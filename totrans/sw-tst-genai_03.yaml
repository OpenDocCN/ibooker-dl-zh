- en: 3 Artificial intelligence, automation, and testing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: The value of good testing
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How tools aid in testing
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to identify when AI tools could be of use in testing
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Before we delve deeper into the use of large language models (LLMs) in testing,
    let’s ask ourselves the following questions:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: What is the purpose and value of testing?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can tooling help us?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When is it appropriate to use AI tools?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It may seem that asking these fundamental questions is unnecessary. But if you
    are someone who sees testing merely as a confirmatory exercise, as in executing
    test cases to confirm a requirement is correct, then your mileage from the subsequent
    chapters will be limited. Understanding the value and performance of testing is
    critical for determining how tools can be used effectively. Thus, in this chapter,
    we’re going to explore why a deeper understanding of testing can help us utilize
    tools. That said, if you are someone who already has that deep understanding,
    feel free to skim through this chapter and move on. For the rest of us, let’s
    go back to square one by asking why we test.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 The value of testing
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To help us appreciate having a clear understanding of why we need testing in
    software development, let’s return to the common perspective that testing is a
    confirmatory exercise. By this, we mean that testing is viewed as something done
    to confirm the following conditions:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Written requirements have been met.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All critical paths have been covered in a system.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The system works as expected.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Teams that hold this perspective tend to overly rely on the use of test cases/scripts
    that contain explicit instructions for a human, or machine, to follow and confirm
    whether an expected outcome has been met. The problem with this mindset and approach
    is less that it’s utilizing test scripts and more that it only uses test scripts
    and nothing else, which results in edge cases being missed, more complex bugs
    or behavior left untested, and generally in a limited understanding of how our
    products behave. Many biases come from an overreliance on test scripts, but if
    we bring it back to the use of LLMs in testing, then it limits our appreciation
    of how these tools can help us. When tools such as ChatGPT grew in popularity,
    a large majority of demonstrations and debates around the use of LLMs in testing
    focused on one thing: test scripts. People would demonstrate how LLMs could generate
    test scripts to be executed manually by either a human or a test automation tool.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Although initially these might have had some use, the options for what else
    could be done with LLMs to help testing began to dry out. On the surface, this
    appears to be a limitation of the tooling in question, but instead, the real problem
    is the limited idea of what testing is and how it can help. So, if we are to expand
    our use of LLMs in testing, we have to first expand our understanding of what
    testing is and how it works.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 A different way of thinking about testing
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To help us establish a deeper understanding, let’s explore a model of testing
    that I use to define what I believe testing is for and how it helps, which is
    shown in figure 3.1.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们建立更深入的理解，让我们探索一个测试模型，我用它来定义我相信测试的目的以及它如何帮助，如图3.1所示。
- en: The model, based on one created by James Lyndsay in his paper “Exploration and
    Strategy” ([https://mng.bz/mRdn](https://mng.bz/mRdn)), consists of two circles.
    The left circle represents imagination, or what we *want* in a product, and the
    right circle represents implementation, or what we *have* in a product. The purpose
    of testing is to learn as much as possible about what’s going on in each of these
    circles by carrying out testing activities. The more we test in these two circles,
    the more we learn. We can then
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型基于詹姆斯·林赛在其论文“探索与策略”中创建的模型（[https://mng.bz/mRdn](https://mng.bz/mRdn)），由两个圆组成。左圆代表想象力，即我们在产品中想要的东西，右圆代表实施，即我们在产品中拥有的东西。测试的目的是通过执行测试活动尽可能多地了解这两个圆中发生的事情。我们在这两个圆中测试得越多，我们就学得越多。然后我们可以
- en: Discover potential problems that might affect the quality
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现可能影响质量的潜在问题
- en: Overlap these two circles of information, ensuring we trust we are building
    the intended product
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将这两个信息圆重叠起来，确保我们相信我们正在构建预期的产品
- en: '![](../../OEBPS/Images/CH03_F01_Winteringham2.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH03_F01_Winteringham2.png)'
- en: Figure 3.1 A model that helps describe the value and purpose of testing
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 一个有助于描述测试价值和目的的模型
- en: To help describe this principle further, let’s look at an example in which a
    team is delivering a hypothetical search feature that we want to ensure is delivered
    to a high degree of quality.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步描述这个原则，让我们看看一个例子，其中一支团队正在交付一个假设的搜索功能，我们希望确保其以高质量交付。
- en: Imagination
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 想象力
- en: 'The Imagination circle represents what it is that we want from our product,
    and that includes expectations that are both explicit and implicit. So in this
    circle, our testing is focused on learning as much as possible about those explicit
    and implicit expectations. By doing so, we not only learn what has been explicitly
    stated in writing or verbally shared, but also dig down into the details and remove
    ambiguity over terms and ideas. Let’s say a representative of the business or
    a user, such as a product owner, has shared this requirement with their team:
    “Search results are to be ordered by relevance.”'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 想象力圆代表我们从产品中想要的东西，这包括显性和隐性的期望。因此，在这个圆中，我们的测试重点是尽可能多地了解这些显性和隐性的期望。通过这样做，我们不仅学习了书面或口头分享的明确内容，还深入细节，消除了术语和概念上的歧义。比如说，业务或用户代表，如产品负责人，已经与他们的团队分享了以下要求：“搜索结果应按相关性排序。”
- en: The explicit information shared here tells us that the product owner wants search
    results ordered by relevance. However, a lot of implied information can be uncovered
    by testing the ideas and concepts behind what is being asked. This might come
    in the form of a series of questions, such as
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这里共享的明确信息告诉我们，产品负责人希望搜索结果按相关性排序。然而，通过测试所提要求背后的想法和概念，可以揭示大量的隐含信息。这可能以一系列问题的形式出现，例如
- en: What is meant by relevant results?
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “相关结果”是什么意思？
- en: Who benefits from the results?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁能从这些结果中受益？
- en: What information is shared?
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分享了哪些信息？
- en: How do we order results by relevancy?
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何按相关性排序结果？
- en: What data should we use?
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该使用什么数据？
- en: By asking these questions, we gain a broader perspective of what is wanted,
    remove any misunderstandings and assumptions in our team’s thinking, and identify
    potential risks that could affect those expectations. If we know more about what
    we are being asked to build, then we’re more likely to build the right thing the
    first time.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过提出这些问题，我们获得了更广泛的视角，消除了我们团队思考中的任何误解和假设，并确定了可能影响这些预期的潜在风险。如果我们对我们被要求构建的内容了解得更多，那么我们更有可能第一次就构建正确的东西。
- en: Implementation
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 实施
- en: By testing the imagination, we get a stronger sense of what we are being asked
    to build. But, just because we might know what to build doesn’t mean we end up
    with a product that matches our expectations. This is why we also test the implementation
    to learn
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过测试想象力，我们能够更强烈地感受到我们被要求构建的内容。但是，仅仅因为我们可能知道要构建什么，并不意味着我们最终得到的产品符合我们的预期。这就是为什么我们还要测试实施过程来学习
- en: Whether the product matches our expectations
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品是否符合我们的预期
- en: How the product might not match our expectations
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品可能不符合我们的预期
- en: Both goals are equally important. We want to ensure that we have built the right
    thing, but there will always be side effects, such as unintended behavior, vulnerabilities,
    missed expectations, and downright weirdness that might appear in our products.
    With our search results example, we could not only test whether the feature delivers
    results in the relevant order but also ask
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个目标同等重要。我们希望确保我们构建了正确的东西，但总会有副作用，比如意外行为、漏洞、未满足的期望，以及可能出现在我们产品中的直接奇怪之处。以我们的搜索结果示例，我们不仅能够测试该功能是否以相关顺序提供结果，还可以询问
- en: What if I use different search terms?
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我使用不同的搜索词会怎样？
- en: What if the relevant results don’t match the behavior of other search tools?
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果相关结果不匹配其他搜索工具的行为怎么办？
- en: What if part of the service is down when I search?
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我在搜索时部分服务中断怎么办？
- en: What if I request results 1000 times in less than 5 seconds?
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我在不到5秒内请求1000次结果会怎样？
- en: What happens if there are no results?
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有结果会发生什么？
- en: By exploring beyond our expectations, we become more aware of what is going
    on in our product—warts and all. This ensures we don’t end up making incorrect
    assumptions about how our product behaves and releasing a poor-quality product.
    It also means that if we find unexpected behavior, we have the choice to attempt
    to remove or readjust our expectations.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通过超越我们的预期进行探索，我们对我们产品中正在发生的事情有了更清醒的认识——包括所有缺点。这确保了我们不会最终对产品行为做出错误的假设，并发布一个质量低劣的产品。这也意味着，如果我们发现意外行为，我们有选择尝试去除或重新调整我们的预期的机会。
- en: 3.1.2 A holistic approach to testing
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1.2 全面的测试方法
- en: The described model of testing the imagination and implementation demonstrates
    that the testing goes beyond a simple confirmation of expectations and lays out
    a more holistic approach to testing. By implementing different activities that
    focus on the imagination and implementation spaces, through the testing we execute,
    we learn more about what we want to build and what we have built. The more we
    learn in these two areas, the more they align with one another. And the more they
    align, the more accurate our perception of quality becomes.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 描述的想象和实施测试模型表明，测试不仅超越了简单确认预期的范畴，而且提出了一种更全面的测试方法。通过实施专注于想象和实施空间的各项活动，通过我们执行的测试，我们能够更多地了解我们想要构建的内容和我们已经构建的内容。在这两个领域学到的越多，它们就越一致。而且，它们越一致，我们对质量的感知就越准确。
- en: A team that is well-informed about their work has a better understanding of
    their product’s quality. We are then also better equipped to decide what steps
    to take to improve quality. This enables us to focus our attention on specific
    risks, make changes in our product to align with users’ expectations or determine
    what problems we want to invest time in to fix and which to leave alone. This
    is the value of good testing—to help teams get into a position where they can
    make these informed decisions and feel confident in the steps they are taking
    to develop a high-quality product.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一个对其工作有充分了解的团队对其产品的质量有更好的理解。然后我们也更有能力决定采取哪些步骤来提高质量。这使得我们能够将注意力集中在特定的风险上，对我们的产品进行更改以符合用户的期望，或确定我们想要投入时间修复的问题，以及哪些问题可以置之不理。这是良好测试的价值——帮助团队进入一个可以做出这些明智决策并对其采取的步骤有信心开发高质量产品的位置。
- en: To help us better appreciate this model, let’s consider a sample context in
    which testing is required. For our example, we are responsible for the delivery
    of a fast-food ordering system. Users log on, find the restaurant they want to
    order from, place their order (which is sent to the restaurant), and then track
    the delivery of their order from within the product. A product like this one would
    need to be highly available, easy to use, and secure. So, to deliver a high-quality
    product, we might need to utilize different testing activities to focus on different
    types of risks, as shown in figure 3.2.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们更好地理解这个模型，让我们考虑一个需要测试的示例情境。在我们的例子中，我们负责交付一个快餐订购系统。用户登录，找到他们想要订购的餐厅，下订单（订单被发送到餐厅），然后从产品内部跟踪订单的配送。这样的产品需要高度可用、易于使用和安全的。因此，为了交付高质量的产品，我们可能需要利用不同的测试活动来关注不同类型的风险，如图3.2所示。
- en: '![](../../OEBPS/Images/CH03_F02_Winteringham2.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH03_F02_Winteringham2.png)'
- en: Figure 3.2 The imagination/implementation model with sample activities shown
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 想象/实施模型，展示了示例活动
- en: In the model, we can see a range of various activities that are placed in specific
    areas because they are focused on specific types of risks. For example, on the
    imagination side, we might be concerned with risks that affect the usability of
    a site. Therefore, we employ testing activities that focus on user experience
    testing and collaborative design. On the implementation side, we want to ensure
    the product is stable and minimize risks that might affect the product availability
    and application. Thus, we employ activities such as exploratory and performance
    testing. Finally, notice how in the area that overlaps, we have added test scripts.
    These are useful because they are informed by our explicit expectations (imagination)
    to mitigate risks around unexpected changes appearing in the product (implementation)
    as it grows and morphs over time, demonstrating that test scripting and automated
    checks are of use but are only one part of the holistic whole.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，我们可以看到一系列各种活动被放置在特定的区域，因为它们专注于特定类型的风险。例如，在想象力方面，我们可能会关注影响网站可用性的风险。因此，我们采用专注于用户体验测试和协作设计的测试活动。在实施方面，我们希望确保产品稳定，并最小化可能影响产品可用性和应用程序的风险。因此，我们采用探索性和性能测试等活动。最后，请注意，在重叠的区域，我们添加了测试脚本。这些脚本是有用的，因为它们基于我们对预期（想象力）的明确期望，以减轻产品在增长和随时间演变过程中出现意外变化的风险（实施），这表明测试脚本和自动化检查是有用的，但它们只是整体的一部分。
- en: Each of these activities has different implementations, different challenges,
    and different ways in which tooling can help. But we wouldn’t be able to easily
    identify these uses if we didn’t understand that testing is an exercise in information
    gathering and knowledge sharing. With this model in place, an appreciation of
    the many different risks our work faces, and the testing activities that help
    mitigate them, we can begin to drill deeper into how tooling plays a part in testing.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这些活动中的每一个都有不同的实施方式、不同的挑战，以及工具如何帮助的不同方式。但如果我们不了解测试是一项信息收集和知识分享的练习，我们就无法轻易地识别这些用途。有了这个模型，我们可以更好地理解我们工作中面临的各种风险，以及有助于减轻这些风险的测试活动，然后我们可以开始深入探讨工具在测试中扮演的角色。
- en: 3.2 How tools help with testing
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 工具如何帮助进行测试
- en: You’ll likely hear a tester say (or you may even have said it yourself) that
    there is never enough time to test everything. It will likely be repeated in this
    book a few times. Teams are always limited by time, budgets, meetings, staffing,
    and other factors, so to implement and execute effective, modern testing, we must
    rely on tools to help us. Tools are essential to testing, but they bring us to
    our next misconception around testing—that a tool, or machine, can test the way
    a human can.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会听到测试员说（或者你可能自己也说过）永远没有足够的时间来测试所有内容。这本书中可能会多次提到这一点。团队总是受限于时间、预算、会议、人员配备和其他因素，因此为了实施和执行有效的现代测试，我们必须依赖工具来帮助我们。工具对于测试至关重要，但它们也让我们对测试产生了下一个误解——即工具或机器可以像人类一样进行测试。
- en: 3.2.1 Automation bias
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.1 自动化偏差
- en: To appreciate how machines and humans differ regarding testing, let’s consider
    an example where both are used to test a website feature. The feature is a full-width
    banner for an e-commerce website with an image and some text to highlight the
    deal of the day. Initially, we test it manually, or in a human-led way, and observe
    the feature is working properly—the image is shown and all the text associated
    with it is correct. Then we decide to use tools to automate testing. We create
    code that will open the browser and assert that element A, which is where the
    deal of the day is loaded, exists. We run the automated test, and it passes. And
    then, one day, after another successful release in which all our automated tests
    pass, an end-user raises a bug and informs us they can’t see the deal of the day.
    All they see is an empty white box at the top of the page.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解机器和人类在测试方面的差异，让我们考虑一个例子，其中两者都被用来测试一个网站功能。这个功能是一个电子商务网站的全宽横幅，其中包含一张图片和一些文字来突出当天的交易。最初，我们手动测试或以人为主导的方式进行测试，并观察到该功能运行正常——图片显示，并且所有与之相关的文字都是正确的。然后我们决定使用工具来自动化测试。我们编写了代码，该代码将打开浏览器并断言元素A存在，这是当天交易加载的地方。我们运行了自动化测试，并且它通过了。然后，有一天，在所有自动化测试都通过的成功发布之后，一个最终用户提出了一个错误，并告诉我们他们看不到当天的交易。他们看到的是页面上方的空白白色框。
- en: 'What happened? During the process of creating the automated test, we have transferred
    our knowledge, which is built on implicit information based on mental heuristics
    and oracles, and made it explicit. We have stripped a complex understanding of
    a feature down to a single instruction: element A should exist on a web page.
    So, when the latest release of our product went out with a faulty function to
    retrieve the deal of the day, or the CSS was incorrect or broken, the automated
    test still passed because element A still exists. However, it takes a human a
    matter of seconds to see something is wrong.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 发生了什么？在创建自动化测试的过程中，我们将基于基于心理启发式和占卜的隐含信息构建的知识转移，并将其明确化。我们将对功能复杂理解简化为一条指令：元素A应该存在于网页上。因此，当我们的产品最新版本发布时，如果有一个功能错误地检索当天的交易，或者CSS不正确或损坏，自动化测试仍然通过，因为元素A仍然存在。然而，人类只需要几秒钟就能看出有问题。
- en: The moral of this story isn’t that tools are bad or unnecessary but that they
    are often misused or misinterpreted. This behavior is a type of *automation bias*
    that creeps into our perspective on the value of tooling, where we ascribe more
    value to the output of a tool than what it is relaying to us. That is, when we
    designed our automated test to look for element A, we assumed that all we as humans
    were doing was looking for element A. But we were considering many other factors,
    even if we weren’t doing it consciously.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这个故事的意义并不是工具本身不好或不必要，而是它们常常被误用或误解。这种行为是一种渗透到我们对工具价值看法中的*自动化偏差*，我们赋予工具输出的价值超过了它传达给我们的价值。也就是说，当我们设计自动化的测试来寻找元素A时，我们假设我们作为人类所做的只是寻找元素A。但我们还考虑了许多其他因素，即使我们没有有意识地这样做。
- en: If we fall prey to automation bias, we run the risk of selecting and implementing
    tools that we believe can reveal and report information in the same way humans
    can, when in fact they don’t, leading to misguided overconfidence in the products
    we’re delivering, or generating a level of workload to have tools emulate human
    behavior that is unsustainable for a modern project. Tools cannot replace testing
    activities, and subscribing to that notion will ultimately lead to problems with
    quality and an increase in risks to a project. So instead, we have to shift our
    thinking more toward how tools can support our testing.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们陷入自动化偏差的陷阱，我们就有可能选择并实施那些我们认为可以像人类一样揭示和报告信息的工具，而实际上它们并不能做到这一点，这可能导致我们对交付的产品产生误导性的过度自信，或者产生一种对于现代项目来说不可持续的工具模拟人类行为的工作量。工具不能取代测试活动，坚持这种观念最终会导致质量问题，并增加项目的风险。因此，我们不得不更多地转变我们的思维方式，思考工具如何支持我们的测试。
- en: 3.2.2 Being selective with tooling
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.2 对工具的选择性使用
- en: Success with tools comes from situations in which some thought has been put
    into the problem we want to solve and what tools could potentially help. To better
    understand this, let’s return to our deal-of-the-day feature and look closer at
    what a human is doing when they test a feature like this.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 工具的成功来自于我们对想要解决的问题以及可能帮助的工具进行了思考的情况。为了更好地理解这一点，让我们回到我们的当天的交易功能，并更仔细地看看当人类测试这样的功能时他们在做什么。
- en: First, we consider different ways of testing the feature. We use our current
    understanding of said feature to formulate test ideas and select what we want
    to test first. Next, we need to set up our test. This might include setting up
    an environment or creating/updating the necessary test data. (We might need to
    create a deal of the day to observe as well as test users to administer and view
    the deal.) With everything set up, we then need to execute our test, loading the
    browser or perhaps multiple browsers to verify that the deal renders correctly.
    Then once we’ve observed the results, we take notes or report our findings to
    our team, all of which would update our understanding of the feature, ready for
    us to start the process again. This flow can be summarized as shown in figure
    3.3.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们考虑不同的测试方法。我们使用对所述功能的当前理解来制定测试想法，并选择首先测试什么。接下来，我们需要设置我们的测试。这可能包括设置环境或创建/更新必要的测试数据。（我们可能需要创建一个当天的交易来观察以及测试用户来管理和查看交易。）一切准备就绪后，我们接下来需要执行我们的测试，加载浏览器或多个浏览器以验证交易是否正确渲染。然后，一旦我们观察到了结果，我们就做笔记或向团队报告我们的发现，所有这些都会更新我们对功能的理解，以便我们再次开始这个过程。这个流程可以总结如图3.3所示。
- en: '![](../../OEBPS/Images/CH03_F03_Winteringham2.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH03_F03_Winteringham2.png)'
- en: Figure 3.3 A visualization of the process of testing the deal-of-the-day feature
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: This cycle may be something that happens rapidly—for example, in an exploratory
    testing session. Or it may take place in a longer form, such as performance testing,
    in which each step has many details to consider. Regardless of the type of activity,
    to carry out the loop successfully, we need tools to complete the process. We
    would likely need to use tools such as database clients, test data managers, or
    infrastructure tools to set up state management. We would use note-taking tools,
    screenshot applications, and project management tools to report what has been
    learned. Figure 3.4 summarizes these tools used in testing by updating our initial
    visualization.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: The visualization demonstrates how modern testing utilizes a range of tools
    for various tasks that occur rather than attempting to wrap the whole testing
    performance into the use of one tool. This is because there are many different
    activities at play when testing is carried out. A tool’s ability to observe patterns,
    changes, and problems will always be limited compared to a human’s observation
    skills. So instead, we get value from tools that do one job well, as opposed to
    a tool that does many things poorly.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: What is so interesting about this kind of thinking is that when we take the
    time to consider it, it seems obvious to us. We all use tools to help us with
    distinct tasks that make up a larger activity. However, most of us do it without
    deliberate thought. Although we know that the use of tools in specific tasks is
    sensible, we need to develop the skills to start choosing and using tools intentionally.
    This means familiarizing ourselves with tools and being more in tune with what
    we’re doing daily in our testing so that we can pick the right tool or, in the
    case of LLMs, the right prompt or enhancement. This is what the rest of this book
    will be focusing on, providing us with the skills needed to know when LLMs can
    help with specific tasks.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F04_Winteringham2.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 A visualization of the testing process, this time with the addition
    of tools
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Knowing when to use LLMs in testing
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now understand how effective tool use in testing is about looking to enhance
    tasks within testing rather than replicating broad testing activities. But where
    do LLMs fit into this? Given their broad applications, let’s take a look at some
    of the common ways in which LLMs are currently being used and see how each can
    be used to support testing.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.1 Generative capabilities
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the vast field of artificial intelligence, LLMs fall under the banner of
    generative AI; that is, LLMs have been built with the purpose of generating content
    (which differs from other AI that may be used to predict or classify). For example,
    this means that if an LLM was asked to generate test cases for us, it would do
    so. However, just because it can generate material like test cases doesn’t mean
    that those test cases are of value to us. We must remind ourselves that how an
    LLM generates outputs is based on a complex model of probabilities. This means
    its generative abilities differ from how we as humans might generate ideas.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'If you recall, in chapter 1 we explored this concept when sending a prompt
    to an LLM:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: '| Create tests for a file upload feature |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
- en: 'which might result in a response like this one (shortened for brevity):'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
- en: '|    1.  Test for File Upload Functionality:   •   Test Case 1.1: Upload a
    Valid File   −   Input: Choose a file with a valid format (e.g., .jpg, .pdf).  
    −   Expected Outcome: The file is successfully uploaded, and a confirmation message
    is displayed.   •   Test Case 1.2: Attempt to Upload an Invalid File   −   Input:
    Choose a file with an invalid format (e.g., .exe, .xhtml).   −   Expected Outcome:
    An error message is displayed, indicating that the file format is not supported.  
    2.  Test for File Size Limit:   •   Test Case 2.1: Upload a File Below the Size
    Limit   −   Input: Choose a file smaller than the maximum allowed size.   −  
    Expected Outcome: The file is successfully uploaded, and a confirmation message
    is displayed.   •   Test Case 2.2: Attempt to Upload a File Exceeding the Size
    Limit   −   Input: Choose a file larger than the maximum allowed size.   −   Expected
    Outcome: An error message is displayed, indicating that the file exceeds the maximum
    size limit. |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
- en: How an LLM has generated these test cases is impressive, but they lack context
    and specificity for the feature or product we are testing. So instead, when working
    with LLMs, we need to make sure that how we prompt or extend them provides them
    with enough context to generate valuable outputs.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: The consequence of ensuring that we provide sufficient context is that it’s
    easier to use LLMs to generate outputs for very specific and targeted tasks. The
    alternative means we would have to provide a massive amount of input data that
    would result in a prompt that is expensive to build and maintain. For example,
    imagine the amount of context you would have to put into an LLM to obtain a test
    strategy relevant to our working context.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Instead, we can get more value from LLMs if we focus on using them to help with
    tasks such as
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '*Test data generation*—When given explicit rules around data sets, LLMs can
    be used to generate rapid sets of data for use in a range of testing activities,
    from exploratory to performance testing.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Suggestions for risks and test ideas*—We should always avoid letting the output
    of an LLM be the sole arbiter of what to test. We can use them to suggest test
    ideas and risks that can be used as jumping-off points for new ideas or factored
    into our existing work.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*风险和建议测试想法*—我们应始终避免让LLM的输出成为测试的唯一仲裁者。我们可以使用它们来提出测试想法和风险，这些想法可以作为新想法的起点或纳入我们的现有工作中。'
- en: '*Code snippets*—Similar to the earlier test case example, we gain little value
    from LLMs if we ask them to generate complete automated tests or frameworks. However,
    using them to generate smaller parts of automation or scripts used to support
    testing activities such as exploratory testing can be advantageous.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*代码片段*—与早期的测试案例示例类似，如果我们要求LLMs生成完整的自动化测试或框架，那么从LLMs那里获得的价值很小。然而，使用它们来生成自动化或脚本的较小部分，这些自动化或脚本用于支持测试活动，如探索性测试，可能是有利的。'
- en: 3.3.2 Transformation capabilities
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.2 转换功能
- en: 'Another benefit that LLMs offer is the ability to transform natural language
    from one structure to another. A common example of LLM transformation is language
    translation. Suppose that we sent something like this to an LLM:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs提供的另一个好处是将自然语言从一种结构转换为另一种结构的能力。LLMs转换的一个常见例子是语言翻译。假设我们向LLM发送了如下内容：
- en: '|'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| Convert the following text delimited by three hashes into French:###Hello,
    my name is Mark### |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 将以下由三个井号分隔的文本翻译成法语：###Hello, my name is Mark### |'
- en: Then it will return a response such as
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它将返回如下响应
- en: '|'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '| Bonjour, je m’appelle Mark |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Bonjour, je m''appelle Mark |'
- en: 'This is a useful way to illustrate how LLMs transform data, but we shouldn’t
    be restricted to spoken languages only. LLMs are capable of transforming all types
    of data from one abstraction to another. Here are some examples that can help
    with testing:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种有用的方式来展示LLMs如何转换数据，但我们不应仅限于口头语言。LLMs能够将所有类型的数据从一种抽象转换为另一种抽象。以下是一些有助于测试的例子：
- en: '*Transforming test data*—Using LLMs to rapidly transform data from one structure
    to another can help speed up testing. For example, we might ask an LLM to convert
    plain-text test data into SQL statements or to convert SQL statements into helper
    functions that are called in test automation.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*转换测试数据*—使用LLMs快速将数据从一种结构转换为另一种结构可以帮助加快测试速度。例如，我们可能要求LLM将纯文本测试数据转换为SQL语句，或将SQL语句转换为在测试自动化中调用的辅助函数。'
- en: '*Converting code*—LLMs can convert functions, classes, and other data into
    new iterations of code. What makes this valuable is that LLMs can transform code
    into different languages but still keep the logic and flow of the original code
    in the newly translated output (although we should always test it to be sure).'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*将代码转换*—大型语言模型（LLMs）可以将函数、类和其他数据转换为代码的新迭代。这使得LLMs非常有价值，因为它们可以将代码转换为不同的语言，同时仍然保持原始代码在新翻译输出中的逻辑和流程（尽管我们始终应该测试以确保无误）。'
- en: '*Summarizing notes*—Although the conversion of data isn’t as direct as, say,
    converting a code snippet from one language to another, we can use LLMs to transform
    and summarize at the same time. Also, we can use LLMs to take raw testing notes
    from testing activities such as exploratory or design testing sessions and have
    them converted into summary notes to be shared with others.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*总结笔记*—虽然数据的转换不像将代码片段从一种语言转换为另一种语言那样直接，但我们可以使用LLMs同时进行转换和总结。此外，我们可以使用LLMs将测试活动（如探索性或设计测试会议）中的原始测试笔记转换为总结笔记，与他人共享。'
- en: 3.3.3 Enhancing capabilities
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.3 增强功能
- en: Finally, we can use LLMs to enhance and expand existing material. This usually
    means providing an LLM with a snippet of data and prompting the LLM to expand
    on it. This has some overlap with the generative capabilities because we’re asking
    LLMs to generate a certain degree of new output, but in this situation, we’re
    providing a lot more upfront context and instructing it to focus on existing material,
    as opposed to prompting an LLM to generate something completely new. This means
    we can use this ability to help us with testing tasks such as
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用LLMs来增强和扩展现有材料。这通常意味着向LLM提供一段数据片段，并提示LLM对其进行扩展。这与生成能力有一些重叠，因为我们要求LLMs生成一定程度的新的输出，但在这个情况下，我们提供了更多的前置上下文，并指导它关注现有材料，而不是提示LLM生成全新的内容。这意味着我们可以利用这种能力来帮助我们完成测试任务，例如
- en: '*Reviewing code*—Not all who conduct testing are confident coders, and even
    those who are comfortable with reading code can struggle at times to make sense
    of the code required to analyze or test. LLMs can enhance our understanding by
    taking code snippets and providing a natural language breakdown of how said code
    works, which can help with risk analysis, test design, and more.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Descriptive code*—Similar to reviewing code, we can use LLMs to help improve
    the descriptiveness of code—for example, rapidly creating code comments that can
    be easily created and maintained. This can be especially useful for automated
    testing, where communicating what our automation code is doing is important for
    maintenance.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Expanding analysis*—We can also use LLMs to expand our analysis activities,
    such as risk analysis and design testing (where we ask questions about requirements
    before the feature is built). By providing it with our current analysis data,
    we can ask LLMs to review and expand on it, suggesting new ideas that we can either
    incorporate into our analysis or ignore.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3.3.4 LLMs in use in testing
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To put these different abilities of an LLM into context, let’s return to our
    visualization of testing with the support of tools (figure 3.5).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F05_Winteringham2.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 A visualization of the testing process, this time with the addition
    of LLMs
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Here, we can see how LLMs can be inserted into distinct and specific tasks within
    the wider testing lifecycle. It brings us back to our area of effect model that
    we covered in chapter 1\. Instead of attempting to use LLMs to replicate the full
    gamut of testing activities that exist within a lifecycle, we prioritize the best
    of our abilities as humans and the value we bring to testing. Then, we choose
    to add LLMs in select areas to expand our work so that we can move faster, learn
    more, and help ensure our teams are better informed so that they can build higher-quality
    products.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we have a limited understanding of what testing is, then the use of tools
    will also be limited.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing is not a confirmatory exercise but rather a collection of different
    activities that help those seeking to learn about the imagination and implementation
    of a product.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The imagination implies our understanding of what we want to build.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The implementation implies our understanding of what we have built.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As our understanding of both aspects increases, we bring them into alignment,
    which helps us deliver a higher-quality product.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We run many different types of testing activities to focus on different types
    of risks and how they affect both imagination and implementation.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools are an essential component of successful testing.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs can be used to generate, transform, and enhance outputs.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs should be used with smaller, specific tasks to generate outputs that provide
    value.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs can generate content that can help with specific tasks or create suggested
    content.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs can transform data to help convert raw data into useful formats or summarize
    it.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs可以将数据转换为帮助将原始数据转换为有用的格式或总结它。
- en: LLMs can also enhance existing material, adding new suggestions or expanding
    details.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs还可以增强现有材料，添加新的建议或扩展细节。
- en: We can insert LLMs into many distinct and specific testing tasks, which reflects
    the area of effect model we learned about in chapter 1.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以将LLMs插入到许多不同和具体的测试任务中，这反映了我们在第一章中学到的效应模型领域。
