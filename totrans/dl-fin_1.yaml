- en: Chapter 2\. Essential Probabilistic Methods for Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章。深度学习的基本概率方法
- en: The rise and accessibility of technology have made it possible for everyone
    to deploy machine learning and deep learning algorithms for data analysis and
    optimization. But unfortunately, this means that a large number of users do not
    understand the basics and underlyings of the different learning models. This makes
    machine learning nothing short of a black box to them, which is a recipe for disaster.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 技术的兴起和可访问性使每个人都能够部署机器学习和深度学习算法进行数据分析和优化。但不幸的是，这意味着许多用户不了解不同学习模型的基础和基础知识。这使得机器学习对他们来说简直就是一个黑匣子，这是一场灾难的前兆。
- en: Fundamental concepts in probability, statistics, and math are essential for
    understanding and mastering data as well as the creation of models that seek to
    interpret and forecast it if possible. This chapter presents the basics of the
    numerical concepts needed to understand the different learning algorithms, or
    at the very least, shows the starting points from where you can build up your
    knowledge towards mastering these mathematical topics.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 理解和掌握概率、统计和数学的基本概念对于理解和掌握数据以及创建试图解释和预测数据的模型至关重要。本章介绍了理解不同学习算法所需的数值概念的基础知识，或者至少展示了你可以从哪里开始建立知识以掌握这些数学主题。
- en: For simplicity, the term *machine learning* used in this book refers to all
    types of learning models (such as machine, deep, and reinforcement learning).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为简单起见，本书中使用的术语*机器学习*指的是所有类型的学习模型（如机器学习、深度学习和强化学习）。
- en: A Primer on Probability
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率入门
- en: '*Probability* is all about describing random variables and random events. The
    world is filled with randomness, and the best way to find your way through chaos
    is to try to explain it using probabilistic methods. Granted, the phrase *explain
    chaos* may be an oxymoron, as chaos cannot really be explained, but we humans
    cannot relinquish control over uncertain events, and with progress we have developed
    tools to make sense out of the scary world.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*概率*是描述随机变量和随机事件的一切。世界充满了随机性，找到穿越混乱的最佳方法是尝试使用概率方法来解释它。诚然，短语*解释混乱*可能是一个矛盾修饰语，因为混乱实际上无法解释，但我们人类无法放弃对不确定事件的控制，随着进步，我们已经开发出工具来理解这个可怕的世界。'
- en: You may wonder what is the use of understanding the basics of probability when
    trying to develop machine learning algorithms for financial trading. This is a
    reasonable question, and you must know that the foundations of a discipline do
    not necessarily resemble it.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道在尝试为金融交易开发机器学习算法时理解概率基础的用途是什么。这是一个合理的问题，你必须知道，一个学科的基础不一定与它相似。
- en: For example, to become a pilot, you have to have to study aerodynamics first,
    which is filled with technical concepts that do not resemble the final skill acquired
    at graduation. This is similar to what is being done in this chapter; by studying
    probabilistic essentials, statistical concepts, and mathematical topics, you will
    start on the right track towards being a machine learning developer.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要成为一名飞行员，你必须首先学习空气动力学，其中充满了与毕业后获得的最终技能不相似的技术概念。这与本章中所做的类似；通过学习概率基础知识、统计概念和数学主题，你将开始走上成为机器学习开发人员的正确道路。
- en: 'Knowing the utility of what you are learning should give you a motivation boost.
    Here are some key probability topics that are important for machine learning:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 了解你正在学习的东西的用途应该会给你动力。以下是一些对机器学习重要的关键概率主题：
- en: Probability distribution functions
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 概率分布函数
- en: The possibility of seeing various outcomes of a random variable is described
    by a *probability distribution*. For many machine learning techniques, it is essential
    to comprehend the features and attributes of typical probability distributions.
    Probability distribution functions also describe different types of time series
    data, which in turn helps in choosing the right algorithm.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*概率分布*描述了随机变量的各种结果的可能性。对于许多机器学习技术来说，理解典型概率分布的特征和属性是至关重要的。概率分布函数还描述了不同类型的时间序列数据，从而有助于选择正确的算法。'
- en: Bayes’ theorem for updating probabilities
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理用于更新概率
- en: Bayes’ theorem is a cornerstone of probability theory and offers a method for
    updating an event’s probability in light of new data. It is incorporated into
    a variety of machine learning techniques, including as Bayesian networks and classifiers.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理是概率论的基石，提供了一种在新数据的光下更新事件概率的方法。它被纳入到各种机器学习技术中，包括贝叶斯网络和分类器。
- en: Hypothesis testing
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 假设检验
- en: '*Hypothesis testing* is used to establish whether a population-based assertion
    is more likely to be true or incorrect based on a sample of data. Many machine
    learning models employ hypothesis testing in their process.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设检验*用于确定基于数据样本的人口断言更可能是真实还是错误的。许多机器学习模型在其过程中使用假设检验。'
- en: Decision trees
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树
- en: '*Decision trees* are a type of machine learning algorithm that borrows from
    probabilistic concepts such as conditional probability, a concept covered in this
    chapter. For more detail, decision trees are covered in Chapter 7.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*决策树*是一种借鉴了条件概率等概率概念的机器学习算法，本章涵盖了这个概念。更详细的内容，决策树在第7章中有详细介绍。'
- en: Information theory
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 信息论
- en: '*Information theory* is the complex study of how information is quantified,
    stored, and transmitted. It is incorporated into numerous machine learning techniques,
    including decision trees.​'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*信息论*是关于信息如何被量化、存储和传输的复杂研究。它被纳入到许多机器学习技术中，包括决策树。'
- en: Introduction to Probabilistic Concepts
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率概念简介
- en: The most basic piece of probabilistic information is a *random variable,* which
    is an uncertain number or outcome. Random variables are used to model events that
    are considered uncertain, such as the future return of a currency pair.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 概率信息中最基本的部分是*随机变量*，它是一个不确定的数字或结果。随机变量用于模拟被认为是不确定的事件，例如货币对未来回报。
- en: 'A random variable is either discrete or continuous. A *discrete random variable*
    has a finite set of values, while a *continuous random variable* has values within
    a certain interval. Consider the following two examples to clarify things:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量要么是离散的，要么是连续的。*离散随机变量*具有有限的值集，而*连续随机变量*具有在某个区间内的值。考虑以下两个例子以澄清事情：
- en: An example of a discrete random variable would be the result of a rolling a
    die. They are limited by the following set {1, 2, 3, 4, 5, 6}.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离散随机变量的一个例子是掷骰子的结果。它们受以下集合的限制{1, 2, 3, 4, 5, 6}。
- en: An example of a continuous random variable would be the daily price returns
    of EURUSD (The exchange rate of 1 Euro per US Dollars).
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续随机变量的一个例子是EURUSD的每日价格回报（1欧元兑换美元的汇率）。
- en: Random variables are described by *probability distributions,* which are functions
    that give the probability of every possible value of these random variables. Generally,
    a histogram is used to show the probability. Histogram plotting is discussed later
    in the chapter.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量由*概率分布*描述，这是给出这些随机变量的每个可能值的概率的函数。通常，直方图用于显示概率。直方图绘制将在本章后面讨论。
- en: At any moment, the probability that a certain event unfolds is between 0 and
    1\. This means that probability is assigned to random variables on a scale between
    0 and 1 such that a probability of 0 represents zero chance of occurence and a
    probability of 1 represents a certainty of occurence.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何时刻，某个事件发生的概率在0和1之间。这意味着概率被分配给随机变量，范围在0到1之间，其中概率为0表示发生的机会为零，概率为1表示发生的确定性。
- en: You can also think of this in percentage terms, which range from 0% to 100%.
    Values within the two numbers are valid, which means that you can have a 0.5133
    (51.33%) probability of a certain event occurring. Consider rolling a die that
    has six sides. What is the probability of getting 3 knowing that the die is not
    manipulated in any way?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以将其以百分比表示，范围从0%到100%。这两个数字之间的值是有效的，这意味着某个事件发生的概率可以是0.5133（51.33%）。考虑掷一个有六个面的骰子。在不以任何方式操纵骰子的情况下，得到3的概率是多少？
- en: 'As the die has six sides, there are six equal probabilities for every outcome,
    which means that for any outcome, the probability is found as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于骰子有六个面，每个结果有六个相等的概率，这意味着对于任何结果，概率如下找到：
- en: <math alttext="upper P left-parenthesis x right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis x right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
- en: 'With *P(x)* designating the probability of event *x*. This gives the answer
    to the question:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 用*P(x)*表示事件*x*的概率。这给出了问题的答案：
- en: <math alttext="upper P left-parenthesis 3 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>3</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis 3 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>3</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
- en: 'When a die is rolled, there can only be one result. It cannot give 3 and 4
    simultaneously, since one side has to dominate the other. This is the concept
    of *mutual exclusivity*. Mutually exclusive events (such as getting a 3 or getting
    a 4 in a die roll) eventually sum up to 1\. Take a look at the following example:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 掷骰子时，只能有一个结果。它不能同时给出3和4，因为一面必须占优势。这就是*互斥性*的概念。互斥事件（例如在掷骰子时得到3或得到4）最终总和为1。看看以下例子：
- en: <math alttext="upper P left-parenthesis 1 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>1</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis 1 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>1</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
- en: <math alttext="upper P left-parenthesis 2 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>2</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis 2 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>2</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
- en: <math alttext="upper P left-parenthesis 3 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>3</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis 3 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>3</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
- en: <math alttext="upper P left-parenthesis 4 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>4</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis 4 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>4</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
- en: <math alttext="upper P left-parenthesis 5 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>5</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis 5 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>5</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
- en: <math alttext="upper P left-parenthesis 6 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>6</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis 6 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>6</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
- en: 'Summing all these mutually exclusive events gives 1, which means that the sum
    of the possible probabilities in a six-sided die is as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有这些互斥事件相加得到1，这意味着六面骰子中可能概率的总和如下：
- en: <math alttext="upper P left-parenthesis 1 right-parenthesis plus upper P left-parenthesis
    2 right-parenthesis plus upper P left-parenthesis 3 right-parenthesis plus upper
    P left-parenthesis 4 right-parenthesis plus upper P left-parenthesis 5 right-parenthesis
    plus upper P left-parenthesis 6 right-parenthesis equals 1"><mrow><mi>P</mi> <mo>(</mo>
    <mn>1</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>2</mn> <mo>)</mo> <mo>+</mo>
    <mi>P</mi> <mo>(</mo> <mn>3</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>4</mn>
    <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>5</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi>
    <mo>(</mo> <mn>6</mn> <mo>)</mo> <mo>=</mo> <mn>1</mn></mrow></math>
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis 1 right-parenthesis plus upper P left-parenthesis
    2 right-parenthesis plus upper P left-parenthesis 3 right-parenthesis plus upper
    P left-parenthesis 4 right-parenthesis plus upper P left-parenthesis 5 right-parenthesis
    plus upper P left-parenthesis 6 right-parenthesis equals 1"><mrow><mi>P</mi> <mo>(</mo>
    <mn>1</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>2</mn> <mo>)</mo> <mo>+</mo>
    <mi>P</mi> <mo>(</mo> <mn>3</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>4</mn>
    <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>5</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi>
    <mo>(</mo> <mn>6</mn> <mo>)</mo> <mo>=</mo> <mn>1</mn></mrow></math>
- en: Note
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: Stating that a random variable has a 0.8 probability of occurring is the same
    as stating that the same variable has a 0.2 probability of not occurring.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 声明随机变量有0.8的发生概率等同于声明相同变量有0.2的不发生概率。
- en: Probability measures can be conditional or unconditional. A *conditional probability*
    is where the occurrence of an event impacts the probability that another events
    occurs. For example, the probability of a sovereign interest rate hike given positive
    employment data is an example of a conditional probability. The probability of
    event A given the occurrence of event B is denoted by the following mathematical
    notation: *P(A|B)*
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 概率测量可以是条件的或无条件的。*条件概率*是指事件发生影响另一个事件发生的概率。例如，鉴于积极的就业数据，主权利率上涨的概率是条件概率的一个例子。给定事件B发生的情况下事件A发生的概率由以下数学符号表示：*P(A|B)*
- en: In contrast, *unconditional probability* is not dependent on other events. Taking
    the example of the conditional probability, you can formulate an unconditional
    probability calculation which measures the probability of an interest rate hike
    regardless of other economic events.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，*无条件概率*不依赖于其他事件。以条件概率为例，您可以制定一个无条件概率计算，该计算测量利率上涨的概率，而不考虑其他经济事件。
- en: 'Probabilities have specific addition and multiplication rules with their own
    interpretations. Let’s take a look at the formulas before seeing an example. The
    *joint probability* of the realization of two events is the probability that they
    will both occur. It is calculated using the following formula:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 概率具有特定的加法和乘法规则，具有自己的解释。在看例子之前，让我们先看一下公式。两个事件实现的*联合概率*是它们都发生的概率。它是使用以下公式计算的：
- en: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    upper P left-parenthesis upper A vertical-bar upper B right-parenthesis times
    upper P left-parenthesis upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo>
    <mi>A</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>|</mo>
    <mi>B</mi> <mo>)</mo> <mo>×</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo></mrow></math>
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    upper P left-parenthesis upper A vertical-bar upper B right-parenthesis times
    upper P left-parenthesis upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo>
    <mi>A</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>|</mo>
    <mi>B</mi> <mo>)</mo> <mo>×</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo></mrow></math>
- en: What that formula says is that the probability of occurence for both A and B
    is the probability that A occurs given B occurs multiplied by the probability
    that B occurs. Therefore, the right side of the equation multiplies a conditional
    probability by an unconditional probability.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 该公式表示的是A和B同时发生的概率是A在B发生的情况下发生的概率乘以B发生的概率。因此，等式的右侧将一个条件概率乘以一个无条件概率。
- en: 'The *addition rule* is used to determine the probability that at least one
    of the two outcomes will occur. This works in two ways: the first one deals with
    mutually exclusive events, and the second one deals with events that are non mutually
    exclusive:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*加法规则*用于确定至少发生两个结果中的一个的概率。这有两种方式：第一种处理互斥事件，第二种处理非互斥事件：'
- en: 'If the events are not mutually exclusive, then to add avoid double counting,
    the formula is:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果事件不是互斥的，则为避免重复计数，公式如下：
- en: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis minus upper P left-parenthesis upper A upper B right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <mi>A</mi> <mi>o</mi> <mi>r</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi>
    <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo>
    <mo>-</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo></mrow></math>
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis minus upper P left-parenthesis upper A upper B right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <mi>A</mi> <mi>o</mi> <mi>r</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi>
    <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo>
    <mo>-</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo></mrow></math>
- en: 'If the events are mutually exclusive, then the formula is simplified to the
    following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果事件是互斥的，则公式简化为以下形式：
- en: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    0"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn></mrow></math>
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    0"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn></mrow></math>
- en: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis minus 0"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>o</mi>
    <mi>r</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo>
    <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo> <mo>-</mo> <mn>0</mn></mrow></math>
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis minus 0"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>o</mi>
    <mi>r</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo>
    <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo> <mo>-</mo> <mn>0</mn></mrow></math>
- en: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>o</mi> <mi>r</mi>
    <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>+</mo>
    <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo></mrow></math>
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>o</mi> <mi>r</mi>
    <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>+</mo>
    <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo></mrow></math>
- en: Notice how in mutually exclusive events, it’s either A or B that can be realized, and
    therefore the probability that both of them will occur is zero. To understand
    why you need to subtract the joint probability of A and B, take a look at Figure
    2-1.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在互斥事件中，只能实现A或B，因此两者都发生的概率为零。要理解为什么需要减去A和B的联合概率，请看图2-1。
- en: '![](Images/dlf_0333.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlf_0333.png)'
- en: Figure 2-1\. The addition rule of probability
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-1。概率的加法规则
- en: Notice how the probability of either A or B occurring while they are mutually
    exclusive must not include their joint probability. Let’s now look at the concept
    of independent events.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，当A或B发生的概率互斥时，必须不包括它们的联合概率。现在让我们来看看独立事件的概念。
- en: '*Independent events* are not tied together (for example, rolling the die twice).
    The joint probability is calculated as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*独立事件*不相互关联（例如，掷骰子两次）。联合概率计算如下：'
- en: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    upper P left-parenthesis upper A right-parenthesis times upper P left-parenthesis
    upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo>
    <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>×</mo> <mi>P</mi> <mo>(</mo>
    <mi>B</mi> <mo>)</mo></mrow></math>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    upper P left-parenthesis upper A right-parenthesis times upper P left-parenthesis
    upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo>
    <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>×</mo> <mi>P</mi> <mo>(</mo>
    <mi>B</mi> <mo>)</mo></mrow></math>
- en: Independent events therefore refer to instances where the occurrence of one
    has absolutely zero impact on the occurrence of the others. Now, let’s see an
    example to validate these concepts. Consider a simple coin toss. The probability
    of getting heads does not depend on what you have gotten in the previous coin
    toss. Therefore the probability of getting heads is always 0.50 (50%). To take
    things further, what is the probability of getting only heads after five coin
    tosses?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，独立事件指的是一个事件的发生对其他事件的发生绝对没有影响。现在，让我们看一个例子来验证这些概念。考虑一个简单的抛硬币。得到正面的概率不取决于您在上一个抛硬币中得到的结果。因此，得到正面的概率始终为0.50（50%）。更进一步，连续五次抛硬币后只得到正面的概率是多少？
- en: 'As the probability of each event is independent from the previous or the next
    one, the formula is as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个事件的概率与前一个或下一个事件是独立的，因此公式如下：
- en: <math alttext="upper P left-parenthesis x right-parenthesis equals 0.50 times
    0.50 times 0.50 times 0.50 times 0.50 equals 0.03125 equals 3.125 percent-sign"><mrow><mi>P</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>50</mn>
    <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>50</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo>
    <mn>50</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>50</mn> <mo>×</mo> <mn>0</mn>
    <mo>.</mo> <mn>50</mn> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>03125</mn> <mo>=</mo>
    <mn>3</mn> <mo>.</mo> <mn>125</mn> <mo>%</mo></mrow></math>
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis x right-parenthesis equals 0.50 times
    0.50 times 0.50 times 0.50 times 0.50 equals 0.03125 equals 3.125 percent-sign"><mrow><mi>P</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>50</mn>
    <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>50</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo>
    <mn>50</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>50</mn> <mo>×</mo> <mn>0</mn>
    <mo>.</mo> <mn>50</mn> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>03125</mn> <mo>=</mo>
    <mn>3</mn> <mo>.</mo> <mn>125</mn> <mo>%</mo></mrow></math>
- en: 'The *expected value* of a random variable is the weighted average of the different
    outcomes. Therefore, the expected value is really another way of referring to
    the mean. Mathematically, the expected value is as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量的*期望值*是不同结果的加权平均值。因此，期望值实际上是指均值的另一种方式。在数学上，期望值如下：
- en: <math alttext="upper E left-parenthesis upper X right-parenthesis equals sigma-summation
    Underscript i equals 1 Overscript n Endscripts left-parenthesis upper P left-parenthesis
    x Subscript i Baseline right-parenthesis x Subscript i Baseline right-parenthesis"><mrow><mi>E</mi>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper E left-parenthesis upper X right-parenthesis equals sigma-summation
    Underscript i equals 1 Overscript n Endscripts left-parenthesis upper P left-parenthesis
    x Subscript i Baseline right-parenthesis x Subscript i Baseline right-parenthesis"><mrow><mi>E</mi>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>
- en: Take a look at Table 2-1 and try to calculate the expected value of the next
    employment numbers in a certain month of the year.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下表2-1，尝试计算一年中某个月的下一个就业人数的期望值。
- en: Table 2-1\. Employment table
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 表2-1。就业表
- en: '| Non-farm payrolls | Probability |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 非农就业人数 | 概率 |'
- en: '| 300,000 | 0.1 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 300,000 | 0.1 |'
- en: '| 400,000 | 0.3 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 400,000 | 0.3 |'
- en: '| 500,000 | 0.5 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 500,000 | 0.5 |'
- en: '| 600,000 | 0.1 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 600,000 | 0.1 |'
- en: '*Non-farm payrolls* refer to a monthly report issued by the US Department of
    Labor that gives information on the total number of paid employees in the nation,
    excluding those employed in the agriculture sector, as well as those employed
    by the government and non-profit organizations.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*非农就业人数*是指美国劳工部发布的每月报告，提供有关全国有薪雇员总数的信息，不包括农业部门的从业人员以及政府和非营利组织的从业人员。'
- en: 'From Table 2-1, economists assume there is a 50% probability that there will
    be a 500,000 increase in the total number of paid employees and a 30% probability
    that there will be a 400,000 increase in the total number of paid employees. The
    expected value is therefore:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 从表2-1中，经济学家假设有50%的概率总有薪员工人数增加50万，有30%的概率总有薪员工人数增加40万。因此期望值为：
- en: <math alttext="upper E left-parenthesis upper X right-parenthesis equals left-parenthesis
    300 comma 000 times 0.1 right-parenthesis plus left-parenthesis 400 comma 000
    times 0.3 right-parenthesis plus left-parenthesis 500 comma 000 times 0.5 right-parenthesis
    plus left-parenthesis 600 comma 000 times 0.1 right-parenthesis equals 460 comma
    000"><mrow><mi>E</mi> <mo>(</mo> <mi>X</mi> <mo>)</mo> <mo>=</mo> <mo>(</mo> <mn>300</mn>
    <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>1</mn> <mo>)</mo>
    <mo>+</mo> <mo>(</mo> <mn>400</mn> <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn>
    <mo>.</mo> <mn>3</mn> <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>500</mn> <mo>,</mo>
    <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>)</mo> <mo>+</mo>
    <mo>(</mo> <mn>600</mn> <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo>
    <mn>1</mn> <mo>)</mo> <mo>=</mo> <mn>460</mn> <mo>,</mo> <mn>000</mn></mrow></math>
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper E left-parenthesis upper X right-parenthesis equals left-parenthesis
    300 comma 000 times 0.1 right-parenthesis plus left-parenthesis 400 comma 000
    times 0.3 right-parenthesis plus left-parenthesis 500 comma 000 times 0.5 right-parenthesis
    plus left-parenthesis 600 comma 000 times 0.1 right-parenthesis equals 460 comma
    000"><mrow><mi>E</mi> <mo>(</mo> <mi>X</mi> <mo>)</mo> <mo>=</mo> <mo>(</mo> <mn>300</mn>
    <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>1</mn> <mo>)</mo>
    <mo>+</mo> <mo>(</mo> <mn>400</mn> <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn>
    <mo>.</mo> <mn>3</mn> <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>500</mn> <mo>,</mo>
    <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>)</mo> <mo>+</mo>
    <mo>(</mo> <mn>600</mn> <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo>
    <mn>1</mn> <mo>)</mo> <mo>=</mo> <mn>460</mn> <mo>,</mo> <mn>000</mn></mrow></math>
- en: Therefore, the number that represents the economists’ consensus is 460,000,
    as it is the closest weighted value to most forecasts. It is the value that represents
    the dataset.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，代表经济学家共识的数字是460,000，因为它是大多数预测的最接近加权值。它是代表数据集的值。
- en: 'Before closing the section on introductory probability, there exists a mathematical
    formula known as *Bayes’ Theorem* that estimates an event’s likelihood based on
    knowledge of previous, related events. The formula for Bayes’ Theorem is as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍概率的部分结束之前，存在一个称为*贝叶斯定理*的数学公式，根据先前相关事件的知识估计事件的可能性。贝叶斯定理的公式如下：
- en: <math alttext="upper P left-parenthesis upper A vertical-bar upper B right-parenthesis
    equals StartFraction upper P left-parenthesis upper B vertical-bar upper A right-parenthesis
    period upper P left-parenthesis upper A right-parenthesis Over upper P left-parenthesis
    upper B right-parenthesis EndFraction"><mrow><mi>P</mi> <mrow><mo>(</mo> <mi>A</mi>
    <mo>|</mo> <mi>B</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>P</mi><mo>(</mo><mi>B</mi><mo>|</mo><mi>A</mi><mo>)</mo><mo>.</mo><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo></mrow>
    <mrow><mi>P</mi><mo>(</mo><mi>B</mi><mo>)</mo></mrow></mfrac></mrow></math>
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P left-parenthesis upper A vertical-bar upper B right-parenthesis
    equals StartFraction upper P left-parenthesis upper B vertical-bar upper A right-parenthesis
    period upper P left-parenthesis upper A right-parenthesis Over upper P left-parenthesis
    upper B right-parenthesis EndFraction"><mrow><mi>P</mi> <mrow><mo>(</mo> <mi>A</mi>
    <mo>|</mo> <mi>B</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>P</mi><mo>(</mo><mi>B</mi><mo>|</mo><mi>A</mi><mo>)</mo><mo>.</mo><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo></mrow>
    <mrow><mi>P</mi><mo>(</mo><mi>B</mi><mo>)</mo></mrow></mfrac></mrow></math>
- en: 'where:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '*P(A|B)* is the probability of event A occurring given that event B has occurred.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P(A|B)*是在事件B发生的情况下事件A发生的概率。'
- en: '*P(B|A)* is the probability of event B occurring given that event A has occurred.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P(B|A)*是在事件A发生的情况下事件B发生的概率。'
- en: '*P(A)* is the probability of event A occurring.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P(A)*是事件A发生的概率。'
- en: '*P(B)* is the probability of event B occurring.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P(B)*是事件B发生的概率。'
- en: In other words, Bayes’ Theorem allows you to update your beliefs about the probability
    of an event based on new information.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，贝叶斯定理允许您根据新信息更新对事件概率的信念。
- en: Note
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'The main takeaways from this section are as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的主要要点如下：
- en: Probabilitydescribes random variables and random events. It is a value between
    0 and 1.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率描述随机变量和随机事件。它是介于0和1之间的值。
- en: Probabilities of events may be grouped together to form more complex scenarios.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件的概率可以组合在一起形成更复杂的情景。
- en: The expected outcome is the weighted average of every probability in the designated
    universe.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期结果是指定宇宙中每个概率的加权平均值。
- en: Sampling and Hypothesis Testing
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 抽样和假设检验
- en: When populations are large, representative samples are taken so that they become
    the main describers of data. Take the United States. Its democratic system means
    that the people hold the right to decide their own fate, but it’s not possible
    to go to every person and ask them about their detailed opinions on every topic
    out there. This is why elections are held and representatives are elected so that
    they act in the people’s name.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '*Sampling* refers to the act of selecting samples of data within a larger population
    and and making conclusions about the statistical properties of the population. There
    are a few different methods of sampling. The most known ones are the following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Simple random sampling
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: With simple random sampling, each element in the population has an equal chance
    of being selected for the sample. This can be a random number generated on a labeled
    population where each individual has the same probability of being selected.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Stratified sampling
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: With stratified sampling, the population is divided into groups based on some
    characteristic, and then a simple random sample is taken from each group in proportion
    to its size.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Cluster sampling
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: With cluster sampling, the population is divided into clusters, and a random
    sample of clusters is selected. Then, all elements within the selected clusters
    are included in the sample.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Systematic sampling
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: With systematic sampling, an element is selected by choosing every *nth* individual
    from the population, where *n* is a fixed number. This means that it is not random
    but pre-specified in advance.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: A rule of thumb is that the more data you acquire, the better the metrics reflect
    the population. Sampling is extremely important in the world of machine learning
    as quite often, you are taking samples of data to represent the true population.
    For example, when performing a back-test on a strategy, you will be required to
    split the whole data set into a *training sample* and a *testing sample* where
    the first is the sample of data on which the algorithm understands its structure,
    and the second is the sample of data on which the algorithm tests its predictive
    power.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, another example of using sampling is *cross validation*, a technique
    that divides a dataset into two or more subgroups. The model is trained using
    one subset, and its results are tested using the other subsets. For various subsets
    of the data, this procedure is repeated numerous times, and then the model’s average
    performance is determined.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: These terms are discussed in more depth in the coming chapters. For now you
    should understand that the concept of sampling is very important in machine learning
    (and even more in deep learning with optimization techniques).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Sampling is not perfect and errors may be possible just as any other estimation
    method. *Sampling error* refers to the difference between the statistic of the
    sample and the statistic of the population (if it’s known). A *statistic* is a
    metric that describes the analyzed dataset (an example of this would be the mean,
    a statistic you will see in greater detail in Chapter 3 dealing with statistics).
    Now, what is the minimum sample size you should have to be able to make inferences
    about the population? The rule of thumb is to have a minimum of 30 observations
    and the more the merrier. This brings the discussion to the *central limit theorem*
    which states that random samples drawn from a population will approach a normal
    distribution (a probability distribution that is symmetric and bell-shaped) as
    the sample gets larger.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'The central limit theorem makes it simple to apply inferences and conclusions
    as hypothesis testing goes well with a normal distribution. Before proceeding
    to hypothesis testing, let’s look at *confidence intervals*, ranges of values
    where the population parameter is expected to be. Confidence intervals are generally
    constructed by adding or subtracting a factor from the point estimate. For example,
    given a sample mean x̄, a confidence interval can be constructed as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x overbar plus-or-minus left-parenthesis r e l i a b i l i t
    y f a c t o r times s t a n d a r d e r r o r right-parenthesis"><mrow><mover
    accent="true"><mi>x</mi> <mo>¯</mo></mover> <mo>±</mo> <mrow><mo>(</mo> <mi>r</mi>
    <mi>e</mi> <mi>l</mi> <mi>i</mi> <mi>a</mi> <mi>b</mi> <mi>i</mi> <mi>l</mi> <mi>i</mi>
    <mi>t</mi> <mi>y</mi> <mi>f</mi> <mi>a</mi> <mi>c</mi> <mi>t</mi> <mi>o</mi> <mi>r</mi>
    <mo>×</mo> <mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>n</mi> <mi>d</mi> <mi>a</mi> <mi>r</mi>
    <mi>d</mi> <mi>e</mi> <mi>r</mi> <mi>r</mi> <mi>o</mi> <mi>r</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="x overbar plus-or-minus left-parenthesis r e l i a b i l i t
    y f a c t o r times s t a n d a r d e r r o r right-parenthesis"><mrow><mover
    accent="true"><mi>x</mi> <mo>¯</mo></mover> <mo>±</mo> <mrow><mo>(</mo> <mi>r</mi>
    <mi>e</mi> <mi>l</mi> <mi>i</mi> <mi>a</mi> <mi>b</mi> <mi>i</mi> <mi>l</mi> <mi>i</mi>
    <mi>t</mi> <mi>y</mi> <mi>f</mi> <mi>a</mi> <mi>c</mi> <mi>t</mi> <mi>o</mi> <mi>r</mi>
    <mo>×</mo> <mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>n</mi> <mi>d</mi> <mi>a</mi> <mi>r</mi>
    <mi>d</mi> <mi>e</mi> <mi>r</mi> <mi>r</mi> <mi>o</mi> <mi>r</mi> <mo>)</mo></mrow></mrow></math>
- en: Let’s try to understand the calculation step by step. The sample mean is an
    estimate of the population and is calculated because it is not possible to calculate
    the population means, therefore, by performing a random sample, the assumption
    is that the sample mean should be equal to the population mean. However, in real
    life, things may differ, and this why you should construct a confidence interval
    using probabilistic methods.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-107
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The *significance level* is the threshold of the confidence interval. For example,
    a confidence interval of 95% means that with 95% confidence, the estimate should
    lie within a certain range. The remaining 5% probability that it does not, is
    called a significance level (generally marked with the alpha symbol α).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: A *reliability f**actor* is a statistical measure that depends on the distribution
    of the estimate and the probability that it falls within the confidence interval.
    For the sake of simplicity, let’s assume that the variance of the population is
    normal and the population is normally distributed. For a significance level of
    5% (thus, a confidence interval of 95%), the reliability factor is 1.96 in this
    case (the way you get this number is less relevant to the discussion).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'The *standard error* is the standard deviation of the sample. *Standard deviation*
    is discussed in greater depth in Chapter 3; for now, just know that it represents
    the fluctuations of the different values around the mean. Standard error is found
    using the following formula:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="s equals StartFraction sigma Over StartRoot n EndRoot EndFraction"><mrow><mi>s</mi>
    <mo>=</mo> <mfrac><mi>σ</mi> <msqrt><mi>n</mi></msqrt></mfrac></mrow></math>
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="s equals StartFraction sigma Over StartRoot n EndRoot EndFraction"><mrow><mi>s</mi>
    <mo>=</mo> <mfrac><mi>σ</mi> <msqrt><mi>n</mi></msqrt></mfrac></mrow></math>
- en: <math alttext="sigma i s t h e p o p u l a t i o n s t a n d a r d d e v i a
    t i o n"><mrow><mi>σ</mi> <mi>i</mi> <mi>s</mi> <mi>t</mi> <mi>h</mi> <mi>e</mi>
    <mi>p</mi> <mi>o</mi> <mi>p</mi> <mi>u</mi> <mi>l</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi>
    <mi>o</mi> <mi>n</mi> <mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>n</mi> <mi>d</mi> <mi>a</mi>
    <mi>r</mi> <mi>d</mi> <mi>d</mi> <mi>e</mi> <mi>v</mi> <mi>i</mi> <mi>a</mi> <mi>t</mi>
    <mi>i</mi> <mi>o</mi> <mi>n</mi></mrow></math>
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="sigma i s t h e p o p u l a t i o n s t a n d a r d d e v i a
    t i o n"><mrow><mi>σ</mi> <mi>i</mi> <mi>s</mi> <mi>t</mi> <mi>h</mi> <mi>e</mi>
    <mi>p</mi> <mi>o</mi> <mi>p</mi> <mi>u</mi> <mi>l</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi>
    <mi>o</mi> <mi>n</mi> <mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>n</mi> <mi>d</mi> <mi>a</mi>
    <mi>r</mi> <mi>d</mi> <mi>d</mi> <mi>e</mi> <mi>v</mi> <mi>i</mi> <mi>a</mi> <mi>t</mi>
    <mi>i</mi> <mi>o</mi> <mi>n</mi></mrow></math>
- en: <math alttext="StartRoot n EndRoot i s t h e s q u a r e r o o t o f t h e p
    o p u l a t i o n n u m b e r"><mrow><msqrt><mi>n</mi></msqrt> <mi>i</mi> <mi>s</mi>
    <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi> <mi>q</mi> <mi>u</mi> <mi>a</mi> <mi>r</mi>
    <mi>e</mi> <mi>r</mi> <mi>o</mi> <mi>o</mi> <mi>t</mi> <mi>o</mi> <mi>f</mi> <mi>t</mi>
    <mi>h</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>p</mi> <mi>u</mi> <mi>l</mi> <mi>a</mi>
    <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mi>n</mi> <mi>u</mi> <mi>m</mi> <mi>b</mi>
    <mi>e</mi> <mi>r</mi></mrow></math>
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartRoot n EndRoot i s t h e s q u a r e r o o t o f t h e p
    o p u l a t i o n n u m b e r"><mrow><msqrt><mi>n</mi></msqrt> <mi>i</mi> <mi>s</mi>
    <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi> <mi>q</mi> <mi>u</mi> <mi>a</mi> <mi>r</mi>
    <mi>e</mi> <mi>r</mi> <mi>o</mi> <mi>o</mi> <mi>t</mi> <mi>o</mi> <mi>f</mi> <mi>t</mi>
    <mi>h</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>p</mi> <mi>u</mi> <mi>l</mi> <mi>a</mi>
    <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mi>n</mi> <mi>u</mi> <mi>m</mi> <mi>b</mi>
    <mi>e</mi> <mi>r</mi></mrow></math>
- en: It is also worth knowing that for a 1% significance level, the reliability factor
    is 2.575, and for a 10% significance level, the reliability factor is 1.645\.
    Let’s take a practical example to make sense out all of this math.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Consider a population of 100 financial instruments (bonds, currency pairs, stocks,
    structured products, etc.). The mean annual return of these instruments is 1.4%.
    Assuming a population standard deviation of 4.34%, what is the confidence interval
    at 1% significance level (99% confidence interval) of the mean?
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'The answer is just plugging the values in the formula as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="1.4 percent-sign plus-or-minus 2.575 times StartFraction 4.34
    percent-sign Over StartRoot 100 EndRoot EndFraction equals 1.4 percent-sign plus-or-minus
    1.11 percent-sign"><mrow><mn>1</mn> <mo>.</mo> <mn>4</mn> <mo>%</mo> <mo>±</mo>
    <mn>2</mn> <mo>.</mo> <mn>575</mn> <mo>×</mo> <mfrac><mrow><mn>4</mn><mo>.</mo><mn>34</mn><mo>%</mo></mrow>
    <msqrt><mn>100</mn></msqrt></mfrac> <mo>=</mo> <mn>1</mn> <mo>.</mo> <mn>4</mn>
    <mo>%</mo> <mo>±</mo> <mn>1</mn> <mo>.</mo> <mn>11</mn> <mo>%</mo></mrow></math>
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="1.4 percent-sign plus-or-minus 2.575 times StartFraction 4.34
    percent-sign Over StartRoot 100 EndRoot EndFraction equals 1.4 percent-sign plus-or-minus
    1.11 percent-sign"><mrow><mn>1</mn> <mo>.</mo> <mn>4</mn> <mo>%</mo> <mo>±</mo>
    <mn>2</mn> <mo>.</mo> <mn>575</mn> <mo>×</mo> <mfrac><mrow><mn>4</mn><mo>.</mo><mn>34</mn><mo>%</mo></mrow>
    <msqrt><mn>100</mn></msqrt></mfrac> <mo>=</mo> <mn>1</mn> <mo>.</mo> <mn>4</mn>
    <mo>%</mo> <mo>±</mo> <mn>1</mn> <mo>.</mo> <mn>11</mn> <mo>%</mo></mrow></math>
- en: This means that the confidence interval is between (0.29%, 2.51%).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see another example. Consider that the annual returns on precious and
    industrial metals (such as gold and copper) are normally distributed with a mean
    of 3.5% and a known population standard deviation of 5.1%. What is the confidence
    interval with 10% significance level of the annual returns on 5 different commodities?
    The answer is as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="3.5 percent-sign plus-or-minus 1.645 times StartFraction 3.5
    percent-sign Over StartRoot 5 EndRoot EndFraction equals 3.5 percent-sign plus-or-minus
    2.23 percent-sign"><mrow><mn>3</mn> <mo>.</mo> <mn>5</mn> <mo>%</mo> <mo>±</mo>
    <mn>1</mn> <mo>.</mo> <mn>645</mn> <mo>×</mo> <mfrac><mrow><mn>3</mn><mo>.</mo><mn>5</mn><mo>%</mo></mrow>
    <msqrt><mn>5</mn></msqrt></mfrac> <mo>=</mo> <mn>3</mn> <mo>.</mo> <mn>5</mn>
    <mo>%</mo> <mo>±</mo> <mn>2</mn> <mo>.</mo> <mn>23</mn> <mo>%</mo></mrow></math>
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="3.5 percent-sign plus-or-minus 1.645 times StartFraction 3.5
    percent-sign Over StartRoot 5 EndRoot EndFraction equals 3.5 percent-sign plus-or-minus
    2.23 percent-sign"><mrow><mn>3</mn> <mo>.</mo> <mn>5</mn> <mo>%</mo> <mo>±</mo>
    <mn>1</mn> <mo>.</mo> <mn>645</mn> <mo>×</mo> <mfrac><mrow><mn>3</mn><mo>.</mo><mn>5</mn><mo>%</mo></mrow>
    <msqrt><mn>5</mn></msqrt></mfrac> <mo>=</mo> <mn>3</mn> <mo>.</mo> <mn>5</mn>
    <mo>%</mo> <mo>±</mo> <mn>2</mn> <mo>.</mo> <mn>23</mn> <mo>%</mo></mrow></math>
- en: This means that the confidence interval is between (1.27%, 5.8%).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-122
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If the sample size is small and / or the population standard deviation is unknown,
    a t-distribution may be a better choice than a normal distribution.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The *t-distribution* is a type of probability distribution used to model the
    distribution of a sample mean when the sample size is small and/or when the population
    standard deviation is unknown. It resembles the normal distribution in shape,
    but with heavier tails, which represents the uncertainty associated with smaller
    sample sizes.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 'Before closing the discussion on sampling and estimation, the following list
    shows the appropriate distributions given the characteristics of the population:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: A small normal distribution with known variance should use the reliability factor
    of the normal distribution.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A large normal distribution with known variance should use the reliability factor
    of the normal distribution.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A small normal distribution with unkown variance should use the reliability
    factor of the t-distribution.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有未知方差的小正态分布应使用t分布的可靠性因子。
- en: A large normal distribution with unkown variance should use the reliability
    factor of the t-distribution.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有未知方差的大正态分布应使用t分布的可靠性因子。
- en: A large non-normal distribution with known variance should use the reliability
    factor of the normal distribution.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有已知方差的大非正态分布应使用正态分布的可靠性因子。
- en: A large non-normal distribution with known variance should use the reliability
    factor of the t-distribution.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有已知方差的大非正态分布应使用t分布的可靠性因子。
- en: Remember that *large* means that the number of observations are greater than
    30\. The non covered combinations in the previous list are complex and out of
    scope of this discussion.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，*大*意味着观察数量大于30。前一个列表中未涵盖的组合是复杂的，超出了本讨论的范围。
- en: The next stop is hypothesis testing, a key probabilistic technique of getting
    conclusions on samples of data. This part is extremely important as it’s used
    in almost all types of statistical analyses and models.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是假设检验，这是一种从数据样本中得出结论的关键概率技术。这部分非常重要，因为它几乎用于所有类型的统计分析和模型中。
- en: In statistics, *hypothesis testing* is a technique for drawing conclusions about
    a population from a small sample of data. It entails developing two competing
    hypotheses, the *null hypothesis* and the *alternative hypothesis*, about a population
    parameter, and then figuring out which is more likely to be accurate using sample
    data.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，*假设检验*是一种从少量数据样本中得出关于总体的结论的技术。它涉及制定两个竞争性假设，*零假设*和*备择假设*，关于总体参数，然后使用样本数据确定哪个更有可能是准确的。
- en: 'For example, a financial analyst is evaluating two portfolios from a risk perspective.
    They formulate two hypotheses:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，金融分析师正在从风险角度评估两个投资组合。他们制定了两个假设：
- en: The null hypothesis states that there is no significant difference in the volatility
    of the two portfolios.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零假设表明两个投资组合的波动性没有显著差异。
- en: The alternative hypothesis states that there is a significant difference in
    the volatility of the two portfolios.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备择假设表明两个投资组合的波动性存在显著差异。
- en: The hypothesis is then tested using statistical analysis to determine if the
    difference in volatility is statistically significant or due to pure chance.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用统计分析来测试假设，以确定波动性差异是否具有统计学意义或纯粹是由于偶然因素。
- en: Following the definition of the null and alternative hypotheses, a test statistic
    is computed using the sample data. To assess the result’s significance, the test
    statistic is then compared to a critical value drawn from a standard distribution.
    The null hypothesis is rejected and the alternative hypothesis is accepted if
    the test statistic is inside the crucial zone. The null hypothesis is not rejected
    and the conclusion that there is insufficient evidence to support the alternative
    hypothesis is reached if the test statistic does not fall inside the crucial zone.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 根据零假设和备择假设的定义，使用样本数据计算一个检验统计量。为了评估结果的显著性，然后将检验统计量与从标准分布中抽取的临界值进行比较。如果检验统计量在关键区域内，则拒绝零假设并接受备择假设。如果检验统计量不在关键区域内，则不拒绝零假设，并得出支持备择假设的证据不足的结论。
- en: 'This is all fancy talk to say that hypothesis testing is basically creating
    two opposing scenarios, running a probability check, and then deciding which scenario
    is more likely true. Hypothesis testing can take two forms:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是花言巧语，说的其实是假设检验基本上是创建两种相反的情景，进行概率检查，然后决定哪种情景更有可能是真实的。假设检验可以采取两种形式：
- en: '*One-tailed test*: An example of this would be to test if the return on certain
    financial instruments is greater than zero.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*单侧检验*：一个例子是测试某些金融工具的回报是否大于零。'
- en: '*Two-tailed test*: An example of this would be to test if the the return on
    certain financial instruments is different from than zero (meaning that it can
    be either greater or smaller than zero).'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*双侧检验*：一个例子是测试某些金融工具的回报是否与零不同（意味着可以大于或小于零）。'
- en: Note
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Hypothesis tests are generally two-tailed.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 假设检验通常是双侧的。
- en: 'The null hypothesis is the one that you want to reject and therefore is tested
    in the hopes of getting rejected and accepting the alternative scenario. A two-tailed
    test takes the following general form:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 零假设是您希望拒绝的假设，因此希望被拒绝并接受备择方案。双侧检验采用以下一般形式：
- en: <math alttext="upper H 0 colon x equals x 0"><mrow><msub><mi>H</mi> <mn>0</mn></msub>
    <mo>:</mo> <mi>x</mi> <mo>=</mo> <msub><mi>x</mi> <mn>0</mn></msub></mrow></math>
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper H 0 colon x equals x 0"><mrow><msub><mi>H</mi> <mn>0</mn></msub>
    <mo>:</mo> <mi>x</mi> <mo>=</mo> <msub><mi>x</mi> <mn>0</mn></msub></mrow></math>
- en: <math alttext="upper H Subscript a Baseline colon x not-equals x 0"><mrow><msub><mi>H</mi>
    <mi>a</mi></msub> <mo>:</mo> <mi>x</mi> <mo>≠</mo> <msub><mi>x</mi> <mn>0</mn></msub></mrow></math>
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper H Subscript a Baseline colon x not-equals x 0"><mrow><msub><mi>H</mi>
    <mi>a</mi></msub> <mo>:</mo> <mi>x</mi> <mo>≠</mo> <msub><mi>x</mi> <mn>0</mn></msub></mrow></math>
- en: As the alternative scenario allows for values above and below zero (which is
    the stated level in the null hypothesis), there should be two critical values.
    Therefore, the rule of a two-tailed test is to reject the null hypothesis if the
    test statistic is greater than the upper critical value or if the test statistic
    is lower than the lower critical value. For instance, for a normally distributed
    data, the test statistic is compared with the critical values (at 5% significance
    level) at +1.96 and -1.96\. The null hypothesis is rejected if the test statistic
    falls outside the range between +1.96 and -1.96.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 由于备择方案允许数值在零上下两侧（这是零假设中规定的水平），应该有两个临界值。因此，双侧检验的规则是，如果检验统计量大于上临界值或小于下临界值，则拒绝零假设。例如，对于正态分布的数据，检验统计量与临界值（在5%显著性水平下）进行比较，分别为+1.96和-1.96。如果检验统计量落在+1.96和-1.96之间的范围之外，则拒绝零假设。
- en: 'The process of hypothesis testing entails the calculation of the test statistic.
    It is calculated by comparing the point estimate of the population parameter with
    the hypothesized value of the null hypothesis. Both are then scaled by the standard
    error of the sample. The mathematical representation is as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 假设检验的过程包括计算检验统计量。通过将总体参数的点估计与零假设的假设值进行比较来计算它。然后，两者都通过样本的标准误差进行缩放。数学表示如下：
- en: <math alttext="t e s t s t a t i s t i c equals StartFraction s a m p l e s
    t a t i s t i c minus h y p o t h e s i z e d v a l u e Over s t a n d a r d e
    r r o r EndFraction"><mrow><mi>t</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi>
    <mi>t</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi> <mi>s</mi> <mi>t</mi> <mi>i</mi> <mi>c</mi>
    <mo>=</mo> <mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi>s</mi><mi>a</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>i</mi><mi>c</mi><mo>-</mo><mi>h</mi><mi>y</mi><mi>p</mi><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mi>d</mi><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi></mrow>
    <mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>a</mi><mi>r</mi><mi>d</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi></mrow></mfrac></mstyle></mrow></math>
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="t e s t s t a t i s t i c equals StartFraction s a m p l e s
    t a t i s t i c minus h y p o t h e s i z e d v a l u e Over s t a n d a r d e
    r r o r EndFraction"><mrow><mi>t</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi>
    <mi>t</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi> <mi>s</mi> <mi>t</mi> <mi>i</mi> <mi>c</mi>
    <mo>=</mo> <mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi>s</mi><mi>a</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>i</mi><mi>c</mi><mo>-</mo><mi>h</mi><mi>y</mi><mi>p</mi><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mi>d</mi><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi></mrow>
    <mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>a</mi><mi>r</mi><mi>d</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi></mrow></mfrac></mstyle></mrow></math>
- en: 'An important consideration in hypothesis testing is that the sample may not
    be representative, which leads to errors in describing the population. This gives
    rise to two types of errors:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '*Type I error*: This error occurs when rejecting the null hypothesis even though
    it is true.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Type II error*: This error occurs when failing to reject the null hypothesis
    even though it is false.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intuitively, the significance level is the probability of making a type I error.
    Remember that if α = 5%, then there is a 5% chance of rejecting a true null hypothesis
    by mistake. An example would make things clearer.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider an analyst doing research on the annual returns of a long-short portfolio
    over a period of 20 years. The mean annual return was 1% with a standard deviation
    of 2%. The analyst’s opinion is that the annual mean return is not equal to zero
    and they want to constuct a 95% confidence interval for this and then construct
    a hypothesis test:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: State the variables. The size of the sample is 20, the standard deviation is
    2% and the mean is 1%.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the standard error, which in this case is 0.44% as per the formula.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the critical values for the 95% confidence interval, which are +1.96
    and -1.96.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The confidence interval is therefore (0.13%, 1.86%).
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specify the null hypothesis, which is, according to the analyst’s opinion, a
    two-tailed test. The null hypothesis is that the annuel return equals zero. You
    should reject it if the test statistic is less than -1.96 or greater than +1.96.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the formula to find the test statistic gives 2.27\. Therefore, the null
    hypothesis is rejected.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'One more important metric to discuss: the p-value. The* p-value* is the probability
    of seeing a test statistic more extreme than the one seen in the statistical test
    given that the null hypothesis is true. Comparing a p-value to a significance
    level—typically 0.05—allows you to understand it. The result is deemed statistically
    significant, and the null hypothesis is rejected in favor of the alternative hypothesis
    if the p-value is less than or equal to the significance level.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: If the p-value is less than the significance level of 5%, it means that there
    is a 5% chance to see a test statistic as extreme as the current one if the null
    hypothesis is true. Another way of defining the p-value is to consider it as the
    smallest significance level for which the null hypothesis can be rejected.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The main takeaways from this section are as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Sampling refers to the collection of data within a population in the aim of
    making conclusions about the statistical properties of the aforementioned population.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sampling is used extensively in machine learning. One example is cross validation.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hypothesis testing is a technique for drawing conclusions about a population
    from a small sample of data.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Primer on Information Theory
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Information theory* is a complex abstract mathematical field that is closely
    related to probability. It is the study of how information is quantified, stored,
    and transmitted. There are three conditions of occurrence when it comes to an
    event:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '*Uncertainty*: If the event has not occurred yet.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Surprise*: If the event has just occurred.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Information*: If the event has occurred in the past.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the key concepts in information theory is *entropy*:the level of uncertainty
    or randomness in a message or information source. It describes the degree to which
    an event or message is unexpected. In contrast, *information gain* measures the
    reduction in entropy (surprise) when receiving new information.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Basically, information theory describes the surprise of events. When an event
    has a low probability of occurrence, it has more surprise and hence, more information
    to provide. Similarly, when an event has a high probability of occurrence, it
    has less surprise and therefore, less information. What you should retain from
    this is that the amount of information learned from an unlikely event is greater
    than the amount of information learned from a likely event.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'Before starting to dig a little deeper in information theory, it is important
    to understand what a *logarithm* is and for that matter what an *exponent* is.
    A general exponential function takes a certain constant or a variable to a certain
    power:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="f left-parenthesis x right-parenthesis equals a Superscript x"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>a</mi> <mi>x</mi></msup></mrow></math>
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="f left-parenthesis x right-parenthesis equals a Superscript x"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>a</mi> <mi>x</mi></msup></mrow></math>
- en: 'In other words, the *exponent of a number* is the number of times you will
    multiply it by itself:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="4 cubed equals 4 times 4 times 4 equals 64"><mrow><msup><mn>4</mn>
    <mn>3</mn></msup> <mo>=</mo> <mn>4</mn> <mo>×</mo> <mn>4</mn> <mo>×</mo> <mn>4</mn>
    <mo>=</mo> <mn>64</mn></mrow></math>
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="4 cubed equals 4 times 4 times 4 equals 64"><mrow><msup><mn>4</mn>
    <mn>3</mn></msup> <mo>=</mo> <mn>4</mn> <mo>×</mo> <mn>4</mn> <mo>×</mo> <mn>4</mn>
    <mo>=</mo> <mn>64</mn></mrow></math>
- en: 'In contrast, a logarithm is the opposite of an exponent, and its aim is to
    find the exponent (knowing 4 and 64 from the previous example and finding 3):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="log Subscript 4 Baseline left-parenthesis 64 right-parenthesis
    equals 3"><mrow><msub><mo form="prefix">log</mo> <mn>4</mn></msub> <mrow><mo>(</mo>
    <mn>64</mn> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math>
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="log Subscript 4 Baseline left-parenthesis 64 right-parenthesis
    equals 3"><mrow><msub><mo form="prefix">log</mo> <mn>4</mn></msub> <mrow><mo>(</mo>
    <mn>64</mn> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math>
- en: 'A logarithm, therefore, is the answer to how many of one number to multiply
    to get another number. Since they are literally inverse functions, you can use
    them together to simplify or even solve for x. Take the following example:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="log Subscript 4 Baseline left-parenthesis x right-parenthesis
    equals 3"><mrow><msub><mo form="prefix">log</mo> <mn>4</mn></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math>
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="log Subscript 4 Baseline left-parenthesis x right-parenthesis
    equals 3"><mrow><msub><mo form="prefix">log</mo> <mn>4</mn></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math>
- en: 'The objective here is to find x given the logarithmic function. The first step
    is simply to use the exponential function on one side as you want it to cancel
    out the logarithm on the right (remember, inverse functions cancel each other
    out). This gives us the following result:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="4 Superscript l o g 4 left-parenthesis x right-parenthesis Baseline
    equals 4 cubed"><mrow><msup><mn>4</mn> <mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi>
    <mn>4</mn></msub> <mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow></msup> <mo>=</mo>
    <msup><mn>4</mn> <mn>3</mn></msup></mrow></math>
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="4 Superscript l o g 4 left-parenthesis x right-parenthesis Baseline
    equals 4 cubed"><mrow><msup><mn>4</mn> <mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi>
    <mn>4</mn></msub> <mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow></msup> <mo>=</mo>
    <msup><mn>4</mn> <mn>3</mn></msup></mrow></math>
- en: <math alttext="x equals 4 cubed"><mrow><mi>x</mi> <mo>=</mo> <msup><mn>4</mn>
    <mn>3</mn></msup></mrow></math>
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="x equals 4 cubed"><mrow><mi>x</mi> <mo>=</mo> <msup><mn>4</mn>
    <mn>3</mn></msup></mrow></math>
- en: <math alttext="x equals 64"><mrow><mi>x</mi> <mo>=</mo> <mn>64</mn></mrow></math>
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="x equals 64"><mrow><mi>x</mi> <mo>=</mo> <mn>64</mn></mrow></math>
- en: 'Logarithms can have different bases. However, the most used logarithm has a
    base of 10. In computer science, base 2 logarithms represent bits (binary digits).
    Therefore, information is represented as bits. The formula of information gain
    is as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis x Subscript i Baseline right-parenthesis
    equals minus l o g 2 left-parenthesis upper P left-parenthesis x Subscript i Baseline
    right-parenthesis right-parenthesis"><mrow><mi>H</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <mi>l</mi> <mi>o</mi>
    <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper H left-parenthesis x Subscript i Baseline right-parenthesis
    equals minus l o g 2 left-parenthesis upper P left-parenthesis x Subscript i Baseline
    right-parenthesis right-parenthesis"><mrow><mi>H</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <mi>l</mi> <mi>o</mi>
    <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
- en: 'Let’s assume two variables *x* and *y* where *x* has a probability of 1 (100%
    and therefore, certain) and *y* has a probability of 0.5 (50% and therefore, mostly
    random), what would be the information in these two cases? The answer is as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis x right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 1 right-parenthesis right-parenthesis
    equals 0"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>1</mn> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo>
    <mn>0</mn></mrow></math>
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper H left-parenthesis x right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 1 right-parenthesis right-parenthesis
    equals 0"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>1</mn> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo>
    <mn>0</mn></mrow></math>
- en: <math alttext="upper H left-parenthesis y right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 0.5 right-parenthesis right-parenthesis
    equals 1"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn></mrow></math>
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper H left-parenthesis y right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 0.5 right-parenthesis right-parenthesis
    equals 1"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn></mrow></math>
- en: So the certain event gives zero information and the one that has a fifty-fifty
    chance of realizing has an information of 1\. What about the very unlikely event
    *z* that has a probability of 0.05 (5%)?
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis z right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 0.05 right-parenthesis right-parenthesis
    equals 4.32"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>0</mn> <mo>.</mo> <mn>05</mn> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mn>4</mn> <mo>.</mo> <mn>32</mn></mrow></math>
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper H left-parenthesis z right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 0.05 right-parenthesis right-parenthesis
    equals 4.32"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>0</mn> <mo>.</mo> <mn>05</mn> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mn>4</mn> <mo>.</mo> <mn>32</mn></mrow></math>
- en: A negative relationship between probability and information is therefore one
    of the principles of information theory. Entropy and information are related concepts,
    but they have different meanings and applications.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '*Entropy* is a metric used to assess how chaotic or random a system is. Entropy
    describes how uncertain or unpredictable a signal is. The degree of disorder or
    unpredictability in the system or communication increases as entropy increases.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '*Information* is the decrease in entropy or uncertainty that happens as a result
    of receiving a signal. A signal’s ability to lessen the receiver’s uncertainty
    or entropy increases with its informational content.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-198
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Entropy is maximized whenever all the events are equally likely.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: 'Entropy is calculated using the following formula:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper S left-parenthesis x Subscript n Baseline right-parenthesis
    equals sigma-summation Underscript i equals 1 Overscript n Endscripts left-parenthesis
    minus l o g 2 left-parenthesis upper P left-parenthesis x Subscript i Baseline
    right-parenthesis right-parenthesis period left-parenthesis upper P left-parenthesis
    x Subscript i Baseline right-parenthesis right-parenthesis right-parenthesis"><mrow><mi>S</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>)</mo></mrow> <mo>=</mo>
    <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <mrow><mo>(</mo> <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub>
    <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>.</mo> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper S left-parenthesis x Subscript n Baseline right-parenthesis
    equals sigma-summation Underscript i equals 1 Overscript n Endscripts left-parenthesis
    minus l o g 2 left-parenthesis upper P left-parenthesis x Subscript i Baseline
    right-parenthesis right-parenthesis period left-parenthesis upper P left-parenthesis
    x Subscript i Baseline right-parenthesis right-parenthesis right-parenthesis"><mrow><mi>S</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>)</mo></mrow> <mo>=</mo>
    <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <mrow><mo>(</mo> <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub>
    <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>.</mo> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
- en: Therefore, it is the average of the sum of logarithms times their respective
    probabilities.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s discuss the final concept of the section, *information gain*.  The
    reduction in entropy caused by changing a dataset is calculated via information
    gain.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Information gain is one of the key concepts you will see in Chapter 7 with decision
    trees, and therefore you may want to refer to this section after understanding
    what decision trees are.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: You mainly calculate information gain by comparing the entropy of a dataset
    before and after a transformation. Recall that entropy is maximized when all the
    outcomes of a random event have the same probability. This can also be presented
    as a distribution where a symmetrical distribution (such as the normal distribution)
    has high entropy and a skewed distribution has low entropy.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-206
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Minimizing entropy is related to maximizing information gain.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'Before closing this introductory section on information theory (you will see
    it in greater depth when discussing decision trees), let’s look at the concept
    of *mutual information*. This measure is calculated between two variables, hence
    the name *mutual*, and it measures the reduction in uncertainty of a variable
    given another variable. The formula for mutual information is as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper M upper I left-parenthesis x comma y right-parenthesis
    equals upper S left-parenthesis x right-parenthesis minus upper S left-parenthesis
    x vertical-bar y right-parenthesis"><mrow><mi>M</mi> <mi>I</mi> <mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo>
    <mo>-</mo> <mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>y</mi> <mo>)</mo></mrow></math>
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper M upper I left-parenthesis x comma y right-parenthesis
    equals upper S left-parenthesis x right-parenthesis minus upper S left-parenthesis
    x vertical-bar y right-parenthesis"><mrow><mi>M</mi> <mi>I</mi> <mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo>
    <mo>-</mo> <mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>y</mi> <mo>)</mo></mrow></math>
- en: <math alttext="upper M upper I left-parenthesis x comma y right-parenthesis
    i s t h e m u t u a l i n f o r m a t i o n o f x a n d y"><mrow><mi>M</mi> <mi>I</mi>
    <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo> <mi>i</mi> <mi>s</mi> <mi>t</mi>
    <mi>h</mi> <mi>e</mi> <mi>m</mi> <mi>u</mi> <mi>t</mi> <mi>u</mi> <mi>a</mi> <mi>l</mi>
    <mi>i</mi> <mi>n</mi> <mi>f</mi> <mi>o</mi> <mi>r</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi>
    <mi>i</mi> <mi>o</mi> <mi>n</mi> <mi>o</mi> <mi>f</mi> <mi>x</mi> <mi>a</mi> <mi>n</mi>
    <mi>d</mi> <mi>y</mi></mrow></math>
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper M upper I left-parenthesis x comma y right-parenthesis
    i s t h e m u t u a l i n f o r m a t i o n o f x a n d y"><mrow><mi>M</mi> <mi>I</mi>
    <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo> <mi>i</mi> <mi>s</mi> <mi>t</mi>
    <mi>h</mi> <mi>e</mi> <mi>m</mi> <mi>u</mi> <mi>t</mi> <mi>u</mi> <mi>a</mi> <mi>l</mi>
    <mi>i</mi> <mi>n</mi> <mi>f</mi> <mi>o</mi> <mi>r</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi>
    <mi>i</mi> <mi>o</mi> <mi>n</mi> <mi>o</mi> <mi>f</mi> <mi>x</mi> <mi>a</mi> <mi>n</mi>
    <mi>d</mi> <mi>y</mi></mrow></math>
- en: <math alttext="upper S left-parenthesis x right-parenthesis i s t h e e n t
    r o p y o f x"><mrow><mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mi>i</mi> <mi>s</mi>
    <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>r</mi> <mi>o</mi>
    <mi>p</mi> <mi>y</mi> <mi>o</mi> <mi>f</mi> <mi>x</mi></mrow></math>
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper S left-parenthesis x right-parenthesis i s t h e e n t
    r o p y o f x"><mrow><mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mi>i</mi> <mi>s</mi>
    <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>r</mi> <mi>o</mi>
    <mi>p</mi> <mi>y</mi> <mi>o</mi> <mi>f</mi> <mi>x</mi></mrow></math>
- en: <math alttext="upper S left-parenthesis x vertical-bar y right-parenthesis i
    s t h e c o n d i t i o n a l e n t r o p y o f x g i v e n y"><mrow><mi>S</mi>
    <mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>y</mi> <mo>)</mo> <mi>i</mi> <mi>s</mi> <mi>t</mi>
    <mi>h</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>i</mi> <mi>t</mi>
    <mi>i</mi> <mi>o</mi> <mi>n</mi> <mi>a</mi> <mi>l</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi>
    <mi>r</mi> <mi>o</mi> <mi>p</mi> <mi>y</mi> <mi>o</mi> <mi>f</mi> <mi>x</mi> <mi>g</mi>
    <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>n</mi> <mi>y</mi></mrow></math>
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper S left-parenthesis x vertical-bar y right-parenthesis i
    s t h e c o n d i t i o n a l e n t r o p y o f x g i v e n y"><mrow><mi>S</mi>
    <mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>y</mi> <mo>)</mo> <mi>i</mi> <mi>s</mi> <mi>t</mi>
    <mi>h</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>i</mi> <mi>t</mi>
    <mi>i</mi> <mi>o</mi> <mi>n</mi> <mi>a</mi> <mi>l</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi>
    <mi>r</mi> <mi>o</mi> <mi>p</mi> <mi>y</mi> <mi>o</mi> <mi>f</mi> <mi>x</mi> <mi>g</mi>
    <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>n</mi> <mi>y</mi></mrow></math>
- en: Mutual information therefore measures the dependence between the variables.
    The greater the mutual information, the bigger the relationship between the variables
    (a value of zero represents independent variables). Keep this concept in mind
    as you will see it in Chapter 3 in the section that deals with correlations. This
    is because mutual information can also be a measure of non-linear correlation
    between the variables.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-214
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s do a summary of what you need to retain in information theory to have
    a basic knowledge of what’s to come:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Information theory uses concepts from probability to calculate information and
    entropy that are used in machine learning models and other calculations (such
    as correlation).
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Information is the decrease in entropy or uncertainty that happens as a result
    of receiving a signal. Entropy is a metric used to assess how chaotic or random
    a system is.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mutual information is a measure of dependence between two random variables.
    It can also be used to calculate the correlation between the two.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools from information theory are used in some machine learning models such
    as decision trees.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Probability presents a basic framework before continuing towards more advanced
    topics. This chapter skimmed over the concepts that you may encounter when dealing
    with machine and deep learning models. It is important to understand how probability
    is calculated and how hypothesis testing is performed (even though, in reality
    algorithms will do this for you).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter is extremely important and presents the required statistical
    knowledge you need, not just for machine learning but also for financial trading
    and even complex data analysis.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
