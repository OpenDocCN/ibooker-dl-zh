- en: Chapter 2\. Essential Probabilistic Methods for Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The rise and accessibility of technology have made it possible for everyone
    to deploy machine learning and deep learning algorithms for data analysis and
    optimization. But unfortunately, this means that a large number of users do not
    understand the basics and underlyings of the different learning models. This makes
    machine learning nothing short of a black box to them, which is a recipe for disaster.
  prefs: []
  type: TYPE_NORMAL
- en: Fundamental concepts in probability, statistics, and math are essential for
    understanding and mastering data as well as the creation of models that seek to
    interpret and forecast it if possible. This chapter presents the basics of the
    numerical concepts needed to understand the different learning algorithms, or
    at the very least, shows the starting points from where you can build up your
    knowledge towards mastering these mathematical topics.
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, the term *machine learning* used in this book refers to all
    types of learning models (such as machine, deep, and reinforcement learning).
  prefs: []
  type: TYPE_NORMAL
- en: A Primer on Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Probability* is all about describing random variables and random events. The
    world is filled with randomness, and the best way to find your way through chaos
    is to try to explain it using probabilistic methods. Granted, the phrase *explain
    chaos* may be an oxymoron, as chaos cannot really be explained, but we humans
    cannot relinquish control over uncertain events, and with progress we have developed
    tools to make sense out of the scary world.'
  prefs: []
  type: TYPE_NORMAL
- en: You may wonder what is the use of understanding the basics of probability when
    trying to develop machine learning algorithms for financial trading. This is a
    reasonable question, and you must know that the foundations of a discipline do
    not necessarily resemble it.
  prefs: []
  type: TYPE_NORMAL
- en: For example, to become a pilot, you have to have to study aerodynamics first,
    which is filled with technical concepts that do not resemble the final skill acquired
    at graduation. This is similar to what is being done in this chapter; by studying
    probabilistic essentials, statistical concepts, and mathematical topics, you will
    start on the right track towards being a machine learning developer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Knowing the utility of what you are learning should give you a motivation boost.
    Here are some key probability topics that are important for machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Probability distribution functions
  prefs: []
  type: TYPE_NORMAL
- en: The possibility of seeing various outcomes of a random variable is described
    by a *probability distribution*. For many machine learning techniques, it is essential
    to comprehend the features and attributes of typical probability distributions.
    Probability distribution functions also describe different types of time series
    data, which in turn helps in choosing the right algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Bayes’ theorem for updating probabilities
  prefs: []
  type: TYPE_NORMAL
- en: Bayes’ theorem is a cornerstone of probability theory and offers a method for
    updating an event’s probability in light of new data. It is incorporated into
    a variety of machine learning techniques, including as Bayesian networks and classifiers.
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis testing
  prefs: []
  type: TYPE_NORMAL
- en: '*Hypothesis testing* is used to establish whether a population-based assertion
    is more likely to be true or incorrect based on a sample of data. Many machine
    learning models employ hypothesis testing in their process.'
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees
  prefs: []
  type: TYPE_NORMAL
- en: '*Decision trees* are a type of machine learning algorithm that borrows from
    probabilistic concepts such as conditional probability, a concept covered in this
    chapter. For more detail, decision trees are covered in Chapter 7.'
  prefs: []
  type: TYPE_NORMAL
- en: Information theory
  prefs: []
  type: TYPE_NORMAL
- en: '*Information theory* is the complex study of how information is quantified,
    stored, and transmitted. It is incorporated into numerous machine learning techniques,
    including decision trees.​'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Probabilistic Concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most basic piece of probabilistic information is a *random variable,* which
    is an uncertain number or outcome. Random variables are used to model events that
    are considered uncertain, such as the future return of a currency pair.
  prefs: []
  type: TYPE_NORMAL
- en: 'A random variable is either discrete or continuous. A *discrete random variable*
    has a finite set of values, while a *continuous random variable* has values within
    a certain interval. Consider the following two examples to clarify things:'
  prefs: []
  type: TYPE_NORMAL
- en: An example of a discrete random variable would be the result of a rolling a
    die. They are limited by the following set {1, 2, 3, 4, 5, 6}.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example of a continuous random variable would be the daily price returns
    of EURUSD (The exchange rate of 1 Euro per US Dollars).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random variables are described by *probability distributions,* which are functions
    that give the probability of every possible value of these random variables. Generally,
    a histogram is used to show the probability. Histogram plotting is discussed later
    in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: At any moment, the probability that a certain event unfolds is between 0 and
    1\. This means that probability is assigned to random variables on a scale between
    0 and 1 such that a probability of 0 represents zero chance of occurence and a
    probability of 1 represents a certainty of occurence.
  prefs: []
  type: TYPE_NORMAL
- en: You can also think of this in percentage terms, which range from 0% to 100%.
    Values within the two numbers are valid, which means that you can have a 0.5133
    (51.33%) probability of a certain event occurring. Consider rolling a die that
    has six sides. What is the probability of getting 3 knowing that the die is not
    manipulated in any way?
  prefs: []
  type: TYPE_NORMAL
- en: 'As the die has six sides, there are six equal probabilities for every outcome,
    which means that for any outcome, the probability is found as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis x right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'With *P(x)* designating the probability of event *x*. This gives the answer
    to the question:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 3 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>3</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'When a die is rolled, there can only be one result. It cannot give 3 and 4
    simultaneously, since one side has to dominate the other. This is the concept
    of *mutual exclusivity*. Mutually exclusive events (such as getting a 3 or getting
    a 4 in a die roll) eventually sum up to 1\. Take a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 1 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>1</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 2 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>2</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 3 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>3</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 4 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>4</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 5 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>5</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 6 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>6</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Summing all these mutually exclusive events gives 1, which means that the sum
    of the possible probabilities in a six-sided die is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 1 right-parenthesis plus upper P left-parenthesis
    2 right-parenthesis plus upper P left-parenthesis 3 right-parenthesis plus upper
    P left-parenthesis 4 right-parenthesis plus upper P left-parenthesis 5 right-parenthesis
    plus upper P left-parenthesis 6 right-parenthesis equals 1"><mrow><mi>P</mi> <mo>(</mo>
    <mn>1</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>2</mn> <mo>)</mo> <mo>+</mo>
    <mi>P</mi> <mo>(</mo> <mn>3</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>4</mn>
    <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>5</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi>
    <mo>(</mo> <mn>6</mn> <mo>)</mo> <mo>=</mo> <mn>1</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Stating that a random variable has a 0.8 probability of occurring is the same
    as stating that the same variable has a 0.2 probability of not occurring.
  prefs: []
  type: TYPE_NORMAL
- en: Probability measures can be conditional or unconditional. A *conditional probability*
    is where the occurrence of an event impacts the probability that another events
    occurs. For example, the probability of a sovereign interest rate hike given positive
    employment data is an example of a conditional probability. The probability of
    event A given the occurrence of event B is denoted by the following mathematical
    notation: *P(A|B)*
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, *unconditional probability* is not dependent on other events. Taking
    the example of the conditional probability, you can formulate an unconditional
    probability calculation which measures the probability of an interest rate hike
    regardless of other economic events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Probabilities have specific addition and multiplication rules with their own
    interpretations. Let’s take a look at the formulas before seeing an example. The
    *joint probability* of the realization of two events is the probability that they
    will both occur. It is calculated using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    upper P left-parenthesis upper A vertical-bar upper B right-parenthesis times
    upper P left-parenthesis upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo>
    <mi>A</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>|</mo>
    <mi>B</mi> <mo>)</mo> <mo>×</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: What that formula says is that the probability of occurence for both A and B
    is the probability that A occurs given B occurs multiplied by the probability
    that B occurs. Therefore, the right side of the equation multiplies a conditional
    probability by an unconditional probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *addition rule* is used to determine the probability that at least one
    of the two outcomes will occur. This works in two ways: the first one deals with
    mutually exclusive events, and the second one deals with events that are non mutually
    exclusive:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the events are not mutually exclusive, then to add avoid double counting,
    the formula is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis minus upper P left-parenthesis upper A upper B right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <mi>A</mi> <mi>o</mi> <mi>r</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi>
    <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo>
    <mo>-</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If the events are mutually exclusive, then the formula is simplified to the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    0"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis minus 0"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>o</mi>
    <mi>r</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo>
    <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo> <mo>-</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>o</mi> <mi>r</mi>
    <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>+</mo>
    <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Notice how in mutually exclusive events, it’s either A or B that can be realized, and
    therefore the probability that both of them will occur is zero. To understand
    why you need to subtract the joint probability of A and B, take a look at Figure
    2-1.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0333.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. The addition rule of probability
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Notice how the probability of either A or B occurring while they are mutually
    exclusive must not include their joint probability. Let’s now look at the concept
    of independent events.
  prefs: []
  type: TYPE_NORMAL
- en: '*Independent events* are not tied together (for example, rolling the die twice).
    The joint probability is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    upper P left-parenthesis upper A right-parenthesis times upper P left-parenthesis
    upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo>
    <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>×</mo> <mi>P</mi> <mo>(</mo>
    <mi>B</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Independent events therefore refer to instances where the occurrence of one
    has absolutely zero impact on the occurrence of the others. Now, let’s see an
    example to validate these concepts. Consider a simple coin toss. The probability
    of getting heads does not depend on what you have gotten in the previous coin
    toss. Therefore the probability of getting heads is always 0.50 (50%). To take
    things further, what is the probability of getting only heads after five coin
    tosses?
  prefs: []
  type: TYPE_NORMAL
- en: 'As the probability of each event is independent from the previous or the next
    one, the formula is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis x right-parenthesis equals 0.50 times
    0.50 times 0.50 times 0.50 times 0.50 equals 0.03125 equals 3.125 percent-sign"><mrow><mi>P</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>50</mn>
    <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>50</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo>
    <mn>50</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>50</mn> <mo>×</mo> <mn>0</mn>
    <mo>.</mo> <mn>50</mn> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>03125</mn> <mo>=</mo>
    <mn>3</mn> <mo>.</mo> <mn>125</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The *expected value* of a random variable is the weighted average of the different
    outcomes. Therefore, the expected value is really another way of referring to
    the mean. Mathematically, the expected value is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper E left-parenthesis upper X right-parenthesis equals sigma-summation
    Underscript i equals 1 Overscript n Endscripts left-parenthesis upper P left-parenthesis
    x Subscript i Baseline right-parenthesis x Subscript i Baseline right-parenthesis"><mrow><mi>E</mi>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at Table 2-1 and try to calculate the expected value of the next
    employment numbers in a certain month of the year.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-1\. Employment table
  prefs: []
  type: TYPE_NORMAL
- en: '| Non-farm payrolls | Probability |'
  prefs: []
  type: TYPE_TB
- en: '| 300,000 | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| 400,000 | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| 500,000 | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 600,000 | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '*Non-farm payrolls* refer to a monthly report issued by the US Department of
    Labor that gives information on the total number of paid employees in the nation,
    excluding those employed in the agriculture sector, as well as those employed
    by the government and non-profit organizations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From Table 2-1, economists assume there is a 50% probability that there will
    be a 500,000 increase in the total number of paid employees and a 30% probability
    that there will be a 400,000 increase in the total number of paid employees. The
    expected value is therefore:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper E left-parenthesis upper X right-parenthesis equals left-parenthesis
    300 comma 000 times 0.1 right-parenthesis plus left-parenthesis 400 comma 000
    times 0.3 right-parenthesis plus left-parenthesis 500 comma 000 times 0.5 right-parenthesis
    plus left-parenthesis 600 comma 000 times 0.1 right-parenthesis equals 460 comma
    000"><mrow><mi>E</mi> <mo>(</mo> <mi>X</mi> <mo>)</mo> <mo>=</mo> <mo>(</mo> <mn>300</mn>
    <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>1</mn> <mo>)</mo>
    <mo>+</mo> <mo>(</mo> <mn>400</mn> <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn>
    <mo>.</mo> <mn>3</mn> <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>500</mn> <mo>,</mo>
    <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>)</mo> <mo>+</mo>
    <mo>(</mo> <mn>600</mn> <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo>.</mo>
    <mn>1</mn> <mo>)</mo> <mo>=</mo> <mn>460</mn> <mo>,</mo> <mn>000</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the number that represents the economists’ consensus is 460,000,
    as it is the closest weighted value to most forecasts. It is the value that represents
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before closing the section on introductory probability, there exists a mathematical
    formula known as *Bayes’ Theorem* that estimates an event’s likelihood based on
    knowledge of previous, related events. The formula for Bayes’ Theorem is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A vertical-bar upper B right-parenthesis
    equals StartFraction upper P left-parenthesis upper B vertical-bar upper A right-parenthesis
    period upper P left-parenthesis upper A right-parenthesis Over upper P left-parenthesis
    upper B right-parenthesis EndFraction"><mrow><mi>P</mi> <mrow><mo>(</mo> <mi>A</mi>
    <mo>|</mo> <mi>B</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>P</mi><mo>(</mo><mi>B</mi><mo>|</mo><mi>A</mi><mo>)</mo><mo>.</mo><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo></mrow>
    <mrow><mi>P</mi><mo>(</mo><mi>B</mi><mo>)</mo></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'where:'
  prefs: []
  type: TYPE_NORMAL
- en: '*P(A|B)* is the probability of event A occurring given that event B has occurred.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(B|A)* is the probability of event B occurring given that event A has occurred.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(A)* is the probability of event A occurring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*P(B)* is the probability of event B occurring.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In other words, Bayes’ Theorem allows you to update your beliefs about the probability
    of an event based on new information.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The main takeaways from this section are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Probabilitydescribes random variables and random events. It is a value between
    0 and 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probabilities of events may be grouped together to form more complex scenarios.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The expected outcome is the weighted average of every probability in the designated
    universe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sampling and Hypothesis Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When populations are large, representative samples are taken so that they become
    the main describers of data. Take the United States. Its democratic system means
    that the people hold the right to decide their own fate, but it’s not possible
    to go to every person and ask them about their detailed opinions on every topic
    out there. This is why elections are held and representatives are elected so that
    they act in the people’s name.
  prefs: []
  type: TYPE_NORMAL
- en: '*Sampling* refers to the act of selecting samples of data within a larger population
    and and making conclusions about the statistical properties of the population. There
    are a few different methods of sampling. The most known ones are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Simple random sampling
  prefs: []
  type: TYPE_NORMAL
- en: With simple random sampling, each element in the population has an equal chance
    of being selected for the sample. This can be a random number generated on a labeled
    population where each individual has the same probability of being selected.
  prefs: []
  type: TYPE_NORMAL
- en: Stratified sampling
  prefs: []
  type: TYPE_NORMAL
- en: With stratified sampling, the population is divided into groups based on some
    characteristic, and then a simple random sample is taken from each group in proportion
    to its size.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster sampling
  prefs: []
  type: TYPE_NORMAL
- en: With cluster sampling, the population is divided into clusters, and a random
    sample of clusters is selected. Then, all elements within the selected clusters
    are included in the sample.
  prefs: []
  type: TYPE_NORMAL
- en: Systematic sampling
  prefs: []
  type: TYPE_NORMAL
- en: With systematic sampling, an element is selected by choosing every *nth* individual
    from the population, where *n* is a fixed number. This means that it is not random
    but pre-specified in advance.
  prefs: []
  type: TYPE_NORMAL
- en: A rule of thumb is that the more data you acquire, the better the metrics reflect
    the population. Sampling is extremely important in the world of machine learning
    as quite often, you are taking samples of data to represent the true population.
    For example, when performing a back-test on a strategy, you will be required to
    split the whole data set into a *training sample* and a *testing sample* where
    the first is the sample of data on which the algorithm understands its structure,
    and the second is the sample of data on which the algorithm tests its predictive
    power.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, another example of using sampling is *cross validation*, a technique
    that divides a dataset into two or more subgroups. The model is trained using
    one subset, and its results are tested using the other subsets. For various subsets
    of the data, this procedure is repeated numerous times, and then the model’s average
    performance is determined.
  prefs: []
  type: TYPE_NORMAL
- en: These terms are discussed in more depth in the coming chapters. For now you
    should understand that the concept of sampling is very important in machine learning
    (and even more in deep learning with optimization techniques).
  prefs: []
  type: TYPE_NORMAL
- en: Sampling is not perfect and errors may be possible just as any other estimation
    method. *Sampling error* refers to the difference between the statistic of the
    sample and the statistic of the population (if it’s known). A *statistic* is a
    metric that describes the analyzed dataset (an example of this would be the mean,
    a statistic you will see in greater detail in Chapter 3 dealing with statistics).
    Now, what is the minimum sample size you should have to be able to make inferences
    about the population? The rule of thumb is to have a minimum of 30 observations
    and the more the merrier. This brings the discussion to the *central limit theorem*
    which states that random samples drawn from a population will approach a normal
    distribution (a probability distribution that is symmetric and bell-shaped) as
    the sample gets larger.
  prefs: []
  type: TYPE_NORMAL
- en: 'The central limit theorem makes it simple to apply inferences and conclusions
    as hypothesis testing goes well with a normal distribution. Before proceeding
    to hypothesis testing, let’s look at *confidence intervals*, ranges of values
    where the population parameter is expected to be. Confidence intervals are generally
    constructed by adding or subtracting a factor from the point estimate. For example,
    given a sample mean x̄, a confidence interval can be constructed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x overbar plus-or-minus left-parenthesis r e l i a b i l i t
    y f a c t o r times s t a n d a r d e r r o r right-parenthesis"><mrow><mover
    accent="true"><mi>x</mi> <mo>¯</mo></mover> <mo>±</mo> <mrow><mo>(</mo> <mi>r</mi>
    <mi>e</mi> <mi>l</mi> <mi>i</mi> <mi>a</mi> <mi>b</mi> <mi>i</mi> <mi>l</mi> <mi>i</mi>
    <mi>t</mi> <mi>y</mi> <mi>f</mi> <mi>a</mi> <mi>c</mi> <mi>t</mi> <mi>o</mi> <mi>r</mi>
    <mo>×</mo> <mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>n</mi> <mi>d</mi> <mi>a</mi> <mi>r</mi>
    <mi>d</mi> <mi>e</mi> <mi>r</mi> <mi>r</mi> <mi>o</mi> <mi>r</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try to understand the calculation step by step. The sample mean is an
    estimate of the population and is calculated because it is not possible to calculate
    the population means, therefore, by performing a random sample, the assumption
    is that the sample mean should be equal to the population mean. However, in real
    life, things may differ, and this why you should construct a confidence interval
    using probabilistic methods.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The *significance level* is the threshold of the confidence interval. For example,
    a confidence interval of 95% means that with 95% confidence, the estimate should
    lie within a certain range. The remaining 5% probability that it does not, is
    called a significance level (generally marked with the alpha symbol α).
  prefs: []
  type: TYPE_NORMAL
- en: A *reliability f**actor* is a statistical measure that depends on the distribution
    of the estimate and the probability that it falls within the confidence interval.
    For the sake of simplicity, let’s assume that the variance of the population is
    normal and the population is normally distributed. For a significance level of
    5% (thus, a confidence interval of 95%), the reliability factor is 1.96 in this
    case (the way you get this number is less relevant to the discussion).
  prefs: []
  type: TYPE_NORMAL
- en: 'The *standard error* is the standard deviation of the sample. *Standard deviation*
    is discussed in greater depth in Chapter 3; for now, just know that it represents
    the fluctuations of the different values around the mean. Standard error is found
    using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="s equals StartFraction sigma Over StartRoot n EndRoot EndFraction"><mrow><mi>s</mi>
    <mo>=</mo> <mfrac><mi>σ</mi> <msqrt><mi>n</mi></msqrt></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sigma i s t h e p o p u l a t i o n s t a n d a r d d e v i a
    t i o n"><mrow><mi>σ</mi> <mi>i</mi> <mi>s</mi> <mi>t</mi> <mi>h</mi> <mi>e</mi>
    <mi>p</mi> <mi>o</mi> <mi>p</mi> <mi>u</mi> <mi>l</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi>
    <mi>o</mi> <mi>n</mi> <mi>s</mi> <mi>t</mi> <mi>a</mi> <mi>n</mi> <mi>d</mi> <mi>a</mi>
    <mi>r</mi> <mi>d</mi> <mi>d</mi> <mi>e</mi> <mi>v</mi> <mi>i</mi> <mi>a</mi> <mi>t</mi>
    <mi>i</mi> <mi>o</mi> <mi>n</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartRoot n EndRoot i s t h e s q u a r e r o o t o f t h e p
    o p u l a t i o n n u m b e r"><mrow><msqrt><mi>n</mi></msqrt> <mi>i</mi> <mi>s</mi>
    <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi> <mi>q</mi> <mi>u</mi> <mi>a</mi> <mi>r</mi>
    <mi>e</mi> <mi>r</mi> <mi>o</mi> <mi>o</mi> <mi>t</mi> <mi>o</mi> <mi>f</mi> <mi>t</mi>
    <mi>h</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>p</mi> <mi>u</mi> <mi>l</mi> <mi>a</mi>
    <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mi>n</mi> <mi>u</mi> <mi>m</mi> <mi>b</mi>
    <mi>e</mi> <mi>r</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth knowing that for a 1% significance level, the reliability factor
    is 2.575, and for a 10% significance level, the reliability factor is 1.645\.
    Let’s take a practical example to make sense out all of this math.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a population of 100 financial instruments (bonds, currency pairs, stocks,
    structured products, etc.). The mean annual return of these instruments is 1.4%.
    Assuming a population standard deviation of 4.34%, what is the confidence interval
    at 1% significance level (99% confidence interval) of the mean?
  prefs: []
  type: TYPE_NORMAL
- en: 'The answer is just plugging the values in the formula as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="1.4 percent-sign plus-or-minus 2.575 times StartFraction 4.34
    percent-sign Over StartRoot 100 EndRoot EndFraction equals 1.4 percent-sign plus-or-minus
    1.11 percent-sign"><mrow><mn>1</mn> <mo>.</mo> <mn>4</mn> <mo>%</mo> <mo>±</mo>
    <mn>2</mn> <mo>.</mo> <mn>575</mn> <mo>×</mo> <mfrac><mrow><mn>4</mn><mo>.</mo><mn>34</mn><mo>%</mo></mrow>
    <msqrt><mn>100</mn></msqrt></mfrac> <mo>=</mo> <mn>1</mn> <mo>.</mo> <mn>4</mn>
    <mo>%</mo> <mo>±</mo> <mn>1</mn> <mo>.</mo> <mn>11</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This means that the confidence interval is between (0.29%, 2.51%).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see another example. Consider that the annual returns on precious and
    industrial metals (such as gold and copper) are normally distributed with a mean
    of 3.5% and a known population standard deviation of 5.1%. What is the confidence
    interval with 10% significance level of the annual returns on 5 different commodities?
    The answer is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="3.5 percent-sign plus-or-minus 1.645 times StartFraction 3.5
    percent-sign Over StartRoot 5 EndRoot EndFraction equals 3.5 percent-sign plus-or-minus
    2.23 percent-sign"><mrow><mn>3</mn> <mo>.</mo> <mn>5</mn> <mo>%</mo> <mo>±</mo>
    <mn>1</mn> <mo>.</mo> <mn>645</mn> <mo>×</mo> <mfrac><mrow><mn>3</mn><mo>.</mo><mn>5</mn><mo>%</mo></mrow>
    <msqrt><mn>5</mn></msqrt></mfrac> <mo>=</mo> <mn>3</mn> <mo>.</mo> <mn>5</mn>
    <mo>%</mo> <mo>±</mo> <mn>2</mn> <mo>.</mo> <mn>23</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This means that the confidence interval is between (1.27%, 5.8%).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If the sample size is small and / or the population standard deviation is unknown,
    a t-distribution may be a better choice than a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The *t-distribution* is a type of probability distribution used to model the
    distribution of a sample mean when the sample size is small and/or when the population
    standard deviation is unknown. It resembles the normal distribution in shape,
    but with heavier tails, which represents the uncertainty associated with smaller
    sample sizes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before closing the discussion on sampling and estimation, the following list
    shows the appropriate distributions given the characteristics of the population:'
  prefs: []
  type: TYPE_NORMAL
- en: A small normal distribution with known variance should use the reliability factor
    of the normal distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A large normal distribution with known variance should use the reliability factor
    of the normal distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A small normal distribution with unkown variance should use the reliability
    factor of the t-distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A large normal distribution with unkown variance should use the reliability
    factor of the t-distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A large non-normal distribution with known variance should use the reliability
    factor of the normal distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A large non-normal distribution with known variance should use the reliability
    factor of the t-distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember that *large* means that the number of observations are greater than
    30\. The non covered combinations in the previous list are complex and out of
    scope of this discussion.
  prefs: []
  type: TYPE_NORMAL
- en: The next stop is hypothesis testing, a key probabilistic technique of getting
    conclusions on samples of data. This part is extremely important as it’s used
    in almost all types of statistical analyses and models.
  prefs: []
  type: TYPE_NORMAL
- en: In statistics, *hypothesis testing* is a technique for drawing conclusions about
    a population from a small sample of data. It entails developing two competing
    hypotheses, the *null hypothesis* and the *alternative hypothesis*, about a population
    parameter, and then figuring out which is more likely to be accurate using sample
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a financial analyst is evaluating two portfolios from a risk perspective.
    They formulate two hypotheses:'
  prefs: []
  type: TYPE_NORMAL
- en: The null hypothesis states that there is no significant difference in the volatility
    of the two portfolios.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The alternative hypothesis states that there is a significant difference in
    the volatility of the two portfolios.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The hypothesis is then tested using statistical analysis to determine if the
    difference in volatility is statistically significant or due to pure chance.
  prefs: []
  type: TYPE_NORMAL
- en: Following the definition of the null and alternative hypotheses, a test statistic
    is computed using the sample data. To assess the result’s significance, the test
    statistic is then compared to a critical value drawn from a standard distribution.
    The null hypothesis is rejected and the alternative hypothesis is accepted if
    the test statistic is inside the crucial zone. The null hypothesis is not rejected
    and the conclusion that there is insufficient evidence to support the alternative
    hypothesis is reached if the test statistic does not fall inside the crucial zone.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is all fancy talk to say that hypothesis testing is basically creating
    two opposing scenarios, running a probability check, and then deciding which scenario
    is more likely true. Hypothesis testing can take two forms:'
  prefs: []
  type: TYPE_NORMAL
- en: '*One-tailed test*: An example of this would be to test if the return on certain
    financial instruments is greater than zero.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Two-tailed test*: An example of this would be to test if the the return on
    certain financial instruments is different from than zero (meaning that it can
    be either greater or smaller than zero).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Hypothesis tests are generally two-tailed.
  prefs: []
  type: TYPE_NORMAL
- en: 'The null hypothesis is the one that you want to reject and therefore is tested
    in the hopes of getting rejected and accepting the alternative scenario. A two-tailed
    test takes the following general form:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H 0 colon x equals x 0"><mrow><msub><mi>H</mi> <mn>0</mn></msub>
    <mo>:</mo> <mi>x</mi> <mo>=</mo> <msub><mi>x</mi> <mn>0</mn></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H Subscript a Baseline colon x not-equals x 0"><mrow><msub><mi>H</mi>
    <mi>a</mi></msub> <mo>:</mo> <mi>x</mi> <mo>≠</mo> <msub><mi>x</mi> <mn>0</mn></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: As the alternative scenario allows for values above and below zero (which is
    the stated level in the null hypothesis), there should be two critical values.
    Therefore, the rule of a two-tailed test is to reject the null hypothesis if the
    test statistic is greater than the upper critical value or if the test statistic
    is lower than the lower critical value. For instance, for a normally distributed
    data, the test statistic is compared with the critical values (at 5% significance
    level) at +1.96 and -1.96\. The null hypothesis is rejected if the test statistic
    falls outside the range between +1.96 and -1.96.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process of hypothesis testing entails the calculation of the test statistic.
    It is calculated by comparing the point estimate of the population parameter with
    the hypothesized value of the null hypothesis. Both are then scaled by the standard
    error of the sample. The mathematical representation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="t e s t s t a t i s t i c equals StartFraction s a m p l e s
    t a t i s t i c minus h y p o t h e s i z e d v a l u e Over s t a n d a r d e
    r r o r EndFraction"><mrow><mi>t</mi> <mi>e</mi> <mi>s</mi> <mi>t</mi> <mi>s</mi>
    <mi>t</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi> <mi>s</mi> <mi>t</mi> <mi>i</mi> <mi>c</mi>
    <mo>=</mo> <mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi>s</mi><mi>a</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>i</mi><mi>c</mi><mo>-</mo><mi>h</mi><mi>y</mi><mi>p</mi><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mi>d</mi><mi>v</mi><mi>a</mi><mi>l</mi><mi>u</mi><mi>e</mi></mrow>
    <mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>a</mi><mi>r</mi><mi>d</mi><mi>e</mi><mi>r</mi><mi>r</mi><mi>o</mi><mi>r</mi></mrow></mfrac></mstyle></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'An important consideration in hypothesis testing is that the sample may not
    be representative, which leads to errors in describing the population. This gives
    rise to two types of errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Type I error*: This error occurs when rejecting the null hypothesis even though
    it is true.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Type II error*: This error occurs when failing to reject the null hypothesis
    even though it is false.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intuitively, the significance level is the probability of making a type I error.
    Remember that if α = 5%, then there is a 5% chance of rejecting a true null hypothesis
    by mistake. An example would make things clearer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider an analyst doing research on the annual returns of a long-short portfolio
    over a period of 20 years. The mean annual return was 1% with a standard deviation
    of 2%. The analyst’s opinion is that the annual mean return is not equal to zero
    and they want to constuct a 95% confidence interval for this and then construct
    a hypothesis test:'
  prefs: []
  type: TYPE_NORMAL
- en: State the variables. The size of the sample is 20, the standard deviation is
    2% and the mean is 1%.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the standard error, which in this case is 0.44% as per the formula.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the critical values for the 95% confidence interval, which are +1.96
    and -1.96.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The confidence interval is therefore (0.13%, 1.86%).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specify the null hypothesis, which is, according to the analyst’s opinion, a
    two-tailed test. The null hypothesis is that the annuel return equals zero. You
    should reject it if the test statistic is less than -1.96 or greater than +1.96.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the formula to find the test statistic gives 2.27\. Therefore, the null
    hypothesis is rejected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'One more important metric to discuss: the p-value. The* p-value* is the probability
    of seeing a test statistic more extreme than the one seen in the statistical test
    given that the null hypothesis is true. Comparing a p-value to a significance
    level—typically 0.05—allows you to understand it. The result is deemed statistically
    significant, and the null hypothesis is rejected in favor of the alternative hypothesis
    if the p-value is less than or equal to the significance level.'
  prefs: []
  type: TYPE_NORMAL
- en: If the p-value is less than the significance level of 5%, it means that there
    is a 5% chance to see a test statistic as extreme as the current one if the null
    hypothesis is true. Another way of defining the p-value is to consider it as the
    smallest significance level for which the null hypothesis can be rejected.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The main takeaways from this section are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Sampling refers to the collection of data within a population in the aim of
    making conclusions about the statistical properties of the aforementioned population.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sampling is used extensively in machine learning. One example is cross validation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hypothesis testing is a technique for drawing conclusions about a population
    from a small sample of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Primer on Information Theory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Information theory* is a complex abstract mathematical field that is closely
    related to probability. It is the study of how information is quantified, stored,
    and transmitted. There are three conditions of occurrence when it comes to an
    event:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Uncertainty*: If the event has not occurred yet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Surprise*: If the event has just occurred.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Information*: If the event has occurred in the past.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the key concepts in information theory is *entropy*:the level of uncertainty
    or randomness in a message or information source. It describes the degree to which
    an event or message is unexpected. In contrast, *information gain* measures the
    reduction in entropy (surprise) when receiving new information.
  prefs: []
  type: TYPE_NORMAL
- en: Basically, information theory describes the surprise of events. When an event
    has a low probability of occurrence, it has more surprise and hence, more information
    to provide. Similarly, when an event has a high probability of occurrence, it
    has less surprise and therefore, less information. What you should retain from
    this is that the amount of information learned from an unlikely event is greater
    than the amount of information learned from a likely event.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before starting to dig a little deeper in information theory, it is important
    to understand what a *logarithm* is and for that matter what an *exponent* is.
    A general exponential function takes a certain constant or a variable to a certain
    power:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="f left-parenthesis x right-parenthesis equals a Superscript x"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>a</mi> <mi>x</mi></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, the *exponent of a number* is the number of times you will
    multiply it by itself:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="4 cubed equals 4 times 4 times 4 equals 64"><mrow><msup><mn>4</mn>
    <mn>3</mn></msup> <mo>=</mo> <mn>4</mn> <mo>×</mo> <mn>4</mn> <mo>×</mo> <mn>4</mn>
    <mo>=</mo> <mn>64</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, a logarithm is the opposite of an exponent, and its aim is to
    find the exponent (knowing 4 and 64 from the previous example and finding 3):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="log Subscript 4 Baseline left-parenthesis 64 right-parenthesis
    equals 3"><mrow><msub><mo form="prefix">log</mo> <mn>4</mn></msub> <mrow><mo>(</mo>
    <mn>64</mn> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'A logarithm, therefore, is the answer to how many of one number to multiply
    to get another number. Since they are literally inverse functions, you can use
    them together to simplify or even solve for x. Take the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="log Subscript 4 Baseline left-parenthesis x right-parenthesis
    equals 3"><mrow><msub><mo form="prefix">log</mo> <mn>4</mn></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The objective here is to find x given the logarithmic function. The first step
    is simply to use the exponential function on one side as you want it to cancel
    out the logarithm on the right (remember, inverse functions cancel each other
    out). This gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="4 Superscript l o g 4 left-parenthesis x right-parenthesis Baseline
    equals 4 cubed"><mrow><msup><mn>4</mn> <mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi>
    <mn>4</mn></msub> <mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow></msup> <mo>=</mo>
    <msup><mn>4</mn> <mn>3</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x equals 4 cubed"><mrow><mi>x</mi> <mo>=</mo> <msup><mn>4</mn>
    <mn>3</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x equals 64"><mrow><mi>x</mi> <mo>=</mo> <mn>64</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Logarithms can have different bases. However, the most used logarithm has a
    base of 10. In computer science, base 2 logarithms represent bits (binary digits).
    Therefore, information is represented as bits. The formula of information gain
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis x Subscript i Baseline right-parenthesis
    equals minus l o g 2 left-parenthesis upper P left-parenthesis x Subscript i Baseline
    right-parenthesis right-parenthesis"><mrow><mi>H</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <mi>l</mi> <mi>o</mi>
    <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s assume two variables *x* and *y* where *x* has a probability of 1 (100%
    and therefore, certain) and *y* has a probability of 0.5 (50% and therefore, mostly
    random), what would be the information in these two cases? The answer is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis x right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 1 right-parenthesis right-parenthesis
    equals 0"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>1</mn> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo>
    <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis y right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 0.5 right-parenthesis right-parenthesis
    equals 1"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: So the certain event gives zero information and the one that has a fifty-fifty
    chance of realizing has an information of 1\. What about the very unlikely event
    *z* that has a probability of 0.05 (5%)?
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis z right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 0.05 right-parenthesis right-parenthesis
    equals 4.32"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>0</mn> <mo>.</mo> <mn>05</mn> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mn>4</mn> <mo>.</mo> <mn>32</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: A negative relationship between probability and information is therefore one
    of the principles of information theory. Entropy and information are related concepts,
    but they have different meanings and applications.
  prefs: []
  type: TYPE_NORMAL
- en: '*Entropy* is a metric used to assess how chaotic or random a system is. Entropy
    describes how uncertain or unpredictable a signal is. The degree of disorder or
    unpredictability in the system or communication increases as entropy increases.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Information* is the decrease in entropy or uncertainty that happens as a result
    of receiving a signal. A signal’s ability to lessen the receiver’s uncertainty
    or entropy increases with its informational content.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Entropy is maximized whenever all the events are equally likely.
  prefs: []
  type: TYPE_NORMAL
- en: 'Entropy is calculated using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper S left-parenthesis x Subscript n Baseline right-parenthesis
    equals sigma-summation Underscript i equals 1 Overscript n Endscripts left-parenthesis
    minus l o g 2 left-parenthesis upper P left-parenthesis x Subscript i Baseline
    right-parenthesis right-parenthesis period left-parenthesis upper P left-parenthesis
    x Subscript i Baseline right-parenthesis right-parenthesis right-parenthesis"><mrow><mi>S</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>)</mo></mrow> <mo>=</mo>
    <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <mrow><mo>(</mo> <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub>
    <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>.</mo> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, it is the average of the sum of logarithms times their respective
    probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s discuss the final concept of the section, *information gain*.  The
    reduction in entropy caused by changing a dataset is calculated via information
    gain.
  prefs: []
  type: TYPE_NORMAL
- en: Information gain is one of the key concepts you will see in Chapter 7 with decision
    trees, and therefore you may want to refer to this section after understanding
    what decision trees are.
  prefs: []
  type: TYPE_NORMAL
- en: You mainly calculate information gain by comparing the entropy of a dataset
    before and after a transformation. Recall that entropy is maximized when all the
    outcomes of a random event have the same probability. This can also be presented
    as a distribution where a symmetrical distribution (such as the normal distribution)
    has high entropy and a skewed distribution has low entropy.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Minimizing entropy is related to maximizing information gain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before closing this introductory section on information theory (you will see
    it in greater depth when discussing decision trees), let’s look at the concept
    of *mutual information*. This measure is calculated between two variables, hence
    the name *mutual*, and it measures the reduction in uncertainty of a variable
    given another variable. The formula for mutual information is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper M upper I left-parenthesis x comma y right-parenthesis
    equals upper S left-parenthesis x right-parenthesis minus upper S left-parenthesis
    x vertical-bar y right-parenthesis"><mrow><mi>M</mi> <mi>I</mi> <mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo>
    <mo>-</mo> <mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>y</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper M upper I left-parenthesis x comma y right-parenthesis
    i s t h e m u t u a l i n f o r m a t i o n o f x a n d y"><mrow><mi>M</mi> <mi>I</mi>
    <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo> <mi>i</mi> <mi>s</mi> <mi>t</mi>
    <mi>h</mi> <mi>e</mi> <mi>m</mi> <mi>u</mi> <mi>t</mi> <mi>u</mi> <mi>a</mi> <mi>l</mi>
    <mi>i</mi> <mi>n</mi> <mi>f</mi> <mi>o</mi> <mi>r</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi>
    <mi>i</mi> <mi>o</mi> <mi>n</mi> <mi>o</mi> <mi>f</mi> <mi>x</mi> <mi>a</mi> <mi>n</mi>
    <mi>d</mi> <mi>y</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper S left-parenthesis x right-parenthesis i s t h e e n t
    r o p y o f x"><mrow><mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mi>i</mi> <mi>s</mi>
    <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>r</mi> <mi>o</mi>
    <mi>p</mi> <mi>y</mi> <mi>o</mi> <mi>f</mi> <mi>x</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper S left-parenthesis x vertical-bar y right-parenthesis i
    s t h e c o n d i t i o n a l e n t r o p y o f x g i v e n y"><mrow><mi>S</mi>
    <mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>y</mi> <mo>)</mo> <mi>i</mi> <mi>s</mi> <mi>t</mi>
    <mi>h</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>n</mi> <mi>d</mi> <mi>i</mi> <mi>t</mi>
    <mi>i</mi> <mi>o</mi> <mi>n</mi> <mi>a</mi> <mi>l</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi>
    <mi>r</mi> <mi>o</mi> <mi>p</mi> <mi>y</mi> <mi>o</mi> <mi>f</mi> <mi>x</mi> <mi>g</mi>
    <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>n</mi> <mi>y</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Mutual information therefore measures the dependence between the variables.
    The greater the mutual information, the bigger the relationship between the variables
    (a value of zero represents independent variables). Keep this concept in mind
    as you will see it in Chapter 3 in the section that deals with correlations. This
    is because mutual information can also be a measure of non-linear correlation
    between the variables.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s do a summary of what you need to retain in information theory to have
    a basic knowledge of what’s to come:'
  prefs: []
  type: TYPE_NORMAL
- en: Information theory uses concepts from probability to calculate information and
    entropy that are used in machine learning models and other calculations (such
    as correlation).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Information is the decrease in entropy or uncertainty that happens as a result
    of receiving a signal. Entropy is a metric used to assess how chaotic or random
    a system is.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mutual information is a measure of dependence between two random variables.
    It can also be used to calculate the correlation between the two.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools from information theory are used in some machine learning models such
    as decision trees.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Probability presents a basic framework before continuing towards more advanced
    topics. This chapter skimmed over the concepts that you may encounter when dealing
    with machine and deep learning models. It is important to understand how probability
    is calculated and how hypothesis testing is performed (even though, in reality
    algorithms will do this for you).
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter is extremely important and presents the required statistical
    knowledge you need, not just for machine learning but also for financial trading
    and even complex data analysis.
  prefs: []
  type: TYPE_NORMAL
