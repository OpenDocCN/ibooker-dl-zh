<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 4. Advanced Editing and Autonomous Workflows in the IDE"><div class="chapter" id="ch04">
<h1><span class="label">Chapter 4. </span>Advanced Editing and Autonomous Workflows in the IDE</h1>

<p><a contenteditable="false" data-primary="IDEs" data-secondary="advanced editing in" data-type="indexterm" id="xi_IDEsadvancededitingin444"/><a contenteditable="false" data-primary="IDEs" data-secondary="autonomous workflows in" data-type="indexterm" id="xi_IDEsautonomousworkflowsin444"/><a contenteditable="false" data-primary="editing" data-secondary="in IDE" data-type="indexterm" id="xi_editinginIDE444"/><a contenteditable="false" data-primary="autonomous workflows" data-secondary="in IDE" data-type="indexterm" id="xi_autonomousworkflowsinIDE444"/><a contenteditable="false" data-primary="workflows" data-secondary="autonomous" data-type="indexterm" id="xi_workflowsautonomous444"/>In Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch02.html#ch02">2</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch03.html#ch03">3</a>, we covered the basics of creating code and using the chat interface to get things done with Copilot in the IDE. The items we’ve discussed will help handle basic use cases. But for more intensive coding efforts like refactoring, making significant edits, or automatically handling more complex changes, Copilot provides advanced features.</p>

<p>In this chapter, we’ll look at a powerful set of features that leverage the AI to handle larger sets of changes and code generation for you. These include the following:</p>

<ul>
	<li>Predictive edits with Next Edit Suggestions</li>
	<li>Batch changes with Copilot Edits</li>
	<li>Automated end-to-end updates with Copilot Agent mode</li>
	<li>Producing code based on images with Copilot Vision</li>
	<li>Debugging with Copilot</li>
</ul>

<p>Let’s start off looking at a feature that can predict where your next edit should be.</p>

<section data-type="sect1" data-pdf-bookmark="Predictive Edits with Next Edit Suggestions"><div class="sect1" id="id43">
<h1>Predictive Edits with Next Edit Suggestions</h1>

<p><a contenteditable="false" data-primary="editing" data-secondary="predictive edits with Next Edit Suggestions (NES)" data-type="indexterm" id="xi_editingpredictiveeditswithNextEditSuggestionsNES4214"/><a contenteditable="false" data-primary="predictive edits, with Next Edit Suggestions (NES)" data-type="indexterm" id="xi_predictiveeditswithNextEditSuggestionsNES4214"/><a contenteditable="false" data-primary="NES (Next Edit Suggestions)" data-secondary="predictive edits using" data-type="indexterm" id="xi_NESNextEditSuggestionspredictiveeditsusing4214"/>Have you ever been trying to refactor your code in some way and found yourself searching through your file to locate all the places you need to make changes? Co­pilot’s Next Edit Suggestions (NES) is designed to eliminate the need for that and simplify the process of identifying and making the <em>next change</em>.</p>

<p>NES predicts and suggests edits based on ongoing changes in your code, typos, or logic errors. The changes it suggests can range from a single symbol to multiple lines of code. In the refactoring use case, NES can analyze the edits you’re making and locate the next place in the logic where a change needs to be made, then the next place, and so on.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id617">
<h1>Activating Next Edit Suggestions</h1>

<p><a contenteditable="false" data-primary="NES (Next Edit Suggestions)" data-secondary="activating" data-type="indexterm" id="id618"/>As of this writing, you can activate NES in VS Code via a pop-up dialog box that’s accessed by clicking the Copilot control in the status bar (<a data-type="xref" href="#enable-nes-from-copil">Figure 4-1</a>).</p>

<figure><div id="enable-nes-from-copil" class="figure"><img alt="" src="assets/lghc_0401.png" width="870" height="440"/>
<h6><span class="label">Figure 4-1. </span>Enable NES from the Copilot control</h6>
</div></figure>

<p>You can also enable it directly in your VS Code configuration by setting <code translate="no">github.copilot.nextEditSuggestions.enabled=true</code> .</p>
</div></aside>

<p>When enabled, and after you make an edit, NES looks at your code and tries to anticipate what else is related and should be changed next. NES highlights its suggestion for the next change by putting an arrow in the editor’s gutter. The <em>gutter<a contenteditable="false" data-primary="gutter" data-type="indexterm" id="id619"/></em> refers to the empty strip of space to the left of the line numbers in the editor. As an example, say we have a Python class that represents a 2D point and includes a method to calculate the distance between two points. It also includes a simple example. The code might look like this:</p>

<pre data-type="programlisting" translate="no">
# Define a class Point with a
# method to calculate the distance to another point
class Point:
    def __init__(self, x, y):
        self.x = x
        self.y = y
      
        
    def distance(self, other):
        return ((self.x - other.x)**2 +
                (self.y - other.y)**2)
          

p1 = Point(1, 2)
p2 = Point(4, 6)
print(p1.distance(p2)</pre>

<p>We want to change this class to work for 3D points, so we change the <code translate="no">__init__</code> statement to add a <code translate="no">z</code> value. If NES is enabled, after we make that change, Copilot will look for the next place where the code needs to be changed to handle the new <code translate="no">z</code> coordinate. Copilot determines it needs to add a constructor for that value in the <code translate="no">init </code>method, suggests the code change, and highlights it with the arrow in the gutter, as shown in <a data-type="xref" href="#nes-identifying-next">Figure 4-2</a>:</p>

<figure><div id="nes-identifying-next" class="figure"><img alt="" src="assets/lghc_0402.png" width="933" height="476"/>
<h6><span class="label">Figure 4-2. </span>NES identifying the next change</h6>
</div></figure>

<p>To get to this change quickly, you just hit Tab. Hovering over the arrow in the gutter presents an informational dialog with extended options for working with NES (<a data-type="xref" href="#nes-options-popup">Figure 4-3</a>). In most cases, you won’t need these. You can just press Tab to accept the suggested change or Escape to reject it and move on.</p>

<figure><div id="nes-options-popup" class="figure"><img alt="" src="assets/lghc_0403.png" width="1002" height="455"/>
<h6><span class="label">Figure 4-3. </span>NES options pop-up</h6>
</div></figure>

<p>Once we process this change (accept or reject), the process continues, and Copilot identifies the next suggested edit (<a data-type="xref" href="#next-change">Figure 4-4</a>). The process will then repeat as long as there are eligible changes that Copilot identifies.</p>

<figure><div id="next-change" class="figure"><img alt="" src="assets/lghc_0404.png" width="823" height="486"/>
<h6><span class="label">Figure 4-4. </span>The next change</h6>
</div></figure>

<div data-type="warning" epub:type="warning">
<h1>Don’t Lose Focus</h1>

<p>If you have a pending NES change (with the arrow visible in the gutter) and switch focus away from the editor, the pending change will disappear, and the NES process will stop.</p>
</div>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id620">
<h1>Using Copilot to Help with Renaming</h1>

<p><a contenteditable="false" data-primary="renaming suggestions" data-type="indexterm" id="id621"/>While we are on the topic of refactoring, did you know you can also have Copilot help you with renaming suggestions? If you highlight a symbol and then hit F2, Copilot will pop up a dialog with suggested alternate names for the symbol. See <a data-type="xref" href="#rename-example">Figure 4-5</a> for an example with our current class.</p>

<figure class="width-70"><div id="rename-example" class="figure"><img alt="" src="assets/lghc_0405.png" width="779" height="408"/>
<h6><span class="label">Figure 4-5. </span>A renaming example</h6>
</div></figure>

<p>When you select a new name, Copilot will apply it to the selected symbols. If other instances should be renamed in separate methods or functions, NES can help catch those.</p>
</div></aside>

<p>While the NES functionality can substantially help with common changes, such as intentional refactoring, it can also catch and point out independent issues, like typos and logic errors.</p>

<p>Assume we had coded the changes to the distance function ourselves and accidentally used the multiplication operator instead of the exponent operator. With NES activated, Copilot would catch that and suggest a change to correct it, as shown in <a data-type="xref" href="#nes-suggesting-change">Figure 4-6</a>.</p>

<figure><div id="nes-suggesting-change" class="figure"><img alt="" src="assets/lghc_0406.png" width="862" height="207"/>
<h6><span class="label">Figure 4-6. </span>NES suggesting a change to fix a logic error</h6>
</div></figure>

<p>NES can also help catch changes that need to be made across multiple files, but that currently seems to be limited to files that are open in the editor. If you need to make batch changes or automatically add a feature that spans multiple files, consider the advanced edit functionality discussed in our next section instead<a contenteditable="false" data-startref="xi_editingpredictiveeditswithNextEditSuggestionsNES4214" data-type="indexterm" id="id622"/><a contenteditable="false" data-primary="" data-startref="xi_predictiveeditswithNextEditSuggestionsNES4214" data-type="indexterm" id="id623"/><a contenteditable="false" data-primary="" data-startref="xi_NESNextEditSuggestionspredictiveeditsusing4214" data-type="indexterm" id="id624"/>.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Copilot Edits"><div class="sect1" id="copilot-edits">
<h1>Copilot Edits</h1>

<p><a contenteditable="false" data-primary="editing" data-secondary="Copilot Edits" data-type="indexterm" id="xi_editingCopilotEdits41094"/><a contenteditable="false" data-primary="Copilot Edits" data-type="indexterm" id="xi_CopilotEdits41094"/>Copilot includes functionality to make AI-driven changes across a selected set of files. This functionality, called <em>Copilot Edits</em>, allows Copilot to update multiple files in response to a natural language prompt. You can think of this as a sort of batch edit<a contenteditable="false" data-primary="batch editing" data-secondary="functionality of" data-type="indexterm" id="id625"/> functionality driven by AI. It can be useful for tasks ranging from simple refactoring all the way to extensive changes, like adding features, across a subset of existing code.</p>

<p>Copilot Edits is a separate mode in Copilot Chat. To use it, you first need to switch from the default Ask mode in chat to Edit mode. This is done via a menu that shows up when you click the drop-down arrow next to Ask<em>, </em>at the bottom of the prompt entry area (<a data-type="xref" href="#switching-chat-to-edi">Figure 4-7</a>).</p>

<figure><div id="switching-chat-to-edi" class="figure"><img alt="" src="assets/lghc_0407.png" width="884" height="393"/>
<h6><span class="label">Figure 4-7. </span>Switching chat to Edit mode</h6>
</div></figure>

<p>In this mode, you select which files to edit and provide a prompt along with any needed context. Copilot then suggests edits to your code across the files that you can accept or reject. Let’s take a look at a simple example.</p>

<p>Suppose we have a simple set of calculator functions written in Python along with some basic tests and a README file.</p>

<div data-type="note" epub:type="note">
<h1>Our Example</h1>

<p>I’m sharing the code here because it provides the background for the changes we’re going to talk about in the rest of the chapter. And even though this is written in Python, you don’t have to know Python to understand what we’ll be doing.</p>
</div>

<p>Here’s the <em>README.md</em> file:</p>

<pre data-type="programlisting" translate="no">
# Calculator Application

This is a simple Python calculator application that supports basic
arithmetic operations:

- Addition
- Subtraction
- Multiplication
- Division

Run the unit tests in `test_calculator.py` to verify functionality
</pre>

<p>The code for the calculator functions is in a file named <em>calculator.py</em>, shown here:</p>

<pre data-type="programlisting" translate="no">
def add(a, b):
    return a + b

def subtract(a, b):
    return a - b

def multiply(a, b):
    return a * b

def divide(a, b):
    if b == 0:
        raise ValueError("Cannot divide by zero")
    return a / </pre>

<p class="pagebreak-before">The code for the test cases is in a file named <em>test_calculator.py</em>:</p>

<pre data-type="programlisting" translate="no">
import unittest
from calculator import add, subtract, multiply, divide

class TestCalculator(unittest.TestCase):
    def test_add(self):
        self.assertEqual(add(2, 3), 5)

    def test_subtract(self):
        self.assertEqual(subtract(5, 3), 2)

    def test_multiply(self):
        self.assertEqual(multiply(4, 3), 12)

    def test_divide(self):
        self.assertEqual(divide(10, 2), 5)
        with self.assertRaises(ValueError):
            divide(10, 0)

if __name__ == "__main__":
    unittest.main()</pre>

<p>(We also have a standard <em>.gitignore</em> file and a LICENSE file in the project.)</p>

<p>Let’s suppose we want to improve our code in the Python files. Here’s a set of tasks we can prompt Copilot to do in Edit mode:</p>

<ul>
	<li>Refactor the <code translate="no">divide</code> function to handle division by zero more gracefully.</li>
	<li>Add <a href="https://oreil.ly/H6bfq">type hints</a> to all functions in <em>calculator.py</em>.</li>
	<li>Write additional unit tests for edge cases in <em>test_calculator.py</em>.</li>
</ul>

<p>To start the Edits process, we need to add the files we want Copilot to work with. In our simple case, for the prompts we’re using, we just need the two Python files. We can add them most easily by selecting them from the file list and dragging and dropping them into the text entry area of the chat dialog. Alternatively, you can include them by using the <code translate="no">#file</code> chat variable. Or you can use the Add Context control to pick them from the list. <a data-type="xref" href="#selected-files-ready">Figure 4-8</a> shows the files added as context and the prompts supplied in the dialog.</p>

<figure><div id="selected-files-ready" class="figure"><img alt="" src="assets/lghc_0408.png" width="913" height="824"/>
<h6><span class="label">Figure 4-8. </span>Selected files ready for Copilot Edits</h6>
</div></figure>

<p>Once we submit this, Copilot will process the prompts against the selected files and propose any needed changes to accomplish the prompts. These proposed changes will be shown inline in the editor. You can choose to review each one and Keep/Undo each proposed change or Keep/Undo all proposed changes at once based on the new “files changed” section in the chat area. <a data-type="xref" href="#edited-files-ready-fo">Figure 4-9</a> shows the results of running the prompts in Edit mode for the specified context.</p>

<figure><div id="edited-files-ready-fo" class="figure"><img alt="" src="assets/lghc_0409.png" width="1827" height="859"/>
<h6><span class="label">Figure 4-9. </span>Edited files ready for review</h6>
</div></figure>

<p>There are controls for keeping or undoing each suggested edit if you need to get that granular. Also, files with proposed/pending changes have a symbol (dot inside a square<a contenteditable="false" data-primary="dot inside a square symbol" data-type="indexterm" id="id626"/>) in the file list and for ones that are open in the editor. Once you’ve decided what to keep or undo for the proposed changes, the Keep/Undo buttons in the “files changed” area will change to a Done button. You click this to stop this round of <span class="keep-together">editing</span>.</p>

<p>Until you click the Done button<a contenteditable="false" data-primary="Done button" data-type="indexterm" id="id627"/>, you can change your mind and roll back the edits Copilot suggested, even if you chose to keep some or all. You can do this in a couple of ways. You can use the Undo option<a contenteditable="false" data-primary="Undo option" data-type="indexterm" id="id628"/> in the “files changed” area above the entry area. Or you can click the left-curving arrow at the top of the chat panel. Or, you can hover over the top of the conversation in the chat and click the X there, as shown in <a data-type="xref" href="#one-of-several-option">Figure 4-10</a>.</p>

<figure><div id="one-of-several-option" class="figure"><img alt="" src="assets/lghc_0410.png" width="760" height="360"/>
<h6><span class="label">Figure 4-10. </span>One of several options to roll back proposed edits</h6>
</div></figure>

<p>To persist the changes in the files, click the Done button. In our example, the <em>calculator.py</em> file has the type hints included, and the divide function has been refactored:</p>

<pre data-type="programlisting" translate="no">
from typing import Optional

def add(a: float, b: float) -&gt; float:
    return a + b

def subtract(a: float, b: float) -&gt; float:
    return a - b

def multiply(a: float, b: float) -&gt; float:
    return a * b

def divide(a: float, b: float) -&gt; Optional[float]:
    if b == 0:
        return None
    return a / b</pre>

<p>And additional test cases have been added per the other prompt:</p>

<pre data-type="programlisting" translate="no">
def test_divide_by_zero(self):
    self.assertIsNone(divide(10, 0))

def test_add_negative_numbers(self):
    self.assertEqual(add(-2, -3), -5)

def test_subtract_negative_numbers(self):
    self.assertEqual(subtract(-5, -3), -2)

def test_multiply_negative_numbers(self):
    self.assertEqual(multiply(-4, 3), -12)

def test_divide_negative_numbers(self):
    self.assertEqual(divide(-10, 2), -5)
    self.assertEqual(divide(10, -2), -5)
    self.assertEqual(divide(-10, -2), 5</pre>

<p>Here’s one more tip for using Copilot Edits. Instead of selecting individual files, you can use the <code translate="no">#codebase</code> chat variable (see <a data-type="xref" href="ch03.html#ch03">Chapter 3</a>) in your prompt to let Copilot try to select the appropriate files to change. For example, if you used the prompt</p>

<pre data-type="programlisting" translate="no">
Add functional documentation in #codebase</pre>

<p>Copilot selects the <em>README.md</em> file to add the documentation to (<a data-type="xref" href="#using-codebase-to-up">Figure 4-11</a>). Of course, you might want to create a separate documentation file, but the point is that Copilot selected the best fit among the ones that were available.</p>

<figure><div id="using-codebase-to-up" class="figure"><img alt="" src="assets/lghc_0411.png" width="1359" height="753"/>
<h6><span class="label">Figure 4-11. </span>Using <code translate="no">#codebase</code> to update files</h6>
</div></figure>

<p>This is meant to show a simple use case, but you can use Copilot Edits at a much larger scale and for more complex changes. The mechanics and approach apply the same way. The more specific you can be with the files you want changed, and the more directive you can be with your prompts, the better. As with any suggestions from the AI, the results may or may not be what you expect and may or may not be correct. This is why the step of reviewing the proposed changes in the editor is so important. If you don’t get the set of changes you expect, you can try going back and tweaking the prompt to see if you can get improved suggestions.</p>

<p>While the AI edit capabilities in Copilot Edits are useful for suggesting changes in files that you select and review, sometimes we may not know which content needs to be <em>picked </em>for a change. And we may not want to do as many manual steps to get the changes in place for review. For those reasons (among others), Copilot can leverage the AI to make simple or complex changes more autonomously. This happens by using Copilot’s other mode, which uses an AI agent to handle the heavy lifting <span class="keep-together">for you</span><a contenteditable="false" data-primary="" data-startref="xi_editingCopilotEdits41094" data-type="indexterm" id="id629"/><a contenteditable="false" data-primary="" data-startref="xi_CopilotEdits41094" data-type="indexterm" id="id630"/>.</p>
</div></section>

<section data-type="sect1" class="pagebreak-before" data-pdf-bookmark="Agent Mode"><div class="sect1" id="id45">
<h1 class="less_space">Agent Mode</h1>

<p><a contenteditable="false" data-primary="autonomous workflows" data-secondary="Agent mode" data-type="indexterm" id="xi_autonomousworkflowsAgentmode42734"/><a contenteditable="false" data-primary="Agent mode" data-type="indexterm" id="xi_Agentmode42734"/> In AI terminology, an AI <em>agent</em> is software that gathers input from its environment, makes decisions, and takes actions autonomously using available<em> tools</em> to achieve specific goals. Agents use the underlying AI models as their <em>brain </em>to help translate between natural language or code and develop plans and make decisions. GitHub Copilot’s Agent mode is your own coding agent.</p>

<p>In Agent mode, Copilot takes one or more prompts as tasks to complete. It then runs in a more autonomous way by using this basic workflow for each task:</p>

<ol>
	<li>Determines the needed context and files to edit (as opposed to you having to specify them). Also, it can create new files if needed.</li>
	<li>Suggests code changes and terminal commands to complete the task. For example, Copilot might suggest or run commands to install dependencies or run tests.</li>
	<li>Checks for correctness of code edits and terminal commands output.</li>
	<li>Prompts for human review or interaction if needed.</li>
	<li>Repeats the preceding steps until it assesses that the task is completed successfully or it can go no further on its own.</li>
</ol>

<p>While it is processing, the agent is leveraging a set of tools defined by GitHub to help accomplish tasks. These tools read files, run commands in the terminal, read output, apply proposed changes, and more. The list of tools is updated as new ones become available for Agent mode to use.</p>

<div data-type="note" epub:type="note">
<h1>Identifying Context</h1>

<p>While the agent usually does a very good job of identifying the appropriate context to use or update, you can use the usual methods (<code translate="no">#file </code>chat variables, Add Context control, etc.) to also target specific files.</p>
</div>

<p>These autonomous capabilities and use of iteration to complete a task are key features. They differentiate Copilot’s Agent mode from more selective, directed approaches like Copilot Edits.</p>

<p>Let’s get an idea of how Agent mode works in practice. We’ll use the same set of files from <a data-type="xref" href="#copilot-edits">“Copilot Edits”</a> that implement the calculator functionality.</p>

<p>First, we need to switch to Agent mode. We can do that in the same way we did to get to Copilot Edits. In the text entry section of the chat panel, click the downward arrow and select Agent from the list (<a data-type="xref" href="#switch-to-agent-mode">Figure 4-12</a>).</p>

<figure><div id="switch-to-agent-mode" class="figure"><img alt="" src="assets/lghc_0412.png" width="1013" height="802"/>
<h6><span class="label">Figure 4-12. </span>Switch to Agent mode</h6>
</div></figure>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id631">
<h1>Tool Control in Agent Chat and MCP</h1>

<p>You may have noticed the icon that looks like tools in the upper left of the text entry area when you’re in Agent mode. Selecting this tool allows you to work with extensions, some built-in tools, and a Model Context Protocol (MCP) interface (<a data-type="xref" href="#opening-tool-options">Figure 4-13</a>).</p>

<figure><div id="opening-tool-options" class="figure"><img alt="" src="assets/lghc_0413.png" width="1724" height="910"/>
<h6><span class="label">Figure 4-13. </span>Opening tool options in Agent mode</h6>
</div></figure>

<p>MCP<a contenteditable="false" data-primary="MCP (Model Context Protocol) standard" data-type="indexterm" id="id632"/> is an open standard for interfacing with AI applications. It’s kind of like a USB-C port that provides a <em>universal</em> way for AI models to connect to and access external tools, data sources, and different environments. It can provide another type of extension capability for Copilot Chat.</p>

<p>Discussing MCP in depth is beyond the scope of this book, but if you’re interested in finding out more about it, check out <a href="https://oreil.ly/cZTac">the Copilot documentation</a>.</p>
</div></aside>

<p>Because Agent mode is more powerful and autonomous than Edits, we can prompt Copilot to do sets of changes that are more significant. We’ll still keep them fairly simple here to introduce the process. But in <a data-type="xref" href="#debugging-with-copilot">“Debugging with Copilot”</a>, you’ll see how to leverage Agent mode for a much more advanced task.</p>

<p>With Copilot in Agent mode, we’re going to have it make three sets of changes to our calculator code. Those changes are as follows:</p>

<ul>
	<li>Add logging to all functions in <em>calculator.py</em>.</li>
	<li>Create a CLI for the calculator application and validate that it works as expected.</li>
	<li>Generate documentation for all functions by using docstrings.</li>
</ul>

<p>As usual, we need to add the prompts to the text input area, as shown in <a data-type="xref" href="#prompts-for-changes-v2">Figure 4-14</a>.</p>

<figure><div id="prompts-for-changes-v2" class="figure"><img alt="" src="assets/lghc_0414.png" width="950" height="508"/>
<h6><span class="label">Figure 4-14. </span>Prompts for changes via Agent mode</h6>
</div></figure>

<p class="pagebreak-before">Now we are ready to submit the prompts. Notice, however, that we didn’t specify any additional context. We didn’t specify files as we did in Edits mode. In Agent mode, Copilot can autonomously figure out what tasks need to be done and what files need to be changed. Copilot can even go further, by applying code edits for review, suggesting terminal commands, and even creating new files—depending on the prompt. As you work with Agent mode and notice any problems or desired changes, you can prompt it further, and it will iterate to resolve any issues.</p>

<p>Once we submit our prompts, Copilot proceeds to analyze them and create a plan to accomplish them (<a data-type="xref" href="#agent-planning-approa2">Figure 4-15</a>).</p>

<figure><div id="agent-planning-approa2" class="figure"><img alt="" src="assets/lghc_0415.png" width="1012" height="713"/>
<h6><span class="label">Figure 4-15. </span>Agent planning an approach</h6>
</div></figure>

<p>After figuring out the plan and what needs to be changed, Copilot will apply edits <em>inline </em>with the<em> </em>existing code. As with Edit mode, after Copilot is done, the proposed changes will be shown inline in the editor. You can choose to review each one and Keep/Undo each proposed change or Keep/Undo all proposed changes at once based on the new “files changed” section in the chat area, as seen in <a data-type="xref" href="#agent-changes-made-in">Figure 4-16</a>.</p>

<figure><div id="agent-changes-made-in" class="figure"><img alt="" src="assets/lghc_0416.png" width="1309" height="861"/>
<h6><span class="label">Figure 4-16. </span>Agent changes made inline</h6>
</div></figure>

<div data-type="warning" epub:type="warning">
<h1>Time to Complete</h1>

<p>Since Agent mode is performing a large number of operations and iterating until the code is working acceptably or it can go no further, execution usually does take more time <a contenteditable="false" data-primary="time, for Agent mode" data-type="indexterm" id="id633"/>(sometimes considerably more) than operations in Edit or Ask mode.</p>
</div>

<p>Files with proposed or pending changes have a symbol (dot inside a square) in the file list and on their editor tab, if they’re open in the editor. Once you’ve reviewed the proposed changes and chosen what to keep or undo, the Keep/Undo buttons in the “files changed” area will change to a Done button. You click this to stop this round of editing.</p>

<div data-type="note" epub:type="note">
<h1>Proposed Changes Available for Execution</h1>

<p>It may not be obvious, but suggested changes that have not been reviewed yet will still be factored in when code is executed.</p>
</div>

<p class="pagebreak-before">Until you click the Done button<a contenteditable="false" data-primary="Done button" data-type="indexterm" id="id634"/>, you can change your mind and roll back the edits Copilot suggested, even if you chose to keep some or all. You can do this in a couple of ways. You can use the Undo option<a contenteditable="false" data-primary="Undo option" data-type="indexterm" id="id635"/> in the “files changed” area above the entry area. Or you can click the left-curving arrow at the top of the chat panel. Or you can hover over the top of the conversation in the chat and click the X there, as shown previously in <a data-type="xref" href="#one-of-several-option">Figure 4-10</a>.</p>

<p>The idea is that you can iterate as much as needed. Once you click the Done button, the changes will be persisted in the files.</p>

<p>One other note here is that since we told the agent we wanted it to validate that the CLI it created worked as expected, the agent suggested commands to be run in the terminal. To run each of these, it was only necessary to copy or direct them into the terminal and hit Enter. As shown in <a data-type="xref" href="#agent-driving-verific2">Figure 4-17</a>, the agent was able in most cases to validate that the output was what was expected and conclude that the CLI was working as expected. (For some reason, it could not parse the output from the <code translate="no">add</code> function, but that was working correctly, along with the others.)</p>

<figure><div id="agent-driving-verific2" class="figure"><img alt="" src="assets/lghc_0417.png" width="1068" height="846"/>
<h6><span class="label">Figure 4-17. </span>Agent driving the verification</h6>
</div></figure>

<p>This is only a quick overview and example of Copilot’s agentic AI capabilities. As you can likely already tell, this powerful feature can help in many areas of making <span class="keep-together">changes</span>—with appropriate prompts and reviews. Expect to see it becoming more ubiquitous throughout Copilot and GitHub. To further get an idea of what Copilot and its agentic AI functions are capable of, you’ll see how to use them in the next section along with another impressive feature of Copilot: parsing visual images to derive context and generate code!</p>

<div data-type="warning" epub:type="warning">
<h1>Using Agent Mode with Copilot Free</h1>

<p>If you’re relying on the Copilot Free<a contenteditable="false" data-primary="Copilot Free, using Agent mode with" data-type="indexterm" id="id636"/> plan, be aware that you have a limited number of interactions available per month, and Agent mode can use many interactions. Depending on your usage pattern, Agent mode use may consume much of your available quota.</p>
</div>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id637">
<h1>Comparing Advanced Coding Features in Copilot</h1>

<p>Since we’ve covered several options for being able to make changes, <a data-type="xref" href="#comparing-advanced-co">Table 4-1</a> can help you decide when to use a particular option<a contenteditable="false" data-startref="xi_autonomousworkflowsAgentmode42734" data-type="indexterm" id="id638"/><a contenteditable="false" data-startref="xi_Agentmode42734" data-type="indexterm" id="id639"/><a contenteditable="false" data-primary="NES (Next Edit Suggestions)" data-type="indexterm" id="id640"/><a contenteditable="false" data-primary="Copilot Edits" data-type="indexterm" id="id641"/>.</p>

<table class="border" id="comparing-advanced-co">
	<caption><span class="label">Table 4-1. </span>Comparing advanced coding features in Copilot</caption>
	<thead>
		<tr>
			<th scope="col">Feature</th>
			<th scope="col">Description</th>
			<th scope="col">When to use</th>
			<th scope="col">Example use cases</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>Next Edit Suggestions (NES)</td>
			<td>Predicts subsequent code edits after manual changes</td>
			<td>
			<ul>
				<li>Simple refactoring</li>
				<li>Editing existing code</li>
				<li>Maintaining consistency during small-scale updates</li>
			</ul>
			</td>
			<td>
			<ul>
				<li>Adding a field to a Python dataclass</li>
				<li>Fixing variable name typos</li>
				<li>Updating API endpoint URLs</li>
			</ul>
			</td>
		</tr>
		<tr>
			<td>Copilot Edits</td>
			<td>Enables multifile editing sessions through natural language prompts and iterative review</td>
			<td>
			<ul>
				<li>Coordinated changes across files</li>
				<li>Medium-scale refactoring tasks</li>
			</ul>
			</td>
			<td>
			<ul>
				<li>Renaming components in React app</li>
				<li>Updating configuration formats</li>
				<li>Adding error handling globally</li>
			</ul>
			</td>
		</tr>
		<tr>
			<td>Copilot Agent mode</td>
			<td>Autonomous AI agent that executes multistep coding tasks with self-correction</td>
			<td>
			<ul>
				<li>Complex project tasks</li>
				<li>End-to-end feature implementation</li>
				<li>First pass at issue resolution</li>
				<li>Creating additional interfaces for code</li>
			</ul>
			</td>
			<td>
			<ul>
				<li>Adding new features to existing code</li>
				<li>Creating a Flask web app from scratch</li>
				<li>Migrating JavaScript to TypeScript</li>
				<li>Taking a pass at generating fixes for issues</li>
			</ul>
			</td>
		</tr>
	</tbody>
</table>
</div></aside>
</div></section>

<section data-type="sect1" class="pagebreak-before" data-pdf-bookmark="Copilot Vision"><div class="sect1" id="id46">
<h1 class="less_space">Copilot Vision</h1>

<p><a contenteditable="false" data-primary="autonomous workflows" data-secondary="Copilot Vision" data-type="indexterm" id="xi_autonomousworkflowsCopilotVision44654"/><a contenteditable="false" data-primary="Copilot Vision" data-type="indexterm" id="xi_CopilotVision44654"/> Have you ever taken a screenshot of an issue you were running into in the IDE and sent it to a coworker because it was easier than trying to explain? Or have you ever seen an app interface and wanted to be able to create the code to implement one similar in style or appearance?</p>

<p>If so, or if you expect this might happen at some point, Copilot has visual-based functionality that can help you out. <em>Copilot Vision</em> is an advanced feature that lets you attach and work with images directly in Copilot Chat within certain IDEs. Given an image, the AI can interpret and analyze it to provide answers. But it can also generate code based on an image.</p>

<p>Images supplied to Copilot for analysis or as a basis for code can be of many types. Here are some example use cases:</p>

<ul>
	<li>Supply a screenshot or a mockup of a UI you want Copilot to emulate.</li>
    <li>Provide an architecture diagram for analysis and explanation.</li>
	<li>Provide a screenshot of an issue you’re encountering in the IDE for it to help with debugging.</li>
	<li>Provide an image with text that is difficult to read and have Copilot extract and report the text so it can be digested.</li>
	<li>Convert hand-drawn diagrams to code.</li>
	<li>Validate entity relationship diagrams against SQL.</li>
</ul>

<div data-type="warning" epub:type="warning">
<h1>Results May Vary</h1>

<p>While the various capabilities of Copilot Vision are impressive, your experience may vary depending on image quality, the model you choose, and more. As with any AI-generated results, you should always be prepared to tweak the input you give Copilot if needed and also review the response it produces.</p>
</div>

<p class="pagebreak-before">Let’s do a quick example of using Copilot Vision to tell us about an image. For this exercise, we’ll use a screenshot of a web app built with a Python library named Gradio and hosted on a platform called Hugging Face Spaces. The screenshot is shown in <a data-type="xref" href="#starting-image-for-us2">Figure 4-18</a>.</p>

<figure><div id="starting-image-for-us2" class="figure"><img alt="" src="assets/lghc_0418.png" width="894" height="432"/>
<h6><span class="label">Figure 4-18. </span>The starting image for use with Vision</h6>
</div></figure>

<p>To use Copilot Vision at the time of this writing, you must attach the image to the chat input area. But you don’t have to be in any particular mode. We’ll start out working in Ask mode. You can attach the image either by dragging the image, pasting it, or selecting it via the usual context methods.  <a data-type="xref" href="#starting-image-attach">Figure 4-19</a> shows the image attached.</p>

<figure><div id="starting-image-attach" class="figure"><img alt="" src="assets/lghc_0419.png" width="972" height="869"/>
<h6><span class="label">Figure 4-19. </span>The starting image attached to chat</h6>
</div></figure>

<p>If we then ask Copilot to “Tell me about this,” it examines the image and is able to pull a lot of details from it. <a data-type="xref" href="#initial-image-analysi2">Figure 4-20</a> shows the start of the output after Copilot’s analysis.</p>

<figure><div id="initial-image-analysi2" class="figure"><img alt="" src="assets/lghc_0420.png" width="1086" height="849"/>
<h6><span class="label">Figure 4-20. </span>Initial image analysis from Copilot</h6>
</div></figure>

<p>Here’s the full output from Copilot regarding the image:</p>

<pre data-type="programlisting" translate="no">
This is a screenshot of a **Sentiment Analysis App** hosted on
[Hugging Face Spaces](https://huggingface.co/spaces). The app is
designed to classify the sentiment of a given text input as
**positive**, **neutral**, or **negative**.

### Key Features:
1. **Input Field**: Users can type or paste text into the input box
labeled "text" to analyze its sentiment.
2. **Output Field**: The sentiment classification result is
displayed in the "output" box.
3. **Buttons**:
   - **Clear**: Clears the input field.
   - **Submit**: Processes the input text and displays the sentiment
result.
4. **Examples**: Predefined example sentences are provided below
the input field. Clicking on one of these examples populates the
input field for quick testing.
5. **Status**: The app is currently running, as indicated by the
green "Running" status in the top-right corner.

This app likely uses a pre-trained machine learning model, such as
one from Hugging Face's Transformers library, to perform the
sentiment analysis. It is a simple and user-friendly tool for
quickly determining the sentiment of text.
</pre>

<p>While this is useful, even more interesting is that Copilot can create code based on the image. If we prompt it with “Can you write the code for this?”, Copilot responds by producing a set of code for it (<a data-type="xref" href="#creating-code-from-an2">Figure 4-21</a>). Interestingly, the implementation it chose here uses Python, the Gradio library, and Hugging Face’s Transformers library for sentiment analysis. These are the same items that were used to originally create the app!</p>

<figure><div id="creating-code-from-an2" class="figure"><img alt="" src="assets/lghc_0421.png" width="1102" height="857"/>
<h6><span class="label">Figure 4-21. </span>Creating code from an image</h6>
</div></figure>

<p>Now let’s see how to incorporate Copilot Vision with Copilot’s agentic AI (via Agent mode) to make some impressive changes to the calculator files we’ve used in the other sections of this chapter.</p>

<p>As it stands right now, our calculator has a command-line interface but no visual interface. Suppose we’ve found a picture of an interface (<a data-type="xref" href="#image-of-desired-inte">Figure 4-22</a>) that we like and would like to have for our calculator.</p>

<figure class="width-40"><div id="image-of-desired-inte" class="figure"><img alt="" src="assets/lghc_0422.png" width="308" height="456"/>
<h6><span class="label">Figure 4-22. </span>The image of the desired interface</h6>
</div></figure>

<p>Let’s use that as context and see if Copilot can create a web interface for our calculator based on that image. At the same time, we also want to add a new function to do exponents. And since we’re adding the web interface, to simplify things when we’re running the app, let’s remove the CLI.</p>

<p>Our prompt then might look something like this:</p>

<pre data-type="programlisting" translate="no">
Update the calculator files in this project as follows:

- Remove the CLI interface
- Add all necessary code to implement and test a function to compute
 exponents
- Create a web interface for all calculator functions to resemble 
the pasted image
- Include any new dependencies needed
- Explain how to run and test the web interface</pre>

<p><a data-type="xref" href="#prompts-and-image-for2">Figure 4-23</a> shows the image attached and the prompts ready to go. Note that, given the level of change and complexity, we switched back to Agent mode for Copilot to accomplish this.</p>

<figure><div id="prompts-and-image-for2" class="figure"><img alt="" src="assets/lghc_0423.png" width="906" height="429"/>
<h6><span class="label">Figure 4-23. </span>Prompts and the image for calculator updates</h6>
</div></figure>

<p>After submitting the prompts, the Copilot agent will assess what needs to be done, come up with a plan, and start proposing and making changes.  <a data-type="xref" href="#agent-creating-web-in">Figure 4-24</a> shows example output where the agent is working on the needed changes to create the web app based on the image. Notice the multiple processes it’s handling, including these:</p>

<ul>
	<li>Getting Flask installed</li>
	<li>Adding web interface pieces and updating routes for all operations in the main file</li>
	<li>Creating new files where needed, such as <em>index.html</em></li>
</ul>

<figure><div id="agent-creating-web-in" class="figure"><img alt="" src="assets/lghc_0424.png" width="920" height="424"/>
<h6><span class="label">Figure 4-24. </span>Agent creating the web interface</h6>
</div></figure>

<p>Depending on the prompt and complexity, Copilot may stop and suggest code for you to use to create a new file, or it can create the file itself. Similarly, it may install dependencies and run terminal commands or suggest them and have you execute the needed commands. If you don’t see as much autonomous behavior as you were expecting, you can revise the prompt to tell/give permission to Copilot to do more up front. Examples would be telling it to create any needed files or to update <span class="keep-together">requirements</span>.</p>

<p>Sometimes Copilot may require multiple iterations with Agent mode to get the results you want. For example, if an issue or problem occurs when the generated code changes are run, you may have to go back and tell Copilot about the issue in the agent prompt and ask it to make additional changes to fix it. When first running through the examples for this chapter, the results were not being shown correctly in the web app. After going through two more iterations, Copilot found and fixed the issue.    </p>

<p>Any iteration with the Agent mode follows the same process of making a plan, updating content with suggested changes inline, and running commands. The output is the same: a set of changes that can be run to test out the code and reviewed to Keep or Undo. <a data-type="xref" href="#ready-after-iteration">Figure 4-25</a> shows an example after the agent fixed a reported issue of results not being shown initially.</p>

<figure><div id="ready-after-iteration" class="figure"><img alt="" src="assets/lghc_0425.png" width="1794" height="927"/>
<h6><span class="label">Figure 4-25. </span>Ready after iterations</h6>
</div></figure>

<p class="pagebreak-before"><a data-type="xref" href="#final-webapp2">Figure 4-26</a> shows the final result running the actual calculator code web app interface created by the Copilot agent. As you can see, it is impressively similar to the reference image it was given and works as expected. Also note that per the prompt to add a function to handle exponents, the web app interface Copilot produced has a calculator button (second from left in the first row) to do exponents (**) that was not in the original image.</p>

<figure><div id="final-webapp2" class="figure"><img alt="" src="assets/lghc_0426.png" width="392" height="513"/>
<h6><span class="label">Figure 4-26. </span>Final web app</h6>
</div></figure>

<p>Copilot Vision, along with NES and Agent mode, can certainly simplify getting code created and updated. But, of course, you need to make sure you can figure out what’s wrong when the generated code isn’t working as intended. To help when that happens, we’ll briefly discuss how Copilot can assist you with debugging<a contenteditable="false" data-primary="" data-startref="xi_autonomousworkflowsCopilotVision44654" data-type="indexterm" id="id642"/><a contenteditable="false" data-primary="" data-startref="xi_CopilotVision44654" data-type="indexterm" id="id643"/>.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Debugging with Copilot"><div class="sect1" id="debugging-with-copilot">
<h1>Debugging with Copilot</h1>

<p><a contenteditable="false" data-primary="GitHub Copilot" data-secondary="debugging with" data-type="indexterm" id="xi_GitHubCopilotdebuggingwith46014"/><a contenteditable="false" data-primary="autonomous workflows" data-secondary="debugging" data-type="indexterm" id="xi_autonomousworkflowsdebugging46014"/><a contenteditable="false" data-primary="debugging" data-type="indexterm" id="xi_debugging46014"/> We’ve previously discussed several Copilot capabilities that are useful for helping you debug problems. We’ve talked about the <code translate="no">/explain<a contenteditable="false" data-primary="/explain command" data-type="indexterm" id="id644"/></code> command to help explain code that might be having issues, and the <code translate="no">/fix<a contenteditable="false" data-primary="/fix command" data-type="indexterm" id="id645"/> </code>command to have Copilot suggest fixes for bugs. Copilot also has a few other features that can be helpful.</p>

<p class="pagebreak-before">In VS Code, Copilot can help set up and customize debug configurations. For example, you can use the <code translate="no">/startDebugging<a contenteditable="false" data-primary="/startDebugging command" data-type="indexterm" id="id646"/></code> shortcut command to create a <em>launch.json</em> file if one doesn’t exist, as shown in <a data-type="xref" href="#using-startdebugging">Figure 4-27</a>. The same could also be done via a prompt in the chat.</p>

<figure><div id="using-startdebugging" class="figure"><img alt="" src="assets/lghc_0427.png" width="816" height="796"/>
<h6><span class="label">Figure 4-27. </span>Using <code translate="no">/startDebugging</code> to generate the launch configuration</h6>
</div></figure>

<p>The same <code translate="no">/startDebugging</code> command can also be used to start a debugging session. When running the command, if a suitable launch config is not found, Copilot will generate one first. In the same conversation, Copilot will then typically include a button that you can click to start the actual debug process (<a data-type="xref" href="#debugging-session-fro">Figure 4-28</a>).</p>

<figure><div id="debugging-session-fro" class="figure"><img alt="" src="assets/lghc_0428.png" width="1504" height="691"/>
<h6><span class="label">Figure 4-28. </span>A debugging session from Copilot</h6>
</div></figure>

<p>In some IDEs, like Visual Studio, Copilot integration includes an<em> exception helper<a contenteditable="false" data-primary="exception helper" data-type="indexterm" id="id647"/></em>. This means that if an exception like <code translate="no">IndexOutOfRangeException</code> occurs during a debugging exception, a pop-up will display an Ask Copilot option. Copilot will provide an explanation of the error, a suggested code fix, and can even preview and apply the fix directly in your IDE. For more details on how to use this, see <a href="https://oreil.ly/QopeF">the <span class="keep-together">documentation</span></a>.</p>

<p>If you’re doing unit testing with Test Explorer<a contenteditable="false" data-primary="Test Explorer, in Visual Studio 2022" data-type="indexterm" id="id648"/> in Visual Studio 2022<a contenteditable="false" data-primary="Visual Studio" data-type="indexterm" id="id649"/>, you have a Debug with Copilot button available. With this feature, Copilot does the following when a test fails:</p>

<ul>
	<li>Generates a comprehensive debug plan</li>
	<li>Sets breakpoints</li>
	<li>Watches critical variables</li>
	<li>Guides you through the debugging process</li>
</ul>

<p>Along the way, Copilot analyzes values of variables at breakpoints, providing guidance and suggestions in a feedback loop.</p>

<div data-type="warning" epub:type="warning">
<h1>IDE-Specific Features</h1>

<p><a contenteditable="false" data-primary="IDEs" data-secondary="specific features of" data-type="indexterm" id="id650"/>Some features in Copilot are only available in certain IDEs. The exception helper and Debug with Copilot option in Test Explorer are only available in Visual Studio (not in other IDEs like VS Code) at the time of this writing.</p>
</div>

<p>Copilot also provides another command in some IDEs called <code translate="no">copilot-debug</code>. You can run this command from a terminal with your application to start a debug session. Here’s an example:</p>

<pre data-type="programlisting" translate="no">
copilot-debug node app.js</pre>

<div data-type="warning" epub:type="warning">
<h1>copilot-debug Issues</h1>

<p>While <code translate="no">copilot-debug<a contenteditable="false" data-primary="copilot-debug command" data-type="indexterm" id="id651"/></code> can be convenient in the terminal, it seems to get <em>stuck </em>in some cases waiting for the IDE to connect. If you encounter an issue running it, try the <code translate="no">/startDebugging<a contenteditable="false" data-primary="/startDebugging command" data-type="indexterm" id="id652"/></code> command or built-in functionality in the IDE to run a debug session.</p>
</div>

<p>Finally, you can use one other technique to debug issues that ties back in with the Copilot Vision functionality we discussed previously. You can have Copilot debug a problem from a screenshot.</p>

<p>Suppose we have a screenshot of some simple C# code (as shown in <a data-type="xref" href="#screenshot-of-c-sharp">Figure 4-29</a>) saved as the file <em>Screenshot 2025-04-28 at 12.37.05 PM.png</em>.</p>

<figure><div id="screenshot-of-c-sharp" class="figure"><img alt="" src="assets/lghc_0429.png" width="476" height="154"/>
<h6><span class="label">Figure 4-29. </span>Screenshot of C# code</h6>
</div></figure>

<p>We can attach that file to our chat dialog and then ask Copilot to help us debug any issues with it. <a data-type="xref" href="#prompt-to-debug-from">Figure 4-30</a> shows one possible prompt.</p>

<figure><div id="prompt-to-debug-from" class="figure"><img alt="" src="assets/lghc_0430.png" width="826" height="157"/>
<h6><span class="label">Figure 4-30. </span>A prompt to debug from the screenshot</h6>
</div></figure>

<p class="pagebreak-before">After processing the prompt and the screenshot, Copilot responds by detailing an unhandled exception that can result from a divide-by-zero condition and suggesting code to resolve the issue (<a data-type="xref" href="#results-of-analyzing">Figure 4-31</a>).</p>

<figure><div id="results-of-analyzing" class="figure"><img alt="" src="assets/lghc_0431.png" width="1089" height="601"/>
<h6><span class="label">Figure 4-31. </span>Results of analyzing the screenshot</h6>
</div></figure>

<p>Ultimately, whether you take advantage of any of the built-in features for debugging in Copilot, the chat interface is still one of your best tools. When you encounter an issue and aren’t sure why it happens, try asking Copilot via a query. Remember that specific queries like “Why does this API call fail for valid input?” yield better results than vague requests<a contenteditable="false" data-primary="" data-startref="xi_GitHubCopilotdebuggingwith46014" data-type="indexterm" id="id653"/><a contenteditable="false" data-primary="" data-startref="xi_autonomousworkflowsdebugging46014" data-type="indexterm" id="id654"/><a contenteditable="false" data-primary="" data-startref="xi_debugging46014" data-type="indexterm" id="id655"/>.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="id48">
<h1>Conclusion</h1>

<p>In this chapter, we’ve looked at several advanced editing and workflow functionalities, including NES, Copilot Edits, Copilot Agent mode, and Copilot Vision. If you have a limited set of changes, deciding which of the first three to use can be confusing. <a data-type="xref" href="#comparing-advanced-co">Table 4-1</a> provides some suggestions to try to clarify when to use each.</p>

<p>In terms of scope, a simple way to think about the differences is as follows:</p>

<ul class="marker:text-textOff list-disc">
	<li>
	<p>NES works at the code-edit level (single file).</p>
	</li>
	<li>
	<p>Copilot Edits operates at the project session level (multiple files).</p>
	</li>
	<li>
	<p>Agent mode functions at the system level (code + terminal + testing).</p>
	</li>
</ul>

<p>For quick inline fixes, NES provides instant suggestions. Copilot Edits is great for guided multifile changes. Agent mode handles complete development lifecycle tasks including code updates and creation, validation, and execution.</p>

<p>With all these features, Copilot provides developer control through Keep/Undo mechanisms and the ability to <em>roll back </em>changes.</p>

<p>Copilot Vision allows Copilot to extract information from images, such as screenshots of a problem, design diagrams, application interfaces, and more. With the extracted information, Copilot can answer questions about the image, do analysis, create text or code based on the image, or leverage parts of the image to solve problems or complete a task. The functionality is easy to use by simply pasting/dragging an image into the chat input area, regardless of which chat mode you’re in.</p>

<p>There’s one other key point to make about Agent mode. AI agents are growing in capabilities, utility, abilities to interact with their environment, and adaptability for handling all kinds of tasks. Expect Copilot’s agentic AI capabilities to continue to expand and grow and be used in other parts of the IDEs and Copilot interfaces. There is really no limit to what the agent component can do, given the right prompting and tools.</p>

<p>Copilot also includes tools to help with debugging, such as the shortcut <code translate="no">/startDebugging</code> command. You can even have Copilot analyze and debug from screenshots. Along with other functionality previously discussed to explain and fix problems via Copilot, these tools can help you more quickly determine the causes of issues. It’s important to note, though, that not all Copilot debug features are provided in all IDEs. Your best bet may still be asking Copilot specific <em>why</em> questions about issues in the chat interface.</p>

<p>With this solid foundation on the basic and advanced use of Copilot, we can move on to some of the targeted tasks it can help with, such as test generation, documentation, and code translation. These capabilities can be among the most valuable to reduce your time spent doing routine tasks and allowing for more focus on the interesting and fun parts of writing code. We’ll discuss how to leverage Copilot to handle these in the next few chapters, starting with using Copilot for testing in<a contenteditable="false" data-startref="xi_IDEsadvancededitingin444" data-type="indexterm" id="id656"/><a contenteditable="false" data-primary="" data-startref="xi_IDEsautonomousworkflowsin444" data-type="indexterm" id="id657"/><a contenteditable="false" data-primary="" data-startref="xi_editinginIDE444" data-type="indexterm" id="id658"/><a contenteditable="false" data-startref="xi_autonomousworkflowsinIDE444" data-type="indexterm" id="id659"/><a contenteditable="false" data-startref="xi_workflowsautonomous444" data-type="indexterm" id="id660"/> <a data-type="xref" href="ch05.html#ch05">Chapter 5</a>.</p>
</div></section>
</div></section></div></div></body></html>