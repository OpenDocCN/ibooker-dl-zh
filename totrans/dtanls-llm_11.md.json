["```py\n[Review]\nIs the sentiment positive or negative?\nAnswer (\"pos\"/\"neg\"):    \n```", "```py\nI am willing to tolerate almost anything in a Sci-Fi movie, \nbut this was almost intolerable. ...\nIs the sentiment positive or negative?\nAnswer (\"pos\"/\"neg\"):    \n```", "```py\nimport argparse\nimport openai\nimport pandas as pd\nimport time\n\nclient = openai.OpenAI()\n\ndef create_prompt(text):                         #1\n    \"\"\" Create prompt for sentiment classification.\n\n    Args:\n        text: text to classify.\n\n    Returns:\n        Prompt for text classification.\n    \"\"\"\n    task = 'Is the sentiment positive or negative?'\n    answer_format = 'Answer (\"pos\"/\"neg\")'\n    return f'{text}\\n{task}\\n{answer_format}:'\n\ndef call_llm(prompt):                              #2\n    \"\"\" Query large language model and return answer.\n\n    Args:\n        prompt: input prompt for language model.\n\n    Returns:\n        Answer by language model and total number of tokens.\n    \"\"\"\n    for nr_retries in range(1, 4):\n        try:\n             #3\n            response = client.chat.completions.create(\n                model='gpt-3.5-turbo',\n                messages=[\n                    {'role':'user', 'content':prompt}\n                    ],\n                temperature=0\n                )\n             #4\n            answer = response.choices[0].message.content\n            nr_tokens = response.usage.total_tokens\n            return answer, nr_tokens\n\n        except Exception as e:\n            print(f'Exception: {e}')\n            time.sleep(nr_retries * 2)\n\n    raise Exception('Cannot query OpenAI model!')\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser()                   #5\n    parser.add_argument('file_path', type=str, help='Path to input file')\n    args = parser.parse_args()\n\n    df = pd.read_csv(args.file_path)\n\n    nr_correct = 0\n    nr_tokens = 0\n\n    for _, row in df.iterrows():  #6\n\n        text = row['text']       #7\n        prompt = create_prompt(text)\n        label, current_tokens = call_llm(prompt)\n\n        ground_truth = row['sentiment']      #8\n        if label == ground_truth:\n            nr_correct += 1\n        nr_tokens += current_tokens\n\n        print(f'Label: {label}; Ground truth: {ground_truth}')\n\n    print(f'Number of correct labels:\\t{nr_correct}')\n    print(f'Number of tokens used   :\\t{nr_tokens}')\n```", "```py\npython basic_classifier.py reviews.csv\n```", "```py\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: pos; Ground truth: pos\nLabel: pos; Ground truth: neg  #1\nLabel: pos; Ground truth: neg\nLabel: negative; Ground truth: neg  #2\nLabel: negative; Ground truth: pos\nLabel: neg; Ground truth: neg\nNumber of correct labels:    6\nNumber of tokens used   :    2228\n```", "```py\nimport openai\nclient = openai.OpenAI()\n\nresponse = client.chat.completions.create(\n    model='gpt-3.5-turbo',\n    messages=[\n        {'role':'user', 'content':prompt}\n        ],\n    logit_bias = {981:100, 29875:100},  #1\n    temperature=0\n    )\n```", "```py\n #1\nLabel: negnegnegnegnegnegnegnegnegneg ...; Ground truth: neg\nLabel: negposnegnegnegnegnegnegnegneg ...; Ground truth: neg\nLabel: negposnegnegnegnegnegnegnegneg ...; Ground truth: neg\nLabel: negposnegposnegnegnegnegnegneg ...; Ground truth: neg\nLabel: posnegposnegposnegposnegposneg ...; Ground truth: pos\nLabel: posnegpospospospospospospospos ...; Ground truth: neg\nLabel: posnegpospospospospospospospos ...; Ground truth: neg\nLabel: negposnegposnegposnegposnegpos ...; Ground truth: neg\nLabel: negposnegposnegposnegposnegpos ...; Ground truth: pos\nLabel: negposnegposnegnegnegnegnegneg ...; Ground truth: neg\nNumber of correct labels:    0\nNumber of tokens used   :    2318  #2\n```", "```py\nresponse = client.chat.completions.create(\n    model='gpt-3.5-turbo',\n    messages=[\n        {'role':'user', 'content':prompt}\n        ],\n    logit_bias = {981:100, 29875:100},  #1\n    temperature=0, max_tokens=1\n    )\n```", "```py\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: pos; Ground truth: pos\nLabel: pos; Ground truth: neg\nLabel: pos; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: pos\nLabel: neg; Ground truth: neg\nNumber of correct labels:    7  #1\nNumber of tokens used   :    2228  #2\n```", "```py\nresponse = client.chat.completions.create(\n    model='gpt-4',\n    messages=[\n        {'role':'user', 'content':prompt}\n        ],\n    logit_bias = {981:100, 29875:100},  #1\n    temperature=0, max_tokens=1\n    )\n```", "```py\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: pos; Ground truth: pos\nLabel: pos; Ground truth: neg\nLabel: pos; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: pos; Ground truth: pos  #1\nLabel: neg; Ground truth: neg\nNumber of correct labels:    8  #2\nNumber of tokens used   :    2228  #3\n```", "```py\nIf you want to see a film starring Stan Laurel from the Laurel & Hardy \ncomedies, this is not the film for you. Stan would not begin to find the \ncharacter and rhythms of those films for another two years. If, however, \nyou want a good travesty of the Rudolph Valentino BLOOD AND SAND, which \nhad been made the previous year, this is the movie for you. All the \nstops are pulled out, both in physical comedy and on the title cards \nand if the movie is not held together by character, the plot of \nValentino's movie is used -- well sort of.\n```", "```py\n[Sample Review]\nIs the sentiment positive or negative?\nAnswer (\"pos\"/\"neg\"):[Sample Solution]\n[Review to Classify]\nIs the sentiment positive or negative?\nAnswer (\"pos\"/\"neg\"):\n```", "```py\nNow, I won't deny that when I purchased #1\nthis off eBay, I had high expectations. ...\nIs the sentiment positive or negative?  #2\nAnswer (\"pos\"/\"neg\"):neg          #3\nI am willing to tolerate almost anything            #4\nin a Sci-Fi movie, but this was almost intolerable. ...\nIs the sentiment positive or negative?              #5\nAnswer (\"pos\"/\"neg\"): \n```", "```py\ndef create_single_text_prompt(text, label):   #1\n    \"\"\" Create prompt for classifying a single text.\n\n    Args:\n        text: text to classify.\n        label: correct class label (empty if unavailable).\n\n    Returns:\n        Prompt for text classification.\n    \"\"\"\n    task = 'Is the sentiment positive or negative?'\n    answer_format = 'Answer (\"pos\"/\"neg\")'\n    return f'{text}\\n{task}\\n{answer_format}:{label}'\n\ndef create_prompt(text, samples):            #2\n    \"\"\" Generates prompt for sentiment classification.\n\n    Args:\n        text: classify this text.\n        samples: integrate these samples into prompt.\n\n    Returns:\n        Input for LLM.\n    \"\"\"\n    parts = []\n    for _, row in samples.iterrows():  #3\n        sample_text = row['text']\n        sample_label = row['sentiment']\n        prompt = create_single_text_prompt(sample_text, sample_label)\n        parts += [prompt]\n\n    prompt = create_single_text_prompt(text, \")  #4\n    parts += [prompt]\n    return '\\n'.join(parts)\n```", "```py\n[Review]\nIs the sentiment positive or negative?\nAnswer (\"pos\"/\"neg\"):[Label]\n```", "```py\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: pos; Ground truth: pos\nLabel: pos; Ground truth: neg\nLabel: pos; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: pos; Ground truth: pos\nLabel: neg; Ground truth: neg\nNumber of correct labels:    8  #1\nNumber of tokens used   :    4078  #2\n```", "```py\nimport argparse\nimport openai\nimport pandas as pd\nimport time\n\nclient = openai.OpenAI()\n\ndef create_single_text_prompt(text, label):\n    \"\"\" Create prompt for classifying a single text.\n\n    Args:\n        text: text to classify.\n        label: correct class label (empty if unavailable).\n\n    Returns:\n        Prompt for text classification.\n    \"\"\"\n    task = 'Is the sentiment positive or negative?'\n    answer_format = 'Answer (\"pos\"/\"neg\")'\n    return f'{text}\\n{task}\\n{answer_format}:{label}'\n\ndef create_prompt(text, samples):             #1\n    \"\"\" Generates prompt for sentiment classification.\n\n    Args:\n        text: classify this text.\n        samples: integrate these samples into prompt.\n\n    Returns:\n        Input for LLM.\n    \"\"\"\n    parts = []\n    for _, row in samples.iterrows():\n        sample_text = row['text']\n        sample_label = row['sentiment']\n        prompt = create_single_text_prompt(sample_text, sample_label)\n        parts += [prompt]\n\n    prompt = create_single_text_prompt(text, \")\n    parts += [prompt]\n    return '\\n'.join(parts)\n #2\ndef call_llm(prompt, model, max_tokens, out_tokens):\n    \"\"\" Query large language model and return answer.\n\n    Args:\n        prompt: input prompt for language model.\n        model: name of OpenAI model to choose.\n        max_tokens: maximum output length in tokens.\n        out_tokens: prioritize these token IDs in output.\n\n    Returns:\n        Answer by language model and total number of tokens.\n    \"\"\"\n    optional_parameters = {}\n    if max_tokens:\n        optional_parameters['max_tokens'] = max_tokens\n    if out_tokens:\n        logit_bias = {int(tid):100 for tid in out_tokens.split(',')}\n        optional_parameters['logit_bias'] = logit_bias\n\n    for nr_retries in range(1, 4):\n        try:\n            response = client.chat.completions.create(\n                model=model,\n                messages=[\n                    {'role':'user', 'content':prompt}\n                    ],\n                **optional_parameters, temperature=0\n                )\n\n            answer = response.choices[0].message.content\n            nr_tokens = response.usage.total_tokens\n            return answer, nr_tokens\n\n        except Exception as e:\n            print(f'Exception: {e}')\n            time.sleep(nr_retries * 2)\n\n    raise Exception('Cannot query OpenAI model!')\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser()       #3\n    parser.add_argument('file_path', type=str, help='Path to input file')\n    parser.add_argument('model', type=str, help='Name of OpenAI model')\n    parser.add_argument('max_tokens', type=int, help='Maximum output size')\n    parser.add_argument('out_tokens', type=str, help='Tokens to prioritize')\n    parser.add_argument('nr_samples', type=int, help='Number of samples')\n    parser.add_argument('sample_path', type=str, help='Path to samples')\n    args = parser.parse_args()\n\n    df = pd.read_csv(args.file_path)\n\n    samples = pd.DataFrame()  #4\n    if args.nr_samples:\n        samples = pd.read_csv(args.sample_path)\n        samples = samples[:args.nr_samples]\n\n    nr_correct = 0\n    nr_tokens = 0\n\n    for _, row in df.iterrows():\n\n        text = row['text']   #5\n        prompt = create_prompt(text, samples)\n        label, current_tokens = call_llm(\n            prompt, args.model, \n            args.max_tokens, \n            args.out_tokens)\n\n        ground_truth = row['sentiment']  #6\n        if label == ground_truth:\n            nr_correct += 1\n        nr_tokens += current_tokens\n\n        print(f'Label: {label}; Ground truth: {ground_truth}')\n\n         #7\n    print(f'Number of correct labels:\\t{nr_correct}')\n    print(f'Number of tokens used   :\\t{nr_tokens}')\n```", "```py\npython tunable_classifier.py reviews.csv\n    gpt-3.5-turbo 0 \"\" 0 \"\"\n```", "```py\npython tunable_classifier.py reviews.csv\n    gpt-3.5-turbo 1 \"981,29875\" 0 \"\"\n```", "```py\npython tunable_classifier.py reviews.csv\n    gpt-3.5-turbo 1 \"981,29875\" 1 \"train_reviews.csv\"\n```", "```py\nNow, I won't deny that when I purchased #1\nthis off eBay, I had high expectations. ...\nIs the sentiment positive or negative?  #2\nAnswer (\"pos\"/\"neg\"):neg          #3\nI am willing to tolerate almost anything            #4\nin a Sci-Fi movie, but this was almost intolerable. ...\nIs the sentiment positive or negative?              #5\nAnswer (\"pos\"/\"neg\"): \n```", "```py\nI am willing to tolerate almost anything\nin a Sci-Fi movie, but this was almost intolerable. ...\n```", "```py\n{'messages':[\n    {'role':'user', 'content':'I am willing to tolerate almost anything \n    â†ª ...'},\n    {'role':'assistant', 'content':'neg'}\n]}\n```", "```py\npip install jsonlines==4.0\n```", "```py\nimport argparse\nimport jsonlines\nimport pandas\n\ndef get_samples(df):                    #1\n    \"\"\" Generate samples from a data frame.\n\n    Args:\n        df: data frame containing samples.\n\n    Returns:\n        List of samples in OpenAI format for fine-tuning.\n    \"\"\"\n    samples = []\n    for _, row in df.iterrows():\n         #2\n        text = row['text']\n        user_message = {'role':'user', 'content':text}\n         #3\n        label = row['sentiment']\n        assistant_message = {'role':'assistant', 'content':label}\n\n        sample = {'messages':[user_message, assistant_message]}\n        samples += [sample]\n\n    return samples\n\nif __name__ == '__main__':\n    #4\n    parser = argparse.ArgumentParser()\n    parser.add_argument('in_path', type=str, help='Path to input')\n    parser.add_argument('out_path', type=str, help='Path to output')\n    args = parser.parse_args()\n\n    df = pandas.read_csv(args.in_path)\n    samples = get_samples(df)    \n     #5\n    with jsonlines.open(args.out_path, 'w') as file:\n        for sample in samples:\n            file.write(sample)\n```", "```py\npython prep_fine_tuning.py   train_reviews.csv train_reviews.jsonl\n```", "```py\nimport openai\nclient = openai.OpenAI()\n\nreply = client.files.create(\n    file=open(in_path, 'rb'), purpose='fine-tune')\n```", "```py\nreply = client.fine_tuning.jobs.retrieve(job_id)\n```", "```py\nimport argparse\nimport openai\nimport time\n\nclient = openai.OpenAI()\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('in_path', type=str, help='Path to input file')\n    args = parser.parse_args()\n\n    reply = client.files.create(              #1\n        file=open(args.in_path, 'rb'), purpose='fine-tune')\n    file_id = reply.id\n\n    reply = client.fine_tuning.jobs.create(       #2\n        training_file=file_id, model='gpt-3.5-turbo')\n    job_id = reply.id\n    print(f'Job ID: {job_id}')\n\n    status = None\n    start_s = time.time()\n\n    while not (status == 'succeeded'):  #3\n\n        time.sleep(5)\n        total_s = time.time() - start_s\n        print(f'Fine-tuning since {total_s} seconds.')\n         #4\n        reply = client.fine_tuning.jobs.retrieve(job_id) \n        status = reply.status\n        print(f'Status: {status}')\n    #5\n    print(f'Fine-tuning is finished!')\n    model_id = reply.fine_tuned_model\n    print(f'Model ID: {model_id}')\n```", "```py\npython fine_tune.py train_reviews.jsonl\n```", "```py\nJob ID: ...\nFine-tuning since 5.00495171546936 seconds.\nStatus: validating_files\n...\nFine-tuning since 46.79299879074097 seconds.\nStatus: running\n...\nFine-tuning since 834.6565797328949 seconds.\nStatus: succeeded\nFine-tuning is finished!\nModel ID: ft:gpt-3.5-turbo-0613...\n```", "```py\nimport argparse\nimport openai\n\nclient = openai.OpenAI()\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('job_id', type=str, help='ID of fine-tuning job')\n    args = parser.parse_args()\n     #1\n    job_info = client.fine_tuning.jobs.retrieve(args.job_id)\n    print(job_info)\n```", "```py\nimport openai\nclient = openai.OpenAI()\n\nresponse = client.chat.completions.create(\n    model='[Fine-tuned model ID]',\n    messages=[\n        {'role':'user', 'content':prompt}\n        ]\n    )\n```", "```py\ndef create_prompt(text):\n    \"\"\" Create prompt for sentiment classification.\n\n    Args:\n        text: text to classify.\n\n    Returns:\n        Prompt for text classification.\n    \"\"\"\n    return text\n```", "```py\nLabel: I understand your concern about smoking in movies, \nespecially those intended for children and adolescents. \nSmoking in films can have an influence on young viewers \nand potentially normalize the behavior. However, it is \nimportant to note that not all instances of smoking in \nmovies are the result of intentional product placement \nor sponsorship by tobacco companies.\n...\n```", "```py\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: pos; Ground truth: pos\nLabel: pos; Ground truth: neg\nLabel: pos; Ground truth: neg\nLabel: neg; Ground truth: neg\nLabel: neg; Ground truth: pos\nLabel: neg; Ground truth: neg\nNumber of correct labels:    7  #1\nNumber of tokens used   :    2085  #2\n```"]