- en: Chapter 14\. Designing Your Own TinyML Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第14章。设计你自己的TinyML应用程序
- en: So far, we’ve explored existing reference applications for important areas like
    audio, image, and gesture recognition. If your problem is similar to one of the
    examples, you should be able to adapt the training and deployment process—but
    what if it isn’t obvious how to modify one of our examples to fit? In this and
    the following chapters, we cover the process of building an embedded machine learning
    solution for a problem for which you don’t have an easy starting point. Your experience
    with the examples will serve as a good foundation for creating your own systems,
    but you also need to learn more about designing, training, and deploying new models.
    Because the constraints of our platforms are so tight, we also spend a lot of
    time discussing how you can make the right optimizations to fit within your storage
    and computational budgets without missing your accuracy targets. You’ll undoubtedly
    spend a lot of your time trying to understand why things aren’t working, so we
    cover a variety of debugging techniques. Finally, we explore how you can build
    in safeguards for your users’ privacy and security.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探讨了重要领域如音频、图像和手势识别的现有参考应用。如果你的问题类似于其中一个示例，你应该能够调整训练和部署过程，但如果不明显如何修改我们的示例以适应呢？在本章和接下来的章节中，我们将介绍为一个没有易于起点的问题构建嵌入式机器学习解决方案的过程。你对示例的经验将为创建自己的系统奠定良好基础，但你还需要了解更多关于设计、训练和部署新模型的知识。由于我们平台的约束非常严格，我们还花了很多时间讨论如何进行正确的优化，以适应存储和计算预算，同时不会错过准确性目标。你肯定会花费大量时间尝试理解为什么事情不起作用，因此我们涵盖了各种调试技术。最后，我们探讨了如何为用户的隐私和安全建立保障措施。
- en: The Design Process
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计过程
- en: Training models can take days or weeks, and bringing up a new embedded hardware
    platform can also be very time-consuming—so one of the biggest risks to any embedded
    machine learning project is running out of time before you have something working.
    The most effective way to reduce this risk is by answering as many of the outstanding
    questions as early in the process as possible, through planning, research, and
    experimentation. Each change to your training data or architecture can easily
    involve a week of coding and retraining, and deployment hardware changes have
    a ripple effect throughout your software stack, involving a lot of rewriting of
    previously working code. Anything you can do at the outset to reduce the number
    of changes required later in the development process can save you the time you
    would have spent making those changes. This chapter focuses on some of the techniques
    we recommend for answering important questions before you start coding the final
    application.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型可能需要几天或几周的时间，引入新的嵌入式硬件平台也可能非常耗时——因此，任何嵌入式机器学习项目最大的风险之一是在你有可用的东西之前时间耗尽。减少这种风险的最有效方法是尽早回答尽可能多的未解决问题，通过规划、研究和实验。对训练数据或架构的每次更改很容易涉及一周的编码和重新训练，部署硬件更改会在整个软件堆栈中产生连锁反应，需要大量重写先前有效的代码。你可以在开始时做的任何事情，以减少后续开发过程中所需更改的数量，可以节省你本来会花在这些更改上的时间。本章重点介绍了我们建议用于在编写最终应用程序之前回答重要问题的一些技术。
- en: Do You Need a Microcontroller, or Would a Larger Device Work?
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你需要微控制器，还是更大的设备可以工作？
- en: The first question you really need to answer is whether you need the advantages
    of an embedded system or can relax your requirements for battery life, cost, and
    size, at least for an initial prototype. Programming on a system with a complete
    modern OS like Linux is a lot easier (and faster) than developing in the embedded
    world. You can get complete desktop-level systems like a Raspberry Pi for under
    $25, along with a lot of peripherals like cameras and other sensors. If you need
    to run compute-heavy neural networks, NVIDIA’s Jetson series of boards start at
    $99 and bring a strong software stack in a small form factor. The biggest downsides
    to these devices are that they will burn several watts, giving them battery-powered
    lifetimes on the order of hours or days at most, depending on the physical size
    of the energy storage. As long as latency isn’t a hard constraint, you can even
    fire up as many powerful cloud servers as you need to handle the neural network
    workload, leaving the client device to handle the interface and network communications.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你真正需要回答的第一个问题是，你是否需要嵌入式系统的优势，或者至少对电池寿命、成本和尺寸的要求可以放松，至少对于一个初始原型来说。在具有完整现代操作系统（如Linux）的系统上编程比在嵌入式世界中开发要容易得多（也更快）。你可以以低于25美元的价格获得像树莓派这样的完整桌面级系统，以及许多外围设备，如摄像头和其他传感器。如果你需要运行计算密集型的神经网络，NVIDIA的Jetson系列板卡起价为99美元，并带来了强大的软件堆栈，体积小。这些设备的最大缺点是它们会消耗几瓦的电力，使它们的电池寿命在几小时或几天左右，具体取决于能量存储的物理尺寸。只要延迟不是一个硬性约束，你甚至可以启动尽可能多的强大云服务器来处理神经网络工作负载，让客户端设备处理界面和网络通信。
- en: We’re strong believers in the power of being able to deploy anywhere, but if
    you’re trying to determine whether an idea will work at all, we highly recommend
    trying to prototype using a device that is easy and quick to experiment with.
    Developing embedded systems is a massive pain in the behind, so the more you can
    tease out the real requirements of your application before you dive in, the more
    chance you have of being successful.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们坚信能够在任何地方部署的力量，但如果你试图确定一个想法是否有效，我们强烈建议尝试使用一个易于快速实验的设备进行原型设计。开发嵌入式系统非常痛苦，所以在深入之前尽可能梳理出应用程序的真正需求，你成功的机会就越大。
- en: Picking a practical example, imagine that you want to build a device to help
    monitor the health of sheep. The final product will need to be able to run for
    weeks or months in an environment without good connectivity, so it must be an
    embedded system. When you’re getting underway, however, you don’t want to use
    such a tricky-to-program device, because you won’t yet know crucial details like
    what models you want to run, which sensors are required, or what actions you need
    to take based on the data you gather, and you won’t yet have any training data.
    To bootstrap your work, you’ll probably want to find a friendly farmer with a
    small flock of sheep that graze somewhere accessible. You could put together a
    Raspberry Pi platform that you remove from each monitored sheep every night yourself
    to recharge, and set up an outdoor WiFi network that covers the range of the grazing
    field so that the devices can easily communicate with a network. Obviously you
    can’t expect real customers to go to this sort of trouble, but you’ll be able
    to answer a lot of questions about what you need to build with this setup, and
    experimenting with new models, sensors, and form factors will be much faster than
    in an embedded version.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 举个实际的例子，想象一下你想要建造一个设备来帮助监测羊的健康。最终产品需要能够在没有良好连接的环境中运行数周甚至数月，因此必须是嵌入式系统。然而，在开始时，你不想使用这种难以编程的设备，因为你还不知道关键细节，比如你想要运行哪些模型，需要哪些传感器，或者根据你收集的数据需要采取什么行动，而且你还没有任何训练数据。为了启动你的工作，你可能会想找一个友好的农民，他们有一小群在易于接近的地方放牧的羊。你可以组装一个树莓派平台，每晚从每只被监测的羊身上取下来自己充电，然后建立一个覆盖放牧区域范围的室外WiFi网络，这样设备就可以轻松地与网络通信。显然，你不能指望真正的客户去做这种麻烦的事情，但通过这种设置，你将能够回答许多关于你需要构建什么的问题，尝试新的模型、传感器和形态因素将比嵌入式版本快得多。
- en: Microcontrollers are useful because they scale up in a way no other hardware
    can. They are cheap, small, and able to run on almost no energy, but these advantages
    only kick in when you actually need to scale. If you can, put off dealing with
    scaling until you absolutely must so that you can be confident that you’re scaling
    the right thing.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 微控制器很有用，因为它们可以按照其他硬件无法做到的方式进行扩展。它们便宜、小巧，几乎不需要能量，但这些优势只有在实际需要扩展时才会发挥作用。如果可以的话，推迟处理扩展的问题，直到绝对必要，这样你就可以确信你正在扩展正确的东西。
- en: Understanding What’s Possible
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解可能性
- en: It’s difficult to know what problems deep learning is able to solve. One rule
    of thumb we’ve found very useful is that neural network models are great at the
    kind of tasks that people can solve “in the blink of an eye.” We intuitively seem
    able to recognize objects, sounds, words, and friends in a comparative instant,
    and these are the same kinds of tasks that neural networks can perform. Similarly,
    DeepMind’s Go-solving algorithm relies on a convolutional neural network that’s
    able to look at a board and return an estimate of how strong a position each player
    is in. The longer-term planning parts of that system are then built up using those
    foundational components.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 很难知道深度学习能够解决什么问题。我们发现一个非常有用的经验法则是，神经网络模型擅长处理人们可以“眨眼间”解决的任务。我们直觉上似乎能够瞬间识别物体、声音、单词和朋友，而这些正是神经网络可以执行的任务。同样，DeepMind的围棋解决算法依赖于一个卷积神经网络，它能够查看棋盘并返回每个玩家处于多强势位置的估计。然后，该系统的长期规划部分是基于这些基础组件构建的。
- en: This is a useful distinction because it draws a line between different kinds
    of “intelligence.” Neural networks are not automatically capable of planning or
    higher-level tasks like theorem solving. They’re much better at taking in large
    amounts of noisy and confusing data, and spotting patterns robustly. For example,
    a neural network might not be a good solution for guiding a sheepdog in how to
    herd a flock through a gate, but it could well be the best approach for taking
    in a variety of sensor data like body temperature, pulse, and accelerometer readings
    to predict whether a sheep is feeling unwell. The sorts of judgments that we’re
    able to perform almost unconsciously are more likely to be covered by deep learning
    than problems that require explicit thinking this doesn’t mean that those more
    abstract problems can’t be helped by neural networks, just that they’re usually
    only a component of a larger system that uses their “instinctual” predictions
    as inputs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有用的区分，因为它在不同种类的“智能”之间划定了界限。神经网络并不自动具备规划或像定理证明这样的高级任务的能力。它们更擅长接收大量嘈杂和混乱的数据，并稳健地发现模式。例如，神经网络可能不是指导牧羊犬如何引导羊群穿过大门的好解决方案，但它很可能是利用各种传感器数据（如体温、脉搏和加速度计读数）来预测羊羊是否感到不适的最佳方法。我们几乎无意识地执行的判断更有可能被深度学习覆盖，而不是需要明确思考的问题。这并不意味着那些更抽象的问题不能通过神经网络得到帮助，只是它们通常只是一个更大系统的组成部分，该系统使用它们的“本能”预测作为输入。
- en: Follow in Someone Else’s Footsteps
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟随他人的脚步
- en: In the research world, “reviewing the literature” is the rather grand name for
    reading research papers and other publications related to a problem you’re interested
    in. Even if you’re not a researcher this can be a useful process when dealing
    with deep learning because there are a lot of useful accounts of attempts to apply
    neural network models to all sorts of challenges, and you’ll save a lot of time
    if you can get some hints on how to get started from the work of others. Understanding
    research papers can be challenging, but the most useful things to glean are what
    kinds of models people use for problems similar to yours and whether there are
    any existing datasets you can use, given that gathering data is one of the most
    difficult parts of the machine learning process.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究领域，“文献回顾”是一个相对宏大的名字，用于指阅读与你感兴趣的问题相关的研究论文和其他出版物。即使你不是研究人员，当涉及深度学习时，这也是一个有用的过程，因为有很多有用的关于尝试将神经网络模型应用于各种挑战的账户，如果你能从他人的工作中获得一些启示，你将节省很多时间。理解研究论文可能是具有挑战性的，但最有用的是了解人们在类似问题上使用了什么样的模型，以及是否有任何现有的数据集可以使用，考虑到收集数据是机器学习过程中最困难的部分之一。
- en: 'For example, if you were interested in predictive maintenance on mechanical
    bearings, you might search for [“deep learning predictive maintenance bearings”
    on arxiv.org](https://oreil.ly/xljQN), which is the most popular online host for
    machine learning research papers. The top result as of this writing is a survey
    paper from 2019, [“Machine Learning and Deep Learning Algorithms for Bearing Fault
    Diagnostics: A Comprehensive Review”](https://oreil.ly/-dqy7) by Shen Zhang et
    al. From this, you’ll learn that there’s a standard public dataset of labeled
    bearing sensor data called the [Case Western Reserve University bearing dataset](https://oreil.ly/q2_79).
    Having an existing dataset is extremely helpful because it will assist you in
    experimenting with approaches even before you have gathered readings from your
    own setup. There’s also a good overview of the different kinds of model architectures
    that have been used on the problem, along with discussions of their benefits,
    costs, and the overall results they achieve.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你对机械轴承的预测性维护感兴趣，你可以在arxiv.org上搜索[“深度学习预测性维护轴承”](https://oreil.ly/xljQN)，这是机器学习研究论文最受欢迎的在线主机。截至本文撰写时，排名第一的结果是来自2019年的一篇综述论文，[“用于轴承故障诊断的机器学习和深度学习算法：综合回顾”](https://oreil.ly/-dqy7)由Shen
    Zhang等人撰写。从中，你将了解到有一个名为[Case Western Reserve University轴承数据集](https://oreil.ly/q2_79)的标记轴承传感器数据的标准公共数据集。拥有现有的数据集非常有帮助，因为它将帮助你在甚至还没有从自己的设置中收集读数之前就进行实验。还有对已经用于该问题的不同模型架构的很好概述，以及对它们的优势、成本和整体结果的讨论。
- en: Find Some Similar Models to Train
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找一些类似的模型进行训练
- en: After you have some ideas about model architectures and training data to use,
    it’s worth spending some time in a training environment experimenting to see what
    results you can achieve with no resource constraints. This book focuses on TensorFlow,
    so we’d recommend that you find an example TensorFlow tutorial or script (depending
    on your level of experience), get it running as is, and then begin to adapt it
    to your problem. If you can, look at the training examples in this book for inspiration
    because they also include all of the steps needed to deploy to an embedded platform.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在你对模型架构和训练数据有了一些想法之后，值得花一些时间在训练环境中进行实验，看看在没有资源限制的情况下你能够取得什么样的结果。本书专注于TensorFlow，因此我们建议你找到一个示例TensorFlow教程或脚本（取决于你的经验水平），将其运行起来，然后开始适应你的问题。如果可能的话，可以参考本书中的训练示例，因为它们还包括部署到嵌入式平台所需的所有步骤。
- en: A good way to think about what models might work is looking at the characteristics
    of your sensor data and trying to match them to something similar in the tutorials.
    For example, if you have single-channel vibration data from a wheel bearing, that’s
    going to be a comparatively high-frequency time series, which has a lot in common
    with audio data from a microphone. As a starting point, you could try converting
    all of your bearing data into *.wav* format and then feed it into the [speech
    training process](https://oreil.ly/dG9gQ) instead of the standard Speech Commands
    dataset, with the appropriate labels. You’d probably then want to customize the
    process a lot more, but hopefully you’d at least get a model that was somewhat
    predictive and be able to use that as a baseline for further experiments. A similar
    process could apply to adapting the gesture tutorial to any accelerometer-based
    classification problem, or retraining the person detector for different machine
    vision applications. If there isn’t an obvious example to start with in this book,
    searching for tutorials that show how to build the model architecture you’re interested
    in using Keras is a good way to get started.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一个思考哪种模型可能有效的好方法是查看传感器数据的特征，并尝试将其与教程中的类似内容进行匹配。例如，如果你有来自轮轴承的单通道振动数据，那将是一个相对高频的时间序列，与麦克风的音频数据有很多共同之处。作为一个起点，你可以尝试将所有轴承数据转换为*.wav*格式，然后将其输入到[语音训练过程](https://oreil.ly/dG9gQ)中，而不是标准的语音命令数据集，带有适当的标签。然后你可能需要更多地定制这个过程，但希望至少能得到一个有些预测性的模型，并将其用作进一步实验的基准。类似的过程也适用于将手势教程适应到任何基于加速度计的分类问题，或者为不同的机器视觉应用重新训练人员检测器。如果在本书中没有明显的示例可供参考，那么搜索展示如何使用Keras构建你感兴趣的模型架构的教程是一个很好的开始。
- en: Look at the Data
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看数据
- en: Most of the focus of machine learning research is on designing new architectures;
    there’s not much coverage of training datasets. This is because in the academic
    world you’re usually given a pregenerated training dataset that is fixed, and
    you’re competing on how well your model can score on it compared to others. Outside
    of research we usually don’t have an existing dataset for our problem, and what
    we care about is the experience we deliver to the end user, not the score on a
    fixed dataset, so our priorities become very different.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分机器学习研究的重点是设计新的架构；对于训练数据集的覆盖并不多。这是因为在学术界，通常会给你一个固定的预生成训练数据集，你的竞争重点是你的模型在这个数据集上的得分如何与其他人相比。在研究之外，我们通常没有现成的数据集来解决问题，我们关心的是我们为最终用户提供的体验，而不是在一个固定数据集上的得分，因此我们的优先事项变得非常不同。
- en: One of the authors has written a [blog post](https://oreil.ly/ghEbc) that covers
    this in more detail, but the summary is that you should expect to spend much more
    time gathering, exploring, labeling, and improving your data than you do on your
    model architecture. The return on the time you invest will be much higher.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一位作者写了一篇[博客文章](https://oreil.ly/ghEbc)更详细地介绍了这一点，但总结是你应该期望花费更多的时间收集、探索、标记和改进你的数据，而不是在模型架构上。你投入的时间回报会更高。
- en: 'There are some common techniques that we’ve found to be very useful when working
    with data. One that sounds extremely obvious but that we still often forget is:
    look at your data! If you have images, download them into folders arranged by
    label on your local machine and browse through them. If you’re working with audio
    files, do the same and listen to a selection of them. You’ll quickly discover
    all sorts of oddities and mistakes that you didn’t expect, from Jaguar cars labeled
    as jaguar cats to recordings in which the audio is too faint or has been cropped
    and cuts off part of a word. Even if you just have numerical data, looking through
    the numbers in a comma-separated values (CSV) text file can be extremely helpful.
    In the past we’ve spotted problems like many of the values reaching the saturation
    limits of sensors and maxing out, or even wrapping around, or the sensitivity
    being too low so that most of the data is crammed into too small a numerical range.
    You can get much more advanced in your data analysis, and you’ll find tools like
    TensorBoard extremely helpful for clustering and other visualizations of what’s
    happening in your dataset.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数据时，我们发现一些常见的技术非常有用。其中一个听起来非常明显但我们经常忘记的技巧是：查看你的数据！如果你有图像，将它们下载到按标签排列的文件夹中，并在本地机器上浏览它们。如果你在处理音频文件，也是同样的操作，并且听一些音频文件的选段。你会很快发现各种你没有预料到的奇怪和错误，比如标记为美洲豹的汽车被标记为美洲豹猫，或者录音中声音太微弱或被裁剪导致部分单词被切断。即使你只有数值数据，查看逗号分隔值（CSV）文本文件中的数字也会非常有帮助。过去我们发现了一些问题，比如许多数值达到传感器的饱和限制并达到最大值，甚至超出，或者灵敏度太低导致大部分数据被挤压到一个过小的数值范围内。你可以在数据分析中更加深入，你会发现像TensorBoard这样的工具对于聚类和其他数据集中发生的可视化非常有帮助。
- en: Another problem to watch out for is an unbalanced training set. If you are classifying
    into categories, the frequency at which different classes occur in your training
    inputs will affect the eventual prediction probabilities. One trap that’s easy
    to fall into is thinking that the results from your network represent true probabilities—for
    example, a 0.5 score for “yes” meaning that the network is predicting there’s
    a 50% chance the spoken word was “yes.” In fact the relationship is a lot more
    complex, given that the ratio of each class in the training data will control
    the output values, but the prior probability of each class in the application’s
    real input distribution is needed to understand the real probability. As another
    example, imagine training a bird image classifier on 10 different species. If
    you then deployed that in the Antarctic, you’d be very suspicious of a result
    that indicated you’d seen a parrot; if you were looking at video from the Amazon,
    a penguin would be equally surprising. It can be challenging to bake this kind
    of domain knowledge into the training process because you typically want roughly
    equal numbers of samples for each class so the network “pays attention” equally
    to each. Instead, there’s typically a calibration process that occurs after the
    model inference has been run, to weight the results based on prior knowledge.
    In the Antarctic example, you might have a very high threshold before you report
    a parrot, but a much lower one for penguins.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个要注意的问题是训练集不平衡。如果你正在对类别进行分类，不同类别在训练输入中出现的频率将影响最终的预测概率。一个容易陷入的陷阱是认为网络的结果代表真实概率——例如，“是”得分为0.5意味着网络预测说话的单词是“是”的概率为50%。事实上，这种关系更加复杂，因为训练数据中每个类别的比例将控制输出值，但应用程序真实输入分布中每个类别的先验概率是需要了解真实概率的。举个例子，想象一下在10种不同物种的鸟类图像分类器上进行训练。如果你将其部署在南极，看到一个指示你看到了鹦鹉的结果会让你非常怀疑；如果你在亚马逊看视频，看到企鹅同样会让你感到惊讶。将这种领域知识融入训练过程可能是具有挑战性的，因为你通常希望每个类别的样本数量大致相等，这样网络才能平等“关注”每个类别。相反，通常在模型推断运行后会进行一个校准过程，根据先验知识对结果进行加权。在南极的例子中，你可能需要一个非常高的阈值才能报告一只鹦鹉，但对企鹅的阈值可能要低得多。
- en: Wizard of Oz-ing
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奥兹巫师
- en: One of our favorite machine learning design techniques doesn’t involve much
    technology at all. The most difficult problem in engineering is determining what
    the requirements are, and it’s very easy to spend a lot of time and resources
    on something that doesn’t actually work well in practice for a problem, especially
    because the process of developing a machine learning model takes a long time.
    To flush out the requirements, we highly recommend the [Wizard of Oz approach](https://oreil.ly/Omr6N).
    In this scenario, you create a mock-up of the system you eventually want to build,
    but instead of having software do the decision making, you have a person as “the
    man behind the curtain.” This lets you test your assumptions before you go through
    a time-consuming development cycle to make sure you have the specifications well
    tested before you bake them into your design.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最喜欢的机器学习设计技术之一实际上并不涉及太多技术。工程中最困难的问题是确定需求是什么，很容易花费大量时间和资源在实际上对于一个问题并不起作用的东西上，特别是因为开发一个机器学习模型的过程需要很长时间。为了澄清需求，我们强烈推荐[绿野仙踪方法](https://oreil.ly/Omr6N)。在这种情况下，你创建一个系统的模拟，但是不是让软件做决策，而是让一个人作为“幕后之人”。这让你在经历耗时的开发周期之前测试你的假设，以确保在将它们融入设计之前对规格进行了充分测试。
- en: How does this work in practice? Imagine that you’re designing a sensor that
    will detect when people are present in a meeting room, and if there’s no one in
    the room, it will dim the lights. Instead of building and deploying a wireless
    microcontroller running a person detection model, with the Wizard of Oz approach
    you’d create a prototype that just fed live video to a person sitting in a nearby
    room with a switch that controlled the lights and instructions to dim them when
    nobody was visible. You’d quickly discover usability issues, like if the camera
    doesn’t cover the entire room and so the lights keep getting turned off when somebody’s
    still present, or if there’s an unacceptable delay in turning them on when someone
    enters the room. You can apply this approach to almost any problem, and it will
    give you precious validation of the assumptions you’re making about your product,
    without you spending time and energy on a machine learning model based on the
    wrong foundations. Even better, you can set up this process so that you generate
    labeled data for your training set from it, given that you’ll have the input data
    along with the decisions that your Wizard made based on those inputs.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这在实践中是如何运作的呢？想象一下，你正在设计一个传感器，用于检测会议室内是否有人，如果没有人在房间里，它会调暗灯光。与构建和部署运行人员检测模型的无线微控制器不同，采用绿野仙踪方法，你会创建一个原型，只需将实时视频传送给一个坐在附近房间里的人，他手里有一个控制灯光的开关，并有指示在没有人可见时将其调暗。你很快会发现可用性问题，比如如果摄像头没有覆盖整个房间，灯光会在有人仍然在场时不断关闭，或者当有人进入房间时打开灯光存在不可接受的延迟。你可以将这种方法应用于几乎任何问题，它将为你提供关于产品的假设的宝贵验证，而不需要你花费时间和精力在基于错误基础的机器学习模型上。更好的是，你可以设置这个过程，以便从中生成用于训练集的标记数据，因为你将拥有输入数据以及你的绿野仙踪根据这些输入所做的决定。
- en: Get It Working on the Desktop First
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 首先在桌面上让它运行起来
- en: The Wizard of Oz approach is one way to get a prototype running as quickly as
    possible, but even after you’ve moved on to model training you should be thinking
    about how to experiment and iterate as quickly as you can. Exporting a model and
    getting that model running fast enough on an embedded platform can take a long
    time, so a great shortcut is to stream data from a sensor in the environment to
    a nearby desktop or cloud machine for processing. This will probably use too much
    energy to be a deployable solution in production, but as long as you can ensure
    the latency doesn’t affect the overall experience, it’s a great way to get feedback
    on how well your machine learning solution works in the context of the whole product
    design.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 绿野仙踪方法是尽快让原型运行起来的一种方式，但即使在进行模型训练之后，你也应该考虑如何尽快进行实验和迭代。将模型导出并使其在嵌入式平台上运行足够快可能需要很长时间，因此一个很好的捷径是从环境中的传感器向附近的桌面或云计算机传输数据进行处理。这可能会消耗太多能量，无法成为生产中可部署的解决方案，但只要你能确保延迟不会影响整体体验，这是一个很好的方式来获取关于你的机器学习解决方案在整个产品设计背景下运行情况的反馈。
- en: Another big benefit is that you can record a stream of sensor data once, and
    then use it over and over again for informal evaluations of your model. This is
    especially useful if there are particularly high-impact errors that a model has
    made in the past that might not be properly captured in the normal metrics. If
    your photo classifier labels a baby as a dog, you might want to especially avoid
    this even if you’re overall 95% accurate because it would be so upsetting for
    the user.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的好处是，你可以录制一次传感器数据流，然后一遍又一遍地用于对模型进行非正式评估。如果模型在过去曾经犯过特别严重的错误，而这些错误可能无法在正常指标中得到充分体现，这将尤其有用。如果你的照片分类器将一个婴儿标记为狗，即使你整体准确率为95%，你可能也会特别想避免这种情况，因为这会让用户感到不安。
- en: There are a lot of choices for how to run the model on the desktop. The easiest
    way to begin is by collecting example data using a platform like the Raspberry
    Pi that has good sensor support, and doing a bulk copy to your desktop machine
    (or a cloud instance if you prefer). You can then use standard TensorFlow in Python
    to train and evaluate potential models in an offline way, with no interactivity.
    When you have a model that seems promising you can take incremental steps, such
    as converting your TensorFlow model to TensorFlow Lite, but continue evaluating
    it against batch data on your PC. After that’s working, you could try putting
    your desktop TensorFlow Lite application behind a simple web API and calling it
    from a device that has the form factor you’re aiming at to understand how it works
    in a real environment.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在桌面上运行模型有很多选择。开始的最简单方法是使用像树莓派这样具有良好传感器支持的平台收集示例数据，然后将数据批量复制到您的桌面机器（或者如果您喜欢，可以复制到云实例）。然后，您可以使用标准的Python
    TensorFlow以离线方式训练和评估潜在模型，没有交互性。当您有一个看起来很有前途的模型时，您可以采取增量步骤，例如将您的TensorFlow模型转换为TensorFlow
    Lite，但继续在PC上针对批处理数据进行评估。在这之后，您可以尝试将桌面TensorFlow Lite应用程序放在一个简单的Web API后面，并从具有您所瞄准的外形因素的设备上调用它，以了解它在真实环境中的工作方式。
