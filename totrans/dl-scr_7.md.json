["```py\na = NumberWithGrad(3)\n\nb = a * 4\nc = b + 3\nd = (a + 2)\ne = c * d\ne.backward()\n```", "```py\na = torch.Tensor([[3., 3.,],\n                  [3., 3.]], requires_grad=True)\n```", "```py\nb = a * 4\nc = b + 3\nd = (a + 2)\ne = c * d\ne_sum = e.sum()\ne_sum.backward()\n```", "```py\nprint(a.grad)\n```", "```py\ntensor([[35., 35.],\n        [35., 35.]], dtype=torch.float64)\n```", "```py\nfrom torch import nn, Tensor\n\nclass PyTorchLayer(nn.Module):\n\n    def __init__(self) -> None:\n        super().__init__()\n\n    def forward(self, x: Tensor,\n                inference: bool = False) -> Tensor:\n        raise NotImplementedError()\n```", "```py\nclass PyTorchModel(nn.Module):\n\n    def __init__(self) -> None:\n        super().__init__()\n\n    def forward(self, x: Tensor,\n                inference: bool = False) -> Tensor:\n        raise NotImplementedError()\n```", "```py\ndef inference_mode(m: nn.Module):\n    m.eval()\n```", "```py\nif inference:\n    self.apply(inference_mode)\n```", "```py\nclass DenseLayer(PyTorchLayer):\n    def __init__(self,\n                 input_size: int,\n                 neurons: int,\n                 dropout: float = 1.0,\n                 activation: nn.Module = None) -> None:\n        super().__init__()\n        self.linear = nn.Linear(input_size, neurons)\n        self.activation = activation\n        if dropout < 1.0:\n            self.dropout = nn.Dropout(1 - dropout)\n\n    def forward(self, x: Tensor,\n                inference: bool = False) -> Tensor:\n        if inference:\n            self.apply(inference_mode)\n\n        x = self.linear(x) # does weight multiplication + bias\n        if self.activation:\n            x = self.activation(x)\n        if hasattr(self, \"dropout\"):\n            x = self.dropout(x)\n\n        return x\n```", "```py\nclass HousePricesModel(PyTorchModel):\n\n    def __init__(self,\n                 hidden_size: int = 13,\n                 hidden_dropout: float = 1.0):\n        super().__init__()\n        self.dense1 = DenseLayer(13, hidden_size,\n                                 activation=nn.Sigmoid(),\n                                 dropout = hidden_dropout)\n        self.dense2 = DenseLayer(hidden_size, 1)\n\n    def forward(self, x: Tensor) -> Tensor:\n\n        assert_dim(x, 2)\n\n        assert x.shape[1] == 13\n\n        x = self.dense1(x)\n        return self.dense2(x)\n```", "```py\npytorch_boston_model = HousePricesModel(hidden_size=13)\n```", "```py\nclass HousePricesModel(PyTorchModel):\n\n    def __init__(self,\n                 hidden_size: int = 13):\n        super().__init__()\n        self.fc1 = nn.Linear(13, hidden_size)\n        self.fc2 = nn.Linear(hidden_size, 1)\n\n    def forward(self, x: Tensor) -> Tensor:\n\n        assert_dim(x, 2)\n\n        assert x.shape[1] == 13\n\n        x = self.fc1(x)\n        x = torch.sigmoid(x)\n        return self.fc2(x)\n```", "```py\nimport torch.optim as optim\n\noptimizer = optim.SGD(pytorch_boston_model.parameters(), lr=0.001)\n```", "```py\nmean_squared_error_loss = nn.MSELoss()\nsoftmax_cross_entropy_loss = nn.CrossEntropyLoss()\n```", "```py\n# First, zero the gradients\nself.optim.zero_grad()\n\n# feed X_batch through the model\noutput = self.model(X_batch)\n\n# Compute the loss\nloss = self.loss(output, y_batch)\n\n# Call backward on the loss to kick off backpropagation\nloss.backward()\n\n# Call self.optim.step() (as before) to update the parameters\nself.optim.step()\n```", "```py\nclass PyTorchTrainer(object):\n    def __init__(self,\n                 model: PyTorchModel,\n                 optim: Optimizer,\n                 criterion: _Loss):\n        self.model = model\n        self.optim = optim\n        self.loss = criterion\n        self._check_optim_net_aligned()\n\n    def _check_optim_net_aligned(self):\n        assert self.optim.param_groups[0]['params']\\\n        == list(self.model.parameters())\n\n    def _generate_batches(self,\n                          X: Tensor,\n                          y: Tensor,\n                          size: int = 32) -> Tuple[Tensor]:\n\n        N = X.shape[0]\n\n        for ii in range(0, N, size):\n            X_batch, y_batch = X[ii:ii+size], y[ii:ii+size]\n\n            yield X_batch, y_batch\n\n    def fit(self, X_train: Tensor, y_train: Tensor,\n            X_test: Tensor, y_test: Tensor,\n            epochs: int=100,\n            eval_every: int=10,\n            batch_size: int=32):\n\n        for e in range(epochs):\n            X_train, y_train = permute_data(X_train, y_train)\n\n            batch_generator = self._generate_batches(X_train, y_train,\n                                                     batch_size)\n\n            for ii, (X_batch, y_batch) in enumerate(batch_generator):\n\n                self.optim.zero_grad()\n                output = self.model(X_batch)\n                loss = self.loss(output, y_batch)\n                loss.backward()\n                self.optim.step()\n\n            output = self.model(X_test)\n            loss = self.loss(output, y_test)\n            print(e, loss)\n```", "```py\nnet = HousePricesModel()\noptimizer = optim.SGD(net.parameters(), lr=0.001)\ncriterion = nn.MSELoss()\n\ntrainer = PyTorchTrainer(net, optimizer, criterion)\n\ntrainer.fit(X_train, y_train, X_test, y_test,\n            epochs=10,\n            eval_every=1)\n```", "```py\noptim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n```", "```py\nnn.Conv2d(in_channels, out_channels, filter_size)\n```", "```py\nclass ConvLayer(PyTorchLayer):\n    def __init__(self,\n                 in_channels: int,\n                 out_channels: int,\n                 filter_size: int,\n                 activation: nn.Module = None,\n                 flatten: bool = False,\n                 dropout: float = 1.0) -> None:\n        super().__init__()\n\n        # the main operation of the layer\n        self.conv = nn.Conv2d(in_channels, out_channels, filter_size,\n                              padding=filter_size // 2)\n\n        # the same \"activation\" and \"flatten\" operations from before\n        self.activation = activation\n        self.flatten = flatten\n        if dropout < 1.0:\n            self.dropout = nn.Dropout(1 - dropout)\n\n    def forward(self, x: Tensor) -> Tensor:\n\n        # always apply the convolution operation\n        x = self.conv(x)\n\n        # optionally apply the convolution operation\n        if self.activation:\n            x = self.activation(x)\n        if self.flatten:\n            x = x.view(x.shape[0], x.shape[1] * x.shape[2] * x.shape[3])\n        if hasattr(self, \"dropout\"):\n            x = self.dropout(x)\n\n        return x\n```", "```py\nclass MNIST_ConvNet(PyTorchModel):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = ConvLayer(1, 16, 5, activation=nn.Tanh(),\n                               dropout=0.8)\n        self.conv2 = ConvLayer(16, 8, 5, activation=nn.Tanh(), flatten=True,\n                               dropout=0.8)\n        self.dense1 = DenseLayer(28 * 28 * 8, 32, activation=nn.Tanh(),\n                                 dropout=0.8)\n        self.dense2 = DenseLayer(32, 10)\n\n    def forward(self, x: Tensor) -> Tensor:\n        assert_dim(x, 4)\n\n        x = self.conv1(x)\n        x = self.conv2(x)\n\n        x = self.dense1(x)\n        x = self.dense2(x)\n        return x\n```", "```py\nmodel = MNIST_ConvNet()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\ntrainer = PyTorchTrainer(model, optimizer, criterion)\n\ntrainer.fit(X_train, y_train,\n            X_test, y_test,\n            epochs=5,\n            eval_every=1)\n```", "```py\nX_train, X_test = X_train - X_train.mean(), X_test - X_train.mean()\nX_train, X_test = X_train / X_train.std(), X_test / X_train.std()\n```", "```py\nfrom torchvision.datasets import MNIST\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n```", "```py\nmnist_trainset = MNIST(root=\"../data/\", train=True)\nX_train = mnist_trainset.train_data\n```", "```py\nimg_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1305,), (0.3081,))\n])\n```", "```py\ndataset = MNIST(\"../mnist_data/\", transform=img_transforms)\n```", "```py\ndataloader = DataLoader(dataset, batch_size=60, shuffle=True)\n```", "```py\nfor X_batch, y_batch in enumerate(batch_generator):\n```", "```py\nfor X_batch, y_batch in enumerate(train_dataloader):\n```", "```py\ntrainer.fit(train_dataloader = train_loader,\n            test_dataloader = test_loader,\n            epochs=1,\n            eval_every=1)\n```", "```py\nclass LSTMLayer(PyTorchLayer):\n    def __init__(self,\n                 sequence_length: int,\n                 input_size: int,\n                 hidden_size: int,\n                 output_size: int) -> None:\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.h_init = torch.zeros((1, hidden_size))\n        self.c_init = torch.zeros((1, hidden_size))\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.fc = DenseLayer(hidden_size, output_size)\n```", "```py\ndef forward(self, x: Tensor) -> Tensor:\n\n    batch_size = x.shape[0]\n\n    h_layer = self._transform_hidden_batch(self.h_init,\n                                           batch_size,\n                                           before_layer=True)\n    c_layer = self._transform_hidden_batch(self.c_init,\n                                           batch_size,\n                                           before_layer=True)\n\n    x, (h_out, c_out) = self.lstm(x, (h_layer, c_layer))\n\n    self.h_init, self.c_init = (\n        self._transform_hidden_batch(h_out,\n                                     batch_size,\n                                     before_layer=False).detach(),\n        self._transform_hidden_batch(c_out,\n                                     batch_size,\n                                     before_layer=False).detach()\n                                    )\n\n    x = self.fc(x)\n\n    return x\n```", "```py\nx, (h_out, c_out) = self.lstm(x, (h_layer, c_layer))\n```", "```py\nclass NextCharacterModel(PyTorchModel):\n    def __init__(self,\n                 vocab_size: int,\n                 hidden_size: int = 256,\n                 sequence_length: int = 25):\n        super().__init__()\n        self.vocab_size = vocab_size\n        self.sequence_length = sequence_length\n\n        # In this model, we have only one layer,\n        # with the same output size as input_size\n        self.lstm = LSTMLayer(self.sequence_length,\n                              self.vocab_size,\n                              hidden_size,\n                              self.vocab_size)\n\n    def forward(self,\n                inputs: Tensor):\n        assert_dim(inputs, 3) # batch_size, sequence_length, vocab_size\n\n        out = self.lstm(inputs)\n\n        return out.permute(0, 2, 1)\n```", "```py\nclass Encoder(PyTorchModel):\n    def __init__(self,\n                 hidden_dim: int = 28):\n        super(Encoder, self).__init__()\n        self.conv1 = ConvLayer(1, 14, activation=nn.Tanh())\n        self.conv2 = ConvLayer(14, 7, activation=nn.Tanh(), flatten=True)\n\n        self.dense1 = DenseLayer(7 * 28 * 28, hidden_dim, activation=nn.Tanh())\n\n    def forward(self, x: Tensor) -> Tensor:\n        assert_dim(x, 4)\n\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.dense1(x)\n\n        return x\n```", "```py\nclass Decoder(PyTorchModel):\n    def __init__(self,\n                 hidden_dim: int = 28):\n        super(Decoder, self).__init__()\n        self.dense1 = DenseLayer(hidden_dim, 7 * 28 * 28, activation=nn.Tanh())\n\n        self.conv1 = ConvLayer(7, 14, activation=nn.Tanh())\n        self.conv2 = ConvLayer(14, 1, activation=nn.Tanh())\n\n    def forward(self, x: Tensor) -> Tensor:\n        assert_dim(x, 2)\n\n        x = self.dense1(x)\n\n        x = x.view(-1, 7, 28, 28)\n        x = self.conv1(x)\n        x = self.conv2(x)\n\n        return x\n```", "```py\nclass Autoencoder(PyTorchModel):\n    def __init__(self,\n                 hidden_dim: int = 28):\n        super(Autoencoder, self).__init__()\n\n        self.encoder = Encoder(hidden_dim)\n\n        self.decoder = Decoder(hidden_dim)\n\n    def forward(self, x: Tensor) -> Tensor:\n        assert_dim(x, 4)\n\n        encoding = self.encoder(x)\n        x = self.decoder(encoding)\n\n        return x, encoding\n```", "```py\ndef forward(self, x: Tensor) -> Tuple[Tensor]:\n```", "```py\noutput = self.model(X_batch)[0]\n...\noutput = self.model(X_test)[0]\n```", "```py\nX_train_auto = (X_train - X_train.min())\n                / (X_train.max() - X_train.min()) * 2 - 1\nX_test_auto = (X_test - X_train.min())\n                / (X_train.max() - X_train.min()) * 2 - 1\n```", "```py\nmodel = Autoencoder(hidden_dim=28)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n\ntrainer = PyTorchTrainer(model, optimizer, criterion)\n\ntrainer.fit(X_train_auto, X_train_auto,\n            X_test_auto, X_test_auto,\n            epochs=1,\n            batch_size=60)\n```", "```py\nreconstructed_images, image_representations = model(X_test_auto)\n```", "```py\ntest_encodings = np.random.uniform(low=-1.0, high=1.0, size=(5, 28))\ntest_imgs = model.decoder(Tensor(test_encodings))\n```"]