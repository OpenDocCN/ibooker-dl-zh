["```py\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\nprint(f\"Features: {dataset['train'].column_names}\")\n```", "```py\nFeatures: ['article', 'highlights', 'id']\n```", "```py\nsample = dataset[\"train\"][1]\nprint(f\"\"\"\nArticle (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n\"\"\")\nprint(sample[\"article\"][:500])\nprint(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\nprint(sample[\"highlights\"])\n\nArticle (excerpt of 500 characters, total length: 3192):\n\n(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his\nthird gold in Moscow as he anchored Jamaica to victory in the men's 4x100m\nrelay. The fastest man in the world charged clear of United States rival Justin\nGatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel\nAshmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds\nwith Canada taking the bronze after Britain were disqualified for a faulty\nhandover. The 26-year-old Bolt has n\n\nSummary (length: 180):\nUsain Bolt wins third gold of world championship .\nAnchors Jamaica to 4x100m relay victory .\nEighth gold at the championships for Bolt .\nJamaica double up in women's 4x100m relay .\n```", "```py\nsample_text = dataset[\"train\"][1][\"article\"][:2000]\n# We'll collect the generated summaries of each model in a dictionary\nsummaries = {}\n```", "```py\nimport nltk\nfrom nltk.tokenize import sent_tokenize\n\nnltk.download(\"punkt\")\n```", "```py\nstring = \"The U.S. are a country. The U.N. is an organization.\"\nsent_tokenize(string)\n```", "```py\n['The U.S. are a country.', 'The U.N. is an organization.']\n```", "```py\ndef three_sentence_summary(text):\n    return \"\\n\".join(sent_tokenize(text)[:3])\n```", "```py\nsummaries[\"baseline\"] = three_sentence_summary(sample_text)\n```", "```py\nfrom transformers import pipeline, set_seed\n\nset_seed(42)\npipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\ngpt2_query = sample_text + \"\\nTL;DR:\\n\"\npipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\nsummaries[\"gpt2\"] = \"\\n\".join(\n    sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))\n```", "```py\npipe = pipeline(\"summarization\", model=\"t5-large\")\npipe_out = pipe(sample_text)\nsummaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))\n```", "```py\npipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\npipe_out = pipe(sample_text)\nsummaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))\n```", "```py\npipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\npipe_out = pipe(sample_text)\nsummaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")\n```", "```py\nprint(\"GROUND TRUTH\")\nprint(dataset[\"train\"][1][\"highlights\"])\nprint(\"\")\n\nfor model_name in summaries:\n    print(model_name.upper())\n    print(summaries[model_name])\n    print(\"\")\n```", "```py\nGROUND TRUTH\nUsain Bolt wins third gold of world championship .\nAnchors Jamaica to 4x100m relay victory .\nEighth gold at the championships for Bolt .\nJamaica double up in women's 4x100m relay .\n\nBASELINE\n(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his\nthird gold in Moscow as he anchored Jamaica to victory in the men's 4x100m\nrelay.\nThe fastest man in the world charged clear of United States rival Justin Gatlin\nas the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and\nBolt won in 37.36 seconds.\nThe U.S finished second in 37.56 seconds with Canada taking the bronze after\nBritain were disqualified for a faulty handover.\n\nGPT2\nNesta, the fastest man in the world.\nGatlin, the most successful Olympian ever.\nKemar, a Jamaican legend.\nShelly-Ann, the fastest woman ever.\nBolt, the world's greatest athlete.\nThe team sport of pole vaulting\n\nT5\nusain bolt wins his third gold medal of the world championships in the men's\n4x100m relay .\nthe 26-year-old anchored Jamaica to victory in the event in the Russian capital\n.\nhe has now collected eight gold medals at the championships, equaling the record\n.\n\nBART\nUsain Bolt wins his third gold of the world championships in Moscow.\nBolt anchors Jamaica to victory in the men's 4x100m relay.\nThe 26-year-old has now won eight gold medals at world championships.\nJamaica's women also win gold in the relay, beating France in the process.\n\nPEGASUS\nUsain Bolt wins third gold of world championships.\nAnchors Jamaica to victory in men's 4x100m relay.\nEighth gold at the championships for Bolt.\nJamaica also win women's 4x100m relay .\n```", "```py\nfrom datasets import load_metric\n\nbleu_metric = load_metric(\"sacrebleu\")\n```", "```py\nimport pandas as pd\nimport numpy as np\n\nbleu_metric.add(\n    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\nresults = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\nresults[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\npd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n```", "```py\nbleu_metric.add(\n    prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\nresults = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\nresults[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\npd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])\n```", "```py\nrouge_metric = load_metric(\"rouge\")\n```", "```py\nreference = dataset[\"train\"][1][\"highlights\"]\nrecords = []\nrouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n\nfor model_name in summaries:\n    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n    score = rouge_metric.compute()\n    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n    records.append(rouge_dict)\npd.DataFrame.from_records(records, index=summaries.keys())\n```", "```py\ndef evaluate_summaries_baseline(dataset, metric,\n                                column_text=\"article\",\n                                column_summary=\"highlights\"):\n    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n    metric.add_batch(predictions=summaries,\n                     references=dataset[column_summary])\n    score = metric.compute()\n    return score\n```", "```py\ntest_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n\nscore = evaluate_summaries_baseline(test_sampled, rouge_metric)\nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\npd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T\n```", "```py\nfrom tqdm import tqdm\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef chunks(list_of_elements, batch_size):\n    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n    for i in range(0, len(list_of_elements), batch_size):\n        yield list_of_elements[i : i + batch_size]\n\ndef evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n                               batch_size=16, device=device,\n                               column_text=\"article\",\n                               column_summary=\"highlights\"):\n    article_batches = list(chunks(dataset[column_text], batch_size))\n    target_batches = list(chunks(dataset[column_summary], batch_size))\n\n    for article_batch, target_batch in tqdm(\n        zip(article_batches, target_batches), total=len(article_batches)):\n\n        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n                        padding=\"max_length\", return_tensors=\"pt\")\n\n        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n                         attention_mask=inputs[\"attention_mask\"].to(device),\n                         length_penalty=0.8, num_beams=8, max_length=128)\n\n        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n                                clean_up_tokenization_spaces=True)\n               for s in summaries]\n        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n\n    score = metric.compute()\n    return score\n```", "```py\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nmodel_ckpt = \"google/pegasus-cnn_dailymail\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\nscore = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n                                   model, tokenizer, batch_size=8)\nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\npd.DataFrame(rouge_dict, index=[\"pegasus\"])\n```", "```py\ndataset_samsum = load_dataset(\"samsum\")\nsplit_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n\nprint(f\"Split lengths: {split_lengths}\")\nprint(f\"Features: {dataset_samsum['train'].column_names}\")\nprint(\"\\nDialogue:\")\nprint(dataset_samsum[\"test\"][0][\"dialogue\"])\nprint(\"\\nSummary:\")\nprint(dataset_samsum[\"test\"][0][\"summary\"])\n```", "```py\nSplit lengths: [14732, 819, 818]\nFeatures: ['id', 'dialogue', 'summary']\n\nDialogue:\nHannah: Hey, do you have Betty's number?\nAmanda: Lemme check\nHannah: <file_gif>\nAmanda: Sorry, can't find it.\nAmanda: Ask Larry\nAmanda: He called her last time we were at the park together\nHannah: I don't know him well\nHannah: <file_gif>\nAmanda: Don't be shy, he's very nice\nHannah: If you say so..\nHannah: I'd rather you texted him\nAmanda: Just text him \nHannah: Urgh.. Alright\nHannah: Bye\nAmanda: Bye bye\n\nSummary:\nHannah needs Betty's number but Amanda doesn't have it. She needs to contact\nLarry.\n```", "```py\npipe_out = pipe(dataset_samsum[\"test\"][0][\"dialogue\"])\nprint(\"Summary:\")\nprint(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\"))\n```", "```py\nSummary:\nAmanda: Ask Larry Amanda: He called her last time we were at the park together.\nHannah: I'd rather you texted him.\nAmanda: Just text him .\n```", "```py\nscore = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model,\n                                   tokenizer, column_text=\"dialogue\",\n                                   column_summary=\"summary\", batch_size=8)\n\nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\npd.DataFrame(rouge_dict, index=[\"pegasus\"])\n```", "```py\nd_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"]]\ns_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"summary\"]]\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\naxes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\naxes[0].set_title(\"Dialogue Token Length\")\naxes[0].set_xlabel(\"Length\")\naxes[0].set_ylabel(\"Count\")\naxes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\naxes[1].set_title(\"Summary Token Length\")\naxes[1].set_xlabel(\"Length\")\nplt.tight_layout()\nplt.show()\n```", "```py\ndef convert_examples_to_features(example_batch):\n    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024,\n                                truncation=True)\n\n    with tokenizer.as_target_tokenizer():\n        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128,\n                                     truncation=True)\n\n    return {\"input_ids\": input_encodings[\"input_ids\"],\n            \"attention_mask\": input_encodings[\"attention_mask\"],\n            \"labels\": target_encodings[\"input_ids\"]}\n\ndataset_samsum_pt = dataset_samsum.map(convert_examples_to_features,\n                                       batched=True)\ncolumns = [\"input_ids\", \"labels\", \"attention_mask\"]\ndataset_samsum_pt.set_format(type=\"torch\", columns=columns)\n```", "```py\nfrom transformers import DataCollatorForSeq2Seq\n\nseq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n```", "```py\nfrom transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n    weight_decay=0.01, logging_steps=10, push_to_hub=True,\n    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n    gradient_accumulation_steps=16)\n```", "```py\nfrom huggingface_hub import notebook_login\n\nnotebook_login()\n```", "```py\ntrainer = Trainer(model=model, args=training_args,\n                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n                  train_dataset=dataset_samsum_pt[\"train\"],\n                  eval_dataset=dataset_samsum_pt[\"validation\"])\n```", "```py\ntrainer.train()\nscore = evaluate_summaries_pegasus(\n    dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n    batch_size=2, column_text=\"dialogue\", column_summary=\"summary\")\n\nrouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\npd.DataFrame(rouge_dict, index=[f\"pegasus\"])\n```", "```py\ntrainer.push_to_hub(\"Training complete!\")\n```", "```py\ngen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\nsample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\nreference = dataset_samsum[\"test\"][0][\"summary\"]\npipe = pipeline(\"summarization\", model=\"transformersbook/pegasus-samsum\")\n\nprint(\"Dialogue:\")\nprint(sample_text)\nprint(\"\\nReference Summary:\")\nprint(reference)\nprint(\"\\nModel Summary:\")\nprint(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])\n```", "```py\nDialogue:\nHannah: Hey, do you have Betty's number?\nAmanda: Lemme check\nHannah: <file_gif>\nAmanda: Sorry, can't find it.\nAmanda: Ask Larry\nAmanda: He called her last time we were at the park together\nHannah: I don't know him well\nHannah: <file_gif>\nAmanda: Don't be shy, he's very nice\nHannah: If you say so..\nHannah: I'd rather you texted him\nAmanda: Just text him \nHannah: Urgh.. Alright\nHannah: Bye\nAmanda: Bye bye\n\nReference Summary:\nHannah needs Betty's number but Amanda doesn't have it. She needs to contact\nLarry.\n\nModel Summary:\nAmanda can't find Betty's number. Larry called Betty last time they were at the\npark together. Hannah wants Amanda to text Larry instead of calling Betty.\n\n```", "```py\ncustom_dialogue = \"\"\"\\\nThom: Hi guys, have you heard of transformers?\nLewis: Yes, I used them recently!\nLeandro: Indeed, there is a great library by Hugging Face.\nThom: I know, I helped build it ;)\nLewis: Cool, maybe we should write a book about it. What do you think?\nLeandro: Great idea, how hard can it be?!\nThom: I am in!\nLewis: Awesome, let's do it together!\n\"\"\"\nprint(pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"])\n```", "```py\nThom, Lewis and Leandro are going to write a book about transformers. Thom\nhelped build a library by Hugging Face. They are going to do it together.\n```"]