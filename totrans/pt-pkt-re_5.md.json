["```py\nimport torch\n\ndef linear(input, weight, bias=None):\n\n    if input.dim() == 2 and bias is not None:\n        # fused op is marginally faster\n        ret = torch.addmm(bias, input, weight.t())\n    else:\n        output = input.matmul(weight.t())\n        if bias is not None:\n            output += bias\n        ret = output\n    return ret\n```", "```py\nimporttorch.nnasnnfromtorchimportTensorclassLinear(nn.Module):def__init__(self,in_features,out_features,bias):![1](Images/1.png)super(Linear,self).__init__()self.in_features=in_featuresself.out_features=out_featuresself.weight=Parameter(torch.Tensor(out_features,in_features))ifbias:self.bias=Parameter(torch.Tensor(out_features))else:self.register_parameter('bias',None)self.reset_parameters()defreset_parameters(self):init.kaiming_uniform_(self.weight,a=math.sqrt(5))ifself.biasisnotNone:fan_in,_=\\\ninit._calculate_fan_in_and_fan_out(self.weight)bound=1/math.sqrt(fan_in)init.uniform_(self.bias,-bound,bound)defforward(self,input:Tensor)->Tensor:![2](Images/2.png)returnF.linear(input,self.weight,self.bias)![3](Images/3.png)\n```", "```py\ndef complex_linear(in_r, in_i, w_r, w_i, b_i, b_r):\n    out_r = (in_r.matmul(w_r.t())\n              - in_i.matmul(w_i.t()) + b_r)\n    out_i = (in_r.matmul(w_i.t())\n              - in_i.matmul(w_r.t()) + b_i)\n\n    return out_r, out_i\n```", "```py\nclass ComplexLinear(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(Linear, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight_r = \\\n          Parameter(torch.randn(out_features,\n                                in_features))\n        self.weight_i = \\\n          Parameter(torch.randn(out_features,\n                                in_features))\n        self.bias_r = Parameter(\n                        torch.randn(out_features))\n        self.bias_i = Parameter(\n                        torch.randn(out_features))\n\n    def forward(self, in_r, in_i):\n        return F.complex_linear(in_r, in_i,\n                 self.weight_r, self.weight_i,\n                 self.bias_r, self.bias_i)\n```", "```py\nclass ComplexLinearSimple(nn.Module):\n    def __init__(self, in_features, out_features):\n        super(ComplexLinearSimple, self).__init__()\n        self.fc_r = Linear(in_features,\n                           out_features)\n        self.fc_i = Linear(in_features,\n                           out_features)\n\n    def forward(self,in_r, in_i):\n        return (self.fc_r(in_r) - self.fc_i(in_i),\n               self.fc_r(in_i)+self.fc_i(in_r))\n```", "```py\ndef my_relu(input, thresh=0.0):\n    return torch.where(\n              input > thresh,\n              input,\n              torch.zeros_like(input))\n```", "```py\nclass MyReLU(nn.Module):\n  def __init__(self, thresh = 0.0):\n      super(MyReLU, self).__init__()\n      self.thresh = thresh\n\n  def forward(self, input):\n      return my_relu(input, self.thresh)\n```", "```py\nimporttorch.nn.functionalasF![1](Images/1.png)classSimpleNet(nn.Module):def__init__(self,D_in,H,D_out):super(SimpleNet,self).__init__()self.fc1=nn.Linear(D_in,H)self.fc2=nn.Linear(H,D_out)defforward(self,x):x=F.relu(self.fc1(x))![2](Images/2.png)returnself.fc2(x)\n```", "```py\nclassSimpleNet(nn.Module):def__init__(self,D_in,H,D_out):super(SimpleNet,self).__init__()self.net=nn.Sequential(![1](Images/1.png)nn.Linear(D_in,H),nn.ReLU(),![2](Images/2.png)nn.Linear(H,D_out))defforward(self,x):returnself.net(x)\n```", "```py\ndefcomplex_relu(in_r,in_i):![1](Images/1.png)return(F.relu(in_r),F.relu(in_i))classComplexReLU(nn.Module):![2](Images/2.png)def__init__(self):super(ComplexReLU,self).__init__()defforward(self,in_r,in_i):returncomplex_relu(in_r,in_i)\n```", "```py\nclass AlexNet(nn.Module):\n\n    def __init__(self, num_classes=1000):\n        super(AlexNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11,\n                      stride=4, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5,\n                      padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3,\n                      padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(384, 256, kernel_size=3,\n                      padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3,\n                      padding=1),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n        )\n        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n        self.classifier = nn.Sequential(\n            nn.Dropout(),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.Linear(4096, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n```", "```py\nfrom torch.hub import load_state_dict_from_url\nmodel_urls = {\n    'alexnet':\n    'https://pytorch.tips/alexnet-download',\n}\n\ndef alexnet(pretrained=False,\n            progress=True, **kwargs):\n    model = AlexNet(**kwargs)\n    if pretrained:\n        state_dict = load_state_dict_from_url(\n              model_urls['alexnet'],\n              progress=progress)\n        model.load_state_dict(state_dict)\n    return model\n```", "```py\nloss_fcn=nn.MSELoss()![1](Images/1.png)loss=loss_fcn(outputs,targets)loss.backward()\n```", "```py\ndef mse_loss(input, target):\n    return ((input-target)**2).mean()\n\nclass MSELoss(nn.Module):\n    def __init__(self):\n        super(MSELoss, self).__init__()\n\n    def forward(self, input, target):\n        return F.mse_loss(input, target)\n```", "```py\ndef complex_mse_loss(input_r, input_i,\n                     target_r, target_i):\n  return (((input_r-target_r)**2).mean(),\n          ((input_i-target_i)**2).mean())\n\nclass ComplexMSELoss(nn.Module):\n    def __init__(self, real_only=False):\n        super(ComplexMSELoss, self).__init__()\n        self.real_only = real_only\n\n    def forward(self, input_r, input_i,\n                target_r, target_i):\n        if (self.real_only):\n          return F.mse_loss(input_r, target_r)\n        else:\n          return complex_mse_loss(\n              input_r, input_i,\n              target_r, target_i)\n```", "```py\nfrom torch import optim\n\noptimizer = optim.SGD(model.parameters(),\n                      lr=0.01, momentum=0.9)\n```", "```py\noptim.SGD([\n        {'params':\n          model.features.parameters()},\n        {'params':\n          model.classifier.parameters(),\n          'lr': 1e-3}\n    ], lr=1e-2, momentum=0.9)\n```", "```py\nfromcollectionsimportdefaultdictclassOptimizer(object):def__init__(self,params,defaults):self.defaults=defaultsself.state=defaultdict(dict)![1](Images/1.png)self.param_groups=[]![2](Images/2.png)param_groups=list(params)iflen(param_groups)==0:raiseValueError(\"\"\"optimizer got an\n                empty parameter list\"\"\")ifnotisinstance(param_groups[0],dict):param_groups=[{'params':param_groups}]forparam_groupinparam_groups:self.add_param_group(param_group)def__getstate__(self):return{'defaults':self.defaults,'state':self.state,'param_groups':self.param_groups,}def__setstate__(self,state):self.__dict__.update(state)defzero_grad(self):![3](Images/3.png)forgroupinself.param_groups:forpingroup['params']:ifp.gradisnotNone:p.grad.detach_()p.grad.zero_()defstep(self,closure):![4](Images/4.png)raiseNotImplementedError\n```", "```py\nfrom torch.optim import Optimizer\n\nclass SimpleSGD(Optimizer):\n\n    def __init__(self, params, lr='required'):\n        if lr is not 'required' and lr < 0.0:\n          raise ValueError(\n            \"Invalid learning rate: {}\".format(lr))\n\n        defaults = dict(lr=lr)\n        super(SimpleSGD, self).__init__(\n            params, defaults)\n\n    def step(self):\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                d_p = p.grad\n                p.add_(d_p, alpha=-group['lr'])\n\n        return\n```", "```py\noptimizer = SimpleSGD(model.parameters(),\n                      lr=0.001)\n```", "```py\noptimizer = SimpleSGD([\n                {'params':\n                 model.features.parameters()},\n                {'params':\n                 model.classifier.parameters(),\n                 'lr': 1e-3}\n            ], lr=1e-2)\n```", "```py\nfor epoch in range(n_epochs):\n\n    # Training\n    for data in train_dataloader:\n        input, targets = data\n        optimizer.zero_grad()\n        output = model(input)\n        train_loss = criterion(output, targets)\n        train_loss.backward()\n        optimizer.step()\n\n    # Validation\n    with torch.no_grad():\n      for input, targets in val_dataloader:\n          output = model(input)\n          val_loss = criterion(output, targets)\n\n# Testing\nwith torch.no_grad():\n  for input, targets in test_dataloader:\n      output = model(input)\n      test_loss = criterion(output, targets)\n```", "```py\nforepochinrange(n_epochs):total_train_loss=0.0![1](Images/1.png)total_val_loss=0.0![1](Images/1.png)if(epoch==epoch//2):optimizer=optim.SGD(model.parameters(),lr=0.001)![2](Images/2.png)# Trainingmodel.train()![3](Images/3.png)fordataintrain_dataloader:input,targets=dataoptimizer.zero_grad()output=model(input)train_loss=criterion(output,targets)train_loss.backward()optimizer.step()total_train_loss+=train_loss![1](Images/1.png)# Validationmodel.eval()![3](Images/3.png)withtorch.no_grad():forinput,targetsinval_dataloader:output=model(input)val_loss=criterion(output,targets)total_val_loss+=val_loss![1](Images/1.png)print(\"\"\"Epoch: {} Train Loss: {} Val Loss {}\"\"\".format(epoch,total_train_loss,total_val_loss))![1](Images/1.png)# Testingmodel.eval()withtorch.no_grad():forinput,targetsintest_dataloader:output=model(input)test_loss=criterion(output,targets)\n```"]