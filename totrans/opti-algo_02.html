<html><head></head><body>
  <h1 class="tochead" id="heading_id_2">2 <a id="idTextAnchor001"/>A deeper look at search and optimization</h1>

  <p class="co-summary-head">This chapter covers<a id="idIndexMarker000"/><a id="marker-23"/></p>

  <ul class="calibre5">
    <li class="co-summary-bullet">Classifying optimization problems based on different criteria</li>

    <li class="co-summary-bullet">Classifying search and optimization algorithms based on the way the search space is explored and how deterministic the algorithm is</li>

    <li class="co-summary-bullet">Introducing heuristics, metaheuristics, and heuristic search strategies</li>

    <li class="co-summary-bullet">A first look at nature-inspired search and optimization algorithms</li>
  </ul>

  <p class="body">Before we dive into the problems and algorithms that I hinted at in chapter 1, it will be useful to be clear about how we talk about these problems and algorithms. Classifying problems allows us to group similar problems together and potentially exploit existing solutions. For example, a traveling salesman problem involving geographic values (i.e., cities and roads) may be used as a model to find the minimum length of wires connecting pins in a very large-scale integration (VLSI) design. The same can be said for classifying the algorithms themselves, as grouping algorithms with similar properties can allow us to easily identify the right algorithm to solve a problem and meet expectations, such as the quality of the solution and the permissible search time. <a id="idIndexMarker001"/></p>

  <p class="body">Throughout this chapter, we’ll discuss common classifications of optimization problems and algorithms. Heuristics and metaheuristics will also be introduced as general algorithmic frameworks or high-level strategies that guide the search process. Many of these strategies are inspired by nature, so we’ll shed some light on nature-inspired algorithms. Let’s start by discussing how we can classify optimization problems based on different criteria.</p>

  <h2 class="fm-head" id="heading_id_3">2.1 Classifying optimization problems</h2>

  <p class="body"><a id="marker-24"/>Optimization is everywhere! In everyday life, you’ll face different kinds of optimization problems. For example, you may like to set the thermostat to a certain temperature to stay comfortable and at the same time save energy. You may select light fixtures and adjust the light levels to reduce energy costs. When you start driving your electric vehicle (EV), you may search for the fastest or most energy-efficient route to your destination. Before arriving at your destination, you may look for a parking spot that is affordable, provides the shortest walking distance to your destination, offers EV charging, and is preferably underground. These optimization problems have different levels of complexity that mainly depend on the type of problem. As mentioned in the previous chapter, the process of optimization involves selecting decision variables from a given feasible search space in such a way as to optimize (minimize or maximize) a given objective function or, in some cases, multiple objective functions. <a id="idIndexMarker002"/></p>

  <p class="body">Optimization problems are characterized by three main components: decision variables or design vectors, objective functions or criteria to be optimized, and a set of hard and soft constraints to be satisfied. The nature of these three components, the permissible time allowed for solving the problem, and the expected quality of the solutions lead to different types of optimization problems, as shown in figure 2.1.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F01_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.1 Optimization problem classification—an optimization problem can be broken down into its constituent parts, which form the basis for classifying such problems.<a id="marker-25"/></p>
  </div>

  <p class="body">The following subsections explain these types in greater detail and provide examples of each type of optimization problem.</p>

  <h3 class="fm-head1" id="heading_id_4">2.1.1 Number and type of decision variables</h3>

  <p class="body">Based on the number of decision variables, optimization problems can be broadly grouped into univariate (single variable) or multivariate (multiple variable) problems. For example, vehicle speed, acceleration, and tire pressure are among the parameters that effect a vehicle’s fuel economy, where fuel economy refers to how far a vehicle can travel on a specific amount of fuel. According to the US Department of Energy, controlling the speed and acceleration of a vehicle can improve its fuel economy by 15% to 30% at highway speeds and 10% to 40% in stop-and-go traffic. A study by the US National Highway Traffic Safety Administration (NHTSA) found that a 1% decrease in tire pressure correlated to a 0.3% reduction in fuel economy. If we are only looking for the optimal vehicle speed for maximum fuel economy, the problem is a univariate optimization problem. Finding the optimal speed and acceleration for maximum fuel economy is a bivariate optimization problem, whereas finding optimal speed, acceleration, and tire pressure is a multivariate problem. <a id="idIndexMarker003"/><a id="idIndexMarker004"/><a id="marker-26"/></p>

  <p class="body">Problem classification also varies according to the type of decision variables. A continuous problem involves continuous-valued variables, where <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">j</sub> <span class="cambria">∈</span> R</span>. In contrast, if <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">j</sub> <span class="cambria">∈</span> Z</span>, the problem is an integer or discrete optimization problem. A mixed-integer problem has both continuous-valued and integer-valued variables. For example, optimizing elevator speed and acceleration (continuous variables) and the sequence of picking up passengers (a discrete variable) is a mixed-integer problem. Problems where the solutions are sets, combinations, or permutations of integer-valued variables are referred to as combinatorial optimization problems.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">Combination vs. permutation</p>

    <p class="fm-sidebar-text">Combinatorics is the branch of mathematics studying both the combination and permutation of a set of elements. The main difference between combination and permutation is the order. If the order of the elements doesn’t matter, it is a combination, and if the order does matter, it is a permutation. Thus, permutations are ordered combinations. Depending on whether repetition of the elements is allowed or not, we can have different forms of combinations and permutations.<a id="idIndexMarker005"/><a id="idIndexMarker006"/></p>

    <p class="sidebarafigures"><img alt="" class="calibre2" src="../Images/CH02_F01_UN01_Khamis.png"/></p>

    <p class="sidebaracaptions">Combinations and permutations—permutations respect order and are thus ordered combinations. Both combinations and permutations have variants with and without repetition.</p>

    <p class="fm-sidebar-text">For example, assume we are designing a fitness plan that includes multiple fitness activities. Five types of exercises can be included in the fitness plan: jogging, swimming, biking, yoga, and aerobics. In a weekly plan, if we choose only three of these five exercises, and repetition is allowed, the number of possible combinations will be <span class="times">(<i class="fm-italics">n</i> + <i class="fm-italics">r</i> – 1)! / <i class="fm-italics">r</i>!(<i class="fm-italics">n</i> – 1)! = (5 + 3 – 1)! / 3!(5 – 1)! = 7! / (3! <span class="cambria">×</span> 4!) = 35</span>. This means we can generate 35 different fitness plans by selecting three of the available five exercises and by allowing repetition.</p>

    <p class="fm-sidebar-text">However, if repetition is not allowed, the number of possible combinations will be <span class="times"><i class="fm-italics">C</i>(<i class="fm-italics">n</i>,<i class="fm-italics">r</i>) = <i class="fm-italics">n</i>! / <i class="fm-italics">r</i>!(<i class="fm-italics">n</i> – <i class="fm-italics">r</i>)! = 5! / (3! <span class="cambria">×</span> 2!) = 10</span>. This formula is often called “<i class="timesitalic">n</i> choose <i class="timesitalic">r</i>” (such as “5 choose 3”), and it’s also known as the <i class="fm-italics">binomial coefficient</i>. This means that we can generate only 10 plans if we don’t want to repeat any of the exercises.</p>

    <p class="fm-sidebar-text">In both combination with and without repetition, the fitness plan doesn’t include the order of performing the included exercises. If we respect specific order, the plan will take the form of a permutation. If repeating exercises is allowed, the number of possible permutations when selecting three of the five available exercises will be <span class="times"><i class="fm-italics">n</i><sup class="fm-superscript">r</sup> = 5<sup class="fm-superscript">3</sup> = 125</span>. However, if repetition is not allowed, the number of possible permutations will be <span class="times"><i class="fm-italics">P</i>(<i class="fm-italics">n</i>,<i class="fm-italics">r</i>) = <i class="fm-italics">n</i>! / (<i class="fm-italics">n</i> – <i class="fm-italics">r</i>)! = 5! / (5 – 3)! = 60</span>.</p>

    <p class="fm-sidebar-text">Combinatorics can be implemented fairly easily in Python when coding from scratch, but there are excellent libraries available, such as SymPy, an open source Python library for symbolic mathematics. Its capabilities include, but are not limited to, statistics, physics, geometry, calculus, equation solving, combinatorics, discrete math, cryptography, and parsing. For example, the binomial coefficient can be calculated in SymPy using the following simple code:</p>
    <pre class="programlisting">from sympy import binomial
print(binomial(5,3))</pre>

    <p class="fm-sidebar-text">See appendix A and the documentation for SymPy for more on implementing combinatorics in Python.</p>
  </div>

  <p class="body">The traveling salesman problem (TSP) is a common example of a combinational problem whose solution is a permutation—a sequence of cities to be visited. In TSP, given <i class="timesitalic">n</i> cities, a traveling salesman must visit all the cities and then return home, making a loop (a round trip). The salesman would like to travel in the most efficient way (such as the fastest, cheapest, or shortest route). <a id="idIndexMarker007"/><a id="marker-27"/></p>

  <p class="body">TSP can be subdivided into <i class="fm-italics">symmetric TSP</i> (STSP) and <i class="fm-italics">asymmetric TSP</i> (ATSP). In STSP, the distance between two cities is the same in both directions, forming an undirected graph. This symmetry halves the number of possible solutions. ATSP is a strict generalization of the symmetric version. In ATSP, paths may not exist in both directions, or the distances might be different, forming a directed graph. Traffic collisions, one-way streets, bridges, and airfares for cities with different departure and arrival fees are examples of how this symmetry could break down.<a id="idIndexMarker008"/><a id="idIndexMarker009"/></p>

  <p class="body">The search space in TSP is very large. For example, let’s assume the salesman is to visit the 13 major cities in the Greater Toronto Area (GTA), as illustrated in figure 2.2. The naive solution’s complexity is <span class="times"><i class="fm-italics">O</i>(<i class="fm-italics">n</i>!)</span>. This means that there are <span class="times"><i class="fm-italics">n</i>! = 13! = 6,227,020,800</span> possible tours in the case of ATSP. This is a huge search space in both STSP and ATSP. However, dynamic programming (DP) algorithms enable reduced complexity. <a id="idIndexMarker010"/><a id="idIndexMarker011"/><a id="marker-28"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F02_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.2 TSP in the Greater Toronto Area (GTA). The traveling salesman must visit all 13 cities and wishes to select the “best” path, whether that be based on distance, time, or some other criterion.</p>
  </div>

  <p class="body">Dynamic programming is a method of solving optimization problems by breaking them down into smaller subproblems and solving each subproblem independently. For example, the complexity of the Bellman-Held-Karp algorithm [1] is <span class="times"><i class="fm-italics">O</i>(2<i class="fm-italics"><sup class="fm-superscript">n</sup></i> × <i class="fm-italics">n</i><sup class="fm-superscript">2</sup>)</span>. There are other solvers and algorithms with different levels of computational complexity and approximation ratios such as the Concorde TSP solver, the 2-opt and 3-opt algorithms, branch and bound algorithms, the Christofides algorithm (or Christofides–Serdyukov algorithm), the Lin-Kernighan algorithm, metaheuristics-based algorithms, graph neural networks, and deep reinforcement learning methods. For example, the Christofides algorithm [2] is a polynomial-time approximation algorithm that produces a solution to TSP that is guaranteed to be no more than 50% longer than the optimal solution with a time complexity of <span class="times"><i class="fm-italics">O</i>(<i class="fm-italics">n</i><sup class="fm-superscript">3</sup>)</span>. See appendix A for the solution of TSP using the Christofides algorithm implemented with the NetworkX package. We will discuss how to solve TSP using a number of these algorithms throughout this book.</p>

  <p class="body">A wide range of discrete optimization problems can be modeled as TSP. These problems include, but are not limited to, microchip manufacturing, permutation flow shop scheduling, arranging school bus routes for children in a school district, assigning routes for airplanes, transporting farming equipment, scheduling of service calls, meal delivery, and routing trucks for parcel delivery and pickup. For example, the capacitated vehicle routing problem (CVRP) is a generalization of TSP where one has to serve a set of customers using a fleet of vehicles based at a common depot. Each customer has a certain demand for goods that are initially located at the depot. The task is to design vehicle routes starting and ending at the depot such that all customer demands are fulfilled. Later in this book, we’ll look at several examples of solving TSP and its variants using stochastic approaches.<a id="idIndexMarker012"/><a id="marker-29"/></p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">Problem types</p>

    <p class="fm-sidebar-text">Decision problems are foundational in the study of algorithmic complexity. Generally speaking, a decision problem is a type of problem that requires determining whether a given input satisfies a certain property or condition. This problem can be answered with a simple “yes” or “no.”</p>

    <p class="fm-sidebar-text">Decision problems are commonly classified based on their levels of complexity. These classes can also be applied to optimization problems, given that optimization problems can be converted into decision-making problems. For example, an optimization problem whose objective is to find an optimal or near-optimal solution within a feasible search space can be paraphrased as a decision-making problem that answers the question “Is there an optimal or a near-optimal solution within the feasible search space?” The answer will be “yes” or “no,” or “true” or “false”.</p>

    <p class="fm-sidebar-text">A generally accepted notion of an algorithm’s efficiency is that its running time is polynomial. This means that the time or the computational cost to solve the problem can be described by a polynomial function of the size of the input for the algorithm. For example, in the context of TSP, the size of the input would typically be the number of cities that the salesperson needs to visit. Problems that can be solved in polynomial time are known as <i class="fm-italics">tractable</i>. The following figure shows different types of problems and gives examples of commonly used benchmarks (toy problems) and real-life applications of each type.</p>

    <p class="sidebarafigures"><img alt="" class="calibre2" src="../Images/CH02_F02_UN02_Khamis.png"/></p>

    <p class="sidebaracaptions">Problem classes based on hardness and completeness. Problems can be categorized into NP-hard, NP-complete, NP, or P.</p>

    <p class="fm-sidebar-text">For example, a complexity class P represents all decision problems that can be solved in polynomial time by deterministic algorithms (i.e., algorithms that do not guess at a solution). The NP or nondeterministic polynomial problems are those whose solutions are hard to find but easy to verify and are solved by a nondeterministic algorithm in polynomial time. NP-complete problems are those that are both NP-hard and verifiable in polynomial time. Finally, a problem is NP-hard if it is at least as hard as the hardest problem in NP-complete. NP-hard problems are usually solved by approximation or heuristic solvers, as it is hard to find efficient exact algorithms to solve such problems.</p>
  </div>

  <p class="body">Clustering is a type of combinatorial problem whose solution takes the form of a combination where the order doesn’t matter. In clustering, given <i class="timesitalic">n</i> objects, we need to group them in <i class="timesitalic">k</i> groups (clusters) such that all objects in a single group or cluster have a “natural” relation to one another, and objects not in the same group are somehow different. This means that the objects will be grouped based on some similarity or dissimilarity metric.</p>

  <p class="body"><i class="fm-italics">Stirling numbers</i> can be used for counting partitions and permutations in combinatorial problems. Stirling numbers of the <i class="fm-italics">first kind</i> count permutations according to their number of cycles, while Stirling numbers of the <i class="fm-italics">second kind</i> represent the number of ways we can partition a set of objects into non-empty subsets. The following formula is for a Stirling number of the second kind (a <i class="fm-italics">Stirling partition number</i>), and it gives the number of ways you can partition a set of <i class="timesitalic">n</i> objects into <i class="timesitalic">k</i> non-empty subsets in the context of our clustering problem:<a id="marker-30"/></p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figuree"><img alt="" class="calibre4" src="../Images/CH02_F02_UN02_Khamis-EQ01.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">2.1</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">Let’s consider smart cart clustering as an example. Shopping and luggage carts are commonly found in shopping malls and large airports. Shoppers or travelers pick up these carts at designated points and leave them in arbitrary places. It is a considerable task to re-collect them, and it is therefore beneficial if a “smarter” version of these carts could draw themselves together automatically to the nearest assembly points, as illustrated in figure 2.3.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F03_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.3 Smart cart clustering. Unused shopping or luggage carts congregate near designated assembly points to make collection and redistribution easier.</p>
  </div>

  <p class="body">In practice, this problem is considered an NP-hard problem, as the search space can be very large based on the numbers of available carts and assembly points. To cluster these carts effectively, the centers of clustering (the <i class="fm-italics">centroids</i>) must be found. The carts in each cluster will then be directed to the assembly point closest to the centroids.</p>

  <p class="body"><a id="marker-31"/>For example, assume that 50 carts are to be clustered around four assembly points. This means that <span class="times"><i class="fm-italics">n</i> = 50</span> and <span class="times"><i class="fm-italics">k</i> = 4</span>. Stirling numbers can be generated using the SymPy library. To do so, simply call the <code class="fm-code-in-text">stirling</code> function on two numbers, <i class="timesitalic">n</i> and <i class="timesitalic">k</i>:<a id="idIndexMarker013"/></p>
  <pre class="programlisting">from sympy.functions.combinatorial.numbers import stirling
print(stirling(50,4))
print(stirling(100,4))</pre>

  <p class="body">The result is <span class="times">5.3 × 10<sup class="fm-superscript">28</sup></span>, and if <i class="timesitalic">n</i> is increased to 100, the number becomes <span class="times">6.7 × 10<sup class="fm-superscript">58</sup></span>. Enumerating all possible partitions for large problems is not feasible.<a id="idIndexMarker014"/><a id="idIndexMarker015"/></p>

  <h3 class="fm-head1" id="heading_id_5">2.1.2 Landscape and number of objective functions</h3>

  <p class="body">An objective function’s <i class="fm-italics">landscape</i> represents the distribution of the function’s values in the feasible search space. In this landscape, you’ll find the optimal solution or the global minima in the lowest valley, assuming you are dealing with a minimization problem, or at the highest peak in the case of a maximization problem. According to the landscape of the objective function, if there is only one clear global optimal solution, the problem is <i class="fm-italics">unimodal</i> (e.g., convex and concave functions). In a <i class="fm-italics">multimodal</i> problem, more than one optimum exists. The objective function is called <i class="fm-italics">deceptive</i> when the global minimum lies in a very narrow valley and there is also a strong local minimum with a wide basin of attraction, such that the value of this objective function is close to the value of an objective function at the global minimum [3]. Figure 2.4 is a 3D visualization of the landscapes of unimodal, multimodal, and deceptive functions generated using Python in the next listing. The complete listing is available in the GitHub repo for the book.<a id="idIndexMarker016"/><a id="idIndexMarker017"/><a id="idIndexMarker018"/><a id="marker-32"/></p>

  <p class="fm-code-listing-caption">Listing 2.1 Examples of objective functions</p>
  <pre class="programlisting">import numpy as np
import math
import matplotlib.pyplot as plt
  
def objective_unimodal(x, y):           <span class="fm-combinumeral">①</span>
    return x**2.0 + y**2.0
  
def objective_multimodal(x, y):         <span class="fm-combinumeral">②</span>
    return np.sin(x) * np.cos(y)
  
def objective_deceptive(x, y):          <span class="fm-combinumeral">③</span>
    return (1-(abs((np.sin(math.pi*(x-2))*np.sin(math.pi*(y-2)))/
<span class="fm-code-continuation-arrow">➥</span>  (math.pi*math.pi*(x-2)*(y-2))))**5)*(2+(x-7)**2+2*(y-7)**2)
  
fig = plt.figure(figsize = (25,25))
ax = fig.add_subplot(1,3,1, projection='3d')
  
x = np.arange(-3, 3, 0.01)
y = np.arange(-3, 3, 0.01)
  
X, Y = np.meshgrid(x, y)
Z = objective_unimodal(X, Y)
surf = ax.plot_surface(X, Y, Z, cmap=plt.cm.cividis)
ax.set_xlabel('x', fontsize=15)
ax.set_ylabel('y', fontsize=15)
ax.set_zlabel('Z', fontsize=15)
ax.set_title("Unimodal/Convex function", fontsize=18)
  
ax = fig.add_subplot(1,3,2, projection='3d')
Z = objective_multimodal(X, Y)
surf = ax.plot_surface(X, Y, Z, cmap=plt.cm.cividis)
ax.set_xlabel('x', fontsize=15)
ax.set_ylabel('y', fontsize=15)
ax.set_zlabel('Z', fontsize=15)
ax.set_title("Multimodal function", fontsize=18)
  
X, Y = np.meshgrid(x, y)
Z = objective_unimodal(X, Y)
ax = fig.add_subplot(1,3,3, projection='3d')
Z = objective_deceptive(X, Y)
surf = ax.plot_surface(X, Y, Z, cmap=plt.cm.cividis, antialiased=False)
ax.set_xlabel('x', fontsize=15)
ax.set_ylabel('y', fontsize=15)
ax.set_zlabel('Z', fontsize=15)
ax.set_title("Deceptive function", fontsize=18)
  
plt.show()</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Unimodal function</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Multimodal function</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Deceptive function</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F04_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.4 Unimodal, multimodal, and deceptive functions. Unimodal functions have one global optimum, whereas multimodal functions can have many. Deceptive functions contain false optima close to the value of an objective function at a global minimum, which can cause some algorithms to get stuck.</p>
  </div>

  <p class="body"><a id="marker-33"/>If the quantity to be optimized is expressed using only one objective function, the problem is referred to as a mono-objective or single-objective optimization problem (such as convex or concave functions). A multi-objective optimization problem specifies multiple objectives to be simultaneously optimized. Problems without an explicit objective function are called constraint-satisfaction problems (CSPs). The goal in this case is to find a solution that satisfies a given set of constraints. <a id="idIndexMarker019"/></p>

  <p class="body">The <i class="timesitalic">n</i>-queen problem is an example of a CSP. In this problem, the aim is to put <i class="timesitalic">n</i> queens on an <span class="times"><i class="fm-italics">n</i> × <i class="fm-italics">n</i></span> board with no two queens on the same row, column, or diagonal, as illustrated in figure 2.5. In this 4-queen problem, there are 5 conflicts in the first state <span class="times">({Q1,Q2}, {Q1,Q3}, {Q2,Q3}, {Q2,Q4}</span>, and <span class="times">{Q3,Q4})</span>. After moving <span class="times">Q4</span>, the number of conflicts reduces by 2, and after moving <span class="times">Q3</span>, the number of conflicts is only 1, which is between <span class="times">Q1</span> and <span class="times">Q2</span>. <a id="idIndexMarker020"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F05_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.5 The <i class="timesitalic">n</i>-queen problem. This problem has no objective function, only a set of constraints that must be satisfied.</p>
  </div>

  <p class="body"><a id="marker-34"/>If we keep moving or placing the pieces, we can reach the goal state where the number of conflicts is 0, which means that no queen could attack any other queen horizontally, vertically, or diagonally. The next listing is a Python implementation of the 4-queen problem.</p>

  <p class="fm-code-listing-caption">Listing 2.2 <i class="fm-italics">n</i>-queen CSP<a id="idIndexMarker021"/></p>
  <pre class="programlisting">from copy import deepcopy
import math
import matplotlib.pyplot as plt
import numpy as np
  
board_size = 4
board = np.full((board_size, board_size), False)         <span class="fm-combinumeral">①</span>
  
def can_attack(board, row, col):
    if any(board[row]):                                  <span class="fm-combinumeral">②</span>
        return True                                      <span class="fm-combinumeral">②</span>
  
    offset = col - row                                   <span class="fm-combinumeral">③</span>
    if any(np.diagonal(board, offset)):                  <span class="fm-combinumeral">③</span>
        return True                                      <span class="fm-combinumeral">③</span>
    offset = (len(board) - 1 - col) - row                <span class="fm-combinumeral">③</span>
    if any(np.diagonal(np.fliplr(board), offset)):       <span class="fm-combinumeral">③</span>
        return True                                      <span class="fm-combinumeral">③</span>
 
    return False
  
board[0][0] = True
col = 1 
states = [deepcopy(board)]
while col &lt; board_size:
    row = 0
    while row &lt; board_size:
        if not can_attack(board, row, col):              <span class="fm-combinumeral">④</span>
            board[row][col] = True
            col += 1
            states.append(deepcopy(board))
            break
        row += 1
        if row == board_size:                            <span class="fm-combinumeral">⑤</span>
            board = np.delete(board, 0, 1)
            new_col = [[False]] * board_size
            board = np.append(board, new_col, 1)
            states.append(deepcopy(board))
            col -= 1
            continue</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Create an n x n board.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Check for a queen on the same row.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Check for queens on the diagonals.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> The piece can be placed in this column.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> The piece cannot be placed in this column.</p>

  <p class="body"><a id="marker-35"/>In the preceding listing, the <code class="fm-code-in-text">can_attack</code> function detects if a newly placed piece can attack a previously placed piece. A piece can attack another piece if it is in the same row, column, or diagonal. Figure 2.6 shows the solution obtained after six steps.<a id="idIndexMarker022"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F06_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.6 <i class="timesitalic">n</i>-queen solution</p>
  </div>

  <p class="body">The first piece is trivially placed in the first position. The second piece must be placed either in the third or fourth position, as the first two can be attacked. By placing it in the third position, however, the third piece cannot be placed. Thus, the first piece is removed (the board is “slid” one column over), and we try again. This continues until a solution is found.</p>

  <p class="body">The full code for this problem, including the code used to generate visualizations, can be found in the code file for listing 2.2, available in the book’s GitHub repo. The solution algorithm is as follows:</p>

  <ol class="calibre7">
    <li class="fm-list-bullet">
      <p class="list">Moving from top to bottom in a column, the algorithm attempts to place the piece while avoiding conflicts. For the first column, this will default to <span class="times">Q1 = 0</span>.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Moving to the next column, if a piece cannot be placed at row 0, it will be placed at row 1, and so on.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">When a piece has been placed, the algorithm moves to the next column.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">If it is impossible to place a piece in a given column, the first column of the entire board is removed, and the current column is reattempted.</p>
    </li>
  </ol>

  <p class="body"><a id="marker-36"/>Constraint programming solvers available in Google OR-Tools can also be used to solve this <span class="times"><i class="fm-italics">n</i> × <i class="fm-italics">n</i></span> queen problem. The next listing shows the steps of the solution using OR-Tools.</p>

  <p class="fm-code-listing-caption">Listing 2.3 Solving the <i class="fm-italics">n</i>-queen problem using OR-Tools</p>
  <pre class="programlisting">import numpy as np
import matplotlib.pyplot as plt
import math
from ortools.sat.python import cp_model                          <span class="fm-combinumeral">①</span>
  
board_size = 4 
                                                                 <span class="fm-combinumeral">②</span>
model = cp_model.CpModel()                                       <span class="fm-combinumeral">③</span>
  
queens = [model.NewIntVar(0, board_size - 1, 'x%i' % i) 
<span class="fm-code-continuation-arrow">➥</span>for i in range(board_size)]                                    <span class="fm-combinumeral">④</span>
  
model.AddAllDifferent(queens)                                    <span class="fm-combinumeral">⑤</span>
  
model.AddAllDifferent(queens[i] + i for i in range(board_size))
model.AddAllDifferent(queens[i] - i for i in range(board_size))
  
solver = cp_model.CpSolver()                                     <span class="fm-combinumeral">⑥</span>
solver.parameters.enumerate_all_solutions = True                 <span class="fm-combinumeral">⑥</span>
solver.Solve(model)                                              <span class="fm-combinumeral">⑥</span>
  
  
all_queens = range(board_size)                                   <span class="fm-combinumeral">⑦</span>
state=[] 
for i in all_queens:
    for j in all_queens:
        if solver.Value(queens[j]) == i:
            # There is a queen in column j, row i.
            state.append(True)
        else:
            state.append(None)     
            
states=np.array(state).reshape(-1, board_size)
fig = plt.figure(figsize=(5,5))                                 <span class="fm-combinumeral">⑧</span>
markers = [                                                     <span class="fm-combinumeral">⑧</span>
    x.tolist().index(True) if True in x.tolist() else None      <span class="fm-combinumeral">⑧</span>
    for x in np.transpose(states)                               <span class="fm-combinumeral">⑧</span>
]                                                               <span class="fm-combinumeral">⑧</span>
res = np.add.outer(range(board_size), range(board_size)) % 2    <span class="fm-combinumeral">⑧</span>
plt.imshow(res, cmap="binary_r")                                <span class="fm-combinumeral">⑧</span>
plt.xticks([])                                                  <span class="fm-combinumeral">⑧</span>
plt.yticks([])                                                  <span class="fm-combinumeral">⑧</span>
plt.plot(markers, marker="*", linestyle="None",                 <span class="fm-combinumeral">⑧</span>
<span class="fm-code-continuation-arrow">➥</span>markersize=100/board_size, color="y")H                        <span class="fm-combinumeral">⑧</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Import a constraint programming solver that uses SAT (satisfiability) methods.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Set the board size for the n x n queen problem.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Define a solver.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Define the variables. The array index represents the column, and the value is the row.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Define the constraint: all rows must be different.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Solve the model.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> Define the constraint: no two queens can be on the same diagonal.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑧</span> Visualize the solution.</p>

  <p class="body">Running this code produces the output in figure 2.7. More information about Google OR-Tools is available in appendix A.<a id="idIndexMarker023"/><a id="idIndexMarker024"/><a id="idIndexMarker025"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F07_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.7 The <i class="fm-italics">n</i>-queen solution using OR-Tools</p>
  </div>

  <h3 class="fm-head1" id="heading_id_6">2.1.3 Constraints</h3>

  <p class="body"><a id="marker-37"/>Constrained problems have hard or soft constraints for equality, inequality, or both. Hard constraints must be satisfied, while soft constraints are nice to satisfy (but are not mandatory). If there are no constraints to be considered, aside from the boundary constraints, the problem is an unconstrained optimization problem. <a id="idIndexMarker026"/><a id="idIndexMarker027"/></p>

  <p class="body">Let’s revisit the ticket pricing problem introduced in section 1.3.1. There is a wide range of derivative-based solvers in Python that can handle such kinds of differentiable mathematical optimization problems (see appendix A). The next listing shows how you can solve this simple ticket pricing problem using SciPy. SciPy is a library containing valuable tools for all things computation.</p>

  <p class="fm-code-listing-caption">Listing 2.4 Optimal ticket pricing</p>
  <pre class="programlisting">import numpy as np
import scipy.optimize as opt
import matplotlib.pyplot as plt
  
def f(x):                                                      <span class="fm-combinumeral">①</span>
    return -(-20*x**2+6200*x-350000)/1000 
 
res=opt.minimize_scalar(f, method='bounded', bounds=[0, 250])  <span class="fm-combinumeral">②</span>
  
print("Optimal Ticket Price ($): %.2f" % res.x)
print("Profit f(x) in K$: %.2f" % -res.fun)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> The objective function, required by minimize_scalar to be a minimization function</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> The bounded method is the constrained minimization procedure that finds the solution.</p>

  <p class="body">Running this code produces the following output:</p>
  <pre class="programlisting">Optimal Ticket Price ($): 155.00
Profit f(x) in K$: 130.50</pre>

  <p class="body">This code finds the optimal ticket price in the range between $0 and $250 that maximizes the profit. As you may have noticed, the profit formula is converted into a minimization problem by adding a negative sign in the objective function to match with the <code class="fm-code-in-text">minimize</code> function in <code class="fm-code-in-text">scipy.optimize</code>. A minus sign is added in the <code class="fm-code-in-text">print</code> function to convert it back into profit.<a id="idIndexMarker028"/><a id="idIndexMarker029"/><a id="idIndexMarker030"/><a id="marker-38"/></p>

  <p class="body">What if we imposed an equality constraint on this problem? Let’s assume that due to incredible international demand for our event, we are now considering using a different event planning company and opening up virtual attendance for our conference so that international guests can also participate. Interested participants can now choose between attending the event in person or joining via a live stream. All participants, whether in-person or virtual, will receive a physical welcome package, which is limited to 10,000 units. Thus, in order to ensure a “full” event, we must either sell 10,000 in-person tickets, 10,000 virtual tickets, or some combination thereof. The new event company is charging us a $1,000,000 flat rate for the event, so we want to sell as many tickets as possible (exactly 10,000). The following equation is associated with this problem:</p>

  <p class="body">Let <i class="timesitalic">x</i> be the number of physical ticket sales, and let <i class="timesitalic">y</i> be the number of virtual ticket sales. Additionally, let <span class="times"><i class="fm-italics">f</i>(<i class="fm-italics">x</i>,<i class="fm-italics">y</i>)</span> be the function for profits generated from the event, where</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figuree"><img alt="" class="calibre4" src="../Images/CH02_F07_Khamis-EQ02.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">2.2</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">Essentially, we earn $155 profit on in-person attendance, and the profit for online attendance is $70, but it increases by some amount with the more physical attendance we have (let’s say that as the event looks “more crowded,” we can charge more for online attendees).</p>

  <p class="body">Suppose we add a constraint function, <span class="times"><i class="fm-italics">x</i> + <i class="fm-italics">y</i> ≤ 10000</span>, which shows that the combined ticket sales cannot exceed 10,000. The problem is now a bivariate mono-objective constrained optimization problem. It is possible to convert this constrained optimization problem to an unconstrained optimization using the Lagrange multiplier, <span class="cambria">λ</span>. We can use SymPy to implement Lagrange multipliers and solve for the optimal mix of virtual and physical ticket sales. The idea is to convert the constrained optimization problem defined by the objective function <span class="times"><i class="fm-italics">f</i>(<i class="fm-italics">x</i>,<i class="fm-italics">y</i>)</span> with an equality constraint <span class="times"><i class="fm-italics">g</i>(<i class="fm-italics">x</i>,<i class="fm-italics">y</i>)</span> into an unconstrained optimization problem using the Lagrangian function <span class="times"><i class="fm-italics">L</i>(<i class="fm-italics">x</i>,y,<span class="cambria">λ</span>) = <i class="fm-italics">f</i>(<i class="fm-italics">x</i>,<i class="fm-italics">y</i>) + <i class="fm-italics">λg</i>(<i class="fm-italics">x</i>,<i class="fm-italics">y</i>)</span>. This function combines an objective function and constraints, enabling constrained optimization problems to be formulated as unconstrained problems through the use of Lagrange multipliers. To do so, we take the partial derivatives of the objective functions and the constraints, with respect to the decision variables <i class="timesitalic">x</i> and <i class="timesitalic">y</i>, to form the unconstrained optimization equations to be used by the SymPy solver, as illustrated in figure 2.8.<a id="idIndexMarker031"/><a id="idIndexMarker032"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F08_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.8 Steps for solving the ticket pricing problem using the Lagrange method</p>
  </div>

  <p class="body">The next listing shows the Python implementation using SymPy. <a id="idIndexMarker033"/><a id="marker-39"/></p>

  <p class="fm-code-listing-caption">Listing 2.5 Maximizing profits using Lagrange multipliers</p>
  <pre class="programlisting">import sympy as sym
  
x,y=sym.var('x, y', positive=True)                     <span class="fm-combinumeral">①</span>
  
f=155*x+(0.001*x**sym.Rational(3,2)+70)*y-1000000      <span class="fm-combinumeral">②</span>
  
g=x+y-10000                                            <span class="fm-combinumeral">③</span>
  
lamda=sym.symbols('lambda')                            <span class="fm-combinumeral">④</span>
Lagr=f-lamda*g                                         <span class="fm-combinumeral">⑤</span>
  
eqs = [sym.diff(Lagr, x), sym.diff(Lagr, y), g]        <span class="fm-combinumeral">⑥</span>
  
sol=sym.solve(eqs,[x,y,lamda], dict=True)              <span class="fm-combinumeral">⑦</span>
   
def getValueOf(k, L):
    for d in L:
        if k in d:
            return d[k]
  
profit=[f.subs(p) for p in sol]
  
print("optimal number of physical ticket sales: x = %.0f" % getValueOf(x, sol))
print("optimal number of online ticket sales: y = %.0f" % getValueOf(y, sol))
print("Expected profil: f(x,y) = $%.4f" % profit[0])</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Define the decision variables.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Define the ticket pricing objective function.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Define the equality constraint.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Lagrange multiplier</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Lagrangian function</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Equations to the solver</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> Solve these three equations in three variables (x,y,lambda) using SymPy.</p>

  <p class="body">By solving the preceding three equations, we get <i class="timesitalic">x</i> and <i class="timesitalic">y</i> values that correspond to the optimized quantities for virtual and physical ticket sales. With the code in listing 2.5, we can see that the best result is to sell 6,424 in-person tickets and 3,576 online tickets. This results in a maximum profit of $2,087,260.</p>

  <h3 class="fm-head1" id="heading_id_7">2.1.4 Linearity of objective functions and constraints</h3>

  <p class="body"><a id="marker-40"/>If all the objective functions and associated constraint conditions are linear, the optimization problem is categorized as a <i class="fm-italics">linear optimization problem</i> or <i class="fm-italics">linear programming problem</i> (LPP or LP), where the goal is to find the optimal value of a linear function subject to linear constraints. Blending problems are a typical application of mixed integer linear programming (MILP), where a number of ingredients are to be blended or mixed to obtain a product with certain characteristics or properties. In the animal feed mix problem described in Paul Jensen’s <i class="fm-italics">Operations Research Models and Methods</i> [4], the optimum amounts of three ingredients in an animal feed mix need to be determined. The possible ingredients, their nutritive contents (in kilograms of nutrient per kilograms of ingredient), and the unit costs are shown in table 2.1.</p>

  <p class="fm-table-caption">Table 2.1 Animal feed mix problem</p>

  <table border="1" class="contenttable-1-table" id="table001" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="20%"/>
    </colgroup>

    <thead class="calibre6">
      <tr class="contenttable-0-tr">
        <th class="contenttable-1-th" rowspan="2">
          <p class="fm-table-head">Ingredients</p>
        </th>

        <th class="contenttable-1-th" colspan="4">
          <p class="fm-table-head">Nutritive content and price of ingredients</p>
        </th>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Calcium (kg/kg)</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Protein (kg/kg)</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Fiber (kg/kg)</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Unit cost (cents/kg)</p>
        </td>
      </tr>
    </thead>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Corn</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.001</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.09</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.02</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">30.5</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Limestone</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.38</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.0</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.0</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">10.0</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Soybean meal</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.002</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.50</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.08</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">90.0</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">The mixture must meet the following restrictions:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Calcium—At least 0.8% but not more than 1.2%</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Protein—At least 22%</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Fiber—At most 5%</p>
    </li>
  </ul>

  <p class="body">The problem is to find the mixture that satisfies these constraints while minimizing cost. The decision variables are <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span>, <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">2</sub></span>, and <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">3</sub></span>, which are proportions of limestone, corn, and soybean meal respectively.</p>

  <p class="body">The objective function <span class="times"><i class="fm-italics">f</i> = 30.5<i class="fm-italics">x</i><sub class="fm-subscript">1</sub> + 10<i class="fm-italics">x</i><sub class="fm-subscript">2</sub> + 90<i class="fm-italics">x</i><sub class="fm-subscript">3</sub></span> needs to be minimized, subject to the following constraints:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Calcium limits: <span class="times">0.008 ≤ 0.001<i class="fm-italics">x</i><sub class="fm-subscript">1</sub> + 0.38<i class="fm-italics">x</i><sub class="fm-subscript">2</sub> + 0.002<i class="fm-italics">x</i><sub class="fm-subscript">3</sub> ≤ 0.012</span></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Protein constraint: <span class="times">0.09<i class="fm-italics">x</i><sub class="fm-subscript">1</sub> + 0.5<i class="fm-italics">x</i><sub class="fm-subscript">3</sub> ≥ 0.22</span></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Fiber constraint: <span class="times">0.02<i class="fm-italics">x</i><sub class="fm-subscript">1</sub> + 0.08<i class="fm-italics">x</i><sub class="fm-subscript">3</sub> &lt;= 0.05</span></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Non-negativity restriction: <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub>, <i class="fm-italics">x</i><sub class="fm-subscript">2</sub>, <i class="fm-italics">x</i><sub class="fm-subscript">2</sub> ≥ 0</span></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Conservation: <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">2</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">2</sub> = 1</span></p>
    </li>
  </ul>

  <p class="body">In this problem, both the objective function and the constraints are linear, so it is an LPP. There are several Python libraries that can be used to solve mathematical optimization problems.</p>

  <p class="body">We’ll try solving the animal feed mix problem using PuLP. PuLP is a Python linear programming library that allows users to define linear programming problems and solve them using optimization algorithms such as COIN-OR’s linear and integer programming solvers. See appendix A for more information about PuLP and other mathematical programming solvers. The next listing shows the steps for solving the animal feed mix problem using PuLP.<a id="marker-41"/></p>

  <p class="fm-code-listing-caption">Listing 2.6 Solving a linear programming problem using PuLP</p>
  <pre class="programlisting">from pulp import *
  
model = LpProblem("Animal_Feed_Mix_Problem", LpMinimize)                    <span class="fm-combinumeral">①</span>
  
x1 = LpVariable('Corn', lowBound = 0, upBound = 1, cat='Continous')         <span class="fm-combinumeral">②</span>  
x2 = LpVariable('Limestone', lowBound = 0, upBound = 1, cat='Continous')    <span class="fm-combinumeral">②</span>
x3 = LpVariable('Soybean meal', lowBound = 0, upBound = 1, cat='Continous') <span class="fm-combinumeral">②</span>
  
  
model += 30.5*x1 + 10.0*x2 + 90*x3, 'Cost'                                  <span class="fm-combinumeral">③</span>
  
model +=0.008 &lt;= 0.001*x1 + 0.38*x2 + 0.002*x3 &lt;= 0.012, 'Calcium limits'   <span class="fm-combinumeral">④</span>
model += 0.09*x1 + 0.5*x3 &gt;=0.22, 'Minimum protein'                         <span class="fm-combinumeral">④</span>
model += 0.02*x1 + 0.08*x3 &lt;=0.05, 'Maximum fiber'                          <span class="fm-combinumeral">④</span>
model += x1+x2+x3 == 1, 'Conservation'                                      <span class="fm-combinumeral">④</span>
  
model.solve()                                                               <span class="fm-combinumeral">⑤</span>
  
for v in model.variables():                                                 <span class="fm-combinumeral">⑥</span>
    print(v.name, '=', round(v.varValue,2)*100, '%')                        <span class="fm-combinumeral">⑥</span>
                                                                            <span class="fm-combinumeral">⑥</span>
print('Total cost of the mixture per kg = ',                                <span class="fm-combinumeral">⑥</span>
    <span class="fm-code-continuation-arrow">➥</span>round(value(model.objective)/100, 2), '$')                            <span class="fm-combinumeral">⑥</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Create a linear programming model.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Define three variables that represent the percentages of corn, limestone, and soybean meal in the mixture.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Define the total cost as theobjective function to be minimized.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Add the constraints.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Solve the problem using PuLP’s choice of solver.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Print the results (the optimal percentages of the ingredients and the cost of the mixture per kg)</p>

  <p class="body">As you can see in this listing, we start by importing PuLP and creating a model as a linear programming problem. We then define LP variables with the associated parameters, such as name, lower bound, and upper bound for each variable’s range and the type of variable (e.g., integer, binary, or continuous). A solver is then used to solve the problem. PuLP supports several solvers, such as GLPK, GUROBI, CPLEX, and MOSEK. The default solver in PuLP is Cbc (COIN-OR branch and cut). Running this code gives the following output:</p>
  <pre class="programlisting">Corn = 65.0%
Limestone = 3.0%
Soybean_meal = 32.0%
Total cost of the mixture per kg = 0.4916$</pre>

  <p class="body">If one of the objective functions, or at least one of the constraints, is nonlinear, the problem is considered a nonlinear optimization problem or nonlinear programming problem (NLP), and it’s harder to solve than a linear problem. A special case of NLP, when the objective function is quadratic, is called quadratic programming (QP). For example, the plant layout problem (PLP) or facility location problem (FLP) is a quadratic assignment problem (QAP) that aims at assigning different facilities (departments) <i class="timesitalic">F</i> to different locations <i class="timesitalic">L</i> in order to minimize a given function cost, such as the total material handling cost, as shown in figure 2.9. <a id="idIndexMarker034"/><a id="idIndexMarker035"/><a id="idIndexMarker036"/><a id="idIndexMarker037"/><a id="idIndexMarker038"/><a id="marker-42"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F09_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.9 Plant layout problem—what is the optimal location for each department that minimizes the overall material handling costs?</p>
  </div>

  <p class="body">Assume that <span class="times"><span class="cambria">ω</span><sub class="fm-subscript">ij</sub></span> is the frequency of interaction or the flow of products between these facilities and <i class="timesitalic">d<sub class="fm-subscript">f(i)f(j)</sub></i> is the distance between facilities <i class="timesitalic">i</i> and <i class="timesitalic">j</i>. The material handling cost (MHC) is</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <p class="fm-equation">MHC<sub class="fm-subscript">ij</sub> = flow × distance = 𝜔<sub class="fm-subscript">ij</sub> × <i class="fm-italics">d<sub class="fm-subscript">f</sub></i><sub class="fm-subscript">(</sub><i class="fm-italics"><sub class="fm-subscript">i</sub></i><sub class="fm-subscript">)</sub><i class="fm-italics"><sub class="fm-subscript">f</sub></i><sub class="fm-subscript">(</sub><i class="fm-italics"><sub class="fm-subscript">j</sub></i><sub class="fm-subscript">)</sub></p>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">2.3</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">and the total material handling cost (TMHC) is the summation of all the material handling costs inside the material handling cost matrix. In matrix notation, the problem can be formulated as</p>

  <p class="fm-equation">Find <i class="fm-italics">X</i> which minimizes <i class="fm-italics">trace</i>(<i class="fm-italics">WXDX<sup class="fm-superscript">T</sup></i>)</p>

  <p class="body">where <i class="timesitalic">X</i> represents the assignment vector, <i class="timesitalic">W</i> is the flow matrix, and <i class="timesitalic">D</i> is the distance matrix. Trace is the sum of elements on the main diagonal (from the upper left to the lower right) of the resultant material handling cost matrix.</p>

  <p class="body">In a more general case, NLP includes nonlinear objective functions, or at least nonlinear constraints, of any form. For example, imagine you’re designing a landmine detection and disposal unmanned ground vehicle (UGV) [5]. In outdoor applications like humanitarian demining, UGVs should be able to navigate through rough terrain. Sandy soils, rocky terrain with obstacles, steep inclines, ditches, and culverts can be difficult for vehicles to negotiate. The locomotion systems of such vehicles need to carefully designed to guarantee motion fluidity. <a id="idIndexMarker039"/></p>

  <p class="body">Assume that you are in charge of finding optimal values for wheel parameters (e.g., diameter, width, and loading) that will</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Minimize the wheel sinkage, which is the maximum amount the wheel sinks in the soil that it is moving on</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Minimize motion resistance, which is the overall resistance faced by the UGV unit due to the different components of resistance (compaction, gravitational, etc.)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Minimize drive torque, which is the driving torque required from the actuating motors for each wheel</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Minimize drive power, which is the driving power required from the actuating motors for each wheel</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Maximize the slope negotiability, which represents the maximum slope that can be climbed by the UGV unit considering its weight and the soil parameters.</p>
    </li>
  </ul>

  <p class="body">Due to availability in the market or manufacturing concerns and costs, the wheel diameter should be in the range of 4 to 8.2 inches, wheel width should be in the range of 3 to 5 inches, and wheel loading should be in the range of 22 to 24 pounds per wheel. This wheel design problem (figure 2.10) can be stated as follows: <a id="idIndexMarker040"/><a id="marker-43"/></p>

  <p class="body">Find <i class="timesitalic">X</i> which optimizes <i class="timesitalic">ƒ</i>, subject to a possible set of boundary constraints, where <i class="timesitalic">X</i> is a vector that is composed of a number of decision variables such as</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = wheel diameter</span>, <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> <span class="cambria">∈</span> [4, 8.2]</span></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">2</sub> = wheel width</span>, <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">2</sub> <span class="cambria">∈</span> [3, 5]</span></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">3</sub> = wheel loading</span>, <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">2</sub> <span class="cambria">∈</span> [22, 24]</span></p>
    </li>
  </ul>

  <p class="body">We can also consider the objective functions <span class="times"><i class="fm-italics">ƒ</i>={<i class="fm-italics">ƒ</i><sub class="fm-subscript">1</sub>, <i class="fm-italics">ƒ</i><sub class="fm-subscript">2</sub>,…}</span>. For example, the function for wheel sinkage might look like this:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figuree"><img alt="" class="calibre4" src="../Images/CH02_F09_Khamis-EQ05.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">2.4</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">where <i class="timesitalic">n</i> is the exponent of sinkage, <span class="times"><i class="fm-italics">k</i><sub class="fm-subscript">c</sub></span> is the cohesive modulus of soil deformation, and <span class="times"><i class="fm-italics">k</i><sub class="fm-subscript">φ</sub></span> is the frictional modulus of soil deformation. This problem is considered to be nonlinear because the objective function is nonlinear.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F10_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.10 The MineProbe wheel design problem [5]</p>
  </div>

  <p class="body"><a id="marker-44"/>The catenary problem discussed in Veselić’s “Finite catenary and the method of Lagrange” article [6] is another example of a nonlinear optimization problem. A catenary is a flexible hanging object composed of multiple parts, such as a chain or telephone cable (figure 2.11). In this problem, we are provided with <i class="timesitalic">n</i> homogenous beams, with lengths <span class="times"><i class="fm-italics">d</i><sub class="fm-subscript">1</sub></span>, <span class="times"><i class="fm-italics">d</i><sub class="fm-subscript">2</sub>, … <i class="fm-italics">d</i><sub class="fm-subscript">n</sub> &gt; 0</span> and masses <span class="times"><i class="fm-italics">m</i><sub class="fm-subscript">1</sub>, <i class="fm-italics">m</i><sub class="fm-subscript">2</sub>, … <i class="fm-italics">m</i><sub class="fm-subscript">n</sub> &gt; 0</span>, which are connected by <span class="times"><i class="fm-italics">n</i> + 1</span> joints <span class="times"><i class="fm-italics">G</i><sub class="fm-subscript">0</sub></span>, <span class="times"><i class="fm-italics">G</i><sub class="fm-subscript">2</sub>, … <i class="fm-italics">G</i><sub class="fm-subscript">n</sub> <sub class="fm-subscript">+ 1</sub></span>. The location of each joint is represented by the Cartesian coordinates <span class="times">(<i class="fm-italics">x<sub class="fm-subscript">i</sub></i>,<i class="fm-italics">y<sub class="fm-subscript">i</sub></i>,<i class="fm-italics">z<sub class="fm-subscript">i</sub></i>)</span>. The ends of the catenary are <span class="times"><i class="fm-italics">G</i><sub class="fm-subscript">0</sub></span> and <span class="times"><i class="fm-italics">G</i><sub class="fm-subscript">n</sub> <sub class="fm-subscript">+ 1</sub></span>, which both have the same <i class="timesitalic">y</i> and <i class="timesitalic">z</i> values (they are at the same height and in line with each other).<a id="idIndexMarker041"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F11_Khamis.png"/><a id="idIndexMarker042"/></p>

    <p class="figurecaption">Figure 2.11 Finite catenary problem—the catenary (or chain) is suspended from two points, <span class="times">G</span><sub class="fm-subscript">0</sub> and <span class="times">G</span><sub class="fm-subscript">n</sub> <sub class="fm-subscript">+ 1</sub>.<a id="idIndexMarker043"/><a id="idIndexMarker044"/></p>
  </div>

  <p class="body">Assuming that the beam lengths and masses are predefined parameters, our goal is to look for stable equilibrium positions in the field of gravity—those positions where the potential energy is minimized. The potential energy to be minimized is defined as follows:<a id="idIndexMarker045"/></p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figuree"><img alt="" class="calibre4" src="../Images/CH02_F11_Khamis-EQ06.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">2.5</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">subject to the following constraints:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figuree"><img alt="" class="calibre4" src="../Images/CH02_F11_Khamis-EQ07.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">2.6<a class="calibre" id="idIndexMarker046"/></p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">where <i class="timesitalic">γ</i> is the gravitational constant. The nonlinearity of the constraints makes this problem nonlinear, despite having a linear objective function.<a id="idIndexMarker047"/><a id="idIndexMarker048"/></p>

  <h3 class="fm-head1" id="heading_id_8">2.1.5 Expected quality and permissible time for the solution</h3>

  <p class="body"><a id="marker-45"/>Optimization problems can also be categorized according to the expected quality of the solutions and the time allowed to find the solutions. Figure 2.12 shows three main types of problems: design problems (strategic functions), planning problems (tactical functions), and control problems (operational functions).<a id="idIndexMarker049"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F12_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.12 Qualities of solutions vs. search time. Some types of problems require fast computations but do not require incredibly accurate results, while others (such as design problems) allow more processing time in return for higher accuracy.</p>
  </div>

  <p class="body">In <i class="fm-italics">design problems</i>, time is not as important as the quality of the solution, and users are willing to wait (sometimes even a few days) to get an optimal, or near-optimal, result. These problems can be solved offline, and the optimization process is usually carried out only once in a long time. Examples of design problems include vehicle design, class scheduling, asset allocation, resource planning, assembly line balancing, inventory management, flight scheduling, and political districting.</p>

  <p class="body">Let’s discuss political districting as a design problem in more detail. Districting is the problem of grouping small geographic areas, called <i class="fm-italics">basic units</i>, into larger geographic clusters, called <i class="fm-italics">districts</i>, in such a way that the latter are acceptable according to relevant planning criteria [7]. Typical examples of basic units are customers, streets, or zip code areas. The planning criteria may include the following:<a id="idIndexMarker050"/><a id="idIndexMarker051"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Balance or equity in terms of demographic background, equitable size, balanced workload, equal sales potential, or the number of customers</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Contiguity to enable traveling between the basic units of the district without having to leave the district</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Compactness to allow for round- or square-shaped undistorted districts without holes</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Respect of boundaries, such as administrative boundaries, railroads, rivers, or mountains</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Socio-economic heterogeneity, to allow for better representation of residents with different incomes, ethnicities, concerns, or views</p>
    </li>
  </ul>

  <p class="body">Political districting, school districting, districting for health services, districting for EV charging stations, districting for micro-mobility stations (e.g., for e-bikes and e-scooters), and districting for sales or delivery are all examples of districting problems.</p>

  <p class="body"><a id="marker-46"/>Political districting is a problem that has plagued societies since the advent of representative democracy in the Roman Republic. In a representative democracy, officials are nominated and elected to represent the interests of the people who elected them. In order to have a greater say when deciding on matters that concern the entire state, the party system came about, which defines political platforms that nominees use to differentiate themselves from their competitors. Manipulating the shapes of electoral districts to determine the outcome of elections is called <i class="fm-italics">gerrymandering</i> (named after the early nineteenth century Massachusetts governor Elbridge Gerry who redrew the map of the Senate’s districts in 1810 in order to weaken the opposing federalist party). Figure 2.13 shows how manipulating the shapes of the districts can sway the vote in favor of a decision that otherwise wouldn’t have won.<a id="idIndexMarker052"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F13_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.13 Example of gerrymandering. The two major political parties, Shield and Bell, try to gain an advantage by manipulating the district boundaries to suppress undesired interests and promote their own.</p>
  </div>

  <p class="body">An effective and transparent political districting strategy is needed to avoid gerrymandering and generate a solution that preserves the integrity of individual subdistricts and divides the population into almost equal voting populations in a reproducible way. In many countries, electoral districts are reviewed from time to time to reflect changes and movements in the country’s population. For example, the Constitution of Canada requires that federal electoral districts be reviewed after each 10-year census.</p>

  <p class="body">Political districting is defined as aggregating <i class="timesitalic">n</i> subregions of a territory into <i class="timesitalic">m</i> electoral districts subject to constraints such as</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">The districts should have near-equal voting population.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">The socioeconomic homogeneity inside each district, as well as the integrity of different communities, should be maximized.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">The districts have to be compact, and the subregions of each district have to be contiguous.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Subregions should be considered as indivisible political units, and their boundaries should be respected.</p>
    </li>
  </ul>

  <p class="body">The problem can be formulated as an optimization problem in which a function that quantifies the preceding factors is maximized. Here is an example of this function:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <p class="fm-equation"><i class="fm-italics">F</i>(<i class="fm-italics">x</i>) = <i class="fm-italics">α</i><sub class="fm-subscript">pop</sub><i class="fm-italics">ƒ</i><sub class="fm-subscript">pop</sub>(<i class="fm-italics">x</i>) + <i class="fm-italics">α</i><sub class="fm-subscript">comp</sub><i class="fm-italics">ƒ</i><sub class="fm-subscript">comp</sub>(<i class="fm-italics">x</i>) + <i class="fm-italics">α</i><sub class="fm-subscript">soc</sub><i class="fm-italics">ƒ</i><sub class="fm-subscript">soc</sub>(<i class="fm-italics">x</i>) + <i class="fm-italics">α</i><sub class="fm-subscript">sim</sub><i class="fm-italics">ƒ</i><sub class="fm-subscript">sim</sub>(<i class="fm-italics">x</i>)</p><!--<div class="figure"><p class="figureE"><img alt="" src="../PNGs/CH02_F13_Khamis-EQ08.png" /></p></div>-->
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">2.7</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">where <i class="timesitalic">x</i> is a solution to the problem or the electoral districts, <span class="times1">α<sub class="fm-subscript">i</sub></span> are user-specified multipliers <span class="times">0 ≤ <span class="cambria">α</span><sub class="fm-subscript">i</sub> ≤ 1</span>, and <span class="times"><i class="fm-italics">ƒ</i><sub class="fm-subscript">pop</sub>, <i class="fm-italics">ƒ</i><sub class="fm-subscript">comp</sub>, <i class="fm-italics">ƒ</i><sub class="fm-subscript">soc</sub>, <i class="fm-italics">ƒ</i><sub class="fm-subscript">int</sub></span>, and <span class="times"><i class="fm-italics">ƒ</i><sub class="fm-subscript">sim</sub></span> are functions that quantify the population equality, compactness of districts, socioeconomic homogeneity, integrity of different communities, and similarity to existing districts respectively. In the upcoming chapters, I will show you how we can use offline optimization algorithms to handle optimal multicriteria assignment design problems.</p>

  <p class="body"><i class="fm-italics">Planning problems</i> need to be solved faster than design problems, in a time span from a few seconds to a few minutes. To find a solution in such a short time, optimality is usually traded for speed. Examples of planning problems include vehicle motion planning, emergency vehicle dispatching and routing, patient admission scheduling, surgery scheduling, and crew scheduling. Let’s consider the ride-sharing problem as an example of a planning problem. <a id="idIndexMarker053"/><a id="marker-47"/></p>

  <p class="body">Ride-sharing involves a fleet of pay-per-use vehicles and a set of passengers with predefined pick-up and drop-off points (figure 2.14). The dispatch service needs to assign a set of passengers in a specific order to each driver to achieve a set of objectives. This ride-sharing problem is a multi-objective constrained optimization problem. A noncomprehensive list of optimization goals for ride-sharing includes<a id="idIndexMarker054"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Minimizing the total travel distance or time of drivers’ trips</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Minimizing the total travel time of passengers’ trips</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Maximizing the number of matched (served) requests</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Minimizing the cost of the drivers’ trips</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Minimizing the cost of the passengers’ trips</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Maximizing the drivers’ earnings</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Minimizing passengers’ waiting time</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Minimizing the total number of drivers required</p>
    </li>
  </ul>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F14_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.14 Ride-sharing problem—this planning problem needs to be solved in a shorter amount of time, as delays could mean lost trips and a bad user experience.</p>
  </div>

  <p class="body">For the ride-sharing problem, both the search time and the quality of the solutions are important. On many popular ride-sharing platforms, dozens if not hundreds of users may simultaneously be searching for rides at the same place in a given district. Overly costly and time-consuming solutions would lead to higher operating costs (i.e., employing more drivers than necessary or calling in drivers from other districts) as well as the potential for lost business (bad user experiences may dissuade passengers from using the platform a second time) and high driver turnover.</p>

  <p class="body">In practice, the assignment of drivers to passengers goes well beyond the distance between passenger and driver—it may also include factors such as driver reliability, passenger rating, vehicle type, and pickup and destination location types. For example, a customer going to the airport may request a larger vehicle to accommodate luggage. In the upcoming chapters, we will discuss how to solve planning problems using different search and optimization algorithms.</p>

  <p class="body"><a id="marker-48"/><i class="fm-italics">Control problems</i> require very fast solutions in real time. In most cases, this means a time span from a millisecond to a few seconds. Vehicle lateral or longitudinal motion control, surgical robot motion control, disruptions management, and ad hoc communication relaying are examples of control problems. Online optimization algorithms are required to handle these kinds of problems. Optimization tasks in both planning and control problems are often carried out repetitively—new orders will, for instance, continuously arrive in a production facility and need to be scheduled to machines in a way that minimizes the waiting time for all jobs. <a id="idIndexMarker055"/></p>

  <p class="body">Imagine a real-world situation where a swarm of unmanned aerial vehicles (UAVs) or micro aerial vehicles (MAVs) is deployed to search for victims trapped on untraversable terrain after a natural disaster, like an earthquake, avalanche, tsunami, tornado, wildfire, etc. The mission consists of two phases: a search phase and a relay phase. During the search phase, the MAVs will conduct a search according to the deployment algorithm. When a target is found, the swarm of MAVs will self-organize to utilize their range-limited communication capabilities and set up an ad hoc communication relay network between the victim and the base station, as illustrated in figure 2.15.<a id="idIndexMarker056"/><a id="idIndexMarker057"/><a id="marker-49"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F15_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.15 Communication relaying problem—a swarm of MAVs must form an ad hoc communication relay between a base station and a trapped victim. The movement of the MAVs is a control problem that must be solved repeatedly, multiple times per second. In this case, speed is more important than accuracy, as minor errors can be immediately corrected during the next cycle.<a id="idIndexMarker058"/></p>
  </div>

  <p class="body">During the search phase, MAVs can be deployed to maximize the area covered. After they detect a victim, the MAVs can be repositioned to maximize the victim’s visibility. The ad hoc communication relay network is then established to maximize the radio coverage in the swarm and find the shortest path between the MAV that detected the victim and the base station, given the following assumptions:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">MAVs are capable of situational awareness by combining data from three noise-prone sensors: a magnetic compass for direction, a speedometer for speed, and an altimeter for altitude.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">MAVs are capable of communicating via a standard protocol such as IEEE 802.11b with a limited range of 100 m.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">MAVs are capable of relaying ground signals as well as controlling signals sent among MAVs.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">MAVs have enough onboard power to sustain 30 minutes of continuous flight, at which point they must return to the base to recharge. However, the amount of flight time varies depending on the amount of signaling completed during flight.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">MAVs are capable of quickly accelerating to a constant flight speed of 10 m/s.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">MAVs are not capable of hovering and have a minimum turn radius of approximately 10 m.</p>
    </li>
  </ul>

  <p class="body">For control problems such as MAV repositioning, search time is of paramount importance. As the MAVs cannot hover and thus must remain in constant motion, delayed decisions may lead to unexpected situations, such as mid-air collisions or a loss of signal. As instructions are sent (or repeated) every few milliseconds, each MAV must be able to decide its next move within that span of time. A MAV must account not only for its current position, target position, and velocity, but must also consider obstacles, communications signal strength, wind, and other environmental effects. Minor errors are acceptable, as they can be corrected in subsequent searches. In the upcoming chapters, we will discuss how to solve control problems like this.</p>

  <p class="body">This book will largely focus on complex, ill-structured problems that cannot be handled by traditional mathematical optimization or derivative-based solvers. We’ll look at examples of design, planning and control problems in various domains. Next, let’s take a look at how search and optimization algorithms are classified.<a id="idIndexMarker059"/><a id="idIndexMarker060"/><a id="marker-50"/></p>

  <h2 class="fm-head" id="heading_id_9">2.2 Classifying search and optimization algorithms</h2>

  <p class="body">When we search, we try to examine different states to find a path from the start (initial) state to the goal state. Often, an optimization algorithm searches for an optimum solution by iteratively transforming a current state or a candidate solution into a new, hopefully better, solution. Search algorithms can be classified based on the way the search space is explored:<a id="idIndexMarker061"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Local search</i> uses only local information about the search space surrounding the current solution to produce new solutions. Since only local information is used, local search algorithms (also known as local optimizers) locate local optima (which may or may not be global optima).<a id="idIndexMarker062"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Global search</i> uses more information about the search space to locate global optima. <a id="idIndexMarker063"/></p>
    </li>
  </ul>

  <p class="body">In other words, global search algorithms explore the entire search space, while local search algorithms only exploit neighborhoods.</p>

  <p class="body">Yet another classification distinguishes between deterministic and stochastic algorithms, as illustrated in figure 2.16:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Deterministic algorithms</i> follow a rigorous procedure in their path, and both the values of their design variables and their functions are repeatable. From the same starting point, they will follow the same path, whether you run the program today or tomorrow. Examples include, but are not limited to, graphical methods, gradient and Hessian-based methods, penalty methods, gradient projection methods, and graph search methods. Graph search methods can be further subdivided into blind search methods (e.g., depth-first, breadth-first, or Dijkstra) and informed search methods (e.g., hill climbing, beam search, best-first, A*, or contraction hierarchies). Deterministic methods are covered in part 1 of this book.<a id="idIndexMarker064"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Stochastic algorithms</i> explicitly use randomness in their parameters or decision-making process or both. For example, genetic algorithms use some random or pseudo-random numbers, resulting in individual paths that are not exactly repeatable. With stochastic algorithms, the time taken to obtain an optimal solution cannot be accurately foretold. Solutions do not always get better, and stochastic algorithms sometimes miss the opportunity to find optimal solutions. This behavior can be advantageous, however, because it can prevent them from becoming trapped in local optima. Examples of stochastic algorithms include tabu search, simulated annealing, genetic algorithms, differential evolution algorithms, particle swarm optimization, ant colony optimization, artificial bee colony, firefly algorithm, etc. Most statistical machine learning algorithms are stochastic because they make use of randomness during the learning stage and they make predictions during the inference stage with a certain level of uncertainty. Moreover, some machine learning models are, like people, unpredictable. Models trained using human behavior-based data as independent variables are more likely to be unpredictable than those trained using independent variables that strictly follow physical laws. For example, the human intent recognition model is less predictable than a model that predicts the stress-strain curve of a material. Due to the uncertainty associated with machine learning predictions, machine learning–based algorithms used to solve optimization problems can be considered stochastic methods. Stochastic algorithms are covered in parts 2 to 5 of this book.<a id="idIndexMarker065"/><a id="marker-51"/></p>
    </li>
  </ul>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F16_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.16 Deterministic vs. stochastic algorithms. Deterministic algorithms follow a set procedure, and the results are repeatable, while stochastic searches have elements of randomness built into the algorithms.</p>
  </div>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">Treasure-hunting mission</p>

    <p class="fm-sidebar-text">The search for an optimal solution in a given search space can be likened to a treasure-hunting mission. Imagine you and a group of friends decided to visit an island looking for pirate treasure.<a id="idIndexMarker066"/></p>

    <p class="fm-sidebar-text">All the areas on the island (except the active volcano area) correspond to the feasible search space of the optimization problem. The treasure corresponds to the optimal solution in this feasible space. You and your friends are the “search agents” launched to search for the solution, each following different search approaches. If you don’t have any information that can guide you while searching, you are following a blind (uninformed) search approach, which is usually inefficient and time-consuming. If you know that the pirates used to hide the treasure in elevated spots, you could then directly climb up the steepest cliff and try to reach the highest peak. This scenario corresponds to the classic hill-climbing technique (informed search). Uninformed and informed search algorithms are presented in the next two chapters. You could also follow a trial-and-error approach, looking for hints and repeatedly moving from one place to another plausible place until you find the treasure. This corresponds to trajectory-based search, which we’ll discuss in part 2 of the book.</p>

    <p class="fm-sidebar-text">If you do not want to take the risk of getting nothing and decide to share information with your friends instead of treasure-hunting alone, you will be following a population-based search approach. While working in a team, you may notice that some treasure hunters show better performance than others. In this case, only better-performing hunters can be kept, and new ones can be recruited to replace the lesser-performing hunters. This is akin to evolutionary algorithms, such as genetic algorithms, where the fittest hunters survive. Genetic algorithms are covered in part 3 of the book. Alternatively, you and other friends can try to emulate the success of the outperforming hunters in each area of the treasure island without getting rid of any team members and without recruiting new ones. This scenario uses the so-called swarm intelligence and corresponds to population-based optimization algorithms such as particle swarm optimization, ant colony optimization, and artificial bee colony algorithm. These algorithms will be discussed in part 4 of the book.</p>

    <p class="fm-sidebar-text">You alone, or with the help of your friends, can build a mental model based on historical data of previous and similar treasure-hunting missions, or you can train a reward predictor based on trial-and-error interaction with the treasure island (search space), taking the strength of the metal detector signal as a reward indicator. After a few iterations, you will learn to maximize the reward from the predictor and improve your behavior until you fulfill the desired goal and find the treasure. This corresponds to a machine learning–based approach, which we’ll discuss in part 5 of this book.<a id="idIndexMarker067"/><a id="idIndexMarker068"/><a id="marker-52"/></p>
  </div>

  <h2 class="fm-head" id="heading_id_10">2.3 Heuristics and metaheuristics</h2>

  <p class="body"><i class="fm-italics">Heuristics</i> (also known as <i class="fm-italics">mental shortcuts</i> or <i class="fm-italics">rules of thumb</i>) are solution strategies, seeking methods, or rules that can facilitate finding acceptable (optimal or near-optimal) solutions to a complex problem in a practical time. Despite the fact that heuristics can seek near-optimal solutions at a reasonable computational cost, they cannot guarantee either feasibility or degree of optimality.<a id="idIndexMarker069"/><a id="idIndexMarker070"/><a id="idIndexMarker071"/></p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">“Eureka! Eureka!”</p>

    <p class="fm-sidebar-text">The word <i class="fm-italics">heuristic</i> comes from the Greek word <i class="fm-italics">heuriskein</i>, which means “to find or discover.” The past tense of this verb, <i class="fm-italics">eureka</i>, was used by the Greek mathematician, physicist, engineer, astronomer, and inventor Archimedes. Archimedes was contracted to detect fraud in the manufacture of a golden crown, and he accepted the challenge. During a subsequent visit to the public baths, he had a revelation. As his body submerged in the water, he observed that the more he sank, the more water was displaced, offering an exact measure of his volume. Realizing the principle at play, he deduced that a crown containing silver, being less dense than pure gold, would need to have greater volume to match the weight of a pure gold crown. Consequently, it would displace more water. Recognizing the solution, Archimedes leaped out of the bath and hurried home, exclaiming “Eureka! Eureka!” which translates to “I’ve found it! I’ve found it!”<a id="idIndexMarker072"/><a id="idIndexMarker073"/></p>
  </div>

  <p class="body"><a id="marker-53"/>The term metaheuristic is a combination of two Greek words: <i class="fm-italics">meta</i>, which means “beyond, on a higher level,” and <i class="fm-italics">heuristics</i>. It’s a term coined by Fred Glover, inventor of the tabu search (discussed in chapter 6) to refer to high-level strategies used to guide and modify other heuristics to enhance their performance. The goal of metaheuristics is to efficiently explore the search space in order to find optimal or near-optimal solutions. Metaheuristics may incorporate mechanisms to achieve a trade-off between exploration (diversification) and exploitation (intensification) of the search space to avoid getting trapped in confined areas of the search space while also finding optimal or near-optimal solutions in a reasonable amount of time. Finding this balance of exploration and exploitation is crucial in heuristics, as discussed in section 1.5. Metaheuristic algorithms are often global optimizers that can be applied to different linear and nonlinear optimization problems with relatively few modifications for specific problems. These algorithms are often robust and can handle different problem sizes, problem instances, and random variables.<a id="idIndexMarker074"/></p>

  <p class="body">Let’s assume that we have 6 objects with different sizes (2, 4, 3, 6, 5, and 1) and we need to pack them into a minimum number of bins. Each bin has a limited size of 7, so the total size of the objects in the bin should be 7 or less. If we have <i class="timesitalic">n</i> objects, there are <i class="fm-italics">n</i>! possible ways of packing the objects. The minimum number of bins we need is the <i class="fm-italics">lower bound</i>. To calculate this lower bound, we need to find the total number of object sizes (2 + 4 + 3 + 6 + 5 + 1 = 21). The lower bound is 21 / 7 = 3 bins. This means that we need at least 3 bins to pack these objects. Figure 2.17 illustrates two heuristics that can be used to solve this bin packing problem.<a id="idIndexMarker075"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F17_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.17 Handling the bin packing problem using first-fit and first-fit decreasing heuristics</p>
  </div>

  <p class="body"><a id="marker-54"/>First-fit heuristics pack the objects following their order without taking into consideration their sizes. This results in the need for four bins that are not fully utilized, as there are seven spaces left in three of these bins. If we apply the first-fit decreasing heuristic, we will order the objects based on their sizes and pack them following this order. This heuristic allows us to pack all the objects in three fully utilized bins, which is the lower bound.</p>

  <p class="body">In the previous example, all the objects have the same height. However, in a more generalized version, let’s consider objects with different widths and heights, as illustrated in figure 2.18. Applying heuristics such as smallest-first can allow us to load the container much faster. Some heuristics do not guarantee optimality; for example, the largest-first heuristic gives a suboptimal solution, as one object is left out. This can be considered an infeasible solution if we need to load all the objects into the container, or it will be a suboptimal solution if the objective is to load as many objects as possible.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F18_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.18 Bin packing problem. Using heuristics allows us to solve the problem much faster than with a brute-force approach. However, some heuristic functions may result in infeasible or suboptimal solutions, and they do not guarantee optimality.</p>
  </div>

  <p class="body"><a id="marker-55"/>To solve this problem in Python, let’s first define the objects, the containers, and what it means to place an object inside a container. For the sake of simplicity, the following listing avoids custom classes and uses <code class="fm-code-in-text">numpy</code> arrays instead.<a id="idIndexMarker076"/></p>

  <p class="fm-code-listing-caption">Listing 2.7 Bin packing problem</p>
  <pre class="programlisting">import numpy
import matplotlib.pyplot as plt
from matplotlib import cm
from matplotlib.colors import rgb2hex
 
width = 4                                                             <span class="fm-combinumeral">①</span>
height = 8                                                            <span class="fm-combinumeral">①</span>
container = numpy.full((height,width), 0)                             <span class="fm-combinumeral">①</span>
  
objects = [[3,1],[3,3],[5,1],[4,2],[3,2]]                             <span class="fm-combinumeral">②</span>
  
def fit(container, object, obj_index, rotate=True):                   <span class="fm-combinumeral">③</span>
    obj_w = object[0]                                                 <span class="fm-combinumeral">③</span>
    obj_h = object[1]                                                 <span class="fm-combinumeral">③</span>
    for i in range(height - obj_h + 1): C                             <span class="fm-combinumeral">③</span>
        for j in range(width - obj_w + 1):                            <span class="fm-combinumeral">③</span>
            placement = container[i : i + obj_h, j : j + obj_w]       <span class="fm-combinumeral">③</span>
            if placement.sum() == 0:                                  <span class="fm-combinumeral">③</span>
                container[i : i + obj_h, j : j + obj_w] = obj_index   <span class="fm-combinumeral">③</span>
                return True                                           <span class="fm-combinumeral">③</span>
        return fit(container, object[::-1], obj_index, rotate=False)  <span class="fm-combinumeral">③</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Define the dimensions of the container, and initialize the numpy array to 0s.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Represent objects to be placed as [width, height].</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> The fit function places objects into the container, either through direct placement, shifting, or rotation.</p>

  <p class="body">The <code class="fm-code-in-text">fit</code> function attempts to write a value to a 2D slice of the container, provided there are no values in that slice already (the sum is 0). If that fails, it shifts along the container from top to bottom, from left to right, and tries again. As a last resort, it tries the same thing but with the object rotated by 90 degrees.<a id="idIndexMarker077"/></p>

  <p class="body">The first heuristic prioritizes fitting by object area in descending order:</p>
  <pre class="programlisting">def largest_first(container, objects):
    excluded = []
    assigned = []
    objects.sort(key=lambda obj: obj[0] * obj[1], reverse=True)   <span class="fm-combinumeral">①</span>
    for obj in objects:
        if not fit(container, obj, objects.index(obj) + 1):
            excluded.append(objects.index(obj) + 1)               <span class="fm-combinumeral">②</span>
        else:
            assigned.append(objects.index(obj) + 1)
    if excluded: print(f"Items excluded: {len(excluded)}")
    visualize(numpy.flip(container, axis=0), assigned)            <span class="fm-combinumeral">③</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Sort elements by area in descending order.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Some objects may not fit; we can keep track of them using a list.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Visualize the filled container.</p>

  <p class="body">The output of this code is shown in figure 2.19. The code for visualizing this result is included in the full code files for listing 2.7, available in the book’s GitHub repo.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F19_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.19 Bin packing using the largest-first heuristic—one object has been excluded, as it does not fit in the remaining space.</p>
  </div>

  <p class="body">The second heuristic sorts first by width and then by total area, in ascending order:</p>
  <pre class="programlisting">def smallest_width_first(container, objects):
    excluded = []
    assigned = []
    objects.sort(key=lambda obj: (obj[0], obj[0] * obj[1]))      <span class="fm-combinumeral">①</span>
    for obj in objects:
        if not fit(container, obj, objects.index(obj) + 1):
            excluded.append(objects.index(obj) + 1)
        else:
            assigned.append(objects.index(obj) + 1)
    if excluded: print(f"Items excluded: {len(excluded)}")
    visualize(numpy.flip(container, axis=0), assigned)           <span class="fm-combinumeral">②</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Sort by width as primary key, and then by area in ascending order.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Visualize the solution.</p>

  <p class="body"><a id="marker-56"/>The <code class="fm-code-in-text">smallest_width_first</code> heuristic manages to successfully fit all the objects into the container, as shown in figure 2.20.<a id="idIndexMarker078"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F20_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.20 Bin packing problem using the smallest-first heuristic—all five objects have been successfully placed in the container.</p>
  </div>

  <p class="body">Different heuristic search strategies can be used to generate candidate solutions. These strategies include, but are not limited to, search by repeated solution construction (e.g., graph search and ant colony optimization), search by repeated solution modification (e.g., tabu search, simulated annealing, genetic algorithm, and particle swarm optimization), and search by repeated solution recombination (e.g., genetic algo<a id="idTextAnchor002"/>rithm and differential evolution).<a id="marker-57"/></p>

  <p class="body">Let’s reconsider the cargo bike loading problem discussed in section 1.3.3. We can order the items to be delivered based on their efficiency (profit per kg), as shown in table 2.2.</p>

  <p class="fm-table-caption">Table 2.2 Packages ranked by efficiency. The efficiency of a package is defined as the profit per kilogram.</p>

  <table border="1" class="contenttable-1-table" id="table002" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="25%"/>
      <col class="contenttable-0-col" span="1" width="25%"/>
      <col class="contenttable-0-col" span="1" width="25%"/>
      <col class="contenttable-0-col" span="1" width="25%"/>
    </colgroup>

    <thead class="calibre6">
      <tr class="contenttable-0-tr">
        <th class="contenttable-1-th">
          <p class="fm-table-head">Item</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Weight (kg)</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Profit ($)</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Efficiency ($/kg)</p>
        </th>
      </tr>
    </thead>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">10</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">7.8</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">20.9</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">2.68</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">7</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">4.9</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">10.3</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">2.10</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">4</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">10</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">12.12</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">1.21</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">1</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">14.6</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">14.54</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">1</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">8</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">16.5</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">13.5</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.82</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">6</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">9.6</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">7.4</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.77</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">2</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">20</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">15.26</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.76</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">9</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">8.77</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">6.6</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.75</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">3</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">8.5</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">5.8</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.68</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">5</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">13</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">8.2</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.63</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">Using a search strategy based on the <i class="fm-italics">repeated solution construction</i> heuristic, we can start by applying a greedy principle and pick items based on their efficiency until we reach the maximum payload of the cargo bike (100 kg) as a hard constraint. The steps for this are shown in table 2.3.<a id="idIndexMarker079"/></p>

  <p class="fm-table-caption">Table 2.3 Repeated solution construction—packages are added to the bike until the maximum capacity is reached.</p>

  <table border="1" class="contenttable-1-table" id="table003" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="20%"/>
    </colgroup>

    <thead class="calibre6">
      <tr class="contenttable-0-tr">
        <th class="contenttable-1-th">
          <p class="fm-table-head">Step</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Item</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Add?</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Total weight (kg)</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Total profit ($)</p>
        </th>
      </tr>
    </thead>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">1</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">10</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Yes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">7.8</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">20.9</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">2</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">7</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Yes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">12.7</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">31.2</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">3</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">4</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Yes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">22.7</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">43.32</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">4</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">1</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Yes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">37.3</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">57.86</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">5</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">8</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Yes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">53.8</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">71.36</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">6</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">6</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Yes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">63.4</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">78.76</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">7</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">2</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Yes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">83.4</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">94.02</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">8</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">9</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Yes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">92.17</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">100.62</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">9</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">3</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">No</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">(100.67)</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">-</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">10</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">5</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">No</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">(113.67)</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">-</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">We obtain the following subset of items: 10, 7, 4, 1, 8, 6, 2, and 9. This can also be written as (1,1,0,1,0,1,1,1,1,1), which when read from left to right shows that we include items 1, 2, 4, 6, 7, 8, 9, and 10 (and exclude items 3 and 5). This results in a total profit of $100.62 and a weight of 92.17 kg. We can generate more solutions by repeating the process of adding objects, starting with an empty container.</p>

  <p class="body">Instead of creating one or more solutions completely from scratch, we could also think about ways of modifying an existing feasible solution—this is a <i class="fm-italics">repeated solution modification</i>-<i class="fm-italics">based</i> heuristic search strategy. Consider the previous solution generated for the cargo-bike problem: (1,1,0,1,0,1,1,1,1,1). We know that this feasible solution is not optimal, but how can we improve it? We could do so by removing item 9 from the cargo bike and adding item 5. This process of removing and adding results in a new solution, (1,1,0,1,1,1,1,1,0,1), with a total profit of $102.22 and a weight of 96.4 kg.<a id="idIndexMarker080"/><a id="marker-58"/></p>

  <p class="body">Another approach is to combine existing solutions to generate new solutions to progress in the search space—this is <i class="fm-italics">repeated solution recombination</i>. Suppose the following two solutions are given:<a id="idIndexMarker081"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><span class="times"><i class="fm-italics">S</i><sub class="fm-subscript">1</sub> = (1,1,1,1,1,0,0,1,0,1)</span> with a weight of 75.8 kg and a profit of $75.78</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><span class="times"><i class="fm-italics">S</i><sub class="fm-subscript">2</sub> = (0,1,0,1,1,0,1,1,1,1)</span> with a weight of 80.97 kg and a profit of $86.88</p>
    </li>
  </ul>

  <p class="body">As illustrated in figure 2.21, we can take the configuration of the first two items of <span class="times"><i class="fm-italics">S</i><sub class="fm-subscript">1</sub></span> and the last eight items of <span class="times"><i class="fm-italics">S</i><sub class="fm-subscript">2</sub></span> to get a new solution. This means that we include items 1, 2, 4, 5, 7, 8, 9, and 10 in the new solution and exclude items 3 and 6. This yields a new solution: <span class="times"><i class="fm-italics">S</i><sub class="fm-subscript">3</sub> = (1,1,0,1,1,0,1,1,1,1)</span> with a weight of 95.57 kg and a higher profit of $101.42.<a id="idIndexMarker082"/><a id="idIndexMarker083"/><a id="idIndexMarker084"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH02_F21_Khamis.png"/></p>

    <p class="figurecaption">Figure 2.21 Repeated solution recombination—taking the first two elements of <span class="times">S<sub class="fm-subscript">1</sub></span> and adding the last eight elements of <span class="times">S<sub class="fm-subscript">2</sub></span> yields a new, better solution.</p>
  </div>

  <h2 class="fm-head" id="heading_id_11">2.4 Nature-inspired algorithms</h2>

  <p class="body">Nature is the ultimate source of inspiration. Problems in nature are usually ill-structured, dynamic, partially observable, nonlinear, multimodal, and multi-objective with hard and soft constraints and with no or limited access to global information. Nature-inspired algorithms are computational models that mimic or reverse engineer the intelligent behaviors observed in nature. Examples include molecular dynamics, cooperative foraging, division of labor, self-replication, immunity, biological evolution, learning, flocking, schooling, and self-organization, just to name just a few.<a id="idIndexMarker085"/><a id="idIndexMarker086"/><a id="idIndexMarker087"/></p>

  <p class="body"><a id="marker-59"/>Molecular dynamics (the science of simulating the motions of a system of particles) and thermal annealing inspired scientists to create an optimization algorithm called <i class="fm-italics">simulated annealing</i>, which we’ll discuss in chapter 5. Evolutionary computing algorithms such as genetic algorithm (GA), genetic programming (GP), evolutionary programming (EP), evolutionary strategies (ES), differential evolution (DE), cultural algorithms (CA), and co-evolution (CoE) are inspired by evolutionary biology (the study of the evolutionary processes) and biological evolution. Part 3 of this book will cover a number of evolutionary computing algorithms.<a id="idIndexMarker088"/><a id="idIndexMarker089"/><a id="idIndexMarker090"/><a id="idIndexMarker091"/><a id="idIndexMarker092"/><a id="idIndexMarker093"/><a id="idIndexMarker094"/><a id="idIndexMarker095"/><a id="idIndexMarker096"/><a id="idIndexMarker097"/><a id="idIndexMarker098"/><a id="idIndexMarker099"/><a id="idIndexMarker100"/><a id="idIndexMarker101"/><a id="idIndexMarker102"/><a id="idIndexMarker103"/></p>

  <p class="body">Ethology (the study of animal behavior) is the main source of inspiration for swarm intelligence algorithms such as particle swarm optimization (PSO), ant colony optimization (ACO), artificial bee colony (ABC), firefly algorithm (FA), bat algorithm (BA), social spider optimization (SSO), butterfly optimization algorithm (BOA), dragonfly algorithm (DA), krill herd (KH), shuffled frog leaping algorithm (SFLA), fish school search (FSS), dolphin partner optimization (DPO), dolphin swarm optimization algorithm (DSOA), cat swarm optimization (CSO), monkey search algorithm (MSA), lion optimization algorithm (LOA), cuckoo search (CS), cuckoo optimization algorithm (COA), wolf search algorithm (WSA), and grey wolf optimizer (GWO). Swarm intelligence-based optimization algorithms are covered in part 4 of this book.<a id="idIndexMarker104"/><a id="idIndexMarker105"/><a id="idIndexMarker106"/><a id="idIndexMarker107"/><a id="idIndexMarker108"/><a id="idIndexMarker109"/><a id="idIndexMarker110"/><a id="idIndexMarker111"/><a id="idIndexMarker112"/><a id="idIndexMarker113"/><a id="idIndexMarker114"/><a id="idIndexMarker115"/><a id="idIndexMarker116"/><a id="idIndexMarker117"/><a id="idIndexMarker118"/><a id="idIndexMarker119"/><a id="idIndexMarker120"/><a id="idIndexMarker121"/><a id="idIndexMarker122"/><a id="idIndexMarker123"/><a id="idIndexMarker124"/><a id="idIndexMarker125"/><a id="idIndexMarker126"/><a id="idIndexMarker127"/><a id="idIndexMarker128"/><a id="idIndexMarker129"/><a id="idIndexMarker130"/><a id="idIndexMarker131"/><a id="idIndexMarker132"/><a id="idIndexMarker133"/><a id="idIndexMarker134"/><a id="idIndexMarker135"/><a id="idIndexMarker136"/><a id="idIndexMarker137"/><a id="idIndexMarker138"/><a id="idIndexMarker139"/><a id="idIndexMarker140"/><a id="idIndexMarker141"/></p>

  <p class="body">Neural networks (NNs) are computational models inspired by the structure and functioning of biological neural networks. How NNs can be used to solve search and optimization problems is described in part 5 of this book. Tabu search (explained in chapter 6) is based on evolving memory (adaptive memory and responsive exploration), which is studied in behavioral psychology (the science of behavior and mind). Reinforcement learning is a branch of machine learning that draws inspiration from several sources such as psychology, neuroscience, and control theory, and it can be used to solve search and optimization problems, as described in the last chapter of the book.<a id="idIndexMarker142"/><a id="idIndexMarker143"/><a id="idIndexMarker144"/><a id="idIndexMarker145"/></p>

  <p class="body"><a id="marker-60"/>Other nature-inspired search and optimization algorithms include, but are not limited to, bacterial foraging optimization algorithm (BFO), bacterial swarming algorithm (BSA), biogeography-based optimization (BBO), invasive weed optimization (IWO), flower pollination algorithm (FPA), forest optimization algorithm (FOA), water flow-like algorithm (WFA), water cycle algorithm (WCA), brainstorm optimization algorithm (BSO), stochastic diffusion search (SDS), alliance algorithm (AA), black hole algorithm (BH), black hole mechanics optimization (BHMO), adaptive black hole algorithm (BHA), improved black hole algorithm (IBH), levy flight black hole (LBH), multiple population levy black hole (MLBH), spiral galaxy-based search algorithm (GbSA), galaxy-based search algorithm (GSA), big-bang big-crunch (BBBC), ray optimization (RO), quantum annealing (QA), quantum-inspired genetic algorithm (QGA), quantum-inspired evolutionary algorithm (QEA), quantum swarm evolutionary algorithm (QSE), and quantum-inspired particle swarm optimization (QPSO). For a comprehensive list of metaheuristic algorithms, see S.M. Almufti’s “Historical survey on metaheuristics algorithms” [8]. <a id="idIndexMarker146"/><a id="idIndexMarker147"/><a id="idIndexMarker148"/><a id="idIndexMarker149"/><a id="idIndexMarker150"/><a id="idIndexMarker151"/><a id="idIndexMarker152"/><a id="idIndexMarker153"/><a id="idIndexMarker154"/><a id="idIndexMarker155"/><a id="idIndexMarker156"/><a id="idIndexMarker157"/><a id="idIndexMarker158"/><a id="idIndexMarker159"/><a id="idIndexMarker160"/><a id="idIndexMarker161"/><a id="idIndexMarker162"/><a id="idIndexMarker163"/><a id="idIndexMarker164"/><a id="idIndexMarker165"/><a id="idIndexMarker166"/><a id="idIndexMarker167"/><a id="idIndexMarker168"/><a id="idIndexMarker169"/><a id="idIndexMarker170"/><a id="idIndexMarker171"/><a id="idIndexMarker172"/><a id="idIndexMarker173"/><a id="idIndexMarker174"/><a id="idIndexMarker175"/><a id="idIndexMarker176"/><a id="idIndexMarker177"/><a id="idIndexMarker178"/><a id="idIndexMarker179"/><a id="idIndexMarker180"/><a id="idIndexMarker181"/><a id="idIndexMarker182"/><a id="idIndexMarker183"/><a id="idIndexMarker184"/><a id="idIndexMarker185"/><a id="idIndexMarker186"/><a id="idIndexMarker187"/><a id="idIndexMarker188"/><a id="idIndexMarker189"/><a id="idIndexMarker190"/><a id="idIndexMarker191"/><a id="idIndexMarker192"/><a id="idIndexMarker193"/><a id="idIndexMarker194"/><a id="idIndexMarker195"/><a id="idIndexMarker196"/></p>

  <p class="body">In the five parts of this book, we’ll explore five primary categories of search and optimization algorithms: graph search algorithms, trajectory-based optimization, evolutionary computing, swarm intelligence algorithms, and machine learning methods. The following algorithms are covered within these categories:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Graph search methods (blind or uninformed search and informed search algorithms)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Simulated annealing (SA)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Tab search (TS)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Genetic algorithm (GA)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Particle swarm optimization (PSO)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Ant colony optimization (ACO)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Artificial bee colony (ABC)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Graph convolutional network (GCN)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Graph Attention Network (GAT)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Self-organizing map (SOM)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Actor-Critic (A2C) architecture</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Proximal policy optimization (PPO)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Multi-armed bandit (MAB)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Contextual multi-armed bandit (CMAB)</p>
    </li>
  </ul>

  <p class="body">Throughout this book, we’ll look at several real-world problems and see how these algorithms can be applied.</p>

  <h2 class="fm-head" id="heading_id_12">Summary</h2>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Search and optimization problems can be classified based on the number of decision variables (univariate and multivariate problems), the types of decision variables (continuous, discrete, or mixed-integer), the number of objective functions (mono-objective, multi-objective, or constraint-satisfaction problems), the landscape of the objective function (unimodal, multimodal, or deceptive), the number of constraints (unconstrained and constrained problems), and the linearity of the objective functions and constraints (linear problems and nonlinear problems).</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Based on the expected quality of the solutions and the search time permitted to find the solutions, optimization problems can also be categorized as design problems (strategic functions), planning problems (tactical functions), or control problems (operational functions).</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Search and optimization algorithms can be classified based on the way the search space is explored (local versus global search), on their optimization speeds (online versus offline optimization), and the determinism of the algorithm (deterministic versus stochastic).</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Heuristics (also known as <i class="fm-italics">mental shortcuts</i> or <i class="fm-italics">rules of thumb</i>) facilitate finding acceptable (optimal or near-optimal) solutions to complex problems in a reasonably practical time.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Metaheuristics are high-level strategies used to guide and modify other heuristics to enhance their performance.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Nature-inspired algorithms are computational models that mimic or reverse engineer the intelligent behaviors observed in nature to solve complex ill-structured problems.<a id="idIndexMarker197"/><a id="marker-61"/></p>
    </li>
  </ul>
</body></html>