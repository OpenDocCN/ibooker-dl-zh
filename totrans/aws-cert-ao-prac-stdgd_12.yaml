- en: Appendix A. Practice Exam
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To check your answers, please refer to the [“Practice Exam Answer Key”](app02.html#exam_answers).
  prefs: []
  type: TYPE_NORMAL
- en: What is an availability zone (AZ)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A physical data center containing multiple AWS servers
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A logical partition of AWS infrastructure that provides redundancy
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A security group that isolates AWS resources
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A region that spans multiple continents
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which cloud service model provides full applications to users without requiring
    them to manage infrastructure?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Infrastructure as a service (IaaS)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Platform as a service (PaaS)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Software as a service (SaaS)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Virtualization as a service (VaaS)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a defining characteristic of the hybrid cloud model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It exclusively uses private data centers for all workloads.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It combines public and private cloud environments.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It relies only on on-premises infrastructure.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It uses a multitenant model for security.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a key advantage of AWS regions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They eliminate the need for availability zones (AZs).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They allow customers to comply with data residency requirements.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They are only available in Asia.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They provide unlimited computing power without redundancy.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS service allows developers to deploy applications without managing
    servers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon EC2
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Lambda
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon RDS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon CloudFront
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following best describes Amazon S3?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A relational database service for structured data storage
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A scalable object storage service designed for durability and availability
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A high-performance compute service for running applications
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A content delivery network (CDN) for accelerating web traffic
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the main benefit of using a confusion matrix to evaluate a machine learning
    (ML) model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It shows the training time of the model.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It helps analyze false positives and false negatives.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It calculates the total number of data points used in training.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It eliminates the need for additional performance metrics.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A bank wants to detect fraudulent transactions in real time. What type of inference
    should they use?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Batch inference
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Asynchronous inference
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Real-time inference
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: On-demand inference
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a major challenge when using high-dimensional datasets in machine learning
    (ML)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It reduces the need for model tuning.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It increases computational costs and complexity.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It makes models interpret data more efficiently.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It ensures better accuracy for all ML tasks.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A company notices that its deployed machine learning (ML) model is becoming
    less accurate over time due to changing customer behavior. What issue is this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model overfitting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Hyperparameter tuning issue
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Feature engineering error
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Drift
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the primary reason for using Amazon SageMaker Model Monitor?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To train deep-learning models faster
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To automatically deploy machine learning (ML) models
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To detect issues such as data drift and concept drift
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To fine-tune pretrained models
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A business wants to improve the efficiency of their data processing pipeline
    by automating feature extraction and transformation. Which AWS tool is best suited
    for this?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Rekognition
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Textract
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon SageMaker Data Wrangler
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Glue
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A software company wants to analyze customer feedback to determine whether reviews
    are positive, neutral, or negative. Which AWS service should they use?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Textract
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Comprehend
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Lambda
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon SageMaker Feature Store
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the primary purpose of hyperparameter tuning in machine learning (ML)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To create new training data
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To adjust model parameters for improved performance
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To convert categorical data into numerical form
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To speed up the training process
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How do diffusion models work?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They add and remove noise in various steps.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They use competing neural networks.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They only create text.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They only create sound.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the primary purpose of fine-tuning a foundation model (FM)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To make a model more general-purpose
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To customize the model for a specific domain
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To lower the latency
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To train the model from scratch
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How does an encoder work in a transformer model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It creates synthetic data.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It fine-tunes hyperparameters.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It evaluates model predictions.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It processes input sequences and extracts meaningful representations.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following describes a limit on how much a large language model
    (LLM) can process at a time?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Overfitting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Bias
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Context windows
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The discriminator
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What’s the reason for using reinforcement learning from human feedback (RLHF)
    in generative AI models?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To improve the alignment the model’s responses with human preferences
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To lower training costs
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To replace deep learning models
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To reduce the latency of the model
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a key benefit of a multimodal foundation model (FM)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It requires much less data for the training
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It can process and create different types of content like text, images, and
    videos
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It is more explainable than text-based models
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It does not require GPUs
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Of the choices below, which is a main reason why large language models consume
    significant compute resources?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They use retrieval-augmented generation (RAG).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They use complex linear algebra.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They process billions of parameters to generate accurate responses.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They rely on human feedback and evaluation for all responses.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Why can RAG help lower hallucinations in AI models?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It has guardrails for certain types of prompts
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It searches a proprietary database to enhance the response
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It disables the probability system
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It relies only on human supervision
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Among these choices, what is a core capability of Amazon Lex?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It analyzes data for fraud detection.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It allows for video analysis.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It supports intents and slot filling to create conversational AI experiences.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It automates the extraction of text from scanned documents.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What can you do with Amazon Comprehend?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyze text to extract insights such as for sentiment, key phrases, and entities.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Transcribe audio recordings into text.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert text into humanlike speech.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Translate text into multiple languages.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a major capability of Amazon Rekognition?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The translation of spoken language into text.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The use of optical character recognition (OCR) for scanned documents.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The generation of AI-powered chatbot responses.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The ability to recognize faces, objects, and scenes in images and videos.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Among these options, which is a technique used in natural language processing
    (NLP) preprocessing?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Automatically correcting all grammatical errors in a sentence.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Translating text into another language before processing.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Lemmatization, which reduces words to their root form.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Applying deepfake detection to verify text authenticity.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is stopword removal used in natural language processing (NLP) preprocessing?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stopwords add important meaning to a text.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It helps remove uncommon words to focus only on frequently used terms.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Stopwords are removed to reduce text length to speed up processing.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Removing stopwords like the and is helps improve efficiency without losing essential
    meaning.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: When is AI not always the best solution for a business use case?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AI models do not work well in cloud-based environments.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AI requires human oversight at all times.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AI can only be used for simple automation tasks.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AI solutions can be complex and costly when a simpler approach may suffice.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the Compare Models feature in the Bedrock playground?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It allows for using image and text responses.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It provides for making longer responses for two different models.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It combines responses from two models.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It allows for evaluating the side-by-side responses from two different models.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Why would you fine-tune a model in Bedrock?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To reduce compute costs
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To improve latency
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To improve response accuracy for domain-specific scenarios
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To use images
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a key advantage of using open source foundation models (FMs) in AWS
    Bedrock?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They are always free to use.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They support real-time inference by default.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They offer transparency, customization, and community innovation.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They provide the codebase and datasets.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What’s a benefit of using a distilled model in Bedrock?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It reduces compute requirements, making it suitable for edge devices.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It increases the context window.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It increases the creativity of the responses.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It guarantees higher accuracy than larger models.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a key benefit of multiagent collaboration in Bedrock?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It relies on distilled models.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It provides for 100% accuracy.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It allows different agents to specialize in specific tasks, leading to better
    problem solving.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It enables users to edit model weights and biases.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a key benefit of batch processing when using Bedrock?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is low latency.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The context window is unlimited.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: There is higher accuracy.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Lower costs.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which technique improves the consistency and clarity of prompts when used repeatedly?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Few-shot prompting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Zero-shot prompting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Chain-of-thought prompting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Prompt templates
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of chain-of-thought (CoT) prompting?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To specify for the large language model (LLM) which examples to use
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To limit the response of the large language model (LLM)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To allow for step-by-step reasoning for complex problems
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To adjust the large language model (LLM) parameters
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which type of prompting involves providing several examples to help the model
    learn a pattern?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Zero-shot prompting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Chain-of-thought (CoT) prompting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Few-shot prompting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Template prompting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is model poisoning?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This allows a model to process personal health data.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: This is when biased or malicious data is injected into the training process.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: This when a model lacks proper licensing.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: This is where there are conflicting instructions in a single prompt.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is exposure as it relates to security risks with foundation models (FMs)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The use of the model for consumer apps
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The loss of GPU performance during training
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The unintentional inclusion of sensitive data in training sets
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The failure to generate output within token limits
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is jailbreaking of a foundation model (FM)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Running a model without GPU acceleration
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Resetting a model’s API token for expanding the access
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Deleting a model’s training history
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Tricking the model into bypassing safety and ethical restrictions
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following best describes AI governance?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A set of marketing strategies for AI adoption
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Policies and oversight structures to guide ethical AI development
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Legal ownership of AI-generated content
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Techniques for building large language models (LLMs)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What does controllability in AI focus on?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reducing computational costs
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Building faster AI systems
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Aligning AI actions with human intent and oversight
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Removing human involvement
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is a business advantage of adopting responsible AI practices?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enhanced trust and improved brand reputation
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Reduced need for data collection
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Increased dependence on human intervention
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Elimination of all algorithmic errors
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the role of Amazon SageMaker Clarify in responsible AI?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Detecting harmful URLs in user prompts
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Managing compute costs during training
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Identifying and explaining bias in data and models
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Encrypting training data
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is Amazon Augmented AI (A2I) primarily used for?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Accelerating training of neural networks
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating synthetic data from scratch
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Managing GPUs in SageMaker
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Integrating human reviews into AI workflows
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a key advantage of reinforcement learning from human feedback (RLHF)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It removes the need for model retraining.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It ensures AI systems remain static.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It helps models align outputs with human preferences and judgments.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It eliminates the need for data labeling.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a compliance risk caused by AI systems developing emergent capabilities?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They strictly follow preprogrammed features with no surprises.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They may behave unpredictably in ways not planned by the original designers.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They automatically file compliance reports as they change.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They prevent the need for any human oversight.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a key characteristic of a regulated workload?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It only applies to gaming or entertainment systems.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It only focuses on making systems faster, not safer.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It only requires encryption of stored data.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It must follow specific compliance rules due to legal, industry, or safety concerns.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is data logging important in AI systems?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It helps speed up model training by skipping error checks.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It captures inputs, outputs, and system events, supporting debugging, monitoring,
    and transparency.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It prevents the need for data residency compliance.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It automatically guarantees 100% model accuracy.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS service provides a detailed history of resource configuration changes
    and relationships to support compliance auditing?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Config
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Trusted Advisor
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Inspector
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Artifact
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Generative AI Security Scoping Matrix, which scope involves using publicly
    available generative AI tools without backend access or customization?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scope 3: Pretrained models'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scope 4: Fine-tuned models'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scope 5: Self-trained models'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scope 1: Consumer applications'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS service uses machine learning (ML) to detect and classify sensitive
    data like personally identifiable information (PII) or protected health information
    (PHI) across your environment?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Verified Permissions
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Shield Advanced
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Macie
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon SageMaker Role Manager
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of a model card in the context of generative AI?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To automatically retrain models with new data
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To manage access controls across cloud infrastructure
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To document the data sources, intended uses, risks, and limitations of a model
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To optimize compute resources for faster model deployment.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In a generative AI system, who always controls user data, regardless of application
    scope?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application provider
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The cloud service provider
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The data annotation team
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The customer or end user
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
