["```py\nfrom openai import OpenAI\n*# Replace 'your_openai_api_key' with your actual OpenAI API key*\nclient = OpenAI(\n    api_key= \"your-api-key\",\n)\ndef get_sentiment(review):\n    response = client.chat.completions.create(\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"The sentiment of this review is: {review}\",\n            }\n        ],\n        model=\"gpt-4-0125-preview\",\n    )\n    completion = response.choices[0].message.content\n    if \"positive\" in completion:\n        return \"positive\"\n    elif \"neutral\" in completion:\n        return \"neutral\"\n    elif \"negative\" in completion:\n        return \"negative\"\n    else:\n        return \"unknown\"\n*# Analyze the reviews and store the output (manually adapted)*\nsentiments = []\nfor review in reviews:\n    sentiments.append(get_sentiment(review))\ndf[\"GPT4\"] = sentiments\n```", "```py\nimport pandas as pd\nfrom transformers import pipeline\n\n*# Assuming df is your DataFrame and it has a column named* \n↪*'review_comment_message'*\n*# Load the sentiment analysis pipeline with the FinBERT-PT-BR model*\nclassifier = pipeline(\"sentiment-analysis\", \n↪model=\"lucas-leme/FinBERT-PT-BR\")\ndef get_sentiment(review):\n    try:\n        result = classifier(review)[0]\n        return result['label'], result['score']\n    except Exception as e:\n        print(f\"Error processing review: {e}\")\n        return None, None\n*# Apply the sentiment analysis to each review*\ndf['sentiment'], df['score'] = \n↪zip(*df['review_comment_message'].map(get_sentiment))\n*# Filter the DataFrame to only include positive reviews*\npositive_reviews_df = df[df['sentiment'] == 'LABEL_1']  \n*# Assuming 'LABEL_1' is positive; adjust label as necessary based on model*\n*↪output*\n*# Now positive_reviews_df contains only the positive reviews*\n```", "```py\nimport pandas as pd\nfrom transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, \n↪pipeline\n[...]\n*# Initialize the M2M100 tokenizer and model for translation*\ntokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\nmodel = \n↪M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n*# Initialize the sentiment analysis pipeline*\nsentiment_pipeline = pipeline('sentiment-analysis', \n↪model='distilbert-base-uncased-finetuned-sst-2-english'\n)\ndef translate_review(review):\n *# Specify the source and target language*\n    tokenizer.src_lang = \"pt\"\n    encoded_pt = tokenizer(review, return_tensors=\"pt\")\n    generated_tokens = model.generate(**encoded_pt, \n    ↪forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n    translated_review = tokenizer.decode(generated_tokens[0], \n    ↪skip_special_tokens=True)\n    return translated_review\ndef analyze_sentiment(review):\n    result = sentiment_pipeline(review)[0]\n    return result['label'], result['score']\n*# Translate reviews from Portuguese to English*\ndf['translated_review'] = \n↪df['review_comment_message'].apply(translate_review)\n*# Apply sentiment analysis to the translated reviews*\ndf['sentiment'], df['score'] = \n↪zip(*df['translated_review'].apply(analyze_sentiment))\n*# Filter the DataFrame to only include reviews with positive sentiment*\npositive_reviews_df = df[df['sentiment'] == 'POSITIVE']\n*# positive_reviews_df now contains only the positive reviews, translated* \n↪*into English*\n```", "```py\nimport pandas as pd\nfrom transformers import pipeline\n*# Assuming df is your DataFrame and it has a column named* \n↪*'review_comment_message'*\n*# Initialize the sentiment analysis pipeline with the multilingual model*\nsentiment_pipeline = pipeline('sentiment-analysis', \n↪model='cardiffnlp/twitter-xlm-roberta-base-sentiment')\ndef analyze_sentiment_multilingual(text):\n    result = sentiment_pipeline(text)[0]\n    return result['label'], result['score']\n*# Apply sentiment analysis to the reviews*\ndf['sentiment'], df['score'] = \n↪zip(*df['review_comment_message'].apply(analyze_sentiment_multilingual))\n*# Filter the DataFrame to only include positive reviews*\npositive_reviews_df = df[df['sentiment'] == 'positive']\n*# positive_reviews_df now contains only the reviews classified as positive*\n```", "```py\nfrom transformers import pipeline\nimport pandas as pd\n*# Load the zero-shot classification pipeline*\nclassifier = pipeline(\"zero-shot-classification\", \n↪model=\"facebook/bart-large-mnli\")\n*# Specify the candidate labels*\ncandidate_labels = [\"positive\", \"negative\"]\n*# Define a function to classify a single review*\ndef classify_review(review):\n    result = classifier(review, candidate_labels=candidate_labels, \n    ↪hypothesis_template=\"This review is {}.\", multi_label=False)\n    return result['labels'][0]\n*# Apply the classification to each review*\ndf['sentiment'] = df['review_comment_message'].apply(classify_review)\n*# Filter the DataFrame to only include positive reviews*\npositive_reviews_df = df[df['sentiment'] == 'positive']\n```", "```py\nimport pandas as pd\nimport nltk\nimport string\nfrom collections import Counter\n*# Download the required NLTK resources*\nnltk.download('punkt')\nnltk.download('stopwords')\n*# Sample data (manually adapted to remove empty records)*\ndf = pd.read_csv('olist_order_reviews_dataset.csv')\ndf = df.dropna(subset = ['review_comment_message'])\n*# Function to tokenize and remove stopwords*\ndef preprocess(text):\n    stopwords = nltk.corpus.stopwords.words('portuguese')\n    tokens = nltk.word_tokenize(text.lower())\n    tokens = [token for token in tokens if token not in string.punctuation \n    ↪and token not in stopwords]\n    return tokens\n*# Function to create word frequency distribution*\ndef word_frequency(tokens):\n    frequency = Counter(tokens)\n    return frequency\n*# Function to summarize short reviews*\ndef summarize_reviews(text, num_keywords=3):\n    tokens = preprocess(text)\n    frequency = word_frequency(tokens)\n    important_words = [word for word, count in \n    ↪frequency.most_common(num_keywords)]\n    summary = ' '.join(important_words)\n    return summary\n*# Apply the function to the DataFrame*\ndf['summary'] = df['review_comment_message'].apply(summarize_reviews)\n*# Display the results (manually adapted to print the summary of the longest* \n↪*message)*\nprint(\"Longest review:\", df.loc[1316][\"review_comment_message\"])\nprint(\"Summary:\", df.loc[1316][\"summary\"])\n```", "```py\nimport pandas as pd\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer\nimport re\n*# Load data. Only negative reviews were chosen for the analysis* \n↪*(adapted manually).*\ndf = pd.read_csv('olist_order_reviews_dataset.csv')\ndf = df.dropna(subset = ['review_comment_message'])\ndf = df[(df[\"review_score\"]==1) | (df[\"review_score\"]==2)]\n*# Preprocess the text*\ndef preprocess_text(text, language='portuguese'):\n *# Remove special characters, convert to lowercase*\n    cleaned_text = re.sub(r'[^\\w\\s]', '', text.lower())\n *# Tokenize words*\n    words = word_tokenize(cleaned_text, language=language)\n *# Remove stopwords*\n    stop_words = set(stopwords.words(language))\n    words = [word for word in words if word not in stop_words]\n *# Apply stemming*\n    stemmer = SnowballStemmer(language)\n    words = [stemmer.stem(word) for word in words]\n    return words\ndf['preprocessed_reviews'] = \n↪df['review_comment_message'].apply(preprocess_text)\n*# Loading the model.*\nfrom gensim.corpora import Dictionary\nfrom gensim.models import LdaModel\n*# Create a dictionary and corpus for LDA*\ndictionary = Dictionary(df['preprocessed_reviews'])\ncorpus = [dictionary.doc2bow(text) for text in df['preprocessed_reviews']]\n*# Train an LDA model*\nnum_topics = 5  *# Adjust this value to the desired number of topics*\nlda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, \n↪random_state=42)\n*# Displaying results (manually adapted to display 7 words).*\ndef display_topics(model, num_topics, num_words=7):\n    for idx, topic in model.print_topics(num_topics, num_words):\n        print(f\"Topic {idx + 1}: {topic}\\n\")\ndisplay_topics(lda_model, num_topics)\n```", "```py\nTopic 1: 0.055*\"compr\" + 0.043*\"receb\" + 0.032*\"produt\" + 0.020*\"2\" + \n↪0.019*\"entreg\" + 0.017*\"apen\" + 0.017*\"ped\"\nTopic 2: 0.043*\"entreg\" + 0.035*\"produt\" + 0.035*\"compr\" + \n↪0.028*\"receb\" + 0.021*\"agor\" + 0.020*\"praz\" + 0.013*\"falt\"\nTopic 3: 0.095*\"produt\" + 0.046*\"receb\" + 0.021*\"entreg\" + \n↪0.017*\"compr\" + 0.016*\"aind\" + 0.016*\"vei\" + 0.015*\"quer\"\nTopic 4: 0.070*\"produt\" + 0.066*\"entreg\" + 0.040*\"cheg\" + 0.024*\"aind\" +\n↪0.024*\"dia\" + 0.023*\"praz\" + 0.019*\"receb\"\nTopic 5: 0.052*\"produt\" + 0.035*\"receb\" + 0.035*\"compr\" + 0.032*\"vei\" + \n↪0.017*\"nao\" + 0.012*\"cheg\" + 0.011*\"entreg\"\n```", "```py\nTopic 1:\nTranslation: 0.055*\"purchase\" + 0.043*\"received\" + 0.032*\"product\" + \n↪0.020*\"2\" + 0.019*\"delivery\" + 0.017*\"only\" + 0.017*\"order\"\nInterpretation: Issues with purchase, receiving products, and delivery; \n↪possible complaints about incomplete or partially received orders.\n\nTopic 2:\nTranslation: 0.043*\"delivery\" + 0.035*\"product\" + 0.035*\"purchase\" + \n↪0.028*\"received\" + 0.021*\"now\" + 0.020*\"deadline\" + 0.013*\"missing\"\nInterpretation: Problems with product delivery, receiving products, and \n↪missing items; concerns about meeting deadlines.\n\nTopic 3:\nTranslation: 0.095*\"product\" + 0.046*\"received\" + 0.021*\"delivery\" + \n↪0.017*\"purchase\" + 0.016*\"still\" + 0.016*\"came\" + 0.015*\"want\"\nInterpretation: Dissatisfaction with products, delivery, and purchase \n↪experience; possible issues with products received or not yet \n↪received.\n\nTopic 4:\nTranslation: 0.070*\"product\" + 0.066*\"delivery\" + 0.040*\"arrived\" + \n↪0.024*\"still\" + 0.024*\"day\" + 0.023*\"deadline\" + 0.019*\"received\"\nInterpretation: Delivery and arrival of products, with possible delays \n↪or dissatisfaction with the time it took to receive them.\n\nTopic 5:\nTranslation: 0.052*\"product\" + 0.035*\"received\" + 0.035*\"purchase\" + \n↪0.032*\"came\" + 0.017*\"not\" + 0.012*\"arrived\" + 0.011*\"delivery\"\nInterpretation: Discontent with products, purchases, and deliveries; \n↪concerns about items not arriving or not being as expected.\n```"]