- en: Chapter 8\. Diffusion Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬8ç« ã€‚æ‰©æ•£æ¨¡å‹
- en: Alongside GANs, diffusion models are one of the most influential and impactful
    generative modeling techniques for image generation to have been introduced over
    the last decade. Across many benchmarks, diffusion models now outperform previously
    state-of-the-art GANs and are quickly becoming the go-to choice for generative
    modeling practitioners, particularly for visual domains (e.g., OpenAIâ€™s DALL.E
    2 and Googleâ€™s ImageGen for text-to-image generation). Recently, there has been
    an explosion of diffusion models being applied across wide range of tasks, reminiscent
    of the GAN proliferation that took place between 2017â€“2020.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸GANså¹¶é©¾é½é©±ï¼Œæ‰©æ•£æ¨¡å‹æ˜¯è¿‡å»åå¹´ä¸­å¼•å…¥çš„æœ€å…·å½±å“åŠ›å’Œå½±å“åŠ›çš„ç”Ÿæˆå»ºæ¨¡æŠ€æœ¯ä¹‹ä¸€ã€‚åœ¨è®¸å¤šåŸºå‡†æµ‹è¯•ä¸­ï¼Œæ‰©æ•£æ¨¡å‹ç°åœ¨èƒœè¿‡ä»¥å‰çš„æœ€å…ˆè¿›GANsï¼Œå¹¶è¿…é€Ÿæˆä¸ºç”Ÿæˆå»ºæ¨¡ä»ä¸šè€…çš„é¦–é€‰é€‰æ‹©ï¼Œç‰¹åˆ«æ˜¯å¯¹äºè§†è§‰é¢†åŸŸï¼ˆä¾‹å¦‚ï¼ŒOpenAIçš„DALL.E
    2å’ŒGoogleçš„ImageGenç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆï¼‰ã€‚æœ€è¿‘ï¼Œæ‰©æ•£æ¨¡å‹åœ¨å¹¿æ³›ä»»åŠ¡ä¸­çš„åº”ç”¨å‘ˆç°çˆ†ç‚¸æ€§å¢é•¿ï¼Œç±»ä¼¼äº2017å¹´è‡³2020å¹´é—´GANçš„æ™®åŠã€‚
- en: 'Many of the core ideas that underpin diffusion models share similarities with
    earlier types of generative models that we have already explored in this book
    (e.g., denoising autoencoders, energy-based models). Indeed, the name *diffusion*
    takes inspiration from the well-studied property of thermodynamic diffusion: an
    important link was made between this purely physical field and deep learning in
    2015.^([1](ch08.xhtml#idm45387010500320))'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šæ”¯æ’‘æ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³ä¸æœ¬ä¹¦ä¸­å·²ç»æ¢ç´¢è¿‡çš„æ—©æœŸç±»å‹çš„ç”Ÿæˆæ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œå»å™ªè‡ªåŠ¨ç¼–ç å™¨ï¼ŒåŸºäºèƒ½é‡çš„æ¨¡å‹ï¼‰æœ‰ç›¸ä¼¼ä¹‹å¤„ã€‚äº‹å®ä¸Šï¼Œåç§°*æ‰©æ•£*çµæ„Ÿæ¥è‡ªçƒ­åŠ›å­¦æ‰©æ•£çš„æ·±å…¥ç ”ç©¶ï¼šåœ¨2015å¹´ï¼Œè¿™ä¸€çº¯ç‰©ç†é¢†åŸŸä¸æ·±åº¦å­¦ä¹ ä¹‹é—´å»ºç«‹äº†é‡è¦è”ç³»ã€‚^([1](ch08.xhtml#idm45387010500320))
- en: Important progress was also being made in the field of score-based generative
    models,^([2](ch08.xhtml#idm45387010496240))^,^([3](ch08.xhtml#idm45387010494000))
    a branch of energy-based modeling that directly estimates the gradient of the
    log distribution (also known as the score function) in order to train the model,
    as an alternative to using contrastive divergence. In particular, Yang Song and
    Stefano Ermon used multiple scales of noise perturbations applied to the raw data
    to ensure the modelâ€”a *noise conditional score network* (NCSN)â€”performs well on
    regions of low data density.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åŸºäºåˆ†æ•°çš„ç”Ÿæˆæ¨¡å‹é¢†åŸŸä¹Ÿå–å¾—äº†é‡è¦è¿›å±•ï¼Œ^([2](ch08.xhtml#idm45387010496240))^,^([3](ch08.xhtml#idm45387010494000))è¿™æ˜¯èƒ½é‡åŸºæ¨¡å‹çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œç›´æ¥ä¼°è®¡å¯¹æ•°åˆ†å¸ƒçš„æ¢¯åº¦ï¼ˆä¹Ÿç§°ä¸ºåˆ†æ•°å‡½æ•°ï¼‰ï¼Œä»¥è®­ç»ƒæ¨¡å‹ï¼Œä½œä¸ºä½¿ç”¨å¯¹æ¯”æ•£åº¦çš„æ›¿ä»£æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯ï¼Œæ¨æ¾å’Œæ–¯ç‰¹å‡¡è¯ºÂ·å„å°”è’™ä½¿ç”¨å¤šä¸ªå°ºåº¦çš„å™ªå£°æ‰°åŠ¨åº”ç”¨äºåŸå§‹æ•°æ®ï¼Œä»¥ç¡®ä¿æ¨¡å‹-ä¸€ä¸ª*å™ªå£°æ¡ä»¶åˆ†æ•°ç½‘ç»œ*ï¼ˆNCSNï¼‰åœ¨ä½æ•°æ®å¯†åº¦åŒºåŸŸè¡¨ç°è‰¯å¥½ã€‚
- en: The breakthrough diffusion model paper came in the summer of 2020.^([4](ch08.xhtml#idm45387010490880))
    Standing on the shoulders of earlier works, the paper uncovers a deep connection
    between diffusion models and score-based generative models, and the authors use
    this fact to train a diffusion model that can rival GANs across several datasets,
    called the *Denoising Diffusion Probabilistic Model* (DDPM).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: çªç ´æ€§çš„æ‰©æ•£æ¨¡å‹è®ºæ–‡äº2020å¹´å¤å¤©å‘è¡¨ã€‚^([4](ch08.xhtml#idm45387010490880))åœ¨å‰äººçš„åŸºç¡€ä¸Šï¼Œè¯¥è®ºæ–‡æ­ç¤ºäº†æ‰©æ•£æ¨¡å‹å’ŒåŸºäºåˆ†æ•°çš„ç”Ÿæˆæ¨¡å‹ä¹‹é—´çš„æ·±åˆ»è”ç³»ï¼Œä½œè€…åˆ©ç”¨è¿™ä¸€äº‹å®è®­ç»ƒäº†ä¸€ä¸ªå¯ä»¥åœ¨å‡ ä¸ªæ•°æ®é›†ä¸Šä¸GANsåŒ¹æ•Œçš„æ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸º*å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹*ï¼ˆDDPMï¼‰ã€‚
- en: This chapter will walk through the theoretical requirements for understanding
    how a denoising diffusion model works. You will then learn how to build your own
    denoising diffusion model using Keras.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« å°†ä»‹ç»ç†è§£å»å™ªæ‰©æ•£æ¨¡å‹å·¥ä½œåŸç†çš„ç†è®ºè¦æ±‚ã€‚ç„¶åï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨Kerasæ„å»ºè‡ªå·±çš„å»å™ªæ‰©æ•£æ¨¡å‹ã€‚
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»‹ç»
- en: To help explain the key ideas that underpin diffusion models, letâ€™s begin with
    a short story!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¸®åŠ©è§£é‡Šæ”¯æ’‘æ‰©æ•£æ¨¡å‹çš„å…³é”®æ€æƒ³ï¼Œè®©æˆ‘ä»¬ä»ä¸€ä¸ªç®€çŸ­çš„æ•…äº‹å¼€å§‹ï¼
- en: The DiffuseTV story describes the general idea behind a diffusion model. Now
    letâ€™s dive into the technicalities of how we build such a model using Keras.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: DiffuseTVæ•…äº‹æè¿°äº†æ‰©æ•£æ¨¡å‹èƒŒåçš„ä¸€èˆ¬æ€æƒ³ã€‚ç°åœ¨è®©æˆ‘ä»¬æ·±å…¥æ¢è®¨å¦‚ä½•ä½¿ç”¨Kerasæ„å»ºè¿™æ ·ä¸€ä¸ªæ¨¡å‹çš„æŠ€æœ¯ç»†èŠ‚ã€‚
- en: Denoising Diffusion Models (DDM)
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å»å™ªæ‰©æ•£æ¨¡å‹ï¼ˆDDMï¼‰
- en: The core idea behind a denoising diffusion model is simpleâ€”we train a deep learning
    model to denoise an image over a series of very small steps. If we start from
    pure random noise, in theory we should be able to keep applying the model until
    we obtain an image that looks as if it were drawn from the training set. Whatâ€™s
    amazing is that this simple concept works so well in practice!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å»å™ªæ‰©æ•£æ¨¡å‹èƒŒåçš„æ ¸å¿ƒæ€æƒ³å¾ˆç®€å•-æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œåœ¨ä¸€ç³»åˆ—éå¸¸å°çš„æ­¥éª¤ä¸­å»å™ªå›¾åƒã€‚å¦‚æœæˆ‘ä»¬ä»çº¯éšæœºå™ªéŸ³å¼€å§‹ï¼Œåœ¨ç†è®ºä¸Šæˆ‘ä»¬åº”è¯¥èƒ½å¤Ÿä¸æ–­åº”ç”¨è¯¥æ¨¡å‹ï¼Œç›´åˆ°è·å¾—ä¸€ä¸ªçœ‹èµ·æ¥å¥½åƒæ˜¯ä»è®­ç»ƒé›†ä¸­ç»˜åˆ¶å‡ºæ¥çš„å›¾åƒã€‚ä»¤äººæƒŠå¥‡çš„æ˜¯ï¼Œè¿™ä¸ªç®€å•çš„æ¦‚å¿µåœ¨å®è·µä¸­æ•ˆæœå¦‚æ­¤å‡ºè‰²ï¼
- en: Letâ€™s first get set up with a dataset and then walk through the forward (noising)
    and backward (denoising) diffusion processes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é¦–å…ˆå‡†å¤‡ä¸€ä¸ªæ•°æ®é›†ï¼Œç„¶åé€æ­¥ä»‹ç»å‰å‘ï¼ˆåŠ å™ªï¼‰å’Œåå‘ï¼ˆå»å™ªï¼‰æ‰©æ•£è¿‡ç¨‹ã€‚
- en: Running the Code for This Example
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¿è¡Œæ­¤ç¤ºä¾‹çš„ä»£ç 
- en: The code for this example can be found in the Jupyter notebook located at *notebooks/08_diffusion/01_ddm/ddm.ipynb*
    in the book repository.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤ç¤ºä¾‹çš„ä»£ç å¯ä»¥åœ¨ä¹¦ç±å­˜å‚¨åº“ä¸­ä½äº*notebooks/08_diffusion/01_ddm/ddm.ipynb*çš„Jupyterç¬”è®°æœ¬ä¸­æ‰¾åˆ°ã€‚
- en: The code is adapted from the excellent [tutorial on denoising diffusion implicit
    models](https://oreil.ly/srPCe) created by AndrÃ¡s BÃ©res available on the Keras
    website.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ä»£ç æ”¹ç¼–è‡ªAndrÃ¡s BÃ©resåœ¨Kerasç½‘ç«™ä¸Šåˆ›å»ºçš„ä¼˜ç§€[å»å™ªæ‰©æ•£éšå¼æ¨¡å‹æ•™ç¨‹](https://oreil.ly/srPCe)ã€‚
- en: The Flowers Dataset
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èŠ±å‰æ•°æ®é›†
- en: Weâ€™ll be using the [Oxford 102 Flower dataset](https://oreil.ly/HfrKV) that
    is available through Kaggle. This is a set of over 8,000 color images of a variety
    of flowers.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨é€šè¿‡Kaggleæä¾›çš„[ç‰›æ´¥102èŠ±å‰æ•°æ®é›†](https://oreil.ly/HfrKV)ã€‚è¿™æ˜¯ä¸€ç»„åŒ…å«å„ç§èŠ±å‰çš„8000å¤šå¼ å½©è‰²å›¾åƒã€‚
- en: You can download the dataset by running the Kaggle dataset downloader script
    in the book repository, as shown in [ExampleÂ 8-1](#downloading-flower-dataset).
    This will save the flower images to the */data* folder.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥é€šè¿‡åœ¨ä¹¦ç±å­˜å‚¨åº“ä¸­è¿è¡ŒKaggleæ•°æ®é›†ä¸‹è½½è„šæœ¬æ¥ä¸‹è½½æ•°æ®é›†ï¼Œå¦‚[ç¤ºä¾‹8-1](#downloading-flower-dataset)æ‰€ç¤ºã€‚è¿™å°†æŠŠèŠ±å‰å›¾åƒä¿å­˜åˆ°*/data*æ–‡ä»¶å¤¹ä¸­ã€‚
- en: Example 8-1\. Downloading the Oxford 102 Flower dataset
  id: totrans-18
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹8-1ã€‚ä¸‹è½½ç‰›æ´¥102èŠ±å‰æ•°æ®é›†
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`As usual, weâ€™ll load the images in using the Keras `image_dataset_from_directory`
    function, resize the images to 64 Ã— 64 pixels, and scale the pixel values to the
    range [0, 1]. Weâ€™ll also repeat the dataset five times to increase the epoch length
    and batch the data into groups of 64 images, as shown in [ExampleÂ 8-2](#flower-preprocessing-ex).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: â€œé€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨Kerasçš„`image_dataset_from_directory`å‡½æ•°åŠ è½½å›¾åƒï¼Œå°†å›¾åƒè°ƒæ•´ä¸º64Ã—64åƒç´ ï¼Œå¹¶å°†åƒç´ å€¼ç¼©æ”¾åˆ°èŒƒå›´[0,
    1]ã€‚æˆ‘ä»¬è¿˜å°†æ•°æ®é›†é‡å¤äº”æ¬¡ï¼Œä»¥å¢åŠ æ—¶ä»£é•¿åº¦ï¼Œå¹¶å°†æ•°æ®åˆ†æˆ64å¼ å›¾åƒä¸€ç»„ï¼Œå¦‚[ç¤ºä¾‹8-2](#flower-preprocessing-ex)æ‰€ç¤ºã€‚
- en: Example 8-2\. Loading the Oxford 102 Flower dataset
  id: totrans-21
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹8-2ã€‚åŠ è½½ç‰›æ´¥102èŠ±å‰æ•°æ®é›†
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](Images/1.png)](#co_diffusion_models_CO1-1)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_diffusion_models_CO1-1)'
- en: Load dataset (when required during training) using the Keras `image_dataset_from_directory`
    function.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨Kerasçš„`image_dataset_from_directory`å‡½æ•°åŠ è½½æ•°æ®é›†ï¼ˆåœ¨è®­ç»ƒæœŸé—´éœ€è¦æ—¶ï¼‰ã€‚
- en: '[![2](Images/2.png)](#co_diffusion_models_CO1-2)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_diffusion_models_CO1-2)'
- en: Scale the pixel values to the range [0, 1].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å°†åƒç´ å€¼ç¼©æ”¾åˆ°èŒƒå›´[0, 1]ã€‚
- en: '[![3](Images/3.png)](#co_diffusion_models_CO1-3)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_diffusion_models_CO1-3)'
- en: Repeat the dataset five times.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ•°æ®é›†é‡å¤äº”æ¬¡ã€‚
- en: '[![4](Images/4.png)](#co_diffusion_models_CO1-4)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_diffusion_models_CO1-4)'
- en: Batch the dataset into groups of 64 images.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ•°æ®é›†åˆ†æˆ64å¼ å›¾åƒä¸€ç»„ã€‚
- en: Example images from the dataset are shown in [FigureÂ 8-2](Images/#flower_example_images).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†ä¸­çš„ç¤ºä¾‹å›¾åƒæ˜¾ç¤ºåœ¨[å›¾8-2](Images/#flower_example_images)ä¸­ã€‚
- en: '![](Images/gdl2_0802.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0802.png)'
- en: Figure 8-2\. Example images from the Oxford 102 Flower dataset
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-2ã€‚ç‰›æ´¥102èŠ±å‰æ•°æ®é›†ä¸­çš„ç¤ºä¾‹å›¾åƒ
- en: Now that we have our dataset we can explore how we should add noise to the images,
    using a forward diffusion process.`  `## The Forward Diffusion Process
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥æ¢è®¨å¦‚ä½•å‘å›¾åƒæ·»åŠ å™ªå£°ï¼Œä½¿ç”¨å‰å‘æ‰©æ•£è¿‡ç¨‹ã€‚` `##å‰å‘æ‰©æ•£è¿‡ç¨‹
- en: Suppose we have an image <math alttext="bold x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math>
    that we want to corrupt gradually over a large number of steps (say, <math alttext="upper
    T equals 1 comma 000"><mrow><mi>T</mi> <mo>=</mo> <mn>1</mn> <mo>,</mo> <mn>000</mn></mrow></math>
    ), so that eventually it is indistinguishable from standard Gaussian noise (i.e.,
    <math alttext="bold x Subscript upper T"><msub><mi>ğ±</mi> <mi>T</mi></msub></math>
    should have zero mean and unit variance). How should we go about doing this?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€å¹…å›¾åƒ<math alttext="bold x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math>ï¼Œæˆ‘ä»¬å¸Œæœ›åœ¨å¤§é‡æ­¥éª¤ï¼ˆæ¯”å¦‚ï¼Œ<math
    alttext="upper T equals 1 comma 000"><mrow><mi>T</mi> <mo>=</mo> <mn>1</mn> <mo>,</mo>
    <mn>000</mn></mrow></math>ï¼‰ä¸­é€æ¸æŸåï¼Œä»¥è‡³äºæœ€ç»ˆä¸æ ‡å‡†é«˜æ–¯å™ªå£°ä¸å¯åŒºåˆ†ï¼ˆå³ï¼Œ<math alttext="bold x Subscript
    upper T"><msub><mi>ğ±</mi> <mi>T</mi></msub></math>åº”å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ–¹å·®ï¼‰ã€‚æˆ‘ä»¬åº”è¯¥å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹å‘¢ï¼Ÿ
- en: We can define a function <math alttext="q"><mi>q</mi></math> that adds a small
    amount of Gaussian noise with variance <math alttext="beta Subscript t"><msub><mi>Î²</mi>
    <mi>t</mi></msub></math> to an image <math alttext="bold x Subscript t minus 1"><msub><mi>ğ±</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math> to generate a new image
    <math alttext="bold x Subscript t"><msub><mi>ğ±</mi> <mi>t</mi></msub></math> .
    If we keep applying this function, we will generate a sequence of progressively
    noisier images ( <math alttext="bold x 0 comma ellipsis comma bold x Subscript
    upper T Baseline"><mrow><msub><mi>ğ±</mi> <mn>0</mn></msub> <mo>,</mo> <mo>...</mo>
    <mo>,</mo> <msub><mi>ğ±</mi> <mi>T</mi></msub></mrow></math> ), as shown in [FigureÂ 8-3](#forward_diffusion_q).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªå‡½æ•°<math alttext="q"><mi>q</mi></math>ï¼Œå®ƒå‘å›¾åƒ<math alttext="bold x Subscript
    t minus 1"><msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math>æ·»åŠ æ–¹å·®ä¸º<math
    alttext="beta Subscript t"><msub><mi>Î²</mi> <mi>t</mi></msub></math>çš„å°‘é‡é«˜æ–¯å™ªå£°ï¼Œä»¥ç”Ÿæˆæ–°å›¾åƒ<math
    alttext="bold x Subscript t"><msub><mi>ğ±</mi> <mi>t</mi></msub></math>ã€‚å¦‚æœæˆ‘ä»¬ä¸æ–­åº”ç”¨è¿™ä¸ªå‡½æ•°ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆä¸€ç³»åˆ—é€æ¸å˜ˆæ‚çš„å›¾åƒï¼ˆ<math
    alttext="bold x 0 comma ellipsis comma bold x Subscript upper T Baseline"><mrow><msub><mi>ğ±</mi>
    <mn>0</mn></msub> <mo>,</mo> <mo>...</mo> <mo>,</mo> <msub><mi>ğ±</mi> <mi>T</mi></msub></mrow></math>ï¼‰ï¼Œå¦‚[å›¾8-3](#forward_diffusion_q)æ‰€ç¤ºã€‚
- en: '![](Images/gdl2_0803.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0803.png)'
- en: Figure 8-3\. The forward diffusion process <math alttext="q"><mi>q</mi></math>
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-3ã€‚å‰å‘æ‰©æ•£è¿‡ç¨‹<math alttext="q"><mi>q</mi></math>
- en: 'We can write this update process mathematically as follows (here, <math alttext="epsilon
    Subscript t minus 1"><msub><mi>Ïµ</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math>
    is a standard Gaussian with zero mean and unit variance):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªæ›´æ–°è¿‡ç¨‹æ•°å­¦åœ°è¡¨ç¤ºå¦‚ä¸‹ï¼ˆè¿™é‡Œï¼Œ<math alttext="epsilon Subscript t minus 1"><msub><mi>Ïµ</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math>æ˜¯å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ–¹å·®çš„æ ‡å‡†é«˜æ–¯åˆ†å¸ƒï¼‰ï¼š
- en: <math alttext="bold x Subscript t Baseline equals StartRoot 1 minus beta Subscript
    t Baseline EndRoot bold x Subscript t minus 1 Baseline plus StartRoot beta Subscript
    t Baseline EndRoot epsilon Subscript t minus 1" display="block"><mrow><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>=</mo> <msqrt><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î²</mi>
    <mi>t</mi></msub></mrow></msqrt> <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>+</mo> <msqrt><msub><mi>Î²</mi> <mi>t</mi></msub></msqrt> <msub><mi>Ïµ</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></math>
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold x Subscript t Baseline equals StartRoot 1 minus beta Subscript
    t Baseline EndRoot bold x Subscript t minus 1 Baseline plus StartRoot beta Subscript
    t Baseline EndRoot epsilon Subscript t minus 1" display="block"><mrow><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>=</mo> <msqrt><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î²</mi>
    <mi>t</mi></msub></mrow></msqrt> <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>+</mo> <msqrt><msub><mi>Î²</mi> <mi>t</mi></msub></msqrt> <msub><mi>Ïµ</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></math>
- en: Note that we also scale the input image <math alttext="bold x Subscript t minus
    1"><msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math>
    , to ensure that the variance of the output image <math alttext="bold x Subscript
    t"><msub><mi>ğ±</mi> <mi>t</mi></msub></math> remains constant over time. This
    way, if we normalize our original image <math alttext="bold x 0"><msub><mi>ğ±</mi>
    <mn>0</mn></msub></math> to have zero mean and unit variance, then <math alttext="bold
    x Subscript upper T"><msub><mi>ğ±</mi> <mi>T</mi></msub></math> will approximate
    a standard Gaussian distribution for large enough <math alttext="upper T"><mi>T</mi></math>
    , by induction, as follows.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæˆ‘ä»¬è¿˜è¦ç¼©æ”¾è¾“å…¥å›¾åƒ<math alttext="bold x Subscript t minus 1"><msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math>ï¼Œä»¥ç¡®ä¿è¾“å‡ºå›¾åƒ<math
    alttext="bold x Subscript t"><msub><mi>ğ±</mi> <mi>t</mi></msub></math>çš„æ–¹å·®éšæ—¶é—´ä¿æŒæ’å®šã€‚è¿™æ ·ï¼Œå¦‚æœæˆ‘ä»¬å°†åŸå§‹å›¾åƒ<math
    alttext="bold x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math>å½’ä¸€åŒ–ä¸ºé›¶å‡å€¼å’Œå•ä½æ–¹å·®ï¼Œé‚£ä¹ˆ<math
    alttext="bold x Subscript upper T"><msub><mi>ğ±</mi> <mi>T</mi></msub></math>å°†åœ¨è¶³å¤Ÿå¤§çš„<math
    alttext="upper T"><mi>T</mi></math>æ—¶é€¼è¿‘æ ‡å‡†é«˜æ–¯åˆ†å¸ƒï¼Œé€šè¿‡å½’çº³ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚
- en: If we assume that <math alttext="bold x Subscript t minus 1"><msub><mi>ğ±</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math> has zero mean and unit
    variance then <math alttext="StartRoot 1 minus beta Subscript t Baseline EndRoot
    bold x Subscript t minus 1"><mrow><msqrt><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î²</mi>
    <mi>t</mi></msub></mrow></msqrt> <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></math>
    will have variance <math alttext="1 minus beta Subscript t"><mrow><mn>1</mn> <mo>-</mo>
    <msub><mi>Î²</mi> <mi>t</mi></msub></mrow></math> and <math alttext="StartRoot
    beta Subscript t Baseline EndRoot epsilon Subscript t minus 1"><mrow><msqrt><msub><mi>Î²</mi>
    <mi>t</mi></msub></msqrt> <msub><mi>Ïµ</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></math>
    will have variance <math alttext="beta Subscript t"><msub><mi>Î²</mi> <mi>t</mi></msub></math>
    , using the rule that <math alttext="upper V a r left-parenthesis a upper X right-parenthesis
    equals a squared upper V a r left-parenthesis upper X right-parenthesis"><mrow><mi>V</mi>
    <mi>a</mi> <mi>r</mi> <mrow><mo>(</mo> <mi>a</mi> <mi>X</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msup><mi>a</mi> <mn>2</mn></msup> <mi>V</mi> <mi>a</mi> <mi>r</mi>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow></mrow></math> . Adding these together,
    we obtain a new distribution <math alttext="bold x Subscript t"><msub><mi>ğ±</mi>
    <mi>t</mi></msub></math> with zero mean and variance <math alttext="1 minus beta
    Subscript t Baseline plus beta Subscript t Baseline equals 1"><mrow><mn>1</mn>
    <mo>-</mo> <msub><mi>Î²</mi> <mi>t</mi></msub> <mo>+</mo> <msub><mi>Î²</mi> <mi>t</mi></msub>
    <mo>=</mo> <mn>1</mn></mrow></math> , using the rule that <math alttext="upper
    V a r left-parenthesis upper X plus upper Y right-parenthesis equals upper V a
    r left-parenthesis upper X right-parenthesis plus upper V a r left-parenthesis
    upper Y right-parenthesis"><mrow><mi>V</mi> <mi>a</mi> <mi>r</mi> <mo>(</mo> <mi>X</mi>
    <mo>+</mo> <mi>Y</mi> <mo>)</mo> <mo>=</mo> <mi>V</mi> <mi>a</mi> <mi>r</mi> <mo>(</mo>
    <mi>X</mi> <mo>)</mo> <mo>+</mo> <mi>V</mi> <mi>a</mi> <mi>r</mi> <mo>(</mo> <mi>Y</mi>
    <mo>)</mo></mrow></math> for independent <math alttext="upper X"><mi>X</mi></math>
    and <math alttext="upper Y"><mi>Y</mi></math> . Therefore, if <math alttext="bold
    x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math> is normalized to a zero mean and
    unit variance, then we guarantee that this is also true for all <math alttext="bold
    x Subscript t"><msub><mi>ğ±</mi> <mi>t</mi></msub></math> , including the final
    image <math alttext="bold x Subscript upper T"><msub><mi>ğ±</mi> <mi>T</mi></msub></math>
    , which will approximate a standard Gaussian distribution. This is exactly what
    we need, as we want to be able to easily sample <math alttext="bold x Subscript
    upper T"><msub><mi>ğ±</mi> <mi>T</mi></msub></math> and then apply a reverse diffusion
    process through our trained neural network model!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å‡è®¾<math alttext="bold x Subscript t minus 1"><msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math>å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ–¹å·®ï¼Œé‚£ä¹ˆ<math
    alttext="StartRoot 1 minus beta Subscript t Baseline EndRoot bold x Subscript
    t minus 1"><mrow><msqrt><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î²</mi> <mi>t</mi></msub></mrow></msqrt>
    <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></math>çš„æ–¹å·®å°†ä¸º<math
    alttext="1 minus beta Subscript t"><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î²</mi>
    <mi>t</mi></msub></mrow></math>ï¼Œè€Œ<math alttext="StartRoot beta Subscript t Baseline
    EndRoot epsilon Subscript t minus 1"><mrow><msqrt><msub><mi>Î²</mi> <mi>t</mi></msub></msqrt>
    <msub><mi>Ïµ</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></math>çš„æ–¹å·®å°†ä¸º<math
    alttext="beta Subscript t"><msub><mi>Î²</mi> <mi>t</msub></math>ï¼Œä½¿ç”¨<math alttext="upper
    V a r left-parenthesis a upper X right-parenthesis equals a squared upper V a
    r left-parenthesis upper X right-parenthesis"><mrow><mi>V</mi> <mi>a</mi> <mi>r</mi>
    <mrow><mo>(</mo> <mi>a</mi> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>a</mi>
    <mn>2</mn></msup> <mi>V</mi> <mi>a</mi> <mi>r</mi> <mrow><mo>(</mo> <mi>X</mi>
    <mo>)</mo></mrow></mrow></math>çš„è§„åˆ™ã€‚å°†è¿™äº›åŠ åœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªæ–°çš„åˆ†å¸ƒ<math alttext="bold x Subscript
    t"><msub><mi>ğ±</mi> <mi>t</mi></msub></math>ï¼Œå‡å€¼ä¸ºé›¶ï¼Œæ–¹å·®ä¸º<math alttext="1 minus beta
    Subscript t Baseline plus beta Subscript t Baseline equals 1"><mrow><mn>1</mn>
    <mo>-</mo> <msub><mi>Î²</mi> <mi>t</mi></msub> <mo>+</mo> <msub><mi>Î²</mi> <mi>t</mi></msub>
    <mo>=</mo> <mn>1</mn></mrow></math>ï¼Œä½¿ç”¨<math alttext="upper V a r left-parenthesis
    upper X plus upper Y right-parenthesis equals upper V a r left-parenthesis upper
    X right-parenthesis plus upper V a r left-parenthesis upper Y right-parenthesis"><mrow><mi>V</mi>
    <mi>a</mi> <mi>r</mi> <mo>(</mo> <mi>X</mi> <mo>+</mo> <mi>Y</mi> <mo>)</mo> <mo>=</mo>
    <mi>V</mi> <mi>a</mi> <mi>r</mi> <mo>(</mo> <mi>X</mi> <mo>)</mo> <mo>+</mo> <mi>V</mi>
    <mi>a</mi> <mi>r</mi> <mo>(</mo> <mi>Y</mi> <mo>)</mo></mrow></math>çš„è§„åˆ™ï¼Œå¯¹äºç‹¬ç«‹çš„<math
    alttext="upper X"><mi>X</mi></math>å’Œ<math alttext="upper Y"><mi>Y</mi></math>ã€‚å› æ­¤ï¼Œå¦‚æœ<math
    alttext="bold x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math>è¢«å½’ä¸€åŒ–ä¸ºé›¶å‡å€¼å’Œå•ä½æ–¹å·®ï¼Œé‚£ä¹ˆæˆ‘ä»¬ä¿è¯å¯¹æ‰€æœ‰<math
    alttext="bold x Subscript t"><msub><mi>ğ±</mi> <mi>t</mi></msub></math>éƒ½æˆç«‹ï¼ŒåŒ…æ‹¬æœ€ç»ˆå›¾åƒ<math
    alttext="bold x Subscript upper T"><msub><mi>ğ±</mi> <mi>T</mi></msub></math>ï¼Œå®ƒå°†è¿‘ä¼¼ä¸ºæ ‡å‡†é«˜æ–¯åˆ†å¸ƒã€‚è¿™æ­£æ˜¯æˆ‘ä»¬éœ€è¦çš„ï¼Œå› ä¸ºæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿè½»æ¾åœ°å¯¹<math
    alttext="bold x Subscript upper T"><msub><mi>ğ±</mi> <mi>T</mi></msub></math>è¿›è¡Œé‡‡æ ·ï¼Œç„¶åé€šè¿‡æˆ‘ä»¬è®­ç»ƒè¿‡çš„ç¥ç»ç½‘ç»œæ¨¡å‹åº”ç”¨åå‘æ‰©æ•£è¿‡ç¨‹ï¼
- en: 'In other words, our forward noising process <math alttext="q"><mi>q</mi></math>
    can also be written as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬çš„å‰å‘å™ªå£°è¿‡ç¨‹<math alttext="q"><mi>q</mi></math>ä¹Ÿå¯ä»¥å†™æˆå¦‚ä¸‹å½¢å¼ï¼š
- en: <math alttext="q left-parenthesis bold x Subscript t Baseline vertical-bar bold
    x Subscript t minus 1 Baseline right-parenthesis equals script upper N left-parenthesis
    bold x Subscript t Baseline semicolon StartRoot 1 minus beta Subscript t Baseline
    EndRoot bold x Subscript t minus 1 Baseline comma beta Subscript t Baseline bold
    upper I right-parenthesis" display="block"><mrow><mi>q</mi> <mrow><mo>(</mo> <msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>|</mo> <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mi>ğ’©</mi> <mrow><mo>(</mo> <msub><mi>ğ±</mi> <mi>t</mi></msub>
    <mo>;</mo> <msqrt><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î²</mi> <mi>t</mi></msub></mrow></msqrt>
    <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>,</mo>
    <msub><mi>Î²</mi> <mi>t</mi></msub> <mi>ğˆ</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="q left-parenthesis bold x Subscript t Baseline vertical-bar bold
    x Subscript t minus 1 Baseline right-parenthesis equals script upper N left-parenthesis
    bold x Subscript t Baseline semicolon StartRoot 1 minus beta Subscript t Baseline
    EndRoot bold x Subscript t minus 1 Baseline comma beta Subscript t Baseline bold
    upper I right-parenthesis" display="block"><mrow><mi>q</mi> <mrow><mo>(</mo> <msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>|</mo> <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mi>ğ’©</mi> <mrow><mo>(</mo> <msub><mi>ğ±</mi> <mi>t</mi></msub>
    <mo>;</mo> <msqrt><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î²</mi> <mi>t</mi></msub></mrow></msqrt>
    <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>,</mo>
    <msub><mi>Î²</mi> <mi>t</mi></msub> <mi>ğˆ</mi> <mo>)</mo></mrow></mrow></math>
- en: The Reparameterization Trick
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é‡æ–°å‚æ•°åŒ–æŠ€å·§
- en: It would also be useful to be able to jump straight from an image <math alttext="bold
    x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math> to any noised version of the image
    <math alttext="bold x Subscript t"><msub><mi>ğ±</mi> <mi>t</mi></msub></math> without
    having to go through <math alttext="t"><mi>t</mi></math> applications of <math
    alttext="q"><mi>q</mi></math> . Luckily, there is a reparameterization trick that
    we can use to do this.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å›¾åƒ<math alttext="bold x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math>ç›´æ¥è·³è½¬åˆ°å›¾åƒçš„ä»»ä½•å™ªå£°ç‰ˆæœ¬<math
    alttext="bold x Subscript t"><msub><mi>ğ±</mi> <mi>t</mi></msub></math>ä¹Ÿä¼šå¾ˆæœ‰ç”¨ï¼Œè€Œä¸å¿…ç»è¿‡<math
    alttext="t"><mi>t</mi></math>æ¬¡<math alttext="q"><mi>q</mi></math>çš„åº”ç”¨ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ç§é‡æ–°å‚æ•°åŒ–æŠ€å·§æ¥å®ç°è¿™ä¸€ç‚¹ã€‚
- en: 'If we define <math alttext="alpha Subscript t Baseline equals 1 minus beta
    Subscript t"><mrow><msub><mi>Î±</mi> <mi>t</mi></msub> <mo>=</mo> <mn>1</mn> <mo>-</mo>
    <msub><mi>Î²</mi> <mi>t</mi></msub></mrow></math> and <math alttext="alpha overbar
    Subscript t Baseline equals product Underscript i equals 1 Overscript t Endscripts
    alpha Subscript i"><mrow><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover>
    <mi>t</mi></msub> <mo>=</mo> <msubsup><mo>âˆ</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>t</mi></msubsup> <msub><mi>Î±</mi> <mi>i</mi></msub></mrow></math> , then we
    can write the following:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬å®šä¹‰<math alttext="alpha Subscript t Baseline equals 1 minus beta Subscript
    t"><mrow><msub><mi>Î±</mi> <mi>t</mi></msub> <mo>=</mo> <mn>1</mn> <mo>-</mo> <msub><mi>Î²</mi>
    <mi>t</mi></msub></mrow></math>å’Œ<math alttext="alpha overbar Subscript t Baseline
    equals product Underscript i equals 1 Overscript t Endscripts alpha Subscript
    i"><mrow><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub>
    <mo>=</mo> <msubsup><mo>âˆ</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>t</mi></msubsup>
    <msub><mi>Î±</mi> <mi>i</mi></msub></mrow></math>ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å†™æˆä»¥ä¸‹å½¢å¼ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column bold x Subscript t 2nd Column
    equals 3rd Column StartRoot alpha Subscript t Baseline EndRoot bold x Subscript
    t minus 1 plus StartRoot 1 minus alpha Subscript t Baseline EndRoot epsilon Subscript
    t minus 1 2nd Row 1st Column Blank 2nd Column equals 3rd Column StartRoot alpha
    Subscript t Baseline alpha Subscript t minus 1 Baseline EndRoot bold x Subscript
    t minus 2 plus StartRoot 1 minus alpha Subscript t Baseline alpha Subscript t
    minus 1 Baseline EndRoot epsilon 3rd Row 1st Column Blank 2nd Column equals 3rd
    Column  ellipsis 4th Row 1st Column Blank 2nd Column equals 3rd Column StartRoot
    alpha overbar Subscript t Baseline EndRoot bold x 0 plus StartRoot 1 minus alpha
    overbar Subscript t Baseline EndRoot epsilon EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>ğ±</mi> <mi>t</mi></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msqrt><msub><mi>Î±</mi> <mi>t</mi></msub></msqrt>
    <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>+</mo>
    <msqrt><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î±</mi> <mi>t</mi></msub></mrow></msqrt>
    <msub><mi>Ïµ</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msqrt><mrow><msub><mi>Î±</mi>
    <mi>t</mi></msub> <msub><mi>Î±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></msqrt>
    <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>2</mn></mrow></msub> <mo>+</mo>
    <msqrt><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î±</mi> <mi>t</mi></msub> <msub><mi>Î±</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></msqrt> <mi>Ïµ</mi></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mo>â‹¯</mo></mtd></mtr> <mtr><mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><msqrt><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover>
    <mi>t</mi></msub></msqrt> <msub><mi>ğ±</mi> <mn>0</mn></msub> <mo>+</mo> <msqrt><mrow><mn>1</mn>
    <mo>-</mo> <msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></mrow></msqrt>
    <mi>Ïµ</mi></mrow></mtd></mtr></mtable></math>
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column bold x Subscript t 2nd Column
    equals 3rd Column StartRoot alpha Subscript t Baseline EndRoot bold x Subscript
    t minus 1 plus StartRoot 1 minus alpha Subscript t Baseline EndRoot epsilon Subscript
    t minus 1 2nd Row 1st Column Blank 2nd Column equals 3rd Column StartRoot alpha
    Subscript t Baseline alpha Subscript t minus 1 Baseline EndRoot bold x Subscript
    t minus 2 plus StartRoot 1 minus alpha Subscript t Baseline alpha Subscript t
    minus 1 Baseline EndRoot epsilon 3rd Row 1st Column Blank 2nd Column equals 3rd
    Column  ellipsis 4th Row 1st Column Blank 2nd Column equals 3rd Column StartRoot
    alpha overbar Subscript t Baseline EndRoot bold x 0 plus StartRoot 1 minus alpha
    overbar Subscript t Baseline EndRoot epsilon EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>ğ±</mi> <mi>t</mi></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msqrt><msub><mi>Î±</mi> <mi>t</mi></msub></msqrt>
    <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>+</mo>
    <msqrt><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î±</mi> <mi>t</mi></msub></mrow></msqrt>
    <msub><mi>Ïµ</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msqrt><mrow><msub><mi>Î±</mi>
    <mi>t</mi></msub> <msub><mi>Î±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></msqrt>
    <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>2</mn></mrow></msub> <mo>+</mo>
    <msqrt><mrow><mn>1</mn> <mo>-</mo> <msub><mi>Î±</mi> <mi>t</mi></msub> <msub><mi>Î±</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></msqrt> <mi>Ïµ</mi></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mo>â‹¯</mo></mtd></mtr> <mtr><mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><msqrt><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover>
    <mi>t</mi></msub></msqrt> <msub><mi>ğ±</mi> <mn>0</mn></msub> <mo>+</mo> <msqrt><mrow><mn>1</mn>
    <mo>-</mo> <msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></mrow></msqrt>
    <mi>Ïµ</mi></mrow></mtd></mtr></mtable></math>
- en: Note that the second line uses the fact that we can add two Gaussians to obtain
    a new Gaussian. We therefore have a way to jump from the original image <math
    alttext="bold x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math> to any step of the
    forward diffusion process <math alttext="bold x Subscript t"><msub><mi>ğ±</mi>
    <mi>t</mi></msub></math> . Moreover, we can define the diffusion schedule using
    the <math alttext="alpha overbar Subscript t"><msub><mover accent="true"><mi>Î±</mi>
    <mo>Â¯</mo></mover> <mi>t</mi></msub></math> values, instead of the original <math
    alttext="beta Subscript t"><msub><mi>Î²</mi> <mi>t</mi></msub></math> values, with
    the interpretation that <math alttext="alpha overbar Subscript t"><msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></math> is the variance
    due to the signal (the original image, <math alttext="bold x 0"><msub><mi>ğ±</mi>
    <mn>0</mn></msub></math> ) and <math alttext="1 minus alpha overbar Subscript
    t"><mrow><mn>1</mn> <mo>-</mo> <msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover>
    <mi>t</mi></msub></mrow></math> is the variance due to the noise ( <math alttext="epsilon"><mi>Ïµ</mi></math>
    ).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œç¬¬äºŒè¡Œä½¿ç”¨äº†æˆ‘ä»¬å¯ä»¥å°†ä¸¤ä¸ªé«˜æ–¯å‡½æ•°ç›¸åŠ ä»¥è·å¾—ä¸€ä¸ªæ–°é«˜æ–¯å‡½æ•°çš„äº‹å®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥ä»åŸå§‹å›¾åƒ<math alttext="bold x
    0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math>è·³è½¬åˆ°å‰å‘æ‰©æ•£è¿‡ç¨‹çš„ä»»ä½•æ­¥éª¤<math alttext="bold
    x Subscript t"><msub><mi>ğ±</mi> <mi>t</mi></msub></math>ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨<math alttext="alpha
    overbar Subscript t"><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover>
    <mi>t</mi></msub></math>å€¼æ¥å®šä¹‰æ‰©æ•£è¿›åº¦è¡¨ï¼Œè€Œä¸æ˜¯åŸå§‹çš„<math alttext="beta Subscript t"><msub><mi>Î²</mi>
    <mi>t</mi></msub></math>å€¼ï¼Œè§£é‡Šä¸º<math alttext="alpha overbar Subscript t"><msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></math>æ˜¯ç”±ä¿¡å·ï¼ˆåŸå§‹å›¾åƒï¼Œ<math
    alttext="bold x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math>ï¼‰å¼•èµ·çš„æ–¹å·®ï¼Œè€Œ<math alttext="1
    minus alpha overbar Subscript t"><mrow><mn>1</mn> <mo>-</mo> <msub><mover accent="true"><mi>Î±</mi>
    <mo>Â¯</mo></mover> <mi>t</mi></msub></mrow></math>æ˜¯ç”±å™ªå£°ï¼ˆ<math alttext="epsilon"><mi>Ïµ</mi></math>ï¼‰å¼•èµ·çš„æ–¹å·®ã€‚
- en: 'The forward diffusion process <math alttext="q"><mi>q</mi></math> can therefore
    also be written as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å‰å‘æ‰©æ•£è¿‡ç¨‹<math alttext="q"><mi>q</mi></math>ä¹Ÿå¯ä»¥å†™æˆå¦‚ä¸‹å½¢å¼ï¼š
- en: <math alttext="q left-parenthesis bold x Subscript t Baseline vertical-bar bold
    x 0 right-parenthesis equals script upper N left-parenthesis bold x Subscript
    t Baseline semicolon StartRoot alpha overbar Subscript t Baseline EndRoot bold
    x 0 comma left-parenthesis 1 minus alpha overbar Subscript t Baseline right-parenthesis
    bold upper I right-parenthesis" display="block"><mrow><mi>q</mi> <mrow><mo>(</mo>
    <msub><mi>ğ±</mi> <mi>t</mi></msub> <mo>|</mo> <msub><mi>ğ±</mi> <mn>0</mn></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mi>ğ’©</mi> <mrow><mo>(</mo> <msub><mi>ğ±</mi> <mi>t</mi></msub>
    <mo>;</mo> <msqrt><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></msqrt>
    <msub><mi>ğ±</mi> <mn>0</mn></msub> <mo>,</mo> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo>
    <msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub> <mo>)</mo></mrow>
    <mi>ğˆ</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="q left-parenthesis bold x Subscript t Baseline vertical-bar bold
    x 0 right-parenthesis equals script upper N left-parenthesis bold x Subscript
    t Baseline semicolon StartRoot alpha overbar Subscript t Baseline EndRoot bold
    x 0 comma left-parenthesis 1 minus alpha overbar Subscript t Baseline right-parenthesis
    bold upper I right-parenthesis" display="block"><mrow><mi>q</mi> <mrow><mo>(</mo>
    <msub><mi>ğ±</mi> <mi>t</mi></msub> <mo>|</mo> <msub><mi>ğ±</mi> <mn>0</mn></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mi>ğ’©</mi> <mrow><mo>(</mo> <msub><mi>ğ±</mi> <mi>t</mi></msub>
    <mo>;</mo> <msqrt><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></msqrt>
    <msub><mi>ğ±</mi> <mn>0</mn></msub> <mo>,</mo> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo>
    <msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub> <mo>)</mo></mrow>
    <mi>ğˆ</mi> <mo>)</mo></mrow></mrow></math>
- en: Diffusion Schedules
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‰©æ•£è¿›åº¦è¡¨
- en: Notice that we are also free to choose a different <math alttext="beta Subscript
    t"><msub><mi>Î²</mi> <mi>t</mi></msub></math> at each timestepâ€”they donâ€™t all have
    be the same. How the <math alttext="beta Subscript t"><msub><mi>Î²</mi> <mi>t</mi></msub></math>
    (or <math alttext="alpha overbar Subscript t"><msub><mover accent="true"><mi>Î±</mi>
    <mo>Â¯</mo></mover> <mi>t</mi></msub></math> ) values change with <math alttext="t"><mi>t</mi></math>
    is called the *diffusion* *schedule*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿é€‰æ‹©ä¸åŒçš„<math alttext="beta Subscript t"><msub><mi>Î²</mi> <mi>t</mi></msub></math>â€”â€”å®ƒä»¬ä¸å¿…å…¨éƒ¨ç›¸åŒã€‚<math
    alttext="beta Subscript t"><msub><mi>Î²</mi> <mi>t</mi></msub></math>ï¼ˆæˆ–<math alttext="alpha
    overbar Subscript t"><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover>
    <mi>t</mi></msub></math>ï¼‰å€¼éšç€<math alttext="t"><mi>t</mi></math>çš„å˜åŒ–è¢«ç§°ä¸º*æ‰©æ•£è¿›åº¦è¡¨*ã€‚
- en: In the original paper (Ho et al., 2020), the authors chose a *linear diffusion
    schedule* for <math alttext="beta Subscript t"><msub><mi>Î²</mi> <mi>t</mi></msub></math>
    â€”that is, <math alttext="beta Subscript t"><msub><mi>Î²</mi> <mi>t</mi></msub></math>
    increases linearly with <math alttext="t"><mi>t</mi></math> , from <math alttext="beta
    1 equals"><mrow><msub><mi>Î²</mi> <mn>1</mn></msub> <mo>=</mo></mrow></math> 0.0001
    to <math alttext="beta Subscript upper T Baseline equals"><mrow><msub><mi>Î²</mi>
    <mi>T</mi></msub> <mo>=</mo></mrow></math> 0.02\. This ensures that in the early
    stages of the noising process we take smaller noising steps than in the later
    stages, when the image is already very noisy.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åŸå§‹è®ºæ–‡ä¸­ï¼ˆHoç­‰äººï¼Œ2020å¹´ï¼‰ï¼Œä½œè€…é€‰æ‹©äº†ä¸€ä¸ª*çº¿æ€§æ‰©æ•£è¿›åº¦è¡¨*ç”¨äº<math alttext="beta Subscript t"><msub><mi>Î²</mi>
    <mi>t</mi></msub></math>â€”â€”å³ï¼Œ<math alttext="beta Subscript t"><msub><mi>Î²</mi>
    <mi>t</mi></msub></math>éšç€<math alttext="t"><mi>t</mi></math>çº¿æ€§å¢åŠ ï¼Œä»<math alttext="beta
    1 equals"><mrow><msub><mi>Î²</mi> <mn>1</mn></msub> <mo>=</mo></mrow></math>0.0001åˆ°<math
    alttext="beta Subscript upper T Baseline equals"><mrow><msub><mi>Î²</mi> <mi>T</mi></msub>
    <mo>=</mo></mrow></math>0.02ã€‚è¿™ç¡®ä¿åœ¨å™ªå£°è¿‡ç¨‹çš„æ—©æœŸé˜¶æ®µï¼Œæˆ‘ä»¬é‡‡å–æ¯”åœ¨åæœŸé˜¶æ®µæ›´å°çš„å™ªå£°æ­¥éª¤ï¼Œå½“å›¾åƒå·²ç»éå¸¸å˜ˆæ‚æ—¶ã€‚
- en: We can code up a linear diffusion schedule as shown in [ExampleÂ 8-3](#linear_diffusion_schedule).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç¼–å†™ä¸€ä¸ªçº¿æ€§æ‰©æ•£è¿›åº¦è¡¨ï¼Œå¦‚[ç¤ºä¾‹8-3](#linear_diffusion_schedule)æ‰€ç¤ºã€‚
- en: Example 8-3\. The linear diffusion schedule
  id: totrans-56
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹8-3ã€‚çº¿æ€§æ‰©æ•£è¿›åº¦è¡¨
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](Images/1.png)](#co_diffusion_models_CO2-1)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_diffusion_models_CO2-1)'
- en: The diffusion times are equally spaced steps between 0 and 1.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰©æ•£æ—¶é—´æ˜¯0åˆ°1ä¹‹é—´ç­‰é—´éš”çš„æ­¥éª¤ã€‚
- en: '[![2](Images/2.png)](#co_diffusion_models_CO2-2)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_diffusion_models_CO2-2)'
- en: The linear diffusion schedule is applied to the diffusion times to produce the
    noise and signal rates.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§æ‰©æ•£è¿›åº¦è¡¨åº”ç”¨äºæ‰©æ•£æ—¶é—´ä»¥äº§ç”Ÿå™ªå£°å’Œä¿¡å·é€Ÿç‡ã€‚
- en: 'In a later paper it was found that a *cosine diffusion schedule* outperformed
    the linear schedule from the original paper.^([5](ch08.xhtml#idm45387010764208))
    A cosine schedule defines the following values of <math alttext="alpha overbar
    Subscript t"><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></math>
    :'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åç»­çš„ä¸€ç¯‡è®ºæ–‡ä¸­å‘ç°ï¼Œ*ä½™å¼¦æ‰©æ•£è¿›åº¦è¡¨*ä¼˜äºåŸå§‹è®ºæ–‡ä¸­çš„çº¿æ€§è¿›åº¦è¡¨ã€‚ä½™å¼¦è¿›åº¦è¡¨å®šä¹‰äº†ä»¥ä¸‹<math alttext="alpha overbar Subscript
    t"><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></math>å€¼ï¼š
- en: <math alttext="alpha overbar Subscript t Baseline equals cosine squared left-parenthesis
    StartFraction t Over upper T EndFraction dot StartFraction pi Over 2 EndFraction
    right-parenthesis" display="block"><mrow><msub><mover accent="true"><mi>Î±</mi>
    <mo>Â¯</mo></mover> <mi>t</mi></msub> <mo>=</mo> <msup><mo form="prefix">cos</mo>
    <mn>2</mn></msup> <mrow><mo>(</mo> <mfrac><mi>t</mi> <mi>T</mi></mfrac> <mo>Â·</mo>
    <mfrac><mi>Ï€</mi> <mn>2</mn></mfrac> <mo>)</mo></mrow></mrow></math>
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="alpha overbar Subscript t Baseline equals cosine squared left-parenthesis
    StartFraction t Over upper T EndFraction dot StartFraction pi Over 2 EndFraction
    right-parenthesis" display="block"><mrow><msub><mover accent="true"><mi>Î±</mi>
    <mo>Â¯</mo></mover> <mi>t</mi></msub> <mo>=</mo> <msup><mo form="prefix">cos</mo>
    <mn>2</mn></msup> <mrow><mo>(</mo> <mfrac><mi>t</mi> <mi>T</mi></mfrac> <mo>Â·</mo>
    <mfrac><mi>Ï€</mi> <mn>2</mn></mfrac> <mo>)</mo></mrow></mrow></math>
- en: 'The updated equation is therefore as follows (using the trigonometric identity
    <math alttext="cosine squared left-parenthesis x right-parenthesis plus sine squared
    left-parenthesis x right-parenthesis equals 1"><mrow><msup><mo form="prefix">cos</mo>
    <mn>2</mn></msup> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>+</mo> <msup><mo
    form="prefix">sin</mo> <mn>2</mn></msup> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mn>1</mn></mrow></math> ):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæ›´æ–°çš„æ–¹ç¨‹å¦‚ä¸‹ï¼ˆä½¿ç”¨ä¸‰è§’æ’ç­‰å¼ <math alttext="cosine squared left-parenthesis x right-parenthesis
    plus sine squared left-parenthesis x right-parenthesis equals 1"><mrow><msup><mo
    form="prefix">cos</mo> <mn>2</mn></msup> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>+</mo> <msup><mo form="prefix">sin</mo> <mn>2</mn></msup> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn></mrow></math>ï¼‰ï¼š
- en: <math alttext="bold x Subscript t Baseline equals cosine left-parenthesis StartFraction
    t Over upper T EndFraction dot StartFraction pi Over 2 EndFraction right-parenthesis
    bold x 0 plus sine left-parenthesis StartFraction t Over upper T EndFraction dot
    StartFraction pi Over 2 EndFraction right-parenthesis epsilon" display="block"><mrow><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>=</mo> <mo form="prefix">cos</mo> <mrow><mo>(</mo> <mfrac><mi>t</mi>
    <mi>T</mi></mfrac> <mo>Â·</mo> <mfrac><mi>Ï€</mi> <mn>2</mn></mfrac> <mo>)</mo></mrow>
    <msub><mi>ğ±</mi> <mn>0</mn></msub> <mo>+</mo> <mo form="prefix">sin</mo> <mrow><mo>(</mo>
    <mfrac><mi>t</mi> <mi>T</mi></mfrac> <mo>Â·</mo> <mfrac><mi>Ï€</mi> <mn>2</mn></mfrac>
    <mo>)</mo></mrow> <mi>Ïµ</mi></mrow></math>
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold x Subscript t Baseline equals cosine left-parenthesis StartFraction
    t Over upper T EndFraction dot StartFraction pi Over 2 EndFraction right-parenthesis
    bold x 0 plus sine left-parenthesis StartFraction t Over upper T EndFraction dot
    StartFraction pi Over 2 EndFraction right-parenthesis epsilon" display="block"><mrow><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>=</mo> <mo form="prefix">cos</mo> <mrow><mo>(</mo> <mfrac><mi>t</mi>
    <mi>T</mi></mfrac> <mo>Â·</mo> <mfrac><mi>Ï€</mi> <mn>2</mn></mfrac> <mo>)</mo></mrow>
    <msub><mi>ğ±</mi> <mn>0</mn></msub> <mo>+</mo> <mo form="prefix">sin</mo> <mrow><mo>(</mo>
    <mfrac><mi>t</mi> <mi>T</mi></mfrac> <mo>Â·</mo> <mfrac><mi>Ï€</mi> <mn>2</mn></mfrac>
    <mo>)</mo></mrow> <mi>Ïµ</mi></mrow></math>
- en: This equation is a simplified version of the actual cosine diffusion schedule
    used in the paper. The authors also add an offset term and scaling to prevent
    the noising steps from being too small at the beginning of the diffusion process.
    We can code up the cosine and offset cosine diffusion schedules as shown in [ExampleÂ 8-4](#cosine_diffusion_schedule).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ–¹ç¨‹æ˜¯è®ºæ–‡ä¸­ä½¿ç”¨çš„å®é™…ä½™å¼¦æ‰©æ•£æ—¶é—´è¡¨çš„ç®€åŒ–ç‰ˆæœ¬ã€‚ä½œè€…è¿˜æ·»åŠ äº†ä¸€ä¸ªåç§»é¡¹å’Œç¼©æ”¾ï¼Œä»¥é˜²æ­¢æ‰©æ•£è¿‡ç¨‹å¼€å§‹æ—¶å™ªå£°æ­¥éª¤å¤ªå°ã€‚æˆ‘ä»¬å¯ä»¥ç¼–å†™ä½™å¼¦å’Œåç§»ä½™å¼¦æ‰©æ•£æ—¶é—´è¡¨ï¼Œå¦‚[ç¤ºä¾‹8-4](#cosine_diffusion_schedule)æ‰€ç¤ºã€‚
- en: Example 8-4\. The cosine and offset cosine diffusion schedules
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹8-4\. ä½™å¼¦å’Œåç§»ä½™å¼¦æ‰©æ•£æ—¶é—´è¡¨
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](Images/1.png)](#co_diffusion_models_CO3-1)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_diffusion_models_CO3-1)'
- en: The pure cosine diffusion schedule (without offset or rescaling).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: çº¯ä½™å¼¦æ‰©æ•£æ—¶é—´è¡¨ï¼ˆä¸åŒ…æ‹¬åç§»æˆ–é‡æ–°ç¼©æ”¾ï¼‰ã€‚
- en: '[![2](Images/2.png)](#co_diffusion_models_CO3-2)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_diffusion_models_CO3-2)'
- en: The offset cosine diffusion schedule that we will be using, which adjusts the
    schedule to ensure the noising steps are not too small at the start of the noising
    process.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨çš„åç§»ä½™å¼¦æ‰©æ•£æ—¶é—´è¡¨ä¼šè°ƒæ•´æ—¶é—´è¡¨ï¼Œä»¥ç¡®ä¿åœ¨æ‰©æ•£è¿‡ç¨‹å¼€å§‹æ—¶å™ªå£°æ­¥éª¤ä¸ä¼šå¤ªå°ã€‚
- en: We can compute the <math alttext="alpha overbar Subscript t"><msub><mover accent="true"><mi>Î±</mi>
    <mo>Â¯</mo></mover> <mi>t</mi></msub></math> values for each <math alttext="t"><mi>t</mi></math>
    to show how much signal ( <math alttext="alpha overbar Subscript t"><msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></math> ) and noise
    ( <math alttext="1 minus alpha overbar Subscript t"><mrow><mn>1</mn> <mo>-</mo>
    <msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></mrow></math>
    ) is let through at each stage of the process for the linear, cosine, and offset
    cosine diffusion schedules, as shown in [FigureÂ 8-4](#signal_and_noise_linear).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥è®¡ç®—æ¯ä¸ª <math alttext="t"><mi>t</mi></math> çš„ <math alttext="alpha overbar
    Subscript t"><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></math>
    å€¼ï¼Œä»¥æ˜¾ç¤ºåœ¨çº¿æ€§ã€ä½™å¼¦å’Œåç§»ä½™å¼¦æ‰©æ•£æ—¶é—´è¡¨çš„æ¯ä¸ªé˜¶æ®µä¸­æœ‰å¤šå°‘ä¿¡å·ï¼ˆ <math alttext="alpha overbar Subscript t"><msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></math> ï¼‰å’Œå™ªå£°ï¼ˆ <math
    alttext="1 minus alpha overbar Subscript t"><mrow><mn>1</mn> <mo>-</mo> <msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></mrow></math> ï¼‰é€šè¿‡ï¼Œå¦‚[å›¾8-4](#signal_and_noise_linear)æ‰€ç¤ºã€‚
- en: '![](Images/gdl2_0804.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0804.png)'
- en: Figure 8-4\. The signal and noise at each step of the noising process, for the
    linear, cosine, and offset cosine diffusion schedules
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-4\. åœ¨æ‰©æ•£è¿‡ç¨‹çš„æ¯ä¸ªæ­¥éª¤ä¸­çš„ä¿¡å·å’Œå™ªå£°ï¼Œå¯¹äºçº¿æ€§ã€ä½™å¼¦å’Œåç§»ä½™å¼¦æ‰©æ•£æ—¶é—´è¡¨
- en: Notice how the noise level ramps up more slowly in the cosine diffusion schedule.
    A cosine diffusion schedule adds noise to the image more gradually than a linear
    diffusion schedule, which improves training efficiency and generation quality.
    This can also be seen in images that have been corrupted by the linear and cosine
    schedules ([FigureÂ 8-5](#diff_schedule_examples)).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œä½™å¼¦æ‰©æ•£æ—¶é—´è¡¨ä¸­çš„å™ªå£°çº§åˆ«ä¸Šå‡é€Ÿåº¦è¾ƒæ…¢ã€‚ä½™å¼¦æ‰©æ•£æ—¶é—´è¡¨å°†å™ªå£°é€æ¸æ·»åŠ åˆ°å›¾åƒä¸­ï¼Œæ¯”çº¿æ€§æ‰©æ•£æ—¶é—´è¡¨æ›´æœ‰æ•ˆåœ°æé«˜äº†è®­ç»ƒæ•ˆç‡å’Œç”Ÿæˆè´¨é‡ã€‚è¿™ä¹Ÿå¯ä»¥åœ¨è¢«çº¿æ€§å’Œä½™å¼¦æ—¶é—´è¡¨ç ´åçš„å›¾åƒä¸­çœ‹åˆ°ï¼ˆ[å›¾8-5](#diff_schedule_examples)ï¼‰ã€‚
- en: '![](Images/gdl2_0805.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0805.png)'
- en: 'Figure 8-5\. An image being corrupted by the linear (top) and cosine (bottom)
    diffusion schedules, at equally spaced values of t from 0 to T (source: [Ho et
    al., 2020](https://arxiv.org/abs/2006.11239))'
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-5\. ä¸€ä¸ªå›¾åƒè¢«çº¿æ€§ï¼ˆé¡¶éƒ¨ï¼‰å’Œä½™å¼¦ï¼ˆåº•éƒ¨ï¼‰æ‰©æ•£æ—¶é—´è¡¨ç ´åï¼Œä»0åˆ°Tçš„ç­‰é—´è·å€¼ï¼ˆæ¥æºï¼š[Hoç­‰äººï¼Œ2020](https://arxiv.org/abs/2006.11239)ï¼‰
- en: The Reverse Diffusion Process
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åå‘æ‰©æ•£è¿‡ç¨‹
- en: Now letâ€™s look at the reverse diffusion process. To recap, we are looking to
    build a neural network <math alttext="p Subscript theta Baseline left-parenthesis
    bold x Subscript t minus 1 Baseline vertical-bar bold x Subscript t Baseline right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>Î¸</mi></msub> <mrow><mo>(</mo> <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>|</mo> <msub><mi>ğ±</mi> <mi>t</mi></msub> <mo>)</mo></mrow></mrow></math>
    that can *undo* the noising processâ€”that is, approximate the reverse distribution
    <math alttext="q left-parenthesis bold x Subscript t minus 1 Baseline vertical-bar
    bold x Subscript t Baseline right-parenthesis"><mrow><mi>q</mi> <mo>(</mo> <msub><mi>ğ±</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>|</mo> <msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>)</mo></mrow></math> . If we can do this, we can sample
    random noise from <math alttext="script upper N left-parenthesis 0 comma bold
    upper I right-parenthesis"><mrow><mi>ğ’©</mi> <mo>(</mo> <mn>0</mn> <mo>,</mo> <mi>ğˆ</mi>
    <mo>)</mo></mrow></math> and then apply the reverse diffusion process multiple
    times in order to generate a novel image. This is visualized in [FigureÂ 8-6](#reverse_diff).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹åå‘æ‰©æ•£è¿‡ç¨‹ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæˆ‘ä»¬è¦æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œ <math alttext="p Subscript theta Baseline left-parenthesis
    bold x Subscript t minus 1 Baseline vertical-bar bold x Subscript t Baseline right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>Î¸</mi></msub> <mrow><mo>(</mo> <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>|</mo> <msub><mi>ğ±</mi> <mi>t</mi></msub> <mo>)</mo></mrow></mrow></math>ï¼Œå®ƒå¯ä»¥*æ’¤é”€*æ‰©æ•£è¿‡ç¨‹ï¼Œå³è¿‘ä¼¼åå‘åˆ†å¸ƒ
    <math alttext="q left-parenthesis bold x Subscript t minus 1 Baseline vertical-bar
    bold x Subscript t Baseline right-parenthesis"><mrow><mi>q</mi> <mo>(</mo> <msub><mi>ğ±</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>|</mo> <msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>)</mo></mrow></math>ã€‚å¦‚æœæˆ‘ä»¬èƒ½åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥ä» <math alttext="script
    upper N left-parenthesis 0 comma bold upper I right-parenthesis"><mrow><mi>ğ’©</mi>
    <mo>(</mo> <mn>0</mn> <mo>,</mo> <mi>ğˆ</mi> <mo>)</mo></mrow></math> ä¸­éšæœºé‡‡æ ·å™ªå£°ï¼Œç„¶åå¤šæ¬¡åº”ç”¨åå‘æ‰©æ•£è¿‡ç¨‹ä»¥ç”Ÿæˆæ–°é¢–çš„å›¾åƒã€‚è¿™åœ¨[å›¾8-6](#reverse_diff)ä¸­å¯è§†åŒ–ã€‚
- en: '![](Images/gdl2_0806.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0806.png)'
- en: Figure 8-6\. The reverse diffusion process <math alttext="p Subscript theta
    Baseline period left-parenthesis bold x Subscript t minus 1 Baseline vertical-bar
    bold x Subscript t Baseline right-parenthesis"><mrow><msub><mi>p</mi> <mi>Î¸</mi></msub>
    <mo>.</mo> <mrow><mo>(</mo> <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>|</mo> <msub><mi>ğ±</mi> <mi>t</mi></msub> <mo>)</mo></mrow></mrow></math>
    tries to *undo* the noise produced by the forward diffusion process
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-6ã€‚åå‘æ‰©æ•£è¿‡ç¨‹<math alttext="p Subscript theta Baseline period left-parenthesis
    bold x Subscript t minus 1 Baseline vertical-bar bold x Subscript t Baseline right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>Î¸</mi></msub> <mo>.</mo> <mrow><mo>(</mo> <msub><mi>ğ±</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>|</mo> <msub><mi>ğ±</mi> <mi>t</mi></msub> <mo>)</mo></mrow></mrow></math>è¯•å›¾*æ’¤æ¶ˆ*ç”±æ­£å‘æ‰©æ•£è¿‡ç¨‹äº§ç”Ÿçš„å™ªå£°
- en: There are many similarities between the reverse diffusion process and the decoder
    of a variational autoencoder. In both, we aim to transform random noise into meaningful
    output using a neural network. The difference between diffusion models and VAEs
    is that in a VAE the forward process (converting images to noise) is part of the
    model (i.e., it is learned), whereas in a diffusion model it is unparameterized.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘æ‰©æ•£è¿‡ç¨‹å’Œå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨çš„è§£ç å™¨ä¹‹é—´å­˜åœ¨è®¸å¤šç›¸ä¼¼ä¹‹å¤„ã€‚ åœ¨ä¸¤è€…ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡éƒ½æ˜¯ä½¿ç”¨ç¥ç»ç½‘ç»œå°†éšæœºå™ªå£°è½¬æ¢ä¸ºæœ‰æ„ä¹‰çš„è¾“å‡ºã€‚ æ‰©æ•£æ¨¡å‹å’ŒVAEä¹‹é—´çš„åŒºåˆ«åœ¨äºï¼Œåœ¨VAEä¸­ï¼Œæ­£å‘è¿‡ç¨‹ï¼ˆå°†å›¾åƒè½¬æ¢ä¸ºå™ªå£°ï¼‰æ˜¯æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼ˆå³ï¼Œå®ƒæ˜¯å­¦ä¹ çš„ï¼‰ï¼Œè€Œåœ¨æ‰©æ•£æ¨¡å‹ä¸­ï¼Œå®ƒæ˜¯éå‚æ•°åŒ–çš„ã€‚
- en: Therefore, it makes sense to apply the same loss function as in a variational
    autoencoder. The original DDPM paper derives the exact form of this loss function
    and shows that it can be optimized by training a network <math alttext="epsilon
    Subscript theta"><msub><mi>Ïµ</mi> <mi>Î¸</mi></msub></math> to predict the noise
    <math alttext="epsilon"><mi>Ïµ</mi></math> that has been added to a given image
    <math alttext="bold x bold 0"><msub><mi>ğ±</mi> <mn mathvariant="bold">0</mn></msub></math>
    at timestep <math alttext="t"><mi>t</mi></math> .
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå°†ä¸å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ä¸­ç›¸åŒçš„æŸå¤±å‡½æ•°åº”ç”¨æ˜¯æœ‰æ„ä¹‰çš„ã€‚ åŸå§‹çš„DDPMè®ºæ–‡æ¨å¯¼å‡ºäº†è¿™ä¸ªæŸå¤±å‡½æ•°çš„ç¡®åˆ‡å½¢å¼ï¼Œå¹¶è¡¨æ˜å¯ä»¥é€šè¿‡è®­ç»ƒä¸€ä¸ªç½‘ç»œ<math alttext="epsilon
    Subscript theta"><msub><mi>Ïµ</mi> <mi>Î¸</mi></msub></math>æ¥é¢„æµ‹å·²æ·»åŠ åˆ°ç»™å®šå›¾åƒ<math alttext="bold
    x bold 0"><msub><mi>ğ±</mi> <mn mathvariant="bold">0</mn></msub></math>çš„å™ªå£°<math
    alttext="epsilon"><mi>Ïµ</mi></math>åœ¨æ—¶é—´æ­¥<math alttext="t"><mi>t</mi></math>ã€‚
- en: In other words, we sample an image <math alttext="bold x bold 0"><msub><mi>ğ±</mi>
    <mn mathvariant="bold">0</mn></msub></math> and transform it by <math alttext="t"><mi>t</mi></math>
    noising steps to get the image <math alttext="bold x Subscript t Baseline equals
    StartRoot alpha overbar Subscript t Baseline EndRoot bold x 0 plus StartRoot 1
    minus alpha overbar Subscript t Baseline EndRoot epsilon"><mrow><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>=</mo> <msqrt><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover>
    <mi>t</mi></msub></msqrt> <msub><mi>ğ±</mi> <mn>0</mn></msub> <mo>+</mo> <msqrt><mrow><mn>1</mn>
    <mo>-</mo> <msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></mrow></msqrt>
    <mi>Ïµ</mi></mrow></math> . We give this new image and the noising rate <math alttext="alpha
    overbar Subscript t"><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover>
    <mi>t</mi></msub></math> to the neural network and ask it to predict <math alttext="epsilon"><mi>Ïµ</mi></math>
    , taking a gradient step against the squared error between the prediction <math
    alttext="epsilon Subscript theta Baseline left-parenthesis bold x Subscript t
    Baseline right-parenthesis"><mrow><msub><mi>Ïµ</mi> <mi>Î¸</mi></msub> <mrow><mo>(</mo>
    <msub><mi>ğ±</mi> <mi>t</mi></msub> <mo>)</mo></mrow></mrow></math> and the true
    <math alttext="epsilon"><mi>Ïµ</mi></math> .
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬å¯¹å›¾åƒ<math alttext="bold x bold 0"><msub><mi>ğ±</mi> <mn mathvariant="bold">0</mn></msub></math>è¿›è¡Œé‡‡æ ·ï¼Œå¹¶é€šè¿‡<math
    alttext="t"><mi>t</mi></math>ä¸ªå™ªå£°æ­¥éª¤å°†å…¶è½¬æ¢ä¸ºå›¾åƒ<math alttext="bold x Subscript t Baseline
    equals StartRoot alpha overbar Subscript t Baseline EndRoot bold x 0 plus StartRoot
    1 minus alpha overbar Subscript t Baseline EndRoot epsilon"><mrow><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>=</mo> <msqrt><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover>
    <mi>t</mi></msub></msqrt> <msub><mi>ğ±</mi> <mn>0</mn></msub> <mo>+</mo> <msqrt><mrow><mn>1</mn>
    <mo>-</mo> <msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</mi></msub></mrow></msqrt>
    <mi>Ïµ</mi></mrow></math>ã€‚ æˆ‘ä»¬å°†è¿™ä¸ªæ–°å›¾åƒå’Œå™ªå£°ç‡<math alttext="alpha overbar Subscript t"><msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mi>t</msub></math>æä¾›ç»™ç¥ç»ç½‘ç»œï¼Œå¹¶è¦æ±‚å®ƒé¢„æµ‹<math
    alttext="epsilon"><mi>Ïµ</mi></math>ï¼Œé‡‡å–æ¢¯åº¦æ­¥éª¤æ¥è®¡ç®—é¢„æµ‹<math alttext="epsilon Subscript
    theta Baseline left-parenthesis bold x Subscript t Baseline right-parenthesis"><mrow><msub><mi>Ïµ</mi>
    <mi>Î¸</mi></msub> <mrow><mo>(</mo> <msub><mi>ğ±</mi> <mi>t</mi></msub> <mo>)</mo></mrow></mrow></math>å’ŒçœŸå®<math
    alttext="epsilon"><mi>Ïµ</mi></math>ä¹‹é—´çš„å¹³æ–¹è¯¯å·®ã€‚
- en: 'Weâ€™ll take a look at the structure of the neural network in the next section.
    It is worth noting here that the diffusion model actually maintains two copies
    of the network: one that is actively trained used gradient descent and another
    (the EMA network) that is an exponential moving average (EMA) of the weights of
    the actively trained network over previous training steps. The EMA network is
    not as susceptible to short-term fluctuations and spikes in the training process,
    making it more robust for generation than the actively trained network. We therefore
    use the EMA network whenever we want to produce generated output from the network.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­æŸ¥çœ‹ç¥ç»ç½‘ç»œçš„ç»“æ„ã€‚ å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ‰©æ•£æ¨¡å‹å®é™…ä¸Šç»´æŠ¤äº†ä¸¤ä¸ªç½‘ç»œå‰¯æœ¬ï¼šä¸€ä¸ªæ˜¯é€šè¿‡æ¢¯åº¦ä¸‹é™ä¸»åŠ¨è®­ç»ƒçš„ç½‘ç»œï¼Œå¦ä¸€ä¸ªæ˜¯æƒé‡çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰ç½‘ç»œï¼Œè¯¥ç½‘ç»œæ˜¯åœ¨å…ˆå‰çš„è®­ç»ƒæ­¥éª¤ä¸­å¯¹ä¸»åŠ¨è®­ç»ƒç½‘ç»œçš„æƒé‡è¿›è¡ŒæŒ‡æ•°ç§»åŠ¨å¹³å‡ã€‚
    EMAç½‘ç»œä¸å¤ªå®¹æ˜“å—åˆ°è®­ç»ƒè¿‡ç¨‹ä¸­çš„çŸ­æœŸæ³¢åŠ¨å’Œå³°å€¼çš„å½±å“ï¼Œå› æ­¤åœ¨ç”Ÿæˆæ–¹é¢æ¯”ä¸»åŠ¨è®­ç»ƒç½‘ç»œæ›´ç¨³å¥ã€‚ å› æ­¤ï¼Œæ¯å½“æˆ‘ä»¬æƒ³è¦ä»ç½‘ç»œç”Ÿæˆè¾“å‡ºæ—¶ï¼Œæˆ‘ä»¬éƒ½ä¼šä½¿ç”¨EMAç½‘ç»œã€‚
- en: The training process for the model is shown in [FigureÂ 8-7](#diff_training_process).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹å¦‚[å›¾8-7](#diff_training_process)æ‰€ç¤ºã€‚
- en: '![](Images/gdl2_0807.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0807.png)'
- en: 'Figure 8-7\. The training process for a denoising diffusion model (source:
    [Ho et al., 2020](https://arxiv.org/abs/2006.11239))'
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-7ã€‚å»å™ªæ‰©æ•£æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼ˆæ¥æºï¼š[Hoç­‰äººï¼Œ2020](https://arxiv.org/abs/2006.11239)ï¼‰
- en: In Keras, we can code up this training step as illustrated in [ExampleÂ 8-5](#diffusion_train_step).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Kerasä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªè®­ç»ƒæ­¥éª¤ç¼–ç ä¸º[ç¤ºä¾‹8-5](#diffusion_train_step)æ‰€ç¤ºã€‚
- en: Example 8-5\. The `train_step` function of the Keras diffusion model
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹8-5ã€‚Kerasæ‰©æ•£æ¨¡å‹çš„`train_step`å‡½æ•°
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](Images/1.png)](#co_diffusion_models_CO4-1)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_diffusion_models_CO4-1)'
- en: We first normalize the batch of images to have zero mean and unit variance.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆå°†å›¾åƒæ‰¹æ¬¡å½’ä¸€åŒ–ä¸ºé›¶å‡å€¼å’Œå•ä½æ–¹å·®ã€‚
- en: '[![2](Images/2.png)](#co_diffusion_models_CO4-2)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_diffusion_models_CO4-2)'
- en: Next, we sample noise to match the shape of the input images.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯¹å½¢çŠ¶ä¸è¾“å…¥å›¾åƒåŒ¹é…çš„å™ªå£°è¿›è¡Œé‡‡æ ·ã€‚
- en: '[![3](Images/3.png)](#co_diffusion_models_CO4-3)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_diffusion_models_CO4-3)'
- en: We also sample random diffusion timesâ€¦â€‹
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å¯¹éšæœºæ‰©æ•£æ—¶é—´è¿›è¡Œé‡‡æ ·â€¦â€‹
- en: '[![4](Images/4.png)](#co_diffusion_models_CO4-4)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_diffusion_models_CO4-4)'
- en: â€¦â€‹and use these to generate the noise and signal rates according to the cosine
    diffusion schedule.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: â€¦å¹¶ä½¿ç”¨è¿™äº›æ ¹æ®ä½™å¼¦æ‰©æ•£è®¡åˆ’ç”Ÿæˆå™ªå£°å’Œä¿¡å·é€Ÿç‡ã€‚
- en: '[![5](Images/5.png)](#co_diffusion_models_CO4-5)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_diffusion_models_CO4-5)'
- en: Then we apply the signal and noise weightings to the input images to generate
    the noisy images.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å°†ä¿¡å·å’Œå™ªå£°æƒé‡åº”ç”¨äºè¾“å…¥å›¾åƒä»¥ç”Ÿæˆå˜ˆæ‚çš„å›¾åƒã€‚
- en: '[![6](Images/6.png)](#co_diffusion_models_CO4-6)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_diffusion_models_CO4-6)'
- en: Next, we denoise the noisy images by asking the network to predict the noise
    and then undoing the noising operation, using the provided `noise_rates` and `signal_rates`.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬é€šè¿‡è¦æ±‚ç½‘ç»œé¢„æµ‹å™ªå£°ç„¶åæ’¤æ¶ˆæ·»åŠ å™ªå£°çš„æ“ä½œï¼Œä½¿ç”¨æä¾›çš„`noise_rates`å’Œ`signal_rates`æ¥å»å™ªå˜ˆæ‚çš„å›¾åƒã€‚
- en: '[![7](Images/7.png)](#co_diffusion_models_CO4-7)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](Images/7.png)](#co_diffusion_models_CO4-7)'
- en: We can then calculate the loss (mean absolute error) between the predicted noise
    and the true noiseâ€¦â€‹
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥è®¡ç®—é¢„æµ‹å™ªå£°å’ŒçœŸå®å™ªå£°ä¹‹é—´çš„æŸå¤±ï¼ˆå¹³å‡ç»å¯¹è¯¯å·®ï¼‰â€¦â€‹
- en: '[![8](Images/8.png)](#co_diffusion_models_CO4-8)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](Images/8.png)](#co_diffusion_models_CO4-8)'
- en: â€¦â€‹and take a gradient step against this loss function.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: â€¦â€‹å¹¶æ ¹æ®è¿™ä¸ªæŸå¤±å‡½æ•°é‡‡å–æ¢¯åº¦æ­¥éª¤ã€‚
- en: '[![9](Images/9.png)](#co_diffusion_models_CO4-9)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[![9](Images/9.png)](#co_diffusion_models_CO4-9)'
- en: The EMA network weights are updated to a weighted average of the existing EMA
    weights and the trained network weights after the gradient step.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: EMAç½‘ç»œæƒé‡æ›´æ–°ä¸ºç°æœ‰EMAæƒé‡å’Œè®­ç»ƒåçš„ç½‘ç»œæƒé‡åœ¨æ¢¯åº¦æ­¥éª¤åçš„åŠ æƒå¹³å‡å€¼ã€‚
- en: The U-Net Denoising Model
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: U-Netå»å™ªæ¨¡å‹
- en: Now that we have seen the kind of neural network that we need to build (one
    that predicts the noise added to a given image), we can look at the architecture
    that makes this possible.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†æˆ‘ä»¬éœ€è¦æ„å»ºçš„ç¥ç»ç½‘ç»œçš„ç±»å‹ï¼ˆä¸€ä¸ªé¢„æµ‹æ·»åŠ åˆ°ç»™å®šå›¾åƒçš„å™ªå£°çš„ç½‘ç»œï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹ä½¿è¿™ç§å¯èƒ½çš„æ¶æ„ã€‚
- en: The authors of the DDPM paper used a type of architecture known as a *U-Net*.
    A diagram of this network is shown in [FigureÂ 8-8](#unet_diffusion), explicitly
    showing the shape of the tensor as it passes through the network.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: DDPMè®ºæ–‡çš„ä½œè€…ä½¿ç”¨äº†ä¸€ç§ç§°ä¸º*U-Net*çš„æ¶æ„ç±»å‹ã€‚è¿™ä¸ªç½‘ç»œçš„å›¾è¡¨æ˜¾ç¤ºåœ¨[å›¾8-8](#unet_diffusion)ä¸­ï¼Œæ˜ç¡®æ˜¾ç¤ºäº†å¼ é‡åœ¨é€šè¿‡ç½‘ç»œæ—¶çš„å½¢çŠ¶ã€‚
- en: '![](Images/gdl2_0808.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0808.png)'
- en: Figure 8-8\. U-Net architecture diagram
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-8\. U-Netæ¶æ„å›¾
- en: 'In a similar manner to a variational autoencoder, a U-Net consists of two halves:
    the downsampling half, where input images are compressed spatially but expanded
    channel-wise, and the upsampling half, where representations are expanded spatially
    while the number of channels is reduced. However, unlike in a VAE, there are also
    *skip connections* between equivalent spatially shaped layers in the upsampling
    and downsampling parts of the network. A VAE is sequential; data flows through
    the network from input to output, one layer after another. A U-Net is different,
    because the skip connections allow information to shortcut parts of the network
    and flow through to later layers.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»ä¼¼äºå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼ŒU-Netç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šä¸‹é‡‡æ ·éƒ¨åˆ†ï¼Œå…¶ä¸­è¾“å…¥å›¾åƒåœ¨ç©ºé—´ä¸Šè¢«å‹ç¼©ä½†åœ¨é€šé“ä¸Šè¢«æ‰©å±•ï¼Œä»¥åŠä¸Šé‡‡æ ·éƒ¨åˆ†ï¼Œå…¶ä¸­è¡¨ç¤ºåœ¨ç©ºé—´ä¸Šè¢«æ‰©å±•ï¼Œè€Œé€šé“æ•°é‡å‡å°‘ã€‚ç„¶è€Œï¼Œä¸VAEä¸åŒçš„æ˜¯ï¼Œåœ¨ç½‘ç»œçš„ä¸Šé‡‡æ ·å’Œä¸‹é‡‡æ ·éƒ¨åˆ†ä¹‹é—´è¿˜æœ‰*è·³è·ƒè¿æ¥*ã€‚VAEæ˜¯é¡ºåºçš„ï¼›æ•°æ®ä»è¾“å…¥åˆ°è¾“å‡ºä¾æ¬¡é€šè¿‡ç½‘ç»œçš„æ¯ä¸€å±‚ã€‚U-Netä¸åŒï¼Œå› ä¸ºè·³è·ƒè¿æ¥å…è®¸ä¿¡æ¯ç»•è¿‡ç½‘ç»œçš„éƒ¨åˆ†å¹¶æµå‘åç»­å±‚ã€‚
- en: A U-Net is particularly useful when we want the output to have the same shape
    as the input. In our diffusion model example, we want to predict the noise added
    to an image, which has exactly the same shape as the image itself, so a U-Net
    is the natural choice for the network architecture.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æˆ‘ä»¬å¸Œæœ›è¾“å‡ºå…·æœ‰ä¸è¾“å…¥ç›¸åŒçš„å½¢çŠ¶æ—¶ï¼ŒU-Netç‰¹åˆ«æœ‰ç”¨ã€‚åœ¨æˆ‘ä»¬çš„æ‰©æ•£æ¨¡å‹ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›é¢„æµ‹æ·»åŠ åˆ°å›¾åƒä¸­çš„å™ªå£°ï¼Œè¿™ä¸ªå™ªå£°ä¸å›¾åƒæœ¬èº«çš„å½¢çŠ¶å®Œå…¨ç›¸åŒï¼Œå› æ­¤U-Netæ˜¯ç½‘ç»œæ¶æ„çš„è‡ªç„¶é€‰æ‹©ã€‚
- en: First letâ€™s take a look at the code that builds this U-Net in Keras, shown in
    [ExampleÂ 8-6](#unet_keras).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆè®©æˆ‘ä»¬çœ‹ä¸€ä¸‹åœ¨Kerasä¸­æ„å»ºè¿™ä¸ªU-Netçš„ä»£ç ï¼Œæ˜¾ç¤ºåœ¨[ç¤ºä¾‹8-6](#unet_keras)ä¸­ã€‚
- en: Example 8-6\. A U-Net model in Keras
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹8-6\. Kerasä¸­çš„U-Netæ¨¡å‹
- en: '[PRE5]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](Images/1.png)](#co_diffusion_models_CO5-1)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_diffusion_models_CO5-1)'
- en: The first input to the U-Net is the image that we wish to denoise.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: U-Netçš„ç¬¬ä¸€ä¸ªè¾“å…¥æ˜¯æˆ‘ä»¬å¸Œæœ›å»å™ªçš„å›¾åƒã€‚
- en: '[![2](Images/2.png)](#co_diffusion_models_CO5-2)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_diffusion_models_CO5-2)'
- en: This image is passed through a `Conv2D` layer to increase the number of channels.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå›¾åƒé€šè¿‡ä¸€ä¸ª`Conv2D`å±‚ä¼ é€’ï¼Œä»¥å¢åŠ é€šé“æ•°é‡ã€‚
- en: '[![3](Images/3.png)](#co_diffusion_models_CO5-3)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_diffusion_models_CO5-3)'
- en: The second input to the U-Net is the noise variance (a scalar).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: U-Netçš„ç¬¬äºŒä¸ªè¾“å…¥æ˜¯å™ªå£°æ–¹å·®ï¼ˆä¸€ä¸ªæ ‡é‡ï¼‰ã€‚
- en: '[![4](Images/4.png)](#co_diffusion_models_CO5-4)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_diffusion_models_CO5-4)'
- en: This is encoded using a sinusoidal embedding.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä½¿ç”¨æ­£å¼¦åµŒå…¥ç¼–ç çš„ã€‚
- en: '[![5](Images/5.png)](#co_diffusion_models_CO5-5)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_diffusion_models_CO5-5)'
- en: This embedding is copied across spatial dimensions to match the size of the
    input image.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåµŒå…¥è¢«å¤åˆ¶åˆ°ç©ºé—´ç»´åº¦ä»¥åŒ¹é…è¾“å…¥å›¾åƒçš„å¤§å°ã€‚
- en: '[![6](Images/6.png)](#co_diffusion_models_CO5-6)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_diffusion_models_CO5-6)'
- en: The two input streams are concatenated across channels.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªè¾“å…¥æµåœ¨é€šé“ä¸Šè¿æ¥ã€‚
- en: '[![7](Images/7.png)](#co_diffusion_models_CO5-7)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](Images/7.png)](#co_diffusion_models_CO5-7)'
- en: The `skips` list will hold the output from the `DownBlock` layers that we wish
    to connect to `UpBlock` layers downstream.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`skips`åˆ—è¡¨å°†ä¿å­˜æˆ‘ä»¬å¸Œæœ›è¿æ¥åˆ°ä¸‹æ¸¸`UpBlock`å±‚çš„`DownBlock`å±‚çš„è¾“å‡ºã€‚'
- en: '[![8](Images/8.png)](#co_diffusion_models_CO5-8)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](Images/8.png)](#co_diffusion_models_CO5-8)'
- en: The tensor is passed through a series of `DownBlock` layers that reduce the
    size of the image, while increasing the number of channels.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: å¼ é‡é€šè¿‡ä¸€ç³»åˆ—`DownBlock`å±‚ä¼ é€’ï¼Œè¿™äº›å±‚å‡å°äº†å›¾åƒçš„å¤§å°ï¼ŒåŒæ—¶å¢åŠ äº†é€šé“çš„æ•°é‡ã€‚
- en: '[![9](Images/9.png)](#co_diffusion_models_CO5-9)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[![9](Images/9.png)](#co_diffusion_models_CO5-9)'
- en: The tensor is then passed through two `ResidualBlock` layers that hold the image
    size and number of channels constant.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œå¼ é‡é€šè¿‡ä¸¤ä¸ª`ResidualBlock`å±‚ä¼ é€’ï¼Œè¿™äº›å±‚ä¿æŒå›¾åƒå¤§å°å’Œé€šé“æ•°é‡æ’å®šã€‚
- en: '[![10](Images/10.png)](#co_diffusion_models_CO5-10)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[![10](Images/10.png)](#co_diffusion_models_CO5-10)'
- en: Next, the tensor is passed through a series of `UpBlock` layers that increase
    the size of the image, while decreasing the number of channels. The skip connections
    incorporate output from the earlier `DownBlock` layers.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œå¼ é‡é€šè¿‡ä¸€ç³»åˆ—`UpBlock`å±‚ä¼ é€’ï¼Œè¿™äº›å±‚å¢åŠ å›¾åƒçš„å¤§å°ï¼ŒåŒæ—¶å‡å°‘é€šé“æ•°ã€‚è·³è·ƒè¿æ¥å°†è¾“å‡ºä¸è¾ƒæ—©çš„`DownBlock`å±‚çš„è¾“å‡ºåˆå¹¶ã€‚
- en: '[![11](Images/11.png)](#co_diffusion_models_CO5-11)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[![11](Images/11.png)](#co_diffusion_models_CO5-11)'
- en: The final `Conv2D` layer reduces the number of channels to three (RGB).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆçš„`Conv2D`å±‚å°†é€šé“æ•°å‡å°‘åˆ°ä¸‰ï¼ˆRGBï¼‰ã€‚
- en: '[![12](Images/12.png)](#co_diffusion_models_CO5-12)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[![12](Images/12.png)](#co_diffusion_models_CO5-12)'
- en: The U-Net is a Keras `Model` that takes the noisy images and noise variances
    as input and outputs a predicted noise map.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: U-Netæ˜¯ä¸€ä¸ªKeras `Model`ï¼Œå®ƒä»¥å˜ˆæ‚çš„å›¾åƒå’Œå™ªå£°æ–¹å·®ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºé¢„æµ‹çš„å™ªå£°å›¾ã€‚
- en: 'To understand the U-Net in detail, we need to explore four more concepts: the
    sinusoidal embedding of the noise variance, the `ResidualBlock`, the `DownBlock`,
    and the `UpBlock`.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è¯¦ç»†äº†è§£U-Netï¼Œæˆ‘ä»¬éœ€è¦æ¢ç´¢å››ä¸ªæ¦‚å¿µï¼šå™ªå£°æ–¹å·®çš„æ­£å¼¦åµŒå…¥ã€`ResidualBlock`ã€`DownBlock`å’Œ`UpBlock`ã€‚
- en: Sinusoidal embedding
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ­£å¼¦åµŒå…¥
- en: '*Sinusoidal embedding* was first introduced in a paper by Vaswani et al.^([6](ch08.xhtml#idm45387008220416))
    We will be using an adaptation of that original idea as utilized in Mildenhall
    et al.â€™s paper titled â€œNeRF: Representing Scenes as Neural Radiance Fields for
    View Synthesis.â€^([7](ch08.xhtml#idm45387008216736))'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ­£å¼¦åµŒå…¥*æœ€åˆæ˜¯ç”±Vaswaniç­‰äººåœ¨ä¸€ç¯‡è®ºæ–‡ä¸­å¼•å…¥çš„ã€‚æˆ‘ä»¬å°†ä½¿ç”¨Mildenhallç­‰äººåœ¨é¢˜ä¸ºâ€œNeRF: Representing Scenes
    as Neural Radiance Fields for View Synthesisâ€çš„è®ºæ–‡ä¸­ä½¿ç”¨çš„è¿™ä¸ªåŸå§‹æƒ³æ³•çš„æ”¹ç¼–ã€‚'
- en: The idea is that we want to be able to convert a scalar value (the noise variance)
    into a distinct higher-dimensional vector that is able to provide a more complex
    representation, for use downstream in the network. The original paper used this
    idea to encode the discrete position of words in a sentence into vectors; the
    NeRF paper extends this idea to continuous values.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå°†æ ‡é‡å€¼ï¼ˆå™ªå£°æ–¹å·®ï¼‰è½¬æ¢ä¸ºä¸€ä¸ªä¸åŒçš„é«˜ç»´å‘é‡ï¼Œèƒ½å¤Ÿæä¾›æ›´å¤æ‚çš„è¡¨ç¤ºï¼Œä»¥ä¾¿åœ¨ç½‘ç»œä¸­ä¸‹æ¸¸ä½¿ç”¨ã€‚åŸå§‹è®ºæ–‡ä½¿ç”¨è¿™ä¸ªæƒ³æ³•å°†å¥å­ä¸­å•è¯çš„ç¦»æ•£ä½ç½®ç¼–ç ä¸ºå‘é‡ï¼›NeRFè®ºæ–‡å°†è¿™ä¸ªæƒ³æ³•æ‰©å±•åˆ°è¿ç»­å€¼ã€‚
- en: 'Specifically, a scalar value *x* is encoded as shown in the following equation:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: å…·ä½“æ¥è¯´ï¼Œæ ‡é‡å€¼*x*è¢«ç¼–ç å¦‚ä¸‹æ–¹ç¨‹æ‰€ç¤ºï¼š
- en: <math alttext="gamma left-parenthesis x right-parenthesis equals left-parenthesis
    sine left-parenthesis 2 pi e Superscript 0 f Baseline x right-parenthesis comma
    ellipsis comma sine left-parenthesis 2 pi e Superscript left-parenthesis upper
    L minus 1 right-parenthesis f right-parenthesis Baseline x right-parenthesis comma
    cosine left-parenthesis 2 pi e Superscript 0 f Baseline x right-parenthesis comma
    ellipsis comma cosine left-parenthesis 2 pi e Superscript left-parenthesis upper
    L minus 1 right-parenthesis f Baseline x right-parenthesis right-parenthesis"
    display="block"><mrow><mi>Î³</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mo>(</mo> <mo form="prefix">sin</mo> <mrow><mo>(</mo> <mn>2</mn> <mi>Ï€</mi>
    <msup><mi>e</mi> <mrow><mn>0</mn><mi>f</mi></mrow></msup> <mi>x</mi> <mo>)</mo></mrow>
    <mo>,</mo> <mo>â‹¯</mo> <mo>,</mo> <mo form="prefix">sin</mo> <mrow><mo>(</mo> <mn>2</mn>
    <mi>Ï€</mi> <msup><mi>e</mi> <mrow><mo>(</mo><mi>L</mi><mo>-</mo><mn>1</mn><mo>)</mo><mi>f</mi><mo>)</mo></mrow></msup>
    <mi>x</mi> <mo>)</mo></mrow> <mo>,</mo> <mo form="prefix">cos</mo> <mrow><mo>(</mo>
    <mn>2</mn> <mi>Ï€</mi> <msup><mi>e</mi> <mrow><mn>0</mn><mi>f</mi></mrow></msup>
    <mi>x</mi> <mo>)</mo></mrow> <mo>,</mo> <mo>â‹¯</mo> <mo>,</mo> <mo form="prefix">cos</mo>
    <mrow><mo>(</mo> <mn>2</mn> <mi>Ï€</mi> <msup><mi>e</mi> <mrow><mo>(</mo><mi>L</mi><mo>-</mo><mn>1</mn><mo>)</mo><mi>f</mi></mrow></msup>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></math>
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="gamma left-parenthesis x right-parenthesis equals left-parenthesis
    sine left-parenthesis 2 pi e Superscript 0 f Baseline x right-parenthesis comma
    ellipsis comma sine left-parenthesis 2 pi e Superscript left-parenthesis upper
    L minus 1 right-parenthesis f right-parenthesis Baseline x right-parenthesis comma
    cosine left-parenthesis 2 pi e Superscript 0 f Baseline x right-parenthesis comma
    ellipsis comma cosine left-parenthesis 2 pi e Superscript left-parenthesis upper
    L minus 1 right-parenthesis f Baseline x right-parenthesis right-parenthesis"
    display="block"><mrow><mi>Î³</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mo>(</mo> <mo form="prefix">sin</mo> <mrow><mo>(</mo> <mn>2</mn> <mi>Ï€</mi>
    <msup><mi>e</mi> <mrow><mn>0</mn><mi>f</mi></mrow></msup> <mi>x</mi> <mo>)</mo></mrow>
    <mo>,</mo> <mo>â‹¯</mo> <mo>,</mo> <mo form="prefix">sin</mo> <mrow><mo>(</mo> <mn>2</mn>
    <mi>Ï€</mi> <msup><mi>e</mi> <mrow><mo>(</mo><mi>L</mi><mo>-</mo><mn>1</mn><mo>)</mo><mi>f</mi><mo>)</mo></mrow></msup>
    <mi>x</mi> <mo>)</mo></mrow> <mo>,</mo> <mo form="prefix">cos</mo> <mrow><mo>(</mo>
    <mn>2</mn> <mi>Ï€</mi> <msup><mi>e</mi> <mrow><mn>0</mn><mi>f</mi></mrow></msup>
    <mi>x</mi> <mo>)</mo></mrow> <mo>,</mo> <mo>â‹¯</mo> <mo>,</mo> <mo form="prefix">cos</mo>
    <mrow><mo>(</mo> <mn>2</mn> <mi>Ï€</mi> <msup><mi>e</mi> <mrow><mo>(</mo><mi>L</mi><mo>-</mo><mn>1</mn><mo>)</mo><mi>f</mi></mrow></msup>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></math>
- en: where we choose <math alttext="upper L equals 16"><mrow><mi>L</mi> <mo>=</mo>
    <mn>16</mn></mrow></math> to be half the size of our desired noise embedding length
    and <math alttext="f equals StartFraction ln left-parenthesis 1000 right-parenthesis
    Over upper L minus 1 EndFraction"><mrow><mi>f</mi> <mo>=</mo> <mfrac><mrow><mo
    form="prefix">ln</mo><mo>(</mo><mn>1000</mn><mo>)</mo></mrow> <mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></math>
    to be the maximum scaling factor for the frequencies.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­æˆ‘ä»¬é€‰æ‹©<math alttext="ä¸Šé™Lç­‰äº16"><mrow><mi>L</mi> <mo>=</mo> <mn>16</mn></mrow></math>ï¼Œæ˜¯æˆ‘ä»¬æœŸæœ›çš„å™ªå£°åµŒå…¥é•¿åº¦çš„ä¸€åŠï¼Œ<math
    alttext="fç­‰äºln(1000)/(L-1)"><mrow><mi>f</mi> <mo>=</mo> <mfrac><mrow><mo form="prefix">ln</mo><mo>(</mo><mn>1000</mn><mo>)</mo></mrow>
    <mrow><mi>L</mi><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></math>æ˜¯é¢‘ç‡çš„æœ€å¤§ç¼©æ”¾å› å­ã€‚
- en: This produces the embedding pattern shown in [FigureÂ 8-9](#sinusoidal_embedding_image).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº§ç”Ÿäº†[å›¾8-9](#sinusoidal_embedding_image)ä¸­æ˜¾ç¤ºçš„åµŒå…¥æ¨¡å¼ã€‚
- en: '![](Images/gdl2_0809.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0809.png)'
- en: Figure 8-9\. The pattern of sinusoidal embeddings for noise variances from 0
    to 1
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-9ã€‚å™ªå£°æ–¹å·®ä»0åˆ°1çš„æ­£å¼¦åµŒå…¥æ¨¡å¼
- en: We can code this sinusoidal embedding function as shown in [ExampleÂ 8-7](#sinusoidal_embedding_diffusion).
    This converts a single noise variance scalar value into a vector of length 32.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªæ­£å¼¦åµŒå…¥å‡½æ•°ç¼–ç å¦‚[ç¤ºä¾‹8-7](#sinusoidal_embedding_diffusion)æ‰€ç¤ºã€‚è¿™å°†ä¸€ä¸ªå•ä¸€çš„å™ªå£°æ–¹å·®æ ‡é‡å€¼è½¬æ¢ä¸ºé•¿åº¦ä¸º32çš„å‘é‡ã€‚
- en: Example 8-7\. The `sinusoidal_embedding` function that encodes the noise variance
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹8-7ã€‚ç¼–ç å™ªå£°æ–¹å·®çš„`sinusoidal_embedding`å‡½æ•°
- en: '[PRE6]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ResidualBlock
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ®‹å·®å—
- en: Both the `DownBlock` and the `UpBlock` contain `ResidualBlock` layers, so letâ€™s
    start with these. We already explored residual blocks in [ChapterÂ 5](ch05.xhtml#chapter_autoregressive),
    when we built a PixelCNN, but we will recap here for completeness.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`DownBlock`å’Œ`UpBlock`éƒ½åŒ…å«`ResidualBlock`å±‚ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ä»è¿™äº›å±‚å¼€å§‹ã€‚æˆ‘ä»¬åœ¨[ç¬¬5ç« ](ch05.xhtml#chapter_autoregressive)ä¸­æ„å»ºPixelCNNæ—¶å·²ç»æ¢è®¨è¿‡æ®‹å·®å—ï¼Œä½†ä¸ºäº†å®Œæ•´èµ·è§ï¼Œæˆ‘ä»¬å°†åœ¨è¿™é‡Œè¿›è¡Œå›é¡¾ã€‚'
- en: A *residual block* is a group of layers that contains a skip connection that
    adds the input to the output. Residual blocks help us to build deeper networks
    that can learn more complex patterns without suffering as greatly from vanishing
    gradient and degradation problems. The vanishing gradient problem is the assertion
    that as the network gets deeper, the gradient propagated through deeper layers
    is tiny and therefore learning is very slow. The degradation problem is the fact
    that as neural networks become deeper, they are not necessarily as accurate as
    their shallower counterpartsâ€”accuracy seems to become saturated at a certain depth
    and then degrade rapidly.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ®‹å·®å—*æ˜¯ä¸€ç»„åŒ…å«è·³è·ƒè¿æ¥çš„å±‚ï¼Œå°†è¾“å…¥æ·»åŠ åˆ°è¾“å‡ºä¸­ã€‚æ®‹å·®å—å¸®åŠ©æˆ‘ä»¬æ„å»ºæ›´æ·±çš„ç½‘ç»œï¼Œå¯ä»¥å­¦ä¹ æ›´å¤æ‚çš„æ¨¡å¼ï¼Œè€Œä¸ä¼šå—åˆ°æ¢¯åº¦æ¶ˆå¤±å’Œé€€åŒ–é—®é¢˜çš„ä¸¥é‡å½±å“ã€‚æ¢¯åº¦æ¶ˆå¤±é—®é¢˜æ˜¯æŒ‡éšç€ç½‘ç»œå˜å¾—æ›´æ·±ï¼Œé€šè¿‡æ›´æ·±å±‚ä¼ æ’­çš„æ¢¯åº¦å¾ˆå°ï¼Œå› æ­¤å­¦ä¹ é€Ÿåº¦éå¸¸æ…¢ã€‚é€€åŒ–é—®é¢˜æ˜¯æŒ‡éšç€ç¥ç»ç½‘ç»œå˜å¾—æ›´æ·±ï¼Œå®ƒä»¬ä¸ä¸€å®šåƒè¾ƒæµ…çš„å¯¹åº”ç½‘ç»œé‚£æ ·å‡†ç¡®â€”â€”å‡†ç¡®æ€§ä¼¼ä¹åœ¨ä¸€å®šæ·±åº¦ä¸Šé¥±å’Œï¼Œç„¶åè¿…é€Ÿé€€åŒ–ã€‚'
- en: Degradation
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é€€åŒ–
- en: The degradation problem is somewhat counterintuitive, but observed in practice
    as the deeper layers must at least learn the identity mapping, which is not trivialâ€”especially
    considering other problems deeper networks face, such as the vanishing gradient
    problem.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: é€€åŒ–é—®é¢˜æœ‰ç‚¹åç›´è§‰ï¼Œä½†åœ¨å®è·µä¸­è§‚å¯Ÿåˆ°ï¼Œå› ä¸ºæ›´æ·±çš„å±‚è‡³å°‘å¿…é¡»å­¦ä¹ æ’ç­‰æ˜ å°„ï¼Œè¿™å¹¶ä¸æ˜¯å¾®ä¸è¶³é“çš„â€”â€”å°¤å…¶è€ƒè™‘åˆ°æ›´æ·±çš„ç½‘ç»œé¢ä¸´çš„å…¶ä»–é—®é¢˜ï¼Œæ¯”å¦‚æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚
- en: The solution, first introduced in the ResNet paper by He et al. in 2015,^([8](ch08.xhtml#idm45387008052288))
    is very simple. By including a skip connection *highway* around the main weighted
    layers, the block has the option to bypass the complex weight updates and simply
    pass through the identity mapping. This allows the network to be trained to great
    depth without sacrificing gradient size or network accuracy.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: A diagram of a `ResidualBlock` is shown in [FigureÂ 8-10](#diffusion_residual).
    Note that in some residual blocks, we also include an extra `Conv2D` layer with
    kernel size 1 on the skip connection, to bring the number of channels in line
    with the rest of the block.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0810.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
- en: Figure 8-10\. The `ResidualBlock` in the U-Net
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can code a `ResidualBlock` in Keras as shown in [ExampleÂ 8-8](#diffusion_residual_code).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-8\. Code for the `ResidualBlock` in the U-Net
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](Images/1.png)](#co_diffusion_models_CO6-1)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Check if the number of channels in the input matches the number of channels
    that we would like the block to output. If not, include an extra `Conv2D` layer
    on the skip connection to bring the number of channels in line with the rest of
    the block.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_diffusion_models_CO6-2)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Apply a `BatchNormalization` layer.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_diffusion_models_CO6-3)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Apply two `Conv2D` layers.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_diffusion_models_CO6-4)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: Add the original block input to the output to provide the final output from
    the block.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: DownBlocks and UpBlocks
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each successive `DownBlock` increases the number of channels via `block_depth`
    (=2 in our example) `ResidualBlock`s, while also applying a final `AveragePooling2D`
    layer in order to halve the size of the image. Each `ResidualBlock` is added to
    a list for use later by the `UpBlock` layers as skip connections across the U-Net.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: An `UpBlock` first applies an `UpSampling2D` layer that doubles the size of
    the image, through bilinear interpolation. Each successive `UpBlock` decreases
    the number of channels via `block_depth` (=2) `ResidualBlock`s, while also concatenating
    the outputs from the `DownBlock`s through skip connections across the U-Net. A
    diagram of this process is shown in [FigureÂ 8-11](#diffusion_down_up_block).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0811.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
- en: Figure 8-11\. The `DownBlock` and corresponding `UpBlock` in the U-Net
  id: totrans-182
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can code the `DownBlock` and `UpBlock` using Keras as illustrated in [ExampleÂ 8-9](#diffusion_down_up_code).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-9\. Code for the `DownBlock` and `UpBlock` in the U-Net model
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](Images/1.png)](#co_diffusion_models_CO7-1)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: The `DownBlock` increases the number of channels in the image using a `ResidualBlock`
    of a given `width`â€¦â€‹
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_diffusion_models_CO7-2)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: â€¦â€‹each of which are saved to a list (`skips`) for use later by the `UpBlock`s.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_diffusion_models_CO7-3)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: A final `AveragePooling2D` layer reduces the dimensionality of the image by
    half.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_diffusion_models_CO7-4)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: The `UpBlock` begins with an `UpSampling2D` layer that doubles the size of the
    image.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](Images/5.png)](#co_diffusion_models_CO7-5)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: The output from a `DownBlock` layer is glued to the current output using a `Concatenate`
    layer.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](Images/6.png)](#co_diffusion_models_CO7-6)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: A `ResidualBlock` is used to reduce the number of channels in the image as it
    passes through the `UpBlock`.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Training the Diffusion Model
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now have all the components in place to train our denoising diffusion model!
    [ExampleÂ 8-10](#diffusion_train_code) creates, compiles, and fits the diffusion
    model.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Example 8-10\. Code for training the `DiffusionModel`
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![1](Images/1.png)](#co_diffusion_models_CO8-1)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Instantiate the model.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_diffusion_models_CO8-2)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Compile the model, using the AdamW optimizer (similar to Adam but with weight
    decay, which helps stabilize the training process) and mean absolute error loss
    function.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_diffusion_models_CO8-3)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Calculate the normalization statistics using the training set.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è®­ç»ƒé›†è®¡ç®—å½’ä¸€åŒ–ç»Ÿè®¡æ•°æ®ã€‚
- en: '[![4](Images/4.png)](#co_diffusion_models_CO8-4)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_diffusion_models_CO8-4)'
- en: Fit the model over 50 epochs.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨50ä¸ªæ—¶ä»£å†…æ‹Ÿåˆæ¨¡å‹ã€‚
- en: The loss curve (noise mean absolute error [MAE]) is shown in [FigureÂ 8-12](#diffusion_loss).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±æ›²çº¿ï¼ˆå™ªéŸ³å¹³å‡ç»å¯¹è¯¯å·®[MAE]ï¼‰æ˜¾ç¤ºåœ¨[å›¾8-12](#diffusion_loss)ä¸­ã€‚
- en: '![](Images/gdl2_0812.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0812.png)'
- en: Figure 8-12\. The noise mean absolute error loss curve, by epoch
  id: totrans-212
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-12ã€‚å™ªéŸ³å¹³å‡ç»å¯¹è¯¯å·®æŸå¤±æ›²çº¿ï¼ŒæŒ‰æ—¶ä»£
- en: Sampling from the Denoising Diffusion Model
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»å»å™ªæ‰©æ•£æ¨¡å‹ä¸­é‡‡æ ·
- en: In order to sample images from our trained model, we need to apply the reverse
    diffusion processâ€”that is, we need to start with random noise and use the model
    to gradually undo the noise, until we are left with a recognizable picture of
    a flower.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä»æˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹ä¸­é‡‡æ ·å›¾åƒï¼Œæˆ‘ä»¬éœ€è¦åº”ç”¨åå‘æ‰©æ•£è¿‡ç¨‹-ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬éœ€è¦ä»éšæœºå™ªéŸ³å¼€å§‹ï¼Œå¹¶ä½¿ç”¨æ¨¡å‹é€æ¸æ¶ˆé™¤å™ªéŸ³ï¼Œç›´åˆ°æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªå¯ä»¥è¯†åˆ«çš„èŠ±æœµå›¾ç‰‡ã€‚
- en: We must bear in mind that our model is trained to predict the total amount of
    noise that has been added to a given noisy image from the training set, not just
    the noise that was added at the last timestep of the noising process. However,
    we do not want to undo the noise all in one goâ€”predicting an image from pure random
    noise in one shot is clearly not going to work! We would rather mimic the forward
    process and undo the predicted noise gradually over many small steps, to allow
    the model to adjust to its own predictions.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¿…é¡»è®°ä½ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ˜¯ç»è¿‡è®­ç»ƒçš„ï¼Œç”¨äºé¢„æµ‹åœ¨è®­ç»ƒé›†ä¸­æ·»åŠ åˆ°ç»™å®šå˜ˆæ‚å›¾åƒçš„æ€»å™ªéŸ³é‡ï¼Œè€Œä¸ä»…ä»…æ˜¯åœ¨å™ªéŸ³è¿‡ç¨‹çš„æœ€åä¸€ä¸ªæ—¶é—´æ­¥éª¤ä¸­æ·»åŠ çš„å™ªéŸ³ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä¸å¸Œæœ›ä¸€æ¬¡æ€§æ¶ˆé™¤æ‰€æœ‰å™ªéŸ³-åœ¨ä¸€æ¬¡é¢„æµ‹ä¸­ä»çº¯éšæœºå™ªéŸ³ä¸­é¢„æµ‹å›¾åƒæ˜¾ç„¶ä¸ä¼šå¥æ•ˆï¼æˆ‘ä»¬å®æ„¿æ¨¡ä»¿æ­£å‘è¿‡ç¨‹ï¼Œå¹¶åœ¨è®¸å¤šå°æ­¥éª¤ä¸­é€æ¸æ¶ˆé™¤é¢„æµ‹çš„å™ªéŸ³ï¼Œä»¥ä½¿æ¨¡å‹èƒ½å¤Ÿé€‚åº”è‡ªå·±çš„é¢„æµ‹ã€‚
- en: To achieve this, we can jump from <math alttext="x Subscript t"><msub><mi>x</mi>
    <mi>t</mi></msub></math> to <math alttext="x Subscript t minus 1"><msub><mi>x</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math> in two stepsâ€”first by
    using our modelâ€™s noise prediction to calculate an estimate for the original image
    <math alttext="x 0"><msub><mi>x</mi> <mn>0</mn></msub></math> and then by reapplying
    the predicted noise to this image, but only over <math alttext="t minus 1"><mrow><mi>t</mi>
    <mo>-</mo> <mn>1</mn></mrow></math> timesteps, to produce <math alttext="x Subscript
    t minus 1"><msub><mi>x</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math>
    . This idea is shown in [FigureÂ 8-13](#diffusion_one_step_sample).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸¤ä¸ªæ­¥éª¤ä¸­ä»<math alttext="x Subscript t"><msub><mi>x</mi> <mi>t</mi></msub></math>è·³åˆ°<math
    alttext="x Subscript t minus 1"><msub><mi>x</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math>ï¼Œé¦–å…ˆä½¿ç”¨æˆ‘ä»¬æ¨¡å‹çš„å™ªéŸ³é¢„æµ‹æ¥è®¡ç®—åŸå§‹å›¾åƒ<math
    alttext="x 0"><msub><mi>x</mi> <mn>0</mn></msub></math>çš„ä¼°è®¡ï¼Œç„¶åé‡æ–°åº”ç”¨é¢„æµ‹çš„å™ªéŸ³åˆ°è¿™ä¸ªå›¾åƒï¼Œä½†åªåœ¨<math
    alttext="t minus 1"><mrow><mi>t</mi> <mo>-</mo> <mn>1</mn></mrow></math>ä¸ªæ—¶é—´æ­¥éª¤å†…ï¼Œäº§ç”Ÿ<math
    alttext="x Subscript t minus 1"><msub><mi>x</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math>ã€‚è¿™ä¸ªæƒ³æ³•åœ¨[å›¾8-13](#diffusion_one_step_sample)ä¸­æ˜¾ç¤ºã€‚
- en: '![](Images/gdl2_0813.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0813.png)'
- en: Figure 8-13\. One step of the sampling process for our diffusion model
  id: totrans-218
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-13ã€‚æ‰©æ•£æ¨¡å‹é‡‡æ ·è¿‡ç¨‹çš„ä¸€æ­¥
- en: If we repeat this process over a number of steps, weâ€™ll eventually get back
    to an estimate for <math alttext="x 0"><msub><mi>x</mi> <mn>0</mn></msub></math>
    that has been guided gradually over many small steps. In fact, we are free to
    choose the number of steps we take, and crucially, it doesnâ€™t have to be the same
    as the large number of steps in the training noising process (i.e., 1,000). It
    can be much smallerâ€”in this example we choose 20.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬é‡å¤è¿™ä¸ªè¿‡ç¨‹å¤šæ¬¡ï¼Œæœ€ç»ˆæˆ‘ä»¬å°†å¾—åˆ°ä¸€ä¸ªç»è¿‡è®¸å¤šå°æ­¥éª¤é€æ¸å¼•å¯¼çš„<math alttext="x 0"><msub><mi>x</mi> <mn>0</mn></msub></math>çš„ä¼°è®¡ã€‚å®é™…ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥è‡ªç”±é€‰æ‹©é‡‡å–çš„æ­¥æ•°ï¼Œå…³é”®æ˜¯ï¼Œå®ƒä¸å¿…ä¸è®­ç»ƒå™ªéŸ³è¿‡ç¨‹ä¸­çš„å¤§é‡æ­¥æ•°ï¼ˆå³1,000ï¼‰ç›¸åŒã€‚å®ƒå¯ä»¥å°å¾—å¤š-åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©äº†20ã€‚
- en: 'The following equation (Song et al., 2020) this process mathematically:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹æ–¹ç¨‹ï¼ˆSongç­‰ï¼Œ2020ï¼‰æ•°å­¦ä¸Šæè¿°äº†è¿™ä¸ªè¿‡ç¨‹ï¼š
- en: <math alttext="bold x Subscript t minus 1 Baseline equals StartRoot alpha overbar
    Subscript t minus 1 Baseline EndRoot ModifyingBelow left-parenthesis StartFraction
    bold x Subscript t Baseline minus StartRoot 1 minus alpha overbar Subscript t
    Baseline EndRoot epsilon Subscript theta Superscript left-parenthesis t right-parenthesis
    Baseline left-parenthesis bold x Subscript t Baseline right-parenthesis Over StartRoot
    alpha overbar Subscript t Baseline EndRoot EndFraction right-parenthesis With
    bottom-brace Underscript predicted bold x 0 Endscripts plus ModifyingBelow StartRoot
    1 minus alpha overbar Subscript t minus 1 Baseline minus sigma Subscript t Superscript
    2 Baseline EndRoot dot epsilon Subscript theta Superscript left-parenthesis t
    right-parenthesis Baseline left-parenthesis bold x Subscript t Baseline right-parenthesis
    With bottom-brace Underscript direction pointing to bold x Subscript t Baseline
    Endscripts plus ModifyingBelow sigma Subscript t Baseline epsilon Subscript t
    Baseline With bottom-brace Underscript random noise Endscripts" display="block"><mrow><msub><mi>ğ±</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>=</mo> <msqrt><msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></msqrt>
    <munder><munder accentunder="true"><mfenced separators="" open="(" close=")"><mfrac><mrow><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>-</mo><msqrt><mrow><mn>1</mn><mo>-</mo><msub><mover accent="true"><mi>Î±</mi>
    <mo>Â¯</mo></mover> <mi>t</mi></msub></mrow></msqrt> <msubsup><mi>Ïµ</mi> <mi>Î¸</mi>
    <mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></msubsup> <mrow><mo>(</mo><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>)</mo></mrow></mrow> <msqrt><msub><mover accent="true"><mi>Î±</mi>
    <mo>Â¯</mo></mover> <mi>t</mi></msub></msqrt></mfrac></mfenced> <mo>ï¸¸</mo></munder>
    <mrow><mtext>predicted</mtext><msub><mi>ğ±</mi> <mn>0</mn></msub></mrow></munder>
    <mo>+</mo> <munder><munder accentunder="true"><mrow><msqrt><mrow><mn>1</mn><mo>-</mo><msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>-</mo><msubsup><mi>Ïƒ</mi> <mi>t</mi> <mn>2</mn></msubsup></mrow></msqrt> <mo>Â·</mo><msubsup><mi>Ïµ</mi>
    <mi>Î¸</mi> <mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></msubsup> <mrow><mo>(</mo><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>)</mo></mrow></mrow> <mo>ï¸¸</mo></munder> <mrow><mtext>direction</mtext><mtext>pointing</mtext><mtext>to</mtext><msub><mi>ğ±</mi>
    <mi>t</mi></msub></mrow></munder> <mo>+</mo> <munder><munder accentunder="true"><mrow><msub><mi>Ïƒ</mi>
    <mi>t</mi></msub> <msub><mi>Ïµ</mi> <mi>t</mi></msub></mrow> <mo>ï¸¸</mo></munder>
    <mrow><mtext>random</mtext><mtext>noise</mtext></mrow></munder></mrow></math>
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold x Subscript t minus 1 Baseline equals StartRoot alpha overbar
    Subscript t minus 1 Baseline EndRoot ModifyingBelow left-parenthesis StartFraction
    bold x Subscript t Baseline minus StartRoot 1 minus alpha overbar Subscript t
    Baseline EndRoot epsilon Subscript theta Superscript left-parenthesis t right-parenthesis
    Baseline left-parenthesis bold x Subscript t Baseline right-parenthesis Over StartRoot
    alpha overbar Subscript t Baseline EndRoot EndFraction right-parenthesis With
    bottom-brace Underscript predicted bold x 0 Endscripts plus ModifyingBelow StartRoot
    1 minus alpha overbar Subscript t minus 1 Baseline minus sigma Subscript t Superscript
    2 Baseline EndRoot dot epsilon Subscript theta Superscript left-parenthesis t
    right-parenthesis Baseline left-parenthesis bold x Subscript t Baseline right-parenthesis
    With bottom-brace Underscript direction pointing to bold x Subscript t Baseline
    Endscripts plus ModifyingBelow sigma Subscript t Baseline epsilon Subscript t
    Baseline With bottom-brace Underscript random noise Endscripts" display="block"><mrow><msub><mi>ğ±</mi>
    <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>=</mo> <msqrt><msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></msqrt>
    <munder><munder accentunder="true"><mfenced separators="" open="(" close=")"><mfrac><mrow><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>-</mo><msqrt><mrow><mn>1</mn><mo>-</mo><msub><mover accent="true"><mi>Î±</mi>
    <mo>Â¯</mo></mover> <mi>t</mi></msub></mrow></msqrt> <msubsup><mi>Ïµ</mi> <mi>Î¸</mi>
    <mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></msubsup> <mrow><mo>(</mo><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>)</mo></mrow></mrow> <msqrt><msub><mover accent="true"><mi>Î±</mi>
    <mo>Â¯</mo></mover> <mi>t</mi></msub></msqrt></mfrac></mfenced> <mo>ï¸¸</mo></munder>
    <mrow><mtext>predicted</mtext><msub><mi>ğ±</mi> <mn>0</mn></msub></mrow></munder>
    <mo>+</mo> <munder><munder accentunder="true"><mrow><msqrt><mrow><mn>1</mn><mo>-</mo><msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>-</mo><msubsup><mi>Ïƒ</mi> <mi>t</mi> <mn>2</mn></msubsup></mrow></msqrt> <mo>Â·</mo><msubsup><mi>Ïµ</mi>
    <mi>Î¸</mi> <mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></msubsup> <mrow><mo>(</mo><msub><mi>ğ±</mi>
    <mi>t</mi></msub> <mo>)</mo></mrow></mrow> <mo>ï¸¸</mo></munder> <mrow><mtext>direction</mtext><mtext>pointing</mtext><mtext>to</mtext><msub><mi>ğ±</mi>
    <mi>t</mi></msub></mrow></munder> <mo>+</mo> <munder><munder accentunder="true"><mrow><msub><mi>Ïƒ</mi>
    <mi>t</mi></msub> <msub><mi>Ïµ</mi> <mi>t</mi></msub></mrow> <mo>ï¸¸</mo></munder>
    <mrow><mtext>random</mtext><mtext>noise</mtext></mrow></munder></mrow></math>
- en: Letâ€™s break this down. The first term inside the brackets on the righthand side
    of the equation is the estimated image <math alttext="x 0"><msub><mi>x</mi> <mn>0</mn></msub></math>
    , calculated using the noise predicted by our network <math alttext="epsilon Subscript
    theta Superscript left-parenthesis t right-parenthesis"><msubsup><mi>Ïµ</mi> <mi>Î¸</mi>
    <mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></msubsup></math> . We then scale this
    by the <math alttext="t minus 1"><mrow><mi>t</mi> <mo>-</mo> <mn>1</mn></mrow></math>
    signal rate <math alttext="StartRoot alpha overbar Subscript t minus 1 Baseline
    EndRoot"><msqrt><msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></msqrt></math>
    and reapply the predicted noise, but this time scaled by the <math alttext="t
    minus 1"><mrow><mi>t</mi> <mo>-</mo> <mn>1</mn></mrow></math> noise rate <math
    alttext="StartRoot 1 minus alpha overbar Subscript t minus 1 Baseline minus sigma
    Subscript t Superscript 2 Baseline EndRoot"><msqrt><mrow><mn>1</mn> <mo>-</mo>
    <msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>-</mo> <msubsup><mi>Ïƒ</mi> <mi>t</mi> <mn>2</mn></msubsup></mrow></msqrt></math>
    . Additional Gaussian random noise <math alttext="sigma Subscript t Baseline epsilon
    Subscript t"><mrow><msub><mi>Ïƒ</mi> <mi>t</mi></msub> <msub><mi>Ïµ</mi> <mi>t</mi></msub></mrow></math>
    is also added, with the factors <math alttext="sigma Subscript t"><msub><mi>Ïƒ</mi>
    <mi>t</mi></msub></math> determining how random we want our generation process
    to be.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ¥åˆ†è§£ä¸€ä¸‹ã€‚æ–¹ç¨‹å¼å³ä¾§æ‹¬å·å†…çš„ç¬¬ä¸€ä¸ªé¡¹æ˜¯ä¼°è®¡çš„å›¾åƒ <math alttext="x 0"><msub><mi>x</mi> <mn>0</mn></msub></math>ï¼Œä½¿ç”¨æˆ‘ä»¬ç½‘ç»œé¢„æµ‹çš„å™ªå£°
    <math alttext="epsilon Subscript theta Superscript left-parenthesis t right-parenthesis"><msubsup><mi>Ïµ</mi>
    <mi>Î¸</mi> <mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></msubsup></math> è®¡ç®—å¾—åˆ°ã€‚ç„¶åæˆ‘ä»¬é€šè¿‡
    <math alttext="t minus 1"><mrow><mi>t</mi> <mo>-</mo> <mn>1</mn></mrow></math>
    ä¿¡å·ç‡ <math alttext="StartRoot alpha overbar Subscript t minus 1 Baseline EndRoot"><msqrt><msub><mover
    accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></msqrt></math>
    ç¼©æ”¾è¿™ä¸ªå€¼ï¼Œå¹¶é‡æ–°åº”ç”¨é¢„æµ‹çš„å™ªå£°ï¼Œä½†è¿™æ¬¡æ˜¯é€šè¿‡ <math alttext="t minus 1"><mrow><mi>t</mi> <mo>-</mo>
    <mn>1</mn></mrow></math> å™ªå£°ç‡ <math alttext="StartRoot 1 minus alpha overbar Subscript
    t minus 1 Baseline minus sigma Subscript t Superscript 2 Baseline EndRoot"><msqrt><mrow><mn>1</mn>
    <mo>-</mo> <msub><mover accent="true"><mi>Î±</mi> <mo>Â¯</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>-</mo> <msubsup><mi>Ïƒ</mi> <mi>t</mi> <mn>2</mn></msubsup></mrow></msqrt></math>
    è¿›è¡Œç¼©æ”¾ã€‚è¿˜æ·»åŠ äº†é¢å¤–çš„é«˜æ–¯éšæœºå™ªå£° <math alttext="sigma Subscript t Baseline epsilon Subscript
    t"><mrow><msub><mi>Ïƒ</mi> <mi>t</mi></msub> <msub><mi>Ïµ</mi> <mi>t</mi></msub></mrow></math>ï¼Œå…¶ä¸­
    <math alttext="sigma Subscript t"><msub><mi>Ïƒ</mi> <mi>t</msub></math> ç¡®å®šäº†æˆ‘ä»¬å¸Œæœ›ç”Ÿæˆè¿‡ç¨‹æœ‰å¤šéšæœºã€‚
- en: The special case <math alttext="sigma Subscript t Baseline equals 0"><mrow><msub><mi>Ïƒ</mi>
    <mi>t</mi></msub> <mo>=</mo> <mn>0</mn></mrow></math> for all <math alttext="t"><mi>t</mi></math>
    corresponds to a type of model known as a *Denoising Diffusion Implicit Model*
    (DDIM), introduced by Song et al. in 2020.^([9](ch08.xhtml#idm45387007342688))
    With a DDIM, the generation process is entirely deterministicâ€”that is, the same
    random noise input will always give the same output. This is desirable as then
    we have a well-defined mapping between samples from the latent space and the generated
    outputs in pixel space.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹æ®Šæƒ…å†µ <math alttext="sigma Subscript t Baseline equals 0"><mrow><msub><mi>Ïƒ</mi>
    <mi>t</mi></msub> <mo>=</mo> <mn>0</mn></mrow></math> å¯¹äºæ‰€æœ‰çš„ <math alttext="t"><mi>t</mi></math>
    å¯¹åº”äºä¸€ç§ç§°ä¸º*å»å™ªæ‰©æ•£éšå¼æ¨¡å‹*ï¼ˆDDIMï¼‰çš„æ¨¡å‹ï¼Œç”±Songç­‰äººåœ¨2020å¹´æå‡ºã€‚^([9](ch08.xhtml#idm45387007342688))
    ä½¿ç”¨DDIMï¼Œç”Ÿæˆè¿‡ç¨‹å®Œå…¨æ˜¯ç¡®å®šæ€§çš„â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œç›¸åŒçš„éšæœºå™ªå£°è¾“å…¥å°†å§‹ç»ˆäº§ç”Ÿç›¸åŒçš„è¾“å‡ºã€‚è¿™æ˜¯å¯å–çš„ï¼Œå› ä¸ºè¿™æ ·æˆ‘ä»¬åœ¨æ½œåœ¨ç©ºé—´çš„æ ·æœ¬å’Œåƒç´ ç©ºé—´ä¸­ç”Ÿæˆçš„è¾“å‡ºä¹‹é—´æœ‰ä¸€ä¸ªæ˜ç¡®å®šä¹‰çš„æ˜ å°„ã€‚
- en: In our example, we will implement a DDIM, thus making our generation process
    deterministic. The code for the DDIM sampling process (reverse diffusion) is shown
    in [ExampleÂ 8-11](#diffusion_sampling).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªDDIMï¼Œä»è€Œä½¿æˆ‘ä»¬çš„ç”Ÿæˆè¿‡ç¨‹ç¡®å®šæ€§ã€‚DDIMé‡‡æ ·è¿‡ç¨‹ï¼ˆåå‘æ‰©æ•£ï¼‰çš„ä»£ç æ˜¾ç¤ºåœ¨[ç¤ºä¾‹ 8-11](#diffusion_sampling)ä¸­ã€‚
- en: Example 8-11\. Sampling from the diffusion model
  id: totrans-225
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 8-11\. ä»æ‰©æ•£æ¨¡å‹ä¸­é‡‡æ ·
- en: '[PRE10]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[![1](Images/1.png)](#co_diffusion_models_CO9-1)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_diffusion_models_CO9-1)'
- en: Look over a fixed number of steps (e.g., 20).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: è§‚å¯Ÿå›ºå®šæ•°é‡çš„æ­¥éª¤ï¼ˆä¾‹å¦‚ï¼Œ20æ­¥ï¼‰ã€‚
- en: '[![2](Images/2.png)](#co_diffusion_models_CO9-2)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_diffusion_models_CO9-2)'
- en: The diffusion times are all set to 1 (i.e., at the start of the reverse diffusion
    process).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰©æ•£æ—¶é—´éƒ½è®¾ç½®ä¸º1ï¼ˆå³åœ¨åå‘æ‰©æ•£è¿‡ç¨‹å¼€å§‹æ—¶ï¼‰ã€‚
- en: '[![3](Images/3.png)](#co_diffusion_models_CO9-3)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_diffusion_models_CO9-3)'
- en: The noise and signal rates are calculated according to the diffusion schedule.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®æ‰©æ•£è®¡åˆ’è®¡ç®—å™ªå£°å’Œä¿¡å·ç‡ã€‚
- en: '[![4](Images/4.png)](#co_diffusion_models_CO9-4)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_diffusion_models_CO9-4)'
- en: The U-Net is used to predict the noise, allowing us to calculate the denoised
    image estimate.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: U-Netç”¨äºé¢„æµ‹å™ªå£°ï¼Œä»è€Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè®¡ç®—å»å™ªå›¾åƒçš„ä¼°è®¡ã€‚
- en: '[![5](Images/5.png)](#co_diffusion_models_CO9-5)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_diffusion_models_CO9-5)'
- en: The diffusion times are reduced by one step.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰©æ•£æ—¶é—´å‡å°‘ä¸€æ­¥ã€‚
- en: '[![6](Images/6.png)](#co_diffusion_models_CO9-6)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_diffusion_models_CO9-6)'
- en: The new noise and signal rates are calculated.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: è®¡ç®—æ–°çš„å™ªå£°å’Œä¿¡å·ç‡ã€‚
- en: '[![7](Images/7.png)](#co_diffusion_models_CO9-7)'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](Images/7.png)](#co_diffusion_models_CO9-7)'
- en: The `t-1` images are calculated by reapplying the predicted noise to the predicted
    image, according to the `t-1` diffusion schedule rates.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ ¹æ®æ‰©æ•£è®¡åˆ’ç‡é‡æ–°åº”ç”¨é¢„æµ‹å™ªå£°åˆ°é¢„æµ‹å›¾åƒï¼Œè®¡ç®—å‡º `t-1` å›¾åƒã€‚
- en: '[![8](Images/8.png)](#co_diffusion_models_CO9-8)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](Images/8.png)](#co_diffusion_models_CO9-8)'
- en: After 20 steps, the final <math alttext="bold x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math>
    predicted images are returned.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ç»è¿‡20æ­¥ï¼Œæœ€ç»ˆçš„ <math alttext="bold x 0"><msub><mi>ğ±</mi> <mn>0</mn></msub></math>
    é¢„æµ‹å›¾åƒè¢«è¿”å›ã€‚
- en: Analysis of the Diffusion Model
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ‰©æ•£æ¨¡å‹çš„åˆ†æ
- en: 'Weâ€™ll now take a look at three different ways that we can use our trained model:
    for generation of new images, testing how the number of reverse diffusion steps
    affects quality, and interpolating between two images in the latent space.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å°†çœ‹ä¸€ä¸‹æˆ‘ä»¬è®­ç»ƒæ¨¡å‹çš„ä¸‰ç§ä¸åŒç”¨æ³•ï¼šç”¨äºç”Ÿæˆæ–°å›¾åƒï¼Œæµ‹è¯•åå‘æ‰©æ•£æ­¥æ•°å¦‚ä½•å½±å“è´¨é‡ï¼Œä»¥åŠåœ¨æ½œåœ¨ç©ºé—´ä¸­ä¸¤ä¸ªå›¾åƒä¹‹é—´çš„æ’å€¼ã€‚
- en: Generating images
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå›¾åƒ
- en: In order to produce samples from our trained model, we can simply run the reverse
    diffusion process, ensuring that we denormalize the output at the end (i.e., take
    the pixel values back into the range [0, 1]). We can achieve this using the code
    in [ExampleÂ 8-12](#diffusion_generation) inside the `DiffusionModel` class.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä»æˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹ä¸­ç”Ÿæˆæ ·æœ¬ï¼Œæˆ‘ä»¬åªéœ€è¿è¡Œé€†æ‰©æ•£è¿‡ç¨‹ï¼Œç¡®ä¿æœ€ç»ˆå»æ ‡å‡†åŒ–è¾“å‡ºï¼ˆå³ï¼Œå°†åƒç´ å€¼å¸¦å›èŒƒå›´[0, 1]ï¼‰ã€‚æˆ‘ä»¬å¯ä»¥åœ¨`DiffusionModel`ç±»ä¸­ä½¿ç”¨[ç¤ºä¾‹8-12](#diffusion_generation)ä¸­çš„ä»£ç æ¥å®ç°è¿™ä¸€ç‚¹ã€‚
- en: Example 8-12\. Generating images using the diffusion model
  id: totrans-247
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹8-12ã€‚ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒ
- en: '[PRE11]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](Images/1.png)](#co_diffusion_models_CO10-1)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_diffusion_models_CO10-1)'
- en: Generate some initial noise maps.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆä¸€äº›åˆå§‹å™ªå£°å›¾ã€‚
- en: '[![2](Images/2.png)](#co_diffusion_models_CO10-3)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_diffusion_models_CO10-3)'
- en: Apply the reverse diffusion process.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: åº”ç”¨é€†æ‰©æ•£è¿‡ç¨‹ã€‚
- en: '[![3](Images/3.png)](#co_diffusion_models_CO10-4)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_diffusion_models_CO10-4)'
- en: The images output by the network will have mean zero and unit variance, so we
    need to denormalize by reapplying the mean and variance calculated from the training
    data.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ç½‘ç»œè¾“å‡ºçš„å›¾åƒå°†å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ–¹å·®ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦é€šè¿‡é‡æ–°åº”ç”¨ä»è®­ç»ƒæ•°æ®è®¡ç®—å¾—å‡ºçš„å‡å€¼å’Œæ–¹å·®æ¥å»æ ‡å‡†åŒ–ã€‚
- en: In [FigureÂ 8-14](#diffusion_samples_epoch) we can observe some samples from
    the diffusion model at different epochs of the training process.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[å›¾8-14](#diffusion_samples_epoch)ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°è®­ç»ƒè¿‡ç¨‹ä¸­ä¸åŒæ—¶æœŸæ‰©æ•£æ¨¡å‹çš„ä¸€äº›æ ·æœ¬ã€‚
- en: '![](Images/gdl2_0814.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0814.png)'
- en: Figure 8-14\. Samples from the diffusion model at different epochs of the training
    process
  id: totrans-257
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-14ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ä¸åŒæ—¶æœŸæ‰©æ•£æ¨¡å‹çš„æ ·æœ¬
- en: Adjusting the number of diffusion steps
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è°ƒæ•´æ‰©æ•£æ­¥æ•°
- en: We can also test to see how adjusting the number of diffusion steps in the reverse
    process affects image quality. Intuitively, the more steps taken by the process,
    the higher the quality of the image generation.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å¯ä»¥æµ‹è¯•è°ƒæ•´é€†å‘è¿‡ç¨‹ä¸­æ‰©æ•£æ­¥æ•°å¦‚ä½•å½±å“å›¾åƒè´¨é‡ã€‚ç›´è§‚åœ°ï¼Œè¿‡ç¨‹ä¸­æ­¥æ•°è¶Šå¤šï¼Œå›¾åƒç”Ÿæˆçš„è´¨é‡å°±è¶Šé«˜ã€‚
- en: We can see in [FigureÂ 8-15](#diffusion_steps_quality) that the quality of the
    generations does indeed improve with the number of diffusion steps. With one giant
    leap from the initial sampled noise, the model can only predict a hazy blob of
    color. With more steps, the model is able to refine and sharpen its generations.
    However, the time taken to generate the images scales linearly with the number
    of diffusion steps, so there is a trade-off. There is minimal improvement between
    20 and 100 diffusion steps, so we choose 20 as a reasonable compromise between
    quality and speed in this example.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥åœ¨[å›¾8-15](#diffusion_steps_quality)ä¸­çœ‹åˆ°ï¼Œéšç€æ‰©æ•£æ­¥æ•°çš„å¢åŠ ï¼Œç”Ÿæˆçš„è´¨é‡ç¡®å®ä¼šæé«˜ã€‚ä»åˆå§‹æŠ½æ ·çš„å™ªå£°ä¸­ä¸€æ¬¡æ€§è·³è·ƒï¼Œæ¨¡å‹åªèƒ½é¢„æµ‹å‡ºä¸€ä¸ªæœ¦èƒ§çš„é¢œè‰²æ–‘å—ã€‚éšç€æ­¥æ•°çš„å¢åŠ ï¼Œæ¨¡å‹èƒ½å¤Ÿæ”¹è¿›å’Œé”åŒ–ç”Ÿæˆç‰©ã€‚ç„¶è€Œï¼Œç”Ÿæˆå›¾åƒæ‰€éœ€çš„æ—¶é—´ä¸æ‰©æ•£æ­¥æ•°æˆçº¿æ€§å…³ç³»ï¼Œå› æ­¤å­˜åœ¨æƒè¡¡ã€‚åœ¨20å’Œ100ä¸ªæ‰©æ•£æ­¥ä¹‹é—´çš„æ”¹è¿›å¾ˆå°ï¼Œå› æ­¤åœ¨è¿™ä¸ªä¾‹å­ä¸­æˆ‘ä»¬é€‰æ‹©20ä½œä¸ºè´¨é‡å’Œé€Ÿåº¦ä¹‹é—´çš„åˆç†æŠ˜è¡·ã€‚
- en: '![](Images/gdl2_0815.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0815.png)'
- en: Figure 8-15\. Image quality improves with the number of diffusion steps
  id: totrans-262
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-15ã€‚éšç€æ‰©æ•£æ­¥æ•°çš„å¢åŠ ï¼Œå›¾åƒè´¨é‡æé«˜
- en: Interpolating between images
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: åœ¨å›¾åƒä¹‹é—´è¿›è¡Œæ’å€¼
- en: Lastly, as we have seen previously with variational autoencoders, we can interpolate
    between points in the Gaussian latent space in order to smoothly transition between
    images in pixel space. Here we choose to use a form of spherical interpolation
    that ensures that the variance remains constant while blending the two Gaussian
    noise maps together. Specifically, the initial noise map at each step is given
    by <math alttext="a sine left-parenthesis StartFraction pi Over 2 EndFraction
    t right-parenthesis plus b cosine left-parenthesis StartFraction pi Over 2 EndFraction
    t right-parenthesis"><mrow><mi>a</mi> <mo form="prefix">sin</mo> <mrow><mo>(</mo>
    <mfrac><mi>Ï€</mi> <mn>2</mn></mfrac> <mi>t</mi> <mo>)</mo></mrow> <mo>+</mo> <mi>b</mi>
    <mo form="prefix">cos</mo> <mrow><mo>(</mo> <mfrac><mi>Ï€</mi> <mn>2</mn></mfrac>
    <mi>t</mi> <mo>)</mo></mrow></mrow></math> , where <math alttext="t"><mi>t</mi></math>
    ranges smoothly from 0 to 1 and <math alttext="a"><mi>a</mi></math> and <math
    alttext="b"><mi>b</mi></math> are the two randomly sampled Gaussian noise tensors
    that we wish to interpolate between.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæ­£å¦‚æˆ‘ä»¬ä¹‹å‰åœ¨å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ä¸­çœ‹åˆ°çš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨é«˜æ–¯æ½œåœ¨ç©ºé—´ä¸­çš„ç‚¹ä¹‹é—´è¿›è¡Œæ’å€¼ï¼Œä»¥ä¾¿åœ¨åƒç´ ç©ºé—´ä¸­å¹³æ»‘è¿‡æ¸¡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é€‰æ‹©ä½¿ç”¨ä¸€ç§çƒé¢æ’å€¼çš„å½¢å¼ï¼Œç¡®ä¿æ–¹å·®åœ¨æ··åˆä¸¤ä¸ªé«˜æ–¯å™ªå£°å›¾ä¹‹é—´ä¿æŒæ’å®šã€‚å…·ä½“æ¥è¯´ï¼Œæ¯ä¸€æ­¥çš„åˆå§‹å™ªå£°å›¾ç”±<math
    alttext="a sine left-parenthesis StartFraction pi Over 2 EndFraction t right-parenthesis
    plus b cosine left-parenthesis StartFraction pi Over 2 EndFraction t right-parenthesis"><mrow><mi>a</mi>
    <mo form="prefix">sin</mo> <mrow><mo>(</mo> <mfrac><mi>Ï€</mi> <mn>2</mn></mfrac>
    <mi>t</mi> <mo>)</mo></mrow> <mo>+</mo> <mi>b</mi> <mo form="prefix">cos</mo>
    <mrow><mo>(</mo> <mfrac><mi>Ï€</mi> <mn>2</mn></mfrac> <mi>t</mi> <mo>)</mo></mrow></mrow></math>ç»™å‡ºï¼Œå…¶ä¸­<math
    alttext="t"><mi>t</mi></math>ä»0å¹³æ»‘åœ°å˜åŒ–åˆ°1ï¼Œ<math alttext="a"><mi>a</mi></math>å’Œ<math
    alttext="b"><mi>b</mi></math>æ˜¯æˆ‘ä»¬å¸Œæœ›åœ¨å…¶é—´æ’å€¼çš„ä¸¤ä¸ªéšæœºæŠ½æ ·çš„é«˜æ–¯å™ªå£°å¼ é‡ã€‚
- en: The resulting images are shown in [FigureÂ 8-16](#diffusion_interpolation).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆçš„å›¾åƒæ˜¾ç¤ºåœ¨[å›¾8-16](#diffusion_interpolation)ä¸­ã€‚
- en: '![](Images/gdl2_0816.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0816.png)'
- en: Figure 8-16\. Interpolating between images using the denoising diffusion model`  `#
    Summary
  id: totrans-267
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾8-16ã€‚ä½¿ç”¨å»å™ªæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¹‹é—´è¿›è¡Œæ’å€¼`  `# æ€»ç»“
- en: 'In this chapter we have explored one of the most exciting and promising areas
    of generative modeling in recent times: diffusion models. In particular, we implemented
    the ideas from a key paper on generative diffusion models (Ho et al., 2020) that
    introduced the original Denoising Diffusion Probabilistic Model (DDPM). We then
    extended this with the ideas from the Denoising Diffusion Implicit Model (DDIM)
    paper to make the generation process fully deterministic.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†è¿‘æœŸæœ€ä»¤äººå…´å¥‹å’Œæœ‰å‰é€”çš„ç”Ÿæˆå»ºæ¨¡é¢†åŸŸä¹‹ä¸€ï¼šæ‰©æ•£æ¨¡å‹ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ç¯‡å…³äºç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„å…³é”®è®ºæ–‡ï¼ˆHoç­‰äººï¼Œ2020ï¼‰ä¸­ä»‹ç»çš„åŸå§‹å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMï¼‰çš„æ€æƒ³ã€‚ç„¶åï¼Œæˆ‘ä»¬å€Ÿé‰´äº†å»å™ªæ‰©æ•£éšå¼æ¨¡å‹ï¼ˆDDIMï¼‰è®ºæ–‡ä¸­çš„æ€æƒ³ï¼Œä½¿ç”Ÿæˆè¿‡ç¨‹å®Œå…¨ç¡®å®šæ€§ã€‚
- en: We have seen how diffusion models are formed of a forward diffusion process
    and a reverse diffusion process. The forward diffusion process adds noise to the
    training data through a series of small steps, while the reverse diffusion process
    consists of a model that tries to predict the noise added.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å·²ç»çœ‹åˆ°æ‰©æ•£æ¨¡å‹ç”±å‰å‘æ‰©æ•£è¿‡ç¨‹å’Œé€†æ‰©æ•£è¿‡ç¨‹ç»„æˆã€‚ å‰å‘æ‰©æ•£è¿‡ç¨‹é€šè¿‡ä¸€ç³»åˆ—å°æ­¥éª¤å‘è®­ç»ƒæ•°æ®æ·»åŠ å™ªå£°ï¼Œè€Œé€†æ‰©æ•£è¿‡ç¨‹åŒ…æ‹¬è¯•å›¾é¢„æµ‹æ·»åŠ çš„å™ªå£°çš„æ¨¡å‹ã€‚
- en: We make use of a reparameterization trick in order to calculate the noised images
    at any step of the forward process without having to go through multiple noising
    steps. We have seen how the chosen schedule of parameters used to add noise to
    the data plays an important part in the overall success of the model.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åˆ©ç”¨é‡æ–°å‚æ•°åŒ–æŠ€å·§ï¼Œä»¥ä¾¿åœ¨å‰å‘è¿‡ç¨‹çš„ä»»ä½•æ­¥éª¤ä¸­è®¡ç®—å¸¦å™ªå£°çš„å›¾åƒï¼Œè€Œæ— éœ€ç»å†å¤šä¸ªåŠ å™ªæ­¥éª¤ã€‚ æˆ‘ä»¬å·²ç»çœ‹åˆ°ï¼Œç”¨äºå‘æ•°æ®æ·»åŠ å™ªå£°çš„å‚æ•°é€‰æ‹©è®¡åˆ’åœ¨æ¨¡å‹çš„æ•´ä½“æˆåŠŸä¸­èµ·ç€é‡è¦ä½œç”¨ã€‚
- en: The reverse diffusion process is parameterized by a U-Net that tries to predict
    the noise at each timestep, given the noised image and the noise rate at that
    step. A U-Net consists of `DownBlock`s that increase the number of channels while
    reducing the size of the image and `UpBlock`s that decrease the number of channels
    while increasing the size. The noise rate is encoded using sinusoidal embedding.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: é€†æ‰©æ•£è¿‡ç¨‹ç”±ä¸€ä¸ªU-Netå‚æ•°åŒ–ï¼Œè¯•å›¾åœ¨æ¯ä¸ªæ—¶é—´æ­¥é¢„æµ‹å™ªå£°ï¼Œç»™å®šåœ¨è¯¥æ­¥éª¤çš„å™ªå£°å›¾åƒå’Œå™ªå£°ç‡ã€‚ U-Netç”±`DownBlock`ç»„æˆï¼Œå®ƒä»¬å¢åŠ é€šé“æ•°åŒæ—¶å‡å°å›¾åƒçš„å¤§å°ï¼Œä»¥åŠ`UpBlock`ï¼Œå®ƒä»¬å‡å°‘é€šé“æ•°åŒæ—¶å¢åŠ å¤§å°ã€‚
    å™ªå£°ç‡ä½¿ç”¨æ­£å¼¦åµŒå…¥è¿›è¡Œç¼–ç ã€‚
- en: Sampling from the diffusion model is conducted over a series of steps. The U-Net
    is used to predict the noise added to a given noised image, which is then used
    to calculate an estimate for the original image. The predicted noise is then reapplied
    using a smaller noise rate. This process is repeated over a series of steps (which
    may be significantly smaller than the number of steps used during training), starting
    from a random point sampled from a standard Gaussian noise distribution, to obtain
    the final generation.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æ‰©æ•£æ¨¡å‹ä¸­è¿›è¡Œé‡‡æ ·æ˜¯åœ¨ä¸€ç³»åˆ—æ­¥éª¤ä¸­è¿›è¡Œçš„ã€‚ ä½¿ç”¨U-Netæ¥é¢„æµ‹æ·»åŠ åˆ°ç»™å®šå™ªå£°å›¾åƒçš„å™ªå£°ï¼Œç„¶åç”¨äºè®¡ç®—åŸå§‹å›¾åƒçš„ä¼°è®¡ã€‚ ç„¶åä½¿ç”¨è¾ƒå°çš„å™ªå£°ç‡é‡æ–°åº”ç”¨é¢„æµ‹çš„å™ªå£°ã€‚
    ä»æ ‡å‡†é«˜æ–¯å™ªå£°åˆ†å¸ƒä¸­éšæœºæŠ½å–çš„éšæœºç‚¹å¼€å§‹ï¼Œé‡å¤è¿™ä¸ªè¿‡ç¨‹ä¸€ç³»åˆ—æ­¥éª¤ï¼ˆå¯èƒ½æ˜æ˜¾å°äºè®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ­¥éª¤æ•°ï¼‰ï¼Œä»¥è·å¾—æœ€ç»ˆç”Ÿæˆã€‚
- en: We saw how increasing the number of diffusion steps in the reverse process improves
    the image generation quality, at the expense of speed. We also performed latent
    space arithmetic in order to interpolate between two images.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çœ‹åˆ°ï¼Œåœ¨é€†è¿‡ç¨‹ä¸­å¢åŠ æ‰©æ•£æ­¥éª¤çš„æ•°é‡ä¼šæé«˜å›¾åƒç”Ÿæˆè´¨é‡ï¼Œä½†ä¼šé™ä½é€Ÿåº¦ã€‚ æˆ‘ä»¬è¿˜æ‰§è¡Œäº†æ½œåœ¨ç©ºé—´ç®—æœ¯ï¼Œä»¥åœ¨ä¸¤ä¸ªå›¾åƒä¹‹é—´æ’å€¼ã€‚
- en: ^([1](ch08.xhtml#idm45387010500320-marker)) Jascha Sohl-Dickstein et al., â€œDeep
    Unsupervised Learning Using Nonequilibrium Thermodynamics,â€ March 12, 2015, [*https://arxiv.org/abs/1503.03585*](https://arxiv.org/abs/1503.03585)
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch08.xhtml#idm45387010500320-marker)) Jascha Sohl-Dicksteinç­‰ï¼Œâ€œä½¿ç”¨éå¹³è¡¡çƒ­åŠ›å­¦è¿›è¡Œæ·±åº¦æ— ç›‘ç£å­¦ä¹ â€ï¼Œ2015å¹´3æœˆ12æ—¥ï¼Œ[*https://arxiv.org/abs/1503.03585*](https://arxiv.org/abs/1503.03585)
- en: ^([2](ch08.xhtml#idm45387010496240-marker)) Yang Song and Stefano Ermon, â€œGenerative
    Modeling by Estimating Gradients of the Data Distribution,â€ July 12, 2019, [*https://arxiv.org/abs/1907.05600*](https://arxiv.org/abs/1907.05600).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch08.xhtml#idm45387010496240-marker)) æ¨æ¾å’ŒStefano Ermonï¼Œâ€œé€šè¿‡ä¼°è®¡æ•°æ®åˆ†å¸ƒçš„æ¢¯åº¦è¿›è¡Œç”Ÿæˆå»ºæ¨¡â€ï¼Œ2019å¹´7æœˆ12æ—¥ï¼Œ[*https://arxiv.org/abs/1907.05600*](https://arxiv.org/abs/1907.05600)ã€‚
- en: ^([3](ch08.xhtml#idm45387010494000-marker)) Yang Song and Stefano Ermon, â€œImproved
    Techniques for Training Score-Based Generative Models,â€ June 16, 2020, [*https://arxiv.org/abs/2006.09011*](https://arxiv.org/abs/2006.09011).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch08.xhtml#idm45387010494000-marker)) æ¨æ¾å’ŒStefano Ermonï¼Œâ€œæ”¹è¿›è®­ç»ƒåŸºäºåˆ†æ•°çš„ç”Ÿæˆæ¨¡å‹çš„æŠ€æœ¯â€ï¼Œ2020å¹´6æœˆ16æ—¥ï¼Œ[*https://arxiv.org/abs/2006.09011*](https://arxiv.org/abs/2006.09011)ã€‚
- en: ^([4](ch08.xhtml#idm45387010490880-marker)) Jonathon Ho et al., â€œDenoising Diffusion
    Probabilistic Models,â€ June 19, 2020, [*https://arxiv.org/abs/2006.11239*](https://arxiv.org/abs/2006.11239).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch08.xhtml#idm45387010490880-marker)) Jonathon Hoç­‰ï¼Œâ€œå»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹â€ï¼Œ2020å¹´6æœˆ19æ—¥ï¼Œ[*https://arxiv.org/abs/2006.11239*](https://arxiv.org/abs/2006.11239)ã€‚
- en: ^([5](ch08.xhtml#idm45387010764208-marker)) Alex Nichol and Prafulla Dhariwal,
    â€œImproved Denoising Diffusion Probabilistic Models,â€ February 18, 2021, [*https://arxiv.org/abs/2102.09672*](https://arxiv.org/abs/2102.09672).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch08.xhtml#idm45387010764208-marker)) Alex Nicholå’ŒPrafulla Dhariwalï¼Œâ€œæ”¹è¿›å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹â€ï¼Œ2021å¹´2æœˆ18æ—¥ï¼Œ[*https://arxiv.org/abs/2102.09672*](https://arxiv.org/abs/2102.09672)ã€‚
- en: ^([6](ch08.xhtml#idm45387008220416-marker)) Ashish Vaswani et al., â€œAttention
    Is All You Need,â€ June 12, 2017, [*https://arxiv.org/abs/1706.03762*](https://arxiv.org/abs/1706.03762).
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch08.xhtml#idm45387008220416-marker)) Ashish Vaswaniç­‰ï¼Œâ€œæ³¨æ„åŠ›å°±æ˜¯ä¸€åˆ‡â€ï¼Œ2017å¹´6æœˆ12æ—¥ï¼Œ[*https://arxiv.org/abs/1706.03762*](https://arxiv.org/abs/1706.03762)ã€‚
- en: '^([7](ch08.xhtml#idm45387008216736-marker)) Ben Mildenhall et al., â€œNeRF: Representing
    Scenes as Neural Radiance Fields for View Synthesis,â€ March 1, 2020, [*https://arxiv.org/abs/2003.08934*](https://arxiv.org/abs/2003.08934).'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch08.xhtml#idm45387008216736-marker)) Ben Mildenhallç­‰ï¼Œâ€œNeRFï¼šå°†åœºæ™¯è¡¨ç¤ºä¸ºç¥ç»è¾å°„åœºè¿›è¡Œè§†å›¾åˆæˆâ€ï¼Œ2020å¹´3æœˆ1æ—¥ï¼Œ[*https://arxiv.org/abs/2003.08934*](https://arxiv.org/abs/2003.08934)ã€‚
- en: ^([8](ch08.xhtml#idm45387008052288-marker)) Kaiming He et al., â€œDeep Residual
    Learning for Image Recognition,â€ December 10, 2015, [*https://arxiv.org/abs/1512.03385*](https://arxiv.org/abs/1512.03385).
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch08.xhtml#idm45387008052288-marker)) Kaiming Heç­‰ï¼Œâ€œç”¨äºå›¾åƒè¯†åˆ«çš„æ·±åº¦æ®‹å·®å­¦ä¹ â€ï¼Œ2015å¹´12æœˆ10æ—¥ï¼Œ[*https://arxiv.org/abs/1512.03385*](https://arxiv.org/abs/1512.03385)ã€‚
- en: ^([9](ch08.xhtml#idm45387007342688-marker)) Jiaming Song et al., â€œDenoising
    Diffusion Implicit Models,â€ October 6, 2020, [*https://arxiv.org/abs/2010.02502*](https://arxiv.org/abs/2010.02502)`
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch08.xhtml#idm45387007342688-marker)) å®‹å˜‰æ˜ç­‰ï¼Œâ€œå»å™ªæ‰©æ•£éšå¼æ¨¡å‹â€ï¼Œ2020å¹´10æœˆ6æ—¥ï¼Œ[*https://arxiv.org/abs/2010.02502*](https://arxiv.org/abs/2010.02502)`
