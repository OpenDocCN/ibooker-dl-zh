["```py\n*Document 1:*\n  Lynn: ham and cheese sandwich, chocolate cookie, ice water\n  Brian: turkey avocado sandwich, plain potato chips, apple juice\n  Mohammed: grilled chicken salad, fruit cup, lemonade\n*Document 2:*\n  Orchard Farms apple juice is premium, organic apple juice made from the\n  freshest apples, never from concentrate. Its juice has received the\n  regional award for best apple juice three years in a row.\n```", "```py\n[a, and, apple, apples, avocado, award, best, brian, cheese, chicken, chips,\n chocolate, concentrate, cookie, cup, farms, for, freshest, from, fruit,\n grilled, ham, has, ice, in, is, its, juice, lemonade, lynn, made,\n mohammed, never, orchard, organic, plain, potato, premium, received,\n regional, row, salad, sandwich, the, three, turkey, water, years]\n```", "```py\n*Document 1:*\n [0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1\n  0 0 0 1 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0]\n\n*Document 2:*\n [1 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0\n  1 1 1 1 0 0 1 0 1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 1]\n```", "```py\nquery_vector = numpy.array(\n  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n   0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n\ndoc1_vector = numpy.array(\n  [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n   0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0])\n\ndoc2_vector = numpy.array(\n  [1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n   1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1])\n\ndef cosine_similarity(vector1, vector2):\n  return dot(vector1, vector2) / (norm(vector1) * norm(vector2))\n\ndoc1_score = cosine_similarity(query_vector, doc1_vector)\ndoc2_score = cosine_similarity(query_vector, doc2_vector)\n\nprint_scores([doc1_score, doc2_score])\n```", "```py\nRelevance Scores:\n  doc1: 0.2828\n  doc2: 0.2828\n```", "```py\nquery_vector = [1, 1] #[apple, juice]\ndoc1_vector  = [1, 1]\ndoc2_vector  = [1, 1]\n\ndoc1_score = cosine_similarity(query_vector, doc1_vector)\ndoc2_score = cosine_similarity(query_vector, doc2_vector)\n\nprint_scores([doc1_score, doc2_score])\n```", "```py\nRelevance Scores:\n  doc1: 1.0\n  doc2: 1.0\n```", "```py\nquery_vector   = [1, 1] #[apple:1, juice:1]\ndoc1_tf_vector = [1, 1] #[apple:1, juice:1]\ndoc2_tf_vector = [3, 4] #[apple:3, juice:4]\n\ndoc1_score = cosine_similarity(query_vector, doc1_tf_vector)\ndoc2_score = cosine_similarity(query_vector, doc2_tf_vector)\n\nprint_scores([doc1_score, doc2_score])\n```", "```py\nRelevance Scores:\n  doc1: 1.0\n  doc2: 0.9899\n```", "```py\nquery_vector   = [1, 1] #[apple:1, juice:1]\ndoc1_tf_vector = [1, 1] #[apple:1, juice:1]\ndoc2_tf_vector = [3, 4] #[apple:3, juice:4]\n\ndoc1_score = dot(query_vector, doc1_tf_vector)\ndoc2_score = dot(query_vector, doc2_tf_vector)\n\nprint_scores([doc1_score, doc2_score])\n```", "```py\nRelevance Scores:\n  doc1: 2\n  doc2: 7\n```", "```py\n*Document 1:*\n  In light of the big reveal in her interview, the interesting\n  thing is that the person in the wrong probably made a good\n  decision in the end.\n\n*Document 2:*\n  My favorite book is the cat in the hat, which is about a crazy\n  cat in a hat who breaks into a house and creates the craziest\n  afternoon for two kids.\n\n*Document 3:*\n  My careless neighbors apparently let a stray cat stay in their\n  garage unsupervised which resulted in my favorite hat that I\n  let them borrow being ruined.\n```", "```py\ndef term_count(content, term):\n  tokenized_content = tokenize(content)\n  term_count = tokenized_content.count(term.lower())\n  return float(round(term_count, 4))\n\nquery = \"the cat in the hat\"\nterms = tokenize(query)\n\nquery_vector = list(numpy.repeat(1, len(terms)))\ndoc_vectors = [[term_count(doc, term) for term in terms] for doc in docs]\ndoc_scores = [dot(v, query_vector) for v in doc_vectors]\n\nprint_term_count_scores(terms, doc_vectors, doc_scores)\n```", "```py\nlabels:  ['the', 'cat', 'in', 'the', 'hat']\n\nquery vector: [1, 1, 1, 1, 1]\n\nDocument Vectors:\n  doc1: [5.0, 0.0, 4.0, 5.0, 0.0]\n  doc2: [3.0, 2.0, 2.0, 3.0, 2.0]\n  doc3: [0.0, 1.0, 2.0, 0.0, 1.0]\n\nRelevance Scores:\n  doc1: 14.0\n  doc2: 12.0\n  doc3: 4.0\n```", "```py\ndef tf(term, doc):\n  tokenized_doc = tokenize(doc)\n  term_count = tokenized_doc.count(term.lower())\n  doc_length = len(tokenized_doc)\n  return numpy.sqrt(term_count / doc_length)\n\nquery = \"the cat in the hat\"\nterms = tokenize(query)\n\nquery_vector = list(numpy.repeat(1, len(terms)))\ndoc_vectors = [[tf(term, doc) for term in terms] for doc in docs]\ndoc_scores = [dot(dv, query_vector) for dv in doc_vectors]\n\nprint_term_frequency_scores(terms, doc_vectors, doc_scores)\n```", "```py\nDocument TF Vector Calculations:\n  doc1: [tf(doc1, \"the\"), tf(doc1, \"cat\"), tf(doc1, \"in\"),\n         tf(doc1, \"the\"), tf(doc1, \"hat\")]\n  doc2: [tf(doc2, \"the\"), tf(doc2, \"cat\"), tf(doc2, \"in\"),\n         tf(doc2, \"the\"), tf(doc2, \"hat\")]\n  doc3: [tf(doc3, \"the\"), tf(doc3, \"cat\"), tf(doc3, \"in\"),\n         tf(doc3, \"the\"), tf(doc3, \"hat\")]\n\nDocument TF Vector Values:\nLabels: ['the', 'cat', 'in', 'the', 'hat']\n  doc1: [0.4303, 0.0, 0.3849, 0.4303, 0.0]\n  doc2: [0.3111, 0.254, 0.254, 0.3111, 0.254]\n  doc3: [0.0, 0.1961, 0.2774, 0.0, 0.1961]\n\nRelevance Scores:\n  doc1: 1.2456\n  doc2: 1.3842\n  doc3: 0.6696\n```", "```py\ndef idf(term):  #1\n  df_map = {\"the\": 9500, \"cat\": 100,   #2\n            \"in\": 9000, \"hat\": 50}    #2\n  total_docs = 10000\n  return 1 + numpy.log((total_docs+1) / (df_map[term] + 1))\n\nterms = [\"the\", \"cat\", \"in\", \"the\", \"hat\"]\nidf_vector = [idf(term) for term in terms] #3\n\nprint_inverse_document_frequency_scores(terms, idf_vector)\n```", "```py\nIDF Vector Values:\n  [idf(\"the\"), idf(\"cat\"), idf(\"in\"), idf(\"the\"), idf(\"hat\")]\n\nIDF Vector:\n  [1.0513, 5.5953, 1.1053, 1.0513, 6.2786]\n```", "```py\ndef tf_idf(term, doc):\n  return TF(term, doc) * IDF(term)***2*\n\nquery = \"the cat in the hat\"\nterms = tokenize(query)\n\nquery_vector = list(numpy.repeat(1, len(terms)))\ndoc_vectors = [[tf_idf(doc, term) for term in terms] for doc in docs]\ndoc_scores = [[dot(query_vector, dv)] for dv in doc_vectors]\n\nprint_tf_idf_scores(terms, doc_vectors, doc_scores)\n```", "```py\nDocument TF-IDF Vector Calculations\n  doc1: [tf_idf(doc1, \"the\"), tf_idf(doc1, \"cat\"), tf_idf(doc1, \"in\"),\n         tf_idf(doc1, \"the\"), tf_idf(doc1, \"hat\")]\n  doc2: [tf_idf(doc2, \"the\"), tf_idf(doc2, \"cat\"), tf_idf(doc2, \"in\"),\n         tf_idf(doc2, \"the\"), tf_idf(doc2, \"hat\")]\n  doc3: [tf_idf(doc3, \"the\"), tf_idf(doc3, \"cat\"), tf_idf(doc3, \"in\"),\n         tf_idf(doc3, \"the\"), tf_idf(doc3, \"hat\")]\n\nDocument TF-IDF Vector Scores\nLabels: ['the', 'cat', 'in', 'the', 'hat']\n  doc1: [0.4756, 0.0, 0.4703, 0.4755, 0.0]\n  doc2: [0.3438, 7.9521, 0.3103, 0.3438, 10.0129]\n  doc3: [0.0, 6.1399, 0.3389, 0.0, 7.7311]\n\nRelevance Scores:\n  doc1: 1.4215\n  doc2: 18.9633\n  doc3: 14.2099\n```", "```py\nengine = get_engine() #1\ncollection = engine.create_collection(\"cat_in_the_hat\")\n```", "```py\nWiping \"cat_in_the_hat\" collection\nCreating \"cat_in_the_hat\" collection\nStatus: Success\n```", "```py\ndocs = [{\"id\": \"doc1\",\n         \"title\": \"Worst\",\n         \"description\": \"\"\"The interesting thing is that the person in the\n                           wrong made the right decision in the end.\"\"\"},\n        {\"id\": \"doc2\",\n         \"title\": \"Best\",\n         \"description\": \"\"\"My favorite book is the cat in the hat, which is\n                           about a crazy cat who breaks into a house and\n                           creates a crazy afternoon for two kids.\"\"\"},\n        {\"id\": \"doc3\",\n         \"title\": \"Okay\",\n         \"description\": \"\"\"My neighbors let the stray cat stay in their\n                           garage, which resulted in my favorite hat that\n                           I let them borrow being ruined.\"\"\"}]\ncollection.add_documents(docs)\n```", "```py\nAdding Documents to 'cat_in_the_hat' collection\nStatus: Success\n```", "```py\nquery = \"the cat in the hat\"\nrequest = {\"query\": query,\n           \"query_fields\": [\"description\"],\n           \"return_fields\": [\"id\", \"title\", \"description\", \"score\"],\n           \"explain\": True}\n\nresponse = collection.search(**request)\ndisplay_search(query, response[\"docs\"])\n```", "```py\n*Query*: the cat in the hat\n*Ranked Docs*:\n[{'id': 'doc2',\n'title': ['Best'],\n'description': ['My favorite book is the cat in the hat, which is about a\n↪crazy cat who breaks into a house and creates a crazy afternoon for\n↪two kids.'],\n'score': 0.68231964, '[explain]': '\n  0.68231964  = sum of:\n    0.15655403 = weight(description:the in 1) [SchemaSimilarity], result of:\n      0.15655403 = score(freq=2.0), product of:\n        2.0 = boost\n        0.13353139 = idf, computed as log(1 + (N - n + 0.5) / (\n          n + 0.5)) from:\n          3 = n, number of documents containing term\n          3 = N, total number of documents with field\n        0.58620685 = tf, computed as freq / (freq + k1 * (\n          1 - b + b * dl / avgdl)) from:\n          2.0 = freq, occurrences of term within document\n          1.2 = k1, term saturation parameter\n          0.75 = b, length normalization parameter\n          28.0 = dl, length of field\n          22.666666 = avgdl, average length of field\n    0.19487953 = weight(description:hat in 1) ...\n    0.27551934 = weight(description:cat in 1) ...\n    0.05536667 = weight(description:in in 1) ...\n'}, {'id': 'doc3',\n'title': ['Okay'],\n'description': ['My neighbors let the stray cat stay in their garage, which\n↪resulted in my favorite hat that I let them borrow being ruined.'],\n'score': 0.62850046, '[explain]': '\n  0.62850046 = sum of:\n    0.21236044  = weight(description:the in 2) ...\n    0.08311336 = weight(description:hat in 2) ...\n    0.21236044 = weight(description:cat in 2) ...\n    0.120666236 = weight(description:in in 2) ...\n'}, {'id': 'doc1',\n'title': ['Worst'],\n'description': ['The interesting thing is that the person in the wrong made\n↪the right decision in the end.'],\n'score': 0.3132525,\n'[explain]': '\n  0.3132525 = sum of:\n    0.089769006 = weight(description:the in 0) ...\n    0.2234835 = weight(description:in in 0) ...\n'}]\n```", "```py\n*Ranked Results (Listing 3.8: TF-IDF Cosine Similarity)*:\n  doc2: 0.998\n  doc3: 0.9907\n  doc1: 0.0809\n\n*Ranked Results (Listing 3.9: BM25 Similarity)*:\n  doc2: 0.6878265\n  doc3: 0.62850046\n  doc1: 0.3132525\n```", "```py\n[ query(\"the\"), query(\"cat\"), query(\"in\"), query(\"the\"), query(\"hat\") ]\n```", "```py\n{!func}query(\"the\") {!func}query(\"cat\") {!func}query(\"in\")\n{!func}query(\"the\") {!func}query(\"hat\")\n```", "```py\nquery = '{!func}query(\"the\") {!func}query(\"cat\") {!func}query(\"in\")\n       ↪{!func}query(\"the\") {!func}query(\"hat\")'\nrequest = {\"query\": query,\n           \"query_fields\": \"description\",\n           \"return_fields\": [\"id\", \"title\", \"score\"]}\n\nresponse = collection.search(**request)\ndisplay_search(query, response[\"docs\"])\n```", "```py\n*Query:*\n {!func}query(\"the\") {!func}query(\"cat\") {!func}query(\"in\")\n  {!func}query(\"the\") {!func}query(\"hat\")\n*Results:*\n [{'id': 'doc2', 'title': ['Best'], 'score': 0.6823196},\n  {'id': 'doc3', 'title': ['Okay'], 'score': 0.62850046},\n  {'id': 'doc1', 'title': ['Worst'], 'score': 0.3132525}]\n```", "```py\n*Generic search request syntax:*\n {\"query\": \"the cat in the hat\",\n  \"query_fields\": [\"title^10\", \"description^2.5\"]}\n```", "```py\n*Solr request syntax:*\n {\"query\": \"the cat in the hat\",\n  \"params\": {\"defType\": \"edismax\",\n             \"qf\": \"title^10 description^2.5\"}}\n```", "```py\n*Solr request syntax:*\n {\"query\": \"the cat in the hat\",\n  \"params\": {\"defType\": \"edismax\",\n             \"qf\": \"title description\",\n             \"pf\": \"title\"}}\n```", "```py\n*Solr request syntax:*\n {\"query\": \"the cat in the hat\",\n  \"params\": {\"defType\": \"edismax\",\n             \"qf\": \"title description\",\n             \"pf2\": \"title description\"}}\n```", "```py\n*Solr request syntax:*\n {\"query\": \"the cat in the hat\",\n  \"params\": {\"defType\": \"edismax\",\n             \"qf\": \"title description\",\n             \"pf3\": \"description\"}}\n```", "```py\n*Solr request syntax:*\n {\"query\": \"*\",\n  \"sort\": \"geodist(location, $user_latitude, $user_longitude) asc\",\n  \"params\": {\"user_latitude\": 33.748,\n             \"user_longitude\": -84.39}}\n```", "```py\n*Solr request syntax:*\n {\"query\": \"{!func}scale(query($keywords),0,25)\n    ↪{!func}recip(geodist($lat_long_field,$user_latitude,\n     ↪$user_longitude),1,25,1)\n     ↪{!func}recip(ms(NOW/HOUR,modify_date),3.16e-11,25,1)\n    ↪{!func}scale(popularity,0,25)\",\n  \"params\": {\"keywords\": \"basketball\",\n             \"lat_long_field\": \"location\",\n             \"user_latitude\": 33.748,\n             \"user_longitude\" -84.391}}\n```", "```py\n*Text query (score + filter):*\n {\"query\": \"the cat in the hat\"}\n\n*Function Query (score only, no filter):*\n {\"query\": '{!func}query(\"the cat in the hat\")'}\n\n*Multiple Function Queries (score only, no filter):*\n {\"query\": '{!func}query(\"the\")\n          ↪{!func}query(\"cat\")\n          ↪{!func}query(\"in\")\n          ↪{!func}query(\"the\")\n          ↪{!func}query(\"hat\")'}\n\n*Boost Query (score only, no filter):*\n {\"query\": \"*\",\n  \"params\": {\"bq\": \"the cat in the hat\"}}\n```", "```py\n{\"query\": \"the cat in the hat\",\n \"params\": {\"defType\": \"edismax\",\n            \"boost\": \"mul(popularity,10)\"}}\n\n{\"query\": \"{!boost b=mul(popularity,10)} the cat in the hat\"}\n```", "```py\n*Generic search request syntax:*\n {\"query\": \"statue of liberty\",\n  \"min_match\": \"100%\"}\n\n*Solr request syntax:*\n {\"query\": \"statue of liberty\",\n  \"params\": {\"defType\": \"edismax\",\n             \"mm\": \"100%\"}}\n```", "```py\n*Generic search request syntax:*\n {\"query\": \"statue of liberty\",\n  \"min_match\": \"1\"}\n\n*Solr request syntax:*\n {\"query\": \"statue of liberty\",\n  \"params\": {\"defType\": \"edismax\",\n             \"mm\": \"1\"}}\n```", "```py\n*Generic search request syntax:*\n {\"query\": \"statue of liberty\",\n  \"query_parser\": \"edismax\",\n  \"min_match\": \"2\"}\n\n*Solr request syntax:*\n {\"query\": \"statue of liberty\",\n  \"params\": {\"defType\": \"edismax\",\n             \"mm\": \"2\"}}\n```", "```py\n*Generic search request syntax:*\n {\"query\": \"the cat in the hat\",\n  \"query_fields\": [\"description\"],\n  \"filters\": [(\"category\", \"books\"), (\"audience\", \"kid\")],\n  \"min_match\": \"100%\"}\n\n*Solr request syntax:*\n {\"query\": \"the cat in the hat\",\n  \"filters\": [\"category:books\", \"audience:kid\"],\n  \"params\": {\"qf\": [\"description\"],\n             \"mm\": \"100%\",\n             \"defType\": \"edismax\"}}\n```", "```py\n*Solr request syntax:*\n {\"query\": '{!func}query(\"{!edismax qf=description mm=100%\n ↪v=$user_query}\")',\n  \"filters\": \"{!cache=false v=$user_query}\",\n  \"params\": {\"user_query\": \"the cat in the hat\"}}\n```", "```py\n*Solr request syntax:*\n {\"query\": \"*\",\n  \"filters\": \"{!cache=false v=$user_query}\",\n  \"params\": {\"bq\": \"{!edismax qf=description mm=100% v=$user_quer}\",\n             \"user_query\": \"the cat in the hat\"}}\n```"]