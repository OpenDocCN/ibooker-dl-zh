- en: Chapter 1\. Introduction to TensorFlow 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。TensorFlow 2简介
- en: TensorFlow has long been the most popular open source Python machine learning
    (ML) library. It was developed by the Google Brain team as an internal tool, but
    in 2015 it was released under an Apache License. Since then, it has evolved into
    an ecosystem full of important assets for model development and deployment. Today
    it supports a wide variety of APIs and modules that are specifically designed
    to handle tasks such as data ingestion and transformation, feature engineering,
    and model construction and serving, as well as many more.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow长期以来一直是最受欢迎的开源Python机器学习（ML）库。它是由Google Brain团队作为内部工具开发的，但在2015年以Apache许可证发布。从那时起，它已经发展成一个充满重要资产的生态系统，用于模型开发和部署。今天，它支持各种特定设计用于处理数据摄入和转换、特征工程、模型构建和服务等任务的API和模块。
- en: TensorFlow has become increasingly complex. The purpose of this book is to help
    simplify the common tasks that a data scientist or ML engineer will need to perform
    during an end-to-end model development process. This book does not focus on data
    science and algorithms; rather, the examples here use prebuilt models as a vehicle
    to teach relevant concepts.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow变得越来越复杂。本书的目的是帮助简化数据科学家或ML工程师在端到端模型开发过程中需要执行的常见任务。本书不关注数据科学和算法；相反，这里的示例使用预构建的模型作为教授相关概念的工具。
- en: This book is written for readers with basic experience in and knowledge about
    building ML models. Some proficiency in Python programming is highly recommended.
    If you work through the book from beginning to end, you will gain a great deal
    of knowledge about the end-to-end model development process and the major tasks
    involved, including data engineering, ingestion, and preparation; model training;
    and serving the model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书适用于具有构建ML模型的基本经验和知识的读者。强烈建议具备一定的Python编程能力。如果您从头到尾阅读本书，您将获得关于端到端模型开发过程和涉及的主要任务的大量知识，包括数据工程、摄入和准备；模型训练；以及服务模型。
- en: The source code for the examples in the book was developed and tested with Google
    Colaboratory (Colab, for short) and a MacBook Pro running macOS Big Sur, version
    11.2.3\. The TensorFlow version used is 2.4.1, and the Python version is 3.7.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中示例的源代码是在Google Colaboratory（简称Colab）和运行macOS Big Sur，版本11.2.3的MacBook Pro上开发和测试的。使用的TensorFlow版本是2.4.1，Python版本是3.7。
- en: Improvements in TensorFlow 2
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 2的改进
- en: As TensorFlow grows, so does its complexity. The learning curve for new TensorFlow
    users is steep because there are so many different aspects to keep in mind. *How
    do I prepare the data for ingestion and training? How do I handle different data
    types? What do I need to consider for different handling methods?* These are just
    some of the basic questions you may have early in your ML journey.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 随着TensorFlow的发展，它的复杂性也在增加。新用户学习TensorFlow的曲线是陡峭的，因为需要记住许多不同的方面。*我如何准备数据进行摄入和训练？如何处理不同的数据类型？对于不同的处理方法需要考虑什么？*这些只是您在ML旅程初期可能遇到的一些基本问题。
- en: A particularly difficult concept to get accustomed to is *lazy execution*, which
    means that TensorFlow doesn’t actually process your data until you explicitly
    tell it to execute the entire code. The idea is to speed up performance. You can
    look at an ML model as a set of nodes and edges (in other words, a graph). When
    you run computations and transform data through the nodes in the path, it turns
    out that only the computations in the datapath are executed. In other words, you
    don’t have to calculate every computation, only the ones that lie directly in
    the path your data takes through the graph from input through output. If the shape
    and format of the data are not correctly matched between one node and the next,
    when you compile the model you will get an error. It is rather difficult to investigate
    where you made a mistake in passing a data structure or tensor shape from one
    node to the next to debug.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特别难以适应的概念是*惰性执行*，这意味着TensorFlow实际上不会处理您的数据，直到您明确告诉它执行整个代码。这个想法是为了加快性能。您可以将ML模型看作一组节点和边（换句话说，一个图）。当您在路径中运行计算并通过节点转换数据时，结果只有数据路径中的计算被执行。换句话说，您不必计算每个计算，只需计算数据通过图从输入到输出的路径中直接位于的计算。如果数据的形状和格式在一个节点和下一个节点之间没有正确匹配，当您编译模型时将会出现错误。在传递数据结构或张量形状时，很难调查您在哪里犯了错误以进行调试。
- en: Through TensorFlow 1.*x*, lazy execution was the way to build and train an ML
    model. Starting with TensorFlow 2, however, *eager execution* is the default way
    to build and train a model. This change makes it much easier to debug the code
    and try different model architectures. Eager execution also makes it much easier
    to learn TensorFlow, in that you will see any mistakes immediately upon executing
    each line of code. You no longer need to build an entire graph of your model before
    you can debug and test whether your input data is in the right shape. This is
    one of several major features and improvements that make TensorFlow 2 easier to
    use than previous versions.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过TensorFlow 1.*x*，惰性执行是构建和训练ML模型的方式。然而，从TensorFlow 2开始，*急切执行*是构建和训练模型的默认方式。这种改变使得调试代码和尝试不同的模型架构变得更加容易。急切执行还使得学习TensorFlow变得更加容易，因为您将立即在执行每行代码时看到任何错误。您不再需要在调试和测试输入数据是否具有正确形状之前构建整个模型图。这是使TensorFlow
    2比以前版本更易于使用的几个主要功能和改进之一。
- en: Keras API
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Keras API
- en: Keras, created by AI researcher François Chollet, is an open source, high-level,
    deep-learning API or framework. It is compatible with multiple ML libraries.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Keras是由AI研究员François Chollet创建的开源、高级、深度学习API或框架。它与多个ML库兼容。
- en: '*High-level* implies that at a lower level there is another framework that
    actually executes the computation—and this is indeed the case. These low-level
    frameworks include TensorFlow, Theano, and the Microsoft Cognitive Toolkit (CNTK).
    The purpose of Keras is to provide easier syntax and coding style for users who
    want to leverage the low-level frameworks to build deep-learning models.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*高级*意味着在更低级别上有另一个实际执行计算的框架，事实上确实如此。这些低级框架包括TensorFlow、Theano和Microsoft认知工具包（CNTK）。Keras的目的是为那些想要利用低级框架构建深度学习模型的用户提供更简单的语法和编码风格。'
- en: After Chollet joined Google in 2015, Keras gradually became a keystone of TensorFlow
    adoption. In 2019, as the TensorFlow team launched version 2.0, it formally adopted
    Keras as TensorFlow’s first-class citizen API, known as `tf.keras`, for all future
    releases. Since then, TensorFlow has integrated `tf.keras` with many other important
    modules. For example, it works seamlessly with the `tf.io` API for reading distributed
    training data. It also works with the `tf.data.Dataset` class, used for streaming
    training data too big to fit into a single computer. This book uses these modules
    throughout all chapters.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 2015年，Chollet加入Google后，Keras逐渐成为TensorFlow采用的基石。2019年，随着TensorFlow团队推出2.0版本，正式采用了Keras作为TensorFlow的一流API，即`tf.keras`，用于所有未来版本。从那时起，TensorFlow已经将`tf.keras`与许多其他重要模块集成在一起。例如，它与`tf.io`
    API无缝配合，用于读取分布式训练数据。它还与`tf.data.Dataset`类一起工作，用于流式传输训练数据，这些数据太大，无法容纳在一台计算机中。本书在所有章节中都使用这些模块。
- en: Today TensorFlow users primarily rely on the `tf.keras` API for building deep
    models quickly and easily. The convenience of getting the training routine working
    quickly allows more time to experiment with different model architectures and
    tuning parameters in the model and training routine.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，TensorFlow用户主要依赖`tf.keras` API来快速轻松地构建深度模型。快速获得训练例程的便利性使得更多时间可以用来尝试不同的模型架构和调整模型和训练例程中的参数。
- en: Reusable Models in TensorFlow
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow中的可重用模型
- en: Academic researchers have built and tested many ML models, all of which tend
    to be complicated in their architecture. It is not practical for users to learn
    how to build these models. Enter the idea of *transfer learning*, where a model
    developed for one task is reused to solve another task, in this case one defined
    by the user. This essentially boils down to transforming user data into the proper
    data structure at model input and output.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 学术研究人员已经构建和测试了许多ML模型，所有这些模型在其架构上都很复杂。用户学习如何构建这些模型并不现实。这就引入了*迁移学习*的概念，其中为一个任务开发的模型被重用来解决另一个任务，即用户定义的任务。这基本上归结为将用户数据转换为适当的数据结构，以便模型输入和输出。
- en: Naturally, there has been great interest in these models and their potential
    uses. Therefore, by popular demand, many models have become available in the open
    source ecosystem. TensorFlow created a repository, TensorFlow Hub, to offer the
    public free access to these complicated models. If you’re interested, you can
    try these models without having to build them yourself. In [Chapter 4](ch04.xhtml#reusable_model_elements),
    you will learn how to download and use models from TensorFlow Hub. Once you do,
    you’ll just need to be aware of the data structure the model expects at input,
    and add a final output layer that is suitable for your prediction goal. Every
    model in TensorFlow Hub contains concise documentation that gives you the necessary
    information to construct your input data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，这些模型及其潜在用途引起了极大的兴趣。因此，应大众需求，许多模型已经在开源生态系统中可用。TensorFlow创建了一个仓库，TensorFlow
    Hub，向公众提供这些复杂模型的免费访问。如果您感兴趣，您可以尝试这些模型，而无需自己构建它们。在[第4章](ch04.xhtml#reusable_model_elements)中，您将学习如何从TensorFlow
    Hub下载和使用模型。一旦您这样做了，您只需要了解模型在输入时期望的数据结构，并添加一个适合您预测目标的最终输出层。TensorFlow Hub中的每个模型都包含简洁的文档，为您提供构建输入数据所需的信息。
- en: Another place to retrieve prebuilt models is the `tf.keras.applications` module,
    which is part of the TensorFlow distribution. In [Chapter 4](ch04.xhtml#reusable_model_elements),
    you’ll learn how to use this module to leverage a prebuilt model for your own
    data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个获取预构建模型的地方是`tf.keras.applications`模块，它是TensorFlow分发的一部分。在[第4章](ch04.xhtml#reusable_model_elements)中，您将学习如何使用此模块来利用预构建模型处理您自己的数据。
- en: Making Commonly Used Operations Easy
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使常用操作变得简单
- en: All of these improvements in TensorFlow 2 make a lot of important operations
    easier and more convenient to implement. Even so, building and training an ML
    model end to end is not a trivial task. This book will show you how to deal with
    each aspect of the TensorFlow 2 model training process, starting from the beginning.
    Following are some of these operations.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 2中的所有这些改进使得许多重要操作更容易实现。即便如此，从头到尾构建和训练一个ML模型并不是一项简单的任务。本书将向您展示如何处理TensorFlow
    2模型训练过程的每个方面，从一开始。以下是其中一些操作。
- en: Open Source Data
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开源数据
- en: A convenient package integrated into TensorFlow 2 is the [TensorFlow dataset
    library](https://oreil.ly/0nt9T). It is a collection of curated open source datasets
    that are readily available for use. This library contains datasets of images,
    text, audio, videos, and many other formats. Some are NumPy arrays, while others
    are in dataset structures. This library also provides documentation for how to
    use TensorFlow to load these datasets. By distributing a wide variety of open
    source data with its product, the TensorFlow team really saves users a lot of
    the trouble of searching for, integrating, and reshaping training data for a TensorFlow
    workload. Some of the open source datasets we’ll use in this book are the [*Titanic*
    dataset](https://oreil.ly/GWCN1) for structured data classification and the [CIFAR-10
    dataset](https://oreil.ly/uwQUm) for image classification.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 集成到TensorFlow 2中的一个方便的包是[TensorFlow数据集库](https://oreil.ly/0nt9T)。这是一个由精心策划的开源数据集组成的集合，可供使用。该库包含图像、文本、音频、视频等多种格式的数据集。有些是NumPy数组，而其他的是数据集结构。该库还提供了如何使用TensorFlow加载这些数据集的文档。通过在其产品中分发各种开源数据集，TensorFlow团队真正为用户节省了搜索、集成和重塑训练数据以适应TensorFlow工作负载的麻烦。本书中将使用的一些开源数据集是用于结构化数据分类的[*泰坦尼克*数据集](https://oreil.ly/GWCN1)和用于图像分类的[CIFAR-10数据集](https://oreil.ly/uwQUm)。
- en: Working with Distributed Datasets
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理分布式数据集
- en: First you have to deal with the question of how to work with training data.
    Many didactic examples teach TensorFlow using prebuilt training data in its native
    format, such as a small pandas DataFrame or a NumPy array, which will fit nicely
    in your computer’s memory. In a more realistic situation, however, you’ll likely
    have to deal with much more training data than your computer memory can handle.
    The size of a table read from a SQL database can easily reach into the gigabytes.
    Even if you have enough memory to load it into a pandas DataFrame or a NumPy array,
    chances are your Python runtime will run out of memory during computation and
    crash.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您必须处理如何处理训练数据的问题。许多教学示例使用TensorFlow中的预构建训练数据，以其原生格式，例如小型pandas DataFrame或NumPy数组，这些数据可以很好地适应计算机的内存。然而，在更现实的情况下，您可能需要处理比计算机内存更多的训练数据。从SQL数据库读取的表的大小很容易达到几十亿字节。即使您有足够的内存将其加载到pandas
    DataFrame或NumPy数组中，您的Python运行时在计算过程中可能会耗尽内存并崩溃。
- en: Large tables of data are typically saved as multiple files in common formats
    such as CSV (comma-separated value) or text. Because of this, you should not attempt
    to load each file in your Python runtime. The correct way to deal with distributed
    datasets is to create a reference that points to the location of *all* the files.
    [Chapter 2](ch02.xhtml#data_storage_and_ingestion) will show you how to use the
    `tf.io` API, which gives you an object that holds a list of file paths and names.
    This is the preferred way to deal with training data regardless of its size and
    file count.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通常将大量数据保存为多个文件，常见格式为CSV（逗号分隔值）或文本。因此，您不应尝试在Python运行时加载每个文件。处理分布式数据集的正确方法是创建一个引用，指向*所有*文件的位置。[第2章](ch02.xhtml#data_storage_and_ingestion)将向您展示如何使用`tf.io`
    API，该API提供一个包含文件路径和名称列表的对象。无论数据大小和文件数量如何，这都是处理训练数据的首选方式。
- en: Data Streaming
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据流式传输
- en: How do you intend to pass data to your model for training? This is an important
    skill, but many popular didactic examples approach it by passing the entire NumPy
    array into the model training routine. Just like with loading large training data,
    you will encounter memory issues if you try passing a large NumPy array to your
    model for training.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 您打算如何将数据传递给模型进行训练？这是一个重要的技能，但许多流行的教学示例通过将整个NumPy数组传递到模型训练例程中来处理。就像加载大型训练数据一样，如果尝试将大型NumPy数组传递给模型进行训练，您将遇到内存问题。
- en: A better way to deal with this is through *data streaming*. Instead of passing
    the entire training data at once, you stream a subset or batch of data for the
    model to train with. In TensorFlow, this is known as your *dataset*. In [Chapter 2](ch02.xhtml#data_storage_and_ingestion),
    you are also going to learn how to make a dataset from the `tf.io` object. Dataset
    objects can be made from all sorts of native data structures. In [Chapter 3](ch03.xhtml#data_preprocessing),
    you will see how to make a `tf.data.Dataset` object from CSV files and images.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的处理方式是通过*数据流*。不是一次性传递整个训练数据，而是为模型训练提供一个子集或批量数据进行流式传输。在TensorFlow中，这被称为您的*数据集*。在[第2章](ch02.xhtml#data_storage_and_ingestion)中，您还将学习如何从`tf.io`对象创建数据集。数据集对象可以从各种本地数据结构创建。在[第3章](ch03.xhtml#data_preprocessing)中，您将看到如何从CSV文件和图像创建`tf.data.Dataset`对象。
- en: With the combination of `tf.io` and `tf.data.Dataset`, you’ll set up a data
    handling workflow for model training without having to read or open a single data
    file in your Python runtime memory.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`tf.io`和`tf.data.Dataset`的组合，您将为模型训练设置一个数据处理工作流程，而无需在Python运行时内存中读取或打开任何数据文件。
- en: Data Engineering
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据工程
- en: To make meaningful features for your model to learn the pattern of, you need
    to apply data- or feature-engineering tasks to your training data. Depending on
    the data type, there are different ways to do this.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使模型能够学习模式，您需要对训练数据应用数据或特征工程任务。根据数据类型，有不同的方法可以做到这一点。
- en: If you are working with tabular data, you may have different values or data
    types in different columns. In [Chapter 3](ch03.xhtml#data_preprocessing), you
    will see how to use TensorFlow’s `feature_column` API to standardize your training
    data. It helps you correctly mark which columns are numeric and which are categorical.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在处理表格数据，可能在不同列中有不同的值或数据类型。在[第3章](ch03.xhtml#data_preprocessing)中，您将看到如何使用TensorFlow的`feature_column`
    API对训练数据进行标准化。它可以帮助您正确标记哪些列是数值列，哪些是分类列。
- en: For image data, you will have different tasks. For example, all of the images
    in your dataset must have the same dimensions. Further, pixel values are typically
    normalized or scaled to a range of [0, 1]. For these tasks, `tf.keras` provides
    the `ImageDataGenerator` class, which standardizes image sizes and normalizes
    pixel values for you.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像数据，您将有不同的任务。例如，数据集中的所有图像必须具有相同的尺寸。此外，像素值通常被归一化或缩放到[0, 1]范围。对于这些任务，`tf.keras`提供了`ImageDataGenerator`类，用于标准化图像尺寸并为您归一化像素值。
- en: Transfer Learning
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习
- en: TensorFlow Hub makes prebuilt, open source models available to everyone. In
    [Chapter 4](ch04.xhtml#reusable_model_elements), you’ll learn how to use the Keras
    layers API to access TensorFlow Hub. In addition, `tf.keras` comes with an inventory
    of these prebuilt models, which can be called using the `tf.keras.applications`
    module. In [Chapter 4](ch04.xhtml#reusable_model_elements), you’ll learn how to
    use this module for transfer learning as well.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Hub为所有人提供了预构建的开源模型。在[第4章](ch04.xhtml#reusable_model_elements)中，您将学习如何使用Keras层API访问TensorFlow
    Hub。此外，`tf.keras`附带了这些预构建模型的清单，可以使用`tf.keras.applications`模块调用。在[第4章](ch04.xhtml#reusable_model_elements)中，您将学习如何使用此模块进行迁移学习。
- en: Model Styles
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型风格
- en: There is definitely more than one way you can implement a model using `tf.keras.`
    This is because some deep learning model architectures or patterns are more complicated
    than others. For common use, the *symbolic API* style, which sets up your model
    architecture sequentially, is likely to suffice. Another style is *imperative
    API*, where you declare a model as a class, so that each time you call upon a
    model object, you are creating an instance of that class. This requires you to
    understand how class inheritance works (I’ll discuss this in [Chapter 6](ch06.xhtml#model_creation_styles)).
    If your programming background stems from an object-oriented programming language
    such as C++ or Java, then this API may have a more natural feel for you. Another
    reason for using the imperative API approach is to keep your model architecture
    code separate from the remaining workflow. In [Chapter 6](ch06.xhtml#model_creation_styles),
    you will learn how to set up and use both of these API styles.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`tf.keras`可以以多种方式实现模型。这是因为一些深度学习模型架构或模式比其他更复杂。对于常见用途，*符号API*风格，按顺序设置模型架构，可能足够了。另一种风格是*命令式API*，其中您将模型声明为一个类，因此每次调用模型对象时，都会创建该类的一个实例。这要求您了解类继承的工作原理（我将在[第6章](ch06.xhtml#model_creation_styles)中讨论）。如果您的编程背景源自面向对象的编程语言，如C++或Java，那么这个API可能对您更自然。使用命令式API方法的另一个原因是将模型架构代码与其余工作流程分开。在[第6章](ch06.xhtml#model_creation_styles)中，您将学习如何设置和使用这两种API风格。
- en: Monitoring the Training Process
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控训练过程
- en: Monitoring how your model is trained and validated across each *epoch* (that
    is, one pass over a training set) is an important aspect of model training. Having
    a validation step at the end of each epoch is the easiest thing you can do to
    guard against *model overfitting*, a phenomenon in which the model starts to memorize
    training data patterns rather than learning the features as intended. In [Chapter 7](ch07.xhtml#monitoring_the_training_process-id00010),
    you will learn how to use various *callbacks* to save model weights and biases
    at every epoch. I’ll also walk you through how to set up and use TensorBoard to
    visualize the training process.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 监控您的模型在每个*epoch*（即一次通过训练集）中是如何训练和验证的是模型训练的一个重要方面。在每个epoch结束时进行验证步骤是您可以采取的最简单的措施，以防止*模型过拟合*，这是一种现象，模型开始记忆训练数据模式而不是按预期学习特征。在[第7章](ch07.xhtml#monitoring_the_training_process-id00010)中，您将学习如何使用各种*回调*来保存每个epoch的模型权重和偏差。我还将指导您如何设置和使用TensorBoard来可视化训练过程。
- en: Distributed Training
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式训练
- en: Even though you know how to handle distributed data and files and stream them
    into your model training routine, what if you find that training takes an unrealistic
    amount of time? This  is  where  *distributed  training* can  help.  It  requires 
    a  cluster  of hardware accelerators, such as graphics processing units (GPUs)
    or Tensor Processing Units (TPUs). These accelerators are available through many
    public cloud providers. You can also work with one GPU or TPU (not a cluster)
    for free in Google Colab; you’ll learn how to use this and the `tf.distribute.MirroredStrategy`
    class, which simplifies and reduces the hard work of setting up distributed training,
    to work through the example in the first part of [Chapter 8](ch08.xhtml#distributed_training-id00013).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您知道如何处理分布式数据和文件并将其流式传输到模型训练例程中，但如果发现训练需要不切实际的时间呢？这就是*分布式训练*可以帮助的地方。它需要一组硬件加速器，例如图形处理单元（GPU）或张量处理单元（TPU）。这些加速器可以通过许多公共云提供商获得。您还可以在Google
    Colab中免费使用一个GPU或TPU（而不是集群）；您将学习如何使用`tf.distribute.MirroredStrategy`类，简化和减少设置分布式训练的繁重工作，在[第8章](ch08.xhtml#distributed_training-id00013)的第一部分示例中进行操作。
- en: Released before `tf.distribute.MirroredStrategy`, the Horovod API from Uber’s
    engineering team is a considerably more complicated alternative. It’s specifically
    built to run training routines on a computing cluster. To learn how to use Horovod,
    you will need to use Databricks, a cloud-based computing platform, to work through
    the example in the second part of [Chapter 8](ch08.xhtml#distributed_training-id00013).
    This will help you learn how to refactor your code to distribute and shard data
    for the Horovod API.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在`tf.distribute.MirroredStrategy`之前发布的Horovod API来自Uber工程团队，是一个相对复杂的替代方案。它专门用于在计算集群上运行训练例程。要学习如何使用Horovod，您需要使用基于云的计算平台Databricks，在[第8章](ch08.xhtml#distributed_training-id00013)的第二部分示例中进行操作。这将帮助您学习如何重构您的代码以分发和分片数据以供Horovod
    API使用。
- en: Serving Your TensorFlow Model
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为您的TensorFlow模型提供服务
- en: Once you’ve built your model and trained it successfully, it’s time for you
    to persist, or store, the model so it can be served to handle user input. You’ll
    see how easy it is to use the `tf.saved_model` API to save your model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您构建了模型并成功训练了它，现在是时候将模型持久化或存储起来，以便可以提供给处理用户输入。您将看到使用`tf.saved_model` API保存您的模型是多么容易。
- en: 'Typically, the model is hosted by a web service. This is where TensorFlow Serving
    comes into the picture: it’s a framework that wraps your model and exposes it
    for web service calls via HTTP. In [Chapter 9](ch09.xhtml#serving_tensorflow_models),
    you will learn how to use a TensorFlow Serving Docker image to host your model.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，模型由Web服务托管。这就是TensorFlow Serving出现的地方：它是一个框架，包装您的模型并通过HTTP公开为Web服务调用。在[第9章](ch09.xhtml#serving_tensorflow_models)中，您将学习如何使用TensorFlow
    Serving Docker镜像来托管您的模型。
- en: Improving the Training Experience
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 改进培训体验
- en: Finally, [Chapter 10](ch10.xhtml#improving_the_modeling_experiencecolon_f) discusses
    some important aspects of assessing and improving your model training process.
    You’ll learn how to use the TensorFlow Model Analysis module to look into the
    issue of model bias. This module provides an interactive dashboard, called Fairness
    Indicators, designed to reveal model bias. Using a Jupyter Notebook environment
    and the model you trained on the *Titanic* dataset from [Chapter 3](ch03.xhtml#data_preprocessing),
    you’ll see how Fairness Indicators works.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，[第10章](ch10.xhtml#improving_the_modeling_experiencecolon_f)讨论了评估和改进模型训练过程的一些重要方面。您将学习如何使用TensorFlow模型分析模块来查看模型偏差的问题。该模块提供了一个交互式仪表板，称为公平性指标，旨在揭示模型偏差。使用Jupyter
    Notebook环境和您在[第3章](ch03.xhtml#data_preprocessing)中训练的*泰坦尼克号*数据集上的模型，您将看到公平性指标是如何工作的。
- en: Another improvement brought about by the `tf.keras` API is that it makes performing
    hyperparameter tuning more convenient. *Hyperparameters* are attributes related
    to model training routines or model architectures. Tuning them is typically a
    tedious process, as it involves thoroughly searching over the parameter space.
    In [Chapter 10](ch10.xhtml#improving_the_modeling_experiencecolon_f) you’ll see
    how to use the Keras Tuner library and an advanced search algorithm known as Hyperband
    to conduct hyperparameter tuning work.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.keras` API带来的另一个改进是使超参数调整更加方便。*超参数*是与模型训练例程或模型架构相关的属性。调整它们通常是一个繁琐的过程，因为它涉及彻底搜索参数空间。在[第10章](ch10.xhtml#improving_the_modeling_experiencecolon_f)中，您将看到如何使用Keras
    Tuner库和一个称为Hyperband的高级搜索算法来进行超参数调整工作。'
- en: Wrapping Up
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: TensorFlow 2 is a major overhaul of the previous version. Its most significant
    improvement is designating the `tf.keras` API as the recommended way to use TensorFlow.
    This API works seamlessly with `tf.io` and `tf.data.Dataset` for an end-to-end
    model training process. These improvements speed up model building and debugging
    so you can experiment with other aspects of model training, such as trying different
    architectures or conducting more efficient hyperparameter searches. So, let’s
    get started.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 2是对以前版本的重大改进。其最重要的改进是将`tf.keras` API指定为使用TensorFlow的推荐方式。这个API与`tf.io`和`tf.data.Dataset`无缝配合，用于端到端的模型训练过程。这些改进加快了模型构建和调试的速度，因此您可以尝试模型训练的其他方面，比如尝试不同的架构或进行更有效的超参数搜索。所以，让我们开始吧。
