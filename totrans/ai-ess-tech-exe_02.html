<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 2. The #1 Mistake Companies Make with AI"><div class="chapter" id="id24">
<h1><span class="label">Chapter 2. </span>The #1 Mistake Companies <span class="keep-together">Make with AI</span></h1>

<p>One of the first questions I ask tech leaders is how they plan to
improve AI reliability, performance, or user satisfaction. If the answer
is “We just bought XYZ tool for that, so we’re good,” I know they’re
headed for trouble. Focusing on tools over processes is a red flag and
the biggest mistake I see executives make when it comes to AI.</p>


<section data-type="sect1" data-pdf-bookmark="Improvement Requires Process"><div class="sect1" id="id39">
<h1>Improvement Requires Process</h1>
<p>Assuming that buying a tool will solve your AI problems is like
joining a gym but not actually going. You’re not going to see
improvement by just throwing money at the problem. Tools are only the
first step; the real work comes after. For example, the metrics that
come built-in to many tools rarely correlate with what you actually care
about. Instead, you need to design metrics that are specific to your
business, along with tests to evaluate your AI’s performance.</p>
<p>The data you get from these tests should also be reviewed regularly
to make sure you’re on track. No matter what area of AI you’re working
on—model evaluation, retrieval-augmented generation (RAG), or prompting strategies—the process is what
matters most. Of course, there’s more to making improvements than just
relying on tools and metrics. You also need to develop and follow
processes.</p>
</div></section>


<section data-type="sect1" data-pdf-bookmark="Rechat’s Success Story"><div class="sect1" id="id40">
<h1>Rechat’s Success Story</h1>
<p>Rechat is a great example of how focusing on processes can lead to
real improvements. The company decided to build an AI agent for real
estate agents to help with a large variety of tasks related to
different aspects of the job. However, they were struggling with
consistency. When the agent worked, it was great, but when it didn’t, it
was a disaster. The team would make a change to address a failure mode
in one place but end up causing issues in other areas. They were stuck
in a cycle of whack-a-mole. They didn’t have visibility into their AI’s
performance beyond “vibe checks,” and their prompts were becoming
increasingly unwieldy.</p>
<p>When I came in to help, the first thing I did was apply a systematic
approach that is illustrated in <a data-type="xref" href="#fig0201">Figure 2-1</a>.</p>

<figure><div id="fig0201" class="figure">
<img src="assets/aete_02in01.png" width="1252" height="688"/>
<h6><span class="label">Figure 2-1. </span>The virtuous cycle<sup><a data-type="noteref" id="id131-marker" href="ch02.html#id131">1</a></sup></h6>
</div></figure>


<p>This is a virtuous cycle for systematically improving large language models (LLMs). The key
insight is that you need both quantitative and qualitative feedback
loops that are <em>fast</em>. You start with LLM invocations (both synthetic and
human-generated), then <span class="keep-together">simultaneously</span>:</p>
<ul class="pagebreak-before">
<li>Run unit tests to catch regressions and verify expected
<span class="keep-together">behaviors.</span></li>
<li>Collect detailed logging traces to understand model behavior.</li>
</ul>
<p>These feed into evaluation and curation (which needs to be
increasingly automated over time). The eval process combines:</p>
<ul>
<li>Human review</li>
<li>Model-based evaluation</li>
<li>A/B testing</li>
</ul>
<p>The results then inform two parallel streams:</p>
<ul>
<li>Fine-tuning with carefully curated data</li>
<li>Prompt engineering improvements</li>
</ul>

<p>These both feed into model improvements, which starts the cycle
again. The dashed line around the edge emphasizes this as a continuous,
iterative process—you keep cycling through faster and faster to drive
continuous improvement. By focusing on the processes outlined in this
diagram, Rechat was able to reduce its error rate by over
50% without investing in new tools!</p>

<p>Check out this <a href="https://oreil.ly/M8KW2">~15-minute video</a> on how we implemented this
process-first approach at Rechat.</p>

</div></section>

<section data-type="sect1" data-pdf-bookmark="Avoid the Red Flags"><div class="sect1" id="id41">
<h1>Avoid the Red Flags</h1>
<p>Instead of asking which tools you should invest in, you should be
asking your team:</p>
<ul>
<li>What are our failure rates for different features or use cases?</li>
<li>What categories of errors are we seeing?</li>
<li>Does the AI have the proper context to help users? How is this being
measured?</li>
<li>What is the impact of recent changes to the AI?</li>
</ul>
<p>The answers to each of these questions should involve appropriate
metrics and a systematic process for measuring, reviewing, and
improving them. If your team struggles to answer these questions
<em>with data and metrics</em>, you are in danger of going off
the rails!</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Avoiding Jargon Is Critical"><div class="sect1" id="id42">
<h1>Avoiding Jargon Is Critical</h1>
<p>We’ve talked about why focusing on processes is better than just
buying tools. But there’s one more thing that’s just as important: how
we talk about AI. Using the wrong words can hide real problems and slow
down progress. To focus on processes, we need to use clear language and
ask good questions. That’s why we provide an AI communication cheat sheet for executives in <a data-type="xref" href="ch03.html#ch_glossary">Chapter 3</a>. That chapter helps you:</p>
<ul>
<li>Understand what AI can and can’t do</li>
<li>Ask questions that lead to real improvements</li>
<li>Ensure that everyone on your team can participate</li>
</ul>
<p>Using this cheat sheet will help you talk about processes, not just
tools. It’s not about knowing every tech word. It’s about asking the
right questions to understand how well your AI is working and how to
make it better.</p>

</div></section>


<div data-type="footnotes"><p data-type="footnote" id="id131"><sup><a href="ch02.html#id131-marker">1</a></sup> Diagram adapted from my blog post, <a href="https://hamel.dev/blog/posts/evals">“Your AI Product Needs Evals”</a>.</p></div></div></section></div>
</div>
</body></html>