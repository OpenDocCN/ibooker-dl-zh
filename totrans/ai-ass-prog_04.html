<html><head></head><body><section data-pdf-bookmark="Chapter 3. Prompt Engineering" data-type="chapter" epub:type="chapter"><div class="chapter" id="prompt_engineering">
<h1><span class="label">Chapter 3. </span>Prompt Engineering</h1>
<p><em>Prompt engineering</em> is a subfield<a contenteditable="false" data-primary="prompt engineering" data-type="indexterm" id="xi_promptengineering.03.3.45"/> of machine learning and <em>natural language processing</em>, which is the study of enabling computers to understand and interpret human language. The main goal is to figure out how to talk<a contenteditable="false" data-primary="large language models (LLMs)" data-secondary="prompt engineering as method to talk to" data-type="indexterm" id="id426"/> to <em>large language models</em>, sophisticated AI systems designed to process and generate human-like language responses, in just the right way so they generate the answer we’re looking for.</p>
<p>Think of it like this: You know how when you ask someone for advice, you’ve got to give them a bit of context and be clear about what you need? It’s like that with LLMs. You’ve got to craft your question or prompt carefully. Sometimes, you might even drop some hints or extra information in your question to make sure the LLM gets what you’re asking.</p>
<p>This is not just about asking one-off questions either. Sometimes it’s like having a whole conversation with the LLM, going back and forth, tweaking your questions until you get that golden nugget of information you need.</p>
<p>For instance, let’s say you’re using an AI-assisted programming tool to develop a web application. You start by asking how to create a simple user login system in JavaScript. The initial response might cover the basics, but then you realize you need more advanced features. So, you follow up with more specific prompts, asking about incorporating password encryption and connecting to a database securely. Each interaction with the AI hones its response, gradually shaping it to fit your project’s specific needs.</p>
<p>Keep in mind that prompt engineering has become a red-hot job category. According to data from <a href="https://oreil.ly/Qy9Zi">Willis Towers Watson</a>, the average yearly earnings of a prompt engineer hover around $130,000, though this figure might be on the conservative side. To lure top talent, companies often sweeten the deal by offering enticing equity packages and bonuses.</p>
<p>In this chapter, we’ll dive deep into the world of prompt engineering and unpack helpful strategies and tricks of the trade.</p>
<section data-pdf-bookmark="Art and Science" data-type="sect1"><div class="sect1" id="art_and_science">
<h1>Art and Science</h1>
<p>Prompt engineering<a contenteditable="false" data-primary="prompt engineering" data-secondary="art and science of" data-type="indexterm" id="id427"/> is a mix of art and science. On one hand, you’ve got to choose the right words and tone to get the AI to respond the way you want. It’s about guiding the conversation in a certain direction. It takes a bit of intuition and a creative touch to guide the conversation in a certain direction and refine your language, teasing out detailed and nuanced replies.</p>
<p>Yes, this can be tricky, especially for software developers. Normally, you follow a set of rules to write your code, and it either works or the compiler tells you what you did wrong. It’s logical and predictable.</p>
<p>But prompt engineering? Not so much. It’s more freeform and unpredictable.</p>
<p>Then again, there is also quite a bit of science to prompt engineering. You need to understand the nuts and bolts of how AI models work, as we discussed in <a data-type="xref" href="ch02.html#how_ai_coding_technology_works">Chapter 2</a>. Along with creativity, you need precision, predictability, and the ability to replicate your results. Often this means you’ve got to experiment, try out different prompts, analyze the results, and tweak things until you get the right response.</p>
<p>With prompt engineering, don’t expect to find any magic solutions that work every time. Sure, there are plenty of courses, videos, and books that claim to have all the “secrets” of prompt engineering. But take them with a grain of salt, or you might be disappointed.</p>
<p>Plus, the world of AI and machine learning is always changing, with new models and techniques popping up all the time. So, the idea of having one definitive technique for prompt engineering? That’s a moving target.</p>
</div></section>
<section data-pdf-bookmark="Challenges" data-type="sect1"><div class="sect1" id="challenges">
<h1>Challenges</h1>
<p>Prompt engineering<a contenteditable="false" data-primary="prompt engineering" data-secondary="challenges" data-type="indexterm" id="id428"/><a contenteditable="false" data-primary="prompt engineering" data-secondary="prompt components" data-type="indexterm" id="xi_promptengineeringpromptcomponents.03.20.22"/><a contenteditable="false" data-primary="large language models (LLMs)" data-secondary="challenges in prompt engineering" data-type="indexterm" id="id429"/> can be frustrating. Even the tiniest change in how you phrase your prompt can make a huge difference in what the LLM spits out. This is because of the advanced technology under the hood, which is based on probabilistic <span class="keep-together">frameworks</span>.</p>
<p>Here are some of the challenges with prompt engineering:</p>
<dl>
<dt>Wordiness</dt>
<dd><p>LLMs can be chatterboxes<a contenteditable="false" data-primary="wordiness challenge for LLMs" data-type="indexterm" id="id430"/>. Give them a prompt, and they might just run with it, giving you a wordy response when all you wanted was a quick answer. They have a tendency to throw in a bunch of related ideas or facts, making the response longer than necessary. If you’d like an LLM to get straight to the point, just ask it to be “concise.”</p></dd>
<dt>Non-transferability</dt>
<dd><p>This means that a prompt that works nicely with one LLM might not be as effective with another<a contenteditable="false" data-primary="non-transferability between LLMs" data-type="indexterm" id="id431"/>. In other words, if you’re switching from ChatGPT to Gemini or GitHub Copilot, you might need to tweak your prompts due to the unique training, design, and specialization of each LLM. Different models are trained on different datasets and algorithms, leading to distinct understandings and interpretations of prompts.</p></dd>
<dt>Length sensitivity</dt>
<dd><p>LLMs can get overwhelmed by long prompts<a contenteditable="false" data-primary="length sensitivity, LLM" data-type="indexterm" id="id432"/> and start to overlook or misinterpret parts of your input. It’s as if the LLM’s attention span falters and its responses become somewhat distracted. This is why you should avoid providing detailed requirements in your prompts; keep a prompt to less than a page.</p></dd>
<dt>Ambiguity</dt>
<dd><p>If your prompt is unclear<a contenteditable="false" data-primary="ambiguity issue for LLMs" data-type="indexterm" id="id433"/><a contenteditable="false" data-primary="large language models (LLMs)" data-secondary="ambiguity issue for" data-type="indexterm" id="id434"/>, the LLM might get confused and serve up responses that are way off base or just plain make-believe. Clarity is key.</p></dd>
</dl>
<p>Despite all this, there are ways to improve the results. And we’ll cover these approaches in the rest of this chapter.</p>
</div></section>
<section data-pdf-bookmark="The Prompt" data-type="sect1"><div class="sect1" id="the_prompt">
<h1>The Prompt</h1>
<p>You can think of a prompt as having four main components, which you can see in <a data-type="xref" href="#a_prompt_has_four_main_componentsdot">Figure 3-1</a>.</p>
<figure><div class="figure" id="a_prompt_has_four_main_componentsdot">
<img alt="" src="assets/aiap_0301.png"/>
<h6><span class="label">Figure 3-1. </span>A prompt has four main components</h6>
</div></figure>
<p>First, the <em>context</em> specifies the persona or role for the LLM to take when providing a response. Next, there are the <em>instructions</em>, such as to summarize, translate, or classify. Then there is the <em>input of content</em> if you want the LLM to process information to create a better response. Finally, you can show how you want the output <em>formatted</em>.</p>
<p>Keep in mind that you do not need all of these components. In fact, you might need just one to get a good response. But as a general rule, it’s better to provide the LLM with more concrete details.</p>
<p>Let’s now look at each of the components.</p>
</div></section>
<section data-pdf-bookmark="Context" data-type="sect1"><div class="sect1" id="context">
<h1>Context</h1>
<p>You’ll often begin your prompt with a sentence or two that provide context<a contenteditable="false" data-primary="context, prompt" data-type="indexterm" id="id435"/>. Often, you’ll specify the role or persona you want the AI to take on when providing the response. This leads to responses that are not only more accurate but also contextually relevant, ensuring a more meaningful result.</p>
<p>For instance, if you want to debug a piece of code, you might use this as the context:</p>
<blockquote>
<p><em>Prompt:</em> You are an experienced software engineer specializing in debugging Java applications.</p>
</blockquote>
<p>Or suppose you want to learn about optimization techniques for a particular algorithm. You could set the stage by stating:</p>
<blockquote>
<p><em>Prompt:</em> You are a senior software developer with expertise in algorithm optimization.</p>
</blockquote>
<p>Adding context helps the LLM approach your prompt with the right mindset.</p>
</div></section>
<section data-pdf-bookmark="Instructions" data-type="sect1"><div class="sect1" id="instructions">
<h1>Instructions</h1>
<p>Your prompt should include at least one clear instruction<a contenteditable="false" data-primary="instructions, prompt" data-type="indexterm" id="id436"/>. There’s nothing stopping you from adding more instructions, but you need to be careful. Loading up your prompt with a bunch of queries can throw the LLM for a loop and make it harder to get the answer you’re looking for.</p>
<p>Let’s break down why that happens. First off, when you have multiple instructions, things can get a bit fuzzy. If they’re not clear or if they seem to clash with each other, the LLM might get confused about which one to focus on or how to balance them all out.</p>
<p>Next, having more instructions means more for the LLM to juggle. It’s got to process and understand each part of your prompt and then figure out how to weave all the parts into a coherent response. That’s a lot of mental gymnastics, and sometimes it can lead to mistakes or answers that are off.</p>
<p>And don’t forget, LLMs go through instructions one at a time, in order. So, the way you line up those queries can influence how they’re interpreted and what kind of answer you get back.</p>
<p>Given all this, a pro tip is to keep it simple. Instead of throwing a whole list of questions at the LLM all at once, try breaking them down into a series of smaller prompts. It’s like having a back-and-forth chat instead of delivering a monologue.</p>
<p>There are also numerous types of instructions for a prompt. In the next few sections, we’ll discuss some of the main instructions used in software development.</p>
<section data-pdf-bookmark="Summarization" data-type="sect2"><div class="sect2" id="summarization">
<h2>Summarization</h2>
<p>Summarization<a contenteditable="false" data-primary="summarization prompts" data-type="indexterm" id="id437"/> can condense a longer piece of text into a shorter version while keeping the main ideas and points intact. This is useful for quickly getting a handle on lengthy documents. For a software developer, summarization can be an especially handy tool in the scenarios listed in <a data-type="xref" href="#summarization_prompts_for_coding_tasks">Table 3-1</a>.</p>
<table class="border" id="summarization_prompts_for_coding_tasks">
<caption><span class="label">Table 3-1. </span>Summarization prompts for coding tasks</caption>
<thead>
<tr>
<th>Use case</th>
<th>Description</th>
<th>Example prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td>Code documentation</td>
<td>Provides a concise overview of extensive documentation highlighting key functionalities, dependencies, and structures.</td>
<td>“Summarize the main points of the following documentation to provide a quick overview of the codebase.”</td>
</tr>
<tr>
<td>Bug reports</td>
<td>Quickly identifies the main issues reported by users in numerous or lengthy bug reports.</td>
<td>“Summarize the common issues reported in the following bug reports to identify the main problems to be addressed.”</td>
</tr>
<tr>
<td>Research papers</td>
<td>Extracts succinct insights from lengthy research papers or technical articles to update the user on the latest research or technologies.</td>
<td>“Provide a summary of the key findings and technologies discussed in the following research paper.”</td>
</tr>
<tr>
<td>Change logs</td>
<td>Enables an understanding of the key changes in a new version of a software library or tool from lengthy change logs.</td>
<td>“Summarize the key changes in the following change log of version 1.1.2.”</td>
</tr>
<tr>
<td>Email threads</td>
<td>Extracts the key points of discussions or decisions from long email threads.</td>
<td>“Summarize the main points of discussion from the following email thread.”</td>
</tr>
</tbody>
</table>
<p>Another type of summarization<a contenteditable="false" data-primary="topic modeling, prompt instructions" data-type="indexterm" id="id438"/> is <em>topic modeling</em>, in which a statistical model discovers the abstract “topics” that occur in a collection of documents. Here are some topic-modeling prompts for developers:</p>
<blockquote>
<p><em>Prompt:</em> Identify the main topics discussed in the following text: {text}</p>
<p><em>Prompt:</em> Extract the keywords from the following text to infer the main topics: {text}</p>
<p><em>Prompt:</em> Suggest tags for the following text based on its content: {text}</p>
</blockquote>
</div></section>
<section data-pdf-bookmark="Text Classification" data-type="sect2"><div class="sect2" id="text_classification">
<h2>Text Classification</h2>
<p><em>Text classification</em> involves giving a computer<a contenteditable="false" data-primary="text classification, prompt instructions" data-type="indexterm" id="id439"/> a bunch of text that it learns to tag with labels. A flavor<a contenteditable="false" data-primary="sentiment analysis" data-type="indexterm" id="id440"/> of this is <em>sentiment analysis</em>, such as when you have a list of social media posts and the LLM figures out which have a positive or negative connotation. For developers, sentiment analysis can be a useful tool to gauge user feedback about an application.</p>
<p>Some sample prompts include:</p>
<blockquote>
<p><em>Prompt:</em> Can you analyze these customer reviews and tell me if the sentiment is generally positive, negative, or neutral? {text}</p>
<p><em>Prompt:</em> Here’s a thread from our user forum discussing the latest update. Could you summarize the overall sentiment for me? {text}</p>
<p><em>Prompt:</em> I’ve compiled a list of feedback from our app store page. Can you categorize the comments by sentiment? {text}</p>
<p><em>Prompt:</em> Evaluate the sentiment of these blog post comments regarding our product announcement. What’s the consensus? {text}</p>
</blockquote>
</div></section>
<section data-pdf-bookmark="Recommendation" data-type="sect2"><div class="sect2" id="recommendation">
<h2>Recommendation</h2>
<p>You can instruct an LLM to provide recommendations<a contenteditable="false" data-primary="recommendations, prompt" data-type="indexterm" id="id441"/>. Developers can use such feedback to improve the caliber of responses for activities like squashing bugs, refining code, or using APIs more effectively.</p>
<p>Check out these example prompts you might use:</p>
<blockquote>
<p><em>Prompt:</em> The following code snippet is throwing a NullPointerException when I try to call &lt;<em>Method()</em>&gt;. Can you help identify the potential cause and suggest a fix?</p>
<p><em>Prompt:</em> Here is a function I wrote to sort a list of integers. Can you recommend any optimizations to make it run faster or be more readable?</p>
</blockquote>
<p>LLM recommendations can be a powerful accelerator for your work, greatly saving time and providing ideas you may not have thought about. This technique is particularly beneficial when dealing with intricate or nuanced tasks.</p>
<p>But there are downsides. One potential hitch is that the LLM might boil down the responses too much and miss the nuances. Also, keep in mind that the model’s knowledge is frozen at a certain point in time, so it might not be up-to-date with the latest information or trends.</p>
<p>If anything, recommendations are a way to kick things off. But you’ll want to dive in and do some more digging on your own to get the full picture.</p>
</div></section>
<section data-pdf-bookmark="Translation" data-type="sect2"><div class="sect2" id="translation">
<h2>Translation</h2>
<p><em>Localization</em> is essentially attuning the software<a contenteditable="false" data-primary="localization, prompt instructions" data-type="indexterm" id="id442"/><a contenteditable="false" data-primary="translation" data-secondary="localization prompt instructions" data-type="indexterm" id="id443"/> to the linguistic and cultural norms of a specific area. It allows your software to speak the local lingo and understand regional quirks, an ability that is key to broadening your market and cultivating a closer connection with your audience. This can lead to a ripple effect of benefits: users are happier because the software feels tailor-made for them, and happy users can mean a healthier bottom line for your business.</p>
<p>In competitive markets, localization can give you an edge when alternatives fall short or simply don’t exist. Plus, by aligning your software with the local ways, including compliance with regional regulations, you’re not just making your software one option but often the only option for a market.</p>
<p>On the flip side, localization is not without its challenges. It can be both expensive and time intensive. It requires meticulous quality assurance to maintain the software’s integrity in different languages. Additionally, software development doesn’t stand still. It’s a continuous cycle of updates and new features, each of which may require its own set of localization efforts. This ongoing process adds layers of complexity and additional costs to the project.</p>
<p>This is where LLMs can come to the rescue. Advanced systems are capable of translating between numerous languages. They can serve as a powerful tool in a developer’s toolkit. <a data-type="xref" href="#examples_of_prompts_for_language_transla">Table 3-2</a> shows some prompts you might use for localization.</p>
<table class="border" id="examples_of_prompts_for_language_transla">
<caption><span class="label">Table 3-2. </span>Examples of prompts for language translation</caption>
<thead>
<tr>
<th>Task type</th>
<th>Description</th>
<th>Sample prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td>UI text translation</td>
<td>Translates buttons, menu items, error messages, dialog boxes, etc.</td>
<td>“Translate the following UI text into French: Save, Exit, File, Edit, Help.”</td>
</tr>
<tr>
<td>Documentation translation</td>
<td>Translates user guides, help files, and other documentation.</td>
<td>“Translate the following user manual paragraph into Spanish.”</td>
</tr>
<tr>
<td>Error message translation</td>
<td>Translates error messages that the software might generate.</td>
<td>“Translate the following error messages into German: File not found, Access denied, Network connection lost.”</td>
</tr>
<tr>
<td>Tooltip translation</td>
<td>Translates tooltips that provide additional information when a user hovers over an item.</td>
<td>“Translate the following tooltips into Japanese: Click to save, Click to open a new file, Click to print.”</td>
</tr>
</tbody>
</table>
<p>Even so, it’s crucial to approach the multilingual capabilities of LLMs with a degree of caution. They aren’t foolproof. These models may sometimes miss the subtleties, idiomatic expressions, and cultural contexts unique to a language. The nuances of language are complex, and getting them right is about more than just direct translation—it’s about conveying the right meaning in the right way.</p>
<p>Handling specific terms or names can be tricky, especially when there isn’t a neat equivalent in another language. Then there’s the challenge of getting the tone and style right. It’s not just about the words but how you say them, and this can change a lot from one language or culture to the next.</p>
<p>Having a language specialist take a look at the output could save you some headaches down the line.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Input of Content" data-type="sect1"><div class="sect1" id="input_of_content">
<h1>Input of Content</h1>
<p>When crafting prompts, it’s helpful to use special symbols like <code>###</code> or <code>"""</code> to clearly separate your instructions<a contenteditable="false" data-primary="content versus instructions, prompts" data-type="indexterm" id="id444"/> from the content or information you want the LLM to work on. These symbols act like boundaries or markers, making it clear where the instructions end and where the content begins.</p>
<p>Consider a scenario in which a software developer needs help summarizing key points from a lengthy piece of documentation regarding a new API they are integrating. Here’s how you could structure the prompt:</p>
<blockquote>
<p><em>Prompt:</em> Extract the key implementation steps for the API from the text below:</p>
<p>Documentation: <code>"""</code></p>
<p>{API documentation text here}</p>
<p><code>"""</code></p>
</blockquote>
<p>Using the <code>"""</code> delimiters is a neat way to split the instruction from the API documentation text. It gives the LLM a clearer picture of what needs to be done and increases the chances of getting a crisp summary of the main steps. Plus, these delimiters tidy up the prompt, making it easier to read, which is a real lifesaver for longer or more complex text inputs.</p>
</div></section>
<section data-pdf-bookmark="Format" data-type="sect1"><div class="sect1" id="format">
<h1>Format</h1>
<p>In your prompt<a contenteditable="false" data-primary="formatting of prompt output, instructing on" data-type="indexterm" id="id445"/>, you can tell the LLM how to format the output. Here’s an example:</p>
<blockquote>
<p><em>Prompt:</em> Create a Python function that takes a list of user objects (each object containing a user’s ID and name) and returns a JSON object that maps user IDs to names. Format the output as JSON.</p>
<p><em>ChatGPT:</em></p>
<pre data-type="programlisting">{
    "code": "def map_user_ids_to_names(users):\n    
      user_map = {user['id']: user['name'] for user in users}\n
      return user_map",
    "example_usage": {
        "input": [
            {"id": 1, "name": "Alice"},
            {"id": 2, "name": "Bob"},
            {"id": 3, "name": "Charlie"}
        ],
        "output": {
            "1": "Alice",
            "2": "Bob",
            "3": "Charlie"
        }
    }
}</pre>
</blockquote>
<p>There are other ways you can format the output. <a data-type="xref" href="#prompts_for_formatting_output">Table 3-3</a> shows some options.</p>
<table class="border" id="prompts_for_formatting_output">
<caption><span class="label">Table 3-3. </span>Prompts for formatting output</caption>
<thead>
<tr>
<th>Format type</th>
<th>Sample prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td>Table</td>
<td>“Create a table comparing the syntax, performance, and use cases of Python, Java, and C++.”</td>
</tr>
<tr>
<td>List</td>
<td>“List the steps to troubleshoot a slow-loading web page.”</td>
</tr>
<tr>
<td>Markdown/HTML</td>
<td>“Explain the differences between GET and POST HTTP methods in Markdown.”</td>
</tr>
<tr>
<td>Text hierarchy</td>
<td>“Provide a structured outline of the software development life cycle (SDLC), including its phases and key activities in each phase.”</td>
</tr>
<tr>
<td>LaTeX formatting</td>
<td>“Express the time complexity of the binary search algorithm in LaTeX notation.”</td>
</tr>
</tbody>
</table>
<p>With a prompt, you can also specify the length of the response. You could guide the LLM with an instruction such as “Provide a brief summary” or “Write a detailed explanation.” Or you could be more specific, such as by saying that the response should be no more than 300 words. The LLM may exceed the word limit you provide, but it will at least be in the general vicinity<a contenteditable="false" data-primary="" data-startref="xi_promptengineeringpromptcomponents.03.20.22" data-type="indexterm" id="id446"/>.</p>
</div></section>
<section data-pdf-bookmark="Best Practices" data-type="sect1"><div class="sect1" id="best_practices">
<h1>Best Practices</h1>
<p>We’ll next take a look at some of the best practices<a contenteditable="false" data-primary="prompt engineering" data-secondary="best practices" data-type="indexterm" id="xi_promptengineeringbestpractices.03.251.56"/> for cooking up prompts that will help get the answers you want. But don’t take these as gospel. These suggestions are more like general advice—which can be somewhat subjective—than hard-and-fast rules. As you spend more time chatting with LLMs, you’ll probably stumble upon your own helpful ways of asking questions that work for you. It’s all part of the journey of prompt engineering.</p>
<section data-pdf-bookmark="Be Specific" data-type="sect2"><div class="sect2" id="be_specific">
<h2>Be Specific</h2>
<p>Crafting the right prompts<a contenteditable="false" data-primary="specificity in prompts" data-type="indexterm" id="id447"/> can be like finding the sweet spot in a good conversation, and it’s maybe the most crucial step to hitting it off with these text-generating systems. The more details, the better. You also need to be clear. Otherwise, the LLM may make assumptions or even hallucinate.</p>
<p class="pagebreak-before">First, let’s take a look at some prompts that are too vague.</p>
<blockquote>
<p><em>Prompt:</em> Develop a feature to enhance data security.</p>
<p><em>Prompt:</em> Can you build a tool to automate the process?</p>
<p><em>Prompt:</em> Optimize the code.</p>
<p><em>Prompt:</em> We need a function to process transactions.</p>
</blockquote>
<p>The following are much more detailed and should get better results:</p>
<blockquote>
<p><em>Prompt:</em> Develop a Python function to parse dates from strings. The function should be able to handle the formats YYYY-MM-DD, MM/DD/YYYY, and Month DD, YYYY. It should return a datetime object. Provide a script that demonstrates the function handling at least three examples of each format correctly, along with a document explaining any dependencies, the logic used in the function, and instructions on how to run the script.</p>
<p><em>Prompt:</em> Develop a SQL query to retrieve from our database a list of customers who made purchases above $500 in the last quarter of 2023. The query should return the customer’s full name, their email address, the total amount spent, and the date of their last purchase. The results should be sorted by the total amount spent in descending order. Please ensure that the query is optimized for performance.</p>
</blockquote>
</div></section>
<section data-pdf-bookmark="Acronyms and Technical Terms" data-type="sect2"><div class="sect2" id="acronyms_and_technical_terms">
<h2>Acronyms and Technical Terms</h2>
<p>It’s crucial to be clear with technical terms and acronyms<a contenteditable="false" data-primary="acronyms in prompts" data-type="indexterm" id="id448"/><a contenteditable="false" data-primary="technical terms in prompts" data-type="indexterm" id="id449"/> while drafting a prompt. This jargon often means different things in different contexts and can lead to unhelpful responses. Thus, it’s a good idea to spell out acronyms and give clear definitions or explanations of any technical terms used.</p>
<p>For example, suppose you are using ChatGPT to help resolve a database connection issue. A poorly crafted prompt might be:</p>
<blockquote>
<p><em>Prompt:</em> Having DB connection issues. How to fix it?</p>
</blockquote>
<p>In this prompt, “DB” is ambiguous as it might refer to different database systems like MySQL, PostgreSQL, or others, and the nature of the connection issue is not clarified.</p>
<p>A more effective prompt would be:</p>
<blockquote>
<p><em>Prompt:</em> I am encountering a connection timeout issue while trying to connect to my PostgreSQL database using JDBC. How can I resolve this?</p>
</blockquote>
<p>This prompt clearly spells out the database system in use, the method of connection, and the specific issue encountered.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Mark Twain once <a href="https://oreil.ly/ZL9d6">wrote</a>, “The difference between the almost right word and the right word is really a large matter. ’Tis the difference between the lightning bug and the lightning.” In a way, the same thing can be said about writing a prompt.</p>
</div>
</div></section>
<section data-pdf-bookmark="Zero- and Few-Shot Learning" data-type="sect2"><div class="sect2" id="zerohyphen_and_fewhyphenshot_learning">
<h2>Zero- and Few-Shot Learning</h2>
<p>With <em>zero-shot learning</em>, you provide one prompt<a contenteditable="false" data-primary="zero-shot learning" data-type="indexterm" id="id450"/> and get the answer you want. Often, this works fine. But given the complexities of programming languages and frameworks, there are times when you need to nudge the LLM.</p>
<p>You can do this<a contenteditable="false" data-primary="few-shot learning" data-type="indexterm" id="id451"/> with <em>few-shot learning</em>. This refers to an LLM’s capability to understand and perform a task with very few examples or training data. This is a significant advantage over traditional machine learning models, which may require a large amount of training data to perform adequately on a task. The LLM’s capability is primarily due to the extensive pretraining on a diverse range of internet text that the LLM undergoes before it is fine-tuned for a specific task.</p>
<p>Let’s take a look at an example of few-shot learning. Consider a scenario in which we want to generate a function that normalizes a given list of numbers. It will scale the values in the list to a range of [0, 1]. In the instructions, we include a list of a few examples of the inputs and normalized outputs.</p>
<blockquote>
<p><em>Prompt:</em> Based on the following examples of normalizing a list of numbers to a range of [0, 1]:</p>
<p>1. Input: [2, 4, 6, 8] Output: [0, 0.3333, 0.6667, 1]</p>
<p>2. Input: [5, 10, 15] Output: [0, 0.5, 1]</p>
<p>3. Input: [1, 3, 2] Output: [0, 1, 0.5]</p>
<p>Generate a function in Python that takes a list of numbers as input and returns a list of normalized numbers.</p>
</blockquote>
<p>ChatGPT will “learn” from the data and come up with some code:</p>
<blockquote>
<p><em>ChatGPT:</em></p>
<pre data-type="programlisting">def normalize(numbers):
    min_value = min(numbers)
    max_value = max(numbers)
    if min_value == max_value:
        return [0] * len(numbers)  # Handle the case where 
                                   # all numbers are the same
    else:
        return [(x - min_value) / (max_value - min_value) for x in numbers]
# Test the function with one of the examples
print(normalize([2, 4, 6, 8]))  # Output: [0.0, 0.3333333333333333, 
                                # 0.6666666666666666, 1.0]</pre>
</blockquote>
</div></section>
<section data-pdf-bookmark="Leading Words" data-type="sect2"><div class="sect2" id="leading_words">
<h2>Leading Words</h2>
<p>The concept of <em>leading words</em> refers to specific keywords<a contenteditable="false" data-primary="leading word prompts" data-type="indexterm" id="id452"/> or phrases that can guide an LLM toward creating a particular kind of output. Sometimes you can achieve the desired result using just one code word. Here’s an example:</p>
<blockquote>
<p><em>Prompt:</em></p>
<p># Create a simple Python function that</p>
<p># 1. Prompts me for a temperature in Fahrenheit</p>
<p># 2. Converts Fahrenheit to Celsius</p>
<p>def</p>
</blockquote>
<p>Using the word <em>def</em> as a leading word informs the model that it should begin writing a Python function. <a data-type="xref" href="#examples_of_leadinghyphenword_prompts">Table 3-4</a> gives more examples of leading words.</p>
<table class="border" id="examples_of_leadinghyphenword_prompts">
<caption><span class="label">Table 3-4. </span>Examples of leading-word prompts</caption>
<thead>
<tr>
<th>Context</th>
<th>Leading word</th>
</tr>
</thead>
<tbody>
<tr>
<td>JavaScript function</td>
<td>Function</td>
</tr>
<tr>
<td>HTML element</td>
<td>&lt;button</td>
</tr>
<tr>
<td>CSS styling</td>
<td>P {</td>
</tr>
<tr>
<td>SQL insert query</td>
<td>INSERT INTO</td>
</tr>
<tr>
<td>Java method creation</td>
<td>public</td>
</tr>
</tbody>
</table>
</div></section>
<section data-pdf-bookmark="Chain of Thought (CoT) Prompting" data-type="sect2"><div class="sect2" id="chain_of_thought_left_parenthesiscotrigh">
<h2>Chain of Thought (CoT) Prompting</h2>
<p>In 2022, some Google researchers<a contenteditable="false" data-primary="chain-of-thought (CoT) prompting" data-type="indexterm" id="id453"/><a contenteditable="false" data-primary="CoT (chain-of-thought) prompting" data-type="indexterm" id="id454"/> introduced <em>chain-of-thought (CoT) prompting</em> in their paper <a href="https://arxiv.org/abs/2201.11903">“Chain-of-Thought Prompting Elicits Reasoning in Large Language Models”</a>. This approach enhances the reasoning abilities of LLMs by breaking down a complex problem into different steps. It’s actually similar to few-shot learning, which allows for nudging the model.</p>
<p>CoT prompting can be very useful in software code generation tasks. Let’s look at an example. Suppose you want to create a web application with a user registration and login functionality using Flask, a Python web framework. <a data-type="xref" href="#chainhyphenofhyphenthought_prompt_exampl">Table 3-5</a> shows the CoT prompting steps.</p>
<table class="border" id="chainhyphenofhyphenthought_prompt_exampl">
<caption><span class="label">Table 3-5. </span>Chain-of-thought prompt examples</caption>
<thead>
<tr>
<th>Action description</th>
<th>Prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td>Understand the requirement</td>
<td>“I need to create a web application using Flask. The application should have a user registration and login functionality. Where should I start?”</td>
</tr>
<tr>
<td>Set up Flask application</td>
<td>“Let’s begin by setting up a basic Flask application. How can I do that?”</td>
</tr>
<tr>
<td>Create user model</td>
<td>“Now that the Flask application is set up, I need to create a user model for handling registration and login. How should I structure this model?”</td>
</tr>
<tr>
<td>Implement registration</td>
<td>“With the user model in place, how can I implement a registration page with the necessary fields?”</td>
</tr>
<tr>
<td>Implement login</td>
<td>“Now let’s move on to creating a login page. How can I ensure secure login?”</td>
</tr>
<tr>
<td>Session management</td>
<td>“After a user logs in, how should I manage user sessions to keep users logged in as they navigate through the app?”</td>
</tr>
<tr>
<td>Logout implementation</td>
<td>“Finally, how can I implement a logout function to securely log users out of the application?”</td>
</tr>
</tbody>
</table>
</div></section>
<section data-pdf-bookmark="Leading Questions" data-type="sect2"><div class="sect2" id="leading_questions">
<h2>Leading Questions</h2>
<p>Leading questions<a contenteditable="false" data-primary="leading questions, in prompts" data-type="indexterm" id="id455"/> in a prompt can often fetch wonky responses from the LLM. It’s better to stay neutral and unbiased. Also, it’s good practice to avoid making assumptions; spell things out instead.</p>
<p>This prompt is a leading question:</p>
<blockquote>
<p><em>Prompt:</em> Isn’t it true that migrating to a microservices architecture will always improve system scalability?</p>
</blockquote>
<p>A more balanced prompt would be:</p>
<blockquote>
<p><em>Prompt:</em> What are the advantages and potential challenges of migrating to a microservices architecture in terms of system scalability?</p>
</blockquote>
</div></section>
<section data-pdf-bookmark="Ask for Examples and Analogies" data-type="sect2"><div class="sect2" id="ask_for_examples_and_analogies">
<h2>Ask for Examples and Analogies</h2>
<p>Suppose you don’t know the concept<a contenteditable="false" data-primary="examples, in prompts" data-type="indexterm" id="id456"/><a contenteditable="false" data-primary="analogies, in prompts" data-type="indexterm" id="id457"/> of inheritance in object-oriented programming. You go to ChatGPT and enter this prompt:</p>
<blockquote>
<p><em>Prompt:</em> Explain inheritance that is used in object-oriented programming.</p>
</blockquote>
<p>You will get a detailed response. But you may want to get something that’s easier to understand. A good way to do this is by asking the LLM for an analogy:</p>
<blockquote>
<p><em>Prompt:</em> Explain inheritance that is used in object-oriented programming by using an analogy.</p>
<p><em>ChatGPT:</em> Think of inheritance like a family tree, where children inherit certain traits and properties from their parents and, potentially, grandparents.</p>
</blockquote>
<p>From there, ChatGPT provides more detail, which proceeds from the analogy, to explain the key elements of inheritance<a contenteditable="false" data-primary="" data-startref="xi_promptengineeringbestpractices.03.251.56" data-type="indexterm" id="id458"/>.</p>
</div></section>
</div></section>
<section class="pagebreak-before" data-pdf-bookmark="Reducing Hallucinations" data-type="sect1"><div class="sect1" id="reducing_hallucinations">
<h1 class="less_space">Reducing Hallucinations</h1>
<p>In <a data-type="xref" href="ch02.html#how_ai_coding_technology_works">Chapter 2</a>, we learned that prompting an LLM can lead to a response<a contenteditable="false" data-primary="prompt engineering" data-secondary="reducing hallucinations" data-type="indexterm" id="xi_promptengineeringreducinghallucinations.03.429.158"/><a contenteditable="false" data-primary="hallucinations" data-type="indexterm" id="xi_hallucinations.03.429.158"/> that is a <em>hallucination</em>, such that the content generated is false or misleading but the LLM expresses the response as if it were true. Hallucinations can be particularly challenging for software development, which requires accuracy.</p>
<p>No doubt, applying the lessons in this chapter can mitigate this issue, but even a well-crafted prompt can spin up hallucinations. There are numerous reasons for this:</p>
<dl>
<dt>Lack of ground truth verification</dt>
<dd><p>LLMs generate responses based on patterns learned from training data without the ability to verify<a contenteditable="false" data-primary="ground truth verification" data-type="indexterm" id="id459"/> the accuracy or reality of the information.</p></dd>
<dt>Overfitting and memorization</dt>
<dd><p>LLMs might memorize incorrect or misleading information<a contenteditable="false" data-primary="overfitting of data" data-type="indexterm" id="id460"/><a contenteditable="false" data-primary="memorization of data, and hallucination" data-type="indexterm" id="id461"/> in their training datasets, especially if such data is repetitive or common.</p></dd>
<dt>Bias in training data</dt>
<dd><p>If the training data<a contenteditable="false" data-primary="bias, training data" data-type="indexterm" id="id462"/> contains biases, inaccuracies, or falsehoods, the model will likely replicate these in its outputs.</p></dd>
<dt>Extrapolation and speculation</dt>
<dd><p>Sometimes, LLMs might extrapolate<a contenteditable="false" data-primary="extrapolation, LLM" data-type="indexterm" id="id463"/><a contenteditable="false" data-primary="speculation, LLM" data-type="indexterm" id="id464"/> from the patterns they’ve seen in the data to generate information about topics or questions that were not adequately covered in the training data.</p></dd>
<dt>Lack of context or misinterpretation</dt>
<dd><p>LLMs can misinterpret or lack the necessary context<a contenteditable="false" data-primary="context, prompt" data-type="indexterm" id="id465"/> to accurately respond to certain prompts. They may not fully understand the nuances or implications of certain queries.</p></dd>
<dt>Slang and idioms</dt>
<dd><p>Such language<a contenteditable="false" data-primary="ambiguity issue for LLMs" data-type="indexterm" id="id466"/><a contenteditable="false" data-primary="large language models (LLMs)" data-secondary="ambiguity issue for" data-type="indexterm" id="id467"/> can create ambiguity that may lead the model to misinterpret the intended meaning, especially if it hasn’t seen enough examples of the slang or idiom in context during training.</p></dd>
</dl>
<p>Then how to reduce hallucinations? For one thing, it’s important to avoid asking open-ended questions like this:</p>
<blockquote>
<p><em>Prompt:</em> What are the different ways to optimize a database?</p>
</blockquote>
<p>This type of prompt encourages the LLM to resort to speculation or overgeneralization. The model may also misinterpret the intent of the question or the desired format of the answer, leading to responses that veer off-topic or contain fabricated information. There may actually be a cascade of hallucinations.</p>
<p>One effective technique is to provide a set of predefined options<a contenteditable="false" data-primary="multiple-choice options for LLM" data-type="indexterm" id="id468"/><a contenteditable="false" data-primary="large language models (LLMs)" data-secondary="multiple-choice options for" data-type="indexterm" id="id469"/> and ask the AI to choose from them. For example, the preceding prompt could be rephrased as follows:</p>
<blockquote>
<p><em>Prompt:</em> Which of the following is a method to optimize a database: indexing, defragmenting, or compressing?</p>
</blockquote>
<p>As another example, consider asking the LLM for a certain type of conclusion. Here is an effective prompt:</p>
<blockquote>
<p><em>Prompt:</em> Is the following syntax correct for initializing an array in Java? Provide a “yes” or “no” response.</p>
</blockquote>
<p>Or you can include multiple steps in the prompt to better guide the model through a structured process and narrow down the possibilities for straying off course<a contenteditable="false" data-primary="" data-startref="xi_promptengineeringreducinghallucinations.03.429.158" data-type="indexterm" id="id470"/><a contenteditable="false" data-primary="" data-startref="xi_hallucinations.03.429.158" data-type="indexterm" id="id471"/>:</p>
<blockquote>
<p><em>Prompt:</em></p>
<p>Step 1: Create a Fibonacci sequence generator.</p>
<p>Step 2: Use the iterative method.</p>
<p>Step 3: Write a Python function named generate_fibonacci that takes an integer n as an argument.</p>
<p>Step 4: The function returns the first n numbers in the Fibonacci sequence as a list.</p>
</blockquote>
</div></section>
<section data-pdf-bookmark="Security and Privacy" data-type="sect1"><div class="sect1" id="security_and_privacy">
<h1>Security and Privacy</h1>
<p>Being watchful about security and privacy<a contenteditable="false" data-primary="prompt engineering" data-secondary="security and privacy" data-type="indexterm" id="id472"/><a contenteditable="false" data-primary="security" data-secondary="prompt engineering" data-type="indexterm" id="id473"/><a contenteditable="false" data-primary="privacy" data-secondary="prompt engineering" data-type="indexterm" id="id474"/> while crafting prompts is key. In fact, the duty to take appropriate precautions should be in the company rulebook. It’s crucial to steer clear of any sensitive or personal information, such as personally identifiable information (PII)<a contenteditable="false" data-primary="personally identifiable information (PII)" data-type="indexterm" id="id475"/> in your prompts. Here’s an example of a prompt that contains identifying information:</p>
<blockquote>
<p><em>Prompt:</em> How would you fix a login issue reported by John Doe at john.doe@example.com?</p>
</blockquote>
<p>It’s wiser to go with something like:</p>
<blockquote>
<p><em>Prompt:</em> How would you tackle a login issue reported by a user?</p>
</blockquote>
<p>This keeps private information private.</p>
<p>It’s also smart to steer clear of spilling any sensitive system details in the prompts. Avoid this:</p>
<blockquote>
<p><em>Prompt:</em> How to fix a database connection error on our production server at IP 192.168.1.1?</p>
</blockquote>
<p>Instead, it’s safer to use a more generic question:</p>
<blockquote>
<p><em>Prompt:</em> How to fix a generic database connection error?</p>
</blockquote>
<p>Moreover, make sure your prompts don’t accidentally nudge folks toward shady practices. A prompt like this is fine from a security viewpoint:</p>
<blockquote>
<p><em>Prompt:</em> How to detect and prevent SQL injection?</p>
</blockquote>
<p>But not this one, which might stir up some bad intentions:</p>
<blockquote>
<p><em>Prompt:</em> How to exploit SQL vulnerabilities in a website?</p>
</blockquote>
<p>Besides sticking to security and privacy rules, embracing diversity<a contenteditable="false" data-primary="bias, training data" data-type="indexterm" id="id476"/> and inclusion when making prompts is important. Getting a solid grasp on bias, which often reflects the training data, is key. It’s a good call to use neutral and inclusive language to avoid any discriminatory or exclusionary phrases in the prompts. Also, getting feedback from a diverse group of people on your prompt crafting can help. This not only improves fairness and inclusivity when interacting with the LLM but also helps get a more accurate and well-rounded understanding of the topics at hand.</p>
</div></section>
<section data-pdf-bookmark="Autonomous AI Agents" data-type="sect1"><div class="sect1" id="autonomous_ai_agents">
<h1>Autonomous AI Agents</h1>
<p>We’ve seen how you can nudge<a contenteditable="false" data-primary="prompt engineering" data-secondary="autonomous AI agents" data-type="indexterm" id="xi_promptengineeringautonomousAIagents.03.497.32"/><a contenteditable="false" data-primary="autonomous AI agents" data-type="indexterm" id="xi_autonomousAIagents.03.497.32"/> LLMs to map out the steps for a process. That’s at the heart of code generation.</p>
<p>But AI agents can crank it up a notch. They don’t just follow prompts. They get creative with LLMs to figure out a game plan for whatever goal you toss at them, and they tap into specialized databases like Pinecone and Chroma DB. They handle complex word embeddings, which the models understand.</p>
<p>Autonomous AI agents are based on academic research and are usually part of open source projects. Their real power is automation. To see how this works, let’s take an example. Suppose you set the objective as follows:</p>
<blockquote>
<p><em>Prompt:</em> Create a basic weather application with a user login system.</p>
</blockquote>
<p><a data-type="xref" href="#process_for_an_autonomous_agent">Table 3-6</a> shows a process that an autonomous agent may go through.</p>
<table class="border" id="process_for_an_autonomous_agent">
<caption><span class="label">Table 3-6. </span>Process for an autonomous agent</caption>
<thead>
<tr>
<th>Phase</th>
<th>Tasks</th>
</tr>
</thead>
<tbody>
<tr>
<td>Creation tasks</td>
<td>Design the user interface (UI).<br/>Sketch the basic layout of the dashboard.<br/>Select color schemes and fonts.<br/>Design icons and other graphic elements.</td>
</tr>
<tr>
<td>API integration for weather data</td>
<td>Search the internet for reliable weather data APIs.<br/>Determine the data points to be displayed.<br/>Write code to fetch and update weather data.</td>
</tr>
<tr>
<td>Location selection functionality</td>
<td>Create a search bar or dropdown for users to select their location.<br/>Connect this to the API code.</td>
</tr>
<tr>
<td>Error handling</td>
<td>Handle errors like failed API calls or invalid location entries.</td>
</tr>
<tr>
<td>Prioritizing tasks</td>
<td>Prioritize setting up the API integration.<br/>Focus on the UI.<br/>Work on location selection functionality and error handling.</td>
</tr>
<tr>
<td>Iteration</td>
<td>Review the generated code and the current state of the weather dashboard.<br/>Identify any remaining tasks or new tasks that have arisen during execution.<br/>Repeat the create and prioritize steps.</td>
</tr>
</tbody>
</table>
<p>This technology is at the forefront and holds much promise. However, it’s not without its fair share of hurdles:</p>
<dl>
<dt>Being resource hogs</dt>
<dd><p>Agents can guzzle down large amounts of compute power. This can put the squeeze on your processors and databases, leading to more wait time, less reliability, and a slump in how things run as time goes on.</p></dd>
<dt>Getting stuck in infinite loops</dt>
<dd><p>Sometimes agents just run in circles, thanks to a lack of progression or a repetitive reward system.</p></dd>
<dt>Being experimental</dt>
<dd><p>Agents can be rough around the edges. They might come with a few bugs or unexpected behaviors and might not be quite ready for the big leagues, depending on what you need them for.</p></dd>
<dt>Having amnesia</dt>
<dd><p>Agents may simply forget certain steps or instructions.</p></dd>
<dt>Having difficulty handling a large number of tasks</dt>
<dd><p>Got a whole laundry list of tasks? That might trip up these agents.</p></dd>
<dt>Getting distracted by extraneous details</dt>
<dd><p>Agents might get sidetracked by the little things that don’t matter, which could send them down the wrong path when picking tools to use.</p></dd>
</dl>
<p>Another innovation that bolsters LLMs is retrieval augmented generation (RAG)<a contenteditable="false" data-primary="retrieval augmented generation (RAG)" data-type="indexterm" id="id477"/><a contenteditable="false" data-primary="RAG (retrieval augmented generation)" data-type="indexterm" id="id478"/>. With RAG, a generative AI application—say written in a framework like <span class="keep-together">LangChain—accesses</span> external sources of data, usually vector databases. They provide more grounding of the model in specific knowledge, which should enhance the LLM’s responses.</p>
<p>RAG can be particularly useful when handling complex software development tasks, such as in these scenarios:</p>
<dl>
<dt>Tackling bugs and glitches</dt>
<dd><p>When developers encounter bugs or errors, RAG digs up fixes and workarounds from all around the web, looking in places like forums or bug databases. It can whip up some tailor-made solutions or code patches that fit your problem.</p></dd>
<dt>Spicing up code reviews</dt>
<dd><p>RAG can pull in all the coding best practices, standards, and must-follow rules from a company’s internal resources. This means it can help streamline your code reviews, dishing out tips and tricks to make your code shine.</p></dd>
<dt>Revving up testing</dt>
<dd><p>When it’s time to put your code through its paces, RAG can be your pit crew. It finds all sorts of test scenarios and patterns, tweaks them to suit your project’s needs, and helps you roll out test cases or scripts faster.</p></dd>
</dl>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In some cases, an LLM will indicate that there’s an issue with your prompt. For example, suppose you write this:</p>
<blockquote>
<p><em>Prompt:</em> Write a REST API using assembler.</p>
</blockquote>
<p>This is how ChatGPT responded:</p>
<blockquote>
<p><em>ChatGPT:</em> Creating a REST API using an assembler language is highly unconventional and complex due to the low-level nature of assembler languages. These languages are usually used for tasks that require fine-grained control over hardware, or for scenarios where performance is a critical concern<a contenteditable="false" data-primary="" data-startref="xi_promptengineeringautonomousAIagents.03.497.32" data-type="indexterm" id="id479"/><a contenteditable="false" data-primary="" data-startref="xi_autonomousAIagents.03.497.32" data-type="indexterm" id="id480"/>.</p>
</blockquote>
</div>
</div></section>
<section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="conclusion-id00002">
<h1>Conclusion</h1>
<p>Again, crafting the perfect prompt involves mixing science with a splash of creativity. It’s all about finding the right ingredients—some creativity, a bit of gut feeling, and a structured approach—to cook up prompts that get LLMs to serve up what you want<a contenteditable="false" data-primary="" data-startref="xi_promptengineering.03.3.45" data-type="indexterm" id="id481"/>. No magic recipe exists, but if you’re clear, throw in a few examples, and lay out your prompts well, you’re on track for better answers.</p>
<p>It’s a process, really. You try something, see how it goes, tweak it, and try again. And as with any skill, you get better the more you work on it with different topics and tasks.</p>
</div></section>

</div></section></body></html>