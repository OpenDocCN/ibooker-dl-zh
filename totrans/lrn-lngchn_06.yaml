- en: Chapter 6\. Agent Architecture
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章\. 代理架构
- en: Building on the architectures described in [Chapter 5](ch05.html#ch05_cognitive_architectures_with_langgraph_1736545670030774),
    this chapter will cover what is perhaps the most important of all current LLM
    architectures, the agent architecture. First, we introduce what makes LLM agents
    unique, then we show how to build them and how to extend them for common use cases.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 建立在[第5章](ch05.html#ch05_cognitive_architectures_with_langgraph_1736545670030774)中描述的架构之上，本章将涵盖所有当前LLM架构中可能最重要的架构——代理架构。首先，我们介绍使LLM代理独特之处，然后展示如何构建它们以及如何扩展它们以适应常见用例。
- en: 'In the artificial intelligence field, there is a long history of creating (intelligent)
    agents, which can be most simply defined as “something that acts,” in the words
    of Stuart Russell and Peter Norvig in their *Artificial Intelligence* (Pearson,
    2020) textbook. The word *acts* actually carries a little more meaning than meets
    the eye:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能领域，创建（智能）代理的历史悠久，正如斯图尔特·罗素和彼得·诺维格在他们所著的《人工智能》（Pearson, 2020）一书中所说：“某种能够行动的东西”可以最简单地定义代理。实际上，“行动”这个词的含义比表面上看要丰富一些：
- en: Acting requires some capacity for deciding what to do.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行动需要一些决定做什么的能力。
- en: Deciding what to do implies having access to more than one possible course of
    action. After all, a decision without options is no decision at all.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定做什么意味着可以访问多个可能的行动方案。毕竟，没有选择的决定根本不是决定。
- en: In order to decide, the agent also needs access to information about the external
    environment (anything outside of the agent itself).
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了做出决定，代理还需要获取有关外部环境（代理本身之外的一切）的信息。
- en: 'So an *agentic* LLM application must be one that uses an LLM to pick from one
    or more possible courses of action, given some context about the current state
    of the world or some desired next state. These attributes are usually implemented
    by mixing two prompting techniques we first met in the [Preface](preface01.html#pr01_preface_1736545679069216):'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个具有代理性的LLM应用必须是一个使用LLM从一种或多种可能的行动方案中选择，给定关于世界当前状态或所需下一个状态的一些上下文的应用。这些属性通常通过混合我们在[前言](preface01.html#pr01_preface_1736545679069216)中首次遇到的两种提示技术来实现：
- en: Tool calling
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 工具调用
- en: Include a list of external functions that the LLM can make use of in your prompt
    (that is, the actions it can decide to take) and provide instructions on how to
    format its choice in the output it generates. You’ll see in a moment what this
    looks like in the prompt.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的提示中包含一个外部函数列表，LLM可以利用这些函数（即它可以决定采取的行动），并提供如何格式化其输出中选择的说明。你很快就会看到提示中的样子。
- en: Chain-of-thought
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 思维链
- en: Researchers have found that LLMs “make better decisions” when given instructions
    to reason about complex problems by breaking them down into granular steps to
    be taken in sequence. This is usually done either by adding instructions along
    the lines of “think step by step” or including examples of questions and their
    decomposition into several steps/actions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员发现，当LLM被指示通过将复杂问题分解为一系列按顺序执行的粒度步骤来进行推理时，它们“做出更好的决定”。这通常是通过添加类似“逐步思考”的指令或包括问题和它们分解为几个步骤/行动的例子来完成的。
- en: 'Here’s an example prompt using both tool calling and chain-of-thought:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个同时使用工具调用和思维链的示例提示：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And the output, when run against `gpt-3.5-turbo` at temperature 0 (to ensure
    the LLM follows the desired output format, CSV) and newline as the stop sequence
    (which instructs the LLM to stop producing output when it reaches this character).
    This makes the LLM produce a single action (as expected, given the prompt asked
    for this):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当在温度0（以确保LLM遵循所需的输出格式，CSV）和换行符作为停止序列（这指示LLM在达到此字符时停止产生输出）的情况下运行`gpt-3.5-turbo`时，输出，这使得LLM产生一个单一的行动（正如预期的那样，因为提示要求这样做）：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The most recent LLMs and chat models have been fine-tuned to improve their
    performance for tool-calling and chain-of-thought applications, removing the need
    for adding specific instructions to the prompt:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最新的LLM和聊天模型已经经过微调，以提高它们在工具调用和思维链应用中的性能，从而消除了在提示中添加特定指令的需要：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The Plan-Do Loop
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计划-执行循环
- en: 'What makes the agent architecture different from the architectures discussed
    in [Chapter 5](ch05.html#ch05_cognitive_architectures_with_langgraph_1736545670030774)
    is a concept we haven’t covered yet: the LLM-driven loop.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使代理架构与[第5章](ch05.html#ch05_cognitive_architectures_with_langgraph_1736545670030774)中讨论的架构不同的概念是我们尚未涉及的概念：由LLM驱动的循环。
- en: Every programmer has encountered loops in their code before. By *loop*, we mean
    running the same code multiple times until a stop condition is hit. The key to
    the agent architecture is to have an LLM control the stop condition—that is, decide
    when to stop looping.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 每个程序员在他们的代码中都遇到过循环。通过“循环”，我们指的是运行相同的代码多次，直到达到停止条件。代理架构的关键是让LLM控制停止条件——也就是说，决定何时停止循环。
- en: 'What we’ll run in this loop will be some variation of the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个循环中我们将运行以下内容的某种变体：
- en: Planning an action or actions
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规划动作或动作
- en: Executing said action(s)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行所述动作（们）
- en: 'Picking up on the example in the previous section, we’ll next run the `search`
    tool with the input `30th president of the United States`, which produces this
    output:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 继续前一小节的例子，我们将运行输入为“美国第30任总统”的`search`工具，它产生以下输出：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'And then we’ll rerun the prompt, with a small addition:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将重新运行提示，增加一点：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And the output:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以及输出：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Notice we added two things:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们添加了两件事：
- en: An “output” tool—which the LLM should use when it has found the final answer,
    and which we’d use as the signal to stop the loop.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个“输出”工具——当LLM找到最终答案时应该使用，我们也会用它作为停止循环的信号。
- en: The result of the tool call from the preceding iteration, simply with the name
    of the tool and its (text) output. This is included in order to allow the LLM
    to move on to the next step in the interaction. In other words, we’re telling
    the LLM, “Hey, we got the results you asked for, what do you want to do next?”
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上一次迭代中工具调用的结果，简单地以工具名称及其（文本）输出。这是为了允许LLM继续进行下一步交互。换句话说，我们在告诉LLM，“嘿，我们得到了你要求的结果，你接下来想做什么？”
- en: 'Let’s continue with a third iteration:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续进行第三次迭代：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And the output:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以及输出：
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With the result from the `calculator` tool, the LLM now has enough information
    to provide the final answer, so it picked the `output` tool and chose “61” as
    the final answer.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用“计算器”工具的结果，LLM现在拥有了足够的信息来提供最终答案，因此它选择了“输出”工具，并选择了“61”作为最终答案。
- en: This is what makes the agent architecture so useful—the LLM is given the agency
    to decide. The next step is to arrive at an answer and decide how many steps to
    take—that is, when to stop.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是使代理架构如此有用的原因——LLM被赋予了决策权。下一步是得出答案并决定采取多少步骤——也就是说，何时停止。
- en: This architecture, called [ReAct](https://oreil.ly/M7hF-), was first proposed
    by Shunyu Yao et al. The rest of this chapter explores how to improve the performance
    of the agent architecture, motivated by the email assistant example from [Chapter 5](ch05.html#ch05_cognitive_architectures_with_langgraph_1736545670030774).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个架构，称为[ReAct](https://oreil.ly/M7hF-)，最初由姚顺宇等人提出。本章的其余部分将探讨如何通过第5章中电子邮件助手示例来提高代理架构的性能。
- en: But first, let’s see what it looks like to implement the basic agent architecture
    using a chat model and LangGraph.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，让我们看看使用聊天模型和LangGraph实现基本代理架构的样子。
- en: Building a LangGraph Agent
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建LangGraph代理
- en: 'For this example, we need to install additional dependencies for the search
    tool we chose to use, DuckDuckGo. To install it for Python:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们需要为所选的搜索工具DuckDuckGo安装额外的依赖项。对于Python的安装：
- en: '*Python*'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'And for JS, we also need to install a dependency for the calculator tool:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于JS，我们还需要为计算器工具安装一个依赖项：
- en: '*JavaScript*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'With that complete, let’s get into the actual code to implement the agent architecture:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，让我们来看看实现代理架构的实际代码：
- en: '*Python*'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE10]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '*JavaScript*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The visual representation is shown in [Figure 6-1](#ch06_figure_1_1736545671744632).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉表示如图[图6-1](#ch06_figure_1_1736545671744632)所示。
- en: '![A diagram of a model  Description automatically generated](assets/lelc_0601.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![模型图  描述自动生成](assets/lelc_0601.png)'
- en: Figure 6-1\. The agent architecture
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-1. 代理架构
- en: 'A few things to notice here:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个需要注意的地方：
- en: 'We’re using two tools in this example: a search tool and a calculator tool,
    but you could easily add more or replace the ones we used. In the Python example,
    you also see an example of creating a custom tool.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用了两个工具：一个搜索工具和一个计算器工具，但你可以很容易地添加更多或替换我们使用的工具。在Python示例中，你还可以看到一个创建自定义工具的例子。
- en: We’ve used two convenience functions that ship with LangGraph. `ToolNode` serves
    as a node in our graph; it executes the tool calls requested in the latest AI
    message found in the state and returns a `ToolMessage` with the results of each.
    `ToolNode` also handles exceptions raised by tools—using the error message to
    build a `ToolMessage` that is then passed to the LLM—which may decide what to
    do with the error.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用了LangGraph附带的两个便利函数。`ToolNode`作为我们图中的一个节点；它执行在状态中找到的最新AI消息中请求的工具调用，并返回每个工具的结果的`ToolMessage`。`ToolNode`还处理由工具引发的异常——使用错误消息构建一个`ToolMessage`，然后将其传递给LLM，LLM可能会决定如何处理该错误。
- en: '`tools_condition` serves as a conditional edge function that looks at the latest
    AI message in the state and routes to the `tools` node if there are any tools
    to execute. Otherwise, it ends the graph.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tools_condition`作为条件边函数，查看状态中的最新AI消息，如果有任何工具要执行，则路由到`tools`节点。否则，结束图。'
- en: Finally, notice that this graph loops between the model and tools nodes. That
    is, the model itself is in charge of deciding when to end the computation, which
    is a key attribute of the agent architecture. Whenever we code a loop in LangGraph,
    we’ll likely want to use a conditional edge, as that allows you to define the
    *stop condition* when the graph should exit the loop and stop executing.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，请注意，这个图在模型和工具节点之间循环。也就是说，模型本身负责决定何时结束计算，这是代理架构的关键属性。每当我们在LangGraph中编写循环时，我们可能会想使用条件边，因为这允许你定义当图应该退出循环并停止执行时的*停止条件*。
- en: 'Now let’s see how it does in the previous example:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看它在前面的例子中的表现：
- en: '*Python*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '*JavaScript*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '*The output:*'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出：*'
- en: '[PRE14]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Walking through this output:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历这个输出：
- en: First the `model` node executed and decided to call the `duckduckgo_search`
    tool, which led the conditional edge to route us to the `tools` node after.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，`model`节点执行并决定调用`duckduckgo_search`工具，这导致条件边将我们路由到后面的`tools`节点。
- en: The `ToolNode` executed the search tool and got the search results printed above,
    which actually contain the answer “Age and Year of Death . January 5, 1933 (aged
    60)”.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ToolNode`执行了搜索工具，并打印出了上面的搜索结果，实际上包含答案“年龄和逝世年份。1933年1月5日（60岁）”。'
- en: The `model` tool was called again, this time with the search results as the
    latest message, and produced the final answer (with no more tool calls); therefore,
    the conditional edge ended the graph.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次调用了`model`工具，这次使用搜索结果作为最新消息，并生成了最终答案（没有更多的工具调用）；因此，条件边结束了图。
- en: Next, let’s look at a few useful extensions to this basic agent architecture,
    customizing both planning and tool calling.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看对这个基本代理架构的一些有用扩展，定制计划和工具调用。
- en: Always Calling a Tool First
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总是首先调用工具
- en: 'In the standard agent architecture, the LLM is always called upon to decide
    what tool to call next. This arrangement has a clear advantage: it gives the LLM
    ultimate flexibility to adapt the behavior of the application to each user query
    that comes in. But this flexibility comes at a cost: unpredictability. If, for
    instance, you, the developer of the application, know that the search tool should
    always be called first, that can actually be beneficial to your application:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准代理架构中，LLM总是被要求决定下一个调用哪个工具。这种安排有一个明显的优势：它给了LLM最大的灵活性，以适应每个到来的用户查询的行为。但这种灵活性是有代价的：不可预测性。例如，如果你，作为应用程序的开发者，知道应该总是首先调用搜索工具，这实际上对你的应用程序是有益的：
- en: It will reduce overall latency, as it will skip the first LLM call that would
    generate that request to call the search tool.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将减少整体延迟，因为它将跳过第一个LLM调用，该调用会生成调用搜索工具的请求。
- en: It will prevent the LLM from erroneously deciding it doesn’t need to call the
    search tool for some user queries.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将防止LLM错误地决定对于某些用户查询不需要调用搜索工具。
- en: On the other hand, if your application doesn’t have a clear rule of the kind
    “you should always call this tool first,” introducing such a constraint would
    actually make your application worse.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果你的应用程序没有明确的规则“你应该总是首先调用这个工具”，引入这种约束实际上会使你的应用程序变得更差。
- en: 'Let’s see what it looks like to do this:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这样做是什么样子：
- en: '*Python*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '*JavaScript*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE16]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The visual representation is shown in [Figure 6-2](#ch06_figure_2_1736545671744669).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 可视表示如图[图6-2](#ch06_figure_2_1736545671744669)所示。
- en: '![A diagram of a model  Description automatically generated](assets/lelc_0602.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![一个模型的图  自动生成的描述](assets/lelc_0602.png)'
- en: Figure 6-2\. Modifying the agent architecture to always call a specific tool
    first
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-2\. 修改代理架构以始终首先调用特定工具
- en: 'Notice the differences compared to the previous section:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意与上一节相比的不同之处：
- en: Now, we start all invocations by calling `first_model`, which doesn’t call an
    LLM at all. It just creates a tool call for the search tool, using the user’s
    message verbatim as the search query. The previous architecture would have the
    LLM generate this tool call (or some other response it deemed better).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，我们开始所有调用，首先调用`first_model`，它根本不调用LLM。它只是使用用户的原始消息作为搜索查询为搜索工具创建一个工具调用。之前的架构会让LLM生成这个工具调用（或它认为更好的其他响应）。
- en: After that, we proceed to `tools`, which is identical to the previous example,
    and from there we proceed to the `agent` node as before.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 之后，我们继续到`tools`，这与之前的例子相同，然后我们继续到之前的`agent`节点。
- en: 'Now let’s see some example output, for the same query as before:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看一些示例输出，与之前的查询相同：
- en: '*Python*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*JavaScript*'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '*The output:*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出：*'
- en: '[PRE19]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This time, we skipped the initial LLM call. We first went to `first_model` node,
    which directly returned a tool call for the search tool. From there we went to
    the previous flow—that is, we executed the search tool and finally went back to
    the `model` node to generate the final answer.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们跳过了最初的LLM调用。我们首先到达`first_model`节点，该节点直接返回搜索工具的工具调用。从那里，我们继续到之前的流程——即执行搜索工具，最后回到`model`节点生成最终答案。
- en: Next let’s go over what you can do when you have many tools you want to make
    available to the LLM.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来让我们看看当你有很多工具想要提供给LLM时你可以做什么。
- en: Dealing with Many Tools
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理许多工具
- en: LLMs are far from perfect, and they currently struggle more when given multiple
    choices or excessive information in a prompt. These limitations also extend to
    the planning of the next action to take. When given many tools (say, more than
    10) the planning performance (that is, the LLM’s ability to choose the right tool)
    starts to suffer. The solution to this problem is to reduce the number of tools
    the LLM can choose from. But what if you do have many tools you want to see used
    for different user queries?
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: LLM远非完美，当给出多个选择或提示中的过多信息时，它们目前遇到的困难更大。这些限制也扩展到下一步行动的计划。当给出许多工具（比如说，超过10个）时，规划性能（即LLM选择正确工具的能力）开始下降。解决这个问题的方法是减少LLM可以选择的工具数量。但如果你确实有很多工具想要用于不同的用户查询呢？
- en: One elegant solution is to use a RAG step to preselect the most relevant tools
    for the current query and then feed the LLM only that subset of tools instead
    of the entire arsenal. This can also help to reduce the cost of calling the LLM
    (commercial LLMs usually charge based on the length of the prompt and outputs).
    On the other hand, this RAG step introduces additional latency to your application,
    so should only be taken when you see performance decreasing after adding more
    tools.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一个优雅的解决方案是使用RAG步骤预先选择当前查询中最相关的工具，然后只向LLM提供这些工具子集而不是整个工具库。这也可以帮助减少调用LLM的成本（商业LLM通常根据提示和输出的长度收费）。另一方面，这个RAG步骤会给你的应用程序引入额外的延迟，因此只有在你在添加更多工具后看到性能下降时才应该采取这一步骤。
- en: 'Let’s see how to do this:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何做到这一点：
- en: '*Python*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE20]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '*JavaScript*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE21]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You can see the visual representation in [Figure 6-3](#ch06_figure_3_1736545671744693).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[图6-3](#ch06_figure_3_1736545671744693)中看到视觉表示。
- en: '![A diagram of a software development process  Description automatically generated](assets/lelc_0603.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![软件开发流程图  自动生成的描述](assets/lelc_0603.png)'
- en: Figure 6-3\. Modifying the agent architecture to deal with many tools
  id: totrans-107
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-3\. 修改代理架构以处理许多工具
- en: Note
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This is very similar to the regular agent architecture. The only difference
    is that we stop by the `select_tools` node before entering the actual agent loop.
    After that, it works just as the regular agent architecture we’ve seen before.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常类似于常规代理架构。唯一的区别是我们进入实际的代理循环之前会经过`select_tools`节点。之后，它就像我们之前看到的常规代理架构一样工作。
- en: 'Now let’s see some example output for the same query as before:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看之前查询的示例输出：
- en: '*Python*'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE22]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*JavaScript*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE23]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '*The output:*'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*输出：*'
- en: '[PRE24]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Notice how the first thing we did was query the retriever to get the most relevant
    tools for the current user query. Then, we proceeded to the regular agent architecture.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们首先做了什么：查询检索器以获取当前用户查询的最相关工具。然后，我们继续到常规代理架构。
- en: Summary
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This chapter introduced the concept of *agency* and discussed what it takes
    to make an LLM application *agentic*: giving the LLM the ability to decide between
    multiple options by using external information.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了*代理*的概念，并讨论了使LLM应用*具有代理性*所需的因素：通过使用外部信息，使LLM能够决定在多个选项之间进行选择。
- en: 'We walked through the standard agent architecture built with LangGraph and
    looked at two useful extensions: how to always call a specific tool first and
    how to deal with many tools.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探讨了使用LangGraph构建的标准代理架构，并查看了两项有用的扩展：如何始终首先调用特定工具以及如何处理多个工具。
- en: '[Chapter 7](ch07.html#ch07_agents_ii_1736545673023633) looks at additional
    extensions to the agent architecture.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](ch07.html#ch07_agents_ii_1736545673023633)探讨了代理架构的额外扩展。'
