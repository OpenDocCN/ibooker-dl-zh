- en: 2 RAG systems and their design
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 RAG系统和它们的设计
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The concept and design of RAG systems
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG系统的概念和设计
- en: An overview of the indexing pipeline
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引管道概述
- en: An overview of the generation pipeline
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成管道概述
- en: An initial look at RAG evaluation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对RAG评估的初步了解
- en: A high-level look at the RAG operations stack
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对RAG操作堆栈的概述
- en: The first chapter explored the core principles behind retrieval-augmented generation
    (RAG) and the large language model (LLM) challenges addressed by it. To construct
    a RAG system, several components need to be assembled. This process includes the
    creation and maintenance of the non-parametric memory, or a knowledge base, for
    the system. Another pipeline facilitates real-time interaction by sending the
    prompts to and accepting the response from the LLM, with retrieval and augmentation
    steps in the middle. Evaluation is yet another critical component, ensuring the
    effectiveness and accuracy of the system. All these components are supported by
    layers of the operations stack.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 第一章探讨了检索增强生成（RAG）背后的核心原则以及它解决的大语言模型（LLM）挑战。要构建一个RAG系统，需要组装几个组件。这个过程包括创建和维护系统的非参数记忆，或知识库。另一个管道通过将提示发送到LLM并从中接受响应来促进实时交互，其中检索和增强步骤位于中间。评估是另一个关键组件，确保系统的有效性和准确性。所有这些组件都由操作堆栈的各个层级支持。
- en: Chapter 2 discusses the design of a RAG system, examining the steps involved
    and the need for two different pipelines. We will call the pipeline that creates
    the knowledge base the “indexing pipeline.” The other pipeline that allows real-time
    interaction with the LLM will be referred to as the “generation pipeline.” We
    will discuss their individual components, such as data loading, embeddings, vector
    stores, retrievers, and more. Additionally, we will get an understanding of how
    the evaluation of RAG systems is conducted and introduce the RAG operations (RAGOps)
    stack that powers such systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 第二章讨论了RAG系统的设计，检查涉及的步骤和需要两个不同的管道。我们将创建知识库的管道称为“索引管道”。允许与LLM进行实时交互的另一个管道将被称为“生成管道”。我们将讨论它们的各个组件，如数据加载、嵌入、向量存储、检索器等。此外，我们将了解如何进行RAG系统的评估，并介绍为这些系统提供动力的RAG操作（RAGOps）堆栈。
- en: This chapter will introduce you to various components discussed in detail in
    the coming chapters. By the end of chapter 2, you will have acquired a deep understanding
    of the components of a RAG system and will be ready to dive deep into the different
    components. By the end of the chapter, you should
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍将在后续章节中详细讨论的各种组件。到第二章结束时，你将深入理解RAG系统的组件，并准备好深入研究不同的组件。到本章结束时，你应该
- en: Be able to understand the several components of the RAG system design.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够理解RAG系统设计的几个组成部分。
- en: Set yourself up for a deeper exploration of the indexing pipeline—the generation
    pipelines, RAG evaluation methods, and the RAGOps stack.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为更深入地探索索引管道——生成管道、RAG评估方法和RAGOps堆栈做好准备。
- en: 2.1 What does a RAG system look like?
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 RAG系统看起来是什么样子？
- en: By now, we have come to know that RAG is a vital component of the systems that
    use LLMs to solve their use cases. But, what is that system like? To illustrate,
    let’s revisit the example used at the beginning chapter 1 (“Who won the 2023 Cricket
    World Cup?”) and lay out the steps we undertook to enable ChatGPT to provide us
    with the accurate response.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解到RAG是使用LLM来解决其用例的系统的一个关键组件。但是，这个系统是什么样的呢？为了说明，让我们回顾一下第一章开头使用的例子（“2023年板球世界杯冠军是谁？”）并概述我们采取的步骤，以使ChatGPT能够为我们提供准确的回答。
- en: 'The initial step was asking the question itself: “Who won the 2023 Cricket
    World Cup?” Following this, we manually searched for sources on the internet that
    might have information regarding the answer to the question. We found one (Wikipedia,
    in our example) and extracted a relevant paragraph from the source. Subsequently,
    we added the relevant paragraph to our original question, pasted the question
    and the retrieved paragraph together in the prompt to ChatGPT, and got a factually
    correct response: “Australia won the 2023 Cricket World Cup.”'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是提出问题本身：“2023年板球世界杯冠军是谁？”随后，我们手动在互联网上搜索可能包含问题答案信息的来源。我们找到了一个（在我们的例子中是维基百科）并从中提取了一段相关的段落。随后，我们将相关的段落添加到我们的原始问题中，将问题和检索到的段落一起粘贴到ChatGPT的提示中，并得到了一个事实正确的回答：“澳大利亚赢得了2023年板球世界杯。”
- en: 'This process can be distilled into five steps, and our system needs to facilitate
    all of them:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可以提炼为五个步骤，我们的系统需要促进所有这些步骤：
- en: User asks a question.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户提出问题。
- en: The system searches for information relevant to the input question.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 系统搜索与输入问题相关的信息。
- en: The information relevant to the input question is fetched, or retrieved, and
    added to the input question.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从输入问题中检索或获取与信息相关的信息，并将其添加到输入问题中。
- en: This question and information are passed to an LLM.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个问题和信息被传递给一个大型语言模型（LLM）。
- en: The LLM responds with a contextual answer.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM 以上下文答案的形式响应。
- en: If you recall, we have already described this process in chapter 1\. Let’s visualize
    it in the context of these five steps as shown in figure 2.1\. This workflow will
    be called the “generation pipeline” since it generates the answer.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得，我们已经在第 1 章中描述了这一过程。让我们在图 2.1 的上下文中可视化这一过程。这个工作流程将被称为“生成管道”，因为它生成答案。
- en: '![A diagram of a process'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个流程图'
- en: AI-generated content may be incorrect.](../Images/CH02_F01_Kimothi.png)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: AI 生成的内可能是不正确的。](../Images/CH02_F01_Kimothi.png)
- en: Figure 2.1  Generation pipeline covering the five RAG steps. The journey from
    query to the response involves search and retrieval, augmentation, and generation.
  id: totrans-24
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.1 生成管道覆盖了五个 RAG 步骤。从查询到响应的旅程涉及搜索和检索、增强和生成。
- en: 'This pipeline enables real-time contextual interaction with the LLM. There
    are, of course, several intricacies in each of the five steps needed to create
    the generation pipeline. Some decisions need to be made about the design of the
    retriever and the LLM choice. The construction of prompts will also affect the
    quality of the response. We will discuss prompt construction in chapter 3\. We
    first must address a critical pre-requisite step before this generation pipeline
    can be put in place. For that, some key questions regarding the external source
    of information need to be answered. We will also need to know, in advance, where
    to look and then establish connections to all these disparate sources:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个管道允许与 LLM 进行实时上下文交互。当然，创建生成管道所需的五个步骤中都有一些复杂性。需要就检索器和 LLM 的选择做出一些决定。提示语的构建也会影响响应的质量。我们将在第
    3 章讨论提示语的构建。在建立这个生成管道之前，我们首先必须解决一个关键的前置步骤。为此，需要回答一些关于信息外部来源的关键问题。我们还需要提前知道在哪里查找，然后与所有这些不同的来源建立连接：
- en: What is the location of the external source of information?
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息外部来源的位置在哪里？
- en: Is it the open internet? Or are there some documents in the company’s internal
    data storage? Is the information present in some third-party databases? Are there
    multiple sources we want to use?
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是开放的互联网吗？还是公司内部数据存储中有一些文档？信息是否存在于某些第三方数据库中？我们想要使用多个来源的信息吗？
- en: Why is this important?
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么这很重要？
- en: What is the nature of the information at the source?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源信息性质是什么？
- en: Are these Word documents or PDF files? Is the information accessed via an API,
    and the response is in JSON format? Will we find answers in one document, or is
    the information distributed in multiple documents?
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些是 Word 文档还是 PDF 文件？访问信息是通过 API 进行的吗？响应格式是 JSON 吗？我们将在一个文档中找到答案，还是信息分布在多个文档中？
- en: Why is this important?
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么这很重要？
- en: We will also need to know the format and nature of data storage to be able to
    extract the information from the source files.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要了解数据存储的格式和性质，以便能够从源文件中提取信息。
- en: When data is stored across multiple sources, such as the internet and an internal
    data lake, the system must connect to each source, search for relevant information
    in various formats, and organize it according to the original query. Every time
    a question is asked, this process of connecting, extracting, and parsing will
    have to be repeated. Information from different sources may lead to factual inconsistencies
    that will have to be resolved in real time. Searching through all the information
    might be prohibitively time-consuming. This will, therefore, prove to be a highly
    suboptimal, unscalable process that may not yield the desired results. A RAG system
    will work best if the information from different sources is
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据存储在多个来源，如互联网和内部数据湖时，系统必须连接到每个来源，以各种格式搜索相关信息，并根据原始查询对其进行组织。每次提问时，都需要重复连接、提取和解析的过程。来自不同来源的信息可能导致事实上的不一致，这些不一致需要实时解决。搜索所有信息可能非常耗时。因此，这将被证明是一个高度次优、不可扩展的过程，可能无法产生期望的结果。如果来自不同来源的信息
- en: Collected in a single location.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集在一个单独的位置。
- en: Stored in a single format.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储在单一格式中。
- en: Broken down into small pieces of information.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将其分解成小块的信息。
- en: 'The need for a consolidated knowledge base arises from the disparate nature
    of external data sources. To address this requirement, we need to undertake a
    series of steps to create and maintain a well-structured knowledge base. This,
    again, is a five-step process:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 统一知识库的需求源于外部数据源的不同性质。为了满足这一需求，我们需要采取一系列步骤来创建和维护一个结构良好的知识库。这又是一个五步的过程：
- en: Connect to previously identified external sources.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接到之前确定的外部来源。
- en: Extract documents and parse text from them.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文档中提取文档并解析文本。
- en: Break down long pieces of text into smaller, manageable pieces.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将长篇文本分解成更小、更易于管理的部分。
- en: Convert these small pieces into a suitable format.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些小部分转换成合适的格式。
- en: Store this information.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存储这些信息。
- en: These steps, which facilitate the creation of this knowledge base, form the
    *indexing pipeline*. The indexing pipeline is shown in figure 2.2.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤，这些步骤有助于创建这个知识库，构成了*索引管道*。索引管道如图2.2所示。
- en: In addition to creating the knowledge base, the indexing pipeline plays a crucial
    role in maintaining and updating it with the latest information to ensure its
    relevance and accuracy. Before the knowledge base is created by the indexing pipeline,
    there is nowhere for the generation pipeline to search for information. It is
    the indexing pipeline that lays the foundation for the subsequent operation of
    the generation pipeline. Therefore, setting up the indexing pipeline comes before
    the generation pipeline can be activated.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 除了创建知识库外，索引管道在维护和更新它以保持其相关性和准确性方面也起着至关重要的作用。在索引管道创建知识库之前，生成管道没有地方可以搜索信息。是索引管道为生成管道的后续操作奠定了基础。因此，设置索引管道是在激活生成管道之前。
- en: Together, these pipelines form the backbone of a RAG system, enabling seamless
    interaction with users and delivering contextually relevant responses. Figure
    2.3 shows the indexing and generation pipelines working together to form the skeleton
    of a RAG system.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些管道共同构成了RAG系统的骨架，使用户能够无缝交互，并交付上下文相关的响应。图2.3显示了索引和生成管道共同工作，形成RAG系统的骨架。
- en: We have established the flow of a RAG system that includes two pipelines. Conceptually,
    this is the complete flow. However, to build such systems to be used in the real
    world, more components are required. The next section reimagines this flow along
    with other considerations and creates a design for RAG systems.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经建立了一个包含两个管道的RAG系统的流程。从概念上讲，这是完整的流程。然而，为了构建用于现实世界的系统，还需要更多的组件。下一节将重新构想这个流程以及其他考虑因素，并为RAG系统设计一个方案。
- en: '![A diagram of a diagram'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个图表的图表'
- en: AI-generated content may be incorrect.](../Images/CH02_F02_Kimothi.png)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能生成的内容可能是不正确的。](../Images/CH02_F02_Kimothi.png)
- en: Figure 2.2  Indexing pipeline covering the steps to create the knowledge base
    for RAG. This involves connecting to the source, parsing, splitting, converting,
    and storing information.
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.2  覆盖创建RAG知识库步骤的索引管道。这包括连接到源，解析，分割，转换和存储信息。
- en: '![A diagram of a knowledge base'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![知识库的图表'
- en: AI-generated content may be incorrect.](../Images/CH02_F03_Kimothi.png)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能生成的内容可能是不正确的。](../Images/CH02_F03_Kimothi.png)
- en: Figure 2.3  The indexing and generation pipelines together make a RAG system.
    The indexing pipeline is an offline process, while the generation pipeline facilitates
    real-time interaction with the knowledge base.
  id: totrans-52
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.3  索引和生成管道共同构成一个RAG系统。索引管道是一个离线过程，而生成管道则促进与知识库的实时交互。
- en: 2.2 Design of RAG systems
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 RAG系统的设计
- en: We saw how RAG systems are created by the indexing and generation pipelines.
    These two pipelines include several parts themselves. Like all software applications,
    production-ready RAG systems require more than just the basic components. We need
    to think about accuracy, observability, scalability, and other important factors.
    This book discusses some of these components at length. Figure 2.4 presents a
    rough layout of a RAG system. Apart from the indexing and generation component,
    we’ll add layers for infrastructure, security, evaluation, etc.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了RAG系统是如何通过索引和生成管道创建的。这两个管道本身也包含几个部分。像所有软件应用一样，生产就绪的RAG系统需要的不仅仅是基本组件。我们需要考虑准确性、可观察性、可扩展性和其他重要因素。本书详细讨论了这些组件。图2.4展示了RAG系统的一个大致布局。除了索引和生成组件外，我们还将添加基础设施、安全、评估等层。
- en: '![A diagram of a company'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![公司的图表'
- en: AI-generated content may be incorrect.](../Images/CH02_F04_Kimothi.png)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH02_F04_Kimothi.png)
- en: Figure 2.4  Components of a production-ready RAG system
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.4  生产就绪的RAG系统组件
- en: 'Let’s look at the main components of a RAG system. The first four components
    complete the indexing pipeline:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看RAG系统的主要组件。前四个组件完成了索引管道：
- en: '*Data-loading componen**t*—Connects to external sources, and extracts and parses
    data'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据加载组件*—连接到外部源，提取和解析数据'
- en: '*Data-splitting componen**t*—Breaks down large pieces of text into smaller,
    manageable parts'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据拆分组件*—将大块文本拆分成更小、更易于管理的部分'
- en: '*Data conversion componen**t*—Converts text data into a more suitable format'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据转换组件*—将文本数据转换为更合适的格式'
- en: '*Storage componen**t*—Stores the data to create a knowledge base for the system'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*存储组件*—存储数据以创建系统的知识库'
- en: 'These next three components complete the generation pipeline:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的三个组件完成了生成管道：
- en: '*Retriever**s*—Responsible for searching and fetching information from the
    storage'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*检索器*—负责从存储中搜索和获取信息'
- en: '*LLM setu**p*—Responsible for generating the response to the input'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*LLM设置*—负责生成对输入的响应'
- en: '*Prompt management*—Enables the augmentation of the retrieved information to
    the original input'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提示管理*—允许增强检索到的信息以匹配原始输入'
- en: The evaluation component measures the accuracy and reliability of the system
    before and after deployment. The monitoring component tracks the performance of
    the RAG system and helps detect failures. Other components include caching, which
    helps store previously generated responses to expedite retrieval for similar queries;
    guardrails, to ensure compliance with policy, regulation, and social responsibility;
    and security, to protect LLMs against breaches such as prompt injection, data
    poisoning, and similar. All the layers are supported by a service infrastructure.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 评估组件在部署前后测量系统的准确性和可靠性。监控组件跟踪RAG系统的性能并帮助检测故障。其他组件包括缓存，有助于存储先前生成的响应以加快类似查询的检索；护栏，以确保符合政策、法规和社会责任；以及安全，以保护LLM免受如提示注入、数据中毒等攻击。所有层都由服务基础设施支持。
- en: All these components are managed and controlled by a central orchestration layer,
    which is responsible for their interaction and sequencing. It provides a unified
    interface for managing and monitoring workflows and processes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些组件都由一个中央编排层管理和控制，该层负责它们的交互和顺序。它提供了一个统一的接口来管理和监控工作流程和过程。
- en: The following sections provide an overview of these components before we examine
    them in depth in subsequent chapters.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨后续章节之前，以下章节提供了这些组件的概述。
- en: 2.3 Indexing pipeline
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 索引管道
- en: We discussed how the indexing pipeline facilitates the creation of the knowledge
    base used in the real-time generation pipeline. For practical purposes, the indexing
    pipeline is an offline or asynchronous pipeline. What this means is that the indexing
    pipeline is not activated in real time when the user is asking a question. Rather,
    it creates the knowledge base in advance and updates it at predefined intervals.
    The indexing pipeline comprises four main components, as seen in figure 2.5.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了索引管道如何促进实时生成管道中使用的知识库的创建。从实际应用的角度来看，索引管道是一个离线或异步管道。这意味着当用户提问时，索引管道不会实时激活。相反，它预先创建知识库并在预定义的时间间隔更新它。索引管道由四个主要组件组成，如图2.5所示。
- en: '![A close-up of a diagram'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图表的特写'
- en: AI-generated content may be incorrect.](../Images/CH02_F05_Kimothi.png)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH02_F05_Kimothi.png)
- en: Figure 2.5  Four components of the indexing pipeline facilitate the creation
    of the knowledge base.
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.5 索引管道的四个组件有助于知识库的创建。
- en: 'Let’s delve deeper into each:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地探讨每个部分：
- en: '*Data splitting (text splitting**)**—*Breaking down text into smaller segments
    enhances the system’s ability to process and analyze information efficiently.
    These smaller pieces in natural language processing (NLP) parlance are commonly
    referred to as “chunks.” The process of splitting large text documents into smaller
    chunks is called “chunking.” We will discuss the need for chunking and various
    chunking strategies in chapter 3.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据拆分（文本拆分**）*——*将文本拆分成更小的片段可以增强系统高效处理和分析信息的能力。在自然语言处理（NLP）术语中，这些较小的片段通常被称为“块”。将大型文本文档拆分成更小块的过程称为“分块”。我们将在第3章中讨论分块的需求和各种分块策略。'
- en: '*Data conversion (embeddings**)**—*Textual data must be converted to a numerical
    format for search and retrieval computations in RAG systems. There are different
    ways of implementing this conversion. For all practical purposes, a data format
    called “embeddings” works best for search and retrieval. You will learn more about
    embeddings and different embedding models in chapter 3.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据转换（嵌入**）*——*在RAG系统中，文本数据必须转换为数值格式，以便进行搜索和检索计算。有几种实现这种转换的方法。从所有实际目的来看，一种称为“嵌入”的数据格式最适合搜索和检索。你将在第3章中了解更多关于嵌入和不同嵌入模型的内容。'
- en: '*Data storag**e**—*Once the data is ready in the desired format (embeddings),
    it needs to be stored in persistent (permanent) memory so that the real-time generation
    pipeline can access data whenever a user asks a question. Data is stored in specialized
    databases known as “vector databases,” which are best suited for search and retrieval
    of embeddings. Chapter 3 explores various vector databases and factors influencing
    their suitability for RAG systems.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据存储*——*一旦数据以所需格式（嵌入）准备好，就需要将其存储在持久（永久）内存中，以便实时生成管道在用户提问时随时访问数据。数据存储在称为“向量数据库”的专用数据库中，这些数据库最适合搜索和检索嵌入。第3章将探讨各种向量数据库及其对RAG系统的适用性影响因素。'
- en: Do you always need an indexing pipeline?
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 你是否总是需要索引管道？
- en: Offline indexing pipelines are typically used when a knowledge base with a large
    amount of data is built for repeated usage (e.g., many enterprise documents, manuals,
    etc.). However, there are some cases in which the generation pipeline connects
    to a third-party API to receive information related to the user question.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 离线索引管道通常用于构建大量数据的知识库，以便重复使用（例如，许多企业文档、手册等）。然而，在某些情况下，生成管道连接到第三方API以接收与用户问题相关的信息。
- en: For example, imagine an application built for users seeking travel advice based
    on the weather forecast. An important component of this application will be fetching
    the weather details for the users’ location. Suppose the system uses a third-party
    API service that can respond with a location’s weather details when provided with
    the location in the input. This weather information is then passed to the LLM
    to generate the advice.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象一个为寻求基于天气预报的旅行建议的用户构建的应用程序。该应用程序的一个重要组成部分将是获取用户位置的天气详情。假设系统使用第三方API服务，当提供输入中的位置时，可以响应位置天气详情。然后，这些天气信息被传递给LLM以生成建议。
- en: This application can also be thought of as a RAG system. But there is a difference.
    This system has outsourced the search and retrieval operation to the third-party
    API. It is the third party that maintains the data. For such systems, the indexing
    pipeline is not required to be built since the search and retrieval happens outside
    the system. Another example is applications that ask the user to input external
    information, like document summarizers. The search operation here is outsourced
    to the user.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这个应用程序也可以被视为一个RAG系统。但有一个区别。这个系统将搜索和检索操作外包给了第三方API。数据由第三方维护。对于此类系统，不需要构建索引管道，因为搜索和检索发生在系统之外。另一个例子是要求用户输入外部信息的应用程序，如文档摘要器。这里的搜索操作外包给了用户。
- en: Therefore, systems that use augment external information to the prompts but
    do not necessarily search and retrieve information themselves, do not warrant
    the creation of a knowledge base, and therefore, do not have an indexing pipeline.
    Some will argue that such systems are not RAG systems in the first place.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，那些使用增强外部信息到提示中但并不一定自行搜索和检索信息的系统，无需创建知识库，因此，没有索引管道。有些人可能会争论，这样的系统根本就不是RAG系统。
- en: 2.4 Generation pipeline
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 生成管道
- en: Building on the foundation established by the indexing pipeline, the generation
    pipeline facilitates real-time interactions in RAG systems. It is the generation
    pipeline that facilitates the retrieval, augmentation, and generation in the system.
    When a user asks a question, the generation pipeline processes the query, retrieves
    relevant information, and generates a response—all without the user directly interacting
    with the underlying indexing pipeline. The generation pipeline is enabled by three
    components, as seen in figure 2.6.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在索引管道建立的基础上，生成管道促进了RAG系统的实时交互。正是生成管道促进了系统中的检索、增强和生成。当用户提问时，生成管道处理查询，检索相关信息，并生成响应——这一切都不需要用户直接与底层索引管道交互。生成管道由三个组件启用，如图2.6所示。
- en: '![A screenshot of a computer'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![计算机屏幕截图'
- en: AI-generated content may be incorrect.](../Images/CH02_F06_Kimothi.png)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是错误的。](../Images/CH02_F06_Kimothi.png)
- en: Figure 2.6  Three components of the generation pipeline enable the real-time
    query-response process of a RAG system.
  id: totrans-88
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.6 生成管道的三个组件使得RAG系统的实时查询-响应过程成为可能。
- en: 'Let’s consider each of these in some more detail:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地考虑这些内容：
- en: '*The retriever—*This is arguably the most critical component of the entire
    system. Using advanced search algorithms, the retriever scans the knowledge base
    to identify and retrieve the most relevant information based on the user’s query.
    The overall effectiveness of the entire system relies heavily on the accuracy
    of the retriever. Also, search is a computationally heavy operation and may take
    time. Therefore, the retriever also contributes heavily to the overall latency
    of the system. We will discuss different retrievers and retrieval strategies in
    chapters 4 and 6.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*检索器*—这可能是整个系统中最关键的部分。使用高级搜索算法，检索器扫描知识库，根据用户的查询识别和检索最相关的信息。整个系统的总体有效性在很大程度上依赖于检索器的准确性。此外，搜索是一个计算密集型操作，可能需要时间。因此，检索器也对系统的总体延迟做出了重大贡献。我们将在第4章和第6章中讨论不同的检索器和检索策略。'
- en: '*Prompt management—*Once the relevant information is retrieved by the retriever,
    it needs to be combined, or augmented, with the original user query. Now, this
    may seem like a simple task at first glance. However, the construction of the
    prompt makes significant difference to the quality of the generated response.
    This component also falls in the gambit of prompt engineering. We will explore
    different prompting and prompt management strategies in chapter 4.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提示管理*—一旦检索器检索到相关信息，就需要将其与原始用户查询结合或增强。乍一看，这似乎是一个简单的任务。然而，提示的构建对生成响应的质量有重大影响。这个组件也属于提示工程的范围。我们将在第4章中探讨不同的提示和提示管理策略。'
- en: '*LLM setu**p**—*At the end, LLMs are responsible for generating the final response.
    A RAG system may rely on more than one LLM. The LLMs can be the foundation (base)
    models that have been pretrained and generally available either open source, like
    those by Meta or Mistral, or through a managed service, like OpenAI or Anthropic.
    LLMs can also be fine-tuned for specific tasks. Fine-tuning involves training
    pre-existing LLMs on specific datasets or tasks to improve performance and adaptability
    for specialized applications. In rare cases, the developer may decide to train
    their LLMs. We will discuss LLMs in depth in chapter 4.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*LLM设置*—最后，LLM负责生成最终响应。RAG系统可能依赖于多个LLM。LLM可以是已经预训练并通常可用的基础模型，例如Meta或Mistral的，或者通过管理服务，如OpenAI或Anthropic。LLM也可以针对特定任务进行微调。微调涉及在特定数据集或任务上训练现有的LLM，以提高性能和适应性，用于专用应用。在罕见的情况下，开发者可能决定训练他们自己的LLM。我们将在第4章中深入讨论LLM。'
- en: 2.5 Evaluation and monitoring
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 评估和监控
- en: Indexing and generation pipelines complete the system from a usage perspective.
    With these two pipelines in place, at least in theory, a user can start interacting
    with the system and get responses. However, in this case, we have no measure of
    the system quality. Is the system performing accurately, or is it still prone
    to hallucinations? Is the information that is being fetched by the retriever the
    most relevant to the query? To answer these questions, we have to put in place
    an evaluation framework. This framework helps in evaluating the quality of the
    system before it is released and then for continuous monitoring and improvement.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 索引和生成管道从使用角度完成了系统。有了这两个管道，至少在理论上，用户可以开始与系统交互并获得响应。然而，在这种情况下，我们没有系统质量的衡量标准。系统是否运行准确，或者它仍然容易产生幻觉？检索器检索到的信息是否与查询最相关？为了回答这些问题，我们必须建立一个评估框架。这个框架有助于在系统发布之前评估其质量，然后进行持续监控和改进。
- en: Building on the advancements of LLMs, RAG represents a recent innovation in
    NLP. Metrics such as relevance scores, recall, and precision are commonly used
    to evaluate the effectiveness of RAG systems. One framework that intuitively guides
    a comprehensive evaluation is the triad of RAG metrics proposed by TruEra ([https://mng.bz/Mw22](https://mng.bz/Mw22)).
    It looks at the RAG evaluation through three dimensions, as shown in
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 建立在LLMs的进步之上，RAG代表了NLP领域的一项最新创新。相关性分数、召回率和精确度等指标通常用于评估RAG系统的有效性。TruEra提出的RAG指标三元组（[https://mng.bz/Mw22](https://mng.bz/Mw22)）提供了一个直观的框架，用于全面评估。它从三个维度来审视RAG评估，如图所示。
- en: figure 2.7.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7。
- en: 'The workflow involves checks in between each step—prompt, context, and answer.
    Let’s take a closer look:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程涉及在每个步骤之间进行检查——提示、上下文和答案。让我们更仔细地看看：
- en: '![A diagram of a customer relationship management'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '![客户关系管理图](../Images/CH02_F07_Kimothi.png)'
- en: AI-generated content may be incorrect.](../Images/CH02_F07_Kimothi.png)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是错误的。](../Images/CH02_F07_Kimothi.png)
- en: Figure 2.7  The triad of RAG evaluation proposed by TruEra. The three pivotal
    dimensions of RAG evaluation are the query, context, and response.
  id: totrans-100
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.7  TruEra提出的RAG评估的三元组。RAG评估的三个关键维度是查询、上下文和响应。
- en: '*Between the retrieved information (context) and the user query (prompt**)**—*Is
    the information being searched and retrieved by the retriever the most relevant
    to the question the user has asked? The consequence of irrelevant information
    being retrieved is that no matter how good the LLM is, if the information being
    augmented is not good, the response will be suboptimal.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在检索到的信息（上下文）和用户查询（提示）之间*——检索器搜索和检索的信息是否与用户提出的问题最相关？检索到不相关信息的结果是，无论LLM有多好，如果增强的信息不好，响应将不会是最优的。'
- en: '*Between the final response (answer) and the retrieved information (context**)*—Does
    the LLM consider all the retrieved information while generating responses? Even'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在最终响应（答案）和检索到的信息（上下文）之间*——在生成响应时，LLM是否考虑了所有检索到的信息？即使'
- en: though RAG is aimed at reducing hallucinations, the system might still ignore
    the retrieved information. There are several reasons for it, which will be discussed
    in subsequent chapters.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管RAG旨在减少幻觉，但系统仍可能忽略检索到的信息。这有几个原因，将在后续章节中讨论。
- en: '*Between the final response (answer) and the user query (prompt**)**—*Is the
    final response in line with the question the user had originally asked? To assess
    the overall effectiveness of the system, the relevance of the final response to
    the original question is necessary.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在最终响应（答案）和用户查询（提示）之间*——最终响应是否与用户最初提出的问题相符？为了评估系统的整体有效性，需要评估最终响应与原始问题的相关性。'
- en: There are several metrics that help assess each of these three dimensions. For
    some of the metrics, a ground truth dataset is warranted. Ground truth datasets
    provide a benchmark for evaluating the accuracy and effectiveness of RAG systems
    by comparing generated responses to manually curated references. We will take
    a deeper look at these metrics and the ground truth dataset in chapter 5\.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个指标有助于评估这三个维度中的每一个。对于某些指标，需要一个基准数据集。基准数据集通过将生成的响应与人工整理的参考进行比较，为评估RAG系统的准确性和有效性提供了一个基准。我们将在第5章中更深入地探讨这些指标和基准数据集。
- en: Continuous evaluation of metrics during live operation can identify the types
    of queries the system struggles to answer accurately. Qualitative feedback can
    also be collected from the user on the generated responses.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在实时操作期间对指标进行持续评估可以识别系统难以准确回答的查询类型。还可以从用户那里收集对生成的响应的定性反馈。
- en: 2.6 The RAGOps Stack
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.6 RAGOps堆栈
- en: 'RAG, and LLM-based apps in general, are being powered by an evolving operations
    stack. Various providers offer infrastructure components such as data storage
    platforms, model hosting services, and application orchestration frameworks. The
    infrastructure can be understood in several layers:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: RAG以及基于LLM的应用正在由一个不断发展的操作堆栈提供支持。各种提供商提供基础设施组件，例如数据存储平台、模型托管服务和应用程序编排框架。该基础设施可以理解为几个层次：
- en: '*Data laye**r*—Tools and platforms used to process and store data in the form
    of embeddings'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*数据层*—用于处理和存储以嵌入形式的数据的工具和平台'
- en: '*Model laye**r*—Providers of proprietary or open source LLMs'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*模型层*—提供专有或开源LLM的提供商'
- en: '*Prompt laye**r*—Tools offering maintenance and evaluation of prompts'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*提示层*—提供提示维护和评估的工具'
- en: '*Evaluation laye**r*—Tools and frameworks providing evaluation metrics for
    RAG'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*评估层*—提供RAG评估指标的工具和框架'
- en: '*App orchestratio**n*—Frameworks that facilitate invocation of different components
    of the system'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*应用编排*—促进系统不同组件调用的框架'
- en: '*Deployment laye**r*—Cloud providers and platforms for deploying RAG apps'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*部署层*—提供部署RAG应用的云提供商和平台'
- en: '*Application laye**r*—Hosting services for RAG apps'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*应用层*—RAG应用的托管服务'
- en: '*Monitoring laye**r*—Platforms offering continuous monitoring of RAG apps'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*监控层*—提供对RAG应用持续监控的平台'
- en: Chapter 7 explores the various layers of infrastructure that support RAG systems.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 第7章探讨了支持RAG系统的各种基础设施层。
- en: 2.7 Caching, guardrails, security, and other layers
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.7 缓存、安全护栏和其他层
- en: Finally, there are certain other components frequently used in RAG systems.
    These components address the problems of system latency, regulatory and ethical
    compliances among other aspects.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，还有一些在RAG系统中经常使用的其他组件。这些组件解决了系统延迟、监管和道德合规等问题。
- en: '*Cachin**g*—Caching is the process in which certain data is stored in cache
    memory for faster retrieval. LLM caching is slightly different from regular caching.
    The LLM responses to queries are stored in a semantic cache. Next time a similar
    query is asked, the response from the cache is retrieved instead of sending the
    query through the complete RAG pipeline. This approach improves the performance
    of the system by reducing the time it takes to respond, the cost of LLM inferencing,
    and the load on the LLM service.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*缓存*—缓存是将某些数据存储在缓存内存中以实现更快检索的过程。LLM缓存与常规缓存略有不同。LLM对查询的响应存储在语义缓存中。下次提出类似查询时，将检索缓存中的响应，而不是将查询通过完整的RAG管道发送。这种方法通过减少响应时间、LLM推理成本和LLM服务负载来提高系统性能。'
- en: '*Guardrail**s*—For several use cases, in practice, there will be a set of boundaries
    within which the output needs to be generated. Guardrails are a predefined set
    of rules added in the system to comply with policies, regulations, and ethical
    guidelines.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*安全护栏*—对于几个用例，在实践中，将有一组输出需要生成的边界。安全护栏是在系统中添加的预定义规则集，以符合政策、法规和道德指南。'
- en: '*Securit**y*—LLMs and LLM-based applications have witnessed new threats, such
    as prompt injections, data poisoning, sensitive information disclosure, and others.
    With evolving threats, the security infrastructure also needs to evolve to address
    concerns around security and data privacy of RAG systems.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*安全*—LLM和基于LLM的应用已经见证了新的威胁，例如提示注入、数据中毒、敏感信息泄露等。随着威胁的发展，安全基础设施也需要发展以解决关于RAG系统安全和数据隐私的担忧。'
- en: RAGOps has also been evolving fast. Logging and tracing, model versioning, and
    feedback layers are some of the RAGOps stack components.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: RAGOps也在快速发展。日志记录和跟踪、模型版本控制和反馈层是RAGOps堆栈的一些组件。
- en: This chapter provided an overview of the key components of RAG systems, including
    the indexing and generation pipelines, evaluation and monitoring, and service
    infrastructure. By understanding these components, you are now equipped to delve
    deeper into each of these components and the intricacies of RAG systems in subsequent
    chapters. In the next chapter, we will start building the indexing pipeline to
    create a knowledge base of our RAG system.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了RAG系统的主要组件，包括索引和生成管道、评估和监控以及服务基础设施。通过理解这些组件，你现在已经准备好在后续章节中深入探讨每个组件以及RAG系统的复杂性。在下一章中，我们将开始构建索引管道，以创建我们RAG系统的知识库。
- en: Summary
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'A RAG-enabled system consists of two main pipelines: the indexing and the generation
    pipeline.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个RAG启用系统由两个主要管道组成：索引管道和生成管道。
- en: The indexing pipeline is responsible for creating and maintaining the knowledge
    base, which involves data loading, text splitting, data conversion (embeddings),
    and data storage in a vector database.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引管道负责创建和维护知识库，这包括数据加载、文本分割、数据转换（嵌入）以及在向量数据库中的数据存储。
- en: The generation pipeline manages real-time interactions by retrieving information,
    augmenting queries, and generating responses using an LLM.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成管道通过检索信息、增强查询和使用大型语言模型（LLM）生成响应来管理实时交互。
- en: Evaluation and monitoring are crucial components for the assessment of system
    performance, covering the relevance between the retrieved information and query,
    the final response and retrieved information, and the final response and the original
    query.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估和监控是评估系统性能的关键组件，涵盖了检索信息与查询之间的相关性、最终响应与检索信息之间的相关性，以及最终响应与原始查询之间的相关性。
- en: The service infrastructure for RAG systems includes layers for data, models,
    prompts, evaluation, app orchestration, deployment, application hosting, and monitoring.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG系统的服务基础设施包括数据、模型、提示、评估、应用编排、部署、应用托管和监控等层。
- en: Additional components such as caching, guardrails, and security measures are
    often employed to improve performance, ensure compliance, and address potential
    threats.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了提高性能、确保合规性和应对潜在威胁，通常会采用额外的组件，如缓存、安全网和安全措施。
