- en: 6 The fine print
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 详细说明
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Controversial and timely discussions around AI
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 围绕人工智能的争议性和及时性讨论
- en: Copyright disputes regarding training data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据相关的版权争议
- en: The economics of AI
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能的经济学
- en: Exaggeration about AI’s performance and advancements
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对人工智能性能和进步的夸张
- en: AI regulation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能监管
- en: Consumption of resources, such as electricity and water, to train and use AI
    models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和使用人工智能模型所需的资源消耗，如电力和水
- en: The philosophical debate around AI, biological brains, and consciousness
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 围绕人工智能、生物大脑和意识的哲学辩论
- en: This chapter addresses some of the bigger questions around AI. It also reveals
    a less flattering AI side—how the field often suffers from exaggeration, speculation,
    and even deception. I think it’s important to be informed about these topics,
    so you can analyze AI announcements and discussions critically. In addition, if
    you’re building AI-based products or using AI intensively, you may want to be
    aware of the broader effects and potential controversies that could arise from
    your work.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了人工智能的一些重大问题。它还揭示了一个不太令人愉快的 AI 方面——该领域经常受到夸张、推测甚至欺骗的影响。我认为了解这些话题很重要，这样你可以批判性地分析人工智能的公告和讨论。此外，如果你正在开发基于人工智能的产品或大量使用人工智能，你可能想了解你的工作可能产生的更广泛的影响和潜在争议。
- en: Copyright
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 版权
- en: Large AI models, such as LLMs and text-to-image models, have been trained using
    data collected from the internet, or *scraped,* most often without authorization
    from its owners. This includes millions of documents, images, and books, which
    has made many people angry, and there have been many lawsuits against AI providers.
    One example is a lawsuit from Getty Images, a website that sells stock images,
    against Stability AI, which creates the Stable Diffusion text-to-image models.
    Getty Images argues that Stability AI used images collected from Getty’s website
    without authorization to train its models. The complaint shows images generated
    by Stability AI’s models, which are similar to those sold on Getty. In some cases,
    the AI model even generates images with a rough imitation of Getty Images’ watermark
    (see figure 6.1).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大型人工智能模型，如 LLM 和文本到图像模型，是使用从互联网收集的数据或 *抓取* 训练的，通常未经所有者授权。这包括数百万份文档、图片和书籍，这让许多人感到愤怒，并对人工智能提供商提起了许多诉讼。一个例子是
    Getty Images（一个销售库存图片的网站）对 Stability AI（创建 Stable Diffusion 文本到图像模型的公司）提起的诉讼。Getty
    Images 认为 Stability AI 在未经授权的情况下使用从 Getty 网站收集的图片来训练其模型。投诉展示了 Stability AI 模型生成的图片，这些图片与
    Getty 销售的图片相似。在某些情况下，AI 模型甚至生成了带有 Getty Images 水印粗糙仿制的图片（见图 6.1）。
- en: '![](../Images/CH06_F01_Maggiori.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH06_F01_Maggiori.jpg)'
- en: 'Figure 6.1  Left: Image sold on Getty Images’ website. Right: Image generated
    by a Stable Diffusion model. Note the watermark in the image. These images are
    reproduced from Getty Images (US), Inc. v. Stability AI, Inc., 1:23-cv-00135,
    (D. Del.)*.*'
  id: totrans-13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 6.1  左：在 Getty Images 网站上销售的图片。右：由 Stable Diffusion 模型生成的图片。注意图片中的水印。这些图片是从
    Getty Images (US), Inc. v. Stability AI, Inc., 1:23-cv-00135, (D. Del.)*.* 中复制的。
- en: A similar lawsuit was filed by *The* *New York Times* against OpenAI on the
    grounds that newspaper articles were scraped without authorization to train OpenAI’s
    models. The complaint contains examples of large portions of text outputted by
    GPT-4, which are verbatim reproductions of text found in *The New York Times*
    (see figure 6.2).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*《纽约时报》* 对 OpenAI 提起了一项类似的诉讼，理由是未经授权抓取报纸文章来训练 OpenAI 的模型。投诉中包含了 GPT-4 输出的大量文本示例，这些文本是
    *《纽约时报》* 中找到的文本的逐字复制（见图 6.2）。'
- en: '![](../Images/CH06_F02_Maggiori.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH06_F02_Maggiori.png)'
- en: Figure 6.2  Example of GPT-4 output (almost) verbatim text as published by The
    New York Times. Figure reproduced from The New York Times Company v. Microsoft
    Corporation, 1:23-cv-11195, (S.D.N.Y.).
  id: totrans-16
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 6.2  GPT-4 输出的示例（几乎）逐字文本，如《纽约时报》所发布。图来自 The New York Times Company v. Microsoft
    Corporation, 1:23-cv-11195, (S.D.N.Y.)。
- en: In addition, a group of artists sued Midjourney, Stability AI, and other image-generation
    providers for using images of the plaintiffs’ work to train their models. They
    argue this allows the models to generate images “in the style of” the plaintiffs
    ([https://mng.bz/ZlKa](https://mng.bz/ZlKa)). It is likely that many other copyright
    infringement allegations will be made against AI providers in the future.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一群艺术家起诉了 Midjourney、Stability AI 和其他图像生成提供商，因为他们使用了原告作品的图片来训练他们的模型。他们认为这允许模型生成“原告风格”的图片
    ([https://mng.bz/ZlKa](https://mng.bz/ZlKa))。未来很可能会对人工智能提供商提出许多其他版权侵权指控。
- en: 'Copyright infringement is usually alleged on two grounds:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 版权侵权通常基于两个理由：
- en: AI models sometimes reproduce verbatim content.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能模型有时会逐字复制内容。
- en: AI providers use copyrighted data without authorization to train models.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能服务提供商未经授权使用受版权保护的数据来训练模型。
- en: Verbatim reproductions happen when a model memorizes training data, which is
    a result of overfitting. It is likely that AI providers will try to minimize this
    by using techniques to prevent overfitting. It’s hard to guarantee that no memorization
    will happen, but it might be mitigated successfully.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型记住训练数据，这是过度拟合的结果时，就会发生逐字复制。人工智能服务提供商可能会通过使用防止过度拟合的技术来尽量减少这种情况。很难保证不会发生记忆，但可能成功减轻。
- en: The second point—that data is used to train models without authorization—is
    more controversial and seems to be the crux of the problem. Supporters of AI providers
    argue that it isn’t a copyright violation. They think it is legitimate to scrape
    data to train a model because the goal is for the model to learn patterns and
    associations from data, not to reproduce a verbatim copy of the data (even if
    that has happened in some unfortunate cases).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 第二点——未经授权使用数据来训练模型——更具争议性，似乎也是问题的核心。人工智能服务提供商的支持者认为这并不构成版权侵犯。他们认为从数据中抓取信息来训练模型是合法的，因为目标是让模型从数据中学习模式和关联，而不是复制数据的逐字逐句（即使不幸地发生了这种情况）。
- en: I’ve even heard some people argue that us humans learn from reading publicly
    available data, and we then use that knowledge to create our own work. So, why
    wouldn’t AI providers be able to do the same?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我甚至听说有些人认为我们人类通过阅读公开可用的数据来学习，然后我们使用这些知识来创造我们自己的作品。那么，为什么人工智能服务提供商不能做同样的事情呢？
- en: The key to this conundrum hinges on the topic of *fair use.* In copyright law,
    it is considered that copying data without authorization is fair in some circumstances.
    This includes copying the data to help build a product that does not replace or
    compete against the original product. For example, throughout this book, I have
    reproduced quotations from other books. I never reached out to their authors to
    ask for permission. This is considered fair use because my quotations don’t make
    this book compete against the other books, and the original author of the quotation
    is clearly attributed. In chapter 1, for instance, I quoted a paragraph from the
    book *The Elements of Statistical Learning.* However, this book covers a different
    topic, so it doesn’t intend to compete with it, stealing some of its customers.
    In fact, I may actually drive some publicity toward that book by mentioning it.
    Had I copied an entire chapter of that book, however, this wouldn’t be considered
    fair use because my book could become a replacement for it. There are no exact
    guidelines on what constitutes fair use, such as a precise number of words in
    a quotation, so this is usually determined case by case in a dispute resolution.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个难题的关键在于*合理使用*这个话题。在版权法中，在某些情况下，未经授权复制数据被认为是合理的。这包括复制数据以帮助构建不取代或与原始产品竞争的产品。例如，在这本书中，我引用了其他书籍的引文。我从未联系过这些书籍的作者请求许可。这被认为是合理使用，因为我的引用并没有使这本书与其他书籍竞争，并且引用的原始作者被明确标注。例如，在第1章中，我引用了《统计学习元素》一书的段落。然而，这本书涉及不同的主题，所以它并不打算与之竞争，窃取其客户。事实上，我可能通过提及它实际上为那本书带来了宣传。然而，如果复制了那本书的整个章节，这就不被认为是合理使用，因为我的书可能成为它的替代品。关于什么构成合理使用没有确切的规定，例如引用中精确的单词数，所以这通常在争议解决中逐案确定。
- en: The lawsuits by Getty Images and *The New York Times* attempted to establish
    that scraping their data by AI providers was not fair use because they used it
    to build competing products. This allegation is particularly easy to visualize
    in the case of image generation—one can imagine that customers of Getty Images
    may use Stable Diffusion instead to create images.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Getty Images和《纽约时报》提起的诉讼试图确立，人工智能服务提供商抓取他们的数据不是合理使用，因为他们用它来构建竞争产品。在图像生成的情况下，这一点尤其容易可视化——可以想象Getty
    Images的客户可能会使用Stable Diffusion来创建图像。
- en: As Getty Images argues ([https://mng.bz/RVgO](https://mng.bz/RVgO)),
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如Getty Images所辩称（[https://mng.bz/RVgO](https://mng.bz/RVgO)），
- en: Stability AI has copied at least 12 million copyrighted images from Getty Images’
    websites. . . . Stability AI now competes directly with Getty Images.
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Stability AI已从Getty Images网站上复制了至少1200万张受版权保护的图片……Stability AI现在与Getty Images直接竞争。
- en: '*The New York Times* lawsuit also tries to establish that OpenAI’s models act
    as a replacement to the newspaper’s website ([https://mng.bz/2yvm](https://mng.bz/2yvm)):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 《纽约时报》的诉讼还试图确立OpenAI的模型作为报纸网站的替代品([https://mng.bz/2yvm](https://mng.bz/2yvm))：
- en: Defendants insist that their conduct is protected as “fair use” because their
    unlicensed use of copyrighted content to train GenAI models serves a new “transformative”
    purpose. But there is nothing “transformative” about using *The Times*’s content
    without payment to create products that substitute for *The Times* and steal audiences
    away from it.
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 被告坚持认为，他们的行为应被视为“合理使用”受到保护，因为他们的未经许可使用受版权保护的内容来训练GenAI模型服务于一个新的“转换”目的。但是，使用《泰晤士报》的内容而不支付费用来创建替代《泰晤士报》并从其那里吸引受众的产品，并没有什么“转换”之处。
- en: As of this writing, these disputes haven’t been settled. We’ll see what happens
    in court.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 到我写这篇文章的时候，这些争议还没有得到解决。我们将看看法庭上会发生什么。
- en: I think one likely outcome from successive disputes is that regulators will
    request AI providers to honor opt-out requests—if a data owner doesn’t want their
    data used to train AI models, it shouldn’t be used. The data owner will have to
    indicate their wish to opt out through machine-readable metadata in an agreed
    format. This is how it works if you don’t want search engines to scrape and index
    your content. You must specify so in a text file called robots.txt, returned upon
    request to your root domain (e.g., [example.com/robots.txt](http://example.com/robots.txt)).
    In a special format, the file describes which sections of the website are allowed
    to be scraped and by whom. All major search engines honor the protocol.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为连续的争议可能的一个结果是，监管机构将要求AI提供商尊重退出的请求——如果数据所有者不希望他们的数据用于训练AI模型，则不应使用。数据所有者必须通过在约定格式中的机器可读元数据中表明他们希望退出的意愿。这就是如果你不希望搜索引擎抓取和索引你的内容时的工作方式。你必须在一个名为robots.txt的文本文件中指定这一点，该文件在请求你的根域名时返回（例如，[example.com/robots.txt](http://example.com/robots.txt)）。该文件以特殊格式描述了哪些网站部分允许被抓取以及由谁抓取。所有主要搜索引擎都遵守此协议。
- en: 'A different controversy is whether AI-generated content is itself protected
    by copyright law. For example, if you generate an image using Midjourney, can
    you prevent others from reproducing the AI-generated image, as it’s a violation
    of *your* copyright? The Copyright Alliance argues that work solely generated
    by AI is not protected by copyright. However, it clarifies ([https://mng.bz/1Xnn](https://mng.bz/1Xnn)):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个争议是AI生成的内容本身是否受版权法保护。例如，如果你使用Midjourney生成一个图像，你能阻止他人复制AI生成的图像吗，因为这侵犯了你的版权？版权联盟认为，仅由AI生成的作品不受版权保护。然而，它澄清了([https://mng.bz/1Xnn](https://mng.bz/1Xnn))：
- en: If a work contains both AI-generated elements and elements of human authorship
    protectable by copyright law—such as human-authored text or a human’s minimally
    creative arrangement, selection, and coordination of various parts of the work—the
    elements of the work that are protected by copyright would be owned by the human
    author.
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果一部作品既包含由AI生成的元素，也包含受版权法保护的人类创作元素——例如人类创作的文本或人类对作品各部分的最小创造性安排、选择和协调——那么受版权保护的作品元素将归人类作者所有。
- en: I’m not quite sure what this means. If I use Midjourney to generate an image,
    is the work solely generated by AI, or am I the work’s coordinator because I wrote
    and refined the prompt? Perhaps the Copyright Alliance doesn’t know yet, as it
    adds after that paragraph, “AI and copyright issues will continue to develop,”
    and it invites you to sign up for the newsletter on AI copyright to stay up to
    date.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我不太确定这是什么意思。如果我使用Midjourney生成一个图像，这个作品是完全由AI生成的，还是因为我编写和改进了提示而我是作品的组织者？也许版权联盟还不知道，因为它在那一部分之后补充说，“AI和版权问题将继续发展”，并邀请您订阅AI版权通讯以保持最新。
- en: Economics of AI
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能的经济
- en: Since the boom of generative AI, we hear a lot about its potential economic
    rewards. By the sounds of it, a lot of people will make a lot of money thanks
    to AI. But is that so?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 自从生成式AI的兴起以来，我们听到了很多关于其潜在经济回报的消息。听起来，很多人将因为AI而赚很多钱。但情况真的是这样吗？
- en: Some AI providers are already collecting billions in revenue. In 2024, for example,
    OpenAI generated $3.7 billion. This is quite impressive for such a young company.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一些AI提供商已经收入数百亿美元。例如，到2024年，OpenAI创造了37亿美元。对于一个如此年轻的公司来说，这相当令人印象深刻。
- en: But revenue is not enough to build a successful business in the long run. For
    that, a business must become profitable—it must collect more revenue than it spends
    on generating it. Otherwise, it can’t pay the bills unless there’s a continued
    injection of cash from investors to subsidize its losses.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 但从长远来看，收入并不足以建立一个成功的企业。为了做到这一点，企业必须盈利——它必须收集比产生收入所花费的更多的收入。否则，除非有投资者持续注入资金来补贴其亏损，否则它无法支付账单。
- en: In 2024, OpenAI *lost* $5 billion. While its $3.7-billion revenue was impressive,
    it wasn’t enough to cover its even more impressive expenses ([https://mng.bz/PdMv](https://mng.bz/PdMv)).
    This was likely related to the high costs of training and serving large AI models.
    Some people have estimated that running ChatGPT might cost OpenAI $700,000 a day
    ([https://mng.bz/JYna](https://mng.bz/JYna)). Training GPT-4 is said to have cost
    the company $100 million ([https://mng.bz/wJma](https://mng.bz/wJma)). Note that
    some models are retrained periodically with new data, so model training is not
    always a one-off expense. The other major AI providers, such as Anthropic and
    Mistral, are also still unprofitable.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 2024年，OpenAI亏损了50亿美元。虽然其37亿美元的营收令人印象深刻，但这并不足以覆盖其更令人印象深刻的支出（[https://mng.bz/PdMv](https://mng.bz/PdMv)）。这很可能与训练和提供大型AI模型的高成本有关。有人估计，运行ChatGPT可能每天要花费OpenAI
    70万美元（[https://mng.bz/JYna](https://mng.bz/JYna)）。据说训练GPT-4的成本为该公司1亿美元（[https://mng.bz/wJma](https://mng.bz/wJma)）。请注意，一些模型会定期用新数据进行重新训练，因此模型训练并不总是一次性支出。其他主要AI提供商，如Anthropic和Mistral，也仍然没有盈利。
- en: In addition to becoming profitable, a business is successful if it generates
    *good* profits—investors want good bang for their buck. In a competitive market,
    profits tend be eroded over time because copycats enter the market, pushing costs
    up and prices down, so it’s hard to make consistently good profits. The latter
    requires a *moat,* also known as a *competitive advantage,* which is a feature
    that protects a company’s market share from competitors. When a business benefits
    from a moat, competitors can’t enter the market on equal terms, so it’s hard or
    too expensive for them to eat into your market share.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 除了盈利之外，一个企业如果能够产生**良好**的利润，那么它才算得上是成功的——投资者希望他们的投资能够得到良好的回报。在竞争激烈的市场中，利润往往会随着时间的推移而逐渐被侵蚀，因为模仿者进入市场，推高了成本并降低了价格，因此很难持续获得良好的利润。后者需要一道**护城河**，也称为**竞争优势**，这是一种保护公司市场份额不受竞争对手侵害的特性。当一个企业从护城河中获益时，竞争对手无法在同等条件下进入市场，因此他们很难或成本过高来侵蚀你的市场份额。
- en: AI providers don’t seem to have a strong moat protecting their market shares.
    In particular, the methodology behind LLMs (the transformer architecture discussed
    in chapter 1) is publicly known, so others can build their own competing models.
    AI providers are a bit uneasy about this. In May 2023, a leaked Google memo said,
    “We have no moat and neither does OpenAI. . . . The uncomfortable truth is, we
    aren’t positioned to win this arms race and neither is OpenAI. . . .While our
    AI still holds a slight edge in terms of quality, the gap is closing astonishingly
    quickly. Open-source AI is faster, more customizable, more private, and pound-for-pound
    more capable.” The memo also admitted, “We have no secret sauce,” and it suggested,
    “People will not pay for restricted AI when free, unrestricted alternatives are
    comparable in quality. We should consider where our value add really is” (Emmanuel
    Maggiori, 2024, *Siliconned*).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 似乎AI提供商并没有强大的护城河来保护他们的市场份额。特别是，LLMs（第1章中讨论的变换器架构）背后的方法论是公开的，因此其他人可以构建自己的竞争模型。AI提供商对此感到有些不安。2023年5月，一份泄露的谷歌备忘录表示：“我们没有护城河，OpenAI也没有。…令人不舒服的真相是，我们并没有处于赢得这场军备竞赛的优势地位，OpenAI也没有。…虽然我们的AI在质量上仍然略占优势，但差距正在惊人地迅速缩小。开源AI更快，更可定制，更私密，并且按性能和功能来看，每一点都更强大。”备忘录还承认：“我们没有秘密配方”，并建议：“当有免费、无限制的替代品在质量上相当时，人们不会为受限的AI付费。我们应该考虑我们的真正价值在哪里”（埃马纽埃尔·马吉奥里，2024年，《硅化》）。
- en: Because there’s no secret sauce, the models created by different providers are
    already converging in terms of performance and capabilities, including open source
    ones. It is conceivable that there will be a market shake-up at some point—some
    companies may go out of business or discontinue their products. The economic case
    for developing large AI models is not as clear as it may seem initially.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有秘密配方，不同提供商创建的模型在性能和能力方面已经趋于一致，包括开源模型。可以预见，在某个时刻可能会发生市场动荡——一些公司可能会倒闭或停止其产品。开发大型AI模型的经济案例并不像最初看起来那么清晰。
- en: In addition to the big players, numerous smaller companies are building AI-based
    products, which are built on top of foundation models—some people call them “AI
    wrappers.” For example, there are tens of companies that offer an AI tool to turn
    an ordinary picture of you into a professional-looking headshot. These tools are
    likely a thin layer added on top of a publicly available AI model such as Stable
    Diffusion, or perhaps a fine-tuned version of one of them. This might seem like
    a winning business idea at first because you’re genuinely making it easy to create
    headshots for people. However, there is no moat—the “secret sauce” of these apps
    is the prompt which, unless it’s very special, others will probably be able to
    come up with too. So, competition multiplies, as we can already see from the multiple
    apps offering similar functionality. It will be hard for these thin businesses
    to generate significant profits.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 除了大公司之外，许多较小的公司正在构建基于AI的产品，这些产品建立在基础模型之上——有些人称它们为“AI包装器”。例如，有数十家公司提供AI工具，可以将你的普通照片转换成专业的头像。这些工具可能只是添加在公开可用的AI模型（如Stable
    Diffusion）之上的一层薄薄的外壳，或者可能是其中之一经过微调的版本。这最初可能看起来像是一个成功的商业想法，因为你确实让人们创建头像变得容易。然而，这里没有护城河——“这些应用的秘诀”是提示词，除非它非常特别，否则其他人可能也能想出来。因此，竞争加剧，正如我们从提供类似功能的多个应用程序中已经看到的那样。这些薄利的企业要产生显著的利润将非常困难。
- en: 'Finally, much has been said about a dramatic increase in business productivity
    thanks to the use of AI tools. In 2023, McKin­sey shared the following estimates
    ([https://mng.bz/qxz6](https://mng.bz/qxz6)):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，关于使用AI工具大幅提高商业生产力的说法已经很多。2023年，麦肯锡分享了以下估计（[https://mng.bz/qxz6](https://mng.bz/qxz6)）：
- en: Generative AI’s impact on productivity could add trillions of dollars in value
    to the global economy. Our latest research estimates that generative AI could
    add the equivalent of $2.6 trillion to $4.4 trillion annually across the 63 use
    cases we analyzed—by comparison, the United Kingdom’s entire GDP in 2021 was $3.1
    trillion.
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 生成式AI对生产力的影响可能为全球经济增加数万亿美元的价值。我们最新的研究估计，在63个我们分析的应用案例中，生成式AI每年可能增加2.6万亿美元至4.4万亿美元的价值——相比之下，2021年英国的国内生产总值（GDP）为3.1万亿美元。
- en: 'But productivity increases have been pretty much undetectable so far. A 2024
    *Economist* article explains:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 但生产力的增长到目前为止几乎无法检测到。2024年《经济学人》的一篇文章解释说：
- en: Macroeconomic data . . . show little evidence of a surge in productivity . .
    . In America, the global centre of AI, output per hour remains below its pre-2020
    trend. Even in global data derived from surveys of purchasing managers, which
    are produced with a shorter lag, there is no sign of a productivity surge. (“What
    happened to the artificial-intelligence revolution?” 2024, July 2, The Economist)
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 宏观经济数据……几乎没有显示出生产力的激增迹象……在美国，作为全球AI中心的美国，每小时的产出仍然低于2020年之前的趋势。即使在采购经理调查产生的全球数据中，这些数据滞后较短，也没有显示出生产力激增的迹象。（“人工智能革命怎么了？”2024年7月2日，《经济学人》）
- en: The article also explains that the rate of adoption of AI in the business world
    has been very slow due to “concerns about data security, biased algorithms and
    hallucinations.” It concludes, “So far the technology has had almost no economic
    impact.” Indeed, it seems that implementing AI in business is harder than it may
    initially seem. Someone recently told me that the problem was the “last mile”—while
    AI can help you do the initial 80% of a job just fine, it’s hard to make it complete
    the remaining 20% well because of hallucinations or the need for painstaking customization.
    This makes productivity gains less impressive than promised.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 文章还解释说，由于“对数据安全、有偏见的算法和幻觉”的担忧，商业世界中AI的采用率一直非常缓慢。它总结道：“到目前为止，这项技术几乎没有任何经济影响。”确实，似乎在商业中实施AI比最初看起来要困难得多。有人最近告诉我，问题是“最后一公里”——虽然AI可以帮助你完成工作的前80%，但由于幻觉或需要痛苦的定制，很难让它很好地完成剩余的20%。这使得生产力的提升不如承诺的那样引人注目。
- en: So, I advise you to be cautious when you hear big statements about AI’s economic
    benefits. The jury is still out.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我建议你在听到关于AI经济收益的大话时要谨慎。结果尚未明朗。
- en: Smoke and mirrors
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 烟雾和幻影
- en: In November 2023, it was revealed that self-driving cars produced by Cruise
    weren’t quite driving themselves. An army of human operators in a remote-control
    room manually intervened when the cars faced problems. This happened once every
    2.5 to 5 miles of driving. The company had 1.5 employees doing this job for every
    car on the streets ([https://mng.bz/7pM7](https://mng.bz/7pM7)). Business professor
    Thomas W. Malone said, “It may be cheaper just to pay a driver to sit in the car
    and drive it” ([https://mng.bz/mGpW](https://mng.bz/mGpW)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年11月，有消息透露，Cruise公司生产的自动驾驶汽车并不能完全自动驾驶。当汽车遇到问题时，远程控制室里的一群人类操作员会手动干预。这种情况每行驶2.5到5英里就会发生一次。该公司为每辆在路上的汽车配备了1.5名员工来做这项工作（[https://mng.bz/7pM7](https://mng.bz/7pM7)）。商业教授托马斯·W·马龙说：“可能只是支付司机坐在车里驾驶会更便宜”
    ([https://mng.bz/mGpW](https://mng.bz/mGpW))。
- en: A few months later, Waymo, which is Cruise’s main competitor, explained in a
    blog article, “Much like phone-a-friend, when the Waymo vehicle encounters a particular
    situation on the road, the autonomous driver can reach out to a human fleet response
    agent for additional information to contextualize its environment” ([https://waymo.com/blog/2024/05/fleet-response/](https://waymo.com/blog/2024/05/fleet-response/)).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 几个月后，Cruise 的主要竞争对手 Waymo 在一篇博客文章中解释说：“就像拨打朋友电话一样，当 Waymo 的车辆在道路上遇到特定情况时，自动驾驶驾驶员可以联系人类车队响应代理以获取更多信息，以对其环境进行上下文化”
    ([https://waymo.com/blog/2024/05/fleet-response/](https://waymo.com/blog/2024/05/fleet-response/))。
- en: Something similar happened with Amazon’s “just walk out” technology, installed
    in Amazon’s supermarkets. This technology allegedly used AI to automatically prepare
    your shopping receipt based on footage from cameras installed on the ceiling.
    In April 2024, a reporter revealed that 1,000 remote workers in India were watching
    the videos and manually preparing or adjusting at least 70% of receipts ([https://mng.bz/5gX8](https://mng.bz/5gX8)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊的“直接出门”技术也发生了类似的事情，这项技术被安装在了亚马逊的超市里。据称，这项技术利用AI根据安装在天花板上的摄像头拍摄的画面自动准备购物收据。2024年4月，一名记者揭露，印度有1000名远程工作人员在观看视频，并手动准备或调整至少70%的收据（[https://mng.bz/5gX8](https://mng.bz/5gX8)）。
- en: The use of humans to secretly power AI is often compared to the Mechanical Turk,
    a fraudulent machine constructed in 1770, which seemed to play chess by itself
    when, in reality, a human secretly powered it. The machine was exhibited on tours
    for 84 years.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用人类秘密地驱动AI的做法常被比作1770年建造的机械 Turk，这个欺诈性的机器似乎能自己下棋，但实际上是由人类秘密地操作的。这台机器在巡展中展出了84年。
- en: The AI field is plagued with big promises, hype, and exaggeration. Mechanical
    Turks are just one example of this—exaggeration and deception come in different
    forms. In April 2023, for example, Google executives claimed that one of their
    AI models had learned the Bengali language even though it hadn’t been trained
    on Bengali-language text. One of them explained, “We discovered that with very
    few amounts of prompting in Bengali, it can now translate all of Bengali” ([https://futurism.com/the-byte/google-ai-bengali).They](https://futurism.com/the-byte/google-ai-bengali).They)
    argued that this was an example of AI having “emergent properties.”
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能领域充斥着大承诺、炒作和夸张。机械 Turk 只是其中的一个例子——夸张和欺骗以不同的形式出现。例如，2023年4月，谷歌高管声称他们的一款 AI
    模型已经学会了孟加拉语，尽管它并没有在孟加拉语文本上进行过训练。其中一位高管解释说：“我们发现，在孟加拉语中只有很少的提示，现在它可以翻译所有的孟加拉语”
    ([https://futurism.com/the-byte/google-ai-bengali](https://futurism.com/the-byte/google-ai-bengali))。他们认为这是一个
    AI 具有“涌现特性”的例子。
- en: The news went viral. An Indian newspaper pondered, “AI learns Bengali on its
    own, should we be worried?” ([https://mng.bz/6eyp](https://mng.bz/6eyp)). Someone
    who heard about this news reached out to me asking if I thought we might soon
    face a “singularity event”—a dramatic explosion of AI’s capabilities—since now
    AI could learn new stuff on its own.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这条新闻迅速传播开来。一家印度报纸思考道：“AI自己学会了孟加拉语，我们应该担心吗？” ([https://mng.bz/6eyp](https://mng.bz/6eyp))。一位听到这个新闻的人联系我，问我是否认为我们可能很快会面临一个“奇点事件”——AI能力的戏剧性爆炸——因为现在AI可以自己学习新东西。
- en: With an understanding of how current AI works (see chapter 1), it’s hard to
    believe it could easily learn a new language that is not part of its training
    data. As it turns out, Bengali was indeed one of the languages the model was trained
    on, contrary to what the Google executives had said ([https://mng.bz/oKYy](https://mng.bz/oKYy)).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了当前AI的工作原理（见第1章）后，很难相信它能够轻易地学习不属于其训练数据的新语言。结果证明，孟加拉语确实是该模型训练的语言之一，这与谷歌高管所说的相反（[https://mng.bz/oKYy](https://mng.bz/oKYy)）。
- en: More recently, in September 2024, OpenAI launched a new model called OpenAI
    o1\. The company framed it as a model capable of “thinking” and “reasoning.” The
    announcement explained, “We are introducing OpenAI o1, a new large language model
    trained with reinforcement learning to perform complex reasoning. o1 thinks before
    it answers—it can produce a long internal chain of thought before responding to
    the user” ([https://mng.bz/nROV](https://mng.bz/nROV)). The article used the word
    “think” 9 times and the word “reason” 17 times. This framing made it sound like
    a major improvement and perhaps a departure from the usual autocompleting LLMs.
    It also sounded like a step toward more human-like AI—the announcement said the
    model could spend more time thinking before responding, “much like a person would.”
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，在2024年9月，OpenAI推出了一种名为OpenAI o1的新模型。公司将其定位为一种能够“思考”和“推理”的模型。通告解释说：“我们推出了OpenAI
    o1，这是一种使用强化学习训练以执行复杂推理的新大型语言模型。o1在回答之前会思考——在回应用户之前，它可以产生一个长的内部思维链。”（[https://mng.bz/nROV](https://mng.bz/nROV)）。文章中使用了“思考”这个词9次，使用了“推理”这个词17次。这种定位让人听起来像是一个重大的改进，也许是从通常的自动补全LLM中的一次转变。它还听起来像是朝着更类似人类的AI迈进了一步——通告说该模型在回答之前可以花更多的时间思考，“就像一个人一样”。
- en: 'But once we look beyond the marketing material, we realize that the o1 system
    isn’t as novel as it seems. It works as follows: first, an LLM is used to generate
    a piece of text with a suggested list of steps to solve the problem. These instructions
    are then added to the end of the original prompt. So, the new prompt contains
    the original task followed by a suggested step-by-step recipe to perform it. Afterward,
    this extended prompt is run through an LLM as usual. This mimics the popular chain-of-thought
    prompting technique, in which the user adds a step-by-step guideline of how to
    solve a problem to the prompt.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 但一旦我们超越营销材料，我们会意识到o1系统并不像看起来那么新颖。它的工作原理如下：首先，使用LLM生成一段包含建议步骤列表的文本，以解决问题。然后，将这些指令添加到原始提示的末尾。因此，新的提示包含了原始任务，后面跟着一个建议的逐步执行方案。之后，这个扩展提示像往常一样通过LLM运行。这模仿了流行的思维链提示技术，其中用户将解决问题的逐步指南添加到提示中。
- en: 'The announcement emphasized that reinforcement learning was used to train the
    system: “Our large-scale reinforcement learning algorithm teaches the model how
    to think productively using its chain of thought in a highly data-efficient training
    process.” This may sound impressive, but it’s probably nothing new. OpenAI has
    been using reinforcement learning with human feedback (RLHF) to refine all its
    models for quite some time (see chapter 1). It’s likely that by “reinforcement
    learning” they meant that humans manually wrote down a small dataset of examples
    of the step-by-step instructions they wanted the LLM to generate, and the LLM
    was refined to produce such instructions more accurately.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 通告强调使用了强化学习来训练系统：“我们的大规模强化学习算法教导模型如何通过其思维链在高度数据高效的训练过程中进行富有成效的思考。”这听起来可能很令人印象深刻，但可能并没有什么新意。OpenAI已经使用带有人类反馈的强化学习（RLHF）来改进其所有模型已有相当长一段时间（见第一章）。很可能是他们所说的“强化学习”是指人类手动编写了一小部分示例数据集，其中包含了他们希望LLM生成的逐步指令，然后LLM被优化以更准确地生成这样的指令。
- en: I advise you to be cautious whenever you hear impressive AI announcements. I
    recommend keeping in mind how current AI works when you analyze announcements,
    which makes it easier to read between the lines and separate the wheat from the
    chaff.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议你在听到令人印象深刻的AI公告时要谨慎。我建议你在分析公告时牢记当前AI的工作原理，这使你更容易读出言外之意，区分精华和糟粕。
- en: Regulation
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规章制度
- en: In August 2024, regulation concerning AI came into force in the European Union,
    known as the AI Act. The AI Act applies to AI that is used, or whose outputs are
    used, inside the EU, even if it’s developed and run elsewhere. The regulation
    has been controversial, with some people deeming it insufficient and others excessive.
    Either way, let’s have a quick discussion about it because you might be affected
    (e.g., you might develop an AI-based product used in the EU) and because it may
    become the blueprint for future AI regulation elsewhere.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在2024年8月，欧盟实施了关于人工智能的法规，被称为AI法案。AI法案适用于在欧盟内使用或其输出被使用的AI，即使它是在其他地方开发和运行的。这项法规引起了争议，有些人认为它不足，而有些人认为它过度。无论如何，让我们快速讨论一下它，因为你可能受到影响（例如，你可能开发了一个在欧盟使用的基于AI的产品），因为它可能成为未来其他地方AI法规的蓝图。
- en: The AI Act contains four special chapters that are especially relevant to developers
    and users of AI systems. We briefly comment on each of them below. You can read
    the full text online ([https://mng.bz/vKWm](https://mng.bz/vKWm)) or have a look
    at the official high-level summary ([https://mng.bz/4aQ5](https://mng.bz/4aQ5)).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: AI法案包含四个特别章节，这些章节对AI系统的开发者和用户特别相关。我们下面简要评论每个章节。您可以在网上阅读全文([https://mng.bz/vKWm](https://mng.bz/vKWm))或查看官方的高级摘要([https://mng.bz/4aQ5](https://mng.bz/4aQ5))。
- en: Prohibited AI practices
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 禁止的人工智能实践
- en: This part of the Act describes a list of AI practices that are outright prohibited
    as they’re considered serious violations. These include AI used to manipulate
    or deceive people, AI that exploits people’s vulnerabilities “due to their age,
    disability or a specific social or economic situation,” and AI for social scoring,
    among other categories.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 本法案的这一部分描述了一系列被明令禁止的人工智能实践，因为这些实践被视为严重的违规行为。这些包括用于操纵或欺骗人们的AI、利用人们因年龄、残疾或特定的社会或经济状况而存在的脆弱性的AI，以及用于社会评分的AI，以及其他类别。
- en: High-risk systems
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高风险系统
- en: This part contains stipulations that apply to high-risk products. These are
    products that are already regulated by the EU and require a third-party conformity
    assessment, such as certain vehicles, machinery, and medical devices. It also
    adds a few more categories to the list, such as AI for targeted job ads and AI
    for visa applications. The Act imposes several requirements on these high-risk
    systems, including enabling human oversight “to understand its capabilities and
    limitations, detect and address issues, avoid over-reliance on the system, interpret
    its output, decide not to use it, or stop its operation.”
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含适用于高风险产品的规定。这些产品已经受到欧盟监管，需要第三方合格评定，例如某些车辆、机械和医疗设备。它还增加了几个新的类别，例如用于针对性招聘广告的AI和用于签证申请的AI。法案对这些高风险系统提出了多项要求，包括启用人工监督“以了解其能力和局限性，检测和解决问题，避免过度依赖系统，解释其输出，决定不使用它或停止其操作。”
- en: Transparency obligations
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 透明度义务
- en: This part requires companies to inform users when they’re interacting with an
    AI system (“unless it's obvious or the AI is used for legal purposes like crime
    detection”), which specifically applies to “an AI system that generates or manipulates
    image, audio or video content constituting a deep fake.” This is the case even
    with systems that are not deemed high risk. Note that if you use AI to generate
    content but then you thoroughly review the content and hold editorial responsibility
    over it, you no longer need to inform others about using AI.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分要求公司在与AI系统互动时通知用户（除非很明显或AI用于法律目的，如犯罪侦查），这特别适用于“生成或操纵构成深度伪造的图像、音频或视频内容的AI系统。”即使对于被认为不是高风险的系统也是如此。请注意，如果你使用AI生成内容，但随后你彻底审查了内容并对其承担编辑责任，你不再需要通知他人使用AI。
- en: By the way, don’t worry about the AI Act ruining your AI art—you can indicate
    that you’re using AI “in an appropriate manner that does not hamper the display
    or enjoyment of the work.”
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，不用担心AI法案会破坏你的AI艺术——你可以表明你正在以“不损害作品展示或欣赏的方式”使用AI。
- en: Foundation models
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基础模型
- en: This part imposes requirements on foundation models, which are denoted by “general-purpose
    AI models.” The Act requires the AI provider to write documentation detailing
    the model’s development, including “information on the data used for training,
    testing and validation” and “known or estimated energy consumption of the model.”
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分对基础模型提出了要求，这些模型被称为“通用人工智能模型”。法案要求AI提供商编写详细说明模型开发的文档，包括“用于训练、测试和验证的数据信息”以及“模型的已知或估计能耗。”
- en: In addition, there’s a special category of very large foundation models the
    Act deems to pose “systemic risk.” These are models that exceed a certain threshold
    in terms of the amount of training (the threshold is currently set to 1025 floating-point
    operations during training). The creators of these models must notify the EU of
    their work, and the EU might impose additional requirements to mitigate risk.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，法案还特别提到了一类非常大的基础模型，这些模型被认为可能带来“系统性风险”。这些模型在训练量方面超过了一定阈值（当前设定为训练过程中的1025次浮点运算）。这些模型的创作者必须通知欧盟他们的工作，欧盟可能会对降低风险提出额外的要求。
- en: In addition, the Act approves training models from scraped data without authorization,
    so long as opt-outs are respected. This was approved indirectly by referring the
    reader to a directive that allows web scraping with the goal of data mining for
    analytics purposes. Some people have criticized this directive saying that “data
    mining” is too broad and could cover pretty much anything ([https://mng.bz/QDa1](https://mng.bz/QDa1)).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该法案批准了未经授权从抓取的数据中训练模型，只要尊重退出权。这是通过引用一个允许为了数据分析目的进行网络抓取的指令间接批准的。有些人批评了这个指令，认为“数据挖掘”过于宽泛，几乎可以涵盖任何内容（[https://mng.bz/QDa1](https://mng.bz/QDa1)）。
- en: Resource consumption
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源消耗
- en: Training and using AI models consumes electricity and other resources, the scale
    of which has been criticized. For example, a journalist called AI “a disaster
    for the climate” ([https://mng.bz/Xxzl](https://mng.bz/Xxzl)).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 训练和使用AI模型消耗电力和其他资源，其规模受到了批评。例如，一位记者称AI“是气候的灾难”（[https://mng.bz/Xxzl](https://mng.bz/Xxzl)）。
- en: It is difficult to gauge AI’s electricity consumption because providers haven’t
    yet reported it consistently. So, we have to rely on studies made by other people.
    These studies aren’t quite standardized, so they’re a bit messy and difficult
    to follow. Some of them even mix different units within the same report in a chaotic
    way, such as kWh, CO2 emissions, and “equivalent number of smartphone charges”
    ([https://arxiv.org/pdf/2311.16863](https://arxiv.org/pdf/2311.16863)). Sometimes
    researchers rely on hearsay and loose logical connections to calculate consumption.
    For example, one researcher deduced LLMs’ energy consumption indirectly from the
    fact that a Google executive said in an interview that LLMs likely consumed 10
    times more power than performing a Google search ([https://mng.bz/yW57](https://mng.bz/yW57)).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 评估人工智能的电力消耗是困难的，因为供应商尚未持续地报告这一数据。因此，我们必须依赖其他人进行的研究。这些研究并不完全标准化，因此它们有些混乱且难以追踪。其中一些研究甚至在同一报告中以混乱的方式混合了不同的单位，例如千瓦时（kWh）、二氧化碳排放量和“相当于智能手机充电次数”（[https://arxiv.org/pdf/2311.16863](https://arxiv.org/pdf/2311.16863)）。有时研究人员会依赖传闻和松散的逻辑联系来计算消耗量。例如，一位研究人员通过一位谷歌高管在一次采访中提到LLM（大型语言模型）可能比执行一次谷歌搜索消耗10倍多的电力这一事实，间接地推断出LLM的能源消耗量（[https://mng.bz/yW57](https://mng.bz/yW57)）。
- en: In the following, I’ll share some results from a study presented by a group
    of researchers from Hugging Face and Carnegie Mellon University. The researchers
    used multiple open source models with their own GPUs and measured consumption.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下内容中，我将分享一组来自Hugging Face和卡内基梅隆大学的研究人员所展示的研究结果。研究人员使用了多个开源模型以及他们自己的GPU，并测量了消耗量。
- en: Table 6.1 shows electricity consumption reported by the researchers for text
    and image generation ([https://arxiv.org/pdf/2311.16863](https://arxiv.org/pdf/2311.16863)).
    Consumption figures are the average across different models studied by the researchers
    (individual consumption per model was not reported in a consistent manner).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.1显示了研究人员报告的文本和图像生成的电力消耗情况（[https://arxiv.org/pdf/2311.16863](https://arxiv.org/pdf/2311.16863)）。消耗数据是研究人员研究的不同模型平均得出的（每个模型的个人消耗量没有以一致的方式报告）。
- en: Table 6.1  Average electricity consumption across different models compared
    with typical household consumption
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表6.1  不同模型平均电力消耗与典型家庭消耗量的比较
- en: '|  | kWh / 1,000 responses | % of daily household kWh (US) | % of daily household
    kWh (UK) |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '|  | 千瓦时/1,000次响应 | 每日家庭千瓦时（美国）的百分比 | 每日家庭千瓦时（英国）的百分比 |'
- en: '| Text generation | 0.047 | 0.15% | 0.5% |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 文本生成 | 0.047 | 0.15% | 0.5% |'
- en: '| Image generation | 2.907 | 9.83% | 30% |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 图像生成 | 2.907 | 9.83% | 30% |'
- en: Note that the figures are per 1,000 uses of the model, such as generating an
    entire response 1,000 times with an LLM or generating 1,000 images with a text-to-image
    model. One thousand uses of AI may seem like a lot, but it might easily be reached
    by intensive users in less than a day. For example, a coder using GitHub Copilot
    might generate hundreds of LLM-based autocompletions every hour. Moreover, many
    of our regular online actions, such as performing a Google search or browsing
    an online store, may trigger LLM queries (Google is already showing AI results
    with searches), which would add more LLM usage even if the user doesn’t use LLMs
    directly. We can also imagine that a small group of graphic designers might generate
    1,000 images in a short time frame by prompting the system repeatedly to create
    images and adjust the result.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这些数据是按每千次模型使用计算的，例如使用LLM生成整个响应1000次或使用文本到图像模型生成1000张图像。1000次AI使用可能看起来很多，但密集用户可能在一天内就轻松达到这个数字。例如，使用GitHub
    Copilot的程序员每小时可能生成数百个基于LLM的自动完成。此外，许多我们常规的在线行为，如进行谷歌搜索或浏览在线商店，可能会触发LLM查询（谷歌已经在搜索中显示AI结果），即使用户没有直接使用LLM，也会增加LLM的使用量。我们还可以想象，一小群图形设计师可能会在短时间内通过反复提示系统创建图像并调整结果来生成1000张图像。
- en: In these experiments, image generation was much more power-hungry than text
    generation. However, the researchers didn’t reveal the prompt used for text generation
    or how much text was generated each time. In addition, they only used text-generation
    models on the smaller end of the spectrum, such as GPT-2 models, which are 100
    times smaller than the generation that succeeded them. The authors reported significant
    variability across models. In particular, the largest image-generation model consumed
    6,000 times as much power as the smallest one.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些实验中，图像生成比文本生成更耗电。然而，研究人员没有透露用于文本生成的提示或每次生成多少文本。此外，他们只使用了较小范围的文本生成模型，如GPT-2模型，这些模型比随后的生成大100倍。作者报告了模型之间的显著差异。特别是，最大的图像生成模型消耗的电量是最小的模型的6000倍。
- en: Note that AI models are constantly being optimized, so consumption could be
    reduced in the future—sometimes a model can be made much smaller without significantly
    reducing its capabilities. For reference, I’ve added two columns to table 6.1
    that compare AI consumption with the total daily electricity consumption by the
    typical US ([https://www.eia.gov/tools/faqs/faq.php?id=97&t=3](https://www.eia.gov/tools/faqs/faq.php?id=97&t=3))
    and UK ([https://mng.bz/MDQE](https://mng.bz/MDQE)) households.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，AI模型正在不断优化，因此未来的消耗可能会减少——有时在不显著降低其能力的情况下，可以将模型做得小得多。为了参考，我在表6.1中添加了两列，比较了AI消耗与典型美国家庭（[https://www.eia.gov/tools/faqs/faq.php?id=97&t=3](https://www.eia.gov/tools/faqs/faq.php?id=97&t=3)）和英国家庭（[https://mng.bz/MDQE](https://mng.bz/MDQE)）的每日总电力消耗。
- en: The greatest worry is not electricity consumption itself, but the CO2 emitted
    to generate it. *Carbon intensity* measures the grams of CO2 emitted per kWh consumed,
    and it varies depending on how power is generated. Table 6.2 restates the above
    results in terms of CO2 emitted based on typical carbon intensity in the US ([https://mng.bz/av6x](https://mng.bz/av6x))
    and the UK ([https://mng.bz/gaXZ](https://mng.bz/gaXZ); both countries produce
    electricity from different sources, so their carbon intensity differs).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最令人担忧的不是电力消耗本身，而是为了产生电力而排放的CO2。*碳强度*衡量每千瓦时消耗产生的CO2克数，这取决于电力是如何产生的。表6.2根据美国（[https://mng.bz/av6x](https://mng.bz/av6x)）和英国（[https://mng.bz/gaXZ](https://mng.bz/gaXZ)；这两个国家从不同的来源发电，因此它们的碳强度不同）典型的碳强度重新表述了上述结果。
- en: Table 6.2  Comparison of the electricity consumption from table 6.1 with equivalent
    CO2 emissions of petrol cars
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表6.2  表6.1中电力消耗与汽油车等效CO2排放的比较
- en: '|  | Grams of CO2 / 1,000 responses (US) | Miles driven for equivalent CO2
    (US) | Grams of CO2 / 1,000 responses (UK) | Miles driven for equivalent CO2 (UK)
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|  | 每千次使用产生的CO2克数（美国） | 等效CO2排放的行驶里程（美国） | 每千次使用产生的CO2克数（英国） | 等效CO2排放的行驶里程（英国）
    |'
- en: '| Text generation | 20 | 0.05 miles | 7.6 | 0.02 miles |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 文本生成 | 20 | 0.05英里 | 7.6 | 0.02英里 |'
- en: '| Image generation | 1,200 | 3.1 miles | 470 | 1.2 miles |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 图像生成 | 1,200 | 3.1英里 | 470 | 1.2英里 |'
- en: To put things in perspective, the table includes the number of miles you’d have
    to drive a car to emit the same amount of CO2 ([https://mng.bz/av6x](https://mng.bz/av6x)).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更清楚地说明问题，表中还包括了您需要驾驶汽车行驶多少英里才能排放相同数量的CO2（[https://mng.bz/av6x](https://mng.bz/av6x)）。
- en: In addition to the electricity required to use AI models, many people have stressed
    that *training* them is a power-hungry activity. It’s been estimated that training
    GPT-3 consumed 1,287 MWh ([https://arxiv.org/pdf/2104.10350](https://arxiv.org/pdf/2104.10350)).
    This amounted to the electricity consumed in one day by 43,000 US households or
    134,000 UK households. Note that, while models are only trained sporadically,
    AI providers train or retrain multiple models a year.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用AI模型所需的电力外，许多人强调，*训练*它们是一项耗能的活动。据估计，训练GPT-3消耗了1,287 MWh ([https://arxiv.org/pdf/2104.10350](https://arxiv.org/pdf/2104.10350))。这相当于43000个美国家庭或134000个英国家庭一天所消耗的电量。请注意，尽管模型只是偶尔进行训练，但AI提供商每年会训练或重新训练多个模型。
- en: Using and training AI models also consumes other resources, such as water for
    cooling down data centers. An article in *Fortune* explained, “Microsoft disclosed
    that its global water consumption spiked 34% from 2021 to 2022 (to nearly 1.7
    billion gallons, or more than 2,500 Olympic-sized swimming pools), a sharp increase
    compared to previous years that outside researchers tie to its AI research” ([https://mng.bz/eyNw](https://mng.bz/eyNw)).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用和训练AI模型也消耗其他资源，例如用于冷却数据中心的水。一篇发表在《财富》杂志上的文章解释说：“微软披露，其全球用水量从2021年到2022年增长了34%（达到近17亿加仑，或超过2500个奥运标准游泳池），与往年相比有显著增长，外部研究人员将其与AI研究联系起来”
    ([https://mng.bz/eyNw](https://mng.bz/eyNw))。
- en: When you use AI, I recommend you keep in mind that “cloud computing” actually
    happens on Earth, inside large refrigerated buildings, and this can be resource-intensive
    and have an influence on the environment.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用AI时，我建议你记住，“云计算”实际上是在地球上，在大型冷藏建筑内进行的，这可能非常耗费资源并对环境产生影响。
- en: Brains and consciousness
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大脑与意识
- en: Let’s finish on a lighter and more philosophical note. It is common to compare
    the structure of AI models with our own biological brains. If you remember from
    chapter 1, LLMs perform lots of projections, which are mathematical operations
    that involve matrix multiplications. Biological neurons have been traditionally
    described as performing a similar calculation, so many ML models, including LLMs,
    are categorized as *artificial neural networks.* In addition, some ML model architectures
    have been compared with the structure of specific parts of our brains. For example,
    convolutional neural networks (CNNs) are often compared with the brain’s visual
    cortex.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以轻松和哲学的笔调结束。将AI模型的结构与我们自己的生物大脑进行比较是很常见的。如果你还记得第一章，LLMs执行了许多投影，这些投影是涉及矩阵乘法的数学运算。生物神经元传统上被描述为执行类似的计算，因此许多ML模型，包括LLMs，被归类为*人工神经网络*。此外，一些ML模型架构与大脑特定部分的构造进行了比较。例如，卷积神经网络（CNNs）通常与大脑的视觉皮层进行比较。
- en: 'In reality, we still don’t quite understand how brains work. For example, the
    traditional understanding of the calculations made by neurons is too simple (Penrose,
    R., 1989, *The Emperor''s New Mind: Concerning Computers, Mind, and the Laws in
    Physics*. Oxford University Press, p. 511). Over the years, much more complicated
    models have been developed. However, these models still cannot predict what scientists
    observe when studying the workings of real neurons. For example, in 2020, a group
    of researchers discovered that the dendrites that pass signals from one neuron
    to another may actually carry out complicated computations (Gidon, A. et al.,
    2020, “Dendritic action potentials and computation in human layer 2/3 cortical
    neurons,” *Science*, *367*[6473], pp. 83–87). So, they aren’t just wires that
    carry signals as previously thought. To complicate things even more, the fluid
    that surrounds neurons contains molecules, known as neuromodulators, which affect
    neurons’ behavior in a way that isn’t fully understood. While progress has been
    made, our understanding of neurons and brains is still quite poor.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '事实上，我们仍然不完全理解大脑是如何工作的。例如，对神经元进行计算的传统理解过于简单（Penrose, R., 1989, *The Emperor''s
    New Mind: Concerning Computers, Mind, and the Laws in Physics*. Oxford University
    Press, p. 511）。多年来，已经开发出更加复杂的模型。然而，这些模型仍然无法预测科学家在研究真实神经元工作时所观察到的现象。例如，2020年，一组研究人员发现，传递信号从一个神经元到另一个神经元的树突实际上可能执行复杂的计算（Gidon,
    A. et al., 2020, “Dendritic action potentials and computation in human layer 2/3
    cortical neurons,” *Science*, *367*[6473], pp. 83–87）。因此，它们不仅仅是像以前认为的那样只是传递信号的电线。更复杂的是，包围神经元的液体中含有被称为神经调节剂的分子，它们以不完全理解的方式影响神经元的行为。虽然已经取得了一些进展，但我们对于神经元和大脑的理解仍然相当有限。'
- en: 'As of today, the brain of only one organism has been fully mapped out, meaning
    that researchers could create a map of all connections between neurons, or *connectome*.
    The organism is a tiny worm called C. Elegans*,* which has around 300 neurons
    and 7,000 connections among them. However, it was impossible to simulate the observed
    worm’s behavior, as the map just tells us which neurons are connected to which
    but not exactly how they work. Neuroscientist Anthony Movshon concluded that the
    “connectome by itself has not explained anything" (Jabr, F., 2012, “The Connectome
    Debate: Is Mapping the Mind of a Worm Worth It?” *Scientific American,* [https://mng.bz/pKaE](https://mng.bz/pKaE)).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，只有一种生物的大脑被完全绘制出来，这意味着研究人员可以创建一个所有神经元之间连接的图谱，即*连接组*。这种生物是一种名为C. Elegans的小型蠕虫，它大约有300个神经元和7000个连接。然而，由于图谱只告诉我们哪些神经元连接到哪些神经元，但没有确切说明它们是如何工作的，因此无法模拟观察到的蠕虫行为。神经科学家安东尼·莫夫申得出结论，"连接组本身并没有解释任何事情"（Jabr,
    F., 2012, “连接组辩论：绘制蠕虫的大脑图值得吗？” *Scientific American*，[https://mng.bz/pKaE](https://mng.bz/pKaE)）。
- en: In some cases, AI models are designed without considering brain structures,
    and the brain analogy is forced later on. For example, the initial articles describing
    CNNs did *not* say that these were inspired by the brain. The researchers claimed
    their design decisions were “guided by our prior knowledge about shape recognition”
    (LeCun, Y. et al., 1989, “Handwritten digit recognition with a back-propagation
    network,” *Advances in Neural Information Processing Systems*, 2). Years later,
    when CNNs became popular, the same researchers claimed that they were “directly
    inspired by the classic notions of simple cells and complex cells in visual neuroscience,
    and the overall architecture is reminiscent of the LGN–V1–V2–V4–IT hierarchy in
    the visual cortex ventral pathway” (LeCun, Y., Bengio, Y., & Hinton, G., 2015,
    “Deep learning,” *Nature, 521*[7553], pp. 436–444).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，AI模型的设计没有考虑到大脑结构，后来才强行引入大脑类比。例如，最初描述CNNs的文章并没有说这些是由大脑启发的。研究人员声称他们的设计决策是“受我们对形状识别的先验知识指导”（LeCun,
    Y. et al., 1989, “使用反向传播网络进行手写数字识别”，*Advances in Neural Information Processing
    Systems*，2）。多年以后，当CNNs变得流行时，同样的研究人员声称他们是“直接受到视觉神经科学中经典概念——简单细胞和复杂细胞——的启发，整体架构与视觉皮层腹侧通路中的LGN-V1-V2-V4-IT层次结构相似”（LeCun,
    Y., Bengio, Y., & Hinton, G., 2015, “深度学习”，*Nature, 521*[7553]，第436–444页）。
- en: Moreover, analogies are often quite loose. For example, the comparison between
    CNNs and the visual cortex only works if we ignore some known things about the
    visual cortex that are not a part of CNNs (see *Smart Until It’s Dumb*, Chapter
    2).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，类比通常相当松散。例如，如果我们忽略视觉皮层中不属于CNNs的一些已知事实，那么CNNs和视觉皮层的比较才成立（参见 *Smart Until It’s
    Dumb*，第二章）。
- en: So, be cautious whenever you hear analogies between AI and brains. We still
    don’t understand brains, so the connection is likely to be highly speculative.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每当您听到AI和大脑之间的类比时，都要谨慎。我们仍然不了解大脑，所以这种联系很可能是高度推测性的。
- en: In addition to brain-related speculation, the latest AI boom has also reignited
    the consciousness debate. Just to cite an example, in 2022, the news went viral
    that an AI engineer claimed Google’s chatbot had become sentient ([https://mng.bz/OBn2](https://mng.bz/OBn2)).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 除了与大脑相关的推测之外，最新的AI热潮也重新点燃了意识辩论。仅举一个例子，2022年，有报道称一位AI工程师声称谷歌的聊天机器人已经具有了意识（[https://mng.bz/OBn2](https://mng.bz/OBn2)）。
- en: But, just like with brains, we don’t quite understand consciousness. We do know
    that some parts of the brain are in charge of unconscious actions (like controlling
    heartbeat), while others are related to conscious perceptions (like vision), but
    we don’t understand why some parts contribute to our consciousness, while others
    don’t. We also don’t understand how general anesthesia works; we just know from
    experience that anesthetics turn off consciousness temporarily, but we don’t know
    the mechanism behind it.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，就像大脑一样，我们对意识并不完全了解。我们知道大脑的一些部分负责无意识行为（如控制心跳），而其他部分与有意识感知（如视觉）有关，但我们不明白为什么有些部分有助于我们的意识，而其他部分则不然。我们也不了解全身麻醉是如何工作的；我们只知道从经验中得知，麻醉剂可以暂时关闭意识，但我们不知道其背后的机制。
- en: In addition, there are many philosophical questions around consciousness that
    don’t have an easy answer. For example, some people think that any computation
    gives rise to consciousness. Under this view, a thermostat is conscious but in
    a different way. Other people, like physicist Roger Penrose, think consciousness
    doesn’t arise from computation at all and thus cannot be created with digital
    computers. The debate is still ongoing, and I’m not sure we’ll ever be able to
    determine whether a thermostat is conscious.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，关于意识存在许多哲学问题，这些问题没有简单的答案。例如，有些人认为任何计算都会产生意识。根据这种观点，恒温器是有意识的，但以不同的方式。其他人，如物理学家罗杰·彭罗斯，认为意识根本不是由计算产生的，因此不能通过数字计算机创造。这场辩论仍在继续，我不确定我们是否能够确定恒温器是否有意识。
- en: So, I advise you to be cautious when anyone claims to have a definitive answer
    about the link between AI and consciousness. There is so much we don’t know.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我建议你在任何人声称对人工智能与意识之间的联系有明确答案时要谨慎。我们还有很多不知道的东西。
- en: As we’ve now reached the end of this book, let’s quickly reflect on the content
    covered. Throughout this book, we’ve discussed the power of AI—how ML innovations
    have pushed the boundaries of what AI can do. We’ve also discussed AI’s limitations—how
    sometimes AI hallucinates or isn’t as useful as it seems at first sight. Because
    AI is not all-powerful, its effects will vary depending on the context—sometimes
    AI may automate away jobs, but other times it may not; sometimes it may be the
    best tool for a task, but other times it may not; and so on. In this book, I tried
    to cover both sides of that debate and share advice accordingly. The last chapter
    completed our analysis by discussing some of the bigger questions surrounding
    AI, many of which are still unanswered and are likely to be hot topics in the
    future.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经到达了这本书的结尾，让我们快速回顾一下所涵盖的内容。在这本书中，我们讨论了人工智能的力量——机器学习创新如何推动人工智能能够做到的边界。我们也讨论了人工智能的限制——有时人工智能会产生幻觉，或者不像乍看之下那么有用。因为人工智能不是万能的，其影响将根据上下文而变化——有时人工智能可能会自动化工作，但有时则不会；有时它可能是完成任务的最好工具，但有时则不是；等等。在这本书中，我试图涵盖辩论的两面，并据此提供建议。最后一章通过讨论围绕人工智能的一些更大的问题来完成我们的分析，其中许多问题仍然没有答案，并且很可能是未来的热门话题。
- en: Summary
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The copyright debate hinges on the interpretation of *fair use.* AI providers
    argue that they scrape data so that their models can learn general patterns and
    that they don’t intend to reproduce the original data, implying it’s a fair use
    of that data. Data owners argue that AI providers use this data to build competing
    products and steal their customers, so this isn’t fair use.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 版权争议取决于对*合理使用*的解释。人工智能提供商认为，他们抓取数据是为了让他们的模型学习一般模式，并且他们没有意图复制原始数据，这意味着这是该数据的合理使用。数据所有者则认为，人工智能提供商使用这些数据来构建竞争产品并窃取他们的客户，所以这不是合理使用。
- en: The economic case for AI is not that clear. AI providers are still largely unprofitable
    and face fierce competition. Smaller companies that create thin AI wrappers also
    face fierce competition and may struggle to make ends meet. Productivity gains
    in the wider economy due to AI have not yet been observed.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能的经济案例并不那么明确。人工智能提供商仍然大部分是无利可图的，面临着激烈的竞争。创建薄人工智能包装的小公司也面临着激烈的竞争，可能难以收支平衡。由于人工智能，更广泛的经济中的生产力增长尚未观察到。
- en: The AI field has a tendency to exaggerate or even deceive. Many products that
    allegedly used AI have been revealed to rely on remote human operators to do the
    job manually. Big AI announcements are often incorrect (like Google saying a model
    learned a language that wasn’t in its training data) or spruced up (like OpenAI
    saying its model “thinks” and “reasons”).
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能领域有夸大或甚至欺骗的倾向。许多声称使用了人工智能的产品被揭露实际上依赖于远程人类操作员手动完成工作。大型人工智能公告往往是不正确的（比如谷歌说一个模型学会了训练数据中没有的语言）或者被粉饰了（比如OpenAI说它的模型“思考”和“推理”）。
- en: The amount of electricity consumption (and other resources like water) to train
    and run AI models has received a lot of criticism, with some people arguing it
    will have detrimental environmental effects. Studies and reports about AI resource
    consumption are still scarce and preliminary, but we can see that it isn’t a negligible
    amount.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和运行人工智能模型所需的电量消耗（以及其他资源如水）受到了很多批评，有些人认为这将对环境产生有害的影响。关于人工智能资源消耗的研究和报告仍然很少，但我们可以看到这并不是一个可以忽略的数量。
- en: Comparisons between AI models and the structure of the brain are highly speculative.
    We don’t quite understand how brains work yet, so comparisons tend to be forced.
    The same goes for AI and consciousness—it’s still an ongoing debate without clear-cut
    answers.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能模型与大脑结构的比较非常具有推测性。我们还没有完全理解大脑是如何工作的，因此比较往往显得牵强。对于人工智能与意识的关系也是如此——这仍然是一个没有明确答案的持续争论。
