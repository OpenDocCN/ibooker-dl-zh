<html><head></head><body>
<div id="sbo-rt-content"><div class="readable-text" id="p1">
<h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">5</span> </span> <span class="chapter-title-text">Agentic RAG</span></h1>
</div>
<div class="introduction-summary">
<h3 class="introduction-header">This chapter covers </h3>
<ul>
<li class="readable-text" id="p2">What agentic RAG is</li>
<li class="readable-text" id="p3">Why we need agentic RAG</li>
<li class="readable-text" id="p4">How to implement agentic RAG</li>
</ul>
</div>
<div class="readable-text" id="p5">
<p>In earlier chapters, we saw how to find relevant data using different methods of vector similarity search. Using similarity search, we can find relevant data in unstructured data sources, but data with a structure can often bring more value over unstructured data because there’s information in the structure itself.</p>
</div>
<div class="readable-text intended-text" id="p6">
<p>Adding structure to data can be an incremental process. We can start with a simple structure and then add more complex structures as we go. We saw this in the previous chapter, where we started with simple graph data and then added more complex structures to it.</p>
</div>
<div class="readable-text intended-text" id="p7">
<p>An agentic RAG system (see figure 5.1) is a system where a variety of retrieval agents are available to retrieve the data needed to answer the user question. The starting interface to an agentic RAG system is usually a retriever router, whose job is to find the best-suited retriever (or retrievers) to perform the task at hand.</p>
</div>
<div class="readable-text intended-text" id="p8">
<p>One common way to implement an agentic RAG system is to use an LLM’s ability to use tools (sometimes called <em>function calling</em>). Not all LLMs have this ability, but OpenAI’s GPT-3.5 and GPT-4 do, and that is what we will use in this chapter. This can be achieved with most LLMs using the ReAct approach (see <a href="https://arxiv.org/abs/2210.03629">https://arxiv.org/abs/2210.03629</a>), but over time, the current trajectory is that this feature will be available in all LLMs. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p9">
<img alt="figure" height="309" src="../Images/5-1.png" width="1009"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 5.1</span> The data flow for an application using agentic RAG</h5>
</div>
<div class="readable-text" id="p10">
<h2 class="readable-text-h2"><span class="num-string">5.1</span> What is agentic RAG?</h2>
</div>
<div class="readable-text" id="p11">
<p>Agentic systems vary in sophistication and complexity, but the core idea is that the system can act on behalf of the user to perform tasks. In this chapter, we will look at a basic agentic system where the system only has to choose which retriever to use and decide whether the found context answers the question. In more advanced systems, the system might make up plans on what kind of tasks to perform to solve the task at hand. Starting from the basics as we do in this chapter is a good way to understand the core concepts of agentic systems, and for RAG tasks, this is often all you need.</p>
</div>
<div class="readable-text intended-text" id="p12">
<p>Agentic RAG is a system whereby a variety of retrieval agents are available to retrieve the data needed to answer the user question. Successful agentic RAG systems require a few foundational parts:</p>
</div>
<ul>
<li class="readable-text" id="p13"> <em>Retriever router</em> —A function that takes in the user question(s) and returns the best retriever(s) to use </li>
<li class="readable-text" id="p14"> <em>Retriever agents</em> —The actual retrievers that can be used to retrieve the data needed to answer the user question(s) </li>
<li class="readable-text" id="p15"> <em>Answer critic</em> —A function that takes in the answers from the retrievers and checks if the original question is answered correctly </li>
</ul>
<div class="readable-text" id="p16">
<h3 class="readable-text-h3"><span class="num-string">5.1.1</span> Retriever agents</h3>
</div>
<div class="readable-text" id="p17">
<p>Retriever agents are the actual retrievers that can be used to retrieve the data needed to answer the user question(s). These retrievers can be very broad, like a vector similarity search, or very specific, like a template of a hardcoded database query that takes in parameters, such as the retriever router, covered in section 5.1.2.</p>
</div>
<div class="readable-text intended-text" id="p18">
<p>A few generic retriever agents are relevant in most agentic RAG systems, like vector similarity search and text2cypher. The former is useful for unstructured data sources and the latter for structured data in a graph database, but in a real-world production system, it’s not trivial to make any of them perform at par with user expectations.</p>
</div>
<div class="readable-text intended-text" id="p19">
<p>That’s why we need specialized retrievers that are very narrow but perform very well at what they’re meant for. These specialized retrievers can be built over time as we identify questions that the generic retrievers have problems generating queries to answer.</p>
</div>
<div class="readable-text" id="p20">
<h3 class="readable-text-h3"><span class="num-string">5.1.2</span> The retriever router</h3>
</div>
<div class="readable-text" id="p21">
<p>To pick the right retriever for the job, we have something called a retriever router. The retriever router is a function that takes in the user question and returns the best retriever(s) to use. How the router makes this decision can vary, but usually an LLM is used to make this decision.</p>
</div>
<div class="readable-text intended-text" id="p22">
<p>Let’s say we have a question like “What is the capital of France?” And let’s say we have coded two retriever agents that are available (that both retrieve the answer from a database):</p>
</div>
<ul>
<li class="readable-text" id="p23"> <code>capital_by_country</code>—A retriever that takes in a country name and returns the capital of that country </li>
<li class="readable-text" id="p24"> <code>country_by_capital</code>—A retriever that takes in a capital name and returns the country of that capital </li>
</ul>
<div class="readable-text" id="p25">
<p>Both of these retrievers can be hardcoded database queries that take in a parameter for the country or capital.</p>
</div>
<div class="readable-text intended-text" id="p26">
<p>The retriever router can be an LLM that takes in the user question and returns the best retriever to use. In this case, the LLM can return the <code>capital_by_country</code> retriever with <code>"France"</code> as the extracted argument. So the actual call to the retriever would be <code>capital_by_country("France")</code>.</p>
</div>
<div class="readable-text intended-text" id="p27">
<p>This is a simple example, but in a real-world scenario, many retrievers may be available. The retriever router can be a complex function that uses the LLM to pick the best retriever for the job.</p>
</div>
<div class="readable-text" id="p28">
<h3 class="readable-text-h3"><span class="num-string">5.1.3</span> Answer critic</h3>
</div>
<div class="readable-text" id="p29">
<p>The answer critic is a function that takes in the answers from the retrievers and checks whether the original question is answered correctly. The answer critic is a blocking function that can stop the answer from being returned to the user if the answer is not correct or is incomplete.</p>
</div>
<div class="readable-text intended-text" id="p30">
<p>If an incomplete or incorrect answer is blocked, the answer critic should generate a new question that can be used to retrieve the correct answer and go through another round of retrieving the correct answer. It might be that the correct answer is not available in the data source, so there needs to be some exit criteria from this loop; the answer critic should be able to handle that and return a message to the user that the answer is not available in such cases.</p>
</div>
<div class="readable-text" id="p31">
<h2 class="readable-text-h2"><span class="num-string">5.2</span> Why do we need agentic RAG?</h2>
</div>
<div class="readable-text" id="p32">
<p>One area where agentic RAG is useful is when we have a variety of data sources and we want to use the best data source for the job. Another common usage is when the data source is very broad or complex and we need specialized retrievers to retrieve the data we need consistently.</p>
</div>
<div class="readable-text intended-text" id="p33">
<p>As seen earlier in the book, generic retrievers like vector similarity search can find relevant data in unstructured data sources. When we have structured data sources like a graph database, we might use generic retrievers like text2cypher that we introduced in chapter 4. If the data is very complex, tools like text2cypher can have problems generating the right query. In such cases, specialized retrievers can be used to retrieve the correct data. This could, for example, be a narrow text2cypher retriever or a hard-coded database query that takes in parameters.</p>
</div>
<div class="readable-text intended-text" id="p34">
<p>Over time, we can identify questions that tools like text2cypher have problems generating queries to answer, and we can build specialized retrievers for those questions and use text2cypher as a catchall retriever for the cases when there isn’t a good specific retriever match.</p>
</div>
<div class="readable-text intended-text" id="p35">
<p>This is where agentic RAG can be useful. A variety of retrievers are available, and we need to use the best retriever for the job and assess the answer before returning it to the user. In a production environment, this is very useful to keep the performance of the system high and the quality of the answers consistent.</p>
</div>
<div class="readable-text" id="p36">
<h2 class="readable-text-h2"><span class="num-string">5.3</span> How to implement agentic RAG</h2>
</div>
<div class="readable-text" id="p37">
<p>In this section, we’ll walk through how to implement the foundational parts of an agentic RAG system. You can follow the implementation directly in the accompanying Jupyter notebook available here: <a href="https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch05.ipynb">https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch05.ipynb</a>.</p>
</div>
<div class="readable-text print-book-callout" id="p38">
<p><span class="print-book-callout-head">NOTE</span> In the implementation in this chapter, we use what we call the “Movies dataset.” See the appendix for more information on the dataset and various ways to load it.</p>
</div>
<div class="readable-text" id="p39">
<h3 class="readable-text-h3"><span class="num-string">5.3.1</span> Implementing retriever tools</h3>
</div>
<div class="readable-text" id="p40">
<p>Before we can route the user input to be handled by the right retriever(s), we need to have the retrievers available for the router to choose from. The retrievers can be very broad, like a vector similarity search, or very specific, like a template of a hardcoded database query that takes in parameters.</p>
</div>
<div class="readable-text intended-text" id="p41">
<p>In this practical example, we’ll use a simple list of retrievers: two that use Cypher templates to get movies by title and movies by actor name and one that uses text2cypher for all other questions. As mentioned earlier, the useful set of retrievers differs from system to system and should be added over time as needed to improve the performance of the application.</p>
</div>
<div class="browsable-container listing-container" id="p42">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.1</span> Available retriever tools</h5>
<div class="code-area-container">
<pre class="code-area">text2cypher_description = {
    "type": "function",
    "function": {
        "name": "text2cypher",
        "description": "Query the database with a user question. When other tools don't fit, fallback to use this one.",
        "parameters": {
            "type": "object",
            "properties": {
                "question": {
                    "type": "string",
                    "description": "The user question to find the answer for",
                }
            },
            "required": ["question"],
        },
    },
}


def text2cypher(question: str):
    """Query the database with a user question."""
    t2c = Text2Cypher(neo4j_driver)
    t2c.set_prompt_section("question", question)
    cypher = t2c.generate_cypher()
    records, _, _ = neo4j_driver.execute_query(cypher)
    return [record.data() for record in records]


movie_info_by_title_description = {
    "type": "function",
    "function": {
        "name": "movie_info_by_title",
        "description": "Get information about a movie by providing the title",
        "parameters": {
            "type": "object",
            "properties": {
                "title": {
                    "type": "string",
                    "description": "The movie title",
                }
            },
            "required": ["title"],
        },
    },
}


def movie_info_by_title(title: str):
    """Return movie information by title."""
    query = """
    MATCH (m:Movie)
    WHERE toLower(m.title) CONTAINS $title
    OPTIONAL MATCH (m)&lt;-[:ACTED_IN]-(a:Person)
    OPTIONAL MATCH (m)&lt;-[:DIRECTED]-(d:Person)
    RETURN m AS movie, collect(a.name) AS cast, collect(d.name) AS directors
    """
    records, _, _ = neo4j_driver.execute_query(query, title=title.lower())
    return [record.data() for record in records]


movies_info_by_actor_description = {
    "type": "function",
    "function": {
        "name": "movies_info_by_actor",
        "description": "Get information about a movie by providing an actor",
        "parameters": {
            "type": "object",
            "properties": {
                "actor": {
                    "type": "string",
                    "description": "The actor name",
                }
            },
            "required": ["actor"],
        },
    },
}


def movies_info_by_actor(actor: str):
    """Return movie information by actor."""
    query = """
    MATCH (a:Person)-[:ACTED_IN]-&gt;(m:Movie)
    OPTIONAL MATCH (m)&lt;-[:ACTED_IN]-(a:Person)
    OPTIONAL MATCH (m)&lt;-[:DIRECTED]-(d:Person)
    WHERE toLower(a.name) CONTAINS $actor
    RETURN m AS movie, collect(a.name) AS cast, collect(d.name) AS directors
    """
    records, _, _ = neo4j_driver.execute_query(query, actor=actor.lower())
    return [record.data() for record in records]</pre>
</div>
</div>
<div class="readable-text" id="p43">
<p>Note that <code>neo4j_driver</code> and <code>text2cypher</code> are imports that you can find implemented in the code repository for this book.</p>
</div>
<div class="readable-text print-book-callout" id="p44">
<p><span class="print-book-callout-head">NOTE</span> The previous retriever definitions follow OpenAI’s tools format at the time of writing this book.</p>
</div>
<div class="readable-text" id="p45">
<p>We need to be careful with how we describe the retriever to the LLM. We need to make sure the LLM understands the retriever and can make a decision on which retriever to use. The parameters are also very important to describe so the LLM can make the right call to the retriever.</p>
</div>
<div class="readable-text intended-text" id="p46">
<p>Note that the LLM can’t make actual calls to your retrievers; it can only make a decision on which retriever to use and what parameters to pass to the retriever. The actual call to the retriever needs to be done by the system that calls the LLM, which we’ll see in the next section.</p>
</div>
<div class="readable-text" id="p47">
<h4 class="readable-text-h4">Note on a generic retriever tool</h4>
</div>
<div class="readable-text" id="p48">
<p>A generic retriever tool that we almost always include in our agentic RAG systems is a tool that is being called if the answer to the question is already given within the question or other parts of the context. This tool is usually a simple function that extracts the answer from the question or context and returns it.</p>
</div>
<div class="readable-text intended-text" id="p49">
<p>An example could be a question like “What’s Dave Smith’s last name?” This is what the retriever tool could look like.</p>
</div>
<div class="browsable-container listing-container" id="p50">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.2</span> Generic retriever tool for answer already in context</h5>
<div class="code-area-container">
<pre class="code-area">answer_given_description = {
    "type": "function",
    "function": {
        "name": "answer_given",
        "description": "If a complete answer to the question is already provided in the conversation, use this tool to extract it.",
        "parameters": {
            "type": "object",
            "properties": {
                "answer": {
                    "type": "string",
                    "description": "The answer to the question",
                }
            },
            "required": ["answer"],
        },
    },
}

def answer_given(answer: str):
    """Extract the answer from a given text."""
    return answer</pre>
</div>
</div>
<div class="readable-text" id="p51">
<h3 class="readable-text-h3"><span class="num-string">5.3.2</span> Implementing the retriever router</h3>
</div>
<div class="readable-text" id="p52">
<p>The retriever router is the central part of the agentic RAG system. Its job is to take in the user question(s) and return the best retriever(s) to use.</p>
</div>
<div class="readable-text intended-text" id="p53">
<p>When implementing the retriever router, we’ll use an LLM to help us with the task. We will provide the LLM with a list of retrievers and the user question(s), and the LLM will return the best retriever(s) to use to find the answer for each question. For simplicity, we’ll use an LLM that has official tools/function-calling support, like OpenAI’s GPT-4o. The functionality can be achieved with other LLMs as well, but the implementation might be different.</p>
</div>
<div class="readable-text intended-text" id="p54">
<p>Before we dig into the routing function, we need to look into some parts that are needed to be able to successfully build an agentic RAG system. These parts are</p>
</div>
<ul>
<li class="readable-text" id="p55"> Handling tool calls </li>
<li class="readable-text" id="p56"> Continuous query updating </li>
<li class="readable-text" id="p57"> Routing the questions to the relevant retrievers </li>
</ul>
<div class="readable-text" id="p58">
<h4 class="readable-text-h4">Handling tool calls on behalf of the LLM</h4>
</div>
<div class="readable-text" id="p59">
<p>When the LLM returns the best retriever to use, the system needs to make the call to the retriever. This can be done by having a function that takes in the retriever and the arguments and makes the call to the retriever. The following listing shows an example of what that function might look like.</p>
</div>
<div class="browsable-container listing-container" id="p60">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.3</span> Retriever call function</h5>
<div class="code-area-container">
<pre class="code-area">def handle_tool_calls(tools: dict[str, any], llm_tool_calls: list[dict[str, any]]):
    output = []
    if llm_tool_calls:
        for tool_call in llm_tool_calls:
            function_to_call = tools[tool_call.function.name]["function"]
            function_args = json.loads(tool_call.function.arguments)
            res = function_to_call(**function_args)
            output.append(res)
    return output</pre>
</div>
</div>
<div class="readable-text" id="p61">
<p>The <code>tools</code> we’re passing in is a dictionary where the key is the name of the tool and the value is the actual function to call. The <code>llm_tool_calls</code> is a list of the tools the LLM has decided to use and the arguments to pass to the tool. The LLM can decide that it wants to make multiple function calls to respond to a single question. The shape of the <code>llm_tool_calls</code> argument looks like the following:</p>
</div>
<div class="browsable-container listing-container" id="p62">
<div class="code-area-container">
<pre class="code-area">[
    {
        "function": {
            "name": "answer_given",
            "arguments": "{\"answer\": \"Dave Smith\"}"
        }
    }
]</pre>
</div>
</div>
<div class="readable-text" id="p63">
<h4 class="readable-text-h4">Continuous query updating</h4>
</div>
<div class="readable-text" id="p64">
<p>When we get to the retriever router function section later, we’ll see that we will send the questions to the LLM one by one in sequence. This is a deliberate choice to make it easier for the LLM to handle each question individually and to make it easier to route the questions to the right retriever.</p>
</div>
<div class="readable-text intended-text" id="p65">
<p>One extra benefit of sending the questions in sequence is that we can use the answers from the previous questions to rewrite the next question. This can be useful if the user asks a follow-up question that is dependent on the answer to the previous question.</p>
</div>
<div class="readable-text intended-text" id="p66">
<p>Consider the following example: “Who has won the most Oscars, and is that person alive?” A rewrite of this question could be “Who won the most Oscars?” and “Is that person alive?” where the second question is dependent on the answer to the first question.</p>
</div>
<div class="readable-text intended-text" id="p67">
<p>So once we have the answer to the first question, we want to update the remaining questions with the new information. This can be done by calling a query updater with the original question and the answers from the retrievers. The query updater updates the existing questions with the new information.</p>
</div>
<div class="browsable-container listing-container" id="p68">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.4</span> Query updater instructions</h5>
<div class="code-area-container">
<pre class="code-area">query_update_prompt = """
    You are an expert at updating questions to make them more atomic, specific, and easier to find the answer to.
    You do this by filling in missing information in the question, with the extra information provided to you in previous answers.

    You respond with the updated question that has all information in it.
    Only edit the question if needed. If the original question already is atomic, specific, and easy to answer, you keep the original.
    Do not ask for more information than the original question. Only rephrase the question to make it more complete.

    JSON template to use:
    {
        "question": "question1"
    }
"""</pre>
</div>
</div>
<div class="readable-text" id="p69">
<p>The query updater is called with the original question and the answers from the retrievers. The output is the updated question, and we instruct the LLM to return the updated question in a JSON format. It’s important that the LLM doesn’t ask for more information than the original question—only rephrase the question to make it more complete.</p>
</div>
<div class="browsable-container listing-container" id="p70">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.5</span> Query updater function</h5>
<div class="code-area-container">
<pre class="code-area">def query_update(input: str, answers: list[any]) -&gt; str:
    messages = [
        {"role": "system", "content": query_update_prompt},
        *answers,
        {"role": "user", "content": f"The user question to rewrite: '{input}'"},
    ]
    config = {"response_format": {"type": "json_object"}}
    output = chat(messages, model = "gpt-4o", config=config, )
    try:
        return json.loads(output)["question"]
    except json.JSONDecodeError:
        print("Error decoding JSON")
    return []</pre>
</div>
</div>
<div class="readable-text" id="p71">
<p>With this in place, we can update the questions with the new information as we go along and make sure the questions are as complete as possible and that we make it as easy as possible to find the answer to the questions.</p>
</div>
<div class="readable-text" id="p72">
<h4 class="readable-text-h4">Routing the questions</h4>
</div>
<div class="readable-text" id="p73">
<p>The final piece in the retriever router is actually routing the questions to the right retriever. This is done by calling the LLM with the questions and the available tools, and the LLM will return the best retriever to use for each question.</p>
</div>
<div class="readable-text intended-text" id="p74">
<p>First, we need to have our tools available in a dictionary so we can pass them to the LLM but also find them when it’s time to invoke the tools. Let’s start by defining the tools we have available.</p>
</div>
<div class="browsable-container listing-container" id="p75">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.6</span> Available retriever tools dictionary</h5>
<div class="code-area-container">
<pre class="code-area">tools = {
    "movie_info_by_title": {
        "description": movie_info_by_title_description,
        "function": movie_info_by_title
    },
    "movies_info_by_actor": {
        "description": movies_info_by_actor_description,
        "function": movies_info_by_actor
    },
    "text2cypher": {
        "description": text2cypher_description,
        "function": text2cypher
    },
    "answer_given": {
        "description": answer_given_description,
        "function": answer_given
    }
}</pre>
</div>
</div>
<div class="readable-text" id="p76">
<p>Here we’ve grouped the tool descriptions and the actual functions in a dictionary so we can easily find the tools when we need to make the actual call to the tools. Let’s start the prompt to the LLM where we describe its task.</p>
</div>
<div class="browsable-container listing-container" id="p77">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.7</span> Retriever router Instructions</h5>
<div class="code-area-container">
<pre class="code-area">tool_picker_prompt = """
    Your job is to choose the right tool needed to respond to the user question.
    The available tools are provided to you in the request.
    Make sure to pass the right and complete arguments to the chosen tool.
"""</pre>
</div>
</div>
<div class="readable-text" id="p78">
<p>This is a pretty short prompt, but it’s enough to instruct the LLM to pick the right retriever for the job because of the built-in tools/function-calling support. Next we’ll have a look at the function that calls the LLM.</p>
</div>
<div class="browsable-container listing-container" id="p79">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.8</span> Retriever router function</h5>
<div class="code-area-container">
<pre class="code-area">def route_question(question: str, tools: dict[str, any], answers: list[dict[str, str]]):
    llm_tool_calls = tool_choice(
        [
            {
                "role": "system",
                "content": tool_picker_prompt,
            },
            *answers,
            {
                "role": "user",
                "content": f"The user question to find a tool to answer: '{question}'",
            },
        ],
        model = "gpt-4o",
        tools=[tool["description"] for tool in tools.values()],
    )
    return handle_tool_calls(tools, llm_tool_calls)</pre>
</div>
</div>
<div class="readable-text" id="p80">
<p>This function takes a single question and the available tools and the answers from the previous questions. It then calls the LLM with the question and the tools, and the LLM will return the best retriever to use for the question. The last line of the function is a call to the <code>handle_tool_calls</code> function we saw earlier that makes the actual call to the retriever.</p>
</div>
<div class="readable-text intended-text" id="p81">
<p>The final piece of the retrieval router is to tie all previous parts together and go all the way from the user input to the answer. We want to make sure that we have a loop that goes through all questions and that we update the questions with the new information as we go along.</p>
</div>
<div class="browsable-container listing-container" id="p82">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.9</span> Agentic RAG function</h5>
<div class="code-area-container">
<pre class="code-area">def handle_user_input(input: str, answers: list[dict[str, str]] = []):
    updated_question = query_update(input, answers)
    response  = route_question(updated_question, tools, answers)
    answers.append({"role": "assistant", "content": f"For the question: '{updated_question}', we have the answer: '{json.dumps(response)}'"})
    return answers</pre>
</div>
</div>
<div class="readable-text" id="p83">
<p>One thing to note here is that the <code>handle_user_input</code> function optionally takes in a list of answers. We will get to this in section 5.3.3.</p>
</div>
<div class="readable-text intended-text" id="p84">
<p>With this in place, we have a complete agentic RAG system that can take in user input and return the answer to the user. The system is built in a way that it can be extended with more retrievers as needed.</p>
</div>
<div class="readable-text intended-text" id="p85">
<p>We need to implement one more part to make the system complete, and that is the answer critic.</p>
</div>
<div class="readable-text" id="p86">
<h3 class="readable-text-h3"><span class="num-string">5.3.3</span> Implementing the answer critic</h3>
</div>
<div class="readable-text" id="p87">
<p>The job of the answer critic is to take all answers from the retrievers and check if the original question is answered correctly. LLMs are nondeterministic and can make mistakes when rewriting the questions, updating the questions, and routing the questions, so we want to have this check in place to make sure we actually receive the answers we need.</p>
</div>
<div class="readable-text intended-text" id="p88">
<p>The following listing shows instructions to the LLM for the answer critic.</p>
</div>
<div class="browsable-container listing-container" id="p89">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.10</span> Answer critic instructions</h5>
<div class="code-area-container">
<pre class="code-area">answer_critique_prompt = """
    You are an expert at identifying if questions have been fully answered or if there is an opportunity to enrich the answer.
    The user will provide a question, and you will scan through the provided information to see if the question is answered.
    If anything is missing from the answer, you will provide a set of new questions that can be asked to gather the missing information.
    All new questions must be complete, atomic, and specific.
    However, if the provided information is enough to answer the original question, you will respond with an empty list.

    JSON template to use for finding missing information:
    {
        "questions": ["question1", "question2"]
    }
"""</pre>
</div>
</div>
<div class="readable-text" id="p90">
<p>We follow the same pattern as before with the JSON format and the instructions to the LLM.</p>
</div>
<div class="readable-text intended-text" id="p91">
<p>Next, we’ll have a look at the function that calls the LLM.</p>
</div>
<div class="browsable-container listing-container" id="p92">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.11</span> Answer critic function</h5>
<div class="code-area-container">
<pre class="code-area">def critique_answers(question: str, answers: list[dict[str, str]]) -&gt; list[str]:
    messages = [
        {
            "role": "system",
            "content": answer_critique_prompt,
        },
        *answers,
        {
            "role": "user",
            "content": f"The original user question to answer: {question}",
        },
    ]
    config = {"response_format": {"type": "json_object"}}
    output = chat(messages, model="gpt-4o", config=config)
    try:
        return json.loads(output)["questions"]
    except json.JSONDecodeError:
        print("Error decoding JSON")
    return []</pre>
</div>
</div>
<div class="readable-text" id="p93">
<p>This function takes the original question and the answers from the retrievers and calls the LLM to check if the original question is answered correctly. If the question is not answered correctly, the LLM will return a list of new questions that can be asked to gather the missing information.</p>
</div>
<div class="readable-text intended-text" id="p94">
<p>If we get a list of new questions back, we can go through the retriever router again to get the missing information. We should also have some exit criteria from this loop so we don’t get stuck in a loop where we can’t get the answer to the original question from the retrievers.</p>
</div>
<div class="readable-text" id="p95">
<h3 class="readable-text-h3"><span class="num-string">5.3.4</span> Tying it all together</h3>
</div>
<div class="readable-text" id="p96">
<p>So far, we have implemented the retriever agents, the retriever router, and the answer critic. The final piece is to tie it all together in a main function that takes in the user input and returns the answer to the user, if the answer is available.</p>
</div>
<div class="readable-text intended-text" id="p97">
<p>The following listing shows what the main function might look like. Let’s start with the instructions to the LLM.</p>
</div>
<div class="browsable-container listing-container" id="p98">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.12</span> Agentic RAG main instructions</h5>
<div class="code-area-container">
<pre class="code-area">main_prompt = """
    Your job is to help the user with their questions.
    You will receive user questions and information needed to answer the questions
    If the information is missing to answer part of or the whole question, you will say that the information
    is missing. You will only use the information provided to you in the prompt to answer the questions.
    You are not allowed to make anything up or use external information.
"""</pre>
</div>
</div>
<div class="readable-text" id="p99">
<p>It’s very important that the LLM only uses the information provided to it in the prompt to answer the questions. This is to make sure that the system is consistent and that we can trust the answers it provides.</p>
</div>
<div class="readable-text intended-text" id="p100">
<p>Next, we’ll have a look at the main function.</p>
</div>
<div class="browsable-container listing-container" id="p101">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.13</span> Agentic RAG main function</h5>
<div class="code-area-container">
<pre class="code-area">def main(input: str):
    answers = handle_user_input(input)
    critique = critique_answers(input, answers)

    if critique:
        answers = handle_user_input(" ".join(critique), answers)

    llm_response = chat(
        [
            {"role": "system", "content": main_prompt},
            *answers,
            {"role": "user", "content": f"The user question to answer: {input}"},
        ],
        model="gpt-4o",
    )

    return llm_response</pre>
</div>
</div>
<div class="readable-text" id="p102">
<p>The main function runs the user input through the agentic RAG system and returns the answer to the user. If the answer is not complete or is incorrect, the critique function will return a list of new questions that can be asked to gather the missing information.</p>
</div>
<div class="readable-text intended-text" id="p103">
<p>We only critique the answers once; if the answers are still incomplete or incorrect after the critique, we return the answers to the user as is and rely on the LLM to let the user know what’s incomplete.</p>
</div>
<div class="readable-text" id="p104">
<h2 class="readable-text-h2">Summary</h2>
</div>
<ul>
<li class="readable-text" id="p105"> Agentic RAG is a system where a variety of retrieval agents are available to retrieve the data needed to answer the user question. </li>
<li class="readable-text" id="p106"> The main interface to an agentic RAG system is usually some kind of use case or retriever router, whose job is to find the best-suited retriever (or retrievers) to perform the task at hand. </li>
<li class="readable-text" id="p107"> The foundational parts of an agentic RAG system are retriever agents, retriever router, and answer critic. </li>
<li class="readable-text" id="p108"> The main parts of an agentic RAG system can be implemented using an LLM with tools/function-calling support. </li>
<li class="readable-text" id="p109"> The retriever agents can be generic or specialized and should be added over time as needed to improve the performance of the application. </li>
<li class="readable-text" id="p110"> The answer critic is a function that takes in the answers from the retrievers and checks if the original question is answered correctly. </li>
</ul>
</div></body></html>