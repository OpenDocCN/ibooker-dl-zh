["```py\n$ docker run -p 5432:5432  \\  ![1](assets/1.png) ![2](assets/2.png)\n\t-e POSTGRES_USER=fastapi \\\n\t-e POSTGRES_PASSWORD=mysecretpassword \\\n\t-e POSTGRES_DB=backend_db \\\n\t-e PGDATA=/var/lib/postgresql/data \\ ![3](assets/3.png)\n    -v \"$(pwd)\"/dbstorage:/var/lib/postgresql/data \\ ![4](assets/4.png)\n    postgres:latest ![1](assets/1.png)\n```", "```py\n$ pip install alembic sqlalchemy psycopg3\n```", "```py`Questi pacchetti collaudati ti permettono di comunicare direttamente con il database relazionale Postgres tramite Python.`psycopg3` è un popolare adattatore di database PostgreSQL per Python, mentre SQLAlchemy è un toolkit SQL e un ORM che ti permette di eseguire query SQL sul tuo database in Python.    Infine, il pacchetto `alembic` è uno *strumento per la migrazione dei database* creato dagli sviluppatori di SQLAlchemy per essere utilizzato con SQLAlchemy. Il flusso di lavoro per la migrazione dei dati è simile al sistema di controllo delle versioni Git, ma per gli schemi del tuo database. Ti permette di gestire le modifiche e gli aggiornamenti dei tuoi schemi in modo da evitare qualsiasi corruzione dei dati, di tenere traccia delle modifiche nel tempo e di ripristinare qualsiasi modifica se necessario.    ## Definire i modelli ORM    Il primo passo per interrogare il database in Python è quello di definire i modelli ORM con le classi SQLAlchemy, come mostrato nell'[Esempio 7-2](#sqlalchemy_models). Puoi utilizzare gli schemi dei dati del diagramma ERD di cui alla [Figura 8-4](ch08.html#erd).    ###### Nota    Aggiungerai la tabella `user` nel prossimo capitolo quando implementerai i meccanismi di autenticazione e autorizzazione.    ##### Esempio 7-2\\. Definizione dei modelli ORM del database    ```", "```py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO2-1)      Dichiara una classe base dichiarativa per creare modelli SQLAlchemy per il suo motore ORM.      [![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO2-2)      Crea il modello `Conversation` specificando le colonne della tabella, la chiave primaria e gli indici secondari.      [![3](assets/3.png)](#co_integrating_databases_into_ai_services_CO2-3)      Utilizza `mapped_column()` per derivare il tipo di colonna dal suggerimento di tipo dato a `Mapped`.      [![4](assets/4.png)](#co_integrating_databases_into_ai_services_CO2-4)      Indicizza il sito `model_type` se vuoi filtrare più velocemente le conversazioni per tipo di modello.      [![5](assets/5.png)](#co_integrating_databases_into_ai_services_CO2-5)      Specifica i valori predefiniti e le operazioni di aggiornamento per le colonne datetime.      [![6](assets/6.png)](#co_integrating_databases_into_ai_services_CO2-6)      Indica che tutti i messaggi orfani devono essere cancellati se una conversazione viene eliminata tramite un'operazione di `CASCADE DELETE`.      [![7](assets/7.png)](#co_integrating_databases_into_ai_services_CO2-7)      Crea il modello `Message` specificando le colonne della tabella, la chiave primaria, gli indici secondari, le relazioni della tabella e le chiavi esterne.      [![8](assets/8.png)](#co_integrating_databases_into_ai_services_CO2-9)      La tabella `messages` conterrà i prompt e le risposte del LLM, i token di utilizzo e i costi, oltre ai codici di stato e agli stati di successo.      [![9](assets/9.png)](#co_integrating_databases_into_ai_services_CO2-10)      Specifica `Mapped[int | None]` per dichiarare una tipizzazione opzionale in modo che la colonna permetta i valori di `NULL` (cioè `nullable=True`).      Una volta definiti i modelli di dati, puoi creare una connessione al database per creare ogni tabella con le configurazioni specificate. Per ottenere questo risultato, dovrai creare un *motore di database* e implementare la *gestione delle sessioni*.    ## Creazione di un motore di database e gestione delle sessioni    L['esempio 7-3](#sqlalchemy_engine) mostra a come creare un motore SQLAlchemy utilizzando la stringa di connessione al database Postgres. Una volta creato, puoi utilizzare il motore e la classe `Base` per creare tabelle per ciascuno dei tuoi modelli di dati.    ###### Avvertenze    Il metodo `create_all()` di SQLAlchemy nell'[Esempio 7-3](#sqlalchemy_engine) può solo creare tabelle nel database ma non modificare le tabelle esistenti. Questo flusso di lavoro è utile solo se stai facendo dei prototipi e sei contento di reimpostare gli schemi del database con nuove tabelle a ogni esecuzione.    Per gli ambienti di produzione, dovresti utilizzare uno strumento di migrazione del database come `alembic` per aggiornare gli schemi del database ed evitare la perdita involontaria di dati. A breve scoprirai il flusso di lavoro della migrazione del database.    ##### Esempio 7-3\\. Creare il motore del database SQLAlchemy    ```", "```py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO3-1)      Per i database Postgres, la stringa di connessione viene definita utilizzando il seguente modello: `*<driver>*://*<username>*:*<password>*@*<origin>*/*<database>*`.      [![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO3-2)      Crea un motore di database async utilizzando la stringa di connessione al database. Attiva il debug logging con `echo=True`.      [![3](assets/3.png)](#co_integrating_databases_into_ai_services_CO3-3)      Elimina tutte le tabelle esistenti e poi crea tutte le tabelle del database utilizzando i modelli SQLAlchemy definiti nell'[Esempio 7-3](#sqlalchemy_engine).      [![4](assets/4.png)](#co_integrating_databases_into_ai_services_CO3-4)      Smaltisce il motore del database durante il processo di spegnimento del server. Qualsiasi codice dopo la parola chiave `yield` all'interno del gestore del contesto `lifespan` di FastAPI viene eseguito quando viene richiesto lo spegnimento del server.      ###### Avvertenze    Per chiarezza, le variabili d'ambiente e i segreti come le stringhe di connessione al database sono codificati in ogni esempio di codice.    Negli scenari di produzione, non codificare mai i segreti e le variabili d'ambiente. Sfrutta i file d'ambiente, i gestori di segreti e gli strumenti come Pydantic Settings per gestire i segreti e le variabili delle applicazioni.    Dopo aver creato il motore, puoi implementare una funzione di fabbrica per creare sessioni al database. La fabbrica di sessioni è un modello di progettazione che ti permette di aprire, interagire e chiudere le connessioni al database nei tuoi servizi.    Dal momento che puoi riutilizzare una sessione, puoi usare il sistema di iniezione delle dipendenze di FastAPI per memorizzare nella cache e riutilizzare le sessioni in ogni runtime di richiesta, come mostrato nell'[Esempio 7-4](#sqlalchemy_session).    ##### Esempio 7-4\\. Creazione di una sessione di database Dipendenza FastAPI    ```", "```py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO4-1)      Crea un factory di sessione di database asincrono legato al motore di database che hai creato in precedenza per connetterti in modo asincrono alla tua istanza di Postgres. Disabilita il commit automatico delle transazioni con `autocommit=false` e il flushing automatico delle modifiche al database con `autoflush=False`. Disabilitare entrambi i comportamenti ti offre un maggiore controllo, ti aiuta a prevenire aggiornamenti di dati non voluti e ti permette di implementare una gestione delle transazioni più robusta.      [![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO4-2)      Definisci una funzione di dipendenza da riutilizzare e iniettare nella tua applicazione FastAPInelle funzioni delroute controller. Poiché la funzione utilizza la parola chiave `yield` all'interno di `async with`, è considerata un gestore di contesto async. FastAPI decorerà internamente `get_db_session` come gestore di contesto quando viene utilizzata comedipendenza.      [![3](assets/3.png)](#co_integrating_databases_into_ai_services_CO4-3)      Utilizza il factory di sessione del database per creare una sessione asincrona. Il gestore del contesto aiuta a gestire il ciclo di vita della sessione del database come l'apertura, l'interazione e la chiusura delle connessioni al database in ogni sessione.      [![4](assets/4.png)](#co_integrating_databases_into_ai_services_CO4-4)      Restituisce la sessione del database al chiamante della funzione `get_db_session`.      [![5](assets/5.png)](#co_integrating_databases_into_ai_services_CO4-5)      Se si verificano delle eccezioni, annulla la transazione e solleva nuovamente l'eccezione.      [![6](assets/6.png)](#co_integrating_databases_into_ai_services_CO4-6)      In ogni caso, chiudi la sessione del database alla fine per liberare le risorse che detiene.      [![7](assets/7.png)](#co_integrating_databases_into_ai_services_CO4-7)      Dichiara una dipendenza annotata della sessione del database che può essere riutilizzata da diversi controllori.      Ora che puoi creare una sessione del database da qualsiasi rotta FastAPI tramite dependency injection, implementiamo gli endpoint di creazione, lettura, aggiornamento e cancellazione (CRUD) per la risorsa conversazioni.    ## Implementare gli endpoint CRUD    Poiché FastAPI si affida a Pydantic per serializzare e convalidare i dati in entrata e in uscita, prima di implementare gli endpoint CRUD dovrai mappare le entità del database nei modelli di Pydantic. In questo modo eviterai di accoppiare strettamente lo schema dell'API con i modelli del database per darti la libertà e la flessibilità di sviluppare l'API e i database in modo indipendente l'uno dall'altro.    Puoi seguire l'[Esempio 7-5](#sqlalchemy_pydantic) per definire i tuoi schemi CRUD.    ##### Esempio 7-5\\. Dichiarazione degli schemi API di Pydantic per gli endpoint di conversazione    ```", "```py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO5-1)      Impostare il modello Pydantic per leggere e convalidare gli attributi di altri modelli come SQLAlchemy, che viene spesso utilizzato in Pydantic quando si lavora conmodelli di database.      [![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO5-2)      Creare modelli Pydantic separati basati sul modello di base per diversi casi d'uso, come la creazione e l'aggiornamento dei record di conversazione o il recupero dei dati.      ###### Suggerimento    Dover dichiarare i modelli Pydantic e SQLAlchemy può sembrare una duplicazione del codice, ma ti permetterà di implementare il tuo livello di accesso ai dati nel modo che preferisci.    In alternativa, se vuoi evitare la duplicazione del codice, puoi utilizzare il pacchetto `sqlmodel`, che integra Pydantic con SQLAlchemy, eliminando gran parte della duplicazione del codice. Tuttavia, tieni presente che `sqlmodel` potrebbe non essere l'ideale per la produzione a causa della flessibilità limitata e del supporto per i casi d'uso avanzati con SQLAlchemy. Per questo motivo, potresti voler utilizzare modelli Pydantic e SQLAlchemy separati per applicazioni complesse.^([1](ch07.html#id951))    Ora che hai i modelli SQLAlchemy e Pydantic, puoi iniziare a sviluppare gli endpoint delle API CRUD.    Nell'implementazione degli endpoint CRUD, dovresti cercare di sfruttare il più possibile le dipendenze FastAPI per ridurre i giri del database. Ad esempio, quando recuperi, aggiorni e cancelli dei record, devi verificare con il database l'esistenza di un record utilizzando il suo ID.    Puoi implementare una funzione di recupero dei record per utilizzare una dipendenza tra i tuoi endpoint get, update e delete, come mostrato nell'[Esempio 7-6](#sqlalchemy_endpoints).    ###### Avvertenze    Tieni presente che FastAPI può memorizzare nella cache l'output della dipendenza `get_conversation` solo all'interno di una singola richiesta e non su più richieste.    ##### Esempio 7-6\\. Implementazione di endpoint CRUD basati sulle risorse per la tabella `conversations`    ```", "```py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO6-1)      Definisce una dipendenza per verificare se il record della conversazione esiste. Solleva un 404 `HTTPException` se il record non viene trovato; altrimenti, restituisce il record recuperato. Questa dipendenza può essere riutilizzata in diversi endpoint CRUD tramite dependency injection.      [![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO6-2)      Inizia la sessione asincrona all'interno di un gestore di contesto asincrono durante ogni richiesta.      [![3](assets/3.png)](#co_integrating_databases_into_ai_services_CO6-3)      Quando si elencano i record, è più efficiente recuperare solo un sottoinsieme di record. Per impostazione predefinita, SQLAlchemy ORM restituisce un sottoinsieme dei record più recenti del database, ma puoi utilizzare i metodi concatenati `.offset(skip)` e `.limit(take)` per recuperare qualsiasi sottoinsieme di record.      [![4](assets/4.png)](#co_integrating_databases_into_ai_services_CO6-4)      Crea un modello Pydantic da un modello SQLAlchemy utilizzando `model_validate()`. Solleva un `ValidationError` se l'oggetto SQLAlchemy passato non può essere creato o non supera i controlli di validazione dei dati di Pydantic.      [![5](assets/5.png)](#co_integrating_databases_into_ai_services_CO6-5)      Per le operazioni che modificano un record (ad esempio, creazione, aggiornamento e cancellazione), esegui il commit della transazione e invia il record aggiornato al client, ad eccezione dell'operazione di cancellazione che deve restituire `None`.      Nota come la logica del controllore viene semplificata grazie a questo approccio di dependency injection.    Inoltre, presta attenzione ai codici di stato di successo che devi inviare al cliente. Le operazioni di recupero riuscite dovrebbero restituire 200, mentre le operazioni di creazione dei record restituiscono 201, gli aggiornamenti 202 e le cancellazioni 204.    Congratulazioni! Ora hai un'API RESTful basata su risorse che puoi utilizzare per eseguire operazioni CRUD sulla tua tabella `conversations`.    Ora che puoi implementare gli endpoint CRUD, rifattorizziamo gli esempi di codice esistenti per utilizzare il modello di progettazione di *repository e servizi* che hai imparato nel [Capitolo 2](ch02.html#ch02). Con questo modello di progettazione, puoi astrarre le operazioni del database per ottenere una base di codice più modulare, manutenibile e testabile.    ## Pattern di progettazione di repository e servizi    Un*repository* *è un modello di progettazione che media la logica di business della tua applicazione e il livello di accesso al database, ad esempio tramite un ORM. Contiene diversi metodi per eseguire operazioni CRUD nel livello del database.*   *Nel [Capitolo 2](ch02.html#ch02) hai visto per la prima volta la [Figura 7-4](#onion), che mostrava la posizione dei repository all'interno dell'architettura applicativa a cipolla/strato quando si lavora con un database.  ![bgai 0704](assets/bgai_0704.png)  ###### Figura 7-4\\. Il modello di repository all'interno dell'architettura applicativa a cipolla/strato    Per implementare un pattern di repository, puoi utilizzare un'*interfaccia astratta*, che impone alcuni vincoli su come definire le classi specifiche del repository, come puoi vedere nell'[Esempio 7-7](#sqlalchemy_repository).    ###### Nota    Se non hai mai usato le classi *astratte*, si tratta di classi che non possono essere istanziate da sole. Le classi astratte possono contenere metodi non implementati che le loro sottoclassi devono implementare.    Una classe concreta è una classe che eredita una classe astratta e implementa tutti i suoi metodi astratti.    ##### Esempio 7-7\\. Implementazione dell'interfaccia astratta di un repository    ```", "```py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO7-1)      Definisce l'interfaccia astratta `Repository` con diverse firme di metodi astratti relativi al CRUD che le sottoclassi devono implementare. Se un metodo astratto non è implementato in una sottoclasse concreta, verrà sollevato un`NotImplementedError`.      Ora che hai una classe `Repository`, puoi dichiarare delle sottoclassi per ciascuna delle tue tabelle per definire come devono essere eseguite le operazioni sul database seguendo i metodi basati sul CRUD. Ad esempio, per eseguire le operazioni CRUD sui record di conversazione nel database, puoi implementare una classe concreta `ConversationRepository`, come mostrato nell'[Esempio 7-8](#sqlalchemy_conversation_repository).    ##### Esempio 7-8\\. Implementazione del repository di conversazione utilizzando l'interfaccia del repository astratto    ```", "```py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO8-1)      Eredita l'interfaccia astratta `Repository` e implementa tutti i suoi metodi rispettando le firme dei metodi.      Ora hai spostato la logica del database per le conversazioni all'interno di`ConversationRepository`. Questo significa che puoi importare questa classe nelle funzioni del controller della tua rotta e iniziare a usarla subito.    Torna al file `main.py` e rifattorizza i controllori di rotta in modo che utilizzino il file`ConversationRepository`, come mostrato nell'[Esempio 7-9](#sqlalchemy_conversation_repository_endpoints).    ##### Esempio 7-9\\. Refactoring degli endpoint CRUD delle conversazioni per utilizzare lo schema del repository    ```", "```py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO9-1)      Posiziona le rotte CRUD di conversazione su un router API separato e includile nell'applicazione FastAPI per un design API modulare.      [![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO9-2)      Refactoring delle rotte CRUD di conversazione per utilizzare lo schema del repository per rendere più leggibile l'implementazione del controller.      Hai notato come i tuoi route controller appaiono più puliti ora che la logica del database è stata astratta all'interno della classe `ConversationRepository`?    Un pattern di *servizio* è un'estensione del pattern di repository che incapsula la logica di business e le operazioni in un livello superiore. Queste operazioni di livello superiore spesso richiedono query più complesse e una sequenza di operazioni CRUD da eseguire per implementare la logica di business.    Ad esempio, puoi implementare un `ConversationService` per recuperare i messaggi relativi a una conversazione o a un utente specifico (vedi [Esempio 7-10](#sqlalchemy_conversation_service)). Poiché estende un`ConversationRepository`, puoi comunque accedere ai metodi CRUD di accesso ai dati di livello inferiore come `list`, `get`, `create`, `update` e`delete`.    Ancora una volta puoi tornare ai tuoi controllori e sostituire i riferimenti al sito con i riferimenti al sito .`ConversationRepository` con quello di`ConversationService`. Inoltre, puoi utilizzare lo stesso servizio per aggiungere un nuovo endpoint per recuperare i messaggi all'interno di una singolaconversazione.    ##### Esempio 7-10\\. Implementazione del pattern dei servizi di conversazione    ```", "```py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO10-1)      Aggiungi un nuovo endpoint per elencare i messaggi di una conversazione utilizzando l'ID della conversazione.      Ora hai un'API RESTful perfettamente funzionante per interagire con i dati delle tue conversazioni seguendo i modelli di repository e di servizio.    ###### Suggerimento    Ora che hai una maggiore familiarità con il modello di repository e servizi, puoi provare a implementare gli endpoint CRUD per la tabella `messages`.    Quando utilizzi i modelli di repository e di servizio, fai attenzione a non accoppiare strettamente i tuoi servizi a specifiche implementazioni del repository e a non sovraccaricare i tuoi servizi con molte responsabilità. Mantieni i repository focalizzati sull'accesso e la manipolazione dei dati ed evita di inserire la logica di business.    Dovrai anche gestire correttamente le transazioni e le eccezioni del database, soprattutto quando si eseguono più operazioni correlate. Inoltre, considera le implicazioni sulle prestazioni delle tue query, come ad esempio l'inclusione di molte JOIN, e ottimizza le query dove è possibile.    È buona norma utilizzare convenzioni di denominazione coerenti per i metodi e le classi ed evitare di codificare le impostazioni di configurazione.    C'è un altro aspetto del flusso di lavoro dello sviluppo dei database che dobbiamo affrontare: la gestione di schemi di database in continua evoluzione, in particolare nei team collaborativi in cui più persone lavorano sullo stesso database sia in ambienti di sviluppo che di produzione.*```", "```py```", "``` $ alembic init ```", "``` project/     alembic.ini     alembic/         env.py ![1](assets/1.png) README         script.py.mako         versions/ ![2](assets/2.png) <migration .py files will appear here> ```", "``` # alembic/env.py  from entities import Base from settings import AppSettings  settings = AppSettings() target_metadata = Base db_url = str(settings.pg_dsn)  ... ```", "``` $ alembic revision --autogenerate -m \"Initial Migration\" ```", "```` Questo comando confronta i modelli SQLAlchemy definiti con lo schema del database esistente e genera automaticamente un file di migrazione SQL nella directory`alembic/versions` nella directory    Se apri il file di migrazione generato, dovresti vedere un contenuto del file simile all'[Esempio 7-14](#alembic_initial_migration).    ##### Esempio 7-14\\. La migrazione iniziale di Alembic    ```py # alembic/versions/24c35f32b152.py  from datetime import UTC, datetime import sqlalchemy as sa from alembic import op  \"\"\" Revision ID: 2413cf32b712 Revises: Create Date: 2024-07-11 12:30:17.089406 \"\"\"  # revision identifiers, used by Alembic. revision = \"24c35f32b152\" down_revision = None branch_labels = None  def upgrade():     op.create_table(         \"conversations\",         sa.Column(\"id\", sa.BigInteger, primary_key=True),         sa.Column(\"title\", sa.String, nullable=False),         sa.Column(\"model_type\", sa.String, index=True, nullable=False),         sa.Column(             \"created_at\", sa.DateTime, default=datetime.now(UTC), nullable=False         ),         sa.Column(             \"updated_at\",             sa.DateTime,             default=datetime.now(UTC),             onupdate=datetime.now(UTC),             nullable=False,         ),     )      op.create_table(         \"messages\",         sa.Column(\"id\", sa.BigInteger, primary_key=True),         sa.Column(             \"conversation_id\",             sa.BigInteger,             sa.ForeignKey(\"conversations.id\", ondelete=\"CASCADE\"),             index=True,             nullable=False,         ),         sa.Column(\"prompt_content\", sa.Text, nullable=False),         sa.Column(\"response_content\", sa.Text, nullable=False),         sa.Column(\"prompt_tokens\", sa.Integer, nullable=True),         sa.Column(\"response_tokens\", sa.Integer, nullable=True),         sa.Column(\"total_tokens\", sa.Integer, nullable=True),         sa.Column(\"is_success\", sa.Boolean, nullable=True),         sa.Column(\"status_code\", sa.Integer, nullable=True),         sa.Column(             \"created_at\", sa.DateTime, default=datetime.now(UTC), nullable=False         ),         sa.Column(             \"updated_at\",             sa.DateTime,             default=datetime.now(UTC),             onupdate=datetime.now(UTC),             nullable=False,         ),     )  def downgrade():     op.drop_table(\"messages\")     op.drop_table(\"conversations\") ```    Ora che hai aggiornato il tuo primo file di migrazione, sei pronto per eseguirlo sul database:    ```py $ alembic upgrade head ```   ``Se hai bisogno di ripristinare l'operazione, puoi eseguire `alembic downgrade`.    Alembic genera l'SQL grezzo necessario per eseguire o ripristinare una migrazione e crea una tabella`alembic_versions` nel database. Utilizza questa tabella per tenere traccia delle migrazioni già applicate al database, in modo che eseguendo nuovamente il comando `alembic upgrade head` non vengano eseguite migrazioni duplicate.    Se in ogni caso gli schemi del database e la cronologia della migrazione si allontanano, puoi sempre rimuovere i file dalla directory `versions` e troncare la tabella`alembic_revision`. Poi reinizializza Alembic per iniziare con un ambiente nuovo e un database esistente.    ###### Avvertenze    Dopo aver migrato un database con un file di migrazione, assicurati di eseguire il commit in un repository Git. Evita di modificare nuovamente i file di migrazione dopo aver migrato un database, poiché Alembic salterà le migrazioni esistenti effettuando un controllo incrociato con la sua tabella di versioning.    Se un file di migrazione è già stato eseguito, non rileverà le modifiche al suo contenuto.    Per aggiornare lo schema del database, crea invece un nuovo file di migrazione.    Seguendo il flusso di lavoro sopra descritto, non solo potrai controllare la versione degli schemi del tuo database, ma potrai anche gestire le modifiche agli ambienti di produzione in base ai cambiamenti dei requisiti dell'applicazione.`` ```py`  ````", "```py`# Memorizzare i dati quando si lavora con gli stream in tempo reale    Ora dovresti essere in grado di implementare i tuoi endpoint CRUD per recuperare e modificare i record delle conversazioni e dei messaggi degli utenti nel tuo database.    Una domanda che rimane senza risposta è come gestire le transazioni all'interno degli endpoint di streaming dei dati, come ad esempio un LLM che trasmette gli output a un client.    Non puoi inviare i dati in streaming a un database relazionale tradizionale, perché garantire la conformità ACID con le transazioni in streaming sarà un'impresa ardua. Al contrario, vorrai eseguire le operazioni standard sul database non appena il server FastAPI restituisce una risposta al client. Questa sfida è esattamente ciò che un'attività in background di FastAPI può risolvere, come puoi vedere nell'[Esempio 7-15](#db_stream).    ##### Esempio 7-15\\. Memorizzazione del contenuto di un flusso di output LLM    ```", "```py    [![1](assets/1.png)](#co_integrating_databases_into_ai_services_CO12-1)      Crea una funzione per memorizzare un messaggio rispetto a una conversazione.      [![2](assets/2.png)](#co_integrating_databases_into_ai_services_CO12-2)      Controlla che il record della conversazione esista e lo recupera all'interno di una dipendenza.      [![3](assets/3.png)](#co_integrating_databases_into_ai_services_CO12-3)      Crea due copie separate del flusso LLM, una per il sito `StreamingResponse` e un'altra da elaborare in un'attività in background.      [![4](assets/4.png)](#co_integrating_databases_into_ai_services_CO12-4)      Crea un'attività in background per memorizzare il messaggio al termine di `StreamingResponse`.      Nell'[Esempio 7-15](#db_stream), permetti a FastAPI di trasmettere completamente la risposta LLM al client.    Non importa se stai utilizzando un endpoint SSE o WebSocket. Una volta che la richiesta e la risposta sono state inviate in streaming, richiama un'attività in background passando il contenuto completo della risposta in streaming. All'interno dell'attività in background, puoi eseguire una funzione per memorizzare il messaggio dopo l'invio della richiesta, con il contenuto completo della risposta LLM.    Utilizzando lo stesso approccio, puoi anche generare un titolo per una conversazione in base al contenuto del primo messaggio. A tal fine, puoi invocare nuovamente il LLM con il contenuto del primo messaggio della conversazione, richiedendo un titolo appropriato per la conversazione. Una volta generato il titolo della conversazione, puoi creare il record della conversazione nel database, come mostrato nell'[Esempio 7-16](#conversation_title).    ##### Esempio 7-16\\. Utilizzo del LLM per generare titoli di conversazione basati sul prompt iniziale dell'utente    ```", "```py    L'uso di SQLAlchemy con Alembic è un approccio collaudato per lavorare con i database relazionali in FastAPI, quindi è più probabile che troverai molte risorse sull'integrazione di queste tecnologie.    Sia l'ORM SQLAlchemy che Alembic ti permettono di interagire con il tuo database e di controllare le modifiche ai suoi schemi.    # Riassunto    In questo capitolo hai approfondito gli aspetti critici dell'integrazione di un database nella tua applicazione FastAPI per memorizzare e recuperare le conversazioni degli utenti.    Hai imparato a capire quando è necessario un database e come identificare il tipo appropriato per il tuo progetto, sia esso relazionale o non relazionale. Comprendendo i meccanismi alla base dei database relazionali e i casi d'uso dei database non relazionali, sei ora in grado di prendere decisioni informate sulla scelta del database.    Hai anche esplorato il flusso di sviluppo, gli strumenti e le migliori pratiche per lavorare con i database relazionali, imparando tecniche per migliorare le prestazioni e l'efficienza delle query e strategie per gestire le modifiche allo schema del database. Inoltre, hai acquisito conoscenze sulla gestione della base di codice, dello schema del database e delle derive dei dati quando lavori in team.    Il prossimo capitolo ti guiderà nell'implementazione della gestione degli utenti, dell'autenticazione e dei meccanismi di autorizzazione, per migliorare ulteriormente la sicurezza della tua applicazione e l'esperienza degli utenti, partendo dalle solide basi del database che hai creato in questo capitolo.    ^([1](ch07.html#id951-marker)) Fai riferimento a questo [thread di discussione su Reddit](https://oreil.ly/OMaOT).```", "```py``*```"]