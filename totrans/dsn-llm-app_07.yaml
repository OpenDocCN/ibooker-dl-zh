- en: Chapter 5\. Adapting LLMs to Your Use Case
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章\. 将LLM适应您的用例
- en: In this chapter, we will continue with our journey through the LLM landscape,
    exploring the various LLMs available for commercial use and providing pointers
    on how to choose the right LLM for your task. We will also examine how to load
    LLMs of various sizes and run inference on them. We will then decipher various
    decoding strategies for text generation. We will also investigate how to interpret
    the outputs and intermediate results from language models, surveying interpretability
    tools like LIT-NLP.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将继续我们的LLM领域之旅，探索可用于商业用途的各种LLM，并提供如何选择适合您任务的正确LLM的指南。我们还将检查如何加载各种大小的LLM并在其上进行推理。然后我们将解码各种用于文本生成的解码策略。我们还将研究如何解释语言模型的输出和中间结果，并对LIT-NLP等可解释性工具进行概述。
- en: Navigating the LLM Landscape
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索LLM领域
- en: Seemingly a new LLM is being released every few days, many claiming to be state
    of the art. Most of these LLMs are not very different from each other, so you
    need not spend too much time tracking new LLM releases. This book’s [GitHub repository](https://oreil.ly/llm-playbooks)
    attempts to keep track of the major releases, but I don’t promise it will be complete.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来每隔几天就会发布一个新的LLM，许多都声称是业界领先。这些LLM之间并没有太大的区别，因此您不需要花太多时间跟踪新的LLM发布。本书的 [GitHub仓库](https://oreil.ly/llm-playbooks)
    尝试跟踪主要发布，但我不能保证它会完整。
- en: Nevertheless, it is a good idea to have a broad understanding of the different
    types of LLM providers out there, the kinds of LLMs being made available, and
    the copyright and licensing implications. Therefore, let’s now explore the LLM
    landscape through this lens and understand the choices at our disposal.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，了解不同类型的LLM提供商、可用的LLM种类以及版权和许可影响是一个好主意。因此，现在让我们通过这个视角来探索LLM领域，并了解我们可用的选择。
- en: Who Are the LLM providers?
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哪些是LLM提供商？
- en: 'LLM providers can be broadly categorized into the following types:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: LLM提供商可以大致分为以下几种类型：
- en: Companies providing proprietary LLMs
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 提供专有LLM的公司
- en: These include companies like OpenAI [(GPT)](https://oreil.ly/r-lb1), Google
    [(Gemini)](https://oreil.ly/KF9Kh), Anthropic [(Claude)](https://oreil.ly/T5Wvo),
    [Cohere](https://oreil.ly/PiKxN), [AI21](https://oreil.ly/Y8T3q), etc. that train
    proprietary LLMs and make them available as an API endpoint (LLM-as-a-service).
    Many of these companies have also partnered with cloud providers that facilitate
    access to these models as a fully managed service. The relevant offerings from
    the major cloud providers are [Amazon Bedrock](https://oreil.ly/FVqRj) and [SageMaker
    JumpStart by Amazon](https://oreil.ly/e0a59), [Vertex AI by Google](https://oreil.ly/mURoC),
    and [Azure OpenAI by Microsoft](https://oreil.ly/Ag1r5).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括像OpenAI [(GPT)](https://oreil.ly/r-lb1)、Google [(Gemini)](https://oreil.ly/KF9Kh)、Anthropic
    [(Claude)](https://oreil.ly/T5Wvo)、[Cohere](https://oreil.ly/PiKxN)、[AI21](https://oreil.ly/Y8T3q)等公司，它们训练专有LLM并将它们作为API端点（LLM-as-a-service）提供。许多这些公司还与云服务提供商合作，以完全托管服务的形式提供对这些模型的访问。主要云服务提供商的相关产品包括
    [Amazon Bedrock](https://oreil.ly/FVqRj) 和 [SageMaker JumpStart by Amazon](https://oreil.ly/e0a59)、[Vertex
    AI by Google](https://oreil.ly/mURoC)、以及 [Azure OpenAI by Microsoft](https://oreil.ly/Ag1r5)。
- en: Companies providing open source LLMs
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 提供开源LLM的公司
- en: These include companies that make the LLM weights public and monetize through
    providing deployment services ([Together AI](https://oreil.ly/urcAf)), companies
    whose primary business would benefit from more LLM adoption ([Cerebras](https://oreil.ly/2cVYY)),
    and research labs that have been releasing LLMs since the early days of Transformers
    (Microsoft, Google, Meta, Salesforce, etc.). Note that companies like Google have
    released both proprietary and open source LLMs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括那些使LLM权重公开并通过提供部署服务来盈利的公司 ([Together AI](https://oreil.ly/urcAf))，那些主要业务将从更多LLM采用中受益的公司
    ([Cerebras](https://oreil.ly/2cVYY))，以及自Transformer早期就一直在发布LLM的研究实验室（微软、谷歌、Meta、Salesforce等）。请注意，像谷歌这样的公司已经发布了专有和开源的LLM。
- en: Self-organizing open source collectives and community research organizations
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自组织开源集体和社区研究组织
- en: This includes the pioneering community research organization [Eleuther AI](https://oreil.ly/ZSlbG),
    and [Big Science](https://oreil.ly/_NlUD). These organizations rely on grants
    for compute infrastructure.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括开创性的社区研究组织 [Eleuther AI](https://oreil.ly/ZSlbG) 和 [Big Science](https://oreil.ly/_NlUD)。这些组织依赖资助来获得计算基础设施。
- en: Academia and government
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 学术界和政府
- en: Due to the high capital costs, not many LLMs have come out of academia so far.
    Examples of LLMs from government/academia include the Abu Dhabi government-funded
    [Technology Innovation Institute](https://oreil.ly/aMwO2), which released the
    [Falcon model](https://oreil.ly/vdhsL), and Tsinghua University, which released
    the [GLM model](https://oreil.ly/K0_zX).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由于高昂的资本成本，到目前为止，还没有很多LLM（大型语言模型）从学术界走出。来自政府/学术界的LLM例子包括阿布扎比政府资助的[技术创新研究所](https://oreil.ly/aMwO2)，它发布了[Falcon模型](https://oreil.ly/vdhsL)，以及清华大学，它发布了[GLM模型](https://oreil.ly/K0_zX)。
- en: '[Table 5-1](#llm-provider-categories) shows the players in the LLM space, the
    category of entity they belong to, and the pre-trained models they have published.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[表5-1](#llm-provider-categories)显示了LLM领域的参与者、他们所属的实体类别以及他们发布的预训练模型。'
- en: Table 5-1\. LLM Providers
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 表5-1\. LLM提供商
- en: '| Name | Category | Pre-trained models released |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 类别 | 发布的预训练模型 |'
- en: '| --- | --- | --- |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Google | Company | BERT, MobileBERT, T5, FLAN-T5, ByT5, Canine, UL2, Flan-UL2,
    Pegasus PaLM, PaLMV2, ELECTRA, Tapas, Switch |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| Google | 公司 | BERT, MobileBERT, T5, FLAN-T5, ByT5, Canine, UL2, Flan-UL2,
    Pegasus PaLM, PaLMV2, ELECTRA, Tapas, Switch |'
- en: '| Microsoft | Company | DeBERTa, DialoGPT, BioGPT, MPNet |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| Microsoft | 公司 | DeBERTa, DialoGPT, BioGPT, MPNet |'
- en: '| OpenAI | Company | GPT-2, GPT-3, GPT-3.5, GPT-4 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| OpenAI | 公司 | GPT-2, GPT-3, GPT-3.5, GPT-4 |'
- en: '| Amazon | Company | Titan |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| Amazon | 公司 | Titan |'
- en: '| Anthropic | Company | Claude, Claude-2 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| Anthropic | 公司 | Claude, Claude-2 |'
- en: '| Cohere | Company | Cohere Command, Cohere Base |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| Cohere | 公司 | Cohere Command, Cohere Base |'
- en: '| Meta | Company | RoBERTa, Llama, Llama 2, BART, OPT, Galactica |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| Meta | 公司 | RoBERTa, Llama, Llama 2, BART, OPT, Galactica |'
- en: '| Salesforce | Company | CTRL, XGen, EinsteinGPT |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| Salesforce | 公司 | CTRL, XGen, EinsteinGPT |'
- en: '| MosaicML | Company (Acquired by Databricks) | MPT |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| MosaicML | 公司（被Databricks收购） | MPT |'
- en: '| Cerebras | Company | Cerebras-GPT, BTLM |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| Cerebras | 公司 | Cerebras-GPT, BTLM |'
- en: '| Databricks | Company | Dolly-V1, Dolly-V2 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| Databricks | 公司 | Dolly-V1, Dolly-V2 |'
- en: '| Stability AI | Company | StableLM |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| Stability AI | 公司 | StableLM |'
- en: '| Together AI | Company | RedPajama |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Together AI | 公司 | RedPajama |'
- en: '| Ontocord AI | Nonprofit | MDEL |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| Ontocord AI | 非营利组织 | MDEL |'
- en: '| Eleuther AI | Nonprofit | Pythia, GPT Neo, GPT-NeoX, GPT-J |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| Eleuther AI | 非营利组织 | Pythia, GPT Neo, GPT-NeoX, GPT-J |'
- en: '| Big Science | Nonprofit | BLOOM |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 大科学 | 非营利组织 | BLOOM |'
- en: '| Tsinghua University | Academic | GLM |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 清华大学 | 学术机构 | GLM |'
- en: '| Technology Innovation Institute | Academic | Falcon |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 技术创新研究所 | 学术机构 | Falcon |'
- en: '| UC Berkeley | Academic | OpenLLaMA |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 加州大学伯克利分校 | 学术机构 | OpenLLaMA |'
- en: '| Adept AI | Company | Persimmon |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| Adept AI | 公司 | Persimmon |'
- en: '| Mistral AI | Company | Mistral |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| Mistral AI | 公司 | Mistral |'
- en: '| AI21 Labs | Company | Jurassic |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| AI21 Labs | 公司 | Jurassic |'
- en: '| X.AI | Company | Grok |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| X.AI | 公司 | Grok |'
- en: Model Flavors
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型风味
- en: Each model is usually released with multiple variants. It is customary to release
    different-sized variants of the same model. As an example, Llama 2 comes in 7B,
    13B, and 70B sizes, where these numbers refer to the number of parameters in the
    model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型通常都会发布多个变体。发布相同模型的不同大小的变体是惯例。例如，Llama 2有7B、13B和70B三种大小，这些数字指的是模型中的参数数量。
- en: These days, LLM providers augment their pre-trained models in various ways to
    make them more amenable to user tasks. The augmentation process typically involves
    fine-tuning the model in some way, often incorporating human supervision. Some
    of these fine-tuning exercises can cost millions of dollars in terms of human
    annotations. We will refer to pre-trained models that have not undergone any augmentation
    as base models.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些天，LLM提供商以各种方式增强他们的预训练模型，使其更易于用户任务。增强过程通常涉及以某种方式微调模型，通常包括人工监督。这些微调练习中的一些可能需要数百万美元的人工标注费用。我们将未经过任何增强的预训练模型称为基础模型。
- en: The following sections describe some of the popular augmentation types.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下章节描述了一些流行的增强类型。
- en: Instruct-models
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指令模型
- en: Instruct-models, or instruction-tuned models, are specialized in following instructions
    written in natural language. While base models possess powerful capabilities,
    they are akin to a rebellious teenager; effectively interacting with them is possible
    only after tediously engineering the right prompts through trial and error, which
    tend to be brittle. This is because the base models are trained on either denoising
    objectives or next-word prediction objectives, which are different from the tasks
    users typically want to solve. By instruction-tuning the base model, the resulting
    model is able to more effectively respond to human instructions and be helpful.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 指令模型或指令调整模型专门用于遵循用自然语言编写的指令。虽然基础模型具有强大的能力，但它们就像一个叛逆的青少年；只有通过反复试验和错误地精心设计正确的提示，才能有效地与之互动，这些提示往往很脆弱。这是因为基础模型是在去噪目标或下一词预测目标上训练的，这与用户通常想要解决的问题不同。通过指令调整基础模型，得到的模型能够更有效地响应人类指令并发挥作用。
- en: A typical instruction-tuning dataset consists of a diverse set of tasks expressed
    in natural language, along with input-output pairs. In [Chapter 6](ch06.html#llm-fine-tuning),
    we will explore various techniques to construct instruction-tuning datasets and
    demonstrate how to perform instruction-tuning on a model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的指令调整数据集包括一组用自然语言表达的任务，以及输入-输出对。在[第6章](ch06.html#llm-fine-tuning)中，我们将探讨构建指令调整数据集的各种技术，并演示如何在模型上执行指令调整。
- en: Here is an example from a popular instruction-tuning dataset called [FLAN](https://oreil.ly/YJ_Xr).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个来自流行的指令调整数据集[FLAN](https://oreil.ly/YJ_Xr)的例子。
- en: '*Prompt:* “What is the sentiment of the following review? The pizza was ok
    but the service was terrible. I stopped in for a quick lunch and got the slice
    special but it ended up taking an hour after waiting several minutes for someone
    at the front counter and then again for the slices. The place was empty other
    than myself, yet I couldn’t get any help/service. OPTIONS: - negative - positive”'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* “以下评论的情感是什么？披萨还可以，但服务太糟糕了。我停下来吃了个快速午餐，点了特制披萨，但等了几个小时，先是等前台有人，然后又等披萨。除了我自己，店里空无一人，但我得不到任何帮助/服务。选项：-
    负面 - 正面”'
- en: ''
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*FLAN:* “Negative”'
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*FLAN:* “负面”'
- en: In this example, the input consists of an instruction, “What is the sentiment
    of the following review?” expressed in a way that humans would naturally express,
    along with the input and output. The input is the actual review and the output
    is the solution to the task, either generated by a model or annotated by a human.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，输入包括一个指令，“以下评论的情感是什么？”以人类自然表达的方式表达，以及输入和输出。输入是实际的评论，输出是任务的解决方案，可以是模型生成的或由人类标注的。
- en: '[Figure 5-1](#instruction-tuning1) demonstrates the instruction-tuning process.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-1](#instruction-tuning1) 展示了指令调整过程。'
- en: '![Instruction tuning process](assets/dllm_0501.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![指令调整过程](assets/dllm_0501.png)'
- en: Figure 5-1\. Instruction-tuning process
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1\. 指令调整过程
- en: Instruction-tuning is one of several techniques that come under the umbrella
    of supervised fine-tuning (SFT). In addition to improving the ability of a model
    to respond effectively to user tasks, SFT-based approaches can also be used to
    make it less harmful by training on safety datasets that help align model outputs
    with the values and preferences of the model creators.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 指令调整是监督微调（SFT）范畴下的几种技术之一。除了提高模型有效响应用户任务的能力外，基于SFT的方法还可以通过在安全数据集上训练来减少其危害性，这些数据集有助于使模型输出与模型创建者的价值观和偏好保持一致。
- en: More advanced techniques to achieve this alignment include reinforcement learning-based
    methods like reinforcement learning from human feedback (RLHF) and reinforcement
    learning from AI feedback (RLAIF).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这种对齐的更高级技术包括基于强化学习的方法，如基于人类反馈的强化学习（RLHF）和基于AI反馈的强化学习（RLAIF）。
- en: In RLHF training, human annotators select or rank candidate outputs based on
    certain criteria, like helpfulness and harmlessness. These annotations are used
    to iteratively train a reward model, which ultimately leads to the LLM being more
    controllable, for example, by refusing to answer inappropriate requests from users.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在RLHF训练中，人类标注员根据某些标准（如有用性和无害性）选择或对候选输出进行排序。这些标注用于迭代训练奖励模型，最终导致LLM更具可控性，例如，拒绝回答用户的不适当请求。
- en: '[Figure 5-2](#rlhf-1) shows the RLHF training process.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-2](#rlhf-1) 展示了RLHF训练过程。'
- en: '![RLHF](assets/dllm_0502.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![RLHF](assets/dllm_0502.png)'
- en: Figure 5-2\. Reinforcement learning from human feedback
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-2\. 来自人类反馈的强化学习
- en: We will cover RLHF and other alignment techniques in detail in [Chapter 8](ch08.html#ch8).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第8章中详细介绍RLHF和其他对齐技术。[第8章](ch08.html#ch8)。
- en: Instead of relying on human feedback for alignment training, one can also leverage
    LLMs to choose between outputs based on their adherence to a set of principles
    (don’t be racist, don’t be rude, etc.). This technique was introduced by Anthropic
    and is called RLAIF. In this technique, humans only provide a desired set of principles
    and values (referred to as [Constitutional AI](https://oreil.ly/d8FeW)), and the
    LLM is tasked with determining whether its outputs adhere to these principles.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 除了依赖人类反馈进行对齐训练外，还可以利用LLM根据其遵循一组原则（不要种族歧视，不要无礼等）来选择输出。这种技术由Anthropic引入，称为RLAIF。在这种技术中，人类只提供一组期望的原则和价值观（称为[宪法AI](https://oreil.ly/d8FeW)），而LLM的任务是确定其输出是否遵循这些原则。
- en: Instruction-tuned models often take the suffix *instruct*, like RedPajama-Instruct.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 指令调整模型通常带有后缀*instruct*，例如RedPajama-Instruct。
- en: Chat-models
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 聊天模型
- en: Chat-models are instruction-tuned models that are optimized for multi-turn dialog.
    Examples include ChatGPT, Llama 2-Chat, MPT-Chat, OpenAssistant, etc.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天模型是针对多轮对话优化的指令调整模型。例如包括ChatGPT、Llama 2-Chat、MPT-Chat、OpenAssistant等。
- en: Long-context models
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 长内容模型
- en: As discussed in [Chapter 1](ch01.html#chapter_llm-introduction), Transformer-based
    LLMs have a limited context length. To recap, context length typically refers
    to the sum of the number of input and output tokens processed by the model per
    invocation. Typical context lengths of modern LLMs range from 8,000 to 128,000
    tokens, with some variants of Gemini supporting over a million tokens. Some models
    are released with a long-context variant; for example GPT 3.5 comes with a default
    4K context size but also has a 16K context size variant. [MPT](https://oreil.ly/wKqdL)
    also has a long-context variant that has been trained on 65k context length but
    can potentially be used for even longer contexts during inference.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如第1章[LLM简介](ch01.html#chapter_llm-introduction)中所述，基于Transformer的LLM具有有限的内容长度。为了回顾，内容长度通常指每次调用模型处理的输入和输出标记的总数。现代LLM的典型内容长度从8,000到128,000个标记不等，一些Gemini的变体支持超过一百万个标记。一些模型发布了长内容变体；例如，GPT
    3.5默认有4K的内容大小，但也有16K的内容大小变体。[MPT](https://oreil.ly/wKqdL)也有一个经过65k内容长度训练的长内容变体，但在推理过程中可以潜在地用于更长的上下文。
- en: Domain-adapted or task-adapted models
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 领域适应或任务适应模型
- en: LLM providers also might perform fine-tuning on specific tasks like summarization
    or financial sentiment analysis. They may also produce distilled versions of the
    model, where a smaller model is fine-tuned on outputs from the larger model for
    a particular task. Examples of task-specific fine-tunes include [FinBERT](https://oreil.ly/uKUAp),
    which is fine-tuned on financial sentiment analysis datasets, and [UniversalNER](https://oreil.ly/8A0pn),
    which is distilled using named-entity-recognition data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: LLM提供商也可能对特定任务，如摘要或金融情感分析进行微调。他们还可能产生模型的精简版本，其中较小的模型针对特定任务的较大模型输出进行微调。特定任务微调的例子包括[FinBERT](https://oreil.ly/uKUAp)，它在金融情感分析数据集上进行微调，以及[UniversalNER](https://oreil.ly/8A0pn)，它使用命名实体识别数据进行精简。
- en: Open Source LLMs
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开源LLM
- en: 'Open source is often used as a catch-all phrase to refer to models with some
    aspect that is publicly available. We will define open source as:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 开源通常被用作一个通用术语，用来指代具有某些公开可访问方面的模型。我们将开源定义为：
- en: Software artifacts that are released under a license that allows users to *study*,
    *use*, *modify*, and *redistribute* them to *anyone* and for any *purpose*.
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在许可下发布的软件工件，允许用户*研究*、*使用*、*修改*并将它们*重新分发*给*任何人*和任何*目的*。
- en: For a more formal and comprehensive definition of open source software, refer
    to the Open Source Initiative’s [official definition](https://oreil.ly/7cezH).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于开源软件的更正式和全面的定义，请参阅开源倡议的[官方定义](https://oreil.ly/7cezH)。
- en: 'For an LLM to be considered fully open, all of the following needs to be published:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要使LLM被认为是完全开放的，以下所有内容都需要公开发布：
- en: Model weights
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 模型权重
- en: This includes all the parameters of the model and the model configuration. Having
    access to this enables us to add to or modify the model parameters in any way
    we deem fit. Model checkpoints at various stages of training are also encouraged
    to be released.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括模型的全部参数和模型配置。能够访问这些内容使我们能够以任何我们认为合适的方式添加或修改模型参数。鼓励在训练的各个阶段发布模型检查点。
- en: Model code
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 模型代码
- en: Releasing only the weights of the model is akin to providing a software binary
    without providing the source code. Model code not only includes model training
    code and hyperparameter settings but also code used for pre-processing training
    data. Releasing information about infrastructure setup and configuration also
    goes a long way toward enhancing model reproducibility. In most cases, even with
    model code fully available, models may not be easily reproducible due to resource
    limitations and the nondeterministic nature of training.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 仅发布模型的权重类似于提供软件二进制文件而不提供源代码。模型代码不仅包括模型训练代码和超参数设置，还包括用于预处理训练数据的代码。发布有关基础设施设置和配置的信息也有助于提高模型的可重复性。在大多数情况下，即使模型代码完全可用，由于资源限制和训练的非确定性，模型可能仍然难以重复。
- en: Training data
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据
- en: This includes the training data used for the model, and ideally information
    or code on how it was sourced. It is also encouraged to release data at different
    stages of transformation of the data preprocessing pipeline, as well as the order
    in which the data was fed to the model. Training data is the component that is
    least published by model providers. Thus, most open source models are not *fully
    open* because the dataset is not public.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括用于模型的训练数据，以及理想情况下有关其来源的信息或代码。还鼓励在数据预处理管道的不同阶段发布数据，以及数据被输入到模型中的顺序。训练数据是模型提供者最少发布的组件。因此，大多数开源模型不是“完全开放”的，因为数据集不是公开的。
- en: Training data is often not released due to competitive reasons. As discussed
    in Chapters [3](ch03.html#chapter-LLM-tokenization) and [4](ch04.html#chapter_transformer-architecture),
    most LLMs today use variants of the same architecture and training code. The distinguishing
    factor can often be the data content and preprocessing. Parts of the training
    data might be acquired using a licensing agreement, which prohibits the model
    provider from releasing the data publicly.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 由于竞争原因，训练数据通常不会公开。正如第[3](ch03.html#chapter-LLM-tokenization)章和第[4](ch04.html#chapter_transformer-architecture)章所讨论的，今天的大多数大型语言模型（LLM）都使用相同的架构和训练代码的变体。区分因素通常可以归结为数据内容和预处理。部分训练数据可能通过许可协议获得，这禁止模型提供者公开发布数据。
- en: Another reason for not releasing training data is that there are unresolved
    legal issues pertaining to training data, especially surrounding copyright. As
    an example, The Pile dataset created by Eleuther AI is no longer available at
    the official link because it contains text from copyrighted books (the Books3
    dataset). Note that The Pile is pre-processed so the books are not in human-readable
    form and are not easily reproducible, as they are split, shuffled, and mixed.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 不公开训练数据的另一个原因是与训练数据相关的未解决的法律问题，尤其是围绕版权的问题。例如，由Eleuther AI创建的Pile数据集在官方链接上已不再可用，因为它包含了受版权保护书籍（Books3数据集）中的文本。请注意，Pile数据集已经过预处理，书籍不是以人类可读的形式存在，并且不容易复制，因为它们被分割、打乱和混合。
- en: Most training data is sourced from the open web and thus may potentially contain
    violent or sexual content that is illegal in certain jurisdictions. Despite the
    best intentions and rigorous filtering, some of these data might still be present
    in the final dataset. Thus many datasets that have been previously open are no
    longer open, LAION’s image datasets being one example.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数训练数据来自公开网络，因此可能包含在某些司法管辖区非法的暴力或色情内容。尽管有最好的意图和严格的过滤，这些数据中的一些可能仍然存在于最终数据集中。因此，许多之前公开的数据集现在不再公开，LAION的图像数据集就是一个例子。
- en: 'Ultimately, the license under which the model has been released determines
    the terms under which you can use, modify, or redistribute the original or modified
    LLM. Broadly speaking, open LLMs are distributed under three types of licenses:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，模型发布的许可证决定了您可以使用、修改或重新分发原始或修改后的LLM的条款。广义而言，开放LLM的分布通常有三种类型的许可证：
- en: Noncommercial
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 非商业
- en: These licenses only allow research and personal use and prohibit the use of
    the model for commercial purposes. In many cases, the model artifacts are gated
    through an application form where a user would have to justify their need for
    access by providing a compelling research use case.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这些许可证仅允许研究和个人使用，并禁止将模型用于商业目的。在许多情况下，模型工件通过申请表进行控制，用户必须通过提供令人信服的研究用例来证明他们访问的需求。
- en: Copy-left
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Copy-left
- en: This type of license permits commercial usage, but all source or derivative
    work needs to be released under the same license, thus making it harder to develop
    proprietary modifications. The degree to which this condition applies depends
    on the specific license being used.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 此类许可证允许商业使用，但所有源或衍生作品都需要在相同的许可证下发布，这使得开发专有修改更加困难。此条件适用的程度取决于所使用的具体许可证。
- en: Permissive
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 宽松
- en: This type of license permits commercial usage, including modifying and redistributing
    it in proprietary applications, i.e., there is no obligation for the redistribution
    to be open source. Some licenses in this category also permit patents.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 此类许可证允许商业使用，包括在专有应用程序中修改和重新分发，即没有义务使再分发成为开源。此类许可证中的一些也允许专利。
- en: New types of licenses are being devised that restrict usage of the model for
    particular use cases, often for safety reasons. An example of this is the [Open
    RAIL-M license](https://oreil.ly/2UVMe), which prohibits usage of the model in
    use cases like providing medical advice, law enforcement, immigration and asylum
    processes, etc. For a full list of restricted use cases, see Attachment A of the
    license.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 正在制定新的许可证类型，这些许可证限制模型用于特定用例，通常出于安全原因。一个例子是[Open RAIL-M许可证](https://oreil.ly/2UVMe)，它禁止在提供医疗建议、执法、移民和庇护程序等用例中使用该模型。有关受限用例的完整列表，请参阅许可证附件A。
- en: As a practitioner intending to use open LLMs in your organization for commercial
    reasons, it is best to use ones with permissive licenses. Popular examples of
    permissive licenses include the Apache 2.0 and the MIT license.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 作为打算为商业原因在您的组织中使用开放LLM的从业者，最好使用具有宽松许可证的LLM。宽松许可证的流行例子包括Apache 2.0和MIT许可证。
- en: '[Creative Commons (CC) licenses](https://oreil.ly/PQy6D) are a popular class
    of licenses used to distribute open LLMs.The licenses have names like CC-BY-NC-SA,
    etc. Here is an easy way to remember what these names mean:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[创意共享（CC）许可证](https://oreil.ly/PQy6D)是用于分发开放LLM的流行许可证类别。许可证的名称如CC-BY-NC-SA等。以下是一个记住这些名称含义的简单方法：'
- en: BY
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: BY
- en: If the license contains this term, it means attribution is needed. If it contains
    only CC-BY, it means the license is permissive.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果许可证包含此条款，则表示需要署名。如果只包含CC-BY，则表示许可证是宽松的。
- en: SA
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: SA
- en: If the license contains this term, it means redistribution should occur under
    the same terms as this license. In other words, it is a copy-left license.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果许可证包含此条款，则表示应在此许可证的相同条款下进行再分发。换句话说，它是一个左派复制许可证。
- en: NC
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: NC
- en: NC stands for noncommercial. Thus, if the license contains this term, the model
    can only be used for research or personal use cases.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: NC代表非商业。因此，如果许可证包含此条款，则模型只能用于研究或个人用例。
- en: ND
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ND
- en: ND stands for no derivatives. If the license contains this term, then distribution
    of modifications to the model is not allowed.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ND代表无衍生。如果许可证包含此条款，则不允许分发模型的修改版本。
- en: Note
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Today, models that have open weights and open code and are released under a
    license that allows redistribution to anyone and for any use case are considered
    open source models. Arguably, however, access to the training data is also crucial
    to inspect and study the model, which is part of the open source definition we
    introduced earlier.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，具有开放权重和开放代码，并且根据允许任何人用于任何用例的许可证发布的模型被认为是开源模型。然而，可以争论的是，访问训练数据对于检查和研究模型也至关重要，这是我们之前介绍的开源定义的一部分。
- en: '[Table 5-2](#llm-taxonomy) shows the various LLMs available, the licenses under
    which they are published, and their available sizes and flavors. Note that the
    LLM may be instruction-tuned or chat-tuned by a different entity than the one
    that pre-trained the LLM.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[表5-2](#llm-taxonomy) 展示了可用的各种LLM、它们发布的许可证以及它们可用的尺寸和版本。请注意，LLM可能由预训练LLM的不同实体进行指令调整或聊天调整。'
- en: Table 5-2\. List of available LLMs
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 表5-2\. 可用LLM列表
- en: '| Name | Availability | Sizes | Variants |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 可用性 | 尺寸 | 变体 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| GPT-4 | Proprietary | Unknown | GPT-4 32K context, GPT-4 8K context |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 专有 | 未知 | GPT-4 32K上下文，GPT-4 8K上下文 |'
- en: '| GPT-3.5 Turbo | Proprietary | Unknown | GPT-3.5 4K context, GPT-3.5 16K context
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 Turbo | 专有 | 未知 | GPT-3.5 4K上下文，GPT-3.5 16K上下文 |'
- en: '| Claude Instant | Proprietary | Unknown | - |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 克劳德即时 | 专有 | 未知 | - |'
- en: '| Claude 2 | Proprietary | Unknown | - |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 克劳德2 | 专有 | 未知 | - |'
- en: '| MPT | Apache 2.0 | 1B, 7B, 30B | MPT 65K storywriter |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| MPT | Apache 2.0 | 1B, 7B, 30B | MPT 65K故事作家 |'
- en: '| CerebrasGPT | Apache 2.0 | 111M, 256M, 590M, 1.3B, 2.7B, 6.7B, 13B | CerebrasGPT
    |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| CerebrasGPT | Apache 2.0 | 111M, 256M, 590M, 1.3B, 2.7B, 6.7B, 13B | CerebrasGPT
    |'
- en: '| Stability LM | CC-BY-SA | 7B | - |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| Stability LM | CC-BY-SA | 7B | - |'
- en: '| RedPajama | Apache 2.0 | 3B, 7B | RedPajama-INCITE-Instruct, RedPajama-INCITE-Chat
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| RedPajama | Apache 2.0 | 3B, 7B | RedPajama-INCITE-Instruct, RedPajama-INCITE-Chat
    |'
- en: '| GPT-Neo X | Apache 2.0 | 20B | - |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| GPT-Neo X | Apache 2.0 | 20B | - |'
- en: '| BLOOM | Open, restricted use | 176B | BLOOMZ |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| BLOOM | 开源，限制使用 | 176B | BLOOMZ |'
- en: '| Llama | Open, no commercial use | 7B, 13B, 33B, 65B | - |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| Llama | 开源，无商业用途 | 7B, 13B, 33B, 65B | - |'
- en: '| Llama 2 | Open, commercial use | 7B, 13B, 70B | Llama 2-Chat |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| Llama 2 | 开源，商业用途 | 7B, 13B, 70B | Llama 2-Chat |'
- en: '| Zephyr | Apache 2.0 | 7B | - |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| Zephyr | Apache 2.0 | 7B | - |'
- en: '| Gemma | Open, restricted use | 2B, 7B | Gemma-Instruction Tuned |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| Gemma | 开源，限制使用 | 2B, 7B | Gemma-Instruction Tuned |'
- en: How to Choose an LLM for Your Task
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何为您的任务选择LLM
- en: 'Given the plethora of options available, how do you ensure you choose the right
    LLM for your task? Depending on your situation, there are a multitude of criteria
    to consider, including:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在众多选项中，您如何确保选择适合您任务的正确LLM？根据您的具体情况，有许多标准需要考虑，包括：
- en: Cost
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 成本
- en: This includes inference or fine-tuning costs, and costs associated with building
    software scaffolding, monitoring and observability, deployment and maintenance
    (collectively referred to as LLMOps).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括推理或微调成本，以及构建软件框架、监控和可观察性、部署和维护（统称为LLMOps）的成本。
- en: '[Time per output token (TPOT)](https://oreil.ly/mEDRt)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[每输出令牌时间（TPOT）](https://oreil.ly/mEDRt)'
- en: This is a metric used to measure the speed of text generation as experienced
    by the end user.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个衡量最终用户体验到的文本生成速度的指标。
- en: Task performance
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 任务性能
- en: This refers to the performance requirements of the task and the relevant metrics
    like precision or accuracy. What level of performance is *good enough*?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这指的是任务的性能要求和相关的指标，如精确度或准确性。什么程度的性能是“足够好”的？
- en: Type of tasks
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 任务类型
- en: The nature of the tasks the LLM will be used for, like summarization, question
    answering, classification, etc.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: LLM将要执行的任务的性质，如摘要、问答、分类等。
- en: Capabilities required
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 需要的能力
- en: Examples of capabilities include arithmetic reasoning, logical reasoning, planning,
    task decomposition, etc. A lot of these capabilities, to the extent that they
    actually exist or approximate, are *emergent properties* of an LLM as discussed
    in [Chapter 1](ch01.html#chapter_llm-introduction), and are not exhibited by smaller
    models.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 能力的例子包括算术推理、逻辑推理、规划、任务分解等。许多这些能力，在它们实际存在或近似存在的程度，是LLM的**涌现属性**，如[第1章](ch01.html#chapter_llm-introduction)中讨论的，并且不是由较小模型展示的。
- en: Licensing
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 许可证
- en: You can use only those models that allow your mode of usage. Even models that
    explicitly allow commercial use can have restrictions on certain types of use
    cases. For example, as noted earlier, the Big Science OpenRAIL-M license restricts
    the usage of the LLM in use cases pertaining to law enforcement, immigration,
    or asylum processes.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您只能使用允许您使用方式的模型。即使某些模型明确允许商业使用，也可能对某些类型的用例有所限制。例如，如前所述，Big Science OpenRAIL-M许可证限制了LLM在涉及执法、移民或庇护程序用例中的使用。
- en: In-house ML/MLOps talent
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 内部机器学习/机器学习操作人才
- en: The strength of in-house talent determines the customizations you can afford.
    For example, do you have enough in-house talent for building inference optimization
    systems?
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 内部人才的实力决定了您可以承受的定制化程度。例如，您是否有足够的内部人才来构建推理优化系统？
- en: Other nonfunctional criteria
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 其他非功能性标准
- en: This includes safety, security, privacy, etc. Cloud providers and startups are
    already implementing solutions that can address these issues.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括安全性、安全性、隐私性等。云服务提供商和初创公司已经在实施可以解决这些问题的解决方案。
- en: You may have to choose between proprietary and open source LLMs.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能需要在专有和开源LLM之间做出选择。
- en: Open Source Versus Proprietary LLMs
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开源与专有LLM
- en: Debates about the merits of open source versus proprietary software have been
    commonplace in the tech industry for several decades now, and we are seeing it
    become increasingly relevant in the realm of LLMs as well. The biggest advantage
    of open source models are the transparency and flexibility they provide, not necessarily
    the cost. Self-hosting open source LLMs can incur a lot of engineering overhead
    and compute/memory costs, and using managed services might not always be able
    to match proprietary models in terms of latency, throughput, and inference cost.
    Moreover, many open source LLMs are not easily accessible through managed services
    and other third-party deployment options. This situation is bound to change dramatically
    as the field matures, but in the meanwhile, run through your calculations for
    your specific situation to determine the costs incurred for using each (type of)
    model.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 关于开源软件与专有软件优缺点的辩论在科技行业已经司空见惯了几十年，现在我们也看到它在LLM领域变得越来越相关。开源模型最大的优势是它们提供的透明性和灵活性，而不仅仅是成本。自托管开源LLM可能会产生大量的工程开销和计算/内存成本，而使用托管服务可能并不总是能够在延迟、吞吐量和推理成本方面与专有模型相匹配。此外，许多开源LLM不易通过托管服务和其他第三方部署选项访问。随着该领域的成熟，这种情况肯定会发生戏剧性的变化，但与此同时，请针对你的具体情况运行你的计算，以确定使用每种（类型）模型产生的成本。
- en: The flexibility provided by open source models helps with your ability to debug,
    interpret, and augment the LLM with any kind of training/fine-tuning you choose,
    instead of the restricted avenues made available by the LLM provider. This allows
    you to more substantially align the LLM to your preferences and values instead
    of the ones decided by the LLM provider. Having full availability of all the token
    probabilities (logits) is a superpower, as we will see throughout the book.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 开源模型提供的灵活性有助于你调试、解释和通过任何选择的训练/微调来增强LLM，而不是LLM提供商提供的受限途径。这让你能够更实质性地将LLM与你的偏好和价值观对齐，而不是由LLM提供商决定的那些。在整个书中，我们将看到拥有所有标记概率（logits）的完全可用性是一种超级能力。
- en: The availability of open source LLMs has enabled teams to develop models and
    applications that might not be lucrative for larger companies with a profit motive,
    like fine-tuning models to support low-resource languages (languages that do not
    have a significant data footprint on the internet, like regional languages of
    India or Indigenous languages of Canada). An example is the [Kannada Llama model](https://oreil.ly/hoBQ1),
    built over Llama 2 by continually pre-training and fine-tuning on tokens from
    the Kannada language, a regional language of India.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 开源LLM的可用性使得团队能够开发出对具有盈利动机的大型公司来说可能并不赚钱的模型和应用，例如微调模型以支持低资源语言（在互联网上没有显著数据足迹的语言，如印度的地区语言或加拿大的土著语言）。一个例子是建立在Llama
    2之上的[Kannada Llama模型](https://oreil.ly/hoBQ1)，它通过持续在卡纳达语标记上进行预训练和微调而构建，卡纳达语是印度的一种地区语言。
- en: Not all open source models are fully transparent. As mentioned earlier, most
    for-profit companies that release open source LLMs do not make the training datasets
    public. For instance, Meta hasn’t disclosed all the details of the training datasets
    used to train the Llama 2 model. Knowing which datasets are used to train the
    model can help you assess whether there is test set contamination and understand
    what kind of knowledge you can expect the LLM to possess.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有开源模型都是完全透明的。正如之前提到的，大多数发布开源大型语言模型（LLM）的盈利性公司并不公开其训练数据集。例如，Meta并未披露用于训练Llama
    2模型的全部训练数据集细节。了解用于训练模型的哪些数据集可以帮助你评估是否存在测试集污染，并理解你可以期望LLM拥有什么样的知识。
- en: As of this book’s writing, open source models like Llama 3.2 and DeepSeek v3
    have more or less caught up to state-of-the-art proprietary models from OpenAI
    or Anthropic. However, there is a new gap developing between proprietary and open
    source models in the realm of reasoning models like OpenAI’s o3, that use inference-time
    compute techniques (discussed in [Chapter 8](ch08.html#ch8)). Throughout this
    book, we will showcase scenarios where open source models have an advantage.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 就本书撰写时的情况而言，开源模型如Llama 3.2和DeepSeek v3在某种程度上已经赶上了OpenAI或Anthropic等公司最先进专有模型的水平。然而，在推理模型领域，如OpenAI的o3，这些模型使用推理时间计算技术（在第8章中讨论），专有模型与开源模型之间正在出现一个新的差距。在整个书中，我们将展示开源模型具有优势的场景。
- en: Tip
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Always check if the model provider has an active developer community on GitHub/Discord/Slack,
    and that the development team is actively engaged in those channels, responding
    to user comments and questions. I recommend preferring models with active developer
    communities, provided they satisfy your primary criteria.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 总是检查模型提供者是否在 GitHub/Discord/Slack 上有一个活跃的开发者社区，并且开发团队是否积极参与这些渠道，回应用户评论和问题。如果它们满足你的主要标准，我建议优先考虑具有活跃开发者社区的模型。
- en: LLM Evaluation
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM 评估
- en: 'We will start this section with a caveat: evaluating LLMs is probably the most
    challenging task in the LLM space at present. Current methods of benchmarking
    are broken, easily gamed, and hard to interpret. Nevertheless, benchmarks are
    still a useful starting point on your road to evaluation. We will start by looking
    at current public benchmarks and then discuss how you can build more holistic
    internal benchmarks.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这个部分开始时提出一个警告：评估大型语言模型（LLM）可能是目前 LLM 领域中最具挑战性的任务。当前的基准测试方法存在缺陷，容易被操纵，且难以解释。尽管如此，基准测试仍然是你在评估道路上的一个有用起点。我们将首先查看当前的公开基准测试，然后讨论如何构建更全面的内部基准测试。
- en: To evaluate LLMs on their task performance, there are a lot of benchmark datasets
    that test a wide variety of skills. Not all skills are relevant to your use case,
    so you can choose to focus on specific benchmarks that test the skills you need
    the LLM to perform well on.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 LLM 在任务性能上的表现，有许多基准数据集可以测试广泛的各种技能。并非所有技能都与你的用例相关，因此你可以选择专注于特定的基准测试，这些基准测试可以测试
    LLM 在你需要其表现良好的技能上。
- en: The leaderboard on these benchmark tests changes very often, especially if only
    open source models are being evaluated, but that does not mean you need to change
    the LLMs you use every time there is a new leader on the board. Usually, the differences
    between the top models are quite marginal. The fine-grained choice of LLM usually
    isn’t the most important criteria determining the success of your task, and you
    are better off spending that bandwidth working on cleaning and understanding your
    data, which is still the most important component of the project.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基准测试的排行榜经常变化，尤其是当只评估开源模型时，但这并不意味着每次榜单上出现新的领先者时，你都需要更换你使用的 LLM。通常，顶级模型之间的差异相当微小。LLM
    的精细选择通常不是决定你任务成功与否的最重要标准，你最好将带宽用于清理和理解你的数据，这仍然是项目最重要的组成部分。
- en: Let’s look at a few popular ways in which the field is evaluating LLMs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看该领域评估 LLM 的几种流行方式。
- en: Eleuther AI LM Evaluation Harness
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Eleuther AI LM 评估工具集
- en: Through the [LM Evaluation Harness](https://oreil.ly/SiOXq), Eleuther AI supports
    benchmarking on over 400 different benchmark tasks, evaluating skills as varied
    as open-domain question answering, arithmetic and logical reasoning, linguistic
    tasks, machine translation, toxic language detection, etc. You can use this tool
    to evaluate any model on the [Hugging Face Hub](https://oreil.ly/IHd22), a platform
    containing thousands of pre-trained and fine-tuned models, on the benchmarks of
    your choice.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 [LM 评估工具集](https://oreil.ly/SiOXq)，Eleuther AI 支持在超过 400 个不同的基准测试任务上进行基准测试，评估的技能范围包括开放域问答、算术和逻辑推理、语言任务、机器翻译、有害语言检测等。你可以使用这个工具在
    [Hugging Face Hub](https://oreil.ly/IHd22) 上评估任何模型，这是一个包含数千个预训练和微调模型的平台，并在你选择的基准测试上进行评估。
- en: 'Here is an example from `bigbench_formal_fallacies_syllogisms_negation`, one
    of the benchmark tasks:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个来自 `bigbench_formal_fallacies_syllogisms_negation` 基准测试任务的示例：
- en: '[PRE0]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this task, the model is asked to spot logical fallacies by deducing whether
    the presented argument is valid given the premises.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个任务中，模型被要求通过演绎所提出的论点是有效的，来识别逻辑谬误。
- en: 'There is also support for evaluation of proprietary models using this harness.
    For example, here is how you would evaluate OpenAI models:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此工具集还支持使用该工具评估专有模型。例如，以下是评估 OpenAI 模型的步骤：
- en: '[PRE1]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Tip
  id: totrans-163
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: While choosing or developing a benchmarking task to evaluate, I recommend focusing
    on picking ones that test the capabilities needed to solve the task of your interest,
    rather than the actual task itself. For example, if you are building a summarizer
    application that needs to perform a lot of logical reasoning to generate the summaries,
    it is better to focus on benchmark tests that directly test logical reasoning
    capabilities than ones that test summarization performance.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择或开发基准任务以评估时，我建议关注挑选那些测试解决你感兴趣的任务所需能力的任务，而不是实际的任务本身。例如，如果你正在构建一个需要大量逻辑推理来生成摘要的摘要应用程序，那么专注于直接测试逻辑推理能力的基准测试比测试摘要性能的基准测试更好。
- en: Hugging Face Open LLM Leaderboard
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Hugging Face Open LLM 领跑者板
- en: 'As of the book’s writing, the [Open LLM Leaderboard](https://oreil.ly/tspBY)
    uses Eleuther AI’s LM Evaluation Harness to evaluate the performance of models
    on six benchmark tasks:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 截至本书撰写时，[Open LLM Leaderboard](https://oreil.ly/tspBY) 使用 Eleuther AI 的 LM Evaluation
    Harness 来评估模型在六个基准任务上的性能：
- en: Massive Multitask Language Understanding (MMLU)
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 大规模多任务语言理解（MMLU）
- en: This test evaluates the LLM on knowledge-intensive tasks, drawing from fields
    like US history, biology, mathematics, and more than 50 other subjects in a multiple
    choice framework.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 此测试在知识密集型任务上评估 LLM，从美国历史、生物学、数学以及超过 50 个其他学科中抽取，采用多项选择框架。
- en: AI2 Reasoning Challenge (ARC)
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: AI2 推理挑战（ARC）
- en: This test evaluates the LLM on multiple-choice grade school science questions
    that need complex reasoning as well as world knowledge to answer.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 此测试评估 LLM 在需要复杂推理和世界知识的中学科学多项选择题上的表现。
- en: Hellaswag
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Hellaswag
- en: This test evaluates commonsense reasoning by providing the LLM with a situation
    and asking it to predict what might happen next out of the given choices, based
    on common sense.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 此测试通过向 LLM 提供一个情境并要求它根据常识从给定选项中预测可能发生的事情来评估常识推理。
- en: TruthfulQA
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: TruthfulQA
- en: This test evaluates the LLM’s ability to provide answers that don’t contain
    falsehoods.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 此测试评估了 LLM 提供不包含虚假信息的答案的能力。
- en: Winogrande
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Winogrande
- en: This test is composed of fill-in-the-blank questions that test commonsense reasoning.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 此测试由测试常识推理的填空题组成。
- en: GSM8K
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: GSM8K
- en: This test evaluates the LLM’s ability to complete grade school math problems
    involving a sequence of basic arithmetic operations.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 此测试评估了 LLM 完成涉及一系列基本算术运算的中学数学问题的能力。
- en: '[Figure 5-3](#llm-leaderboard) shows a snapshot of the LLM leaderboard as of
    the time of the book’s writing. We can see that:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-3](#llm-leaderboard) 展示了截至本书撰写时的 LLM 领跑者板快照。我们可以看到：'
- en: Larger models perform better.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更大的模型表现更好。
- en: Instruction-tuned or fine-tuned variants of models perform better.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指令调整或微调的模型表现更好。
- en: '![Snapshot of the Open LLM Leaderboard](assets/dllm_0503.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![Open LLM 领跑者板快照](assets/dllm_0503.png)'
- en: Figure 5-3\. Snapshot of the Open LLM Leaderboard
  id: totrans-183
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-3\. Open LLM 领跑者板的快照
- en: The validity of these benchmarks are in question as complete test set decontamination
    is not guaranteed. Model providers are also optimizing to solve these benchmarks,
    thus reducing the value of these benchmarks to serve as reliable estimators of
    general-purpose performance.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基准的有效性受到质疑，因为不能保证完整的测试集去污染。模型提供者也在优化以解决这些基准，从而降低了这些基准作为通用性能可靠估计器的价值。
- en: HELM
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: HELM
- en: '[Holistic Evaluation of Language Models (HELM)](https://oreil.ly/MNHDs) is
    an evaluation framework by Stanford that aims to calculate a wide variety of metrics
    over a range of benchmark tasks. Fifty-nine metrics are calculated overall, testing
    accuracy, calibration, robustness, fairness, bias, toxicity, efficiency, summarization
    performance, copyright infringement, and more. The tasks tested include question
    answering, summarization, text classification, information retrieval, sentiment
    analysis, and toxicity detection.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[语言模型全面评估（HELM）](https://oreil.ly/MNHDs) 是斯坦福大学的一个评估框架，旨在在一系列基准任务上计算广泛的指标。总共计算了五十九个指标，测试了准确性、校准、鲁棒性、公平性、偏见、毒性、效率、摘要性能、版权侵权等。测试的任务包括问答、摘要、文本分类、信息检索、情感分析和毒性检测。'
- en: '[Figure 5-4](#helm-leaderboard) shows a snapshot of the HELM leaderboard as
    of the time of the book’s writing.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-4](#helm-leaderboard) 展示了截至本书撰写时的 HELM 领跑者板快照。'
- en: '![Snapshot of the HELM leaderboard](assets/dllm_0504.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![HELMA 领跑者板快照](assets/dllm_0504.png)'
- en: Figure 5-4\. Snapshot of the HELM leaderboard
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-4\. HELM 领跑者板快照
- en: Elo Rating
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Elo 评分
- en: Now that we have seen the limitations of quantitative evaluation, let’s explore
    how we can most effectively incorporate human evaluations. One promising framework
    is the [Elo rating system](https://oreil.ly/bTD7I), used in chess to rank players.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经看到了定量评估的局限性，让我们来探讨如何最有效地融入人工评估。一个有希望的框架是用于棋类比赛的[Elo评分系统](https://oreil.ly/bTD7I)。
- en: '[Large model systems organization (LMSYS Org)](https://oreil.ly/HGVz2) has
    implemented an evaluation platform based on the Elo rating system called the [Chatbot
    Arena](https://oreil.ly/evgQX). Chatbot Arena solicits crowdsourced evaluations
    by inviting people to choose between two randomized and anonymized LLMs by chatting
    with them side-by-side. The leaderboard is found [online](https://oreil.ly/Y6zmN),
    with models from OpenAi, DeepSeek, Google DeepMind, and Anthropic dominating.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[大型模型系统组织（LMSYS Org）](https://oreil.ly/HGVz2)已经实施了一个基于Elo评分系统的评估平台，称为[Chatbot
    Arena](https://oreil.ly/evgQX)。Chatbot Arena通过邀请人们通过与他们并肩聊天来选择两个随机化和匿名化的LLM，从而征集众包评估。排行榜可在[网上](https://oreil.ly/Y6zmN)找到，OpenAi、DeepSeek、Google
    DeepMind和Anthropic的模型占据主导地位。'
- en: '[Figure 5-5](#chatbotarena-leaderboard) shows a snapshot of the Chatbot Arena
    leaderboard as of the time of the book’s writing.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-5](#chatbotarena-leaderboard)展示了在本书撰写时Chatbot Arena排行榜的快照。'
- en: '![Snapshot of the Chatbot Arena leaderboard](assets/dllm_0505.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![Chatbot Arena排行榜快照](assets/dllm_0505.png)'
- en: Figure 5-5\. Snapshot of the Chatbot Arena leaderboard
  id: totrans-195
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-5. Chatbot Arena排行榜快照
- en: Interpreting benchmark results
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解释基准结果
- en: 'How do you interpret evaluation results presented in research papers? Try to
    methodically ask as many questions as possible, and check if the answers are covered
    in the paper or other material. As an example, let us take the Llama 2-chat evaluation
    graphs presented in the [Llama 2 paper](https://oreil.ly/BcgXs). In particular,
    study Figures 1 and 3, which demonstrate how Llama 2-Chat compares in helpfulness
    and safety with other chat models. Some of the questions that come to mind are:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何解释研究论文中呈现的评估结果？尽量系统地提出尽可能多的问题，并检查答案是否在论文或其他材料中有覆盖。例如，让我们以[Llama 2论文](https://oreil.ly/BcgXs)中展示的Llama
    2-Chat评估图为例。特别是研究图1和图3，它们展示了Llama 2-Chat与其他聊天模型在有用性和安全性方面的比较。一些可能想到的问题是：
- en: What does the evaluation dataset look like? Do we have access to it?
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估数据集看起来是什么样子？我们是否有权访问它？
- en: What is the difficulty level of the test set? Maybe the model is competitive
    with respect to ChatGPT for easier examples but how does it perform with more
    difficult examples?
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集的难度级别是多少？也许模型在较简单的例子上与ChatGPT具有竞争力，但它在更困难的例子上的表现如何？
- en: What proportion of examples in the test set can be considered difficult?
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集中有多少比例的例子可以被认为是困难的？
- en: What kinds of scenarios are covered in the test set? What degree of overlap
    do these scenarios have with the chat-tuning sets?
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集中涵盖了哪些类型的场景？这些场景与聊天微调集的重叠程度如何？
- en: What definition do they use for safety?
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们使用的是哪种安全定义？
- en: Can there be a bias in the evaluation due to models being evaluated on the basis
    of a particular definition of safety, which Llama 2 was trained to adhere to,
    while other models may have different definitions of safety?
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于评估是基于特定安全定义的，而Llama 2被训练遵守这一定义，而其他模型可能有不同的安全定义，评估中是否存在偏见？
- en: Rigorously interrogating the results this way helps you develop a deeper understanding
    of what is being evaluated, and whether it aligns with the capabilities you need
    from the language model for your own tasks. For more rigorous LLM evaluation,
    I strongly recommend developing your own internal benchmarks.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式严格审查结果有助于你更深入地理解正在评估的内容，以及它是否与你从语言模型中需要的自身任务能力相一致。为了进行更严格的LLM评估，我强烈建议开发你自己的内部基准。
- en: Warning
  id: totrans-205
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Do not trust evaluations performed by GPT-4 or any other LLM. We have no idea
    what evaluation criteria it uses nor do we have a deeper understanding of its
    biases.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 不要相信GPT-4或其他任何LLM进行的评估。我们不知道它使用的是什么评估标准，也没有对其偏见有更深入的了解。
- en: Robust evaluation of LLMs is further complicated by the sensitivity of the prompts
    and the probabilistic nature of generative models. For example, I often see papers
    claiming that “GPT-4 does not have reasoning capabilities,” while not using any
    prompting techniques during evaluation. In many of these cases, it turns out that
    the model can in fact perform the task if prompted with CoT prompting. While evaluation
    prompts need not be heavily engineered, using rudimentary techniques like CoT
    should be standard practice, and not using them means that the model capabilities
    are being underestimated.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 对LLM（大型语言模型）的鲁棒评估因提示的敏感性和生成模型的概率性质而进一步复杂化。例如，我经常看到一些论文声称“GPT-4没有推理能力”，但在评估过程中并没有使用任何提示技术。在这些案例中，实际上如果使用CoT提示，模型确实可以完成这项任务。虽然评估提示不需要过度设计，但使用像CoT这样的基本技术应该是标准做法，而不使用它们意味着模型的能力被低估了。
- en: Loading LLMs
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载LLM
- en: While it is possible to load and run inference on LLMs with just CPUs, you need
    GPUs if you want acceptable text generation speeds. Choosing a GPU depends on
    cost, the size of the model, whether you are training the model or just running
    inference, and support for optimizations. Tim Dettmers has developed a great [flowchart](https://oreil.ly/t6iPQ)
    that you can use to figure out which GPU best serves your needs.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然使用CPU加载和运行LLM的推理是可能的，但如果你想要可接受的文本生成速度，你需要GPU。选择GPU取决于成本、模型的大小、你是否在训练模型或只是运行推理，以及是否支持优化。Tim
    Dettmers开发了一个很好的[流程图](https://oreil.ly/t6iPQ)，你可以用它来确定哪种GPU最适合你的需求。
- en: 'Let’s figure out the amount of GPU RAM needed to load an LLM of a given size.
    LLMs can be loaded in various *precisions*:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算加载给定大小LLM所需的GPU RAM量。LLM可以以各种*精度*加载：
- en: Float32
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Float32
- en: 32-bit floating point representation, each parameter occupying 4 bytes of storage.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 32位浮点数表示，每个参数占用4字节的存储空间。
- en: Float16
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: Float16
- en: 16-bit floating point representation. Only 5 bits are reserved for the exponent
    as opposed to 8 bits in Float32\. This means that using Float16 comes with overflow/underflow
    problems for very large and small numbers.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 16位浮点数表示。与Float32中的8位相比，只有5位被保留用于指数。这意味着使用Float16会带来非常大和非常小的数字的溢出/下溢问题。
- en: bfloat16 (BF16)
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: bfloat16 (BF16)
- en: 16-bit floating point representation. Just like Float32, 8 bits are reserved
    for the exponent, thus alleviating the underflow/overflow problems observed in
    Float16.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 16位浮点数表示。与Float32一样，8位被保留用于指数，从而缓解了在Float16中观察到的下溢/溢出问题。
- en: Int8
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Int8
- en: 8-bit integer representation. Running inference in 8-bit mode is around 20%
    slower than running in Float16.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 8位整数表示。在8位模式下运行推理比在Float16模式下运行慢约20%。
- en: FP8, FP4
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: FP8, FP4
- en: 8-bit and 4-bit floating point representation.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 8位和4位浮点数表示。
- en: We will explore these formats in detail in [Chapter 9](ch09.html#ch09). Generally,
    running inference on a model with 7B parameters will need around 7 GB of GPU RAM
    if running in 8-bit mode and around 14 GB if running in BF16\. If you intend to
    fine-tune the whole model, you will need a lot more memory.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第9章](ch09.html#ch09)中详细探讨这些格式。一般来说，在8位模式下运行具有70亿参数的模型的推理需要大约7GB的GPU RAM，而在BF16模式下运行则需要大约14GB。如果你打算微调整个模型，你需要更多的内存。
- en: Hugging Face Accelerate
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hugging Face Accelerate
- en: 'You can run inference on models even if they don’t fit in the GPU RAM. The
    [*accelerate* library](https://oreil.ly/OYdyf) by Hugging Face facilitates this
    by loading parts of the model into CPU RAM if the GPU RAM is filled, and then
    loading parts of the model into disk if the CPU RAM is also filled. [“Accelerate
    Big Model Inference: How Does it Work?”](https://oreil.ly/J8duc) shows how the
    accelerate library operates under the hood. This whole process is abstracted from
    the user, so all you need to load a large model is to run this code:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 即使模型不适合GPU RAM，你也可以在模型上运行推理。Hugging Face的[*accelerate*库](https://oreil.ly/OYdyf)通过在GPU
    RAM填满时将模型的部分加载到CPU RAM中，并在CPU RAM也填满时将模型的部分加载到磁盘上来简化这个过程。[“加速大模型推理：它是如何工作的？”](https://oreil.ly/J8duc)展示了accelerate库在底层是如何工作的。整个过程对用户来说是抽象的，所以你只需要运行以下代码就可以加载大型模型：
- en: '[PRE2]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Ollama
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ollama
- en: There are many tools available that facilitate loading LLMs locally, including
    on your own laptop. One such library is Ollama, which supports Windows, Mac, and
    Linux operating systems. Using Ollama, you can load 13B models if your machine
    has at least 16GB of available RAM. Ollama supports many open models like Mistral,
    Llama, Gemma, etc. Ollama provides a REST API that you can use to run inference
    and build LLM-driven applications. It also has several Terminal and UI integrations
    that enable you to build user-facing applications with ease.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多工具可供使用，可以方便地在本地加载 LLM，包括在你的笔记本电脑上。其中一个这样的库是 Ollama，它支持 Windows、Mac 和 Linux
    操作系统。使用 Ollama，如果你的机器至少有 16GB 的可用 RAM，则可以加载 13B 模型。Ollama 支持许多开源模型，如 Mistral、Llama、Gemma
    等。Ollama 提供了一个 REST API，你可以使用它来运行推理并构建由 LLM 驱动的应用程序。它还提供了几个终端和 UI 集成，使你能够轻松地构建面向用户的应用程序。
- en: 'Let’s see how we can use Google’s Gemma 2B model using Ollama. First, download
    [the version of Ollama](https://oreil.ly/yly44) to your machine based on your
    operating system. Next, pull the Gemma model to your machine with:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 Ollama 来使用 Google 的 Gemma 2B 模型。首先，根据你的操作系统下载 [Ollama 的版本](https://oreil.ly/yly44)
    到你的机器上。接下来，使用以下命令将 Gemma 模型拉取到你的机器上：
- en: '[PRE3]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can also create a Modelfile that contains configuration information for
    the model. This includes system prompts and prompt templates, decoding parameters
    like temperature, and conversation history. Refer to the [documentation](https://oreil.ly/ba-1u)
    for a full list of available options.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以创建一个包含模型配置信息的 Modelfile。这包括系统提示和提示模板、解码参数如温度和会话历史。请参阅 [文档](https://oreil.ly/ba-1u)
    以获取可用选项的完整列表。
- en: 'An example Modelfile is:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例 Modelfile 是：
- en: '[PRE4]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After creating your Modelfile, you can run the model:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建你的 Modelfile 之后，你可以运行模型：
- en: '[PRE5]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The book’s GitHub repo contains a sample end-to-end application built using
    Ollama and one of its UI integrations. You can also experiment with similar tools
    like [LM Studio](https://oreil.ly/uFsiR) and [GPT4All](https://oreil.ly/XUXhq).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 该书的 GitHub 仓库包含一个使用 Ollama 和其 UI 集成构建的端到端应用程序示例。你还可以尝试类似工具，如 [LM Studio](https://oreil.ly/uFsiR)
    和 [GPT4All](https://oreil.ly/XUXhq)。
- en: Tip
  id: totrans-235
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: You can load custom models using Ollama if they are in the GPT-Generated Unified
    Format (GGUF).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用 Ollama 加载的模型是 GPT-Generated Unified Format (GGUF)，则可以加载自定义模型。
- en: LLM Inference APIs
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM 推理 API
- en: While you can deploy an LLM yourself, modern-day inference consists of so many
    optimizations, many of them proprietary, that it takes a lot of effort to bring
    your inference speeds up to par with commercially available solutions. Several
    inference services like [Together AI](https://oreil.ly/L3zo0) exist that facilitate
    inference of open source or custom models either through serverless endpoints
    or dedicated instances. Another option is Hugging Face’s [TGI (Text Generation
    Inference)](https://oreil.ly/XXFpa), which has been recently [reinstated](https://oreil.ly/BJJlY)
    to a permissive open source license.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可以自己部署 LLM，但现代推理包含了许多优化，其中许多是专有的，因此要将你的推理速度提升到与商业解决方案相媲美的水平需要付出很多努力。存在一些推理服务，如
    [Together AI](https://oreil.ly/L3zo0)，它们通过无服务器端点或专用实例促进开源或自定义模型的推理。另一个选择是 Hugging
    Face 的 [TGI (文本生成推理)](https://oreil.ly/XXFpa)，它最近已被 [重新授权](https://oreil.ly/BJJlY)
    为宽松的开源许可证。
- en: Decoding Strategies
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解码策略
- en: Now that we have learned how to load a model, let’s understand how to effectively
    generate text. To this end, several *decoding* strategies have been devised in
    the past few years. Let’s go through them in detail.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何加载模型，让我们了解如何有效地生成文本。为此，在过去的几年中已经设计了几种 *解码* 策略。让我们详细地了解一下。
- en: Greedy Decoding
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 贪婪解码
- en: 'The simplest form of decoding is to just generate the token that has the highest
    probability. The drawback of this approach is that it causes repetitiveness in
    the output. Here is an example:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 解码的最简单形式就是生成具有最高概率的标记。这种方法的缺点是会导致输出重复。以下是一个示例：
- en: '[PRE6]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You can see that the output starts getting repetitive. Therefore, greedy decoding
    is not suitable unless you are generating really short sequences, like a token
    just producing a classification task output.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到输出开始变得重复。因此，除非你正在生成非常短的序列，例如仅产生分类任务输出的标记，否则贪婪解码不适用。
- en: '[Figure 5-6](#greedy-decoding) shows an example of greedy decoding using the
    FLAN-T5 model. Note that we missed out on some great sequences because one of
    the desired tokens has slightly lower probability, ensuring it never gets picked.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-6](#greedy-decoding) 展示了使用 FLAN-T5 模型进行贪婪解码的示例。请注意，我们错过了一些很好的序列，因为其中一个期望的标记的概率略低，确保它永远不会被选中。'
- en: '![Greedy decoding](assets/dllm_0506.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![贪婪解码](assets/dllm_0506.png)'
- en: Figure 5-6\. Greedy decoding
  id: totrans-247
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-6\. 贪婪解码
- en: Beam Search
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Beam Search
- en: An alternative to greedy decoding is beam search. An important parameter of
    beam search is the beam size, *n*. At the first step, the top *n* tokens with
    the highest probabilities are selected as hypotheses. For the next few steps,
    the model generates token continuations for each of the hypotheses. The token
    chosen to be generated is the one whose continuations have the highest cumulative
    probability.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 贪婪解码的另一种选择是束搜索。束搜索的一个重要参数是束大小，*n*。在第一步中，选择概率最高的前*n*个标记作为假设。在接下来的几个步骤中，模型为每个假设生成标记的延续。被选中的生成标记是那些延续具有最高累积概率的标记。
- en: 'In the Hugging Face `transformers` library, the `num_beams` parameter of the
    `model.generate()` function determines the size of the beam. Here is how the decoding
    code would look if we used beam search:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在Hugging Face `transformers`库中，`model.generate()`函数的`num_beams`参数决定了束的大小。以下是我们使用束搜索时的解码代码示例：
- en: '[PRE7]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[Figure 5-7](#beam-search) shows an example of beam search using the FLAN-T5
    model. Note that the repetitiveness problem hasn’t really been solved using beam
    search. Similar to greedy decoding, the generated text also sounds very constricted
    and not humanlike, due to the complete absence of lower probability words.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-7](#beam-search) 展示了使用FLAN-T5模型进行束搜索的示例。请注意，束搜索并没有真正解决重复性问题。与贪婪解码类似，由于完全缺乏低概率词汇，生成的文本听起来非常拘谨，不像是人类语言。'
- en: '![Beam search](assets/dllm_0507.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![束搜索](assets/dllm_0507.png)'
- en: Figure 5-7\. Beam search
  id: totrans-254
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-7\. 束搜索
- en: To resolve these issues, we will need to start introducing some randomness and
    begin sampling from the probability distribution to ensure not just the top two
    or three tokens get generated all the time.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题，我们需要开始引入一些随机性，并从概率分布中进行采样，以确保不仅仅是前两个或三个标记总是被生成。
- en: Top-k Sampling
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Top-k Sampling
- en: 'In top-k sampling, the model samples from a distribution of just the k tokens
    of the output distribution that have the highest probability. The probability
    mass is redistributed over the k tokens, and the model samples from this distribution
    to generate the next token. Hugging Face provides the `top_k` parameter in its
    generate function:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在top-k采样中，模型从输出分布中具有最高概率的k个标记的分布中进行采样。概率质量重新分配到k个标记上，模型从这个分布中进行采样以生成下一个标记。Hugging
    Face在其generate函数中提供了`top_k`参数：
- en: '[PRE8]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[Figure 5-8](#topk-sampling) shows an example of top-k sampling using the FLAN-T5
    model. Note that this is a vast improvement from greedy or beam search. However,
    top-k leads to problematic generations when used in cases where the probability
    is dominated by a few tokens, meaning that tokens with very low probability end
    up being included in the top-k.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-8](#topk-sampling) 展示了使用FLAN-T5模型进行top-k采样的示例。请注意，这比贪婪或束搜索有了很大的改进。然而，当在概率主要由少数标记支配的情况下使用时，top-k会导致生成问题，这意味着具有非常低概率的标记最终会被包含在top-k中。'
- en: '![Top-k sampling](assets/dllm_0508.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![Top-k采样](assets/dllm_0508.png)'
- en: Figure 5-8\. Top-k sampling
  id: totrans-261
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-8\. Top-k采样
- en: Top-p Sampling
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Top-p Sampling
- en: 'Top-p sampling solves the problem with top-k sampling by making the number
    of candidate tokens dynamic. Top-p involves choosing the smallest number of tokens
    whose cumulative distribution exceeds a given probability p. Here is how you can
    implement this using Hugging Face `transformers`:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: Top-p采样通过使候选标记的数量动态化来解决top-k采样的问题。Top-p涉及选择累积分布超过给定概率p的最小标记数量。以下是如何使用Hugging
    Face `transformers`实现此方法的示例：
- en: '[PRE9]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[Figure 5-9](#topp-sampling) shows an example of top-p sampling using the FLAN-T5
    model. Top-p sampling, also called nucleus sampling, is the most popular sampling
    strategy used today.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-9](#topp-sampling) 展示了使用FLAN-T5模型进行top-p采样的示例。Top-p采样，也称为核采样，是目前最流行的采样策略。'
- en: '![Top-p sampling](assets/dllm_0509.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![Top-p采样](assets/dllm_0509.png)'
- en: Figure 5-9\. Top-p sampling
  id: totrans-267
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-9\. Top-p采样
- en: Note
  id: totrans-268
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: So far, the decoding approaches we have seen operate serially; i.e., each token
    is generated one at a time, with a full pass through the model each time. This
    is too inefficient for latency-sensitive applications. In [Chapter 9](ch09.html#ch09),
    we will discuss methods like speculative decoding, which can speed up the decoding
    process.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们看到的解码方法都是串行操作的；即每次生成一个标记，每次都要通过整个模型。这对于对延迟敏感的应用来说太低效了。在[第9章](ch09.html#ch09)中，我们将讨论像推测性解码这样的方法，这些方法可以加快解码过程。
- en: Running Inference on LLMs
  id: totrans-270
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在LLMs上运行推理
- en: Now that we have learned how to access and load LLMs and understood the decoding
    process, let’s begin using them to solve our tasks. We call this *LLM inference*.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学会了如何访问和加载LLM，并理解了解码过程，让我们开始使用它们来解决我们的任务。我们称之为*LLM推理*。
- en: You will have seen that LLM outputs are not consistent and sometimes differ
    wildly across multiple generations for the same prompt. As we learned in the section
    on decoding, unless you are using greedy search or any other deterministic algorithm,
    the LLM is sampling from a token distribution.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，LLM的输出并不一致，有时在相同的提示下多次生成时差异很大。正如我们在解码部分所学到的，除非你使用贪婪搜索或任何其他确定性算法，否则LLM是从标记分布中进行采样的。
- en: Some ways to make the generation more deterministic is to set the temperature
    to zero and keeping the random seed for the sampling constant. Even then, you
    may not be able to guarantee the same (deterministic) outputs every time you send
    the LLM the same input.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 使生成过程更加确定性的方法之一是将温度设置为零并保持采样随机种子恒定。即便如此，你可能也无法保证每次向LLM发送相同的输入时都能得到相同的（确定性）输出。
- en: Sources of nondeterminism range from using multi-threading to floating-point
    rounding errors to use of certain model architectures (for example, it is known
    that the [Sparse MoE architecture](https://oreil.ly/pzchE) produces nondeterministic
    outputs).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 非确定性的来源包括使用多线程、浮点数舍入错误以及某些模型架构的使用（例如，已知[稀疏MoE架构](https://oreil.ly/pzchE)会产生非确定性输出）。
- en: Reducing the temperature to zero or close to zero impacts the LLM’s creativity
    and makes its outputs more predictable, which might not be suitable for many applications.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 将温度降低到零或接近零会影响LLM的创造力，并使其输出更加可预测，这可能不适合许多应用。
- en: In production settings where reliability is important, you should run multiple
    generations for the same input and use a technique like majority voting or heuristics
    to select the right output. This is very important due to the nature of the decoding
    process; sometimes the wrong tokens can be generated, and since every token generated
    is a function of the tokens generated before it, the error can be propagated far
    ahead.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中，当可靠性很重要时，你应该对相同的输入进行多次生成，并使用如多数投票或启发式算法等技术来选择正确的输出。这非常重要，因为解码过程具有这种性质；有时可能会生成错误的标记，并且由于每个生成的标记都是之前生成的标记的函数，错误可能会传播得很远。
- en: '[Self-consistency](https://oreil.ly/wEE8q) is a popular prompting technique
    that uses majority voting in conjunction with CoT prompting. In this technique,
    we add the CoT prompt “Let’s think step by step” to the input and run multiple
    generations (reasoning paths). We then use majority voting to select the correct
    output.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '[自洽性](https://oreil.ly/wEE8q)是一种流行的提示技术，它结合了多数投票和CoT提示。在这种技术中，我们将CoT提示“让我们一步步思考”添加到输入中，并运行多次生成（推理路径）。然后我们使用多数投票来选择正确的输出。'
- en: Structured Outputs
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结构化输出
- en: We might want the output of the LLM to be in some structured format, so that
    it can be consumed by other software systems. But this is easier said than done;
    current LLMs aren’t as controllable as we would like them to be. Some LLMs can
    be excessively chatty. Ask them to give a Yes/No answer and they respond with
    “The answer to this question is ‘Yes’.”
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能希望LLM的输出以某种结构化格式呈现，以便它可以被其他软件系统消费。但这说起来容易做起来难；当前的LLM并不像我们希望的那样可控。一些LLM可能会过于健谈。如果你要求它们给出是/否的回答，它们可能会回答“这个问题的答案是‘是’”。
- en: One way to get structured outputs from the LLM is to define a JSON schema, provide
    the schema to the LLM, and prompt it to generate outputs adhering to the schema.
    For larger models, this works almost all the time, with some schema corruption
    errors that you can catch and handle.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 从LLM获取结构化输出的方法之一是定义一个JSON模式，将模式提供给LLM，并提示它生成符合该模式的输出。对于较大的模型，这几乎总是有效的，可能会有一些模式损坏错误，你可以捕获并处理。
- en: For smaller models, you can use libraries like [Jsonformer](https://oreil.ly/aSc0f).
    Jsonformer delegates the generation of the content tokens to the LLM but fills
    the content in JSON form by itself. Jsonformer is built on top of Hugging Face
    and thus supports any model that is supported by Hugging Face.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较小的模型，你可以使用像[Jsonformer](https://oreil.ly/aSc0f)这样的库。Jsonformer将内容标记的生成委托给LLM，但自己以JSON形式填充内容。Jsonformer建立在Hugging
    Face之上，因此支持Hugging Face支持的任何模型。
- en: More advanced structured outputs can be facilitated by using libraries like
    [LMQL](https://oreil.ly/LlkEj) or [Guidance](https://oreil.ly/cFe5s). These libraries
    provide a programming paradigm for prompting and facilitate controlled generation.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用像[LMQL](https://oreil.ly/LlkEj)或[Guidance](https://oreil.ly/cFe5s)这样的库，可以促进更高级的结构化输出。这些库提供了一种提示编程范式，并促进了受控生成。
- en: 'Features available through these libraries include:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这些库提供的功能包括：
- en: Restricting output to a finite set of tokens
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 将输出限制为有限个标记的集合
- en: This is useful for classification problems, where you have a finite set of output
    labels. For example, you can restrict the output to be positive, negative, or
    neutral for a sentiment analysis task.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于分类问题很有用，其中你有一个有限的输出标签集合。例如，你可以将输出限制为正面、负面或中性，用于情感分析任务。
- en: Controlling output format using regular expressions
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 使用正则表达式控制输出格式
- en: For example, you can use regular expressions to specify a custom date format.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以使用正则表达式来指定自定义日期格式。
- en: Control output format using context-free grammars (CFG)
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上下文无关文法（CFG）控制输出格式
- en: A CFG defines the rules that generated strings need to follow. For more background
    on CFGs, refer to [Aditya’s blog](https://oreil.ly/M00us). Using CFGs, we can
    use LLMs to more effectively solve sequence tagging tasks like NER or part-of-speech
    tagging.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: CFG定义了生成字符串需要遵循的规则。有关CFG的更多背景信息，请参阅[Aditya的博客](https://oreil.ly/M00us)。使用CFG，我们可以更有效地使用LLMs解决序列标记任务，如命名实体识别（NER）或词性标注。
- en: Model Debugging and Interpretability
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型调试和可解释性
- en: Now that we are comfortable with loading LLMs and generating text using them,
    we would like to be able to understand model behavior and explore the examples
    for which the model fails. Interpretability in LLMs is much less developed than
    in other areas of machine learning. However, we can get partial interpretability
    by exploring how the output changes upon minor variances in the input, and by
    analyzing the intermediate outputs as the inputs propagate through the Transformer
    architecture.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经熟悉了加载LLMs并使用它们生成文本，我们希望能够理解模型的行为并探索模型失败的例子。在LLMs中的可解释性比机器学习的其他领域要少得多。然而，我们可以通过探索输入的微小变化对输出产生的影响，以及通过分析输入在Transformer架构中传播时的中间输出，来获得部分可解释性。
- en: Google’s open source tool [LIT-NLP](https://oreil.ly/YFY4q) is a handy tool
    that supports visualizations of model behavior as well as various debugging workflows.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: Google的开源工具[LIT-NLP](https://oreil.ly/YFY4q)是一个方便的工具，它支持模型行为的可视化以及各种调试工作流程。
- en: '[Figure 5-10](#lit-NLP) shows an example of LIT-NLP in action, providing interpretability
    for a T5 model running a summarization task.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-10](#lit-NLP)展示了LIT-NLP的实际应用示例，为运行摘要任务的T5模型提供了可解释性。'
- en: '![lit-NLP](assets/dllm_0510.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![lit-NLP](assets/dllm_0510.png)'
- en: Figure 5-10\. LIT-NLP
  id: totrans-295
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-10. LIT-NLP
- en: 'LIT-NLP features that help you debug your models include:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: LIT-NLP提供的有助于调试模型的功能包括：
- en: Visualization of the attention mechanism
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意力机制可视化
- en: Salience maps, which show parts of the input that are paid most attention to
    by the model
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显著性地图，显示模型最关注的输入部分
- en: Visualization of embeddings
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入可视化
- en: Counterfactual analysis that shows how your model behavior changes after a change
    to the input like adding or removing a token.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反事实分析显示了在输入发生变化（如添加或删除标记）后，你的模型行为如何改变。
- en: For more details on using LIT-NLP for error analysis, refer to [Google’s tutorial](https://oreil.ly/zcsLu)
    on using LIT-NLP with the Gemma LLM where they find errors in few-shot prompts
    by analyzing incorrect examples and observing which parts of the prompt contributed
    most to the output (salience).
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 有关使用LIT-NLP进行错误分析的更多详细信息，请参阅[Google的教程](https://oreil.ly/zcsLu)，其中他们在Gemma LLM中使用LIT-NLP分析错误示例，并观察哪些提示部分对输出（显著性）贡献最大。
- en: Summary
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we journeyed through the LLM landscape and noted the various
    options we have at our disposal. We learned how to determine the criteria most
    relevant to our tasks and choose the right LLM accordingly. We explored various
    LLM benchmarks and showed how to interpret their results. We learned how to load
    LLMs and run inference on them, along with efficient decoding strategies. Finally,
    we showcased interpretability tools like LIT-NLP that can help us understand what
    is going on behind the scenes in the Transformer architecture.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们穿越了LLM（大型语言模型）的景观，并注意到了我们可用的各种选项。我们学习了如何确定与我们任务最相关的标准，并据此选择合适的LLM。我们探讨了各种LLM基准，并展示了如何解读其结果。我们还学习了如何加载LLMs并在其上进行推理，以及高效的解码策略。最后，我们展示了如LIT-NLP之类的可解释性工具，这些工具可以帮助我们理解在Transformer架构背后发生的事情。
- en: In the next chapter, we will learn how to update a model to improve its performance
    on our tasks of interest. We will walk through a full-fledged fine-tuning example
    and explore the hyperparameter tuning decisions involved. We will also learn how
    to construct training datasets for fine-tuning.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何更新模型以改进其在我们感兴趣的任务上的性能。我们将通过一个完整的微调示例进行操作，并探索其中涉及的超参数调整决策。我们还将学习如何构建用于微调的训练数据集。
