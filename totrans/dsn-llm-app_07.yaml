- en: Chapter 5\. Adapting LLMs to Your Use Case
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will continue with our journey through the LLM landscape,
    exploring the various LLMs available for commercial use and providing pointers
    on how to choose the right LLM for your task. We will also examine how to load
    LLMs of various sizes and run inference on them. We will then decipher various
    decoding strategies for text generation. We will also investigate how to interpret
    the outputs and intermediate results from language models, surveying interpretability
    tools like LIT-NLP.
  prefs: []
  type: TYPE_NORMAL
- en: Navigating the LLM Landscape
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Seemingly a new LLM is being released every few days, many claiming to be state
    of the art. Most of these LLMs are not very different from each other, so you
    need not spend too much time tracking new LLM releases. This book’s [GitHub repository](https://oreil.ly/llm-playbooks)
    attempts to keep track of the major releases, but I don’t promise it will be complete.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, it is a good idea to have a broad understanding of the different
    types of LLM providers out there, the kinds of LLMs being made available, and
    the copyright and licensing implications. Therefore, let’s now explore the LLM
    landscape through this lens and understand the choices at our disposal.
  prefs: []
  type: TYPE_NORMAL
- en: Who Are the LLM providers?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'LLM providers can be broadly categorized into the following types:'
  prefs: []
  type: TYPE_NORMAL
- en: Companies providing proprietary LLMs
  prefs: []
  type: TYPE_NORMAL
- en: These include companies like OpenAI [(GPT)](https://oreil.ly/r-lb1), Google
    [(Gemini)](https://oreil.ly/KF9Kh), Anthropic [(Claude)](https://oreil.ly/T5Wvo),
    [Cohere](https://oreil.ly/PiKxN), [AI21](https://oreil.ly/Y8T3q), etc. that train
    proprietary LLMs and make them available as an API endpoint (LLM-as-a-service).
    Many of these companies have also partnered with cloud providers that facilitate
    access to these models as a fully managed service. The relevant offerings from
    the major cloud providers are [Amazon Bedrock](https://oreil.ly/FVqRj) and [SageMaker
    JumpStart by Amazon](https://oreil.ly/e0a59), [Vertex AI by Google](https://oreil.ly/mURoC),
    and [Azure OpenAI by Microsoft](https://oreil.ly/Ag1r5).
  prefs: []
  type: TYPE_NORMAL
- en: Companies providing open source LLMs
  prefs: []
  type: TYPE_NORMAL
- en: These include companies that make the LLM weights public and monetize through
    providing deployment services ([Together AI](https://oreil.ly/urcAf)), companies
    whose primary business would benefit from more LLM adoption ([Cerebras](https://oreil.ly/2cVYY)),
    and research labs that have been releasing LLMs since the early days of Transformers
    (Microsoft, Google, Meta, Salesforce, etc.). Note that companies like Google have
    released both proprietary and open source LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Self-organizing open source collectives and community research organizations
  prefs: []
  type: TYPE_NORMAL
- en: This includes the pioneering community research organization [Eleuther AI](https://oreil.ly/ZSlbG),
    and [Big Science](https://oreil.ly/_NlUD). These organizations rely on grants
    for compute infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Academia and government
  prefs: []
  type: TYPE_NORMAL
- en: Due to the high capital costs, not many LLMs have come out of academia so far.
    Examples of LLMs from government/academia include the Abu Dhabi government-funded
    [Technology Innovation Institute](https://oreil.ly/aMwO2), which released the
    [Falcon model](https://oreil.ly/vdhsL), and Tsinghua University, which released
    the [GLM model](https://oreil.ly/K0_zX).
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 5-1](#llm-provider-categories) shows the players in the LLM space, the
    category of entity they belong to, and the pre-trained models they have published.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-1\. LLM Providers
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Category | Pre-trained models released |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Google | Company | BERT, MobileBERT, T5, FLAN-T5, ByT5, Canine, UL2, Flan-UL2,
    Pegasus PaLM, PaLMV2, ELECTRA, Tapas, Switch |'
  prefs: []
  type: TYPE_TB
- en: '| Microsoft | Company | DeBERTa, DialoGPT, BioGPT, MPNet |'
  prefs: []
  type: TYPE_TB
- en: '| OpenAI | Company | GPT-2, GPT-3, GPT-3.5, GPT-4 |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon | Company | Titan |'
  prefs: []
  type: TYPE_TB
- en: '| Anthropic | Company | Claude, Claude-2 |'
  prefs: []
  type: TYPE_TB
- en: '| Cohere | Company | Cohere Command, Cohere Base |'
  prefs: []
  type: TYPE_TB
- en: '| Meta | Company | RoBERTa, Llama, Llama 2, BART, OPT, Galactica |'
  prefs: []
  type: TYPE_TB
- en: '| Salesforce | Company | CTRL, XGen, EinsteinGPT |'
  prefs: []
  type: TYPE_TB
- en: '| MosaicML | Company (Acquired by Databricks) | MPT |'
  prefs: []
  type: TYPE_TB
- en: '| Cerebras | Company | Cerebras-GPT, BTLM |'
  prefs: []
  type: TYPE_TB
- en: '| Databricks | Company | Dolly-V1, Dolly-V2 |'
  prefs: []
  type: TYPE_TB
- en: '| Stability AI | Company | StableLM |'
  prefs: []
  type: TYPE_TB
- en: '| Together AI | Company | RedPajama |'
  prefs: []
  type: TYPE_TB
- en: '| Ontocord AI | Nonprofit | MDEL |'
  prefs: []
  type: TYPE_TB
- en: '| Eleuther AI | Nonprofit | Pythia, GPT Neo, GPT-NeoX, GPT-J |'
  prefs: []
  type: TYPE_TB
- en: '| Big Science | Nonprofit | BLOOM |'
  prefs: []
  type: TYPE_TB
- en: '| Tsinghua University | Academic | GLM |'
  prefs: []
  type: TYPE_TB
- en: '| Technology Innovation Institute | Academic | Falcon |'
  prefs: []
  type: TYPE_TB
- en: '| UC Berkeley | Academic | OpenLLaMA |'
  prefs: []
  type: TYPE_TB
- en: '| Adept AI | Company | Persimmon |'
  prefs: []
  type: TYPE_TB
- en: '| Mistral AI | Company | Mistral |'
  prefs: []
  type: TYPE_TB
- en: '| AI21 Labs | Company | Jurassic |'
  prefs: []
  type: TYPE_TB
- en: '| X.AI | Company | Grok |'
  prefs: []
  type: TYPE_TB
- en: Model Flavors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each model is usually released with multiple variants. It is customary to release
    different-sized variants of the same model. As an example, Llama 2 comes in 7B,
    13B, and 70B sizes, where these numbers refer to the number of parameters in the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: These days, LLM providers augment their pre-trained models in various ways to
    make them more amenable to user tasks. The augmentation process typically involves
    fine-tuning the model in some way, often incorporating human supervision. Some
    of these fine-tuning exercises can cost millions of dollars in terms of human
    annotations. We will refer to pre-trained models that have not undergone any augmentation
    as base models.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections describe some of the popular augmentation types.
  prefs: []
  type: TYPE_NORMAL
- en: Instruct-models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Instruct-models, or instruction-tuned models, are specialized in following instructions
    written in natural language. While base models possess powerful capabilities,
    they are akin to a rebellious teenager; effectively interacting with them is possible
    only after tediously engineering the right prompts through trial and error, which
    tend to be brittle. This is because the base models are trained on either denoising
    objectives or next-word prediction objectives, which are different from the tasks
    users typically want to solve. By instruction-tuning the base model, the resulting
    model is able to more effectively respond to human instructions and be helpful.
  prefs: []
  type: TYPE_NORMAL
- en: A typical instruction-tuning dataset consists of a diverse set of tasks expressed
    in natural language, along with input-output pairs. In [Chapter 6](ch06.html#llm-fine-tuning),
    we will explore various techniques to construct instruction-tuning datasets and
    demonstrate how to perform instruction-tuning on a model.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example from a popular instruction-tuning dataset called [FLAN](https://oreil.ly/YJ_Xr).
  prefs: []
  type: TYPE_NORMAL
- en: '*Prompt:* “What is the sentiment of the following review? The pizza was ok
    but the service was terrible. I stopped in for a quick lunch and got the slice
    special but it ended up taking an hour after waiting several minutes for someone
    at the front counter and then again for the slices. The place was empty other
    than myself, yet I couldn’t get any help/service. OPTIONS: - negative - positive”'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*FLAN:* “Negative”'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this example, the input consists of an instruction, “What is the sentiment
    of the following review?” expressed in a way that humans would naturally express,
    along with the input and output. The input is the actual review and the output
    is the solution to the task, either generated by a model or annotated by a human.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 5-1](#instruction-tuning1) demonstrates the instruction-tuning process.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Instruction tuning process](assets/dllm_0501.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-1\. Instruction-tuning process
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Instruction-tuning is one of several techniques that come under the umbrella
    of supervised fine-tuning (SFT). In addition to improving the ability of a model
    to respond effectively to user tasks, SFT-based approaches can also be used to
    make it less harmful by training on safety datasets that help align model outputs
    with the values and preferences of the model creators.
  prefs: []
  type: TYPE_NORMAL
- en: More advanced techniques to achieve this alignment include reinforcement learning-based
    methods like reinforcement learning from human feedback (RLHF) and reinforcement
    learning from AI feedback (RLAIF).
  prefs: []
  type: TYPE_NORMAL
- en: In RLHF training, human annotators select or rank candidate outputs based on
    certain criteria, like helpfulness and harmlessness. These annotations are used
    to iteratively train a reward model, which ultimately leads to the LLM being more
    controllable, for example, by refusing to answer inappropriate requests from users.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 5-2](#rlhf-1) shows the RLHF training process.'
  prefs: []
  type: TYPE_NORMAL
- en: '![RLHF](assets/dllm_0502.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-2\. Reinforcement learning from human feedback
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We will cover RLHF and other alignment techniques in detail in [Chapter 8](ch08.html#ch8).
  prefs: []
  type: TYPE_NORMAL
- en: Instead of relying on human feedback for alignment training, one can also leverage
    LLMs to choose between outputs based on their adherence to a set of principles
    (don’t be racist, don’t be rude, etc.). This technique was introduced by Anthropic
    and is called RLAIF. In this technique, humans only provide a desired set of principles
    and values (referred to as [Constitutional AI](https://oreil.ly/d8FeW)), and the
    LLM is tasked with determining whether its outputs adhere to these principles.
  prefs: []
  type: TYPE_NORMAL
- en: Instruction-tuned models often take the suffix *instruct*, like RedPajama-Instruct.
  prefs: []
  type: TYPE_NORMAL
- en: Chat-models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Chat-models are instruction-tuned models that are optimized for multi-turn dialog.
    Examples include ChatGPT, Llama 2-Chat, MPT-Chat, OpenAssistant, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Long-context models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As discussed in [Chapter 1](ch01.html#chapter_llm-introduction), Transformer-based
    LLMs have a limited context length. To recap, context length typically refers
    to the sum of the number of input and output tokens processed by the model per
    invocation. Typical context lengths of modern LLMs range from 8,000 to 128,000
    tokens, with some variants of Gemini supporting over a million tokens. Some models
    are released with a long-context variant; for example GPT 3.5 comes with a default
    4K context size but also has a 16K context size variant. [MPT](https://oreil.ly/wKqdL)
    also has a long-context variant that has been trained on 65k context length but
    can potentially be used for even longer contexts during inference.
  prefs: []
  type: TYPE_NORMAL
- en: Domain-adapted or task-adapted models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLM providers also might perform fine-tuning on specific tasks like summarization
    or financial sentiment analysis. They may also produce distilled versions of the
    model, where a smaller model is fine-tuned on outputs from the larger model for
    a particular task. Examples of task-specific fine-tunes include [FinBERT](https://oreil.ly/uKUAp),
    which is fine-tuned on financial sentiment analysis datasets, and [UniversalNER](https://oreil.ly/8A0pn),
    which is distilled using named-entity-recognition data.
  prefs: []
  type: TYPE_NORMAL
- en: Open Source LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Open source is often used as a catch-all phrase to refer to models with some
    aspect that is publicly available. We will define open source as:'
  prefs: []
  type: TYPE_NORMAL
- en: Software artifacts that are released under a license that allows users to *study*,
    *use*, *modify*, and *redistribute* them to *anyone* and for any *purpose*.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a more formal and comprehensive definition of open source software, refer
    to the Open Source Initiative’s [official definition](https://oreil.ly/7cezH).
  prefs: []
  type: TYPE_NORMAL
- en: 'For an LLM to be considered fully open, all of the following needs to be published:'
  prefs: []
  type: TYPE_NORMAL
- en: Model weights
  prefs: []
  type: TYPE_NORMAL
- en: This includes all the parameters of the model and the model configuration. Having
    access to this enables us to add to or modify the model parameters in any way
    we deem fit. Model checkpoints at various stages of training are also encouraged
    to be released.
  prefs: []
  type: TYPE_NORMAL
- en: Model code
  prefs: []
  type: TYPE_NORMAL
- en: Releasing only the weights of the model is akin to providing a software binary
    without providing the source code. Model code not only includes model training
    code and hyperparameter settings but also code used for pre-processing training
    data. Releasing information about infrastructure setup and configuration also
    goes a long way toward enhancing model reproducibility. In most cases, even with
    model code fully available, models may not be easily reproducible due to resource
    limitations and the nondeterministic nature of training.
  prefs: []
  type: TYPE_NORMAL
- en: Training data
  prefs: []
  type: TYPE_NORMAL
- en: This includes the training data used for the model, and ideally information
    or code on how it was sourced. It is also encouraged to release data at different
    stages of transformation of the data preprocessing pipeline, as well as the order
    in which the data was fed to the model. Training data is the component that is
    least published by model providers. Thus, most open source models are not *fully
    open* because the dataset is not public.
  prefs: []
  type: TYPE_NORMAL
- en: Training data is often not released due to competitive reasons. As discussed
    in Chapters [3](ch03.html#chapter-LLM-tokenization) and [4](ch04.html#chapter_transformer-architecture),
    most LLMs today use variants of the same architecture and training code. The distinguishing
    factor can often be the data content and preprocessing. Parts of the training
    data might be acquired using a licensing agreement, which prohibits the model
    provider from releasing the data publicly.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason for not releasing training data is that there are unresolved
    legal issues pertaining to training data, especially surrounding copyright. As
    an example, The Pile dataset created by Eleuther AI is no longer available at
    the official link because it contains text from copyrighted books (the Books3
    dataset). Note that The Pile is pre-processed so the books are not in human-readable
    form and are not easily reproducible, as they are split, shuffled, and mixed.
  prefs: []
  type: TYPE_NORMAL
- en: Most training data is sourced from the open web and thus may potentially contain
    violent or sexual content that is illegal in certain jurisdictions. Despite the
    best intentions and rigorous filtering, some of these data might still be present
    in the final dataset. Thus many datasets that have been previously open are no
    longer open, LAION’s image datasets being one example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Ultimately, the license under which the model has been released determines
    the terms under which you can use, modify, or redistribute the original or modified
    LLM. Broadly speaking, open LLMs are distributed under three types of licenses:'
  prefs: []
  type: TYPE_NORMAL
- en: Noncommercial
  prefs: []
  type: TYPE_NORMAL
- en: These licenses only allow research and personal use and prohibit the use of
    the model for commercial purposes. In many cases, the model artifacts are gated
    through an application form where a user would have to justify their need for
    access by providing a compelling research use case.
  prefs: []
  type: TYPE_NORMAL
- en: Copy-left
  prefs: []
  type: TYPE_NORMAL
- en: This type of license permits commercial usage, but all source or derivative
    work needs to be released under the same license, thus making it harder to develop
    proprietary modifications. The degree to which this condition applies depends
    on the specific license being used.
  prefs: []
  type: TYPE_NORMAL
- en: Permissive
  prefs: []
  type: TYPE_NORMAL
- en: This type of license permits commercial usage, including modifying and redistributing
    it in proprietary applications, i.e., there is no obligation for the redistribution
    to be open source. Some licenses in this category also permit patents.
  prefs: []
  type: TYPE_NORMAL
- en: New types of licenses are being devised that restrict usage of the model for
    particular use cases, often for safety reasons. An example of this is the [Open
    RAIL-M license](https://oreil.ly/2UVMe), which prohibits usage of the model in
    use cases like providing medical advice, law enforcement, immigration and asylum
    processes, etc. For a full list of restricted use cases, see Attachment A of the
    license.
  prefs: []
  type: TYPE_NORMAL
- en: As a practitioner intending to use open LLMs in your organization for commercial
    reasons, it is best to use ones with permissive licenses. Popular examples of
    permissive licenses include the Apache 2.0 and the MIT license.
  prefs: []
  type: TYPE_NORMAL
- en: '[Creative Commons (CC) licenses](https://oreil.ly/PQy6D) are a popular class
    of licenses used to distribute open LLMs.The licenses have names like CC-BY-NC-SA,
    etc. Here is an easy way to remember what these names mean:'
  prefs: []
  type: TYPE_NORMAL
- en: BY
  prefs: []
  type: TYPE_NORMAL
- en: If the license contains this term, it means attribution is needed. If it contains
    only CC-BY, it means the license is permissive.
  prefs: []
  type: TYPE_NORMAL
- en: SA
  prefs: []
  type: TYPE_NORMAL
- en: If the license contains this term, it means redistribution should occur under
    the same terms as this license. In other words, it is a copy-left license.
  prefs: []
  type: TYPE_NORMAL
- en: NC
  prefs: []
  type: TYPE_NORMAL
- en: NC stands for noncommercial. Thus, if the license contains this term, the model
    can only be used for research or personal use cases.
  prefs: []
  type: TYPE_NORMAL
- en: ND
  prefs: []
  type: TYPE_NORMAL
- en: ND stands for no derivatives. If the license contains this term, then distribution
    of modifications to the model is not allowed.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Today, models that have open weights and open code and are released under a
    license that allows redistribution to anyone and for any use case are considered
    open source models. Arguably, however, access to the training data is also crucial
    to inspect and study the model, which is part of the open source definition we
    introduced earlier.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 5-2](#llm-taxonomy) shows the various LLMs available, the licenses under
    which they are published, and their available sizes and flavors. Note that the
    LLM may be instruction-tuned or chat-tuned by a different entity than the one
    that pre-trained the LLM.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-2\. List of available LLMs
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Availability | Sizes | Variants |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-4 | Proprietary | Unknown | GPT-4 32K context, GPT-4 8K context |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-3.5 Turbo | Proprietary | Unknown | GPT-3.5 4K context, GPT-3.5 16K context
    |'
  prefs: []
  type: TYPE_TB
- en: '| Claude Instant | Proprietary | Unknown | - |'
  prefs: []
  type: TYPE_TB
- en: '| Claude 2 | Proprietary | Unknown | - |'
  prefs: []
  type: TYPE_TB
- en: '| MPT | Apache 2.0 | 1B, 7B, 30B | MPT 65K storywriter |'
  prefs: []
  type: TYPE_TB
- en: '| CerebrasGPT | Apache 2.0 | 111M, 256M, 590M, 1.3B, 2.7B, 6.7B, 13B | CerebrasGPT
    |'
  prefs: []
  type: TYPE_TB
- en: '| Stability LM | CC-BY-SA | 7B | - |'
  prefs: []
  type: TYPE_TB
- en: '| RedPajama | Apache 2.0 | 3B, 7B | RedPajama-INCITE-Instruct, RedPajama-INCITE-Chat
    |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-Neo X | Apache 2.0 | 20B | - |'
  prefs: []
  type: TYPE_TB
- en: '| BLOOM | Open, restricted use | 176B | BLOOMZ |'
  prefs: []
  type: TYPE_TB
- en: '| Llama | Open, no commercial use | 7B, 13B, 33B, 65B | - |'
  prefs: []
  type: TYPE_TB
- en: '| Llama 2 | Open, commercial use | 7B, 13B, 70B | Llama 2-Chat |'
  prefs: []
  type: TYPE_TB
- en: '| Zephyr | Apache 2.0 | 7B | - |'
  prefs: []
  type: TYPE_TB
- en: '| Gemma | Open, restricted use | 2B, 7B | Gemma-Instruction Tuned |'
  prefs: []
  type: TYPE_TB
- en: How to Choose an LLM for Your Task
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Given the plethora of options available, how do you ensure you choose the right
    LLM for your task? Depending on your situation, there are a multitude of criteria
    to consider, including:'
  prefs: []
  type: TYPE_NORMAL
- en: Cost
  prefs: []
  type: TYPE_NORMAL
- en: This includes inference or fine-tuning costs, and costs associated with building
    software scaffolding, monitoring and observability, deployment and maintenance
    (collectively referred to as LLMOps).
  prefs: []
  type: TYPE_NORMAL
- en: '[Time per output token (TPOT)](https://oreil.ly/mEDRt)'
  prefs: []
  type: TYPE_NORMAL
- en: This is a metric used to measure the speed of text generation as experienced
    by the end user.
  prefs: []
  type: TYPE_NORMAL
- en: Task performance
  prefs: []
  type: TYPE_NORMAL
- en: This refers to the performance requirements of the task and the relevant metrics
    like precision or accuracy. What level of performance is *good enough*?
  prefs: []
  type: TYPE_NORMAL
- en: Type of tasks
  prefs: []
  type: TYPE_NORMAL
- en: The nature of the tasks the LLM will be used for, like summarization, question
    answering, classification, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Capabilities required
  prefs: []
  type: TYPE_NORMAL
- en: Examples of capabilities include arithmetic reasoning, logical reasoning, planning,
    task decomposition, etc. A lot of these capabilities, to the extent that they
    actually exist or approximate, are *emergent properties* of an LLM as discussed
    in [Chapter 1](ch01.html#chapter_llm-introduction), and are not exhibited by smaller
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Licensing
  prefs: []
  type: TYPE_NORMAL
- en: You can use only those models that allow your mode of usage. Even models that
    explicitly allow commercial use can have restrictions on certain types of use
    cases. For example, as noted earlier, the Big Science OpenRAIL-M license restricts
    the usage of the LLM in use cases pertaining to law enforcement, immigration,
    or asylum processes.
  prefs: []
  type: TYPE_NORMAL
- en: In-house ML/MLOps talent
  prefs: []
  type: TYPE_NORMAL
- en: The strength of in-house talent determines the customizations you can afford.
    For example, do you have enough in-house talent for building inference optimization
    systems?
  prefs: []
  type: TYPE_NORMAL
- en: Other nonfunctional criteria
  prefs: []
  type: TYPE_NORMAL
- en: This includes safety, security, privacy, etc. Cloud providers and startups are
    already implementing solutions that can address these issues.
  prefs: []
  type: TYPE_NORMAL
- en: You may have to choose between proprietary and open source LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Open Source Versus Proprietary LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Debates about the merits of open source versus proprietary software have been
    commonplace in the tech industry for several decades now, and we are seeing it
    become increasingly relevant in the realm of LLMs as well. The biggest advantage
    of open source models are the transparency and flexibility they provide, not necessarily
    the cost. Self-hosting open source LLMs can incur a lot of engineering overhead
    and compute/memory costs, and using managed services might not always be able
    to match proprietary models in terms of latency, throughput, and inference cost.
    Moreover, many open source LLMs are not easily accessible through managed services
    and other third-party deployment options. This situation is bound to change dramatically
    as the field matures, but in the meanwhile, run through your calculations for
    your specific situation to determine the costs incurred for using each (type of)
    model.
  prefs: []
  type: TYPE_NORMAL
- en: The flexibility provided by open source models helps with your ability to debug,
    interpret, and augment the LLM with any kind of training/fine-tuning you choose,
    instead of the restricted avenues made available by the LLM provider. This allows
    you to more substantially align the LLM to your preferences and values instead
    of the ones decided by the LLM provider. Having full availability of all the token
    probabilities (logits) is a superpower, as we will see throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: The availability of open source LLMs has enabled teams to develop models and
    applications that might not be lucrative for larger companies with a profit motive,
    like fine-tuning models to support low-resource languages (languages that do not
    have a significant data footprint on the internet, like regional languages of
    India or Indigenous languages of Canada). An example is the [Kannada Llama model](https://oreil.ly/hoBQ1),
    built over Llama 2 by continually pre-training and fine-tuning on tokens from
    the Kannada language, a regional language of India.
  prefs: []
  type: TYPE_NORMAL
- en: Not all open source models are fully transparent. As mentioned earlier, most
    for-profit companies that release open source LLMs do not make the training datasets
    public. For instance, Meta hasn’t disclosed all the details of the training datasets
    used to train the Llama 2 model. Knowing which datasets are used to train the
    model can help you assess whether there is test set contamination and understand
    what kind of knowledge you can expect the LLM to possess.
  prefs: []
  type: TYPE_NORMAL
- en: As of this book’s writing, open source models like Llama 3.2 and DeepSeek v3
    have more or less caught up to state-of-the-art proprietary models from OpenAI
    or Anthropic. However, there is a new gap developing between proprietary and open
    source models in the realm of reasoning models like OpenAI’s o3, that use inference-time
    compute techniques (discussed in [Chapter 8](ch08.html#ch8)). Throughout this
    book, we will showcase scenarios where open source models have an advantage.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Always check if the model provider has an active developer community on GitHub/Discord/Slack,
    and that the development team is actively engaged in those channels, responding
    to user comments and questions. I recommend preferring models with active developer
    communities, provided they satisfy your primary criteria.
  prefs: []
  type: TYPE_NORMAL
- en: LLM Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will start this section with a caveat: evaluating LLMs is probably the most
    challenging task in the LLM space at present. Current methods of benchmarking
    are broken, easily gamed, and hard to interpret. Nevertheless, benchmarks are
    still a useful starting point on your road to evaluation. We will start by looking
    at current public benchmarks and then discuss how you can build more holistic
    internal benchmarks.'
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate LLMs on their task performance, there are a lot of benchmark datasets
    that test a wide variety of skills. Not all skills are relevant to your use case,
    so you can choose to focus on specific benchmarks that test the skills you need
    the LLM to perform well on.
  prefs: []
  type: TYPE_NORMAL
- en: The leaderboard on these benchmark tests changes very often, especially if only
    open source models are being evaluated, but that does not mean you need to change
    the LLMs you use every time there is a new leader on the board. Usually, the differences
    between the top models are quite marginal. The fine-grained choice of LLM usually
    isn’t the most important criteria determining the success of your task, and you
    are better off spending that bandwidth working on cleaning and understanding your
    data, which is still the most important component of the project.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at a few popular ways in which the field is evaluating LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Eleuther AI LM Evaluation Harness
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Through the [LM Evaluation Harness](https://oreil.ly/SiOXq), Eleuther AI supports
    benchmarking on over 400 different benchmark tasks, evaluating skills as varied
    as open-domain question answering, arithmetic and logical reasoning, linguistic
    tasks, machine translation, toxic language detection, etc. You can use this tool
    to evaluate any model on the [Hugging Face Hub](https://oreil.ly/IHd22), a platform
    containing thousands of pre-trained and fine-tuned models, on the benchmarks of
    your choice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example from `bigbench_formal_fallacies_syllogisms_negation`, one
    of the benchmark tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]` `premises``,` `deductively` `valid` `or` `invalid``?``",` [PRE1] [PRE2]'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3] [PRE4]`py  [PRE5]py  [PRE6]'
  prefs: []
  type: TYPE_NORMAL
