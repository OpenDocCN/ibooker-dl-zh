- en: Chapter 5\. Adapting LLMs to Your Use Case
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 5 章\. 将 LLM 适配到您的用例
- en: In this chapter, we will continue with our journey through the LLM landscape,
    exploring the various LLMs available for commercial use and providing pointers
    on how to choose the right LLM for your task. We will also examine how to load
    LLMs of various sizes and run inference on them. We will then decipher various
    decoding strategies for text generation. We will also investigate how to interpret
    the outputs and intermediate results from language models, surveying interpretability
    tools like LIT-NLP.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将继续我们的 LLM 格局之旅，探索可用于商业用途的各种 LLM，并提供如何选择适合您任务的正确 LLM 的指南。我们还将检查如何加载各种大小的
    LLM 并在其上进行推理。然后我们将解码各种用于文本生成的解码策略。我们还将研究如何解释语言模型的输出和中间结果，并调查如 LIT-NLP 等可解释性工具。
- en: Navigating the LLM Landscape
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 LLM 格局
- en: Seemingly a new LLM is being released every few days, many claiming to be state
    of the art. Most of these LLMs are not very different from each other, so you
    need not spend too much time tracking new LLM releases. This book’s [GitHub repository](https://oreil.ly/llm-playbooks)
    attempts to keep track of the major releases, but I don’t promise it will be complete.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来每隔几天就会发布一个新的 LLM，许多都声称是业界领先。这些 LLM 之间并没有太大的区别，因此您不需要花费太多时间跟踪新的 LLM 发布。本书的
    [GitHub 仓库](https://oreil.ly/llm-playbooks) 尝试跟踪主要发布，但我不能保证它会完全完整。
- en: Nevertheless, it is a good idea to have a broad understanding of the different
    types of LLM providers out there, the kinds of LLMs being made available, and
    the copyright and licensing implications. Therefore, let’s now explore the LLM
    landscape through this lens and understand the choices at our disposal.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，了解现有的不同类型 LLM 提供商、可用的 LLM 类型以及版权和许可影响是一个好主意。因此，现在让我们通过这个视角来探索 LLM 的格局，并了解我们可用的选择。
- en: Who Are the LLM providers?
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM 提供商是谁？
- en: 'LLM providers can be broadly categorized into the following types:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 提供商可以大致分为以下几类：
- en: Companies providing proprietary LLMs
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 提供专有 LLM 的公司
- en: These include companies like OpenAI [(GPT)](https://oreil.ly/r-lb1), Google
    [(Gemini)](https://oreil.ly/KF9Kh), Anthropic [(Claude)](https://oreil.ly/T5Wvo),
    [Cohere](https://oreil.ly/PiKxN), [AI21](https://oreil.ly/Y8T3q), etc. that train
    proprietary LLMs and make them available as an API endpoint (LLM-as-a-service).
    Many of these companies have also partnered with cloud providers that facilitate
    access to these models as a fully managed service. The relevant offerings from
    the major cloud providers are [Amazon Bedrock](https://oreil.ly/FVqRj) and [SageMaker
    JumpStart by Amazon](https://oreil.ly/e0a59), [Vertex AI by Google](https://oreil.ly/mURoC),
    and [Azure OpenAI by Microsoft](https://oreil.ly/Ag1r5).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括像 OpenAI [(GPT)](https://oreil.ly/r-lb1)、Google [(Gemini)](https://oreil.ly/KF9Kh)、Anthropic
    [(Claude)](https://oreil.ly/T5Wvo)、[Cohere](https://oreil.ly/PiKxN)、[AI21](https://oreil.ly/Y8T3q)
    等公司，它们训练专有 LLM 并将其作为 API 端点（LLM-as-a-service）提供。许多这些公司还与云服务提供商合作，以完全托管服务的形式提供对这些模型的访问。主要云服务提供商的相关产品包括
    [Amazon Bedrock](https://oreil.ly/FVqRj) 和 [SageMaker JumpStart by Amazon](https://oreil.ly/e0a59)、[Vertex
    AI by Google](https://oreil.ly/mURoC) 以及 [Azure OpenAI by Microsoft](https://oreil.ly/Ag1r5)。
- en: Companies providing open source LLMs
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 提供开源 LLM 的公司
- en: These include companies that make the LLM weights public and monetize through
    providing deployment services ([Together AI](https://oreil.ly/urcAf)), companies
    whose primary business would benefit from more LLM adoption ([Cerebras](https://oreil.ly/2cVYY)),
    and research labs that have been releasing LLMs since the early days of Transformers
    (Microsoft, Google, Meta, Salesforce, etc.). Note that companies like Google have
    released both proprietary and open source LLMs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括那些使 LLM 权重公开并通过提供部署服务来盈利的公司 ([Together AI](https://oreil.ly/urcAf))，那些主要业务将从更多
    LLM 采用中受益的公司 ([Cerebras](https://oreil.ly/2cVYY))，以及从 Transformer 早期就开始发布 LLM
    的研究实验室（微软、谷歌、Meta、Salesforce 等）。请注意，像谷歌这样的公司已经发布了专有和开源的 LLM。
- en: Self-organizing open source collectives and community research organizations
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自组织开源集体和社区研究组织
- en: This includes the pioneering community research organization [Eleuther AI](https://oreil.ly/ZSlbG),
    and [Big Science](https://oreil.ly/_NlUD). These organizations rely on grants
    for compute infrastructure.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括开创性的社区研究组织 [Eleuther AI](https://oreil.ly/ZSlbG) 和 [Big Science](https://oreil.ly/_NlUD)。这些组织依赖资助来获取计算基础设施。
- en: Academia and government
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 学术界和政府
- en: Due to the high capital costs, not many LLMs have come out of academia so far.
    Examples of LLMs from government/academia include the Abu Dhabi government-funded
    [Technology Innovation Institute](https://oreil.ly/aMwO2), which released the
    [Falcon model](https://oreil.ly/vdhsL), and Tsinghua University, which released
    the [GLM model](https://oreil.ly/K0_zX).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 5-1](#llm-provider-categories) shows the players in the LLM space, the
    category of entity they belong to, and the pre-trained models they have published.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-1\. LLM Providers
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Category | Pre-trained models released |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
- en: '| Google | Company | BERT, MobileBERT, T5, FLAN-T5, ByT5, Canine, UL2, Flan-UL2,
    Pegasus PaLM, PaLMV2, ELECTRA, Tapas, Switch |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
- en: '| Microsoft | Company | DeBERTa, DialoGPT, BioGPT, MPNet |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
- en: '| OpenAI | Company | GPT-2, GPT-3, GPT-3.5, GPT-4 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
- en: '| Amazon | Company | Titan |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
- en: '| Anthropic | Company | Claude, Claude-2 |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
- en: '| Cohere | Company | Cohere Command, Cohere Base |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '| Meta | Company | RoBERTa, Llama, Llama 2, BART, OPT, Galactica |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: '| Salesforce | Company | CTRL, XGen, EinsteinGPT |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
- en: '| MosaicML | Company (Acquired by Databricks) | MPT |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: '| Cerebras | Company | Cerebras-GPT, BTLM |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: '| Databricks | Company | Dolly-V1, Dolly-V2 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: '| Stability AI | Company | StableLM |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
- en: '| Together AI | Company | RedPajama |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
- en: '| Ontocord AI | Nonprofit | MDEL |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: '| Eleuther AI | Nonprofit | Pythia, GPT Neo, GPT-NeoX, GPT-J |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: '| Big Science | Nonprofit | BLOOM |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
- en: '| Tsinghua University | Academic | GLM |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
- en: '| Technology Innovation Institute | Academic | Falcon |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
- en: '| UC Berkeley | Academic | OpenLLaMA |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
- en: '| Adept AI | Company | Persimmon |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
- en: '| Mistral AI | Company | Mistral |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
- en: '| AI21 Labs | Company | Jurassic |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
- en: '| X.AI | Company | Grok |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: Model Flavors
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Each model is usually released with multiple variants. It is customary to release
    different-sized variants of the same model. As an example, Llama 2 comes in 7B,
    13B, and 70B sizes, where these numbers refer to the number of parameters in the
    model.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: These days, LLM providers augment their pre-trained models in various ways to
    make them more amenable to user tasks. The augmentation process typically involves
    fine-tuning the model in some way, often incorporating human supervision. Some
    of these fine-tuning exercises can cost millions of dollars in terms of human
    annotations. We will refer to pre-trained models that have not undergone any augmentation
    as base models.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: The following sections describe some of the popular augmentation types.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Instruct-models
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Instruct-models, or instruction-tuned models, are specialized in following instructions
    written in natural language. While base models possess powerful capabilities,
    they are akin to a rebellious teenager; effectively interacting with them is possible
    only after tediously engineering the right prompts through trial and error, which
    tend to be brittle. This is because the base models are trained on either denoising
    objectives or next-word prediction objectives, which are different from the tasks
    users typically want to solve. By instruction-tuning the base model, the resulting
    model is able to more effectively respond to human instructions and be helpful.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 指令模型，或称为指令微调模型，擅长遵循自然语言中编写的指令。尽管基础模型拥有强大的能力，但它们就像一个叛逆的青少年；只有通过反复试验和错误地精心设计正确的提示，才能有效地与之互动，这往往很脆弱。这是因为基础模型是在去噪目标或下一词预测目标上训练的，这些目标与用户通常想要解决的问题不同。通过指令微调基础模型，得到的模型能够更有效地响应人类指令并发挥作用。
- en: A typical instruction-tuning dataset consists of a diverse set of tasks expressed
    in natural language, along with input-output pairs. In [Chapter 6](ch06.html#llm-fine-tuning),
    we will explore various techniques to construct instruction-tuning datasets and
    demonstrate how to perform instruction-tuning on a model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的指令微调数据集包括用自然语言表达的各种任务，以及输入-输出对。在[第6章](ch06.html#llm-fine-tuning)中，我们将探讨构建指令微调数据集的各种技术，并演示如何在模型上执行指令微调。
- en: Here is an example from a popular instruction-tuning dataset called [FLAN](https://oreil.ly/YJ_Xr).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个来自流行的指令微调数据集[FLAN](https://oreil.ly/YJ_Xr)的例子。
- en: '*Prompt:* “What is the sentiment of the following review? The pizza was ok
    but the service was terrible. I stopped in for a quick lunch and got the slice
    special but it ended up taking an hour after waiting several minutes for someone
    at the front counter and then again for the slices. The place was empty other
    than myself, yet I couldn’t get any help/service. OPTIONS: - negative - positive”'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* “以下评论的情感是什么？披萨还可以，但服务太糟糕了。我停下来吃了个快速午餐，点了特制披萨，但等了十几分钟后，前面柜台的某人，然后又等披萨，结果花了一个小时。除了我自己，这个地方空无一人，但我得不到任何帮助/服务。选项：-
    负面 - 正面”'
- en: ''
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*FLAN:* “Negative”'
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*FLAN:* “负面”'
- en: In this example, the input consists of an instruction, “What is the sentiment
    of the following review?” expressed in a way that humans would naturally express,
    along with the input and output. The input is the actual review and the output
    is the solution to the task, either generated by a model or annotated by a human.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，输入包括一个指令，“以下评论的情感是什么？”以人类自然表达的方式表达，以及输入和输出。输入是实际的评论，输出是任务的解决方案，可以是模型生成的或由人类标注的。
- en: '[Figure 5-1](#instruction-tuning1) demonstrates the instruction-tuning process.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-1](#instruction-tuning1)演示了指令微调过程。'
- en: '![Instruction tuning process](assets/dllm_0501.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![指令微调过程](assets/dllm_0501.png)'
- en: Figure 5-1\. Instruction-tuning process
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1\. 指令微调过程
- en: Instruction-tuning is one of several techniques that come under the umbrella
    of supervised fine-tuning (SFT). In addition to improving the ability of a model
    to respond effectively to user tasks, SFT-based approaches can also be used to
    make it less harmful by training on safety datasets that help align model outputs
    with the values and preferences of the model creators.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 指令微调是监督微调（SFT）技术范畴下的几种技术之一。除了提高模型有效响应用户任务的能力外，基于SFT的方法还可以通过在安全数据集上训练来减少其潜在的危害，这些数据集有助于使模型输出与模型创建者的价值观和偏好保持一致。
- en: More advanced techniques to achieve this alignment include reinforcement learning-based
    methods like reinforcement learning from human feedback (RLHF) and reinforcement
    learning from AI feedback (RLAIF).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这种一致性的更高级技术包括基于强化学习的方法，如基于人类反馈的强化学习（RLHF）和基于AI反馈的强化学习（RLAIF）。
- en: In RLHF training, human annotators select or rank candidate outputs based on
    certain criteria, like helpfulness and harmlessness. These annotations are used
    to iteratively train a reward model, which ultimately leads to the LLM being more
    controllable, for example, by refusing to answer inappropriate requests from users.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在RLHF训练中，人类标注者根据某些标准（如有用性和无害性）选择或对候选输出进行排序。这些标注用于迭代训练奖励模型，最终导致LLM更具可控性，例如，拒绝回答用户的不适当请求。
- en: '[Figure 5-2](#rlhf-1) shows the RLHF training process.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-2](#rlhf-1)展示了RLHF训练过程。'
- en: '![RLHF](assets/dllm_0502.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![RLHF](assets/dllm_0502.png)'
- en: Figure 5-2\. Reinforcement learning from human feedback
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We will cover RLHF and other alignment techniques in detail in [Chapter 8](ch08.html#ch8).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Instead of relying on human feedback for alignment training, one can also leverage
    LLMs to choose between outputs based on their adherence to a set of principles
    (don’t be racist, don’t be rude, etc.). This technique was introduced by Anthropic
    and is called RLAIF. In this technique, humans only provide a desired set of principles
    and values (referred to as [Constitutional AI](https://oreil.ly/d8FeW)), and the
    LLM is tasked with determining whether its outputs adhere to these principles.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Instruction-tuned models often take the suffix *instruct*, like RedPajama-Instruct.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Chat-models
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Chat-models are instruction-tuned models that are optimized for multi-turn dialog.
    Examples include ChatGPT, Llama 2-Chat, MPT-Chat, OpenAssistant, etc.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: Long-context models
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As discussed in [Chapter 1](ch01.html#chapter_llm-introduction), Transformer-based
    LLMs have a limited context length. To recap, context length typically refers
    to the sum of the number of input and output tokens processed by the model per
    invocation. Typical context lengths of modern LLMs range from 8,000 to 128,000
    tokens, with some variants of Gemini supporting over a million tokens. Some models
    are released with a long-context variant; for example GPT 3.5 comes with a default
    4K context size but also has a 16K context size variant. [MPT](https://oreil.ly/wKqdL)
    also has a long-context variant that has been trained on 65k context length but
    can potentially be used for even longer contexts during inference.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Domain-adapted or task-adapted models
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLM providers also might perform fine-tuning on specific tasks like summarization
    or financial sentiment analysis. They may also produce distilled versions of the
    model, where a smaller model is fine-tuned on outputs from the larger model for
    a particular task. Examples of task-specific fine-tunes include [FinBERT](https://oreil.ly/uKUAp),
    which is fine-tuned on financial sentiment analysis datasets, and [UniversalNER](https://oreil.ly/8A0pn),
    which is distilled using named-entity-recognition data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Open Source LLMs
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Open source is often used as a catch-all phrase to refer to models with some
    aspect that is publicly available. We will define open source as:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Software artifacts that are released under a license that allows users to *study*,
    *use*, *modify*, and *redistribute* them to *anyone* and for any *purpose*.
  id: totrans-74
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a more formal and comprehensive definition of open source software, refer
    to the Open Source Initiative’s [official definition](https://oreil.ly/7cezH).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: 'For an LLM to be considered fully open, all of the following needs to be published:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Model weights
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: This includes all the parameters of the model and the model configuration. Having
    access to this enables us to add to or modify the model parameters in any way
    we deem fit. Model checkpoints at various stages of training are also encouraged
    to be released.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Model code
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Releasing only the weights of the model is akin to providing a software binary
    without providing the source code. Model code not only includes model training
    code and hyperparameter settings but also code used for pre-processing training
    data. Releasing information about infrastructure setup and configuration also
    goes a long way toward enhancing model reproducibility. In most cases, even with
    model code fully available, models may not be easily reproducible due to resource
    limitations and the nondeterministic nature of training.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Training data
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: This includes the training data used for the model, and ideally information
    or code on how it was sourced. It is also encouraged to release data at different
    stages of transformation of the data preprocessing pipeline, as well as the order
    in which the data was fed to the model. Training data is the component that is
    least published by model providers. Thus, most open source models are not *fully
    open* because the dataset is not public.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Training data is often not released due to competitive reasons. As discussed
    in Chapters [3](ch03.html#chapter-LLM-tokenization) and [4](ch04.html#chapter_transformer-architecture),
    most LLMs today use variants of the same architecture and training code. The distinguishing
    factor can often be the data content and preprocessing. Parts of the training
    data might be acquired using a licensing agreement, which prohibits the model
    provider from releasing the data publicly.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Another reason for not releasing training data is that there are unresolved
    legal issues pertaining to training data, especially surrounding copyright. As
    an example, The Pile dataset created by Eleuther AI is no longer available at
    the official link because it contains text from copyrighted books (the Books3
    dataset). Note that The Pile is pre-processed so the books are not in human-readable
    form and are not easily reproducible, as they are split, shuffled, and mixed.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Most training data is sourced from the open web and thus may potentially contain
    violent or sexual content that is illegal in certain jurisdictions. Despite the
    best intentions and rigorous filtering, some of these data might still be present
    in the final dataset. Thus many datasets that have been previously open are no
    longer open, LAION’s image datasets being one example.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: 'Ultimately, the license under which the model has been released determines
    the terms under which you can use, modify, or redistribute the original or modified
    LLM. Broadly speaking, open LLMs are distributed under three types of licenses:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Noncommercial
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: These licenses only allow research and personal use and prohibit the use of
    the model for commercial purposes. In many cases, the model artifacts are gated
    through an application form where a user would have to justify their need for
    access by providing a compelling research use case.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Copy-left
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: This type of license permits commercial usage, but all source or derivative
    work needs to be released under the same license, thus making it harder to develop
    proprietary modifications. The degree to which this condition applies depends
    on the specific license being used.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Permissive
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: This type of license permits commercial usage, including modifying and redistributing
    it in proprietary applications, i.e., there is no obligation for the redistribution
    to be open source. Some licenses in this category also permit patents.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: New types of licenses are being devised that restrict usage of the model for
    particular use cases, often for safety reasons. An example of this is the [Open
    RAIL-M license](https://oreil.ly/2UVMe), which prohibits usage of the model in
    use cases like providing medical advice, law enforcement, immigration and asylum
    processes, etc. For a full list of restricted use cases, see Attachment A of the
    license.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: As a practitioner intending to use open LLMs in your organization for commercial
    reasons, it is best to use ones with permissive licenses. Popular examples of
    permissive licenses include the Apache 2.0 and the MIT license.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[Creative Commons (CC) licenses](https://oreil.ly/PQy6D) are a popular class
    of licenses used to distribute open LLMs.The licenses have names like CC-BY-NC-SA,
    etc. Here is an easy way to remember what these names mean:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: BY
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: If the license contains this term, it means attribution is needed. If it contains
    only CC-BY, it means the license is permissive.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: SA
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: If the license contains this term, it means redistribution should occur under
    the same terms as this license. In other words, it is a copy-left license.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: NC
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: NC stands for noncommercial. Thus, if the license contains this term, the model
    can only be used for research or personal use cases.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: ND
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: ND stands for no derivatives. If the license contains this term, then distribution
    of modifications to the model is not allowed.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Today, models that have open weights and open code and are released under a
    license that allows redistribution to anyone and for any use case are considered
    open source models. Arguably, however, access to the training data is also crucial
    to inspect and study the model, which is part of the open source definition we
    introduced earlier.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 5-2](#llm-taxonomy) shows the various LLMs available, the licenses under
    which they are published, and their available sizes and flavors. Note that the
    LLM may be instruction-tuned or chat-tuned by a different entity than the one
    that pre-trained the LLM.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-2\. List of available LLMs
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | Availability | Sizes | Variants |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
- en: '| GPT-4 | Proprietary | Unknown | GPT-4 32K context, GPT-4 8K context |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
- en: '| GPT-3.5 Turbo | Proprietary | Unknown | GPT-3.5 4K context, GPT-3.5 16K context
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
- en: '| Claude Instant | Proprietary | Unknown | - |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
- en: '| Claude 2 | Proprietary | Unknown | - |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
- en: '| MPT | Apache 2.0 | 1B, 7B, 30B | MPT 65K storywriter |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
- en: '| CerebrasGPT | Apache 2.0 | 111M, 256M, 590M, 1.3B, 2.7B, 6.7B, 13B | CerebrasGPT
    |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
- en: '| Stability LM | CC-BY-SA | 7B | - |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
- en: '| RedPajama | Apache 2.0 | 3B, 7B | RedPajama-INCITE-Instruct, RedPajama-INCITE-Chat
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: '| GPT-Neo X | Apache 2.0 | 20B | - |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
- en: '| BLOOM | Open, restricted use | 176B | BLOOMZ |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
- en: '| Llama | Open, no commercial use | 7B, 13B, 33B, 65B | - |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
- en: '| Llama 2 | Open, commercial use | 7B, 13B, 70B | Llama 2-Chat |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
- en: '| Zephyr | Apache 2.0 | 7B | - |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
- en: '| Gemma | Open, restricted use | 2B, 7B | Gemma-Instruction Tuned |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
- en: How to Choose an LLM for Your Task
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Given the plethora of options available, how do you ensure you choose the right
    LLM for your task? Depending on your situation, there are a multitude of criteria
    to consider, including:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Cost
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: This includes inference or fine-tuning costs, and costs associated with building
    software scaffolding, monitoring and observability, deployment and maintenance
    (collectively referred to as LLMOps).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[Time per output token (TPOT)](https://oreil.ly/mEDRt)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: This is a metric used to measure the speed of text generation as experienced
    by the end user.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Task performance
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: This refers to the performance requirements of the task and the relevant metrics
    like precision or accuracy. What level of performance is *good enough*?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Type of tasks
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: The nature of the tasks the LLM will be used for, like summarization, question
    answering, classification, etc.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Capabilities required
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Examples of capabilities include arithmetic reasoning, logical reasoning, planning,
    task decomposition, etc. A lot of these capabilities, to the extent that they
    actually exist or approximate, are *emergent properties* of an LLM as discussed
    in [Chapter 1](ch01.html#chapter_llm-introduction), and are not exhibited by smaller
    models.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Licensing
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: You can use only those models that allow your mode of usage. Even models that
    explicitly allow commercial use can have restrictions on certain types of use
    cases. For example, as noted earlier, the Big Science OpenRAIL-M license restricts
    the usage of the LLM in use cases pertaining to law enforcement, immigration,
    or asylum processes.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: In-house ML/MLOps talent
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: The strength of in-house talent determines the customizations you can afford.
    For example, do you have enough in-house talent for building inference optimization
    systems?
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Other nonfunctional criteria
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: This includes safety, security, privacy, etc. Cloud providers and startups are
    already implementing solutions that can address these issues.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: You may have to choose between proprietary and open source LLMs.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Open Source Versus Proprietary LLMs
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Debates about the merits of open source versus proprietary software have been
    commonplace in the tech industry for several decades now, and we are seeing it
    become increasingly relevant in the realm of LLMs as well. The biggest advantage
    of open source models are the transparency and flexibility they provide, not necessarily
    the cost. Self-hosting open source LLMs can incur a lot of engineering overhead
    and compute/memory costs, and using managed services might not always be able
    to match proprietary models in terms of latency, throughput, and inference cost.
    Moreover, many open source LLMs are not easily accessible through managed services
    and other third-party deployment options. This situation is bound to change dramatically
    as the field matures, but in the meanwhile, run through your calculations for
    your specific situation to determine the costs incurred for using each (type of)
    model.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 关于开源软件与专有软件优缺点的争论在科技行业已经司空见惯了几十年，现在我们也在LLM（大型语言模型）领域看到这一现象变得越来越相关。开源模型最大的优势是它们提供的透明度和灵活性，而不仅仅是成本。自托管开源LLM可能会产生大量的工程开销和计算/内存成本，而使用托管服务可能无法始终在延迟、吞吐量和推理成本方面与专有模型相匹配。此外，许多开源LLM通过托管服务和第三方部署选项并不容易获得。随着该领域的成熟，这种状况必将发生巨大变化，但在此期间，请针对您的具体情况运行计算，以确定使用每种（类型）模型所产生的成本。
- en: The flexibility provided by open source models helps with your ability to debug,
    interpret, and augment the LLM with any kind of training/fine-tuning you choose,
    instead of the restricted avenues made available by the LLM provider. This allows
    you to more substantially align the LLM to your preferences and values instead
    of the ones decided by the LLM provider. Having full availability of all the token
    probabilities (logits) is a superpower, as we will see throughout the book.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 开源模型提供的灵活性有助于您调试、解释和通过您选择的任何类型的训练/微调来增强LLM，而不是LLM提供商提供的受限途径。这使您能够更实质性地将LLM与您的偏好和价值观对齐，而不是由LLM提供商决定的那些。在整个书中，我们将看到拥有所有标记概率（logits）的完全可用性是一种超级能力。
- en: The availability of open source LLMs has enabled teams to develop models and
    applications that might not be lucrative for larger companies with a profit motive,
    like fine-tuning models to support low-resource languages (languages that do not
    have a significant data footprint on the internet, like regional languages of
    India or Indigenous languages of Canada). An example is the [Kannada Llama model](https://oreil.ly/hoBQ1),
    built over Llama 2 by continually pre-training and fine-tuning on tokens from
    the Kannada language, a regional language of India.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 开源LLM的可用性使团队能够开发出对具有盈利动机的大型公司来说可能并不盈利的模型和应用，例如微调模型以支持低资源语言（在互联网上没有显著数据足迹的语言，如印度的地区语言或加拿大的土著语言）。一个例子是[卡纳达Llama模型](https://oreil.ly/hoBQ1)，它是在Llama
    2的基础上，通过不断在卡纳达语言（印度的地区语言）的标记上进行预训练和微调而构建的。
- en: Not all open source models are fully transparent. As mentioned earlier, most
    for-profit companies that release open source LLMs do not make the training datasets
    public. For instance, Meta hasn’t disclosed all the details of the training datasets
    used to train the Llama 2 model. Knowing which datasets are used to train the
    model can help you assess whether there is test set contamination and understand
    what kind of knowledge you can expect the LLM to possess.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有开源模型都是完全透明的。如前所述，大多数发布开源LLM的盈利性公司并不公开其训练数据集。例如，Meta并未披露用于训练Llama 2模型的训练数据集的所有细节。了解用于训练模型的哪些数据集可以帮助您评估是否存在测试集污染，并了解LLM可能拥有的知识类型。
- en: As of this book’s writing, open source models like Llama 3.2 and DeepSeek v3
    have more or less caught up to state-of-the-art proprietary models from OpenAI
    or Anthropic. However, there is a new gap developing between proprietary and open
    source models in the realm of reasoning models like OpenAI’s o3, that use inference-time
    compute techniques (discussed in [Chapter 8](ch08.html#ch8)). Throughout this
    book, we will showcase scenarios where open source models have an advantage.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 就本书撰写时的情况来看，开源模型如Llama 3.2和DeepSeek v3在某种程度上已经赶上了OpenAI或Anthropic等公司最先进的专有模型。然而，在推理模型领域，如OpenAI的o3，它使用推理时计算技术（在第8章中讨论）的情况下，专有模型与开源模型之间正在出现一个新的差距。在整个书中，我们将展示开源模型具有优势的场景。
- en: Tip
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Always check if the model provider has an active developer community on GitHub/Discord/Slack,
    and that the development team is actively engaged in those channels, responding
    to user comments and questions. I recommend preferring models with active developer
    communities, provided they satisfy your primary criteria.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 总是检查模型提供者是否在GitHub/Discord/Slack上有活跃的开发者社区，并且开发团队是否积极参与这些渠道，回应用户评论和问题。如果它们满足你的主要标准，我建议优先考虑具有活跃开发者社区的模型。
- en: LLM Evaluation
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM评估
- en: 'We will start this section with a caveat: evaluating LLMs is probably the most
    challenging task in the LLM space at present. Current methods of benchmarking
    are broken, easily gamed, and hard to interpret. Nevertheless, benchmarks are
    still a useful starting point on your road to evaluation. We will start by looking
    at current public benchmarks and then discuss how you can build more holistic
    internal benchmarks.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从这个部分开始，先提出一个警告：在当前LLM（大型语言模型）领域，评估LLM可能是最具挑战性的任务。现有的基准测试方法存在缺陷，容易被操纵，且难以解释。尽管如此，基准测试仍然是你在评估之路上的一个有用起点。我们将从查看当前的公共基准测试开始，然后讨论你如何构建更全面的内部基准测试。
- en: To evaluate LLMs on their task performance, there are a lot of benchmark datasets
    that test a wide variety of skills. Not all skills are relevant to your use case,
    so you can choose to focus on specific benchmarks that test the skills you need
    the LLM to perform well on.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要评估LLM在任务性能上的表现，有许多基准数据集可以测试广泛的技能。并非所有技能都与你的用例相关，因此你可以选择专注于特定的基准，这些基准测试的是LLM需要表现良好的技能。
- en: The leaderboard on these benchmark tests changes very often, especially if only
    open source models are being evaluated, but that does not mean you need to change
    the LLMs you use every time there is a new leader on the board. Usually, the differences
    between the top models are quite marginal. The fine-grained choice of LLM usually
    isn’t the most important criteria determining the success of your task, and you
    are better off spending that bandwidth working on cleaning and understanding your
    data, which is still the most important component of the project.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基准测试的排行榜变化非常频繁，尤其是在只评估开源模型的情况下，但这并不意味着每次榜单上出现新的领先者时，你都需要更换你使用的LLM。通常，顶级模型之间的差异相当微小。LLM的精细选择通常不是决定你任务成功与否的最重要标准，你最好将带宽用于清理和理解你的数据，这仍然是项目最重要的组成部分。
- en: Let’s look at a few popular ways in which the field is evaluating LLMs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看该领域评估LLM的几种流行方式。
- en: Eleuther AI LM Evaluation Harness
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Eleuther AI LM评估工具
- en: Through the [LM Evaluation Harness](https://oreil.ly/SiOXq), Eleuther AI supports
    benchmarking on over 400 different benchmark tasks, evaluating skills as varied
    as open-domain question answering, arithmetic and logical reasoning, linguistic
    tasks, machine translation, toxic language detection, etc. You can use this tool
    to evaluate any model on the [Hugging Face Hub](https://oreil.ly/IHd22), a platform
    containing thousands of pre-trained and fine-tuned models, on the benchmarks of
    your choice.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 通过[LM评估工具](https://oreil.ly/SiOXq)，Eleuther AI支持在超过400个不同的基准任务上进行基准测试，评估的技能范围包括开放域问答、算术和逻辑推理、语言任务、机器翻译、有害语言检测等。你可以使用这个工具在[Hugging
    Face Hub](https://oreil.ly/IHd22)上评估任何模型，这是一个包含数千个预训练和微调模型的平台，并在你选择的基准上进行测试。
- en: 'Here is an example from `bigbench_formal_fallacies_syllogisms_negation`, one
    of the benchmark tasks:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个来自`bigbench_formal_fallacies_syllogisms_negation`基准任务的示例：
- en: '[PRE0]` `premises``,` `deductively` `valid` `or` `invalid``?``",` [PRE1] [PRE2]'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE0]` `前提``,` `演绎` `有效` `或` `无效``?``",` [PRE1] [PRE2]'
- en: '[PRE3] [PRE4]`py  [PRE5]py  [PRE6]'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE3] [PRE4]`py  [PRE5]py  [PRE6]'
