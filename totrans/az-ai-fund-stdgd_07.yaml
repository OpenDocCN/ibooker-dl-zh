- en: Chapter 7\. Features of Natural Language Processing Workloads on Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ll look into NLP, a key topic that makes up about 15%–20%
    of the AI-900 exam. We’ll kick things off with an exploration of core NLP scenarios.
    Then, we’ll get into Microsoft Azure services for NLP, starting with key phrase
    extraction and how entity recognition pulls important context from text. From
    there, we’ll walk through sentiment analysis, an essential tool for reading emotions
    in written language, and cover the basics of language modeling. You’ll also find
    an introduction to speech recognition and synthesis. This is where machines learn
    to understand and produce humanlike speech. Finally, we’ll wrap up with how to
    use NLP with conversational language understanding (CLU) and conversational AI.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Imagine trying to get your computer to not just read but actually understand
    what you’re saying—that’s where NLP steps in. NLP is a part of AI that gives machines
    the power to interpret and generate human language. It’s about taking apart the
    complexities of text and speech and transforming them into something a computer
    can work with. This is what fuels everything from the search results you see on
    Google to chatbots to generative AI apps like ChatGPT that answer questions and
    those voice-activated assistants that talk back. By bridging the gap between human
    communication and computer logic, NLP makes technology feel more intuitive—almost
    like it’s listening.
  prefs: []
  type: TYPE_NORMAL
- en: 'NLP doesn’t work alone—it’s backed by two powerful AI systems: machine learning
    (ML) and deep learning (DL). ML gives NLP systems the models and algorithms they
    need to spot patterns and make predictions. DL takes this a step further, allowing
    NLP to tackle complex tasks like understanding the context of conversation or
    gauging sentiment. DL models mimic the brain’s structure, giving NLP systems a
    real boost in “thinking” more like us. And because ML and DL help NLP keep learning
    from new data, these systems keep getting better at handling language naturally.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll see NLP in action in three main ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Language processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Speech recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Translation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In language processing, NLP can do things like sentiment analysis, which is
    how it picks up on emotion in text, or entity recognition, where it identifies
    specific names or places within content. Then there’s speech recognition and synthesis:
    those technologies that allow your virtual assistants to understand and respond
    when you speak. And, of course, NLP powers translation tools, breaking down language
    barriers so that people from different parts of the world can connect easily.'
  prefs: []
  type: TYPE_NORMAL
- en: Tokenization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Tokenization* is about breaking down words and parts of words into numbers,
    which are known as *tokens*. This is the first step in the NLP process. It provides
    the framework for identifying the words or phrases that NLP models need to analyze,
    classify, or respond to.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take an example. Suppose we have this sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: Time flies like an arrow, time flies fast.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'When we tokenize this sentence, each word (or token) is given an identifier.
    Because the words *time* and *flies* repeat, they get only one token ID even though
    they appear twice. Here’s how it breaks down:'
  prefs: []
  type: TYPE_NORMAL
- en: time
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: flies
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: like
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: an
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: arrow
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: fast
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'So our sentence becomes a sequence of tokens: [1, 2, 3, 4, 5, 1, 2, 6]—that
    is, there are eight words but six tokens.'
  prefs: []
  type: TYPE_NORMAL
- en: Without tokenization, a computer would see the sentence as one continuous string
    of characters, which isn’t useful for analysis. Breaking it down allows the NLP
    model to interpret each part separately and understand how they work together.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some other considerations in tokenization:'
  prefs: []
  type: TYPE_NORMAL
- en: Text normalization
  prefs: []
  type: TYPE_NORMAL
- en: Before tokenizing, the text might be normalized. This usually means converting
    everything to lowercase and removing punctuation. In our example, normalization
    would turn “Time flies like an arrow, time flies fast” into “time flies like an
    arrow time flies fast.” Normalization helps simplify the processing, although
    sometimes specific details like capitalization or punctuation are necessary. For
    instance, “Dr. Johnson” and “dr” convey very different meanings in a medical context
    where “Dr.” indicates a title.
  prefs: []
  type: TYPE_NORMAL
- en: Stop-word removal
  prefs: []
  type: TYPE_NORMAL
- en: Words like *the*, *an*, or *and* are common in most sentences but don’t always
    add useful meaning. By removing these stop words, NLP systems can emphasize the
    core content. For our sentence, if we remove *like* and *an*, we’re left with
    “time flies arrow time flies fast,” which directs more attention to the essential
    words.
  prefs: []
  type: TYPE_NORMAL
- en: N-grams
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, instead of breaking a sentence down to single words, NLP models capture
    phrases (such as bigrams for two words or trigrams for three). For example, “time
    flies” could be treated as a bigram to capture a specific phrase instead of treating
    “time” and “flies” as separate tokens. This can preserve important context, as
    in the case of “New York City,” which, if split, might lose its meaning.
  prefs: []
  type: TYPE_NORMAL
- en: Stemming
  prefs: []
  type: TYPE_NORMAL
- en: To make analysis clearer, similar words are often grouped together. For example,
    *flying*, *flew*, and *flies* could be treated as the root form *fly*. In our
    example, both instances of *flies* would link back to the base *fly* token, making
    it easier to analyze related concepts together.
  prefs: []
  type: TYPE_NORMAL
- en: Lemmatization
  prefs: []
  type: TYPE_NORMAL
- en: 'This reduces words to their base form, or lemma, so that different versions
    of a word—such as *running*, *ran*, and *runs*—all map back to a single, consistent
    root form: *run*. Unlike simple stemming, which just chops off endings, lemmatization
    applies linguistic rules to ensure that the base form is meaningful and grammatically
    accurate. This process makes text analysis more precise by grouping related words.'
  prefs: []
  type: TYPE_NORMAL
- en: Frequency Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once you’ve tokenized the words, the next step is *frequency analysis:* examining
    how frequently each word appears. The most common words (ignoring basics like
    *a*, *the*, and similar words) can hint at the main theme of the text. Take a
    political speech about economic growth, for example: the most frequent words might
    include *growth*, *jobs*, *future*, and *economy*. If we look at word pairs (bigrams),
    a common pair might be “new jobs,” which points to a focus on employment and economic
    expansion.'
  prefs: []
  type: TYPE_NORMAL
- en: Counting word occurrences, known as *simple frequency analysis*, works well
    for examining a single document. But when you’re working with multiple documents,
    you need a way to pinpoint the most relevant words in each one. That’s where *term
    frequency-inverse document frequency (TF-IDF)* comes in. This method scores words
    by how often they appear in a document compared to the entire set of documents.
    Words that appear often in one document but are rare in the others stand out as
    especially relevant.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some additional considerations in frequency analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of simple frequency analysis
  prefs: []
  type: TYPE_NORMAL
- en: While simple frequency or bigram analysis offers helpful initial insights, it
    can miss nuances or context. Frequently used words may not always indicate the
    main topic, especially if they’re general or if they depend on context. When analyzing
    complex or larger documents, more advanced methods like TF-IDF, latent Dirichlet
    allocation (LDA), or other topic-modeling techniques are often more insightful.
    *LDA* is a statistical model that identifies topics in a collection of documents
    by finding groups of words that frequently appear together. This helps to uncover
    underlying themes or subjects, making it easier to analyze and categorize large
    amounts of text.
  prefs: []
  type: TYPE_NORMAL
- en: Broader uses of TF-IDF
  prefs: []
  type: TYPE_NORMAL
- en: TF-IDF isn’t just for finding relevant words—it’s also used in similarity analysis
    to group related documents, making it a powerful tool for tasks like information
    retrieval and recommendation systems.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced contextual models
  prefs: []
  type: TYPE_NORMAL
- en: For even more refined insights, techniques like word2vec, BERT (bidirectional
    encoder representations from transformers), or other contextual embeddings consider
    each word’s meaning based on surrounding text, which brings greater clarity to
    themes across a document and improves tasks like summarization, sentiment analysis,
    and topic detection.
  prefs: []
  type: TYPE_NORMAL
- en: Text Classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another powerful way to analyze text is by using a classification algorithm,
    like logistic regression, to categorize it based on predefined labels, which is
    called *text classification*. A common application for this is sorting social
    media posts for sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say you’re working with social media comments that are already labeled
    as either 0 (critical) or 1 (supportive):'
  prefs: []
  type: TYPE_NORMAL
- en: “This initiative is exactly what we need!” = 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Totally disappointed with the results so far” = 0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Great job! Keep it up!” = 1
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “This approach misses the point entirely” = 0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With enough labeled examples, you can train a classification model that learns
    to distinguish between supportive and critical posts. Using the tokenized text
    as features and the sentiment label (0 or 1), the model starts to detect patterns.
    For instance, comments with words like *great*, *exactly*, or *job* tend to be
    supportive while words like *disappointed* or *misses* indicate criticism.
  prefs: []
  type: TYPE_NORMAL
- en: To make this work, you’ll need to convert words into numbers. Basic methods
    like the bag-of-words model and TF-IDF score word importance based on frequency
    while advanced embeddings like word2vec or GloVe capture meaning based on context.
    Logistic regression is a good starting point, but other algorithms like naive
    Bayes and support vector machine (SVM), DL models like recurrent neural networks
    (RNNs), or transformers can boost performance, especially for larger datasets
    or nuanced content.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure your model is effective, evaluate it with metrics like accuracy, precision,
    recall, and the F1 score, which reveal how well the model generalizes new data.
    Just keep in mind that models can struggle with subtleties like sarcasm. For example,
    a comment like “Love the effort…the result is certainly something” could be misinterpreted
    as supportive.
  prefs: []
  type: TYPE_NORMAL
- en: Classification models have plenty of uses beyond sorting social media sentiment,
    such as tagging news articles by category (e.g., “politics,” “entertainment,”
    or “health”) or even spotting trending topics—showing just how versatile text
    classification can be.
  prefs: []
  type: TYPE_NORMAL
- en: Semantic Language Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the world of NLP, models have come a long way, making it possible to capture
    the deep and subtle relationships between words. The secret sauce is embeddings—essentially
    multidimensional number arrays that map each word, or token, to a unique point
    in space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Think of each element in an embedding as a coordinate in a multidimensional
    space. Each token—whether it’s “coffee,” “latte,” or “soccer”—finds its own spot
    in this space. Tokens that are related by meaning are closer to one another. Here’s
    a quick example in three dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: '“coffee”: [9, 2, 3]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“tea”: [9, 2, 2]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“caffeine”: [8, 2, 3]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“latte”: [9, 3, 3]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '“soccer”: [1, 7, 3]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Figure 7-1](#i07_chapter7_figure_1_1742068263357633) shows the plotting for
    these items.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aaif_0701.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. The plotting for the embeddings
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The plotting shows that “coffee,” caffeine,” and “latte” huddle close together
    while “soccer” sits off to the side, indicating less of a semantic connection.
    This layout helps us see patterns in how words relate to one another based on
    meaning.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced models, called *semantic language models*, take these embeddings and
    add complexity. For example, BERT and GPT models use what’s called *contextual
    embeddings*. This means a word like *bank* gets a different representation in
    “riverbank” versus “national bank,” helping models better grasp the intended meaning.
  prefs: []
  type: TYPE_NORMAL
- en: How would you visualize high-dimensional embeddings? You can use techniques
    like principal component analysis (PCA) or t-distributed stochastic neighbor embedding
    (t-SNE), which simplify these multidimensional embeddings into a two- or three-dimensional
    view. This makes it much easier to see the relationships between tokens. Most
    embeddings are initially trained on enormous datasets (think word2vec or GloVe),
    and they can later be fine-tuned for specialized areas, such as legal or medical
    content.
  prefs: []
  type: TYPE_NORMAL
- en: Learning from these embeddings often relies on self-supervised learning, where
    models teach themselves by predicting missing or next words. This is helpful for
    building multilingual embeddings, where words with similar meanings across languages
    find similar spots in the embedding space.
  prefs: []
  type: TYPE_NORMAL
- en: But embeddings aren’t without issues. They can mirror biases present in training
    data, such as linking demographic groups to certain roles, which can result in
    skewed predictions. Correcting these biases through debiasing techniques is crucial
    for fair, responsible use.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Services for NLP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Microsoft Azure offers three main services for NLP: Azure AI Language, Azure
    AI Translator, and Azure AI Speech. Let’s take a look at each.'
  prefs: []
  type: TYPE_NORMAL
- en: First, *Azure AI Language* enables you to understand, analyze, and respond to
    text data through a wide range of preconfigured and customizable features. It
    also has tools that cater to different levels of complexity. [Table 7-1](#i07_chapter7_table_1_1742068263363592)
    describes the features of the service.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-1\. Features of Azure AI Language
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Named entity recognition (NER) | Identifies entities like names, dates, and
    locations in unstructured text, categorizing them into groups for easy organization
    |'
  prefs: []
  type: TYPE_TB
- en: '| PII and PHI detection | Detects, categorizes, and redacts sensitive information,
    including personally identifiable information (PII) and protected health information
    (PHI), in text |'
  prefs: []
  type: TYPE_TB
- en: '| Language detection | Identifies the language of a text document and returns
    a code for the detected language, covering a wide range of languages and dialects
    |'
  prefs: []
  type: TYPE_TB
- en: '| Sentiment analysis and opinion mining | Analyzes text to determine positive
    or negative sentiment, providing insight into customer feedback and public opinion
    |'
  prefs: []
  type: TYPE_TB
- en: '| Summarization | Produces a concise summary of a document or transcription
    by extracting key sentences |'
  prefs: []
  type: TYPE_TB
- en: '| Key phrase extraction | Identifies the main concepts in text, returning a
    list of key phrases to highlight major themes or topics |'
  prefs: []
  type: TYPE_TB
- en: '| Entity linking | Disambiguates terms and entities in text to references like
    Wikipedia, providing additional context |'
  prefs: []
  type: TYPE_TB
- en: The second service Azure offers is *Azure AI Translator*. This service enables
    applications to instantly translate text into multiple languages. [Table 7-2](#i07_chapter7_table_2_1742068263363623)
    describes the features of this service.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-2\. Features of Azure AI Translator
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Text translation | Translates text instantly between a supported source and
    target languages, with options for creating custom dictionaries and managing translation
    exceptions |'
  prefs: []
  type: TYPE_TB
- en: '| Document translation | Offers two modes: asynchronous batch translation for
    large sets of files, which retains the format and structure with Azure Blob Storage,
    and synchronous translation for individual documents, which preserves the structure
    without storage requirements |'
  prefs: []
  type: TYPE_TB
- en: '| Custom translator | Allows customization of translation models for specific
    industry languages, terminology, and styles, including creating specialized dictionaries
    for tailored translations |'
  prefs: []
  type: TYPE_TB
- en: The third service, *Azure AI Speech*, is geared toward converting spoken language
    into text and vice versa. [Table 7-3](#i07_chapter7_table_3_1742068263363647)
    lists the features of this service.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-3\. Features of Azure AI Speech
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Speech-to-text | Transcribes audio to text from various sources, such as
    microphones and audio files, in real time or with batch processingFeatures include
    speaker diarization and automatic formatting for improved readability |'
  prefs: []
  type: TYPE_TB
- en: '| Real-time speech-to-text | Provides instant transcription of live audio,
    which is ideal for applications needing immediate text, such as live-meeting captions,
    pronunciation assessments, and contact center support |'
  prefs: []
  type: TYPE_TB
- en: '| Text-to-speech | Converts written text to lifelike, synthesized speech using
    neural voices, with customization options for pitch, pronunciation, and speed
    |'
  prefs: []
  type: TYPE_TB
- en: '| Fast transcription API | Offers a quick, synchronous transcription option
    for prerecorded audio, delivering results with minimal delaySuitable for urgent
    tasks like video transcription and fast audio processingAvailable through the
    preview API |'
  prefs: []
  type: TYPE_TB
- en: Next, we’ll take a look at these services and how they work with NLP applications.
  prefs: []
  type: TYPE_NORMAL
- en: Key Phrase Extraction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Key phrase extraction* is an NLP technique that identifies the most relevant
    words or phrases within a text. This pinpoints the main topics or themes without
    needing to analyze the entire document. Key phrase extraction is a valuable tool
    in NLP because it enables systems to quickly grasp the core content of a text,
    which is essential in tasks like summarizing, content tagging, or indexing large
    documents.'
  prefs: []
  type: TYPE_NORMAL
- en: Typical uses for key phrase extraction range across many fields. In customer
    service, for instance, key phrase extraction can help identify main concerns or
    frequently mentioned issues in customer feedback, making it easier for teams to
    address common problems. This technique also supports social media analysis by
    quickly identifying trending topics from user-generated content, such as tweets
    or posts, so brands can understand public sentiment or emerging discussions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider a more detailed example: a company analyzing customer reviews for
    a new product. Using key phrase extraction, the model identifies common phrases
    like “easy to use,” “battery life,” and “customer support.” These extracted phrases
    help the company see what features customers talk about most without having to
    manually read each review. Additionally, negative phrases like “difficult setup”
    or “short battery life” allow the company to pinpoint areas needing improvement.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look at how you can use key phrase extraction using [Azure AI Language
    Studio](https://oreil.ly/8gTK0). Once you’re at the dashboard for the Language
    Studio, select “Extract information” and then click “Extract key phrases.” You’ll
    find different examples of text, such as for travel, medical reports, and banking.
    We’ll select banking. This is a message from a customer who requested a cancellation
    for a credit card because it was lost. Click Run. [Figure 7-2](#i07_chapter7_figure_2_1742068263357669)
    shows the results.
  prefs: []
  type: TYPE_NORMAL
- en: At the top are the key phrases that were extracted. They include details like
    the address, linked email account, Social Security number, and SWIFT code. Below
    is the original text with the extracted key phrases highlighted.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aaif_0702.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-2\. Key phrases extracted from a message about a credit card cancellation
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Entity Recognition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Entity recognition*, often called *named entity recognition (NER)*, is a process
    in AI where you teach a model to identify and classify elements, or entities,
    in a text. These entities could be names of people, places, organizations, dates,
    or even products—basically, anything meaningful and distinct in a body of text.
    Think of NER as a way to highlight or tag essential parts of information automatically.
    This makes it easier to analyze and categorize data without manual sorting.'
  prefs: []
  type: TYPE_NORMAL
- en: A common use case for NER is for customer service chatbots to recognize a user’s
    name, location, or problem type. This allows the system to personalize the responses.
    In legal or financial sectors, NER can automatically extract contract dates, client
    names, or financial figures from documents, reducing the need for tedious human
    review. NER also enhances search engines, making search results more relevant
    by helping the engine understand the context behind keywords.
  prefs: []
  type: TYPE_NORMAL
- en: How does entity recognition actually work? It follows a few key steps. First,
    the model preprocesses the text by breaking it into smaller parts, like sentences
    or words. Then, it uses language algorithms to spot potential entities based on
    patterns. After that, it classifies these entities into categories, such as “person”
    or “organization.” Finally, the model refines its guesses based on training data
    and produces a list of recognized entities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a quick example to bring this to life. Suppose we have this sentence:
    “John Doe from TechCorp called on October 10, 2024 about the quarterly report.”
    After running it through an NER model, we get the results shown in [Table 7-4](#i07_chapter7_table_4_1742068263363668).'
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-4\. Results of using NER
  prefs: []
  type: TYPE_NORMAL
- en: '| Entity | Type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| John Doe | Person |'
  prefs: []
  type: TYPE_TB
- en: '| TechCorp | Organization |'
  prefs: []
  type: TYPE_TB
- en: '| October 10, 2024 | Date |'
  prefs: []
  type: TYPE_TB
- en: '| Quarterly report | Miscellaneous |'
  prefs: []
  type: TYPE_TB
- en: When using Azure AI Foundry, you can select “Extract named entities.” Then,
    select “Medical Report” and click Run. [Figure 7-3](#i07_chapter7_figure_3_1742068263357693)
    shows a list of the entities that were found as well as the original text that
    marks them. If you hover over one of these highlights, you will see more details,
    such as the confidence level.
  prefs: []
  type: TYPE_NORMAL
- en: '*Named entity linking (NEL)* takes NER a step further by not only identifying
    entities in text but also connecting them to unique, real-world references. Suppose
    you’re reading an article that mentions Paris. With entity linking, an AI model
    won’t just recognize Paris as a location; it will also understand whether the
    article refers to Paris, France, or Paris, Texas, depending on the context. Entity
    linking is like giving each entity a unique ID or link to a database. This mitigates
    confusion about what the term represents.'
  prefs: []
  type: TYPE_NORMAL
- en: Entity linking comes in handy in a lot of fields. In news aggregation, it helps
    ensure that all references to a particular event or person, such as a CEO or celebrity,
    consistently point to the same profile, avoiding duplication. In health care,
    entity linking can automatically connect mentions of a medical condition to a
    knowledge base of treatments, symptoms, and research articles.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aaif_0703.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-3\. NER for a medical report
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Sentiment Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I mentioned sentiment analysis earlier in this chapter, but let’s take a deeper
    look at it now. *Sentiment analysis* is like giving your AI model emotional intelligence.
    It allows the system to read between the lines and determine if a piece of text
    is positive, negative, or neutral. Essentially, sentiment analysis works by analyzing
    the words and phrases in a text to figure out the mood or feeling behind them.
    So whether you’re analyzing customer reviews, social media comments, or survey
    responses, sentiment analysis can help you understand how people feel about a
    product, service, or topic without needing a human to go through everything manually.
  prefs: []
  type: TYPE_NORMAL
- en: In customer service, sentiment analysis can flag negative comments or complaints
    so that agents can respond more quickly. In marketing, it helps track brand reputation
    over time by monitoring sentiment on social media or review sites. It’s also valuable
    in product development, where analyzing feedback can reveal trends in customer
    satisfaction or highlight recurring issues that need fixing.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 7-5](#i07_chapter7_table_5_1742068263363690) shows an example of sentiment
    analysis—specifically, an analysis of the following review: “The new phone’s camera
    is fantastic, but the battery life is disappointing.”'
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-5\. Sentiment analysis of a product review
  prefs: []
  type: TYPE_NORMAL
- en: '| Phrase | Sentiment | Score |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| new phone’s camera | Positive | +2 |'
  prefs: []
  type: TYPE_TB
- en: '| fantastic | Positive | +3 |'
  prefs: []
  type: TYPE_TB
- en: '| battery life | Neutral | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| disappointing | Negative | -3 |'
  prefs: []
  type: TYPE_TB
- en: The AI would then sum up these scores to produce an overall sentiment score
    for the review. Here, the score would likely lean toward neutral or slightly positive
    since the enthusiasm for the camera is balanced by disappointment with the battery.
  prefs: []
  type: TYPE_NORMAL
- en: Language Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Language detection* is a feature of the Azure AI Language service that identifies
    the language of a given text. It supports more than one hundred languages. This
    service allows multiple documents to be processed at once. Results include:'
  prefs: []
  type: TYPE_NORMAL
- en: The language name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ISO 639-1 language code (a two-letter code like “fr” that is part of an
    international standard for language representation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A confidence score
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To illustrate, let’s say you operate a travel forum where users post feedback
    about destinations worldwide. Here are three examples of feedback you receive:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Feedback 1: “An amazing spot for birdwatching and hiking.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Feedback 2: “Le personnel était très accueillant et serviable.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Feedback 3: “Il posto perfetto per rilassarsi con la famiglia.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Table 7-6](#i07_chapter7_table_6_1742068263363710) shows the results that
    Azure AI Language provides.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-6\. Language detection for a message forum
  prefs: []
  type: TYPE_NORMAL
- en: '| Document | Language | ISO 639-1 code | Confidence score |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Feedback 1 | English | en | 0.8 |'
  prefs: []
  type: TYPE_TB
- en: '| Feedback 2 | French | fr | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Feedback 3 | Italian | it | 0.9 |'
  prefs: []
  type: TYPE_TB
- en: When a comment includes a mix of languages, Azure focuses on the predominant
    one. This provides a single language label with a confidence score that might
    be slightly lower if multiple languages are detected. In cases where the content
    is minimal or ambiguous, such as with a simple emoji or symbol, Azure might label
    the language as “unknown” and leave the language identifier empty, with a “NaN”
    (not a number) score to indicate that it couldn’t confidently determine a language.
  prefs: []
  type: TYPE_NORMAL
- en: Speech Recognition and Synthesis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When it comes to AI and speech, there are two key skills that make it all work:
    speech recognition and speech synthesis. *Speech recognition* is what allows AI
    to listen to spoken input and understand what’s being said. *Speech synthesis*,
    on the other hand, is how AI generates spoken output. This essentially gives it
    the ability to “talk” back to you. Together, these capabilities make it possible
    for AI to engage in a natural, back-and-forth conversation, creating more interactive
    and personal experiences.'
  prefs: []
  type: TYPE_NORMAL
- en: Speech recognition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Speech recognition technology powers many day-to-day conveniences:'
  prefs: []
  type: TYPE_NORMAL
- en: Meeting transcription
  prefs: []
  type: TYPE_NORMAL
- en: AI can create a full transcript of your Zoom call or meeting, so you can stay
    focused without taking notes.
  prefs: []
  type: TYPE_NORMAL
- en: Real-time captions
  prefs: []
  type: TYPE_NORMAL
- en: In a livestream, captions make it so you do not miss any details.
  prefs: []
  type: TYPE_NORMAL
- en: Voice-activated customer service
  prefs: []
  type: TYPE_NORMAL
- en: You can talk to the system and not have to navigate menu options. The AI will
    understand and connect you to what you are looking for.
  prefs: []
  type: TYPE_NORMAL
- en: Dictation
  prefs: []
  type: TYPE_NORMAL
- en: Speak freely, and AI transcribes your words into notes, which is ideal for capturing
    ideas quickly or managing daily tasks hands-free.
  prefs: []
  type: TYPE_NORMAL
- en: How does speech recognition work? It begins with capturing your audio input,
    then moves to feature extraction, where the AI isolates and analyzes sound features.
    An acoustic model translates these features into phonemes, then a language model
    maps phonemes to words using statistical probabilities. Finally, a decoding process
    refines the output. This creates clear and accurate text from spoken language.
  prefs: []
  type: TYPE_NORMAL
- en: To see this in Azure, you can go to the [Speech Studio](https://oreil.ly/zlmtI)
    and select “Real-time speech to text.” Select a language and then either upload
    an audio file or create one. Speak into your computer’s microphone, and the system
    will convert your words into text as you speak. It will even create a *.wav* audio
    file that you can download. You can see this in [Figure 7-4](#i07_chapter7_figure_4_1742068263357714).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aaif_0704.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-4\. The speech-to-text capabilities of Azure
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When you look at the JSON, you’ll see a detailed description of the output,
    including the offsets and duration for each word. Here’s a snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Speech synthesis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Under the hood, speech synthesis relies on a few essential steps. It starts
    with text analysis, breaking down the text’s structure and meaning. Then prosody
    and acoustic modeling add tone, pitch, and emphasis, giving the speech a natural
    cadence. Finally, waveform generation turns all of this into audio, creating a
    clear, humanlike voice. With these capabilities, speech synthesis provides a more
    engaging, interactive experience that feels like a true conversation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few of the use cases for speech synthesis:'
  prefs: []
  type: TYPE_NORMAL
- en: Hands-free reading
  prefs: []
  type: TYPE_NORMAL
- en: Speech synthesis reads articles, messages, or notes aloud, keeping you engaged
    while you’re multitasking.
  prefs: []
  type: TYPE_NORMAL
- en: Step-by-step guidance
  prefs: []
  type: TYPE_NORMAL
- en: When you are following a recipe or workout, for instance, an app can read the
    instructions aloud, so you can stay focused without a screen.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual assistant responses
  prefs: []
  type: TYPE_NORMAL
- en: A friendly voice responds to your questions, whether you’re checking the weather
    forecast or asking for directions.
  prefs: []
  type: TYPE_NORMAL
- en: Public announcements
  prefs: []
  type: TYPE_NORMAL
- en: Speech synthesis makes it easy to broadcast important information, creating
    clear and easily understood public messages.
  prefs: []
  type: TYPE_NORMAL
- en: GPS navigation
  prefs: []
  type: TYPE_NORMAL
- en: A GPS system guides you turn by turn, reading out directions so that you can
    stay focused on the road.
  prefs: []
  type: TYPE_NORMAL
- en: Translation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we are working across cultures and languages, breaking down language barriers
    becomes essential. Sure, hiring multilingual individuals can help, but with the
    sheer number of languages and their combinations, scaling this approach quickly
    becomes a challenge. Enter *machine translation*—automated systems designed to
    bridge linguistic gaps.
  prefs: []
  type: TYPE_NORMAL
- en: Machine translation provides a scalable solution to language barriers, yet it’s
    not as simple as replacing one word with another. Words alone don’t carry the
    full weight of meaning. Tone, context, and intent have to make the jump, too.
  prefs: []
  type: TYPE_NORMAL
- en: To meet this challenge, machine translation technology needs to go beyond just
    understanding individual words. It has to grasp the full picture, considering
    factors like context, informal or formal tone, slang, and unique grammar rules.
    Only then can it provide translations that feel natural and stay true to the original
    intent.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ve probably encountered text translation in everyday tools: from translating
    a government document to clicking the Translate button on social media posts.
    Then there’s speech translation, which allows spoken language to be translated
    directly from one language to another. Whether it’s converting spoken words to
    text before translation or delivering a voice-to-voice translation, this technology
    is making real-time, cross-language conversations easier.'
  prefs: []
  type: TYPE_NORMAL
- en: Machine translation relies on advanced algorithms and neural networks. These
    networks process enormous amounts of multilingual text data to understand linguistic
    patterns, structures, and meanings across languages. By mapping out how words
    relate to one another in various languages, the system learns to create more accurate
    translations.
  prefs: []
  type: TYPE_NORMAL
- en: The beauty of machine translation lies in its continuous improvement. As these
    systems interact with users and process new language data, they refine their accuracy
    over time. This iterative learning helps AI stay up-to-date with evolving language
    trends and cultural nuances.
  prefs: []
  type: TYPE_NORMAL
- en: Conversational Language Understanding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Conversational language understanding (CLU)* makes it possible for you to
    create language models that understand and respond to everyday conversational
    phrases. Suppose you’re telling a virtual assistant, “Dim the kitchen lights.”
    With CLU, the assistant not only understands the command but also knows exactly
    which lights you mean, so you get precisely the response you’re looking for. This
    tool is particularly useful for applications that involve command and control,
    customer support, or large-scale enterprise solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To build an effective model, you’ll work with three essential elements:'
  prefs: []
  type: TYPE_NORMAL
- en: Utterances
  prefs: []
  type: TYPE_NORMAL
- en: Examples of things users might say, such as “Lower the blinds in the living
    room.”
  prefs: []
  type: TYPE_NORMAL
- en: Entities
  prefs: []
  type: TYPE_NORMAL
- en: Specific items in an utterance. In “Start the coffee maker,” “coffee maker”
    is the entity—it tells the system what to act on.
  prefs: []
  type: TYPE_NORMAL
- en: Intents
  prefs: []
  type: TYPE_NORMAL
- en: The purpose behind an utterance. For “Start the coffee maker,” the intent might
    be “PowerOn,” indicating that the user wants to turn the device on.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together, these components guide the model to recognize different
    actions. [Table 7-7](#i07_chapter7_table_7_1742068263363729) is a snapshot of
    how these might look.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7-7\. CLU elements
  prefs: []
  type: TYPE_NORMAL
- en: '| Intent | Sample utterances | Entities |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Farewell | “See you later,” “goodbye” | N/A |'
  prefs: []
  type: TYPE_TB
- en: '| PowerOn | “Turn on the heater” | Heater (device) |'
  prefs: []
  type: TYPE_TB
- en: '| PowerOff | “Shut off the TV” | TV (device) |'
  prefs: []
  type: TYPE_TB
- en: '| CheckNews | “Give me the latest news” | N/A |'
  prefs: []
  type: TYPE_TB
- en: '| None | “Why is the sky blue?” | N/A |'
  prefs: []
  type: TYPE_TB
- en: The “None” intent acts as a catchall for any input that doesn’t fit a defined
    intent, so your model can gracefully handle unexpected questions or irrelevant
    statements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Getting a CLU model to work well involves a few steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Define your schema
  prefs: []
  type: TYPE_NORMAL
- en: Think about what your model needs to know. Identify the intents for user actions
    and the specific entities you want to capture.
  prefs: []
  type: TYPE_NORMAL
- en: Label your data
  prefs: []
  type: TYPE_NORMAL
- en: Properly label each utterance with the relevant intents and entities—this step
    is crucial for accurate training.
  prefs: []
  type: TYPE_NORMAL
- en: Train your model
  prefs: []
  type: TYPE_NORMAL
- en: Your model learns from labeled examples, gradually improving its ability to
    recognize patterns and predict outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluate its performance
  prefs: []
  type: TYPE_NORMAL
- en: Test the model to see how accurately it identifies intents and entities with
    new data.
  prefs: []
  type: TYPE_NORMAL
- en: Refine and retrain
  prefs: []
  type: TYPE_NORMAL
- en: Based on your model’s test performance, you may need to adjust and retrain to
    boost accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Deploy the model
  prefs: []
  type: TYPE_NORMAL
- en: When it’s ready, deploy the model so that you can use it to interpret real-world
    user inputs via the Runtime API.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some popular ways you could use CLU:'
  prefs: []
  type: TYPE_NORMAL
- en: Enterprise bots
  prefs: []
  type: TYPE_NORMAL
- en: Within large companies, CLU-based bots can streamline tasks like finding HR
    resources, answering FAQs, or helping with scheduling by coordinating with multiple
    services.
  prefs: []
  type: TYPE_NORMAL
- en: Health care virtual assistants
  prefs: []
  type: TYPE_NORMAL
- en: A virtual assistant could assist patients with scheduling appointments, provide
    medication reminders, or even help triage symptoms. It could automate tasks for
    health care staff, such as patient check-ins or answering frequently asked questions
    about health services.
  prefs: []
  type: TYPE_NORMAL
- en: Ecommerce recommendations
  prefs: []
  type: TYPE_NORMAL
- en: In an online shopping app, CLU can help a virtual assistant understand natural
    language shopping requests like “Show me sports jackets under $100” or “I need
    a gift for a 10-year-old.” The assistant could then retrieve relevant items, making
    the shopping experience smoother.
  prefs: []
  type: TYPE_NORMAL
- en: Conversational AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Imagine this: you’re a customer, and it’s midnight. You’ve got a question about
    a product, and you want a quick answer—without waiting for a support team or diving
    into lengthy documentation. That’s where conversational AI steps in, ready to
    assist you at any hour, across multiple platforms, from web chat to social media.'
  prefs: []
  type: TYPE_NORMAL
- en: With *conversational AI*—specifically through “bots”—companies can keep up with
    customer demands for fast, personal responses. These bots are designed to answer
    questions, troubleshoot issues, and guide you, all in natural, friendly language.
    And when they’re powered by tools like Azure AI Language’s question-answering
    feature, they can go a step further. This feature allows bots to provide real-time
    answers to common questions and handle multipart conversations naturally, passing
    you to a human only if the question is more complex.
  prefs: []
  type: TYPE_NORMAL
- en: An important element behind a bot’s effectiveness is its integration with a
    relevant knowledge base filled with question-and-answer pairs. A well-informed
    bot, connected to a company’s repository of Q&A content, can respond with accurate,
    up-to-date information that reflects the latest products, services, and FAQs.
    This setup ensures that customers receive reliable answers and reduces the risk
    of customers being misled by outdated or irrelevant information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check out an example. Go to the [Azure AI Language Studio](https://oreil.ly/Sd_hv)
    and create an Azure search resource: Click “Create new” and select “Custom question
    answering.”'
  prefs: []
  type: TYPE_NORMAL
- en: You will then go through a series of screens for the configuration. First is
    “Choose language setting.” Here, select English and click Next. You’ll be taken
    to the “Enter basic information” section. Enter a name for the project and a description,
    then select “No answer found” for the default when the AI cannot find an answer
    to a user question. Press Next and then select “Create Project.”
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 7-5](#i07_chapter7_figure_5_1742068263357735) shows the dashboard.'
  prefs: []
  type: TYPE_NORMAL
- en: On the top left of the screen, click “Add source,” and you’ll see some menu
    options. This is where you can add a knowledge base, whether through a URL or
    file. We’ll select the option for URL and use this [one](https://oreil.ly/vd6nx).
    This is Microsoft Azure’s FAQ for conversational language understanding (you can
    also add more than one URL). Click the customized URL, and you’ll see the screen
    in [Figure 7-6](#i07_chapter7_figure_6_1742068263357756).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aaif_0705.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-5\. The dashboard for creating a conversational AI system for a knowledge
    base
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![](assets/aaif_0706.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-6\. The screen for the knowledge base that Azure AI created
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'On the left side of the screen, you can see how Azure AI Language has parsed
    the FAQ into question-answer pairs. If you click one of them, you get different
    options to customize a question:'
  prefs: []
  type: TYPE_NORMAL
- en: Edit the answer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Add alternate phrasings for questions when there are multiple ways users might
    ask the same thing. These alternate questions should be as different as possible
    in wording while keeping the meaning intact, and the list should be limited to
    a maximum of 10 variations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incorporate follow-up prompts to link question-and-answer pairs in multiturn
    conversations. This linkage allows the client application to deliver a primary
    answer while offering additional questions for the user to choose from if needed.
    To see all the connections for a specific question-and-answer pair, select “view
    context tree.”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Assign metadata tags to help the client application refine the results of a
    user query. For instance, a question like “What are the store hours?” might yield
    different responses depending on the specific store location—such as if the metadata
    is “Location: New York” versus “Location: Los Angeles.” By using metadata tags,
    the application can deliver answers tailored to the user’s specific needs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can test this by clicking the flask icon on the top left of the screen.
    [Figure 7-7](#i07_chapter7_figure_7_1742068263357777) shows the chatbot for this.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aaif_0707.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-7\. The chatbot that tests a knowledge base AI system
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, I asked, “Is there any SDK support?” And I got the correct answer,
    with clickable links.
  prefs: []
  type: TYPE_NORMAL
- en: If you click Inspect, you will get an analysis for how the AI came up with the
    answer. There will also be a ​confidence score.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve explored key topics like NLP, tokenization, frequency analysis, and other
    foundational concepts that form the backbone of AI understanding. Each of these
    areas is essential not only for understanding how AI works but also for navigating
    the specific questions you’ll encounter on the AI-900 exam.
  prefs: []
  type: TYPE_NORMAL
- en: Quiz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To check your answers, please refer to the [“Chapter 7 Answer Key”](app02.html#answers_chapter_7_sample_questions_1745932457451921).
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following Azure AI Services enables instant translation of text
    into multiple languages?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Azure AI Language
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Azure AI Speech
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Azure AI Translator
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Azure AI Sentiment
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the primary function of named entity recognition (NER) in NLP?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To analyze sentiment
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To detect language
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To identify and categorize entities
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To extract key phrases
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which feature of Azure AI Speech allows for real-time transcription of live
    audio?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Text-to-speech
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Summarization
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Real-time speech-to-text
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Custom Translator
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is tokenization in the context of NLP?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assigning a unique identifier to each entity
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Converting text to speech
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Breaking text into individual words or phrases
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Detecting language in text
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following best describes Azure’s key phrase extraction feature?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It categorizes entities in text.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It highlights main concepts or themes.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It detects the language of a document.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It analyzes sentiment in text.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which NLP feature in Azure would be most suitable for identifying sensitive
    information like Social Security numbers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Language detection
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Key phrase extraction
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: PII detection
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which term refers to removing common words that don’t add meaning, like *the*
    and *an*, during NLP processing?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lemmatization
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Stop-word removal
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Tokenization
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Frequency analysis
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In the Azure AI Language Studio, which feature would you use to automatically
    link an entity like “Paris” to a specific reference?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Entity recognition
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Entity linking
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Language detection
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Summarization
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the purpose of the Fast Transcription API in Azure AI Speech?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To translate text
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To provide quick, synchronous transcription of audio
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To detect sentiment in audio
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To convert text to lifelike speech
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which Azure feature can be used to summarize large volumes of text by extracting
    key sentences?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Text-to-speech
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Summarization
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Language detection
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Entity recognition
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
