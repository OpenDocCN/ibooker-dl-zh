# 第十章. 自主后台编码代理

*自主后台编码代理*正迅速成为 AI 编码工具的下一阶段进化。与在键入时建议代码的熟悉“领航员”助手不同，这些代理更像是可以异步处理整个任务的背景初级开发者。代码在为代理启动的隔离环境中生成，可以运行测试，结果通常以一个完整的拉取请求的形式返回供你审查。

在本节中，我将探讨后台编码代理是什么，它们是如何工作的，当前工具的格局（OpenAI Codex、Google Jules、Cursor、Devin 等），以及它们与传统 IDE 助手相比如何。我还会检查它们的性能、局限性和它们对未来软件工程预示的实用变化。

# 从领航员到自主代理：后台编码代理是什么？

传统的 AI 编码助手（如 Cursor、GitHub Copilot 或 VSCode 扩展 Cline）是*监督编码代理*——响应开发者提示或内联上下文的交互式助手。它们本质上是在聊天或写作时生成建议的自动完成功能，但人类开发者是每个步骤的驾驶员。

相比之下，自主后台编码代理具有更大的独立性。你给他们一个高级任务或目标，然后“派他们去”独立解决问题，而不需要持续的监督。这些代理将阅读和修改你的代码库，制定计划，执行代码（甚至运行测试或命令），并产生结果（通常是提交或拉取请求）——所有这些都在异步工作流程中完成。

想象一下领航员和自动驾驶之间的区别：你的领航员（就像 GitHub Copilot 一样）始终在你旁边的驾驶舱内，等待你的指令；而自动驾驶（后台代理）可以在一段时间内独立驾驶飞机。这种自主性意味着后台代理可以在你专注于其他事情的同时处理多步骤编码任务。使用像 Codex 和 Jules 这样的异步代理就像扩展你的认知带宽：你可以将任务发送给 AI，然后直到它完成都可以不去管它。与 AI 的单线程来回互动相比，你突然拥有了多线程的工作流程：代理与你并行工作，就像一个有能力的初级开发者一样在后台工作。

关键的是，后台代理在隔离的开发环境中（通常是云虚拟机或容器）而不是直接在你的编辑器中运行。它们通常将你的仓库克隆到沙盒中，安装依赖项，并拥有构建和测试项目所需的工具。出于安全考虑，这些沙盒受到限制（例如，“除非明确允许，否则不允许互联网访问”）并且是瞬时的。代理可以运行编译器、测试、linters 等，而不会对你的本地机器造成任何风险。当任务完成时，代理输出代码更改（差异）和它所做的工作摘要。通常这会以拉取请求的形式出现（包含代码差异、提交信息，有时还有解释），然后你可以审查并合并。

总结来说，一个后台编码代理是一个由 AI 驱动的自主编码器，它理解你的意图，通过阅读和编写代码以及测试，在一个沙盒环境中完成整个任务，然后为你提供可审查的结果。它不仅仅是建议一两条代码——它可以处理更大范围的任务：

+   在代码库中编写新的功能 X。

+   对模块 Y 进行重构以提高效率。

+   升级此项目的依赖项。

这是我们可能将 AI 融入开发工作流程的重大转变，从辅助建议转向委托*实际实施工作*。

# 自主编码代理是如何工作的？

在幕后，大多数后台代理遵循类似的操作模式：*计划、执行、验证、报告*。让我们来了解一下这些步骤及其功能。

## 计划

当你给代理一个任务（通常是通过一个提示或命令来描述你想要什么），代理首先解析请求并制定攻击计划。一些代理在开始编码之前会明确地展示这个计划。例如，[Google 的 Jules](https://oreil.ly/jxDhZ)提供了一个执行计划，你可以在它开始编码之前审查和调整，这“防止了担心代理是否正确理解了你的请求”的焦虑。一个好的代理会将任务分解成子步骤：

> 第 1 步：在代码库中搜索相关部分；第 2 步：在文件 A、B、C 中进行更改；第 3 步：运行测试；第 4 步：提交更改。

这个规划阶段是有效自主性的关键：这是 AI 在深入之前思考*如何*实现你的目标的方式。

代理为任务启动了一个专用开发环境。例如，Jules 会将你的代码库“克隆到安全的 Google Cloud VM”中，并在那里异步工作。OpenAI 的 Codex 同样在每个自己的云沙盒中运行每个任务，预先加载了你的存储库。Cursor 等工具的后台代理使用具有互联网访问权限的远程基于 Ubuntu 的机器来安装包，可以通过 Docker 或快照进行自定义。确保环境具有所有必需的依赖项（如正确的语言运行时和构建工具）既关键又复杂。正如我在之前的分析中提到的，“为代理启动一个平滑的环境以运行所需的环境是关键……而配置它的用户体验可能和 CI 管道一样令人沮丧，甚至更糟。”尽管如此，代理通过允许配置文件指定设置步骤来解决这个问题。目标是创建一个*云中的开发环境*，它反映了人类开发者成功运行项目代码和测试所需的一切。

显然，许多代理在设置后禁用了其代码的互联网访问，这样他们就可以在不允许数据泄露或不受限制的互联网调用的情况下进行沙盒运行。一些代理允许为特定需求进行受控的互联网使用：例如，OpenAI 最近为像获取包更新或文档这样的 Codex 任务启用了可选的互联网访问。

## 执行

接下来是重头戏：代理开始根据计划编写和修改代码。凭借针对编码进行了微调的大型语言模型（或模型混合），它可以读取多个文件，生成新代码，如果需要，甚至可以创建新文件。这就是代理本质上像程序员一样行动的地方：定位应该进行更改的位置，编辑代码，并插入新的逻辑。

从早期运行中一个有趣的观察是，代理通常使用暴力文本搜索（如 Unix `grep`命令）来找到代码库中的相关部分。例如，一个代理可能会搜索函数名或关键字，以确定在存储库中的哪个位置进行更改。这似乎非常简单——他们不应该使用复杂的语义代码搜索或基于 AST 的分析吗？然而，它既有效又可靠。正如[Birgitta Böckeler 指出](https://oreil.ly/wDSkr)，许多编码代理默认使用简单的全文搜索，可能发现这是最广泛有效的方法，尽管存在更先进的技术。

当代理编辑代码时，一些系统提供实时日志或状态更新，以便如果你想的话可以跟踪。OpenAI Codex 在处理任务时暴露了代理的“思考”和命令（总结）日志。Cursor 允许你“查看其状态并进入代理正在运行的机器”以观察或甚至在任务中途干预。然而，在实践中，这个想法是你不需要照看——你可以让代理自动运行。

## 验证

这些代理的一个定义性能力是它们不仅仅编写代码——它们经常编译代码并*运行测试以验证*它们的更改。例如，OpenAI 的 Codex 被设计成迭代运行测试，直到收到通过的结果。如果一个代理能够运行项目的测试套件（或者至少是相关测试的子集），它就可以捕捉错误并在后续迭代中自动纠正它们。这是巨大的进步：它将 AI 从仅仅*生成*代码转变为同时*调试*和*验证*其代码。

理论上，一个具有强大测试框架的代理可以尝试修复问题，看到测试失败，调整代码，并循环直到测试通过——无需人类介入。实际上，环境问题有时会阻碍这一点。在我研究的一个案例中，由于环境不匹配（某些工具缺失），Codex 无法运行完整的测试套件，导致 PR 中仍有两个失败的测试。如果环境完全一致，代理可以在创建 PR 之前修复这些微不足道的问题。

这强调了为什么环境设置对自主代理如此重要：如果它们能够运行开发者会运行的所有内容（linters、测试、构建），它们就可以自动纠正许多错误。像 Devin 这样的代理强调这个循环——Devin“编写代码，在代码中找到错误，纠正代码，并运行其自身的端到端测试以验证其工作”，这是其正常操作的一部分。事实上，Devin 甚至可以启动它构建的前端应用的实时预览部署，这样你就可以在浏览器中手动验证一个功能，这是验证步骤的巧妙扩展。

## 报告

一旦代理有一个候选解决方案（所有测试都通过，或者它认为代码已准备好），它就会为你准备结果。根据平台的不同，这可能是一个 GitHub 上的 PR，聊天中的差异和解释，或者准备好合并的文件。

在这个阶段，你——人类——进行审查。这里我们回到了“信任但核实”：你信任代理生成有用的东西，但通过代码审查和额外的测试来核实这些变化。许多代理系统明确地与 PR 审查流程集成，因为这对开发者来说是一个熟悉的流程。例如，Jules 可以连接到你的 GitHub，并为其更改打开一个分支和 PR。OpenAI 的 Codex 在 ChatGPT 内展示差异和解释，供你批准或提出后续问题。如果你发现问题或有更改请求，你通常可以将这些反馈给代理进行另一轮迭代。

一些代理通过聊天处理这个问题（Devin 可以从链接的 Slack 线路中获取反馈：如果你指出问题或请求调整，它将“开始回复”以解决问题）。其他代理可能需要一个新的运行，使用调整后的提示或使用审查评论界面。令人印象深刻的是，Devin 甚至对 GitHub PR 评论中询问**为什么**它做出了某些更改做出了回应——它用一个“眼睛”表情符号来表示它看到了评论，然后发布了一个详细的解释来说明其推理。（在这种情况下，解释并不完全正确，但它能够讨论 PR 的事实表明这些代理可以变得多么交互式。）

如果一切看起来都很好，你可以合并代理的 PR 或集成更改。如果不满意，你可能丢弃它或让代理再次尝试。团队面临的一个实用问题是，如果代理的输出**几乎**是好的但并不完全如此，该怎么办。你会花时间修复代理生成的补丁的最后 10%–20%，即使它是一个你分配给 AI 的低优先级任务吗？这就是我所说的 AI 贡献的“沉没成本”困境。[Birgitta Böckeler](https://oreil.ly/IdJ9d) 思考，如果一个代理 PR 只部分成功，团队将不得不决定“在哪些情况下他们会丢弃拉取请求，在哪些情况下他们会投入时间将其完成最后的 20%”对于原本不值得太多开发时间的任务。没有统一的答案——这取决于上下文和更改的价值——但这是由自主代理引入的一种新的权衡。

总结来说，背景编码代理处理编码任务的端到端周期：**理解 → 规划 → 编码 → 测试 → 交付**。它们本质上模拟了一个勤奋、有条理的开发者在被分配任务时可能做的事情，尽管是在当前人工智能的限制范围内（见图 10-1）。

![](img/bevc_1001.png)

###### 图 10-1\. 自主人工智能代理工作流程：自我指导的代理规划任务、执行解决方案、验证结果，并在最小化人工干预的情况下报告结果。

# 背景代理与 IDE 内部人工智能助手相比如何？

值得明确区分我们拥有了几年的编码人工智能工具（如 GitHub Copilot、ChatGPT 编码模式等）和这一代新的自主代理。两者都很有用，但它们扮演不同的角色，具有不同的优势和劣势。

最明显的区别是它们的**自主程度**。像 Copilot 或 VSCode 的 AI 扩展这样的 IDE 内部助手与你**同步**工作——当你调用它们时，它们会生成建议或回答问题，它们的范围通常限于当前上下文（如你正在编辑的文件或函数，或你给出的特定提示）。**你**决定何时接受建议、请求另一个或应用更改。

在后台代理中，一旦你启动了一个任务，代理将自主执行可能数百个动作（文件编辑、运行、搜索）而无需进一步确认。它正在*异步*操作。这需要更高的信任度（你让它自主更改东西），但同时也让你免于微观管理。我经常将其描述为拥有一个 AI *配对程序员*与一个 AI *助理开发者*在团队中的区别。配对程序员（Copilot）与你一起逐个按键；助理开发者（Codex/Jules 等）在另一个问题上并行工作。

AI 工具的副驾驶风格意味着它们擅长微任务——编写一个函数、完成一行、生成一小段代码、回答有关如何使用 API 的问题。它们不会维护长篇叙事或项目级理解，除非是在你的编辑器中打开的文件或有限的窗口内。

自主代理在*项目级别*上操作。它们加载你的整个仓库（或至少索引它），并可以在多个模块之间进行协调更改。它们跟踪多步骤计划。例如，GitHub Copilot 可能会在你提示的情况下帮助你编写单元测试，但后台代理可以独立决定在一个文件中添加相应的实现，在另一个文件中添加测试，在第三个文件中修改配置——所有这些都是作为一个统一任务的一部分。这使得代理非常适合像重构跨切面关注点（日志记录、错误处理）、执行升级（通常涉及许多文件）或实现影响后端和前端的特性等任务。IDE 助手难以处理这些任务，因为它们缺乏长期任务记忆和整个仓库的可见性。

Copilot 风格的助手是*反应性*的——它们对你的代码或查询做出响应。它们不会主动采取行动。后台代理是*主动性*的，一旦激活，它们将主动采取行动以达到目标。Jules 或 Devin 代理可能会决定，“我需要在这里创建一个新文件”或“让我现在运行测试”，而不需要在每个步骤都明确告知。它们还可以*主动通知你一些事情*，比如：

> 我发现另一个地方可以应用这个更改，所以我也会包括它。

它们的行为更像是一名员工，可能会说：“我在代码中注意到 X，所以我也把它修复了。”尽管如此，自主性也意味着它们可能会做你预料不到或不一定想要的事情。这种工具风格的监督性质意味着它只会做你接受的事情（也许除了你没有注意到的细微建议）。因此，强大的力量（主动性）需要更大的监管。

一个主要区别是，后台代理可以*执行代码和命令*，而传统的 IDE 助手通常不能（除非你把 ChatGPT 的代码解释器模式算在内，但那更多是用于数据分析，而不是与你的项目构建集成）。

代理将运行您的测试套件，启动开发服务器，编译应用程序，甚至可能部署它。它们在沙盒中运行，但实质上就像有一个能够使用终端的自动化开发者。这是一个颠覆性的变化——它关闭了验证/修复的循环。IDE 助手可能会生成看似合理的代码，但如果它没有实际运行，可能会出现运行时问题或失败的测试。

使用运行代码的代理，您更有可能得到真正功能性的输出。它还卸载了调试步骤；如果出现问题，代理可以立即尝试修复。另一方面，这要求代理的环境必须正确（如前所述），并且可能带来潜在的副作用。想象一下，一个代理正在运行数据库迁移或修改数据——通常它们处于沙盒模式，所以这不会影响生产环境，但请小心。

GitHub Copilot 和类似工具位于编辑器中，这对于流程中的编码来说很棒。代理通常也与项目管理工具和 DevOps 工具集成。例如，您可能创建一个 GitHub 问题，让代理接管并生成一个 PR，或者从 CI 管道触发代理运行某些任务（如自动修复 PR 上的 lint 错误）。实际上，CodeGen 宣传其代理能够附加到问题跟踪器，以便当问题移动到“进行中”时，AI 代理开始处理它。这种集成超出了 IDE 工具的范围。这暗示 AI 代理可能成为 CI/CD 循环的一部分——例如，自动尝试修复构建失败或自动为小问题创建后续 PR。这是一种不同的协作模式：不仅帮助开发者编写代码，还作为团队工具链中的机器人用户。

使用类似 Copilot 的助手通常仍然感觉像是在编程，只是更快——你输入，它们建议，你接受，你测试。使用后台代理感觉更像是一种委托后的审查。人力从编写代码转移到编写良好的任务描述，然后审查生成的代码。我称之为“生成者与审查者不对称”——从头开始生成解决方案（或代码）很困难，但审查和改进它更容易。异步代理利用这一点：它们处理大量生成，而您则负责（通常是更快地）审查和调整。这可能是一种生产力上的恩赐，但也意味着作为工程师，您需要提高您的代码审查和验证技能。

代码审查始终很重要，但现在它不仅是为了其他人类同事的代码，也是为了 AI 生成的代码，这些代码可能存在不同的错误模式。我的座右铭是，您应该将代理生成的代码视为由一个略微过于热情的初级开发者编写的：假设有良好的意图和一定的能力，但验证一切，并且不要犹豫要求更改或拒绝不符合标准的情况。

在实践中，我发现我通常会将类似 Copilot 风格的工具和后台代理**一起**使用。例如，在我积极编码一个复杂的逻辑片段时，我可能会使用 Copilot 或 Cursor 的行内建议，因为我希望对这个逻辑有紧密的控制。同时，我可能会将一个边缘但耗时的工作（比如更新所有我们的 API 客户端库以支持新的端点）委托给后台代理并行处理。它们填补了不同的细分市场。一个不一定取代另一个。事实上，我预见 IDE 将提供统一的经验：从“完成此行”到“生成函数”再到“嘿，AI，请为我实现整个工单。”你可以根据范围选择工具。

# 结合多个 AI 模型以最大化优势

到目前为止，我经常将“AI”作为一个单一的、统一的助手来提及。实际上，有许多 AI 模型，每个都有不同的优势。有些在自然语言理解方面很出色，有些在生成代码方面表现出色，而有些可能专注于特定领域（如数学问题求解器或 UI 生成器）。高级的 Vibe 编码实践者可以一起协调多个 AI，利用每个 AI 最擅长的地方。这就像拥有一支专家团队而不是一个单一的全能者。

考虑一个未来的工作流程，其中你将拥有：

+   一个高度训练于编程的 CodeGen AI，能够高效地生成和修复代码

+   一个专注于生成测试用例和发现边缘情况的 TestGen AI

+   一个编写清晰文档和解释的 Doc AI

+   一个擅长生成 UI 布局或图形的 Design AI

+   一个专注于性能调优甚至可能了解底层细节的优化 AI

你可以将任务通过这些 AI 中的几个。例如，你可以要求 CodeGen AI 编写实现代码。立即，你将输出结果提供给 TestGen AI 以生成测试（或对其提出批评）。然后将代码和测试提供给 Doc AI 以生成文档或使用指南。如果代码涉及用户界面，也许 Design AI 会先提出布局结构，然后由 CodeGen AI 实现。通过串联它们，你可以利用每个模型的领域专业知识。这类似于软件流水线或装配线，但不同的是，这里不是不同的人类角色，而是不同的 AI 角色。

即使在类似模型之间，结合它们可以提高可靠性。如果你有两个来自不同提供商或不同架构的代码生成模型，你可以让它们都尝试解决方案，然后比较或测试两个输出。如果一个模型的输出通过了所有测试，而另一个没有，你选择通过的那个。如果两个都通过了，但方法不同，你可能手动选择更易读的那个。如果一个失败了，你甚至可以向失败的模型展示成功的代码作为学习的提示。这种 AI 交叉对话可以减少错误，因为两个不同的模型犯完全相同的错误的可能性较小。这就像得到第二个意见。你现在已经可以找到使用一个 AI 检查另一个推理的研究和工具——例如，一个生成答案，另一个对其进行评判。

## 根据任务类型区分模型

使用适合的工具。大型语言模型（LLMs）是好的通用主义者，但有时较小的、专业的模型或工具表现更好。例如，对于算术或某些算法，一个确定性工具（或更受约束的 AI）可能更好。一些高级开发设置使用符号求解器或较老的基于规则的 AI 来完成特定子任务，而使用 LLMs 来完成其他任务。作为一个高级的 vibe 程序员，你可能会维护一个工具箱：当你需要正则表达式时，你调用一个正则表达式特定的生成器；当你需要提交信息时，可能使用一个针对摘要微调的模型。美的是这些可以通过简单的脚本或提示包装器进行集成。例如，你可以有一个本地的脚本`ai_regex_generator`，它内部提示 AI，但有一些预处理和后处理以确保输出是有效的正则表达式，并且可能在提供的示例上对其进行测试。

## 使用编排系统

如果你发现自己经常结合模型，你可能需要使用或构建一个编排系统，这是一个被称为*AI 编排*或*代理*的新兴框架类别。这些系统允许你定义一个流程；例如：

> 第 1 步：使用模型 A 来解释用户请求。
> 
> 第 2 步：如果请求是关于数据分析，使用模型 B 生成 SQL；如果是关于文本，使用模型 C...
> 
> 第 3 步：将结果输入模型 D 进行解释。

如果你正在构建由多个 AI 步骤驱动的应用程序或服务，这会更相关。但即使在个人开发中，你也可以编写一个多步骤的方法。例如，一个定制的 CLI 工具`ai_dev_assist`接受一个提示，并在幕后使用 AI 将提示分类到`代码`、`设计`、`测试`和`优化`等类别。根据类别，它将提示转发到适当的专家 AI。当它收到结果时，它可以选择将结果管道输入另一个 AI 进行审查或改进。

这种协调其他 AI 的元-AI 听起来很复杂，但高级用户可以利用现有技术来设置它。随着我们开始看到 IDE 或云平台上的专用支持，它可能会变得更简单。

## 人类-人工智能混合团队

在讨论多种智能的同时，我们不要忘记*人类*协作者。一个高级的 vibe 编码者也知道何时将其他人类开发者纳入循环。例如，你可能会使用 AI 生成两个或三个不同的设计原型，然后将其带给你的团队的用户体验设计师进行反馈。哪一个与我们的品牌相符？哪一个感觉直观？如果一个 AI 编写了一块复杂的代码，你可能会与同事进行代码审查会议，专注于这一部分，承认“AI 帮助编写了这个，所以我想要另一双人类的眼睛来看它。”在某种程度上，“多模型”方法可以包括人类作为高度先进模型——每个实体（人类或 AI）都有独特的优势。开发的未来可能经常是人与 AI 的配对编程，甚至是团队编程，其中一些“团队成员”是 AI。

想象一下通过 vibe 编码构建一个小型 Web 应用程序。你的工作流程可能看起来像这样：

1.  你使用 UI 布局 AI 根据描述生成你页面的 HTML/CSS（专注于前端）。

1.  你可以使用内容 AI 生成所需的占位文本或图像（例如营销文本，可能使用针对文案写作的模型）。

1.  然后，你使用主要的代码 AI 在 JavaScript 中生成交互功能，给它 HTML，这样它就知道要连接到哪些元素 ID。

1.  然后，你要求一个测试 AI 为界面交互生成 Selenium 或 Playwright 测试。

1.  最后，你使用安全 AI 扫描代码中的常见漏洞。这可能是一个模型，或者是一个简单的静态分析工具，它通过 AI 增强。

这种多模型方法涵盖了一个集成流程中的前端、后端（如果有的话）、内容、测试和安全。每个 AI 处理其部分，而你作为协调者，确保它们都保持一致。

虽然今天你可能需要手动将一个工具的输出复制到另一个工具，或者使用一些粘合脚本，但明天的集成开发环境（IDE）可能会让你配置这个管道，使其感觉无缝。关键点是：*如果你可以访问多个 AI 模型，不要只依赖一个 AI 模型*。为每个任务使用最好的模型，并使它们协同工作。这会导致更好的结果，同时也减少了单点故障——如果一个模型在某方面做得不好，另一个模型可能会弥补这个弱点。

结合 AI 模型是一个高级动作，但它是对专业化的逻辑扩展，这是软件工程中众所周知的原则（想想微服务，每个服务都擅长做一件事）。在这里，每个 AI 服务都擅长做一件事。作为一个 vibe 编码者，你的角色扩展到 AI 指挥家，而不仅仅是 AI 提示者。这需要更多的设置和思考，但回报是 AI 协作者的交响乐，每个协作者都对高质量的产品做出了贡献。

现在你已经知道了它们是如何工作的，让我们来认识一些领先的例子，看看它们是如何排列的。

# 自动化编码代理的主要参与者

当我在 2025 年写下这些内容时，自主编码代理领域在过去一年中迅速发展，不同平台出现了不同的方法。这些工具代表了从被动完成代码到作为主动开发伙伴的转变，这些伙伴可以独立执行复杂任务。

云命令行代理：OpenAI Codex

[OpenAI 的 Codex](https://oreil.ly/Ml-NU)是云代理方法的典范，通过 ChatGPT 的界面或开源 CLI 操作。它启动隔离的沙盒以并行执行编码任务，处理从 React 升级到单元测试创建的一切。Codex 的独特之处在于其在真实编码任务上的强化学习训练，使其能够遵循最佳实践，如迭代运行测试直到通过。虽然运行结果可能会有所不同，但 Codex 通常会在有良好界限的任务上收敛到有效解决方案。它的优势在于在类似 CI 的环境中进行实际代码执行，代表了真正与开发管道“配对”的第一波代理。

工作流程集成代理：Google Jules

[Google Jules](https://jules.google)通过深度集成 GitHub 工作流程采取了不同的方法。在 Google Cloud VM 上运行，具有完整的仓库克隆，Jules 强调可见的、结构化的规划——在执行前展示其推理并允许修改计划。这种“先计划后执行”的哲学，结合实时反馈能力，将 Jules 定位为监督助手而不是黑盒自动化。其 GitHub 原生设计意味着它直接在团队工作的地方运行，创建分支和 PR 而无需切换上下文。代理甚至尝试了新颖的功能，如音频变更日志，指向更易于访问的代码审查流程。

IDE 集成代理：Cursor

[Cursor 的背景代理](https://oreil.ly/V-Pci)代表了以 IDE 为中心的方法，直接从编辑器启动但在远程机器上执行。这种混合模型允许开发者从他们的指挥中心编排多个 AI 工作者，同时保持本地控制。Cursor 为 Ubuntu 实例提供可定制的环境（通过*environment.json*或 Dockerfiles），为代理提供完整的互联网访问和包安装能力。关键创新是无缝的 IDE 集成：开发者可以监控代理进度，在需要时进行干预，并在完成后立即访问本地更改。这种方法模糊了本地 AI 辅助和云执行能力之间的界限。

团队集成代理：Devin

[Devin](https://devin.ai)将自己定位为“AI 队友”而非仅仅是工具，与 Slack、GitHub 和 Jira 等问题跟踪器集成。由 Cognition Labs 构建，它使用针对长期推理和多步执行定制的 AI 模型。Devin 擅长并行执行小型维护任务，如错误修复、测试添加和代码检查清理，这些任务通常会被降级。其协作设计包括状态更新、澄清请求，甚至自动预览部署。虽然它处理简单任务很好，但复杂问题仍然可能需要显著的人工干预，突显了自主编码的当前边界。

该领域正在迅速扩张，既有老牌玩家也有初创公司竞相定义这一类别。微软暗示了“Copilot++”，超越了内联建议，转向代理功能。企业正受到像 CodeGen（使用 Anthropic 的 Claude）这样的初创公司的追捧，承诺“永不休息的 SWEs”。同时，开源项目和学术研究继续推动边界，探索如何使代码生成更可靠和更具上下文。

这种激增表明，我们正在见证一个新开发范式的诞生，其中个人开发者协调多个 AI 代理，每个代理针对软件生命周期的不同方面进行专门化。正在出现的关键区别是：

+   执行环境（本地与云）

+   集成深度（集成开发环境与工作流程工具）

+   自主程度（监督与独立）

+   目标用例（维护与功能开发）

# 挑战与局限性

尽管自主编码代理继承了本书中讨论的人工辅助开发的根本挑战——特别是第三章中探讨的 70%问题——但它们的自主性质引入了独特的复杂性，需要单独审查：

连续决策的复合效应

与每个步骤都由人类干预的交互式 AI 辅助不同，自主代理会做出一系列决策，这些决策可以以独特的方式累积错误。当一个代理误解了初始要求时，它不仅仅生成一个有缺陷的功能：它基于这种误解构建了一个*整个实现架构*。每个后续决策都会加强原始错误，形成我所说的“连贯的错误”：代码在内部是一致的，但与实际需求根本不匹配。

这种顺序决策特别挑战处理多文件更改的代理。一个实现新功能的代理可能正确地修改了后端 API，但随后通过前端、数据库模式和测试套件传播了错误假设。到你审查完整的 pull request 时，解开这些相互关联的错误通常需要比传统 AI 辅助可能的交互式、增量更正更多的努力。

规模化环境脆弱性

虽然第八章讨论了一般的环境配置挑战，但自主代理由于它们的沙盒执行模型而面临独特的复杂情况。每次代理运行都需要启动一个与你的开发设置*精确*匹配的隔离环境——这是一个扩展性不佳的挑战。当你同时运行多个代理时，即使是环境中的微小变化也可能导致截然不同的结果。

考虑一个场景，其中五个代理同时处理不同的功能。代理 A 可能在它的容器中有一个稍微旧一点的 Node 版本，代理 B 可能缺少特定的系统库，而代理 C 可能有不同的时区设置。这些在执行期间不可见的差异，在开始整合他们的工作时，会以微妙的错误形式出现，这些错误只有在开始整合他们的工作时才会显现。代理沙盒之间的这种“环境漂移”代表了一种新的集成挑战类型，这种挑战在单一开发者工作流程中是不存在的。

异步协调悖论

自主代理承诺并行开发，但这引入了与人类团队动态截然不同的协调挑战。当多个代理修改重叠的代码部分时，它们缺乏人类使用的隐含沟通渠道——没有快速的信息请求“你正在修改认证模块吗？”或者对同事正在做什么的非正式了解。

这就形成了我所说的*异步协调悖论*：你运行的代理越多以增加生产力，整合它们就越复杂。与自然通过站立会议和非正式沟通进行协调的人类开发者不同，代理在隔离状态下操作。你可能会发现代理 A 重构了一个实用函数，而代理 B 正忙于向旧版本添加新调用，从而产生了如果代理有人类开发者对彼此工作的自然意识就不会发生的冲突。

审查瓶颈——放大

虽然代码审查对于所有 AI 生成的代码仍然是必不可少的（如前几章所述），但自主代理通过数量和时机放大了这一挑战。与交互式 AI 辅助不同，代码是在你工作时逐步到达的，而代理生成的 PRs 则表现为完整的实现——通常是在夜间运行后同时到达的多个 PR。

这创造了一种与审查人类 PR 时得到的认知过载不同的情况。对于人类贡献，你通常可以依赖提交信息和 PR 描述来反映开发者的实际思维过程。然而，代理 PR 要求你从代码本身逆向工程代理的“推理”。当五个代理在周一早上各自提交 500 行或更多的 PR 时，审查负担从协作质量检查转变为更像是考古探险。

将任务委托给代理需要信任

可能最重要的是，自主代理以交互式 AI 工具不同的方式挑战了我们的信任模型。当你将任务委托给代理并离开时，你是在对可接受的风险进行隐含的赌注。这与监督式 AI 辅助截然不同，在监督式 AI 辅助中，你保持对每一刻的控制。

考虑代理技术的安全影响。具有存储库写入访问权限和执行能力的自主代理提供了独特的攻击面。一个被破坏或误导的代理不仅会*建议*不良代码，它还会积极*提交*并可能甚至*部署*它。我们为代理的沙箱化和访问控制必须比基于建议的工具（在第八章中介绍）更为复杂。

新兴的组织挑战

随着团队扩大代理的使用规模，新的组织模式正在出现，这些模式在传统的 AI 辅助中并不存在。当请求代码的开发者因病缺席时，“拥有”代理生成的代码的是谁？如何跟踪团队间的代理资源使用情况？当代理的为期一个月的重构项目与紧急功能开发冲突时会发生什么？

这些不是技术限制，而是组织挑战，并且它们是自主系统的独特挑战。它们需要新的角色（代理协调员？）、新的流程（代理影响评估？）和新的工具（代理机群管理？），这些工具超越了本书早期章节中讨论的个体开发者考虑因素。

这些代理的自主性——它们独立工作、做出顺序决策和大规模操作的能力——将它们从生产力工具转变为接近团队成员的东西。这种转变不仅需要本书中讨论的技术实践，还需要全新的协调、信任和集成框架，而我们才刚刚开始理解这些框架。

# 有效使用 AI 编码代理的最佳实践

虽然许多通用 AI 开发实践适用于自主编码代理，但基于代理的开发需要特别考虑某些方面。基于对 Codex、Jules、Devin 和 Cursor 的背景代理等工具的集体经验，这些实践解决了将整个开发任务委托给独立运行的 AI 系统所面临的独特挑战。

## 策略性地选择自主代理将要实施的任务

人工智能助手和自主代理之间的基本区别在于它们的范围和独立性。代理擅长定义明确、封装的任务，具有清晰的成功标准——尤其是涉及许多小任务并行执行的任务。理想的代理任务分配包括全面的测试覆盖率改进、系统性的依赖项更新、批量重构操作以及跨多个组件的标准化功能实现。

考虑一下，要求人工智能助手帮助编写单个测试与指派代理在整个模块中实现 80%测试覆盖率之间的区别。代理可以系统地处理每个未测试的功能，生成适当的测试用例，运行它们以验证正确性，并迭代直到达到覆盖率目标。这种系统性和可衡量的工作是自主代理的理想领域。

相反，那些需要做出重大架构决策、解释复杂利益相关者需求或设计新颖算法的任务，更适合由人类主导的开发，并辅以人工智能。关键在于识别更大任务中哪些方面可以有效地委托给代理，哪些方面需要人类的判断和创造力。

## 利用代理特定的规划和监督功能

现代自主代理通过复杂的规划和执行透明度功能脱颖而出，这些功能需要积极的参与。当 Jules 在开始工作之前展示其执行计划，或者当 Cursor 显示代理活动的实时日志时，这些代表了对基于代理的开发独特的关键干预点。

*规划阶段*是您的主要质量关卡。不仅要审查提出的计划是否正确，还要审查其效率和与代码库约定的契合度。如果 Jules 计划更新 Next.js 应用程序但遗漏了关键的 webpack 配置更改，那么在规划阶段发现这些问题可以防止后续进行大量的返工。这种主动审查与被动代码审查有根本性的区别，代表了开发者工具包中的新技能。

*运行时监控*提供了另一层针对代理的特定监督。虽然您不需要监视每个操作，但定期的检查可以防止代理追求低效的解决方案或做出不必要的广泛更改。Cursor 能够“进入”代理的环境进行中任务，这展示了现代工具如何在不完全放弃自主工作流程的情况下支持干预。为了最大化效率，您需要学会何时干预，何时让代理自行纠正。

## 管理并发代理操作

与传统的开发不同，在传统开发中，单个开发者一次只处理一个任务，代理使真正的并行开发成为可能。这种能力需要新的协调策略。当同时运行多个代理时——可能一个在更新依赖项，另一个在添加日志基础设施——你必须考虑它们工作之间的潜在冲突和依赖关系。

为每个代理的范围设定清晰的边界，以最大限度地减少合并冲突。在可能的情况下，将代理分配到不同的模块或应用的不同层。考虑集成顺序：添加新功能的代理可能需要等待另一个代理的基础设施改进完成。这种协调比传统的独立开发更像是在管理一个分布式团队。

## 发展团队实践以整合代理

自主代理的引入从根本上改变了团队动态和审查流程。与审查同事精心制作的 PR 不同，代理生成的 PR 可能包含技术上正确但风格上不一致的代码。团队必须发展新的审查实践，以考虑到这种差异。

考虑建立针对特定代理的审查清单，强调的不仅是正确性，还有与团队惯例和架构模式的契合度。记录你在与代理一起工作时发现的常见怪癖：也许你选择的代理持续使用某些反模式或错过特定的优化机会。这种制度化的知识有助于审查员快速识别和解决反复出现的问题。

## 使用自主系统构建反馈循环

最重要的可能就是，自主代理使迭代开发出现了一种新的形式，其中反馈循环不仅限于代码审查。当一个代理的拉取请求需要改进时，你通常可以将其退回并要求进行另一轮迭代，并提供具体的指导。这与传统开发不同，将工作退回给人类同事会带来社会和时间成本。

努力开发与所选代理配合良好的提示模式。当你找到成功的提示公式，并持续产生高质量的结果时，请记录下来。为常见任务类型创建模板，包括所有必要的上下文和约束。这是一种针对代理的提示工程，它考虑了他们的规划、执行和修订周期，并且它代表了一种与通用人工智能交互不同的独特技能。

目标保持不变：高效地交付高质量的软件。自主代理只是提供了一种实现这一目标的新工具，你应该深思熟虑地将它整合到现有的实践中，而不是完全取代既定方法。通过理解这些代理并利用它们独特的功能，同时保持严格的质量标准，团队可以实现显著的生产力提升，而不会牺牲代码质量或架构完整性。

# 摘要和下一步

总结来说，我将重申第四章中的观点：人工智能不会取代开发者，但能够有效使用人工智能的开发者可能会取代那些不能的人。自主编码代理的出现是朝着这个方向的一大步——那些学会利用这些“无头同事”的人将能够在更短的时间内完成更多工作。只要我们适应变化并继续将我们的工作标准保持得高，对软件工程师来说，这是一个激动人心的时代。工具可能会改变，但目标保持不变：构建可靠、高效和创新的软件。有了人工智能代理在我们身边（或在幕后），我们有了新的方式来实现这些目标——也许在机器人熬夜加班的时候，我们还能睡个好觉。

接下来，本书的最后一章更广泛地探讨了人工智能在编码领域的未来，包括代理人工智能的未来。
