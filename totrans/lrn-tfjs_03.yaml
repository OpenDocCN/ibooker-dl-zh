- en: Chapter 2\. Introducing TensorFlow.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: “If your actions inspire others to dream more, learn more,
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: do more, and become more, you are a leader.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —John Quincy Adams
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We’ve been talking about TensorFlow.js a bit and what it can do, but we haven’t
    really dug into what a machine learning framework like TensorFlow.js actually
    is. In this chapter, we’ll tackle the concept of a machine learning framework
    and then quickly dive into writing code. I know it’s important to write code that
    has some kind of tangible outcome, so in this chapter, you’ll finally get your
    computer running TensorFlow.js and producing results.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will:'
  prefs: []
  type: TYPE_NORMAL
- en: Look at the concept of TensorFlow.js
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up TensorFlow.js
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Run a TensorFlow.js model package
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take a deep look at what the AI did
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s start with the framework we’ll be using to make it all happen.
  prefs: []
  type: TYPE_NORMAL
- en: Hello, TensorFlow.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given how our previous chapter discussed the philosophies of ancient times and
    the birth of machine learning as a field, you’d expect AI frameworks to have a
    history that reaches as far back as the early 1960s. However, AI was stagnant
    for a long time, and this time is often called “AI winter.” The concepts of AI
    were beleaguered by disbelief and extreme mathematical calculations for the small
    data that was available. Who could blame these researchers? Most software developers
    today depend on shipping apps without writing GPU-enabled linear algebra and calculus
    from scratch, and building your own AI shouldn’t be the exception. Fortunately,
    due to some open source contributions from the Google Brain team, we have options.
  prefs: []
  type: TYPE_NORMAL
- en: There’s a lot of buzzwords that get thrown around when you’re starting machine
    learning. TensorFlow, TensorFlow Lite, and TensorFlow.js can all be mentioned,
    and it’s not clear to most newcomers what these terms mean or why there are even
    three of them. For now, let’s ignore the term *tensor*, as you’ve heard the word
    in [Chapter 1](ch01.html#the_chapter_1) and you’ll really get to understand it
    in subsequent chapters. Instead, let’s focus on defining TensorFlow.js so we can
    use it.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow, without any extra “.js” or “Lite,” was Google’s first public machine
    learning framework; the Google Brain team released it in late 2015.^([1](ch02.html#idm45049254746888))
    This framework focused on effectively solving machine learning problems for Google
    in the cloud with Python. It wasn’t long before Google realized there would be
    benefits to pushing this popular framework to IoT and mobile devices that have
    limited computing power, and that required an adaptation of TensorFlow, which
    is known as TensorFlow Lite. This successful adaptation paved the way to push
    TensorFlow ideals into other languages.
  prefs: []
  type: TYPE_NORMAL
- en: You can probably guess what happened next. In early 2018, Google announced a
    Google-backed JavaScript import of the machine learning framework TensorFlow for
    JavaScript, called TensorFlow.js. This new effort empowered the practicality of
    TensorFlow in a whole new way. Daniel Smilkov, Nikhil Thorat, and Shanqing Cai
    were part of a team that released TensorFlow.js. At the [TensorFlow Developer
    Summit](https://youtu.be/YB-kfeNIPCE), Smilkov and Thorat train a model to control
    a *PAC-MAN* game using computer vision and a webcam in the browser.
  prefs: []
  type: TYPE_NORMAL
- en: It was this moment when the “Python-only” chains were removed from options of
    popular AI frameworks, and neural networks could effectively traverse the JavaScript
    domain. *If you can run JavaScript, you can run AI that is powered by TensorFlow.js
    ML.*
  prefs: []
  type: TYPE_NORMAL
- en: 'All three of these implementations are alive today and grow with their specific
    purpose. By expanding TensorFlow to a JavaScript implementation, we can now implement
    AI/ML with node servers and even the client browser. In the paper “TensorFlow.js:
    Machine Learning for the Web and Beyond” [(Daniel Smilkov et al., 2019)](https://oreil.ly/XkIjZ),
    they state, “TensorFlow.js has empowered a new set of developers from the extensive
    JavaScript community to build and deploy machine learning models and enabled new
    classes of on-device computation.” TensorFlow.js can leverage a vast platform
    of devices while still accessing the GPU and even Web Assembly. With JavaScript,
    our machine learning can venture to the horizon and back.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s also worth noting that in several benchmarking tests, Node has outperformed
    Python 3 with lower CPU load,^([2](ch02.html#idm45049254735528)) so while Python
    has been the adopted language of most AI, JavaScript serves as a parimary language
    platform for products and services.
  prefs: []
  type: TYPE_NORMAL
- en: But there’s no need to remove or promote any one language. TensorFlow models
    are based on directed acyclic graphs (DAGs), which are language-independent graphs
    that are the *output* of the training. These graphs can be trained by one language
    and then converted and consumed by a completely different programming language.
    It’s the goal of this book to arm you with the tools you’ll need to get the most
    out of using JavaScript and TensorFlow.js.
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging TensorFlow.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For a lot of people, “learning” can sometimes mean starting at the fundamentals,
    which means starting with the mathematics. For those people, a framework like
    TensorFlow and a pragmatic branch of a framework like TensorFlow.js is a poor
    start. In this book, we’ll be building projects and touching on the fundamentals
    of the framework of TensorFlow.js, and we’ll spend little time, if any, on the
    underlying mathematical magic.
  prefs: []
  type: TYPE_NORMAL
- en: Frameworks like TensorFlow and TensorFlow.js help us avoid the specifics of
    the linear algebra involved. You’re freed from terms like *forward propagation*
    and *backpropagation*, as well as their computations and calculus. Instead, we’ll
    be focused on industry terms like *inference* and *model training*.
  prefs: []
  type: TYPE_NORMAL
- en: While TensorFlow.js can access lower-layer APIs (such as `tfjs-core`) to do
    some fundamental optimization on classical problems, those moments are left to
    the academics and advanced users who have a strong foundation regardless of the
    framework at hand. This book is meant to show the power of TensorFlow.js, and
    utilizing the hard work and optimization of the framework is how we’ll do that.
    We leave TensorFlow.js the job of configuring and optimizing our code to work
    with the wide variety of device constraints and WebGL APIs.
  prefs: []
  type: TYPE_NORMAL
- en: We might even take things a bit too far and apply machine learning to algorithms
    you could easily code by hand, but that’s generally where most people really grasp
    concepts clearly. Solving simple problems you understand with machine learning
    helps you extrapolate the steps, logic, and trade-offs of solving advanced problems
    you could never code by hand.
  prefs: []
  type: TYPE_NORMAL
- en: On the other side of the coin, some fundamentals of neurons, activation functions,
    and model initialization cannot be ignored and may require some explanation. It’s
    the goal of this book to give you a healthy balance of theory and practicality.
  prefs: []
  type: TYPE_NORMAL
- en: As you might have surmised, the variety of platforms for TensorFlow.js means
    that there’s no singular prescribed setup. We’ll be able to run TensorFlow.js
    in a client or a server for this book. However, our most tacit interactive option
    is to take full advantage of the browser. For that reason, we’ll perform the lion’s
    share of examples in the browser. We will, of course, still cover the key aspects
    of hosting a node server solution where appropriate. Each of these two tools has
    their underlying drawbacks and benefits, which we’ll mention as we venture into
    the power of TensorFlow.js.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s Get TensorFlow.js Ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like any popular tool, you might notice there are several flavors for the TensorFlow.js
    package, as well as several locations where you can access the code. The majority
    of this book will focus on the most available and “ready to run” versions of TensorFlow.js,
    which means the browser client. Optimized builds of the framework are made for
    the server side. These builds talk to the same underlying C++ core API that Python
    does, but via Node.js, which allows you to leverage all the performance of your
    server’s graphics card or CPU. TensorFlow.js AI models run in a variety of locations
    and utilize a variety of optimizations for each environment (see [Figure 2-1](#flavors)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Tensorflow options chart](assets/ltjs_0201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. Options for TensorFlow.js
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The knowledge you’ll learn in this book can be applied to most platforms. For
    your convenience, we’ll cover the setup process for the most common platforms.
    If you’re uncomfortable setting up your environments from scratch, you can simply
    access the preconfigured projects built for you in the source code associated
    with this book, located at [*https://github.com/GantMan/learn-tfjs*](https://github.com/GantMan/learn-tfjs).
  prefs: []
  type: TYPE_NORMAL
- en: Getting Set Up with TensorFlow.js in the Browser
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s jump into the fastest, most versatile, and simplest way of running TensorFlow.js.
    To get TensorFlow.js running in your browser, it’s actually quite easy. I’m going
    to assume that you’re familiar with the basics of JavaScript and that you’ve imported
    JavaScript libraries into existing code before. TensorFlow.js supports a wide
    variety of ways to be included, so developers of any experience can access it.
    If you’re familiar with including JavaScript dependencies, you’ll be familiar
    with these common practices. We can import TensorFlow.js into a page two ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Using NPM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Including a script tag
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using NPM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the most popular ways to manage your dependencies for your website is
    to use a package manager. If you’re used to building projects with NPM or Yarn,
    you can access the code via the NPM registry at [*https://oreil.ly/R2lB8*](https://oreil.ly/R2lB8).
    Simply install the dependency at the command line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have imported the `tfjs` package, you can import this code in your
    JavaScript project with the following ES6 JavaScript import code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Including a Script Tag
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If a website does not use a package manager, you can simply add a script tag
    to the HTML document. This is the second way you can include TensorFlow.js in
    your project. You can download and host TensorFlow.js locally or utilize a content
    delivery network (CDN). We’ll be pointing the script tag at a CDN-hosted script
    source:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Besides caching across websites, CDNs are extremely quick because they utilize
    edge locations to ensure speedy delivery worldwide.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you might have noticed, I’ve locked this code to a specific version (2.7.0),
    which I strongly recommend you always do in your projects regarding CDNs. You
    don’t want to run into any issues with automatic breaking changes for your site.
  prefs: []
  type: TYPE_NORMAL
- en: Getting Set Up with TensorFlow.js Node
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The TensorFlow.js package we use for the browser works just fine with Node.js,
    and this is a fine solution if you’re planning on only temporarily experimenting
    with Node.js. A good rule is to use the simple `/tfjs` over the `/tfjs-node` import
    if you’re not interested in hosting a live project for others or training on large
    amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: If your goal is to go beyond experimentation and into effective Node.js with
    TensorFlow.js, you should spend some time improving your Node.js setup with some
    of [these alternative packages](https://oreil.ly/zREQy). There are two better
    distributions of TensorFlow.js that are built specifically for Node and speed.
    They are `tfjs-node` and `tfjs-node-gpu`. Keep in mind that each developer machine
    is unique and your installs and experiences may vary.
  prefs: []
  type: TYPE_NORMAL
- en: For Node.js you’ll likely make a selection between `@tensorflow/tfjs-node` or
    `@tensorflow/tfjs-node-gpu`. You can utilize the latter GPU-powered package if
    your computer is configured with an NVIDIA GPU and properly set up with CUDA software.
    Compute Unified Device Architecture (CUDA) allows direct GPU-accelerated access
    through a parallel computing platform for NVIDIA hardware. While the GPU package
    is the absolute fastest of the TensorFlow.js options, it’s also the least likely
    to be ready and configured for most machines, due to its hardware and software
    constraints. For now, our examples will work on installing `tfjs-node` and leave
    the optional CUDA configuration up to you.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Oftentimes, if your computer has not been set up to develop advanced C++ libraries,
    you might have to do a bit of installing to get your machine ready. This rabbit
    hole is only necessary if you’re looking to actively work with `tfjs-node` or
    `tfjs-node-gpu`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If your NPM install was successful, congratulations! You are ready to import
    from this package. If you have Node set up to handle ES6, you can import with
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If you haven’t configured your Node.js package to handle ES6 imports, you can
    still access the code with a classic require:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Verifying TensorFlow.js Is Working
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All of the previous methods will make a variable `tf` available in your JavaScript
    code, which gives you access to TensorFlow.js. To make sure our import worked
    appropriately, let’s log the version of the imported TensorFlow.js library.
  prefs: []
  type: TYPE_NORMAL
- en: Add this code to your JavaScript, and if you see a version printed in the console,
    your import is good to go!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: When the page is run, we can right-click the page and inspect to access the
    JavaScript console logs. There we’ll find the output of our log command, “3.0.0”
    or whatever version of TensorFlow.js you imported. For the Node.js example, the
    value will simply print directly in the console.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Before you access features of the `tf` variable (TensorFlow.js library), you
    would normally need to assure TensorFlow.js has properly loaded a backend and
    is ready. The aforementioned code bypasses this check, but it’s always prudent
    to run your initial code awaiting the promise of `tf.ready()`.
  prefs: []
  type: TYPE_NORMAL
- en: Download and Run These Examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned in [Chapter 1](ch01.html#the_chapter_1), you have access to code
    from this book. To make sure you don’t have to set up these projects from scratch
    on every example, ensure you have the source code for each project, including
    the simple code shown previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the project in your preferred way from the book’s repo: [*https://github.com/GantMan/learn-tfjs*](https://github.com/GantMan/learn-tfjs).'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the directory for Chapter 2, and make sure you can run the code
    on your machine.
  prefs: []
  type: TYPE_NORMAL
- en: Running the simple example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In *chapter2/simple/simplest-example* we are avoiding NPM and simply pulling
    our code from a CDN. With the way this code is currently structured, we don’t
    even have to host the site! We can simply open *index.html* in any modern browser,
    and it will work!
  prefs: []
  type: TYPE_NORMAL
- en: At some point, we’ll actually need to host these simple examples because we’ll
    access additional assets that require full URIs. We can do this quite easily by
    using a small web server to host the files. The smallest web server I know is
    called Web Server for Chrome and has a funny hand-drawn “200 OK!” logo. Within
    five minutes, we can get our files properly served on a local server.
  prefs: []
  type: TYPE_NORMAL
- en: You can find Web Server for Chrome on the [Chrome Web Store as an extension](https://oreil.ly/ZOedW).
    In this book we’ll sometimes call this plug-in “200 OK!” When you point the web
    server at the *index.html* file, it will automatically serve the file for you,
    and all adjacent files will be accessible with their associated URLs, as we will
    require in later lessons. The app interface should look like [Figure 2-3](#two_hundred).
  prefs: []
  type: TYPE_NORMAL
- en: '![200 OK! Dialogue](assets/ltjs_0203.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-3\. Web Server for Chrome 200 OK! dialog
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you’d like to peruse other options or want a link to the mentioned Chrome
    plug-in, take a look at *chapter2/extra/hosting-options.md* to find the one that
    works for you. And of course, if you find a fantastic option that’s not listed,
    please contribute a pull request.
  prefs: []
  type: TYPE_NORMAL
- en: Once you find a server that runs *simple-example* in a way you enjoy, you can
    use that service for all simple options going forward.
  prefs: []
  type: TYPE_NORMAL
- en: Running the NPM web example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you’re more familiar with NPM, the basic NPM example for this project uses
    Parcel. Parcel is the fastest application bundler with zero configuration. It
    also includes Hot Module Reloading to get real-time updates and excellent error
    logging.
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the code, navigate to *chapter2/web/web-example* and do an NPM install
    (`npm i`). Once that’s done, there’s a script in the *package.json* that kicks
    everything off. You can simply run the start script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: That’s it! We’ll be using this method to run all NPM-based code in the book.
  prefs: []
  type: TYPE_NORMAL
- en: Running the Node.js example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Node.js example is just as easy to run as the Parcel NPM example. While
    Node.js is generally unopinionated, the Node.js examples in this book will include
    a few opinionated dev dependencies so we can make our Node.js example code align
    with the browser examples. The code throughout this book will take full advantage
    of ECMAScript. We do this with some transpiling, file watching, and node magic.
  prefs: []
  type: TYPE_NORMAL
- en: 'To prep this example, navigate to *chapter2/node-example* and do an NPM install
    (`npm i`). If you have any issues, you may need to run `npm i -g ts-node nodemon
    node-gyp` to assure you have the needed libraries to make all our magic happen.
    Once your node packages are properly in place, you can start the project at any
    time by running the start script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The code is transpiled via TypeScript and reload-friendly `nodemon`. If everything
    ran properly, you’ll see the installed TensorFlow.js version printed directly
    in the console/terminal where you ran the server.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s Use Some Real TensorFlow.js
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have TensorFlow.js, let’s use it to make something epic! OK, that’s
    quite a simplification: if it were that easy, the book would be over. There’s
    still a mountain of things to learn, but that doesn’t stop us from taking a gondola
    to get a high-level view.'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow.js has plenty of prewritten code and models we can utilize. These
    pre-written libraries help us get the benefits of utilizing TensorFlow.js without
    fully grasping the underlying concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are plenty of community-driven models that work quite well, the
    official maintained list of TensorFlow.js models is on the TensorFlow GitHub under
    a repo named `tfjs-models`. For stability, we’ll use these as often as we can
    in this book. You can peruse the links here: [*https://github.com/tensorflow/tfjs-models*](https://github.com/tensorflow/tfjs-models).'
  prefs: []
  type: TYPE_NORMAL
- en: For this foray into running actual TensorFlow.js models, let’s pick something
    with a relatively simple input and output. We’ll use the TensorFlow.js *Toxicity*
    classifier to check if text input is insulting or not.
  prefs: []
  type: TYPE_NORMAL
- en: The Toxicity Classifier
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Google provides a few “ready-to-go” models of varying complexity. One beneficial
    model is called the Toxicity model, which is perhaps one of the most straightforward
    and useful models for beginners.
  prefs: []
  type: TYPE_NORMAL
- en: Like all programming, a model will require specific input and will provide specific
    output. To kick things off, let’s take a look at what those are for in this model.
    Toxicity detects toxic content such as threats, insults, cussing, and generalized
    hate. Since those aren’t necessarily mutually exclusive, it’s important that each
    of these violations has their own probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Toxicity model attempts to identify a probability that a given input is
    true or false for the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: Identity attack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Insult
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obscene
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Severe toxicity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sexually explicit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threat
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Toxicity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you give the model a string, it returns an array of seven objects to identify
    the percentage-of-probability prediction for each specific violation. Percentages
    are represented as two `Float32` values between zero and one.
  prefs: []
  type: TYPE_NORMAL
- en: If a sentence is surely *not* a violation, the probabilities will give most
    of the value to the zero index in the `Float32` array.
  prefs: []
  type: TYPE_NORMAL
- en: For example, `[0.7630404233932495, 0.2369595468044281]` reads that the prediction
    for this particular violation is 76% not a violation and 24% likely a violation.
  prefs: []
  type: TYPE_NORMAL
- en: This can be quite a “Hold on, what!?” moment for most developers. It’s a bit
    strange getting probabilities where we’re used to true and false, isn’t it? But
    in an intuitive way, we’ve always understood that language has a lot of gray area.
    The exact science of insults often depends on the person and even the day!
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, the model has a bonus feature of allowing you to pass a threshold
    that will identify when a particular violation surpasses the allotted limit. When
    an insult is detected beyond the threshold, the `match` flag is set to true. This
    is a nice little bonus to help you quickly map the results for significant violations.
    Picking a valid threshold depends on your needs and the situation. You can shoot
    from the hip, but if you need some guidance, statistics has all kinds of tools
    you could review. Read up on Receiver Operating Characteristic (ROC) graphs for
    plotting and picking an optimal threshold for your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To activate the Toxicity model, we will have to write something insulting. The
    following example uses an insult based on looks. The insult avoids using profanity
    but is still offensive. This is not directed to anyone in particular and is meant
    to illustrate the capabilities of AI to understand and identify toxic comments.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to choose an insult that is easy for humans to recognize, but
    difficult for a computer. Sarcasm detection is difficult in text form and has
    been a major problem in computer science. To seriously test this model, the insult
    should avoid common and blatant inflammatory wording. Running the Toxicity model
    on a particularly crafty insult with the threshold set to `0.5` yields the array
    shown in [Example 2-1](#output_full_toxicity).
  prefs: []
  type: TYPE_NORMAL
- en: 'The insult input: “She looks like a cavewoman, only far less intelligent!”'
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-1\. The full toxicity report on the input sentence
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from [Example 2-1](#output_full_toxicity), we snuck under the
    “insult” radar by a hair (50.2% false), but we got dinged by the toxicity indicator,
    which resulted in `"match": true`. This is quite impressive, because I don’t have
    any explicitly offensive language in the sentence. As a programmer, it wouldn’t
    be straightforward to write an algorithm to catch and identify this toxic insult,
    but AI was trained to identify the complex patterns of toxic language after studying
    heaps of labeled insults so we don’t have to.'
  prefs: []
  type: TYPE_NORMAL
- en: The previous example uses a single sentence in an array as input. If you include
    multiple sentences as input, your sentence index will correspond directly with
    your result index for each category.
  prefs: []
  type: TYPE_NORMAL
- en: 'But don’t take my word for it; now it’s your turn to run the code. You can
    add the model to your website with NPM via this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'and then import the library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Or you can add the script directly from a CDN.^([3](ch02.html#idm45049252373352))
    Order matters with script tags, so make sure your tag is placed on the page before
    you try to use the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Either of the previous examples will provide results in a ready-to-go `toxicity`
    variable. We’ll use this variable’s `load` method to load the ML model promise.
    And from that model, we can utilize the `classify` method on an array of sentences.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s an example of loading the model and running classification on three sentences.
    This exact example can be found in three different forms in the associated sections
    of [the chapter code on GitHub](https://oreil.ly/sTs5a).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_introducing_tensorflow_js_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The model is loaded into the browser with a threshold.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_introducing_tensorflow_js_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The loaded model is asked to classify inputs.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_introducing_tensorflow_js_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The object is printed nicely using JavaScript Object Notation.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you run this code in a browser, you’ll need to view the console to view the
    output. You can navigate to the console from inspecting the page, or generally,
    you can press Control+Shift+J on Windows or Command+Option+J on Mac. If you’re
    running this from the command line with `npm start`, you should see the output
    immediately in the console.
  prefs: []
  type: TYPE_NORMAL
- en: The results for multiple sentences are grouped by toxicity category. So the
    previous code attempts to identify each sentence depending on each category. For
    instance, the “insult” output from the previous should read similar to [Example 2-2](#output_insult_result).
  prefs: []
  type: TYPE_NORMAL
- en: Example 2-2\. Insult section results
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Ta-daaaaa! The code works great. Each `results` index corresponds to the input
    sentence index, and it properly diagnoses the two insults among the three sentences.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations on running your first TensorFlow.js model. Now that you’re a
    master of AI, let’s talk through the steps and underlying concepts of this library.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When we call `toxicity.load`, you might be thinking the model is being loaded
    into memory, but you’d only be half-right. Most of these libraries do not ship
    with the trained model in the JavaScript codebase. Read that sentence again. This
    might seem a bit alarming to our NPM developers, but it makes complete sense to
    our CDN users. The load method fires off a network call to download the model
    that the library uses. In some cases, the model that is loaded is optimized for
    the environment and device where the JavaScript is located. Review the network
    logs illustrated in [Figure 2-4](#model_download).
  prefs: []
  type: TYPE_NORMAL
- en: '![Toxicity Download](assets/ltjs_0204.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-4\. Network download requests
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: While the Toxicity NPM bundle can be minified and zipped to a mere 2.4 KB, there’s
    an additional multimegabyte payload over the network for the actual model file
    when the library is used.
  prefs: []
  type: TYPE_NORMAL
- en: The load method for this Toxicity library takes a threshold that it will apply
    to all subsequent classifications and then fires off a network call to download
    the actual model file. When that model is fully downloaded, the library then loads
    the model into tensor-optimized memory for use.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to evaluate each library appropriately. Let’s review some common
    questions people ask when they learn a bit more about this.
  prefs: []
  type: TYPE_NORMAL
- en: Classifying
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next thing our Toxicity code did is run a `classify` method. This is the
    moment where our input sentences were passed through the model, and we got the
    results. While it seemed just as simple as any other JavaScript function, this
    library actually hid some fundamental processing that was necessary.
  prefs: []
  type: TYPE_NORMAL
- en: All data in and out of a model is converted to a tensor. We will cover tensors
    in greater detail in [Chapter 3](ch03.html#the_chapter_3), but it’s important
    to note that this conversion is essential for the AI. All the input strings are
    converted, and calculations are made, and the results that come out are tensors
    that are reconverted into normal JavaScript primitives.
  prefs: []
  type: TYPE_NORMAL
- en: It’s nice that this library handled this for us. When you’re finished with this
    book, you’ll be able to wrap machine learning models with the same dexterity.
    You’ll be able to keep your users in blissful ignorance of the intricacies of
    data conversions that are happening behind the scenes.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll jump into that conversion. You’ll fully grasp the
    transition of data into tensors and all the data manipulation superpowers that
    come with it.
  prefs: []
  type: TYPE_NORMAL
- en: Try It Yourself
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you’ve implemented one model, you can most likely implement the [other
    models provided by Google](https://oreil.ly/WFq62). Most of the other Google models’
    GitHub pages have README documents explaining how to implement each library. Many
    of the implementations are similar to what we saw with Toxicity.
  prefs: []
  type: TYPE_NORMAL
- en: Take a moment to browse through the existing models to let your imagination
    run wild. You can begin working with these libraries immediately. Knowing these
    models exist will also be useful as you progress in this book. Not only are you
    going to better understand what these libraries are capable of, but you might
    want to combine and even improve on these existing libraries for your needs.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll start digging into the details of what these well-wrapped
    libraries are hiding so we can unleash your TensorFlow.js skills without limit.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter Review
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We set up your computer for TensorFlow.js via a few common practice options.
    We assured our machine is ready to run TensorFlow.js, and we even pulled down
    and ran a packaged model for determining text toxicity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter Challenge: Truck Alert!'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Take the time to try the [MobileNet model](https://oreil.ly/fUKoy), which has
    the ability to look at images and attempt to classify the predominant artifact.
    This model can be passed any `<img>`, `<video>`, or `<canvas>` element, and it
    returns an array of most likely predictions for what it sees in that particular
    graphic.
  prefs: []
  type: TYPE_NORMAL
- en: The MobileNet model has been trained to classify [1,000 possible items](https://oreil.ly/6PEAn)
    from stone walls, to garbage trucks, to even an Egyptian cat. People have used
    this library to detect a wide variety of fun things. I once saw some code that
    connected a webcam to MobileNet to [detect llamas](https://oreil.ly/L0nBz).
  prefs: []
  type: TYPE_NORMAL
- en: For this Chapter Challenge, you’re tasked with creating a website that can detect
    trucks. Given an input image, you’re looking to identify if it’s a truck or not.
    When you detect a truck from a photo, do an `alert("TRUCK DETECTED!")`. By default,
    the MobileNet package returns the top three detections. If any of those three
    see a truck in the photo, your alert should notify the user just like in [Figure 2-5](#truck_detected).
  prefs: []
  type: TYPE_NORMAL
- en: '![Truck detector with active alert](assets/ltjs_0205.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-5\. Truck detector working
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can find the answer to this challenge in [Appendix B](app02.html#appendix_b).
  prefs: []
  type: TYPE_NORMAL
- en: Review Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s review the lessons we’ve learned from the code you’ve written in this
    chapter. Take a moment to answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Can regular TensorFlow run in the browser?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does TensorFlow.js have access to the GPU?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do you have to have CUDA installed to run TensorFlow.js?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If I don’t specify a version on a CDN, what happens?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does the Toxicity classifier identify violations?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When do we pass a threshold to Toxicity?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Does the Toxicity code contain all the needed files?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do we have to do any tensor work to use this Toxicity library?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Solutions to these exercises are available in [Appendix A](app01.html#book_appendix).
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch02.html#idm45049254746888-marker)) TensorFlow didn’t reach 1.0.0 status
    until February 11, 2017.
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](ch02.html#idm45049254735528-marker)) 2x boost with Node over Python case
    study: [*https://oreil.ly/4Jrbu*](https://oreil.ly/4Jrbu)'
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch02.html#idm45049252373352-marker)) Notice this version is locked at
    1.2.2.
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch02.html#idm45049252013384-marker)) The Toxicity model info is available
    at [*https://oreil.ly/Eejyi*](https://oreil.ly/Eejyi).
  prefs: []
  type: TYPE_NORMAL
