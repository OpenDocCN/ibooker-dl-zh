<html><head></head><body><section data-pdf-bookmark="Chapter 6. Real-Time Communication &#10;with Generative Models" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch06">
<h1><span class="label">Chapter 6. </span>Real-Time Communication 
<span class="keep-together">with Generative Models</span></h1>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id873">
<h1>Chapter Goals</h1>
<p><a data-primary="real-time communication with generative models" data-type="indexterm" id="ix_ch06-asciidoc0"/>In this chapter, you will learn about:</p>

<ul>
<li>
<p>When to implement real-time communication in AI workflows</p>
</li>
<li>
<p>Web communication mechanisms by comparing their features, differences, and similarities</p>
</li>
<li>
<p>Real-time communication mechanisms including server-sent events (SSE) and WebSocket (WS)</p>
</li>
<li>
<p>Selecting the correct streaming technology for your use case</p>
</li>
<li>
<p>Implementing mocked streaming endpoints from scratch for testing and prototyping</p>
</li>
<li>
<p>Implementing real-time API endpoints with both SSE and WebSocket 
<span class="keep-together">mechanisms</span></p>
</li>
<li>
<p>How to gracefully handle exceptions and close streaming 
<span class="keep-together">connections</span></p>
</li>
<li>
<p>API design patterns to simplify streaming endpoints</p>
</li>
</ul>
</div></aside>

<p>This chapter will explore AI streaming workloads such as chatbots, detailing the use of real-time communication technologies like SSE and WebSocket.
You will learn the difference between these technologies and how to implement model streaming by building endpoints for real-time text-to-text interactions.</p>






<section data-pdf-bookmark="Web Communication Mechanisms" data-type="sect1"><div class="sect1" id="id90">
<h1>Web Communication Mechanisms</h1>

<p><a data-primary="real-time communication with generative models" data-secondary="web communication mechanisms" data-type="indexterm" id="ix_ch06-asciidoc1"/>In the previous chapter, you learned about implementing concurrency in AI workflows by leveraging asynchronous programming, background tasks, and continuous batching.
With concurrency, your services become more resilient to matching increased demand when multiple users access your application simultaneously.
Concurrency solves the problem of allowing simultaneous users to access your service and helps to decrease the waiting times, yet AI data generation remains a resource-intensive and time-consuming task.</p>

<p>Up until this point, you’ve been building endpoints using the conventional HTTP communication where the client sends a request to the server.
The web server processes the incoming requests and responds via HTTP messages.</p>

<p><a data-type="xref" href="#client_server_architecture">Figure 6-1</a> shows the client-server architecture.</p>

<figure><div class="figure" id="client_server_architecture">
<img alt="bgai 0601" src="assets/bgai_0601.png"/>
<h6><span class="label">Figure 6-1. </span>The client-server architecture (Source: <a class="orm:hideurl" href="https://scaleyourapp.com">scaleyourapp.com</a>)</h6>
</div></figure>

<p>Since the HTTP protocol is stateless, the server treats each incoming request completely independent and unrelated from other requests.
This means that multiple incoming requests from differing clients wouldn’t affect how the server responds to each one.
As an example, in a conversational AI service that doesn’t use a database, each request may provide the full conversation history and receive the correct response from the server.</p>

<p><a data-primary="HTTP request-response model" data-type="indexterm" id="id874"/>The <em>HTTP request-response</em> model is a widely adopted API design pattern used across the web due to its simplicity.
However, this approach becomes inadequate as soon as the client or the server needs real-time updates.</p>

<p>In the standard HTTP request-response model, your services typically respond to the user’s request once it has been entirely processed.
However, if the data generation process is lengthy and sluggish, your users will wait a long time and subsequently be inundated with lots of information at once.
Imagine chatting to a bot that takes several minutes to reply, and once it does, you’re shown overwhelming blocks of text.</p>

<p>Alternatively, if you provide the data to the client as it’s being generated, rather than holding off until the entire generation process is complete, you can mitigate lengthy delays and deliver the information in digestible chunks.
This approach not only enhances user experience but also maintains user engagement during the ongoing processing of their request.</p>

<p>There will be cases where implementing real-time features can be overkill and escalate the development burden.
For instance, some open source models or APIs lack the real-time generation capability.
Furthermore, adding data streaming endpoints can add to the complexity of your system on both sides, the server and the client.
It means having to handle exceptions differently and manage concurrent connections to the streaming endpoints to avoid memory leakage.
If the client disconnects during a stream, there may be a chance for data loss or state drift between the server and the client.
And, you may need to implement complex reconnection and state management logic to handle cases where the connection drops.</p>

<p>Maintaining many concurrent open connections can also put a burden on your servers and lead to an increase in hosting and infrastructure costs.</p>

<p>Equally important, you also need to consider the scalability of handling a large number of concurrent streams, your application’s latency requirements, and browser compatibilities with your chosen streaming protocol.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Compared to traditional web applications that have some form of I/O or data processing latency, AI applications also have AI model inference latency, depending on the model you’re using.</p>

<p>Since this latency can be significant, your AI services should be able to handle longer waiting times on both the server and client sides, including managing the user experience.</p>
</div>

<p>If your use case does benefit from real-time features, then you have a few architectural design patterns you can implement:</p>

<ul>
<li>
<p>Regular/short polling</p>
</li>
<li>
<p>Long polling</p>
</li>
<li>
<p>SSE</p>
</li>
<li>
<p>WS</p>
</li>
</ul>

<p>The choice depends on your requirements for user experience, scalability, latency, development cost, and maintainability.</p>

<p>Let’s explore each option in more detail.</p>








<section data-pdf-bookmark="Regular/Short Polling" data-type="sect2"><div class="sect2" id="id91">
<h2>Regular/Short Polling</h2>

<p><a data-primary="real-time communication with generative models" data-secondary="web communication mechanisms" data-tertiary="regular/short polling" data-type="indexterm" id="ix_ch06-asciidoc2"/><a data-primary="regular/short polling" data-type="indexterm" id="ix_ch06-asciidoc3"/><a data-primary="web communication mechanisms" data-secondary="regular/short polling" data-type="indexterm" id="ix_ch06-asciidoc4"/>A method to benefit from semi-real-time updates is to use <em>regular/short polling</em>, as shown in <a data-type="xref" href="#short_polling">Figure 6-2</a>.
In this polling mechanism, the client periodically sends HTTP requests to the server to check for updates at preconfigured intervals.
The shorter the intervals, the closer you get to real-time updates but also the higher the traffic you will have to manage.</p>

<figure><div class="figure" id="short_polling">
<img alt="bgai 0602" src="assets/bgai_0602.png"/>
<h6><span class="label">Figure 6-2. </span>Regular/short polling</h6>
</div></figure>

<p>You can use this technique if you’re building a service to generate data such as images in batches.
The client simply submits a request to start the batch job and is given a unique job/request identifier.
It then periodically checks back with the server to confirm the status and outputs of the requested job.
The server then responds with new data or provides an empty response (and perhaps a status update) if outputs are yet to be computed.</p>

<p>As you can imagine with short polling, you’ll end up with an excessive number of incoming requests that the server needs to respond to, even when there’s no new information.
If you have multiple concurrent users, this approach can quickly overwhelm the server, which limits your application’s scalability.
However, you can still reduce server load by using cached responses (i.e., executing status checks on the backend at a tolerable frequency) and implementing rate limiting, which you will learn more about in Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch09.html#ch09">9</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch10.html#ch10">10</a>.</p>

<p>A potential use case for short polling in AI services is when you have some in-progress batch or inference jobs.
You can expose endpoints for your clients to use short polling to keep up-to-date with the status of these jobs.
And, fetch the results when they’re completed.</p>

<p>An alternative is to leverage long polling instead.<a data-startref="ix_ch06-asciidoc4" data-type="indexterm" id="id875"/><a data-startref="ix_ch06-asciidoc3" data-type="indexterm" id="id876"/><a data-startref="ix_ch06-asciidoc2" data-type="indexterm" id="id877"/></p>
</div></section>








<section data-pdf-bookmark="Long Polling" data-type="sect2"><div class="sect2" id="id92">
<h2>Long Polling</h2>

<p><a data-primary="long polling" data-type="indexterm" id="ix_ch06-asciidoc5"/><a data-primary="real-time communication with generative models" data-secondary="web communication mechanisms" data-tertiary="long polling" data-type="indexterm" id="ix_ch06-asciidoc6"/><a data-primary="web communication mechanisms" data-secondary="long polling" data-type="indexterm" id="ix_ch06-asciidoc7"/>If you want to reduce the burden on your server while continuing to leverage a real-time polling mechanism, you can implement <em>long polling</em> (see <a data-type="xref" href="#long_polling">Figure 6-3</a>), an improved version of regular/short polling.</p>

<figure><div class="figure" id="long_polling">
<img alt="bgai 0603" src="assets/bgai_0603.png"/>
<h6><span class="label">Figure 6-3. </span>Long polling</h6>
</div></figure>

<p>With long polling, both the server and the client are configured to prevent
<em>timeouts</em> (if possible) that occur when either the client or the server gives up on the prolonged request.</p>
<div data-type="tip"><h6>Tip</h6>
<p>Timeouts are observed more often in a typical HTTP request-response cycle when a request takes an extended time to resolve or when there are network issues.</p>
</div>

<p>To implement long polling, the server keeps the incoming requests open (i.e., hanging) until there is data available to send back.
For instance, this can be useful when you have an LLM with unpredictable processing times.
The client is instructed to wait for an extended period of time and avoid aborting and repeating the requests 
<span class="keep-together">prematurely.</span></p>

<p>You can use long polling if you need a simple API design and application architecture for processing prolonged jobs, such as multiple AI inferences.
This technique allows you to avoid implementing a batch job manager to keep track of jobs for bulk data generation.
Instead, the client requests remain open until they are processed, avoiding the constant short polling request-response cycle that can overload the server.</p>

<p>While long polling sounds similar to the typical HTTP request-response model, it differs on how the client handles requests.
In long polling, the client typically receives a single message per request.
Once the server sends a response, the connection is closed.
The client then immediately opens a new connection to wait for the next message.
This process repeats, allowing the client to receive multiple messages over time, but each HTTP request-response cycle handles only one message.</p>

<p>Since long polling maintains an open connection until a message is available, it reduces the frequency of requests compared to short polling and implements a near-real-time communication mechanism.
However, the server still has to hold onto unfulfilled requests, which consume server resources.
Additionally, if there are multiple open requests by the same client, message ordering can be challenging to manage, potentially leading to out-of-order messages.</p>

<p>If you don’t have a specific requirement for using polling mechanisms, a more modern alternative to polling mechanisms for real-time communication is SSE via the Event Source interface.<a data-startref="ix_ch06-asciidoc7" data-type="indexterm" id="id878"/><a data-startref="ix_ch06-asciidoc6" data-type="indexterm" id="id879"/><a data-startref="ix_ch06-asciidoc5" data-type="indexterm" id="id880"/></p>
</div></section>








<section data-pdf-bookmark="Server-Sent Events" data-type="sect2"><div class="sect2" id="id93">
<h2>Server-Sent Events</h2>

<p><a data-primary="real-time communication with generative models" data-secondary="web communication mechanisms" data-tertiary="Server Sent Events" data-type="indexterm" id="ix_ch06-asciidoc8"/><a data-primary="Server Sent Events (SSE)" data-type="indexterm" id="ix_ch06-asciidoc9"/><a data-primary="web communication mechanisms" data-secondary="Server Sent Events" data-type="indexterm" id="ix_ch06-asciidoc10"/><em>Server-sent events</em> (SSE) is an HTTP-based mechanism for establishing a persistent and unidirectional connection from the server to the client.
While the connection is open, the server can continuously push updates to the client as data becomes 
<span class="keep-together">available.</span></p>

<p>Once the client establishes the persistent SSE connection with the server, it won’t need to re-establish it again, unlike the long polling mechanism where the client repeatedly sends requests to the server to maintain an open connection.</p>

<p>When you’re serving GenAI models, SSE will be a more suitable real-time communication mechanism compared to long polling. SSE is designed specifically for handling real-time events and is more efficient than long polling.
Due to repeated opening and closing connections, long polling becomes resource intensive and leads to higher latency and overhead.
SSE, on the other hand, supports automatic reconnection and event IDs to resume interrupted streams, which long polling lacks.</p>

<p>In SSE, the client makes a standard HTTP <code>GET</code> request with an <code>Accept:text/event-stream</code> header, and the server responds with a status code of <code>200</code> and a <code>Content-Type: text/event-stream</code> header.
After this handshake, the server can send events to the client over the same connection.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id881">
<h1>SSE and EventSource Interface</h1>
<p><a data-primary="EventSource interface" data-type="indexterm" id="id882"/><a data-primary="Server Sent Events (SSE)" data-secondary="EventSource interface" data-type="indexterm" id="id883"/>The SSE specification describes a built-in <code>EventSource</code>
interface that opens a persistent connection with the server for sending events from the server. Similar to WebSocket, the connection is persistent.</p>

<p><code>EventSource</code> is a less powerful way of communicating with the server than 
<span class="keep-together">WebSocket.</span></p>

<p>Why should one ever use it? The main reason: it’s simpler. In many applications, the power of WebSocket is a little bit too much.
We will talk about WebSocket shortly.</p>

<p>We need to receive a stream of data from a server—maybe chat messages or market prices, or whatever.
That’s what <code>EventSource</code> is good at.
Also, it supports auto-reconnect, something we need to implement manually with WebSocket.
Besides, it’s a plain old HTTP, not a new protocol.</p>

<p>Upon creation, a new <code>EventSource</code> connects to the server, and if the connection is broken, it reconnects. That’s very convenient, as we don’t have to care about it. There’s a small delay between reconnections, a few seconds by default. The server can set the recommended delay using <code>retry</code>: in response to (milliseconds).</p>
</div></aside>

<p>While SSE should be your first choice for real-time applications, you can still opt for a simpler long polling mechanism where updates are infrequent or if your environment doesn’t support persistent connections.</p>

<p>One last important detail to note is that SSE connections are <em>unidirectional</em>, meaning that you send a regular HTTP request to the server, and you get the response via SSE.
Therefore, they’re only suitable for applications that don’t need to send data to the server.
You may have seen SSE in action within news feeds, notifications, and real-time dashboards like stock data charts.</p>

<p>Unsurprisingly, SSE also shines in chat applications when you need to stream LLM responses in a conversation.
In this instance, the client can establish a separate persistent connection until the server fully streams the LLM’s response to the user.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>ChatGPT leverages SSE under the hood to enable real-time responses to user queries.</p>
</div>

<p><a data-type="xref" href="#server_sent_events">Figure 6-4</a> shows how the SSE communication mechanism operates.</p>

<figure><div class="figure" id="server_sent_events">
<img alt="bgai 0604" src="assets/bgai_0604.png"/>
<h6><span class="label">Figure 6-4. </span>SSE</h6>
</div></figure>

<p>To solidify your understanding, we will be building two mini-projects in this chapter using SSE.
One to stream data from a mocked data generator, and another to stream LLM responses.</p>

<p>You will learn more details about the SSE mechanism during the aforementioned projects.</p>

<p>In summary, SSE is excellent for establishing persistent unidirectional connections, but what if you need to both send and receive messages during a persistent connection? This is where WebSocket would come in handy.<a data-startref="ix_ch06-asciidoc10" data-type="indexterm" id="id884"/><a data-startref="ix_ch06-asciidoc9" data-type="indexterm" id="id885"/><a data-startref="ix_ch06-asciidoc8" data-type="indexterm" id="id886"/></p>
</div></section>








<section data-pdf-bookmark="WebSocket" data-type="sect2"><div class="sect2" id="id94">
<h2>WebSocket</h2>

<p><a data-primary="real-time communication with generative models" data-secondary="web communication mechanisms" data-tertiary="WebSocket" data-type="indexterm" id="ix_ch06-asciidoc11"/><a data-primary="web communication mechanisms" data-secondary="WebSocket" data-type="indexterm" id="ix_ch06-asciidoc12"/><a data-primary="WebSocket (WS)" data-type="indexterm" id="ix_ch06-asciidoc13"/>The last real-time communication mechanism to cover is WebSocket.</p>

<p><a data-primary="bidirectional connection" data-type="indexterm" id="id887"/>WebSocket is an excellent real-time communication mechanism for establishing persistent <em>bidirectional connections</em> between the client and the server for real-time chat, as well as voice and video applications with an AI model.
A bidirectional connection means that both sides can send and receive real-time data in any order, as long as a persistent connection is open between the client and the server.
It’s designed to work over standard HTTP ports to ensure compatibility with existing security measures.
Web applications that require two-way communication with servers benefit the most from this mechanism as they can avoid the overhead and complexity of HTTP 
<span class="keep-together">polling.</span></p>

<p>You can use WebSocket in a variety of applications including social feeds, multiplayer games, financial feeds, location-based updates, multimedia chat, etc.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id888">
<h1>Webhook Versus WebSocket</h1>
<p><a data-primary="Webhook, WebSocket versus" data-type="indexterm" id="id889"/><a data-primary="WebSocket (WS)" data-secondary="Webhook versus" data-type="indexterm" id="id890"/>Don’t confuse WebSocket with Webhook.
These terms get used interchangeably but refer to different real-time web communication mechanisms.</p>

<p>Webhooks are used for real-time server-to-server communication to support event-driven application architectures.
Therefore, when a server exposes a webhook endpoint, it is telling other servers to immediately send data to that webhook endpoint when an event happens.</p>

<p>You can think of webhooks as a nonpersistent but real-time unidirectional communication mechanism where one server sends messages to another as they’re generated.
In reality, there are no handshakes or open connections established between servers.</p>
</div></aside>

<p>Unlike all other communication mechanisms discussed so far, the WebSocket protocol doesn’t transfer data over HTTP after the initial handshake.
Instead, the WebSocket protocol defined in the RFC 6455
specification implements a two-way messaging mechanism (full-duplex) over a single TCP connection.
As a result, WebSocket is faster for data transmission than HTTP because it has less protocol overhead and operates at a lower level in the network protocol stack.
This is because HTTP sits on top of TCP, so stripping back to TCP will be faster.</p>
<div data-type="tip"><h6>Tip</h6>
<p>WebSocket keeps a socket open on both the client and the server for the duration of the connection.
Note that this also makes servers stateful, which makes scaling trickier.</p>
</div>

<p>You may now be wondering how the WebSocket protocol works.</p>

<p>According to RFC 6455, to establish a WebSocket connection, the client sends an HTTP “upgrade” request to the server, asking to open a WebSocket connection.
<a data-primary="opening handshake" data-type="indexterm" id="id891"/>This is referred to as the <em>opening handshake</em>, which initiates the WebSocket connection lifecycle in the
<em>CONNECTING</em> state.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Your AI services should be able to handle multiple concurrent handshakes and also authenticate them before opening a connection. New connections can consume server resources, so they must be handled properly by your server.</p>
</div>

<p>The HTTP upgrade request should contain a set of required headers, as shown in
<a data-type="xref" href="#websocket_handshake">Example 6-1</a>.</p>
<div data-type="example" id="websocket_handshake">
<h5><span class="label">Example 6-1. </span>WebSocket opening handshake over HTTP</h5>

<pre data-code-language="text" data-type="programlisting"><code>GET ws://localhost:8000/generate/text/stream HTTP/1.1 </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-1"><img alt="1" src="assets/1.png"/></a><code>
Origin: http://localhost:3000
Connection: Upgrade </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-2"><img alt="2" src="assets/2.png"/></a><code>
Host: http://localhost:8000
Upgrade: websocket </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-3"><img alt="2" src="assets/2.png"/></a><code>
Sec-WebSocket-Key: 8WnhvZTK66EVvhDG++RD0w== </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-3" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-4"><img alt="3" src="assets/3.png"/></a><code>
Sec-WebSocket-Protocol: html-chat, text-chat </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-4" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-5"><img alt="4" src="assets/4.png"/></a><code>
Sec-WebSocket-Version: 13</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Make an HTTP upgrade request to the WebSocket endpoint.
WebSocket endpoints start with <code>ws://</code> instead of the typical <code>http://</code>.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Request to upgrade and open a WebSocket connection.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-4" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-3"><img alt="3" src="assets/3.png"/></a></dt>
<dd><p>Use a random, 16-byte, Base64-encoded string to ensure the server supports the WebSocket protocol.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-5" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-4"><img alt="4" src="assets/4.png"/></a></dt>
<dd><p>Use the <code>html-chat</code> or the <code>text-chat</code> subprotocol if <code>html-chat</code> is not available.
Subprotocols regulate what data will be exchanged.</p></dd>
</dl></div>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>In production, always use secure WebSocket <code>wss://</code> endpoints.</p>

<p>The <code>wss://</code> protocol, similar to <code>https://</code>, is not only encrypted but also more reliable.
That’s because <code>ws://</code> data is not encrypted and visible for any intermediary.
Old proxy servers don’t know about WebSocket.
They may see “strange” headers and abort the connection.</p>

<p>On the other hand, <code>wss://</code> is the secure version of WebSocket, running over Transport Layer Security (TLS), which encrypts the data at the sender and decrypts it at the receiver.
So data packets are passed encrypted through proxies.
They can’t see what’s inside and let them through.</p>
</div>

<p>Once the WebSocket connection is established, text or binary messages can be transmitted in both directions in the form of <em>message frames</em>.
The connection lifecycle is now in the <em>OPEN</em> state.</p>

<p>You can view the WebSocket communication mechanism in <a data-type="xref" href="#websockets">Figure 6-5</a>.</p>

<figure><div class="figure" id="websockets">
<img alt="bgai 0605" src="assets/bgai_0605.png"/>
<h6><span class="label">Figure 6-5. </span>WS communication</h6>
</div></figure>

<p><a data-primary="message frames" data-type="indexterm" id="id892"/><em>Message frames</em> are a way to package and transmit data between the client and server.
They aren’t anything unique to WebSocket as they apply to all connections over the TCP protocol that form the basis of HTTP.
However, a WebSocket message frame consists of several components:</p>
<dl>
<dt>Fixed header</dt>
<dd>
<p>Describes basic information about the message</p>
</dd>
<dt>Extended payload length (optional)</dt>
<dd>
<p>Provides the actual length of the payload when the length exceeds 125 bytes</p>
</dd>
<dt>Masking key</dt>
<dd>
<p>Masks the payload data in frames sent from the client to the server, preventing certain types of security vulnerabilities, particularly <em>cache poisoning</em><sup><a data-type="noteref" href="ch06.html#id893" id="id893-marker">1</a></sup> and <em>cross-protocol</em><sup><a data-type="noteref" href="ch06.html#id894" id="id894-marker">2</a></sup> attacks</p>
</dd>
<dt>Payload</dt>
<dd>
<p>Contains the actual message content</p>
</dd>
</dl>

<p class="less_space pagebreak-before">Unlike the verbose headers in HTTP requests, WebSocket frames have minimal headers that include the following:</p>
<dl>
<dt>Text frames</dt>
<dd>
<p>Used for UTF-8 encoded text data</p>
</dd>
<dt>Binary frames</dt>
<dd>
<p>Used for binary data</p>
</dd>
<dt>Fragmentation</dt>
<dd>
<p>Used to fragment messages into multiple frames, which are reassembled by the recipient</p>
</dd>
</dl>

<p>The beauty of the WebSocket protocol is also its ability to maintain a persistent connection through <em>control frames</em>.</p>

<p><a data-primary="control frames" data-type="indexterm" id="id895"/><em>Control frames</em> are special frames used to manage the connection:</p>
<dl>
<dt>Ping/pong frames</dt>
<dd>
<p>Used to check the connection’s status</p>
</dd>
<dt>Close frame</dt>
<dd>
<p>Used to terminate the connection gracefully</p>
</dd>
</dl>

<p>When it’s time to close the WebSocket connection, a close frame is sent by the client or the server.
The close frame can optionally specify a status code and/or a reason for closing the connection.
At this point, the WebSocket connection enters the <em>CLOSING</em> state.</p>

<p>The <em>CLOSING</em> state ends once the other party responds with another
close frame.
This concludes the full WebSocket connection lifecycle at the <em>CLOSED</em> state, as shown in
<a data-type="xref" href="#websocket_connection_lifecycle">Figure 6-6</a>.</p>

<figure><div class="figure" id="websocket_connection_lifecycle">
<img alt="bgai 0606" src="assets/bgai_0606.png"/>
<h6><span class="label">Figure 6-6. </span>WebSocket connection lifecycle</h6>
</div></figure>

<p>As you can see, using the WebSocket communication mechanism can be a bit of overkill for simple applications that won’t require the overheads.
For most GenAI applications, SSE connections may be enough.</p>

<p>However, there are GenAI use cases where WebSocket can shine, such as multimedia chat and voice-to-voice applications, collaborative GenAI apps, and real-time transcription services based on bidirectional communication.
To gain some hands-on experience, you will be building a speech-to-text application later in this chapter.<a data-startref="ix_ch06-asciidoc13" data-type="indexterm" id="id896"/><a data-startref="ix_ch06-asciidoc12" data-type="indexterm" id="id897"/><a data-startref="ix_ch06-asciidoc11" data-type="indexterm" id="id898"/></p>

<p>Now that you’ve learned about several unique web communication mechanisms for real-time applications, let’s quickly summarize how they all compare.</p>
</div></section>








<section class="less_space pagebreak-before" data-pdf-bookmark="Comparing Communication Mechanisms" data-type="sect2"><div class="sect2" id="id95">
<h2>Comparing Communication Mechanisms</h2>

<p><a data-primary="real-time communication with generative models" data-secondary="web communication mechanisms" data-tertiary="comparing communication mechanisms" data-type="indexterm" id="ix_ch06-asciidoc14"/><a data-primary="web communication mechanisms" data-secondary="comparing communication mechanisms" data-type="indexterm" id="ix_ch06-asciidoc15"/><a data-type="xref" href="#communication_mechanims_figure">Figure 6-7</a>
outlines the aforementioned five communication mechanisms used in web development.</p>

<figure><div class="figure" id="communication_mechanims_figure">
<img alt="bgai 0607" src="assets/bgai_0607.png"/>
<h6><span class="label">Figure 6-7. </span>Comparison of web communication mechanisms</h6>
</div></figure>

<p>As you can see from <a data-type="xref" href="#communication_mechanims_figure">Figure 6-7</a>, the messaging patterns differ in each approach.</p>

<p><em>HTTP request-response</em> is the most common model supported by all web clients and servers, suitable for RESTful APIs and services that don’t require real-time updates.</p>

<p><a data-primary="regular/short polling" data-type="indexterm" id="id899"/><em>Short/regular polling</em> involves clients checking for data at set intervals, which is straightforward but can be resource-intensive when scaling services.
It is normally used in applications to perform infrequent updates such as in analytics dashboards.</p>

<p><a data-primary="long polling" data-type="indexterm" id="id900"/><em>Long polling</em> is more efficient for real-time updates by keeping connections open until data is available on the server.
However, it can still drain the server resources, making it ideal for near-real-time features such as notifications.</p>

<p><a data-primary="Server Sent Events (SSE)" data-secondary="messaging patterns" data-type="indexterm" id="id901"/><em>SSE</em> maintains a single persistent connection that is server-to-client only, using the HTTP protocol.
It is straightforward to set up, leverages the browser’s <code>EventSource</code> API and ships with built-in features like reconnection.
These factors make SSE suitable for applications requiring live feeds, chat features, and real-time dashboards.</p>

<p><a data-primary="WebSocket (WS)" data-secondary="messaging patterns" data-type="indexterm" id="id902"/><em>WebSocket</em> provides full-duplex (double-sided) communication with low latency and binary data support, but is complex to implement.
It is widely used in applications requiring high interactivity and real-time data exchange, such as multiplayer games, chat applications, collaborative tools, and real-time transcription services.</p>

<p>With the invention of SSE and WebSocket and their rising popularity, short/regular polling and long polling are becoming less common real-time mechanisms in web applications.</p>

<p><a data-type="xref" href="#communication_mechanisms_table">Table 6-1</a> compares the features, challenges, and
applications for each mechanism in detail.</p>
<table class="striped" id="communication_mechanisms_table">
<caption><span class="label">Table 6-1. </span>Comparison of web communication mechanisms</caption>
<thead>
<tr>
<th>Communication mechanism</th>
<th>Features</th>
<th>Challenges</th>
<th>Applications</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>HTTP request-response</p></td>
<td><p>Simple request-and-response model, stateless protocol, supported by all web clients and servers</p></td>
<td><p>High latency for real-time updates, inefficient for frequent server-to-client data transfer</p></td>
<td><p>RESTful APIs, web services where real-time updates aren’t critical</p></td>
</tr>
<tr>
<td><p>Short/regular polling</p></td>
<td><p>Client regularly requests data at intervals, easy to implement</p></td>
<td><p>Wasteful of resources when there’s no new data, latency depends on poll intervals</p></td>
<td><p>Applications with infrequent updates, simple near-real-time dashboards, status
updates for submitted jobs</p></td>
</tr>
<tr>
<td><p>Long polling</p></td>
<td><p>More efficient than short polling for real-time
updates, maintains open connection until data is available</p></td>
<td><p>Can be resource-intensive on the server, complex to manage multiple
connections</p></td>
<td><p>Real-time notifications, older chat applications</p></td>
</tr>
<tr>
<td><p>Server-sent events</p></td>
<td><p>Single persistent connection for updates,
built-in reconnection and event ID support</p></td>
<td><p>Unidirectional communication from server to the client only</p></td>
<td><p>Live feeds, chat application, real-time analytics dashboards</p></td>
</tr>
<tr>
<td><p>WebSocket</p></td>
<td><p>Full-duplex communication, low latency, supports binary data</p></td>
<td><p>More complex to implement and manage, requires WebSocket support on the server</p></td>
<td><p>Multiplayer games, chat applications, collaborative editing tools, video
conferencing and webinar apps, real-time transcription and translation apps</p></td>
</tr>
</tbody>
</table>

<p>Having reviewed real-time communication mechanisms in detail, let’s dive deeper into SSE and WebSocket by implementing our own streaming endpoints using these two mechanisms.<a data-startref="ix_ch06-asciidoc15" data-type="indexterm" id="id903"/><a data-startref="ix_ch06-asciidoc14" data-type="indexterm" id="id904"/>
In the next section, you will learn how to implement streaming endpoints working with both technologies.<a data-startref="ix_ch06-asciidoc1" data-type="indexterm" id="id905"/></p>
</div></section>
</div></section>






<section data-pdf-bookmark="Implementing SSE Endpoints" data-type="sect1"><div class="sect1" id="id248">
<h1>Implementing SSE Endpoints</h1>

<p><a data-primary="real-time communication with generative models" data-secondary="implementing SSE endpoints" data-type="indexterm" id="ix_ch06-asciidoc16"/><a data-primary="Server Sent Events (SSE)" data-secondary="implementing SSE endpoints" data-type="indexterm" id="ix_ch06-asciidoc17"/>In <a data-type="xref" href="ch03.html#ch03">Chapter 3</a>, you learned about LLMs, which are <em>autoregressive</em> models that predict the next token based on previous inputs.
After each generation step, the output token is appended to the inputs and passed through the model again until a <code>&lt;stop&gt;</code> token is generated to break the loop.
Instead of waiting for the loop to finish, you can forward the output tokens as they’re being generated to the user as a data stream.</p>

<p>Model providers will normally expose an option for you to set the output mode as a data stream using <code>stream=True</code>.
With this option set, the model provider can return a data generator instead of the final output to you, which you can directly pass to your FastAPI server for streaming.</p>

<p>To demonstrate this in action, refer to <a data-type="xref" href="#async_azure_openai_client">Example 6-2</a>,
which implements an asynchronous data generator using the <code>openai</code> library.</p>
<div data-type="tip"><h6>Tip</h6>
<p>To run <a data-type="xref" href="#async_azure_openai_client">Example 6-2</a>, you will need to create an instance of Azure OpenAI on the Azure portal and create a model deployment.
Make note of API endpoint, key, and model deployment name.
For <a data-type="xref" href="#async_azure_openai_client">Example 6-2</a>, you can use the <code>2023-05-15</code> api version.</p>
</div>
<div data-type="example" id="async_azure_openai_client">
<h5><span class="label">Example 6-2. </span>Implementing Azure OpenAI async chat client for streaming responses</h5>

<pre data-code-language="python" data-type="programlisting"><code class="c1"># stream.py</code>

<code class="kn">import</code> <code class="nn">asyncio</code>
<code class="kn">import</code> <code class="nn">os</code>
<code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">AsyncGenerator</code>
<code class="kn">from</code> <code class="nn">openai</code> <code class="kn">import</code> <code class="n">AsyncAzureOpenAI</code>

<code class="k">class</code> <code class="nc">AzureOpenAIChatClient</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-1"><img alt="1" src="assets/1.png"/></a>
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">)</code><code class="p">:</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">aclient</code> <code class="o">=</code> <code class="n">AsyncAzureOpenAI</code><code class="p">(</code>
            <code class="n">api_key</code><code class="o">=</code><code class="n">os</code><code class="o">.</code><code class="n">environ</code><code class="p">[</code><code class="s2">"</code><code class="s2">OPENAI_API_KEY</code><code class="s2">"</code><code class="p">]</code><code class="p">,</code>
            <code class="n">api_version</code><code class="o">=</code><code class="n">os</code><code class="o">.</code><code class="n">environ</code><code class="p">[</code><code class="s2">"</code><code class="s2">OPENAI_API_VERSION</code><code class="s2">"</code><code class="p">]</code><code class="p">,</code>
            <code class="n">azure_endpoint</code><code class="o">=</code><code class="n">os</code><code class="o">.</code><code class="n">environ</code><code class="p">[</code><code class="s2">"</code><code class="s2">OPENAI_API_ENDPOINT</code><code class="s2">"</code><code class="p">]</code><code class="p">,</code>
            <code class="n">azure_deployment</code><code class="o">=</code><code class="n">os</code><code class="o">.</code><code class="n">environ</code><code class="p">[</code><code class="s2">"</code><code class="s2">OPENAI_API_DEPLOYMENT</code><code class="s2">"</code><code class="p">]</code><code class="p">,</code>
        <code class="p">)</code>

    <code class="k">async</code> <code class="k">def</code> <code class="nf">chat_stream</code><code class="p">(</code>
        <code class="bp">self</code><code class="p">,</code> <code class="n">prompt</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="n">model</code><code class="p">:</code> <code class="nb">str</code> <code class="o">=</code> <code class="s2">"</code><code class="s2">gpt-3.5-turbo</code><code class="s2">"</code>
    <code class="p">)</code> <code class="o">-</code><code class="o">&gt;</code> <code class="n">AsyncGenerator</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="kc">None</code><code class="p">]</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-2"><img alt="2" src="assets/2.png"/></a>
        <code class="n">stream</code> <code class="o">=</code> <code class="k">await</code> <code class="bp">self</code><code class="o">.</code><code class="n">aclient</code><code class="o">.</code><code class="n">chat</code><code class="o">.</code><code class="n">completions</code><code class="o">.</code><code class="n">create</code><code class="p">(</code>
            <code class="n">messages</code><code class="o">=</code><code class="p">[</code>
                <code class="p">{</code>
                    <code class="s2">"</code><code class="s2">role</code><code class="s2">"</code><code class="p">:</code> <code class="s2">"</code><code class="s2">user</code><code class="s2">"</code><code class="p">,</code>
                    <code class="s2">"</code><code class="s2">content</code><code class="s2">"</code><code class="p">:</code> <code class="n">prompt</code><code class="p">,</code>
                <code class="p">}</code>
            <code class="p">]</code><code class="p">,</code>
            <code class="n">model</code><code class="o">=</code><code class="n">model</code><code class="p">,</code>
            <code class="n">stream</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-3" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-3"><img alt="3" src="assets/3.png"/></a>
        <code class="p">)</code>

        <code class="k">async</code> <code class="k">for</code> <code class="n">chunk</code> <code class="ow">in</code> <code class="n">stream</code><code class="p">:</code>
            <code class="k">yield</code> <code class="sa">f</code><code class="s2">"</code><code class="s2">data: </code><code class="si">{</code><code class="n">chunk</code><code class="o">.</code><code class="n">choices</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">delta</code><code class="o">.</code><code class="n">content</code> <code class="ow">or</code> <code class="s1">'</code><code class="s1">'</code><code class="si">}</code><code class="se">\n</code><code class="se">\n</code><code class="s2">"</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-4" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-4"><img alt="4" src="assets/4.png"/></a>
            <code class="k">await</code> <code class="n">asyncio</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mf">0.05</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-5" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-5"><img alt="5" src="assets/5.png"/></a>

        <code class="k">yield</code> <code class="sa">f</code><code class="s2">"</code><code class="s2">data: [DONE]</code><code class="se">\n</code><code class="se">\n</code><code class="s2">"</code>


<code class="n">azure_chat_client</code> <code class="o">=</code> <code class="n">AzureOpenAIChatClient</code><code class="p">(</code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Create an asynchronous <code>AzureOpenAIChatClient</code> to interact with the Azure OpenAI API.
The chat client requires an API endpoint, deployment name, key, and version to function.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Define a <code>chat_stream</code> asynchronous generator method that yields each output token from the API.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-3" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-3"><img alt="3" src="assets/3.png"/></a></dt>
<dd><p>Set the <code>stream=True</code> to receive an output stream from the API instead of the full response at once.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-4" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-4"><img alt="4" src="assets/4.png"/></a></dt>
<dd><p>Loop over the stream and yield each output token or return an empty string if <code>delta.content</code> is empty.
The <code>data:</code> substring should be prefixed to each token so that browsers can correctly parse the content using the <code>EventSource</code> API.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-5" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-5"><img alt="5" src="assets/5.png"/></a></dt>
<dd><p>Slow down the streaming rate to reduce back pressure on the clients.</p></dd>
</dl></div>

<p>In <a data-type="xref" href="#async_azure_openai_client">Example 6-2</a>, you create an instance of
<code>AsyncAzureOpenAI</code>, which allows you to chat with the Azure OpenAI models via an API in your private Azure environment.</p>

<p>By setting the <code>stream=True</code>, <code>AsyncAzureOpenAI</code> returns a data stream (an async generator function) instead of the full model response.
You can loop over the data stream and <code>yield</code> tokens with the <code>data:</code> prefix to comply with the SSE specification.
This will let browsers to automatically parse the stream content using the widely available <code>EventSource</code> web API.<sup><a data-type="noteref" href="ch06.html#id906" id="id906-marker">3</a></sup></p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>When exposing streaming endpoints, you’ll need to consider how fast the clients can consume the data you’re sending them.
A good practice is to reduce the streaming rate as you saw in <a data-type="xref" href="#async_azure_openai_client">Example 6-2</a> to reduce the back pressure on clients.
You can adjust the throttling by testing your services with different clients on various devices.</p>
</div>








<section data-pdf-bookmark="SSE with GET Request" data-type="sect2"><div class="sect2" id="id443">
<h2>SSE with GET Request</h2>

<p>You can now implement the SSE endpoint by passing the chat stream to the FastAPI’s <code>StreamingResponse</code> as a <code>GET</code> endpoint, as shown in <a data-type="xref" href="#sse_endpoint">Example 6-3</a>.</p>
<div data-type="example" id="sse_endpoint">
<h5><span class="label">Example 6-3. </span>Implementing an SSE endpoint using the FastAPI’s <code>StreamingResponse</code></h5>

<pre data-code-language="python" data-type="programlisting"><code class="c1"># main.py</code>

<code class="kn">from</code> <code class="nn">fastapi</code><code class="nn">.</code><code class="nn">responses</code> <code class="kn">import</code> <code class="n">StreamingResponse</code>
<code class="kn">from</code> <code class="nn">stream</code> <code class="kn">import</code> <code class="n">azure_chat_client</code>

<code class="o">.</code><code class="o">.</code><code class="o">.</code>

<code class="nd">@app</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="s2">"</code><code class="s2">/generate/text/stream</code><code class="s2">"</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-1"><img alt="1" src="assets/1.png"/></a>
<code class="k">async</code> <code class="k">def</code> <code class="nf">serve_text_to_text_stream_controller</code><code class="p">(</code>
    <code class="n">prompt</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code>
<code class="p">)</code> <code class="o">-</code><code class="o">&gt;</code> <code class="n">StreamingResponse</code><code class="p">:</code>
    <code class="k">return</code> <code class="n">StreamingResponse</code><code class="p">(</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-2"><img alt="2" src="assets/2.png"/></a>
        <code class="n">azure_chat_client</code><code class="o">.</code><code class="n">chat_stream</code><code class="p">(</code><code class="n">prompt</code><code class="p">)</code><code class="p">,</code> <code class="n">media_type</code><code class="o">=</code><code class="s2">"</code><code class="s2">text/event-stream</code><code class="s2">"</code>
    <code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Implement an SSE endpoint with the <code>GET</code> method to use with the <code>EventSource</code> API on the browser.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Pass the chat stream generator to the <code>StreamingResponse</code> to forward the output stream as it is being generated to the client.
Set the <code>media_type=text/event-stream</code> as per SSE specifications so that the browsers can handle the response correctly.</p></dd>
</dl></div>

<p>With the <code>GET</code> endpoint set up on the server, you can create a simple HTML form on the client to consume the SSE stream via the <code>EventSource</code> interface, as shown in <a data-type="xref" href="#sse_client">Example 6-4</a>.</p>
<div data-type="tip"><h6>Tip</h6>
<p><a data-type="xref" href="#sse_client">Example 6-4</a> doesn’t use any JavaScript libraries or web frameworks.
However, there are libraries to assist you in implementing the
<code>EventSource</code> connection in any framework of your choice such as React, Vue, or SvelteKit.</p>
</div>
<div data-type="example" id="sse_client">
<h5><span class="label">Example 6-4. </span>Implementing SSE on the client using the browser <code>EventSource</code> API</h5>

<pre data-code-language="html" data-type="programlisting"><code>{# pages/client-sse.html #}

</code><code class="cp">&lt;!DOCTYPE html&gt;</code>
<code class="p">&lt;</code><code class="nt">html</code> <code class="na">lang</code><code class="o">=</code><code class="s">"en"</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">head</code><code class="p">&gt;</code>
    <code class="p">&lt;</code><code class="nt">title</code><code class="p">&gt;</code><code>SSE with EventSource API</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">title</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="p">/</code><code class="nt">head</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">body</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">button</code> <code class="na">id</code><code class="o">=</code><code class="s">"streambtn"</code><code class="p">&gt;</code><code>Start Streaming</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">button</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">label</code> <code class="na">for</code><code class="o">=</code><code class="s">"messageInput"</code><code class="p">&gt;</code><code>Enter your prompt:</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">label</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">input</code> <code class="na">type</code><code class="o">=</code><code class="s">"text"</code> <code class="na">id</code><code class="o">=</code><code class="s">"messageInput"</code> <code class="na">placeholder</code><code class="o">=</code><code class="s">"Enter your prompt"</code><code class="p">&gt;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-1"><img alt="1" src="assets/1.png"/></a>
<code class="p">&lt;</code><code class="nt">div</code> <code class="na">style</code><code class="o">=</code><code class="s">"padding-top: 10px"</code> <code class="na">id</code><code class="o">=</code><code class="s">"responseContainer"</code><code class="p">&gt;</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">div</code><code class="p">&gt;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-2"><img alt="2" src="assets/2.png"/></a>

<code class="p">&lt;</code><code class="nt">script</code><code class="p">&gt;</code>
    <code class="kd">let</code> <code class="nx">source</code><code class="p">;</code>
    <code class="kd">const</code> <code class="nx">button</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s1">'streambtn'</code><code class="p">)</code><code class="p">;</code>
    <code class="kd">const</code> <code class="nx">container</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s1">'container'</code><code class="p">)</code><code class="p">;</code>
    <code class="kd">const</code> <code class="nx">input</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s1">'messageInput'</code><code class="p">)</code><code class="p">;</code>

    <code class="kd">function</code> <code class="nx">resetForm</code><code class="p">(</code><code class="p">)</code><code class="p">{</code>
        <code class="nx">input</code><code class="p">.</code><code class="nx">value</code> <code class="o">=</code> <code class="s1">''</code><code class="p">;</code>
        <code class="nx">container</code><code class="p">.</code><code class="nx">textContent</code> <code class="o">=</code> <code class="s1">''</code><code class="p">;</code>
    <code class="p">}</code>

    <code class="kd">function</code> <code class="nx">handleOpen</code><code class="p">(</code><code class="p">)</code> <code class="p">{</code>
        <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'Connection was opened'</code><code class="p">)</code><code class="p">;</code>
    <code class="p">}</code>
    <code class="kd">function</code> <code class="nx">handleMessage</code><code class="p">(</code><code class="nx">e</code><code class="p">)</code><code class="p">{</code>
        <code class="k">if</code> <code class="p">(</code><code class="nx">e</code><code class="p">.</code><code class="nx">data</code> <code class="o">===</code> <code class="s1">'[DONE]'</code><code class="p">)</code> <code class="p">{</code>
            <code class="nx">source</code><code class="p">.</code><code class="nx">close</code><code class="p">(</code><code class="p">)</code><code class="p">;</code>
            <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'Connection was closed'</code><code class="p">)</code><code class="p">;</code>
            <code class="k">return</code><code class="p">;</code>
        <code class="p">}</code>

        <code class="nx">container</code><code class="p">.</code><code class="nx">textContent</code> <code class="o">+=</code> <code class="nx">e</code><code class="p">.</code><code class="nx">data</code><code class="p">;</code>
    <code class="p">}</code>
    <code class="kd">function</code> <code class="nx">handleClose</code><code class="p">(</code><code class="nx">e</code><code class="p">)</code><code class="p">{</code>
        <code class="nx">console</code><code class="p">.</code><code class="nx">error</code><code class="p">(</code><code class="nx">e</code><code class="p">)</code><code class="p">;</code>
        <code class="nx">source</code><code class="p">.</code><code class="nx">close</code><code class="p">(</code><code class="p">)</code>
    <code class="p">}</code>

    <code class="nx">button</code><code class="p">.</code><code class="nx">addEventListener</code><code class="p">(</code><code class="s1">'click'</code><code class="p">,</code> <code class="kd">function</code><code class="p">(</code><code class="p">)</code> <code class="p">{</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-3" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-3"><img alt="3" src="assets/3.png"/></a>
        <code class="kd">const</code> <code class="nx">message</code> <code class="o">=</code> <code class="nx">input</code><code class="p">.</code><code class="nx">value</code><code class="p">;</code>
        <code class="kd">const</code> <code class="nx">url</code> <code class="o">=</code> <code class="s1">'http://localhost:8000/generate/text/stream?prompt='</code> <code class="o">+</code>
            <code class="nb">encodeURIComponent</code><code class="p">(</code><code class="nx">message</code><code class="p">)</code><code class="p">;</code>
        <code class="nx">resetForm</code><code class="p">(</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-4" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-4"><img alt="4" src="assets/4.png"/></a>

        <code class="nx">source</code> <code class="o">=</code> <code class="ow">new</code> <code class="nx">EventSource</code><code class="p">(</code><code class="nx">url</code><code class="p">)</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-5" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-5"><img alt="5" src="assets/5.png"/></a>
        <code class="nx">source</code><code class="p">.</code><code class="nx">addEventListener</code><code class="p">(</code><code class="s1">'open'</code><code class="p">,</code> <code class="nx">handleOpen</code><code class="p">,</code> <code class="kc">false</code><code class="p">)</code><code class="p">;</code>
        <code class="nx">source</code><code class="p">.</code><code class="nx">addEventListener</code><code class="p">(</code><code class="s1">'message'</code><code class="p">,</code> <code class="nx">handleMessage</code><code class="p">,</code> <code class="kc">false</code><code class="p">)</code><code class="p">;</code>
        <code class="nx">source</code><code class="p">.</code><code class="nx">addEventListener</code><code class="p">(</code><code class="s1">'error'</code><code class="p">,</code> <code class="nx">handleClose</code><code class="p">,</code> <code class="kc">false</code><code class="p">)</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-6" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-6"><img alt="6" src="assets/6.png"/></a>
    <code class="p">}</code><code class="p">)</code><code class="p">;</code>

<code class="p">&lt;</code><code class="p">/</code><code class="nt">script</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="p">/</code><code class="nt">body</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="p">/</code><code class="nt">html</code><code class="p">&gt;</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Create a simple HTML input and button for initiating SSE requests.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Create an empty container to be used as a sink for the stream content.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-3" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-3"><img alt="3" src="assets/3.png"/></a></dt>
<dd><p>Listen for button <code>clicks</code> and run the SSE callback.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-4" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-4"><img alt="4" src="assets/4.png"/></a></dt>
<dd><p>Reset the content form and response container of previous content.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-5" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-5"><img alt="5" src="assets/5.png"/></a></dt>
<dd><p>Create a new <code>EventSource</code> object and listen to connection state changes to handle events.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-6" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-6"><img alt="6" src="assets/6.png"/></a></dt>
<dd><p>Log to console when an SSE connection is opened.
Handle each message by rendering message content to the response container until the <code>[DONE]</code> message is received, which signals that the connection should now be closed.
Additionally, close the connection if any errors occur and log the error to the browser’s 
<span class="keep-together">console.</span></p></dd>
</dl></div>

<p>With the SSE client implemented in <a data-type="xref" href="#sse_client">Example 6-4</a>, you can now use it to test your SSE endpoint.
However, you need to serve the HTML first.</p>

<p>Create a <code>pages</code> directory and then place the HTML file inside.
Then <em>mount</em> the directory onto your FastAPI server to serve its content as static files, as shown in <a data-type="xref" href="#mounting_static_files">Example 6-5</a>.
Via mounting, FastAPI takes care of mapping API paths to each file so that you can access them with a browser from the same origin as your server.</p>
<div data-type="example" id="mounting_static_files">
<h5><span class="label">Example 6-5. </span>Mounting HTML files on the server as static assets</h5>

<pre data-code-language="python" data-type="programlisting"><code class="c1"># main.py</code>

<code class="kn">from</code> <code class="nn">fastapi</code><code class="nn">.</code><code class="nn">staticfiles</code> <code class="kn">import</code> <code class="n">StaticFiles</code>

<code class="n">app</code><code class="o">.</code><code class="n">mount</code><code class="p">(</code><code class="s2">"</code><code class="s2">/pages</code><code class="s2">"</code><code class="p">,</code> <code class="n">StaticFiles</code><code class="p">(</code><code class="n">directory</code><code class="o">=</code><code class="s2">"</code><code class="s2">pages</code><code class="s2">"</code><code class="p">)</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"</code><code class="s2">pages</code><code class="s2">"</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO5-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO5-1"><img alt="1" src="assets/1.png"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO5-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO5-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Mount the <code>pages</code> directory onto the <code>/pages</code> to serve its content as static assets.
Once mounted, you can access each file by visiting
<code><em>&lt;origin&gt;</em>/pages/<em>&lt;filename&gt;</em></code>.</p></dd>
</dl></div>

<p>By implementing <a data-type="xref" href="#mounting_static_files">Example 6-5</a>, you serve the HTML from the same origin as your API server.
This avoids triggering the browser’s CORS security mechanism, which can block outgoing requests reaching your server.</p>

<p>You can now access the HTML page by visiting
<code>http://localhost:8000/pages/sse-client.html</code>.</p>










<section data-pdf-bookmark="Cross-origin resource sharing" data-type="sect3"><div class="sect3" id="id96">
<h3>Cross-origin resource sharing</h3>

<p><a data-primary="cross-origin resource sharing (CORS)" data-type="indexterm" id="ix_ch06-asciidoc18"/><a data-primary="CORS (cross-origin resource sharing)" data-type="indexterm" id="ix_ch06-asciidoc18a"/>If you try to open the <a data-type="xref" href="#sse_client">Example 6-4</a> HTML file in your browser directly and click the Start Streaming button, you will notice that nothing happens.
You can check the browser’s network tab to view what happened to the outgoing requests.</p>

<p>After some investigations, you should notice that your browser has blocked outgoing requests to your server as its preflight
<em>cross-origin resource sharing</em> (CORS) checks with your server have failed.</p>

<p>CORS is a security mechanism implemented in browsers to control how resources on a web page can be requested from another domain, and is relevant only when sending requests directly from the browser instead of a server.
Browsers use CORS to check whether they’re allowed to send requests to the server from a different origin (i.e., domain) than the server.</p>

<p>For example, if your client is hosted on <code>https://example.com</code> and it needs to fetch data from an API hosted on <code>https://api.example.com</code>, the browser will block this request unless the API server has CORS enabled.</p>

<p>For now, you can bypass these CORS errors by adding a CORS middleware on your server, as you can see in <a data-type="xref" href="#cors">Example 6-6</a>, to allow any incoming requests from browsers.</p>
<div data-type="example" id="cors">
<h5><span class="label">Example 6-6. </span>Apply CORS settings</h5>

<pre data-type="programlisting"># main.py

from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"], <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO6-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO6-1"><img alt="1" src="assets/1.png"/></a>
)</pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO6-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO6-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Allow incoming requests from any origins, methods (<code>GET</code>, <code>POST</code>, etc.) and 
<span class="keep-together">headers.</span></p></dd>
</dl></div>

<p>Streamlit avoids triggering the CORS mechanism by sending requests on its internal server even though the generated UI runs on the browser.</p>

<p>On the other hand, the FastAPI documentation page makes requests from the same origin as the server (i.e., <code>http://localhost:8000</code>), so requests by default don’t trigger the CORS security 
<span class="keep-together">mechanism.</span></p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>In <a data-type="xref" href="#cors">Example 6-6</a>, you configure the CORS middleware to process any incoming requests, effectively bypassing the CORS security mechanism for easier development.
In production, you should allow only a handful of origins, methods, and headers to be processed by your server.<a data-startref="ix_ch06-asciidoc18" data-type="indexterm" id="id907"/><a data-startref="ix_ch06-asciidoc18a" data-type="indexterm" id="id908"/></p>
</div>

<p>If you followed Example <a data-type="xref" data-xrefstyle="select:labelnumber" href="#mounting_static_files">6-5</a> or <a data-type="xref" data-xrefstyle="select:labelnumber" href="#cors">6-6</a>,  you should now be able to view the incoming stream from your SSE endpoint (see <a data-type="xref" href="#sse_results">Figure 6-8</a>).</p>

<figure><div class="figure" id="sse_results">
<img alt="bgai 0608" src="assets/bgai_0608.png"/>
<h6><span class="label">Figure 6-8. </span>Incoming stream from the SSE endpoint</h6>
</div></figure>

<p>Congratulations!
You now have a full working solution where model responses are directly streamed to your client as soon as generated data becomes available.
By implementing this feature, your users will now have a more pleasant experience interacting with your chatbot as they receive responses to their queries in real time.</p>

<p>Your solution also implemented concurrency using an asynchronous client for interacting with the Azure OpenAI API to stream faster responses to your users.
You can try using a synchronous client to compare the differences in generation speeds.
With an asynchronous client, the generation speed can be so fast that you will receive a block of text at once even though it is actually being streamed to the browser.</p>
</div></section>










<section data-pdf-bookmark="Streaming LLM outputs from Hugging Face models" data-type="sect3"><div class="sect3" id="id97">
<h3>Streaming LLM outputs from Hugging Face models</h3>

<p><a data-primary="Hugging Face models, streaming LLM outputs from" data-type="indexterm" id="ix_ch06-asciidoc19"/><a data-primary="large language models (LLMs)" data-secondary="streaming LLM outputs from Hugging Face models" data-type="indexterm" id="ix_ch06-asciidoc20"/>Now that you’ve learned how to implement SSE endpoints with model providers such as Azure OpenAI, you may be wondering if you can stream model outputs from open source models you’ve previously downloaded from Hugging Face.</p>

<p>Although Hugging Face’s <code>transformers</code> library implements a <code>TextStreamer</code>
component that you can pass to your model pipeline, the easiest solution is to run a separate inference server such as HF Inference Server to implement model streaming.</p>

<p><a data-type="xref" href="#hf_llm_inference_server">Example 6-7</a> shows how to set up a simple model inference server using Docker by providing a <code>model-id</code>.</p>
<div data-type="example" id="hf_llm_inference_server">
<h5><span class="label">Example 6-7. </span>Serving HF LLM models via HF Inference Server</h5>

<pre data-code-language="bash" data-type="programlisting"><code>$</code> <code>docker</code> <code>run</code> <code>--runtime</code> <code>nvidia</code> <code>--gpus</code> <code>all</code> <code class="se">\ </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-1"><img alt="1" src="assets/1.png"/></a>
    <code>-v</code> <code>~/.cache/huggingface:/root/.cache/huggingface</code> <code class="se">\ </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-2"><img alt="2" src="assets/2.png"/></a>
    <code>--env</code> <code class="s2">"HUGGING_FACE_HUB_TOKEN=&lt;secret&gt;"</code> <code class="se">\ </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-3" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-3"><img alt="3" src="assets/3.png"/></a>
    <code>-p</code> <code class="m">8080</code><code>:8000</code> <code class="se">\ </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-4" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-4"><img alt="4" src="assets/4.png"/></a>
    <code>--ipc</code><code class="o">=</code><code>host</code> <code class="se">\ </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-5" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-5"><img alt="5" src="assets/5.png"/></a>
    <code>vllm/vllm-openai:latest</code> <code class="se">\ </code><a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-6"><img alt="1" src="assets/1.png"/></a> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-6" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-7"><img alt="6" src="assets/6.png"/></a>
    <code>--model</code> <code>mistralai/Mistral-7B-v0.1</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-7" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-8"><img alt="7" src="assets/7.png"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Use Docker to download and run the latest <code>vllm/vllm-openai</code> container on all available NVIDIA GPUs.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Share a volume with the Docker container to avoid downloading weights every run.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-3" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-3"><img alt="3" src="assets/3.png"/></a></dt>
<dd><p>Set the secret environment variable to access gated models like <code>mistralai/Mistral-7B-v0.1</code>.<sup><a data-type="noteref" href="ch06.html#id909" id="id909-marker">4</a></sup></p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-4" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-4"><img alt="4" src="assets/4.png"/></a></dt>
<dd><p>Run the inference server on localhost port <code>8080</code> by mapping host port <code>8080</code> to exposed Docker container port <code>8000</code>.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-5" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-5"><img alt="5" src="assets/5.png"/></a></dt>
<dd><p>Enable inter-process communication (IPC) between the container and the host to allow the container to access the host’s shared memory.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-7" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-6"><img alt="6" src="assets/6.png"/></a></dt>
<dd><p>The vLLM inference server uses the OpenAI API Specification for LLM serving.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-8" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-7"><img alt="7" src="assets/7.png"/></a></dt>
<dd><p>Download and use the gated <code>mistralai/Mistral-7B-v0.1</code> from Hugging Face Hub.</p></dd>
</dl></div>

<p>With the model server running, you can now use an <code>AsyncInferenceClient</code> to generate outputs in a streaming format, as shown in <a data-type="xref" href="#hf_llm_streaming">Example 6-8</a>.</p>
<div data-type="example" id="hf_llm_streaming">
<h5><span class="label">Example 6-8. </span>Consuming the LLM output stream from HF Inference Stream</h5>

<pre data-type="programlisting">import asyncio
from typing import AsyncGenerator
from huggingface_hub import AsyncInferenceClient

client = AsyncInferenceClient("http://localhost:8080")

async def chat_stream(prompt: str) -&gt; AsyncGenerator[str, None]:
    stream = await client.text_generation(prompt, stream=True)
    async for token in stream:
        yield token
        await asyncio.sleep(0.05)</pre></div>

<p>While <a data-type="xref" href="#hf_llm_streaming">Example 6-8</a> shows how to use the Hugging Face inference server, you can still use other model-serving frameworks such as <a href="https://oreil.ly/LQAzF">vLLM</a> that support streaming model responses.<a data-startref="ix_ch06-asciidoc20" data-type="indexterm" id="id910"/><a data-startref="ix_ch06-asciidoc19" data-type="indexterm" id="id911"/></p>

<p>Before we move on to talking about WebSocket, let’s look at consuming another variant of SSE endpoints using the <code>POST</code> method.</p>
</div></section>
</div></section>








<section data-pdf-bookmark="SSE with POST Request" data-type="sect2"><div class="sect2" id="id98">
<h2>SSE with POST Request</h2>

<p><a data-primary="POST request, SSE with" data-type="indexterm" id="ix_ch06-asciidoc21"/><a data-primary="Server Sent Events (SSE)" data-secondary="with POST request" data-type="indexterm" id="ix_ch06-asciidoc22"/>The <a href="https://oreil.ly/61ovi"><code>EventSource</code> specification</a> expects <code>GET</code> endpoints on the server to correctly consume the incoming SSE stream.
This makes implementing real-time applications with SSE straightforward as the
<code>EventSource</code> interface can handle issues such as connection drops and automatic reconnection.</p>

<p>However, using HTTP <code>GET</code> requests comes with its own limitations.
<code>GET</code> requests are normally less secure than other request methods and more vulnerable to <em>XSS</em> attacks.<sup><a data-type="noteref" href="ch06.html#id912" id="id912-marker">5</a></sup>
In addition, since <code>GET</code> requests can’t have any request body, you can only transfer data as part of the URL’s query parameters to the server.
The issue is that there is a URL length limit you need to consider and any query parameters must be encoded correctly into the request URL.
Therefore, you can’t just append the whole conversation history to the URL as a parameter.
Your server must handle maintaining the history of the conversation and keeping track of conversational context with <code>GET</code> SSE 
<span class="keep-together">endpoints.</span></p>

<p>A common workaround to the aforementioned limitation is to implement a <code>POST</code> SSE endpoint even if the SSE specification doesn’t support it.
As a result, the implementation will be more complex.</p>

<p>First let’s implement the <code>POST</code> endpoint on the server in <a data-type="xref" href="#sse_server_post">Example 6-9</a>.</p>
<div data-type="example" id="sse_server_post">
<h5><span class="label">Example 6-9. </span>Implementing SSE endpoint on the server</h5>

<pre data-code-language="python" data-type="programlisting"><code class="c1"># main.py</code>

<code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">Annotated</code>
<code class="kn">from</code> <code class="nn">fastapi</code> <code class="kn">import</code> <code class="n">Body</code><code class="p">,</code> <code class="n">FastAPI</code>
<code class="kn">from</code> <code class="nn">fastapi.responses</code> <code class="kn">import</code> <code class="n">StreamingResponse</code>
<code class="kn">from</code> <code class="nn">stream</code> <code class="kn">import</code> <code class="n">azure_chat_client</code>

<code class="nd">@app</code><code class="o">.</code><code class="n">post</code><code class="p">(</code><code class="s2">"/generate/text/stream"</code><code class="p">)</code>
<code class="k">async</code> <code class="k">def</code> <code class="nf">serve_text_to_text_stream_controller</code><code class="p">(</code>
    <code class="n">prompt</code><code class="p">:</code> <code class="n">Annotated</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">Body</code><code class="p">()]</code>
<code class="p">)</code> <code class="o">-&gt;</code> <code class="n">StreamingResponse</code><code class="p">:</code>
    <code class="k">return</code> <code class="n">StreamingResponse</code><code class="p">(</code>
        <code class="n">azure_chat_client</code><code class="o">.</code><code class="n">chat_stream</code><code class="p">(</code><code class="n">prompt</code><code class="p">),</code> <code class="n">media_type</code><code class="o">=</code><code class="s2">"text/event-stream"</code>
    <code class="p">)</code></pre></div>

<p>With the <code>POST</code> endpoint for streaming chat outputs implemented, you can now develop the client logic to process the SSE stream.</p>

<p>You will have to manually process the incoming streaming yourself using the browser’s <code>fetch</code> web interface, as shown in <a data-type="xref" href="#sse_client_post">Example 6-10</a>.</p>
<div data-type="example" id="sse_client_post">
<h5><span class="label">Example 6-10. </span>Implementing SSE on the client using the browser <code>EventSource</code> API</h5>

<pre data-code-language="html" data-type="programlisting"><code>{# pages/client-sse-post.html #}

</code><code class="cp">&lt;!DOCTYPE html&gt;</code>
<code class="p">&lt;</code><code class="nt">html</code> <code class="na">lang</code><code class="o">=</code><code class="s">"en"</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">head</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">title</code><code class="p">&gt;</code><code>SSE With Post Request</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">title</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="p">/</code><code class="nt">head</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">body</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">button</code> <code class="na">id</code><code class="o">=</code><code class="s">"streambtn"</code><code class="p">&gt;</code><code>Start Streaming</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">button</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">label</code> <code class="na">for</code><code class="o">=</code><code class="s">"messageInput"</code><code class="p">&gt;</code><code>Enter your prompt:</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">label</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">input</code> <code class="na">type</code><code class="o">=</code><code class="s">"text"</code> <code class="na">id</code><code class="o">=</code><code class="s">"messageInput"</code> <code class="na">placeholder</code><code class="o">=</code><code class="s">"Enter message"</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">div</code> <code class="na">style</code><code class="o">=</code><code class="s">"padding-top: 10px"</code> <code class="na">id</code><code class="o">=</code><code class="s">"container"</code><code class="p">&gt;</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">div</code><code class="p">&gt;</code>

<code class="p">&lt;</code><code class="nt">script</code><code class="p">&gt;</code>
    <code class="kd">const</code> <code class="nx">button</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s1">'streambtn'</code><code class="p">)</code><code class="p">;</code>
    <code class="kd">const</code> <code class="nx">container</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s1">'container'</code><code class="p">)</code><code class="p">;</code>
    <code class="kd">const</code> <code class="nx">input</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s1">'messageInput'</code><code class="p">)</code><code class="p">;</code>

    <code class="kd">function</code> <code class="nx">resetForm</code><code class="p">(</code><code class="p">)</code><code class="p">{</code>
        <code class="nx">input</code><code class="p">.</code><code class="nx">value</code> <code class="o">=</code> <code class="s1">''</code><code class="p">;</code>
        <code class="nx">container</code><code class="p">.</code><code class="nx">textContent</code> <code class="o">=</code> <code class="s1">''</code><code class="p">;</code>
    <code class="p">}</code>

    <code class="k">async</code> <code class="kd">function</code> <code class="nx">stream</code><code class="p">(</code><code class="nx">message</code><code class="p">)</code><code class="p">{</code>
        <code class="kd">const</code> <code class="nx">response</code> <code class="o">=</code> <code class="k">await</code> <code class="nx">fetch</code><code class="p">(</code><code class="s1">'http://localhost:8000/generate/text/stream'</code><code class="p">,</code> <code class="p">{</code>
            <code class="nx">method</code><code class="o">:</code> <code class="s2">"POST"</code><code class="p">,</code>
            <code class="nx">cache</code><code class="o">:</code> <code class="s2">"no-cache"</code><code class="p">,</code>
            <code class="nx">keepalive</code><code class="o">:</code> <code class="kc">true</code><code class="p">,</code>
            <code class="nx">headers</code><code class="o">:</code> <code class="p">{</code>
                <code class="s2">"Content-Type"</code><code class="o">:</code> <code class="s2">"application/json"</code><code class="p">,</code>
                <code class="s2">"Accept"</code><code class="o">:</code> <code class="s2">"text/event-stream"</code><code class="p">,</code>
            <code class="p">}</code><code class="p">,</code>
            <code class="nx">body</code><code class="o">:</code> <code class="nb">JSON</code><code class="p">.</code><code class="nx">stringify</code><code class="p">(</code><code class="p">{</code>
                <code class="nx">prompt</code><code class="o">:</code> <code class="nx">message</code><code class="p">,</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-1"><img alt="1" src="assets/1.png"/></a>
            <code class="p">}</code><code class="p">)</code><code class="p">,</code>
        <code class="p">}</code><code class="p">)</code><code class="p">;</code>

        <code class="kd">const</code> <code class="nx">reader</code> <code class="o">=</code> <code class="nx">response</code><code class="p">.</code><code class="nx">body</code><code class="p">.</code><code class="nx">getReader</code><code class="p">(</code><code class="p">)</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-2"><img alt="2" src="assets/2.png"/></a>
        <code class="kd">const</code> <code class="nx">decoder</code> <code class="o">=</code> <code class="ow">new</code> <code class="nx">TextDecoder</code><code class="p">(</code><code class="p">)</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-3" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-3"><img alt="3" src="assets/3.png"/></a>

        <code class="k">while</code> <code class="p">(</code><code class="kc">true</code><code class="p">)</code> <code class="p">{</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-4" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-4"><img alt="4" src="assets/4.png"/></a>
            <code class="kd">const</code> <code class="p">{</code><code class="nx">value</code><code class="p">,</code> <code class="nx">done</code><code class="p">}</code> <code class="o">=</code> <code class="k">await</code> <code class="nx">reader</code><code class="p">.</code><code class="nx">read</code><code class="p">(</code><code class="p">)</code><code class="p">;</code>
            <code class="k">if</code> <code class="p">(</code><code class="nx">done</code><code class="p">)</code> <code class="k">break</code><code class="p">;</code>
            <code class="nx">container</code><code class="p">.</code><code class="nx">textContent</code> <code class="o">+=</code> <code class="nx">decoder</code><code class="p">.</code><code class="nx">decode</code><code class="p">(</code><code class="nx">value</code><code class="p">)</code><code class="p">;</code>
        <code class="p">}</code>
    <code class="p">}</code>

    <code class="nx">button</code><code class="p">.</code><code class="nx">addEventListener</code><code class="p">(</code><code class="s1">'click'</code><code class="p">,</code> <code class="k">async</code> <code class="kd">function</code><code class="p">(</code><code class="p">)</code> <code class="p">{</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-5" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-5"><img alt="5" src="assets/5.png"/></a>
        <code class="nx">resetForm</code><code class="p">(</code><code class="p">)</code>
        <code class="k">await</code> <code class="nx">stream</code><code class="p">(</code><code class="nx">input</code><code class="p">.</code><code class="nx">value</code><code class="p">)</code>

    <code class="p">}</code><code class="p">)</code><code class="p">;</code>

<code class="p">&lt;</code><code class="p">/</code><code class="nt">script</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="p">/</code><code class="nt">body</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="p">/</code><code class="nt">html</code><code class="p">&gt;</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Send a <code>POST</code> request to the backend using the browser’s <code>fetch</code> interface.
Prepare the body as a JSON string as part of the request.
Add headers to specify the request body being sent and the response that is expected from the server.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Access the <code>reader</code> of the stream from the response body stream.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-3" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-3"><img alt="3" src="assets/3.png"/></a></dt>
<dd><p>Create an instance of a text decoder for processing each message.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-4" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-4"><img alt="4" src="assets/4.png"/></a></dt>
<dd><p>Run an infinite loop and read the next message in the stream using the
<code>reader</code>.
If the stream has ended, <code>done=true</code>, so break the loop; otherwise, decode the message with the text decoder and append to the response container’s
<code>textContent</code> to render.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-5" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-5"><img alt="5" src="assets/5.png"/></a></dt>
<dd><p>Listen on button <code>click</code> events to run a callback that resets the form state and makes the SSE connection with the backend endpoint with a prompt.</p></dd>
</dl></div>

<p>As you can see from <a data-type="xref" href="#sse_client_post">Example 6-10</a>, consuming the SSE stream without the

<span class="keep-together"><code>EventSource</code></span> can become complex.</p>
<div data-type="tip"><h6>Tip</h6>
<p>An alternative to <a data-type="xref" href="#sse_client_post">Example 6-10</a> is to use <code>GET</code> SSE endpoints but send the large payload to the server beforehand using a <code>POST</code> request.
The server stores the data and uses it when the SSE connection is established.</p>

<p>SSE also supports cookies, so you can rely on cookies to exchange large payloads in <code>GET</code> SSE endpoints.</p>
</div>

<p>If you want to consume the SSE endpoint in production, your solution should also support retry functionality, error handling, or even the ability to abort connections.</p>

<p><a data-primary="exponential backoff" data-type="indexterm" id="id913"/><a data-type="xref" href="#sse_retry">Example 6-11</a> demonstrates how to implement a client-side retry functionality with an <em>exponential backoff delay</em> in JavaScript.<sup><a data-type="noteref" href="ch06.html#id914" id="id914-marker">6</a></sup></p>
<div data-type="example" id="sse_retry">
<h5><span class="label">Example 6-11. </span>Implementing client-side retry functionality with exponential backoff</h5>

<pre data-code-language="javascript" data-type="programlisting"><code class="c1">// pages/client-sse-post.html within &lt;script&gt; tag
</code>
<code class="kd">function</code> <code class="nx">sleep</code><code class="p">(</code><code class="nx">ms</code><code class="p">)</code> <code class="p">{</code>
    <code class="k">return</code> <code class="k">new</code> <code class="nb">Promise</code><code class="p">(</code><code class="nx">resolve</code> <code class="o">=&gt;</code> <code class="nx">setTimeout</code><code class="p">(</code><code class="nx">resolve</code><code class="p">,</code> <code class="nx">ms</code><code class="p">)</code><code class="p">)</code><code class="p">;</code>
<code class="p">}</code>

<code class="nx">async</code> <code class="kd">function</code> <code class="nx">stream</code><code class="p">(</code>
    <code class="nx">message</code><code class="p">,</code>
    <code class="nx">maxRetries</code> <code class="o">=</code> <code class="mi">3</code><code class="p">,</code>
    <code class="nx">initialDelay</code> <code class="o">=</code> <code class="mi">1000</code><code class="p">,</code>
    <code class="nx">backoffFactor</code> <code class="o">=</code> <code class="mi">2</code><code class="p">,</code>
<code class="p">)</code> <code class="p">{</code>
    <code class="kd">let</code> <code class="nx">delay</code> <code class="o">=</code> <code class="nx">initialDelay</code><code class="p">;</code>
    <code class="k">for</code> <code class="p">(</code><code class="kd">let</code> <code class="nx">attempt</code> <code class="o">=</code> <code class="mi">0</code><code class="p">;</code> <code class="nx">attempt</code> <code class="o">&lt;</code> <code class="nx">maxRetries</code><code class="p">;</code> <code class="nx">attempt</code><code class="o">++</code><code class="p">)</code> <code class="p">{</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-1"><img alt="1" src="assets/1.png"/></a>
        <code class="k">try</code> <code class="p">{</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-2"><img alt="2" src="assets/2.png"/></a>
            <code class="p">...</code> <code class="c1">// Establish SSE connection here
</code>            <code class="k">return</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-3" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-3"><img alt="3" src="assets/3.png"/></a>
        <code class="p">}</code> <code class="k">catch</code> <code class="p">(</code><code class="nx">error</code><code class="p">)</code> <code class="p">{</code>
            <code class="nx">console</code><code class="p">.</code><code class="nx">warn</code><code class="p">(</code><code class="sb">`</code><code class="sb">Failed to establish SSE connection: </code><code class="si">${</code><code class="nx">error</code><code class="si">}</code><code class="sb">`</code><code class="p">)</code><code class="p">;</code>
            <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code>
                <code class="sb">`</code><code class="sb">Re-establishing connection - attempt number </code><code class="si">${</code><code class="nx">attempt</code> <code class="o">+</code> <code class="mi">1</code><code class="si">}</code><code class="sb">`</code><code class="p">,</code>
            <code class="p">)</code><code class="p">;</code>
            <code class="k">if</code> <code class="p">(</code><code class="nx">attempt</code> <code class="o">&lt;</code> <code class="nx">maxRetries</code> <code class="o">-</code> <code class="mi">1</code><code class="p">)</code> <code class="p">{</code>
                <code class="nx">await</code> <code class="nx">sleep</code><code class="p">(</code><code class="nx">delay</code><code class="p">)</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-4" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-4"><img alt="4" src="assets/4.png"/></a>
                <code class="nx">delay</code> <code class="o">*=</code> <code class="nx">backoffFactor</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-5" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-5"><img alt="5" src="assets/5.png"/></a>
            <code class="p">}</code> <code class="k">else</code> <code class="p">{</code>
                <code class="k">throw</code> <code class="nx">error</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-6" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-6"><img alt="6" src="assets/6.png"/></a>
            <code class="p">}</code>
        <code class="p">}</code>
    <code class="p">}</code>
<code class="p">}</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>As long as <code>maxRetries</code> isn’t reached, attempt to establish the SSE connection.
Count each attempt.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Use a <code>try</code> and <code>catch</code> to handle connection errors.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-3" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-3"><img alt="3" src="assets/3.png"/></a></dt>
<dd><p>Exit the function if successful.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-4" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-4"><img alt="4" src="assets/4.png"/></a></dt>
<dd><p>Pause in <code>delay</code> milliseconds before retrying.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-5" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-5"><img alt="5" src="assets/5.png"/></a></dt>
<dd><p>Implement exponential backoff by multiplying a backoff factor to the delay value in each iteration.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-6" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-6"><img alt="6" src="assets/6.png"/></a></dt>
<dd><p>Rethrow the <code>error</code> if <code>maxRetries</code> is reached.</p></dd>
</dl></div>

<p>You should now feel more comfortable implementing your own SSE endpoints for streaming model responses.
SSE is the go-to communication mechanism that applications like ChatGPT use for real-time conversations with the model.
Since SSE predominantly supports text-based streams, it is ideal for LLM output streaming scenarios.<a data-startref="ix_ch06-asciidoc22" data-type="indexterm" id="id915"/><a data-startref="ix_ch06-asciidoc21" data-type="indexterm" id="id916"/></p>

<p>In the next section, we’re going to implement the same solution using the WebSocket mechanism so that you can compare differences in the implementation details.
In addition, you’re going to learn what makes WebSocket ideal for scenarios that require real-time duplex communication such as in live transcription services.<a data-startref="ix_ch06-asciidoc17" data-type="indexterm" id="id917"/><a data-startref="ix_ch06-asciidoc16" data-type="indexterm" id="id918"/></p>
</div></section>
</div></section>






<section data-pdf-bookmark="Implementing WS Endpoints" data-type="sect1"><div class="sect1" id="id249">
<h1>Implementing WS Endpoints</h1>

<p><a data-primary="real-time communication with generative models" data-secondary="implementing WS endpoints" data-type="indexterm" id="ix_ch06-asciidoc23"/><a data-primary="WebSocket (WS)" data-secondary="implementing endpoints with WS protocol" data-type="indexterm" id="ix_ch06-asciidoc24"/>In this section, you’re going to implement an endpoint using the WebSocket protocol.
With this endpoint, you will stream the LLM outputs to the client using WebSocket to compare with the SSE connection.
By the end, you will learn the differences and similarities between SSE and WebSocket in streaming LLM outputs in real time.</p>








<section data-pdf-bookmark="Streaming LLM Outputs with WebSocket" data-type="sect2"><div class="sect2" id="id99">
<h2>Streaming LLM Outputs with WebSocket</h2>

<p><a data-primary="real-time communication with generative models" data-secondary="implementing WS endpoints" data-tertiary="streaming LLM outputs with WS" data-type="indexterm" id="ix_ch06-asciidoc25"/><a data-primary="WebSocket (WS)" data-secondary="implementing endpoints with WS protocol" data-tertiary="streaming LLM outputs with WS" data-type="indexterm" id="ix_ch06-asciidoc26"/>FastAPI supports WebSocket through the use of the <code>WebSocket</code> interface from the Starlette web framework.
As WebSocket connections need to be managed, let’s start by implementing a connection manager to keep track of active connections and managing their states.</p>

<p><a data-primary="WebSocket (WS)" data-secondary="connection manager" data-type="indexterm" id="id919"/>You can implement a WebSocket connection manager by following
<a data-type="xref" href="#websockets_manager">Example 6-12</a>.</p>
<div data-type="example" id="websockets_manager">
<h5><span class="label">Example 6-12. </span>Implementing a WebSocket connection manager</h5>

<pre data-code-language="python" data-type="programlisting"><code class="c1"># stream.py</code>

<code class="kn">from</code> <code class="nn">fastapi</code><code class="nn">.</code><code class="nn">websockets</code> <code class="kn">import</code> <code class="n">WebSocket</code>

<code class="k">class</code> <code class="nc">WSConnectionManager</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-1"><img alt="1" src="assets/1.png"/></a>
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">)</code> <code class="o">-</code><code class="o">&gt;</code> <code class="kc">None</code><code class="p">:</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">active_connections</code><code class="p">:</code> <code class="nb">list</code><code class="p">[</code><code class="n">WebSocket</code><code class="p">]</code> <code class="o">=</code> <code class="p">[</code><code class="p">]</code>

    <code class="k">async</code> <code class="k">def</code> <code class="nf">connect</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">websocket</code><code class="p">:</code> <code class="n">WebSocket</code><code class="p">)</code> <code class="o">-</code><code class="o">&gt;</code> <code class="kc">None</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-2"><img alt="2" src="assets/2.png"/></a>
        <code class="k">await</code> <code class="n">websocket</code><code class="o">.</code><code class="n">accept</code><code class="p">(</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">active_connections</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">websocket</code><code class="p">)</code>

    <code class="k">async</code> <code class="k">def</code> <code class="nf">disconnect</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">websocket</code><code class="p">:</code> <code class="n">WebSocket</code><code class="p">)</code> <code class="o">-</code><code class="o">&gt;</code> <code class="kc">None</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-3" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-3"><img alt="3" src="assets/3.png"/></a>
        <code class="bp">self</code><code class="o">.</code><code class="n">active_connections</code><code class="o">.</code><code class="n">remove</code><code class="p">(</code><code class="n">websocket</code><code class="p">)</code>
        <code class="k">await</code> <code class="n">websocket</code><code class="o">.</code><code class="n">close</code><code class="p">(</code><code class="p">)</code>

    <code class="nd">@staticmethod</code>
    <code class="k">async</code> <code class="k">def</code> <code class="nf">receive</code><code class="p">(</code><code class="n">websocket</code><code class="p">:</code> <code class="n">WebSocket</code><code class="p">)</code> <code class="o">-</code><code class="o">&gt;</code> <code class="nb">str</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-4" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-4"><img alt="4" src="assets/4.png"/></a>
        <code class="k">return</code> <code class="k">await</code> <code class="n">websocket</code><code class="o">.</code><code class="n">receive_text</code><code class="p">(</code><code class="p">)</code>

    <code class="nd">@staticmethod</code>
    <code class="k">async</code> <code class="k">def</code> <code class="nf">send</code><code class="p">(</code>
        <code class="n">message</code><code class="p">:</code> <code class="nb">str</code> <code class="o">|</code> <code class="nb">bytes</code> <code class="o">|</code> <code class="nb">list</code> <code class="o">|</code> <code class="nb">dict</code><code class="p">,</code> <code class="n">websocket</code><code class="p">:</code> <code class="n">WebSocket</code>
    <code class="p">)</code> <code class="o">-</code><code class="o">&gt;</code> <code class="kc">None</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-5" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-5"><img alt="5" src="assets/5.png"/></a>
        <code class="k">if</code> <code class="nb">isinstance</code><code class="p">(</code><code class="n">message</code><code class="p">,</code> <code class="nb">str</code><code class="p">)</code><code class="p">:</code>
            <code class="k">await</code> <code class="n">websocket</code><code class="o">.</code><code class="n">send_text</code><code class="p">(</code><code class="n">message</code><code class="p">)</code>
        <code class="k">elif</code> <code class="nb">isinstance</code><code class="p">(</code><code class="n">message</code><code class="p">,</code> <code class="nb">bytes</code><code class="p">)</code><code class="p">:</code>
            <code class="k">await</code> <code class="n">websocket</code><code class="o">.</code><code class="n">send_bytes</code><code class="p">(</code><code class="n">message</code><code class="p">)</code>
        <code class="k">else</code><code class="p">:</code>
            <code class="k">await</code> <code class="n">websocket</code><code class="o">.</code><code class="n">send_json</code><code class="p">(</code><code class="n">message</code><code class="p">)</code>


<code class="n">ws_manager</code> <code class="o">=</code> <code class="n">WSConnectionManager</code><code class="p">(</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-6" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-6"><img alt="6" src="assets/6.png"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Create a <code>WSConnectionManager</code> to track and handle active WS connections.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Open a WebSocket connection using the <code>accept()</code> method.
Add the new connection to the list of active connections.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-3" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-3"><img alt="3" src="assets/3.png"/></a></dt>
<dd><p>When disconnecting, close the connection and remove the <code>websocket</code>
instance from the active connections list.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-4" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-4"><img alt="4" src="assets/4.png"/></a></dt>
<dd><p>Receive incoming messages as text during an open connection.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-5" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-5"><img alt="5" src="assets/5.png"/></a></dt>
<dd><p>Send messages to the client using the relevant send method.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-6" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-6"><img alt="6" src="assets/6.png"/></a></dt>
<dd><p>Create a single instance of the <code>WSConnectionManager</code> to reuse across the app.</p></dd>
</dl></div>

<p>You can also extend the connection manager in <a data-type="xref" href="#websockets_manager">Example 6-12</a> to <em>broadcast</em> messages (e.g., real-time system alerts, notifications, or updates) to all connected clients.
This is useful in applications such as group chats or collaborative whiteboard/document editing tools.</p>

<p>As the connection manager maintains a pointer to every client via the <code>active_​con⁠nec⁠tions</code> list, you can broadcast messages to each client, as shown in <a data-type="xref" href="#websockets_broadcast">Example 6-13</a>.</p>
<div data-type="example" id="websockets_broadcast">
<h5><span class="label">Example 6-13. </span>Broadcasting messages to connected clients using the WebSocket manager</h5>

<pre data-type="programlisting"># stream.py

from fastapi.websockets import WebSocket

class WSConnectionManager:
    ...
    async def broadcast(self, message: str | bytes | list | dict) -&gt; None:
        for connection in self.active_connections:
            await self.send(message, connection)</pre></div>

<p>With the WebSocket manager implemented, you can now develop a WebSocket endpoint to stream responses to the clients.
However, before implementing the endpoint, follow <a data-type="xref" href="#chat_stream_ws">Example 6-14</a> to update the
<code>chat_stream</code>
method so that it yields the stream content in a suitable format for WebSocket connections.</p>
<div data-type="example" id="chat_stream_ws">
<h5><span class="label">Example 6-14. </span>Update the chat client streaming method to yield content suitable for WebSocket connections</h5>

<pre data-code-language="python" data-type="programlisting"><code class="c1"># stream.py</code>

<code class="kn">import</code> <code class="nn">asyncio</code>
<code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">AsyncGenerator</code>

<code class="k">class</code> <code class="nc">AzureOpenAIChatClient</code><code class="p">:</code>
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">)</code><code class="p">:</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">aclient</code> <code class="o">=</code> <code class="o">.</code><code class="o">.</code><code class="o">.</code>

    <code class="k">async</code> <code class="k">def</code> <code class="nf">chat_stream</code><code class="p">(</code>
        <code class="bp">self</code><code class="p">,</code> <code class="n">prompt</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="n">mode</code><code class="p">:</code> <code class="nb">str</code> <code class="o">=</code> <code class="s2">"</code><code class="s2">sse</code><code class="s2">"</code><code class="p">,</code> <code class="n">model</code><code class="p">:</code> <code class="nb">str</code> <code class="o">=</code> <code class="s2">"</code><code class="s2">gpt-4o</code><code class="s2">"</code>
    <code class="p">)</code> <code class="o">-</code><code class="o">&gt;</code> <code class="n">AsyncGenerator</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="kc">None</code><code class="p">]</code><code class="p">:</code>
        <code class="n">stream</code> <code class="o">=</code> <code class="o">.</code><code class="o">.</code><code class="o">.</code>  <code class="c1"># OpenAI chat completion stream</code>

        <code class="k">async</code> <code class="k">for</code> <code class="n">chunk</code> <code class="ow">in</code> <code class="n">stream</code><code class="p">:</code>
            <code class="k">if</code> <code class="n">chunk</code><code class="o">.</code><code class="n">choices</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">delta</code><code class="o">.</code><code class="n">content</code> <code class="ow">is</code> <code class="ow">not</code> <code class="kc">None</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-1"><img alt="1" src="assets/1.png"/></a>
                <code class="k">yield</code> <code class="p">(</code>
                    <code class="sa">f</code><code class="s2">"</code><code class="s2">data: </code><code class="si">{</code><code class="n">chunk</code><code class="o">.</code><code class="n">choices</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">delta</code><code class="o">.</code><code class="n">content</code><code class="si">}</code><code class="se">\n</code><code class="se">\n</code><code class="s2">"</code>
                    <code class="k">if</code> <code class="n">mode</code> <code class="o">==</code> <code class="s2">"</code><code class="s2">sse</code><code class="s2">"</code>
                    <code class="k">else</code> <code class="n">chunk</code><code class="o">.</code><code class="n">choices</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">delta</code><code class="o">.</code><code class="n">content</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-2"><img alt="2" src="assets/2.png"/></a>
                <code class="p">)</code>
                <code class="k">await</code> <code class="n">asyncio</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mf">0.05</code><code class="p">)</code>
        <code class="k">if</code> <code class="n">mode</code> <code class="o">==</code> <code class="s2">"</code><code class="s2">sse</code><code class="s2">"</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-3"><img alt="2" src="assets/2.png"/></a>
            <code class="k">yield</code> <code class="sa">f</code><code class="s2">"</code><code class="s2">data: [DONE]</code><code class="se">\n</code><code class="se">\n</code><code class="s2">"</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Only yield non-empty content.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Yield the stream content based on connection type (SSE or WS).</p></dd>
</dl></div>

<p>After updating the <code>stream_chat</code> method, you can focus on adding a WebSocket endpoint.
Use the <code>@app.websocket</code> to decorate a controller function that uses the 
<span class="keep-together">FastAPI’s</span> <code>WebSocket</code> class, as shown in
<a data-type="xref" href="#websocket_endpoint">Example 6-15</a>.</p>
<div data-type="example" id="websocket_endpoint">
<h5><span class="label">Example 6-15. </span>Implementing a WS endpoint</h5>

<pre data-code-language="python" data-type="programlisting"><code class="c1"># main.py</code>

<code class="kn">import</code> <code class="nn">asyncio</code>
<code class="kn">from</code> <code class="nn">loguru</code> <code class="kn">import</code> <code class="n">logger</code>
<code class="kn">from</code> <code class="nn">fastapi</code><code class="nn">.</code><code class="nn">websockets</code> <code class="kn">import</code> <code class="n">WebSocket</code><code class="p">,</code> <code class="n">WebSocketDisconnect</code>
<code class="kn">from</code> <code class="nn">stream</code> <code class="kn">import</code> <code class="n">ws_manager</code><code class="p">,</code> <code class="n">azure_chat_client</code>

<code class="nd">@app</code><code class="o">.</code><code class="n">websocket</code><code class="p">(</code><code class="s2">"</code><code class="s2">/generate/text/streams</code><code class="s2">"</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-1"><img alt="1" src="assets/1.png"/></a>
<code class="k">async</code> <code class="k">def</code> <code class="nf">websocket_endpoint</code><code class="p">(</code><code class="n">websocket</code><code class="p">:</code> <code class="n">WebSocket</code><code class="p">)</code> <code class="o">-</code><code class="o">&gt;</code> <code class="kc">None</code><code class="p">:</code>
    <code class="n">logger</code><code class="o">.</code><code class="n">info</code><code class="p">(</code><code class="s2">"</code><code class="s2">Connecting to client....</code><code class="s2">"</code><code class="p">)</code>
    <code class="k">await</code> <code class="n">ws_manager</code><code class="o">.</code><code class="n">connect</code><code class="p">(</code><code class="n">websocket</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-2"><img alt="2" src="assets/2.png"/></a>
    <code class="k">try</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-3" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-3"><img alt="3" src="assets/3.png"/></a>
        <code class="k">while</code> <code class="kc">True</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-4" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-4"><img alt="4" src="assets/4.png"/></a>
            <code class="n">prompt</code> <code class="o">=</code> <code class="k">await</code> <code class="n">ws_manager</code><code class="o">.</code><code class="n">receive</code><code class="p">(</code><code class="n">websocket</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-5" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-5"><img alt="5" src="assets/5.png"/></a>
            <code class="k">async</code> <code class="k">for</code> <code class="n">chunk</code> <code class="ow">in</code> <code class="n">azure_chat_client</code><code class="o">.</code><code class="n">chat_stream</code><code class="p">(</code><code class="n">prompt</code><code class="p">,</code> <code class="s2">"</code><code class="s2">ws</code><code class="s2">"</code><code class="p">)</code><code class="p">:</code>
                <code class="k">await</code> <code class="n">ws_manager</code><code class="o">.</code><code class="n">send</code><code class="p">(</code><code class="n">chunk</code><code class="p">,</code> <code class="n">websocket</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-6" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-6"><img alt="6" src="assets/6.png"/></a>
                <code class="k">await</code> <code class="n">asyncio</code><code class="o">.</code><code class="n">sleep</code><code class="p">(</code><code class="mf">0.05</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-7" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-7"><img alt="7" src="assets/7.png"/></a>
    <code class="k">except</code> <code class="n">WebSocketDisconnect</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-8" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-8"><img alt="8" src="assets/8.png"/></a>
        <code class="n">logger</code><code class="o">.</code><code class="n">info</code><code class="p">(</code><code class="s2">"</code><code class="s2">Client disconnected</code><code class="s2">"</code><code class="p">)</code>
    <code class="k">except</code> <code class="ne">Exception</code> <code class="k">as</code> <code class="n">e</code><code class="p">:</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-9" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-9"><img alt="9" src="assets/9.png"/></a>
        <code class="n">logger</code><code class="o">.</code><code class="n">error</code><code class="p">(</code><code class="sa">f</code><code class="s2">"</code><code class="s2">Error with the WebSocket connection: </code><code class="si">{</code><code class="n">e</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
        <code class="k">await</code> <code class="n">ws_manager</code><code class="o">.</code><code class="n">send</code><code class="p">(</code><code class="s2">"</code><code class="s2">An internal server error has occurred</code><code class="s2">"</code><code class="p">)</code>
    <code class="k">finally</code><code class="p">:</code>
        <code class="k">await</code> <code class="n">ws_manager</code><code class="o">.</code><code class="n">disconnect</code><code class="p">(</code><code class="n">websocket</code><code class="p">)</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-10" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-10"><img alt="10" src="assets/10.png"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Create a WebSocket endpoint accessible at
<code>ws://localhost:8000/generate/text/stream</code>.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Open the WebSocket connection between the client and the server.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-3" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-3"><img alt="3" src="assets/3.png"/></a></dt>
<dd><p>As long as the connection is open, keep sending or receiving messages.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-4" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-4"><img alt="4" src="assets/4.png"/></a></dt>
<dd><p>Handle errors and log important events within the <code>websocket_controller</code> to identify root causes of errors and handle unexpected situations gracefully.
Break the infinite loop when the connection is closed by the server or the client.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-5" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-5"><img alt="5" src="assets/5.png"/></a></dt>
<dd><p>When the first message is received, pass it as a prompt to OpenAI API.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-6" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-6"><img alt="6" src="assets/6.png"/></a></dt>
<dd><p>Asynchronously iterate over the generated chat stream and send each chunk to the client.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-7" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-7"><img alt="7" src="assets/7.png"/></a></dt>
<dd><p>Wait for a small amount of time before sending the next message to reduce race condition issues and allow the client sufficient time for stream processing.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-8" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-8"><img alt="8" src="assets/8.png"/></a></dt>
<dd><p>When the client closes the WebSocket connection, the  <code>WebSocketDisconnect</code> exception is raised.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-9" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-9"><img alt="9" src="assets/9.png"/></a></dt>
<dd><p>If there is a server-side error during an open connection, log the error and identify the client.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-10" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-10"><img alt="10" src="assets/10.png"/></a></dt>
<dd><p>Break the infinite loop and gracefully close the WebSocket connection if the stream has finished, there is an internal error, or the client has closed the connection.
Remove the connection from the active WebSocket connections list.</p></dd>
</dl></div>

<p>Now that you have a WebSocket endpoint, let’s develop the client HTML to test the endpoint (see <a data-type="xref" href="#ws_client">Example 6-16</a>).</p>
<div data-type="example" id="ws_client">
<h5><span class="label">Example 6-16. </span>Implement client-side WebSocket connections with error handling and exponential backoff retry functionality</h5>

<pre data-code-language="html" data-type="programlisting"><code>{# pages/client-ws.html #}

</code><code class="cp">&lt;!DOCTYPE html&gt;</code>
<code class="p">&lt;</code><code class="nt">html</code> <code class="na">lang</code><code class="o">=</code><code class="s">"en"</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">head</code><code class="p">&gt;</code>
    <code class="p">&lt;</code><code class="nt">title</code><code class="p">&gt;</code><code>Stream with WebSocket</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">title</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="p">/</code><code class="nt">head</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">body</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">button</code> <code class="na">id</code><code class="o">=</code><code class="s">"streambtn"</code><code class="p">&gt;</code><code>Start Streaming</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">button</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">button</code> <code class="na">id</code><code class="o">=</code><code class="s">"closebtn"</code><code class="p">&gt;</code><code>Close Connection</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">button</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">label</code> <code class="na">for</code><code class="o">=</code><code class="s">"messageInput"</code><code class="p">&gt;</code><code>Enter your prompt:</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">label</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">input</code> <code class="na">type</code><code class="o">=</code><code class="s">"text"</code> <code class="na">id</code><code class="o">=</code><code class="s">"messageInput"</code> <code class="na">placeholder</code><code class="o">=</code><code class="s">"Enter message"</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="nt">div</code> <code class="na">style</code><code class="o">=</code><code class="s">"padding-top: 10px"</code> <code class="na">id</code><code class="o">=</code><code class="s">"container"</code><code class="p">&gt;</code><code class="p">&lt;</code><code class="p">/</code><code class="nt">div</code><code class="p">&gt;</code>

<code class="p">&lt;</code><code class="nt">script</code><code class="p">&gt;</code>
    <code class="kd">const</code> <code class="nx">streamButton</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s1">'streambtn'</code><code class="p">)</code><code class="p">;</code>
    <code class="kd">const</code> <code class="nx">closeButton</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s1">'closebtn'</code><code class="p">)</code><code class="p">;</code>
    <code class="kd">const</code> <code class="nx">container</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s1">'container'</code><code class="p">)</code><code class="p">;</code>
    <code class="kd">const</code> <code class="nx">input</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s1">'messageInput'</code><code class="p">)</code><code class="p">;</code>

    <code class="kd">let</code> <code class="nx">ws</code><code class="p">;</code>
    <code class="kd">let</code> <code class="nx">retryCount</code> <code class="o">=</code> <code class="mf">0</code><code class="p">;</code>
    <code class="kd">const</code> <code class="nx">maxRetries</code> <code class="o">=</code> <code class="mf">5</code><code class="p">;</code>
    <code class="kd">let</code> <code class="nx">isError</code> <code class="o">=</code> <code class="kc">false</code><code class="p">;</code>

    <code class="kd">function</code> <code class="nx">sleep</code><code class="p">(</code><code class="nx">ms</code><code class="p">)</code> <code class="p">{</code>
        <code class="k">return</code> <code class="ow">new</code> <code class="nb">Promise</code><code class="p">(</code><code class="nx">resolve</code> <code class="p">=&gt;</code> <code class="nx">setTimeout</code><code class="p">(</code><code class="nx">resolve</code><code class="p">,</code> <code class="nx">ms</code><code class="p">)</code><code class="p">)</code><code class="p">;</code>
    <code class="p">}</code>

    <code class="kd">function</code> <code class="nx">connectWebSocket</code><code class="p">(</code><code class="p">)</code> <code class="p">{</code>
        <code class="nx">ws</code> <code class="o">=</code> <code class="ow">new</code> <code class="nx">WebSocket</code><code class="p">(</code><code class="s2">"ws://localhost:8000/generate/text/streams"</code><code class="p">)</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-1"><img alt="1" src="assets/1.png"/></a>

        <code class="nx">ws</code><code class="p">.</code><code class="nx">onopen</code> <code class="o">=</code> <code class="nx">handleOpen</code><code class="p">;</code>
        <code class="nx">ws</code><code class="p">.</code><code class="nx">onmessage</code> <code class="o">=</code> <code class="nx">handleMessage</code><code class="p">;</code>
        <code class="nx">ws</code><code class="p">.</code><code class="nx">onclose</code> <code class="o">=</code> <code class="nx">handleClose</code><code class="p">;</code>
        <code class="nx">ws</code><code class="p">.</code><code class="nx">onerror</code> <code class="o">=</code> <code class="nx">handleError</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-2" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-2"><img alt="2" src="assets/2.png"/></a>
    <code class="p">}</code>

    <code class="kd">function</code> <code class="nx">handleOpen</code><code class="p">(</code><code class="p">)</code><code class="p">{</code>
        <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s2">"WebSocket connection opened"</code><code class="p">)</code><code class="p">;</code>
        <code class="nx">retryCount</code> <code class="o">=</code> <code class="mf">0</code><code class="p">;</code>
        <code class="nx">isError</code> <code class="o">=</code> <code class="kc">false</code><code class="p">;</code>
    <code class="p">}</code>

    <code class="kd">function</code> <code class="nx">handleMessage</code><code class="p">(</code><code class="nx">event</code><code class="p">)</code> <code class="p">{</code>
        <code class="nx">container</code><code class="p">.</code><code class="nx">textContent</code> <code class="o">+=</code> <code class="nx">event</code><code class="p">.</code><code class="nx">data</code><code class="p">;</code>
    <code class="p">}</code>

    <code class="k">async</code> <code class="kd">function</code> <code class="nx">handleClose</code><code class="p">(</code><code class="p">)</code><code class="p">{</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-3" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-3"><img alt="3" src="assets/3.png"/></a>
        <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s2">"WebSocket connection closed"</code><code class="p">)</code><code class="p">;</code>
        <code class="k">if</code> <code class="p">(</code><code class="nx">isError</code> <code class="o">&amp;&amp;</code> <code class="nx">retryCount</code> <code class="o">&lt;</code> <code class="nx">maxRetries</code><code class="p">)</code> <code class="p">{</code>
            <code class="nx">console</code><code class="p">.</code><code class="nx">warn</code><code class="p">(</code><code class="s2">"Retrying connection..."</code><code class="p">)</code><code class="p">;</code>
            <code class="k">await</code> <code class="nx">sleep</code><code class="p">(</code><code class="nb">Math</code><code class="p">.</code><code class="nx">pow</code><code class="p">(</code><code class="mf">2</code><code class="p">,</code> <code class="nx">retryCount</code><code class="p">)</code> <code class="o">*</code> <code class="mf">1000</code><code class="p">)</code><code class="p">;</code>
            <code class="nx">retryCount</code><code class="o">++</code><code class="p">;</code>
            <code class="nx">connectWebSocket</code><code class="p">(</code><code class="p">)</code><code class="p">;</code>
        <code class="p">}</code>
        <code class="k">else</code> <code class="k">if</code> <code class="p">(</code><code class="nx">isError</code><code class="p">)</code> <code class="p">{</code>
            <code class="nx">console</code><code class="p">.</code><code class="nx">error</code><code class="p">(</code><code class="s2">"Max retries reached. Could not reconnect."</code><code class="p">)</code><code class="p">;</code>
        <code class="p">}</code>
    <code class="p">}</code>

    <code class="kd">function</code> <code class="nx">handleError</code><code class="p">(</code><code class="nx">error</code><code class="p">)</code> <code class="p">{</code>
        <code class="nx">console</code><code class="p">.</code><code class="nx">error</code><code class="p">(</code><code class="s2">"WebSocket error:"</code><code class="p">,</code> <code class="nx">error</code><code class="p">)</code><code class="p">;</code>
        <code class="nx">isError</code> <code class="o">=</code> <code class="kc">true</code><code class="p">;</code>
        <code class="nx">ws</code><code class="p">.</code><code class="nx">close</code><code class="p">(</code><code class="p">)</code><code class="p">;</code>
    <code class="p">}</code>

    <code class="kd">function</code> <code class="nx">resetForm</code><code class="p">(</code><code class="p">)</code><code class="p">{</code>
        <code class="nx">input</code><code class="p">.</code><code class="nx">value</code> <code class="o">=</code> <code class="s1">''</code><code class="p">;</code>
        <code class="nx">container</code><code class="p">.</code><code class="nx">textContent</code> <code class="o">=</code> <code class="s1">''</code><code class="p">;</code>
    <code class="p">}</code>

    <code class="nx">streamButton</code><code class="p">.</code><code class="nx">addEventListener</code><code class="p">(</code><code class="s1">'click'</code><code class="p">,</code> <code class="kd">function</code><code class="p">(</code><code class="p">)</code> <code class="p">{</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-4" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-4"><img alt="4" src="assets/4.png"/></a>
        <code class="kd">const</code> <code class="nx">prompt</code> <code class="o">=</code> <code class="nb">document</code><code class="p">.</code><code class="nx">getElementById</code><code class="p">(</code><code class="s2">"messageInput"</code><code class="p">)</code><code class="p">.</code><code class="nx">value</code><code class="p">;</code>
        <code class="k">if</code> <code class="p">(</code><code class="nx">prompt</code> <code class="o">&amp;&amp;</code> <code class="nx">ws</code> <code class="o">&amp;&amp;</code> <code class="nx">ws</code><code class="p">.</code><code class="nx">readyState</code> <code class="o">===</code> <code class="nx">WebSocket</code><code class="p">.</code><code class="nx">OPEN</code><code class="p">)</code> <code class="p">{</code>
            <code class="nx">ws</code><code class="p">.</code><code class="nx">send</code><code class="p">(</code><code class="nx">prompt</code><code class="p">)</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-5" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-5"><img alt="5" src="assets/5.png"/></a>
        <code class="p">}</code>
        <code class="nx">resetForm</code><code class="p">(</code><code class="p">)</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-6" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-6"><img alt="6" src="assets/6.png"/></a>
    <code class="p">}</code><code class="p">)</code><code class="p">;</code>

    <code class="nx">closeButton</code><code class="p">.</code><code class="nx">addEventListener</code><code class="p">(</code><code class="s1">'click'</code><code class="p">,</code> <code class="kd">function</code><code class="p">(</code><code class="p">)</code> <code class="p">{</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-7" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-7"><img alt="7" src="assets/7.png"/></a>
        <code class="nx">isError</code> <code class="o">=</code> <code class="kc">false</code><code class="p">;</code>
        <code class="k">if</code> <code class="p">(</code><code class="nx">ws</code><code class="p">)</code> <code class="p">{</code>
            <code class="nx">ws</code><code class="p">.</code><code class="nx">close</code><code class="p">(</code><code class="p">)</code><code class="p">;</code>
        <code class="p">}</code>
    <code class="p">}</code><code class="p">)</code><code class="p">;</code>

    <code class="nx">connectWebSocket</code><code class="p">(</code><code class="p">)</code><code class="p">;</code> <a class="co" href="#callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-1" id="co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-8"><img alt="1" src="assets/1.png"/></a>
<code class="p">&lt;</code><code class="p">/</code><code class="nt">script</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="p">/</code><code class="nt">body</code><code class="p">&gt;</code>
<code class="p">&lt;</code><code class="p">/</code><code class="nt">html</code><code class="p">&gt;</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-1" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-1"><img alt="1" src="assets/1.png"/></a></dt>
<dd><p>Establish a WebSocket connection with the FastAPI server.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-2" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-2"><img alt="2" src="assets/2.png"/></a></dt>
<dd><p>Add callback handlers to the WebSocket connection instance to handle opening, closing, message, and error events.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-3" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-3"><img alt="3" src="assets/3.png"/></a></dt>
<dd><p>Gracefully handle connection errors and re-establish the connection with an exponential backoff retry functionality using an <code>isError</code> flag.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-4" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-4"><img alt="4" src="assets/4.png"/></a></dt>
<dd><p>Add an event listener to the streaming button to send the first message to the server.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-5" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-5"><img alt="5" src="assets/5.png"/></a></dt>
<dd><p>Once the connection is established, send the initial non-empty prompt as the first message to the server.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-6" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-6"><img alt="6" src="assets/6.png"/></a></dt>
<dd><p>Reset the form to before establishing the WebSocket connection to start.</p></dd>
<dt><a class="co" href="#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-7" id="callout_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-7"><img alt="7" src="assets/7.png"/></a></dt>
<dd><p>Add an event listener to the close connection button to close the connection when the button is clicked.</p></dd>
</dl></div>

<p>Now you can visit <a class="bare" href="http://localhost:8000/pages/client-ws.html"><em class="hyperlink">http://localhost:8000/pages/client-ws.html</em></a> to test your WebSocket streaming endpoint (see <a data-type="xref" href="#ws_results">Figure 6-9</a>).</p>

<figure><div class="figure" id="ws_results">
<img alt="bgai 0609" src="assets/bgai_0609.png"/>
<h6><span class="label">Figure 6-9. </span>Incoming stream from the WebSocket endpoint</h6>
</div></figure>

<p>You should now have a fully working LLM streaming application with WebSocket.
Well done!</p>

<p>You now may be wondering which solution is better: streaming with SSE or WS connections. The answer depends on your application requirements.
SSE is simple to implement and is native to HTTP protocol, so most clients support it.
If all you need is one-way streaming to the client, then I suggest implementing SSE connections for streaming LLM outputs.</p>

<p>WebSocket connections provide more control to your streaming mechanism and allow for duplex communication within the same connection—for instance, in real-time chat applications with multiple users and the LLM, speech-to-text, text-to-speech, and speech-to-speech services.
However, using WebSocket requires upgrading the connection from HTTP to the WebSocket protocol, which legacy clients and older browsers may not support.
In addition, you will need to handle exceptions slightly differently with WebSocket endpoints.<a data-startref="ix_ch06-asciidoc26" data-type="indexterm" id="id920"/><a data-startref="ix_ch06-asciidoc25" data-type="indexterm" id="id921"/></p>
</div></section>








<section data-pdf-bookmark="Handling WebSocket Exceptions" data-type="sect2"><div class="sect2" id="id100">
<h2>Handling WebSocket Exceptions</h2>

<p><a data-primary="exception handling, for WS" data-type="indexterm" id="id922"/><a data-primary="real-time communication with generative models" data-secondary="implementing WS endpoints" data-tertiary="handling WS exceptions" data-type="indexterm" id="id923"/><a data-primary="WebSocket (WS)" data-secondary="implementing endpoints with WS protocol" data-tertiary="handling WS exceptions" data-type="indexterm" id="id924"/>Handling WebSocket exceptions differs from traditional HTTP connections.
If you refer to <a data-type="xref" href="#websocket_endpoint">Example 6-15</a>, you will notice that you’re no longer returning a response with status codes, or <code>HTTPExceptions</code>, to the client but rather maintaining an open connection after connection acceptance.</p>

<p>As long as the connection is open, you’re sending and receiving messages.
However, as soon as an exception has occurred, you should handle it either by gracefully closing the connection and/or by sending an error message to the client in replacement of an <code>HTTPException</code> response.</p>

<p>Since the WebSocket protocol doesn’t support the usual HTTP status codes (<code>4xx</code> or <code>5xx</code>), you can’t use status codes to notify the clients of server-side issues.
Instead, you should send WebSocket messages to clients to notify them of issues before you close any active connections from the server.</p>

<p>During the connection closure, you can use several WebSocket-related status codes to specify the closure reason.
Using these closure reasons, you can implement any custom closure behavior on the server or the clients.</p>

<p><a data-type="xref" href="#ws_status_codes">Table 6-2</a> shows a few common status codes that can be sent with a <code>CLOSE</code> frame.</p>
<table class="striped" id="ws_status_codes">
<caption><span class="label">Table 6-2. </span>WebSocket protocol common status codes</caption>
<thead>
<tr>
<th>Status code</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>1000</p></td>
<td><p>Normal closure</p></td>
</tr>
<tr>
<td><p>1001</p></td>
<td><p>Client navigated away or server has gone down</p></td>
</tr>
<tr>
<td><p>1002</p></td>
<td><p>An endpoint (i.e., client or server) received data violating the WS protocol (e.g., unmasked packets, invalid payload length)</p></td>
</tr>
<tr>
<td><p>1003</p></td>
<td><p>An endpoint received unsupported data (e.g., was expecting text, got binary)</p></td>
</tr>
<tr>
<td><p>1007</p></td>
<td><p>An endpoint received inconsistently encoded data (e.g., non-UTF-8 data within a text message)</p></td>
</tr>
<tr>
<td><p>1008</p></td>
<td><p>An endpoint received a message that violates its policy; can be used to hide closure details for security reasons</p></td>
</tr>
<tr>
<td><p>1011</p></td>
<td><p>Internal server error</p></td>
</tr>
</tbody>
</table>

<p>You can learn more about other WebSocket status codes in the WebSocket protocol
<a href="https://oreil.ly/1L_HH">RFC 6455—Section 7.4</a>.</p>
</div></section>








<section data-pdf-bookmark="Designing APIs for Streaming" data-type="sect2"><div class="sect2" id="id101">
<h2>Designing APIs for Streaming</h2>

<p><a data-primary="real-time communication with generative models" data-secondary="designing APIs for streaming" data-type="indexterm" id="id925"/><a data-primary="streaming, API design patterns for" data-type="indexterm" id="id926"/>Now that you’re more familiar with both SSE and WebSocket endpoint implementations, I want to cover one last important detail around their architectural design.</p>

<p>A common pitfall of designing streaming APIs is exposing an excessive number of streaming endpoints.
For instance, if you’re building a chatbot application, you may expose several streaming endpoints, each preconfigured to handle different incoming messages in a single conversation.
By using this particular API design pattern, you’re asking the client to switch between endpoints, providing the necessary information in each step while navigating the streaming connections during a single conversation.
This design pattern adds to the complexity of both the backend and frontend applications since the conversation states need to be managed on both sides while avoiding race condition and networking issues between components.</p>

<p>A simpler API design pattern is to provide a single entry point for the client to initiate a stream with your GenAI model(s) and use headers, request body, or query parameters to trigger the relevant logic in the backend.
With this design, the backend logic is abstracted away from the client, which simplifies state management on the frontend while all routing and business logic are implemented on the backend.
Since the backend has access to databases, other services, and customized prompts, it can easily 
<span class="keep-together">perform</span> CRUD operations and switch between prompts or models to compute a response.
Therefore, one endpoint can act as a single entry point for switching logic, manage application states, and generate custom responses.<a data-startref="ix_ch06-asciidoc24" data-type="indexterm" id="id927"/><a data-startref="ix_ch06-asciidoc23" data-type="indexterm" id="id928"/></p>
</div></section>
</div></section>






<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="id102">
<h1>Summary</h1>

<p>This chapter covered several different strategies for implementing real-time communication via data streaming in your GenAI services.</p>

<p>You learned about several web communication mechanisms including the traditional HTTP request-response model, short/regular polling, long polling, SSE, and WebSocket.
You then compared these mechanisms in detail to understand their features, benefits, disadvantages, and use cases, in particular for AI workflows.
Finally, you implemented two LLM streaming endpoints using the asynchronous Azure OpenAI client to learn how to leverage SSE and WebSocket real-time communication<a data-startref="ix_ch06-asciidoc0" data-type="indexterm" id="id929"/> 
<span class="keep-together">mechanisms.</span></p>

<p>In the next chapter, you will learn more about API development workflows when integrating databases for AI services.
This will include how to set up, migrate, and interact with databases.
You’ll also learn how to handle data storage-and-retrieval operations within streaming endpoints by using FastAPI’s background tasks.</p>

<p>Topics covered in the next chapter will include setting up databases and designing schemas, working with the SQLAlchemy, database migrations, and handling database operations when streaming model outputs.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="id893"><sup><a href="ch06.html#id893-marker">1</a></sup> Attackers can use cache poisoning to inject malicious data to caching systems, which then serve incorrect data to users or systems. To protect against this attack, the client and the server mask payloads to appear as random data before sending them.</p><p data-type="footnote" id="id894"><sup><a href="ch06.html#id894-marker">2</a></sup> These attacks involve tricking a server into leaking sensitive information by sending an HTTP response to a WebSocket frame.</p><p data-type="footnote" id="id906"><sup><a href="ch06.html#id906-marker">3</a></sup> See MDN resources for more details on the <a href="https://oreil.ly/0yuKA"><code>EventSource</code> interface</a>.</p><p data-type="footnote" id="id909"><sup><a href="ch06.html#id909-marker">4</a></sup> Follow the <a href="https://oreil.ly/a7KeV">“Accessing Private/Gated Models” guide</a> to generate a Hugging Face user access token.</p><p data-type="footnote" id="id912"><sup><a href="ch06.html#id912-marker">5</a></sup> Attackers use the XSS vulnerability to insert harmful scripts into web pages, which are then executed by other users’ browsers.</p><p data-type="footnote" id="id914"><sup><a href="ch06.html#id914-marker">6</a></sup> Exponential backoff reduces the chances of API rate-limiting errors by increasing the delay after each retry.</p></div></div></section></body></html>