<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 4. Training Models"><div class="chapter" id="linear_models_chapter">
<h1><span class="label">Chapter 4. </span>Training Models</h1>


<p>So<a data-type="indexterm" data-primary="training models" id="xi_trainingmodels453_1"/> far we have treated machine learning models and their training algorithms mostly like black boxes. If you went through some of the exercises in the previous chapters, you may have been surprised by how much you can get done without knowing anything about what’s under the hood: you optimized a regression system, you improved a digit image classifier, and you even built a spam classifier from scratch, all without knowing how they actually work. Indeed, in many situations you don’t really need to know the implementation details.</p>

<p>However, having a good understanding of how things work can help you quickly home in on the appropriate model, the right training algorithm to use, and a good set of hyperparameters for your task. Understanding what’s under the hood will also help you debug issues and perform error analysis more efficiently. Lastly, most of the topics discussed in this chapter will be essential in understanding, building, and training neural networks (discussed in <a data-type="xref" href="part02.html#neural_nets_part">Part II</a> of this book).</p>

<p>In this chapter we will start by looking at the linear regression model<a data-type="indexterm" data-primary="linear regression" id="xi_linearregression4972_1"/><a data-type="indexterm" data-primary="training models" data-secondary="linear regression" id="id1432"/>, one of the simplest models there is. We will discuss two very different ways to train it:</p>

<ul>
<li>
<p>Using a “closed-form” equation⁠<sup><a data-type="noteref" id="id1433-marker" href="ch04.html#id1433">1</a></sup> that directly computes the model parameters that best fit the model to the training set (i.e., the model parameters that minimize the cost function over the training set).</p>
</li>
<li>
<p>Using an iterative optimization approach called gradient descent (GD)<a data-type="indexterm" data-primary="gradient descent (GD)" id="id1434"/> that gradually tweaks the model parameters to minimize the cost function over the training set, eventually converging to the same set of parameters as the first method. We will look at a few variants of gradient descent that we will use again and again when we study neural networks in <a data-type="xref" href="part02.html#neural_nets_part">Part II</a>: batch GD, mini-batch GD, and stochastic GD.</p>
</li>
</ul>

<p>Next we will look at polynomial regression<a data-type="indexterm" data-primary="overfitting of data" data-secondary="polynomial regression" id="id1435"/><a data-type="indexterm" data-primary="polynomial regression" id="id1436"/><a data-type="indexterm" data-primary="regression models" data-secondary="polynomial regression" id="id1437"/><a data-type="indexterm" data-primary="training models" data-secondary="polynomial regression" id="id1438"/>, a more complex model that can fit nonlinear datasets. Since this model has more parameters than linear regression, it is more prone to overfitting the training data. We will explore how to detect whether this is the case using learning curves, and then we will look at several regularization techniques that can reduce the risk of overfitting the training set.</p>

<p>Finally, we will examine two more models that are commonly used for classification tasks: logistic regression and softmax regression.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>There will be quite a few math equations in this chapter using basic concepts of linear algebra and calculus. To understand these equations, you need to be familiar with vectors and matrices—how to transpose them, multiply them, and invert
them—as well as partial derivatives. If these concepts are unfamiliar, please review the introductory Jupyter notebooks on linear algebra and calculus provided in the <a href="https://github.com/ageron/handson-mlp">online supplemental material</a>. If you are truly allergic to math, you can just skip the equations; the text should still help you grasp most of the concepts. That said, learning the mathematical formalism is extremely useful, as it will allow you to read ML papers. Although it may seem daunting at first, it’s actually not that hard, and this chapter includes code that should help you make sense of the equations.</p>
</div>






<section data-type="sect1" data-pdf-bookmark="Linear Regression"><div class="sect1" id="id72">
<h1>Linear Regression</h1>

<p>In<a data-type="indexterm" data-primary="training models" data-secondary="linear regression" id="xi_trainingmodelslinearregression4223_1"/> <a data-type="xref" href="ch01.html#landscape_chapter">Chapter 1</a> we looked at a simple linear model of life satisfaction (<a data-type="xref" href="#life_satisfaction_equation">Equation 4-1</a>).</p>
<div id="life_satisfaction_equation" data-type="equation">
<h5><span class="label">Equation 4-1. </span>A simple linear model of life satisfaction</h5>
<math alttext="life normal bar satisfaction equals theta 0 plus theta 1 times GDP normal bar per normal bar capita" display="block">
  <mrow>
    <mtext>life</mtext>
    <mo>_</mo>
    <mtext>satisfaction</mtext>
    <mo>=</mo>
    <msub><mi>θ</mi> <mn>0</mn> </msub>
    <mspace width="0.166667em"/>
    <mo>+</mo>
    <mspace width="0.166667em"/>
    <msub><mi>θ</mi> <mn>1</mn> </msub>
    <mo>×</mo>
    <mtext>GDP</mtext>
    <mo>_</mo>
    <mtext>per</mtext>
    <mo>_</mo>
    <mtext>capita</mtext>
  </mrow>
</math>
</div>

<p>This model is just a linear function of the input feature <code translate="no">GDP_per_capita</code>. <em>θ</em><sub>0</sub> and <em>θ</em><sub>1</sub> are the model’s parameters.</p>

<p>More generally, a linear model makes a prediction by simply computing a weighted sum of the input features, plus a constant called the <em>bias term</em><a data-type="indexterm" data-primary="biases" data-secondary="bias term constant" id="id1439"/> (also called the <em>intercept term</em>)<a data-type="indexterm" data-primary="intercept term constant" id="id1440"/>, as shown in <a data-type="xref" href="#linear_regression_equation">Equation 4-2</a>.</p>
<div id="linear_regression_equation" data-type="equation">
<h5><span class="label">Equation 4-2. </span>Linear regression model prediction</h5>
<math alttext="ModifyingAbove y With caret equals theta 0 plus theta 1 x 1 plus theta 2 x 2 plus midline-horizontal-ellipsis plus theta Subscript n Baseline x Subscript n" display="block">
  <mrow>
    <mover accent="true"><mi>y</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <msub><mi>θ</mi> <mn>0</mn> </msub>
    <mo>+</mo>
    <msub><mi>θ</mi> <mn>1</mn> </msub>
    <msub><mi>x</mi> <mn>1</mn> </msub>
    <mo>+</mo>
    <msub><mi>θ</mi> <mn>2</mn> </msub>
    <msub><mi>x</mi> <mn>2</mn> </msub>
    <mo>+</mo>
    <mo>⋯</mo>
    <mo>+</mo>
    <msub><mi>θ</mi> <mi>n</mi> </msub>
    <msub><mi>x</mi> <mi>n</mi> </msub>
  </mrow>
</math>
</div>

<p>In this equation:</p>

<ul>
<li>
<p><em>ŷ</em> is the predicted value.</p>
</li>
<li>
<p><em>n</em> is the number of features.</p>
</li>
<li>
<p><em>x</em><sub><em>i</em></sub> is the <em>i</em><sup>th</sup> feature value.</p>
</li>
<li>
<p><em>θ</em><sub><em>j</em></sub> is the <em>j</em><sup>th</sup> model parameter, including the bias term <em>θ</em><sub>0</sub> and the feature weights <em>θ</em><sub>1</sub>, <em>θ</em><sub>2</sub>, ⋯, <em>θ</em><sub><em>n</em></sub>.</p>
</li>
</ul>

<p>This can be written much more concisely using a vectorized form, as shown in <a data-type="xref" href="#linear_regression_prediction_vectorized_equation">Equation 4-3</a>.</p>
<div id="linear_regression_prediction_vectorized_equation" data-type="equation"><h5><span class="label">Equation 4-3. </span>Linear regression model prediction (vectorized form)</h5><math><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><msub><mi>h</mi><mi mathvariant="bold">θ</mi></msub><mo>(</mo><mi mathvariant="bold">x</mi><mo>)</mo><mo>=</mo><mi mathvariant="bold">θ</mi><mo>·</mo><mi mathvariant="bold">x</mi></math>
</div>

<p>In this equation:</p>

<ul>
<li>
<p><em>h</em><sub><strong>θ</strong></sub> is the hypothesis function<a data-type="indexterm" data-primary="hypothesis function" id="id1441"/>, using the model parameters <strong>θ</strong>.</p>
</li>
<li>
<p><strong>θ</strong> is the model’s <em>parameter vector</em>,<a data-type="indexterm" data-primary="parameter vector" id="id1442"/> containing the bias term <em>θ</em><sub>0</sub> and the feature weights <em>θ</em><sub>1</sub> to <em>θ</em><sub><em>n</em></sub>.</p>
</li>
<li>
<p><strong>x</strong> is the instance’s <em>feature vector</em>,<a data-type="indexterm" data-primary="feature vectors" id="id1443"/> containing <em>x</em><sub>0</sub> to <em>x</em><sub><em>n</em></sub>, with <em>x</em><sub>0</sub> always equal to 1.</p>
</li>
<li>
<p><strong>θ</strong> · <strong>x</strong> is the dot product of the vectors <strong>θ</strong> and <strong>x</strong>, which is equal to <em>θ</em><sub>0</sub><em>x</em><sub>0</sub> + <em>θ</em><sub>1</sub><em>x</em><sub>1</sub> + <em>θ</em><sub>2</sub><em>x</em><sub>2</sub> + ... + <em>θ</em><sub><em>n</em></sub><em>x</em><sub><em>n</em></sub>.</p>
</li>
</ul>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In machine learning, vectors are often represented as <em>column vectors</em>,<a data-type="indexterm" data-primary="column vectors" id="id1444"/> which are 2D arrays with a single column. If <strong>θ</strong> and <strong>x</strong> are column vectors, then the prediction is <math><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><msup><mi mathvariant="bold">θ</mi><mo>⊺</mo></msup><mi mathvariant="bold">x</mi></math>, where <math><msup><mi mathvariant="bold">θ</mi><mo>⊺</mo></msup></math> is the <em>transpose</em> of <strong>θ</strong> (a row vector instead of a column vector) and <math><msup><mi mathvariant="bold">θ</mi><mo>⊺</mo></msup><mi mathvariant="bold">x</mi></math> is the matrix multiplication of <math><msup><mi mathvariant="bold">θ</mi><mo>⊺</mo></msup></math> and <strong>x</strong>. It is of course the same prediction, except that it is now represented as a single-cell matrix rather than a scalar value. In this book I will use this notation to avoid switching between dot products and matrix multiplications.</p>
</div>

<p>OK, that’s the linear regression model—but how do we train it? Well, recall that training a model means setting its parameters so that the model best fits the training set. For this purpose, we first need a measure of how well (or poorly) the model fits the training data. In <a data-type="xref" href="ch02.html#project_chapter">Chapter 2</a> we saw that the most common performance measure of a regression model is the root mean squared error (<a data-type="xref" href="ch02.html#rmse_equation">Equation 2-1</a>). Therefore, to train a linear regression model, we need to find the value of <strong>θ</strong> that minimizes the RMSE<a data-type="indexterm" data-primary="root mean square error (RMSE)" id="id1445"/>. In practice, it is simpler to minimize the mean squared error (MSE)<a data-type="indexterm" data-primary="mean squared error (MSE)" id="id1446"/><a data-type="indexterm" data-primary="MSE (mean squared error)" id="id1447"/> than the RMSE, and it leads to the same result (because the value that minimizes a positive function also minimizes its square root).</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Learning algorithms will often optimize a different loss function during training than the performance measure used to evaluate the final model. This is generally because the function is easier to optimize and/or because it has extra terms needed during training only (e.g., for regularization). A good performance metric is as close as possible to the final business objective. A good training loss is easy to optimize and strongly correlated with the metric. For example, classifiers are often trained using a cost function<a data-type="indexterm" data-primary="cost function" data-secondary="linear regression" id="id1448"/> such as the log loss (as you will see later in this chapter) but evaluated using precision/recall. The log loss is easy to minimize, and doing so will usually improve precision/recall.</p>
</div>

<p>The MSE of a linear regression hypothesis <em>h</em><sub><strong>θ</strong></sub> on a training set <strong>X</strong> is calculated using <a data-type="xref" href="#mse_cost_function">Equation 4-4</a>.</p>
<div id="mse_cost_function" data-type="equation"><h5><span class="label">Equation 4-4. </span>MSE cost function for a linear regression model</h5><math display="block">
  <mrow>
    <mtext>MSE</mtext>
    <mrow>
      <mo>(</mo>
      <mi mathvariant="bold">X</mi>
      <mo lspace="0%" rspace="0%">,</mo>
      <mi mathvariant="bold">y</mi>
      <mo lspace="0%" rspace="0%">,</mo>
      <msub><mi>h</mi> <mi mathvariant="bold">θ</mi> </msub>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac><mn>1</mn> <mi>m</mi></mfrac>
    </mstyle>
    <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </munderover>
    <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">θ</mi> <mo>⊺</mo> </msup><msup><mi mathvariant="bold">x</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msup><mo>-</mo><msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msup><mo>)</mo></mrow> <mn>2</mn> </msup>
  </mrow>
</math>
</div>

<p>Most of these notations<a data-type="indexterm" data-primary="notations" id="id1449"/> were presented in <a data-type="xref" href="ch02.html#project_chapter">Chapter 2</a> (see <a data-type="xref" href="ch02.html#notations">“Notations”</a>). The only difference is that we write <em>h</em><sub><strong>θ</strong></sub> instead of just <em>h</em> to make it clear that the model is parametrized by the vector <strong>θ</strong>. To simplify notations, we will just write MSE(<strong>θ</strong>) instead of MSE(<strong>X</strong>, <em>h</em><sub><strong>θ</strong></sub>).</p>








<section data-type="sect2" data-pdf-bookmark="The Normal Equation"><div class="sect2" id="id73">
<h2>The Normal Equation</h2>

<p>To<a data-type="indexterm" data-primary="computational complexity" data-secondary="normal equation" id="xi_computationalcomplexityNormalequation41003_1"/><a data-type="indexterm" data-primary="linear regression" data-secondary="normal equation" id="xi_linearregressionNormalequation41003_1"/><a data-type="indexterm" data-primary="normal equation" id="xi_Normalequation41003_1"/> find the value of <strong>θ</strong> that minimizes the MSE, there exists a <em>closed-form solution</em><a data-type="indexterm" data-primary="closed-form equation/solution" id="id1450"/>—in other words, a mathematical equation that gives the result directly. This is called the <em>normal equation</em> (<a data-type="xref" href="#equation_four_four">Equation 4-5</a>).</p>
<div class="fifty-percent" id="equation_four_four" data-type="equation"><h5><span class="label">Equation 4-5. </span>Normal equation</h5><math display="block">
  <mrow>
    <mover accent="true"><mi mathvariant="bold">θ</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">X</mi> <mo>⊺</mo> </msup><mi mathvariant="bold">X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow> </msup>
    <msup><mi mathvariant="bold">X</mi> <mo>⊺</mo> </msup>
    <mi mathvariant="bold">y</mi>
  </mrow>
</math>
</div>

<p>In this equation:</p>

<ul>
<li>
<p><math><mover accent="true"><mi mathvariant="bold">θ</mi><mo>^</mo></mover></math> is the value of <strong>θ</strong> that minimizes the cost function.</p>
</li>
<li>
<p><strong>y</strong> is the vector of target values containing <em>y</em><sup>(1)</sup> to <em>y</em><sup>(<em>m</em>)</sup>.</p>
</li>
</ul>

<p>Let’s generate some linear-looking data to test this equation on (<a data-type="xref" href="#generated_data_plot">Figure 4-1</a>):</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>

<code class="n">rng</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">default_rng</code><code class="p">(</code><code class="n">seed</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">m</code> <code class="o">=</code> <code class="mi">200</code>  <code class="c1"># number of instances</code>
<code class="n">X</code> <code class="o">=</code> <code class="mi">2</code> <code class="o">*</code> <code class="n">rng</code><code class="o">.</code><code class="n">random</code><code class="p">((</code><code class="n">m</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>  <code class="c1"># column vector</code>
<code class="n">y</code> <code class="o">=</code> <code class="mi">4</code> <code class="o">+</code> <code class="mi">3</code> <code class="o">*</code> <code class="n">X</code> <code class="o">+</code> <code class="n">rng</code><code class="o">.</code><code class="n">standard_normal</code><code class="p">((</code><code class="n">m</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>  <code class="c1"># column vector</code></pre>

<figure class="smallerseventyfive"><div id="generated_data_plot" class="figure">
<img src="assets/hmls_0401.png" alt="Scatter plot showing a linear dataset with increasing trend, generated to illustrate the application of the normal equation in linear regression." width="1669" height="1071"/>
<h6><span class="label">Figure 4-1. </span>A randomly generated linear dataset</h6>
</div></figure>

<p>Now let’s compute <math><mover accent="true"><mi mathvariant="bold">θ</mi><mo>^</mo></mover></math> using the normal equation. We will use the <code translate="no">inv()</code> function from NumPy’s linear algebra module (<code translate="no">np.linalg</code>) to compute the inverse of a matrix, and the <code translate="no">@</code> operator for matrix multiplication:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="kn">import</code> <code class="n">add_dummy_feature</code>

<code class="n">X_b</code> <code class="o">=</code> <code class="n">add_dummy_feature</code><code class="p">(</code><code class="n">X</code><code class="p">)</code>  <code class="c1"># add x0 = 1 to each instance</code>
<code class="n">theta_best</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">linalg</code><code class="o">.</code><code class="n">inv</code><code class="p">(</code><code class="n">X_b</code><code class="o">.</code><code class="n">T</code> <code class="o">@</code> <code class="n">X_b</code><code class="p">)</code> <code class="o">@</code> <code class="n">X_b</code><code class="o">.</code><code class="n">T</code> <code class="o">@</code> <code class="n">y</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The <code translate="no">@</code> operator<a data-type="indexterm" data-primary="@ operator (matrix multiplication)" id="id1451"/> performs matrix multiplication. If <code translate="no">A</code> and <code translate="no">B</code> are NumPy arrays, then <code translate="no">A @ B</code> is equivalent to <code translate="no">np.matmul(A, B)</code>. Many other libraries, like TensorFlow, PyTorch, and JAX, support the <code translate="no">@</code> operator as well. However, you cannot use <code translate="no">@</code> on pure Python arrays (i.e., lists of lists).</p>
</div>

<p>The function that we used to generate the data is <em>y</em> = 4 + 3<em>x</em><sub>1</sub> + Gaussian noise. Let’s see what the equation found:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">theta_best</code><code class="w"/>
<code class="go">array([[3.69084138],</code>
<code class="go">       [3.32960458]])</code></pre>

<p>We would have hoped for <em>θ</em><sub>0</sub> = 4 and <em>θ</em><sub>1</sub> = 3 instead of <em>θ</em><sub>0</sub> = 3.6908 and <em>θ</em><sub>1</sub> = 3.3296. Close enough, but the noise made it impossible to recover the exact parameters of the original function. The smaller and noisier the dataset, the harder it gets.</p>

<p>Now we can make predictions using <math><mover accent="true"><mi mathvariant="bold">θ</mi><mo>^</mo></mover></math>:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X_new</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">([[</code><code class="mi">0</code><code class="p">],</code> <code class="p">[</code><code class="mi">2</code><code class="p">]])</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X_new_b</code> <code class="o">=</code> <code class="n">add_dummy_feature</code><code class="p">(</code><code class="n">X_new</code><code class="p">)</code>  <code class="c1"># add x0 = 1 to each instance</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_predict</code> <code class="o">=</code> <code class="n">X_new_b</code> <code class="o">@</code> <code class="n">theta_best</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_predict</code><code class="w"/>
<code class="go">array([[ 3.69084138],</code>
<code class="go">       [10.35005055]])</code></pre>

<p>Let’s plot this model’s predictions (<a data-type="xref" href="#linear_model_predictions_plot">Figure 4-2</a>):</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="k">as</code> <code class="nn">plt</code>

<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">X_new</code><code class="p">,</code> <code class="n">y_predict</code><code class="p">,</code> <code class="s2">"r-"</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s2">"Predictions"</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="s2">"b."</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># beautify the figure: add labels, axis, grid, and legend</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

<figure class="smallerseventy"><div id="linear_model_predictions_plot" class="figure">
<img src="assets/hmls_0402.png" alt="Scatter plot showing data points with a fitted linear regression line representing predictions." width="1669" height="1071"/>
<h6><span class="label">Figure 4-2. </span>Linear regression model predictions</h6>
</div></figure>

<p>Performing linear regression using Scikit-Learn is relatively straightforward<a data-type="indexterm" data-primary="LinearRegression" id="id1452"/><a data-type="indexterm" data-primary="sklearn" data-secondary="linear_model.LinearRegression" id="id1453"/>:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">LinearRegression</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">lin_reg</code> <code class="o">=</code> <code class="n">LinearRegression</code><code class="p">()</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">lin_reg</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">lin_reg</code><code class="o">.</code><code class="n">intercept_</code><code class="p">,</code> <code class="n">lin_reg</code><code class="o">.</code><code class="n">coef_</code><code class="w"/>
<code class="go">(array([3.69084138]), array([[3.32960458]]))</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">lin_reg</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_new</code><code class="p">)</code><code class="w"/>
<code class="go">array([[ 3.69084138],</code>
<code class="go">       [10.35005055]])</code></pre>

<p>Notice that Scikit-Learn separates the bias term (<code translate="no">intercept_</code>)<a data-type="indexterm" data-primary="biases" data-secondary="bias term constant" id="id1454"/> from the feature weights (<code translate="no">coef_</code>). The <code translate="no">LinearRegression</code> class is based on the <code translate="no">scipy.linalg.lstsq()</code> function (the name stands for “least squares”), which you could call directly:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">theta_best_svd</code><code class="p">,</code> <code class="n">residuals</code><code class="p">,</code> <code class="n">rank</code><code class="p">,</code> <code class="n">s</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">linalg</code><code class="o">.</code><code class="n">lstsq</code><code class="p">(</code><code class="n">X_b</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">rcond</code><code class="o">=</code><code class="mf">1e-6</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">theta_best_svd</code><code class="w"/>
<code class="go">array([[3.69084138],</code>
<code class="go">       [3.32960458]])</code></pre>

<p>This function computes <math><mover accent="true"><mi mathvariant="bold">θ</mi><mo>^</mo></mover><mo>=</mo><msup><mi mathvariant="bold">X</mi><mo>+</mo></msup><mi mathvariant="bold">y</mi></math>, where <math><msup><mi mathvariant="bold">X</mi><mo>+</mo></msup></math> is the <em>pseudoinverse</em><a data-type="indexterm" data-primary="pseudoinverse" id="id1455"/> of <strong>X</strong> (specifically, <span class="keep-together">the Moore–Penrose</span> inverse).<a data-type="indexterm" data-primary="Moore-Penrose inverse" id="id1456"/> You can use <code translate="no">np.linalg.pinv()</code> to compute the <span class="keep-together">pseudoinverse</span> directly:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">np</code><code class="o">.</code><code class="n">linalg</code><code class="o">.</code><code class="n">pinv</code><code class="p">(</code><code class="n">X_b</code><code class="p">)</code> <code class="o">@</code> <code class="n">y</code><code class="w"/>
<code class="go">array([[3.69084138],</code>
<code class="go">       [3.32960458]])</code></pre>

<p>The pseudoinverse itself is computed using a standard matrix factorization technique called <em>singular value decomposition</em> (SVD)<a data-type="indexterm" data-primary="singular value decomposition (SVD)" id="id1457"/><a data-type="indexterm" data-primary="SVD (singular value decomposition)" id="id1458"/> that can decompose the training set matrix <strong>X</strong> into the matrix multiplication of three matrices <strong>U</strong> <strong>Σ</strong> <strong>V</strong><sup>⊺</sup> (see <code translate="no">numpy.linalg.svd()</code>). The pseudoinverse is computed as <math><msup><mi mathvariant="bold">X</mi><mo>+</mo></msup><mo>=</mo><mi mathvariant="bold">V</mi><msup><mi mathvariant="bold">Σ</mi><mo>+</mo></msup><msup><mi mathvariant="bold">U</mi><mo>⊺</mo></msup></math>. To compute the matrix <math><msup><mi mathvariant="bold">Σ</mi><mo>+</mo></msup></math>, the algorithm takes <strong>Σ</strong> and sets to zero all values smaller than a tiny threshold value, then it replaces all the nonzero values with their inverse, and finally it transposes the resulting matrix. This approach is more efficient than computing the normal equation, plus it handles edge cases nicely: indeed, the normal equation may not work if the matrix <strong>X</strong><sup>⊺</sup><strong>X</strong> is not invertible (i.e., singular), such as if <em>m</em> &lt; <em>n</em> or if some features are redundant, but the pseudoinverse is always defined.<a data-type="indexterm" data-startref="xi_linearregressionNormalequation41003_1" id="id1459"/><a data-type="indexterm" data-startref="xi_Normalequation41003_1" id="id1460"/></p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Computational Complexity"><div class="sect2" id="id74">
<h2>Computational Complexity</h2>

<p>The<a data-type="indexterm" data-primary="linear regression" data-secondary="computational complexity" id="xi_linearregressioncomputationalcomplexity42324_1"/> normal equation computes the inverse of <strong>X</strong><sup>⊺</sup> <strong>X</strong>, which is an (<em>n</em> + 1) × (<em>n</em> + 1) matrix (where <em>n</em> is the number of features). The <em>computational complexity</em> of inverting such a matrix is typically about <em>O</em>(<em>n</em><sup>2.4</sup>) to <em>O</em>(<em>n</em><sup>3</sup>), depending on the implementation. In other words, if you double the number of features, you multiply the computation time by roughly 2<sup>2.4</sup> = 5.3 to 2<sup>3</sup> = 8.</p>

<p>The SVD approach used by Scikit-Learn’s <code translate="no">LinearRegression</code><a data-type="indexterm" data-primary="LinearRegression" id="id1461"/><a data-type="indexterm" data-primary="sklearn" data-secondary="linear_model.LinearRegression" id="id1462"/> class is about <em>O</em>(<em>n</em><sup>2</sup>). If you double the number of features, you multiply the computation time by roughly 4.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Both the normal equation and the SVD approach get very slow when the number of features grows large (e.g., 100,000). On the positive side, both are linear with regard to the number of instances in the training set (they are <em>O</em>(<em>m</em>)), so they handle large training sets efficiently, provided they can fit in memory.</p>
</div>

<p>Also, once you have trained your linear regression model (using the normal equation or any other algorithm), predictions are very fast: the computational complexity is linear with regard to both the number of instances you want to make predictions on and the number of features. In other words, making predictions on twice as many instances (or twice as many features) will take roughly twice as much time.<a data-type="indexterm" data-startref="xi_computationalcomplexityNormalequation41003_1" id="id1463"/></p>

<p>Now we will look at a very different way to train a linear regression model, which is better suited for cases where there are a large number of features or too many training instances to fit in memory.<a data-type="indexterm" data-startref="xi_linearregressioncomputationalcomplexity42324_1" id="id1464"/><a data-type="indexterm" data-startref="xi_trainingmodelslinearregression4223_1" id="id1465"/></p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Gradient Descent"><div class="sect1" id="gradientDescent4">
<h1>Gradient Descent</h1>

<p><em>Gradient descent</em><a data-type="indexterm" data-primary="gradient descent (GD)" id="xi_gradientdescentGD424519_1"/><a data-type="indexterm" data-primary="linear regression" data-secondary="gradient descent in" id="xi_linearregressiongradientdescentin424519_1"/><a data-type="indexterm" data-primary="training models" data-secondary="gradient descent" id="xi_trainingmodelsgradientdescent424519_1"/> is a generic optimization algorithm capable of finding optimal solutions to a wide range of problems. The general idea of gradient descent is to tweak parameters iteratively in order to minimize a cost function.</p>

<p>Suppose you are lost in the mountains in a dense fog, and you can only feel the slope of the ground below your feet. A good strategy to get to the bottom of the valley quickly is to go downhill in the direction of the steepest slope. This is exactly what gradient descent does: it measures the local gradient of the error function with regard to the parameter vector<a data-type="indexterm" data-primary="parameter vector" id="id1466"/> <strong>θ</strong>, and it goes in the direction of descending gradient. Once the gradient is zero, you have reached a minimum!</p>

<p>In practice, you start by filling <strong>θ</strong> with random values (this is called <em>random initialization</em>).<a data-type="indexterm" data-primary="random initialization" id="id1467"/> Then you improve it gradually, taking one baby step at a time, each step attempting to decrease the cost function<a data-type="indexterm" data-primary="cost function" data-secondary="gradient descent" id="xi_costfunctiongradientdescent4249213_1"/> (e.g., the MSE), until the algorithm <em>converges</em> to a minimum (see <a data-type="xref" href="#gradient_descent_diagram">Figure 4-3</a>).</p>

<figure class="width-70"><div id="gradient_descent_diagram" class="figure">
<img src="assets/hmls_0403.png" alt="Diagram illustrating gradient descent where model parameters adjust in decreasing steps towards the minimum of a cost function, demonstrating the effect of a small learning rate." width="1137" height="630"/>
<h6><span class="label">Figure 4-3. </span>In this depiction of gradient descent, the model parameters are initialized randomly and get tweaked repeatedly to minimize the cost function; the learning step size is proportional to the slope of the cost function, so the steps gradually get smaller as the cost approaches the minimum</h6>
</div></figure>

<p>An important parameter in gradient descent is the size of the steps, determined by the <em>learning rate</em> hyperparameter<a data-type="indexterm" data-primary="hyperparameters" data-secondary="learning rate" id="id1468"/><a data-type="indexterm" data-primary="learning rate" data-secondary="too small" id="id1469"/>. If the learning rate is too small, then the algorithm will have to go through many iterations to converge, which will take a long time (see <a data-type="xref" href="#small_learning_rate_diagram">Figure 4-4</a>).</p>

<figure class="width-70"><div id="small_learning_rate_diagram" class="figure">
<img src="assets/hmls_0404.png" alt="Diagram illustrating a gradient descent path with a small learning rate, showing slow progression towards the minimum cost." width="1131" height="582"/>
<h6><span class="label">Figure 4-4. </span>Learning rate too small</h6>
</div></figure>

<p>On the other hand, if the learning rate is too high, you might jump across the valley and end up on the other side, possibly even higher up than you were before. This might make the algorithm diverge, with larger and larger values, failing to find a good solution (see <a data-type="xref" href="#large_learning_rate_diagram">Figure 4-5</a>).</p>

<figure class="width-70"><div id="large_learning_rate_diagram" class="figure">
<img src="assets/hmls_0405.png" alt="Diagram illustrating how a high learning rate can cause gradient descent to overshoot the optimal point, resulting in divergence." width="1131" height="582"/>
<h6><span class="label">Figure 4-5. </span>Learning rate too high</h6>
</div></figure>

<p>Additionally, not all cost functions look like nice, regular bowls. There may be holes, ridges, plateaus, and all sorts of irregular terrain, making convergence to the minimum difficult. <a data-type="xref" href="#gradient_descent_pitfalls_diagram">Figure 4-6</a> shows the two main challenges with gradient descent. If the random initialization<a data-type="indexterm" data-primary="random initialization" id="id1470"/> starts the algorithm on the left, then it will converge to a <em>local minimum</em>, which is not as good as the <em>global minimum</em>.<a data-type="indexterm" data-primary="global versus local minimum, gradient descent" id="id1471"/><a data-type="indexterm" data-primary="gradient descent (GD)" data-secondary="local versus global minimum" id="id1472"/><a data-type="indexterm" data-primary="local versus global minimum, gradient descent" id="id1473"/> If it starts on the right, then it will take a very long time to cross the plateau. And if you stop too early, you will never reach the global minimum.</p>

<figure class="width-70"><div id="gradient_descent_pitfalls_diagram" class="figure">
<img src="assets/hmls_0406.png" alt="Diagram illustrating gradient descent pitfalls, showing a local minimum trap and a plateau that slows progress toward the global minimum." width="1134" height="587"/>
<h6><span class="label">Figure 4-6. </span>Gradient descent pitfalls</h6>
</div></figure>

<p>Fortunately, the MSE cost function for a linear regression model happens to be a <em>convex function</em>,<a data-type="indexterm" data-primary="convex functions" id="id1474"/> which means that if you pick any two points on the curve, the line segment joining them is never below the curve. This implies that there are no local minima, just one global minimum. It is also a continuous function with a slope that never changes abruptly.⁠<sup><a data-type="noteref" id="id1475-marker" href="ch04.html#id1475">2</a></sup> These two facts have a great consequence: gradient descent is guaranteed to approach arbitrarily closely the global minimum (if you wait long enough and if the learning rate is not too high).</p>

<p>While the cost function has the shape of a bowl, it can be an elongated bowl if the features have very different scales. <a data-type="xref" href="#elongated_bowl_diagram">Figure 4-7</a> shows gradient descent on a training set where features 1 and 2 have the same scale (on the left), and on a training set where feature 1 has much smaller values than feature 2 (on the right).⁠<sup><a data-type="noteref" id="id1476-marker" href="ch04.html#id1476">3</a></sup></p>

<p>As you can see, on the left the gradient descent algorithm goes straight toward the minimum, thereby reaching it quickly, whereas on the right it first goes in a direction almost orthogonal to the direction of the global minimum, and it ends with a long march down an almost flat valley. It will eventually reach the minimum, but it will take a long time.</p>

<p>This diagram also illustrates the fact that training a model means searching for a combination of model parameters<a data-type="indexterm" data-primary="model parameters" id="id1477"/> that minimizes a cost function (over the training set). It is a search in the model’s <em>parameter space</em>.<a data-type="indexterm" data-primary="parameter space" id="id1478"/> The more parameters a model has, the more dimensions this space has, and the harder the search is: searching for a needle in a 300-dimensional haystack is much trickier than in 3 dimensions. Fortunately, since the cost function is convex in the case of linear regression, the needle is simply at the bottom of the bowl.</p>

<figure class="width-90"><div id="elongated_bowl_diagram" class="figure">
<img src="assets/hmls_0407.png" alt="Diagram showing gradient descent paths on cost function contours; left is circular indicating equal feature scaling, right is elongated showing uneven scaling." width="1422" height="639"/>
<h6><span class="label">Figure 4-7. </span>Gradient descent with (left) and without (right) feature scaling</h6>
</div></figure>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>When using gradient descent, you should ensure that all features have a similar scale<a data-type="indexterm" data-primary="feature scaling" id="id1479"/> (e.g., using Scikit-Learn’s <code translate="no">StandardScaler</code> class), or else it will take much longer to converge.</p>
</div>








<section data-type="sect2" data-pdf-bookmark="Batch Gradient Descent"><div class="sect2" id="id76">
<h2>Batch Gradient Descent</h2>

<p>Most<a data-type="indexterm" data-primary="batch gradient descent" id="xi_batchgradientdescent42985_1"/><a data-type="indexterm" data-primary="gradient descent (GD)" data-secondary="batch gradient descent" id="xi_gradientdescentGDbatchgradientdescent42985_1"/> models have more than one model parameter. Therefore, to implement gradient descent, you need to compute the gradient of the cost function with regard to each model parameter <em>θ</em><sub><em>j</em></sub>. In other words, you need to calculate how much the cost function will change if you change <em>θ</em><sub><em>j</em></sub> just a little bit. This is called a <em>partial derivative</em>.<a data-type="indexterm" data-primary="partial derivative" id="id1480"/> It is like asking, “What is the slope of the mountain toward the east?” and then asking the same question facing north (and so on for all other dimensions, if you can imagine a universe with more than three dimensions). <a data-type="xref" href="#mse_partial_derivatives">Equation 4-6</a> computes the partial derivative of the MSE with regard to parameter <em>θ</em><sub><em>j</em></sub>, denoted ∂ MSE(<strong>θ</strong>) / ∂θ<sub><em>j</em></sub>.</p>
<div id="mse_partial_derivatives" data-type="equation"><h5><span class="label">Equation 4-6. </span>Partial derivatives of the cost function</h5><math display="block">
  <mrow>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac><mi>∂</mi> <mrow><mi>∂</mi><msub><mi>θ</mi> <mi>j</mi> </msub></mrow></mfrac>
    </mstyle>
    <mtext>MSE</mtext>
    <mrow>
      <mo>(</mo>
      <mi mathvariant="bold">θ</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac><mn>2</mn> <mi>m</mi></mfrac>
    </mstyle>
    <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </munderover>
    <mrow>
      <mo>(</mo>
      <msup><mi mathvariant="bold">θ</mi> <mo>⊺</mo> </msup>
      <msup><mi mathvariant="bold">x</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msup>
      <mo>-</mo>
      <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msup>
      <mo>)</mo>
    </mrow>
    <mspace width="0.166667em"/>
    <msubsup><mi>x</mi> <mi>j</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msubsup>
  </mrow>
</math>
</div>

<p>Instead of computing these partial derivatives individually, you can use <a data-type="xref" href="#mse_gradient_vector">Equation 4-7</a> to compute them all in one go. The gradient vector, denoted ∇<sub><strong>θ</strong></sub>MSE(<strong>θ</strong>), contains all the partial derivatives of the cost function (one for each model parameter).</p>
<div id="mse_gradient_vector" data-type="equation"><h5><span class="label">Equation 4-7. </span>Gradient vector of the cost function</h5><math display="block">
  <mrow>
    <msub><mi>∇</mi> <mi mathvariant="bold">θ</mi> </msub>
    <mspace width="0.166667em"/>
    <mtext>MSE</mtext>
    <mrow>
      <mo>(</mo>
      <mi mathvariant="bold">θ</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
<mrow>
<mo stretchy="true">(</mo>
      <mtable>

        <mtr>
          <mtd>
            <mrow>
              <mfrac><mi>∂</mi> <mrow><mi>∂</mi><msub><mi>θ</mi> <mn>0</mn> </msub></mrow></mfrac>
              <mtext>MSE</mtext>
              <mrow>
                <mo>(</mo>
                <mi mathvariant="bold">θ</mi>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mrow>
              <mfrac><mi>∂</mi> <mrow><mi>∂</mi><msub><mi>θ</mi> <mn>1</mn> </msub></mrow></mfrac>
              <mtext>MSE</mtext>
              <mrow>
                <mo>(</mo>
                <mi mathvariant="bold">θ</mi>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mo>⋮</mo>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mrow>
              <mfrac><mi>∂</mi> <mrow><mi>∂</mi><msub><mi>θ</mi> <mi>n</mi> </msub></mrow></mfrac>
              <mtext>MSE</mtext>
              <mrow>
                <mo>(</mo>
                <mi mathvariant="bold">θ</mi>
                <mo>)</mo>
              </mrow>
            </mrow>
          </mtd>
        </mtr>

      </mtable>
    <mo stretchy="true">)</mo>
</mrow>
    <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac><mn>2</mn> <mi>m</mi></mfrac>
    </mstyle>
    <msup><mi mathvariant="bold">X</mi> <mo>⊺</mo> </msup>
    <mrow>
      <mo>(</mo>
      <mi mathvariant="bold">X</mi>
      <mi mathvariant="bold">θ</mi>
      <mo>-</mo>
      <mi mathvariant="bold">y</mi>
      <mo>)</mo>
    </mrow>
  </mrow>
</math>
</div>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Notice that this formula involves calculations over the full training set <strong>X</strong>, at each gradient descent step! This is why the algorithm is called <em>batch gradient descent</em>: it uses the whole batch of training data at every step (actually, <em>full gradient descent</em><a data-type="indexterm" data-primary="full gradient descent" id="id1481"/> would probably be a better name). As a result, it is terribly slow on very large training sets (we will look at some much faster gradient descent algorithms shortly). However, gradient descent scales well with the number of features; training a linear regression model when there are hundreds of thousands of features is much faster using gradient descent than using the normal equation or SVD<a data-type="indexterm" data-startref="xi_costfunctiongradientdescent4249213_1" id="id1482"/> decomposition.</p>
</div>

<p>Once you have the gradient vector, which points uphill, just go in the opposite direction to go downhill. This means subtracting ∇<sub><strong>θ</strong></sub>MSE(<strong>θ</strong>) from <strong>θ</strong>. This is where the learning rate <em>η</em> comes into play:⁠<sup><a data-type="noteref" id="id1483-marker" href="ch04.html#id1483">4</a></sup> multiply the gradient vector by <em>η</em> to determine the size of the downhill step (<a data-type="xref" href="#gradient_descent_step">Equation 4-8</a>).</p>
<div id="gradient_descent_step" data-type="equation"><h5><span class="label">Equation 4-8. </span>Gradient descent step</h5><math><msup><mi mathvariant="bold">θ</mi><mrow><mo>(</mo><mtext>next step</mtext><mo>)</mo></mrow></msup><mo>=</mo><mi mathvariant="bold">θ</mi><mo>-</mo><mi>η</mi><msub><mo>∇</mo><mi mathvariant="bold">θ</mi></msub><mo> </mo><mtext>MSE</mtext><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></math></div>

<p>Let’s look at a quick implementation of this algorithm:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">eta</code> <code class="o">=</code> <code class="mf">0.1</code>  <code class="c1"># learning rate</code>
<code class="n">n_epochs</code> <code class="o">=</code> <code class="mi">1000</code>
<code class="n">m</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">X_b</code><code class="p">)</code>  <code class="c1"># number of instances</code>

<code class="n">rng</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">default_rng</code><code class="p">(</code><code class="n">seed</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">theta</code> <code class="o">=</code> <code class="n">rng</code><code class="o">.</code><code class="n">standard_normal</code><code class="p">((</code><code class="mi">2</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>  <code class="c1"># randomly initialized model parameters</code>

<code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
    <code class="n">gradients</code> <code class="o">=</code> <code class="mi">2</code> <code class="o">/</code> <code class="n">m</code> <code class="o">*</code> <code class="n">X_b</code><code class="o">.</code><code class="n">T</code> <code class="o">@</code> <code class="p">(</code><code class="n">X_b</code> <code class="o">@</code> <code class="n">theta</code> <code class="o">-</code> <code class="n">y</code><code class="p">)</code>
    <code class="n">theta</code> <code class="o">=</code> <code class="n">theta</code> <code class="o">-</code> <code class="n">eta</code> <code class="o">*</code> <code class="n">gradients</code></pre>

<p>That wasn’t too hard! Each iteration over the training set is called an <em>epoch</em>. Let’s look at the resulting <code translate="no">theta</code>:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">theta</code><code class="w"/>
<code class="go">array([[3.69084138],</code>
<code class="go">       [3.32960458]])</code></pre>

<p>Hey, that’s exactly what the normal equation found! Gradient descent worked perfectly. But what if you had used a different learning rate<a data-type="indexterm" data-primary="learning rate" data-secondary="gradient descent" id="id1484"/> (<code translate="no">eta</code>)? <a data-type="xref" href="#gradient_descent_plot">Figure 4-8</a> shows the first 20 steps of gradient descent using three different learning rates. The line at the bottom of each plot represents the random starting point, then each epoch is represented by a darker and darker line.</p>

<figure><div id="gradient_descent_plot" class="figure">
<img src="assets/hmls_0408.png" alt="Diagram showing the first 20 steps of gradient descent with learning rates of 0.02, 0.1, and 0.5, illustrating slow convergence, optimal convergence, and divergence, respectively." width="2870" height="1065"/>
<h6><span class="label">Figure 4-8. </span>Gradient descent with various learning rates</h6>
</div></figure>

<p>On the left, the learning rate is too low: the algorithm will eventually reach the solution, but it will take a long time. In the middle, the learning rate looks pretty good: in just a few epochs, it has already converged to the solution. On the right, the learning rate is too high: the algorithm diverges, jumping all over the place and actually getting further and further away from the solution at every step.</p>

<p>To find a good learning rate, you can use grid search (see <a data-type="xref" href="ch02.html#project_chapter">Chapter 2</a>). However, you may want to limit the number of epochs<a data-type="indexterm" data-primary="epochs" id="id1485"/> so that grid search can eliminate models that take too long to converge.</p>

<p>You may wonder how to set the number of epochs. If it is too low, you will still be far away from the optimal solution when the algorithm stops; but if it is too high, you will waste time while the model parameters<a data-type="indexterm" data-primary="model parameters" id="id1486"/> do not change anymore. A simple solution is to set a very large number of epochs but to interrupt the algorithm when the gradient vector becomes tiny—that is, when its norm becomes smaller than a tiny number <em>ε</em> (called the <em>tolerance</em>)—<a data-type="indexterm" data-primary="tolerance (ε)" id="id1487"/><a data-type="indexterm" data-primary="ε (tolerance)" id="id1488"/>because this happens when gradient descent has (almost) reached the minimum.<a data-type="indexterm" data-startref="xi_batchgradientdescent42985_1" id="id1489"/><a data-type="indexterm" data-primary="convergence rate" id="id1490"/><a data-type="indexterm" data-startref="xi_gradientdescentGDbatchgradientdescent42985_1" id="id1491"/></p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id1492">
<h1>Convergence Rate</h1>
<p>When the cost function is convex and its slope does not change abruptly (as is the case for the MSE cost function), batch gradient descent with a fixed learning rate will eventually converge to the optimal solution, but you may have to wait a while: it can take <em>O</em>(1/<em>ε</em>) iterations to reach the optimum within a range of <em>ε</em>, depending on the shape of the cost function. If you divide the tolerance by 10 to have a more precise solution, then the algorithm may have to run about 10 times longer.</p>
</div></aside>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Stochastic Gradient Descent"><div class="sect2" id="id77">
<h2>Stochastic Gradient Descent</h2>

<p>The<a data-type="indexterm" data-primary="stochastic gradient descent (SGD)" id="xi_stochasticgradientdescentSGD44634_1"/> main problem with batch gradient descent is the fact that it uses the whole training set to compute the gradients at every step, which makes it very slow when the training set is large. At the opposite extreme, <em>stochastic gradient descent</em> picks a random instance in the training set at every step and computes the gradients based only on that single instance. Obviously, working on a single instance at a time makes the algorithm much faster because it has very little data to manipulate at every iteration. It also makes it possible to train on huge training sets, since only one instance needs to be in memory at each iteration (stochastic GD can be implemented as an out-of-core algorithm; see <a data-type="xref" href="ch01.html#landscape_chapter">Chapter 1</a>).</p>

<p>On the other hand, due to its stochastic (i.e., random) nature, this algorithm is much less regular than batch gradient descent: instead of gently decreasing until it reaches the minimum, the cost function will bounce up and down, decreasing only on average. Over time it will end up very close to the minimum, but once it gets there it will continue to bounce around, never settling down (see <a data-type="xref" href="#sgd_random_walk_diagram">Figure 4-9</a>). Once the algorithm stops, the final parameter values will be good, but not optimal.</p>

<p>When the cost function<a data-type="indexterm" data-primary="cost function" data-secondary="gradient descent" id="xi_costfunctiongradientdescent447223_1"/> is very irregular (as in <a data-type="xref" href="#gradient_descent_pitfalls_diagram">Figure 4-6</a>), this can actually help the algorithm jump out of local minima, so stochastic gradient descent has a better chance of finding the global minimum than batch gradient descent does.</p>

<p>Therefore, randomness is good to escape from local optima, but bad because it means that the algorithm can never settle at the minimum. One solution to this dilemma is to gradually reduce the learning rate. The steps start out large (which helps make quick progress and escape local minima), then get smaller and smaller, allowing the algorithm to settle at the global minimum. This process is akin to <em>simulated annealing</em>,<a data-type="indexterm" data-primary="simulated annealing" id="id1493"/> an algorithm inspired by the process in metallurgy of annealing, where molten metal is slowly cooled down. The function that determines the learning rate at each iteration is called the <em>learning schedule</em>.<a data-type="indexterm" data-primary="learning schedules" id="id1494"/> If the learning rate<a data-type="indexterm" data-primary="learning rate" data-secondary="reduced too quickly" id="id1495"/> is reduced too quickly, you may get stuck in a local minimum, or even end up frozen halfway to the minimum. If the learning rate is reduced too slowly, you may jump around the minimum for a long time and end up with a suboptimal solution if you halt training too early.</p>

<figure class="width-55"><div id="sgd_random_walk_diagram" class="figure">
<img src="assets/hmls_0409.png" alt="Diagram illustrating the path of stochastic gradient descent, showing a random walk toward the minimum cost area on a contour plot." width="968" height="713"/>
<h6><span class="label">Figure 4-9. </span>With stochastic gradient descent, each training step is much faster but also much more stochastic than when using batch gradient descent</h6>
</div></figure>

<p>This code implements stochastic gradient descent using a simple learning schedule:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">n_epochs</code> <code class="o">=</code> <code class="mi">50</code>
<code class="n">t0</code><code class="p">,</code> <code class="n">t1</code> <code class="o">=</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">50</code>  <code class="c1"># learning schedule hyperparameters</code>

<code class="k">def</code> <code class="nf">learning_schedule</code><code class="p">(</code><code class="n">t</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">t0</code> <code class="o">/</code> <code class="p">(</code><code class="n">t</code> <code class="o">+</code> <code class="n">t1</code><code class="p">)</code>

<code class="n">rng</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">default_rng</code><code class="p">(</code><code class="n">seed</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">theta</code> <code class="o">=</code> <code class="n">rng</code><code class="o">.</code><code class="n">standard_normal</code><code class="p">((</code><code class="mi">2</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>  <code class="c1"># randomly initialized model parameters</code>

<code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
    <code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">m</code><code class="p">):</code>
        <code class="n">random_index</code> <code class="o">=</code> <code class="n">rng</code><code class="o">.</code><code class="n">integers</code><code class="p">(</code><code class="n">m</code><code class="p">)</code>
        <code class="n">xi</code> <code class="o">=</code> <code class="n">X_b</code><code class="p">[</code><code class="n">random_index</code> <code class="p">:</code> <code class="n">random_index</code> <code class="o">+</code> <code class="mi">1</code><code class="p">]</code>
        <code class="n">yi</code> <code class="o">=</code> <code class="n">y</code><code class="p">[</code><code class="n">random_index</code> <code class="p">:</code> <code class="n">random_index</code> <code class="o">+</code> <code class="mi">1</code><code class="p">]</code>
        <code class="n">gradients</code> <code class="o">=</code> <code class="mi">2</code> <code class="o">*</code> <code class="n">xi</code><code class="o">.</code><code class="n">T</code> <code class="o">@</code> <code class="p">(</code><code class="n">xi</code> <code class="o">@</code> <code class="n">theta</code> <code class="o">-</code> <code class="n">yi</code><code class="p">)</code>  <code class="c1"># for SGD, do not divide by m</code>
        <code class="n">eta</code> <code class="o">=</code> <code class="n">learning_schedule</code><code class="p">(</code><code class="n">epoch</code> <code class="o">*</code> <code class="n">m</code> <code class="o">+</code> <code class="n">iteration</code><code class="p">)</code>
        <code class="n">theta</code> <code class="o">=</code> <code class="n">theta</code> <code class="o">-</code> <code class="n">eta</code> <code class="o">*</code> <code class="n">gradients</code></pre>

<p>By convention we iterate by rounds of <em>m</em> iterations; each round is called an <em>epoch</em>, as earlier. While the batch gradient descent code iterated 1,000 times through the whole training set, this code goes through the training set only 50 times and reaches a pretty good solution:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">theta</code><code class="w"/>
<code class="go">array([[3.69826475],</code>
<code class="go">       [3.30748311]])</code></pre>

<p><a data-type="xref" href="#sgd_plot">Figure 4-10</a> shows the first 20 steps of training (notice how irregular the steps are).</p>

<figure class="width-70"><div id="sgd_plot" class="figure">
<img src="assets/hmls_0410.png" alt="Scatter plot showing multiple linear regression lines demonstrating the first 20 steps of stochastic gradient descent, illustrating how the algorithm converges towards optimal parameters." width="1669" height="1071"/>
<h6><span class="label">Figure 4-10. </span>The first 20 steps of stochastic gradient descent</h6>
</div></figure>

<p>Note that since instances are picked randomly, some instances may be picked several times per epoch, while others may not be picked at all. If you want to be sure that the algorithm goes through every instance at each epoch, another approach is to shuffle the training set (making sure to shuffle the input features and the labels jointly), then go through it instance by instance, then shuffle it again, and so on. However, this approach is more complex, and it generally does not improve the result.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>When using stochastic gradient descent, the training instances must be independent and identically distributed (IID) <a data-type="indexterm" data-primary="independent and identically distributed (IID), training instances as" id="id1496"/><a data-type="indexterm" data-primary="IID (independent and identically distributed), training instances as" id="id1497"/>to ensure that the parameters get pulled toward the global optimum, on average. A simple way to ensure this is to shuffle the instances during training (e.g., pick each instance randomly, or shuffle<a data-type="indexterm" data-primary="shuffling data" id="id1498"/> the training set at the beginning of each epoch). If you do not shuffle the instances—for example, if the instances are sorted by label—then SGD will start by optimizing for one label, then the next, and so on, and it will not settle close to the global minimum.</p>
</div>

<p>To perform linear regression<a data-type="indexterm" data-primary="linear regression" data-secondary="using stochastic gradient descent" data-secondary-sortas="stochastic" id="id1499"/> using stochastic GD with Scikit-Learn, you can use the <code translate="no">SGDRegressor</code> class, which defaults to optimizing the MSE cost function. The following code runs for a maximum of 1,000 epochs (<code translate="no">max_iter</code>) or until the loss drops by less than 10<sup>–5</sup> (<code translate="no">tol</code>) during 100 epochs (<code translate="no">n_iter_no_change</code>). It starts with a learning rate of 0.01 (<code translate="no">eta0</code>), using the default learning schedule (different from the one we used). Lastly, it does not use any regularization (<code translate="no">penalty=None</code>; more details on this shortly)<a data-type="indexterm" data-primary="sklearn" data-secondary="linear_model.SGDRegressor" id="id1500"/><a data-type="indexterm" data-primary="SGDRegressor" id="id1501"/>:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">SGDRegressor</code>

<code class="n">sgd_reg</code> <code class="o">=</code> <code class="n">SGDRegressor</code><code class="p">(</code><code class="n">max_iter</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code> <code class="n">tol</code><code class="o">=</code><code class="mf">1e-5</code><code class="p">,</code> <code class="n">penalty</code><code class="o">=</code><code class="kc">None</code><code class="p">,</code> <code class="n">eta0</code><code class="o">=</code><code class="mf">0.01</code><code class="p">,</code>
                       <code class="n">n_iter_no_change</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">sgd_reg</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="o">.</code><code class="n">ravel</code><code class="p">())</code>  <code class="c1"># y.ravel() because fit() expects 1D targets</code></pre>

<p>Once again, you find a solution quite close to the one returned by the normal <span class="keep-together">equation</span>:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">sgd_reg</code><code class="o">.</code><code class="n">intercept_</code><code class="p">,</code> <code class="n">sgd_reg</code><code class="o">.</code><code class="n">coef_</code><code class="w"/>
<code class="go">(array([3.68899733]), array([3.33054574]))</code></pre>
<div data-type="tip"><h6>Tip</h6>
<p>All Scikit-Learn estimators can be trained using the <code translate="no">fit()</code> method<a data-type="indexterm" data-primary="fit(), Scikit-Learn" data-secondary="versus partial_fit()" data-secondary-sortas="partial_fit" id="id1502"/>, but some estimators also have a <code translate="no">partial_fit()</code><a data-type="indexterm" data-primary="partial_fit()" id="id1503"/> method that you can call to run a single round of training on one or more instances (it ignores hyperparameters like <code translate="no">max_iter</code> or <code translate="no">tol</code>). Repeatedly calling <code translate="no">partial_fit()</code> will gradually train the model. This is useful when you need more control over the training process. Other models have a <code translate="no">warm_start</code> hyperparameter instead (and some have both): if you set <code translate="no">warm_start=True</code>, calling the <code translate="no">fit()</code> method on a trained model will not reset the model; it will just continue training where it left off, respecting hyperparameters like <code translate="no">max_iter</code> and <code translate="no">tol</code>. Note that <code translate="no">fit()</code> resets the iteration counter used by the learning schedule, while <code translate="no">partial_fit()</code> does not.<a data-type="indexterm" data-startref="xi_costfunctiongradientdescent447223_1" id="id1504"/><a data-type="indexterm" data-startref="xi_stochasticgradientdescentSGD44634_1" id="id1505"/></p>
</div>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Mini-Batch Gradient Descent"><div class="sect2" id="id78">
<h2>Mini-Batch Gradient Descent</h2>

<p>The<a data-type="indexterm" data-primary="gradient descent (GD)" data-secondary="mini-batch gradient descent" id="xi_gradientdescentGDminibatchgradientdescent45424_1"/><a data-type="indexterm" data-primary="mini-batch gradient descent" id="xi_minibatchgradientdescent45424_1"/> last gradient descent algorithm we will look at is called <em>mini-batch gradient descent</em>. It is straightforward once you know batch and stochastic gradient descent: at each step, instead of <a data-type="indexterm" data-primary="GPUs" data-see="graphical processing units" id="id1506"/>computing the gradients based on the full training set (as in batch GD) or based on just one instance (as in stochastic GD), mini-batch GD computes the gradients on small random sets of instances called <em>mini-batches</em>. The main advantage of mini-batch GD over stochastic GD is that you can get a performance boost from hardware acceleration of matrix operations, especially when using <em>graphical processing units</em> (GPUs).<a data-type="indexterm" data-primary="graphical processing units (GPUs)" id="id1507"/></p>

<p>The algorithm’s progress<a data-type="indexterm" data-primary="gradient descent (GD)" data-secondary="algorithm comparisons" id="id1508"/> in parameter space is less erratic than with stochastic GD, especially with fairly large mini-batches. As a result, mini-batch GD will end up walking around a bit closer to the minimum than stochastic GD—but it may be harder for it to escape from local minima (in the case of problems that suffer from local minima, unlike linear regression with the MSE cost function). <a data-type="xref" href="#gradient_descent_paths_plot">Figure 4-11</a> shows the paths taken by the three gradient descent algorithms in parameter space during training. They all end up near the minimum, but batch GD’s path actually stops at the minimum, while both stochastic GD and mini-batch GD continue to walk around. However, don’t forget that batch GD takes a lot of time to take each step, and stochastic GD and mini-batch GD would also reach the minimum if you used a good learning schedule.</p>

<figure class="width-70"><div id="gradient_descent_paths_plot" class="figure">
<img src="assets/hmls_0411.png" alt="Diagram showing the paths of stochastic, mini-batch, and batch gradient descent algorithms in parameter space, illustrating their different approaches to convergence near the minimum." width="1972" height="1064"/>
<h6><span class="label">Figure 4-11. </span>Gradient descent paths in parameter space</h6>
</div></figure>

<p><a data-type="xref" href="#linear_regression_algorithm_comparison">Table 4-1</a> compares the algorithms we’ve discussed so far for linear regression⁠<sup><a data-type="noteref" id="id1509-marker" href="ch04.html#id1509">5</a></sup> (recall that <em>m</em> is the number of training instances and <em>n</em> is the number of features).</p>
<table id="linear_regression_algorithm_comparison">
<caption><span class="label">Table 4-1. </span>Comparison of algorithms for linear regression</caption>
<thead>
<tr>
<th>Algorithm</th>
<th>Large <em>m</em></th>
<th>Out-of-core support</th>
<th>Large <em>n</em></th>
<th>Hyperparams</th>
<th>Scaling required</th>
<th>Scikit-Learn</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>Normal equation</p></td>
<td><p>Fast</p></td>
<td><p>No</p></td>
<td><p>Slow</p></td>
<td><p>0</p></td>
<td><p>No</p></td>
<td><p>N/A</p></td>
</tr>
<tr>
<td><p>SVD</p></td>
<td><p>Fast</p></td>
<td><p>No</p></td>
<td><p>Slow</p></td>
<td><p>0</p></td>
<td><p>No</p></td>
<td><p><code translate="no">LinearRegression</code></p></td>
</tr>
<tr>
<td><p>Batch GD</p></td>
<td><p>Slow</p></td>
<td><p>No</p></td>
<td><p>Fast</p></td>
<td><p>2</p></td>
<td><p>Yes</p></td>
<td><p>N/A</p></td>
</tr>
<tr>
<td><p>Stochastic GD</p></td>
<td><p>Fast</p></td>
<td><p>Yes</p></td>
<td><p>Fast</p></td>
<td><p>≥2</p></td>
<td><p>Yes</p></td>
<td><p><code translate="no">SGDRegressor</code></p></td>
</tr>
<tr>
<td><p>Mini-batch GD</p></td>
<td><p>Fast</p></td>
<td><p>Yes</p></td>
<td><p>Fast</p></td>
<td><p>≥2</p></td>
<td><p>Yes</p></td>
<td><p>N/A</p></td>
</tr>
</tbody>
</table>

<p>There is almost no difference after training: all these algorithms end up with very similar models and make predictions in exactly the same way.<a data-type="indexterm" data-startref="xi_gradientdescentGD424519_1" id="id1510"/><a data-type="indexterm" data-startref="xi_gradientdescentGDminibatchgradientdescent45424_1" id="id1511"/><a data-type="indexterm" data-startref="xi_linearregression4972_1" id="id1512"/><a data-type="indexterm" data-startref="xi_linearregressiongradientdescentin424519_1" id="id1513"/><a data-type="indexterm" data-startref="xi_minibatchgradientdescent45424_1" id="id1514"/><a data-type="indexterm" data-startref="xi_trainingmodelsgradientdescent424519_1" id="id1515"/></p>
</div></section>
</div></section>






<section data-type="sect1" class="less_space pagebreak-before" data-pdf-bookmark="Polynomial Regression"><div class="sect1" id="polynomial_regression">
<h1>Polynomial Regression</h1>

<p>What<a data-type="indexterm" data-primary="data" data-secondary="underfitting of" id="xi_dataunderfittingof45695_1"/><a data-type="indexterm" data-primary="learning curves, overfit or underfit analysis" id="xi_learningcurvesoverfitorunderfitanalysis45695_1"/><a data-type="indexterm" data-primary="linear regression" data-secondary="learning curves in" id="xi_linearregressionlearningcurvesin45695_1"/><a data-type="indexterm" data-primary="overfitting of data" data-secondary="learning curves to assess" id="xi_overfittingofdatalearningcurvestoassess45695_1"/><a data-type="indexterm" data-primary="training models" data-secondary="learning curves in" id="xi_trainingmodelslearningcurvesin45695_1"/><a data-type="indexterm" data-primary="underfitting of data" id="xi_underfittingofdata45695_1"/> if your data is more complex than a straight line? Surprisingly, you can use a linear model to fit nonlinear data. A simple way to do this is to add powers of each feature as new features, then train a linear model on this extended set of features. This technique is called <em>polynomial regression</em>.<a data-type="indexterm" data-primary="polynomial regression" id="xi_polynomialregression4569304_1"/><a data-type="indexterm" data-primary="regression models" data-secondary="polynomial regression" id="xi_regressionmodelspolynomialregression4569304_1"/><a data-type="indexterm" data-primary="training models" data-secondary="polynomial regression" id="xi_trainingmodelspolynomialregression4569304_1"/></p>

<p>Let’s look at an example. First, we’ll generate some nonlinear data (see <a data-type="xref" href="#quadratic_data_plot">Figure 4-12</a>), based on a simple <em>quadratic equation</em>—<a data-type="indexterm" data-primary="quadratic equation" id="id1516"/>that’s an equation of the form <em>y</em> = <em>ax</em>² + <em>bx</em> + <em>c</em>—plus some noise:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">rng</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">default_rng</code><code class="p">(</code><code class="n">seed</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">m</code> <code class="o">=</code> <code class="mi">200</code>  <code class="c1"># number of instances</code>
<code class="n">X</code> <code class="o">=</code> <code class="mi">6</code> <code class="o">*</code> <code class="n">rng</code><code class="o">.</code><code class="n">random</code><code class="p">((</code><code class="n">m</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code> <code class="o">-</code> <code class="mi">3</code>
<code class="n">y</code> <code class="o">=</code> <code class="mf">0.5</code> <code class="o">*</code> <code class="n">X</code> <code class="o">**</code> <code class="mi">2</code> <code class="o">+</code> <code class="n">X</code> <code class="o">+</code> <code class="mi">2</code> <code class="o">+</code> <code class="n">rng</code><code class="o">.</code><code class="n">standard_normal</code><code class="p">((</code><code class="n">m</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code></pre>

<figure class="width-65"><div id="quadratic_data_plot" class="figure">
<img src="assets/hmls_0412.png" alt="Scatter plot of a nonlinear and noisy dataset showing a quadratic pattern, illustrating why a straight line wouldn't fit well." width="1670" height="1068"/>
<h6><span class="label">Figure 4-12. </span>Generated nonlinear and noisy dataset</h6>
</div></figure>

<p>Clearly, a straight line will never fit this data properly. So let’s use Scikit-Learn’s <code translate="no">PolynomialFeatures</code> class to transform our training data, adding the square (second-degree polynomial) of each feature in the training set as a new feature (in this case there is just one feature)<a data-type="indexterm" data-primary="PolynomialFeatures" id="xi_PolynomialFeatures4587286_1"/><a data-type="indexterm" data-primary="sklearn" data-secondary="preprocessing.PolynomialFeatures" id="xi_ScikitLearnsklearnpreprocessingPolynomialFeatures4587286_1"/>:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="kn">import</code> <code class="n">PolynomialFeatures</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">poly_features</code> <code class="o">=</code> <code class="n">PolynomialFeatures</code><code class="p">(</code><code class="n">degree</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">include_bias</code><code class="o">=</code><code class="kc">False</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X_poly</code> <code class="o">=</code> <code class="n">poly_features</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="w"/>
<code class="go">array([1.64373629])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X_poly</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="w"/>
<code class="go">array([1.64373629, 2.701869  ])</code></pre>

<p><code translate="no">X_poly</code> now contains the original feature of <code translate="no">X</code> plus the square of this feature. Now we can fit a <code translate="no">LinearRegression</code> model to this extended training data (<a data-type="xref" href="#quadratic_predictions_plot">Figure 4-13</a>):</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">lin_reg</code> <code class="o">=</code> <code class="n">LinearRegression</code><code class="p">()</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">lin_reg</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_poly</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">lin_reg</code><code class="o">.</code><code class="n">intercept_</code><code class="p">,</code> <code class="n">lin_reg</code><code class="o">.</code><code class="n">coef_</code><code class="w"/>
<code class="go">(array([2.00540719]), array([[1.11022126, 0.50526985]]))</code></pre>

<figure class="width-65"><div id="quadratic_predictions_plot" class="figure">
<img src="assets/hmls_0413.png" alt="Scatter plot showing polynomial regression model predictions with a red curve fitting the data points, illustrating the relationship between x1 and y." width="1670" height="1068"/>
<h6><span class="label">Figure 4-13. </span>Polynomial regression model predictions</h6>
</div></figure>

<p>Not bad: the model estimates 
<math>
  <mrow>
    <mover accent="true"><mi>y</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <mn>0.56</mn>
    <msup><mrow><msub><mi>x</mi> <mn>1</mn> </msub></mrow> <mn>2</mn> </msup>
    <mo>+</mo>
    <mn>0.93</mn>
    <msub><mi>x</mi> <mn>1</mn> </msub>
    <mo>+</mo>
    <mn>1.78</mn>
  </mrow>
</math> when in fact the original function was 
<math>
  <mrow>
    <mi>y</mi>
    <mo>=</mo>
    <mn>0.5</mn>
    <msup><mrow><msub><mi>x</mi> <mn>1</mn> </msub></mrow> <mn>2</mn> </msup>
    <mo>+</mo>
    <mn>1.0</mn>
    <msub><mi>x</mi> <mn>1</mn> </msub>
    <mo>+</mo>
    <mn>2.0</mn>
    <mo>+</mo>
    <mtext>Gaussian noise</mtext>
  </mrow>
</math>.</p>

<p>Note that when there are multiple features, polynomial regression is capable of finding relationships between features, which is something a plain linear regression model cannot do. This is made possible by the fact that <code translate="no">PolynomialFeatures</code> also adds all combinations of features up to the given degree. For example, if there were two features <em>a</em> and <em>b</em>, <code translate="no">PolynomialFeatures</code> with <code translate="no">degree=3</code> would not only add the features <em>a</em><sup>2</sup>, <em>a</em><sup>3</sup>, <em>b</em><sup>2</sup>, and <em>b</em><sup>3</sup>, but also the combinations <em>ab</em>, <em>a</em><sup>2</sup><em>b</em>, and <em>ab</em><sup>2</sup>.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p><code translate="no">PolynomialFeatures(degree=<em>d</em>)</code> transforms an array containing <em>n</em> features into an array containing (<em>n</em> + <em>d</em>)! / <em>d</em>!<em>n</em>! features, where <em>n</em>! is the <em>factorial</em> of <em>n</em>, equal to 1 × 2 × 3 × ⋯ × <em>n</em>. Beware of the combinatorial explosion of the number of features!<a data-type="indexterm" data-startref="xi_PolynomialFeatures4587286_1" id="id1517"/><a data-type="indexterm" data-startref="xi_ScikitLearnsklearnpreprocessingPolynomialFeatures4587286_1" id="id1518"/></p>
</div>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Learning Curves"><div class="sect1" id="id80">
<h1>Learning Curves</h1>

<p>If you perform high-degree polynomial regression, you will likely fit the training data much better than with plain linear regression<a data-type="indexterm" data-primary="linear regression" data-secondary="comparison of algorithms" id="id1519"/>. For example, <a data-type="xref" href="#high_degree_polynomials_plot">Figure 4-14</a> applies a 300-degree polynomial model to the preceding training data, and compares the result with a pure linear model and a quadratic model (second-degree polynomial). Notice how the 300-degree polynomial model wiggles around to get as close as possible to the training instances.</p>

<figure class="width-65"><div id="high_degree_polynomials_plot" class="figure">
<img src="assets/hmls_0414.png" alt="Graph comparing linear (1-degree), quadratic (2-degree), and 300-degree polynomial regression models, illustrating overfitting with the high-degree polynomial as it closely follows the data points." width="1670" height="1068"/>
<h6><span class="label">Figure 4-14. </span>High-degree polynomial regression</h6>
</div></figure>

<p>This high-degree polynomial regression model is severely overfitting the training data, while the linear model is underfitting it. The model that will generalize best in this case is the quadratic model, which makes sense because the data was generated using a quadratic model. But in general you won’t know what function generated the data, so how can you decide how complex your model should be? How can you tell that your model is overfitting or underfitting the data?</p>

<p>In <a data-type="xref" href="ch02.html#project_chapter">Chapter 2</a> you used cross-validation<a data-type="indexterm" data-primary="cross-validation" id="xi_crossvalidation465949_1"/> to get an estimate of a model’s generalization performance. If a model performs well on the training data but generalizes poorly according to the cross-validation metrics, then your model is overfitting. If it performs poorly on both, then it is underfitting. This is one way to tell when a model is too simple or too complex.</p>

<p>Another way to tell is to look at the <em>learning curves</em>, which are plots of the model’s training error and validation error as a function of the training iteration: just evaluate the model at regular intervals during training on both the training set and the validation set, and plot the results. If the model cannot be trained incrementally (i.e., if it does not support <code translate="no">partial_fit()</code> or <code translate="no">warm_start</code>), then you must train it several times on gradually larger subsets of the training set.</p>

<p>Scikit-Learn has a useful <code translate="no">learning_curve()</code><a data-type="indexterm" data-primary="learning_curve()" id="id1520"/><a data-type="indexterm" data-primary="sklearn" data-secondary="model_selection.learning_curve()" id="id1521"/> function to help with this: it trains and evaluates the model using cross-validation. By default it retrains the model on growing subsets of the training set, but if the model supports incremental learning you can set <code translate="no">exploit_incremental_learning=True</code> when calling <code translate="no">learning_curve()</code> and it will train the model incrementally instead. The function returns the training set sizes at which it evaluated the model, and the training and validation scores it measured for each size and for each cross-validation fold. Let’s use this function to look at the learning curves of the plain linear regression model (see <a data-type="xref" href="#underfitting_learning_curves_plot">Figure 4-15</a>):</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">learning_curve</code>

<code class="n">train_sizes</code><code class="p">,</code> <code class="n">train_scores</code><code class="p">,</code> <code class="n">valid_scores</code> <code class="o">=</code> <code class="n">learning_curve</code><code class="p">(</code>
    <code class="n">LinearRegression</code><code class="p">(),</code> <code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">train_sizes</code><code class="o">=</code><code class="n">np</code><code class="o">.</code><code class="n">linspace</code><code class="p">(</code><code class="mf">0.01</code><code class="p">,</code> <code class="mf">1.0</code><code class="p">,</code> <code class="mi">40</code><code class="p">),</code> <code class="n">cv</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code>
    <code class="n">scoring</code><code class="o">=</code><code class="s2">"neg_root_mean_squared_error"</code><code class="p">)</code>
<code class="n">train_errors</code> <code class="o">=</code> <code class="o">-</code><code class="n">train_scores</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="n">valid_errors</code> <code class="o">=</code> <code class="o">-</code><code class="n">valid_scores</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>

<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">train_sizes</code><code class="p">,</code> <code class="n">train_errors</code><code class="p">,</code> <code class="s2">"r-+"</code><code class="p">,</code> <code class="n">linewidth</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s2">"train"</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">train_sizes</code><code class="p">,</code> <code class="n">valid_errors</code><code class="p">,</code> <code class="s2">"b-"</code><code class="p">,</code> <code class="n">linewidth</code><code class="o">=</code><code class="mi">3</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s2">"valid"</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># beautify the figure: add labels, axis, grid, and legend</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

<figure class="width-60"><div id="underfitting_learning_curves_plot" class="figure">
<img src="assets/hmls_0415.png" alt="Line graph of learning curves shows root mean square error (RMSE) decreasing and plateauing for both training and validation sets as training set size increases, indicating underfitting." width="1665" height="1071"/>
<h6><span class="label">Figure 4-15. </span>Learning curves</h6>
</div></figure>

<p>This model is underfitting, it’s too simple for the data. How can we tell? Well, let’s look at the training error. When there are just one or two instances in the training set, the model can fit them perfectly, which is why the curve starts at zero. But as new instances are added to the training set, it becomes impossible for the model to fit the training data perfectly, both because the data is noisy and because it is not linear at all. So the error on the training data goes up until it reaches a plateau, at which point adding new instances to the training set doesn’t make the average error much better or worse. Now let’s look at the validation error. When the model is trained on very few training instances, it is incapable of generalizing properly, which is why the validation error is initially quite large. Then, as the model is shown more training examples, it learns, and thus the validation error slowly goes down. However, once again a straight line cannot do a good job of modeling the data, so the error ends up at a plateau, very close to the other curve.</p>

<p>These learning curves are typical of a model that’s underfitting. Both curves have reached a plateau; they are close and fairly high.</p>
<div data-type="tip"><h6>Tip</h6>
<p>If your model is underfitting the training data, adding more training examples will not help. You need to use a better model or come up with better features.</p>
</div>

<p>Now let’s look at the learning curves of a 10th-degree polynomial model on the same data (<a data-type="xref" href="#learning_curves_plot">Figure 4-16</a>)<a data-type="indexterm" data-primary="pipelines" id="id1522"/>:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.pipeline</code> <code class="kn">import</code> <code class="n">make_pipeline</code>

<code class="n">polynomial_regression</code> <code class="o">=</code> <code class="n">make_pipeline</code><code class="p">(</code>
    <code class="n">PolynomialFeatures</code><code class="p">(</code><code class="n">degree</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code> <code class="n">include_bias</code><code class="o">=</code><code class="kc">False</code><code class="p">),</code>
    <code class="n">LinearRegression</code><code class="p">())</code>

<code class="n">train_sizes</code><code class="p">,</code> <code class="n">train_scores</code><code class="p">,</code> <code class="n">valid_scores</code> <code class="o">=</code> <code class="n">learning_curve</code><code class="p">(</code>
    <code class="n">polynomial_regression</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">train_sizes</code><code class="o">=</code><code class="n">np</code><code class="o">.</code><code class="n">linspace</code><code class="p">(</code><code class="mf">0.01</code><code class="p">,</code> <code class="mf">1.0</code><code class="p">,</code> <code class="mi">40</code><code class="p">),</code> <code class="n">cv</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code>
    <code class="n">scoring</code><code class="o">=</code><code class="s2">"neg_root_mean_squared_error"</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># same as earlier</code></pre>

<figure class="width-60"><div id="learning_curves_plot" class="figure">
<img src="assets/hmls_0416.png" alt="Learning curves for a 10th-degree polynomial model showing root mean square error (RMSE) decreasing with larger training set sizes, with validation error stabilizing." width="1665" height="1071"/>
<h6><span class="label">Figure 4-16. </span>Learning curves for the 10th-degree polynomial model</h6>
</div></figure>

<p>These learning curves look a bit like the previous ones, but there are two very important differences:</p>

<ul>
<li>
<p>The error on the training data is much lower than before.</p>
</li>
<li>
<p>There is a gap between the curves. This means that the model performs better on the training data than on the validation data, which is the hallmark of an overfitting model. If you used a much larger training set, however, the two curves would continue to get closer.</p>
</li>
</ul>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id1523">
<h1>The Bias/Variance Trade-Off</h1>
<p>An important theoretical result of statistics and machine learning is the fact that a model’s generalization error can be expressed as the sum of three very different errors:</p>
<dl>
<dt><em>Bias</em></dt>
<dd>
<p>This part of the generalization error is due to wrong assumptions, such as assuming that the data is linear when it is actually quadratic. A high-bias model is most likely to underfit the training data.⁠<sup><a data-type="noteref" id="id1524-marker" href="ch04.html#id1524">6</a></sup></p>
</dd>
<dt><em>Variance</em></dt>
<dd>
<p>This part is due to the model’s excessive sensitivity to small variations in the training data. A model with many degrees of freedom (such as a high-degree polynomial model) is likely to have high variance and thus overfit the training data.</p>
</dd>
<dt><em>Irreducible error</em></dt>
<dd>
<p>This part is due to the noisiness of the data itself. The only way to reduce this part of the error is to clean up the data (e.g., fix the data sources, such as broken sensors, or detect and remove outliers).</p>
</dd>
</dl>

<p>Increasing a model’s complexity will typically increase its variance and reduce its bias. Conversely, reducing a model’s complexity (or increasing regularization) increases its bias and reduces its variance (see <a data-type="xref" href="#bias_variance_tradeoff_diagram">Figure 4-17</a>). This is why it is called a trade-off.</p>

<figure class="width-90"><div id="bias_variance_tradeoff_diagram" class="figure">
<img src="assets/hmls_0417.png" alt="Diagram illustrating the bias-variance trade-off, showing target and prediction distributions across varying model complexities and regularization levels." width="1444" height="675"/>
<h6><span class="label">Figure 4-17. </span>Bias/variance trade-off</h6>
</div></figure>
</div></aside>
<div data-type="tip"><h6>Tip</h6>
<p>One way to improve an overfitting model is to feed it more training data until the validation error gets close enough to the training error.<a data-type="indexterm" data-startref="xi_crossvalidation465949_1" id="id1525"/><a data-type="indexterm" data-startref="xi_dataunderfittingof45695_1" id="id1526"/><a data-type="indexterm" data-primary="degrees of freedom" id="id1527"/><a data-type="indexterm" data-primary="irreducible error" id="id1528"/><a data-type="indexterm" data-startref="xi_learningcurvesoverfitorunderfitanalysis45695_1" id="id1529"/><a data-type="indexterm" data-startref="xi_linearregressionlearningcurvesin45695_1" id="id1530"/><a data-type="indexterm" data-startref="xi_overfittingofdatalearningcurvestoassess45695_1" id="id1531"/><a data-type="indexterm" data-startref="xi_polynomialregression4569304_1" id="id1532"/><a data-type="indexterm" data-startref="xi_regressionmodelspolynomialregression4569304_1" id="id1533"/><a data-type="indexterm" data-startref="xi_trainingmodelslearningcurvesin45695_1" id="id1534"/><a data-type="indexterm" data-startref="xi_trainingmodelspolynomialregression4569304_1" id="id1535"/><a data-type="indexterm" data-startref="xi_underfittingofdata45695_1" id="id1536"/><a data-type="indexterm" data-primary="variance" data-secondary="bias/variance tradeoff" id="id1537"/><a data-type="indexterm" data-primary="bias" data-secondary="variance/bias tradeoff" id="id1538"/></p>
</div>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Regularized Linear Models"><div class="sect1" id="id396">
<h1>Regularized Linear Models</h1>

<p>As<a data-type="indexterm" data-primary="linear models" data-secondary="regularized" id="xi_linearmodelsregularized47423_1"/><a data-type="indexterm" data-primary="regularization" data-secondary="linear models" id="xi_regularizationlinearmodels47423_1"/><a data-type="indexterm" data-primary="training models" data-secondary="regularized linear models" id="xi_trainingmodelsregularizedlinearmodels47423_1"/> you saw in Chapters <a data-type="#xref" data-xrefstyle="select:labelnumber" href="ch01.html#landscape_chapter">1</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch02.html#project_chapter">2</a>, a good way to reduce overfitting is to regularize the model (i.e., to constrain it): the fewer degrees of freedom it has, the harder it will be for it to overfit the data. A simple way to regularize a polynomial model is to reduce the number of polynomial degrees.</p>

<p>What about linear models? Can we regularize them too? You may wonder why we may want to do that: aren’t linear models constrained enough already? Well, linear regression makes a few assumptions, including the fact that the true relationship between the inputs and the outputs is linear, the noise has zero mean, constant variance, and is independent of the inputs, plus the input matrix has full rank, meaning that the inputs are not colinear⁠<sup><a data-type="noteref" id="id1539-marker" href="ch04.html#id1539">7</a></sup> and there at least as many samples as parameters. In practice, some assumptions don’t hold perfectly. For example, some inputs may be close to colinear, which makes linear regression numerically unstable, meaning that very small differences in the training set can have a big impact on the trained model. Regularization can stabilize linear models and make them more accurate.</p>

<p>So how can we regularize a linear model? This is usually done by constraining its weights. In this section, we will discuss ridge regression, lasso regression, and elastic net regression, which implement three different ways to do that.</p>








<section data-type="sect2" data-pdf-bookmark="Ridge Regression"><div class="sect2" id="id81">
<h2>Ridge Regression</h2>

<p><em>Ridge regression</em><a data-type="indexterm" data-primary="linear regression" data-secondary="ridge regression" id="xi_linearregressionridgeregression474719_1"/><a data-type="indexterm" data-primary="regression models" data-secondary="ridge regression" id="xi_regressionmodelsridgeregression474719_1"/><a data-type="indexterm" data-primary="Tikhonov regularization" id="xi_Tikhonovregularization474719_1"/> (also called <em>Tikhonov regularization</em>) is a regularized version of linear regression: a <em>regularization term</em> equal to <math><mfrac><mi>α</mi><mi>m</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><msub><mi>θ</mi><mi>i</mi></msub><mn>2</mn></msup></math> is added to the MSE. This forces the learning algorithm to not only fit the data but also keep the model weights as small as possible. This constraint makes the model less flexible, preventing it from stretching itself too much to fit every data point: this reduces the risk of overfitting. Note that the regularization term should only be added to the cost function during training. Once the model is trained, you want to use the unregularized MSE (or the RMSE) to evaluate the model’s performance.</p>

<p class="pagebreak-before">The hyperparameter <em>α</em><a data-type="indexterm" data-primary="alpha (α) hyperparameter" id="id1540"/><a data-type="indexterm" data-primary="hyperparameters" data-secondary="α (alpha)" data-secondary-sortas="aaa" id="id1541"/><a data-type="indexterm" data-primary="α (alpha) hyperparameter" id="id1542"/> controls how much you want to regularize the model. If <em>α</em> = 0, then ridge regression is just linear regression. If <em>α</em> is very large, then all weights end up very close to zero and the result is a flat line going through the data’s mean. <a data-type="xref" href="#ridge_cost_function">Equation 4-9</a> presents the ridge regression cost<a data-type="indexterm" data-primary="cost function" data-secondary="ridge regression" id="id1543"/> function.⁠<sup><a data-type="noteref" id="id1544-marker" href="ch04.html#id1544">8</a></sup></p>
<div id="ridge_cost_function" data-type="equation"><h5><span class="label">Equation 4-9. </span>Ridge regression cost function</h5><math display="block">
<mrow><mi>J</mi><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></mrow><mo>=</mo><mrow><mtext>MSE</mtext><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></mrow><mo>+</mo><mfrac><mi>α</mi><mi>m</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><msub><mi>θ</mi><mi>i</mi></msub><mn>2</mn></msup></math></div>

<p>Note that the bias term <em>θ</em><sub>0</sub> is not regularized (the sum starts at <em>i</em> = 1, not 0). If we define <strong>w</strong> as the vector of feature weights (<em>θ</em><sub>1</sub> to <em>θ</em><sub><em>n</em></sub>), then the regularization term is equal to <em>α</em>(∥<strong>w</strong>∥<sub>2</sub>)<sup>2</sup> / <em>m</em>, where ∥<strong>w</strong>∥<sub>2</sub> represents the ℓ<sub>2</sub> norm of the weight vector.⁠<sup><a data-type="noteref" id="id1545-marker" href="ch04.html#id1545">9</a></sup> For batch gradient descent<a data-type="indexterm" data-primary="batch gradient descent" id="id1546"/><a data-type="indexterm" data-primary="gradient descent (GD)" data-secondary="batch gradient descent" id="id1547"/>, just add 2<em>α</em><strong>w</strong> / <em>m</em> to the part of the MSE gradient vector that corresponds to the feature weights, without adding anything to the gradient of the bias term (see <a data-type="xref" href="#mse_gradient_vector">Equation 4-7</a>).</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>It is important to scale the data (e.g., using a <code translate="no">StandardScaler</code>) before performing ridge regression, as it is sensitive to the scale of the input features. This is true of most regularized models.</p>
</div>

<p><a data-type="xref" href="#ridge_regression_plot">Figure 4-18</a> shows several ridge models that were trained on some very noisy linear data using different <em>α</em> values. On the left, plain ridge models are used, leading to linear predictions. On the right, the data is first expanded using 
<span class="keep-together"><code translate="no">PolynomialFeatures(degree=10)</code>,</span> then it is scaled using a <code translate="no">StandardScaler</code>, and finally the ridge models are applied to the resulting features: this is polynomial regression with ridge regularization<a data-type="indexterm" data-primary="regularization" data-secondary="ridge" id="id1548"/><a data-type="indexterm" data-primary="ridge regularization" id="id1549"/>. Note how increasing <em>α</em> leads to flatter (i.e., less extreme, more reasonable) predictions, thus reducing the model’s variance but increasing its bias.</p>

<figure><div id="ridge_regression_plot" class="figure">
<img src="assets/hmls_0418.png" alt="Graphs showing linear and polynomial ridge regression models applied to noisy linear data, with increasing alpha values resulting in flatter predictions." width="2569" height="919"/>
<h6><span class="label">Figure 4-18. </span>Linear (left) and polynomial (right) models, both with various levels of ridge regularization</h6>
</div></figure>

<p>As with linear regression, we can perform ridge regression either by computing a closed-form equation or by performing gradient descent. The pros and cons are the same. <a data-type="xref" href="#ridge_regression_solution">Equation 4-10</a> shows the closed-form solution<a data-type="indexterm" data-primary="closed-form equation/solution" id="id1550"/>, where <strong>A</strong> is the (<em>n</em> + 1) × (<em>n</em> + 1) <em>identity matrix</em>,<a data-type="indexterm" data-primary="identity matrix" id="id1551"/>⁠<sup><a data-type="noteref" id="id1552-marker" href="ch04.html#id1552">10</a></sup> except with a 0 in the top-left cell, corresponding to the bias term.</p>
<div class="fifty-percent" id="ridge_regression_solution" data-type="equation"><h5><span class="label">Equation 4-10. </span>Ridge regression closed-form solution</h5><math display="block">
  <mrow>
    <mover accent="true"><mi mathvariant="bold">θ</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">X</mi> <mo>⊺</mo> </msup><mi mathvariant="bold">X</mi><mo>+</mo><mi>α</mi><mi mathvariant="bold">A</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow> </msup>
    <msup><mi mathvariant="bold">X</mi> <mo>⊺</mo> </msup>
    <mi mathvariant="bold">y</mi>
  </mrow>
</math>
</div>

<p>Here is how to perform ridge regression with Scikit-Learn using a closed-form solution (a variant of <a data-type="xref" href="#ridge_regression_solution">Equation 4-10</a> that uses a matrix factorization technique by André-Louis Cholesky):</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">Ridge</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">ridge_reg</code> <code class="o">=</code> <code class="n">Ridge</code><code class="p">(</code><code class="n">alpha</code><code class="o">=</code><code class="mf">0.1</code><code class="p">,</code> <code class="n">solver</code><code class="o">=</code><code class="s2">"cholesky"</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">ridge_reg</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">ridge_reg</code><code class="o">.</code><code class="n">predict</code><code class="p">([[</code><code class="mf">1.5</code><code class="p">]])</code><code class="w"/>
<code class="go">array([1.84414523])</code></pre>

<p>And using stochastic gradient descent:⁠<sup><a data-type="noteref" id="id1553-marker" href="ch04.html#id1553">11</a></sup></p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">sgd_reg</code> <code class="o">=</code> <code class="n">SGDRegressor</code><code class="p">(</code><code class="n">penalty</code><code class="o">=</code><code class="s2">"l2"</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="mf">0.1</code> <code class="o">/</code> <code class="n">m</code><code class="p">,</code> <code class="n">tol</code><code class="o">=</code><code class="kc">None</code><code class="p">,</code><code class="w"/>
<code class="gp">... </code>                       <code class="n">max_iter</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code> <code class="n">eta0</code><code class="o">=</code><code class="mf">0.01</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code><code class="w"/>
<code class="gp">...</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">sgd_reg</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="o">.</code><code class="n">ravel</code><code class="p">())</code>  <code class="c1"># y.ravel() because fit() expects 1D targets</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">sgd_reg</code><code class="o">.</code><code class="n">predict</code><code class="p">([[</code><code class="mf">1.5</code><code class="p">]])</code><code class="w"/>
<code class="go">array([1.83659707])</code></pre>

<p>The <code translate="no">penalty</code> hyperparameter sets the type of regularization term to use. Specifying <code translate="no">"l2"</code> indicates that you want SGD to add a regularization term to the MSE cost function equal to <code translate="no">alpha</code> times the square of the ℓ<sub>2</sub> norm of the weight vector. This is just like ridge regression, except there’s no division by <em>m</em> in this case; that’s why we passed <code translate="no">alpha=0.1 / m</code>, to get the same result as <code translate="no">Ridge(alpha=0.1)</code>.</p>
<div data-type="tip"><h6>Tip</h6>
<p>The <code translate="no">RidgeCV</code> <a data-type="indexterm" data-primary="RidgeCV" id="id1554"/><a data-type="indexterm" data-primary="sklearn" data-secondary="linear_model.RidgeCV" id="id1555"/>class also performs ridge regression, but it automatically tunes hyperparameters using cross-validation. It’s roughly equivalent to using <code translate="no">GridSearchCV</code>, but it’s optimized for ridge regression and runs <em>much</em> faster. Several other estimators (mostly linear) also have efficient CV variants,<a data-type="indexterm" data-startref="xi_linearregressionridgeregression474719_1" id="id1556"/><a data-type="indexterm" data-startref="xi_regressionmodelsridgeregression474719_1" id="id1557"/><a data-type="indexterm" data-primary="regularization" data-secondary="Tikhonov" id="id1558"/><a data-type="indexterm" data-primary="ridge regression" id="id1559"/><a data-type="indexterm" data-startref="xi_Tikhonovregularization474719_1" id="id1560"/> such as <code translate="no">LassoCV</code> and 
<span class="keep-together"><code translate="no">ElasticNetCV</code>.</span></p>
</div>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Lasso Regression"><div class="sect2" id="lasso_regression">
<h2>Lasso Regression</h2>

<p><em>Least absolute shrinkage and selection operator regression</em><a data-type="indexterm" data-primary="cost function" data-secondary="lasso regression" id="xi_costfunctionlassoregression481461_1"/><a data-type="indexterm" data-primary="lasso regression" id="xi_lassoregression481461_1"/><a data-type="indexterm" data-primary="regression models" data-secondary="lasso regression" id="xi_regressionmodelslassoregression481461_1"/><a data-type="indexterm" data-primary="regularization" data-secondary="lasso regression" id="xi_regularizationlassoregression481461_1"/> (usually simply called <em>lasso regression</em>) is another regularized version of linear regression: just like ridge regression, it adds a regularization term to the cost function, but it uses the ℓ<sub>1</sub> norm of the weight vector instead of the square of the ℓ<sub>2</sub> norm (see <a data-type="xref" href="#lasso_cost_function">Equation 4-11</a>). Notice that the ℓ<sub>1</sub> norm is multiplied by 2<em>α</em>, whereas the ℓ<sub>2</sub> norm was multiplied by <em>α</em> / <em>m</em> in ridge regression. These factors were chosen to ensure that the optimal <em>α</em> value is independent from the training set size: different norms lead to different factors (see <a href="https://github.com/scikit-learn/scikit-learn/issues/15657">Scikit-Learn issue #15657</a> for more details).</p>
<div id="lasso_cost_function" data-type="equation"><h5><span class="label">Equation 4-11. </span>Lasso regression cost function</h5><math display="block"><mrow><mi>J</mi><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></mrow><mo>=</mo><mrow><mtext>MSE</mtext><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></mrow><mo>+</mo><mrow><mn>2</mn><mi>α</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfenced open="|" close="|"><msub><mi>θ</mi><mi>i</mi></msub></mfenced></mrow></math></div>

<p><a data-type="xref" href="#lasso_regression_plot">Figure 4-19</a> shows the same thing as <a data-type="xref" href="#ridge_regression_plot">Figure 4-18</a> but replaces the ridge models with lasso models and uses different <em>α</em> values.</p>

<p>An important characteristic of lasso regression is that it tends to eliminate the weights of the least important features (i.e., set them to zero). For example, the dashed line in the righthand plot in <a data-type="xref" href="#lasso_regression_plot">Figure 4-19</a> (with <em>α</em> = 0.01) looks roughly cubic: all the weights for the high-degree polynomial features are equal to zero. In other words, lasso regression automatically performs feature selection<a data-type="indexterm" data-primary="feature selection" id="id1561"/> and outputs a <em>sparse model</em><a data-type="indexterm" data-primary="sparse models" id="id1562"/> with few nonzero feature weights. Of course, there’s a trade-off: if you increase <em>α</em> too much, the model will be very sparse, but its performance will plummet.</p>

<figure><div id="lasso_regression_plot" class="figure">
<img src="assets/hmls_0419.png" alt="Plots showing linear (left) and polynomial (right) models using lasso regression with different α values, illustrating varying levels of regularization." width="2569" height="919"/>
<h6><span class="label">Figure 4-19. </span>Linear (left) and polynomial (right) models, both using various levels of lasso regularization</h6>
</div></figure>

<p>You can get a sense of why the ℓ<sub>1</sub> norm induces sparsity by looking at <a data-type="xref" href="#lasso_vs_ridge_plot">Figure 4-20</a>: the axes represent two model parameters, and the background contours represent different loss functions. In the top-left plot, the contours represent the ℓ<sub>1</sub> loss (|<em>θ</em><sub>1</sub>| + |<em>θ</em><sub>2</sub>|), which drops linearly as you get closer to any axis. For example, if you initialize the model parameters to <em>θ</em><sub>1</sub> = 2 and <em>θ</em><sub>2</sub> = 0.5, running gradient descent will decrement both parameters equally (as represented by the dashed yellow line); therefore <em>θ</em><sub>2</sub> will reach 0 first (since it was closer to 0 to begin with). After that, gradient descent will roll down the gutter until it reaches <em>θ</em><sub>1</sub> = 0 (with a bit of bouncing around, since the gradients of ℓ<sub>1</sub> never get close to 0: they are either –1 or 1 for each parameter). 
<span class="keep-together">In the top-right</span> plot, the contours represent lasso regression’s cost function (i.e., an MSE cost function plus an ℓ<sub>1</sub> loss). The small white circles show the path that gradient descent takes to optimize some model parameters that were initialized around 
<span class="keep-together"><em>θ</em><sub>1</sub> = 0.25 and <em>θ</em><sub>2</sub> = –1:</span> notice again how the path quickly reaches <em>θ</em><sub>2</sub> = 0, then rolls down the gutter and ends up bouncing around the global optimum (represented by the red square). If we increased <em>α</em>, the global optimum would move left along the dashed yellow line, while if we decreased <em>α</em>, the global optimum would move right (in this example, the optimal parameters for the unregularized MSE are <em>θ</em><sub>1</sub> = 2 and <em>θ</em><sub>2</sub> = 0.5).</p>

<p>The two bottom plots show the same thing but with an ℓ<sub>2</sub> penalty instead. In the bottom-left plot, you can see that the ℓ<sub>2</sub> loss decreases as we get closer to the origin, so gradient descent just takes a straight path toward that point. In the bottom-right plot, the contours represent ridge regression’s cost function (i.e., an MSE cost function plus an ℓ<sub>2</sub> loss). As you can see, the gradients get smaller as the parameters approach the global optimum, so gradient descent naturally slows down. This limits the bouncing around, which helps ridge converge faster than lasso regression. Also note that the optimal parameters (represented by the red square) get closer and closer to the origin when you increase <em>α</em>, but they never get eliminated entirely.</p>

<figure><div id="lasso_vs_ridge_plot" class="figure">
<img src="assets/hmls_0420.png" alt="Diagram comparing lasso and ridge regularization techniques, showing the paths of gradient descent in ℓ~1~ and ℓ~2~ penalty spaces, and illustrating how lasso encourages sparsity by reaching parameter zero faster." width="2896" height="2254"/>
<h6><span class="label">Figure 4-20. </span>Lasso versus ridge regularization</h6>
</div></figure>
<div data-type="tip"><h6>Tip</h6>
<p>To keep gradient descent from bouncing around the optimum at the end when using lasso regression, you need to gradually reduce the learning rate during training. It will still bounce around the optimum, but the steps will get smaller and smaller, so it will converge.</p>
</div>

<p>The lasso cost function is not differentiable at <em>θ</em><sub><em>i</em></sub> = 0 (for <em>i</em> = 1, 2, ⋯, <em>n</em>), but gradient descent still works if you use a <em>subgradient vector</em><a data-type="indexterm" data-primary="subgradient vector" id="id1563"/> <strong>g</strong>⁠<sup><a data-type="noteref" id="id1564-marker" href="ch04.html#id1564">12</a></sup> instead when any <em>θ</em><sub><em>i</em></sub> = 0. <a data-type="xref" href="#lasso_subgradient_vector">Equation 4-12</a> shows a subgradient vector equation you can use for gradient descent with the lasso cost function.</p>
<div id="lasso_subgradient_vector" data-type="equation" class="less_space pagebreak-before"><h5><span class="label">Equation 4-12. </span>Lasso regression subgradient vector</h5><math><mrow><mi>g</mi><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></mrow><mo>=</mo><mrow><msub><mo>∇</mo><mi mathvariant="bold">θ</mi></msub><mo> </mo><mtext>MSE</mtext><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></mrow><mo>+</mo><mrow><mn>2</mn><mi>α</mi><mfenced><mtable><mtr><mtd><mtext>sign</mtext><mo>(</mo><msub><mi>θ</mi><mn>1</mn></msub><mo>)</mo></mtd></mtr><mtr><mtd><mtext>sign</mtext><mo>(</mo><msub><mi>θ</mi><mn>2</mn></msub><mo>)</mo></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><mtext>sign</mtext><mo>(</mo><msub><mi>θ</mi><mi>n</mi></msub><mo>)</mo></mtd></mtr></mtable></mfenced></mrow><mo>  </mo><mtext>where </mtext><mrow><mtext>sign</mtext><mo>(</mo><msub><mi>θ</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>=</mo><mrow><mfenced open="{" close=""><mtable><mtr><mtd><mo>-</mo><mn>1</mn></mtd><mtd><mtext>if </mtext><msub><mi>θ</mi><mi>i</mi></msub><mo>&lt;</mo><mn>0</mn></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mtext>if </mtext><msub><mi>θ</mi><mi>i</mi></msub><mo>=</mo><mn>0</mn></mtd></mtr><mtr><mtd><mo>+</mo><mn>1</mn></mtd><mtd><mtext>if </mtext><msub><mi>θ</mi><mi>i</mi></msub><mo>&gt;</mo><mn>0</mn></mtd></mtr></mtable></mfenced></mrow></math></div>

<p>Here is a small Scikit-Learn example using the <code translate="no">Lasso</code> class:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">Lasso</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">lasso_reg</code> <code class="o">=</code> <code class="n">Lasso</code><code class="p">(</code><code class="n">alpha</code><code class="o">=</code><code class="mf">0.1</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">lasso_reg</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">lasso_reg</code><code class="o">.</code><code class="n">predict</code><code class="p">([[</code><code class="mf">1.5</code><code class="p">]])</code><code class="w"/>
<code class="go">array([1.87550211])</code></pre>

<p>Note that you could instead use <code translate="no">SGDRegressor(penalty="l1", alpha=0.1)</code>.<a data-type="indexterm" data-startref="xi_costfunctionlassoregression481461_1" id="id1565"/><a data-type="indexterm" data-startref="xi_lassoregression481461_1" id="id1566"/><a data-type="indexterm" data-startref="xi_regressionmodelslassoregression481461_1" id="id1567"/><a data-type="indexterm" data-startref="xi_regularizationlassoregression481461_1" id="id1568"/></p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Elastic Net Regression"><div class="sect2" id="id83">
<h2>Elastic Net Regression</h2>

<p><em>Elastic net regression</em><a data-type="indexterm" data-primary="elastic net" id="id1569"/> is a middle ground between ridge regression<a data-type="indexterm" data-primary="linear regression" data-secondary="ridge regression" id="id1570"/><a data-type="indexterm" data-primary="regression models" data-secondary="ridge regression" id="id1571"/><a data-type="indexterm" data-primary="regularization" data-secondary="elastic net" id="id1572"/><a data-type="indexterm" data-primary="ridge regression" id="id1573"/> and lasso regression. The regularization term is a weighted sum of both ridge and lasso’s regularization terms, and you can control the mix ratio <em>r</em>. When <em>r</em> = 0, elastic net is equivalent to ridge regression, and when <em>r</em> = 1, it is equivalent to lasso regression (<a data-type="xref" href="#elastic_net_cost_function">Equation 4-13</a>).<a data-type="indexterm" data-primary="cost function" data-secondary="elastic net" id="id1574"/></p>
<div id="elastic_net_cost_function" data-type="equation"><h5><span class="label">Equation 4-13. </span>Elastic net cost function</h5><math display="block"><mrow><mi>J</mi><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></mrow><mo>=</mo><mrow><mtext>MSE</mtext><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></mrow><mo>+</mo><mi>r</mi><mfenced><mrow><mn>2</mn><mi>α</mi><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mfenced open="|" close="|"><msub><mi>θ</mi><mi>i</mi></msub></mfenced></mrow></mfenced><mo>+</mo><mo>(</mo><mn>1</mn><mo>-</mo><mi>r</mi><mo>)</mo><mfenced><mrow><mfrac><mi>α</mi><mi>m</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msubsup><mi>θ</mi><mi>i</mi><mn>2</mn></msubsup></mrow></mfenced></math></div>

<p>So when should you use elastic net regression, or ridge, lasso, or plain linear regression<a data-type="indexterm" data-primary="Tikhonov regularization" id="id1575"/> (i.e., without any regularization)? It is almost always preferable to have at least a little bit of regularization, so generally you should avoid plain linear regression. Ridge is a good default, but if you suspect that only a few features are useful, you should prefer lasso or elastic net because they tend to reduce the useless features’ weights down to zero, as discussed earlier. In general, elastic net is preferred over lasso because lasso may behave erratically when the number of features is greater than the number of training instances or when several features are strongly correlated.</p>

<p>Here is a short example that uses Scikit-Learn’s <code translate="no">ElasticNet</code> (<code translate="no">l1_ratio</code> corresponds to the mix ratio <em>r</em>):</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">ElasticNet</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">elastic_net</code> <code class="o">=</code> <code class="n">ElasticNet</code><code class="p">(</code><code class="n">alpha</code><code class="o">=</code><code class="mf">0.1</code><code class="p">,</code> <code class="n">l1_ratio</code><code class="o">=</code><code class="mf">0.5</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">elastic_net</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">elastic_net</code><code class="o">.</code><code class="n">predict</code><code class="p">([[</code><code class="mf">1.5</code><code class="p">]])</code><code class="w"/>
<code class="go">array([1.8645014])</code></pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Early Stopping"><div class="sect2" id="id84">
<h2>Early Stopping</h2>

<p>A<a data-type="indexterm" data-primary="early stopping regularization" id="xi_earlystoppingregularization48782_1"/><a data-type="indexterm" data-primary="regularization" data-secondary="early stopping" id="xi_regularizationearlystopping48782_1"/> different way to regularize iterative learning algorithms such as gradient descent is to stop training as soon as the validation error reaches a minimum. This popular technique is called <em>early stopping</em>. <a data-type="xref" href="#early_stopping_plot">Figure 4-21</a> shows a complex model (in this case, a high-degree polynomial regression model) being trained with batch gradient descent on the quadratic dataset we used earlier. As the epochs go by, the algorithm learns, and its prediction error (RMSE) on the training set goes down, along with its prediction error on the validation set. After a while, though, the validation error stops decreasing and starts to go back up. This indicates that the model has started to overfit the training data. With early stopping you just stop training as soon as the validation error reaches the minimum. It is such a simple and efficient regularization technique that Geoffrey Hinton called it a “beautiful free lunch”.⁠<sup><a data-type="noteref" id="id1576-marker" href="ch04.html#id1576">13</a></sup> That said, the validation error sometimes comes back down after a while: this is<a data-type="indexterm" data-primary="double descent" id="id1577"/> called <em>double descent</em>. It’s fairly common with large neural networks, and is an area of active research.</p>

<figure class="width-65"><div id="early_stopping_plot" class="figure">
<img src="assets/hmls_0421.png" alt="Graph illustrating early stopping regularization with RMSE on the y-axis and epochs on the x-axis; the validation error is shown to increase after reaching the minimum, marked as the &quot;Best model.&quot;" width="1665" height="1071"/>
<h6><span class="label">Figure 4-21. </span>Early stopping regularization</h6>
</div></figure>
<div data-type="tip"><h6>Tip</h6>
<p>With stochastic<a data-type="indexterm" data-primary="stochastic gradient descent (SGD)" data-secondary="early stopping" id="id1578"/> and mini-batch gradient descent<a data-type="indexterm" data-primary="mini-batch gradient descent" id="id1579"/>, the curves are not so smooth, and it may be hard to know whether you have reached the minimum or not. One solution is to stop only after the validation error has been above the minimum for some time (when you are confident that the model will not do any better), then roll back the model parameters<a data-type="indexterm" data-primary="model parameters" id="id1580"/> to the point where the validation error was at a minimum.</p>
</div>

<p class="pagebreak-before">Here is a basic implementation of early stopping:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">copy</code> <code class="kn">import</code> <code class="n">deepcopy</code>
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">root_mean_squared_error</code>
<code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="kn">import</code> <code class="n">StandardScaler</code>

<code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">X_valid</code><code class="p">,</code> <code class="n">y_valid</code> <code class="o">=</code> <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># split the quadratic dataset</code>

<code class="n">preprocessing</code> <code class="o">=</code> <code class="n">make_pipeline</code><code class="p">(</code><code class="n">PolynomialFeatures</code><code class="p">(</code><code class="n">degree</code><code class="o">=</code><code class="mi">90</code><code class="p">,</code> <code class="n">include_bias</code><code class="o">=</code><code class="kc">False</code><code class="p">),</code>
                              <code class="n">StandardScaler</code><code class="p">())</code>
<code class="n">X_train_prep</code> <code class="o">=</code> <code class="n">preprocessing</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>
<code class="n">X_valid_prep</code> <code class="o">=</code> <code class="n">preprocessing</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">X_valid</code><code class="p">)</code>
<code class="n">sgd_reg</code> <code class="o">=</code> <code class="n">SGDRegressor</code><code class="p">(</code><code class="n">penalty</code><code class="o">=</code><code class="kc">None</code><code class="p">,</code> <code class="n">eta0</code><code class="o">=</code><code class="mf">0.002</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">n_epochs</code> <code class="o">=</code> <code class="mi">500</code>
<code class="n">best_valid_rmse</code> <code class="o">=</code> <code class="nb">float</code><code class="p">(</code><code class="s1">'inf'</code><code class="p">)</code>

<code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
    <code class="n">sgd_reg</code><code class="o">.</code><code class="n">partial_fit</code><code class="p">(</code><code class="n">X_train_prep</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>
    <code class="n">y_valid_predict</code> <code class="o">=</code> <code class="n">sgd_reg</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_valid_prep</code><code class="p">)</code>
    <code class="n">val_error</code> <code class="o">=</code> <code class="n">root_mean_squared_error</code><code class="p">(</code><code class="n">y_valid</code><code class="p">,</code> <code class="n">y_valid_predict</code><code class="p">)</code>
    <code class="k">if</code> <code class="n">val_error</code> <code class="o">&lt;</code> <code class="n">best_valid_rmse</code><code class="p">:</code>
        <code class="n">best_valid_rmse</code> <code class="o">=</code> <code class="n">val_error</code>
        <code class="n">best_model</code> <code class="o">=</code> <code class="n">deepcopy</code><code class="p">(</code><code class="n">sgd_reg</code><code class="p">)</code></pre>

<p>This code first adds the polynomial features and scales all the input features, both for the training set and for the validation set (the code assumes that you have split the original training set into a smaller training set and a validation set). Then it creates an <code translate="no">SGDRegressor</code><a data-type="indexterm" data-primary="sklearn" data-secondary="linear_model.SGDRegressor" id="id1581"/><a data-type="indexterm" data-primary="SGDRegressor" id="id1582"/> model with no regularization and a small learning rate. In the training loop, it calls <code translate="no">partial_fit()</code> instead of <code translate="no">fit()</code>, to perform incremental learning. At each epoch, it measures the RMSE<a data-type="indexterm" data-primary="root mean square error (RMSE)" id="id1583"/> on the validation set. If it is lower than the lowest RMSE seen so far, it saves a copy of the model in the <code translate="no">best_model</code> variable. This implementation does not actually stop training, but it lets you revert to the best model after training. Note that the model is copied using <code translate="no">copy.deepcopy()</code>,<a data-type="indexterm" data-primary="copy.deepcopy()" id="id1584"/><a data-type="indexterm" data-primary="deepcopy()" id="id1585"/> because it copies both the model’s hyperparameters <em>and</em> the learned parameters. In contrast, <code translate="no">sklearn.base.clone()</code><a data-type="indexterm" data-primary="clone()" id="id1586"/><a data-type="indexterm" data-primary="sklearn" data-secondary="base.clone()" id="id1587"/> only copies the model’s hyperparameters.<a data-type="indexterm" data-startref="xi_earlystoppingregularization48782_1" id="id1588"/><a data-type="indexterm" data-startref="xi_linearmodelsregularized47423_1" id="id1589"/><a data-type="indexterm" data-startref="xi_regularizationearlystopping48782_1" id="id1590"/><a data-type="indexterm" data-startref="xi_regularizationlinearmodels47423_1" id="id1591"/><a data-type="indexterm" data-startref="xi_trainingmodelsregularizedlinearmodels47423_1" id="id1592"/></p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Logistic Regression"><div class="sect1" id="id85">
<h1>Logistic Regression</h1>

<p>As<a data-type="indexterm" data-primary="logistic regression" id="xi_logisticregression49203_1"/><a data-type="indexterm" data-primary="training models" data-secondary="logistic regression" id="xi_trainingmodelslogisticregression49203_1"/> discussed in <a data-type="xref" href="ch01.html#landscape_chapter">Chapter 1</a>, some regression algorithms can be used for classification (and vice versa). <em>Logistic regression</em> (also called <em>logit regression</em>) is commonly used to estimate the probability that an instance belongs to a particular class (e.g., what is the probability that this email is spam?). If the estimated probability is greater than a given threshold (typically 50%), then the model predicts that the instance belongs to that class (called the <em>positive class</em>, labeled “1”),<a data-type="indexterm" data-primary="positive class" id="id1593"/> and otherwise it predicts that it does not (i.e., it belongs to the <em>negative class</em>, labeled “0”).<a data-type="indexterm" data-primary="negative class" id="id1594"/> This makes it a binary classifier<a data-type="indexterm" data-primary="binary classifiers" id="id1595"/><a data-type="indexterm" data-primary="classification" data-secondary="binary classifier" id="id1596"/>.</p>








<section data-type="sect2" data-pdf-bookmark="Estimating Probabilities"><div class="sect2" id="id86">
<h2>Estimating Probabilities</h2>

<p>So<a data-type="indexterm" data-primary="logistic regression" data-secondary="estimating probabilities" id="xi_logisticregressionestimatingprobabilities49233_1"/><a data-type="indexterm" data-primary="probabilities, estimating" id="xi_probabilitiesestimating49233_1"/> how does logistic regression work? Just like a linear regression model, a logistic regression model computes a weighted sum of the input features (plus a bias term), but instead of outputting the result directly like the linear regression model does, it outputs the <em>logistic</em> of this result (see <a data-type="xref" href="#logisticregression_model_estimated_probability_vectorized_form">Equation 4-14</a>).</p>
<div class="fifty-percent" id="logisticregression_model_estimated_probability_vectorized_form" data-type="equation"><h5><span class="label">Equation 4-14. </span>Logistic regression model estimated probability (vectorized form)</h5><math display="block">
  <mrow>
    <mover accent="true"><mi>p</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <msub><mi>h</mi> <mi mathvariant="bold">θ</mi> </msub>
    <mrow>
      <mo>(</mo>
      <mi mathvariant="bold">x</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mi>σ</mi>
    <mrow>
      <mo>(</mo>
      <msup><mi mathvariant="bold">θ</mi> <mo>⊺</mo> </msup>
      <mi mathvariant="bold">x</mi>
      <mo>)</mo>
    </mrow>
  </mrow>
</math></div>

<p>The logistic—denoted <em>σ</em>(·)—is a <em>sigmoid function</em><a data-type="indexterm" data-primary="sigmoid activation function" data-secondary="in logistic regression" data-secondary-sortas="logistic regression" id="id1597"/> (i.e., <em>S</em>-shaped) that outputs a number between 0 and 1. It is defined as shown in <a data-type="xref" href="#equation_four_fourteen">Equation 4-15</a> and <a data-type="xref" href="#logistic_function_plot">Figure 4-22</a>.<a data-type="indexterm" data-primary="logistic function" id="id1598"/></p>
<div data-type="equation" id="equation_four_fourteen">
<h5><span class="label">Equation 4-15. </span>Logistic function</h5>
<math display="block">
  <mrow>
    <mi>σ</mi>
    <mrow>
      <mo>(</mo>
      <mi>t</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac><mn>1</mn> <mrow><mn>1</mn><mo>+</mo><mo form="prefix">exp</mo><mo>(</mo><mo lspace="0%" rspace="0%">-</mo><mi>t</mi><mo>)</mo></mrow></mfrac>
    </mstyle>
  </mrow>
</math>
</div>

<figure><div id="logistic_function_plot" class="figure">
<img src="assets/hmls_0422.png" alt="Graph illustrating the logistic function, showing an S-shaped curve that rises from 0 to 1 as the input value increases." width="2269" height="762"/>
<h6><span class="label">Figure 4-22. </span>Logistic function</h6>
</div></figure>

<p>Once the logistic regression model has estimated the probability <math><mover><mi>p</mi><mo>^</mo></mover></math> = <em>h</em><sub><strong>θ</strong></sub>(<strong>x</strong>) that an instance <strong>x</strong> belongs to the positive class, it can make its prediction <em>ŷ</em> easily (see <a data-type="xref" href="#equation_four_fifteen">Equation 4-16</a>).</p>
<div data-type="equation" id="equation_four_fifteen">
<h5><span class="label">Equation 4-16. </span>Logistic regression model prediction using a 50% threshold <span class="keep-together">probability</span></h5>
<math display="block">
  <mrow>
    <mover accent="true"><mi>y</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <mfenced separators="" open="{" close="">
      <mtable>
        <mtr>
          <mtd columnalign="left">
            <mn>0</mn>
          </mtd>
          <mtd columnalign="left">
            <mrow>
              <mtext>if</mtext>
              <mspace width="4.pt"/>
              <mover accent="true"><mi>p</mi> <mo>^</mo></mover>
              <mo>&lt;</mo>
              <mn>0.5</mn>
            </mrow>
          </mtd>
        </mtr>
        <mtr>
          <mtd columnalign="left">
            <mn>1</mn>
          </mtd>
          <mtd columnalign="left">
            <mrow>
              <mtext>if</mtext>
              <mspace width="4.pt"/>
              <mover accent="true"><mi>p</mi> <mo>^</mo></mover>
              <mo>≥</mo>
              <mn>0.5</mn>
            </mrow>
          </mtd>
        </mtr>
      </mtable>
    </mfenced>
  </mrow>
</math>
</div>

<p class="pagebreak-before">Notice that <em>σ</em>(<em>t</em>) &lt; 0.5 when <em>t</em> &lt; 0, and <em>σ</em>(<em>t</em>) ≥ 0.5 when <em>t</em> ≥ 0, so a logistic regression model using the default threshold of 50% probability predicts 1 if <strong>θ</strong><sup>⊺</sup> <strong>x</strong> is positive and 0 if it is negative.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The score <em>t</em> is often called the <em>logit</em>.<a data-type="indexterm" data-primary="logit function" id="id1599"/> The name comes from the fact that the logit function, defined as logit(<em>p</em>) = log(<em>p</em> / (1 – <em>p</em>)), is the inverse of the logistic function. Indeed, if you compute the logit of the estimated probability <em>p</em>, you will find that the result is <em>t</em>. The logit is also called the <em>log-odds</em>,<a data-type="indexterm" data-primary="log-odds function" id="id1600"/> since it is the log of the ratio between the estimated probability for the positive class and the estimated probability for the negative class.<a data-type="indexterm" data-startref="xi_logisticregressionestimatingprobabilities49233_1" id="id1601"/><a data-type="indexterm" data-startref="xi_probabilitiesestimating49233_1" id="id1602"/></p>
</div>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Training and Cost Function"><div class="sect2" id="id87">
<h2>Training and Cost Function</h2>

<p>Now you know how a logistic regression model estimates probabilities and makes predictions. But how is it trained? The objective of training is to set the parameter vector<a data-type="indexterm" data-primary="parameter vector" id="id1603"/> <strong>θ</strong> so that the model estimates high probabilities for positive instances (<em>y</em> = 1) and low probabilities for negative instances (<em>y</em> = 0). This idea is captured by the cost function shown in <a data-type="xref" href="#cost_function_of_a_single_training_instance">Equation 4-17</a> for a single training instance <strong>x</strong>.<a data-type="indexterm" data-primary="cost function" data-secondary="logistic regression" id="xi_costfunctionlogisticregression41027448_1"/><a data-type="indexterm" data-primary="logistic regression" data-secondary="training and cost function" id="xi_logisticregressiontrainingandcostfunction41027448_1"/><a data-type="indexterm" data-primary="training set" data-secondary="cost function of" id="xi_trainingsetcostfunctionof41027448_1"/></p>
<div id="cost_function_of_a_single_training_instance" data-type="equation"><h5><span class="label">Equation 4-17. </span>Cost function of a single training instance</h5><math><mrow><mi>c</mi><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></mrow><mo>=</mo><mrow><mfenced open="{" close=""><mtable><mtr><mtd><mo>-</mo><mi>log</mi><mo>(</mo><mover accent="true"><mi>p</mi><mo>^</mo></mover><mo>)</mo></mtd><mtd><mtext>if </mtext><mi>y</mi><mo>=</mo><mn>1</mn></mtd></mtr><mtr><mtd><mo>-</mo><mi>log</mi><mo>(</mo><mn>1</mn><mo>-</mo><mover accent="true"><mi>p</mi><mo>^</mo></mover><mo>)</mo></mtd><mtd><mtext>if </mtext><mi>y</mi><mo>=</mo><mn>0</mn></mtd></mtr></mtable></mfenced></mrow></math></div>

<p>This cost function makes sense because  –log(<em>t</em>) grows very large when <em>t</em> approaches 0, so the cost will be large if the model estimates a probability close to 0 for a positive instance, and it will also be large if the model estimates a probability close to 1 for a negative instance. On the other hand, –log(<em>t</em>) is close to 0 when <em>t</em> is close to 1, so the cost will be close to 0 if the estimated probability is close to 0 for a negative instance or close to 1 for a positive instance, which is precisely what we want.</p>

<p>The cost function over the whole training set is the average cost over all training instances. It can be written in a single expression called the <em>log loss</em>,<a data-type="indexterm" data-primary="log loss" id="id1604"/> shown in <a data-type="xref" href="#logistic_regression_cost_function">Equation 4-18</a>.</p>
<div id="logistic_regression_cost_function" data-type="equation"><h5><span class="label">Equation 4-18. </span>Logistic regression cost function (log loss)</h5><math display="block"><mrow><mi>J</mi><mo>(</mo><mi mathvariant="bold">θ</mi><mo>)</mo></mrow><mo>=</mo><mrow><mo>-</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mfenced open="[" close="]"><mrow><msup><mi>y</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mi>l</mi><mi>o</mi><mi>g</mi><mfenced><msup><mover accent="true"><mi>p</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mfenced><mo>+</mo><mo>(</mo><mn>1</mn><mo>-</mo><msup><mi>y</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mfenced><mrow><mn>1</mn><mo>-</mo><msup><mover accent="true"><mi>p</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow></mfenced></mrow></mfenced></mrow></math></div>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>The log loss was not just pulled out of a hat. It can be shown mathematically (using Bayesian inference) that minimizing this loss will result in the model with the <em>maximum likelihood</em> of being optimal, assuming that the instances follow a Gaussian distribution<a data-type="indexterm" data-primary="Gaussian distribution" id="id1605"/> around the mean of their class. When you use the log loss, this is the implicit assumption you are making. The more wrong this assumption is, the more biased the model will be. Similarly, when we used the MSE to train linear regression models, we were implicitly assuming that the data was purely linear, plus some Gaussian noise. So, if the data is not linear (e.g., if it’s quadratic) or if the noise is not Gaussian (e.g., if outliers are not exponentially rare), then the model will be<a data-type="indexterm" data-startref="xi_costfunctionlogisticregression41027448_1" id="id1606"/><a data-type="indexterm" data-startref="xi_logisticregressiontrainingandcostfunction41027448_1" id="id1607"/><a data-type="indexterm" data-startref="xi_trainingsetcostfunctionof41027448_1" id="id1608"/> biased.</p>
</div>

<p>The bad news is that there is no known closed-form equation<a data-type="indexterm" data-primary="closed-form equation/solution" id="id1609"/> to compute the value of <strong>θ</strong> that minimizes this cost function (there is no equivalent of the normal equation). But the good news is that this cost function is convex, so gradient descent (or any other optimization algorithm) is guaranteed to find the global minimum (if the learning rate is not too large and you wait long enough). The partial derivatives of the cost function with regard to the <em>j</em><sup>th</sup> model parameter <em>θ</em><sub><em>j</em></sub> are given by <a data-type="xref" href="#logistic_cost_function_partial_derivatives">Equation 4-19</a>.</p>
<div id="logistic_cost_function_partial_derivatives" data-type="equation"><h5><span class="label">Equation 4-19. </span>Logistic cost function partial derivatives</h5><math display="block">
  <mrow>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac><mi>∂</mi> <mrow><mi>∂</mi><msub><mi>θ</mi> <mi>j</mi> </msub></mrow></mfrac>
    </mstyle>
    <mtext>J</mtext>
    <mrow>
      <mo>(</mo>
      <mi mathvariant="bold">θ</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac><mn>1</mn> <mi>m</mi></mfrac>
    </mstyle>
    <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </munderover>
    <mfenced separators="" open="(" close=")">
      <mi>σ</mi>
      <mrow>
        <mo>(</mo>
        <msup><mi mathvariant="bold">θ</mi> <mo>⊺</mo> </msup>
        <msup><mi mathvariant="bold">x</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msup>
        <mo>)</mo>
      </mrow>
      <mo>-</mo>
      <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msup>
    </mfenced>
    <mspace width="0.166667em"/>
    <msubsup><mi>x</mi> <mi>j</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msubsup>
  </mrow>
</math>
</div>

<p>This equation looks very much like <a data-type="xref" href="#mse_partial_derivatives">Equation 4-6</a>: for each instance it computes the prediction error and multiplies it by the <em>j</em><sup>th</sup> feature value, and then it computes the average over all training instances. Once you have the gradient vector containing all the partial derivatives, you can use it in the batch gradient descent algorithm. That’s it: you now know how to train a logistic regression model. For stochastic GD you would take one instance at a time, and for mini-batch GD you would use a mini-batch at a time.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Decision Boundaries"><div class="sect2" id="id88">
<h2>Decision Boundaries</h2>

<p>We<a data-type="indexterm" data-primary="decision boundaries" id="xi_decisionboundaries410853_1"/><a data-type="indexterm" data-primary="logistic regression" data-secondary="decision boundaries illustration" id="xi_logisticregressiondecisionboundariesillustration410853_1"/> can use the iris dataset<a data-type="indexterm" data-primary="iris data set" id="id1610"/> to illustrate logistic regression. This is a famous dataset that contains the sepal and petal length and width of 150 iris flowers of three different species: <em>Iris setosa</em>, <em>Iris versicolor</em>, and <em>Iris virginica</em> (see <a data-type="xref" href="#iris_dataset_diagram">Figure 4-23</a>).</p>

<figure class="width-90"><div id="iris_dataset_diagram" class="figure">
<img src="assets/hmls_0423.png" alt="Photographs of three iris species: _Iris virginica_, _Iris versicolor_, and _Iris setosa_, demonstrating petal and sepal features." width="1440" height="800"/>
<h6><span class="label">Figure 4-23. </span>Flowers of three iris plant species⁠<sup><a data-type="noteref" id="id1611-marker" href="ch04.html#id1611">14</a></sup></h6>
</div></figure>

<p>Let’s try to build a classifier to detect the <em>Iris virginica</em> type based only on the petal width feature. The first step is to load the data and take a quick peek:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.datasets</code> <code class="kn">import</code> <code class="n">load_iris</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">iris</code> <code class="o">=</code> <code class="n">load_iris</code><code class="p">(</code><code class="n">as_frame</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="nb">list</code><code class="p">(</code><code class="n">iris</code><code class="p">)</code><code class="w"/>
<code class="go">['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names',</code>
<code class="go"> 'filename', 'data_module']</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">iris</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="mi">3</code><code class="p">)</code><code class="w"/>
<code class="go">   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)</code>
<code class="go">0                5.1               3.5                1.4               0.2</code>
<code class="go">1                4.9               3.0                1.4               0.2</code>
<code class="go">2                4.7               3.2                1.3               0.2</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">iris</code><code class="o">.</code><code class="n">target</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="mi">3</code><code class="p">)</code>  <code class="c1"># note that the instances are not shuffled</code><code class="w"/>
<code class="go">0    0</code>
<code class="go">1    0</code>
<code class="go">2    0</code>
<code class="go">Name: target, dtype: int64</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">iris</code><code class="o">.</code><code class="n">target_names</code><code class="w"/>
<code class="go">array(['setosa', 'versicolor', 'virginica'], dtype='&lt;U10')</code></pre>

<p>Next we’ll split the data and train a logistic regression model on the training set:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">LogisticRegression</code>
<code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">train_test_split</code>

<code class="n">X</code> <code class="o">=</code> <code class="n">iris</code><code class="o">.</code><code class="n">data</code><code class="p">[[</code><code class="s2">"petal width (cm)"</code><code class="p">]]</code><code class="o">.</code><code class="n">values</code>
<code class="n">y</code> <code class="o">=</code> <code class="n">iris</code><code class="o">.</code><code class="n">target_names</code><code class="p">[</code><code class="n">iris</code><code class="o">.</code><code class="n">target</code><code class="p">]</code> <code class="o">==</code> <code class="s1">'virginica'</code>
<code class="n">X_train</code><code class="p">,</code> <code class="n">X_test</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> <code class="n">train_test_split</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>

<code class="n">log_reg</code> <code class="o">=</code> <code class="n">LogisticRegression</code><code class="p">(</code><code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">log_reg</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code></pre>

<p>Let’s look at the model’s estimated probabilities for flowers with petal widths varying from 0 cm to 3 cm (<a data-type="xref" href="#logistic_regression_plot">Figure 4-24</a>):⁠<sup><a data-type="noteref" id="id1612-marker" href="ch04.html#id1612">15</a></sup></p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">X_new</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">linspace</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">3</code><code class="p">,</code> <code class="mi">1000</code><code class="p">)</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>  <code class="c1"># reshape to get a column vector</code>
<code class="n">y_proba</code> <code class="o">=</code> <code class="n">log_reg</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">X_new</code><code class="p">)</code>
<code class="n">decision_boundary</code> <code class="o">=</code> <code class="n">X_new</code><code class="p">[</code><code class="n">y_proba</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">]</code> <code class="o">&gt;=</code> <code class="mf">0.5</code><code class="p">][</code><code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">]</code>

<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">X_new</code><code class="p">,</code> <code class="n">y_proba</code><code class="p">[:,</code> <code class="mi">0</code><code class="p">],</code> <code class="s2">"b--"</code><code class="p">,</code> <code class="n">linewidth</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code>
         <code class="n">label</code><code class="o">=</code><code class="s2">"Not Iris virginica proba"</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">X_new</code><code class="p">,</code> <code class="n">y_proba</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">],</code> <code class="s2">"g-"</code><code class="p">,</code> <code class="n">linewidth</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s2">"Iris virginica proba"</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">([</code><code class="n">decision_boundary</code><code class="p">,</code> <code class="n">decision_boundary</code><code class="p">],</code> <code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="s2">"k:"</code><code class="p">,</code> <code class="n">linewidth</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code>
         <code class="n">label</code><code class="o">=</code><code class="s2">"Decision boundary"</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># beautify the figure: add grid, labels, axis, legend, arrows, and samples</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

<figure class="width-90"><div id="logistic_regression_plot" class="figure">
<img src="assets/hmls_0424.png" alt="Graph showing estimated probabilities of a classifier predicting _Iris virginica_ versus not _Iris virginica_ based on petal width, with a decision boundary at 1.6 cm where probabilities are equal." width="2266" height="769"/>
<h6><span class="label">Figure 4-24. </span>Estimated probabilities and decision boundary</h6>
</div></figure>

<p>The petal width of <em>Iris virginica</em> flowers (represented as triangles) ranges from 1.4 cm to 2.5 cm, while the other iris flowers (represented by squares) generally have a smaller petal width, ranging from 0.1 cm to 1.8 cm. Notice that there is a bit of overlap. Above about 2 cm the classifier is highly confident that the flower is an <em>Iris virginica</em> (it outputs a high probability for that class), while below 1 cm it is highly confident that it is not an <em>Iris virginica</em> (high probability for the “Not Iris virginica” class). In between these extremes, the classifier is unsure. However, if you ask it to predict the class (using the <code translate="no">predict()</code> method rather than the <code translate="no">predict_proba()</code> method), it will return whichever class is the most likely. Therefore, there is a <em>decision boundary</em> at around 1.6 cm where both probabilities are equal to 50%: if the petal width is greater than 1.6 cm the classifier will predict that the flower is an <em>Iris virginica</em>, and otherwise it will predict that it is not (even if it is not very confident):</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">decision_boundary</code><code class="w"/>
<code class="go">np.float64(1.6516516516516517)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">log_reg</code><code class="o">.</code><code class="n">predict</code><code class="p">([[</code><code class="mf">1.7</code><code class="p">],</code> <code class="p">[</code><code class="mf">1.5</code><code class="p">]])</code><code class="w"/>
<code class="go">array([ True, False])</code></pre>

<p><a data-type="xref" href="#logistic_regression_contour_plot">Figure 4-25</a> shows the same dataset, but this time displaying two features: petal width and length. Once trained, the logistic regression classifier can, based on these two features, estimate the probability that a new flower is an <em>Iris virginica</em>. The dashed line represents the points where the model estimates a 50% probability: this is the model’s decision boundary. Note that it is a linear boundary.⁠<sup><a data-type="noteref" id="id1613-marker" href="ch04.html#id1613">16</a></sup> Each parallel line represents the points where the model outputs a specific probability, from 15% (bottom left) to 90% (top right). All the flowers beyond the top-right line have over a 90% chance of being <em>Iris virginica</em>, according to the model.</p>

<figure><div id="logistic_regression_contour_plot" class="figure">
<img src="assets/hmls_0425.png" alt="Contour plot of logistic regression showing decision boundary and probability lines for classifying Iris virginica based on petal width and length." width="2872" height="1074"/>
<h6><span class="label">Figure 4-25. </span>Linear decision boundary</h6>
</div></figure>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The hyperparameter controlling the regularization strength of a Scikit-Learn <code translate="no">LogisticRegression</code><a data-type="indexterm" data-primary="LogisticRegression" id="id1614"/><a data-type="indexterm" data-primary="sklearn" data-secondary="linear_model.LogisticRegression" id="id1615"/> model is not <code translate="no">alpha</code> (as in other linear models), but its inverse: <code translate="no">C</code>. The higher the value of <code translate="no">C</code>, the <em>less</em> the model is regularized.</p>
</div>

<p>Just like the other linear models, logistic regression models can be regularized using ℓ<sub>1</sub> or ℓ<sub>2</sub> penalties. Scikit-Learn actually adds an ℓ<sub>2</sub> penalty by default.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Softmax Regression"><div class="sect2" id="id89">
<h2>Softmax Regression</h2>

<p>The<a data-type="indexterm" data-primary="classification" data-secondary="softmax regression" id="xi_classificationsoftmaxregression411724_1"/><a data-type="indexterm" data-primary="logistic regression" data-secondary="softmax regression model" id="xi_logisticregressionsoftmaxregressionmodel411724_1"/><a data-type="indexterm" data-primary="multinomial logistic regression" id="xi_multinomiallogisticregression411724_1"/><a data-type="indexterm" data-primary="regression models" data-secondary="softmax regression" id="xi_regressionmodelssoftmaxregression411724_1"/><a data-type="indexterm" data-primary="softmax regression" id="xi_softmaxregression411724_1"/> logistic regression model can be generalized to support multiple classes directly, without having to train and combine multiple binary classifiers (as discussed in <a data-type="xref" href="ch03.html#classification_chapter">Chapter 3</a>). This is called <em>softmax regression</em>, or <em>multinomial logistic regression</em>.</p>

<p>The idea is simple: when given an instance <strong>x</strong>, the softmax regression model first computes a score <em>s</em><sub><em>k</em></sub>(<strong>x</strong>) for each class <em>k</em>, then estimates the probability of each class by applying the <em>softmax function</em> (also called the <em>normalized exponential</em>)<a data-type="indexterm" data-primary="normalized exponential (softmax function)" id="id1616"/> to the scores. The equation to compute <em>s</em><sub><em>k</em></sub>(<strong>x</strong>) should look familiar, as it is just like the equation for linear regression prediction (see <a data-type="xref" href="#softmax_score_for_class_k">Equation 4-20</a>).</p>
<div class="fifty-percent" id="softmax_score_for_class_k" data-type="equation"><h5><span class="label">Equation 4-20. </span>Softmax score for class k</h5><math display="block">
  <mrow>
    <msub><mi>s</mi> <mi>k</mi> </msub>
    <mrow>
      <mo>(</mo>
      <mi mathvariant="bold">x</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">θ</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msup><mo>)</mo></mrow> <mo>⊺</mo> </msup>
    <mi mathvariant="bold">x</mi>
  </mrow>
</math>
</div>

<p>Note that each class has its own dedicated parameter vector<a data-type="indexterm" data-primary="parameter vector" id="id1617"/> <strong>θ</strong><sup>(<em>k</em>)</sup>. All these vectors are typically stored as rows in a <em>parameter matrix</em> <strong>Θ</strong>.<a data-type="indexterm" data-primary="parameter matrix" id="id1618"/></p>

<p>Once you have computed the score of every class for the instance <strong>x</strong>, you can estimate the probability <math><msub><mover><mi>p</mi><mo>^</mo></mover><mi>k</mi></msub></math> that the instance belongs to class <em>k</em> by running the scores through the softmax function (<a data-type="xref" href="#softmax_function">Equation 4-21</a>).<a data-type="indexterm" data-primary="softmax activation function" id="id1619"/> The function computes the exponential of every score, then normalizes them (dividing by the sum of all the exponentials). The scores are generally called logits or log-odds (although they are actually unnormalized log-odds).</p>
<div id="softmax_function" data-type="equation"><h5><span class="label">Equation 4-21. </span>Softmax function</h5><math display="block">
  <mrow>
    <msub><mover accent="true"><mi>p</mi> <mo>^</mo></mover> <mi>k</mi> </msub>
    <mo>=</mo>
    <mi>σ</mi>
    <msub><mfenced separators="" open="(" close=")"><mi mathvariant="bold">s</mi><mo>(</mo><mi mathvariant="bold">x</mi><mo>)</mo></mfenced> <mi>k</mi> </msub>
    <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac><mrow><mtext>exp</mtext><mfenced separators="" open="(" close=")"><msub><mi>s</mi> <mi>k</mi> </msub><mrow><mo>(</mo><mi mathvariant="bold">x</mi><mo>)</mo></mrow></mfenced></mrow> <mrow><munderover><mo>∑</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow> <mi>K</mi> </munderover><mrow><mtext>exp</mtext><mfenced separators="" open="(" close=")"><msub><mi>s</mi> <mi>j</mi> </msub><mrow><mo>(</mo><mi mathvariant="bold">x</mi><mo>)</mo></mrow></mfenced></mrow></mrow></mfrac>
    </mstyle>
  </mrow>
</math>
</div>

<p>In this equation:</p>

<ul>
<li>
<p><em>K</em> is the number of classes.</p>
</li>
<li>
<p><strong>s</strong>(<strong>x</strong>) is a vector containing the scores of each class for the instance <strong>x</strong>.</p>
</li>
<li>
<p><em>σ</em>(<strong>s</strong>(<strong>x</strong>))<sub><em>k</em></sub> is the estimated probability that the instance <strong>x</strong> belongs to class <em>k</em>, given the scores of each class for that instance.</p>
</li>
</ul>

<p>Just like the logistic regression classifier, by default the softmax regression classifier predicts the class with the highest estimated probability (which is simply the class with the highest score), as shown in <a data-type="xref" href="#softmax_regression_classifier_prediction">Equation 4-22</a>.</p>
<div id="softmax_regression_classifier_prediction" data-type="equation" class="less_space pagebreak-before"><h5><span class="label">Equation 4-22. </span>Softmax regression classifier prediction</h5><math display="block">
  <mrow>
    <mover accent="true"><mi>y</mi> <mo>^</mo></mover>

    <mo>=</mo>

    <munder><mo form="prefix">argmax</mo> <mi>k</mi></munder>
    <mspace width="0.166667em"/>
    <mi>σ</mi>
    <msub><mfenced separators="" open="(" close=")"><mi mathvariant="bold">s</mi><mo>(</mo><mi mathvariant="bold">x</mi><mo>)</mo></mfenced> <mi>k</mi> </msub>

    <mo>=</mo>

    <munder><mo form="prefix">argmax</mo> <mi>k</mi></munder>
    <mspace width="0.166667em"/>
    <msub><mi>s</mi> <mi>k</mi> </msub>
    <mrow>
      <mo>(</mo>
      <mi mathvariant="bold">x</mi>
      <mo>)</mo>
    </mrow>

    <mo>=</mo>

    <munder><mo form="prefix">argmax</mo> <mi>k</mi></munder>
    <mspace width="0.166667em"/>
    <mfenced separators="" open="(" close=")">
      <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">θ</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msup><mo>)</mo></mrow> <mo>⊺</mo> </msup>
      <mi mathvariant="bold">x</mi>
    </mfenced>
  </mrow>
</math>
</div>

<p>The <em>argmax</em> operator<a data-type="indexterm" data-primary="argmax()" id="id1620"/> returns the value of a variable that maximizes a function. In this equation, it returns the value of <em>k</em> that maximizes the estimated probability <em>σ</em>(<strong>s</strong>(<strong>x</strong>))<sub><em>k</em></sub>.</p>
<div data-type="tip"><h6>Tip</h6>
<p>The softmax regression classifier predicts only one class at a time (i.e., it is multiclass, not multioutput), so it should be used only with mutually exclusive classes, such as different species of plants. You cannot use it to recognize multiple people in one picture.<a data-type="indexterm" data-startref="xi_decisionboundaries410853_1" id="id1621"/><a data-type="indexterm" data-startref="xi_logisticregressiondecisionboundariesillustration410853_1" id="id1622"/></p>
</div>

<p>Now that you know how the model estimates probabilities and makes predictions, let’s take a look at training. The objective is to have a model that estimates a high probability for the target class (and consequently a low probability for the other classes). Minimizing the cost function shown in <a data-type="xref" href="#cross_entropy_cost_function">Equation 4-23</a>, called the <em>cross entropy</em>,<a data-type="indexterm" data-primary="cross entropy" id="id1623"/> should lead to this objective because it penalizes the model when it estimates a low probability for a target class. Cross entropy is frequently used to measure how well a set of estimated class probabilities matches the target classes.</p>
<div id="cross_entropy_cost_function" data-type="equation"><h5><span class="label">Equation 4-23. </span>Cross entropy cost function</h5><math display="block"><mrow><mi>J</mi><mo>(</mo><mi mathvariant="bold">Θ</mi><mo>)</mo></mrow><mo>=</mo><mrow><mo>-</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msubsup><mi>y</mi><mi>k</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup><mi>log</mi><mfenced><msubsup><mover accent="true"><mi>p</mi><mo>^</mo></mover><mi>k</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup></mfenced></mrow></math></div>

<p>In this equation, <math><msubsup><mi>y</mi><mi>k</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup></math> is the target probability that the <em>i</em><sup>th</sup> instance belongs to class <em>k</em>. In general, it is either equal to 1 or 0, depending on whether the instance belongs to the class or not.</p>

<p>Notice that when there are just two classes (<em>K</em> = 2), this cost function is equivalent to the logistic regression cost function (log loss; see <a data-type="xref" href="#logistic_regression_cost_function">Equation 4-18</a>).<a data-type="indexterm" data-primary="information theory" id="id1624"/></p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id1625">
<h1>Cross Entropy</h1>
<p>Cross entropy originated from Claude Shannon’s <em>information theory</em>. Suppose you want to efficiently transmit information about the weather every day. If there are eight options (sunny, rainy, etc.), you could encode each option using 3 bits, because 2<sup>3</sup> = 8. However, if you think it will be sunny almost every day, it would be much more efficient to code “sunny” on just one bit (0) and the other seven options on four bits (starting with a 1). Cross entropy measures the average number of bits you actually send per option. If your assumption about the weather is perfect, cross entropy will be equal to the entropy of the weather itself (i.e., its intrinsic unpredictability). But if your assumption is wrong (e.g., if it rains often), cross entropy will be greater by an amount called the <em>Kullback–Leibler (KL) divergence</em>.<a data-type="indexterm" data-primary="KL (Kullback-Leibler) divergence" id="id1626"/><a data-type="indexterm" data-primary="Kullback-Leibler (KL) divergence" id="id1627"/></p>

<p>The cross entropy between two probability distributions <em>p</em> and <em>q</em> is defined as <em>H</em>(<em>p</em>,<em>q</em>) = –Σ<sub><em>x</em></sub> <em>p</em>(<em>x</em>) log <em>q</em>(<em>x</em>) (at least when the distributions are discrete). For more details, check out <a href="https://homl.info/xentropy">my video on the subject</a>.</p>
</div></aside>

<p>The gradient vector of this cost function with regard to <strong>θ</strong><sup>(<em>k</em>)</sup> is given by <a data-type="xref" href="#cross_entropy_gradient_vector_for_class_k">Equation 4-24</a>.</p>
<div id="cross_entropy_gradient_vector_for_class_k" data-type="equation"><h5><span class="label">Equation 4-24. </span>Cross entropy gradient vector for class k</h5><math display="block">
  <mrow>
    <msub><mi>∇</mi> <msup><mi mathvariant="bold">θ</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow> </msup> </msub>
    <mspace width="0.166667em"/>
    <mi>J</mi>
    <mrow>
      <mo>(</mo>
      <mi mathvariant="bold">Θ</mi>
      <mo>)</mo>
    </mrow>
    <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true">
      <mfrac><mn>1</mn> <mi>m</mi></mfrac>
    </mstyle>
    <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </munderover>
    <mrow>
      <mrow><mo fence="true" stretchy="true">(</mo></mrow>
        <msubsup><mover accent="true"><mi>p</mi> <mo>^</mo></mover> <mi>k</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msubsup>
        <mo>-</mo>
        <msubsup><mi>y</mi> <mi>k</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msubsup>
      <mrow><mo fence="true" stretchy="true">)</mo></mrow>
      <msup><mi mathvariant="bold">x</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msup>
    </mrow>
  </mrow>
</math>
</div>

<p>Now you can compute the gradient vector for every class, then use gradient descent (or any other optimization algorithm) to find the parameter matrix <strong>Θ</strong> that minimizes the cost function.</p>

<p>Let’s use softmax regression to classify the iris plants into all three classes. Scikit-Learn’s <code translate="no">LogisticRegression</code><a data-type="indexterm" data-primary="LogisticRegression" id="id1628"/><a data-type="indexterm" data-primary="sklearn" data-secondary="linear_model.LogisticRegression" id="id1629"/> classifier uses softmax regression automatically when you train it on more than two classes (assuming you use <code translate="no">solver="lbfgs"</code>, which is the default). It also applies ℓ<sub>2</sub> regularization by default, which you can control using the hyperparameter <code translate="no">C</code>: decrease <code translate="no">C</code> to increase regularization, as mentioned earlier.</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">X</code> <code class="o">=</code> <code class="n">iris</code><code class="o">.</code><code class="n">data</code><code class="p">[[</code><code class="s2">"petal length (cm)"</code><code class="p">,</code> <code class="s2">"petal width (cm)"</code><code class="p">]]</code><code class="o">.</code><code class="n">values</code>
<code class="n">y</code> <code class="o">=</code> <code class="n">iris</code><code class="p">[</code><code class="s2">"target"</code><code class="p">]</code>
<code class="n">X_train</code><code class="p">,</code> <code class="n">X_test</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> <code class="n">train_test_split</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>

<code class="n">softmax_reg</code> <code class="o">=</code> <code class="n">LogisticRegression</code><code class="p">(</code><code class="n">C</code><code class="o">=</code><code class="mi">30</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">softmax_reg</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code></pre>

<p>So the next time you find an iris with petals that are 5 cm long and 2 cm wide, you can ask your model to tell you what type of iris it is, and it will answer <em>Iris virginica</em> (class 2) with 96% probability (or <em>Iris versicolor</em> with 4% probability):</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">softmax_reg</code><code class="o">.</code><code class="n">predict</code><code class="p">([[</code><code class="mi">5</code><code class="p">,</code> <code class="mi">2</code><code class="p">]])</code><code class="w"/>
<code class="go">array([2])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">softmax_reg</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">([[</code><code class="mi">5</code><code class="p">,</code> <code class="mi">2</code><code class="p">]])</code><code class="o">.</code><code class="n">round</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code><code class="w"/>
<code class="go">array([[0.  , 0.04, 0.96]])</code></pre>

<p><a data-type="xref" href="#softmax_regression_contour_plot">Figure 4-26</a> shows the resulting decision boundaries, represented by the background colors. Notice that the decision boundaries between any two classes are linear. The figure also shows the probabilities for the <em>Iris versicolor</em> class, represented by the curved lines (e.g., the line labeled with 0.30 represents the 30% probability boundary). Notice that the model can predict a class that has an estimated probability below 50%. For example, at the point where all decision boundaries meet<a data-type="indexterm" data-primary="decision boundaries" id="id1630"/>, all classes have an equal estimated probability of 33%.</p>

<figure><div id="softmax_regression_contour_plot" class="figure">
<img src="assets/hmls_0426.png" alt="Diagram showing the decision boundaries of softmax regression on the Iris dataset, with linear boundaries and probability contours for the Iris versicolor class." width="2872" height="1071"/>
<h6><span class="label">Figure 4-26. </span>Softmax regression decision boundaries</h6>
</div></figure>

<p>In this chapter, you learned various ways to train linear models, both for regression and for classification. You used a closed-form equation to solve linear regression, as well as gradient descent, and you learned how various penalties can be added to the cost function during training to regularize the model. Along the way, you also learned how to plot learning curves and analyze them, and how to implement early stopping. Finally, you learned how logistic regression and softmax regression work. We’ve opened up the first machine learning black boxes! In the next chapters we will open many more, starting with support vector machines.<a data-type="indexterm" data-startref="xi_classificationsoftmaxregression411724_1" id="id1631"/><a data-type="indexterm" data-startref="xi_logisticregression49203_1" id="id1632"/><a data-type="indexterm" data-startref="xi_logisticregressionsoftmaxregressionmodel411724_1" id="id1633"/><a data-type="indexterm" data-startref="xi_multinomiallogisticregression411724_1" id="id1634"/><a data-type="indexterm" data-startref="xi_regressionmodelssoftmaxregression411724_1" id="id1635"/><a data-type="indexterm" data-startref="xi_softmaxregression411724_1" id="id1636"/><a data-type="indexterm" data-startref="xi_trainingmodels453_1" id="id1637"/><a data-type="indexterm" data-startref="xi_trainingmodelslogisticregression49203_1" id="id1638"/></p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Exercises"><div class="sect1" id="id728">
<h1>Exercises</h1>
<ol>
<li>
<p>Which linear regression training algorithm can you use if you have a training set with millions of features?</p>
</li>
<li>
<p>Suppose the features in your training set have very different scales. Which algorithms might suffer from this, and how? What can you do about it?</p>
</li>
<li>
<p>Can gradient descent get stuck in a local minimum when training a logistic regression model?</p>
</li>
<li>
<p>Do all gradient descent algorithms lead to the same model, provided you let them run long enough?</p>
</li>
<li>
<p>Suppose you use batch gradient descent and you plot the validation error at every epoch. If you notice that the validation error consistently goes up, what is likely going on? How can you fix this?</p>
</li>
<li>
<p>Is it a good idea to stop mini-batch gradient descent immediately when the validation error goes up?</p>
</li>
<li>
<p>Which gradient descent algorithm (among those we discussed) will reach the vicinity of the optimal solution the fastest? Which will actually converge? How can you make the others converge as well?</p>
</li>
<li>
<p>Suppose you are using polynomial regression. You plot the learning curves and you notice that there is a large gap between the training error and the validation error. What is happening? What are three ways to solve this?</p>
</li>
<li>
<p>Suppose you are using ridge regression and you notice that the training error and the validation error are almost equal and fairly high. Would you say that the model suffers from high bias or high variance? Should you increase the regularization hyperparameter <em>α</em> or reduce it?</p>
</li>
<li>
<p>Why would you want to use:</p>
<ol>
<li>
<p>Ridge regression instead of plain linear regression (i.e., without any 
<span class="keep-together">regularization)?</span></p>
</li>
<li>
<p>Lasso instead of ridge regression?</p>
</li>
<li>
<p>Elastic net instead of lasso regression?</p>
</li>

</ol>
</li>
<li>
<p>Suppose you want to classify pictures as outdoor/indoor and daytime/nighttime. Should you implement two logistic regression classifiers or one softmax regression classifier?</p>
</li>
<li>
<p>Implement batch gradient descent with early stopping for softmax regression without using Scikit-Learn, only NumPy. Use it on a classification task such as the iris dataset.</p>
</li>

</ol>

<p>Solutions to these exercises are available at the end of this chapter’s notebook, at <a href="https://homl.info/colab-p" class="bare"><em class="hyperlink">https://homl.info/colab-p</em></a>.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="id1433"><sup><a href="ch04.html#id1433-marker">1</a></sup> A closed-form equation<a data-type="indexterm" data-primary="closed-form equation/solution" id="id1639"/> is only composed of a finite number of constants, variables, and standard operations: for example, <em>a</em> = sin(<em>b</em> – <em>c</em>). No infinite sums, no limits, no integrals, etc.</p><p data-type="footnote" id="id1475"><sup><a href="ch04.html#id1475-marker">2</a></sup> Technically speaking, its derivative<a data-type="indexterm" data-primary="Lipschitz continuous, derivative as" id="id1640"/> is <em>Lipschitz continuous</em>.</p><p data-type="footnote" id="id1476"><sup><a href="ch04.html#id1476-marker">3</a></sup> Since feature 1 is smaller, it takes a larger change in <em>θ</em><sub>1</sub> to affect the cost function, which is why the bowl is elongated along the <em>θ</em><sub>1</sub> axis.</p><p data-type="footnote" id="id1483"><sup><a href="ch04.html#id1483-marker">4</a></sup> Eta (<em>η</em>) is the seventh letter of the Greek alphabet.</p><p data-type="footnote" id="id1509"><sup><a href="ch04.html#id1509-marker">5</a></sup> While the normal equation can only perform linear regression, the gradient descent algorithms can be used to train many other models, as you’ll see.</p><p data-type="footnote" id="id1524"><sup><a href="ch04.html#id1524-marker">6</a></sup> This notion of bias is not to be confused with the bias term of linear models.</p><p data-type="footnote" id="id1539"><sup><a href="ch04.html#id1539-marker">7</a></sup> Inputs are colinear when one input is equal to a linear combination of some other inputs. For example, the temperature in Celsius degrees is colinear with the temperature in Fahrenheit degrees.</p><p data-type="footnote" id="id1544"><sup><a href="ch04.html#id1544-marker">8</a></sup> It is common to use the notation <em>J</em>(<strong>θ</strong>) for cost functions that don’t have a short name; I’ll often use this notation throughout the rest of this book. The context will make it clear which cost function is being discussed.</p><p data-type="footnote" id="id1545"><sup><a href="ch04.html#id1545-marker">9</a></sup> Norms are discussed in <a data-type="xref" href="ch02.html#project_chapter">Chapter 2</a>.</p><p data-type="footnote" id="id1552"><sup><a href="ch04.html#id1552-marker">10</a></sup> A square matrix full of 0s except for 1s on the main diagonal (top left to bottom right).</p><p data-type="footnote" id="id1553"><sup><a href="ch04.html#id1553-marker">11</a></sup> Alternatively, you can use the <code translate="no">Ridge</code> <a data-type="indexterm" data-primary="Ridge" id="id1641"/><a data-type="indexterm" data-primary="sklearn" data-secondary="linear_model.Ridge" id="id1642"/>class with the <code translate="no">"sag"</code> solver. Stochastic average GD<a data-type="indexterm" data-primary="stochastic gradient descent (SGD)" data-secondary="ridge regularization" id="id1643"/> is a variant of stochastic GD. For more details, see the presentation <a href="https://homl.info/12">“Minimizing Finite Sums with the Stochastic Average Gradient Algorithm”</a> by Mark Schmidt et al. from the University of British Columbia.</p><p data-type="footnote" id="id1564"><sup><a href="ch04.html#id1564-marker">12</a></sup> You can think of a subgradient vector at a nondifferentiable point as an intermediate vector between the gradient vectors around that point.</p><p data-type="footnote" id="id1576"><sup><a href="ch04.html#id1576-marker">13</a></sup> Slide #63 of the <a href="https://homl.info/freelunch">NeurIPS 2015 Deep Learning Tutorial</a>.</p><p data-type="footnote" id="id1611"><sup><a href="ch04.html#id1611-marker">14</a></sup> Photos reproduced from the corresponding Wikipedia pages. <em>Iris virginica</em> photo by Frank Mayfield (<a href="https://oreil.ly/O2fAq">Creative Commons BY-SA 2.0</a>), <em>Iris versicolor</em> photo by D. Gordon E. Robertson (<a href="https://oreil.ly/pMbrK">Creative Commons BY-SA 3.0</a>), <em>Iris setosa</em> photo public domain.</p><p data-type="footnote" id="id1612"><sup><a href="ch04.html#id1612-marker">15</a></sup> NumPy’s <code translate="no">reshape()</code> function allows one dimension to be –1, which means “automatic”: the value is inferred from the length of the array and the remaining dimensions.</p><p data-type="footnote" id="id1613"><sup><a href="ch04.html#id1613-marker">16</a></sup> It is the set of points <strong>x</strong> such that <em>θ</em><sub>0</sub> + <em>θ</em><sub>1</sub><em>x</em><sub>1</sub> +  <em>θ</em><sub>2</sub><em>x</em><sub>2</sub> = 0, which defines a straight line.</p></div></div></section></div></div></body></html>