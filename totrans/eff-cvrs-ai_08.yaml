- en: 7 Augmenting intent data with generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creating new training and testing examples with generative AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying gaps in your current conversational AI data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use LLMs to build new intents in your conversational AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conversational AI users are frustrated when the AI does not understand them—especially
    if it happens multiple times! This applies to all conversational AI types, including
    question-answering bots, process-oriented bots, and routing agents. We’ve seen
    multiple strategies for improving the AI’s ability to understand. The first strategy—improving
    intent training manually (chapter 5)—gives full control to the human builder,
    but it takes time and specialized skill. The second strategy—retrieval-augmented
    generation (RAG, chapter 6)—gives much more control to generative AI, reducing
    the role of the human builder over time. This chapter introduces a hybrid approach
    where generative AI augments the builder. This applies to rules-based or generative
    AI–based systems.
  prefs: []
  type: TYPE_NORMAL
- en: Using generative AI as a “muse” for the human builder reduces the effort and
    time required of the human builder, increases the amount of test data available
    for data science activities, and gives the human builder the final say, which
    eliminates most opportunities for hallucinations (which is when AI says something
    that looks reasonable but is not true).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you are building a conversational AI solution to help your IT help
    desk. From interviews, you know that password resets are the most frequent task
    the AI needs to support. Therefore, the AI needs a strong understanding of the
    password reset intent.
  prefs: []
  type: TYPE_NORMAL
- en: Because the conversational AI solution is new, you don’t have any production
    user utterances to train from. When you ask the service desk how users generally
    start their conversations, you hear “Well, they usually say something about ‘forgot
    password’ or ‘cannot login.’” You are appropriately suspicious—surely the users
    have a broader vocabulary than that—but you have a hard time imagining what that
    vocabulary might be. Generative AI can help you imagine.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at how the human builder and generative AI can be partners.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Getting started
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Large language models (LLMs) are skilled at performing many technical tasks,
    including classification and question answering. These are the same tasks at the
    core of conversational AI. So why don’t we just use generative AI for our core
    conversational AI tasks?
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are generalizable because they have been trained on huge amounts of data.
    This makes them a quick study on many tasks, but it also comes with some cost.
    What are the costs to using LLM as the classifier in conversational AI?
  prefs: []
  type: TYPE_NORMAL
- en: '*Monetary*—LLMs can be expensive to run.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Speed*—Because LLMs consider billions of parameters, they can be slower (a
    time cost).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Reputation risk*—LLMs are so generalized that they may hallucinate output
    that makes your bot look bad or exposes you to legal risk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Lack of transparency and explainability*—LLMs are often a “black box.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By contrast, conversational AI uses purpose-built technology. Because its classifier
    is trained only to do the task at hand, it is much cheaper, and it runs quickly
    because it considers fewer parameters. While that may reduce the accuracy, the
    system is guaranteed to use a set of controlled responses. These comparisons are
    summarized in table 7.1.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.1 Comparing and contrasting traditional natural language processing
    (NLP) in conversational AI and generative AI on the classification task
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Feature | Traditional NLP | Generative AI |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Model  | Purpose-built for excellence at only one task: classification  |
    Generalized model good at many tasks  |'
  prefs: []
  type: TYPE_TB
- en: '| Runtime speed  | Fast  | Slow  |'
  prefs: []
  type: TYPE_TB
- en: '| Runtime cost  | Low  | High  |'
  prefs: []
  type: TYPE_TB
- en: '| Accuracy  | Mostly accurate (trained by you on small data)  | Mostly accurate
    (pretrained on huge data)  |'
  prefs: []
  type: TYPE_TB
- en: '| Scalability  | Manageable for up to 100 intents; very difficult afterward  |
    Generalizes very well via RAG pattern  |'
  prefs: []
  type: TYPE_TB
- en: '| Controllability  | Strictly controlled by humans; requires extensive testing  |
    Prone to hallucinate when given full control; hallucinations are hard to detect
    automatically  |'
  prefs: []
  type: TYPE_TB
- en: We can use a hybrid approach to get the best of both methods.
  prefs: []
  type: TYPE_NORMAL
- en: '7.1.1 Why do it: Pros and cons'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An LLM can greatly reduce the time and effort spent by a human builder. LLMs
    and humans work best together—as partners. Training a conversational AI classifier
    requires human effort, but it also requires data, and that data can be hard to
    collect. Sometimes that data cannot be collected until the conversational AI is
    deployed in production. Even in our familiar example of detecting “forgot password”
    problems, we still don’t know all the ways users might state their problem. They
    may use the “wrong” words!
  prefs: []
  type: TYPE_NORMAL
- en: 'LLMs are especially helpful in these scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Bootstrapping*—AI suffers from a “cold start” problem. How can you train when
    you have no data? LLMs can generate an initial set of training data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Expanding*—Use LLMs to fill the gaps in your existing data when you don’t
    have enough data to optimize your classifier’s accuracy. This is especially useful
    for understanding rare but important intents (such as users reporting fraud).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Robust testing*—LLMs can generate additional data for testing, increasing
    your confidence in the robustness of the conversational AI. (This is helpful even
    if generative AI creates the answers, as in RAG.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An LLM can help you run many experiments, some of which will generate output
    that is directly usable by your application, either as training or testing data.
    You and the LLM can help each other too. For instance, the LLM can give you themes
    and variations that your users may use. You can select your favorites and ask
    the LLM to expand on those by updating the prompt instructions or few-shot examples.
  prefs: []
  type: TYPE_NORMAL
- en: Your interactions with the LLM will be iterative and collaborative. For instance,
    you are unlikely to design the right prompt the first time. The LLM may not understand
    the task correctly or may give you content that’s not quite helpful. Expect to
    do a few rounds of experimentation before you get great results. After that, you
    can quickly generate suggestions across all your intents and improve your AI’s
    understanding of your users.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.2 What you need
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Many LLMs can help us with our task of generating more training or testing data
    for our “forgot password” intent. So do we just pick one and turn it loose? Not
    quite. The LLM will help you, but you should not expect it to do all the work.
    Instead, you should have an idea of where you need to start, such as knowing what
    gaps you have in your solution. You also need to select an LLM that is appropriate
    for your use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'Access to an LLM is an obvious prerequisite for using an LLM to augment your
    conversational AI. There are several non-obvious considerations when selecting
    that LLM:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Terms and conditions*—Several LLMs explicitly forbid you from using their
    LLM to “build or improve another model.” This clause is intended to keep you from
    building a competitive LLM, but using an LLM to improve conversational AI could
    be construed in this way, and your appetite for legal risk may vary. (Consult
    with your legal department—they may have already selected LLMs for your company
    to use.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data privacy*—As you use the LLM, will it be allowed to keep your data and
    train on it in the future? The data in your conversational AI may be confidential
    to your corporation. If it is, you can’t just share it with any LLM.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Capability*—Not every LLM is capable of creative generation tasks. Make sure
    you select a model that can follow instructions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Open source or proprietary*—For many use cases, explainability is important.
    Open source models generally give you more insight into the model’s training process,
    such as the training data and source code for the model. Proprietary models generally
    do not expose that information but usually have more ease-of-use. This may also
    affect your ethical and regulatory compliance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Latency and response times*—There are speed and accuracy tradeoffs; a larger
    model may be both more accurate and slower to run.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter and the rest of the book, we will use multiple prompts and models
    to provide examples. These examples will be adaptable to your model (or models)
    of choice. Feel free to experiment with other models, especially those that weren’t
    available as we wrote this book.
  prefs: []
  type: TYPE_NORMAL
- en: You will also need to bring some domain knowledge to the LLM. This can include
    background on the problems your users are bringing to your conversational AI,
    the intents your system needs to support, and utterances belonging to those intents.
    Bring as much real-world data as you can. Then use the LLM to augment that data.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.3 How to use the augmented data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An LLM can help you generate additional data for use by your chatbot. Using
    an LLM at build time reduces the risk and effect of hallucinations. These options
    include adding to your training data, adding to your testing data, and modifying
    your existing data (for example, changing grammatical structure and synonyms).
  prefs: []
  type: TYPE_NORMAL
- en: The best source is data is from real users of a production system. We recognize
    that this introduces a chicken-and-egg problem—you may not have any data if you
    are not in production yet. Your intent classifier needs to be trained on varied
    data so that it can understand varied data. The chatbot should be tested on data
    that it was not trained on.
  prefs: []
  type: TYPE_NORMAL
- en: When you don’t have any training data, you’ll tend to generate low-variance
    utterances. You’ll have a couple of key words in mind, and you’ll “anchor” yourself
    to them. Even with dozens of examples, low-variance utterances don’t convey much
    information. High-variation utterances cover a lot of ground quickly, as shown
    in table 7.2, and they generally make your classifier stronger.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.2 Comparing low-variation to high-variation utterances. High-variation
    utterances increase the robustness of classifiers.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Low-variation utterance set | High-variation utterance set |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| • I forgot my password • Forgot my password'
  prefs: []
  type: TYPE_NORMAL
- en: • Forgot password
  prefs: []
  type: TYPE_NORMAL
- en: • Help I forgot my password
  prefs: []
  type: TYPE_NORMAL
- en: '| • I can’t log in • Account locked out'
  prefs: []
  type: TYPE_NORMAL
- en: • Forgot password
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: The high-variation utterances easily cover the low-variation utterances despite
    being fewer in number. The single utterance “forgot password” is enough to predict
    the intent of all four low-variance utterances. The reverse is not true and wouldn’t
    be true even if we added dozens more slight variations on “forgot password” to
    the low-variance set. “I can’t log in” has no direct word overlap—the low-variance
    set doesn’t cover it.
  prefs: []
  type: TYPE_NORMAL
- en: We prefer a small, high-variance training data set that covers a large volume
    of low-variance test utterances. Better to train on 10 strong variations than
    100 weak variations. This makes the chatbot robust to the diverse utterances it
    will see in production. It also reduces your chances of accidentally unbalancing
    the training set (which leads to weak understanding).
  prefs: []
  type: TYPE_NORMAL
- en: We can visualize the information conveyed by the utterances in figure 7.1\.
    The first plot shows the low-variation utterances from table 7.2\. Since they
    only convey two words, you can think that the utterances are tightly clustered
    together. The second plot shows the high-variation utterances. With no word overlap,
    the utterances are spread all over the grid, but there is a lot of empty space.
    The third plot shows an ideal test set where there is broad coverage of the grid.
    The fourth plot shows an ideal training set, which covers maximum variation in
    a small number of examples. The test data set can be much larger than the training
    set. We want the test set to have variation, but it’s fine if we have near-duplicates.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll first demonstrate how to use generative AI to create
    high-variance utterances. Then we’ll expand on those utterances via many slight
    variations. By the end of the chapter, you’ll see how to generate utterances matching
    the third and fourth plots.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F01_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 Visualizing coverage from different kinds of utterance sets. Our
    ideal training data is set 4, which covers a large variation in a small number
    of utterances. Set 3 is the ideal testing data.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Imagine you are building a chatbot for a typical retail store. Create ten utterances
    for a `#store_location` intent, for when users ask questions like “Where is your
    store located?” Keep track of how much time this takes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create ten more utterances, without using the words “where,” “store,” “located,”
    or “location.” (Time yourself again.) Do these utterances have more variety?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat the previous two exercises for a `#store_hours` intent. First use whatever
    words you want, and then restrict yourself from using “when,” “time,” and “hours.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 7.2 Hardening your existing intents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll start our exercise knowing which intent we need to improve: the “forgot
    password” intent. We need enough training data so that the conversational AI can
    detect this intent. Remember that our support staff didn’t know all the ways users
    might state this problem. They said, “Users usually say something about ‘forgot
    password’ or ‘cannot login.’” That won’t be enough to train the chatbot on a robust
    “forgot password” intent.'
  prefs: []
  type: TYPE_NORMAL
- en: We will use the LLM as our partner. First, the LLM will help us generate contextual
    synonyms so that we see a broad range of vocabulary. Next, the LLM will generate
    full utterances using this vocabulary. Then we will have the LLM generate different
    grammatical variations, such as questions versus statements and past tense versus
    present tense. We’ll also have the LLM transfer lessons learned from building
    one intent (“forgot password”) into building the next intent (“find a store”).
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start with the simplest step—finding synonyms.
  prefs: []
  type: TYPE_NORMAL
- en: Can I use a different LLM?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Yes! We will use multiple models in this book. The field of generative AI is
    moving quickly, and models used during the writing of this book may be supplanted
    by better models by the time this book is published or by the time you read it.
    The principles we’ll demonstrate are more important than the specific models we’ll
    use.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.1 Get creative with synonyms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first step is designing a prompt. A good prompt ensures your LLM understands
    its task, and the first task in this example is generating a broad range of synonyms.
    The process of prompt engineering requires an iterative process of experimentation.
  prefs: []
  type: TYPE_NORMAL
- en: Our subject matter experts advised that the utterances often include “forgot
    password.” One way of increasing your chatbot’s robustness is to make sure you
    have coverage on noun and verb phrases. Let’s ask an LLM to generate some likely
    synonyms for the noun phrases.
  prefs: []
  type: TYPE_NORMAL
- en: How do I set up and run my LLM?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: There are multiple options for setting up an LLM environment. You can run LLMs
    locally on your machine, using a tool like Ollama, or run them on a commercially
    hosted platform. We used the Prompt Lab available in IBM’s watsonx.ai platform
    due to our familiarity with it, but nothing in this chapter is platform dependent.
    Use your favorite platform.
  prefs: []
  type: TYPE_NORMAL
- en: For this exercise, we will use the falcon-40b-8lang-instruct model ([https://huggingface.co/tiiuae/falcon-40b](https://huggingface.co/tiiuae/falcon-40b))
    with greedy decoding. Greedy decoding instructs the model to generate the next
    most probable word at each step and yields the same output every time.
  prefs: []
  type: TYPE_NORMAL
- en: Though we want to end up with full sentence fragments, we got better results
    by breaking the task down into pieces. User utterances are typically sentences
    or fragments, primarily built from nouns and verb phrases. Let’s start with a
    simple prompt—just asking for synonyms—to get our nouns.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.1 Generating noun synonyms without context
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Simple instruction'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Prompted cue for the LLM'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding listing, we used the LLM as a generic thesaurus. While the
    output nouns are synonyms for “password,” they are not synonyms that are often
    used in the context of logging in. We need to provide more context to the LLM
    to get better results.
  prefs: []
  type: TYPE_NORMAL
- en: This time let’s tell the LLM why we are asking for synonyms and what kind of
    synonyms we are looking for. The following listing shows the improved prompt and
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.2 Generating noun synonyms with context
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Background information given to the LLM'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Detailed instructions grounding the task to forgetting passwords'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Cue for LLM'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 LLM response'
  prefs: []
  type: TYPE_NORMAL
- en: These synonyms sound much more familiar. Next, let’s create contextual verb
    synonyms.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.3 Generating verb synonyms with context
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Updated instruction for verbs instead of nouns'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Updated cue for verbs instead of nouns'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: Not bad, though the last verb is a little weird in this context. Another limitation
    is that all the generated verbs are in the past tense. This is appropriate given
    that our example was also in the past tense, but we want our LLM to generate more
    variety for us. Let’s try expanding from *verbs* to *verb phrases*.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.4 Generating verb phrase synonyms with context
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Updated instruction and cue for “verb phrases”'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: The LLM gave us full sentences (oops!), but now we are getting some present
    tense utterances (“cannot remember”) along with the other past tense utterances.
    We are making progress! With only a few minutes of prompting, we got the LLM to
    give us a lot of variation to think about. Before, we might have assumed our chatbot
    would just have to look for “forgot” and “password.” Now we have a dozen other
    useful words to consider when we test the bot.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s experiment a little more. This time we’ll increase the creativity of the
    model by moving to *sampling decoding* and increasing the temperature. We’ll also
    revise the prompt by asking for “10 synonyms” instead of “5 nouns.” Listing 7.5
    shows the nouns, and listing 7.6 shows the verb phrases.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  With greedy decoding, the LLM generates the same results every time. Sampling
    decoding generates non-deterministic output. If you try these prompts, you’ll
    probably get different results. This is okay! We are only using the LLM to spark
    our creativity.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.5 Generating noun synonyms with increased creativity settings
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Updated prompt and cue'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: Awesome! This is a great list of nouns. Your system may not use all of them,
    but this is a thorough list for testing.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try verbs next.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.6 Generating verb phrase synonyms with increased creativity settings
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Updated instruction and cue'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a much more creative list of synonyms. While there are some oddities
    in this list (“unknown,” “not applicable”) there are some nice creative sparks:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Slightly wrong verb*—“Did not remember” is odd, but it makes you think of
    “Cannot remember.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Wrong tense*—“Didn’t know” makes you consider “Do not know.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sentiment*—“OMG” reminds you that utterances may include frustration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ve generated synonyms relevant to our domain with only a few minutes of effort,
    but we still only have piece-parts. We started with the utterance “I forgot my
    password” and can now plug in new nouns and verb phrases, but we are still stuck
    with a simple subject-verb-object structure. Our users will surely use more varied
    grammar. We don’t want the chatbot to depend on only one grammatical form. We
    want it to be resilient to more varied utterances. Let’s use LLMs to generate
    more grammatical variations.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.2 Generate new grammatical variations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Instead of asking the LLM to generate words or word pairs, let’s try having
    it generate entire utterances. We need to design a prompt that introduces word
    variation, but we don’t want to bias the model too hard toward “I forgot my password.”
    We will use a similar prompt that sets a context, but rather than directly including
    the phrase “I forgot my password,” we will describe the user’s problem instead
    (they can’t log in).
  prefs: []
  type: TYPE_NORMAL
- en: Our first attempt is shown in the following listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.7 Generating entire utterances
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Updated instruction and cue'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are starting to get more variety. This list of utterances has several ideas
    we haven’t seen yet (like “password reset email”). Even better, we are getting
    more variety in the sentence structure. The output list has the following grammatical
    varieties:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Subject verb object statement (active voice)*—I forgot my password.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Passive voice statement*—My account is locked.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Prepositional*—I need help with my account.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Question*—Can you help me log in?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Qualifiers*—I tried resetting my password but it didn’t work.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The variety in our sample utterances is improving. The generated utterances
    are usable for our training or test sets, but there are still gaps. For instance,
    all these utterances are perfect sentences. What about our users who are so busy
    (or frustrated) that they only give us a few words? Can the LLM generate useful
    sentence fragments? The following listing explores this idea.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.8 Generating sentence fragment utterances
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Updated instruction to generate fragments. Cue is unchanged.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 One-shot example below the cue'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: In our previous prompts, we were not able to generate sentence fragments. This
    time, we gave the LLM extra help. Aside from our usual updates to the prompt (replacing
    “utterances” with “fragments”), we gave the LLM one additional hint. We provided
    the first example fragment “Forgot password.” This is called one-shot learning
    because we gave the LLM one example of what we wanted, and that helped the LLM
    learn how to process our request.
  prefs: []
  type: TYPE_NORMAL
- en: Zero-shot? One-shot? Few-shot?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The “zero-shot,” “one-shot,” and “few-shot” terms refer to the number of examples
    (shots) given in the prompt. A zero-shot prompt does not give any examples. A
    one-shot prompt gives one example, and a few-shot prompt gives a few examples.
  prefs: []
  type: TYPE_NORMAL
- en: For training data generation, one-shot learning is a great way to get exactly
    the kind of output you want. Whenever you are having trouble getting an LLM to
    follow your instructions, consider giving a good example rather than just tweaking
    the instructions. While writing this chapter, we tried several more prompts than
    are included in this book, and none of them gave us sentence fragments until we
    used one-shot learning.
  prefs: []
  type: TYPE_NORMAL
- en: Further, you can use one-shot learning to take the lessons learned while building
    one intent and apply them to another intent. In the next listing, we use examples
    from a “store location” intent to generate examples for a “password reset” intent.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.9 Using one-shot learning for multiple grammatical structures
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Standard background for LLM, unchanged from the past several examples'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 One-shot example includes instruction and desired output'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Instruction to the LLM, supplemented by the cue “Direct Question:”'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 LLM output (starts after the cue “Direct Question:”)'
  prefs: []
  type: TYPE_NORMAL
- en: With a single prompt, we were able to get examples of each of the grammatical
    structures we wanted (the LLM made a mistake on “direct question,” but the output
    is still useful).
  prefs: []
  type: TYPE_NORMAL
- en: Here’s one more trick for generating utterances. Rather than using detailed
    instructions, provide a few examples, and ask the LLM to generate more. We’ll
    use a different prompt format and a different model—granite-13b-instruct-v2 ([https://mng.bz/DMlR](https://mng.bz/DMlR))—and
    we’ll use sampling decoding for increased creativity and non-deterministic results.
    The following listing shows the prompt and first output.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.10 Using a creative prompt to generate examples with a Granite model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '#1 A marker indicating our instruction to the model'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The actual instruction'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Beginning of examples'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Output cue'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: 'Because we are using non-deterministic settings, the model output is different
    every time. Here are the outputs from the next five executions of the same prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: “Can you help me recover my password”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “I’m locked out of my account”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Can’t remember username or password”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Hoping you can help me, I just reset my password but it’s not working”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “I’ve failed logging in 5 times in a row”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We didn’t specify exactly what variation we wanted, but we still got some interesting
    variations. We saw new verbs (“recover”) and concepts (“5 times in a row”). This
    highlights the value of experimenting with different LLMs, different prompts,
    and different parameter settings. Generating training data requires creativity.
    Don’t rely on one or two experiments to do the work—you and generative AI can
    work together to be creative.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.3 Build strong intents from LLM output
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s recap our experiments so far. We’ve generated nouns and verbs as in-context
    synonyms (not just generic synonyms). We’ve generated entire utterances with a
    similar structure, then used LLMs to generate utterances with varied grammatical
    structures. We’ve used multiple models, prompts, and parameter settings. Generative
    AI has been a great partner!
  prefs: []
  type: TYPE_NORMAL
- en: From these experiments, we have a lot of possibilities for building a training
    set. Let’s select 10 utterances covering the variations we generated earlier.
    For some of the utterances, we’ll use the verbatim output from the LLMs. For other
    utterances, we’ll substitute some variations. For instance, the generated utterances
    were heavy on “password”—we can substitute “login information” or “account information.”
    The utterances were also heavy on “forgot,” so we’ll substitute “can’t remember.”
    The following listing shows one possible selection of utterances.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.11 Ten hand-selected utterances based on LLM suggestions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We’ve come a long way since the initial suggestion that “most requests include
    the words ‘forgot’ and ‘password’”! If we use these utterances in our training
    set, we will have much more robust chatbot understanding than if we had stuck
    to our keyword-based advice.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve been successful generating ideas across multiple prompting sessions.
    This begs the question, can we do everything in one prompt? We would expect to
    need all our tricks to date: a context for the LLM, a clear instruction, and a
    one-shot example. Let’s try to train a “store locator” intent using our best examples
    from the “forgot password” intent. The following listing demonstrates this using
    the falcon-40b-8lang-instruct model with greedy decoding again.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.12 Using one-shot learning to copy lessons from one intent to another
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Standard background for LLM'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Instruction and cue for one-shot example (password reset)'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 One-shot example'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Instruction and cue for target (store locator)'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: 'Not bad! This is a reasonable start for our new intent. There are several positive
    aspects to this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Verb variety*—No verb is repeated, aside from “is.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Concept variety*—The examples cover both absolute and relative concepts via
    “location” and “direction.” They also cover time and space (“how long,” “how far”).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Granularity variety*—Utterances range from “what city” to “what street” as
    well as “from here.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'However, the utterances also have some limitations:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Grammatical structure*—The utterances are all questions. There are no commands
    or fragments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Noun variety*—Every example uses “store.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Obvious omissions*—I’m lost without my GPS. It’s surprising the utterances
    didn’t explicitly include something like “What’s your address” or “driving directions.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The task is too hard to complete in a single prompt. We asked the LLM for everything
    we wanted and even gave examples. The LLM was able to complete many of our requests
    but also ignored or failed to fulfill several of our requests. Things aren’t as
    simple as perfecting one intent and then asking the LLM replicate that to all
    the other intents. There are just too many instructions and variables in our task
    for current LLMs to get everything right in one try. That may well change in the
    future.
  prefs: []
  type: TYPE_NORMAL
- en: This is why we suggest using an LLM as a partner rather than doing everything
    by yourself or doing everything with an LLM. You cannot offload your thinking
    onto the LLM, but you *can* have an LLM run experiments for you very quickly.
    Generating synonyms and grammar variety sounds easy, but you probably couldn’t
    do it as quickly and completely as an LLM. Have the LLM generate lots of ideas
    and then pick the best ones.
  prefs: []
  type: TYPE_NORMAL
- en: REMEMBER  The LLM can’t think for you, but it can give you a very good “first
    draft.”
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.3 summarizes dos and don’ts for using LLMs to generate training and
    test data.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.3 Dos and don’ts for using LLMs to generate training and testing data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Do | Don’t |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| • Use the LLM as a partner or creative assistant. You still drive the process.
    • Set contextual guidance and focused instructions'
  prefs: []
  type: TYPE_NORMAL
- en: • Use examples and one-shot learning to nudge the LLM
  prefs: []
  type: TYPE_NORMAL
- en: • Experiment with multiple prompts
  prefs: []
  type: TYPE_NORMAL
- en: • Use LLM output to augment data collected from users
  prefs: []
  type: TYPE_NORMAL
- en: '| • Accept LLM output without reviewing or refining it • Expect the LLM to
    know what you want'
  prefs: []
  type: TYPE_NORMAL
- en: • Perform too many tasks in a single prompt
  prefs: []
  type: TYPE_NORMAL
- en: • Feed confidential data into a proprietary LLM platform that keeps your data
    “for future training purposes”
  prefs: []
  type: TYPE_NORMAL
- en: • Assume that LLM output is fully representative of user data
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are great for generating utterance training data when you have a clear
    problem but no representative user utterances. While we always prefer to use actual
    user utterances from a production system, we don’t always have that luxury. LLM-generated
    data helps us fill in the gaps. Their vast training sets likely include some data
    from your domain (such as customer service), but it may not include all your needs.
    They’ve seen lots of “password reset” utterances but probably none that include
    the name of your application. Given a choice between no training data, fabricated
    training data from subject matter experts, and LLM-generated training data, the
    LLM-generated option is the best bet.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.4 Creating even more examples with templates
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous section, we generated a varied list of utterances by combining
    multiple different outputs from the LLM and using them to generate new utterances.
    Figure 7.2 shows an example of mutating full utterances (from listing 7.7) with
    synonyms seen in listings 7.1 to 7.6.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F02_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 Generating additional examples from the initial LLM output. The LLM
    generated “My password isn’t working,” but we now know a related utterance is
    “My login information isn’t working.”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: TIP  Creating examples from templates is a programmatic task, not specifically
    a generative AI task. Mixing and matching multiple styles can generate the best
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Using templates is especially helpful when some of the LLM outputs only contain
    one verb or noun. We were able to introduce variety into our utterance collection
    with manual changes, but we can take this to the extreme by considering the LLM
    outputs as templates. Starting with the basic utterance “I forgot my password,”
    we then explored contextual synonyms for “forgot” and “password.” Figure 7.3 converts
    this utterance into a template of “I <verb phrase> my <noun phrase>,” which can
    generate more utterances.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F03_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 Converting “I forgot my password” into a template that lets us replace
    verbs and nouns in context. One option from this template is “I lost my credentials.”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This template generates 36 total utterances due to having six verb choices and
    six noun choices (6 × 6 = 36). This is a lot of data, but it is quite unbalanced—it
    all uses the exact same grammatical structure. Worse, some of the utterances may
    not ever be uttered by users. This approach is not suitable for generating training
    data, since it overweighs the bot toward a single pattern. These templated utterances
    will hide the influence of other more varied utterances like “Can you help me
    log in?” “I tried to reset my password, but it didn’t work,” and “account locked
    out.”
  prefs: []
  type: TYPE_NORMAL
- en: The templated utterances are useful for your testing set if you recognize the
    imbalance. There is nothing wrong with testing your conversational AI on all 36
    utterances as a sanity test. Just don’t limit yourself to testing one template
    and assuming the intent is well-trained.
  prefs: []
  type: TYPE_NORMAL
- en: A templated approach can be useful for generating testing data that helps ensure
    the chatbot can tell two intents apart in the face of extraneous information.
    In addition to our “forgot password” template, let’s assume we have a “store location”
    template that uses the verbs “need,” “forgot,” and “want” and the nouns “address,”
    “location,” and “driving directions.” The store location template is like figure
    7.3, but it uses “I <verb phrase> your <noun phrase>.” We’ll also assume that
    some users will greet the bot (“Hi,” “hello,” “good day”) or generically ask for
    help (“can you help,” “please assist”). These generic additions do not add any
    differentiating information to the user utterance. Will they somehow affect the
    chatbot? Figure 7.4 shows how we can set up a test.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F04_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 Using common templates to see whether greetings and closures affect
    the chatbot’s understanding. One possible utterance is “Hello I lost my credentials
    please assist.”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: There are three verb variations and three noun variations in each intent, giving
    nine (3 × 3 = 9) possibilities for each intent. Without considering greetings,
    we could have run 18 tests (9 per intent). In this test, we have added three greeting
    variations and two closure variations, allowing us to increase the test size six-fold.
    The 108 (18 × 6 = 108) utterances will include “Hi! I forgot my password. Can
    you help?” and “Good day. I need your address. Please assist.” and 106 more variations.
    These can all be included in a test set.
  prefs: []
  type: TYPE_NORMAL
- en: In theory, there is no difference between theory and practice—in practice there
    is.Yogi Berra
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We do not expect adding the greetings and closure variations to affect the classification,
    but we can verify this. If your training data is severely unbalanced, the chatbot
    may be affected by these extra words. Therefore, running this kind of test can
    be valuable as another sanity test, in addition to the methods shown in chapter
    5.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Use generative AI to create examples for a “store location” intent. How many
    nouns, verbs, and grammatical structures can you generate? Track the amount of
    time you spend on this exercise:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use a prompt with instructions only. This is a zero-shot prompt.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a prompt that includes examples. This is a one-shot or few-shot prompt.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Did the model generate more varied utterances in less time than when you created
    utterances manually?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Repeat the previous exercise for an intent that is not well understood in a
    chatbot you are building (or using). If possible, augment the bot’s training or
    test data sets with some of these new utterances, and measure the change in accuracy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 7.3 Getting more creative
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Chapter 5 demonstrated rock-solid data science principles for evaluating and
    improving your training and testing data. Those principles give you metrics that
    demonstrate your chatbot’s ability to understand and quantify the effect of the
    improvements you are trying to make. Those robust principles take time to implement.
    This section will show you a few creative ways to use an LLM before diving deeper
    into statistical approaches. These LLM-based techniques do not replace the statistical
    approaches, but they can give you a quick intuition.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.1 Brainstorm additional intents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The LLM can help you brainstorm new intents your system might need to handle.
    While we prefer to work from real-world data, such as a backlog of support tickets,
    a little brainstorming doesn’t hurt. If you are starting a brand-new support process,
    you may not have any data to work with and need a kickstart. The following listing
    demonstrates an intent brainstorming process.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.13 Brainstorming new intents
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Standard background for LLM—still unchanged'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Instruction and cue'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: This looks like a great start. We have product search, price dispute, order
    tracking, login problems, and returns. These all seem worthy of expanding into
    intents and process flows in your conversational AI.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.2 Check for confusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can also see if the LLM agrees with the intents we have created. We can take
    the training utterances we have selected and ask the LLM to sort them into intents.
    Let’s see what happens if we remove the intent name from our “forgot password”
    intent.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.14 Does the LLM predict the same intent (“forgot password”) as we
    did?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Instruction for LLM'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Input belonging to the instruction'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Cue'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 LLM output'
  prefs: []
  type: TYPE_NORMAL
- en: The LLM suggested two intents where we had only used one. The intents “login”
    and “password reset” are in line with our original “forgot password” label. The
    LLM-derived intents feel too narrow, especially since both intents are likely
    to have the same answer.
  prefs: []
  type: TYPE_NORMAL
- en: LLM output format is not always consistent
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In listing 7.14, the LLM “invented” an output schema with hyphenated list entry
    and arrows from utterance to intent. Since we are just reviewing the results visually,
    this is okay, but additional instructions to the LLM might help (e.g., “respond
    in a bulleted list”). We could also demonstrate our desired format with a one-shot
    example.
  prefs: []
  type: TYPE_NORMAL
- en: This test is not as robust as the other techniques shown in chapter 5, but it
    can be used as a quick sanity test on your training data. If the LLM does not
    find any cohesion in your training data, you might have a problem.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs and human builders work well together. Figure 7.5 summarizes the many ways
    LLMs can help you change your conversational AI to improve its ability to understand
    your users.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F05_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 An LLM augments the human builder in many ways.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Take a chatbot that you are building or using. Describe its purpose. Use that
    description and a creative LLM prompt to generate example problems that the bot
    would solve. Use sampling decoding, and run the prompt multiple times to get multiple
    ideas. Do these line up with the intents or process flows the bot handles?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Take a chatbot you are building. Extract a subset of utterances from the test
    data. Ask an LLM to predict the intent or process flow they belong to. Does the
    LLM prediction align with how your bot is implemented?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs are great partners that augment human builders. Humans and LLMs are better
    together.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experiment with different models, prompts, and parameters to get the best output
    from LLMs. Keep iterating! Don’t expect your first attempt to be perfect.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t just give instructions to an LLM. Provide examples through one-shot or
    few-shot prompts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you identify a gap in your data, you can ask an LLM to help you fill it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLM output can be used directly in your training data, or you can manually refine
    it first.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use greedy decoding to get the same output every time. Use sampling decoding
    to get randomized responses with additional creativity. Execute the same prompt
    multiple times with sampling decoding to get a variety of responses, and use the
    most helpful output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
