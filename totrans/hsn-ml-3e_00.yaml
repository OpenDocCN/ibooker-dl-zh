- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: The Machine Learning Tsunami
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习海啸
- en: In 2006, Geoffrey Hinton et al. published [a paper](https://homl.info/136)⁠⁠^([1](preface01.html#idm45720219385120))
    showing how to train a deep neural network capable of recognizing handwritten
    digits with state-of-the-art precision (>98%). They branded this technique “deep
    learning”. A deep neural network is a (very) simplified model of our cerebral
    cortex, composed of a stack of layers of artificial neurons. Training a deep neural
    net was widely considered impossible at the time,⁠⁠^([2](preface01.html#idm45720253720192))
    and most researchers had abandoned the idea in the late 1990s. This paper revived
    the interest of the scientific community, and before long many new papers demonstrated
    that deep learning was not only possible, but capable of mind-blowing achievements
    that no other machine learning (ML) technique could hope to match (with the help
    of tremendous computing power and great amounts of data). This enthusiasm soon
    extended to many other areas of machine learning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 2006年，Geoffrey Hinton等人发表了一篇论文，展示了如何训练一个能够以最先进的精度（>98%）识别手写数字的深度神经网络。他们将这种技术称为“深度学习”。深度神经网络是我们大脑皮层的（非常）简化模型，由一系列人工神经元层组成。在当时，训练深度神经网络被普遍认为是不可能的，大多数研究人员在1990年代末放弃了这个想法。这篇论文重新激起了科学界的兴趣，不久之后，许多新论文证明了深度学习不仅是可能的，而且能够实现令人惊叹的成就，其他任何机器学习（ML）技术都无法匹敌（在巨大的计算能力和大量数据的帮助下）。这种热情很快扩展到许多其他机器学习领域。
- en: A decade later, machine learning had conquered the industry, and today it is
    at the heart of much of the magic in high-tech products, ranking your web search
    results, powering your smartphone’s speech recognition, recommending videos, and
    perhaps even driving your car.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 十年后，机器学习已经征服了行业，如今它是许多高科技产品中许多神奇功能的核心，比如排名您的网络搜索结果，为您的智能手机提供语音识别，推荐视频，甚至可能驾驶您的汽车。
- en: Machine Learning in Your Projects
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在您的项目中应用机器学习
- en: So, naturally you are excited about machine learning and would love to join
    the party!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您对机器学习感到兴奋，并希望加入这个派对！
- en: Perhaps you would like to give your homemade robot a brain of its own? Make
    it recognize faces? Or learn to walk around?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 也许您想让您自制的机器人拥有自己的大脑？让它识别人脸？或学会四处走动？
- en: 'Or maybe your company has tons of data (user logs, financial data, production
    data, machine sensor data, hotline stats, HR reports, etc.), and more than likely
    you could unearth some hidden gems if you just knew where to look. With machine
    learning, you could accomplish the following [and much more](https://homl.info/usecases):'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 或者您的公司有大量数据（用户日志、财务数据、生产数据、机器传感器数据、热线统计、人力资源报告等），很可能如果您知道在哪里寻找，您可以发现一些隐藏的宝藏。通过机器学习，您可以实现以下目标[以及更多](https://homl.info/usecases)：
- en: Segment customers and find the best marketing strategy for each group.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析客户并找到每个群体的最佳营销策略。
- en: Recommend products for each client based on what similar clients bought.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据类似客户购买的产品，为每个客户推荐产品。
- en: Detect which transactions are likely to be fraudulent.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测哪些交易可能是欺诈性的。
- en: Forecast next year’s revenue.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测明年的收入。
- en: Whatever the reason, you have decided to learn machine learning and implement
    it in your projects. Great idea!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 无论出于何种原因，您已经决定学习机器学习并在您的项目中实施它。好主意！
- en: Objective and Approach
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标和方法
- en: This book assumes that you know close to nothing about machine learning. Its
    goal is to give you the concepts, tools, and intuition you need to implement programs
    capable of *learning from data*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本书假设您对机器学习几乎一无所知。其目标是为您提供实现能够*从数据中学习*的程序所需的概念、工具和直觉。
- en: 'We will cover a large number of techniques, from the simplest and most commonly
    used (such as linear regression) to some of the deep learning techniques that
    regularly win competitions. For this, we will be using production-ready Python
    frameworks:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖大量技术，从最简单和最常用的（如线性回归）到一些经常赢得比赛的深度学习技术。为此，我们将使用生产就绪的Python框架：
- en: '[Scikit-Learn](https://scikit-learn.org) is very easy to use, yet it implements
    many machine learning algorithms efficiently, so it makes for a great entry point
    to learning machine learning. It was created by David Cournapeau in 2007, and
    is now led by a team of researchers at the French Institute for Research in Computer
    Science and Automation (Inria).'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scikit-Learn非常易于使用，同时高效实现了许多机器学习算法，因此它是学习机器学习的绝佳入门点。它由David Cournapeau于2007年创建，现在由法国国家计算机与自动化研究所（Inria）的一组研究人员领导。
- en: '[TensorFlow](https://tensorflow.org) is a more complex library for distributed
    numerical computation. It makes it possible to train and run very large neural
    networks efficiently by distributing the computations across potentially hundreds
    of multi-GPU (graphics processing unit) servers. TensorFlow (TF) was created at
    Google and supports many of its large-scale machine learning applications. It
    was open sourced in November 2015, and version 2.0 was released in September 2019.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow是一个更复杂的分布式数值计算库。它通过在数百个多GPU（图形处理单元）服务器上分布计算，使得训练和运行非常大的神经网络变得高效。TensorFlow（TF）由Google创建，并支持许多其大规模机器学习应用。它于2015年11月开源，2.0版本于2019年9月发布。
- en: '[Keras](https://keras.io) is a high-level deep learning API that makes it very
    simple to train and run neural networks. Keras comes bundled with TensorFlow,
    and it relies on TensorFlow for all the intensive computations.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras是一个高级深度学习API，使训练和运行神经网络变得非常简单。Keras与TensorFlow捆绑在一起，并依赖于TensorFlow进行所有密集计算。
- en: The book favors a hands-on approach, growing an intuitive understanding of machine
    learning through concrete working examples and just a little bit of theory.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本书倾向于实践方法，通过具体的工作示例和一点点理论来培养对机器学习的直观理解。
- en: Tip
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: While you can read this book without picking up your laptop, I highly recommend
    you experiment with the code examples.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以不用拿起笔记本阅读本书，但我强烈建议您尝试一下代码示例。
- en: Code Examples
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码示例
- en: 'All the code examples in this book are open source and available online at
    [*https://github.com/ageron/handson-ml3*](https://github.com/ageron/handson-ml3),
    as Jupyter notebooks. These are interactive documents containing text, images,
    and executable code snippets (Python in our case). The easiest and quickest way
    to get started is to run these notebooks using Google Colab: this is a free service
    that allows you to run any Jupyter notebook directly online, without having to
    install anything on your machine. All you need is a web browser and a Google account.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有代码示例都是开源的，可以在[*https://github.com/ageron/handson-ml3*](https://github.com/ageron/handson-ml3)上在线获取，作为Jupyter笔记本。这些是交互式文档，包含文本、图片和可执行的代码片段（在我们的案例中是Python）。开始的最简单最快的方法是使用Google
    Colab运行这些笔记本：这是一个免费服务，允许您直接在线运行任何Jupyter笔记本，无需在您的机器上安装任何东西。您只需要一个网络浏览器和一个Google账号。
- en: Note
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In this book, I will assume that you are using Google Colab, but I have also
    tested the notebooks on other online platforms such as Kaggle and Binder, so you
    can use those if you prefer. Alternatively, you can install the required libraries
    and tools (or the Docker image for this book) and run the notebooks directly on
    your own machine. See the instructions at [*https://homl.info/install*](https://homl.info/install).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我假设您正在使用Google Colab，但我也在其他在线平台上测试了这些笔记本，如Kaggle和Binder，所以如果您愿意，也可以使用这些平台。或者，您可以安装所需的库和工具（或本书的Docker镜像），并在自己的机器上直接运行这些笔记本。请参阅[*https://homl.info/install*](https://homl.info/install)上的说明。
- en: This book is here to help you get your job done. If you wish to use additional
    content beyond the code examples, and that use falls outside the scope of fair
    use guidelines, (such as selling or distributing content from O’Reilly books,
    or incorporating a significant amount of material from this book into your product’s
    documentation), please reach out to us for permission, at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在帮助您完成工作。如果您希望使用代码示例以外的其他内容，并且该使用超出了公平使用准则的范围（例如出售或分发O'Reilly图书的内容，或将本书的大量材料整合到产品文档中），请通过[*permissions@oreilly.com*](mailto:permissions@oreilly.com)联系我们以获取许可。
- en: 'We appreciate, but do not require, attribution. An attribution usually includes
    the title, author, publisher, and ISBN. For example: “*Hands-On Machine Learning
    with Scikit-Learn, Keras, and TensorFlow* by Aurélien Géron. Copyright 2023 Aurélien
    Géron, 978-1-098-12597-4.”'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢，但不要求署名。署名通常包括标题、作者、出版商和ISBN。例如：“*使用Scikit-Learn、Keras和TensorFlow进行实践机器学习*
    by Aurélien Géron. 版权所有 2023 Aurélien Géron, 978-1-098-12597-4.”
- en: Prerequisites
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 先决条件
- en: This book assumes that you have some Python programming experience. If you don’t
    know Python yet, [*https://learnpython.org*](https://learnpython.org) is a great
    place to start. The official tutorial on [Python.org](https://docs.python.org/3/tutorial)
    is also quite good.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本书假定您具有一些Python编程经验。如果您还不了解Python，[*https://learnpython.org*](https://learnpython.org)是一个很好的开始。[Python.org](https://docs.python.org/3/tutorial)上的官方教程也非常不错。
- en: This book also assumes that you are familiar with Python’s main scientific libraries—in
    particular, [NumPy](https://numpy.org), [Pandas](https://pandas.pydata.org), and
    [Matplotlib](https://matplotlib.org). If you have never used these libraries,
    don’t worry; they’re easy to learn, and I’ve created a tutorial for each of them.
    You can access them online at [*https://homl.info/tutorials*](https://homl.info/tutorials).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本书还假定您熟悉Python的主要科学库，特别是[NumPy](https://numpy.org)、[Pandas](https://pandas.pydata.org)和[Matplotlib](https://matplotlib.org)。如果您从未使用过这些库，不用担心；它们很容易学习，我为每个库创建了一个教程。您可以在[*https://homl.info/tutorials*](https://homl.info/tutorials)上在线访问它们。
- en: Moreover, if you want to fully understand how the machine learning algorithms
    work (not just how to use them), then you should have at least a basic understanding
    of a few math concepts, especially linear algebra. Specifically, you should know
    what vectors and matrices are, and how to perform some simple operations like
    adding vectors, or transposing and multiplying matrices. If you need a quick introduction
    to linear algebra (it’s really not rocket science!), I provide a tutorial at [*https://homl.info/tutorials*](https://homl.info/tutorials).
    You will also find a tutorial on differential calculus, which may be helpful to
    understand how neural networks are trained, but it’s not entirely essential to
    grasp the important concepts. This book also uses other mathematical concepts
    occasionally, such as exponentials and logarithms, a bit of probability theory,
    and some basic statistics concepts, but nothing too advanced. If you need help
    on any of these, please check out [*https://khanacademy.org*](https://khanacademy.org),
    which offers many excellent and free math courses online.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果您想完全理解机器学习算法的工作原理（不仅仅是如何使用它们），那么您应该至少对一些数学概念有基本的了解，尤其是线性代数。具体来说，您应该知道什么是向量和矩阵，以及如何执行一些简单的操作，比如添加向量，或转置和相乘矩阵。如果您需要快速了解线性代数（这真的不是什么难事！），我在[*https://homl.info/tutorials*](https://homl.info/tutorials)提供了一个教程。您还会找到一个关于微分计算的教程，这可能有助于理解神经网络是如何训练的，但并非完全必要掌握重要概念。本书偶尔还使用其他数学概念，如指数和对数，一些概率论，以及一些基本的统计概念，但没有太高级的内容。如果您需要帮助，请查看[*https://khanacademy.org*](https://khanacademy.org)，该网站提供许多优秀且免费的数学课程。
- en: Roadmap
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 路线图
- en: 'This book is organized in two parts. [Part I, “The Fundamentals of Machine
    Learning”](part01.html#fundamentals_part), covers the following topics:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本书分为两部分。[第一部分，“机器学习基础”](part01.html#fundamentals_part)，涵盖以下主题：
- en: What machine learning is, what problems it tries to solve, and the main categories
    and fundamental concepts of its systems
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习是什么，它试图解决什么问题，以及其系统的主要类别和基本概念
- en: The steps in a typical machine learning project
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 典型机器学习项目中的步骤
- en: Learning by fitting a model to data
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将模型拟合到数据来学习
- en: Optimizing a cost function
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化成本函数
- en: Handling, cleaning, and preparing data
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理，清洗和准备数据
- en: Selecting and engineering features
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择和工程特征
- en: Selecting a model and tuning hyperparameters using cross-validation
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用交叉验证选择模型和调整超参数
- en: The challenges of machine learning, in particular underfitting and overfitting
    (the bias/variance trade-off)
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的挑战，特别是欠拟合和过拟合（偏差/方差权衡）
- en: 'The most common learning algorithms: linear and polynomial regression, logistic
    regression, *k*-nearest neighbors, support vector machines, decision trees, random
    forests, and ensemble methods'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最常见的学习算法：线性和多项式回归，逻辑回归，k-最近邻，支持向量机，决策树，随机森林和集成方法
- en: Reducing the dimensionality of the training data to fight the “curse of dimensionality”
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少训练数据的维度以对抗“维度灾难”
- en: Other unsupervised learning techniques, including clustering, density estimation,
    and anomaly detection
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他无监督学习技术，包括聚类，密度估计和异常检测
- en: '[Part II, “Neural Networks and Deep Learning”](part02.html#neural_nets_part),
    covers the following topics:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[第二部分，“神经网络和深度学习”](part02.html#neural_nets_part)，涵盖以下主题：'
- en: What neural nets are and what they’re good for
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络是什么以及它们适用于什么
- en: Building and training neural nets using TensorFlow and Keras
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorFlow和Keras构建和训练神经网络
- en: 'The most important neural net architectures: feedforward neural nets for tabular
    data, convolutional nets for computer vision, recurrent nets and long short-term
    memory (LSTM) nets for sequence processing, encoder–decoders and transformers
    for natural language processing (and more!), autoencoders, generative adversarial
    networks (GANs), and diffusion models for generative learning'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最重要的神经网络架构：用于表格数据的前馈神经网络，用于计算机视觉的卷积网络，用于序列处理的循环网络和长短期记忆（LSTM）网络，用于自然语言处理的编码器-解码器和变压器（以及更多！），自动编码器，生成对抗网络（GANs）和扩散模型用于生成学习
- en: Techniques for training deep neural nets
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练深度神经网络的技术
- en: How to build an agent (e.g., a bot in a game) that can learn good strategies
    through trial and error, using reinforcement learning
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建一个代理（例如游戏中的机器人），通过试错学习良好策略，使用强化学习
- en: Loading and preprocessing large amounts of data efficiently
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高效加载和预处理大量数据
- en: Training and deploying TensorFlow models at scale
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在规模上训练和部署TensorFlow模型
- en: The first part is based mostly on Scikit-Learn, while the second part uses TensorFlow
    and Keras.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 第一部分主要基于Scikit-Learn，而第二部分使用TensorFlow和Keras。
- en: Caution
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Don’t jump into deep waters too hastily: while deep learning is no doubt one
    of the most exciting areas in machine learning, you should master the fundamentals
    first. Moreover, most problems can be solved quite well using simpler techniques
    such as random forests and ensemble methods (discussed in [Part I](part01.html#fundamentals_part)).
    deep learning is best suited for complex problems such as image recognition, speech
    recognition, or natural language processing, and it requires a lot of data, computing
    power, and patience (unless you can leverage a pretrained neural network, as you
    will see).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 不要过于仓促地跳入深水：尽管深度学习无疑是机器学习中最令人兴奋的领域之一，但您应该先掌握基础知识。此外，大多数问题可以使用更简单的技术（如随机森林和集成方法）很好地解决（在[第一部分](part01.html#fundamentals_part)讨论）。深度学习最适合复杂问题，如图像识别，语音识别或自然语言处理，它需要大量数据，计算能力和耐心（除非您可以利用预训练的神经网络，如您将看到的那样）。
- en: Changes Between the First and the Second Edition
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一版和第二版之间的变化
- en: 'If you have already read the first edition, here are the main changes between
    the first and the second edition:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经阅读了第一版，以下是第一版和第二版之间的主要变化：
- en: All the code was migrated from TensorFlow 1.x to TensorFlow 2.x, and I replaced
    most of the low-level TensorFlow code (graphs, sessions, feature columns, estimators,
    and so on) with much simpler Keras code.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有代码都已从TensorFlow 1.x迁移到TensorFlow 2.x，并且我用更简单的Keras代码替换了大部分低级TensorFlow代码（图形，会话，特征列等）。
- en: The second edition introduced the Data API for loading and preprocessing large
    datasets, the distribution strategies API to train and deploy TF models at scale,
    TF Serving and Google Cloud AI Platform to productionize models, and (briefly)
    TF Transform, TFLite, TF Addons/Seq2Seq, TensorFlow.js, and TF Agents.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二版引入了用于加载和预处理大型数据集的Data API，用于规模训练和部署TF模型的分布策略API，用于将模型投入生产的TF Serving和Google
    Cloud AI Platform，以及（简要介绍）TF Transform，TFLite，TF Addons/Seq2Seq，TensorFlow.js和TF
    Agents。
- en: It also introduced many additional ML topics, including a new chapter on unsupervised
    learning, computer vision techniques for object detection and semantic segmentation,
    handling sequences using convolutional neural networks (CNNs), natural language
    processing (NLP) using recurrent neural networks (RNNs), CNNs and transformers,
    GANs, and more.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它还引入了许多其他ML主题，包括一个新的无监督学习章节，用于目标检测和语义分割的计算机视觉技术，使用卷积神经网络（CNN）处理序列，使用循环神经网络（RNN）、CNN和变压器进行自然语言处理（NLP），GANs等。
- en: See [*https://homl.info/changes2*](https://homl.info/changes2) for more details.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多详细信息，请参阅[*https://homl.info/changes2*](https://homl.info/changes2)。
- en: Changes Between the Second and the Third Edition
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二版和第三版之间的变化
- en: 'If you read the second edition, here are the main changes between the second
    and the third edition:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您阅读了第二版，以下是第二版和第三版之间的主要变化：
- en: All the code was updated to the latest library versions. In particular, this
    third edition introduces many new additions to Scikit-Learn (e.g., feature name
    tracking, histogram-based gradient boosting, label propagation, and more). It
    also introduces the *Keras Tuner* library for hyperparameter tuning, Hugging Face’s
    *Transformers* library for natural language processing, and Keras’s new preprocessing
    and data augmentation layers.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有代码都已更新到最新的库版本。特别是，这第三版引入了许多新的Scikit-Learn补充（例如，特征名称跟踪，基于直方图的梯度提升，标签传播等）。它还引入了用于超参数调整的Keras
    Tuner库，用于自然语言处理的Hugging Face的Transformers库，以及Keras的新预处理和数据增强层。
- en: Several vision models were added (ResNeXt, DenseNet, MobileNet, CSPNet, and
    EfficientNet), as well as guidelines for choosing the right one.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加了几个视觉模型（ResNeXt、DenseNet、MobileNet、CSPNet和EfficientNet），以及选择正确模型的指南。
- en: '[Chapter 15](ch15.html#rnn_chapter) now analyzes the Chicago bus and rail ridership
    data instead of generated time series, and it introduces the ARMA model and its
    variants.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第15章](ch15.html#rnn_chapter)现在分析芝加哥公共汽车和轨道乘客数据，而不是生成的时间序列，并介绍了ARMA模型及其变体。'
- en: '[Chapter 16](ch16.html#nlp_chapter) on natural language processing now builds
    an English-to-Spanish translation model, first using an encoder–decoder RNN, then
    using a transformer model. The chapter also covers language models such as Switch
    Transformers, DistilBERT, T5, and PaLM (with chain-of-thought prompting). In addition,
    it introduces vision transformers (ViTs) and gives an overview of a few transformer-based
    visual models, such as data-efficient image transformers (DeiTs), Perceiver, and
    DINO, as well as a brief overview of some large multimodal models, including CLIP,
    DALL·E, Flamingo, and GATO.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第16章](ch16.html#nlp_chapter)关于自然语言处理现在构建了一个英语到西班牙语的翻译模型，首先使用编码器-解码器RNN，然后使用变压器模型。该章还涵盖了语言模型，如Switch
    Transformers、DistilBERT、T5和PaLM（带有思维链提示）。此外，它介绍了视觉变压器（ViTs）并概述了一些基于变压器的视觉模型，如数据高效图像变压器（DeiTs）、Perceiver和DINO，以及一些大型多模态模型的简要概述，包括CLIP、DALL·E、Flamingo和GATO。'
- en: '[Chapter 17](ch17.html#autoencoders_chapter) on generative learning now introduces
    diffusion models, and shows how to implement a denoising diffusion probabilistic
    model (DDPM) from scratch.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第17章](ch17.html#autoencoders_chapter)关于生成学习现在引入了扩散模型，并展示了如何从头开始实现去噪扩散概率模型（DDPM）。'
- en: '[Chapter 19](ch19.html#deployment_chapter) migrated from Google Cloud AI Platform
    to Google Vertex AI, and uses distributed Keras Tuner for large-scale hyperparameter
    search. The chapter now includes TensorFlow.js code that you can experiment with
    online. It also introduces additional distributed training techniques, including
    PipeDream and Pathways.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第19章](ch19.html#deployment_chapter)从Google Cloud AI平台迁移到Google Vertex AI，并使用分布式Keras
    Tuner进行大规模超参数搜索。该章现在包括您可以在线尝试的TensorFlow.js代码。它还介绍了其他分布式训练技术，包括PipeDream和Pathways。'
- en: In order to allow for all the new content, some sections were moved online,
    including installation instructions, kernel principal component analysis (PCA),
    mathematical details of Bayesian Gaussian mixtures, TF Agents, and former appendices
    A (exercise solutions), C (support vector machine math), and E (extra neural net
    architectures).
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了容纳所有新内容，一些部分被移至在线，包括安装说明、核主成分分析（PCA）、贝叶斯高斯混合的数学细节、TF Agents，以及以前的附录A（练习解决方案）、C（支持向量机数学）和E（额外的神经网络架构）。
- en: See [*https://homl.info/changes3*](https://homl.info/changes3) for more details.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 更多详情请查看[*https://homl.info/changes3*](https://homl.info/changes3)。
- en: Other Resources
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他资源
- en: Many excellent resources are available to learn about machine learning. For
    example, Andrew Ng’s [ML course on Coursera](https://homl.info/ngcourse) is amazing,
    although it requires a significant time investment.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多优秀的资源可供学习机器学习。例如，Andrew Ng在Coursera上的ML课程令人惊叹，尽管需要投入大量时间。
- en: There are also many interesting websites about machine learning, including Scikit-Learn’s
    exceptional [User Guide](https://homl.info/skdoc). You may also enjoy [Dataquest](https://dataquest.io),
    which provides very nice interactive tutorials, and ML blogs such as those listed
    on [Quora](https://homl.info/1).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多关于机器学习的有趣网站，包括Scikit-Learn的出色[用户指南](https://homl.info/skdoc)。您可能还会喜欢[Dataquest](https://dataquest.io)，它提供非常好的交互式教程，以及像[Quora](https://homl.info/1)上列出的ML博客。
- en: 'There are many other introductory books about machine learning. In particular:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多关于机器学习的入门书籍。特别是：
- en: Joel Grus’s [*Data Science from Scratch*](https://homl.info/grusbook), 2nd edition
    (O’Reilly), presents the fundamentals of machine learning and implements some
    of the main algorithms in pure Python (from scratch, as the name suggests).
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Joel Grus的《从零开始的数据科学》，第二版（O'Reilly），介绍了机器学习的基础知识，并使用纯Python实现了一些主要算法（从头开始，正如名称所示）。
- en: 'Stephen Marsland’s *Machine Learning: An Algorithmic Perspective*, 2nd edition
    (Chapman & Hall), is a great introduction to machine learning, covering a wide
    range of topics in depth with code examples in Python (also from scratch, but
    using NumPy).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stephen Marsland的《机器学习：算法视角》，第二版（Chapman＆Hall），是机器学习的一个很好的入门，深入涵盖了各种主题，使用Python中的代码示例（也是从头开始，但使用NumPy）。
- en: Sebastian Raschka’s *Python Machine Learning*, 3rd edition (Packt Publishing),
    is also a great introduction to machine learning and leverages Python open source
    libraries (Pylearn 2 and Theano).
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sebastian Raschka的《Python机器学习》，第三版（Packt Publishing），也是机器学习的一个很好的入门，利用了Python开源库（Pylearn
    2和Theano）。
- en: François Chollet’s *Deep Learning with Python*, 2nd edition (Manning), is a
    very practical book that covers a large range of topics in a clear and concise
    way, as you might expect from the author of the excellent Keras library. It favors
    code examples over mathematical theory.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: François Chollet的《Python深度学习》，第二版（Manning），是一本非常实用的书，以清晰简洁的方式涵盖了广泛的主题，正如你可能从优秀的Keras库的作者所期望的那样。它更偏向于代码示例而不是数学理论。
- en: Andriy Burkov’s [*The Hundred-Page Machine Learning Book*](https://themlbook.com)
    (self-published) is very short but covers an impressive range of topics, introducing
    them in approachable terms without shying away from the math equations.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andriy Burkov的《百页机器学习书》（自出版）非常简短，但涵盖了令人印象深刻的一系列主题，以平易近人的术语介绍，而不回避数学方程式。
- en: Yaser S. Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin’s *Learning from
    Data* (AMLBook) is a rather theoretical approach to ML that provides deep insights,
    in particular on the bias/variance trade-off (see [Chapter 4](ch04.html#linear_models_chapter)).
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yaser S. Abu-Mostafa，Malik Magdon-Ismail和Hsuan-Tien Lin的《从数据中学习》（AMLBook）是一个相当理论化的ML方法，提供了深刻的见解，特别是关于偏差/方差权衡（参见[第4章](ch04.html#linear_models_chapter)）。
- en: 'Stuart Russell and Peter Norvig’s *Artificial Intelligence: A Modern Approach*,
    4th edition (Pearson), is a great (and huge) book covering an incredible amount
    of topics, including machine learning. It helps put ML into perspective.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stuart Russell和Peter Norvig的《人工智能：现代方法》，第4版（Pearson），是一本涵盖大量主题的伟大（而庞大）的书籍，包括机器学习。它有助于将ML置于透视中。
- en: Jeremy Howard and Sylvain Gugger’s *Deep Learning for Coders with fastai and
    PyTorch* (O’Reilly) provides a wonderfully clear and practical introduction to
    deep learning using the fastai and PyTorch libraries.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeremy Howard和Sylvain Gugger的《使用fastai和PyTorch进行编码的深度学习》（O'Reilly）提供了一个清晰实用的深度学习介绍，使用了fastai和PyTorch库。
- en: Finally, joining ML competition websites such as [Kaggle.com](https://kaggle.com/)
    will allow you to practice your skills on real-world problems, with help and insights
    from some of the best ML professionals out there.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，加入ML竞赛网站，如[Kaggle.com](https://kaggle.com/)，将使您能够在实际问题上练习技能，并获得来自一些最优秀的ML专业人士的帮助和见解。
- en: Conventions Used in This Book
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书使用的约定
- en: 'The following typographical conventions are used in this book:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用以下排版约定：
- en: '*Italic*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*斜体*'
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 指示新术语、URL、电子邮件地址、文件名和文件扩展名。
- en: '`Constant width`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`等宽`'
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 用于程序清单，以及在段落中引用程序元素，如变量或函数名、数据库、数据类型、环境变量、语句和关键字。
- en: '**`Constant width bold`**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**`等宽粗体`**'
- en: Shows commands or other text that should be typed literally by the user.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 显示用户应按照字面意义输入的命令或其他文本。
- en: '*`Constant width italic`*'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*`等宽斜体`*'
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 显示应替换为用户提供的值或由上下文确定的值的文本。
- en: Punctuation
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 标点
- en: To avoid any confusion, punctutation appears outside of quotes throughout the
    book. My apologies to the purists.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为避免混淆，本书中引号外的标点符号。对纯粹主义者表示歉意。
- en: Tip
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: This element signifies a tip or suggestion.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示提示或建议。
- en: Note
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This element signifies a general note.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示一般说明。
- en: Warning
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: This element indicates a warning or caution.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示警告或注意事项。
- en: O’Reilly Online Learning
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O'Reilly在线学习
- en: Note
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For more than 40 years, [*O’Reilly Media*](https://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 40多年来，[*O'Reilly Media*](https://oreilly.com)提供技术和商业培训、知识和见解，帮助公司取得成功。
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*https://oreilly.com*](https://oreilly.com).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们独特的专家和创新者网络通过书籍、文章和我们的在线学习平台分享他们的知识和专长。O'Reilly的在线学习平台为您提供按需访问实时培训课程、深入学习路径、交互式编码环境以及来自O'Reilly和其他200多家出版商的大量文本和视频。有关更多信息，请访问[*https://oreilly.com*](https://oreilly.com)。
- en: How to Contact Us
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何联系我们
- en: 'Please address comments and questions concerning this book to the publisher:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 请将有关本书的评论和问题发送至出版商：
- en: O’Reilly Media, Inc.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: O'Reilly Media, Inc.
- en: 1005 Gravenstein Highway North
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1005 Gravenstein Highway North
- en: Sebastopol, CA 95472
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sebastopol, CA 95472
- en: 800-998-9938 (in the United States or Canada)
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 800-998-9938（美国或加拿大）
- en: 707-829-0515 (international or local)
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0515（国际或本地）
- en: 707-829-0104 (fax)
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0104（传真）
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://homl.info/oreilly3*](https://homl.info/oreilly3).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为本书创建了一个网页，列出勘误、示例和任何其他信息。您可以在[*https://homl.info/oreilly3*](https://homl.info/oreilly3)访问此页面。
- en: Email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com) to comment
    or ask technical questions about this book.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 发送电子邮件至[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)评论或询问有关本书的技术问题。
- en: For news and information about our books and courses, visit [*https://oreilly.com*](https://oreilly.com).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 有关我们的书籍和课程的新闻和信息，请访问[*https://oreilly.com*](https://oreilly.com)。
- en: 'Find us on LinkedIn: [*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在LinkedIn上找到我们：[*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)
- en: 'Follow us on Twitter: [*https://twitter.com/oreillymedia*](https://twitter.com/oreillymedia)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在Twitter上关注我们：[*https://twitter.com/oreillymedia*](https://twitter.com/oreillymedia)
- en: 'Watch us on YouTube: [*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在YouTube上观看我们：[*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)
- en: Acknowledgments
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: Never in my wildest dreams did I imagine that the first and second editions
    of this book would get such a large audience. I received so many messages from
    readers, many asking questions, some kindly pointing out errata, and most sending
    me encouraging words. I cannot express how grateful I am to all these readers
    for their tremendous support. Thank you all so very much! Please do not hesitate
    to [file issues on GitHub](https://homl.info/issues3) if you find errors in the
    code examples (or just to ask questions), or to submit [errata](https://homl.info/errata3)
    if you find errors in the text. Some readers also shared how this book helped
    them get their first job, or how it helped them solve a concrete problem they
    were working on. I find such feedback incredibly motivating. If you find this
    book helpful, I would love it if you could share your story with me, either privately
    (e.g., via [LinkedIn](https://linkedin.com/in/aurelien-geron)) or publicly (e.g.,
    tweet me at @aureliengeron or write an [Amazon review](https://homl.info/amazon3)).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在我最疯狂的梦想中，我从未想象过这本书的第一版和第二版会获得如此庞大的读者群。我收到了许多读者的留言，许多人提出问题，一些人友善地指出勘误，大多数人给我寄来鼓励的话语。我无法表达我对所有这些读者的巨大支持的感激之情。非常感谢你们所有人！如果您在代码示例中发现错误（或者只是想提问），请毫不犹豫地在GitHub上[提交问题](https://homl.info/issues3)，或者如果您在文本中发现错误，请提交[勘误](https://homl.info/errata3)。一些读者还分享了这本书如何帮助他们找到第一份工作，或者如何帮助他们解决了他们正在处理的具体问题。我发现这样的反馈极具激励性。如果您觉得这本书有帮助，我会很高兴如果您能与我分享您的故事，无论是私下（例如通过[LinkedIn](https://linkedin.com/in/aurelien-geron)）还是公开（例如在Twitter上@
    aureliengeron发推文或撰写[亚马逊评论](https://homl.info/amazon3)）。
- en: 'Huge thanks as well to all the wonderful people who offered their time and
    expertise to review this third edition, correcting errors and making countless
    suggestions. This edition is so much better thanks to them: Olzhas Akpambetov,
    George Bonner, François Chollet, Siddha Ganju, Sam Goodman, Matt Harrison, Sasha
    Sobran, Lewis Tunstall, Leandro von Werra, and my dear brother Sylvain. You are
    all amazing!'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 同样非常感谢所有那些慷慨提供时间和专业知识来审阅这第三版，纠正错误并提出无数建议的出色人士。多亏了他们，这版书变得更好了：Olzhas Akpambetov、George
    Bonner、François Chollet、Siddha Ganju、Sam Goodman、Matt Harrison、Sasha Sobran、Lewis
    Tunstall、Leandro von Werra和我亲爱的弟弟Sylvain。你们都太棒了！
- en: 'I am also very grateful to the many people who supported me along the way,
    by answering my questions, suggesting improvements, and contributing to the code
    on GitHub: in particular, Yannick Assogba, Ian Beauregard, Ulf Bissbort, Rick
    Chao, Peretz Cohen, Kyle Gallatin, Hannes Hapke, Victor Khaustov, Soonson Kwon,
    Eric Lebigot, Jason Mayes, Laurence Moroney, Sara Robinson, Joaquín Ruales, and
    Yuefeng Zhou.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我也非常感激许多人在我前进的道路上支持我，回答我的问题，提出改进建议，并在GitHub上贡献代码：特别是Yannick Assogba、Ian Beauregard、Ulf
    Bissbort、Rick Chao、Peretz Cohen、Kyle Gallatin、Hannes Hapke、Victor Khaustov、Soonson
    Kwon、Eric Lebigot、Jason Mayes、Laurence Moroney、Sara Robinson、Joaquín Ruales和Yuefeng
    Zhou。
- en: 'This book wouldn’t exist without O’Reilly’s fantastic staff, in particular
    Nicole Taché, who gave me insightful feedback and was always cheerful, encouraging,
    and helpful: I could not dream of a better editor. Big thanks to Michele Cronin
    as well, who cheered me on through the final chapters and managed to get me past
    the finish line. Thanks to the whole production team, in particular Elizabeth
    Kelly and Kristen Brown. Thanks as well to Kim Cofer for the thorough copyediting,
    and to Johnny O’Toole, who managed the relationship with Amazon and answered many
    of my questions. Thanks to Kate Dullea for greatly improving my illustrations.
    Thanks to Marie Beaugureau, Ben Lorica, Mike Loukides, and Laurel Ruma for believing
    in this project and helping me define its scope. Thanks to Matt Hacker and all
    of the Atlas team for answering all my technical questions regarding formatting,
    AsciiDoc, MathML, and LaTeX, and thanks to Nick Adams, Rebecca Demarest, Rachel
    Head, Judith McConville, Helen Monroe, Karen Montgomery, Rachel Roumeliotis, and
    everyone else at O’Reilly who contributed to this book.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 没有O'Reilly出色的员工，特别是Nicole Taché，这本书就不会存在，她给了我深刻的反馈，总是充满活力、鼓励和帮助：我无法想象有比她更好的编辑。非常感谢Michele
    Cronin，她在最后几章中给予我鼓励，并帮助我完成了最后的工作。感谢整个制作团队，特别是Elizabeth Kelly和Kristen Brown。同样感谢Kim
    Cofer进行了彻底的编辑工作，以及Johnny O'Toole，他管理了与亚马逊的关系，并回答了我许多问题。感谢Kate Dullea大大改进了我的插图。感谢Marie
    Beaugureau、Ben Lorica、Mike Loukides和Laurel Ruma相信这个项目，并帮助我定义其范围。感谢Matt Hacker和整个Atlas团队回答了我关于格式、AsciiDoc、MathML和LaTeX的所有技术问题，感谢Nick
    Adams、Rebecca Demarest、Rachel Head、Judith McConville、Helen Monroe、Karen Montgomery、Rachel
    Roumeliotis以及O'Reilly的所有其他贡献者。
- en: 'I’ll never forget all the wonderful people who helped me with the first and
    second editions of this book: friends, colleagues, experts, including many members
    of the TensorFlow team. The list is long: Olzhas Akpambetov, Karmel Allison, Martin
    Andrews, David Andrzejewski, Paige Bailey, Lukas Biewald, Eugene Brevdo, William
    Chargin, François Chollet, Clément Courbet, Robert Crowe, Mark Daoust, Daniel
    “Wolff” Dobson, Julien Dubois, Mathias Kende, Daniel Kitachewsky, Nick Felt, Bruce
    Fontaine, Justin Francis, Goldie Gadde, Irene Giannoumis, Ingrid von Glehn, Vincent
    Guilbeau, Sandeep Gupta, Priya Gupta, Kevin Haas, Eddy Hung, Konstantinos Katsiapis,
    Viacheslav Kovalevskyi, Jon Krohn, Allen Lavoie, Karim Matrah, Grégoire Mesnil,
    Clemens Mewald, Dan Moldovan, Dominic Monn, Sean Morgan, Tom O’Malley, James Pack,
    Alexander Pak, Haesun Park, Alexandre Passos, Ankur Patel, Josh Patterson, André
    Susano Pinto, Anthony Platanios, Anosh Raj, Oscar Ramirez, Anna Revinskaya, Saurabh
    Saxena, Salim Sémaoune, Ryan Sepassi, Vitor Sessak, Jiri Simsa, Iain Smears, Xiaodan
    Song, Christina Sorokin, Michel Tessier, Wiktor Tomczak, Dustin Tran, Todd Wang,
    Pete Warden, Rich Washington, Martin Wicke, Edd Wilder-James, Sam Witteveen, Jason
    Zaman, Yuefeng Zhou, and my brother Sylvain.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我永远不会忘记所有在这本书的第一版和第二版中帮助过我的美好人们：朋友、同事、专家，包括TensorFlow团队的许多成员。名单很长：Olzhas Akpambetov，Karmel
    Allison，Martin Andrews，David Andrzejewski，Paige Bailey，Lukas Biewald，Eugene Brevdo，William
    Chargin，François Chollet，Clément Courbet，Robert Crowe，Mark Daoust，Daniel “Wolff”
    Dobson，Julien Dubois，Mathias Kende，Daniel Kitachewsky，Nick Felt，Bruce Fontaine，Justin
    Francis，Goldie Gadde，Irene Giannoumis，Ingrid von Glehn，Vincent Guilbeau，Sandeep
    Gupta，Priya Gupta，Kevin Haas，Eddy Hung，Konstantinos Katsiapis，Viacheslav Kovalevskyi，Jon
    Krohn，Allen Lavoie，Karim Matrah，Grégoire Mesnil，Clemens Mewald，Dan Moldovan，Dominic
    Monn，Sean Morgan，Tom O’Malley，James Pack，Alexander Pak，Haesun Park，Alexandre Passos，Ankur
    Patel，Josh Patterson，André Susano Pinto，Anthony Platanios，Anosh Raj，Oscar Ramirez，Anna
    Revinskaya，Saurabh Saxena，Salim Sémaoune，Ryan Sepassi，Vitor Sessak，Jiri Simsa，Iain
    Smears，Xiaodan Song，Christina Sorokin，Michel Tessier，Wiktor Tomczak，Dustin Tran，Todd
    Wang，Pete Warden，Rich Washington，Martin Wicke，Edd Wilder-James，Sam Witteveen，Jason
    Zaman，Yuefeng Zhou，以及我的兄弟Sylvain。
- en: 'Last but not least, I am infinitely grateful to my beloved wife, Emmanuelle,
    and to our three wonderful children, Alexandre, Rémi, and Gabrielle, for encouraging
    me to work hard on this book. Their insatiable curiosity was priceless: explaining
    some of the most difficult concepts in this book to my wife and children helped
    me clarify my thoughts and directly improved many parts of it. Plus, they keep
    bringing me cookies and coffee, who could ask for more?'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我要无限感谢我亲爱的妻子Emmanuelle和我们三个美妙的孩子Alexandre、Rémi和Gabrielle，他们鼓励我努力完成这本书。他们无尽的好奇心是无价的：向妻子和孩子们解释这本书中一些最困难的概念帮助我澄清了思路，直接改进了许多部分。此外，他们还不断给我送来饼干和咖啡，还能要求什么呢？
- en: '^([1](preface01.html#idm45720219385120-marker)) Geoffrey E. Hinton et al.,
    “A Fast Learning Algorithm for Deep Belief Nets”, *Neural Computation* 18 (2006):
    1527–1554.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '^([1](preface01.html#idm45720219385120-marker)) Geoffrey E. Hinton等人，“深度信念网络的快速学习算法”，《神经计算》18
    (2006): 1527–1554。'
- en: ^([2](preface01.html#idm45720253720192-marker)) Despite the fact that Yann LeCun’s
    deep convolutional neural networks had worked well for image recognition since
    the 1990s, although they were not as general-purpose.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](preface01.html#idm45720253720192-marker)) 尽管Yann LeCun的深度卷积神经网络自上世纪90年代以来在图像识别方面表现良好，但它们并不是通用的。
