- en: 3 Getting started with Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creating containers for our project components using Docker and Docker Compose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing Docker containers and images for enhanced security and maintenance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing general Docker maintenance to ensure our containers and images
    do not eat up disk space
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using health checks to ensure the system is up and running
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the last chapter (or sprint, if we are thinking in Agile terms), we created
    a functional (albeit basic) ACH parser. We also experimented with generative AI
    tools to help us work faster and more efficiently. We have made some progress
    exploring tools and getting our bearing with ACH processing. Enjoy that feeling
    because there will surely be days when we log off the computer feeling completely
    drained.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have been given project requirements and a general framework
    of what a final project should contain. Of course, there are different approaches
    that we might take when working on a project, each having its pros and cons. While
    we may end up favoring one approach over others, there are always factors to consider
    when tackling a project, such as
  prefs: []
  type: TYPE_NORMAL
- en: How does the size and complexity of the project compare to our team’s experience
    and knowledge?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Have the project requirements been well defined, or is the business/customer
    still feeling the project out? How do the requirements compare to the time allotted
    for the project?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is our risk tolerance for items such as bugs, delays, new technologies,
    and similar?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do we have existing infrastructure for the project, such as testing environments
    and automated builds? If not, will we need to factor in building that infrastructure,
    or will that come later?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While the previous points may seem more pertinent when having more of a leadership
    role (technical lead, architect, etc.), it is beneficial to have everyone thinking
    about them because different perspectives are always useful. We just need to be
    careful that our feedback comes across as constructive and not as an attack on
    our co-workers (and we should be careful about when it is obvious any feedback
    will be ignored). Let us get back to our project at hand.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Where to begin
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, you may not have any choice in what you are able to work on. The business
    needs may dictate that you work on these pieces in this order. However, assuming
    you have a choice on where to start, what would you pick? You could start with
    a piece that you are comfortable with—perhaps you are a strong Python programmer,
    so you want to finish working on the ACH parser.
  prefs: []
  type: TYPE_NORMAL
- en: Or, maybe you should pick the thing you know the least. Maybe you have never
    worked with Next.js before, and you want to ensure you have enough time to devote
    to that part because you feel the other pieces won’t take much time.
  prefs: []
  type: TYPE_NORMAL
- en: We like to get started with the whole project! Well, not the whole project,
    but we like to see if we can get all the pieces talking to each other in some
    form. Even if it is the equivalent of a bunch of “Hello, World!” programs and
    components, at least we have the pieces together, and then we can pick them up,
    start building them, and let them evolve. It is really up to you—you could just
    as easily jump around to other chapters and get the various components up and
    running. This chapter focuses on getting a Docker setup and then putting our basic
    project components in place. Subsequent chapters will build on these components,
    but for now, we want to create an environment that looks similar to the one in
    figure 3.1.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, this environment will provide us with a UI container running
    Node and Next.js, an API container powered by FastAPI, and a database container
    running PostgreSQL. Running these inside Docker also allows the introduction of
    other
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a computer program  Description automatically generated](../Images/CH03_F01_Kardell.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1  An overview of our ACH system
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: components that we will explore in other chapters. While this project takes
    a more service-oriented approach to architecture, this general approach of using
    Docker to break our software down paves the way for other architecture patterns.
    The goal is not to make you an expert in Docker (check out *Docker in Action*
    [2019, Manning] by Jeff Nickoloff and Stephen Kuenzli if you want to become an
    expert) but rather to show you how to use it to explore different technologies
    and software without having to install and configure it on a host machine. It
    really helps you stay more organized.
  prefs: []
  type: TYPE_NORMAL
- en: Is the monolith dead?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Since we are using containers, and you may have heard about Microservices and
    how they are the latest and greatest, you might be tempted to run back to your
    company looking for any monolithic software and start insisting that they are
    doing it wrong. We would advise against that. Just because something is new does
    not necessarily mean it is better. Monolithic architecture can have its drawbacks,
    but there is no silver bullet when it comes to technology. Change for the sake
    of change is not only unnecessary—it can be detrimental to the software.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we suggest that if it is not broken, do not fix it. If there is monolithic
    software running at your company, it may continue to run for long after you have
    left the company. Only after identifying problems with the architecture should
    you look for alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: Monolithic architecture can also be very useful in developing proof of concepts,
    as you can bundle and deploy everything in one easy package. We believe everything
    has its time and place, so while we encourage forward thinking and engineering,
    remember that part of Agile is looking to deliver the right product at the right
    time. It just may not be the right time to explore moving to containers.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Creating a docker-compose.yml file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you have never worked with Docker before, you are in for a real treat. Docker
    allows us to create and distribute various containers. A container is sort of
    a mini-VM that you build in a declarative fashion and can be pulled in by others.
    If you are a Java programmer, think of your pom.xml and Maven, where you can basically
    describe your project and provide that file to someone else, so they can use it
    to have Maven pull the necessary files. Containers are similar, except they work
    on a larger scale. In figure 3.1, we showed a solution that has multiple containers
    running Nginx, FastAPI, and PostgreSQL. When working with a multicontainer application,
    we want to be able to manage everything from a centralized location, and that
    is where Docker Compose comes into play. We can declare a docker-compose.yml file
    and configure all the applications, containers, and services in one location.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are new to Docker, you might try to use Copilot, but our attempt did
    not yield any meaningful results. We tried to use the following command with Copilot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/Prompt-Icon.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The results of that prompt are shown in the following listing. Unfortunately,
    it did not produce any actual executable code.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.1  Failed attempt at a Docker setup
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We had much better results asking ChatGPT directly, as shown in the next listing,
    as it provided an actual compose file.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.2  docker-compose.yml generated by ChatGPT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#1 The version tag is obsolete, but even 3.7 was outdated when ChatGPT provided
    this answer; this is an example of the need to verify responses.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 ChatGPT gives us a nonstandard name of Dockerfile.fastapi; instead, we should
    use Dockerfile with no extension or fastapi.Dockerfile (see [https://mng](https://mng.bz/xKoB)
    [.bz/xKoB](https://mng.bz/xKoB) ); this is another example of the need to verify
    responses.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 These environment variables allow configuration for the Postgres database.'
  prefs: []
  type: TYPE_NORMAL
- en: These were good starts, but we need to back up a step so that we can break the
    code down and get something even shorter. Because we relied too heavily on generative
    AI, we started larger than we normally would, and that is a good lesson for us
    to take away. We spoke about the need for quick feedback loops and short cycles.
    It is never a good idea to change too much code in one session because when verifying
    our changes, we are unsure what actually addressed our problem. Therefore, asking
    generative AI to build four or five containers without a good understanding of
    what needs to happen was a bad idea.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have gotten a dose of reality and taken a step back, let us pick
    a single container to get up and running.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1 Creating a CloudBeaver container
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will start by building out a CloudBeaver container. CloudBeaver is a database
    management tool that supports multiple databases through a simple web-based user
    interface. There is no shortage of database management interfaces. You may also
    want to check out pgAdmin ([https://www.pgadmin.org/](https://www.pgadmin.org/))
    since we are working with a Postgres database or DataGrip by JetBrains ([https://www.jetbrains.com/datagrip/](https://www.jetbrains.com/datagrip/))
    since we’ll be using other JetBrains IDEs in this project. We do not have any
    vested interest in any particular product but are hoping to share what we have
    seen in use in FinTech.
  prefs: []
  type: TYPE_NORMAL
- en: We are installing CloudBeaver because we want another way to view and manage
    our database other than just using code. Your company probably has a preferred
    tool, and you can feel free to use it. However, CloudBeaver is simple to get up
    and running.
  prefs: []
  type: TYPE_NORMAL
- en: So, why are we setting up a database management tool before our database? That
    is a good question. Because CloudBeaver is a web interface, we will be able to
    confirm the container is up and running simply by opening a browser and navigating
    to a URL. So, CloudBeaver provides a quick and simple way to get started and verify
    our progress. Another option is to use our IDE, as IDEs often provide integration
    (or a plugin) to browse the database. Of course, using our IDE gets away from
    Docker, and we are looking to explore different containers with Docker.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that in mind, let’s get started by prompting ChatGPT:'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** Create just a basic Cloudbeaver service
    in Docker Compose.'
  prefs: []
  type: TYPE_NORMAL
- en: We receive the following output.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.3  Sample CloudBeaver container output from ChatGPT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '#1 The version tag is obsolete, but even 3. 1 was outdated when ChatGPT provided
    this answer; this is an example of the need to verify ChatGPT responses.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output looks plausible, but we see the version number is `3.1`. The latest
    Docker compose version was `3.8`, but now the `version` tag has been marked as
    obsolete by the project. While we can still specify it for the time being, using
    it will show a warning message. If it were ever to become an error, that would
    certainly pose a problem. So, we tell ChatGPT:'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** Update the basic setup to remove the
    Docker Compose version as it is now obsolete.'
  prefs: []
  type: TYPE_NORMAL
- en: With that, our file is updated. The ability to update output from our conversation
    is a powerful aspect of generative AI that we should keep in mind. Of course,
    we could have simply removed it from the produced file; however, we hope that
    our updated prompt will feed back into the system, and we will eventually stop
    getting the `version` tag as part of generated files.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can copy and paste the output from listing 3.3 into a docker-compose.yml
    file, navigate to the folder, and then issue the command `docker-compose` `up`.
    On our machine, it failed to do this because of the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This error is pretty straightforward, but remembering what you have running
    that might be using the port is not always straightforward. We could also update
    our docker-compose file to use a different port, but at this point, we can find
    the offending process on Windows PowerShell by using `netstat` `-aon` `|` `findstr`
    `"8080"` and then `tasklist` `|` `findstr` `PID` where PID are the process IDs
    that we just came across (which are on the right-hand side). Once you do that,
    you can either determine whether you want to shut down/stop whatever program you
    have running or adjust the port being used. In our case, another Docker container
    was being used, so it was safe to shut down. At this point, running `docker-compose`
    `up` works, and we can navigate to http://localhost:8080/ and see a web interface
    shown in figure 3.2.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated](../Images/CH03_F02_Kardell.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2  CloudBeaver welcome screen
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 3.2.2 Create a PostgreSQL container
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Things will get a little more interesting now because we get to add a database
    container. Eventually, the database will store our ACH files and associated data,
    but for now, we will keep things simple. We can also populate the database with
    data when the container starts, so that we can use CloudBeaver to connect to the
    database and view our data. We can ask ChatGPT to simply
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** Update the docker-compose file to also
    include a `postgres` service.'
  prefs: []
  type: TYPE_NORMAL
- en: Again, that created a helpful starting point, shown in the next listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.4  Multiple containers generated by ChatGPT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: However, let’s take a step back and build a simpler file, which will serve us
    better at this time because we are still trying to adhere to the principle of
    YAGNI (“You aren’t going to need it”) as much as possible. Some purists might
    argue that even creating these Docker containers violates that principle. We do
    not strictly need any of this for our project at this point—we may not even need
    a database. Perhaps, we could get away with just writing to a file or keeping
    things in memory! That could certainly be true, but we could also look at this
    as the existing code because our application is built on PostgreSQL and so that
    is going to be a requirement regardless of whether we really need it.
  prefs: []
  type: TYPE_NORMAL
- en: What is YAGNI?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: YAGNI is an acronym for “You aren’t going to need it.” It is a principle of
    extreme programming and ties back to our Agile principles, such as minimum viable
    product (MVP), by trying to enforce the idea of avoiding unnecessary work and
    complexity. Sometimes, when coding, it is hard to resist adding that extra function
    that you’re pretty sure you will need later, so you might as well code it now.
    Then, that code never gets used but is flagged by static code analysis for fixes
    and requires changes when you update some object.
  prefs: []
  type: TYPE_NORMAL
- en: So, if nothing else, just keep the principle in mind to avoid that extra complexity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go back to building our container. We add a simple container with the
    following (you can view the whole file in the provided v2/docker folder on GitHub
    for this chapter):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: With this, we can navigate to CloudBeaver with http://localhost:8080 and set
    up a connection; however, we do not have any data to view. We want to be able
    to load some data when the container is built, so we will look into doing that
    now. Note that we removed the networking and volume fields from the generated
    Dockerfile because we are going to rely on the networking that is set up by Docker.
    By default, all the containers defined with our docker-compose file under services
    will be able to communicate with each other. Also, we are not interested in persisting
    data in this project (at least for now), so we removed the volumes tag. This gives
    us a simple starting point.
  prefs: []
  type: TYPE_NORMAL
- en: To add some data, we will create a SQL script that executes when the container
    is first built. We start off by creating a `health_check` table. This table could
    be used to determine whether our application is in a valid state. For us, it is
    more of a “Hello, World!” scenario than anything meaningful.
  prefs: []
  type: TYPE_NORMAL
- en: Health checks
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Because our application will be spread across a number of containers, it is
    often useful to create a health check. It is a common pattern to follow when using
    microservices. Even though we have started by initially creating a database table
    named `health_check`, this is just the beginning.
  prefs: []
  type: TYPE_NORMAL
- en: Docker allows us to create a health check for the container within our setup,
    which we will explore later. This test can determine whether the container is
    “unhealthy.” When using a container orchestration tool such as Kubernetes, these
    health status checks can trigger alerts to admins, as well as automatically restart
    containers.
  prefs: []
  type: TYPE_NORMAL
- en: Tools such as Kubernetes also have expanded these checks to differentiate between
    the app being unavailable because it is initializing and because something crashed.
    These are referred to as “readiness” and “liveness,” respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have a little more robust container, we will be working with four
    `docker-compose` commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker-compose` `build`—We use this command when we need to build the container
    as specified in the Dockerfile. Any updates to files/scripts that we are including
    in the container will require us to issue this command.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker-compose` `up`—This command is used when we need to start our containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker-compose` `stop`—We use this command when we want to stop our container
    and leave the data in place. While important, we will typically use the `down`
    argument because we will rely on our initialization scripts to populate the database
    and start with a fresh database each time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker-compose` `down`—This command is used when we need to stop and remove
    the containers. We use it to make changes to any of our initialization scripts
    because the initialization will not occur when the database exists.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll require these commands as we make changes to our Dockerfiles. Usually,
    for development, we just chain them together as `docker-compose` `down` `&&` `docker-compose`
    `build` `&&` `docker-compose` `up`. You can even slim the command down to `docker-compose`
    `down` `&&` `docker-compose` `up` `--build`.
  prefs: []
  type: TYPE_NORMAL
- en: Initially creating our containers may take a bit of time, but the process will
    be significantly faster when making small incremental changes. We should now be
    able to view our table and its data through CloudBeaver.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.3 API container
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our next container expands on our container experience by building a container
    for our APIs. Soon, we will begin to build out specific APIs for dealing with
    ACH files, but for now, we will keep things very basic. We want to make use of
    the FastAPI framework for running our APIs in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will create a Python container from the standard Docker Python image (an
    image in Docker is a standard read-only template used to create a container) and
    install FastAPI and some dependencies on top. In our previous containers, we worked
    directly in the docker-compose file to create our containers. With this container,
    we will create a Dockerfile that will be referenced by the docker-compose file.
    To store the dependencies and configuration of the image, we need to introduce
    a few new commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '`FROM`—Specifies a base image to start building the image from.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`COPY`—Copies directories/files from the local machine to the image. In the
    upcoming section, we will create a requirements.txt that will need to be copied
    to the image that contains FastAPI, among other things.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RUN`—Executes a command in the image during the build process. We will execute
    `pip` to install the required Python packages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CMD`—Specifies a default command to run when the container starts. We will
    use this command to run Uvicorn, which is an Asynchronous Server Gateway Interface
    (ASGI) that we need to run FastAPI.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As mentioned, we are using the `FROM` command to declare a base image to build
    from. Docker will default to the latest if you do not specify anything, but you
    can also specify a particular image tag. Specifying a tag can be useful for various
    reasons, especially if you want to lock the image to a particular version. We
    will use the `latest` for our images because we consider this a development project
    that would not be immediately pushed to production.
  prefs: []
  type: TYPE_NORMAL
- en: What do we mean by a development project? We just mean that in a production
    environment, more care is needed when changing the software version. You may have
    deprecated features, and there may be bugs or vulnerabilities that you should
    be aware of. These are all considerations that you need to weigh before changing
    the version. In this instance, we pick the latest version of Python when building
    our container. In a production environment, you would want to control that upgrade
    by running it through your test suite and ensuring no incompatibilities exist.
  prefs: []
  type: TYPE_NORMAL
- en: These concerns about the containers’ version also extend to the application
    itself. This container installs FastAPI on top of the Python container, so we
    have a requirements.txt file to take care of that. We have chosen to just install
    the latest packages for this example; however, we encourage you to look at locking
    in a particular version and other requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Python requirements.txt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Our example uses the package name without any type of versioning. However, there
    are better safety measures that you can take advantage of, such as
  prefs: []
  type: TYPE_NORMAL
- en: '*Specifying the exact versio**n*—`package``==``1.0.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*A version rang**e*—`package>=1.0.0,<2.0.0`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Exclude a versio**n*—`package!=1.0.5`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*A version combined with a Python version*—`package==1.1.0;``python_version``<``''3.10''`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also install from version control systems, URLs, and local files.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you can create a requirements.txt for your project by using `pip` `freeze`
    `>` `requirements.txt`.
  prefs: []
  type: TYPE_NORMAL
- en: You should be able to use the standard `docker-compose` `build` and `docker-compose
    up` commands to build and bring the containers online. Depending on the ports
    that you used (`8000` for us), you should be able to navigate to the APIs with
    http://localhost:8000/ and then see the output `{"message":"Hello` `World!"}`,
    which is still pretty cool although not doing much.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.4 Web server container
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The final piece of our container puzzle that we are looking into is a web interface.
    The plan is to provide a dashboard with which we can upload and view ACH files.
    Again, for now, we are just going to build a simple page to ensure everything
    is working. For this container, we will be building our application on top of
    Nginx. While a large number of existing infrastructures run Apache for a web Server,
    Nginx has had a slightly larger market share for the past few years.
  prefs: []
  type: TYPE_NORMAL
- en: This container builds on some of the concepts we explored before, such as building
    a container using a base image. In addition, you will likely want to manage the
    ports from the docker-compose file. Previously, we specified ports such as `8000:8000`,
    which gave both the host and container ports, respectively. By default, Nginx
    will be listening on `port` `80`, and while we could update its configuration
    file to define a different port to listen on, we can take this opportunity to
    introduce configuring the ports in Docker. Suppose we want to be able to keep
    the default port for Nginx and just give a different port to the web browser.
    For instance, let us say we want to be able to navigate to http://localhost:3000/hello.xhtml
    to access our sample web page. We can do that by specifying `3000:80` and then
    starting our containers.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we have set all the containers we are going to need so far, but
    we haven’t ensured they are talking to each other.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Connecting our containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now, let’s go back to getting our containers to communicate. We would like to
    make sure that our containers can interact. Our use case is simple to start with,
    but it lays the groundwork for expanding our project. We would like to be able
    to access a web page that uses the API layer to access our `health_check` database
    table. This table is not necessarily changing at this point, but we can manually
    adjust it and see the results. It will be a nice first step in ensuring that everything
    is functioning as expected.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned earlier, ports can pose a problem, not only from a security perspective
    but just remembering which ports you have chosen. So, let us make a list of our
    containers and the ports we are using.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.1 Container port listing
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Container name | Host port | Internal port |'
  prefs: []
  type: TYPE_TB
- en: '| CloudBeaver | `8080` | `8080` |'
  prefs: []
  type: TYPE_TB
- en: '| Postgres | `-` | `5432` |'
  prefs: []
  type: TYPE_TB
- en: '| Api | `8000` | `8000` |'
  prefs: []
  type: TYPE_TB
- en: '| Web | `3000` | `80` |'
  prefs: []
  type: TYPE_TB
- en: 3.3.1 Connecting to the database
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our first step is to have the API container connected to the database and grab
    the result from the table. At this point, we are only looking to get the plumbing
    sorted out, so we are not going to look at writing a unit test yet. We will be
    able to easily test this ourselves as we build out the sample. First, we will
    focus on updating our API layer to connect to the database and return our given
    status.
  prefs: []
  type: TYPE_NORMAL
- en: We start by updating our requirements.txt to include `psycopg[c]` to support
    connecting to the database.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.5  Our updated requirements.txt
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `psycopg[c]` is a production appropriate approach but also requires updating
    our Dockerfile to include additional dependencies. You should now be able to access
    http://localhost:8000/health/status to view the status. If everything went okay,
    you should see `[{"id":1,"status":"OK"}]`. If not, you can jump down to section
    3.2.2, which discusses some common problems you may encounter.
  prefs: []
  type: TYPE_NORMAL
- en: We have a few things to think about now that we have updated this code. Our
    `health_check` table is currently built to have a sequential ID and a status,
    and we decided to return all our records in this example. You can experiment with
    this by going into CloudBeaver (http://localhost:8080), clicking the `SQL` command,
    and inserting another record with `INSERT` `INTO` `health_check` `VALUES(DEFAULT,`
    `'testing')`. It is not necessary to capitalize the SQL statements, but we find
    that doing so helps keep the code more readable when dealing with SQL intermingled
    with other code. After inserting the record, you will find that navigating back
    to the health/status endpoint will return all records. So, you should see something
    similar to `[{"id":1,"status":"OK"},{"id":2,"status":"testing"}]`. Later, we can
    review and explore ways to address this. Keep in mind that we wanted to provide
    the health of the current system but that we are not doing anything to update
    that table at this time.
  prefs: []
  type: TYPE_NORMAL
- en: Exposed ports and internal networks
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When specifying our connection string, we selected `port` `5432`. You can also
    see that the `postgres` container is listening on `5432` as there should be a
    log message saying `listening` `on` `IPv4 address 0.0.0.0,` `port` `5432`. However,
    our list of ports shows we did not specify it, so what gives?
  prefs: []
  type: TYPE_NORMAL
- en: Because we are using Docker Compose, one of the benefits is the creation of
    an internal network. This allows the containers to talk to each other as if they
    were on the same network. In our case, the above ports were only for the host
    system. If we wanted to write scripts or browse the database using tools installed
    on our desktop, then we could have exposed `port` `5432`.
  prefs: []
  type: TYPE_NORMAL
- en: Why can we use CloudBeaver to view the SQL data? Well, that is because we exposed
    the `8080` `port` for CloudBeaver which we can browse with our web browser. So,
    we are communicating externally with CloudBeaver, but CloudBeaver can use the
    internal network to hit `port` `5432`.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.2 Troubleshooting PostgreSQL and FastAPI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is entirely likely that things did not go as expected when setting up your
    container or that things will not go as intended when setting up other containers.
    When starting the containers with `docker-compose` `up`, be sure to keep an eye
    on the logs as you may frequently see a meaningful error message. Also note that
    you may need to scroll back because an earlier container failed, and others are
    running after it, or an error/warning message was just lost in the shuffle. The
    following are some of the more common errors you may get in the scenario of a
    container not starting.
  prefs: []
  type: TYPE_NORMAL
- en: We are trying to make a connection from one container to another, so you may
    see a message on the console similar to  `Is` `the` `server` `running` `on` `that`
    `host` `and` `accepting` `TCP/IP` `connections?`  This message could mean that
    the container failed to start, and since it is connecting from our FastAPI code
    to the database, there may be a syntax error in our code that prevented the container
    from starting. This error could be a typo in our code or could result from dependencies
    that we failed to include. If the code is syntactically correct, check the requirements.txt
    and Dockerfile to ensure that all requirements are being installed.
  prefs: []
  type: TYPE_NORMAL
- en: The error `connection` `to` `server` `at` `"localhost"` `(::1),` `port` `5432`
    `failed:` `Cannot` `assign` `requested` `address` is another one we can run into.
    This error is common because many examples may refer to `localhost`, and it may
    be easy to mistakenly use localhost instead of the name/address of the container.
    You may also assume that since we are running on our computer, you can use `localhost`.
    Remember, though, that we are running in a container. We should specify the name
    of the container in our connection string rather than `localhost`.
  prefs: []
  type: TYPE_NORMAL
- en: The error `psycopg.OperationalError:` `connection` `failed:` `FATAL:` `password
    authentication` `failed` `for` `user` `"postgres"` can occur when you have an
    invalid user or password specified. Look at the Dockerfile and docker-compose.yml
    to ensure you have the correct username and password. Remember that at this point,
    we have defined the username and password in our docker-compose file when setting
    up the database container, but we also had to hardcode it into our Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Another error we may encounter, especially when generative AI is helping, is
    a `NameError`. A `NameError` is raised when a local or global name is not found,
    meaning we tried to use a variable, function, or module that has either not been
    defined or is not accessible in the current scope. We encountered the error `NameError:`
    `name` `'status'` `is` `not` `defined` when working through the code ourselves
    because we were not paying close attention to the code generative AI suggested.
    The variable `status` was populated by Copilot even though that was not the name
    of the variable we used. So, this amounted to a simple syntax error, and we had
    to return the right value.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Calling our API
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, we should be able to confirm that the API has access to the database
    container. We have one more jump that we would like to make—we want to be able
    to create a web page that will access the API. Although we have already seen that
    we can access the API in our browser, we were able to get away with testing that
    way because our REST API was using a `GET` request, which is the same request
    used to retrieve web pages. Later, when using some of the other HTTP verbs such
    as `POST`, `PUT`, and `DELETE`, we will not be able to test in this fashion. Furthermore,
    we will be looking to build the UI, so we need to ensure connectivity between
    the web and API containers.
  prefs: []
  type: TYPE_NORMAL
- en: We will create a simple web page that incorporates d3.js to display our results.
    In our case, we do not need anything fancy, so we will just create a list of the
    results. If you are not familiar with HTML or d3.js, this would be a wonderful
    time to see whether our generative AI tool could help you get started.
  prefs: []
  type: TYPE_NORMAL
- en: We prompted ChatGPT (GPT-40) with
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** Create a simple d3.js webpage that
    calls an API.'
  prefs: []
  type: TYPE_NORMAL
- en: It produced an example visible in `chat_gpt_example.xhtml`.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.6  Sample page produced by ChatGPT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This response gives us a great starting point, and with a few tweaks, we have
    a workable solution for our initial needs.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.7  Updated sample page
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '#1 We start by giving our page a title and importing d3.js.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Creates a heading and updates the ID to be more meaningful for our purposes'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Accesses the API endpoint for the status check'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Updates the select statement and text fields (ID and text) so that we are
    writing out the expected data'
  prefs: []
  type: TYPE_NORMAL
- en: In addition to customizing the output for our specific need, we had to bump
    up the version of d3.js to the current level. This is a reoccurring theme when
    working with generative AI; depending on the model and training data, the latest
    software may not always be included. It is a good idea to quickly double-check
    all software release levels just to confirm you are running an appropriate version.
  prefs: []
  type: TYPE_NORMAL
- en: The most important customization that we had to make was pointing the page to
    the correct API URL. You can refer to the port listing we made earlier; do you
    have any ideas what that URL will look like? You may have been tripped up by the
    previous example of connecting the database and API containers where we had to
    specify the container name. In that example, we were internal to Docker. Now,
    our web page is external, so we want to access it from the outside and thus use
    localhost with `port` `8000`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Testing access gives us a CORS (cross-origin resource sharing) error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: CORS
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: CORS, which is better known as the bane of getting things done quickly, is one
    of the more common problems you will run into. CORS stands for cross-origin resource
    sharing and is a security mechanism that allows servers to specify controls over
    which resources are shared with external callers.
  prefs: []
  type: TYPE_NORMAL
- en: CORS provides the idea of simple requests and preflight requests. We are not
    really concerned with simple requests because preflight requests are the ones
    that trigger CORS exceptions. To work around these exceptions, we will need to
    configure our server to ensure some specific headers dealing with CORS are sent
    back.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following headers need to be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Access-Control-Allow-Origin`—Specifies which sites are allowed to access the
    resource. We can use a wildcard `*`, but this can pose a potential security risk.
    Remember, the principle of least privilege? Start with a more focused origin and
    only broaden it as necessary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Access-Control-Allow-Methods`—Specifies which HTTP methods are allowed. Again,
    you can use wildcards but should only use what is necessary. In our example, we
    are only using `GET` so that is the only one we really need. Later, we will be
    using more requests, but we recommend keeping it as `GET` for now and not updating
    it to use HTTP methods we have not yet defined, so that CORS will complain again
    later as it provides good troubleshooting practice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Access-Control-Allow-Headers`—Allows the server to specify what headers can
    be used for the request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Access-Control-Allow-Credentials`—Indicates whether the browser should include
    credentials for requests. If you have authenticated requests or need to maintain
    state with cookies, or otherwise have requests that include sensitive information,
    set this to `true`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To correct this error, our API layer needs to be updated with the following.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.8  Incorporating CORS into our API
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '#1 We import the CORSMiddleware from fastapi.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The origins are where we expect to receive requests from; we create this
    as a separate variable because we expect to update it a few times.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 We pass all the parameters here; allow_methods and allow_headers are an
    integral part of securing our API.'
  prefs: []
  type: TYPE_NORMAL
- en: Notice how we tried to keep the origins and methods narrow. In other words,
    we limited the allowed origins and methods to only what we need for now. Resist
    the urge to future-proof the code by using wildcards and more methods than you
    currently have/need. This is because when it comes to security, we want to keep
    it locked down. We wanted to say “Less is more” but did not want anyone coming
    back to us saying that they were hacked because they had less security! We mean
    that less access is better!
  prefs: []
  type: TYPE_NORMAL
- en: With the CORS updates in place, you should be able to build the containers and
    bring Docker back up. Hopefully, you can now navigate to http://localhost:3000/health.xhtml
    and see some results. You should be able to again go back into Cloud­Beaver and
    enter additional records in the `health_check` table, which will be displayed
    when you refresh the web page.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.1 Troubleshooting our web site
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The main problem you are likely to encounter is the error that we discussed
    before—the CORS error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As previously mentioned, this security-related error is easy to work around
    if you choose to just allow everything. We would caution against this approach
    as you should maintain some security. Often, your APIs may have a level of redirection
    built in as they may go through other tools such as WSO2 API Manager (which we
    discuss in chapter 4). In this case, you may want to just specify that middle
    layer in your CORS configuration. Or, you may want to limit HTTP requests. Again,
    the idea is that if you do not need it, then you should not have it.
  prefs: []
  type: TYPE_NORMAL
- en: An `ERR_SSL_PROTOCOL_ERROR` may occur if you are using HTTPS and the API was
    only listening on HTTP. You may see an error on your web browser console such
    as `Failed` `to` `load` `resource:` `net::ERR_SSL_PROTOCOL_ERROR`. For now, we
    are using HTTP and not HTTPS because we did not want to introduce additional complications
    with certificates. However, we will work on expanding this later in our project.
  prefs: []
  type: TYPE_NORMAL
- en: You may encounter a `404` `error` from d3.js such as `d3.v7.min.js:2` `Uncaught`
    `(in promise)` `Error:` `404 Not` `Found`. This is usually going to be a typo
    in your API endpoint. Another reason could be using the wrong HTTP method (`GET`
    when you need `POST`), although it is more common to see a `405` `Method` `Not`
    `Allowed.` We have seen some frameworks use the `404` error code as well. Other
    problems also exist, but we start exceeding the scope of this book as they start
    getting into server and network configurations. So, you will need more assistance
    if you have eliminated these basic reasons.
  prefs: []
  type: TYPE_NORMAL
- en: We mention this here although it could happen at any time. If Docker is not
    running, then you may get errors building and starting your project. Seeing an
    error such as `error` `during` `connect:` `this` `error` `may` `indicate` `that`
    `the` `docker` `daemon` `is` `not running` is an obvious message that you do not
    have Docker running. However, we are likely to make that mistake at least a couple
    of times, so it is best to address it now.
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Container security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hopefully, you have an idea of how cool working with containers can be. Yes,
    our application has inherited some complexity but that is a tradeoff for some
    of the benefits of using this type of architecture.
  prefs: []
  type: TYPE_NORMAL
- en: We also inherit some security risk as part of this convenience. When we build
    a container using an image, even an official image can have risks associated with
    it. These come in the form of security vulnerabilities included in the package.
    It is important to understand these problems as they could be serious exploits
    in a version of the image or packages you are using. Some images are complex,
    and it may not be apparent what is actually included in a particular image. That
    is where tools such as Snyk and Docker Scout come into play. They can scan your
    containers and report on vulnerabilities in any of the images or included packages.
  prefs: []
  type: TYPE_NORMAL
- en: Snyk offers a command-line-scanning tool that creates an inventory of our Docker
    containers (figure 3.3). We can then use their web site to view scans and fix
    potential problems. When new problems are discovered in one of our containers,
    we will be automatically alerted so that we can begin fixing them immediately
    (if necessary).
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated](../Images/CH03_F03_Kardell.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3  Sample results generated by Snyk
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Another aspect to pay attention to is port numbers used both within the containers
    and exposed to the world. We can see ports available using `docker` `ps`. When
    configuring containers, it may be helpful to allow ports to be set dynamically.
    For instance, our `api` `host` `port` could be set with `${API_PORT:-8080}:80`,
    which would allow us to default to `port` `8080` unless `API_PORT` has been defined,
    in which case that would take precedence.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are numerous options within Docker to help secure containers, and we
    will briefly touch on some and their application:'
  prefs: []
  type: TYPE_NORMAL
- en: '`--read-only`—It marks a container as read-only, which can help limit malicious
    activity in the event of an attacker gaining access to the container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--memory` and `–cpu`—There are multiple configuration options around memory
    and CPU. These can configure how many resources are available to a container from
    the host system. Preventing a container from eating up too much of a resource
    is important to the overall health of the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--no-new-privileges`—It prevents the application from gaining any new privileges.
    This means Docker will prevent you from executing scripts and commands that would
    give you root privileges. The idea again is to keep malicious code and users contained.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The principles of least privilege and defense in depth
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A common notion in security is known as the principle of least privilege (PoLP).
    We try to use minimal access or only the necessary permissions to complete our
    work, elevating those permissions only when necessary and then reverting to our
    original state. Ideally, even administrators or those with root access are not
    using it as their default sign-on. It is easier to grant users everything or higher
    permissions, but if their account is compromised, then the attacker has that same
    access. Perhaps, even more common is a user just making a typo or not paying attention
    to the system or directory they are in, and causing damage by removing unintended
    files. We have heard more than one story of a script being run as root that brought
    down the system. Or someone may be doing `rm *` in the wrong directory and crashing
    the system!
  prefs: []
  type: TYPE_NORMAL
- en: “Defense in depth” or “security in layers” is another security practice that
    you will be implementing, regardless of your role in an organization. It simply
    refers to the broad range of security practices put in place to protect an organization
    from physical security to network security to application security. As a developer,
    you are likely going to be involved in the application-level security. This will
    also expand into data security and access management, as you will need to encrypt
    and mask data, as well as authenticate and authorize users to the system.
  prefs: []
  type: TYPE_NORMAL
- en: If you are part of a large organization, the managing and security of containers
    may not be your area, especially if you are working in a software developer role.
    In a smaller company, you may be wearing multiple hats, and having some knowledge
    of these concepts will be useful. In our case, we are using containers to play
    around with our development project, and we just need to understand the CliffsNotes.
    However, security is a major consideration in all organizations, and understanding
    some of the basics will not only help you be a better developer but will also
    give you a different perspective when that next annoying request comes from the
    security team. If you want to explore Docker security further, check out the OWASP
    Docker Security Cheat Sheet ([https://mng.bz/nR8K](https://mng.bz/nR8K)).
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Optimizing Docker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Docker is great, especially if you are a developer. There are tons of Docker
    images that you can use to explore different technologies and tools without the
    need to install them on your machine (other than with the Docker image). So, you
    no longer need to clutter up your personal machine with a bunch of software that
    you later forget about. Of course, this convenience is not without some drawbacks.
    For instance, if you have started all the Docker projects bundled with this chapter,
    you may have a lot of wasted space as Docker created containers, images, and volumes
    for each, which is why we are just going to take a little bit of a dive into managing
    and optimizing Docker.
  prefs: []
  type: TYPE_NORMAL
- en: So, why optimize? When we look at optimizing Docker, we are primarily speaking
    about removing unnecessary components and perhaps building them out from a different
    image. By reducing the components, we can usually achieve better security, faster
    deployment, and potentially run-time improvements. As developers, we may haphazardly
    pull in images with little regard for what they are built on. After all, we usually
    try to get to our work, but for now, let us see what things look like under the
    hood.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.1 General maintenance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, we run the command `docker image ls`. It will show us the images and
    their sizes. Here is a sample output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The first thing you should notice is that we have a bunch of repositories with
    `<none>`. These are known as dangling images and can appear when we are building/rebuilding
    our project. We may have brought some of these on ourselves simply by working
    in our development environment and continually building our containers as we modify
    our project. Another common reason is using the `latest` tag. We had previously
    chosen to use the `latest` tag because we always wanted the latest project. Now
    we could be paying a price for that decision. In our current environment, we personally
    are not overly concerned about this, but in a production environment, where we
    had a specific project we were building, we would ensure we had tagged our project
    to a specific level.
  prefs: []
  type: TYPE_NORMAL
- en: 'To clean up these dangling images, we can issue the following `prune` command.
    With all the prerequisite warnings about being careful when removing things, we
    issue `docker` `image` `prune` and are prompted to confirm we want to continue.
    Then, several images are removed, and we then do `docker` `image` `ls` to see
    what is left:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Then, we take a look at what is left over, and we see we have previous images
    out there that we presumably do not care about (`dockercompose6-api` and `dockercompose6-web`).
    We can confirm they are not in use by any (either running or not) containers by
    issuing `docker` `ps` `-a` `--filter ancestor=dockercompose6-api:latest`. This
    code will return the status of the container. When nothing is returned, it can
    be safely deleted.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.2 Optimizing image size
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have done some general clean-up, it may be a little easier to review
    our images. We can start again by taking a look at the current images with `docker`
    `image` `ls`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Our biggest image is the `dockercompose7-api` image at 1.09 GB.
  prefs: []
  type: TYPE_NORMAL
- en: One way we can reduce image size is checking whether the particular Docker image
    supports Alpine Linux. Alpine Linux is a lightweight version of Linux focusing
    on security, which makes it a good fit for use within Docker.
  prefs: []
  type: TYPE_NORMAL
- en: Postgres went from 417 MB to 239 MB just by switching the image, and the web
    went from 187 MB to 42.6 MB. Unfortunately, we cannot simply switch to Alpine
    for our biggest container, the API layer that currently sits at 1.09 GB. This
    is because we are running `apt-get` in our Dockerfile, and this is not supported
    by Alpine since it is not based on Debian. We can take a shortcut and use the
    `slim` tag. By specifying `slim` instead of `alpine`, we do not need to change
    our Dockerfile and end up with an image that is about half the size, at 557 MB.
  prefs: []
  type: TYPE_NORMAL
- en: Slim vs. alpine
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: So, what exactly is the difference between the `slim` and `alpine` tags? Both
    are typically smaller than a standard image, with `alpine` images typically being
    even smaller than `slim` images.
  prefs: []
  type: TYPE_NORMAL
- en: As the name implies, `slim` images are minimized versions of the standard images,
    removing nonessential components such as documentation and development libraries
    but leaving the core functionality intact. Remember, these containers are specifically
    designed for running whatever you have put in them. They are not meant for people
    to be logged in and cruising around, so we do not need things such as man pages
    for documentation.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, Alpine focuses on security, and it is based on the `musl` `libc`
    library and BusyBox. These can cause problems with other software and libraries
    that you may be installing. As we saw, we had to update our Dockerfile to take
    advantage of Alpine with some minor changes. Of course, for larger projects, more
    extensive testing would be needed to ensure everything is working.
  prefs: []
  type: TYPE_NORMAL
- en: We can look into reducing the image even further if we want to pursue using
    Alpine for the API layer. We will need to update the Dockerfile to use the Alpine
    Package Keeper (`apk`) instead of `apt-get` to install the needed packages. Your
    mileage may vary depending on your project and what exactly needs to be installed.
    In this case, removing the `RUN` `apt-get` line and replacing it with
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: allowed us to successfully get the project up and running again. This reduced
    the image size for another 200 MB, bringing it down from 557 MB to 344 MB—quite
    a difference from the original 1GB!
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a smaller base image in your Dockerfile is one of the most straightforward
    ways of reducing the image size. One of the mantras of development is “Make it
    work, make it right, make it fast.” That approach works for containers as well.
    There are benefits of smaller image size, but you do not need to worry about that
    right at the beginning of your project. When working with a big company, there
    will likely be a whole team that takes care of this for you, so you may not have
    a lot of flexibility when it comes to building and running containers.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.3 Optimizing build time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A task that can go hand in hand with optimizing image size is also working on
    the actual build time. Several tools are available for analyzing Docker images.
    Two popular tools are Docker Scout and dive, which is a command-line tool. Let
    us look at running the Docker Scout utility because it is readily available within
    Docker Desktop. This discussion also provides a good introduction to some of the
    metrics and terms that get thrown around when using Docker. Figure 3.4 shows the
    results of analyzing our API image. This screen is from the personal (free) tier
    of using Docker and Docker Scout. More features are available for the paid tiers
    ([https://www.docker.com/pricing/](https://www.docker.com/pricing/)).
  prefs: []
  type: TYPE_NORMAL
- en: The layers are what we are primarily interested in when considering ways to
    optimize the build. In a Dockerfile, the order of instructions matters, and each
    instruction translates into a layer, although there is not always a one-to-one
    correspondence. We can see the size of each layer and the command being executed.
    We can also see how the filesystem is affected by each of the commands.
  prefs: []
  type: TYPE_NORMAL
- en: One way to optimize the builds is to ensure we are managing the layers appropriately.
    Layers should be kept to a minimum, and any adding/removing of files should happen
    in the same layer. For instance, a command that may download temporary files should
    also be cleaned up.
  prefs: []
  type: TYPE_NORMAL
- en: We also mentioned that the order of instructions in a Dockerfile matters because
    Docker uses a caching mechanism to determine if a command needs to be rerun. Therefore,
    items that change frequently, such as your application code, are usually near
    the bottom of the instructions, while less frequent changes or changes that may
    cause a large download are executed near the top. Doing this in reverse order
    is known as
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated](../Images/CH03_F04_Kardell.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4  Analysis with Docker Scout
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: cache busting because it breaks Docker’s cache mechanism and can cause Docker
    to rebuild the entire image every time.
  prefs: []
  type: TYPE_NORMAL
- en: Docker squash is another tool that can help with removing layers and other unused
    files. A few different versions of this utility and also an experimental command
    within Docker itself for this functionality can be found on the internet.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is also a `.`dockerignore file that functions similar to a .gitignore
    file (if you are familiar with Git). Otherwise, the concept is simple: we can
    put files or directories into these ignore files, and Docker will ignore them.
    So, maybe unnecessary configuration files from your IDE, other application related
    information, and documentation such as READMEs are all good candidates for these
    files.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, general application maintenance can go a long way, ensuring that dependencies
    are up to date and that you have minimized CSS, JavaScript, and so forth to keep
    the images small.
  prefs: []
  type: TYPE_NORMAL
- en: 3.7 Removing the hardcoded username/password
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have covered some of the maintenance aspects of working with Docker
    and Docker images, let us take our advice from earlier and work with the application.
    One thing that we had to do was specify a username and password for the PostgreSQL
    instance (remember the `POSTGRES_USER` and `POSTGRES_PASSWORD` from our docker
  prefs: []
  type: TYPE_NORMAL
- en: -compose file).
  prefs: []
  type: TYPE_NORMAL
- en: We were able to do this with environment variables; however, when it came to
    the API container, we hardcoded the values, and that is something we always want
    to avoid if possible.
  prefs: []
  type: TYPE_NORMAL
- en: Avoid magic numbers and hardcoded values
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Magic numbers have unexplained meanings, such as when we define a log level
    of 1, 2, 3, 4, or 5\. Which one is the highest severity? What does it mean to
    have a log level of 1 versus a log level of 4? That is an example of a magic number.
  prefs: []
  type: TYPE_NORMAL
- en: We consider hardcoded values to be a superset of magic numbers as they come
    with a similar set of problems. Any time we start using hardcoded values such
    as usernames/passwords, ports, servers, and similar, it poses a problem. Not only
    can it be a security concern to have them stored insecurely in source control
    but can also pose a maintenance nightmare when they are sprinkled throughout the
    code, and your server moves after 10 years. Finding all those places and testing
    that everything was changed correctly can be a real pain.
  prefs: []
  type: TYPE_NORMAL
- en: Even though we have yet to examine the application, we will practice good habits
    by removing our hardcoded values.
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, Docker comes with a way for us to make use of environment variables
    by applying an `env_file` directive that specifies an environment file. As a bonus,
    we can refer to the `gitignore` command to prevent this file from being uploaded
    to source control. Or maybe there is another layer of redirection where the more
    sensitive information (the database credentials) is referenced and stored somewhere
    else. If you are not storing the environment variables in source control, be sure
    that they are well documented somewhere so that new instances, or new employees,
    know how to set them up. Often, we have found ourselves having someone email us
    random configuration files because nobody is sure how to set up the system and
    what exactly is still needed!
  prefs: []
  type: TYPE_NORMAL
- en: The first order of business is to create a file to hold our environment variables.
    We will need to create a file named `.`sql_server.conf. The actual name of the
    file is not important but should be something meaningful. The leading period (.)
    will often cause the operating system to hide the file and an extension “conf”
    is a standard for configuration files. Another common naming standard is to use
    .env. We often see .env files being used in companies, especially when there are
    source control tools such as Git, which are usually set to ignore .env files.
    Another example form the Docker documentation available at [https://mng.bz/vK5M](https://mng.bz/vK5M)
    shows the use of an environment file named webapp.env when defining their webapp
    service.
  prefs: []
  type: TYPE_NORMAL
- en: The main thing to remember is that the naming of the file is flexible, and neither
    a specific name nor leading period are required for them to work. However, we
    are simply establishing a convention, and that may be slightly different from
    the standards and conventions in place at other companies (remember the saying,
    “When in Rome . . .”).
  prefs: []
  type: TYPE_NORMAL
- en: With the file created, we will move our hardcoded username and password denoted
    by `POSTGRES_USER` and `POSTGRESS_PASSWORD`, respectively, ending with a file
    that contains
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We will also need to update the `docker-compose.yml` to make use of this newly
    created file. Note that we removed environment and replaced it with `env_file`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we also made a change to the API container to employ the same `.sql_server.conf`
    in the `env_file` directive. Before going further, we should build and bring our
    containers up to ensure that everything is still working. Finally, we will need
    to update our API container to also pull in these variables. We import the `os`
    module and then use `getenv` to retrieve the environment variables that were set
    in our .sql_server.conf file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: With those changes, we can remove, build, and bring up the containers to test.
    You may also want to change the values in the environment to ensure that the changes
    are indeed working. In addition, do not forget to sign into CloudBeaver to ensure
    that is working as well.
  prefs: []
  type: TYPE_NORMAL
- en: The `os.getenv` command also allows you to specify a default value if the `environment`
    variable is not found. So, we could have used `os.getenv("POSTGRES_USER",` `"postgres"),`
    but we stayed away from a default value in this example because we wanted to ensure
    that our containers would not work accidentally if we had set something up incorrectly
    (because the Postgres user was still valid somehow). Your use cases will vary,
    so just keep that functionality in mind.
  prefs: []
  type: TYPE_NORMAL
- en: We also updated the `DATABASE_URL`. Substituting the `POSTGRES_USER` for both
    the `dbname` and `user` in the connection string. This is just a convention in
    the PostgreSQL database. The `dbname` and `user` are independent of each other,
    but we kept our SQL script straightforward, so the table was created under the
    same username. You will also notice that the connection string contains hardcoded
    values for the host and port. We are leaving it up to you whether you would like
    to replace those with an environment value that will not hurt anything and may
    also be an opportunity for you to try out the default value in the `os.getenv`
    mentioned earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 3.8 Health checks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In our sample, we built out a simple health check endpoint. This endpoint is
    something that applications could use to get a status of the system or application.
    It can be as fine-grained as you want, checking not just the services that it
    may be running but also potential problems connecting to other services.
  prefs: []
  type: TYPE_NORMAL
- en: Here we would like to take a moment to look at health checks from a purely Docker
    perspective as opposed to what may be done at the application level. These health
    checks can be used to determine whether the container is running correctly (or
    healthy). Containers can be in multiple statuses such as starting, healthy, or
    unhealthy, and the importance of knowing the state of a container is one of the
    benefits of using containers. Unhealthy containers will adversely affect your
    system and could be the result of bad application code, networking problems, or
    perhaps a bad update in one of the components being used in the container. Docker
    and Docker Compose can automatically restart containers in an attempt to resolve
    potential problems, or you may build a more robust logging and notification system
    to monitor your containers.
  prefs: []
  type: TYPE_NORMAL
- en: We can determine the health of our containers using the `docker` `ps` command.
    You can run the command now; however, unless the image you are using includes
    a health check, you will not see starting/healthy/unhealthy next to the status;
    you will only see the up time. To save space, we will format the output of the
    `docker ps` command with the `format` argument. Running `docker` `ps` `--format`
    `'{{.Names}}` `-` `{{.Status}}'` from the command line shows
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: First, let’s add a health check for the Postgres container. We will update the
    Dockerfile with
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Notice that the command takes several parameters and that the actual work is
    done by the `CMD`. The `pg_isready` is a Postgres command that confirms the database
    is up and running. It requires a user, so we are referencing the `environment`
    variable we defined.
  prefs: []
  type: TYPE_NORMAL
- en: If we rebuild following the usual procedure of removing the containers, rebuilding,
    and bringing them back up, then running that `docker ps` command gives us
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We can see that the Postgres container now shows as healthy. Including health
    checks helps us prepare our containers for a production environment where a container
    orchestration tool such as Docker Swarm or Kubernetes will enable our containers
    to be self-healing, meaning that the containers will be able to be restarted or
    replaced if they fail these checks. That is a bit beyond the scope of this book
    though. For the time being, keep in mind the power that health checks provide
    and the potential difference between a health check at the application level versus
    health checks from the Docker perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Docker and Docker Compose can manage our environment. By building out small
    pieces of a project into separate containers, we can start expanding each component
    of our project independently.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating team experience, project size, and risk factors is vital when determining
    the best approach to a project.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative AI tools can increase productivity but have limitations and require
    verification.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker creates isolated environments for efficiently managing multiple services
    and technologies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transitioning to microservices should be based on need, not trend, as monolithic
    architectures can still be effective.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dividing a project into manageable components and ensuring initial connectivity
    is crucial for effective development.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Health checks in containers provide system status monitoring and enable self-healing
    in production environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security and efficient management are achieved by applying the principle of
    least privilege and using vulnerability scanning tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container optimization is important in reducing image size and build time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Environment variables should be used to avoid hardcoding sensitive information
    such as usernames and passwords.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adhering to best practices in storage, application optimization, and dependency
    management enhances Docker’s effectiveness.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
