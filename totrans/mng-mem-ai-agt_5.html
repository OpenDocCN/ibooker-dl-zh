<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 5. Collective Memory: How Teams and Organizations Share Knowledge Through AI Agents"><div class="chapter" id="ch05_collective_memory_how_teams_and_organizations_sha_1758256568088949">
      <h1><span class="label">Chapter 5. </span>Collective Memory: How Teams and Organizations Share Knowledge Through AI Agents</h1>
      <p>So far, we’ve focused on individual agents in AI systems: how they store, retrieve, and manage information. But why limit agent memory to a single user’s interactions? Organizations and teams constantly build contextual stores of knowledge while executives, managers, and team leads struggle to effectively collect, store, and disseminate this information to those who need it.</p>
      <p>AI agents offer a solution: shared memory systems that preserve organizational knowledge beyond any individual’s tenure. With agents, the possibility emerges of a binding organizational memory that persists beyond any one person—dampening the impact of retirements, promotions, and role changes that naturally erase critical institutional insights. But how exactly can this process work, and what does this mean for the future of work?</p>
      <section data-type="sect1" class="pagebreak-before" data-pdf-bookmark="From Individual to Collective Intelligence"><div class="sect1" id="ch05_from_individual_to_collective_intelligence_1758256568089028">
        <h1 class="less_space">From Individual to Collective Intelligence</h1>
        <p>Let’s start by clarifying what we mean by <em>collective organizational knowledge</em>. Psychologists have a useful framework for this: transactive memory systems (TMSs). A <em>TMS</em> is defined as the “group-level knowledge sharing and memory system for encoding, storing, and retrieving information from different knowledge areas in a group.”<sup><a data-type="noteref" id="id76-marker" href="ch05.html#id76">1</a></sup> In essence, it’s about “knowing what other team members know” and being able to access that knowledge when needed. This helps assemble the different pieces of distributed group knowledge into one coherent “group mind”—and this group mind is directly associated with team effectiveness.</p>
        <p>Rather than simply storing individual knowledge with an AI agent, new architectures are being developed to expand from one-on-one agent-human interactions to broader agent-human-team interactions with shared knowledge bases. The data stores are exactly the kind of TMSs that hold the potential to improve team effectiveness (<a data-type="xref" href="#ch05_figure_1_1758256568086742">Figure 5-1</a>). Indeed, there’s convincing evidence that such centralized systems of knowledge benefit not only existing team members but newly onboarded and novice employees as well. In a recent 2023 call center study, AI assistants deployed to support customer interactions demonstrated this effect dramatically: novice workers improved their productivity by 34% while experienced workers saw minimal gains, suggesting that the AI effectively captured and disseminated the expertise of top performers throughout the <span class="keep-together">organization</span>.<sup><a data-type="noteref" id="id77-marker" href="ch05.html#id77">2</a></sup></p>
        <figure><div id="ch05_figure_1_1758256568086742" class="figure">
          <img alt="Diagram illustrating how an AI intelligence hub processes and synthesizes knowledge from strategic thinkers, creative innovators, data analysts, and domain experts for team-wide benefits." src="assets/mmai_0501.png" width="1113" height="624"/>
          <h6><span class="label">Figure 5-1. </span>Example of AI integration in a TMS</h6>
        </div></figure>
        <p>The shift from siloed knowledge to shared organizational memory represents more than a technical evolution. When a senior engineer’s problem-solving approach can be captured and made accessible to junior team members through AI agents, we’re not just preserving information—we’re democratizing expertise.</p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Team Knowledge Sharing Platforms and Tactics"><div class="sect1" id="ch05_team_knowledge_sharing_platforms_and_tactics_1758256568089081">
        <h1>Team Knowledge Sharing Platforms <span class="keep-together">and Tactics</span></h1>
        <p>So what options are there for developing one’s own internal knowledge system or TMS? The landscape of AI-powered knowledge management platforms reveals sophisticated approaches to team collaboration that go far beyond simple document storage.</p>
        <p>Several platforms demonstrate different approaches to building organizational memory:</p>
        <dl>
          <dt>Zep</dt>
          <dd>
            <p>A memory platform that builds “temporal knowledge graphs” from team interactions and business data, creating memory systems that track how information changes over time. Zep maintains intraorganizational information across all team interactions—remembering preferences, conversations, and business knowledge—which enables AI agents to access collective team expertise and transfer best practices from top performers to newer members, similar to the knowledge-dissemination effects in the call center study.</p>
          </dd>
          <dt>Onyx</dt>
          <dd>
            <p>An open source AI platform that connects enterprise applications (Google Drive, Slack, Confluence, Salesforce, etc.) to create a unified knowledge search and AI assistant system. The platform enables teams to find shared information while preserving security. With custom AI assistants that can be embedded directly into existing workflows, Onyx builds searchable institutional memory stores that can scale from small teams to thousands of users.</p>
          </dd>
          <dt>MCP</dt>
          <dd>
            <p>Although MCP is not strictly a platform but rather is a protocol, it standardizes how applications provide context to LLMs. MCP enables teams to build persistent memory systems through servers like the Knowledge Graph Memory Server, which maintains entities, relationships, and observations across conversations. Unlike traditional platforms, MCP creates a decentralized approach where multiple lightweight servers can expose specific capabilities—from local files to remote APIs—while maintaining a unified interface for AI agents. This architecture allows teams to construct custom knowledge graphs that evolve with each interaction, storing not just information but also the relationships and context between different pieces of organizational knowledge.<sup><a data-type="noteref" id="id78-marker" href="ch05.html#id78">3</a></sup></p>
          </dd>
        </dl>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Building Organizational Memory with AI Agents"><div class="sect1" id="ch05_building_organizational_memory_with_ai_agents_1758256568089131">
        <h1>Building Organizational Memory with <span class="keep-together">AI Agents</span></h1>
        <p>Having a choice in which platform you adopt is helpful—but how are these tools capturing the critical organizational knowledge in the first place? Once again, the answer comes down to novel storage and retrieval strategies.</p>
        <section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Capturing Institutional Knowledge"><div class="sect2" id="ch05_capturing_institutional_knowledge_1758256568089177">
          <h2 class="less_space">Capturing Institutional Knowledge</h2>
          <p>Across these platforms, several common strategies emerge for building organizational memory:</p>
          <dl>
            <dt>Continuous learning from daily work</dt>
            <dd>
              <p>AI agents can observe and learn from senior experts’ problem-solving approaches through their daily interactions, capturing not just what they do but also how they approach problems.</p>
            </dd>
            <dt>Contextual knowledge preservation</dt>
            <dd>
              <p>Unlike traditional documentation methods, AI agents can preserve the context around decisions: why certain choices were made, what alternatives were considered, and what constraints existed at the time.</p>
            </dd>
            <dt>Dynamic knowledge graphs</dt>
            <dd>
              <p>Modern systems like those implementing the A-MEM (agentic memory) framework create interconnected knowledge networks following the Zettelkasten method. When new memory is added, the system generates comprehensive notes with contextual descriptions, keywords, and tags, creating a web of related information.<sup><a data-type="noteref" id="id79-marker" href="ch05.html#id79">4</a></sup></p>
            </dd>
          </dl>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Memory-Preservation Strategies"><div class="sect2" id="ch05_memory_preservation_strategies_1758256568089223">
          <h2>Memory-Preservation Strategies</h2>
          <p>Organizations are implementing several strategies to ensure knowledge persistence across agent lifecycles:</p>
          <ul>
            <li>
              <p>Checkpointing mechanisms that periodically save agent state and learned patterns</p>
            </li>
            <li>
              <p>Hierarchical memory systems with short-term, long-term, and archival storage tiers</p>
            </li>
            <li>
              <p>Cross-agent knowledge synchronization to ensure that discoveries by one agent benefit the entire system</p>
            </li>
            <li>
              <p>Version control for agent memory, allowing rollback and historical analysis</p>
            </li>
          </ul>
        </div></section>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Human-AI Team Collaboration Patterns"><div class="sect1" id="ch05_human_ai_team_collaboration_patterns_1758256568089271">
        <h1>Human-AI Team Collaboration Patterns</h1>
        <p>For all this talk about memory patterns, storage, and retrieval, we’ve overlooked the most crucial element of AI agent collaboration: the humans themselves. If organizations hope to successfully integrate agents into their teams, they must create the space, opportunity, and trust necessary for employees to understand how and why these agents will enhance—not replace—their work.</p>
        <p>The integration of AI agents into team memory systems requires significant organizational change. The requirements for workforce transformation include:</p>
        <dl>
          <dt>Employee empowerment</dt>
          <dd>
            <p>There is no better way to encourage AI use than to give employees the keys to their tools. Asking which agents employees want to use and giving them the freedom to experiment is a surefire way to increase adoption.</p>
          </dd>
          <dt>Cultural shift to augmentation</dt>
          <dd>
            <p>Some employees will be rightfully skeptical of new tooling. Rather than dismissing or ignoring these feelings, organizations should clearly establish how agents are not a “replacement” for employees but are cognitive partners that amplify human capabilities rather than substitute for them.</p>
          </dd>
          <dt>Trust-building through transparency</dt>
          <dd>
            <p>Establishing clear guidelines about what AI agents can access, how they learn, and what decisions remain solely human based builds trust between organization leaders who wish to encourage AI use and employees who want control over their own choices.</p>
          </dd>
        </dl>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Looking Forward: The Feedback Loop"><div class="sect1" id="ch05_looking_forward_the_feedback_loop_1758256568089317">
        <h1>Looking Forward: The Feedback Loop</h1>
        <p>When we started this chapter, we viewed agentic memory as something between a single human and an AI agent. By now, it should be clear that’s only one piece of a much larger system. As more employees interact with organizational agents, these systems capture and store increasing amounts of context. This stored context then becomes accessible to other team members, transforming previously tacit knowledge into shared resources that boost productivity across the organization. We’re witnessing the beginning of a powerful feedback loop: the more people use these systems, the smarter and more valuable the systems become. As organizations adopt enterprise-level knowledge stores, this dynamic will only accelerate. The companies that thrive will be those that successfully transform their AI agents from mere tools into collaborative team members, their static data into living knowledge, and their individual expertise into collective intelligence.</p>
      </div></section>
    <div data-type="footnotes"><p data-type="footnote" id="id76"><sup><a href="ch05.html#id76-marker">1</a></sup> Nadine Bienefeld, Michaela Kolbe, Giovanni Camen, Dominic Huser, and Philipp Karl Buehler, “Human-AI Teaming: Leveraging Transactive Memory and Speaking Up for Enhanced Team Effectiveness,” <em>Frontiers in Psychology </em>14 (2023): 1208019, <a href="https://doi.org/10.3389/fpsyg.2023.1208019"><em class="hyperlink">https://doi.org/10.3389/fpsyg.2023.1208019</em></a>.</p><p data-type="footnote" id="id77"><sup><a href="ch05.html#id77-marker">2</a></sup> Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond, “Generative AI at Work,” NBER Working Paper No. 31161 (April 2023), <a href="https://doi.org/10.3386/w31161"><em class="hyperlink">https://doi.org/10.3386/w31161</em></a>.</p><p data-type="footnote" id="id78"><sup><a href="ch05.html#id78-marker">3</a></sup> “Introducing the Model Context Protocol,” Anthropic, November 25, 2024, <a href="https://www.anthropic.com/news/model-context-protocol"><em class="hyperlink"><span class="keep-together">https://www.anthropic.com/news/model-context-protocol</span></em></a>.</p><p data-type="footnote" id="id79"><sup><a href="ch05.html#id79-marker">4</a></sup> Wujiang Xu, Kai Mei, Hang Gao, Juntao Tan, Zujie Liang, and Yongfeng Zhang, “A-MEM: Agentic Memory for LLM Agents,” arXiv:2502.12110, 2025. <a href="https://doi.org/10.48550/arXiv.2502.12110"><em class="hyperlink">https://doi.org/10.48550/arXiv.2502.12110</em></a>.</p></div></div></section></div></div></body></html>