<html><head></head><body><section data-pdf-bookmark="Chapter 10. Creating ML Models to Predict Sequences" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch10_creating_ml_models_to_predict_sequences_1748549713795870">
      <h1><span class="label">Chapter 10. </span>Creating ML Models to Predict Sequences</h1>
      <p><a data-type="xref" href="ch09.html#ch09_understanding_sequence_and_time_series_data_1748549698134578">Chapter 9</a> introduced sequence data and the attributes of a time series, including seasonality, trend, autocorrelation, and noise. You created a synthetic series to use for predictions, and you explored how to do basic statistical forecasting. </p>
      <p>Over the next couple of chapters, you’ll learn how to use ML for forecasting. <a contenteditable="false" data-primary="time series data" data-secondary="predicting with ML models" data-tertiary="windowed dataset" data-type="indexterm" id="ch19wind"/><a contenteditable="false" data-primary="datasets" data-secondary="windowed datasets" data-type="indexterm" id="ch19wind2"/><a contenteditable="false" data-primary="windowed datasets" data-type="indexterm" id="ch19wind3"/>But before you start creating models, you need to understand how to structure the time series data for training predictive models by creating what we’ll call a <em>windowed <span class="keep-together">dataset.</span></em></p>
      <p>To understand why you need to do this, consider the time series you created in <a data-type="xref" href="ch09.html#ch09_understanding_sequence_and_time_series_data_1748549698134578">Chapter 9</a>. You can see a plot of it in <a data-type="xref" href="#ch10_figure_1_1748549713788310">Figure 10-1</a>.</p>
      <p>If at any point, you want to predict a value at time <em>t</em>, you’ll want to predict it as a function of the values preceding time <em>t</em>. For example, say you want to predict the value of the time series at time step 1,200 as a function of the 30 values preceding it. In this case, the values from time steps 1,170 to 1,199 would determine the value at time step 1,200 (see <a data-type="xref" href="#ch10_figure_2_1748549713788360">Figure 10-2</a>).</p>
            <figure><div class="figure" id="ch10_figure_1_1748549713788310">
        <img alt="" src="assets/aiml_1001.png"/>
        <h6><span class="label">Figure 10-1. </span>Synthetic time series</h6>
      </div></figure>
      <figure><div class="figure" id="ch10_figure_2_1748549713788360">
        <img alt="" src="assets/aiml_1002.png"/>
        <h6><span class="label">Figure 10-2. </span>Previous values impacting prediction</h6>
      </div></figure>
      <p>Now, this begins to look familiar: you can consider the values from 1,170 to 1,199 to be your <em>features</em> and the value at 1,200 to be your <em>label</em>. If you can get your dataset into a condition where you have a certain number of values as features and the following value as the label, and if you do this for every known value in the dataset, then you’ll end up with a pretty decent set of features and labels that you can use to train a model.</p>
      <p>Before doing this for the time series dataset from <a data-type="xref" href="ch09.html#ch09_understanding_sequence_and_time_series_data_1748549698134578">Chapter 9</a>, let’s create a very simple dataset that has all the same attributes but a much smaller amount of data.</p>
      <section data-pdf-bookmark="Creating a Windowed Dataset" data-type="sect1"><div class="sect1" id="ch10_creating_a_windowed_dataset_1748549713796115">
        <h1>Creating a Windowed Dataset</h1>
        <p>PyTorch has a lot of APIs that are useful for manipulating data. For example, you can use <code>torch.arange(10)</code> to create a basic dataset containing the numbers 0–9, thus emulating a time series. You can then turn that dataset into the beginnings of a windowed dataset. Here’s the code:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">torch</code>
 
<code class="k">def</code> <code class="nf">create_sliding_windows</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">window_size</code><code class="p">,</code> <code class="n">shift</code><code class="o">=</code><code class="mi">1</code><code class="p">):</code>
    <code class="c1"># Convert input to tensor if it isn't already</code>
    <code class="k">if</code> <code class="ow">not</code> <code class="nb">isinstance</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">torch</code><code class="o">.</code><code class="n">Tensor</code><code class="p">):</code>
        <code class="n">data</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="n">data</code><code class="p">)</code>
 
    <code class="c1"># Calculate number of valid windows</code>
    <code class="n">n</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">data</code><code class="p">)</code>
    <code class="n">num_windows</code> <code class="o">=</code> <code class="nb">max</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="p">(</code><code class="n">n</code> <code class="err">–</code> <code class="n">window_size</code><code class="p">)</code> <code class="o">//</code> <code class="n">shift</code> <code class="o">+</code> <code class="mi">1</code><code class="p">)</code>
 
    <code class="c1"># Create strided view of data</code>
    <code class="n">windows</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">unfold</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="n">window_size</code><code class="p">,</code> <code class="n">shift</code><code class="p">)</code>
 
    <code class="k">return</code> <code class="n">windows</code>
 
<code class="c1"># Example usage:</code>
<code class="n">data</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="mi">10</code><code class="p">)</code>
<code class="n">windows</code> <code class="o">=</code> <code class="n">create_sliding_windows</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">window_size</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> <code class="n">shift</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
 
<code class="c1"># Print each window</code>
<code class="k">for</code> <code class="n">window</code> <code class="ow">in</code> <code class="n">windows</code><code class="p">:</code>
    <code class="nb">print</code><code class="p">(</code><code class="n">window</code><code class="o">.</code><code class="n">numpy</code><code class="p">())</code>
 </pre>
        <p>First, it creates the dataset by using a range, which simply makes the dataset contain the values 0 to <em>n</em> – 1, where <em>n</em> is, in this case, 10.</p>
        <p>Next, calling <code>create_sliding_windows</code> and passing a parameter of <code>5</code> specifies that the network should split the dataset into windows of five items. Specifying <code>shift=1</code> causes each window to then be shifted one spot from the previous one: the first window will contain the five items beginning at 0, the next window will contain the five items beginning at 1, etc.</p>
        <p class="pagebreak-before">Running this code will give you the following result:</p>
<pre data-code-language="python" data-type="programlisting">
<code class="p">[</code><code class="mi">0</code> <code class="mi">1</code> <code class="mi">2</code> <code class="mi">3</code> <code class="mi">4</code><code class="p">]</code>
<code class="p">[</code><code class="mi">1</code> <code class="mi">2</code> <code class="mi">3</code> <code class="mi">4</code> <code class="mi">5</code><code class="p">]</code>
<code class="p">[</code><code class="mi">2</code> <code class="mi">3</code> <code class="mi">4</code> <code class="mi">5</code> <code class="mi">6</code><code class="p">]</code>
<code class="p">[</code><code class="mi">3</code> <code class="mi">4</code> <code class="mi">5</code> <code class="mi">6</code> <code class="mi">7</code><code class="p">]</code>
<code class="p">[</code><code class="mi">4</code> <code class="mi">5</code> <code class="mi">6</code> <code class="mi">7</code> <code class="mi">8</code><code class="p">]</code>
<code class="p">[</code><code class="mi">5</code> <code class="mi">6</code> <code class="mi">7</code> <code class="mi">8</code> <code class="mi">9</code><code class="p">]</code>
</pre>
        <p>Earlier, you saw that we want to make training data out of this, where there are <em>n</em> values defining a feature and there is a subsequent value giving a label. You can do this with some simple Python list slicing that splits each window into two things: everything before the last value and the last value only. </p>
        <p>This uses the <code>unfold</code> technique on tensor data, which creates a sliding window over your data to turn it into sets like those outlined previously. </p>
        <p>It also takes three parameters:</p>
        <dl>
          <dt>Dimension (0 in this case)</dt>
          <dd>
            <p>This is the dimension along which to unfold.</p>
          </dd>
          <dt>window_size</dt>
          <dd>
            <p>This is the size of each sliding window.</p>
          </dd>
          <dt>shift</dt>
          <dd>
            <p>This is the stride/step size between windows.</p>
          </dd>
        </dl>
        <p>This process gives us an <code><em>x</em></code> and a <code><em>y</em></code> dataset, as shown here:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">torch</code>
 
<code class="k">def</code> <code class="nf">create_sliding_windows_with_target</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">window_size</code><code class="p">,</code> <code class="n">shift</code><code class="o">=</code><code class="mi">1</code><code class="p">):</code>
    <code class="c1"># Convert input to tensor if it isn't already</code>
    <code class="k">if</code> <code class="ow">not</code> <code class="nb">isinstance</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">torch</code><code class="o">.</code><code class="n">Tensor</code><code class="p">):</code>
        <code class="n">data</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">torch</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code>
 
    <code class="c1"># Create windows using unfold</code>
    <code class="n">windows</code> <code class="o">=</code> <code class="n">data</code><code class="o">.</code><code class="n">unfold</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="n">window_size</code><code class="p">,</code> <code class="n">shift</code><code class="p">)</code>
 
    <code class="c1"># Split each window into features</code>
    <code class="n">features</code> <code class="o">=</code> <code class="n">windows</code><code class="p">[:,</code> <code class="p">:</code><code class="err">–</code><code class="mi">1</code><code class="p">]</code>  <code class="c1"># All elements except the last</code>
    <code class="n">targets</code> <code class="o">=</code> <code class="n">windows</code><code class="p">[:,</code> <code class="err">–</code><code class="mi">1</code><code class="p">:]</code>   <code class="c1"># Just the last element</code>
 
    <code class="k">return</code> <code class="n">features</code><code class="p">,</code> <code class="n">targets</code>
 
<code class="c1"># Example usage:</code>
<code class="n">data</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="mi">10</code><code class="p">)</code>
<code class="n">features</code><code class="p">,</code> <code class="n">targets</code> <code class="o">=</code> <code class="n">create_sliding_windows_with_target</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">window_size</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> 
                                                             <code class="n">shift</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
 
<code class="c1"># Print each window's features and target</code>
<code class="k">for</code> <code class="n">x</code><code class="p">,</code> <code class="n">y</code> <code class="ow">in</code> <code class="nb">zip</code><code class="p">(</code><code class="n">features</code><code class="p">,</code> <code class="n">targets</code><code class="p">):</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Features: </code><code class="si">{</code><code class="n">x</code><code class="o">.</code><code class="n">numpy</code><code class="p">()</code><code class="si">}</code><code class="s2">, Target: </code><code class="si">{</code><code class="n">y</code><code class="o">.</code><code class="n">numpy</code><code class="p">()</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
 </pre>
        <p>The results are now in line with what you’d expect. The first four values in the window can be thought of as the features, with the subsequent value being the label:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="p">[</code><code class="mi">0</code> <code class="mi">1</code> <code class="mi">2</code> <code class="mi">3</code><code class="p">]</code> <code class="p">[</code><code class="mi">4</code><code class="p">]</code>
<code class="p">[</code><code class="mi">1</code> <code class="mi">2</code> <code class="mi">3</code> <code class="mi">4</code><code class="p">]</code> <code class="p">[</code><code class="mi">5</code><code class="p">]</code>
<code class="p">[</code><code class="mi">2</code> <code class="mi">3</code> <code class="mi">4</code> <code class="mi">5</code><code class="p">]</code> <code class="p">[</code><code class="mi">6</code><code class="p">]</code>
<code class="p">[</code><code class="mi">3</code> <code class="mi">4</code> <code class="mi">5</code> <code class="mi">6</code><code class="p">]</code> <code class="p">[</code><code class="mi">7</code><code class="p">]</code>
<code class="p">[</code><code class="mi">4</code> <code class="mi">5</code> <code class="mi">6</code> <code class="mi">7</code><code class="p">]</code> <code class="p">[</code><code class="mi">8</code><code class="p">]</code>
<code class="p">[</code><code class="mi">5</code> <code class="mi">6</code> <code class="mi">7</code> <code class="mi">8</code><code class="p">]</code> <code class="p">[</code><code class="mi">9</code><code class="p">]</code></pre>
        <p>Now, with the PyTorch TensorDataset type,<a contenteditable="false" data-primary="TensorDataset type (PyTorch)" data-type="indexterm" id="id1438"/><a contenteditable="false" data-primary="datasets" data-secondary="creating with PyTorch TensorDataset type" data-type="indexterm" id="id1439"/> you can turn this into a dataset and do things like shuffling and batching natively. </p>
        <p>Note that when shuffling data,<a contenteditable="false" data-primary="DataLoader" data-secondary="shuffling data" data-tertiary="validation and test datasets removed first" data-type="indexterm" id="id1440"/><a contenteditable="false" data-primary="shuffling data with DataLoader" data-secondary="validation and test datasets removed first" data-type="indexterm" id="id1441"/> it’s good practice to ensure that the validation and test datasets are separated first. In time series data, shuffling before the split can cause information from the training set to bleed into the test set, which would compromise the evaluation process.</p>
        <p>Here, it’s been shuffled and batched with a batch size of 2:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="kn">from</code> <code class="nn">torch.utils.data</code> <code class="kn">import</code> <code class="n">TensorDataset</code><code class="p">,</code> <code class="n">DataLoader</code>
 
<code class="c1"># Create dataset</code>
<code class="n">data</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="mi">10</code><code class="p">)</code>
<code class="n">features</code><code class="p">,</code> <code class="n">targets</code> <code class="o">=</code> <code class="n">create_sliding_windows_with_target</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">window_size</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> 
                                                             <code class="n">shift</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
 
<code class="c1"># Combine features and targets into a dataset</code>
<code class="n">dataset</code> <code class="o">=</code> <code class="n">TensorDataset</code><code class="p">(</code><code class="n">features</code><code class="p">,</code> <code class="n">targets</code><code class="p">)</code>
 
<code class="c1"># Create DataLoader with shuffling and batching</code>
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">2</code>
<code class="n">dataloader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">dataset</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">,</code> <code class="n">shuffle</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
 
<code class="c1"># Example iteration</code>
<code class="k">for</code> <code class="n">batch_features</code><code class="p">,</code> <code class="n">batch_targets</code> <code class="ow">in</code> <code class="n">dataloader</code><code class="p">:</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Batch features shape: </code><code class="si">{</code><code class="n">batch_features</code><code class="o">.</code><code class="n">shape</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Features:</code><code class="se">\n</code><code class="si">{</code><code class="n">batch_features</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Targets:</code><code class="se">\n</code><code class="si">{</code><code class="n">batch_targets</code><code class="si">}</code><code class="se">\n</code><code class="s2">"</code><code class="p">)</code>
 </pre>
        <p>The results show that the first batch has two sets of <code><em>x</em></code> (starting at 5 and 0, respectively) with their labels, the second batch has two sets of <code><em>x</em></code> (starting at 1 and 3, respectively) with their labels, and so on:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="n">tensor</code><code class="p">([[</code><code class="mi">5</code><code class="p">,</code> <code class="mi">6</code><code class="p">,</code> <code class="mi">7</code><code class="p">,</code> <code class="mi">8</code><code class="p">],</code>
        <code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="mi">3</code><code class="p">]])</code>
<code class="n">Targets</code><code class="p">:</code>
<code class="n">tensor</code><code class="p">([[</code><code class="mi">9</code><code class="p">],</code>
        <code class="p">[</code><code class="mi">4</code><code class="p">]])</code>
 
 
<code class="n">Features</code><code class="p">:</code>
<code class="n">tensor</code><code class="p">([[</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">,</code> <code class="mi">3</code><code class="p">,</code> <code class="mi">4</code><code class="p">],</code>
        <code class="p">[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">4</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">6</code><code class="p">]])</code>
<code class="n">Targets</code><code class="p">:</code>
<code class="n">tensor</code><code class="p">([[</code><code class="mi">5</code><code class="p">],</code>
        <code class="p">[</code><code class="mi">7</code><code class="p">]])</code>
 
 
<code class="n">Features</code><code class="p">:</code>
<code class="n">tensor</code><code class="p">([[</code><code class="mi">4</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">6</code><code class="p">,</code> <code class="mi">7</code><code class="p">],</code>
        <code class="p">[</code><code class="mi">2</code><code class="p">,</code> <code class="mi">3</code><code class="p">,</code> <code class="mi">4</code><code class="p">,</code> <code class="mi">5</code><code class="p">]])</code>
<code class="n">Targets</code><code class="p">:</code>
<code class="n">tensor</code><code class="p">([[</code><code class="mi">8</code><code class="p">],</code>
        <code class="p">[</code><code class="mi">6</code><code class="p">]])</code>
 </pre>
        <p>With this technique, you can now<a contenteditable="false" data-primary="time series data" data-secondary="creating training data from time series dataset" data-type="indexterm" id="id1442"/> turn any time series dataset into a set of training data for a neural network. In the next section, you’ll explore how to take the synthetic data from <a data-type="xref" href="ch09.html#ch09_understanding_sequence_and_time_series_data_1748549698134578">Chapter 9</a> and create a training set from it. From there, you’ll move on to creating a simple DNN that is trained on this data and can be used to predict future values.<a contenteditable="false" data-primary="" data-startref="ch19wind" data-type="indexterm" id="id1443"/><a contenteditable="false" data-primary="" data-startref="ch19wind2" data-type="indexterm" id="id1444"/><a contenteditable="false" data-primary="" data-startref="ch19wind3" data-type="indexterm" id="id1445"/></p>
        <section data-pdf-bookmark="Creating a Windowed Version of the Time Series Dataset" data-type="sect2"><div class="sect2" id="ch10_creating_a_windowed_version_of_the_time_series_dat_1748549713796195">
          <h2>Creating a Windowed Version of the Time Series Dataset</h2>
          <p>As a recap, here’s the<a contenteditable="false" data-primary="time series data" data-secondary="creating a synthetic time series" data-tertiary="windowed version" data-type="indexterm" id="ch10synwin"/><a contenteditable="false" data-primary="time series data" data-secondary="predicting with ML models" data-tertiary="windowed dataset of synthetic time series" data-type="indexterm" id="ch10synwin2"/> code we used in the previous chapter to create a synthetic time series dataset:</p>
          <pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>
<code class="k">def</code> <code class="nf">trend</code><code class="p">(</code><code class="n">time</code><code class="p">,</code> <code class="n">slope</code><code class="o">=</code><code class="mi">0</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">slope</code> <code class="o">*</code> <code class="n">time</code>
 
<code class="k">def</code> <code class="nf">seasonal_pattern</code><code class="p">(</code><code class="n">season_time</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">season_time</code> <code class="o">&lt;</code> <code class="mf">0.4</code><code class="p">,</code>
                    <code class="n">np</code><code class="o">.</code><code class="n">cos</code><code class="p">(</code><code class="n">season_time</code> <code class="o">*</code> <code class="mi">2</code> <code class="o">*</code> <code class="n">np</code><code class="o">.</code><code class="n">pi</code><code class="p">),</code>
                    <code class="mi">1</code> <code class="o">/</code> <code class="n">np</code><code class="o">.</code><code class="n">exp</code><code class="p">(</code><code class="mi">3</code> <code class="o">*</code> <code class="n">season_time</code><code class="p">))</code>
 
<code class="k">def</code> <code class="nf">seasonality</code><code class="p">(</code><code class="n">time</code><code class="p">,</code> <code class="n">period</code><code class="p">,</code> <code class="n">amplitude</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">phase</code><code class="o">=</code><code class="mi">0</code><code class="p">):</code>
    <code class="n">season_time</code> <code class="o">=</code> <code class="p">((</code><code class="n">time</code> <code class="o">+</code> <code class="n">phase</code><code class="p">)</code> <code class="o">%</code> <code class="n">period</code><code class="p">)</code> <code class="o">/</code> <code class="n">period</code>
    <code class="k">return</code> <code class="n">amplitude</code> <code class="o">*</code> <code class="n">seasonal_pattern</code><code class="p">(</code><code class="n">season_time</code><code class="p">)</code>
 
<code class="k">def</code> <code class="nf">noise</code><code class="p">(</code><code class="n">time</code><code class="p">,</code> <code class="n">noise_level</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">seed</code><code class="o">=</code><code class="kc">None</code><code class="p">):</code>
    <code class="n">rnd</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">RandomState</code><code class="p">(</code><code class="n">seed</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">rnd</code><code class="o">.</code><code class="n">randn</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">time</code><code class="p">))</code> <code class="o">*</code> <code class="n">noise_level</code>
 
<code class="n">time</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="mi">4</code> <code class="o">*</code> <code class="mi">365</code> <code class="o">+</code> <code class="mi">1</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="s2">"float32"</code><code class="p">)</code>
<code class="n">series</code> <code class="o">=</code> <code class="n">trend</code><code class="p">(</code><code class="n">time</code><code class="p">,</code> <code class="mf">0.1</code><code class="p">)</code>
<code class="n">baseline</code> <code class="o">=</code> <code class="mi">10</code>
<code class="n">amplitude</code> <code class="o">=</code> <code class="mi">20</code>
<code class="n">slope</code> <code class="o">=</code> <code class="mf">0.09</code>
<code class="n">noise_level</code> <code class="o">=</code> <code class="mi">5</code>
 
<code class="n">series</code> <code class="o">=</code> <code class="n">baseline</code> <code class="o">+</code> <code class="n">trend</code><code class="p">(</code><code class="n">time</code><code class="p">,</code> <code class="n">slope</code><code class="p">)</code>
<code class="n">series</code> <code class="o">+=</code> <code class="n">seasonality</code><code class="p">(</code><code class="n">time</code><code class="p">,</code> <code class="n">period</code><code class="o">=</code><code class="mi">365</code><code class="p">,</code> <code class="n">amplitude</code><code class="o">=</code><code class="n">amplitude</code><code class="p">)</code>
<code class="n">series</code> <code class="o">+=</code> <code class="n">noise</code><code class="p">(</code><code class="n">time</code><code class="p">,</code> <code class="n">noise_level</code><code class="p">,</code> <code class="n">seed</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
 </pre>
          <p>This will create a time series that looks like the one in <a data-type="xref" href="#ch10_figure_3_1748549713788388">Figure 10-3</a>. If you want to change it, feel free to tweak the values of the various constants.</p>
          <figure><div class="figure" id="ch10_figure_3_1748549713788388">
            <img src="assets/aiml_1003.png"/>
            <h6><span class="label">Figure 10-3. </span>Plotting the time series with trend, seasonality, and noise</h6>
          </div></figure>
          <p>Once you have the series, you can turn it into a windowed dataset with code similar to that in the previous section:</p>
          <pre data-code-language="python" data-type="programlisting"><code class="kn">import</code> <code class="nn">torch</code>
<code class="kn">from</code> <code class="nn">torch.utils.data</code> <code class="kn">import</code> <code class="n">TensorDataset</code><code class="p">,</code> <code class="n">DataLoader</code>
 
<code class="c1"># Convert the numpy series to a PyTorch tensor</code>
<code class="n">series_tensor</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="n">series</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">torch</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code>
 
<code class="c1"># Create windowed dataset with 30-day windows (predicting next day)</code>
<code class="n">window_size</code> <code class="o">=</code> <code class="mi">30</code>
<code class="n">features</code><code class="p">,</code> <code class="n">targets</code> <code class="o">=</code> <code class="n">create_sliding_windows_with_target</code><code class="p">(</code>
    <code class="n">series_tensor</code><code class="p">,</code> <code class="n">window_size</code><code class="o">=</code><code class="n">window_size</code><code class="p">,</code> <code class="n">shift</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
 
<code class="c1"># Create PyTorch Dataset and DataLoader</code>
<code class="n">dataset</code> <code class="o">=</code> <code class="n">TensorDataset</code><code class="p">(</code><code class="n">features</code><code class="p">,</code> <code class="n">targets</code><code class="p">)</code>
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">32</code>
<code class="n">train_loader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">dataset</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">,</code> <code class="n">shuffle</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
 
<code class="c1"># Print some information about the dataset</code>
<code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Series length: </code><code class="si">{</code><code class="nb">len</code><code class="p">(</code><code class="n">series</code><code class="p">)</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Number of windows: </code><code class="si">{</code><code class="nb">len</code><code class="p">(</code><code class="n">features</code><code class="p">)</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Feature shape: </code><code class="si">{</code><code class="n">features</code><code class="o">.</code><code class="n">shape</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>  <code class="c1"># Should be (num_windows, </code>
                                                        <code class="n">window_size</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Target shape: </code><code class="si">{</code><code class="n">targets</code><code class="o">.</code><code class="n">shape</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>    <code class="c1"># Should be (num_windows, 1)</code>
 
<code class="c1"># Show a few examples</code>
<code class="nb">print</code><code class="p">(</code><code class="s2">"</code><code class="se">\n</code><code class="s2">First few windows:"</code><code class="p">)</code>
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">3</code><code class="p">):</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"</code><code class="se">\n</code><code class="s2">Window </code><code class="si">{</code><code class="n">i</code><code class="o">+</code><code class="mi">1</code><code class="si">}</code><code class="s2">:"</code><code class="p">)</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Features (previous </code><code class="si">{</code><code class="n">window_size</code><code class="o">-</code><code class="mi">1</code><code class="si">}</code><code class="s2"> days): </code><code class="si">{</code><code class="n">features</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code class="o">.</code><code class="n">numpy</code><code class="p">()</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Target (next day): </code><code class="si">{</code><code class="n">targets</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code class="o">.</code><code class="n">item</code><code class="p">()</code><code class="si">:</code><code class="s2">.2f</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code></pre>
          <p>You can see the output here:</p>
          <pre data-code-language="python" data-type="programlisting"><code class="n">Series</code> <code class="n">length</code><code class="p">:</code> <code class="mi">1461</code>
<code class="n">Number</code> <code class="n">of</code> <code class="n">windows</code><code class="p">:</code> <code class="mi">1432</code>
<code class="n">Feature</code> <code class="n">shape</code><code class="p">:</code> <code class="n">torch</code><code class="o">.</code><code class="n">Size</code><code class="p">([</code><code class="mi">1432</code><code class="p">,</code> <code class="mi">29</code><code class="p">])</code>
<code class="n">Target</code> <code class="n">shape</code><code class="p">:</code> <code class="n">torch</code><code class="o">.</code><code class="n">Size</code><code class="p">([</code><code class="mi">1432</code><code class="p">,</code> <code class="mi">1</code><code class="p">])</code>
 
<code class="n">First</code> <code class="n">few</code> <code class="n">windows</code><code class="p">:</code>
 
<code class="n">Window</code> <code class="mi">1</code><code class="p">:</code>
<code class="n">Features</code> <code class="p">(</code><code class="n">previous</code> <code class="mi">29</code> <code class="n">days</code><code class="p">):</code> <code class="p">[</code><code class="mf">32.48357</code>  <code class="mf">29.395714</code> <code class="mf">33.40659</code>  <code class="mf">37.858486</code> 
 <code class="mf">29.14184</code>  <code class="mf">29.20528</code>  <code class="mf">38.32948</code>  <code class="mf">34.322147</code> <code class="mf">28.183279</code> <code class="mf">33.283253</code> <code class="mf">28.287313</code> 
 <code class="mf">28.303862</code> <code class="mf">31.864614</code> <code class="mf">21.104889</code> <code class="mf">22.057411</code> <code class="mf">27.875519</code> <code class="mf">25.622026</code> <code class="mf">32.25094</code>  
 <code class="mf">26.127428</code> <code class="mf">23.588236</code> <code class="mf">37.95459</code>  <code class="mf">29.468477</code> <code class="mf">30.900469</code> <code class="mf">23.39905</code>  <code class="mf">27.755371</code> 
 <code class="mf">30.980967</code> <code class="mf">24.615065</code> <code class="mf">32.186863</code> <code class="mf">27.23822</code> <code class="p">]</code>
<code class="n">Target</code> <code class="p">(</code><code class="nb">next</code> <code class="n">day</code><code class="p">):</code> <code class="mf">28.71</code>
 
<code class="n">Window</code> <code class="mi">2</code><code class="p">:</code>
<code class="n">Features</code> <code class="p">(</code><code class="n">previous</code> <code class="mi">29</code> <code class="n">days</code><code class="p">):</code> <code class="p">[</code><code class="mf">29.395714</code> <code class="mf">33.40659</code>  <code class="mf">37.858486</code> <code class="mf">29.14184</code>  
 <code class="mf">29.20528</code>  <code class="mf">38.32948</code>  <code class="mf">34.322147</code> <code class="mf">28.183279</code> <code class="mf">33.283253</code> <code class="mf">28.287313</code> <code class="mf">28.303862</code> 
 <code class="mf">31.864614</code> <code class="mf">21.104889</code> <code class="mf">22.057411</code> <code class="mf">27.875519</code> <code class="mf">25.622026</code> <code class="mf">32.25094</code>  <code class="mf">26.127428</code> 
 <code class="mf">23.588236</code> <code class="mf">37.95459</code>  <code class="mf">29.468477</code> <code class="mf">30.900469</code> <code class="mf">23.39905</code>  <code class="mf">27.755371</code> <code class="mf">30.980967</code> 
 <code class="mf">24.615065</code> <code class="mf">32.186863</code> <code class="mf">27.23822</code>  <code class="mf">28.710733</code><code class="p">]</code>
<code class="n">Target</code> <code class="p">(</code><code class="nb">next</code> <code class="n">day</code><code class="p">):</code> <code class="mf">27.08</code>
 
<code class="n">Window</code> <code class="mi">3</code><code class="p">:</code>
<code class="n">Features</code> <code class="p">(</code><code class="n">previous</code> <code class="mi">29</code> <code class="n">days</code><code class="p">):</code> <code class="p">[</code><code class="mf">33.40659</code>  <code class="mf">37.858486</code> <code class="mf">29.14184</code>  <code class="mf">29.20528</code>  
 <code class="mf">38.32948</code>  <code class="mf">34.322147</code> <code class="mf">28.183279</code> <code class="mf">33.283253</code> <code class="mf">28.287313</code> <code class="mf">28.303862</code> <code class="mf">31.864614</code> 
 <code class="mf">21.104889</code> <code class="mf">22.057411</code> <code class="mf">27.875519</code> <code class="mf">25.622026</code> <code class="mf">32.25094</code>  <code class="mf">26.127428</code> <code class="mf">23.588236</code> 
 <code class="mf">37.95459</code>  <code class="mf">29.468477</code> <code class="mf">30.900469</code> <code class="mf">23.39905</code>  <code class="mf">27.755371</code> <code class="mf">30.980967</code> <code class="mf">24.615065</code> 
 <code class="mf">32.186863</code> <code class="mf">27.23822</code>  <code class="mf">28.710733</code> <code class="mf">27.083256</code><code class="p">]</code>
<code class="n">Target</code> <code class="p">(</code><code class="nb">next</code> <code class="n">day</code><code class="p">):</code> <code class="mf">39.27</code></pre>
          <p>To train a model with this data,<a contenteditable="false" data-primary="time series data" data-secondary="splitting with whole seasons per split" data-type="indexterm" id="id1446"/> you’ll split the series into training and validation datasets. In this case, we’ll train on 1,000 records by splitting the list and turning it into <code>train_dataset</code> and <code>val_dataset</code> subsets. This uses the <code>Subset</code> class from <code>torch.utils.data</code>.</p>
          <p>You can then load these with a <code>DataLoader</code>, as we saw in <a data-type="xref" href="ch03.html#ch03_going_beyond_the_basics_detecting_features_in_ima_1748570891074912">Chapter 3</a>:</p>
          <pre data-code-language="python" data-type="programlisting"><code class="n">train_size</code> <code class="o">=</code> <code class="mi">1000</code> 
<code class="n">total_windows</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">full_dataset</code><code class="p">)</code>
<code class="n">train_indices</code> <code class="o">=</code> <code class="nb">list</code><code class="p">(</code><code class="nb">range</code><code class="p">(</code><code class="n">train_size</code><code class="p">))</code>
<code class="n">val_indices</code> <code class="o">=</code> <code class="nb">list</code><code class="p">(</code><code class="nb">range</code><code class="p">(</code><code class="n">train_size</code><code class="p">,</code> <code class="n">total_windows</code><code class="p">))</code>
 
<code class="c1"># Create training and validation datasets using Subset</code>
<code class="n">train_dataset</code> <code class="o">=</code> <code class="n">Subset</code><code class="p">(</code><code class="n">full_dataset</code><code class="p">,</code> <code class="n">train_indices</code><code class="p">)</code>
<code class="n">val_dataset</code> <code class="o">=</code> <code class="n">Subset</code><code class="p">(</code><code class="n">full_dataset</code><code class="p">,</code> <code class="n">val_indices</code><code class="p">)</code>
 
<code class="c1"># Create DataLoaders</code>
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">32</code>
<code class="n">train_loader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">train_dataset</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">,</code> <code class="n">shuffle</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">val_loader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">val_dataset</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">,</code> <code class="n">shuffle</code><code class="o">=</code><code class="kc">False</code><code class="p">)</code></pre>
          <p>The important thing to remember now is that your data is a dataset, so you can easily use it in model training without further coding.</p>
          <p>If you want to inspect what the data looks like, you can do so with code like this:</p>
          <pre data-code-language="python" data-type="programlisting"><code class="n">features</code><code class="p">,</code> <code class="n">target</code> <code class="o">=</code> <code class="n">train_dataset</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>
<code class="nb">print</code><code class="p">(</code><code class="s2">"First window:"</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Features shape: </code><code class="si">{</code><code class="n">features</code><code class="o">.</code><code class="n">shape</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Features: </code><code class="si">{</code><code class="n">features</code><code class="o">.</code><code class="n">numpy</code><code class="p">()</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Target: </code><code class="si">{</code><code class="n">target</code><code class="o">.</code><code class="n">item</code><code class="p">()</code><code class="si">}</code><code class="se">\n</code><code class="s2">"</code><code class="p">)</code>
 </pre>
          <p>Here, the <code>batch_size</code> is set to <code>1</code>, just to make the results more readable. You’ll therefore end up with output like this, in which a single set of data is in the batch:</p>
          <pre data-code-language="python" data-type="programlisting"><code class="n">First</code> <code class="n">window</code><code class="p">:</code>
<code class="n">Features</code> <code class="n">shape</code><code class="p">:</code> <code class="n">torch</code><code class="o">.</code><code class="n">Size</code><code class="p">([</code><code class="mi">29</code><code class="p">])</code>
<code class="n">Features</code><code class="p">:</code> <code class="p">[</code><code class="mf">32.48357</code>  <code class="mf">29.395714</code> <code class="mf">33.40659</code>  <code class="mf">37.858486</code> <code class="mf">29.14184</code>  <code class="mf">29.20528</code>  <code class="mf">38.32948</code>
 <code class="mf">34.322147</code> <code class="mf">28.183279</code> <code class="mf">33.283253</code> <code class="mf">28.287313</code> <code class="mf">28.303862</code> <code class="mf">31.864614</code> <code class="mf">21.104889</code>
 <code class="mf">22.057411</code> <code class="mf">27.875519</code> <code class="mf">25.622026</code> <code class="mf">32.25094</code>  <code class="mf">26.127428</code> <code class="mf">23.588236</code> <code class="mf">37.95459</code>
 <code class="mf">29.468477</code> <code class="mf">30.900469</code> <code class="mf">23.39905</code>  <code class="mf">27.755371</code> <code class="mf">30.980967</code> <code class="mf">24.615065</code> <code class="mf">32.186863</code>
 <code class="mf">27.23822</code> <code class="p">]</code>
<code class="n">Target</code><code class="p">:</code> <code class="mf">28.71073341369629</code>
 </pre>
          <p>The first batch of numbers are the features. We’ve set the window size to 30, so it’s a <span class="keep-together">1 × 30</span> tensor. The second number is the label (28.710 in this case), which the model will try to fit the features to. You’ll see how that works in the next section.<a contenteditable="false" data-primary="" data-startref="ch10synwin" data-type="indexterm" id="id1447"/><a contenteditable="false" data-primary="" data-startref="ch10synwin2" data-type="indexterm" id="id1448"/></p>
        </div></section>
      </div></section>
      <section data-pdf-bookmark="Creating and Training a DNN to Fit the Sequence Data" data-type="sect1"><div class="sect1" id="ch10_creating_and_training_a_dnn_to_fit_the_sequence_da_1748549713796262">
        <h1>Creating and Training a DNN to Fit the Sequence Data</h1>
        <p>Now that you have the data,<a contenteditable="false" data-primary="deep neural networks (DNNs)" data-secondary="time series data" data-type="indexterm" id="id1449"/><a contenteditable="false" data-primary="time series data" data-secondary="predicting with ML models" data-tertiary="deep neural network" data-type="indexterm" id="id1450"/> creating a neural network model becomes very straightforward. Let’s first explore a simple DNN. Here’s the model definition:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="c1"># Define the model</code>
<code class="k">class</code> <code class="nc">TimeSeriesModel</code><code class="p">(</code><code class="n">nn</code><code class="o">.</code><code class="n">Module</code><code class="p">):</code>
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">window_size</code><code class="p">):</code>
        <code class="nb">super</code><code class="p">(</code><code class="n">TimeSeriesModel</code><code class="p">,</code> <code class="bp">self</code><code class="p">)</code><code class="o">.</code><code class="fm">__init__</code><code class="p">()</code>
        <code class="c1"># window_size-1 because our features are window_size-1</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">network</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">Sequential</code><code class="p">(</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="n">window_size</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">10</code><code class="p">),</code>  
            <code class="n">nn</code><code class="o">.</code><code class="n">ReLU</code><code class="p">(),</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">10</code><code class="p">),</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">ReLU</code><code class="p">(),</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>
        <code class="p">)</code>
 
    <code class="k">def</code> <code class="nf">forward</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">x</code><code class="p">):</code>
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">network</code><code class="p">(</code><code class="n">x</code><code class="p">)</code>
 </pre>
        <p>It’s a super-simple model with three linear layers, the first of which accepts the input shape of <code>window_size</code> and then a hidden layer of 10 neurons, before an output layer that will contain the predicted value.</p>
        <p>The model is initialized with a loss function and optimizer, as before: </p>
        <pre data-code-language="python" data-type="programlisting"><code class="c1"># Initialize model, loss function, and optimizer</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">TimeSeriesModel</code><code class="p">(</code><code class="n">window_size</code><code class="p">)</code>
<code class="n">criterion</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">MSELoss</code><code class="p">()</code>
<code class="n">optimizer</code> <code class="o">=</code> <code class="n">optim</code><code class="o">.</code><code class="n">Adam</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">parameters</code><code class="p">())</code></pre>
        <p>In this case, the loss function<a contenteditable="false" data-primary="loss functions" data-secondary="MSELoss for regression problems" data-type="indexterm" id="id1451"/><a contenteditable="false" data-primary="MSELoss loss function" data-type="indexterm" id="id1452"/><a contenteditable="false" data-primary="Adam optimizer" data-secondary="time series DNN" data-type="indexterm" id="id1453"/><a contenteditable="false" data-primary="optimizers" data-secondary="Adam" data-tertiary="time series DNN" data-type="indexterm" id="id1454"/> is specified as <code>MSELoss</code>, which stands for “mean squared error” and is commonly used in regression problems (which is what this ultimately boils down to). For the optimizer, <code>Adam</code> is a good fit. <a contenteditable="false" data-primary="“Deep Learning Specialization” (Coursera by Ng)" data-primary-sortas="Deep Learning Specialization" data-type="indexterm" id="id1455"/><a contenteditable="false" data-primary="Ng, Andrew" data-type="indexterm" id="id1456"/>I won’t go into detail on these types of functions in this book, but any good resource on ML will teach you about them—Andrew Ng’s seminal “<a href="https://oreil.ly/A8QzN">Deep Learning Specialization</a>” on Coursera is a great place to start. </p>
        <p>Training is then pretty standard. It’s composed of loading the batches from the training loader and performing a forward pass with them, followed by a backward pass with optimization:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="k">for</code> <code class="n">batch_features</code><code class="p">,</code> <code class="n">batch_targets</code> <code class="ow">in</code> <code class="n">train_loader</code><code class="p">:</code>
    <code class="n">batch_features</code> <code class="o">=</code> <code class="n">batch_features</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
    <code class="n">batch_targets</code> <code class="o">=</code> <code class="n">batch_targets</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
 
    <code class="c1"># Forward pass</code>
    <code class="n">outputs</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">batch_features</code><code class="p">)</code>
    <code class="n">loss</code> <code class="o">=</code> <code class="n">criterion</code><code class="p">(</code><code class="n">outputs</code><code class="p">,</code> <code class="n">batch_targets</code><code class="p">)</code>
 
    <code class="c1"># Backward pass and optimize</code>
    <code class="n">optimizer</code><code class="o">.</code><code class="n">zero_grad</code><code class="p">()</code>
    <code class="n">loss</code><code class="o">.</code><code class="n">backward</code><code class="p">()</code>
    <code class="n">optimizer</code><code class="o">.</code><code class="n">step</code><code class="p">()</code>
 
    <code class="n">train_loss</code> <code class="o">+=</code> <code class="n">loss</code><code class="o">.</code><code class="n">item</code><code class="p">()</code></pre>
        <p>Given that we also have a validation dataset, we can also perform a validation pass for each epoch:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="c1"># Validation phase</code>
<code class="n">model</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code>
<code class="n">val_loss</code> <code class="o">=</code> <code class="mi">0</code>
<code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code>
    <code class="k">for</code> <code class="n">batch_features</code><code class="p">,</code> <code class="n">batch_targets</code> <code class="ow">in</code> <code class="n">val_loader</code><code class="p">:</code>
        <code class="n">batch_features</code> <code class="o">=</code> <code class="n">batch_features</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
        <code class="n">batch_targets</code> <code class="o">=</code> <code class="n">batch_targets</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
 
        <code class="n">outputs</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">batch_features</code><code class="p">)</code>
        <code class="n">val_loss</code> <code class="o">+=</code> <code class="n">criterion</code><code class="p">(</code><code class="n">outputs</code><code class="p">,</code> <code class="n">batch_targets</code><code class="p">)</code><code class="o">.</code><code class="n">item</code><code class="p">()</code>
 
<code class="c1"># Calculate average losses</code>
<code class="n">train_loss</code> <code class="o">/=</code> <code class="nb">len</code><code class="p">(</code><code class="n">train_loader</code><code class="p">)</code>
<code class="n">val_loss</code> <code class="o">/=</code> <code class="nb">len</code><code class="p">(</code><code class="n">val_loader</code><code class="p">)</code>
 
<code class="n">train_losses</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">train_loss</code><code class="p">)</code>
<code class="n">val_losses</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">val_loss</code><code class="p">)</code></pre>
        <p>As you train, you’ll see the loss function report a number that will start high but decline steadily. <a data-type="xref" href="#ch10_figure_4_1748549713788413">Figure 10-4</a> shows the loss over 100 epochs.</p>
        <figure><div class="figure" id="ch10_figure_4_1748549713788413">
          <img src="assets/aiml_1004.png"/>
          <h6><span class="label">Figure 10-4. </span>The DNN predictor of model loss over time for the time series data</h6>
        </div></figure>
      </div></section>
      <section data-pdf-bookmark="Evaluating the Results of the DNN" data-type="sect1"><div class="sect1" id="ch10_evaluating_the_results_of_the_dnn_1748549713796347">
        <h1>Evaluating the Results of the DNN</h1>
        <p>Once you have a trained DNN,<a contenteditable="false" data-primary="deep neural networks (DNNs)" data-secondary="time series data" data-tertiary="evaluating the results" data-type="indexterm" id="ch10eval"/><a contenteditable="false" data-primary="time series data" data-secondary="predicting with ML models" data-tertiary="evaluating the results" data-type="indexterm" id="ch10eval2"/> you can start predicting with it. But remember, you have a windowed dataset, so the prediction for a given point is based on the values of a certain number of time steps before it.</p>
        <p>Also, given that the dataset is batched, we can easily use the loaders to access batches and explore what it looks like to predict on them. </p>
        <p>Here’s the code. We iterate through each batch in the loader and get the features and targets, and then we can get the predictions for the batch by sending the batch to the model:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="k">for</code> <code class="n">batch_features</code><code class="p">,</code> <code class="n">batch_targets</code> <code class="ow">in</code> <code class="n">val_loader</code><code class="p">:</code>
    <code class="n">batch_features</code> <code class="o">=</code> <code class="n">batch_features</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
    <code class="n">predictions</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">batch_features</code><code class="p">)</code>
    <code class="n">val_predictions</code><code class="o">.</code><code class="n">extend</code><code class="p">(</code><code class="n">predictions</code><code class="o">.</code><code class="n">cpu</code><code class="p">()</code><code class="o">.</code><code class="n">numpy</code><code class="p">())</code>
    <code class="n">val_targets</code><code class="o">.</code><code class="n">extend</code><code class="p">(</code><code class="n">batch_targets</code><code class="o">.</code><code class="n">numpy</code><code class="p">())</code></pre>
        <p>The predictions are then converted from PyTorch tensors into NumPy arrays using <code>.numpy()</code>, and then the batches are turned into a single list with the <code>extend()</code> call.</p>
        <p>You might have also noticed the <code>.cpu()</code> in this code. PyTorch allows you to designate <em>where</em> your code runs, and if you have a GPU or other accelerator available, you can push the intense calculations of ML to it. You can also use a CPU to do other things like processing and preprocessing data to save accelerator time. This code allows you to explicitly express that.</p>
        <p>So, you can then compare your predictions with the actual values quite easily. Here’s the code you use to plot the predicted values against the actual ones using matplotlib:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="c1"># Make predictions</code>
<code class="n">model</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code>
<code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code>
    <code class="c1"># Get predictions for validation set</code>
    <code class="n">val_predictions</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="n">val_targets</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="k">for</code> <code class="n">batch_features</code><code class="p">,</code> <code class="n">batch_targets</code> <code class="ow">in</code> <code class="n">val_loader</code><code class="p">:</code>
        <code class="n">batch_features</code> <code class="o">=</code> <code class="n">batch_features</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
        <code class="n">outputs</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">batch_features</code><code class="p">)</code>
        <code class="n">val_predictions</code><code class="o">.</code><code class="n">extend</code><code class="p">(</code><code class="n">outputs</code><code class="o">.</code><code class="n">cpu</code><code class="p">()</code><code class="o">.</code><code class="n">numpy</code><code class="p">())</code>
        <code class="n">val_targets</code><code class="o">.</code><code class="n">extend</code><code class="p">(</code><code class="n">batch_targets</code><code class="o">.</code><code class="n">numpy</code><code class="p">())</code>
 
<code class="c1"># Plot predictions vs actual for validation set</code>
<code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">15</code><code class="p">,</code> <code class="mi">6</code><code class="p">))</code>
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">val_targets</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s1">'Actual'</code><code class="p">,</code> <code class="n">color</code><code class="o">=</code><code class="s2">"lightgrey"</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">val_predictions</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s1">'Predicted'</code><code class="p">,</code> <code class="n">color</code><code class="o">=</code><code class="s2">"red"</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'Predictions vs Actual Values (Validation Set)'</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'Time'</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'Value'</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">()</code>
<code class="n">plt</code><code class="o">.</code><code class="n">grid</code><code class="p">(</code><code class="kc">True</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>
        <p>You can see the results of this in <a data-type="xref" href="#ch10_figure_5_1748549713788437">Figure 10-5</a>. The line for the predicted values (in red) closely matches the overall pattern of the original data, but it’s less noisy, with a lot less variance.</p>
        <figure><div class="figure" id="ch10_figure_5_1748549713788437">
          <img src="assets/aiml_1005.png"/>
          <h6><span class="label">Figure 10-5. </span>Predicted versus actual values in the validation set</h6>
        </div></figure>
        <p>From a quick visual inspection, you can see that the prediction isn’t bad because it’s generally following the curve of the original data. When there are rapid changes in the data, the prediction takes a little time to catch up, but on the whole, it isn’t bad.</p>
        <p>However, it’s hard to be precise when eyeballing the curve. It’s best to have a good metric, and in <a data-type="xref" href="ch09.html#ch09_understanding_sequence_and_time_series_data_1748549698134578">Chapter 9</a> you learned about one—the MAE.<a contenteditable="false" data-primary="mean absolute error (MAE)" data-secondary="measuring time series prediction accuracy" data-type="indexterm" id="id1457"/> Now that you have the valid data and the results, you can measure the MAE with this code by using <code>torch.mean</code> and <code>torch.abs</code>:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="n">val_predictions_tensor</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="n">val_predictions</code><code class="p">)</code>
<code class="n">val_targets_tensor</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="n">val_targets</code><code class="p">)</code>
<code class="n">mae_torch</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">torch</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code>
                       <code class="n">val_predictions_tensor</code> <code class="err">–</code> <code class="n">val_targets_tensor</code><code class="p">))</code>
<code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Validation MAE (PyTorch): </code><code class="si">{</code><code class="n">mae_torch</code><code class="si">:</code><code class="s2">.4f</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
 </pre>
        <p>Randomness has been introduced into the data, so your results may vary, but when I tried it, I got a value of 4.57 as the MAE.</p>
        <p>You could also argue that at this point, the process of getting the predictions as accurate has become the process of minimizing that MAE. There are some techniques that you can use to do this, including the obvious changing of the window size. I’ll leave you to experiment with that, but in the next section, you’ll do some basic hyperparameter tuning on the optimizer to improve how your neural network learns, and see what impact that will have on the MAE.<a contenteditable="false" data-primary="" data-startref="ch10eval" data-type="indexterm" id="id1458"/><a contenteditable="false" data-primary="" data-startref="ch10eval2" data-type="indexterm" id="id1459"/></p>
      </div></section>
      <section class="pagebreak-before less_space" data-pdf-bookmark="Tuning the Learning Rate" data-type="sect1"><div class="sect1" id="ch10_tuning_the_learning_rate_1748549713796412">
        <h1>Tuning the Learning Rate</h1>
        <p>In the previous example,<a contenteditable="false" data-primary="time series data" data-secondary="predicting with ML models" data-tertiary="learning rate tuned" data-type="indexterm" id="id1460"/><a contenteditable="false" data-primary="Adam optimizer" data-secondary="time series DNN" data-tertiary="learning rate tuned" data-type="indexterm" id="id1461"/><a contenteditable="false" data-primary="optimizers" data-secondary="Adam" data-tertiary="learning rate tuned" data-type="indexterm" id="id1462"/><a contenteditable="false" data-primary="learning rate (LR)" data-secondary="tuning for time series DNN" data-type="indexterm" id="id1463"/><a contenteditable="false" data-primary="Adam optimizer" data-secondary="learning rate parameter adjustment" data-type="indexterm" id="id1464"/> you might recall that you compiled the model with an optimizer that looked like this:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="n">optimizer</code> <code class="o">=</code> <code class="n">optim</code><code class="o">.</code><code class="n">Adam</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">parameters</code><code class="p">())</code></pre>
        <p>In that case, you didn’t specify an LR, so the model used the default LR of 1 × 10<sup>–</sup><sup>3</sup>. But that seemed to be a really arbitrary number. What if you changed it, and how should you go about changing it? It would take a lot of experimentation to find the best rate.</p>
        <p>One way to experiment with this is by using a <code>torch.optim.lr_scheduler,</code> which can change the LR on the fly, epoch by epoch, as the model trains.</p>
        <p>A good practice is to start with a higher LR and gradually reduce it as the network learns. Here’s an example:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="n">optimizer</code> <code class="o">=</code> <code class="n">optim</code><code class="o">.</code><code class="n">Adam</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">parameters</code><code class="p">(),</code> <code class="n">lr</code><code class="o">=</code><code class="mf">0.01</code><code class="p">)</code> </pre>
        <p>In this case, you’re going to start the LR at 1e – 2, which is really high. However, you can set a scheduler to multiply the LR rate by a “gamma” amount every <em>n</em> epochs. So, for example, the following code will change it every 30 epochs. We’ll start at 0.01, and then, after the thirtieth epoch, it will multiply the LR by .1 to get 0.001. After 60, it will be 0.0001, etc.:</p>
        <pre data-code-language="python" data-type="programlisting"><code class="n">scheduler</code> <code class="o">=</code> <code class="n">lr_scheduler</code><code class="o">.</code><code class="n">StepLR</code><code class="p">(</code><code class="n">optimizer</code><code class="p">,</code> <code class="n">step_size</code><code class="o">=</code><code class="mi">30</code><code class="p">,</code> <code class="n">gamma</code><code class="o">=</code><code class="mf">0.1</code><code class="p">)</code></pre>
        <p>When we run the scheduler like this, the performance improves a little—giving MAE of 4.36. </p>
        <p>You can continue to explore like this by tweaking the LR and also the size of the window—30 days of data to predict 1 day may not be enough, so you might want to try a window of 40 days. Also, try training for more epochs. With a bit of experimentation, you could get an MAE of close to 4, which isn’t bad.</p>
      </div></section>
      <section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="ch10_summary_1748549713796471">
        <h1>Summary</h1>
        <p>In this chapter, you took the statistical analysis of the time series from <a data-type="xref" href="ch09.html#ch09_understanding_sequence_and_time_series_data_1748549698134578">Chapter 9</a> and applied ML to try to do a better job of prediction. ML really is all about pattern matching, and, as expected, you were able to quickly create a deep neural network to spot the patterns with low error before exploring some hyperparameter tuning to improve the accuracy further. </p>
        <p>In <a data-type="xref" href="ch11.html#ch11_using_convolutional_and_recurrent_methods_for_sequ_1748549734762226">Chapter 11</a>, you’ll go beyond a simple DNN and examine the implications of using an RNN to predict sequential values.</p>
      </div></section>
    </div></section></body></html>