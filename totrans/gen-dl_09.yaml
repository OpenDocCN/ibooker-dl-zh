- en: Chapter 6\. Normalizing Flow Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬6ç« ã€‚æ­£è§„åŒ–æµæ¨¡å‹
- en: 'So far, we have discussed three families of generative models: variational
    autoencoders, generative adversarial networks, and autoregressive models. Each
    presents a different way to address the challenge of modeling the distribution
    <math alttext="p left-parenthesis x right-parenthesis"><mrow><mi>p</mi> <mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></math> , either by introducing a latent variable
    that can be easily sampled (and transformed using the decoder in VAEs or generator
    in GANs), or by tractably modeling the distribution as a function of the values
    of preceding elements (autoregressive models).'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»è®¨è®ºäº†ä¸‰ç±»ç”Ÿæˆæ¨¡å‹å®¶æ—ï¼šå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œè‡ªå›å½’æ¨¡å‹ã€‚æ¯ç§æ¨¡å‹éƒ½æå‡ºäº†ä¸åŒçš„æ–¹æ³•æ¥è§£å†³å»ºæ¨¡åˆ†å¸ƒp(x)çš„æŒ‘æˆ˜ï¼Œè¦ä¹ˆé€šè¿‡å¼•å…¥ä¸€ä¸ªå¯ä»¥è½»æ¾é‡‡æ ·çš„æ½œå˜é‡ï¼ˆå¹¶åœ¨VAEä¸­ä½¿ç”¨è§£ç å™¨æˆ–åœ¨GANä¸­ä½¿ç”¨ç”Ÿæˆå™¨è¿›è¡Œè½¬æ¢ï¼‰ï¼Œè¦ä¹ˆé€šè¿‡å¯å¤„ç†åœ°å°†åˆ†å¸ƒå»ºæ¨¡ä¸ºå‰é¢å…ƒç´ å€¼çš„å‡½æ•°ï¼ˆè‡ªå›å½’æ¨¡å‹ï¼‰ã€‚
- en: In this chapter, we will cover a new family of generative modelsâ€”normalizing
    flow models. As we shall see, normalizing flows share similarities with both autoregressive
    models and variational autoencoders. Like autoregressive models, normalizing flows
    are able to explicitly and tractably model the data-generating distribution <math
    alttext="p left-parenthesis x right-parenthesis"><mrow><mi>p</mi> <mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow></math> . Like VAEs, normalizing flows attempt to map the data
    into a simpler distribution, such as a Gaussian distribution. The key difference
    is that normalizing flows place a constraint on the form of the mapping function,
    so that it is invertible and can therefore be used to generate new data points.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€ç§æ–°çš„ç”Ÿæˆæ¨¡å‹å®¶æ—â€”â€”æ­£è§„åŒ–æµæ¨¡å‹ã€‚æ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„ï¼Œæ­£è§„åŒ–æµä¸è‡ªå›å½’æ¨¡å‹å’Œå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨éƒ½æœ‰ç›¸ä¼¼ä¹‹å¤„ã€‚åƒè‡ªå›å½’æ¨¡å‹ä¸€æ ·ï¼Œæ­£è§„åŒ–æµèƒ½å¤Ÿæ˜ç¡®ä¸”å¯å¤„ç†åœ°å»ºæ¨¡æ•°æ®ç”Ÿæˆåˆ†å¸ƒp(x)ã€‚åƒå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ä¸€æ ·ï¼Œæ­£è§„åŒ–æµè¯•å›¾å°†æ•°æ®æ˜ å°„åˆ°ä¸€ä¸ªæ›´ç®€å•çš„åˆ†å¸ƒï¼Œæ¯”å¦‚é«˜æ–¯åˆ†å¸ƒã€‚å…³é”®åŒºåˆ«åœ¨äºï¼Œæ­£è§„åŒ–æµå¯¹æ˜ å°„å‡½æ•°çš„å½¢å¼æ–½åŠ äº†çº¦æŸï¼Œä½¿å…¶å¯é€†ï¼Œå› æ­¤å¯ä»¥ç”¨æ¥ç”Ÿæˆæ–°çš„æ•°æ®ç‚¹ã€‚
- en: We will dig into this definition in detail in the first section of this chapter
    before implementing a normalizing flow model called RealNVP using Keras. We will
    also see how normalizing flows can be extended to create more powerful models,
    such as GLOW and FFJORD.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« çš„ç¬¬ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è¯¦ç»†æ¢è®¨è¿™ä¸ªå®šä¹‰ï¼Œç„¶åä½¿ç”¨Keraså®ç°ä¸€ä¸ªåä¸ºRealNVPçš„æ­£è§„åŒ–æµæ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å°†çœ‹åˆ°å¦‚ä½•æ‰©å±•æ­£è§„åŒ–æµä»¥åˆ›å»ºæ›´å¼ºå¤§çš„æ¨¡å‹ï¼Œå¦‚GLOWå’ŒFFJORDã€‚
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»‹ç»
- en: We will begin with a short story to illustrate the key concepts behind normalizing
    flows.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä»ä¸€ä¸ªç®€çŸ­çš„æ•…äº‹å¼€å§‹ï¼Œä»¥é˜æ˜æ­£è§„åŒ–æµèƒŒåçš„å…³é”®æ¦‚å¿µã€‚
- en: The story of Jacob and the F.L.O.W. machine is a depiction of a normalizing
    flow model. Letâ€™s now explore the theory of normalizing flows in more detail,
    before we implement a practical example using Keras.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: é›…å„å¸ƒå’ŒF.L.O.W.æœºå™¨çš„æ•…äº‹æ˜¯å¯¹æ­£è§„åŒ–æµæ¨¡å‹çš„æè¿°ã€‚ç°åœ¨è®©æˆ‘ä»¬æ›´è¯¦ç»†åœ°æ¢è®¨æ­£è§„åŒ–æµçš„ç†è®ºï¼Œç„¶ååœ¨ä½¿ç”¨Keraså®ç°ä¸€ä¸ªå®é™…ç¤ºä¾‹ä¹‹å‰ã€‚
- en: Normalizing Flows
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ­£è§„åŒ–æµ
- en: The motivation of normalizing flow models is similar to that of variational
    autoencoders, which we explored in [ChapterÂ 3](ch03.xhtml#chapter_vae). To recap,
    in a variational autoencoder, we learn an *encoder* mapping function between a
    complex distribution and a much simpler distribution that we can sample from.
    We then also learn a *decoder* mapping function from the simpler distribution
    to the complex distribution, so that we can generate a new data point by sampling
    a point <math alttext="z"><mi>z</mi></math> from the simpler distribution and
    applying the learned transformation. Probabilistically speaking, the decoder models
    <math alttext="p left-parenthesis x vertical-bar z right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>z</mi> <mo>)</mo></mrow></math> but the encoder
    is only an approximation <math alttext="q left-parenthesis z vertical-bar x right-parenthesis"><mrow><mi>q</mi>
    <mo>(</mo> <mi>z</mi> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow></math> of the true
    <math alttext="p left-parenthesis z vertical-bar x right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <mi>z</mi> <mo>|</mo> <mi>x</mi> <mo>)</mo></mrow></math> â€”the encoder
    and decoder are two completely distinct neural networks.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£è§„åŒ–æµæ¨¡å‹çš„åŠ¨æœºä¸æˆ‘ä»¬åœ¨ç¬¬3ç« ä¸­æ¢è®¨çš„å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨çš„åŠ¨æœºç±»ä¼¼ã€‚ç®€è€Œè¨€ä¹‹ï¼Œåœ¨å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ ä¸€ä¸ª*ç¼–ç å™¨*æ˜ å°„å‡½æ•°ï¼Œå°†ä¸€ä¸ªå¤æ‚åˆ†å¸ƒæ˜ å°„åˆ°ä¸€ä¸ªæˆ‘ä»¬å¯ä»¥ä»ä¸­é‡‡æ ·çš„ç®€å•åˆ†å¸ƒã€‚ç„¶åæˆ‘ä»¬è¿˜å­¦ä¹ ä¸€ä¸ª*è§£ç å™¨*æ˜ å°„å‡½æ•°ï¼Œä»ç®€å•åˆ†å¸ƒåˆ°å¤æ‚åˆ†å¸ƒï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥é€šè¿‡ä»ç®€å•åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ªç‚¹zå¹¶åº”ç”¨å­¦ä¹ åˆ°çš„è½¬æ¢æ¥ç”Ÿæˆä¸€ä¸ªæ–°çš„æ•°æ®ç‚¹ã€‚ä»æ¦‚ç‡ä¸Šè®²ï¼Œè§£ç å™¨å»ºæ¨¡p(x|z)ï¼Œä½†ç¼–ç å™¨åªæ˜¯çœŸå®p(z|x)çš„è¿‘ä¼¼â€”ç¼–ç å™¨å’Œè§£ç å™¨æ˜¯ä¸¤ä¸ªå®Œå…¨ä¸åŒçš„ç¥ç»ç½‘ç»œã€‚
- en: In a normalizing flow model, the decoding function is designed to be the exact
    inverse of the encoding function and quick to calculate, giving normalizing flows
    the property of tractability. However, neural networks are not by default invertible
    functions. This raises the question of how we can create an invertible process
    that converts between a complex distribution (such as the data generation distribution
    of a set of watercolor paintings) and a much simpler distribution (such as a bell-shaped
    Gaussian distribution) while still making use of the flexibility and power of
    deep learning.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ­£è§„åŒ–æµæ¨¡å‹ä¸­ï¼Œè§£ç å‡½æ•°è¢«è®¾è®¡ä¸ºç¼–ç å‡½æ•°çš„ç²¾ç¡®é€†å‡½æ•°ä¸”è®¡ç®—è¿…é€Ÿï¼Œä½¿å¾—æ­£è§„åŒ–æµå…·æœ‰å¯å¤„ç†æ€§è´¨ã€‚ç„¶è€Œï¼Œç¥ç»ç½‘ç»œé»˜è®¤æƒ…å†µä¸‹ä¸æ˜¯å¯é€†å‡½æ•°ã€‚è¿™å¼•å‘äº†ä¸€ä¸ªé—®é¢˜ï¼Œå³æˆ‘ä»¬å¦‚ä½•åˆ›å»ºä¸€ä¸ªå¯é€†è¿‡ç¨‹ï¼Œå°†ä¸€ä¸ªå¤æ‚åˆ†å¸ƒï¼ˆå¦‚ä¸€ç»„æ°´å½©ç”»çš„æ•°æ®ç”Ÿæˆåˆ†å¸ƒï¼‰è½¬æ¢ä¸ºä¸€ä¸ªæ›´ç®€å•çš„åˆ†å¸ƒï¼ˆå¦‚é’Ÿå½¢é«˜æ–¯åˆ†å¸ƒï¼‰ï¼ŒåŒæ—¶ä»ç„¶åˆ©ç”¨æ·±åº¦å­¦ä¹ çš„çµæ´»æ€§å’Œå¼ºå¤§æ€§ã€‚
- en: To answer this question, we first need to understand a technique known as *change
    of variables*. For this section, we will work with a simple example in just two
    dimensions, so that you can see exactly how normalizing flows work in fine detail.
    More complex examples are just extensions of the basic techniques presented here.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦äº†è§£ä¸€ç§ç§°ä¸º*å˜é‡å˜æ¢*çš„æŠ€æœ¯ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªç®€å•çš„äºŒç»´ç¤ºä¾‹ï¼Œè¿™æ ·ä½ å¯ä»¥çœ‹åˆ°å½’ä¸€åŒ–æµæ˜¯å¦‚ä½•è¯¦ç»†å·¥ä½œçš„ã€‚æ›´å¤æ‚çš„ä¾‹å­åªæ˜¯åŸºæœ¬æŠ€æœ¯çš„æ‰©å±•ã€‚
- en: Change of Variables
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å˜é‡å˜æ¢
- en: Suppose we have a probability distribution <math alttext="p Subscript upper
    X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi> <mi>X</mi></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math> defined over a rectangle
    <math alttext="upper X"><mi>X</mi></math> in two dimensions ( <math alttext="x
    equals left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><mi>x</mi> <mo>=</mo>
    <mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></math> ), as shown in [FigureÂ 6-2](#simple_prob).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåœ¨äºŒç»´çŸ©å½¢<math alttext="upper X"><mi>X</mi></math>ä¸Šå®šä¹‰çš„æ¦‚ç‡åˆ†å¸ƒ<math alttext="p
    Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>ï¼ˆ<math
    alttext="x equals left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><mi>x</mi>
    <mo>=</mo> <mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math>ï¼‰ï¼Œå¦‚[å›¾6-2](#simple_prob)æ‰€ç¤ºã€‚
- en: '![https://www.math3d.org/VlDIWw2AK](Images/gdl2_0602.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![https://www.math3d.org/VlDIWw2AK](Images/gdl2_0602.png)'
- en: Figure 6-2\. A probability distribution <math alttext="p Subscript upper X Baseline
    left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi> <mi>X</mi></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math> defined over two dimensions,
    shown in 2D (left) and 3D (right)
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-2ã€‚åœ¨äºŒç»´ç©ºé—´ä¸­å®šä¹‰çš„æ¦‚ç‡åˆ†å¸ƒ<math alttext="p Subscript upper X Baseline left-parenthesis
    x right-parenthesis"><mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>ï¼Œåœ¨2Dï¼ˆå·¦ï¼‰å’Œ3Dï¼ˆå³ï¼‰ä¸­æ˜¾ç¤º
- en: 'This function integrates to 1 over the domain of the distribution (i.e., <math
    alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> in the range [1, 4] and
    <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math> in the range [0,
    2]), so it represents a well-defined probability distribution. We can write this
    as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªå‡½æ•°åœ¨åˆ†å¸ƒçš„å®šä¹‰åŸŸä¸Šç§¯åˆ†ä¸º1ï¼ˆå³<math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>åœ¨èŒƒå›´[1,
    4]ï¼Œ<math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>åœ¨èŒƒå›´[0, 2]ï¼‰ï¼Œå› æ­¤å®ƒä»£è¡¨äº†ä¸€ä¸ªæ˜ç¡®å®šä¹‰çš„æ¦‚ç‡åˆ†å¸ƒã€‚æˆ‘ä»¬å¯ä»¥å†™æˆå¦‚ä¸‹å½¢å¼ï¼š
- en: <math alttext="integral Subscript 0 Superscript 2 Baseline integral Subscript
    1 Superscript 4 Baseline p Subscript upper X Baseline left-parenthesis x right-parenthesis
    d x 1 d x 2 equals 1" display="block"><mrow><msubsup><mo>âˆ«</mo> <mrow><mn>0</mn></mrow>
    <mn>2</mn></msubsup> <msubsup><mo>âˆ«</mo> <mrow><mn>1</mn></mrow> <mn>4</mn></msubsup>
    <msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mi>d</mi> <msub><mi>x</mi> <mn>1</mn></msub> <mi>d</mi> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>=</mo> <mn>1</mn></mrow></math>
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="integral Subscript 0 Superscript 2 Baseline integral Subscript
    1 Superscript 4 Baseline p Subscript upper X Baseline left-parenthesis x right-parenthesis
    d x 1 d x 2 equals 1" display="block"><mrow><msubsup><mo>âˆ«</mo> <mrow><mn>0</mn></mrow>
    <mn>2</mn></msubsup> <msubsup><mo>âˆ«</mo> <mrow><mn>1</mn></mrow> <mn>4</mn></msubsup>
    <msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mi>d</mi> <msub><mi>x</mi> <mn>1</mn></msub> <mi>d</mi> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>=</mo> <mn>1</mn></mrow></math>
- en: 'Letâ€™s say that we want to shift and scale this distribution so that it is instead
    defined over a unit square <math alttext="upper Z"><mi>Z</mi></math> . We can
    achieve this by defining a new variable <math alttext="z equals left-parenthesis
    z 1 comma z 2 right-parenthesis"><mrow><mi>z</mi> <mo>=</mo> <mo>(</mo> <msub><mi>z</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>z</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>
    and a function <math alttext="f"><mi>f</mi></math> that maps each point in <math
    alttext="upper X"><mi>X</mi></math> to exactly one point in <math alttext="upper
    Z"><mi>Z</mi></math> as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 'å‡è®¾æˆ‘ä»¬æƒ³è¦ç§»åŠ¨å’Œç¼©æ”¾è¿™ä¸ªåˆ†å¸ƒï¼Œä½¿å…¶åœ¨ä¸€ä¸ªå•ä½æ­£æ–¹å½¢<math alttext="upper Z"><mi>Z</mi></math>ä¸Šå®šä¹‰ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å®šä¹‰ä¸€ä¸ªæ–°å˜é‡<math
    alttext="z equals left-parenthesis z 1 comma z 2 right-parenthesis"><mrow><mi>z</mi>
    <mo>=</mo> <mo>(</mo> <msub><mi>z</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>z</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math>å’Œä¸€ä¸ªå°†<math alttext="upper X"><mi>X</mi></math>ä¸­çš„æ¯ä¸ªç‚¹æ˜ å°„åˆ°<math
    alttext="upper Z"><mi>Z</mi></math>ä¸­çš„ä¸€ä¸ªç‚¹çš„å‡½æ•°<math alttext="f"><mi>f</mi></math>æ¥å®ç°è¿™ä¸€ç‚¹ï¼š '
- en: <math alttext="StartLayout 1st Row 1st Column z 2nd Column equals 3rd Column
    f left-parenthesis x right-parenthesis 2nd Row 1st Column z 1 2nd Column equals
    3rd Column StartFraction x 1 minus 1 Over 3 EndFraction 3rd Row 1st Column z 2
    2nd Column equals 3rd Column StartFraction x 2 Over 2 EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mi>z</mi></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>z</mi> <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo><mn>1</mn></mrow>
    <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>z</mi>
    <mn>2</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><msub><mi>x</mi>
    <mn>2</mn></msub> <mn>2</mn></mfrac></mtd></mtr></mtable></math>
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column z 2nd Column equals 3rd Column
    f left-parenthesis x right-parenthesis 2nd Row 1st Column z 1 2nd Column equals
    3rd Column StartFraction x 1 minus 1 Over 3 EndFraction 3rd Row 1st Column z 2
    2nd Column equals 3rd Column StartFraction x 2 Over 2 EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mi>z</mi></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>z</mi> <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>-</mo><mn>1</mn></mrow>
    <mn>3</mn></mfrac></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>z</mi>
    <mn>2</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><msub><mi>x</mi>
    <mn>2</mn></msub> <mn>2</mn></mfrac></mtd></mtr></mtable></math>
- en: Note that this function is *invertible*. That is, there is a function <math
    alttext="g"><mi>g</mi></math> that maps every <math alttext="z"><mi>z</mi></math>
    back to its corresponding <math alttext="x"><mi>x</mi></math> . This is essential
    for a change of variables, as otherwise we cannot consistently map backward and
    forward between the two spaces. We can find <math alttext="g"><mi>g</mi></math>
    simply by rearranging the equations that define <math alttext="f"><mi>f</mi></math>
    , as shown in [FigureÂ 6-3](#change_of_variables).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œè¿™ä¸ªå‡½æ•°æ˜¯*å¯é€†çš„*ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæœ‰ä¸€ä¸ªå‡½æ•°<math alttext="g"><mi>g</mi></math>ï¼Œå®ƒå°†æ¯ä¸ª<math alttext="z"><mi>z</mi></math>æ˜ å°„å›å…¶å¯¹åº”çš„<math
    alttext="x"><mi>x</mi></math>ã€‚è¿™å¯¹äºå˜é‡å˜æ¢æ˜¯å¿…ä¸å¯å°‘çš„ï¼Œå¦åˆ™æˆ‘ä»¬æ— æ³•åœ¨ä¸¤ä¸ªç©ºé—´ä¹‹é—´ä¸€è‡´åœ°è¿›è¡Œå‰å‘å’Œåå‘æ˜ å°„ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•åœ°é‡æ–°æ’åˆ—å®šä¹‰<math
    alttext="f"><mi>f</mi></math>çš„æ–¹ç¨‹æ¥æ‰¾åˆ°<math alttext="g"><mi>g</mi></math>ï¼Œå¦‚[å›¾6-3](#change_of_variables)æ‰€ç¤ºã€‚
- en: '![](Images/gdl2_0603.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0603.png)'
- en: Figure 6-3\. Changing variables between <math alttext="upper X"><mi>X</mi></math>
    and <math alttext="upper Z"><mi>Z</mi></math>
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-3ã€‚åœ¨<math alttext="upper X"><mi>X</mi></math>å’Œ<math alttext="upper Z"><mi>Z</mi></math>ä¹‹é—´æ”¹å˜å˜é‡
- en: 'We now need to see how the change of variables from <math alttext="upper X"><mi>X</mi></math>
    to <math alttext="upper Z"><mi>Z</mi></math> affects the probability distribution
    <math alttext="p Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    . We can do this by plugging the equations that define <math alttext="g"><mi>g</mi></math>
    into <math alttext="p Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    to transform it into a function <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> that is defined in terms of <math alttext="z"><mi>z</mi></math>
    :'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬éœ€è¦çœ‹çœ‹ä»<math alttext="upper X"><mi>X</mi></math>åˆ°<math alttext="upper Z"><mi>Z</mi></math>çš„å˜é‡å˜æ¢å¦‚ä½•å½±å“æ¦‚ç‡åˆ†å¸ƒ<math
    alttext="p Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡å°†å®šä¹‰<math
    alttext="g"><mi>g</mi></math>çš„æ–¹ç¨‹ä»£å…¥<math alttext="p Subscript upper X Baseline
    left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi> <mi>X</mi></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>æ¥å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ªä»¥<math alttext="z"><mi>z</mi></math>ä¸ºå˜é‡çš„å‡½æ•°<math
    alttext="p Subscript upper Z Baseline left-parenthesis z right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>Z</mi></msub> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></math>ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis 2nd Column equals 3rd Column StartFraction left-parenthesis
    left-parenthesis 3 z 1 plus 1 right-parenthesis minus 1 right-parenthesis left-parenthesis
    2 z 2 right-parenthesis Over 9 EndFraction 2nd Row 1st Column Blank 2nd Column
    equals 3rd Column StartFraction 2 z 1 z 2 Over 3 EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mrow><mo>(</mo><mrow><mo>(</mo><mn>3</mn><msub><mi>z</mi>
    <mn>1</mn></msub> <mo>+</mo><mn>1</mn><mo>)</mo></mrow><mo>-</mo><mn>1</mn><mo>)</mo></mrow><mrow><mo>(</mo><mn>2</mn><msub><mi>z</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></mrow> <mn>9</mn></mfrac></mtd></mtr> <mtr><mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mn>2</mn><msub><mi>z</mi> <mn>1</mn></msub>
    <msub><mi>z</mi> <mn>2</mn></msub></mrow> <mn>3</mn></mfrac></mtd></mtr></mtable></math>
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis 2nd Column equals 3rd Column StartFraction left-parenthesis
    left-parenthesis 3 z 1 plus 1 right-parenthesis minus 1 right-parenthesis left-parenthesis
    2 z 2 right-parenthesis Over 9 EndFraction 2nd Row 1st Column Blank 2nd Column
    equals 3rd Column StartFraction 2 z 1 z 2 Over 3 EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mrow><mo>(</mo><mrow><mo>(</mo><mn>3</mn><msub><mi>z</mi>
    <mn>1</mn></msub> <mo>+</mo><mn>1</mn><mo>)</mo></mrow><mo>-</mo><mn>1</mn><mo>)</mo></mrow><mrow><mo>(</mo><mn>2</mn><msub><mi>z</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></mrow> <mn>9</mn></mfrac></mtd></mtr> <mtr><mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mn>2</mn><msub><mi>z</mi> <mn>1</mn></msub>
    <msub><mi>z</mi> <mn>2</mn></msub></mrow> <mn>3</mn></mfrac></mtd></mtr></mtable></math>
- en: However, if we now integrate <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> over the unit square, we can see that
    we have a problem!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬ç°åœ¨åœ¨å•ä½æ­£æ–¹å½¢ä¸Šå¯¹p_Z(z)è¿›è¡Œç§¯åˆ†ï¼Œæˆ‘ä»¬ä¼šå‘ç°æœ‰é—®é¢˜ï¼
- en: <math alttext="integral Subscript 0 Superscript 1 Baseline integral Subscript
    0 Superscript 1 Baseline StartFraction 2 z 1 z 2 Over 3 EndFraction d z 1 d z
    2 equals one-sixth" display="block"><mrow><msubsup><mo>âˆ«</mo> <mrow><mn>0</mn></mrow>
    <mn>1</mn></msubsup> <msubsup><mo>âˆ«</mo> <mrow><mn>0</mn></mrow> <mn>1</mn></msubsup>
    <mfrac><mrow><mn>2</mn><msub><mi>z</mi> <mn>1</mn></msub> <msub><mi>z</mi> <mn>2</mn></msub></mrow>
    <mn>3</mn></mfrac> <mi>d</mi> <msub><mi>z</mi> <mn>1</mn></msub> <mi>d</mi> <msub><mi>z</mi>
    <mn>2</mn></msub> <mo>=</mo> <mfrac><mn>1</mn> <mn>6</mn></mfrac></mrow></math>
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="integral Subscript 0 Superscript 1 Baseline integral Subscript
    0 Superscript 1 Baseline StartFraction 2 z 1 z 2 Over 3 EndFraction d z 1 d z
    2 equals one-sixth" display="block"><mrow><msubsup><mo>âˆ«</mo> <mrow><mn>0</mn></mrow>
    <mn>1</mn></msubsup> <msubsup><mo>âˆ«</mo> <mrow><mn>0</mn></mrow> <mn>1</mn></msubsup>
    <mfrac><mrow><mn>2</mn><msub><mi>z</mi> <mn>1</mn></msub> <msub><mi>z</mi> <mn>2</mn></msub></mrow>
    <mn>3</mn></mfrac> <mi>d</mi> <msub><mi>z</mi> <mn>1</mn></msub> <mi>d</mi> <msub><mi>z</mi>
    <mn>2</mn></msub> <mo>=</mo> <mfrac><mn>1</mn> <mn>6</mn></mfrac></mrow></math>
- en: The transformed function <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> is now no longer a valid probability
    distribution, because it only integrates to 1/6\. If we want to transform our
    complex probability distribution over the data into a simpler distribution that
    we can sample from, we must ensure that it integrates to 1.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè½¬æ¢åçš„å‡½æ•°p_Z(z)ä¸å†æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ¦‚ç‡åˆ†å¸ƒï¼Œå› ä¸ºå®ƒåªç§¯åˆ†åˆ°1/6ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦å°†æ•°æ®ä¸Šçš„å¤æ‚æ¦‚ç‡åˆ†å¸ƒè½¬æ¢ä¸ºä¸€ä¸ªç®€å•çš„æˆ‘ä»¬å¯ä»¥ä»ä¸­æŠ½æ ·çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬å¿…é¡»ç¡®ä¿å®ƒç§¯åˆ†åˆ°1ã€‚
- en: The missing factor of 6 is due to the fact that the domain of our transformed
    probability distribution is six times smaller than the original domainâ€”the original
    rectangle <math alttext="upper X"><mi>X</mi></math> had area 6, and this has been
    compressed into a unit square <math alttext="upper Z"><mi>Z</mi></math> that only
    has area 1\. Therefore, we need to multiply the new probability distribution by
    a normalization factor that is equal to the relative change in area (or volume
    in higher dimensions).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼ºå°‘çš„å› å­6æ˜¯å› ä¸ºæˆ‘ä»¬è½¬æ¢åçš„æ¦‚ç‡åˆ†å¸ƒçš„å®šä¹‰åŸŸæ¯”åŸå§‹å®šä¹‰åŸŸå°äº†å…­å€â€”â€”åŸå§‹çŸ©å½¢Xçš„é¢ç§¯ä¸º6ï¼Œè€Œè¿™è¢«å‹ç¼©æˆäº†åªæœ‰é¢ç§¯ä¸º1çš„å•ä½æ­£æ–¹å½¢Zã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å°†æ–°çš„æ¦‚ç‡åˆ†å¸ƒä¹˜ä»¥ä¸€ä¸ªå½’ä¸€åŒ–å› å­ï¼Œè¯¥å› å­ç­‰äºé¢ç§¯ï¼ˆæˆ–åœ¨æ›´é«˜ç»´åº¦ä¸­çš„ä½“ç§¯ï¼‰çš„ç›¸å¯¹å˜åŒ–ã€‚
- en: Luckily, there is a way to calculate this volume change for a given transformationâ€”it
    is the absolute value of the Jacobian determinant of the transformation. Letâ€™s
    unpack that!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¸è¿çš„æ˜¯ï¼Œæœ‰ä¸€ç§æ–¹æ³•å¯ä»¥è®¡ç®—ç»™å®šå˜æ¢çš„ä½“ç§¯å˜åŒ–â€”â€”å³å˜æ¢çš„é›…å¯æ¯”è¡Œåˆ—å¼çš„ç»å¯¹å€¼ã€‚è®©æˆ‘ä»¬æ¥è§£é‡Šä¸€ä¸‹ï¼
- en: The Jacobian Determinant
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é›…å¯æ¯”è¡Œåˆ—å¼
- en: 'The *Jacobian* of a function <math alttext="z equals f left-parenthesis x right-parenthesis"><mrow><mi>z</mi>
    <mo>=</mo> <mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math> is the matrix
    of its first-order partial derivatives, as shown here:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å‡½æ•°z=f(x)çš„é›…å¯æ¯”çŸ©é˜µæ˜¯å…¶ä¸€é˜¶åå¯¼æ•°çš„çŸ©é˜µï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: <math alttext="normal upper J equals StartFraction normal partial-differential
    z Over normal partial-differential x EndFraction equals Start 3 By 3 Matrix 1st
    Row 1st Column StartFraction normal partial-differential z 1 Over normal partial-differential
    x 1 EndFraction 2nd Column  ellipsis 3rd Column StartFraction normal partial-differential
    z 1 Over normal partial-differential x Subscript n Baseline EndFraction 2nd Row
    1st Column  ellipsis 2nd Column  ellipsis 3rd Row 1st Column StartFraction normal
    partial-differential z Subscript m Baseline Over normal partial-differential x
    1 EndFraction 2nd Column  ellipsis 3rd Column StartFraction normal partial-differential
    z Subscript m Baseline Over normal partial-differential x Subscript n Baseline
    EndFraction EndMatrix" display="block"><mrow><mi mathvariant="normal">J</mi> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>âˆ‚</mi><mi>z</mi></mrow>
    <mrow><mi>âˆ‚</mi><mi>x</mi></mrow></mfrac></mstyle> <mo>=</mo> <mfenced open="["
    close="]"><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>âˆ‚</mi><msub><mi>z</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mstyle></mtd>
    <mtd><mo>â‹¯</mo></mtd> <mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>âˆ‚</mi><msub><mi>z</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mi>n</mi></msub></mrow></mfrac></mstyle></mtd></mtr>
    <mtr><mtd><mo>â‹±</mo></mtd> <mtd><mo>â‹®</mo></mtd></mtr> <mtr><mtd><mstyle scriptlevel="0"
    displaystyle="true"><mfrac><mrow><mi>âˆ‚</mi><msub><mi>z</mi> <mi>m</mi></msub></mrow>
    <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mstyle></mtd>
    <mtd><mo>â‹¯</mo></mtd> <mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>âˆ‚</mi><msub><mi>z</mi>
    <mi>m</mi></msub></mrow> <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mi>n</mi></msub></mrow></mfrac></mstyle></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal upper J equals StartFraction normal partial-differential
    z Over normal partial-differential x EndFraction equals Start 3 By 3 Matrix 1st
    Row 1st Column StartFraction normal partial-differential z 1 Over normal partial-differential
    x 1 EndFraction 2nd Column  ellipsis 3rd Column StartFraction normal partial-differential
    z 1 Over normal partial-differential x Subscript n Baseline EndFraction 2nd Row
    1st Column  ellipsis 2nd Column  ellipsis 3rd Row 1st Column StartFraction normal
    partial-differential z Subscript m Baseline Over normal partial-differential x
    1 EndFraction 2nd Column  ellipsis 3rd Column StartFraction normal partial-differential
    z Subscript m Baseline Over normal partial-differential x Subscript n Baseline
    EndFraction EndMatrix" display="block"><mrow><mi mathvariant="normal">J</mi> <mo>=</mo>
    <mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>âˆ‚</mi><mi>z</mi></mrow>
    <mrow><mi>âˆ‚</mi><mi>x</mi></mrow></mfrac></mstyle> <mo>=</mo> <mfenced open="["
    close="]"><mtable><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>âˆ‚</mi><msub><mi>z</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mstyle></mtd>
    <mtd><mo>â‹¯</mo></mtd> <mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>âˆ‚</mi><msub><mi>z</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mi>n</mi></msub></mrow></mfrac></mstyle></mtd></mtr>
    <mtr><mtd><mo>â‹±</mo></mtd> <mtd><mo>â‹®</mo></mtd></mtr> <mtr><mtd><mstyle scriptlevel="0"
    displaystyle="true"><mfrac><mrow><mi>âˆ‚</mi><msub><mi>z</mi> <mi>m</mi></msub></mrow>
    <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mstyle></mtd>
    <mtd><mo>â‹¯</mo></mtd> <mtd><mstyle scriptlevel="0" displaystyle="true"><mfrac><mrow><mi>âˆ‚</mi><msub><mi>z</mi>
    <mi>m</mi></msub></mrow> <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mi>n</mi></msub></mrow></mfrac></mstyle></mtd></mtr></mtable></mfenced></mrow></math>
- en: The best way to explain this is with our example. If we take the partial derivative
    of <math alttext="z 1"><msub><mi>z</mi> <mn>1</mn></msub></math> with respect
    to <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> , we obtain <math
    alttext="one-third"><mfrac><mn>1</mn> <mn>3</mn></mfrac></math> . If we take the
    partial derivative of <math alttext="z 1"><msub><mi>z</mi> <mn>1</mn></msub></math>
    with respect to <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    , we obtain 0\. Similarly, if we take the partial derivative of <math alttext="z
    2"><msub><mi>z</mi> <mn>2</mn></msub></math> with respect to <math alttext="x
    1"><msub><mi>x</mi> <mn>1</mn></msub></math> , we obtain 0\. Lastly, if we take
    the partial derivative of <math alttext="z 2"><msub><mi>z</mi> <mn>2</mn></msub></math>
    with respect to <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    , we obtain <math alttext="one-half"><mfrac><mn>1</mn> <mn>2</mn></mfrac></math>
    .
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å¥½çš„æ–¹æ³•æ˜¯ç”¨æˆ‘ä»¬çš„ä¾‹å­æ¥è§£é‡Šã€‚å¦‚æœæˆ‘ä»¬å¯¹z1å…³äºx1è¿›è¡Œåå¯¼æ•°ï¼Œæˆ‘ä»¬å¾—åˆ°1/3ã€‚å¦‚æœæˆ‘ä»¬å¯¹z1å…³äºx2è¿›è¡Œåå¯¼æ•°ï¼Œæˆ‘ä»¬å¾—åˆ°0ã€‚åŒæ ·ï¼Œå¦‚æœæˆ‘ä»¬å¯¹z2å…³äºx1è¿›è¡Œåå¯¼æ•°ï¼Œæˆ‘ä»¬å¾—åˆ°0ã€‚æœ€åï¼Œå¦‚æœæˆ‘ä»¬å¯¹z2å…³äºx2è¿›è¡Œåå¯¼æ•°ï¼Œæˆ‘ä»¬å¾—åˆ°1/2ã€‚
- en: 'Therefore, the Jacobian matrix for our function <math alttext="f left-parenthesis
    x right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math>
    is as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å‡½æ•°çš„é›…å¯æ¯”çŸ©é˜µå¦‚ä¸‹ï¼š
- en: <math alttext="upper J equals Start 2 By 2 Matrix 1st Row 1st Column one-third
    2nd Column 0 2nd Row 1st Column 0 2nd Column one-half EndMatrix" display="block"><mrow><mi>J</mi>
    <mo>=</mo> <mfenced open="(" close=")"><mtable><mtr><mtd><mfrac><mn>1</mn> <mn>3</mn></mfrac></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mfrac><mn>1</mn>
    <mn>2</mn></mfrac></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper J equals Start 2 By 2 Matrix 1st Row 1st Column one-third
    2nd Column 0 2nd Row 1st Column 0 2nd Column one-half EndMatrix" display="block"><mrow><mi>J</mi>
    <mo>=</mo> <mfenced open="(" close=")"><mtable><mtr><mtd><mfrac><mn>1</mn> <mn>3</mn></mfrac></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mfrac><mn>1</mn>
    <mn>2</mn></mfrac></mtd></mtr></mtable></mfenced></mrow></math>
- en: The *determinant* is only defined for square matrices and is equal to the signed
    volume of the parallelepiped created by applying the transformation represented
    by the matrix to the unit (hyper)cube. In two dimensions, this is therefore just
    the signed area of the parallelogram created by applying the transformation represented
    by the matrix to the unit square.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¡Œåˆ—å¼ä»…å¯¹æ–¹é˜µæœ‰å®šä¹‰ï¼Œå¹¶ä¸”ç­‰äºé€šè¿‡å°†çŸ©é˜µè¡¨ç¤ºçš„å˜æ¢åº”ç”¨äºå•ä½ï¼ˆè¶…ï¼‰ç«‹æ–¹ä½“è€Œåˆ›å»ºçš„å¹³è¡Œå…­é¢ä½“çš„æœ‰ç¬¦å·ä½“ç§¯ã€‚åœ¨äºŒç»´ä¸­ï¼Œè¿™åªæ˜¯é€šè¿‡å°†çŸ©é˜µè¡¨ç¤ºçš„å˜æ¢åº”ç”¨äºå•ä½æ­£æ–¹å½¢è€Œåˆ›å»ºçš„å¹³è¡Œå››è¾¹å½¢çš„æœ‰ç¬¦å·é¢ç§¯ã€‚
- en: 'There is a [general formula](https://oreil.ly/FuDCf) for calculating the determinant
    of a matrix with *n* dimensions, which runs in <math alttext="script upper O left-parenthesis
    n cubed right-parenthesis"><mrow><mi>ğ’ª</mi> <mo>(</mo> <msup><mi>n</mi> <mn>3</mn></msup>
    <mo>)</mo></mrow></math> time. For our example, we only need the formula for two
    dimensions, which is simply as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰ä¸€ä¸ªç”¨äºè®¡ç®—å…·æœ‰nç»´çš„çŸ©é˜µè¡Œåˆ—å¼çš„[é€šç”¨å…¬å¼](https://oreil.ly/FuDCf)ï¼Œå…¶è¿è¡Œæ—¶é—´ä¸ºğ’ª(n^3)ã€‚å¯¹äºæˆ‘ä»¬çš„ä¾‹å­ï¼Œæˆ‘ä»¬åªéœ€è¦äºŒç»´çš„å…¬å¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: <math alttext="normal d normal e normal t Start 2 By 2 Matrix 1st Row 1st Column
    a 2nd Column b 2nd Row 1st Column c 2nd Column d EndMatrix equals a d minus b
    c" display="block"><mrow><mi>det</mi> <mfenced open="(" close=")"><mtable><mtr><mtd><mi>a</mi></mtd>
    <mtd><mi>b</mi></mtd></mtr> <mtr><mtd><mi>c</mi></mtd> <mtd><mi>d</mi></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mi>a</mi> <mi>d</mi> <mo>-</mo> <mi>b</mi> <mi>c</mi></mrow></math>
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal d normal e normal t Start 2 By 2 Matrix 1st Row 1st Column
    a 2nd Column b 2nd Row 1st Column c 2nd Column d EndMatrix equals a d minus b
    c" display="block"><mrow><mi>det</mi> <mfenced open="(" close=")"><mtable><mtr><mtd><mi>a</mi></mtd>
    <mtd><mi>b</mi></mtd></mtr> <mtr><mtd><mi>c</mi></mtd> <mtd><mi>d</mi></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mi>a</mi> <mi>d</mi> <mo>-</mo> <mi>b</mi> <mi>c</mi></mrow></math>
- en: Therefore, for our example, the determinant of the Jacobian is <math alttext="one-third
    times one-half minus 0 times 0 equals one-sixth"><mrow><mfrac><mn>1</mn> <mn>3</mn></mfrac>
    <mo>Ã—</mo> <mfrac><mn>1</mn> <mn>2</mn></mfrac> <mo>-</mo> <mn>0</mn> <mo>Ã—</mo>
    <mn>0</mn> <mo>=</mo> <mfrac><mn>1</mn> <mn>6</mn></mfrac></mrow></math> . This
    is the scaling factor of 1/6 that we need to ensure that the probability distribution
    after transformation still integrates to 1!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¯¹äºæˆ‘ä»¬çš„ç¤ºä¾‹ï¼Œé›…å¯æ¯”è¡Œåˆ—å¼çš„è¡Œåˆ—å¼æ˜¯ <math alttext="one-third times one-half minus 0 times
    0 equals one-sixth"><mrow><mfrac><mn>1</mn> <mn>3</mn></mfrac> <mo>Ã—</mo> <mfrac><mn>1</mn>
    <mn>2</mn></mfrac> <mo>-</mo> <mn>0</mn> <mo>Ã—</mo> <mn>0</mn> <mo>=</mo> <mfrac><mn>1</mn>
    <mn>6</mn></mfrac></mrow></math>ã€‚è¿™æ˜¯æˆ‘ä»¬éœ€è¦ç¡®ä¿å˜æ¢åçš„æ¦‚ç‡åˆ†å¸ƒä»ç„¶ç§¯åˆ†ä¸º1çš„ç¼©æ”¾å› å­ä¸º1/6ï¼
- en: Tip
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æç¤º
- en: By definition, the determinant is signedâ€”that is, it can be negative. Therefore
    we need to take the absolute value of the Jacobian determinant in order to obtain
    the relative change of volume.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æ ¹æ®å®šä¹‰ï¼Œè¡Œåˆ—å¼æ˜¯æœ‰ç¬¦å·çš„â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒå¯ä»¥æ˜¯è´Ÿæ•°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦å–é›…å¯æ¯”è¡Œåˆ—å¼çš„ç»å¯¹å€¼ï¼Œä»¥è·å¾—ä½“ç§¯çš„ç›¸å¯¹å˜åŒ–ã€‚
- en: The Change of Variables Equation
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å˜é‡è½¬æ¢æ–¹ç¨‹
- en: We can now write down a single equation that describes the process for changing
    variables between <math alttext="upper X"><mi>X</mi></math> and <math alttext="upper
    Z"><mi>Z</mi></math> . This is known as the *change of variables equation* ([Equation
    6-1](#cov_equation)).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¯ä»¥å†™ä¸‹ä¸€ä¸ªå•ä¸€æ–¹ç¨‹ï¼Œæè¿°åœ¨ <math alttext="upper X"><mi>X</mi></math> å’Œ <math alttext="upper
    Z"><mi>Z</mi></math> ä¹‹é—´å˜é‡è½¬æ¢çš„è¿‡ç¨‹ã€‚è¿™è¢«ç§°ä¸º*å˜é‡è½¬æ¢æ–¹ç¨‹*ï¼ˆ[æ–¹ç¨‹6-1](#cov_equation)ï¼‰ã€‚
- en: Equation 6-1\. The change of variables equation
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹6-1. å˜é‡è½¬æ¢æ–¹ç¨‹
- en: <math alttext="p Subscript upper X Baseline left-parenthesis x right-parenthesis
    equals p Subscript upper Z Baseline left-parenthesis z right-parenthesis StartAbsoluteValue
    normal d normal e normal t left-parenthesis StartFraction normal partial-differential
    z Over normal partial-differential x EndFraction right-parenthesis EndAbsoluteValue"
    display="block"><mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow> <mfenced separators="" open="|" close="|"><mi>det</mi>
    <mfenced separators="" open="(" close=")"><mfrac><mrow><mi>âˆ‚</mi><mi>z</mi></mrow>
    <mrow><mi>âˆ‚</mi><mi>x</mi></mrow></mfrac></mfenced></mfenced></mrow></math>
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="p Subscript upper X Baseline left-parenthesis x right-parenthesis
    equals p Subscript upper Z Baseline left-parenthesis z right-parenthesis StartAbsoluteValue
    normal d normal e normal t left-parenthesis StartFraction normal partial-differential
    z Over normal partial-differential x EndFraction right-parenthesis EndAbsoluteValue"
    display="block"><mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow> <mfenced separators="" open="|" close="|"><mi>det</mi>
    <mfenced separators="" open="(" close=")"><mfrac><mrow><mi>âˆ‚</mi><mi>z</mi></mrow>
    <mrow><mi>âˆ‚</mi><mi>x</mi></mrow></mfrac></mfenced></mfenced></mrow></math>
- en: How does this help us build a generative model? The key is understanding that
    if <math alttext="p Subscript upper Z Baseline left-parenthesis z right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>Z</mi></msub> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></math>
    is a simple distribution from which we can easily sample (e.g., a Gaussian), then
    in theory, all we need to do is find an appropriate invertible function <math
    alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow></math> that can map from the data <math alttext="upper X"><mi>X</mi></math>
    into <math alttext="upper Z"><mi>Z</mi></math> and the corresponding inverse function
    <math alttext="g left-parenthesis z right-parenthesis"><mrow><mi>g</mi> <mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></math> that can be used to map a sampled <math alttext="z"><mi>z</mi></math>
    back to a point <math alttext="x"><mi>x</mi></math> in the original domain. We
    can use the preceding equation involving the Jacobian determinant to find an exact,
    tractable formula for the data distribution <math alttext="p left-parenthesis
    x right-parenthesis"><mrow><mi>p</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math>
    .
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¦‚ä½•å¸®åŠ©æˆ‘ä»¬æ„å»ºä¸€ä¸ªç”Ÿæˆæ¨¡å‹ï¼Ÿå…³é”®åœ¨äºç†è§£ï¼Œå¦‚æœ <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> æ˜¯ä¸€ä¸ªç®€å•çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°ä»ä¸­æŠ½æ ·ï¼ˆä¾‹å¦‚ï¼Œé«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œé‚£ä¹ˆç†è®ºä¸Šï¼Œæˆ‘ä»¬æ‰€éœ€è¦åšçš„å°±æ˜¯æ‰¾åˆ°ä¸€ä¸ªé€‚å½“çš„å¯é€†å‡½æ•°
    <math alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi> <mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></math>ï¼Œå¯ä»¥å°†æ•°æ® <math alttext="upper X"><mi>X</mi></math>
    æ˜ å°„åˆ° <math alttext="upper Z"><mi>Z</mi></math>ï¼Œä»¥åŠç›¸åº”çš„é€†å‡½æ•° <math alttext="g left-parenthesis
    z right-parenthesis"><mrow><mi>g</mi> <mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></math>ï¼Œå¯ä»¥ç”¨æ¥å°†æŠ½æ ·çš„
    <math alttext="z"><mi>z</mi></math> æ˜ å°„å›åŸå§‹åŸŸä¸­çš„ç‚¹ <math alttext="x"><mi>x</mi></math>ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ¶‰åŠé›…å¯æ¯”è¡Œåˆ—å¼çš„å‰è¿°æ–¹ç¨‹æ‰¾åˆ°æ•°æ®åˆ†å¸ƒ
    <math alttext="p left-parenthesis x right-parenthesis"><mrow><mi>p</mi> <mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></math> çš„ä¸€ä¸ªç²¾ç¡®ã€å¯å¤„ç†çš„å…¬å¼ã€‚
- en: However, there are two major issues when applying this in practice that we first
    need to address!
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œåœ¨å®è·µä¸­åº”ç”¨æ—¶å­˜åœ¨ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦è§£å†³ï¼
- en: Firstly, calculating the determinant of a high-dimensional matrix is computationally
    extremely expensiveâ€”specifically, it is <math alttext="script upper O left-parenthesis
    n cubed right-parenthesis"><mrow><mi>ğ’ª</mi> <mo>(</mo> <msup><mi>n</mi> <mn>3</mn></msup>
    <mo>)</mo></mrow></math> . This is completely impractical to implement in practice,
    as even small 32 Ã— 32â€“pixel grayscale images have 1,024 dimensions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œè®¡ç®—é«˜ç»´çŸ©é˜µçš„è¡Œåˆ—å¼åœ¨è®¡ç®—ä¸Šæ˜¯æå…¶æ˜‚è´µçš„â€”â€”å…·ä½“æ¥è¯´ï¼Œæ˜¯ <math alttext="script upper O left-parenthesis
    n cubed right-parenthesis"><mrow><mi>ğ’ª</mi> <mo>(</mo> <msup><mi>n</mi> <mn>3</mn></msup>
    <mo>)</mo></mrow></math>ã€‚è¿™åœ¨å®è·µä¸­æ˜¯å®Œå…¨ä¸åˆ‡å®é™…çš„ï¼Œå› ä¸ºå³ä½¿æ˜¯å°çš„32Ã—32åƒç´ ç°åº¦å›¾åƒä¹Ÿæœ‰1024ä¸ªç»´åº¦ã€‚
- en: Secondly, it is not immediately obvious how we should go about calculating the
    invertible function <math alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math> . We could use a neural network
    to find some function <math alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math> but we cannot necessarily invert
    this networkâ€”neural networks only work in one direction!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶æ¬¡ï¼Œæˆ‘ä»¬ä¸æ¸…æ¥šå¦‚ä½•è®¡ç®—å¯é€†å‡½æ•° <math alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math>ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç¥ç»ç½‘ç»œæ‰¾åˆ°ä¸€äº›å‡½æ•° <math alttext="f
    left-parenthesis x right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math>ï¼Œä½†æˆ‘ä»¬ä¸èƒ½ä¿è¯å¯ä»¥åè½¬è¿™ä¸ªç½‘ç»œâ€”â€”ç¥ç»ç½‘ç»œåªèƒ½å•å‘å·¥ä½œï¼
- en: To solve these two problems, we need to use a special neural network architecture
    that ensures that the change of variables function <math alttext="f"><mi>f</mi></math>
    is invertible and has a determinant that is easy to calculate.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è§£å†³è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸€ç§ç‰¹æ®Šçš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œç¡®ä¿å˜é‡è½¬æ¢å‡½æ•° <math alttext="f"><mi>f</mi></math> æ˜¯å¯é€†çš„ï¼Œå¹¶ä¸”å…¶è¡Œåˆ—å¼æ˜“äºè®¡ç®—ã€‚
- en: We shall see how to do this in the following section using a technique called
    *real-valued non-volume preserving (RealNVP) transformations*.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­çœ‹åˆ°å¦‚ä½•ä½¿ç”¨ä¸€ç§ç§°ä¸º*å®å€¼éä½“ç§¯ä¿æŒï¼ˆRealNVPï¼‰å˜æ¢*çš„æŠ€æœ¯æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
- en: RealNVP
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RealNVP
- en: RealNVP was first introduced by Dinh et al. in 2017.^([1](ch06.xhtml#idm45387014186656))
    In this paper the authors show how to construct a neural network that can transform
    a complex data distribution into a simple Gaussian, while also possessing the
    desired properties of being invertible and having a Jacobian that can be easily
    calculated.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: RealNVPé¦–æ¬¡ç”±Dinhç­‰äººåœ¨2017å¹´æå‡ºã€‚åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œä½œè€…å±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå¯ä»¥å°†å¤æ‚çš„æ•°æ®åˆ†å¸ƒè½¬æ¢ä¸ºç®€å•çš„é«˜æ–¯åˆ†å¸ƒï¼ŒåŒæ—¶å…·æœ‰å¯é€†æ€§å’Œæ˜“äºè®¡ç®—é›…å¯æ¯”è¡Œåˆ—å¼çš„æœŸæœ›ç‰¹æ€§ã€‚
- en: Running the Code for This Example
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¿è¡Œæ­¤ç¤ºä¾‹çš„ä»£ç 
- en: The code for this example can be found in the Jupyter notebook located at *notebooks/06_normflow/01_realnvp/realnvp.ipynb*
    in the book repository.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: æ­¤ç¤ºä¾‹çš„ä»£ç å¯ä»¥åœ¨ä½äºä¹¦ç±å­˜å‚¨åº“ä¸­çš„*notebooks/06_normflow/01_realnvp/realnvp.ipynb*çš„Jupyterç¬”è®°æœ¬ä¸­æ‰¾åˆ°ã€‚
- en: The code has been adapted from the excellent [RealNVP tutorial](https://oreil.ly/ZjjwP)
    created by Mandolini Giorgio Maria et al. available on the Keras website.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥ä»£ç æ”¹ç¼–è‡ªç”±Mandolini Giorgio Mariaç­‰äººåˆ›å»ºçš„ä¼˜ç§€[RealNVPæ•™ç¨‹](https://oreil.ly/ZjjwP)ï¼Œå¯åœ¨Kerasç½‘ç«™ä¸Šæ‰¾åˆ°ã€‚
- en: The Two Moons Dataset
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªmoonsæ•°æ®é›†
- en: The dataset we will use for this example is created by the `make_moons` function
    from the Python library `sklearn`. This creates a noisy dataset of points in 2D
    that resemble two crescents, as shown in [FigureÂ 6-4](#moons_image).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨æ­¤ç¤ºä¾‹ä¸­ä½¿ç”¨çš„æ•°æ®é›†æ˜¯ç”±Pythonåº“`sklearn`ä¸­çš„`make_moons`å‡½æ•°åˆ›å»ºçš„ã€‚è¿™å°†åˆ›å»ºä¸€ä¸ªå˜ˆæ‚çš„2Dç‚¹æ•°æ®é›†ï¼Œç±»ä¼¼äºä¸¤ä¸ªæ–°æœˆå½¢çŠ¶ï¼Œå¦‚[å›¾6-4](#moons_image)æ‰€ç¤ºã€‚
- en: '![gdl2 0604](Images/gdl2_0604.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![gdl2 0604](Images/gdl2_0604.png)'
- en: Figure 6-4\. The two moons dataset in two dimensions
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-4ã€‚äºŒç»´ä¸­çš„ä¸¤ä¸ªmoonsæ•°æ®é›†
- en: The code for creating this dataset is given in [ExampleÂ 6-1](#moons-dataset).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºæ­¤æ•°æ®é›†çš„ä»£ç åœ¨[ç¤ºä¾‹6-1](#moons-dataset)ä¸­ç»™å‡ºã€‚
- en: Example 6-1\. Creating a *moons* dataset
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹6-1ã€‚åˆ›å»ºä¸€ä¸ª*moons*æ•°æ®é›†
- en: '[PRE0]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](Images/1.png)](#co_normalizing_flow_models_CO1-1)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_normalizing_flow_models_CO1-1)'
- en: Make a noisy, unnormalized moons dataset of 3,000 points.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªåŒ…å«3,000ä¸ªç‚¹çš„å˜ˆæ‚ã€éæ ‡å‡†åŒ–çš„moonsæ•°æ®é›†ã€‚
- en: '[![2](Images/2.png)](#co_normalizing_flow_models_CO1-2)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_normalizing_flow_models_CO1-2)'
- en: Normalize the dataset to have mean 0 and standard deviation 1.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ•°æ®é›†å½’ä¸€åŒ–ä¸ºå‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1ã€‚
- en: We will build a RealNVP model that can generate points in 2D that follow a similar
    distribution to the two moons dataset. Whilst this is a very simple example, it
    will help us understand how a normalizing flow model works in practice, in fine
    detail.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªRealNVPæ¨¡å‹ï¼Œå¯ä»¥ç”Ÿæˆéµå¾ªä¸ä¸¤ä¸ªmoonsæ•°æ®é›†ç±»ä¼¼åˆ†å¸ƒçš„2Dç‚¹ã€‚è™½ç„¶è¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ä¾‹å­ï¼Œä½†å®ƒå°†å¸®åŠ©æˆ‘ä»¬è¯¦ç»†äº†è§£æ­£è§„åŒ–æµæ¨¡å‹åœ¨å®è·µä¸­çš„å·¥ä½œæ–¹å¼ã€‚
- en: First, however, we need to introduce a new type of layer, called a coupling
    layer.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä»‹ç»ä¸€ç§æ–°ç±»å‹çš„å±‚ï¼Œç§°ä¸ºè€¦åˆå±‚ã€‚
- en: Coupling Layers
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è€¦åˆå±‚
- en: A *coupling layer* produces a scale and translation factor for each element
    of its input. In other words, it produces two tensors that are exactly the same
    size as the input, one for the scale factor and one for the translation factor,
    as shown in [FigureÂ 6-5](#coupling_layer).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*è€¦åˆå±‚*ä¸ºå…¶è¾“å…¥çš„æ¯ä¸ªå…ƒç´ äº§ç”Ÿä¸€ä¸ªæ¯”ä¾‹å’Œå¹³ç§»å› å­ã€‚æ¢å¥è¯è¯´ï¼Œå®ƒäº§ç”Ÿä¸¤ä¸ªä¸è¾“å…¥å®Œå…¨ç›¸åŒå¤§å°çš„å¼ é‡ï¼Œä¸€ä¸ªç”¨äºæ¯”ä¾‹å› å­ï¼Œä¸€ä¸ªç”¨äºå¹³ç§»å› å­ï¼Œå¦‚[å›¾6-5](#coupling_layer)æ‰€ç¤ºã€‚'
- en: '![](Images/gdl2_0605.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0605.png)'
- en: 'Figure 6-5\. A coupling layer outputs two tensors that are the same shape as
    the input: a scaling factor (s) and a translation factor (t)'
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-5ã€‚è€¦åˆå±‚è¾“å‡ºä¸¤ä¸ªä¸è¾“å…¥ç›¸åŒå½¢çŠ¶çš„å¼ é‡ï¼šä¸€ä¸ªç¼©æ”¾å› å­ï¼ˆsï¼‰å’Œä¸€ä¸ªå¹³ç§»å› å­ï¼ˆtï¼‰
- en: To build a custom `Coupling` layer for our simple example, we can stack `Dense`
    layers to create the scale output and a different set of `Dense` layers to create
    the translation output, as shown in [ExampleÂ 6-2](#coupling-layer-code).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†ä¸ºæˆ‘ä»¬çš„ç®€å•ç¤ºä¾‹æ„å»ºè‡ªå®šä¹‰çš„`Coupling`å±‚ï¼Œæˆ‘ä»¬å¯ä»¥å †å `Dense`å±‚ä»¥åˆ›å»ºæ¯”ä¾‹è¾“å‡ºï¼Œå¹¶å †å ä¸åŒçš„`Dense`å±‚ä»¥åˆ›å»ºå¹³ç§»è¾“å‡ºï¼Œå¦‚[ç¤ºä¾‹6-2](#coupling-layer-code)æ‰€ç¤ºã€‚
- en: Tip
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æç¤º
- en: For images, `Coupling` layer blocks use `Conv2D` layers instead of `Dense` layers.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå›¾åƒï¼Œ`Coupling`å±‚å—ä½¿ç”¨`Conv2D`å±‚è€Œä¸æ˜¯`Dense`å±‚ã€‚
- en: Example 6-2\. A `Coupling` layer in Keras
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹6-2ã€‚Kerasä¸­çš„`Coupling`å±‚
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](Images/1.png)](#co_normalizing_flow_models_CO2-1)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_normalizing_flow_models_CO2-1)'
- en: The input to the `Coupling` layer block in our example has two dimensions.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç¤ºä¾‹ä¸­`Coupling`å±‚å—çš„è¾“å…¥æœ‰ä¸¤ä¸ªç»´åº¦ã€‚
- en: '[![2](Images/2.png)](#co_normalizing_flow_models_CO2-2)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_normalizing_flow_models_CO2-2)'
- en: The *scaling* stream is a stack of `Dense` layers of size 256.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç¼©æ”¾*æµæ˜¯ä¸€ä¸ªå¤§å°ä¸º256çš„`Dense`å±‚å †å ã€‚'
- en: '[![3](Images/3.png)](#co_normalizing_flow_models_CO2-3)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_normalizing_flow_models_CO2-3)'
- en: The final scaling layer is of size 2 and has `tanh` activation.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆçš„ç¼©æ”¾å±‚å¤§å°ä¸º2ï¼Œå¹¶å…·æœ‰`tanh`æ¿€æ´»ã€‚
- en: '[![4](Images/4.png)](#co_normalizing_flow_models_CO2-4)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_normalizing_flow_models_CO2-4)'
- en: The *translation* stream is a stack of `Dense` layers of size 256.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¹³ç§»*æµæ˜¯ä¸€ä¸ªå¤§å°ä¸º256çš„`Dense`å±‚å †å ã€‚'
- en: '[![5](Images/5.png)](#co_normalizing_flow_models_CO2-5)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_normalizing_flow_models_CO2-5)'
- en: The final translation layer is of size 2 and has `linear` activation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€ç»ˆçš„ç¿»è¯‘å±‚å¤§å°ä¸º2ï¼Œå¹¶å…·æœ‰`linear`æ¿€æ´»ã€‚
- en: '[![6](Images/6.png)](#co_normalizing_flow_models_CO2-6)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_normalizing_flow_models_CO2-6)'
- en: The `Coupling` layer is constructed as a Keras `Model` with two outputs (the
    scaling and translation factors).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`Coupling`å±‚è¢«æ„å»ºä¸ºä¸€ä¸ªKeras `Model`ï¼Œå…·æœ‰ä¸¤ä¸ªè¾“å‡ºï¼ˆç¼©æ”¾å’Œå¹³ç§»å› å­ï¼‰ã€‚'
- en: Notice how the number of channels is temporarily increased to allow for a more
    complex representation to be learned, before being collapsed back down to the
    same number of channels as the input. In the original paper, the authors also
    use regularizers on each layer to penalize large weights.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œä¸´æ—¶å¢åŠ é€šé“æ•°ä»¥å…è®¸å­¦ä¹ æ›´å¤æ‚çš„è¡¨ç¤ºï¼Œç„¶åå°†å…¶æŠ˜å å›ä¸è¾“å…¥ç›¸åŒæ•°é‡çš„é€šé“ã€‚åœ¨åŸå§‹è®ºæ–‡ä¸­ï¼Œä½œè€…è¿˜åœ¨æ¯ä¸€å±‚ä¸Šä½¿ç”¨æ­£åˆ™åŒ–å™¨æ¥æƒ©ç½šå¤§çš„æƒé‡ã€‚
- en: Passing data through a coupling layer
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é€šè¿‡è€¦åˆå±‚ä¼ é€’æ•°æ®
- en: The architecture of a coupling layer is not particularly interestingâ€”what makes
    it unique is the way the input data is masked and transformed as it is fed through
    the layer, as shown in [FigureÂ 6-6](#forward_update_equations).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: è€¦åˆå±‚çš„æ¶æ„å¹¶ä¸ç‰¹åˆ«æœ‰è¶£â€”â€”å®ƒçš„ç‹¬ç‰¹ä¹‹å¤„åœ¨äºè¾“å…¥æ•°æ®åœ¨é€šè¿‡å±‚æ—¶å¦‚ä½•è¢«æ©ç›–å’Œè½¬æ¢ï¼Œå¦‚[å›¾6-6](#forward_update_equations)æ‰€ç¤ºã€‚
- en: '![](Images/gdl2_0606.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0606.png)'
- en: Figure 6-6\. The process of transforming the input <math alttext="x"><mi>x</mi></math>
    through a coupling layer
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-6ã€‚é€šè¿‡è€¦åˆå±‚è½¬æ¢è¾“å…¥<math alttext="x"><mi>x</mi></math>çš„è¿‡ç¨‹
- en: Notice how only the first <math alttext="d"><mi>d</mi></math> dimensions of
    the data are fed through to the first coupling layerâ€”the remaining <math alttext="upper
    D minus d"><mrow><mi>D</mi> <mo>-</mo> <mi>d</mi></mrow></math> dimensions are
    completely masked (i.e., set to zero). In our simple example with <math alttext="upper
    D equals 2"><mrow><mi>D</mi> <mo>=</mo> <mn>2</mn></mrow></math> , choosing <math
    alttext="d equals 1"><mrow><mi>d</mi> <mo>=</mo> <mn>1</mn></mrow></math> means
    that instead of the coupling layer seeing two values, <math alttext="left-parenthesis
    x 1 comma x 2 right-parenthesis"><mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math> , the layer
    sees <math alttext="left-parenthesis x 1 comma 0 right-parenthesis"><mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <mn>0</mn> <mo>)</mo></mrow></math>
    .
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„æ•°æ®çš„å‰<math alttext="d"><mi>d</mi></math>ç»´åº¦è¢«ç›´æ¥ä¼ é€’åˆ°ç¬¬ä¸€ä¸ªè€¦åˆå±‚ï¼Œå‰©ä¸‹çš„<math alttext="upper
    D minus d"><mrow><mi>D</mi> <mo>-</mo> <mi>d</mi></mrow></math>ç»´åº¦å®Œå…¨è¢«é®è”½ï¼ˆå³è®¾ä¸ºé›¶ï¼‰ã€‚åœ¨æˆ‘ä»¬çš„ç®€å•ç¤ºä¾‹ä¸­ï¼Œé€‰æ‹©<math
    alttext="d equals 1"><mrow><mi>d</mi> <mo>=</mo> <mn>1</mn></mrow></math>æ„å‘³ç€è€¦åˆå±‚çœ‹åˆ°çš„ä¸æ˜¯ä¸¤ä¸ªå€¼<math
    alttext="left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>ï¼Œè€Œæ˜¯çœ‹åˆ°<math
    alttext="left-parenthesis x 1 comma 0 right-parenthesis"><mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <mn>0</mn> <mo>)</mo></mrow></math>ã€‚
- en: 'The outputs from the layer are the scale and translation factors. These are
    again masked, but this time with the *inverse* mask to previously, so that only
    the second halves are let throughâ€”i.e., in our example, we obtain <math alttext="left-parenthesis
    0 comma s 2 right-parenthesis"><mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <msub><mi>s</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math> and <math alttext="left-parenthesis
    0 comma t 2 right-parenthesis"><mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <msub><mi>t</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math> . These are then applied element-wise
    to the second half of the input <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    and the first half of the input <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    is simply passed straight through, without being updated at all. In summary, for
    a vector with dimension <math alttext="upper D"><mi>D</mi></math> where <math
    alttext="d less-than upper D"><mrow><mi>d</mi> <mo><</mo> <mi>D</mi></mrow></math>
    , the update equations are as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: å±‚çš„è¾“å‡ºæ˜¯æ¯”ä¾‹å’Œå¹³ç§»å› å­ã€‚è¿™äº›å†æ¬¡è¢«é®è”½ï¼Œä½†è¿™æ¬¡æ˜¯ä¸ä¹‹å‰çš„*åå‘*é®ç½©ï¼Œåªæœ‰ååŠéƒ¨åˆ†è¢«æ”¾è¡Œâ€”â€”å³åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å¾—åˆ°<math alttext="left-parenthesis
    0 comma s 2 right-parenthesis"><mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <msub><mi>s</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math>å’Œ<math alttext="left-parenthesis 0 comma
    t 2 right-parenthesis"><mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <msub><mi>t</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math>ã€‚ç„¶åè¿™äº›è¢«é€å…ƒç´ åº”ç”¨åˆ°è¾“å…¥çš„ååŠéƒ¨åˆ†<math alttext="x
    2"><msub><mi>x</mi> <mn>2</mn></msub></math>ï¼Œè€Œè¾“å…¥çš„å‰åŠéƒ¨åˆ†<math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math>åˆ™ç›´æ¥ä¼ é€’ï¼Œå®Œå…¨ä¸è¢«æ›´æ–°ã€‚æ€»ä¹‹ï¼Œå¯¹äºç»´åº¦ä¸º<math alttext="upper D"><mi>D</mi></math>çš„å‘é‡ï¼Œå…¶ä¸­<math
    alttext="d less-than upper D"><mrow><mi>d</mi> <mo><</mo> <mi>D</mi></mrow></math>ï¼Œæ›´æ–°æ–¹ç¨‹å¦‚ä¸‹ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column z Subscript 1 colon d 2nd Column
    equals 3rd Column x Subscript 1 colon d 2nd Row 1st Column z Subscript d plus
    1 colon upper D 2nd Column equals 3rd Column x Subscript d plus 1 colon upper
    D Baseline circled-dot normal e normal x normal p left-parenthesis s left-parenthesis
    x Subscript 1 colon d Baseline right-parenthesis right-parenthesis plus t left-parenthesis
    x Subscript 1 colon d Baseline right-parenthesis EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>z</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub>
    <mo>âŠ™</mo> <mi>exp</mi> <mfenced separators="" open="(" close=")"><mi>s</mi> <mo>(</mo>
    <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>)</mo></mfenced>
    <mo>+</mo> <mi>t</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column z Subscript 1 colon d 2nd Column
    equals 3rd Column x Subscript 1 colon d 2nd Row 1st Column z Subscript d plus
    1 colon upper D 2nd Column equals 3rd Column x Subscript d plus 1 colon upper
    D Baseline circled-dot normal e normal x normal p left-parenthesis s left-parenthesis
    x Subscript 1 colon d Baseline right-parenthesis right-parenthesis plus t left-parenthesis
    x Subscript 1 colon d Baseline right-parenthesis EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>z</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub>
    <mo>âŠ™</mo> <mi>exp</mi> <mfenced separators="" open="(" close=")"><mi>s</mi> <mo>(</mo>
    <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>)</mo></mfenced>
    <mo>+</mo> <mi>t</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
- en: 'You may be wondering why we go to the trouble of building a layer that masks
    so much information. The answer is clear if we investigate the structure of the
    Jacobian matrix of this function:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯èƒ½æƒ³çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦è´¹åŠ›æ„å»ºä¸€ä¸ªé®è”½äº†è¿™ä¹ˆå¤šä¿¡æ¯çš„å±‚ã€‚ç­”æ¡ˆå¾ˆæ˜æ˜¾ï¼Œå¦‚æœæˆ‘ä»¬è°ƒæŸ¥è¿™ä¸ªå‡½æ•°çš„é›…å¯æ¯”çŸ©é˜µçš„ç»“æ„ï¼š
- en: <math alttext="StartFraction normal partial-differential z Over normal partial-differential
    x EndFraction equals Start 2 By 2 Matrix 1st Row 1st Column bold upper I 2nd Column
    0 2nd Row 1st Column StartFraction normal partial-differential z Subscript d plus
    1 colon upper D Baseline Over normal partial-differential x Subscript 1 colon
    d Baseline EndFraction 2nd Column normal d normal i normal a normal g left-parenthesis
    normal e normal x normal p left-bracket s left-parenthesis x Subscript 1 colon
    d Baseline right-parenthesis right-bracket right-parenthesis EndMatrix" display="block"><mrow><mfrac><mrow><mi>âˆ‚</mi><mi>z</mi></mrow>
    <mrow><mi>âˆ‚</mi><mi>x</mi></mrow></mfrac> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>ğˆ</mi></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mfrac><mrow><mi>âˆ‚</mi><msub><mi>z</mi>
    <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mrow>
    <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mrow></mfrac></mtd>
    <mtd><mrow><mi>diag</mi> <mo>(</mo> <mi>exp</mi> <mrow><mo>[</mo> <mi>s</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>)</mo></mrow>
    <mo>]</mo></mrow> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential z Over normal partial-differential
    x EndFraction equals Start 2 By 2 Matrix 1st Row 1st Column bold upper I 2nd Column
    0 2nd Row 1st Column StartFraction normal partial-differential z Subscript d plus
    1 colon upper D Baseline Over normal partial-differential x Subscript 1 colon
    d Baseline EndFraction 2nd Column normal d normal i normal a normal g left-parenthesis
    normal e normal x normal p left-bracket s left-parenthesis x Subscript 1 colon
    d Baseline right-parenthesis right-bracket right-parenthesis EndMatrix" display="block"><mrow><mfrac><mrow><mi>âˆ‚</mi><mi>z</mi></mrow>
    <mrow><mi>âˆ‚</mi><mi>x</mi></mrow></mfrac> <mo>=</mo> <mfenced open="[" close="]"><mtable><mtr><mtd><mi>ğˆ</mi></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mfrac><mrow><mi>âˆ‚</mi><msub><mi>z</mi>
    <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mrow>
    <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mrow></mfrac></mtd>
    <mtd><mrow><mi>diag</mi> <mo>(</mo> <mi>exp</mi> <mrow><mo>[</mo> <mi>s</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>)</mo></mrow>
    <mo>]</mo></mrow> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: The top-left <math alttext="d times d"><mrow><mi>d</mi> <mo>Ã—</mo> <mi>d</mi></mrow></math>
    submatrix is simply the identity matrix, because <math alttext="z Subscript 1
    colon d Baseline equals x Subscript 1 colon d"><mrow><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>=</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mrow></math>
    . These elements are passed straight through without being updated. The top-right
    submatrix is therefore 0, because <math alttext="z Subscript 1 colon d"><msub><mi>z</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></math> is not dependent on
    <math alttext="x Subscript d plus 1 colon upper D"><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>
    .
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: å·¦ä¸Šè§’çš„<math alttext="d times d"><mrow><mi>d</mi> <mo>Ã—</mo> <mi>d</mi></mrow></math>å­çŸ©é˜µåªæ˜¯å•ä½çŸ©é˜µï¼Œå› ä¸º<math
    alttext="z Subscript 1 colon d Baseline equals x Subscript 1 colon d"><mrow><msub><mi>z</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>=</mo> <msub><mi>x</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mrow></math>ã€‚è¿™äº›å…ƒç´ ç›´æ¥ä¼ é€’è€Œä¸è¢«æ›´æ–°ã€‚å› æ­¤ï¼Œå³ä¸Šè§’çš„å­çŸ©é˜µä¸º0ï¼Œå› ä¸º<math
    alttext="z Subscript 1 colon d"><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></math>ä¸ä¾èµ–äº<math
    alttext="x Subscript d plus 1 colon upper D"><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>ã€‚
- en: The bottom-left submatrix is complex, and we do not seek to simplify this. The
    bottom-right submatrix is simply a diagonal matrix, filled with the elements of
    <math alttext="normal e normal x normal p left-parenthesis s left-parenthesis
    x Subscript 1 colon d Baseline right-parenthesis right-parenthesis"><mrow><mi>exp</mi>
    <mo>(</mo> <mi>s</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow></math> , because <math alttext="z Subscript
    d plus 1 colon upper D"><msub><mi>z</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>
    is linearly dependent on <math alttext="x Subscript d plus 1 colon upper D"><msub><mi>x</mi>
    <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>
    and the gradient is dependent only on the scaling factor (not on the translation
    factor). [FigureÂ 6-7](#jacobian_upper_triangular) shows a diagram of this matrix
    form, where only the nonzero elements are filled in with color.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: å·¦ä¸‹è§’çš„å­çŸ©é˜µæ˜¯å¤æ‚çš„ï¼Œæˆ‘ä»¬ä¸å¯»æ±‚ç®€åŒ–è¿™ä¸ªã€‚å³ä¸‹è§’çš„å­çŸ©é˜µåªæ˜¯ä¸€ä¸ªå¯¹è§’çŸ©é˜µï¼Œå¡«å……æœ‰<math alttext="normal e normal x normal
    p left-parenthesis s left-parenthesis x Subscript 1 colon d Baseline right-parenthesis
    right-parenthesis"><mrow><mi>exp</mi> <mo>(</mo> <mi>s</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub> <mo>)</mo></mrow> <mo>)</mo></mrow></math>
    ï¼Œå› ä¸º<math alttext="z Subscript d plus 1 colon upper D"><msub><mi>z</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>æ˜¯çº¿æ€§ç›¸å…³äº<math
    alttext="x Subscript d plus 1 colon upper D"><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></math>ï¼Œæ¢¯åº¦ä»…ä¾èµ–äºç¼©æ”¾å› å­ï¼ˆè€Œä¸ä¾èµ–äºå¹³ç§»å› å­ï¼‰ã€‚[å›¾6-7](#jacobian_upper_triangular)æ˜¾ç¤ºäº†è¿™ä¸ªçŸ©é˜µå½¢å¼çš„å›¾è¡¨ï¼Œåªæœ‰éé›¶å…ƒç´ è¢«å¡«å……ä¸ºå½©è‰²ã€‚
- en: Notice how there are no nonzero elements above the diagonalâ€”for this reason,
    this matrix form is called *lower triangular*. Now we see the benefit of structuring
    the matrix in this wayâ€”the determinant of a lower-triangular matrix is just equal
    to the product of the diagonal elements. In other words, the determinant is not
    dependent on any of the complex derivatives in the bottom-left submatrix!
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„å¯¹è§’çº¿ä¸Šæ–¹æ²¡æœ‰éé›¶å…ƒç´ â€”å› æ­¤ï¼Œè¿™ç§çŸ©é˜µå½¢å¼è¢«ç§°ä¸º*ä¸‹ä¸‰è§’å½¢*ã€‚ç°åœ¨æˆ‘ä»¬çœ‹åˆ°äº†ä»¥è¿™ç§æ–¹å¼æ„é€ çŸ©é˜µçš„å¥½å¤„â€”ä¸‹ä¸‰è§’çŸ©é˜µçš„è¡Œåˆ—å¼å°±ç­‰äºå¯¹è§’çº¿å…ƒç´ çš„ä¹˜ç§¯ã€‚æ¢å¥è¯è¯´ï¼Œè¡Œåˆ—å¼ä¸ä¾èµ–äºå·¦ä¸‹å­çŸ©é˜µä¸­çš„ä»»ä½•å¤æ‚å¯¼æ•°ï¼
- en: '![](Images/gdl2_0607.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0607.png)'
- en: Figure 6-7\. The Jacobian matrix of the transformationâ€”a lower triangular matrix,
    with determinant equal to the product of the elements along the diagonal
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-7ã€‚å˜æ¢çš„é›…å¯æ¯”çŸ©é˜µâ€”â€”ä¸€ä¸ªä¸‹ä¸‰è§’çŸ©é˜µï¼Œè¡Œåˆ—å¼ç­‰äºå¯¹è§’çº¿ä¸Šå…ƒç´ çš„ä¹˜ç§¯
- en: 'Therefore, we can write the determinant of this matrix as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªçŸ©é˜µçš„è¡Œåˆ—å¼å†™æˆå¦‚ä¸‹å½¢å¼ï¼š
- en: <math alttext="normal d normal e normal t left-parenthesis normal upper J right-parenthesis
    equals normal e normal x normal p left-bracket sigma-summation Underscript j Endscripts
    s left-parenthesis x Subscript 1 colon d Baseline right-parenthesis Subscript
    j Baseline right-bracket" display="block"><mrow><mi>det</mi> <mrow><mo>(</mo>
    <mi mathvariant="normal">J</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>exp</mi> <mfenced
    separators="" open="[" close="]"><munder><mo>âˆ‘</mo> <mi>j</mi></munder> <mi>s</mi>
    <msub><mrow><mo>(</mo><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow> <mi>j</mi></msub></mfenced></mrow></math>
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal d normal e normal t left-parenthesis normal upper J right-parenthesis
    equals normal e normal x normal p left-bracket sigma-summation Underscript j Endscripts
    s left-parenthesis x Subscript 1 colon d Baseline right-parenthesis Subscript
    j Baseline right-bracket" display="block"><mrow><mi>det</mi> <mrow><mo>(</mo>
    <mi mathvariant="normal">J</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>exp</mi> <mfenced
    separators="" open="[" close="]"><munder><mo>âˆ‘</mo> <mi>j</mi></munder> <mi>s</mi>
    <msub><mrow><mo>(</mo><msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow> <mi>j</mi></msub></mfenced></mrow></math>
- en: This is easily computable, which was one of the two original goals of building
    a normalizing flow model.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¾ˆå®¹æ˜“è®¡ç®—çš„ï¼Œè¿™æ˜¯æ„å»ºå½’ä¸€åŒ–æµæ¨¡å‹çš„ä¸¤ä¸ªæœ€åˆç›®æ ‡ä¹‹ä¸€ã€‚
- en: 'The other goal was that the function must be easily invertible. We can see
    that this is true as we can write down the invertible function just by rearranging
    the forward equations, as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: å¦ä¸€ä¸ªç›®æ ‡æ˜¯å‡½æ•°å¿…é¡»æ˜“äºåè½¬ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥é€šè¿‡é‡æ–°æ’åˆ—æ­£å‘æ–¹ç¨‹æ¥å†™å‡ºå¯é€†å‡½æ•°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: <math alttext="StartLayout 1st Row 1st Column x Subscript 1 colon d 2nd Column
    equals 3rd Column z Subscript 1 colon d 2nd Row 1st Column x Subscript d plus
    1 colon upper D 2nd Column equals 3rd Column left-parenthesis z Subscript d plus
    1 colon upper D Baseline minus t left-parenthesis x Subscript 1 colon d Baseline
    right-parenthesis right-parenthesis circled-dot normal e normal x normal p left-parenthesis
    minus s left-parenthesis x Subscript 1 colon d Baseline right-parenthesis right-parenthesis
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>x</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mrow><mo>(</mo> <msub><mi>z</mi>
    <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub> <mo>-</mo>
    <mi>t</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>âŠ™</mo> <mi>exp</mi> <mfenced separators=""
    open="(" close=")"><mo>-</mo> <mi>s</mi> <mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mfenced></mrow></mtd></mtr></mtable></math>
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column x Subscript 1 colon d 2nd Column
    equals 3rd Column z Subscript 1 colon d 2nd Row 1st Column x Subscript d plus
    1 colon upper D 2nd Column equals 3rd Column left-parenthesis z Subscript d plus
    1 colon upper D Baseline minus t left-parenthesis x Subscript 1 colon d Baseline
    right-parenthesis right-parenthesis circled-dot normal e normal x normal p left-parenthesis
    minus s left-parenthesis x Subscript 1 colon d Baseline right-parenthesis right-parenthesis
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>x</mi>
    <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><msub><mi>z</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>x</mi> <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mrow><mo>(</mo> <msub><mi>z</mi>
    <mrow><mi>d</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>D</mi></mrow></msub> <mo>-</mo>
    <mi>t</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>âŠ™</mo> <mi>exp</mi> <mfenced separators=""
    open="(" close=")"><mo>-</mo> <mi>s</mi> <mo>(</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mo>:</mo><mi>d</mi></mrow></msub>
    <mo>)</mo></mfenced></mrow></mtd></mtr></mtable></math>
- en: The equivalent diagram is shown in [FigureÂ 6-8](#backward_update_equations).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ç­‰æ•ˆå›¾è¡¨æ˜¾ç¤ºåœ¨[å›¾6-8](#backward_update_equations)ä¸­ã€‚
- en: '![](Images/gdl2_0608.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0608.png)'
- en: Figure 6-8\. The inverse function x = g(z)
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-8ã€‚é€†å‡½æ•°x = g(z)
- en: We now have almost everything we need to build our RealNVP model. However, there
    is one issue that still remainsâ€”how should we update the first <math alttext="d"><mi>d</mi></math>
    elements of the input? Currently they are left completely unchanged by the model!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å‡ ä¹æ‹¥æœ‰æ„å»ºRealNVPæ¨¡å‹æ‰€éœ€çš„ä¸€åˆ‡ã€‚ç„¶è€Œï¼Œä»ç„¶å­˜åœ¨ä¸€ä¸ªé—®é¢˜â€”æˆ‘ä»¬åº”è¯¥å¦‚ä½•æ›´æ–°è¾“å…¥çš„å‰<d>ä¸ªå…ƒç´ ï¼Ÿç›®å‰ï¼Œå®ƒä»¬è¢«æ¨¡å‹å®Œå…¨ä¿æŒä¸å˜ï¼
- en: Stacking coupling layers
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å †å è€¦åˆå±‚
- en: To resolve this problem, we can use a really simple trick. If we stack coupling
    layers on top of each other but alternate the masking pattern, the layers that
    are left unchanged by one layer will be updated in the next. This architecture
    has the added benefit of being able to learn more complex representations of the
    data, as it is a deeper neural network.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªéå¸¸ç®€å•çš„æŠ€å·§ã€‚å¦‚æœæˆ‘ä»¬å°†è€¦åˆå±‚å †å åœ¨ä¸€èµ·ï¼Œä½†äº¤æ›¿æ©ç æ¨¡å¼ï¼Œé‚£ä¹ˆè¢«ä¸€ä¸ªå±‚ä¿æŒä¸å˜çš„å±‚å°†åœ¨ä¸‹ä¸€ä¸ªå±‚ä¸­æ›´æ–°ã€‚è¿™ç§æ¶æ„çš„é¢å¤–å¥½å¤„æ˜¯èƒ½å¤Ÿå­¦ä¹ æ•°æ®çš„æ›´å¤æ‚è¡¨ç¤ºï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªæ›´æ·±çš„ç¥ç»ç½‘ç»œã€‚
- en: 'The Jacobian of this composition of coupling layers will still be simple to
    compute, because linear algebra tells us that the determinant of a matrix product
    is the product of the determinants. Similarly, the inverse of the composition
    of two functions is just the composition of the inverses, as shown in the following
    equations:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›è€¦åˆå±‚çš„é›…å¯æ¯”çŸ©é˜µä»ç„¶å¾ˆå®¹æ˜“è®¡ç®—ï¼Œå› ä¸ºçº¿æ€§ä»£æ•°å‘Šè¯‰æˆ‘ä»¬ï¼ŒçŸ©é˜µä¹˜ç§¯çš„è¡Œåˆ—å¼æ˜¯å¯¹è§’çº¿ä¸Šå…ƒç´ çš„ä¹˜ç§¯ã€‚åŒæ ·ï¼Œä¸¤ä¸ªå‡½æ•°çš„å¤åˆçš„é€†å‡½æ•°å°±æ˜¯é€†å‡½æ•°çš„å¤åˆï¼Œå¦‚ä¸‹æ–¹ç¨‹æ‰€ç¤ºï¼š
- en: <math alttext="StartLayout 1st Row 1st Column normal d normal e normal t left-parenthesis
    normal upper A dot normal upper B right-parenthesis 2nd Column equals 3rd Column
    normal d normal e normal t left-parenthesis normal upper A right-parenthesis normal
    d normal e normal t left-parenthesis normal upper B right-parenthesis 2nd Row
    1st Column left-parenthesis f Subscript b Baseline ring f Subscript a Baseline
    right-parenthesis Superscript negative 1 2nd Column equals 3rd Column f Subscript
    a Superscript negative 1 Baseline ring f Subscript b Superscript negative 1 EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>det</mi>
    <mo>(</mo> <mi mathvariant="normal">A</mi> <mo>Â·</mo> <mi mathvariant="normal">B</mi>
    <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mi>det</mi>
    <mo>(</mo> <mi mathvariant="normal">A</mi> <mo>)</mo> <mi>det</mi> <mo>(</mo>
    <mi mathvariant="normal">B</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msup><mrow><mo>(</mo><msub><mi>f</mi>
    <mi>b</mi></msub> <mo>âˆ˜</mo><msub><mi>f</mi> <mi>a</mi></msub> <mo>)</mo></mrow>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msubsup><mi>f</mi>
    <mi>a</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msubsup> <mo>âˆ˜</mo> <msubsup><mi>f</mi>
    <mi>b</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></mtd></mtr></mtable></math>
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column normal d normal e normal t left-parenthesis
    normal upper A dot normal upper B right-parenthesis 2nd Column equals 3rd Column
    normal d normal e normal t left-parenthesis normal upper A right-parenthesis normal
    d normal e normal t left-parenthesis normal upper B right-parenthesis 2nd Row
    1st Column left-parenthesis f Subscript b Baseline ring f Subscript a Baseline
    right-parenthesis Superscript negative 1 2nd Column equals 3rd Column f Subscript
    a Superscript negative 1 Baseline ring f Subscript b Superscript negative 1 EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>det</mi>
    <mo>(</mo> <mi mathvariant="normal">A</mi> <mo>Â·</mo> <mi mathvariant="normal">B</mi>
    <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mi>det</mi>
    <mo>(</mo> <mi mathvariant="normal">A</mi> <mo>)</mo> <mi>det</mi> <mo>(</mo>
    <mi mathvariant="normal">B</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msup><mrow><mo>(</mo><msub><mi>f</mi>
    <mi>b</mi></msub> <mo>âˆ˜</mo><msub><mi>f</mi> <mi>a</mi></msub> <mo>)</mo></mrow>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msubsup><mi>f</mi>
    <mi>a</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msubsup> <mo>âˆ˜</mo> <msubsup><mi>f</mi>
    <mi>b</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msubsup></mrow></mtd></mtr></mtable></math>
- en: Therefore, if we stack coupling layers, flipping the masking each time, we can
    build a neural network that is able to transform the whole input tensor, while
    retaining the essential properties of having a simple Jacobian determinant and
    being invertible. [FigureÂ 6-9](#stacking_coupling) shows the overall structure.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬å †å è€¦åˆå±‚ï¼Œæ¯æ¬¡ç¿»è½¬æ©ç ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿè½¬æ¢æ•´ä¸ªè¾“å…¥å¼ é‡ï¼ŒåŒæ—¶ä¿ç•™å…·æœ‰ç®€å•é›…å¯æ¯”è¡Œåˆ—å¼å’Œå¯é€†æ€§çš„åŸºæœ¬å±æ€§ã€‚[å›¾6-9](#stacking_coupling)æ˜¾ç¤ºäº†æ•´ä½“ç»“æ„ã€‚
- en: '![](Images/gdl2_0609.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0609.png)'
- en: Figure 6-9\. Stacking coupling layers, alternating the masking with each layer
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-9ã€‚å †å è€¦åˆå±‚ï¼Œæ¯å±‚äº¤æ›¿æ©ç 
- en: Training the RealNVP Model
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®­ç»ƒRealNVPæ¨¡å‹
- en: 'Now that we have built the RealNVP model, we can train it to learn the complex
    distribution of the two moons dataset. Remember, we want to minimize the negative
    log-likelihood of the data under the model <math alttext="minus log p Subscript
    upper X Baseline left-parenthesis x right-parenthesis"><mrow><mo>-</mo> <mo form="prefix">log</mo>
    <mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></mrow></math>
    . Using [Equation 6-1](#cov_equation), we can write this as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»æ„å»ºäº†RealNVPæ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥è®­ç»ƒå®ƒæ¥å­¦ä¹ ä¸¤ä¸ªæœˆäº®æ•°æ®é›†çš„å¤æ‚åˆ†å¸ƒã€‚è®°ä½ï¼Œæˆ‘ä»¬å¸Œæœ›æœ€å°åŒ–æ¨¡å‹ä¸‹æ•°æ®çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ <math alttext="minus
    log p Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><mo>-</mo>
    <mo form="prefix">log</mo> <mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></mrow></math> ã€‚ä½¿ç”¨[æ–¹ç¨‹6-1](#cov_equation)ï¼Œæˆ‘ä»¬å¯ä»¥å†™æˆå¦‚ä¸‹å½¢å¼ï¼š
- en: <math alttext="minus log p Subscript upper X Baseline left-parenthesis x right-parenthesis
    equals minus log p Subscript upper Z Baseline left-parenthesis z right-parenthesis
    minus log StartAbsoluteValue normal d normal e normal t left-parenthesis StartFraction
    normal partial-differential z Over normal partial-differential x EndFraction right-parenthesis
    EndAbsoluteValue" display="block"><mrow><mo>-</mo> <mo form="prefix">log</mo>
    <mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow>
    <mo>=</mo> <mo>-</mo> <mo form="prefix">log</mo> <mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow> <mo>-</mo> <mo form="prefix">log</mo>
    <mfenced separators="" open="|" close="|"><mi>det</mi> <mfenced separators=""
    open="(" close=")"><mfrac><mrow><mi>âˆ‚</mi><mi>z</mi></mrow> <mrow><mi>âˆ‚</mi><mi>x</mi></mrow></mfrac></mfenced></mfenced></mrow></math>
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="minus log p Subscript upper X Baseline left-parenthesis x right-parenthesis
    equals minus log p Subscript upper Z Baseline left-parenthesis z right-parenthesis
    minus log StartAbsoluteValue normal d normal e normal t left-parenthesis StartFraction
    normal partial-differential z Over normal partial-differential x EndFraction right-parenthesis
    EndAbsoluteValue" display="block"><mrow><mo>-</mo> <mo form="prefix">log</mo>
    <mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow>
    <mo>=</mo> <mo>-</mo> <mo form="prefix">log</mo> <mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow> <mo>-</mo> <mo form="prefix">log</mo>
    <mfenced separators="" open="|" close="|"><mi>det</mi> <mfenced separators=""
    open="(" close=")"><mfrac><mrow><mi>âˆ‚</mi><mi>z</mi></mrow> <mrow><mi>âˆ‚</mi><mi>x</mi></mrow></mfrac></mfenced></mfenced></mrow></math>
- en: We choose the target output distribution <math alttext="p Subscript upper Z
    Baseline left-parenthesis z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></math> of the forward process
    <math alttext="f"><mi>f</mi></math> to be a standard Gaussian, because we can
    easily sample from this distribution. We can then transform a point sampled from
    the Gaussian back into the original image domain by applying the inverse process
    <math alttext="g"><mi>g</mi></math> , as shown in [FigureÂ 6-10](#realnvp_to_gaussian).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é€‰æ‹©æ­£å‘è¿‡ç¨‹<f>çš„ç›®æ ‡è¾“å‡ºåˆ†å¸ƒ <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> ä¸ºæ ‡å‡†é«˜æ–¯åˆ†å¸ƒï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥è½»æ¾ä»è¿™ä¸ªåˆ†å¸ƒä¸­é‡‡æ ·ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡åº”ç”¨é€†è¿‡ç¨‹<g>å°†ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·çš„ç‚¹è½¬æ¢å›åŸå§‹å›¾åƒåŸŸï¼Œå¦‚[å›¾6-10](#realnvp_to_gaussian)æ‰€ç¤ºã€‚
- en: '![](Images/gdl2_0610.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0610.png)'
- en: Figure 6-10\. Transforming between the complex distribution <math alttext="p
    Subscript upper X Baseline left-parenthesis x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>X</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    and a simple Gaussian <math alttext="p Subscript upper Z Baseline left-parenthesis
    z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub> <mrow><mo>(</mo>
    <mi>z</mi> <mo>)</mo></mrow></mrow></math> in 1D (middle row) and 2D (bottom row)
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-10ã€‚åœ¨1Dï¼ˆä¸­é—´è¡Œï¼‰å’Œ2Dï¼ˆåº•éƒ¨è¡Œï¼‰ä¸­ï¼Œå°†å¤æ‚åˆ†å¸ƒ<math alttext="p Subscript upper X Baseline left-parenthesis
    x right-parenthesis"><mrow><msub><mi>p</mi> <mi>X</mi></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>å’Œç®€å•é«˜æ–¯<math alttext="p Subscript upper
    Z Baseline left-parenthesis z right-parenthesis"><mrow><msub><mi>p</mi> <mi>Z</mi></msub>
    <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow></mrow></math>ä¹‹é—´çš„è½¬æ¢
- en: '[ExampleÂ 6-3](#realnvp_model) shows how to build a RealNVP network, as a custom
    Keras `Model`.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç¤ºä¾‹6-3](#realnvp_model)å±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªRealNVPç½‘ç»œï¼Œä½œä¸ºè‡ªå®šä¹‰çš„Keras `Model`ã€‚'
- en: Example 6-3\. Building the RealNVP model in Keras
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹6-3ã€‚åœ¨Kerasä¸­æ„å»ºRealNVPæ¨¡å‹
- en: '[PRE2]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](Images/1.png)](#co_normalizing_flow_models_CO3-1)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_normalizing_flow_models_CO3-1)'
- en: The target distribution is a standard 2D Gaussian.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®æ ‡åˆ†å¸ƒæ˜¯æ ‡å‡†çš„2Dé«˜æ–¯åˆ†å¸ƒã€‚
- en: '[![2](Images/2.png)](#co_normalizing_flow_models_CO3-2)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_normalizing_flow_models_CO3-2)'
- en: Here, we create the alternating mask pattern.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åˆ›å»ºäº¤æ›¿çš„æ©ç æ¨¡å¼ã€‚
- en: '[![3](Images/3.png)](#co_normalizing_flow_models_CO3-3)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_normalizing_flow_models_CO3-3)'
- en: A list of `Coupling` layers that define the RealNVP network.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å®šä¹‰RealNVPç½‘ç»œçš„`Coupling`å±‚åˆ—è¡¨ã€‚
- en: '[![4](Images/4.png)](#co_normalizing_flow_models_CO3-4)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_normalizing_flow_models_CO3-4)'
- en: In the main `call` function of the network, we loop over the `Coupling` layers.
    If `training=True`, then we move forward through the layers (i.e., from data to
    latent space). If `training=False`, then we move backward through the layers (i.e.,
    from latent space to data).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç½‘ç»œçš„ä¸»`call`å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬éå†`Coupling`å±‚ã€‚å¦‚æœ`training=True`ï¼Œé‚£ä¹ˆæˆ‘ä»¬é€šè¿‡å±‚å‘å‰ç§»åŠ¨ï¼ˆå³ä»æ•°æ®åˆ°æ½œåœ¨ç©ºé—´ï¼‰ã€‚å¦‚æœ`training=False`ï¼Œé‚£ä¹ˆæˆ‘ä»¬é€šè¿‡å±‚å‘åç§»åŠ¨ï¼ˆå³ä»æ½œåœ¨ç©ºé—´åˆ°æ•°æ®ï¼‰ã€‚
- en: '[![5](Images/5.png)](#co_normalizing_flow_models_CO3-5)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_normalizing_flow_models_CO3-5)'
- en: This line describes both the forward and backward equations dependent on the
    `direction` (try plugging in `direction = -1` and `direction = 1` to prove this
    to yourself!).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¡Œæè¿°äº†æ­£å‘å’Œåå‘æ–¹ç¨‹ï¼Œå–å†³äº`direction`ï¼ˆå°è¯•å°†`direction = -1`å’Œ`direction = 1`ä»£å…¥ä»¥è¯æ˜è¿™ä¸€ç‚¹ï¼ï¼‰ã€‚
- en: '[![6](Images/6.png)](#co_normalizing_flow_models_CO3-6)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_normalizing_flow_models_CO3-6)'
- en: The log determinant of the Jacobian, which we need to calculate the loss function,
    is simply the sum of the scaling factors.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: é›…å¯æ¯”è¡Œåˆ—å¼çš„å¯¹æ•°ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—æŸå¤±å‡½æ•°ï¼Œç®€å•åœ°æ˜¯ç¼©æ”¾å› å­çš„æ€»å’Œã€‚
- en: '[![7](Images/7.png)](#co_normalizing_flow_models_CO3-7)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](Images/7.png)](#co_normalizing_flow_models_CO3-7)'
- en: The loss function is the negative sum of the log probability of the transformed
    data, under our target Gaussian distribution and the log determinant of the Jacobian.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±å‡½æ•°æ˜¯è½¬æ¢æ•°æ®çš„å¯¹æ•°æ¦‚ç‡çš„è´Ÿå’Œï¼Œæ ¹æ®æˆ‘ä»¬çš„ç›®æ ‡é«˜æ–¯åˆ†å¸ƒå’Œé›…å¯æ¯”è¡Œåˆ—å¼çš„å¯¹æ•°ç¡®å®šã€‚
- en: Analysis of the RealNVP Model
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RealNVPæ¨¡å‹çš„åˆ†æ
- en: Once the model is trained, we can use it to transform the training set into
    the latent space (using the forward direction, <math alttext="f"><mi>f</mi></math>
    ) and, more importantly, to transform a sampled point in the latent space into
    a point that looks like it could have been sampled from the original data distribution
    (using the backward direction, <math alttext="g"><mi>g</mi></math> ).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡å‹è®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å®ƒå°†è®­ç»ƒé›†è½¬æ¢ä¸ºæ½œåœ¨ç©ºé—´ï¼ˆä½¿ç”¨æ­£å‘æ–¹å‘<math alttext="f"><mi>f</mi></math>ï¼‰ï¼Œæ›´é‡è¦çš„æ˜¯ï¼Œå°†æ½œåœ¨ç©ºé—´ä¸­çš„é‡‡æ ·ç‚¹è½¬æ¢ä¸ºçœ‹èµ·æ¥å¯èƒ½æ˜¯ä»åŸå§‹æ•°æ®åˆ†å¸ƒä¸­é‡‡æ ·çš„ç‚¹ï¼ˆä½¿ç”¨åå‘æ–¹å‘<math
    alttext="g"><mi>g</mi></math>ï¼‰ã€‚
- en: '[FigureÂ 6-11](#realnvp_before_training) shows the output from the network before
    any learning has taken placeâ€”the forward and backward directions just pass information
    straight through with hardly any transformation.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾6-11](#realnvp_before_training)æ˜¾ç¤ºäº†åœ¨ä»»ä½•å­¦ä¹ ä¹‹å‰ç½‘ç»œçš„è¾“å‡º - æ­£å‘å’Œåå‘æ–¹å‘åªæ˜¯ç›´æ¥ä¼ é€’ä¿¡æ¯ï¼Œå‡ ä¹æ²¡æœ‰ä»»ä½•è½¬æ¢ã€‚'
- en: '![](Images/gdl2_0611.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0611.png)'
- en: Figure 6-11\. The RealNVP model inputs (left) and outputs (right) before training,
    for the forward process (top) and the reverse process (bottom)
  id: totrans-148
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-11ã€‚RealNVPæ¨¡å‹åœ¨è®­ç»ƒå‰çš„è¾“å…¥ï¼ˆå·¦ï¼‰å’Œè¾“å‡ºï¼ˆå³ï¼‰ï¼Œç”¨äºæ­£å‘è¿‡ç¨‹ï¼ˆé¡¶éƒ¨ï¼‰å’Œåå‘è¿‡ç¨‹ï¼ˆåº•éƒ¨ï¼‰
- en: After training ([FigureÂ 6-12](#realnvp_after_training)), the forward process
    is able to convert the points from the training set into a distribution that resembles
    a Gaussian. Likewise, the backward process can take points sampled from a Gaussian
    distribution and map them back to a distribution that resembles the original data.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒåï¼ˆ[å›¾6-12](#realnvp_after_training)ï¼‰ï¼Œæ­£å‘è¿‡ç¨‹èƒ½å¤Ÿå°†è®­ç»ƒé›†ä¸­çš„ç‚¹è½¬æ¢ä¸ºç±»ä¼¼é«˜æ–¯åˆ†å¸ƒçš„åˆ†å¸ƒã€‚åŒæ ·ï¼Œåå‘è¿‡ç¨‹å¯ä»¥å°†ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·çš„ç‚¹æ˜ å°„å›ç±»ä¼¼åŸå§‹æ•°æ®çš„åˆ†å¸ƒã€‚
- en: '![](Images/gdl2_0612.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0612.png)'
- en: Figure 6-12\. The RealNVP model inputs (left) and outputs (right) after training,
    for the forward process (top) and the reverse process (bottom)
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-12ã€‚RealNVPæ¨¡å‹åœ¨è®­ç»ƒåçš„è¾“å…¥ï¼ˆå·¦ï¼‰å’Œè¾“å‡ºï¼ˆå³ï¼‰ï¼Œç”¨äºæ­£å‘è¿‡ç¨‹ï¼ˆé¡¶éƒ¨ï¼‰å’Œåå‘è¿‡ç¨‹ï¼ˆåº•éƒ¨ï¼‰
- en: The loss curve for the training process is shown in [FigureÂ 6-13](#realnvp_loss_curve).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒè¿‡ç¨‹çš„æŸå¤±æ›²çº¿æ˜¾ç¤ºåœ¨[å›¾6-13](#realnvp_loss_curve)ä¸­ã€‚
- en: '![](Images/gdl2_0613.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0613.png)'
- en: Figure 6-13\. The loss curve for the RealNVP training process
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-13ã€‚RealNVPè®­ç»ƒè¿‡ç¨‹çš„æŸå¤±æ›²çº¿
- en: This completes our discussion of RealNVP, a specific case of a normalizing flow
    generative model. In the next section, weâ€™ll cover some modern normalizing flow
    models that extend the ideas introduced in the RealNVP paper.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å®Œæˆäº†æˆ‘ä»¬å¯¹RealNVPçš„è®¨è®ºï¼Œè¿™æ˜¯æ­£åˆ™åŒ–æµç”Ÿæˆæ¨¡å‹çš„ä¸€ä¸ªç‰¹å®šæ¡ˆä¾‹ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€äº›ç°ä»£æ­£åˆ™åŒ–æµæ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹æ‰©å±•äº†RealNVPè®ºæ–‡ä¸­ä»‹ç»çš„æ€æƒ³ã€‚
- en: Other Normalizing Flow Models
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…¶ä»–æ­£åˆ™åŒ–æµæ¨¡å‹
- en: Two other successful and important normalizing flow models are *GLOW* and *FFJORD*.
    The following sections describe the key advancements they made.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å¦å¤–ä¸¤ä¸ªæˆåŠŸä¸”é‡è¦çš„æ­£åˆ™åŒ–æµæ¨¡å‹æ˜¯*GLOW*å’Œ*FFJORD*ã€‚ä»¥ä¸‹éƒ¨åˆ†æè¿°äº†å®ƒä»¬æ‰€å–å¾—çš„å…³é”®è¿›å±•ã€‚
- en: GLOW
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GLOW
- en: Presented at NeurIPS 2018, GLOW was one of the first models to demonstrate the
    ability of normalizing flows to generate high-quality samples and produce a meaningful
    latent space that can be traversed to manipulate samples. The key step was to
    replace the reverse masking setup with invertible 1 Ã— 1 convolutional layers.
    For example, with RealNVP applied to images, the ordering of the channels is flipped
    after each step, to ensure that the network gets the chance to transform all of
    the input. In GLOW a 1 Ã— 1 convolution is applied instead, which effectively acts
    as a general method to produce any permutation of the channels that the model
    desires. The authors show that even with this addition, the distribution as a
    whole remains tractable, with determinants and inverses that are easy to compute
    at scale.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨NeurIPS 2018ä¸Šå±•ç¤ºçš„GLOWæ˜¯ç¬¬ä¸€ä¸ªè¯æ˜å½’ä¸€åŒ–æµèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡æ ·æœ¬å¹¶äº§ç”Ÿå¯éå†ä»¥æ“ä½œæ ·æœ¬çš„æœ‰æ„ä¹‰æ½œåœ¨ç©ºé—´çš„æ¨¡å‹ä¹‹ä¸€ã€‚å…³é”®æ­¥éª¤æ˜¯ç”¨å¯é€†çš„1Ã—1å·ç§¯å±‚æ›¿æ¢åå‘æ©ç è®¾ç½®ã€‚ä¾‹å¦‚ï¼Œåœ¨åº”ç”¨äºå›¾åƒçš„RealNVPä¸­ï¼Œé€šé“çš„é¡ºåºåœ¨æ¯ä¸€æ­¥ä¹‹åéƒ½ä¼šç¿»è½¬ï¼Œä»¥ç¡®ä¿ç½‘ç»œæœ‰æœºä¼šè½¬æ¢æ‰€æœ‰çš„è¾“å…¥ã€‚è€Œåœ¨GLOWä¸­ï¼Œåº”ç”¨äº†1Ã—1å·ç§¯ï¼Œè¿™æœ‰æ•ˆåœ°ä½œä¸ºä¸€ç§é€šç”¨æ–¹æ³•æ¥äº§ç”Ÿæ¨¡å‹æ‰€éœ€çš„ä»»ä½•é€šé“æ’åˆ—ã€‚ä½œè€…è¡¨æ˜ï¼Œå³ä½¿åŠ å…¥äº†è¿™ä¸€æ­¥éª¤ï¼Œæ•´ä½“åˆ†å¸ƒä»ç„¶æ˜¯å¯å¤„ç†çš„ï¼Œå…·æœ‰æ˜“äºå¤§è§„æ¨¡è®¡ç®—çš„è¡Œåˆ—å¼å’Œé€†ã€‚
- en: '![](Images/gdl2_0614.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0614.png)'
- en: 'Figure 6-14\. Random samples from the GLOW model (source: [Kingma and Dhariwal,
    2018](https://arxiv.org/abs/1807.03039))^([2](ch06.xhtml#idm45387012901552))'
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-14ã€‚GLOWæ¨¡å‹çš„éšæœºæ ·æœ¬ï¼ˆæ¥æºï¼š[Kingmaå’ŒDhariwalï¼Œ2018](https://arxiv.org/abs/1807.03039)ï¼‰^([2](ch06.xhtml#idm45387012901552))
- en: FFJORD
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FFJORD
- en: 'RealNVP and GLOW are discrete time normalizing flowsâ€”that is, they transform
    the input through a discrete set of coupling layers. FFJORD (Free-Form Continuous
    Dynamics for Scalable Reversible Generative Models), presented at ICLR 2019, shows
    how it is possible to model the transformation as a continuous time process (i.e.,
    by taking the limit as the number of steps in the flow tends to infinity and the
    step size tends to zero). In this case, the dynamics are modeled using an ordinary
    differential equation (ODE) whose parameters are produced by a neural network
    ( <math alttext="f Subscript theta"><msub><mi>f</mi> <mi>Î¸</mi></msub></math>
    ). A black-box solver is used to solve the ODE at time <math alttext="t 1"><msub><mi>t</mi>
    <mn>1</mn></msub></math> â€”i.e., to find <math alttext="z 1"><msub><mi>z</mi> <mn>1</mn></msub></math>
    given some initial point <math alttext="z 0"><msub><mi>z</mi> <mn>0</mn></msub></math>
    sampled from a Gaussian at <math alttext="t 0"><msub><mi>t</mi> <mn>0</mn></msub></math>
    , as described by the following equations:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: RealNVPå’ŒGLOWæ˜¯ç¦»æ•£æ—¶é—´å½’ä¸€åŒ–æµæ¨¡å‹ï¼Œå³å®ƒä»¬é€šè¿‡ä¸€ç»„ç¦»æ•£çš„è€¦åˆå±‚æ¥è½¬æ¢è¾“å…¥ã€‚FFJORDï¼ˆç”¨äºå¯æ‰©å±•å¯é€†ç”Ÿæˆæ¨¡å‹çš„è‡ªç”±å½¢å¼è¿ç»­åŠ¨åŠ›å­¦ï¼‰ï¼Œåœ¨ICLR
    2019ä¸Šå±•ç¤ºäº†å¦‚ä½•å°†è½¬æ¢å»ºæ¨¡ä¸ºè¿ç»­æ—¶é—´è¿‡ç¨‹ï¼ˆå³ï¼Œé€šè¿‡å°†æµä¸­æ­¥æ•°è¶‹è¿‘äºæ— ç©·å¤§ä¸”æ­¥é•¿è¶‹è¿‘äºé›¶çš„æé™æ¥å®ç°ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒåŠ¨åŠ›å­¦æ˜¯ä½¿ç”¨ç”±ç¥ç»ç½‘ç»œäº§ç”Ÿçš„æ™®é€šå¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰æ¥å»ºæ¨¡çš„ã€‚ä½¿ç”¨é»‘ç›’æ±‚è§£å™¨æ¥è§£å†³åœ¨æ—¶é—´t1å¤„çš„ODEï¼Œå³æ‰¾åˆ°åœ¨æ—¶é—´t0å¤„ä»é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·çš„ä¸€äº›åˆå§‹ç‚¹z0çš„z1ï¼Œå¦‚ä¸‹é¢çš„æ–¹ç¨‹æ‰€æè¿°çš„é‚£æ ·ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column z 0 2nd Column tilde 3rd Column
    p left-parenthesis z 0 right-parenthesis 2nd Row 1st Column StartFraction normal
    partial-differential z left-parenthesis t right-parenthesis Over normal partial-differential
    t EndFraction 2nd Column equals 3rd Column f Subscript theta Baseline left-parenthesis
    x left-parenthesis t right-parenthesis comma t right-parenthesis 3rd Row 1st Column
    x 2nd Column equals 3rd Column z 1 EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>z</mi> <mn>0</mn></msub></mtd> <mtd><mo>âˆ¼</mo></mtd>
    <mtd columnalign="left"><mrow><mi>p</mi> <mo>(</mo> <msub><mi>z</mi> <mn>0</mn></msub>
    <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mfrac><mrow><mi>âˆ‚</mi><mi>z</mi><mo>(</mo><mi>t</mi><mo>)</mo></mrow>
    <mrow><mi>âˆ‚</mi><mi>t</mi></mrow></mfrac></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>f</mi>
    <mi>Î¸</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mrow><mo>(</mo> <mi>t</mi> <mo>)</mo></mrow>
    <mo>,</mo> <mi>t</mi> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>x</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><msub><mi>z</mi> <mn>1</mn></msub></mtd></mtr></mtable></math>
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column z 0 2nd Column tilde 3rd Column
    p left-parenthesis z 0 right-parenthesis 2nd Row 1st Column StartFraction normal
    partial-differential z left-parenthesis t right-parenthesis Over normal partial-differential
    t EndFraction 2nd Column equals 3rd Column f Subscript theta Baseline left-parenthesis
    x left-parenthesis t right-parenthesis comma t right-parenthesis 3rd Row 1st Column
    x 2nd Column equals 3rd Column z 1 EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>z</mi> <mn>0</mn></msub></mtd> <mtd><mo>âˆ¼</mo></mtd>
    <mtd columnalign="left"><mrow><mi>p</mi> <mo>(</mo> <msub><mi>z</mi> <mn>0</mn></msub>
    <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mfrac><mrow><mi>âˆ‚</mi><mi>z</mi><mo>(</mo><mi>t</mi><mo>)</mo></mrow>
    <mrow><mi>âˆ‚</mi><mi>t</mi></mrow></mfrac></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>f</mi>
    <mi>Î¸</mi></msub> <mrow><mo>(</mo> <mi>x</mi> <mrow><mo>(</mo> <mi>t</mi> <mo>)</mo></mrow>
    <mo>,</mo> <mi>t</mi> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>x</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><msub><mi>z</mi> <mn>1</mn></msub></mtd></mtr></mtable></math>
- en: A diagram of the transformation process is shown in [FigureÂ 6-15](#ffjord_model).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: è½¬æ¢è¿‡ç¨‹çš„å›¾ç¤ºåœ¨[å›¾6-15](#ffjord_model)ä¸­å±•ç¤ºã€‚
- en: '![](Images/gdl2_0615.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/gdl2_0615.png)'
- en: 'Figure 6-15\. FFJORD models the transformation between the data distribution
    and a standard Gaussian via an ordinary differential equation, parameterized by
    a neural network (source: [Will Grathwohl et al., 2018](https://arxiv.org/abs/1810.01367))^([3](ch06.xhtml#idm45387012548496))'
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾6-15ã€‚FFJORDé€šè¿‡ç”±ç¥ç»ç½‘ç»œå‚æ•°åŒ–çš„æ™®é€šå¾®åˆ†æ–¹ç¨‹æ¨¡æ‹Ÿæ•°æ®åˆ†å¸ƒä¸æ ‡å‡†é«˜æ–¯ä¹‹é—´çš„è½¬æ¢ï¼ˆæ¥æºï¼š[Will Grathwohlç­‰äººï¼Œ2018](https://arxiv.org/abs/1810.01367)ï¼‰^([3](ch06.xhtml#idm45387012548496))
- en: Summary
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: In this chapter we explored normalizing flow models such as RealNVP, GLOW, and
    FFJORD.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬æ¢è®¨äº†è¯¸å¦‚RealNVPã€GLOWå’ŒFFJORDç­‰å½’ä¸€åŒ–æµæ¨¡å‹ã€‚
- en: A normalizing flow model is an invertible function defined by a neural network
    that allows us to directly model the data density via a change of variables. In
    the general case, the change of variables equation requires us to calculate a
    highly complex Jacobian determinant, which is impractical for all but the simplest
    of examples.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: å½’ä¸€åŒ–æµæ¨¡å‹æ˜¯ç”±ç¥ç»ç½‘ç»œå®šä¹‰çš„å¯é€†å‡½æ•°ï¼Œå…è®¸æˆ‘ä»¬é€šè¿‡å˜é‡çš„æ”¹å˜ç›´æ¥å»ºæ¨¡æ•°æ®å¯†åº¦ã€‚åœ¨ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå˜é‡æ”¹å˜æ–¹ç¨‹è¦æ±‚æˆ‘ä»¬è®¡ç®—ä¸€ä¸ªé«˜åº¦å¤æ‚çš„é›…å¯æ¯”è¡Œåˆ—å¼ï¼Œè¿™å¯¹äºé™¤äº†æœ€ç®€å•çš„ä¾‹å­ä¹‹å¤–éƒ½æ˜¯ä¸åˆ‡å®é™…çš„ã€‚
- en: 'To sidestep this issue, the RealNVP model restricts the form of the neural
    network, such that it adheres to the two essential criteria: it is invertible
    and has a Jacobian determinant that is easy to compute.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è§„é¿è¿™ä¸ªé—®é¢˜ï¼ŒRealNVPæ¨¡å‹é™åˆ¶äº†ç¥ç»ç½‘ç»œçš„å½¢å¼ï¼Œä½¿å…¶ç¬¦åˆä¸¤ä¸ªåŸºæœ¬æ ‡å‡†ï¼šå¯é€†ä¸”é›…å¯æ¯”è¡Œåˆ—å¼æ˜“äºè®¡ç®—ã€‚
- en: It does this through stacking coupling layers, which produce scale and translation
    factors at each step. Importantly, the coupling layer masks the data as it flows
    through the network, in a way that ensures that the Jacobian is lower triangular
    and therefore has a simple-to-compute determinant. Full visibility of the input
    data is achieved through flipping the masks at each layer.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: å®ƒé€šè¿‡å †å è€¦åˆå±‚æ¥å®ç°ï¼Œè¿™äº›å±‚åœ¨æ¯ä¸€æ­¥äº§ç”Ÿå°ºåº¦å’Œå¹³ç§»å› å­ã€‚é‡è¦çš„æ˜¯ï¼Œè€¦åˆå±‚åœ¨æ•°æ®æµç»ç½‘ç»œæ—¶ä¼šæ©ç›–æ•°æ®ï¼Œä»¥ç¡®ä¿é›…å¯æ¯”æ˜¯ä¸‹ä¸‰è§’å½¢çš„ï¼Œå› æ­¤å…·æœ‰æ˜“äºè®¡ç®—çš„è¡Œåˆ—å¼ã€‚é€šè¿‡åœ¨æ¯ä¸€å±‚ç¿»è½¬æ©ç ï¼Œå®ç°äº†å¯¹è¾“å…¥æ•°æ®çš„å®Œå…¨å¯è§æ€§ã€‚
- en: By design, the scale and translation operations can be easily inverted, so that
    once the model is trained it is possible to run data through the network in reverse.
    This means that we can target the forward transformation process toward a standard
    Gaussian, which we can easily sample from. We can then run the sampled points
    backward through the network to generate new observations.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‰è®¾è®¡ï¼Œå°ºåº¦å’Œå¹³ç§»æ“ä½œå¯ä»¥è½»æ¾åœ°è¢«åè½¬ï¼Œå› æ­¤ä¸€æ—¦æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå°±å¯ä»¥é€šè¿‡ç½‘ç»œåå‘è¿è¡Œæ•°æ®ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥å°†æ­£å‘è½¬æ¢è¿‡ç¨‹å®šå‘åˆ°æ ‡å‡†é«˜æ–¯åˆ†å¸ƒï¼Œä»ä¸­è½»æ¾é‡‡æ ·ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ç½‘ç»œåå‘è¿è¡Œé‡‡æ ·ç‚¹ä»¥ç”Ÿæˆæ–°çš„è§‚æµ‹æ•°æ®ã€‚
- en: The RealNVP paper also shows how it is possible to apply this technique to images,
    by using convolutions inside the coupling layers, rather than densely connected
    layers. The GLOW paper extended this idea to remove the necessity for any hardcoded
    permutation of the masks. The FFJORD model introduced the concept of continuous
    time normalizing flows, by modeling the transformation process as an ODE defined
    by a neural network.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: RealNVPè®ºæ–‡è¿˜å±•ç¤ºäº†å¦‚ä½•å°†è¿™ç§æŠ€æœ¯åº”ç”¨äºå›¾åƒï¼Œé€šè¿‡åœ¨è€¦åˆå±‚å†…éƒ¨ä½¿ç”¨å·ç§¯ï¼Œè€Œä¸æ˜¯å¯†é›†è¿æ¥å±‚ã€‚GLOWè®ºæ–‡å°†è¿™ä¸€æ€æƒ³æ‰©å±•åˆ°æ¶ˆé™¤ä»»ä½•ç¡¬ç¼–ç æ’åˆ—æ©æ¨¡çš„å¿…è¦æ€§ã€‚FFJORDæ¨¡å‹å¼•å…¥äº†è¿ç»­æ—¶é—´å½’ä¸€åŒ–æµçš„æ¦‚å¿µï¼Œé€šè¿‡å°†è½¬æ¢è¿‡ç¨‹å»ºæ¨¡ä¸ºç”±ç¥ç»ç½‘ç»œå®šä¹‰çš„ODEã€‚
- en: Overall, we have seen how normalizing flows are a powerful generative modeling
    family that can produce high-quality samples, while maintaining the ability to
    tractably describe the data density function.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°äº†å½’ä¸€åŒ–æµæ˜¯ä¸€ä¸ªå¼ºå¤§çš„ç”Ÿæˆå»ºæ¨¡å®¶æ—ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„æ ·æœ¬ï¼ŒåŒæ—¶ä¿æŒèƒ½å¤Ÿå¯é åœ°æè¿°æ•°æ®å¯†åº¦å‡½æ•°çš„èƒ½åŠ›ã€‚
- en: ^([1](ch06.xhtml#idm45387014186656-marker)) Laurent Dinh et al., â€œDensity Estimation
    Using Real NVP,â€ May 27, 2016, [*https://arxiv.org/abs/1605.08803v3*](https://arxiv.org/abs/1605.08803v3).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch06.xhtml#idm45387014186656-marker)) Laurent Dinhç­‰äººï¼Œâ€œä½¿ç”¨Real NVPè¿›è¡Œå¯†åº¦ä¼°è®¡â€ï¼Œ2016å¹´5æœˆ27æ—¥ï¼Œ[*https://arxiv.org/abs/1605.08803v3*](https://arxiv.org/abs/1605.08803v3)ã€‚
- en: '^([2](ch06.xhtml#idm45387012901552-marker)) Diedrick P. Kingma and Prafulla
    Dhariwal, â€œGlow: Generative Flow with Invertible 1x1 Convolutions,â€ July 10, 2018,
    *[*https://arxiv.org/abs/1807.03039*](https://arxiv.org/abs/1807.03039)*.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '^([2](ch06.xhtml#idm45387012901552-marker)) Diedrick P. Kingmaå’ŒPrafulla Dhariwalï¼Œâ€œGlow:
    å…·æœ‰å¯é€†1x1å·ç§¯çš„ç”Ÿæˆæµâ€ï¼Œ2018å¹´7æœˆ10æ—¥ï¼Œ[*https://arxiv.org/abs/1807.03039*](https://arxiv.org/abs/1807.03039)ã€‚'
- en: '^([3](ch06.xhtml#idm45387012548496-marker)) Will Grathwohl et al., â€œFFJORD:
    Free-Form Continuous Dynamics for Scalable Reversible Generative Models,â€ October
    22, 2018, *[*https://arxiv.org/abs/1810.01367*](https://arxiv.org/abs/1810.01367)*.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '^([3](ch06.xhtml#idm45387012548496-marker)) Will Grathwohlç­‰äººï¼Œâ€œFFJORD: ç”¨äºå¯æ‰©å±•å¯é€†ç”Ÿæˆæ¨¡å‹çš„è‡ªç”±å½¢å¼è¿ç»­åŠ¨åŠ›å­¦â€ï¼Œ2018å¹´10æœˆ22æ—¥ï¼Œ[*https://arxiv.org/abs/1810.01367*](https://arxiv.org/abs/1810.01367)ã€‚'
