# 机器学习的通用工作流程

> [`deeplearningwithpython.io/chapters/chapter06_universal-workflow-of-ml`](https://deeplearningwithpython.io/chapters/chapter06_universal-workflow-of-ml)

我们之前的例子假设我们已经有了一个标记的数据集来开始，并且我们可以立即开始训练一个模型。在现实世界中，这通常不是情况。你不是从一个数据集开始的；你是从一个问题开始的。

想象一下你正在启动自己的机器学习咨询店。你注册公司，建立了一个华丽的网站，通知了你的网络。项目开始滚滚而来：

+   为图片分享社交网络的个性化照片搜索引擎 — 输入“婚礼”并检索你在婚礼上拍摄的所有照片，无需任何手动标记。

+   在新兴的聊天应用帖子中标记垃圾邮件和攻击性文本内容。

+   为在线电台的用户构建音乐推荐系统。

+   为电子商务网站检测信用卡欺诈。

+   预测展示广告的点击通过率，以决定在特定时间向特定用户展示哪个广告。

+   在饼干制造线的传送带上标记异常饼干。

+   使用卫星图像预测尚未发现的考古遗址的位置。

如果你能从 `keras.datasets` 导入正确的数据集并开始拟合一些深度学习模型，那将非常方便。不幸的是，在现实世界中，你必须从头开始。

在本章中，你将了解可以用来接近和解决任何机器学习问题（如之前所列）的通用逐步蓝图。这个模板将汇集和巩固你在第四章和第五章中学到的所有内容，并为你提供更广泛的背景，这将为你将在下一章中学习的内容提供锚点。

机器学习的通用工作流程大致分为三个部分：

+   *定义任务* — 理解问题域和客户所提要求背后的业务逻辑。收集数据集，理解数据代表什么，并选择你将如何衡量任务上的成功。

+   *开发一个模型* — 准备你的数据以便机器学习模型可以处理，选择一个模型评估协议和一个简单的基线来超越，训练一个具有泛化能力但可能过拟合的第一个模型，然后正则化和调整你的模型，直到你达到最佳可能的泛化性能。

+   *部署模型* — 向利益相关者展示你的工作，将模型部署到网络服务器、移动应用、网页或嵌入式设备上，监控模型在野外的性能，并开始收集你将需要用于构建下一个模型生成所需的数据。

让我们深入探讨。

## 定义任务

没有对你所做事情的背景有深入的理解，你无法做好工作。为什么你的客户想要解决这个特定问题？他们将从解决方案中获得什么价值？你的模型将如何被使用？它将如何融入客户的企业流程？有什么类型的数据可用或可以收集？可以将哪种机器学习任务映射到商业问题？

### 构建问题

构建机器学习问题通常涉及与利益相关者的许多详细讨论。以下是你应该放在首位的问题：

+   你的输入数据将是什么？你试图预测什么？只有在你有可用训练数据的情况下，你才能学会预测某物：例如，只有在你有电影评论和情感注释可用的情况下，你才能学会分类电影评论的情感。因此，数据可用性通常是这一阶段的限制因素。在许多情况下，你将不得不自己收集和注释新的数据集（我们将在下一节中介绍）。

+   你正在面对哪种机器学习任务？是二分类？多分类？标量回归？向量回归？多分类、多标签分类？图像分割？排序？其他，比如聚类、生成或强化学习？在某些情况下，可能机器学习甚至不是理解你的数据的最佳方式，你应该使用其他方法，例如传统的统计分析：

    +   图片搜索引擎项目是一个多分类、多标签分类任务。

    +   垃圾邮件检测项目是一个二分类任务。如果你将“攻击性内容”作为一个单独的类别，它就是一个三分类任务。

    +   音乐推荐引擎的解决方案不是通过深度学习，而是通过矩阵分解（协同过滤）来处理的。

    +   信用卡欺诈检测项目是一个二分类任务。

    +   点击率预测项目是一个标量回归任务。

    +   异常饼干检测是一个二分类任务，但它还需要一个作为第一阶段的对象检测模型来正确裁剪原始图像中的饼干。请注意，被称为“异常检测”的机器学习技术集合在这个设置中可能并不适用！

    +   从卫星图像中寻找新考古遗址的项目是一个图像相似性排序任务：你需要检索出看起来最像已知考古遗址的新图像。

+   现有的解决方案是什么样的？也许你的客户已经有一个手工制作的算法来处理垃圾邮件过滤或信用卡欺诈检测——包含大量的嵌套`if`语句。也许有人目前负责手动处理这个过程——在饼干工厂监控传送带并手动移除坏饼干，或者为喜欢特定艺术家的用户制作歌曲推荐播放列表。你应该确保理解已经存在的系统，以及它们是如何工作的。

+   你需要处理特定的约束条件吗？例如，你可能发现你正在为构建垃圾邮件检测系统的应用，该应用是严格端到端加密的，因此垃圾邮件检测模型将不得不运行在终端用户的手机上，并且必须在外部数据集上训练。也许 cookie 过滤模型有如此大的延迟限制，它需要在工厂的嵌入式设备上运行，而不是在远程服务器上。你应该理解你的工作将适应的完整背景。

一旦你完成了研究，你应该知道你的输入将是什么，你的目标将是什么，以及问题映射到的广泛类型的机器学习任务。在这个阶段，要意识到你正在提出的假设：

+   你假设给定你的输入，可以预测你的目标。

+   你假设可用的数据（或你将很快收集的数据）足够信息量，可以学习输入和目标之间的关系。

在你有一个工作模型之前，这些只是假设，等待被验证或证伪。并不是所有问题都可以用机器学习来解决；仅仅因为你有输入 X 和目标 Y 的例子，并不意味着 X 包含足够的信息来预测 Y。例如，如果你试图根据最近的股价历史预测股市中股票的走势，你不太可能成功，因为价格历史并不包含很多预测信息。

### 收集数据集

一旦你理解了任务的性质，并且知道你的输入和目标将是什么，那么就是数据收集的时候了——这是大多数机器学习项目中最为艰巨、耗时且昂贵的部分：

+   照片搜索引擎项目要求你首先选择你想要分类的标签集——你确定了 10,000 个常见的图像类别。然后，你需要手动将成千上万你过去用户上传的图像用这个集合中的标签进行标记。

+   对于聊天应用垃圾邮件检测项目，因为用户聊天是端到端加密的，你不能使用它们的内文来训练模型。你需要获取一个包含数万条未过滤社交媒体帖子的独立数据集，并手动将其标记为垃圾邮件、冒犯性或可接受。

+   对于音乐推荐引擎，你可以直接使用用户的“喜欢”。不需要收集新的数据。同样，对于点击率预测项目，你有一份广泛的点击率记录，这些记录可以追溯到多年前的广告。

+   对于饼干标记模型，你需要在输送带上方安装摄像头来收集数万张图像，然后有人需要手动标注这些图像。目前知道如何做这项工作的人正在饼干工厂工作——但这似乎并不太难，你应该能够训练人们来做这件事。

+   卫星图像项目将需要一支考古学家团队来收集现有兴趣点的数据库，并且对于每个地点，你需要找到在不同天气条件下拍摄的存在卫星图像。为了得到一个好的模型，你需要数千个不同的地点。

你在第五章中学到，一个模型泛化能力几乎完全来自其训练数据的特点——你拥有的数据点的数量，你标签的可靠性，你特征的质量。一个好的数据集是一个值得关注和投资的资产。如果你有额外的 50 小时可以用于项目，那么最有效的方式可能是收集更多数据，而不是寻找增量模型改进。

数据比算法更重要这一点在 2009 年一篇由谷歌研究人员撰写的论文中被最著名地提出，该论文题为“数据的不可思议有效性”（标题是对尤金·维格纳 1960 年出版的著名书籍《数学在自然科学中的不可思议有效性》的改编）。这在大规模深度学习流行之前，但令人惊讶的是，深度学习的兴起反而增加了数据的重要性。

如果你正在进行监督学习，那么一旦你收集了输入（如图像），你将需要为它们提供*标注*（如图像的标签）：你将训练模型预测的目标。

有时，标注可以自动检索——例如，在我们的音乐推荐任务或点击率预测任务中。但通常，你必须手动标注你的数据。这是一个劳动密集型的过程。

#### 投资数据标注基础设施

你的数据标注过程将决定你的目标质量，这反过来又决定了你的模型质量。仔细考虑你拥有的选项：

+   你是否应该自己标注数据？

+   你是否应该使用像 Mechanical Turk 这样的众包平台来收集标签？

+   你是否应该使用专门的数据标注公司的服务？

外包可能可以节省你的时间和金钱，但会失去控制。使用像 Mechanical Turk 这样的服务可能是低成本的，并且可以很好地扩展，但你的标注可能最终会相当嘈杂。

为了选择最佳选项，考虑你正在工作的限制条件：

+   数据标注员需要是领域专家吗，或者任何人都可以标注数据？猫狗图像分类问题的标签可以被任何人选择，但对于狗品种分类任务则需要专业知识。同时，标注骨折的 CT 扫描几乎需要医学学位。

+   如果标注数据需要专业知识，你能培训人员来做吗？如果不能，你如何获取相关专家的帮助？

+   你自己是否理解专家是如何生成标注的？如果你不理解，你将不得不将你的数据集视为一个黑盒，你将无法进行手动特征工程——这虽然不是关键，但可能会有限制。

如果你决定在内部标注数据，问问自己你将使用什么软件来记录标注。你可能需要自己开发那个软件。高效的数据标注软件可以为你节省大量时间，所以在项目早期就值得投资。

#### 警惕非代表性数据

机器学习模型只能理解与它们之前所见相似的输入。因此，用于训练的数据应该能够代表生产数据，这一点至关重要，应该是你所有数据收集工作的基础。

假设你正在开发一个应用程序，用户可以拍照来查找菜肴的名称。你使用一个受美食爱好者欢迎的图片分享社交网络的图片来训练模型。到了部署时间，愤怒的用户反馈开始涌入：你的应用程序有 8 次错误。发生了什么？你的测试集准确率远超过 90%！快速查看用户上传的数据揭示，随机餐馆随机智能手机拍摄的随机菜肴的移动图片与你训练模型时所用的专业质量、光线充足、令人垂涎的图片大相径庭：*你的训练数据并不代表生产数据*。这是一个严重的错误——欢迎来到机器学习地狱。

如果可能的话，直接从你的模型将使用的环境中收集数据。一个电影评论情感分类模型应该用于新的 IMDb 评论，而不是 Yelp 餐厅评论，也不是 Twitter 状态更新。如果你想对推文的情感进行评分，首先收集并标注实际的推文——来自与你预期在生产中使用的类似用户群体。如果无法在生产数据上训练，那么确保你完全理解你的训练数据和生产数据之间的差异，并且你正在积极纠正这些差异。

你应该注意的一个相关现象是*概念漂移*。你几乎会在所有现实世界的问题中遇到概念漂移，尤其是那些处理用户生成数据的问题。当生产数据的属性随时间变化时，就会发生概念漂移，导致模型精度逐渐下降。2013 年训练的音乐推荐引擎可能今天并不太有效。同样，你使用的 IMDB 数据集是在 2011 年收集的，基于它的模型在 2020 年的评论上可能不如 2012 年的评论表现得好，因为词汇、表达和电影类型随着时间的推移而演变。在对抗性环境（如信用卡欺诈检测）中，概念漂移尤其严重，欺诈模式几乎每天都在变化。处理快速概念漂移需要持续的数据收集、标注和模型重新训练。

请记住，机器学习只能用来记忆训练数据中存在的模式。你只能识别你之前看到过的。使用基于过去数据的机器学习来预测未来是假设未来会像过去一样表现。这通常并不成立。

### 理解你的数据

将数据集视为黑盒是不良的做法。在你开始训练模型之前，你应该探索和可视化你的数据，以了解使其具有预测性的因素——这将指导特征工程——并筛选潜在的问题：

+   如果你的数据包含图像或自然语言文本，直接查看一些样本（及其标签）。

+   如果你的数据包含数值特征，绘制特征值的直方图是一个好主意，以了解值的范围和不同值的频率。

+   如果你的数据包含位置信息，将其绘制在地图上。是否有任何明显的模式出现？

+   是否有一些样本缺少某些特征值？如果是这样，你需要在准备数据时处理这个问题（我们将在下一节中介绍如何做）。

+   如果你的任务是分类问题，打印出数据中每个类别的实例数量。类别是否大致均匀分布？如果不均匀，你需要考虑这种不平衡。

+   检查是否存在*目标泄露*——数据中存在提供关于目标的信息的特征，而这些信息在生产环境中可能不可用。如果你正在使用医疗记录来训练模型以预测某人将来是否会接受癌症治疗，并且记录中包含特征“这个人已被诊断出患有癌症”，那么你的目标就被人为地泄露到数据中。始终问自己，数据中的每个特征在生产环境中是否将以相同的形式可用？

### 选择成功度量

要控制某物，你需要能够观察它。要在项目中取得成功，你必须首先定义你所说的成功是什么。准确率？精确率和召回率？客户保留率？你的成功指标将指导你在整个项目中做出的所有技术选择。它应该直接与你的高级目标对齐，例如你客户的商业成功。

对于平衡的分类问题，其中每个类别的可能性相等，准确率和**曲线下面积**（AUC）以及**接收者操作特征**（ROC）是常见的指标。对于类别不平衡问题、排名问题或多标签分类，你可以使用精确率和召回率或一个计算假阳性、真阳性、假阴性和真阴性的指标。而且，定义自己的自定义指标来衡量成功并不罕见。为了了解机器学习成功指标的多样性以及它们如何与不同的问题域相关，浏览 Kaggle 上的数据科学竞赛（[`kaggle.com`](https://kaggle.com)）很有帮助；它展示了广泛的问题和评估指标。

## 开发模型

一旦你知道如何衡量你的进度，你就可以开始模型开发了。大多数教程和研究项目都假设这是唯一的一步——跳过问题定义和数据集收集，这些被认为是已经完成的，并且跳过模型部署和维护，这些被认为是其他人负责的。实际上，模型开发只是机器学习工作流程中的一步，如果问我，这并不是最困难的一步。机器学习中最困难的事情是定义问题、收集、标注和清理数据。所以加油，接下来与比较起来将会容易得多！

### 准备数据

如你之前所学，深度学习模型通常不会直接摄入原始数据。数据预处理的目标是使手头的原始数据更适合神经网络处理。这包括向量化、归一化或处理缺失值。许多预处理技术是特定领域的（例如，特定于文本数据或图像数据）；我们将在遇到实际示例时介绍这些技术。现在，我们将回顾适用于所有数据域的基本内容。

#### 向量化

神经网络中的所有输入和目标通常必须是浮点数据张量（或在特定情况下，整数或字符串的张量）。无论你需要处理什么数据——声音、图像、文本——你都必须首先将其转换为张量，这一步称为*数据向量化*。例如，在第四章的两个先前的文本分类示例中，我们从表示为整数列表（代表单词序列）的文本开始，我们使用多热编码将它们转换为`float32`数据张量。在分类数字和预测房价的示例中，数据已经以向量化的形式提供，因此你可以跳过这一步。

#### 值归一化

在第二章的 MNIST 数字分类示例中，你从 0-255 范围内的整数编码图像数据开始，编码灰度值。在你将此数据输入网络之前，你必须将其转换为`float32`并除以 255，以便最终得到 0-1 范围内的浮点值。同样，在预测房价时，你从具有各种范围的特性开始——一些特征具有小的浮点值，而其他特征则具有相当大的整数值。在你将此数据输入网络之前，你必须独立归一化每个特征，使其具有标准差为 1 和均值为 0。

通常，将相对较大的值（例如，多位整数，这些值远大于网络的初始权重值）或异构数据（例如，一个特征的范围在 0-1 之间，另一个特征的范围在 100-200 之间）输入神经网络是不安全的。这样做可能会触发大的梯度更新，从而阻止网络收敛。为了使网络的学习更容易，你的数据应具有以下特征：

+   *取小值*——通常，大多数值应在 0-1 范围内。

+   *保持同质性*——也就是说，所有特征应取大致相同的值范围。

此外，以下更严格的归一化实践很常见，并且可能有所帮助，尽管并不总是必要的（例如，在数字分类示例中你没有这样做）：

+   独立归一化每个特征，使其均值为 0。

+   独立归一化每个特征，使其标准差为 1。

这可以通过 NumPy 数组轻松完成：

```py
# Assuming x is a 2D data matrix of shape (samples, features)
x -= x.mean(axis=0)
x /= x.std(axis=0) 
```

#### 处理缺失值

你可能有时会在数据中遇到缺失值。例如，在房价示例中，第二个特征是该地区房屋的中位年龄。如果这个特征对于所有样本都不可用怎么办？那么在训练或测试数据中就会出现缺失值。

你可以完全丢弃该特征，但并不一定必须这样做：

+   如果特征是分类的，创建一个表示“值缺失”的新类别是安全的。模型将自动学习这与目标之间的关系。

+   如果特征是数值型的，避免输入一个任意的值，比如 0，因为这可能会在你的特征形成的潜在空间中造成不连续性，使得在它上面训练的模型更难泛化。相反，考虑用数据集中该特征的均值或中位数来替换缺失值。你也可以训练一个模型来预测给定其他特征值的特征值。

注意，如果你预计测试数据中会有缺失的类别特征，但网络是在没有缺失值的数据上训练的，那么网络就没有学会忽略缺失值！在这种情况下，你应该人工生成带有缺失条目的训练样本：复制一些训练样本多次，并丢弃你预计在测试数据中可能缺失的某些类别特征。

### 选择一个评估协议

正如你在上一章所学，模型的目的在于实现泛化，你在整个模型开发过程中所做的每一个建模决策都将由寻求衡量泛化性能的*验证指标*所指导。你的验证协议的目标是准确估计你选择的成功指标（如准确率）在实际生产数据上的表现。这个过程的可信度对于构建一个有用的模型至关重要。

在第五章中，我们回顾了三种常见的评估协议：

+   *维护一个保留验证集* — 当你拥有大量数据时的可行方法

+   *执行 K 折交叉验证* — 当你拥有的样本太少，保留验证集不可靠时的正确选择

+   *执行迭代 K 折验证* — 当数据很少时进行高度精确的模型评估

只需从中选择一个。在大多数情况下，第一个就足够好了。正如你之前所学的，始终要关注你的验证集（s）的*代表性*，并小心不要在训练集和验证集（s）之间有重复的样本。

### 打败基线

当你开始着手构建模型本身时，你的初始目标是实现*统计功效*，正如你在第五章所见——也就是说，开发一个能够打败简单基线的小型模型。

在这个阶段，你应该关注以下三个最重要的方面：

+   *特征工程* — 过滤掉无信息特征（特征选择）并利用你对问题的了解来开发可能有用的新特征。

+   *选择正确的架构先验* — 你将使用哪种类型的模型架构？一个密集连接的网络、一个卷积神经网络（ConvNet）、一个循环神经网络、一个 Transformer？深度学习对于这个任务来说甚至是一个好的方法吗，或者你应该使用其他方法？

+   *选择一个足够好的训练配置* — 你应该使用什么损失函数？什么批大小和学习率？

对于大多数问题，你可以从现有的模板开始。你不是第一个尝试构建垃圾邮件检测器、音乐推荐引擎或图像分类器的人。确保研究先前的艺术，以确定最有可能在你的任务上表现良好的特征工程技术和模型架构。

注意，并不总是能够实现统计能力。如果你尝试了多个合理的架构后仍然无法击败一个简单的基线，那么你可能问的问题的答案可能不在输入数据中。记住，你正在做出两个假设：

+   你假设，给定你的输入，可以预测你的输出。

+   你假设可用的数据足够有信息量，可以学习输入和输出之间的关系。

这些假设可能是不正确的，在这种情况下，你必须回到起点。

### 扩大规模：开发一个过拟合的模型

一旦你获得了一个具有统计能力的模型，问题就变成了，你的模型是否足够强大？它是否有足够的层和参数来正确地模拟当前的问题？例如，逻辑回归模型在 MNIST 上具有统计能力，但不足以很好地解决这个问题。记住，机器学习中的普遍张力在于优化和泛化之间；理想模型是那种正好位于欠拟合和过拟合、欠容量和过容量之间的模型。为了找出这个边界的位置，首先你必须跨越它。

为了找出你需要多大的模型，你必须开发一个过拟合的模型。这相当容易，正如你在第五章中学到的：

+   添加层。

+   使层更大。

+   训练更多的轮次。

总是监控训练损失和验证损失，以及你关心的任何指标的训练和验证值。当你看到模型在验证数据上的性能开始下降时，你就实现了过拟合。

### 规范化和调整你的模型

一旦你获得了统计能力并且能够过拟合，你就知道你走在了正确的道路上。此时，你的目标变成了最大化泛化性能。

这个阶段将花费最多的时间：你将反复修改你的模型，训练它，在验证数据上评估（此时不是测试数据），再次修改，然后重复，直到模型尽可能好。以下是一些你应该尝试的事情：

+   尝试不同的架构；添加或移除层。

+   添加 dropout。

+   如果你的模型很小，添加 L1 或 L2 正则化。

+   尝试不同的超参数（例如每层的单元数或优化器的学习率）以找到最佳配置。

+   可选地，迭代数据整理或特征工程：收集和标注更多数据，开发更好的特征，或者移除似乎没有信息量的特征。

可以通过使用*自动超参数调整软件*，如 KerasTuner，来自动化大部分这项工作。我们将在第十八章中介绍这一点。

请注意以下几点：每次你使用验证过程中的反馈来调整你的模型时，你都会将有关验证过程的信息泄露到模型中。重复几次是无害的；然而，在许多迭代中系统地这样做，最终会导致你的模型过度拟合验证过程（即使没有模型直接在验证数据上训练）。这使得评估过程变得不太可靠。

一旦你开发出一个令人满意的模型配置，你就可以在所有可用数据（训练和验证）上训练你的最终生产模型，并在测试集上最后一次评估它。如果测试集上的性能明显低于验证数据上的性能，这可能意味着你的验证程序最终并不可靠，或者你在调整模型参数时开始过度拟合验证数据。在这种情况下，你可能想切换到一个更可靠的评估协议（例如迭代 K 折验证）。

## 部署你的模型

在你的模型成功通过测试集的最终评估后，它就准备好部署并开始其生产生活。

### 向利益相关者解释你的工作并设定期望

成功和客户信任关乎始终满足或超越人们的期望；你实际交付的系统只是这幅图的一半。另一半是在发布前设定适当的期望。

非专业人士对人工智能系统的期望往往是不切实际的。例如，他们可能期望系统“理解”其任务，并在任务背景下具备类似人类的常识。为了解决这个问题，你应该考虑展示一些你模型（例如，展示被错误分类的样本看起来是什么样子，特别是那些误分类似乎令人惊讶的样本）的*故障模式*。

他们可能还期望达到人类水平的表现，尤其是对于以前由人类处理的流程。大多数机器学习模型，因为它们（不完美地）被训练来近似人类生成的标签，远远达不到这个水平。您应该清楚地传达模型性能预期。避免使用像“该模型准确率为 98%”这样的抽象陈述（大多数人会在心里将其四舍五入到 100%），而更倾向于谈论假阴性率和假阳性率。例如，您可以说：“在这些设置下，欺诈检测模型的假阴性率为 5%，假阳性率为 2.5%。每天，平均有 200 笔有效交易会被标记为欺诈并送交人工审查，平均有 14 笔欺诈交易会被遗漏。平均有 266 笔欺诈交易会被正确捕获。”明确地将模型性能指标与业务目标联系起来。

您还应该确保与利益相关者讨论关键发布参数的选择——例如，在哪个概率阈值下应标记交易（不同的阈值会产生不同的假阴性率和假阳性率）。这类决策涉及权衡，只有深入了解业务背景才能处理。

### 部署推理模型

机器学习项目并不在你到达一个可以保存训练模型的 Colab 笔记本时就结束了。你很少会将训练期间操作的精确 Python 模型对象投入生产。

首先，您可能希望将模型导出为 Python 以外的其他格式：

+   您的生产环境可能根本不支持 Python——例如，如果它是一个移动应用或嵌入式系统。

+   如果应用程序的其他部分不在 Python 中（它可能是 JavaScript、C++等），使用 Python 来提供服务可能会引起显著的开销。

其次，由于您的生产模型仅用于输出预测（称为*推理*阶段），而不是用于训练，您有空间进行各种优化，可以使模型运行更快并减少其内存占用。

让我们快速看一下您可用的不同模型部署选项。

#### 将模型作为 REST API 部署

将模型转化为产品的最简单方法可能是通过 REST API 在线提供服务。有许多库可以帮助实现这一点。Keras 支持两种最流行的方法——*TensorFlow Serving*和*ONNX*（即 Open Neural Network Exchange）。这两个库都是通过将所有模型权重和计算图从 Python 程序中提取出来来运行的，因此您可以从多个不同的环境中提供服务（例如，一个 C++服务器）。如果这听起来很像第三章中讨论的编译机制，您就完全正确了。TensorFlow Serving 本质上是一个用于通过特定保存权重的`tf.function`计算图提供服务的库。

Keras 允许通过所有 Keras 模型上可用的易于使用的 `export()` 方法访问 TensorFlow Serving 和 ONNX。以下是一个代码片段，展示了它是如何为 TensorFlow Serving 工作的：

```py
# Exports the model as a TensorFlow SavedModel artifact
model.export("path/to/location", format="tf_saved_model")

# Loads the artifact in a different process, environment, or
# programming language
reloaded_artifact = tf.saved_model.load("path/to/location")
predictions = reloaded_artifact.serve(input_data) 
```

对于 ONNX 也存在类似的流程：

```py
model.export("path/to/location", format="onnx")

ort_session = onnxruntime.InferenceSession("path/to/location")
predictions = ort_session.run(None, input_data) 
```

您应该在以下情况下使用此部署设置：

+   将会消费模型预测的应用程序将能够可靠地访问互联网（显然）。例如，如果您的应用程序是一个移动应用程序，从远程 API 提供预测意味着在飞行模式或低连接性环境中应用程序将不可用。

+   应用程序没有严格的延迟要求：请求、推理和回答往返通常需要大约 500 毫秒。

+   用于推理的输入数据不太敏感：数据将以解密形式在服务器上可用，因为模型需要查看它（但请注意，您应该使用 SSL 加密 HTTP 请求和响应）。

例如，图像搜索引擎项目、音乐推荐系统、信用卡欺诈检测项目和卫星图像项目都非常适合通过 REST API 提供服务。

当将模型作为 REST API 部署时，一个重要的问题是您是想自己托管代码还是想使用完全管理的第三方云服务。例如，Google 产品 Cloud AI Platform 允许您简单地将您的 TensorFlow 模型上传到 Google Cloud Storage (GCS)，并提供一个 API 端点来查询它。它负责许多实际细节，例如批处理预测、负载均衡和扩展。

#### 在设备上部署模型

有时，您可能需要您的模型与运行使用它的应用程序的同一设备上运行——可能是一台智能手机、机器人上的嵌入式 ARM CPU 或小型设备上的微控制器。例如，也许您已经看到过一种能够自动检测您指向的场景中的人脸和人物的相机：那可能是一个直接在相机上运行的微型深度学习模型。

您应该在以下情况下使用此设置：

+   您的模型有严格的延迟限制，或者需要在低连接性环境中运行。如果您正在构建沉浸式增强现实应用程序，查询远程服务器不是一个可行的选项。

+   您可以将模型做得足够小，使其能够在目标设备的内存和功耗限制下运行。

+   对于您的任务来说，获得尽可能高的准确度不是至关重要的：运行时间和准确度之间总是存在权衡，因此内存和功耗限制通常要求您发送一个模型，它的性能不如您在大型 GPU 上运行的最好模型。

+   输入数据非常敏感，因此不应在远程服务器上解密。

例如，我们的垃圾邮件检测模型需要作为聊天应用的一部分在终端用户的智能手机上运行，因为消息是端到端加密的，所以根本无法由远程托管模型读取。同样，坏 cookie 检测模型有严格的延迟限制，需要在工厂运行。幸运的是，在这种情况下，我们没有电力或空间限制，因此实际上可以在 GPU 上运行该模型。

要在智能手机或嵌入式设备上部署 Keras 模型，你可以再次使用`export()`方法创建包含计算图的 TensorFlow 或 ONNX 保存的模型。TensorFlow Lite（[`www.tensorflow.org/lite`](https://www.tensorflow.org/lite)）是一个在 Android 和 iOS 智能手机、ARM CPU、Raspberry Pi 或某些微控制器上运行的框架，用于高效的设备上深度学习推理。它使用与 TensorFlow Serving 相同的 TensorFlow 保存模型格式。ONNX 运行时也可以在移动设备上运行。

#### 在浏览器中部署模型

深度学习通常用于基于浏览器或桌面基于 JavaScript 的应用程序。虽然通常可以通过 REST API 让应用程序查询远程模型，但让模型直接在浏览器中、用户的电脑上运行（如果可用，利用 GPU 资源）可能会有关键优势。

在以下情况下使用此设置：

+   你希望将计算任务卸载给终端用户，这可以显著降低服务器成本。

+   输入数据需要保持在终端用户的电脑或手机上。例如，在我们的垃圾邮件检测项目中，聊天应用的网页版和桌面版（作为用 JavaScript 编写的跨平台应用实现）应使用本地运行的模型。

+   你的应用程序有严格的延迟限制：虽然运行在终端用户笔记本电脑或智能手机上的模型可能比运行在你自己服务器上大型 GPU 上的模型要慢，但你没有额外的 100 毫秒的网络往返时间。

+   在模型下载并缓存后，你需要确保你的应用在没有连接的情况下也能继续工作。

当然，只有当你的模型足够小，不会占用用户笔记本电脑或智能手机的 CPU、GPU 或 RAM 时，你才应该选择这个选项。此外，由于整个模型将下载到用户的设备上，你应该确保模型中没有任何需要保密的内容。请注意，给定一个训练好的深度学习模型，通常可以恢复一些关于训练数据的信息：如果模型是在敏感数据上训练的，最好不要将其公开。

在 JavaScript 中部署模型时，TensorFlow 生态系统包括 TensorFlow.js ([`www.tensorflow.org/js`](https://www.tensorflow.org/js))，并且 ONNX 支持原生 JavaScript 运行时。TensorFlow.js 甚至实现了几乎所有的 Keras API（它最初是在 WebKeras 这个工作名称下开发的）以及许多低级别的 TensorFlow API。你可以轻松地将保存的 Keras 模型导入 TensorFlow.js，以便在基于浏览器的 JavaScript 应用或桌面 Electron 应用中查询它。

#### 推理模型优化

在对推理环境进行优化时，特别是在对可用功率和内存有严格限制的环境（如智能手机和嵌入式设备）或对低延迟有要求的场景中，优化你的模型尤为重要。在将模型导入 TensorFlow.js 或导出到 TensorFlow Lite 之前，你应该始终寻求优化模型。

你可以应用两种流行的优化技术：

+   *权重剪枝* — 并非权重张量中的每个系数都对预测贡献相同。通过仅保留最重要的系数，你可以显著减少模型层中的参数数量。这会在性能指标上带来轻微的代价，但可以减少模型的内存和计算占用。通过调整你想要应用的剪枝程度，你可以控制大小和准确度之间的权衡。

+   *权重量化* — 深度学习模型使用单精度浮点数(`float32`)权重进行训练。然而，可以将权重*量化*到 8 位有符号整数(`int8`)，以获得一个仅用于推理的模型，其大小是原来的四分之一，但仍然接近原始模型的准确度。Keras 模型自带内置的`quantize()` API，可以帮助实现这一点。只需调用`model.quantize("int8")`即可将模型中的每个权重压缩到一个字节。

### 监控野外的模型

你已经导出了推理模型，将其集成到你的应用中，并在生产数据上进行了测试运行——模型的行为完全符合你的预期。你已经编写了单元测试以及日志和状态监控代码——完美。现在是你按下那个大红色按钮并将模型部署到生产环境的时候了。

即使这样也不是终点。一旦部署了模型，你需要持续监控其行为、在新数据上的性能、与其他应用的交互，以及最终对业务指标的影响：

+   在部署新的音乐推荐系统后，你的在线广播的用户参与度是上升还是下降？在切换到新的点击率预测模型后，平均广告点击率是否有所增加？考虑使用*随机 A/B 测试*来隔离模型本身的影响与其他变化：一部分案例应该通过新的模型，而另一部分控制案例应该坚持旧的过程。一旦处理了足够多的案例，两个结果之间的差异很可能是模型的影响。

+   如果可能的话，对模型在生产数据上的预测进行定期手动审计。通常可以重用数据标注的基础设施：将一部分生产数据发送进行手动标注，并将模型的预测与新的标注进行比较。例如，你绝对应该为图像搜索引擎和不良 cookie 标记系统做这件事。

+   当手动审计不可能时，考虑其他评估途径，例如用户调查（例如，在垃圾邮件和违规内容标记系统中）。

### 维护你的模型

最后，没有模型是永恒的。你已经了解了*概念漂移*：随着时间的推移，你的生产数据的特征会发生变化，逐渐降低模型的性能和相关性。你的音乐推荐系统的寿命将以周计算。对于信用卡欺诈检测系统，可能是几天；在最佳情况下，图像搜索引擎可能是几年。

一旦你的模型上线，你就应该开始准备训练下一代将取代它的模型：

+   注意生产数据的变化。是否有新特征可用？你是否应该扩展或修改标签集？

+   继续收集和标注数据，并随着时间的推移不断改进你的标注流程。特别是，你应该特别注意收集那些似乎难以分类的样本，因为当前模型最有可能帮助提高性能。

这就结束了机器学习的通用工作流程——这有很多事情需要记住。成为专家需要时间和经验，但不用担心，你已经比几章前聪明多了。你现在已经熟悉了大局——机器学习项目涵盖的整个范围。虽然本书的大部分内容将关注模型开发部分，但你现在已经意识到，这仅仅是整个工作流程的一部分。始终牢记大局！

## 摘要

+   当你承担一个新的机器学习项目时，首先，定义手头的问题：

    +   理解你着手要做的事情的更广泛背景——最终目标是什么，有什么限制？

    +   收集并标注数据集；确保你深入理解你的数据。

    +   选择你将如何衡量你问题的成功。你将在验证数据上监控哪些指标？

+   一旦你理解了问题，并且拥有合适的数据集，开发一个模型：

    +   准备你的数据。

    +   选择你的评估协议。保留验证？K 折验证？你应该使用数据集的哪一部分进行验证？

    +   实现统计功效：击败简单的基线。

    +   规模化：开发一个可以过拟合的模型。

    +   根据验证数据上的性能，对模型进行正则化并调整其超参数。许多机器学习研究往往只关注这一步——但请记住大局。

+   当模型准备就绪，并在测试数据上表现出良好的性能时，就到了部署的时候：

    +   首先，确保与利益相关者设定适当的期望。

    +   优化用于推理的最终模型，并将其部署到所选的部署环境中——例如，Web 服务器、移动设备、浏览器、嵌入式设备等。

    +   监控模型在生产环境中的性能，并持续收集数据，以便开发下一代的模型。
