- en: References
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Chapter 1
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一章
- en: Young, B. (2023). AI expert speculates on GPT-4 architecture. Weights & Biases.
    [https://api.wandb.ai/links/byyoung3/8zxbl12q](https://api.wandb.ai/links/byyoung3/8zxbl12q)
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Young, B. (2023). AI专家对GPT-4架构进行推测。Weights & Biases。[https://api.wandb.ai/links/byyoung3/8zxbl12q](https://api.wandb.ai/links/byyoung3/8zxbl12q)
- en: Micikevicius, P. (2017). Mixed-precision training of deep neural networks. NVIDIA
    Developer. [https://mng.bz/6eaA](https://mng.bz/6eaA)
  id: totrans-3
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Micikevicius, P. (2017)。深度神经网络混合精度训练。NVIDIA开发者。[https://mng.bz/6eaA](https://mng.bz/6eaA)
- en: Accelerate AI development with Google Cloud TPUs. [https://cloud.google.com/](https://cloud.google.com/tpu)[tpu](https://cloud.google.com/tpu)
  id: totrans-4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 利用Google Cloud TPUs加速AI开发。[https://cloud.google.com/](https://cloud.google.com/tpu)[tpu](https://cloud.google.com/tpu)
- en: Metz, C. (2023, July 23). Researchers poke holes in safety controls of ChatGPT
    and other chatbots. *New York Times*.
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Metz, C. (2023年7月23日)。研究人员质疑ChatGPT和其他聊天机器人的安全控制。*纽约时报*。
- en: Hu, K. (2023, February 2). ChatGPT sets record for fastest-growing user base—analyst
    note. Reuters. [https://mng.bz/XxKv](https://mng.bz/XxKv)
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hu, K. (2023年2月2日)。ChatGPT创下用户增长最快的记录——分析师评论。路透社。[https://mng.bz/XxKv](https://mng.bz/XxKv)
- en: Chapter 2
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二章
- en: 'Friederici, A. D. (2011). The brain basis of language processing: From structure
    to function. *Physiology Review, 91,* 1357-1392\. [https://doi.org/10.1152/physrev](https://doi.org/10.1152/physrev.00006.2011)[.00006.2011](https://doi.org/10.1152/physrev.00006.2011)'
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Friederici, A. D. (2011)。语言处理的大脑基础：从结构到功能。*生理学评论，91*，1357-1392。[https://doi.org/10.1152/physrev](https://doi.org/10.1152/physrev.00006.2011)[.00006.2011](https://doi.org/10.1152/physrev.00006.2011)
- en: 'Nation, P., and Waring, R. (1997). Vocabulary size, text coverage, and word
    lists. In: N. Schmitt and M. McCarthy, eds., *Vocabulary: Description, Acquisition,
    and Pedagogy* (pp. 6-19). Cambridge University Press.'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Nation, P. 和 Waring, R. (1997)。词汇量、文本覆盖率和词汇表。在：N. Schmitt 和 M. McCarthy 编著，《词汇：描述、获取和教学法》（第6-19页）。剑桥大学出版社。
- en: Brown, T. B., Mann, B., Ryder, N., et al. (2020). Language models are few-shot
    learners. [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Brown, T. B.，Mann, B.，Ryder, N. 等. (2020)。语言模型是少样本学习者。[https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)
- en: Google/SentencePiece. [https://github.com/google/sentencepiece](https://github.com/google/sentencepiece)
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Google/SentencePiece。[https://github.com/google/sentencepiece](https://github.com/google/sentencepiece)
- en: Petrov, A., La Malfa, E., Torr, P. H. S., and Bibi, A. (2023). Language model
    tokenizers introduce unfairness between languages. [https://arxiv.org/abs/2305.15425](https://arxiv.org/abs/2305.15425)
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Petrov, A.，La Malfa, E.，Torr, P. H. S. 和 Bibi, A. (2023)。语言模型分词器在语言间引入不公平。[https://arxiv.org/abs/2305.15425](https://arxiv.org/abs/2305.15425)
- en: Chapter 3
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三章
- en: Denk, T. (2019). Linear relationships in the transformer’s positional encoding.
    [https://mng.bz/oKxd](https://mng.bz/oKxd)
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Denk, T. (2019)。Transformer的位置编码中的线性关系。[https://mng.bz/oKxd](https://mng.bz/oKxd)
- en: Raff, E. (2022). *Inside Deep Learning*. Manning.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Raff, E. (2022)。*深度学习内部*。Manning。
- en: Chapter 4
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四章
- en: Yong, E. (2012). Simulated brain scores top test marks. *Nature*. [https://www.nature](https://www.nature.com/articles/nature.2012.11914)[.com/articles/nature.2012.11914](https://www.nature.com/articles/nature.2012.11914)
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Yong, E. (2012)。模拟大脑获得最高测试分数。*自然*。[https://www.nature](https://www.nature.com/articles/nature.2012.11914)[.com/articles/nature.2012.11914](https://www.nature.com/articles/nature.2012.11914)
- en: Forsyth, J. A., and Mongrut, S. (2022). Does duration of competitive advantage
    drive long-term returns in the stock market? *Revista Contabilidade & Finanças,
    33*(89), 329–342\. [https://doi.org/10.1590/1808-057x202113660](https://doi.org/10.1590/1808-057x202113660)
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Forsyth, J. A. 和 Mongrut, S. (2022)。竞争优势的持续时间是否推动股市的长期回报？*Revista Contabilidade
    & Finanças, 33*(89)，329–342。[https://doi.org/10.1590/1808-057x202113660](https://doi.org/10.1590/1808-057x202113660)
- en: 'Lin, S., Hilton, J., and Evans, O. (2022). TruthfulQA: Measuring how models
    mimic human falsehoods. [https://arxiv.org/abs/2109.07958](https://arxiv.org/abs/2109.07958)'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Lin, S.，Hilton, J. 和 Evans, O. (2022)。TruthfulQA：衡量模型模仿人类错误的方式。[https://arxiv.org/abs/2109.07958](https://arxiv.org/abs/2109.07958)
- en: 'Parrish, A., Chen, A., Nangia, N., et al. (2022) BBQ: A hand-built bias benchmark
    for question answering. [https://arxiv.org/abs/2110.08193](https://arxiv.org/abs/2110.08193))'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Parrish, A.，Chen, A.，Nangia, N. 等. (2022) BBQ：问答中的手建偏差基准。[https://arxiv.org/abs/2110.08193](https://arxiv.org/abs/2110.08193))
- en: Chen, M., Tworek, J., Jun, H., et al. (2021). Evaluating large language models
    trained on code. [https://arxiv.org/abs/2107.03374](https://arxiv.org/abs/2107.03374)
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Chen, M.，Tworek, J.，Jun, H. 等. (2021)。评估在代码上训练的大型语言模型。[https://arxiv.org/abs/2107.03374](https://arxiv.org/abs/2107.03374)
- en: How can we draw a duck (in order to create a tikzducks package and store it
    in CTAN)? [https://mng.bz/W2Jg](https://mng.bz/W2Jg)
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sutton, R. (2019). The bitter lesson. [https://mng.bz/EaJq](https://mng.bz/EaJq)
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 5
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Barber, R. G., Oza, A., Carlson, R., and Ramirez, R. (2023, October 18). Why
    scientists are reanimating spider corpses for research. NPR. [https://mng.bz/lYgj](https://mng.bz/lYgj)
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: OpenAI. Fine-tuning. [https://mng.bz/dXnD](https://mng.bz/dXnD)
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hugging Face. Fine-tune a pretrained model. [https://huggingface.co/docs/](https://huggingface.co/docs/transformers/training)[transformers/training](https://huggingface.co/docs/transformers/training)
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Luo, Y, Yang, Z., Meng, F.,et al. (2025). An empirical study of catastrophic
    forgetting in large language models during continual fine-tuning. [https://arxiv.org/abs/](https://arxiv.org/abs/2308.08747)[2308.08747](https://arxiv.org/abs/2308.08747)
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: McCloskey, M., and Cohen, N. J. (1989). Catastrophic interference in connectionist
    networks. *Psychology of Learning and Motivation, 24,* 109-165\. [https://doi.org/](https://doi.org/10.1016/S0079-7421(08)60536-8)[10.1016/S0079-7421(08)60536-8](https://doi.org/10.1016/S0079-7421(08)60536-8)
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Belrose, N., Schneider-Joseph, D., Ravfogel, S., et al. (2023). LEACE: Perfect
    linear concept erasure in closed form. [https://arxiv.org/abs/2306.03819](https://arxiv.org/abs/2306.03819)'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Phung, D. V., Thakur, A., Castricato, L., Tow, J., and Havrilla, A. (2025).
    Implementing RLHF: Learning to summarize with trlX. Weights & Measures. [https://mng.bz/rKzg](https://mng.bz/rKzg)'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Kolter, Z., and Madry, M. (n.d.). Adversarial robustness: Theory and practice.
    [https://adversarial-ml-tutorial.org/](https://adversarial-ml-tutorial.org/)'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: OpenAI. (2023, March 27). GPT-4 technical report. [https://cdn.openai.com/](https://cdn.openai.com/papers/gpt-4.pdf)[papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf)
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Chowdhery, A., Narang, S., Devlin, J., et al. (2022). PaLM: Scaling language
    modeling with pathways. [https://arxiv.org/abs/2204.02311](https://arxiv.org/abs/2204.02311)'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Liang, W., Izzo, Z., Zhang, Y., et al. (2024). Monitoring AI-modified content
    at scale: A case study on the impact of ChatGPT on AI conference peer reviews.
    [https://arxiv.org/abs/2403.07183](https://arxiv.org/abs/2403.07183)'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Li, C., and Flanigan, J. (2023). Task contamination: Language models may not
    be few-shot anymore. [https://arxiv.org/abs/2312.16337](https://arxiv.org/abs/2312.16337)'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Near, J. P., and Abuah, C. (2021). *Programming Differential Privacy*. [https://prog](https://programming-dp.com/)[ramming-dp.com/](https://programming-dp.com/)
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 6
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Albergotti, R., and Matsakis, L. (2023, January 23). OpenAI has hired an army
    of contractors to make basic coding obsolete. Semafor. [https://mng.bz/MDGQ](https://mng.bz/MDGQ)
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Introducing Code Llama, a state-of-the-art large language model for coding.
    (2023, August 24). Meta. [https://mng.bz/av2j](https://mng.bz/av2j)
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'von Werra, L., and Ben Allal, L. (2023, May 4). StarCoder: A state-of-the-art
    LLM for code. Hugging Face. [https://huggingface.co/blog/starcoder](https://huggingface.co/blog/starcoder)'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'von Werra, L., and Ben Allal, L. (2023, May 4). StarCoder: A state-of-the-art
    LLM for code. Hugging Face. [https://huggingface.co/blog/starcoder](https://huggingface.co/blog/starcoder)'
- en: Biderman, S., and Raff, E. (2022). Fooling MOSS detection with pretrained language
    models. [https://arxiv.org/abs/2201.07406](https://arxiv.org/abs/2201.07406).
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Biderman, S., and Raff, E. (2022). Fooling MOSS detection with pretrained language
    models. [https://arxiv.org/abs/2201.07406](https://arxiv.org/abs/2201.07406).
- en: 'Dyer, E., and Gur-Ari, G. (2020, June 30). Minerva: Solving quantitative reasoning
    problems with language models. Google Research. [https://mng.bz/gane](https://mng.bz/gane).'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Dyer, E., and Gur-Ari, G. (2020, June 30). Minerva: Solving quantitative reasoning
    problems with language models. Google Research. [https://mng.bz/gane](https://mng.bz/gane).'
- en: 'Azerbayev, Z., Schoelkopf, H., Paster, K., et al. (2023, October 16). Llemma:
    An open language model for mathematics. EleutherAI. [https://blog.eleuther.ai/](https://blog.eleuther.ai/llemma/)[llemma/](https://blog.eleuther.ai/llemma/)'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Azerbayev, Z., Schoelkopf, H., Paster, K., et al. (2023, October 16). Llemma:
    An open language model for mathematics. EleutherAI. [https://blog.eleuther.ai/](https://blog.eleuther.ai/llemma/)[llemma/](https://blog.eleuther.ai/llemma/)'
- en: Richardson, D. (1968). Some undecidable problems involving elementary functions
    of a real variable. *Journal of Symbolic Logic, 33,* 514–520.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Richardson, D. (1968). Some undecidable problems involving elementary functions
    of a real variable. *Journal of Symbolic Logic, 33,* 514–520.
- en: Nogueira, R., Jiang, Z., and Lin, J. (2021). Investigating the limitations of
    transformers with simple arithmetic tasks. [https://arxiv.org/abs/2102.13019v3](https://arxiv.org/abs/2102.13019v3)
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Nogueira, R., Jiang, Z., and Lin, J. (2021). Investigating the limitations of
    transformers with simple arithmetic tasks. [https://arxiv.org/abs/2102.13019v3](https://arxiv.org/abs/2102.13019v3)
- en: Golkar, S., Pettee, M., Eickenberg, M., et al. (2024). Investigating the limitations
    of transformers with simple arithmetic tasks. [https://arxiv.org/abs/2310.02989](https://arxiv.org/abs/2310.02989)
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Golkar, S., Pettee, M., Eickenberg, M., et al. (2024). Investigating the limitations
    of transformers with simple arithmetic tasks. [https://arxiv.org/abs/2310.02989](https://arxiv.org/abs/2310.02989)
- en: Chapter 7
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第7章
- en: 'Romeo, R. R., Leonard, J. A., Robinson, S. T., et al. (2018). Beyond the 30-million-word
    gap: Children’s conversational exposure is associated with language-related brain
    function. *Psychological Science, 29,* 700–710\. [https://doi.org/10.1177/](https://doi.org/10.1177/0956797617742725)[0956797617742725](https://doi.org/10.1177/0956797617742725)'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Romeo, R. R., Leonard, J. A., Robinson, S. T., et al. (2018). Beyond the 30-million-word
    gap: Children’s conversational exposure is associated with language-related brain
    function. *Psychological Science, 29,* 700–710\. [https://doi.org/10.1177/](https://doi.org/10.1177/0956797617742725)[0956797617742725](https://doi.org/10.1177/0956797617742725)'
- en: Gilkerson, J., Richards, J. A., Warren, S. F., et al. (2017). Mapping the early
    language environment using all-day recordings and automated analysis. *American
    Journal of Speech-Language Pathology, 26,* 248-265\. [https://doi.org/10.1044/2016_AJSLP-15-0169](https://doi.org/10.1044/2016_AJSLP-15-0169)
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gilkerson, J., Richards, J. A., Warren, S. F., et al. (2017). Mapping the early
    language environment using all-day recordings and automated analysis. *American
    Journal of Speech-Language Pathology, 26,* 248-265\. [https://doi.org/10.1044/2016_AJSLP-15-0169](https://doi.org/10.1044/2016_AJSLP-15-0169)
- en: 'Shumailov, I., Shumaylov, Z., Zhao, Y., et al. (2024). The curse of recursion:
    Training on generated data makes models forget. [https://arxiv.org/abs/2305.17493](https://arxiv.org/abs/2305.17493)'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Shumailov, I., Shumaylov, Z., Zhao, Y., et al. (2024). The curse of recursion:
    Training on generated data makes models forget. [https://arxiv.org/abs/2305.17493](https://arxiv.org/abs/2305.17493)'
- en: 'Stanovich K. E. (2009). *What Intelligence Tests Miss: The Psychology of Rational
    Thought*. Yale University Press.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Stanovich K. E. (2009). *What Intelligence Tests Miss: The Psychology of Rational
    Thought*. Yale University Press.'
- en: Improving the realism of synthetic images. (2017, July 7). Apple Machine Learning
    Research. [https://machinelearning.apple.com/research/gan](https://machinelearning.apple.com/research/gan)
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 改进合成图像的真实性。 (2017, July 7). Apple Machine Learning Research. [https://machinelearning.apple.com/research/gan](https://machinelearning.apple.com/research/gan)
- en: 'Dai, D., Sun, Y., Dong, L., et al. (2023). Why can GPT learn in-context? Language
    models secretly perform gradient descent as meta-optimizers. In *Findings of the
    Association for Computational Linguistics: ACL 2023* (pp. 4005–4019). Association
    for Computational Linguistics.'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Dai, D., Sun, Y., Dong, L., et al. (2023). Why can GPT learn in-context? Language
    models secretly perform gradient descent as meta-optimizers. In *Findings of the
    Association for Computational Linguistics: ACL 2023* (pp. 4005–4019). Association
    for Computational Linguistics.'
- en: Hiller, J. (2023, December 12). Microsoft targets nuclear to power AI operations.
    *Wall Street Journal*. [https://mng.bz/pKe5](https://mng.bz/pKe5)
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hiller, J. (2023, December 12). Microsoft targets nuclear to power AI operations.
    *Wall Street Journal*. [https://mng.bz/pKe5](https://mng.bz/pKe5)
- en: Disavino, S. (2023, September 8). Texas power prices soar as grid passes reliability
    test in heat wave. Reuters. [https://mng.bz/OB0K](https://mng.bz/OB0K)
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Disavino, S. (2023年9月8日). 德克萨斯州电力价格飙升，电网在热浪中通过可靠性测试。路透社。[https://mng.bz/OB0K](https://mng.bz/OB0K)
- en: Emoji recently added, v15.1\. (n.d.). Unicode. [https://www.unicode.org/emoji/](https://www.unicode.org/emoji/charts-15.1/emoji-released.html)[charts-15.1/emoji-released.html](https://www.unicode.org/emoji/charts-15.1/emoji-released.html)
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最近添加的emoji，v15.1。 (未注明日期)。Unicode。[https://www.unicode.org/emoji/charts-15.1/emoji-released.html](https://www.unicode.org/emoji/charts-15.1/emoji-released.html)
- en: Wei, J., Wang, X., Schuurmans, D., et al. (2023). Chain-of-thought prompting
    elicits reasoning in large language models. [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Wei, J., Wang, X., Schuurmans, D. 等. (2023年)。思维链提示引发大型语言模型的推理。[https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)
- en: 'Wang, L., Xu, W., Lan, Y., et al. (2023). Plan-and-solve prompting: Improving
    zero-shot chain-of-thought reasoning by large language models. In *Proceedings
    of the 61st Annual Meeting of the Association for Computational Linguistics* (Vol.
    1: Long Papers, pp. 2609-2634). Association for Computational Linguistics.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Wang, L., Xu, W., Lan, Y. 等. (2023年)。计划-解决提示：通过大型语言模型提高零样本思维链推理。[第61届计算语言学年会*（第1卷：长篇论文，第2609-2634页）。计算语言学协会。
- en: Guan, L., Valmeekam, K., Sreedharan, S., and Kambhampati, S. (2023). Leveraging
    pre-trained large language models to construct and utilize world models for model-based
    task planning. [https://arxiv.org/abs/2305.14909](https://arxiv.org/abs/2305.14909)
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Guan, L., Valmeekam, K., Sreedharan, S. 和 Kambhampati, S. (2023年)。利用预训练的大型语言模型构建和利用世界模型以进行基于模型的任务规划。[https://arxiv.org/abs/2305.14909](https://arxiv.org/abs/2305.14909)
- en: 'Bhargava, A. Y. (2015). *Grokking Algorithms: An illustrated Guide for Programmers
    and Other Curious People*. Manning Publications.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Bhargava, A. Y. (2015年). *Grokking Algorithms: An illustrated Guide for Programmers
    and Other Curious People*。Manning Publications。'
- en: Merrill, W., and Sabharwal, S. (2024). The expressive power of transformers
    with chain of thought. In *International Conference on Learning Representations
    2024*. [https://openreview.net/forum?id=NjNGlPh8Wh](https://openreview.net/forum?id=NjNGlPh8Wh)
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Merrill, W. 和 Sabharwal, S. (2024年)。具有思维链的Transformer的表达能力。在*2024年学习表示国际会议*。[https://openreview.net/forum?id=NjNGlPh8Wh](https://openreview.net/forum?id=NjNGlPh8Wh)
- en: Carlini, N. (2023, September 22). Playing chess with large language models.
    [https://nicholas.carlini.com/writing/2023/chess-llm.html](https://nicholas.carlini.com/writing/2023/chess-llm.html)
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Carlini, N. (2023年9月22日). 与大型语言模型下棋。[https://nicholas.carlini.com/writing/2023/chess-llm.html](https://nicholas.carlini.com/writing/2023/chess-llm.html)
- en: Edwards B. (2022, November 7). New Go-playing trick defeats world-class Go AI—but
    loses to human amateurs. *Ars Technica*. [https://mng.bz/dW6O](https://mng.bz/dW6O)
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Edwards B. (2022年11月7日). 新的围棋技巧击败了世界级围棋AI——但输给了业余爱好者。*Ars Technica*。[https://mng.bz/dW6O](https://mng.bz/dW6O)
- en: Chapter 8
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第8章
- en: Yagoda, M. (2024, February 23). Airline held liable for its chatbot giving passenger
    bad advice—what this means for travellers. BBC. [https://mng.bz/xK7W](https://mng.bz/xK7W)
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Yagoda, M. (2024年2月23日). 航空公司因其聊天机器人给出糟糕的建议而承担责任——这对旅客意味着什么。BBC。[https://mng.bz/xK7W](https://mng.bz/xK7W)
- en: 'Notopoulos, K. (2023, December 18). A car dealership added an AI chatbot to
    its site: Then all hell broke loose. [https://mng.bz/AQPz](https://mng.bz/AQPz)'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Notopoulos, K. (2023年12月18日)。一家汽车经销商在其网站上添加了AI聊天机器人：然后一切乱套了。[https://mng.bz/AQPz](https://mng.bz/AQPz)
- en: 'Suresh, H., Lao, N., and Liccardi, I. (2020). Misplaced trust: Measuring the
    interference of machine learning in human decision-making. In *Proceedings of
    the 12th ACM Conference on Web Science (WebSci ’20)* (pp. 315-324). Association
    for Computing Machinery. [https://doi.org/10.1145/3394231.3397922](https://doi.org/10.1145/3394231.3397922)'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Suresh, H., Lao, N., 和 Liccardi, I. (2020年). 误置的信任：衡量机器学习对人类决策的干扰。在*第12届ACM网络科学会议（WebSci
    '20）*（第315-324页）。计算机制造协会。[https://doi.org/10.1145/3394231.3397922](https://doi.org/10.1145/3394231.3397922)
- en: Chapter 9
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第9章
- en: Hofmann, V., Kalluri, P. R., Jurafsky, D., and King, S. (2024). Dialect prejudice
    predicts AI decisions about people’s character, employability, and criminality.
    [https://arxiv.org/abs/2403.00742](https://arxiv.org/abs/2403.00742)
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hofmann, V., Kalluri, P. R., Jurafsky, D., 和 King, S. (2024年). 方言偏见预测AI对人们性格、就业能力和犯罪性的判断。[https://arxiv.org/abs/2403.00742](https://arxiv.org/abs/2403.00742)
- en: Omiye, J. A., Lester, J. C., Spichak, S. et al. (2023). Large language models
    propagate race-based medicine. npj Digital Medicine, 6, 195\. [https://doi.org/10.1038/](https://doi.org/10.1038/s41746-023-00939-z)[s41746-023-00939-z](https://doi.org/10.1038/s41746-023-00939-z)
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Omiye, J. A., Lester, J. C., Spichak, S. 等人 (2023). 大型语言模型传播基于种族的医学。npj数字医学，6，195。[https://doi.org/10.1038/](https://doi.org/10.1038/s41746-023-00939-z)[s41746-023-00939-z](https://doi.org/10.1038/s41746-023-00939-z)
- en: Farm labor. (2025, January 8). Economic Research Service. [https://www.ers.usda](https://www.ers.usda.gov/topics/farm-economy/farm-labor/)[.gov/topics/farm-economy/farm-labor/](https://www.ers.usda.gov/topics/farm-economy/farm-labor/)
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 农业劳动力。 (2025年1月8日)。经济研究服务。[https://www.ers.usda](https://www.ers.usda.gov/topics/farm-economy/farm-labor/)[.gov/topics/farm-economy/farm-labor/](https://www.ers.usda.gov/topics/farm-economy/farm-labor/)
- en: 'Verma, P., and De Vync, G. (2023, June 2). ChatGPT took their jobs: Now they
    walk dogs and fix air conditioners. *The Washington Post*. [https://mng.bz/EwQd](https://mng.bz/RVYK)'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Verma, P. 和 De Vync, G. (2023年6月2日)。ChatGPT夺走了他们的工作：现在他们遛狗和修理空调。*华盛顿邮报*。[https://mng.bz/EwQd](https://mng.bz/RVYK)
- en: Marr, B. (2024, April 18). The role of generative AI in video game development.
    *Forbes*. [https://mng.bz/Pdpn](https://mng.bz/Pdpn)
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Marr, B. (2024年4月18日)。生成式AI在视频游戏开发中的作用。*Forbes*。[https://mng.bz/Pdpn](https://mng.bz/Pdpn)
- en: Lev-Ram, M. (2023, January 26). Casualties of Big Tech layoffs find other companies
    are clamoring to hire them. *Forbes*. [https://mng.bz/JYXV](https://mng.bz/JYXV)
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Lev-Ram, M. (2023年1月26日)。科技巨头裁员受害者发现其他公司争相雇佣他们。*Forbes*。[https://mng.bz/JYXV](https://mng.bz/JYXV)
- en: Lohr, S. (2024, February 1). Generative A.I.’s biggest impact will be in banking
    and tech, report says. *New York Times*. [https://mng.bz/wJ7P](https://mng.bz/wJ7P)
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Lohr, S. (2024年2月1日)。报告称，生成式AI的最大影响将在银行和科技领域。*纽约时报*。[https://mng.bz/wJ7P](https://mng.bz/wJ7P)
- en: Pethokoukis, J. (2016, June 16). What the story of ATMs and bank tellers reveals
    about the “rise of the robots’’ and jobs. American Enterprise Institute. [https://mng.bz/qx7r](https://mng.bz/qx7r)
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pethokoukis, J. (2016年6月16日)。ATM和银行柜员的故事揭示了“机器人崛起”和就业的情况。美国企业研究所。[https://mng.bz/qx7r](https://mng.bz/qx7r)
- en: 'Hunter, L. W., Bernhardt, A., Hughes, K. L., and Skuratowicz, E. (2001). It’s
    not just the ATMs: Technology, firm strategies, jobs, and earnings in retail banking.
    *ILR Review, 54*(2A), 402-424\. [https://doi.org/10.1177/001979390105400222](https://doi.org/10.1177/001979390105400222)'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hunter, L. W., Bernhardt, A., Hughes, K. L. 和 Skuratowicz, E. (2001)。不仅仅是ATM：零售银行业的科技、企业策略、就业和收入。*ILR评论，54*(2A)，402-424。[https://doi.org/10.1177/001979390105400222](https://doi.org/10.1177/001979390105400222)
- en: Rosalsky, G. (2024, June 18). If AI is so good, why are there still so many
    jobs for translators? NPR. [https://mng.bz/7pBv](https://mng.bz/7pBv)
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Rosalsky, G. (2024年6月18日)。如果AI如此出色，为什么翻译工作仍然如此之多？NPR。[https://mng.bz/7pBv](https://mng.bz/7pBv)
- en: Marr, B. (2024, May 28). How generative AI will change the jobs of artists and
    designers. *Forbes*. [https://mng.bz/mG7a](https://mng.bz/mG7a)
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Marr, B. (2024年5月28日)。生成式AI将如何改变艺术家和设计师的工作。*Forbes*。[https://mng.bz/mG7a](https://mng.bz/mG7a)
- en: 'Autor, D., Chin, C., Salomons, A., and Seegmiller, B. (2024). New frontiers:
    The origins and content of new work, 1940–2018\. *The Quarterly Journal of Economics,
    139,* 1399–1465\. [https://doi.org/10.1093/qje/qjae008](https://doi.org/10.1093/qje/qjae008)'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Autor, D.，Chin, C.，Salomons, A. 和 Seegmiller, B. (2024)。新前沿：1940-2018年新工作的起源和内容。*经济学季刊，139*，1399-1465。[https://doi.org/10.1093/qje/qjae008](https://doi.org/10.1093/qje/qjae008)
- en: Dave, P. (2023, April 8). StackOverflow will charge AI giants for training data.
    *Wired*. [https://mng.bz/5gDO](https://mng.bz/5gDO)
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Dave, P. (2023年4月8日)。StackOverflow将对AI巨头收取训练数据费用。*Wired*。[https://mng.bz/5gDO](https://mng.bz/5gDO)
- en: Grimm, D. (2024, May 8). Stack Overflow bans users en masse for rebelling against
    OpenAI partnership—users banned for deleting answers to prevent them being used
    to train ChatGPT. Tom’s Hardware. [https://mng.bz/nR75](https://mng.bz/nR75)
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Grimm, D. (2024年5月8日)。Stack Overflow因用户反抗OpenAI合作而大规模封禁用户——封禁用户删除答案以防止其被用于训练ChatGPT。Tom’s
    Hardware。[https://mng.bz/nR75](https://mng.bz/nR75)
- en: 'Bishop, T. (2020, October 20). Expedia Group CEO on Google antitrust case:
    “Very pleased to see the government finally taking action.” Geek Wire. [https://mng.bz/vK7p](https://mng.bz/vK7p)'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bishop, T. (2020年10月20日)。Expedia集团首席执行官谈谷歌反垄断案：“非常高兴看到政府最终采取行动。”Geek Wire。[https://mng.bz/vK7p](https://mng.bz/vK7p)
- en: 'Siddiqui, T. (2023, June 29). Risks of artificial intelligence must be considered
    as the technology evolves: Geoffrey Hinton. University of Toronto. [https://mng.bz/4aNR](https://mng.bz/4aNR)'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Siddiqui, T. (2023年6月29日)。随着技术的发展，必须考虑人工智能的风险：杰弗里·辛顿。多伦多大学。[https://mng.bz/4aNR](https://mng.bz/4aNR)
- en: Bengio, Y. (2023, June 24). FAQ on catastrophic AI risks. [https://mng.bz/QDO6](https://mng.bz/QDO6)
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bengio, Y. (2023年6月24日)。关于灾难性AI风险的常见问题解答。[https://mng.bz/QDO6](https://mng.bz/QDO6)
- en: 'Introducing Llama 3.1: Our most capable models to date. (2024, July 23). Meta.
    [https://ai.meta.com/blog/meta-llama-3-1/](https://ai.meta.com/blog/meta-llama-3-1/)'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 介绍Llama 3.1：我们迄今为止最强大的模型。(2024年7月23日)。Meta。[https://ai.meta.com/blog/meta-llama-3-1/](https://ai.meta.com/blog/meta-llama-3-1/)
- en: 'Min, S., Gururangan, S., Wallace, E., et al. (2023). SILO language models:
    Isolating legal risk in a nonparametric datastore. [https://arxiv.org/abs/2308.04430](https://arxiv.org/abs/2308.04430)'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Min, S., Gururangan, S., Wallace, E., et al. (2023). SILO语言模型：在非参数数据集中隔离法律风险。[https://arxiv.org/abs/2308.04430](https://arxiv.org/abs/2308.04430)
- en: 'Rivero, N. (2022, September 21). Low-background metal: Pure, unadulterated
    treasure. *Quartz*. [https://mng.bz/eyXZ](https://mng.bz/eyXZ)'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Rivero, N. (2022年9月21日)。低背景金属：纯净、未被污染的宝藏。《Quartz》。[https://mng.bz/eyXZ](https://mng.bz/eyXZ)
- en: Shumailov, I., Shumaylov, Z., Zhao, Y. et al. (2024). AI models collapse when
    trained on recursively generated data. *Nature, 631,* 755–759\. [https://doi.org/10](https://doi.org/10.1038/s41586-024-07566-y)[.1038/s41586-024-07566-y](https://doi.org/10.1038/s41586-024-07566-y)
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Shumailov, I., Shumaylov, Z., Zhao, Y. 等. (2024)。当在递归生成数据上训练时，AI模型会崩溃。《自然》，631期，第755–759页。[https://doi.org/10.1038/s41586-024-07566-y](https://doi.org/10.1038/s41586-024-07566-y)
- en: Coffey, L. (2024, February 9). Professors cautious of tools to detect AI-generated
    writing. Inside Higher Education. [https://mng.bz/Xxj9](https://mng.bz/Xxj9)
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Coffey, L. (2024年2月9日)。教授们对检测AI生成写作的工具持谨慎态度。《高等教育内参》。[https://mng.bz/Xxj9](https://mng.bz/Xxj9)
- en: Has Stack Exchange’s traffic decreased since ChatGPT? (2023). Stack Exchange.
    [https://mng.bz/yW7p](https://mng.bz/yW7p)
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ChatGPT推出后，Stack Exchange的流量是否有所下降？(2023)。Stack Exchange。[https://mng.bz/yW7p](https://mng.bz/yW7p)
- en: Dhamani, N., and Engler, M. (2024). *Introduction to Generative AI*. Manning.
    [https://www.manning.com/books/introduction-to-generative-ai](https://www.manning.com/books/introduction-to-generative-ai)
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Dhamani, N. 和 Engler, M. (2024)。*生成式AI导论*。Manning。[https://www.manning.com/books/introduction-to-generative-ai](https://www.manning.com/books/introduction-to-generative-ai)
- en: index
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 索引
