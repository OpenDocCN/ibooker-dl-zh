- en: Chapter 11\. Building with LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章\. 使用LLM构建
- en: One of the biggest open questions in the world of LLMs today is how to best
    put them in the hands of end users. In some ways, LLMs are actually a more intuitive
    interface for computing than what came before them. They are much more forgiving
    of typos, slips of the tongue, and the general imprecision of humans, when compared
    to traditional computer applications. On the other hand, the very ability to handle
    inputs that are “slightly off” comes with a tendency to sometimes produce results
    that are also “slightly off”—which is also very much unlike any previous computing
    tendencies.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在今天的LLM（大型语言模型）世界中，最大的未解之谜之一是如何最好地将它们交到最终用户手中。在某种程度上，LLM实际上比之前的计算界面更加直观。与传统的计算机应用程序相比，它们对拼写错误、口误和人类的一般不精确性更加宽容。另一方面，处理“稍微偏离”的输入的能力也带来了一种倾向，即有时会产生“稍微偏离”的结果——这与之前的任何计算倾向都大不相同。
- en: In fact, computers were designed to reliably repeat the same set of instructions
    with the same results every time. Over the past few decades, that principle of
    reliability has permeated the design of human-computer interfaces (variously called
    HCI, UX, and UI) to the extent that a lot of the usual constructs end up being
    subpar for use in applications that rely heavily on LLMs.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，计算机被设计成每次都能可靠地重复执行同一组指令并得到相同的结果。在过去的几十年里，这一可靠性原则已经渗透到人机界面（统称为HCI、UX和UI）的设计中，以至于许多通常的结构最终在依赖于LLM的应用程序中变得不够好。
- en: 'Let’s take an example: Figma is a software application used by designers to
    create faithful renderings of designs for websites, mobile applications, book
    or magazine covers—the list goes on. As is the case with pretty much all productivity
    software (software for the creation of some kind of long-form content), its interface
    is a combination of the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举一个例子：Figma是一个设计师使用的软件应用程序，用于创建网站、移动应用、书籍或杂志封面等设计的忠实呈现——列表可以继续下去。与几乎所有生产力软件（用于创建某种长篇内容的软件）一样，其界面是以下因素的组合：
- en: A palette of tools and prebuilt *primitives* (fundamental building blocks),
    in this case lines, shapes, selection and paint tools, and many more
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一系列工具和预构建的*基本构建块*，在这种情况下是线条、形状、选择和绘图工具等等。
- en: 'A canvas, where the user inserts these building blocks and organizes them into
    their creation: a website page, a mobile app screen, and so on'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个画布，用户在此处插入这些构建块并将它们组织成自己的创作：一个网站页面、一个移动应用屏幕等等。
- en: This interface is built upon the premise that the capabilities of the software
    are known ahead of time, which is in fact true in the case of Figma. All building
    blocks and tools were coded by a software engineer ahead of time. Therefore, they
    were known to exist at the time the interface was designed. It sounds almost silly
    to point that out, but the same is not strictly true of software that makes heavy
    use of LLMs.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这个界面建立在软件功能事先已知的前提之上，这在Figma的案例中确实是真实的。所有构建块和工具都是软件工程师事先编写的。因此，在界面设计时，它们就已经存在了。指出这一点听起来几乎有些荒谬，但同样的情况并不严格适用于大量使用LLM的软件。
- en: 'Look at a word processor (e.g., Microsoft Word or Google Docs). This is a software
    application for the creation of long-form text content of some kind, such as a
    blog post, article, book chapter, and the like. The interface at our disposal
    here is also made up of a familiar combination:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下文字处理器（例如，Microsoft Word或Google Docs）。这是一个用于创建某种长篇文本内容的软件应用程序，例如博客文章、文章、书籍章节等等。我们可用的界面也是由以下熟悉的组合构成的：
- en: 'A palette of tools and prebuilt *primitives*: in the case of a word processor,
    the primitives available are tables, lists, headings, image placeholders, and
    so forth, and the tools are spellcheck, commenting, and so on.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一系列工具和预构建的*基本构建块*：在文字处理器的例子中，可用的基本构建块包括表格、列表、标题、图像占位符等等，而工具包括拼写检查、注释等等。
- en: '*A canvas*: in this case, it’s literally a blank page, where the user types
    words and may include some of the elements just mentioned.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*画布*：在这种情况下，它字面上是一个空白页面，用户在此处输入文字，并可能包含上述提到的某些元素。'
- en: How would this situation change if we were to build an LLM-native word processor?
    This chapter explores three possible answers to this question, which are broadly
    applicable to any LLM application. For each of the patterns we explore, we’ll
    go over what key concepts you’d need to implement it successfully. We don’t mean
    to imply that these are the only ones, it will be a while until the dust settles
    on this particular question.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们构建一个LLM原生文字处理器，这种情况会如何改变？本章探讨了三个可能的答案，这些答案广泛适用于任何LLM应用程序。对于我们所探讨的每个模式，我们将概述你需要实现它的关键概念。我们并不想暗示这些是唯一的，关于这个特定问题的尘埃可能还需要一段时间才会落定。
- en: Let’s look at each of these patterns, starting with the easiest to add to an
    existing app.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一查看这些模式，从最容易添加到现有应用程序的模式开始。
- en: Interactive Chatbots
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交互式聊天机器人
- en: This is arguably the easiest lift to add to an existing software application.
    At its most basic conception, this idea just bolts on an AI sidekick—to bounce
    ideas off of—while all work still happens in the existing user interface of the
    application. An example here is GitHub Copilot Chat, which can be used in a sidebar
    inside the VSCode code editor.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是向现有软件应用程序添加的最简单的改进。在最基本的概念上，这个想法只是将一个AI助手附加到应用现有的用户界面中——以供提出想法——而所有工作仍然在应用程序的现有用户界面中完成。这里的一个例子是GitHub
    Copilot Chat，它可以在VSCode代码编辑器的侧边栏中使用。
- en: An upgrade to this pattern is to add some communication points between the AI
    sidekick extension and the main application. For example, in VSCode, the assistant
    can “see” the content of the file currently being edited or whatever portion of
    that code the user has selected. And in the other direction, the assistant can
    insert or edit text in that open editor, arriving at some basic form of collaboration
    between the user and the LLM.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 将这种模式升级的一种方法是添加一些AI助手扩展和主应用程序之间的通信点。例如，在VSCode中，助手可以“看到”当前正在编辑的文件内容或用户选定的代码的任何部分。在另一个方向上，助手可以在该打开编辑器中插入或编辑文本，从而实现用户和LLM之间的一种基本形式的协作。
- en: Note
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 备注
- en: Streaming chat as we’re describing here is currently the prototypical application
    of LLMs. It’s almost always the first thing app developers learn to build on their
    LLM journey, and it’s almost always the first thing companies reach for when adding
    LLMs to their existing applications. Maybe this will remain the case for years
    to come, but another possible outcome could be for streaming chat to become the
    command line of the LLM era—that is, the closest to direct programming access,
    becoming a niche interface, just as it did for computers.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所描述的，流式聊天是目前LLM的典型应用。它几乎是应用开发者在其LLM之旅中学习的第一个要构建的内容，它几乎是公司向现有应用程序添加LLM时首先寻求的内容。也许这种情况会持续多年，但另一种可能的结局可能是流式聊天成为LLM时代的命令行——即，最接近直接编程访问的，成为一个利基界面，就像它对计算机所做的那样。
- en: 'To build the most basic chatbot you should use these components:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建最基础的聊天机器人，你应该使用以下组件：
- en: A chat model
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一个聊天模型
- en: Their dialogue tuning lends itself well to multiturn interactions with a user.
    Refer to the [Preface](preface01.html#pr01_preface_1736545679069216) for more
    on dialogue tuning.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的对话调整非常适合与用户的多次交互。有关对话调整的更多信息，请参阅[序言](preface01.html#pr01_preface_1736545679069216)。
- en: Conversation history
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对话历史
- en: A useful chatbot needs to be able to “get past hello.” That is, if the chatbot
    can’t remember the previous user inputs, it will be much harder to have meaningful
    conversations with it, which implicitly refer to previous messages.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有用的聊天机器人需要能够“超越你好”。也就是说，如果聊天机器人无法记住之前的用户输入，那么与它进行有意义的对话将会非常困难，这隐含地指代了之前的消息。
- en: 'To go beyond the basics, you’d probably add the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要超越基础，你可能需要添加以下内容：
- en: Streaming output
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 流式输出
- en: The best chatbot experiences currently stream LLM output token by token (or
    in larger chunks, like sentences or paragraphs) directly to the user, which alleviates
    the latency inherent to LLMs today.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 目前最好的聊天机器人体验是将LLM的输出逐个token（或更大的块，如句子或段落）直接流式传输到用户，这减轻了今天LLM固有的延迟。
- en: Tool calling
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 工具调用
- en: To give the chatbot the ability to interact with the main canvas and tools of
    the application, you can expose them as tools the model can decide to call on—for
    instance, a “get selected text” tool and an “insert text at end of doc” tool.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要使聊天机器人能够与应用程序的主画布和工具交互，你可以将它们暴露为模型可以决定调用的工具——例如，“获取选中文本”工具和“在文档末尾插入文本”工具。
- en: Human-in-the-loop
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 人工参与式
- en: As soon as you give the chatbot tools that can change what’s in the application
    canvas, you create the need to give back some control to the user—for example,
    letting the user confirm, or even edit, before new text is inserted.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你给聊天机器人工具可以改变应用程序画布中的内容，你就需要将一些控制权交还给用户——例如，让用户在插入新文本之前确认，甚至编辑。
- en: Collaborative Editing with LLMs
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与LLMs的协作编辑
- en: 'Most productivity software has some form of collaborative editing built in,
    which we can classify into one of these buckets (or somewhere in between):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数生产力软件都内置了某种形式的协作编辑功能，我们可以将其归类为以下类别之一（或介于两者之间）：
- en: Save and send
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 保存和发送
- en: 'This is the most basic version, which only supports one user editing the document
    at a time, before “passing the buck” to another user (for example, sending the
    file over email) and repeating the process until done. The most obvious example
    is the Microsoft Office suite of apps: Excel, Word, PowerPoint.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最基本的版本，一次只能支持一个用户编辑文档，然后在“移交接力棒”给另一个用户（例如，通过电子邮件发送文件）并重复此过程，直到完成。最明显的例子是Microsoft
    Office应用程序套件：Excel、Word、PowerPoint。
- en: Version control
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 版本控制
- en: 'This is an evolution of save and send that supports multiple editors working
    simultaneously on their own (and unaware of each other’s changes) by providing
    tools to combine their work afterward: merge strategies (how to combine unrelated
    changes) and conflict resolution (how to combine incompatible changes). The most
    popular example today is Git/GitHub, used by software engineers to collaborate
    on software projects.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是保存和发送的演变，支持多个编辑者同时在自己的文档上工作（并且不知道彼此的更改），通过提供工具在之后合并他们的工作：合并策略（如何合并无关的更改）和冲突解决（如何合并不兼容的更改）。今天最受欢迎的例子是Git/GitHub，软件工程师用它来协作软件项目。
- en: Real-time collaboration
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 实时协作
- en: This enables multiple editors to work on the same document at the same time,
    while seeing each other’s changes. This is arguably the most natural form of software-enabled
    collaboration, evidenced by the popularity of Google Docs and Google Sheets among
    technical and nontechnical computer users.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得多个编辑者可以同时编辑同一份文档，同时看到彼此的更改。这可以说是软件支持的最自然形式的协作，这一点可以从Google Docs和Google Sheets在技术和非技术计算机用户中的流行程度得到证明。
- en: 'This pattern of LLM user experience consists of employing an LLM agent as one
    of those “users” contributing to this shared document. This can take many forms,
    including the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这种LLM用户体验模式包括将LLM代理作为那些“用户”之一，为这个共享文档做出贡献。这可以采取多种形式，包括以下几种：
- en: An always-on “copilot” giving you suggestions on how to complete the next sentence
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总是处于“副驾驶”状态，为你提供如何完成下一句的建议
- en: An asynchronous “drafter,” which you task with, for example, going off and researching
    the topic in question and returning later with a section you can incorporate in
    your final document
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个异步的“草稿人”，你可以分配给，例如，去研究相关主题，然后稍后带回来可以融入最终文档的章节
- en: 'To build this, you’d likely need the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建这个，你可能会需要以下内容：
- en: Shared state
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 共享状态
- en: The LLM agent and the human users should be on the same footing in terms of
    access and understanding of the state of the document—that is, they would be able
    to parse the state of the document and produce edits to that state in a compatible
    format.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理和人类用户在访问和理解文档状态方面应该处于同等地位——也就是说，他们能够解析文档的状态并产生对该状态的编辑，以兼容的格式。
- en: Task manager
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 任务管理器
- en: Producing a useful edit to the document will invariably be a multistep process,
    which can take time and fail halfway. This creates the need for reliable scheduling
    and orchestration of long-running jobs, with queueing, error recovery, and control
    over running tasks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 生成有用的文档编辑将不可避免地是一个多步骤的过程，这可能需要时间，并且可能在半途中失败。这需要可靠的长运行作业调度和编排，包括排队、错误恢复和对运行任务的控制。
- en: Merging forks
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 合并分支
- en: Users will continue to edit the document after tasking the LLM agent, so LLM
    outputs will need to be merged with the users’ work, either manually by the user
    (an experience like Git) or automatically (through conflict resolution algorithms
    such as CRDT and operational transformation (OT), employed by applications such
    as Google Docs).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 用户在分配任务给LLM代理后将继续编辑文档，因此LLM的输出需要与用户的工作合并，要么由用户手动（类似于Git）合并，要么自动（通过如Google Docs所使用的CRDT和操作转换（OT）等冲突解决算法）。
- en: Concurrency
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 并发
- en: The fact that the human user and the LLM agent are working on the same thing
    at the same time requires the ability to handle interruptions, cancellations,
    reroutings (do this instead), and queueing (do this as well).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 人类用户和LLM代理同时处理同一件事情需要处理中断、取消、重新路由（这样做）和排队（这样做）的能力。
- en: Undo/redo stack
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 撤销/重做堆栈
- en: This is a ubiquitous pattern in productivity software, which inevitably is needed
    here too. Users change their minds and want to go back to an earlier state of
    the document, and the LLM application needs to be capable of following them there.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在生产力软件中普遍存在的模式，不可避免地也需要在这里。用户可能会改变主意，想要回到文档的早期状态，LLM应用需要能够跟随他们到那里。
- en: Intermediate output
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 中间输出
- en: Merging user and LLM outputs is made a lot easier when those outputs are gradual
    and arrive piecemeal as soon as they’re produced, in much the same way that a
    person writes a 10-paragraph page one sentence at a time.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当输出逐渐进行并且一旦产生就分批到达时，合并用户和LLM的输出会变得容易得多，就像一个人逐句写一个10段落的页面一样。
- en: Ambient Computing
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 环境计算
- en: 'A very useful UX pattern has been the always-on background software that pipes
    up when something “interesting” has happened that deserves your attention. You
    can find this in many places today. A few examples are:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常有用的UX模式是始终开启的背景软件，当发生需要你注意的“有趣”事件时，它会发出声音。你可以在今天找到很多这样的例子。以下是一些例子：
- en: You can set an alert in your brokerage app to notify you when some stock goes
    below a certain price.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在你的经纪应用中设置一个警报，当某些股票价格低于某个特定价格时通知你。
- en: You can ask Google to notify you when new search results are found matching
    some search query.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以要求谷歌在找到匹配某些搜索查询的新搜索结果时通知你。
- en: You can define alerts for your computer infrastructure to notify you when something
    is outside the regular pattern of behavior.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以为你的计算机基础设施定义警报，当某些行为偏离常规模式时通知你。
- en: 'The main obstacle to deploying this pattern more widely may be coming up with
    a reliable definition of *interesting* ahead of time that is both of the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在更广泛地部署这种模式时，主要障碍可能是提前找到一个可靠的*有趣*的定义，这个定义同时满足以下两点：
- en: Useful
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有用
- en: It will notify you when you think it should.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当你认为应该通知你时，它会通知你。
- en: Practical
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 实用性
- en: Most users won’t want to spend massive amounts of time ahead precreating endless
    rules for alerts.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数用户不会愿意花费大量时间预先创建无尽的规则来设置警报。
- en: The reasoning capabilities of LLMs can unlock new applications of this pattern
    of *ambient computing* that are simultaneously more useful (they identify more
    of what you’d find interesting) and less work to set up (their reasoning can replace
    a lot or all of the manual setup of rules).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的推理能力可以解锁这种*环境计算*模式的新应用，这些应用同时更加有用（它们能识别出更多你感兴趣的内容）并且设置起来更加简单（它们的推理可以替代大部分或全部的手动规则设置）。
- en: 'The big difference between *collaborative* and *ambient* is concurrency:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*协作*和*环境*之间的主要区别在于并发性：'
- en: Collaborative
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 协作
- en: You and the LLM are usually (or sometimes) doing work at the same time and feeding
    off each other’s work.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你和LLM通常（或有时）同时工作，并从对方的工作中汲取灵感。
- en: Ambient
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 环境
- en: The LLM is continuously doing some kind of work in the background while you,
    the user, are presumably doing something else entirely.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当你，用户，可能在做其他事情时，LLM（大型语言模型）会持续在后台进行某种工作。
- en: 'To build this, you need:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 构建这个系统，你需要：
- en: Triggers
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 触发器
- en: 'The LLM agent needs to receive (or poll periodically for) new information from
    the environment. This is in fact what motivates ambient computing: a preexisting
    source of periodic or continuous new information that needs to be processed.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: LLM代理需要从环境中接收（或定期轮询）新信息。这实际上是环境计算的动力：一个现有的周期性或连续的新信息来源，需要被处理。
- en: Long-term memory
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 长期记忆
- en: It would not be possible to detect new interesting events without consulting
    a database of previously received information.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 没有咨询之前接收到的信息数据库，将无法检测到新的有趣事件。
- en: Reflection (or learning)
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 反思（或学习）
- en: Understanding what is *interesting* (what deserves human input) likely requires
    learning from each previous interesting event after it happens. This is usually
    called a *reflection step*, in which the LLM produces an update to its long-term
    memory, possibly modifying its internal “rules” for detecting future interesting
    events.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 理解什么是*有趣*的（什么值得人类输入）可能需要从每个已经发生的有兴趣的事件中学习。这通常被称为*反思步骤*，其中LLM更新其长期记忆，可能修改其检测未来有趣事件的内部“规则”。
- en: Summarize output
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 总结输出
- en: An agent working in the background is likely to produce much more output than
    the human user would like to see. This requires that the agent architecture be
    modified to produce summaries of the work done and surface to the user only what
    is new or noteworthy.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在后台工作的代理可能会产生比人类用户希望看到的多得多的输出。这要求代理架构被修改以生成工作摘要，并将新或值得注意的内容仅呈现给用户。
- en: Task manager
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 任务管理器
- en: Having an LLM agent working continuously in the background requires employing
    some system for managing the work, queuing new runs, and handling and recovering
    from error.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在后台持续运行LLM代理需要采用某种系统来管理工作，排队新的运行，并处理和从错误中恢复。
- en: Summary
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: LLMs have the potential to change not only [how we build software](https://oreil.ly/RqnCm),
    but also the very software we build. This new capability that we developers have
    at our disposal to generate new content will not only enhance many existing apps,
    but it can make new things possible that we haven’t dreamed of yet.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs有潜力改变我们构建软件的方式，甚至改变我们构建的软件本身。我们开发者现在可以利用的新能力来生成新内容，不仅将增强许多现有应用，还可以实现我们尚未梦想过的新事物。
- en: There’s no shortcut here. You really do need to build something (s)crappy, speak
    to users, and rinse and repeat until something new and unexpected comes out the
    other side.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有捷径。您真的需要构建一些（s）crap的东西，与用户沟通，然后重复这个过程，直到出现新的、意料之外的东西。
- en: With this last chapter, and the book as a whole, we have tried to give you the
    knowledge we think can help you build something uniquely good with LLMs. We want
    to thank you for coming on this journey with us and wish you the best of luck
    in your career and future.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这一章以及整本书，我们试图向您提供我们认为可以帮助您利用LLMs构建独特优秀事物的知识。我们感谢您与我们一同踏上这段旅程，并祝您在事业和未来中一切顺利。
