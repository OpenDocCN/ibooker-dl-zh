<html><head></head><body>
  <div class="readable-text" id="p1"> &#13;
   <h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">6</span> </span> <span class="chapter-title-text">Advanced text mining with generative AI</span></h1> &#13;
  </div> &#13;
  <div class="introduction-summary"> &#13;
   <h3 class="introduction-header sigil_not_in_toc">This chapter covers</h3> &#13;
   <ul> &#13;
    <li class="readable-text" id="p2">Sentiment analysis with a generative AI language model</li> &#13;
    <li class="readable-text" id="p3">Sentiment analysis with a generative AI API</li> &#13;
    <li class="readable-text" id="p4">Sentiment analysis with machine learning</li> &#13;
    <li class="readable-text" id="p5">Text summarization with generative AI</li> &#13;
    <li class="readable-text" id="p6">Text summarization with dedicated libraries</li> &#13;
    <li class="readable-text" id="p7">Topic modeling</li> &#13;
   </ul> &#13;
  </div> &#13;
  <div class="readable-text" id="p8"> &#13;
   <p>In the previous chapter, you got a taste of text-mining basics and discovered how generative AI can speed up and refine your analyses. Now, let’s go deeper. Ahead, you’ll tackle advanced NLP techniques such as sentiment analysis and text summarization. These tools are invaluable in the business world, enabling companies to swiftly gauge customer sentiment from reviews, social media, or customer service interactions, leading to more informed decision-making. Text summarization, on the other hand, can distill lengthy reports, research findings, or customer feedback into digestible insights, saving your precious time and ensuring key information doesn’t go unnoticed. Together, these techniques can significantly enhance how businesses understand and respond to their audiences, driving better strategies and outcomes.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p9"> &#13;
   <p>In this chapter, you’ll see how the straightforward sentiment analysis methods from chapter 5 stack up against the advanced capabilities of machine learning models and generative AI’s linguistic finesse. Prepare to witness firsthand the challenge of outperforming generative AI in NLP tasks. Your objective? As always, to impress your boss. But this time, by swiftly and accurately uncovering key customer insights through the extraction and summarization of negative reviews. With generative AI as your ally, you’re equipped to sail smoothly through these complex processes.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p10"> &#13;
   <h2 class="readable-text-h2" id="sigil_toc_id_91"><span class="num-string">6.1</span> Review analysis</h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p11"> &#13;
   <p>As you move forward in this chapter, remember the task your boss handed you: to uncover the main issues customers have with your company’s products and services, based on their reviews. The initial steps you took in the previous chapter shed some light, but now you are faced with an intriguing challenge: can you deepen your understanding by tapping into more advanced NLP techniques? Let’s find out together.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p12"> &#13;
   <p>The dataset you examined in the previous chapter contained customer reviews (described in detail in section 5.2.2). It was rather disorganized, which is common for this type of data. Additionally, the fact that the reviews are in Portuguese poses another challenge, assuming you’re not familiar with the language. To navigate this clutter, we’ll explore various techniques for deriving insights from unstructured data, among which these are the two most important:</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p13"> <em>Sentiment analysis</em><em> </em>—The process of determining the underlying emotions, opinions, or attitudes expressed within a piece of text, such as positive, negative, or neutral sentiment. This technique is invaluable for businesses aiming to gauge customer satisfaction, monitor brand reputation, or understand consumer needs. For example, after applying it to customer reviews, a company can pinpoint which features of a product or service are most appreciated or which aspects are causing dissatisfaction. </li> &#13;
   <li class="readable-text" id="p14"> <em>Text summarization</em><em> </em>—The technique of condensing a larger body of text into a shorter, coherent representation that retains the most essential information and key ideas. This method is particularly useful for professionals who need to quickly assimilate large volumes of information without sacrificing understanding. For instance, a financial analyst could employ text summarization to distill comprehensive market reports and research papers into concise summaries, enabling faster decision-making and efficiently keeping abreast of critical market trends and forecasts. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p15"> &#13;
   <p>You might have noticed that the basic NLP techniques described in the previous chapter already laid the groundwork for sentiment analysis and text summarization. Utilizing keywords or predefined lexicons to filter out positive reviews indeed serves as a rudimentary form of sentiment analysis, while even basic frequency analysis proved sufficient to highlight the main concerns appearing in customer feedback, thus providing a form of text summary. So, are you going to learn anything new in this chapter? Absolutely, you will.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p16"> &#13;
   <p>To put it simply, what you’ve learned so far is akin to learning how to peel potatoes. In this chapter, we’re about to master the art of gourmet cuisine. However, our approach remains highly practical, meaning you won’t be required to perform complex calculations mentally. Instead, we’ll introduce you to the best tools available for achieving your objectives. Specifically, we will use pretrained machine learning models available online to conduct sentiment analysis and text summarization, with generative AI guiding us throughout the process. We will also leverage generative AI’s inherent language capabilities to directly undertake these NLP tasks. The subsequent sections will offer a comparison of these two methods and the basic NLP techniques introduced previously, providing insight into their relative performance and utility.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p17"> &#13;
   <h2 class="readable-text-h2" id="sigil_toc_id_92"><span class="num-string">6.2</span> Sentiment analysis</h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p18"> &#13;
   <p>Sentiment analysis is a type of text classification where a label or class is assigned to a given text. For example, labels such as “correct,” “incorrect,” or “unknown” can be used to classify texts based on their grammatical correctness. Specifically, in sentiment analysis, the labels “positive,” “negative,” and “neutral” are typically used to reflect the author’s emotions and attitudes toward a subject. For instance, a statement like “I hate your company and your sh**y Quantum Fluff!” carries strong negative sentiment. Without NLP tools, such emotionally charged comments could easily be overlooked by your company’s PR department amidst a sea of other feedback. However, hoping that negative opinions will remain similarly unseen by other customers is nothing but wishful thinking. Such views tend to spread rapidly, much like a wildfire in a savanna, potentially endangering your company’s reputation. Therefore, learning how to automatically detect customer sentiments is crucial for your business’s well-being.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p19"> &#13;
   <p>It’s important to note that text classification encompasses a much wider range of applications than just sentiment analysis. Consider a scenario where the input involves not just a single piece of text, like customer reviews, but two pieces, with the goal of identifying the relationship between them. This leads to the field of natural language inference (NLI), which significantly broadens the scope of language analysis.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p20"> &#13;
   <p>NLI tasks can vary depending on the inputs and the labels assigned, but ultimately they all boil down to text classification. For instance, the first input text might be a premise, such as “A robin is a bird,” and the second a hypothesis, like “A robin can fly.” The possible labels could be “entailment,” indicating that the hypothesis logically follows from the premise (e.g., since a robin is a bird, and most birds can fly, it entails that a robin can fly); “contradiction,” indicating that the hypothesis contradicts the premise; and “neutral” for hypotheses that are irrelevant or cases that are difficult to categorize. This framework allows for the development of programs that, at least theoretically, can perform a form of reading comprehension. The practical implementation of such programs, however, depends on various factors, including task complexity, the volume and quality of training data, and our skill (and perhaps a bit of luck) in creating a model capable of undertaking such a challenge.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p21"> &#13;
   <p>The task assigned by your boss—to classify reviews—is considerably less complex than the mentioned NLI tasks. Nonetheless, it offers an excellent opportunity to explore the fundamentals of text classification and sentiment analysis.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p22"> &#13;
   <p>In the previous chapter, we demonstrated how to conduct basic sentiment analysis, particularly extracting positive reviews using rule-based (keyword search) and dictionary-based (lexicon) methods. Now, consider how our simple classifier, utilizing these approaches, would classify the following review: “Great, another software update that fixes nothing.” Given the presence of words like “great” and “fixes,” it might mistakenly classify this statement as positive, despite its sarcastic tone expressing frustration over unmet promises of improvement by the software update.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p23"> &#13;
   <p>Pretrained models are getting pretty good at sniffing out sarcasm in text, but they’re not magic. They achieve this feat through a combination of analyzing language tricks and understanding the broader context. By training on massive amounts of text data, including examples dripping with sarcasm and others that are plain and literal, these models become familiar with the linguistic gymnastics humans use to convey hidden meaning. They learn to identify red flags like positive words used in negative situations (“this is perfect” after a frustrating experience) or phrases that go against the grain of normal conversation (“Can’t wait for Monday morning!”). But sarcasm isn’t all about wordplay. Pretrained models also zoom out, examining the surrounding text and the relationship between the speaker and listener. For instance, a sarcastic comment between friends is more likely than a sarcastic remark from your boss during a performance review.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p24"> &#13;
   <p>Now, let’s examine the phrase, “back to the drawing board.” Through basic keyword or dictionary-based analysis, accurately classifying this expression poses a challenge, as it lacks explicit sentiment indicators. However, “back to the drawing board” is typically used to express that an attempt has failed and it’s time to start over, often carrying a connotation of disappointment or setback.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p25"> &#13;
   <p>In contrast, machine learning models, developed with extensive and diverse text datasets, can accurately comprehend idiomatic expressions and their contextual meanings, effectively identifying sentiments of disappointment or frustration. This capability is crucial for thorough sentiment analysis, proving particularly valuable in evaluating feedback, reviews, or internal communications where such expressions are common. An added advantage of such models is their ability to adapt to different domains or languages with little manual effort, making them versatile tools for sentiment analysis across various datasets. A prime example of such a pretrained model is a large language model or LLM.</p> &#13;
  </div> &#13;
  <div class="readable-text print-book-callout" id="p26"> &#13;
   <p><span class="print-book-callout-head">Large Language Model (LLM)</span>  An LLM is a powerful AI system trained on vast amounts of text so it can understand and generate human language. It uses deep learning to perform a wide range of NLP tasks, including translation, summarization, question answering, and sentiment analysis, by predicting the likelihood of a sequence of words. The capabilities of LLMs extend beyond simple text processing, enabling them to grasp context, infer meaning, and even generate coherent and contextually relevant text responses, making them powerful tools in both research and application domains.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p27"> &#13;
   <p>All the generative AI models discussed so far and utilized throughout this book are LLMs. Although they were originally designed for general-purpose conversations rather than as dedicated review classifiers, their exceptional ability to understand text and extract insights enables them to be effectively used for sentiment analysis tasks. In the following sections, we will show how to apply them to sentiment analysis and compare the results with those obtained from smaller machine learning models.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p28"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_93"><span class="num-string">6.2.1</span> What can you learn from sentiment analysis?</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p29"> &#13;
   <p>Sentiment analysis offers invaluable insights across various business domains, enabling your company to understand customer emotions, preferences, and feedback on a granular level. For example, if you work for a retail brand, you can analyze social media mentions to gauge consumer sentiment toward a new product launch, identifying areas of excitement or concern to tailor marketing strategies accordingly. If you happen to deal with the finance sector, sentiment analysis of news articles and financial forums can help you and your investors predict market trends and make informed decisions. If you are engaged in hospitality businesses, like hotels and restaurants, utilizing sentiment analysis on review platforms to highlight areas for improvement in service or ambiance can directly impact customer satisfaction and loyalty. Additionally, in tech companies, you can leverage sentiment analysis in user feedback for software updates, prioritizing fixes and features that address the most pressing user concerns. This strategic application of sentiment analysis not only enhances product and service quality but also fosters a closer connection with customers by showing responsiveness to their needs and opinions.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p30"> &#13;
   <p>The simplest and most often used form of sentiment analysis categorizes texts into three groups: positive, negative, and neutral sentiments. In many cases, such as with our reviews, this is enough to understand customer sentiment. However, you may encounter situations where you will have to explore more complex aspects of the human soul (read: demandingness) and apply other instances of sentiment analysis, such as these:</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p31"> <em>Emotion detection</em><em> </em>—This involves identifying specific emotions expressed in the text, such as happiness, sadness, anger, surprise, fear, and disgust, allowing for a more detailed understanding of the user’s feelings and reactions. This may be crucial, such as for detecting suicidal ideation on social media. Another business application where emotion detection is essential is in customer support and service interactions, especially for industries like telecommunications, banking, or utilities, where customer frustrations can escalate quickly. For example, in a telecommunications company, emotion detection can be employed in analyzing customer support chats or call transcripts. By identifying specific emotions such as frustration, anger, or disappointment, the company can flag cases that require immediate attention or intervention. This allows for a prioritized response to highly dissatisfied customers before they tell everyone on the web that Quantum Fluff (your company’s pet feature) actually does more harm than good. </li> &#13;
   <li class="readable-text" id="p32"> <em>Aspect-based sentiment analysis</em><em> </em>—This technique focuses on identifying sentiments related to specific aspects or features within a text. For instance, in product reviews, it differentiates sentiments toward the product’s price, quality, design, etc., providing detailed insights into various facets of customer feedback. Who knows—maybe Quantum Fluff would gain more customer appreciation if it was cheaper? </li> &#13;
   <li class="readable-text" id="p33"> <em>Intensity or sentiment strength</em><em> </em>—Sentiment analysis can also assess the intensity or degree of sentiment expressed, distinguishing between mild and strong emotions. This helps in understanding not just the nature of the sentiment but also its strength or urgency. For instance, after such an analysis, it may turn out that Quantum Fluff provokes such intense negative feelings that people are willing to pay more just to get rid of it, offering your company new opportunities to earn. </li> &#13;
   <li class="readable-text" id="p34"> <em>Intent analysis</em><em> </em>—Beyond identifying sentiment, some approaches aim to understand the intent behind a text, such as whether the user intends to purchase, recommend, or complain about a product or service. This may prove useful for evaluating customer support tickets, emails, and social media messages. By analyzing the language and phrases customers use, the system can determine their intent, such as seeking information about new plans, reporting a service outage, requesting technical support, or expressing intent to cancel their service. For instance, if a customer’s message is found to contain phrases such as “turn this bloody Quantum Fluff off,” “better fluffs elsewhere,” or “thinking of switching,” the system can flag this as a high-priority intent to churn. This can trigger an immediate response from a specialized customer retention team, who can reach out to the customer with personalized offers (such as five months without Quantum Fluff for free), support, or solutions aimed at addressing their concerns. This proactive approach not only improves customer satisfaction by providing timely and relevant responses but also aids in reducing churn rates, directly impacting the company’s bottom line. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p35"> &#13;
   <p>These advanced approaches to sentiment analysis allow for a richer, more complex understanding of textual data, offering deeper insights into consumer behavior, market trends, and public opinion.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p36"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_94"><span class="num-string">6.2.2</span> Direct sentiment analysis with generative AIs</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p37"> &#13;
   <p>Even though generative AIs were primarily designed for generating text completions rather than performing sentiment analysis, their ability to comprehend text can be utilized for a quick assessment of the sentiment expressed in any given piece of text. You can test this by examining three reviews from our example dataset. These reviews come with scores of 5, 3, and 1, which indicate positive, neutral, and negative sentiments respectively. The reviews, along with their translations, are presented in table 6.1. Also detailed are the results of the sentiment analysis conducted by ChatGPT 4 and Gemini Advanced. To achieve similar results, you can use the prompt “What is the sentiment of these reviews?” followed by including the reviews in Portuguese.</p> &#13;
  </div> &#13;
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p38"> &#13;
   <h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 6.1</span> Direct sentiment analysis with generative AIs</h5> &#13;
   <table> &#13;
    <thead> &#13;
     <tr> &#13;
      <th> &#13;
       <div>&#13;
         Review translated by Google Translate &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Review score &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         True sentiment &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Sentiment analysis by ChatGPT 4 &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Sentiment analysis by Gemini Advanced &#13;
       </div></th> &#13;
     </tr> &#13;
    </thead> &#13;
    <tbody> &#13;
     <tr> &#13;
      <td>  I received it well before the stipulated time. <br/></td> &#13;
      <td>  5 <br/></td> &#13;
      <td>  positive <br/></td> &#13;
      <td>  <em>positive</em> <br/>  The customer received the product well before the stipulated deadline, indicating a positive experience with the delivery. <br/></td> &#13;
      <td>  <em>positive</em> <br/>  The reviewer received the product well before the estimated delivery date. <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Good product, but what came to me does not match the photo in the ad. <br/></td> &#13;
      <td>  3 <br/></td> &#13;
      <td>  neutral <br/></td> &#13;
      <td>  <em>mixed/neutral</em> <br/>  The review mentions that the product is good (positive sentiment), but also states that the received product does not match the photo in the advertisement (negative sentiment). This combination of sentiments makes the overall sentiment mixed or neutral. <br/></td> &#13;
      <td>  <em>mixed</em> <br/>  The reviewer says the product is good, but it doesn’t match the photo in the ad. <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  I would like to know why my product has not yet arrived at my residence and nobody has given me satisfaction or anything like that. <br/></td> &#13;
      <td>  1 <br/></td> &#13;
      <td>  negative <br/></td> &#13;
      <td>  <em>negative</em> <br/>  The customer is expressing dissatisfaction with the fact that the product has not yet arrived at their residence and that they haven’t received any explanation or communication regarding the delay. This indicates a negative experience with the delivery and customer service. <br/></td> &#13;
      <td>  <em>negative</em> <br/>  The reviewer hasn’t received the product yet and hasn’t received any updates from the seller. <br/></td> &#13;
     </tr> &#13;
    </tbody> &#13;
   </table> &#13;
  </div> &#13;
  <div class="readable-text" id="p39"> &#13;
   <p>As you can see in the table, both ChatGPT 4 and Gemini Advanced demonstrated perfect understanding of the reviews. The outcomes from this modest experiment are encouraging and warrant further exploration into how direct application of generative AIs compares with the basic sentiment analysis techniques outlined in section 5.5.4. In that section, the simplest keyword search (listing 5.6) managed to identify positive reviews with a sensitivity of around 47% and a specificity of up to 90%. </p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p40"> &#13;
   <p>You are about to see whether direct utilization of generative AI’s language capabilities can yield improved results. The review scores provided in our example dataset will once again be used as a reference point for evaluating the quality of the analysis through the calculation of sensitivity and specificity. But before we can draw any conclusions, we need to conduct direct sentiment analysis with generative AI on a larger sample, by using its API.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p41"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_95"><span class="num-string">6.2.3</span> Sentiment analysis with generative AI’s API</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p42"> &#13;
   <p>To evaluate generative AI’s capabilities in detecting sentiments on a broader scale, we will utilize the ChatGPT 4 API. For details on API usage, see chapter 1. It’s also important to note that accessing the API might require a subscription or a specific pricing plan. Your goal here is to have ChatGPT assess the sentiment of the first 500 non-empty reviews from the dataset, and compare these results with those from a basic sentiment analysis using keywords, as conducted in section 5.5.4 (listing 5.6).</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p43"> &#13;
   <p>The following code demonstrates how you can use the API to conduct sentiment analysis on the reviews by leveraging the intrinsic language capabilities of ChatGPT 4. To make it operational, you’ll need to replace <code>your-api-key</code> with your actual ChatGPT API key and ensure that your account has sufficient funds. Fortunately, you can also find the results of this analysis in the books GitHub repository in the Sentiment_Analysis_500reviews.csv file.</p> &#13;
  </div> &#13;
  <div class="browsable-container listing-container" id="p44"> &#13;
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 6.1</span> Sentiment analysis with ChatGPT's intrinsic language capabilities</h5> &#13;
   <div class="code-area-container code-area-with-html"> &#13;
    <pre class="code-area">from openai import OpenAI&#13;
<em># Replace 'your_openai_api_key' with your actual OpenAI API key</em>&#13;
client = OpenAI(&#13;
    api_key= "your-api-key",&#13;
)&#13;
def get_sentiment(review):&#13;
    response = client.chat.completions.create(&#13;
        messages=[&#13;
            {&#13;
                "role": "user",&#13;
                "content": f"The sentiment of this review is: {review}",&#13;
            }&#13;
        ],&#13;
        model="gpt-4-0125-preview",&#13;
    )&#13;
    completion = response.choices[0].message.content&#13;
    if "positive" in completion:&#13;
        return "positive"&#13;
    elif "neutral" in completion:&#13;
        return "neutral"&#13;
    elif "negative" in completion:&#13;
        return "negative"&#13;
    else:&#13;
        return "unknown"&#13;
<em># Analyze the reviews and store the output (manually adapted)</em>&#13;
sentiments = []&#13;
for review in reviews:&#13;
    sentiments.append(get_sentiment(review))&#13;
df["GPT4"] = sentiments</pre>  &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p45"> &#13;
   <p>The preceding code is straightforward. For each of the 500 reviews stored in the DataFrame, we send the following prompt to ChatGPT via the API: <code>The</code> <code>sentiment</code> <code>of</code> <code>this review</code> <code>is:</code>, appending the actual review text. The model then generates a response, which is classified as positive if it includes the word “positive.” The terms “negative” and “neutral” are utilized to identify negative and neutral sentiments respectively. If none of these words are found, the review is left without an assigned sentiment. Note that this method of analyzing ChatGPT’s responses is quite basic and may overlook more nuanced answers, such as those indicating mixed feelings within a review. Despite its simplicity, this approach can still produce remarkable results, as documented in table 6.2. </p> &#13;
  </div> &#13;
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p46"> &#13;
   <h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 6.2</span> Quality of sentiment analysis with ChatGPT 4 API</h5> &#13;
   <table> &#13;
    <thead> &#13;
     <tr> &#13;
      <th> &#13;
       <div>&#13;
         Sentiment analysis ( &#13;
        <em>n</em>=500) &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Number of reviews classified as positive &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Sensitivity &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Specificity &#13;
       </div></th> &#13;
     </tr> &#13;
    </thead> &#13;
    <tbody> &#13;
     <tr> &#13;
      <td>  Reference review score <br/></td> &#13;
      <td>  320 (64%) <br/>  true positives <br/></td> &#13;
      <td>  1 <br/></td> &#13;
      <td>  1 <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Basic keyword search <br/></td> &#13;
      <td>  163 (33%) <br/></td> &#13;
      <td>  0.45 <br/></td> &#13;
      <td>  0.9 <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  ChatGPT 4 API <br/></td> &#13;
      <td>  250 (50%) <br/></td> &#13;
      <td>  0.74 <br/></td> &#13;
      <td>  0.93 <br/></td> &#13;
     </tr> &#13;
    </tbody> &#13;
   </table> &#13;
  </div> &#13;
  <div class="readable-text" id="p47"> &#13;
   <p>As in our previous approach, you can use the <code>review_score</code> variable from the dataset to evaluate the sensitivity and specificity of extracting positive reviews. Any review that obtained the score of 4 or 5 was considered positive. Obviously, the sentiment assessment with the <code>review_score</code> variable obtains sensitivity and specificity of 1, as this is our benchmark.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p48"> &#13;
   <p>The results shown in table 6.2 indicate that both the basic keyword analysis and the method utilizing the ChatGPT 4 API exhibit very high specificity, exceeding 0.9. This means that both approaches seldom misclassify negative or neutral reviews as positive. Furthermore, ChatGPT 4 demonstrates significantly higher sensitivity (0.74), capturing many positive reviews that the basic keyword search missed. In the previous chapter, our attempts to improve the sensitivity of extracting positive reviews achieved limited success. Despite adopting more advanced techniques for cleaning the reviews, applying lemmatization, and using predefined dictionaries for Portuguese sentiment analysis, we only managed to enhance sensitivity by a few percentage points. However, by leveraging ChatGPT 4 to determine the sentiment of the reviews, we succeeded in increasing sensitivity by over 20%! This significant improvement was achieved even with the most basic interpretation of the model’s responses, marking a substantial and unequivocal advancement, albeit at a cost. Given that the ChatGPT API charges based on token usage, analyzing a large volume of real data—not just 500 sample reviews but thousands—could pose a financial challenge, prompting the question of its cost-effectiveness. While I appreciate the simplicity and effectiveness of this method, it may be too early to request additional funding from your finance department.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p49"> &#13;
   <p>At this juncture, it’s crucial to recognize that when ChatGPT is queried about sentiment analysis or any similar task that it is inherently capable of performing due to its ability to “read” with comprehension, its typical advice often revolves around guiding you to write specific code to accomplish the task at hand. The model may highlight the advantages of traditional NLP methods, emphasizing their capacity for analyzing nuanced and specific data among other benefits. In practice, however, most data encountered is relatively standard and predominantly in English, which—as demonstrated—can be quickly and efficiently analyzed by generative AI. The principal drawback of such analysis is the time and cost involved, in addition to limited control over the tool, which could be modified or updated at any time by an external party. </p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p50"> &#13;
   <p>A common criticism of generative AIs is their “black box” nature, offering limited transparency in how responses are generated and on what basis. This argument is valid when comparing the performance of generative AIs to basic NLP tools like keyword searches. However, it becomes less convincing once we begin to use a trained language model of any size. Nevertheless, could it be that generative AIs, with their advanced “reading” capabilities, represent the best option for tackling NLP tasks? A year ago (before API access to ChatGPT 4 was available), we conducted a similar test using earlier OpenAI models, and the outcomes were unimpressive. We had a preference for conventional NLP methodologies. However, with the advancements in generative AI technology, our certainty on this matter has waned.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p51"> &#13;
   <p>With that said, let’s proceed to explore sentiment analysis using traditional and well-established machine learning methods. In the next section, we will examine whether, with the help of pretrained models, we can achieve results as compelling as those provided by the ChatGPT 4 API.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p52"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_96"><span class="num-string">6.2.4</span> Sentiment analysis with machine learning</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p53"> &#13;
   <p>Previously, you learned how to conduct the simplest forms of sentiment analysis using methods such as frequency analysis, keyword searches, or dictionary-based approaches. While mastering these foundational techniques remains crucial, particularly for less commonly studied languages, the reality is that for the majority of everyday tasks, more sophisticated methods, such as machine learning, are preferred. </p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p54"> &#13;
   <p>Machine learning has been around for some time now and should not intimidate anyone who dares to call themselves a data analyst. The era when proficiency in Excel sufficed is behind us; today, teaching your computer to recognize patterns has become a routine task. Thankfully, with the advent of new technologies, libraries, pipelines, and models, effective utilization has become significantly more accessible than in the past. While gaining an understanding of the underlying mechanics, such as matrix multiplication, is beneficial, and we encourage delving into these concepts, a deep technical grasp is no longer a prerequisite for using these models effectively. This situation is analogous to driving a car: knowing how the engine works isn’t necessary to be a competent driver, but in certain scenarios, such knowledge could help you avoid accidents or prevent you from being robbed by your car mechanic. And by no means do you have to construct the car in order to drive it! Most people acquire vehicles through purchase and sale transactions. Pretrained machine learning models are even more accessible, with many available online for free.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p55"> &#13;
   <h4 class="readable-text-h4 sigil_not_in_toc">Where can I find my model?</h4> &#13;
  </div> &#13;
  <div class="readable-text" id="p56"> &#13;
   <p>So, what are your options when searching for a new, shiny, fast, safe, and collision-free model? As always, you could resort to a good old-fashioned web browser, or save yourself some time by discussing your requirements with the generative AI of your choice (Gemini is recommended for reasons mentioned earlier). However, it’s likely that all these efforts will, in any case, direct you to the Hugging Face website (<a href="https://huggingface.co/">https://huggingface.co/</a>).</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p57"> &#13;
   <p>The Hugging Face website serves as a central hub for AI practitioners, offering access to a wealth of resources tailored to NLP and machine learning. At its core is the Model Hub, where users can explore and download a wide array of pretrained models suitable for various NLP tasks, such as sentiment analysis, text generation, and language translation. The website also features comprehensive documentation and tutorials to assist developers in implementing these models in their projects. Additionally, the Hugging Face platform encourages community engagement, allowing users to share their own models and collaborate with others.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p58"> &#13;
   <p>While Hugging Face models are powerful tools for advancing NLP tasks, you should proceed with caution. Concerns have been raised regarding the potential for some models to harbor vulnerabilities or malicious code. Although the platform conducts malware scans on uploaded content and actively works to remove any malicious code, the arms race in cybersecurity is ongoing. Malicious actors continuously seek new security loopholes to exploit. To avoid becoming an unwitting victim in this cyber conflict, it’s crucial to proactively safeguard your security. The following list of ten security commandments is applicable not only to Hugging Face models but to any model (or software) downloaded from the web:</p> &#13;
  </div> &#13;
  <ol> &#13;
   <li class="readable-text" id="p59"> <em>Use verified models</em><em> </em>—Prefer models verified by the platform or those from reputable and known organizations. </li> &#13;
   <li class="readable-text" id="p60"> <em>Review model documentation</em><em> </em>—Carefully read the model’s documentation for potential red flags. </li> &#13;
   <li class="readable-text" id="p61"> <em>Check contributor reputation</em><em> </em>—Research the model’s contributors to ensure they are trustworthy. </li> &#13;
   <li class="readable-text" id="p62"> <em>Conduct security assessments</em><em> </em>—Use security tools to scan for vulnerabilities or malicious code within the model. </li> &#13;
   <li class="readable-text" id="p63"> <em>Isolate testing</em><em> </em>—Test new models in a safe, isolated environment away from sensitive data or systems. </li> &#13;
   <li class="readable-text" id="p64"> <em>Follow community feedback</em><em> </em>—Pay attention to the community feedback and reports about specific models or contributors. </li> &#13;
   <li class="readable-text" id="p65"> <em>Update regularly</em><em> </em>—Keep your models and their dependencies up to date to ensure you have the latest security patches. </li> &#13;
   <li class="readable-text" id="p66"> <em>Limit permissions</em><em> </em>—When integrating models into your systems, grant them the least privileges necessary to perform their function. </li> &#13;
   <li class="readable-text" id="p67"> <em>Use encryption</em><em> </em>—Encrypt sensitive data to protect it in case of accidental exposure by a malicious model. </li> &#13;
   <li class="readable-text" id="p68"> <em>Stay informed</em><em> </em>—Regularly follow updates and security advice from Hugging Face and the broader AI community. </li> &#13;
  </ol> &#13;
  <div class="readable-text" id="p69"> &#13;
   <p>Another popular option for finding an applicable model is GitHub (https://github.com/). This vast repository hosts a multitude of pretrained models shared by developers and researchers from around the world. While GitHub offers an extensive range of models for various tasks, you should approach it with the same caution advised for Hugging Face models. The open nature of GitHub means that anyone can upload code, which could potentially include vulnerabilities or malicious content. These ten commandments serve as a guide to achieving maximum security.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p70"> &#13;
   <h4 class="readable-text-h4 sigil_not_in_toc">What if the model I need does not exist?</h4> &#13;
  </div> &#13;
  <div class="readable-text" id="p71"> &#13;
   <p>So much for theory, but real life is much more challenging. What should you do if the new, shiny, fast, safe, and collision-free model of your dreams doesn’t exist? Let’s revisit our example. If our reviews were written in standard English, finding a relevant pretrained model to perform sentiment analysis would be straightforward. However, the fact that our input is in Portuguese presents us with an opportunity to explore additional options.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p72"> &#13;
   <p>What alternatives do we have for conducting the desired analysis, especially when dealing with less commonly used languages? What if our task is really fancy, like assessing how politically correct a joke is? Or what if we combine the two, and are dealing with the task of assessing the political correctness of a joke written in Korean, say, in its northern dialect? (Before you go any further, we recommend consulting your favorite generative AI about the potential implications of developing such a model and considering whether you really should get involved.)</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p73"> &#13;
   <p>Here are some options:</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p74"> <em>Search for a suboptimal model</em><em> </em>—This should be your starting point, no matter how uncommon your task or language is. It’s always worth checking whether someone has already tackled a similar, but maybe not identical, challenge. Why reinvent the wheel? Explore resources like the Hugging Face Model Hub and GitHub, use a web browser, or enlist generative AI to assist in your search. While you might not be completely satisfied with any existing models you find, they can provide valuable benchmarks for comparing your further efforts. &#13;
  <div class="readable-text list-body-item" id="p75"> &#13;
   <p class="readable-text list-body-item">Pros of this approach include time efficiency, as it saves you from starting absolutely from scratch. Additionally, it offers an opportunity for learning and improvement by analyzing existing models. However, cons might include the challenge of finding a perfect match for your specific needs, limitations in model performance or adaptability, and the risk of depending on a model that may not be actively maintained or updated.</p> &#13;
  </div> </li> &#13;
  </ul> &#13;
  <ul> &#13;
   <li class="readable-text" id="p76"> <em>Translating input to English</em><em> </em>—This is a practical approach for conducting NLP tasks on less common languages, leveraging automatic translation tools and applying English-trained models. This method benefits from the extensive availability and sophistication of models for English, enhancing the potential for accurate analysis. However, it carries the risk of losing nuances and cultural context, possibly introducing errors or biases due to translation imperfections. Generative AIs can mitigate some of these challenges by providing more accurate translations and preprocessing the text to align better with English-trained models, thus preserving more original meaning and reducing translation-related inaccuracies. </li> &#13;
   <li class="readable-text" id="p77"> <em>Use multilingual models</em><em> </em>—If you can’t find a model fine-tuned specifically for your task and language, another effective approach is to use multilingual models such as XLM-RoBERTa or Multilingual BERT. These models are trained on vast datasets covering a wide array of languages, enabling them to understand and process multiple languages simultaneously without the need for language-specific training. This approach makes them highly versatile and an effective solution when a task-specific, language-specific model is unavailable. The primary advantage of using multilingual models lies in their broad applicability, saving the effort of developing or finding models tailored to each language, and offering respectable performance across various NLP tasks. However, these models may not match the performance of specialized models in certain tasks or languages due to their generalized nature. Additionally, customizing them for highly specific or nuanced tasks can be complex. </li> &#13;
   <li class="readable-text" id="p78"> <em>Utilize zero-shot learning models</em><em> </em>—These models, which are trained to understand instructions in natural language, excel at generalizing to tasks they haven’t been explicitly trained on by leveraging semantic knowledge and relationships between concepts. This allows them to infer, for example, the sentiment of texts in categories or contexts they’ve never directly encountered, based on understanding gained from related tasks. However, while zero-shot learning models provide the flexibility to tackle a wide range of tasks with a single model, their performance might not always match that of models fine-tuned on specific tasks, especially in highly nuanced or domain-specific contexts. </li> &#13;
   <li class="readable-text" id="p79"> <em>Fine-tune an existing model</em><em> </em>—This is a practical option when resources for data collection are limited, allowing you to enhance a pretrained model with task-specific adjustments. This method is time-efficient, cost-effective, and it lowers the barrier to advanced modeling techniques. However, it depends on the pretrained model’s relevance to your task and the quality of labeled data used for fine-tuning. There’s also a risk of overfitting if adjustments aren’t made correctly. &#13;
  <div class="readable-text list-body-item" id="p80"> &#13;
   <p>For NLP tasks, you might consider fine-tuning one of the existing LLMs, such as the widely recognized BERT, available on the Hugging Face platform. Such LLMs have been pretrained on extensive text corpora and possess a comprehensive understanding of language, which can be further tailored to specific NLP tasks using a comparatively smaller dataset. This can reduce the amount of effort and expertise needed, though computational resources and understanding of model behavior are still required.</p> &#13;
  </div> &#13;
  <div class="readable-text list-body-item" id="p81"> &#13;
   <p>As usual, generative AI can significantly facilitate this process by offering their assistance and expertise. But in this case, they can offer even more. As all generative AIs discussed in this book are LLMs themselves, they can serve as a linguistic foundation for the model you are developing. In other words, you can fine-tune generative AI to your specific task! </p> &#13;
  </div> </li> &#13;
  </ul> &#13;
  <ul> &#13;
   <li class="readable-text" id="p82"> <em>Train your own model</em><em> </em>—This option involves collecting a sufficient amount of labeled data and training the model yourself. This approach allows for customizing and optimizing the model to fit the specific nuances of your dataset and task. The main advantage is the potential for high accuracy and relevance to your particular use case, as the model learns directly from data reflective of your domain. However, the drawbacks include the significant time, effort, and expertise required to gather labeled data and design and effectively train the model. These challenges persist regardless of the assistance provided by generative AI. Additionally, this method demands substantial computational resources. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p83"> &#13;
   <p>Let’s test a few of these options and compare their results. Fine-tuning an existing model and training one from scratch demands greater expertise and falls beyond this book’s scope. However, should you opt for this route, generative AI can offer significant assistance by providing guidance, resources, and tools tailored to your needs. Additionally, you can refer to <em>Build a Large Language Model (From Scratch)</em> by Sebastian Raschka (Manning, 2024) for further instructions and insights into navigating these advanced techniques.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p84"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_97"><span class="num-string">6.2.5</span> Sentiment analysis with a suboptimal model</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p85"> &#13;
   <p>To try out the first option, searching for a suboptimal model, you could start by searching for an existing sentiment classifier for Portuguese, but this attempt proved unsuccessful (as of March 2024). Consultations with ChatGPT 4 and Gemini Advanced yielded some suggestions, but none fully met our requirements, and many of the provided links were invalid. Both generative AIs eventually advised manually scouring the Hugging Face website and GitHub for suitable models, a task that unfortunately led to no significant findings. </p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p86"> &#13;
   <p>Consequently, you could opt for a less-than-ideal solution suggested by Gemini—the FinBERT-PT-BR classifier, which was trained on Portuguese financial news. Despite this not being the ideal dataset for analyzing customer reviews, a human-in-the-loop approach and error monitoring might help you identify and address the model’s shortcomings. All in all, it might be useful to proceed with this model anyway and assess its efficacy.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p87"> &#13;
   <p>First, let’s become fully aware of the potential drawbacks of this approach. To achieve this, you could start by asking ChatGPT the following question:</p> &#13;
  </div> &#13;
  <div class="readable-text prompt" id="p88"> &#13;
   <p><strong class="prompt-head-image"><img alt="image" height="67px" src="../Images/Init-MA.png" width="66px"/></strong><strong><span class="aframe-location"/></strong>I have a dataframe with a column <code>review_comment_message</code> containing customer reviews in Portuguese. I want to extract positive reviews using a sentiment classifier found on this website: <a href="https://huggingface.co/lucas-leme/FinBERT-PT-BR">https://huggingface.co/lucas-leme/FinBERT-PT-BR</a></p> &#13;
  </div> &#13;
  <div class="readable-text prompt" id="p89"> &#13;
   <p>What are the potential drawbacks of using this model for my task?</p> &#13;
  </div> &#13;
  <div class="readable-text response" id="p90"> &#13;
   <p><strong class="response-head-image"><img alt="image" height="60px" src="../Images/Response.png" width="59px"/></strong><strong><span class="aframe-location"/></strong>[...] Potential Drawbacks:</p> &#13;
  </div> &#13;
  <ol class="response"> &#13;
   <li class="readable-text" id="p91"> Domain Mismatch: FinBERT-PT-BR is specialized for financial contexts, which might not align well with general customer reviews. </li> &#13;
   <li class="readable-text" id="p92"> Sentiment Analysis Complexity: The model may struggle with nuances like sarcasm or cultural expressions, affecting accuracy. </li> &#13;
   <li class="readable-text" id="p93"> Language Specificity: Regional variations in Portuguese could lead to inconsistent performance across different Portuguese-speaking regions. </li> &#13;
   <li class="readable-text" id="p94"> Model Biases: Pretrained models carry inherent biases and limitations from their training data, potentially skewing results. </li> &#13;
   <li class="readable-text" id="p95"> Computational Demands: Processing a large volume of reviews with a transformer-based model requires substantial computing resources. </li> &#13;
   <li class="readable-text" id="p96"> Ethical Considerations: Ensuring ethical and privacy-respecting use of customer reviews is crucial. </li> &#13;
  </ol> &#13;
  <div class="readable-text response" id="p97"> &#13;
   <p>In short, while FinBERT-PT-BR offers an intriguing solution, its financial focus, potential language and regional limitations, computational demands, and the need for ethical diligence present notable challenges for extracting positive reviews from a general customer feedback dataset.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p98"> &#13;
   <p>This conversation illustrates the potential benefits of discussing your analytical ideas with generative AI. Notably, ChatGPT was able to offer insightful comments on a resource it was previously unfamiliar with. Moreover, ChatGPT asserted that it didn’t use the provided link to further investigate the model’s website for additional information. This prompts the question: how did it know? The explanation given upon inquiry was remarkable:</p> &#13;
  </div> &#13;
  <div class="readable-text response" id="p99"> &#13;
   <p>You caught me in a bit of an overextension based on the name “FinBERT-PT-BR,” inferring from the “Fin” prefix, which commonly denotes finance-related models (like FinBERT being a well-known adaptation of BERT for financial texts). The assumption was that this model, given its name, is specialized for analyzing financial text in Portuguese. Such naming conventions are typical for domain-specific versions of BERT and other language models, where the prefix or suffix indicates the model’s specialized training corpus or intended application area. However, without directly accessing the provided link or having specific knowledge of this model in my training data up to my last update in April 2023, I relied on these conventions to inform my response.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p100"> &#13;
   <p>If this isn’t a demonstration of pure intelligence, then I’m not sure what is. However, even if you don’t share my sense of wonder, it should be clear by now that consulting advanced generative AIs like ChatGPT 4 when planning your research is far from a waste of time.</p> &#13;
  </div> &#13;
  <div class="callout-container sidebar-container"> &#13;
   <div class="readable-text" id="p101"> &#13;
    <h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Generative AI interprets external resources</h5> &#13;
   </div> &#13;
   <div class="readable-text" id="p102"> &#13;
    <p>It could be advantageous to inquire with generative AI whether using a specific external resource (such as a model, database, etc.) for your research is reasonable, or to discuss potential drawbacks associated with a particular resource. Even if the generative AI is encountering the resource for the first time, there’s a possibility it can deduce the resource’s contents and how it might influence your analysis.</p> &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p103"> &#13;
   <p>Let’s ask our generative AI to prepare a code snippet. We used the following prompt in the same ChatGPT session: “Propose a code snippet to utilize this model to extract positive reviews from my data.” The obtained snippet is shown in the following listing.</p> &#13;
  </div> &#13;
  <div class="browsable-container listing-container" id="p104"> &#13;
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 6.2</span> Extracting positive reviews with the help of a suboptimal model</h5> &#13;
   <div class="code-area-container code-area-with-html"> &#13;
    <pre class="code-area">import pandas as pd&#13;
from transformers import pipeline&#13;
&#13;
<em># Assuming df is your DataFrame and it has a column named </em>&#13;
<span class="">↪</span><em>'review_comment_message'</em>&#13;
<em># Load the sentiment analysis pipeline with the FinBERT-PT-BR model</em>&#13;
classifier = pipeline("sentiment-analysis", &#13;
<span class="">↪</span>model="lucas-leme/FinBERT-PT-BR")&#13;
def get_sentiment(review):&#13;
    try:&#13;
        result = classifier(review)[0]&#13;
        return result['label'], result['score']&#13;
    except Exception as e:&#13;
        print(f"Error processing review: {e}")&#13;
        return None, None&#13;
<em># Apply the sentiment analysis to each review</em>&#13;
df['sentiment'], df['score'] = &#13;
<span class="">↪</span>zip(*df['review_comment_message'].map(get_sentiment))&#13;
<em># Filter the DataFrame to only include positive reviews</em>&#13;
positive_reviews_df = df[df['sentiment'] == 'LABEL_1']  <em> </em>&#13;
<em># Assuming 'LABEL_1' is positive; adjust label as necessary based on model</em>&#13;
<em><span class="">↪</span>output</em>&#13;
<em># Now positive_reviews_df contains only the positive reviews</em></pre>  &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p105"> &#13;
   <p>This snippet was provided alongside instructions on how to install the required libraries and a detailed comment emphasizing the importance of consulting the model’s documentation to understand the model’s output. Specifically, it was necessary to manually replace <code>LABEL_1</code> with an appropriate label indicating positive reviews, in our case, <code>POSITIVE</code>. Generative AI also detailed the use of exception handling around the classifier to manage any potential errors during processing, such as inputs that were too long or unexpected.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p106"> &#13;
   <p>In the Jupyter notebook from the book’s GitHub repository, you can find this code manually adapted and applied to analyze the first 500 reviews from our testing dataset. As before, the <code>review_score</code> variable was employed to evaluate the sensitivity and specificity of the classifier. The FinBERT-PT-BR model recognized positive reviews with a sensitivity of 0.56 and a specificity of 0.93. This performance surpasses simple keyword-based classification, yet it does not reach the efficacy of the results achieved through direct application of ChatGPT 4’s language capabilities.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p107"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_98"><span class="num-string">6.2.6</span> Sentiment analysis on translated inputs</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p108"> &#13;
   <p>Now you may want to explore whether translating the input and employing a sentiment classifier for English texts could produce better results. The pros and cons of such a solution were listed in section 6.2.4, so let’s jump to implementation right away.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p109"> &#13;
   <p>We began with a specific prompt: “Write a code snippet to extract positive reviews from our dataset. Clean the reviews and translate them to English and then apply the most appropriate sentiment classifier for English.” Then we explored several options to identify the best method for translating the input, aiming for a simple and reliable solution that doesn’t require registration or payment. Ultimately, with generative AI’s help, we developed the following code snippet.</p> &#13;
  </div> &#13;
  <div class="browsable-container listing-container" id="p110"> &#13;
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 6.3</span> Sentiment analysis on translated inputs</h5> &#13;
   <div class="code-area-container code-area-with-html"> &#13;
    <pre class="code-area">import pandas as pd&#13;
from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, &#13;
<span class="">↪</span>pipeline&#13;
[...]&#13;
<em># Initialize the M2M100 tokenizer and model for translation</em>&#13;
tokenizer = M2M100Tokenizer.from_pretrained("facebook/m2m100_418M")&#13;
model = &#13;
<span class="">↪</span>M2M100ForConditionalGeneration.from_pretrained("facebook/m2m100_418M")&#13;
<em># Initialize the sentiment analysis pipeline</em>&#13;
sentiment_pipeline = pipeline('sentiment-analysis', &#13;
<span class="">↪</span>model='distilbert-base-uncased-finetuned-sst-2-english'&#13;
)&#13;
def translate_review(review):&#13;
<em>    # Specify the source and target language</em>&#13;
    tokenizer.src_lang = "pt"&#13;
    encoded_pt = tokenizer(review, return_tensors="pt")&#13;
    generated_tokens = model.generate(**encoded_pt, &#13;
    <span class="">↪</span>forced_bos_token_id=tokenizer.get_lang_id("en"))&#13;
    translated_review = tokenizer.decode(generated_tokens[0], &#13;
    <span class="">↪</span>skip_special_tokens=True)&#13;
    return translated_review&#13;
def analyze_sentiment(review):&#13;
    result = sentiment_pipeline(review)[0]&#13;
    return result['label'], result['score']&#13;
<em># Translate reviews from Portuguese to English</em>&#13;
df['translated_review'] = &#13;
<span class="">↪</span>df['review_comment_message'].apply(translate_review)&#13;
<em># Apply sentiment analysis to the translated reviews</em>&#13;
df['sentiment'], df['score'] = &#13;
<span class="">↪</span>zip(*df['translated_review'].apply(analyze_sentiment))&#13;
<em># Filter the DataFrame to only include reviews with positive sentiment</em>&#13;
positive_reviews_df = df[df['sentiment'] == 'POSITIVE']&#13;
<em># positive_reviews_df now contains only the positive reviews, translated </em>&#13;
<span class="">↪</span><em>into English</em></pre>  &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p111"> &#13;
   <p>The code employs the Meta model for translation, m2m100_418M, which supports multiple languages, including Portuguese and English. For sentiment analysis, it uses the distilbert-base-uncased-finetuned-sst-2-english model. Both models were recommended by generative AI for their broad applicability and performance. However, it was noted that we might consider exploring other models better tailored to our specific requirements.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p112"> &#13;
   <p>While the code executes smoothly, translating 500 reviews took some time, so patience is advised if you plan to replicate this process. Using the <code>review_score</code> variable, we again evaluated the sensitivity and specificity of this method for identifying positive reviews. The corresponding code can be found in the Jupyter notebook in the book’s GitHub repository. Remarkably, this approach of translating input achieved a sensitivity of 0.86 and specificity of 0.89 for correctly classifying positive reviews, offering the best results thus far and proving comparable to those obtained using ChatGPT 4’s inherent language capabilities. Not bad, indeed.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p113"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_99"><span class="num-string">6.2.7</span> Sentiment analysis with multilingual models</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p114"> &#13;
   <p>Our next step is to explore whether using multilingual models for sentiment analysis could yield better results. The characteristics of such models, together with their potential drawbacks, were presented in section 6.2.4, so let’s proceed with the implementation.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p115"> &#13;
   <p>We used the prompt, “Now, I want to repeat this exercise but instead of translating the input, I’d rather use a multilingual model. Could you write a relevant code snippet for me?” Unfortunately, the obtained code didn’t work immediately, due to package dependency issues. Rather than manually resolving these issues or meticulously reviewing the entire error log, we simply copied the last few lines of the error message into the generative AI chat window for assistance. ChatGPT clarified the issue in plain English—far more helpful than the typical technical jargon found in error messages—and suggested two solutions: either downgrading one package or upgrading another, which promptly resolved the issue.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p116"> &#13;
   <p>As you progress through this book, you may encounter similar situations where packages evolve, and today’s code becomes deprecated tomorrow. Often, the solution involves minor adjustments, which could take mere seconds to implement but hours to figure out. With generative AI, you can move past endlessly scrolling through Stack Overflow for debugging tips.</p> &#13;
  </div> &#13;
  <div class="callout-container sidebar-container"> &#13;
   <div class="readable-text" id="p117"> &#13;
    <h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Generative AI is the ultimate tool for bug extermination</h5> &#13;
   </div> &#13;
   <div class="readable-text" id="p118"> &#13;
    <p>Imagine the most deadly and ruthless bug spray. Multiply its effectiveness by a thousandfold, and you’re still not capturing the full extent of how adept generative AI is at tackling bugs! Instead of attempting to decode the error message yourself, simply paste it (or a fragment) into the model’s chat and request a translation into human language along with appropriate solutions. In the majority of instances, you’ll receive a swift and satisfactory response.</p> &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p119"> &#13;
   <p>After smashing all the dependency bugs and correcting the output labels manually, we obtained the following working piece of code (don’t forget to install the required libraries).</p> &#13;
  </div> &#13;
  <div class="browsable-container listing-container" id="p120"> &#13;
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 6.4</span> Sentiment analysis with a multilingual model</h5> &#13;
   <div class="code-area-container code-area-with-html"> &#13;
    <pre class="code-area">import pandas as pd&#13;
from transformers import pipeline&#13;
<em># Assuming df is your DataFrame and it has a column named </em>&#13;
<span class="">↪</span><em>'review_comment_message'</em>&#13;
<em># Initialize the sentiment analysis pipeline with the multilingual model</em>&#13;
sentiment_pipeline = pipeline('sentiment-analysis', &#13;
<span class="">↪</span>model='cardiffnlp/twitter-xlm-roberta-base-sentiment')&#13;
def analyze_sentiment_multilingual(text):&#13;
    result = sentiment_pipeline(text)[0]&#13;
    return result['label'], result['score']&#13;
<em># Apply sentiment analysis to the reviews</em>&#13;
df['sentiment'], df['score'] = &#13;
<span class="">↪</span>zip(*df['review_comment_message'].apply(analyze_sentiment_multilingual))&#13;
<em># Filter the DataFrame to only include positive reviews</em>&#13;
positive_reviews_df = df[df['sentiment'] == 'positive']&#13;
<em># positive_reviews_df now contains only the reviews classified as positive</em></pre>  &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p121"> &#13;
   <p>This script leverages the twitter-xlm-roberta-base-sentiment model to directly classify the sentiment of each review in the dataset, eliminating the need to translate them into English first. It achieves a sensitivity of 0.79 and specificity of 0.93, which are scores comparable to those achieved using ChatGPT 4’s innate language capabilities. This discovery suggests we’ve found a solution of similar quality that is both more cost-effective and faster than utilizing the generative AI API. However, before you rush to request a raise from your boss, let’s explore if we can surpass this performance by utilizing a zero-shot learning model.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p122"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_100"><span class="num-string">6.2.8</span> Sentiment analysis with zero-shot learning models</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p123"> &#13;
   <p>As a reminder, zero-shot learning models are particularly well-suited for tasks where labeled training data is scarce or unavailable. These models can generalize to tasks they haven’t been explicitly trained on, making them ideal for classifying text into categories (such as sentiment analysis) without needing a dataset specific to that task. For extracting positive reviews from our dataset in Portuguese using a zero-shot learning approach, you can leverage models designed for multilingual understanding, such as those available through the Hugging Face Transformers library.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p124"> &#13;
   <p>All this, and much more, you will learn when you ask generative AI a question similar to this one: “I want to extract positive reviews from my dataset with help of a zero-shot learning model. Reviews are in Portuguese. How do I achieve this?” In response, ChatGPT 4 generated the following code, which was adapted to our input data manually. To run the code, you will have to install the transformers library with the command <code>pip install transformers</code>.</p> &#13;
  </div> &#13;
  <div class="browsable-container listing-container" id="p125"> &#13;
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 6.5</span> Sentiment analysis with a zero-shot learning model</h5> &#13;
   <div class="code-area-container code-area-with-html"> &#13;
    <pre class="code-area">from transformers import pipeline&#13;
import pandas as pd&#13;
<em># Load the zero-shot classification pipeline</em>&#13;
classifier = pipeline("zero-shot-classification", &#13;
<span class="">↪</span>model="facebook/bart-large-mnli")&#13;
<em># Specify the candidate labels</em>&#13;
candidate_labels = ["positive", "negative"]&#13;
<em># Define a function to classify a single review</em>&#13;
def classify_review(review):&#13;
    result = classifier(review, candidate_labels=candidate_labels, &#13;
    <span class="">↪</span>hypothesis_template="This review is {}.", multi_label=False)&#13;
    return result['labels'][0]&#13;
<em># Apply the classification to each review</em>&#13;
df['sentiment'] = df['review_comment_message'].apply(classify_review)&#13;
<em># Filter the DataFrame to only include positive reviews</em>&#13;
positive_reviews_df = df[df['sentiment'] == 'positive']</pre>  &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p126"> &#13;
   <p>The code suggested by generative AI leverages the facebook/bart-large-mnli model, which is equipped to handle multilingual texts and has been trained on a variant of the Multi-Genre Natural Language Inference (MNLI) dataset. This enables the model to conduct zero-shot classification on texts in various languages, including Portuguese. ChatGPT, however, points out that this model serves merely as an example, and we may discover other models that could yield better results for specific datasets. For instance, the typeform/distilbert-base-uncased-mnli model is presented as an alternative that is smaller and faster, though potentially less precise.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p127"> &#13;
   <p>The effectiveness of the zero-shot learning model was evaluated using the <code>review_score</code> variable. The model achieved a sensitivity of 0.87 for identifying positive reviews and a specificity of 0.74. While this performance is marginally inferior to that of a multilingual model, it remains sufficiently robust to warrant considering zero-shot learning models in your analysis.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p128"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_101"><span class="num-string">6.2.9</span> Comparing results of advanced sentiment analysis</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p129"> &#13;
   <p>In the previous sections, we explored several methods for performing sentiment analysis using pretrained machine learning models. Initially, we leveraged ChatGPT 4’s inherent language capabilities to identify positive reviews (section 6.2.3). This approach was followed by employing a suboptimal pretrained model tailored for sentiment analysis in Portuguese financial texts (section 6.2.5). Next, we utilized a sentiment classifier designed for English, applying it to translated inputs (section 6.2.6). To circumvent the errors and biases introduced by translation, we opted for a multilingual model (section 6.2.7) and a zero-shot learning model capable of supporting multiple languages (section 6.2.8). These methodologies were tested on a dataset of 500 non-empty reviews, using the <code>review_score</code> variable to evaluate the sensitivity and specificity of the classifications. All the results are gathered in table 6.3.</p> &#13;
  </div> &#13;
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p130"> &#13;
   <h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 6.3</span> Quality of sentiment analysis with different pretrained models</h5> &#13;
   <table> &#13;
    <thead> &#13;
     <tr> &#13;
      <th> &#13;
       <div>&#13;
         Sentiment analysis ( &#13;
        <em>n</em>=500) &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Number of reviews classified as positive &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Sensitivity &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Specificity &#13;
       </div></th> &#13;
     </tr> &#13;
    </thead> &#13;
    <tbody> &#13;
     <tr> &#13;
      <td>  Reference review score <br/></td> &#13;
      <td>  320 (63%) <br/>  true positives <br/></td> &#13;
      <td>  1 <br/></td> &#13;
      <td>  1 <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Basic keyword search <br/></td> &#13;
      <td>  163 (33%) <br/></td> &#13;
      <td>  0.45 <br/></td> &#13;
      <td>  0.9 <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  ChatGPT 4 API <br/></td> &#13;
      <td>  250 (50%) <br/></td> &#13;
      <td>  0.74 <br/></td> &#13;
      <td>  0.93 <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Suboptimal model <br/></td> &#13;
      <td>  193 (39%) <br/></td> &#13;
      <td>  0.56 <br/></td> &#13;
      <td>  0.93 <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Translated inputs <br/></td> &#13;
      <td>  295 (59%) <br/></td> &#13;
      <td>  0.86 <br/></td> &#13;
      <td>  0.89 <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Multilingual model <br/></td> &#13;
      <td>  265 (53%) <br/></td> &#13;
      <td>  0.79 <br/></td> &#13;
      <td>  0.93 <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Zero-shot learning model <br/></td> &#13;
      <td>  325 (65%) <br/></td> &#13;
      <td>  0.87 <br/></td> &#13;
      <td>  0.74 <br/></td> &#13;
     </tr> &#13;
    </tbody> &#13;
   </table> &#13;
  </div> &#13;
  <div class="readable-text" id="p131"> &#13;
   <p>These results demonstrate that, in our tests, the multilingual model outperformed all others, uniquely surpassing the ChatGPT 4 API. A zero-shot learning model that supports multiple languages achieved results comparable to those of generative AI’s inherent language capabilities. Similarly, the method involving translating the input showed potential for high performance. Conversely, classifications based solely on keyword searches lagged significantly in sensitivity, though a more meticulous selection of keywords could potentially enhance its effectiveness. </p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p132"> &#13;
   <p>Notably, just a year ago, the outcome of such an evaluation would have differed substantially, with ChatGPT 3—then the sole option available via API—failing to match even the basic keyword analysis in performance. Just think what can be achieved if ChatGPT 5 is finally released!</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p133"> &#13;
   <p>To sum up, this section illustrated how to conduct sentiment analysis using a variety of advanced pretrained models. Selecting the appropriate methodology for your data and task may involve testing several options, typically on a smaller subset of data, to determine the most cost-effective strategy that could lead to the long-awaited promotion you’ve been aiming for (just imagine: no more Quantum Fluff disguise on Sundays!). Generative AI can facilitate this process by providing a list of options, discussing their advantages and disadvantages, writing the necessary code snippets to implement them, and then testing and summarizing the results. In certain scenarios, you might choose to directly utilize language capabilities by accessing their APIs or using them as a foundation to fine-tune your own model, although the latter option has not been explored in this book.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p134"> &#13;
   <h2 class="readable-text-h2" id="sigil_toc_id_102"><span class="num-string">6.3</span> Text summarization</h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p135"> &#13;
   <p>In the preceding sections, we successfully classified reviews based on their sentiment. The results obtained may not be entirely satisfactory in terms of efficiency, and additional analysis would be required to enhance the basic methods presented. However, let’s assume that your boss is content with the results and wishes to explore further. The question at hand is, what do customers most often complain about?</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p136"> &#13;
   <p>This task aligns exceptionally well with another NLP method you’re about to explore: text summarization. This technique aims to shorten long documents into more concise versions, maintaining the essential information and presenting it coherently. Utilizing approaches like rule-based methods or machine learning, text summarization enables users to swiftly capture the main concepts and pertinent details from large text collections.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p137"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_103"><span class="num-string">6.3.1</span> How can you benefit from text summarization?</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p138"> &#13;
   <p>You can apply text summarization across a wide range of business scenarios to enhance efficiency, improve understanding, and streamline communication. Here are some examples:</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p139"> <em>Customer support</em><em> </em>—Automatically generating concise summaries of customer inquiries or feedback from emails, chat messages, or social media will facilitate quicker response times. Even if it’s widely anticipated that the feedback will concern complaints about Quantum Fluff, it is valuable to have it quantitatively confirmed. </li> &#13;
   <li class="readable-text" id="p140"> <em>Executive briefings</em><em> </em>—Summarizing key points from lengthy reports, financial analyses, or market research for a quick review by executives and decision-makers can assist your boss and his colleagues in guiding the company toward glory and financial success. If you succeed, you will get your share . . . in the glory. </li> &#13;
   <li class="readable-text" id="p141"> <em>News aggregation</em><em> </em>—Creating short summaries of news articles can benefit not just news aggregation apps or websites but also your company. After all, staying informed about developments in the Quantum Fluff market is a routine task for any fluff manufacturer that values its reputation. </li> &#13;
   <li class="readable-text" id="p142"> <em>Legal document review</em><em> </em>—You think lawyers and other legal professionals fall into ecstasy when reading through their dense legal jargon, don’t you? However, the reality is they would greatly appreciate being relieved of this burden. If you could develop a tool that summarizes legal documents, contracts, or case files, facilitating a quicker grasp of their essential contents, they might just honor you with a monument (which you can add to your pension plan, together with your glory shares gained earlier). </li> &#13;
   <li class="readable-text" id="p143"> <em>Academic research</em><em> </em>—How about academics and researchers? Do they enjoy their scientific jargon? Perhaps, but a tool that summarizes academic papers or journals, enabling quick comprehension of the premise, methodology, results, and conclusions without reading the full text, would likely be valued by students, post-docs, and that part of the research community who is still hoping for tenure. Those, in particular, whose survival depends on reading and publishing swiftly. </li> &#13;
   <li class="readable-text" id="p144"> <em>Medical records summarization</em><em> </em>—Health professionals represent another group that could greatly benefit from quick summaries, for instance of patient histories, lab reports, or clinical findings. This may facilitate faster diagnoses and improve treatment planning. But it’s not just doctors who would benefit—patients would too. Imagine how pleasant and humanizing it would be if your doctor had the time to actually engage in real conversation with you! </li> &#13;
   <li class="readable-text" id="p145"> <em>Meeting minutes</em><em> </em>—Text summarization techniques can streamline recorded discussions or meeting transcripts into concise, actionable summaries, emphasizing key decisions, action items, and discussion points. However, volunteering to develop such a tool carries its risks. What if your program uncovers a widely acknowledged yet unspoken truth within the company: that many of the meetings are, in fact, a sheer waste of time? </li> &#13;
   <li class="readable-text" id="p146"> <em>Email management</em><em> </em>—Do you recall that spaghetti email conversation in your company about which coffee machine should be ordered for the office? Missing a few episodes of this soap opera would no longer be an issue if you had a tool capable of summarizing long email threads. This tool would distill the essence of discussions, decisions, or action items into a concise brief, perhaps starting with “Previously, in the New Coffee Machine saga . . .” </li> &#13;
   <li class="readable-text" id="p147"> <em>Content marketing</em><em> </em>—With the new Quantum Fluff feature to promote, no matter what, your marketing department is working their fingers to the bone. Why not help them by creating a tool that could generate summaries of blog posts, articles, or whitepapers to use in newsletters, social media, or marketing materials, engaging readers and encouraging them to explore the full content? </li> &#13;
   <li class="readable-text" id="p148"> <em>Product reviews analysis</em><em> </em>—Summarizing customer reviews and feedback on products or services may help to quickly identify trends, preferences, and areas of improvement. This objective aligns with what your boss is expecting from you, and in the following sections, we will guide you on how to meet those expectations. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p149"> &#13;
   <p>These examples illustrate how text summarization can be a powerful tool for various industries, helping to save time, reduce information overload, and enhance decision-making processes.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p150"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_104"><span class="num-string">6.3.2</span> How can generative AI help in text summarization?</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p151"> &#13;
   <p>Generative AI offers significant potential in summarizing texts efficiently and effectively. By leveraging its deep understanding of language structure, context, and semantics, generative AI can process large volumes of textual information and condense it into shorter, coherent summaries. This capability is particularly useful for extracting the most important information and presenting it in an easily digestible form, saving you and your coworkers a lot of time and effort.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p152"> &#13;
   <p>Furthermore, generative AI’s advanced natural language processing capabilities allow it to generate two types of summaries:</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p153"> <em>Extractive summaries</em><em> </em>—This approach involves selecting and compiling key phrases or sentences directly from the text to create a summary. For example, it can summarize a news article by extracting the most informative sentences that cover the who, what, when, where, and why. </li> &#13;
   <li class="readable-text" id="p154"> <em>Abstractive summaries</em><em> </em>—These summaries reformulate the original text, often generating new phrases and sentences that weren’t in the initial document, to capture its essence more creatively and fluidly. An example would be condensing a novel’s plot into a brief overview that captures the main themes and plot points without directly quoting the text. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p155"> &#13;
   <p>Both types of summaries can be tailored for a specific level of detail and originality. Moreover, the adaptability of generative AI to different domains and languages makes it a flexible tool for a broad spectrum of applications and industries.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p156"> &#13;
   <p>However, this brilliance does not come without its pitfalls. Most of these were touched upon earlier when we discussed the risks of opting for generative AI over traditional NLP methods. </p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p157"> <em>Cost-effectiveness</em><em> </em>—Deploying generative AI-based solutions at scale can be slow but can quickly escalate in costs. </li> &#13;
   <li class="readable-text" id="p158"> <em>Lack of control</em><em> </em>—Acquiring and maintaining the best-performing generative AI models in-house can be challenging for many companies, causing them to depend on third parties. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p159"> &#13;
   <p>For a more detailed comparison of generative AI and traditional NLP methods for text summarization, with their potential drawbacks and tradeoffs, refer to table 6.4.</p> &#13;
  </div> &#13;
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p160"> &#13;
   <h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 6.4</span> Text summarization: Generative AI vs. traditional NLP methods</h5> &#13;
   <table> &#13;
    <thead> &#13;
     <tr> &#13;
      <th> &#13;
       <div>&#13;
         Factor &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Generative AI &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Traditional NLP methods &#13;
       </div></th> &#13;
     </tr> &#13;
    </thead> &#13;
    <tbody> &#13;
     <tr> &#13;
      <td>  Summary type <br/></td> &#13;
      <td>  Extractive <br/>  <span class="num-string">•</span> When prompted correctly can generate extractive summaries, however it tends to drift toward abstractive summaries <br/>  Abstractive <br/>  <span class="num-string">•</span> Processes the entire document, understands the key points and relationships, and generates a summary that conveys the essential meaning in its own words <br/>  <span class="num-string">•</span> Can rephrase ideas, use synonyms, and change the sentence structure <br/>  <span class="num-string">•</span> Can incorporate the overall sentiment or tone of the original text, or change it on demand according to the needs <br/></td> &#13;
      <td>  Extractive <br/>  <span class="num-string">•</span> Select the most important words and sentences <br/>  <span class="num-string">•</span> Prioritize factual accuracy <br/>  <span class="num-string">•</span> Present the main ideas in a clear and concise way <br/>  Abstractive <br/>  <span class="num-string">•</span> Predefined templates are used to generate summaries <br/>  <span class="num-string">•</span> Typically does not generate entirely new text to create a summary <br/>  <span class="num-string">•</span> May not be able to capture the overall sentiment <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Computational efficiency <br/></td> &#13;
      <td>  Low <br/>  <span class="num-string">•</span> Computationally expensive training and inference <br/></td> &#13;
      <td>  High <br/>  <span class="num-string">•</span> Faster training and inference <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Scalability <br/></td> &#13;
      <td>  Low <br/>  <span class="num-string">•</span> May struggle with long documents <br/>  <span class="num-string">•</span> May require significant resources to process complex summaries <br/>  <span class="num-string">•</span> Using an API is slow and expensive <br/></td> &#13;
      <td>  High <br/>  <span class="num-string">•</span> Scales well with larger datasets <br/>  <span class="num-string">•</span> Relatively low cost of usage <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Interpretability <br/></td> &#13;
      <td>  Low <br/>  <span class="num-string">•</span> Difficult to understand how the model arrives at a summary <br/>  <span class="num-string">•</span> Like a black box <br/></td> &#13;
      <td>  High <br/>  <span class="num-string">•</span> Clear picture of chosen sentences <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Model optimization <br/></td> &#13;
      <td>  Complex <br/>  <span class="num-string">•</span> Requires complex techniques like reinforcement learning to optimize for specific objectives (e.g., factual accuracy, sentiment analysis) <br/>  <span class="num-string">•</span> Prompt engineering may help at setting summary objectives, but it is not fully deterministic and requires monitoring <br/></td> &#13;
      <td>  Simple <br/>  <span class="num-string">•</span> Can be optimized with simpler techniques like sentence scoring functions that prioritize factual keywords or specific emotions <br/></td> &#13;
     </tr> &#13;
    </tbody> &#13;
   </table> &#13;
  </div> &#13;
  <div class="readable-text" id="p161"> &#13;
   <p>With these considerations, you might find yourself compromising on the accuracy, simplicity, and fun that generative AI offers to develop more traditional, albeit potentially more suitable, solutions for your company.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p162"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_105"><span class="num-string">6.3.3</span> Summarizing text with ChatGPT</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p163"> &#13;
   <p>Let’s return to your boss’s inquiry and discover what customers most often complain about. To address this task, you first need to identify negative reviews using one of the methods described in previous sections. For demonstration purposes, we will take a shortcut and use the set of negative reviews determined by the <code>review_score</code> variable, which was previously used to assess the effectiveness of our sentiment analysis. Once the negative reviews are extracted, they will be subjected to text summarization for further insight.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p164"> &#13;
   <p>This is a good opportunity to mention another potential issue with texts such as customer reviews. As globalization spreads, you can expect these texts to appear in dozens of languages. When using traditional NLP methods for summarization, the reviews should first be clustered by language, then translated to a common language (most likely English), and only then be subjected to further analysis. With the polyglot capabilities of generative AI, all these steps can be reduced to a single mention in the prompt, indicating that regardless of the input language, you want the summaries in the language of your choice. How brilliant! With generative AI at hand, we can finally finish building the Tower of Babel and even make some cash by offering it for short-term rent!</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p165"> &#13;
   <p>As a warm-up, let’s see how generative AI can summarize the longest review in our example dataset.</p> &#13;
  </div> &#13;
  <div class="readable-text prompt" id="p166"> &#13;
   <p><strong class="prompt-head-image"><img alt="image" height="67px" src="../Images/Init-MA.png" width="66px"/></strong><strong><span class="aframe-location"/></strong>Summarize this text “NÃO RECEBI O PRODUTO, O PRODUTO CONSTA COMO ENVIADO PARA O CORREIO DE RIBEIRÃO PRETO. O CORREIO NÃO RECEBEU O PRODUTO. ENVIE VARIAS MENSAGEM PARA A targaryen E NÃO OBTIVE. ESTA targaryen ESTA SUJANDO SEU NOME”. Use Portuguese in your summary. Provide English translations for both the original and the summary.</p> &#13;
  </div> &#13;
  <div class="readable-text response" id="p167"> &#13;
   <p><strong class="response-head-image"><img alt="image" height="60px" src="../Images/Response.png" width="59px"/></strong><strong><span class="aframe-location"/></strong>Here’s a summarization of the given text using a simple non-ML approach based on extracting the most frequent words:</p> &#13;
  </div> &#13;
  <div class="readable-text response" id="p168"> &#13;
   <p>[...]</p> &#13;
  </div> &#13;
  <div class="readable-text response" id="p169"> &#13;
   <p>Summary (English translation):</p> &#13;
  </div> &#13;
  <div class="readable-text response" id="p170"> &#13;
   <p>“PRODUCT NOT RECEIVED, POST OFFICE NOT RECEIVED, targaryen NO RESPONSE.”</p> &#13;
  </div> &#13;
  <div class="readable-text response" id="p171"> &#13;
   <p>Please note that this summarization is relatively simple and may not capture all the nuances of the original text. For more accurate and coherent summarization, you can use more advanced techniques like TextRank, or machine learning-based methods.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p172"> &#13;
   <p>This response is fast, easy to obtain, and comprehensive. You can further play with your favorite generative AI and ask it to generate longer or shorter summaries, review titles, and review descriptions written in the style of your favorite author, or you can even ask it to turn your boring reviews into pretty brilliant haikus, like this one:</p> &#13;
  </div> &#13;
  <div class="readable-text response" id="p173"> &#13;
   <p>Product never came,</p> &#13;
  </div> &#13;
  <div class="readable-text response" id="p174"> &#13;
   <p>Messages to targaryen,</p> &#13;
  </div> &#13;
  <div class="readable-text response" id="p175"> &#13;
   <p>Silent, tarnished name.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p176"> &#13;
   <p>Remember the protagonist in Chuck Palahniuk’s <em>Fight Club</em> who fought his office boredom by disseminating haikus to all employees? Armed with your newly gained knowledge, you can now harness generative AI to develop a straightforward application that sends negative feedback back to the unhappy customer in this elegant form. At the very least, they shouldn’t be grumbling about the absence of a response any longer. However, do not expect any praise from your boss after this exercise.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p177"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_106"><span class="num-string">6.3.4</span> Summarizing text with dedicated libraries</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p178"> &#13;
   <p>When selecting NLP summarization techniques, your choice should depend largely on the type and length of the text to be summarized. For extensive texts such as books, abstractive summarization techniques are often more suitable. These methods can generate concise overviews by understanding and paraphrasing key concepts, making them ideal for capturing the essence of lengthy narratives or detailed discussions without needing to quote the original text extensively. For scientific articles or technical documents, a mix of extractive and abstractive methods might be best, pulling out significant sentences or terms (extractive) and then synthesizing those elements into a coherent summary (abstractive) that captures the document’s main findings and implications. Moving to shorter texts, such as news articles or blog posts, extractive summarization can be effective, identifying and compiling the most informative parts directly from the source.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p179"> &#13;
   <p>For short texts such as customer reviews, it may be more beneficial to concentrate on extracting main keywords or topics rather than creating summaries. Sentiment analysis, coupled with keyword extraction, often provides sufficient insight. In fact, given the exercises in the previous sections, you should generally know what to expect from text summarizations of the negative reviews.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p180"> &#13;
   <p>As for the particular methods, text summarization techniques can generally be divided into two categories: rule-based approaches and machine learning approaches. Each offers distinct methods for generating text summaries, with their own strengths and limitations.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p181"> &#13;
   <p>Rule-based approaches rely on predefined linguistic rules and heuristics, such as sentence length, position, and the frequency of key terms, to extract important sentences. While straightforward and interpretable, these approaches can be rigid and may fail to adapt to the nuances of different texts. Here are a couple of the most common rule-based methods for generating extractive summarizations:</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p182"> <em>Sentence scoring and extraction</em><em> </em>—This method scores sentences based on predefined criteria, such as the position of the sentence and the presence of keywords. Term frequency-inverse document frequency (TF-IDF) is often used to score sentences based on the frequency of important terms. The highest-scoring sentences are then combined to form the summary. </li> &#13;
   <li class="readable-text" id="p183"> <em>TextRank</em><em> </em>—A variation of the PageRank algorithm, TextRank represents sentences as nodes in a graph, with edges representing content overlap. The most central sentences are extracted for the summary. </li> &#13;
   <li class="readable-text" id="p184"> <em>Frequency-based methods</em><em> </em>—This approach identifies and extracts key terms, <em>n</em>-grams, or phrases from the text that represent the main topics. These keywords are then used to create a summary. </li> &#13;
   <li class="readable-text" id="p185"> <em>Cue phrase method</em><em> </em>—Utilizes specific cue phrases (e.g., “in summary,” “to conclude”) that often signal important information. Sentences containing these phrases are extracted for the summary. </li> &#13;
   <li class="readable-text" id="p186"> <em>Lead-based summarization</em><em> </em>—Commonly used in news articles, this method involves extracting the initial few sentences or the first paragraph, assuming that text contains the most critical information. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p187"> &#13;
   <p>Rule-based approaches can also be used for abstractive summarization. However, this requires rule-based paraphrasing or predefined templates to generate summaries by filling in slots with relevant information extracted from the text. As you might guess, the output is not as smooth as the abstractive summaries created by generative AI.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p188"> &#13;
   <p>Apart from rule-based approaches, Python offers multiple machine learning techniques to summarize texts: latent semantic analysis (LSA) and latent Dirichlet allocation (LDA) can be used to analyze latent topics, whereas pretrained language models like BERT, text-to-text transfer transformer (T5), and Bidirectional and Auto-Regressive Transformer (BART) can be fine-tuned for specific tasks. Presenting the details of these methods and their capabilities is beyond the scope of this book, not to mention that most of them are designed for other purposes than summarizing texts as short as our reviews. However, with options like the Gensim, scikit-learn, and Hugging Face Transformers libraries, you can select the right technique for your requirements and text type. At the same time, generative AI can assist you and provide advice.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p189"> &#13;
   <p>Let’s now revisit our example. To understand how traditional NLP methods can summarize reviews and to compare them with the straightforward approach presented in section 6.3.3, we will use a simple rule-based technique—a frequency-based approach—to analyze our negative reviews. This method identifies the most common words after removing stopwords, providing a quick insight into the prevalent concerns or keywords within each review. First, we will ask ChatGPT to generate relevant code in Python, using this prompt, “Provide Python code to generate summaries of very short customer reviews in Portuguese. Use a frequency-based approach.” The resulting code, after some adaptations to our input data, can be found in the Jupyter notebook in the book’s GitHub repository.</p> &#13;
  </div> &#13;
  <div class="browsable-container listing-container" id="p190"> &#13;
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 6.6</span> Summarizing the longest review—a frequency-based approach</h5> &#13;
   <div class="code-area-container code-area-with-html"> &#13;
    <pre class="code-area">import pandas as pd&#13;
import nltk&#13;
import string&#13;
from collections import Counter&#13;
<em># Download the required NLTK resources</em>&#13;
nltk.download('punkt')&#13;
nltk.download('stopwords')&#13;
<em># Sample data (manually adapted to remove empty records)</em>&#13;
df = pd.read_csv('olist_order_reviews_dataset.csv')&#13;
df = df.dropna(subset = ['review_comment_message'])&#13;
<em># Function to tokenize and remove stopwords</em>&#13;
def preprocess(text):&#13;
    stopwords = nltk.corpus.stopwords.words('portuguese')&#13;
    tokens = nltk.word_tokenize(text.lower())&#13;
    tokens = [token for token in tokens if token not in string.punctuation &#13;
    <span class="">↪</span>and token not in stopwords]&#13;
    return tokens&#13;
<em># Function to create word frequency distribution</em>&#13;
def word_frequency(tokens):&#13;
    frequency = Counter(tokens)&#13;
    return frequency&#13;
<em># Function to summarize short reviews</em>&#13;
def summarize_reviews(text, num_keywords=3):&#13;
    tokens = preprocess(text)&#13;
    frequency = word_frequency(tokens)&#13;
    important_words = [word for word, count in &#13;
    <span class="">↪</span>frequency.most_common(num_keywords)]&#13;
    summary = ' '.join(important_words)&#13;
    return summary&#13;
<em># Apply the function to the DataFrame</em>&#13;
df['summary'] = df['review_comment_message'].apply(summarize_reviews)&#13;
<em># Display the results (manually adapted to print the summary of the longest </em>&#13;
<span class="">↪</span><em>message)</em>&#13;
print("Longest review:", df.loc[1316]["review_comment_message"])&#13;
print("Summary:", df.loc[1316]["summary"])</pre>  &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p191"> &#13;
   <p>The code proposed by generative AI functions well and can be readily adapted to summarize reviews in the entire dataset. For instance, the three-word summary of the example review from section 6.3.3 is “produto, correio, targaryen” (product, mail, targaryen). In this context, “targaryen,” like all <em>Game of Thrones</em> house names, are our data provider’s means of anonymizing store names.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p192"> &#13;
   <p>You can generate longer and more informative summaries by modifying the <code>num_keywords</code> parameter in the preceding code. However, in our opinion, the output generated with this simple frequency-based approach is not as precise and to the point (and not even as entertaining) as ChatGPT’s haikus. Direct three-word summaries “manually crafted” by generative AI also seem a bit better, although a more rigorous approach would be needed to assess which outcome is truly superior.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p193"> &#13;
   <p>To get a feeling for the results, you can compare the output for the first five reviews, gathered in table 6.5. All translations were provided by ChatGPT.</p> &#13;
  </div> &#13;
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p194"> &#13;
   <h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 6.5</span> Summary efforts on a sample of five customer reviews</h5> &#13;
   <table> &#13;
    <thead> &#13;
     <tr> &#13;
      <th> &#13;
       <div>&#13;
         Translated review &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Three-word summary by frequency-based methods &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         Three-word summary by ChatGPT 4 &#13;
       </div></th> &#13;
      <th> &#13;
       <div>&#13;
         ChatGPT’s haiku &#13;
       </div></th> &#13;
     </tr> &#13;
    </thead> &#13;
    <tbody> &#13;
     <tr> &#13;
      <td>  I received it well before the stipulated deadline. <br/></td> &#13;
      <td>  received <br/>  well <br/>  before <br/></td> &#13;
      <td>  Early delivery <br/></td> &#13;
      <td>  Arrived well before <br/>  Stipulated deadline nears <br/>  Satisfaction found <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Congratulations Lannister stores, I loved shopping online, safe and practical. Congratulations to everyone and happy Easter. <br/></td> &#13;
      <td>  congratulations <br/>  lannister <br/>  stores <br/></td> &#13;
      <td>  Lannister stores praised <br/></td> &#13;
      <td>  Lannister stores cheer <br/>  Safe and practical shopping <br/>  Happy Easter joy <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Efficient device. On the website, the device brand is printed as 3desinfector, and upon arrival, it has another name... Update with the correct brand since it’s the same device. <br/></td> &#13;
      <td>  efficient <br/>  brand <br/>  device <br/></td> &#13;
      <td>  Efficient, mislabeled device <br/></td> &#13;
      <td>  Efficient device <br/>  Misnamed but still performs well <br/>  Update with true brand <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  But a little, lagging... for the price, it’s good. <br/></td> &#13;
      <td>  a bit <br/>  lagging <br/>  ... <br/></td> &#13;
      <td>  Lagging, decent value <br/></td> &#13;
      <td>  Slight lag appears, <br/>  Yet value stands its ground, <br/>  Acceptable deal. <br/></td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td>  Reliable seller, product ok, and delivery before the deadline <br/></td> &#13;
      <td>  reliable <br/>  seller <br/>  product <br/></td> &#13;
      <td>  Reliable seller, prompt <br/></td> &#13;
      <td>  Trustworthy vendor, <br/>  Product meets expectations, <br/>  Early delivery. <br/></td> &#13;
     </tr> &#13;
    </tbody> &#13;
   </table> &#13;
  </div> &#13;
  <div class="callout-container sidebar-container"> &#13;
   <div class="readable-text" id="p195"> &#13;
    <h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Generative AI provides both extractive and abstractive summaries</h5> &#13;
   </div> &#13;
   <div class="readable-text" id="p196"> &#13;
    <p>While generative AI can perform both types of summarizations, its primary strength lies in abstractive summarization, as it has been trained on vast amounts of textual data and is capable of generating human-like coherent summaries.</p> &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p197"> &#13;
   <p>Another concern is that summarizing each negative review individually doesn’t effectively address the task assigned by your boss. Someone still needs to read through all the summaries and draw conclusions from them. To tackle this issue more efficiently, you can employ another method called <em>topic modeling</em>, which helps identify common themes and topics across a collection of documents, such as the negative reviews in this case.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p198"> &#13;
   <h3 class="readable-text-h3" id="sigil_toc_id_107"><span class="num-string">6.3.5</span> Topic modeling</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p199"> &#13;
   <p>Topic modeling is not a form of text summarization per se, but it can be used to generate a high-level summary of the main themes and topics in a collection of documents. While text summarization techniques aim to create condensed versions of individual documents by extracting or generating the most important sentences or phrases, topic modeling techniques are designed to uncover the underlying latent structure and themes within a corpus of texts.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p200"> &#13;
   <p>Topic modeling can help you understand the main topics and their distribution across a set of documents, but it does not generate human-readable summaries of the individual texts. Instead, it represents each document as a mixture of topics, with each topic being a probability distribution over words.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p201"> &#13;
   <p>Our example set of negative customer reviews is an ideal candidate for demonstrating topic modeling, which can summarize them in a convenient, human-readable form. Let’s start by asking ChatGPT for the relevant code, using the prompt, “I have a set of short negative customer reviews in Portuguese stored in a pandas dataframe column. I want to know what are the main concerns raised by customers. How to extract this information from reviews?”</p> &#13;
  </div> &#13;
  <div class="browsable-container listing-container" id="p202"> &#13;
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 6.7</span> Summarizing negative reviews with topic modeling</h5> &#13;
   <div class="code-area-container code-area-with-html"> &#13;
    <pre class="code-area">import pandas as pd&#13;
import nltk&#13;
from nltk.corpus import stopwords&#13;
from nltk.tokenize import word_tokenize&#13;
from nltk.stem import SnowballStemmer&#13;
import re&#13;
<em># Load data. Only negative reviews were chosen for the analysis </em>&#13;
<span class="">↪</span><em>(adapted manually).</em>&#13;
df = pd.read_csv('olist_order_reviews_dataset.csv')&#13;
df = df.dropna(subset = ['review_comment_message'])&#13;
df = df[(df["review_score"]==1) | (df["review_score"]==2)]&#13;
<em># Preprocess the text</em>&#13;
def preprocess_text(text, language='portuguese'):&#13;
<em>    # Remove special characters, convert to lowercase</em>&#13;
    cleaned_text = re.sub(r'[^\w\s]', '', text.lower())&#13;
<em>    # Tokenize words</em>&#13;
    words = word_tokenize(cleaned_text, language=language)&#13;
<em>    # Remove stopwords</em>&#13;
    stop_words = set(stopwords.words(language))&#13;
    words = [word for word in words if word not in stop_words]&#13;
<em>    # Apply stemming</em>&#13;
    stemmer = SnowballStemmer(language)&#13;
    words = [stemmer.stem(word) for word in words]&#13;
    return words&#13;
df['preprocessed_reviews'] = &#13;
<span class="">↪</span>df['review_comment_message'].apply(preprocess_text)&#13;
<em># Loading the model.</em>&#13;
from gensim.corpora import Dictionary&#13;
from gensim.models import LdaModel&#13;
<em># Create a dictionary and corpus for LDA</em>&#13;
dictionary = Dictionary(df['preprocessed_reviews'])&#13;
corpus = [dictionary.doc2bow(text) for text in df['preprocessed_reviews']]&#13;
<em># Train an LDA model</em>&#13;
num_topics = 5  <em># Adjust this value to the desired number of topics</em>&#13;
lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, &#13;
<span class="">↪</span>random_state=42)&#13;
<em># Displaying results (manually adapted to display 7 words).</em>&#13;
def display_topics(model, num_topics, num_words=7):&#13;
    for idx, topic in model.print_topics(num_topics, num_words):&#13;
        print(f"Topic {idx + 1}: {topic}\n")&#13;
display_topics(lda_model, num_topics)</pre>  &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p203"> &#13;
   <p>The proposed code was manually adapted to analyze only negative results from our example dataset (reviews with <code>review_score</code> of 1 or 2). The output is a list of the five most common topics mentioned in the reviews; however, the topics themselves are not presented in a friendly form. Fortunately, we have generative AI at hand to help us read and interpret what, by nature, is not human-readable. In this case, informing the model directly about the negative nature of the input leads to better conclusions.</p> &#13;
  </div> &#13;
  <div class="readable-text prompt" id="p204"> &#13;
   <p><strong class="prompt-head-image"><img alt="image" height="67px" src="../Images/Init-MA.png" width="66px"/></strong><strong><span class="aframe-location"/></strong>Can you interpret this output of topic modeling? Provide English translations. Keep in mind that the input consisted only of negative customer reviews:</p> &#13;
  </div> &#13;
  <div class="browsable-container listing-container" id="p205"> &#13;
   <div class="code-area-container code-area-with-html"> &#13;
    <pre class="code-area">Topic 1: 0.055*"compr" + 0.043*"receb" + 0.032*"produt" + 0.020*"2" + &#13;
<span class="">↪</span>0.019*"entreg" + 0.017*"apen" + 0.017*"ped"&#13;
Topic 2: 0.043*"entreg" + 0.035*"produt" + 0.035*"compr" + &#13;
<span class="">↪</span>0.028*"receb" + 0.021*"agor" + 0.020*"praz" + 0.013*"falt"&#13;
Topic 3: 0.095*"produt" + 0.046*"receb" + 0.021*"entreg" + &#13;
<span class="">↪</span>0.017*"compr" + 0.016*"aind" + 0.016*"vei" + 0.015*"quer"&#13;
Topic 4: 0.070*"produt" + 0.066*"entreg" + 0.040*"cheg" + 0.024*"aind" +&#13;
<span class="">↪</span>0.024*"dia" + 0.023*"praz" + 0.019*"receb"&#13;
Topic 5: 0.052*"produt" + 0.035*"receb" + 0.035*"compr" + 0.032*"vei" + &#13;
<span class="">↪</span>0.017*"nao" + 0.012*"cheg" + 0.011*"entreg"</pre>  &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text response" id="p206"> &#13;
   <p><strong class="response-head-image"><img alt="image" height="60px" src="../Images/Response.png" width="59px"/></strong><strong><span class="aframe-location"/></strong>Here’s the interpretation of the topic modeling output with English translations, considering that the input consisted only of negative customer reviews:</p> &#13;
  </div> &#13;
  <div class="browsable-container listing-container" id="p207"> &#13;
   <div class="code-area-container code-area-with-html"> &#13;
    <pre class="code-area">Topic 1:&#13;
Translation: 0.055*"purchase" + 0.043*"received" + 0.032*"product" + &#13;
<span class="">↪</span>0.020*"2" + 0.019*"delivery" + 0.017*"only" + 0.017*"order"&#13;
Interpretation: Issues with purchase, receiving products, and delivery; &#13;
<span class="">↪</span>possible complaints about incomplete or partially received orders.&#13;
&#13;
Topic 2:&#13;
Translation: 0.043*"delivery" + 0.035*"product" + 0.035*"purchase" + &#13;
<span class="">↪</span>0.028*"received" + 0.021*"now" + 0.020*"deadline" + 0.013*"missing"&#13;
Interpretation: Problems with product delivery, receiving products, and &#13;
<span class="">↪</span>missing items; concerns about meeting deadlines.&#13;
&#13;
Topic 3:&#13;
Translation: 0.095*"product" + 0.046*"received" + 0.021*"delivery" + &#13;
<span class="">↪</span>0.017*"purchase" + 0.016*"still" + 0.016*"came" + 0.015*"want"&#13;
Interpretation: Dissatisfaction with products, delivery, and purchase &#13;
<span class="">↪</span>experience; possible issues with products received or not yet &#13;
<span class="">↪</span>received.&#13;
&#13;
Topic 4:&#13;
Translation: 0.070*"product" + 0.066*"delivery" + 0.040*"arrived" + &#13;
<span class="">↪</span>0.024*"still" + 0.024*"day" + 0.023*"deadline" + 0.019*"received"&#13;
Interpretation: Delivery and arrival of products, with possible delays &#13;
<span class="">↪</span>or dissatisfaction with the time it took to receive them.&#13;
&#13;
Topic 5:&#13;
Translation: 0.052*"product" + 0.035*"received" + 0.035*"purchase" + &#13;
<span class="">↪</span>0.032*"came" + 0.017*"not" + 0.012*"arrived" + 0.011*"delivery"&#13;
Interpretation: Discontent with products, purchases, and deliveries; &#13;
<span class="">↪</span>concerns about items not arriving or not being as expected.</pre>  &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p208"> &#13;
   <p>As demonstrated, generative AI can be very useful when dealing with difficult-to-read output, particular when it is written in a language you are not familiar with. It is evident that generative AI is able to make a nice and plausible story out of extracted keywords. However, in our example, all five of the most common topics were related to the same issue: dissatisfaction with delivery, which is a take-home message for your boss.</p> &#13;
  </div> &#13;
  <div class="callout-container sidebar-container"> &#13;
   <div class="readable-text" id="p209"> &#13;
    <h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Generative AI interprets the output</h5> &#13;
   </div> &#13;
   <div class="readable-text" id="p210"> &#13;
    <p>Generative AI is helpful in extracting the essence of the output of text-mining methods, even if it is presented in a hard-to-read format and a foreign language.</p> &#13;
   </div> &#13;
  </div> &#13;
  <div class="readable-text" id="p211"> &#13;
   <p>To conclude, this section showcased the application of generative AI to identify the most common customer concerns by employing text summarization and topic modeling techniques on the set of customer reviews. In addition, we entertained ourselves by generating a bunch of haikus. This comprehensive approach demonstrates the versatility and utility of generative AI in the realm of natural language processing and text analysis.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p212"> &#13;
   <p>However, while generative AI is a powerful language model that performs well in various NLP tasks, including text summarization, its performance may not always be better than dedicated summarization libraries. The choice between generative AI and dedicated libraries depends on several factors, such as the nature of the text, the desired summary type (extractive or abstractive), and the domain-specific context.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p213"> &#13;
   <p>Dedicated summarization libraries may be optimized for specific tasks and can often provide more control over the summarization process, enabling users to fine-tune the output according to their requirements. Additionally, they may perform better on domain-specific or technical texts.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p214"> &#13;
   <p>On the other hand, generative AI’s strength lies in its ability to generate more coherent and natural-sounding summaries, especially for abstractive summarization. It can be an excellent choice for generating human-like summaries or when the focus is on producing easily comprehensible output.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p215"> &#13;
   <p>In short, there isn’t a one-size-fits-all answer, and the choice between generative AI and dedicated summarization libraries depends on the specific requirements of the task at hand. It is essential to evaluate different approaches and choose the one that best fits your needs.</p> &#13;
  </div> &#13;
  <div class="callout-container sidebar-container"> &#13;
   <div class="readable-text" id="p216"> &#13;
    <h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Things to ask generative AI</h5> &#13;
   </div> &#13;
   <ul> &#13;
    <li class="readable-text" id="p217"> How to perform your_task with the help of your API? </li> &#13;
    <li class="readable-text" id="p218"> What is this bunch of text about? </li> &#13;
    <li class="readable-text" id="p219"> Which NLP method will be the best to summarize my type of data? </li> &#13;
    <li class="readable-text" id="p220"> Can you make this output human-readable? </li> &#13;
   </ul> &#13;
  </div> &#13;
  <div class="readable-text" id="p221"> &#13;
   <h2 class="readable-text-h2" id="sigil_toc_id_108">Summary</h2> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p222"> For complex NLP tasks, certain specialized tools might still surpass the capabilities of the most advanced generative AIs. </li> &#13;
   <li class="readable-text" id="p223"> Even though generative AI might outperform conventional methods for your NLP task, it may not always be cost-effective. </li> &#13;
   <li class="readable-text" id="p224"> Top generative AI models are high-maintenance pets; many companies find it challenging to keep them in-house. To deploy them at an industrial scale, reliance on third-party solutions, such as APIs, is often necessary. </li> &#13;
   <li class="readable-text" id="p225"> The performance of generative AI improves markedly with each version. </li> &#13;
   <li class="readable-text" id="p226"> Just because version <em>n</em> of your preferred generative AI cannot make coffee doesn’t imply that version <em>n</em>+1 won’t be capable of doing so. </li> &#13;
   <li class="readable-text" id="p227"> Generative AI is brilliant when it comes to text summarization and paraphrasing in the given form (prose, poetry, drama, you name it). It provides both extractive and abstractive summaries. </li> &#13;
   <li class="readable-text" id="p228"> Use generative AI to interpret or summarize results—especially ones that are hard to read. </li> &#13;
  </ul>&#13;
 </body></html>