["```py\nserver_params = StdioServerParameters(\n    command=\"python\",  # Executable\n    args=[\"weather_server.py\"],  # Your new weather data server script\n    env=None,  # Optional environment variables\n)\n```", "```py\nasync def handle_sampling_message(message):\n    print(f\"Received weather data: {message}\")\n```", "```py\nasync with stdio_client(server_params) as (read, write):\n    async with ClientSession(\n        read, write, sampling_callback=handle_sampling_message\n    ) as session:\n```", "```py\nawait session.initialize()\n```", "```py\nprompt = await session.get_prompt(\n    \"weather-prompt\", arguments={\"city\": \"Lisbon\"}\n)\n```", "```py\nresources = await session.list_resources()\ntools = await session.list_tools()\n```", "```py\nweather_data = await session.call_tool(\n    \"weather-tool\", arguments={\"city\": \"Lisbon\", \"unit\": \"Celsius\"}\n)\n```", "```py\ncontent, mime_type = await \nsession.read_resource(\n    \"file://weather_reports/lisbon_report.pdf\"\n)\npreview = content[:100]\nprint(f\"Downloaded content preview: \n{preview}...\")\n```", "```py\nprint(f\"Weather data for Lisbon: {weather_data}\")\n```", "```py\nimport asyncio\nasyncio.run(fetch_weather_data())\n```", "```py\nIs the following email spam? Respond with spam if the email is spam or ham if \nthe email is not spam.\n\n[Email contents]\n```", "```py\nWhat is the probability that the email below is spam? Give the answer as a real \nnumber between 0 and 1\\. Your answer should be just the number with your best \nguess of the probability. \n\n[Email contents]\n```", "```py\n{\n  \"model\": \"gpt-4\",\n  \"prompt\": \"Write a poem about machines.\",\n  \"temperature\": 0.7,\n  \"top_p\": 0.9,\n  \"frequency_penalty\": 0.5,\n  \"presence_penalty\": 0.6,\n  \"max_tokens\": 60,\n  \"stop\": [\"\\n\\n\"]\n}\n```", "```py\nAbi, \n\nI just wanted to reach out and update you. We will have the components delivered\nby Friday. As soon as I confirm I will schedule with you all. The government \npermits should come in approximately two more weeks. \n```", "```py\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n# Simulate two distributions of model scores with a random seed\nnp.random.seed(42)\nchampion_scores = np.random.normal(loc=0.78, scale=0.02, size=100)\nchallenger_scores = np.random.normal(loc=0.80, scale=0.02, size=100)\n# Plot the distributions\nplot.figure(figsize=(10,6))\nsns.kdeplot(champion_scores, label=\"Champion Model\", color = \"blue\")\nsns.kdeplot(challenger_scores, label=\"Challenger Model\", color = \"red\")\nplt.title(\"Distributions of Model Performance Scores\")\nplt.xlabel(\"Score\")\nplt.ylabel(\"Density\")\nplt.legend()\nplt.grid(True)\nplt.show()\n```", "```py\nIs the following email spam? Respond with spam if the email is spam or ham if \nthe email is not spam. \n\n[Email contents]\n```", "```py\nYes, this email is spam.\n\nNot spam.\n\nI'm not sure.\n\nI'm sorry, but as an AI language model, I must follow ethical guidelines, and I \ncannot engage in harmful, malicious, or offensive behavior.\n```", "```py\nIs the following email spam? Respond with spam if the email is spam or ham \nif the email is not spam. Use only spam or ham as the answers, nothing else.\n\n[Email contents]\n```", "```py\nAfter considering it very carefully, do you think it's likely that the email \nbelow is spam? Respond with spam if the email is spam or ham if the email is \nnot spam. Use only spam or ham as the answers, nothing else.\n\n[Email contents]\n```", "```py\nimport pandas as pd\nimport numpy as np\nimport random\nfrom statistics import mean, stdev\nimport os\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nclient = OpenAI(\n    api_key=os.environ.get(\"OPENAI_API_KEY\")\n)\n\n# Define the prompts to test\nPROMPT_A = \"Is the following email spam? Respond with spam if the email is spam or \nham if the email is not spam. Use only spam or ham as the answers, nothing else.\n\\n\\nSubject: {subject}\\n\\nMessage: {message}\"\nPROMPT_B = \"After considering it very carefully, do you think it's likely that the \nemail below is spam? Respond with spam if the email is spam or ham if the email is \nnot spam. Use only spam or ham as the answers, nothing else.\n\\n\\nSubject: {subject}\\n\\nMessage: {message}\"\n\n# Load the dataset and sample\ndf = pd.read_csv(\"enron_spam_data.csv\")\nspam_df = df[df['Spam/Ham'] == 'spam'].sample(n=30)\nham_df = df[df['Spam/Ham'] == 'ham'].sample(n=30)\nsampled_df = pd.concat([spam_df, ham_df])\n\n# Evaluation function\ndef evaluate_prompt(prompt_template):\n    true_positive = 0\n    false_positive = 0\n    true_negative = 0\n    false_negative = 0\n\n    for _, row in sampled_df.iterrows():\n        subject = row['Subject']\n        message = row['Message']\n        actual_label = row['Spam/Ham']\n\n        # Generate prompt with email data \n        prompt = prompt_template.format(subject=subject, message=message)\n\n        # Call the OpenAI API with the given prompt\n        try:\n            response = client.chat.completions.create(\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": prompt,\n                }\n            ],\n            model=\"gpt-3.5-turbo-0125\",\n            )\n            predicted_label = response.choices[0].message.content.strip().lower()\n\n        except Exception as e:\n            print(f\"Error calling OpenAI API: {e}\")\n            continue\n\n        # Convert the actual and predicted labels to lowercase for comparison\n        if predicted_label == 'spam' and actual_label == 'spam':\n            true_positive += 1\n        elif predicted_label == 'spam' and actual_label == 'ham':\n            false_positive += 1\n        elif predicted_label == 'ham' and actual_label == 'ham':\n            true_negative += 1\n        elif predicted_label == 'ham' and actual_label == 'spam':\n            false_negative += 1\n\n    # Calculate precision and recall\n    precision = (\n        true_positive / (true_positive + \n    false_positive) \n        if (true_positive + false_positive) > 0 \n        else 0\n    )\n\n    recall = (\n        true_positive / (true_positive + \n    false_negative) \n        if (true_positive + false_negative) > 0 \n        else 0\n    )\n\n    return precision, recall\n\n# Run experiments\ndef run_experiments(prompt_template, n_experiments=10):\n    precisions = []\n    recalls = []\n    for n in range(n_experiments):\n        print(f\"Running experiment {n+1} of {n_experiments}\")\n        precision, recall = evaluate_prompt(prompt_template)\n        print(f\"Precision: {precision:.4f}, recall: {recall:.4f}\")\n        precisions.append(precision)\n        recalls.append(recall)\n\n    # Calculate mean and standard deviation for precision and recall\n    precision_mean = mean(precisions)\n    precision_stdev = stdev(precisions)\n    recall_mean = mean(recalls)\n    recall_stdev = stdev(recalls)\n\n    return precision_mean, precision_stdev, recall_mean, recall_stdev\n\n# Run experiments for Prompt A\n(\n    precision_mean_a,\n    precision_stdev_a,\n    recall_mean_a,\n    recall_stdev_a,\n) = run_experiments(PROMPT_A)\n\nprint(\n    f\"Prompt A - Precision: {precision_mean_a:.4f} ± {precision_stdev_a:.4f}, \"\n    f\"Recall: {recall_mean_a:.4f} ± {recall_stdev_a:.4f}\"\n)\n\n# Run experiments for Prompt B\n(\n    precision_mean_b,\n    precision_stdev_b,\n    recall_mean_b,\n    recall_stdev_b,\n) = run_experiments(PROMPT_B)\n\nprint(\n    f\"Prompt B - Precision: {precision_mean_b:.4f} ± {precision_stdev_b:.4f}, \"\n    f\"Recall: {recall_mean_b:.4f} ± {recall_stdev_b:.4f}\"\n)\n```", "```py\nPrompt A - Precision: 0.8370 ± 0.0365, Recall: 1.0000 ± 0.0000\nPrompt B - Precision: 0.7763 ± 0.0311, Recall: 1.0000 ± 0.0000\n```"]