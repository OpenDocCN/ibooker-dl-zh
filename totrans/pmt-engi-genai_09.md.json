["```py\n!pip install diffusers==0.11.1\n!pip install transformers scipy ftfy accelerate\n```", "```py\n# create an inference pipeline\nimport torch\nfrom diffusers import StableDiffusionPipeline\n\npipe = StableDiffusionPipeline.from_pretrained(\n    \"CompVis/stable-diffusion-v1-4\",\n    torch_dtype=torch.float16)\n\npipe = pipe.to(\"cuda\")\n```", "```py\n# run inference on a prompt\nprompt = \"a photograph of an astronaut riding a horse\"\n\ngenerator = torch.Generator(\"cuda\").manual_seed(1024)\n\nimage = pipe(prompt, num_inference_steps=50,\n    guidance_scale=7, generator=generator\n    ).images[0] # image here is in PIL format\n\n# Now to display an image you can either save it such as:\nimage.save(f\"astronaut_rides_horse.png\")\n\n# If you're in a google colab you can directly display:\nimage\n```", "```py\nimport os\nimport base64\nimport requests\nfrom IPython.display import Image\n\nengine_id = \"stable-diffusion-xl-1024-v1-0\"\napi_host = os.getenv('API_HOST', 'https://api.stability.ai')\napi_key = os.getenv(\"STABILITY_API_KEY\")\n\nimage_description = \"computers being tied together\"\nprompt = f\"\"\"an illustration of {image_description}. in the\nstyle of corporate memphis, white background, professional,\nclean lines, warm pastel colors\"\"\"\n\nresponse = requests.post(\n    f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n    headers={\n        \"Content-Type\": \"application/json\",\n        \"Accept\": \"application/json\",\n        \"Authorization\": f\"Bearer {api_key}\"\n    },\n    json={\n        \"text_prompts\": [\n            {\n                \"text\": prompt,\n            }\n        ],\n        \"cfg_scale\": 7,\n        \"height\": 1024,\n        \"width\": 1024,\n        \"samples\": 1,\n        \"steps\": 30,\n    },\n)\n\nif response.status_code != 200:\n    raise Exception(\n        \"Non-200 response: \" + str(response.text))\n\ndata = response.json()\n\nimage_paths = []\n\n# if there's no /out folder, create it\nif not os.path.exists(\"./out\"):\n    os.makedirs(\"./out\")\n\nfor i, image in enumerate(data[\"artifacts\"]):\n    filename = f\"./out/image-{i}.png\"\n    with open(filename, \"wb\") as f:\n        f.write(base64.b64decode(image[\"base64\"]))\n\n    image_paths.append(filename)\n\n# display the first image\nImage(filename=image_paths[0])\n```", "```py\nstable-diffusion-webui/\n    outputs/\n        txt2img-images/\n            2023-10-05/\n                your_image.png\n```", "```py\nMarilyn Monroe as a (pirate:1.5) on a desert island, detailed clothing,\nby Stanley Artgerm Lau and Alphonse Mucha\n```", "```py\nracy, nudity, cleavage\n```", "```py\nvogue fashion shoot of [Emma Watson: Amber Heard: 0.5],\nhighly realistic, high resolution, highly detailed,\ndramatic, 8k\n```", "```py\nheadshot of a man in an office,  as a Pixar Disney character\nfrom Up ( 2 0 0 9 ), unreal engine, octane render, 3 d\nrender, photorealistic, in the style of Pixar\n```", "```py\na painting of a woman in a pirate costume on the beach\nwith a pirate hat on her head and a pirate ship in the background,\na fine art painting, Chris Rallis, fantasy art, stanley artgerm lau\n```", "```py\nstatue of a king, texture, intricate, details, highly\ndetailed, masterpiece, architecture, building, trending on\nartstation, focus, sharp focus, concept art, digital\npainting, fantasy, sunny, day, midday, in the style of\nhigh fantasy art\n```", "```py\nNew York City by Studio Ghibli\n```", "```py\nUS military unit on patrol in Afghanistan\n```", "```py\nwoman playing piano at a Great Gatsby flapper party, 1920s,\nsymmetrical face\n```", "```py\npainting of Rachel Weisz\n```", "```py\n1960s Mad Men style apartment\n```", "```py\nScarlett Johansson, best quality, extremely detailed\n```", "```py\nmonochrome, lowres, bad anatomy, worst quality, low quality\n```", "```py\nA beautiful magical castle viewed from the outside, texture,\nintricate, details, highly detailed, masterpiece,\narchitecture, building, trending on artstation, focus, sharp\nfocus, concept art, digital painting, fantasy, sunny, day,\nmidday, in the style of high fantasy art\n```", "```py\nThe Happy Goldfish, illustrated children's book\n```", "```py\nskateboarding in Times Square nvinkpunk\n```", "```py\n!nvidia-smi --query-gpu=name,memory.total, \\\n    memory.free --format=csv,noheader\n```", "```py\n!wget -q https://github.com/ShivamShrirao/diffusers/raw/ \\\n    main/examples/dreambooth/train_dreambooth.py\n!wget -q https://github.com/ShivamShrirao/diffusers/raw/ \\\n    main/scripts/convert_diffusers_to_original_stable_ \\\n    diffusion.py\n%pip install -qq \\\ngit+https://github.com/ShivamShrirao/diffusers\n%pip install -q -U --pre triton\n%pip install -q accelerate transformers ftfy \\\nbitsandbytes==0.35.0 gradio natsort safetensors xformers\n```", "```py\n#@markdown If model weights should be saved directly in\n#@markdown google drive (takes around 4-5 GB).\nsave_to_gdrive = False\nif save_to_gdrive:\n    from google.colab import drive\n    drive.mount('/content/drive')\n\n#@markdown Name/Path of the initial model.\nMODEL_NAME = \"runwayml/stable-diffusion-v1-5\" \\\n    #@param {type:\"string\"}\n\n#@markdown Enter the directory name to save model at.\n\nOUTPUT_DIR = \"stable_diffusion_weights/ukj\" \\\n    #@param {type:\"string\"}\nif save_to_gdrive:\n    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\nelse:\n    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n\nprint(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n\n!mkdir -p $OUTPUT_DIR\n```", "```py\n# You can also add multiple concepts here.\n# Try tweaking `--max_train_steps` accordingly.\n\nconcepts_list = [\n     {\n         \"instance_prompt\":      \"photo of ukj person\",\n         \"class_prompt\":         \"photo of a person\",\n         \"instance_data_dir\":    \"/content/data/ukj\",\n         \"class_data_dir\":       \"/content/data/person\"\n     }\n]\n\n# `class_data_dir` contains regularization images\nimport json\nimport os\nfor c in concepts_list:\n    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n\nwith open(\"concepts_list.json\", \"w\") as f:\n    json.dump(concepts_list, f, indent=4)\n```", "```py\nimport os\nfrom google.colab import files\nimport shutil\n\nfor c in concepts_list:\n    print(f\"\"\"Uploading instance images for\n`{c['instance_prompt']}`\"\"\")\n    uploaded = files.upload()\n    for filename in uploaded.keys():\n        dst_path = os.path.join(c['instance_data_dir'],\n            filename)\n        shutil.move(filename, dst_path)\n```", "```py\n!python3 train_dreambooth.py \\\n  --pretrained_model_name_or_path=$MODEL_NAME \\\n  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n  --output_dir=$OUTPUT_DIR \\\n  --revision=\"fp16\" \\\n  --with_prior_preservation --prior_loss_weight=1.0 \\\n  --seed=1337 \\\n  --resolution=512 \\\n  --train_batch_size=1 \\\n  --train_text_encoder \\\n  --mixed_precision=\"fp16\" \\\n  --use_8bit_adam \\\n  --gradient_accumulation_steps=1 \\\n  --learning_rate=1e-6 \\\n  --lr_scheduler=\"constant\" \\\n  --lr_warmup_steps=0 \\\n  --num_class_images=50 \\\n  --sample_batch_size=4 \\\n  --max_train_steps=800 \\\n  --save_interval=10000 \\\n  --save_sample_prompt=\"photo of ukj person\" \\\n  --concepts_list=\"concepts_list.json\"\n```", "```py\nWEIGHTS_DIR = \"\"\nif WEIGHTS_DIR == \"\":\n    from natsort import natsorted\n    from glob import glob\n    import os\n    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \\\n        \"*\"))[-1]\nprint(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")\n\n#@markdown Run to generate a grid of preview images from the last saved weights.\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nweights_folder = OUTPUT_DIR\nfolders = sorted([f for f in os.listdir(weights_folder) \\\n    if f != \"0\"], key=lambda x: int(x))\n\nrow = len(folders)\ncol = len(os.listdir(os.path.join(weights_folder,\n    folders[0], \"samples\")))\nscale = 4\nfig, axes = plt.subplots(row, col, figsize=(col*scale,\n    row*scale), gridspec_kw={'hspace': 0, 'wspace': 0})\n\nfor i, folder in enumerate(folders):\n    folder_path = os.path.join(weights_folder, folder)\n    image_folder = os.path.join(folder_path, \"samples\")\n    images = [f for f in os.listdir(image_folder)]\n    for j, image in enumerate(images):\n        if row == 1:\n            currAxes = axes[j]\n        else:\n            currAxes = axes[i, j]\n        if i == 0:\n            currAxes.set_title(f\"Image {j}\")\n        if j == 0:\n            currAxes.text(-0.1, 0.5, folder, rotation=0,\n            va='center', ha='center',\n            transform=currAxes.transAxes)\n        image_path = os.path.join(image_folder, image)\n        img = mpimg.imread(image_path)\n        currAxes.imshow(img, cmap='gray')\n        currAxes.axis('off')\n\nplt.tight_layout()\nplt.savefig('grid.png', dpi=72)\n```", "```py\n#@markdown Run conversion.\nckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n\nhalf_arg = \"\"\n#@markdown Convert to fp16, takes half the space (2GB).\nfp16 = True #@param {type: \"boolean\"}\nif fp16:\n    half_arg = \"--half\"\n!python convert_diffusers_to_original_stable_diffusion.py \\\n    --model_path $WEIGHTS_DIR  --checkpoint_path \\\n    $ckpt_path $half_arg\nprint(f\"[*] Converted ckpt saved at {ckpt_path}\")\n```", "```py\na professional headshot of ukj person, standing with his\narms crossed and smiling at the camera with his arms\ncrossed, a character portrait, Adam Bruce Thomson, private\npress, professional photo\n```", "```py\nanime cat girl with pink hair and a cat ears outfit is posing for a picture\nin front of a gaze, photorealistic, 1girl, a character portrait, floral print,\nAlice Prin, sots art, official art, sunlight, wavy hair, looking at viewer\n```", "```py\ndisfigured, ugly, bad, immature, photo, amateur, overexposed, underexposed\n```", "```py\nSD1:1, 512, 512 # 1:1 square\nXL1:1, 1024, 1024 # 1:1 square\nSD3:2, 768, 512 # 3:2 landscape\nXL3:2, 1216, 832 # 3:2 landscape\nSD9:16, 403, 716 # 9:16 portrait\nXL9:16, 768, 1344 # 9:16 portrait\n```", "```py\nSquare 1:1, 1.0 # 1:1 ratio based on minimum dimension\nLandscape 3:2, 3/2 # Set width based on 3:2 ratio to height\nPortrait 9:16, 9/16 # Set width based on 9:16 ratio to height\n```"]