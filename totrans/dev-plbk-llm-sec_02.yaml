- en: Chapter 2\. The OWASP Top 10 for LLM Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the spring of 2023, I began researching security vulnerabilities specific
    to LLMs. At the time, there was a relatively large body of research on security
    for AI in general, but very little organized research about LLMs. However, I did
    find some research papers and blogs that covered some ideas in the area. I began
    the process of collecting these research papers and summarizing them using ChatGPT.
    Eventually, I provided a few examples from the current Top 10 list of web application
    vulnerabilities and asked ChatGPT to generate a draft Top 10 for LLMs in a similar
    format.
  prefs: []
  type: TYPE_NORMAL
- en: I thought what came out looked interesting, so I sent it to Jeff Williams, a
    founder of OWASP, the Open Worldwide Application Security Project, to see what
    he thought. Jeff, Contrast Security’s chief technology officer, wrote the first
    OWASP Top 10 list in 2001\. His goal was to create an accessible resource for
    developers that detailed the most critical risks and vulnerable areas of web applications.
    At the time, the World Wide Web was still only a few years old, and most developers
    had little to no understanding of how to create secure web applications. That
    original Top 10 list became a seminal work and a foundational resource in application
    security.
  prefs: []
  type: TYPE_NORMAL
- en: I didn’t tell Jeff that my list was primarily machine generated. As the original
    Top 10 list’s author, I figured he could give me an idea of whether my Top 10
    list looked novel and worth pursuing. Jeff encouraged me to petition the OWASP
    board for approval to spin it up as a new project. A few weeks later, the OWASP
    board approved the project, and I announced it, along with a link to a refined
    version of the draft Top 10 I’d generated with ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: What I thought would be an obscure research project and a bit of fun turned
    out to be much bigger. When I announced the project formation on my personal LinkedIn
    page, I’d hoped to find a dozen or so like-minded individuals interested in the
    obscure topic of LLM security. As it turned out, my initial blog post racked up
    almost 10,000 views, and hundreds of individuals volunteered to join the expert
    team in the weeks that followed.
  prefs: []
  type: TYPE_NORMAL
- en: This book isn’t a product of OWASP, and the vulnerabilities and risks here won’t
    precisely map to any public version of the Top 10 for LLM apps list. Instead,
    you should expect to see my view on these risks. However, my learning and thinking
    on the topic is heavily influenced by my work leading the project and the creation
    and initial release of the OWASP Top 10 for LLM Applications list. Since then,
    I’ve had many people ask me for details about how we ran the project and how we
    were able to create such an impactful framework in such a short time. So, before
    we examine individual risks and vulnerabilities, I’ll give you some of the backstory
    of OWASP and the LLM Applications project.
  prefs: []
  type: TYPE_NORMAL
- en: About OWASP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Open Worldwide Application Security Project is a nonprofit organization
    focused on improving software security. Founded in 2001, OWASP provides a platform
    for security experts to share their knowledge and best practices about web security,
    from application-level vulnerabilities to emerging threats. Today, it has tens
    of thousands of active members and over 250 local chapters around the globe.
  prefs: []
  type: TYPE_NORMAL
- en: The organization is community-driven and encourages the participation of volunteers
    who contribute to various projects, including documentation, tools, and forums.
    It operates under an open source model, making its resources freely accessible
    to the public. Over the years, OWASP has garnered a strong following among the
    security community, and its guidelines and tools are considered industry standards
    in many contexts.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to the original Top 10 list for web applications (updated regularly,
    most recently in 2021), specialized Top 10 lists have emerged from OWASP over
    the years. These include:'
  prefs: []
  type: TYPE_NORMAL
- en: OWASP Mobile Top 10
  prefs: []
  type: TYPE_NORMAL
- en: Lists key mobile app risks for Android and iOS, including insecure data storage,
    insufficient cryptography, and insecure communication
  prefs: []
  type: TYPE_NORMAL
- en: OWASP API Security Top 10
  prefs: []
  type: TYPE_NORMAL
- en: Highlights API-specific risks like improper asset management and broken object-level
    security
  prefs: []
  type: TYPE_NORMAL
- en: OWASP IoT Top 10
  prefs: []
  type: TYPE_NORMAL
- en: Identifies top Internet of Things (IoT) security concerns, such as insecure
    network services, lack of physical hardening, and insecure software/firmware
  prefs: []
  type: TYPE_NORMAL
- en: OWASP Cloud Native Top 10
  prefs: []
  type: TYPE_NORMAL
- en: Focuses on cloud native app risks, covering data exposure, broken authentication,
    and insecure deployment configurations
  prefs: []
  type: TYPE_NORMAL
- en: OWASP Top 10 for Serverless
  prefs: []
  type: TYPE_NORMAL
- en: Addresses security concerns unique to serverless architecture, an increasingly
    popular but risky model
  prefs: []
  type: TYPE_NORMAL
- en: OWASP Top 10 Privacy Risks
  prefs: []
  type: TYPE_NORMAL
- en: Promotes good privacy practices, addressing issues like lack of data encryption
    and insufficient auditing and logging
  prefs: []
  type: TYPE_NORMAL
- en: The Top 10 for LLM Applications Project
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Within a week after I posted the announcement about the formation of the Top
    10 for LLM Applications project, well over 200 people had signed on to it, and
    we held a kick-off event via Zoom. At that first meeting, I laid out a vision
    for what I hoped the group could accomplish and proposed an aggressive roadmap:
    we would build the first version of the list in eight weeks. A typical OWASP Top
    10 list may take a year or more to develop, but we decided that this space was
    moving so fast and this type of resource was so needed that we had to work more
    quickly.'
  prefs: []
  type: TYPE_NORMAL
- en: We decided to run the project in two-week, Agile-style sprints. Since most of
    the experts in the group were familiar with Agile development, everyone quickly
    adapted to the pace.
  prefs: []
  type: TYPE_NORMAL
- en: Project Execution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first sprint of the project was brainstorming and commentary. Everyone reviewed
    the original version of the list, which I called version 0.1\. There were plenty
    of problems with that initial version, and the team was aggressive about pointing
    them out. At the same time, we began to create a wiki page with links to all the
    resources the group found on LLM security issues. It turned out a lot had been
    written, but this was the first time anyone had ever collected the information
    and made it easy to access. This new, curated collection of resources was the
    first win for the group.
  prefs: []
  type: TYPE_NORMAL
- en: The second sprint was to generate a new version of the list. This time, rather
    than being the work of a single person and an AI, it would be the product of the
    collective wisdom of our expert team, which continued to grow week by week. In
    the first week, the group focused on generating ideas for the Top 10 list. We
    published a template and asked the group to submit candidate vulnerabilities.
    In that week, we developed 43 detailed descriptions of possible areas. We then
    conducted two rounds of voting using Google Forms, leveraging the team’s collective
    wisdom to narrow the list to 10, which we published as version 0.5\. This version
    was far more detailed and comprehensive than version 0.1\. The positive reception
    from the larger community gave the group the energy to keep working.
  prefs: []
  type: TYPE_NORMAL
- en: The next sprint was used to refine each entry. We created Slack channels for
    each vulnerability type and chose a volunteer as the entry lead for each item.
    Subteams of 10 to 30 individuals then fleshed out and tuned each entry. Again,
    we included a round of voting for the whole team to be involved and point out
    weak areas that needed more attention. Along the way, we found some entries overlapped
    and merged them. This change created space to pull up some entries that had fallen
    below the 10 item cut-off. The result of this sprint became version 0.9 of the
    list. Interestingly, the word count of version 0.9 was about 33% shorter than
    0.5; the extra time and refinement had allowed the subteams to focus their thinking
    and make the entries punchy and tight.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we took a final sprint to review, tweak, and clean up each entry. We
    gathered another round of feedback via Google Forms to ensure everything was ready.
    By this time we had a dedicated design lead who laid out the whole document in
    an attractive PDF for publication.
  prefs: []
  type: TYPE_NORMAL
- en: Reception
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: My announcement for the 1.0 version of the list was viewed on LinkedIn over
    40,000 times. And that doesn’t include the many posts made by group members on
    their own pages and blogs. In the days following the publication of the announcement,
    reporters picked up the news and it was covered in media outlets such as *Wired*,
    *SD Times*, *The Register*, *I**nfosecurity* *Magazine*, and *Diginomica*. It’s
    safe to say hundreds of thousands of people became aware of our work in just the
    first few weeks.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the sheer number of people exposed, the thing that amazed me was the
    uniformly positive feedback. We also saw the first government agencies in the
    US and Europe referencing our work as a foundational document. While everyone
    on our expert team agreed there was much more to do, it seemed the world was so
    hungry for advice in this area that our document hit the mark. While we received
    many questions and comments, it’s safe to say that everyone involved felt pleased
    and proud of our work.
  prefs: []
  type: TYPE_NORMAL
- en: Keys to Success
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many people have asked me how we could drive this project so quickly to a successful
    outcome. Looking back, I believe several factors contributed. I’ll share them
    here in the hopes that others running similar projects in the future might benefit.
  prefs: []
  type: TYPE_NORMAL
- en: Timing undoubtedly played a considerable role. The wave of interest in LLMs
    that followed the release of ChatGPT was massive. It drew my attention, and countless
    others became excited as well. This helped attract a large and diverse expert
    group and motivated a smaller group of these people to spend long hours on the
    project with a tight deadline.
  prefs: []
  type: TYPE_NORMAL
- en: Having a clear plan and timeline from the start was crucial. My knowledge of
    LLM security was limited at the beginning of the project, but I’ve made a career
    of running complex projects with many contributors. Creating a clear roadmap with
    specific phases and a schedule let people know what we were doing and when. The
    fact that everyone could see a goal that wasn’t too far away kept people motivated.
    Every two weeks, we had global meetings via Zoom and posted recordings on YouTube
    for people who couldn’t attend live. The meetings and recordings were critical
    to coordinating a globally distributed team.
  prefs: []
  type: TYPE_NORMAL
- en: A freeform but short brainstorming phase at the start was critical. LLM security
    was such a new area that taking those first two weeks for people to throw out
    ideas and argue on Slack was crucial. It also allowed us to collect and socialize
    a repository of the existing research in the area. That let us start at a point
    where everyone on the project had access to the best preexisting research.
  prefs: []
  type: TYPE_NORMAL
- en: However, keeping this phase short was equally critical. We could maintain momentum
    by limiting brainstorming to two weeks and shifting quickly to a creation phase.
    I’ve seen other projects get stuck and be unable to move past brainstorming before
    people lose interest.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the project’s core team wasn’t something I’d originally planned, but
    it became critical. Having a large expert team was a fantastic asset. The group
    grew to nearly 500 people by the time we published 1.0\. A team that large would
    have been totally unmanageable. During the project’s first few weeks, I was looking
    for active and knowledgeable people. I approached about a dozen of them and asked
    if they’d be willing to join the project’s core leadership team. I told them it
    would be extra work, but they’d get to be at the heart of the project. There would
    be no specific reward for taking this role. Most accepted immediately. I believe
    that recognizing people and asking for their support formally motivated them to
    spend more time and energy on the project. They were all invested!
  prefs: []
  type: TYPE_NORMAL
- en: Short sprints with visible deliverables are a core tenet of Agile, and this
    is a place where it shined. Using an Agile Release Train model, I could continue
    to drive the group forward despite conflicting opinions. If some members had concerns
    about an area, we didn’t let it get us stuck. We acknowledged it and agreed we’d
    resolve it in the next sprint. When we got to version 1.0 of the list, there were
    still some places where people wanted to do more, so we just agreed there would
    be more versions of the list. It would be a living document, and the most important
    thing was to get a version of this resource into the hands of the developers who
    needed it.
  prefs: []
  type: TYPE_NORMAL
- en: This Book and the Top 10 List
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As I mentioned, this book is not a product of the OWASP Foundation. However,
    the experience of working with this team has had an enormous impact on my understanding
    of and perspectives on LLM security. This mindset means that much of the guidance
    in the following chapters is influenced by the fantastic team that builds and
    maintains the Top 10 project. In this way, readers should feel comfortable that
    they’re getting advice that isn’t the product of a single author, but is informed
    by a larger community of experts.
  prefs: []
  type: TYPE_NORMAL
- en: In the following several chapters, we’ll review the top risk and vulnerability
    areas for LLMs. The risks we discuss will contain many areas common to the OWASP
    Top 10, but won’t be precisely the same as any version of the official Top 10
    list. The Top 10 list is a quick read that highlights critical areas; here, we’ll
    dig more deeply into the risks, remediation steps, and expanded real-world case
    studies.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll return to the OWASP version of the Top 10 list in [Chapter 10](ch10.html#learning_from_future_history),
    where we’ll briefly review the 2023 version of the list and map it to chapters
    in this book. We’ll then show how to use the Top 10 framework to document and
    share analysis of security vulnerabilities and successful exploits.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 3](ch03.html#architectures_and_trust_boundaries), we’ll examine
    the overall structure of typical LLM applications and discuss the trust boundaries
    and dangers. Subsequent chapters will then probe individual risk areas and examine
    vulnerabilities, attacks, and examples so that you can plan your strategy for
    securing your own use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go!
  prefs: []
  type: TYPE_NORMAL
