- en: Chapter 4\. Understanding Drug–Drug Interactions Using Graphs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Graphs* are a fundamental structure found everywhere in the world around us.
    A familiar example is social networks, where *nodes* represent individuals and
    *edges* capture the relationship between them. In train systems, nodes could represent
    stations and edges the routes linking them. Less obvious examples include research
    collaborations linked by coauthorship, web pages interconnected by hyperlinks,
    and supermarket baskets, where frequently copurchased items are connected.'
  prefs: []
  type: TYPE_NORMAL
- en: Biology, too, is filled with data that naturally lends itself to a network framework—genes
    interact to control cell functions, proteins physically bind to each other, and
    cells send signals to each other, all forming graph-like systems. Even molecules
    can be represented as graphs, with atoms as nodes and chemical bonds as edges,
    as shown in [Figure 4-1](#example-graphs). At larger biological scales, ecological
    food webs capture predator–prey and other species interactions, while disease
    transmission networks map the spread of pathogens through populations.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dlfb_0401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-1\. Examples of graphs from different contexts. The social network
    shows people as nodes connected by edges representing relationships. The rail
    network illustrates stations as nodes and train routes as edges. The molecule
    network depicts the molecular structure of caffeine, where nodes represent atoms,
    and edges represent chemical bonds (hydrogen atoms are not shown).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: These types of network relationships can be modeled using *graph neural networks*
    (GNNs). Recently, deep learning on graphs has become increasingly popular and
    effective. In this chapter, we will explore a graph of *drug–drug interactions*
    (DDIs) to gain insights into its connectivity. Specifically, we aim to predict
    whether two nodes should connect, which is a task known as *link prediction*.
    Link prediction is valuable here because, while we have an existing DDI graph,
    it may be incomplete—some true connections between drugs might be missing due
    to limited research or untested combinations. By accurately predicting these links,
    one could improve drug safety by identifying potential negative interactions and
    even discover new combination therapies by predicting which drugs might interact
    positively.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As in earlier chapters, we recommend keeping this chapter’s companion Colab
    notebook open as you read. Running the code yourself helps reinforce the material
    and gives you a place to immediately experiment with new ideas.
  prefs: []
  type: TYPE_NORMAL
- en: Biology Primer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DDIs occur when the effects of one drug are altered by the presence of another.
    DDIs can amplify each drug’s effects, counteract them, or change the way a drug
    is processed in the body, which may result in either therapeutic benefits or adverse
    outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Beneficial Drug–Drug Interactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In some cases, DDIs can be harnessed for therapeutic advantage. In cancer treatment,
    for example, combination therapies pair drugs that target different pathways in
    cancer cells. One drug may inhibit tumor growth, while another restricts the tumor’s
    blood supply, weakening it further. This multitargeted approach not only improves
    patient outcomes but also reduces the likelihood of drug resistance.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, certain antibiotics work better in combination. For instance, penicillin
    and gentamicin are often combined to treat infections like endocarditis. Penicillin
    weakens the bacterial cell wall, allowing gentamicin to penetrate the cell and
    disrupt protein synthesis, leading to a more effective antibiotic treatment.
  prefs: []
  type: TYPE_NORMAL
- en: Harmful Drug–Drug Interactions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Harmful DDIs are generally much more common than beneficial ones—most drugs
    are not designed with other drugs in mind, which often leads to unintended side
    effects in patients taking multiple medications. Additionally, many drugs influence
    similar biological pathways, increasing the likelihood that one drug will amplify
    or counteract the effects of another. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: Amplification example
  prefs: []
  type: TYPE_NORMAL
- en: Aspirin, commonly used as a pain reliever or blood thinner, can amplify the
    effects of other anticoagulants, such as warfarin. When taken together, both drugs
    thin the blood more than intended, raising the risk of excessive bleeding or bruising.
  prefs: []
  type: TYPE_NORMAL
- en: Counteraction example
  prefs: []
  type: TYPE_NORMAL
- en: Ibuprofen can reduce the effectiveness of antihypertensive drugs, such as ACE
    inhibitors and beta-blockers. Ibuprofen causes the body to retain sodium and fluid,
    which raises blood pressure and counteracts these medications.
  prefs: []
  type: TYPE_NORMAL
- en: Most negative DDIs are actually more *indirect*. For instance, many drugs are
    metabolized in the liver by the cytochrome P450 enzyme system, so drugs that inhibit
    this system can impact a wide range of other medications. Grapefruit, though not
    a “drug” in the traditional sense, contains compounds that inhibit the cytochrome
    P450 system. One of the most serious grapefruit interactions occurs with certain
    statins used to control cholesterol. Grapefruit compounds inhibit an enzyme that
    would normally break down these statins, causing higher-than-expected drug levels
    to accumulate in the bloodstream. This buildup can lead to very severe side effects,
    including liver damage and muscle tissue breakdown.
  prefs: []
  type: TYPE_NORMAL
- en: DrugBank
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DrugBank is one of the largest databases of drug interactions, providing detailed
    information on drugs and their known interactions. It has been widely used in
    various DDI studies. For example, in [Figure 4-2](#drugbank-clusters), an early
    study from 2016 clustered DrugBank DDIs (at the time, the database contained around
    1,000 nodes; in this chapter, we work with a more recent version containing over
    4,000 nodes) to reveal major drug clusters, including those related to cytochrome
    P450 interactions discussed earlier.^([1](ch04.html#id726))
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dlfb_0402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-2\. Community-based drug–drug interaction network using data from DrugBank
    4.1, containing 1,141 nodes (drugs) and 11,688 edges (drug–drug interactions).
    Clustering was performed using the Force Atlas 2 layout algorithm, which simulates
    a physical system to position nodes closer together based on their interactions,
    with colors assigned to highlight distinct communities of interacting drugs.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this chapter, we will use a processed version of DrugBank’s DDI data, available
    through a publicly accessible benchmark dataset from the [Open Graph Benchmark](https://oreil.ly/S_wR-)
    resource by researchers from Stanford University.^([2](ch04.html#id727)) Before
    diving into the dataset and its applications, let’s begin with a brief primer
    on machine learning on graphs.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning Primer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You probably already have an intuitive sense of what a graph is, but to be
    more precise, a graph is a structure that represents relationships between pairs
    of objects. It consists of two main components:'
  prefs: []
  type: TYPE_NORMAL
- en: Nodes (or vertices)
  prefs: []
  type: TYPE_NORMAL
- en: These represent individual entities, like people in a social network or proteins
    in an interaction network.
  prefs: []
  type: TYPE_NORMAL
- en: Edges
  prefs: []
  type: TYPE_NORMAL
- en: These are the connections between nodes, indicating relationships or interactions.
    In a social network, for example, an edge might represent a friendship, while
    in a protein interaction network, an edge represents an observed physical interaction
    between two proteins.
  prefs: []
  type: TYPE_NORMAL
- en: Graphs can be *directed* (where edges have a direction, showing a one-way relationship)
    or *undirected* (indicating a two-way relationship). An example of a directed
    biological graph is predator–prey relationships between species in an ecosystem—an
    owl preys on mice; it’s usually not the other way around. An example of an undirected
    biological graph is gene coexpression networks, where the nodes are genes and
    the edges are correlations between the expression levels of each gene pair.
  prefs: []
  type: TYPE_NORMAL
- en: Edges can have *attributes* such as *weights*, which reflect the strength of
    a connection. Nodes can also have attributes that capture additional information.
    For example, in the predator–prey example, edge weights might represent the number
    of times one species predates another, and each node might contain additional
    information about that species such as its estimated population size. Graphs vary
    in connection density (sparse versus dense), may include self-loops (nodes connected
    to themselves), and can be dynamic (changing over time, like social networks)
    or static.
  prefs: []
  type: TYPE_NORMAL
- en: Certain graph properties have significant computational implications. For instance,
    *graph size* can pose a challenge, as large graphs may need to be distributed
    across multiple processing units to avoid memory overload. *Graph sparsity*—which
    is the proportion of existing edges relative to the total possible edges in the
    graph—affects storage and computation efficiency, with specialized techniques
    designed to handle sparsely connected networks. Additionally, sparse graphs allow
    for more efficient convolution operations, as fewer neighbors need to be considered
    (explained further later in this chapter). Finally, the level of *connectivity*
    plays a crucial role. While graphs with many small, disconnected subgraphs can
    often be processed in parallel, densely connected graphs are more challenging
    to parallelize.
  prefs: []
  type: TYPE_NORMAL
- en: Representing Graph Structures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In [Figure 4-3](#graph-representations), we see an undirected graph containing
    five nodes (N0, N1, N2, N3, N4) and five edges:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dlfb_0403.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-3\. Visual representation of an undirected graph. The same graph is
    represented as an adjacency matrix and as a bidirectional edge list, where each
    undirected edge is shown in both directions. In practice, many GNN libraries require
    such bidirectional edge lists. Self-edges (not shown here) are also often included
    by default to help preserve node identity. Each node is often associated with
    a feature vector (not shown), but not always (as in this chapter).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We can numerically represent the graph structure in two main ways:'
  prefs: []
  type: TYPE_NORMAL
- en: Adjacency matrix
  prefs: []
  type: TYPE_NORMAL
- en: Each node is listed along the rows and columns of a matrix, with edges indicated
    by values in the corresponding cells.
  prefs: []
  type: TYPE_NORMAL
- en: Edge list
  prefs: []
  type: TYPE_NORMAL
- en: Each row in this list represents an edge by specifying its start and end nodes.
  prefs: []
  type: TYPE_NORMAL
- en: The choice of representation impacts memory usage, especially depending on graph
    sparsity. An adjacency matrix has fixed high memory usage, as it accounts for
    all possible edges that could exist, while an edge list is more compact because
    it only stores the edges that exist. For sparse graphs, where the number of edges
    is much smaller than the total possible, an edge list is typically much more memory
    efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Graph Neural Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With this foundational understanding of graphs, we can explore how graph neural
    networks learn from them. GNNs are a class of models designed to operate directly
    on graph structures, capturing information from both nodes and their connections.
    At a high level, GNNs work by iteratively aggregating information from a node’s
    neighbors, producing rich representations (embeddings) that reflect both the node’s
    features and its position within the broader graph structure. We’ll break down
    this process in more detail shortly—but first, why do we need GNNs in the first
    place? What kinds of graph-related problems can they solve?
  prefs: []
  type: TYPE_NORMAL
- en: 'GNNs are commonly used for these main tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Node classification
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the type or property of a node within a graph; for example, determining
    the category of a drug within a DDI network (e.g., antidepressant, antihistamine,
    or antibiotic).
  prefs: []
  type: TYPE_NORMAL
- en: Edge classification
  prefs: []
  type: TYPE_NORMAL
- en: Predicting the type or existence of a connection between two nodes; for example,
    determining whether two drugs are likely to interact.
  prefs: []
  type: TYPE_NORMAL
- en: Edge regression
  prefs: []
  type: TYPE_NORMAL
- en: Estimating a continuous value for a connection between nodes. In the context
    of DDI networks, this could involve predicting the severity or strength of an
    interaction rather than just its presence or type.
  prefs: []
  type: TYPE_NORMAL
- en: Graph classification
  prefs: []
  type: TYPE_NORMAL
- en: Predicting a property of an entire graph; for example, identifying whether a
    drug molecule, represented as a graph of atoms and bonds, has a specific property,
    such as being water soluble or binding to a specific disease-associated protein.
  prefs: []
  type: TYPE_NORMAL
- en: 'These tasks all rely on the GNN’s ability to extract meaningful representations
    from the graph structure. Whether the goal is to classify nodes, predict edges,
    or assess whole-graph properties, the core mechanism remains the same: learning
    expressive embeddings through iterative information exchange. This leads us to
    the central idea behind most GNN architectures: *message passing*.'
  prefs: []
  type: TYPE_NORMAL
- en: Graph Embeddings and Message Passing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A primary goal in GNNs is to learn the structure around each node by generating
    a per-node embedding vector that captures information from its neighborhood. Unlike
    in images, where pixels have a fixed spatial arrangement, graph connections lack
    inherent order, making traditional convolutional approaches less applicable.
  prefs: []
  type: TYPE_NORMAL
- en: To address this, modern GNNs use a framework known as *message passing*, where
    each node iteratively exchanges messages with its neighbors and aggregates their
    information to update its own representation. This idea was formalized in the
    Message Passing Neural Network (MPNN) framework by Gilmer *et al*., which has
    become the foundation for many contemporary GNN architectures.^([3](ch04.html#id740))
    Earlier forms of GNNs were introduced by Scarselli *et al*., who proposed recursive
    neural models for learning on graphs, though without the modular message-passing
    abstraction seen today.^([4](ch04.html#id741))
  prefs: []
  type: TYPE_NORMAL
- en: Message passing is a flexible framework that underpins many GNN models. It often
    refers to the interaction between *sender* and *receiver* nodes, where the sender
    transmits information and the receiver aggregates it to update its own representation.
    *Graph convolution* is one specific implementation of message passing, where nodes
    aggregate information from their neighbors using functions such as summation,
    mean, or max. In contrast, nonconvolutional approaches such as graph attention
    networks (GATs) use attention mechanisms to assign different weights to neighbors
    based on their relative importance. The choice of aggregation function—whether
    sum, mean, max, or attention—affects the types of patterns the GNN can learn.
  prefs: []
  type: TYPE_NORMAL
- en: 'Increasing the number of message-passing layers (i.e., the number of hops a
    node can “see”) expands each node’s receptive field, enabling it to incorporate
    information from more distant parts of the graph. However, deeper GNNs can run
    into two key challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: Over-smoothing
  prefs: []
  type: TYPE_NORMAL
- en: As the number of message-passing layers increases, each node incorporates information
    from a broader neighborhood. While this can be beneficial up to a point, stacking
    too many layers causes node embeddings to become increasingly similar—eventually
    collapsing to near-identical representations regardless of a node’s local structure
    or features. This degrades the model’s ability to distinguish between nodes, especially
    in classification tasks where fine-grained differences can be very important.
  prefs: []
  type: TYPE_NORMAL
- en: Over-squashing
  prefs: []
  type: TYPE_NORMAL
- en: When long-range information must pass through a limited number of intermediate
    nodes or edges, it becomes overly compressed. This bottleneck prevents distant
    signals from being accurately preserved—especially in graphs with long, narrow
    paths, such as trees or hierarchies often seen in biology (e.g., gene regulatory
    networks or phylogenetic trees). As a result, important context from far-apart
    nodes gets “squashed” before it can meaningfully influence predictions.
  prefs: []
  type: TYPE_NORMAL
- en: To mitigate these issues, common strategies include adding skip connections,
    incorporating attention mechanisms, or rewiring the graph to shorten path lengths.
    In practice, using just two or three message-passing layers—capturing information
    from a few hops away—often provides a good balance between expressivity and stability.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In GNNs, “layers” are better understood as message-passing iterations rather
    than traditional neural network layers. Unlike MLPs, where each layer applies
    a distinct learned transformation, each GNN layer aggregates information from
    a node’s immediate neighbors. Thus, a model with three layers enables each node
    to incorporate information from up to three hops away in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Cold-Start Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A significant challenge in GNNs is predicting on *unseen nodes*, often referred
    to as the *cold-start problem*. Many traditional graph models operate in a *transductive*
    setting, where training occurs on a fixed graph, limiting predictions to relationships
    among nodes seen during training.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, real-world applications often involve dynamic graphs where new nodes
    are introduced. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: In a social network, a new user joins, and the platform needs to predict their
    potential connections.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a recommendation system, a newly released product must be matched to relevant
    users based on their preferences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In drug discovery, a newly synthesized compound must be evaluated for interactions
    with existing molecules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To address the cold-start problem, GNNs can adopt an *inductive learning* approach,
    enabling generalization to new, unseen nodes. This capability is essential for
    dynamic graphs where new nodes are frequently added, as it eliminates the need
    to retrain the model whenever the graph changes. It is achieved by learning patterns
    and relationships that are transferable across the graph. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: Instead of memorizing specific connections, the model identifies structural
    similarities (e.g., the role of a node in its local neighborhood) or shared features
    (e.g., common attributes across nodes).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a new node is added, its feature vector and immediate connections to existing
    nodes provide enough context for the model to embed it within the graph and make
    predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notable frameworks like GraphSAGE focus on inductive learning by sampling neighborhoods
    and aggregating local features to generate embeddings for unseen nodes. Techniques
    such as feature propagation and attention mechanisms further enhance this capability,
    making GNNs highly adaptable to evolving, real-world graphs.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For a more detailed (but highly accessible) introduction to GNNs, we recommend
    the excellent lecture [“Theoretical Foundations of Graph Neural Networks”](https://oreil.ly/GXy3v)
    by Petar Veličković on YouTube. It offers clear GNN explanations from one of the
    leading experts in the field.
  prefs: []
  type: TYPE_NORMAL
- en: GraphSAGE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we implement a GraphSAGE model,^([5](ch04.html#id754)) an inductive
    approach that can predict the properties of nodes it has never seen before by
    aggregating information from their neighbors. In the original paper, GraphSAGE
    was evaluated on tasks like classifying academic papers into six biology-related
    categories using citation graphs, assigning Reddit posts to 50 communities based
    on user interactions, and predicting protein functions across multiple protein–protein
    interaction graphs. These benchmarks demonstrated GraphSAGE’s ability to generalize
    to unseen nodes and outperform traditional methods, highlighting its versatility
    in dynamic, real-world graphs.
  prefs: []
  type: TYPE_NORMAL
- en: A key advantage of GraphSAGE is its scalability to massive graphs. Training
    on large graphs can be resource intensive because embedding updates for each node
    requires iterating over its neighbors. GraphSAGE addresses this challenge by using
    *subsampling*, where only a small, fixed number of neighbors is sampled for each
    node. These subgraphs are processed in mini-batches, significantly reducing memory
    and computation costs.
  prefs: []
  type: TYPE_NORMAL
- en: 'As illustrated in [Figure 4-4](#graphsage-illustration) (from the [original
    paper](https://oreil.ly/wz_mG)), GraphSAGE has two main components: sampling a
    subgraph and aggregating neighborhood information for each node. The resulting
    embeddings can be used for downstream tasks such as node classification or link
    prediction. While GraphSAGE can incorporate edge or node annotations, it does
    not depend on them, and for most of this chapter, we will focus solely on the
    graph structure.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dlfb_0404.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4-4\. GraphSAGE stands for Graph SAmple and AggreGatE, representing
    its two main steps: (1) sampling a node’s neighbors and (2) aggregating their
    features to generate an embedding. These embeddings can be used for downstream
    tasks, such as (3) predicting node properties or relationships within the graph.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Selecting a Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll work with a unique data source: the Open Graph Benchmark
    (OGB) dataset of processed DrugBank DDIs called [`ogbl-ddi`](https://oreil.ly/WWr52).
    This dataset is particularly convenient for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: It is well studied, providing a wealth of existing research to draw inspiration
    from.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It enables us to compare our model’s performance with other approaches using
    the [leaderboard](https://oreil.ly/VPv1R).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Additionally, OGB simplifies the workflow by offering built-in data loaders
    compatible with various deep learning frameworks and an `Evaluator` class for
    computing problem-specific metrics. This allows us to focus on building and refining
    our model rather than spending a long time on data preparation.
  prefs: []
  type: TYPE_NORMAL
- en: Describing the Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already discussed DDI networks in general. The OGBL DDI dataset in particular
    is an unweighted, undirected graph of DDIs, where each node is an FDA-approved
    or experimental drug and edges represent either beneficial or harmful interactions
    between drugs.
  prefs: []
  type: TYPE_NORMAL
- en: To make the problem more challenging, the dataset is split in an interesting
    way—by the proteins that each drug targets. This “protein–target split” ensures
    that the test set contains drugs that primarily bind to different proteins than
    those in the training and validation sets, meaning they are more likely to operate
    through distinct biological mechanisms. This forces the model to learn more generalizable
    biology. If we created our own split—such as a random split of drugs—there would
    likely be greater overlap in biological mechanisms between the training and test
    sets, which would make the problem easier but would ultimately reduce the model’s
    ability to generalize to unseen drugs in real-world scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As always, let’s start by doing some exploratory analysis of the dataset to
    get a feel for what we’re dealing with. We start by loading the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This downloads the `ogbl-ddi` dataset and neatly packs it into an object ready
    for inspection. The full graph is accessible with `.graph`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The graph is stored in *edge-list* format under the key `edge_index`. Both
    `edge_feat` and `node_feat` are `None`, meaning the graph includes only the structure—without
    additional edge features such as interaction strengths or node features such as
    drug properties. Next, let’s examine the number of nodes and edges in the graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can plot the *degree distribution*, or the distribution of the number of
    connections per node, to get a sense of the high-level graph structure (depicted
    in [Figure 4-5](#fig4-5)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/dlfb_0405.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-5\. The degree distribution of nodes in the DDI network follows a power-law
    distribution where a few drugs interact with many others, but the majority is
    more isolated.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We observe that a few drugs act as *hubs*, exhibiting a high degree of interaction
    with many other drugs, while most drugs have a low degree, interacting with only
    a few other drugs. This pattern is consistent with a [*power-law distribution*](https://oreil.ly/pcVKt),
    commonly seen in biological and social networks, where a small number of elements
    have very high connectivity (hubs) while the majority have low connectivity. However,
    it is important to note that this characteristic might be specific to this dataset
    and may not generalize to all DDI networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can compute the *density* of the graph, or the ratio of edges to the number
    of possible edges, to quantify how densely interconnected our graph is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This shows that while the dataset contains a seemingly large number of edges,
    it is not extremely dense, as 77% of possible connections are absent. With a density
    of 23%, the graph might be considered moderately interconnected, though this label
    is a bit subjective and depends on the specific context.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset comes with its own methods to extract useful information. For example,
    `.get_edge_split` will list the graph’s edges across the different data splits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that the `valid` and `test` splits actually contain two types of
    edges:'
  prefs: []
  type: TYPE_NORMAL
- en: The `edge` key holds the positive data, representing known drug interactions.
    Here, *positive* refers to the fact that these interactions are known, not whether
    they are beneficial or harmful.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `edge_neg` key contains negative edges, representing drug pairs with no
    known interactions. However, because some interactions may simply be undiscovered,
    this data is considered *weakly labeled* and may include inaccuracies (false negatives).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Importantly, the training dataset does not include explicit negative edges (i.e.,
    there’s no predefined `edge_neg` list in `train`). However, since most node pairs
    in a sparse graph are unconnected, negative samples can be drawn from this large
    set of nonedges during training. The method used to sample these negatives is
    an important hyperparameter, as it can significantly affect performance. Some
    negative edges are trivially easy to distinguish, which can lead to inflated metrics.
    In contrast, the validation and test datasets include a predefined `edge_neg`
    key that specifies which unconnected node pairs to use for evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now examine the relative sizes of the `train`, `valid`, and `test` splits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In this dataset, the training set contains roughly 10 times more positive edges
    than the validation and test sets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another important consideration is whether all nodes in the validation and
    test sets also appear in the training set. This determines whether the model will
    encounter completely unseen nodes during evaluation—a key distinction between
    transductive and inductive learning. You can check this with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In our case, all nodes in the validation and test sets are indeed present in
    the training graph. This defines a transductive setting, where the model sees
    all nodes during training and only needs to predict whether specific edges exist
    between them. This setup is simpler than the inductive case, where the model must
    make predictions involving entirely unseen nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with transductive evaluation allows us to assess model performance
    in a controlled setting before tackling the more complex inductive scenario. Models
    like GraphSAGE are well suited to inductive tasks because they generate node embeddings
    based on local neighborhoods. This means that even unseen nodes can be embedded
    meaningfully, provided they connect to known parts of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: For now, we’ll focus on the transductive case and ensure that the model performs
    well when all nodes are known.
  prefs: []
  type: TYPE_NORMAL
- en: Examining Drug Names
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Although not immediately available in the graph object, there is additional
    annotation data that comes with the `ogbl-ddi` dataset. Let’s examine this information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: We can see that each row is a DDI, with each drug having an ID (an accession
    in the [DrugBank database](https://oreil.ly/CfISy)) and a description of the nature
    of the interaction.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This chapter’s dataset is ultimately derived from [DrugBank](https://oreil.ly/MYb6A),
    which provides extensive information about drugs and their interactions. While
    some of this information is included in the benchmark dataset, much more could
    be added, such as chemical properties, target genes, and other drug-specific details.
    However, access to the full DrugBank resource is not free for nonacademic users.
  prefs: []
  type: TYPE_NORMAL
- en: 'When working with our graph, we will mostly be dealing with node indices, but
    we can always look up the mapping between node ID and DrugBank drug IDs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This lookup allows us to look a bit deeper at the degree distribution observation
    from earlier. What are the drugs that bind many other drugs? Let’s examine the
    drugs with the highest number of edges. Since all but 14 drug interactions are
    represented twice in this dataframe (once as *A-B* and once as *B-A*), we can
    count on the `first drug name` column to get the most frequently binding drugs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 4-6](#top-interacting-drugs) visualizes the structure of these top
    interacting drugs. Interestingly, many of these drugs, such as desipramine, amitriptyline,
    and clomipramine, share a common three-ring (tricyclic) core structure, which
    may contribute to their similar interaction profiles.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dlfb_0406.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-6\. Chemical structures of the top 10 drugs with the highest number
    of drug–drug interactions in the dataset. Interestingly, many of these drugs,
    such as desipramine, amitriptyline, and clomipramine, share a common three-ring
    (tricyclic) core structure, which may contribute to their similar interaction
    profiles by promoting broad target binding and extensive metabolism via cytochrome
    P450 enzymes. Structures were acquired from DrugBank.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This list of drugs may seem a bit obscure if you’re not accustomed to memorizing
    drug names, but there are a few emergent patterns here:'
  prefs: []
  type: TYPE_NORMAL
- en: Affecting transporter proteins
  prefs: []
  type: TYPE_NORMAL
- en: The drug with the highest number of interactions (2,477) is quinidine, used
    to treat certain heart arrhythmias. Like other drugs on this list, such as clozapine
    and carbamazepine, quinidine interacts strongly with transporter proteins (with
    the most famous one being a protein called P-glycoprotein), which regulate the
    absorption and transport of many drugs across cells. This broad influence on drug
    levels largely explains its high interaction count in this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Affecting drug metabolism
  prefs: []
  type: TYPE_NORMAL
- en: Many of these drugs, like the antidepressants (desipramine, amitriptyline, clomipramine,
    imipramine), the antipsychotics (chlorpromazine, clozapine, haloperidol), and
    the mood stabilizer carbamazepine, are metabolized by the cytochrome P450 enzyme
    family in the liver. This system, introduced earlier, plays a major role in drug
    metabolism and is central to many drug interactions, because drugs that inhibit
    or activate cytochrome P450 enzymes can alter the metabolism of other drugs taken
    simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Dosage sensitivity
  prefs: []
  type: TYPE_NORMAL
- en: Finally, these top interacting drugs also tend to have narrow *therapeutic ranges*,
    meaning even small changes in blood concentrations can lead to adverse effects.
    This makes interactions more likely to occur and be noticed.
  prefs: []
  type: TYPE_NORMAL
- en: 'From this additional table of drug information, we can construct a lookup table
    of `node_id` to DrugBank `dbid` to drug names, allowing us to bring more biological
    context to our project as we start modeling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: For example, using this lookup table, we can see that node ID 935 corresponds
    to the drug memantine, which has the DrugBank ID DB01043.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing Graphs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let’s take a look at what a portion of this graph data actually looks like.
    The entire graph is too large to meaningfully visualize all at once, but we can
    sample a subgraph and visualize that. The strategy here is to select a subset
    of nodes from the original training graph and then subset the split dataset by
    these nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'This extracts a subgraph containing 50 nodes from the training set. We can
    visualize it in [Figure 4-7](#ddi-subgraph-plot) using the `plot_ddi_graph` function,
    which leverages the popular `networkx` library—a widely used Python tool for creating
    and visualizing graph structures:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/dlfb_0407.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-7\. A sampled subgraph of the DDI network, with nodes labeled by drug
    names. While this graph was sampled to just 50 nodes for clarity, the visualization
    already highlights the diversity of interactions, including densely connected
    drugs and more isolated drugs.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 4-7](#ddi-subgraph-plot) highlights the diversity of interactions,
    including densely connected clusters (e.g., around Clomipramine, an antidepressant)
    and isolated or sparsely connected drugs. While this graph was sampled for clarity,
    it illustrates how certain drugs act as hubs, reflecting their broad interaction
    profiles, and others interact more selectively, potentially due to specific biological
    mechanisms.'
  prefs: []
  type: TYPE_NORMAL
- en: With this initial data exploration complete, we’re ready to move on to building
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Building a Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having explored the dataset from `LinkPropPredDataset`, we now turn our attention
    to the process of preparing it for use in the JAX/Flax framework. Although the
    dataset isn’t out-of-the-box compatible, this offers a valuable opportunity to
    better understand the intricacies of graph processing. In this section, we’ll
    walk through the necessary adjustments to ensure that the dataset is properly
    formatted for our model.
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, we don’t have to start from scratch. The JAX ecosystem has `jraph`,
    a graph library that offers foundational, graph-aware classes and data structures,
    allowing us to build flexible graph processing models while benefiting from JAX’s
    speed and efficiency. If you’d like to explore `jraph` in more detail before diving
    into our implementation, we recommend this excellent tutorial on graph nets with
    `jraph` from DeepMind.^([6](ch04.html#id764))
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: PyTorch, particularly its extension library `pytorch-geometric`, is arguably
    the most comprehensive deep learning framework for working with graphs. It offers
    a robust toolkit that simplifies selecting graph models from a model zoo, handling
    efficient data loading, and working with convenient data classes. Datasets like
    OGBL have dedicated data loaders tailored for this framework. However, in this
    chapter, we are using `jraph`, as it integrates seamlessly with JAX, aligning
    better with our overall approach for the book.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started with building a dataset we can train models on. As mentioned,
    there are several ways to represent a graph, such as using an adjacency matrix
    or an edge list. Since we’re using `jraph`, we go for the edge-list format, the
    default, which is much more memory efficient for sparser datasets like a DDI network.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Dataset Builder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We have packaged the dataset building into a class called `DatasetBuilder`.
    As we go along, you’ll recognize many parts from the previous section where we
    explored the raw dataset. Let’s go through it step-by-step, starting with the
    main method, `build`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: During instantiation, the builder receives a `path` to ensure that the dataset
    is stored in the specified location, eliminating the need to redownload it every
    time. The `build` method then generates a dictionary where the keys indicate data
    splits, each associated with a `Dataset` value. We’ll examine the `Dataset` class
    in a little more detail shortly, but for now, think of it as a dataset bundle
    with convenience methods for easier handling during training. The parameters passed
    to `build` help with subsetting the graph, which we will also get into a little
    bit later.
  prefs: []
  type: TYPE_NORMAL
- en: Download the Raw Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Looking at the `build` code, we can see that the raw dataset is first downloaded,
    leveraging the `LinkPropPredDataset` we saw before. Since the training split does
    not have negative pairs, we add a `neg_edges` key to simplify later handling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Prepare the Annotation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The dataset annotation is not directly useful when training our model in this
    project, but it is handy to have readily accessible to perform all sorts of sanity
    checks. You will recognize the implementation from before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The annotation is the same for all the dataset splits; hence, we only need to
    prepare it once and assign it to the `Dataset`.
  prefs: []
  type: TYPE_NORMAL
- en: Prepare the Graph
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next we look at `prepare_graph`, one of the main functions of the dataset builder:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The `make_undirected` method ensures that the DDI graph is undirected, meaning
    the relationship between drugs *A-B* is equivalent to *B-A*. Since `jraph` does
    not offer a toggle between directed and undirected graphs, we need to represent
    all edges in both directions. This process, known as *symmetrizing* the graph,
    makes the adjacency relationships symmetric, effectively converting a directed
    graph into an undirected one. This transformation is applied across all dataset
    splits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Practically speaking, implementing this transformation is straightforward.
    We start with the `pos_pairs` and add a corresponding set of edges where the sender
    and receiver nodes are swapped:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we prepare the graph using the main parameters that `GraphsTuple` expects:
    `senders` and `receivers`, which define the edges by specifying the source and
    destination nodes. Each node or edge can be annotated (although they are not here),
    with node annotations stored in `nodes` and edge annotations in `edges`. In addition,
    `GraphsTuple` incorporates metadata such as `n_nodes` and `n_edges`, which indicate
    the number of nodes and edges, respectively, and `globals`, which can store graph-level
    information such as a unique graph identifier or aggregated features. While we
    won’t use `globals` here, it remains available for scenarios requiring data applicable
    to the entire graph.'
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You may wonder why we sometimes need to pass the number of nodes independently
    from the graph. Why can’t this be inferred from the edges? This is because inferring
    node count from edges could miss isolated nodes, which have no connections to
    other nodes (i.e., no interactions with other drugs).
  prefs: []
  type: TYPE_NORMAL
- en: In general, `GraphsTuple` is a versatile data structure that can host data in
    various ways. Instead of having one `GraphsTuple` per data split, we could construct
    a single graph containing both training and evaluation datasets, using the `nodes`
    attribute to specify which set each node belongs to.
  prefs: []
  type: TYPE_NORMAL
- en: Prepare the Pairs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the graph in place, we use the `prepare_pairs` method to obtain the drug–drug
    pairs—both positive and negative—that the model will classify as either connected
    or not:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: For evaluation datasets, preparing pairs is straightforward, as we can directly
    use the positive and negative pairs provided by the OGBL dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You might wonder why we don’t use the edges from the graph we just created to
    generate the positive pairs. The reason is that since we made the graph undirected,
    each positive pair is represented twice, which could lead to redundancy and errors
    during evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the training dataset, preparing pairs is slightly more complex because
    negative pairs are not provided and must be inferred using the `infer_negative_pairs`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: The method begins by constructing an adjacency matrix and initializing it with
    zeros using NumPy. It then marks all existing edges with ones. To identify negative
    edges, the method flips the matrix values so that connections become zeros and
    nonconnections become ones. Finally, it retains only the upper triangle (`triu`)
    of the matrix (excluding the diagonal) to avoid self-loops and duplicate pairs.
    The remaining nonzero entries are converted into an edge list of negative node
    pairs.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting negative pairs far outnumber the positive pairs due to the graph’s
    sparsity. This imbalance can be advantageous, as it provides more examples of
    negative edges to sample. However, as mentioned previously, the way negative pairs
    are sampled significantly affects performance, as some pairs are trivial to predict
    as being unconnected. We will need to carefully select a fair subset of negative
    pairs during training.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Using an adjacency matrix approach assumes that it can fit into memory. If this
    is not feasible, alternative methods for generating negative node pairs include
    sampling a noncomprehensive subset or using efficient implementations that rely
    on sparse adjacency matrices.
  prefs: []
  type: TYPE_NORMAL
- en: The positive and negative pairs are then encapsulated in a `Pairs` data class,
    which we’ll examine further during training. It is a simple data class that stores
    arrays of positive and negative pairs and includes utilities for subsampling pairs
    during learning and accessing pairs in batches.
  prefs: []
  type: TYPE_NORMAL
- en: Subsetting the Graph
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To efficiently explore how a model learns from graphs, it is useful to be able
    to create a smaller subset of the dataset. This allows us to work with a more
    manageable graph size for experimentation. The subset method does exactly that:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: It selects a subset of nodes based on a specified `node_limit` and applies this
    subset consistently across all dataset splits (i.e., training, validation, test).
    By default, the subsetted graph renumbers the node IDs to create a smaller, compact
    graph. However, you can retain the original node IDs from the full dataset by
    setting the `keep_original_ids` parameter to `True`.
  prefs: []
  type: TYPE_NORMAL
- en: The Dataset Class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we have all the pieces in place to create a `Dataset` class that will
    enable flexible exploration of the graph along with its annotations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Here, we show only the `Dataset` fields, but the class also provides several
    useful methods. Notably, it handles subsetting the graph and managing annotations
    consistently behind the scenes. While we encourage you to explore the code online
    to get a better sense of its functionality, understanding every detail isn’t necessary
    to begin training.
  prefs: []
  type: TYPE_NORMAL
- en: Building a Prototype
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s start simple. We need to build a model that predicts links between nodes.
    We’ll do this using only the graph’s connectivity—no node features or annotations.
    Surprisingly, this connectivity information alone can be quite powerful for learning
    which node pairs are likely to be connected.
  prefs: []
  type: TYPE_NORMAL
- en: While link prediction can be framed as a binary classification task (i.e., connection
    versus no-connection), it differs from typical classification problems in key
    ways. The input to the model is not a single node or feature vector, but a pair
    of nodes, and the prediction depends on their structural relationship in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our prototype model will be made up of several key components, some defined
    directly within the model and others handled as part of the training process:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Model components:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Neighborhood encoding: Generates node embeddings that reflect the local graph
    structure'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Link prediction: Uses these embeddings to score the likelihood of a connection
    between node pairs'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Training components:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Negative sampling: Selects unconnected node pairs to contrast with true edges'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Loss function: Computes the training signal to optimize model performance'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We begin by focusing on the most crucial part: how we encode each node’s local
    neighborhood.'
  prefs: []
  type: TYPE_NORMAL
- en: Node Encoder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Arguably the most impactful choice for our model is how we encode the nodes’
    neighborhood. For this, we use a GraphSAGE-inspired implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'The main input parameters to the module are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`n_nodes`'
  prefs: []
  type: TYPE_NORMAL
- en: Defines the total number of nodes in the original graph.
  prefs: []
  type: TYPE_NORMAL
- en: '`embedding_dim`'
  prefs: []
  type: TYPE_NORMAL
- en: Specifies the dimensionality of the node embeddings. This controls how richly
    the model can represent neighborhood information. Lower values (e.g., 16 or 32)
    may limit expressiveness, while higher values (e.g., 128 or 256) offer more capacity
    at the cost of increased computation. In practice, smaller graphs can support
    higher embedding dimensions, while larger graphs benefit from lower values here.
  prefs: []
  type: TYPE_NORMAL
- en: '`dropout_rate`'
  prefs: []
  type: TYPE_NORMAL
- en: Sets the fraction of neurons randomly deactivated during training to reduce
    overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: '`last_layer_self` and `degree_norm`'
  prefs: []
  type: TYPE_NORMAL
- en: Configure aspects of the graph convolution behavior, which are described in
    more detail in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: At the heart of GraphSAGE is the `node_embeddings` matrix. In the `setup` method,
    this is initialized as a learnable parameter using `nn.Embed`, with shape `[n_nodes,
    embedding_dim]`. The embeddings are initialized using the `glorot_uniform` method
    to promote stable training dynamics. During training, these embeddings are updated
    by aggregating information from each node’s neighbors, gradually encoding higher-order
    structural patterns. The goal is for these embeddings to converge to representations
    that reflect the likelihood of connections between node pairs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main logic of the encoder is implemented in the `__call__` method. One
    important (though hard-coded) design choice here is the number of `SAGEConv` layers,
    which defines how many rounds of message passing are applied:'
  prefs: []
  type: TYPE_NORMAL
- en: With one layer, each node aggregates information from its immediate neighbors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With two layers, each node can access information from neighbors up to two hops
    away.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thus, the number of layers controls the receptive field of each node. Between
    layers, ReLU activation introduces nonlinearity, and dropout is applied for regularization
    to prevent overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Graph Convolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ve now reached the core architectural component of our model: the `SAGEConv`
    layer. Let’s dive into it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: When setting up a `SAGEConv` layer, we specify the embedding dimension (using
    `embedding_dim`), whether to add self-loops (`with_self`), and whether to apply
    degree normalization (`degree_norm`). The latter two options are optional, as
    their impact on model performance depends on the dataset’s characteristics, such
    as size and connectivity patterns. Enabling or disabling these features can significantly
    influence model behavior.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each `SAGEConv` layer performs the following key steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Optionally adds self-edges
  prefs: []
  type: TYPE_NORMAL
- en: Allows each node to consider its own embedding during aggregation
  prefs: []
  type: TYPE_NORMAL
- en: Aggregates neighborhood embeddings
  prefs: []
  type: TYPE_NORMAL
- en: Collects and averages the embeddings of each node’s neighbors
  prefs: []
  type: TYPE_NORMAL
- en: Optionally normalizes by degree
  prefs: []
  type: TYPE_NORMAL
- en: Scales the contribution of neighbors based on their degree, reducing bias from
    highly connected nodes
  prefs: []
  type: TYPE_NORMAL
- en: Combines embeddings with neighbors
  prefs: []
  type: TYPE_NORMAL
- en: Merges the original node embeddings with the aggregated neighbor embeddings
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When reading the implementation of the `SAGEConv` convolutional layer, you
    might be wondering: *where’s the convolution?*'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike convolutional neural networks (CNNs) for images or sequences, where `nn.Conv`
    applies spatial filters over regular grids, graph neural networks define “convolution”
    more abstractly. In GNNs, convolution means aggregating information from a node’s
    local neighborhood and combining it with its own embedding. This is implemented
    using operations like `segment_mean`, followed by a learnable transformation—typically
    via `nn.Dense`. So, while you won’t see an explicit `nn.Conv` in `SAGEConv`, the
    dense layer at the end serves as the core trainable part of the “graph convolution.”
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth noting that `SAGEConv` focuses solely on aggregation and linear transformation.
    It does not include nonlinear activations, batch normalization, or dropout—those
    are typically applied at the model level to allow for greater flexibility and
    reuse.
  prefs: []
  type: TYPE_NORMAL
- en: Adding self edges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the `NodeEncoder`, we use two `SAGEConv` layers, and the first layer has
    the `with_self` parameter set to `True`. Adding self-loops ensures that a node’s
    own embedding is included in the aggregation process during neighborhood updates
    (by including the node in its own list of senders). Without self-loops, a node’s
    updated embedding would reflect only information from its neighbors, potentially
    biasing the representation away from its original identity. Including self-loops
    allows each node to contribute to its own update, balancing its existing features
    with neighborhood context.
  prefs: []
  type: TYPE_NORMAL
- en: This can be accomplished by adding ones to the diagonal of the adjacency matrix,
    effectively connecting each node to itself. In our implementation, the `with_self`
    and `last_layer_self` parameters control whether self-loops are included in the
    first and second `SAGEConv` layers, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Even without explicit self-loops, models can preserve a node’s identity by using
    skip connections. For example, in our implementation, we concatenate the original
    and updated embeddings using `combined_embeddings = jnp.concatenate([x, x_updated],
    axis=-1)`. This helps retain the node’s original features. However, it differs
    from self-loops in that the original embedding is added after the neighborhood
    aggregation, not as part of it. Including self-loops ensures that the node’s identity
    contributes directly to the aggregation step itself.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregating the neighborhood
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We now turn to the core operation of message passing: aggregating information
    from each node’s neighborhood.'
  prefs: []
  type: TYPE_NORMAL
- en: This is the first point where the graph structure is explicitly used. For each
    edge, the sender node’s embedding (or features) is gathered and aggregated on
    a per-receiver basis. In other words, each receiver node updates its embedding
    by combining information from all its connected senders. The result is a new representation
    that reflects the structure and features of its local neighborhood.
  prefs: []
  type: TYPE_NORMAL
- en: In our implementation, we use `jraph.segment_mean` as the aggregation function,
    which computes the mean of sender embeddings for each receiver. Other common choices
    include sum, max, or even attention-weighted aggregation, as used in GAT-style
    models. The optimal aggregation method often depends on the graph’s topology and
    the downstream task, so experimenting with different strategies can be valuable.
  prefs: []
  type: TYPE_NORMAL
- en: Normalizing by degree
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Degree normalization ensures that all nodes, regardless of their connectivity,
    contribute more evenly during training. This can help stabilize optimization,
    avoiding exploding or vanishing gradients. However, excessive normalization may
    *over-smooth* node embeddings, potentially erasing finer details of a node’s local
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our implementation, we apply *symmetric degree normalization*, which works
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Messages are divided by the square root of the *sender’s degree* before aggregation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The aggregated result is then divided by the square root of the *receiver’s
    degree*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This square-root scaling—common in various flavors of GNNs—balances message
    influence across nodes while avoiding unintended scaling effects.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Whether degree normalization improves performance depends on the dataset and
    its structural properties. It’s especially helpful in graphs with a high degree
    of variability, where a few high-degree nodes might otherwise dominate message
    passing. It also improves stability in deeper GNNs by keeping signal magnitudes
    under control.
  prefs: []
  type: TYPE_NORMAL
- en: However, in graphs where raw connection strength or node centrality carries
    important meaning—such as physical interaction networks, citation graphs, or transportation
    systems—normalization may suppress informative signals. If time allows, it’s often
    worth comparing normalized and unnormalized variants during model development.
  prefs: []
  type: TYPE_NORMAL
- en: Combining embeddings with neighborhoods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After aggregation (and optional normalization), we combine the updated node
    embeddings with the original embeddings—typically by concatenation. This produces
    a unified representation that captures both the node’s initial features and the
    information gathered from its local neighborhood. This enrichment step ensures
    that embeddings reflect both individual identity and structural context.
  prefs: []
  type: TYPE_NORMAL
- en: 'Concatenating the original and aggregated embeddings doubles the feature dimensionality.
    To bring this back to the intended embedding size, the combined vector is passed
    through a fully connected `Dense` layer. This layer serves two key purposes:'
  prefs: []
  type: TYPE_NORMAL
- en: Maintains consistent dimensionality
  prefs: []
  type: TYPE_NORMAL
- en: Projects the concatenated vector back to the original embedding size, ensuring
    compatibility with the next model layer
  prefs: []
  type: TYPE_NORMAL
- en: Learns better representations
  prefs: []
  type: TYPE_NORMAL
- en: Learns how to optimally fuse original and neighborhood features, enabling the
    model to refine what information to retain or emphasize
  prefs: []
  type: TYPE_NORMAL
- en: Because the `Dense` transformation is learnable, the model adapts over training
    to make the most effective use of both types of input.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: During model training, the graph structure remains fixed. Only the `node_embeddings`
    are updated, evolving over time as the model learns from the neighborhood aggregation
    and feature transformation process.
  prefs: []
  type: TYPE_NORMAL
- en: Link Prediction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We now use the learned node embeddings to predict whether a given pair of nodes
    is connected. If the embeddings have effectively captured the graph’s structure,
    the model should be able to assign high scores to true edges and low scores to
    unrelated node pairs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at how the embeddings are used in the `LinkPredictor` module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The `LinkPredictor` takes a pair of node embeddings—one from the sender and
    one from the receiver—and estimates the likelihood of an edge between them. Here’s
    how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: Combining embeddings
  prefs: []
  type: TYPE_NORMAL
- en: The sender and receiver embeddings are combined using element-wise multiplication.
    This operation captures the interaction between corresponding dimensions of each
    embedding, producing a fixed-size vector that reflects their pairwise compatibility.
  prefs: []
  type: TYPE_NORMAL
- en: Transforming representations
  prefs: []
  type: TYPE_NORMAL
- en: The combined vector is passed through a multilayer perceptron (MLP), consisting
    of several `Dense` layers with ReLU activation and dropout. These layers are defined
    by the `n_layers` and `embedding_dim` parameters and serve to learn increasingly
    abstract representations of the node pair interaction.
  prefs: []
  type: TYPE_NORMAL
- en: Output layer
  prefs: []
  type: TYPE_NORMAL
- en: The final layer is a single-neuron `Dense` layer that outputs a logit—an unnormalized
    score representing the likelihood of an edge. During training, this logit is passed
    through a sigmoid to produce a probability between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: The overall goal is for the model to learn to output high scores for true (positive)
    edges and low scores for negative edges, forming the basis for binary link prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Drug–Drug Interaction Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s now put everything together into a `DdiModel` that we can train:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s walk through the main components of this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`setup` method: Initializes two core submodules:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`node_encoder`: Generates node embeddings from the input graph'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`link_predictor`: Scores node pairs based on their embeddings to predict the
    presence or absence of an edge'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`__call__` method: Defines the forward pass of the model and supports both
    training and inference:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `node_encoder` computes embeddings `h` for all nodes in the graph. The use
    of `h` as a variable name follows a common convention, where `h` represents a
    “hidden state” or embedding.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If `is_pred=False` (training mode):'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Positive pairs: The model passes sender and receiver embeddings through the
    `link_predictor` to estimate connection likelihood.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Negative pairs: Similarly processed to estimate nonconnection scores.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Returns a dictionary of predicted scores for both “pos” and “neg” pairs.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And if `is_pred=True` (inference mode): Takes an arbitrary array of node pairs
    and returns predicted scores. This enables applying the model to new or unseen
    node pairs after training.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`create_train_state` method: Sets up the training process:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Initializes model parameters using dummy inputs and a random seed
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Constructs a `TrainState` object with the model’s `apply_fn`, parameters, optimizer
    (`tx`), and dropout key for training
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`add_mean_embedding` static method: Appends a global mean embedding to the
    existing embedding matrix. This can be useful in downstream tasks where a graph-level
    summary representation is desired.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together, these components define a full link prediction pipeline for drug–drug
    interaction graphs. Next, we’ll look at how to train this model end to end.
  prefs: []
  type: TYPE_NORMAL
- en: Training the Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: From the previous sections, we have established how to prepare datasets and
    define a model. Now we’ll proceed by creating instances of both before moving
    forward with training.
  prefs: []
  type: TYPE_NORMAL
- en: Create a Manageable Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will create a subset containing approximately 10% of the total graph data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: By reducing the dataset size, we create a graph that is easier to handle during
    initial experimentation. This smaller graph allows us to test the model architecture
    and training setup more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: We now have a graph with a set of positive and negative node pairs that we can
    learn from. The visualization in [Figure 4-8](#ddi-training-subgraph) provides
    a high-level view of the training dataset’s structure, where nodes represent drugs
    and edges represent interactions between them. The circular layout arranges all
    nodes around a circle, with edges connecting related nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dlfb_0408.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-8\. Circular layout of training dataset of 500 nodes. Each node represents
    a drug, and edges represent interactions between them.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: While the individual node labels and details may not be legible in this plot,
    it offers a broad overview of key graph properties. These include the density
    of connections, overall sparsity, and presence of clusters or isolated nodes.
    This visualization illustrates the graph’s complexity, despite being a small subsampled
    set.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: Create the Training Loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, let’s examine the training loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The `train` function coordinates the entire training process, broken down into
    several key stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Initialization*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Initializes a `MetricsLogger` to track training and evaluation metrics
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimates an optimal batch size using the `optimal_batch_size` function
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Displays training progress using a `tqdm` progress bar
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Training over epochs*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each epoch:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Sets up random number generators (`rng`) for shuffling and sampling training
    pairs.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The training set is iterated over in batches using `get_train_batches`, which
    samples positive and negative node pairs.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Each batch is passed to `train_step`, which updates model parameters based on
    the current loss.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Training metrics (e.g., loss and hits@20) are logged after each batch via `metrics.log_step`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Evaluation*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At intervals defined by `eval_every`, the model is evaluated on the validation
    set using `get_eval_batches` and `eval_step`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation metrics are logged via `metrics.log_step`, and summary statistics
    are printed using `metrics.latest()`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additional features of this training loop include:'
  prefs: []
  type: TYPE_NORMAL
- en: Support for custom loss functions
  prefs: []
  type: TYPE_NORMAL
- en: A user-defined `loss_fn` can be passed in to control the optimization objective.
  prefs: []
  type: TYPE_NORMAL
- en: Optional loss normalization
  prefs: []
  type: TYPE_NORMAL
- en: Controlled by the `norm_loss` flag. When `True`, the loss is averaged over examples
    to ensure scale invariance across batch sizes.
  prefs: []
  type: TYPE_NORMAL
- en: Restorable training state
  prefs: []
  type: TYPE_NORMAL
- en: The function is decorated with `@restorable`, enabling checkpointing and resumption
    of training mid-run.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset is processed in batches using the `Pairs` class, which handles consistent
    sampling of node pairs for both training and evaluation. We’ll take a closer look
    at how this class works next.
  prefs: []
  type: TYPE_NORMAL
- en: Create the Pairs Class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `Pairs` class is a utility that simplifies the handling of positive and
    negative node pairs during training and evaluation. You’ve already seen it in
    action within the training loop. Here, we’ll break down its functionality more
    explicitly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The class provides several key methods for batching and sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: '`get_eval_batches`'
  prefs: []
  type: TYPE_NORMAL
- en: Returns evaluation batches of positive and negative pairs, ensuring shape alignment
    and balanced sizes. It slices the `pos` and `neg` arrays using the same indices,
    up to the size of the smaller set.
  prefs: []
  type: TYPE_NORMAL
- en: '`get_train_batches`'
  prefs: []
  type: TYPE_NORMAL
- en: Returns shuffled training batches. Positive pairs are shuffled using `rng_shuffle`,
    and fresh negative pairs are sampled using `_global_negative_sampling`. This introduces
    variation between epochs and improves generalization.
  prefs: []
  type: TYPE_NORMAL
- en: '`get_dummy_input`'
  prefs: []
  type: TYPE_NORMAL
- en: Returns a very small batch (two positive and two negative pairs). This is useful
    to get the correct shape of data that we can use to initialize the model parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Together, these methods enable consistent and efficient batch generation for
    both training and evaluation, while introducing enough variability to improve
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Batching by pairs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'During each epoch, we must process a large number of positive and negative
    node pairs. As we’ve seen in the introduction to graph convolution layers, calculating
    node embeddings for large networks can become computationally expensive. To address
    this, we use batching—processing subsets of the data one at a time. This strategy
    is applied to both training and evaluation data, with some key differences:'
  prefs: []
  type: TYPE_NORMAL
- en: Training batches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `get_train_batches` method provides batches of positive and negative pairs,
    shuffling the data at the start of every epoch to introduce diversity in the order
    of pairs.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Negative pairs are resampled once per epoch using the `_global_negative_sampling`
    method. This variation helps the model learn from a more diverse set of examples.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation batches
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `get_eval_batches` method returns batches of positive and negative pairs
    according to the specified `batch_size`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: To ensure compatibility, the `_n_pairs` method limits the batch size to the
    smaller of the positive or negative sets, so the two arrays match in shape.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation batches are processed in a fixed order for reproducibility and consistent
    metrics across runs. This deterministic behavior simplifies debugging and ensures
    that order-sensitive metrics like Hits@K and MRR are stable.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: To maintain uniform batch sizes, the `Pairs` class drops the final incomplete
    batch during both training and evaluation. This avoids irregularities in computation.
    Over multiple epochs, shuffling ensures that all data points are eventually seen,
    even if some are skipped in a single run.
  prefs: []
  type: TYPE_NORMAL
- en: 'To maximize efficiency, we use the `optimal_batch_size` utility function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This function computes the largest batch size that minimizes dropped data and
    ensures consistency across training and evaluation. It balances computational
    efficiency and data utilization by selecting sizes that are both large and compatible
    with the dataset structure.
  prefs: []
  type: TYPE_NORMAL
- en: Consistent batch sizes are critical for optimizing jitted functions, which rely
    on static input shapes. They prevent unnecessary recompilation, improve memory
    and compute efficiency on accelerators like GPUs and TPUs, and reduce the complexity
    of handling irregular input.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling negative pairs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An important aspect of training is how we sample negative pairs. Since there
    are many more pairs without connections than with connections, we cannot use all
    negative examples; doing so would create a highly imbalanced training dataset.
    Instead, we select a subset of negative pairs to balance the dataset. This is
    where `_global_negative_sampling` comes in.
  prefs: []
  type: TYPE_NORMAL
- en: 'The subset of negative samples can significantly impact training. In this implementation,
    we use the simplest approach: *global sampling*, where we uniformly sample from
    all possible negative pairs. This strategy is suitable when we are broadly interested
    in potential node connections across the entire graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'While global sampling is straightforward and effective, many alternative strategies
    exist that drive the model to learn different patterns. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: Local sampling
  prefs: []
  type: TYPE_NORMAL
- en: Ensures that negative pairs share at least one sender node, focusing on pairs
    that are structurally similar to positive pairs. This can help the model learn
    more fine-grained distinctions.
  prefs: []
  type: TYPE_NORMAL
- en: Hard negative sampling
  prefs: []
  type: TYPE_NORMAL
- en: Selects negative pairs that the model struggles to classify as negatives (i.e.,
    pairs with a high predicted likelihood of being connected, even though they are
    not). This approach forces the model to improve on challenging cases and can accelerate
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Adversarial negative sampling
  prefs: []
  type: TYPE_NORMAL
- en: Generates challenging negative pairs using an adversarial approach, where a
    secondary model selects negatives that maximize the main model’s loss. While computationally
    expensive, it can lead to robust embeddings and improved performance.
  prefs: []
  type: TYPE_NORMAL
- en: Ratio of positive to negative pairs
  prefs: []
  type: TYPE_NORMAL
- en: Balances the number of positive and negative pairs in the dataset. While a 1:1
    ratio is common, some tasks may benefit from a higher ratio of negatives (e.g.,
    1:5). In our DDI problem, we explored varying the ratio, but it did not significantly
    impact performance (not shown) and introduced unnecessary complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Create the Train Step Function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `train_step` function is where learning actually happens during training.
    It performs a forward pass, computes the loss, and applies gradients to update
    the model’s parameters. This function is applied to batches of node pairs throughout
    each epoch.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: You’ll notice that the function is decorated using `@partial(jax.jit, static_argnames=["loss_fn",
    "norm_loss"])`. This pattern allows these arguments—the loss function (`loss_fn`)
    and whether to normalize the loss (`norm_loss`)—to be treated as static during
    JAX’s just-in-time (JIT) compilation. By marking these arguments as static, JAX
    avoids recompiling the function every time they change.
  prefs: []
  type: TYPE_NORMAL
- en: 'Inside the function, a nested `calculate_loss` method defines the core of the
    computation:'
  prefs: []
  type: TYPE_NORMAL
- en: The model is applied to the current batch using `state.apply_fn(...)`, producing
    predictions (`scores`) for positive and negative node pairs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The specified `loss_fn` is used to compute the training loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `evaluate_hits_at_20` function computes the `hits@20` metric to track how
    well the model ranks correct node pairs near the top.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: JAX’s `value_and_grad` is then used to calculate both the loss and its gradient
    with respect to the model parameters. These gradients are applied to the training
    state using `state.apply_gradients`.
  prefs: []
  type: TYPE_NORMAL
- en: If `norm_loss=True`, the total loss is divided by the number of training pairs
    in the batch (positive + negative), ensuring that loss magnitudes remain comparable
    across different batch sizes or sampling ratios.
  prefs: []
  type: TYPE_NORMAL
- en: 'The default loss function used in training is the binary log loss function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'This loss function performs the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Sigmoid transformation
  prefs: []
  type: TYPE_NORMAL
- en: Converts the raw logits (unbounded scores) into probabilities in the range (0,
    1). These probabilities represent the model’s confidence that a given node pair
    is a positive class (i.e., a true drug–drug interaction).
  prefs: []
  type: TYPE_NORMAL
- en: Clipping
  prefs: []
  type: TYPE_NORMAL
- en: Ensures numerical stability by constraining probabilities to lie slightly within
    (0, 1). This avoids issues such as `log(0)`, which can cause the loss to diverge
    or return `NaN` during training.
  prefs: []
  type: TYPE_NORMAL
- en: Loss calculation
  prefs: []
  type: TYPE_NORMAL
- en: Ensures that positive pairs are penalized when their predicted probabilities
    are far from 1, and negative pairs are penalized when their predicted probabilities
    are far from 0\. The total loss is computed as the average of the positive and
    negative log losses.
  prefs: []
  type: TYPE_NORMAL
- en: This loss provides a simple yet effective objective for training the model to
    distinguish between interacting and noninteracting drug pairs.
  prefs: []
  type: TYPE_NORMAL
- en: Create the Evaluation Metric
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we want to evaluate the model’s performance. This follows a similar
    approach to `train_step`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The notable differences in `eval_step` are:'
  prefs: []
  type: TYPE_NORMAL
- en: No training mode
  prefs: []
  type: TYPE_NORMAL
- en: The `is_training` flag is set to `False`, which disables behaviors like dropout
    and ensures that the model is evaluated deterministically.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation metric
  prefs: []
  type: TYPE_NORMAL
- en: Rather than just returning the loss, the function also computes `hits@20`, a
    ranking-based metric commonly used in link prediction tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Hits@20 evaluates how well the model ranks positive node pairs compared to negative
    ones, giving an intuitive signal of ranking quality. Specifically, it identifies
    the 20th highest score among the negative pairs as a threshold and calculates
    the proportion of positive scores that exceed this threshold; then it calculates
    the proportion of positive scores that exceeds this threshold. A higher Hits@20
    indicates that the model correctly ranks many true interactions above even one
    of the most confident false ones.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We could have imported the `ogb.linkproppred.Evaluator` from the Open Graph
    Benchmark (OGB) library, which computes Hits@20\. However, by directly implementing
    the metric, we make the evaluation process more transparent and tailored to our
    specific use case. This approach provides greater flexibility for modifications
    and extensions while clearly showing how the model is evaluated.
  prefs: []
  type: TYPE_NORMAL
- en: Train the Simplest Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are finally ready to train the model. We’ll start with a relatively simple
    architecture and monitor its performance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: The learning curves in [Figure 4-9](#ddi-simplest-model) show the training process
    over 500 epochs. The training loss decreases steadily and the Hits@20 metric improves
    on both training and validation sets. However, the growing divergence between
    the training and validation curves—particularly visible in the later epochs—suggests
    moderate overfitting. This indicates that while the model is capturing meaningful
    patterns, its generalization to unseen data could be improved.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/dlfb_0409.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-9\. Learning curves showing the training loss (left) and Hits@20 metric
    (right) over 500 epochs. While both metrics improve on the training set, a growing
    gap between training and validation suggests moderate overfitting.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'A word of warning: two sources of variance can lead to surprisingly different
    metrics curves in this plot—even with the same model and training setup.'
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic node sampling
  prefs: []
  type: TYPE_NORMAL
- en: Graph neural networks that use neighborhood sampling can be highly sensitive
    to the random seed. In drug–drug interaction prediction, some nodes are connected
    to many easily predictable links, while others are not. Which nodes get included
    in your training data can have a major impact on the learned representations,
    loss, and evaluation metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Discontinuous metrics
  prefs: []
  type: TYPE_NORMAL
- en: 'Hits@20 is a ranking-based metric that compares each positive score to the
    20th highest negative score. This thresholding introduces discontinuity: a small
    change in any score near the threshold—especially among the top-ranked negatives—can
    flip the outcome for many positives from success to failure or vice versa. This
    makes Hits@20 unusually sensitive to minor score shifts, even when the model or
    loss appears unchanged. This doesn’t mean it’s a bad metric—just something to
    be aware of.'
  prefs: []
  type: TYPE_NORMAL
- en: To reduce this variability, we can increase the number of nodes we include in
    the dataset (as shown in [“Train on a Larger Dataset”](#training-on-a-larger-dataset)).
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve trained a first working model, we’ll explore strategies to reduce
    overfitting and improve overall performance.
  prefs: []
  type: TYPE_NORMAL
- en: Improving the Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Everything is working end-to-end—we have prepared a dataset, built a model,
    and trained it. However, the model’s performance is suboptimal. In this section,
    we’ll explore some tweaks to see if we can achieve better results.
  prefs: []
  type: TYPE_NORMAL
- en: Change to AUC Loss
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we’ve used binary log loss to train our model. However, for our task,
    the primary goal is to ensure that positive pairs are ranked higher than negative
    pairs. While probabilities can also be used to prioritize, they often saturate
    near 1 or 0 for confident predictions, making it harder to differentiate between
    highly ranked pairs. In contrast, ranking-based metrics focus on the relative
    ordering of scores, which better aligns with the task of identifying and prioritizing
    the most promising drug interactions. This is particularly valuable in DDI prediction,
    where the goal is often to focus on the top-scoring pairs for further investigation.
  prefs: []
  type: TYPE_NORMAL
- en: Inspired by a paper on pairwise learning for neural link prediction (PLNLP),^([7](ch04.html#id808))
    which outlines key stages of a link prediction pipeline, we will swap the loss
    function to better align with our objective. Instead of focusing on binary classifications,
    we adopt a ranking-based approach that encourages the model to score connected
    pairs higher than unconnected ones, aligning conceptually with the area under
    the curve (AUC) metric.
  prefs: []
  type: TYPE_NORMAL
- en: AUC measures the probability that a randomly chosen positive instance (connected
    node pair) has a higher score than a randomly chosen negative instance (nonconnected
    pair). While directly optimizing AUC would be ideal, it is computationally challenging
    because its gradients are often undefined or zero. To address this, we use a *surrogate
    loss function* that mimics AUC’s properties while remaining easy to optimize.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple and effective surrogate is the squared loss, which penalizes deviations
    from the target score difference of 1 between positive and negative pairs. This
    means the model is penalized both when the difference is less than 1 (underestimation)
    and when it is greater than 1 (overestimation). By minimizing this penalty, the
    model learns to consistently assign higher scores to connected pairs while maintaining
    an appropriate margin over unconnected ones. Here’s the implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This loss function encourages the model to score linked pairs higher than nonlinked
    pairs, improving its ranking performance. The motivation for discarding the cross-entropy
    loss is that the Hits@N metric, commonly used by Open Graph Benchmark (OGB) for
    evaluating link prediction benchmarks, does not measure the quality of predicted
    probabilities. Instead, it focuses solely on ensuring that true edges are ranked
    higher than false edges. Although the difference between these approaches is subtle,
    it has significant practical implications. Let’s explore the effect of the loss
    function switch on the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'From the learning curves in [Figure 4-10](#ddi-simplest-auc-model), we can
    see that changing the loss function to an AUC-based objective has led to better
    results. First, training is noticeably smoother: the training and validation losses
    fall in near-lockstep, with virtually no gap. Second, Hits@20 climbs more quickly
    and saturates at a higher level on the validation set than before, reflecting
    stronger generalization. In short, aligning the objective with our ranking metric
    directly translates into better and more reliable performance.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/dlfb_0410.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-10\. Learning curves for loss (left) and Hits@20 (right) after replacing
    binary-cross-entropy with an AUC-optimizing loss. The new objective keeps train
    and validation losses tightly coupled and pushes the validation Hits@20 to higher,
    stabler values.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It appears that this model is already fairly strong as measured by our choice
    of metric, but let’s see if we can push performance even higher and reduce overfitting
    further by exploring hyperparameter sweeps.
  prefs: []
  type: TYPE_NORMAL
- en: Set Model Sweeping and Training Parameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our model and training loop include several hyperparameters, and it’s not immediately
    clear which combinations will yield the best performance. One natural starting
    point is the embedding dimension, which directly controls the capacity of the
    model to richly represent graph structure.
  prefs: []
  type: TYPE_NORMAL
- en: Varying embedding dimensions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will vary the `embedding_dim` parameter and train new models for each value
    to evaluate its impact on performance. Since previous experiments showed improved
    results with longer training, we will also extend the number of epochs in this
    sweep:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The following loop automates training across a range of `embedding_dim` values,
    storing the evaluation metrics for later analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'As shown in [Figure 4-11](#ddi-sweep-embedding-dim), there’s a clear relationship
    between embedding size and model performance: larger embedding vectors tend to
    yield better validation metrics. This is likely because higher-dimensional embeddings
    provide greater capacity to capture complex relationships and patterns in the
    graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/dlfb_0411.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-11\. Maximum Hits@20 achieved by models with varying embedding dimensions,
    highlighting the impact of embedding size on performance.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The model with embedding dimensions set to 512 seem to achieve a perfect Hits@20
    of ~1 on the training set, suggesting that it has sufficient capacity to fully
    (and even overly) fit the training data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Increasing the embedding size and training the model for longer, as we have
    done in this section, comes with higher computational costs. Whether this trade-off
    is worthwhile depends on the resources available and the relative importance of
    improving model performance in your specific use case.
  prefs: []
  type: TYPE_NORMAL
- en: Varying multiple hyperparameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For this experiment, we broaden our search by sweeping over multiple model hyperparameters
    simultaneously. This builds on the previous experiment but explores a wider region
    of the hyperparameter space in the hopes of discovering better-performing configurations.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will vary the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Dropout rate: 0, 0.3, or 0.5'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Self-edges in the last convolutional layer: Whether to include self-edges (`last_layer_self`:
    True or False)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Degree normalization: Whether to normalize node embeddings by their degree
    (`degree_norm`: True or False)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Number of MLP layers in the link predictor: 1, 2, or 3 (`n_mlp_layers`)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For this experiment, we fix the embedding dimension at 512, as it was among
    the best-performing settings in the earlier sweep. While an embedding size of
    256 also performed reasonably well and would reduce computational cost, we opt
    for 512 in anticipation of scaling to larger graphs. A larger embedding size offers
    greater capacity to model complex relational patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s set up the sweep:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'To train models with each parameter combination, we use the following approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Similar to the earlier experiment, this loop automates the process of training
    models across all parameter combinations. Each model’s performance is evaluated,
    and metrics such as Hits@20 are recorded for later analysis.
  prefs: []
  type: TYPE_NORMAL
- en: We then calculate the maximum Hits@20 metric for each parameter combination
    and split. Additionally, we generate a more readable representation for the convolutional
    layer configurations used in the encoder. This systematic exploration helps us
    identify the most effective combinations of hyperparameters for optimizing the
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then extract the maximum Hits@20 metric for each parameter combination and
    split:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: Next, in [Figure 4-12](#ddi-sweep-all), we visualize an overview of model performance
    across different hyperparameter combinations. This plot contains a lot of information,
    so let’s first clarify how to interpret it. Each pair of points represents the
    training and validation Hits@20 scores for a single model configuration. Our goal
    is to identify configurations where validation performance is high and closely
    matches training performance—suggesting good generalization without overfitting.
    This is particularly important because the dataset is split by protein targets,
    meaning that the validation set contains drugs targeting different proteins than
    those seen during training.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Models that show similar performance on both training and validation sets are
    more likely to generalize well. Prioritizing these configurations can help guide
    robust model selection.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/dlfb_0412.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-12\. Maximum Hits@20 achieved by each configuration in our hyper-parameter
    grid. Rows correspond to dropout_rate (0.0, 0.3, 0.5); columns vary the number
    of MLP layers (1–3) in the link predictor. Each x-axis category toggles self-loops
    and degree normalization. The best generalization comes from the minimal model
    (far left, top row).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'There are many models in this plot, but one stands out in the upper-left corner:
    the best-performing model without dropout. It uses a simple convolutional setup
    (no self-edges, no normalization) and a single-layer link predictor. It’s notable
    that such a minimal configuration performs so well, suggesting that simpler models
    can still be highly effective.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other observations from the plot:'
  prefs: []
  type: TYPE_NORMAL
- en: Degree normalization hurts almost everywhere. Both “with norm” columns show
    a noticeable drop in validation performance relative to their “no norm” counterparts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deeper MLP heads overfit more. Moving from one to three MLP layers widens the
    train–valid gap and very rarely yields a higher peak validation score.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dropout does not consistently help, though some models with high dropout perform
    well, suggesting it’s not strictly harmful either.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Self-edges make little difference. The two “with self-edges” categories track
    their “no self-edges” twins closely, suggesting that this graph already conveys
    enough reciprocal information. Overall, the task appears quite forgiving—many
    configurations exceed 0.8 on validation—but the simplest, lowest-capacity model
    remains the most reliable choice.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s now inspect the learning curves for the best-performing configuration,
    shown in [Figure 4-13](#ddi-best-model).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: Recall that the previous metrics represented maximum values—meaning they may
    not have occurred at the same point in training and do not rule out eventual overfitting
    if training were to proceed. Plotting the full learning curves provides additional
    insight. In [Figure 4-13](#ddi-best-model), we see strong learning on the training
    set, but the configuration appears prone to overfitting without early stopping.
    This is evident from the widening gap between training and validation metrics
    over time.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dlfb_0413.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-13\. Learning curves for loss (left) and Hits@20 (right) of the best-performing
    configuration. The model achieves near-perfect training performance, but the validation
    metric plateaus and then declines, indicating overfitting.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s also examine the learning curves of an alternative high-performing model
    in [Figure 4-14](#ddi-alt-best-model). This configuration comes from a different
    region of the hyperparameter space: it includes more layers in the link predictor
    and applies a high dropout rate to encourage generalization. It also uses a different
    convolutional setup. Notably, the training and validation curves remain closer
    together, suggesting that this model learns a more generalizable representation
    and is less susceptible to overfitting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/dlfb_0414.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-14\. Learning curves for loss (left) and Hits@20 (right) of an alternative
    high-performing model. This configuration demonstrates improved generalization,
    with train and validation metrics remaining stable and closely aligned.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: While it’s tempting to focus only on the top headline metrics to identify the
    best-performing configuration, examining training dynamics can offer deeper insight
    into model performance. Based on both maximum metrics and learning curve behavior,
    we would recommend this latest model for its strong performance and stability.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: There are many additional hyperparameters that could be explored—including those
    already present in our model and training loop, as well as others not yet considered.
    For example, we could experiment with alternative negative sampling strategies,
    vary the ratio of negative to positive pairs, or increase the depth of the graph
    convolutional layers. However, for this smaller dataset, the current performance
    is strong enough that we consider further tuning unnecessary.
  prefs: []
  type: TYPE_NORMAL
- en: Train on a Larger Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we train a model on a much larger DDI dataset—scaling up from using
    roughly one-tenth to approximately one-half of the available data.
  prefs: []
  type: TYPE_NORMAL
- en: As noted earlier, the optimal model configuration often depends on dataset size
    and graph connectivity. With this larger dataset, additional hyperparameter exploration
    revealed that *degree normalization* becomes critical for strong performance.
    Moreover, a moderate dropout rate of 0.3 struck the best balance between regularization
    and learning capacity for this setting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the full `DdiModel` setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: The resulting learning curves in [Figure 4-15](#ddi-large-best-model) look quite
    different from the smaller-set runs. Validation Hits@20 climbs to ∼0.9—on par
    with our best earlier models—but training Hits@20 remains unexpectedly low, hovering
    near 0.1\. This wide gap likely reflects the increased difficulty of distinguishing
    positives from a much larger and more diverse set of negatives in the denser graph.
    It may also indicate that even with an AUC-like loss, nailing top-k ranking metrics
    like Hits@20 remains challenging at scale. Either way, further work—such as improved
    negative sampling or top-k–specific objectives—may be needed to fully leverage
    the larger dataset, and we encourage you to explore further.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '![](assets/dlfb_0415.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-15\. Learning curves for loss (left) and Hits@20 (right) of the best-performing
    model trained on the larger dataset. Maximum validation performance is high but
    does not show significant improvement over the performance of models trained on
    smaller datasets, suggesting further hyperparameter tuning or model adjustments
    may be needed.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The strong validation performance suggests this model could scale to even larger
    datasets. However, scaling beyond 50% of the dataset becomes difficult due to
    memory constraints. With an embedding size of 512 for all nodes, the current implementation
    can run into out-of-memory (OOM) issues during XLA compilation.
  prefs: []
  type: TYPE_NORMAL
- en: A better solution would be to adopt a sampling strategy, as used in GraphSAGE,
    where the model processes subgraphs in batches. This makes it feasible to scale
    to larger datasets without reducing embedding size or compromising performance.
    However, implementing this is beyond the scope of the current chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Extensions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many ways to extend the model and training setup explored in this
    chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Graph sampling for scalability
  prefs: []
  type: TYPE_NORMAL
- en: Replace full-batch training with neighborhood sampling to scale to larger graphs
    without exceeding memory constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Incorporate node features
  prefs: []
  type: TYPE_NORMAL
- en: Integrate drug-specific information, such as chemical structure or pharmacological
    annotations, to enrich the learned embeddings and improve prediction accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Improve negative sampling
  prefs: []
  type: TYPE_NORMAL
- en: Use more informative strategies like hard negative mining, where the model is
    shown negative pairs it finds confusing (e.g., those with high predicted interaction
    scores). This encourages the model to focus on challenging distinctions and improves
    generalization.
  prefs: []
  type: TYPE_NORMAL
- en: Try alternative GNN architectures
  prefs: []
  type: TYPE_NORMAL
- en: Explore other models like Graph Attention Networks, which weigh the importance
    of neighboring nodes, which are theoretically more expressive.
  prefs: []
  type: TYPE_NORMAL
- en: Transfer to new biological problems
  prefs: []
  type: TYPE_NORMAL
- en: Apply the same modeling framework to other interaction networks, such as gene
    regulatory, protein-protein, or drug-target interaction graphs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, here are some analysis ideas you could explore:'
  prefs: []
  type: TYPE_NORMAL
- en: Error analysis by drug class
  prefs: []
  type: TYPE_NORMAL
- en: Break down model performance by therapeutic class or chemical category to identify
    where the model struggles most.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction certainty
  prefs: []
  type: TYPE_NORMAL
- en: Examine the distribution of predicted probabilities. Which drug pairs is the
    model highly confident about (close to 0 or 1)? Which fall near 0.5? Investigate
    whether uncertain predictions share common characteristics (e.g., unusual structures,
    sparse connectivity).
  prefs: []
  type: TYPE_NORMAL
- en: Embedding visualization
  prefs: []
  type: TYPE_NORMAL
- en: Use dimensionality reduction methods (e.g., t-SNE, UMAP) to project node embeddings
    into 2D and inspect whether drugs with similar functions cluster together.
  prefs: []
  type: TYPE_NORMAL
- en: Temporal validation
  prefs: []
  type: TYPE_NORMAL
- en: If drug interaction timestamps are available, evaluate the model on future data
    after training on past interactions. This mimics a real-world deployment scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Counterfactual analysis
  prefs: []
  type: TYPE_NORMAL
- en: Perturb the graph structure—for example, remove a known interaction or introduce
    a plausible but incorrect one—and observe how predictions change. This helps probe
    model sensitivity and identify influential edges.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we developed graph neural network models to predict links between
    nodes, applying them to the biologically meaningful task of drug–drug interaction
    (DDI) prediction. Starting with a simple architecture, we systematically explored
    model components and training strategies, eventually achieving strong validation
    performance through careful tuning of the loss function and key hyperparameters.
    Along the way, we introduced practical tools for evaluating performance, diagnosing
    overfitting, and scaling to larger datasets. These techniques are broadly applicable
    beyond DDIs, extending to a wide range of biological graph problems.
  prefs: []
  type: TYPE_NORMAL
- en: Our results show that even relatively simple graph models, when thoughtfully
    designed and optimized, can learn meaningful biological structure. As graph-based
    data becomes increasingly central in biology, the approaches introduced here provide
    a solid foundation for tackling more complex tasks—in drug discovery, genomics,
    systems biology, and beyond.
  prefs: []
  type: TYPE_NORMAL
- en: '^([1](ch04.html#id726-marker)) Udrescu, L. et al. [“Clustering Drug–Drug Interaction
    Networks with Energy Model Layouts: Community Analysis and Drug Repurposing”](https://oreil.ly/rdShs).
    *Scientific Reports*, 6 (2016): 32745.'
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](ch04.html#id727-marker)) Hu, Weihua, Matthias Fey, Marinka Zitnik, Yuxiao
    Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. 2020\. [“Open
    Graph Benchmark: Datasets for Machine Learning on Graphs”](https://oreil.ly/eK20s).
    arXiv.Org. May 2, 2020.'
  prefs: []
  type: TYPE_NORMAL
- en: '^([3](ch04.html#id740-marker)) Gilmer et al., “Neural Message Passing for Quantum
    Chemistry,” *Proceedings of the 34th International Conference on Machine Learning*
    (Sydney, NSW, Australia), vol. 70 (2017): 1263–1272, JMLR.org.'
  prefs: []
  type: TYPE_NORMAL
- en: '^([4](ch04.html#id741-marker)) F. Scarselli et al., “The Graph Neural Network
    Model,” *IEEE Transactions on Neural Networks* 20, no. 1 (2009): 61–80.'
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch04.html#id754-marker)) Hamilton, W. L., Ying, Z., & Leskovec, J. (2017).
    [Inductive representation learning on large graphs](https://oreil.ly/8mNRd). *Neural
    Information Processing Systems*, 30, 1024–1034.
  prefs: []
  type: TYPE_NORMAL
- en: ^([6](ch04.html#id764-marker)) Google DeepMind. [“Intro to Graph Neural Nets
    with JAX/Jraph”](https://oreil.ly/r6MCp).
  prefs: []
  type: TYPE_NORMAL
- en: ^([7](ch04.html#id808-marker)) Wang, Z., Zhou, Y., Hong, L., Zou, Y., Su, H.,
    & Chen, S. (2021). [Pairwise learning for neural link prediction](https://doi.org/10.48550/arxiv.2112.02936).
    arXiv (Cornell University).
  prefs: []
  type: TYPE_NORMAL
