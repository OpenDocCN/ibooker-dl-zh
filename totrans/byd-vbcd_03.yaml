- en: 'Chapter 2\. The Art of the Prompt: Communicating Effectively with AI'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章. 提示的艺术：与AI有效沟通
- en: In vibe coding, prompts are the new source code.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在vibe coding中，提示是新的源代码。
- en: The way you communicate your intent to the AI has a direct impact on the quality
    of the code it generates. Writing a good prompt is both an art and a science,
    often called *prompt engineering*. This chapter will equip you with techniques
    to get the most out of your AI coding assistant. We’ll start with some fundamentals
    about why prompts matter and then delve into a toolbox of prompting techniques,
    from simple to advanced. By learning how to craft effective prompts and how to
    iteratively refine them ([Figure 2-1](#ch02_figure_1_1752630042957579)), you’ll
    be able to cocreate with AI more efficiently and accurately.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你向AI传达意图的方式直接影响到它生成的代码质量。编写一个好的提示既是艺术也是科学，通常被称为*提示工程*。本章将为你提供技巧，让你充分利用你的AI编码助手。我们将从为什么提示很重要的一些基本原理开始，然后深入探讨一系列提示技巧，从简单到高级。通过学习如何制作有效的提示以及如何迭代地改进它们（[图2-1](#ch02_figure_1_1752630042957579)），你将能够更高效、更准确地与AI合作。
- en: '![](assets/bevc_0201.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/bevc_0201.png)'
- en: 'Figure 2-1\. An illustration of a chatbot assisting with coding. The developer
    and AI engage in a dialogue: the developer provides instructions or questions
    (prompts), and the AI responds with code or answers. Communicating effectively
    with the AI through well-crafted prompts is key to getting accurate and useful
    code generation.'
  id: totrans-4
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-1. 一个聊天机器人协助编程的插图。开发者和AI进行对话：开发者提供指令或问题（提示），AI则回应代码或答案。通过精心制作的提示与AI有效沟通是获得准确和有用代码生成的关键。
- en: Prompt Engineering Fundamentals
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程基础
- en: If vibe coding is a conversation between you and an AI model, *prompt engineering*
    is the skill of speaking the AI’s language to get the best results. A well-crafted
    prompt can be the difference between an irrelevant or buggy code suggestion and
    a perfect solution. Mastering prompt engineering means understanding how to guide
    the AI effectively, how to provide context, and how to iterate with the AI when
    the first answer isn’t quite right.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果vibe coding是你和AI模型之间的对话，那么*提示工程*就是用AI的语言说话以获得最佳结果的技能。一个精心制作的提示可以区分无关或带错误的代码建议和完美的解决方案。掌握提示工程意味着理解如何有效地引导AI，如何提供上下文，以及当第一个答案不太正确时如何与AI迭代。
- en: When you program with an AI, you are essentially programming *through* the AI
    using natural language. The prompt you provide is like a high-level programming
    language that the AI interpreter then translates into actual code. Just as a compiler’s
    output is only as good as the source code fed to it, an AI’s output is only as
    good as the prompt.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当你用AI编程时，你实际上是通过自然语言通过AI编程的。你提供的提示就像是一种高级编程语言，AI解释器随后将其翻译成实际的代码。就像编译器的输出只取决于其输入的源代码一样，AI的输出也只取决于提示。
- en: 'Why are prompts so important? LLMs, despite their sophistication, are not mind
    readers. They respond only to the input they’re given. Ambiguous or poorly worded
    prompts can lead to irrelevant or incorrect code, while a clear and specific prompt
    can yield a spot-on solution on the first try. In traditional coding, you spend
    time thinking about algorithms and writing code; in vibe coding, you spend time
    thinking about how to convey your requirements to the AI. It’s a shift in what
    “writing code” means: you might write a paragraph instead of a function, but you
    still need to be precise and logical.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么提示如此重要？尽管LLMs（大型语言模型）非常复杂，但它们并不是心灵感应者。它们只对它们接收到的输入做出反应。含糊不清或措辞不当的提示可能导致无关或错误的代码，而一个清晰具体的提示则可能在第一次尝试时就提供完美的解决方案。在传统的编码中，你花费时间思考算法并编写代码；在vibe
    coding中，你花费时间思考如何向AI传达你的需求。这改变了“编写代码”的含义：你可能写一段文字而不是一个函数，但你仍然需要精确和逻辑。
- en: Think of writing prompts as being like writing documentation or user stories
    for a very literal and pedantic junior developer, one who will do exactly (and
    only) what the documentation says, and who has a lot of knowledge but no common
    sense beyond patterns they have seen. If your instructions (prompts) leave room
    for interpretation, the AI might fill the gaps in ways you didn’t intend. Thus,
    learning to *communicate* with the AI is as crucial as learning a programming
    language’s syntax used to be.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 将编写提示想象成为一位非常字面和刻板的初级开发者编写文档或用户故事，这位开发者会严格按照（并且仅）文档说明去做，他拥有大量知识，但除了他们看到过的模式之外没有常识。如果你的指令（提示）留下了可以解释的空间，AI可能会以你未预料到的方式填补这些空白。因此，学会与AI进行沟通与学习编程语言的语法一样至关重要。
- en: Another reason prompts are crucial is reproducibility and future-proofing. If
    you discover a prompt that reliably generates good code for a certain pattern
    or task, that prompt becomes a valuable piece of knowledge (almost like a snippet
    or template). You might save it or reuse it in similar contexts. In teams, developers
    might share effective prompt patterns with each other, similar to how they share
    coding best practices.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 提示至关重要的另一个原因是可重复性和未来保障。如果你发现一个提示可以可靠地生成针对特定模式或任务的优质代码，那么这个提示就成了一项宝贵的知识（几乎像是一个片段或模板）。你可能保存它或在类似情境中重用它。在团队中，开发者可能会相互分享有效的提示模式，类似于他们分享编码最佳实践的方式。
- en: Finally, as models get better and more integrated, they may allow more complex
    interactions. Being good at prompting will let you harness new capabilities quickly.
    For instance, some advanced systems allow you to attach extensive instructions
    or provide entire reference documents as part of the context for the model. Knowing
    how to structure that input is key to leveraging such power.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，随着模型变得更好和更集成，它们可能允许更复杂的交互。擅长提示将让你能够快速利用新功能。例如，一些高级系统允许你附加广泛的指令或提供整个参考文档作为模型的上下文。了解如何构建这种输入是利用这种力量的关键。
- en: So treat prompt writing as a new essential skill. In many ways, prompting *is*
    programming. The main difference is you’re writing in a language (like English)
    that the AI then converts into code. But you still have to be clear, logical,
    and anticipate edge cases in your description.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，将提示写作视为一项新的基本技能。在许多方面，提示实际上就是编程。主要区别在于你使用的是一种语言（如英语），然后AI将其转换为代码。但你在描述中仍然需要清晰、逻辑性强，并预见到边缘情况。
- en: 'Specificity and Clarity: Writing Prompts That Deliver'
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具体性和清晰性：编写能够达到目的的提示
- en: One of the golden rules of prompting (which I’ll lay out more fully in [Chapter 3](ch03.html#ch03_the_70_problem_ai_assisted_workflows_that_actual_1752630043200933))
    is to be specific and clear about what you want. Unlike a human collaborator,
    an AI doesn’t truly understand your goal beyond the words you provide. A common
    mistake is giving the AI a very high-level prompt like “Make a website” and expecting
    magic. The AI works better with concrete details.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 提示的一个黄金法则（我将在第3章（ch03.html#ch03_the_70_problem_ai_assisted_workflows_that_actual_1752630043200933）中更详细地阐述）是明确且清晰地表达你的需求。与人类合作者不同，AI并不真正理解你提供单词之外的目标。一个常见的错误是给AI一个非常高级的提示，比如“制作一个网站”，并期望出现魔法。AI更擅长处理具体细节。
- en: Always assume it knows nothing about your project beyond what you provide. Include
    relevant details such as the programming language, framework, and libraries, as
    well as the specific function or snippet in question. If there’s an error, provide
    the exact error message and describe what the code is supposed to do. Any vagueness
    or room for interpretation can lead to unintended outputs.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 总是假设它对你提供的项目一无所知。包括相关的细节，如编程语言、框架和库，以及具体的函数或代码片段。如果有错误，请提供确切的错误消息并描述代码应该做什么。任何含糊不清或解释空间都可能导致意外的输出。
- en: 'For example, instead of “Write a sorting function,” you could say:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，与其说“编写一个排序函数”，你可以说：
- en: Write a Python function sort_by_lastname(customers) that takes a list of customer
    records (each with a first_name and last_name field) and returns a list sorted
    by last_name alphabetically. Include a brief docstring and handle the case of
    missing last names by treating them as empty strings.
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 编写一个Python函数`sort_by_lastname(customers)`，该函数接受一个包含客户记录的列表（每个记录都有一个`first_name`和`last_name`字段）并按`last_name`字母顺序返回排序后的列表。包括一个简短的文档字符串，并处理缺少姓氏的情况，将其视为空字符串。
- en: 'This prompt sets clear expectations about the language (Python), the function
    name and purpose, the input structure, the sort key, additional requirements (docstring),
    and an edge case. It’s likely to produce exactly what you need or very close to
    it. Essentially, think like a spec writer: the more precisely you specify the
    task, the less guesswork the AI has to do and the fewer revisions you’ll need.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示明确了关于语言（Python）、函数名称和目的、输入结构、排序键、额外要求（文档字符串）和边缘情况的期望。它很可能会产生你需要的或非常接近你需要的答案。本质上，要像编写规范一样：你指定的任务越精确，AI需要猜测的就越少，你需要的修订也就越少。
- en: 'Strategies for specificity include:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 提高具体性的策略包括：
- en: Mention the language or environment
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 提及语言或环境
- en: 'If you want a solution in JavaScript, say so: “Write a JavaScript function...”
    versus just “Write a function...” If you want it for a specific framework or version,
    include that (“Using React Hooks...” or “in Python 3...”).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要JavaScript解决方案，请明确指出：“写一个JavaScript函数...”而不是仅仅“写一个函数...”。如果你需要特定框架或版本，请包含它（“使用React
    Hooks...”或“在Python 3...”）。
- en: Define the scope of the output
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 定义输出范围
- en: Do you want just a single function? A full file or module? Tests included? For
    example, “Provide only the function implementation” and “Provide a complete runnable
    script” can yield different responses.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需要一个函数吗？一个完整的文件或模块？包括测试？例如，“仅提供函数实现”和“提供完整的可运行脚本”可以产生不同的响应。
- en: Include requirements and constraints
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 包含需求和约束
- en: 'In the login example, we specified password length and attempt limit. Think
    of edge cases or constraints and put them in the prompt. If you need the code
    to be optimized for performance or use a certain algorithm, say so: “using O(n)
    time and O(1) space” or “using a binary search approach.”'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在登录示例中，我们指定了密码长度和尝试限制。考虑边缘情况或约束，并将它们放入提示中。如果你需要代码针对性能进行优化或使用特定的算法，请说明：“使用O(n)时间和O(1)空间”或“使用二分搜索方法。”
- en: Avoid ambiguous references
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 避免含糊不清的引用
- en: Don’t use words like *it* without a clear antecedent. Instead of “Process it
    and return the result,” say, “Process the array and return the resulting array.”
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 不要在没有明确先行词的情况下使用像“它”这样的词。例如，不要说“处理它并返回结果”，而要说“处理数组并返回结果数组”。
- en: Name your desired output format
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 命名你期望的输出格式
- en: 'If you want the AI to output just code or code with comments or an explanation,
    you can instruct that: “Give only the code, no explanation” or “Provide code and
    a brief comment for each step.”'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望AI仅输出代码或带注释的代码或解释，你可以指示：“仅提供代码，无需解释”或“为每个步骤提供代码和简要注释。”
- en: A clear prompt sets the AI up for success. If you find the AI’s answers often
    need a lot of correction, examine whether your prompts might be underspecified.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 清晰的提示为AI的成功奠定了基础。如果你发现AI的答案经常需要大量纠正，请检查你的提示是否可能过于不具体。
- en: 'Here’s what not to do:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是不要做的事情：
- en: Don’t write a whole novel
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 不要写一整篇小说
- en: Long-winded prompts that include irrelevant info can confuse the model or cause
    it to focus on the wrong thing. Be concise but complete in your description. For
    instance, you usually don’t need to preface with “You are a world-class programmer...”
    in a coding context (some people do that in general ChatGPT usage, but for coding
    tasks, it’s often unnecessary and could add noise).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 过于冗长且包含无关信息的提示可能会使模型困惑或导致它关注错误的事情。描述要简洁完整。例如，在编码环境中，通常不需要以“你是一位世界级的程序员...”作为前言（一些人在一般ChatGPT使用中这样做，但在编码任务中，这通常是多余的，可能会增加噪音）。
- en: Don’t assume the AI will fill in details by itself correctly
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 不要假设AI会自行正确填充细节
- en: If something is important (like thread safety, handling of special characters,
    etc.), mention it. If it’s not mentioned, assume the AI might not handle it.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果某些事情很重要（如线程安全、特殊字符的处理等），请提及。如果没有提及，假设AI可能不会处理它。
- en: Avoid open-ended “creative” prompts when you need deterministic outputs
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要确定性输出时，避免开放式的“创意”提示
- en: 'For example, saying, “Write some code to analyze data” might cause the AI to
    guess what analysis you want. Instead, specify:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，说“写一些代码来分析数据”可能会让AI猜测你想要的分析类型。相反，请具体指定：
- en: Calculate the average and standard deviation of a list of numbers.
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 计算数字列表的平均值和标准差。
- en: 'In summary, *say exactly what you mean*. The more the AI “knows” about what
    you truly want, the better it can deliver. If you find yourself having to correct
    the AI multiple times, ask: could my initial prompt have been clearer?'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，*明确表达你的意思*。AI“了解”你真正想要的东西越多，它就能提供得越好。如果你发现自己不得不多次纠正AI，请问：我的初始提示是否可以更清晰？
- en: 'Iterative Refinement: The Feedback Loop with the AI'
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迭代优化：与AI的反馈循环
- en: Even with clear prompts, you won’t always get the perfect answer on the first
    try. Think of interacting with the AI as a conversation or an iterative development
    process. This is the feedback loop I touched on in [Chapter 1](ch01.html#ch01_introduction_what_is_vibe_coding_1752630042333281).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 即使有清晰的提示，你也不一定能在第一次尝试时就得到完美的答案。将与AI的交互视为对话或迭代开发过程。这正是我在[第一章](ch01.html#ch01_introduction_what_is_vibe_coding_1752630042333281)中提到的反馈循环。
- en: When the AI gives you code, review it critically, just as you would code written
    by a human. Does it meet the requirements? If not, identify what’s missing or
    wrong. Then provide feedback or a refined prompt. This can be done in a conversational
    AI by simply continuing the dialogue, or in an editor by writing another comment
    for the AI to respond to.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当AI给你代码时，要像审查人类编写的代码一样批判性地审查它。它是否符合要求？如果不符，确定缺少或错误的地方。然后提供反馈或优化提示。这可以通过对话式AI简单地继续对话来完成，或者在编辑器中为AI写另一个评论以供其回复。
- en: 'By providing feedback to the AI, you steer it closer to your desired outcome. In
    a sense, you are *training* it on the fly for your specific problem. Advanced
    prompt engineering is like the loop in [Figure 2-2](#ch02_figure_2_1752630042957608):
    Prompt → AI output → Review → Refine prompt → AI output →...until satisfied. Keeping
    each iteration’s changes small is useful; if you overhaul the prompt too much,
    you may lose some good parts of the previous output.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向AI提供反馈，你可以将其引导到更接近你期望的结果。从某种意义上说，你是在实时训练它来解决你的特定问题。高级提示工程就像[图2-2](#ch02_figure_2_1752630042957608)中的循环：提示
    → AI输出 → 审查 → 优化提示 → AI输出 → ...直到满意。保持每次迭代的更改尽可能小是有用的；如果你对提示进行大规模的修改，你可能会丢失一些前一个输出的好部分。
- en: '![](assets/bevc_0202.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/bevc_0202.png)'
- en: Figure 2-2\. Advanced prompt engineering loop.
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-2\. 高级提示工程循环。
- en: 'For example, you might prompt:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可能会提示：
- en: Write a function that takes a list of integers and returns their sum.
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 编写一个函数，该函数接收一个整数列表并返回它们的总和。
- en: 'The AI then returns a function, but its code assumes a non-empty list and doesn’t
    handle an empty list well. You could then reply:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: AI随后返回一个函数，但它的代码假设列表不为空，并且没有很好地处理空列表。然后你可以回复：
- en: That looks good. However, please modify it to return 0 if the list is empty.
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 看起来不错。但是，请修改它，如果列表为空则返回0。
- en: The AI would then update the function accordingly. In this way, you didn’t have
    to prompt from scratch; you just told the AI to make an adjustment. The AI already
    had the context of the previous code it gave.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: AI随后会相应地更新函数。这样，你不必从头开始提示；你只是告诉AI进行一些调整。AI已经有了之前给出的代码的上下文。
- en: 'If you’re using an inline assistant, refinement might look like editing the
    code and perhaps writing a comment like `# TODO: handle empty list` and then seeing
    if the AI suggests a fix for that.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你使用内联助手，优化可能看起来像编辑代码，并可能写一个注释如`# TODO: 处理空列表`，然后看看AI是否建议修复这个问题。'
- en: 'Another refinement approach is reprompting with more info if the first output
    wasn’t right. Suppose you said, “Sort a list of names,” and it gave code sorting
    case-sensitively but you wanted case-insensitive. You could rephrase:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种优化方法是，如果第一次输出不正确，重新提示更多信息。假设你说，“对一组名字进行排序”，它给出了按大小写敏感排序的代码，但你想要不区分大小写的排序。你可以重新表述：
- en: Sort a list of names case-insensitively.
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不区分大小写地对一组名字进行排序。
- en: 'Or even:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 或者甚至：
- en: The previous code sorts case-sensitively. Modify it to be case-insensitive.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 之前的代码按大小写敏感排序。修改它使其不区分大小写。
- en: 'In debugging, for more complex logic bugs (where no obvious error message is
    thrown but the output is wrong), you can prompt the AI to walk through the code’s
    execution. For instance:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在调试过程中，对于更复杂的逻辑错误（没有抛出明显的错误信息，但输出结果错误），你可以提示AI遍历代码的执行过程。例如：
- en: Walk through this function line by line and track the value of total at each
    step. It’s not accumulating correctly—where does the logic go wrong?
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 逐行遍历这个函数，并跟踪每一步的总值。它没有正确累加——逻辑在哪里出错？
- en: 'This is an example of a “rubber duck” debugging prompt: you’re essentially
    asking the AI to simulate the debugging process a human might do with prints or
    a debugger. Such prompts often reveal subtle issues like variables not resetting
    or incorrect conditional logic, because the AI will spell out the state at each
    step. If you suspect a certain part of the code, you can zoom in:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个“橡皮鸭”调试提示的例子：你实际上是在要求AI模拟人类可能会用打印或调试器进行的调试过程。这样的提示通常会揭示微妙的问题，比如变量没有重置或不正确的条件逻辑，因为AI会在每个步骤中说明状态。如果你怀疑代码的某个部分，你可以聚焦于：
- en: Explain what the filter call is doing here and if it might be excluding more
    items than it should.
  id: totrans-59
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 解释这里过滤器调用在做什么，以及它是否可能排除了它不应该排除的更多项。
- en: Engaging the AI in an explanatory role can surface the bug in the process of
    explanation.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释过程中与AI互动可以揭示错误。
- en: 'After the explanation, it’s often effective to directly ask for what you need:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释之后，直接询问你需要的内容通常很有效：
- en: What might be causing this issue, and how can I fix it?
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 什么可能导致了这个问题，我该如何修复它？
- en: 'This invites the AI to both diagnose and propose a solution. If the AI’s first
    answer is unclear or partially helpful, don’t hesitate to ask a follow-up question:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这邀请AI进行诊断并提出解决方案。如果AI的第一个答案不清楚或只有部分帮助，不要犹豫，提出后续问题：
- en: That explanation makes sense. Can you show me how to fix the code? Please provide
    the corrected code.
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 那个解释是有道理的。你能展示我如何修复代码吗？请提供修正后的代码。
- en: 'In a chat setting, the AI has the conversation history, so it can directly
    output the modified code. If you’re using an inline tool like Copilot in VSCode
    or Cursor without a chat, you might instead write a comment above the code:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在聊天环境中，AI有聊天历史，因此它可以直接输出修改后的代码。如果你使用VSCode中的Copilot或Cursor这样的内联工具而没有聊天功能，你可以在代码上方写一个注释：
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In general, though, the interactive chat yields more thorough explanations.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一般而言，交互式聊天会产生更详尽的解释。
- en: 'Another follow-up pattern: if the AI gives a fix but you don’t understand why,
    ask:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种后续模式：如果AI提供了一个修复方案但你不知道为什么，你可以问：
- en: Can you explain why that change solves the problem?
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你能解释一下为什么这个改变能解决问题吗？
- en: This way, you learn for next time, and you double-check that the AI’s reasoning
    is sound.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，你可以为下一次学习，并且可以再次确认AI的推理是合理的。
- en: 'LLMs thrive on examples and corrections. If you point out what’s wrong or give
    a quick example, the AI can incorporate it:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在示例和纠正中茁壮成长。如果你指出错误或给出一个快速示例，AI可以将其纳入：
- en: If input is [], it should return 0, but now it errors.
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果输入是[]，它应该返回0，但现在它报错了。
- en: This iterative process is normal. In fact, trying to cram every detail into
    one prompt might be less effective than a couple of back-and-forth turns. Use
    that to your advantage.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这种迭代过程是正常的。实际上，试图在一个提示中塞入所有细节可能不如几次来回的交流有效。利用这一点来发挥你的优势。
- en: 'Be patient and specific in your feedback. Instead of saying, “No, that’s wrong,”
    say what’s wrong or what’s needed:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在反馈时要耐心且具体。而不仅仅是说，“不，这是错误的”，而是说明哪里错了或需要什么：
- en: This code doesn’t handle negative numbers correctly. It should treat them as
    0 in the sum.
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这段代码没有正确处理负数。它应该将它们视为求和中的0。
- en: 'Also, if the AI goes off track, you can steer it back: sometimes resetting
    or rephrasing is easier than trying to salvage a very incorrect attempt. Use your
    judgment. If the AI output shows that it is completely misunderstanding you, clarify
    your prompt from scratch.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果AI偏离了轨道，你可以引导它回到正轨：有时重置或重新措辞比试图挽救一个非常错误的尝试更容易。运用你的判断力。如果AI的输出显示它完全误解了你，请从头开始澄清你的提示。
- en: As you refine, you’ll also learn how the AI interpreted your prompt. This can
    inform how you write future prompts. You might realize, “Oh, it took ‘login system’
    to mean an entire UI. Next time I’ll specify backend only.”
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你不断优化，你也会了解到AI是如何解读你的提示的。这可以指导你如何撰写未来的提示。你可能会意识到，“哦，它把‘登录系统’理解为一个完整的用户界面。下次我只指定后端。”
- en: 'Think of it like debugging code: if the AI output is wrong, the “bug” might
    be in your prompt, not in the AI’s processing. Just as you’d examine and fix your
    code when it produces incorrect results, you should refine your prompts when the
    AI generates unexpected or incorrect output. The conversation between you and
    the AI is like a debugging session where each exchange helps you pinpoint and
    fix the issue.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 想象它就像调试代码：如果AI的输出是错误的，“bug”可能在于你的提示，而不是AI的处理。就像你会在代码产生错误结果时检查和修复你的代码一样，当AI生成意外或不正确的输出时，你应该优化你的提示。你和AI之间的对话就像一个调试会话，每次交流都有助于你定位和修复问题。
- en: Comparing Two Prompts
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较两个提示
- en: 'Imagine you have a simple Node.js function meant to convert a list of user
    objects to a lookup map by user ID. However, it’s throwing an error. Here’s the
    buggy code:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你有一个简单的 Node.js 函数，旨在通过用户ID将用户对象列表转换为查找映射。然而，它抛出了错误。以下是存在错误的代码：
- en: '[PRE1]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This code is supposed to iterate through the user’s array and build an object
    where keys are user IDs. However, there is a bug: the loop uses `i <= users.length`
    instead of `i < users.length`. This will cause `users[i]` to be undefined on the
    last iteration, likely leading to a runtime error (like attempting to access the
    property ID of `undefined`). Let’s see how an AI assistant might respond to two
    different prompts about this issue (see [Figure 2-3](#ch02_figure_3_1752630042957630)).'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码本应遍历用户的数组并构建一个对象，其中键是用户ID。然而，存在一个错误：循环使用 `i <= users.length` 而不是 `i < users.length`。这将在最后一次迭代时导致
    `users[i]` 为 undefined，很可能会引发运行时错误（例如尝试访问 `undefined` 的属性 ID）。让我们看看人工智能助手如何对关于这个问题的两个不同提示做出回应（见[图2-3](#ch02_figure_3_1752630042957630)）。
- en: '![](assets/bevc_0203.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/bevc_0203.png)'
- en: 'Figure 2-3\. Prompt quality impact comparison: vague prompts produce generic
    or incorrect code, while specific, well-structured prompts generate accurate,
    contextually appropriate solutions.'
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-3\. 提示质量影响比较：模糊的提示会产生通用或不正确的代码，而具体、结构良好的提示则会产生准确、上下文相关的解决方案。
- en: Poor prompt
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 糟糕的提示
- en: 'Here’s an example of a poor prompt:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个糟糕的提示示例：
- en: Why isn’t my mapUsersById function working?
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为什么我的 mapUsersById 函数不起作用？
- en: 'AI’s response to the poor prompt (simulated):'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对糟糕提示的人工智能回应（模拟）：
- en: It’s hard to say without more information. Are you sure the function is being
    called with a proper array of users? Perhaps the issue is that users is empty
    or not an array, causing the loop not to execute properly. It could also be that
    there’s an error when setting the property on userMap. Make sure that each user
    has an id property. If users is undefined or null, that would also cause it to
    not work.
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 没有更多信息很难说。你确定函数是以正确的用户数组调用的吗？也许问题是用户数组为空或不是数组，导致循环无法正确执行。也可能是设置 userMap 属性时出错。确保每个用户都有一个
    id 属性。如果用户是 undefined 或 null，也会导致它无法工作。
- en: This answer is quite vague. The prompt gave no details except the function name,
    so the AI is guessing at generic causes (“Maybe the array is empty or not an array,”
    “Make sure each user has an ID”). It did not identify the actual bug.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这个答案相当模糊。提示没有提供任何细节，除了函数名，所以人工智能在猜测通用原因（“可能数组为空或不是数组”，“确保每个用户都有一个 ID”）。它没有识别出实际的错误。
- en: 'This is the kind of response you get when the question is underspecified—the
    model can only regurgitate common debugging tips. If you’re a developer, this
    isn’t very helpful because it doesn’t address the real mistake. The lack of context
    and specificity in the prompt yields a generic answer: essentially, the AI equivalent
    of “Have you tried turning it off and on again?” This aligns with the community
    advice that vague prompts lead to irrelevant or generic answers.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当问题未具体说明时，你会得到这样的回应——模型只能重复常见的调试提示。如果你是开发者，这并不很有帮助，因为它没有解决真正的错误。提示中的上下文和具体性不足导致了一个通用的答案：本质上，人工智能的“你试过关机再开机吗？”这种回应与社区建议相符，即模糊的提示会导致无关或通用的答案。
- en: Improved prompt
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 改进的提示
- en: 'Let’s try this again:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再试一次：
- en: 'I have a JavaScript function `mapUsersById` that should convert an array of
    user objects into a `map (object)` keyed by user ID. However, it throws an error
    when I run it. For example, when I pass `[ {id: 1, name: "Alice"} ]`, I get `TypeError:
    Cannot read property ''id'' of undefined`. Here is the function code:'
  id: totrans-94
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '我有一个名为 `mapUsersById` 的 JavaScript 函数，它应该将用户对象的数组转换为按用户ID键控的 `map (对象)`。然而，当我运行它时，它会抛出错误。例如，当我传递
    `[ {id: 1, name: "Alice"} ]` 时，我得到 `TypeError: Cannot read property ''id'' of
    undefined`。以下是函数代码：'
- en: ''
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ''
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It should return `{ "1": {id: 1, name: "Alice"} }`. What is the bug and how
    can I fix it?'
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '它应该返回 `{ "1": {id: 1, name: "Alice"} }`。错误是什么，我该如何修复它？'
- en: 'The AI’s response to the improved prompt (simulated):'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对改进提示的人工智能回应（模拟）：
- en: 'The error Cannot read property `''id''` of undefined suggests that at some
    point, user is undefined, and then you try to access user.id. Looking at your
    loop, the issue is with the loop bounds. You are using `i <= users.length`. If
    `users.length` is `1` (for one user in the array), the loop runs with `i = 0`
    and `i = 1`. When `i` is `1`, `users[1]` is undefined (since the only index in
    the array is 0). Thus user becomes undefined on that iteration, and `user.id`
    throws a `TypeError`. The fix is to change the loop condition to `i < users.length`
    so that `i` goes from `0` to `users.length-1`. For example:'
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 错误“无法读取属性`'id'`的未定义”表明，在某个时刻，用户是未定义的，然后你尝试访问user.id。查看你的循环，问题出在循环边界上。你正在使用`i
    <= users.length`。如果`users.length`是`1`（数组中的一个用户），循环将运行`i = 0`和`i = 1`。当`i`是`1`时，`users[1]`是未定义的（因为数组中只有一个索引是0）。因此，在那个迭代中，用户变为未定义，`user.id`抛出`TypeError`。修复方法是更改循环条件为`i
    < users.length`，这样`i`将从`0`到`users.length-1`。例如：
- en: ''
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-102
  prefs:
  - PREF_BQ
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ''
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This way, `i` will be `0` for the first (and only) element, and then the loop
    stops. With that change, your function will no longer hit an undefined user and
    should work as expected, returning `{"1": {id: 1, name: "Alice"}}` for the given
    input.'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '这样，`i`将为第一个（也是唯一的一个）元素是`0`，然后循环停止。有了这个变化，你的函数将不再遇到未定义的用户，并应该按预期工作，对于给定的输入返回`{"1":
    {id: 1, name: "Alice"}}`。'
- en: 'This response directly pinpoints the bug (using `<=` in the loop) and explains
    why it causes the user to be undefined. It then provides the correct code solution
    (`i < users.length`) and confirms the expected outcome. The improved prompt succeeded
    because it followed our principles: it specified the language (JavaScript), described
    the function’s purpose, included the exact error message and a sample input, and
    even provided the code snippet in question.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个响应直接指出了错误（在循环中使用`<=`），并解释了为什么会导致用户未定义。然后提供了正确的代码解决方案（`i < users.length`）并确认了预期的结果。改进的提示之所以成功，是因为它遵循了我们的原则：指定了语言（JavaScript）、描述了函数的目的、包含了确切的错误信息和示例输入，甚至提供了相关的代码片段。
- en: 'Notice how the AI used the error message as a clue to focus on the loop bounds—a
    targeted prompt enabled the AI to engage in true problem solving, effectively
    simulating how a human debugger would think: “Where could undefined come from?
    Likely from the loop indexing.” This is a concrete demonstration of the benefit
    of detailed prompts.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 注意AI如何利用错误信息作为线索来关注循环边界——一个有针对性的提示使AI能够参与真正的解决问题，有效地模拟人类调试员的思维方式：“未定义可能来自哪里？很可能是来自循环索引。”这是详细提示带来益处的具体体现。
- en: 'Prompting Techniques: A Toolbox for Effective Communication'
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示技术：有效沟通的工具箱
- en: Now let’s get into specific techniques that can supercharge your prompting skills.
    These are like patterns or recipes you can use when a straightforward instruction
    isn’t enough or when you want to guide the AI in a certain way.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们深入了解可以大幅提升你的提示技能的具体技术。这些就像模式或食谱，当直接的指令不够或者你想以某种方式引导AI时，你可以使用它们。
- en: 'By mastering these techniques, you can handle an array of situations: instructing
    the AI in plain English, giving it examples, making it explain or structure its
    output, or setting it into different mindsets or roles. All of these help you
    guide the AI to produce exactly what you need.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过掌握这些技术，你可以处理各种情况：用简单的英语指导AI、给它提供例子、让它解释或结构化其输出，或者将其设定为不同的思维模式或角色。所有这些都有助于你引导AI产生你所需的内容。
- en: Prompting techniques are not mutually exclusive; you will often use several
    together for best results, especially on complex tasks.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 提示技术不是相互排斥的；你通常会同时使用几种技术以获得最佳效果，尤其是在复杂任务中。
- en: A Note on Style
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 样式注意事项
- en: 'When you use these techniques, adapt your tone to the model. Many models respond
    well to polite or neutral instructions. You don’t need to use archaic or overly
    formal language. Direct but polite often works: “Please do X” or “Let’s do Y.”
    For example, with chain-of-thought (CoT) prompting, a popular phrase is “Let’s
    think step-by-step.” Models like GPT-4 recognize this as a cue to show reasoning.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用这些技术时，调整你的语气以适应模型。许多模型对礼貌或中性的指令反应良好。你不需要使用过时的或过于正式的语言。直接但礼貌通常有效：“请做X”或“让我们做Y”。例如，在思维链（CoT）提示中，一个流行的短语是“让我们一步步思考。”像GPT-4这样的模型会将这视为一个显示推理的线索。
- en: Zero-Shot Prompting
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零样本提示
- en: '*Zero-shot* prompting is simply asking the model to do something without providing
    any examples or additional guidance beyond the instruction. Essentially, the model
    is solving the task from “zero” examples.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '*零样本提示*就是简单地要求模型做某事，而不提供任何示例或超出指令的额外指导。本质上，模型是从“零”个示例中解决问题。'
- en: '*When to use:* This is the most common scenario: you just ask for what you
    want in plain language. If the task is standard and the prompt is clear, this
    is often sufficient.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用：* 这是最常见的场景：你只用普通语言请求你想要的东西。如果任务是标准的，提示清晰，这通常就足够了。'
- en: '*Example:*'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例：*'
- en: Write a Python function that checks if a number is prime.
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 编写一个Python函数，用于检查一个数字是否为素数。
- en: This is zero shot. The AI will likely produce a prime-checking function using
    a loop or trial division.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这是零样本。AI可能会使用循环或试除法生成一个素数检查函数。
- en: '*Pros:* It’s quick and relies on the model’s learned knowledge. Modern models
    are surprisingly good at zero-shot responses for many programming tasks, especially
    if they’re common (like prime checking, sorting, or string manipulation).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '*优点：* 它很快，并且依赖于模型学习到的知识。现代模型在许多编程任务的零样本响应方面表现得惊人地好，尤其是如果它们很常见（如素数检查、排序或字符串操作）。'
- en: '*Cons:* If the task is unusual or output format is specific, zero shot might
    yield a result that doesn’t quite match what you need on the first try, because
    the model might have multiple ways to interpret it.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*缺点：* 如果任务是不同寻常的或输出格式是特定的，零样本可能第一次尝试的结果并不完全符合你的需求，因为模型可能有多种解释它的方式。'
- en: Usually, it’s a good idea to try zero shot first for simple things. If the result
    is off, you may then shift to refining or other techniques.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，对于简单的事情，先尝试零样本是一个好主意。如果结果不理想，你可能会转向细化或其他技术。
- en: One-Shot and Few-Shot Prompting
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单次尝试和少量样本提示
- en: '*One-shot* prompting means you provide exactly one example of what you want
    (input and desired output) as part of the prompt; *few-shot* prompting means providing
    a few examples (typically two to five) before asking the model to perform the
    task on a new input.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*单次尝试提示*意味着你作为提示的一部分提供你想要的 exactly one 个示例（输入和期望的输出）；*少量样本提示*意味着在要求模型对新输入执行任务之前提供几个示例（通常是两个到五个）。'
- en: This is like showing the model, “Here’s how I solve one instance. Now you do
    the next one similarly.”
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这就像向模型展示，“这是解决一个实例的方法。现在你以类似的方式解决下一个。”
- en: '*When to use:* This type of prompting is useful when the model might not know
    exactly the format or style you need or when the task is a bit unusual. By giving
    examples, you reduce ambiguity.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用：* 当模型可能不知道你需要的确切格式或风格，或者任务有点不同寻常时，这种提示很有用。通过提供示例，你可以减少歧义。'
- en: '*Example (one shot):* Suppose you’re using a language or a certain style that
    the model might not have seen as much. Let’s say you want pseudocode in a specific
    format. Your prompt might be:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例（单次尝试）：* 假设你使用的是模型可能没有见过很多的语言或某种风格。比如说，你想要特定格式的伪代码。你的提示可能是：'
- en: Convert the following English instructions to Python-like pseudocode.
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将以下英文指令转换为类似Python的伪代码。
- en: 'Example instruction: “Calculate the factorial of n”:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 示例指令：“计算n的阶乘”：
- en: '[PRE4]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You’ve provided one example (factorial) and the format you want. Now the model
    is more likely to produce pseudocode for the “largest number” instruction in a
    similar format (with a function, with if/else or loop logic as needed).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 你提供了一个示例（阶乘）和想要的格式。现在模型更有可能以类似格式（带有函数，需要时带有if/else或循环逻辑）生成“最大数字”指令的伪代码。
- en: '*Example (few shot):* Let’s say you want the AI to use a specific algorithm.
    You might give it a smaller example of that algorithm in action as a hint. Or
    if the task has multiple correct answers but you prefer a certain one, an example
    can push it toward that.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例（少量样本）：* 假设你想要AI使用特定的算法。你可以给它一个该算法操作的较小示例作为提示。或者如果任务有多个正确答案但你更喜欢其中一个，示例可以推动它朝那个方向。'
- en: 'Few-shot prompting is powerful for formatting; for instance:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 少量样本提示在格式化方面非常强大；例如：
- en: Convert The Following English Statements To SQL Queries.\N1."Get All Employees
    Hired After 2020” → Select * From Employees Where Hire_Date > ’2020-01-01’;\N2\.
    “List Customer Names Who Made A Purchase In The Last Month” → Select Name From
    Customers Join Purchases On ... Where Purchase_Date > ...;\N3\. “Count Of Products
    That Are Out Of Stock” →
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将以下英文语句转换为SQL查询。\N1."在2020年之后雇佣的所有员工" → Select * From Employees Where Hire_Date
    > '2020-01-01';\N2. "列出在过去一个月内进行过购买的客户姓名" → Select Name From Customers Join Purchases
    On ... Where Purchase_Date > ...;\N3. "缺货产品的数量" →
- en: 'Here, once you give two examples of English-to-SQL, the AI is likely to answer
    the third query correctly by following the pattern. Few-shot examples can be applied
    to coding too: show the AI the style you want in a small sample and then ask for
    more. It’s like giving it a minitraining dataset within your prompt.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，一旦你给出两个英语到SQL的示例，AI很可能会按照模式正确回答第三个查询。少样本示例也可以应用于编码：在小的样本中向AI展示你想要的风格，然后要求更多。这就像在你的提示中给它一个迷你训练数据集。
- en: '*Pros:* You can achieve outputs in very specific styles. This technique also
    helps the model handle tasks that involve following a pattern or applying a concept
    repetitively.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*优点:* 你可以实现非常具体的输出风格。这种技术还有助于模型处理涉及遵循模式或重复应用概念的任务。'
- en: Context Window
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 上下文窗口
- en: The term *context window* refers to the maximum amount of text (measured in
    tokens) that a language model can process in a single interaction, including both
    the input prompt and the generated response. This represents a limitation of current
    AI models—once you reach this threshold, the model cannot process additional information.
    When you’re crafting prompts, everything you include (instructions, examples,
    data, and the space needed for the response) must fit within this fixed capacity.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 术语*上下文窗口*指的是语言模型在单次交互中可以处理的文本最大量（以标记衡量），包括输入提示和生成的响应。这代表了当前AI模型的限制——一旦达到这个阈值，模型就无法处理更多信息。当你制作提示时，你必须将包括在内的一切（指令、示例、数据和响应所需的空间）都放入这个固定容量中。
- en: '*Cons:* Few-shot prompting in particular makes the prompt longer (which uses
    up context window). For very large/complex examples, it might “eat” a lot of the
    model’s capacity. But usually a small example or two is fine.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*缺点:* 尤其是少样本提示会使提示变得更长（这会消耗上下文窗口）。对于非常大的/复杂示例，它可能会“消耗”模型的大量容量。但通常一个小例子或两个就足够了。'
- en: '*Tip:* If you want the model to strictly adhere to a certain output structure,
    giving an example can nearly guarantee it matches that structure rather than offering
    a free-form reply that you have to parse.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示:* 如果你想让模型严格遵循某种输出结构，给出一个例子几乎可以保证它符合该结构，而不是提供一个需要解析的自由形式回复。'
- en: Chain-of-Thought Prompting
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 思维链提示
- en: '*Chain-of-thought* (CoT) prompting involves asking the model to think step-by-step
    or show its reasoning before giving the final answer. In other words, you encourage
    the model to break down the problem.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '*思维链*（CoT）提示涉及要求模型在给出最终答案之前逐步思考或展示其推理。换句话说，你鼓励模型分解问题。'
- en: '*When to use:* This is useful for complex problems that involve reasoning and
    multistep computations, or when you suspect the model might make a mistake if
    it jumps straight to the answer. It’s also useful if you want an explanation in
    the output.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用:* 这对于涉及推理和多步计算的复杂问题很有用，或者当你怀疑模型如果直接跳到答案可能会出错时。如果你想在输出中看到解释，这也很有用。'
- en: Combinatorial Math
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组合数学
- en: '*Combinatorial math* deals with counting, arranging, and selecting objects
    according to specific rules or constraints. Common problems include calculating
    permutations (arrangements where order matters), combinations (selections where
    order does not matter), and other counting principles. Key notation includes “n
    choose k” (written as C(n,k) or nCk), which represents the number of ways to choose
    k items from n total items, calculated using the formula n!/(k!(n-k)!). These
    calculations frequently appear in probability, statistics, and discrete mathematics
    applications.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*组合数学* 处理根据特定规则或约束进行计数、排列和选择对象的问题。常见问题包括计算排列（顺序重要的排列）、组合（顺序不重要的选择）和其他计数原理。关键符号包括“从n中选k”（写作C(n,k)或nCk），它表示从n个总项目中选择k个项目的不同方式，该方式使用公式n!/(k!(n-k)!)计算。这些计算在概率、统计学和离散数学应用中经常出现。'
- en: '*Example:* Instead of just asking a [combinatorial math problem](https://oreil.ly/vI3V5)
    like “What is 12 choose 4?” and getting an answer, you might say:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例:* 与仅仅询问一个[组合数学问题](https://oreil.ly/vI3V5)如“12选4是什么？”并得到答案相比，你可能会说：'
- en: Solve 12 choose 4 step-by-step.
  id: totrans-146
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 逐步解决12选4。
- en: 'The model might then outline:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可能会先概述：
- en: '[PRE5]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In coding, CoT can be useful for tricky algorithmic tasks. You might try the
    following prompt:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在编码中，CoT对于棘手的算法任务很有用。你可以尝试以下提示：
- en: Explain step-by-step how to merge two sorted lists, then provide the Python
    code.
  id: totrans-150
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 逐步解释如何合并两个有序列表，然后提供Python代码。
- en: 'The model would first outline something like:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 模型首先可能会概述如下：
- en: We will use two pointers starting at the heads of each list, compare the elements,
    append the smaller to a result list, and move that pointer, and so on…
  id: totrans-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们将使用两个指针，分别从每个列表的头部开始，比较元素，将较小的元素追加到结果列表中，然后移动该指针，依此类推...
- en: Then it might give the code. This ensures it has structured the solution correctly
    before coding.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然后它可能会给出代码。这确保它在编码之前正确地构建了解决方案。
- en: 'Another use is debugging or understanding output:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个用途是调试或理解输出：
- en: Walk through the logic to determine if the number 19 is prime, then give the
    result.
  id: totrans-155
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 通过逻辑分析来确定19是否为素数，然后给出结果。
- en: 'The model might list divisions by primes, then conclude:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可能会列出素数的除法，然后得出结论：
- en: 19 is prime.
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 19是素数。
- en: '*Pros:* Improves correctness on tasks requiring reasoning. There’s [research
    evidence](https://oreil.ly/t7flF) that prompting the model to “think out loud”
    can lead to better results on math and logic tasks. It also gives you insight
    into the model’s process, which can be instructive or help you trust the answer
    more.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '*优点:* 提高了需要推理的任务的正确性。有[研究证据](https://oreil.ly/t7flF)表明，提示模型“大声思考”可以提高数学和逻辑任务的结果。这还让你了解了模型的过程，这可能是有益的或帮助你更信任答案。'
- en: '*Cons:* The output is longer (which might not be what you want in final code).
    Also, some interfaces (like typical code completions) aren’t set up to show reasoning
    separate from code. This technique is more common in Q&A or chat scenarios. However,
    you can instruct the model to include the reasoning as comments in the code, which
    is a neat way to get thoroughly commented code.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*缺点:* 输出会更长（这可能在最终代码中不是你想要的）。此外，一些接口（如典型的代码补全）没有设置好以显示与代码分开的推理。这种技术在问答或聊天场景中更为常见。然而，你可以指示模型将推理作为代码中的注释包含在内，这是一种获取详尽注释代码的巧妙方法。'
- en: Role Prompting
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 角色提示
- en: '*Role prompting* means you ask the AI to assume a certain identity or role
    that might influence how it responds.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*角色提示*意味着你要求AI扮演一个可能影响其响应方式的特定身份或角色。'
- en: '*When to use:* This is useful when you want to influence the style or detail
    of the answer or get a certain perspective. For instance, an AI taking on an “expert”
    role might give a more advanced solution or more explanation, while a “beginner”
    role might make it explain more basic concepts.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用:* 当你想影响答案的风格或细节，或获得某种特定观点时，这很有用。例如，一个扮演“专家”角色的AI可能会提供一个更高级的解决方案或更多的解释，而“初学者”角色可能会让它解释更多基本概念。'
- en: '*Examples:*'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例:*'
- en: You are a Python instructor. Explain the following code and then modify it to
    be more Pythonic.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是一位Python讲师。解释以下代码，然后修改它使其更符合Python风格。
- en: Act as a security analyst. Here’s some code. Identify any security vulnerabilities.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 担任安全分析师的角色。以下是一些代码。识别任何安全漏洞。
- en: Pretend you are a linter that checks code for style issues.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设你是一个检查代码风格问题的代码检查器。
- en: This can significantly affect the response. Assigning the AI a security analyst
    role might make it focus on things it otherwise wouldn’t mention (like data validation,
    secure coding practices, or potential vulnerabilities). An instructor role might
    make it provide clearer explanations and perhaps not assume prior knowledge.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以显著影响响应。将AI分配为安全分析师角色可能会让它关注它否则不会提及的事情（如数据验证、安全编码实践或潜在漏洞）。讲师角色可能会让它提供更清晰的解释，也许不会假设先验知识。
- en: 'In coding, you might say before asking for code:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在编码中，你可能会在请求代码之前说：
- en: You are an expert C++ programmer well-versed in optimization, instructing a
    junior developer.
  id: totrans-169
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你是一位精通优化的专家级C++程序员，正在指导一位初级开发者。
- en: The result will likely use more advanced C++ features and explain why certain
    choices were made, balancing technical sophistication with educational clarity.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可能会使用更多高级的C++特性，并解释为什么做出了某些选择，在技术复杂性和教育清晰度之间取得平衡。
- en: '*Pros:* This technique steers the tone and depth of the answer. This can tailor
    the solution to a certain level of complexity or thoroughness. It’s useful if
    you want either a very simple solution (tell it to act as a novice and maybe it’ll
    avoid complex tricks) or a very optimized one (tell it to act as a performance
    guru).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '*优点:* 这种技术可以引导答案的语气和深度。这可以使解决方案适应一定程度的复杂性或详尽程度。如果你想要一个非常简单的解决方案（让它扮演新手角色，可能会避免复杂的技巧）或一个非常优化的解决方案（让它扮演性能专家角色），这很有用。'
- en: '*Cons:* Sometimes the model might focus more on the persona than needed (an
    “instructor” might start explaining things you already know). Also, some AI safety
    systems are more sensitive to certain role descriptions—particularly those that
    might suggest deception, authority impersonation, or potentially harmful activities—though
    straightforward technical and professional roles like “data analyst” or “software
    engineer” typically work without issues.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '*缺点:* 有时模型可能会过分关注角色特征（例如，“讲师”可能会解释你已经知道的事情）。此外，一些AI安全系统对某些角色描述更为敏感——尤其是那些可能暗示欺骗、权威模仿或潜在有害活动的描述——尽管像“数据分析师”或“软件工程师”这样的直接技术和专业角色通常没有问题。'
- en: Contextual Prompting
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上下文提示
- en: '*Contextual prompting* means giving the AI additional context or information
    beyond the immediate task description. AI models don’t have persistent memory
    of your entire project unless you provide it in the prompt (or through some integrated
    context window in advanced IDE integrations). So if you want the AI to write code
    that fits into your existing codebase, give it that context. Basically, you supply
    relevant data or background as part of the prompt.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*上下文提示*意味着向AI提供超出即时任务描述的额外上下文或信息。除非你在提示中提供（或通过高级IDE集成中的某些集成上下文窗口），否则AI模型不会记住你整个项目的持久记忆。因此，如果你想AI编写适合你现有代码库的代码，就提供那个上下文。基本上，你将相关数据或背景作为提示的一部分提供。'
- en: '*When to use:* Use when solving a problem requires knowing certain data or
    definitions that the model might not know or might not recall correctly from training.
    Or use when you want to ensure consistency with some external info (like an API
    spec or previous part of conversation).'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用:* 当解决问题需要了解模型可能不知道或可能无法从训练中正确回忆的数据或定义时使用。或者，当您想确保与某些外部信息（如API规范或对话的先前部分）的一致性时使用。'
- en: '*Examples:*'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例:*'
- en: 'If you have a data structure and you want code that works with it, you might
    paste its definition:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个数据结构，并且想要与之配合工作的代码，你可以粘贴其定义：
- en: '[PRE6]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: By including the class definition, you make the AI much more likely to use `Node.value`
    and `Node.next` properly in its code.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 通过包含类定义，使AI更可能在其代码中正确使用`Node.value`和`Node.next`。
- en: 'If you want to use a specific API, include a snippet of the documentation in
    the prompt:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要使用特定的API，请在提示中包含文档片段：
- en: 'Using the requests library, fetch the data from the API. (The API returns JSON
    with format: {...})'
  id: totrans-181
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用requests库从API获取数据。（API返回格式为JSON的格式：{...}）
- en: If you include even a short example of API usage from docs, the AI can mimic
    it.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从文档中包含API使用的简短示例，AI可以模仿它。
- en: 'For disambiguation:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 为了消除歧义：
- en: Using the term `*student*` to refer to high school students, write a function
    that…
  id: totrans-184
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用术语`*学生*`来指代高中生，编写一个函数...
- en: If *student* could be ambiguous in context, you’ve clarified it.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在上下文中`*学生*`可能存在歧义，你已经澄清了它。
- en: '*Pros:* You’re grounding the AI in the context you care about. It’s less likely
    to make wrong assumptions if you supply the facts. This is extremely helpful if
    the AI otherwise might not remember or know your specific use-case details.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '*优点:* 你正在将AI扎根于你关心的上下文中。如果你提供事实，它就不太可能做出错误的假设。如果AI否则可能不会记住或知道你的特定用例细节，这非常有帮助。'
- en: '*Cons:* This technique makes prompts longer. Also, the model might occasionally
    regurgitate the provided context into the answer (like copying lines from a documentation
    snippet into the code if not careful). But usually it uses it appropriately.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '*缺点:* 这种技术会使提示变得更长。此外，模型有时可能会将提供的上下文直接重复到答案中（如果不小心，可能会像从文档片段中复制行到代码中一样）。但通常它使用它是恰当的。'
- en: '*Tip:* If you have a large context (like a big schema or many lines of code),
    sometimes it’s better to summarize the key elements for the model rather than
    including everything verbatim. This approach helps you stay within context limits
    while ensuring the model receives the most relevant information. However, if the
    content is small enough, just include it raw.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示:* 如果你有一个大的上下文（如大的模式或许多代码行），有时最好为模型总结关键元素，而不是包括所有内容。这种方法有助于你保持在上下文限制内，同时确保模型接收到的信息是最相关的。然而，如果内容足够小，只需直接包含它。'
- en: 'Constraints are also useful to mention: performance constraints (“Optimize
    for O(n log n) or better”), compatibility constraints (“Must run on Python 3.8”),
    or library choices (“Use standard library only, no external dependencies”). These
    act like guardrails and ensure the AI doesn’t suggest something outside acceptable
    bounds.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 提及约束条件也很有用：性能约束（“优化为O(n log n)或更好”），兼容性约束（“必须在Python 3.8上运行”），或库选择（“仅使用标准库，无外部依赖”）。这些就像护栏一样，确保AI不会建议超出可接受范围的内容。
- en: Metaprompting
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 元提示
- en: '*Metaprompting* is giving instructions about the output itself, not just what
    the solution should do. It’s like telling the AI how to format or approach the
    solution.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '*元提示*是关于输出本身的指令，而不仅仅是解决方案应该做什么。这就像告诉AI如何格式化或处理解决方案。'
- en: '*When to use:* Useful when you need the answer in a specific format or style
    or when you want to control how the AI works through the problem.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用:* 当您需要特定格式或风格的答案，或者您想通过问题控制AI的工作方式时，这很有用。'
- en: '*Examples:*'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例:*'
- en: First, explain the approach in two sentences, then provide the code.
  id: totrans-194
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 首先，用两句话解释方法，然后提供代码。
- en: 'This ensures the AI doesn’t launch straight into code:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这确保AI不会直接进入代码：
- en: Do not use any libraries in the solution.
  id: totrans-196
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在解决方案中不要使用任何库。
- en: 'This places a constraint on the solution:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这对解决方案施加了一个约束：
- en: Format the output as JSON.
  id: totrans-198
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将输出格式化为JSON。
- en: 'This is useful if you’re using the AI to produce data, not code:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用AI生成数据而不是代码，这很有用：
- en: Only provide the function body, without the definition line.
  id: totrans-200
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 只提供函数体，不要提供定义行。
- en: 'This is handy if you want to insert the function into existing code:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想将函数插入现有代码，这很方便：
- en: If the input is invalid, instead of error, return None.
  id: totrans-202
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果输入无效，而不是错误，返回None。
- en: This is not exactly the output format, but it’s instructing the AI how to behave
    for certain cases.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是一个精确的输出格式，但它指导AI在特定情况下如何表现。
- en: '*Pros:* You get exactly what you need, how you need it, without extra editing.
    This is crucial for some scenarios. If you plan to automatically use the AI’s
    output in a pipeline, then you really want consistent formatting.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '*优点:* 您可以得到您需要的，以您需要的方式，无需额外编辑。这在某些情况下至关重要。如果您计划自动将AI的输出用于管道，那么您真的希望格式保持一致。'
- en: '*Cons:* If the instructions conflict with the model’s default style, sometimes
    it might partially follow them or you have to emphasize them. For instance, even
    if you say “only code, no explanation,” occasionally the model might include a
    tiny comment or so. Usually, phrasing it as a direct imperative helps:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '*缺点:* 如果指令与模型的默认风格冲突，有时它可能部分遵循它们，或者您必须强调它们。例如，即使您说“只有代码，没有解释”，偶尔模型可能会包含一些小的注释。通常，用直接命令的措辞有助于：'
- en: Do not include any explanation; output only code inside a single code block.
  id: totrans-206
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不要包含任何解释；仅在一个代码块内输出代码。
- en: Models like GPT follow that quite well.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 像GPT这样的模型很好地遵循这一点。
- en: Self-Consistency (Multiple Outputs and Majority Voting)
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自洽性（多个输出和多数投票）
- en: '*Self-consistency* is more of a strategy than a prompt style. The idea is to
    get multiple outputs for the same prompt and then decide on the best or most common
    one. As [Sander Schulhoff of Learn Prompting notes](https://oreil.ly/fHABW), self-consistency
    leverages the notion that if you ask the model multiple times (with slight randomness)
    and many of its answers agree, that consensus is likely correct.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '*自洽性*更多的是一种策略，而不是提示风格。想法是获取相同提示的多个输出，然后决定最好的或最常见的。正如[Sander Schulhoff of Learn
    Prompting]（https://oreil.ly/fHABW）指出，自洽性利用了这样一个观点：如果您多次（带有轻微随机性）询问模型，并且许多答案一致，那么这种共识很可能是正确的。'
- en: '*When to use:* This is useful for complex problems where you’re unsure the
    model’s first answer is correct, especially if you can’t verify it easily yourself,
    or if you want a confidence check from the AI by seeing whether it gives the same
    answer repeatedly.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*何时使用:* 这对于复杂问题很有用，您不确定模型的第一个答案是否正确，尤其是如果您无法轻松验证它，或者您想通过看到它是否反复给出相同答案来从AI那里获得信心检查。'
- en: '*How to use manually:* On some platforms (like ChatGPT), you can click “Regenerate
    answer.” Or you can copy the prompt into a new session and see if it gives the
    same result. If you get three answers and two are the same and one is different,
    you might trust the two (assuming the problem has a single correct answer).'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '*手动使用方法:* 在某些平台（如ChatGPT）上，您可以点击“重新生成答案”。或者，您可以将提示复制到新会话中，看看是否得到相同的结果。如果您得到三个答案，其中两个相同，一个不同，您可能会相信那两个（假设问题只有一个正确答案）。'
- en: In programming context, if it’s generating code for something deterministic,
    usually it will give very similar code each time (with small variations in variable
    names or style). But if it’s an algorithmic question (like “What’s the output
    of this code?”), you could check multiple runs.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在编程环境中，如果它为确定性任务生成代码，通常每次都会给出非常相似的代码（变量名或风格上的小变化）。但如果是一个算法问题（如“这段代码的输出是什么？”），你可以检查多次运行。
- en: This technique is more powerful in noncoding tasks (like logic puzzles) but
    worth noting.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术在非编码任务（如逻辑谜题）中更强大，但值得关注。
- en: '*Another angle—ensemble prompting:* You can actually ask the model within one
    prompt to consider multiple possibilities:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '*另一个角度——集成提示：* 你实际上可以在一个提示中让模型考虑多个可能性：'
- en: Give two different solutions to this problem.
  id: totrans-215
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为这个问题提供两种不同的解决方案。
- en: Then perhaps you can see which one you like or test both. This is like self-consistency
    in one shot because you get multiple answers.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可能可以看到你喜欢的哪一个，或者测试两个。这就像一次性获得多个答案的自我一致性。
- en: '*Pros:* This technique can increase confidence in the solution if multiple
    attempts converge. Also, you might get variety (which is good if you want to choose
    the most elegant solution among many).'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '*优点：* 如果多次尝试收敛，这种技术可以提高对解决方案的信心。此外，你可能会得到多样性（如果你想在多个解决方案中选择最优雅的解决方案，这很好）。'
- en: '*Cons:* It’s time-consuming to do multiple calls and compare outputs.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '*缺点：* 进行多次调用并比较输出很耗时。'
- en: In practice, if I’m unsure about an answer, I’ll often repose the question differently
    to see if I get the same answer. If I do, I’m more confident it’s correct.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，如果我对答案不确定，我经常会以不同的方式重新提出问题，看看是否能得到相同的答案。如果我能得到相同的答案，我就更有信心它是正确的。
- en: ReAct (Reason + Act) Prompting
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReAct (推理 + 行动) 提示
- en: '*ReAct* is a more advanced prompting technique that [combines *reasoning* and
    *acting*](https://arxiv.org/abs/2210.03629). It gets the model not only to think,
    like CoT does, but also to take actions like making a calculation, calling an
    API, or using a tool. (See the [ReAct Prompt Engineering Guide](https://oreil.ly/P_KIV)
    for more). In current practice, this is often used with frameworks like LangChain,
    where the AI can output a special format that a program interprets as an action
    (like a command to execute or a query to run), then feed the result back.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '*ReAct* 是一种更高级的提示技术，它[结合了 *推理* 和 *行动*](https://arxiv.org/abs/2210.03629)。它不仅让模型像
    CoT 那样思考，还能执行计算、调用 API 或使用工具等动作。（更多信息请参阅 [ReAct 提示工程指南](https://oreil.ly/P_KIV)）。在当前实践中，这通常与
    LangChain 等框架一起使用，其中 AI 可以输出程序解释为动作的特殊格式（如执行命令或运行查询），然后将结果反馈回来。'
- en: For our scope (without such an execution environment in the loop), you can still
    do a form of ReAct by instructing the AI to first outline a plan, then output
    the result. It’s similar to CoT but specifically oriented to using tools or performing
    subtasks.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的范围（在没有这种执行环境的情况下），你仍然可以通过指示 AI 首先概述一个计划，然后输出结果来进行一种形式的 ReAct。这类似于 CoT，但专门针对使用工具或执行子任务。
- en: '*Example:*'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '*示例：*'
- en: Using Python, determine the current weather in Paris and print it.
  id: totrans-224
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使用 Python，确定巴黎当前的天气并将其打印出来。
- en: 'Unless the AI has browsing capabilities, it cannot truly get the current weather.
    A ReAct approach would have the AI first reason through the problem by stating:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 除非 AI 具有浏览能力，否则它无法真正获取当前的天气。ReAct 方法会让 AI 首先通过陈述问题来推理问题：
- en: I need to access current weather data for Paris, which requires calling a weather
    API.
  id: totrans-226
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我需要获取巴黎当前的天气数据，这需要调用天气 API。
- en: The AI would then attempt to use an available tool to make this API call. If
    successful, it would receive actual weather data; if no such tool is available,
    it might acknowledge the limitation or work with hypothetical data. Finally, the
    AI would write the Python code to display the weather information, incorporating
    whatever data it was able to obtain through this reasoning and action process.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 然后 AI 会尝试使用可用的工具来调用这个 API。如果成功，它会接收到实际的天气数据；如果没有这样的工具，它可能会承认限制或使用假设数据。最后，AI
    会编写 Python 代码来显示天气信息，结合通过推理和行动过程获得的所有数据。
- en: Without external tool access, ReAct might not be particularly relevant for simple
    prompting tasks. However, when evaluating AI tools for your organization, determining
    whether they can access current information from the internet represents a critical
    capability assessment. Many AI models operate with knowledge cutoffs, meaning
    their training data only extends to a specific date, which can result in outdated
    information for rapidly changing topics.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 没有外部工具访问，ReAct可能对简单的提示任务并不特别相关。然而，在评估你组织的AI工具时，确定它们是否可以访问互联网上的当前信息代表了一个关键的能力评估。许多AI模型在知识截止点下运行，这意味着它们的训练数据只延伸到特定日期，这可能导致快速变化主题的信息过时。
- en: 'If you are using an environment where the AI can execute code (such as Jupyter
    integrations or similar platforms), you could implement ReAct by instructing the
    system:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个AI可以执行代码的环境中（例如Jupyter集成或类似平台），你可以通过指示系统来实现ReAct：
- en: First write a test for this function, run it, then adjust the code accordingly.
  id: totrans-230
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 首先为这个函数编写一个测试，运行它，然后相应地调整代码。
- en: This demonstrates the ReAct pattern through a reasoning step (writing the test),
    followed by an action (executing the test), and then code adjustment based on
    the results. However, orchestrating such workflows through pure prompts requires
    advanced prompting techniques and appropriate technical infrastructure.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过一个推理步骤（编写测试）来展示ReAct模式，然后是执行测试的动作，然后根据结果调整代码。然而，通过纯提示来编排这样的工作流程需要高级提示技术和适当的技术基础设施。
- en: '*Simpler use:* You can simulate a Q&A where the AI has intermediate steps that
    mimic actions:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '*简单使用:* 你可以模拟一个问答，其中AI有中间步骤来模拟动作：'
- en: Think step-by-step and if you need to, do calculations.
  id: totrans-233
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 逐步思考，如果需要，进行计算。
- en: It’s effectively CoT but with a more imperative tone.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是CoT，但语气更加命令式。
- en: '*Pros:* When available, it can solve problems that require external info or
    iterative trial (like the AI can correct itself by actually running code). In
    debugging contexts, an AI that can execute code to test it is fantastic.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '*优点:* 当可用时，它可以解决需要外部信息或迭代试验的问题（例如，AI可以通过实际运行代码来自我纠正）。在调试环境中，能够执行代码以进行测试的AI非常出色。'
- en: '*Cons:* This technique is not widely accessible without specific tooling. And
    if you just prompt that way in plain ChatGPT, it will either imagine the actions
    or just do CoT.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '*缺点:* 这种技术没有特定的工具支持时并不广泛可用。而且，如果你在普通的ChatGPT中以这种方式进行提示，它要么会想象动作，要么只是做CoT。'
- en: For our purposes in prompt writing, keep in mind that some systems (like OpenAI’s
    tool-using agents or others) exist, but in vanilla prompting we mostly do CoT,
    and we ourselves handle actions like running the code or tests.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写提示的目的上，请记住，一些系统（如OpenAI的工具使用代理或其他系统）存在，但在纯提示中，我们主要做CoT，并且我们自己处理像运行代码或测试这样的动作。
- en: 'Advanced Prompting: Combining Techniques and Handling Complexity'
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级提示：结合技术和处理复杂性
- en: 'Prompting techniques can be combined. For instance, you might do a few-shot
    prompt that also demonstrates CoT in the examples. Or you might combine a role
    with CoT:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 提示技术可以结合使用。例如，你可能进行一个几轮提示，同时也在示例中展示CoT。或者你可能将角色与CoT结合：
- en: As a senior engineer, think step-by-step through the problem, then give the
    code.
  id: totrans-240
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为一名高级工程师，逐步思考问题，然后给出代码。
- en: Now that we’ve explored various prompting techniques, let’s see them in action
    with a scenario or two, then discuss how to review and refine the AI’s output
    (which leads into the next chapter about understanding and owning the generated
    code).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了各种提示技术，让我们通过一个或两个场景来看看它们在实际中的应用，然后讨论如何审查和改进AI的输出（这引出了下一章关于理解和掌握生成代码的内容）。
- en: 'Imagine you have a function that isn’t working. You might use a combination
    of role and CoT prompting:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个不工作的函数。你可能需要结合角色和CoT提示：
- en: You are a Python debugger. Let’s think step-by-step to find the bug in the following
    code.
  id: totrans-243
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你是一位Python调试器。让我们逐步思考，找出以下代码中的错误。
- en: This would be followed by the code. The AI might respond with an analysis of
    each line and pinpoint the bug.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这将随后是代码。AI可能会对每一行进行分析，并指出错误。
- en: 'Or let’s say you want to generate code for a somewhat complex algorithm, ensure
    it’s well commented, and also get test cases for it. A combined prompt might look
    like this:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 或者让我们假设你想要为某个相对复杂的算法生成代码，确保它有良好的注释，并且还需要为其获取测试用例。一个组合提示可能看起来像这样：
- en: You are an expert Python developer. Let’s solve this step-by-step. We need a
    function `merge_sorted_lists(list1, list2)` that merges two sorted lists into
    one sorted list. First, explain the approach, then provide the Python code with
    comments. After that, give 2–3 example tests in code to demonstrate it works.
  id: totrans-246
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你是一位专家Python开发者。让我们一步步解决这个问题。我们需要一个函数`merge_sorted_lists(list1, list2)`，它将两个排序后的列表合并成一个排序后的列表。首先，解释方法，然后提供带有注释的Python代码。之后，给出2-3个示例测试代码来演示它的工作。
- en: This single prompt is quite comprehensive. The first sentence sets a role. The
    second requests step-by-step reasoning. The third gives the main task. The fourth
    sentence asks for code with explanatory comments, and the fifth even asks for
    tests.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这个单一提示非常全面。第一句话设定了一个角色。第二句要求逐步推理。第三句给出了主要任务。第四句要求带有解释注释的代码，第五句甚至要求测试。
- en: The AI might then output an explanation, then the code with inline comments,
    then some test cases at the end. This is an advanced use, but it shows how you
    can direct the AI through a multifaceted response.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，AI可能会输出一个解释，然后是带有内联注释的代码，最后是一些测试用例。这是一个高级用法，但它展示了你可以如何通过多方面的响应来指导AI。
- en: Know the Model’s Limits
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解模型的限制
- en: Prompt engineering also involves knowing what *not* to ask and how to avoid
    pitfalls. If a prompt is getting too large or includes too many instructions,
    the model might get confused or truncate some output. If you find it starts ignoring
    parts of your prompt, you might need to simplify or do it in parts. If an AI model
    sometimes produces incorrect facts or code (it “hallucinates”), you learn to double-check
    and not use it as a factual oracle. If you find it tends to give overly verbose
    code, you can preempt that with “Make the solution as concise as possible.” If
    it sometimes uses functions that don’t exist, you might instruct, “Use only the
    API functions listed below” and list them. The better you understand the AI’s
    behavior, the more you can mold your prompts to get around any weaknesses.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程还涉及知道什么**不**要问以及如何避免陷阱。如果一个提示太长或包含太多指令，模型可能会感到困惑或截断部分输出。如果你发现它开始忽略你的提示部分，你可能需要简化或分部分来做。如果一个AI模型有时会产生错误的事实或代码（它“产生幻觉”），你会学会双重检查并且不将其作为事实预言家使用。如果你发现它倾向于给出过于冗长的代码，你可以通过“尽可能使解决方案简洁”来预防。如果它有时使用不存在的函数，你可以指示“只使用以下列出的API函数”并列出它们。你越了解AI的行为，你就能越能调整你的提示来克服任何弱点。
- en: 'If a task is very complex, you can also break it into subtasks for the AI.
    For example, you might first prompt:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个任务非常复杂，你也可以将其分解为子任务给AI。例如，你可能会首先提示：
- en: List the steps to implement a basic compiler for a simple arithmetic expression
    language.
  id: totrans-252
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 列出实现一个简单算术表达式语言的基本编译器的步骤。
- en: 'Once the AI gives the steps, you tackle each step with separate prompts, maybe
    even in separate files or sessions:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦AI给出了步骤，你就用单独的提示来处理每个步骤，甚至可能在单独的文件或会话中：
- en: 'Now implement step 1: tokenization.'
  id: totrans-254
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现在实现步骤1：分词。
- en: 'This is like doing system design with the AI: you can outline then refine each
    piece. It leverages the AI’s ability to assist in planning (not just coding).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这就像用AI做系统设计：你可以概述然后细化每个部分。它利用了AI在规划（不仅仅是编码）方面的辅助能力。
- en: Stateful Conversation Versus One-Shot Prompting
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有状态对话与一次性提示
- en: In a chat setting, you have a conversation history, known as *state*. You can
    build up context by discussing with the AI. In an IDE completion setting, the
    context is mostly your file content and comments. Both allow cumulative context
    in different ways. Use conversation if you need the AI to remember what was said
    (like refining an answer). Use fresh prompts or file context if you want to ensure
    it’s focusing only on what’s relevant now. Sometimes wiping away the context prevents
    the model from sticking to a potentially wrong earlier assumption.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在聊天设置中，你有一个对话历史，称为**状态**。你可以通过与AI讨论来建立上下文。在IDE完成设置中，上下文主要是你的文件内容和注释。两者都以不同的方式允许累积上下文。如果你需要AI记住之前说过的话（比如完善答案），请使用对话。如果你想确保它只关注现在相关的信息，请使用新的提示或文件上下文。有时清除上下文可以防止模型坚持可能错误的早期假设。
- en: 'By practicing with these techniques on various examples, you’ll become adept
    at knowing which approach to use and when:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在各种示例中练习这些技术，你会熟练地知道何时使用哪种方法：
- en: If output format is important, give examples (few shot) or explicit formatting
    instructions.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果输出格式很重要，给出示例（少样本）或明确的格式化指令。
- en: If logic is tricky, use CoT or step-by-step.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果逻辑很复杂，使用CoT或逐步进行。
- en: If the solution can vary in quality, set a role (like “seasoned engineer”) to
    get a better style.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果解决方案的质量可能有所不同，设置一个角色（如“资深工程师”）以获得更好的风格。
- en: If the model isn’t complying, maybe break your prompts into pieces, simplify
    them, or use stronger wording for constraints.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果模型不遵守，也许可以将你的提示分成几个部分，简化它们，或者使用更强的措辞来约束。
- en: Common Prompt Antipatterns and How to Avoid Them
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见提示反模式及其避免方法
- en: Not all prompts are created equal. By now, we’ve seen numerous examples of effective
    prompts, but it’s equally instructive to recognize antipatterns—common mistakes
    that lead to poor AI responses. This section covers some frequent prompt failures
    and how to fix them.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有提示都是平等的。到目前为止，我们已经看到了许多有效的提示示例，但同样有教育意义的是识别反模式——这些常见的错误会导致AI的糟糕响应。本节涵盖了一些常见的提示失败及其修复方法。
- en: The vague prompt
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模糊的提示
- en: This is the classic “It doesn’t work, please fix it” or “Write something that
    does X” without enough detail. The question “Why isn’t my function working?” will
    generally get a useless answer. Vague prompts force the AI to guess the context
    and often result in generic advice or irrelevant code.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种经典的“它不起作用，请修复它”或“写一些能做X的事情”的描述，但缺乏足够的细节。问题“我的函数为什么不起作用？”通常只会得到一个无用的答案。模糊的提示迫使AI猜测上下文，通常会导致一般性的建议或不相关的代码。
- en: 'The fix is straightforward: add context and specifics. If you find yourself
    asking a question and the answer feels like a Magic 8–Ball response (“Have you
    tried checking X?”), stop and reframe your query with more details (error messages,
    code excerpt, expected versus actual outcome, etc.). A good practice is to read
    your prompt and ask, “Could this question apply to dozens of different scenarios?”
    If the answer is yes, it’s too vague. Make it so specific that it could only apply
    to your scenario.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方法是添加上下文和具体细节。如果你发现自己提出一个问题，而答案感觉像是一个魔球（“你尝试检查X了吗？”），停下来，用更多细节重新构建你的查询（错误信息、代码摘录、预期与实际结果等）。一个好的做法是阅读你的提示并问自己，“这个问题是否适用于数十种不同的场景？”如果答案是肯定的，那么它太模糊了。让它变得如此具体，以至于只能适用于你的场景。
- en: The overloaded prompt
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过载的提示
- en: 'This is the opposite issue: asking the AI to do too many things at once. For
    instance:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这是相反的问题：要求AI一次做太多事情。例如：
- en: Generate a complete Node.js app with authentication, a frontend in React, and
    deployment scripts.
  id: totrans-270
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 生成一个完整的Node.js应用程序，包括身份验证、React前端和部署脚本。
- en: 'Or even, on a smaller scale:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，在更小的范围内：
- en: Fix these 5 bugs and also add these 3 features in one go.
  id: totrans-272
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一次性修复这5个错误并添加这3个功能。
- en: The AI might attempt it, but you’ll likely get a jumbled or incomplete result,
    or it might ignore some parts of the request. Even if it addresses everything,
    the response will be long and harder to verify.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: AI可能会尝试，但你很可能会得到一个混乱或不完整的结果，或者它可能会忽略请求的一些部分。即使它解决了所有问题，响应也会很长且难以验证。
- en: 'The remedy is to split the tasks. Prioritize: do one thing at a time, as we
    emphasized earlier. This makes it easier to catch mistakes and ensures the model
    stays focused. If you catch yourself writing a paragraph that uses “and” multiple
    times in the instructions, consider breaking it into separate prompts or sequential
    steps.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方法是分解任务。优先考虑：一次只做一件事，正如我们之前强调的那样。这使得更容易捕捉错误并确保模型保持专注。如果你发现自己写了一个在指令中使用“和”多次的段落，考虑将其分解成单独的提示或顺序步骤。
- en: Missing the question
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 缺少问题
- en: Sometimes users will present a lot of information but never clearly ask a question
    or specify what they need, like dumping a large code snippet and just saying,
    “Here’s my code.” This can confuse the AI—it doesn’t know what you want.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 有时用户会提供大量信息，但从未清楚地提出问题或指定他们需要什么，就像只是扔出一个大的代码片段，然后说，“这是我的代码。”这可能会让AI困惑——它不知道你想要什么。
- en: 'Always include a clear ask:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 总是包括一个清晰的请求：
- en: Identify any bugs in the above code.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别上述代码中的任何错误。
- en: Explain what this code does.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释这段代码的功能。
- en: Complete the to-dos in the code.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成代码中的待办事项。
- en: A prompt should have a purpose. If you just provide text without a question
    or instruction, the AI might make incorrect assumptions (like summarizing the
    code instead of fixing it, etc.). Make sure the AI knows why you showed it some
    code. Even a simple addition like “What’s wrong with this code?” or “Please continue
    implementing this function” gives it direction.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 一个提示应该有一个目的。如果你只是提供文本而没有问题或指令，AI可能会做出错误的假设（比如总结代码而不是修复它等）。确保AI知道你为什么展示了某些代码。即使是简单的添加，如“这段代码有什么问题？”或“请继续实现这个函数”，也能给它指明方向。
- en: Vague success criteria
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模糊的成功标准
- en: 'This is a subtle one. Sometimes you might ask for an optimization or improvement,
    but you don’t define what success looks like—for example, “Make this function
    faster.” Faster by what metric? If the AI doesn’t know your performance constraints,
    it might micro-optimize something that doesn’t matter or use an approach that’s
    theoretically faster but practically negligible. Or “Make this code cleaner”:
    “cleaner” is subjective. We dealt with this by explicitly stating goals like “reduce
    duplication” or “improve variable names,” etc.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个微妙的问题。有时你可能会要求优化或改进，但你没有定义成功是什么样的——例如，“让这个函数更快。”更快是根据什么指标？如果AI不知道你的性能限制，它可能会对一些无关紧要的事情进行微观优化，或者使用理论上更快但实际上可以忽略不计的方法。或者“让这个代码更简洁”：简洁是主观的。我们通过明确陈述目标来解决此问题，例如“减少重复”或“改进变量名”等。
- en: 'The fix: quantify or qualify the improvement:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 修复方法：量化或限定改进：
- en: Optimize this function to run in linear time (current version is quadratic).
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化此函数以线性时间运行（当前版本是二次方）。
- en: Refactor this to remove global variables and use a class instead.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将此重构以移除全局变量并使用类代替。
- en: Basically, be explicit about what problem you’re solving with the refactor or
    feature. If you leave it too open, the AI might solve a different problem than
    the one you care about.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，在重构或功能中明确说明你正在解决的问题。如果你让它太开放，AI可能会解决一个与你关心的不同的问题。
- en: Ignoring AI’s clarification or output
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 忽略AI的澄清或输出
- en: 'Sometimes the AI might respond with a clarifying question or an assumption:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 有时AI可能会用一个澄清问题或假设来回应：
- en: Are you using React class components or functional components?
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你使用的是React类组件还是函数组件？
- en: I assume the input is a string—please confirm.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我假设输入是一个字符串——请确认。
- en: If you ignore these and just reiterate your request, you’re missing an opportunity
    to improve the prompt. The AI is signaling that it needs more info. Always answer
    its questions or refine your prompt to include those details.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你忽略这些并只是重复你的请求，你错过了改进提示的机会。AI正在发出需要更多信息的需求信号。始终回答它的问题或改进你的提示以包括这些细节。
- en: 'Additionally, if the AI’s output is clearly off (like it misunderstood the
    question), don’t just retry the same prompt verbatim. Take a moment to adjust
    your wording. Maybe your prompt had an ambiguous phrase or omitted something essential.
    Treat it like a conversation: if a human misunderstood, you’d explain differently;
    do the same for the AI.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果AI的输出明显错误（例如误解了问题），不要只是重复相同的提示。花点时间调整你的措辞。也许你的提示中有一个模糊的短语或遗漏了某些关键信息。把它当作对话来处理：如果一个人误解了，你会用不同的方式解释；对AI也这样做。
- en: Inconsistency
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不一致性
- en: If you keep changing how you ask or mixing different formats in one go, the
    model can get confused. Two examples include switching between first person and
    third person in instructions or mixing pseudocode with actual code in a confusing
    way.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不断改变提问方式或一次混合不同的格式，模型可能会感到困惑。两个例子包括在说明中在第一人称和第三人称之间切换或以令人困惑的方式将伪代码与实际代码混合。
- en: Try to maintain a consistent style within a single prompt. If you provide examples,
    ensure they are clearly delineated (use Markdown triple backticks for code, quotes
    for input/output examples, etc.). Consistency helps the model parse your intent
    correctly. Also, if you have a preferred style (say, ES6 versus ES5 syntax), consistently
    mention it; otherwise, the model might suggest one way in one prompt and another
    way later.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试在单个提示中保持一致的风格。如果你提供示例，确保它们清晰界定（使用Markdown三重反引号表示代码，引号表示输入/输出示例等）。一致性有助于模型正确解析你的意图。此外，如果你有首选风格（比如，ES6与ES5语法），请始终一致地提及它；否则，模型可能会在一个提示中建议一种方式，而在以后的提示中建议另一种方式。
- en: Vague references like “the above code”
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模糊的引用，如“上面的代码”
- en: When using chat, if you say “the above function” or “the previous output,” be
    sure the reference is clear. If the conversation is long and you say, “Refactor
    the above code,” the AI might lose track or pick the wrong code snippet to refactor.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用聊天时，如果你说“上面的函数”或“前面的输出”，确保引用是清晰的。如果对话很长，你说，“重构上面的代码”，AI可能会失去跟踪或选择错误的代码片段进行重构。
- en: It’s safer to either quote the code again or specifically name the function
    you want refactored. Models have a limited attention window, and although many
    LLMs can refer to prior parts of the conversation, giving it explicit context
    again can help avoid confusion. This is especially true if some time (or several
    messages) passed since the code was shown.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 最好是再次引用代码或具体指出你想重构的函数。模型有有限的注意力窗口，尽管许多LLM可以参考对话的先前部分，但再次提供明确的上下文可以帮助避免混淆。这尤其适用于代码展示后经过了一些时间（或几条消息）。
- en: Summary and Next Steps
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要和下一步
- en: 'The art of prompting is iterative and creative. As models evolve, prompt best
    practices might change (for instance, future models might better understand intent
    with less wording). But the underlying principle remains: communicate effectively,
    and the AI will serve you better.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 提示的艺术是迭代和创造性的。随着模型的发展，提示的最佳实践可能会改变（例如，未来的模型可能用更少的文字就能更好地理解意图）。但基本原理保持不变：有效沟通，AI将更好地为你服务。
- en: In essence, mastering prompt engineering is like mastering a new programming
    language—the language of instructions for AI. It’s a blend of technical writing,
    foresight, and interactive debugging of the *prompt* itself. But once you get
    good at it, the AI truly starts to feel like an extension of your own mind, because
    you can reliably extract the solutions you envision (or even those you don’t fully
    envision yet but can guide the AI to discover) with minimal friction. This skill
    will likely become as fundamental as knowing how to google things or how to use
    a debugger—it’s part of the modern developer’s skill set in the age of vibe coding.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，掌握提示工程就像掌握一门新的编程语言——AI的指令语言。它融合了技术写作、前瞻性和对*提示*本身的交互式调试。但一旦你擅长它，AI就会真正地感觉像是你思维的延伸，因为你可以用最小的摩擦可靠地提取你设想（甚至是你尚未完全设想但可以引导AI发现的）的解决方案。这项技能可能会变得和知道如何使用谷歌或如何使用调试器一样基本——它是现代开发者技能集在vibe编码时代的一部分。
- en: If AI can solve about 70% of a problem, how do you approach it as a partner
    in coding? [Chapter 3](ch03.html#ch03_the_70_problem_ai_assisted_workflows_that_actual_1752630043200933)
    looks at how developers *really* use AI and sets out some “golden rules” for vibe
    coding.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 如果AI可以解决大约70%的问题，你作为编码的合作伙伴将如何处理？[第3章](ch03.html#ch03_the_70_problem_ai_assisted_workflows_that_actual_1752630043200933)探讨了开发者*真正*如何使用AI，并制定了一些“黄金法则”用于vibe编码。
