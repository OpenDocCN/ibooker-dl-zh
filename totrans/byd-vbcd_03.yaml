- en: 'Chapter 2\. The Art of the Prompt: Communicating Effectively with AI'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In vibe coding, prompts are the new source code.
  prefs: []
  type: TYPE_NORMAL
- en: The way you communicate your intent to the AI has a direct impact on the quality
    of the code it generates. Writing a good prompt is both an art and a science,
    often called *prompt engineering*. This chapter will equip you with techniques
    to get the most out of your AI coding assistant. We’ll start with some fundamentals
    about why prompts matter and then delve into a toolbox of prompting techniques,
    from simple to advanced. By learning how to craft effective prompts and how to
    iteratively refine them ([Figure 2-1](#ch02_figure_1_1752630042957579)), you’ll
    be able to cocreate with AI more efficiently and accurately.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bevc_0201.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2-1\. An illustration of a chatbot assisting with coding. The developer
    and AI engage in a dialogue: the developer provides instructions or questions
    (prompts), and the AI responds with code or answers. Communicating effectively
    with the AI through well-crafted prompts is key to getting accurate and useful
    code generation.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Prompt Engineering Fundamentals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If vibe coding is a conversation between you and an AI model, *prompt engineering*
    is the skill of speaking the AI’s language to get the best results. A well-crafted
    prompt can be the difference between an irrelevant or buggy code suggestion and
    a perfect solution. Mastering prompt engineering means understanding how to guide
    the AI effectively, how to provide context, and how to iterate with the AI when
    the first answer isn’t quite right.
  prefs: []
  type: TYPE_NORMAL
- en: When you program with an AI, you are essentially programming *through* the AI
    using natural language. The prompt you provide is like a high-level programming
    language that the AI interpreter then translates into actual code. Just as a compiler’s
    output is only as good as the source code fed to it, an AI’s output is only as
    good as the prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 'Why are prompts so important? LLMs, despite their sophistication, are not mind
    readers. They respond only to the input they’re given. Ambiguous or poorly worded
    prompts can lead to irrelevant or incorrect code, while a clear and specific prompt
    can yield a spot-on solution on the first try. In traditional coding, you spend
    time thinking about algorithms and writing code; in vibe coding, you spend time
    thinking about how to convey your requirements to the AI. It’s a shift in what
    “writing code” means: you might write a paragraph instead of a function, but you
    still need to be precise and logical.'
  prefs: []
  type: TYPE_NORMAL
- en: Think of writing prompts as being like writing documentation or user stories
    for a very literal and pedantic junior developer, one who will do exactly (and
    only) what the documentation says, and who has a lot of knowledge but no common
    sense beyond patterns they have seen. If your instructions (prompts) leave room
    for interpretation, the AI might fill the gaps in ways you didn’t intend. Thus,
    learning to *communicate* with the AI is as crucial as learning a programming
    language’s syntax used to be.
  prefs: []
  type: TYPE_NORMAL
- en: Another reason prompts are crucial is reproducibility and future-proofing. If
    you discover a prompt that reliably generates good code for a certain pattern
    or task, that prompt becomes a valuable piece of knowledge (almost like a snippet
    or template). You might save it or reuse it in similar contexts. In teams, developers
    might share effective prompt patterns with each other, similar to how they share
    coding best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, as models get better and more integrated, they may allow more complex
    interactions. Being good at prompting will let you harness new capabilities quickly.
    For instance, some advanced systems allow you to attach extensive instructions
    or provide entire reference documents as part of the context for the model. Knowing
    how to structure that input is key to leveraging such power.
  prefs: []
  type: TYPE_NORMAL
- en: So treat prompt writing as a new essential skill. In many ways, prompting *is*
    programming. The main difference is you’re writing in a language (like English)
    that the AI then converts into code. But you still have to be clear, logical,
    and anticipate edge cases in your description.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specificity and Clarity: Writing Prompts That Deliver'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the golden rules of prompting (which I’ll lay out more fully in [Chapter 3](ch03.html#ch03_the_70_problem_ai_assisted_workflows_that_actual_1752630043200933))
    is to be specific and clear about what you want. Unlike a human collaborator,
    an AI doesn’t truly understand your goal beyond the words you provide. A common
    mistake is giving the AI a very high-level prompt like “Make a website” and expecting
    magic. The AI works better with concrete details.
  prefs: []
  type: TYPE_NORMAL
- en: Always assume it knows nothing about your project beyond what you provide. Include
    relevant details such as the programming language, framework, and libraries, as
    well as the specific function or snippet in question. If there’s an error, provide
    the exact error message and describe what the code is supposed to do. Any vagueness
    or room for interpretation can lead to unintended outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, instead of “Write a sorting function,” you could say:'
  prefs: []
  type: TYPE_NORMAL
- en: Write a Python function sort_by_lastname(customers) that takes a list of customer
    records (each with a first_name and last_name field) and returns a list sorted
    by last_name alphabetically. Include a brief docstring and handle the case of
    missing last names by treating them as empty strings.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This prompt sets clear expectations about the language (Python), the function
    name and purpose, the input structure, the sort key, additional requirements (docstring),
    and an edge case. It’s likely to produce exactly what you need or very close to
    it. Essentially, think like a spec writer: the more precisely you specify the
    task, the less guesswork the AI has to do and the fewer revisions you’ll need.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Strategies for specificity include:'
  prefs: []
  type: TYPE_NORMAL
- en: Mention the language or environment
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want a solution in JavaScript, say so: “Write a JavaScript function...”
    versus just “Write a function...” If you want it for a specific framework or version,
    include that (“Using React Hooks...” or “in Python 3...”).'
  prefs: []
  type: TYPE_NORMAL
- en: Define the scope of the output
  prefs: []
  type: TYPE_NORMAL
- en: Do you want just a single function? A full file or module? Tests included? For
    example, “Provide only the function implementation” and “Provide a complete runnable
    script” can yield different responses.
  prefs: []
  type: TYPE_NORMAL
- en: Include requirements and constraints
  prefs: []
  type: TYPE_NORMAL
- en: 'In the login example, we specified password length and attempt limit. Think
    of edge cases or constraints and put them in the prompt. If you need the code
    to be optimized for performance or use a certain algorithm, say so: “using O(n)
    time and O(1) space” or “using a binary search approach.”'
  prefs: []
  type: TYPE_NORMAL
- en: Avoid ambiguous references
  prefs: []
  type: TYPE_NORMAL
- en: Don’t use words like *it* without a clear antecedent. Instead of “Process it
    and return the result,” say, “Process the array and return the resulting array.”
  prefs: []
  type: TYPE_NORMAL
- en: Name your desired output format
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want the AI to output just code or code with comments or an explanation,
    you can instruct that: “Give only the code, no explanation” or “Provide code and
    a brief comment for each step.”'
  prefs: []
  type: TYPE_NORMAL
- en: A clear prompt sets the AI up for success. If you find the AI’s answers often
    need a lot of correction, examine whether your prompts might be underspecified.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what not to do:'
  prefs: []
  type: TYPE_NORMAL
- en: Don’t write a whole novel
  prefs: []
  type: TYPE_NORMAL
- en: Long-winded prompts that include irrelevant info can confuse the model or cause
    it to focus on the wrong thing. Be concise but complete in your description. For
    instance, you usually don’t need to preface with “You are a world-class programmer...”
    in a coding context (some people do that in general ChatGPT usage, but for coding
    tasks, it’s often unnecessary and could add noise).
  prefs: []
  type: TYPE_NORMAL
- en: Don’t assume the AI will fill in details by itself correctly
  prefs: []
  type: TYPE_NORMAL
- en: If something is important (like thread safety, handling of special characters,
    etc.), mention it. If it’s not mentioned, assume the AI might not handle it.
  prefs: []
  type: TYPE_NORMAL
- en: Avoid open-ended “creative” prompts when you need deterministic outputs
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, saying, “Write some code to analyze data” might cause the AI to
    guess what analysis you want. Instead, specify:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate the average and standard deviation of a list of numbers.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In summary, *say exactly what you mean*. The more the AI “knows” about what
    you truly want, the better it can deliver. If you find yourself having to correct
    the AI multiple times, ask: could my initial prompt have been clearer?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Iterative Refinement: The Feedback Loop with the AI'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even with clear prompts, you won’t always get the perfect answer on the first
    try. Think of interacting with the AI as a conversation or an iterative development
    process. This is the feedback loop I touched on in [Chapter 1](ch01.html#ch01_introduction_what_is_vibe_coding_1752630042333281).
  prefs: []
  type: TYPE_NORMAL
- en: When the AI gives you code, review it critically, just as you would code written
    by a human. Does it meet the requirements? If not, identify what’s missing or
    wrong. Then provide feedback or a refined prompt. This can be done in a conversational
    AI by simply continuing the dialogue, or in an editor by writing another comment
    for the AI to respond to.
  prefs: []
  type: TYPE_NORMAL
- en: 'By providing feedback to the AI, you steer it closer to your desired outcome. In
    a sense, you are *training* it on the fly for your specific problem. Advanced
    prompt engineering is like the loop in [Figure 2-2](#ch02_figure_2_1752630042957608):
    Prompt → AI output → Review → Refine prompt → AI output →...until satisfied. Keeping
    each iteration’s changes small is useful; if you overhaul the prompt too much,
    you may lose some good parts of the previous output.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bevc_0202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-2\. Advanced prompt engineering loop.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'For example, you might prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: Write a function that takes a list of integers and returns their sum.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The AI then returns a function, but its code assumes a non-empty list and doesn’t
    handle an empty list well. You could then reply:'
  prefs: []
  type: TYPE_NORMAL
- en: That looks good. However, please modify it to return 0 if the list is empty.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The AI would then update the function accordingly. In this way, you didn’t have
    to prompt from scratch; you just told the AI to make an adjustment. The AI already
    had the context of the previous code it gave.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’re using an inline assistant, refinement might look like editing the
    code and perhaps writing a comment like `# TODO: handle empty list` and then seeing
    if the AI suggests a fix for that.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another refinement approach is reprompting with more info if the first output
    wasn’t right. Suppose you said, “Sort a list of names,” and it gave code sorting
    case-sensitively but you wanted case-insensitive. You could rephrase:'
  prefs: []
  type: TYPE_NORMAL
- en: Sort a list of names case-insensitively.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Or even:'
  prefs: []
  type: TYPE_NORMAL
- en: The previous code sorts case-sensitively. Modify it to be case-insensitive.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In debugging, for more complex logic bugs (where no obvious error message is
    thrown but the output is wrong), you can prompt the AI to walk through the code’s
    execution. For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Walk through this function line by line and track the value of total at each
    step. It’s not accumulating correctly—where does the logic go wrong?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is an example of a “rubber duck” debugging prompt: you’re essentially
    asking the AI to simulate the debugging process a human might do with prints or
    a debugger. Such prompts often reveal subtle issues like variables not resetting
    or incorrect conditional logic, because the AI will spell out the state at each
    step. If you suspect a certain part of the code, you can zoom in:'
  prefs: []
  type: TYPE_NORMAL
- en: Explain what the filter call is doing here and if it might be excluding more
    items than it should.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Engaging the AI in an explanatory role can surface the bug in the process of
    explanation.
  prefs: []
  type: TYPE_NORMAL
- en: 'After the explanation, it’s often effective to directly ask for what you need:'
  prefs: []
  type: TYPE_NORMAL
- en: What might be causing this issue, and how can I fix it?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This invites the AI to both diagnose and propose a solution. If the AI’s first
    answer is unclear or partially helpful, don’t hesitate to ask a follow-up question:'
  prefs: []
  type: TYPE_NORMAL
- en: That explanation makes sense. Can you show me how to fix the code? Please provide
    the corrected code.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In a chat setting, the AI has the conversation history, so it can directly
    output the modified code. If you’re using an inline tool like Copilot in VSCode
    or Cursor without a chat, you might instead write a comment above the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In general, though, the interactive chat yields more thorough explanations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another follow-up pattern: if the AI gives a fix but you don’t understand why,
    ask:'
  prefs: []
  type: TYPE_NORMAL
- en: Can you explain why that change solves the problem?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This way, you learn for next time, and you double-check that the AI’s reasoning
    is sound.
  prefs: []
  type: TYPE_NORMAL
- en: 'LLMs thrive on examples and corrections. If you point out what’s wrong or give
    a quick example, the AI can incorporate it:'
  prefs: []
  type: TYPE_NORMAL
- en: If input is [], it should return 0, but now it errors.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This iterative process is normal. In fact, trying to cram every detail into
    one prompt might be less effective than a couple of back-and-forth turns. Use
    that to your advantage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Be patient and specific in your feedback. Instead of saying, “No, that’s wrong,”
    say what’s wrong or what’s needed:'
  prefs: []
  type: TYPE_NORMAL
- en: This code doesn’t handle negative numbers correctly. It should treat them as
    0 in the sum.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Also, if the AI goes off track, you can steer it back: sometimes resetting
    or rephrasing is easier than trying to salvage a very incorrect attempt. Use your
    judgment. If the AI output shows that it is completely misunderstanding you, clarify
    your prompt from scratch.'
  prefs: []
  type: TYPE_NORMAL
- en: As you refine, you’ll also learn how the AI interpreted your prompt. This can
    inform how you write future prompts. You might realize, “Oh, it took ‘login system’
    to mean an entire UI. Next time I’ll specify backend only.”
  prefs: []
  type: TYPE_NORMAL
- en: 'Think of it like debugging code: if the AI output is wrong, the “bug” might
    be in your prompt, not in the AI’s processing. Just as you’d examine and fix your
    code when it produces incorrect results, you should refine your prompts when the
    AI generates unexpected or incorrect output. The conversation between you and
    the AI is like a debugging session where each exchange helps you pinpoint and
    fix the issue.'
  prefs: []
  type: TYPE_NORMAL
- en: Comparing Two Prompts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Imagine you have a simple Node.js function meant to convert a list of user
    objects to a lookup map by user ID. However, it’s throwing an error. Here’s the
    buggy code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This code is supposed to iterate through the user’s array and build an object
    where keys are user IDs. However, there is a bug: the loop uses `i <= users.length`
    instead of `i < users.length`. This will cause `users[i]` to be undefined on the
    last iteration, likely leading to a runtime error (like attempting to access the
    property ID of `undefined`). Let’s see how an AI assistant might respond to two
    different prompts about this issue (see [Figure 2-3](#ch02_figure_3_1752630042957630)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bevc_0203.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2-3\. Prompt quality impact comparison: vague prompts produce generic
    or incorrect code, while specific, well-structured prompts generate accurate,
    contextually appropriate solutions.'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Poor prompt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here’s an example of a poor prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: Why isn’t my mapUsersById function working?
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'AI’s response to the poor prompt (simulated):'
  prefs: []
  type: TYPE_NORMAL
- en: It’s hard to say without more information. Are you sure the function is being
    called with a proper array of users? Perhaps the issue is that users is empty
    or not an array, causing the loop not to execute properly. It could also be that
    there’s an error when setting the property on userMap. Make sure that each user
    has an id property. If users is undefined or null, that would also cause it to
    not work.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This answer is quite vague. The prompt gave no details except the function name,
    so the AI is guessing at generic causes (“Maybe the array is empty or not an array,”
    “Make sure each user has an ID”). It did not identify the actual bug.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the kind of response you get when the question is underspecified—the
    model can only regurgitate common debugging tips. If you’re a developer, this
    isn’t very helpful because it doesn’t address the real mistake. The lack of context
    and specificity in the prompt yields a generic answer: essentially, the AI equivalent
    of “Have you tried turning it off and on again?” This aligns with the community
    advice that vague prompts lead to irrelevant or generic answers.'
  prefs: []
  type: TYPE_NORMAL
- en: Improved prompt
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s try this again:'
  prefs: []
  type: TYPE_NORMAL
- en: 'I have a JavaScript function `mapUsersById` that should convert an array of
    user objects into a `map (object)` keyed by user ID. However, it throws an error
    when I run it. For example, when I pass `[ {id: 1, name: "Alice"} ]`, I get `TypeError:
    Cannot read property ''id'' of undefined`. Here is the function code:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_BQ
  type: TYPE_PRE
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It should return `{ "1": {id: 1, name: "Alice"} }`. What is the bug and how
    can I fix it?'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The AI’s response to the improved prompt (simulated):'
  prefs: []
  type: TYPE_NORMAL
- en: 'The error Cannot read property `''id''` of undefined suggests that at some
    point, user is undefined, and then you try to access user.id. Looking at your
    loop, the issue is with the loop bounds. You are using `i <= users.length`. If
    `users.length` is `1` (for one user in the array), the loop runs with `i = 0`
    and `i = 1`. When `i` is `1`, `users[1]` is undefined (since the only index in
    the array is 0). Thus user becomes undefined on that iteration, and `user.id`
    throws a `TypeError`. The fix is to change the loop condition to `i < users.length`
    so that `i` goes from `0` to `users.length-1`. For example:'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_BQ
  type: TYPE_PRE
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This way, `i` will be `0` for the first (and only) element, and then the loop
    stops. With that change, your function will no longer hit an undefined user and
    should work as expected, returning `{"1": {id: 1, name: "Alice"}}` for the given
    input.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This response directly pinpoints the bug (using `<=` in the loop) and explains
    why it causes the user to be undefined. It then provides the correct code solution
    (`i < users.length`) and confirms the expected outcome. The improved prompt succeeded
    because it followed our principles: it specified the language (JavaScript), described
    the function’s purpose, included the exact error message and a sample input, and
    even provided the code snippet in question.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice how the AI used the error message as a clue to focus on the loop bounds—a
    targeted prompt enabled the AI to engage in true problem solving, effectively
    simulating how a human debugger would think: “Where could undefined come from?
    Likely from the loop indexing.” This is a concrete demonstration of the benefit
    of detailed prompts.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompting Techniques: A Toolbox for Effective Communication'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let’s get into specific techniques that can supercharge your prompting skills.
    These are like patterns or recipes you can use when a straightforward instruction
    isn’t enough or when you want to guide the AI in a certain way.
  prefs: []
  type: TYPE_NORMAL
- en: 'By mastering these techniques, you can handle an array of situations: instructing
    the AI in plain English, giving it examples, making it explain or structure its
    output, or setting it into different mindsets or roles. All of these help you
    guide the AI to produce exactly what you need.'
  prefs: []
  type: TYPE_NORMAL
- en: Prompting techniques are not mutually exclusive; you will often use several
    together for best results, especially on complex tasks.
  prefs: []
  type: TYPE_NORMAL
- en: A Note on Style
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you use these techniques, adapt your tone to the model. Many models respond
    well to polite or neutral instructions. You don’t need to use archaic or overly
    formal language. Direct but polite often works: “Please do X” or “Let’s do Y.”
    For example, with chain-of-thought (CoT) prompting, a popular phrase is “Let’s
    think step-by-step.” Models like GPT-4 recognize this as a cue to show reasoning.'
  prefs: []
  type: TYPE_NORMAL
- en: Zero-Shot Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Zero-shot* prompting is simply asking the model to do something without providing
    any examples or additional guidance beyond the instruction. Essentially, the model
    is solving the task from “zero” examples.'
  prefs: []
  type: TYPE_NORMAL
- en: '*When to use:* This is the most common scenario: you just ask for what you
    want in plain language. If the task is standard and the prompt is clear, this
    is often sufficient.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Example:*'
  prefs: []
  type: TYPE_NORMAL
- en: Write a Python function that checks if a number is prime.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is zero shot. The AI will likely produce a prime-checking function using
    a loop or trial division.
  prefs: []
  type: TYPE_NORMAL
- en: '*Pros:* It’s quick and relies on the model’s learned knowledge. Modern models
    are surprisingly good at zero-shot responses for many programming tasks, especially
    if they’re common (like prime checking, sorting, or string manipulation).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Cons:* If the task is unusual or output format is specific, zero shot might
    yield a result that doesn’t quite match what you need on the first try, because
    the model might have multiple ways to interpret it.'
  prefs: []
  type: TYPE_NORMAL
- en: Usually, it’s a good idea to try zero shot first for simple things. If the result
    is off, you may then shift to refining or other techniques.
  prefs: []
  type: TYPE_NORMAL
- en: One-Shot and Few-Shot Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*One-shot* prompting means you provide exactly one example of what you want
    (input and desired output) as part of the prompt; *few-shot* prompting means providing
    a few examples (typically two to five) before asking the model to perform the
    task on a new input.'
  prefs: []
  type: TYPE_NORMAL
- en: This is like showing the model, “Here’s how I solve one instance. Now you do
    the next one similarly.”
  prefs: []
  type: TYPE_NORMAL
- en: '*When to use:* This type of prompting is useful when the model might not know
    exactly the format or style you need or when the task is a bit unusual. By giving
    examples, you reduce ambiguity.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Example (one shot):* Suppose you’re using a language or a certain style that
    the model might not have seen as much. Let’s say you want pseudocode in a specific
    format. Your prompt might be:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert the following English instructions to Python-like pseudocode.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Example instruction: “Calculate the factorial of n”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: You’ve provided one example (factorial) and the format you want. Now the model
    is more likely to produce pseudocode for the “largest number” instruction in a
    similar format (with a function, with if/else or loop logic as needed).
  prefs: []
  type: TYPE_NORMAL
- en: '*Example (few shot):* Let’s say you want the AI to use a specific algorithm.
    You might give it a smaller example of that algorithm in action as a hint. Or
    if the task has multiple correct answers but you prefer a certain one, an example
    can push it toward that.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Few-shot prompting is powerful for formatting; for instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Convert The Following English Statements To SQL Queries.\N1."Get All Employees
    Hired After 2020” → Select * From Employees Where Hire_Date > ’2020-01-01’;\N2\.
    “List Customer Names Who Made A Purchase In The Last Month” → Select Name From
    Customers Join Purchases On ... Where Purchase_Date > ...;\N3\. “Count Of Products
    That Are Out Of Stock” →
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Here, once you give two examples of English-to-SQL, the AI is likely to answer
    the third query correctly by following the pattern. Few-shot examples can be applied
    to coding too: show the AI the style you want in a small sample and then ask for
    more. It’s like giving it a minitraining dataset within your prompt.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Pros:* You can achieve outputs in very specific styles. This technique also
    helps the model handle tasks that involve following a pattern or applying a concept
    repetitively.'
  prefs: []
  type: TYPE_NORMAL
- en: Context Window
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term *context window* refers to the maximum amount of text (measured in
    tokens) that a language model can process in a single interaction, including both
    the input prompt and the generated response. This represents a limitation of current
    AI models—once you reach this threshold, the model cannot process additional information.
    When you’re crafting prompts, everything you include (instructions, examples,
    data, and the space needed for the response) must fit within this fixed capacity.
  prefs: []
  type: TYPE_NORMAL
- en: '*Cons:* Few-shot prompting in particular makes the prompt longer (which uses
    up context window). For very large/complex examples, it might “eat” a lot of the
    model’s capacity. But usually a small example or two is fine.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Tip:* If you want the model to strictly adhere to a certain output structure,
    giving an example can nearly guarantee it matches that structure rather than offering
    a free-form reply that you have to parse.'
  prefs: []
  type: TYPE_NORMAL
- en: Chain-of-Thought Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Chain-of-thought* (CoT) prompting involves asking the model to think step-by-step
    or show its reasoning before giving the final answer. In other words, you encourage
    the model to break down the problem.'
  prefs: []
  type: TYPE_NORMAL
- en: '*When to use:* This is useful for complex problems that involve reasoning and
    multistep computations, or when you suspect the model might make a mistake if
    it jumps straight to the answer. It’s also useful if you want an explanation in
    the output.'
  prefs: []
  type: TYPE_NORMAL
- en: Combinatorial Math
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Combinatorial math* deals with counting, arranging, and selecting objects
    according to specific rules or constraints. Common problems include calculating
    permutations (arrangements where order matters), combinations (selections where
    order does not matter), and other counting principles. Key notation includes “n
    choose k” (written as C(n,k) or nCk), which represents the number of ways to choose
    k items from n total items, calculated using the formula n!/(k!(n-k)!). These
    calculations frequently appear in probability, statistics, and discrete mathematics
    applications.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Example:* Instead of just asking a [combinatorial math problem](https://oreil.ly/vI3V5)
    like “What is 12 choose 4?” and getting an answer, you might say:'
  prefs: []
  type: TYPE_NORMAL
- en: Solve 12 choose 4 step-by-step.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The model might then outline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In coding, CoT can be useful for tricky algorithmic tasks. You might try the
    following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: Explain step-by-step how to merge two sorted lists, then provide the Python
    code.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The model would first outline something like:'
  prefs: []
  type: TYPE_NORMAL
- en: We will use two pointers starting at the heads of each list, compare the elements,
    append the smaller to a result list, and move that pointer, and so on…
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Then it might give the code. This ensures it has structured the solution correctly
    before coding.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another use is debugging or understanding output:'
  prefs: []
  type: TYPE_NORMAL
- en: Walk through the logic to determine if the number 19 is prime, then give the
    result.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The model might list divisions by primes, then conclude:'
  prefs: []
  type: TYPE_NORMAL
- en: 19 is prime.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Pros:* Improves correctness on tasks requiring reasoning. There’s [research
    evidence](https://oreil.ly/t7flF) that prompting the model to “think out loud”
    can lead to better results on math and logic tasks. It also gives you insight
    into the model’s process, which can be instructive or help you trust the answer
    more.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Cons:* The output is longer (which might not be what you want in final code).
    Also, some interfaces (like typical code completions) aren’t set up to show reasoning
    separate from code. This technique is more common in Q&A or chat scenarios. However,
    you can instruct the model to include the reasoning as comments in the code, which
    is a neat way to get thoroughly commented code.'
  prefs: []
  type: TYPE_NORMAL
- en: Role Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Role prompting* means you ask the AI to assume a certain identity or role
    that might influence how it responds.'
  prefs: []
  type: TYPE_NORMAL
- en: '*When to use:* This is useful when you want to influence the style or detail
    of the answer or get a certain perspective. For instance, an AI taking on an “expert”
    role might give a more advanced solution or more explanation, while a “beginner”
    role might make it explain more basic concepts.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Examples:*'
  prefs: []
  type: TYPE_NORMAL
- en: You are a Python instructor. Explain the following code and then modify it to
    be more Pythonic.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Act as a security analyst. Here’s some code. Identify any security vulnerabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pretend you are a linter that checks code for style issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can significantly affect the response. Assigning the AI a security analyst
    role might make it focus on things it otherwise wouldn’t mention (like data validation,
    secure coding practices, or potential vulnerabilities). An instructor role might
    make it provide clearer explanations and perhaps not assume prior knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 'In coding, you might say before asking for code:'
  prefs: []
  type: TYPE_NORMAL
- en: You are an expert C++ programmer well-versed in optimization, instructing a
    junior developer.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The result will likely use more advanced C++ features and explain why certain
    choices were made, balancing technical sophistication with educational clarity.
  prefs: []
  type: TYPE_NORMAL
- en: '*Pros:* This technique steers the tone and depth of the answer. This can tailor
    the solution to a certain level of complexity or thoroughness. It’s useful if
    you want either a very simple solution (tell it to act as a novice and maybe it’ll
    avoid complex tricks) or a very optimized one (tell it to act as a performance
    guru).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Cons:* Sometimes the model might focus more on the persona than needed (an
    “instructor” might start explaining things you already know). Also, some AI safety
    systems are more sensitive to certain role descriptions—particularly those that
    might suggest deception, authority impersonation, or potentially harmful activities—though
    straightforward technical and professional roles like “data analyst” or “software
    engineer” typically work without issues.'
  prefs: []
  type: TYPE_NORMAL
- en: Contextual Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Contextual prompting* means giving the AI additional context or information
    beyond the immediate task description. AI models don’t have persistent memory
    of your entire project unless you provide it in the prompt (or through some integrated
    context window in advanced IDE integrations). So if you want the AI to write code
    that fits into your existing codebase, give it that context. Basically, you supply
    relevant data or background as part of the prompt.'
  prefs: []
  type: TYPE_NORMAL
- en: '*When to use:* Use when solving a problem requires knowing certain data or
    definitions that the model might not know or might not recall correctly from training.
    Or use when you want to ensure consistency with some external info (like an API
    spec or previous part of conversation).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Examples:*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have a data structure and you want code that works with it, you might
    paste its definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: By including the class definition, you make the AI much more likely to use `Node.value`
    and `Node.next` properly in its code.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to use a specific API, include a snippet of the documentation in
    the prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the requests library, fetch the data from the API. (The API returns JSON
    with format: {...})'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you include even a short example of API usage from docs, the AI can mimic
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'For disambiguation:'
  prefs: []
  type: TYPE_NORMAL
- en: Using the term `*student*` to refer to high school students, write a function
    that…
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If *student* could be ambiguous in context, you’ve clarified it.
  prefs: []
  type: TYPE_NORMAL
- en: '*Pros:* You’re grounding the AI in the context you care about. It’s less likely
    to make wrong assumptions if you supply the facts. This is extremely helpful if
    the AI otherwise might not remember or know your specific use-case details.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Cons:* This technique makes prompts longer. Also, the model might occasionally
    regurgitate the provided context into the answer (like copying lines from a documentation
    snippet into the code if not careful). But usually it uses it appropriately.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Tip:* If you have a large context (like a big schema or many lines of code),
    sometimes it’s better to summarize the key elements for the model rather than
    including everything verbatim. This approach helps you stay within context limits
    while ensuring the model receives the most relevant information. However, if the
    content is small enough, just include it raw.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Constraints are also useful to mention: performance constraints (“Optimize
    for O(n log n) or better”), compatibility constraints (“Must run on Python 3.8”),
    or library choices (“Use standard library only, no external dependencies”). These
    act like guardrails and ensure the AI doesn’t suggest something outside acceptable
    bounds.'
  prefs: []
  type: TYPE_NORMAL
- en: Metaprompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Metaprompting* is giving instructions about the output itself, not just what
    the solution should do. It’s like telling the AI how to format or approach the
    solution.'
  prefs: []
  type: TYPE_NORMAL
- en: '*When to use:* Useful when you need the answer in a specific format or style
    or when you want to control how the AI works through the problem.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Examples:*'
  prefs: []
  type: TYPE_NORMAL
- en: First, explain the approach in two sentences, then provide the code.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This ensures the AI doesn’t launch straight into code:'
  prefs: []
  type: TYPE_NORMAL
- en: Do not use any libraries in the solution.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This places a constraint on the solution:'
  prefs: []
  type: TYPE_NORMAL
- en: Format the output as JSON.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is useful if you’re using the AI to produce data, not code:'
  prefs: []
  type: TYPE_NORMAL
- en: Only provide the function body, without the definition line.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is handy if you want to insert the function into existing code:'
  prefs: []
  type: TYPE_NORMAL
- en: If the input is invalid, instead of error, return None.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is not exactly the output format, but it’s instructing the AI how to behave
    for certain cases.
  prefs: []
  type: TYPE_NORMAL
- en: '*Pros:* You get exactly what you need, how you need it, without extra editing.
    This is crucial for some scenarios. If you plan to automatically use the AI’s
    output in a pipeline, then you really want consistent formatting.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Cons:* If the instructions conflict with the model’s default style, sometimes
    it might partially follow them or you have to emphasize them. For instance, even
    if you say “only code, no explanation,” occasionally the model might include a
    tiny comment or so. Usually, phrasing it as a direct imperative helps:'
  prefs: []
  type: TYPE_NORMAL
- en: Do not include any explanation; output only code inside a single code block.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Models like GPT follow that quite well.
  prefs: []
  type: TYPE_NORMAL
- en: Self-Consistency (Multiple Outputs and Majority Voting)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Self-consistency* is more of a strategy than a prompt style. The idea is to
    get multiple outputs for the same prompt and then decide on the best or most common
    one. As [Sander Schulhoff of Learn Prompting notes](https://oreil.ly/fHABW), self-consistency
    leverages the notion that if you ask the model multiple times (with slight randomness)
    and many of its answers agree, that consensus is likely correct.'
  prefs: []
  type: TYPE_NORMAL
- en: '*When to use:* This is useful for complex problems where you’re unsure the
    model’s first answer is correct, especially if you can’t verify it easily yourself,
    or if you want a confidence check from the AI by seeing whether it gives the same
    answer repeatedly.'
  prefs: []
  type: TYPE_NORMAL
- en: '*How to use manually:* On some platforms (like ChatGPT), you can click “Regenerate
    answer.” Or you can copy the prompt into a new session and see if it gives the
    same result. If you get three answers and two are the same and one is different,
    you might trust the two (assuming the problem has a single correct answer).'
  prefs: []
  type: TYPE_NORMAL
- en: In programming context, if it’s generating code for something deterministic,
    usually it will give very similar code each time (with small variations in variable
    names or style). But if it’s an algorithmic question (like “What’s the output
    of this code?”), you could check multiple runs.
  prefs: []
  type: TYPE_NORMAL
- en: This technique is more powerful in noncoding tasks (like logic puzzles) but
    worth noting.
  prefs: []
  type: TYPE_NORMAL
- en: '*Another angle—ensemble prompting:* You can actually ask the model within one
    prompt to consider multiple possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: Give two different solutions to this problem.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Then perhaps you can see which one you like or test both. This is like self-consistency
    in one shot because you get multiple answers.
  prefs: []
  type: TYPE_NORMAL
- en: '*Pros:* This technique can increase confidence in the solution if multiple
    attempts converge. Also, you might get variety (which is good if you want to choose
    the most elegant solution among many).'
  prefs: []
  type: TYPE_NORMAL
- en: '*Cons:* It’s time-consuming to do multiple calls and compare outputs.'
  prefs: []
  type: TYPE_NORMAL
- en: In practice, if I’m unsure about an answer, I’ll often repose the question differently
    to see if I get the same answer. If I do, I’m more confident it’s correct.
  prefs: []
  type: TYPE_NORMAL
- en: ReAct (Reason + Act) Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*ReAct* is a more advanced prompting technique that [combines *reasoning* and
    *acting*](https://arxiv.org/abs/2210.03629). It gets the model not only to think,
    like CoT does, but also to take actions like making a calculation, calling an
    API, or using a tool. (See the [ReAct Prompt Engineering Guide](https://oreil.ly/P_KIV)
    for more). In current practice, this is often used with frameworks like LangChain,
    where the AI can output a special format that a program interprets as an action
    (like a command to execute or a query to run), then feed the result back.'
  prefs: []
  type: TYPE_NORMAL
- en: For our scope (without such an execution environment in the loop), you can still
    do a form of ReAct by instructing the AI to first outline a plan, then output
    the result. It’s similar to CoT but specifically oriented to using tools or performing
    subtasks.
  prefs: []
  type: TYPE_NORMAL
- en: '*Example:*'
  prefs: []
  type: TYPE_NORMAL
- en: Using Python, determine the current weather in Paris and print it.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Unless the AI has browsing capabilities, it cannot truly get the current weather.
    A ReAct approach would have the AI first reason through the problem by stating:'
  prefs: []
  type: TYPE_NORMAL
- en: I need to access current weather data for Paris, which requires calling a weather
    API.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The AI would then attempt to use an available tool to make this API call. If
    successful, it would receive actual weather data; if no such tool is available,
    it might acknowledge the limitation or work with hypothetical data. Finally, the
    AI would write the Python code to display the weather information, incorporating
    whatever data it was able to obtain through this reasoning and action process.
  prefs: []
  type: TYPE_NORMAL
- en: Without external tool access, ReAct might not be particularly relevant for simple
    prompting tasks. However, when evaluating AI tools for your organization, determining
    whether they can access current information from the internet represents a critical
    capability assessment. Many AI models operate with knowledge cutoffs, meaning
    their training data only extends to a specific date, which can result in outdated
    information for rapidly changing topics.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using an environment where the AI can execute code (such as Jupyter
    integrations or similar platforms), you could implement ReAct by instructing the
    system:'
  prefs: []
  type: TYPE_NORMAL
- en: First write a test for this function, run it, then adjust the code accordingly.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This demonstrates the ReAct pattern through a reasoning step (writing the test),
    followed by an action (executing the test), and then code adjustment based on
    the results. However, orchestrating such workflows through pure prompts requires
    advanced prompting techniques and appropriate technical infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: '*Simpler use:* You can simulate a Q&A where the AI has intermediate steps that
    mimic actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Think step-by-step and if you need to, do calculations.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It’s effectively CoT but with a more imperative tone.
  prefs: []
  type: TYPE_NORMAL
- en: '*Pros:* When available, it can solve problems that require external info or
    iterative trial (like the AI can correct itself by actually running code). In
    debugging contexts, an AI that can execute code to test it is fantastic.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Cons:* This technique is not widely accessible without specific tooling. And
    if you just prompt that way in plain ChatGPT, it will either imagine the actions
    or just do CoT.'
  prefs: []
  type: TYPE_NORMAL
- en: For our purposes in prompt writing, keep in mind that some systems (like OpenAI’s
    tool-using agents or others) exist, but in vanilla prompting we mostly do CoT,
    and we ourselves handle actions like running the code or tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Advanced Prompting: Combining Techniques and Handling Complexity'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prompting techniques can be combined. For instance, you might do a few-shot
    prompt that also demonstrates CoT in the examples. Or you might combine a role
    with CoT:'
  prefs: []
  type: TYPE_NORMAL
- en: As a senior engineer, think step-by-step through the problem, then give the
    code.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now that we’ve explored various prompting techniques, let’s see them in action
    with a scenario or two, then discuss how to review and refine the AI’s output
    (which leads into the next chapter about understanding and owning the generated
    code).
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine you have a function that isn’t working. You might use a combination
    of role and CoT prompting:'
  prefs: []
  type: TYPE_NORMAL
- en: You are a Python debugger. Let’s think step-by-step to find the bug in the following
    code.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This would be followed by the code. The AI might respond with an analysis of
    each line and pinpoint the bug.
  prefs: []
  type: TYPE_NORMAL
- en: 'Or let’s say you want to generate code for a somewhat complex algorithm, ensure
    it’s well commented, and also get test cases for it. A combined prompt might look
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: You are an expert Python developer. Let’s solve this step-by-step. We need a
    function `merge_sorted_lists(list1, list2)` that merges two sorted lists into
    one sorted list. First, explain the approach, then provide the Python code with
    comments. After that, give 2–3 example tests in code to demonstrate it works.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This single prompt is quite comprehensive. The first sentence sets a role. The
    second requests step-by-step reasoning. The third gives the main task. The fourth
    sentence asks for code with explanatory comments, and the fifth even asks for
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: The AI might then output an explanation, then the code with inline comments,
    then some test cases at the end. This is an advanced use, but it shows how you
    can direct the AI through a multifaceted response.
  prefs: []
  type: TYPE_NORMAL
- en: Know the Model’s Limits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prompt engineering also involves knowing what *not* to ask and how to avoid
    pitfalls. If a prompt is getting too large or includes too many instructions,
    the model might get confused or truncate some output. If you find it starts ignoring
    parts of your prompt, you might need to simplify or do it in parts. If an AI model
    sometimes produces incorrect facts or code (it “hallucinates”), you learn to double-check
    and not use it as a factual oracle. If you find it tends to give overly verbose
    code, you can preempt that with “Make the solution as concise as possible.” If
    it sometimes uses functions that don’t exist, you might instruct, “Use only the
    API functions listed below” and list them. The better you understand the AI’s
    behavior, the more you can mold your prompts to get around any weaknesses.
  prefs: []
  type: TYPE_NORMAL
- en: 'If a task is very complex, you can also break it into subtasks for the AI.
    For example, you might first prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: List the steps to implement a basic compiler for a simple arithmetic expression
    language.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Once the AI gives the steps, you tackle each step with separate prompts, maybe
    even in separate files or sessions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now implement step 1: tokenization.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is like doing system design with the AI: you can outline then refine each
    piece. It leverages the AI’s ability to assist in planning (not just coding).'
  prefs: []
  type: TYPE_NORMAL
- en: Stateful Conversation Versus One-Shot Prompting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a chat setting, you have a conversation history, known as *state*. You can
    build up context by discussing with the AI. In an IDE completion setting, the
    context is mostly your file content and comments. Both allow cumulative context
    in different ways. Use conversation if you need the AI to remember what was said
    (like refining an answer). Use fresh prompts or file context if you want to ensure
    it’s focusing only on what’s relevant now. Sometimes wiping away the context prevents
    the model from sticking to a potentially wrong earlier assumption.
  prefs: []
  type: TYPE_NORMAL
- en: 'By practicing with these techniques on various examples, you’ll become adept
    at knowing which approach to use and when:'
  prefs: []
  type: TYPE_NORMAL
- en: If output format is important, give examples (few shot) or explicit formatting
    instructions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If logic is tricky, use CoT or step-by-step.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the solution can vary in quality, set a role (like “seasoned engineer”) to
    get a better style.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the model isn’t complying, maybe break your prompts into pieces, simplify
    them, or use stronger wording for constraints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common Prompt Antipatterns and How to Avoid Them
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Not all prompts are created equal. By now, we’ve seen numerous examples of effective
    prompts, but it’s equally instructive to recognize antipatterns—common mistakes
    that lead to poor AI responses. This section covers some frequent prompt failures
    and how to fix them.
  prefs: []
  type: TYPE_NORMAL
- en: The vague prompt
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is the classic “It doesn’t work, please fix it” or “Write something that
    does X” without enough detail. The question “Why isn’t my function working?” will
    generally get a useless answer. Vague prompts force the AI to guess the context
    and often result in generic advice or irrelevant code.
  prefs: []
  type: TYPE_NORMAL
- en: 'The fix is straightforward: add context and specifics. If you find yourself
    asking a question and the answer feels like a Magic 8–Ball response (“Have you
    tried checking X?”), stop and reframe your query with more details (error messages,
    code excerpt, expected versus actual outcome, etc.). A good practice is to read
    your prompt and ask, “Could this question apply to dozens of different scenarios?”
    If the answer is yes, it’s too vague. Make it so specific that it could only apply
    to your scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: The overloaded prompt
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is the opposite issue: asking the AI to do too many things at once. For
    instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a complete Node.js app with authentication, a frontend in React, and
    deployment scripts.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Or even, on a smaller scale:'
  prefs: []
  type: TYPE_NORMAL
- en: Fix these 5 bugs and also add these 3 features in one go.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The AI might attempt it, but you’ll likely get a jumbled or incomplete result,
    or it might ignore some parts of the request. Even if it addresses everything,
    the response will be long and harder to verify.
  prefs: []
  type: TYPE_NORMAL
- en: 'The remedy is to split the tasks. Prioritize: do one thing at a time, as we
    emphasized earlier. This makes it easier to catch mistakes and ensures the model
    stays focused. If you catch yourself writing a paragraph that uses “and” multiple
    times in the instructions, consider breaking it into separate prompts or sequential
    steps.'
  prefs: []
  type: TYPE_NORMAL
- en: Missing the question
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sometimes users will present a lot of information but never clearly ask a question
    or specify what they need, like dumping a large code snippet and just saying,
    “Here’s my code.” This can confuse the AI—it doesn’t know what you want.
  prefs: []
  type: TYPE_NORMAL
- en: 'Always include a clear ask:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify any bugs in the above code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explain what this code does.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complete the to-dos in the code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A prompt should have a purpose. If you just provide text without a question
    or instruction, the AI might make incorrect assumptions (like summarizing the
    code instead of fixing it, etc.). Make sure the AI knows why you showed it some
    code. Even a simple addition like “What’s wrong with this code?” or “Please continue
    implementing this function” gives it direction.
  prefs: []
  type: TYPE_NORMAL
- en: Vague success criteria
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is a subtle one. Sometimes you might ask for an optimization or improvement,
    but you don’t define what success looks like—for example, “Make this function
    faster.” Faster by what metric? If the AI doesn’t know your performance constraints,
    it might micro-optimize something that doesn’t matter or use an approach that’s
    theoretically faster but practically negligible. Or “Make this code cleaner”:
    “cleaner” is subjective. We dealt with this by explicitly stating goals like “reduce
    duplication” or “improve variable names,” etc.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The fix: quantify or qualify the improvement:'
  prefs: []
  type: TYPE_NORMAL
- en: Optimize this function to run in linear time (current version is quadratic).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refactor this to remove global variables and use a class instead.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basically, be explicit about what problem you’re solving with the refactor or
    feature. If you leave it too open, the AI might solve a different problem than
    the one you care about.
  prefs: []
  type: TYPE_NORMAL
- en: Ignoring AI’s clarification or output
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Sometimes the AI might respond with a clarifying question or an assumption:'
  prefs: []
  type: TYPE_NORMAL
- en: Are you using React class components or functional components?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I assume the input is a string—please confirm.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you ignore these and just reiterate your request, you’re missing an opportunity
    to improve the prompt. The AI is signaling that it needs more info. Always answer
    its questions or refine your prompt to include those details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, if the AI’s output is clearly off (like it misunderstood the
    question), don’t just retry the same prompt verbatim. Take a moment to adjust
    your wording. Maybe your prompt had an ambiguous phrase or omitted something essential.
    Treat it like a conversation: if a human misunderstood, you’d explain differently;
    do the same for the AI.'
  prefs: []
  type: TYPE_NORMAL
- en: Inconsistency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you keep changing how you ask or mixing different formats in one go, the
    model can get confused. Two examples include switching between first person and
    third person in instructions or mixing pseudocode with actual code in a confusing
    way.
  prefs: []
  type: TYPE_NORMAL
- en: Try to maintain a consistent style within a single prompt. If you provide examples,
    ensure they are clearly delineated (use Markdown triple backticks for code, quotes
    for input/output examples, etc.). Consistency helps the model parse your intent
    correctly. Also, if you have a preferred style (say, ES6 versus ES5 syntax), consistently
    mention it; otherwise, the model might suggest one way in one prompt and another
    way later.
  prefs: []
  type: TYPE_NORMAL
- en: Vague references like “the above code”
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When using chat, if you say “the above function” or “the previous output,” be
    sure the reference is clear. If the conversation is long and you say, “Refactor
    the above code,” the AI might lose track or pick the wrong code snippet to refactor.
  prefs: []
  type: TYPE_NORMAL
- en: It’s safer to either quote the code again or specifically name the function
    you want refactored. Models have a limited attention window, and although many
    LLMs can refer to prior parts of the conversation, giving it explicit context
    again can help avoid confusion. This is especially true if some time (or several
    messages) passed since the code was shown.
  prefs: []
  type: TYPE_NORMAL
- en: Summary and Next Steps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The art of prompting is iterative and creative. As models evolve, prompt best
    practices might change (for instance, future models might better understand intent
    with less wording). But the underlying principle remains: communicate effectively,
    and the AI will serve you better.'
  prefs: []
  type: TYPE_NORMAL
- en: In essence, mastering prompt engineering is like mastering a new programming
    language—the language of instructions for AI. It’s a blend of technical writing,
    foresight, and interactive debugging of the *prompt* itself. But once you get
    good at it, the AI truly starts to feel like an extension of your own mind, because
    you can reliably extract the solutions you envision (or even those you don’t fully
    envision yet but can guide the AI to discover) with minimal friction. This skill
    will likely become as fundamental as knowing how to google things or how to use
    a debugger—it’s part of the modern developer’s skill set in the age of vibe coding.
  prefs: []
  type: TYPE_NORMAL
- en: If AI can solve about 70% of a problem, how do you approach it as a partner
    in coding? [Chapter 3](ch03.html#ch03_the_70_problem_ai_assisted_workflows_that_actual_1752630043200933)
    looks at how developers *really* use AI and sets out some “golden rules” for vibe
    coding.
  prefs: []
  type: TYPE_NORMAL
