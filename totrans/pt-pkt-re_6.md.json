["```py\ndevice=torch.device(\"cuda\"iftorch.cuda.is_available()else\"cpu\")![1](Images/1.png)model.to(device)![2](Images/2.png)forepochinrange(n_epochs):fordataintrainloader:input,labels=datainput=input.to(device)![3](Images/3.png)labels=labels.to(device)![3](Images/3.png)optimizer.zero_grad()output=model(input)loss=criterion(input,labels)loss.backward()optimizer.step()\n```", "```py\n&#33;curl 'https://raw.githubusercontent.com/pytorch' \\'/xla/master/contrib/scripts/env-setup.py'\\\n-opytorch-xla-env-setup.py&#33;python pytorch-xla-env-setup.py --version &#34;nightly&#34; ![1](Images/1.png)\n```", "```py\nimport torch_xla.core.xla_model as xm\n\ndevice = xm.xla_device()\n```", "```py\nmodel.to(device)forepochinrange(n_epochs):fordataintrainloader:input,labels=datainput=input.to(device)labels=labels.to(device)optimizer.zero_grad()output=model(input)loss=criterion(input,labels)loss.backward()optimizer.step()print(output.device)![1](Images/1.png)# out: xla:1\n```", "```py\nif torch.cuda.device_count() > 1:\n  print(\"This machine has\",\n        torch.cuda.device_count(),\n        \"GPUs available.\")\n  model = nn.DataParallel(model)\n\nmodel.to(\"cuda\")\n```", "```py\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn.parallel \\\n  import DistributedDataParallel as DDP\n```", "```py\ndefdist_training_loop(rank,world_size,dataloader,model,loss_fn,optimizer):dist.init_process_group(\"gloo\",rank=rank,world_size=world_size)![1](Images/1.png)model=model.to(rank)![2](Images/2.png)ddp_model=DDP(model,device_ids=[rank])![3](Images/3.png)optimizer=optimizer(ddp_model.parameters(),lr=0.001)forepochsinrange(n_epochs):forinput,labelsindataloader:input=input.to(rank)labels=labels.to(rank)![4](Images/4.png)optimizer.zero_grad()outputs=ddp_model(input)![5](Images/5.png)loss=loss_fn(outputs,labels)loss.backward()optimizer.step()dist.destroy_process_group()\n```", "```py\nif __name__==\"__main__\":\n  world_size = 2\n  mp.spawn(dist_training_loop,\n      args=(world_size,),\n      nprocs=world_size,\n      join=True)\n```", "```py\nclassTwoGPUAlexNet(AlexNet):def__init__(self):super(ModelParallelAlexNet,self).__init__(num_classes=num_classes,*args,**kwargs)self.features.to('cuda:0')self.avgpool.to('cuda:0')self.classifier.to('cuda:1')self.split_size=split_sizedefforward(self,x):splits=iter(x.split(self.split_size,dim=0))s_next=next(splits)s_prev=self.seq1(s_next).to('cuda:1')ret=[]fors_nextinsplits:s_prev=self.seq2(s_prev)![1](Images/1.png)ret.append(self.fc(s_prev.view(s_prev.size(0),-1)))s_prev=self.seq1(s_next).to('cuda:1')![2](Images/2.png)s_prev=self.seq2(s_prev)ret.append(self.fc(s_prev.view(s_prev.size(0),-1)))returntorch.cat(ret)\n```", "```py\nmodel=TwoGPUAlexNet()loss_fn=nn.MSELoss()optimizer=optim.SGD(model.parameters(),lr=0.001)forepochsinrange(n_epochs):forinput,labelsindataloader;input=input.to(\"cuda:0\")labels=labels.to(\"cuda:1\")![1](Images/1.png)optimizer.zero_grad()outputs=model(input)loss_fn(outputs,labels).backward()optimizer.step()\n```", "```py\nclass Simple2GPUModel(nn.Module):\n    def __init__(self, dev0, dev1):\n        super(Simple2GPUModel,\n              self).__init__()\n        self.dev0 = dev0\n        self.dev1 = dev1\n        self.net1 = torch.nn.Linear(\n                      10, 10).to(dev0)\n        self.relu = torch.nn.ReLU()\n        self.net2 = torch.nn.Linear(\n                      10, 5).to(dev1)\n\n    def forward(self, x):\n        x = x.to(self.dev0)\n        x = self.relu(self.net1(x))\n        x = x.to(self.dev1)\n        return self.net2(x)\n```", "```py\ndefmodel_parallel_training(rank,world_size):print(f\"Running DDP with a model parallel\")setup(rank,world_size)# set up mp_model and devices for this processdev0=rank*2dev1=rank*2+1mp_model=Simple2GPUModel(dev0,dev1)ddp_mp_model=DDP(mp_model)![1](Images/1.png)loss_fn=nn.MSELoss()optimizer=optim.SGD(ddp_mp_model.parameters(),lr=0.001)forepochsinrange(n_epochs):forinput,labelsindataloader:input=input.to(dev0),labels=labels,to(dev1)![2](Images/2.png)optimizer.zero_grad()outputs=ddp_mp_model(input)![3](Images/3.png)loss=loss_fn(outputs,labels)loss.backward()optimizer.step()cleanup()\n```", "```py\n>>>python-mtorch.distributed.launch--nproc_per_node=NUM_GPUS--nnodes=2--node_rank=0![1](Images/1.png)--master_addr=\"192.168.1.1\"--master_port=1234TRAINING_SCRIPT.py(--arg1--arg2--arg3)\n```", "```py\n>>>python-mtorch.distributed.launch--nproc_per_node=NUM_GPUS--nnodes=2--node_rank=1![1](Images/1.png)--master_addr=\"192.168.1.1\"--master_port=1234TRAINING_SCRIPT.py(--arg1--arg2--arg3)\n```", "```py\n>>> python -m torch.distributed.launch --help\n```", "```py\nimporttorch.nnasnnimporttorch.nn.functionalasFclassNet(nn.Module):def__init__(self,nodes_1=120,nodes_2=84):super(Net,self).__init__()self.conv1=nn.Conv2d(3,6,5)self.pool=nn.MaxPool2d(2,2)self.conv2=nn.Conv2d(6,16,5)self.fc1=nn.Linear(16*5*5,nodes_1)![1](Images/1.png)self.fc2=nn.Linear(nodes_1,nodes_2)![2](Images/2.png)self.fc3=nn.Linear(nodes_2,10)defforward(self,x):x=self.pool(F.relu(self.conv1(x)))x=self.pool(F.relu(self.conv2(x)))x=x.view(-1,16*5*5)x=F.relu(self.fc1(x))x=F.relu(self.fc2(x))x=self.fc3(x)returnx\n```", "```py\nfrom ray import tune\nimport numpy as np\n\nconfig = {\n  \"nodes_1\": tune.sample_from(\n      lambda _: 2 ** np.random.randint(2, 9)),\n  \"nodes_2\": tune.sample_from(\n      lambda _: 2 ** np.random.randint(2, 9)),\n  \"lr\": tune.loguniform(1e-4, 1e-1),\n  \"batch_size\": tune.choice([2, 4, 8, 16])\n  }\n```", "```py\nimport torch\nimport torchvision\nfrom torchvision import transforms\n\ndef load_data(data_dir=\"./data\"):\n  train_transforms = transforms.Compose([\n      transforms.RandomCrop(32, padding=4),\n      transforms.RandomHorizontalFlip(),\n      transforms.ToTensor(),\n      transforms.Normalize(\n          (0.4914, 0.4822, 0.4465),\n          (0.2023, 0.1994, 0.2010))])\n\n  test_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(\n        (0.4914, 0.4822, 0.4465),\n        (0.2023, 0.1994, 0.2010))])\n\n  trainset = torchvision.datasets.CIFAR10(\n      root=data_dir, train=True,\n      download=True, transform=train_transforms)\n\n  testset = torchvision.datasets.CIFAR10(\n      root=data_dir, train=False,\n      download=True, transform=test_transforms)\n\n  return trainset, testset\n```", "```py\nfromtorchimportoptimfromtorchimportnnfromtorch.utils.dataimportrandom_splitdeftrain_model(config):device=torch.device(\"cuda\"iftorch.cuda.is_available()else\"cpu\")model=Net(config['nodes_1'],config['nodes_2']).to(device=device)![1](Images/1.png)criterion=nn.CrossEntropyLoss()optimizer=optim.SGD(model.parameters(),lr=config['lr'],momentum=0.9)![2](Images/2.png)trainset,testset=load_data()test_abs=int(len(trainset)*0.8)train_subset,val_subset=random_split(trainset,[test_abs,len(trainset)-test_abs])trainloader=torch.utils.data.DataLoader(train_subset,batch_size=int(config[\"batch_size\"]),shuffle=True)![3](Images/3.png)valloader=torch.utils.data.DataLoader(val_subset,batch_size=int(config[\"batch_size\"]),shuffle=True)![3](Images/3.png)forepochinrange(10):train_loss=0.0epoch_steps=0fordataintrainloader:inputs,labels=datainputs=inputs.to(device)labels=labels.to(device)optimizer.zero_grad()outputs=model(inputs)loss=criterion(outputs,labels)loss.backward()optimizer.step()train_loss+=loss.item()val_loss=0.0total=0correct=0fordatainvalloader:withtorch.no_grad():inputs,labels=datainputs=inputs.to(device)labels=labels.to(device)outputs=model(inputs)_,predicted=torch.max(outputs.data,1)total+=labels.size(0)correct+=\\\n(predicted==labels).sum().item()loss=criterion(outputs,labels)val_loss+=loss.cpu().numpy()print(f'epoch: {epoch} ',f'train_loss: ',f'{train_loss/len(trainloader)}',f'val_loss: ',f'{val_loss/len(valloader)}',f'val_acc: {correct/total}')tune.report(loss=(val_loss/len(valloader)),accuracy=correct/total)\n```", "```py\nfrom ray.tune import CLIReporter\nfrom ray.tune.schedulers import ASHAScheduler\n\nscheduler = ASHAScheduler(\n    metric=\"loss\",\n    mode=\"min\",\n    max_t=10,\n    grace_period=1,\n    reduction_factor=2)\n\nreporter = CLIReporter(\n    metric_columns=[\"loss\",\n                    \"accuracy\",\n                    \"training_iteration\"])\n```", "```py\nfrom functools import partial\n\nresult = tune.run(\n    partial(train_model),\n    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n    config=config,\n    num_samples=10,\n    scheduler=scheduler,\n    progress_reporter=reporter)\n```", "```py\nbest_trial = result.get_best_trial(\n    \"loss\", \"min\", \"last\")\nprint(\"Best trial config: {}\".format(\n    best_trial.config))\nprint(\"Best trial final validation loss:\",\n      \"{}\".format(\n          best_trial.last_result[\"loss\"]))\nprint(\"Best trial final validation accuracy:\",\n      \"{}\".format(\n          best_trial.last_result[\"accuracy\"]))\n```", "```py\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\nclass LeNet5(nn.Module):\n    def __init__(self):\n        super(LeNet5, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.max_pool2d(\n            F.relu(self.conv1(x)), (2, 2))\n        x = F.max_pool2d(\n            F.relu(self.conv2(x)), 2)\n        x = x.view(-1,\n                   int(x.nelement() / x.shape[0]))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nmodel = LeNet5()\n```", "```py\nfor n, p in model.named_parameters():\n  print(n, \": \", p.dtype)\n\n# out:\n# conv1.weight :  torch.float32\n# conv1.bias :  torch.float32\n# conv2.weight :  torch.float32\n# conv2.bias :  torch.float32\n# fc1.weight :  torch.float32\n# fc1.bias :  torch.float32\n# fc2.weight :  torch.float32\n# fc2.bias :  torch.float32\n# fc3.weight :  torch.float32\n# fc3.bias :  torch.float32\n```", "```py\nmodel = model.half()\n\nfor n, p in model.named_parameters():\n  print(n, \": \", p.dtype)\n\n# out:\n# conv1.weight :  torch.float16\n# conv1.bias :  torch.float16\n# conv2.weight :  torch.float16\n# conv2.bias :  torch.float16\n# fc1.weight :  torch.float16\n# fc1.bias :  torch.float16\n# fc2.weight :  torch.float16\n# fc2.bias :  torch.float16\n# fc3.weight :  torch.float16\n# fc3.bias :  torch.float16\n```", "```py\nimport torch.quantization\n\nquantized_model = \\\n  torch.quantization.quantize_dynamic(\n      model,\n      {torch.nn.Linear},\n      dtype=torch.qint8)\n```", "```py\nstatic_quant_model = LeNet5()\nstatic_quant_model.qconfig = \\\n  torch.quantization.get_default_qconfig('fbgemm')\n\ntorch.quantization.prepare(\n    static_quant_model, inplace=True)\ntorch.quantization.convert(\n    static_quant_model, inplace=True)\n```", "```py\nqat_model = LeNet5()\nqat_mode.qconfig = \\\n  torch.quantization.get_default_qat_qconfig('fbgemm')\n\ntorch.quantization.prepare_qat(\n    qat_model, inplace=True)\ntorch.quantization.convert(\n    qat_model, inplace=True)\n```", "```py\nfrom torch import nn\nimport torch.nn.functional as F\n\nclass LeNet5(nn.Module):\n    def __init__(self):\n        super(LeNet5, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.max_pool2d(\n            F.relu(self.conv1(x)), (2, 2))\n        x = F.max_pool2d(\n            F.relu(self.conv2(x)), 2)\n        x = x.view(-1,\n                   int(x.nelement() / x.shape[0]))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n```", "```py\ndevice = torch.device(\"cuda\" if\n  torch.cuda.is_available() else \"cpu\")\nmodel = LeNet5().to(device)\n\nprint(list(model.conv1.named_parameters()))\n# out:\n# [('weight', Parameter containing:\n# tensor([[[[0.0560, 0.0066, ..., 0.0183, 0.0783]]]],\n#        device='cuda:0',\n#        requires_grad=True)),\n#  ('bias', Parameter containing:\n# tensor([0.0754, -0.0356, ..., -0.0111, 0.0984],\n#        device='cuda:0',\n#        requires_grad=True))]\n```", "```py\nimport torch.nn.utils.prune as prune\n\nprune.random_unstructured(model.conv1,\n                          name=\"weight\",\n                          amount=0.25)\n```", "```py\nprune.random_unstructured(model.conv1,\n                          name=\"bias\",\n                          amount=0.25)\n```", "```py\nmodel=LeNet5().to(device)forname,moduleinmodel.named_modules():ifisinstance(module,torch.nn.Conv2d):prune.random_unstructured(module,name='weight',amount=0.3)![1](Images/1.png)elifisinstance(module,torch.nn.Linear):prune.random_unstructured(module,name='weight',amount=0.5)![2](Images/2.png)\n```", "```py\nmodel = LeNet5().to(device)\n\nparameters_to_prune = (\n    (model.conv1, 'weight'),\n    (model.conv2, 'weight'),\n    (model.fc1, 'weight'),\n    (model.fc2, 'weight'),\n    (model.fc3, 'weight'),\n)\n\nprune.global_unstructured(\n    parameters_to_prune,\n    pruning_method=prune.L1Unstructured,\n    amount=0.25)\n```", "```py\nclass MyPruningMethod(prune.BasePruningMethod):\n  PRUNING_TYPE = 'unstructured'\n\n  def compute_mask(self, t, default_mask):\n    mask = default_mask.clone()\n    mask.view(-1)[::2] = 0\n    return mask\n\ndef my_unstructured(module, name):\n  MyPruningMethod.apply(module, name)\n  return module\n```", "```py\nmodel = LeNet5().to(device)\nmy_unstructured(model.fc1, name='bias')\n```"]