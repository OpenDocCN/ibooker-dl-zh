["```py\ndata = datasets.make_moons(3000, noise=0.05)[0].astype(\"float32\") ![1](Images/1.png)\nnorm = layers.Normalization()\nnorm.adapt(data)\nnormalized_data = norm(data) ![2](Images/2.png)\n```", "```py\ndef Coupling():\n    input_layer = layers.Input(shape=2) ![1](Images/1.png)\n\n    s_layer_1 = layers.Dense(\n        256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)\n    )(input_layer) ![2](Images/2.png)\n    s_layer_2 = layers.Dense(\n        256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)\n    )(s_layer_1)\n    s_layer_3 = layers.Dense(\n        256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)\n    )(s_layer_2)\n    s_layer_4 = layers.Dense(\n        256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)\n    )(s_layer_3)\n    s_layer_5 = layers.Dense(\n        2, activation=\"tanh\", kernel_regularizer=regularizers.l2(0.01)\n    )(s_layer_4) ![3](Images/3.png)\n\n    t_layer_1 = layers.Dense(\n        256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)\n    )(input_layer) ![4](Images/4.png)\n    t_layer_2 = layers.Dense(\n        256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)\n    )(t_layer_1)\n    t_layer_3 = layers.Dense(\n        256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)\n    )(t_layer_2)\n    t_layer_4 = layers.Dense(\n        256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)\n    )(t_layer_3)\n    t_layer_5 = layers.Dense(\n        2, activation=\"linear\", kernel_regularizer=regularizers.l2(0.01)\n    )(t_layer_4) ![5](Images/5.png)\n\n    return models.Model(inputs=input_layer, outputs=[s_layer_5, t_layer_5]) ![6](Images/6.png)\n```", "```py\nclass RealNVP(models.Model):\n    def __init__(self, input_dim, coupling_layers, coupling_dim, regularization):\n        super(RealNVP, self).__init__()\n        self.coupling_layers = coupling_layers\n        self.distribution = tfp.distributions.MultivariateNormalDiag(\n            loc=[0.0, 0.0], scale_diag=[1.0, 1.0]\n        ) ![1](Images/1.png)\n        self.masks = np.array(\n            [[0, 1], [1, 0]] * (coupling_layers // 2), dtype=\"float32\"\n        ) ![2](Images/2.png)\n        self.loss_tracker = metrics.Mean(name=\"loss\")\n        self.layers_list = [\n            Coupling(input_dim, coupling_dim, regularization)\n            for i in range(coupling_layers)\n        ] ![3](Images/3.png)\n\n    @property\n    def metrics(self):\n        return [self.loss_tracker]\n\n    def call(self, x, training=True):\n        log_det_inv = 0\n        direction = 1\n        if training:\n            direction = -1\n        for i in range(self.coupling_layers)[::direction]: ![4](Images/4.png)\n            x_masked = x * self.masks[i]\n            reversed_mask = 1 - self.masks[i]\n            s, t = self.layers_list[i](x_masked)\n            s *= reversed_mask\n            t *= reversed_mask\n            gate = (direction - 1) / 2\n            x = (\n                reversed_mask\n                * (x * tf.exp(direction * s) + direction * t * tf.exp(gate * s))\n                + x_masked\n            ) ![5](Images/5.png)\n            log_det_inv += gate * tf.reduce_sum(s, axis = 1) ![6](Images/6.png)\n        return x, log_det_inv\n\n    def log_loss(self, x):\n        y, logdet = self(x)\n        log_likelihood = self.distribution.log_prob(y) + logdet ![7](Images/7.png)\n        return -tf.reduce_mean(log_likelihood)\n\n    def train_step(self, data):\n        with tf.GradientTape() as tape:\n            loss = self.log_loss(data)\n        g = tape.gradient(loss, self.trainable_variables)\n        self.optimizer.apply_gradients(zip(g, self.trainable_variables))\n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\n    def test_step(self, data):\n        loss = self.log_loss(data)\n        self.loss_tracker.update_state(loss)\n        return {\"loss\": self.loss_tracker.result()}\n\nmodel = RealNVP(\n    input_dim = 2\n    , coupling_layers= 6\n    , coupling_dim = 256\n    , regularization = 0.01\n)\n\nmodel.compile(optimizer=optimizers.Adam(learning_rate=0.0001))\n\nmodel.fit(\n    normalized_data\n    , batch_size=256\n    , epochs=300\n)\n```"]