- en: Chapter 5\. Hyperparameter Optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章 超参数优化
- en: Training a deep model and training a good deep model are very different things.
    While it’s easy enough to copy-paste some TensorFlow code from the internet to
    get a first prototype running, it’s much harder to transform that prototype into
    a high-quality model. The process of taking a prototype to a high-quality model
    involves many steps. We’ll explore one of these steps, hyperparameter optimization,
    in the rest of this chapter.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 训练一个深度模型和训练一个好的深度模型是非常不同的事情。虽然从互联网上复制粘贴一些TensorFlow代码以运行第一个原型是很容易的，但要将该原型转变为高质量模型则更加困难。将原型转变为高质量模型的过程涉及许多步骤。我们将在本章的其余部分探讨其中一个步骤，即超参数优化。
- en: To first approximation, hyperparameter optimization is the process of tweaking
    all parameters of a model not learned by gradient descent. These quantities are
    called “hyperparameters.” Consider fully connected networks from the previous
    chapter. While the weights of fully connected networks can be learned from data,
    the other settings of the network can’t. These hyperparameters include the number
    of hidden layers, the number of neurons per hidden layer, the learning rate, and
    more. How can you systematically find good values for these quantities? Hyperparameter
    optimization methods provide our answer to this question.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 首次近似地说，超参数优化是调整模型中所有不是通过梯度下降学习的参数的过程。这些量被称为“超参数”。考虑一下前一章中的全连接网络。虽然全连接网络的权重可以从数据中学习，但网络的其他设置不能。这些超参数包括隐藏层的数量、每个隐藏层的神经元数量、学习率等。如何系统地找到这些量的良好值？超参数优化方法为我们提供了这个问题的答案。
- en: Recall that we mentioned previously that model performance is tracked on a held-out
    “validation” set. Hyperparameter optimization methods systematically try multiple
    choices for hyperparameters on the validation set. The best-performing set of
    hyperparameter values is then evaluated on a second held-out “test” set to gauge
    the true model performance. Different hyperparameter optimization methods differ
    in the algorithm they use to propose new hyperparameter settings. These algorithms
    range from the obvious to quite sophisticated. We will only cover some of the
    simpler methods in these chapters, since the more sophisticated hyperparameter
    optimization techniques tend to require very large amounts of computational power.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下我们之前提到过，模型性能是在一个保留的“验证”集上进行跟踪的。超参数优化方法系统地在验证集上尝试多种超参数选择。表现最佳的超参数值集合然后在第二个保留的“测试”集上进行评估，以衡量真实的模型性能。不同的超参数优化方法在它们用来提出新的超参数设置的算法上有所不同。这些算法从显而易见的到相当复杂的不等。在这些章节中，我们只会涵盖一些较简单的方法，因为更复杂的超参数优化技术往往需要大量的计算能力。
- en: As a case study, we will tune the Tox21 toxicity fully connected network introduced
    in [Chapter 4](ch04.html#fully_connected_networks) to achieve good performance.
    We strongly encourage you (as always) to run the hyperparameter optimization methods
    yourself using the code in the [GitHub repo associated with this book](https://github.com/matroid/dlwithtf).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个案例研究，我们将调整[第4章](ch04.html#fully_connected_networks)中介绍的Tox21毒性全连接网络，以获得良好的性能。我们强烈鼓励您（一如既往）使用与本书相关的[GitHub存储库](https://github.com/matroid/dlwithtf)中的代码自行运行超参数优化方法。
- en: Hyperparameter Optimization Isn’t Just for Deep Networks!
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数优化不仅适用于深度网络！
- en: It’s worth emphasizing that hyperparameter optimization isn’t only for deep
    networks. Most forms of machine learning algorithms have parameters that can’t
    be learned with the default learning methods. These parameters are also called
    hyperparameters. You will see some examples of hyperparameters for random forests
    (another common machine learning method) later in this chapter.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 值得强调的是，超参数优化不仅适用于深度网络。大多数形式的机器学习算法都有无法通过默认学习方法学习的参数。这些参数也被称为超参数。在本章的后面部分，您将看到随机森林（另一种常见的机器学习方法）的一些超参数示例。
- en: It’s worth noting, however, that deep networks tend to be more sensitive to
    hyperparameter choice than other algorithms. While a random forest might underperform
    slightly with default choices for hyperparameters, deep networks might fail to
    learn entirely. For this reason, mastering hyperparameter optimization is a critical
    skill for a would-be deep learner.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然而值得注意的是，深度网络往往对超参数选择更为敏感，而不同于其他算法。虽然随机森林可能会因为超参数的默认选择而表现稍差，但深度网络可能完全无法学习。因此，掌握超参数优化是一名潜在的深度学习者的关键技能。
- en: Model Evaluation and Hyperparameter Optimization
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估和超参数优化
- en: In the previous chapters, we have only entered briefly into the question of
    how to tell whether a machine learning model is good or not. Any measurement of
    model performance must gauge the model’s ability to generalize. That is, can the
    model make predictions on datapoints it has never seen before? The best test of
    model performance is to create a model, then evaluate *prospectively* on data
    that becomes available *after* the model was constructed. However, this sort of
    test is unwieldy to do regularly. During a design phase, a practicing data scientist
    may want to evaluate many different types of models or learning algorithms to
    find which is best.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们只是简要地讨论了如何判断一个机器学习模型是否好。任何模型性能的测量都必须评估模型的泛化能力。也就是说，模型能否对它从未见过的数据点进行预测？模型性能的最佳测试是创建一个模型，然后在模型构建之后可用的数据上进行*前瞻性*评估。然而，这种测试方式通常难以定期进行。在设计阶段，一名实践数据科学家可能希望评估许多不同类型的模型或学习算法，以找到最佳的那个。
- en: The solution to this dilemma is to “hold-out” part of the available dataset
    as a validation set. This validation set will be used to measure the performance
    of different models (with differing hyperparameter choices). It’s also good practice
    to have a second held-out set, the test set, for gauging the performance of the
    final model chosen by hyperparameter selection methods.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这一困境的方法是将可用数据集的一部分作为验证集“保留”。这个验证集将用于衡量不同模型的性能（具有不同的超参数选择）。最好还要有第二个保留集，即测试集，用于评估超参数选择方法选择的最终模型的性能。
- en: Let’s assume you have a hundred datapoints. A simple procedure would be to use
    80 of these datapoints to train prospective models with 20 held-out datapoints
    used to validate the model choice. The “goodness” of a proposed model can then
    be tracked by its “score” on the held-out 20 datapoints. Models can be iteratively
    improved by proposing new designs, and accepting only those that improve performance
    on the held-out set.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您有一百个数据点。一个简单的程序是使用其中80个数据点来训练潜在模型，使用20个保留的数据点来验证模型选择。然后可以通过模型在保留的20个数据点上的“分数”来跟踪所提出模型的“好坏”。通过提出新设计并仅接受那些在保留集上表现更好的模型，可以逐步改进模型。
- en: 'In practice, though, this procedure leads to *overfitting*. Practitioners quickly
    learn peculiarities of the held-out set and tweak model structure to artificially
    boost scores on the held-out set. To combat this, practitioners commonly break
    the held-out set into two parts: one part for validation of hyperparameters and
    the other for final model validation. In this case, let’s say you reserve 10 datapoints
    for validation and 10 for final testing. This would be called an 80/10/10 data
    split.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在实践中，这个过程会导致*过拟合*。从业者很快会了解保留集的特殊性，并调整模型结构以在保留集上人为提高分数。为了应对这一问题，从业者通常将保留集分为两部分：一部分用于超参数验证，另一部分用于最终模型验证。在这种情况下，假设您保留了10个数据点用于验证，另外10个用于最终测试。这将被称为80/10/10数据分割。
- en: Why Is the Test Set Necessary?
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么测试集是必要的？
- en: An important point worth noting is that hyperparameter optimization methods
    are themselves a form of learning algorithm. In particular, they are a learning
    algorithm for setting nondifferentiable quantities that aren’t easily amenable
    to calculus-based analysis. The “training set” for the hyperparameter learning
    algorithm is simply the held-out validation set.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的一个重要观点是，超参数优化方法本身就是一种学习算法形式。特别是，它们是一种用于设置不易通过基于微积分的分析处理的不可微量的学习算法。超参数学习算法的“训练集”就是保留的验证集。
- en: In general, it isn’t very meaningful to gauge model performance on their training
    sets. As always, learned quantities must generalize and it is consequently necessary
    to test performance on a different set. Since the training set is used for gradient-based
    learning, and the validation set is used for hyperparameter learning, the test
    set is necessary to gauge how well learned hyperparameters generalize to new data.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，在训练集上衡量模型性能并没有太多意义。与往常一样，学到的量必须具有泛化性，因此有必要在不同的集合上测试性能。由于训练集用于基于梯度的学习，验证集用于超参数学习，因此测试集是必要的，以评估学到的超参数在新数据上的泛化能力。
- en: Black-Box Learning Algorithms
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 黑盒学习算法
- en: Black-box learning algorithms assume no structural information about the systems
    they are trying to optimize. Most hyperparameter methods are black-box; they work
    for any type of deep learning or machine learning algorithm.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 黑盒学习算法假设它们试图优化的系统没有结构信息。大多数超参数方法都是黑盒的；它们适用于任何类型的深度学习或机器学习算法。
- en: Black-box methods in general don’t scale as well as white-box methods (such
    as gradient descent) since they tend to get lost in high-dimensional spaces. Due
    to the lack of directional information from a gradient, black-box methods can
    get lost in even 50 dimensional spaces (optimizing 50 hyperparameters is quite
    challenging in practice).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，黑盒方法不像白盒方法（如梯度下降）那样具有良好的可扩展性，因为它们往往会在高维空间中迷失。由于黑盒方法缺乏来自梯度的方向信息，它们甚至可能在50维空间中迷失（在实践中优化50个超参数是相当具有挑战性的）。
- en: To understand why, suppose there are 50 hyperparameters, each with 3 potential
    values. Then the black-box algorithm must blindly search a space of size <math
    alttext="3 Superscript 50"><msup><mn>3</mn> <mn>50</mn></msup></math> . This can
    be done, but performing the search will require lots of computational power in
    general.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解为什么，假设有50个超参数，每个超参数有3个潜在值。那么黑盒算法必须盲目搜索一个大小为<math alttext="3 Superscript 50"><msup><mn>3</mn>
    <mn>50</mn></msup></math>的空间。这是可以做到的，但通常需要大量的计算能力。
- en: Metrics, Metrics, Metrics
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 度量，度量，度量。
- en: When choosing hyperparameters, you want to select those that make the models
    you design more accurate. In machine learning, a *metric* is a function that gauges
    the accuracy of predictions from a trained model. Hyperparameter optimization
    is done to optimize for hyperparameters that maximize (or minimize) this metric
    on the validation set. While this sounds simple up front, the notion of accuracy
    can in fact be quite subtle. Suppose you have a binary classifier. Is it more
    important to never mislabel false samples as true or to never mislabel true samples
    as false? How can you choose for model hyperparameters that satisfy the needs
    of your applications?
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择超参数时，您希望选择那些使您设计的模型更准确的超参数。在机器学习中，*度量*是一个函数，用于衡量经过训练模型的预测准确性。超参数优化是为了优化使度量在验证集上最大化（或最小化）的超参数。虽然这一听起来很简单，但准确性的概念实际上可能相当微妙。假设您有一个二元分类器。是更重要的是永远不要将假样本误标为真样本，还是永远不要将真样本误标为假样本？如何选择满足应用需求的模型超参数？
- en: The answer turns out to be to choose the correct metric. In this section, we
    will discuss many different metrics for classification and regression problems.
    We will comment on the qualities each metric emphasizes. There is no best metric,
    but there are more suitable and less suitable metrics for different applications.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是选择正确的指标。在本节中，我们将讨论许多不同的分类和回归问题的指标。我们将评论每个指标强调的特点。没有最佳指标，但对于不同的应用程序，有更合适和不太合适的指标。
- en: Metrics Aren’t a Replacement for Common Sense!
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指标不能替代常识！
- en: Metrics are terribly blind. They only optimize for a single quantity. Consequently,
    blind optimization of metrics can lead to entirely unsuitable outcomes. On the
    web, media sites often choose to optimize the metric of “user clicks.” Some enterprising
    young journalist or advertiser then realized that titles like “You’ll never believe
    what happened when X” induced users to click at higher fractions. Lo and behold,
    clickbait was born. While clickbait headlines do indeed induce readers to click,
    they also turn off readers and lead them to avoid spending time on clickbait-filled
    sites. Optimizing for user clicks resulted in drops in user engagement and trust.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 指标是非常盲目的。它们只优化一个数量。因此，盲目优化指标可能导致完全不合适的结果。在网络上，媒体网站经常选择优化“用户点击”这一指标。然后，一些有抱负的年轻记者或广告商意识到像“当X发生时，您绝对不会相信发生了什么”这样的标题会导致用户点击的比例更高。于是，点击诱饵诞生了。虽然点击诱饵标题确实会诱使读者点击，但它们也会让读者失去兴趣，并导致他们避免在充斥着点击诱饵的网站上花费时间。优化用户点击导致用户参与度和信任度下降。
- en: The lesson here is general. Optimizing for one metric often comes at the cost
    of a separate quantity. Make sure that the quantity you wish to optimize for is
    indeed the “right” quantity. Isn’t it interesting how machine learning still seems
    to require human judgment at its core?
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的教训是普遍的。优化一个指标往往会以另一个数量为代价。确保您希望优化的数量确实是“正确”的数量。机器学习似乎仍然需要人类判断，这是不是很有趣呢？
- en: Binary Classification Metrics
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二元分类指标
- en: Before introducing metrics for binary classification models, we think you will
    find it useful to learn about some auxiliary quantities. When a binary classifier
    makes predictions on a set of datapoints, you can split all these predictions
    into one of four categories ([Table 5-1](#ch5-table1)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍二元分类模型的指标之前，我们认为您会发现学习一些辅助量是有用的。当二元分类器对一组数据点进行预测时，您可以将所有这些预测分为四类之一（[表5-1](#ch5-table1)）。
- en: Table 5-1\. Prediction categories
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 表5-1. 预测类别
- en: '| Category | Meaning |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 含义 |'
- en: '| --- | --- |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| True Positive (TP) | Predicted true, Label true |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 真阳性（TP） | 预测为真，标签为真 |'
- en: '| False Positive (FP) | Predicted true, Label false |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 假阳性（FP） | 预测为真，标签为假 |'
- en: '| True Negative (TN) | Predicted false, Label false |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 真阴性（TN） | 预测为假，标签为假 |'
- en: '| False Negative (FN) | Predicted false, Label true |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 假阴性（FN） | 预测为假，标签为真 |'
- en: We will also find it useful to introduce the notation shown in [Table 5-2](#ch5-table2).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将介绍[表5-2](#ch5-table2)中显示的符号。
- en: Table 5-2\. Positives and negatives
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 表5-2. 正负
- en: '| Category | Meaning |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 含义 |'
- en: '| --- | --- |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| P | Number of positive labels |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| P | 正标签的数量 |'
- en: '| N | Number of negative labels |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| N | 负标签的数量 |'
- en: In general, minimizing the number of false positives and false negatives is
    highly desirable. However, for any given dataset, it is often not possible to
    minimize both false positives and false negatives due to limitations in the signal
    present. Consequently, there are a variety of metrics that provide various trade-offs
    between false positives and false negatives. These trade-offs can be quite important
    for applications. Suppose you are designing a medical diagnostic for breast cancer.
    Then a false positive would be to mark a healthy patient as having breast cancer.
    A false negative would be to mark a breast cancer sufferer as not having the disease.
    Neither of these outcomes is desirable, and designing the correct balance is a
    tricky question in bioethics.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，最小化假阳性和假阴性的数量是非常可取的。然而，对于任何给定的数据集，通常由于信号的限制，往往不可能同时最小化假阳性和假阴性。因此，有各种指标提供假阳性和假阴性之间的各种权衡。这些权衡对于应用程序可能非常重要。假设您正在设计乳腺癌的医学诊断。那么，将一个健康患者标记为患有乳腺癌将是一个假阳性。将一个乳腺癌患者标记为没有这种疾病将是一个假阴性。这两种结果都是不可取的，设计正确的平衡是生物伦理学中一个棘手的问题。
- en: We will now show you a number of different metrics that balance false positives
    and false negatives in different ratios ([Table 5-3](#ch5-table3)). Each of these
    ratios optimizes for a different balance, and we will dig into some of these in
    more detail.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将展示一些不同的指标，平衡不同比例的假阳性和假阴性（[表5-3](#ch5-table3)）。每个比例都优化了不同的平衡，我们将更详细地探讨其中一些。
- en: Table 5-3\. Binary metrics table
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 表5-3. 二元指标表
- en: '| Metric | Definition |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 指标 | 定义 |'
- en: '| --- | --- |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Accuracy | (TP + TN)/(P + N) |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | (TP + TN)/(P + N) |'
- en: '| Precision | TP/(TP + FP) |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 精确率 | TP/(TP + FP) |'
- en: '| Recall | TP/(TP + FN) = TP/P |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 召回率 | TP/(TP + FN) = TP/P |'
- en: '| Specificity | TN/(FP + TN) = TN/N |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 特异性 | TN/(FP + TN) = TN/N |'
- en: '| False Positive Rate (FPR) | FP/(FP + TN) = FP/N |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 假阳性率（FPR） | FP/(FP + TN) = FP/N |'
- en: '| False Negative Rate (FNR) | FN/(TP + FN) = FN/P |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 假阴性率（FNR） | FN/(TP + FN) = FN/P |'
- en: '*Accuracy* is the simplest metric. It simply counts the fraction of predictions
    that were made correctly by the classifier. In straightforward applications, accuracy
    should be the first go-to metric for a practitioner. After accuracy, *precision*
    and *recall* are the most commonly measured metrics. Precision simply measures
    what fraction of the datapoints predicted positive were actually positive. Recall
    in its turn measures the fraction of positive labeled datapoints that the classifier
    labeled positive. *Specificity* measures the fraction of datapoints labeled negative
    that were correctly classified. The false positive rate measures the fraction
    of datapoints labeled negative that were misclassified as positive. False negative
    rate is the fraction of datapoints labeled positive that were falsely labeled
    as negatives.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*准确率*是最简单的指标。它简单地计算分类器正确预测的比例。在简单的应用中，准确率应该是从业者首选的指标。在准确率之后，*精确度*和*召回率*是最常测量的指标。精确度简单地衡量了被预测为正类的数据点实际上是正类的比例。召回率则衡量了分类器标记为正类的正类标记数据点的比例。*特异度*衡量了被正确分类的负类标记数据点的比例。假阳率衡量了被错误分类为正类的负类标记数据点的比例。假阴率是被错误标记为负类的正类标记数据点的比例。'
- en: These metrics all emphasize different aspects of a classifier’s performance.
    They can also be useful in constructing some more sophisticated measurements of
    a binary classifier’s performance. For example, suppose that your binary classifier
    outputs class probabilities, and not just raw predictions. Then, there rises the
    question of choosing a *cutoff*. That is, at what probability of positive do you
    label the output as actually positive? The most common answer is 0.5, but by choosing
    higher or lower cutoffs, it is often possible to manually vary the balance between
    precision, recall, FPR, and TPR. These trade-offs are often represented graphically.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标强调分类器性能的不同方面。它们还可以用于构建一些更复杂的二元分类器性能测量。例如，假设您的二元分类器输出类别概率，而不仅仅是原始预测。那么，就会出现选择*截断*的问题。也就是说，在什么正类概率下您将输出标记为实际正类？最常见的答案是0.5，但通过选择更高或更低的截断，通常可以手动调整精确度、召回率、FPR和TPR之间的平衡。这些权衡通常以图形方式表示。
- en: The receiver operator curve (ROC) plots the trade-off between the true positive
    rate and the false positive rate as the cutoff probability is varied (see [Figure 5-1](#ch5-roc)).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接收器操作特征曲线（ROC）绘制了真正率和假正率之间的权衡，随着截断概率的变化（参见[图5-1](#ch5-roc)）。
- en: '![roc_intro3.png](assets/tfdl_0501.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![roc_intro3.png](assets/tfdl_0501.png)'
- en: Figure 5-1\. The receiver operator curve (ROC).
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1。接收器操作特征曲线（ROC）。
- en: The area under curve (AUC) for the receiver operator curve (ROC-AUC) is a commonly
    measured metric. The ROC-AUC metric is useful since it provides a global picture
    of the binary classifier for all choices of cutoff. A perfect metric would have
    ROC-AUC 1.0 since the TPR would always be maximized. For comparison, a random
    classifier would have ROC-AUC 0.5\. The ROC-AUC is often useful for imbalanced
    datasets, since the global view partially accounts for the imbalance in the dataset.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接收器操作特征曲线（ROC-AUC）下的曲线下面积（AUC）是一个常用的指标。ROC-AUC指标很有用，因为它提供了二元分类器在所有截断选择下的全局图像。一个完美的指标将具有ROC-AUC
    1.0，因为真正率将始终被最大化。作为比较，一个随机分类器将具有ROC-AUC 0.5。ROC-AUC在不平衡数据集中通常很有用，因为全局视图部分考虑了数据集中的不平衡。
- en: Multiclass Classification Metrics
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类别分类指标
- en: Many common machine learning tasks require models to output classification labels
    that aren’t just binary. The ImageNet challenge (ILSVRC) required entrants to
    build models that would recognize which of a thousand potential object classes
    were in provided images, for example. Or in a simpler example, perhaps you want
    to predict tomorrow’s weather, where provided classes are “sunny,” “rainy,” and
    “cloudy.” How do you measure the performance of such a model?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 许多常见的机器学习任务需要模型输出不仅仅是二元分类标签。例如，ImageNet挑战（ILSVRC）要求参赛者构建能够识别提供图像中的一千个潜在对象类别中的哪一个的模型。或者在一个更简单的例子中，也许您想要预测明天的天气，提供的类别是“晴天”、“下雨”和“多云”。如何衡量这种模型的性能？
- en: The simplest method is to use a straightforward generalization of accuracy that
    measures the fraction of datapoints correctly labeled ([Table 5-4](#ch5-table4)).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法是使用准确率的直接泛化，它衡量了被分类器正确标记的数据点的比例([表5-4](#ch5-table4))。
- en: Table 5-4\. Multiclass classification metrics
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 表5-4。多类别分类指标
- en: '| Metric | Definition |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 指标 | 定义 |'
- en: '| --- | --- |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Accuracy | Num Correctly Labeled/Num Datapoints |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | 正确标记的数量/数据点数量 |'
- en: We note that there do exist multiclass generalizations of quantities like precision,
    recall, and ROC-AUC, and we encourage you to look into these definitions if interested.
    In practice, there’s a simpler visualization, the *confusion matrix*, which works
    well. For a multiclass problem with *k* classes, the confusion matrix is a *k*
    × *k* matrix. The (*i*, *j*)-th cell represents the number of datapoints labeled
    as class *i* with true label class *j*. [Figure 5-2](#ch5-confmat) illustrates
    a confusion matrix.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到确实存在诸如精确度、召回率和ROC-AUC等数量的多类别泛化，并鼓励您在感兴趣的情况下查阅这些定义。在实践中，有一个更简单的可视化方法，即*混淆矩阵*，它效果很好。对于一个具有*k*个类别的多类别问题，混淆矩阵是一个*k*×*k*的矩阵。(*i*,
    *j*)-th单元格表示被标记为类别*i*且真实标签为类别*j*的数据点的数量。[图5-2](#ch5-confmat)展示了一个混淆矩阵。
- en: '![confusion_matrix.png](assets/tfdl_0502.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![confusion_matrix.png](assets/tfdl_0502.png)'
- en: Figure 5-2\. The confusion matrix for a 10-way classifier.
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-2。一个10类分类器的混淆矩阵。
- en: Don’t underestimate the power of the human eye to catch systematic failure patterns
    from simple visualizations! Looking at the confusion matrix can provide quick
    understanding that dozens of more complex multiclass metrics might miss.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 不要低估人眼从简单可视化中捕捉到系统性失败模式的能力！查看混淆矩阵可以快速理解许多更复杂的多类别指标可能忽略的内容。
- en: Regression Metrics
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归指标
- en: You learned about regression metrics a few chapters ago. As a quick recap, the
    Pearson *R*² and RMSE (root-mean-squared error) are good defaults.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您在几章前学习了回归指标。简要回顾一下，皮尔逊*R*²和RMSE（均方根误差）是很好的默认值。
- en: We only briefly covered the mathematical definition of *R*² previously, but
    will delve into it more now. Let <math alttext="x Subscript i"><msub><mi>x</mi>
    <mi>i</mi></msub></math> represent predictions and <math alttext="y Subscript
    i"><msub><mi>y</mi> <mi>i</mi></msub></math> represent labels. Let <math alttext="x
    overbar"><mover accent="true"><mi>x</mi> <mo>¯</mo></mover></math> and <math alttext="y
    overbar"><mover accent="true"><mi>y</mi> <mo>¯</mo></mover></math> represent the
    mean of the predicted values and the labels, respectively. Then the Pearson *R*
    (note the lack of square) is
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前只简要介绍了* R *²的数学定义，但现在将更深入地探讨它。让<msub><mi>x</mi> <mi>i</mi></msub>代表预测值，<msub><mi>y</mi>
    <mi>i</mi></msub>代表标签。让<mover accent="true"><mi>x</mi> <mo>¯</mo></mover>和<mover
    accent="true"><mi>y</mi> <mo>¯</mo></mover>分别代表预测值和标签的平均值。那么皮尔逊*R*（注意没有平方）是
- en: <math display="block"><mrow><mi>R</mi> <mo>=</mo> <mfrac><mrow><msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>N</mi></msubsup> <mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow><mrow><mo>(</mo><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>-</mo><mover accent="true"><mi>y</mi> <mo>¯</mo></mover><mo>)</mo></mrow></mrow>
    <mrow><msqrt><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>N</mi></msubsup> <msup><mrow><mo>(</mo><msub><mi>x</mi> <mi>i</mi></msub>
    <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></msqrt> <msqrt><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>N</mi></msubsup> <msup><mrow><mo>(</mo><msub><mi>y</mi> <mi>i</mi></msub>
    <mo>-</mo><mover accent="true"><mi>y</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></msqrt></mrow></mfrac></mrow></math>
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: R = ∑（（xi - <mover accent="true"><mi>x</mi> <mo>¯</mo></mover>）（yi - <mover
    accent="true"><mi>y</mi> <mo>¯</mo></mover>））/（√（∑（xi - <mover accent="true"><mi>x</mi>
    <mo>¯</mo></mover>）^2）√（∑（yi - <mover accent="true"><mi>y</mi> <mo>¯</mo></mover>）^2））
- en: This equation can be rewritten as
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程可以重写为
- en: <math display="block"><mrow><mi>R</mi> <mo>=</mo> <mfrac><mrow><mi>cov</mi>
    <mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow> <mrow><mi>σ</mi><mo>(</mo><mi>x</mi><mo>)</mo><mi>σ</mi><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfrac></mrow></math>
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: R = cov（x，y）/（σ（x）σ（y））
- en: where cov represents the covariance and <math alttext="sigma"><mi>σ</mi></math>
    represents the standard deviation. Intuitively, the Pearson *R* measures the joint
    fluctuations of the predictions and labels from their means normalized by their
    respective ranges of fluctuations. If predictions and labels differ, these fluctuations
    will happen at different points and will tend to cancel, making *R*² smaller.
    If predictions and labels tend to agree, the fluctuations will happen together
    and make *R*² larger. We note that *R*² is limited to a range between 0 and 1.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 其中cov代表协方差，σ代表标准差。直观地说，皮尔逊*R*度量了预测值和标签从它们的平均值归一化的联合波动。如果预测值和标签不同，这些波动将发生在不同点，并且倾向于抵消，使*R*²变小。如果预测值和标签趋于一致，波动将一起发生，并使*R*²变大。我们注意到*R*²限制在0到1之间的范围。
- en: 'The RMSE measures the absolute quantity of the error between the predictions
    and the true quantities. It stands for root-mean-squared error, which is roughly
    analogous to the absolute value of the error between the true quantity and the
    predicted quantity. Mathematically, the RMSE is defined as follows (using the
    same notation as before):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 'RMSE度量了预测值和真实值之间的误差的绝对量。它代表均方根误差，大致类似于真实数量和预测数量之间的误差的绝对值。从数学上讲，RMSE定义如下（使用与之前相同的符号）： '
- en: <math display="block"><mrow><mi>RMSE</mi> <mo>=</mo> <msqrt><mfrac><mrow><msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>N</mi></msubsup> <msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><msub><mi>y</mi> <mi>i</mi></msub> <mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mi>N</mi></mfrac></msqrt></mrow></math>
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 均方根误差（RMSE）= √（∑（xi - yi）^2 / N）
- en: Hyperparameter Optimization Algorithms
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数优化算法
- en: As we mentioned earlier in the chapter, hyperparameter optimization methods
    are learning algorithms for finding values of the hyperparameters that optimize
    the chosen metric on the validation set. In general, this objective function cannot
    be differentiated, so any optimization method must by necessity be a black box.
    In this section, we will show you some simple black-box learning algorithms for
    choosing hyperparameter values. We will use the Tox21 dataset from [Chapter 4](ch04.html#fully_connected_networks)
    as a case study to demonstrate these black-box optimization methods. The Tox21
    dataset is small enough to make experimentation easy, but complex enough that
    hyperparameter optimization isn’t trivial.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章前面提到的，超参数优化方法是用于在验证集上找到优化所选指标的超参数值的学习算法。一般来说，这个目标函数是不可微分的，因此任何优化方法必须是一个黑盒。在本节中，我们将向您展示一些简单的黑盒学习算法，用于选择超参数值。我们将使用来自[第4章](ch04.html#fully_connected_networks)的Tox21数据集作为案例研究，以演示这些黑盒优化方法。Tox21数据集足够小，使实验变得容易，但足够复杂，使超参数优化并不是微不足道的。
- en: We note before setting off that none of these black-box algorithms works perfectly.
    As you will soon see, in practice, much human input is required to optimize hyperparameters.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动之前，我们注意到这些黑盒算法都不是完美的。很快你会看到，在实践中，需要大量人为输入来优化超参数。
- en: Can’t Hyperparameter Optimization Be Automated?
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数优化不能自动化吗？
- en: One of the long-running dreams of machine learning has been to automate the
    process of selecting model hyperparameters. Projects such as the “automated statistician”
    and others have sought to remove some of the drudgery from the hyperparameter
    selection process and make model construction more easily available to non-experts.
    However, in practice, there has typically been a steep cost in performance for
    the added convenience.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的一个长期梦想是自动选择模型的超参数。诸如“自动统计学家”等项目一直致力于消除超参数选择过程中的一些繁琐工作，并使模型构建更容易为非专家所掌握。然而，在实践中，通常为了增加便利性而付出了性能的巨大代价。
- en: In recent years, there has been a surge of work focused on improving the algorithmic
    foundations of model tuning. Gaussian processes, evolutionary algorithms, and
    reinforcement learning have all been used to learn model hyperparameters and architectures
    with very limited human input. Recent work has shown that with large amounts of
    computing power, these algorithms can exceed expert performance in model tuning!
    But the overhead is severe, with dozens to hundreds of times greater computational
    power required.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，有大量的工作集中在改进模型调整的算法基础上。高斯过程、进化算法和强化学习都被用来学习模型的超参数和架构，几乎没有人为输入。最近的研究表明，借助大量的计算能力，这些算法可以超越专家在模型调整方面的表现！但是开销很大，需要数十到数百倍的计算能力。
- en: For now, automatic model tuning is still not practical. All algorithms we cover
    in this section require significant manual tuning However, as hardware quality
    improves, we anticipate that hyperparameter learning will become increasingly
    automated. In the near term, we recommend strongly that all practitioners master
    the intricacies of hyperparameter tuning. A strong ability to hyperparameter tune
    is the skill that separates the expert from the novice.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，自动模型调整仍然不太实用。本节中涵盖的所有算法都需要大量手动调整。然而，随着硬件质量的提高，我们预计超参数学习将变得越来越自动化。在短期内，我们强烈建议所有从业者掌握超参数调整的复杂性。精通超参数调整是区分专家和新手的技能。
- en: Setting Up a Baseline
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 建立一个基准线
- en: The first step in hyperparameter tuning is finding a *baseline*. A baseline
    is performance achievable by a robust (non–deep learning usually) algorithm. In
    general, random forests are a superb choice for setting baselines. As shown in
    [Figure 5-3](#ch5-rf), random forests are an ensemble method that train many decision
    tree models on subsets of the input data and input features. These individual
    trees then vote on the outcome.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数调整的第一步是找到一个*基准线*。基准线是由一个强大的（通常非深度学习）算法可以实现的性能。一般来说，随机森林是设置基准线的绝佳选择。如[图5-3](#ch5-rf)所示，随机森林是一种集成方法，它在输入数据和输入特征的子集上训练许多决策树模型。这些个体树然后对结果进行投票。
- en: '![random_forest_new2.png](assets/tfdl_0503.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![random_forest_new2.png](assets/tfdl_0503.png)'
- en: Figure 5-3\. An illustration of a random forest. Here v is the input feature
    vector.
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-3。随机森林的示意图。这里v是输入特征向量。
- en: Random forests tend to be quite robust models. They are noise tolerant, and
    don’t worry about the scale of their input features. (Although we don’t have to
    worry about this for Tox21 since all our features are binary, in general deep
    networks are quite sensitive to their input range. It’s healthy to normalize or
    otherwise scale the input range for good performance. We will return to this point
    in later chapters.) They also tend to have strong generalization and don’t require
    much hyperparameter tuning to boot. For certain datasets, beating the performance
    of a random forest with a deep network can require considerable sophistication.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林往往是相当强大的模型。它们对噪声具有容忍性，不担心其输入特征的规模。（虽然对于Tox21我们不必担心这一点，因为我们所有的特征都是二进制的，但一般来说，深度网络对其输入范围非常敏感。为了获得良好的性能，最好对输入范围进行归一化或缩放。我们将在后面的章节中回到这一点。）它们还倾向于具有强大的泛化能力，不需要太多的超参数调整。对于某些数据集，要想用深度网络超越随机森林的性能可能需要相当大的复杂性。
- en: How can we create and train a random forest? Luckily for us, in Python, the
    scikit-learn library provides a high-quality implementation of a random forest.
    There are many tutorials and introductions to scikit-learn available, so we’ll
    just display the training and prediction code needed to build a Tox21 random forest
    model here ([Example 5-1](#ch5-tox21rf)).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何创建和训练一个随机森林？幸运的是，在Python中，scikit-learn库提供了一个高质量的随机森林实现。有许多关于scikit-learn的教程和介绍，所以我们只会展示构建Tox21随机森林模型所需的训练和预测代码（[示例5-1](#ch5-tox21rf)）。
- en: Example 5-1\. Defining and training a random forest on the Tox21 dataset
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例5-1。在Tox21数据集上定义和训练一个随机森林
- en: '[PRE0]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here `train_X`, `train_y`, and so on are the Tox21 datasets defined in the
    previous chapter. Recall that all these quantities are NumPy arrays. `n_estimators`
    refers to the number of decision trees in our forest. Setting 50 or 100 trees
    often provides decent performance. Scikit-learn offers a simple object-oriented
    API with `fit(X, y)` and `predict(X)` methods. This model achieves the following
    accuracy with respect to our weighted accuracy metric:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的`train_X`，`train_y`等是在上一章中定义的Tox21数据集。回想一下，所有这些量都是NumPy数组。`n_estimators`指的是我们森林中的决策树数量。设置50或100棵树通常会提供良好的性能。Scikit-learn提供了一个简单的面向对象的API，具有`fit(X,
    y)`和`predict(X)`方法。该模型根据我们的加权准确性指标实现了以下准确性：
- en: '[PRE1]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Recall that the fully connected network from [Chapter 4](ch04.html#fully_connected_networks)
    achieved performance:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，来自[第4章](ch04.html#fully_connected_networks)的全连接网络取得了良好的性能：
- en: '[PRE2]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: It looks like our baseline gets greater accuracy than our deep learning model!
    Time to roll up our sleeves and get to work.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们的基线比我们的深度学习模型获得了更高的准确性！是时候卷起袖子开始工作了。
- en: Graduate Student Descent
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 研究生下降
- en: The simplest method to try good hyperparameters is to simply try a number of
    different hyperparameter variants manually to see what works. This strategy can
    be surprisingly effective and educational. A deep learning practitioner needs
    to build up intuition about the structure of deep networks. Given the very weak
    state of theory, empirical work is the best way to learn how to build deep learning
    models. We highly recommend trying many variants of the fully connected model
    yourself. Be systematic; record your choices and results in a spreadsheet and
    systematically explore the space. Try to understand the effects of various hyperparameters.
    Which make network training proceed faster and which slower? What ranges of settings
    completely break learning? (These are quite easy to find, unfortunately.)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试好的超参数的最简单方法是手动尝试多种不同的超参数变体，看看哪种有效。这种策略可能会出奇地有效和有教育意义。深度学习从业者需要建立对深度网络结构的直觉。鉴于理论的非常薄弱，经验性工作是学习如何构建深度学习模型的最佳方法。我们强烈建议尝试许多不同的全连接模型变体。要有系统性；在电子表格中记录您的选择和结果，并系统地探索空间。尝试理解各种超参数的影响。哪些使网络训练进行得更快，哪些使其变慢？哪些设置范围完全破坏了学习？（这些很容易找到，不幸的是。）
- en: There are a few software engineering tricks that can make this search easier.
    Make a function whose arguments are the hyperparameter you wish to explore and
    have it print out the accuracy. Then trying new hyperparameter combinations requires
    only a single function call. [Example 5-2](#ch5-tox21fcnetfun) shows what this
    function signature would look like for our fully connected network from the Tox21
    case study.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些软件工程技巧可以使这种搜索更容易。创建一个函数，其参数是您希望探索的超参数，并让其打印出准确性。然后尝试新的超参数组合只需要一个函数调用。[示例5-2](#ch5-tox21fcnetfun)展示了这个函数签名在Tox21案例研究中的全连接网络中会是什么样子。
- en: Example 5-2\. A function mapping hyperparameters to different Tox21 fully connected
    networks
  id: totrans-101
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例5-2。将超参数映射到不同的Tox21全连接网络的函数
- en: '[PRE3]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let’s walk through each of these hyperparameters. `n_hidden` controls the number
    of neurons in each hidden layer of the network. `n_layers` controls the number
    of hidden layers. `learning_rate` controls the learning rate used in gradient
    descent, and `dropout_prob` is the probability neurons are not dropped during
    training steps. `n_epochs` controls the number of passes through the total data
    and `batch_size` controls the number of datapoints in each batch.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐个讨论这些超参数。`n_hidden`控制网络中每个隐藏层中的神经元数量。`n_layers`控制隐藏层的数量。`learning_rate`控制梯度下降中使用的学习率，`dropout_prob`是训练步骤中不丢弃神经元的概率。`n_epochs`控制通过总数据的次数，`batch_size`控制每个批次中的数据点数量。
- en: '`weight_positives` is the only new hyperparameter here. For unbalanced datasets,
    it can often be helpful to weight examples of both classes to have equal weight.
    For the Tox21 dataset, DeepChem provides weights for us to use. We simply multiply
    the per-example cross-entropy terms by the weights to perform this weighting ([Example 5-3](#ch5-tox21weight)).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`weight_positives`是这里唯一的新超参数。对于不平衡的数据集，通常有助于对两类示例进行加权，使它们具有相等的权重。对于Tox21数据集，DeepChem为我们提供了要使用的权重。我们只需将每个示例的交叉熵项乘以权重以执行此加权（[示例5-3](#ch5-tox21weight)）。'
- en: Example 5-3\. Weighting positive samples for Tox21
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例5-3。对Tox21加权正样本
- en: '[PRE4]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Why is the method of picking hyperparameter values called graduate student descent?
    Machine learning, until recently, has been a primarily academic field. The tried-and-true
    method for designing a new machine learning algorithm has been describing the
    method desired to a new graduate student, and asking them to work out the details.
    This process is a bit of a rite of passage, and often requires the student to
    painfully try many design alternatives. On the whole, this is a very educational
    experience, since the only way to gain design aesthetic is to build up a memory
    of settings that work and don’t work.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么选择超参数值的方法被称为研究生下降？直到最近，机器学习一直是一个主要的学术领域。设计新的机器学习算法的经过考验的方法是描述所需的方法给一个新的研究生，并要求他们解决细节。这个过程有点像一种仪式，通常需要学生痛苦地尝试许多设计替代方案。总的来说，这是一个非常有教育意义的经历，因为获得设计美学的唯一方法是建立起一个记忆工作和不工作的设置。
- en: Grid Search
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网格搜索
- en: After having tried a few manual settings for hyperparameters, the process will
    begin to feel very tedious. Experienced programmers will be tempted to simply
    write a `for` loop that iterates over the choices of hyperparameters desired.
    This process is more or less the grid-search method. For each hyperparameter,
    pick a list of values that might be good hyperparameters. Write a nested `for`
    loop that tries all combinations of these values to find their validation accuracies,
    and keep track of the best performers.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试了一些超参数的手动设置之后，这个过程将开始变得非常乏味。有经验的程序员往往会诱惑简单地编写一个`for`循环，迭代所需的超参数选择。这个过程更多或少是网格搜索方法。对于每个超参数，选择一个可能是好的超参数的值列表。编写一个嵌套的`for`循环，尝试所有这些值的组合以找到它们的验证准确性，并跟踪最佳表现者。
- en: There is one subtlety in the process, however. Deep networks can be fairly sensitive
    to the choice of random seed used to initialize the network. For this reason,
    it’s worth repeating each choice of hyperparameter settings multiple times and
    averaging the results to damp the variance.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个过程中有一个微妙之处。深度网络对用于初始化网络的随机种子的选择非常敏感。因此，值得重复每个超参数设置的选择多次，并对结果进行平均以减少方差。
- en: The code to do this is straightforward, as [Example 5-4](#ch5-tox21grid) shows.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如[示例5-4](#ch5-tox21grid)所示，执行此操作的代码很简单。
- en: Example 5-4\. Performing grid search on Tox21 fully connected network hyperparameters
  id: totrans-112
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例5-4。对Tox21完全连接网络超参数进行网格搜索
- en: '[PRE5]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Random Hyperparameter Search
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机超参数搜索
- en: For experienced practitioners, it will often be very tempting to reuse magical
    hyperparameter settings or search grids that worked in previous applications.
    These settings can be valuable, but they can also lead us astray. Each machine
    learning problem is slightly different, and the optimal settings might lie in
    a region of parameter space we haven’t previously considered. For that reason,
    it’s often worthwhile to try random settings for hyperparameters (where the random
    values are chosen from a reasonable range).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有经验的从业者来说，往往会很诱人地重复使用在以前的应用中有效的神奇超参数设置或搜索网格。这些设置可能很有价值，但也可能导致我们走入歧途。每个机器学习问题都略有不同，最佳设置可能位于我们以前未考虑的参数空间的某个区域。因此，尝试超参数的随机设置（其中随机值是从一个合理范围内选择的）通常是值得的。
- en: There’s also a deeper reason to try random searches. In higher-dimensional spaces,
    regular grids can miss a lot of information, especially if the spacing between
    grid points isn’t great. Selecting random choices for grid points can help us
    from falling into the trap of loose grids. [Figure 5-4](#ch5-tox21gridvsrandom)
    illustrates this fact.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试随机搜索还有一个更深层次的原因。在高维空间中，常规网格可能会错过很多信息，特别是如果网格点之间的间距不大的话。选择网格点的随机选择可以帮助我们避免陷入松散网格的陷阱。[图5-4](#ch5-tox21gridvsrandom)说明了这一事实。
- en: '![random_grid.png](assets/tfdl_0504.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![random_grid.png](assets/tfdl_0504.png)'
- en: Figure 5-4\. An illustration of why random hyperparameter search can be superior
    to grid search.
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-4。说明为什么随机超参数搜索可能优于网格搜索。
- en: How can we implement random hyperparameter search in software? A neat software
    trick is to sample the random values desired up front and store them in a list.
    Then, random hyperparameter search simply turns into grid search over these randomly
    sampled lists. Here’s an example. For learning rates, it’s often useful to try
    a wide range from .1 to .000001 or so. [Example 5-5](#ch5-tox21randsamp) uses
    NumPy to sample some random learning rates.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何在软件中实现随机超参数搜索？一个巧妙的软件技巧是预先抽样所需的随机值并将其存储在列表中。然后，随机超参数搜索简单地变成了对这些随机抽样列表进行网格搜索。这里有一个例子。对于学习率，通常很有用的是尝试从.1到.000001等范围内的广泛范围。[示例5-5](#ch5-tox21randsamp)使用NumPy来抽样一些随机学习率。
- en: Example 5-5\. Sampling random learning rates
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例5-5。对学习率进行随机抽样
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We use a mathematical trick here. Note that .1 = 10^(–1) and .000001 = 10^(–6).
    Sampling real-valued numbers between ranges like 1 and 6 is easy with `np.random.uniform`.
    We can raise these sampled values to a power to recover our learning rates. Then
    `learning_rates` holds a list of values that we can feed into our grid search
    code from the previous section.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用了一个数学技巧。请注意，.1 = 10^（-1），.000001 = 10^（-6）。使用`np.random.uniform`在1和6之间对实值进行抽样很容易。我们可以将这些抽样值提升到一个幂以恢复我们的学习率。然后`learning_rates`保存了一个值列表，我们可以将其输入到前一节的网格搜索代码中。
- en: Challenge for the Reader
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 读者的挑战
- en: In this chapter, we’ve only covered the basics of hyperparameter tuning, but
    the tools covered are quite powerful. As a challenge, try tuning the fully connected
    deep network to achieve validation performance higher than that of the random
    forest. This might require a bit of work, but it’s well worth the experience.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们只涵盖了超参数调整的基础知识，但所涵盖的工具非常强大。作为挑战，尝试调整完全连接的深度网络，以实现高于随机森林的验证性能。这可能需要一些工作，但这个经验是非常值得的。
- en: Review
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾
- en: In this chapter, we covered the basics of hyperparameter optimization, the process
    of selecting values for model parameters that can’t be learned automatically on
    the training data. In particular, we introduced random and grid hyperparameter
    search and demonstrated the use of such code for optimizing models on the Tox21
    dataset introduced in the last chapter.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了超参数优化的基础知识，即选择模型参数的值，这些值无法在训练数据上自动学习。特别是，我们介绍了随机和网格超参数搜索，并演示了在上一章中介绍的Tox21数据集上优化模型的代码的使用。
- en: In [Chapter 6](ch06.html#convolutional_neural_networks), we will return to our
    survey of deep architectures and introduce you to convolutional neural networks,
    one of the fundamental building blocks of modern deep architectures.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](ch06.html#convolutional_neural_networks)中，我们将回顾深度架构，并向您介绍卷积神经网络，这是现代深度架构的基本构建块之一。
