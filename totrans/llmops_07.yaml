- en: Chapter 7\. Evaluation for LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章\. 长语言模型的评估
- en: Language models have become increasingly sophisticated, but assessing their
    effectiveness accurately remains a significant challenge.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型变得越来越复杂，但准确评估其有效性仍然是一个重大挑战。
- en: The importance of LLM evaluation has garnered attention not only from academia
    but also from industry stakeholders. This convergence of research and testing
    efforts signifies the importance of the problem and the collective determination
    to find effective solutions. It also accelerates the pace of innovation, helping
    researchers understand and improve these models further.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 长语言模型评估的重要性不仅引起了学术界的关注，也引起了行业利益相关者的关注。这种研究和测试努力的融合标志着问题的重大性和集体寻找有效解决方案的决心。它还加速了创新的步伐，帮助研究人员进一步理解和改进这些模型。
- en: In academia, researchers have been exploring new methodologies, developing innovative
    metrics, and conducting rigorous experiments to push the boundaries of LLM evaluation
    Although there are some leading contenders, there are no clear winners yet, since
    many metrics and scoreboards end up being useful for just a short period or for
    a narrow set of applications. Regardless, industry players are keenly aware of
    the practical implications of LLM performance.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在学术界，研究人员一直在探索新的方法，开发创新指标，并进行严格的实验，以推动长语言模型评估的边界。尽管有一些领先竞争者，但还没有明确的赢家，因为许多指标和排行榜最终只对短暂的时间或狭窄的应用范围有用。无论如何，行业参与者对长语言模型性能的实际影响非常敏感。
- en: At its core, evaluation aims to gauge how well an LLM accomplishes its intended
    purpose, whether it’s generating coherent and contextually relevant text, understanding
    user input, or completing specific tasks. In this chapter, you’ll learn about
    a systematic framework designed to tackle this challenge for different applications,
    along with some tips on what has worked.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，评估旨在衡量长语言模型实现其预期目的的程度，无论是生成连贯且上下文相关的文本、理解用户输入还是完成特定任务。在本章中，您将了解一个旨在应对不同应用的挑战的系统框架，以及一些关于哪些方法有效的提示。
- en: Why Evaluation Is a Hard Problem
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么评估是一个难题
- en: '*Evaluating* LLMs is the process of assessing their performance and capabilities.
    It involves a combination of methods to determine how well an LLM achieves its
    intended purpose and adheres to ethical guidelines.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*评估* 长语言模型是评估其性能和能力的过程。它涉及一系列方法，以确定长语言模型实现其预期目的和遵守道德指南的程度。'
- en: Developing and deploying ML solutions requires creating new types of testing
    and evaluation than those used in traditional software development. In particular,
    ML models use random numbers during training and need to be tested in aggregate
    across datasets, as well as on specific atomic pieces of data that can help validate
    that the training worked correctly. However, once the models are trained, most
    ML models are deterministic in that they don’t use random methods to make inferences;
    i.e., that the same inputs will always produce the same outputs.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 开发和部署机器学习解决方案需要创建比传统软件开发中使用的测试和评估类型更新的类型。特别是，机器学习模型在训练过程中使用随机数，需要在数据集的整体上进行测试，以及在对特定原子数据片段的测试中，这些测试有助于验证训练是否正确进行。然而，一旦模型被训练，大多数机器学习模型都是确定性的，即它们不使用随机方法进行推理；也就是说，相同的输入将始终产生相同的输出。
- en: In contrast, LLMs use random numbers during training and making inferences,
    so the same input can produce different outputs even if there have been no changes
    in the model. Several other assumptions no longer hold or need to be augmented.
    This chapter will explore several open questions around datasets, metrics, and
    methodology selection.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，长语言模型在训练和推理过程中使用随机数，因此即使模型没有变化，相同的输入也可能产生不同的输出。还有几个其他假设不再成立或需要增强。本章将探讨关于数据集、指标和方法选择选择的一些开放性问题。
- en: 'Any operational ML solution must provide some expected performance characteristics
    before going into production. You also need a way to monitor it effectively to
    identify and fix any performance problems after deployment. Model evaluation helps:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 任何运营中的机器学习解决方案在投入生产之前都必须提供一些预期的性能特征。您还需要一种有效监控它的方法，以便在部署后识别和修复任何性能问题。模型评估有助于：
- en: Ensure that the model is performing as expected
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保模型按预期运行
- en: Identify areas where the model can be improved
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定模型可以改进的领域
- en: Ensure that the model is being used safely and responsibly
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保模型被安全且负责任地使用
- en: 'Why is evaluating LLMs so hard? There are several reasons:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么评估长语言模型如此困难？有几个原因：
- en: First, human language is very complex and can be difficult to quantify. This
    makes it difficult to develop accurate quality evaluation metrics.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，人类语言非常复杂，难以量化。这使得开发准确的质量评估指标变得困难。
- en: Language models are typically trained on large datasets of text. This makes
    it difficult to find a representative sample of text that the model has never
    seen before to use for evaluation.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言模型通常在大量的文本数据集上训练。这使得很难找到模型之前从未见过的代表性文本样本用于评估。
- en: Language models can exhibit bias in line with the datasets they are trained
    on, generating text that violates social, ethical, or legal norms.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言模型可能会表现出与它们训练数据集一致的偏差，生成违反社会、道德或法律规范的文本。
- en: The difficulty of interpreting why LLMs generate particular outputs can lead
    to challenges around reproducibility and consistent experimental design.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 解释为什么大型语言模型（LLM）生成特定输出的难度可能导致可重复性和一致实验设计方面的挑战。
- en: 'LLMs are trained on massive amounts of data, and the number of possible inputs
    they can receive is practically infinite, so it’s impossible to exhaustively test
    them on every scenario. Evaluating even a tiny fraction of possibilities is a
    monumental task. Therefore, we must content ourselves with evaluating categories
    of scenarios, such as:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: LLM在大量数据上训练，它们可以接收的可能输入数量实际上是无限的，因此不可能在每种情况下都进行彻底测试。评估可能性的一小部分就是一个艰巨的任务。因此，我们必须满足于评估场景类别，例如：
- en: Informativeness and factuality
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息性和事实性
- en: Is the output factually correct?
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出是否具有事实准确性？
- en: Does the output contain sufficient information relevant to the input prompt?
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出是否包含与输入提示相关的足够信息？
- en: Is the generated text a complete response to the input?
  id: totrans-22
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的文本是否是对输入的完整响应？
- en: Fluency and coherence
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流畅性和连贯性
- en: Are the outputs grammatically correct and readable?
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出的语法是否正确且易于阅读？
- en: Do they follow a logical flow?
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们是否遵循逻辑流程？
- en: Is the output language at an appropriate level?
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出的语言水平是否适当？
- en: Engagement and style
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参与度和风格
- en: How engaging and interesting are the LLM’s outputs?
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM的输出有多吸引人和有趣？
- en: Is the writing style appropriate?
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 写作风格是否适当？
- en: Safety and bias
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全性和偏差
- en: What harmful content could this LLM generate?
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这种LLM可能生成哪些有害内容？
- en: Could the output be used to put people at risk?
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出是否可能使人们处于危险之中？
- en: Is the output using biased concepts or language?
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出是否使用了有偏的概念或语言？
- en: Grounding
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础
- en: How well grounded is the LLM’s response in real-world information?
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM的响应在现实世界信息中的基础有多牢固？
- en: Does it offer appropriate references?
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否提供了适当的参考文献？
- en: Does it avoid hallucinations?
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否避免了幻觉？
- en: Efficiency
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 效率
- en: What computational resources does the LLM require to generate outputs?
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM生成输出需要多少计算资源？
- en: How long does it take to start generating the response?
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始生成响应需要多长时间？
- en: How long does it take to generate a complete response?
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成完整响应需要多长时间？
- en: 'While there are clear success metrics for some types of tasks (e.g., accuracy
    in image recognition: “Is this a picture of a bird?”), what constitutes a “good”
    response from an LLM can be subjective. Does the output provide relevant information?
    Is it creative? Is it factually accurate? These goals can conflict, making it
    hard to design a single metric that captures everything. “Good performance” can
    mean several things.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然某些类型任务的成功指标是明确的（例如，图像识别中的准确性：“这是否是一张鸟的图片？”），但来自LLM的“良好”响应可能具有主观性。输出是否提供了相关信息？是否具有创造性？是否具有事实准确性？这些目标可能存在冲突，使得很难设计一个能够捕捉所有内容的单一指标。“良好表现”可能意味着几件事情。
- en: Another difference between evaluating ML and LLM models is that when an ML model
    fails an evaluation task, the developing team usually turns to *interpretability*
    tools that explain why the model made decisions. Such tools try to understand
    the internal mechanisms of models by running an extremely large number of examples
    through a model and measuring how changes in the input influence the output. Since
    most ML models are deterministic (the same input will always provide the same
    output), these tools allow developers to understand what parts of the input are
    important for generating some outputs, essentially improving their understanding
    of how the model works internally. ​As of today, interpretability tools are unavailable
    for LLMs because LLMs have too many parameters and are nondeterministic; thus,
    an immense quantity of examples and computation time would be needed to understand
    their internal ​workings.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 评估机器学习（ML）和大型语言模型（LLM）之间的另一个区别在于，当一个ML模型未能通过评估任务时，开发团队通常会转向*可解释性*工具来解释模型做出决策的原因。这些工具通过在一个模型上运行大量示例并测量输入变化对输出的影响，试图理解模型的内部机制。由于大多数ML模型是确定性的（相同的输入总是产生相同的输出），这些工具允许开发者理解哪些输入部分对于生成某些输出是重要的，从而本质上提高了他们对模型内部工作原理的理解。截至目前，由于LLM具有太多参数且是非确定性的，因此可解释性工具对LLM不可用；因此，需要大量的示例和计算时间来理解其内部工作。
- en: Evaluating Performance
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估性能
- en: There are a number of ways to evaluate and monitor the accuracy of LLM-based
    solutions during development and after deployment. *Manually checking* the output
    for accuracy and correctness can be time-consuming, and it depends on the judgment
    of evaluators. *Automatic evaluation* uses tools to evaluate the accuracy of the
    LLM’s output; essentially, you’re using LLMs to evaluate LLMs. User feedback is
    also helpful in identifying areas where the LLM is performing poorly and needs
    improvement.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发和部署后评估基于LLM的解决方案的准确性和监控方法有很多种。*手动检查*输出的准确性和正确性可能很耗时，并且取决于评估者的判断。*自动评估*使用工具来评估LLM输出的准确性；本质上，你是在使用LLM来评估LLM。用户反馈也有助于识别LLM表现不佳且需要改进的领域。
- en: Most importantly, you cannot evaluate an LLM without an application. In many
    LLM applications, users know which real-world performance metrics would be useful.
    For example, let’s say your company is using LLMs to generate text scripts for
    web advertisements. When humans write the advertising copy, a typical evaluation
    method is to perform an *A/B test*, randomly offering different options to similar
    audiences, A and B, and measuring the success rate (for example, number of ad
    clicks) of each audience. If the success rate for the audience receiving option
    A is different enough from that of option B to be statistically significant, the
    company would select option A as the more successful script. The same method can
    be used on LLM-generated copy. Indeed, for many common ML tasks, such as classifying
    text, identifying images, and counting objects, it makes sense to simply use the
    existing pre-LLM methods and metrics.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，没有应用程序就无法评估LLM。在许多LLM应用中，用户知道哪些现实世界的性能指标是有用的。例如，假设贵公司正在使用LLM来生成网络广告的文本脚本。当人类编写广告文案时，一种典型的评估方法是进行*A/B测试*，随机向类似受众A和B提供不同的选项，并测量每个受众的成功率（例如，广告点击次数）。如果接受选项A的受众的成功率与接受选项B的受众的成功率有足够的差异，以至于具有统计学意义，公司会选择选项A作为更成功的脚本。同样的方法也可以用于LLM生成的文案。实际上，对于许多常见的ML任务，如文本分类、图像识别和物体计数，简单地使用现有的预LLM方法和指标是有意义的。
- en: There are, however, some metrics that are specific to NLP and don’t require
    user involvement, making them less costly and good choices to evaluate LLMs.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一些指标是特定于自然语言处理（NLP）的，并且不需要用户参与，这使得它们成本较低，是评估LLM的好选择。
- en: Since a major part of what LLMs do is generate content, we use a set of metrics
    called *generative metrics* to measure the quality of the content generated. The
    most basic of these, called n*-gram-based metrics*, assess the similarity between
    generated text and existing data by examining the overlap of sequences of *n*
    words. To use this metric for an evaluation, you should know the expected “correct”
    answer, and you can compare how many of the *n* words generated by the LLM are
    in the correct answer.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLM（大型语言模型）的主要功能是生成内容，我们使用一套称为**生成指标**的度量标准来衡量生成内容的品质。其中最基本的一种，称为**基于n-gram的指标**，通过检查*n*个单词序列的重叠来评估生成文本与现有数据之间的相似性。为了使用这个指标进行评估，你应该知道预期的“正确”答案，然后可以比较LLM生成的*n*个单词中有多少在正确答案中。
- en: For example, if *n* equals 1, the comparison looks at individual words; if *n*
    equals 2, it considers pairs of words; and so on. These metrics quantify the degree
    of similarity based on the shared *n*-grams, providing insights into the coherence
    and relevance of the generated text compared to the correct answer.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果*n*等于1，比较将查看单个单词；如果*n*等于2，它将考虑单词对；依此类推。这些指标根据共享的*n*-gram量化相似度，为生成文本与正确答案之间的连贯性和相关性提供见解。
- en: 'For example, one of your tests could be “Q: What’s the capital of France? A:
    Paris.” The *n*-gram test can be very simple and will work well when the LLM answers
    “Paris” (100% of the *n*-grams match) but won’t perform well when the LLM provides
    the correct answer “The capital of France is Paris.” Since you were expecting
    the answer to be Paris, only 16.6% of the words in the second answer match the
    correct answer, and you may think that the LLM is not performing as well as it
    really is.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你的一个测试可以是“问题：法国的首都是什么？答案：巴黎。”*n-gram测试*可以非常简单，当LLM回答“巴黎”（100%的*n*-gram匹配）时效果很好，但当LLM提供正确答案“法国的首都是巴黎”时，表现就不会很好。因为你预期答案是巴黎，第二个答案中只有16.6%的单词与正确答案匹配，你可能会认为LLM的表现不如实际那么好。
- en: 'Second*, similarity-based metrics* aim to capture various aspects of similarity
    between generated text and a reference text. They include:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，**基于相似度的指标**旨在捕捉生成文本与参考文本之间相似性的各个方面。它们包括：
- en: BERTScore
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: BERTScore
- en: Measures both content overlap and fluency
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 测量内容重叠和流畅性
- en: SemScore
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: SemScore
- en: Checks that the generated text conveys the same meaning and intent as the reference
    text
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 检查生成的文本是否传达了与参考文本相同的意义和意图
- en: MoverScore
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: MoverScore
- en: Calculates the minimum amount of “work” required to transform one text into
    another
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 计算将一个文本转换为另一个文本所需的最小“工作量”。
- en: These metrics compare how similar two whole sentences are by computing embeddings
    and comparing them. Using the same example as before, the LLM answers “It’s Paris”
    and “The capital of France is Paris” will both generate a high score, as both
    these sentences have similar meanings. One problem is that the sentence “Teh KaPiTaLL
    of Franceland is PARIS” will also score high in terms of meaning similarity, even
    though it’s full of spelling errors and uses the made-up word “Franceland.”
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标通过计算嵌入并比较它们来比较两个整个句子的相似度。使用之前的例子，LLM回答“它是巴黎”和“法国的首都是巴黎”都会得到高分，因为这两个句子具有相似的意义。一个问题在于，句子“Teh
    KaPiTaLL of Franceland is PARIS”在意义上相似度方面也会得到高分，尽管它充满了拼写错误并使用了虚构的单词“Franceland”。
- en: 'Therefore, we turn to *LLM-based metrics*, which use other LLMs to evaluate
    the target LLM’s generation quality and identify potential hallucinations. These
    metrics identify correct answers and can also evaluate fluency and grammatical
    correctness, but they are expensive to compute. Here are some popular metrics
    and the papers that define how to implement and use them:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们转向**基于LLM的指标**，这些指标使用其他LLM来评估目标LLM的生成质量并识别潜在的幻觉。这些指标可以识别正确答案，还可以评估流畅性和语法正确性，但计算成本较高。以下是一些流行的指标以及定义如何实现和使用它们的论文：
- en: '[G-Eval](https://oreil.ly/IzuUL)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[G-Eval](https://oreil.ly/IzuUL)'
- en: Scores the generated text based on its coherence, fluency, and factual consistency
    as judged by another LLM.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 根据另一个LLM判断的连贯性、流畅性和事实一致性来评分生成的文本。
- en: '[UniEval](https://oreil.ly/nMMsh)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[UniEval](https://oreil.ly/nMMsh)'
- en: Considers multiple factors like fluency, grammaticality, and factual coherence
    through an ensemble of LLM evaluators.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一组LLM评估器考虑多个因素，如流畅性、语法性和事实连贯性。
- en: '[GPTScore](https://oreil.ly/ylJna)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[GPTScore](https://oreil.ly/ylJna)'
- en: Designed specifically for GPT-like models, it uses an LLM to evaluate aspects
    like coherence, safety, and factual consistency.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 专为GPT类模型设计，它使用一个LLM来评估连贯性、安全性和事实一致性等方面。
- en: '[TRUE](https://oreil.ly/UwZvJ)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[TRUE](https://oreil.ly/UwZvJ)'
- en: Uses other LLMs to assess factual correctness and identify potential factual
    hallucinations.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用其他LLM来评估事实正确性和识别潜在的事实幻觉。
- en: '[SelfCheckGPT](https://oreil.ly/8AKE9)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[SelfCheckGPT](https://oreil.ly/8AKE9)'
- en: Designed for GPT models, it focuses on identifying logical inconsistencies and
    factual errors in the generated text.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为GPT模型设计，它专注于识别生成文本中的逻辑不一致性和事实错误。
- en: These metrics are configurable to your specific use case. Although many provide
    example questions and expected answers in their papers, you should generate a
    question-and-answer database that is applicable to your use case.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标可以根据您的特定用例进行配置。尽管许多基准测试在其论文中提供了示例问题和预期答案，但您应该生成一个适用于您用例的问题和答案数据库。
- en: 'There are also many general benchmarks for LLMs that have the goal of evaluating
    how well an LLM performs as a general problem-solver, without focusing on a specific
    task. These benchmarks tend to be more useful if you’re building a platform-level
    LLM, like Google’s Gemini or OpenAI’s ChatGPT. Although such benchmark results
    are useful in some aspects and appear frequently in marketing materials that describe
    how good a model is, they suffer from an important drawback: they can’t tell how
    well a model will perform on a specific task. It’s possible that model A performs
    substantially better than model B in general tasks and therefore on a general
    benchmark like GLUE, but model B may perform better than model A in the tasks
    you need it to do; for example, analyzing legal documents. It is therefore important
    to understand these benchmarks for what they are: an aggregate score of general
    applicability.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 对于LLM，也有许多通用基准测试，其目标是评估LLM作为通用问题解决者的表现如何，而不专注于特定任务。这些基准测试如果您正在构建平台级LLM（如Google的Gemini或OpenAI的ChatGPT）时更有用。尽管这些基准测试在某些方面很有用，并且经常出现在描述模型如何好的营销材料中，但它们存在一个重要的缺点：它们无法告诉模型在特定任务上的表现如何。可能模型A在一般任务上比模型B表现好得多，因此在像GLUE这样的通用基准测试上，但模型B在您需要它完成的任务上可能比模型A表现更好；例如，分析法律文件。因此，了解这些基准测试是什么很重要：它们是一般适用性的综合评分。
- en: Some of the top benchmarks are listed in [Table 7-1](#ch07_table_1_1748896751659531),
    but keep in mind that this is an active area of research, with new benchmarks
    being proposed all the time.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一些顶级基准测试列表见[表7-1](#ch07_table_1_1748896751659531)，但请记住，这是一个活跃的研究领域，新的基准测试一直在被提出。
- en: Table 7-1\. General LLM benchmarks
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-1\. 通用LLM基准测试
- en: '| Benchmark | Description | Focus |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 基准测试 | 描述 | 重点关注 |'
- en: '| --- | --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| [General Language Understanding Evaluation](https://oreil.ly/rcLR4) (GLUE)
    | Suite of tasks assessing core NLP abilities | Natural language understanding
    (NLU) |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| [通用语言理解评估](https://oreil.ly/rcLR4) (GLUE) | 一系列评估核心NLP能力的任务 | 自然语言理解 (NLU)
    |'
- en: '| [SuperGLUE](https://oreil.ly/mpepc) | Successor to GLUE, featuring more challenging
    tasks | NLU |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| [SuperGLUE](https://oreil.ly/mpepc) | GLUE的后继者，具有更具挑战性的任务 | NLU |'
- en: '| [HellaSwag](https://oreil.ly/2VpX9) | Focuses on reasoning and commonsense
    understanding | Natural language inference (NLI) |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| [HellaSwag](https://oreil.ly/2VpX9) | 专注于推理和常识理解 | 自然语言推理 (NLI) |'
- en: '| [TruthfulQA](https://oreil.ly/adQ-N) | Evaluates factual correctness and
    avoidance of factual hallucinations | Question qnswering (QA) |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| [TruthfulQA](https://oreil.ly/adQ-N) | 评估事实正确性和避免事实幻觉 | 问题回答 (QA) |'
- en: '| [Massive Multitask Language Understanding](https://oreil.ly/0xT-x) (MMLU)
    | Large-scale benchmark on diverse tasks | Multi-task learning |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| [大规模多任务语言理解](https://oreil.ly/0xT-x) (MMLU) | 在各种任务上的大规模基准测试 | 多任务学习 |'
- en: These benchmarks are public, and so are their question-and-answer pairs. This
    allows different LLMs to be compared on the exact same criteria and therefore
    allows comparisons between LLMs.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基准测试是公开的，它们的问答对也是公开的。这使得不同的LLM可以在完全相同的标准下进行比较，因此允许LLM之间的比较。
- en: 'However, this creates a problem: LLM developers can train the model simply
    to perform well on the benchmarks, like a student memorizing the answers to an
    upcoming exam. This is a very serious problem in practice. It’s not uncommon to
    see an LLM perform well in general benchmarks, only to perform below the level
    of GPT-3.5 (a now-obsolete but inexpensive model) in a practical application,
    like describing a scene. When this happens, there’s usually little reason to use
    the model that has the higher general scores—your users should have the final
    word.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这会产生一个问题：LLM开发者可以简单地训练模型在基准测试中表现良好，就像学生为了即将到来的考试而记忆答案一样。这在实践中是一个非常严重的问题。在LLM在一般基准测试中表现良好，但在实际应用（如描述场景）中表现低于GPT-3.5（一个现在已过时但价格低廉的模型）的情况下并不少见。当这种情况发生时，通常没有理由使用具有更高一般分数的模型——最终决定权应该在用户手中。
- en: Another problem is that LLMs are highly sensitive to the compatibility of the
    data used in training and prompts used in evaluation. A seemingly minor change
    in the prompt can lead to drastically different outputs. This makes it difficult
    to design prompts that consistently elicit the desired response and assess the
    LLM’s true capabilities.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题在于，LLMs对训练中使用的数据和评估中使用的提示的兼容性非常敏感。提示中的看似微小的变化可能导致截然不同的输出。这使得设计能够持续引发所需响应并评估LLMs真实能力的提示变得困难。
- en: For example, some models may respond better when asked to “think step-by-step”
    ([Wei et al., 2023](https://oreil.ly/YIrYf)), while others might respond better
    when asked politely, with prompts starting with “please.” These are the results
    of training bias. In this example, if the portion of the training dataset that
    contained more polite instructions had a higher proportion of correct answers,
    simply adding “please” to all prompts will yield better results on benchmarks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一些模型在被要求“逐步思考”时可能响应得更好（[Wei等人，2023](https://oreil.ly/YIrYf)），而另一些模型在被礼貌地要求，提示以“请”开头时可能响应得更好。这些都是训练偏差的结果。在这个例子中，如果训练数据集中包含更多礼貌指令的部分有更高的正确答案比例，那么在所有提示中简单地添加“请”将能在基准测试中产生更好的结果。
- en: 'LLMs use another trick that students frequently use to improve their exam scores
    when they don’t know the answer to a question: they repeat or paraphrase parts
    of the question or prompt in their responses. This can create a false sense of
    understanding or agreement, making the text produced for the answer highly related
    to the question, even when the quality of the answer itself is low.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs使用了一种学生经常用来提高考试分数的技巧，即当他们不知道问题的答案时，会在回答中重复或改写问题的部分或提示。这可能会产生一种虚假的理解或同意感，使得生成的答案文本与问题高度相关，即使答案本身的质量很低。
- en: In summary, benchmarks can be useful to compare LLMs with other LLMs, but be
    aware of their limitations and use them with ​care.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，基准测试可以用来比较LLMs，但要注意它们的局限性，并谨慎使用。
- en: Some applications of LLM are so common that they deserve special attention,
    like RAG and multi-agent systems. Although the metrics described here can be used
    to evaluate RAG and multi-agent systems, each of them has its own specific metrics,
    described in the next sections.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的一些应用非常普遍，值得特别关注，如RAG和多智能体系统。尽管这里描述的指标可以用来评估RAG和多智能体系统，但每个系统都有其特定的指标，将在下一节中描述。
- en: Evaluating What Breaks Before It Breaks Everything
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估在一切崩溃之前会崩溃什么
- en: When LLMs first entered production environments, their early failures appeared
    sporadic and unpredictable. These initial glitches were often dismissed as the
    model simply “acting weird,” a kind of random quirkiness rather than a systemic
    issue. However, as usage expanded and data accumulated, clearer, more consistent
    patterns of failure began to surface. These patterns are not traditional software
    bugs, like segmentation faults or crashes, but rather what we call failure modes
    (see [Table 7-2](#table0702)).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当大型语言模型（LLMs）首次进入生产环境时，它们早期的失败显得零散且不可预测。这些初始故障通常被忽视，被认为是模型“行为古怪”，是一种随机的不寻常行为，而不是系统性问题。然而，随着使用范围的扩大和数据积累，开始出现更清晰、更一致的失败模式。这些模式不是传统的软件错误，如段错误或崩溃，而是我们所说的故障模式（见[表7-2](#table0702)）。
- en: Table 7-2\. Common LLM failure modes and where evaluation can catch them
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-2\. 常见LLM故障模式和评估可以捕捉到它们的位置
- en: '| Failure mode | Where to evaluate | Tools/signals |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 故障模式 | 评估位置 | 工具/信号 |'
- en: '| --- | --- | --- |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Hallucinations | Retrieval, prompt, inference | Similarity to source, factual
    checks |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 幻觉 | 检索、提示、推理 | 与源相似度、事实核查 |'
- en: '| Prompt regressions | Orchestration | Prompt diffing, quality degradation
    logs |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 提示回归 | 协调 | 提示差异，质量退化日志 |'
- en: '| Latency spikes | Inference, retrieval | p95/p99 latency metrics, tracing
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 延迟峰值 | 推理、检索 | p95/p99延迟指标、跟踪 |'
- en: '| Data drift | Input, retrieval | Embedding shifts, cluster distribution |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 数据漂移 | 输入、检索 | 嵌入式偏移、聚类分布 |'
- en: '| Inconsistent behavior | Inference | Session-level tracing, repeat queries
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 行为不一致 | 推理 | 会话级跟踪、重复查询 |'
- en: '| Safety violations | Output | Toxicity filters, PII detection |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 安全违规 | 输出 | 毒性过滤器、PII检测 |'
- en: '*Failure modes* represent recurring but explainable breakdowns that arise due
    to a fundamental mismatch between the model’s internal assumptions and the complex
    realities of real-world data and interactions. Unlike conventional software errors
    that trigger exceptions or cause program crashes, failure modes are often “silent
    failures”. The system continues to operate normally on the surface, producing
    outputs that look syntactically valid and stylistically coherent. Yet beneath
    this veneer, these outputs can be factually incorrect, ethically problematic,
    or structurally flawed. This subtlety makes failure modes particularly insidious,
    as they evade detection by traditional debugging methods, which typically rely
    on outright crashes or obvious error signals.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*故障模式*代表由于模型内部假设与真实世界数据和交互的复杂现实之间的基本不匹配而出现的反复但可解释的故障。与传统软件错误不同，传统软件错误会触发异常或导致程序崩溃，故障模式通常是“无声的故障”。表面上，系统继续正常运行，产生看似语法有效和风格一致的输出。然而，在这层表象之下，这些输出可能是事实错误、道德问题或结构上的缺陷。这种微妙性使得故障模式特别狡猾，因为它们可以通过传统的调试方法逃避检测，这些方法通常依赖于彻底的崩溃或明显的错误信号。'
- en: Therefore, the evaluation paradigm for LLMs must evolve beyond reactive debugging
    toward a more proactive approach (see [Figure 7-1](#fig0701)). Instead of waiting
    for failures to disrupt users, the goal becomes to anticipate and detect these
    failure modes early, before they propagate harm or misinformation. This proactive
    detection requires sophisticated monitoring frameworks that combine automated
    metrics, human-in-the-loop validation, and domain-specific checks to identify
    when the model’s assumptions no longer hold, or when outputs deviate from expected
    behavior. By shifting evaluation from post-hoc fixes to continuous, anticipatory
    oversight, we can better ensure the reliability, safety, and ethical integrity
    of LLM deployments at scale.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，LLMs的评估范式必须从反应式调试发展到更主动的方法（见图7-1）。而不是等待故障破坏用户，目标变为预测并早期检测这些故障模式，在它们传播危害或错误信息之前。这种主动检测需要复杂的监控框架，结合自动化指标、人工验证和领域特定检查，以确定模型假设何时不再成立，或输出何时偏离预期行为。通过将评估从事后修复转移到持续、前瞻性的监督，我们可以更好地确保大规模LLM部署的可靠性、安全性和道德完整性。
- en: '![](assets/llmo_0701.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/llmo_0701.png)'
- en: Figure 7-1\. Evaluating traditional ML models versus LLMs
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1. 评估传统ML模型与LLMs
- en: Let us try to understand the most common failure modes in modern LLM pipelines
    and identify where observability and evaluation tools can intercept them early.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试了解现代LLM管道中最常见的故障模式，并确定可观察性和评估工具可以早期拦截它们的位置。
- en: Hallucinations
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 幻觉
- en: Among the various failure modes LLMs exhibit, hallucinations stand out as the
    most infamous and challenging to manage. Hallucinations happen when an LLM produces
    responses that are linguistically fluent and confident, yet factually incorrect
    or completely fabricated. This phenomenon arises because LLMs generate text by
    predicting the most statistically likely token sequences based on their training
    data, rather than querying a reliable, up-to-date factual knowledge base. Therefore,
    hallucinations are an inherent risk, especially when LLMs are applied in high-stakes
    domains such as healthcare, finance, or legal services, where inaccurate or misleading
    information can lead to serious consequences.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMs展现的各种故障模式中，幻觉（hallucinations）因其最臭名昭著且难以管理而突出。当LLMs产生看似语言流畅且自信的响应，但实际上却是事实错误或完全虚构时，就会发生幻觉。这种现象的出现是因为LLMs通过根据其训练数据预测最可能出现的标记序列来生成文本，而不是查询可靠、最新的事实知识库。因此，幻觉是一种固有的风险，尤其是在LLMs应用于高风险领域，如医疗保健、金融或法律服务时，不准确或误导性信息可能导致严重后果。
- en: Evaluating hallucinations extends beyond simply detecting isolated factual errors.
    Instead, it demands a systematic, longitudinal approach to pattern monitoring.
    This typically involves logging all generated outputs and, where possible, comparing
    them to verified ground truths. When exact ground-truth data isn’t accessible,
    one alternative strategy is conducting consistency checks across multiple generations
    of the model’s responses to detect contradictions or instability. These evaluation
    methods help identify individual hallucinations as well as the conditions and
    contexts in which they occur more frequently.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 评估幻觉不仅限于简单地检测孤立的事实错误。相反，它要求采用系统性的、纵向的图案监控方法。这通常涉及记录所有生成的输出，并在可能的情况下，将它们与验证过的真实情况进行比较。当无法获取精确的真实数据时，一种替代策略是在模型的多个响应代际之间进行一致性检查，以检测矛盾或不稳定性。这些评估方法有助于识别个别幻觉以及它们更频繁发生的条件和情境。
- en: In RAG systems, hallucinations often signal problems in the retrieval component.
    For instance, if the retriever fetches irrelevant, outdated, or low-quality documents,
    the LLM is more likely to generate incorrect or fabricated content. This interdependence
    makes it important to maintain observability across both the retrieval and inference
    layers. Comprehensive monitoring frameworks that track the quality and relevance
    of retrieved documents alongside the model’s output can help diagnose whether
    hallucinations are stemming from retrieval failures, generative errors, or a combination
    of both. Understanding these root causes is essential for designing targeted mitigation
    strategies, such as improving retrieval accuracy, integrating more reliable knowledge
    sources, or incorporating verification mechanisms during generation.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在RAG系统中，幻觉通常表明检索组件存在问题。例如，如果检索器检索到无关、过时或低质量的文档，LLM生成错误或虚构内容的机会就更大。这种相互依赖性使得在检索和推理层之间保持可观察性变得很重要。跟踪检索文档的质量和相关性以及模型输出的综合监控框架可以帮助诊断幻觉是否源于检索失败、生成错误或两者的结合。理解这些根本原因对于设计针对性的缓解策略至关重要，例如提高检索准确性、整合更可靠的知识来源或在生成过程中引入验证机制。
- en: Prompt regressions
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示回归
- en: '*Prompt regression* represents a particularly subtle yet deeply frustrating
    failure mode in LLM deployments. Unlike obvious output errors, prompt regressions
    arise from seemingly minor changes to the prompt templates, such as renaming variables,
    inserting or removing whitespace, or adjusting formatting, that unexpectedly degrade
    the quality of the model’s outputs. These degradations are often not immediately
    apparent, making them harder to detect and diagnose in real time.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示回归*代表了在LLM部署中一种特别微妙但深感受挫的失败模式。与明显的输出错误不同，提示回归源于对提示模板的看似微小的更改，例如重命名变量、插入或删除空白或调整格式，这些更改意外地降低了模型输出的质量。这些退化通常不是立即显而易见的，这使得它们在实时中更难检测和诊断。'
- en: 'The challenge is compounded by the inherent nondeterminism of LLMs: given the
    same input, the model may generate different outputs across runs, due to sampling
    methods and stochastic token prediction. This variability makes it difficult to
    reproduce prompt regressions consistently, posing a significant barrier to traditional
    debugging approaches.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这个挑战因LLM固有的非确定性而加剧：由于采样方法和随机标记预测，在相同的输入下，模型可能在不同的运行中生成不同的输出。这种可变性使得一致地重现提示回归变得困难，对传统的调试方法构成了重大障碍。
- en: To manage this complexity, robust evaluation systems must integrate detailed
    prompt versioning and logging capabilities. Tracking changes at a granular level
    is essential, as is supporting prompt diffs that highlight exactly what was modified
    between versions. By correlating these prompt changes with measurable metrics,
    such as declines in response helpfulness, factual accuracy, or structural coherence,
    teams can precisely pinpoint when and how regressions begin to manifest.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了管理这种复杂性，稳健的评估系统必须整合详细的提示版本控制和日志记录功能。在细粒度级别跟踪变化是必要的，同样重要的是支持提示差异，突出显示版本之间确切修改的内容。通过将这些提示更改与可衡量的指标相关联，例如响应有用性、事实准确性或结构连贯性的下降，团队可以精确地确定回归何时以及如何开始显现。
- en: This systematic correlation enables effective root-cause analysis, allowing
    developers to identify the problematic prompt iterations swiftly. More importantly,
    it empowers teams to roll back to previously stable prompt versions when they
    detect regressions, preserving output quality and user trust. In this way, prompt-regression
    monitoring becomes part of a proactive evaluation strategy to ensure that subtle
    prompt-engineering tweaks don’t unintentionally erode model performance or reliability
    over time.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这种系统性的相关性使得有效的根本原因分析成为可能，允许开发者迅速识别有问题的提示迭代。更重要的是，它使团队能够在检测到退化时回滚到之前稳定的提示版本，从而保持输出质量和用户信任。因此，提示退化监控成为主动评估策略的一部分，以确保细微的提示工程调整不会无意中随着时间的推移侵蚀模型性能或可靠性。
- en: Latency spikes
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 延迟峰值
- en: Regardless of a system’s intelligence or sophistication, users uniformly reject
    slow and unresponsive experiences. Latency, especially spikes occurring at the
    high end of the distribution, such as the 95th (p95) or 99th percentiles (p99)
    is particularly damaging. These tail latencies, though rare in frequency, disproportionately
    impact user experience by causing noticeable delays and, in some cases, triggering
    downstream timeouts or failures in interconnected systems.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 无论系统的智能或复杂程度如何，用户都会一致地拒绝缓慢和无响应的体验。延迟，尤其是在分布的高端出现的峰值，如第95百分位数（p95）或第99百分位数（p99），尤其具有破坏性。这些尾部延迟虽然频率较低，但会不成比例地影响用户体验，造成明显的延迟，在某些情况下，还会触发下游系统的超时或故障。
- en: Effective evaluation of latency requires continuous, fine-grained monitoring
    that tracks not only average response times but also token usage patterns and
    relevant system-level metrics. This comprehensive observability is important for
    detecting abrupt increases in latency early, before they degrade service quality
    at scale.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对延迟的有效评估需要持续的、细粒度的监控，不仅要跟踪平均响应时间，还要跟踪令牌使用模式和相关的系统级指标。这种全面的可观察性对于在它们大规模降低服务质量之前及早发现延迟的突然增加至关重要。
- en: When such latency spikes occur, robust tracing mechanisms become indispensable
    for root cause analysis. These tools enable engineers to dissect the request pipeline
    and identify bottlenecks or failure points. Potential culprits may include excessively
    long input prompts that increase processing time, delays within retrieval components
    responsible for fetching relevant documents, or bottlenecks in upstream dependencies,
    such as vector databases or external APIs. Additionally, changes to the underlying
    model version or system infrastructure can introduce unexpected latency regressions.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当这种延迟峰值发生时，强大的跟踪机制对于根本原因分析变得不可或缺。这些工具使工程师能够剖析请求管道并识别瓶颈或故障点。可能的罪魁祸首可能包括过长的输入提示，这会增加处理时间，负责检索相关文档的检索组件中的延迟，或者上游依赖（如向量数据库或外部API）中的瓶颈。此外，底层模型版本或系统基础设施的更改可能会引入意外的延迟退化。
- en: Without this level of observability, latency spikes remain invisible to monitoring
    dashboards and alerting systems until end users experience degraded performance
    or failures. Therefore, embedding end-to-end tracing and real-time latency monitoring
    into the evaluation workflow is essential for maintaining smooth, predictable
    system behavior and ensuring a consistently responsive user experience.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 没有这种级别的可观察性，延迟峰值对监控仪表板和警报系统来说是不可见的，直到最终用户体验到性能下降或故障。因此，将端到端跟踪和实时延迟监控嵌入到评估流程中对于保持平稳、可预测的系统行为和确保一致响应的用户体验至关重要。
- en: Data drift
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据漂移
- en: In live production environments, user behavior and input data are in a state
    of continuous flux. This dynamic landscape often leads to data drift, a phenomenon
    where the foundational assumptions embedded in a system–such as expected input
    formats, distributions of user intents, or the nature of contextual embeddings–gradually
    diverge from the evolving reality of incoming data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在实时生产环境中，用户行为和输入数据处于持续变化的状态。这种动态环境常常导致数据漂移，这是一种现象，其中系统内嵌入的基本假设（如预期的输入格式、用户意图的分布或上下文嵌入的性质）逐渐与不断变化的数据现实相偏离。
- en: Data drift manifests in several distinct ways. Input drift typically shows up
    as an increase in adversarial or malformed queries that deviate from the original
    training or design expectations. This can stress the system’s robustness and degrade
    output quality. Retriever drift occurs when the relevance of the documents returned
    by retrieval components declines, even if the retrieval algorithms and configurations
    remain unchanged. Similarly, embedding drift arises when the vector representations
    used to compare semantic similarity become less effective, causing retrieval systems
    to fail despite stable system parameters.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 数据漂移以几种不同的方式表现出来。输入漂移通常表现为对抗性或格式错误的查询增加，这些查询偏离了原始的训练或设计预期。这可能会对系统的鲁棒性造成压力，并降低输出质量。检索器漂移发生在检索组件返回的文档的相关性下降时，即使检索算法和配置保持不变。同样，当用于比较语义相似性的向量表示变得不那么有效时，就会发生嵌入漂移，导致检索系统即使系统参数稳定也会失败。
- en: Effectively evaluating drift demands rigorous statistical monitoring of input
    feature distributions over time. Techniques include cluster analyses of query
    types to detect emerging user intents or new patterns of interaction, histograms
    of token lengths to track shifts in input verbosity, and continuous measurement
    of embedding similarity scores to catch subtle shifts in semantic representation.
    These quantitative early-warning signals allow engineering teams to anticipate
    when the system’s assumptions will no longer hold.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 有效评估漂移需要对输入特征分布进行严格的统计监控。技术包括对查询类型进行聚类分析以检测新兴的用户意图或新的交互模式，对标记长度进行直方图分析以跟踪输入冗余度的变化，以及持续测量嵌入相似度分数以捕捉语义表示的微妙变化。这些定量的早期预警信号允许工程团队预测系统假设何时将不再成立。
- en: By proactively detecting drift, teams gain the opportunity to retrain models,
    refresh retrieval indexes, and redesign prompt templates before any degradation
    becomes noticeable to end users. This anticipatory approach ensures that the system
    adapts seamlessly to evolving data landscapes, maintaining both accuracy and user
    satisfaction over time.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 通过主动检测漂移，团队有机会在任何退化对最终用户变得明显之前重新训练模型、刷新检索索引和重新设计提示模板。这种前瞻性方法确保系统能够无缝适应不断变化的数据景观，在一段时间内保持准确性和用户满意度。
- en: Inconsistent behavior
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不一致的行为
- en: The inherently stochastic nature of LLM generation means that repeating the
    exact same query multiple times can yield different responses on each occasion,
    a phenomenon called nondeterminism. This variability is a natural consequence
    of probabilistic token sampling strategies, which promote diversity and creativity
    in generated text. However, this randomness presents a fundamental challenge for
    use cases where auditability, compliance, and reproducibility are critical. In
    such contexts, inconsistent outputs can undermine trust, complicate debugging,
    and even violate regulatory requirements.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: LLM生成的本质上是随机的，这意味着重复相同的查询多次可能会在每次都产生不同的响应，这种现象称为非确定性。这种可变性是概率性标记采样策略的自然结果，这些策略促进了生成文本的多样性和创造性。然而，这种随机性为那些审计性、合规性和可重复性至关重要的用例带来了根本性的挑战。在这种情况下，不一致的输出可能会损害信任，使调试复杂化，甚至违反监管要求。
- en: Evaluating and managing inconsistent behavior requires a session-level tracing
    framework that goes beyond simply logging inputs and outputs. It must capture
    rich contextual metadata alongside each interaction, including model hyperparameters
    like temperature and top-k sampling values, specific model versions, and any relevant
    prior conversation history or user interactions. This comprehensive trace allows
    teams to reconstruct and analyze the exact environment and conditions that produced
    a given output.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 评估和管理不一致的行为需要一个会话级跟踪框架，而不仅仅是简单地记录输入和输出。它必须捕获每个交互的丰富上下文元数据，包括模型超参数（如温度和top-k采样值）、特定模型版本以及任何相关的先前对话历史或用户交互。这种全面的跟踪允许团队重建和分析产生特定输出的确切环境和条件。
- en: With detailed session-level logs (see [Figure 7-2](#fig0702)), it becomes possible
    to identify patterns of variability, correlate output inconsistencies with particular
    settings or context changes, and enforce reproducibility where necessary by fixing
    sampling parameters or replaying interaction sequences. This granular level of
    evaluation is essential for deploying LLMs responsibly in sensitive domains where
    predictable, verifiable behavior is nonnegotiable.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 通过详细的会话级日志（见[图7-2](#fig0702)），可以识别变化模式，将输出不一致性与特定的设置或上下文变化相关联，并在必要时通过修复采样参数或重新播放交互序列来强制执行可重复性。这种细粒度的评估对于在需要可预测、可验证行为的敏感领域负责任地部署LLM至关重要。
- en: '![](assets/llmo_0702.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/llmo_0702.png)'
- en: Figure 7-2\. Logging styles vary in scope, from isolated events to full sessions
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-2\. 记录风格的范围各不相同，从孤立事件到完整会话
- en: Consistency can be enforced selectively, using deterministic decoding strategies
    like greedy or beam search, although this typically sacrifices output diversity.
    The key is balancing consistency where required and building monitoring systems
    that highlight inconsistency when it matters.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 可以选择性地强制执行一致性，使用如贪婪或束搜索等确定性解码策略，尽管这通常会牺牲输出多样性。关键是平衡所需的一致性，并建立当需要时突出不一致性的监控系统。
- en: Ethical and compliance risks
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 道德和合规风险
- en: LLMs can inadvertently produce toxic content or biased language, leak private
    information, or be vulnerable to jailbreak prompts. These risks carry serious
    legal and reputational consequences. To mitigate them, evaluation tools must integrate
    automated filters and classifiers that flag problematic outputs in real time,
    as we discussed earlier in the chapter. Metrics such as safety scores, toxicity
    indices, and bias measurements should be collected alongside model metadata for
    auditing purposes.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: LLM可能会无意中产生有毒内容或带有偏见的语言，泄露私人信息，或容易受到越狱提示的影响。这些风险会带来严重的法律和声誉后果。为了减轻这些风险，评估工具必须集成自动过滤器分类器，实时标记问题输出，正如我们在本章前面讨论的那样。应收集如安全分数、毒性指数和偏见测量等指标，以供审计之用。
- en: Metrics for RAG Applications
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG应用程序的指标
- en: A RAG application uses an LLM to generate text, but it helps the LLM be more
    precise by retrieving data from a knowledge base and appending that data to the
    user prompt. RAG applications go through the steps shown in [Figure 7-3](#ch07_figure_1_1748896751654685).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: RAG应用程序使用LLM生成文本，但它通过从知识库检索数据并将这些数据附加到用户提示中，帮助LLM更加精确。RAG应用程序经过[图7-3](#ch07_figure_1_1748896751654685)中显示的步骤。
- en: '![](assets/llmo_0703.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/llmo_0703.png)'
- en: Figure 7-3\. RAG application workflow
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-3\. RAG应用程序工作流程
- en: 'Let’s look at each step in more detail:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看每个步骤：
- en: User input
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 用户输入
- en: The user submits a question or prompt to the RAG application.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 用户向RAG应用程序提交问题或提示。
- en: Retrieval
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 检索
- en: The application utilizes a retrieval system to search a database of relevant
    documents or text data, such as *n* articles, manuals, code snippets, or any other
    information relevant to the LLM’s domain. The retrieval system identifies the
    most relevant portions of the data based on the user’s query, using techniques
    like vector similarity search.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序利用检索系统搜索相关文档或文本数据的数据库，例如*n*篇文章、手册、代码片段或任何与LLM领域相关的其他信息。检索系统根据用户的查询，使用向量相似度搜索等技术，识别数据中最相关的部分。
- en: Prompt augmentation
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 提示增强
- en: The application concatenates a developer-crafted prompt with the retrieved text
    from the previous step and the original user input.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序将开发者定制的提示与上一步检索到的文本和原始用户输入连接起来。
- en: LLM generation
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: LLM生成
- en: The augmented prompt is then sent to the LLM, which uses the additional context
    it provides to generate a response and present it to the user.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 增强的提示随后被发送到LLM，LLM使用它提供的额外上下文生成响应并将其呈现给用户。
- en: 'In addition to the generation metrics described in the previous section, RAGs
    can benefit from retrieval metrics that assess the effectiveness of the retrieval
    component. Some key retrieval metrics include:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上一节中描述的生成指标外，RAG还可以从检索指标中受益，这些指标评估检索组件的有效性。一些关键检索指标包括：
- en: Recall
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆
- en: This measures how thoroughly the system gathers the material that really matters.
    To compute it, you start with a “ground-truth” collection of documents that experts
    have already judged relevant to a query. When the retrieval step runs, you look
    at the overlap between this authoritative set and the documents the system produced.
    If the engine surfaces almost every item the experts identified, recall is considered
    high; if it misses many of them, recall is low. You can measure the result as
    a percentage.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这衡量了系统收集真正重要材料的彻底程度。为了计算它，你从一个“真实”文档集合开始，这个集合已经被专家判断为与查询相关。当检索步骤运行时，你查看这个权威集合与系统生成的文档之间的重叠。如果引擎几乎显示了专家识别的每个项目，则认为召回率很高；如果它遗漏了许多项目，召回率就低。你可以将结果测量为百分比。
- en: Mean reciprocal rank (MRR)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 均值倒数排名（MRR）
- en: This measures how quickly a user sees the first genuinely useful result. For
    each query, scan the ranked list from the top until you encounter the first relevant
    document and note its position. A document in the first slot is ideal, one in
    the fifth slot is less impressive, and so on. You then convert those positions
    into scores that reward early appearance and average the scores across many queries.
    A high MRR means that users usually encounter something relevant right at or near
    the top of the page. Although you can use whatever scoring mechanism you want,
    a typical way to score a search that retrieves *n* documents is to assign *n*
    points if a correct answer comes in the first position, *n* – 1 if it comes in
    the second position, and so on.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这衡量了用户看到第一个真正有用结果的速度。对于每个查询，从顶部开始扫描排名列表，直到你遇到第一个相关文档，并记录其位置。第一个位置上的文档是理想的，第五个位置上的文档则不那么令人印象深刻，依此类推。然后，将这些位置转换为奖励早期出现的分数，并在许多查询中平均这些分数。高MRR意味着用户通常在页面顶部或附近立即遇到相关内容。尽管你可以使用任何你想要的评分机制，但检索*n*个文档的典型评分方式是，如果正确答案出现在第一个位置，则分配*n*分，如果出现在第二个位置，则分配*n*
    - 1分，依此类推。
- en: Mean average precision (MAP)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 均值平均精度（MAP）
- en: This evaluates both the placement and consistency of relevant items throughout
    the list. Working down through the results for a single query, you keep a running
    tally so that every time another relevant document appears, you check what fraction
    of everything seen so far is relevant. When you finish the list, you average those
    interim fractions to summarize that one query. For example, if your retrieval
    step is expected to return three results and the three results returned are relevant,
    the average precision is 100%. If the first and second results are relevant, the
    AP is (100% + 100% + 0%) / 3 = 67%. If the first and third results are relevant,
    the AP is (100% + 0% + 67%) / 3 = 56%. Repeating the process for many queries
    and averaging again yields MAP. For example, the MAP of the last two queries is
    (67%+ 56%) / 2 = 61%. A high value indicates that relevant documents show up frequently
    and are distributed toward the top of the result rather than being scattered sparsely
    or bunched near the bottom.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这评估了相关项在整个列表中的位置和一致性。在单个查询的结果中向下工作，你保持一个累计计数，以便每次出现另一个相关文档时，你检查到目前为止看到的所有内容中有多少是相关的。当你完成列表时，你平均这些中间分数来总结一个查询。例如，如果你的检索步骤预期返回三个结果，并且返回的三个结果都是相关的，则平均精度为100%。如果前两个结果是相关的，则AP为（100%
    + 100% + 0%）/ 3 = 67%。如果第一个和第三个结果是相关的，则AP为（100% + 0% + 67%）/ 3 = 56%。对许多查询重复此过程并再次平均，得到MAP。例如，最后两个查询的MAP为（67%
    + 56%）/ 2 = 61%。高值表示相关文档频繁出现，并且分布在整个结果列表的顶部，而不是分散或集中在底部。
- en: Context precision
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文精确度
- en: This metric looks at the flip side of recall; i.e., given everything the retriever
    returned, how much of it is genuinely helpful? You inspect each passage to decide
    whether it supports the language model’s task or merely adds noise. When the bulk
    of retrieved results match the ground-truth collection of documents, context precision
    is high; when irrelevant or misleading passages dominate, the score drops. You
    can measure context precision as a percentage.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指标关注的是召回率的另一面；即，检索器返回的所有内容中，有多少是真正有用的？你需要检查每一段内容，以判断它是否支持语言模型的任务，或者仅仅是增加了噪音。当大部分检索到的结果与真实文档集合相匹配时，上下文精确度就很高；当无关或误导性的段落占主导地位时，分数会下降。你可以将上下文精确度测量为百分比。
- en: Relevance
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性
- en: This approach provides a balance between precision and recall. It considers
    both how completely the retrieved set covers the needed facts and how free it
    is of extraneous material. High relevance means the context supplied to the language
    model simultaneously contains nearly all critical information and avoids clutter,
    thereby giving the model an ideal foundation for an accurate, focused response.
    Although you can calculate relevance by taking the simple average (or even the
    sum) of precision and recall, practitioners typically take the harmonic mean of
    precision and recall (this is called the F1-score), which makes balanced results
    like 60% precision and 60% recall score higher than unbalanced results like 90%
    precision and 30% recall.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法在精确度和召回率之间取得了平衡。它考虑了检索到的集合如何完全覆盖所需的事实，以及它有多少非相关材料。高相关性意味着提供给语言模型的上下文同时包含了几乎所有关键信息，避免了杂乱，从而为模型提供了一个准确、专注的响应的理想基础。虽然你可以通过简单平均（甚至总和）精确度和召回率来计算相关性，但从业者通常采用精确度和召回率的调和平均（这被称为F1分数），这使得平衡的结果，如60%的精确度和60%的召回率，比不平衡的结果，如90%的精确度和30%的召回率，得分更高。
- en: While you can measure each of these metrics on your own, in practice you’re
    likely to use an evaluation tool. Most evaluation tools can measure both the retrieval
    metrics just described and the generation metrics described in the previous section.
    For simple applications, you can use an [existing framework](https://oreil.ly/QUyLl)
    like [Ragas](https://oreil.ly/JkFwY) that provides prebuilt functionality and
    streamlined workflow. Ragas is a Python-based application that contains all the
    previous metrics and can measure the outputs of your application and summarize
    the results in a single score. Ragas is also designed to be user-friendly, with
    clear documentation and examples. This makes it easier for researchers and developers,
    even those without extensive coding experience, to evaluate their RAG systems.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可以自己测量这些指标中的每一个，但在实践中你很可能会使用一个评估工具。大多数评估工具都可以测量前面描述的检索指标和上一节中描述的生成指标。对于简单应用，你可以使用一个现有的框架，如[现有框架](https://oreil.ly/QUyLl)
    [Ragas](https://oreil.ly/JkFwY)，它提供了预构建的功能和简化的工作流程。Ragas是一个基于Python的应用程序，包含所有之前的指标，可以测量你应用程序的输出，并在单个分数中总结结果。Ragas还设计得易于使用，具有清晰的文档和示例。这使得研究人员和开发者，即使是没有丰富编码经验的人，也能更容易地评估他们的RAG系统。
- en: For most production applications, you will need a customizable evaluator that
    allows you to define your own metrics, add your own datasets, and integrate tests
    with your CI/CD tools; for example, by automatically running a set of tests after
    a new model version is deployed. One popular open source tool to perform these
    tasks is the [LangSmith](https://oreil.ly/F8EVF) toolset, created by the makers
    of LangChain.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数生产应用，你需要一个可定制的评估器，允许你定义自己的指标，添加自己的数据集，并将测试与你的CI/CD工具集成；例如，在部署新的模型版本后自动运行一系列测试。一个流行的开源工具是LangChain制作者创建的[LangSmith](https://oreil.ly/F8EVF)工具集，用于执行这些任务。
- en: To perform evaluations in LangSmith, you first define a dataset of test cases
    and one or more evaluators. For each evaluator, you can define a metric (such
    as the metrics in this chapter) or a rubric that explains, in English, how to
    score answers. You can use the LangSmith programming interface to connect the
    output of your LLM to the evaluator and automatically score it.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 要在LangSmith中执行评估，你首先定义一组测试用例和一个或多个评估器。对于每个评估器，你可以定义一个指标（例如本章中提到的指标）或一个说明如何评分的评分标准。你可以使用LangSmith编程接口将你的LLM的输出连接到评估器，并自动评分。
- en: Because LangSmith offers an SDK, you can run the tests during development, but
    you can also run the tests whenever you deploy a new model. You do this by creating
    a script that sends prompts to the new model and uses LangSmith to evaluate the
    answers as soon as the model is deployed by your CI/CD tool.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LangSmith提供了一个SDK，你可以在开发期间运行测试，但也可以在部署新模型时运行测试。你这样做是通过创建一个脚本来向新模型发送提示，并使用LangSmith在CI/CD工具部署模型后立即评估答案。
- en: You can also use the SDK to create a script that periodically runs a test in
    production using a fixed dataset to see whether a model is *drifting*; that is,
    whether the model’s performance is changing over time. In general, you would expect
    that running the same test over the same dataset would have the same score, but
    if you’re using an LLM service like OpenAI’s GPT API or Google’s Gemini API, the
    underlying model can change outside of your control. This is called *model drift*
    and is explained in more detail at the end of this chapter. In any case, running
    a periodic test as described here will let you detect model drift.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用SDK创建一个脚本，该脚本定期在生产环境中使用固定数据集运行测试，以查看模型是否*漂移*；也就是说，模型的表现是否随时间变化。一般来说，您会期望在相同的数据集上运行相同的测试会得到相同的分数，但如果你使用的是像OpenAI的GPT
    API或Google的Gemini API这样的LLM服务，底层的模型可能会在你的控制之外发生变化。这被称为*模型漂移*，将在本章末尾进行更详细的解释。无论如何，按照这里描述的定期运行测试将让你能够检测到模型漂移。
- en: Metrics for Agentic Systems
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理系统指标
- en: In late 2024, the term *agentic system* started to become more popular. In the
    context of LLMs, an agentic system is an AI system with several internal modules
    and multiple steps that can autonomously plan, decide, and act to pursue high-level
    goals with only strategic human oversight. In an agentic system, the user sends
    a request to a coordinating LLM that breaks the requests into tasks. The coordinating
    LLM then sends each task to itself, to other LLMs, or to specialist programs.
    It compiles their responses and provides the compilation to the user. This multistep
    process generates a myriad of evaluation issues.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 到2024年底，术语“代理系统”开始变得更加流行。在LLM的背景下，代理系统是一个具有多个内部模块和多个步骤的AI系统，它可以自主地规划、决策和行动，以仅通过战略性的人类监督来实现高级目标。在代理系统中，用户向协调LLM发送请求，该LLM将请求分解为任务。协调LLM然后将每个任务发送给自己、其他LLM或专业程序。它编译他们的响应，并将编译后的结果提供给用户。这个多步骤过程产生了大量的评估问题。
- en: 'All the metrics defined earlier in this chapter still apply; thus, if one of
    the components of the agentic system is a RAG system, you can use the RAG metrics,
    and for content-generating LLMs, you can use the generative metrics defined toward
    the beginning of this chapter. There are, however, additional complexities:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本章前面定义的所有指标仍然适用；因此，如果代理系统的某个组件是RAG系统，则可以使用RAG指标，对于内容生成型LLM，可以使用本章开头定义的生成型指标。然而，还存在一些额外的复杂性：
- en: Dynamic behavior
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 动态行为
- en: Agents can exhibit emergent behaviors based on their interactions, making it
    hard to predict outcomes or when these behaviors will occur.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 代理可能会根据其交互表现出涌现行为，这使得预测结果或这些行为何时发生变得困难。
- en: Context sensitivity
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 环境敏感性
- en: The performance of agents can vary significantly based on context, requiring
    extensive testing across different scenarios.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 代理的性能可能会根据环境显著变化，需要在不同场景中进行广泛的测试。
- en: Continuous learning
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 持续学习
- en: Many LLMs and agents adapt over time based on interactions, making static evaluations
    less relevant.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 许多LLM和代理会根据交互随着时间的推移进行适应，使得静态评估变得不那么相关。
- en: Feedback loops
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈回路
- en: The presence of feedback loops between agents can create nonlinear effects that
    are hard to replicate.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 代理之间存在的反馈回路可能会产生难以复制的非线性效应。
- en: Integration with existing systems
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 与现有系统的集成
- en: Deploying agents in real-world environments can reveal unforeseen issues that
    aren’t present in simulated settings.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界环境中部署代理可能会揭示在模拟设置中不存在的问题。
- en: Environmental variability
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 环境可变性
- en: Changes in the operational environment can lead to unexpected behaviors, complicating
    the evaluation process.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 运营环境的变化可能导致意外的行为，从而复杂化评估过程。
- en: Multiple goals
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 多个目标
- en: Agents may have conflicting objectives or collaborate in ways that require balancing
    multiple criteria, complicating evaluation metrics. Sometimes two agents have
    poor metrics individually but collaborate well and generate output that is better
    than would be produced by collaboration between two different agents with better
    individual metrics.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 代理可能会有冲突的目标或以需要平衡多个标准的方式进行协作，从而复杂化评估指标。有时两个代理的指标单独来看可能不好，但协作得很好，生成的输出比两个具有更好单独指标的代理之间的协作产生的输出要好。
- en: In practice, it’s easier to evaluate the end product of the agentic collaboration.
    Therefore, the two main ways of evaluating agentic systems are human evaluators
    and LLM evaluators. While human evaluation is considered the gold standard, it
    can be expensive and time-consuming. On the other hand, using LLMs as evaluators
    often strikes a good balance among cost, quality, and effectiveness, but it can
    occasionally be biased. Two other problems are that LLMs are opaque and resource
    intensive. If you use an LLM evaluator, don’t be completely hands-off. An LLM
    evaluating a model can start to perform poorly, so it’s advisable to have some
    level of human double-checking. Additionally, there is no universally accepted
    set of metrics for evaluating agentic systems, leading to inconsistencies.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，评估代理协作的最终产品更容易。因此，评估代理系统的两种主要方式是人类评估者和LLM评估者。虽然人类评估被认为是黄金标准，但它可能很昂贵且耗时。另一方面，使用LLM作为评估者通常在成本、质量和有效性之间取得良好的平衡，但偶尔可能会存在偏见。其他两个问题是LLM是透明的且资源密集型。如果你使用LLM评估者，不要完全放手。一个评估模型的LLM可能会开始表现不佳，因此建议进行一定水平的人类双重检查。此外，没有一套普遍接受的评估代理系统的指标，导致不一致性。
- en: Also, resource constraints (on computational power and memory, for example)
    limit how much evaluation one can do. Resource consumption may vary widely for
    different configurations, affecting scalability assessments.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，资源限制（例如计算能力和内存）限制了可以进行多少评估。不同配置的资源消耗可能差异很大，影响可扩展性评估。
- en: 'For any LLM-based agentic system there are four key evaluation objectives:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何基于LLM的代理系统，有四个关键评估目标：
- en: Examine its internal properties.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 检查其内部属性。
- en: This means looking at its core language skills, how well it grasps context,
    whether it can learn and transfer knowledge, and how readily unexpected abilities
    (emergent behaviors) appear. You also ask how quickly it adapts to new environments
    or tasks and how effectively multiple agents cooperate. Evidence comes from coherence
    and relevance in answers, comprehension during live interactions, decision-making
    in controlled scenarios, and responsiveness when the situation changes. Logs and
    simulations reveal collective behaviors, while longitudinal testing shows whether
    performance improves, plateaus, or degrades over time. To measure performance,
    you can use the metrics defined previously.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着要查看其核心语言技能，它如何掌握上下文，它是否能够学习和迁移知识，以及意外能力（涌现行为）出现的容易程度。你还询问它如何快速适应新环境或任务，以及多个代理如何有效地合作。证据来自答案中的连贯性和相关性，实时互动中的理解，受控场景中的决策，以及情况变化时的响应性。日志和模拟揭示了集体行为，而纵向测试显示性能是否随时间提高、停滞或下降。为了衡量性能，你可以使用之前定义的指标。
- en: Audit performance at the engineering level.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在工程层面审计性能。
- en: You care about efficiency, scalability, and robustness when things go wrong.
    Measure the computational resources used to fulfill tasks. Stress tests show what
    happens as you scale up the number of agents or workloads, and fault injection
    experiments probe resilience and recovery strategies under adverse conditions.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 当事情出错时，你关心效率、可扩展性和鲁棒性。测量完成任务所使用的计算资源。压力测试显示随着代理数量或工作负载的增加会发生什么，而故障注入实验探测在不利条件下的弹性和恢复策略。
- en: Focus on the quality of interaction.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 关注交互质量。
- en: Here you want to know how engaging, clear, and trustworthy the dialogue feels
    to human users. Metrics such as session length, turn-taking frequency, and response
    latency quantify engagement, while surveys probe perceived reliability, conversational
    coherence, and relationship warmth. Observational studies of real-world use round
    out the picture by documenting how users actually behave around the agent.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这里你想知道对话对人类用户来说有多吸引人、清晰和值得信赖。会话长度、轮流频率和响应延迟等指标量化了参与度，而调查则探测感知的可靠性、对话连贯性和关系温暖。对现实世界使用的观察研究通过记录用户实际上如何围绕代理行为来完善画面。
- en: Measure user satisfaction.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 测量用户满意度。
- en: Ultimately, people must feel the system helps them accomplish their goals, and
    it should leave them with a positive emotional impression. You can capture explicit
    feedback on task success (like a thumbs-up or thumbs-down after each response),
    run sentiment analysis on user comments, and conduct surveys that gauge both moment-to-moment
    emotions and overall approval.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，人们必须感觉到系统帮助他们实现目标，并且它应该给他们留下积极的情感印象。你可以捕捉关于任务成功的明确反馈（如每次响应后的点赞或踩），对用户评论进行情感分析，并开展调查，以衡量即时情绪和整体满意度。
- en: One typical way to measure success is to calculate the net promoter score (NPS)
    by asking users “How likely are you to recommend the system for a task?” and give
    a score between 0 and 10 inclusive. Users who give a score of 9 or 10 are considered
    *promoters*, and users who give scores between 0 and 6 are considered *detractors*.
    The NPS is calculated as % Promoters – % Detractors. It can range from +100 (every
    user is a promoter) to –100 (every user is a detractor). Scores above +30 indicate
    strong performance.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 衡量成功的一个典型方法是通过询问用户“你有多可能推荐这个系统来完成一项任务？”并给出0到10之间的分数。得分为9或10的用户被认为是*推荐者*，得分为0到6的用户被认为是*反对者*。NPS的计算方法是%推荐者
    – %反对者。它可以从+100（每个用户都是推荐者）到-100（每个用户都是反对者）不等。得分高于+30表示表现强劲。
- en: Together, these four perspectives—system properties, technical performance,
    interaction quality, and user satisfaction—provide a holistic, complementary view
    of how well an agentic LLM system actually works in practice.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个视角——系统属性、技术性能、交互质量和用户满意度——共同提供了一个全面、互补的视角，说明了代理LLM系统在实际中工作得有多好。
- en: Given the complexity of measuring agentic systems, practitioners usually use
    different measurement strategies at different steps of the system-development
    process. If you were to break the development of an agentic system down into three
    steps, then model development and training, deployment, and production monitoring
    would be the different metrics that are most important at each stage.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 由于衡量代理系统的复杂性，实践者通常在系统开发的不同步骤中使用不同的测量策略。如果你将代理系统的开发分解为三个步骤，那么模型开发和训练、部署和生产监控将是每个阶段最重要的不同指标。
- en: 'Stage 1: Model development and training and integration into the agentic system'
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一阶段：模型开发和训练以及集成到代理系统中
- en: 'While the model is still in the lab, focus on *intrinsic capabilities*:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型仍在实验室阶段时，关注*内在能力*：
- en: Language abilities
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 语言能力
- en: Track response coherence and end-user comprehension. You can use the generative
    metrics and the associated tools described in this chapter.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪响应一致性和最终用户理解。你可以使用本章中描述的生成性指标和相关工具。
- en: Integration
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 集成
- en: Measure how each component of the agentic system is used when a user request
    comes in. Test whether the appropriate agents are involved in the tasks. For example,
    if you have a program that performs math (a calculator agent) that should be called
    by your orchestrating LLM when the user enters a math question, ensure that this
    is what actually happens. If it isn’t, you may need to adjust your orchestrating
    prompt.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 测量当用户请求到来时，代理系统的每个组件是如何被使用的。测试适当的代理是否参与了任务。例如，如果你有一个执行数学（计算代理）的程序，当用户输入数学问题时应该由你的编排LLM调用，确保这确实发生了。如果没有，你可能需要调整你的编排提示。
- en: 'Stage 2: Agentic system deployment'
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第二阶段：代理系统部署
- en: With a trained model checkpoint in hand, you now ask, “Will people trust this
    system and find it useful?”
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个训练好的模型检查点后，你现在要问，“人们会信任这个系统并认为它有用吗？”
- en: Trust and reliability
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 信任和可靠性
- en: Use survey-based internal user trust scores. The NPS metric defined previously
    is a good indicator of whether users like the system and find it useful.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基于调查的内部用户信任分数。之前定义的NPS指标是衡量用户是否喜欢该系统并认为它有用的良好指标。
- en: User–agent relationship
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 用户-代理关系
- en: Long-form user interviews and quick user satisfaction polls can tell you how
    test users feel about the system.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 长期用户访谈和快速用户满意度调查可以告诉你测试用户对系统的感受。
- en: Overall satisfaction and perceived effectiveness
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 总体满意度和感知有效性
- en: A/B tasks, success rate tallies, and sentiment analysis of open-text feedback
    provide ground truth.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: A/B测试、成功率统计和开放文本反馈的情感分析提供基准事实。
- en: Built-in survey widgets make it easy to collect this data in a controlled sandbox
    before you expose the system to real customers.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 内置的调查小部件使得在将系统向真实客户公开之前，在受控沙盒中收集这些数据变得容易。
- en: 'Stage 3: Production'
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第三阶段：生产
- en: 'At scale, you watch for higher-order phenomena and operational health:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在规模上，你关注更高阶的现象和运营健康：
- en: Agent component utilization
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 代理组件利用率
- en: Check whether component agents are being used as you expected. You may have
    created several specialist agents in anticipation of user workloads, but if some
    are not being used, it may make sense to shut them down and move their functionality
    to the orchestrating LLM where answers will be provided quickly.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 检查组件代理是否按预期使用。你可能已经创建了几个专业代理来预期用户的工作负载，但如果某些代理没有被使用，关闭它们并将它们的功能转移到提供快速答案的编排LLM中可能是有意义的。
- en: Engagement
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 参与度
- en: Measure average session duration and per-user interaction frequency as leading
    indicators of churn. Are users completing tasks? Are they returning day after
    day to complete more tasks?
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 测量平均会话持续时间和每个用户的交互频率作为流失的前瞻性指标。用户是否完成了任务？他们是否日复一日地回来完成更多任务？
- en: Computational efficiency
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 计算效率
- en: As with any computational system, monitor the computational resources. Log average
    task completion time and resource utilization (CPU/GPU) to spot bottlenecks before
    your cloud bill spikes.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何计算系统一样，监控计算资源。记录平均任务完成时间和资源利用率（CPU/GPU），以便在云服务账单激增之前发现瓶颈。
- en: General Evaluation Considerations
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一般评估考虑因素
- en: Ultimately, the success of your system is measured by its users. The main goal
    of metrics that can be automatically measured is to catch errors and improve the
    system to improve the user experience without frustrating users. However, as much
    as you can afford to do so, conduct user studies over an extended period to track
    changes in trust and satisfaction as users interact with your product.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，你系统的成功是由其用户来衡量的。可以自动衡量的指标的主要目标是捕捉错误并改进系统，以改善用户体验而不会让用户感到沮丧。然而，尽你所能，在较长时间内进行用户研究，以跟踪用户与你的产品互动时信任和满意度的变化。
- en: NPS is a quick and useful one-question indicator of success and for that reason
    is widely adopted in many industries.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: NPS是一个快速且有用的单一问题成功指标，因此它在许多行业中得到了广泛的应用。
- en: Satisfaction widgets are also very useful; for example, you can collect user
    feedback after each interaction by adding “thumbs-up” and “thumbs-down” buttons
    after each response, providing user feedback on real-world interactions.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 满意度小部件也非常有用；例如，你可以在每个回复后添加“点赞”和“踩”按钮，以便在现实世界的交互中收集用户反馈。
- en: You can also use commercial monitoring platforms like [Weights & Biases](https://wandb.ai/site)
    or develop your own metrics with the LangSmith tool described earlier in this
    chapter to monitor your system in production. LangSmith can automatically evaluate
    the outputs of the agentic system. Weights & Biases can collect metrics, show
    dashboards, and emit alerts when metrics become lower than some threshold you
    define.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用像[Weights & Biases](https://wandb.ai/site)这样的商业监控平台，或者使用本章前面描述的LangSmith工具开发自己的指标来监控你的系统在生产中的表现。LangSmith可以自动评估代理系统的输出。Weights
    & Biases可以收集指标，显示仪表板，并在指标低于你定义的某些阈值时发出警报。
- en: By integrating channels for immediate user feedback, you can learn from user
    interactions and improve your application over time. This iterative process of
    collecting feedback and updating your application ensures that it adapts to user
    preferences, ultimately enhancing trust and satisfaction.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 通过整合即时用户反馈的渠道，你可以从用户交互中学习，并随着时间的推移改进你的应用程序。收集反馈并更新应用程序的这种迭代过程确保了它能够适应用户偏好，最终增强信任和满意度。
- en: The Value of Automated Metrics
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动化指标的价值
- en: As shown in [Chapter 6](ch06.html#ch06_api_first_llm_deployment_1748919660052702),
    automated metrics can make it a lot easier for you to see whether changes are
    improving your application. For example, let’s say you have an application that
    generates text that describes an image. Your existing prompt has an NPS of 90%,
    but a new paper is proposing a different prompting technique (for example, using
    bullet points). If your metrics are automated, it’s easier to create an A/B test,
    offering output from the existing prompt to audience A and from the new prompt
    to audience B. You should expect the NPS of audience A to remain close to 90%
    (since it’s using the existing prompt). If the NPS of audience B, the one using
    the new prompt, is higher, you can decide to switch everyone to the new prompt.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [第 6 章](ch06.html#ch06_api_first_llm_deployment_1748919660052702) 所示，自动化的指标可以使你更容易地看到更改是否在改善你的应用程序。例如，假设你有一个生成描述图像文本的应用程序。你现有的提示词的
    NPS 为 90%，但一篇新的论文提出了不同的提示技术（例如，使用项目符号）。如果你的指标是自动化的，那么创建 A/B 测试就更容易了，向受众 A 提供现有提示词的输出，向受众
    B 提供新提示词的输出。你应该预期受众 A 的 NPS 保持在 90% 左右（因为它使用的是现有提示词）。如果使用新提示词的受众 B 的 NPS 更高，你可以决定将所有人切换到新提示词。
- en: Another use of A/B tests is to improve computational efficiency. LLMOps practitioners
    frequently try to reduce prompts while keeping the same performance. Since most
    LLMs are priced (or consume resources) based on prompt size, you want to use the
    smallest prompt that achieves a given quality threshold. You don’t even need to
    generate the smaller prompts yourself; you can use an LLM to summarize or reduce
    existing prompts while keeping the meaning and intention of the original prompt.
    If you have automated metrics, you can then test several prompts and select the
    smallest one that achieves your performance requirements. This can save enormous
    amounts of money and resources. Of course, you can also do this without using
    automated metrics, but it will take a lot longer.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: A/B 测试的另一个用途是提高计算效率。LLMOps 实践者经常试图在保持相同性能的同时减少提示词。由于大多数 LLMs 的定价（或消耗资源）基于提示词大小，你希望使用最小的提示词来实现给定的质量阈值。你甚至不需要自己生成更小的提示词；你可以使用
    LLM 来总结或减少现有的提示词，同时保持原始提示词的意义和意图。如果你有自动化的指标，你可以测试几个提示词，并选择达到你性能要求的最小提示词。这可以节省大量的金钱和资源。当然，你也可以不使用自动化指标来做这件事，但这会花费更长的时间。
- en: Model Drift
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型漂移
- en: LLMs are under constant development, with new models and new model versions
    coming up all the time. The performance of your application can drift because
    of a change in the model. Sometimes it improves, but sometimes it declines. If
    you don’t measure it, you won’t know.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 正在不断发展，新的模型和新版本模型不断涌现。你的应用程序的性能可能会因为模型的变化而漂移。有时它有所改善，但有时会下降。如果你不衡量它，你就不会知道。
- en: For example, the popular GPT-3.5 Turbo model has four versions, the first two
    of which ceased to work on February 13, 2025\. For users who configured their
    settings to “auto-update,” calls to these deprecated versions started going to
    the latest version automatically. For all other users, they just started returning
    errors.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，流行的 GPT-3.5 Turbo 模型有四个版本，其中前两个在 2025 年 2 月 13 日停止工作。对于将设置配置为“自动更新”的用户，对这些已弃用的版本的调用开始自动转向最新版本。对于所有其他用户，它们只是开始返回错误。
- en: In both cases, LLMOps would help. The latter case is more obvious, as even the
    most basic of monitoring systems (receiving lots of angry emails from disappointed
    users) will catch it.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，LLMOps 都会提供帮助。后者的情况更为明显，因为即使是最基本的监控系统（收到大量失望用户的愤怒邮件）也能捕捉到它。
- en: The former case, when a model automatically changes to a new version, can generate
    unexpected issues. For example, it’s possible that some guardrails that you had
    to implement to prevent errors in earlier versions of the model are not necessary
    anymore. A typical case is dedicating a large portion of the prompt to safeguards
    against biases and offensive answers. Newer versions of models typically incorporate
    defenses against several known attacks, so including these defenses in your prompts
    might become just a waste of money.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 前者的情况，当模型自动切换到新版本时，可能会产生意外问题。例如，可能一些你为了防止模型早期版本出现错误而必须实施的防护措施现在不再必要了。一个典型的例子是将大量提示词用于防止偏见和冒犯性回答。模型的较新版本通常包含针对几种已知攻击的防御措施，因此将这些防御措施包含在提示词中可能只是浪费金钱。
- en: A more difficult scenario is when performance unexpectedly drops. It’s possible
    for a prompt that worked with the old version to stop working with the new version,
    for unknown reasons.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个更复杂的情况下，性能可能会意外下降。有可能一个与旧版本兼容的提示在新版本中停止工作，原因不明。
- en: Ideally, you would know about the version shift ahead of time so you could perform
    tests and make adjustments while both versions are still available. However, not
    all applications developed during the initial AI boom were built with metrics
    and monitoring in mind. Many developers were surprised when their applications
    suddenly stopped working or started giving different results due to a change in
    the backend of their cloud model provider.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，你会在版本变动之前得知，这样你可以在两个版本都可用时进行测试和调整。然而，并非所有在初始AI热潮期间开发的应用都是基于指标和监控构建的。许多开发者在他们的应用程序突然停止工作或由于云模型提供商后端的变化而开始给出不同结果时感到惊讶。
- en: Traditional Metrics Aren’t Enough
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统指标不足
- en: As we discussed earlier, in the RAG and Agents Evaluation section, standard
    metrics such as accuracy and loss have long served as foundational indicators
    of model performance during the training and validation phases. These metrics
    effectively quantify how well a model fits its training data or generalizes to
    held-out validation sets. However, they fall short in capturing the nuanced and
    multifaceted failure modes that emerge once models are deployed in complex, real-world
    production environments.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，在RAG和代理评估部分，标准指标如准确性和损失在训练和验证阶段一直作为模型性能的基础指标。这些指标有效地量化了模型如何适应其训练数据或泛化到保留的验证集。然而，它们在捕捉模型部署到复杂、现实世界的生产环境后出现的微妙和多方面的故障模式方面存在不足。
- en: In production, outputs can be syntactically fluent and stylistically polished,
    yet harbor hallucinations, latent biases, or structural inconsistencies that traditional
    metrics like accuracy or loss simply do not detect. These subtle issues often
    have serious downstream consequences, from propagating misinformation to causing
    ethical violations and user dissatisfaction.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，输出可能在语法上流畅且在风格上精致，但可能隐藏着幻觉、潜在偏见或结构不一致性，这些是传统的指标如准确度或损失所无法检测到的。这些微妙的问题往往有严重的下游后果，从传播错误信息到造成道德违规和用户不满。
- en: As a result, production-level evaluation demands toolsets and frameworks that
    are specifically designed for continuous, real-time monitoring of model behavior.
    These systems focus on detecting anomalies, tracking data and concept drift, assessing
    user impact, and identifying emerging ethical risks. Effective evaluation in this
    context requires more than just recognizing failure modes; it calls for architecting
    comprehensive observability pipelines that can capture these failures early and
    with high fidelity.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，生产级评估需要专门为持续、实时监控模型行为设计的工具集和框架。这些系统专注于检测异常、跟踪数据和方法漂移、评估用户影响，以及识别新兴的道德风险。在这种背景下，有效的评估不仅需要识别故障模式，还需要构建能够早期且高保真地捕获这些故障的综合可观察性管道。
- en: Such observability systems must be capable of tracing errors back to the precise
    stages in the inference or data-processing pipeline where they arose, whether
    that means input preprocessing, retrieval components, the generative model itself,
    or post-processing layers. Such granular mapping lets engineering teams perform
    rapid root-cause analysis, prioritize fixes, and confidently roll out mitigations.
    This proactive, end-to-end monitoring infrastructure transforms evaluation from
    a reactive afterthought into a strategic, integral part of maintaining reliability,
    safety, and ethical integrity in LLM-powered systems at scale.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的可观察性系统必须能够追踪错误回到推理或数据处理管道中它们出现的精确阶段，无论这意味着输入预处理、检索组件、生成模型本身，还是后处理层。这种细粒度的映射让工程团队能够快速进行根本原因分析，优先处理修复，并自信地推出缓解措施。这种主动的端到端监控基础设施将评估从反应性的事后考虑转变为维护大规模LLM系统可靠性、安全性和道德完整性的战略、关键部分。
- en: The Observability Pipeline
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可观察性管道
- en: Evaluation can no longer be an afterthought, applied only after a response is
    generated. It must be embedded throughout the LLM pipeline, from initial input
    to final user feedback (see [Figure 7-4](#fig0704)).
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 评估不能再是事后考虑，仅在生成响应之后应用。它必须嵌入到LLM管道的每个环节中，从初始输入到最终用户反馈（见图7-4）。
- en: '![](assets/llmo_0704.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/llmo_0704.png)'
- en: Figure 7-4\. Observability pipeline for LLMs
  id: totrans-239
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-4. LLM的可观察性管道
- en: Preprocessing and Prompt Construction
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理和提示构建
- en: LLM deployment failures often trace back not to the model itself, but to the
    prompts it receives. In production environments, prompts are rarely fixed, handcrafted
    snippets. Instead, they are dynamically generated, assembled from templates, and
    parameterized based on upstream data sources or evolving user state. This dynamism
    introduces complexity and variability that can subtly undermine the system’s performance
    if not carefully managed.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 部署失败往往不是模型本身的问题，而是它接收到的提示信息。在生产环境中，提示信息很少是固定的、手工编写的片段。相反，它们是动态生成的，由模板组装，并根据上游数据源或不断变化用户状态进行参数化。这种动态性引入了复杂性和可变性，如果不加以妥善管理，可能会微妙地损害系统的性能。
- en: Evaluation at the prompt stage focuses on several critical dimensions. First,
    prompts must be syntactically valid, correctly formatted, and free from errors
    that could disrupt parsing or tokenization. Second, they need to be semantically
    coherent, providing clear, unambiguous instructions that align with the model’s
    expected input format. Third, rigorous version control of prompt templates and
    their variants is essential. By capturing every prompt version and structural
    modification, teams gain traceability that links downstream inference errors directly
    back to specific prompt changes.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示阶段进行评估时，重点关注几个关键维度。首先，提示信息必须语法正确、格式正确，并且没有可能干扰解析或分词的错误。其次，它们需要语义上连贯，提供清晰、明确的指令，与模型预期的输入格式相一致。第三，对提示模板及其变体的严格版本控制至关重要。通过捕捉每个提示版本和结构修改，团队可以获得可追溯性，将下游推理错误直接关联到特定的提示更改。
- en: To prevent cascading failures during model inference, it’s important to detect
    malformed inputs early, such as missing context variables or incorrectly injected
    parameters. Monitoring metrics like prompt token length distribution is another
    key operational practice. Excessively long prompts risk being truncated, which
    can omit vital context and degrade the output quality. Conversely, prompts that
    are too short may fail to provide sufficient context, effectively starving the
    model of the information it needs to generate accurate and relevant responses.
    By continuously tracking these distributions, teams can proactively identify regressions
    and intervene before they impact end users’ experience.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止模型推理期间的级联故障，早期检测格式不正确的输入很重要，例如缺失上下文变量或错误注入的参数。监控如提示标记长度分布等指标是另一项关键的操作实践。过长的提示信息可能会被截断，这可能导致重要上下文的遗漏并降低输出质量。相反，过短的提示信息可能无法提供足够上下文，实际上会剥夺模型生成准确和相关信息的能力。通过持续跟踪这些分布，团队可以主动识别回归并干预，防止其影响最终用户的使用体验。
- en: As prompt engineering matures into a formalized discipline, evaluation in this
    stage evolves from reactive debugging toward a model of foundational pipeline
    governance. This shift emphasizes systematic oversight, reproducibility, and controlled
    iteration, ensuring that prompt generation remains a stable, reliable cornerstone
    of the overall LLM inference pipeline.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 随着提示工程成熟为一个正式化的学科，这一阶段的评估从反应式调试转向了基础管道治理的模型。这种转变强调系统性的监督、可重复性和受控迭代，确保提示生成始终是整体
    LLM 推理管道中稳定、可靠的基石。
- en: Retrieval in RAG Pipelines
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG 管道中的检索
- en: 'In RAG systems, failures frequently originate not within the LLM itself, but
    within the retrieval stage. Evaluating retrieval performance is therefore critical.
    It involves assessing multiple dimensions: the contextual relevance of retrieved
    documents, the freshness of the information, and timeliness relative to the query’s
    intent and domain.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RAG 系统中，失败往往不是源于 LLM 本身，而是检索阶段。因此，评估检索性能至关重要。这涉及到评估多个维度：检索文档的上下文相关性、信息的时效性，以及相对于查询意图和领域的及时性。
- en: Effective RAG observability frameworks should log the exact set of documents
    retrieved for each user query, to enable retrospective analysis and reproducibility.
    Quantitative metrics, such as similarity scores between retrieved documents and
    verified ground-truth sources, provide objective measures of retrieval accuracy.
    Monitoring retrieval latency is also essential, since delays in fetching documents
    directly impact the system’s overall responsiveness and the user experience.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的 RAG 可观察性框架应记录每个用户查询检索的确切文档集，以实现回顾性分析和可重复性。如检索文档与验证的地面实源之间的相似度分数等量化指标，提供了检索准确性的客观度量。监控检索延迟也是至关重要的，因为获取文档的延迟会直接影响系统的整体响应性和用户体验。
- en: One of the most powerful evaluation techniques in this context is *embedding
    similarity drift detection*. By continuously tracking the statistical distributions
    of query and document embeddings, teams can detect subtle shifts that may signal
    degradation in retrieval quality. These shifts often precede more obvious failures,
    such as hallucinations or vague, nonspecific responses, caused by irrelevant or
    outdated documents. Once this kind of drift is detected, timely interventions
    include retraining the retriever, refreshing the index, and reconfiguring the
    retrieval pipeline.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，最强大的评估技术之一是*嵌入相似度漂移检测*。通过持续跟踪查询和文档嵌入的统计分布，团队可以检测出可能预示检索质量下降的微妙变化。这些变化通常发生在更明显的故障之前，例如由无关或过时的文档引起的幻觉或模糊、不具体的响应。一旦检测到这种漂移，及时干预措施包括重新训练检索器、刷新索引和重新配置检索管道。
- en: Without this granular observability, it becomes extremely challenging to differentiate
    failures caused by retrieval issues from those arising in the generation stage.
    Properly instrumented evaluation pipelines that span both the retrieval and generation
    components are thus indispensable for maintaining the reliability, accuracy, and
    user trustworthiness of RAG-powered enterprise LLM systems.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 没有这种细粒度的可观测性，区分由检索问题引起的故障和生成阶段出现的故障变得极其困难。因此，跨越检索和生成组件的适当仪器化的评估管道对于维护由RAG驱动的企业LLM系统的可靠性、准确性和用户信任至关重要。
- en: LLM Inference
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM推理
- en: At the inference stage, the key metrics span several dimensions. Factual accuracy
    assesses whether the generated text aligns with verifiable truth, while hallucination
    rate measures the frequency of hallucinations. Fluency evaluates the readability
    and coherence of outputs. Latency tracks response times, which directly affect
    user experience and system throughput.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理阶段，关键指标跨越多个维度。事实准确性评估生成的文本是否与可验证的事实相符，而幻觉率衡量幻觉的频率。流畅性评估输出的可读性和连贯性。延迟跟踪响应时间，这直接影响用户体验和系统吞吐量。
- en: 'To enable deep diagnostics, observability systems must log detailed metadata
    for every inference call:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现深度诊断，可观测性系统必须为每个推理调用记录详细的元数据：
- en: Token counts for both inputs and outputs reveal usage patterns and potential
    truncations.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入和输出的标记计数揭示了使用模式和潜在的截断。
- en: Temperature and other sampling parameters clarify the probabilistic nature of
    generation.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 温度和其他采样参数阐明了生成的概率性质。
- en: Model versioning lets you trace performance changes to specific code or model
    updates.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型版本控制让您能够追踪性能变化到特定的代码或模型更新。
- en: Abrupt shifts in completion length may indicate truncation errors or latent
    failures that aren’t immediately obvious in the delivered responses, making this
    metric particularly valuable.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成长度突然变化可能表明截断错误或潜在的故障，这些故障在提供的响应中并不立即明显，这使得这一指标特别有价值。
- en: Beyond surface metrics, internal evaluation techniques provide an additional
    layer of quality assurance. Self-consistency checks, which compare multiple generations
    of the same prompt, can identify outputs that are superficially fluent but inconsistent
    or contradictory. Similarly, confidence scores derived from auxiliary evaluators
    or specialized classifiers help flag outputs that deviate from the expected factual
    or ethical standards.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 除了表面指标之外，内部评估技术提供了额外的质量保证层。自洽性检查，即比较同一提示的多个生成版本，可以识别出表面上流畅但不一致或矛盾的输出。同样，来自辅助评估器或专业分类器的置信度分数有助于标记偏离预期事实或伦理标准的输出。
- en: Inference is rarely a standalone process; it’s usually embedded within intricate
    chains or pipelines involving multiple calls, retrieval steps, and post-processing.
    This is where structured logging and trace visualization tools become essential.
    These tools enable real-time monitoring, facilitate root-cause analysis, and empower
    teams to pinpoint precisely where failures or inefficiencies occur within complex
    workflows. Together, these observability practices elevate inference evaluation
    from a passive measurement to an active governance mechanism that’s essential
    for maintaining reliability, accuracy, and trustworthiness in deployed LLM systems.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 推理很少是一个独立的过程；它通常嵌入在复杂的链或管道中，涉及多个调用、检索步骤和后处理。这就是结构化日志和跟踪可视化工具变得至关重要的地方。这些工具能够实时监控，促进根本原因分析，并使团队能够精确地确定在复杂的工作流程中失败或不效率发生的位置。这些可观察性实践将推理评估从被动的测量提升为一种积极的治理机制，这对于维护部署的LLM系统的可靠性、准确性和可信度至关重要。
- en: Postprocessing and Output Validation
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 后处理和输出验证
- en: After the generation phase, outputs typically undergo a *postprocessing* stage,
    where formatting, cleanup, and structural adjustments prepare the data for delivery
    to end users or downstream systems. Although this step may seem straightforward,
    even minor structural errors introduced here can cascade into significant failures
    throughout the application stack.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成阶段之后，输出数据通常进入一个*后处理*阶段，该阶段包括格式化、清理和结构调整，以便将数据交付给最终用户或下游系统。尽管这一步骤看起来很简单，但即使在这里引入的微小结构错误也可能在整个应用程序堆栈中引发重大故障。
- en: 'Evaluation at the post-processing stage centers on *structural validation*.
    This involves verifying that the generated outputs conform to expected formats:
    for instance, ensuring that JSON responses are syntactically valid, adhere strictly
    to predefined schemas, and include all mandatory fields. This is important, because
    outputs that appear grammatically correct can still be functionally unusable if
    key data elements are missing or malformed.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理阶段的评估集中在*结构验证*上。这涉及到验证生成的输出是否符合预期的格式：例如，确保JSON响应在语法上是有效的，严格遵循预定义的架构，并包含所有必填字段。这很重要，因为即使输出在语法上正确，如果关键数据元素缺失或格式不正确，仍然可能无法使用。
- en: Automated tooling plays a vital role here. *Schema validators* check systematically
    for structural integrity, while additional automated checks can detect empty completions
    or other anomalies that could disrupt downstream processing. In high-stakes domains
    and compliance-critical applications, undetected errors during post-processing
    risk triggering silent failures or even regulatory breaches, with potentially
    severe consequences.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化工具在这里发挥着至关重要的作用。*架构验证器*系统地检查结构完整性，而额外的自动化检查可以检测空完成或其他可能干扰下游处理的异常。在高风险领域和合规性关键的应用中，后处理过程中未检测到的错误可能会触发静默故障甚至违规行为，后果可能非常严重。
- en: By elevating postprocessing to a formal, evaluable stage within the overall
    system pipeline, teams gain the ability to proactively detect and remediate structural
    issues before they propagate. This perspective transforms post-processing from
    a passive formatting step into a critical checkpoint for ensuring output reliability,
    correctness, and compliance in production LLM deployments.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将后处理提升为整体系统管道中的一个正式、可评估的阶段，团队能够主动检测和修复在问题扩散之前的结构性问题。这种视角将后处理从被动的格式化步骤转变为确保生产环境中LLM部署的输出可靠性、正确性和合规性的关键检查点。
- en: Capturing Feedback
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 捕获反馈
- en: Feedback data includes signals like user ratings, thumbs-up/down, direct textual
    feedback, and implicit behavioral indicators, like engagement duration, query
    abandonment, and rates of escalation to human agents.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈数据包括用户评分、点赞/踩、直接文本反馈以及隐含的行为指标，如参与时长、查询放弃率和升级到人工代理的比率。
- en: Consistently capturing and integrating this feedback grounds your evaluation
    firmly in real-world user experience, revealing nuanced gaps and failure modes
    that static internal benchmarks and offline testing might overlook. Metrics in
    this stage serve as vital usability indicators that directly inform system refinement
    priorities. These include *dwell time*, which measures how long users engage with
    generated content; *abandonment rates*, which signal frustration or dissatisfaction,
    and *retry frequency*, which can indicate unclear or unhelpful responses.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 一致地捕捉和整合这种反馈，将你的评估牢牢地建立在现实世界用户体验的基础上，揭示了静态内部基准和离线测试可能忽视的细微差距和故障模式。这一阶段的指标作为关键的用户可用性指标，直接告知系统改进的优先级。这些包括*停留时间*，它衡量用户与生成内容的互动时间；*放弃率*，它表示挫败感或不满意；以及*重试频率*，它可以表明不明确或不有帮助的响应。
- en: Evaluation platforms like LangSmith facilitate rubric-driven scoring of outputs,
    along dimensions like factuality, relevance, and structural correctness. These
    scores are enriched with metadata, including model versions, prompt variants,
    and contextual information, enabling fine-grained traceability and longitudinal
    performance analysis.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: LangSmith等评估平台通过事实性、相关性、结构正确性等维度促进输出结果的评分，这些评分通过元数据得到丰富，包括模型版本、提示变体和上下文信息，从而实现细粒度的可追溯性和纵向性能分析。
- en: As approaches like human-in-the-loop fine-tuning and reward modeling mature,
    feedback transitions from a passive measurement tool into an active driver of
    continuous improvement. User signals become training data that dynamically steers
    model updates and pipeline adjustments, closing the loop between deployment and
    iteration.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 随着像人工反馈微调和奖励建模这样的方法成熟，反馈从被动的测量工具转变为持续改进的积极驱动者。用户信号成为训练数据，动态引导模型更新和管道调整，关闭部署和迭代之间的循环。
- en: Every stage of the pipeline yields unique and complementary insights into your
    system’s health. Their real power emerges when these observations are integrated
    holistically into an end-to-end observability framework. This interconnected visibility
    is critical for maintaining robust, reliable, and user-centered LLM applications
    in dynamic production environments.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 管道的每个阶段都会为你系统健康提供独特且互补的见解。当这些观察结果被整体集成到一个端到端的可观察性框架中时，它们的真正力量才会显现。这种互联的可见性对于在动态生产环境中维护稳健、可靠和以用户为中心的LLM应用至关重要。
- en: 'At its core, observability is an anomaly-detection problem. You’re looking
    for patterns or deviations from expected behavior in your system’s metrics, logs,
    traces, and outputs. Like a smoke detector, the goal isn’t to catch every minor
    issue but to catch the ones that matter before they spread into serious failures.
    Post-LLM evaluation metrics that you likely set up in training, these observability
    metrics cover the remainder of the pipeline. You can do this across four stages,
    each with its own benefits:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，可观察性是一个异常检测问题。你正在寻找系统指标、日志、跟踪和输出中的模式或与预期行为的偏差。就像烟雾探测器一样，目标不是捕捉每一个小问题，而是在它们扩散成严重故障之前捕捉那些重要的问题。在LLM评估中，你可能在训练中设置了一些指标，这些可观察性指标涵盖了管道的其余部分。你可以通过四个阶段来完成这项工作，每个阶段都有其自身的优势：
- en: 'Stage 1: Threshold-based alerts'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 第1阶段：基于阈值的警报
- en: This is the simplest form. Here, you can set explicit limits on key metrics,
    like API response times over 2 seconds or token counts exceeding 1024\. When thresholds
    are crossed, tools like Prometheus collect the data, and Grafana triggers alerts
    that notify teams via Slack or issue trackers. It’s straightforward and fast to
    implement, but may miss complex or evolving issues since the thresholds are static.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最简单的形式。在这里，你可以对关键指标设置明确的限制，例如超过2秒的API响应时间或超过1024的令牌计数。当阈值被超过时，像Prometheus这样的工具会收集数据，Grafana会触发通过Slack或问题跟踪器通知团队的警报。这很简单，实施起来也很快，但由于阈值是静态的，可能会错过复杂或不断变化的问题。
- en: 'Stage 2: Statistical anomaly detection'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 第2阶段：统计异常检测
- en: Here, you move beyond fixed limits by analyzing metric behavior over time using
    rolling statistics, such as moving averages and z-scores. For example, a sudden
    spike in latency with a high z-score signals an anomaly worth investigating. Grafana
    dashboards paired with AlertManager highlight these deviations, and integrating
    with trace tools like LangSmith helps pinpoint which requests or outputs caused
    the alert. This method adapts to normal fluctuations, reducing false positives.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您通过分析随时间变化的指标行为，如移动平均和z分数，超越了固定限制。例如，延迟突然上升且z分数较高，表明值得调查的异常情况。Grafana仪表板与AlertManager配合使用，突出显示这些偏差，与像LangSmith这样的跟踪工具集成有助于确定哪些请求或输出触发了警报。这种方法适应正常波动，减少误报。
- en: 'Stage 3: Drift detection'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 第三阶段：漂移检测
- en: This monitors changes in input data or retrieval quality that can degrade AI
    performance over time. For instance, if user queries shift or similarity scores
    in retriever embeddings drop, it’s a sign that data or retrieval may be stale.
    Using libraries like FAISS for embedding analysis and frameworks like LangChain
    for pipeline monitoring, you can detect these shifts early. Automated workflows
    then refresh retrievers or retrain the models, thus keeping the system accurate
    and relevant.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这监控着输入数据或检索质量的变化，这些变化可能会随着时间的推移降低AI性能。例如，如果用户查询发生变化或检索嵌入中的相似度得分下降，这可能表明数据或检索可能已过时。使用FAISS等库进行嵌入分析和使用LangChain等框架进行管道监控，您可以提前检测这些变化。然后，自动工作流程刷新检索器或重新训练模型，从而保持系统的准确性和相关性。
- en: 'Stage 4: Feedback Signal Monitoring'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 第四阶段：反馈信号监控
- en: User feedback and fallback behaviors provide direct insight into real-world
    system health. A drop in positive ratings or an increase in fallback (default)
    responses indicates issues in user experience or model degradation. Tools like
    LangSmith and MLflow link this feedback to specific model versions and deployments,
    helping teams diagnose the root cause and decide whether to rollback or retrain.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 用户反馈和回退行为提供了对现实世界系统健康状况的直接洞察。正面评分下降或回退（默认）响应增加表明用户体验或模型退化存在问题。像LangSmith和MLflow这样的工具将此反馈链接到特定的模型版本和部署，帮助团队诊断根本原因并决定是否回滚或重新训练。
- en: 'A robust observability system combines all these four layers. While the following
    tools mentioned are my general suggestions, feel free to stick with the stack
    you already have:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 一个强大的可观察性系统结合了这四个层次。虽然以下提到的工具是我的一般建议，但您也可以继续使用您已有的堆栈：
- en: Prometheus collects runtime metrics (CPU, memory, latency, token usage).
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus 收集运行时指标（CPU、内存、延迟、令牌使用情况）。
- en: Grafana offers real-time dashboards and alerting on thresholds and statistical
    anomalies.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grafana 提供基于阈值的实时仪表板和警报以及统计异常。
- en: MLflow/ZenML tracks model versions and experiment metadata.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow/ZenML 跟踪模型版本和实验元数据。
- en: LangSmith provides trace-level insights and connects feedback signals to model
    performance.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangSmith 提供跟踪级别的洞察并将反馈信号连接到模型性能。
- en: My goal here is not to recommend tools but to provide you with some references.
    Regardless of the tool you choose, or even if you choose to hard-code everything,
    what matters most is your implementation technique. By layering simple threshold
    alerts, adaptive statistical methods, drift detection, and user feedback monitoring,
    you can build a comprehensive pipeline that catches everything from obvious breaches
    to subtle degradations in AI system health.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里的目标不是推荐工具，而是为您提供一些参考。无论您选择哪种工具，或者即使您选择硬编码一切，最重要的是您的实现技术。通过分层简单的阈值警报、自适应统计方法、漂移检测和用户反馈监控，您可以构建一个全面的管道，从明显的违规行为到AI系统健康状况的微妙退化都能捕捉到。
- en: Conclusion
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'This chapter covered general LLM evaluation metrics and additional considerations
    for two specific cases: RAG and multi-agent systems. The importance of automatically
    collecting metrics cannot be overstated. It can mean the difference between having
    a successful and trusted application and waking up to lots of angry users.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了通用LLM评估指标以及针对两个特定案例（RAG和多智能体系统）的额外考虑。自动收集指标的重要性不容忽视。它可能意味着成功和受信任的应用程序与醒来面对众多愤怒用户之间的区别。
- en: While the chapter has focused on general principles that work regardless of
    the specific metrics used, it also points to the latest metrics and frameworks
    available as of the writing of this chapter. Keep in mind that this is a very
    active area of research. However, while new metrics may be created at any time,
    the principles will remain the same.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本章重点介绍了无论使用何种具体指标都适用的通用原则，但它也指出了截至本章撰写时的最新指标和框架。请记住，这是一个非常活跃的研究领域。然而，尽管可能会随时创建新的指标，但原则将保持不变。
- en: References
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: CoreWeave. n.d. [Weights & Biases](https://wandb.ai/site), accessed May 21,
    2025.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: CoreWeave. 未知。[权重与偏差](https://wandb.ai/site)，访问日期：2025年5月21日。
- en: 'Es, Shahul, et al. [“Ragas: Automated Evaluation of Retrieval Augmented Generation”](https://oreil.ly/QUyLl),
    arXiv, April 2025.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: Es，沙胡尔，等人。[“Ragas：检索增强生成的自动评估”](https://oreil.ly/QUyLl)，arXiv，2025年4月。
- en: 'Fu, Jinlan, et al. [“GPTScore: Evaluate as You Desire”](https://oreil.ly/ylJna),
    arXiv, February 2023.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 傅金兰，等人。[“GPTScore：按需评估”](https://oreil.ly/ylJna)，arXiv，2023年2月。
- en: Hendrycks, Dan, et al. [“Measuring Massive Multitask Language Understanding”](https://oreil.ly/0xT-x),
    arXiv, January 2021.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: Hendrycks，丹，等人。[“衡量大规模多任务语言理解”](https://oreil.ly/0xT-x)，arXiv，2021年1月。
- en: 'Honovich, Or, et al. [“TRUE: Re-Evaluating Factual Consistency Evaluation”](https://oreil.ly/UwZvJ),
    arXiv, May 2022.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: Honovich，奥，等人。[“TRUE：重新评估事实一致性评估”](https://oreil.ly/UwZvJ)，arXiv，2022年5月。
- en: LangSmith. n.d. [“Get Started with LangSmith”](https://oreil.ly/F8EVF), accessed
    May 21, 2025.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: LangSmith. 未知。[“开始使用LangSmith”](https://oreil.ly/F8EVF)，访问日期：2025年5月21日。
- en: 'Lin, Stephanie, et al. [“TruthfulQA: Measuring How Models Mimic Human Falsehoods”](https://oreil.ly/adQ-N),
    arXiv, May 2022.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 林，斯蒂芬妮，等人。[“TruthfulQA：衡量模型模仿人类错误的方式”](https://oreil.ly/adQ-N)，arXiv，2022年5月。
- en: 'Liu, Yang, et al. [“G-Eval: NLG Evaluation Using GPT-4 with Better Human Alignment”](https://oreil.ly/IzuUL),
    arXiv, May 2023.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 刘洋，等人。[“G-Eval：使用GPT-4进行检索增强生成的自动评估”](https://oreil.ly/IzuUL)，arXiv，2023年5月。
- en: Machan, J. J. n.d. [Ragas](https://oreil.ly/JkFwY), accessed May 21, 2025.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 马查恩，J. J. 未知。[Ragas](https://oreil.ly/JkFwY)，访问日期：2025年5月21日。
- en: 'Manakul, Potsawee, et al. [“SelfCheckGPT: Zero-Resource Black-Box Hallucination
    Detection for Generative Large Language Models”](https://oreil.ly/8AKE9), arXiv,
    October 2023.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 曼库尔，波萨维，等人。[“SelfCheckGPT：用于生成大型语言模型的零资源黑盒幻觉检测”](https://oreil.ly/8AKE9)，arXiv，2023年10月。
- en: 'Wang, Alex, et al. [“GLUE: A Multi-Task Benchmark and Analysis Platform for
    Natural Language Understanding”](https://oreil.ly/rcLR4), arXiv, February 2019.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 王磊，亚历克斯，等人。[“GLUE：自然语言理解的多元任务基准和分析平台”](https://oreil.ly/rcLR4)，arXiv，2019年2月。
- en: 'Wang, Alex, et al. [“SuperGLUE: A Stickier Benchmark for General-Purpose Language
    Understanding Systems”](https://oreil.ly/mpepc), arXiv, February 2020.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 王磊，亚历克斯，等人。[“SuperGLUE：通用语言理解系统的粘性基准”](https://oreil.ly/mpepc)，arXiv，2020年2月。
- en: Wei, Jason, et al. [“Chain-of-Thought Prompting Elicits Reasoning in Large Language
    Models”](https://oreil.ly/YIrYf), arXiv, January 2023.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 魏杰森，等人。[“思维链提示激发大型语言模型中的推理”](https://oreil.ly/YIrYf)，arXiv，2023年1月。
- en: 'Zellers, Rowan, et al. [“HellaSwag: Can a Machine Really Finish Your Sentence?”](https://oreil.ly/2VpX9),
    arXiv, May 2019.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 泽勒，罗万，等人。[“HellaSwag：机器真的能完成你的句子吗？”](https://oreil.ly/2VpX9)，arXiv，2019年5月。
- en: Zhong, Ming, et al. [“Towards a Unified Multi-Dimensional Evaluator for Text
    Generation”](https://oreil.ly/nMMsh), arXiv, October 2022.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 钟明，等人。[“向文本生成的统一多维度评估器迈进”](https://oreil.ly/nMMsh)，arXiv，2022年10月。
