- en: Chapter 8\. Using Your Data as a Differentiator
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we spent some time giving you a point of view on the power
    (and potential) of small language models (SLMs). We introduced the notion that
    one model doesn’t have to—and won’t—rule them all. We outlined how humongous models
    are clunky to operate, expensive, and center power on the few (vendors) that can
    afford to build them. But, what’s more, they won’t help you take advantage of
    your data (unless you give it away) to generate value tailored to your business—in
    short, they help you to be an AI User as opposed to an AI Value Creator. We posit,
    and will continue to prove, how highly focused models can do some incredible things.
    We want to see an AI future that is open; hence, we oppose the notion that one
    super LLM (large language model) should rule them all.
  prefs: []
  type: TYPE_NORMAL
- en: 'A fundamental premise of this book is the only way for you to become an AI
    Value Creator is to first see your data as a dormant superpower. To maximize what
    you can do with AI and create value, we believe big bets must be placed on fostering
    a collaborative ecosystem across your company that can put your data to work,
    creating value for *you*. In fact, we think this notion is so important, it literally
    became the title of this book: *AI Value Creators*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we look at how developers and domain experts in your company
    can leverage new techniques in model customization to contribute to your company’s
    Gen AI models, driving defensible and differentiated AI innovation for *your*
    business: create value.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Customizing Open Source for the Enterprise: A New Way of Looking at Enterprise
    Data'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we noted earlier in this book, less than 1% of enterprise data resides in
    today’s LLMs. And if you’re going to become the AI Value Creator that this book
    was written to help you become, you’re going to have to work in your most valuable
    asset (your enterprise data) and have it part of your LLM strategy—ultimately
    unlocking a plethora of value creation opportunities.
  prefs: []
  type: TYPE_NORMAL
- en: To really understand how profound this is, let’s time-travel back to the origin
    of our digital world, an origin that was understood and conceptualized almost
    350 years ago by Gottfried Wilhelm Leibniz. Even back then, Leibniz already understood
    that you could take the information that was available around us in the form of
    language or mathematics and encode it in a binary representation. (Leibniz not
    only created binary math, but he also help to create calculus, so we can see why
    some of you may not be fans.) He famously said, “To create everything, one thing
    is sufficient.” Leibniz clearly knew the value and the power of representing information
    differently (in this case, binary notation). Fast-forward to today and you’ll
    easily note that the last few decades have seen a tremendous amount of value creation
    and business transformation driven by the evolution and expressiveness of our
    world’s data representations. For example, today, taste and smells have data representations,
    ultimately represented by numbers that further translate into just ones and zeros
    by the time a computer starts working on the data. In fact, perfume and flavor
    houses literally discover and propose new products using vectors to represent
    lemon-fresh or honey butter. Think about it. Who but AI could have ever thought
    of creating Everything Bagel ice cream! Truth be told, long before LLMs came along,
    wine and perfume descriptions have been entertaining us with their poetic (and
    often ridiculous) creativity for years. Because let’s be honest, who really smells
    “a whisper of sun-kissed elderflower on a dewy morning” or tastes “hints of melancholy
    with a bold finish of existential crisis”? Going forward, expect the creativity
    to go to new (polite for “potentially even more ridiculous”) levels thanks to
    LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Original Eras Tour: Looking Back a Few Decades on Data Representations'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Over the last decades, new representations of data have created completely new
    opportunities and capabilities for all businesses and industries. We thought it
    worthwhile to spend some time on this topic to help you fully appreciate an LLM’s
    value for your enterprise—*especially* when it’s nuanced with your data. The point
    is that your enterprise data can be folded into this new data representation (an
    LLM) that can make your data usable in ways that only movies could have imagined
    just a few years ago, and that can bring enormous amounts of value to your company.
  prefs: []
  type: TYPE_NORMAL
- en: When you think about it, aside from the weights in a model, AI is just compressed
    data. It’s just a new representation of that data and, as it turns out, over the
    last decades, there have been various epochs of data representations, each one
    unlocking a new era of value creation. This current AI revolution has *a lot*
    to do with the power of data representations and the power of being able to encode
    incredible amounts of information, of every possible form, inside these new, incredibly
    capable “vessels” that are foundation models (LLMs). Here is how we see some of
    those data representation eras over the years.
  prefs: []
  type: TYPE_NORMAL
- en: 'Up to the 1980s: Expert systems'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: These were (and since they are still used today, perhaps we should have written
    “are”) *handcrafted symbolic representations of our data*. Data was encoded in
    a relational database, which created a new way in which businesses could organize
    and connect to data in a way they couldn’t easily do before. This era had a very
    profound impact on business. Suddenly, a company could automate things like payroll,
    transactions could connect to inventories, and other core processes. Along the
    way, expert systems were created. Humans wrote rules for logical business flows
    with connected structured data. A great example is fraud detection or supply chain
    management—and many companies still use this method today—there’s a rule and if
    breached, a flag appears or an action is undertaken.
  prefs: []
  type: TYPE_NORMAL
- en: Rules are great for a subset of things, but they aren’t all that creative and
    there are always exceptions, so they can only really get so much right. On the
    backend of a rules-based system is a lot of manual effort to maintain and build
    those rules. A new rule must be written for each individual situation. (This is
    why we call this representational era handcrafted. For example, storing data in
    a relational database required a DBA to handcraft a schema to receive it. Humans
    do a lot of the work and a lot of the thinking around the design of that work
    too.) Perhaps a way to spot potential credit card fraud at a gas station was with
    a $1 purchase...new rule. Over time, that rule got diluted as a predictor, and
    some other indicator proved useful...new rule. It’s a simple example, but it used
    to happen all the time (or it didn’t, and companies would get frustrated). In
    the end, these systems worked as long as the rules were right. But over time,
    there were so many variations and rules that most of these systems collapsed on
    themselves. Now think about today’s digital economy—how can a rules-based system
    respond to threats from increased access points and complex transactions, identify
    signals left by perpetrators hidden in noisy and ephemeral daily activity, or
    respond to coordinated attacks with consolidated monitoring in a timely fashion?
    They can’t.
  prefs: []
  type: TYPE_NORMAL
- en: '1980s to ~2010: Machine learning'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now we move into an era of *more task-specific, less handcrafted feature representations
    of our data*. How did this happen? Because as more data became available, there
    was a shift toward data-driven approaches. It was a really big thing back then,
    because machines started to generate their own rules from that data and learn
    new representations of our world by being shown examples of it, as opposed to
    being given hand-coded rules (programmatically). Very cool! Many of these techniques
    are still used by data scientists today; for example, decision trees, support
    vector machines (SVMs), k-nearest neighbor, and more. This era was about learning
    how to get computers to help build features and getting those machines to learn
    from their insights. Those learnings were good, perhaps great. And while machines
    (with the help of humans) were using data in new ways, new representations and
    encoding mechanisms emerged—for example, graph-based representations of data (represented
    as networks with nodes and edges). Suddenly, the world starting using this new
    data representation and found a way to traverse it and it became critical to businesses
    doing things like internet search, social media, and connecting people and groups.
  prefs: []
  type: TYPE_NORMAL
- en: '2010 to ~2017: Deep learning'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now we move into the big data era (remember those 3 Vs: volume, velocity, and
    variety). Computers could now access more data than ever. Now computers didn’t
    just discover but could create new data representations. Enter the world of *task-specific
    learned feature* *representations of our data*. In this era, the world got access
    to massive amounts of compute (thanks to the cloud and GPUs) and ever-increasing
    amounts of data (thanks to the internet). Computers created and built feature
    representations, but everything was still heavily reliant on human expertise and
    loads of manual efforts. Things like the availability of resources to process
    more data and a lack of capabilities to build more complex models were still “getting
    in the way.” For example, AI for natural language processing (NLP) didn’t have
    much of a memory beyond a few words.'
  prefs: []
  type: TYPE_NORMAL
- en: This was the start of the deep learning era. There are many things beyond the
    scope of this book, like activation functions, that came to life to help this
    era. We had the synergistic combination of more and more data (starting from the
    big data era, when the world was busy collecting data) and compute (namely, it
    was discovered the GPUs we used for gaming could provide powerful processing capabilities
    because of the way they handle matrix math, which is the math deep learning does).
    Now some very cool things started to happen in this era, perhaps not magical (yet...that’s
    the next phase). All that math-computer power (GPUs to build the representations)
    got mixed with a consumability model (the cloud) and suddenly anyone could build
    AI models for less than the cost of a cheap cup of coffee. In this era, computers
    started to learn from massive amounts of data and build out task-specific feature
    representations; for example, computer vision to detect anomalies in an X-ray
    or a defect in a weld point on a production line, and so on. Some of those feature
    representations were wildly complex and the computers invented new composite features,
    like mixing together gender, location, height, and profession into a coarsified
    feature that would describe something.
  prefs: []
  type: TYPE_NORMAL
- en: 'Today: Foundation models (aka LLMs)'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Today, we can *encode any knowledge form and work with that data in ways we
    never imagined*.
  prefs: []
  type: TYPE_NORMAL
- en: Like we said earlier, foundation models are all about the power to encode incredible
    amounts of information of every possible form inside these new incredible model
    types. Our world has entered the era of LLMs where the approach not only takes
    advantage of massive compute capability and all that data, but a new technology
    (self-supervised learning at scale—thanks to transformers) drastically reduced
    the amount of curated labeled data needed to train a model. This is a massive
    departure from the past.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, this new data representation is trained on vast, immense datasets
    and can fulfill a broad range of general tasks. These new data representations
    (LLMs) serve as the base or building blocks for crafting more specialized applications.
    Their flexibility and massive size set them apart from the previous era’s representations,
    which were trained on limited datasets to accomplish specific tasks.
  prefs: []
  type: TYPE_NORMAL
- en: These new data representations are created by taking training data and breaking
    it down into smaller chunks, which are referred to as *tokens* (a token can be
    a word or a fragment of a word). This process creates trillions of these tokens,
    which are then converted into a vector, and those vectors are used to represent
    the tokens in a form an AI can understand. But these tokens can be anything, and
    as you’ve learned earlier, that means the data stored inside doesn’t have to be
    words—it can be anything (code, images, sound, taste and smell profiles, and more).
    As these tokens (not converted to vectors) pass through the layers of the neural
    network during training, a series of mathematical operations, which are mostly
    made up of matrix multiplications and a few other simple operations, are applied—but
    this is all done at a massive scale. During this build phase, data is combined
    and recombined across changing sequences of these tokens. In fact, information
    from different modalities (audio and text) can be combined into the same foundation
    model during training. A great example of this is OpenAI’s latest GPT that combines
    the power of text and image generation (from their DALL-E model) in one place.
  prefs: []
  type: TYPE_NORMAL
- en: During training, network parameters get adjusted so the outputted LLMs get better
    and better at representing the sequences of the input tokens. And as it goes through
    this training process, the model learns more and more of the structure of the
    data it’s being trained on, its nuances, and the knowledge and correlations within.
    Again, it’s not really magic; it’s just math, human ingenuity, and a lot of computing
    power.
  prefs: []
  type: TYPE_NORMAL
- en: Now the power of this new data representation, which is encoded within an LLM,
    derives its capability from its scale (the sheer amount of data that can be brought
    into it), from its connectivity of the data (semantic connections are made across
    wide disparate input data, which makes them very expressive), and from its multimodality.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now here’s our observation and the reason for this chapter. Over the last couple
    of years, we’ve witnessed these representations pretty much take all the public
    data that’s available in the world and pull it inside an LLM. For the sake of
    argument, let’s assume 100% of that kind of data has made its way into an LLM.
    Now contrast this with our previously shared estimate that barely 1% of enterprise
    data has made its way into an off-the-shelf LLM. This is a very interesting contrast:
    almost all public data has made its way in, and almost all enterprise data has
    not.'
  prefs: []
  type: TYPE_NORMAL
- en: Stand Up and Represent!...Your Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By this point in the book, you should have a sense of just how much of an inflection
    point the era of AI really is. Data collected at enormous volumes is a problem
    well-solved (understanding it is a different problem), and compute is available
    en masse—these forces synergized with new AI techniques that made for a perfect
    storm for AI disruption. So how do you get started putting your data to work?
    As we discussed in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635),
    you have to start with a trusted LLM. Once you’ve identified a base model that
    you can trust, it’s time to get your enterprise data into this era’s data-powerful
    representation. Finally, you deploy your customized model and scale and create
    value with your AI. So, let’s talk about these three steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: It All Starts with Trust'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Do not underestimate this turning point for AI: everything in AI will be different
    from here on out because of this latest representational format.'
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, to create value from your enterprise data, the very first step has
    nothing to do with your data at all. Your first step will be to select a trusted
    model—think of it as a “value” vessel, or foundation—to build upon. This step
    is critical because your enterprise data will be added on top of this starting
    point, so it’ll be quite beneficial to know what is already inside that foundation,
    the “recipe” used to make it, and how it works. This all goes back to [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974),
    where we told you to ask your LLM vendor questions like, “What data did you use
    to train your model?” and consider answers like “It’s none of your business” and
    “We don’t know” as unacceptable. Again, is this really any different than where
    you choose to build a house? The foundation has to be solid. Does your foundation
    (LLM) contain copyright infringement, hate, anger, profanity (HAP), bias, racism,
    pornography, and more? If today’s LLMs are compressed representations of the internet,
    and you believe everything on the internet is true, there is no harmful content,
    and you have none of these concerns, then you’re good to go! Have you ever gone
    through a Reddit thread and seen the toxicity in some of those groups? (And it’s
    far worse in the rooms we don’t go into.) Is that what you want to mix your precious
    data with when you try to put it to work? This will be at the core of the model
    that will ultimately be enriched to represent your business!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s get into the why, building on the same water quality analogy we used
    in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)
    when we discussed the importance of transparency of data lineage in an LLM. Imagine
    that we give you a glass of water (an LLM) and your intent is to add lemon juice
    and sugar (we’ll consider this your enterprise data) with the goal of making lemonade.
    If we gave you an opaque glass full of water (an LLM for which you know nothing
    about the data, and when you ask where did we get the water from, you’re not given
    any straight answers), would you feel comfortable using it with your fresh lemons
    and expensive organic cane sugar? Think about it: the glass is opaque, you can’t
    even see inside it! The water inside that glass could pure spring water, but it
    could also be cloudy and murky puddle water, or even contaminated water! If you
    couldn’t see inside that glass, would you still drink what’s inside it after adding
    tons of high-quality sugar and lemon to it? Probably not, so why would you do
    this with one of your company’s most previous assets—your data?'
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, with LLMs, it is nearly impossible to isolate or constrain a model
    to give responses informed by the enterprise data that you added and have it ignore
    all that cloudy murky water (data) that’s in the glass. Sure, techniques like
    retrieval-augmented generation (RAG) and fine-turning can help, but even when
    your model is customized, it is most likely still going to inherit some degree
    of performance and safety (or lack thereof) characteristics from the base model
    you used as a starting point.
  prefs: []
  type: TYPE_NORMAL
- en: In this analogy, it’s important that *the glass you’re handed to make lemonade
    is transparent* so that you can see inside of it. You need to know where the water
    is coming from that serves as the base for your lemonade so that when you mix
    your ingredients together, you have a good idea of what’s going to happen, how
    it will look, and how it’s going to taste. It’s the same when you want to put
    your data to work with an LLM. You need a base model that is transparent in terms
    of what data was used and the recipe used to make it. That way, when you add your
    data to it, you do so confidently, safely, and securely.
  prefs: []
  type: TYPE_NORMAL
- en: Another aspect of transparency is having broad commercial rights and freedom
    of action for the final model that is created. Remember, this chapter *is not*
    a chapter about model providers; it is a chapter about *your* data. You need to
    have permissive rights for your enhanced model so that when you encode your information
    into the model you choose for your business, you have *full freedom of action*
    to do what you need to do for your business. And, because you’re building on top
    of a model that has public data from the outside world, it should also be vendor
    indemnified from legal claims.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As we talked about in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635),
    ensure you do your due diligence around what indemnifications your LLM comes with.
    Today, every vendor out there is offering some sort of indemnification, but you
    need to know that every vendor’s indemnification protections are different. Some
    don’t indemnify on what’s created, some fully indemnify, some limit the size of
    the indemnification, some don’t indemnify on the output but do in the usage of,
    and so on. Yes, you’re going to have to get your legal team involved.
  prefs: []
  type: TYPE_NORMAL
- en: The IBM commercial—in Granite you should trust
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will say it again: we hope you agree that almost all of this book has been
    anything but about IBM. We hope you’ve appreciated the care we took to build your
    AI acumen, frame out the use cases, and note the things to watch out for and the
    things you’ll want to ensure you’ve got straightened out as you embark on your
    AI journey—with but one or two tiny IBM commercials. With that said, we thought
    we’d afford ourselves a page or two to focus on an open source model you’ll notice
    we haven’t spent much time on: IBM Granite. We’re very proud of the IBM Granite
    series because it hits on the very things we’ve discussed: transparency in the
    data used to train the models (check out the pages of details on the training
    data used in Granite 3 in its technical report^([1](ch08.html#id1056))); the models
    are released in the open with a no-nonsense permissive Apache 2.0 license; and
    most importantly, the Granite family is designed to have cost-efficient, fit-for-purpose
    models that can be further customized with enterprise data (we will dive into
    the details a little later in this chapter).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-1](#ch08_figure_1_1740182052159344) shows the breadth of models in
    the IBM Granite 3 family (and by the time you read this book, Granite 4 will likely
    be released, or close to it).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a high-level overview of what the models in [Figure 8-1](#ch08_figure_1_1740182052159344)
    are meant for and why they matter:'
  prefs: []
  type: TYPE_NORMAL
- en: Granite Language
  prefs: []
  type: TYPE_NORMAL
- en: These are your bread-and-butter workhorse LLMs for enterprise language tasks.
    These models deliver top performance for their size and are designed to be further
    customized using techniques like PEFT and InstructLab.
  prefs: []
  type: TYPE_NORMAL
- en: Granite Vision
  prefs: []
  type: TYPE_NORMAL
- en: These are multimodal models that are specialized on vision *understanding* tasks
    (image + prompt in, text out). Think of these for any document understanding,
    chart Q&A, like having an LLM explain trend lines and opine on things in a bar
    graph, or even multimodal RAG tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Granite Guardian
  prefs: []
  type: TYPE_NORMAL
- en: These are “guardrail” models (we discussed these in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635))
    that sit alongside any deployed LLM (not just Granite) and help monitor inputs
    to and outputs from the model, making sure there is no harmful or biased content,
    hallucinations, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Granite Embedding
  prefs: []
  type: TYPE_NORMAL
- en: These models convert large amounts of language and code into vector embeddings
    or numeric representations—this is very useful for enabling RAG workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Granite Time Series
  prefs: []
  type: TYPE_NORMAL
- en: These are very small, GenAI-based forecasting models. Instead of being trained
    on large amounts of language, these models were trained on large amounts of time
    series data points to get their predictive superpowers.
  prefs: []
  type: TYPE_NORMAL
- en: Granite Geospatial
  prefs: []
  type: TYPE_NORMAL
- en: These Earth Science multimodal models were developed in collaboration with NASA
    to predict everything from weather forecasts to the amount of biomass in a satellite
    image.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aivc_0801.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-1\. Snapshot of the IBM Granite model family
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The key tenets of IBM’s Granite models are transparency and flexibility. Every
    Granite model is released with full disclosure of the data used in training and
    under an Apache 2.0 license to provide users the maximum level of freedom of action
    to use and deploy them for their business. It is this commitment to transparency
    and openness that awarded Granite one of the highest scores in [Stanford’s Transparency
    Index ranking of LLM providers](https://oreil.ly/FQHb5).
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: Representing your Enterprise Data within an LLM'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once you have selected a trusted model starting point (in our analogy, this
    is your transparent glass filled with pristine water that you will use to make
    lemonade), the next step is to select the method by which you will add your enterprise
    data to that foundation (the sugar and lemons that turn water into lemonade).
    There are multiple techniques available, including these common patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval-augmented generation (RAG)
  prefs: []
  type: TYPE_NORMAL
- en: You might already be familiar with RAG, as it is one of the top patterns deployed
    in enterprises today. We alluded to this pattern throughout this book, but it’s
    worth explicitly talking about it here because it’s a pretty common mechanism
    to add enterprise data to an LLM. In a RAG pattern, once a query is submitted
    by a user, that query is used to retrieve relevant enterprise information from
    (typically) a database using essentially a similarity match between the text in
    the query and the text in the database. (This database is typically a vector database
    that supports semantic searching, but it could be a traditional relational database
    too, or a hybrid version of the two, and even files on an object storage service,
    among other options.) Then the original user query is concatenated with the retrieved
    information (often called the grounding context) into a prompt that is fed to
    the LLM. The LLM can now use both its vast knowledge accrued in training alongside
    the retrieved information provided in the prompt to answer the question. As you
    may have inferred, in a RAG pattern, the model weights are not touched at all,
    and this has some upsides and downsides to it. RAG is an exceptional technique,
    especially when it is important to have the very latest information available
    whenever answering a user query (it is much easier to update a supporting database
    with the latest and greatest details than to retrain or fine-tune a model with
    the updated information). However, RAG does have several downsides. First, there
    are lots of dependencies and complexities that have to be managed; RAG is not
    just a model, it’s a system. Another is that every time you want the model to
    answer a question—for example, about some internal HR policy—you need to provide
    the entire text of that HR policy to the LLM (this also drives up inferencing
    costs, over and over again). Related to this is the fact that an LLM never really
    internalizes the information that is provided in a RAG workflow, which is to say
    it isn’t learning new concepts and applying them in new ways across various tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning
  prefs: []
  type: TYPE_NORMAL
- en: Another common approach for customizing an LLM with enterprise data is fine-tuning.
    Fine-tuning is where the actual weights of the model are updated based on new
    data (those input/output training pairs we’ve referred to throughout this book).
    This approach can be done with far less compute than retraining the original model
    from scratch and with less data. This technique offers a more reasonable starting
    point for AI Value Creators to start customizing their models. There are many
    different types of fine-tuning techniques. One is called supervised fine-tuning
    (SFT), where all the parameters are updated, and another is called parameter-efficient
    fine-tuning (PEFT) where only a portion of the parameters are updated. There are
    also methods like low-rank adaptation (LoRA) where an external (to the LLM) module
    of parameters is trained to work with the base model. LoRAs are convenient because
    these modules can then be removed when they are not needed or swapped out for
    new modules when the model is doing a different task. For example, perhaps you
    run a role-playing game (RPG) company and build a LoRA adapter on top of your
    LLM for game dialog and nonplayer character interaction, but another LoRA adapter
    gets subbed in for storytelling and narration. LoRA adapters have their drawbacks
    too—as you can imagine, if you wanted 50 fine-tuned customizations, then you’re
    managing the lifecycle of 50 different adapters. We’d also speculate that since
    they use very low-rank matrices, at some point their data capacity might be limited.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of the day, the fine-tuning method you’ll eventually choose depends
    on your performance goals and cost constraints. The more parameters you target,
    the better the performance, but the more expensive it will be to train the model.
    While fine-tuning provides a way to intrinsically improve a model based on proprietary
    data, models that are fine-tuned also suffer from what is called *catastrophic
    forgetting*. This basically means that once you fine-tune a model on a task, the
    model becomes a specialist in it; that is to say, it is very good at that task,
    but it loses (forgets) some of its ability as a generalist to try and execute
    tasks it used to know how to do. This means, for every task you want to train
    your model on, you need to maintain a separate, fine-tuned version of that model
    (or in the case of LoRAs, a separate LoRA adapter for each important task).
  prefs: []
  type: TYPE_NORMAL
- en: InstructLab
  prefs: []
  type: TYPE_NORMAL
- en: InstructLab is an open source form of fine-tuning cooked up at Red Hat that
    was specifically designed for infusing proprietary enterprise knowledge back into
    an LLM in a collaborative manner while maintaining the LLM’s general-purpose capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing InstructLab
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The open source [InstructLab](https://instructlab.ai) method for tuning LLMs
    was designed from the start to address the challenges faced by AI practitioners
    who want to specialize and deploy LLMs for [specific business needs](https://github.com/instructlab).
    Not only does InstructLab facilitate specializing a model on domain-specific data,
    the goal of InstructLab is to make contributing to LLMs as easy as a developer
    might contribute to any other software project. InstructLab came about to try
    and bridge some of the gaps between how open source software works and how open
    source AI was working, and it now has both an open source presence and enterprise
    offering supported by Red Hat.
  prefs: []
  type: TYPE_NORMAL
- en: InstructLab aims to shape the future of GenAI by providing a framework to enable
    teams and communities to contribute knowledge and skill to existing LLMs in an
    accessible way. Core to InstructLab is a novel model alignment method called *Large-scale
    Alignment for chatBots* (LAB).^([2](ch08.html#id1070))
  prefs: []
  type: TYPE_NORMAL
- en: 'As we alluded to in the previous section, there are many communities rapidly
    embracing and extending permissively licensed open source AI models, but they’ve
    all been faced with three main points of friction that is a problem well solved
    for traditional open source software, namely:'
  prefs: []
  type: TYPE_NORMAL
- en: There’s no way to contribute back to those base LLMs directly
  prefs: []
  type: TYPE_NORMAL
- en: Enhancements show up as forks (search around and you’ll find an uncontrollable,
    ever-populating massive herd of Llamas—one-off, fine-tuned versions of the Llama
    LLM—roaming our GenAI world), and this forces you to choose a “best-fit” model
    that isn’t easily extensible. Also, these forks are expensive for model creators
    to maintain because what happens when the “parent” Llama changes? How do you get
    those enhancements? And we didn’t even account for sifting through the massive
    Llama herd to figure out which Llama is right for you.
  prefs: []
  type: TYPE_NORMAL
- en: There’s a high barrier to entry if you want to contribute back into a model
  prefs: []
  type: TYPE_NORMAL
- en: Did you do something special? Came up with some incredible new idea—and it works?
    You have to learn how to fork, train, and refine models to see your idea forward,
    which requires a heck of a lot of expertise.
  prefs: []
  type: TYPE_NORMAL
- en: There is no direct community governance and no best practices around review,
    curation, and distribution of forked models
  prefs: []
  type: TYPE_NORMAL
- en: Ever watch five-year-old kids play soccer? Enough said.
  prefs: []
  type: TYPE_NORMAL
- en: InstructLab solves these problems because it gives you the tools to create and
    merge contributions (skills and/or knowledge artifacts) to an LLM, without requiring
    a team with deep AI engineering skills at your disposal.
  prefs: []
  type: TYPE_NORMAL
- en: Dipping your toe into the InstructLab pool
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'InstructLab’s technology gives upstream models with sufficient infrastructure
    resources the ability to create regular builds of their customized models—not
    by rebuilding and retraining the entire model, but by infusing new skills and/or
    knowledge into it. It does this through a combination of three key processes that
    we cover in this section:'
  prefs: []
  type: TYPE_NORMAL
- en: A taxonomy-driven data curation methodology
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Synthetic data generation—at scale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An instruction-tuning method that has multiple phases and avoids catastrophic
    forgetting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The InstructLab project provides tools for developers to add and merge new skills
    and/or knowledge into any open LLM through a GitHub workflow—right from their
    laptop.
  prefs: []
  type: TYPE_NORMAL
- en: Through the InstructLab project, shown in [Figure 8-2](#ch08_figure_3_1740182052159414),
    teams can contribute LAB alignment “recipes” for new skills and/or knowledge (your
    enterprise data) through a pull request to an InstructLab project. All accepted
    skills and/or knowledge recipes are subsequently added on top of a given pretrained
    starter during the model alignment phase by the InstructLab project maintainers
    (be they with a public model or private within your company).
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a diagram of a diagram  Description automatically generated](assets/aivc_0802.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-2\. InstructLab offers a new way to make community contributions additive
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Enabling contributions in the alignment phase of model development, rather than
    investing resources into the time-consuming process of pretraining new base models,
    allows for an agile iterative development process well suited for collaboration
    within your company (or in an open community, perhaps around an industry, where
    a consortium of businesses are working together to create a model bespoke to their
    industry). We’ve seen it firsthand. Pretraining an LLM can take months and thousands
    of superexpensive GPUs, evaporating water and what’s in your wallet. In contrast,
    using InstructLab, a given LLM can often be aligned using fine-tuning methods
    in less than a day’s time, allowing for a much more rapid update release cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Can you smell what’s cooking? Skill and knowledge recipes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At its core, a skill or knowledge recipe is just a simple set of instructions
    on how to programmatically generate large amounts of labeled synthetic data (again,
    AI helping AI) that exemplifies a given skill set or area of knowledge. Each recipe
    is comprised of a short description of a skill or knowledge gap, and then five,
    or more, handcrafted examples. In the case of a knowledge recipe, the input would
    also include a knowledge source, such as a company’s benefits manual in an HR
    use case, that covers the desired topic.
  prefs: []
  type: TYPE_NORMAL
- en: These recipes are provided in the form of a prompt to a larger teacher model
    (InstructLab debuted with Mixtral-Instruct as its teacher model), which is used
    to generate a large volume of corresponding synthetic data. Why synthetic data?
    It’s a critical component of InstructLab because many companies do not have enough
    targeted data to train (using InstructLab or more standard PEFT methods) something
    as big as an LLM on their ultra-specific tasks. Synthetic data is also how InstructLab
    turns large corpuses of unstructured enterprise data into a structured dataset
    that can be used to train your model. Once this data is generated, it can be used
    to fine-tune your LLM to teach it the missing skills or knowledge you want to
    push upstream into your company’s model.
  prefs: []
  type: TYPE_NORMAL
- en: Using synthetic data to align a model isn’t a novel idea on its own. In fact,
    there are multiple examples of synthetic data being used to align models, including
    examples of model distillation (as we discussed in [Chapter 7](ch07.html#ch07_where_this_technology_is_headed_one_model_will_not_1740182051667482)).
    For example, Vicuna-13B was trained on synthetic data generated from GPT-4\. But
    again, there’s a problem. OpenAI’s terms and conditions do not support the use
    of GPT-4 for the creation of commercially competitive models, which *makes the
    viability of these models questionable.* There are other models that we could
    point you to as well, but they all require closed models like GPT-4 as their teacher
    model to generate the required synthetic data. And right here is when you get
    to how open source drives technology forward. What makes the LAB method so appealing
    is that it proves that permissibly licensed open source models (of which Apache
    2.0 is an example) can be used as teacher models and still drive state-of-the-art
    (SOTA) model performance.
  prefs: []
  type: TYPE_NORMAL
- en: To date, all skill and/or knowledge recipes contributed to the InstructLab project
    are mapped out in a logical, hierarchical InstructLab taxonomy. In simple terms,
    you can think of a taxonomy as a tree structure that organizes things into categories
    and subcategories (see [Figure 8-2](#ch08_figure_3_1740182052159414)). For InstructLab,
    a taxonomy classifies data samples into smaller groups (each branch is further
    divided into more specific levels) that ultimately support different tasks (leaves
    on a branch). This gives developers a visual framework not just to identify skills
    and knowledge that might help a project, but also a way to spot and fill gaps
    with new knowledge and skills they want to contribute.
  prefs: []
  type: TYPE_NORMAL
- en: InstructLab’s taxonomy also helps ensure that a diverse set of synthetic data
    is generated to cover all the different subtasks that might be desired when contributing
    a recipe for any one high-level task.
  prefs: []
  type: TYPE_NORMAL
- en: Consider an LLM assisting an agent with the task of writing social media posts,
    like our agentic example in the last chapter. How you post on X (formerly known
    as Twitter) is different from LinkedIn or Instagram. Some platforms need short
    forms because of character limits; emojis are more prevalent in others; some platforms
    are very image-based, while others call for more business acumen. These are writing
    skills specific to social media. In the InstructLab taxonomy snippet shown in
    [Figure 8-3](#ch08_figure_4_1740182052159436), if a contributor was trying to
    improve a model’s ability to write social media posts, they could contribute to
    the *social_media* branch (or create a new one if it didn’t exist) that falls
    under the *freeform* branch, which falls under the *writing* branch in the skills
    taxonomy. Their contributions would be synthetic data recipes for each targeted
    social media outlet. Want to make your AI become a poet? Give it different poetry
    examples and create skills that are specific to haiku, one for sonnet, another
    for limerick, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a person''s face  AI-generated content may be incorrect.](assets/aivc_0803.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-3\. An example of an InstructLab skills taxonomy for writing
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: LAB’s unique training regimen assimilates this new data during the alignment
    phase instead of the expensive pretraining phase where most LLMs are infused with
    their core knowledge and capabilities. And again, this training protocol also
    mitigates catastrophic forgetting. Quite simply, the way InstructLab works ensures
    that newly added knowledge won’t overwrite what the model learned before.
  prefs: []
  type: TYPE_NORMAL
- en: When all synthetic data recipes have been submitted and added to a project’s
    taxonomy, InstructLab’s training and generation pipeline runs all the recipes
    to generate synthetic data. It then filters that generated data down to include
    only high-quality samples, and, using a novel phased fine-tuning approach, aligns
    each of the starter models (the student models) using the generated synthetic
    data, thereby infusing the model with all of the contributed skills and knowledge.
    Since a picture is worth a thousand words, as they say, we’ve summarized this
    entire workflow in [Figure 8-4](#ch08_figure_5_1740182052159457).
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a diagram of a cube  Description automatically generated with
    medium confidence](assets/aivc_0804.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-4\. How Large-scale Alignment for chatBots (LAB) works
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Harnessing the power of the community
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To drive rapid innovation, the open source version of InstructLab has committed
    to a periodic training and release cycle for community-trained models. The latest
    versions of the InstructLab models are made publicly available on Hugging Face,
    which, as you know from the first part of this book, is the heartbeat of the world’s
    largest organized AI community. Hugging Face’s reach gives the community the ability
    to download an InstructLab-tuned model, experiment with it, and find gaps in its
    performance. Once identified, community members can build and contribute their
    own skill and knowledge recipes back to the InstructLab project through a pull
    request. As you’d expect with traditional open source projects, InstructLab committers
    and project maintainers review contributions and merge all accepted contributions
    back to the main model once a week. Of course, for your own private models, you
    can do all of this within your company and operate in the same manner.
  prefs: []
  type: TYPE_NORMAL
- en: To support developers who are using and contributing to InstructLab models,
    the InstructLab project includes a command-line interface tool called the *Language
    Model Development Kit* (LMDK). LMDK implements the InstructLab workflow on a contributor’s
    laptop.Think of it as a test kitchen for trying out and submitting new recipes
    for generating synthetic data to teach an LLM new skills. Now a developer is up
    and running in an instant, and perhaps they start experimenting with a local version
    of their open sourced LLM (like Granite). They may find some gaps or areas in
    the model’s performance they want to improve, cook up some knowledge or skill
    recipes to fill them in, and voilà! This entire process (as shown in [Figure 8-5](#ch08_figure_6_1740182052159477))
    acts like a flywheel for rapid open source AI innovation.
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a process  AI-generated content may be incorrect.](assets/aivc_0805.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-5\. The InstructLab innovation cycle: a flywheel for rapid open source
    innovation'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A day in the life of an InstructLab contributor
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we said earlier, it’s outside the scope of this book to take you through
    the whole InstructLab process, but there are a lot of [tutorials](https://oreil.ly/1MOTp)
    you can easily find with step-by-step instructions that will turn you into a hero
    contributor in no time.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-4](#ch08_figure_5_1740182052159457) gave you an idea of the aspects
    of being an InstructLab contributor, and as you’ve figured out by now, it all
    starts with a skills recipe. The following code shows you what a rhyming skill
    recipe actually looks like (it’s written in YAML):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Next, using the local version of InstructLab’s synthetic data generator, you’d
    create your own synthetic alignment data for the skill or knowledge you are building.
    This data can then be used to align your own local version of your model and quickly
    test it to see if your contribution is closing a gap. You can keep experimenting
    with this process until your model can perform the task you’re after. Once your
    recipe is perfected in LMDK, you submit it as a pull request to the InstructLab
    taxonomy on GitHub, as you would any other open source or internal software project.
    Next, a group of committers accept or deny submissions, updating the final taxonomy
    with the new YAML files. (Again, this scenario could be publicly external or fully
    internal to your company.)
  prefs: []
  type: TYPE_NORMAL
- en: The final step of InstructLab is the build process, which can be run on a regular
    basis, periodically updating your LLM with (for example) the latest and greatest
    contributions from your developer community. In this build process, all of the
    synthetic data generated to date gets aggregated and is used in a multistage training
    process designed to maximize performance and reduce issues like catastrophic forgetting.
    When the new build of your model is available, you now have an LLM, customized
    on all of the enterprise data submitted by your developers and domain SMEs.
  prefs: []
  type: TYPE_NORMAL
- en: While we are still in the early days of InstructLab, we are seeing that this
    end-to-end process of specializing small models on enterprise data can drive both
    performance (higher is better) improvements *and* significant cost reductions,
    when compared to using a large general-purpose model alone, as shown in [Figure 8-6](#ch08_figure_7_1740182052159496).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In scenarios that involve highly sensitive organizational information—such as
    employee health or disciplinary records—embedding that sensitive data directly
    into an LLM likely isn’t something you want to do. Instead, you can use your data
    to customize your LLM via InstructLab and align it closely with your company’s
    branding, style, cultural values, etc., and separately store that sensitive information
    securely within a RAG system with controlled access. This approach allows your
    tailored LLM to seamlessly and securely access sensitive data only when needed,
    ensuring both enhanced communication and strict data confidentiality. Likewise,
    if you had data in a domain that was constantly changing or where the use case
    required the most up-to-date data, RAG likely makes more sense for that data too.
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of sales and sales  Description automatically generated with medium
    confidence](assets/aivc_0806.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-6\. Demonstrating the impact of InstructLab
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Step 3: The Grand Finale: Deployment and Experimentation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There’s no sense in having a trusted LLM enriched with your data if no one in
    your company can use it. This makes the final step all about deploying your new-age
    data representation value creation asset. So, what’s needed to make this real?
    A lot of experimentation. If you think back to every previous transformative technology
    (like the internet), history has shown there is also a transition point from experimenting
    to deploying at scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is incredible excitement, anticipation, and expectation surrounding GenAI
    and agents in our world today. We see applications and APIs that can impact hundreds
    of millions of consumers. Indeed, the type of excitement being generated could
    be compared to the advent of the internet browser (that Netscape moment we talked
    about in [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)).
    But, if you think about this internet comparison, enterprise value wasn’t unlocked
    the instant Netscape came out. It wasn’t until the internet glued together everything:
    from inventories to supply chains all the way to the frontend and omnichannel.
    We think AI will undergo that same evolution: +AI to AI+.'
  prefs: []
  type: TYPE_NORMAL
- en: To unlock AI’s value in the enterprise, you need to be able to target the same
    deployment at scale across an enterprise. But to get there, you will need a governed
    environment that allows for experimentation, customizing your models through key
    workflows like RAG, fine-tuning, and InstructLab, and then transitioning those
    models to deployment at scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'Importantly, as your customized models are now representations of valuable
    enterprise intellectual property (IP), there are key business decisions that will
    need to be made at the time of deployment. Decisions like: can you trust your
    model to live in the cloud, or is the data that is represented by your model sensitive
    enough that it can only be deployed on premises? Do you need those proactive and
    reactive guardrails we talked about in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)
    to make sure your applications using these models are not abused? Do you need
    to actively monitor the performance and safety of your deployments? And as GenAI
    permeates throughout your enterprise, you’re expanding the surface attack area
    for digital exploitation, so (again, from [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635))
    you’re going to have to think about adversarial attacks and other new ways bad
    actors might try to exploit your digital masterpiece.'
  prefs: []
  type: TYPE_NORMAL
- en: The Future Is Open, Collaborative, and Customizable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Much of the internet is built on open source software. Every day, whether you
    realize it or not, you’re interacting with a Linux operating system, and an Apache
    web server is helping you accomplish your goals. Today, open source software also
    powers smartphones running on Android operating systems and the Secure Sockets
    Layer (SSL) cryptographic protocol that secures millions of financial transactions
    every day. We’re telling you that open, community-built, and enterprise-customized
    LLMs can bring some of the same benefits. Putting LLM weights out for the world
    to see gives everyone the chance to innovate, test, refine, and shape the future
    of this powerful technology. Allowing builders to understand the data provenance
    fosters trust and provides explainability.
  prefs: []
  type: TYPE_NORMAL
- en: Transparent open source software makes systems more stable and secure. That
    can lead to faster, more predictable release cycles, and safer AI-related software.
    Improving LLM trust and transparency is one of the top goals of the InstructLab
    project.
  prefs: []
  type: TYPE_NORMAL
- en: Open source software also encourages the kind of healthy competition that prevents
    one or two companies from monopolizing the industry. When everyone is allowed
    to participate, innovation thrives and costs to consumers typically drop.
  prefs: []
  type: TYPE_NORMAL
- en: You’ve now unlocked the secret to turning your data into your competitive superpower.
    But before you dash off to dominate your industry (or at least impress your colleagues),
    let’s wrap up by gazing into our non-AI powered crystal ball (it’s just our thoughts,
    we don’t really have one) and take an educated guess at what wild adventures await
    the ever-evolving landscape of Gen AI and agents.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch08.html#id1056-marker)) Granite Team, IBM, “Granite 3.0 Language Models,”
    2023, [*https://ibm.biz/granite-report*.](https://ibm.biz/granite-report)
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](ch08.html#id1070-marker)) Shivchander Sudalairaj et al., “LAB: Large-Scale
    Alignment for ChatBots,” preprint, arXiv, April 29, 2024, [*https://arxiv.org/abs/2403.01081*](https://arxiv.org/abs/2403.01081).'
  prefs: []
  type: TYPE_NORMAL
