- en: Chapter 8\. Using Your Data as a Differentiator
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章\. 利用你的数据作为差异化因素
- en: In the last chapter, we spent some time giving you a point of view on the power
    (and potential) of small language models (SLMs). We introduced the notion that
    one model doesn’t have to—and won’t—rule them all. We outlined how humongous models
    are clunky to operate, expensive, and center power on the few (vendors) that can
    afford to build them. But, what’s more, they won’t help you take advantage of
    your data (unless you give it away) to generate value tailored to your business—in
    short, they help you to be an AI User as opposed to an AI Value Creator. We posit,
    and will continue to prove, how highly focused models can do some incredible things.
    We want to see an AI future that is open; hence, we oppose the notion that one
    super LLM (large language model) should rule them all.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们花了一些时间给你介绍关于小型语言模型（SLMs）的力量（和潜力）的观点。我们提出了一个观点，即一个模型不必——也不会——统治所有模型。我们概述了巨大的模型操作起来笨拙、昂贵，并且权力集中在少数（供应商）手中，他们能够负担得起构建它们。但是，更重要的是，它们不会帮助你利用你的数据（除非你将其放弃）来生成适合你业务的定制价值——简而言之，它们帮助你成为一个AI用户，而不是AI价值创造者。我们认为，高度专注的模型可以做些令人难以置信的事情，我们将继续证明这一点。我们希望看到一个开放的AI未来；因此，我们反对一个超级LLM（大型语言模型）应该统治所有模型的观点。
- en: 'A fundamental premise of this book is the only way for you to become an AI
    Value Creator is to first see your data as a dormant superpower. To maximize what
    you can do with AI and create value, we believe big bets must be placed on fostering
    a collaborative ecosystem across your company that can put your data to work,
    creating value for *you*. In fact, we think this notion is so important, it literally
    became the title of this book: *AI Value Creators*.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的一个基本前提是，你成为AI价值创造者的唯一方式是首先将你的数据视为一种沉睡的超级力量。为了最大限度地利用AI并创造价值，我们相信必须在你公司内部建立一个协作生态系统，以便利用你的数据，为你创造价值。事实上，我们认为这个观点非常重要，它甚至成为了本书的标题：*AI价值创造者*。
- en: 'In this chapter, we look at how developers and domain experts in your company
    can leverage new techniques in model customization to contribute to your company’s
    Gen AI models, driving defensible and differentiated AI innovation for *your*
    business: create value.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨你的公司中的开发人员和领域专家如何利用模型定制的最新技术来为你的公司的Gen AI模型做出贡献，为你的业务驱动可防御和差异化的AI创新：创造价值。
- en: 'Customizing Open Source for the Enterprise: A New Way of Looking at Enterprise
    Data'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为企业定制开源：一种看待企业数据的新方法
- en: As we noted earlier in this book, less than 1% of enterprise data resides in
    today’s LLMs. And if you’re going to become the AI Value Creator that this book
    was written to help you become, you’re going to have to work in your most valuable
    asset (your enterprise data) and have it part of your LLM strategy—ultimately
    unlocking a plethora of value creation opportunities.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如本书前面所述，不到1%的企业数据存储在当今的LLMs（大型语言模型）中。如果你想要成为本书旨在帮助你成为的AI价值创造者，你将不得不在你的最有价值资产（你的企业数据）上工作，并使其成为你的LLM策略的一部分——最终解锁大量的价值创造机会。
- en: To really understand how profound this is, let’s time-travel back to the origin
    of our digital world, an origin that was understood and conceptualized almost
    350 years ago by Gottfried Wilhelm Leibniz. Even back then, Leibniz already understood
    that you could take the information that was available around us in the form of
    language or mathematics and encode it in a binary representation. (Leibniz not
    only created binary math, but he also help to create calculus, so we can see why
    some of you may not be fans.) He famously said, “To create everything, one thing
    is sufficient.” Leibniz clearly knew the value and the power of representing information
    differently (in this case, binary notation). Fast-forward to today and you’ll
    easily note that the last few decades have seen a tremendous amount of value creation
    and business transformation driven by the evolution and expressiveness of our
    world’s data representations. For example, today, taste and smells have data representations,
    ultimately represented by numbers that further translate into just ones and zeros
    by the time a computer starts working on the data. In fact, perfume and flavor
    houses literally discover and propose new products using vectors to represent
    lemon-fresh or honey butter. Think about it. Who but AI could have ever thought
    of creating Everything Bagel ice cream! Truth be told, long before LLMs came along,
    wine and perfume descriptions have been entertaining us with their poetic (and
    often ridiculous) creativity for years. Because let’s be honest, who really smells
    “a whisper of sun-kissed elderflower on a dewy morning” or tastes “hints of melancholy
    with a bold finish of existential crisis”? Going forward, expect the creativity
    to go to new (polite for “potentially even more ridiculous”) levels thanks to
    LLMs.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 要真正理解这一点有多么深刻，让我们回到我们数字世界的起源，这个起源几乎350年前就被戈特弗里德·威廉·莱布尼茨所理解和构想。即使在那时，莱布尼茨已经明白，你可以将我们周围以语言或数学形式存在的所有信息编码成二进制表示。
    (莱布尼茨不仅创造了二进制数学，还帮助创立了微积分，所以我们也可以理解为什么有些人可能不是他的粉丝。) 他著名地说：“创造一切，只需一件事就足够了。” 莱布尼茨显然知道以不同方式（在这种情况下，二进制表示）表示信息的价值和力量。快进到今天，你很容易就会注意到，在过去的几十年里，由于我们世界数据表示的演变和表现力，已经创造了巨大的价值创造和商业转型。例如，今天，味道和气味都有数据表示，最终在计算机开始处理数据时，这些数据被进一步转换成仅仅是零和一。事实上，香水和调味品公司实际上使用向量来发现和提出新的产品，这些产品代表柠檬清新或蜂蜜黄油。想想看。除了人工智能，还有谁能想到创造一切贝果冰淇淋！说实话，在LLM出现之前，葡萄酒和香水描述已经用它们诗意的（以及常常荒谬的）创造力娱乐了我们多年。因为让我们说实话，谁真的能闻到“清晨露水中的阳光亲吻的金银花轻吟”或尝到“带有存在主义危机大胆结束的忧郁暗示”？展望未来，由于LLM，我们期待创造力达到新的（礼貌地说，“可能甚至更荒谬”）水平。
- en: 'The Original Eras Tour: Looking Back a Few Decades on Data Representations'
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 原始的Eras巡演：回顾数据表示的几个十年
- en: Over the last decades, new representations of data have created completely new
    opportunities and capabilities for all businesses and industries. We thought it
    worthwhile to spend some time on this topic to help you fully appreciate an LLM’s
    value for your enterprise—*especially* when it’s nuanced with your data. The point
    is that your enterprise data can be folded into this new data representation (an
    LLM) that can make your data usable in ways that only movies could have imagined
    just a few years ago, and that can bring enormous amounts of value to your company.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几十年里，新的数据表示为所有企业和行业创造了全新的机会和能力。我们认为花些时间在这个话题上是有价值的，帮助你充分认识到LLM对你企业的价值——*尤其是*当它与你的数据相结合时。关键在于，你的企业数据可以融入这种新的数据表示（一个LLM），它可以使你的数据以只有电影几年前能想象到的方式变得可用，并为你的公司带来巨大的价值。
- en: When you think about it, aside from the weights in a model, AI is just compressed
    data. It’s just a new representation of that data and, as it turns out, over the
    last decades, there have been various epochs of data representations, each one
    unlocking a new era of value creation. This current AI revolution has *a lot*
    to do with the power of data representations and the power of being able to encode
    incredible amounts of information, of every possible form, inside these new, incredibly
    capable “vessels” that are foundation models (LLMs). Here is how we see some of
    those data representation eras over the years.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当你这么想的时候，除了模型中的权重之外，人工智能只是压缩的数据。它只是数据的新表示形式，而且正如所证明的，在过去的几十年里，已经有过各种数据表示时代，每个时代都开启了一个新的价值创造时代。这次人工智能革命与数据表示的力量以及能够在这些新、强大的“容器”中编码大量信息的力量有很大关系，这些“容器”是基础模型（LLMs）。以下是我们如何看到这些年来的一些数据表示时代。
- en: 'Up to the 1980s: Expert systems'
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 到1980年代：专家系统
- en: These were (and since they are still used today, perhaps we should have written
    “are”) *handcrafted symbolic representations of our data*. Data was encoded in
    a relational database, which created a new way in which businesses could organize
    and connect to data in a way they couldn’t easily do before. This era had a very
    profound impact on business. Suddenly, a company could automate things like payroll,
    transactions could connect to inventories, and other core processes. Along the
    way, expert systems were created. Humans wrote rules for logical business flows
    with connected structured data. A great example is fraud detection or supply chain
    management—and many companies still use this method today—there’s a rule and if
    breached, a flag appears or an action is undertaken.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是（并且由于它们今天仍在使用，也许我们应该写成“是”），*我们数据的手工制作的符号表示*。数据被编码在关系型数据库中，这创造了一种新的方式，让企业能够以他们以前无法轻松做到的方式组织和连接数据。这个时代对商业产生了深远的影响。突然之间，一家公司可以自动化像工资支付这样的东西，交易可以连接到库存，以及其他核心流程。在这个过程中，创建了专家系统。人类为连接的结构化数据编写了逻辑业务流程的规则。一个很好的例子是欺诈检测或供应链管理——许多公司今天仍在使用这种方法——有一条规则，如果被违反，就会显示一个标志或采取行动。
- en: Rules are great for a subset of things, but they aren’t all that creative and
    there are always exceptions, so they can only really get so much right. On the
    backend of a rules-based system is a lot of manual effort to maintain and build
    those rules. A new rule must be written for each individual situation. (This is
    why we call this representational era handcrafted. For example, storing data in
    a relational database required a DBA to handcraft a schema to receive it. Humans
    do a lot of the work and a lot of the thinking around the design of that work
    too.) Perhaps a way to spot potential credit card fraud at a gas station was with
    a $1 purchase...new rule. Over time, that rule got diluted as a predictor, and
    some other indicator proved useful...new rule. It’s a simple example, but it used
    to happen all the time (or it didn’t, and companies would get frustrated). In
    the end, these systems worked as long as the rules were right. But over time,
    there were so many variations and rules that most of these systems collapsed on
    themselves. Now think about today’s digital economy—how can a rules-based system
    respond to threats from increased access points and complex transactions, identify
    signals left by perpetrators hidden in noisy and ephemeral daily activity, or
    respond to coordinated attacks with consolidated monitoring in a timely fashion?
    They can’t.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 规则对于某些事物来说很有效，但它们并不那么有创造性，而且总有例外，因此它们只能做到这么正确。基于规则的系统在后台需要大量的手动工作来维护和构建这些规则。每个个别情况都需要编写一条新规则。（这就是为什么我们称这个表示时代为手工制作的。例如，将数据存储在关系型数据库中需要数据库管理员手工创建一个模式来接收它。人类在工作的设计和思考方面做了大量工作。）也许在加油站用1美元购买东西就能发现潜在的信用卡欺诈……新规则。随着时间的推移，这条规则作为预测因素被稀释，而其他一些指标被证明是有用的……新规则。这是一个简单的例子，但这种情况过去经常发生（或者没有发生，公司会感到沮丧）。最终，这些系统只要规则正确就能工作。但随着时间的推移，有如此多的变化和规则，大多数这些系统最终都崩溃了。现在想想今天的数字经济——基于规则的系统如何应对增加的接入点和复杂交易带来的威胁，如何识别隐藏在嘈杂和短暂日常活动中的犯罪者留下的信号，或者如何及时对协调攻击进行集中监控？它们做不到。
- en: '1980s to ~2010: Machine learning'
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1980年代至2010年代：机器学习
- en: Now we move into an era of *more task-specific, less handcrafted feature representations
    of our data*. How did this happen? Because as more data became available, there
    was a shift toward data-driven approaches. It was a really big thing back then,
    because machines started to generate their own rules from that data and learn
    new representations of our world by being shown examples of it, as opposed to
    being given hand-coded rules (programmatically). Very cool! Many of these techniques
    are still used by data scientists today; for example, decision trees, support
    vector machines (SVMs), k-nearest neighbor, and more. This era was about learning
    how to get computers to help build features and getting those machines to learn
    from their insights. Those learnings were good, perhaps great. And while machines
    (with the help of humans) were using data in new ways, new representations and
    encoding mechanisms emerged—for example, graph-based representations of data (represented
    as networks with nodes and edges). Suddenly, the world starting using this new
    data representation and found a way to traverse it and it became critical to businesses
    doing things like internet search, social media, and connecting people and groups.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们进入了一个*更专注于特定任务、更少手工制作特征表示数据*的时代。这是怎么发生的呢？因为随着数据的增多，数据驱动的方法开始转变。这在当时是一件大事，因为机器开始从数据中生成自己的规则，并通过展示示例来学习我们世界的新的表示，而不是被给予手编的规则（程序化）。非常酷！许多这些技术至今仍被数据科学家们使用；例如，决策树、支持向量机（SVMs）、k-最近邻等。这个时代是关于学习如何让计算机帮助构建特征，并让这些机器从它们的洞察中学习。这些学习是好的，也许是非常好的。当机器（在人类的帮助下）以新的方式使用数据时，新的表示和编码机制出现了——例如，基于图的数据表示（表示为具有节点和边的网络）。突然之间，世界开始使用这种新的数据表示，并找到了一种遍历它的方法，这对进行互联网搜索、社交媒体和连接人与群体等业务变得至关重要。
- en: '2010 to ~2017: Deep learning'
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2010年到~2017年：深度学习
- en: 'Now we move into the big data era (remember those 3 Vs: volume, velocity, and
    variety). Computers could now access more data than ever. Now computers didn’t
    just discover but could create new data representations. Enter the world of *task-specific
    learned feature* *representations of our data*. In this era, the world got access
    to massive amounts of compute (thanks to the cloud and GPUs) and ever-increasing
    amounts of data (thanks to the internet). Computers created and built feature
    representations, but everything was still heavily reliant on human expertise and
    loads of manual efforts. Things like the availability of resources to process
    more data and a lack of capabilities to build more complex models were still “getting
    in the way.” For example, AI for natural language processing (NLP) didn’t have
    much of a memory beyond a few words.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们进入了大数据时代（记得那些3V：体积、速度和多样性）。计算机现在可以访问比以往更多的数据。现在计算机不仅发现了数据，还能创建新的数据表示。进入了我们的数据*特定任务学习特征表示*的世界。在这个时代，世界获得了访问大量计算资源的机会（得益于云和GPU）和不断增长的数据量（得益于互联网）。计算机创建并构建了特征表示，但一切仍然高度依赖于人类的专长和大量的手动工作。例如，处理更多数据的资源可用性和构建更复杂模型的能力不足仍然“阻碍了”发展。例如，自然语言处理（NLP）的AI没有多少记忆，超出了几个单词的范围。
- en: This was the start of the deep learning era. There are many things beyond the
    scope of this book, like activation functions, that came to life to help this
    era. We had the synergistic combination of more and more data (starting from the
    big data era, when the world was busy collecting data) and compute (namely, it
    was discovered the GPUs we used for gaming could provide powerful processing capabilities
    because of the way they handle matrix math, which is the math deep learning does).
    Now some very cool things started to happen in this era, perhaps not magical (yet...that’s
    the next phase). All that math-computer power (GPUs to build the representations)
    got mixed with a consumability model (the cloud) and suddenly anyone could build
    AI models for less than the cost of a cheap cup of coffee. In this era, computers
    started to learn from massive amounts of data and build out task-specific feature
    representations; for example, computer vision to detect anomalies in an X-ray
    or a defect in a weld point on a production line, and so on. Some of those feature
    representations were wildly complex and the computers invented new composite features,
    like mixing together gender, location, height, and profession into a coarsified
    feature that would describe something.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这标志着深度学习时代的开始。有许多内容超出了这本书的范围，例如激活函数，它们的出现是为了帮助这个时代。我们有了更多和更多数据的协同组合（从大数据时代开始，当时世界正忙于收集数据），以及计算能力（特别是，我们发现我们用于游戏的GPU由于处理矩阵数学的方式，能够提供强大的处理能力，这是深度学习所使用的数学）。现在，这个时代开始发生一些非常酷的事情，也许还不是魔法般（那将是下一个阶段）。所有那些数学-计算机能力（用于构建表示的GPU）与可消费模式（云）混合在一起，突然之间，任何人都可以以低于一杯廉价咖啡的成本构建AI模型。在这个时代，计算机开始从大量数据中学习，并构建特定任务的特性表示；例如，计算机视觉用于检测X光片中的异常或生产线焊接点的缺陷等。其中一些特性表示非常复杂，计算机发明了新的复合特性，例如将性别、位置、身高和职业混合成一个粗略的特征，以描述某物。
- en: 'Today: Foundation models (aka LLMs)'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 今天：基础模型（也称为LLMs）
- en: Today, we can *encode any knowledge form and work with that data in ways we
    never imagined*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我们可以*编码任何知识形式，并以我们从未想象过的方式处理这些数据*。
- en: Like we said earlier, foundation models are all about the power to encode incredible
    amounts of information of every possible form inside these new incredible model
    types. Our world has entered the era of LLMs where the approach not only takes
    advantage of massive compute capability and all that data, but a new technology
    (self-supervised learning at scale—thanks to transformers) drastically reduced
    the amount of curated labeled data needed to train a model. This is a massive
    departure from the past.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所说的，基础模型的核心是能够在这些新的、令人惊叹的模型类型中编码各种形式的大量信息。我们的世界已经进入了LLMs的时代，这种方法不仅利用了巨大的计算能力和所有这些数据，而且一种新技术（大规模的自监督学习——多亏了transformers）大幅减少了训练模型所需的精心标注的数据量。这与过去有巨大的不同。
- en: Specifically, this new data representation is trained on vast, immense datasets
    and can fulfill a broad range of general tasks. These new data representations
    (LLMs) serve as the base or building blocks for crafting more specialized applications.
    Their flexibility and massive size set them apart from the previous era’s representations,
    which were trained on limited datasets to accomplish specific tasks.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，这种新的数据表示是在庞大的、巨大的数据集上训练的，并且能够完成广泛的通用任务。这些新的数据表示（LLMs）作为构建更专业应用的基石或构建块。它们的灵活性和庞大的规模使它们区别于之前时代的表示，后者是在有限的数据集上训练以完成特定任务的。
- en: These new data representations are created by taking training data and breaking
    it down into smaller chunks, which are referred to as *tokens* (a token can be
    a word or a fragment of a word). This process creates trillions of these tokens,
    which are then converted into a vector, and those vectors are used to represent
    the tokens in a form an AI can understand. But these tokens can be anything, and
    as you’ve learned earlier, that means the data stored inside doesn’t have to be
    words—it can be anything (code, images, sound, taste and smell profiles, and more).
    As these tokens (not converted to vectors) pass through the layers of the neural
    network during training, a series of mathematical operations, which are mostly
    made up of matrix multiplications and a few other simple operations, are applied—but
    this is all done at a massive scale. During this build phase, data is combined
    and recombined across changing sequences of these tokens. In fact, information
    from different modalities (audio and text) can be combined into the same foundation
    model during training. A great example of this is OpenAI’s latest GPT that combines
    the power of text and image generation (from their DALL-E model) in one place.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些新的数据表示是通过将训练数据分解成更小的块来创建的，这些块被称为*标记*（一个标记可以是一个单词或一个单词的片段）。这个过程创建了数万亿这样的标记，然后这些标记被转换成向量，这些向量被用来以AI可以理解的形式表示标记。但这些标记可以是任何东西，正如你之前所学的，这意味着存储在其中的数据不一定是单词——它可以是一切（代码、图像、声音、味觉和嗅觉特征等）。在训练过程中，这些（未转换为向量的）标记通过神经网络的不同层，应用了一系列数学运算，这些运算主要由矩阵乘法和一些其他简单运算组成——但这都是在巨大的规模上完成的。在这个构建阶段，数据会在这些标记不断变化的序列中组合和重新组合。实际上，不同模态（音频和文本）的信息可以在训练期间结合到同一个基础模型中。一个很好的例子是OpenAI最新的GPT，它将文本和图像生成的力量（来自他们的DALL-E模型）结合在一个地方。
- en: During training, network parameters get adjusted so the outputted LLMs get better
    and better at representing the sequences of the input tokens. And as it goes through
    this training process, the model learns more and more of the structure of the
    data it’s being trained on, its nuances, and the knowledge and correlations within.
    Again, it’s not really magic; it’s just math, human ingenuity, and a lot of computing
    power.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，网络参数会进行调整，以便输出的LLM在表示输入标记的序列方面变得越来越好。随着它通过这个训练过程，模型会越来越多地学习它所训练的数据的结构、细微差别以及其中的知识和相关性。再次强调，这并不是真正的魔法；这只是数学、人类的创造力以及大量的计算能力。
- en: Now the power of this new data representation, which is encoded within an LLM,
    derives its capability from its scale (the sheer amount of data that can be brought
    into it), from its connectivity of the data (semantic connections are made across
    wide disparate input data, which makes them very expressive), and from its multimodality.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这个新的数据表示（编码在LLM中）的能力来源于其规模（可以带入其中的数据量），来源于数据的连通性（在广泛不同的输入数据之间建立语义连接，这使得它们非常具有表现力），以及其多模态性。
- en: 'Now here’s our observation and the reason for this chapter. Over the last couple
    of years, we’ve witnessed these representations pretty much take all the public
    data that’s available in the world and pull it inside an LLM. For the sake of
    argument, let’s assume 100% of that kind of data has made its way into an LLM.
    Now contrast this with our previously shared estimate that barely 1% of enterprise
    data has made its way into an off-the-shelf LLM. This is a very interesting contrast:
    almost all public data has made its way in, and almost all enterprise data has
    not.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下我们的观察和本章的原因。在过去的几年里，我们见证了这些表示方法几乎将世界上所有可用的公共数据都拉入了一个大型语言模型（LLM）中。为了辩论的目的，让我们假设100%的这种数据已经进入了LLM。现在，将这一点与我们之前分享的估计进行对比，即仅有不到1%的企业数据进入了现成的LLM。这是一个非常有趣的对比：几乎所有公共数据都进入了，而几乎所有企业数据都没有。
- en: Stand Up and Represent!...Your Data
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 站起来并代表！...你的数据
- en: By this point in the book, you should have a sense of just how much of an inflection
    point the era of AI really is. Data collected at enormous volumes is a problem
    well-solved (understanding it is a different problem), and compute is available
    en masse—these forces synergized with new AI techniques that made for a perfect
    storm for AI disruption. So how do you get started putting your data to work?
    As we discussed in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635),
    you have to start with a trusted LLM. Once you’ve identified a base model that
    you can trust, it’s time to get your enterprise data into this era’s data-powerful
    representation. Finally, you deploy your customized model and scale and create
    value with your AI. So, let’s talk about these three steps.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 到这本书的这一部分，你应该对AI时代真正是一个转折点有一个感觉。收集的大量数据是一个已经解决的问题（理解它是一个不同的问题），计算资源大量可用——这些力量与新的AI技术相结合，为AI颠覆创造了完美的风暴。那么，你如何开始使用你的数据呢？正如我们在[第五章](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)中讨论的那样，你必须从一个值得信赖的LLM开始。一旦你确定了一个你可以信赖的基础模型，就是时候将你的企业数据带入这个时代的数据强大表示了。最后，你部署你的定制模型，通过AI进行扩展并创造价值。所以，让我们来谈谈这三个步骤。
- en: 'Step 1: It All Starts with Trust'
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步：一切始于信任
- en: 'Do not underestimate this turning point for AI: everything in AI will be different
    from here on out because of this latest representational format.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 不要低估这个AI的转折点：从现在开始，AI中的所有东西都将因为这种最新的表示格式而有所不同。
- en: Ultimately, to create value from your enterprise data, the very first step has
    nothing to do with your data at all. Your first step will be to select a trusted
    model—think of it as a “value” vessel, or foundation—to build upon. This step
    is critical because your enterprise data will be added on top of this starting
    point, so it’ll be quite beneficial to know what is already inside that foundation,
    the “recipe” used to make it, and how it works. This all goes back to [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974),
    where we told you to ask your LLM vendor questions like, “What data did you use
    to train your model?” and consider answers like “It’s none of your business” and
    “We don’t know” as unacceptable. Again, is this really any different than where
    you choose to build a house? The foundation has to be solid. Does your foundation
    (LLM) contain copyright infringement, hate, anger, profanity (HAP), bias, racism,
    pornography, and more? If today’s LLMs are compressed representations of the internet,
    and you believe everything on the internet is true, there is no harmful content,
    and you have none of these concerns, then you’re good to go! Have you ever gone
    through a Reddit thread and seen the toxicity in some of those groups? (And it’s
    far worse in the rooms we don’t go into.) Is that what you want to mix your precious
    data with when you try to put it to work? This will be at the core of the model
    that will ultimately be enriched to represent your business!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，要从企业数据中创造价值，第一步与你的数据毫无关系。你的第一步将是选择一个值得信赖的模型——把它想象成一个“价值”容器，或者基础，来构建其上。这一步至关重要，因为你的企业数据将添加到这个起点之上，因此了解这个基础中已经包含的内容，制作它的“配方”，以及它是如何工作的，将非常有好处。这一切都回到了[第一章](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)，在那里我们告诉你要向你的LLM供应商提出问题，比如，“你用了什么数据来训练你的模型？”并将“这不关你的事”和“我们不知道”这样的回答视为不可接受。再次强调，这难道不是与你选择在哪里建造房子的地方有什么不同吗？基础必须坚固。你的基础（LLM）是否包含版权侵权、仇恨、愤怒、亵渎（HAP）、偏见、种族主义、色情等内容？如果今天的LLM是互联网的压缩表示，而你相信互联网上的所有内容都是真实的，没有有害内容，你没有任何这些担忧，那么你可以继续前进！你有没有经历过Reddit的某个帖子，看到其中一些群体中的毒性？（而且我们不去的房间里情况更糟。）当你试图使用这些数据时，你希望将它们与这些内容混合吗？这将最终成为代表你业务的模型的基石！
- en: 'Let’s get into the why, building on the same water quality analogy we used
    in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)
    when we discussed the importance of transparency of data lineage in an LLM. Imagine
    that we give you a glass of water (an LLM) and your intent is to add lemon juice
    and sugar (we’ll consider this your enterprise data) with the goal of making lemonade.
    If we gave you an opaque glass full of water (an LLM for which you know nothing
    about the data, and when you ask where did we get the water from, you’re not given
    any straight answers), would you feel comfortable using it with your fresh lemons
    and expensive organic cane sugar? Think about it: the glass is opaque, you can’t
    even see inside it! The water inside that glass could pure spring water, but it
    could also be cloudy and murky puddle water, or even contaminated water! If you
    couldn’t see inside that glass, would you still drink what’s inside it after adding
    tons of high-quality sugar and lemon to it? Probably not, so why would you do
    this with one of your company’s most previous assets—your data?'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨原因，基于我们在[第五章](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)中使用过的相同水质类比，当时我们讨论了在LLM（大型语言模型）中数据血缘透明度的重要性。想象一下，我们给你一杯水（一个LLM），你的意图是加入柠檬汁和糖（我们将这视为你的企业数据），目标是制作柠檬水。如果我们给你一个不透明的装满水的玻璃杯（一个你对数据一无所知的LLM，当你问我们从哪里得到水时，你得不到任何直接的回答），你会感到舒服地使用它来搭配你新鲜柠檬和昂贵的有机甘蔗糖吗？想想看：这个玻璃杯是不透明的，你甚至看不到里面！里面的水可能是纯净的泉水，也可能是混浊的泥潭水，甚至可能是受污染的水！如果你看不到这个玻璃杯里面的东西，你还会在加入大量高品质的糖和柠檬后喝里面的东西吗？可能不会，那么为什么你要用你公司最宝贵的资产之一——你的数据来做这样的事情呢？
- en: Similarly, with LLMs, it is nearly impossible to isolate or constrain a model
    to give responses informed by the enterprise data that you added and have it ignore
    all that cloudy murky water (data) that’s in the glass. Sure, techniques like
    retrieval-augmented generation (RAG) and fine-turning can help, but even when
    your model is customized, it is most likely still going to inherit some degree
    of performance and safety (or lack thereof) characteristics from the base model
    you used as a starting point.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在使用LLM时，几乎不可能隔离或限制一个模型，使其根据你添加的企业数据提供有见地的回答，同时忽略玻璃杯中所有那些混浊的水（数据）。当然，检索增强生成（RAG）和微调等技术可以帮助，但即使你的模型被定制，它仍然很可能会从你作为起点使用的基模型继承一些程度的表现力和安全性（或缺乏这些）特征。
- en: In this analogy, it’s important that *the glass you’re handed to make lemonade
    is transparent* so that you can see inside of it. You need to know where the water
    is coming from that serves as the base for your lemonade so that when you mix
    your ingredients together, you have a good idea of what’s going to happen, how
    it will look, and how it’s going to taste. It’s the same when you want to put
    your data to work with an LLM. You need a base model that is transparent in terms
    of what data was used and the recipe used to make it. That way, when you add your
    data to it, you do so confidently, safely, and securely.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个类比中，重要的是你用来制作柠檬水的玻璃杯必须是透明的，这样你才能看到里面。你需要知道为你的柠檬水提供基础的水是从哪里来的，这样当你混合你的原料时，你就有了一个很好的想法，知道会发生什么，它看起来会怎样，它的味道会怎样。当你想用LLM来利用你的数据时，情况也是一样的。你需要一个基础模型，它在数据使用和制作它的配方方面是透明的。这样，当你将你的数据添加到其中时，你就可以自信、安全、可靠地这样做。
- en: Another aspect of transparency is having broad commercial rights and freedom
    of action for the final model that is created. Remember, this chapter *is not*
    a chapter about model providers; it is a chapter about *your* data. You need to
    have permissive rights for your enhanced model so that when you encode your information
    into the model you choose for your business, you have *full freedom of action*
    to do what you need to do for your business. And, because you’re building on top
    of a model that has public data from the outside world, it should also be vendor
    indemnified from legal claims.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 透明度的另一个方面是对于创建的最终模型拥有广泛的商业权利和行动自由。记住，这一章**不是**关于模型提供商的章节；这是一章关于**你的**数据的章节。你需要对你的增强模型拥有许可权，这样当你将信息编码到为你的业务选择的模型中时，你就有**完全的行动自由**去做你需要为你的业务做的事情。而且，因为你是在基于一个包含来自外部世界的公共数据的模型之上构建的，它也应该由供应商承担法律索赔。
- en: Tip
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: As we talked about in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635),
    ensure you do your due diligence around what indemnifications your LLM comes with.
    Today, every vendor out there is offering some sort of indemnification, but you
    need to know that every vendor’s indemnification protections are different. Some
    don’t indemnify on what’s created, some fully indemnify, some limit the size of
    the indemnification, some don’t indemnify on the output but do in the usage of,
    and so on. Yes, you’re going to have to get your legal team involved.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 [第五章](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)
    中讨论的那样，确保您对您的 LLM 所提供的赔偿进行尽职调查。今天，每个供应商都在提供某种形式的赔偿，但您需要知道每个供应商的赔偿保护都是不同的。有些不赔偿所创建的内容，有些完全赔偿，有些限制赔偿的规模，有些不赔偿输出但赔偿在使用的方面，等等。是的，您将不得不让您的法律团队介入。
- en: The IBM commercial—in Granite you should trust
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IBM 商业广告——在 Granite 中你应该信任
- en: 'We will say it again: we hope you agree that almost all of this book has been
    anything but about IBM. We hope you’ve appreciated the care we took to build your
    AI acumen, frame out the use cases, and note the things to watch out for and the
    things you’ll want to ensure you’ve got straightened out as you embark on your
    AI journey—with but one or two tiny IBM commercials. With that said, we thought
    we’d afford ourselves a page or two to focus on an open source model you’ll notice
    we haven’t spent much time on: IBM Granite. We’re very proud of the IBM Granite
    series because it hits on the very things we’ve discussed: transparency in the
    data used to train the models (check out the pages of details on the training
    data used in Granite 3 in its technical report^([1](ch08.html#id1056))); the models
    are released in the open with a no-nonsense permissive Apache 2.0 license; and
    most importantly, the Granite family is designed to have cost-efficient, fit-for-purpose
    models that can be further customized with enterprise data (we will dive into
    the details a little later in this chapter).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再说一遍：我们希望您同意，这本书的大部分内容都不是关于 IBM 的。我们希望您已经欣赏到我们为构建您的 AI 理解所付出的努力，概述了用例，并注意到了您在开始
    AI 之旅时需要注意的事项以及您想要确保已经解决的问题——只有一两个小小的 IBM 商业广告。话虽如此，我们认为我们应该给自己留下一页或两页，专注于一个开源模型，您会注意到我们并没有花太多时间在上面：IBM
    Granite。我们非常自豪于 IBM Granite 系列，因为它触及了我们讨论的要点：模型训练数据使用的透明度（查看 Granite 3 技术报告中关于训练数据的详细页面^([1](ch08.html#id1056)）；模型以无废话的
    Apache 2.0 许可证公开发布；最重要的是，Granite 系列旨在拥有成本效益高、适合特定用途的模型，可以使用企业数据进行进一步定制（我们将在本章稍后深入探讨细节）。
- en: '[Figure 8-1](#ch08_figure_1_1740182052159344) shows the breadth of models in
    the IBM Granite 3 family (and by the time you read this book, Granite 4 will likely
    be released, or close to it).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-1](#ch08_figure_1_1740182052159344) 展示了 IBM Granite 3 系列模型的广泛性（在你阅读这本书的时候，Granite
    4 可能已经发布，或者接近发布）。'
- en: 'Here is a high-level overview of what the models in [Figure 8-1](#ch08_figure_1_1740182052159344)
    are meant for and why they matter:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是对 [图 8-1](#ch08_figure_1_1740182052159344) 中模型的概述以及它们为什么重要：
- en: Granite Language
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Granite 语言
- en: These are your bread-and-butter workhorse LLMs for enterprise language tasks.
    These models deliver top performance for their size and are designed to be further
    customized using techniques like PEFT and InstructLab.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是您企业语言任务中的基础工作马力的 LLM，这些模型在它们的规模上提供了顶级性能，并设计为可以使用 PEFT 和 InstructLab 等技术进一步定制。
- en: Granite Vision
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Granite 视觉
- en: These are multimodal models that are specialized on vision *understanding* tasks
    (image + prompt in, text out). Think of these for any document understanding,
    chart Q&A, like having an LLM explain trend lines and opine on things in a bar
    graph, or even multimodal RAG tasks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是多模态模型，专门用于视觉 *理解* 任务（图像 + 提示输入，文本输出）。考虑这些模型用于任何文档理解、图表问答，就像让一个大型语言模型解释趋势线并在条形图中发表意见，或者甚至是多模态
    RAG 任务。
- en: Granite Guardian
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Granite 守护者
- en: These are “guardrail” models (we discussed these in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635))
    that sit alongside any deployed LLM (not just Granite) and help monitor inputs
    to and outputs from the model, making sure there is no harmful or biased content,
    hallucinations, etc.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是“安全线”模型（我们在 [第五章](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)
    中讨论过），它们位于任何部署的 LLM（不仅仅是 Granite）旁边，并帮助监控模型输入和输出，确保没有有害或偏见的内容、幻觉等。
- en: Granite Embedding
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Granite 嵌入
- en: These models convert large amounts of language and code into vector embeddings
    or numeric representations—this is very useful for enabling RAG workflows.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型将大量语言和代码转换为向量嵌入或数值表示——这对于启用RAG工作流程非常有用。
- en: Granite Time Series
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Granite时间序列
- en: These are very small, GenAI-based forecasting models. Instead of being trained
    on large amounts of language, these models were trained on large amounts of time
    series data points to get their predictive superpowers.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是非常小的基于GenAI的预测模型。它们不是在大量语言上训练，而是在大量时间序列数据点上训练，以获得它们的预测超级能力。
- en: Granite Geospatial
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Granite地理空间
- en: These Earth Science multimodal models were developed in collaboration with NASA
    to predict everything from weather forecasts to the amount of biomass in a satellite
    image.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这些地球科学多模态模型是与NASA合作开发的，用于预测从天气预报到卫星图像中生物量的数量。
- en: '![](assets/aivc_0801.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aivc_0801.png)'
- en: Figure 8-1\. Snapshot of the IBM Granite model family
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-1. IBM Granite模型家族快照
- en: The key tenets of IBM’s Granite models are transparency and flexibility. Every
    Granite model is released with full disclosure of the data used in training and
    under an Apache 2.0 license to provide users the maximum level of freedom of action
    to use and deploy them for their business. It is this commitment to transparency
    and openness that awarded Granite one of the highest scores in [Stanford’s Transparency
    Index ranking of LLM providers](https://oreil.ly/FQHb5).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: IBM的Granite模型的关键原则是透明度和灵活性。每个Granite模型都会在Apache 2.0许可下发布，并完全披露用于训练的数据，以使用户能够获得最大程度的行动自由，用于其业务的使用和部署。正是对透明度和开放性的这种承诺，使Granite在[斯坦福大学对LLM提供商的透明度指数排名](https://oreil.ly/FQHb5)中获得了最高的评分之一。
- en: 'Step 2: Representing your Enterprise Data within an LLM'
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第2步：在LLM中表示你的企业数据
- en: 'Once you have selected a trusted model starting point (in our analogy, this
    is your transparent glass filled with pristine water that you will use to make
    lemonade), the next step is to select the method by which you will add your enterprise
    data to that foundation (the sugar and lemons that turn water into lemonade).
    There are multiple techniques available, including these common patterns:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你选择了可信的模型起点（在我们的类比中，这是你装满纯净水的透明玻璃，你将用它来制作柠檬水），下一步就是选择你将如何将企业数据添加到这个基础（将水变成柠檬水的糖和柠檬）的方法。有多种技术可供选择，包括以下常见模式：
- en: Retrieval-augmented generation (RAG)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）
- en: You might already be familiar with RAG, as it is one of the top patterns deployed
    in enterprises today. We alluded to this pattern throughout this book, but it’s
    worth explicitly talking about it here because it’s a pretty common mechanism
    to add enterprise data to an LLM. In a RAG pattern, once a query is submitted
    by a user, that query is used to retrieve relevant enterprise information from
    (typically) a database using essentially a similarity match between the text in
    the query and the text in the database. (This database is typically a vector database
    that supports semantic searching, but it could be a traditional relational database
    too, or a hybrid version of the two, and even files on an object storage service,
    among other options.) Then the original user query is concatenated with the retrieved
    information (often called the grounding context) into a prompt that is fed to
    the LLM. The LLM can now use both its vast knowledge accrued in training alongside
    the retrieved information provided in the prompt to answer the question. As you
    may have inferred, in a RAG pattern, the model weights are not touched at all,
    and this has some upsides and downsides to it. RAG is an exceptional technique,
    especially when it is important to have the very latest information available
    whenever answering a user query (it is much easier to update a supporting database
    with the latest and greatest details than to retrain or fine-tune a model with
    the updated information). However, RAG does have several downsides. First, there
    are lots of dependencies and complexities that have to be managed; RAG is not
    just a model, it’s a system. Another is that every time you want the model to
    answer a question—for example, about some internal HR policy—you need to provide
    the entire text of that HR policy to the LLM (this also drives up inferencing
    costs, over and over again). Related to this is the fact that an LLM never really
    internalizes the information that is provided in a RAG workflow, which is to say
    it isn’t learning new concepts and applying them in new ways across various tasks.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经熟悉了RAG，因为它是目前企业中部署的顶级模式之一。我们在整本书中都提到了这个模式，但在这里明确地讨论它是有价值的，因为它是一种将企业数据添加到LLM的相当常见的机制。在RAG模式中，一旦用户提交查询，该查询就会用于从（通常是）数据库中检索相关企业信息，这主要是通过查询中的文本和数据库中的文本之间的相似性匹配来实现的。（这个数据库通常是一个支持语义搜索的向量数据库，但也可以是传统的关系数据库，或者是两种数据库的混合版本，甚至可以是对象存储服务上的文件，以及其他选项。）然后，原始用户查询与检索到的信息（通常称为基础上下文）连接起来，形成一个提供给LLM的提示。现在，LLM可以使用其在训练中积累的广泛知识以及提示中提供的检索信息来回答问题。正如你可能推断的那样，在RAG模式中，模型权重根本不接触，这既有优点也有缺点。RAG是一种卓越的技术，尤其是在回答用户查询时需要提供最新信息时（更新支持数据库以包含最新和最详细的信息比重新训练或微调包含更新信息的模型要容易得多）。然而，RAG也有一些缺点。首先，有许多依赖性和复杂性需要管理；RAG不仅仅是一个模型，它是一个系统。另一个缺点是，每次你想让模型回答一个问题——例如，关于某些内部人力资源政策——你都需要向LLM提供该人力资源政策的全部文本（这也增加了推理成本，一次又一次）。与此相关的是，LLM从未真正内化在RAG工作流程中提供的信息，也就是说，它没有学习新的概念并以新的方式在各种任务中应用这些概念。
- en: Fine-tuning
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 微调
- en: Another common approach for customizing an LLM with enterprise data is fine-tuning.
    Fine-tuning is where the actual weights of the model are updated based on new
    data (those input/output training pairs we’ve referred to throughout this book).
    This approach can be done with far less compute than retraining the original model
    from scratch and with less data. This technique offers a more reasonable starting
    point for AI Value Creators to start customizing their models. There are many
    different types of fine-tuning techniques. One is called supervised fine-tuning
    (SFT), where all the parameters are updated, and another is called parameter-efficient
    fine-tuning (PEFT) where only a portion of the parameters are updated. There are
    also methods like low-rank adaptation (LoRA) where an external (to the LLM) module
    of parameters is trained to work with the base model. LoRAs are convenient because
    these modules can then be removed when they are not needed or swapped out for
    new modules when the model is doing a different task. For example, perhaps you
    run a role-playing game (RPG) company and build a LoRA adapter on top of your
    LLM for game dialog and nonplayer character interaction, but another LoRA adapter
    gets subbed in for storytelling and narration. LoRA adapters have their drawbacks
    too—as you can imagine, if you wanted 50 fine-tuned customizations, then you’re
    managing the lifecycle of 50 different adapters. We’d also speculate that since
    they use very low-rank matrices, at some point their data capacity might be limited.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用企业数据定制 LLM 的另一种常见方法是微调。微调是指根据新数据（我们在本书中多次提到的输入/输出训练对）更新模型的实际权重。这种方法比从头开始重新训练原始模型所需的计算量要少，并且数据量也更少。这项技术为
    AI 价值创造者提供了一个更合理的起点，以开始定制他们的模型。存在许多不同类型的微调技术。其中一种是监督微调（SFT），其中所有参数都会更新，另一种是参数高效微调（PEFT），其中只有部分参数会更新。还有像低秩适应（LoRA）这样的方法，其中外部（相对于
    LLM）的参数模块被训练与基础模型一起工作。LoRAs 很方便，因为这些模块可以在不需要时移除，或者当模型执行不同任务时用新模块替换。例如，也许你经营一家角色扮演游戏（RPG）公司，并在你的
    LLM 上构建一个 LoRA 适配器用于游戏对话和非玩家角色交互，但另一个 LoRA 适配器被用于故事讲述和叙述。LoRA 适配器也有其缺点——正如你可以想象的那样，如果你想要
    50 个微调过的定制，那么你正在管理 50 个不同适配器的生命周期。我们还会推测，由于它们使用非常低秩的矩阵，在某个时候它们的数据容量可能会受到限制。
- en: At the end of the day, the fine-tuning method you’ll eventually choose depends
    on your performance goals and cost constraints. The more parameters you target,
    the better the performance, but the more expensive it will be to train the model.
    While fine-tuning provides a way to intrinsically improve a model based on proprietary
    data, models that are fine-tuned also suffer from what is called *catastrophic
    forgetting*. This basically means that once you fine-tune a model on a task, the
    model becomes a specialist in it; that is to say, it is very good at that task,
    but it loses (forgets) some of its ability as a generalist to try and execute
    tasks it used to know how to do. This means, for every task you want to train
    your model on, you need to maintain a separate, fine-tuned version of that model
    (or in the case of LoRAs, a separate LoRA adapter for each important task).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，你将选择的微调方法取决于你的性能目标和成本限制。你针对的参数越多，性能越好，但训练模型的开销也会越大。虽然微调提供了一种基于专有数据内在改进模型的方法，但经过微调的模型也会遭受所谓的*灾难性遗忘*。这基本上意味着一旦你在某个任务上微调了一个模型，该模型就变成了该任务的专业人士；也就是说，它在那个任务上非常擅长，但它失去了（忘记了）一些作为通才尝试执行它曾经知道如何执行的任务的能力。这意味着，对于你想要训练模型上的每一个任务，你需要维护该模型的一个单独的、微调过的版本（或者在
    LoRAs 的情况下，为每个重要任务维护一个单独的 LoRA 适配器）。
- en: InstructLab
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: InstructLab
- en: InstructLab is an open source form of fine-tuning cooked up at Red Hat that
    was specifically designed for infusing proprietary enterprise knowledge back into
    an LLM in a collaborative manner while maintaining the LLM’s general-purpose capabilities.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: InstructLab 是 Red Hat 研发的一种开源微调形式，它专门设计用于以协作方式将专有企业知识注入到大型语言模型（LLM）中，同时保持 LLM
    的一般用途能力。
- en: Introducing InstructLab
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍 InstructLab
- en: The open source [InstructLab](https://instructlab.ai) method for tuning LLMs
    was designed from the start to address the challenges faced by AI practitioners
    who want to specialize and deploy LLMs for [specific business needs](https://github.com/instructlab).
    Not only does InstructLab facilitate specializing a model on domain-specific data,
    the goal of InstructLab is to make contributing to LLMs as easy as a developer
    might contribute to any other software project. InstructLab came about to try
    and bridge some of the gaps between how open source software works and how open
    source AI was working, and it now has both an open source presence and enterprise
    offering supported by Red Hat.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 开源[InstructLab](https://instructlab.ai)方法用于调整LLM，从一开始就是为了解决希望专门化和部署LLM以满足[特定业务需求](https://github.com/instructlab)的AI从业者所面临的挑战。InstructLab不仅促进了在特定领域数据上对模型的专门化，其目标是将向LLM的贡献变得与开发者向任何其他软件项目贡献一样简单。InstructLab的出现是为了尝试弥合开源软件的工作方式与开源AI的工作方式之间的差距，现在它既有开源的存在，也有由Red
    Hat支持的企业级产品。
- en: InstructLab aims to shape the future of GenAI by providing a framework to enable
    teams and communities to contribute knowledge and skill to existing LLMs in an
    accessible way. Core to InstructLab is a novel model alignment method called *Large-scale
    Alignment for chatBots* (LAB).^([2](ch08.html#id1070))
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: InstructLab旨在通过提供一个框架来塑造GenAI（生成式人工智能）的未来，使团队和社区能够以可访问的方式向现有的LLM贡献知识和技能。InstructLab的核心是一种新颖的模型对齐方法，称为*大型聊天机器人对齐*（LAB）.^([2](ch08.html#id1070))
- en: 'As we alluded to in the previous section, there are many communities rapidly
    embracing and extending permissively licensed open source AI models, but they’ve
    all been faced with three main points of friction that is a problem well solved
    for traditional open source software, namely:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中提到的，许多社区正在迅速采用和扩展许可宽松的开源AI模型，但它们都面临着三个主要摩擦点，这些问题对于传统开源软件来说已经得到了很好的解决，即：
- en: There’s no way to contribute back to those base LLMs directly
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 没有直接贡献回这些基础LLM（大型语言模型）的方法
- en: Enhancements show up as forks (search around and you’ll find an uncontrollable,
    ever-populating massive herd of Llamas—one-off, fine-tuned versions of the Llama
    LLM—roaming our GenAI world), and this forces you to choose a “best-fit” model
    that isn’t easily extensible. Also, these forks are expensive for model creators
    to maintain because what happens when the “parent” Llama changes? How do you get
    those enhancements? And we didn’t even account for sifting through the massive
    Llama herd to figure out which Llama is right for you.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 增强功能以分支的形式出现（四处搜索，你会发现一个无法控制的、不断增长的庞大Llama群体——Llama LLM的独立微调版本——在我们的GenAI世界中游荡），这迫使你选择一个“最佳匹配”的模型，而这个模型并不容易扩展。此外，这些分支对模型创建者来说维护成本很高，因为当“父级”Llama发生变化时会发生什么？你如何获取这些增强功能？而且我们还没有考虑到在庞大的Llama群体中筛选出适合你的Llama。
- en: There’s a high barrier to entry if you want to contribute back into a model
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想向模型贡献内容，入门门槛很高
- en: Did you do something special? Came up with some incredible new idea—and it works?
    You have to learn how to fork, train, and refine models to see your idea forward,
    which requires a heck of a lot of expertise.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你做了什么特别的事情吗？想出了某个令人难以置信的新想法——并且它有效？你必须学习如何分支、训练和改进模型以推进你的想法，这需要大量的专业知识。
- en: There is no direct community governance and no best practices around review,
    curation, and distribution of forked models
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 目前没有直接的社区治理，也没有关于审查、整理和分发分支模型的最佳实践
- en: Ever watch five-year-old kids play soccer? Enough said.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你有没有看过五岁孩子踢足球？无需多言。
- en: InstructLab solves these problems because it gives you the tools to create and
    merge contributions (skills and/or knowledge artifacts) to an LLM, without requiring
    a team with deep AI engineering skills at your disposal.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: InstructLab通过为你提供创建和合并贡献（技能和/或知识工件）到LLM的工具来解决这些问题，而不需要你拥有一个具备深厚AI工程技能的团队。
- en: Dipping your toe into the InstructLab pool
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 尝试涉足InstructLab的领域
- en: 'InstructLab’s technology gives upstream models with sufficient infrastructure
    resources the ability to create regular builds of their customized models—not
    by rebuilding and retraining the entire model, but by infusing new skills and/or
    knowledge into it. It does this through a combination of three key processes that
    we cover in this section:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: InstructLab的技术为上游模型提供了足够的基础设施资源，使其能够创建其定制模型的常规构建版本——不是通过重建和重新训练整个模型，而是通过注入新的技能和/或知识。它通过三种关键过程的组合来实现，我们将在本节中介绍：
- en: A taxonomy-driven data curation methodology
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种以分类法驱动的数据整理方法
- en: Synthetic data generation—at scale
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规模化的合成数据生成
- en: An instruction-tuning method that has multiple phases and avoids catastrophic
    forgetting
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种具有多个阶段且避免灾难性遗忘的指令调整方法
- en: The InstructLab project provides tools for developers to add and merge new skills
    and/or knowledge into any open LLM through a GitHub workflow—right from their
    laptop.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: InstructLab项目为开发者提供了工具，通过GitHub工作流程将新的技能和/或知识添加到任何开源LLM中——直接从他们的笔记本电脑开始。
- en: Through the InstructLab project, shown in [Figure 8-2](#ch08_figure_3_1740182052159414),
    teams can contribute LAB alignment “recipes” for new skills and/or knowledge (your
    enterprise data) through a pull request to an InstructLab project. All accepted
    skills and/or knowledge recipes are subsequently added on top of a given pretrained
    starter during the model alignment phase by the InstructLab project maintainers
    (be they with a public model or private within your company).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 通过InstructLab项目，如图[图8-2](#ch08_figure_3_1740182052159414)所示，团队可以通过向InstructLab项目提交拉取请求，为新技能和/或知识（你的企业数据）贡献LAB校准“配方”。所有被接受的技能和/或知识配方随后将由InstructLab项目的维护者（无论是公共模型还是公司内部的私有模型）在模型校准阶段添加到预训练的起始模型之上。
- en: '![A diagram of a diagram of a diagram  Description automatically generated](assets/aivc_0802.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![一个图解的图解的图  自动生成的描述](assets/aivc_0802.png)'
- en: Figure 8-2\. InstructLab offers a new way to make community contributions additive
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-2\. InstructLab提供了一种新的方式来使社区贡献具有累加性
- en: Enabling contributions in the alignment phase of model development, rather than
    investing resources into the time-consuming process of pretraining new base models,
    allows for an agile iterative development process well suited for collaboration
    within your company (or in an open community, perhaps around an industry, where
    a consortium of businesses are working together to create a model bespoke to their
    industry). We’ve seen it firsthand. Pretraining an LLM can take months and thousands
    of superexpensive GPUs, evaporating water and what’s in your wallet. In contrast,
    using InstructLab, a given LLM can often be aligned using fine-tuning methods
    in less than a day’s time, allowing for a much more rapid update release cycle.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型开发的校准阶段启用贡献，而不是将资源投入到耗时的新基础模型预训练过程中，允许进行敏捷的迭代开发流程，非常适合在公司内部（或者在可能围绕一个行业，由企业联盟共同合作以创建特定于其行业的模型的开源社区中）进行协作。我们亲眼见证了这一点。预训练一个大型语言模型可能需要数月时间以及数千个超级昂贵的GPU，这不仅消耗水资源，还会让你的钱包缩水。相比之下，使用InstructLab，一个给定的LLM通常可以在不到一天的时间内通过微调方法进行校准，从而允许更快的更新发布周期。
- en: Can you smell what’s cooking? Skill and knowledge recipes
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你能闻到什么正在烹饪的气味？技能和知识配方
- en: At its core, a skill or knowledge recipe is just a simple set of instructions
    on how to programmatically generate large amounts of labeled synthetic data (again,
    AI helping AI) that exemplifies a given skill set or area of knowledge. Each recipe
    is comprised of a short description of a skill or knowledge gap, and then five,
    or more, handcrafted examples. In the case of a knowledge recipe, the input would
    also include a knowledge source, such as a company’s benefits manual in an HR
    use case, that covers the desired topic.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本质上，一项技能或知识配方仅仅是一组简单的指令，用于程序化生成大量标记的合成数据（再次强调，AI帮助AI），这些数据可以体现特定的技能集或知识领域。每个配方包括对技能或知识差距的简短描述，然后是五个或更多的手工制作的示例。在知识配方的案例中，输入还包括一个知识来源，例如在人力资源用例中，涵盖所需主题的公司福利手册。
- en: These recipes are provided in the form of a prompt to a larger teacher model
    (InstructLab debuted with Mixtral-Instruct as its teacher model), which is used
    to generate a large volume of corresponding synthetic data. Why synthetic data?
    It’s a critical component of InstructLab because many companies do not have enough
    targeted data to train (using InstructLab or more standard PEFT methods) something
    as big as an LLM on their ultra-specific tasks. Synthetic data is also how InstructLab
    turns large corpuses of unstructured enterprise data into a structured dataset
    that can be used to train your model. Once this data is generated, it can be used
    to fine-tune your LLM to teach it the missing skills or knowledge you want to
    push upstream into your company’s model.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这些配方以提示的形式提供给更大的教师模型（InstructLab首次推出时以Mixtral-Instruct作为其教师模型），用于生成大量相应的合成数据。为什么是合成数据？它是InstructLab的一个关键组成部分，因为许多公司没有足够的目标数据来训练（使用InstructLab或更标准的PEFT方法）像LLM这样的大型任务。合成数据也是InstructLab将大量非结构化企业数据转化为可以用于训练您模型的结构化数据集的方式。一旦这些数据生成，就可以用来微调您的LLM，使其学会您想要推送到公司模型中的缺失技能或知识。
- en: Using synthetic data to align a model isn’t a novel idea on its own. In fact,
    there are multiple examples of synthetic data being used to align models, including
    examples of model distillation (as we discussed in [Chapter 7](ch07.html#ch07_where_this_technology_is_headed_one_model_will_not_1740182051667482)).
    For example, Vicuna-13B was trained on synthetic data generated from GPT-4\. But
    again, there’s a problem. OpenAI’s terms and conditions do not support the use
    of GPT-4 for the creation of commercially competitive models, which *makes the
    viability of these models questionable.* There are other models that we could
    point you to as well, but they all require closed models like GPT-4 as their teacher
    model to generate the required synthetic data. And right here is when you get
    to how open source drives technology forward. What makes the LAB method so appealing
    is that it proves that permissibly licensed open source models (of which Apache
    2.0 is an example) can be used as teacher models and still drive state-of-the-art
    (SOTA) model performance.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用合成数据来调整模型本身并不是一个新颖的想法。事实上，有多个使用合成数据来调整模型的例子，包括模型蒸馏（如我们在[第7章](ch07.html#ch07_where_this_technology_is_headed_one_model_will_not_1740182051667482)中讨论的）。例如，Vicuna-13B是在从GPT-4生成的合成数据上训练的。但再次，有一个问题。OpenAI的条款和条件不支持使用GPT-4来创建具有商业竞争力的模型，这*使得这些模型的可行性变得可疑*。我们还可以向您推荐其他一些模型，但它们都需要像GPT-4这样的封闭模型作为教师模型来生成所需的合成数据。而就在这里，你就能看到开源如何推动技术向前发展。使LAB方法如此吸引人的是，它证明了可以许可的开源模型（Apache
    2.0是一个例子）可以用作教师模型，并且仍然可以驱动最先进的（SOTA）模型性能。
- en: To date, all skill and/or knowledge recipes contributed to the InstructLab project
    are mapped out in a logical, hierarchical InstructLab taxonomy. In simple terms,
    you can think of a taxonomy as a tree structure that organizes things into categories
    and subcategories (see [Figure 8-2](#ch08_figure_3_1740182052159414)). For InstructLab,
    a taxonomy classifies data samples into smaller groups (each branch is further
    divided into more specific levels) that ultimately support different tasks (leaves
    on a branch). This gives developers a visual framework not just to identify skills
    and knowledge that might help a project, but also a way to spot and fill gaps
    with new knowledge and skills they want to contribute.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，所有贡献给InstructLab项目的技能和/或知识配方都已在一个逻辑的、分层的InstructLab分类法中进行了规划。简单来说，你可以将分类法想象成一个树状结构，它将事物组织成类别和子类别（参见[图8-2](#ch08_figure_3_1740182052159414)）。对于InstructLab来说，分类法将数据样本分类成更小的组（每个分支进一步细分为更具体的层级），最终支持不同的任务（分支上的叶子）。这为开发者提供了一个视觉框架，不仅可以帮助他们识别可能有助于项目的技能和知识，还可以发现并填补他们希望贡献的新知识和技能的空白。
- en: InstructLab’s taxonomy also helps ensure that a diverse set of synthetic data
    is generated to cover all the different subtasks that might be desired when contributing
    a recipe for any one high-level task.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: InstructLab的分类法还有助于确保生成多样化的合成数据，以涵盖在为任何一项高级任务贡献配方时可能希望的所有不同子任务。
- en: Consider an LLM assisting an agent with the task of writing social media posts,
    like our agentic example in the last chapter. How you post on X (formerly known
    as Twitter) is different from LinkedIn or Instagram. Some platforms need short
    forms because of character limits; emojis are more prevalent in others; some platforms
    are very image-based, while others call for more business acumen. These are writing
    skills specific to social media. In the InstructLab taxonomy snippet shown in
    [Figure 8-3](#ch08_figure_4_1740182052159436), if a contributor was trying to
    improve a model’s ability to write social media posts, they could contribute to
    the *social_media* branch (or create a new one if it didn’t exist) that falls
    under the *freeform* branch, which falls under the *writing* branch in the skills
    taxonomy. Their contributions would be synthetic data recipes for each targeted
    social media outlet. Want to make your AI become a poet? Give it different poetry
    examples and create skills that are specific to haiku, one for sonnet, another
    for limerick, and so on.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个大型语言模型（LLM）协助代理完成撰写社交媒体帖子的任务，就像我们在上一章中的代理示例一样。你在X（以前称为Twitter）上的发布方式与LinkedIn或Instagram不同。一些平台由于字符限制需要简短的形式；在其他平台上，表情符号更为常见；有些平台非常注重图像，而另一些则要求更多的商业洞察力。这些都是社交媒体特有的写作技巧。在[图8-3](#ch08_figure_4_1740182052159436)中展示的InstructLab分类法片段中，如果贡献者试图提高模型撰写社交媒体帖子的能力，他们可以贡献到位于技能分类法中“写作”分支下的“*social_media*”分支（或者如果不存在，可以创建一个新的分支）。他们的贡献将是针对每个目标社交媒体平台的合成数据食谱。想要让你的AI成为诗人吗？给它提供不同的诗歌示例，并创建针对俳句、十四行诗、打油诗等特定诗歌形式的技能。
- en: '![A diagram of a person''s face  AI-generated content may be incorrect.](assets/aivc_0803.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![一个人脸的图解，AI生成的内容可能不正确。](assets/aivc_0803.png)'
- en: Figure 8-3\. An example of an InstructLab skills taxonomy for writing
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-3\. InstructLab写作技能分类法的一个示例
- en: LAB’s unique training regimen assimilates this new data during the alignment
    phase instead of the expensive pretraining phase where most LLMs are infused with
    their core knowledge and capabilities. And again, this training protocol also
    mitigates catastrophic forgetting. Quite simply, the way InstructLab works ensures
    that newly added knowledge won’t overwrite what the model learned before.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: LAB独特的训练计划在对齐阶段而不是昂贵的预训练阶段吸收这些新数据。而且，这种训练协议还能减轻灾难性遗忘。简单来说，InstructLab的工作方式确保新添加的知识不会覆盖模型之前学到的内容。
- en: When all synthetic data recipes have been submitted and added to a project’s
    taxonomy, InstructLab’s training and generation pipeline runs all the recipes
    to generate synthetic data. It then filters that generated data down to include
    only high-quality samples, and, using a novel phased fine-tuning approach, aligns
    each of the starter models (the student models) using the generated synthetic
    data, thereby infusing the model with all of the contributed skills and knowledge.
    Since a picture is worth a thousand words, as they say, we’ve summarized this
    entire workflow in [Figure 8-4](#ch08_figure_5_1740182052159457).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有合成数据食谱都已提交并添加到项目的分类法中后，InstructLab的训练和生成管道会运行所有食谱以生成合成数据。然后，它将生成的数据过滤下来，只包括高质量的样本。然后，使用一种新颖的分阶段微调方法，使用生成的合成数据对每个起始模型（学生模型）进行对齐，从而将所有贡献的技能和知识注入模型。正如人们所说，“一张图胜千言”，我们已将整个工作流程总结在[图8-4](#ch08_figure_5_1740182052159457)中。
- en: '![A diagram of a diagram of a cube  Description automatically generated with
    medium confidence](assets/aivc_0804.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![一个立方体图的图解，描述自动生成，中等置信度](assets/aivc_0804.png)'
- en: Figure 8-4\. How Large-scale Alignment for chatBots (LAB) works
  id: totrans-98
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-4\. 大规模对齐聊天机器人（LAB）的工作原理
- en: Harnessing the power of the community
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利用社区的力量
- en: To drive rapid innovation, the open source version of InstructLab has committed
    to a periodic training and release cycle for community-trained models. The latest
    versions of the InstructLab models are made publicly available on Hugging Face,
    which, as you know from the first part of this book, is the heartbeat of the world’s
    largest organized AI community. Hugging Face’s reach gives the community the ability
    to download an InstructLab-tuned model, experiment with it, and find gaps in its
    performance. Once identified, community members can build and contribute their
    own skill and knowledge recipes back to the InstructLab project through a pull
    request. As you’d expect with traditional open source projects, InstructLab committers
    and project maintainers review contributions and merge all accepted contributions
    back to the main model once a week. Of course, for your own private models, you
    can do all of this within your company and operate in the same manner.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了推动快速创新，开源版本的InstructLab已经承诺为社区训练的模型实施定期培训和发布周期。InstructLab模型的最新版本在Hugging
    Face上公开发布，正如你在本书的第一部分所知，Hugging Face是世界上最大的有组织AI社区的脉搏。Hugging Face的覆盖范围使社区能够下载经过InstructLab调整的模型，对其进行实验，并发现其性能中的差距。一旦确定，社区成员可以通过pull
    request构建并贡献他们自己的技能和知识食谱回到InstructLab项目。正如你所期望的传统开源项目一样，InstructLab的提交者和项目维护者每周审查贡献，并将所有接受的贡献合并回主模型。当然，对于你自己的私有模型，你可以在公司内部完成所有这些操作，并以相同的方式运营。
- en: To support developers who are using and contributing to InstructLab models,
    the InstructLab project includes a command-line interface tool called the *Language
    Model Development Kit* (LMDK). LMDK implements the InstructLab workflow on a contributor’s
    laptop.Think of it as a test kitchen for trying out and submitting new recipes
    for generating synthetic data to teach an LLM new skills. Now a developer is up
    and running in an instant, and perhaps they start experimenting with a local version
    of their open sourced LLM (like Granite). They may find some gaps or areas in
    the model’s performance they want to improve, cook up some knowledge or skill
    recipes to fill them in, and voilà! This entire process (as shown in [Figure 8-5](#ch08_figure_6_1740182052159477))
    acts like a flywheel for rapid open source AI innovation.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持使用和贡献InstructLab模型的开发者，InstructLab项目包括一个名为*语言模型开发工具包*（LMDK）的命令行界面工具。LMDK在贡献者的笔记本电脑上实现了InstructLab工作流程。把它想象成一个测试厨房，用于尝试和提交生成合成数据的新食谱，以教授LLM新技能。现在，开发者可以瞬间启动，也许他们会开始尝试他们开源LLM（如Granite）的本地版本。他们可能会发现模型性能中的一些差距或需要改进的领域，制作一些知识或技能食谱来填补这些空白，然后，哇！这个过程（如图8-5所示）就像一个快速开源AI创新的飞轮。
- en: '![A diagram of a process  AI-generated content may be incorrect.](assets/aivc_0805.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![一个流程图，AI生成的内容可能不正确。](assets/aivc_0805.png)'
- en: 'Figure 8-5\. The InstructLab innovation cycle: a flywheel for rapid open source
    innovation'
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-5\. InstructLab创新周期：快速开源创新的飞轮
- en: A day in the life of an InstructLab contributor
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: InstructLab贡献者的一天
- en: As we said earlier, it’s outside the scope of this book to take you through
    the whole InstructLab process, but there are a lot of [tutorials](https://oreil.ly/1MOTp)
    you can easily find with step-by-step instructions that will turn you into a hero
    contributor in no time.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所述，本书的范围不包括带你完成整个InstructLab流程，但你可以轻松找到很多[教程](https://oreil.ly/1MOTp)，这些教程有逐步指导，让你迅速成为英雄贡献者。
- en: '[Figure 8-4](#ch08_figure_5_1740182052159457) gave you an idea of the aspects
    of being an InstructLab contributor, and as you’ve figured out by now, it all
    starts with a skills recipe. The following code shows you what a rhyming skill
    recipe actually looks like (it’s written in YAML):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[图8-4](#ch08_figure_5_1740182052159457)向你展示了成为InstructLab贡献者的方面，而且正如你现在所理解的，这一切都始于一个技能食谱。以下代码展示了rhyming技能食谱的实际样子（它是用YAML编写的）：'
- en: '[PRE0]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, using the local version of InstructLab’s synthetic data generator, you’d
    create your own synthetic alignment data for the skill or knowledge you are building.
    This data can then be used to align your own local version of your model and quickly
    test it to see if your contribution is closing a gap. You can keep experimenting
    with this process until your model can perform the task you’re after. Once your
    recipe is perfected in LMDK, you submit it as a pull request to the InstructLab
    taxonomy on GitHub, as you would any other open source or internal software project.
    Next, a group of committers accept or deny submissions, updating the final taxonomy
    with the new YAML files. (Again, this scenario could be publicly external or fully
    internal to your company.)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用InstructLab合成数据生成器的本地版本，你可以为你要构建的技能或知识创建自己的合成对齐数据。这些数据随后可以用来对齐你自己的模型本地版本，并快速测试以查看你的贡献是否在缩小差距。你可以继续通过这个过程进行实验，直到你的模型能够完成你想要的任务。一旦你在LMDK中完善了你的配方，你就可以将其作为拉取请求提交到GitHub上的InstructLab分类法，就像提交任何其他开源或内部软件项目一样。接下来，一组提交者会接受或拒绝提交，并使用新的YAML文件更新最终的分类法。（同样，这种场景可以是公开的外部或完全内部于你的公司。）
- en: The final step of InstructLab is the build process, which can be run on a regular
    basis, periodically updating your LLM with (for example) the latest and greatest
    contributions from your developer community. In this build process, all of the
    synthetic data generated to date gets aggregated and is used in a multistage training
    process designed to maximize performance and reduce issues like catastrophic forgetting.
    When the new build of your model is available, you now have an LLM, customized
    on all of the enterprise data submitted by your developers and domain SMEs.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: InstructLab的最后一步是构建过程，这可以定期运行，定期更新你的LLM（例如）使用来自你的开发者社区的最新和最好的贡献。在这个构建过程中，迄今为止生成的所有合成数据都会被聚合，并用于一个多阶段训练过程，旨在最大化性能并减少像灾难性遗忘等问题。当你的模型的新构建可用时，你现在拥有了一个LLM，它基于你的开发者提交的所有企业数据和领域SME提交的定制化。
- en: While we are still in the early days of InstructLab, we are seeing that this
    end-to-end process of specializing small models on enterprise data can drive both
    performance (higher is better) improvements *and* significant cost reductions,
    when compared to using a large general-purpose model alone, as shown in [Figure 8-6](#ch08_figure_7_1740182052159496).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们还在InstructLab的早期阶段，但我们看到，在企业数据上专门化小型模型的全端到端过程可以推动性能（越高越好）改进和显著的成本降低，这与仅使用大型通用模型相比，如图8-6所示。
- en: Note
  id: totrans-111
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In scenarios that involve highly sensitive organizational information—such as
    employee health or disciplinary records—embedding that sensitive data directly
    into an LLM likely isn’t something you want to do. Instead, you can use your data
    to customize your LLM via InstructLab and align it closely with your company’s
    branding, style, cultural values, etc., and separately store that sensitive information
    securely within a RAG system with controlled access. This approach allows your
    tailored LLM to seamlessly and securely access sensitive data only when needed,
    ensuring both enhanced communication and strict data confidentiality. Likewise,
    if you had data in a domain that was constantly changing or where the use case
    required the most up-to-date data, RAG likely makes more sense for that data too.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在涉及高度敏感组织信息的情况中——例如员工健康或纪律记录——直接将敏感数据嵌入到LLM中可能不是你想要的。相反，你可以使用你的数据通过InstructLab定制你的LLM，并使其与公司的品牌、风格、文化价值观等紧密对齐，并将该敏感信息安全地存储在具有受控访问权限的RAG系统中。这种方法允许你的定制LLM在需要时无缝且安全地访问敏感数据，确保了增强的沟通和严格的数据保密性。同样，如果你在某个不断变化或使用案例需要最新数据的领域，RAG对于该数据来说也可能更有意义。
- en: '![A graph of sales and sales  Description automatically generated with medium
    confidence](assets/aivc_0806.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![销售和销售描述自动生成的图表，置信度中等](assets/aivc_0806.png)'
- en: Figure 8-6\. Demonstrating the impact of InstructLab
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-6\. 展示InstructLab的影响
- en: 'Step 3: The Grand Finale: Deployment and Experimentation'
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3步：高潮：部署和实验
- en: There’s no sense in having a trusted LLM enriched with your data if no one in
    your company can use it. This makes the final step all about deploying your new-age
    data representation value creation asset. So, what’s needed to make this real?
    A lot of experimentation. If you think back to every previous transformative technology
    (like the internet), history has shown there is also a transition point from experimenting
    to deploying at scale.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的公司没有人能使用一个用你的数据丰富了的受信任的LLM（大型语言模型），那就没有意义。这使得最终步骤完全关乎部署你的新一代数据表示价值创造资产。那么，要实现这一点需要什么？大量的实验。如果你回顾一下每一次之前的技术变革（比如互联网），历史已经表明，从实验到大规模部署也存在一个过渡点。
- en: 'There is incredible excitement, anticipation, and expectation surrounding GenAI
    and agents in our world today. We see applications and APIs that can impact hundreds
    of millions of consumers. Indeed, the type of excitement being generated could
    be compared to the advent of the internet browser (that Netscape moment we talked
    about in [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)).
    But, if you think about this internet comparison, enterprise value wasn’t unlocked
    the instant Netscape came out. It wasn’t until the internet glued together everything:
    from inventories to supply chains all the way to the frontend and omnichannel.
    We think AI will undergo that same evolution: +AI to AI+.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们今天的世界中，围绕生成式人工智能（GenAI）和智能体充满了极大的兴奋、期待和预期。我们看到的应用程序和API可以影响数亿消费者。确实，这种兴奋的类型可以与互联网浏览器的出现（我们在[第1章](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)中提到的Netscape时刻）相提并论。但是，如果你考虑这种互联网比较，企业价值并不是在Netscape出现的那一刻就被释放的。直到互联网将一切粘合在一起：从库存到供应链，再到前端和全渠道。我们认为人工智能也将经历同样的演变：+AI到AI+。
- en: To unlock AI’s value in the enterprise, you need to be able to target the same
    deployment at scale across an enterprise. But to get there, you will need a governed
    environment that allows for experimentation, customizing your models through key
    workflows like RAG, fine-tuning, and InstructLab, and then transitioning those
    models to deployment at scale.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要在企业中释放人工智能的价值，你需要能够跨企业规模地针对相同的部署进行目标定位。但要做到这一点，你需要一个受管理的环境，允许进行实验，通过关键工作流程如RAG、微调和InstructLab来定制你的模型，然后将这些模型过渡到大规模部署。
- en: 'Importantly, as your customized models are now representations of valuable
    enterprise intellectual property (IP), there are key business decisions that will
    need to be made at the time of deployment. Decisions like: can you trust your
    model to live in the cloud, or is the data that is represented by your model sensitive
    enough that it can only be deployed on premises? Do you need those proactive and
    reactive guardrails we talked about in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)
    to make sure your applications using these models are not abused? Do you need
    to actively monitor the performance and safety of your deployments? And as GenAI
    permeates throughout your enterprise, you’re expanding the surface attack area
    for digital exploitation, so (again, from [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635))
    you’re going to have to think about adversarial attacks and other new ways bad
    actors might try to exploit your digital masterpiece.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，由于你的定制模型现在代表了有价值的企业的知识产权（IP），在部署时将需要做出关键的商业决策。例如：你是否可以信任你的模型在云端运行，或者你的模型所代表的数据是否敏感到只能在本地部署？你是否需要我们在[第5章](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)中提到的那些主动和被动的安全措施，以确保使用这些模型的应用不会被滥用？你是否需要积极监控你部署的性能和安全？随着生成式人工智能（GenAI）渗透到你的企业中，你正在扩大数字利用的攻击面，因此（再次从[第5章](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)中提到）你将不得不考虑对抗性攻击和其他不良行为者可能试图利用你的数字杰作的新方法。
- en: The Future Is Open, Collaborative, and Customizable
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来是开放的、协作的和可定制的。
- en: Much of the internet is built on open source software. Every day, whether you
    realize it or not, you’re interacting with a Linux operating system, and an Apache
    web server is helping you accomplish your goals. Today, open source software also
    powers smartphones running on Android operating systems and the Secure Sockets
    Layer (SSL) cryptographic protocol that secures millions of financial transactions
    every day. We’re telling you that open, community-built, and enterprise-customized
    LLMs can bring some of the same benefits. Putting LLM weights out for the world
    to see gives everyone the chance to innovate, test, refine, and shape the future
    of this powerful technology. Allowing builders to understand the data provenance
    fosters trust and provides explainability.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 互联网的大部分内容都是基于开源软件构建的。每天，无论你是否意识到，你都在与Linux操作系统互动，Apache网络服务器正帮助你实现目标。如今，开源软件也驱动着运行Android操作系统的智能手机，以及每天保障数百万金融交易安全的Secure
    Sockets Layer（SSL）加密协议。我们告诉您，开放、社区共建和企业定制的LLM可以带来一些相同的益处。将LLM权重公之于众，让每个人都有机会创新、测试、精炼并塑造这一强大技术的未来。允许构建者了解数据来源，可以培养信任并提供可解释性。
- en: Transparent open source software makes systems more stable and secure. That
    can lead to faster, more predictable release cycles, and safer AI-related software.
    Improving LLM trust and transparency is one of the top goals of the InstructLab
    project.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 透明开源软件使系统更加稳定和安全。这可能导致更快速、更可预测的发布周期，以及更安全的AI相关软件。提高LLM的可信度和透明度是InstructLab项目的主要目标之一。
- en: Open source software also encourages the kind of healthy competition that prevents
    one or two companies from monopolizing the industry. When everyone is allowed
    to participate, innovation thrives and costs to consumers typically drop.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 开源软件还鼓励一种健康的竞争，防止一家或两家公司垄断行业。当每个人都被允许参与时，创新就会蓬勃发展，消费者的成本通常会下降。
- en: You’ve now unlocked the secret to turning your data into your competitive superpower.
    But before you dash off to dominate your industry (or at least impress your colleagues),
    let’s wrap up by gazing into our non-AI powered crystal ball (it’s just our thoughts,
    we don’t really have one) and take an educated guess at what wild adventures await
    the ever-evolving landscape of Gen AI and agents.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经揭开了将你的数据转化为你的竞争优势的秘密。但在你冲出去统治你的行业（或者至少给你的同事留下深刻印象）之前，让我们通过观察我们的非AI驱动的水晶球（这只是我们的想法，我们实际上并没有一个）来结束，并对不断演变的通用人工智能和代理的广阔前景进行一次有根据的猜测。
- en: ^([1](ch08.html#id1056-marker)) Granite Team, IBM, “Granite 3.0 Language Models,”
    2023, [*https://ibm.biz/granite-report*.](https://ibm.biz/granite-report)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch08.html#id1056-marker)) Granite Team, IBM, “Granite 3.0 语言模型,” 2023,
    [*https://ibm.biz/granite-report*.](https://ibm.biz/granite-report)
- en: '^([2](ch08.html#id1070-marker)) Shivchander Sudalairaj et al., “LAB: Large-Scale
    Alignment for ChatBots,” preprint, arXiv, April 29, 2024, [*https://arxiv.org/abs/2403.01081*](https://arxiv.org/abs/2403.01081).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch08.html#id1070-marker)) Shivchander Sudalairaj等人，“LAB：为聊天机器人进行的大规模对齐，”预印本，arXiv，2024年4月29日，[*https://arxiv.org/abs/2403.01081*](https://arxiv.org/abs/2403.01081)。
