- en: Capitolo 11\. Testare i servizi di intelligenza artificiale
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章\. 测试人工智能服务
- en: 'Questo lavoro è stato tradotto utilizzando l''AI. Siamo lieti di ricevere il
    tuo feedback e i tuoi commenti: [translation-feedback@oreilly.com](mailto:translation-feedback@oreilly.com)'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作是用AI翻译的。我们很高兴收到你的反馈和评论：[translation-feedback@oreilly.com](mailto:translation-feedback@oreilly.com)
- en: In questo capitolo scoprirai l'importanza del testing e le sue sfide nella creazione
    di servizi GenAI, oltre a concetti chiave come i piani di test, i modelli di verifica
    e validazione, la piramide del testing e il ruolo dei dati, degli ambienti e dei
    confini del testing.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解在创建GenAI服务时测试的重要性和挑战，以及关键概念，如测试计划、验证和验证模型、测试金字塔以及数据、测试环境和边界的作用。
- en: Per fare pratica con i test, utilizzerai `pytest`, un popolare framework di
    test con funzioni come le fixture di test, gli ambiti, i marcatori e la parametrizzazione
    delle fixture. Imparerai anche a conoscere il plug-in `pytest-mock` per il patching
    delle funzioni e a usare stub, mock e oggetti spia per simulare e controllare
    le dipendenze esterne durante i test.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了练习测试，你将使用`pytest`，这是一个流行的测试框架，具有测试固定装置、作用域、标记和固定装置参数化等功能。你还将了解用于修补功能的`pytest-mock`插件，并学习使用存根、模拟和间谍对象来模拟和控制测试期间的外部依赖。
- en: Poiché il mocking può rendere i test più fragili, esploreremo anche la dependency
    injection, che ti permette di iniettare dipendenze mock o stub direttamente nei
    componenti da testare, evitando modifiche al codice in runtime.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模拟可能会使测试变得脆弱，我们还将探索依赖注入，这允许你直接将模拟或存根依赖注入到要测试的组件中，从而避免在运行时修改代码。
- en: Parleremo del ruolo dell'isolamento e dell'idempotenza nei test, di quando usare
    i mock e di come testare il codice GenAI sia deterministico che probabilistico.
    Alla fine di questo capitolo, sarai sicuro di poter scrivere suite di test complete
    che includono test unitari, di integrazione, end-to-end e comportamentali per
    i tuoi servizi.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论隔离和幂等性在测试中的作用，何时使用模拟，以及如何测试GenAI代码，无论是确定性的还是概率性的。在本章结束时，你将确信能够编写包含单元测试、集成测试、端到端测试和行为测试的完整测试套件，用于你的服务。
- en: Prima di tuffarci nella scrittura dei test, esploriamo i concetti fondamentali
    del testing del software tradizionale e come affrontare il testing dei servizi
    GenAI, che può rivelarsi impegnativo a causa della natura probabilistica dei modelli
    AI.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入编写测试之前，我们探索一下传统软件测试的基本概念以及如何应对GenAI服务的测试，这可能会因为AI模型的不确定性而变得具有挑战性。
- en: L'importanza dei test
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试的重要性
- en: In teoria, tutti concordano sul fatto che i test sono necessari quando si realizza
    un software. Si scrivono test per avere fiducia nella funzionalità e nelle prestazioni
    dei sistemi, soprattutto quando interagiscono tra loro. Ma realisticamente, i
    progetti possono saltare l'implementazione di test manuali o automatizzati a causa
    di vari vincoli, tra cui il budget, il tempo o i costi di manodopera associati
    alla manutenzione dei test.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，所有人都同意在实现软件时进行测试是必要的。编写测试是为了对系统的功能和性能有信心，尤其是在它们相互交互时。但现实中，由于预算、时间或与测试维护相关的人力成本等限制，项目可能会跳过手动或自动测试的实施。
- en: I progetti che saltano i test, in parte o del tutto, finiscono per affrontare
    i problemi del software in modo reattivo invece che proattivo. In questo modo
    si accumula un *debito tecnico* che dovrai poi ripagare in costi di manodopera
    e di server, con gli interessi, per saldare.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 跳过测试的部分或全部项目最终会以被动而非主动的方式应对软件问题。这样会积累一个*技术债务*，你需要用人力和服务器成本，加上利息，来偿还。
- en: Il problema di quando effettuare i test è difficile da risolvere. Se stai solo
    sperimentando e mettendo insieme un prototipo in rapide iterazioni, realisticamente
    non dovrai preoccuparti molto dei test. Tuttavia, non appena avrai un prodotto
    minimo vendibile, un sistema che si interfaccia con dati sensibili ed elabora
    i pagamenti degli utenti, dovrai prendere in seria considerazione i piani di test.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当何时进行测试的问题难以解决。如果你只是在快速迭代中尝试并组装原型，实际上你不需要过分担心测试。然而，一旦你有一个可销售的最小产品，一个与敏感数据交互并处理用户支付的系统，你就必须认真考虑测试计划。
- en: All'inizio della mia carriera, stavo costruendo un sistema di gestione dell'apprendimento
    per un cliente. Ho scritto un endpoint webhook per interfacciarmi con i sistemi
    di pagamento di Stripe e con la mia soluzione di autenticazione fatta in casa
    che registrava gli utenti solo al primo pagamento. Il sistema doveva addebitare
    ed elaborare i pagamenti degli abbonamenti sia dei clienti nuovi che di quelli
    già esistenti e inviare email di conferma, tenendo traccia dei record degli utenti,
    degli abbonamenti, dei pagamenti, delle sessioni di checkout e delle fatture.
    La logica di questo webhook è risultata così contorta e complessa che ha portato
    a una mostruosità che è diventata una funzione di 1.000 righe. La funzione controllava
    eventi ricevuti non ordinati di vario tipo, con molteplici viaggi verso il database.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: All'inizio della mia carriera, stavo costruendo un sistema di gestione dell'apprendimento
    per un cliente. Ho scritto un endpoint webhook per interfacciarmi con i sistemi
    di pagamento di Stripe e con la mia soluzione di autenticazione fatta in casa
    che registrava gli utenti solo al primo pagamento. Il sistema doveva addebitare
    ed elaborare i pagamenti degli abbonamenti sia dei clienti nuovi che di quelli
    già esistenti e inviare email di conferma, tenendo traccia dei record degli utenti,
    degli abbonamenti, dei pagamenti, delle sessioni di checkout e delle fatture.
    La logica di questo webhook è risultata così contorta e complessa che ha portato
    a una mostruosità che è diventata una funzione di 1.000 righe. La funzione controllava
    eventi ricevuti non ordinati di vario tipo, con molteplici viaggi verso il database.
- en: L'intera soluzione ha dovuto essere scartata alla fine, poiché il comportamento
    del webhook era così *incostante*, restituendo risposte non coerenti allo stesso
    insieme di input. Gli utenti non potevano registrarsi nemmeno dopo aver effettuato
    un pagamento con successo. Questa incostanza ha reso insopportabile il debug del
    webhook, costringendomi a riscrivere l'integrazione del sistema di pagamento da
    zero. Se solo avessi rallentato la pianificazione e modularizzato la logica e
    avessi scritto dei test in anticipo, avrei potuto risparmiarmi tanti grattacapi.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: L'intera soluzione ha dovuto essere scartata alla fine, poiché il comportamento
    del webhook era così *incostante*, restituendo risposte non coerenti allo stesso
    insieme di input. Gli utenti non potevano registrarsi nemmeno dopo aver effettuato
    un pagamento con successo. Questa incostanza ha reso insopportabile il debug del
    webhook, costringendomi a riscrivere l'integrazione del sistema di pagamento da
    zero. Se solo avessi rallentato la pianificazione e modularizzato la logica e
    avessi scritto dei test in anticipo, avrei potuto risparmiarmi tanti grattacchi.
- en: Quando rallenti per pianificare e testare i tuoi servizi, stai barattando tempo
    e fatica in cambio di fiducia nel tuo codice.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Quando rallenti per pianificare e testare i tuoi servizi, stai barattando tempo
    e fatica in cambio di fiducia nel tuo codice.
- en: 'Altre occasioni in cui dovresti prendere in considerazione l''implementazione
    di test sono quando:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 'Altre occasioni in cui dovresti prendere in considerazione l''implementazione
    di test sono quando:'
- en: Più collaboratori aggiungono modifiche nel tempo
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Più collaboratori aggiungono modifiche nel tempo
- en: I manutentori modificano le dipendenze esterne
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: I manutentori modificano le dipendenze esterne
- en: Aumenta il numero di componenti e di dipendenze nei tuoi servizi
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aumenta il numero di componenti e di dipendenze nei tuoi servizi
- en: All'improvviso si nota la comparsa di troppi bug
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: All'improvviso si nota la comparsa di troppi bug
- en: 'La posta in gioco è troppo alta se le cose vanno male: la mia esperienza è
    rientrata in questa categoria.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'La posta in gioco è troppo alta se le cose vanno male: la mia esperienza è
    rientrata in questa categoria.'
- en: Ora dovresti capire in che modo i test possono essere utili al tuo progetto.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Ora dovresti capire in che modo i test possono essere utili al tuo progetto.
- en: Test del software
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Test del software
- en: Ora che conosci le sfide e i potenziali approcci per testare i servizi GenAI,
    rivediamo i concetti di testing del software per capire la loro rilevanza per
    i casi d'uso GenAI e le insidie comuni da evitare.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Ora che conosci le sfide e i potenziali approcci per testare i servizi GenAI,
    rivediamo i concetti di testing del software per capire la loro rilevanza per
    i casi d'uso GenAI e le insidie comuni da evitare.
- en: Tipi di test
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Tipi di test
- en: 'Esistono tre tipi di test comuni nel testing del software che, in ordine crescente
    di dimensione e complessità, sono i seguenti:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 'Esistono tre tipi di test comuni nel testing del software che, in ordine crescente
    di dimensione e complessità, sono i seguenti:'
- en: Test unitari
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Test unitari
- en: Si concentrano sul test di singoli componenti o funzioni in modo isolato su
    un insieme discreto di input e casi limite per convalidare la funzionalità a livello
    di singolo componente. I test unitari sono atomici e hanno un ambito di applicazione
    minimo e spesso non si basano su sistemi o dipendenze esterne.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Si concentrano sul test di singoli componenti o funzioni in modo isolato su
    un insieme discreto di input e casi limite per convalidare la funzionalità a livello
    di singolo componente. I test unitari sono atomici e hanno un ambito di applicazione
    minimo e spesso non si basano su sistemi o dipendenze esterne.
- en: Test di integrazione
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Test di integrazione
- en: I test di integrazione spesso rilevano i problemi di comportamento dell'applicazione
    a livello di sottosistema, convalidando i flussi di dati e i contratti di interfaccia
    (cioè le specifiche) tra i vari componenti.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: I test di integrazione spesso rilevano i problemi di comportamento dell'applicazione
    a livello di sottosistema, convalidando i flussi di dati e i contratti di interfaccia
    (cioè le specifiche) tra i vari componenti.
- en: Test end-to-end (E2E)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Test end-to-end (E2E)
- en: Verifica le funzionalità dell'applicazione al massimo livello del sistema, dall'inizio
    alla fine, simulando scenari d'uso reali. I test E2E offrono i massimi livelli
    di fiducia nelle funzionalità e nelle prestazioni dell'applicazione, ma sono i
    più impegnativi da progettare, sviluppare e mantenere.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在系统最高级别验证应用程序的功能，从开始到结束，模拟真实使用场景。端到端测试提供了对应用程序功能和性能的最高信心水平，但它们在设计和维护方面最具挑战性。
- en: Suggerimento
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '**建议**'
- en: I test E2E e i test di integrazione hanno delle somiglianze che li rendono difficili
    da distinguere l'uno dall'altro. Se un test è grande e a volte difettoso, è possibile
    che tu stia lavorando a un test E2E.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端测试和集成测试有相似之处，使得它们难以区分。如果一个测试很大且有时有缺陷，那么你可能在处理一个端到端测试。
- en: I test di integrazione normalmente controllano un sottoinsieme di sistemi e
    interazioni, non l'intero sistema o una lunga catena di sottosistemi.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 集成测试通常控制系统的一部分和交互，而不是整个系统或长链子系统的所有部分。
- en: La[Figura 11-1](#test_types) mostra l'ambito di ciascun tipo di test. I test
    unitari mostrati a sinistra si concentrano su componenti isolati, mentre i test
    di integrazione verificano le interazioni a coppie di più componenti, anche con
    servizi esterni. Infine, i test E2E coprono l'intero percorso dell'utente e il
    flusso di dati all'interno dell'applicazione per confermare la funzionalità prevista.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-1](#test_types) 展示了每种测试类型的范围。左侧显示的单元测试集中在独立的组件上，而集成测试验证多个组件之间的交互，甚至包括外部服务。最后，端到端测试覆盖整个用户路径和应用程序内部的数据流，以确认预期的功能。'
- en: '![bgai 1101](assets/bgai_1101.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1101](assets/bgai_1101.png)'
- en: Figura 11-1\. Tipi di test nel testing del software
  id: totrans-36
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-1\. 软件测试中的测试类型
- en: Prima di implementare i test sopra citati, puoi anche utilizzare *controlli
    statici del codice* con strumenti come `mypy` per individuare gli errori di sintassi
    e di tipo. Durante la scrittura del codice, i controlli statici possono anche
    aiutarti a individuare le violazioni dello stile del codice, l'uso improprio di
    funzioni edipendenze, le vulnerabilità di sicurezza, il codice morto o inutilizzato,
    i problemi di flusso dei dati e i potenziali bug nei componenti del sistema.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施上述测试之前，你也可以使用代码的**静态检查**，例如使用 `mypy` 工具来识别语法和类型错误。在编写代码时，静态检查还可以帮助你识别代码风格的违规、函数和依赖的不当使用、安全漏洞、死代码或未使用代码、数据流问题以及系统组件中的潜在错误。
- en: Man mano che passi dai controlli statici e dai test unitari all'integrazione
    e poi ai test E2E, i tuoi casi di test diventano più preziosi ma anche più complessi,
    costosi e lenti.Inoltre, dato che i test E2E hanno un campo d'azione più ampio
    con l'interazione di più componenti, diventeranno più fragili e suscettibili di
    fallire, richiedendo aggiornamenti frequenti per rimanere allineati con le modifiche
    del codice.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你从静态检查和单元测试过渡到集成测试，再到端到端测试（E2E），你的测试案例变得更加宝贵，但也更加复杂、昂贵和缓慢。此外，由于端到端测试涉及更多组件的交互，它们将变得更加脆弱，容易失败，需要频繁更新以保持与代码更改的一致性。
- en: 'Anche i test E2E sono complessi e poco affidabili/nondeterministici. Secondo
    Martin Fowler,^([1](ch11.html#id1148)) queste sono le ragioni principali del non
    determinismo:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 即使端到端测试也很复杂且不可靠/非确定性的。根据 Martin Fowler 的观点^([1](ch11.html#id1148))，这些是非确定性的主要原因：
- en: La*mancanza di isolamento* fa sì che i componenti interferiscano tra loro, portando
    a risultati imprevedibili.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隔离不足**会导致组件之间相互干扰，导致不可预测的结果。'
- en: Un*comportamento asincrono* con operazioni che avvengono fuori sequenza o in
    momenti imprevedibili può portare a risultati non deterministici.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异步行为**，操作在非顺序或不可预测的时刻发生，可能导致非确定性的结果。'
- en: '*I servizi remoti* possono introdurre una variabilità dovuta alla latenza della
    rete, alla disponibilità del servizio o a risposte diverse.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**远程服务**可能由于网络延迟、服务可用性或不同响应而引入可变性。'
- en: Le*perdite di risorse*, se non gestite correttamente, possono portare a un comportamento
    incoerente del sistema. Le risorse interessate includono la memoria, i file handle
    o le connessioni a database, client, ecc.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源泄露**，如果管理不当，可能导致系统行为不一致。涉及的资源包括内存、文件句柄或数据库、客户端等连接。'
- en: Infine, a causa della fragilità dei test E2E, i refactoring e le modifiche alle
    funzionalità possono farli fallire. Pertanto, esiste un compromesso tra il livello
    di fiducia che ottieni dai test E2E e la flessibilità di apportare modifiche ai
    tuoi sistemi.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于端到端测试的脆弱性，重构和功能修改可能会导致测试失败。因此，在端到端测试的置信度和修改系统的灵活性之间存在权衡。
- en: La sfida più grande nel testare il software
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试软件的最大挑战
- en: La sfida più grande nel testare i servizi consiste nell'identificare cosa testare
    e con quali dettagli. A tal fine, devi decidere cosa prendere in giro, fingere
    o mantenere reale, oltre a configurare una serie di strumenti e ambienti di test.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 测试服务时最大的挑战在于确定测试什么以及测试的细节。为此，你必须决定什么可以忽略、模拟或保持真实，以及配置一系列测试工具和环境。
- en: Per superare questa sfida, puoi pianificare i test in anticipo, identificando
    i punti di rottura del sistema e restringendo i problemi ai singoli componenti
    e alle interazioni. Poi, immagina chi è l'utente ed elenca i passi che compie
    quando interagisce con i sistemi problematici. Infine, puoi tradurre questi elenchi
    di passi in test individuali e automatizzarli.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这个挑战，你可以提前规划测试，识别系统的故障点，将问题限制在单个组件和交互中。然后，想象一下用户是谁，并列出他们与有问题的系统交互时采取的步骤。最后，你可以将这些步骤列表转换为单个测试并自动化它们。
- en: Un'altra sfida con i test che causa molta frustrazione è quella di dover riscrivere
    i test ogni volta che viene modificato il codice da testare.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 测试的另一个挑战是每次测试的代码被修改时都需要重写测试，这会带来很多挫败感。
- en: Poiché i refactoring del codice non cambiano il comportamento funzionale ma
    i dettagli dell'implementazione, possono essere un segno che non stai testando
    le cose giuste. Ad esempio, se stai testando la logica interna di elaborazione
    delle stringhe della funzione `count_tokens(text)` piuttosto che solo il suo output
    finale (cioè il conteggio dei token), l'utilizzo di una libreria esterna per sostituire
    la logica di manipolazione delle stringhe può far fallire i tuoi test.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于代码重构不会改变功能性但会改变实现细节，因此这可能是一个迹象，表明你没有测试正确的事情。例如，如果你正在测试`count_tokens(text)`函数的内部字符串处理逻辑，而不是仅仅测试其最终输出（即令牌计数），使用外部库来替换字符串处理逻辑可能会导致你的测试失败。
- en: Un segno rivelatore del fatto che potresti testare i dettagli dell'implementazione
    è quando i tuoi test falliscono quando modifichi il codice (ad esempio, falsi
    positivi), oppure passano anche quando introduci modifiche radicali al codice
    (ad esempio, falsi negativi). Puoi usare tecniche come i *test black-box* per
    testare il tuo sistema fornendo degli input e osservando gli output, senza considerare
    i dettagli dell'implementazione.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一个揭示你可能正在测试实现细节的迹象是，当修改代码时你的测试失败（例如，假阳性），或者即使引入了根本性的代码修改，测试也能通过（例如，假阴性）。你可以使用*黑盒测试*等技术来测试你的系统，提供输入并观察输出，而不考虑实现的细节。
- en: Se pianifichi i tuoi test in anticipo, puoi evitare queste difficoltà.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你提前规划测试，你可以避免这些困难。
- en: Test di pianificazione
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试规划
- en: Per identificare i test necessari durante la pianificazione, puoi utilizzare
    il processo di *verifica e validazione* (V&V).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划阶段确定必要的测试时，你可以使用*验证与验证*（V&V）过程。
- en: Seguendo questo processo, prima si conferma il possesso dei requisiti giusti
    (validazione) e poi si ricorre a test per verificare che tutti i requisiti siano
    soddisfatti (verifica).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 按照此流程，首先确认拥有正确的需求（验证），然后通过测试来验证所有需求是否得到满足（验证）。
- en: Avvertenze
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意事项
- en: Una copertura del codice del 100% con test superati completerà solo il processo
    di verifica, non la validazione. Devi comunque assicurarti che i tuoi servizi
    implementino le funzioni giuste (cioè la validazione).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 通过测试覆盖率达到100%只能完成验证过程，而不是验证。你仍然必须确保你的服务实现了正确的功能（即验证）。
- en: Il processo di V&V può essere visualizzato come un modello a forma di V come
    nella [Figura 11-2](#vv).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: V&V（验证与验证）过程可以看作是一个V形模型，就像[图11-2](#vv)中所示。
- en: Quando si scende lungo il modello a V, si definiscono i requisiti del software
    e si progetta la soluzione prima di implementarla sotto forma di codice. In seguito,
    si risale la "V" eseguendo test progressivi (unità, integrazione, E2E, ecc.) per
    convalidare che la soluzione soddisfi le esigenze aziendali.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当沿着V形模型向下走时，定义软件需求并设计解决方案，在将其以代码形式实现之前。随后，通过执行渐进式测试（单元、集成、端到端等）来上升“V”，以验证解决方案是否满足业务需求。
- en: '![bgai 1102](assets/bgai_1102.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1102](assets/bgai_1102.png)'
- en: Figura 11-2\. Modello di verifica e validazione
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-2\. 验证和验证模型
- en: Come già detto in precedenza, i test di validazione possono essere difficili
    da identificare. Esattamente quali test progressivi dovresti implementare?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，验证测试可能难以识别。你应实施哪些渐进式测试？
- en: Quando hai difficoltà a individuare cosa testare, puoi scrivere dei test basati
    sui problemi e sui bug che trovi nell'applicazione. Questo approccio è *reattivo*,
    in quanto scrivi i test solo quando si presentano i problemi, il che può aiutarti
    a superare la difficoltà di non sapere cosa testare. Tuttavia, i test per risolvere
    i problemi più avanti nel *ciclo di vita dello sviluppo del software* (SDLC) richiedono
    un impegno significativo, in quanto avrai a che fare con un sistema più complesso
    con molte parti mobili da testare.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当你难以确定要测试什么时，你可以根据在应用程序中找到的问题和错误编写测试。这种方法是*反应性*的，因为你只在出现问题时编写测试，这可以帮助你克服不知道要测试什么的困难。然而，在软件开发生命周期（SDLC）的后期解决问题的测试需要大量的投入，因为你将处理一个更复杂的系统，其中有许多可移动部分需要测试。
- en: Per questo motivo, movimenti come lo *shift-left testing* sostengono l'adozione
    di pratiche di testing *preventive*, pianificate in anticipo e scritte durante
    lo sviluppo, per ridurre l'impegno di testing. La[Figura 11-3](#shift_left) dimostra
    come lo spostamento delle attività di testing all'inizio dello SLDC possa ridurre
    l'onere complessivo.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，像*左移测试*这样的运动支持在开发过程中提前规划并编写的*预防性测试实践*的采用，以减少测试工作量。[图11-3](#shift_left)展示了如何将测试活动移至SLDC（软件生命周期开发周期）的开始，从而减少总体负担。
- en: '![bgai 1103](assets/bgai_1103.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1103](assets/bgai_1103.png)'
- en: Figura 11-3\. Test del software con il cambio a sinistra
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-3\. 软件左移测试
- en: Un approccio comune nei test shift-left è il *test-driven development* (TDD),
    come mostrato nella [Figura 11-4](#tdd).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 测试左移的常见方法之一是*测试驱动开发*（TDD），如图11-4所示。
- en: '![bgai 1104](assets/bgai_1104.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1104](assets/bgai_1104.png)'
- en: Figura 11-4\. TDD
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-4\. TDD
- en: Nell'approccio TDD, scrivi i test prima del codice vero e proprio. Si tratta
    di un processo iterativo in cui i test scritti falliranno all'inizio, ma il tuo
    obiettivo sarà quello di scrivere la quantità minima di codice per far sì che
    i test passino. Una volta passati, rifattorizzerai il codice per ottimizzare il
    sistema, mantenendo i test passati per concludere il processo TDD iterativo.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在TDD（测试驱动开发）方法中，先编写测试，然后再编写实际代码。这是一个迭代过程，其中编写的测试最初会失败，但你的目标将是编写尽可能少的代码以确保测试通过。一旦通过，你将重构代码以优化系统，同时保持测试通过以完成TDD迭代过程。
- en: Suggerimento
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 建议
- en: Un ottimo esempio di come le pratiche TDD siano utili per testare i servizi
    GenAI è durante l'*ingegnerizzazione del prompt*. Scrivi prima una serie di test
    e poi continua a iterare sul design del prompt finché tutti i test non passano.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: TDD（测试驱动开发）的一个很好的例子是在*提示工程*期间测试GenAI（生成式人工智能）服务。首先编写一系列测试，然后继续迭代提示设计，直到所有测试都通过。
- en: Utilizzando gli stessi casi di test, puoi verificare eventuali segni di regressione
    e se il cambio di modello riduce le prestazioni dei tuoi servizi.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的测试案例，你可以验证任何回归迹象，以及模型更改是否降低了你的服务性能。
- en: Come puoi vedere, l'obiettivo generale del TDD è quello di ridurre gli sforzi
    di testing migliorando la qualità del codice, la progettazione della soluzione
    e l'individuazione precoce dei problemi.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，TDD（测试驱动开发）的总体目标是通过提高代码质量、解决方案设计和早期问题识别来减少测试工作量。
- en: Dimensioni del test
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试尺寸
- en: 'Inoltre, durante la pianificazione, devi decidere le varie dimensioni dei test,
    tra cui l''*ambito*, la *copertura* e la *completezza*:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在规划过程中，你必须决定测试的各个维度，包括*范围*、*覆盖率*和*完整性*：
- en: Ambito di applicazione
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 应用范围
- en: Definisce quali sono i componenti, i sistemi e gli scenari d'uso da testare.
    Come parte della definizione dell'ambito, dovrai anche tracciare i *confini del
    test* per chiarire cosa sarà testato e cosa no.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 定义需要测试的组件、系统和用例。作为定义范围的一部分，你还必须跟踪*测试边界*，以明确将要测试什么以及不测试什么。
- en: Copertura o superficie di prova
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 测试覆盖或测试表面
- en: Misura la quantità di sistema o di codice da testare.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 测量需要测试的系统或代码量。
- en: Completezza
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 完整性
- en: Indica quanto dettagliati, approfonditi e completi saranno i tuoi test all'interno
    dell'ambito e della copertura definiti. Ad esempio, dovrai decidere se testare
    ogni potenziale utilizzo, gli scenari di successo e di fallimento e i casi limite
    per ogni componente, sistema e interazione.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 指示你的测试在定义的范围和覆盖范围内将有多详细、多深入和完整。例如，你必须决定是否测试每个潜在的使用情况、成功和失败的场景以及每个组件、系统和交互的边界情况。
- en: Il *volume/spazio* definisce i confini e le dimensioni di ciò che viene testato;
    la superficie misura la diffusione dei test; la profondità implica il dettaglio,
    la profondità e la completezza dei casi di test.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*体积/空间*定义了被测试内容的边界和尺寸；表面衡量测试的扩散；深度意味着测试案例的详细程度、深度和完整性。'
- en: Dati del test
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试数据
- en: 'Per ottenere una maggiore copertura e completezza dei test, puoi sfruttare
    quattro diversi tipi di dati di test:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更全面的测试覆盖和完整性，你可以利用四种不同的测试数据类型：
- en: Dati validi
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 有效数据
- en: Gli ingressi al sistema rientrano nell'intervallo valido e previsto in condizioni
    normali.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的输入在正常情况下符合预期和有效的区间内。
- en: Dati non validi
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 无效数据
- en: Input inaspettati, sbagliati, NULL o al di fuori dell'intervallo valido. Puoi
    utilizzare i dati negativi per verificare il comportamento del sistema quando
    vengono utilizzati in modo improprio.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 预期之外、错误、NULL或超出有效区间的输入。你可以使用负数据来验证系统在不当使用时的行为。
- en: Dati di confine
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 边界数据
- en: I dati del test si trovano ai limiti degli intervalli di ingresso accettabili,
    sia al limite superiore che a quello inferiore.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据位于可接受输入区间的边界上，无论是上限还是下限。
- en: Dati enormi
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 巨大的数据
- en: Utilizzato per le prestazioni e per lo stress test del sistema per misurarne
    i limiti.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 用于测量系统性能和压力测试的极限。
- en: Fasi del test
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试阶段
- en: 'Non importa se stai implementando un test unitario, di integrazione o E2E,
    puoi strutturare i test in diverse fasi distinte utilizzando il modello *dato-quando-allora*
    (GWT), come illustrato qui:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是在实现单元测试、集成测试还是端到端测试，你都可以使用*数据-当-那么*（GWT）模型来结构化不同的测试阶段，如下所示：
- en: '*Dati (precondizioni)*: Prima di ogni test, puoi impostare le condizioni di
    test e gli stati o i dati predefiniti (ad esempio, le *fixture*).'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*数据（预条件）*：在每次测试之前，你可以设置测试条件和预定义的状态或数据（例如，*固定值*）。'
- en: '*Quando (fasi del test)*: durante il test, eseguirai una serie di azioni che
    vorrai testare. È qui che passerai le tue fixture di test al *sistema sotto test*
    (SUT) che, a seconda dell''ambito del test, può essere una singola funzione o
    l''interoservizio.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*当（测试阶段）*：在测试过程中，你将执行一系列你想要测试的动作。在这里，你将你的测试固定值传递给*被测试系统*（SUT），根据测试范围，它可能是一个单独的函数或整个服务。'
- en: '*Poi (risultati attesi)*: dopo aver eseguito la SUT con le fixture, in questa
    fase verificherai i risultati rispetto alle tue aspettative utilizzando una serie
    di asserzioni.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*然后（预期结果）*：在用固定值执行SUT之后，在这个阶段，你将通过一系列断言来验证结果是否符合你的预期。'
- en: '*Pulizia*: Una volta terminato, puoi ripulire gli artefatti del test in una
    fase opzionale di*pulizia/strappo*.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*清理*：一旦完成，你可以在一个可选的*清理/剥离*阶段清理测试的工件。'
- en: '`pytest` raccomanda di strutturare i test utilizzando il modello *arrange-act-assert-cleanup*,
    che corrisponde direttamente al modello GWT con una fase di pulizia opzionale.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest`推荐使用*安排-执行-断言-清理*（arrange-act-assert-cleanup）模型来结构化测试，这直接对应于GWT模型，并包含一个可选的清理阶段。'
- en: Ambienti di prova
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试环境
- en: Quando pianifichi i test, devi anche considerare diversi *ambienti di test*
    che coprono il tempo di compilazione, il tempo di compilazione e gli ambienti
    di runtime.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当你计划测试时，你也必须考虑覆盖编译时间、编译时间和运行时环境的多个*测试环境*。
- en: In molti linguaggi di programmazione, il *momento della compilazione* è quello
    in cui il codice sorgente viene tradotto in codice eseguibile. Ad esempio, se
    stai scrivendo del codice in C++, il processo di compilazione prevede un controllo
    completo dei tipi di codice. Se vengono riscontrati errori di tipo, il processo
    di compilazione fallisce. Una volta che tutti i controlli sono stati superati,
    il compilatore C++ traduce il codice in un file binario eseguibile.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多编程语言中，*编译时刻*是源代码被转换为可执行代码的时刻。例如，如果你正在用C++编写代码，编译过程包括对代码类型的全面检查。如果发现类型错误，编译过程将失败。一旦所有检查都通过，C++编译器将代码转换为可执行的二进制文件。
- en: Nota
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: La tipizzazione forte in C++ è stata progettata per migliorare il rilevamento
    degli errori, la robustezza del codice e il supporto degli strumenti per gli sviluppatori
    in codebase più grandi e complesse che cambiano frequentemente.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: C++中的强类型设计是为了提高错误检测、代码的鲁棒性以及在大而复杂的代码库中频繁变化的情况下支持开发者工具。
- en: Essendo un linguaggio interpretato, Python non ha un tempo di compilazione tradizionale
    come il C++, ma converte il codice in bytecode per l'esecuzione.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种解释型语言，Python没有像C++那样的传统编译时间，但它将代码转换为字节码以执行。
- en: Durante le ispezioni, i controllori statici del codice come `mypy` possono identificare
    i problemi di base del tuo codice, fungendo da livello di verifica iniziale per
    i tuoi sforzi di testing.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在审查过程中，代码的静态检查工具如`mypy`可以识别你的代码的基本问题，作为测试努力的初步验证级别。
- en: Avvertenze
  id: totrans-107
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意事项
- en: Poiché Python è un linguaggio tipizzato dinamicamente, non applica la tipizzazione
    per impostazione predefinita. Tuttavia, i controllori statici di tipo come `mypy`
    possono fornire un valore significativo se utilizzi i suggerimenti di tipo nel
    tuo codice Python.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Python是一种动态类型语言，它默认不应用类型检查。然而，如果你在Python代码中使用类型提示，像`mypy`这样的类型检查器可以提供有价值的帮助。
- en: Mentre i controlli statici sono ottimi per individuare i problemi di base del
    codice in fase di compilazione, i test unitari, di integrazione e E2E possono
    verificare la funzionalità del sistema in fase *di esecuzione* quando si esegue
    il codice dell'applicazione. In fase di runtime, strumenti come Pydantic possono
    eseguire controlli di convalida dei dati per individuare strutture di dati inaspettate.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的静态检查非常适合在编译阶段发现代码的基本问题，而单元测试、集成测试和端到端测试可以在执行代码时验证系统的功能。在运行时，像Pydantic这样的工具可以执行数据验证检查，以识别意外的数据结构。
- en: I tuoi servizi GenAI possono anche richiedere ulteriori fasi di configurazione
    e compilazione, come il download dei pesi e il precaricamento dei modelli, prima
    di eseguire il codice dell'applicazione. L'ambiente in cui vengono completate
    le fasi di compilazione, la configurazione e l'installazione delle dipendenze
    viene definito *tempo di compilazione*, che puoi anche testare.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 你的GenAI服务可能还需要额外的配置和编译阶段，如下载权重和预加载模型，然后才能执行应用程序代码。编译、配置和依赖项安装的阶段完成的环境被定义为*编译时间*，这也可以进行测试。
- en: Strategie di test
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试策略
- en: Nel panorama del software, diversi esperti hanno sviluppato strategie per bilanciare
    la distribuzione dei test nei progetti, che si basano su anni di esperienza di
    testing del software da parte degli sviluppatori che le hanno rese popolari.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件领域，许多专家已经开发了平衡项目测试分布的策略，这些策略基于开发者多年的软件测试经验，并因此变得流行。
- en: La strategia più adottata è la *piramide dei test*, come mostrato nella[Figura
    11-5](#testing_pyramid), che promuove la scrittura di più test unitari.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的策略是*测试金字塔*，如图[图11-5](#testing_pyramid)所示，它促进了更多单元测试的编写。
- en: '![bgai 1105](assets/bgai_1105.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1105](assets/bgai_1105.png)'
- en: Figura 11-5\. Piramide dei test
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-5. 测试金字塔
- en: La[Tabella 11-1](#testing_pyramid_example) illustra lo scopo di ogni livello
    della piramide di test con un esempio concreto nel contesto di un servizio GenAI.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[表11-1](#testing_pyramid_example)展示了测试金字塔每个层次的用途，通过一个具体的GenAI服务示例来说明。'
- en: Tabella 11-1\. Test della piramide nel mondo reale
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 表11-1. 现实世界中的测试金字塔
- en: '| Strato | Scopo | Esempio |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 层级 | 目的 | 示例 |'
- en: '| --- | --- | --- |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Test end-to-end | Convalida l''intero flusso dell''applicazione dall''inizio
    alla fine | Testare il login dell''utente, generare testo in base a un prompt
    e salvare il contenuto generato |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 端到端测试 | 验证应用程序从开始到结束的整个流程 | 测试用户登录，根据提示生成文本并保存生成的内容 |'
- en: '| Test di integrazione | Verifica che i vari moduli o servizi funzionino correttamente
    insieme | Testare le interazioni tra l''API di generazione del testo e il database
    che memorizza i prompt dell''utente e i testi generati |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 集成测试 | 验证各个模块或服务是否能够正确协同工作 | 测试文本生成API与存储用户提示和生成文本的数据库之间的交互 |'
- en: '| Test unitari | Verifica singoli componenti o funzioni in modo isolato | Testare
    varie funzioni di utilità che elaborano gli input del modello, ad esempio per
    rimuovere i contenuti inappropriati. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 单元测试 | 以隔离方式验证单个组件或功能 | 测试各种处理模型输入的实用函数，例如移除不适当的内容。 |'
- en: Il problema del modello piramidale è che mentre i test unitari migliorano la
    copertura del codice, non necessariamente migliorano la "copertura del business",
    poiché i requisiti del progetto e i casi d'uso potrebbero non essere testati a
    fondo. Di conseguenza, affidarsi solo ai test unitari può creare un falso senso
    di sicurezza, trascurando potenzialmente di testare la logica di business essenziale
    e i flussi di lavoro degli utenti. D'altra parte, i test di integrazione ti permettono
    di coprire più terreno e i test orientati al business.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 金字塔模型的难题在于，虽然单元测试可以提高代码覆盖率，但并不一定能提高“业务覆盖率”，因为项目需求和用例可能没有得到充分测试。因此，仅依赖单元测试可能会产生虚假的安全感，可能会忽略测试关键的业务逻辑和用户工作流。另一方面，集成测试允许你覆盖更多领域，以及面向业务的测试。
- en: Avvertenze
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意事项
- en: Gli esperti di testing del software hanno anche identificato alcune strategie
    come *anti-pattern* che sono controproducenti.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 软件测试专家还识别了一些被认为是*反模式*的策略，这些策略是无效的。
- en: Se li segui, spenderai una quantità eccessiva di tempo per configurare i test,
    implementerai test troppo specifici e strettamente accoppiati e finirai per avere
    test che presentano un comportamento non deterministico a scatti.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遵循这些策略，你将花费过多的时间来配置测试，实现过于具体和紧密耦合的测试，最终可能会得到具有非确定性行为的测试。
- en: La[Tabella 11-2](#testing_antipatterns) e la [Figura 11-6](#testing_antipatterns_viz)
    mostrano un elenco di anti-pattern per il testing del software.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[表11-2](#testing_antipatterns) 和 [图11-6](#testing_antipatterns_viz) 展示了软件测试的反模式列表。'
- en: Tabella 11-2\. Antipattern per il testing del software
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 表11-2\. 软件测试反模式
- en: '| Strategia | Distribuzione del test | Commenti |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 战略 | 测试分布 | 评论 |'
- en: '| --- | --- | --- |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Prova del cono gelato | Un piccolo numero di test unitari con un gran numero
    di test di integrazione e E2E, seguiti da test manuali. | Evitare. Considerato
    un anti-pattern a causa dell''inefficienza dell''implementazione dei test manuali
    e degli alti costi di mantenimento dei test di integrazione e E2E. |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 冰淇淋锥测试 | 少量的单元测试和大量的集成测试以及端到端测试，随后是手动测试。 | 避免使用。由于手动测试实现效率低下以及集成测试和端到端测试的维护成本高昂，被认为是一种反模式。
    |'
- en: '| Test del cupcake | Simile al cono gelato; ha un piccolo numero di test di
    unità e integrazione automatizzati, un numero moderato di test E2E/GUI automatizzati
    e un gran numero di test manuali.Ogni tipo di test viene eseguito da un team diverso.
    | Evitare. Considerato un anti-pattern perché può portare a cicli di feedback
    lenti, a spese di comunicazione tra i team e a test fragili con alti costi di
    manutenzione. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 蛋糕测试 | 与冰淇淋锥测试类似；有少量的单元测试和集成自动化测试，中等数量的端到端/GUI自动化测试，以及大量的手动测试。每种类型的测试由不同的团队执行。
    | 避免使用。被认为是一种反模式，因为它可能导致反馈周期缓慢，团队间沟通成本增加，以及维护成本高昂的脆弱测试。 |'
- en: '| Test della clessidra | Un gran numero di test unitari alla base e di test
    E2E in alto, ma un numero significativamente inferiore di test di integrazione
    al centro. | Evita. Considerato un anti-pattern. Non è così grave come il cono
    gelato, ma comporta comunque un numero eccessivo di fallimenti di test che i test
    di media portata avrebbero potuto coprire. |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 水晶球测试 | 底部有大量的单元测试和顶部的端到端测试，但中间的集成测试数量显著较少。 | 避免使用。被认为是一种反模式。虽然不如冰淇淋锥测试严重，但仍然会导致大量的测试失败，这些失败本可以通过中等范围的测试覆盖。
    |'
- en: '![bgai 1106](assets/bgai_1106.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1106](assets/bgai_1106.png)'
- en: Figura 11-6\. Visualizzazione degli anti-pattern di testing
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-6\. 测试反模式可视化
- en: La[Tabella 11-3](#testing_strategies) e la [Figura 11-7](#testing_strategies_viz)
    mettono a confronto le strategie di testing del software.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[表11-3](#testing_strategies) 和 [图11-7](#testing_strategies_viz) 对比了软件测试策略。'
- en: Tabella 11-3\. Confronto tra le strategie di test
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 表11-3\. 测试策略对比
- en: '| Strategia | Distribuzione del test | Commenti |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 战略 | 测试分布 | 评论 |'
- en: '| --- | --- | --- |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Piramide di test**(Mike Cohn) | Un gran numero di test unitari alla base,
    meno test di integrazione al centro e ancora meno test E2E in cima. | Tuttavia,
    la piramide può essere percepita come un concetto fisico per promuovere la costruzione
    del livello inferiore di test unitari, per poi costruire il livello successivo
    e così via, fino a raggiungere la cima. Questo approccio è inefficace se applicato
    ad applicazioni legacy con un''ampia base di codice. |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| **测试金字塔**(Mike Cohn) | 底部有大量的单元测试，中间较少的集成测试，顶部更少的端到端测试。 | 然而，金字塔可以被看作是一个物理概念，用来促进单元测试底层的构建，然后构建下一层，以此类推，直到达到顶部。如果将这种方法应用于具有广泛代码基础的遗留应用程序，则这种方法是无效的。
    |'
- en: '| **Trofeo di prova**(Kent C. Dodds) | Si concentra su una solida base di controlli
    statici, poi test unitari, seguiti da test di integrazione e da un numero minore
    di test E2E in cima. | La motivazione è che i test E2E e di integrazione sono
    i più validi. Tuttavia, i test E2E sono lenti e costosi. I test di integrazione
    rappresentano un equilibrio tra i due mondi. |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| **测试奖杯**(Kent C. Dodds) | 专注于一个坚实的静态控制基础，然后是单元测试，接着是集成测试，最后是顶部较少的端到端测试。 |
    动机是端到端测试和集成测试是最有效的。然而，端到端测试是缓慢且昂贵的。集成测试代表了这两个世界的平衡。 |'
- en: '| **Prova il nido d''ape**(Stephen H. Fishman) | Rappresenta un approccio equilibrato
    con uguale enfasi su unità, integrazione, E2E e altri tipi di test (prestazioni,
    sicurezza, ecc.). | Può essere meno efficiente se non viene gestita correttamente
    e può non essere ottimale per ogni progetto. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| **测试蜂巢**(Stephen H. Fishman) | 代表了一个平衡的方法，对单元、集成、端到端和其他类型的测试（性能、安全等）给予同等重视。
    | 如果没有得到正确管理，可能效率较低，并且可能不是每个项目的最佳选择。 |'
- en: '![bgai 1107](assets/bgai_1107.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1107](assets/bgai_1107.png)'
- en: Figura 11-7\. Visualizzazione delle strategie di test
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-7. 测试策略可视化
- en: Per i servizi GenAI, che spesso comportano integrazioni complesse e considerazioni
    sulle prestazioni, la strategia di testing trofeo potrebbe essere la più adatta.
    La strategia trofeo consiste in una solida base di controlli statici, alimentati
    da strumenti come `mypy` e Pydantic, affiancati da test di integrazione che raggiungono
    un equilibrio tra valore, fiducia e costi di testing.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 对于GenAI服务，由于通常涉及复杂的集成和性能考虑，测试策略奖杯可能是最合适的。奖杯策略包括一个由`mypy`和Pydantic等工具支持的静态控制坚实基础，辅以达到价值、信任和测试成本之间平衡的集成测试。
- en: Se i tuoi servizi GenAI devono essere testati in modo completo con diversi tipi
    di test, compresi quelli di performance e quelli esplorativi, allora il modello
    a nido d'ape potrebbe essere più adatto al tuo progetto, in quanto può uniformare
    gli sforzi di test.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的GenAI服务需要通过多种类型的测试进行全面测试，包括性能测试和探索性测试，那么蜂巢模型可能更适合你的项目，因为它可以统一测试的努力。
- en: Ora dovresti sentirti più a tuo agio nell'identificare gli esami di cui hai
    bisogno e nel pianificare i tuoi test.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该更自在地识别你需要参加的考试，并规划你的测试。
- en: Ora che conosci i concetti di testing del software, esaminiamo le sfide e i
    potenziali approcci al testing dei servizi GenAI.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了软件测试的概念，让我们来探讨GenAI服务测试的挑战和潜在的方法。
- en: Le sfide del test dei servizi GenAI
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GenAI服务测试的挑战
- en: Se hai deciso di testare i tuoi servizi GenAI, dovrai affrontare diverse sfide.
    Il test dei servizi che sfruttano modelli GenAI probabilistici richiede un approccio
    più completo rispetto al software tradizionale.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你决定测试你的GenAI服务，你将面临不同的挑战。利用GenAI概率模型的服务的测试需要比传统软件更全面的方法。
- en: Vediamo alcuni motivi per cui testare i servizi GenAI sarà una sfida.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看一下为什么测试GenAI服务将是一个挑战。
- en: Variabilità dei risultati (flaccidezza)
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果的变异性（脆弱性）
- en: A parità di input e di codice di implementazione, i servizi GenAI spesso producono
    output diversi. Gli output variano perché questi modelli utilizzano tecniche probabilistiche
    come il campionamento da una distribuzione piuttosto che affidarsi a funzioni
    deterministiche. Naturalmente, la variabilità che si riscontra negli output può
    dipendere dal modello e la regolazione delle configurazioni, come i valori di
    temperatura, può ridurre questavarianza.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在相同的输入和实现代码下，GenAI服务通常会产生不同的输出。输出之所以不同，是因为这些模型使用概率技术，如从分布中进行采样，而不是依赖于确定性函数。当然，观察到的输出变异性可能取决于模型和配置的调节，如温度值，这可以减少这种变异性。
- en: 'La variabilità degli output dei modelli GenAI può anche far esplodere il numero
    di potenziali casi di test che puoi scrivere (cioè l''*area/ambito di applicazione
    dei test*) per coprire tutte le possibilità. Per questo motivo, non puoi affidarti
    completamente a test deterministici: i tuoi test funzioneranno in modo incoerente
    e saranno troppo *deboli* per essere eseguiti in modo affidabile in una pipeline
    CI/CD.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI模型的输出可变性也可能导致你可以编写的潜在测试案例数量激增（即测试的*应用范围/领域*），以覆盖所有可能性。因此，你不能完全依赖确定性测试：你的测试将无法连贯执行，并且过于*薄弱*，无法在CI/CD管道中可靠执行。
- en: 'Dovresti invece affrontare il problema dei test GenAI da una prospettiva statistica
    e probabilistica: prendi diversi campioni basati su ipotesi valide da una *distribuzione
    legittima di input* per verificare la qualità dei prodotti in uscita dal tuo modello.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该从统计和概率的角度来处理GenAI测试问题：从*合法输入分布*中基于有效假设抽取多个样本，以验证模型输出的产品质量。
- en: Nota
  id: totrans-156
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Per *distribuzione legittima degli input*, intendo la selezione di input che
    siano in linea con lo scopo del modello, rappresentativi di scenari reali e rilevanti
    per il problema che stai cercando di risolvere con il modello.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*合法输入分布*，我指的是选择与模型目标一致、代表现实场景且与你要用模型解决的问题相关的输入。
- en: Un approccio più complesso consiste nell'utilizzare modelli di discriminazione
    per attribuire un punteggio ai risultati variabili del tuo servizio, a patto che
    tu stabilisca delle aspettative di una certa tolleranza o soglia.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更复杂的方法是使用判别模型对你的服务可变结果进行评分，前提是你设定了某种容忍度或阈值的期望。
- en: Vedrai degli esempi di come farlo più avanti nel capitolo.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本章后面看到如何做到这一点的一些示例。
- en: Vincoli di prestazioni e risorse (lento e costoso)
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能和资源限制（慢且昂贵）
- en: Poiché il test dei servizi GenAI richiede un approccio più statistico e/o multimodello,
    dovrai affrontare anche problemi di latenza, utilizzo e hosting.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GenAI服务的测试需要更统计和/或多模型的方法，你还将面临延迟、使用和托管等问题。
- en: I tuoi test non possono essere eseguiti in modo sufficientemente veloce e affidabile
    per essere eseguiti continuamente all'interno di una pipeline CI/CD tradizionale.
    Finirai per avere costi eccessivi per l'utilizzo dei token con chiamate multiple
    alle API dei modelli e test multimodello complessi e lenti. Queste sfide rimangono
    a meno che tu non faccia diverse ipotesi per semplificare l'ambito dei test, ridurre
    la frequenza dei test dei modelli e utilizzare tecniche di test efficienti come
    il mocking e il patching, l'iniezione di dipendenza e i test statistici di ipotesi.
    Puoi anche studiare l'uso di piccoli modelli discriminatori sintonizzati per ridurre
    la latenza e migliorare le prestazioni.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你的测试无法以足够快和可靠的方式在传统的CI/CD管道中连续执行。你将面临因多次调用模型API和复杂的、缓慢的多模型测试而导致的过高成本。除非你做出假设以简化测试范围、减少模型测试频率并使用如mocking和patching、依赖注入和假设统计测试等高效的测试技术，否则这些挑战将持续存在。你也可以研究使用小型调谐判别模型来减少延迟并提高性能。
- en: Regressione
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归
- en: '*I test di regressione* sono un altro tipo di test da pianificare quando si
    lavora con imodelli GenAI.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '*回归测试*是当你与GenAI模型一起工作时需要计划的一种测试类型。'
- en: 'Una [ricerca pubblicata nel 2023](https://oreil.ly/1oLQG) che ha confrontato
    il comportamento di ChatGPT nel tempo ha rilevato che:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 一项于2023年发布的[研究](https://oreil.ly/1oLQG)比较了ChatGPT随时间的行为，发现：
- en: Le prestazioni e il comportamento di GPT-3.5 e GPT-4 possono variare notevolmente
    nel tempo. Ad esempio, GPT-4 (marzo 2023) è stato ragionevole nell'identificare
    i numeri primi rispetto ai numeri composti (84% di accuratezza), ma GPT-4 (giugno
    2023) è stato scarso in queste stesse domande (51% di accuratezza). GPT-4 è diventato
    meno disposto a rispondere alle domande sensibili e alle domande del sondaggio
    d'opinione a giugno rispetto a marzo. Inoltre, sia GPT-4 che GPT-3.5 hanno avuto
    più errori di formattazione nella generazione del codice a giugno rispetto a marzo.
  id: totrans-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-3.5和GPT-4的性能和行为可能会随时间显著变化。例如，GPT-4（2023年3月）在识别素数与合数方面表现合理（准确率为84%），但GPT-4（2023年6月）在这些相同的问题上表现不佳（准确率为51%）。与3月相比，GPT-4在6月对敏感问题和调查问卷问题的回答意愿降低。此外，GPT-4和GPT-3.5在6月生成代码时的格式错误比3月更多。
- en: Secondo questo studio, il comportamento dello "stesso" servizio LLM può cambiare
    in modo sostanziale in un lasso di tempo relativamente breve, evidenziando la
    necessità di un monitoraggio continuo di LLMs (e di qualsiasi servizio GenAI).
    Sulla base di questa scoperta, puoi supporre che le prestazioni dei tuoi servizi
    GenAI possano peggiorare nel tempo a causa della messa a punto o della riqualificazione
    del modello, dei cambiamenti nei modelli di interazione dell'utente e dei cambiamenti
    nei dati di formazione o nell'ambiente operativo.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这项研究，即使是“相同”的LLM服务在相对较短的时间内也可能发生显著变化，这突显了对LLMs（以及任何GenAI服务）进行持续监控的必要性。基于这一发现，你可以假设你的GenAI服务的性能可能会随着时间的推移而恶化，这是由于模型的调整或重新训练、用户交互模型的变化以及训练数据或操作环境的变化。
- en: Per approfondire, i modelli di intelligenza artificiale probabilistici possono
    subire una *deriva del modello*, ovvero una riduzione delle prestazioni nel tempo
    attribuibile ai dati di addestramento sottostanti. La messa a punto su dati aggiuntivi
    può avere effetti collaterali inaspettati sul comportamento del modello in altri
    compiti.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 为了深入了解，概率性人工智能模型可能会经历一种*模型漂移*，即随着时间的推移，性能下降，这种下降可以归因于训练数据。在额外数据上的开发可能会对模型在其他任务中的行为产生意外的副作用。
- en: 'Con il passare del tempo, i dati di addestramento originali possono allontanarsi
    dalla realtà: le tendenze cambiano, si verificano nuovi eventi storici, le lingue
    si evolvono e la conoscenza umana si espande o muta assumendo nuove forme che
    non possono essere colte se i dati di addestramento non vengono continuamente
    aggiornati.Questo fenomeno che causa la deriva del modello viene definito *deriva
    concettuale*, che si verifica quando le proprietà statistiche della variabile
    target che il modello sta cercando di prevedere cambiano nel tempo. La deriva
    concettuale può portare a un peggioramento delle prestazioni del modello perché
    le relazioni e i modelli appresi durante l''addestramento non sono più validi.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，原始的训练数据可能会远离现实：趋势在变化，新的历史事件发生，语言在发展，人类知识以新的形式扩展或变化，而这些变化如果不能持续更新训练数据就无法捕捉到。这种导致模型漂移的现象被称为*概念漂移*，它发生在模型试图预测的目标变量的统计属性随时间变化时。概念漂移可能导致模型性能下降，因为训练期间学习的关联和模型不再有效。
- en: Inoltre, anche la *deriva dei dati*, che comporta cambiamenti nella distribuzione
    delle caratteristiche di input all'interno dei dati di formazione, può portare
    alla deriva del modello.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，*数据漂移*，即数据集中输入特征分布的变化，也可能导致模型漂移。
- en: Questo tipo di deriva è spesso dovuta a cambiamenti nei metodi di campionamento,
    nella distribuzione della popolazione e nella raccolta dei dati, a cambiamenti
    stagionali ed effetti temporali nei dati, a cambiamenti esterni nelle fonti di
    dati o a problemi di qualità nelle pipeline di elaborazione.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这种漂移通常是由于采样方法、人口分布和数据收集的变化，数据中的季节性和时间效应，数据源的外部变化或数据处理管道中的质量问题所引起的。
- en: I test di regressione e il monitoraggio (in particolare se ti affidi a fornitori
    di modelli esterni come OpenAI) possono aiutarti a individuare i problemi di deriva
    del modello sulle tue attività e sui tuoi casi d'uso specifici. Qualsiasi potenziale
    deriva può essere affrontata a livello di applicazione tramite la convalida dei
    dati o l'utilizzo di tecniche come il RAG o a livello di modello tramite la riqualificazione
    e la messa a punto del modello per ridurre i problemi di regressione.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 回归测试和监控（尤其是如果你依赖外部模型提供商如OpenAI）可以帮助你识别你的活动和特定用例中的模型漂移问题。任何潜在的数据漂移都可以通过数据验证或使用如RAG等技术来处理，或者在应用层面通过重新训练和调整模型来减少回归问题。
- en: Pregiudizio
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏差
- en: Un'altra grande sfida nel testare i servizi GenAI è quella di rilevare le distorsioni
    dei modelli prima di metterli in produzione. Spesso le distorsioni vengono analizzate
    durante il processo di esplorazione dei dati da parte dei data scientist e degli
    ingegneri ML responsabili della produzione dei modelli. Tuttavia, con i modelli
    GenAI di ampia portata, c'è sempre la possibilità che venga introdotta una qualche
    forma di distorsione a causa di una valutazione errata, dei metodi di campionamento,
    dell'elaborazione dei dati, degli algoritmi di formazione o di distorsioni nascoste
    nei dati stessi.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试通用人工智能服务时，另一个重大挑战是在投入生产之前检测模型的偏差。通常，偏差是在数据科学家和负责模型生产的机器学习工程师进行数据探索过程中被分析的。然而，对于范围广泛的通用人工智能模型，总有可能因为评估错误、采样方法、数据处理、训练算法或数据中隐藏的偏差而引入某种形式的偏差。
- en: Ad esempio, se un modello linguistico viene addestrato su un set di dati che
    contiene per lo più testi relativi a un gruppo demografico specifico, potrebbe
    generare risultati orientati verso quel gruppo demografico, escludendo potenzialmente
    altri gruppi. Allo stesso modo, se un modello di riconoscimento delle immagini
    viene addestrato per lo più su immagini di uomini che svolgono professioni come
    medici e ingegneri, potrebbe imparare a generare immagini con un pregiudizio di
    genere.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果一个语言模型在主要包含特定人口群体相关文本的数据集上训练，它可能会产生倾向于该人口群体的结果，从而排除其他潜在群体。同样，如果一个图像识别模型主要在医生和工程师等职业男性的图像上训练，它可能会学会生成带有性别偏见的图像。
- en: Il pregiudizio diventa particolarmente grave negli scenari in cui si desidera
    utilizzare gli LLMs come giudici, ad esempio come strumenti di valutazione dell'intelligenza
    artificiale o valutatori di colloqui.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在希望使用大型语言模型（LLMs）作为法官的场景中，偏见变得尤为严重，例如作为人工智能评估工具或面试评估者。
- en: I pregiudizi possono manifestarsi in varie forme, come pregiudizi di genere,
    pregiudizi razziali, pregiudizi di età e così via, e ogni tipo di pregiudizio
    richiede test e metriche specifiche per essere rilevato. Senza sapere per cosa
    fare i test, non puoi verificare con sicurezza se i tuoi servizi GenAI sono al
    100% privi di pregiudizi.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 偏见可以以多种形式表现出来，如性别偏见、种族偏见、年龄偏见等等，每种偏见都需要特定的测试和指标来检测。如果不清楚要测试什么，就无法确保你的通用人工智能服务100%没有偏见。
- en: Una possibile soluzione a questo problema è quella di sfruttare gli autocontrolli
    dei modelli e i discriminatori dell'intelligenza artificiale, dove un modello
    secondario identifica o misura la presenza di eventuali pregiudizi. Spesso c'è
    un compromesso tra latenza e quote di utilizzo quando si rilevano i pregiudizi
    durante il runtime del servizio.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的可能方法之一是利用模型的自我控制和人工智能的判别器，其中次要模型识别或测量潜在偏见的存在。在服务运行时检测偏见时，通常需要在延迟和利用率之间做出权衡。
- en: Attacchi avversari
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对抗性攻击
- en: I servizi GenAI rivolti al pubblico possono essere vulnerabili ad attacchi avversari
    come la manipolazione dei token, la gestione insicura dei dati, la richiesta di
    jailbreak o l'iniezione di prompt, la divulgazione di informazioni sensibili,
    l'avvelenamento dei dati, il furto di modelli, il denial of service, l'eccessiva
    agenzia e in generale l'uso improprio e l'abuso. Per questo motivo, qualsiasi
    servizio GenAI esposto a Internet dovrà includere livelli di protezione.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 面向公众的通用人工智能服务可能容易受到对抗性攻击，如令牌操纵、数据管理不安全、请求越狱或提示注入、敏感信息泄露、数据中毒、模型盗窃、拒绝服务、过度代理以及一般的不当使用和滥用。因此，任何暴露于互联网的通用人工智能服务都必须包括保护级别。
- en: Risorse e liste di controllo come la [top 10 di OWASP per le applicazioni LLM](https://genai.owasp.org)
    forniscono un punto di partenza per aggiungere protezioni ai tuoiservizi GenAI.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如[OWASP LLM应用前10名](https://genai.owasp.org)等资源和清单提供了为你的通用人工智能服务添加保护措施的一个起点。
- en: Tuttavia, la creazione di meccanismi di salvaguardia può essere impegnativa
    perché i metodi attuali, al momento in cui scriviamo, si basano su modelli di
    classificazione e discriminazione per rilevare gli attacchi avversari e i contenuti
    dannosi. Questi modelli di salvaguardia spesso richiedono centinaia di megabyte
    di dipendenze, il che può appesantire l'applicazione, rallentare significativamente
    il throughput del servizio e non riuscire a individuare ogni potenziale scenario
    di attacco.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，创建防护机制可能具有挑战性，因为目前的方法基于分类和判别模型来检测对抗攻击和有害内容。这些防护模型通常需要数百兆字节的依赖项，这可能会使应用程序变重，显著降低服务的吞吐量，并且无法识别每个潜在的攻击场景。
- en: I test avversari assicurano che le misure di salvaguardia adottate siano sufficienti
    a proteggere i tuoi servizi e la tua reputazione. Nell'ambito dei test avversari,
    dovresti anche verificare le prestazioni delle tue protezioni di autenticazione
    e autorizzazione.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗测试确保采取的防护措施足以保护你的服务和声誉。在对抗测试的范围内，你还应验证你的身份验证和授权保护的性能。
- en: '[Il Capitolo 9](ch09.html#ch09) approfondisce l''implementazione di questi
    livelli di protezione e le tecniche di valutazione per proteggere i tuoi modelli
    da questi attacchi.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](ch09.html#ch09) 深入探讨了这些防护层的实现和评估技术，以保护你的模型免受这些攻击。'
- en: Copertura dei test non vincolati
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试覆盖率
- en: Lo spazio latente dei modelli GenAI è così vasto che non si può fare affidamento
    sui test unitari per ottenere una copertura del 100% di ogni scenario di utilizzo.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI 模型的潜在空间如此之大，以至于不能仅依靠单元测试来获得 100% 的使用场景覆盖率。
- en: Poiché esiste un numero infinito di input e risposte, per quanto tu possa testare
    i tuoi modelli, ci saranno casi limite nascosti che sfuggiranno ai tuoi test.
    Per questo motivo, invece di affidarti alla predefinizione di ogni scenario, puoi
    implementare i *test comportamentali*, che si concentrano sulle proprietà delle
    risposte invece che sugli output esatti.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 由于存在无限多的输入和输出，无论你测试多少你的模型，都会有一些隐藏的边界情况会逃过你的测试。因此，而不是依赖每个场景的预定义，你可以实现 *行为测试*，这些测试专注于响应的性质而不是确切的输出。
- en: Esempi di proprietà comportamentali che puoi misurare sono la *coerenza* delle
    strutture di dati generate, la *rilevanza* degli output rispetto agli input, la
    *tossicità*, la *correttezza* e la *fedeltà* (cioè la fedele aderenza alle tue
    politiche e linee guida etiche). Puoi anche aggiungere un umano nel ciclo come
    ulteriore livello di test per individuare le risposte inaspettate.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以测量的行为属性示例包括生成的数据结构的 *一致性*、输出相对于输入的 *相关性*、*毒性*、*正确性* 和 *忠实度*（即忠实于你的政策和伦理指南）。你还可以将人类添加到测试循环中作为额外的测试级别，以识别意外的响应。
- en: Avvertenze
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意事项
- en: Se stai realizzando un'applicazione RAG o agenziale con più modelli e dipendenze
    esterne, i test comportamentali diventano ancora più pratici. Testare un insieme
    fisso di esempi può far perdere casi limite, interazioni inaspettate tra i componenti
    e variabilità delle risposte dovute a fattori esterni.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在开发一个包含多个模型和外部依赖的 RAG 或代理应用程序，行为测试变得更加实用。测试一组固定的示例可能会丢失边界情况、组件之间的意外交互以及由于外部因素导致的响应变化。
- en: Nella prossima sezione imparerai a implementare i tuoi test unitari, di integrazione,
    E2E e comportamentali seguendo un progetto pratico.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何通过实际项目来实施你的单元测试、集成测试、端到端测试和行为测试。
- en: 'Progetto: Implementazione di test per un sistema RAG'
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目：实现 RAG 系统的测试
- en: Nel progetto pratico, scriverai una suite di test per il modulo RAG che hai
    implementato nel [Capitolo 5](ch05.html#ch05). Il sistema RAG che dovrai testare
    si interfaccia con un LLM, un database vettoriale e il filesystem del server tramite
    metodi asincroni, quindi rappresenta un'opportunità perfetta per comprendere i
    principi di test discussi finora.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际项目中，你将为在第 [5章](ch05.html#ch05) 中实现的 RAG 模块编写一组测试。你将测试的 RAG 系统将通过异步方法与一个 LLM、一个向量数据库和服务器文件系统接口，因此这是一个完美理解迄今为止讨论的测试原则的机会。
- en: Seguendo gli esempi di codice, imparerai le migliori pratiche per implementare
    i test di unità, integrazione e E2E per i tuoi servizi GenAI, nonché le lorodifferenze.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循代码示例，你将学习实施单元测试、集成测试和端到端测试的最佳实践，以及它们之间的差异。
- en: Test unitari
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单元测试
- en: Puoi iniziare a testare i tuoi servizi GenAI con i test unitari. Lo scopo di
    un test unitario è quello di verificare che una parte isolata del tuo codice,
    di solito una singola funzione o metodo, funzioni come previsto.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Puoi iniziare a testare i tuoi servizi GenAI con i test unitari. Lo scopo di
    un test unitario è quello di verificare che una parte isolata del tuo codice,
    di solito una singola funzione o metodo, funzioni come previsto.
- en: Prima di scrivere i test, è importante pianificare i casi di test da implementare.
    Per un tipico sistema RAG, puoi scrivere test unitari sulle pipeline di caricamento,
    trasformazione, recupero e generazione dei dati.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Prima di scrivere i test, è importante pianificare i casi di test da implementare.
    Per un tipico sistema RAG, puoi scrivere test unitari sulle pipeline di caricamento,
    trasformazione, recupero e generazione dei dati.
- en: La[Figura 11-8](#unit_boundaries) visualizza i confini di questi potenziali
    test unitari su un diagramma di pipeline di dati.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: La[Figura 11-8](#unit_boundaries) visualizza i confini di questi potenziali
    test unitari su un diagramma di pipeline di dati.
- en: '![bgai 1108](assets/bgai_1108.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1108](assets/bgai_1108.png)'
- en: Figura 11-8\. Confini dei test unitari visualizzati sul diagramma della pipeline
    di dati RAG
  id: totrans-200
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figura 11-8\. Confini dei test unitari visualizzati sul diagramma della pipeline
    di dati RAG
- en: Si noti che i confini del test terminano all'inizio e alla fine di ogni funzione
    della pipeline di elaborazione dati, perché lo scopo di questi test unitari è
    quello di testare solo il codice della pipeline di elaborazione dati e non il
    database, il filesystem, il modello LLM o le interfacce associate.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Si noti che i confini del test terminano all'inizio e alla fine di ogni funzione
    della pipeline di elaborazione dati, perché lo scopo di questi test unitari è
    quello di testare solo il codice della pipeline di elaborazione dati e non il
    database, il filesystem, il modello LLM o le interfacce associate.
- en: In questi test unitari, supporrai che questi sistemi esterni restituiscano ciò
    che ti aspetti e concentrerai i tuoi test unitari solo su ciò che farà il tuo
    codice di elaborazione dei dati.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: In questi test unitari, supporrai che questi sistemi esterni restituiscano ciò
    che ti aspetti e concentrerai i tuoi test unitari solo su ciò che farà il tuo
    codice di elaborazione dei dati.
- en: Per brevità, non testeremo tutti i componenti del sistema, ma seguendo una manciata
    di esempi, dovresti sentirti a tuo agio nell'implementare test successivi per
    ottenere una copertura completa.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Per brevità, non testeremo tutti i componenti del sistema, ma seguendo una manciata
    di esempi, dovresti sentirti a tuo agio nell'implementare test successivi per
    ottenere una copertura completa.
- en: Installare e configurare pytest
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Installare e configurare pytest
- en: Per questo progetto utilizzerai il pacchetto `pytest`, che ha componenti integrati
    per la gestione di test fixture, parametri, codice asincrono, collezioni di test
    e un ricco ecosistema di plug-in.`pytest` è più potente, flessibile ed estensibile
    rispetto a`unittest`, il pacchetto di test integrato di Python spesso utilizzato
    per semplici scenari di test.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: Per questo progetto utilizzerai il pacchetto `pytest`, che ha componenti integrati
    per la gestione di test fixture, parametri, codice asincrono, collezioni di test
    e un ricco ecosistema di plug-in. `pytest` è più potente, flessibile ed estensibile
    rispetto a `unittest`, il pacchetto di test integrato di Python spesso utilizzato
    per semplici scenari di test.
- en: 'Puoi installare `pytest` utilizzando i seguenti metodi:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 'Puoi installare `pytest` utilizzando i seguenti metodi:'
- en: '[PRE0]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Successivamente, crea una cartella `tests` nella radice del tuo progetto dove
    potrai creare moduli Python seguendo lo schema *test_xxx.py*.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Successivamente, crea una cartella `tests` nella radice del tuo progetto dove
    potrai creare moduli Python seguendo lo schema *test_xxx.py*.
- en: '`pytest`Il raccoglitore di test può quindi attraversare la cartella `tests`
    e trovare tutti i moduli, le classi e le funzioni di test in essa contenuti:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '`pytest`Il raccoglitore di test può quindi attraversare la cartella `tests`
    e trovare tutti i moduli, le classi e le funzioni di test in essa contenuti:'
- en: '[PRE1]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'All''interno di ogni file di test, puoi aggiungere le tue funzioni di test
    che contengono sempre almeno un''istruzione `assert`. Se non viene sollevata alcuna
    eccezione in queste istruzioni `assert`, i tuoi test otterranno `PASSED`. Altrimenti,
    `pytest` li contrassegnerà come `FAILED` insieme a un motivo/traccia del perché
    le istruzioni `assert` sono fallite:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 'All''interno di ogni file di test, puoi aggiungere le tue funzioni di test
    che contengono sempre almeno un''istruzione `assert`. Se non viene sollevata alcuna
    eccezione in queste istruzioni `assert`, i tuoi test otterranno `PASSED`. Altrimenti,
    `pytest` li contrassegnerà come `FAILED` insieme a un motivo/traccia del perché
    le istruzioni `assert` sono fallite:'
- en: '[PRE2]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Supponiamo che tu abbia scritto due funzioni di test in ogni modulo di test:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 'Supponiamo che tu abbia scritto due funzioni di test in ogni modulo di test:'
- en: Puoi quindi eseguire i tuoi test tramite il comando `pytest <test_dirt_path>`.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Puoi quindi eseguire i tuoi test tramite il comando `pytest <test_dirt_path>`.
- en: '[PRE3]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Avvertenze
  id: totrans-216
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Avvertenze
- en: Evita di scrivere test di grandi dimensioni, perché diventano sempre più difficili
    da capire e da implementare correttamente.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Evita di scrivere test di grandi dimensioni, perché diventano sempre più difficili
    da capire e da implementare correttamente.
- en: Quando si scrivono i test unitari, ci si preoccupa solo di un componente isolato
    del sistema, come ad esempio una singola funzione del codice, mentre gli altri
    componenti non rientrano nel campo di applicazione dei test unitari. Pertanto,
    si verificherà solo se un singolo componente si comporta come ci si aspetta, dato
    un insieme di dati di test come input.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Quando si scrivono i test unitari, ci si preoccupa solo di un componente isolato
    del sistema, come ad esempio una singola funzione del codice, mentre gli altri
    componenti non rientrano nel campo di applicazione dei test unitari. Pertanto,
    si verificherà solo se un singolo componente si comporta come ci si aspetta, dato
    un insieme di dati di test come input.
- en: Ad esempio, puoi verificare se la tua funzione di chunking sta dividendo un
    documento in pezzi come ti aspetteresti. Forse vuoi sperimentare strategie di
    chunking diverse o complesse per la tua pipeline RAG e vuoi assicurarti che il
    testo in ingresso sia suddiviso correttamente. I test unitari con dati di test
    predefiniti o *fixture* possono darti fiducia nella tua funzione di chunking.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: Ad esempio, puoi verificare se la tua funzione di chunking sta dividendo un
    documento in pezzi come ti aspetteresti. Forse vuoi sperimentare strategie di
    chunking diverse o complesse per la tua pipeline RAG e vuoi assicurarti che il
    testo in ingresso sia suddiviso correttamente. I test unitari con dati di test
    predefiniti o *fixture* possono darti fiducia nella tua funzione di chunking.
- en: L['esempio 11-1](#unit_test) mostra un esempio di test unitario per la tua funzione
    di chunking.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: L['esempio 11-1](#unit_test) mostra un esempio di test unitario per la tua funzione
    di chunking.
- en: Esempio 11-1\. Esempio di test unitario per una funzione di token chunking
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Esempio 11-1\. Esempio di test unitario per una funzione di token chunking
- en: '[PRE4]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO1-1)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO1-1)'
- en: Suddivide un elenco di token interi in elenchi più piccoli di un determinato
    `chunk_size`.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: Suddivide un elenco di token interi in elenchi più piccoli di un determinato
    `chunk_size`.
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO1-2)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_testing_ai_services_CO1-2)'
- en: Specifica i dati del test nella parte *GIVEN (precondizioni)* del test.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: Specifica i dati del test nella parte *GIVEN (precondizioni)* del test.
- en: '[![3](assets/3.png)](#co_testing_ai_services_CO1-3)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_testing_ai_services_CO1-3)'
- en: Esegui le fasi di test nella parte *WHEN* del test che includono il passaggio
    dei dati di test al sistema in esame.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Esegui le fasi di test nella parte *WHEN* del test che includono il passaggio
    dei dati di test al sistema in esame.
- en: '[![4](assets/4.png)](#co_testing_ai_services_CO1-4)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_testing_ai_services_CO1-4)'
- en: Controlla i risultati rispetto alle uscite previste nella parte *THEN* del test.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Controlla i risultati rispetto alle uscite previste nella parte *THEN* del test.
- en: Attrezzature e ambito di applicazione
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Attrezzature e ambito di applicazione
- en: 'I dati di input di che hai definito nell''[Esempio 11-1](#unit_test) per i
    test sono chiamati anche *fixture*, poiché il loro valore rimane fisso per ogni
    esecuzione del test. Esistono due tipi di fixture:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 'I dati di input di che hai definito nell''[Esempio 11-1](#unit_test) per i
    test sono chiamati anche *fixture*, poiché il loro valore rimane fisso per ogni
    esecuzione del test. Esistono due tipi di fixture:'
- en: Apparecchio fresco
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: Apparecchio fresco
- en: La definisci all'interno di ogni test, che poi Python raccoglie (cioè scarta)
    dopo il test. L'[esempio 11-1](#unit_test) utilizza una fixture fresca.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: La definisci all'interno di ogni test, che poi Python raccoglie (cioè scarta)
    dopo il test. L'[esempio 11-1](#unit_test) utilizza una fixture fresca.
- en: Apparecchio condiviso
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: Apparecchio condiviso
- en: Puoi riutilizzarlo in più test per evitare di ripetere sempre la stessa fixture
    per ogni nuovo test.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Puoi riutilizzarlo in più test per evitare di ripetere sempre la stessa fixture
    per ogni nuovo test.
- en: Puoi dichiarare una fixture condivisa al di fuori delle funzioni di test come
    variabile globale del modulo di test, ma è considerato un anti-pattern, in quanto
    potresti modificarla inavvertitamente.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Puoi dichiarare una fixture condivisa al di fuori delle funzioni di test come
    variabile globale del modulo di test, ma è considerato un anti-pattern, in quanto
    potresti modificarla inavvertitamente.
- en: Avvertenze
  id: totrans-238
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Avvertenze
- en: Le fixture condivise devono essere *immutabili*, altrimenti un test può cambiare
    la fixture, creando un effetto collaterale che si ripercuote sugli altri test.
    Una delle principali cause di test difettosi sono le fixture mutabili.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Le fixture condivise devono essere *immutabili*, altrimenti un test può cambiare
    la fixture, creando un effetto collaterale che si ripercuote sugli altri test.
    Una delle principali cause di test difettosi sono le fixture mutabili.
- en: Invece di essere responsabile della gestione dello stato delle fixture condivise,
    puoi affidarti al sistema di iniezione delle dipendenze di `pytest`attraverso
    l'uso di *funzioni di fixture*, come mostrato nell'[Esempio 11-2](#fixture_function).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Invece di essere responsabile della gestione dello stato delle fixture condivise,
    puoi affidarti al sistema di iniezione delle dipendenze di `pytest`attraverso
    l'uso di *funzioni di fixture*, come mostrato nell'[Esempio 11-2](#fixture_function).
- en: Esempio 11-2\. `pytest` funzione di fissaggio
  id: totrans-241
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Esempio 11-2\. `pytest` funzione di fissaggio
- en: '[PRE5]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO2-1)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_testing_ai_services_CO2-1)'
- en: Dichiara la funzione `input_text` come una fixture `pytest` che può essere condivisa
    nel modulo come specificato da `scope="module"`.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: Dichiara la funzione `input_text` come una fixture `pytest` che può essere condivisa
    nel modulo come specificato da `scope="module"`.
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO2-2)'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_testing_ai_services_CO2-2)'
- en: Usa la dependency injection di `pytest` per iniettare una fixture condivisa
    in diversi test.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `pytest` 的依赖注入来注入一个共享的 fixture 到不同的测试中。
- en: Puoi dichiarare una funzione come una fixture `pytest` utilizzando il decoratore
    `@pytest.fixture(scope)`. Il parametro `scope` specifica la durata della fixture
    condivisa all'interno di una sessione di test.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `@pytest.fixture(scope)` 装饰器将一个函数声明为 `pytest` 固定值。参数 `scope` 指定了 fixture
    共享在测试会话中的持续时间。
- en: In base al valore di `scope`, `pytest` crea e distrugge le fixture una volta
    per ogni funzione di test, `class`, `module`, `package`, o per l'intero test `session`.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 `scope` 的值，`pytest` 会为每个测试函数、`class`、`module`、`package` 或整个测试 `session` 创建和销毁一次
    fixture。
- en: Suggerimento
  id: totrans-249
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Suggerimento
- en: Uno scenario in cui potresti aver bisogno di una fixture condivisa per persistere
    tra i moduli o per l'intera sessione di test è quando recuperi la fixture da un'API
    esterna e vuoi evitare di fare richiesteripetute.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下场景中，你可能需要一个共享的 fixture 以在模块之间或整个测试会话中持久化：当你从外部 API 恢复 fixture 并希望避免重复请求。
- en: Utilizzando le fixture, puoi implementare diversi test con vari input che coprono
    valori validi, non validi e limite per verificare la robustezza di ogni componente.
    Tuttavia, dovrai separare le funzioni di test per ogni serie di input e output
    previsti. Per evitare di riscrivere lo stesso test, `pytest` ha una funzione di
    *parametrizzazione* che puoisfruttare.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 fixture，你可以实现不同的测试，这些测试具有不同的输入，包括有效值、无效值和边界值，以验证每个组件的鲁棒性。然而，你必须为每个预期的输入和输出系列分离测试函数。为了避免重写相同的测试，`pytest`
    有一个名为 *参数化* 的功能可以利用。
- en: Parametrizzazione
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参数化
- en: Con la parametrizzazione di `pytest`, puoi iterare su diversi dati di test e
    output attesi per evitare di duplicare i test, come puoi vedere nell'[Esempio
    11-3](#pytest_params).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `pytest` 的参数化，你可以迭代不同的测试数据和预期输出，以避免重复测试，如 `[示例 11-3](#pytest_params)` 中所示。
- en: Esempio 11-3\. Parametrizzazione di`pytest`
  id: totrans-254
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-3\. `pytest` 的参数化
- en: '[PRE6]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO3-1)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[#co_testing_ai_services_CO3-1]'
- en: Utilizza la funzione decoratrice `@pytest.mark.parametrize` per specificare
    più argomenti di test e gli output attesi. Gli argomenti di test coprono valori
    validi, vuoti, non validi, intervalli di confine e valori grandi per verificare
    la robustezza della funzione di raggruppamento dei token.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `@pytest.mark.parametrize` 装饰器来指定多个测试参数和预期的输出。测试参数包括有效值、空值、无效值、边界值和大值，以验证分词函数的鲁棒性。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO3-2)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)[#co_testing_ai_services_CO3-2]'
- en: Inietta i parametri di test nella funzione di test e se l'output previsto è
    un `ValueError`, usa `pytest.raises` per verificare che sia stata sollevata un'eccezione
    `ValueError`. Altrimenti, esegui il controllo dell'asserzione.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 将测试参数注入到测试函数中，如果预期的输出是 `ValueError`，则使用 `pytest.raises` 来验证是否抛出了 `ValueError`
    异常。否则，执行断言检查。
- en: Puoi anche memorizzare i dati del test all'interno di file JSON e caricarli
    come fixture da iniettare nelle funzioni di test parametrizzate, come mostrato
    nell'[Esempio 11-4](#pytest_params_json).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将测试数据存储在 JSON 文件中，并将其作为 fixture 注入到参数化测试函数中，如 `[示例 11-4](#pytest_params_json)`
    中所示。
- en: Esempio 11-4\. Fissaggi JSON nei test parametrici di `pytest`
  id: totrans-261
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-4\. `pytest` 参数化测试中的 JSON 固定值
- en: '[PRE7]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO4-1)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[#co_testing_ai_services_CO4-1]'
- en: Il file JSON contiene un elenco di casi di test come dizionari.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 文件包含一个测试用例列表，以字典形式表示。
- en: Come puoi vedere, le fixture e la tecnica di parametrizzazione sono strumenti
    estremamente potenti per aiutarti a verificare la robustezza di ogni funzione
    del tuo codice.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，fixture 和参数化技术是帮助你验证代码中每个函数的鲁棒性的强大工具。
- en: Quando scrivi dei test, probabilmente vorrai specificare il codice di configurazione,
    le configurazioni e le fixture globali da condividere tra i file di test. Fortunatamente,
    puoi ottenere questo risultato nel filedi configurazione globale di`pytest`chiamato
    *conftest.py*.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 当你编写测试时，你可能希望指定配置代码、配置和全局 fixture，以便在测试文件之间共享。幸运的是，你可以在 `pytest` 的全局配置文件 `conftest.py`
    中获得这个结果。
- en: Modulo Conftest
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Modulo Conftest
- en: Se vuoi che tutti i tuoi moduli di test abbiano accesso alle fixture e alle
    configurazioni globali, puoi aggiungere un modulo *conftest.py* alla tua directory
    `tests`. Tutte le fixture, il codice di setup e le configurazioni definite nel
    modulo conftest saranno condivise con gli altri moduli di test. Vedi l'[Esempio
    11-5](#conftest_fixture).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想让所有测试模块都能访问 fixture 和全局配置，你可以在你的 `tests` 目录中添加一个 *conftest.py* 模块。在 conftest
    模块中定义的所有 fixture、设置代码和配置将被其他测试模块共享。参见 [示例 11-5](#conftest_fixture)。
- en: Esempio 11-5\. Aggiungere un dispositivo condiviso per ogni modulo
  id: totrans-269
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-5\. 为每个模块添加共享设备
- en: '[PRE8]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO5-1)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)(#co_testing_ai_services_CO5-1)'
- en: Definisce una fixture condivisa in *conftest.py* da utilizzare per ogni modulo
    di test. Altrimenti, la fixture sarebbe limitata a un singolo modulo.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *conftest.py* 中定义一个共享 fixture，用于每个测试模块。否则，该 fixture 将仅限于单个模块。
- en: Ora hai imparato a scrivere dei test di base utilizzando il framework `pytest`
    secondo il modello GWT. Ora vediamo come eseguire le operazioni di configurazione
    e pulizia prima e dopo i test.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何使用 `pytest` 框架按照 GWT 模型编写基本测试。现在我们来看看如何在测试前后执行配置和清理操作。
- en: Configurazione e smontaggio
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置和拆解
- en: Quando si implementano i test, potrebbe essere necessario configurare un ambiente
    di prova prima ed eseguire operazioni di smantellamento o pulizia dopo. Puoi usare
    la parola chiave `yield` nelle fixture condivise per implementare le operazioni
    di configurazione e smantellamento che devono avvenire in modo coerente per ogni
    test.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现测试时，可能需要在测试之前配置测试环境，并在测试之后执行拆解或清理操作。你可以在共享 fixture 中使用关键字 `yield` 来实现需要为每个测试一致执行的配置和拆解操作。
- en: Ad esempio, potresti aver bisogno di utilizzare questa funzione per impostare
    e ripulire una sessione del database, come dimostrato nell'[Esempio 11-6](#setup_teardown).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可能需要使用此函数来设置和清理数据库会话，如 [示例 11-6](#setup_teardown) 中所示。
- en: Esempio 11-6\. Configurare e chiudere una sessione di database in una fixture
    condivisa
  id: totrans-277
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 11-6\. 在共享 fixture 中配置和关闭数据库会话
- en: '[PRE9]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![1](assets/1.png)](#co_testing_ai_services_CO6-1)'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)(#co_testing_ai_services_CO6-1)'
- en: Crea una fixture globale condivisa in *conftest.py* che viene creata e distrutta
    una volta per ogni funzione di test.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *conftest.py* 中创建一个全局共享 fixture，它会在每个测试函数执行时创建和销毁。
- en: '[![2](assets/2.png)](#co_testing_ai_services_CO6-2)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)(#co_testing_ai_services_CO6-2)'
- en: Instanzia il client del database `qdrant` e poi crea e configura una collezione
    di test con un punto dati inserito come parte della fase di configurazione del
    test.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化数据库客户端 `qdrant`，然后创建并配置一个包含插入数据点的测试集合，作为测试配置阶段的一部分。
- en: '[![3](assets/3.png)](#co_testing_ai_services_CO6-5)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)(#co_testing_ai_services_CO6-5)'
- en: Consegna il client del database alla funzione di test come parte della fase
    di test principale.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据库客户端作为测试主要阶段的一部分传递给测试函数。
- en: '[![4](assets/4.png)](#co_testing_ai_services_CO6-6)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '![4](assets/4.png)(#co_testing_ai_services_CO6-6)'
- en: Al termine di ogni test, chiude la connessione del client al database. Il codice
    di demolizione dopo la parola chiave `yield` viene eseguito una volta completata
    l'operazione di resa.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 每次测试结束后，关闭数据库客户端的连接。在关键字 `yield` 后面的拆毁代码会在完成返回操作后执行一次。
- en: '[![5](assets/5.png)](#co_testing_ai_services_CO6-7)'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '![5](assets/5.png)(#co_testing_ai_services_CO6-7)'
- en: Inietta il client del database preconfigurato in ogni funzione di test dopo
    aver completato l'impostazione del test. Interroga il database per il documento
    inserito e afferma che è stato recuperato un punto di dati. Una volta completata
    la fase di asserzione, esegui il processo di smantellamento come parte della funzione
    fixture `db_client`.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成测试设置后，将预配置的数据库客户端注入到每个测试函数中。查询数据库以获取插入的文档，并断言已成功检索到数据点。在断言阶段完成后，作为 fixture
    函数 `db_client` 的一部分执行拆毁过程。
- en: Seguendo l'esempio dell'[Esempio 11-6](#setup_teardown), puoi anche creare delle
    fixture con fasi di setup e teardown per il tuo client di test API o per qualsiasi
    altro servizio esterno.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 [示例 11-6](#setup_teardown) 的示例，你也可以为你的 API 测试客户端或任何其他外部服务创建具有设置和拆毁阶段的 fixture。
- en: Inoltre, avrai notato che l'[Esempio 11-6](#setup_teardown) ha utilizzato un
    client sincrono invece di uno asincrono. Questo perché la gestione dei test asincroni
    può essere complicata, problematica e soggetta a errori e perché richiede l'installazione
    di plugin aggiuntivi di `pytest` per la gestione dei loop di eventi dei test.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你可能已经注意到，[示例11-6](#setup_teardown)使用了同步客户端而不是异步客户端。这是因为异步测试的管理可能很复杂、有问题且容易出错，并且需要安装额外的`pytest`插件来管理测试的事件循环。
- en: Per evitare che i test unitari si rivelino inefficaci, dovresti usare i mock
    per isolare i componenti funzionali dai servizi esterni. Questo perché l'ambito
    e i confini di verifica dei test unitari non includono le dipendenze e le interfacce
    esterne, mentre i test delle dipendenze e delle interfacce esterne, come le interazioni
    con il database, rientrano nell'ambito dei test di integrazione.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免单元测试变得无效，你应该使用mock来隔离功能组件与外部服务。这是因为单元测试的检查范围和边界不包括依赖和外部接口，而依赖和外部接口的测试，例如与数据库的交互，属于集成测试的范畴。
- en: In seguito imparerai a gestire i test asincroni e le tecniche di mocking/patching.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，你将学习如何管理异步测试以及mocking/patching技术。
- en: Gestione dei test asincroni
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异步测试管理
- en: 'Per eseguire test asincroni, puoi utilizzare dei plug-in come `pytest-asyncio`
    che si integrano`pytest` con `asyncio` di Python:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行异步测试，你可以使用像`pytest-asyncio`这样的插件，这些插件将`pytest`与Python的`asyncio`集成：
- en: '[PRE10]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11] # tests/rag/retrieve.py  @pytest.mark.asyncio ![1](assets/1.png) async
    def test_search_db(async_db_client): ![2](assets/2.png)     result = await async_db_client.search(         collection_name="test",
    query_vector=[0.18, 0.81, 0.75, 0.12], limit=1     )     assert result is not
    None [PRE12]`  [PRE13] class FakeLLMClient: ![1](assets/1.png)     def __init__(self):         self.cache
    = dict()      def invoke(self, query):         if query in self.cache:             return
    self.cache.get(query) ![2](assets/2.png)          response = requests.post("http://localhost:8001",
    json={"query": query})         if response.status_code != 200:             return
    "Error fetching result"          result = response.json().get("response")         self.cache[query]
    = result         return result  def process_query(query, llm_client, token):     response
    = llm_client.invoke(query, token) ![1](assets/1.png)     return response  def
    test_fake_llm_client(query):     llm_client = FakeLLMClient()     query = "some
    query"     response = process_query(query, llm_client, token="fake_token")     assert
    response == "some response" [PRE14] class DummyLLMClient:     def invoke(self,
    query, token): ![1](assets/1.png)         return "some response"  def process_query(query,
    llm_client, token):     response = llm_client.invoke(query, token) ![1](assets/1.png)     return
    response  def test_dummy_llm_client(query):     llm_client = DummyLLMClient()     query
    = "some query"     response = process_query(query, llm_client, token="fake_token")     assert
    response == "some response" [PRE15] class StubLLMClient:     def invoke(self,
    query):         if query == "specific query": ![1](assets/1.png)             return
    "specific response"         return "default response"  def process_query(query,
    llm_client):     response = llm_client.invoke(query)     return response  def
    test_stub_llm_client():     llm_client = StubLLMClient()     query = "specific
    query"     response = process_query(query, llm_client)     assert response ==
    "specific response" [PRE16] class SpyLLMClient:     def __init__(self):         self.call_count
    = 0         self.calls = []      def invoke(self, query):         self.call_count
    += 1 ![1](assets/1.png)         self.calls.append((query))         return "some
    response"  def process_query(query, llm_client):     response = llm_client.invoke(query)     return
    response  def test_process_query_with_spy():     llm_client = SpyLLMClient()     query
    = "some query"      process_query(query, llm_client)      assert llm_client.call_count
    == 1     assert llm_client.calls == [("some query")] [PRE17] $ pip install pytest-mock
    [PRE18] def process_query(query, llm_client):     response = llm_client.invoke(query)     return
    response  def test_process_query_with_mock(mocker):     llm_client = mocker.Mock()
    ![1](assets/1.png)     llm_client.invoke.return_value = "mock response"     query
    = "some query"      process_query(query, llm_client)     process_query(query,
    llm_client)      assert llm_client.invoke.call_count == 2     llm_client.invoke.assert_any_call("some
    query") [PRE19] class LLMClient:     def invoke(self, query):         return openai.ChatCompletion.create(             model="gpt-4o",
    messages=[{"role": "user", "content": query}]         )  @pytest.fixture def llm_client():     return
    LLMClient()  def test_fake(mocker, llm_client):     class FakeOpenAIClient: ![1](assets/1.png)         @staticmethod         def
    invoke(model, query):             return {"choices": [{"message": {"content":
    "fake response"}}]}      mocker.patch(openai.ChatCompletion, new=FakeOpenAIClient)
    ![1](assets/1.png)     result = llm_client.invoke("test query")     assert result
    == {"choices": [{"message": {"content": "fake response"}}]}  def test_stub(mocker,
    llm_client):     stub = mocker.Mock()     stub.process.return_value = "stubbed
    response"     result = llm_client.invoke(stub)     assert result == "stubbed response"  ![2](assets/2.png)  def
    test_spy(mocker, llm_client):     spy = mocker.spy(LLMClient, ''send_request'')     spy.return_value
    = "some_value"     llm_client.invoke("some query")     spy.call_count == 1  ![3](assets/3.png)  def
    test_mock(mocker, llm_client):     mock = mocker.Mock()     llm_client.invoke(mock)     mock.process.assert_called_once_with("some
    query") ![4](assets/4.png) [PRE20]`  [PRE21] def calculate_recall(expected: list[int],
    retrieved: list[int]) -> int: ![1](assets/1.png)     true_positives = len(set(expected)
    & set(retrieved))     return true_positives / len(expected)   def calculate_precision(expected:
    list[int], retrieved: list[int]) -> int: ![2](assets/2.png)     true_positives
    = len(set(expected) & set(retrieved))     return true_positives / len(retrieved)  expected_document_ids
    = [1, 2, 3, 4, 5] retrieved_documents_ids = [2, 3, 6, 7]  recall = calculate_recall(expected_document_ids,
    retrieved_documents_ids) precision = calculate_precision(expected_document_ids,
    retrieved_documents_ids)  print(f"Recall: {recall:.2f}") # Recall: 0.40 print(f"Precision:
    {precision:.2f}") # Precision: 0.50 [PRE22] @pytest.mark.parametrize("query_vector,
    expected_ids", [ ![1](assets/1.png)     ([0.1, 0.2, 0.3, 0.4], [1, 2, 3]),     ([0.2,
    0.3, 0.4, 0.5], [2, 1, 3]),     ([0.3, 0.4, 0.5, 0.6], [3, 2, 1]),     ... ])
    def test_retrieval_subsystem(db_client, query_vector, expected_ids): ![2](assets/2.png)     response
    = db_client.search( ![2](assets/2.png)         collection_name="test",         query_vector=query_vector,         limit=3     )      retrieved_ids
    = [point.id for point in response]     recall = calculate_recall(expected_ids,
    retrieved_ids)     precision = calculate_precision(expected_ids, retrieved_ids)      assert
    recall >= 0.66 ![3](assets/3.png)     assert precision >= 0.66 ![3](assets/3.png)
    [PRE23] @pytest.mark.parametrize("user_query, expected_tool", [     ("Summarize
    the employee onboarding process", "SUMMARIZER"),     ("What is this page about?
    https://...", "WEBSEARCH"),     ("Analyze the 2024 annual accounts", "ANALYZER"),     ...
    # Add 100 different cases with a balanced category distribution ]) ![1](assets/1.png)
    def test_llm_tool_selection_response(user_query, expected_tool):     response
    = llm.invoke(user_query, response_type="json")     assert response["selected_tool"]
    == expected_tool     assert response["message"] is not None [PRE24] $ pip install
    textstat [PRE25]`##### Esempio 11-17\. Test di funzionalità minima per la leggibilità    [PRE26]    [![1](assets/1.png)](#co_testing_ai_services_CO17-1)      Itera
    su vari esempi controllando il punteggio di leggibilità anche quando un utente
    chiede spiegazioni semplici.      [![2](assets/2.png)](#co_testing_ai_services_CO17-2)      Utilizza
    la formula di Flesch per valutare il punteggio di leggibilità. Un buon punteggio
    si aggira in genere tra 60 e 70, il che indica che il testo è facilmente comprensibile
    dagli studenti delle scuole superiori.      [![3](assets/3.png)](#co_testing_ai_services_CO17-3)      Verifica
    che il punteggio di leggibilità sia superiore ai valori attesi ma non troppo alto.
    Un punteggio molto alto potrebbe indicare risposte troppo semplici e prive di
    dettagli rilevanti.      Il test di leggibilità mostrato nell''[Esempio 11-17](#mft_test)
    dovrebbe darti un''idea su come scrivere le tue MFT. Ad esempio, puoi verificare
    la concisione o il livello di dettaglio delle risposte nei tuoi casi d''uso.[PRE27]`####
    Test di invarianza (IT)    I*test di invarianza* verificano se le previsioni di
    un modello rimangono coerenti quando vengono apportate modifiche irrilevanti agli
    input. Questi test possono misurare la sensibilità dei parametri e verificare
    la robustezza del modello a variazioni che non dovrebbero influenzare gli output.    Esempi
    di IT includono la verifica dell''assenza di cambiamenti nelle risposte del modello
    se si modificano i prompt di:    *   Cambiare la sensibilità alle maiuscole           *   Iniettare
    spazi bianchi, caratteri di escape e caratteri speciali           *   Include
    errori di battitura o grammaticali           *   Sostituzione di parole con sinonimi           *   Commutazione
    del formato dei numeri (tra cifre e parole)           *   Riordinare i pezzi di
    testo/contesto nel prompt              Esistono anche molti altri tipi di controlli
    che possono essere effettuati attraverso i test di invarianza.    L[''esempio
    11-18](#it_test) mostra un semplice test di invarianza.    ##### Esempio 11-18\.
    Test di invarianza    [PRE28]    Come vedi, la maggior parte di questi test modifica
    leggermente gli input con l''aspettativa che gli output rimangano per lo più simili.
    Ora dovresti sentirti sicuro nell''implementare i tuoi test di invarianza.    ####
    Test di aspettativa direzionale (DET)    I*test di aspettativa direzionale* verificano
    se il modello si comporta in modo logico e se le uscite cambiano nella giusta
    direzione al variare degli ingressi.    Esempi di DET sono la verifica dei giusti
    aggiustamenti del sentimento tra il prompt e la risposta o la specificità delle
    risposte a domande specifiche. Se il prompt esprime emozioni negative, il modello
    non deve ignorarle e deve affrontarle in modo appropriato. Allo stesso modo, alle
    domande dettagliate bisogna rispondere con la specificità appropriata.    Come
    puoi vedere nell''[Esempio 11-19](#det_test), ci aspettiamo e verifichiamo una
    correlazione positiva tra il prompt e la risposta sia per quanto riguarda la lunghezza
    che la complessità.    ##### Esempio 11-19\. Test di aspettativa direzionale per
    verificare la lunghezza della risposta    [PRE29]    [![1](assets/1.png)](#co_testing_ai_services_CO18-1)      Itera
    diversi prompt in cui uno è una variante complessa di un altro.      [![2](assets/2.png)](#co_testing_ai_services_CO18-2)      Utilizza
    la lunghezza del testo della risposta come indicatore per verificare la complessità
    relativa delle risposte, partendo dal presupposto che più complesso è il prompt,
    più lunga (e più complessa) è la risposta. Potrebbero esistere indicatori più
    accurati per valutare la complessità delle risposte, come il punteggio di leggibilità
    di Flesch.      Gli MFT, gli IT e i DET non sono gli unici tipi di test che puoi
    implementare per verificare il comportamento dei tuoi modelli. Puoi anche utilizzare
    tecniche più complesse affidandoti ad altri modelli di intelligenza artificiale
    l''esecuzione dei tuoi test, come scoprirai più avanti.    #### Test di autovalutazione    Un''altra
    tecnica per verificare il comportamento dei modelli GenAI è quella di affidarsi
    ad altri modelli AI durante i test, un processo definito *autovalutazione*.    I*test
    di autovalutazione* utilizzano un modello discriminatore/valutatore per verificare
    la qualità dei risultati in base a varie metriche come il tasso di allucinazione,
    la tossicità, la correttezza, la pertinenza delle risposte, ecc. Per i risultati
    LLM, puoi utilizzare un modello LLM o un modello di classificazione come valutatore,
    come mostrato nell''[Esempio 11-20](#self_evaluation_test).    ##### Esempio 11-20\.
    Autovalutazione LLM per la misurazione della tossicità    [PRE30]    [![1](assets/1.png)](#co_testing_ai_services_CO19-1)      Costruisci
    un prompt del sistema di valutazione per il LLM, descrivendo come eseguire il
    compito di valutazione.      [![2](assets/2.png)](#co_testing_ai_services_CO19-3)      Richiedi
    che le risposte siano restituite in formato strutturato per un semplice parsing.
    Puoi anche richiedere delle misure invece di valutazioni booleane.      [![3](assets/3.png)](#co_testing_ai_services_CO19-4)      Ottiene
    con grazia il valore `is_toxic` e fallisce l''asserzione se non è possibile ottenere
    un valore `False`.      L''idea centrale dell''[Esempio 11-20](#self_evaluation_test)
    è quella di far sì che il LLM "valuti se stesso" o di implementare dei test che
    ne verifichino le prestazioni in base a criteri, proprietà o comportamenti predefiniti.    I
    test di valutazione automatica sono tecniche potenti per valutare la qualità delle
    risposte in base a varie metriche, ma si basano su altri modelli e su chiamate
    API aggiuntive, che possono aumentare i costi.    Grazie a queste tecniche di
    test, ora dovresti avere tutti gli strumenti necessari per verificare le prestazioni
    dei tuoi modelli GenAI, sia che tu ti stia interfacciando con un LLM che con altri
    tipi di generatori.    Il passo successivo all''implementazione di diversi test
    di integrazione è quello di testare l''intero sistema utilizzando i test E2E.
    La prossima sezione tratterà l''E2E in modo più dettagliato.[PRE31]`## Test end-to-end    Fino
    a questo punto, hai lavorato su test unitari e di integrazione per i tuoi servizi
    GenAI. Per completare l''ultimo livello di test, ora ti concentrerai sull''implementazione
    di alcuni test E2E.    Nel [Capitolo 5](ch05.html#ch05) hai implementato un web
    scraper e un modulo RAG nel tuo servizio FastAPI e hai sviluppato un''interfaccia
    utente Streamlit per interagire con il tuo servizio API LLM.    Quando hai testato
    la tua applicazione caricando documenti o fornendo URL attraverso l''interfaccia
    utente di Streamlit, stavi eseguendo test E2E *manuali* sull''intero RAG e sulle
    pipeline di web scraper, ciascuna contenente più di due componenti.    La[Figura
    11-11](#e2e_boundaries) mostra i test E2E eseguiti e i loro confini.  ![bgai 1111](assets/bgai_1111.png)  ######
    Figura 11-11\. Confini del test E2E visualizzati sul diagramma della pipeline
    di dati RAG    Come mostrato nella [Figura 11-11](#e2e_boundaries), un segno che
    indica che stai lavorando a un test E2E è la presenza di un confine di test che
    copre più componenti e servizi esterni.    ###### Suggerimento    Puoi combinare
    più test E2E in un test più grande, più complesso ma più lento.    I test più
    grandi tendono a essere più fragili, più incerti e di conseguenza frustranti da
    mantenere, ma possono darti una maggiore sicurezza sulla funzionalità dell''applicazione
    in tutti i componenti e le interazioni.    Sebbene tu abbia eseguito manualmente
    questi test E2E tramite l''interfaccia utente, avresti potuto anche automatizzarli
    utilizzando framework di test con un client di test API o browser headless per
    ridurre il carico di lavoro manuale. Tuttavia, non è necessario automatizzare
    tutti i test E2E, poiché alcuni di essi trarrebbero beneficio dal tocco umano.    I
    test E2E manuali possono comunque aiutarti a scoprire problemi che potrebbero
    passare inosservati con i test automatizzati. Puoi identificare e pianificare
    manualmente alcuni test E2E e poi sviluppare versioni automatizzate da inserire
    nelle tue pipeline CI/CD, assicurandoti di aver tenuto conto della fragilità e
    dell''incertezza di questi test.    Se un test E2E fallisce, significa che anche
    uno o più dei tuoi test di unità o di integrazione potrebbero fallire. Altrimenti,
    forse hai diversi punti ciechi nella tua suite di test o ci sono interazioni tra
    componenti e sottosistemi che danno luogo a comportamenti emergenti a livello
    di sistema che non puoi prevedere con i test di unità o di integrazione.    ######
    Suggerimento    A differenza dei test di unità o di integrazione, non è necessario
    eseguire E2E con la stessa frequenza.    Inoltre, non hai necessariamente bisogno
    di un''interfaccia utente per eseguire i test E2E: puoi attivare gli endpoint
    delle tue API, tramite codice o strumenti di test, e fornire i dati di test per
    verificare la funzionalità prevista di ciascun endpoint.    ###### Avvertenze    Il
    test di un endpoint tramite invocazione non è considerato un test unitario o di
    integrazione, ma piuttosto un test E2E. Questo perché ogni endpoint gestisce una
    funzione di controller che potenzialmente coinvolge diversi servizi e operazioni
    che lavorano insieme per fornire una funzionalità.    Per definizione, i test
    di integrazione hanno come scopo solo la verifica dell''interfaccia di due componenti.    Imparerai
    presto ad automatizzare i test manuali E2E utilizzando `pytest` e un client di
    test API tramite test *verticali* e *orizzontali*:    Test verticali E2E      Verifica
    la funzionalità di una funzione o di un flusso di lavoro specifico, su più livelli
    dell''applicazione, ad esempio dall''interfaccia utente al database.      Test
    E2E orizzontali      Verifica la funzionalità di vari scenari utente, in genere
    su più sistemi e servizi integrati.      Esaminiamo i test E2E verticali in modo
    più dettagliato prima di parlare dei test E2E orizzontali.    ### Test verticali
    E2E    Tornando alla [Figura 11-11](#e2e_boundaries), il test E2E di sinistra,
    che verifica la funzionalità di caricamento dei file, l''estrazione, la trasformazione
    e l''archiviazione dei contenuti in un database, è un test E2E verticale. Allo
    stesso modo, anche il secondo test è considerato verticale, in quanto verifica
    la logica di recupero dei contenuti dal database quando viene fornita una query
    e poi utilizza il modello LLM per la generazione del testo in un contesto di domande
    e risposte. D''altra parte, il test che copre l''intera pipeline di dati RAG,
    dal caricamento dei file alla risposta LLM, è un test orizzontale.    La distinzione
    principale è che i test orizzontali sono più ampi e testano interi scenari utente,
    mentre i test verticali sono più mirati e testano un flusso di lavoro o una funzione
    specifica attraverso i livelli.    ###### Suggerimento    In un''applicazione
    con un''architettura a strati o a cipolla, i test verticali consistono essenzialmente
    nel "navigare nella cipolla" e nel controllare i flussi di dati e le interazioni
    tra i vari livelli per verificare che siano ben integrati e che funzionino come
    previsto.    Prima di implementare qualsiasi test E2E, creiamo una fixture globale
    che inizializzi un client di test FastAPI, come mostrato nell''[Esempio 11-21](#test_client).
    Questo client di test sarà utilizzato per invocare gli endpoint API per i test
    E2E verticali e orizzontali.    ##### Esempio 11-21\. Implementazione di una fixture
    client di prova    [PRE32]    Con il client di test, ora puoi eseguire test E2E
    verticali e orizzontali, iniziando con i test verticali che coprono le funzionalità
    di caricamento e archiviazione dei file, come dimostrato nell''[Esempio 11-22](#test_vertical).    #####
    Esempio 11-22\. Implementazione di un E2E verticale per verificare la funzionalità
    del flusso di lavoro di caricamento e archiviazione    [PRE33]    [![1](assets/1.png)](#co_testing_ai_services_CO20-1)      Usa
    la fixture del client del database vettoriale qdrant che hai creato in precedenza
    durante i test di integrazione.      [![2](assets/2.png)](#co_testing_ai_services_CO20-2)      Carica
    un file utilizzando il client di prova e verifica che la risposta dell''API sia
    positiva.      [![3](assets/3.png)](#co_testing_ai_services_CO20-3)      Controlla
    che la ricerca nel database restituisca il vettore contenente il contenuto del
    file per verificare la funzionalità dell''endpoint `/upload`.      ###### Suggerimento    L[''esempio
    11-22](#test_vertical) potrebbe essere implementato anche con una fixture mock
    `db_client` per evitare di dipendere da una dipendenza esterna. Invece di controllare
    i risultati restituiti dal database, verificherai se il client del database è
    stato chiamato per memorizzare un file e uncontenuto corretti.    Tieni presente
    che l''utilizzo di un mock verificherebbe solo che il client del database sia
    stato chiamato con i parametri previsti, ma non verificherebbe l''effettiva funzionalità
    di memorizzazione o recupero del database.    Come hai visto nell''[Esempio 11-22](#test_vertical),
    i test E2E verticali verificano la funzionalità di un''applicazione livello per
    livello, tipicamente in ordine lineare e gerarchico. Puoi suddividere la tua applicazione
    in livelli distinti e concentrarti su particolari sottosistemi, come le richieste
    API e le chiamate ai database, per verificare se tali sottosistemi funzionano
    come previsto.    ### Test E2E orizzontali    Con i test E2E orizzontali, invece,
    si assume la prospettiva di un utente che naviga attraverso le funzionalità e
    i flussi di lavoro dell''applicazione per individuare errori, bug e altri problemi.
    Questi test coprono l''intera applicazione, quindi è fondamentale avere flussi
    di lavoro ben costruiti e chiaramente definiti per eseguirliin modo efficace.Ad
    esempio, un test E2E orizzontale potrebbe comportare la verifica dell''interfaccia
    utente, del database e dell''integrazione con un LLM per verificare la funzionalità
    di un chatbot abilitato alle RAG da un capo all''altro.    L[''esempio 11-23](#test_horizontal)
    mostra come potrebbe apparire un test orizzontale.    ##### Esempio 11-23\. Implementazione
    di un E2E orizzontale per verificare l''intera funzionalità del flusso di lavoro
    dell''utente RAG Q&A    [PRE34]    [![1](assets/1.png)](#co_testing_ai_services_CO21-1)      Verifica
    che il file sia stato caricato e memorizzato nel database senza errori.      [![2](assets/2.png)](#co_testing_ai_services_CO21-2)      Verifica
    che la risposta di LLM alla domanda del test sia basata sulcontenuto del file
    caricato.      ###### Suggerimento    Puoi scrivere un test orizzontale separato
    per verificare che l''LLM non si riferisca alla sua conoscenza interna o abbia
    delle allucinazioni. Ad esempio, prima di caricare il file nell''[Esempio 11-23](#test_horizontal),
    l''LLM dovrebbe rispondere con "Non lo so" solo se l''utente chiede chi è "Ali
    Parandeh".    Qualsiasi altro risultato potrebbe indicare che LLM ha delle allucinazioni
    o sta utilizzando le sue conoscenze interne. Oppure, il database dei vettori potrebbe
    non essere stato resettato correttamente dalle precedenti esecuzioni del test.
    Una registrazione e un monitoraggio appropriati dei tuoi servizi possono aiutarti
    a risolvere eventuali problemi derivanti da test E2E come questo.    Come hai
    visto nell''[Esempio 11-23](#test_horizontal), il test dei flussi di lavoro degli
    utenti può comportare la chiamata a uno o più endpoint in una sequenza e la verifica
    degli effetti collaterali e dei risultati attesi.    Gli esempi [11-22](#test_vertical)
    e [11-23](#test_horizontal) dovrebbero averti chiarito meglio lo scopo dei test
    E2E, sia verticali che orizzontali; perché differiscono dai test di integrazione;
    e come progettarli e implementarli .[PRE35]``  [PRE36]'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE11] # tests/rag/retrieve.py  @pytest.mark.asyncio ![1](assets/1.png) async
    def test_search_db(async_db_client): ![2](assets/2.png)     result = await async_db_client.search(         collection_name="test",
    query_vector=[0.18, 0.81, 0.75, 0.12], limit=1     )     assert result is not
    None [PRE12]`  [PRE13] class FakeLLMClient: ![1](assets/1.png)     def __init__(self):         self.cache
    = dict()      def invoke(self, query):         if query in self.cache:             return
    self.cache.get(query) ![2](assets/2.png)          response = requests.post("http://localhost:8001",
    json={"query": query})         if response.status_code != 200:             return
    "Error fetching result"          result = response.json().get("response")         self.cache[query]
    = result         return result  def process_query(query, llm_client, token):     response
    = llm_client.invoke(query, token) ![1](assets/1.png)     return response  def
    test_fake_llm_client(query):     llm_client = FakeLLMClient()     query = "some
    query"     response = process_query(query, llm_client, token="fake_token")     assert
    response == "some response" [PRE14] class DummyLLMClient:     def invoke(self,
    query, token): ![1](assets/1.png)         return "some response"  def process_query(query,
    llm_client, token):     response = llm_client.invoke(query, token) ![1](assets/1.png)     return
    response  def test_dummy_llm_client(query):     llm_client = DummyLLMClient()     query
    = "some query"     response = process_query(query, llm_client, token="fake_token")     assert
    response == "some response" [PRE15] class StubLLMClient:     def invoke(self,
    query):         if query == "specific query": ![1](assets/1.png)             return
    "specific response"         return "default response"  def process_query(query,
    llm_client):     response = llm_client.invoke(query)     return response  def
    test_stub_llm_client():     llm_client = StubLLMClient()     query = "specific
    query"     response = process_query(query, llm_client)     assert response ==
    "specific response" [PRE16] class SpyLLMClient:     def __init__(self):         self.call_count
    = 0         self.calls = []      def invoke(self, query):         self.call_count
    += 1 ![1](assets/1.png)         self.calls.append((query))         return "some
    response"  def process_query(query, llm_client):     response = llm_client.invoke(query)     return
    response  def test_process_query_with_spy():     llm_client = SpyLLMClient()     query
    = "some query"      process_query(query, llm_client)      assert llm_client.call_count
    == 1     assert llm_client.calls == [("some query")] [PRE17] $ pip install pytest-mock
    [PRE18] def process_query(query, llm_client):     response = llm_client.invoke(query)     return
    response  def test_process_query_with_mock(mocker):     llm_client = mocker.Mock()
    ![1](assets/1.png)     llm_client.invoke.return_value = "mock response"     query
    = "some query"      process_query(query, llm_client)     process_query(query,
    llm_client)      assert llm_client.invoke.call_count == 2     llm_client.invoke.assert_any_call("some
    query") [PRE19] class LLMClient:     def invoke(self, query):         return openai.ChatCompletion.create(             model="gpt-4o",
    messages=[{"role": "user", "content": query}]         )  @pytest.fixture def llm_client():     return
    LLMClient()  def test_fake(mocker, llm_client):     class FakeOpenAIClient: ![1](assets/1.png)         @staticmethod         def
    invoke(model, query):             return {"choices": [{"message": {"content":
    "fake response"}}]}      mocker.patch(openai.ChatCompletion, new=FakeOpenAIClient)
    ![1](assets/1.png)     result = llm_client.invoke("test query")     assert result
    == {"choices": [{"message": {"content": "fake response"}}]}  def test_stub(mocker,
    llm_client):     stub = mocker.Mock()     stub.process.return_value = "stubbed
    response"     result = llm_client.invoke(stub)     assert result == "stubbed response"  ![2](assets/2.png)  def
    test_spy(mocker, llm_client):     spy = mocker.spy(LLMClient, ''send_request'')     spy.return_value
    = "some_value"     llm_client.invoke("some query")     spy.call_count == 1  ![3](assets/3.png)  def
    test_mock(mocker, llm_client):     mock = mocker.Mock()     llm_client.invoke(mock)     mock.process.assert_called_once_with("some
    query") ![4](assets/4.png) [PRE20]`  [PRE21] def calculate_recall(expected: list[int],
    retrieved: list[int]) -> int: ![1](assets/1.png)     true_positives = len(set(expected)
    & set(retrieved))     return true_positives / len(expected)   def calculate_precision(expected:
    list[int], retrieved: list[int]) -> int: ![2](assets/2.png)     true_positives
    = len(set(expected) & set(retrieved))     return true_positives / len(retrieved)  expected_document_ids
    = [1, 2, 3, 4, 5] retrieved_documents_ids = [2, 3, 6, 7]  recall = calculate_recall(expected_document_ids,
    retrieved_documents_ids) precision = calculate_precision(expected_document_ids,
    retrieved_documents_ids)  print(f"Recall: {recall:.2f}") # Recall: 0.40 print(f"Precision:
    {precision:.2f}") # Precision: 0.50 [PRE22] @pytest.mark.parametrize("query_vector,
    expected_ids", [ ![1](assets/1.png)     ([0.1, 0.2, 0.3, 0.4], [1, 2, 3]),     ([0.2,
    0.3, 0.4, 0.5], [2, 1, 3]),     ([0.3, 0.4, 0.5, 0.6], [3, 2, 1]),     ... ])
    def test_retrieval_subsystem(db_client, query_vector, expected_ids): ![2](assets/2.png)     response
    = db_client.search( ![2](assets/2.png)         collection_name="test",         query_vector=query_vector,         limit=3     )      retrieved_ids
    = [point.id for point in response]     recall = calculate_recall(expected_ids,
    retrieved_ids)     precision = calculate_precision(expected_ids, retrieved_ids)      assert
    recall >= 0.66 ![3](assets/3.png)     assert precision >= 0.66 ![3](assets/3.png)
    [PRE23] @pytest.mark.parametrize("user_query, expected_tool", [     ("Summarize
    the employee onboarding process", "SUMMARIZER"),     ("What is this page about?
    https://...", "WEBSEARCH"),     ("Analyze the 2024 annual accounts", "ANALYZER"),     ...
    # Add 100 different cases with a balanced category distribution ]) ![1](assets/1.png)
    def test_llm_tool_selection_response(user_query, expected_tool):     response
    = llm.invoke(user_query, response_type="json")     assert response["selected_tool"]
    == expected_tool     assert response["message"] is not None [PRE24] $ pip install
    textstat [PRE25]`##### Esempio 11-17\. Test di funzionalità minima per la leggibilità    [PRE26]    [![1](assets/1.png)](#co_testing_ai_services_CO17-1)      Itera
    su vari esempi controllando il punteggio di leggibilità anche quando un utente
    chiede spiegazioni semplici.      [![2](assets/2.png)](#co_testing_ai_services_CO17-2)      Utilizza
    la formula di Flesch per valutare il punteggio di leggibilità. Un buon punteggio'
