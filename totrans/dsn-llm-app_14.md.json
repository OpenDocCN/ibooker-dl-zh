["```py\npattern = r\"(?i)\\b(?:C\\.?F\\.?O|Chief\\s+Financial\\s+Officer)\\b\"\n```", "```py\nfrom sentence_transformers import SentenceTransformer, util\nsbert_model = SentenceTransformer('msmarco-distilbert-base-tas-b')\nembedding = sbert_model.encode(\"American pizza is one of the nation's greatest\ncultural exports\", show_progress_bar=True, device='cuda',\n\nconvert_to_tensor=True)\nprint(\"Embedding size:\", embedding.shape[0])\nprint(embedding)\n```", "```py\nEmbedding size: 768\n\ntensor([-3.9256e-01,  1.0734e-01,  1.3579e-01,  7.6147e-02,  5.2521e-02,\n-6.5887e-03,  1.9225e-01,  3.5374e-01,  2.5725e-01,  5.6408e-02,...])\n```", "```py\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\n\ntokenizer=\nAutoTokenizer.from_pretrained(\n  \"sentence-transformers/msmarco-distilbert-base-tas-b\")\nmodel =\nAutoModel.from_pretrained(\"sentence-transformers/msmarco-distilbert-base-tas-b\")\n\ninput = tokenizer(\n  'American pizza is one of the nation's greatest cultural exports',\npadding=True, truncation=True, return_tensors='pt')\n\nwith torch.no_grad():\n        output = model(**input, return_dict=True)\n       embedding = output.last_hidden_state[:, 0]\nprint(embedding)\n```", "```py\nchunks = ['The President of the U.S is Joe Biden',\n'Ramen consumption has increased in the last 5 months']\n```", "```py\nfrom sentence_transformers import SentenceTransformer, util\nsbert_model = SentenceTransformer('msmarco-distilbert-base-tas-b')\nchunk_embeddings = sbert_model.encode(chunks, show_progress_bar=True,\ndevice='cuda', normalize_embeddings=True, convert_to_tensor=True)\nquery_embedding = sbert_model.encode(query, device='cuda',\nnormalize_embeddings=True, convert_to_tensor=True)\nmatches = util.semantic_search(query_embedding, chunk_embeddings,\nscore_function=util.dot_score)\n```", "```py\n[[{'corpus_id': 0, 'score': 0.8643729090690613},\n  {'corpus_id': 1, 'score': 0.6223753690719604}]]\n```", "```py\n!pip install sentence-transformers\n\nfrom sentence_transformers import SentenceTransformer, util\nmodel = SentenceTransformer('all-mpnet-base-v2')\n\nsentences = ['After his 25th anniversary at the company, Mr. Pomorenko\nconfirmed that he is not retiring',  'Mr. Pomorenko announced his retirement\nyesterday']\nembeddings = model.encode(sentences)\ncosine_scores = util.cos_sim(embeddings[0], embeddings[1])\nprint(\"Cosine Similarity:\", cosine_scores.item())\n```", "```py\nCosine Similarity: 0.7870\n```", "```py\nCosine Similarity: 0.7677!\n```", "```py\nfrom datasets import load_dataset\nfrom sentence_transformers import SentenceTransformer, SentenceTransformerTrainer\nfrom sentence_transformers.losses import TripletLoss\n\nmodel = SentenceTransformer( \"'all-mpnet-base-v2'\")\n\ndataset = load_dataset(\"csv\", data_files=\"negatives_dataset.csv\")\n\nloss = TripletLoss(model)\n\ntrainer = SentenceTransformerTrainer(\n    model=model,\n    train_dataset=dataset\n    loss=loss\n   )\ntrainer.train()\nmodel.save_pretrained(\"mpnet_finetuned_negatives\")\n```", "```py\n!pip install InstructorEmbedding\n\nfrom InstructorEmbedding import INSTRUCTOR\nmodel = INSTRUCTOR('hkunlp/instructor-large')\n\ncustomized_embeddings = model.encode(\n[['Represent the question for retrieving supporting documents:',\n  'Who is the CEO of Apple'],\n ['Represent the sentence for retrieval:',\n  'Tim Cook is the CEO of Apple'],\n ['Represent the sentence for retrieval:',\n  'He is a musically gifted CEO'],\n)\n```", "```py\n‘Represent the {domain} {text_type} for {task_objective}:’\n```", "```py\nfrom sentence_transformers import SentenceTransformer\nfrom sentence_transformers import SentenceTransformerTrainer, losses\nfrom datasets import load_dataset\n\nmodel = SentenceTransformer(\"all-mpnet-base-v2\")\ntrain_dataset = load_dataset(\"csv\", data_files=\"finetune_dataset.csv\")\nloss = losses.MultipleNegativesRankingLoss(model)\nloss = losses.MatryoshkaLoss(model, loss, [768, 512, 256, 128]])\n\ntrainer = SentenceTransformerTrainer(\n    model=model,\n    train_dataset=train_dataset,\n    loss=loss,\n)\ntrainer.train()\n```", "```py\nfrom sentence_transformers.quantization import quantize_embeddings\n\nmodel = SentenceTransformer(\"all-mpnet-base-v2\")\nembeddings = model.encode([\"I heard the horses are excited for Halloween.\",\n\"Dalmatians are the most patriotic of dogs.\", \"This restaurant is making me\nnostalgic.\"])\nbinary_embeddings = quantize_embeddings(embeddings, precision=\"binary\")\n```", "```py\n!pip install chromadb\n\nimport chromadb\nchroma_client = chromadb.Client()\n\ncollection = chroma_client.create_collection(name=\"mango_science\")\nchunks = ['353 varieties of mangoes are now extinct',\n'Mangoes are grown in the tropics']\nmetadata = [{\"topic\": \"extinction\", \"chapter\": \"2\"}, {\"topic\": \"regions\",\n  \"chapter\": \"5\"}]\nunique_ids = [str(i) for i in range(len(chunks))]\n\ncollection.add(\n   documents=chunks,\n   metadatas=metadata,\n   ids=unique_ids\n  )\nresults = collection.query(\n   query_texts=[\"Where are mangoes grown?\"],\n   n_results=2,\n   where={\"chapter\": { \"$ne\": \"2\"}},\n   where_document={\"$contains\":\"grown\"}\n)\n```"]