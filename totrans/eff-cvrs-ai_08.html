<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">7</span> </span> <span class="chapter-title-text">Augmenting intent data with generative AI</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header">This chapter covers</h3> 
   <ul> 
    <li class="readable-text" id="p2">Creating new training and testing examples with generative AI</li> 
    <li class="readable-text" id="p3">Identifying gaps in your current conversational AI data</li> 
    <li class="readable-text" id="p4">Use LLMs to build new intents in your conversational AI</li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p5"> 
   <p>Conversational AI users are frustrated when the AI does not understand them—especially if it happens multiple times! This applies to all conversational AI types, including question-answering bots, process-oriented bots, and routing agents. We’ve seen multiple strategies for improving the AI’s ability to understand. The first strategy—improving intent training manually (chapter 5)—gives full control to the human builder, but it takes time and specialized skill. The second strategy—retrieval-augmented generation (RAG, chapter 6)—gives much more control to generative AI, reducing the role of the human builder over time. This chapter introduces a hybrid approach where generative AI augments the builder. This applies to rules-based or generative AI–based systems.</p> 
  </div> 
  <div class="readable-text intended-text" id="p6"> 
   <p>Using generative AI as a “muse” for the human builder reduces the effort and time required of the human builder, increases the amount of test data available for data science activities, and gives the human builder the final say, which eliminates most opportunities for hallucinations (which is when AI says something that looks reasonable but is not true).</p> 
  </div> 
  <div class="readable-text intended-text" id="p7"> 
   <p>Let’s say you are building a conversational AI solution to help your IT help desk. From interviews, you know that password resets are the most frequent task the AI needs to support. Therefore, the AI needs a strong understanding of the password reset intent.</p> 
  </div> 
  <div class="readable-text intended-text" id="p8"> 
   <p>Because the conversational AI solution is new, you don’t have any production user utterances to train from. When you ask the service desk how users generally start their conversations, you hear “Well, they usually say something about ‘forgot password’ or ‘cannot login.’” You are appropriately suspicious—surely the users have a broader vocabulary than that—but you have a hard time imagining what that vocabulary might be. Generative AI can help you imagine.</p> 
  </div> 
  <div class="readable-text intended-text" id="p9"> 
   <p>Let’s look at how the human builder and generative AI can be partners.</p> 
  </div> 
  <div class="readable-text" id="p10"> 
   <h2 class=" readable-text-h2"><span class="num-string">7.1</span> Getting started</h2> 
  </div> 
  <div class="readable-text" id="p11"> 
   <p>Large language models (LLMs) are skilled at performing many technical tasks, including classification and question answering. These are the same tasks at the core of conversational AI. So why don’t we just use generative AI for our core conversational AI tasks?</p> 
  </div> 
  <div class="readable-text intended-text" id="p12"> 
   <p>LLMs are generalizable because they have been trained on huge amounts of data. This makes them a quick study on many tasks, but it also comes with some cost. What are the costs to using LLM as the classifier in conversational AI? </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p13"> <em>Monetary</em><em> </em>—LLMs can be expensive to run. </li> 
   <li class="readable-text" id="p14"> <em>Speed</em><em> </em>—Because LLMs consider billions of parameters, they can be slower (a time cost). </li> 
   <li class="readable-text" id="p15"> <em>Reputation risk</em><em> </em>—LLMs are so generalized that they may hallucinate output that makes your bot look bad or exposes you to legal risk. </li> 
   <li class="readable-text" id="p16"> <em>Lack of transparency and explainability</em><em> </em>—LLMs are often a “black box.” </li> 
  </ul> 
  <div class="readable-text" id="p17"> 
   <p>By contrast, conversational AI uses purpose-built technology. Because its classifier is trained only to do the task at hand, it is much cheaper, and it runs quickly because it considers fewer parameters. While that may reduce the accuracy, the system is guaranteed to use a set of controlled responses. These comparisons are summarized in table 7.1.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p18"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 7.1</span> Comparing and contrasting traditional natural language processing (NLP) in conversational AI and generative AI on the classification task</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Feature 
       </div></th> 
      <th> 
       <div>
         Traditional NLP 
       </div></th> 
      <th> 
       <div>
         Generative AI 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Model <br/></td> 
      <td>  Purpose-built for excellence at only one task: classification <br/></td> 
      <td>  Generalized model good at many tasks <br/></td> 
     </tr> 
     <tr> 
      <td>  Runtime speed <br/></td> 
      <td>  Fast <br/></td> 
      <td>  Slow <br/></td> 
     </tr> 
     <tr> 
      <td>  Runtime cost <br/></td> 
      <td>  Low <br/></td> 
      <td>  High <br/></td> 
     </tr> 
     <tr> 
      <td>  Accuracy <br/></td> 
      <td>  Mostly accurate (trained by you on small data) <br/></td> 
      <td>  Mostly accurate (pretrained on huge data) <br/></td> 
     </tr> 
     <tr> 
      <td>  Scalability <br/></td> 
      <td>  Manageable for up to 100 intents; very difficult afterward <br/></td> 
      <td>  Generalizes very well via RAG pattern <br/></td> 
     </tr> 
     <tr> 
      <td>  Controllability <br/></td> 
      <td>  Strictly controlled by humans; requires extensive testing <br/></td> 
      <td>  Prone to hallucinate when given full control; hallucinations are hard to detect automatically <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p19"> 
   <p>We can use a hybrid approach to get the best of both methods.</p> 
  </div> 
  <div class="readable-text" id="p20"> 
   <h3 class=" readable-text-h3"><span class="num-string">7.1.1</span> Why do it: Pros and cons</h3> 
  </div> 
  <div class="readable-text" id="p21"> 
   <p>An LLM can greatly reduce the time and effort spent by a human builder. LLMs and humans work best together—as partners. Training a conversational AI classifier requires human effort, but it also requires data, and that data can be hard to collect. Sometimes that data cannot be collected until the conversational AI is deployed in production. Even in our familiar example of detecting “forgot password” problems, we still don’t know all the ways users might state their problem. They may use the “wrong” words!</p> 
  </div> 
  <div class="readable-text intended-text" id="p22"> 
   <p>LLMs are especially helpful in these scenarios:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p23"> <em>Bootstrapping</em><em> </em>—AI suffers from a “cold start” problem. How can you train when you have no data? LLMs can generate an initial set of training data. </li> 
   <li class="readable-text" id="p24"> <em>Expanding</em><em> </em>—Use LLMs to fill the gaps in your existing data when you don’t have enough data to optimize your classifier’s accuracy. This is especially useful for understanding rare but important intents (such as users reporting fraud). </li> 
   <li class="readable-text" id="p25"> <em>Robust testing</em><em> </em>—LLMs can generate additional data for testing, increasing your confidence in the robustness of the conversational AI. (This is helpful even if generative AI creates the answers, as in RAG.) </li> 
  </ul> 
  <div class="readable-text" id="p26"> 
   <p>An LLM can help you run many experiments, some of which will generate output that is directly usable by your application, either as training or testing data. You and the LLM can help each other too. For instance, the LLM can give you themes and variations that your users may use. You can select your favorites and ask the LLM to expand on those by updating the prompt instructions or few-shot examples.</p> 
  </div> 
  <div class="readable-text intended-text" id="p27"> 
   <p>Your interactions with the LLM will be iterative and collaborative. For instance, you are unlikely to design the right prompt the first time. The LLM may not understand the task correctly or may give you content that’s not quite helpful. Expect to do a few rounds of experimentation before you get great results. After that, you can quickly generate suggestions across all your intents and improve your AI’s understanding of your users.</p> 
  </div> 
  <div class="readable-text" id="p28"> 
   <h3 class=" readable-text-h3"><span class="num-string">7.1.2</span> What you need</h3> 
  </div> 
  <div class="readable-text" id="p29"> 
   <p>Many LLMs can help us with our task of generating more training or testing data for our “forgot password” intent. So do we just pick one and turn it loose? Not quite. The LLM will help you, but you should not expect it to do all the work. Instead, you should have an idea of where you need to start, such as knowing what gaps you have in your solution. You also need to select an LLM that is appropriate for your use case.</p> 
  </div> 
  <div class="readable-text intended-text" id="p30"> 
   <p>Access to an LLM is an obvious prerequisite for using an LLM to augment your conversational AI. There are several non-obvious considerations when selecting that LLM:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p31"> <em>Terms and conditions</em><em> </em>—Several LLMs explicitly forbid you from using their LLM to “build or improve another model.” This clause is intended to keep you from building a competitive LLM, but using an LLM to improve conversational AI could be construed in this way, and your appetite for legal risk may vary. (Consult with your legal department—they may have already selected LLMs for your company to use.) </li> 
   <li class="readable-text" id="p32"> <em>Data privacy</em><em> </em>—As you use the LLM, will it be allowed to keep your data and train on it in the future? The data in your conversational AI may be confidential to your corporation. If it is, you can’t just share it with any LLM. </li> 
   <li class="readable-text" id="p33"> <em>Capability</em><em> </em>—Not every LLM is capable of creative generation tasks. Make sure you select a model that can follow instructions. </li> 
   <li class="readable-text" id="p34"> <em>Open source or proprietary</em><em> </em>—For many use cases, explainability is important. Open source models generally give you more insight into the model’s training process, such as the training data and source code for the model. Proprietary models generally do not expose that information but usually have more ease-of-use. This may also affect your ethical and regulatory compliance. </li> 
   <li class="readable-text" id="p35"> <em>Latency and response times</em><em> </em>—There are speed and accuracy tradeoffs; a larger model may be both more accurate and slower to run. </li> 
  </ul> 
  <div class="readable-text" id="p36"> 
   <p>In this chapter and the rest of the book, we will use multiple prompts and models to provide examples. These examples will be adaptable to your model (or models) of choice. Feel free to experiment with other models, especially those that weren’t available as we wrote this book.</p> 
  </div> 
  <div class="readable-text intended-text" id="p37"> 
   <p>You will also need to bring some domain knowledge to the LLM. This can include background on the problems your users are bringing to your conversational AI, the intents your system needs to support, and utterances belonging to those intents. Bring as much real-world data as you can. Then use the LLM to augment that data.</p> 
  </div> 
  <div class="readable-text" id="p38"> 
   <h3 class=" readable-text-h3"><span class="num-string">7.1.3</span> How to use the augmented data</h3> 
  </div> 
  <div class="readable-text" id="p39"> 
   <p>An LLM can help you generate additional data for use by your chatbot. Using an LLM at build time reduces the risk and effect of hallucinations. These options include adding to your training data, adding to your testing data, and modifying your existing data (for example, changing grammatical structure and synonyms).</p> 
  </div> 
  <div class="readable-text intended-text" id="p40"> 
   <p>The best source is data is from real users of a production system. We recognize that this introduces a chicken-and-egg problem—you may not have any data if you are not in production yet. Your intent classifier needs to be trained on varied data so that it can understand varied data. The chatbot should be tested on data that it was not trained on.</p> 
  </div> 
  <div class="readable-text intended-text" id="p41"> 
   <p>When you don’t have any training data, you’ll tend to generate low-variance utterances. You’ll have a couple of key words in mind, and you’ll “anchor” yourself to them. Even with dozens of examples, low-variance utterances don’t convey much information. High-variation utterances cover a lot of ground quickly, as shown in table 7.2, and they generally make your classifier stronger.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p42"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 7.2</span> Comparing low-variation to high-variation utterances. High-variation utterances increase the robustness of classifiers.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Low-variation utterance set 
       </div></th> 
      <th> 
       <div>
         High-variation utterance set 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  • I forgot my password <br/>  • Forgot my password <br/>  • Forgot password <br/>  • Help I forgot my password <br/></td> 
      <td>  • I can’t log in <br/>  • Account locked out <br/>  • Forgot password <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p43"> 
   <p>The high-variation utterances easily cover the low-variation utterances despite being fewer in number. The single utterance “forgot password” is enough to predict the intent of all four low-variance utterances. The reverse is not true and wouldn’t be true even if we added dozens more slight variations on “forgot password” to the low-variance set. “I can’t log in” has no direct word overlap—the low-variance set doesn’t cover it.</p> 
  </div> 
  <div class="readable-text intended-text" id="p44"> 
   <p>We prefer a small, high-variance training data set that covers a large volume of low-variance test utterances. Better to train on 10 strong variations than 100 weak variations. This makes the chatbot robust to the diverse utterances it will see in production. It also reduces your chances of accidentally unbalancing the training set (which leads to weak understanding).</p> 
  </div> 
  <div class="readable-text intended-text" id="p45"> 
   <p>We can visualize the information conveyed by the utterances in figure 7.1. The first plot shows the low-variation utterances from table 7.2. Since they only convey two words, you can think that the utterances are tightly clustered together. The second plot shows the high-variation utterances. With no word overlap, the utterances are spread all over the grid, but there is a lot of empty space. The third plot shows an ideal test set where there is broad coverage of the grid. The fourth plot shows an ideal training set, which covers maximum variation in a small number of examples. The test data set can be much larger than the training set. We want the test set to have variation, but it’s fine if we have near-duplicates.</p> 
  </div> 
  <div class="readable-text intended-text" id="p46"> 
   <p>In this chapter, we’ll first demonstrate how to use generative AI to create high-variance utterances. Then we’ll expand on those utterances via many slight variations. By the end of the chapter, you’ll see how to generate utterances matching the third and fourth plots.</p> 
  </div> 
  <div class="browsable-container figure-container" id="p47">  
   <img alt="figure" src="../Images/CH07_F01_Freed2.png" width="919" height="364"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 7.1</span> Visualizing coverage from different kinds of utterance sets. Our ideal training data is set 4, which covers a large variation in a small number of utterances. Set 3 is the ideal testing data.</h5>
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p48"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text" id="p49"> Imagine you are building a chatbot for a typical retail store. Create ten utterances for a <code>#store_location</code> intent, for when users ask questions like “Where is your store located?” Keep track of how much time this takes. </li> 
    <li class="readable-text" id="p50"> Create ten more utterances, without using the words “where,” “store,” “located,” or “location.” (Time yourself again.) Do these utterances have more variety? </li> 
    <li class="readable-text" id="p51"> Repeat the previous two exercises for a <code>#store_hours</code> intent. First use whatever words you want, and then restrict yourself from using “when,” “time,” and “hours.” </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p52"> 
   <h2 class=" readable-text-h2"><span class="num-string">7.2</span> Hardening your existing intents</h2> 
  </div> 
  <div class="readable-text" id="p53"> 
   <p>We’ll start our exercise knowing which intent we need to improve: the “forgot password” intent. We need enough training data so that the conversational AI can detect this intent. Remember that our support staff didn’t know all the ways users might state this problem. They said, “Users usually say something about ‘forgot password’ or ‘cannot login.’” That won’t be enough to train the chatbot on a robust “forgot password” intent.</p> 
  </div> 
  <div class="readable-text intended-text" id="p54"> 
   <p>We will use the LLM as our partner. First, the LLM will help us generate contextual synonyms so that we see a broad range of vocabulary. Next, the LLM will generate full utterances using this vocabulary. Then we will have the LLM generate different grammatical variations, such as questions versus statements and past tense versus present tense. We’ll also have the LLM transfer lessons learned from building one intent (“forgot password”) into building the next intent (“find a store”).</p> 
  </div> 
  <div class="readable-text intended-text" id="p55"> 
   <p>We’ll start with the simplest step—finding synonyms.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p56"> 
    <h5 class=" callout-container-h5 readable-text-h5">Can I use a different LLM?</h5> 
   </div> 
   <div class="readable-text" id="p57"> 
    <p>Yes! We will use multiple models in this book. The field of generative AI is moving quickly, and models used during the writing of this book may be supplanted by better models by the time this book is published or by the time you read it. The principles we’ll demonstrate are more important than the specific models we’ll use. </p> 
   </div> 
  </div> 
  <div class="readable-text" id="p58"> 
   <h3 class=" readable-text-h3"><span class="num-string">7.2.1</span> Get creative with synonyms</h3> 
  </div> 
  <div class="readable-text" id="p59"> 
   <p>The first step is designing a prompt. A good prompt ensures your LLM understands its task, and the first task in this example is generating a broad range of synonyms. The process of prompt engineering requires an iterative process of experimentation. </p> 
  </div> 
  <div class="readable-text intended-text" id="p60"> 
   <p>Our subject matter experts advised that the utterances often include “forgot password.” One way of increasing your chatbot’s robustness is to make sure you have coverage on noun and verb phrases. Let’s ask an LLM to generate some likely synonyms for the noun phrases.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p61"> 
    <h5 class=" callout-container-h5 readable-text-h5">How do I set up and run my LLM?</h5> 
   </div> 
   <div class="readable-text" id="p62"> 
    <p>There are multiple options for setting up an LLM environment. You can run LLMs locally on your machine, using a tool like Ollama, or run them on a commercially hosted platform. We used the Prompt Lab available in IBM’s watsonx.ai platform due to our familiarity with it, but nothing in this chapter is platform dependent. Use your favorite platform.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p63"> 
   <p>For this exercise, we will use the falcon-40b-8lang-instruct model (<a href="https://huggingface.co/tiiuae/falcon-40b">https://huggingface.co/tiiuae/falcon-40b</a>) with greedy decoding. Greedy decoding instructs the model to generate the next most probable word at each step and yields the same output every time.</p> 
  </div> 
  <div class="readable-text intended-text" id="p64"> 
   <p>Though we want to end up with full sentence fragments, we got better results by breaking the task down into pieces. User utterances are typically sentences or fragments, primarily built from nouns and verb phrases. Let’s start with a simple prompt—just asking for synonyms—to get our nouns.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p65"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.1</span> Generating noun synonyms without context</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">Generate a list of nouns. <span class="aframe-location"/> #1
The nouns should be synonyms of 'password'. 

List of 5 nouns <span class="aframe-location"/> #2
credentials, secret, key, code, accesscode <span class="aframe-location"/> #3</pre> 
    <div class="code-annotations-overlay-container">
     #1 Simple instruction
     <br/>#2 Prompted cue for the LLM
     <br/>#3 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p66"> 
   <p>In the preceding listing, we used the LLM as a generic thesaurus. While the output nouns are synonyms for “password,” they are not synonyms that are often used in the context of logging in. We need to provide more context to the LLM to get better results. </p> 
  </div> 
  <div class="readable-text intended-text" id="p67"> 
   <p>This time let’s tell the LLM why we are asking for synonyms and what kind of synonyms we are looking for. The following listing shows the improved prompt and results.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p68"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.2</span> Generating noun synonyms with context</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">You are a consumer contacting an online retailer via their  <span class="aframe-location"/> #1
chat service. 
Generate a numbered list of nouns a consumer might use while <span class="aframe-location"/> #2
describing their inability to log in to your service in the   #2
phrase "I forgot my password".   #2
The nouns should be synonyms of 'password'.  #2

List of 5 nouns <span class="aframe-location"/> #3
1. "account information" 2. "credentials" 3. "login information" <span class="aframe-location"/> #4
4. "authentication" 5. "identifier"  #4</pre> 
    <div class="code-annotations-overlay-container">
     #1 Background information given to the LLM
     <br/>#2 Detailed instructions grounding the task to forgetting passwords
     <br/>#3 Cue for LLM
     <br/>#4 LLM response
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p69"> 
   <p>These synonyms sound much more familiar. Next, let’s create contextual verb synonyms.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p70"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.3</span> Generating verb synonyms with context</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">You are a consumer contacting an online retailer via 
their chat service. 

Generate a numbered list of verbs a consumer might <span class="aframe-location"/> #1
use while describing their inability to log in to   #1
your service in the phrase "I forgot my password".   #1
The verbs should be synonyms of 'forgot'.  #1

List of 5 verbs <span class="aframe-location"/> #2
1. Forgot 2. Lost 3. Mislaid 4. Misplaced 5. Err <span class="aframe-location"/> #3</pre> 
    <div class="code-annotations-overlay-container">
     #1 Updated instruction for verbs instead of nouns
     <br/>#2 Updated cue for verbs instead of nouns
     <br/>#3 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p71"> 
   <p>Not bad, though the last verb is a little weird in this context. Another limitation is that all the generated verbs are in the past tense. This is appropriate given that our example was also in the past tense, but we want our LLM to generate more variety for us. Let’s try expanding from <em>verbs </em>to <em>verb phrases</em>.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p72"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.4</span> Generating verb phrase synonyms with context</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">You are a consumer contacting an online retailer via their chat service. 

Generate a numbered list of verb phrases a consumer  <span class="aframe-location"/> #1
Might use while describing their inability to log in   #1
to your service in the phrase "I forgot my password".   #1
The verb phrases should be synonymous with 'forgot'.  #1
#1
List of 5 verb phrases  #1
1. I forgot my password. <span class="aframe-location"/> #2
2. I lost my password.   #2
3. I misremembered my password.  #2
4. I misplaced my password.  #2
5. I cannot remember my password.  #2</pre> 
    <div class="code-annotations-overlay-container">
     #1 Updated instruction and cue for “verb phrases”
     <br/>#2 LLM output
     <br/>#3 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p73"> 
   <p>The LLM gave us full sentences (oops!), but now we are getting some present tense utterances (“cannot remember”) along with the other past tense utterances. We are making progress! With only a few minutes of prompting, we got the LLM to give us a lot of variation to think about. Before, we might have assumed our chatbot would just have to look for “forgot” and “password.” Now we have a dozen other useful words to consider when we test the bot. </p> 
  </div> 
  <div class="readable-text intended-text" id="p74"> 
   <p>Let’s experiment a little more. This time we’ll increase the creativity of the model by moving to <em>sampling decoding</em> and increasing the temperature. We’ll also revise the prompt by asking for “10 synonyms” instead of “5 nouns.” Listing 7.5 shows the nouns, and listing 7.6 shows the verb phrases.</p> 
  </div> 
  <div class="readable-text print-book-callout" id="p75"> 
   <p><span class="print-book-callout-head">NOTE </span> With greedy decoding, the LLM generates the same results every time. Sampling decoding generates non-deterministic output. If you try these prompts, you’ll probably get different results. This is okay! We are only using the LLM to spark our creativity.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p76"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.5</span> Generating noun synonyms with increased creativity settings</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">You are a consumer contacting an online retailer via their chat service.

Generate a numbered list of synonyms a consumer might <span class="aframe-location"/> #1
use for 'password' while they described a problem like   #1
"I forgot my password".  #1
#1
List of 10 synonyms for 'password'  #1
1. "Secret" 2. "Personal Identification Number" 3. "PIN"<span class="aframe-location"/> #2
4. "Access Code" 5. "Log-in Information" 6. "Log-in Data"  #2
7. "Account Information" 8. "Account Data"   #2
9. "Identification Number" 10. "Security Code"  #2</pre> 
    <div class="code-annotations-overlay-container">
     #1 Updated prompt and cue
     <br/>#2 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p77"> 
   <p>Awesome! This is a great list of nouns. Your system may not use all of them, but this is a thorough list for testing. </p> 
  </div> 
  <div class="readable-text intended-text" id="p78"> 
   <p>Let’s try verbs next.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p79"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.6</span> Generating verb phrase synonyms with increased creativity settings</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">You are a consumer contacting an online retailer via their chat service.

Generate a numbered list of synonyms a consumer might <span class="aframe-location"/> #1
use for 'forgot' while they described a problem like   #1
"I forgot my password". #1
#1
List of 10 synonyms for 'forgot'  #1
1. Forgot 2. Did not remember 3. Didn’t know 4. Unknown <span class="aframe-location"/> #2
5. Not applicable 6. Unable to access 7. Couldn’t recall  #2
8. Didn’t memorise 9. OMG Failed to remember  #2
10. Unable to login  #2</pre> 
    <div class="code-annotations-overlay-container">
     #1 Updated instruction and cue
     <br/>#2 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p80"> 
   <p>This is a much more creative list of synonyms. While there are some oddities in this list (“unknown,” “not applicable”) there are some nice creative sparks:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p81"> <em>Slightly wrong verb</em><em> </em>—“Did not remember” is odd, but it makes you think of “Cannot remember.” </li> 
   <li class="readable-text" id="p82"> <em>Wrong tense</em><em> </em>—“Didn’t know” makes you consider “Do not know.” </li> 
   <li class="readable-text" id="p83"> <em>Sentiment</em><em> </em>—“OMG” reminds you that utterances may include frustration. </li> 
  </ul> 
  <div class="readable-text" id="p84"> 
   <p>We’ve generated synonyms relevant to our domain with only a few minutes of effort, but we still only have piece-parts. We started with the utterance “I forgot my password” and can now plug in new nouns and verb phrases, but we are still stuck with a simple subject-verb-object structure. Our users will surely use more varied grammar. We don’t want the chatbot to depend on only one grammatical form. We want it to be resilient to more varied utterances. Let’s use LLMs to generate more grammatical variations.</p> 
  </div> 
  <div class="readable-text" id="p85"> 
   <h3 class=" readable-text-h3"><span class="num-string">7.2.2</span> Generate new grammatical variations</h3> 
  </div> 
  <div class="readable-text" id="p86"> 
   <p>Instead of asking the LLM to generate words or word pairs, let’s try having it generate entire utterances. We need to design a prompt that introduces word variation, but we don’t want to bias the model too hard toward “I forgot my password.” We will use a similar prompt that sets a context, but rather than directly including the phrase “I forgot my password,” we will describe the user’s problem instead (they can’t log in). </p> 
  </div> 
  <div class="readable-text intended-text" id="p87"> 
   <p>Our first attempt is shown in the following listing.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p88"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.7</span> Generating entire utterances</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">You are a consumer contacting an online retailer via their chat service. 

Generate a numbered list of example utterances a  <span class="aframe-location"/> #1
consumer might start conversation with if they couldn't   #1
log in.  Use a variety of nouns and verbs related to    #1
logging in, passwords, and accounts.  #1
#1
List of 10 utterances  #1
1. I can't log in         <span class="aframe-location"/> #2
2. My password isn't working  #2
3. I don't know my password  #2
4. I forgot my username  #2
5. I forgot my password  #2
6. My account is locked  #2
7. I didn't get my password reset email # #2
8. I need help with my account  #2
9. Can you help me log in?  #2
10. I tried resetting my password but it didn't work  #2</pre> 
    <div class="code-annotations-overlay-container">
     #1 Updated instruction and cue
     <br/>#2 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p89"> 
   <p>We are starting to get more variety. This list of utterances has several ideas we haven’t seen yet (like “password reset email”). Even better, we are getting more variety in the sentence structure. The output list has the following grammatical varieties:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p90"> <em>Subject verb object statement (active voice)</em><em> </em>—I forgot my password. </li> 
   <li class="readable-text" id="p91"> <em>Passive voice statement</em><em> </em>—My account is locked. </li> 
   <li class="readable-text" id="p92"> <em>Prepositional</em><em> </em>—I need help with my account. </li> 
   <li class="readable-text" id="p93"> <em>Question</em><em> </em>—Can you help me log in? </li> 
   <li class="readable-text" id="p94"> <em>Qualifiers</em><em> </em>—I tried resetting my password but it didn’t work. </li> 
  </ul> 
  <div class="readable-text" id="p95"> 
   <p>The variety in our sample utterances is improving. The generated utterances are usable for our training or test sets, but there are still gaps. For instance, all these utterances are perfect sentences. What about our users who are so busy (or frustrated) that they only give us a few words? Can the LLM generate useful sentence fragments? The following listing explores this idea.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p96"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.8</span> Generating sentence fragment utterances</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">You are a consumer contacting an online retailer via their chat service. 

Generate a numbered list of example fragments a <span class="aframe-location"/> #1
Consumer might start conversation with if they  #1
couldn't log in.  Use a variety of nouns and verbs  #1
related to logging in, passwords, and accounts. Use  #1
sentence fragments only.  #1
#1
List of 10 sentence fragments   #1
1.  Forgot password <span class="aframe-location"/> #2
2.  Unable to login <span class="aframe-location"/> #3
3.  Account locked out  #3
4.  Need help resetting password  #3
5.  Can't remember email address  #3
6.  Email is not working  #3
7.  Unable to change password  #3
8.  Unable to access account #3
9.  Unable to create new account  #3
10. Unable to delete old account  #3</pre> 
    <div class="code-annotations-overlay-container">
     #1 Updated instruction to generate fragments. Cue is unchanged.
     <br/>#2 One-shot example below the cue
     <br/>#3 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p97"> 
   <p>In our previous prompts, we were not able to generate sentence fragments. This time, we gave the LLM extra help. Aside from our usual updates to the prompt (replacing “utterances” with “fragments”), we gave the LLM one additional hint. We provided the first example fragment “Forgot password.” This is called one-shot learning because we gave the LLM one example of what we wanted, and that helped the LLM learn how to process our request.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p98"> 
    <h5 class=" callout-container-h5 readable-text-h5">Zero-shot? One-shot? Few-shot?</h5> 
   </div> 
   <div class="readable-text" id="p99"> 
    <p>The “zero-shot,” “one-shot,” and “few-shot” terms refer to the number of examples (shots) given in the prompt. A zero-shot prompt does not give any examples. A one-shot prompt gives one example, and a few-shot prompt gives a few examples.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p100"> 
   <p>For training data generation, one-shot learning is a great way to get exactly the kind of output you want. Whenever you are having trouble getting an LLM to follow your instructions, consider giving a good example rather than just tweaking the instructions. While writing this chapter, we tried several more prompts than are included in this book, and none of them gave us sentence fragments until we used one-shot learning.</p> 
  </div> 
  <div class="readable-text intended-text" id="p101"> 
   <p>Further, you can use one-shot learning to take the lessons learned while building one intent and apply them to another intent. In the next listing, we use examples from a “store location” intent to generate examples for a “password reset” intent.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p102"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.9</span> Using one-shot learning for multiple grammatical structures</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">You are a consumer contacting an online retailer via <span class="aframe-location"/> #1
their chat service. #1

Generate phrases a user might use to find out where<span class="aframe-location"/> #2
stores are located. Create phrases for each of the  #2
following grammatical types. #2
Direct Question: Where are you located?  #2
Indirect Question: Can you tell me how to find your  #2
stores?  #2
Fragment: Store location  #2
Command: Give me driving directions  #2

Generate phrases a user might use when they need to <span class="aframe-location"/> #3
reset their password. #3
Create phrases for each of the following grammatical #3
types. #3
Direct Question:  I forgot my password. <span class="aframe-location"/> #4
Indirect Question:  How can I reset my password?  #4
Fragment:  Password reset #4
Command:  Send me a password reset link  #4</pre> 
    <div class="code-annotations-overlay-container">
     #1 Standard background for LLM, unchanged from the past several examples
     <br/>#2 One-shot example includes instruction and desired output
     <br/>#3 Instruction to the LLM, supplemented by the cue “Direct Question:”
     <br/>#4 LLM output (starts after the cue “Direct Question:”)
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p103"> 
   <p>With a single prompt, we were able to get examples of each of the grammatical structures we wanted (the LLM made a mistake on “direct question,” but the output is still useful).</p> 
  </div> 
  <div class="readable-text intended-text" id="p104"> 
   <p>Here’s one more trick for generating utterances. Rather than using detailed instructions, provide a few examples, and ask the LLM to generate more. We’ll use a different prompt format and a different model—granite-13b-instruct-v2 (<a href="https://mng.bz/DMlR">https://mng.bz/DMlR</a>)—and we’ll use sampling decoding for increased creativity and non-deterministic results. The following listing shows the prompt and first output.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p105"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.10</span> Using a creative prompt to generate examples with a Granite model</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">&lt;|instruction|&gt; <span class="aframe-location"/> #1
Here are actual utterances submitted by customers to an <span class="aframe-location"/> #2
automated help desk. Your task is to create new   #2
examples from people having problems with their   #2
password and login ability.  #2

&lt;|example|&gt; <span class="aframe-location"/> #3
I can't log in

&lt;|example|&gt;
My login information isn't working

&lt;|example|&gt;
Forgot password

&lt;|example|&gt;
Help me get into my account

&lt;|example|&gt; <span class="aframe-location"/> #4
Hi there, I can't seem to login to my account <span class="aframe-location"/> #5</pre> 
    <div class="code-annotations-overlay-container">
     #1 A marker indicating our instruction to the model
     <br/>#2 The actual instruction
     <br/>#3 Beginning of examples
     <br/>#4 Output cue
     <br/>#5 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p106"> 
   <p>Because we are using non-deterministic settings, the model output is different every time. Here are the outputs from the next five executions of the same prompt:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p107"> “Can you help me recover my password” </li> 
   <li class="readable-text" id="p108"> “I’m locked out of my account” </li> 
   <li class="readable-text" id="p109"> “Can’t remember username or password” </li> 
   <li class="readable-text" id="p110"> “Hoping you can help me, I just reset my password but it’s not working” </li> 
   <li class="readable-text" id="p111"> “I’ve failed logging in 5 times in a row” </li> 
  </ul> 
  <div class="readable-text" id="p112"> 
   <p>We didn’t specify exactly what variation we wanted, but we still got some interesting variations. We saw new verbs (“recover”) and concepts (“5 times in a row”). This highlights the value of experimenting with different LLMs, different prompts, and different parameter settings. Generating training data requires creativity. Don’t rely on one or two experiments to do the work—you and generative AI can work together to be creative.</p> 
  </div> 
  <div class="readable-text" id="p113"> 
   <h3 class=" readable-text-h3"><span class="num-string">7.2.3</span> Build strong intents from LLM output</h3> 
  </div> 
  <div class="readable-text" id="p114"> 
   <p>Let’s recap our experiments so far. We’ve generated nouns and verbs as in-context synonyms (not just generic synonyms). We’ve generated entire utterances with a similar structure, then used LLMs to generate utterances with varied grammatical structures. We’ve used multiple models, prompts, and parameter settings. Generative AI has been a great partner!</p> 
  </div> 
  <div class="readable-text intended-text" id="p115"> 
   <p>From these experiments, we have a lot of possibilities for building a training set. Let’s select 10 utterances covering the variations we generated earlier. For some of the utterances, we’ll use the verbatim output from the LLMs. For other utterances, we’ll substitute some variations. For instance, the generated utterances were heavy on “password”—we can substitute “login information” or “account information.” The utterances were also heavy on “forgot,” so we’ll substitute “can’t remember.” The following listing shows one possible selection of utterances.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p116"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.11</span> Ten hand-selected utterances based on LLM suggestions</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">1. I can't log in
2. My login information isn't working
3. Forgot password
4. Account locked out
5. I can't remember my account information
6. My account is locked
7. I didn't get my password reset email
8. Need help with resetting account
9. Can you help me log in?
10. I tried to reset my password but it didn't work</pre>  
   </div> 
  </div> 
  <div class="readable-text" id="p117"> 
   <p>We’ve come a long way since the initial suggestion that “most requests include the words ‘forgot’ and ‘password’”! If we use these utterances in our training set, we will have much more robust chatbot understanding than if we had stuck to our keyword-based advice.</p> 
  </div> 
  <div class="readable-text intended-text" id="p118"> 
   <p>We’ve been successful generating ideas across multiple prompting sessions. This begs the question, can we do everything in one prompt? We would expect to need all our tricks to date: a context for the LLM, a clear instruction, and a one-shot example. Let’s try to train a “store locator” intent using our best examples from the “forgot password” intent. The following listing demonstrates this using the falcon-40b-8lang-instruct model with greedy decoding again.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p119"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.12</span> Using one-shot learning to copy lessons from one intent to another</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">You are a consumer contacting an online retailer via  <span class="aframe-location"/> #1
their chat service.  #1

Generate a numbered list of example utterances a  <span class="aframe-location"/> #2
consumer might start conversation with if they couldn't  #2
log in. Use a variety of nouns and verbs related to   #2
logging in, passwords, and accounts. Use a variety of  #2
grammar structures in the utterances.  #2
#2
List of 10 utterances  #2
1. I can't log in <span class="aframe-location"/> #3
2. My login information isn't working  #3
3. Forgot password  #3
4. Account locked out  #3
5. I can’t remember my account information  #3
6. My account is locked  #3
7. I didn't get my password reset email  #3
8. Need help with resetting account  #3
9. Can you help me log in?  #3
10. I tried to reset my password but it didn't work  #3

Generate a numbered list of example utterances a <span class="aframe-location"/> #4
consumer might start conversation with if they need to   #4
find your store. Use a variety of nouns and verbs  #4
related to finding, location, and directions. Use a   #4
variety of grammar structures in the utterances.  #4
#4
List of 10 utterances  #4
1. Where is your store located? <span class="aframe-location"/> #5
2. How do I find your store?  #5
3. What direction is your store from here?  #5
4. Which exit should I take to get to your store?  #5
5. Is your store north or south of here?  #5
6. Your store is on what street?  #5
7. Where is your store exactly?  #5
8. How far is your store from here?  #5
9. How long will it take me to get to your store?  #5
10. What city is your store in?  #5</pre> 
    <div class="code-annotations-overlay-container">
     #1 Standard background for LLM
     <br/>#2 Instruction and cue for one-shot example (password reset)
     <br/>#3 One-shot example
     <br/>#4 Instruction and cue for target (store locator)
     <br/>#5 LLM output
     <br/>#6 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p120"> 
   <p>Not bad! This is a reasonable start for our new intent. There are several positive aspects to this output:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p121"> <em>Verb variety</em><em> </em>—No verb is repeated, aside from “is.” </li> 
   <li class="readable-text" id="p122"> <em>Concept variety</em><em> </em>—The examples cover both absolute and relative concepts via “location” and “direction.” They also cover time and space (“how long,” “how far”). </li> 
   <li class="readable-text" id="p123"> <em>Granularity variety</em><em> </em>—Utterances range from “what city” to “what street” as well as “from here.” </li> 
  </ul> 
  <div class="readable-text" id="p124"> 
   <p>However, the utterances also have some limitations:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p125"> <em>Grammatical structure</em><em> </em>—The utterances are all questions. There are no commands or fragments. </li> 
   <li class="readable-text" id="p126"> <em>Noun variety</em><em> </em>—Every example uses “store.” </li> 
   <li class="readable-text" id="p127"> <em>Obvious omissions</em><em> </em>—I’m lost without my GPS. It’s surprising the utterances didn’t explicitly include something like “What’s your address” or “driving directions.” </li> 
  </ul> 
  <div class="readable-text" id="p128"> 
   <p>The task is too hard to complete in a single prompt. We asked the LLM for everything we wanted and even gave examples. The LLM was able to complete many of our requests but also ignored or failed to fulfill several of our requests. Things aren’t as simple as perfecting one intent and then asking the LLM replicate that to all the other intents. There are just too many instructions and variables in our task for current LLMs to get everything right in one try. That may well change in the future.</p> 
  </div> 
  <div class="readable-text intended-text" id="p129"> 
   <p>This is why we suggest using an LLM as a partner rather than doing everything by yourself or doing everything with an LLM. You cannot offload your thinking onto the LLM, but you <em>can</em> have an LLM run experiments for you very quickly. Generating synonyms and grammar variety sounds easy, but you probably couldn’t do it as quickly and completely as an LLM. Have the LLM generate lots of ideas and then pick the best ones.</p> 
  </div> 
  <div class="readable-text print-book-callout" id="p130"> 
   <p><span class="print-book-callout-head">REMEMBER </span> The LLM can’t think for you, but it can give you a very good “first draft.”</p> 
  </div> 
  <div class="readable-text" id="p131"> 
   <p>Table 7.3 summarizes dos and don’ts for using LLMs to generate training and test data.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p132"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 7.3</span> Dos and don’ts for using LLMs to generate training and testing data</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Do 
       </div></th> 
      <th> 
       <div>
         Don’t 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  • Use the LLM as a partner or creative assistant. You still drive the process. <br/>  • Set contextual guidance and focused instructions <br/>  • Use examples and one-shot learning to nudge the LLM <br/>  • Experiment with multiple prompts <br/>  • Use LLM output to augment data collected from users <br/></td> 
      <td>  • Accept LLM output without reviewing or refining it <br/>  • Expect the LLM to know what you want <br/>  • Perform too many tasks in a single prompt <br/>  • Feed confidential data into a proprietary LLM platform that keeps your data “for future training purposes” <br/>  • Assume that LLM output is fully representative of user data <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p133"> 
   <p>LLMs are great for generating utterance training data when you have a clear problem but no representative user utterances. While we always prefer to use actual user utterances from a production system, we don’t always have that luxury. LLM-generated data helps us fill in the gaps. Their vast training sets likely include some data from your domain (such as customer service), but it may not include all your needs. They’ve seen lots of “password reset” utterances but probably none that include the name of your application. Given a choice between no training data, fabricated training data from subject matter experts, and LLM-generated training data, the LLM-generated option is the best bet.</p> 
  </div> 
  <div class="readable-text" id="p134"> 
   <h3 class=" readable-text-h3"><span class="num-string">7.2.4</span> Creating even more examples with templates</h3> 
  </div> 
  <div class="readable-text" id="p135"> 
   <p>In the previous section, we generated a varied list of utterances by combining multiple different outputs from the LLM and using them to generate new utterances. Figure 7.2 shows an example of mutating full utterances (from listing 7.7) with synonyms seen in listings 7.1 to 7.6.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p136">  
   <img alt="figure" src="../Images/CH07_F02_Freed2.png" width="718" height="291"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 7.2</span> Generating additional examples from the initial LLM output. The LLM generated “My password isn’t working,” but we now know a related utterance is “My login information isn’t working.”</h5>
  </div> 
  <div class="readable-text print-book-callout" id="p137"> 
   <p><span class="print-book-callout-head">TIP</span>  Creating examples from templates is a programmatic task, not specifically a generative AI task. Mixing and matching multiple styles can generate the best results.</p> 
  </div> 
  <div class="readable-text" id="p138"> 
   <p>Using templates is especially helpful when some of the LLM outputs only contain one verb or noun. We were able to introduce variety into our utterance collection with manual changes, but we can take this to the extreme by considering the LLM outputs as templates. Starting with the basic utterance “I forgot my password,” we then explored contextual synonyms for “forgot” and “password.” Figure 7.3 converts this utterance into a template of “I &lt;verb phrase&gt; my &lt;noun phrase&gt;,” which can generate more utterances.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p139">  
   <img alt="figure" src="../Images/CH07_F03_Freed2.png" width="684" height="239"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 7.3</span> Converting “I forgot my password” into a template that lets us replace verbs and nouns in context. One option from this template is “I lost my credentials.”</h5>
  </div> 
  <div class="readable-text" id="p140"> 
   <p>This template generates 36 total utterances due to having six verb choices and six noun choices (6 <span class="regular-symbol">×</span> 6 = 36). This is a lot of data, but it is quite unbalanced—it all uses the exact same grammatical structure. Worse, some of the utterances may not ever be uttered by users. This approach is not suitable for generating training data, since it overweighs the bot toward a single pattern. These templated utterances will hide the influence of other more varied utterances like “Can you help me log in?” “I tried to reset my password, but it didn’t work,” and “account locked out.”</p> 
  </div> 
  <div class="readable-text intended-text" id="p141"> 
   <p>The templated utterances are useful for your testing set if you recognize the imbalance. There is nothing wrong with testing your conversational AI on all 36 utterances as a sanity test. Just don’t limit yourself to testing one template and assuming the intent is well-trained.</p> 
  </div> 
  <div class="readable-text intended-text" id="p142"> 
   <p>A templated approach can be useful for generating testing data that helps ensure the chatbot can tell two intents apart in the face of extraneous information. In addition to our “forgot password” template, let’s assume we have a “store location” template that uses the verbs “need,” “forgot,” and “want” and the nouns “address,” “location,” and “driving directions.” The store location template is like figure 7.3, but it uses “I &lt;verb phrase&gt; your &lt;noun phrase&gt;.” We’ll also assume that some users will greet the bot (“Hi,” “hello,” “good day”) or generically ask for help (“can you help,” “please assist”). These generic additions do not add any differentiating information to the user utterance. Will they somehow affect the chatbot? Figure 7.4 shows how we can set up a test.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p143">  
   <img alt="figure" src="../Images/CH07_F04_Freed2.png" width="900" height="301"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 7.4</span> Using common templates to see whether greetings and closures affect the chatbot’s understanding. One possible utterance is “Hello I lost my credentials please assist.”</h5>
  </div> 
  <div class="readable-text" id="p144"> 
   <p>There are three verb variations and three noun variations in each intent, giving nine (3 <span class="regular-symbol">×</span> 3 = 9) possibilities for each intent. Without considering greetings, we could have run 18 tests (9 per intent). In this test, we have added three greeting variations and two closure variations, allowing us to increase the test size six-fold. The 108 (18 <span class="regular-symbol">×</span> 6 = 108) utterances will include “Hi! I forgot my password. Can you help?” and “Good day. I need your address. Please assist.” and 106 more variations. These can all be included in a test set.</p> 
  </div> 
  <div class="readable-text" id="p145"> 
   <blockquote>
    <div>
     In theory, there is no difference between theory and practice—in practice there is. 
     <div class=" quote-cite">
       Yogi Berra 
     </div>
    </div>
   </blockquote> 
  </div> 
  <div class="readable-text" id="p146"> 
   <p>We do not expect adding the greetings and closure variations to affect the classification, but we can verify this. If your training data is severely unbalanced, the chatbot may be affected by these extra words. Therefore, running this kind of test can be valuable as another sanity test, in addition to the methods shown in chapter 5.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p147"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text buletless-item" id="p148"> Use generative AI to create examples for a “store location” intent. How many nouns, verbs, and grammatical structures can you generate? Track the amount of time you spend on this exercise: 
     <ul> 
      <li> Use a prompt with instructions only. This is a zero-shot prompt. </li> 
      <li> Use a prompt that includes examples. This is a one-shot or few-shot prompt. </li> 
      <li> Did the model generate more varied utterances in less time than when you created utterances manually? </li> 
     </ul></li> 
    <li class="readable-text" id="p149"> Repeat the previous exercise for an intent that is not well understood in a chatbot you are building (or using). If possible, augment the bot’s training or test data sets with some of these new utterances, and measure the change in accuracy. </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p150"> 
   <h2 class=" readable-text-h2"><span class="num-string">7.3</span> Getting more creative</h2> 
  </div> 
  <div class="readable-text" id="p151"> 
   <p>Chapter 5 demonstrated rock-solid data science principles for evaluating and improving your training and testing data. Those principles give you metrics that demonstrate your chatbot’s ability to understand and quantify the effect of the improvements you are trying to make. Those robust principles take time to implement. This section will show you a few creative ways to use an LLM before diving deeper into statistical approaches. These LLM-based techniques do not replace the statistical approaches, but they can give you a quick intuition.</p> 
  </div> 
  <div class="readable-text" id="p152"> 
   <h3 class=" readable-text-h3"><span class="num-string">7.3.1</span> Brainstorm additional intents</h3> 
  </div> 
  <div class="readable-text" id="p153"> 
   <p>The LLM can help you brainstorm new intents your system might need to handle. While we prefer to work from real-world data, such as a backlog of support tickets, a little brainstorming doesn’t hurt. If you are starting a brand-new support process, you may not have any data to work with and need a kickstart. The following listing demonstrates an intent brainstorming process.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p154"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.13</span> Brainstorming new intents</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">You are a consumer contacting an online retailer via  <span class="aframe-location"/> #1
their chat service.  #1

Generate a numbered list of example problems you might <span class="aframe-location"/> #2
have causing you to contact the retailer's chatbot.  #2
#2
List of 5 problems:  #2
1. I want to buy something but I can't find it on your website <span class="aframe-location"/> #3
2. The price has changed  #3
3. My order hasn't arrived  #3
4. I need help with my account  #3
5. I want to return something  #3</pre> 
    <div class="code-annotations-overlay-container">
     #1 Standard background for LLM—still unchanged
     <br/>#2 Instruction and cue
     <br/>#3 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p155"> 
   <p>This looks like a great start. We have product search, price dispute, order tracking, login problems, and returns. These all seem worthy of expanding into intents and process flows in your conversational AI.</p> 
  </div> 
  <div class="readable-text" id="p156"> 
   <h3 class=" readable-text-h3"><span class="num-string">7.3.2</span> Check for confusion</h3> 
  </div> 
  <div class="readable-text" id="p157"> 
   <p>We can also see if the LLM agrees with the intents we have created. We can take the training utterances we have selected and ask the LLM to sort them into intents. Let’s see what happens if we remove the intent name from our “forgot password” intent. </p> 
  </div> 
  <div class="browsable-container listing-container" id="p158"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 7.14</span> Does the LLM predict the same intent (“forgot password”) as we did?</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">Given a list of utterances, predict the intent  <span class="aframe-location"/> #1
classification they belong to. #1

List of utterances <span class="aframe-location"/> #2
1. I can't log in  #2
2. My login information isn't working  #2
3. Forgot password #2
4. Account locked out  #2
5. I can’t remember my account information  #2
6. My account is locked  #2
7. I didn't get my password reset email  #2
8. Need help with resetting account  #2
9. Can you help me log in?  #2
10. I tried to reset my password but it didn't work  #2

Intent Classification: <span class="aframe-location"/> #3
- "I can't log in" -&gt; "Login"<span class="aframe-location"/> #4
- "My login information isn't working" -&gt; "Login" #4
- "Forgot password" -&gt; "Password Reset"  #4
- "Account locked out" -&gt; "Login" #4
- "I can’t remember my account information" -&gt;  #4
 "Login" #4
- "My account is locked" -&gt; "Login"  #4
- "I didn't get my password reset email" -&gt;  #4
"Password Reset"  #4
- "Need help with resetting account" -&gt; "Password Reset"  #4
- "Can you help me log in?" -&gt; "Login"  #4
- "I tried to reset my password but it didn't work" -&gt;  #4
 "Password Reset"  #4</pre> 
    <div class="code-annotations-overlay-container">
     #1 Instruction for LLM
     <br/>#2 Input belonging to the instruction
     <br/>#3 Cue
     <br/>#4 LLM output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p159"> 
   <p>The LLM suggested two intents where we had only used one. The intents “login” and “password reset” are in line with our original “forgot password” label. The LLM-derived intents feel too narrow, especially since both intents are likely to have the same answer.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p160"> 
    <h5 class=" callout-container-h5 readable-text-h5">LLM output format is not always consistent</h5> 
   </div> 
   <div class="readable-text" id="p161"> 
    <p>In listing 7.14, the LLM “invented” an output schema with hyphenated list entry and arrows from utterance to intent. Since we are just reviewing the results visually, this is okay, but additional instructions to the LLM might help (e.g., “respond in a bulleted list”). We could also demonstrate our desired format with a one-shot example.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p162"> 
   <p>This test is not as robust as the other techniques shown in chapter 5, but it can be used as a quick sanity test on your training data. If the LLM does not find any cohesion in your training data, you might have a problem.</p> 
  </div> 
  <div class="readable-text intended-text" id="p163"> 
   <p>LLMs and human builders work well together. Figure 7.5 summarizes the many ways LLMs can help you change your conversational AI to improve its ability to understand your users.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p164">  
   <img alt="figure" src="../Images/CH07_F05_Freed2.png" width="658" height="305"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 7.5</span> An LLM augments the human builder in many ways.</h5>
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p165"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text" id="p166"> Take a chatbot that you are building or using. Describe its purpose. Use that description and a creative LLM prompt to generate example problems that the bot would solve. Use sampling decoding, and run the prompt multiple times to get multiple ideas. Do these line up with the intents or process flows the bot handles? </li> 
    <li class="readable-text" id="p167"> Take a chatbot you are building. Extract a subset of utterances from the test data. Ask an LLM to predict the intent or process flow they belong to. Does the LLM prediction align with how your bot is implemented? </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p168"> 
   <h2 class=" readable-text-h2">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p169"> LLMs are great partners that augment human builders. Humans and LLMs are better together. </li> 
   <li class="readable-text" id="p170"> Experiment with different models, prompts, and parameters to get the best output from LLMs. Keep iterating! Don’t expect your first attempt to be perfect. </li> 
   <li class="readable-text" id="p171"> Don’t just give instructions to an LLM. Provide examples through one-shot or few-shot prompts. </li> 
   <li class="readable-text" id="p172"> When you identify a gap in your data, you can ask an LLM to help you fill it. </li> 
   <li class="readable-text" id="p173"> LLM output can be used directly in your training data, or you can manually refine it first. </li> 
   <li class="readable-text" id="p174"> Use greedy decoding to get the same output every time. Use sampling decoding to get randomized responses with additional creativity. Execute the same prompt multiple times with sampling decoding to get a variety of responses, and use the most helpful output. </li> 
  </ul>
 </div></div></body></html>