["```py\n   Inputs:\n        context  : the content to ask the question about\n        question : question asked specific to the content\n        expected : the expected answer\n\nLLM: Question-Answer (the prompt used to ask the question)\n        inputs:\n               context and question\n        outputs: \n               the prediction/answer to the question\n\n   Embeddings: uses an LLM embedding model to create the embedding \nrepresentation of the text\n\n     Embedding_predicted: embeds the output of the Question-Answer LLM\n     Embedding_expected: embeds the output of the expected answer\n\nPython: Evaluation (Python code to measure embedding similarity)\n     Inputs:\n            Embedding_predicted output\n            Embedding_expected output\n     Outputs: \n            the similarity score between predicted and expected\n\n   Outputs:\n        context: -> input.context\n        question: -> input.question\n     expected: -> input.expected\n     predicted: -> output.question_answer\n     evaluation_score: output.evaluation\n\n### Example Output\n{\n    \"context\": \"Back to the Future (1985)…\",\n    \"evaluation_score\": 0.9567478002354606,\n    \"expected\": \"Marty traveled back in time 30 years.\",\n    \"predicted\": \"Marty traveled back in time 30 years from 1985 to 1955 \nin the movie \\\"Back to the Future.\\\"\",\n    \"question\": \"How far did Marty travel back in time in the movie \nBack to the Future (1985)\"\n}\n```", "```py\nsystem:\nAnswer the users question based on the context below. Keep the answer \nshort and concise. Respond \"Unsure about answer\" if not sure about the \nanswer.\n\nContext: {{context}}     #1\n\nuser:\nQuestion: {{question}}     #2\n```", "```py\nInputs:\n       statement  : introduces the context and then asks for output\n       expected : the expected answer to the statement\n LLM: few_shot (the prompt used to ask the question)\n       inputs:statement\n       outputs: the prediction/answer to the statement\n\nEmbeddings: uses an LLM embedding model to create the embedding \nrepresentation of the text\n\n        Embedding_predicted: embeds the output of the few_shot LLM\n        Embedding_expected: embeds the output of the expected answer\n\n   Python: Evaluation (Python code to measure embedding similarity)\n        Inputs:\n               Embedding_predicted output\n               Embedding_expected output\n        Outputs: the similarity score between predicted and expected\n\nOutputs:\n        statement: -> input.statement\n        expected: -> input.expected\n        predicted: -> output.few_shot\n        evaluation_score: output.evaluation\n\n### Example Output\n{\n    \"evaluation_score\": 0.906647282920417,     #1\n    \"expected\": \"We ate sunner and watched the setting sun.\",\n    \"predicted\": \"After a long hike, we sat by the lake \nand enjoyed a peaceful sunner as the sky turned \nbrilliant shades of orange and pink.\",     #2\n    \"statement\": \"A sunner is a meal we eat in Cananda \nat sunset, please use the word in a sentence\"     #3\n}\n```", "```py\nsystem:\nYou are an eccentric word dictionary maker. You will be asked to \n\nconstruct a sentence using the word.\nThe following are examples that demonstrate how to craft a sentence using \nthe word.\nA \"whatpu\" is a small, furry animal native to Tanzania. \nAn example of a sentence that uses the word whatpu is:     #1\nWe were traveling in Africa and we saw these very cute whatpus.\nTo do a \"farduddle\" means to jump up and down really fast. An example of a \nsentence that uses the word farduddle is:\nI was so excited that I started to farduddle.     #2\n\nPlease only return the sentence requested by the user.   #3\n\nuser:\n{{statement}}    #4\n```", "```py\nInputs:\n        statement  : the statement to be classified\n        expected : the expected classification of the statement\n\n    LLM: zero_shot (the prompt used to classify)\n        inputs: statement\n        outputs: the predicted class given the statement\n\n    Embeddings: uses an LLM embedding model to create the embedding \nrepresentation of the text\n\n    Embedding_predicted: embeds the output of the zero_shot LLM\n    Embedding_expected: embeds the output of the expected answer\n\n    Python: Evaluation (Python code to measure embedding similarity)\n        Inputs:\n               Embedding_predicted output\n             Embedding_expected output\n          Outputs: the similarity score between predicted and expected\n\n   Outputs:\n        statement: -> input.statement\n        expected: -> input.expected\n        predicted: -> output.few_shot\n        evaluation_score: output.evaluation\n\n   ### Example Output\n{\n       \"evaluation_score\": 1,     #1\n       \"expected\": \"neutral\",\n       \"predicted\": \"neutral\",\n       \"statement\": \"I think the vacation is okay. \"     #2\n   }\n```", "```py\nsystem:\nClassify the text into neutral, negative or positive. \nReturn on the result and nothing else.     #1\n\nuser:\n{{statement}}     #2\n```", "```py\n   Inputs:\n        statement  : the statement problem to be solved\n        expected : the expected solution to the problem\n\n LLM: cot (the prompt used to solve the problem)\n        inputs: statement\n        outputs: the predicted answer given the problem statement\n\nLLM: evaluate_answer (the prompt used to evaluate the solution)\n        inputs:\n               statement: -> input.statement\n               expected: -> input.expected\n               predicted: -> output.cot\n\n        outputs: a score of how well the problem was answered\n\n   Outputs:\n        statement: -> input.statement\n        expected: -> input.expected\n        predicted: -> output.cot\n        evaluation_score: output.evaluate_answer\n\n   ### Example Output\n{\n    \"evaluation_score\": \"0.5\",     #1\n    \"expected\": \"After the final jump, Max finds himself \nin the year 1980 and he is 75 years old.\",     #2\n    \"predicted\": \" Max starts in the year 2300 and \ntravels backward in 40-year increments, spending 5 years \nin each period. The journeys will be as follows:\n\\n\\n- From 2300 to 2260: Max is 25 + 5 = 30 years old.\n\\n- From 2260 to 2220: Max is 30 + 5 = 35 years old.\n\\n- From 2220 to 2180: Max is 35 + 5 = 40 years old.\n\\n- From 2180 to 2140: Max is 40 + 5 = 45 years old.\n\\n- From 2140 to 2100: Max is 45 + 5 = 50 years old.\n\\n- From 2100 to 2060: Max is 50 + 5 = 55 years old.\n\\n- From 2060 to 2020: Max is 55 + 5 = 60 years old.\n\\n- From 2020 to 1980: Max is 60 + 5 = 65 years old.\n\\n- From 1980 to 1940: Max is 65 + 5 = 70 years old.\n\\n- From 1940 to 1900: Max is 70 + 5\"     #3\n}\n```", "```py\nsystem:\n\"In a time travel movie, Sarah travels back in time to \nprevent a historic event from happening. She arrives \n2 days before the event. After spending a day preparing, \nshe attempts to change the event but realizes she has \nactually arrived 2 years early, not 2 days. She then \ndecides to wait and live in the past until the event's \noriginal date. How many days does Sarah spend in the past \nbefore the day of the event?\"     #1\n\nChain of Thought:     #2\n\n    Initial Assumption: Sarah thinks she has arrived 2 days before the event.\n    Time Spent on Preparation: 1 day spent preparing.\n    Realization of Error: Sarah realizes she's actually 2 years early.\n    Conversion of Years to Days: \n2 years = 2 × 365 = 730 days (assuming non-leap years).\n    Adjust for the Day Spent Preparing: 730 - 1 = 729 days.\n    Conclusion: Sarah spends 729 days in the past before the day of the event.\n\n\"In a sci-fi film, Alex is a time traveler who decides \nto go back in time to witness a famous historical battle \nthat took place 100 years ago, which lasted for 10 days. \nHe arrives three days before the battle starts. However, \nafter spending six days in the past, he jumps forward in \ntime by 50 years and stays there for 20 days. Then, he \ntravels back to witness the end of the battle. How many \ndays does Alex spend in the past before he sees the end of\n the battle?\"     #3\n\nChain of Thought:     #4\n\n    Initial Travel: Alex arrives three days before the battle starts.\n    Time Spent Before Time Jump: Alex spends six days in the past. \nThe battle has started and has been going on for 3 days (since he \narrived 3 days early and has now spent 6 days, 3 + 3 = 6).\n    First Time Jump: Alex jumps 50 years forward and stays for 20 days.\n This adds 20 days to the 6 days he's already spent in the past \n(6 + 20 = 26).\n    Return to the Battle: When Alex returns, he arrives back on the same \nday he left (as per time travel logic). The battle has been going on for \n3 days now.\n    Waiting for the Battle to End: The battle lasts 10 days. Since he's \nalready witnessed 3 days of it, he needs to wait for 7 more days.\n    Conclusion: Alex spends a total of 3 (initial wait) + 3 (before the \nfirst jump) + 20 (50 years ago) + 7 (after returning) = 33 days in the \npast before he sees the end of the battle.\nThink step by step but only show the final answer to the statement.\n\nuser:\n{{statement}}     #5\n```", "```py\nsystem:\n\nPlease confirm that expected and predicted results are \nthe same for the given problem.     #1\nReturn a score from 0 to 1 where 1 is a perfect match and 0 is no match.\nPlease just return the score and not the explanation.     #2\n\nuser:\nProblem: {{problem}}     #3\n\nExpected result: {{expected}}     #4\n\nPredicted result: {{predicted}}     #5\n```", "```py\n   Inputs:\n        statement  : the statement problem to be solved\n        expected : the expected solution to the problem\n\nLLM: cot (the prompt used to solve the problem)\n        inputs: statement\n        outputs: the predicted answer given the problem statement\n\nLLM: evaluate_answer (the prompt used to evaluate the solution)\n        inputs:\n               statement: -> input.statement\n               expected: -> input.expected\n               predicted: -> output.cot\n\n         outputs: a score of how well the problem was answered\n\n    Outputs:\n        statement: -> input.statement\n        expected: -> input.expected\n        predicted: -> output.cot\n        evaluation_score: output.evaluate_answer\n\n    ### Example Output\n   {\n       \"evaluation_score\": \"1\",     #1\n       \"expected\": \"After the final jump, ↪\n          ↪ Max finds himself in the year 1980 and \n   he is 75 years old.\",     #2\n       \"predicted\": \"Max starts in… ↪\n          ↪ Therefore, after the final jump, ↪\n          ↪ Max is 75 years old and in the year 1980.\",     #3\n       \"statement\": \"In a complex time travel …\"     #4\n   }\n```", "```py\nsystem:\nYou are an expert in solving time travel problems.\nYou are given a time travel problem and you have to solve it.\nLet's think step by step.     #1\nPlease finalize your answer in a single statement.     #2\n\nuser:\n{{statement}}     #3\n```", "```py\n   Inputs:\n        statement  : the statement problem to be solved\n\n   LLM: decompose_steps (the prompt used to decompose the problem)\n        inputs: \n               statement: -> input.statement     #1\n\n        outputs: the breakdown of steps to solve the problem\n\n   LLM: calculate_steps (the prompt used to calculate the steps)\n        inputs:\n               statement: -> input.statement\n               decompose_steps: -> output.decompose_steps     #2\n\n               outputs: the calculation for each step\n   LLM: calculate_solution (attempts to solve the problem)\n        inputs:\n               statement: -> input.statement\n               decompose_steps: -> output.decompose_steps\n               calculate_steps: -> output.calculate_steps     #3\n\n         outputs: the final solution statement\n\n   Outputs:\n        statement: -> input.statement\n        decompose_steps: -> output.decompose_steps\n        calculate_steps: -> output.calculate_steps\n        calculate_solution: -> output.calculate_solution\n\n   ### Example Output\n{\n    \"calculate_steps\": \"1\\. The days spent by Alex\",\n    \"decompose_steps\": \"To figure out the …\",\n    \"solution\": \"Alex spends 13 days in the ↪\n           ↪ past before the end of the battle.\",     #4\n    \"statement\": \"In a sci-fi film, Alex …\"    \n}\n```", "```py\nsystem:\nYou are a problem solving AI assistant.\nYour job is to break the users problem down into smaller steps and list \nthe steps in the order you would solve them.\nThink step by step, not in generalities.\nDo not attempt to solve the problem, just list the steps. #1\n\nuser:\n{{statement}}     #2\n```", "```py\nsystem:\nYou are a problem solving AI assistant.\nYou will be given a list of steps that solve a problem.\nYour job is to calculate the output for each of the steps in order.\nDo not attempt to solve the whole problem,\njust list output for each of the steps.     #1\nThink step by step.     #2\n\nuser:\n{{statement}}\n\n{{steps}}     #3\n```", "```py\nsystem:\nYou are a problem solving AI assistant.\nYou will be given a list of steps and the calculated output for each step.\nUse the calculated output from each step to determine the final \nsolution to the problem.\nProvide only the final solution to the problem in a \nsingle concise sentence. Do not include any steps \nin your answer.     #1\n\nuser:\n{{statement}}\n\n{{steps}}     #2\n\n{{calculated}}     #3\n```", "```py\nsystem:\n\n\"In a time travel movie, Sarah travels back… \"     #1\n\nChain of Thought:\n\n    Initial Assumption: …     #2\n    Conclusion: Sarah spends 729 days in the past before the day of the event.\n\n\"In a complex time travel movie plot, Max, a 25 year old…\"     #3\n\nChain of Thought:\n    Starting Point: Max starts …     #4\n    Conclusion: After the final jump, \nMax finds himself in the year 1980 and he is 75 years old.\nThink step by step,\n but only show the final answer to the statement.     #5\n\nuser:\n{{statement}}\n```", "```py\n{\n    \"name\": \"self-consistency-prompting_default_20240203_100322_912000\",\n    \"created_on\": \"2024-02-03T10:22:30.028558\",\n    \"status\": \"Completed\",\n    \"display_name\": \"self-consistency-prompting_variant_0_202402031022\",\n    \"description\": null,\n    \"tags\": null,\n    \"properties\": {\n        \"flow_path\": \"…prompt_flow/self-consistency-prompting\",     #1\n        **\"output_path\"**: \"…/.promptflow/.runs/self-\n↪ consistency-prompting_default_20240203_100322_912000\",     #2\n        \"system_metrics\": {\n            \"total_tokens\": 4649,\n            \"prompt_tokens\": 3635,\n            \"completion_tokens\": 1014,\n            \"duration\": 30.033773\n        }\n    },\n    \"flow_name\": \"self-consistency-prompting\",\n    \"data\": \"…/prompt_flow/self-consistency-prompting/\n↪ statements.jsonl\",     #3\n    \"output\": \"…/.promptflow/.runs/self-consistency-↪\n↪ prompting_default_20240203_100322_912000/flow_outputs\"\n}\n```", "```py\nfrom promptflow import tool\nfrom typing import List\nimport numpy as np\nfrom scipy.spatial.distance import cosine\n@tool\ndef consistency(texts: List[str],\n                embeddings: List[List[float]]) -> str:\n    if len(embeddings) != len(texts):\n        raise ValueError(\"The number of embeddings ↪\n       ↪ must match the number of texts.\")\n\n    mean_embedding = np.mean(embeddings, axis=0)     #1\n    similarities = [1 - cosine(embedding, mean_embedding) ↪\n                ↪ for embedding in embeddings]     #2\n    most_similar_index = np.argmax(similarities)     #3\n\n    from promptflow import log_metric\n    log_metric(key=\"highest_ranked_output\", value=texts[most_similar_index])     #4\n\n    return texts[most_similar_index]     #5\n```", "```py\n@tool\ndef my_python_tool(\n    input: str,\n    input_node: int,\n    history: str,\n    semantic_function: str,\n    evaluation_function: str,\n    function_name: str,\n    skill_name: str,\n    max_tokens: int,\n    temperature: float,\n    deployment_name: str,\n    connection: Union[OpenAIConnection, \n                      AzureOpenAIConnection],     #1\n) -> str:\n    if input is None or input == \"\":     #2\n        return \"\"\n\n    kernel = sk.Kernel(log=sk.NullLogger())\n    # code for setting up the kernel and LLM connection omitted\n\n    function = kernel.create_semantic_function(\n                             semantic_function,                                               \n                             function_name=function_name,\n                             skill_name=skill_name,\n                             max_tokens=max_tokens,\n                             temperature=temperature,\n                             top_p=0.5)     #3\n    evaluation = kernel.create_semantic_function(\n                             evaluation_function,        \n                             function_name=\"Evaluation\",\n                             skill_name=skill_name,\n                             max_tokens=max_tokens,\n                             temperature=temperature,\n                             top_p=0.5)     #4\n\n    async def main():\n        query = f\"{history}\\n{input}\"\n        try:\n            eval = int((await evaluation.invoke_async(query)).result)\n            if eval > 25:     #5\n                return await function.invoke_async(query)    #6\n        except Exception as e:\n            raise Exception(\"Evaluation failed\", e)\n\n       try:\n        result = asyncio.run(main()).result\n        return result\n    except Exception as e:\n        print(e)\n        return \"\"\n```", "```py\n{\n    \"answer_1_1\": \"\",     #1\n    \"answer_1_2\": \"\",\n    \"answer_1_3\": \"\",\n    \"answer_2_1\": \"Alex spends a total of 29 days in the past before he \nsees the end of the battle.\",\n    \"answer_2_2\": \"\",     #2\n    \"answer_2_3\": \"Alex spends a total of 29 days in the past before he \nsees the end of the battle.\",\n    \"answer_3_1\": \"\",     #3\n    \"answer_3_2\": \"Alex spends a total of 29 days in the past before he \nsees the end of the battle.\",\n    \"answer_3_3\": \"Alex spends a total of 9 days in the past before he \nsees the end of the battle.\",\n```"]