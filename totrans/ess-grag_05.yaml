- en: 6 Constructing knowledge graphs with LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 使用LLM构建知识图谱
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Structured data extraction
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化数据提取
- en: Different approaches to extraction
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取的不同方法
- en: In this chapter, you will explore the process of constructing knowledge graphs
    using LLMs from unstructured sources like text documents. The focus will be on
    how LLMs can extract and structure data from raw text, transforming it into usable
    formats for building knowledge graphs.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将探索使用LLM从非结构化来源，如文本文档，构建知识图谱的过程。重点将放在LLM如何从原始文本中提取和结构化数据，将其转换为构建知识图谱的可使用格式。
- en: In previous chapters, you learned about basic techniques for document chunking,
    embedding, and retrieval (chapter 2), as well as more advanced methods for improving
    retrieval accuracy (chapter 3). However, as you learned in chapter 4, relying
    solely on text embeddings can lead to challenges in scenarios where data needs
    to be structured to answer questions that require filtering, counting, or aggregation
    operations. To solve the limitations of only using text embeddings, you will learn
    how to transform unstructured data into structured formats suitable for knowledge
    graph construction, using LLMs for automated data extraction. By the end of the
    chapter, you will be able to extract structured information from raw text, design
    a knowledge graph model for the extracted data, and import this data into a graph
    database.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，您学习了文档块分割、嵌入和检索的基本技术（第2章），以及提高检索准确性的更高级方法（第3章）。然而，正如您在第4章中学到的，在需要将数据进行结构化以回答需要过滤、计数或聚合操作的问题的情况下，仅依赖文本嵌入会导致挑战。为了解决仅使用文本嵌入的局限性，您将学习如何使用LLM将非结构化数据转换为适合知识图谱构建的结构化格式，进行自动数据提取。到本章结束时，您将能够从原始文本中提取结构化信息，为提取的数据设计知识图谱模型，并将这些数据导入图数据库。
- en: You’ll begin by exploring a common challenge in legal document retrieval---managing
    multiple contracts and their terms---and learn how structured data extraction
    provides a solution. Throughout the chapter, you’ll follow examples that illustrate
    the process and guide you step by step through the workflow of constructing a
    knowledge graph from unstructured text.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 您将从探索法律文件检索中一个常见的挑战——管理多个合同及其条款——开始，并了解结构化数据提取如何提供解决方案。在整个章节中，您将跟随示例，说明这个过程，并逐步引导您通过从非结构化文本构建知识图谱的工作流程。
- en: 6.1 Extracting structured data from text
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 从文本中提取结构化数据
- en: Much of the information found online, and even within companies, exists in unstructured
    formats like various documents. However, there are situations where the simple
    retrieval technique using only text embeddings falls short. Legal documents are
    one such example.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在线找到的大部分信息，甚至在公司内部，都存在于各种文档等非结构化格式中。然而，在某些情况下，仅使用文本嵌入的简单检索技术不足以解决问题。法律文件就是一个例子。
- en: For instance, if you’re asking about the payment terms in a contract with ACME
    Inc., it’s crucial to ensure that the terms are actually from that specific contract
    and not from others. When you simply chunk and retrieve across multiple legal
    documents, the top `k` chunks you get at retrieval could come from different,
    unrelated documents, causing confusion, as shown in figure 6.1.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您在询问与ACME公司签订的合同中的付款条款，确保条款确实来自该特定合同，而不是其他合同，是至关重要的。当您简单地跨多个法律文件进行块分割和检索时，检索到的最上面的`k`个块可能来自不同的、无关的文档，导致混淆，如图6.1所示。
- en: '![figure](../Images/6-1.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-1.png)'
- en: Figure 6.1 Basic vector retrieval strategy might return chunks from various
    contracts.
  id: totrans-11
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.1 基本的向量检索策略可能会从各种合同中返回块。
- en: Figure 6.1 illustrates how contract documents are broken down into text chunks
    and indexed using text embeddings. When an end user asks a specific question,
    such as about the payment terms of a particular contract, the system retrieves
    the most relevant chunks. However, if multiple contracts contain different payment
    terms, the retrieval process may unintentionally pull information from various
    documents, mixing relevant chunks from the target contract with irrelevant ones
    from others. This happens because the system focuses on retrieving top-ranked
    text chunks based on similarity, without always distinguishing whether the chunks
    come from the correct contract. As a result, chunks that share keywords like “payment”
    or “terms” but belong to different contracts may be included, leading to a fragmented
    and inconsistent view of the terms. This confusion can then be responsible when
    the LLM tries to synthesize these mixed chunks into a coherent answer, ultimately
    increasing the risk of inaccurate or misleading information.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1说明了合同文档是如何被分解成文本块并使用文本嵌入进行索引的。当最终用户提出特定问题，例如关于某个特定合同的付款条款时，系统会检索最相关的文本块。然而，如果多个合同包含不同的付款条款，检索过程可能会无意中从多个文档中提取信息，将目标合同的有关部分与来自其他合同的无关部分混合。这是因为系统专注于根据相似性检索排名最高的文本块，而并不总是区分这些块是否来自正确的合同。结果，包含“付款”或“条款”等关键词但属于不同合同的块可能会被包括在内，导致对条款的碎片化和不一致的看法。当LLM试图将这些混合块综合成一个连贯的答案时，这种混淆可能会产生，最终增加不准确或误导性信息的风险。
- en: 'Additionally, consider the following question: How many active contracts do
    we currently have with ACME Inc.? To answer this, you would first need to filter
    all contracts based on their active status and then count the relevant ones. These
    types of queries resemble traditional business intelligence questions, where the
    text-embedding approach falls short.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，考虑以下问题：我们目前与ACME公司有多少活跃合同？要回答这个问题，你首先需要根据合同的有效状态过滤所有合同，然后计算相关合同的数量。这类查询类似于传统的商业智能问题，而文本嵌入方法在这些方面存在不足。
- en: Text embeddings are primarily designed to retrieve semantically similar content,
    not to handle operations like filtering, sorting, or aggregating data. To handle
    such operations, structured data is required, as text embeddings alone are not
    well-suited for these operations.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 文本嵌入主要是为了检索语义相似的内容，而不是处理过滤、排序或聚合数据等操作。要处理这些操作，需要结构化数据，因为仅凭文本嵌入本身并不适合这些操作。
- en: For some domains, structuring data is vital when implementing RAG applications.
    Luckily, LLMs excel at extracting structured data from text due to their deep
    understanding of natural language, allowing them to identify relevant information
    accurately. They can be finetuned or guided through specific prompts to locate
    and extract required data points, converting unstructured information into a structured
    format like tables or key–value pairs. Using LLMs for structured data extraction
    is particularly useful when dealing with large volumes of documents where manually
    identifying and organizing such information would be labor intensive and time
    consuming. By automating the extraction process, LLMs enable businesses to transform
    unstructured information into actionable, structured data, which can then be used
    for further analysis or RAG applications.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些领域，在实施RAG应用时，对数据进行结构化至关重要。幸运的是，由于LLMs对自然语言的深入理解，它们在从文本中提取结构化数据方面表现出色，这使得它们能够准确识别相关信息。它们可以通过特定的提示进行微调或引导，以定位和提取所需的数据点，将非结构化信息转换为表格或键值对等结构化格式。使用LLMs进行结构化数据提取在处理大量文档时尤其有用，因为手动识别和组织此类信息将非常耗时且劳动密集。通过自动化提取过程，LLMs使企业能够将非结构化信息转换为可操作的、结构化数据，这些数据可以用于进一步分析或RAG应用。
- en: 'Imagine you’re working at a company as a software engineer, and you’re part
    of a team tasked with building a chatbot that can answer questions based on the
    company’s legal documents. Since this is a large-scale project, the team is divided
    into two groups: one focused on data preparation and the other on implementing
    the retrieval systems described in chapters 4 and 5\. You’re assigned to the data
    preparation team, where your job is to process legal documents and extract structured
    information. This information will be used to build a knowledge graph, following
    the workflow visualized in figure 6.2.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您在一家公司作为软件工程师工作，并且您是负责构建一个能够根据公司法律文件回答问题的聊天机器人的团队的一员。由于这是一个大规模项目，团队被分为两组：一组专注于数据准备，另一组负责实施第4章和第5章中描述的检索系统。您被分配到数据准备团队，您的任务是处理法律文件并提取结构化信息。这些信息将被用于构建知识图谱，遵循图6.2中可视化的工作流程。
- en: '![figure](../Images/6-2.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/6-2.png)'
- en: Figure 6.2 Building knowledge graphs from text by using LLMs to extract structured
    data information
  id: totrans-18
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.2 使用LLM提取结构化数据信息构建知识图谱
- en: The workflow visualized in figure 6.2 begins with contract documents as input,
    which are processed using an LLM to extract structured information. In the legal
    domain, you can extract various details such as involved parties, dates, terms,
    and more. Here, the structured output is represented in a JSON format, and this
    structured information is then stored in Neo4j, which will serve as the foundation
    for the legal chatbot’s data retrieval.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2中可视化的工作流程从合同文档作为输入开始，使用LLM进行处理以提取结构化信息。在法律领域，您可以提取各种细节，例如涉及方、日期、条款等。在这里，结构化输出以JSON格式表示，然后这些结构化信息被存储在Neo4j中，它将作为法律聊天机器人数据检索的基础。
- en: 'These two examples highlight the limitations of simple text embeddings when
    it comes to handling specific, structured queries, such as asking for payment
    terms in a contract or counting active agreements. In both cases, accurate answers
    require structured data rather than relying solely on the semantic similarity
    of unstructured text. In the remainder of this chapter, we’ll dive deeper into
    how LLMs can be effectively used to extract structured data from complex documents
    and how this structured output plays a critical role in constructing reliable
    knowledge graphs for advanced retrieval tasks. To follow along, you’ll need access
    to a running, blank Neo4j instance. This can be a local installation or a cloud-hosted
    instance; just make sure it’s empty. You can follow the implementation directly
    in the accompanying Jupyter notebook available here: [https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch06.ipynb](https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch06.ipynb).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个示例突出了简单文本嵌入在处理特定、结构化查询时的局限性，例如在合同中询问付款条款或计算活跃协议。在这两种情况下，准确的答案需要结构化数据，而不是仅仅依赖于非结构化文本的语义相似性。在本章的剩余部分，我们将更深入地探讨如何有效地使用LLM从复杂文档中提取结构化数据，以及这种结构化输出在构建用于高级检索任务的可信知识图谱中的关键作用。为了跟上进度，您需要访问一个运行中的空白Neo4j实例。这可以是一个本地安装或云托管实例；只需确保它是空的。您可以直接在以下提供的Jupyter笔记本中查看实现：[https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch06.ipynb](https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch06.ipynb)。
- en: Let’s dive in.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨。
- en: 6.1.1 Structured Outputs model definition
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.1 结构化输出模型定义
- en: Extracting structured data from text is not a new idea; it has been a vital
    task in data processing for many years. Historically, this process was known as
    *information extraction* and required complex systems, often relying on multiple
    machine learning models working together. These systems were typically expensive
    to build and maintain, requiring a team of skilled engineers and domain experts
    to ensure they functioned correctly. Due to these reasons, only large organizations
    with substantial resources could afford to implement such solutions. The high
    cost and technical barriers made it inaccessible for many businesses and individuals.
    However, advancements in LLMs have dramatically simplified the process. Today,
    users can prompt an LLM to extract structured information with a much lower technical
    threshold instead of building and training multiple models. This shift has opened
    up a wide range of use cases for structured data extraction.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从文本中提取结构化数据不是一个新想法；这多年来一直是数据处理中的一个关键任务。历史上，这个过程被称为*信息提取*，需要复杂的系统，通常依赖于多个机器学习模型协同工作。这些系统通常成本高昂且难以维护，需要一支由熟练工程师和领域专家组成的团队来确保它们正确运行。由于这些原因，只有拥有大量资源的组织才能负担得起实施此类解决方案。高昂的成本和技术壁垒使得许多企业和个人无法接触。然而，LLMs的进步极大地简化了这一过程。如今，用户可以提示LLM提取结构化信息，而无需构建和训练多个模型，技术门槛大大降低。这种转变为结构化数据提取打开了广泛的应用场景。
- en: Extracting structured data using LLMs has become such a common use case that
    OpenAI introduced a Structured Outputs feature in its API to simplify and standardize
    the process. This feature allows developers to define the expected output format
    ahead of time, ensuring that the model’s response adheres to a specific structure.
    Structured Outputs is not a separate library; it is a built-in capability of the
    OpenAI API, available through function calling or schema definitions. For example,
    in Python, developers often use libraries like Pydantic to define data schemas.
    These schemas can then be passed to the model, guiding it to produce outputs that
    match the specified format, as shown in the following listing.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLMs提取结构化数据已成为如此常见的用例，以至于OpenAI在其API中引入了结构化输出功能，以简化并标准化这一过程。此功能允许开发者在事先定义期望的输出格式，确保模型的响应符合特定的结构。结构化输出不是一个单独的库；它是OpenAI
    API的内置功能，可以通过函数调用或模式定义来访问。例如，在Python中，开发者通常使用Pydantic等库来定义数据模式。然后，这些模式可以传递给模型，指导它产生符合指定格式的输出，如下面的列表所示。
- en: Listing 6.1 Defining the desired output using the Pydantic library
  id: totrans-25
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.1 使用Pydantic库定义期望的输出
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `CalendarEvent` class in listing 6.1 represents a structured way to capture
    details about an event. It includes a name for the event, a date when it will
    occur, and a list of participants. By defining these attributes explicitly, it
    ensures that any event data conforms to this structure, making it easier to extract
    and work with event information in a reliable and consistent manner. The available
    types for attributes are
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.1中的`CalendarEvent`类代表了一种结构化的方式来捕捉关于事件的信息。它包括事件名称、事件发生的日期以及参与者列表。通过明确定义这些属性，它确保任何事件数据都符合这种结构，使得以可靠和一致的方式提取和处理事件信息变得更加容易。属性可用的类型有
- en: String
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串
- en: Number
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数字
- en: Boolean
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布尔
- en: Integer
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整数
- en: Object
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象
- en: Array
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数组
- en: Enum
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 枚举
- en: anyOf
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: anyOf
- en: Let’s examine the definition of the `date` attribute.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考察一下`date`属性的定义。
- en: Listing 6.2 `date` attribute
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.2 `date`属性
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The code in listing 6.2 provides instructions on how to extract data for the
    `date` attribute. Naming the attribute `date` signals to the model to focus on
    date-related information. By using the `str` type, we specify that the extracted
    information should be represented as a string, as there’s no native datetime type
    available. Additionally, the `description` clarifies the desired `yyyy-MM-dd`
    format. This step is crucial because, although the model knows it’s dealing with
    a string, the description ensures that the date follows the specific format. Without
    this guidance, the `str` type alone might not convey enough detail about the expected
    output structure.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.2中的代码提供了如何提取`date`属性数据的说明。将属性命名为`date`向模型发出信号，使其关注与日期相关的信息。通过使用`str`类型，我们指定提取的信息应以字符串形式表示，因为没有可用的本地日期时间类型。此外，`description`说明了期望的`yyyy-MM-dd`格式。这一步至关重要，因为尽管模型知道它正在处理字符串，但描述确保日期遵循特定的格式。没有这种指导，仅`str`类型可能不足以传达预期的输出结构。
- en: Structured Outputs significantly simplifies the development process by ensuring
    that the LLM responses adhere to a predefined schema. This reduces the need for
    post-processing and validation, allowing developers to focus on using the data
    within their systems. The feature provides type safety, guaranteeing that responses
    are always correctly formatted, and eliminates the need for complex prompts to
    achieve consistent output, making the process more efficient and reliable overall.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化输出通过确保LLM的响应遵循预定义的架构，显著简化了开发过程。这减少了后处理和验证的需求，使得开发者能够专注于在系统中使用数据。该功能提供了类型安全，确保响应始终正确格式化，并消除了实现一致输出的复杂提示需求，使整个过程更加高效和可靠。
- en: The first step in extracting structured output from legal documents is to define
    the contract data model that needs to be extracted. Since you’re a software engineer
    and not a legal expert, it’s important to consult someone with domain knowledge
    to determine which information is most important to extract. Additionally, speaking
    with end users about the specific questions they want answered can provide valuable
    insights.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 从法律文件中提取结构化输出的第一步是定义需要提取的合同数据模型。由于你不是法律专家，而是软件工程师，因此咨询具有领域知识的人来确定哪些信息最重要是重要的。此外，与最终用户交谈，了解他们想要回答的具体问题，可以提供宝贵的见解。
- en: Following these initial discussions, you propose the contract data model shown
    in the following listing.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些初步讨论之后，你提出了以下列表所示的合同数据模型。
- en: Listing 6.3 Defining the desired output using a Pydantic object
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.3 使用Pydantic对象定义期望的输出
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#1 Description of the extracted object'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 提取对象的描述'
- en: '#2 Using enum to define the possible values an LLM can use'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用enum定义LLM可以使用的可能值'
- en: '#3 An attribute can be an object like the Organization in this example.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 在本例中，属性可以是对象，如组织。'
- en: '#4 Since the datetime type isn’t available, you want to define the date format
    to be extracted.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 由于datetime类型不可用，你需要定义要提取的日期格式。'
- en: '#5 You can use Optional for attributes that might not appear in all contracts.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 你可以使用Optional来定义可能不在所有合同中出现的属性。'
- en: The class name, `Contract`, along with the concise docstring, “Represents the
    key details of the contract,” provide the LLM with a high-level understanding
    that the desired output should capture essential contractual information. This
    guides the model to focus on extracting and organizing key details, such as the
    contract type, involved parties, dates, and financials.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 类名`Contract`以及简洁的文档字符串“表示合同的详细信息”，为LLM提供了高级理解，即期望的输出应捕获关键合同信息。这指导模型专注于提取和组织关键细节，例如合同类型、相关方、日期和财务信息。
- en: In general, attributes can be categorized as either mandatory or optional. When
    an attribute is optional, you designate it with an `Optional` type, indicating
    to the LLM that the information may or may not be present. It’s vital to mark
    attributes as optional when information could be missing, as otherwise, some LLMs
    may hallucinate values in an attempt to fill the gaps. For instance, `total_amount`
    is optional since some contracts are simply agreements with no monetary exchange.
    Conversely, the `effective_date` attribute is mandatory, as you expect each contract
    to have a starting date.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，属性可以分为强制性和可选性。当一个属性是可选的时，你用`Optional`类型来指定，这表示LLM该信息可能存在也可能不存在。当信息可能缺失时，标记属性为可选是至关重要的，否则，一些LLM可能会尝试填充空白而虚构值。例如，`total_amount`是可选的，因为一些合同仅仅是无货币交换的协议。相反，`effective_date`属性是强制性的，因为你期望每个合同都有一个起始日期。
- en: Notice how each attribute includes a `description` value to provide clear guidance
    to the LLM, ensuring it extracts the desired information accurately. This is a
    good practice, even when some attributes seem obvious. In some cases, you may
    also want to specify the allowed values for a particular attribute. You can achieve
    this by using the `enum` parameter. For example, the `contract_type` attribute
    utilizes the `enum` parameter to inform the LLM of the specific categories to
    apply. The following listing contains the available values for the `contract_type`
    parameter.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，每个属性都包含一个`description`值，以向LLM提供清晰的指导，确保它准确提取所需信息。即使某些属性看似明显，这也是一个好习惯。在某些情况下，你可能还希望指定特定属性的允许值。你可以通过使用`enum`参数来实现这一点。例如，`contract_type`属性使用`enum`参数来告知LLM应用的具体类别。以下列表包含了`contract_type`参数的可用值。
- en: Listing 6.4 Contract type enum values
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.4 合同类型枚举值
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Clearly, the list in listing 6.4 is not exhaustive, as there are additional
    options that could be included.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，列表6.4并不详尽，因为还有其他选项可以包含在内。
- en: Some attributes may be more complex and can be defined as custom objects. For
    instance, the `parties` attribute is a list of `Organization` objects. A list
    is used because contracts typically involve multiple parties, and a custom object
    allows for extracting more than just a simple string about a specific attribute.
    The code in the following listing defines the `Organization` object.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一些属性可能更复杂，可以定义为自定义对象。例如，`parties`属性是一个`Organization`对象的列表。使用列表是因为合同通常涉及多个当事人，而自定义对象允许提取比特定属性简单的字符串更多的信息。以下列表中的代码定义了`Organization`对象。
- en: Listing 6.5 Custom `Organization` object
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.5 自定义`Organization`对象
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#1 You can provide possible values in the description instead of enum if you
    aren’t providing all possible values but only examples.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 如果您没有提供所有可能的值，而是只提供示例，您可以在描述中提供可能的值而不是枚举。'
- en: The `Organization` object in listing 6.5 captures the key details of an organization
    involved in the contract, including its name, primary location, and role. The
    `location` attribute is a nested `Location` object, allowing us to structure the
    information into values like city, state, and country. As you can see, we can
    have nested objects, but the typical advice is to avoid too many levels of nested
    objects for better performance. For the `role` attribute, we’ve provided examples
    like “provider” and “client” but opted not to use an enum to avoid restricting
    the values. This flexibility is important, as the exact roles may vary and aren’t
    entirely predictable. By defining the organization this way, the LLM is guided
    to extract more detailed and structured information about the parties involved.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.5中的`Organization`对象捕捉了参与合同的组织的关键细节，包括其名称、主要位置和角色。`location`属性是一个嵌套的`Location`对象，允许我们将信息结构化到城市、州和国家等值。如您所见，我们可以有嵌套对象，但典型的建议是避免过多层级的嵌套对象以获得更好的性能。对于`role`属性，我们提供了“提供者”和“客户”等示例，但选择不使用枚举以避免限制值。这种灵活性很重要，因为确切的角色可能各不相同，并且并不完全可预测。通过这种方式定义组织，LLM被引导提取关于参与方的更详细和结构化的信息。
- en: Lastly, you need to define the `Location` object.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您需要定义`Location`对象。
- en: Listing 6.6 Custom `Location` object
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.6 自定义`Location`对象
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 LLMs are familiar with ISO standards being used for countries, so you instruct
    the model to standardize values based on a specific standard.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 LLM熟悉用于国家的ISO标准，因此您可以指示模型根据特定标准标准化值。'
- en: The `Location` object represents a physical address, capturing details such
    as the street address, city, state or region, and country. All attributes, except
    for the `country`, are optional, allowing flexibility when full location details
    may not be available. For the `country` attribute, we guide the LLM to use the
    two-letter ISO standard, ensuring consistency and making it easier to work with
    and process across different systems. This structure enables the LLM to extract
    standardized, usable information while allowing for incomplete or partial data
    when necessary.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`Location`对象代表一个物理地址，它捕捉了诸如街道地址、城市、州或地区以及国家等详细信息。除了`country`属性外，所有属性都是可选的，这允许在完整的位置详细信息可能不可用的情况下具有灵活性。对于`country`属性，我们指导LLM使用两字母的ISO标准，以确保一致性，并使其在不同系统之间的工作和加工更加容易。这种结构使得LLM能够在必要时提取标准化的、可用的信息，同时允许存在不完整或部分数据。'
- en: You’ve now defined the contract data model, which can be used to extract relevant
    information from the company’s contracts. This model will serve as the blueprint
    for guiding LLMs in structured data extraction. With a clear understanding of
    the data structure in place, it’s time to explore how you can effectively prompt
    the LLM to extract this information.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已定义了合同数据模型，该模型可用于从公司的合同中提取相关信息。此模型将作为指导LLM进行结构化数据提取的蓝图。在明确了解数据结构的基础上，现在是时候探索如何有效地提示LLM提取这些信息了。
- en: 6.1.2 Structured Outputs extraction request
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.2 结构化输出提取请求
- en: With the contract data model defined, you now have a data definition that LLMs
    can follow to extract structured information. The next step is to ensure that
    the LLM understands exactly how to output this data in a consistent format. This
    is where OpenAI’s Structured Outputs feature comes in. By using this feature,
    you can guide the LLM’s behavior to output data that strictly adheres to the contract
    model while using the same chat template introduced in previous chapters.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了合同数据模型后，您现在有一个数据定义，LLM可以遵循以提取结构化信息。下一步是确保LLM确切地了解如何以一致格式输出这些数据。这正是OpenAI的Structured
    Outputs功能发挥作用的地方。通过使用此功能，您可以引导LLM的行为，使其输出严格遵循合同模型的数据，同时使用在前面章节中引入的相同聊天模板。
- en: The Structured Outputs documentation ([https://mng.bz/oZZp](https://mng.bz/oZZp))
    uses system messages to additionally guide the LLM to focus on the task at hand.
    By using a system message, as shown in the following listing, you can provide
    clear instructions to steer the model’s behavior effectively.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化输出文档([https://mng.bz/oZZp](https://mng.bz/oZZp))使用系统消息来额外引导LLM（大型语言模型）专注于当前任务。通过使用以下列表中所示的系统消息，您可以提供明确的指令以有效地引导模型的行为。
- en: Listing 6.7 System message for structured output extraction
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.7 结构化输出提取的系统消息
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: It’s difficult to provide precise instructions for crafting the ideal system
    message. What’s clear is that you should define the domain and provide the LLM
    with context on how the output will be used. Beyond that, it often comes down
    to trial and error.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 提供精确指令以构建理想的系统消息很困难。明确的是，您应该定义领域并为LLM提供有关输出将如何使用的上下文。除此之外，这通常归结为试错。
- en: Finally, you define a function that takes any text as input and outputs a dictionary
    as defined by the contract data model.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您定义一个函数，该函数接受任何文本作为输入，并输出一个根据合同数据模型定义的字典。
- en: Listing 6.8 System message for structured output extraction
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.8 结构化输出提取的系统消息
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Passing in system message as first message'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将系统消息作为第一条消息传递'
- en: '#2 The document is passed as a user message without any additional instructions.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将文档作为用户消息传递，不附加任何额外指令。'
- en: '#3 The output format is defined using the response_format parameters.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 使用response_format参数定义输出格式。'
- en: The extract function in listing 6.8 processes a text document and returns a
    dictionary based on the contract data model. It utilizes the latest GPT-4o model
    available at the time of writing, which supports structured output. The function
    sends a system message to guide the LLM, followed by the raw user-provided document
    text without any modifications. The response is then formatted according to the
    `Contract` data model and returned as a dictionary.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.8中的extract函数处理一个文本文档，并根据合同数据模型返回一个字典。该函数利用了撰写时最新的GPT-4o模型，该模型支持结构化输出。该函数发送一个系统消息以引导LLM，然后是未经修改的原始用户提供的文档文本。然后根据`Contract`数据模型格式化响应，并以字典形式返回。
- en: To see this process in action, let’s now look at how we can apply this method
    using a real-world dataset. Since accessing proprietary contracts can be difficult
    due to confidentiality, you will use a public dataset titled the Contract Understanding
    Atticus Dataset (CUAD).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看到这个过程在实际中的应用，现在让我们看看如何使用真实世界的数据集应用这种方法。由于保密性，访问专有合同可能很困难，因此您将使用一个名为Contract
    Understanding Atticus Dataset（CUAD）的公共数据集。
- en: 6.1.3 CUAD dataset
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.3 CUAD数据集
- en: While all companies have contracts and legal documents, these are typically
    not public due to the sensitive nature of the information they contain. For the
    purpose of this demonstration, we will use a single text document from the CUAD
    dataset (Hendrycks et al., 2021). CUAD is a specialized corpus created for training
    AI models to understand and review legal contracts.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然所有公司都有合同和法律文件，但由于其中包含的信息具有敏感性，这些文件通常不会公开。为了演示目的，我们将使用CUAD数据集（Hendrycks等人，2021年）中的一个文本文件。CUAD是为训练AI模型理解和审查法律合同而创建的专业语料库。
- en: The following listing shows an improved version. The contract is available in
    the accompanying GitHub repository of the book, eliminating the need to download
    the entire dataset. The code handles opening the file and reading its content.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了一个改进版本。合同可在本书的配套GitHub存储库中找到，从而消除了下载整个数据集的需要。代码处理打开文件和读取其内容。
- en: Listing 6.9 Reading the contract text document
  id: totrans-84
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.9 读取合同文本文件
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#1 Reads the file'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 读取文件'
- en: You can now process the contract by executing the code shown in the following
    listing.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以通过执行以下列表中所示的代码来处理合同。
- en: Listing 6.10 Extracting structured information from text
  id: totrans-88
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.10 从文本中提取结构化信息
- en: '[PRE9]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The results will look similar to the following listing.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将类似于以下列表。
- en: Listing 6.11 Results of the extraction
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.11 提取结果
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The extracted contract data is organized into structured fields, though not
    all attributes are fully populated. For instance, some fields like `end_date`
    and `total_amount` are marked as `None`, indicating missing or unspecified information.
    Meanwhile, attributes such as the `contract_scope` contain more detailed, descriptive
    text that outlines the operational details of the agreement, such as the services
    provided and responsibilities. The structure includes a clear breakdown of the
    parties involved, their roles, and locations. The contract also specifies its
    start date and renewal conditions, but other financial or termination details
    remain undefined as they are missing in the contract.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 提取的合同数据被组织到结构化字段中，尽管并非所有属性都完全填充。例如，一些字段如`end_date`（结束日期）和`total_amount`（总金额）被标记为`None`，表示信息缺失或未指定。同时，如`contract_scope`（合同范围）这样的属性包含更详细、描述性的文本，概述了协议的操作细节，如提供的服务和责任。结构包括对涉及各方、他们的角色和位置的清晰分解。合同还指定了其开始日期和续约条件，但其他财务或终止细节仍然未定义，因为它们在合同中缺失。
- en: Exercise 6.1
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习6.1
- en: Download the CUAD dataset and explore creating various contract data models
    based on different types of contracts. Once you’ve defined different models, you
    can test and refine them by analyzing how well they capture and categorize the
    key legal information across the contracts.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 下载CUAD数据集并探索基于不同类型合同的创建各种合同数据模型。一旦你定义了不同的模型，你可以通过分析它们如何捕捉和分类合同中的关键法律信息来测试和改进它们。
- en: In this section, you successfully extracted structured data from a contract
    document using the CUAD dataset and the contract data model defined earlier. The
    LLM was guided to identify key contract details, and the results were formatted
    in a structured way, allowing you to organize important information such as contract
    type, parties, and terms. This process demonstrates how LLMs can efficiently transform
    unstructured legal documents into actionable data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你成功使用CUAD数据集和之前定义的合同数据模型从合同文档中提取了结构化数据。LLM被引导识别关键合同细节，结果以结构化的方式格式化，使你能够组织重要信息，如合同类型、各方和条款。这个过程展示了LLM如何有效地将非结构化法律文件转换为可操作的数据。
- en: Now that you’ve seen how to extract structured information from legal contracts,
    the next section will focus on how to incorporate this data into a knowledge graph.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了如何从法律合同中提取结构化信息，下一节将重点介绍如何将此数据集成到知识图谱中。
- en: 6.2 Constructing the graph
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 构建图
- en: As the final step in the chapter, you’ll import the extracted structured output
    into Neo4j. This follows the standard approach for importing structured data.
    First, you should design a suitable graph model that represents the relationships
    and entities in your data. Graph modeling is beyond the scope of this book, but
    you can use LLMs to assist in defining the graph schema or look at other learning
    material such as Neo4j Graph Academy.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 作为本章的最后一步，你将把提取的结构化输出导入Neo4j。这遵循了导入结构化数据的标准方法。首先，你应该设计一个合适的图模型，以表示你的数据中的关系和实体。图建模超出了本书的范围，但你可以使用LLM来帮助定义图模式或查看其他学习材料，如Neo4j图学院。
- en: 'An example of a contract graph model is illustrated in figure 6.3, which you
    will be using in this step. The graph model represents a contract system with
    three main entities: `Contract`, `Organization`, and `Location`. The `Contract`
    node stores details such as its ID, type, effective date, term, total amount,
    governing law, and scope.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 合同图模型的示例如图6.3所示，你将在本步骤中使用它。图模型表示一个合同系统，包含三个主要实体：`Contract`（合同）、`Organization`（组织）和`Location`（位置）。`Contract`节点存储诸如其ID、类型、生效日期、期限、总金额、管辖法律和范围等详细信息。
- en: Organizations are linked to contracts through the `HAS_PARTY` relationship,
    and each organization has a `HAS_LOCATION` relationship to a `Location` node,
    which captures the organization’s address, city, state, and country. Locations
    are represented as separate nodes to accommodate the possibility that a single
    organization may have multiple addresses.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 组织通过`HAS_PARTY`关系与合同相连接，每个组织都有一个到`Location`节点的`HAS_LOCATION`关系，它捕捉组织的地址、城市、州和国家。位置作为单独的节点表示，以适应单个组织可能有多个地址的可能性。
- en: Now that you’ve defined the graph model, the next step is to begin the process
    of constructing the knowledge graph. This involves several key steps, each of
    which will be covered in the following subsections. First, you’ll define unique
    constraints and indexes to ensure data integrity and improve performance. After
    that, you’ll import the structured contract data into Neo4j using a Cypher statement.
    Once the data is loaded, you will visualize the graph to confirm that all entities
    and relationships are correctly represented. Finally, we’ll address important
    data refinement tasks, such as entity resolution, which ensures that different
    representations of the same real-world entity are merged correctly, and we’ll
    touch on how to handle both structured and unstructured data in the graph.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经定义了图模型，下一步是开始构建知识图谱的过程。这涉及到几个关键步骤，每个步骤将在以下子节中详细说明。首先，你将定义唯一约束和索引以确保数据完整性并提高性能。之后，你将使用Cypher语句将结构化合约数据导入Neo4j。一旦数据加载，你将可视化图谱以确认所有实体和关系都正确表示。最后，我们将讨论重要的数据精炼任务，例如实体解析，这确保了同一现实世界实体的不同表示被正确合并，并且我们将简要介绍如何在图中处理结构化和非结构化数据。
- en: '![figure](../Images/6-3.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-3.png)'
- en: Figure 6.3 Contract graph model
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.3 合约图模型
- en: 6.2.1 Data import
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 数据导入
- en: Defining unique constraints and indexes wherever applicable is a best practice,
    as it not only ensures the integrity of the graph but also enhances query performance.
    The code in the following listing defines unique constraints for `Contract`, `Organization`,
    and `Location` nodes.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在适用的地方定义唯一约束和索引是一种最佳实践，因为它不仅确保了图谱的完整性，还增强了查询性能。以下列表中的代码定义了`Contract`、`Organization`和`Location`节点的唯一约束。
- en: Listing 6.12 Defining the unique constraints
  id: totrans-107
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.12 定义唯一约束
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Next, you need to prepare an import Cypher statement that will take the dictionary
    output and load it into Neo4j, adhering to the graph schema outlined in figure
    6.3\. The import Cypher statement is shown in the following listing.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要准备一个导入Cypher语句，该语句将字典输出加载到Neo4j中，遵循图6.3中概述的图模式。导入Cypher语句如下所示。
- en: Listing 6.13 Defining the import Cypher statement
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.13 定义导入Cypher语句
- en: '[PRE12]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#1 Creates the Contract node using a random UUID as unique identifier'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用随机UUID作为唯一标识符创建合约节点'
- en: '#2 Creates the Party nodes and their locations'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 创建党派节点及其位置'
- en: '#3 Links parties to their location'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将党派与其位置链接'
- en: '#4 Links parties to the contract'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将党派与合约链接'
- en: Explaining Cypher statements, such as the one in listing 6.13, is outside the
    scope of this book. However, if you need assistance, LLMs can help clarify the
    details and provide a deeper understanding of the Cypher statement. However, we
    want to highlight that the query in listing 6.13 is not idempotent due to the
    use of `randomUUID()` for the contract ID. As a result, running the query multiple
    times will create duplicate contract entries in the database, each with a unique
    ID.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 解释Cypher语句，如列表6.13中的语句，超出了本书的范围。然而，如果你需要帮助，LLMs可以帮助澄清细节并提供对Cypher语句的更深入理解。然而，我们想强调的是，由于使用了`randomUUID()`来生成合约ID，列表6.13中的查询不是幂等的。因此，多次运行查询将在数据库中创建重复的合约条目，每个条目都有一个唯一的ID。
- en: Now that everything is prepared, you can execute the code in the following listing
    to import the contract into Neo4j.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一切准备就绪，你可以执行以下列表中的代码，将合约导入Neo4j。
- en: Listing 6.14 Importing the contract data into Neo4j
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.14 将合约数据导入Neo4j
- en: '[PRE13]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Once the import is successful, you can open the Neo4j browser to explore the
    generated graph, which should closely resemble the visualization shown in figure
    6.4.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 导入成功后，你可以打开Neo4j浏览器来探索生成的图谱，它应该与图6.4中显示的可视化非常相似。
- en: '![figure](../Images/6-4.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-4.png)'
- en: Figure 6.4 Contract graph data visualized
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.4 合约图数据可视化
- en: 'The visualization in figure 6.4 depicts a graph where a central “Licensing
    Agreement” (representing a contract) is linked to two organizations: “Mortgage
    Logic.com, Inc.” and “TrueLink, Inc.” via the relationship `HAS_PARTY`. Each organization
    is further connected to a “US” node representing their location through the `LOCATED_AT`
    relationship.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4中的可视化展示了一个图谱，其中中心“许可协议”（代表合约）通过`HAS_PARTY`关系与两个组织“Mortgage Logic.com, Inc.”和“TrueLink,
    Inc.”相连。每个组织进一步通过`LOCATED_AT`关系连接到一个代表其位置的“US”节点。
- en: 6.2.2 Entity resolution
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 实体解析
- en: You’ve successfully imported the graph, but your work isn’t done yet. In most
    cases, especially when dealing with natural language processing or LLM-driven
    data processing, some level of data cleaning is necessary. One of the most crucial
    steps in this cleaning process is entity resolution. Entity resolution refers
    to the process of identifying and merging different representations of the same
    real-world entity within a dataset or knowledge graph. When working with large
    and diverse datasets, it’s common for the same entity to appear in multiple forms
    due to inconsistencies like spelling variations, different naming conventions,
    or even slight discrepancies in data formats, as shown in figure 6.5, where we
    see three nodes representing variations of the same entity. The three names are
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 您已成功导入图，但您的工作还没有完成。在大多数情况下，尤其是在处理自然语言处理或LLM驱动的数据处理时，某些程度的数据清理是必要的。在这个清理过程中，实体识别是最关键的一步。实体识别是指在一个数据集或知识图中识别和合并同一现实世界实体的不同表示的过程。当处理大型且多样化的数据集时，由于拼写变化、不同的命名规范或数据格式中的微小差异等原因，同一实体可能以多种形式出现是很常见的，如图6.5所示，我们看到了代表同一实体变体的三个节点。这三个名称是
- en: UTI Asset Management Company
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UTI资产管理公司
- en: UTI Asset Management Company Limited
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UTI资产管理公司有限公司
- en: UTI Asset Management Company Ltd
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UTI资产管理有限公司
- en: '![figure](../Images/6-5.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/6-5.png)'
- en: Figure 6.5 Potential duplicates
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.5 潜在重复项
- en: Entity resolution in this context involves identifying that all these variations
    refer to the same real-world organization, despite minor differences in naming
    conventions (such as “Limited” vs. “Ltd”). The goal of entity resolution is to
    unify these disparate references into a single, coherent node within the graph.
    This not only improves data integrity but also enhances the graph’s ability to
    make more accurate inferences and relationships. Techniques used in entity resolution
    include string matching, clustering algorithms, and even machine learning methods
    that use the context surrounding each entity to detect and resolve duplicates.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，实体识别涉及识别所有这些变体都指的是同一现实世界组织，尽管在命名规范（如“Limited”与“Ltd”）上存在细微差异。实体识别的目标是将这些不同的引用统一到图中的一个单一、连贯的节点中。这不仅提高了数据完整性，还增强了图进行更准确推理和关系的能力。实体识别中使用的技巧包括字符串匹配、聚类算法，甚至使用每个实体周围上下文来检测和解决重复的机器学习方法。
- en: It is important to note that entity resolution is highly use case and domain
    specific. A generic, one-size-fits-all solution rarely works because each domain
    has its own naming conventions, data schemas, and nuances in how entities are
    represented. For instance, the methods and thresholds that might work well for
    resolving organizations in a financial dataset could produce suboptimal results
    when dealing with biological entities in a healthcare setting. Consequently, one
    of the most effective strategies is to develop domain-specific ontologies or rules
    that reflect your particular data context. Additionally, using subject matter
    experts to define matching criteria and using iterative feedback loops—where potential
    matches are verified or corrected—can greatly improve accuracy. By combining domain
    expertise with context-aware machine learning or clustering techniques, you can
    develop a more robust and flexible approach to entity resolution. This will ensure
    that you capture the subtle details that matter most in your unique data environment.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，实体识别高度依赖于具体用例和领域。一个通用的、一刀切解决方案很少能奏效，因为每个领域都有自己的命名规范、数据架构以及实体表示的细微差别。例如，在金融数据集中解决组织的方法和阈值可能在对医疗保健环境中的生物实体进行处理时产生次优结果。因此，最有效的策略之一是开发特定领域的本体或规则，以反映您的特定数据环境。此外，使用领域专家来定义匹配标准，并使用迭代反馈循环——其中潜在的匹配项被验证或修正——可以大大提高准确性。通过结合领域专业知识与上下文感知的机器学习或聚类技术，您可以开发出更稳健和灵活的实体识别方法。这将确保您捕捉到在您独特的数据环境中最重要的细微细节。
- en: 6.2.3 Adding unstructured data to the graph
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.3 将非结构化数据添加到图中
- en: Knowledge graphs are increasingly used to store both structured and unstructured
    data, a scenario that has become even more common with the advent of LLMs. In
    this context, LLMs can be used to extract structured data from unstructured sources
    like text documents. However, storing the original unstructured documents and
    the extracted structured data within the graph preserves the richness of the original
    data while enabling more precise querying and analysis of the extracted information.
    An expanded graph schema where structured and unstructured information is combined
    is presented in figure 6.6\.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱越来越多地被用来存储结构化和非结构化数据，随着LLMs（大型语言模型）的出现，这种场景变得更加普遍。在这种情况下，LLMs可以用来从非结构化来源，如文本文档中提取结构化数据。然而，在图中存储原始的非结构化文档和提取的结构化数据，既保留了原始数据的丰富性，又使得对提取信息的查询和分析更加精确。图6.6展示了将结构化和非结构化信息结合的扩展图模式。
- en: '![figure](../Images/6-6.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/6-6.png)'
- en: Figure 6.6 Expanded graph model with added unstructured data
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.6 增强的图模型，包含非结构化数据
- en: When incorporating unstructured data into a graph, it’s common to use a simple
    chunking strategy based on token count or word length to split text into manageable
    segments. While this naive approach works for general use cases, certain domains,
    such as legal contracts, benefit from more specialized chunking methods. For example,
    splitting a contract by its clauses preserves its semantic structure and improves
    the quality of downstream analysis. This smarter approach allows the graph to
    capture more meaningful relationships, enabling richer insights and more accurate
    inferences.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 当将非结构化数据纳入图中时，通常使用基于标记计数或词长的基础分块策略来将文本分割成可管理的段。虽然这种朴素的方法适用于通用用例，但某些领域，如法律合同，则受益于更专业的分块方法。例如，通过条款分割合同可以保留其语义结构，并提高下游分析的质量。这种更智能的方法允许图捕获更有意义的关系，从而实现更深入的见解和更准确的推断。
- en: This chapter has guided you through constructing knowledge graphs from unstructured
    data using LLMs. You explored the limitations of text embeddings in handling structured
    queries and learned how structured data extraction provides a solution. By defining
    data models, prompting LLMs for extraction, and importing the results into a graph
    database, you saw how to transform raw text into usable data for knowledge graphs.
    Additionally, we covered key tasks like entity resolution and combining structured
    and unstructured data for richer insights. With this knowledge, you can now apply
    structured data extraction in practical scenarios.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 本章已指导您使用LLMs从非结构化数据构建知识图谱。您探讨了文本嵌入在处理结构化查询方面的局限性，并学习了结构化数据提取是如何提供解决方案的。通过定义数据模型、提示LLMs进行提取以及将结果导入图数据库，您了解了如何将原始文本转换为知识图谱的可用数据。此外，我们还涵盖了实体解析和结合结构化和非结构化数据以获得更深入见解的关键任务。有了这些知识，您现在可以在实际场景中应用结构化数据提取。
- en: Summary
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Simply chunking documents for retrieval can result in inaccurate or mixed results,
    especially in domains like legal documents where document boundaries matter.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单地对文档进行分块以进行检索可能会导致不准确或混合的结果，尤其是在法律文件等文档边界重要的领域。
- en: Retrieval tasks like filtering, sorting, and aggregating require structured
    data, as text embeddings alone are not suited for such operations.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤、排序和聚合等检索任务需要结构化数据，因为仅凭文本嵌入不适合此类操作。
- en: LLMs are effective at extracting structured data from unstructured text, converting
    it into usable formats like tables or key–value pairs.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs在从非结构化文本中提取结构化数据，并将其转换为表格或键值对等可用格式方面非常有效。
- en: Structured output features in LLMs allow developers to define schemas, ensuring
    responses follow a specific format and reducing the need for postprocessing.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs中的结构化输出特征允许开发者定义模式，确保响应遵循特定的格式，并减少后处理的需求。
- en: Defining a clear data model with attributes such as contract type, parties,
    and dates is essential for guiding LLMs to extract relevant information accurately.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义一个清晰的数据模型，具有合同类型、各方和日期等属性，对于指导LLMs准确提取相关信息至关重要。
- en: Entity resolution in knowledge graphs is important for merging different representations
    of the same entity, improving data consistency and accuracy.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在知识图谱中进行实体解析对于合并同一实体的不同表示非常重要，这有助于提高数据的一致性和准确性。
- en: Combining structured and unstructured data in knowledge graphs preserves the
    richness of the source material while enabling more precise querying.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在知识图谱中将结构化和非结构化数据相结合，既保留了原始资料的丰富性，又使得查询更加精确。
