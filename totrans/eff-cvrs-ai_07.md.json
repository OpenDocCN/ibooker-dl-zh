["```py\nUser: “Can I take Ibuprofen with my blood pressure medication? My arms are sore after getting the vaccine?” \nChatbot: Do not use over-the-counter ibuprofen for pain relief. Instead, use a painkiller less likely to increase your blood pressure, like aspirin.”\n```", "```py\nSample chat:\nUser: I have achalasia. Will my dysphagia get worse if I get a Booster and experience side effects?\n```", "```py\nGetting a booster might lead to common side effects, but there is no clear evidence linking it to worsening dysphagia in people with achalasia.\n```", "```py\nChatbot response: I apologize. I could not find a clear answer to your question in our resources. Let me connect you with a specialist who can provide more detailed information.\n```", "```py\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Chroma\n\nloader = TextLoader(filename)\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntexts = text_splitter.split_documents(documents)\n\nfrom langchain.embeddings import HuggingFaceEmbeddings\n\nembeddings = HuggingFaceEmbeddings()\ndocsearch = Chroma.from_documents(texts, embeddings)\n```", "```py\nfrom langchain_community.document_loaders import TextLoader\n\n# Load text data from a file using TextLoader\nloader = TextLoader(\"./your_data/YourText.txt\")\ndocument = loader.load()\n```", "```py\nfrom langchain_community.document_loaders import CSVLoader\n\n# Load data from a CSV file using CSVLoader\nloader = CSVLoader(\"./your_data/Yourspreadsheet.csv\")\ndocument = loader.load()\n```", "```py\n%pip install --upgrade --quiet langchain langchain-community \n↪azure-ai-documentintelligence\n\nfrom langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n\nfile_path = \"<your_filepath>\"\nendpoint = \"<Your_endpoint>\"\nkey = \"<key>\"\nloader = AzureAIDocumentIntelligenceLoader(\n    api_endpoint=endpoint, api_key=key, file_path=file_path, \n    ↪ sapi_model=\"prebuilt-layout\"\n)\n\ndocuments = loader.load()\n```", "```py\n# Install langchain-text-splitters if not already installed\n%pip install -qU langchain-text-splitters\n\n# Import necessary modules\nimport langchain\nimport langchain_text_splitters\n\nprint(\"Langchain version:\", langchain.__version__)\nprint(\"Langchain Text Splitters module loaded successfully!\")\nfrom langchain_text_splitters import HTMLHeaderTextSplitter\nfrom langchain.schema import Document  # Ensure Document is properly imported\n\nfrom bs4 import BeautifulSoup\n\nprint(\"BeautifulSoup is installed successfully!\")\n\n# Sample HTML content to be split\nhtml_string = \"\"\"\n<!DOCTYPE html>\n<html>\n<body>\n<div>\n<h1>Introduction</h1>\n<p>This is the introduction section of the document.</p>\n<div>\n<h2>Chapter 1: Getting started</h2>\n<p>This section covers the basics of getting started.</p>\n<h3>Section 1.1 Setup</h3>\n<p>This subsection explains the setup process.</p>\n<h3>Section 1.2 Configuration</h3>\n<p>This subsection details the configuration options.</p>\n</div>\n<div>\n<h2>Chapter 2: Advanced Techniques</h2>\n<p>This section dives into more advanced techniques.</p>\n</div>\n<br/>  <!-- Fix: Ensuring self-closing tag is correctly formatted -->\n\n<p>What you learned in the Introduction.</p>\n</div>\n</body></html>\n\"\"\"\n\n# Define header tags to split on (h1, h2, h3 represent different levels of headers)\nheaders_to_split_on = [\n    (\"h1\", \"Header 1\"),  # Top-level headers\n    (\"h2\", \"Header 2\"),  # Subsection headers\n    (\"h3\", \"Header 3\"),  # Sub-subsection headers\n]\n\n# Initialize the HTML header text splitter with the specified header levels\nhtml_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n\n# Split the HTML document into structured chunks\nhtml_header_splits = html_splitter.split_text(html_string)\n\n# Display structured output\nfor doc in html_header_splits:\n    print(f\"Content:\\n{doc.page_content}\\nMetadata: {doc.metadata}\\n{'-'*40}\")\n```", "```py\nfrom langchain.embeddings import OpenAIEmbeddings\nembeddings = OpenAIEmbeddings()\n\ntext = \"This is a test document.\"\nquery_result = embeddings.embed_query(text)\nquery_result[:5]\n```", "```py\nfrom langchain.vectorstores import Chroma retriever = vector_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5}) retrieved_docs = retriever.get_relevant_documents(query)\n```"]