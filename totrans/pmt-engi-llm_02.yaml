- en: Chapter 1\. Introduction to Prompt Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章：提示工程简介
- en: ChatGPT was released in late November of 2022\. By January of the following
    year, the application had accumulated an estimated 100 million monthly users,
    making ChatGPT the fastest-growing consumer application *ever*. (In comparison,
    TikTok took 9 months to reach 100 million users, and Instagram took 2.5 years.)
    And as you can surely attest, esteemed reader, this public acclaim is well deserved!
    LLMs—like the one that backs ChatGPT—are revolutionizing the way we work. Rather
    than running to Google to find answers via a traditional web search, you can easily
    just ask an LLM to talk about a topic. Rather than reading Stack Overflow or rummaging
    through blog posts to answer technical questions, you can ask an LLM to write
    you a personalized tutorial on your exact problem space and then follow it up
    with a set of questions and answers (a Q&A) about the topic. Rather than following
    the traditional steps to build a programming library, you can boost your progress
    by pairing with an LLM-based assistant to build the scaffolding and autocomplete
    your code as you write it!
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT于2022年11月底发布。到次年1月，该应用已积累了约1亿月活跃用户，使ChatGPT成为史上增长最快的消费应用*之一*。（相比之下，TikTok用了9个月才达到1亿用户，而Instagram则用了2.5年。）正如您所肯定的那样，尊敬的读者，这种公众赞誉是当之无愧的！LLMs（如支撑ChatGPT的LLM）正在改变我们的工作方式。与其跑到谷歌通过传统网络搜索寻找答案，不如直接询问一个LLM来讨论一个主题。与其阅读Stack
    Overflow或翻阅博客文章来回答技术问题，不如让LLM为您撰写一个针对您具体问题空间的个性化教程，然后通过一系列问题和答案（问答）来跟进该主题。与其遵循传统的步骤来构建编程库，您可以通过与基于LLM的助手配对来加速进度，并在编写代码时自动完成代码！
- en: And to you, *future* reader, will you use LLMs in ways that we, your humble
    authors from the year 2024, cannot fathom? If the current trends continue, you’ll
    likely have conversations with LLMs many times during the course of a typical
    day—in the voice of the IT support assistant when your cable goes out, in a friendly
    conversation with the corner ATM, and, yes, even with a frustratingly realistic
    robo dialer. There will be other interactions as well. LLMs will curate your news
    for you, summarizing the headline stories that you’re most likely to be interested
    in and removing (or perhaps *adding*) biased commentary. You’ll use LLMs to assist
    in your communications by writing and summarizing emails, and office and home
    assistants will even reach out into the real world and interact on your behalf.
    In a single day, your personal AI assistant might at one point act as a travel
    agent, helping you make travel plans, book flights, and reserve hotels; and then
    at another point, act as a shopping assistant, helping you find and purchase items
    you need.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 而对于你，*未来的*读者，你会如何使用LLMs，这是我们2024年的谦逊作者们无法想象的？如果当前趋势持续下去，你可能会在典型的一天中多次与LLMs进行对话——在电缆故障时以IT支持助手的口吻，在与街角ATM的友好交谈中，甚至在与令人沮丧的现实机器人拨号器对话。还会有其他互动。LLMs将为您定制新闻，总结您最可能感兴趣的头版新闻，并移除（或可能*添加*）有偏见的评论。您将使用LLMs来协助您的沟通，撰写和总结电子邮件，甚至办公室和家庭助手会代表您进入现实世界进行互动。在一天之内，您的个人AI助手可能会在某个时刻充当旅行代理人，帮助您制定旅行计划、预订航班和预订酒店；然后，在另一个时刻，充当购物助手，帮助您找到并购买您需要的物品。
- en: Why are LLMs so amazing? It’s because they are magic! As futurist Arthur C.
    Clarke famously stated, “Any sufficiently advanced technology is indistinguishable
    from magic.” We think a machine that you can have a conversation with certainly
    qualifies as magic, but it’s the goal of this book to dispel this magic. We will
    demonstrate that no matter how uncanny, intuitive, and humanlike LLMs sometimes
    seem to be, at the core, LLMs are simply models that predict the next word in
    a block of text—that’s it and nothing more! As such, LLMs are merely tools for
    helping users to accomplish some task, and the way that you interact with these
    tools is by crafting the *prompt*―the block of text―that they are to complete.
    This is what we call *prompt engineering*. Through this book, we will build up
    a practical framework for prompt engineering and ultimately for building LLM applications,
    which *will* be a magical experience for your users.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么大型语言模型（LLMs）如此神奇？这是因为它们具有魔力！正如未来学家亚瑟·C·克拉克著名地指出，“任何足够先进的技术都和魔法无法区分。”我们认为，你可以与之进行对话的机器当然可以算作是魔法，但本书的目标是消除这种魔力。我们将证明，无论LLMs有时看起来多么神秘、直观和人性化，本质上，LLMs只是预测文本块中下一个单词的模型——仅此而已，没有更多！因此，LLMs仅仅是帮助用户完成某些任务的工具，而你与这些工具互动的方式是通过构建*提示*——即它们要完成的文本块。这就是我们所说的*提示工程*。通过这本书，我们将建立一个实用的提示工程框架，最终用于构建LLM应用，这将*绝对*为你的用户提供一种神奇的经历。
- en: This chapter sets the background for the journey you are about to take into
    prompt engineering. But first, let us tell you about how we, your authors, discovered
    the magic for ourselves.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章为即将开始的提示工程之旅设定了背景。但首先，让我们告诉你，作为本书的作者，我们是如何自己发现这种魔力的。
- en: LLMs Are Magic
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs Are Magic
- en: Both authors of this book were early research developers for the GitHub Copilot
    code completion product. Albert was on the founding team, and John appeared on
    the scene as Albert was moving on to other distant-horizon LLM research projects.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书两位作者都是GitHub Copilot代码补全产品的早期研究开发者。阿尔伯特是创始团队的一员，而约翰在阿尔伯特转向其他遥远视野的LLM研究项目时出现在了舞台上。
- en: 'Albert first discovered the magic halfway through 2020\. He puts it as follows:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 阿尔伯特在2020年中期首次发现了这种魔力。他这样描述：
- en: 'Every half year or so, during our ideation meetings in the ML-on-code group,
    someone would bring up the matter of code synthesis. And the answer was always
    the same: it will be amazing, one day, but that day won’t come for another five
    years at least. It was our cold fusion.'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 大约每半年，在我们机器学习代码组的创意会议上，总会有人提出代码生成的议题。答案总是相同的：它将有一天变得神奇，但至少还需要五年时间。这就是我们的冷聚变。
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This was true until the first day I laid hands on an early prototype of the
    LLM that would become OpenAI Codex. Then I saw that the future was now: cold fusion
    had finally arrived.'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 直到有一天，我第一次接触到了将成为OpenAI Codex的LLM的早期原型。那时，我看到未来已经到来：冷聚变终于实现了。
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It was immediately clear that this model was wholly different from the sorry
    stabs at code synthesis we had known before. This model wouldn’t just have a chance
    of predicting the next word―it could generate whole statements and whole functions
    from just the docstring. Functions that worked!
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 很明显，这个模型与我们之前所知的那些糟糕的代码生成尝试完全不同。这个模型不仅有机会预测下一个单词，它甚至可以从文档字符串中生成整个语句和整个函数。这些函数是有效的！
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Before we decided what we could build with this model (spoiler: it would eventually
    become GitHub’s Copilot code completion product), we wanted to quantify how good
    the model really was. So, we crowdsourced a bunch of GitHub engineers and had
    them come up with self-contained coding tasks. Some of the tasks were comparatively
    easy―but these were hardcore coders, and many of their tasks were also pretty
    involved. A good number of the tasks were the kind a junior developer would turn
    to Google for, but some would push even a senior developer to Stack Overflow.
    Yet, if we gave the model a few tries, it could solve most of them.'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在我们决定可以用这个模型构建什么（剧透：它最终将成为GitHub的Copilot代码补全产品）之前，我们想量化这个模型真正有多好。因此，我们征集了一群GitHub工程师，让他们提出一些自包含的编码任务。其中一些任务相对简单——但这些是硬核程序员，他们中的许多人的任务也很复杂。许多任务是一个初级开发者会转向Google寻求帮助的类型，但也有一些甚至会让资深开发者求助于Stack
    Overflow。然而，如果我们给这个模型一些尝试，它就能解决大多数问题。
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We knew it then—this was the engine that would usher in a new age of coding.
    All we had to do was build the right vehicle around it.
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们当时就知道——这是将引领编码新时代的引擎。我们唯一需要做的就是围绕它构建正确的载体。
- en: 'For John, the magical moment came a couple years later, in early 2023, when
    he was kicking the tires on the vehicle and taking it out for a spin. He recounts
    it as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对于约翰来说，那个神奇的时刻是在两年后的2023年初，当他开始试驾这辆车并出去兜风时。他这样描述：
- en: 'I set up a screen recording session and laid out the coding challenge that
    I planned to tackle: create a function that takes an integer and returns the text
    version of that number. So, given an input of 10, the output would be “ten,” and
    given an input of 1,004,712, the output would be “one million four thousand seven
    hundred twelve.” It’s harder than you might expect, because, thanks to English,
    weird exceptions abound. The text versions of numbers between 10 and 20—“eleven,”
    “twelve,” and the teens—don’t follow the same pattern as numbers in any other
    decade. The tens place digit breaks expected patterns—for example, if 90 is “ninety”
    and 80 is “eighty,” then why isn’t 30 “threety” and 20 “twoty?” But the real twist
    in my coding challenge was that I wanted to implement the solution in a language
    in which I had zero personal experience—Rust. Was Copilot up to the challenge?'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我设置了一个屏幕录制会话，并概述了我计划解决的编码挑战：创建一个函数，它接受一个整数并返回该数字的文本版本。所以，给定输入10，输出将是“ten”，给定输入1,004,712，输出将是“one
    million four thousand seven hundred twelve。”这比你想象的要难，因为，多亏了英语，奇怪的反常现象比比皆是。10到20之间的数字的文本版本——“eleven”、“twelve”和青少年——并不遵循任何其他十年中数字的相同模式。十位数的数字打破了预期的模式——例如，如果90是“ninety”，80是“eighty”，那么为什么30不是“threety”，20不是“twoty”呢？但我在编码挑战中的真正转折是，我想在一个我没有任何个人经验的编程语言中实现解决方案——Rust。Copilot能应对这个挑战吗？
- en: ''
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Normally, when learning a new programming language, I would refer to the typical
    how-tos: How do I create a variable? How do I create a list? How do I iterate
    over the items in a list? How do I write an if statement? But with Copilot, I
    started by just writing a docstring:'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 通常，在学习一门新的编程语言时，我会参考典型的教程：如何创建一个变量？如何创建一个列表？如何遍历列表中的项？如何编写一个if语句？但与Copilot一起，我一开始只是写了一个文档字符串：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Copilot saw *fn* and jumped in to help:'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Copilot看到*fn*就跳进来帮忙：
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Perfect! I didn’t know how to annotate types for the input arguments or return
    value of functions, but as we continued to work together, I would direct the high-level
    flow of work via comments like “Split up the input number into groups of three
    digits,” and Copilot would effectively teach me programming constructs. These
    included things like how to create vectors and assign them to variables, as in
    `let mut number_string_vec = Vec::new();` and how to make loops, as in `while
    number > 0 {.`
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 完美！我不知道如何为函数的输入参数或返回值注释类型，但随着我们继续一起工作，我会通过像“将输入数字分成三位一组”这样的注释来指导工作的整体流程，而Copilot会有效地教我编程结构。这包括如何创建向量并将它们分配给变量，例如`let
    mut number_string_vec = Vec::new();`以及如何创建循环，例如`while number > 0 {.`
- en: ''
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The experience was great. I was making progress and learning the language without
    being distracted by constant references to language tutorials—my project was my
    tutorial. Then, 20 minutes into this experiment, Copilot blew my mind. I typed
    a comment and started the next control loop that I knew we would need:'
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 体验非常好。我在不断进步和学习语言的同时，没有被语言教程的持续参考所打扰——我的项目就是我的教程。然后，在这个实验进行到20分钟时，Copilot让我大吃一惊。我输入了一条注释，并启动了下一个我知道我们需要的控制循环：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: After a moment’s pause, Copilot interjected 30 lines of code! [In the recording,
    you can actually hear me audibly gasp](https://oreil.ly/4ZYWY). The code compiled
    successfully—it was all syntactically correct—and it ran. The answer was a little
    wonky. An input of 5,034,012 resulted in the string “five thirty four thousand
    twelve million,” but hey, I wouldn’t expect a human to be right the first time,
    and the bug was easy to spot and correct. By the end of the 40-minute pairing
    session, I’d done the impossible—I ’d created nontrivial code in a language that
    I was completely unfamiliar with! Copilot had coached me toward basic understanding
    of Rust syntax, and it had demonstrated a more abstract grasp of my goals and
    interjected at several points to help me fill in the details. If I had tried this
    on my own, I suspect it would have taken hours.
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '暂停片刻后，Copilot插入了30行代码！[在录音中，你实际上可以听到我明显地倒吸一口凉气](https://oreil.ly/4ZYWY)。代码编译成功——它完全是语法正确的——并且运行了。答案是有点古怪。输入5,034,012产生了字符串“五十三万四千一百二十”，但嘿，我并不期望人类第一次就能做到正确，而且错误很容易被发现和纠正。在40分钟的配对会议结束时，我做到了不可能的事情——我在一个我完全不熟悉的语言中创建了非平凡代码！Copilot指导我理解Rust语法的基础，并且它展示了对我的目标有更抽象的理解，并在几个地方插话帮助我填补细节。如果我自己尝试这样做，我怀疑这需要几个小时。 '
- en: 'Our magical experiences are not unique. If you’re reading this book, you’ve
    likely had some mind-blowing interactions with LLMs yourself. Perhaps you first
    became aware of the power of LLMs with ChatGPT, or maybe your first experience
    was with one of the first-generation applications that have been pouring out since
    early 2023: internet search assistants such as Microsoft’s Bing or Google’s Bard,
    or document assistants such as Microsoft’s broader Copilot suite of tools. But
    getting to this technological inflection point was not something that happened
    overnight. To truly understand LLMs, it is important to know how we got here.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的神奇体验并不独特。如果你正在阅读这本书，你很可能自己也有过一些令人震惊的与LLM的互动。也许你第一次意识到LLM的力量是从ChatGPT开始的，或者也许你的第一次体验是来自2023年初涌现的第一代应用之一：如微软的Bing或谷歌的Bard这样的互联网搜索助手，或者是微软更广泛的Copilot工具套件中的文档助手。但达到这个技术转折点并不是一夜之间发生的事情。要真正理解LLM，了解我们是如何到达这里的是非常重要的。
- en: 'Language Models: How Did We Get Here?'
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 语言模型：我们是如何到达这里的？
- en: 'To understand how we got to this very interesting point in the history of technology,
    we first need to know what a language model actually is and what it does. Who
    better to ask than the world’s most popular LLM application: ChatGPT (see [Figure 1-1](#ch01_1_figure_1_1728408393602766)).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解我们是如何到达技术史上的这个非常有趣点的，我们首先需要知道语言模型实际上是什么以及它做什么。谁比世界上最受欢迎的LLM应用——ChatGPT（见[图1-1](#ch01_1_figure_1_1728408393602766)）——更适合提问呢？
- en: '![A screenshot of a phone  Description automatically generated](assets/pefl_0101.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![手机屏幕截图  自动生成的描述](assets/pefl_0101.png)'
- en: Figure 1-1\. What is a language model?
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 什么是语言模型？
- en: 'See? It’s just like we said at the opening of the chapter: the primary goal
    of a language model is to predict the probability of the next word. You’ve seen
    this functionality before, haven’t you? It’s the bar of completion words that
    appears above the keypad when you’re typing out a text message on your iPhone
    (see [Figure 1-2](#ch01_1_figure_2_1728408393602779)). You might have never noticed
    it…*because it isn’t that useful.* If this is all that language models do, then
    how on earth are they currently taking the world by storm?'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 看吧？这就像我们在本章开头所说的：语言模型的主要目标是预测下一个单词的概率。你之前见过这个功能，不是吗？这是你在iPhone上输入短信时出现在键盘上方的完成单词栏（见[图1-2](#ch01_1_figure_2_1728408393602779)）。你可能从未注意到它…*因为它并不那么有用。*
    如果语言模型就做这些，那么它们目前是如何震撼世界的呢？
- en: '![A person holding a cell phone  Description automatically generated](assets/pefl_0102.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![一个人手持手机的图片  自动生成的描述](assets/pefl_0102.png)'
- en: Figure 1-2\. John pointing to the completion bar on his phone
  id: totrans-36
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. 约翰指向他手机上的完成栏
- en: Early Language Models
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 早期语言模型
- en: Language models have actually been around for a long time. If you’re reading
    this book soon after its publication, then the language model that powers the
    iPhone guess-the-next-word functionality is based upon [a Markov model of natural
    language that was first introduced in 1948](https://oreil.ly/D6Q3U). However,
    there are other more recent language models that have more directly set the stage
    for the AI revolution that is now underway.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型实际上已经存在很长时间了。如果你在本书出版后不久阅读它，那么为 iPhone 的猜下一个词功能提供动力的语言模型是基于 [1948 年首次提出的自然语言马尔可夫模型](https://oreil.ly/D6Q3U)。然而，还有其他更近期的语言模型，它们更直接地为目前正在进行的
    AI 革命奠定了基础。
- en: 'By 2014, the most powerful language models were based on the [sequence to sequence
    (seq2seq) architecture introduced at Google](https://arxiv.org/abs/1409.3215).
    Seq2seq was a recurrent neural network, which, in theory, should have been ideal
    for text processing because it processes one token at a time and recurrently updates
    its internal state. This allows seq2seq to process arbitrarily long sequences
    of text. With specialized architectures and training, the seq2seq architecture
    was capable of performing several different types of natural language tasks: classification,
    entity extraction, translation, summarization, and more. But these models had
    an Achilles’ heel—an information bottleneck limited their capabilities.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 到 2014 年，最强大的语言模型是基于 [在 Google 介绍过的序列到序列（seq2seq）架构](https://arxiv.org/abs/1409.3215)。Seq2seq
    是一个循环神经网络，从理论上讲，它应该非常适合文本处理，因为它一次处理一个标记，并循环更新其内部状态。这使得 seq2seq 能够处理任意长度的文本序列。通过专门的架构和训练，seq2seq
    架构能够执行多种不同的自然语言任务：分类、实体提取、翻译、摘要等。但这些模型有一个致命的弱点——信息瓶颈限制了它们的性能。
- en: 'The seq2seq architecture has two major components: the encoder and the decoder
    (see [Figure 1-3](#ch01_1_figure_3_1728408393602789)). Processing starts by sending
    the encoder a stream of tokens that are processed one at a time. As the tokens
    are received, the encoder updates a hidden state vector that accumulates information
    from the input sequence. When the last token has been processed, the final value
    of the hidden state, called the thought vector, is sent to the decoder. The decoder
    then uses the information from the thought vector to generate output tokens. The
    problem, though, is that the thought vector is fixed and finite. It often “forgets”
    important information from longer blocks of text, giving the decoder little to
    work with—this is the information bottleneck.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: seq2seq 架构有两个主要组件：编码器和解码器（见图 1-3）。处理开始时，向编码器发送一系列标记，这些标记逐个处理。随着标记的接收，编码器更新一个隐藏状态向量，该向量累积来自输入序列的信息。当处理完最后一个标记后，隐藏状态的最后值，称为思维向量，被发送到解码器。然后解码器使用思维向量中的信息来生成输出标记。问题是，思维向量是固定和有限的。它经常“忘记”较长的文本块中的重要信息，给解码器的工作空间很少——这就是信息瓶颈。
- en: '![](assets/pefl_0103.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0103.png)'
- en: Figure 1-3\. A translation seq2seq model
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-3\. 一种翻译 seq2seq 模型
- en: 'The model in the figure works as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的模型工作如下：
- en: Tokens from the source language are sent to the encoder one at a time and converted
    to an embedding vector, and they update the internal state of the encoder.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 源语言标记逐个发送到编码器，并转换为嵌入向量，并更新编码器的内部状态。
- en: The internal state is packaged up as the thought vector and sent to the decoder.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内部状态被打包成思维向量并发送到解码器。
- en: A special “start” token is sent to the decoder, indicating that this is the
    start of the output tokens.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向解码器发送一个特殊的“开始”标记，表示这是输出标记的开始。
- en: Conditioned upon the value of the thought vector, the decoder state is updated
    and an output token from the target language is emitted.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据思维向量的值，解码器状态被更新，并发出目标语言的输出标记。
- en: The output token is provided as the next input into the decoder. At this point,
    the process recurrently loops back and forth from step 4 to step 5.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出标记作为下一个输入提供给解码器。此时，过程从步骤 4 反复循环到步骤 5。
- en: Finally, the decoder emits a special “end” token, indicating that the decoding
    process is complete. The limited thought vector could transfer only a limited
    amount of information to the decoder.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，解码器发出一个特殊的“结束”标记，表示解码过程已完成。有限的思维向量只能将有限的信息传递给解码器。
- en: A 2015 paper, [“Neural Machine Translation by Jointly Learning to Align and
    Translate”](https://arxiv.org/abs/1409.0473), introduced a new approach to addressing
    this bottleneck. Rather than having the encoder supply a single thought vector,
    it preserved all the hidden state vectors generated for each token encountered
    in the encoding process and then allowed the decoder to “soft search” over all
    of the vectors. As a demonstration, the paper showed that using soft search with
    an English-to-French translation model increased translation quality significantly.
    This soft search technique soon came to be known as the attention mechanism.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 2015 年的一篇论文，“通过联合学习对齐和翻译进行神经机器翻译”（[“Neural Machine Translation by Jointly Learning
    to Align and Translate”](https://arxiv.org/abs/1409.0473)），介绍了一种解决这一瓶颈的新方法。它不是让编码器提供一个单一的思想向量，而是保留了编码过程中为每个遇到的标记生成的所有隐藏状态向量，然后允许解码器在所有这些向量上进行“软搜索”。作为演示，论文展示了使用软搜索的英法翻译模型显著提高了翻译质量。这种软搜索技术很快就被人们称为注意力机制。
- en: The attention mechanism soon gained a good deal of attention of its own in the
    AI community, culminating in the 2017 Google Research paper [“Attention Is All
    You Need”](https://arxiv.org/abs/1706.03762), which introduced the transformer
    architecture shown in [Figure 1-4](#fig-1-4). The transformer retained the high-level
    structure of its predecessor—consisting of an encoder that received tokens as
    input followed by a decoder that generated output tokens. But unlike the seq2seq
    model, all of the recurrent circuitry had been removed, and the transformer instead
    relies completely upon the attention mechanism. The resulting architecture was
    very flexible and much better at modeling training data than seq2seq. But whereas
    seq2seq could process arbitrarily long sequences, the transformer could process
    only a fixed, finite sequence of inputs and outputs. Since the transformer is
    the direct progenitor of the GPT models, this is a limitation that we have been
    pushing back against ever since.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制很快在人工智能社区引起了广泛关注，最终在 2017 年的 Google 研究论文“[“Attention Is All You Need”](https://arxiv.org/abs/1706.03762)”中达到高潮，该论文介绍了图
    1-4 中所示的 transformer 架构。Transformer 保留了其前辈的高级结构——由接收标记作为输入的编码器随后是生成输出标记的解码器组成。但与
    seq2seq 模型不同，所有循环电路都被移除，transformer 完全依赖于注意力机制。结果架构非常灵活，在建模训练数据方面比 seq2seq 更好。但
    whereas seq2seq 可以处理任意长度的序列，transformer 只能处理固定、有限的输入和输出序列。由于 transformer 是 GPT
    模型的直接祖先，因此这是我们自那时以来一直在努力克服的局限性。
- en: '![](assets/pefl_0104.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0104.png)'
- en: Figure 1-4\. Transformer architecture
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-4\. Transformer 架构
- en: GPT Enters the Scene
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT 进入场景
- en: The generative pre-trained transformer architecture was introduced in the 2018
    paper [“Improving Language Understanding by Generative Pre-Training”](https://oreil.ly/vIiDJ).
    The architecture wasn’t particularly special or new. Actually, the architecture
    was just a transformer with the encoder ripped off—it was just the decoder side.
    However, this simplification led to some unexpected new possibilities that would
    only be fully realized in coming years. It was this generative pre-trained transformer
    architecture—GPT—that would soon ignite the ongoing AI revolution.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 生成预训练的 transformer 架构在 2018 年的论文“[“Improving Language Understanding by Generative
    Pre-Training”](https://oreil.ly/vIiDJ)”中首次提出。该架构并不特别特殊或新颖。实际上，该架构只是一个去掉了编码器的 transformer——它只是解码器部分。然而，这种简化带来了一些意想不到的新可能性，这些可能性将在未来的几年内完全实现。正是这种生成预训练的
    transformer 架构——GPT——很快点燃了正在进行的 AI 革命。
- en: 'In 2018, this wasn’t apparent. At that point in time, it was standard practice
    to *pre-train* models with unlabeled data—for instance, scraps of text from the
    internet—and then modify the architecture of the models and apply specialized
    fine-tuning so that the final model would then be able to do *one* task very well.
    And so it was with the generative *pre-trained* transformer architecture. The
    2018 paper simply showed that this pattern worked really well for GPTs—pre-training
    on unlabeled text followed by supervised fine-tuning for a particular task led
    to really good models for a variety of tasks such as classification, measuring
    similarities among documents, and answering multiple-choice questions. But we
    should emphasize one point: after the GPT was fine-tuned, it was only good at
    the single task for which it was fine-tuned.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在2018年，这一点并不明显。在那个时间点，使用未标记的数据**预训练**模型是标准做法——例如，从互联网上获取的零散文本——然后修改模型的架构并应用专门的微调，以便最终的模型能够非常擅长完成**一个**任务。因此，生成式**预训练**的Transformer架构也是如此。2018年的论文仅仅表明，这种模式对于GPTs来说非常有效——在未标记的文本上进行预训练，然后针对特定任务进行监督微调，导致了在分类、测量文档之间的相似性以及回答多项选择题等多种任务上表现良好的模型。但我们应该强调一点：在GPT微调之后，它只擅长它被微调的那个单一任务。
- en: 'GPT-2 was simply a scaled-up version of GPT. When it was introduced in 2019,
    it was beginning to dawn upon researchers that the GPT architecture was something
    special. This is clearly evidenced in the second paragraph of the [OpenAI blog
    post introducing GPT-2](https://oreil.ly/_tv8t):'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-2仅仅是GPT的一个扩展版本。当它在2019年推出时，研究人员开始意识到GPT架构的特殊性。这一点在[OpenAI介绍GPT-2的博客文章](https://oreil.ly/_tv8t)的第二段中得到了明确的体现：
- en: Our model, called GPT-2 (a successor to GPT), was trained simply to predict
    the next word in 40 GB of Internet text. Due to our concerns about malicious applications
    of the technology, we are not releasing the trained model.
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们称之为GPT-2（GPT的继任者）的模型，仅仅是为了预测40GB互联网文本中的下一个单词而进行训练。由于我们对技术恶意应用的担忧，我们没有发布训练好的模型。
- en: Wow! How can those two sentences belong next to each other? How does something
    as innocuous as predicting the next word—just like an iPhone does when you write
    a text message—lead to such grave concerns about misuse? If you read the corresponding
    academic paper, [“Language Models Are Unsupervised Multitask Learners”](https://oreil.ly/QEeI9),
    then you start to find out. GPT-2 was 1.5 billion parameters, as compared with
    GPT’s 117 million, and was trained on 40 GB of text, as compared with GPT’s 4.5
    GB. A simple order-of-magnitude increase in model and training set size led to
    an unprecedented emergent quality—instead of having to fine-tune GPT-2 for a single
    task, you could apply the raw, pre-trained model to the task and often achieve
    better results than state-of-the-art models that were fine-tuned specifically
    for the task. This included benchmarks for understanding ambiguous pronouns, predicting
    missing words in text, tagging parts of speech, and more. And despite falling
    behind the state of the art, GPT-2 also fared surprisingly well on reading comprehension,
    summarization, translation, and question-answering tasks, again against models
    fine-tuned specifically for those tasks.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！这两句话怎么可能放在一起？预测下一个单词——就像iPhone在你发短信时做的那样——怎么会引起如此严重的滥用担忧？如果你阅读了相应的学术论文[“Language
    Models Are Unsupervised Multitask Learners”](https://oreil.ly/QEeI9)，那么你就会开始了解到。GPT-2有15亿个参数，相比之下GPT有1170万个，训练文本量为40GB，而GPT为4.5GB。模型和训练集规模的简单数量级增加导致了前所未有的涌现质量——你不需要为GPT-2的单一任务进行微调，你可以直接应用原始的预训练模型到任务中，并且通常比专门针对该任务进行微调的最先进模型取得更好的结果。这包括理解模糊代词、预测文本中的缺失单词、标记词性等基准测试。尽管在阅读理解、摘要、翻译和问答任务上落后于最先进的技术，但GPT-2在这些特定任务针对的模型上仍然表现出色。
- en: But, why all the concern about “malicious applications” of this model? It’s
    because the model had become quite good at mimicking natural text. And, as the
    OpenAI blog post indicates, this capability could be used to “generate misleading
    news articles, impersonate others online, automate the production of abusive or
    faked content to post on social media, and automate the production of spam/phishing
    content.” If anything, this possibility has only become more real and concerning
    today than it was in 2019.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，为什么人们对这个模型的“恶意应用”如此关注？这是因为该模型在模仿自然文本方面已经变得相当出色。正如OpenAI博客文章所指出的，这种能力可以用来“生成误导性新闻文章、在线冒充他人、自动化生产用于社交媒体的侮辱性或伪造内容，以及自动化生产垃圾邮件/钓鱼内容。”如果有什么的话，这种可能性在2019年之后变得更加真实和令人担忧。
- en: GPT-3 saw another order-of-magnitude increase in both model size and training
    data, with a corresponding leap in capability. The 2020 paper [“Language Models
    Are Few-Shot Learners”](https://arxiv.org/abs/2005.14165) showed that, given a
    few examples of the task you want the model to complete, (a.k.a. “few-shot examples”),
    the model could faithfully reproduce the input pattern and, as a result, perform
    just about any language-based task that you could imagine—and often with remarkably
    high-quality results. This is when we found out that you could modify the input—the
    prompt—and thereby condition the model to perform the requisite task at hand.
    This was the birth of prompt engineering.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3在模型大小和训练数据量上又提高了一个数量级，能力也相应地飞跃。2020年的论文[“Language Models Are Few-Shot Learners”](https://arxiv.org/abs/2005.14165)表明，给定一些你希望模型完成的任务的示例（即“少量示例”），模型可以忠实地复制输入模式，因此可以执行几乎所有你能想象的语言任务——并且通常能产生高质量的结果。这就是我们了解到你可以修改输入——提示词——从而条件化模型执行当前任务的时候。这就是提示工程诞生的时刻。
- en: ChatGPT, released in November 2022, was backed by GPT-3.5―and the rest is history!
    But, it’s a history rapidly in the making (see [Table 1-1](#ch01_1_table_1_1728408393607235)).
    In March of 2023, GPT-4 was released, and although the details were not officially
    revealed, that model was rumored to be another order of magnitude larger in both
    model size and amount of training data, and it was again much more capable than
    its predecessors. Since then, more and more models have appeared. Some are from
    OpenAI while others are from major industry players, such as Llama from Meta,
    Claude from Anthropic, and Gemini from Google. We have continued to see leaps
    in quality, and increasingly, the same level of quality is available in smaller
    and faster models. If anything, *the progress is only accelerating*.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT于2022年11月发布，由GPT-3.5支持——其余的都是历史！但是，这是一个正在迅速形成的历史（见[表1-1](#ch01_1_table_1_1728408393607235)）。2023年3月，GPT-4发布，尽管细节尚未官方公布，但该模型传闻在模型大小和训练数据量上又提高了一个数量级，并且其能力比前辈们又强得多。从那时起，越来越多的模型出现了。有些来自OpenAI，而有些来自主要行业玩家，如Meta的Llama、Anthropic的Claude和Google的Gemini。我们继续看到质量上的飞跃，并且越来越频繁地，相同水平的质量出现在更小、更快的模型中。如果有什么的话，*进步正在加速*。
- en: Table 1-1\. Details of the GPT-series models, showing the exponential nature
    of increase in all metrics
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-1\. GPT系列模型的详细信息，显示了所有指标增加的指数性质
- en: '| Model | Release date | Parameter count | Training data | Training cost |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 发布日期 | 参数数量 | 训练数据 | 训练成本 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| GPT-1 | June 11, 2018 | 117 million | BookCorpus: 4.5 GB of text from 7,000
    unpublished books of various genres | 1.7e19 FLOP |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| GPT-1 | 2018年6月11日 | 1.17亿 | BookCorpus：来自7000本未出版书籍的4.5GB文本 | 1.7e19 FLOP
    |'
- en: '| GPT-2 | February 14, 2019 (initial); November 5, 2019 (full) | 1.5 billion
    | WebText: 40 GB of text and 8 million documents from 45 million web pages upvoted
    on Reddit | 1.5e21 FLOP |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| GPT-2 | 2019年2月14日（初始）；2019年11月5日（完整） | 15亿 | WebText：来自4500万个Reddit点赞网页的40GB文本和800万个文档
    | 1.5e21 FLOP |'
- en: '| GPT-3 | May 28, 2020 | 175 billion | 499 billion tokens consisting of Common
    Crawl (570 GB), WebText, English Wikipedia, and two books corpora (Books1 and
    Books2) | 3.1e23 FLOP |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3 | 2020年5月28日 | 1750亿 | 由Common Crawl（570GB）、WebText、英语维基百科和两个书籍语料库（Books1和Books2）组成的4990亿个token
    | 3.1e23 FLOP |'
- en: '| GPT-3.5 | March 15, 2022 | 175 billion | Undisclosed | Undisclosed |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| GPT-3.5 | 2022年3月15日 | 1750亿 | 未公开 | 未公开 |'
- en: '| GPT-4 | March 14, 2023 | 1.8 trillion (rumored) | Rumored to be 13 trillion
    tokens | Estimated to be 2.1e25 FLOP |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| GPT-4 | 2023年3月14日 | 1.8万亿（传闻） | 传闻达到13万亿个token | 估计为2.1e25 FLOP |'
- en: Prompt Engineering
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程
- en: Now, we arrive at the beginning of *your* journey into the world of prompt engineering.
    At their core, LLMs are capable of one thing—completing text. The input into the
    model is called the *prompt*—it is a document, or block of text, that we expect
    the model to complete. *Prompt engineering*, then, in its simplest form, is the
    practice of crafting the prompt so that its completion contains the information
    required to address the problem at hand.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来到了您进入提示工程世界的起点。从根本上说，LLM能够完成一件事——完成文本。输入到模型中的称为*提示*——它是一份文档或文本块，我们期望模型能够完成。因此，最简单的提示工程实践就是构建提示，使其完成的内容包含解决当前问题的所需信息。
- en: In this book, we provide a much larger picture of prompt engineering that involves
    moves well beyond a single prompt and discuss the entire LLM-based application,
    where prompt construction and the interpretation of the answer are done programmatically.
    To build a quality piece of software and a quality UX, the prompt engineer must
    create a pattern for iterative communication among the user, the application,
    and the LLM. The user conveys their problem to the application, the application
    constructs a pseudodocument to be sent to the LLM, the LLM completes the document,
    and finally, the application parses the completion and conveys the result back
    to the user or otherwise performs an action on the user’s behalf. The science
    *and art* of prompt engineering is to make sure that this communication is structured
    in a way that best translates among very different domains, the user’s problem
    space, and the document space of LLMs.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们提供了一个关于提示工程的大得多图景，它涉及的内容远远超出了单个提示的范围，并讨论了整个基于LLM的应用，其中提示构建和答案的解释都是通过程序完成的。为了构建高质量的软件和高质量的UX，提示工程师必须为用户、应用程序和LLM之间的迭代通信创建一个模式。用户将问题传达给应用程序，应用程序构建一个伪文档以发送给LLM，LLM完成文档，最后，应用程序解析完成的内容并将结果传达给用户，或者代表用户执行其他操作。提示工程的科学和艺术在于确保这种沟通以最佳方式在不同领域、用户的问题空间和LLM的文档空间之间进行结构化。
- en: Prompt engineering comes in several levels of sophistication. The most basic
    form makes use of only a very thin application layer. For instance, when you engage
    with ChatGPT, you’re crafting a prompt almost directly; the application is merely
    wrapping the conversation thread in a special ChatML markdown. (You’ll learn more
    about this in [Chapter 3](ch03.html#ch03a_moving_toward_chat_1728432131625250).)
    Similarly, when GitHub Copilot was first created for code completions, it was
    doing little more than passing the current file along to the model to complete.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程有几个复杂程度不同的级别。最基本的形式只使用一个非常薄的应用层。例如，当您与ChatGPT互动时，您几乎是在直接构建提示；应用程序只是将对话线程包裹在一个特殊的ChatML
    Markdown中。（您将在第3章中了解更多关于这一点。[Chapter 3](ch03.html#ch03a_moving_toward_chat_1728432131625250)。）同样，当GitHub
    Copilot最初被创建用于代码补全时，它所做的只是将当前文件传递给模型以完成。
- en: At the next level of sophistication, prompt engineering involves modifying and
    augmenting the user’s input into the model. For instance, LLMs deal with text,
    so a tech support hotline could transcribe a user’s speech to text and use it
    in the prompt sent to the LLM. Additionally, relevant content from previous help
    transcripts or from relevant support documentation could be included in the prompt.
    As a real-world example, as GitHub Copilot code completions developed, we realized
    that the completion quality improved considerably if we incorporated relevant
    snippets from the user’s neighboring tabs. This makes sense, right? The user had
    the tabs open because they were referencing information there, so it stands to
    reason that the model could benefit from this information as well. Another example
    is the new Bing chat-based search experience. In this instance, content from traditional
    search results is pulled into the prompt. This allows the assistant to competently
    discuss information that it never saw in the training data (for instance, because
    it referred to events that happened after the model was trained). More importantly,
    this approach helps Bing reduce hallucinations, a topic we’ll revisit several
    times throughout the book, starting in the next chapter.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个复杂程度的提示工程中，涉及对用户输入到模型中的内容进行修改和增强。例如，LLM处理文本，因此技术支持热线可以将用户的语音转录成文本，并将其用于发送给LLM的提示中。此外，之前帮助记录或相关支持文档中的相关内容也可以包含在提示中。作为一个现实世界的例子，随着GitHub
    Copilot代码补全的发展，我们意识到，如果我们结合用户相邻标签中的相关片段，补全质量会显著提高。这很有道理，对吧？用户打开标签是因为他们在那里参考信息，所以从逻辑上讲，模型也可以从这些信息中受益。另一个例子是新的Bing基于聊天的搜索体验。在这种情况下，传统搜索结果的内容被拉入提示中。这使得助手能够熟练地讨论它在训练数据中从未见过的信息（例如，因为它提到了模型训练之后发生的事件）。更重要的是，这种方法有助于Bing减少幻觉，这是我们将在本书的多个地方重新讨论的话题，下一章将开始讨论。
- en: Another aspect of prompt engineering at this level of sophistication comes when
    the interactions with the LLM become *stateful*, meaning they maintain context
    and information from prior interactions. A chat application is the quintessential
    example here. With each new exchange from the user, the application must recall
    what happened in previous exchanges and generate a prompt that faithfully represents
    the interaction. As the conversation or history gets longer, you will have to
    be careful to not overfill the prompt or include spurious content that might distract
    the model. You may choose to drop the earliest exchanges or less relevant content
    from previous exchanges, and you may even employ summarization to compress the
    content.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个复杂程度的提示工程中，另一个方面出现在与LLM的交互变得**状态化**时，这意味着它们会保持之前交互中的上下文和信息。聊天应用在这里是典型的例子。随着用户每次新的交流，应用必须回忆之前交流中发生的事情，并生成一个忠实反映交互的提示。随着对话或历史记录变长，你必须小心不要让提示过于满载或包含可能分散模型注意力的虚假内容。你可以选择丢弃最早的交流或不太相关的旧内容，甚至可以采用摘要来压缩内容。
- en: 'Yet another aspect of prompt engineering at this level of sophistication involves
    giving the LLM-based application tools that allow the LLM to reach out into the
    real world by making API requests to read information or to even create or modify
    assets that are available on the internet. For instance, an LLM-based email application
    might receive this input from a user: “Send Diane an invitation to a meeting on
    May 5.” This application would use one tool to identify Diane in the user’s contacts
    list and then use a calendar API to look up her availability before finally sending
    an email invitation. As these models get cheaper and more powerful, just imagine
    the possibilities available with the APIs already at our disposal today! Prompt
    engineering here is critical. How will the model know which tool to use? How will
    it use the tool in the correct way? How will your application properly share the
    information from the tool execution with the model? What do we do when the tool
    usage results in some sort of error state? We will talk about all of this in [Chapter 8](ch08.html#ch08_01_conversational_agency_1728429579285372).'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个复杂程度级别的提示工程中，另一个方面涉及为基于LLM的应用程序提供工具，这些工具允许LLM通过API请求读取信息，甚至创建或修改互联网上可用的资产，从而进入现实世界。例如，一个基于LLM的电子邮件应用程序可能会从用户那里收到这样的输入：“向戴安发送5月5日的会议邀请。”这个应用程序会使用一个工具来识别用户联系人列表中的戴安，然后使用日历API查找她的可用性，最后发送电子邮件邀请。随着这些模型变得更便宜、更强大，想象一下我们今天已经可以利用的API带来的可能性吧！在这里，提示工程至关重要。模型将如何知道使用哪个工具？它将如何正确地使用这个工具？你的应用程序将如何适当地将工具执行的信息与模型共享？当工具使用导致某种错误状态时，我们该怎么办？我们将在[第8章](ch08.html#ch08_01_conversational_agency_1728429579285372)中讨论所有这些问题。
- en: The final level of sophistication that we cover in this book is how to provide
    the LLM application with agency—the ability to make its own decisions about how
    to accomplish broad goals supplied by the user. This is clearly on the frontier
    of our capabilities with LLMs, but research and practical exploration are underway.
    Already, you can download [AutoGPT](https://oreil.ly/h3mJZ) and supply it with
    a goal, and it will take off on a multistep process to gather the information
    it needs to accomplish the goal. Does it always work? No. Actually, unless the
    goal is quite constrained, it tends to fail at the task more often than it succeeds.
    But giving LLM applications some form of agency and autonomy is still an important
    step toward exciting future possibilities. You’ll read our take on this in Chapters
    [8](ch08.html#ch08_01_conversational_agency_1728429579285372) and [9](ch09.html#ch09_llm_workflows_1728407155661595).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 本书涵盖的最后一个复杂程度是如何为LLM应用程序提供代理能力——即让应用程序能够就如何实现用户提供的广泛目标做出自己的决定。这显然是我们使用LLMs的能力的前沿，但研究和实践探索正在进行中。现在，你可以在[AutoGPT](https://oreil.ly/h3mJZ)上下载它，并为其提供一个目标，它将启动一个多步骤过程来收集实现目标所需的信息。它总是能成功吗？不。实际上，除非目标非常受限，否则它往往比成功更频繁地失败。但为LLM应用程序提供某种形式的代理和自主性仍然是通往令人兴奋的未来可能性的重要一步。你将在第[8章](ch08.html#ch08_01_conversational_agency_1728429579285372)和第[9章](ch09.html#ch09_llm_workflows_1728407155661595)中读到我们对这一点的看法。
- en: Conclusion
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'As we said at the start, this chapter sets the background for the journey you
    are about to take into prompt engineering. We started with a discussion of the
    recent history of language models, and we highlighted why LLMs are so special
    and different—and why they are fueling the AI revolution that we are all now witnessing.
    We then defined the topic of this book: prompt engineering.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们一开始所说的，本章为即将开始的提示工程之旅设定了背景。我们首先讨论了语言模型最近的历程，并强调了LLMs为何如此特别和不同——以及为什么它们正在推动我们现在都见证的AI革命。然后，我们定义了本书的主题：提示工程。
- en: In particular, you should understand that this book isn’t going to be all about
    how to do nitpicky wording of a single prompt to get one good completion. Sure,
    we’ll cover that, and we’ll cover in detail all the things you need to do to generate
    high-quality completions that serve their intended purpose. But when we say, “prompt
    engineering,” we mean building the entire LLM-based application. The LLM application
    serves as a transformation layer, iteratively and statefully converting real-world
    needs into text that LLMs can address and then converting the data provided by
    the LLMs into information and action that address those real-world needs.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其重要的是，你应该理解这本书不会仅仅关于如何对单个提示进行字斟句酌以获得一个良好的补全。当然，我们会涵盖这一点，并且我们会详细说明你需要做的一切来生成高质量、服务于其预期目的的补全。但当我们说“提示工程”时，我们指的是构建整个基于LLM的应用程序。LLM应用程序作为一个转换层，迭代地、有状态地将现实世界的需求转换为LLM可以处理的数据，然后将LLM提供的数据转换为满足这些现实世界需求的信息和行动。
- en: Before we set off on this journey, let’s make sure we’re appropriately packed.
    In the next chapter, you’ll learn how LLM text completion works from the top-level
    API all the way down to low-level attention mechanisms. In the subsequent chapter,
    we’ll build upon that knowledge to explain how LLMs have been expanded to handle
    chat and tool usage, and you’ll see that deep down, it’s really all the same thing—text
    completion. Then, with those foundational ideas in store, you’ll be ready for
    your journey.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们踏上这段旅程之前，让我们确保我们已经适当地打包了。在下一章中，你将学习从顶层API到低级注意力机制的LLM文本补全是如何工作的。在随后的章节中，我们将在此基础上扩展知识，解释LLMs是如何被扩展以处理聊天和工具使用的，你将看到实际上，这本质上都是同一件事——文本补全。然后，带着这些基础理念，你将准备好开始你的旅程。
