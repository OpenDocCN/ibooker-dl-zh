- en: Chapter 2\. Fundamentals of Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Probability is a field of mathematics that quantifies our uncertainty regarding
    events. For example, when rolling dice or flipping a coin, barring any irregularities
    in the dice or coin themselves, we are uncertain about the result to come. However,
    we can quantify our belief in each of the potential outcomes via probabilities.
    We say, for example, that on every coin toss the probability of the coin showing
    up heads is <math alttext="one-half"><mfrac><mn>1</mn> <mn>2</mn></mfrac></math>
    . And on every dice roll, we say the probability of a die facing up with a five
    is <math alttext="one-sixth"><mfrac><mn>1</mn> <mn>6</mn></mfrac></math> . These
    are the sorts of probabilities we talk about with ease in our daily lives, but
    how can we define and utilize them effectively? In this chapter we’ll discuss
    the fundamentals of probability and how they connect to key concepts in deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Events and Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When running a trial such as rolling a dice or tossing a coin, we intuitively
    assign some belief to the trial’s possible outcomes. In this section, we aim to
    formalize some of these concepts. In particular, we will begin by working in this
    *discrete* space, where discrete signifies a finite or countably infinite number
    of possibilities. Both rolling a dice and tossing a coin are in the discrete space—when
    rolling a fair dice there are six possible outcomes and when tossing a fair coin
    there are two. We term the entire set of possibilities for an experiment the *sample
    space.* For example, the numbers one through six would make up the sample space
    for rolling a fair dice. We can define *events* as subsets of the sample space.
    The event of rolling at least a three corresponds with the dice facing up any
    number in the subset of three, four, five, and six in the sample space defined
    previously. A set of probabilities that sum to one over all outcomes in the sample
    space is termed a *probability distribution* over that sample space, and these
    distributions will be the main focus of our discussion.
  prefs: []
  type: TYPE_NORMAL
- en: In general, we won’t worry too much about where exactly these probabilities
    come from, as that requires a much more rigorous and thorough examination beyond
    the scope of this text. However, we will give some intuition about the different
    interpretations. At a high level, the *frequentist* view sees the probability
    of an outcome as arising from its frequency over a long-run experiment. In the
    case of fair dice, this view claims we can say the probability of any side of
    the dice showing up on a given roll is <math alttext="one-sixth"><mfrac><mn>1</mn>
    <mn>6</mn></mfrac></math> , since performing a large number of rolls and counting
    up the occurrences of each side will give us an estimate that is roughly this
    fraction. As the number of rolls in the experiment grows, we see that this estimate
    gets closer and closer to the limit <math alttext="one-sixth"><mfrac><mn>1</mn>
    <mn>6</mn></mfrac></math> , the outcome’s probability.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the *Bayesian* view of probability is based more on quantifying
    our prior belief in hypotheses and how we update our beliefs in light of new data.
    For a fair dice, the Bayesian view would claim there is no prior information,
    both from the dice’s structure and the rolling process, that would suggest any
    side of the dice as being more likely to turn up than any other side. Thus, we
    would say each outcome has probability <math alttext="one-sixth"><mfrac><mn>1</mn>
    <mn>6</mn></mfrac></math> , our prior belief. The set of probabilities, in this
    case all being <math alttext="one-sixth"><mfrac><mn>1</mn> <mn>6</mn></mfrac></math>
    , associated with each outcome is termed our *prior.* As we see new data, the
    Bayesian view gives us a methodology to update our prior accordingly, where we
    term this new belief our *posterior.* This Bayesian view is sometimes directly
    applied to neural network training, where we first assume that each weight in
    the network has some prior associated with it. As we train the network, we update
    the prior associated with each weight accordingly to better fit the data we see.
    At the end of the training, we are left with a posterior distribution associated
    with each weight.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will assume throughout this chapter that the probabilities associated with
    any outcome have been determined via reasonable methods, and focus on how we can
    manipulate these probabilities for use in our analyses. We start with the four
    tenets of probability, specifically in the discrete space:'
  prefs: []
  type: TYPE_NORMAL
- en: The sum of probabilities for all possible outcomes in a sample space must be
    equal to one. In other words, the probability distribution over the sample space
    must sum to one. This should make sense intuitively, since the set of all outcomes
    in the sample space must represent the entire set of possibilities. The probability
    distribution not summing to one would imply the existence of possibilities not
    accounted for, which is contradictory. Mathematically, we say that for any valid
    probability distribution, <math alttext="sigma-summation Underscript o Endscripts
    upper P left-parenthesis o right-parenthesis equals 1"><mrow><msub><mo>∑</mo>
    <mi>o</mi></msub> <mi>P</mi> <mrow><mo>(</mo> <mi>o</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mn>1</mn></mrow></math> , where <math alttext="o"><mi>o</mi></math> represents
    an outcome.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let <math alttext="upper E 1"><msub><mi>E</mi> <mn>1</mn></msub></math> be an
    event, and recall that we define an event as a subset of possible outcomes. We
    call <math alttext="upper E 1 Superscript c"><msubsup><mi>E</mi> <mn>1</mn> <mi>c</mi></msubsup></math>
    the *complement* of <math alttext="upper E 1"><msub><mi>E</mi> <mn>1</mn></msub></math>
    , or all possible outcomes in the sample space that are not in <math alttext="upper
    E 1"><msub><mi>E</mi> <mn>1</mn></msub></math> . The second tenet of probability
    is that <math alttext="upper P left-parenthesis upper E 1 right-parenthesis equals
    1 minus upper P left-parenthesis upper E 1 Superscript c Baseline right-parenthesis"><mrow><mi>P</mi>
    <mrow><mo>(</mo> <msub><mi>E</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>=</mo>
    <mn>1</mn> <mo>-</mo> <mi>P</mi> <mrow><mo>(</mo> <msubsup><mi>E</mi> <mn>1</mn>
    <mi>c</mi></msubsup> <mo>)</mo></mrow></mrow></math> . This is just an application
    of the first tenet—if this were not true, it would clearly contradict the first
    tenet. In [Figure 2-1](#we_see_here_how_the_event_a), we see an example of this,
    where *S* represents the entire space of outcomes, and the event and its complement
    together form the entirety of *S*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/fdl2_0201.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 2-1\. Event A and its complement interact to form the entire set of possibilities,
    S. The complement simply defines all the possibilities not originally in A.
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: Let <math alttext="upper E 1"><msub><mi>E</mi> <mn>1</mn></msub></math> and
    <math alttext="upper E 2"><msub><mi>E</mi> <mn>2</mn></msub></math> be two events,
    where <math alttext="upper E 1"><msub><mi>E</mi> <mn>1</mn></msub></math> is a
    subset (not necessarily strict) of <math alttext="upper E 2"><msub><mi>E</mi>
    <mn>2</mn></msub></math> . The third tenet is that <math alttext="upper P left-parenthesis
    upper E 1 right-parenthesis less-than-or-equal-to upper P left-parenthesis upper
    E 2 right-parenthesis"><mrow><mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>1</mn></msub>
    <mo>)</mo></mrow> <mo>≤</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></mrow></math> . This, again, shouldn’t be too surprising—the
    second event has at least as many outcomes as the first event, and all the outcomes
    the first event has since the second is a superset of the first. If this tenet
    were not true, that would imply the existence of outcomes with negative probability,
    which is impossible from our definitions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The fourth and last tenet of probability is the principle of inclusion and exclusion,
    which states that <math alttext="upper P left-parenthesis upper A union upper
    B right-parenthesis equals upper P left-parenthesis upper A right-parenthesis
    plus upper P left-parenthesis upper B right-parenthesis minus upper P left-parenthesis
    upper A intersection upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi>
    <mo>∪</mo> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo>
    <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo> <mo>-</mo> <mi>P</mi> <mo>(</mo>
    <mi>A</mi> <mo>∩</mo> <mi>B</mi> <mo>)</mo></mrow></math> . For those not familiar
    with this terminology, the <math alttext="union"><mo>∪</mo></math> denotes the
    *union* of the two events, a set operation that takes the two events and returns
    an event that contains all elements from the two original sets. The <math alttext="intersection"><mo>∩</mo></math>
    , or *intersection,* is a set operation that returns an event that contains all
    elements belonging to both of the two original sets. The idea behind the equality
    presented is that by just naively summing the probabilities of *A* and *B,* we
    double-count the elements that belong to both sets. Thus, to accurately obtain
    the probability of the union, we must subtract the probability of the intersection.
    In [Figure 2-2](#the_middle_sliver_labeled), we show two events and what their
    intersection would look like physically, while the union is all the outcomes in
    the combined area of the events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](Images/fdl2_0202.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: Figure 2-2\. The middle sliver is the overlap between the two sets, containing
    all the outcomes that are in both sets. The union is all the events in the combined
    area of the two circles; if we were to add their probabilities naively, we would
    double-count all the outcomes in the middle sliver.
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
- en: 'These tenets of probability find their way into everything that has to do with
    the field. For example, in deep learning, most of our problems fall into one of
    two categories: *regression* and *classification*. In the latter, we train a neural
    model that can predict the likelihood that the input belongs to one of a discrete
    number of classes. The famous MNIST digits dataset, for example, provides us with
    pictures of digits and associated numerical labels in the range of 0 through 9\.
    Our objective is to build a *classifier* that can take in this picture and return
    the most likely label as its guess. This is naturally formulated as a problem
    in probability—the classifier produces a probability distribution over the sample
    space, 0 through 9, for any given input and its best guess is the digit that is
    assigned the highest probability. How does this relate to our tenets? Since the
    classifier is producing a probability distribution, it must follow the tenets.
    For example, the probabilities associated with each digit must sum to one—a quick
    back-of-the-envelope check to ensure the model isn’t buggy. In the next section,
    we cover probabilities where we are initially given relevant information that
    affects our beliefs and how to use that information.'
  prefs: []
  type: TYPE_NORMAL
- en: Conditional Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Knowing information often changes our beliefs, and by consequence, our probabilities.
    Going back to our classic dice example, we may roll the dice thinking that it’s
    fair, while in reality there’s a hidden weight at the dice’s core, making it more
    likely to land up a number greater than three. As we roll the dice, we of course
    start to notice this pattern, and our belief regarding the dice’s fairness starts
    to shift. This is at the core of conditional probability itself. Instead of thinking
    simply about <math alttext="upper P left-parenthesis b i a s e d right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <mi>b</mi> <mi>i</mi> <mi>a</mi> <mi>s</mi> <mi>e</mi> <mi>d</mi> <mo>)</mo></mrow></math>
    or <math alttext="upper P left-parenthesis f a i r right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <mi>f</mi> <mi>a</mi> <mi>i</mi> <mi>r</mi> <mo>)</mo></mrow></math>
    , we have to think about probabilities like <math alttext="upper P left-parenthesis
    b i a s e d vertical-bar i n f o r m a t i o n right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <mi>b</mi> <mi>i</mi> <mi>a</mi> <mi>s</mi> <mi>e</mi> <mi>d</mi> <mo>|</mo>
    <mi>i</mi> <mi>n</mi> <mi>f</mi> <mi>o</mi> <mi>r</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi>
    <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>)</mo></mrow></math> instead. This quantity,
    which we term a *conditional probability,* is spoken as “the probability the dice
    is biased *given* the information we’ve seen.”
  prefs: []
  type: TYPE_NORMAL
- en: How do we think about such probabilities intuitively? For starters, we must
    imagine that we are now in a different universe than the one we started in. The
    new universe is one that incorporates the information we’ve seen since the start
    of the experiment, e.g., our past dice rolls. Going back to our MNIST example,
    the probability distribution that the trained neural net produces is actually
    a conditional probability distribution. The probability that the input image is
    zero, for example, can be seen as *P(0|input).* In plain English, we want to find
    the probability of a zero given all of the pixels that make up the specific input
    image we fed into our neural net. Our new universe is the universe in which the
    input pixels have taken on this specific configuration of values. This is distinct
    from simply looking at *P(0),* the probability of returning a zero, which we can
    think about in terms of prior belief. Without any knowledge of the input pixel
    configuration, we’d have no reason to believe that the possibility of returning
    a zero is any more or less likely than that of any other digit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, seeing certain information does not change our probabilities—we
    call this property *independence.* For example, Tom Brady may have thrown a touchdown
    pass after the third roll of our experiment, but incorporating that information
    into our new universe should (hopefully!) have no impact on the likelihood of
    the dice being biased. We state this independenceproperty as *P(biased|Tom Brady
    throws a touchdown pass) =* *P(biased).* Note that any two events <math alttext="upper
    E 1"><msub><mi>E</mi> <mn>1</mn></msub></math> and <math alttext="upper E 2"><msub><mi>E</mi>
    <mn>2</mn></msub></math> that satisfy this property are independent. Perhaps slightly
    more counterintuitively, if it happens to be the case that all of our dice rolls
    so far don’t numerically change our prior belief regarding the dice’s fairness
    (maybe the dice rolls so far have shown up evenly across one through six and our
    initial prior belief was that the dice was fair), we’d still say that these events
    are independent. Finally, note that independence is symmetric: if <math alttext="upper
    P left-parenthesis upper E 1 vertical-bar upper E 2 right-parenthesis equals upper
    P left-parenthesis upper E 1 right-parenthesis"><mrow><mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>E</mi> <mn>1</mn></msub> <mo>|</mo> <msub><mi>E</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>1</mn></msub>
    <mo>)</mo></mrow></mrow></math> , then it is also the case that <math alttext="upper
    P left-parenthesis upper E 2 vertical-bar upper E 1 right-parenthesis equals upper
    P left-parenthesis upper E 2 right-parenthesis"><mrow><mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>E</mi> <mn>2</mn></msub> <mo>|</mo> <msub><mi>E</mi> <mn>1</mn></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></mrow></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous section, we introduced intersection and union notation. It
    turns out that we can break down the intersection operation into a product of
    probabilities. We have the following equality: <math alttext="upper P left-parenthesis
    upper E 1 intersection upper E 2 right-parenthesis equals upper P left-parenthesis
    upper E 1 vertical-bar upper E 2 right-parenthesis asterisk upper P left-parenthesis
    upper E 2 right-parenthesis"><mrow><mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi>
    <mn>1</mn></msub> <mo>∩</mo> <msub><mi>E</mi> <mn>2</mn></msub> <mo>)</mo></mrow>
    <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>1</mn></msub> <mo>|</mo>
    <msub><mi>E</mi> <mn>2</mn></msub> <mo>)</mo></mrow> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>E</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mrow></math> . Let’s break
    down the intuition here. On the left side, we have the probability that both events
    <math alttext="upper E 1"><msub><mi>E</mi> <mn>1</mn></msub></math> and <math
    alttext="upper E 2"><msub><mi>E</mi> <mn>2</mn></msub></math> have occurred. On
    the right side, we have the same idea, but expressed slightly differently. In
    the universe where both events have occurred, one way to arrive in this universe
    is to first have <math alttext="upper E 2"><msub><mi>E</mi> <mn>2</mn></msub></math>
    occur, followed by <math alttext="upper E 1"><msub><mi>E</mi> <mn>1</mn></msub></math>
    . Porting this intuition into mathematical terms, we must first find the probability
    that <math alttext="upper E 2"><msub><mi>E</mi> <mn>2</mn></msub></math> has occurred,
    followed by the probability that <math alttext="upper E 1"><msub><mi>E</mi> <mn>1</mn></msub></math>
    has occurred in the universe where <math alttext="upper E 2"><msub><mi>E</mi>
    <mn>2</mn></msub></math> has already occurred. How do we combine these two probabilities?
    Intuitively, it makes sense that we multiply them—we must have both events occur,
    the first unconditionally and the second in the universe where the first has already
    occurred. Note that the order of these events doesn’t really matter, as both paths
    get us to the same universe. So, more completely, <math alttext="upper P left-parenthesis
    upper E 1 intersection upper E 2 right-parenthesis equals upper P left-parenthesis
    upper E 1 vertical-bar upper E 2 right-parenthesis asterisk upper P left-parenthesis
    upper E 2 right-parenthesis equals upper P left-parenthesis upper E 2 vertical-bar
    upper E 1 right-parenthesis asterisk upper P left-parenthesis upper E 1 right-parenthesis"><mrow><mi>P</mi>
    <mrow><mo>(</mo> <msub><mi>E</mi> <mn>1</mn></msub> <mo>∩</mo> <msub><mi>E</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi>
    <mn>1</mn></msub> <mo>|</mo> <msub><mi>E</mi> <mn>2</mn></msub> <mo>)</mo></mrow>
    <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>2</mn></msub> <mo>)</mo></mrow>
    <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>2</mn></msub> <mo>|</mo>
    <msub><mi>E</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>E</mi> <mn>1</mn></msub> <mo>)</mo></mrow></mrow></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: However, some of these paths make much more physical sense than others. For
    example, if we think of *<math alttext="upper E 1"><msub><mi>E</mi> <mn>1</mn></msub></math>*
    as the event where someone contracts a disease, and <math alttext="upper E 2"><msub><mi>E</mi>
    <mn>2</mn></msub></math> as the event where the patient shows symptoms of the
    disease, the path in which the patient contracts the disease and then shows symptoms
    makes much more physical sense than the reverse.
  prefs: []
  type: TYPE_NORMAL
- en: In the case where the two events are independent, we have that <math alttext="upper
    P left-parenthesis upper E 1 intersection upper E 2 right-parenthesis equals upper
    P left-parenthesis upper E 1 vertical-bar upper E 2 right-parenthesis asterisk
    upper P left-parenthesis upper E 2 right-parenthesis equals upper P left-parenthesis
    upper E 1 right-parenthesis asterisk upper P left-parenthesis upper E 2 right-parenthesis
    period"><mrow><mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>1</mn></msub> <mo>∩</mo>
    <msub><mi>E</mi> <mn>2</mn></msub> <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>E</mi> <mn>1</mn></msub> <mo>|</mo> <msub><mi>E</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>1</mn></msub>
    <mo>)</mo></mrow> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>E</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow> <mo>.</mo></mrow></math> Hopefully this makes some intuitive
    sense. In the independence scenario, the fact that <math alttext="upper E 2"><msub><mi>E</mi>
    <mn>2</mn></msub></math> has occurred doesn’t affect the chances of <math alttext="upper
    E 1"><msub><mi>E</mi> <mn>1</mn></msub></math> occurring; i.e., incorporating
    this information into the new universe doesn’t affect the probability of the next
    event. In the next section, we cover random variables, which are relevant summaries
    of events and also have their own probability distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Random Variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once again, let’s consider the coin flipping experiment. If we flip a coin some
    finite number of times, natural questions start to arise. How many heads did we
    encounter during our experiment? How many tails? How many tails until the first
    head? Every outcome in such an experiment has an answer to each of the listed
    questions. If we flip a coin say, five times, and we receive the sequence TTHHT,
    we have seen two heads, three tails, and two tails until the first head.
  prefs: []
  type: TYPE_NORMAL
- en: We can think of a *random variable* as a map, or a function, from the sample
    space to another space, such as the integers in [Figure 2-3](#the_random_variables_x_y_andz).
    Such a function would take as input the sequence TTHHT and output one of the three
    answers listed depending on the question we ask. The value that the random variable
    takes on would be the output associated with result of the experiment. Although
    random variables are deterministic in that they map a given input to a single
    output, they are not deterministic in that they also have a distribution associated
    with their output space. This is due to the inherent randomness in the experiment—depending
    on the probability of the input outcome, its corresponding output may be more
    or less likely than other outputs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/fdl2_0203.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-3\. Random variables X, Y, and Z all act on the same sample space,
    but have varying outputs. It’s important to keep in mind what you’re measuring!
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note that multiple inputs could map to the same output. For example, *X(HHH)*
    = 3 in addition to *X(HHTH)* in [Figure 2-3](#the_random_variables_x_y_andz).
  prefs: []
  type: TYPE_NORMAL
- en: One easy way to begin is to just think of this map as an identity function—whatever
    we flip or roll, its map in the output space is exactly the same as the input.
    Encoding a heads as a one and a tails as a zero, we can define a random variable
    representing the coin flip as whether the coin came up heads, i.e., *C(1) = 1,*
    where *C* is our random variable. In the dice scenario, the mapped output is the
    same as whatever we rolled, i.e., *D**(5) = 5,* where *D*is our random variable.
  prefs: []
  type: TYPE_NORMAL
- en: Why should we care about random variables and their distributions? It turns
    out they play a vital role in deep learning and machine learning as a whole. For
    example, in [Chapter 4](ch04.xhtml#training_feed_forward), we will cover the concept
    of *dropout*, a technique for mitigating overfitting in neural networks. The idea
    of a dropout layer is that, during training, it independently and at random masks
    every neuron in the previous layer with some probability. This prevents the network
    from becoming overly dependent on specific connections or subnetworks. We can
    think of every neuron in the previous layer as representing a coin flip-type experiment.
    The only difference is that we set the probability of this experiment, rather
    than a fair coin having the default probability <math alttext="one-half"><mfrac><mn>1</mn>
    <mn>2</mn></mfrac></math> of showing up either side. Each neuron has a random
    variable *X* associated with it, with input one if the dropout layer decides to
    mask it and zero otherwise. *X* is an identity function from the input space to
    the output space, i.e., *X(1) = 1* and *X(0) = 0\.*
  prefs: []
  type: TYPE_NORMAL
- en: Random variables, in general, need not be the identity map. Most functions you
    can think of are valid methods of mapping the input space to an output space where
    the random variable is defined. For example, if the input space were every possible
    length *n* sequence of coin flips, the function could be to count the number of
    heads in the sequence and square it. Some random variables can even be expressed
    as functions of other random variables, or a function of a function, as we will
    cover later. If we again consider the input space of every possible length *n*
    sequence of coin flips, the random variable counting the number of heads in the
    input sequence is the same as counting whether each individual coin flip turned
    up heads and taking a sum of all of those values. In mathematical terms, we say
    <math alttext="upper X equals sigma-summation Underscript i equals 1 Overscript
    n Endscripts upper C Subscript i"><mrow><mi>X</mi> <mo>=</mo> <msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup> <msub><mi>C</mi>
    <mi>i</mi></msub></mrow></math> , where *X* is the random variable representing
    the total number of heads, and <math alttext="upper C Subscript i"><msub><mi>C</mi>
    <mi>i</mi></msub></math> is the binary random variable associated with the *i*th
    coin flip. Back to the dropout example, we can think of the random variable representing
    the total number of masked-out neurons as the sum of binary random variables representing
    each neuron.
  prefs: []
  type: TYPE_NORMAL
- en: In the future, when we want to refer to the event where the random variable
    takes on a specific value *c* (the domain being the output space we’ve been referring
    to, e.g., the number of heads in a sequence of coin flips), we will write this
    concisely as *X = c*.We denote the probability that the random variable takes
    on a specific value as *P(X = c),* for example. The probability that the random
    variable takes on any given value in the output space is just the sum of the probabilities
    of the inputs that map to it. This should make some intuitive sense, as this is
    basically the fourth tenet of probability where the intersection between any two
    events is the empty set since all the events we start from are individual, distinct
    inputs. Note that *P(X)* itself is also a probability distribution that follows
    all the basic tenets of probability described in the first section. In the next
    section, we consider statistics regarding random variables.
  prefs: []
  type: TYPE_NORMAL
- en: Expectation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we discussed, a random variable is a map from input space to output space,
    where inputs are generated according to some probability distribution. The random
    variable can be thought of as a relevant summary of the input, and can take on
    many forms depending on the question we ask. Sometimes, it’s useful to understand
    statistics regarding the random variable. For example, if we flip a coin eight
    times, how many heads do we expect to see on average? And, of course, we don’t
    see the average number of heads all the time—how much does the number of heads
    we see tend to vary? The first quantity is what we call the random variable’s
    *expectation*, and the second is the random variable’s *variance*.
  prefs: []
  type: TYPE_NORMAL
- en: For a random variable *X*, we denote its expectation as <math alttext="double-struck
    upper E left-bracket upper X right-bracket"><mrow><mi>𝔼</mi> <mo>[</mo> <mi>X</mi>
    <mo>]</mo></mrow></math> . We can think of this as the average value that *X*
    takes on, weighted by the probability of each of those outcomes. Mathematically,
    this is written as <math alttext="double-struck upper E left-bracket upper X right-bracket
    equals sigma-summation Underscript o Endscripts o asterisk upper P left-parenthesis
    upper X equals o right-parenthesis"><mrow><mi>𝔼</mi> <mrow><mo>[</mo> <mi>X</mi>
    <mo>]</mo></mrow> <mo>=</mo> <msub><mo>∑</mo> <mi>o</mi></msub> <mi>o</mi> <mo>*</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>=</mo> <mi>o</mi> <mo>)</mo></mrow></mrow></math>
    . Note that if all outcomes *o* are equally likely, we get a simple average of
    all the outcomes. It makes sense to use the probability of the outcome as a weighting,
    since some outcomes are more likely than others, and the average value we observe
    will be skewed toward such outcomes. For a single fair coin flip, the expected
    number of heads would be <math alttext="sigma-summation Underscript o element-of
    StartSet 0 comma 1 EndSet Endscripts o asterisk upper P left-parenthesis o right-parenthesis
    equals 0 asterisk 0.5 plus 1 asterisk 0.5 equals 0.5"><mrow><msub><mo>∑</mo> <mrow><mi>o</mi><mo>∈</mo><mo>{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>}</mo></mrow></msub>
    <mi>o</mi> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>o</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mn>0</mn> <mo>*</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>+</mo> <mn>1</mn>
    <mo>*</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn> <mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>5</mn></mrow></math>
    . In other words, we’d expect to see half of a head for any given fair coin flip.
    Of course, this makes no physical sense in that we could never possibly flip half
    of a head, but this gives you an idea of the proportions we’d expect to see over
    a long run experiment.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to our example of length *n* sequences of coin flips, let’s try to
    find the expected number of heads in such a sequence. We have *n* + 1 possible
    number of heads, and according to our formula, we’d need to find the probability
    of attaining each possible number to use as our weights. Mathematically, we’d
    need to compute <math alttext="sigma-summation Underscript x element-of StartSet
    0 comma ellipsis comma n EndSet Endscripts x asterisk upper P left-parenthesis
    upper X equals x right-parenthesis"><mrow><msub><mo>∑</mo> <mrow><mi>x</mi><mo>∈</mo><mo>{</mo><mn>0</mn><mo>,</mo><mo>...</mo><mo>,</mo><mi>n</mi><mo>}</mo></mrow></msub>
    <mi>x</mi> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>=</mo> <mi>x</mi>
    <mo>)</mo></mrow></mrow></math> , where *X* is the random variable representing
    the total number of heads. However, as *n* gets larger and larger, performing
    this calculation starts to become more and more complicated.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, let’s denote <math alttext="upper X Subscript i"><msub><mi>X</mi> <mi>i</mi></msub></math>
    as the binary random variable for the *i*th coin flip and use the observation
    we made in the last section of being able to break up the total number of heads
    into a sum over heads/tails for all the individual coin flips. Since we know <math
    alttext="upper X equals upper X 1 plus upper X 2 plus ellipsis plus upper X Subscript
    n"><mrow><mi>X</mi> <mo>=</mo> <msub><mi>X</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>X</mi>
    <mn>2</mn></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>X</mi> <mi>n</mi></msub></mrow></math>
    , we can also say that <math alttext="double-struck upper E left-bracket upper
    X right-bracket equals double-struck upper E left-bracket upper X 1 plus upper
    X 2 plus ellipsis plus upper X Subscript n Baseline right-bracket"><mrow><mi>𝔼</mi>
    <mrow><mo>[</mo> <mi>X</mi> <mo>]</mo></mrow> <mo>=</mo> <mi>𝔼</mi> <mrow><mo>[</mo>
    <msub><mi>X</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>X</mi> <mn>2</mn></msub>
    <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>X</mi> <mi>n</mi></msub> <mo>]</mo></mrow></mrow></math>
    . How does making this substitution make our problem easier? We now introduce
    the concept of *linearity of expectation,* which states we can break up the right
    side into the sum <math alttext="double-struck upper E left-bracket upper X 1
    right-bracket plus double-struck upper E left-bracket upper X 2 right-bracket
    plus ellipsis plus double-struck upper E left-bracket upper X Subscript n Baseline
    right-bracket"><mrow><mi>𝔼</mi> <mrow><mo>[</mo> <msub><mi>X</mi> <mn>1</mn></msub>
    <mo>]</mo></mrow> <mo>+</mo> <mi>𝔼</mi> <mrow><mo>[</mo> <msub><mi>X</mi> <mn>2</mn></msub>
    <mo>]</mo></mrow> <mo>+</mo> <mo>...</mo> <mo>+</mo> <mi>𝔼</mi> <mrow><mo>[</mo>
    <msub><mi>X</mi> <mi>n</mi></msub> <mo>]</mo></mrow></mrow></math> . We know that
    the expected number of heads for each flip is 0.5, so the expected number of heads
    in a sequence of *n* flips is just 0.5**n*. This is much simpler than going down
    the previous route, as this approach’s difficulty does not scale with the number
    of flips.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go over the simplification we made in a bit more detail. Mathematically,
    if we have any two independent random variables *A* and *B*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="double-struck upper E left-bracket upper A plus upper B right-bracket
    equals sigma-summation Underscript a comma b Endscripts left-parenthesis a plus
    b right-parenthesis asterisk upper P left-parenthesis upper A equals a comma upper
    B equals b right-parenthesis"><mrow><mi>𝔼</mi> <mrow><mo>[</mo> <mi>A</mi> <mo>+</mo>
    <mi>B</mi> <mo>]</mo></mrow> <mo>=</mo> <msub><mo>∑</mo> <mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow></msub>
    <mrow><mo>(</mo> <mi>a</mi> <mo>+</mo> <mi>b</mi> <mo>)</mo></mrow> <mo>*</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mi>A</mi> <mo>=</mo> <mi>a</mi> <mo>,</mo> <mi>B</mi>
    <mo>=</mo> <mi>b</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals sigma-summation Underscript a comma b Endscripts left-parenthesis
    a plus b right-parenthesis asterisk upper P left-parenthesis upper A equals a
    right-parenthesis asterisk upper P left-parenthesis upper B equals b right-parenthesis"><mrow><mo>=</mo>
    <msub><mo>∑</mo> <mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>a</mi> <mo>+</mo> <mi>b</mi> <mo>)</mo></mrow> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo>
    <mi>A</mi> <mo>=</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo>
    <mi>B</mi> <mo>=</mo> <mi>b</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals sigma-summation Underscript a comma b Endscripts a asterisk
    upper P left-parenthesis upper A equals a right-parenthesis asterisk upper P left-parenthesis
    upper B equals b right-parenthesis plus b asterisk upper P left-parenthesis upper
    A equals a right-parenthesis asterisk upper P left-parenthesis upper B equals
    b right-parenthesis"><mrow><mo>=</mo> <msub><mo>∑</mo> <mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow></msub>
    <mi>a</mi> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>A</mi> <mo>=</mo> <mi>a</mi>
    <mo>)</mo></mrow> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>B</mi> <mo>=</mo>
    <mi>b</mi> <mo>)</mo></mrow> <mo>+</mo> <mi>b</mi> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo>
    <mi>A</mi> <mo>=</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo>
    <mi>B</mi> <mo>=</mo> <mi>b</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals sigma-summation Underscript a comma b Endscripts a asterisk
    upper P left-parenthesis upper A equals a right-parenthesis asterisk upper P left-parenthesis
    upper B equals b right-parenthesis plus sigma-summation Underscript a comma b
    Endscripts b asterisk upper P left-parenthesis upper A equals a right-parenthesis
    asterisk upper P left-parenthesis upper B equals b right-parenthesis"><mrow><mo>=</mo>
    <msub><mo>∑</mo> <mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow></msub> <mi>a</mi>
    <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>A</mi> <mo>=</mo> <mi>a</mi> <mo>)</mo></mrow>
    <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>B</mi> <mo>=</mo> <mi>b</mi> <mo>)</mo></mrow>
    <mo>+</mo> <msub><mo>∑</mo> <mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow></msub>
    <mi>b</mi> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>A</mi> <mo>=</mo> <mi>a</mi>
    <mo>)</mo></mrow> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>B</mi> <mo>=</mo>
    <mi>b</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals sigma-summation Underscript a Endscripts a asterisk upper
    P left-parenthesis upper A equals a right-parenthesis sigma-summation Underscript
    b Endscripts upper P left-parenthesis upper B equals b right-parenthesis plus
    sigma-summation Underscript b Endscripts b asterisk upper P left-parenthesis upper
    B equals b right-parenthesis sigma-summation Underscript a Endscripts upper P
    left-parenthesis upper A equals a right-parenthesis"><mrow><mo>=</mo> <msub><mo>∑</mo>
    <mi>a</mi></msub> <mi>a</mi> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>A</mi>
    <mo>=</mo> <mi>a</mi> <mo>)</mo></mrow> <msub><mo>∑</mo> <mi>b</mi></msub> <mi>P</mi>
    <mrow><mo>(</mo> <mi>B</mi> <mo>=</mo> <mi>b</mi> <mo>)</mo></mrow> <mo>+</mo>
    <msub><mo>∑</mo> <mi>b</mi></msub> <mi>b</mi> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo>
    <mi>B</mi> <mo>=</mo> <mi>b</mi> <mo>)</mo></mrow> <msub><mo>∑</mo> <mi>a</mi></msub>
    <mi>P</mi> <mrow><mo>(</mo> <mi>A</mi> <mo>=</mo> <mi>a</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals sigma-summation Underscript a Endscripts a asterisk upper
    P left-parenthesis upper A equals a right-parenthesis plus sigma-summation Underscript
    b Endscripts b asterisk upper P left-parenthesis upper B equals b right-parenthesis"><mrow><mo>=</mo>
    <msub><mo>∑</mo> <mi>a</mi></msub> <mi>a</mi> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo>
    <mi>A</mi> <mo>=</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>+</mo> <msub><mo>∑</mo>
    <mi>b</mi></msub> <mi>b</mi> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>B</mi>
    <mo>=</mo> <mi>b</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals double-struck upper E left-bracket upper A right-bracket
    plus double-struck upper E left-bracket upper B right-bracket"><mrow><mo>=</mo>
    <mi>𝔼</mi> <mo>[</mo> <mi>A</mi> <mo>]</mo> <mo>+</mo> <mi>𝔼</mi> <mo>[</mo> <mi>B</mi>
    <mo>]</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note that we made the independence assumption we talked about earlier in the
    chapter here when we broke up the probability of the event *A = a* and the event
    *B = b* into a product of the two individual probabilities. The rest of the derivation
    doesn’t require additional assumptions, so we recommend working through the algebra
    on your own. Although we won’t show this for the dependent case, linearity of
    expectation also holds for dependent random variables.
  prefs: []
  type: TYPE_NORMAL
- en: Going back to the dropout example, the expectation of the total number of masked
    neurons can be broken up into a sum of expectations over each neuron. The expected
    number of masked neurons, similarly to the expected number of heads in a sequence
    of coin flips, is *p*n,* where *p* is the probability of being masked (and the
    expectation of each individual binary random variable representing a neuron) and
    *n* is the number of neurons.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, we don’t always see the expected number of occurrences of an event
    in every repetition of an experiment. In some cases, such as the expected number
    of heads in a single, fair coin flip from earlier, we never see it! Next, we will
    quantify the average deviation, or variance, from the expected value we see in
    repetitions of an experiment.
  prefs: []
  type: TYPE_NORMAL
- en: Variance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We define the variance, or Var(*X*), as <math alttext="double-struck upper
    E left-bracket left-parenthesis upper X minus mu right-parenthesis squared right-bracket"><mrow><mi>𝔼</mi>
    <mo>[</mo> <msup><mrow><mo>(</mo><mi>X</mi><mo>-</mo><mi>μ</mi><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>]</mo></mrow></math> , where we let <math alttext="mu equals
    double-struck upper E left-bracket upper X right-bracket"><mrow><mi>μ</mi> <mo>=</mo>
    <mi>𝔼</mi> <mo>[</mo> <mi>X</mi> <mo>]</mo></mrow></math> . In plain English,
    this measure represents the average squared difference between the value *X* takes
    on and its expectation. Note that <math alttext="left-parenthesis upper X minus
    mu right-parenthesis squared"><msup><mrow><mo>(</mo><mi>X</mi><mo>-</mo><mi>μ</mi><mo>)</mo></mrow>
    <mn>2</mn></msup></math> itself is also a random variable since it is a function
    of a function (*X*), which is still a function. Although we won’t get into too
    much detail about why we use this formula in particular, we encourage you to think
    about why we don’t use a formula such as <math alttext="double-struck upper E
    left-bracket upper X minus mu right-bracket"><mrow><mi>𝔼</mi> <mo>[</mo> <mi>X</mi>
    <mo>-</mo> <mi>μ</mi> <mo>]</mo></mrow></math> instead. To obtain a slightly simpler
    form for the variance, we can perform the following simplification:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="double-struck upper E left-bracket left-parenthesis upper X minus
    mu right-parenthesis squared right-bracket equals double-struck upper E left-bracket
    upper X squared minus 2 mu upper X plus mu squared right-bracket"><mrow><mi>𝔼</mi>
    <mrow><mo>[</mo> <msup><mrow><mo>(</mo><mi>X</mi><mo>-</mo><mi>μ</mi><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>]</mo></mrow> <mo>=</mo> <mi>𝔼</mi> <mrow><mo>[</mo> <msup><mi>X</mi>
    <mn>2</mn></msup> <mo>-</mo> <mn>2</mn> <mi>μ</mi> <mi>X</mi> <mo>+</mo> <msup><mi>μ</mi>
    <mn>2</mn></msup> <mo>]</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals double-struck upper E left-bracket upper X squared right-bracket
    minus double-struck upper E left-bracket 2 mu upper X right-bracket plus double-struck
    upper E left-bracket mu squared right-bracket"><mrow><mo>=</mo> <mi>𝔼</mi> <mrow><mo>[</mo>
    <msup><mi>X</mi> <mn>2</mn></msup> <mo>]</mo></mrow> <mo>-</mo> <mi>𝔼</mi> <mrow><mo>[</mo>
    <mn>2</mn> <mi>μ</mi> <mi>X</mi> <mo>]</mo></mrow> <mo>+</mo> <mi>𝔼</mi> <mrow><mo>[</mo>
    <msup><mi>μ</mi> <mn>2</mn></msup> <mo>]</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals double-struck upper E left-bracket upper X squared right-bracket
    minus 2 mu double-struck upper E left-bracket upper X right-bracket plus mu squared"><mrow><mo>=</mo>
    <mi>𝔼</mi> <mrow><mo>[</mo> <msup><mi>X</mi> <mn>2</mn></msup> <mo>]</mo></mrow>
    <mo>-</mo> <mn>2</mn> <mi>μ</mi> <mi>𝔼</mi> <mrow><mo>[</mo> <mi>X</mi> <mo>]</mo></mrow>
    <mo>+</mo> <msup><mi>μ</mi> <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals double-struck upper E left-bracket upper X squared right-bracket
    minus 2 double-struck upper E left-bracket upper X right-bracket squared plus
    double-struck upper E left-bracket upper X right-bracket squared"><mrow><mo>=</mo>
    <mi>𝔼</mi> <mrow><mo>[</mo> <msup><mi>X</mi> <mn>2</mn></msup> <mo>]</mo></mrow>
    <mo>-</mo> <mn>2</mn> <mi>𝔼</mi> <msup><mrow><mo>[</mo><mi>X</mi><mo>]</mo></mrow>
    <mn>2</mn></msup> <mo>+</mo> <mi>𝔼</mi> <msup><mrow><mo>[</mo><mi>X</mi><mo>]</mo></mrow>
    <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals double-struck upper E left-bracket upper X squared right-bracket
    minus double-struck upper E left-bracket upper X right-bracket squared"><mrow><mo>=</mo>
    <mi>𝔼</mi> <mrow><mo>[</mo> <msup><mi>X</mi> <mn>2</mn></msup> <mo>]</mo></mrow>
    <mo>-</mo> <mi>𝔼</mi> <msup><mrow><mo>[</mo><mi>X</mi><mo>]</mo></mrow> <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a moment to go through each of these steps. In the first step, we
    fully express the random variable as all of its component terms via classic binomial
    expansion. In the second step, we perform linearity of expectation to break out
    the component terms into their own, individual expectations. In the third step,
    we note that <math alttext="mu"><mi>μ</mi></math> , or <math alttext="double-struck
    upper E left-bracket upper X right-bracket"><mrow><mi>𝔼</mi> <mo>[</mo> <mi>X</mi>
    <mo>]</mo></mrow></math> , and its square are both constants and thus can be pulled
    out of the surrounding expectation. They are constants since they are not a function
    of the value *X* takes on and are instead evaluated using the entire domain (the
    set of values *X* can take on). Constants can be seen as random variables that
    can take on only one value, which is the constant itself. Thus, their expectations,
    or the average value the random variable takes on, is the constant itself since
    we always see the constant. The final steps are algebraic manipulations that bring
    us to the simplified result. Let’s use this formula to find the variance of the
    binary random variable representing a single neuron under dropout, and *p* is
    the probability of the neuron being masked out:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="double-struck upper E left-bracket upper X squared right-bracket
    minus double-struck upper E left-bracket upper X right-bracket squared equals
    sigma-summation Underscript x element-of 0 comma 1 Endscripts x squared asterisk
    upper P left-parenthesis upper X equals x right-parenthesis minus left-parenthesis
    sigma-summation Underscript x element-of 0 comma 1 Endscripts x asterisk upper
    P left-parenthesis upper X equals x right-parenthesis right-parenthesis squared"><mrow><mi>𝔼</mi>
    <mrow><mo>[</mo> <msup><mi>X</mi> <mn>2</mn></msup> <mo>]</mo></mrow> <mo>-</mo>
    <mi>𝔼</mi> <msup><mrow><mo>[</mo><mi>X</mi><mo>]</mo></mrow> <mn>2</mn></msup>
    <mo>=</mo> <msub><mo>∑</mo> <mrow><mi>x</mi><mo>∈</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow></mrow></msub>
    <msup><mi>x</mi> <mn>2</mn></msup> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>X</mi>
    <mo>=</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>-</mo> <msup><mrow><mo>(</mo><msub><mo>∑</mo>
    <mrow><mi>x</mi><mo>∈</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow></mrow></msub>
    <mi>x</mi><mo>*</mo><mi>P</mi><mrow><mo>(</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>)</mo></mrow><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals sigma-summation Underscript x element-of 0 comma 1 Endscripts
    x squared asterisk upper P left-parenthesis upper X equals x right-parenthesis
    minus p squared"><mrow><mo>=</mo> <msub><mo>∑</mo> <mrow><mi>x</mi><mo>∈</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow></mrow></msub>
    <msup><mi>x</mi> <mn>2</mn></msup> <mo>*</mo> <mi>P</mi> <mrow><mo>(</mo> <mi>X</mi>
    <mo>=</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>-</mo> <msup><mi>p</mi> <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals p minus p squared"><mrow><mo>=</mo> <mi>p</mi> <mo>-</mo>
    <msup><mi>p</mi> <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals p left-parenthesis 1 minus p right-parenthesis"><mrow><mo>=</mo>
    <mi>p</mi> <mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>p</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'These simplifications should make sense. We know from [“Expectation”](#expectation_sect1)
    that the expectation of the binary random variable representing a neuron is just
    *p,* and the rest is algebraic simplifications. We highly encourage you to work
    through these derivations on your own. As we start to think about the random variable
    representing the number of masked neurons in the entire layer, we naturally ask
    the question of whether there exists a similar linearity property for variance
    as there does for expectation. Unfortunately, the property does not hold in general:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper V a r left-parenthesis upper A plus upper B right-parenthesis
    equals double-struck upper E left-bracket left-parenthesis upper A plus upper
    B right-parenthesis squared right-bracket minus double-struck upper E left-bracket
    upper A plus upper B right-bracket squared"><mrow><mi>V</mi> <mi>a</mi> <mi>r</mi>
    <mrow><mo>(</mo> <mi>A</mi> <mo>+</mo> <mi>B</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mi>𝔼</mi> <mrow><mo>[</mo> <msup><mrow><mo>(</mo><mi>A</mi><mo>+</mo><mi>B</mi><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>]</mo></mrow> <mo>-</mo> <mi>𝔼</mi> <msup><mrow><mo>[</mo><mi>A</mi><mo>+</mo><mi>B</mi><mo>]</mo></mrow>
    <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals double-struck upper E left-bracket upper A squared plus
    2 asterisk upper A asterisk upper B plus upper B squared right-bracket minus left-parenthesis
    double-struck upper E left-bracket upper A right-bracket plus double-struck upper
    E left-bracket upper B right-bracket right-parenthesis squared"><mrow><mo>=</mo>
    <mi>𝔼</mi> <mrow><mo>[</mo> <msup><mi>A</mi> <mn>2</mn></msup> <mo>+</mo> <mn>2</mn>
    <mo>*</mo> <mi>A</mi> <mo>*</mo> <mi>B</mi> <mo>+</mo> <msup><mi>B</mi> <mn>2</mn></msup>
    <mo>]</mo></mrow> <mo>-</mo> <msup><mrow><mo>(</mo><mi>𝔼</mi><mrow><mo>[</mo><mi>A</mi><mo>]</mo></mrow><mo>+</mo><mi>𝔼</mi><mrow><mo>[</mo><mi>B</mi><mo>]</mo></mrow><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals double-struck upper E left-bracket upper A squared right-bracket
    plus 2 double-struck upper E left-bracket upper A asterisk upper B right-bracket
    plus double-struck upper E left-bracket upper B squared right-bracket minus double-struck
    upper E left-bracket upper A right-bracket squared minus 2 double-struck upper
    E left-bracket upper A right-bracket double-struck upper E left-bracket upper
    B right-bracket minus double-struck upper E left-bracket upper B right-bracket
    squared"><mrow><mo>=</mo> <mi>𝔼</mi> <mrow><mo>[</mo> <msup><mi>A</mi> <mn>2</mn></msup>
    <mo>]</mo></mrow> <mo>+</mo> <mn>2</mn> <mi>𝔼</mi> <mrow><mo>[</mo> <mi>A</mi>
    <mo>*</mo> <mi>B</mi> <mo>]</mo></mrow> <mo>+</mo> <mi>𝔼</mi> <mrow><mo>[</mo>
    <msup><mi>B</mi> <mn>2</mn></msup> <mo>]</mo></mrow> <mo>-</mo> <mi>𝔼</mi> <msup><mrow><mo>[</mo><mi>A</mi><mo>]</mo></mrow>
    <mn>2</mn></msup> <mo>-</mo> <mn>2</mn> <mi>𝔼</mi> <mrow><mo>[</mo> <mi>A</mi>
    <mo>]</mo></mrow> <mi>𝔼</mi> <mrow><mo>[</mo> <mi>B</mi> <mo>]</mo></mrow> <mo>-</mo>
    <mi>𝔼</mi> <msup><mrow><mo>[</mo><mi>B</mi><mo>]</mo></mrow> <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals double-struck upper E left-bracket upper A squared right-bracket
    minus double-struck upper E left-bracket upper A right-bracket squared plus double-struck
    upper E left-bracket upper B squared right-bracket minus double-struck upper E
    left-bracket upper B right-bracket squared plus 2 double-struck upper E left-bracket
    upper A asterisk upper B right-bracket minus 2 double-struck upper E left-bracket
    upper A right-bracket double-struck upper E left-bracket upper B right-bracket"><mrow><mo>=</mo>
    <mi>𝔼</mi> <mrow><mo>[</mo> <msup><mi>A</mi> <mn>2</mn></msup> <mo>]</mo></mrow>
    <mo>-</mo> <mi>𝔼</mi> <msup><mrow><mo>[</mo><mi>A</mi><mo>]</mo></mrow> <mn>2</mn></msup>
    <mo>+</mo> <mi>𝔼</mi> <mrow><mo>[</mo> <msup><mi>B</mi> <mn>2</mn></msup> <mo>]</mo></mrow>
    <mo>-</mo> <mi>𝔼</mi> <msup><mrow><mo>[</mo><mi>B</mi><mo>]</mo></mrow> <mn>2</mn></msup>
    <mo>+</mo> <mn>2</mn> <mi>𝔼</mi> <mrow><mo>[</mo> <mi>A</mi> <mo>*</mo> <mi>B</mi>
    <mo>]</mo></mrow> <mo>-</mo> <mn>2</mn> <mi>𝔼</mi> <mrow><mo>[</mo> <mi>A</mi>
    <mo>]</mo></mrow> <mi>𝔼</mi> <mrow><mo>[</mo> <mi>B</mi> <mo>]</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals upper V a r left-parenthesis upper A right-parenthesis
    plus upper V a r left-parenthesis upper B right-parenthesis plus 2 left-parenthesis
    double-struck upper E left-bracket upper A asterisk upper B right-bracket minus
    double-struck upper E left-bracket upper A right-bracket double-struck upper E
    left-bracket upper B right-bracket right-parenthesis"><mrow><mo>=</mo> <mi>V</mi>
    <mi>a</mi> <mi>r</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>+</mo> <mi>V</mi> <mi>a</mi>
    <mi>r</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo> <mo>+</mo> <mn>2</mn> <mo>(</mo> <mi>𝔼</mi>
    <mo>[</mo> <mi>A</mi> <mo>*</mo> <mi>B</mi> <mo>]</mo> <mo>-</mo> <mi>𝔼</mi> <mo>[</mo>
    <mi>A</mi> <mo>]</mo> <mi>𝔼</mi> <mo>[</mo> <mi>B</mi> <mo>]</mo> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals upper V a r left-parenthesis upper A right-parenthesis
    plus upper V a r left-parenthesis upper B right-parenthesis plus 2 upper C o v
    left-parenthesis upper A comma upper B right-parenthesis"><mrow><mo>=</mo> <mi>V</mi>
    <mi>a</mi> <mi>r</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>+</mo> <mi>V</mi> <mi>a</mi>
    <mi>r</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo> <mo>+</mo> <mn>2</mn> <mi>C</mi> <mi>o</mi>
    <mi>v</mi> <mo>(</mo> <mi>A</mi> <mo>,</mo> <mi>B</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: As we can see from the last line, the final term in the expression, which we
    call the *covariance* between the two random variables, ruins our hope for linearity.
    However, covariance is another key concept in probability—the intuition for covariance
    is that it measures the dependence between two random variables. As one random
    variable more completely determines the value of another random variable (think
    of *A* as the number of heads in a sequence of coin flips and *B* as the number
    of tails in the same sequence of coin flips), the magnitude of the covariance
    increases. Thus, it stands to reason that if *A* and *B* are independent random
    variables, the covariance between them should be zero, and linearity should hold
    in this special case. We highly encourage you to work through the math and show
    this on your own.
  prefs: []
  type: TYPE_NORMAL
- en: Back to the dropout example, the variance of the total number of masked neurons
    can be broken up into a sum of variances over each neuron, since each neuron is
    masked independently. The variance of the number of masked neurons is *p(1 – p)*n,*
    where *p(1 – p)* is the variance for any given neuron and *n* is the number of
    neurons. Expectation and variance in dropout allow us to understand more deeply
    what we expect to see when applying such a layer in a deep neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Bayes’ Theorem
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Returning to our discussion on conditional probability, we noted that the probability
    of intersection between two events could be written as a product of a conditional
    distribution and a distribution over a single event. Let’s translate this into
    the language of random variables, now that we have introduced this new terminology.
    We denote *A* to be one random variable, and *B* to denote a second. Let *a* be
    a value that *A* can take on, and *b* be a value that *B* can take on. The analogy
    to the intersection operation for random variables is the *joint probability distribution
    P(A=a,B=b),* which denotes the event where *A = a* and *B = b.* We can think of
    *A = a* and *B = b* as individual events, and when we write *P(A = a,B = b)*,
    we are considering the probability that both events have occurred, i.e., their
    intersection <math alttext="upper P left-parenthesis upper A equals a intersection
    upper B equals b right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>=</mo>
    <mi>a</mi> <mo>∩</mo> <mi>B</mi> <mo>=</mo> <mi>b</mi> <mo>)</mo></mrow></math>
    . Note that we generally write the joint probability distribution as *P(A,B),*
    since this encompasses all possible joint settings of the random variables *A*
    and *B.*
  prefs: []
  type: TYPE_NORMAL
- en: 'We mentioned earlier that intersection operations could be written as the product
    of a conditional distribution and a distribution over a single event. Rewriting
    this in the format for random variables, we have *P(A = a,B = b) = P(A = a|B =
    b)P(B = b)*. And more generally, considering all possible joint settings of the
    two random variables, we have *P(A,B) = P(A|B)P(B).* We also discussed how there
    always exists a second way of writing this joint distribution as a product: *P(A
    = a,B = b) = P(B = b|A = a)P(A=a),* and more generally*, P(A,B) = P(B|A)P(A).*
    We noted that sometimes one of these paths makes more sense than the other. For
    example, in the case where symptoms are represented by *A* and disease is represented
    by *B,* the path in which *B* takes on a value *b*, and then *A* takes on a value
    *a* in that universe makes much more sense than the reverse since, biologically,
    people contract a disease first and only then show symptoms for that disease.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this doesn’t mean that the reverse isn’t useful. It is almost universally
    the case that people show up at a hospital with mild symptoms, and medical professionals
    must try to infer the most likely disease from these symptoms to effectively treat
    the underlying disease. *Bayes’ Theorem* gives us a way of calculating the probability
    of a disease given the observed symptoms. Since the same joint probability distribution
    can be written in the two ways mentioned in the previous paragraph, we have the
    following equality:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper B vertical-bar upper A right-parenthesis
    equals StartFraction upper P left-parenthesis upper A vertical-bar upper B right-parenthesis
    upper P left-parenthesis upper B right-parenthesis Over upper P left-parenthesis
    upper A right-parenthesis EndFraction"><mrow><mi>P</mi> <mrow><mo>(</mo> <mi>B</mi>
    <mo>|</mo> <mi>A</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>P</mi><mo>(</mo><mi>A</mi><mo>|</mo><mi>B</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>B</mi><mo>)</mo></mrow>
    <mrow><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If *B* represents disease, while *A* represents symptoms, this gives us a method
    for computing the likelihood of any disease given the observed symptoms. Let’s
    analyze the right side to see if the equality also makes intuitive sense. The
    likelihood of symptoms given the disease times the likelihood of the disease is
    just the joint distribution, which makes sense as the numerator here. The denominator
    is the likelihood of seeing those symptoms, which can also be expressed as a sum
    of the numerator over all possible diseases. This is an instance of a more general
    process called *marginalization,* or removing a subset of random variables from
    a joint distribution by summing over all possible configurations of the subset:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A right-parenthesis equals sigma-summation
    Underscript b Endscripts upper P left-parenthesis upper A comma upper B equals
    b right-parenthesis"><mrow><mi>P</mi> <mrow><mo>(</mo> <mi>A</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mo>∑</mo> <mi>b</mi></msub> <mi>P</mi> <mrow><mo>(</mo> <mi>A</mi>
    <mo>,</mo> <mi>B</mi> <mo>=</mo> <mi>b</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'In more concise terms, we have:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper B equals b Subscript q u e r y
    Baseline vertical-bar upper A right-parenthesis equals StartFraction upper P left-parenthesis
    upper B equals b Subscript q u e r y Baseline comma upper A right-parenthesis
    Over sigma-summation Underscript b Endscripts upper P left-parenthesis upper B
    equals b comma upper A right-parenthesis EndFraction"><mrow><mi>P</mi> <mrow><mo>(</mo>
    <mi>B</mi> <mo>=</mo> <msub><mi>b</mi> <mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi></mrow></msub>
    <mo>|</mo> <mi>A</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>P</mi><mo>(</mo><mi>B</mi><mo>=</mo><msub><mi>b</mi>
    <mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi></mrow></msub> <mo>,</mo><mi>A</mi><mo>)</mo></mrow>
    <mrow><msub><mo>∑</mo> <mi>b</mi></msub> <mi>P</mi><mrow><mo>(</mo><mi>B</mi><mo>=</mo><mi>b</mi><mo>,</mo><mi>A</mi><mo>)</mo></mrow></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Bayes’ Theorem is a very valuable application of probability in the real world,
    especially in the case of disease prediction. Additionally, if we replace the
    random variable for symptoms with a random variable representing the result of
    a test for a specific disease, and the random variable over all diseases with
    a random variable over presence of the specific disease, we can infer the likelihood
    of actually having a specific disease given a positive test for it using Bayes’
    Theorem. This is a common problem in most hospitals, and is especially relevant
    to epidemiology given the outbreak of COVID-19.
  prefs: []
  type: TYPE_NORMAL
- en: Entropy, Cross Entropy, and KL Divergence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Probability distributions, by definition, give us a way of comparing the likelihoods
    of various possible events. However, even if we know the most likely event (or
    events) that is to occur, when running the experiment we are bound to see all
    sorts of events. In this section, we first consider the problem of defining a
    single metric that encapsulates all of the uncertainty within a probability distribution,
    which we will define as the distribution’s *entropy*.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s set up the following scenario. I am a researcher who is running an experiment.
    The experiment could be something as simple as flipping a coin or rolling a dice.
    You are recording the results of the experiment. We are both in different rooms,
    but connected through a phone line. I run the experiment and receive a result,
    and communicate that result to you via the phone. You record that result in a
    notebook, where you pick some binary string representation of that result as what
    you write down. As a scribe, you are necessary in this situation—I may run hundreds
    of trials and my memory is limited, so I cannot remember the results of all of
    my trials.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if I roll a dice and neither of us knows anything about the fairness
    of the dice, you could denote the outcome one as “0,” two as “1,” three as “10,”
    four as “11,” five as “100,” and six as “101.” Whenever I communicate a result
    of the experiment to you, you add that result’s corresponding string representation
    to the end of the string consisting of all results so far. If I were to roll a
    one, followed by two twos, and finally a one, using the encoding scheme defined
    so far you would have written down “0110.”
  prefs: []
  type: TYPE_NORMAL
- en: After all runs of the experiment have ended, I have a meeting with you and try
    to decipher this string “0110” into a sequence of outcomes for use in my research.
    However, as the researcher, I am puzzled by this string—does it represent a one,
    followed by two twos, and finally a one? Or does it represent a one, followed
    by a two, followed by a three? Or even a one, followed by a four, followed by
    a one? It seems that there are at least a few possible translations of this string
    into outcomes using the encoding scheme.
  prefs: []
  type: TYPE_NORMAL
- en: To prevent this situation from ever occurring again, we decide to enforce some
    limitations on the binary strings you can use to represent outcomes. We use what
    is called a *prefix code*, which disallows binary string representations of different
    outcomes from being prefixes of each other. It’s not too difficult to see why
    this would result in a unique translation of string to outcomes. Let’s say we
    have a binary string, some prefix of which we have been able to successfully decode
    into a series of outcomes. To decode the rest of the string, or the suffix, we
    must first find the next outcome in the series. When we find a prefix of this
    suffix that translates to an outcome, we already know that, by definition, there
    is no smaller prefix that translates to a valid outcome. We now have a larger
    prefix of the binary string that has been successfully translated to a series
    of outcomes. We then recursively use this logic until we have reached the end
    of the string.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have some guidelines on string representations for outcomes, we
    redo the original experiment with one as “0,” two as “10,” three as “110,” four
    as “1110,” five as “11110,” and six as “111110.” However, as noted earlier, I
    may carry out hundreds of trials, and as the scribe you probably want to limit
    the amount of writing you have to do. With no information about the dice, we can’t
    do too much better than this. Assuming each outcome shows up with probability
    <math alttext="one-sixth"><mfrac><mn>1</mn> <mn>6</mn></mfrac></math> , the expected
    number of letters you’d need to write down per trial is 3.5\. We could get down
    to 3 if we set one as “000,” two as “001,” three as “010,” four as “011,” five
    as “100,” and six as “101,” for example.
  prefs: []
  type: TYPE_NORMAL
- en: But what if we knew information about the dice? For example, what if it were
    a weighted dice that showed up six almost all of the time? In that case, you probably
    want to assign a shorter binary string to six, for example “0” (instead of assigning
    “0” to one) so you can limit the expected amount of writing you have to do. It
    makes intuitive sense that, as the result of any single trial becomes more and
    more certain, the expected number of characters you’d need to write becomes lower
    by assigning the shortest binary strings to the most likely outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This raises the question: given a probability distribution over outcomes, what
    is the optimal encoding scheme, where optimal is defined as the fewest expected
    number of characters you’d need to write per trial? Although this whole situation
    may feel a bit contrived, it provides us with a slightly different lens through
    which we can understand the uncertainty within a probability distribution. As
    we noted, as the result of an experiment becomes more and more certain, the optimal
    encoding scheme would allow the scribe to write fewer and fewer characters in
    expectation per trial. For example, in the extreme case where we already knew
    beforehand that a six would always show up, the scribe wouldn’t need to write
    anything down.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It turns out that, although we won’t show it here, the best you can do is assign
    a binary string of length <math alttext="log Subscript 2 Baseline StartFraction
    1 Over p left-parenthesis x Subscript i Baseline right-parenthesis EndFraction"><mrow><msub><mo
    form="prefix">log</mo> <mn>2</mn></msub> <mfrac><mn>1</mn> <mrow><mi>p</mi><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow></mfrac></mrow></math> to each possible outcome
    <math alttext="x Subscript i"><msub><mi>x</mi> <mi>i</mi></msub></math> , where
    <math alttext="p left-parenthesis x Subscript i Baseline right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow></math> is its
    probability. The expected string length of any given trial would then be:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="double-struck upper E Subscript p left-parenthesis x right-parenthesis
    Baseline left-bracket log Subscript 2 Baseline StartFraction 1 Over p left-parenthesis
    x right-parenthesis EndFraction right-bracket equals sigma-summation Underscript
    x Subscript i Baseline Endscripts p left-parenthesis x Subscript i Baseline right-parenthesis
    log Subscript 2 Baseline StartFraction 1 Over p left-parenthesis x Subscript i
    Baseline right-parenthesis EndFraction"><mrow><msub><mi>𝔼</mi> <mrow><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></msub>
    <mrow><mo>[</mo> <msub><mo form="prefix">log</mo> <mn>2</mn></msub> <mfrac><mn>1</mn>
    <mrow><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac> <mo>]</mo></mrow>
    <mo>=</mo> <msub><mo>∑</mo> <msub><mi>x</mi> <mi>i</mi></msub></msub> <mi>p</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <msub><mo
    form="prefix">log</mo> <mn>2</mn></msub> <mfrac><mn>1</mn> <mrow><mi>p</mi><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals minus sigma-summation Underscript x Subscript i Baseline
    Endscripts p left-parenthesis x Subscript i Baseline right-parenthesis log Subscript
    2 Baseline p left-parenthesis x Subscript i Baseline right-parenthesis"><mrow><mo>=</mo>
    <mo>-</mo> <msub><mo>∑</mo> <msub><mi>x</mi> <mi>i</mi></msub></msub> <mi>p</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <msub><mo
    form="prefix">log</mo> <mn>2</mn></msub> <mi>p</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This expression is defined as the *entropy* of a probability distribution. In
    the case where we are completely certain of the final outcome (e.g., the dice
    always lands up six), we can evaluate the expression for entropy and see that
    we get a result of 0.
  prefs: []
  type: TYPE_NORMAL
- en: In the case where we are completely certain of the final outcome (e.g., the
    dice always lands up six), we can evaluate the expression for entropy and see
    that we get a result of 0\. Additionally, the probability distribution that has
    the highest entropy is the one that places equal probability over all possible
    outcomes. This is because, for any given trial, we are no more certain that a
    particular outcome will appear as opposed to any other outcome. As a result, we
    cannot use the strategy of assigning a shorter string to any single outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have defined entropy, we can discuss cross entropy, which provides
    us a way of measuring the distinctness of two distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Equation 2-1\. Cross entropy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: <math alttext="upper C upper E left-parenthesis p StartAbsoluteValue EndAbsoluteValue
    q right-parenthesis equals double-struck upper E Subscript p left-parenthesis
    x right-parenthesis Baseline left-bracket log Subscript 2 Baseline StartFraction
    1 Over q left-parenthesis x right-parenthesis EndFraction right-bracket equals
    sigma-summation Underscript x Endscripts p left-parenthesis x right-parenthesis
    log Subscript 2 Baseline StartFraction 1 Over q left-parenthesis x right-parenthesis
    EndFraction equals minus sigma-summation Underscript x Endscripts p left-parenthesis
    x right-parenthesis log Subscript 2 Baseline q left-parenthesis x right-parenthesis"><mrow><mi>C</mi>
    <mi>E</mi> <mrow><mo>(</mo> <mi>p</mi> <mo>|</mo> <mo>|</mo> <mi>q</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mi>𝔼</mi> <mrow><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></msub>
    <mrow><mo>[</mo> <msub><mo form="prefix">log</mo> <mn>2</mn></msub> <mfrac><mn>1</mn>
    <mrow><mi>q</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac> <mo>]</mo></mrow>
    <mo>=</mo> <msub><mo>∑</mo> <mi>x</mi></msub> <mi>p</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <msub><mo form="prefix">log</mo> <mn>2</mn></msub> <mfrac><mn>1</mn>
    <mrow><mi>q</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac> <mo>=</mo> <mo>-</mo>
    <msub><mo>∑</mo> <mi>x</mi></msub> <mi>p</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <msub><mo form="prefix">log</mo> <mn>2</mn></msub> <mrow><mi>q</mi> <mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Note that cross entropy has a <math alttext="log StartFraction 1 Over q left-parenthesis
    x right-parenthesis EndFraction"><mrow><mo form="prefix">log</mo> <mfrac><mn>1</mn>
    <mrow><mi>q</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac></mrow></math> term,
    which can be interpreted as the optimal binary string length assigned to each
    outcome, assuming outcomes appear according to probability distribution *q(x)*.
    However, note that this is an expectation with respect to *p(x)*, so how do we
    interpret this entire expression? Well, we can understand the cross entropy to
    mean the expected string length for any trial given we have optimized for the
    encoding scheme for distribution *q(x)* while, in reality, all of the outcomes
    are appearing according to the distribution *p(x)*. This can definitely happen
    in an experiment where we have only limited a priori information about the experiment,
    so we assume some distribution *q(x)* to optimize our encoding scheme, but as
    we carry out trials, we learn more information that gets us closer to the true
    distribution *p(x)*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The KL divergence takes this logic a bit further. If we take the cross entropy,
    which tells us the expected number of bits per trial given we have optimized our
    encoding for the incorrect distribution *q(x),* and subtract from that the entropy,
    which tells us the expected number of bits per trial given we have optimized for
    the correct distribution *p(x*), we get the expected number of extra bits required
    to represent a trial when using *q(x)* compared to *p(x)*. Here is the expression
    for the KL divergence:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper K upper L left-parenthesis p StartAbsoluteValue EndAbsoluteValue
    q right-parenthesis equals double-struck upper E Subscript p left-parenthesis
    x right-parenthesis Baseline left-bracket log Subscript 2 Baseline StartFraction
    1 Over q left-parenthesis x right-parenthesis EndFraction minus log Subscript
    2 Baseline StartFraction 1 Over p left-parenthesis x right-parenthesis EndFraction
    right-bracket equals double-struck upper E Subscript p left-parenthesis x right-parenthesis
    Baseline left-bracket log Subscript 2 Baseline StartFraction p left-parenthesis
    x right-parenthesis Over q left-parenthesis x right-parenthesis EndFraction right-bracket"><mrow><mi>K</mi>
    <mi>L</mi> <mrow><mo>(</mo> <mi>p</mi> <mo>|</mo> <mo>|</mo> <mi>q</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msub><mi>𝔼</mi> <mrow><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></msub>
    <mrow><mo>[</mo> <msub><mo form="prefix">log</mo> <mn>2</mn></msub> <mfrac><mn>1</mn>
    <mrow><mi>q</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac> <mo>-</mo> <msub><mo
    form="prefix">log</mo> <mn>2</mn></msub> <mfrac><mn>1</mn> <mrow><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac>
    <mo>]</mo></mrow> <mo>=</mo> <msub><mi>𝔼</mi> <mrow><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></msub>
    <mrow><mo>[</mo> <msub><mo form="prefix">log</mo> <mn>2</mn></msub> <mfrac><mrow><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow>
    <mrow><mi>q</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac> <mo>]</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: At the unique global minimum *q(x)* = *p(x)*, the KL divergence is exactly zero.
    Why this is the unique minimum is a bit beyond the scope of this text, so we leave
    that as an exercise for you.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, when trying to match the true distribution *p(x)* with a learned
    distribution *q(x)*, KL divergence is often minimized as an objective function.
    Most models will actually minimize the cross entropy in place of the KL divergence,
    which is effectively the same optimization problem due to the KL being a difference
    between the cross entropy and the entropy of *p(x)*, where the entropy of *p(x)*
    is a constant and has no dependence on the weights that parameterize *q(x)*. Thus,
    the gradient with respect to the weights that parameterize *q(x)* when using either
    objective is the same.
  prefs: []
  type: TYPE_NORMAL
- en: One common example where cross-entropy/KL divergence is optimized is in the
    standard training of a neural network classifier. The neural network’s objective
    is to learn a distribution over target classes such that, for any given example
    *x[i]*, <math alttext="p Subscript theta Baseline left-parenthesis y vertical-bar
    x equals x Subscript i Baseline right-parenthesis"><mrow><msub><mi>p</mi> <mi>θ</mi></msub>
    <mrow><mo>(</mo> <mi>y</mi> <mo>|</mo> <mi>x</mi> <mo>=</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math> matches the true distribution
    *p(y|x* *= x[i])*, which has all of its probability mass placed over the true
    label *y[i]* and zero probability over all other classes. Minimizing the sum of
    cross entropies between the learned distribution and the true distribution over
    all examples is actually the exact same as minimizing the negative log likelihood
    of the data. Both are valid interpretations of how neural networks are trained,
    and lead to the same objective function. We encourage you to try writing out both
    expressions independently to see this.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Probability Distributions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have looked at probability distributions through the lens of discrete
    outcomes and events. However, as it turns out, probability distributions aren’t
    just for sets of discrete outcomes like the CIFAR-10 target classes or the MNIST
    digits. We can define probability distributions over sample spaces of infinite
    size, such as all the real numbers. In this section, we will extend principles
    covered in the previous sections to the continuous realm.
  prefs: []
  type: TYPE_NORMAL
- en: In the continuous realm, probability distributions are often referred to as
    *probability density functions*, or PDFs. PDFs are nonnegative functions over
    a sample space, such as all the reals, that integrate to one. Recall from calculus
    that the integration of a function is the area of the region underneath the function,
    bounded by the *x*-axis. PDFs follow the basic tenets introduced in the first
    section, but instead of adding the probability of outcomes to get the probability
    of an event, we use integration. For example, say *X* is a continuous random variable
    that is defined over all the real numbers. If we’d like to know the probability
    of the event <math alttext="upper P left-parenthesis upper X less-than-or-equal-to
    2 right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>X</mi> <mo>≤</mo> <mn>2</mn>
    <mo>)</mo></mrow></math> , all we’d need to do is integrate the PDF of *X* from
    negative infinity to 2.
  prefs: []
  type: TYPE_NORMAL
- en: But how about the probability of any individual outcome, say *P*(*X* = 2)? Since
    we use integration to find probabilities in the continuous space, the probability
    of any individual outcome is actually zero due to the width of the region being
    infinitesimal. We instead use the term *likelihood* to distinguish between the
    probability of events and the value that the PDF evaluates to when we input a
    setting of *X*. Likelihoods are still valuable, as they tell us what individual
    outcomes we are most likely to see when performing an experiment over a continuous
    space. Going forward, when considering continuous probability distributions, we
    will only refer to events as having probability, rather than individual outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: One famous example of a continuous probability distribution is the *uniform
    distribution* over some interval on the real line. Under the uniform distribution,
    the likelihood of each outcome is the same, meaning that no outcome is any more
    likely to appear than another. Thus, the uniform distribution looks like a rectangle,
    where the base of the rectangle is the interval constituting its domain, and the
    height, or the likelihood for each outcome, is the value that makes the area of
    the rectangle equal to one. [Figure 2-4](#c299) shows the uniform distribution
    over the interval [0,0.5].
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/fdl2_0204.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-4\. The uniform distribution has uniform height over its entire area,
    which shows that each value in the domain of the distribution has equal likelihood.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This example was chosen specifically to show a concrete difference between likelihoods
    and probabilities in the continuous realm. The height of the rectangle being 2
    was no error—there is no constraint on the magnitude of the likelihood in continuous
    distributions, unlike probabilities, which must be less than or equal to 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another famous example of a continuous probability distribution is the *Gaussian
    distribution*, which is one of the more common ways in which data presents itself
    in the real world. The Gaussian distribution is defined by two parameters: its
    mean <math alttext="mu"><mi>μ</mi></math> and its standard deviation <math alttext="sigma"><mi>σ</mi></math>
    . The PDF of a Gaussian distribution is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="f left-parenthesis x semicolon mu comma sigma right-parenthesis
    equals StartFraction 1 Over sigma StartRoot 2 pi EndRoot EndFraction e Superscript
    minus one-half left-parenthesis StartFraction x minus mu Over sigma EndFraction
    right-parenthesis squared"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>;</mo>
    <mi>μ</mi> <mo>,</mo> <mi>σ</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mn>1</mn>
    <mrow><mi>σ</mi><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt></mrow></mfrac>
    <msup><mi>e</mi> <mrow><mo>-</mo><mfrac><mn>1</mn> <mn>2</mn></mfrac><msup><mrow><mo>(</mo><mfrac><mrow><mi>x</mi><mo>-</mo><mi>μ</mi></mrow>
    <mi>σ</mi></mfrac><mo>)</mo></mrow> <mn>2</mn></msup></mrow></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Why this function integrates to 1 over the real domain is beyond the scope of
    this chapter, but one important characteristic of a Gaussian distribution is that
    its mean is also its unique mode. In other words, the outcome with the highest
    likelihood is also, uniquely, the mean outcome. This is not the case for all distributions.
    For example, [Figure 2-4](#c299) does not have this property. The graph of a standard
    Gaussian, which has mean zero and unit variance, is shown in [Figure 2-5](#c302)
    (the PDF asymptotically reaches zero in the limit in both directions).
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/fdl2_0205.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-5\. The Gaussian distribution has a bell shape, with highest likelihood
    in the center and dropping exponentially as the value in question gets farther
    and farther from the center.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Why is the Gaussian distribution so prevalent in real-world data? One reason
    for this is a theorem called the *Central Limit Theorem* (CLT). This theorem states
    that sums of independent random variables converge to a Gaussian distribution
    as the number of variables in the sum goes to infinity, even if each variable
    is not distributed as a Gaussian. One example is the number of masked neurons
    after a dropout layer is applied. As the number of neurons from the previous layer
    goes to infinity, the number of masked neurons (which is a sum of independent
    Bernoulli random variables, as discussed in [“Random Variables”](#random-variablesonce)),
    when standardized correctly, is approximately distributed as a standard Gaussian
    distribution. We won’t cover CLT in much depth here, but it has more recently
    been extended to weakly dependent variables under certain special conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Many real-world datasets can be seen as approximately sums of many random variables.
    For example, the distribution of a disease prevalence within a given population,
    similarly to the number of masked neurons after applying dropout, is the sum of
    many Bernoulli random variables (where each person is a Bernoulli random variable
    that has a value of 1 if they have the disease and a value of 0 if they do not)—although
    likely dependent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Continuous random variables are still functions, just as we defined discrete
    random variables. The only difference is that the range of this function is a
    continuous space. To compute the expectation and variance of a continuous random
    variable, all we need to do is replace our summations with integrations, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="double-struck upper E left-bracket upper X right-bracket equals
    integral Underscript x Endscripts x asterisk f left-parenthesis upper X equals
    x right-parenthesis d x"><mrow><mi>𝔼</mi> <mrow><mo>[</mo> <mi>X</mi> <mo>]</mo></mrow>
    <mo>=</mo> <msub><mo>∫</mo> <mi>x</mi></msub> <mi>x</mi> <mo>*</mo> <mi>f</mi>
    <mrow><mo>(</mo> <mi>X</mi> <mo>=</mo> <mi>x</mi> <mo>)</mo></mrow> <mi>d</mi>
    <mi>x</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper V a r left-parenthesis upper X right-parenthesis equals
    integral Underscript x Endscripts left-parenthesis x minus double-struck upper
    E left-bracket upper X right-bracket right-parenthesis squared asterisk f left-parenthesis
    upper X equals x right-parenthesis d x"><mrow><mi>V</mi> <mi>a</mi> <mi>r</mi>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <msub><mo>∫</mo> <mi>x</mi></msub>
    <msup><mrow><mo>(</mo><mi>x</mi><mo>-</mo><mi>𝔼</mi><mrow><mo>[</mo><mi>X</mi><mo>]</mo></mrow><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>*</mo> <mi>f</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>=</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mi>d</mi> <mi>x</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, let’s evaluate the expectation for our uniform random variable
    defined earlier. But first, confirm that it makes intuitive sense that the expectation
    should be 0.25, since the endpoints of the interval are 0 and 0.5 and all values
    in between are of equal likelihood. Now, let’s evaluate the integral and see if
    the computation matches our intuition:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="integral Subscript 0 Superscript 0.5 Baseline x asterisk f left-parenthesis
    x right-parenthesis d x equals integral Subscript 0 Superscript 0.5 Baseline 2
    x d x"><mrow><msubsup><mo>∫</mo> <mn>0</mn> <mrow><mn>0</mn><mo>.</mo><mn>5</mn></mrow></msubsup>
    <mi>x</mi> <mo>*</mo> <mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mi>d</mi> <mi>x</mi> <mo>=</mo> <msubsup><mo>∫</mo> <mn>0</mn> <mrow><mn>0</mn><mo>.</mo><mn>5</mn></mrow></msubsup>
    <mn>2</mn> <mi>x</mi> <mi>d</mi> <mi>x</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals x squared vertical-bar Subscript 0 Baseline Superscript
    0.5 Baseline"><mrow><mo>=</mo> <msup><mi>x</mi> <mn>2</mn></msup> <msubsup><mrow><mo>|</mo></mrow>
    <mn>0</mn> <mrow><mn>0</mn><mo>.</mo><mn>5</mn></mrow></msubsup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="equals 0.25"><mrow><mo>=</mo> <mn>0</mn> <mo>.</mo> <mn>25</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Where the superscript and the subscript of the | symbol represent the values
    at which we will evaluate the preceding function, which we will then difference
    to get the value of the integral. We see that the expectation comes out to the
    same value as our intuition, which is a great sanity check.
  prefs: []
  type: TYPE_NORMAL
- en: 'Bayes’ Theorem also holds for continuous variables. The only major difference
    is when marginalizing out a subset of variables, you will need to integrate over
    the entire domain of the marginalized subset rather than taking a discrete sum
    over all possible configurations of the marginalized subset. Again, this is an
    example of extending the tenets of probability to the continuous space by replacing
    summations with integrations. Here is Bayes’ Theorem for continuous probability
    distributions, following the notation from [“Bayes’ Theorem”](#bayes-theorem-sect):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper B equals b Subscript q u e r y
    Baseline vertical-bar upper A right-parenthesis equals StartFraction upper P left-parenthesis
    upper A vertical-bar upper B equals b Subscript q u e r y Baseline right-parenthesis
    upper P left-parenthesis upper B equals b Subscript q u e r y Baseline right-parenthesis
    Over upper P left-parenthesis upper A right-parenthesis EndFraction equals StartFraction
    upper P left-parenthesis upper A vertical-bar upper B equals b Subscript q u e
    r y Baseline right-parenthesis upper P left-parenthesis upper B equals b Subscript
    q u e r y Baseline right-parenthesis Over integral Underscript b Endscripts upper
    P left-parenthesis upper A comma upper B equals b right-parenthesis d b EndFraction"><mrow><mi>P</mi>
    <mrow><mo>(</mo> <mi>B</mi> <mo>=</mo> <msub><mi>b</mi> <mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi></mrow></msub>
    <mo>|</mo> <mi>A</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>P</mi><mrow><mo>(</mo><mi>A</mi><mo>|</mo><mi>B</mi><mo>=</mo><msub><mi>b</mi>
    <mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi></mrow></msub> <mo>)</mo></mrow><mi>P</mi><mrow><mo>(</mo><mi>B</mi><mo>=</mo><msub><mi>b</mi>
    <mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi></mrow></msub> <mo>)</mo></mrow></mrow>
    <mrow><mi>P</mi><mo>(</mo><mi>A</mi><mo>)</mo></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>P</mi><mrow><mo>(</mo><mi>A</mi><mo>|</mo><mi>B</mi><mo>=</mo><msub><mi>b</mi>
    <mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi></mrow></msub> <mo>)</mo></mrow><mi>P</mi><mrow><mo>(</mo><mi>B</mi><mo>=</mo><msub><mi>b</mi>
    <mrow><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi></mrow></msub> <mo>)</mo></mrow></mrow>
    <mrow><msub><mo>∫</mo> <mi>b</mi></msub> <mi>P</mi><mrow><mo>(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo>=</mo><mi>b</mi><mo>)</mo></mrow><mi>d</mi><mi>b</mi></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'And finally, we have our discussion on entropy, cross entropy, and KL divergence.
    All three of these extend nicely to the continuous space as well. We replace our
    summations with integrations and note that the properties introduced in the previous
    section still hold. For example, over a given domain, the distribution with the
    highest entropy is the uniform distribution, and the KL divergence between two
    distributions is zero if and only if the two distributions are the exact same.
    Here are the definitions in their continuous form, following [Equation 2-1](#cross-entropy-formula):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis f left-parenthesis x right-parenthesis
    right-parenthesis equals minus integral Underscript x Endscripts f left-parenthesis
    x right-parenthesis log Subscript 2 Baseline f left-parenthesis x right-parenthesis
    d x"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>f</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <msub><mo>∫</mo> <mi>x</mi></msub>
    <mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <msub><mo form="prefix">log</mo>
    <mn>2</mn></msub> <mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mi>d</mi>
    <mi>x</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper K upper L left-parenthesis f left-parenthesis x right-parenthesis
    StartAbsoluteValue EndAbsoluteValue g left-parenthesis x right-parenthesis right-parenthesis
    equals integral Underscript x Endscripts f left-parenthesis x right-parenthesis
    log Subscript 2 Baseline StartFraction f left-parenthesis x right-parenthesis
    Over g left-parenthesis x right-parenthesis EndFraction d x"><mrow><mi>K</mi>
    <mi>L</mi> <mrow><mo>(</mo> <mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>|</mo> <mo>|</mo> <mi>g</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <msub><mo>∫</mo> <mi>x</mi></msub> <mi>f</mi> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <msub><mo form="prefix">log</mo> <mn>2</mn></msub>
    <mfrac><mrow><mi>f</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow> <mrow><mi>g</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac>
    <mi>d</mi> <mi>x</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper C upper E left-parenthesis f left-parenthesis x right-parenthesis
    StartAbsoluteValue EndAbsoluteValue g left-parenthesis x right-parenthesis right-parenthesis
    equals minus integral Underscript x Endscripts f left-parenthesis x right-parenthesis
    log Subscript 2 Baseline g left-parenthesis x right-parenthesis d x"><mrow><mi>C</mi>
    <mi>E</mi> <mrow><mo>(</mo> <mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>|</mo> <mo>|</mo> <mi>g</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <msub><mo>∫</mo> <mi>x</mi></msub> <mi>f</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <msub><mo form="prefix">log</mo>
    <mn>2</mn></msub> <mi>g</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mi>d</mi>
    <mi>x</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Our extension of these concepts to the continuous space will come in handy in
    [Chapter 10](ch10.xhtml#ch10), where we model many distributions as Gaussians.
    Additionally, we use the KL divergence/cross-entropy terms as a regularization
    procedure on the complexity of one of our learned distributions. Since KL divergence
    is only zero when the query distribution matches the target distribution, setting
    the target distribution to a Gaussian forces the learned distribution to approximate
    a Gaussian.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter we covered the fundamentals of probability, first building the
    intuition behind the basics of probability distributions and then moving to relevant
    applications of probability, such as conditional probability, random variables,
    expectation, and variance. We saw the applications of probability in deep learning,
    such as how a neural net parametrizes a probability distribution during classification
    tasks, and how we can quantify the mathematical properties of dropout, a regularization
    technique in neural nets. Finally, we discussed measurements of uncertainty in
    probability distributions such as entropy, and generalized these concepts to the
    continuous realm.
  prefs: []
  type: TYPE_NORMAL
- en: Probability is a field that affects the choices in our everyday lives, and it’s
    key to understand the meaning behind the numbers. Additionally, we hope that this
    introduction puts the rest of the book in perspective and allows you to more rigorously
    understand future concepts. In the next chapter, we will discuss the structure
    of neural networks, and the motivations behind their design.
  prefs: []
  type: TYPE_NORMAL
