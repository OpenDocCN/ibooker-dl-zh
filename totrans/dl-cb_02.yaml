- en: Chapter 2\. Getting Unstuck
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deep learning models are often treated as a black box; we pour data in at one
    end and an answer comes out at the other without us having to care much about
    how our network learns. While it is true that deep neural nets can be remarkably
    good at distilling a signal out of complex input data, the flip side of treating
    these networks as black boxes is that it isn’t always clear what to do when things
    get stuck.
  prefs: []
  type: TYPE_NORMAL
- en: A common theme among the techniques we discuss here is that we want the network
    to *generalize* rather than to *memorize*. It is worth pondering the question
    of why neural networks generalize at all. Some of the models described in this
    book and used in production contain millions of parameters that would allow the
    network to memorize inputs with very many examples. If everything goes well, though,
    it doesn’t do this, but rather develops generalized rules about its input.
  prefs: []
  type: TYPE_NORMAL
- en: If things don’t go well, you can try the techniques described in this chapter.
    We’ll start out by looking at how we know that we’re stuck. We’ll then look at
    various ways in which we can preprocess our input data to make it easier for the
    network to work with.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Determining That You Are Stuck
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do you know when your network is stuck?
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Look at various metrics while the network trains.
  prefs: []
  type: TYPE_NORMAL
- en: The most common signs that things are not well with a neural network are that
    the network is not learning anything or that it is learning the wrong thing. When
    we set up the network, we specify the *loss function*. This determines what the
    network is trying to optimize for. During training the loss is continuously printed.
    If this value doesn’t go down after a few iterations, we’re in trouble. The network
    is not learning anything measured by its own notion of progress.
  prefs: []
  type: TYPE_NORMAL
- en: A second metric that comes in handy is *accuracy*. This shows the percentage
    of the inputs for which the network is predicting the right answer. As the loss
    goes down, the accuracy should go up. If accuracy does not go up even though the
    loss is decreasing, then our network is learning something, but not the thing
    we were hoping for. Accuracy can take a while, though, to pick up. A complex visual
    network will take a long time before it gets any labels right while still learning,
    so take this into account before giving up prematurely.
  prefs: []
  type: TYPE_NORMAL
- en: The third thing to look for, and this is probably the most common way to get
    stuck, is *overfitting*. With overfitting we see our loss decrease and our accuracy
    increase, but the accuracy we see over our testing set doesn’t keep up. Assuming
    we have a testing set and have added this to the metrics to track, we can see
    this each time an epoch finishes. Typically the testing accuracy at first increases
    with the accuracy of the training set, but then a gap appears, and oftentimes
    the testing accuracy even starts to drop while the training accuracy keeps increasing.
  prefs: []
  type: TYPE_NORMAL
- en: What’s happening here is that our network is learning a direct mapping between
    the inputs and the expected outputs, rather than learning generalizations. As
    long as it sees an input it has seen before, everything looks cool. But confronted
    with a sample from the test set, which it hasn’t seen during training, it starts
    to fail.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Paying attention to the metrics that are displayed during training is a good
    way to keep track of the progress of the learning process. The three metrics we
    discussed here are the most important, but frameworks like Keras offer many more
    and the option to build them yourselves.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Solving Runtime Errors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What should you do when your network complains about incompatible shapes?
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Look at the network structure and experiment with different numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Keras is a great abstraction over hairier frameworks like TensorFlow or Theano,
    but like any abstraction, this comes at a cost. When all is well our clearly defined
    model runs happily on top of TensorFlow or Theano. When it doesn’t, though, we
    get an error from the depths of the underlying framework. These errors are hard
    to make sense of without understanding the intricacies of those frameworks—which
    is what we wanted to avoid in the first place by using Keras.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two things that can help and don’t require us to go on a deep dive.
    The first is to print the structure of our network. Let’s say we have a simple
    model that takes in five variables and classifies into eight categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now inspect the model with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now if we get a runtime error about an incompatible shape, of the feared form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: we know something internal must be wrong that isn’t easy to track down using
    the stack trace. There are some other things to try, though.
  prefs: []
  type: TYPE_NORMAL
- en: First, take a look at whether any of the shapes are either `X` or `Y`. If so,
    that’s probably where the problem is. Knowing that is half the work—which of course
    still leaves the other half. The other thing to pay attention to is the names
    of the layers. Often they come back in the error message, sometimes in a mangled
    form. Keras auto-assigns names to anonymous layers, so looking at the summary
    is useful in this respect too. If needed we can assign our own names, like with
    the input layer in the example shown here.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we can’t find the shape or the name that the runtime error is mentioning,
    we can try something else before having to dive in (or post on StackOverflow):
    use different numbers.'
  prefs: []
  type: TYPE_NORMAL
- en: Neural networks contain loads of hyperparameters, like the sizes of the various
    layers. These are usually picked because they seem reasonable, given other networks
    that do similar things. But their actual value is somewhat arbitrary. In our example,
    does the hidden layer really need 12 units? Would 11 do a lot worse, and would
    13 lead to overfitting?
  prefs: []
  type: TYPE_NORMAL
- en: Probably not. We tend to pick numbers that feel nice, often powers of two. So
    if you are stuck on a runtime error, change these numbers and see what it does
    to the error message. If the error message remains the same, the variable that
    you changed has nothing to do with it. Once it starts changing, though, you know
    you’ve reached something related.
  prefs: []
  type: TYPE_NORMAL
- en: 'This can be subtle. For example, some networks require that all batches have
    the same size. If your data isn’t divisible by the batch size, your last batch
    will be too small and you’ll get an error like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Here `X` would be the batch size and `Y` the size of your last incomplete batch.
    You might recognize `X` as your batch size, but `Y` is hard to place. But if you
    change the batch size, `Y` also changes, which provides a hint as to where to
    look.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Understanding errors reported by the framework that is abstracted away by Keras
    is fundamentally tricky. The abstraction breaks, and we suddenly see the internals
    of the machinery. The techniques from this recipe allow you to postpone looking
    into those details by spotting shapes and names in the errors and, failing that,
    experimenting with numbers and seeing what changes.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Checking Intermediate Results
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Your network quickly gets to a promising level of accuracy but refuses to go
    beyond that.
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Check whether it hasn’t gotten stuck at an obvious local maximum.
  prefs: []
  type: TYPE_NORMAL
- en: One situation in which this can happen is when one label is far more common
    than any others, and your network quickly learns that always predicting this outcome
    gives decent results. It is not hard to verify that this is happening; just feed
    the network a sample of inputs and look at the outputs. If all outputs are the
    same, you are stuck this way.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the following recipes in this chapter offer suggestions for how to fix
    this. Alternatively, you could play with the distribution of the data. If 95%
    of your examples are dogs and only 5% cats, the network might not see enough cats.
    By artificially changing the distribution to, say, 65%/35%, you make it a little
    easier for the network.
  prefs: []
  type: TYPE_NORMAL
- en: This is, of course, not without its own risks. The network might now have more
    of a chance to learn about cats, but it will also learn the wrong base distribution,
    or prior. This means that in case of doubt the network will now be more likely
    to pick “cat” as the answer, even though, all things being equal, “dog” is more
    likely.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Looking at the distribution of output labels of a network for a small sample
    of inputs is an easy way to get an idea of what is actually being done, yet it
    is often overlooked. Playing with the distribution is a way to try to get the
    network unstuck if it focuses on just the top answer, but you should probably
    consider other techniques too.
  prefs: []
  type: TYPE_NORMAL
- en: There are other things to look out for in the output when a network isn’t converging
    quickly; the occurrence of NaNs is an indication of exploding gradients, and if
    the outputs of your network seem to be clipped and can’t seem to reach the right
    values, you might have an incorrect activation function on your final layer.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Picking the Right Activation Function (for Your Final Layer)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do you pick the right activation function for your final layer when things
    are off?
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Make sure that the activation function corresponds with the intention of the
    network.
  prefs: []
  type: TYPE_NORMAL
- en: A good way to get started with deep learning is to find an example online somewhere
    and modify it step by step until it does what you want it to do. However, if the
    intention of the example network is different from what your goal, you might have
    to change the activation function of the final layer. Let’s take a look at some
    common choices.
  prefs: []
  type: TYPE_NORMAL
- en: The softmax activation function makes sure that the sum of the output vector
    is exactly 1\. This is an appropriate activation function for networks that output
    exactly one label for a given input (for example, an image classifier). The output
    vector will then represent the probability distribution—if the entry for “cat”
    in the output vector is .65, then the network thinks that it sees a cat with 65%
    certainty. Softmax only works when there is one answer. When multiple answers
    are possible, give the sigmoid activation a try.
  prefs: []
  type: TYPE_NORMAL
- en: A linear activation function is appropriate for regression problems when we
    need to predict a numeric value given an input. An example would be to predict
    a movie rating given a series of movie reviews. The linear activation function
    will take the values of the previous layer and multiply them with a set of weights
    such that it best fits the expected output. Just as it is a good idea to normalize
    the input data into a [–1, 1] range or thereabouts, it often helps to do the same
    for outputs. So, if our movie ratings are between 0 and 5, we’d subtract 2.5 and
    divide by the same when creating the training data.
  prefs: []
  type: TYPE_NORMAL
- en: If the network outputs an image, make sure that the activation function you
    use is in line with how you normalize the pixels. The standard normalization of
    deducting the mean pixel value and dividing by the standard deviation results
    in values that center around 0, so it won’t work with sigmoid, and since 30% of
    the values will fall outside the range [–1, 1] tanh won’t be a good fit either.
    You can still use these, but you’d have to change the normalization applied to
    your output.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on what you know about the output distribution, it might be useful
    to do something even more fancy. Movie ratings, for example, tend to center around
    3.7 or so, so using that as the center could well yield better results. When the
    actual distribution is skewed such that values around the average are much more
    likely than outliers, using a tanh activation function can be appropriate. This
    squashes any value into a [–1, 1] range. By mapping the expected outputs to the
    same range, keeping the expected distribution in mind, we can mimic any shape
    of our output data.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Picking the right output activation function is crucial, but in most cases not
    difficult. If your output represents a probability distribution with one possible
    outcome, softmax is for you; otherwise, you need to experiment.
  prefs: []
  type: TYPE_NORMAL
- en: You also need to make sure that the loss function works with the activation
    function of the final layer. The loss function steers the training of the network
    by calculating how “wrong” a prediction is, given an expected value. We saw that
    a softmax activation function is the right choice when a network does multilabel
    predictions; in that case you probably want to go with a categorical loss function
    like Keras’s `categorical_crossentropy`.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5 Regularization and Dropout
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have detected your network is overfitting, what can you do about it?
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Restrict what the network can do by using regularization and dropout.
  prefs: []
  type: TYPE_NORMAL
- en: A neural network with enough parameters can fit any input/output mapping by
    memorizing. Accuracy seems great while training, but of course the network fails
    to perform very well on data it hasn’t seen before and so does poorly on the test
    data or indeed in production. The network is overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: One obvious way to stop the network from overfitting is to reduce the number
    of parameters that we have by decreasing the number of layers or making each layer
    smaller. But this of course also reduces the expressive power of our network.
    Regularization and dropout offer us something in between by restricting the expressive
    power of our network in a way that doesn’t hurt the ability to learn (too much).
  prefs: []
  type: TYPE_NORMAL
- en: With regularization we add penalties to *extreme* values for parameters. The
    intuition here is that in order to fit an arbitrary input/output mapping, a network
    would need arbitrary parameters, while learned parameters tend to be in a normal
    range. So, making it harder to get to those arbitrary parameters should keep the
    network on the path of learning rather than memorizing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Application in Keras is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Regularizers can be applied to the weights of the kernel or the bias of the
    layer, or to the output of the layer. Which one and what penalty to use is mostly
    a matter of trial and error. 0.01 seems like a popular starting value.
  prefs: []
  type: TYPE_NORMAL
- en: Dropout is a similar technique, but more radical. Rather than keeping the weights
    of neurons in check, we randomly ignore a percentage of all neurons during training.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to regularization, this makes it harder for a network to memorize input/output
    pairs, since it can’t rely on specific neurons working during training. This nudges
    the network into learning general, robust features rather than one-off, specific
    ones to cover one training instance.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Keras dropout is applied to a layer using the `Dropout` (pseudo)layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: This applies a dropout of 30% to the max-pooling layer, ignoring 30% of its
    neurons during training.
  prefs: []
  type: TYPE_NORMAL
- en: When doing inference, dropout is not applied. All things being equal this would
    increase the output of the layer by over 40%, so the framework automatically scales
    these outputs back.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you make your network more expressive, its tendency to overfit or memorize
    its inputs rather than learn general features will increase. Both regularization
    and dropout can play a role to reduce this effect. Both work by reducing the freedom
    of the network to develop arbitrary features, by punishing extreme values (regularization)
    or by ignoring the contribution of a percentage of the neurons in a layer (dropout).
  prefs: []
  type: TYPE_NORMAL
- en: An interesting alternative way to look at how networks with dropout work is
    to consider that if we have *N* neurons and we randomly switch a certain percentage
    of the neurons off, we really have created a generator that can create a very
    large variety of different but related networks. During training these different
    networks all learn the task at hand, but at evaluation time they all run in parallel
    and their average opinion is taken. So even if some of them start overfitting,
    chances are that this is drowned out in the aggregate vote.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6 Network Structure, Batch Size, and Learning Rate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How do you find the best network structure, batch size, and learning rate for
    a given problem?
  prefs: []
  type: TYPE_NORMAL
- en: Solution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Start small and work your way up.
  prefs: []
  type: TYPE_NORMAL
- en: Once we’ve identified the sort of network we’ll need to solve a specific problem,
    we still have to make a number of implementation decisions. The more important
    among those are decisions about the network structure, the learning rate, and
    the batch size.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with the network structure. How many layers will we have? How big
    will each of those layers be? A decent strategy is to start with the smallest
    sizes that could possibly work. Being all enthusiastic about the “deep” in deep
    learning, there is a certain temptation to start with many layers. But typically
    if a one- or two-layer network doesn’t perform at all, chances are that adding
    more layers isn’t going to really help.
  prefs: []
  type: TYPE_NORMAL
- en: Continuing with the size of each individual layer, larger layers can learn more,
    but they also take longer and have more space to hide problems. As with the number
    of layers, start small and expand from there. If you suspect that the expressive
    power of a smaller network will be insufficient to make any sense of your data,
    consider simplifying your data; start with a small network that only distinguishes
    between the two most popular labels and then gradually increase the complexity
    of both the data and the network.
  prefs: []
  type: TYPE_NORMAL
- en: The batch size is the number of samples we feed into the network before adjusting
    the weights. The larger the batch size, the longer it takes to finish one, but
    the more accurate the gradient is. In order to get results quickly, it is advisable
    to start with a smallish batch size—32 seems to work well.
  prefs: []
  type: TYPE_NORMAL
- en: The learning rate determines how much we’ll change the weights in our network
    in the direction of the derived gradient. The higher the rate, the quicker we
    move through the landscapes. Too big a rate, though, and we risk skipping over
    the good bits and we start thrashing. When we take into account that a smaller
    batch size leads to a less accurate gradient, it stands to reason that we should
    combine a small batch size with a smaller learning rate. So, the suggestion here
    is again to start out small and, when things work, experiment with larger batch
    rates and higher learning rates.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Training on GPUs impacts this assessment. GPUs efficiently run steps in parallel,
    so there is no real reason to pick a batch size that is so small that it leaves
    part of the GPU idle. What batch size that is depends of course on the network,
    but as long as the time per batch doesn’t increase by much when you increase the
    batch size, you’re still on the right side of things. A second consideration when
    running on GPUs is memory. When a batch no longer fits in the memory of the GPU
    things start to fail and you’ll start to see out of memory messages.
  prefs: []
  type: TYPE_NORMAL
- en: Discussion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Network structure, batch size, and learning rate are some of the important hyper
    parameters that impact the performance of networks but have little to do with
    the actual strategy. For all of these a reasonable strategy is to start small
    (but big enough that things still work) and go bigger step by step, observing
    that the network still performs.
  prefs: []
  type: TYPE_NORMAL
- en: As we increase the number of layers and the size of each layer, we’ll start
    to see symptoms of overfitting at some point (training and testing accuracy start
    to diverge, for example). That might be a good time to look at regularization
    and dropout.
  prefs: []
  type: TYPE_NORMAL
