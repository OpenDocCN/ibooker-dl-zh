["```py\nstepback_system_message = f\"\"\"    \nYou are an expert at world knowledge. Your task is to step back #1\nand paraphrase a question to a more generic step-back question, which\nis easier to answer. Here are a few examples\n\n\"input\": \"Could the members of The Police perform lawful arrests?\" #2\n\"output\": \"what can the members of The Police do?\"\n\n\"input\": \"Jan Sindel’s was born in what country?\"\n\"output\": \"what is Jan Sindel’s personal history?\"\n\"\"\"\n```", "```py\ndef generate_stepback(question: str):\n    user_message = f\"\"\"{question}\"\"\"\n    step_back_question = chat(\n        messages=[\n            {\"role\": \"system\", \"content\": stepback_system_message},\n            {\"role\": \"user\", \"content\": user_message},\n        ]\n    )\n    return step_back_question\n```", "```py\nquestion = \"Which team did Thierry Audel play for from 2007 to 2008?\"\nstep_back_question = generate_stepback(question)\nprint(f\"Stepback results: {step_back_question}\")\n# Stepback results: What is the career history of Thierry Audel?\n```", "```py\nimport re\ndef split_text_by_titles(text):\n    # A regular expression pattern for titles that\n    # match lines starting with one or more digits, an optional uppercase letter,\n    # followed by a dot, a space, and then up to 60 characters\n    title_pattern = re.compile(r\"(\\n\\d+[A-Z]?\\. {1,3}.{0,60}\\n)\", re.DOTALL)\n    titles = title_pattern.findall(text)\n    # Split the text at these titles\n    sections = re.split(title_pattern, text)\n    sections_with_titles = []\n    # Append the first section\n    sections_with_titles.append(sections[0])\n    # Iterate over the rest of the sections\n    for i in range(1, len(titles) + 1):\n        section_text = sections[i * 2 - 1].strip() + \"\\n\" +\n↪ sections[i * 2].strip()\n        sections_with_titles.append(section_text)\n\n    return sections_with_titles\n\nsections = split_text_by_titles(text)\nprint(f\"Number of sections: {len(sections)}\")\n# Number of sections: 9\n```", "```py\ndef num_tokens_from_string(string: str, model: str = \"gpt-4\") -> int:\n    \"\"\"Returns the number of tokens in a text string.\"\"\"\n    encoding = tiktoken.encoding_for_model(model)\n    num_tokens = len(encoding.encode(string))\n    return num_tokens\n\nfor s in sections:\n    print(num_tokens_from_string(s))\n# 154, 254, 4186, 570, 2703, 1441, 194, 600\n```", "```py\nparent_chunks = []\nfor s in sections:\n    parent_chunks.extend(chunk_text(s, 2000, 40))\n```", "```py\ncypher_import_query = \"\"\"    #1\nMERGE (pdf:PDF {id:$pdf_id})    #2\nMERGE (p:Parent {id:$pdf_id + '-' + $id})\nSET p.text = $parent\nMERGE (pdf)-[:HAS_PARENT]->(p)    #3\nWITH p, $children AS children, $embeddings as embeddings\nUNWIND range(0, size(children) - 1) AS child_index\nMERGE (c:Child {id: $pdf_id + '-' + $id + '-' + toString(child_index)})\nSET c.text = children[child_index], c.embedding = embeddings[child_index]\nMERGE (p)-[:HAS_CHILD]->(c);\n\"\"\"\n```", "```py\nfor i, chunk in enumerate(parent_chunks):\n\n    child_chunks = chunk_text(chunk, 500, 20) #1\n\n    embeddings = embed(child_chunks) #2\n    # Add to neo4j\n\n    neo4j_driver.execute_query( #3\n        cypher_import_query,\n        id=str(i),\n        pdf_id='1709.00666'\n        parent=chunk,\n        children=child_chunks,\n        embeddings=embeddings,\n    )\n```", "```py\nMATCH p=(pdf:PDF)-[:HAS_PARENT]->()-[:HAS_CHILD]->()\nRETURN p LIMIT 25\n```", "```py\ndriver.execute_query(\"\"\"CREATE VECTOR INDEX parent IF NOT EXISTS\nFOR (c:Child)\nON c.embedding\"\"\")\n```", "```py\nretrieval_query = \"\"\"  \nCALL db.index.vector.queryNodes($index_name, $k * 4, $question_embedding) #1\nYIELD node, score      #2\nMATCH (node)<-[:HAS_CHILD]-(parent)   #3\nWITH parent, max(score) AS score\nRETURN parent.text AS text, score\nORDER BY score DESC    #4\nLIMIT toInteger($k)\n\"\"\"\n```", "```py\ndef parent_retrieval(question: str, k: int = 4) -> List[str]:\n    question_embedding = embed([question])[0]\n\n    similar_records, _, _ = neo4j_driver.execute_query(\n        retrieval_query,\n        question_embedding=question_embedding,\n        k=k,\n        index_name=index_name,\n    )\n\n    return [record[\"text\"] for record in similar_records]\n```", "```py\nsystem_message = \"You're en Einstein expert, but can only use the↪\n↪ provided documents to respond to the questions.\"\ndef generate_answer(question: str, documents: List[str]) -> str:\n    user_message = f\"\"\"\n    Use the following documents to answer the question that will follow:\n    {documents}\n\n    ---\n\n    The question to answer using information only from the above↪\n↪ documents: {question}\n    \"\"\"\n    result = chat(\n        messages=[\n            {\"role\": \"system\", \"content\": system_message},\n            {\"role\": \"user\", \"content\": user_message},\n        ]\n    )\n    print(\"Response:\", result)\n```", "```py\ndef rag_pipeline(question: str) -> str:\n    stepback_prompt = generate_stepback(question)\n    print(f\"Stepback prompt: {stepback_prompt}\")\n    documents = parent_retrieval(stepback_prompt)\n    answer = generate_answer(question, documents)\n    return answer\n```", "```py\nrag_pipeline(\"When was Einstein granted the patent for his blouse design?\")\n# Stepback prompt: What are some notable achievements in Einstein's life?\n# Response: Einstein was granted the patent for his blouse design on October 27, 1936.\n```"]