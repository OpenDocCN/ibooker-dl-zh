["```py\n{\"messages\": [{\"role\": \"system\", \"content\": \"You're a chatbot that only responds with emojis!\"}, {\"role\": \"user\", \"content\": \"I heard the koala habitat was destroyed by the fire.\"}, {\"role\": \"assistant\", \"content\": \"(sadkoala)\" }]}\n\n{\"messages\": [{\"role\": \"system\", \"content\": \"You're a chatbot that only responds with emojis!\"}, {\"role\": \"user\", \"content\": \"I've been working nonstop and need a break.\"}, {\"role\": \"assistant\", \"content\": \"(tired)\" }]}\n\n{\"messages\": [{\"role\": \"system\", \"content\": \"You're a chatbot that only responds with emojis!\"}, {\"role\": \"user\", \"content\": \"I just finished reading an amazing book!\"}, {\"role\": \"assistant\", \"content\": \"(like)\" }]}\n```", "```py\n# Basic checks to ensure the data file is valid\ndef basic_checks(data_file):\n    try:\n        with open(data_file, 'r', encoding='utf-8') as f:    #1\n            dataset = [json.loads(line) for line in f]       #2\n\n        print(f\"Basic checks for file {data_file}:\")\n        print(\"Count of examples in training dataset:\", len(dataset))\n        print(\"First example:\")                              #3\n        for message in dataset[0][\"messages\"]:             #4\n            print(message)\n        return True\n    except Exception as e:\n        print(f\"An error occurred in file {data_file}: {e}\")\n        return False\n```", "```py\ndef format_checks(dataset, filename):\n    # Initialize a dictionary used to track format errors\n    format_errors = defaultdict(int)\n\n    # Iterate over each example in the dataset\n    for ex in dataset:\n        # Check if the example is a dictionary, if not \n        # increment the corresponding error count\n        if not isinstance(ex, dict):\n            format_errors[\"data_type\"] += 1\n            continue\n\n        # Check if the example has a \"messages\" key, \n        # if not increment the corresponding error count\n        messages = ex.get(\"messages\", None)\n        if not messages:\n            format_errors[\"missing_messages_list\"] += 1\n            continue\n\n        # Iterate over each message\n        for message in messages:\n            # Check if the message has \"role\" and \"content\" keys,\n            # if not increment the corresponding error count\n            if \"role\" not in message or \"content\" not in message:\n                format_errors[\"message_missing_key\"] += 1\n\n            # Check if the message has any unrecognized keys,\n            # if so increment the corresponding error count\n            if any(k not in (\"role\", \"content\", \"name\", \n                   ↪\"function_call\") for k in message):\n                format_errors[\"message_unrecognized_key\"] += 1\n\n            # Check if the role of the message is one of the recognized\n            # roles, if not increment the corresponding error count\n            if message.get(\"role\", None) not in (\n                \"system\",\n                \"user\",\n                \"assistant\",\n                \"function\",\n            ):\n                format_errors[\"unrecognized_role\"] += 1\n\n            # Check if the message has either content or a function call, \n            # and if the content is a string, if not increment the \n            # corresponding error count\n            content = message.get(\"content\", None)\n            function_call = message.get(\"function_call\", None)\n            if (not content and not function_call) or not \n            ↪isinstance(content, str):\n                format_errors[\"missing_content\"] += 1\n\n        # Check if there is at least one message with the role \"assistant\",\n        # if not increment the corresponding error count\n        if not any(message.get(\"role\", None) == \"assistant\" \n        ↪for message in messages):\n            format_errors[\"example_missing_assistant_message\"] += 1\n\n    # If there are any format errors, print them and return False\n    if format_errors:\n        print(f\"Formatting errors found in file {filename}:\")\n        for k, v in format_errors.items():\n            print(f\"{k}: {v}\")\n        return False\n\n    print(f\"No formatting errors found in file {filename}\")\n    return True\n```", "```py\n# Pricing and default n_epochs estimate\nMAX_TOKENS = 4096\n\nTARGET_EPOCHS = 3\nMIN_TARGET_EXAMPLES = 100\nMAX_TARGET_EXAMPLES = 25000\nMIN_DEFAULT_EPOCHS = 1\nMAX_DEFAULT_EPOCHS = 25\n\ndef estimate_tokens(dataset, assistant_tokens):\n    # Set the initial number of epochs to the target epochs\n    n_epochs = TARGET_EPOCHS\n\n    # Get the number of examples in the dataset\n    n_train_examples = len(dataset)\n\n    # If the examples total is less than the minimum target\n    # adjust the epochs to ensure we have enough examples for\n    # training\n    if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n        n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES \n           ↪// n_train_examples)\n    # If the  number of examples is more than the maximum target\n    # adjust the  epochs to ensure we don't exceed the maximum \n    # for training\n    elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n        n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES \n          ↪// n_train_examples)\n\n    # Calculate the total number of tokens in the dataset\n    n_billing_tokens_in_dataset = sum(\n        min(MAX_TOKENS, length) for length in assistant_tokens\n    )\n\n    # Print the total token count that will be charged during training\n    print(\n        f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that \n            ↪will be charged for during training\"\n    )\n\n    # Print the default number of epochs for training\n    print(f\"You will train for {n_epochs} epochs on this dataset\")\n\n    # Print the total number of tokens that will be charged during training\n    print(f\"You will be charged for ~{n_epochs * \n                        ↪n_billing_tokens_in_dataset} tokens\")\n\n    # If the total token count exceeds the maximum tokens, print a warning \n    if n_billing_tokens_in_dataset > MAX_TOKENS:\n        print(\n            f\"WARNING: Your dataset contains examples longer than \n                       ↪4K tokens by {n_billing_tokens_in_dataset – \n                       ↪MAX_TOKENS} tokens.\"\n        )\n        print(\n            \"You will be charged for the full length of these \n             ↪examples during training, but only the first\n             ↪4K tokens will be used for training.\"\n```", "```py\nimport os\nfrom openai import AzureOpenAI\n\nAPI_VERSION = '2023-09-15-preview'                   #1\n\nclient = AzureOpenAI(\n    api_key=os.getenv('AOAI_FT_KEY'),                #2\n    api_version=API_VERSION,\n    azure_endpoint = os.getenv('AOAI_FT_ENDPOINT'))  #2\n\nTRAINING_FILENAME = 'data/emoji_FT_train.jsonl'       #3\n\n# Upload the training dataset files\nfile = client.files.create(\n    file=open(TRAINING_FILENAME, \"rb\"),\n    purpose=\"fine-tune\"\n)\n\nprint(\"Training file ID:\", file.id)\nprint(\"Training file name:\", file.filename)\n```", "```py\nResponse:\n Training file ID: file-ca4c57d7ad814211a2db49e0382c5a77\n Training file name: emoji_FT_train.jsonl\n```", "```py\nimport os\nfrom openai import AzureOpenAI\n\nAPI_VERSION = '2023-09-15-preview'                        #1\n\n# Connect to the servvice\nclient = AzureOpenAI(\n    api_key=os.getenv('AOAI_FT_KEY'),                      #2\n    api_version=API_VERSION,\n    azure_endpoint = os.getenv('AOAI_FT_ENDPOINT'))        #2\n\n# Begin by creating the fine-tuning job\nft = client.fine_tuning.jobs.create(\n    training_file=\"file-ca4c57d7ad814211a2db49e0382c5a77\",   #3\n    model=\"gpt-35-turbo-0613\",\n    hyperparameters={\n        \"n_epochs\":3\n    },\n    suffix=\"emoji\"\n)\nprint(\"Finetuning job ID:\", ft.id)\n```", "```py\nFinetuning job ID: ftjob-367ee1995af740a0bf24876221585f7a\n```", "```py\nimport os\nfrom openai import AzureOpenAI\n\nAPI_VERSION = '2023-09-15-preview'\n\nclient = AzureOpenAI(\n    api_key=os.getenv('AOAI_FT_KEY'),\n    api_version=API_VERSION,\n    azure_endpoint = os.getenv('AOAI_FT_ENDPOINT'))\n\n# List all the FT jobs\nft_jobs = client.fine_tuning.jobs.list()\n\nfor ft_job in ft_jobs:\n    print(ft_job.id, ft_job.status)\n```", "```py\nftjob-367ee1995af740a0bf24876221585f7a pending\nftjob-c41a9dc551834a1aa0be8befe788a22b running\nftjob-1a7faac8856d46e48a038c02555fe6e5 succeeded\nftjob-505d5a8bd321406dbf4605b636b0c0cd succeeded\n```", "```py\nimport os\nfrom openai import AzureOpenAI\n\nAPI_VERSION = '2023-09-15-preview'\n\nclient = AzureOpenAI(\n    api_key=os.getenv('AOAI_FT_KEY'),\n    api_version=API_VERSION,\n    azure_endpoint = os.getenv('AOAI_FT_ENDPOINT'))\n\n#List all the FT events for the job from\n#earier: ftjob-367ee1995af740a0bf24876221585f7a\nft_job_events = client.fine_tuning.jobs.list_events(\n    fine_tuning_job_id=\"ftjob-367ee1995af740a0bf24876221585f7a \", \n    limit=2)\n\n# Loop through the events and print the details\nfor ft_job_event in ft_job_events:\n    print(ft_job_event.id, ft_job_event.message)\n```", "```py\nftevent-1e89dc7cc62046048bcea50de1cccbb9 Jobs ahead in queue: 1\nftevent-42649f5c7677472f83eaa6cd4cde0dba Job enqueued. \n↪Waiting for jobs ahead to complete.\n```", "```py\n# Define the API version\nAPI_VERSION = '2023-09-15-preview'\n\n# Create an instance of the AzureOpenAI client\nclient = AzureOpenAI(\n    api_key=os.getenv('AOAI_FT_KEY'),\n    api_version=API_VERSION,\n    azure_endpoint = os.getenv('AOAI_FT_ENDPOINT'))\n\n# Define the job ID of the fine-tuning job to track\nJOB_ID = \"ftjob-367ee1995af740a0bf24876221585f7a\"\n\n# Record the start time of the tracking\nstart_time = time.time()\n\n# Get the status of the fine-tuning job\nft_job = client.fine_tuning.jobs.retrieve(JOB_ID)\nstatus = ft_job.status\n\n# If the job is not yet done, continue to poll its status every 30 seconds\nwhile status not in [\"succeeded\", \"failed\"]:\n    ft_job = client.fine_tuning.jobs.retrieve(JOB_ID)\n    print(ft_job)\n\n    # Update the status\n    status = ft_job.status\n\n    # Print the elapsed time since the start of tracking\n    print(\"Elapsed time: {} minutes {} seconds\".format( \n        ↪int((time.time() - start_time) // 60), \n        ↪int((time.time() - start_time) % 60)))\n\n    # Print the current status\n    print(f'Status: {status}')\n\n    # Clear the output before displaying new output – prevents flickering\n    clear_output(wait=True)\n\n    # Wait for 30 seconds before the next poll\n    time.sleep(30)\n\n# Once the job is done, print its final status\nprint(f'Fine-tuning job {JOB_ID} finished with status: {status}')\n```"]