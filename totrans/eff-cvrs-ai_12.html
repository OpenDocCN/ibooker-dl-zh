<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">10</span> </span> <span class="chapter-title-text">Reducing complexity with generative AI</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header">This chapter covers</h3> 
   <ul> 
    <li class="readable-text" id="p2">Designing and improving process flows with generative AI</li> 
    <li class="readable-text" id="p3">Replacing disambiguation dialogue flows with LLM judgments</li> 
    <li class="readable-text" id="p4">Testing static dialogue flows with generative AI as the “user”</li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p5"> 
   <p>It’s difficult to design a process-oriented bot that meets all the needs and desires of all stakeholders. Competing priorities may lead to a “design by committee” that introduces complexity. And well-meaning people can design edge cases that hamper the main dialogue flow. These complexities burden your users and make them more likely to quit or fail when using the bot. Generative AI can help you detect and improve these scenarios, helping you remove complexity and increase the successfulness of your bot.</p> 
  </div> 
  <div class="readable-text intended-text" id="p6"> 
   <p>Process flow builders often ask for too much information from the user. (More information is better, right? Not if it causes the chatbot to fail!) There are several ways to improve process flows with generative AI:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p7"> Use generative AI to make suggestions about how to build a process flow. </li> 
   <li class="readable-text" id="p8"> If your process flow is built, use generative AI to suggest improvements. It can also test the flow by acting as the user. </li> 
   <li class="readable-text" id="p9"> Replace some static process flows with a large language mode (LLM)–driven process. </li> 
  </ul> 
  <div class="readable-text" id="p10"> 
   <p>We’ll start by exploring a claim status process flow for a medical insurance provider. Then we’ll see how generative AI can help us design and improve this process flow and others.</p> 
  </div> 
  <div class="readable-text" id="p11"> 
   <h2 class=" readable-text-h2"><span class="num-string">10.1</span> AI-assisted process flows at build time</h2> 
  </div> 
  <div class="readable-text" id="p12"> 
   <p>Figure 10.1 shows the simplest possible view of a process flow.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p13">  
   <img alt="figure" src="../Images/CH10_F01_Freed2.png" width="792" height="43"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 10.1</span> A high-level view of a process flow. It is initiated by the recognition of a specific intent, it includes one or more sequential steps, and it ends with completion of the process flow (satisfying the intent).</h5>
  </div> 
  <div class="readable-text" id="p14"> 
   <p>Our example process flow involves medical insurance customers who call into a chatbot to find the status of a claim. At first, this process sounds like a simple lookup, but it has several criteria to meet:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p15"> <em>Intent detection</em>—Figure out that the user’s intent is “claim status.” This initiates a process flow with multiple steps. </li> 
   <li class="readable-text" id="p16"> <em>Beginning of process flow</em>—Gather the information required to complete the claim status process: in this case, the information needed to search for a claim. </li> 
   <li class="readable-text" id="p17"> <em>Middle of process flow</em>—Use the gathered information to perform some action. In this example, that is searching for the user’s claim. </li> 
   <li class="readable-text" id="p18"> <em>End of process flow</em>—Complete the flow by providing the claim status to the user. </li> 
  </ul> 
  <div class="readable-text" id="p19"> 
   <p>The overall claims process flow is shown in figure 10.2.</p> 
  </div> 
  <div class="readable-text intended-text" id="p20"> 
   <p>In chapter 5, we showed how you could improve a chatbot’s intent classifier to <em>detect</em> and <em>understand</em> the user’s intent. In this chapter, we’ll focus on improving the rest of the process flow to successfully <em>fulfill</em> the user’s intent.</p> 
  </div> 
  <div class="browsable-container figure-container" id="p21">  
   <img alt="figure" src="../Images/CH10_F02_Freed2.png" width="852" height="395"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 10.2</span> Visualizing a claim status process flow</h5>
  </div> 
  <div class="readable-text" id="p22"> 
   <h3 class=" readable-text-h3"><span class="num-string">10.1.1</span> Generating dialogue flows with generative AI</h3> 
  </div> 
  <div class="readable-text" id="p23"> 
   <p>Conversational AI process flows are often based on an existing workflow. That flow could be copied from another channel, from a web application, or from a call center script. For our claim status example, let’s assume there was no existing process to work from. We can use an LLM to help us design the target workflow. </p> 
  </div> 
  <div class="readable-text intended-text" id="p24"> 
   <p>The following listing shows an example LLM prompt.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p25"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.1</span> Prompt to design a medical insurance claims status flow</h5> 
   <div class="code-area-container code-area-with-html"> 
    <pre class="code-area">Instruction: You are a conversational designer. <span class="aframe-location"/> #1
<span class="">↪</span>You are building a chatbot to help users find  
<span class="">↪</span>information about their insurance claims. 
<span class="">↪</span>Insurance claims include the following information:  
<span class="">↪</span>a claim date, a member ID, a claim amount, and a 
<span class="">↪</span>claim status. 
Design a dialogue flow to help users find their claim.<span class="aframe-location"/> #2
<span class="">↪</span>The dialogue flow should be as brief as possible and   #2
<span class="">↪</span>easy for the users to complete.  #2
Describe why you have constructed the dialogue flow this way.  #2

Output: <span class="aframe-location"/> #3</pre> 
    <div class="code-annotations-overlay-container">
     #1 Scenario and background
     <br/>#2 Detailed instructions
     <br/>#3 Output cue
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p26"> 
   <p>We had to give the LLM several pieces of information for the task:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p27"> <em>Scenario/background</em>—The LLM should know the scenario behind the task (“you are a conversational designer”). The LLM should also be given background assumptions, such as what information is available on medical claims. </li> 
   <li class="readable-text" id="p28"> <em>Instructions</em>—The LLM must design a dialogue flow that achieves a user goal (finding the claim) while being as brief and easy as possible. Further, the LLM should describe its “reasoning,” which will help us evaluate the output. </li> 
   <li class="readable-text" id="p29"> <em>Cue</em>—The cue “Output” lets the LLM know the instruction is finished. </li> 
  </ul> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p30"> 
    <h5 class=" callout-container-h5 readable-text-h5">Small changes may cause big differences</h5> 
   </div> 
   <div class="readable-text" id="p31"> 
    <p>LLMs may give significantly different answers to very similar prompts. Even formatting changes, like adding a space or including or omitting newline characters, can cause major output changes. The exact prompts used in this book are included on the book’s GitHub site at <a href="https://github.com/andrewrfreed/EffectiveConversationalAI">https://github.com/andrewrfreed/EffectiveConversationalAI</a>.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p32"> 
   <p>The next listing shows the output when the prompt uses three lines in the instruction (the lines starting with “Instruction,” “Design,” and “Describe”).</p> 
  </div> 
  <div class="browsable-container listing-container" id="p33"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.2</span> Output from mixtral-8x7b-instruct-01 for claim status flow (less newlines)</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">The dialogue flow for the insurance claim chatbot would 
look like this:

1. User: Hi, I want to check my insurance claim. <span class="aframe-location"/> #1
2. Chatbot: Sure, I can help you with that. Can you   #1
please provide me with your member ID?  #1
3. User: My member ID is 123456.  #1
4. Chatbot: Thank you. Now, can you tell me the date   #1
of your claim?  #1
5. User: The claim date is January 10, 2022. #1
6. Chatbot: Got it. And can you tell me the claim  #1
 amount? #1
7. User: The claim amount is $1000.  #1
8. Chatbot: Thank you. I have all the information I #1
 need. Let me check the status of your claim.  #1
9. Chatbot: The status of your claim is approved and   #1
the amount of $1000 has been paid.  #1

The dialogue flow is designed to be brief and easy for  <span class="aframe-location"/> #2
the users to complete. The chatbot starts by asking for  #2
the member ID, which is the most important piece of   #2
information needed to identify the user's claims. The   #2
chatbot then asks for the claim date and the claim   #2
amount, which are necessary to locate the specific   #2
claim. By asking for the information in this order, the   #2
chatbot can quickly and efficiently retrieve the user's   #2
claim information. #2
#2
Additionally, the chatbot confirms the claim information  #2
with the user before checking the claim status. This   #2
reduces the chances of errors and ensures that the user  #2
receives accurate information. The chatbot also provides  #2
clear and concise instructions throughout the   #2
conversation, making it easy for the user to follow   #2
along and complete the process. #2
#2
Overall, the dialogue flow is designed to provide a   #2
seamless and efficient user experience, while also    #2
ensuring the accuracy and reliability of the   #2
information provided. #2</pre> 
    <div class="code-annotations-overlay-container">
     #1 Sample conversation, including the chatbot and user messages
     <br/>#2 Explanation of the design process
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p34"> 
   <p>The LLM designed a two-sided sample conversation demonstrating what both the bot and the user would say. This is nice—it is helpful to visualize what a complete conversation looks like. We should be aware that this is only a sample—users may respond in many ways to these questions. Let’s recap what happened in the exchange with the LLM:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p35"> We told the LLM that claims had a member ID, date, amount, and status. It inferred that the status was an output and the other three data points were inputs. </li> 
   <li class="readable-text" id="p36"> The LLM designed a process flow that collects all three data points in sequential order. </li> 
   <li class="readable-text" id="p37"> The generated dialogue is polite and useful. The bot acknowledges user input with “thank you.” It also gives clear instructions to the user about what is expected in each step of the flow. </li> 
  </ul> 
  <div class="readable-text" id="p38"> 
   <p>Interestingly, we get very different output depending on how we use newline characters in the prompt. The following listing shows the output from a prompt using six lines (a new line after every period in the instruction).</p> 
  </div> 
  <div class="browsable-container listing-container" id="p39"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.3</span> Output from mixtral-8x7b-instruct-01 for claim status flow (more newlines)</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">1. The dialogue flow starts with a greeting and an introduction to the chatbot's purpose. 

   Chatbot: Hello! I'm here to help you find information about your insurance claims. May I have your member ID, please?

   Rationale: By starting with a greeting and an introduction, the user is made aware of the chatbot's purpose and what they can expect from the conversation. Asking for the member ID first helps to identify the user's account and narrow down the search for their claim.

2. After the user provides their member ID, the chatbot confirms the member ID and asks for the claim date.

   Chatbot: Thank you for providing your member ID. To help you find your claim, could you please tell me the date of the claim?

   Rationale: Confirming the member ID ensures that the chatbot has the correct information and helps to build trust with the user. Asking for the claim date next helps to further narrow down the search for the user's claim.

3. After the user provides the claim date, the chatbot confirms the claim date and asks for the claim amount.

   Chatbot: Thank you for providing the claim date. Just to confirm, the claim amount was [insert claim amount]. Is that correct?

   Rationale: Confirming the claim date and amount helps to ensure that the chatbot has the correct information and reduces the likelihood of errors.

4. After the user confirms the claim amount, the chatbot provides the claim status.

   Chatbot: Great, the claim amount is correct. The status of your claim is [insert claim status]. Is there anything else I can help you with?

   Rationale: Providing the claim status is the ultimate goal of the conversation, and it is important to provide this information as soon as possible. By asking if there is anything else the user needs, the chatbot is able to provide additional assistance if necessary.

Overall, this dialogue flow is designed to be brief and easy for the user to complete. By asking for the most important information first (member ID and claim date), the chatbot is able to quickly narrow down the search for the user's claim. Confirming the member ID, claim date, and claim amount helps to ensure that the chatbot has the correct information and reduces the likelihood of errors. Providing the claim status is the ultimate goal of the conversation, and the chatbot is able to provide this information as soon as possible. Finally, by asking if there is anything else the user needs, the chatbot is able to provide additional assistance if necessary.</pre>  
   </div> 
  </div> 
  <div class="readable-text" id="p40"> 
   <p>The output in listing 10.3 is quite different. First, the sample conversation and rationale are interleaved. Every step of the conversation has a description, an example chatbot message, and a detailed rationale. Second, the sample conversation includes only the bot messages. We don’t see user responses. Third, this process flow implies confirmation statements after each piece of data is received from the user. Finally, the sample dialogue contains minor errors. Instruction 3 says it will ask for the claim amount, but the dialogue shows it confirming a claim amount without collecting it.</p> 
  </div> 
  <div class="readable-text intended-text" id="p41"> 
   <p>Together, the two prompts give us plenty of ideas for constructing a dialogue flow to implement a claim status process. Since listing 10.2 is more fully formed, we will use that as our baseline. Though it is pretty good, the process generated seems a little lengthy. Can we improve the process flow? Of course we can! Let’s ask the LLM for improvements.</p> 
  </div> 
  <div class="readable-text" id="p42"> 
   <h3 class=" readable-text-h3"><span class="num-string">10.1.2</span> Improving dialogue flow with generative AI</h3> 
  </div> 
  <div class="readable-text" id="p43"> 
   <p>We can ask an LLM to improve process flows whether they were generated by LLMs or humans. Let’s improve the process flow in listing 10.2, which we generated via LLM to help users learn their claim status. </p> 
  </div> 
  <div class="readable-text intended-text" id="p44"> 
   <p>The process flow, as currently constructed, requires three pieces of information: a member ID, a date, and a claim amount. This meets some basic requirements, like authenticating the caller (by member ID) and providing search criteria (member ID plus date and amount). However, this could be burdensome to the user. By intuition, it seems that the member ID plus one more piece of information could uniquely identify the claim. Let’s ask the LLM how to simplify the process flow. </p> 
  </div> 
  <div class="browsable-container listing-container" id="p45"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.4</span> Asking the LLM to improve the dialogue flow from listing 10.2</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">&lt;&lt;Listing 10.1 prompt&gt;&gt; <span class="aframe-location"/> #1
&lt;&lt;Listing 10.2 output&gt;&gt; <span class="aframe-location"/> #2


Instruction: Simplify the dialogue flow above. Only <span class="aframe-location"/> #3
require the user to provide two pieces of information. 

Output: <span class="aframe-location"/> #4</pre> 
    <div class="code-annotations-overlay-container">
     #1 The full content of listing 10.1 is in the prompt but omitted here for brevity.
     <br/>#2 The full content of listing 10.2 is in the prompt but omitted here for brevity.
     <br/>#3 A lightweight instruction to the LLM
     <br/>#4 Output cue
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p46"> 
   <p>The “improvement” prompt is simple in nature. We simulate a conversation with the LLM by including the full history of our past conversation: the original prompt and its response. We then provide a basic instruction (“simplify the dialogue flow above”) with a definition of simplification (“only require the user to provide two pieces of information”). The output from this prompt is shown in the following listing.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p47"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.5</span> Simplified dialogue flow and justification provided by LLM</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">The simplified dialogue flow for the insurance claim chatbot would look like this:

1. User: Hi, I want to check my insurance claim.
2. Chatbot: Sure, I can help you with that. Can you  <span class="aframe-location"/> #1
   please provide me with your member ID and the claim   #1
   date?  #1
3. User: My member ID is 123456 and the claim date is January 10, 2022.
4. Chatbot: Thank you. I have all the information I need. Let me
   check the status of your claim.
5. Chatbot: The status of your claim is approved and  <span class="aframe-location"/> #2
   the amount of $1000 has been paid.  #2


The simplified dialogue flow only requires the user to provide two 
pieces of information: the member ID and the claim date. This reduces
the number of steps in the conversation and makes it even easier for
the user to complete. The chatbot can use the member ID to identify
the user's claims and the claim date to locate the specific claim.

By asking for both pieces of information at once, the chatbot can 
streamline the conversation and provide a more efficient user 
experience. The chatbot still confirms the claim information with 
the user before checking the claim status, ensuring the accuracy 
and reliability of the information provided.

Overall, the simplified dialogue flow is designed to provide a quick
and easy user experience, while still ensuring the accuracy and 
reliability of the information provided.</pre> 
    <div class="code-annotations-overlay-container">
     #1 Step 2 now collects all information in a single turn.
     <br/>#2 Step 5 converts the claim amount from an input to an output parameter.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p48"> 
   <p>We see two suggestions from the LLM: first, to not ask the claim amount, and second, to combine two questions into one. Let’s review them in detail:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p49"> <em>Removing the claim amount</em><em> </em>—Member ID and claim date are the two most “unique” data elements and the ones the user is most likely to have in hand. They are also the easiest to enter in web or phone bots, with most chat platforms having libraries to accept IDs and dates. The chatbot also informs the caller of the claim amount during the readout. </li> 
   <li class="readable-text" id="p50"> <em>Asking two questions at once</em><em> </em>—The new flow combines member ID and claim date into a single question (step 2). This is excellent for power users who want as few steps as possible. This may be more challenging for users who only have one piece of information available and need help finding the second. It is good for the chatbot to accept both pieces of information in one turn, but it may not be optimal to require it. </li> 
  </ul> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p51"> 
    <h5 class=" callout-container-h5 readable-text-h5">Subject matter experts or LLMs?</h5> 
   </div> 
   <div class="readable-text" id="p52"> 
    <p>We advise using subject matter expert (SME) advice before taking any solution to production. LLMs are great for generating ideas and testing ideas quickly. Use LLMs to explore the art of the possible and quickly draft potential solutions.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p53"> 
   <p>In one simple prompt, we generated two suggestions for how to improve the dialogue flow. Can you think of other ways to improve the dialogue flow? What instructions would you give the LLM? </p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p54"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text buletless-item" id="p55"> Take listing 10.4 and try some alternative instructions: 
     <ul> 
      <li> Only ask the user for one piece of information at a time. </li> 
      <li> Guide a user who says “I don’t have it” for one of the questions. </li> 
      <li> Introduce additional parameters, such as a claim ID, and see how the bot generates additional process flow variations. </li> 
     </ul></li> 
    <li class="readable-text buletless-item" id="p56"> Use an LLM to generate a process flow for a different scenario, such as these: 
     <ul> 
      <li> Booking a flight </li> 
      <li> Buying a movie ticket </li> 
      <li> Recommending a vacation destination </li> 
     </ul></li> 
   </ol> 
   <div class="readable-text" id="p57"> 
    <p>Or use a scenario from a chatbot you are building!</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p58"> 
   <h2 class=" readable-text-h2"><span class="num-string">10.2</span> AI-assisted process flows at run time</h2> 
  </div> 
  <div class="readable-text" id="p59"> 
   <p>It’s been great using generative AI to build process flow designs. So far, these have been somewhat static flows, usable in traditional conversational AI solutions. Claims status is an example of a “slot-filling” search, where we use a conversational process to collect information required to complete a task. This often takes the form of collecting required parameters for an API call. It requires careful mapping of questions and answer responses to an API. Then the answers are slotted into API parameters until the API can be executed. Slot-filling is one of the most popular conversational process flow patterns.</p> 
  </div> 
  <div class="readable-text intended-text" id="p60"> 
   <p>What about deferring more control to the LLM in these flows?</p> 
  </div> 
  <div class="readable-text" id="p61"> 
   <h3 class=" readable-text-h3"><span class="num-string">10.2.1</span> Executing dialogue flows with generative AI</h3> 
  </div> 
  <div class="readable-text" id="p62"> 
   <p>Our previous process flow was designed statically. Let’s try something different. We will just describe the process and let the LLM decide what questions to ask during the live conversation. Figure 10.3 shows how we’ll incorporate an LLM into the process of gathering information for the claim search API.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p63">  
   <img alt="figure" src="../Images/CH10_F03_Freed2.png" width="817" height="329"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 10.3</span> How a conversational AI can use an LLM to decide what question to ask next</h5>
  </div> 
  <div class="readable-text" id="p64"> 
   <p>We are assuming some logic in the chatbot:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p65"> When it detects a claim status intent, it lets the LLM decide what question to ask next. </li> 
   <li class="readable-text" id="p66"> When it detects the LLM responding with a list of variables, it takes back control and executes a claim search. </li> 
   <li class="readable-text" id="p67"> It uses guardrails like a preclassifier to ensure data sent to the LLM is not malicious, like “ignore all previous instructions and &lt;do something nasty&gt;.” </li> 
  </ul> 
  <div class="readable-text" id="p68"> 
   <p>The following listing demonstrates an LLM generating the conversation one step at a time.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p69"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.6</span> Letting the LLM decide what questions to ask for claim status</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">Instruction: You are a conversational designer. You <span class="aframe-location"/> #1
are building a chatbot to help users find information  #1
about their insurance claims.  #1
Insurance claims include the following information: a   #1
claim date, a member ID, and a claim amount.  #1
Generate conversational responses until you have <span class="aframe-location"/> #2
collected all three pieces of information.  #2
When you have all the information, respond with a   #2
payload in this format:  #2
{"memberID": "(the member id collected)", "claimDate":   #2
"(the claim date collected)", "claimAmount":   #2
"(the claim amount collected)"} #2

System: How can I help you? <span class="aframe-location"/> #3
User: I need information on my claim.  #3
System: <span class="aframe-location"/> #4</pre> 
    <div class="code-annotations-overlay-container">
     #1 Similar instruction to the previous prompts
     <br/>#2 Description of new task
     <br/>#3 Assuming a static greeting to the bot, we feed the bot’s initial greeting and user’s first utterance.
     <br/>#4 Output cue
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p70"> 
   <p>This simple prompt is enough to get the bot generating some dialogue for us. (We wrote this prompt in just a few minutes.) The next few listings show the output from each consecutive iteration of the prompt. The following listing shows the first turn, using the output from listing 10.6.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p71"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.7</span> Conversational turn 2 output (LLM generating next question to ask)</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">&lt;&lt;Listing 10.6 repeated&gt;&gt; <span class="aframe-location"/> #1
System: I can help you with that. What is your member  <span class="aframe-location"/> #2
ID?  #2</pre> 
    <div class="code-annotations-overlay-container">
     #1 Previous listing is included here
     <br/>#2 Output from first prompt
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p72"> 
   <p>The bot has done a nice job so far. It decided to ask for the member ID first. Let’s see what it does when the user responds.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p73"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.8</span> Conversational turn 2 output (LLM generating next question to ask)</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">&lt;&lt;Listing 10.7 repeated&gt;&gt; <span class="aframe-location"/> #1
User: 1234567 <span class="aframe-location"/> #2
System: What is your claim date? <span class="aframe-location"/> #3</pre> 
    <div class="code-annotations-overlay-container">
     #1 Previous listing is included here
     <br/>#2 User’s response is passed from chatbot to LLM
     <br/>#3 LLM response
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p74"> 
   <p>This is another reasonable response. The LLM is responding well without any guidance besides the initial prompt. The responses are a bit repetitive—both questions took the form of “What is your &lt;X&gt;.” Let’s see the rest of the conversation.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p75"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.9</span> Conversational output showing turns 3 and 4 </h5> 
   <div class="code-area-container"> 
    <pre class="code-area">&lt;&lt;Listing 10.8 repeated&gt;&gt; <span class="aframe-location"/> #1
User: May 4, 2024 <span class="aframe-location"/> #2
System: What is your claim amount? <span class="aframe-location"/> #3
User: $1000 <span class="aframe-location"/> #4
System: "memberID": "1234567", "claimDate": <span class="aframe-location"/> #5
"May 4, 2024", "claimAmount": "1000"</pre> 
    <div class="code-annotations-overlay-container">
     #1 Previous listing is included here
     <br/>#2 User’s response is passed from chatbot to LLM
     <br/>#3 LLM asks the final question
     <br/>#4 User’s final response is passed from chatbot to LLM
     <br/>#5 LLM generates a payload that the chatbot can use for search
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p76"> 
   <p>At the end of the dialogue flow, the LLM has done everything we needed. It asked questions without using hardcoded dialogue, and it generated a parameter set we could pass to the claim search API. (It did not generate valid JSON, but it could probably learn to do that from a better prompt.)</p> 
  </div> 
  <div class="readable-text intended-text" id="p77"> 
   <p>It could be tempting to give full control to the LLM at this point. Before we do, let’s see how the LLM reacts in a different scenario. This time, the user won’t know everything the system needs. How will the LLM react? The next listing demonstrates this scenario.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p78"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.10</span> LLM generated responses for when user doesn’t have all the information</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">Instruction: You are a conversational designer. You are building a chatbot to help users find information about their insurance claims.
Insurance claims include the following information: a claim date, a member ID, and a claim amount.
Generate conversational responses until you have collected all three pieces of information.
When you have all the information, respond with a  <span class="aframe-location"/> #1
payload in this format: {"memberID":   #1
"(the member id collected)", "claimDate":   #1
"(the claim date collected)", "claimAmount":   #1
"(the claim amount collected)"}  #1

System: How can I help you? <span class="aframe-location"/> #2
User: I need information on my claim.  #2
System: I can help you with that. What is your member   #2
ID?  #2
User: I don't know it. <span class="aframe-location"/> #3
System: What is your claim date?
User: I don't know that either.  #3
System: What is your claim amount?
User: $1000
System: I can help you with that. What is your member <span class="aframe-location"/> #4
ID?  #4</pre> 
    <div class="code-annotations-overlay-container">
     #1 Same instruction as in previous examples
     <br/>#2 Same initial conversation as in previous examples
     <br/>#3 User does not know some information
     <br/>#4 The LLM gets stuck!
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p79"> 
   <p>Uh-oh! The LLM has no sense of error handling in this prompt. It looks like the LLM will perpetually ask questions until the user ends the chat in frustration. The user probably can’t opt out of this chat either. Clearly this approach has some limitations.</p> 
  </div> 
  <div class="readable-text" id="p80"> 
   <p>Asking multiple questions to fulfill a search process was hit and miss. Let’s try something else. What if we let the LLM do the search?</p> 
  </div> 
  <div class="readable-text" id="p81"> 
   <h3 class=" readable-text-h3"><span class="num-string">10.2.2</span> Using LLM for a search process</h3> 
  </div> 
  <div class="readable-text" id="p82"> 
   <p>In scenarios like medical insurance, a careful search is critical. A healthcare provider may have hundreds of open claims (or more) across their patient population. Strict search criteria are critical to successful searches, not to mention being required by law. Let’s imagine a different scenario where there are far fewer options to search for.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p83"> 
    <h5 class=" callout-container-h5 readable-text-h5">Isn’t this retrieval-augmented generation (RAG)?</h5> 
   </div> 
   <div class="readable-text" id="p84"> 
    <p>Sort of. We are creating textual “passages” based on the output of structured APIs and letting the LLM reason over them. Purists may not call it RAG, but it has similarities. And most importantly, it is a useful tool in your toolbox, whatever you call it.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p85"> 
   <p>Our scenario for this example is consumers checking their bank account balances. A consumer generally has between one and four accounts at one bank. The chatbot will need to know which account the user is asking about. Only a few pieces of metadata are relevant to the accounts, including type (checking or savings), owner (solo or joint), and ID (though owners may not remember it).</p> 
  </div> 
  <div class="readable-text intended-text" id="p86"> 
   <p>Let’s assume the user is logged in to our chatbot (we know who they are from their logged-in user ID or their verified phone number). They ask for an account balance, and the chatbot asks the LLM for help. The flow diagram is shown in figure 10.4.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p87">  
   <img alt="figure" src="../Images/CH10_F04_Freed2.png" width="817" height="351"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 10.4</span> Using an LLM to handle user responses</h5>
  </div> 
  <div class="readable-text" id="p88"> 
   <p>We can imagine the user asking the following questions of the assistant:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p89"> How much money is in my account? </li> 
   <li class="readable-text" id="p90"> How much money is in my savings account? </li> 
   <li class="readable-text" id="p91"> How much money is our joint savings account? </li> 
   <li class="readable-text" id="p92"> How much money is in my son’s account? </li> 
   <li class="readable-text" id="p93"> How much money is in the account I just opened? </li> 
  </ul> 
  <div class="readable-text" id="p94"> 
   <p>The prompt and example output are shown in the following listing. This prompt is executed with stopping criteria of any whitespace character (space or newline). Otherwise, the LLM continues the output with a justification of its choice.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p95"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.11</span> Using an LLM to perform a search</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">&lt;|instruction|&gt;
You are supporting a digital assistant. A user is asking a question <span class="aframe-location"/> #1
about one of their bank accounts. Use the contextual information #1
provided to identify the bank account they are most likely asking about. #1

&lt;|user|&gt;
How much money is in my son’s account?  <span class="aframe-location"/> #2

&lt;|context|&gt;
User Name: Bob
Accounts: [ {"id":12345, "type":"checking", "owners":["Bob","Jane"], <span class="aframe-location"/> #3
 "opened":"12/25/2000"}, {"id":23456, "type":"saving",  #3
"owners":["Bob","Jane"], "opened":"1/3/2005}, {"id":34567,  #3
"type":"saving", "owners":["Bob","Jack"], "opened": "2/4/2024"}] #3

&lt;|output|&gt;
Account id: 34567  <span class="aframe-location"/> #4</pre> 
    <div class="code-annotations-overlay-container">
     #1 Basic instruction provided as a prompt
     <br/>#2 User’s input is passed directly to the LLM
     <br/>#3 LLM receives the context of the logged-in user and the metadata for all accounts
     <br/>#4 Output cue and output
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p96"> 
   <p>Awesome! The LLM can answer all five questions. Table 10.1 shows the LLM responses. Recall that we are only asking the LLM to pick the account ID. The chatbot will still invoke the final “check balance” API call and formulate the final response.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p97"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 10.1</span> Responses from listing 10.11 for several different input questions</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Question 
       </div></th> 
      <th> 
       <div>
         Response (Account ID) 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  How much money is in my account? <br/></td> 
      <td>  12345 <br/></td> 
     </tr> 
     <tr> 
      <td>  How much money is in my savings account? <br/></td> 
      <td>  23456 <br/></td> 
     </tr> 
     <tr> 
      <td>  How much money is in our joint savings account? <br/></td> 
      <td>  23456 <br/></td> 
     </tr> 
     <tr> 
      <td>  How much money is in my son’s account? <br/></td> 
      <td>  34567 <br/></td> 
     </tr> 
     <tr> 
      <td>  How much money is in the account I just opened? <br/></td> 
      <td>  34567 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p98"> 
   <p>We can make several observations :</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p99"> <em>Variability</em><em> </em>—We handled several different search criteria, including dates, types, and owners, without asking any disambiguation questions. </li> 
   <li class="readable-text" id="p100"> <em>Flexibility</em><em> </em>—Criteria like “my son” or “the account I just opened” were handled without a strict API parameter. </li> 
   <li class="readable-text" id="p101"> <em>Default choice</em><em> </em>—For the two ambiguous questions (“my account”) and (“our joint savings account”), the bot chose the first matching choice. This implies that sort order is important. </li> 
  </ul> 
  <div class="readable-text" id="p102"> 
   <p>The LLM offers incredible flexibility! If the stakes are low enough, letting the LLM search is an excellent strategy. Assuming that our output message is something like “Your &lt;type&gt; account with ID &lt;id&gt; has &lt;balance&gt;,” it may be okay that the LLM did not ask a clarifying question. The bot is always responding with accurate information and supporting evidence. The user may still ask follow-up questions like “No, I meant my savings account balance” if they need different information.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p103"> 
    <h5 class=" callout-container-h5 readable-text-h5">Is letting an LLM pick an account ID safe? What about hallucinations?</h5> 
   </div> 
   <div class="readable-text" id="p104"> 
    <p>In the example of consumers checking their bank account balances, we introduce safety by separating out the API call from the LLM judgment. A typical “get balance” API will have two parameters: a user ID and an account ID. In this scenario, we only let the LLM pick the account ID. Thus, we are protected from the LLM hallucinating a user ID and account ID combination that leaks someone else’s account information. If the LLM hallucinates an account ID, the API will fail the call; if the LLM picks the wrong account for this user, at least they will hear about one of their own accounts. Be sure to test your design and implementation thoroughly before assuming it is safe.</p> 
   </div> 
   <div class="readable-text" id="p105"> 
    <p>This kind of safety-driven design should be used when letting LLMs execute API calls.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p106"> 
   <p>Generative AI with LLMs offers us interesting possibilities in augmenting our chatbots. We need to carefully balance the trade-offs between implementation speed and control. But LLMs support things that would otherwise be difficult or impossible in traditional chatbots.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p107"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text" id="p108"> Update the prompt in listing 10.6 to give more varied responses (not just “what is your &lt;X&gt;”). </li> 
    <li class="readable-text" id="p109"> Update the prompt in listing 10.11 so that the LLM gives a sentinel value like “n/a” if the user’s question is ambiguous. You can give additional instructions in the prompt or add few-shot examples for the LLM to learn from. </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p110"> 
   <h2 class=" readable-text-h2"><span class="num-string">10.3</span> AI-assisted flows at test time</h2> 
  </div> 
  <div class="readable-text" id="p111"> 
   <p>In the previous sections, we used generative AI to design or implement the chat solution by having the LLM act as the chatbot. In this section, we will turn that paradigm on its head. We will use the LLM to generate typical or “creative” responses and see how the chatbot handles them in our insurance claims scenario. This conceptualized flow is shown in figure 10.5.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p112">  
   <img alt="figure" src="../Images/CH10_F05_Freed2.png" width="822" height="225"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 10.5</span> Flow diagram of how the test script invokes an LLM as a "user" of the chatbot</h5>
  </div> 
  <div class="readable-text" id="p113"> 
   <p>We need three things to put this test script together: a generalized prompt for the LLM to act as a user, a test script to invoke both the chatbot and the LLM, and a methodology for reviewing the results.</p> 
  </div> 
  <div class="readable-text intended-text" id="p114"> 
   <p>Let’s get started.</p> 
  </div> 
  <div class="readable-text" id="p115"> 
   <h3 class=" readable-text-h3"><span class="num-string">10.3.1</span> Setting up generative AI to be the user</h3> 
  </div> 
  <div class="readable-text" id="p116"> 
   <p>The LLM will need three pieces of information to be an effective user: general instructions for the task, a description of the scenario we need to test, and the conversation so far.</p> 
  </div> 
  <div class="readable-text intended-text" id="p117"> 
   <p>First, let’s provide some simple background telling the LLM we want it to mimic a user in an ongoing conversation. The instruction can start quite simply:</p> 
  </div> 
  <div class="browsable-container listing-container" id="p118"> 
   <div class="code-area-container"> 
    <pre class="code-area">Act as a user of a telephone-based medical insurance chatbot. Continue the conversation with a likely response.</pre>  
   </div> 
  </div> 
  <div class="readable-text" id="p119"> 
   <p>This instruction describes the basics of what we want the LLM to do. We are telling the LLM to respond as the user, not the system. We give no further guidance to the LLM.</p> 
  </div> 
  <div class="readable-text intended-text" id="p120"> 
   <p>Second, we want the LLM to be able to handle different scenarios. We need an adaptable prompt. Here are a few scenarios we’d like to test:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p121"> The user has all the information they need (member ID, claim date, claim amount). </li> 
   <li class="readable-text" id="p122"> The user is missing some necessary information. </li> 
   <li class="readable-text" id="p123"> The user is missing some necessary information but has alternatives (a claim ID). </li> 
  </ul> 
  <div class="readable-text" id="p124"> 
   <p>For each scenario, we would give slightly different guidance to the prompt. Table 10.2 maps some scenarios to the detailed guidance we could give the LLM.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p125"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 10.2</span> Scenario descriptions and prompt-able guidance</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Description 
       </div></th> 
      <th> 
       <div>
         Guidance 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  User has all the information they need <br/></td> 
      <td>  You are trying to find out if one of your medical claims was paid. <br/>  You know your member ID is 123456, the claim date is May 4, 2024, and the claim amount of $1000. <br/></td> 
     </tr> 
     <tr> 
      <td>  User is missing some necessary information <br/></td> 
      <td>  You are trying to find out if your most recent medical claim was paid. <br/>  You know your member ID is 123456 but don’t know anything else. <br/></td> 
     </tr> 
     <tr> 
      <td>  User is missing some necessary information but has alternatives <br/></td> 
      <td>  You are trying to find out if your most recent medical claim was paid. <br/>  You know your member ID is 123456 and that the claim ID is 987654321987654. <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p126"> 
   <p>The guidance in table 10.2 has the following information the LLM can use in the conversation:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p127"> <em>Scenario</em><em> </em>—What the LLM should try to do, such as find out if a claim was paid. </li> 
   <li class="readable-text" id="p128"> <em>Test data</em><em> </em>—We know the chatbot can call APIs, so we need the LLM to provide data that exists in our system. We explicitly give the LLM the information we want it to use. </li> 
   <li class="readable-text" id="p129"> <em>Boundaries</em><em> </em>—We tell the LLM what it does not know. This should prevent the LLM from “inventing” (hallucinating) information that will cause our later API calls to fail. </li> 
  </ul> 
  <div class="readable-text" id="p130"> 
   <p>We don’t provide the LLM any other guidance. We want to see how it tries to achieve these outcomes in the chatbot.</p> 
  </div> 
  <div class="readable-text intended-text" id="p131"> 
   <p>Finally, we need to provide the conversational transcript to the LLM to inform how it responds next (and what it has already responded with). The test script will be able to keep track of the transcript because it is invoking both the chatbot and LLM. (There are many ways to gather the chat transcript, and chapter 12 will demonstrate a few more.)</p> 
  </div> 
  <div class="readable-text intended-text" id="p132"> 
   <p>We can now build a Python function to generate a prompt for a given scenario. The function takes two arguments: the guidance for the scenario (as seen in table 10.2) and the conversational transcript. The next listing shows the function.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p133"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.12</span> Python function to build a prompt for a test scenario</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">def get_prompt(guidance, transcript):
   prompt=f'''
INSTRUCTION:
You are a user trying to find out your claim status.<span class="aframe-location"/> #1
{guidance} <span class="aframe-location"/> #2
Continue the conversation with a likely response.  #1

CONVERSATION:
{transcript} <span class="aframe-location"/> #3
User: ''' <span class="aframe-location"/> #4
   return prompt</pre> 
    <div class="code-annotations-overlay-container">
     #1 Generic description of the task
     <br/>#2 Scenario-specific guidance and test details
     <br/>#3 Injects the conversational transcript
     <br/>#4 Cue for LLM response
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p134"> 
   <p>This code’s function dynamically builds a prompt for a given scenario and conversation transcript. </p> 
  </div> 
  <div class="readable-text intended-text" id="p135"> 
   <p>Listing 10.13 demonstrates how we can call the <code>get_prompt()</code> function. It assumes a <code>call_llm()</code> function whose implementation will vary based on the LLM platform (assume it is initiated with an API key, it lets you pick a model and configuration settings, and it then provides a function that receives a prompt and returns output). Be sure to use sampling decoding in your <code>call_llm()</code> function so that you get variety in your responses.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p136"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.13</span> Python code to use a dynamic prompt</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">guidance='''You are trying to find out if one of your <span class="aframe-location"/> #1
medical claims was paid.  #1
You know your member ID 123456, claim date of May 4,  #1
2024, and the claim amount of $100.'''
transcript='''System: How can I help?
User: I need to check my claim status
System: What's your member ID?''' <span class="aframe-location"/> #2

prompt=get_prompt(guidance, transcript) <span class="aframe-location"/> #3
user_response=call_llm(prompt) <span class="aframe-location"/> #4
transcript += f"\nUser: {user_response}" <span class="aframe-location"/> #5</pre> 
    <div class="code-annotations-overlay-container">
     #1 Full text of the test scenario to guide the LLM
     <br/>#2 Full conversational transcript to date
     <br/>#3 Builds the prompt dynamically
     <br/>#4 Gets LLM response (e.g., “Sure, my member ID is 123456”)
     <br/>#5 Updates the conversational transcript
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p137"> 
   <p>We now have the first half of our test script. Let’s set up the other half.</p> 
  </div> 
  <div class="readable-text" id="p138"> 
   <h3 class=" readable-text-h3"><span class="num-string">10.3.2</span> Setting up the conversational test</h3> 
  </div> 
  <div class="readable-text" id="p139"> 
   <p>Next, the test script must call the chatbot. The script will take the LLM-generated “user” input and pass it to the bot. Then the script will take the bot’s response, append it to the transcript, and call the LLM again. We will again depend on a function not implemented here (the implementation will vary by platform)—in this case, that function is <code>call_chatbot()</code>. This function is expected to configure a connection to a chatbot, authenticate with an API key, and manage a user conversation. </p> 
  </div> 
  <div class="readable-text intended-text" id="p140"> 
   <p>The following listing shows this part of our test script.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p141"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.14</span> Python code to call the chatbot</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">#user_response comes from LLM call
bot_response=call_chatbot(user_response) <span class="aframe-location"/> #1
transcript += f"\nSystem: {bot_response}" <span class="aframe-location"/> #2</pre> 
    <div class="code-annotations-overlay-container">
     #1 Sends a message to the chatbot
     <br/>#2 Stores the chatbot response in the transcript
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p142"> 
   <p>We can now put all the pieces together. In the next listing, we combine all the elements into a single test script.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p143"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.15</span> Python code combining LLM-as-user and chatbot calls</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">def run_test(guidance):
   print(f"Running test with:\n{guidance}\n")
   bot_response = call_chatbot('') <span class="aframe-location"/> #1
   transcript = f"System: {bot_response}"
   for i in range(4): <span class="aframe-location"/> #2
      prompt=get_prompt(guidance, transcript)
      user_response=call_llm(prompt)
      transcript += f"\nUser: {user_response}"
      bot_response=call_chatbot(user_response) <span class="aframe-location"/> #3
      transcript += f"\nSystem: {bot_response}" <span class="aframe-location"/> #4
   print(f"Transcript:\n{transcript}") <span class="aframe-location"/> #5</pre> 
    <div class="code-annotations-overlay-container">
     #1 A conversation is often initiated with “blank” input.
     <br/>#2 Tests a few turns of the conversation
     <br/>#3 Sends the LLM response to the chatbot
     <br/>#4 Stores the chatbot response in the transcript
     <br/>#5 Prints the transcript at the end of the test
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p144"> 
   <p>The script initiates a connection to the chatbot and runs through a fixed number of turns (four). Depending on our test needs, we could increase or decrease that number or put in additional logic to detect when the conversation has ended (or failed). </p> 
  </div> 
  <div class="readable-text intended-text" id="p145"> 
   <p>The next listing shows some example output from running this script on one of our test scenarios.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p146"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.16</span> Test script example output</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">Running test with:
You are trying to find out if one of your medical claims was paid.
You know your member ID 123456, claim date of May 4, 2024, and the 
claim amount of $1000.

Transcript:
System: How can I help you?
User: Hi, I'd like to check the status of a medical claim.
System: I can help you with that. What is your member ID?
User: Yes, my member ID is 123456.
System: What is your claim date?
User: My claim date is May 4, 2024.
System: What is your claim amount?
User: The claim amount was $1000.
System: Thank you. I have all the information I need. Let me check the status of your claim.
The status of your claim is approved and the amount of $1000 has been paid.</pre>  
   </div> 
  </div> 
  <div class="readable-text" id="p147"> 
   <p>This script sets up the basic mechanics of having an LLM act as a user of your chatbot. </p> 
  </div> 
  <div class="readable-text intended-text" id="p148"> 
   <p>This kind of test is an excellent supplement to your other testing efforts. LLMs may generate user inputs that you never thought to handle in your chatbot, and it is good to find out how your chatbot responds to them. Remember that the LLM is only simulating a human—real humans may never act or “speak” the way an LLM does. But then again, they might.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p149"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text" id="p150"> Play the role of the bot. Implement the function <code>call_chatbot(user_ response)</code> with the following code: </li> 
   </ol> 
   <div class="browsable-container listing-container" id="p151"> 
    <div class="code-area-container"> 
     <pre class="code-area">return input('Enter the bot response: ')</pre>  
    </div> 
   </div> 
   <div class="readable-text" id="p152"> 
    
<ol class=" faux-ol-li" style="list-style: none;"> 
    <li class="readable-text faux-li has-faux-ol-li-counter">This lets you test how the LLM responds (as a user) to the messages you (as a chatbot) send. This saves you from having to implement a chatbot just to see how this test script works.</li> </ol>
   </div> 
   <ol class=" faux-ol-li" style="list-style: none;"> 
    <li class="readable-text faux-li has-faux-ol-li-counter" id="p153"><span class="faux-ol-li-counter">2. </span> Connect the <code>call_chatbot(user_response)</code> function to an actual chatbot you are building. Connect the <code>call_llm(prompt)</code> function to your AI platform of choice. Update the <code>get_prompt</code> function to be more appropriate for your scenario. Does the LLM stretch the capabilities of your chatbot? </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p154"> 
   <h2 class=" readable-text-h2">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p155"> LLMs can design a process flow for you from scratch. With a little prompting, they can generate example conversational flows and justify their design choices. This process flow can then be implemented in traditional conversational AI. </li> 
   <li class="readable-text" id="p156"> LLMs can also take an existing process flow and improve it. A typical improvement is simplifying the process flow. </li> 
   <li class="readable-text" id="p157"> You can use generative AI to execute an entire conversation. There is a trade-off between implementation speed and control. This is especially noticeable on error paths. </li> 
   <li class="readable-text" id="p158"> You can replace some slot-filling process flows with an LLM-driven process. This can be much more flexible than strictly matching to API parameters. </li> 
   <li class="readable-text" id="p159"> Consider the cost of being wrong when letting LLMs make judgments. Look for cases where “mistakes” are not critical. Be careful about which APIs the LLM is allowed to influence. </li> 
   <li class="readable-text" id="p160"> LLMs can simulate users of your conversational AI. Use them to generate test conversations that show how your system may behave in certain scenarios. </li> 
  </ul>
 </div></div></body></html>