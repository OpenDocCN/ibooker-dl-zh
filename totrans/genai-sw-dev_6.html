<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 6. Documentation and Technical Writing"><div class="chapter" id="ch06_documentation_and_technical_writing_1749441076918717">
      <h1><span class="label">Chapter 6. </span>Documentation and Technical Writing</h1>
      <p>Documentation is vital for clarity, consistency, and knowledge transfer in software development. It ensures that team members understand the code when onboarding and reduces the learning curve during day-to-day work, leaving less room for lost context and the consequent errors and refactorings.</p>
      <p>Documentation is also important <a contenteditable="false" data-type="indexterm" data-primary="documentation" id="id459"/><a contenteditable="false" data-type="indexterm" data-primary="technical writing" id="id460"/>for nontechnical stakeholders such as product managers, customer-support representatives, and those working in marketing, sales, and operations. Clear documentation fosters collaboration across teams and creates a single source of truth that prevents miscommunication. As software evolves, proper documentation simplifies codebase maintenance and onboarding for new developers, bolstering the longevity of the project.</p>
      <p>Outside the company, documenting how to use a software product can help sales and marketing efforts, prevent difficulties during customer onboarding, and foster user engagement with the product. Writing features and workflows down for external stakeholders is also a great starting point for collecting their feedback on how to improve the product.</p>
      <p>Despite its importance, documentation often doesn’t get written at all. Software engineers don’t usually enjoy writing for humans, so they often skip it if they can. But they are almost always under deadline pressure, and when they have to make compromises, documentation is often one of the things left behind. Even when it does get written, heavy workloads and time pressure often lead to rushed or incomplete content. Writing high-quality documentation takes time. Additional challenges include finding the right level of detail and keeping documentation up to date as systems evolve.</p>
      <p>AI tools were helping generate written content for many years before the recent LLM-driven AI wave. Writing tools such as Grammarly, which helps find the correct words and fix mistakes, are especially helpful for those writing in a foreign language. In software development, tools such as Swagger and Javadoc also use AI to automatically generate API documentation in tandem with code updates.</p>
      <p>The tools I review in this chapter were launched more recently, mostly since the generative AI wave started in 2022, and all aim to extend the simplicity of generating documentation from code beyond simple modules (like APIs) and helpers (like Grammarly). Some aim to be competent enough to replace the need for human action in writing documentation.</p>
      <section data-type="sect1" data-pdf-bookmark="Types of Documentation"><div class="sect1" id="ch06_types_of_documentation_1749441076918822">
        <h1>Types of Documentation</h1>
        <p>There are four key types of documentation commonly found in software <span class="keep-together">development:</span></p>
        <dl>
          <dt>API/SDK documentation</dt>
          <dd>
            <p>A critical resource <a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="SDKs (software development kits)" id="id461"/><a contenteditable="false" data-type="indexterm" data-primary="SDKs (software development kits)" data-secondary="documentation" id="id462"/><a contenteditable="false" data-type="indexterm" data-primary="APIs (application programming interfaces), documentation" id="id463"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="APIs (application programming interfaces)" id="id464"/>for developers, documentation of APIs and software development kits (SDKs), provides clear, structured details about the functions, methods, and services available within a software system. These documentation interfaces serve as a bridge between different software components, ensuring that developers can integrate and use the system efficiently.</p>
          </dd>
          <dt>Internal documentation and feature specifications</dt>
          <dd>
            <p>When business stakeholders define a new product or feature to be developed in order to fulfill a <a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="internal" id="id465"/><a contenteditable="false" data-type="indexterm" data-primary="internal documentation" id="id466"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="feature specifications" id="id467"/><a contenteditable="false" data-type="indexterm" data-primary="feature specifications" id="id468"/><a contenteditable="false" data-type="indexterm" data-primary="specifications, documentation" id="id469"/>business objective, they write feature specifications to let software engineers know what functionalities to implement. The engineers’ role is to extend those specifications with technical system designs, architectural decisions, and workflows that document not just <em>what</em> was implemented, but also <em>how</em> it was implemented. This type of documentation is vital for maintaining and evolving software projects over time, especially when the original engineers are no longer around.</p>
          </dd>
          <dt>User guides and manuals</dt>
          <dd>
            <p>These documents help nontechnical users understand how to use the software. They include everything <a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="user guides" id="id470"/><a contenteditable="false" data-type="indexterm" data-primary="user guides" id="id471"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="manuals" id="id472"/><a contenteditable="false" data-type="indexterm" data-primary="manuals" id="id473"/>from installation instructions to troubleshooting tips. They’re useful during the sales process as support material for sales and marketing colleagues, and as customers use the product. The challenge here lies in writing documentation for users who don’t have a technical background.</p>
          </dd>
          <dt>Release notes and changelogs</dt>
          <dd>
            <p>These documents are used to <a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="release notes" id="id474"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="changelogs" id="id475"/><a contenteditable="false" data-type="indexterm" data-primary="release notes" id="id476"/><a contenteditable="false" data-type="indexterm" data-primary="changelogs, documentation" id="id477"/>communicate changes to the software, such as bug fixes, new features, or performance improvements. More than just keeping everyone informed, effective release notes inform both internal and external stakeholders of the need to update integrations and workflows to accommodate the changes.</p>
          </dd>
        </dl>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Evaluation Process"><div class="sect1" id="ch06_evaluation_process_1749441076918877">
        <h1>Evaluation Process</h1>
        <p>I evaluated more than 20 AI tools in the documentation and technical writing space in order to shortlist <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="documentation" data-tertiary="evaluation" id="id478"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="tools" data-tertiary="evaluation" id="id479"/>the four highlighted in this chapter. Every tool covered here meets the following criteria:</p>
        <ul>
          <li>
            <p>It is a professional project with a competent team behind it.</p>
          </li>
          <li>
            <p>It generates high-quality results.</p>
          </li>
          <li>
            <p>It offers some level of functionality for free or on a trial basis.</p>
          </li>
          <li>
            <p>It has a high level of adoption at the time of writing (mid-2025).</p>
          </li>
        </ul>
        <p>For this test, I created a very simple authentication flow, with both frontend and backend. The full code, which is available in this book’s <a href="https://github.com/sergiopereira-io/oreilly_book">GitHub repository</a>, contains flows for signup, login, and logout. I’ve used the AI tools in this chapter to document my code. My main point of comparison is whether the documentation produced can be useful for any of the four documentation use cases explained previously.</p>
        <p>Again, for this test I gave preference to tools that can be used with a simple signup and free trial, so I stayed away from enterprise tools.</p>
      
        <p>The full documentation generated for each test can be found in the book’s <a href="https://github.com/sergiopereira-io/oreilly_book">GitHub repository</a>.</p>
        <section data-type="sect2" data-pdf-bookmark="Swimm"><div class="sect2" id="ch06_swimm_1749441076918989">
          <h2>Swimm</h2>
          <p><a href="https://swimm.io">Swimm</a> is an AI-powered documentation tool designed specifically for <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="documentation" data-tertiary="Swimm" id="tldcswm"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="tools" data-tertiary="Swimm" id="dctlswmm"/><a contenteditable="false" data-type="indexterm" data-primary="Swimm" id="swmmiw"/>software engineers. It automates the creation and maintenance of code documentation. To ensure that it stays current with every code change, Swimm integrates directly into the code repository. Engineers can create documentation for a certain code file or snippet, or create/update documentation with each new pull request (PR). The latter option is a great fit for most software development teams’ processes, since a PR represents the most granular level of iteration to the codebase. Each such iteration needs to be documented, and each has the potential to render the existing documentation outdated.</p>
          <p>I think this flow is comparable to the automated code reviews in <a data-type="xref" href="ch03.html#ch03_bug_detection_and_code_review_1749441076008122">Chapter 3</a>. I can see how embedding these tools into a repo can provide a seamless integration into existing software development processes.</p>
          <p class="pagebreak-before less_space">While Swimm can be blended into the repo and create or update documentation upon each PR, for the sake of this comparison test, I haven’t used that exact flow. I’ve simply used Swimm’s browser-based UI, which allows me to connect the repo, select specific files to be documented, and prompt for what to include in the documentation, as shown in <a data-type="xref" href="#ch06_figure_1_1749441076913322">Figure 6-1</a>.</p>
          <figure><div id="ch06_figure_1_1749441076913322" class="figure">
            <img alt="" src="assets/gasd_0601.png" width="600" height="491"/>
            <h6><span class="label">Figure 6-1. </span>Swimm’s widget to create a piece of documentation</h6>
          </div></figure>
          <p>In this flow, I’ve asked Swimm to document the backend part of my authentication flow with a simple prompt: </p>
          <pre data-type="programlisting">Describe the functionality and technical implementation. 
 </pre>
          <p>The desired output is a document that can be used for internal visibility on ongoing initiatives and for onboarding future team members. You can see a sample of the result in <a data-type="xref" href="#ch06_figure_2_1749441076913353">Figure 6-2</a>.</p>
          <figure><div id="ch06_figure_2_1749441076913353" class="figure">
            <img alt="" src="assets/gasd_0602.png" width="600" height="795"/>
            <h6><span class="label">Figure 6-2. </span>Sample of Swimm’s output for the backend documentation</h6>
          </div></figure>
          <p class="pagebreak-before less_space">This output is quite good. I like the structure of the document as well as its content. However, my authentication flow is probably too simple to showcase Swimm’s full potential. So I tested a second example for a more complex document: </p>
          <pre data-type="programlisting">Describe the frontend code and create a test plan for each flow. </pre>
          <p>The result was again very good. It generated a full document (whose table of contents can be found in <a data-type="xref" href="#ch06_figure_3_1749441076913376">Figure 6-3</a>), including a high-level introduction and then a deep dive into specific code components that impact the flow and thus should be documented.</p>
          <figure><div id="ch06_figure_3_1749441076913376" class="figure">
            <img alt="" src="assets/gasd_0603.png" width="304" height="800"/>
            <h6><span class="label">Figure 6-3. </span>Table of contents of the document generated by Swimm for the frontend code</h6>
          </div></figure>
          <p>The last section of the document, as I asked, identifies the main flows of my code and provides test plans for each. The actual test plans are quite simplistic, but that’s probably a byproduct of the simplicity of the underlying flow, as shown here:</p>
          <p class="pagebreak-before less_space">
            <strong>Test plan</strong>
          </p>
        <dl> <dt> Test login flow</dt>
       <dd>   <ol>
            <li>
              <p>Verify the login form is visible by default.</p>
            </li>
            <li>
              <p>Enter valid credentials and submit; expect a success message.</p>
            </li>
            <li>
              <p>Enter invalid credentials and submit; expect an error alert.</p>
            </li>
            <li>
              <p>Click “Register here” and ensure the registration form appears.</p>
            </li>
          </ol></dd>
          <dt>
            Test registration flow
          </dt>
         <dd> <ol>
            <li>
              <p>Click “Register here” to switch to the registration form.</p>
            </li>
            <li>
              <p>Enter valid details and submit; expect a success message.</p>
            </li>
            <li>
              <p>Enter invalid details and submit; expect an error alert.</p>
            </li>
            <li>
              <p>Click “Login here” and ensure the login form reappears.</p>
            </li>
          </ol></dd>
          <dt>
            Test success and logout
          </dt>
         <dd> <ol>
            <li>
              <p>After successful login or registration, verify the success message is displayed.</p>
            </li>
            <li>
              <p>Click the logout button and ensure the login form is shown again.</p>
            </li>
          </ol></dd></dl>
          <p>Swimm did well in this test. It was easy to get started with this tool, and it generated relevant documentation for my requests in correct Markdown format, which is the standard in technical documentation. However, I found it quite limiting that Swimm can only document one file of code at a time. This produces very fragmented pieces of documentation that are closer to a <em>read.me</em> file than a higher-level codebase and flow documentation. </p>
          <p>I see working with a larger scope of source material as a natural evolution for Swimm, which could leverage its superior integration flow to create documentation for the whole codebase, or at least groups of files. It could work horizontally, documenting the structure of frontend code by using all frontend files as the object of a document, or vertically, documenting a feature flow by using all files <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="documentation" data-tertiary="Swimm" data-startref="tldcswm" id="id480"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="tools" data-tertiary="Swimm" data-startref="dctlswmm" id="id481"/><a contenteditable="false" data-type="indexterm" data-primary="Swimm" data-startref="swmmiw" id="id482"/>related to that feature.</p>
          <p>As such, I’m rating Swimm a 6/10. While the UX is good, the output is still far from the quality of documentation that I would accept from my teams.</p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="ChatGPT"><div class="sect2" id="ch06_chatgpt_1749441076919038">
          <h2>ChatGPT</h2>
          <p><a href="https://chat.openai.com">ChatGPT</a> is most software engineers’ go-to LLM tool for <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="documentation" data-tertiary="ChatGPT" id="tldcCHPT"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="tools" data-tertiary="ChatGPT" id="dctlchpgt"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT" data-secondary="documentation" id="tpgtch"/>creating documentation, so I’m including it in this chapter, specifically the GPT-4o model, the most advanced available at the time of writing (mid-2025).</p>
          <p>I started by prompting ChatGPT to generate the documentation for my code. I included in the prompt all six code files, a screenshot of the repository structure (so it understands the relationships between the code files), and instructions for what the documentation should include, as seen in <a data-type="xref" href="#ch06_figure_4_1749441076913394">Figure 6-4</a>.</p>
          <figure><div id="ch06_figure_4_1749441076913394" class="figure">
            <img alt="" src="assets/gasd_0604.png" width="600" height="264"/>
            <h6><span class="label">Figure 6-4. </span>Instructions to ChatGPT to document my code</h6>
          </div></figure>
          <p>ChatGPT generated very comprehensive documentation, as seen in the table of contents in <a data-type="xref" href="#ch06_figure_5_1749441076913411">Figure 6-5</a>.</p>
          <figure><div id="ch06_figure_5_1749441076913411" class="figure">
            <img alt="" src="assets/gasd_0605.png" width="270" height="800"/>
            <h6><span class="label">Figure 6-5. </span>Table of contents of the documentation generated by ChatGPT</h6>
          </div></figure>
          <p>This is a really good output; it’s very complete documentation with sections for all of the expected main components, from high-level context (such as repository structure) to a detailed deep dive in each specific component, such as the API, visible in <a data-type="xref" href="#ch06_figure_6_1749441076913428">Figure 6-6</a>.</p>
          <figure><div id="ch06_figure_6_1749441076913428" class="figure">
            <img alt="" src="assets/gasd_0606.png" width="600" height="640"/>
            <h6><span class="label">Figure 6-6. </span>ChatGPT’s documentation of the API module</h6>
          </div></figure>
          <p>You can ask ChatGPT to output the documentation directly into a Markdown file. I committed the final documentation generated by ChatGPT (as well as the other tools in this chapter) to the book’s <a href="https://github.com/sergiopereira-io/oreilly_book">GitHub repository</a>.</p>
          <p class="pagebreak-before less_space">As expected, ChatGPT performs very well in this limited-scope test. It will work with up to 20 files at a time, and the file size limit varies by file type. While that’s totally OK for small projects like my authentication application, it is insufficient for most production-level applications. On top of those limits, ChatGPT also offers an inconvenient UI, compared to tools that connect to the repository. The need to upload files manually and give ChatGPT contextual information about their structure and relationships makes it more challenging to use, especially for large projects.</p>
          <p>As such, I’m rating ChatGPT a 7/10 for this use case. The quality of the documentation is very good, with the caveat of the limits and inconvenient UI. It would take a software <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="documentation" data-tertiary="ChatGPT" data-startref="tldcCHPT" id="id483"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="tools" data-tertiary="ChatGPT" data-startref="dctlchpgt" id="id484"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT" data-secondary="documentation" data-startref="tpgtch" id="id485"/>engineer some creativity to document clusters of an application (by functionality or part of the stack, or module) within the limit of 20 files per piece of <span class="keep-together">documentation.</span></p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Cursor"><div class="sect2" id="ch06_cursor_1749441076919085">
          <h2>Cursor</h2>
          <p><a href="https://www.cursor.com">Cursor</a> is a relatively new player in the AI coding tool space. It was <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="documentation" data-tertiary="Cursor" id="tldccrsr"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="tools" data-tertiary="Cursor" id="dctlCuroR"/><a contenteditable="false" data-type="indexterm" data-primary="Cursor" data-secondary="documentation" id="crsrdcmn"/>launched in 2023 and has captured massive market share in the specific category of IDEs with AI code-assistant capabilities, which has been led by GitHub Copilot. As of August 2024, <span class="keep-together">Cursor</span> had 40,000 customers.<sup><a data-type="noteref" id="id486-marker" href="ch06.html#id486">1</a></sup></p>
          <p>Cursor’s product is an AI-native IDE that started as a fork from the popular Visual Studio Code. It allows software engineers to select which LLM should power the tool; I’ve used Anthropic’s Claude 3.5 Sonnet. As an actual IDE, Cursor has visibility into all code files in my repository, regardless of their number or size. You enter prompts through a chat feature, as shown in <a data-type="xref" href="#ch06_figure_7_1749441076913461">Figure 6-7</a>.</p>
          <figure><div id="ch06_figure_7_1749441076913461" class="figure">
            <img alt="" src="assets/gasd_0607.png" width="600" height="126"/>
            <h6><span class="label">Figure 6-7. </span>Prompt to Cursor to generate documentation</h6>
          </div></figure>
          <p class="pagebreak-before less_space">The document Cursor generated was good, with sections for the expected main components, as seen in the table of contents in <a data-type="xref" href="#ch06_figure_8_1749441076913477">Figure 6-8</a>.</p>
          <figure><div id="ch06_figure_8_1749441076913477" class="figure">
            <img alt="" src="assets/gasd_0608.png" width="332" height="800"/>
            <h6><span class="label">Figure 6-8. </span>Table of contents of the documentation generated by Cursor</h6>
          </div></figure>
          <p>Despite the very comprehensive outline and the relevancy of its content, Cursor has a significant pitfall when it comes to generating Markdown documents. For some reason (perhaps a bug), the generated content is only partially formatted as a Markdown file. It outputs some sections as raw text, such as the snippet in <a data-type="xref" href="#ch06_figure_9_1749441076913495">Figure 6-9</a>. This makes it much harder to read.</p>
          <figure><div id="ch06_figure_9_1749441076913495" class="figure">
            <img alt="" src="assets/gasd_0609.png" width="600" height="334"/>
            <h6><span class="label">Figure 6-9. </span>Formatting issue in Cursor’s generated Markdown document</h6>
          </div></figure>
          <p>Despite these formatting issues, the documentation generated is extensive, covers the right topics, and has the correct level of technical depth. It’s definitely in line with what <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="documentation" data-tertiary="Cursor" data-startref="tldccrsr" id="id487"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="tools" data-tertiary="Cursor" data-startref="dctlCuroR" id="id488"/><a contenteditable="false" data-type="indexterm" data-primary="Cursor" data-secondary="documentation" data-startref="crsrdcmn" id="id489"/>I would consider acceptable documentation from my teams. As such, I rate <span class="keep-together">Cursor</span> 8/10.</p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Scribe"><div class="sect2" id="ch06_scribe_1749441076919131">
          <h2>Scribe</h2>
          <p><a href="https://scribehow.com">Scribe</a> is a very different tool from the others reviewed in <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="documentation" data-tertiary="Scribe" id="tldccscrb"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="tools" data-tertiary="Scribe" id="dctlsbrc"/><a contenteditable="false" data-type="indexterm" data-primary="Scribe" id="sbrcib"/>this chapter. This tool is best suited for creating user guides, standard operating procedures (SOPs), or bug reports in a visual way. While my use of Swimm, ChatGPT, and Cursor focused on creating written documentation about the technical implementation of a certain product or functionality, I used Scribe to produce a guide about the product’s <span class="keep-together">functionality.</span> </p>
          <p>While Scribe was created in 2019 as a basic screen capture tool, the functionality I used for this test, called Scribe AI, was only launched in 2023. It leverages the original functionality that allows a user to record a browser session, but instead of simply storing the video of the recording, it also creates an entire workflow with annotations, based on the screen transitions in the recording. That’s why it caters to UI-related use cases, like bug reports and product guides.</p>
          <p>To start the test, I installed Scribe’s Chrome extension and used it to record a simple session of registering a new account and logging in to that account. My goal was for Scribe to generate a user guide that I could share with external nontechnical stakeholders, like users of the product.</p>
          <p>The experience of recording my first session was quite seamless; I got the recording I needed easily on my first try. It’s called a Scribe, the name for both the video recording and the annotated workflow that’s generated, and it’s available in <a href="https://oreil.ly/lsVD3">this public link</a>. I’d say this output is good, since it identifies the screen transitions in my workflow and captures the screenshots of each screen, highlighting the action that the user did on the screen to cause the transition. The result is in line with user shadowing tools like Hotjar or Fullstory, which are commonly used for user research and bug <span class="keep-together">tracking.</span></p>
          <p>Scribe offers a feature that converts the raw HTML document in the preceding public link into an AI-generated document. I used the authentication flow to test the feature, which allows the user to write a prompt specifying the documentation piece to be generated from the screen recording. My instructions were simple, as shown in <a data-type="xref" href="#ch06_figure_10_1749441076913514">Figure 6-10</a>.</p>
          <figure><div id="ch06_figure_10_1749441076913514" class="figure">
            <img alt="" src="assets/gasd_0610.png" width="600" height="472"/>
            <h6><span class="label">Figure 6-10. </span>Instructions to Scribe to generate a document from raw tracking of website actions</h6>
          </div></figure>
          <p class="fix_tracking">The resulting document is <a href="https://oreil.ly/WcT6u">publicly available here</a>. I found this output underwhelming. It’s generic; it feels like it could have been written about any application, not specifically about mine. It generated a document and embedded Scribes (specific flows) into it, as opposed to generating a document based on the flow I recorded, which was my intention. This makes me think that the tool might be a better fit to generate larger pieces of documentation that involve several different Scribes merged together in a large <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="documentation" data-tertiary="Scribe" data-startref="tldccscrb" id="id490"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="tools" data-tertiary="Scribe" data-startref="dctlsbrc" id="id491"/><a contenteditable="false" data-type="indexterm" data-primary="Scribe" data-startref="sbrcib" id="id492"/>document (e.g., a product guide). The content of the generated document is not very relevant to the use case. As such, I’m rating Scribe a 5/10.</p>
        </div></section>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Tool Comparison"><div class="sect1" id="ch06_tool_comparison_1749441076919179">
        <h1>Tool Comparison</h1>
        <p><a data-type="xref" href="#ch06_table_1_1749441076915226">Table 6-1</a> compares the <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="documentation" data-tertiary="comparing" id="id493"/><a contenteditable="false" data-type="indexterm" data-primary="documentation" data-secondary="tools" data-tertiary="comparing" id="id494"/>ratings for each of the tools discussed in the chapter.</p>
        <table id="ch06_table_1_1749441076915226" class="striped">
          <caption><span class="label">Table 6-1. </span>AI documentation tools overview</caption>
          <thead>
            <tr>
              <th>Tool</th>
              <th>UX</th>
              <th>Test performance</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Swimm</td>
              <td>Repository extension</td>
              <td>6/10</td>
            </tr>
            <tr>
              <td>ChatGPT</td>
              <td>Website</td>
              <td>7/10</td>
            </tr>
            <tr>
              <td>Cursor</td>
              <td>IDE</td>
              <td>8/10</td>
            </tr>
            <tr>
              <td>Scribe</td>
              <td>Chrome extension</td>
              <td>5/10</td>
            </tr>
          </tbody>
        </table>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="ch06_conclusion_1749441076919227">
        <h1>Conclusion</h1>
        <p>As a CTO for over a decade, I’ve found that documentation is one of those things that’s always lacking, but never to the point where it’s worth pausing ongoing work to fix it. In fact, bad documentation is a form of technical debt, but one that doesn’t break systems or degrade performance. It <em>does</em> degrade the <em>team’s</em> performance, however, which is a less visible and perhaps more damaging form of debt in a software development team.</p>
        <p>I’ve always found it hard to push software engineers in my teams to write documentation in the first place, and even harder to keep that documentation organized, accessible, and updated. I think that AI tools like the ones I reviewed in this chapter can play a fundamental role in making that process easier. With a simple prompt, they can generate documentation within seconds. It would take a human at least an hour or two to generate a similar document. And that time commitment compounds with complexity: the larger a system is, the more challenging and time-consuming it is to document it properly and keep that documentation up to date. In a team of a few dozen people, that work could easily add up to thousands of collective hours of work a year.</p>
        <p>While AI tools can create documentation instantly, they can also create bad documentation (just like humans can). I recommend that teams take the same approach to documentation as to setting coding guidelines: create a template for prompts or even for documents, with predefined sections and subsections. This serves as a backstop to avoid unnecessarily long documents, and facilitates readability by making content easier to find.</p>
        <p>With all that said, documentation created by AI tools must <em>always</em> be thoroughly reviewed and edited by team members. While it takes seconds to produce 90% of the deliverable, the final revisions and quality control must be performed by human beings, since the output does not always fulfill the objective. See the case with Scribe, where the document generated is generic; a human reviewer would have caught that flaw and improved the documentation manually.</p>
      </div></section>
    <div data-type="footnotes"><p data-type="footnote" id="id486"><sup><a href="ch06.html#id486-marker">1</a></sup> Anysphere Team. August 22, 2024. <a href="https://www.cursor.com/blog/series-a">“Series A and Magic”</a>. <em>Cursor</em> (blog).</p></div></div></section></div></div></body></html>