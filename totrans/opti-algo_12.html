<html><head></head><body>
  <h1 class="tochead" id="heading_id_2">9 <a id="idTextAnchor000"/>Particle swarm optimization<a id="idIndexMarker000"/></h1>

  <p class="co-summary-head">This chapter covers<a id="marker-321"/></p>

  <ul class="calibre5">
    <li class="co-summary-bullet">Introducing swarm intelligence</li>

    <li class="co-summary-bullet">Understanding the continuous particle swarm optimization algorithm</li>

    <li class="co-summary-bullet">Understanding binary particle swarm optimization</li>

    <li class="co-summary-bullet">Understanding permutation-based particle swarm optimization</li>

    <li class="co-summary-bullet">Adapting particle swarm optimization for a better trade-off between exploration and exploitation</li>

    <li class="co-summary-bullet">Solving continuous and discrete problems using particle swarm optimization</li>
  </ul>

  <p class="body">In the treasure-hunting mission I introduced in chapter 2, suppose you want to collaborate and share information with your friends instead of doing the treasure- hunting alone. However, you do not want to follow a competitive approach in which you only keep better-performing hunters and recruit new hunters to replace poorer-performing ones, like in the genetic algorithm (GA) explained in the previous chapters. You want to adopt a more cooperative approach and keep all the hunters, without replacing any, but you want to give more weight to the better-performing hunters and try to emulate their success. This scenario uses <i class="fm-italics">swarm intelligence</i> and corresponds to population-based optimization algorithms such as <i class="fm-italics">particle swarm optimization</i> (PSO), <i class="fm-italics">ant colony optimization</i> (ACO), and <i class="fm-italics">artificial bee colony</i> (ABC) algorithms, which will be explained in this fourth part of the book. <a id="idIndexMarker001"/><a id="idIndexMarker002"/><a id="idIndexMarker003"/></p>

  <p class="body">In this chapter, we’ll focus on different variants of PSO algorithms and apply them to solve continuous and discrete optimization problems. These variants include continuous PSO, binary PSO, permutation-based PSO, and adaptive PSO. Function optimization, the traveling salesman problem, neural network training, trilateration, coffee shop planning, and the doctor scheduling problem are discussed in this chapter and its supplementary exercises included in appendix C. The next chapter will cover the ACO and ABC algorithms.</p>

  <h2 class="fm-head" id="heading_id_3">9.1 Introducing swarm intelligence</h2>

  <p class="body"><a id="marker-322"/>Life on this planet is full of astonishing examples of collective behavior. Individual species depend upon one another for sustenance, often forming surprising alliances to achieve a common goal: the continuance of the species. The majority of living things also display amazing altruism in order to protect and provide the best care for their offspring, comparable to any form of sacrifice shown by human beings. They can cooperatively perform complex tasks such as foraging for food, dividing up labor, constructing nests, brood sorting, protecting, herding, schooling, and flocking, to name just a few. These complex collective behaviors emerge from individual interactions between spatially distributed and simple entities without a centralized controller or coordinator and without a script or access to global information. Various cooperation patterns, communication mechanisms, and adaptation strategies are employed to enable such complex collective behaviors. <a id="idIndexMarker004"/><a id="idIndexMarker005"/></p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">Swarm intelligence</p>

    <p class="fm-sidebar-text">Swarm intelligence is a subfield of artificial intelligence that explores how large groups of relatively simple and spatially distributed agents can interact with each other and with their environment in a decentralized and self-organized manner to collectively achieve complex goals.<a id="idIndexMarker006"/></p>
  </div>

  <p class="body">Several efficient population-based algorithms have been designed to exploit the power of collective intelligence by mimicking the collective behaviors observed in nature to solve complex optimization problems. Table 9.1 provides a non-exhaustive list of swarm intelligence algorithms and their sources of inspiration from unicellular and multicellular living organisms. <a id="idIndexMarker007"/></p>

  <p class="fm-table-caption">Table 9.1 Examples of swarm intelligence algorithms and their sources of inspiration<a id="marker-323"/></p>

  <table border="1" class="contenttable-1-table" id="table001" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="30%"/>
      <col class="contenttable-0-col" span="1" width="30%"/>
    </colgroup>

    <thead class="calibre6">
      <tr class="contenttable-0-tr">
        <th class="contenttable-1-th">
          <p class="fm-table-head">Organisms</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Class</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Source of inspiration</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Algorithms</p>
        </th>
      </tr>
    </thead>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Unicellular organisms</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Bacteria</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Bacterial swarm foraging</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Bacterial foraging optimization algorithm (BFO)</p>

          <p class="fm-table-body">Bacterial swarming algorithm (BSA)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td" rowspan="17">
          <p class="fm-table-body">Multicellular organisms</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Bird/fish</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Bird flocking and fish schooling</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Particle swarm optimization (PSO)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Ant</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Ant foraging behaviors</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Ant colony optimization (ACO)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Bees</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Foraging behavior of honeybees</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Artificial bee colony (ABC)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Bats</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Echolocation behavior of bats</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Bat algorithm (BA)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Fireflies</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Flashing behavior of fireflies</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Firefly algorithm (FA)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Butterflies</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Foraging behavior of butterflies</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Butterfly optimization algorithm (BOA)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Dragonflies</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Static and dynamic swarming behaviors of dragonflies</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Dragonfly algorithm (DA)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Spiders</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Cooperative behavior of the social spiders</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Social spider optimization (SSO)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Krill</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Herding behavior of krill</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Krill herd (KH)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Frogs</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Frog cooperative search for food</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Shuffled frog leaping algorithm (SFLA)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Fish</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Gregarious behavior of fish</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Fish school search (FSS)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Dolphins</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Dolphins’ behavior in detecting, chasing after, and preying on swarms of sardines</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Dolphin partner optimization (DPO)</p>

          <p class="fm-table-body">Dolphin swarm optimization algorithm (DSOA)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Cats</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Resting and tracing behaviors of cats</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Cat swarm optimization (CSO)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Monkeys</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Search for food</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Monkey search algorithm (MSA)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Lions</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Solitary and cooperative behaviors of lions</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Lion optimization algorithm (LOA)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Cuckoos</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Reproduction strategy of cuckoos</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Cuckoo search (CS)</p>

          <p class="fm-table-body">Cuckoo optimization algorithm (COA)</p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Wolves</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Leadership hierarchy and hunting mechanism of gray wolves</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Wolf search algorithm (WSA)</p>

          <p class="fm-table-body">Grey wolf optimizer (GWO)</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">For example, bacteria, which are single-celled organisms, possess underlying social intelligence allowing them to cooperate to solve challenges. Bacteria develop intricate communication capabilities like chemotactic signaling to cooperatively self-organize into highly structured colonies with elevated environmental adaptability. Bacterial chemotaxis is the process by which bacterial cells migrate through concentration gradients of chemical attractants and repellents. The E. coli bacterium uses this bacterial chemotaxis during the foraging process. This collective behavior provides the basis for optimization algorithms such as the bacterial foraging optimization algorithm (BFO) and bacterial swarming algorithm (BSA). <a id="idIndexMarker008"/><a id="idIndexMarker009"/><a id="idIndexMarker010"/><a id="idIndexMarker011"/></p>

  <p class="body"><a id="marker-324"/>Ethology, the study of animal behavior, is the main source of inspiration for swarm intelligence algorithms such as particle swarm optimization (PSO), ant colony optimization (ACO), artificial bee colony (ABC), bat algorithm (BA), firefly algorithm (FA), and social spider optimization (SSO). For example, honeybees are highly cooperative social insects that cooperatively construct hives in which about 30,000 bees can live and work together. They differentiate their work: some make wax, some make honey, some make bee-bread, some shape and mold combs, and some bring water to the cells and mingle it with the honey. Young bees engage in out-of-door work while the elder bees do the indoor work. During the foraging process, rather than expending energy searching in all directions, honeybee colonies use individual foragers to reduce the cost/ benefit ratio. Additionally, colonies concentrate their foraging efforts on the most lucrative patches and disregard those of lesser quality. It has been observed that when a colony’s food resources are scarce, foragers recruit more nestmates to food sources they have found, and changes in their dance patterns upon returning to the hive facilitate this increased recruitment. <a id="idIndexMarker012"/><a id="idIndexMarker013"/><a id="idIndexMarker014"/><a id="idIndexMarker015"/><a id="idIndexMarker016"/><a id="idIndexMarker017"/><a id="idIndexMarker018"/><a id="idIndexMarker019"/><a id="idIndexMarker020"/><a id="idIndexMarker021"/><a id="idIndexMarker022"/><a id="idIndexMarker023"/></p>

  <p class="body">The fundamental components of swarm intelligence algorithms typically involve numerous decentralized processing agents that operate without central supervision. These agents communicate with neighboring agents and adapt their behavior based on received information. Furthermore, the majority of the research carried out on swarm intelligence algorithms is primarily based on experimental observations of collective behavior exhibited by living organisms. These observations are translated into models, which are then tested through simulations in order to derive the metaheuristics that form the basis of swarm intelligence algorithms, as illustrated in figure 9.1. This experimental approach enables researchers to gain a deeper understanding of the complex interactions between individual agents and how they give rise to collective behavior. By simulating these interactions and testing various scenarios, researchers can refine the algorithms and improve their effectiveness. As an example of such experimental research, you can watch the “The Waggle Dance of the Honeybee” video of the experiment conducted by Georgia Tech College of Computing to understand how honeybees communicate the location of new food sources (www.youtube.com/watch?v=bFDGPgXtK-U).</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F01_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.1 Derivation process for swarm intelligence algorithms</p>
  </div>

  <p class="body">Algorithm 9.1 shows the common steps in a swarm intelligence algorithm. The algorithm starts by initializing the algorithm parameters, such as the number of individuals in the swarm, the maximum number of iterations, and the termination criteria. A swarm of initial candidate solutions is then sampled (the different sampling methods were explained in section 7.1). The algorithm then iterates over all the individuals in the swarm, performing the following operations: finding the best so far, finding the best neighbor, and updating the individual. <a id="idIndexMarker024"/><a id="idIndexMarker025"/><a id="marker-325"/></p>

  <p class="fm-code-listing-caption">Algorithm 9.1 Swarm intelligence algorithm</p>
  <pre class="programlisting">Initialize parameters
Initialize swarm
While (stopping criteria not met) loop over all individuals
    Find best so far
    Find best neighbor
    Update individual</pre>

  <p class="body">The individual and the neighbor are evaluated using the defined objective/fitness function. The neighborhood structure and update mechanism depend on the algorithm being used. This loop over all the individuals is repeated until the termination criterion is met, which could be a maximum number of iterations or reaching a satisfactory fitness level. At this point, the algorithm stops and returns the best solution found during the optimization process. In the following sections, we’ll dive deep into the PSO algorithm.</p>

  <h2 class="fm-head" id="heading_id_4">9.2 Continuous PSO</h2>

  <p class="body">Particle swarm optimization (PSO) is a population-based stochastic optimization technique developed by Russell Eberhart and James Kennedy in 1995. Since then, PSO has gained popularity and has been applied to various real-world applications in different domains. This algorithm is inspired by the conduct of social organisms such as birds, fish, ants, termites, wasps, and bees. PSO emulates the actions of these creatures, with each member of the swarm being referred to as a <i class="fm-italics">particle</i>, akin to a bird in a flock, a fish in a school, or a bee in a colony. Eberhart and Kennedy opted to use the term “particle” to refer to an individual or candidate solution in the context of optimization, as they believed it was more suitable for describing the particle’s velocity and acceleration.<a id="idIndexMarker026"/><a id="idIndexMarker027"/><a id="marker-326"/></p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">Bird flocking</p>

    <p class="fm-sidebar-text">Bird flocking is a behavior controlled by three simple rules, as illustrated in the following figure:<a id="idIndexMarker028"/></p>

    <ul class="calibre5">
      <li class="fm-list-bullet2">
        <p class="list-s"><i class="fm-italics">Separation</i>—Prevent getting too close to nearby birds to avoid overcrowding.</p>
      </li>

      <li class="fm-list-bullet2">
        <p class="list-s"><i class="fm-italics">Alignment</i>—Adjust the heading to correspond to the average direction of neighboring birds.</p>
      </li>

      <li class="fm-list-bullet2">
        <p class="list-s"><i class="fm-italics">Coherence</i>—Move toward the average position of neighboring birds.</p>
      </li>
    </ul>

    <p class="sidebarafigures"><img alt="" class="calibre2" src="../Images/CH09_F01_UN01_Khamis.png"/></p>

    <p class="sidebaracaptions">Bird flocking rules: separation, alignment, and coherence</p>

    <p class="fm-sidebar-text">When birds—spatially distributed agents interacting with each other and with their environment in a decentralized and self-organized manner without access to global information—apply these three simple rules, the outcome is the emergent behavior of bird flocking.</p>
  </div>

  <p class="body">The particles (candidate solutions) move, or fly, through the feasible search space by following the current best particles. Thus, PSO is guided by a straightforward principle: emulate the success of neighboring individuals. Each particle in the swarm operates in a decentralized manner by utilizing both its own intelligence and the collective intelligence of the group. Therefore, if one particle uncovers a favorable route to food, the remaining members of the swarm can immediately adopt the same path.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">The PSO algorithm</p>

    <p class="fm-sidebar-text">“This [PSO] algorithm belongs ideologically to that philosophical school that allows wisdom to emerge rather than trying to impose it, that emulates nature rather than trying to control it, and that seeks to make things simpler rather than more complex.” J. Kennedy and R. Eberhart, inventors of PSO [1].<a id="idIndexMarker029"/><a id="idIndexMarker030"/></p>
  </div>

  <p class="body"><a id="marker-327"/>Figure 9.2 shows the PSO flowchart. We start by initializing the algorithm parameters and creating an initial swarm of particles. These particles represent the candidate solutions. Each particle in the search space holds the current position <i class="timesitalic">x<sup class="fm-superscript">i</sup></i> and current velocity <i class="timesitalic">v<sup class="fm-superscript">i</sup></i>. The fitness of each particle is then evaluated based on the fitness/objective function to be optimized. The best position each particle has achieved so far is known as the personal best or <i class="fm-italics">pbest</i>. The best position achieved by the particles in its neighborhood is known as <i class="fm-italics">nbest</i>. If the neighborhood is restricted to a few particles, the best is called the local best, <i class="fm-italics">lbest</i>. If the neighborhood is the whole swarm, the best achieved by the whole swarm is called the global best, <i class="fm-italics">gbest</i>. We’ll discuss neighborhood structures in PSO further in section 9.2.3.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F02_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.2 The PSO algorithm</p>
  </div>

  <p class="body">After evaluating the fitness of each particle, PSO updates each particle’s personal best position if the current fitness is superior, identifies the global best position based on the best fitness in the entire swarm, and adjusts particle velocities and positions using a combination of personal and global information. These steps guide the swarm toward optimal or near-optimal solutions by balancing individual and collective learning, promoting exploration and exploitation in the search space. The process iterates until termination criteria are met.</p>

  <h3 class="fm-head1" id="heading_id_5">9.2.1 Motion equations</h3>

  <p class="body"><a id="marker-328"/>The velocity (<i class="timesitalic">v</i>) and position (<i class="timesitalic">x</i>) of each particle are updated using the following equations:<a id="idIndexMarker031"/><a id="idIndexMarker032"/></p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F02_Khamis-EQ01.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.1</p>
        </td>
      </tr>
    </tbody>
  </table>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F02_Khamis-EQ02.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.2</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">where</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="timesitalic">k</i> is the iteration number.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="timesitalic">i</i> and <i class="timesitalic">d</i> are the particle number and the dimension. For example, dimension = 1 in the case of a univariate optimization problem with a single decision variable, dimension = 2 in the case of a bivariate problem, etc.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="timesitalic">ω</i> is the inertia weight.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><span class="times"><i class="fm-italics">c</i>1, <span class="times"><i class="fm-italics">c</i>2</span></span> are the acceleration coefficients.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><span class="times"><i class="fm-italics">r</i>1, <i class="fm-italics">r</i>2</span> are random numbers between 0 and 1 and are generated in each iteration for each dimension, and not for each particle.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="timesitalic">pbest</i> is the best position achieved by the particle.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="timesitalic">gbest</i> is the best position achieved by the whole swarm. <i class="timesitalic">gbest</i> should be replaced by <i class="timesitalic">nbest or lbest</i> if you are dividing the swarm into multiple neighborhoods.</p>
    </li>
  </ul>

  <p class="body">As you can see in these two equations, we start by updating the velocity <span class="times"><i class="fm-italics">v</i><sub class="fm-subscript">(</sub><i class="fm-italics"><sub class="fm-subscript">k</sub></i> <sub class="fm-subscript">+ 1)</sub><i class="fm-italics"><sup class="fm-superscript">id</sup></i></span>. The position is then updated to <span class="times"><i class="fm-italics">x</i><sub class="fm-subscript">(</sub><i class="fm-italics"><sub class="fm-subscript">k</sub></i> <sub class="fm-subscript">+ 1)</sub><i class="fm-italics"><sup class="fm-superscript">id</sup></i></span> by taking the current position <i class="timesitalic">x<sub class="fm-subscript">k</sub><sup class="fm-superscript">id</sup></i> and adding to it the new displacement <span class="times"><i class="fm-italics">v</i><sub class="fm-subscript">(</sub><i class="fm-italics"><sub class="fm-subscript">k</sub></i> <sub class="fm-subscript">+ 1)</sub><i class="fm-italics"><sup class="fm-superscript">id</sup></i> × <i class="fm-italics">timestamp</i></span> where <span class="times"><i class="fm-italics">timestamp</i> = 1</span>, which represents a single iteration.</p>

  <p class="body">To understand these motion update equations, let’s visualize these equations using vectors in the 2D Cartesian coordinate system, as shown in figure 9.3. As you can see, the velocity update equation consists of three primary components, each contributing to the movement of particles in the search space:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Inertia component</i>—The first part of the velocity update equation represents the influence of a particle’s inertia, taking into account that a particle (like a fish in a school or a bird in a flock) cannot abruptly change its direction. As you will see later, this inertia component is crucial, as it allows the algorithm to be more adaptive and helps maintain a balance between exploration and exploitation. <a id="idIndexMarker033"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Cognitive component</i>—The second part of the equation, referred to as the cognitive component, represents the particle’s attraction toward its personal best position, or individual proximity (<i class="fm-italics">i</i>-proximity). This component reflects the degree of trust a particle places in its own past experiences, without considering the experiences of its neighbors or the swarm as a whole. The cognitive component encourages particles to explore the areas around their personal best positions, allowing them to fine-tune their search in promising regions.<a id="idIndexMarker034"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Social component</i>—The third part of the velocity update equation is the social component, which represents the particle’s attraction to the swarm’s collective knowledge or group proximity (<i class="fm-italics">g</i>-proximity). This component takes into account the experiences of neighboring particles and the swarm as a whole, guiding the particles toward the global best position found so far. The social component fosters collaboration among particles, helping them converge toward an optimal solution more effectively.<a id="idIndexMarker035"/><a id="marker-329"/></p>
    </li>
  </ul>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F03_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.3 Visualizing the motion equation for a particle in the swarm</p>
  </div>

  <p class="body">To better understand the meaning of each component, imagine a group of friends visiting a large amusement park for the first time. Their goal is to visit the most thrilling rides in the park as efficiently as possible. The friends can be thought of as particles in the PSO algorithm, with each person’s enjoyment of the rides serving as the objective function to optimize. Each person has a preferred way of exploring the available rides, like walking through certain parts of the park or trying specific rides like roller coasters or water slides. This is similar to the inertia component in PSO, where particles maintain their current velocity and direction, ensuring they don’t change their exploration pattern too abruptly.</p>

  <p class="body">Each friend relies on their own personal experiences to find the most thrilling rides. For instance, one friend might have had a great time on a roller coaster earlier in the day. They’re more likely to return to their favorite one or want to find more similar rides, knowing it was a good choice. They trust their judgment and focus on exploring the areas around the roller coaster, seeking out rides that they think they’ll enjoy based on their personal experience. This is the cognitive component, where particles in PSO are attracted to their personal best positions, following their past experiences and individual preferences.</p>

  <p class="body">The friends then collaborate to find the most thrilling ride based on their shared experiences. Imagine one of the friends has just ridden the most exciting roller coaster and can’t wait to tell the others about it. As they share their excitement, the group collectively becomes more attracted to that ride, influencing their individual choices. This is the social component, where particles in PSO are influenced by the global best position or the collective knowledge of the swarm.</p>

  <p class="body">The following subsections dive into more detail about the different PSO parameters.</p>

  <h3 class="fm-head1" id="heading_id_6">9.2.2 Fitness update</h3>

  <p class="body"><a id="marker-330"/>After moving, each particle updates its own personal best using the following equation, assuming a minimization problem:<a id="idIndexMarker036"/><a id="idIndexMarker037"/></p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F03_Khamis-EQ03.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.3</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">After that, each neighborhood updates its best as follows:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F03_Khamis-EQ04.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.4</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">The neighborhood best (<i class="timesitalic">nbest</i>) is the same as the global best (<i class="timesitalic">gbest</i>) if the neighborhood is the whole swarm.</p>

  <p class="body">PSO has two main variants based on how particles’ positions and velocities are updated—synchronous and asynchronous PSO:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Synchronous PSO (S-PSO)</i>—All particles in the swarm update their positions and velocities simultaneously in a global manner. The local and global best are then updated. This synchronous approach ensures that all particles have access to the same global best position when updating their velocities and positions, promoting global exploration.<a id="idIndexMarker038"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Asynchronous PSO (A-PSO)</i>—Particles are updated based on the current state of the swarm. This asynchronous approach allows the particles to update their positions and velocities based on the most recent information available.<a id="idIndexMarker039"/><a id="marker-331"/></p>
    </li>
  </ul>

  <p class="body">Figure 9.4 shows the difference between S-PSO and A-PSO. As you’ll notice, in A-PSO, the neighborhood best update is moved into the particle’s update loop. This allows particles to evaluate their fitness and update their positions and velocities independently and asynchronously.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F04_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.4 Synchronous and asynchronous PSO</p>
  </div>

  <p class="body">Although both synchronous and asynchronous PSO strategies can be employed to handle optimization problems, the asynchronous version is generally more effective, as it allows particles to take advantage of the most recent neighbor information.</p>

  <h3 class="fm-head1" id="heading_id_7">9.2.3 Initialization</h3>

  <p class="body">PSO initialization includes initializing the particle position, velocity, and personal best, and initializing the algorithm’s parameters:<a id="idIndexMarker040"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Particle position initialization</i>—Particle positions represent candidate solutions to the problem, and they can be sampled using different sampling methods, as explained in section 7.1. For example, the initial positions of the particles can be randomly assigned within the defined feasible search space.<a id="idIndexMarker041"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Particle velocity initialization</i>—The velocities of the particles can be set to zero or small values initially. Initializing them with small velocities ensures that the particles’ updates are gradual, preventing them from moving too far away from their starting positions. In contrast, large initial velocities may lead to significant updates, which can potentially cause divergence and hinder the convergence of the algorithm.<a id="idIndexMarker042"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Personal best position initialization</i>—The personal best position of each particle, which represents the best solution found by the particle so far, should be initialized to its initial position. This allows the particles to begin their search with their starting points as a reference and to update their personal bests as they discover better solutions.<a id="idIndexMarker043"/><a id="marker-332"/></p>
    </li>
  </ul>

  <p class="body">As shown in equation 9.1, PSO has three primary parameters that play a critical role in controlling the search algorithm’s behavior: the inertia weight (<i class="fm-italics">ω</i>) and the acceleration coefficients (<i class="fm-italics">c</i>1, <span class="times"><i class="fm-italics">c</i>2</span>). These parameters influence the balance between exploration and exploitation within the optimization process:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Inertia weight</i>—Large values of <i class="fm-italics">ω</i> encourage exploration, while small values promote exploitation, allowing the cognitive and social components to exert greater control. A widely adopted value for <i class="fm-italics">ω</i> is 0.792.<a id="idIndexMarker044"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Acceleration coefficients</i>—Setting <span class="times"><i class="fm-italics">c</i>1</span> to 0 reduces the PSO algorithm to a <i class="fm-italics">social-only</i> or <i class="fm-italics">selfless PSO</i> model. In this case, particles are solely attracted to the group best and ignore their personal bests. This leads to an emphasis on global exploration based on the swarm’s collective knowledge. Setting <span class="times"><i class="fm-italics">c</i>2</span> to 0 results in a <i class="fm-italics">cognition-only model</i>, where particles act as independent hill climbers, relying only on their personal bests. In this scenario, the particles do not consider the experiences of other swarm members, focusing on local exploitation based on their individual experiences. In many applications, <span class="times"><i class="fm-italics">c</i>1</span> and <span class="times"><i class="fm-italics">c</i>2</span> are set to 1.49. Although there is no theoretical justification for this specific value, it has been empirically found to work well in various optimization problems. Generally, the sum of <span class="times"><i class="fm-italics">c</i>1</span> and <span class="times"><i class="fm-italics">c</i>2</span> should be less than or equal to 4 to maintain the algorithm’s stability and convergence properties.<a id="idIndexMarker045"/></p>
    </li>
  </ul>

  <p class="body">Other parameters to consider include swarm size and neighborhood size. There is no one-size-fits-all solution, as the optimal values depend on the specific problem being solved. However, some best practices and guidelines can help inform your choices:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Swarm size</i>—A large swarm size can promote global exploration and prevent premature convergence, but at the cost of increased computational effort. A small swarm size can lead to faster convergence and reduced computational effort but may increase the risk of premature convergence. For many problems, a swarm size between 20 and 100 particles has been found to yield good results. It is advisable to conduct experiments with different swarm sizes to determine the best trade-off between exploration, exploitation, and computational complexity for the problem at hand.<a id="idIndexMarker046"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Neighborhood size</i>—A large neighborhood size can encourage global exploration and information sharing among particles but may reduce the ability to exploit local optima. A small neighborhood size can promote local exploitation and convergence speed but may limit global exploration. You can use different neighborhood structures, as you’ll see in the next subsection. <a id="idIndexMarker047"/><a id="marker-333"/></p>
    </li>
  </ul>

  <p class="body">Generally speaking, selecting the best algorithm parameters requires experimentation and fine-tuning based on the specific problem you are trying to solve. It is often beneficial to perform a sensitivity analysis or use a parameter-tuning technique to find the optimal parameter values for your problem. We’ll look at this in more detail in section 9.5.</p>

  <h3 class="fm-head1" id="heading_id_8">9.2.4 Neighborhoods</h3>

  <p class="body">In the PSO algorithm, particles within a specific vicinity engage in mutual communication by sharing details about each other’s success within that local region. Subsequently, all particles gravitate toward a position that is considered to be an improvement based on a key performance indicator. The efficacy of the PSO algorithm is heavily reliant on the social network structure it employs. Choosing an appropriate neighborhood topology plays a crucial role in ensuring the algorithm’s convergence and in preventing it from becoming trapped in local minima. <a id="idIndexMarker048"/><a id="idIndexMarker049"/><a id="idIndexMarker050"/></p>

  <p class="body">Some of the prevalent neighborhood topologies utilized in PSO include the star social structure, the ring topology, the Von Neumann model, and the wheel topology:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">The star social structure, also known as the global best (gbest) PSO</i>—This is a neighborhood topology where all particles are connected, as shown in figure 9.5a. This structure allows access to global information within the swarm, with the result that each particle is drawn toward the optimal solution discovered by the entire swarm. The <i class="fm-italics">gbest</i> PSO has been demonstrated to converge more rapidly than other network structures. However, it is more prone to becoming ensnared in local minima without fully exploring the search space. This topology excels when applied to unimodal problems, as it allows for efficient and effective optimization in such cases.<a id="idIndexMarker051"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Ring topology, also known as the local best (lbest) PSO</i>—Following this topology, a particle interacts exclusively with its immediately adjacent neighbors (figure 9.5b). Each particle endeavors to emulate its most successful neighbor by gravitating toward the optimal solution discovered within the local vicinity. Although convergence occurs at a slower pace than with the star structure, the ring topology explores a more extensive portion of the search space. This topology is recommended for multimodal problems.<a id="idIndexMarker052"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Von Neumann model</i>—In this topology, particles are arranged in a grid-like structure or square topology where each particle is connected with four other particles (the neighbors above, below, and to the right and left), as shown in figure 9.5c.<a id="idIndexMarker053"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Wheel topology</i>—In this topology, the particles are isolated from each other, and one particle is randomly selected as the focal point or hub for all information flow, as illustrated in figure 9.5d.<a id="idIndexMarker054"/><a id="marker-334"/></p>
    </li>
  </ul>

  <p class="body">The choice of neighborhood topology depends on the problem’s characteristics and the desired balance between exploration and exploitation. Experiment with different topologies to find the best fit for your problem.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F05_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.5 PSO neighborhood topologies: a) the star social structure, b) the ring topology, c) the Von Neumann model, and d) the wheel topology</p>
  </div>

  <p class="body">Let’s now look at how to solve a continuous optimization problem using PSO. The Michalewicz function is a nonconvex mathematical function commonly used as a test problem for optimization algorithms. This function is given by the following formula:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F05_Khamis-EQ05.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.5</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">where <i class="timesitalic">d</i> is the dimension of the problem and <i class="timesitalic">m</i> is a constant (usually <span class="times"><i class="fm-italics">m</i> = 10</span>). This function has <i class="timesitalic">d</i> local minima. For <span class="times"><i class="fm-italics">d</i> = 2</span>, the minimum value is <span class="times">–1.8013</span> at <span class="times">(2.20, 1.57)</span>.</p>

  <p class="body">Let’s start by defining the Michalewicz function as shown in listing 9.1. This function can accept size-1 arrays with single or multiple rows. If the input position is a size-1 array with a single row, we reshape it to a 2D array with a single row using the <code class="fm-code-in-text">reshape()</code> function. A <i class="fm-italics">size-1 array</i>, also known as a <i class="fm-italics">singleton array</i>, is an array data structure that contains only one element. This reshaping enables uniform handling of both single-row size-1 arrays and arrays with multiple rows. This is evident in the implementation of the PSO solver, where the function addresses solving one solution at a time. Additionally, the function seamlessly manages arrays with multiple rows, a scenario encountered when simultaneously evaluating multiple solutions. This aspect will be further elaborated upon later in the context of pymoo and PySwarms solvers.<a id="idIndexMarker055"/><a id="idIndexMarker056"/><a id="idIndexMarker057"/><a id="marker-335"/></p>

  <p class="fm-code-listing-caption">Listing 9.1 Solving the Michalewicz function using PSO</p>
  <pre class="programlisting">import numpy as np
import math
import matplotlib.pyplot as plt
  
def michalewicz_function(position):
    m = 10
    position = np.array(position)
    if len(position.shape) == 1:            <span class="fm-combinumeral">①</span>
        position = position.reshape(1, -1)  <span class="fm-combinumeral">①</span>
    n = position.shape[1]
    j = np.arange(1, n + 1)
    s = np.sin(position) * np.power(np.sin((j * np.square(position)) /
<span class="fm-code-continuation-arrow">➥</span> np.pi), 2 * m)                           <span class="fm-combinumeral">②</span>
    return -np.sum(s, axis=1)               <span class="fm-combinumeral">②</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Reshape to a 2D array with a single row if the position is a size-1 array.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> The Michalewicz formula</p>

  <p class="body">Let’s now create a PSO solver from scratch. As a continuation of listing 9.1, we’ll start by defining a particle class with position, velocity, and personal best value as follows:</p>
  <pre class="programlisting">class Particle:
    def __init__(self, position, velocity, pbest_position, pbest_value):
        self.position = position
        self.velocity = velocity
        self.pbest_position = pbest_position
        self.pbest_value = pbest_value</pre>

  <p class="body">The fitness function to be minimized is the Michalewicz function in this example:</p>
  <pre class="programlisting">def fitness_function(position):
    return michalewicz_function(position)</pre>

  <p class="body">We can now define the velocity update function following equation 9.1. The function takes three arguments—<code class="fm-code-in-text">particle</code>, which is an object representing the current particle; <code class="fm-code-in-text">gbest_position</code>, which is the global best position found by the swarm so far; and <code class="fm-code-in-text">options</code>, which is a dictionary containing the algorithm parameters (specifically, the inertia weight <code class="fm-code-in-text">w</code> and the cognitive and social acceleration coefficients <code class="fm-code-in-text">c1</code> and <code class="fm-code-in-text">c2</code>):</p>
  <pre class="programlisting">def update_velocity(particle, gbest_position, options):    
    w = options['w']
    c1 = options['c1']
    c2 = options['c2']
    inertia = w * particle.velocity
    cognitive = c1 * np.random.rand() * (particle.pbest_position –
<span class="fm-code-continuation-arrow">➥</span> particle.position)
    social = c2 * np.random.rand() * (gbest_position - particle.position)
    new_velocity = inertia + cognitive + social
    return new_velocity</pre>

  <p class="body"><a id="marker-336"/>The function computes the three components of the new velocity: the inertia component, the cognitive component, and the social component, as per equation 9.1. It returns the updated velocity as the sum of the three components.</p>

  <p class="body">We can now define the PSO solver function. This function takes four parameters as inputs—<code class="fm-code-in-text">swarm_size</code>, which is the size of the particle swarm; <code class="fm-code-in-text">iterations</code>, which is the maximum number of iterations to run the algorithm for; <code class="fm-code-in-text">bounds</code>, which is a list of tuples defining the lower and upper bounds of the search space for each dimension of the input vector; and <code class="fm-code-in-text">options</code>, which is a dictionary containing the algorithm parameters (such as the inertia weight and cognitive and social acceleration coefficients):</p>
  <pre class="programlisting">def pso(swarm_size, iterations, bounds, options):                            <span class="fm-combinumeral">①</span>
    swarm = []                                                               <span class="fm-combinumeral">①</span>
    for _ in range(swarm_size):                                              <span class="fm-combinumeral">①</span>
        position = np.array([np.random.uniform(low=low, high=high) for low,  <span class="fm-combinumeral">①</span>
<span class="fm-code-continuation-arrow">➥</span> high in bounds])                                                          <span class="fm-combinumeral">①</span>
        velocity = np.array([np.random.uniform(low=-abs(high-low),           <span class="fm-combinumeral">①</span>
<span class="fm-code-continuation-arrow">➥</span>  high=abs(high-low)) for low, high in bounds])                            <span class="fm-combinumeral">①</span>
        pbest_position = position                                            <span class="fm-combinumeral">①</span>
        pbest_value = fitness_function(position)                             <span class="fm-combinumeral">①</span>
        particle = Particle(position, velocity, pbest_position, pbest_value) <span class="fm-combinumeral">①</span>
        swarm.append(particle)                                               <span class="fm-combinumeral">①</span>
  
    gbest_position = swarm[np.argmin([particle.pbest_value for particle in   <span class="fm-combinumeral">②</span>
<span class="fm-code-continuation-arrow">➥</span> swarm])].pbest_position                                                   <span class="fm-combinumeral">②</span>
    gbest_value = np.min([particle.pbest_value for particle in swarm])       <span class="fm-combinumeral">②</span>
  
    for _ in range(iterations):
        for _, particle in enumerate(swarm):
            particle.velocity = update_velocity(particle, gbest_position,    <span class="fm-combinumeral">③</span>
options)                                                                     <span class="fm-combinumeral">③</span>
            particle.position += particle.velocity                           <span class="fm-combinumeral">③</span>
  
            particle.position = np.clip(particle.position, [low for low, high 
  <span class="fm-code-continuation-arrow">➥</span> in bounds], [high for low, high in bounds])                             <span class="fm-combinumeral">④</span>
  
            current_value = fitness_function(particle.position)              <span class="fm-combinumeral">⑤</span>
            if current_value &lt; particle.pbest_value:                         <span class="fm-combinumeral">⑤</span>
                particle.pbest_position = particle.position                  <span class="fm-combinumeral">⑤</span>
                particle.pbest_value = current_value                         <span class="fm-combinumeral">⑤</span>
  
            if current_value &lt; gbest_value:                                  <span class="fm-combinumeral">⑥</span>
                gbest_position = particle.position                           <span class="fm-combinumeral">⑥</span>
                gbest_value = current_value                                  <span class="fm-combinumeral">⑥</span>
            
            particle.position += particle.velocity                           <span class="fm-combinumeral">⑦</span>
  
    return gbest_position, gbest_value                                       <span class="fm-combinumeral">⑧</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Initialize a random swarm.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Initialize the global best.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Update the velocity and position.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Apply the bounds.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Update the personal best (pbest).</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Update the global best (gbest).</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> Update the position.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑧</span> Return the global best position and corresponding value.</p>

  <p class="body"><a id="marker-337"/>The function first initializes the particle swarm by randomly generating the initial positions and velocities for each particle within the bounds defined by <code class="fm-code-in-text">bounds</code>. It then evaluates the fitness function for each particle and updates its personal best position and value accordingly. The function then enters a loop, where it updates the velocity and position of each particle using the <code class="fm-code-in-text">update_velocity</code> function, which takes the global best position found so far as input. The function also applies bounds to the particle position and updates its personal best position and value. The function then updates the global best position and value based on the star topology. Other topologies, such as ring, Von Neumann, and wheel, can be found in the complete code of listing 9.1, available in the book’s GitHub repository. Finally, the function returns the global best position and value found by the algorithm.<a id="idIndexMarker058"/></p>

  <p class="body">We can now use this PSO solver to minimize the Michalewicz function after we set up the problem and algorithm parameters as follows:</p>
  <pre class="programlisting">swarm_size = 50                                                            <span class="fm-combinumeral">①</span>
iterations = 1000                                                          <span class="fm-combinumeral">①</span>
options = {'w': 0.9, 'c1': 0.5, 'c2': 0.3}                                 <span class="fm-combinumeral">①</span>
  
dimension = 2                                                              <span class="fm-combinumeral">②</span>
bounds = [(0, math.pi)] * dimension                                        <span class="fm-combinumeral">②</span>
  
best_position, best_value = pso(swarm_size, iterations, bounds, options)   <span class="fm-combinumeral">③</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> PSO parameters</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Dimension and domain of the Michalewicz function for each variable</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Use the implemented PSO solver to solve the problem.</p>

  <p class="body">You can print the optimal solution and minimum value of the function after running PSO:</p>
  <pre class="programlisting">print(f"Optimal solution: {np.round(best_position,3)}")
print(f"Minimum value: {np.round(best_value,4)}")
print()</pre>

  <p class="body">The output would be as follows:</p>
  <pre class="programlisting">Optimal solution: [2.183 1.57]
Minimum value: [-1.8013]</pre>

  <p class="body">Compared to genetic algorithms, there are fewer Python libraries available for PSO. Pymoo provides a PSO implementation for continuous problems. As a continuation of listing 9.1, pymoo PSO can be used to solve the same problem as follows:<a id="marker-338"/></p>
  <pre class="programlisting">from pymoo.algorithms.soo.nonconvex.pso import PSO
from pymoo.core.problem import Problem
from pymoo.optimize import minimize
 
class MichalewiczFunction(Problem):                       <span class="fm-combinumeral">①</span>
    def __init__(self):
        super().__init__(n_var=2,                         <span class="fm-combinumeral">②</span>
                         n_obj=1,
                         n_constr=0,
                         xl=0,                            <span class="fm-combinumeral">③</span>
                         xu=math.pi,                      <span class="fm-combinumeral">③</span>
                         vtype=float)
 
    def _evaluate(self, x, out, *args, **kwargs):
        out["F"]= michalewicz_function(x)                 <span class="fm-combinumeral">④</span>
  
problem = MichalewiczFunction()                           <span class="fm-combinumeral">⑤</span>
 
algorithm = PSO(w=0.9, c1=2.0, c2=2.0)                    <span class="fm-combinumeral">⑥</span>
  
res = minimize(problem,
               algorithm,
               seed=1,
               verbose=False)                             <span class="fm-combinumeral">⑦</span>
  
print(f"Optimal solution: {np.round(res.X,3)}")           <span class="fm-combinumeral">⑧</span>
print(f"Minimum value: {np.round(res.F,4)}")              <span class="fm-combinumeral">⑧</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Define the problem.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> The 2D Michalewicz function</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Set the lower and upper bounds.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Evaluate the objective function.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Create a problem instance.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Define the solver with the parameters.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> Apply PSO to solve the problem.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑧</span> Print the optimal solution and minimum value of the function after running PSO.</p>

  <p class="body">This code produces the following output:</p>
  <pre class="programlisting">Optimal solution: [2.203 1.571]
Minimum value: [-1.8013]</pre>

  <p class="body">PySwarms is another open source optimization library for Python that implements different variants of PSO. PySwarms can be used as follows to handle the problem:</p>
  <pre class="programlisting">!pip install pyswarms
import pyswarms as ps                                                      <span class="fm-combinumeral">①</span>
  
dimension = 2                                                              <span class="fm-combinumeral">②</span>
bounds = (np.zeros(dimension), np.pi * np.ones(dimension))                 <span class="fm-combinumeral">③</span>
  
options = {'w': 0.9, 'c1': 0.5, 'c2': 0.3}                                 <span class="fm-combinumeral">④</span>
  
optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=dimension,
<span class="fm-code-continuation-arrow">➥</span> options=options, bounds=bounds)                                         <span class="fm-combinumeral">⑤</span>
  
cost, pos = optimizer.optimize(michalewicz_function, iters=1000)           <span class="fm-combinumeral">⑥</span>
  
print(f"Optimal solution: {np.round(pos,3)}")                              <span class="fm-combinumeral">⑦</span>
print(f"Minimum value: {np.round(cost,4)}")                                <span class="fm-combinumeral">⑦</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Import the PSO solver from pyswarms.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Dimension of the Michalewicz function</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Create bounds for the search space.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Set up the optimizer.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Create an instance of the optimizer.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Optimize the Michalewicz function</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> Print the optimal solution and minimum value of the function after running PSO.</p>

  <p class="body">This code produces the following output:</p>
  <pre class="programlisting">Optimal solution: [2.203 1.571]
Minimum value: -1.8013</pre>

  <p class="body">The pyswarms.single package implements various techniques in continuous single- objective optimization. From this module, we used the global-best PSO (<i class="fm-italics">gbest</i> PSO) algorithm in the previous code. You can experiment by replacing this solver with local-best.</p>

  <p class="body"><a id="marker-339"/>Figure 9.6 shows the 3D landscape and 2D contours of the Michalewicz function, the optimal solution, and the solutions obtained by PSO, PSO Pymoo, and PSO PySwarms.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F06_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.6 3D and 2D plots of the Michalewicz function. The three solutions are all very close to the optimal solution.</p>
  </div>

  <p class="body">The three versions of PSO provide comparable results. However, PSO PySwarms and PSO pymoo are more stable, as they provide more consistent results each time you run the code. The PySwarms library is more comprehensive than pymoo for PSO, as it provides implementations of different variants and topologies of PSO, including discrete PSO, which will be explained in the next two sections.</p>

  <h2 class="fm-head" id="heading_id_9">9.3 Binary PSO</h2>

  <p class="body">PSO was originally developed for problems that involve continuous-valued variables. However, many real-world problems are discrete or combinatorial in nature, such as TSP, task allocation, scheduling, assignment problems, and feature selection, among others. These types of problems involve searching through a finite set of possible solutions, rather than searching through a continuous space. To handle these discrete problems, PSO variants have been developed, such as binary PSO and permutation-based PSO.<a id="idIndexMarker059"/><a id="idIndexMarker060"/><a id="idIndexMarker061"/></p>

  <p class="body">In <i class="fm-italics">binary PSO</i> (BPSO), each particle represents a position in the binary space, where each element is either 0 or 1. The binary sequence is updated bit by bit based on its current value, the fitness-based value of that particular bit within the particle, and the best value of the same bit observed so far among its neighboring particles. This approach enables the search to be conducted in a binary space rather than a continuous space, which is well suited for problems where the variables are binary. <a id="idIndexMarker062"/><a id="marker-340"/></p>

  <p class="body">In BPSO, the velocity is defined in terms of the probability of the bit changing. To restrict the values of the velocity elements to the range of [0,1], the sigmoid function is used:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F06_Khamis-EQ06.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.6</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">The position update equation then becomes</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F06_Khamis-EQ07.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.7</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">where <i class="timesitalic">r</i> is a randomly generated number in [0, 1]. Figure 9.7 shows the sigmoid function and the probability of the updated position to be 1. For example, if <i class="timesitalic">v</i> = 0.3, this means that the probability that the updated position will be 1 is 30%, and the probability that it will be 0 is 70%.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F07_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.7 Position and velocity notations in binary PSO (BPSO). Each particle represents a position in the binary space. Velocity is defined in terms of the probability of the bit changing.</p>
  </div>

  <p class="body">As you’ll notice, the velocity components will remain as real-valued numbers using the original equation, but these values are then passed through the sigmoid function before updating the position vector. The following equations are the velocity update equations in BPSO:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F07_Khamis-EQ08.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.8</p>
        </td>
      </tr>
    </tbody>
  </table>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F07_Khamis-EQ09.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.9</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">The positions are updated according to the following equation:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F07_Khamis-EQ10.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.10</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">where<a id="marker-341"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><span class="times"><i class="fm-italics">ϕ</i><sub class="fm-subscript">1</sub></span> and <span class="times"><i class="fm-italics">ϕ</i><sub class="fm-subscript">2</sub></span> represent different random numbers drawn from uniform distributions. Sometimes these parameters are chosen from a uniform distribution 0–2, such that the sum of their two limits is 4.0.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><span class="times"><i class="fm-italics">v<sup class="fm-superscript">i</sup><sup class="fm-superscript">d</sup><sub class="fm-subscript">k</sub></i> <sub class="fm-subscript">+1</sub></span> is the probability that an individual <i class="timesitalic">i</i> will choose 1 for the bit at the <i class="timesitalic">d<sup class="fm-superscript">th</sup></i> site in the bit string.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="timesitalic">x<sub class="fm-subscript">k</sub><sup class="fm-superscript">id</sup></i> is the current state of string <i class="timesitalic">i</i> at bit <i class="fm-italics">d</i>.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="timesitalic">v<sub class="fm-subscript">k</sub><sup class="fm-superscript">id</sup></i> is a measure of the string’s current probability to choose 1.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="timesitalic">pbest<sub class="fm-subscript">k</sub><sup class="fm-superscript">id</sup></i> is the best state found so far for bit <i class="timesitalic">d</i> of individual <i class="timesitalic">i</i> (i.e., a 1 or a 0).</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="timesitalic">gbest<sub class="fm-subscript">k</sub><sup class="fm-superscript">d</sup></i> is 1 or 0 depending on what the value of bit <i class="timesitalic">d</i> is in the best neighbor to date.</p>
    </li>
  </ul>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">BPSO example</p>

    <p class="fm-sidebar-text">To illustrate how BPSO works, suppose we have a population of five binary particles, where each particle consists of 6 bits. Let’s assume the particles are represented by the following binary strings: 101101, 110001, 011110, 100010, and 001011. We want to update particle 4 (represented by the binary string 100010) at bit 3 (which has a current value of 0). The current propensity (velocity) of this bit to be 1 is assumed to be 0.23. Additionally, we assume that the best value of this particle found so far is 101110, while the best value found by the entire population is 101111. Let’s also assume that <span class="times">ϕ<sub class="fm-subscript">1</sub> = 1.5</span> and <span class="times">ϕ<sub class="fm-subscript">2</sub> = 1.9</span>. Using equations 9.8 and 9.9, we can get the updated velocity of bit 3 in particle 4 as follows:</p>

    <p class="fm-sidebar-text">Particle 4: <span class="times">100010, <i class="fm-italics">v<sub class="fm-subscript">k</sub></i><sup class="fm-superscript">43</sup> = 0.23, <i class="fm-italics">x<sub class="fm-subscript">k</sub></i><sup class="fm-superscript">43</sup> = 0, <i class="fm-italics">pbest<sub class="fm-subscript">k</sub></i><sup class="fm-superscript">43</sup> = 1, <i class="fm-italics">gbest<sub class="fm-subscript">k</sub></i><sup class="fm-superscript">3</sup> = 1, ϕ<sub class="fm-subscript">1</sub> = 1.5, ϕ<sub class="fm-subscript">2</sub> = 1.9</span></p>

    <p class="fm-sidebar-text"><span class="times"><i class="fm-italics">v<sub class="fm-subscript">k</sub></i> <sub class="fm-subscript">+ 1</sub><sup class="fm-superscript">43</sup> = 0.23 + 1.5(1–0) + 1.9(1–0) = 3.63</span></p>

    <p class="fm-sidebar-text"><span class="times"><i class="fm-italics">sig</i>(<i class="fm-italics">v<sub class="fm-subscript">k</sub></i> <sub class="fm-subscript">+ 1</sub><sup class="fm-superscript">43</sup>) = <i class="fm-italics">sig</i>(3.63) = 1/(1 + <i class="fm-italics">e</i><sup class="fm-superscript">–3.63</sup>) = 0.974</span></p>

    <p class="fm-sidebar-text">Generate a random number <span class="times"><i class="fm-italics">r</i><sup class="fm-superscript">43</sup> = 0.6</span>, and update the position using equation 9.10 as follows:</p>

    <p class="fm-sidebar-text"><span class="times"><i class="fm-italics">x<sub class="fm-subscript">k</sub></i> <sub class="fm-subscript">+ 1</sub><sup class="fm-superscript">43</sup> = 1</span> as <span class="times"><i class="fm-italics">sig</i>(<i class="fm-italics">v<sub class="fm-subscript">k</sub></i> <sub class="fm-subscript">+ 1</sub><sup class="fm-superscript">43</sup>) &gt; <i class="fm-italics">r</i><sup class="fm-superscript">43</sup></span></p>

    <p class="fm-sidebar-text">Updated particle 4: 100110</p>
  </div>

  <p class="body">For more information about BPSO, see Kennedy and Eberhart’s article “A discrete binary version of the particle swarm algorithm” [2].<a id="idIndexMarker063"/><a id="idIndexMarker064"/><a id="marker-342"/></p>

  <h2 class="fm-head" id="heading_id_10">9.4 Permutation-based PSO</h2>

  <p class="body">Numerous efforts have been undertaken to employ PSO in solving permutation problems. The challenge of adapting PSO to tackle these problems arises from the fact that the notions of velocity and direction are not inherently applicable to permutation problems. To overcome this obstacle, arithmetic operations like addition and multiplication need to be redefined. <a id="idIndexMarker065"/><a id="idIndexMarker066"/></p>

  <p class="body">In M. Clerc’s 2004 article, “Discrete particle swarm optimization, illustrated by the traveling salesman problem” [3], PSO was applied to solve the TSP. The position of a particle was the solution to a problem (the permutation of cities). The velocity of a particle was defined as the set of swaps to be performed on a particle. As you have seen, the right side of equation 9.1 contains three arithmetic operations: multiplication, subtraction, and addition. These operations are redefined for the new search space as follows:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Multiplication</i>—The velocity vector constrains a number of swaps between cities. Multiplying this vector by a constant <i class="timesitalic">c</i>, results in another velocity vector with a different length, depending on the value of the constant. If <span class="times"><i class="fm-italics">c</i> = 0</span>, the length of the velocity vector (i.e., the included number of swaps) is set to 0. This means that no swap will be performed. If <span class="times"><i class="fm-italics">c</i> &lt; 1</span>, the velocity is truncated. If <span class="times"><i class="fm-italics">c</i> &gt; 1</span>, the velocity is augmented as illustrated in figure 9.8. Augmentation means adding a swap taken from the top of the current velocity vector to the end of the new velocity vector.<a id="idIndexMarker067"/></p>
    </li>
  </ul>

  <div class="figure">
    <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F08_Khamis.png"/></p>

    <p class="figurecaptiond">Figure 9.8 Redefined multiplication for permutation-based PSO</p>
  </div>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Subtraction</i>—Subtracting two positions should produce a velocity. This operation produces the sequence of swaps that could transform one position to the other. For example, let’s consider an 8-city TSP. A candidate solution for this TSP is represented by a permutation such as [2, 4, 6, 1, 5, 3, 8, 7]. Figure 9.9 shows how a new velocity vector is produced by subtracting two positions.<a id="idIndexMarker068"/></p>
    </li>
  </ul>

  <div class="figure">
    <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F09_Khamis.png"/></p>

    <p class="figurecaptiond">Figure 9.9 Redefined subtraction operation for permutation-based PSO</p>
  </div>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Addition</i>—The operation is performed by applying the sequence of swaps defined by the velocity to the position vector. Figure 9.10 shows how a new position (i.e., a new candidate solution) is generated by adding the velocity swap vector to the current position.<a id="idIndexMarker069"/><a id="marker-343"/></p>
    </li>
  </ul>

  <div class="figure">
    <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F10_Khamis.png"/></p>

    <p class="figurecaptiond">Figure 9.10 Redefined addition operation for permutation-based PSO</p>
  </div>

  <p class="body">These redefined arithmetic operations allow us to update the velocity and position of PSO particles.</p>

  <h2 class="fm-head" id="heading_id_11">9.5 Adaptive PSO</h2>

  <p class="body">The inertia, cognitive, and social components are the primary PSO parameters that can be used to achieve an equilibrium between exploration and exploitation during the optimization process. These three factors significantly influence the behavior of the algorithm, as discussed in the following subsections.<a id="idIndexMarker070"/></p>

  <h3 class="fm-head1" id="heading_id_12">9.5.1 Inertia weight</h3>

  <p class="body">The inertia parameter represents the tendency of a particle to maintain its current trajectory. By adjusting the inertia value, the algorithm can balance its focus on searching the solution space broadly (exploration) or homing in on the best solutions found thus far (exploitation). Large values of <i class="timesitalic">ω</i> promote exploration, and small values promote exploitation, as illustrated in figure 9.11. Excessively small values may hinder the swarm’s exploration capabilities. As the value of <i class="timesitalic">ω</i> decreases, the influence of the cognitive and social components on position updates becomes more dominant.<a id="idIndexMarker071"/><a id="idIndexMarker072"/><a id="marker-344"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F11_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.11 Effect of PSO parameters on the search behavior. Large inertia promotes exploration, and small values promote exploitation. <span class="times"><i class="fm-italics">c</i>1 &gt; <span class="times"><i class="fm-italics">c</i>2</span></span> results in excessive wandering of individuals through the search space. In contrast, <span class="times"><i class="fm-italics">c</i>2 &gt; <span class="times"><i class="fm-italics">c</i>1</span></span> may lead particles to rush prematurely toward a local optimum.</p>
  </div>

  <p class="body">When <span class="times"><i class="fm-italics">ω</i> &gt; 1</span>, particle velocities tend to escalate over time, accelerating toward the maximum velocity (provided that velocity clamping is utilized), ultimately causing the swarm to diverge. In this scenario, particles struggle to alter their direction to return to promising regions. On the other hand, when <span class="times"><i class="fm-italics">ω</i> &lt; 1</span>, particles may gradually decelerate until their velocities approach 0, depending on the acceleration coefficients’ values. Velocity clamping can be considered by setting a maximum (and minimum) limit for the velocity. If the calculated velocity for a particle exceeds this limit, it is set to the maximum (or minimum) value. This prevents particles from wandering too far off in the problem space or getting stuck in a specific region in the search space.</p>

  <p class="body">The following methods can be used to update the inertia weight:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Random selection (RS)</i>—This involves selecting a different inertia weight in each iteration. The weight can be chosen from a distribution with a mean and standard deviation of your choice, but it’s important to ensure that the swarm still converges despite the randomness. The following formula can be used:<a id="idIndexMarker073"/></p>
    </li>
  </ul>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F11_Khamis-EQ11.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.11</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body-ind">where <i class="fm-italics">rand</i>(.) is a uniformly distributed random number within the range [0,1]. Therefore, the mean value of the inertia weight is 0.75.</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Linear time varying (LTV)</i>—This involves gradually decreasing the value of <i class="timesitalic">𝜔</i> from a starting high value of <i class="timesitalic">𝜔<sub class="fm-subscript">max</sub></i> to a final low value of <i class="timesitalic">𝜔<sub class="fm-subscript">min</sub></i> following this equation:<a id="idIndexMarker074"/><a id="marker-345"/></p>
    </li>
  </ul>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F11_Khamis-EQ12.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.12</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body-ind">where <i class="timesitalic">𝑡<sub class="fm-subscript">max</sub></i> is the number of iterations, <i class="timesitalic">t</i> is the current iteration, and <i class="timesitalic">𝜔<sub class="fm-subscript">t</sub></i> is the value of the inertia weight in the <span class="times"><i class="fm-italics">t</i><sup class="fm-superscript">th</sup></span> iteration. Typically, the convention is to set <i class="timesitalic">𝜔<sub class="fm-subscript">max</sub></i> and <i class="timesitalic">𝜔<sub class="fm-subscript">min</sub></i> to 0.9 and 0.4 respectively.</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Nonlinear time varying (NLTV)</i>—This approach also involves decreasing the inertia weight from an initial high value, but this decrement can be nonlinear, as shown in the following equation:<a id="idIndexMarker075"/></p>
    </li>
  </ul>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F11_Khamis-EQ13.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.13</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body-ind">where <span class="times"><i class="fm-italics">𝜔<sub class="fm-subscript">𝑡</sub></i><sub class="fm-subscript">=0</sub> = 0.9</span> is the initial choice of <i class="timesitalic">𝜔</i>. By allowing more time to fall off toward the lower end of the dynamic range, NLTV can enhance local search or exploitation.</p>

  <p class="body">Figure 9.12 shows these three update methods.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F12_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.12 Different inertia weight update methods</p>
  </div>

  <p class="body">As you can see, in random selection, a different inertia weight is randomly selected in each iteration. The mean value of the inertia weight is 0.75. LTV linearly decreases the inertia weight. In NLTV, the inertia weight decrement is more gradual than in LTV. In summary, the inertia weight plays a crucial role in the convergence speed and solution quality of the PSO algorithm. A high inertia weight promotes exploration, while a low inertia weight encourages exploitation.</p>

  <h3 class="fm-head1" id="heading_id_13">9.5.2 Cognitive and social components</h3>

  <p class="body"><a id="marker-346"/>The cognitive component <span class="times"><i class="fm-italics">c</i>1</span> is a parameter associated with a particle’s individual learning capability, where the particle is influenced by its own experiences. The social component <span class="times"><i class="fm-italics">c</i>2</span> is a parameter linked to the collective learning capability of all particles within the swarm. It represents the degree to which a particle is influenced by the best solutions found by its neighbors. If <span class="times"><i class="fm-italics">c</i>1 &gt; <i class="fm-italics">c</i>2</span>, the algorithm will show exploratory behavior, and if <span class="times"><i class="fm-italics">c</i>2 &gt; <i class="fm-italics">c</i>1</span>, the algorithm will tend to exploit the local search space, as illustrated in figure 9.11. Setting <span class="times"><i class="fm-italics">c</i>1</span> = 0 reduces the velocity model to a social-only model or selfless model (the particles are all attracted to <i class="fm-italics">nbest</i>). On the other hand, setting <span class="times"><i class="fm-italics">c</i>2 = 0</span> reduces it to a cognition-only model (particles are independent, as in the case of the hill climbing algorithm).<a id="idIndexMarker076"/><a id="idIndexMarker077"/><a id="idIndexMarker078"/><a id="idIndexMarker079"/></p>

  <p class="body">Typically, <span class="times"><i class="fm-italics">c</i>1</span> and <span class="times"><i class="fm-italics">c</i>2</span> are kept constant in PSO. Empirically, the sum of <span class="times"><i class="fm-italics">c</i>1</span> and <span class="times"><i class="fm-italics">c</i>2</span> should be less than or equal to 4, and any significant deviations from this may result in divergent behavior. In adaptive PSO, it is advisable to gradually decrease the value of <span class="times"><i class="fm-italics">c</i>1</span> over time and concurrently increase the value of <span class="times"><i class="fm-italics">c</i>2</span> using linear formulas [4], as follows:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F12_Khamis-EQ14.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.14</p>
        </td>
      </tr>
    </tbody>
  </table>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F12_Khamis-EQ15.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.15</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">where <i class="timesitalic">t</i> is the iteration index, <span class="times"><i class="fm-italics">c</i>1<i class="fm-italics"><sub class="fm-subscript">max</sub></i></span> and <span class="times"><i class="fm-italics">c</i>2<i class="fm-italics"><sub class="fm-subscript">max</sub></i></span> are the maximum cognitive and social parameters respectively, <span class="times"><i class="fm-italics">c</i>1<i class="fm-italics"><sub class="fm-subscript">min</sub></i></span> and <span class="times"><i class="fm-italics">c</i>2<i class="fm-italics"><sub class="fm-subscript">min</sub></i></span> are the minimum cognitive and social parameters respectively, and <i class="timesitalic">t<sub class="fm-subscript">max</sub></i> is the maximum iteration.<a id="marker-347"/></p>

  <p class="body">Figure 9.13 shows the linearly changing <span class="times"><i class="fm-italics">c</i>1 and <span class="times"><i class="fm-italics">c</i>2</span></span>. As you can see, we start with <span class="times"><i class="fm-italics">c</i>1 &gt; <span class="times"><i class="fm-italics">c</i>2</span></span> to favor exploration. As the search progresses, <span class="times"><i class="fm-italics">c</i>2</span> starts to be higher than <span class="times"><i class="fm-italics">c</i>1</span> in order to favor exploitation.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F13_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.13 Cognitive and social acceleration coefficient updates. c1&gt;c2 results in more exploration, while c2&gt;c1 may lead to more exploitation.</p>
  </div>

  <p class="body">Let’s now see how we can use PSO to handle continuous and discrete optimization problems.<a id="idIndexMarker080"/></p>

  <h2 class="fm-head" id="heading_id_14">9.6 Solving the traveling salesman problem</h2>

  <p class="body">In the previous chapter, you saw how to solve the TSP for 20 major cities in the United States, starting from New York City, using a genetic algorithm. Let’s now solve the same problem using PSO, as shown in the next listing. We’ll start by defining the latitude and longitude for the twenty US cities and computing the inter-city distances between them.<a id="idIndexMarker081"/><a id="idIndexMarker082"/><a id="idIndexMarker083"/><a id="marker-348"/></p>

  <p class="fm-code-listing-caption">Listing 9.2 Solving TSP using PSO</p>
  <pre class="programlisting">import numpy as np
import pandas as pd
from collections import defaultdict
from haversine import haversine
import networkx as nx
import matplotlib.pyplot as plt
import pyswarms as ps
  
cities = {
    'New York City': (40.72, -74.00),
    'Philadelphia': (39.95, -75.17),       
    'Baltimore': (39.28, -76.62),
    'Charlotte': (35.23, -80.85),
    'Memphis': (35.12, -89.97),
    'Jacksonville': (30.32, -81.70),
    'Houston': (29.77, -95.38),
    'Austin': (30.27, -97.77),
    'San Antonio': (29.53, -98.47),
    'Fort Worth': (32.75, -97.33),
    'Dallas': (32.78, -96.80),
    'San Diego': (32.78, -117.15),
    'Los Angeles': (34.05, -118.25),
    'San Jose': (37.30, -121.87),
    'San Francisco': (37.78, -122.42),    
    'Indianapolis': (39.78, -86.15),
    'Phoenix': (33.45, -112.07),       
    'Columbus': (39.98, -82.98), 
    'Chicago': (41.88, -87.63),
    'Detroit': (42.33, -83.05)
}                                                    <span class="fm-combinumeral">①</span>
  
distance_matrix = defaultdict(dict)                  <span class="fm-combinumeral">②</span>
for ka, va in cities.items():                        <span class="fm-combinumeral">②</span>
    for kb, vb in cities.items():                    <span class="fm-combinumeral">②</span>
        distance_matrix[ka][kb] = 0.0 if kb == ka    <span class="fm-combinumeral">②</span>
<span class="fm-code-continuation-arrow">➥</span> else haversine((va[0],va[1]), (vb[0], vb[1]))     <span class="fm-combinumeral">②</span>
  
distances = pd.DataFrame(distance_matrix)            <span class="fm-combinumeral">③</span>
distance=distances.values                            <span class="fm-combinumeral">③</span>
city_names=list(distances.columns)                   <span class="fm-combinumeral">③</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Define the latitude and longitude for twenty major US cities.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Create a haversine distance matrix based on the latitude and longitude coordinates.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Convert the distance dictionary into a dataframe with distances as values and city names as headers.</p>

  <p class="body">Next, we can count the number of cities and set up the integer bounds of the decision variables, which represent the order in which the cities are visited. The first function, <code class="fm-code-in-text">tsp_distance</code>, takes two arguments: <code class="fm-code-in-text">position</code> and <code class="fm-code-in-text">distance</code>. <code class="fm-code-in-text">position</code> is a 1D array that represents the order in which the cities are visited. <code class="fm-code-in-text">distance</code> is a 2D array that contains the distances between all pairs of cities. The function first defines <code class="fm-code-in-text">tour</code> as a permutation of the indices that represent the order of visiting the cities. It then calculates the total distance of the tour by summing the distances between adjacent cities as well as the distance between the last city in the tour and the starting city. <a id="idIndexMarker084"/></p>

  <p class="body">The second function, <code class="fm-code-in-text">tsp_cost</code>, takes two arguments: <code class="fm-code-in-text">x</code> and <code class="fm-code-in-text">distance</code>. <code class="fm-code-in-text">x</code> is a 2D array that contains the decision variables for the TSP problem, with each row representing a different particle in the swarm. <code class="fm-code-in-text">distance</code> is a 2D array that contains the distances between all pairs of cities. The function calculates the cost of each particle by calling the <code class="fm-code-in-text">tsp_distance</code> function on each row of <code class="fm-code-in-text">x</code> and returns a list of the costs:<a id="idIndexMarker085"/><a id="marker-349"/></p>
  <pre class="programlisting">n_cities = len(city_names)                                            <span class="fm-combinumeral">①</span>
bounds = (np.zeros(n_cities), np.ones(n_cities)*(n_cities-1))         <span class="fm-combinumeral">①</span>
  
def tsp_distance(position, distance):                                 <span class="fm-combinumeral">②</span>
    tour = np.argsort(position)                                       <span class="fm-combinumeral">③</span>
    total_distance = distance[0, tour[0]]                             <span class="fm-combinumeral">④</span>
    for i in range(n_cities-1):                                       <span class="fm-combinumeral">④</span>
        total_distance += distance[tour[i], tour[i+1]]                <span class="fm-combinumeral">④</span>
    total_distance += distance[tour[-1], 0]                           <span class="fm-combinumeral">④</span>
    return total_distance
  
def tsp_cost(x, distance):                                            <span class="fm-combinumeral">⑤</span>
    n_particles = x.shape[0]                                          <span class="fm-combinumeral">⑤</span>
    cost=0                                                            <span class="fm-combinumeral">⑤</span>
    cost = [tsp_distance(x[i], distance) for i in range(n_particles)] <span class="fm-combinumeral">⑤</span>
    return cost                                                       <span class="fm-combinumeral">⑤</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Define the TSP problem as a permutation optimization problem with integer bounds.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Define the TSP distance function</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Convert the permutation to a TSP tour.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Compute the total distance of the tour from New York City as the first city, and add the distance from the last city back to New York City.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Compute and return the cost of each particle in the swarm.</p>

  <p class="body">As a continuation of listing 9.2, the following code sets the parameters for the PSO optimizer. <code class="fm-code-in-text">options</code> is a dictionary that contains the values for the inertia weight (<code class="fm-code-in-text">w</code>), cognitive (<code class="fm-code-in-text">c1</code>) and social (<code class="fm-code-in-text">c2</code>) acceleration coefficients, number of neighbors to consider (<code class="fm-code-in-text">k</code>), and the p-value for the Minkowski distance (<code class="fm-code-in-text">p</code>). <code class="fm-code-in-text">n_particles</code> represents the number of particles used in the optimization, and <code class="fm-code-in-text">dimensions</code> represents the number of decision variables, which is equal to the number of cities in the TSP problem. The best solution found by the optimizer is converted to a TSP tour by sorting the indices of the solution in ascending order and using them to index the <code class="fm-code-in-text">city_names</code> list in the same order. This creates a list of city names in the order that they are visited in the best tour. We then print the best route and its length:<a id="idIndexMarker086"/><a id="idIndexMarker087"/><a id="idIndexMarker088"/><a id="idIndexMarker089"/><a id="idIndexMarker090"/><a id="idIndexMarker091"/><a id="idIndexMarker092"/><a id="idIndexMarker093"/></p>
  <pre class="programlisting">options = {'w': 0.79, 'c1': 2.05, 'c2': 2.05, 'k': 10, 'p': 2}            <span class="fm-combinumeral">①</span>
optimizer = ps.discrete.BinaryPSO(n_particles=100, dimensions=n_cities,
<span class="fm-code-continuation-arrow">➥</span> options=options)                                                       <span class="fm-combinumeral">②</span>
  
cost, solution = optimizer.optimize(tsp_cost, iters=150, verbose=True,
<span class="fm-code-continuation-arrow">➥</span> distance=distance)                                                     <span class="fm-combinumeral">③</span>
  
tour = np.argsort(solution)                                               <span class="fm-combinumeral">④</span>
city_names_tour = [city_names[i] for i in tour]                           <span class="fm-combinumeral">④</span>
  
Route = " → ".join(city_names_tour)                                       <span class="fm-combinumeral">⑤</span>
print("Route:", Route)                                                    <span class="fm-combinumeral">⑤</span>
print("Route length:", np.round(cost, 3))                                 <span class="fm-combinumeral">⑤</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Set up the PSO parameters.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Instantiate the PSO optimizer.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Solve the problem.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Convert the best solution to a TSP tour.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Print the best route and its length.</p>

  <p class="body">Listing 9.2 produces the following output:</p>
  <pre class="programlisting">Route: New York City → Columbus → Indianapolis → Memphis → San Francisco → San Jose → Los Angeles → San Diego → Phoenix → Dallas → Fort Worth → San Antonio → Austin → Houston → Jacksonville → Charlotte → Baltimore → Philadelphia → Chicago → Detroit
Route length: 12781.892</pre>

  <p class="body"><a id="marker-350"/>Figure 9.14 shows the obtained route. The complete version of listing 9.2 is available in the book’s GitHub repo, and it shows the steps for visualizing the route as a NetworkX graph.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F14_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.14 PSO solution for the 20-city TSP</p>
  </div>

  <p class="body">Feel free to adjust the code according to your needs by modifying elements such as the problem data, the initial city, or the parameters of the algorithm.<a id="idIndexMarker094"/><a id="idIndexMarker095"/><a id="idIndexMarker096"/></p>

  <h2 class="fm-head" id="heading_id_15">9.7 Neural network training using PSO</h2>

  <p class="body">Machine learning (ML) is a subfield of artificial intelligence (AI) that endows an artificial system or process with the ability to learn from experience and observation without being explicitly programmed. Many ML approaches have been and are still being proposed, and more details about ML will be provided in chapter 11. For now, let’s consider neural networks, which are one of the most used and successful statistical ML approaches. The artificial neural network (ANN or NN) approach is inspired by the biological brain and can be considered a highly simplified computational model, as NN is very far from matching a brain’s complexity. NN is at the heart of deep learning models that nowadays form the basis of many successful applications that touch everybody’s life, such as text, audio, image, and video generation, voice assistants, and recommendation engines, to name just a few.<a id="marker-351"/><a id="idIndexMarker097"/><a id="idIndexMarker098"/><a id="idIndexMarker099"/><a id="idIndexMarker100"/><a id="idIndexMarker101"/></p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">The human brain</p>

    <p class="fm-sidebar-text">Aristotle (384-322 BC) wrote, “Of all the animals, man has the largest brain in proportion to his size.” The human brain is composed of an average of 86 billon interconnected nerve cells or <i class="fm-italics">neurons</i>. Each biological neuron is connected to several thousand other neurons. It is extremely energy efficient, as it can perform the equivalent of an exaflop (a billion billion mathematical operations per second) with just 20 watts of power.</p>
  </div>

  <p class="body">For simplicity, consider ML as glorified curve fitting, which intends to find a mapping function between independent and dependent variables. For example, suppose a vision-based object recognition model takes as input a digital image taken by the front camera of a vehicle—the output would be recognized objects, such as cars, pedestrians, cyclists, lanes, traffic lights, etc. In fact, ML shares the same ingredients as curve fitting in terms of model, scoring criteria, and search strategy. However, ML approaches, such as NNs, are a way to create functions that no human could write. They tend to create nonlinear, nonmonotonic, nonpolynomial, and even noncontinuous functions that approximate the relationship between independent and dependent variables in a data set. <a id="idIndexMarker102"/></p>

  <p class="body">An NN is a massively parallel adaptive network of simple nonlinear computing elements called neurons that are arranged in input, hidden, and output layers. Each node, or artificial neuron, connects to another and has an associated weight and threshold allowing the node to simulate a neuron firing. Each individual node has its own linear regression model, composed of input data, a bias, a threshold, and an output, as illustrated in figure 9.15. A neuron <i class="timesitalic">k</i> can be described with the following equation:<a id="idIndexMarker103"/></p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F14_Khamis-EQ16.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.16</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">Its output is</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <div class="figure2">
            <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F14_Khamis-EQ17.png"/></p>
          </div>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">9.17</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">where <i class="timesitalic">x<sub class="fm-subscript">i</sub></i> are the inputs, <i class="timesitalic">ω<sub class="fm-subscript">ki</sub></i> are the weights, <i class="timesitalic">b</i> is the bias term that defines the ability to fire in the absence of external input to the node, and <i class="timesitalic">φ</i> is the activation function. This activation function makes the neuron fire the output when the input <i class="timesitalic">z<sub class="fm-subscript">k</sub></i> reaches a threshold <i class="timesitalic">θ<sub class="fm-subscript">k</sub></i>. There are different forms of activation functions (aka squashing functions) such as sign, step, tanh, arctan, s-shaped sigmoid (aka logistic), softmax, radial basis function, and rectified linear unit (ReLU). <a id="idIndexMarker104"/><a id="idIndexMarker105"/><a id="idIndexMarker106"/><a id="marker-352"/></p>

  <p class="body">As in the case of curve fitting, a scoring criterion or cost function is used to estimate deviation between the estimated values and the actual values. In this context, training an NN is fundamentally an optimization problem. The goal of training is to find the optimal parameters (weights and biases) that minimize the difference between the network’s output and the expected output. This difference is often quantified using a loss or cost function, such as these:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Mean squared error (MSE)</i>—MSE is often used in regression problems. It calculates the square of the difference between the predicted and actual values and then averages these across the dataset. This function heavily penalizes large errors. <a id="idIndexMarker107"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Cross-entropy loss</i>—Cross-entropy loss is typically used for binary and multiclass classification problems. It measures the dissimilarity between the predicted probability distribution and the actual distribution. In other words, it compares the model’s confidence in its prediction with the actual outcome. <a id="idIndexMarker108"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Negative log likelihood (NLL)</i>—NLL is another loss function in multiclass classification. If <i class="timesitalic">y</i> is the true label and <span class="times"><i class="fm-italics">p</i>(<i class="fm-italics">y</i>)</span> is the predicted probability of that label, the negative log likelihood is defined as <span class="times">–log(<i class="fm-italics">p</i>(<i class="fm-italics">y</i>))</span>. The log function transforms the probabilities, which range between 0 and 1, to a scale that ranges from positive infinity to 0. When the predicted probability for the correct class is high (close to 1), the log value is closer to 0, but as the predicted probability for the correct class decreases, the log value increases toward infinity. Negating the log value thus gives a quantity that is minimized when the predicted probability for the correct class is maximized.<a id="idIndexMarker109"/><a id="idIndexMarker110"/><a id="idIndexMarker111"/></p>
    </li>
  </ul>

  <div class="figure">
    <p class="figured"><img alt="" class="calibre4" src="../Images/CH09_F15_Khamis.png"/></p>

    <p class="figurecaptiond">Figure 9.15 Neural network node demonstration</p>
  </div>

  <p class="body">Training an NN involves the following steps:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Initialization</i>—Before training starts, the weights and biases in the network are typically initialized with small random numbers.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Feedforward</i>—In this stage, the input is passed through the network to produce an output. This output is generated by performing computations on the inputs using the initial or current weights, bias, and activation function transformation. The output of one layer becomes the input to the next layer until the final output is produced.<a id="marker-353"/><a id="idIndexMarker112"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Error calculation</i>—After the feedforward stage, the output is compared with the desired output to calculate the error using a loss function. This function quantifies how far the network’s predictions are from the actual values.<a id="idIndexMarker113"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Backpropagation</i>—The calculated error is then propagated back through the network, starting from the output layer and moving back toward the input layer. This process computes the gradient or derivative of the loss function with respect to the weights and biases in the network.<a id="idIndexMarker114"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Weight adjustment</i>—In this final stage, the weights of the network are updated in an effort to reduce the error. This is typically done using a technique called <i class="fm-italics">gradient descent</i>. The weights are adjusted in the direction that most decreases the error, as determined by the gradients calculated during backpropagation.<a id="idIndexMarker115"/></p>
    </li>
  </ul>

  <p class="body">By repeating these steps for many iterations (or epochs), the network gradually learns to produce outputs that are closer to the desired ones, thus “learning” from the input data.</p>

  <p class="body">Now that you have a basic understanding of NNs, let’s train a simple NN using PSO following a supervised learning approach. During supervised training, the NN learns by initially processing a labeled dataset. By training on a labeled dataset, the network can subsequently predict labels for a new, unlabeled data set during the inferencing stage, after training. <a id="idIndexMarker116"/></p>

  <p class="body">For this example, we will use the Penguins dataset. This is a popular dataset in the data science community, containing information on the size, sex, and species of penguins. The dataset consists of 344 observations collected from three islands in the Palmer Archipelago, Antarctica. It includes the following seven variables:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">species</code>—The species of penguin (Adelie, Chinstrap, or Gentoo)<a id="idIndexMarker117"/><a id="marker-354"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">island</code>—The island where the penguin was observed (Biscoe, Dream, or Torgersen)<a id="idIndexMarker118"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">bill_length_mm</code>—The length of the penguin’s bill in millimeters<a id="idIndexMarker119"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">bill_depth_mm</code>—The depth of the penguin’s bill in millimeters<a id="idIndexMarker120"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">flipper_length_mm</code>—The length of the penguin’s flipper in millimeters<a id="idIndexMarker121"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">body_mass_g</code>—The mass of the penguin’s body in grams<a id="idIndexMarker122"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">sex</code>—The sex of the penguin (male or female)</p>
    </li>
  </ul>

  <p class="body">Our simple NN, described in the PySwarms use cases, has the following characteristics:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Input layer size</i>—4</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Hidden layer size</i>—10 (activation function: tanh(<i class="fm-italics">x</i>)). The hyperbolic tangent activation function (aka Tanh, tanh, or TanH) maps input values to be between –1 and 1, and it’s used to introduce nonlinearity in NNs. Remember that a sigmoid function maps input values to be between 0 and 1. The tanh function is centered at 0, which helps mitigate the vanishing gradient problem, compared to the sigmoid function. However, both tanh and sigmoid activations suffer from the vanishing gradient problem to some degree. Alternatives like rectified linear unit (ReLU) and its variants are often preferred.<a id="idIndexMarker123"/><a id="idIndexMarker124"/><a id="idIndexMarker125"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Output layer size</i>—3 (activation function: softmax(<i class="fm-italics">x</i>)). Softmax is a generalization of the sigmoid function. This function takes as input the <i class="fm-italics">logits</i> that represent unnormalized outputs of the last layer of the network before they are transformed into probabilities by applying a softmax function. These logits can be interpreted as a measure of the “evidence” that a certain input belongs to a particular class. The higher the logit value for a particular class, the more likely it is that the input belongs to that class.<a id="idIndexMarker126"/></p>
    </li>
  </ul>

  <p class="body">The following listing shows the steps for training this simple NN using PSO. We start by importing the libraries we’ll need and reading the penguin dataset.</p>

  <p class="fm-code-listing-caption">Listing 9.3 Neural network training using PSO</p>
  <pre class="programlisting">import seaborn as sns                             <span class="fm-combinumeral">①</span>
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder    <span class="fm-combinumeral">②</span>
from sklearn.decomposition import PCA             <span class="fm-combinumeral">②</span>
import pyswarms as ps                             <span class="fm-combinumeral">③</span>
  
penguins = sns.load_dataset('penguins')           <span class="fm-combinumeral">④</span>
penguins.head()                                   <span class="fm-combinumeral">⑤</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Required for loading the dataset</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Required for target label encoding</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Required for dimensionality reduction</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Load the Penguins dataset.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Show the dataset rows and columns.</p>

  <p class="body"><a id="marker-355"/>This produces the output shown in figure 9.16.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F16_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.16 Penguins dataset</p>
  </div>

  <p class="body">As a continuation of listing 9.3, we can visualize this dataset using the seaborn library as follows:<a id="idIndexMarker127"/></p>
  <pre class="programlisting">plt.figure(figsize=(8, 6))
sns.scatterplot(data=penguins, x='bill_length_mm', y='body_mass_g', 
<span class="fm-code-continuation-arrow">➥</span> hue='species', style="species")
plt.title('Bill Length vs. Body Mass by Species')
plt.show()</pre>

  <p class="body">The output is shown in figure 9.17.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F17_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.17 Bill length vs. body mass by species in the Penguins dataset</p>
  </div>

  <p class="body"><a id="marker-356"/>Next, we define a <code class="fm-code-in-text">logits_function</code> to take in a vector <code class="fm-code-in-text">p</code> of parameters for the NN and return the logits (pre-activation values) for the final layer of the network. As illustrated in figure 9.18, this function starts by extracting the weights and biases for the first and second layers of the network from the parameter vector <i class="timesitalic">p</i> using indexing and reshaping operations. Then, the function performs forward propagation by computing the pre-activation value <span class="times"><i class="fm-italics">z</i><sup class="fm-superscript">1</sup></span> in the first layer as the dot product of the input data <i class="timesitalic">X</i> and the first set of weights <span class="times"><i class="fm-italics">W</i><sup class="fm-superscript">1</sup></span>, plus the bias term <span class="times"><i class="fm-italics">b</i><sup class="fm-superscript">1</sup></span>. It then applies the tanh activation function to <span class="times"><i class="fm-italics">z</i><sup class="fm-superscript">1</sup></span> to obtain the activation value <span class="times"><i class="fm-italics">a</i><sup class="fm-superscript">1</sup></span> in the first layer. Finally, the function computes the pre-activation value for the second layer by taking the dot product of <span class="times"><i class="fm-italics">a</i><sup class="fm-superscript">1</sup></span> and the second set of weights <span class="times"><i class="fm-italics">W</i><sup class="fm-superscript">2</sup></span> and adding the bias term <span class="times"><i class="fm-italics">b</i><sup class="fm-superscript">2</sup></span>. The resulting values are returned as the logits from the final layer of the network:</p>
  <pre class="programlisting">def logits_function(p):
  
    W1 = p[0: n_inputs * n_hidden].reshape((n_inputs, n_hidden)) 
    b1 = p[n_inputs * n_hidden: (n_inputs + 1) * n_hidden].reshape((n_hidden,))  <span class="fm-combinumeral">①</span>
    W2 = p[(n_inputs +1) * n_hidden: -n_classes].reshape((n_hidden, n_classes))  <span class="fm-combinumeral">②</span>
    b2 = p[-n_classes:].reshape((n_classes,))                                    <span class="fm-combinumeral">③</span>
  
    z1 = X.dot(W1) + b1                                                          <span class="fm-combinumeral">④</span>
    a1 = np.tanh(z1)                                                             <span class="fm-combinumeral">④</span>
    logits = a1.dot(W2) + b2                                                     <span class="fm-combinumeral">⑤</span>
    return logits                                                                <span class="fm-combinumeral">⑤</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Extracting the weights of the first laye</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Extracting the weights of the second layer</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Extracting the biases of the second layer</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Calculate the pre-activation value in the first layer .</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Calculate and return the logits.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F18_Khamis.png"/></p>

    <p class="figurecaption">Figure 9.18 NN layers</p>
  </div>

  <p class="body"><a id="marker-357"/>Next, we define the <code class="fm-code-in-text">forward_prop</code> function to perform a forward pass through an NN with two layers. This computes the softmax probabilities and negative log likelihood loss for the output, given a set of parameters <code class="fm-code-in-text">params</code>. The function first calls the <code class="fm-code-in-text">logits_function</code> to obtain the logits for the final layer of the network, given the parameters <code class="fm-code-in-text">params</code>. Then the function applies the softmax function to the logits using the <code class="fm-code-in-text">np.exp</code> function and normalizes the resulting values by dividing by the sum of the exponentiated logits for each sample, using the <code class="fm-code-in-text">np.sum</code> function with the <code class="fm-code-in-text">axis=1</code> argument. This gives a probability distribution over the classes for each sample. The function then computes the negative log likelihood loss by taking the negative log of the probability of the correct class for each sample, which is obtained by indexing the <code class="fm-code-in-text">probs</code> array using the <code class="fm-code-in-text">y</code> variable, which contains the true class labels. The <code class="fm-code-in-text">np.sum</code> function is used to compute the sum of these negative log probabilities across all samples, and the result is divided by the total number of samples to obtain the average loss per sample. Finally, the function returns the computed loss:<a id="idIndexMarker128"/></p>
  <pre class="programlisting">def forward_prop(params):
  
    logits = logits_function(params)                                  <span class="fm-combinumeral">①</span>
  
    exp_scores = np.exp(logits)                                       <span class="fm-combinumeral">②</span>
    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)    <span class="fm-combinumeral">②</span>
  
    correct_logprobs = -np.log(probs[range(num_samples), y])          <span class="fm-combinumeral">③</span>
    loss = np.sum(correct_logprobs) / num_samples                     <span class="fm-combinumeral">④</span>
  
    return loss                                                       <span class="fm-combinumeral">④</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Obtain the logits for the softmax.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Apply softmax to calculate the probability distribution over the classes.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Compute the negative log likelihood.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Compute and return the loss.</p>

  <p class="body"><a id="marker-358"/>To perform forward propagation over the whole swarm of particles, we define the following <code class="fm-code-in-text">particle_loss()</code> function. This function computes the loss for each particle in a PSO swarm, given its position in the search space. It is worth noting that each position represents the NN parameters (<span class="times">w1,b1,w2,b2</span>) with <code class="fm-code-in-text">dimension</code> calculated as follows:</p>
  <pre class="programlisting">dimension = (n_inputs * n_hidden) + (n_hidden * n_classes) + n_hidden + n_classes = 4 * 10 + 10 * 3 + 10 * 3 + 1 * 10 + 1 * 3 = 83.</pre>

  <p class="body">An example of a candidate setting of NN parameters (i.e., a <i class="fm-italics">position</i> in PSO terminology) is given here:</p>
  <pre class="programlisting">[ 3.65105185e-01 -9.57472869e-02  4.99475198e-01  2.33703047e-01
  5.56295931e-01  6.95323783e-01  8.76045204e-02  5.52892675e-01
  3.33363337e-01  5.60680304e-01  3.24233602e-01  3.40402243e-01
  2.28940991e-01  6.47396295e-01  2.49476898e-01 -2.15041386e-01
  6.61749764e-01  4.50805880e-01  7.31521923e-01  4.55724886e-01
  5.81614992e-01  4.21303249e-01  3.10417945e-01  2.80091464e-01
  3.63352355e-01  7.21593713e-01  4.11009136e-01  3.50489680e-01
  6.82325768e-01  3.60945155e-01  3.34258781e-01  5.53845122e-01
  5.39748679e-01  8.45310205e-01  7.38728229e-01  5.44408893e-01
  4.22464042e-01  4.45099192e-01  4.36914661e-01 -2.40298612e-02
  4.68795601e-01  4.58388074e-01  2.29566792e-01  5.18783606e-01
  1.21226363e-01  2.80730816e-01  4.13249634e-01  1.91229505e-01
  6.30829496e-01 -4.52777424e-01  1.62066215e-01  3.07603861e-01
  1.54565454e-01  5.39974173e-01  4.48241886e-01 -2.81999490e-04
  2.93907050e-01  2.58571312e-01  7.87784363e-01  5.06092352e-01
  1.85010537e-01  8.06641243e-01  8.30985197e-01  4.06314407e-01
  2.20795704e-01  3.25405213e-01  6.02993839e-01  4.21051295e-01
  5.24352428e-01  2.49710316e-01  4.99212007e-01  4.48000964e-01
  4.90888329e-01  3.94908331e-01  6.35997377e-01  5.91192453e-01
  6.16639300e-01  6.85748919e-01  5.40805197e-01 -1.51195135e+00
  3.21751027e-01  3.93555680e-01  5.23679003e-01]</pre>

  <p class="body">The PSO algorithm can then use these loss values to update the positions of the particles and search for the optimal set of parameters for the NN.<a id="idIndexMarker129"/></p>
  <pre class="programlisting">def particle_loss(x):
    n_particles = x.shape[0]                               <span class="fm-combinumeral">①</span>
    j = [forward_prop(x[i]) for i in range(n_particles)]   <span class="fm-combinumeral">②</span>
    return np.array(j)                                     <span class="fm-combinumeral">②</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Determine the number of particles.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Compute and return the loss for each particle.</p>

  <p class="body">The last function we need is <code class="fm-code-in-text">predict</code>, which uses the NN parameters corresponding to the positions of particles in a PSO swarm to predict the class labels for each sample in the dataset. This function first calls <code class="fm-code-in-text">logits_function</code> to obtain the logits for the final layer of the network, given the positions <code class="fm-code-in-text">pos</code> of the particles in the search space. Then the function computes the predicted class labels by taking the <code class="fm-code-in-text">argmax</code> of the logits across the columns (i.e., along the second axis or <code class="fm-code-in-text">axis=1</code>), using the <code class="fm-code-in-text">np.argmax</code> function. This gives the index of the class with the highest probability for each sample. Finally, the function returns the predicted class labels as a numpy array <code class="fm-code-in-text">y_pred</code>:<a id="idIndexMarker130"/><a id="idIndexMarker131"/></p>
  <pre class="programlisting">def predict(pos):
    logits = logits_function(pos)         <span class="fm-combinumeral">①</span>
    y_pred = np.argmax(logits, axis=1)    <span class="fm-combinumeral">②</span>
    return y_pred                         <span class="fm-combinumeral">②</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Obtain logits for the final layer of the network.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Compute and return the predicted class labels.</p>

  <p class="body"><a id="marker-359"/>We can now train the NN using different PSOs available in PySwarms. The code starts by setting up several training samples, inputs, and the number of hidden layers and outputs. The dimensions are then computed based on the number of inputs, hidden nodes, and output classes. Three variants of PSO are defined: <code class="fm-code-in-text">globalBest</code>, <code class="fm-code-in-text">localBest</code>, and <code class="fm-code-in-text">binaryPSO</code>. The PSO hyperparameters are set using a dictionary called <code class="fm-code-in-text">options</code>. These hyperparameters include the inertia weight <code class="fm-code-in-text">w</code>, the cognitive parameter <code class="fm-code-in-text">c1</code>, the social parameter <code class="fm-code-in-text">c2</code>, the number of neighbors to be considered <code class="fm-code-in-text">k</code>, and the Minkowski distance parameter <code class="fm-code-in-text">p</code> (<code class="fm-code-in-text">p=1</code> is the sum-of-absolute values [or the L1 distance], while <code class="fm-code-in-text">p=2</code> is the Euclidean [or L2] distance):<a id="idIndexMarker132"/><a id="idIndexMarker133"/><a id="idIndexMarker134"/></p>
  <pre class="programlisting">X = penguins[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm',
<span class="fm-code-continuation-arrow">➥</span> 'body_mass_g']].to_numpy()                                            <span class="fm-combinumeral">①</span>
num_samples = X.shape[0]                                                 <span class="fm-combinumeral">②</span>
n_inputs = X.shape[1]                                                    <span class="fm-combinumeral">②</span>
n_hidden = 10                                                            <span class="fm-combinumeral">②</span>
n_classes = len(np.unique(y))                                            <span class="fm-combinumeral">②</span>
  
dimensions = (n_inputs * n_hidden) + (n_hidden * n_classes) + n_hidden + n_
classes                                                                  <span class="fm-combinumeral">③</span>
  
PSO_varaints = ['globalBest', 'localBest', 'binaryPSO']                  <span class="fm-combinumeral">④</span>
  
options = {'w':0.79, 'c1': 0.9, 'c2': 0.5, 'k': 8, 'p': 2}               <span class="fm-combinumeral">⑤</span>
  
  
for algorithm in PSO_varaints:                                           <span class="fm-combinumeral">⑥</span>
    if algorithm == 'globalBest':
  
        optimizer = ps.single.GlobalBestPSO(n_particles=150, 
<span class="fm-code-continuation-arrow">➥</span> dimensions=dimensions, options=options)
        cost, pos = optimizer.optimize(particle_loss, iters=2000)
        print("#"*30)
        print(f"PSO varaints: {algorithm}")
        print(f"Best average accuracy: {100*round((predict(pos) == y).mean(),3)} %")
        print()
    elif algorithm == 'localBest':
        optimizer = ps.single.LocalBestPSO(n_particles=150, 
<span class="fm-code-continuation-arrow">➥</span> dimensions=dimensions, options=options)
        cost, pos = optimizer.optimize(particle_loss, iters=2000)
        print("#"*30)
        print(f"PSO varaints: {algorithm}")
        print(f"Best average accuracy: {100*round((predict(pos) == y).mean(),3)} %")
        print()
    elif algorithm == 'binaryPSO':
        optimizer = ps.discrete.BinaryPSO(n_particles=150, 
<span class="fm-code-continuation-arrow">➥</span> dimensions=dimensions, options=options)
        cost, pos = optimizer.optimize(particle_loss, iters=2000)
        print("#"*30)
        print(f"PSO varaints: {algorithm}")
        print(f"Best average accuracy: {100*round((predict(pos) == y).mean(),3)} %")
        print()</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Get the feature vector</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Set up the number of training samples, inputs, hidden layers, and outputs.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Set up the dimensions of the problem.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Define the variants of PSO.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Set up the PSO hyperparameters</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Train the NN using different variants of PSO, and print the best accuracy.</p>

  <p class="body">The code then trains an NN, using each variant of PSO in turn, by creating an instance of the PSO optimizer and calling the <code class="fm-code-in-text">optimize</code> method, passing in the loss function and the number of iterations to run, <code class="fm-code-in-text">iters</code>. The best loss and particle position found by the optimizer are stored in <code class="fm-code-in-text">cost</code> and <code class="fm-code-in-text">pos</code> respectively. The code then prints the variant of PSO used along with the best accuracy that was obtained by using the corresponding particle position to make a prediction and comparing it to the true class label <code class="fm-code-in-text">y</code>.</p>

  <p class="body">Running the complete listing produces the following output:</p>
  <pre class="programlisting">##############################
PSO variant: globalBest
Best average accuracy: 99.1 %
##############################
PSO variant: localBest
Best average accuracy: 69.1 %
##<a id="idTextAnchor001"/>############################
PSO variant: binaryPSO
Best average accuracy: 43.8 %</pre>

  <p class="body">As you can see, <code class="fm-code-in-text">globalBest</code> PSO is the most efficient PSO variant for training this NN. Binary PSO does not match with the continuous nature of the NN parameters. <a id="idIndexMarker135"/><a id="marker-360"/></p>

  <p class="body">You can experiment with the code by changing the problem and algorithm parameters. For example, you could use a reduced feature set such as <code class="fm-code-in-text">bill_length_mm</code> and <code class="fm-code-in-text">flipper_length_mm</code> instead of the four features used in this code. You could also change the algorithm parameters and apply velocity clamping. <code class="fm-code-in-text">velocity clamp</code> is a parameter enabled in PySwarms to set the limits for velocity clamping. It’s a tuple of size 2 where the first entry is the minimum velocity and the second entry is the maximum velocity.<a id="idIndexMarker136"/><a id="idIndexMarker137"/><a id="idIndexMarker138"/><a id="idIndexMarker139"/><a id="idIndexMarker140"/><a id="idIndexMarker141"/></p>

  <p class="body">In the next chapter, you will be introduced to ant colony optimization (ACO) and artificial bee colony (ABC) as other effective optimization algorithms inspired by swarm intelligence.</p>

  <h2 class="fm-head" id="heading_id_16">Summary</h2>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">PSO employs a stochastic approach that utilizes the collective intelligence and movement of a swarm of particles. It is based on the idea of social interaction, which allows for efficient problem-solving.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">The fundamental principle of PSO is to guide the swarm toward the best position in the search space while also remembering each particle’s own best-known position, as well as the global best-known position of the swarm.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">PSO is guided by a straightforward principle: emulate the success of neighboring individuals.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Although PSO was initially designed for solving problems with continuous variables, many real-world problems involve discrete or combinatorial variables. In these problems, the search space is finite, and the algorithm needs to search through a set of discrete solutions. To address these types of problems, different variants of PSO have been developed, such as binary PSO (BPSO) and permutation-based PSO.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">By carefully tuning inertia weight and cognitive and social acceleration coefficients, PSO can effectively balance exploration and exploitation.<a id="marker-361"/></p>
    </li>
  </ul>
</body></html>