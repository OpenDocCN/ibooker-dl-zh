- en: 12 Conversational summarization for smooth handoff
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 对话摘要以实现平滑交接
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Defining elements of an effective conversation summary
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义有效对话摘要的要素
- en: Instrumenting your conversational AI to enhance summarization
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 量化你的对话AI以增强摘要功能
- en: Summarizing a chat transcript into prose with LLMs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LLM将聊天记录摘要成散文
- en: Extracting structured details from a chat transcript with LLMs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LLM从聊天记录中提取结构化细节
- en: Conversational AI builders would love it if their systems contained all user
    conversations. But for most use cases, some percentage of users will end their
    interaction with a human and not your bot. Conversational AI is designed to handle
    the easily automated conversations and direct the higher-value or more challenging
    ones to human agents. Users who want to self-service may be frustrated by “failing”
    with the conversational AI, so it’s important to give that human agent the best
    start possible at handling the call after a transfer.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 对话AI构建者希望他们的系统中包含所有用户对话。但对于大多数用例，一些百分比的用户会在与人类交互结束后结束与你的机器人的交互。对话AI旨在处理易于自动化的对话，并将更有价值或更具挑战性的对话引导给人类代表。希望自助服务的用户可能会因为“失败”与对话AI而感到沮丧，因此，在转接后为人类代表提供尽可能好的开始处理电话非常重要。
- en: The two simplest handoff methods are also the least satisfactory. We can transfer
    the conversation “blind” to the human agent and have them ask again for all the
    information they need. Or we can pass the agent the full conversational transcript
    and ask them to search it for the information they need (while the user is waiting!).
    It’s better to give the human agent a targeted summary of the conversation to
    date so they can quickly pick up where the conversational AI left off.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 两种最简单的交接方法也是最不令人满意的。我们可以“盲目”将对话转交给人类代表，并让他们再次询问所有需要的信息。或者我们可以将完整的对话记录交给代表，并要求他们搜索所需的信息（同时用户在等待！）。更好的做法是给人类代表一个有针对性的对话摘要，这样他们可以快速接手对话AI留下的地方。
- en: 12.1 Intro to summarization
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 摘要简介
- en: A summary makes handoffs from AI to human go smoothly. First, we’ll review why
    summaries are needed. Then we’ll explore the elements of effective summaries.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要使AI到人类的交接过程更加顺畅。首先，我们将回顾为什么需要摘要。然后，我们将探讨有效摘要的要素。
- en: 12.1.1 Why summarization is needed
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.1 为什么需要摘要
- en: Most conversational AI solutions store full transcripts of conversations for
    auditing and data analysis purposes. This is a treasure trove of training data
    when you have time to analyze it. But when you are a call center agent being transferred
    a conversation from the AI, you don’t have time to read a lengthy transcript.
    You need to quickly grasp the essence of the user’s problem so you can start helping
    them. We’ve seen AI chat transcripts that go for multiple pages (hundreds of words).
    An agent needs a few targeted bullet points—any more will take too long to read,
    and any less will not convey enough useful information.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数对话AI解决方案存储完整的对话记录以供审计和数据分析。当你有时间分析时，这是一座宝库。但当你是一名被AI转接对话的客户服务中心代表时，你没有时间阅读冗长的记录。你需要快速抓住用户问题的本质，以便开始帮助他们。我们见过AI聊天记录长达多页（数百个单词）。代表需要几个有针对性的要点——更多将花费太多时间阅读，而更少则无法传达足够有用的信息。
- en: Figure 12.1 illustrates how a conversational summary is generated from a full
    conversational transcript when the chatbot hands off the conversation to a human
    agent.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1说明了当聊天机器人将对话转交给人类代表时，如何从完整的对话记录中生成对话摘要。
- en: '![figure](../Images/CH12_F01_Freed2.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH12_F01_Freed2.png)'
- en: Figure 12.1 An effective summary helps an agent get up to speed quickly, even
    if the user previously had a lengthy conversation with a bot.
  id: totrans-14
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.1 一个有效的摘要帮助代表快速熟悉情况，即使用户之前与机器人进行了长时间的对话。
- en: From the previous chapter, we know that some users immediately opt out to an
    agent, but many users go through a series of steps before getting frustrated.
    The following listing shows an example conversation where the user apparently
    accomplishes their goal but still requests an agent.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一章，我们知道一些用户会立即选择转接到代表，但许多用户在感到沮丧之前会经历一系列步骤。以下列表显示了一个示例对话，其中用户似乎完成了他们的目标，但仍然要求转接到代表。
- en: Listing 12.1 Example conversation between user and AI
  id: totrans-16
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.1 用户与AI的示例对话
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 User appears to accomplish their goal'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 用户似乎完成了他们的目标'
- en: '#2 User still opts out'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 用户仍然选择退出'
- en: We’re not sure why the user opted out (maybe the check didn’t arrive?). But
    that is beside the point. In most conversational AI solutions, users can opt out
    anywhere in the conversation. The conversation in listing 12.1 had seven turns
    and probably took about two minutes. It’s just long enough that it takes some
    effort to read and comprehend. Would you want to read that full conversation if
    you were the human agent? What if the conversation was longer?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不确定用户为什么选择退出（可能是检查没有到达？）。但这不是重点。在大多数对话式AI解决方案中，用户可以在对话的任何地方选择退出。列表12.1中的对话有七个回合，可能大约花费了两分钟。这足够长，以至于阅读和理解需要一些努力。如果你是人工代理，你会想阅读那个完整的对话吗？如果对话更长会怎样？
- en: A smooth handoff should happen quickly. The agent should quickly comprehend
    what has happened so they can be effective. The user should not have to wait for
    agent to get up to speed. An effective summary facilitates all those needs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 平滑的转接应该迅速发生。代理应该迅速理解发生了什么，以便他们能够有效行动。用户不应该需要等待代理熟悉情况。有效的总结有助于满足所有这些需求。
- en: 12.1.2 Elements of effective summaries
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.2 有效总结的要素
- en: A conversation summary includes just enough information to understand the complete
    conversation. It should include structured metadata and a short text summary;
    the summary’s contents will vary based on your specific use case. Figure 12.2
    shows an example.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一个对话总结只包含足够的信息来理解完整的对话。它应该包括结构化元数据和简短的文本总结；总结的内容将根据您的特定用例而变化。图12.2显示了示例。
- en: Metadata summary elements
  id: totrans-24
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 元数据摘要要素
- en: Structured summary elements often come from closed-form questions, such as “What’s
    your member ID?” (“Open-form” questions are like “How may I help?”) These summary
    elements can include data that was collected during the conversation or context
    that was supplied from outside of the conversation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化摘要要素通常来自封闭形式的问题，例如“你的会员ID是什么？”（“开放形式”问题类似于“我能帮您什么？”）这些摘要要素可以包括在对话中收集的数据或来自对话之外提供的环境。
- en: 'These are some example elements:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些示例要素：
- en: User ID of the logged-in user (chat) or the caller’s phone number (voice/SMS)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已登录用户的用户ID（聊天）或来电者的电话号码（语音/SMS）
- en: Identifiers collected during the chat
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天中收集的标识符
- en: Identifiers found during the chat
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天中发现的标识符
- en: Number of chat sessions the user has ever had
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户曾经进行的聊天会话数量
- en: Sentiment analysis of user utterances
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户话语的情感分析
- en: '![figure](../Images/CH12_F02_Freed2.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH12_F02_Freed2.png)'
- en: Figure 12.2 An effective summary pulls out key details from the conversation.
    Here it includes a summary of the conversation and the last claim searched. The
    AI portion of the call may have taken two minutes, but the human agent can read
    the summary in seconds.
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.2 一个有效的总结从对话中提取关键细节。这里包括对话总结和最后搜索的索赔。通话中的AI部分可能花费了两分钟，但人工代理可以在几秒钟内阅读总结。
- en: In figure 12.2, the chat collected five pieces of information, but the human
    agent only needs to know three. Figure 12.3 breaks down the summary.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在图12.2中，聊天收集了五条信息，但人工代理只需要知道三条。图12.3分解了总结。
- en: '![figure](../Images/CH12_F03_Freed2.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH12_F03_Freed2.png)'
- en: Figure 12.3 Not every closed-form question needs to be stored in the summary.
    In this medical insurance claim review, the most important information is the
    provider ID, member ID, and claim ID.
  id: totrans-36
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.3 并非每个封闭形式的问题都需要存储在总结中。在这个医疗保险索赔审查中，最重要的信息是提供者ID、会员ID和索赔ID。
- en: 'In this medical insurance claim search, it takes a lot of information to validate
    the caller. We need to verify who is calling, who they are calling about, and
    what they are calling about. It takes three data elements alone to confirm the
    member information: an ID, a date, and a confirmation of the name. The human agent
    receiving the transfer only needs to know that the member was verified, and the
    member ID suffices for that.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个医疗保险索赔搜索中，需要大量信息来验证来电者。我们需要核实来电者是谁，他们打电话的原因，以及他们打电话的内容。仅通过三个数据元素就能确认会员信息：一个ID、一个日期和姓名的确认。接收转接的人工代理只需要知道会员已被验证，会员ID就足够了。
- en: Similarly, there are many pieces of information about the claim—some given by
    the user (date of service) and some by the AI (status, paid date, paid amount).
    The summary only includes the claim ID, which will be sufficient for the agent
    to retrieve the full claim, including all the details that were not part of the
    conversation.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，关于索赔的信息有很多——一些由用户（服务日期）提供，一些由AI（状态、支付日期、支付金额）提供。摘要只包括索赔ID，这对于代理检索完整的索赔，包括所有不属于对话的细节，将足够。
- en: It’s useful to include summary elements in software used by human agents fielding
    conversations. In contact center software, this is called a *screen pop*—a feature
    that displays contextual information to an agent while they handle a conversation.
    Figure 12.4 shows an example screen pop for our medical insurance agent. They
    receive the structured information as a highlight, and through backend integration,
    they can get even more information. Clicking on the member ID should show information
    about the member or an image of their ID card. Clicking on the claim should show
    the claim itself (for instance, as a PDF).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在由人类代理处理对话的软件中包含摘要元素是有用的。在接触中心软件中，这被称为*屏幕弹出*——一个在代理处理对话时显示上下文信息的功能。图12.4展示了我们医疗保险代理的一个示例屏幕弹出。他们以高亮的形式接收结构化信息，并通过后端集成，他们可以获得更多信息。点击会员ID应显示关于会员的信息或其身份证照片。点击索赔应显示索赔本身（例如，作为PDF文件）。
- en: '![figure](../Images/CH12_F04_Freed2.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH12_F04_Freed2.png)'
- en: Figure 12.4 When a summary is integrated with contact center software, the human
    agent can have a wealth of information at their fingertips. When an insurance
    agent clicks on the member ID in their software, they could get additional details
    on that member.
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.4 当摘要与接触中心软件集成时，人类代理可以触手可及地拥有大量信息。当保险代理在其软件中点击会员ID时，他们可以获得关于该会员的额外详细信息。
- en: Structured metadata gives key data points from the conversation so far. It prevents
    the human agent from having to re-ask questions that the user has already answered
    for the bot. Users get *very* frustrated when they must answer the same questions
    again! The human agent benefits from having this information at their fingertips,
    but they still need to be aware of the overall context of the conversation. That’s
    where the free-text summary comes in.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化元数据提供了到目前为止对话中的关键数据点。它防止人类代理不得不重新询问用户已经为机器人回答过的问题。当用户必须再次回答相同的问题时，他们会感到非常沮丧！人类代理从能够触手可及的信息中受益，但他们仍然需要意识到对话的整体背景。这就是自由文本摘要的作用所在。
- en: Free-text summary elements
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自由文本摘要元素
- en: A conversation may have included hundreds of words before it was transferred
    to a human agent. (The example transcript we are using is about 100 words.) The
    average adult reads at 200 words per minute when reading for fun and slower for
    complex material. Our user doesn’t want to wait any longer than necessary, so
    our human agent needs to get up to speed quickly. A good summary can reduce that
    time by minutes.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一个对话在转交给人类代理之前可能包含数百个单词。（我们使用的示例记录大约有100个单词。）当成年人为了娱乐阅读时，平均每分钟阅读200个单词，对于复杂材料则更慢。我们的用户不想等待比必要的更长的时间，因此我们的人类代理需要快速熟悉情况。一个好的摘要可以减少几分钟的时间。
- en: Follow the “keep it simple” philosophy. A summary of one to two sentences conveys
    a lot of information quickly. The free-text summary in our example—“User searched
    for their claim and found it was paid three months after filing”—encapsulates
    the entire search process in the first five words as well as a likely reason for
    transfer in the last eight words.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循“简单至上”的哲学。一至两句话的摘要可以快速传达大量信息。我们示例中的自由文本摘要——“用户搜索他们的索赔并发现它在提交后三个月支付”——在前五个词中封装了整个搜索过程，以及在最后八个词中提供了一个可能的转接原因。
- en: 'The free-text summary is also not repetitive. It eliminates several redundant
    pieces of information:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 自由文本摘要也不重复。它消除了几条冗余信息：
- en: '*The user’s initial intent*—This is not explicitly included, since it is inferred
    from a claim search being done.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用户的初始意图*——这并没有明确包含，因为它可以从进行的索赔搜索中推断出来。'
- en: '*The intermediate questions*—It does not say “The bot asked for the tax ID,
    member ID, date of birth, etc.” These are all implied from the user finding the
    claim. The system does not find claims until sufficient information is provided.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*中间问题*——它没有说“机器人要求提供税务ID、会员ID、出生日期等。”这些都是在用户找到索赔时隐含的。系统不会找到索赔，直到提供足够的信息。'
- en: '*The structured content*—The summary doesn’t need to waste words repeating
    the structured content, which has already been provided in compact form.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*结构化内容*——摘要不需要浪费文字重复已经以紧凑形式提供过的结构化内容。'
- en: The summary also does not identify who initiated the transfer (the user or the
    system). This could be added in a new structured field.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要也没有识别出谁启动了传输（用户或系统）。这可以在新的结构化字段中添加。
- en: There are trade-offs in the summarization process. Too brief a summary will
    omit information that helps the agent. Too lengthy a summary will not help the
    agent learn quickly, compared to reading the original transcript. Choose a summarization
    methodology that works best for your use case.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在摘要过程中存在权衡。过于简短的摘要会省略帮助代理的信息。过于冗长的摘要与阅读原始记录相比，不会帮助代理快速学习。选择最适合你用例的摘要方法。
- en: Later in this chapter, we will show you how to use generative AI to generate
    summaries. First, though, we need the conversational AI to structure data in the
    right format to generate summaries.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后面部分，我们将向您展示如何使用生成式人工智能来生成摘要。不过，首先我们需要对话式人工智能以正确的格式结构化数据以生成摘要。
- en: Exercises
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: 'Design your ideal summaries for the following sample conversation. You will
    refine these summaries later in the chapter with additional techniques:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 设计你理想的以下样本对话摘要。你将在本章的后面部分使用额外的技术来完善这些摘要：
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Design a purely textual summary of the sample conversation.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设计一个纯文本摘要的样本对话。
- en: Design a structured summary of the data elements. Would you extract different
    structured elements if the caller asked for the details of the member’s health
    plan or tried to proactively estimate the cost of a procedure?
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设计数据元素的结构化摘要。如果呼叫者要求成员的健康计划详情或尝试主动估计程序的成本，你会提取不同的结构化元素吗？
- en: Take a conversation transcript from a chatbot you are working on. Summarize
    the conversation in both text and structured elements.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从你正在工作的聊天机器人中提取一个对话记录。以文本和结构化元素的形式总结对话。
- en: 12.2 Preparing your chatbot for summarization
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 准备你的聊天机器人进行摘要
- en: We’ve taken it as a given that your chatbot keeps track of the conversational
    transcript. Most platforms do, but not all. The transcript is the bare minimum
    element you need to build a summary. In this section, we’ll show you multiple
    ways to collect the data necessary for both textual and structured summaries of
    conversations.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设你的聊天机器人会跟踪对话记录。大多数平台都会这样做，但并非所有平台都会。记录是构建摘要所需的最基本元素。在本节中，我们将向您展示多种收集数据的方法，这些数据对于对话的文本和结构化摘要都是必要的。
- en: 12.2.1 Using out-of-the-box elements
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.1 使用现成的元素
- en: Conversational AI platforms often include built-in elements to help with conversational
    summarization. The most common element is a conversational transcript—a running
    log of messages between the user and the assistant. This is accessible in different
    ways on different platforms. One common mechanism is called a *session variable*.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对话式人工智能平台通常包含内置元素以帮助进行对话摘要。最常见的一个元素是对话记录——用户和助手之间消息的运行日志。在不同的平台上，可以通过不同的方式访问它。一个常见的机制被称为*会话变量*。
- en: Figure 12.5 shows how the transcript can be accessed in our platform (watsonx)
    via a built-in session variable called “session history.”
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5展示了如何在我们的平台（watsonx）中通过一个名为“会话历史”的内置会话变量访问记录。
- en: '![figure](../Images/CH12_F05_Freed2.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH12_F05_Freed2.png)'
- en: Figure 12.5 Accessing the conversation transcript through the "session history"
    variable
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.5 通过“会话历史”变量访问对话记录
- en: Depending on your chat platform, the conversational transcript will be stored
    in different formats. Our platform provides the summary in a JSON format, as shown
    in the following listing.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的聊天平台，对话记录将以不同的格式存储。我们的平台以JSON格式提供摘要，如下所示。
- en: Note  In many conversational AI platforms, the transcript is not available to
    the dialogue session as a variable unless you craft it yourself via webhooks.
    We’ll demonstrate how to build a variable with the transcript later in the chapter.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在许多对话式人工智能平台中，除非你通过webhooks自己构建，否则对话记录不会作为变量提供给对话会话。我们将在本章后面部分演示如何构建包含记录的变量。
- en: Listing 12.2 Conversational transcript via the built-in “session history” variable
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.2 通过内置的“会话历史”变量访问对话记录
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The JSON format is intended for machines to read, but you can run the transcript
    through a transform process. We made the figures in this chapter more human-readable
    by replacing the `"a"` keys with `"Bot"`, the `"u"` keys with `"User"`, and the
    `\n` (newlines) with spaces.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: The transcript also includes some metadata that you may choose to ignore, such
    as the “yes” and “no” choices being offered via buttons. Other conversational
    AI platforms may include further metadata like timestamps.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Later in this chapter (in section 12.3), we will demonstrate running this transcript
    format through an LLM for summarization. We will see that LLMs are quite resilient
    to the transcript format. You can summarize transcripts in their native format
    or reformat them so they are easier for humans to read.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: 12.2.2 Instrumenting your chatbot for transcripts
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some conversational AI platforms require you to create and store the conversation
    transcript yourself. Or you may choose to create your own version of the transcript
    in the exact format you prefer. Either way, this is implemented in your *orchestration
    layer*, as shown in figure 12.6\. The orchestration layer is responsible for calling
    external systems via APIs. The specific terminology will vary based on your conversational
    AI platform, but this is often called a *webhook*.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH12_F06_Freed2.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
- en: Figure 12.6 You can use your chatbot’s orchestration layer to create a conversational
    transcript in whatever format you need.
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A webhook is a type of API. Webhooks are generally available before the bot
    processes the user’s response (a “pre”-webhook), after processing the user’s response
    (a “post”-webhook), or at other predefined events. Webhooks can access conversational
    context either natively or as input parameters. The next listing demonstrates
    pseudocode for constructing a transcript. (Consult your conversational AI platform
    documentation for the correct terminology and format.)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Listing 12.3 Pseudocode for a webhook that updates a transcript
  id: totrans-78
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#1 The user’s message is usually found in the request object.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The bot’s message is usually found in the response object.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '#3 The user’s message may not exist every time. For example, most conversations
    start with a bot greeting.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '#4 The transcript should be stored in a context variable (session variable).
    All user and bot messages are appended to the transcript.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Listing 12.3 demonstrates a post-webhook, since it has access to the request
    and the response. Every time the bot responds to the user, the webhook updates
    the transcript. This transcript includes the minimum possible elements—just the
    user and bot messages—and a very simple one-message-per-line format, readable
    by humans. You can create your transcript in whatever format you wish, such as
    a single string, string array, JSON object, or custom object.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown earlier, a simple transcript is easiest to read. Conversational AI
    platforms generally have many data elements available per message that you can
    optionally use in your transcripts:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，简单的转录最容易阅读。对话式AI平台通常每条消息都有许多可选项的数据元素，您可以在转录中使用：
- en: '*Message timestamp*—You can use a timestamp to show the absolute time a message
    was received or sent (“11:25:53 AM”) or the relative time since the beginning
    of the chat (“00:01:15” for a message 1 minute and 15 seconds after the beginning).'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*消息时间戳*—您可以使用时间戳来显示消息接收或发送的绝对时间（例如，“上午11:25:53”）或自聊天开始以来的相对时间（例如，消息开始后1分15秒的“00:01:15”）。'
- en: '*Buttons*—You can indicate when the bot offered options via buttons and when
    the user clicked on a button. This is especially interesting in voice solutions,
    where users may enter dual tone multi-frequency (DTMF, or “touch tone”) input
    through their keypad. For example, you’ll know that the user pressed “0” rather
    than saying “zero.”'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*按钮*—您可以通过按钮指示机器人提供了哪些选项，以及用户何时点击了按钮。这在语音解决方案中尤其有趣，因为用户可能通过他们的键盘输入双音多频（DTMF，或“触摸音”）输入。例如，您会知道用户按下了“0”而不是说出“零”。'
- en: '*Original or post-processed input*—Many conversational AI platforms normalize
    certain input types like dates and numbers. You can use the original utterance,
    like “February first two thousand twenty-four” or a post-processed version like
    “02/01/2024”.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*原始或后处理输入*—许多对话式AI平台会规范化某些输入类型，如日期和数字。您可以使用原始话语，如“二零二四年二月第一”，或后处理版本如“02/01/2024”。'
- en: '*Rich-text and non-text elements*—Your bot may respond with HTML markup or
    even images and links that may not be suitable for a transcript.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*富文本和非文本元素*—您的机器人可能会以HTML标记或甚至图像和链接的形式响应，这些可能不适合转录。'
- en: 'The pseudocode in listing 12.3 demonstrated how to update a context variable
    that tracked conversational context, but it did not demonstrate how to initialize
    that variable. The simplest option is to initialize an empty string like the following:
    `response.context.transcript = ''''`.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.3中的伪代码演示了如何更新跟踪对话上下文的上下文变量，但没有演示如何初始化该变量。最简单的方法是将变量初始化为空字符串，如下所示：`response.context.transcript
    = ''`。
- en: 'Several other data elements related to a conversation are available, and you
    may wish to include them at the beginning of your transcript:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 与对话相关的其他几个数据元素可供使用，您可能希望在转录的开头包括它们：
- en: '*Session timestamp*—When the conversation started.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*会话时间戳*—对话开始的时间。'
- en: '*Session duration*—How long the conversation lasted.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*会话时长*—对话持续了多长时间。'
- en: '*User identifier*—This could include information about a logged-in user accessing
    the chat, such as name, email, or user ID. For a phone solution, this could be
    the caller’s phone number.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用户标识符*—这可能包括有关登录用户访问聊天室的信息，例如姓名、电子邮件或用户ID。对于电话解决方案，这可能是指叫方的电话号码。'
- en: '*Device and channel identifier*—How the user accessed your conversational AI,
    such as device type (e.g., mobile or desktop) or which channel they used (e.g.,
    chat widget, SMS, Facebook Messenger, etc.).'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设备和渠道标识符*—用户如何访问您的对话式AI，例如设备类型（例如，移动或桌面）或他们使用的渠道（例如，聊天小部件、短信、Facebook Messenger等）。'
- en: '*Transfer reason*—Why the bot transferred the caller to an agent, such as “immediate
    opt-out,” “opt-out,” or “bot didn’t understand user.”'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*转移原因*—机器人将呼叫者转接到代理的原因，例如“立即退订”、“退订”或“机器人不理解用户”。'
- en: You may instead choose to leave these elements for the structured section of
    the summary (as key-value pairs), rather than including them in a prose summary,
    since they apply to the entire conversation.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择将这些元素留给总结的结构化部分（作为键值对），而不是将它们包含在散文总结中，因为它们适用于整个对话。
- en: All these data elements and more are typically available in your conversational
    AI platform. They are often included in the AI’s system logs, which are another
    data source for building transcripts. These optional data elements are provided
    by conversational AI platforms because they are generic and are applicable to
    any conversation as metadata. They are a great start to any conversational transcript.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些数据元素以及更多通常都可在您的对话式AI平台中找到。它们通常包含在AI的系统日志中，这是构建转录的另一个数据源。这些可选数据元素由对话式AI平台提供，因为它们是通用的，适用于任何对话作为元数据。它们是任何对话转录的绝佳起点。
- en: We saw earlier in the chapter that a good summary includes more than an unstructured
    transcript. Structured metadata is quite useful in summarizing the important parts
    of a conversation. Some parts of this metadata are not generic—they are specific
    for your exact implementation. In our medical insurance example, member IDs and
    claim IDs were unique.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面，我们了解到一个好的摘要不仅仅是一个非结构化的记录。结构化元数据在总结对话的重要部分时非常有用。这些元数据的一些部分不是通用的——它们针对您特定的实现是特定的。在我们的医疗保险示例中，会员ID和索赔ID是唯一的。
- en: The conversational AI platform doesn’t give any special meaning to member IDs—they
    are recorded as just another user message. If you want to use specific contextual
    elements from your implementation in a summary, you’ll have to instrument the
    AI yourself to store them so that they can be included in a summary. Let’s see
    how.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对话式AI平台不会给会员ID赋予任何特殊含义——它们被记录为另一条用户消息。如果您想在摘要中使用实施中的特定上下文元素，您将不得不自己配置AI来存储它们，以便它们可以被包含在摘要中。让我们看看如何操作。
- en: 12.2.3 Instrumenting your chatbot (for data points)
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.3 配置您的聊天机器人（对于数据点）
- en: Conversational AI platforms generally let you store arbitrary values in variables,
    often called *context variables* or *session variables*. You should make use of
    these for any data you collect during the conversation that has significant meaning,
    especially if it helps you find more information later.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对话式AI平台通常允许您在变量中存储任意值，这些变量通常被称为*上下文变量*或*会话变量*。您应该利用这些变量来收集对话中的任何具有重大意义的数据，尤其是如果它有助于您稍后找到更多信息。
- en: 'The data you store will vary based on your specific application. Here are a
    few examples by domain:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 您存储的数据将根据您的特定应用程序而变化。以下是一些按领域划分的示例：
- en: '*Medical insurance*—Member ID, provider ID, claim ID'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*医疗保险*—会员ID，提供者ID，索赔ID'
- en: '*Retail*—Order number, product ID, retail location'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*零售*—订单号，产品ID，零售地点'
- en: '*Banking*—Account ID, account type'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*银行*—账户ID，账户类型'
- en: Any time the bot asks a question with a fixed-format response, like “what’s
    your claim ID,” that response is a good candidate for instrumentation.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 任何时候机器人用固定格式的响应提出问题，比如“你的索赔ID是什么”，这个响应都是进行配置的合适候选。
- en: Be careful with sensitive data
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 小心敏感数据
- en: Many types of data need to be treated carefully. There are rules and regulations
    on how to handle data that could identify a person (PI) or other sensitive data
    points. Your conversational AI may already deal with them, but adding them to
    summaries or logs may need to be reviewed with your legal team. Be minimalist
    in what you collect, what you store, and how long you store it, and confirm your
    choices with your lawyers.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 许多类型的数据需要谨慎处理。有关如何处理可能识别个人（PI）或其他敏感数据点的数据，有规则和法规。您的对话式AI可能已经处理了它们，但将它们添加到摘要或日志中可能需要与您的法律团队进行审查。在收集、存储以及存储时间上要尽量简约，并请您的律师确认您的选择。
- en: The way you store context will depend on your conversational AI platform. You
    may be able to do this in a user interface, or your platform may require you to
    write code. Figure 12.7 shows the low-code method used in our platform to store
    context variables.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 您存储上下文的方式将取决于您的对话式AI平台。您可能能够在用户界面中这样做，或者您的平台可能要求您编写代码。图12.7显示了我们在平台中用于存储上下文变量的低代码方法。
- en: You can access your stored context variables later in the conversation, including
    accessing them to create a structured summary. The following listing shows pseudocode
    for accessing these context variables and storing them in a structured object.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在对话中稍后访问存储的上下文变量，包括访问它们以创建结构化摘要。以下列表显示了访问这些上下文变量并将它们存储在结构化对象中的伪代码。
- en: Listing 12.4 Pseudocode for a webhook that creates a structured summary
  id: totrans-112
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.4 创建结构化摘要的webhook的伪代码
- en: '[PRE4]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#1 This method called as the conversation is transferred to an agent.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 当对话转移到代理时，调用此方法。'
- en: '#2 You can define a custom object to hold your summary.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 您可以定义一个自定义对象来保存您的摘要。'
- en: '#3 Set any values required for your custom summary.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 设置您自定义摘要所需的任何值。'
- en: '![figure](../Images/CH12_F07_Freed2.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH12_F07_Freed2.png)'
- en: Figure 12.7 Storing contextually important information into a context variable
    so that it can be retrieved later by a summary
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.7 将上下文重要信息存储到上下文变量中，以便稍后通过摘要检索
- en: You can also use these variables directly in your assistant to create an unstructured
    summary. Figure 12.8 shows the low-code method used in our platform to combine
    several variables into a larger summary string.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以直接在你的助手中使用这些变量来创建一个非结构化的摘要。图12.8展示了我们平台中用于将多个变量组合成更大的摘要字符串的低代码方法。
- en: '![figure](../Images/CH12_F08_Freed2.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH12_F08_Freed2.png)'
- en: Figure 12.8 Using a low-code expression editor to combine multiple data elements
    into a summary
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图12.8 使用低代码表达式编辑器将多个数据元素组合成摘要
- en: This section demonstrated multiple ways to collect the data necessary for summarization.
    Conversational AI platforms collect a lot of data that you can use in summaries.
    You can instrument your AI assistants to collect the additional data you need,
    and you can control the formatting of that data. The data you collect is useful
    for many purposes, including efficient handoffs to human agents.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本节展示了多种收集摘要所需数据的途径。对话式AI平台收集了大量的数据，这些数据可以用于摘要。你可以对你的AI助手进行配置，以收集你需要额外数据，并且你可以控制这些数据的格式。你收集的数据对于许多用途都很有用，包括高效地将任务转交给人工客服。
- en: Exercises
  id: totrans-123
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: Revisit the summaries you created in the section 12.1 exercises. Would you now
    change any of the data elements included in those summaries?
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回顾你在12.1节练习中创建的摘要。你现在会改变那些摘要中包含的数据元素吗？
- en: 12.3 Improving summaries with generative AI
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 使用生成式AI改进摘要
- en: What if you don’t want to modify your conversational AI at all? Can you still
    collect all the data you need for a great summary and format it the way you need?
    Can generative AI do more work so you have less work? Yes! Let’s look at how.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你根本不想修改你的对话AI，你还能收集到制作优秀摘要所需的所有数据，并以你需要的格式进行整理吗？生成式AI能做更多的工作，让你有更少的工作要做吗？是的！让我们看看如何做到这一点。
- en: 'You have two key prerequisites. First, you need a conversational transcript
    in some form: a built-in transcript from your conversational AI platform, one
    you created yourself, or an extract from your platform’s conversational logs.
    Second, you need to know what a good summary looks like for your use case. Armed
    with those two prerequisites, you can work with an LLM to get the summary you
    need.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 你有两个关键的前提条件。首先，你需要某种形式的对话记录：来自你的对话AI平台的内置记录，你自己创建的记录，或者从你的平台对话日志中提取的记录。其次，你需要知道对于你的用例来说一个好的摘要是什么样的。有了这两个前提条件，你就可以与一个LLM合作，以获取你需要的摘要。
- en: In this section, we will use the granite-13b-chat-v2 model with greedy decoding.
    This model is good at the summarization and extraction techniques we require.
    We’ll use greedy decoding so that the model will not be creative and the outputs
    will be repeatable. (We want to generate the same summary and extract the same
    details for a given conversation.)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用granite-13b-chat-v2模型并采用贪婪解码。这个模型擅长我们需要的摘要和提取技术。我们将使用贪婪解码，这样模型就不会有创造性，输出将是可重复的。（我们希望对于给定的对话生成相同的摘要和提取相同的细节。）
- en: 12.3.1 Generating a text summary of a transcript with summarizing prompts
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.1 使用摘要提示生成转录本的文本摘要
- en: We’ll start our exercise with a simple summarization prompt, shown in the following
    listing. We’ll pass the model the JSON version of our chat transcript.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个简单的摘要提示开始我们的练习，如下所示。我们将传递给模型我们聊天记录的JSON版本。
- en: Listing 12.5 Generating a summary of a JSON chat transcript
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.5 生成JSON聊天记录的摘要
- en: '[PRE5]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 Task description and hint for interpreting the JSON object'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 任务描述和解析JSON对象提示'
- en: '#2 Instruction to limit the summary size'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 指令以限制摘要大小'
- en: '#3 JSON version of the chat transcript'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 聊天记录的JSON版本'
- en: '#4 Cue'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 提示'
- en: '#5 Model output'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 模型输出'
- en: The generated summary is the verbatim last utterance from the AI. This may seem
    strange at first, but this is a pretty good summary of the conversation. The bot’s
    last utterance is rich in details that encompass the most important elements of
    the conversation.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的摘要是从AI那里直接摘录的最后一句原话。一开始这可能看起来有些奇怪，但这确实是对话的一个相当好的总结。机器人的最后一句发言包含了很多细节，涵盖了对话中最重要的一部分。
- en: By using sampling decoding and a creative temperature setting, we could have
    gotten a differently structured summary, at the risk of introducing hallucinations.
    We can also change the transcript format and see if that helps the LLM. The next
    listing shows a prompt that summarizes the same conversation with a different
    input format—unstructured text instead of JSON.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用采样解码和创造性的温度设置，我们可能会得到一个不同结构的摘要，但风险是引入幻觉。我们还可以更改转录格式，看看是否有助于LLM。下一条目显示了一个以不同输入格式（非结构化文本而非JSON）总结相同对话的提示。
- en: Listing 12.6 Generating a summary of a text chat transcript
  id: totrans-140
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.6 生成文本聊天转录摘要
- en: '[PRE6]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 Task description with no additional hints'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 无额外提示的任务描述'
- en: '#2 Same instruction to limit the summary size'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 相同的指令以限制摘要大小'
- en: '#3 Text version of chat transcript'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 聊天转录的文本版本'
- en: '#4 Same cue'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 相同的提示'
- en: '#5 Model output'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 模型输出'
- en: This generated summary contains the same informational content as the summary
    generated from JSON. It’s still based on the bot’s last message, but this time,
    it’s paraphrased into prose. The summary also includes a third sentence—in contrast
    with the prompt’s instructions—that attempts to make sense of the user’s last
    utterance.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这个生成的摘要包含与从JSON生成的摘要相同的信息内容。它仍然基于机器人的最后一条消息，但这次，它被改写成了散文。摘要还包括一个第三句话——与提示的指令相反——试图理解用户的最后一句发言。
- en: Note  For the remainder of this chapter, we will omit the conversational transcript
    from the book to keep the listings smaller. We will use the human-readable version
    of the conversation transcript. The full listings are available in the book’s
    GitHub repository at [https://github.com/andrewrfreed/EffectiveConversationalAI](https://github.com/andrewrfreed/EffectiveConversationalAI).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在本章剩余部分，我们将省略书籍中的对话转录内容以保持列表较小。我们将使用可读性更好的对话转录版本。完整的列表可在书籍的GitHub仓库中找到，网址为[https://github.com/andrewrfreed/EffectiveConversationalAI](https://github.com/andrewrfreed/EffectiveConversationalAI)。
- en: 'Remember our advice earlier in this section: you need to know what a good summary
    looks like. The summaries generated by the LLM have been okay so far, but perhaps
    we can do better. One method is to provide better instructions to the model, as
    shown in the following listing. Because we are emphasizing instructions, we’ll
    switch to a more instructible model, in this case granite-13b-instruct-v2\. The
    model is asked to emphasize the dialogue immediately preceding the escalation.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 记住本节前面给出的建议：你需要知道一个好的摘要是什么样的。到目前为止，LLM生成的摘要还不错，但也许我们可以做得更好。一种方法是向模型提供更好的指令，如下一条目所示。因为我们强调指令，我们将切换到一个更具可指导性的模型，在这种情况下是
    granite-13b-instruct-v2。模型被要求强调升级前的对话。
- en: Listing 12.7 Enhancing the summarization instructions to the LLM
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.7 增强对LLM的摘要指令
- en: '[PRE7]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Original task description'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 原始任务描述'
- en: '#2 Original instruction to limit the summary size'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 原始指令以限制摘要大小'
- en: '#3 Enhanced instruction on what to emphasize'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 加强强调内容的指导'
- en: '#4 Text version of chat transcript'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 聊天转录的文本版本'
- en: '#5 Same cue'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 相同的提示'
- en: '#6 Model output'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 模型输出'
- en: The model follows the instruction. The last message from the bot tells the user
    their claim was paid (“The claim was paid on May 23, 2024 for $201.83”), and the
    user then opts out. The LLM summary succinctly says, “they want to know why their
    claim is denied.” This summary is short but perhaps too speculative, seeing that
    the claim was paid and not actually denied. Maybe the user felt they should have
    been paid more, or maybe they needed an itemized list. The text summary also omits
    the near-verbatim playback of the transcript seen in listing 12.6, leaving that
    information for a separate structured summary. We’re closer to what our human
    agent needs. Let’s improve the prompt to reduce the LLM’s speculation.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 模型遵循指令。机器人的最后一条消息告诉用户他们的索赔已被支付（“索赔已于2024年5月23日支付201.83美元”），然后用户选择退出。LLM的摘要简洁地说：“他们想知道为什么他们的索赔被拒绝。”这个摘要很短，但可能过于推测，因为索赔已被支付，实际上并没有被拒绝。也许用户觉得他们应该得到更多的支付，或者也许他们需要一个详细的清单。文本摘要还省略了列表12.6中看到的转录内容的近字面回放，将那些信息留给单独的结构化摘要。我们更接近于人类代理所需的内容。让我们改进提示以减少LLM的推测。
- en: A useful method is to invoke the LLM with a one-shot prompt (with one example)
    or a few-shot prompt (with multiple examples). Creating the one-shot example forces
    us to think about what a good summary looks like for a given conversation. Using
    one or more examples is often the fastest way to improve a prompt.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有用的方法是使用单次提示（带有一个示例）或少量提示（带有多个示例）来调用LLM。创建单次示例迫使我们思考给定对话的良好总结是什么样的。使用一个或多个示例通常是改进提示最快的方式。
- en: The following listing shows a one-shot example that also uses the granite-13b-instruct-v2
    model.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表展示了一个使用granite-13b-instruct-v2模型的单次示例。
- en: Listing 12.8 A one-shot summarization prompt
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.8 一个单次总结提示
- en: '[PRE8]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#1 Original task description with updated delineation via “&lt;|instruction|&gt;”'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 通过“&lt;|instruction|&gt;”更新划分的任务描述'
- en: '#2 One-shot example of conversation transcript with summary'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 带有总结的对话记录单次示例'
- en: '#3 Text version of chat transcript'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 聊天记录的文本版本'
- en: '#4 Restructured cue'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 重新结构化的提示'
- en: '#5 Model output'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 模型输出'
- en: This generated summary is also quite reasonable when combined with the structured
    metadata. There is some speculation—“they want more information”—but again it
    seems like the user would need more information if they wanted an agent after
    finding the claim is supposedly paid. The summary is also structured after the
    example, with a token-for-token match in the first six words of the summary.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当与结构化元数据结合时，此生成的总结也非常合理。有一些推测——“他们想要更多信息”——但再次看来，如果用户在发现声明似乎是付费的之后想要一个代理，他们可能需要更多信息。总结在示例之后也是结构化的，总结的前六个词与示例的词对词匹配。
- en: Note that in the one-shot summarization example (listing 12.8), we used a slightly
    different format. Instead of using delineation via `Transcript:`, we used specially
    formatted tokens like `<|transcript|>`. Without these special tokens, we were
    unable to generate good summaries. Likely the model had trouble separating the
    prompt sections and the conversation elements because both used colons. Future
    large language models (LLMs) may be more resilient to delineation characters appearing
    multiple places in the prompt. This kind of small change can have a huge effect
    on LLM performance.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在单次总结示例（列表12.8）中，我们使用了稍微不同的格式。我们不是使用“Transcript:”的划分，而是使用了特殊格式的标记，如`<|transcript|>`。没有这些特殊标记，我们无法生成好的总结。可能模型在区分提示部分和对话元素时遇到了困难，因为两者都使用了冒号。未来的大型语言模型（LLM）可能对提示中多次出现划分字符更具弹性。这种小的变化可以对LLM性能产生巨大影响。
- en: 'Either emphasizing instructions or examples in your prompts can work. Consider
    the following tradeoffs:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的提示中强调指令或示例都是可行的。考虑以下权衡：
- en: '*Control of the output*—Most LLMs are trained on summarization by default.
    Many are responsive to instructions and generate good summaries. One-shot and
    few-shot prompts further constrain the output to use the language you desire,
    though you may have to provide several examples.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*输出控制*——大多数LLM默认训练于总结。许多对指令有反应并生成好的总结。单次和少量提示进一步限制了输出以使用你想要的语言，尽管你可能需要提供几个示例。'
- en: '*Cost*—Adding examples increases the inference cost due to there being more
    input tokens.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*成本*——添加示例会增加推理成本，因为输入的标记更多。'
- en: The text summaries we have generated so far include an overview of the conversation
    but mostly do not include the structured metadata that will be helpful for the
    agent. Earlier in the chapter, we demonstrated instrumenting your chatbot using
    a variety of code and low-code methods to gather structured metadata that could
    be passed to the agent. What if we don’t want to instrument our chatbot—could
    an LLM extract the structured metadata?
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止生成的文本总结包括对话概述，但大部分不包括对代理有帮助的结构化元数据。在章节的早期，我们展示了使用各种代码和低代码方法来配置你的聊天机器人，以收集可以传递给代理的结构化元数据。如果我们不想配置我们的聊天机器人——LLM能否提取结构化元数据？
- en: 12.3.2 Generating a structured summary of a transcript with extractive prompts
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.2 使用提取提示生成对话记录的结构化总结
- en: We can use LLMs to extract structured data from conversation transcripts—extraction
    is another task that many LLMs are trained on.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用大型语言模型（LLM）从对话记录中提取结构化数据——提取是许多LLM训练的另一项任务。
- en: 'Our first task is to decide what the structured output needs to look like.
    There are many possibilities, but one useful format is JSON. This is useful for
    two reasons: JSON is easy for downstream applications to consume, and many LLMs
    are good at generating JSON.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一项任务是决定结构化输出需要看起来像什么。有许多可能性，但一个有用的格式是JSON。这有两个原因：JSON易于下游应用程序消费，许多LLM擅长生成JSON。
- en: We will again use an instructible model. This time we will use mistral-7b-instruct-
    v0-2 because it can generate JSON from instructions alone. The following listing
    shows a prompt that generates structured JSON output from the conversation.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将再次使用可指导的模型。这次我们将使用mistral-7b-instruct-v0-2，因为它可以仅从指令中生成JSON。以下列表显示了一个提示，该提示从对话中生成了结构化的JSON输出。
- en: Listing 12.9 An extractive summary without examples
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.9 没有示例的提取摘要
- en: '[PRE9]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#1 Updated task description with simple instruction about JSON format'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 更新后的任务描述，包含关于JSON格式的简单说明'
- en: '#2 Text version of chat transcript'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 聊天记录的文本版本'
- en: '#3 Updated cue to generate JSON'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 更新后的提示以生成JSON'
- en: '#4 Model output'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 模型输出'
- en: This is an excellent first attempt. The model generated JSON and extracted all
    the structured data points collected. But it collected more data than we asked
    for—we wanted only the IDs—and it duplicated one of the data points (the tax ID
    is the provider’s ID).
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个出色的第一次尝试。模型生成了JSON并提取了收集到的所有结构化数据点。但它收集了比我们要求更多的数据——我们只想得到ID——并且重复了一个数据点（税务ID是提供者的ID）。
- en: Note  Many models can generate JSON after seeing a few examples. All the models
    we tested extracted several data points rather than the three expected. The mistral
    model was one of the few to generate valid JSON with no examples in the prompt.
    We expect models to continue improving at generating JSON data. Alternatively,
    you can provide an example schema in your instruction.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：许多模型在看到几个示例后可以生成JSON。我们测试的所有模型都提取了几个数据点，而不是预期的三个。mistral模型是少数几个在提示中没有示例就能生成有效JSON的模型之一。我们预计模型将继续在生成JSON数据方面取得进步。或者，您可以在指令中提供一个示例模式。
- en: Let’s augment this prompt with an example (shown in bold).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用示例（以粗体显示）来增强这个提示。
- en: Listing 12.10 An extractive summary with one example
  id: totrans-187
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.10 带有一个示例的提取摘要
- en: '[PRE10]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '****#1 Same task description'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '****#1 相同的任务描述'
- en: '#2 One-shot example'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 一次性示例'
- en: '#3 Text version of chat transcript'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 聊天记录的文本版本'
- en: '#4 Same cue'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 相同的提示'
- en: '#5 Model output****  ****With one example, we were able to show the model that
    we didn’t need every piece of data in the output. We also got the model to stop
    duplicating the provider’s tax ID. Last, the JSON response is now minifying to
    a single line without line breaks. The extracted data is still accurate, but we
    may require exact key names. If the agent’s application expects to read a field
    called `ClaimID`, then it is not acceptable for the summary to reference `ClaimNumber`.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 模型输出****  ****通过一个例子，我们向模型展示了我们不需要输出中的每一份数据。我们还让模型停止重复提供者的税务识别号。最后，JSON响应现在已压缩成单行，没有换行符。提取的数据仍然准确，但我们可能需要确切的键名。如果代理的应用程序期望读取名为`ClaimID`的字段，那么摘要引用`ClaimNumber`是不可接受的。'
- en: We give the model a more detailed example (shown in bold) in the following listing.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在以下列表中给出了一个更详细的示例（以粗体显示）。
- en: Listing 12.11 Updated one-shot example for extractive summary
  id: totrans-195
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表12.11 更新后的提取摘要的一次性示例
- en: '[PRE11]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '******#1 Same task description'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '******#1 相同的任务描述'
- en: '#2 Updated one-shot example'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 更新后的一次性示例'
- en: '#3 Text version of the chat transcript'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 聊天记录的文本版本'
- en: '#4 Same cue'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 相同的提示'
- en: '#5 Model output******  ******This worked well. We only get the keys we desired.
    It’s slightly frustrating that the one-shot example needed to be so close to the
    second transcript. This implies that to summarize other conversational flows,
    we may need to provide examples for each one. (What if the conversation includes
    authorization IDs, electronic payment IDs, or other IDs?) And there’s one other
    gotcha: the `TaxID` and `MemberID` were numeric values, but it produced a string
    value for `ClaimID`—even after seeing the example.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 模型输出******  ******这效果很好。我们只得到了我们想要的键。令人稍微有些沮丧的是，一次性示例需要与第二个记录如此接近。这暗示了要总结其他对话流程，我们可能需要为每个流程提供示例。（如果对话包括授权ID、电子支付ID或其他ID怎么办？）还有一个需要注意的问题：`TaxID`和`MemberID`是数值，但`ClaimID`生成了字符串值——即使看到了示例。'
- en: Testing for hallucinations
  id: totrans-202
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 测试幻觉
- en: In our extractive summarization examples, we did not encounter any hallucinations,
    but this doesn’t mean they are impossible. Any summarization prompt should be
    tested on multiple inputs before it is deployed to see if it hallucinates. After
    it is deployed, you can detect hallucinations by verifying that each extracted
    value appeared in the transcript text.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的提取式摘要示例中，我们没有遇到任何幻觉，但这并不意味着它们是不可能的。任何摘要提示在部署之前都应该在多个输入上进行测试，以查看它是否会产生幻觉。部署后，你可以通过验证每个提取的值是否出现在记录文本中来检测幻觉。
- en: Let’s go back to the previous one-shot example and instead add some instructions,
    shown in bold in the following listing.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到之前的一次性示例，并添加一些指令，如下面的列表中用粗体显示。
- en: Listing 12.12 An extractive summary with one example
  id: totrans-205
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 12.12 包含一个示例的提取摘要
- en: '[PRE12]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**#1 Augmented task description'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**#1 增强的任务描述**'
- en: '#2 Smaller one-shot example'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**#2 较小的一次性示例**'
- en: '#3 Text version of the chat transcript'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**#3 聊天记录的文本版本**'
- en: '#4 Same cue'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**#4 相同的提示**'
- en: '#5 Model output**  **Voila! Exactly the output we desired. We were able to
    prompt an LLM to produce the structured summary we wanted using a combination
    of instructions and examples. We did not need to modify our assistant, aside from
    calling the LLM. That call is isolated to the component that handles transferring
    conversations to agents.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '**#5 模型输出** **Voila! 正是我们期望的输出。我们能够通过结合指令和示例，提示一个LLM生成我们想要的具有结构化的摘要。除了调用LLM之外，我们不需要修改我们的助手。这个调用仅限于处理将对话传递给代理的组件。**'
- en: Exercises
  id: totrans-212
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: Review the ideal summary you created in section 12.1 for the example chat transcript.
    Use your favorite LLM (or your company’s preferred LLM) to generate a prose summary
    of that transcript. How close does the LLM get to your preferred summary? Did
    you use instructions, few-shot examples, or both?
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回顾你在第12.1节中为示例聊天记录创建的理想摘要。使用你最喜欢的LLM（或你公司首选的LLM）生成该记录的散文摘要。LLM离你偏好的摘要有多近？你是否使用了指令、少量示例或两者都使用了？
- en: Repeat exercise 1, but also modify the model parameters. In this chapter, we
    used greedy decoding and a repetition penalty of 1.1\. Try sampling decoding,
    or try raising or lowering the penalty. Do you get better performance with different
    parameters? Does this match your expectations?
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复练习1，但也要修改模型参数。在本章中，我们使用了贪婪解码和1.1的重复惩罚。尝试采样解码，或者尝试提高或降低惩罚。你是否得到了更好的性能？这符合你的预期吗？
- en: 'Is it possible to generate the prose summary *and* to extract key details from
    the transcript in the same prompt? Design a prompt that generates this output:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是否有可能在同一个提示中生成散文摘要并从记录中提取关键细节？设计一个提示，以生成以下输出：
- en: '[PRE13]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 4\. Invent a conversation that includes multiple claim searches. Create dialogue
    you imagine a bot and user would have if the user was calling to check on four
    total claims. Some of the claims are paid, some of the claims are still processing,
    and the last claim was denied. This conversation will have approximately two to
    four times as much content as the original sample conversation. What do you want
    this summary to look like? Once you have a target summary in mind, use an LLM,
    and try to generate that summary.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4. 设计一个包含多个声明搜索的对话。想象一下，如果用户打电话来检查四个总声明，机器人和用户会进行怎样的对话。其中一些声明是付费的，一些声明仍在处理中，最后一个声明被拒绝。这个对话的内容将是原始样本对话的两到四倍。你希望这个摘要看起来像什么？一旦你有了目标摘要，使用LLM并尝试生成该摘要。
- en: '5\. Design an ideal summary for the following sample conversation:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5. 为以下样本对话设计一个理想的摘要：
- en: '[PRE14]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now build a prompt for your LLM to generate a similar summary.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 现在为你的LLM构建一个提示，以生成类似的摘要。
- en: 6\. Test your new prompt against the original sample conversation in listing
    12.1\. If necessary, refine the prompt so that it generates good summaries for
    both conversations.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 6. 将你的新提示与列表12.1中的原始样本对话进行测试。如有必要，调整提示，以便为这两个对话生成好的摘要。
- en: Summary
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Transfers to human agents are an inevitable part of many conversational AI solutions.
    Agents benefit from receiving brief summaries that extract key highlights from
    the conversation, both in prose and in structured formats.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将对话传递给人工代理是许多对话式AI解决方案的必然部分。代理从接收简短的摘要中受益，这些摘要从对话中提取了关键要点，无论是散文形式还是结构化格式。
- en: A summary requires a conversational transcript. Most conversational AI platforms
    generate a transcript for you, but you can configure your conversational AI to
    generate one in your desired format.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摘要需要一个对话记录。大多数对话式AI平台都会为你生成记录，但你也可以配置你的对话式AI以生成你需要的格式。
- en: Structured summaries can be generated by enhancing your conversational AI to
    store key data points as they are collected, or they can be extracted using LLMs
    when the conversation is completed.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to know what a good summary looks like before you ask an LLM to generate
    one.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs can generate prose summaries and extract key details from transcripts.
    Use clear instructions and examples to generate the summary you desire.************  ******#
    index
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[accuracy](../Text/chapter-4.html#p14)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '[APIs (application programming interfaces)](../Text/chapter-1.html#p41)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[using](../Text/chapter-1.html#p59)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: AI (artificial intelligence)
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[traditional (classification-based)](../Text/chapter-4.html#p63), [2nd](../Text/chapter-4.html#p79)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '[Arize](../Text/chapter-6.html#p258)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: annotated logs
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[for traditional (classification-based) AI](../Text/chapter-4.html#p222)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[answer generation](../Text/chapter-6.html#p82)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[AOV (average order value)](../Text/chapter-3.html#p64)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: B
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[behavioral patterns](../Text/chapter-9.html#p70)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '[blind testing](../Text/chapter-4.html#p64)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: C
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[conversation outcomes](../Text/chapter-3.html#p83), [2nd](../Text/chapter-3.html#p92),
    [3rd](../Text/chapter-3.html#p98), [4th](../Text/chapter-3.html#p140), [5th](../Text/chapter-3.html#p151)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[comparison check](../Text/chapter-6.html#p84)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '[contained conversations, defined](../Text/chapter-3.html#p79)'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '[cross-functional teams](../Text/chapter-3.html#p28), [2nd](../Text/chapter-3.html#p41)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '[complexity](../Text/chapter-8.html#p10), [2nd](../Text/chapter-8.html#p40)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[effect on business metrics](../Text/chapter-8.html#p25), [2nd](../Text/chapter-8.html#p35)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '[effect on end user](../Text/chapter-8.html#p14)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[incremental cost and benefit of reducing for user](../Text/chapter-8.html#p37)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '[continuous improvement](../Text/chapter-1.html#p129)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: context, importance of in virtual assistant performance
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[building trust and loyalty](../Text/chapter-9.html#p43)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '[contextual information](../Text/chapter-9.html#p46), [2nd](../Text/chapter-9.html#p85)'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '[efficiency in problem solving](../Text/chapter-9.html#p31)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[enhanced relevance and accuracy](../Text/chapter-9.html#p21)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '[influencing user interactions](../Text/chapter-9.html#p19), [2nd](../Text/chapter-9.html#p44)'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[personalized experience](../Text/chapter-9.html#p26)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[proactive support](../Text/chapter-9.html#p40)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[CohereEmbeddings](../Text/chapter-6.html#p180)'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[conversational summarization](../Text/chapter-12.html#p1)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[call center agents](../Text/chapter-2.html#p102)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[classification models](../Text/chapter-4.html#p172)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[conversational AI](../Text/chapter-1.html#p1)'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '[benefits of](../Text/chapter-1.html#p20)'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[building](../Text/chapter-1.html#p42), [2nd](../Text/chapter-2.html#p1)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '[continuous improvement](../Text/chapter-1.html#p130), [2nd](../Text/chapter-1.html#p188)'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[defined](../Text/chapter-1.html#p10)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[how it works](../Text/chapter-1.html#p28)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[responding to users with generative AI](../Text/chapter-2.html#p131), [2nd](../Text/chapter-2.html#p168)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[software platforms](../Text/chapter-1.html#p190)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[understanding users](../Text/chapter-4.html#p1)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[confusion matrix](../Text/chapter-5.html#p42), [2nd](../Text/chapter-5.html#p152)'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '[context variables](../Text/chapter-12.html#p87)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[complex flows](../Text/chapter-8.html#p1)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[commercial cloud platform](../Text/chapter-1.html#p194)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: D
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '[DTMF (dual tone multi-frequency)](../Text/chapter-12.html#p72)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '[device type](../Text/chapter-9.html#p60)'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[decoder-only architectures](../Text/chapter-4.html#p43)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '[document transformers](../Text/chapter-6.html#p155), [2nd](../Text/chapter-6.html#p166)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '[disambiguation feature](../Text/chapter-4.html#p173)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[document loaders](../Text/chapter-6.html#p154)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '[direct question](../Text/chapter-7.html#p103)'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[decoding_method](../Text/chapter-2.html#p163)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[DirectoryLoader](../Text/chapter-6.html#p163)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: E
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '[encoder-only architectures](../Text/chapter-4.html#p42)'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[encoder-decoder model architecture](../Text/chapter-4.html#p44)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[embedding generation](../Text/chapter-6.html#p122)'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: F
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[free-text summary elements](../Text/chapter-12.html#p37)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '[FaithfulnessEvaluator](../Text/chapter-6.html#p243)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '[FAISS (Facebook AI Similarity Search)](../Text/chapter-6.html#p192)'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[FAQ (frequently asked question) bots](../Text/chapter-1.html#p67), [2nd](../Text/chapter-2.html#p6)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '[dynamic question and answering](../Text/chapter-2.html#p72)'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[foundations of](../Text/chapter-2.html#p13)'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[static question and answering](../Text/chapter-2.html#p32), [2nd](../Text/chapter-2.html#p70)'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[Flan-ul2 model](../Text/chapter-1.html#p116)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: G
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: golden test set
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '[annotating for generative AI](../Text/chapter-4.html#p209)'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '[annotating for traditional (classifier-based) AI](../Text/chapter-4.html#p197)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '[grammatical variations, generating new](../Text/chapter-7.html#p86), [2nd](../Text/chapter-7.html#p112)'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '[golden intent](../Text/chapter-5.html#p79)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '[generation metrics](../Text/chapter-6.html#p238), [2nd](../Text/chapter-6.html#p244)'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '[generative AI (artificial intelligence)](../Text/chapter-1.html#p73), [2nd](../Text/chapter-4.html#p81),
    [3rd](../Text/chapter-10.html#p1)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[annotated logs for](../Text/chapter-4.html#p229)'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '[augmenting intent data with](../Text/chapter-7.html#p1)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '[defined](../Text/chapter-1.html#p81)'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '[effectively using](../Text/chapter-1.html#p111), [2nd](../Text/chapter-1.html#p125)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '[guardrails](../Text/chapter-1.html#p90), [2nd](../Text/chapter-1.html#p109)'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '[improving summarization with](../Text/chapter-12.html#p105)'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '[model platform](../Text/chapter-1.html#p192)'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '[generated_text](../Text/chapter-2.html#p166)'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[granite-13b-instruct-v2 model](../Text/chapter-12.html#p120)'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: H
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[human in the loop](../Text/chapter-1.html#p106)'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[hallucinations](../Text/chapter-1.html#p87), [2nd](../Text/chapter-6.html#p139)'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: I
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '[IVR (interactive voice response)](../Text/chapter-2.html#p104), [2nd](../Text/chapter-11.html#p15)'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: intent data
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[augmenting with generative](../Text/chapter-7.html#p1)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '[improvement planning](../Text/chapter-3.html#p1)'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '[developing and delivering fixes](../Text/chapter-3.html#p230), [2nd](../Text/chapter-3.html#p235)'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '[driving to same goal](../Text/chapter-3.html#p46), [2nd](../Text/chapter-3.html#p141)'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '[indexing metrics](../Text/chapter-6.html#p214), [2nd](../Text/chapter-6.html#p221)'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '[intents](../Text/chapter-2.html#p33)'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '[hardening existing intents](../Text/chapter-7.html#p4), [2nd](../Text/chapter-7.html#p149)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: immediate opt-outs
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '[allowing user to opt in](../Text/chapter-11.html#p79)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '[conveying capabilities and setting expectations](../Text/chapter-11.html#p68)'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '[starting with great experience](../Text/chapter-11.html#p56), [2nd](../Text/chapter-11.html#p66)'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: improvement
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '[identifying and resolving problems](../Text/chapter-3.html#p153), [2nd](../Text/chapter-3.html#p218)'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: '[recognizing need for](../Text/chapter-3.html#p13)'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: K
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '[KPIs (key performance indicators)](../Text/chapter-3.html#p23)'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '[Kanban board](../Text/chapter-3.html#p239)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: '[k-fold](../Text/chapter-5.html#p127)'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: '[cross validation](../Text/chapter-4.html#p66)'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: '[testing](../Text/chapter-5.html#p60)'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: L
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: logs, obtaining and preparing test data from
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[preparing and scrubbing data for use in iterative improvements](../Text/chapter-4.html#p191)'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: '[LLMs (large language models)](../Text/chapter-1.html#p68), [2nd](../Text/chapter-2.html#p125),
    [3rd](../Text/chapter-6.html#p60), [4th](../Text/chapter-7.html#p11), [5th](../Text/chapter-7.html#p51),
    [6th](../Text/chapter-10.html#p9)'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '[augmenting intent data with](../Text/chapter-7.html#p151), [2nd](../Text/chapter-7.html#p159)'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '[integrating with](../Text/chapter-2.html#p136)'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '[pros and cons of](../Text/chapter-7.html#p21)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '[requirements for](../Text/chapter-7.html#p29)'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '[using augmented data](../Text/chapter-7.html#p39)'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '[load method](../Text/chapter-6.html#p158)'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: M
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '[modality](../Text/chapter-9.html#p81)'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '[comparing modalities](../Text/chapter-9.html#p95)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: '[examples of how modality affects user experience](../Text/chapter-9.html#p111),
    [2nd](../Text/chapter-9.html#p119)'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '[importance in designing virtual assistant flows](../Text/chapter-9.html#p104)'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: messages
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '[error messages](../Text/chapter-11.html#p165), [2nd](../Text/chapter-11.html#p182)'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: '[greeting messages](../Text/chapter-11.html#p184), [2nd](../Text/chapter-11.html#p209)'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: '[metadata, summary elements](../Text/chapter-12.html#p21)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '[meaning, extracting](../Text/chapter-1.html#p55)'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: '[min_tokens](../Text/chapter-2.html#p162)'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: '[models, selection](../Text/chapter-1.html#p117)'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: N
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: '[NPS (net promoter score)](../Text/chapter-3.html#p123)'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: '[NDCG (Normalized Discounted Cumulative Gain)](../Text/chapter-6.html#p236)'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '[NLU (natural language understanding)](../Text/chapter-6.html#p36)'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: '[NLP (natural language processing)](../Text/chapter-9.html#p168)'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: O
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: '[OpenAIEmbeddings class](../Text/chapter-6.html#p178)'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '[opt-outs](../Text/chapter-11.html#p1)'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: '[drivers of](../Text/chapter-11.html#p11), [2nd](../Text/chapter-11.html#p46)'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: '[escalation](../Text/chapter-11.html#p211)'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: '[gathering data on opt-out behavior](../Text/chapter-11.html#p37)'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '[immediate](../Text/chapter-11.html#p52), [2nd](../Text/chapter-11.html#p82)'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: '[improving dialogue with generative AI](../Text/chapter-11.html#p162)'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: '[reducing](../Text/chapter-11.html#p90), [2nd](../Text/chapter-11.html#p121)'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: '[retention](../Text/chapter-11.html#p131), [2nd](../Text/chapter-11.html#p156)'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: '[orchestration layer](../Text/chapter-12.html#p65)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: '[Ollama](../Text/chapter-7.html#p62)'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: '[one-shot prompting](../Text/chapter-4.html#p48)'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: P
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: '[persistent user history](../Text/chapter-9.html#p38)'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: '[prompts](../Text/chapter-1.html#p98)'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: '[prompt engineering](../Text/chapter-4.html#p47)'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: '[parameter tuning](../Text/chapter-4.html#p49)'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '[postfiltering output](../Text/chapter-1.html#p103)'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: '[previous interactions](../Text/chapter-9.html#p75)'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: '[process-oriented bots](../Text/chapter-2.html#p93)'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: '[precision and recall, improving for multiple intents](../Text/chapter-5.html#p118)'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: '[precision](../Text/chapter-5.html#p23)'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: '[process-oriented or transactional solutions](../Text/chapter-1.html#p12)'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: '[passage retrieval](../Text/chapter-6.html#p78)'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: '[preprocessing data](../Text/chapter-6.html#p121)'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '[prompt stuffing](../Text/chapter-6.html#p167)'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: '[prefiltering input](../Text/chapter-1.html#p96)'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: '[PII (personal identifiable information)](../Text/chapter-4.html#p129)'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: process flows
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '[AI-assisted at build time](../Text/chapter-10.html#p12), [2nd](../Text/chapter-10.html#p53)'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: '[AI-assisted at run time](../Text/chapter-10.html#p59)'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: '[executing dialogue flows with generative AI](../Text/chapter-10.html#p62),
    [2nd](../Text/chapter-10.html#p80)'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: Q
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: '[qualitative problem exploration](../Text/chapter-3.html#p167)'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: '[QPS (queries per second)](../Text/chapter-6.html#p217)'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: '[question-answering](../Text/chapter-1.html#p11), [2nd](../Text/chapter-4.html#p51)'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: '[quantitative evaluation for issue discovery](../Text/chapter-3.html#p174)'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: R
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: '[routing agents](../Text/chapter-1.html#p13), [2nd](../Text/chapter-2.html#p97)'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: '[retrievers](../Text/chapter-6.html#p156)'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '[recall](../Text/chapter-5.html#p15)'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: '[RAGAS, defined](../Text/chapter-6.html#p259)'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: '[retrieval and matching at runtime](../Text/chapter-6.html#p124)'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: '[RAG (retrieval-augmented generation)](../Text/chapter-1.html#p76), [2nd](../Text/chapter-3.html#p136),
    [3rd](../Text/chapter-4.html#p50), [4th](../Text/chapter-5.html#p162), [5th](../Text/chapter-6.html#p1),
    [6th](../Text/chapter-6.html#p19), [7th](../Text/chapter-6.html#p51), [8th](../Text/chapter-6.html#p98)'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: '[additional considerations](../Text/chapter-6.html#p134), [2nd](../Text/chapter-6.html#p205)'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '[benefits of](../Text/chapter-6.html#p63), [2nd](../Text/chapter-6.html#p88)'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: '[combining with other generative AI use cases](../Text/chapter-6.html#p90)'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: '[comparing intents, search, and RAG approaches](../Text/chapter-6.html#p96)'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: '[designing adaptive flows with](../Text/chapter-9.html#p137), [2nd](../Text/chapter-9.html#p153)'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: '[evaluating and analyzing performance](../Text/chapter-6.html#p207)'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: '[implementation of](../Text/chapter-6.html#p103), [2nd](../Text/chapter-6.html#p129)'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: '[in conversational AI](../Text/chapter-6.html#p53)'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '[maintaining and updating adaptive flows](../Text/chapter-9.html#p166)'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: '[retrieving and generating contextually relevant responses](../Text/chapter-9.html#p155)'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: '[routing requests to LLMs](../Text/chapter-2.html#p153)'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: '[retrieval metrics](../Text/chapter-6.html#p223)'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: S
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: '[slot filling](../Text/chapter-8.html#p73)'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: self-service
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: '[incentivizing](../Text/chapter-11.html#p73)'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '[storage in vector database](../Text/chapter-6.html#p123)'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: '[session history](../Text/chapter-9.html#p37)'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: '[session variables](../Text/chapter-12.html#p55)'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '[SSA (Sensibleness and Specificity Average)](../Text/chapter-6.html#p242)'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: '[SMEs (subject matter experts)](../Text/chapter-3.html#p35), [2nd](../Text/chapter-5.html#p66),
    [3rd](../Text/chapter-10.html#p52)'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: '[search, role of in conversational AI](../Text/chapter-6.html#p12), [2nd](../Text/chapter-6.html#p49)'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: '[benefits of traditional search](../Text/chapter-6.html#p31)'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: '[drawbacks of traditional search](../Text/chapter-6.html#p39)'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: '[using search in conversational AI](../Text/chapter-6.html#p24)'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: '[search processes, using LLM for](../Text/chapter-10.html#p82), [2nd](../Text/chapter-10.html#p106)'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: '[support resources](../Text/chapter-4.html#p17)'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: '[screen pop](../Text/chapter-12.html#p33)'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: '[synonyms, generating](../Text/chapter-7.html#p59), [2nd](../Text/chapter-7.html#p84)'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: '[sensitive data](../Text/chapter-12.html#p94)'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: summarization
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: '[elements of effective](../Text/chapter-12.html#p19), [2nd](../Text/chapter-12.html#p45)'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: '[improving with generative AI](../Text/chapter-12.html#p109), [2nd](../Text/chapter-12.html#p155)'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: '[need for](../Text/chapter-12.html#p11)'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: '[overview of](../Text/chapter-12.html#p9)'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: '[preparing chatbot for](../Text/chapter-12.html#p53), [2nd](../Text/chapter-12.html#p101)'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: '[sampling decoding](../Text/chapter-7.html#p74)'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: '[solutioning](../Text/chapter-3.html#p200)'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: '[sprint planning](../Text/chapter-3.html#p232)'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: T
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: '[traditional search](../Text/chapter-6.html#p18)'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: '[transitioning from routing agents to process-oriented bots](../Text/chapter-2.html#p110)'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: '[transfer decision](../Text/chapter-6.html#p85)'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: traditional AI
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: '[improving weak understanding for](../Text/chapter-5.html#p1), [2nd](../Text/chapter-5.html#p180)'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '[templates, creating examples with](../Text/chapter-7.html#p135), [2nd](../Text/chapter-7.html#p146)'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: '[test data, obtaining and preparing from logs](../Text/chapter-4.html#p127)'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: '[annotation process](../Text/chapter-4.html#p195), [2nd](../Text/chapter-4.html#p211)'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: '[guidelines for identifying candidate test utterances](../Text/chapter-4.html#p136),
    [2nd](../Text/chapter-4.html#p181)'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: '[obtaining production logs](../Text/chapter-4.html#p131)'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '[preparing and scrubbing data for use in iterative improvements](../Text/chapter-4.html#p183),
    [2nd](../Text/chapter-4.html#p193)'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: '[triaging issues](../Text/chapter-3.html#p183), [2nd](../Text/chapter-3.html#p198)'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: '[test time, AI-assisted flows at](../Text/chapter-10.html#p111)'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: '[setting up conversational test](../Text/chapter-10.html#p139), [2nd](../Text/chapter-10.html#p153)'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: '[setting up generative AI to be user](../Text/chapter-10.html#p116), [2nd](../Text/chapter-10.html#p137)'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: '[time zone](../Text/chapter-9.html#p54)'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: '[true negatives](../Text/chapter-5.html#p33)'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: '[traditional (classification-based) AI solution, assessing](../Text/chapter-4.html#p103)'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: '[training data, selection](../Text/chapter-1.html#p92)'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: U
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: '[user location](../Text/chapter-9.html#p48)'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: understanding
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: '[achieving with generative AI](../Text/chapter-4.html#p38), [2nd](../Text/chapter-4.html#p52)'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: '[achieving with traditional conversational AI](../Text/chapter-4.html#p29)'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: '[annotated logs](../Text/chapter-4.html#p220), [2nd](../Text/chapter-4.html#p242)'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: '[fundamentals of](../Text/chapter-4.html#p37)'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: '[iterative improvement](../Text/chapter-4.html#p232)'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: '[measuring](../Text/chapter-4.html#p61), [2nd](../Text/chapter-4.html#p95)'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: '[weak](../Text/chapter-4.html#p12), [2nd](../Text/chapter-4.html#p20)'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: user journeys
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: '[aligning with user’s mental model](../Text/chapter-8.html#p71)'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: '[allowing flexibility in expected user responses](../Text/chapter-8.html#p77),
    [2nd](../Text/chapter-8.html#p89)'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: '[spotting complex dialogue flows](../Text/chapter-8.html#p49)'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: '[supporting self-service task flows with API/backend processes](../Text/chapter-8.html#p92)'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: '[using what is known about user](../Text/chapter-8.html#p61)'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: users
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: '[assessing where you are today](../Text/chapter-4.html#p101), [2nd](../Text/chapter-4.html#p115)'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: '[understanding](../Text/chapter-4.html#p1)'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: '[user preferences](../Text/chapter-9.html#p65)'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: V
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: '[verb phrases](../Text/chapter-7.html#p71)'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: virtual assistants
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
- en: '[enhancing context awareness and improving overall user experience with RAG](../Text/chapter-9.html#p134),
    [2nd](../Text/chapter-9.html#p170)'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: '[importance of context in performance](../Text/chapter-9.html#p11)'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
- en: '[modelities](../Text/chapter-9.html#p91), [2nd](../Text/chapter-9.html#p129)'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: '[voice bots, design considerations](../Text/chapter-9.html#p121)'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: '[voice solutions, accommodating](../Text/chapter-11.html#p104)'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
- en: W
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: weak understanding
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
- en: '[establishing baseline](../Text/chapter-5.html#p58)'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: '[identifying biggest problems](../Text/chapter-5.html#p50)'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: '[identifying problematic patterns in misunderstood utterances](../Text/chapter-5.html#p13),
    [2nd](../Text/chapter-5.html#p37)'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
- en: '[improvement plan](../Text/chapter-5.html#p9)'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
- en: '[improving F1 score for one intent](../Text/chapter-5.html#p112)'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
- en: '[improving for traditional AI](../Text/chapter-5.html#p1)'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: '[improving precision for one intent](../Text/chapter-5.html#p94)'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
- en: '[improving recall for one intent](../Text/chapter-5.html#p76)'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
- en: '[incremental improvements](../Text/chapter-5.html#p48)'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: '[solving](../Text/chapter-5.html#p139), [2nd](../Text/chapter-5.html#p142),
    [3rd](../Text/chapter-5.html#p154), [4th](../Text/chapter-5.html#p156)'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
- en: '[traditional AI](../Text/chapter-5.html#p168), [2nd](../Text/chapter-5.html#p171),
    [3rd](../Text/chapter-5.html#p176)'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
- en: '[validating initial training strategy](../Text/chapter-5.html#p65)'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: '[验证初始训练策略](../Text/chapter-5.html#p65)'
- en: '[wrong intent matched](../Text/chapter-5.html#p74)'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: '[意图匹配错误](../Text/chapter-5.html#p74)'
- en: Z
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: Z
- en: '[zero-shot prompting](../Text/chapter-7.html#p99)******'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: '[零样本提示](../Text/chapter-7.html#p99)******'
