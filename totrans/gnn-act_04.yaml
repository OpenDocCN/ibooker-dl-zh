- en: 3 Graph convolutional networks and GraphSAGE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Introducing GraphSAGE and graph convolutional networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applying convolutional graph neural networks to generate product bundles from
    Amazon
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key parameters and settings for graph convolutional networks and GraphSAGE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More theoretical insights, including convolution and message passing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the first two chapters of this book, we explored fundamental concepts related
    to graphs and graph representation learning. All of this served to set us up for
    part 2, where we’ll explore distinct types of graph neural network (GNN) architectures,
    including convolutional GNNs, graph attention networks (GATs), and graph autoencoders
    (GAEs).
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, our goal is to understand and apply graph convolutional networks
    (GCNs) and GraphSAGE [1, 2]. These two architectures are part of a larger class
    of GNNs that approach deep learning by applying convolutions to graph data.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional operations are relatively common in deep learning models, particularly
    for image-based tasks that rely heavily on convolutional neural networks (CNNs).
    To learn more about CNNs and their application to computer vision, we recommend
    checking out *Deep Learning with Python* (Manning, 2024) or *Deep Learning with
    PyTorch* (Manning, 2023).
  prefs: []
  type: TYPE_NORMAL
- en: We provide a short primer on convolutions later in the chapter, but essentially
    convolutional operations can be understood as performing a spatial or local averaging
    across entities. For example, in images, CNN layers form representations at incrementally
    larger pixel subdomains. For GCNs, we’ll apply the same idea of a local averaging,
    but with neighborhoods of nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you’ll learn how to apply convolutional GNNs to a node prediction
    problem, key parameters and settings for GCN and GraphSAGE, ways to optimize performance
    for convolutional GNNs, and relevant theoretical topics, including graph convolution
    and message passing. Additionally, we’ll explore the Amazon Products dataset.
    This chapter is structured as follows: first, we jump into the product category
    prediction problem and create baseline models (section 3.1); then we adjust our
    models using neighborhood aggregation (section 3.2); next, we optimize our models
    using general deep learning methods (section 3.3); following that, we explain
    relevant theory in more detail (section 3.4); and finally, we dig deeper into
    the Amazon Products dataset used in this chapter and later in the book (section
    3.5).'
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is designed to immerse you immediately in the application of convolutional
    GNNs, equipping you with the essential knowledge needed to deploy these models
    effectively. The initial sections provide you with the minimum toolkit for a functioning
    understanding of convolutional GNNs in practice.
  prefs: []
  type: TYPE_NORMAL
- en: However, when facing challenging modeling problems, deeper comprehension becomes
    invaluable. The latter sections of the chapter cover underlying principles of
    the layers, settings, and parameters introduced earlier. They are crafted to enhance
    your conceptual grasp, ensuring that your practical skills are complemented by
    a thorough theoretical understanding. This holistic approach aims to not only
    enable you to apply GNNs but to innovate and adapt them to the nuanced demands
    of real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: Note  While *GraphSAGE* refers to a specific individual architecture, it may
    be confusing that *GCN* also refers to a specific architecture and not the entire
    class of GNNs based on convolutions. So, in this chapter, we’ll use *convolutional
    GNNs* to refer to this entire class of GNNs, which include GraphSAGE and GCN.
    We’ll use *GCN* to refer to the individual architecture introduced by Thomas Kipf
    and Max Welling [1].
  prefs: []
  type: TYPE_NORMAL
- en: Note  Code from this chapter can be found in notebook form at the GitHub repository
    ([https://mng.bz/wJMW](https://mng.bz/wJMW)). Colab links and data from this chapter
    can be accessed in the same locations.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Predicting consumer product categories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start our exploration of convolutional GNNs with a product management
    problem using the Amazon Products dataset (see table 3.1). Imagine you’re a product
    manager aiming to enhance sales by identifying and promoting emerging trends in
    product bundles. You have a dataset derived from Amazon’s product co-purchasing
    network, containing a rich set of relationships between products based on customer
    buying behavior. Your task is to use insights about product categories and co-purchasing
    patterns to uncover hidden and appealing product bundles that resonate with your
    customers.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.1 Overview of the Amazon Products dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Amazon co-purchases organized by product category |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Number of nodes (products)  | ~2,500,000  |'
  prefs: []
  type: TYPE_TB
- en: '| Node features  | 100  |'
  prefs: []
  type: TYPE_TB
- en: '| Node categories  | 47  |'
  prefs: []
  type: TYPE_TB
- en: '| Total number of edges  | ~61,900,000  |'
  prefs: []
  type: TYPE_TB
- en: 'To tackle this, we introduce GCNs and GraphSAGE—two convolutional GNN architectures.
    This section will guide you through training these models on the Amazon Products
    dataset. We’ll focus on two tasks: identifying a product’s category and finding
    sets of product bundles by analyzing the similarity between product embeddings
    produced by the trained models.'
  prefs: []
  type: TYPE_NORMAL
- en: Note  If you want to get deeper into the theory behind GCN and GraphSAGE, see
    section 3.4\. For details about the Amazon Products dataset, see section 3.5.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following our model training process, in this section, we’ll do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Preprocess our dataset*—We’ll take the Amazon Products dataset and reduce
    its size to work with systems with minimal resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Construct our model classes*—We’ll focus on two convolutional GNNs: GCN and
    GraphSAGE. We’ll initially create model classes and instantiate them with default
    parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Code our training and validation loops*—We’ll train the models with a validation
    step for each epoch. To compare the two models, we’ll train them simultaneously
    with the same batches.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Assess model performance*—We’ll take a look at training curves. Then, we’ll
    use traditional classification metrics and observe the ability of the model to
    predict particular categories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our immediate goal is to develop first passes of our trained models. So, at
    this point, the emphasis isn’t on performance optimization but on covering the
    essential steps to get a baseline model working. Subsequent sections will refine
    these approaches, enhancing performance and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Loading and processing the data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We start by downloading the Amazon Products dataset from the Open Graph Benchmark
    (OGB) site ([https://ogb.stanford.edu/](https://ogb.stanford.edu/)). This dataset
    is large for a single machine, taking up 1.3 GB. This includes 2.5 million nodes
    (products) and 61.9 million edges (co-purchases).
  prefs: []
  type: TYPE_NORMAL
- en: To make working with this data manageable for systems with smaller memory capacity
    and less powerful processors, we’ll reduce its size. We simply take the nodes
    that have the first 10,000 node indices in the original graph and create a subgraph
    based on those. Depending on your problem, there are other strategies to create
    subgraphs. In chapter 8, we look at creating subgraphs in more depth.
  prefs: []
  type: TYPE_NORMAL
- en: In creating a subset graph, there is often bookkeeping that must be done to
    ensure our node subset has a consistent and logical ordering and is connected
    to the correct labels and features. We must also filter out edges that are connected
    to nodes from outside the subset. Lastly, we want to make sure we can call back
    the original indices of the subset in case we want to call back useful information;
    for example, for the Amazon Products dataset, we can access the SKU (Amazon Standard
    Identification Number, ASIN) numbers and product categories of each node using
    their original indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we relabel the nodes with a consistent ordering. Then, we reassign the
    respective node features and labels to correspond to the new indices. Even though
    we choose nodes with the first 10,000 indices, this may not be so in any particular
    case. Here’s how we’ll refine and prepare the data for modeling in four steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Initialize the subset graph *—We create a new graph object that will store
    our subset of data. This graph will hold the edges, features, and labels of the
    nodes that have indices 0–9,999 in our original graph.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Relabel node indices *—To ensure consistency and avoid index mismatches, we
    relabel the node indices within our subset graph. This relabeling is crucial because
    operations within GNNs depend heavily on indexing to process node and edge information.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Feature and label assignment *—We assign node features (x) and labels (y)
    to our new graph object. These features and labels are sliced from the original
    dataset, corresponding to our specified subset indices.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Edge mask utilization *—The `return_edge_mask` option, used during the subgraph
    extraction, lets us identify which edges were selected during the subgraph creation.
    This is useful for tracing back to the original graph’s structure or for any structural
    analysis required later.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By restructuring the data in this manner, we not only make it manageable but
    also tailor it specifically for efficient processing in subsequent graph-based
    learning tasks. This setup is foundational as we proceed to construct and evaluate
    our GNN models in the following sections. The following listing shows the code
    for implementing that process.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.1 Reading in data and creating a subgraph
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Loads dataset from the specified root directory and specifies ogbn-products
    to indicate which dataset is being loaded'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The first graph object from the dataset is selected for processing.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Creates an array of indices for the first 10,000 nodes, which defines our
    subset for the experiment'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Calls the subgraph function with subset_indices to extract edges and attributes
    relevant to these indices. The nodes are relabeled to maintain a consistent zero-based
    index in the new graph.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Indexes node features from the original data according to subset_indices
    to ensure that only relevant features are transferred to the new graph'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Similarly, indexes node labels to maintain correspondence with the subset
    features'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Creates a new instance of the data class to store our subset graph'
  prefs: []
  type: TYPE_NORMAL
- en: '#8 Assigns the edge index array created during the subgraph extraction to the
    new graph'
  prefs: []
  type: TYPE_NORMAL
- en: '#9 Assigns subset features to the new graph’s node feature matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '#10 Assigns node labels corresponding to the subset to the new graph'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Creating our model classes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After setting up our dataset and preparing a manageable subgraph, we transition
    to the core of our graph machine learning pipeline: defining the models. In this
    section, we focus on two popular types of GNNs provided by the PyTorch Geometric
    (PyG) library: GCN and GraphSAGE.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding our model architectures
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: PyG simplifies the construction of GNNs through modular layer objects, each
    encapsulating a specific type of graph convolution. These layers can be stacked
    and integrated with other PyTorch modules to build complex architectures tailored
    to various graph-based tasks.
  prefs: []
  type: TYPE_NORMAL
- en: GCN model
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The GCN model uses the `GCNConv` layer, which implements the graph convolution
    operation as described by Kipf and Welling in their seminal paper [1]. It takes
    advantage of the spectral properties of graphs to facilitate information flow
    between nodes, allowing the model to learn representations that embed both local
    graph structure and node features.
  prefs: []
  type: TYPE_NORMAL
- en: In listing 3.2, the GCN class sets up a two-layer model. Each layer is represented
    by the `GCNConv` module, which processes graph data by applying a convolution
    operation that directly uses the graph’s structure.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize its workings, from an input set of node features and the graph
    structure (`edge_index`), the network will update node features by aggregating
    the neighborhood information from each respective node. After the first layer,
    we apply a rectified linear unit (ReLU) activation function, which adds nonlinearity
    to the model. The second layer refines these features further.
  prefs: []
  type: TYPE_NORMAL
- en: If we want to look at the node embeddings directly—for instance, to visualize
    them or to use them in some other analysis—we can just return them right after
    the second layer. Otherwise, we apply another activation function—in this case,
    a softmax function—to normalize the outputs for our classification problem.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.2 GCN class
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Initializes the first graph convolution layer that transforms input features
    (in_channels) into hidden features (hidden_channels)'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Forward method that dictates how data flows through the model from input
    to output'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Applies the ReLU activation function after the first convolution to add
    nonlinearity to the model'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Optionally returns the raw embeddings from the network, which can be useful
    for tasks that require raw node representations without classification, such as
    visualization or further processing'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Applies a log softmax activation to the final layer’s output'
  prefs: []
  type: TYPE_NORMAL
- en: GraphSAGE model
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Much like the GCN model, the GraphSAGE model class in our code also sets up
    a two-layer network, but with the `SAGEConv` layers. While structurally similar
    in code, GraphSAGE is a significant shift from GCN in theory. Unlike GCN’s full
    reliance on the entire graph’s adjacency matrix, GraphSAGE is designed to learn
    from randomly sampled neighborhood data, making it particularly well-suited for
    large graphs. This sampling approach allows GraphSAGE to scale effectively by
    focusing on localized regions of the graph.
  prefs: []
  type: TYPE_NORMAL
- en: GraphSAGE uses the `SAGEConv` layer, which supports various aggregation functions—mean,
    pool, and long short-term memory (LSTM)—offering flexibility in how node features
    are aggregated. After each `SAGEConv` layer, similar to the GCN model, a nonlinearity
    is applied. If node embeddings are required directly for tasks such as visualization
    or further analysis, they can be returned immediately following the second layer.
    Otherwise, a softmax function is applied to normalize the outputs for classification
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The key difference in PyG’s implementation of these models lies in their efficiency
    and scalability with large datasets. Both models learn node representations, but
    GraphSAGE provides a significant advantage for practical applications involving
    very large graphs. Unlike GCN, which can operate on sparse data representations
    but still processes information from the entire graph structure, GraphSAGE doesn’t
    require the entire adjacency matrix. Instead, it samples local neighborhoods,
    which allows it to handle vast networks efficiently without overwhelming memory
    resources by having to load the entire graph representation.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.3 GraphSAGE class
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Initializes the first graph convolution layer that transforms input features
    (in_channels) into hidden features (hidden_channels)'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Forward method that dictates how data flows through the model from input
    to output'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Applies the ReLU activation function after the first convolution to add
    nonlinearity to the model'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Optionally returns the raw embeddings from the network, which can be useful
    for tasks that require raw node representations without classification, such as
    visualization or further processing'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Applies a log softmax activation to the final layer’s output'
  prefs: []
  type: TYPE_NORMAL
- en: Integration and customization
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: While we use default settings in this introductory example, both models are
    highly customizable. Parameters such as the number of layers, hidden dimensions,
    and types of aggregation functions (for GraphSAGE) can be adjusted to optimize
    performance for specific datasets or tasks. Next, we’ll train these models on
    our subset graph and evaluate their performance to demonstrate their practical
    applications and effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3 Model training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With our data ready and our models set up, let’s get into the training process.
    Training is relatively straightforward, as it follows typical machine learning
    routines but applied to graph data. We’ll be training two models simultaneously—GCN
    and GraphSAGE—by feeding them the same data each epoch. This parallel training
    allows us to directly compare the performance and efficiency of these two model
    types under identical conditions. Here’s a concise breakdown of the training loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Initialize optimizers*—Set up Adam optimizers with a learning rate of 0.01\.
    This helps us fine-tune the model weights effectively during training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Training and validation loops*—For each epoch, run the training function,
    which processes the data through the model to compute losses and update weights.
    Concurrently, validate the model on unseen data to monitor overfitting and adjust
    training strategies accordingly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Track progress*—Record losses for both training and validation phases to visualize
    the learning curve and adjust parameters if needed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Conclude with testing*—After training, the models are evaluated on a separate
    test set to gauge their generalization capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By maintaining a consistent training regimen for both models, we ensure that
    any differences in performance can be attributed to the models’ architectural
    differences rather than varied training conditions. The following listing contains
    the annotated code of our training logic.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.4 Training loop
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Initializes models for the GCN and GraphSAGE'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Initializes models for the GCN and GraphSAGE'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Sets up optimizers for the GCN and GraphSAGE models'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Sets up optimizers for the GCN and GraphSAGE models'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Initializes the cross-entropy loss function for the classification task'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Train functions used every epoch'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Validation functions used every epoch'
  prefs: []
  type: TYPE_NORMAL
- en: '#8 Sets up arrays to capture losses for each model'
  prefs: []
  type: TYPE_NORMAL
- en: '#9 Training and validation loop'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve set up and trained our models, it’s time to see how well they
    perform. The next section will look at the training and validation loss curves
    to understand how the models learned over time. It will check out key metrics
    such as accuracy, precision, recall, and F1 scores to evaluate how well our models
    can predict product categories based on our graph data. All of this is to understand
    our models and to figure out where we can improve them in later sections.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.4 Model performance analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For the next section, we’ll look at the model performance of the GCN and GraphSAGE
    models. We’ll first examine the training curves and point out that we have to
    improve the overfitting in a subsequent chapter. Then, we’ll look at the F1 and
    log loss scores, followed by examining accuracy for the product categories.
  prefs: []
  type: TYPE_NORMAL
- en: Training curves
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: During the training process, we saved the losses for each model for every epoch.
    *Loss* is a measure of how well our model is able to make correct predictions,
    with lower values being better.
  prefs: []
  type: TYPE_NORMAL
- en: Using `Matplotlib`, we use this data to plot training loss and validation loss
    curves, shown in figure 3.1\. Such curves track the performance of the model on
    training and validation datasets over the course of the training process. Ideally,
    both losses should decline over time. However, in our curves, we see a divergence
    beginning near epoch 20\. The validation loss curves reach a nadir and then begin
    to climb. Meanwhile, the training loss continues to decline. Our models’ performance
    continues to improve on the training data but degrades on the validation data
    past some optimal point. This is the classic overfitting problem, which we’ll
    address later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 Training and validation loss curves for the GCN model (left) and
    GraphSAGE model (right) trained in this section. The divergence of the validation
    from the training curve signals over-fitting, where the model learns the training
    data too well and at the expense of generalizing to new data.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In our training process, we’ve saved the instance of the model with the best
    performance, which is the instance with the lowest validation loss. Next, we look
    at two classification metrics to assess performance: log loss and F1 score.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Classification performance: F1 and log loss'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Given the overfitting problems shown earlier, we turn to the classification
    performance of our models to establish a baseline for our improvement efforts.
    We use our validation sets to establish F1 and log loss scores, shown in table
    3.2\. (The F1 score is weighted, which measures F1 for each class separately,
    then averages them, weighing each class by its proportion of the total data.)
  prefs: []
  type: TYPE_NORMAL
- en: The middling scores indicate that the models have much room for improvement.
    Our F1 scores don’t exceed 80%, while the log loss scores are no lower than 1.25\.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.2 Classification performance of our models, by F1 score and log loss
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '|  | F1 Score | Log Loss |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| GCN  | 0.781  | 1.25  |'
  prefs: []
  type: TYPE_TB
- en: '| GraphSAGE  | 0.733  | 1.88  |'
  prefs: []
  type: TYPE_TB
- en: In this case, GCN performs better for both metrics. To improve these scores
    for a multiclass problem, we could look more deeply at the model’s capability
    to predict individual classes and examine its performance for imbalanced classes.
  prefs: []
  type: TYPE_NORMAL
- en: Model performance at a class level
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Amazon Products dataset comes with two useful files that map each node with
    its class, and each node with its individual Amazon product number (ASIN). To
    evaluate the performance of our baseline models by class, we take the node class
    information and create a table, as shown in figure 3.2, summarizing prediction
    accuracy for the 25 classes containing the most items.
  prefs: []
  type: TYPE_NORMAL
- en: 'Along with accuracy, in this table, we examine the biggest mispredictions for
    each class. From this information, let’s make some high-level observations:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Performance by category*—Both models show variability in their prediction
    accuracy across different product categories. The Books category and CDs & Vinyl
    category have high accuracy rates. This can be due to their relatively high number
    of samples. It could also indicate that these categories are more distinct or
    well-defined, making it easier for the model to distinguish them. The first factor,
    number of samples, is easy to adjust because we’re using 10,000 product nodes
    and can draw millions more from our dataset. You can give it a try by adjusting
    the size of the subset in the provided code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To improve less distinctive classes, we need to make a deeper exploration of
    the node features to determine how distinctive the classes are relative to each
    other and to brainstorm ways to enhance those features to bring out their novelty.
  prefs: []
  type: TYPE_NORMAL
- en: '*Performance by model*—Looking over all the classes, GraphSAGE generally appears
    to perform better than GCN in most categories, as seen from the higher percentages
    of correct predictions. This suggests that GraphSAGE’s approach of aggregating
    features from a node’s neighborhood might be more effective for this dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Misclassifications*—Common misclassifications tend to occur between categories
    that might share similar characteristics or be frequently purchased together.
    For example, the misclassification between Books and Movies & TV or between Electronics
    and Cell Phones & Accessories suggests that items in these categories may share
    overlapping features or are often bought by similar customer segments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![figure](../Images/3-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 Classification performance (accuracy) by product category, comparing
    GCN and GraphSAGE
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Though we generally don’t want misclassifications, observing the classes most
    likely to be misconstrued for another could inform us about common customer perceptions
    or confusions between product categories, highlighting potential areas for marketing
    and product placement strategies.
  prefs: []
  type: TYPE_NORMAL
- en: The next two sections will improve the models’ performance from these baseline
    results by taking advantage of the properties of our GNNs (section 3.2) and by
    using well-known deep learning methods (section 3.3). To end this section, let’s
    use our models to come up with a product bundle for our product manager.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.5 Our first product bundle
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the beginning of this section, we discussed our use case of a product manager
    who wants to enhance sales by introducing product bundles. Let’s use one of our
    newly trained models to suggest a bundle for a given product. We’ll group together
    the nodes whose embeddings are most similar to a selected node, forming a bundle
    based on their similarity. Later in the chapter, as we improve the models, we’ll
    come back to the exercise.
  prefs: []
  type: TYPE_NORMAL
- en: Note  The code won’t be reviewed extensively here but can be found in the repository.
  prefs: []
  type: TYPE_NORMAL
- en: Node ID to product number
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One key file provided in the Amazon Products dataset is a comma-separated values
    (CSV) file mapping for node index to Amazon product ID (ASIN). In the repository,
    this is used to create a Python dictionary of node ID (key) to ASIN (value). Using
    a node’s ASIN, we can access information about the product using a URL in this
    format: www.amazon.com/dp/{ASIN}. (Given the age of the dataset, a few ASINs don’t
    have web pages currently, but the vast majority we tested do at the time of writing.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a product bundle, we work with node embeddings. We choose an individual
    product node and then find the six most similar products to it. This takes four
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Produce node embeddings by running our nodes through our trained GNN.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a similarity matrix using the node embeddings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sort the top five embeddings by similarity to our chosen product.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the node indices of these top embeddings to product IDs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A seed may be set to ensure reproducibility. Otherwise, your results will differ
    with every run of your program.
  prefs: []
  type: TYPE_NORMAL
- en: Produce node embeddings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Like chapter 2, we run our nodes through the model to produce an embedding
    instead of a prediction. In contrast to chapter 2, we have a trained model for
    this purpose that has learned from the node features and the co-purchasing relationships
    of our dataset. To accomplish this, we put our model into evaluation mode (`eval()`),
    disable gradient computations that support backpropagation (`no_grad()`), and
    then run a forward pass of the graph data through the model. Earlier, when defining
    the model class, we enabled an option to return an embedding or a prediction (`return_embeds`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Create a similarity matrix
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A similarity matrix is a set of data, usually in tabular form, that contains
    the similarities between all pairs of items in a set. In our case, we use cosine
    similarity, and compare the embeddings of all the nodes in our set. SciKit Learn’s
    `cosine_similarity` function accomplishes this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: List the items closest in similarity to a chosen node
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To identify items most similar to a specific node, we begin by selecting a
    node—referred to by its index as `product_idx`. Using the cosine similarity matrix,
    we examine how closely related each node is to our chosen node by sorting the
    similarities in descending order. The top entries from this sorting (specifically,
    the first six, where `top_k` is set to `6`) represent the nodes most similar to
    our selected node. Notably, the list includes the selected node itself, So, for
    practical purposes, we consider the next five nodes to effectively create a bundle
    of similar items:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Convert the node indices to product IDs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: From here, using the index-to-ASIN dictionary will identify the product bundle
    from the node indices. With this done, let’s pick a product node at random and
    generate a product bundle around it.
  prefs: []
  type: TYPE_NORMAL
- en: Product Bundle Demo
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'At random, we pick node #123\. Using our index-to-ASIN dictionary, we get ASIN:
    B00BV1P6GK. This ASIN belongs to the product Funko POP Television: Adventure Time
    Marceline Vinyl Figure, as shown in figure 3.3\. The category of this product
    is Toys & Games.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.3 Our selected product, Funko POP Television: Adventure Time Marceline
    Vinyl Figure. In this section, a product bundle will be generated for this product.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Marceline, the hundreds-of-years-old Vampire Queen, is one of the main characters
    in the popular animated TV series *Adventure Time.* Marceline is known for her
    rock star persona, love of music, and playing her bass guitar, which is often
    a focal point in her appearances. Her persona is reflected in the figurine, which
    is smiling and has a relaxed but confident pose.
  prefs: []
  type: TYPE_NORMAL
- en: '*Adventure Time* is an animated series that follows the surreal and epic adventures
    of a boy named Finn and his magical dog Jake in the mystical Land of Ooo, filled
    with princesses, vampires, ice kings, and many other bizarre characters.'
  prefs: []
  type: TYPE_NORMAL
- en: For a collection based on the *Adventure Time* series, one may expect a variety
    of vinyl figures representing the show’s eclectic cast of characters. Let’s see
    what our system generates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the process outlined earlier, the bundle shown in figure 3.4, was generated.
    There is one *Adventure Time* vinyl figure included. The rest of the choices seem
    unrelated at first glance, but maybe this set is a nonintuitive bundle. Let’s
    take a closer look:'
  prefs: []
  type: TYPE_NORMAL
- en: '*First ranked similarity: Funko POP Television: Adventure Time Finn with Accessories*—Finn
    is the central character from *Adventure Time*, a recommendation we expected.
    This suggests that fans of Marceline might also appreciate or collect merchandise
    related to other main characters from the same show.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Second ranked similarity: Funko My Little Pony: DJ Pon-3 Vinyl Figure*—This
    item might seem out of context at first glance, but it may indicate a crossover
    interest in animated series. DJ Pon-3, or Vinyl Scratch, from *My Little Pony*
    is a musical character like Marceline, appealing to those who enjoy characters
    associated with music.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![figure](../Images/3-4.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 A product bundle centered on the Marceline product. The recommendations
    are members of the Toy & Games category. The themes of these products connect
    loosely to the selected product.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*Third ranked similarity: Funko My Little Pony: Twilight Sparkle Vinyl Figure*—Similar
    to DJ Pon-3, Twilight Sparkle from *My Little Pony* represents another connection
    to a popular animated series. This inclusion could appeal to collectors who enjoy
    fantasy themes and strong female characters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Fourth and fifth ranked similarities: Pirate-themed accessories (Gold Coins,
    Tattoos, Handheld Brass Telescope with Wooden Box)*—These items are less directly
    related to “Adventure Time” or “My Little Pony”, but they enhance the theme of
    adventure and exploration, which is a significant element of both series.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All in all, this is not a bad product bundle from our baseline models! Wrapping
    up this introductory section on model training and evaluation, we’ve now established
    a solid foundation for understanding and using GNNs. This understanding is crucial
    as we progress to section 3.2, where we’ll dive deeper into neighborhood aggregation,
    an effective tool to enhance performance. Then, in section 3.3, we’ll draw from
    general deep learning approaches to further optimize the models’ performances.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Aggregation methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we extend the product category analysis from the previous section
    and take a deeper look into the characteristics of GNNs that influence their performance
    on tasks such as product categorization. Specifically, we explore aggregation
    methods, techniques that have a large influence on the performance of convolutional
    GNNs. Neighborhood aggregation allows nodes to gather and integrate feature information
    from their local node neighborhoods, capturing contextual relevance within the
    larger network.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start with the simple aggregations mean, sum, and max, each applied over
    all layers of a model. Then, we survey a few more advanced implementations in
    PyG: unique aggregations applied per layer, list aggregations, aggregation functions,
    and a layer-wise aggregation known as jumping knowledge networks (JK-Nets). Finally,
    we provide some guidelines on applying such methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1 Neighborhood aggregation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One way graph data structures are different is that nodes are interconnected
    through edges, creating a network where nodes can be directly linked or separated
    by several degrees. This spatial arrangement means that any given node may be
    in close proximity to certain other nodes, forming what we call its *neighborhood*.
    The concept of a node’s neighborhood is critical as it often holds key insights
    into the node’s characteristics and that of the overall graph.
  prefs: []
  type: TYPE_NORMAL
- en: In convolutional GNNs, node neighborhoods are used through a process known as
    *neighborhood aggregation*. This technique involves gathering and combining feature
    information from a node’s immediate neighbors to capture both their individual
    and collective properties. By doing so, a node’s representation is enriched with
    the contextual information provided by its surroundings, which enhances the model’s
    capability to learn more complex and nuanced patterns within the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Neighborhood aggregation operates under the premise that nodes in proximity
    to each other are likely to influence each other more significantly than those
    farther away. This is particularly advantageous for tasks where the relationship
    and interaction between nodes are predictive of their behaviors or properties.
  prefs: []
  type: TYPE_NORMAL
- en: Neighborhood aggregation in PyG
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the PyG layers GCN (`GCNconv`) and GraphSAGE (`SAGEConv`), neighborhood aggregation
    is implemented in different ways. In GCN, a weighted average aggregation is built
    into the layer; if you want to tweak it, you must create a customized version
    of this layer. In this section, we’ll mostly focus on GraphSAGE, which allows
    you to set an aggregation via a parameter. An upcoming section will examine a
    layer-wise aggregation used in GCN.
  prefs: []
  type: TYPE_NORMAL
- en: 'In `SAGEConv`, the `aggr` parameter specifies the type of aggregation. The
    options include, but are not limited to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Sum aggregation*—A simple aggregation that sums up all neighbor node features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mean aggregation*—Computes the mean of the neighbor node features. This is
    often used for its simplicity and effectiveness in averaging feature information,
    helping to smooth out anomalies in the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Max aggregation*—Takes the maximum feature value among all neighbors for each
    feature dimension. This can help when the most prominent features are more informative
    than average features, capturing the most significant signals from the neighbors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*LSTM aggregation*—A relatively compute- and memory-intensive method that uses
    an LSTM network to process features of the ordered sequence of neighbor nodes.
    It considers the sequence of nodes, which can be crucial for tasks where the order
    of node processing affects the results. As such, special care must be taken to
    arrange a dataset’s nodes and edges for training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing among these types will depend on the characteristics of a given graph,
    and the prediction goals. If you don’t have a good feel for which method will
    be more effective for your graph and your use case, trial and error can suffice
    to choose the aggregation method. In addition, while some of the aggregation options
    can be applied out of the box, others—such as LSTM aggregation, which relies on
    a trained LSTM network—require some thought to be put into data preparation.
  prefs: []
  type: TYPE_NORMAL
- en: To see the effect of different aggregations, we add the `aggr` parameter to
    our model class and then proceed to train as in section 3.1, swapping out the
    mean, sum, and max aggregations. It should be noted that the mean aggregation
    is the default for the `SAGEConv` layer, so it’s equivalent to our GraphSAGE baseline
    model. Creating a *GraphSAGE* class with aggregations would look like the following
    listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.5 GraphSAGE class with aggregation parameter
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Sets keyword parameter for aggregation'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 First GraphSAGE layer with specified aggregation'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Second GraphSAGE layer with specified aggregation'
  prefs: []
  type: TYPE_NORMAL
- en: Results of using mean, max, and sum aggregations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Table 3.3 compares the models using F1 score and log loss as performance metrics.
    The table shows that the model using max aggregation is the best under both measures.
    The results for the model using max aggregation shows the highest F1 score of
    0.7449 and the lowest log loss of 2.1039, suggesting that max aggregation is a
    little more capable at identifying and using the most influential features in
    the prediction task. The model that uses mean aggregation is equivalent to the
    model trained in section 3.1\. We observe that the max aggregation out-performs
    the other two. Overall, the performance using different aggregations is very similar
    to that of our baseline GraphSAGE model.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.3 Classification performance for GraphSAGE models with different settings
    for neighborhood aggregation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Aggregation Type | F1 Score | Log Loss |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Mean (default)  | 0.7406  | 2.1214  |'
  prefs: []
  type: TYPE_TB
- en: '| Sum  | 0.7384  | 2.2496  |'
  prefs: []
  type: TYPE_TB
- en: '| Max  | 0.7449  | 2.1039  |'
  prefs: []
  type: TYPE_TB
- en: What model should be chosen if separate models had the highest F1 score and
    log loss? For example, what if the max aggregation model scored highest for F1,
    but the mean aggregation model took the highest for log loss? This will depend
    on the context of your application, your requirements for prediction, and the
    consequences of potential errors.
  prefs: []
  type: TYPE_NORMAL
- en: In a healthcare situation, such as predicting patient readmissions within 30
    days of discharge, for example, the choice of model can significantly affect patient
    outcomes and resource allocation. A model with a high F1 score would have a more
    balanced precision and recall, making it better in situations where missing a
    readmission could be costly or dangerous. It would be expected to identify more
    patients at risk, allowing for timely interventions. However, this could also
    result in higher false positives, leading to unnecessary treatments and increased
    costs.
  prefs: []
  type: TYPE_NORMAL
- en: A model that exhibits low log loss, on the other hand, offers high confidence
    in its predictions, prioritizing the accuracy of each prediction over the number
    of positive cases detected. This model is useful when resource allocation needs
    to be precise or when treatments have substantial side effects.
  prefs: []
  type: TYPE_NORMAL
- en: Coming back to our product manager who is deciding which products and product
    bundles to allocate marketing dollars to, having more confident predictions would
    be desirable in preventing wasted marketing efforts. The lower likelihood of false
    positives helps in efficiently using resources, but at the risk of missing some
    revenue-generating bundle configurations due to conservative predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we used a simple string argument for the `aggr` parameter.
    PyG, however, has a wide set of tools to incorporate a variety of aggregation
    methods into your models. We explore these in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 Advanced aggregation tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section explores more advanced aggregation tools within PyG. We begin by
    assigning distinct aggregation methods to different layers within a multilayer
    architecture. Next, we explore the combination of various aggregation strategies—such
    as `'mean'`, `'max'`, and `'sum'`—within a single layer. Finally, we revisit GCNs
    to examine the jumping knowledge (JK) method.
  prefs: []
  type: TYPE_NORMAL
- en: Using multiple aggregations across layers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In a multilayer GraphSAGE model, you can of course adjust the aggregation function
    at each layer independently. For example, you might use mean aggregation at the
    first layer to smooth features but switch to max aggregation at a subsequent layer
    to highlight the most significant of the resulting neighbor features.
  prefs: []
  type: TYPE_NORMAL
- en: As a first exercise in our exploration, let’s apply a couple of permutations
    of aggregations to two layers and see if these configurations outperform our previous
    results. We use the code from before, swapping out the `aggr` settings for `conv1`
    and `conv2`. For one model, we use *mean* for the first layer and *max* at the
    second. For the other model, we use *sum* for the first layer and *max* at the
    second. Table 3.4 summarizes the results.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.4 Classification performance for GraphSAGE models with different settings
    for neighborhood aggregation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Aggregation Type | F1 Score | Log Loss |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Mean (default)  | 0.7406  | 2.1214  |'
  prefs: []
  type: TYPE_TB
- en: '| Sum  | 0.7384  | 2.2496  |'
  prefs: []
  type: TYPE_TB
- en: '| Max  | 0.7449  | 2.1039  |'
  prefs: []
  type: TYPE_TB
- en: '| Layered: Mean → Max  | 0.7316  | 2.2041  |'
  prefs: []
  type: TYPE_TB
- en: '| Layered: Sum → Max  | 0.7344  | 2.345  |'
  prefs: []
  type: TYPE_TB
- en: We have middling results at best for our dataset. The model with only max aggregation
    outperforms the newer models. Let’s move on to combining several aggregations
    for each layer.
  prefs: []
  type: TYPE_NORMAL
- en: List aggregations and aggregation functions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In PyG, the concept of using a list for specifying aggregation functions allows
    you to customize your models with multiple aggregation strategies simultaneously.
    This feature is significant as it enables the model to use different aspects of
    graph data, potentially enhancing model performance by capturing various properties
    of the graph. In a way, you’re aggregating your aggregations. For instance, you
    could combine `'mean'`, `'max'`, and `'sum'` aggregations in a single layer to
    capture average, most significant, and summed structural properties of the neighborhood.
  prefs: []
  type: TYPE_NORMAL
- en: This works in PyG by passing a list of aggregation functions, either as strings
    or as `Aggregation` module instances, into the `MessagePassing` class. PyG resolves
    these strings against a predefined set of aggregation functions or can directly
    use an aggregation function as the `aggr` argument. For example, using the keyword
    `'mean'` invokes the `MeanAggregation()` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a universe of combinations to try, but let’s try two examples to
    demonstrate, mixing familiar aggregations, `''`max`''`, `''`sum`''`, and `''`mean`''`;
    and a set of more exotic aggregations, `SoftmaxAggregation` and `StdAggregation`
    [3]. They can be applied to our `conv1` layer as follows (table 3.5 compares these
    results with previous results):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Table 3.5 Classification performance for GraphSAGE models with list aggregations
    added
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Aggregation type | F1 score | Log loss |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Mean (default)  | 0.7406  | 2.1214  |'
  prefs: []
  type: TYPE_TB
- en: '| Sum  | 0.7384  | 2.2496  |'
  prefs: []
  type: TYPE_TB
- en: '| Max  | 0.7449  | 2.1039  |'
  prefs: []
  type: TYPE_TB
- en: '| Layered: Mean →Max  | 0.7316  | 2.2041  |'
  prefs: []
  type: TYPE_TB
- en: '| Layered: Sum →Max  | 0.7344  | 2.345  |'
  prefs: []
  type: TYPE_TB
- en: '| List (standard)  | 0.7484  | 2.622  |'
  prefs: []
  type: TYPE_TB
- en: '| List (exotic)  | 0.745  | 2.156  |'
  prefs: []
  type: TYPE_TB
- en: Figure 3.5 visualizes the performance comparison from table 3.5\. While the
    F1 scores are very similar, there is a slight performance boost in F1 score from
    the “standard” list aggregation, though with the drawback of a much higher log
    loss.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-5.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 Performance comparison visualized from table 3.5\. While the F1 scores
    are very similar, the standard list aggregation performs slightly better with
    respect to log loss.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Given the results of our quick survey of these aggregation methods applied to
    the GraphSAGE layer, you might conclude that sticking with the default setting
    is often the best option. However, the potential for performance improvements
    through tailored aggregation strategies suggests that further exploration could
    be beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming section 3.2.3, we’ll review some considerations in applying
    these aggregation methods. Before that, we’ll come back to the GCN layer to examine
    the JK aggregation method.
  prefs: []
  type: TYPE_NORMAL
- en: Jumping knowledge networks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Jumping knowledge* (JK) is a novel approach for node representation learning
    on graphs that addresses limitations of existing models such as GCNs and GraphSAGE
    [4]. It focuses on overcoming a problem of neighborhood aggregation models in
    which models are sensitive to the graph’s structure, causing inconsistent learning
    quality across different graph parts.'
  prefs: []
  type: TYPE_NORMAL
- en: Jumping knowledge networks (JK-Nets) allow flexible usage of different neighborhood
    ranges for each node, thereby adapting to local neighborhood properties and task-specific
    requirements. This adaptation results in improved node representations by enabling
    the model to selectively use information from various neighborhood depths based
    on the node and the subgraph’s context. JK has been implemented for the GCN layer
    in PyG, as shown in listing 3.6\.
  prefs: []
  type: TYPE_NORMAL
- en: 'Its main parameter, `mode`, specifies the aggregation scheme used to combine
    outputs from different layers. The options are listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`''cat''`—Concatenates the outputs from all layers along the feature dimension.
    This approach preserves all information from each layer but increases the dimensionality
    of the output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`''max''`—Applies max pooling across the layer outputs. This method takes the
    maximum value across all layers for each feature, which can help in capturing
    the most significant features from the graph while being robust against less informative
    signals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`''lstm''`—Uses a bidirectional LSTM to learn attention scores for each layer’s
    output. The outputs are then combined based on these learned attention weights,
    allowing the model to focus on the most relevant layers dynamically based on the
    input graph structure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Listing 3.6 GCN class with `JumpingKnowledge` layer
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Initializes JK with concatenation mode'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 List to save outputs from each layer for JK'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Appends the layer outputs list'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Applies JK aggregation to the collected layer outputs'
  prefs: []
  type: TYPE_NORMAL
- en: In the listing, for the initialization, a `JumpingKnowledge` layer is initialized
    with the mode set to `'cat'` (concatenate), indicating that the features from
    each layer will be concatenated to form the final node representations.
  prefs: []
  type: TYPE_NORMAL
- en: In the forward pass, `layer_outputs` is initialized as an empty list to store
    the outputs from each convolutional layer. This list will be used by the `JumpingKnowledge`
    layer.
  prefs: []
  type: TYPE_NORMAL
- en: The first convolutional layer processes the input `x` and the graph structure
    `edge_index`, and applies a ReLU activation function to introduce nonlinearity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output of the first layer (`x1`) is then added to the `layer_outputs` list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After the second convolutional layer, the second output (`x2`) is also added
    to the `layer_outputs` list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, the `JumpingKnowledge` layer takes the list of outputs from all the previous
    layers and aggregates them according to the specified mode (`'cat'`). In concatenation
    mode, the feature vectors from each layer are concatenated along the feature dimension.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Table 3.6 compares the classification performance for GCN models. The baseline
    GCN model from section 3.1 is compared to a version using the `JumpingKnowledge`
    aggregation method. The baseline model has a better F1 score, while the JK model
    outperforms in log loss.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.6 Classification performance for GCN models
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Model | F1 Score | Log Loss |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Baseline GCN  | 0.781  | 1.42  |'
  prefs: []
  type: TYPE_TB
- en: '| JK (GCN)  | 0.699  | 1.36  |'
  prefs: []
  type: TYPE_TB
- en: The results show that choosing between the baseline and JK versions involves
    a tradeoff between higher recall/precision and higher prediction certainty. This
    tradeoff should be carefully considered based on the specific requirements and
    goals of the task at hand. Further exploration in section 3.2.3 will review some
    considerations in applying these aggregation methods effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.3 Practical considerations in applying aggregation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Choosing the right aggregation method is a technical decision that should be
    informed by the specific characteristics and needs of the dataset at hand as well
    as the use case. For datasets where the local neighborhood structure is crucial,
    using mean or sum aggregations could potentially blur essential features. In contrast,
    max aggregation could help highlight critical attributes. For example, in a social
    network graph where influencer detection is key, max aggregation might be more
    effective. On the other hand, if what we want to do is represent typical features,
    max aggregation may overemphasize outliers. In a dataset of financial transactions,
    where we want to understand typical user behavior, a max aggregation could distort
    the common behavioral features in favor of one or two large but uncommon transactions.
  prefs: []
  type: TYPE_NORMAL
- en: The task itself can dictate the choice of aggregation method. Tasks that require
    capturing the most influential features might benefit from max aggregation, while
    those needing a general representation may find mean aggregation sufficient. In
    a recommendation system for products, max aggregation could help identify the
    most important product features that drive purchases. Additionally, the nature
    of the graph’s topology should guide the aggregation method. Densely connected
    graphs might require different strategies compared to sparsely connected graphs
    to avoid over-smoothing or underrepresentation of node features. For instance,
    a transportation network graph with varying node connectivity might need different
    aggregations at different layers.
  prefs: []
  type: TYPE_NORMAL
- en: Given the dataset’s complexity, empirical testing of different aggregation methods
    is essential. Experimentation can help identify which methods best capture the
    relational dynamics and feature distributions of the dataset. This is particularly
    important for more exotic aggregation methods, where intuition alone may not suffice
    to determine their effectiveness. The scalability of the chosen aggregation method
    to handle millions of nodes and edges efficiently is also crucial. It’s important
    to balance computational efficiency with the sophistication of the method, especially
    for real-time applications such as recommendation systems.
  prefs: []
  type: TYPE_NORMAL
- en: Aggregation methods should be considered alongside other model enhancements
    such as feature engineering, node embedding techniques, and regularization strategies
    to address overfitting and improve model generalization. For instance, combining
    effective aggregation methods with advanced embedding techniques (e.g., Node2Vec)
    or incorporating dropout for regularization could significantly boost model performance.
  prefs: []
  type: TYPE_NORMAL
- en: While there is no one-size-fits-all aggregation method, a thoughtful combination
    of techniques, backed by empirical validation, can significantly enhance model
    performance and applicability. This strategic approach not only aids in accurate
    product categorization but also in crafting effective recommendation systems that
    are crucial in e-commerce settings.
  prefs: []
  type: TYPE_NORMAL
- en: This section explored and applied different aggregations to our models. The
    next section will round out our exploration of convolutional GNNs by applying
    regularization and adjusting the depth of our models. We’ll consolidate our improvements
    into a final model, from which we’ll generate another product bundle based on
    the Marceline figurine to see if there is improvement.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Further optimizations and refinements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Up to now, the GCN and GraphSAGE layers have been introduced via a product
    management example. We established a baseline using the default settings in section
    3.1\. In section 3.2, we examined the use of neighborhood and layer aggregation.
    In this section, we’ll consider other ways we can refine and improve our model.
    In the first subsections, we’ll introduce two other adjustments: the use of dropout
    and model depth. Dropout is a well-known regularization technique that can reduce
    overfitting, and model depth is an adjustment that has a unique meaning for GNNs.'
  prefs: []
  type: TYPE_NORMAL
- en: In section 3.3.3, we synthesize these insights to develop a model that incorporates
    multiple improvements and observe the cumulative performance uplift. Finally,
    in section 3.3.4, we revisit our product bundle problem. We create a new product
    bundle using the refined model of section 3.3.3 and compare its performance to
    the bundle created in section 3.1.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.1 Dropout
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Dropout* is a regularization technique used to prevent overfitting in neural
    networks by randomly dropping units during training. This helps the model generalize
    better by reducing its dependency on specific neurons.'
  prefs: []
  type: TYPE_NORMAL
- en: In PyG, the `dropout` function works similarly to the standard PyTorch dropout,
    meaning it randomly sets some elements of the input tensor and the hidden-layer
    activations to `0` during the training process. During each forward pass in training,
    inputs and activations are set to `0` according to the specified dropout rate.
    This helps prevent overfitting by ensuring that the model doesn’t rely too heavily
    on any particular input or activation.
  prefs: []
  type: TYPE_NORMAL
- en: The structure of the graph, including its vertices (nodes) and edges, remains
    unchanged during dropout. The graph’s topology is preserved, and only the neural
    network’s activations are affected. This distinction is crucial as it maintains
    the integrity of the graph while still using dropout to improve model robustness.
    PyG does have functions that can drop nodes or drop edges during training, but
    the dropout built into `GCNConv` and `SAGEConv` refers to the traditional deep
    learning dropout.
  prefs: []
  type: TYPE_NORMAL
- en: In PyG, both the GraphSAGE and GCN layers use `dropout` rate as a parameter,
    with a default of 0\. Figure 3.6 illustrates the performance of GCN models with
    varying dropout rates (0%, 50%, and 85%). As shown, higher dropout rates can help
    mitigate overfitting, as indicated by the reduced gap between training and validation
    losses. For the 85% case, the higher dropout rate could be causing the model to
    converge more slowly, or it could be a sign of overfitting. More testing is warranted
    to find out.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s examine model depth and how it’s implemented for convolutional GNNs.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.2 Model depth
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In GNNs, a *layer* refers to the number of hops or message-passing steps. Each
    layer allows nodes to aggregate information from their immediate neighbors, effectively
    increasing the receptive field by one hop per layer. A three-layer model, for
    example, would interrogate the neighborhood three hops away from each node. The
    *depth* of a GNN, then, refers to the number of layers in the network, analogous
    to the depth in traditional deep learning models but with key differences due
    to graph-structured data.
  prefs: []
  type: TYPE_NORMAL
- en: If a GNN has too few layers, it may not capture sufficient information from
    the graph, leading to poor representation learning, as each node can only aggregate
    information from a limited neighborhood. Conversely, increasing the number of
    layers can lead to *over-smoothing*, where node features become too similar, making
    it difficult to distinguish between different nodes. With each additional layer,
    nodes aggregate information from a larger neighborhood, diluting the unique features
    of individual nodes. Various metrics and methods have been proposed to measure
    and mitigate this effect.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 Training curve comparisons of three models with different levels
    of dropout. The left has a dropout of 0%, the middle a dropout of 50%, and the
    right a dropout of 85%. For our model and dataset, adding dropout indeed ameliorates
    overfitting. The model with 85% dropout could show signs of either underfitting
    or slowly converging, requiring more experimentation.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The performance of GNNs with different depths can vary significantly. Typically,
    GNNs with 2 or 3 layers perform competitively on many tasks, balancing the need
    for sufficient neighborhood information without causing over-smoothing. While
    deeper GNNs can theoretically capture more complex patterns, they often suffer
    from over-smoothing and increased computational complexity. Very deep GNNs, such
    as those with 50 or more layers, can lead to higher validation loss, indicating
    over-fitting and/or over-smoothing.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.7 compares the performance of GNNs with different depths (e.g., 2 layers,
    10 layers, and 50 layers). We see that the 2-layer model achieves a good balance
    between training and validation loss. In the 10-layer GNNs, we see some improvement
    in training loss but also signs of over-smoothing from the higher validation loss.
    The 50-layer model shows degraded training and validation loss, which indicates
    severe over-smoothing or over-fitting.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.7 Training curves for trained models of different depths: 2 layers
    (top), 10 layers (middle), 50 layers (bottom). The 2-layer model has the best
    profile with no signs of overfitting or performance degradation.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Balancing the depth of the model is critical to achieving optimal performance
    in GNNs. Too few layers may result in weak representation learning, while too
    many layers can lead to over-smoothing, where node features become indistinguishable.
    In the next section, we apply what we’ve learned about tuning our model in this
    chapter, resulting in a refined model that will outperform our baseline.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.3 Improving the baseline model’s performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Given all the insights gained in this chapter, let’s train models that synthesize
    these learnings and compare them against the baseline. Some key takeaways from
    the previous sections that we’ll incorporate are listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Model depth*—We’ll keep it low, at two layers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Neighborhood aggregation*—We’ll use max aggregation and experiment with two
    list aggregations. The same aggregation will be used on both layers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Dropout*—We’ll use 50% dropout on both layers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following listing shows a GraphSAGE class with adjustable dropout, layer
    depth, and aggregations.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.7 GraphSAGE class
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '#1 The layer is initialized with number of layers, dropout rate, and aggregation
    type.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The loop applies the aggregation to each layer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We trained three models using the preceding class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Table 3.7 summarizes the performance of different GraphSAGE models with various
    aggregation methods and a baseline model using the default mean aggregation. The
    results indicate that all the improved models outperform the baseline in both
    F1 score and log loss. Notably, Model 2, which uses a combination of `'max'`,
    `'sum'`, and `'mean'` aggregations, achieved the highest F1 score of 0.8828\.
    Model 3, with a combination of `SoftmaxAggregation()` and `StdAggregation()`,
    shows the best log loss at 0.5764, suggesting it has the highest prediction certainty
    among the tested configurations.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.7 Two-layer GraphSAGE models using 50% dropout and different aggregation
    types
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| GraphSAGE Model | Aggregation Type | F1 Score | Log Loss |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Model 1  | `''max''`  | 0.8674  | 0.594  |'
  prefs: []
  type: TYPE_TB
- en: '| Model 2  | `[''max'', ''sum'', ''mean'']`  | 0.8876  | 0.660  |'
  prefs: []
  type: TYPE_TB
- en: '| Model 3  | `[SoftmaxAggregation(), StdAggregation()]`  | 0.8829  | 0.574  |'
  prefs: []
  type: TYPE_TB
- en: '| Baseline model  | Mean (default)  | 0.7406  | 2.1214  |'
  prefs: []
  type: TYPE_TB
- en: The confusion matrix in figure 3.8 visualizes the classification performance
    of Model 1 with max aggregation. The majority of values are along the diagonal,
    indicating that the model is correctly classifying most instances. However, there
    are off-diagonal elements, representing misclassifications, for example, instances
    of class 0 being classified as class 1 or vice versa. The frequency and spread
    of these misclassifications highlight areas where the model struggles. Additionally,
    using the bar on the side indicating the count of members per class, the confusion
    matrix shows how these different classes are distributed. Some classes have higher
    counts, while others have significantly lower counts, suggesting class imbalance
    in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 Confusion matrix from the two-layer GraphSAGE model with 50% dropout
    and max aggregation. The strong diagonal pattern indicates good classification
    performance. The sidebar gives a distribution of the classes, highlighting a class
    imbalance.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Note that, in all of this, we’ve been using less than 1% of the dataset’s nodes,
    arbitrarily chosen by index order. Increasing the number of nodes would improve
    the performance of our models. Additionally, selecting a subgraph in a more meaningful
    way while keeping the number of nodes the same could also increase performance.
  prefs: []
  type: TYPE_NORMAL
- en: While the current models show significant improvement, several other strategies
    can be considered to further enhance performance. Increasing the dataset size
    by using a larger subset can provide more training data, potentially improving
    model generalization. Refining subgraph selection based on domain knowledge or
    using graph sampling techniques can ensure that more meaningful data is used for
    training. Hyperparameter optimization, systematically tuning hyperparameters using
    tools such as Hyperopt, can help find the optimal settings for the model. Hyperopt
    allows for efficient searching of the hyperparameter space using algorithms such
    as Bayesian optimization. Exploring more sophisticated aggregation functions or
    custom aggregations tailored to the specific characteristics of the dataset can
    also yield improvements. Additionally, implementing regularization methods such
    as L2 regularization or gradient clipping can stabilize training and prevent over-fitting.
    Graph preprocessing techniques, such as normalization, feature engineering, and
    dimensionality reduction on graph features, can enhance the quality of input data,
    further boosting model performance. Next, we’ll select the model that performs
    highest on log loss to generate another product bundle.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.4 Revisiting the Marcelina product bundle
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The models have markedly improved from our baselines in section 3.1\. Let’s
    revisit the product bundling problem and recommend one for our product manager
    based on our refined GraphSAGE model from the earlier section. Using the process
    from section 3.1.5 results in the bundle in figure 3.9, which is displayed with
    the original bundle for comparison.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-9.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 Product bundles centered on the Marceline product. The upper bundle
    is from the improved model from section 3.3.3, while the lower bundle is from
    the baseline model of section 3.1.5\. The new recommendations are members of the
    Toy & Games, Books, and Movies & TV categories.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'What do you think of this new bundle? Is it an improvement, that is, more likely
    to drive purchases than the former bundle? This new bundle incorporates items
    from Toys & Games, Books, and Movies & TV categories, which is a diverse product
    selection. The introduction of the *Wild Kratts: Wildest Animal Adventures* DVD
    alongside the adventure book *The Sword of Shannara* and action figures reflects
    a pivot toward a more family-oriented and child-friendly product mix.'
  prefs: []
  type: TYPE_NORMAL
- en: This new bundle’s potential for driving purchases is grounded in the enhanced
    understanding of customer purchase behaviors and preferences captured by the updated
    model. The bundle seems well-suited for gifting purposes, catering to both the
    collectors of pop culture memorabilia (e.g., the Marceline figure and related
    collectibles) and young fans of fantasy and adventure narratives.
  prefs: []
  type: TYPE_NORMAL
- en: 'The shift from a more generic collection of toys to a focused, theme-oriented
    bundle could likely increase its attractiveness as a purchase. The inclusion of
    both entertainment (*Wild Kratts: Wildest Animal Adventures* DVD) and literary
    (*The Sword of Shannara*) elements, in addition to the collectible figures, provides
    a more comprehensive entertainment experience centered around popular themes of
    adventure and exploration. This could appeal to parents looking for engaging and
    themed gifts that also offer educational value, such as the animal- and nature-related
    content of Wild Kratts.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s crucial to consider the psychological effect of a well-curated bundle.
    By aligning the products more closely with identified customer interests and cross-selling
    patterns, the bundle not only caters to existing demand but also encourages additional
    purchases by enhancing perceived value by how the bundled items complement each
    other.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, the decision on whether this new bundle is an improvement over the
    original should be validated through customer feedback and sales data. Tracking
    the sales performance of both bundles (as well as bundles suggested by human product
    managers) and gathering direct customer insights through surveys or A/B testing
    would be beneficial to quantitatively assess which bundle performs better in terms
    of sales and customer satisfaction. This data-driven approach will confirm the
    theoretical benefits of the advanced modeling techniques used in the new bundle’s
    creation.
  prefs: []
  type: TYPE_NORMAL
- en: With this, we conclude the hands-on product example of this chapter. The next
    two sections are optional as they dive deeper into the theory of convolutional
    GNNs and take a closer look at the Amazon Products dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Under the hood
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we’ve created and refined a working convolutional GNN, let’s dig deeper
    into the elements of a GNN to better understand how they work. Such knowledge
    can help when we want to design new GNNs or troubleshoot a GNN.
  prefs: []
  type: TYPE_NORMAL
- en: In chapter 2, we introduced the idea of using GNN layers to produce a prediction
    or create embeddings using message passing. Here’s that architecture diagram again,
    reproduced in figure 3.10\.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get below the surface of a GNN layer and examine its elements. Then, we’ll
    tie this to the concept of aggregation functions.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-10.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 Node embedding architecture diagram from chapter 2
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 3.4.1 Convolution methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s first consider one of the most popular architectures for deep learning,
    the convolutional neural network (CNN). CNNs are typically used for computer vision
    tasks such as segmentation or classification. A CNN layer can be thought of as
    having a sequence of operations that are applied to input data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Layer: Filter → Activation function → Pooling'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of each entire layer is some transformed data that makes some downstream
    task easier or more successful. These transformation operations include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Filter (or kernel operation)*—A process that transforms the input data. The
    filter is used to highlight some specific features of the input data and consists
    of learnable weights that are optimized by an objective or loss function.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Activation Function*—A nonlinear transformation applied to the filter output.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Pooling*—An operation that reduces the size of the filter output for subsequent
    learning tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CNNs and many GNNs share a common foundation: the concept of convolution. You
    read about the concept of convolution when we discussed the three operations used
    in a CNN. Convolution in both CNNs and GNNs is all about learning by establishing
    *hierarchies of localized patterns* in the data. For CNNs this might be used for
    image classification, whereas a convolutional GNN, such as a GCN, might use convolution
    to predict features of nodes. To emphasize this point, CNNs apply convolution
    to a fixed grid of pixels to identify patterns in the grid. GCN models apply convolution
    to graphs of nodes to identify patterns in the graph.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I referred to the *concept* of convolution in the previous paragraph because
    the convolution can be implemented in different ways. Theoretically, convolution
    relates to the mathematical convolution operator, which we’ll be discussing in
    more detail shortly. For GNNs, convolution can be separated into spatial and spectral
    methods [1, 5, 6]:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Spatial*—Sliding a window (filter) across a graph.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Spectral*—Filtering a graph signal using spectral methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spatial methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In traditional deep learning, convolutional processes learn data representations
    by applying a special filter called a *convolutional kernel* to input data. This
    kernel is smaller in size than the input data and is applied by moving it across
    the input data. This is shown in figure 3.11, where we apply our convolutional
    kernel (the matrix in the center) to an image of a lion. The resulting image has
    been inverted due to our convolutional kernel, which has negative values for all
    non-center elements. We can see that some of the features have been emphasized,
    such as the outline of the lion. This highlights the filtering aspect of convolutions.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-11.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 A convolution of an input image (left). The kernel (middle) is passed
    over the image of an animal, resulting in a distinct representation (right) of
    the input image. In a deep learning process, the parameters of the filter (the
    numbers in the matrix) are learned parameters.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This use of convolutional networks is particularly common in the computer vision
    domain. For example, when learning on 2D images, we can apply a simple CNN of
    a few layers. In each layer, we pass a 2D filter (kernel) over each image. The
    3 × 3 filter works on an image many times its size. We can produce learned representations
    of the input image by doing this over successive layers.
  prefs: []
  type: TYPE_NORMAL
- en: For graphs, we want to apply this same idea of moving a window across our data,
    but now we need to make adjustments to account for the relational and non-Euclidian
    topology of our data. For images, we’re dealing with rigid 2D grids; for graphs,
    we’re dealing with data that has no fixed shape or order. Without a predefined
    ordering of the nodes in a graph, we use the concept of a *neighborhood*, consisting
    of a starting node, and all of its one-hop neighbors (i.e., all nodes within one
    hop from the central node). Then, our sliding window moves across a graph by moving
    across its node neighborhoods.
  prefs: []
  type: TYPE_NORMAL
- en: In figure 3.12, we see an illustration comparing convolution applied to grid
    data and applied to graph data. In the grid case, pixel values are filtered around
    the nine pixels immediately surrounding the central pixel (marked with a gray
    dot). However, for a graph, node attributes are filtered based on all nodes that
    can be connected by one edge. Once we have the nodes that we’ll be considering,
    we then need to perform some operation on the nodes. This is known as the *aggregation
    operation*; for example, all the node weights in a neighborhood might be averaged
    or summed, or we might take the max value. What is important for graphs is that
    this operation is *permutation invariant*. The order of the nodes shouldn’t matter.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-12.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 A comparison of convolution over grid data (left; e.g., a 2D image)
    and over a graph (right).
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Spectral methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To introduce the second method of convolution, let’s examine the concept of
    a graph signal [6]. In the field of information processing, *signals* are sequences
    that can be examined in either time or frequency domains. When studying a signal
    in the time domain, we consider its dynamics, namely how it changes over time.
    From the frequency domain, we consider how much of the signal lies within each
    frequency band.
  prefs: []
  type: TYPE_NORMAL
- en: We can also study the signal of a graph in an analogous way. To do this, we
    define a graph signal as a vector of node features. Thus, for a given graph, its
    set of node weights can be used to construct its signal. As a visual example,
    in figure 3.13, we have a graph with values associated with each node, where the
    height of each respective bar represents some node feature.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-13.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.13 A random positive graph signal on the vertices of the graph. The
    height of each vertical bar represents the signal value at the node where the
    bar originates.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: To operate on this graph signal, we represent the graph signal as a matrix,
    where each row is a set of features associated with a particular node. We can
    then apply operations from signal processing on the graph matrix. One critical
    operation is that of the Fourier transform. The Fourier transform can express
    a graph signal, its set of node features, into a frequency representation. Conversely,
    an inverse Fourier transform will revert the frequency representation into a graph
    signal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Above and beyond: Limitations of traditional deep learning methods to graphs'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Why can’t we apply CNNs directly to a graph structure? The reason is because
    graph representations have an ambiguity that image representations don’t. CNNs,
    and traditional deep learning tools in general, can’t resolve this ambiguity.
    A neural network that can deal with this ambiguity is said to be *permutation
    equivariant* or *permutation invariant*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s illustrate the ambiguity of a graph versus an image by considering the
    image of the lion shown earlier. A simple representation of this set of pixels
    is as a 2D matrix (with dimensions for height and width). This representation
    will be unique: if we swap out two rows of the image, or two columns, we don’t
    have an equivalent image. Similarly, if we swap out two columns or rows of the
    matrix representation of the image (as shown in figure 3.14), we don’t have an
    equivalent matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-14.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.14 The image of a lion is unique (left). If we swap out two columns
    (right), we end up with a distinct photo with respect to the original.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This isn’t the case with a graph. Graphs can be represented by adjacency matrices
    (described in chapter1 and appendix A), such that each row and column element
    stands for the relation between two nodes. If an element is nonzero, it means
    that the row node and column node are linked. Given such a matrix, we can repeat
    our previous experiment and swap out two rows as we did with the image. Unlike
    the case of the image, we end up with a matrix that represents the graph we started
    with. We can do any number of permutations or rows and columns and end up with
    a matrix that represents the same graph.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to the convolution operation, to successfully apply a convolutional
    filter or a CNN to the graph’s matrix representation, such an operation or layer
    would have to yield the same result no matter the ordering of the adjacency matrix
    (because every ordering describes the same thing). CNNs fail in this respect.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finding convolutional filters that can be applied to graphs has been solved
    in a variety of ways. In this chapter, we examined two ways this has been done:
    spatial and spectral methods. (For a deeper discussion and derivation of convolutional
    filters applied to graphs, see [7].)'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.2 Message passing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Both spatial and spectral approaches describe how we can combine data on our
    graph. Spatial methods look at the graph structure and combine data across spatial
    neighborhoods. Spectral methods look at the graph signal and use methods from
    signal processing, such as the Fourier transform to combine data across the graph.
    Implicit to both these methods is the idea of message passing.
  prefs: []
  type: TYPE_NORMAL
- en: In chapter 3, we introduced message passing as a way to extract more information
    from our graphs. Let’s go step-by-step and consider what message passing does.
    First, the messages from each node or edge are collected from neighboring nodes.
    Second, we transform these messages to encode the data as feature vectors. Finally,
    we update the node or edge data to include these messages. The result is that
    each node or edge ends up containing individual data as well as data from the
    rest of the graph. The amount of data that becomes encoded in these nodes is reflected
    by the number of hops or message-passing steps. This is the same as the number
    of layers in a GNN. In figure 3.15, we show a mental model for message passing.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-15.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.15 Elements of our message-passing layer. Each message-passing layer
    consists of an aggregation, a transformation, and an update step.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The output of each message-passing layer is a set of embeddings or features.
    In the aggregation step, we gather the messages from the graph neighborhoods.
    In the transformation step, we apply a neural network to the aggregated messages.
    Finally, in the update step, we alter the features of the nodes or edges to include
    the message passing data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this way, a GNN layer is similar to a CNN layer. It can be interpreted as
    a sequence of operations that are applied to input data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Layer: Aggregate → Transform → Update'
  prefs: []
  type: TYPE_NORMAL
- en: As we explore different GNNs in this book, we’ll return to this set of operations,
    as most types of GNNs can be seen as modifications of these elements. For example,
    in this chapter, you’re learning about GCNs as a specific type of aggregation.
    In the next chapter, you’ll learn about GATs, which combine both transformation
    and aggregation steps by learning how to aggregate messages using an attention
    mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: To build this message-passing step, let’s work through the preceding process,
    adding more detail. The first two steps can be understood as a type of filter,
    similar to the first step of a conventional neural network. First, we aggregate
    node or edge datausing our *aggregation operator*. For example, we might sum the
    features, average the features, or choose the maximum values. The most important
    thing is that the order of the nodes shouldn’t matter for the final representation.
    The reason that the order shouldn’t matter is that we want our models to be permutation
    equivariant, which means that subtraction or division wouldn’t be suitable.
  prefs: []
  type: TYPE_NORMAL
- en: Once we’ve aggregated information from all node or collected all the messages,
    we then transform them into *embeddings* by passing the new messages through a
    neural network and an activation function. Once we have these transformed embeddings,
    we apply an activation function and then combine them with the node or edge data
    and the previous embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: The activation function is a nonlinear transformation that is applied to the
    transformed and aggregated messages. We need the function to be nonlinear; otherwise,
    the model would be linear, regardless of how many layers it has, similar to a
    linear (or logistic, in our case) regression model. These are standard activation
    functions used in artificial neural networks, such as the ReLU, which is the maximum
    value between zero and the input value. The pooling step then reduces the overall
    size of the filter output for any graph-level learning tasks. For node prediction,
    this can be omitted, which we’ll do here.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can combine the previous description into a single expression for the message-passing
    operation. First, let’s assume that we’re working with node embeddings as we’ll
    do in this chapter. We want to transform the data for node *n* into a node embedding.
    We can do so using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: (3.1)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-1.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *u* represents the nodes. The learnable weights are given by *W*[a], which
    will be tuned based on the loss function, and *σ* is the activation function.
    To build the embeddings, we need to take all the node data and combine it into
    a single vector. This is where the aggregation function comes in. For GCNs, the
    aggregation operator is summation. Therefore,
  prefs: []
  type: TYPE_NORMAL
- en: (3.2)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'where, for node *u,* *h*[v]is data from node *v* in the neighborhood of node
    *u*, *N(u)*. Combining both equations, we can construct a general formula for
    constructing node embeddings:'
  prefs: []
  type: TYPE_NORMAL
- en: (3.3)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-3.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For the preceding formula, we see that a node and its neighborhood play a central
    part. Indeed, this is one of the main reasons that GNNs have proven to be so successful.
    We also see that we need to make a choice on both our activation function and
    our aggregation function. Finally, these are updated to include the previous data
    at each node:'
  prefs: []
  type: TYPE_NORMAL
- en: (3.4)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-4.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we’re concatenating the messages together. It’s also possible to use other
    methods to update the message information, and the choice depends on the architecture
    used.
  prefs: []
  type: TYPE_NORMAL
- en: This update equation is the essence of message passing. For each layer, we’re
    *updating* all the node data using the *transformed* data that contains all *aggregated*
    messages. If we have only one layer, we perform this operation only once, we’re
    aggregating the information from the neighbors one hop away from our starting
    node. If we run these operations for multiple iterations, we aggregate nodes within
    two hops of our central node into the node feature data. Thus, the number of GNN
    layers is directly tied to the size of the neighborhoods we’re interrogating with
    our model.
  prefs: []
  type: TYPE_NORMAL
- en: These are the fundamentals for what operations are being performed during a
    message-passing step. The variations of things such as aggregation or activation
    functions highlight key differences in the architecture of a GNN.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.3 GCN aggregation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The key distinction between GCN and GraphSAGE is that they perform different
    aggregation operations. GCN is a spectral-based GNN, whereas GraphSAGE is a spatial
    method. To better understand the difference between the two, let’s look at implementing
    them both.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to understand how to apply convolution to graphs. Mathematically,
    the convolutional operation can be expressed as the combination of two functions
    that produces a third function as
  prefs: []
  type: TYPE_NORMAL
- en: (3.5)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'where *f*(*x*) and *h*(*x*) are functions, and the operator represents element-wise
    multiplication. In the context of CNNs, the image and the kernel matrices are
    the functions in equation 3.6:'
  prefs: []
  type: TYPE_NORMAL
- en: (3.6)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'This mathematical operation is interpreted as the kernel sliding over the image,
    as in the sliding window method. We can convert the preceding description to matrices
    or tensors describing our data. To apply the convolution of equation 3.7 to graphs,
    we use the following ingredients:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Matrix representations of the graph:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vector **x** as the graph signal
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Adjacency matrix **A**
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Laplacian matrix **L**
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A matrix of eigenvectors of the Laplacian **U**
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A parameterized matrix for the weights, **H**
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fourier transform based on the matrix operations: **U**^T**x**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This leads to the expression for spectral convolution over a graph:'
  prefs: []
  type: TYPE_NORMAL
- en: (3.7)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-7.png)'
  prefs: []
  type: TYPE_IMG
- en: Because this operation isn’t a simple element-wise multiplication, we’re using
    the symbol *[G] to express this operation. Several convolutional-based GNNs build
    on equation 3.8; next, we’ll examine the GCN version.
  prefs: []
  type: TYPE_NORMAL
- en: GCNs introduced changes to the convolution equation (3.8) to simplify operations
    and to reduce computational cost. These changes include using a filter based on
    a polynomial rather than a set of matrices and limiting the number of hops to
    one. This reduces the computational complexity from quadratic to linear, which
    is significant. However, the key thing to note is that GCNs updated the aggregation
    function that we described earlier. This will still use a summation but includes
    a normalization term.
  prefs: []
  type: TYPE_NORMAL
- en: Previously, the aggregation operator was summation. This can lead to problems
    in graphs where the degree of nodes can have high variance. If a graph contains
    nodes whose degrees are high, those nodes will dominate. To solve this, one method
    is to replace summation with averaging. The aggregation function is then expressed
    as
  prefs: []
  type: TYPE_NORMAL
- en: (3.8)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-8.png)'
  prefs: []
  type: TYPE_IMG
- en: Therefore, for GCN message passing, we have
  prefs: []
  type: TYPE_NORMAL
- en: (3.9)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-9.png)'
  prefs: []
  type: TYPE_IMG
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '*h* is the updated node embedding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: sigma, *σ*, is a nonlinearity (i.e., activation function) applied to every element.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: W is a trained weight matrix.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|*N *| denotes the count of the elements in the set of graph nodes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The summed factor,
  prefs: []
  type: TYPE_NORMAL
- en: (3.10)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'is a special normalization called *symmetric normalization*. Additionally,
    GCNs include self-loops such that node embeddings include both neighborhood data
    and data from the starting node. So, to implement a GCN, the following operations
    must occur:'
  prefs: []
  type: TYPE_NORMAL
- en: Graph nodes adjusted to contain self-loops
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matrix multiplication of the trained weight matrix and the node embeddings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normalization operations summing the terms of the symmetric normalization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In figure 3.16, we explain each of the terms used in a message-passing step
    in detail.
  prefs: []
  type: TYPE_NORMAL
- en: So far this has all been theoretical. Let’s next look at how we implement this
    in PyG.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-16.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.16 Mapping of key computational operations in the GCN embedding formula
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 3.4.4 GCN in PyTorch Geometric
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the PyG documentation, you can find source code that implements the GCN layer,
    as well as a simplified implementation of the GCN layer. In the following, we’ll
    point out how the source code implements the preceding key operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In table 3.8, we break down key steps in the computation of the GCN embeddings
    and tie them to functions in the source code. These operations are implemented
    using a class and a function:'
  prefs: []
  type: TYPE_NORMAL
- en: Function `gcn_norm` performs normalization and add self-loops to the graph.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Class `GCNConv` instantiates the GNN layer and performs matrix operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Table 3.8 Mapping key computational operations in the GCN embedding formula
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Operation | Function/Method |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Add self-loops to nodes  | `gcn_norm()`, annotated in listing 3.8  |'
  prefs: []
  type: TYPE_TB
- en: '| Multiply weights and embeddings *W*^(^(*k*)^)*h*[u]  | `GCNConv.__init__`;
    `GCNConv.forward`  |'
  prefs: []
  type: TYPE_TB
- en: '| Symmetric normalization  | `gcn_norm()`, annotated in listing 3.8  |'
  prefs: []
  type: TYPE_TB
- en: 'In listing 3.8, we show the code in detail for the `gcn_norm` function and
    class and use annotation to highlight the key operations. This normalization function
    is a key aspect for the GCN architecture. The `gcn_norm` arguments are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`edge_index`—The node representations are in a tensor or sparse tensor form.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`edge_weight`—An array of one-dimensional edge weights is optional.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_nodes`—This is a dimension of the input graph.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`improved`—This introduces an alternative method to add self-loops from the
    Graph U-Nets paper [8].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Add_self_loops`—Adding self-loops is the default, but it’s optional.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Listing 3.8 The `gcn_norm` function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Performs symmetric normalization of the input graph and adds a self-loop
    to the input graph'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The fill_value parameter is used in the alternative self-loop operation.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 If the graph input is a sparse tensor, the first block of code in the if-statement
    will apply. Otherwise, the second will apply.'
  prefs: []
  type: TYPE_NORMAL
- en: In practice, we can simplify the implementation of the normalization considerably
    by using some functions from PyTorch and PyG. In listing 3.9, we show a shortened
    version of normalizing the adjacency matrix. First, we compute the in-degree for
    each node and then calculate the inverse square root. We then use this to create
    a new edge weighting and apply the degree-based inverse square root to this weighting.
    Finally, we create a sparse tensor that represents the adjacency matrix and assign
    this to our data.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.9 Normalizing using PyTorch and PyG
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Assumes node indices start from 0'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Computes in-degree for each node'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Computes the degree-based inverse square'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Creates a new edge_weight tensor'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Applies deg_inv_sqrt to edge weights'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Assumes node indices start from 0'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Creates a sparse tensor and assigns to data'
  prefs: []
  type: TYPE_NORMAL
- en: In the following listing, we have excerpts of the `GCNConv` class, which calls
    on the `gcn_norm` function as well as the matrix operations.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.10 The `GCNConv` class
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '#1 The forward propagation function performs symmetric normalization given
    one of two options: that the input graph is a tensor or a sparse tensor. The source
    code for a tensor input is included here.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Linear transformation of the node feature matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Message propagation'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 There is an optional additive bias to the output.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.5 Spectral vs. spatial convolution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous section, we talked about interpreting convolution in two ways:
    (1) via a thought experiment of sliding a window filter across part of a graph
    consisting of a local neighborhood of linked nodes, and (2) by processing graph
    signal data through a filter. We also discussed how these two interpretations
    highlight two branches of convolutional GNNs: the spatial method and the spectral
    method. Sliding window and other spatial methods rely on a graph’s geometrical
    structure to perform convolution. Spectral methods instead use graph signal filters.'
  prefs: []
  type: TYPE_NORMAL
- en: There is no clear demarcation between the spectral and spatial methods, and
    often one type can be interpreted as the other. For example, one contribution
    of GCN is the demonstration that its spectral derivation could be interpreted
    in a spatial way. However, at the time of writing, spatial methods are preferred
    because they have fewer restrictions and, in general, offer less computational
    complexity. We’ve highlighted additional aspects of both spectral and spatial
    methods in table 3.9.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.9 A comparison of spectral and spatial convolutional methods
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Spectral | Spatial |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Operation: performing a convolution using a graph’s eigenvalues  | Operation:
    aggregation of node features in node neighborhoods  |'
  prefs: []
  type: TYPE_TB
- en: '| • Must be undirected • Operation dependent on node features'
  prefs: []
  type: TYPE_NORMAL
- en: • Generally less computationally efficient
  prefs: []
  type: TYPE_NORMAL
- en: '| • Not required to be undirected • Operation not dependent on node features'
  prefs: []
  type: TYPE_NORMAL
- en: • Generally more computationally efficient
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.6 GraphSAGE aggregation function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GraphSAGE improved on the computational cost of GCNs by limiting the number
    of neighboring nodes used in the aggregation operation. Instead, GraphSAGE aggregates
    from a randomly selected sample of the neighborhood. The aggregation operator
    is more flexible (e.g., it can be a summation or an average), but the messages
    that are considered are now only a subset of all messages. Mathematically, we
    can write this as
  prefs: []
  type: TYPE_NORMAL
- en: (3.11)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-11.png)'
  prefs: []
  type: TYPE_IMG
- en: where Ɐ*u* ϵ *S* denotes that the neighborhood is picked from a random sample,
    *S,* of the total neighborhood. From the GraphSAGE paper [2], we have the general
    embedding updating process, which the paper introduces as Algorithm 1, reproduced
    here in figure 3.17.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-17.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.17 Algorithm 1, the GraphSAGE embedding generation algorithm from the
    GraphSAGE paper [2]
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The basics of this algorithm can be described as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For every layer/iteration *and* for every node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Aggregate the embeddings of the neighbors.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Concatenate neighbor embeddings with the central node.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Matrix multiply that concatenation with the Weights matrix.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Multiply that result with an activation function.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply a normalization.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Update node features, z, with node embeddings, h.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s take a closer look at what this means for the message-passing step. We’ve
    defined message passing for GraphSAGE as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: (3.12)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-13.png)'
  prefs: []
  type: TYPE_IMG
- en: If we choose the mean as the aggregation function, this becomes
  prefs: []
  type: TYPE_NORMAL
- en: (3.13)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-14.png)'
  prefs: []
  type: TYPE_IMG
- en: For implementation, we can further reduce this to
  prefs: []
  type: TYPE_NORMAL
- en: (3.14)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/Equation-3-15.png)'
  prefs: []
  type: TYPE_IMG
- en: where *x'*[i] denotes the generated central node embeddings, and *x*[i] and
    *x*[j] are the input features of the central and neighboring nodes, respectively.
    The weight matrices are applied to both central nodes and neighboring nodes, as
    shown in figure 3.18, but only the neighboring nodes have an aggregation operator
    (in this case, the mean).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-18.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.18 Mapping key computational operations in the GraphSAGE embedding
    formula
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We’ve now seen all the main features of the GraphSAGE algorithm. Let’s next
    look at how we implement this in PyG.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.7 GraphSAGE in PyTorch Geometric
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In table 3.10, we break down the key operations and where they occur in PyG’s
    GraphSAGE class. The key operations are aggregation of the neighbor embeddings,
    concatenation of a node’s neighbors’ embeddings with that node’s embeddings, multiplication
    of weights with the concatenation, and application of an activation function.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.10 Mapping key computational operations in the GCN embedding formula
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Operation | Function/Method |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Aggregate the embeddings of the neighbors (sum, mean, or other).  | `SAGEConv.message_and_aggregate`  |'
  prefs: []
  type: TYPE_TB
- en: '| Concatenate neighbor embeddings with that of the central node.  | `SAGEConv.forward`  |'
  prefs: []
  type: TYPE_TB
- en: '| Matrix multiply that concatenation with the Weights matrix.  | `SAGEConv.message_and_aggregate`  |'
  prefs: []
  type: TYPE_TB
- en: '| Apply an activation function.  | If the `project` parameter is set to `True`,
    done in `SAGEConv.forward`  |'
  prefs: []
  type: TYPE_TB
- en: '| Apply a normalization.  | `SAGEConv.forward`  |'
  prefs: []
  type: TYPE_TB
- en: For GraphSAGE, PyG also has source code to implement this layer in the `SAGEConv`
    class, excerpts of which are shown in the following listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.11 The GraphSAGE class
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '#1 If the project parameter is set to True, this applies a linear transformation
    with an activation function (ReLU, in this case) to the neighbor nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Propagates messages and applies a linear transformation'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Assigns the root node to a variable'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 If the root_weight parameter is set to True and a root node exists, this
    will add (concatenate) the transformed root node features to the output.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 If the normalize parameter is set to True, L2 normalization will be applied
    to the output features.'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Matrix multiplication with an aggregation. Setting the aggr parameter establishes
    the aggregation scheme (e.g., mean, max, lstm; default is add). adj_t is the sparse
    matrix representation of the input; using such a representation speeds up calculations.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Amazon Products dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In both this chapter and chapter 5, we use the Amazon Products dataset [9].
    This dataset explores product relationships, particularly co-purchases, which
    are products purchased in the same transaction. This co-purchase data is a great
    dataset for benchmarking methods for predicting both nodes and edges. We give
    a bit more information about the dataset in this section.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate the concept of co-purchases, in figure 3.19, we show six example
    co-purchase images for an online customer. For each product, we include a picture,
    a plain text product label, and a bold text category label.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-19.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.19 Examples of co-purchases on Amazon.com. Each product is represented
    by a picture, a plain text product title, and a bold text product category. We
    see that some co-purchases feature products that are obvious complements of one
    another, while other groupings are less so.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Some of these co-purchase groups seem to fit together well, such as the book
    purchases or the clothing purchases. Other co-purchases are less explainable,
    such as an Apple iPod being purchased with instant meals, or beans being purchased
    with a wireless speaker. In those less obvious groupings, there may be some latent
    product relationship, or maybe it’s just mere coincidence. Examining the data
    at scale can provide clues.
  prefs: []
  type: TYPE_NORMAL
- en: To show how the co-purchasing graph would appear at a small scale, figure 3.20
    takes one of the images from the previous figure and represents the products as
    nodes, with the edges between them representing each co-purchase. For one customer
    and one purchase, this is a small graph, with only four nodes and six edges. But
    for the same customer over time, for a larger set of customers with the same tastes
    in food, or even all the customers, it’s easy to imagine how this graph can scale
    with more products and product connections branching from these few products.
  prefs: []
  type: TYPE_NORMAL
- en: The construction of this dataset is a long journey in itself, which is very
    much of interest to graph construction and the decisions that have to be made
    to get a meaningful and useful dataset. Put simply, this dataset was derived from
    purchasing log data from Amazon, which directly showed co-purchases, and from
    text data from product reviews, which was used to indirectly show product relationships.
    (For the in-depth story, see [8]).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-20.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.20 A graph representation of one of the co-purchases from figure 3.19\.
    Each product’s picture is a node, and the co-purchases are the edges (shown as
    lines) between the products. For the four products shown here, this graph is only
    the co-purchasing graph of one customer. If we show the corresponding graph for
    all customers of Amazon, the number of products and edges could feature tens of
    thousands of product nodes and millions of co-purchasing edges.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: To explore the product relationships, we can use the Amazon Products co-purchasing
    graph, a dataset of products that have been bought together in the same transaction
    (defined as a co-purchase). In this dataset, products are represented by nodes
    with both the type of product that was bought, which are the category labels,
    and some feature information. The feature information takes the product description
    and first applies a natural language processing (NLP) method, the bag-of-words
    algorithm, to convert the strings into numerical values. Then, to convert this
    into the same fixed length, the creators of the dataset used principal component
    analysis (PCA) to convert this into a vector of length 100\.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, co-purchases are represented by edges, which refers to two products
    that were bought together. In total, the dataset, `ogbn-products`, consists of
    2.5 million nodes (products) and 61.9 million edges (co-purchases). The dataset
    is provided through the Open Graph Benchmark (OGB) dataset, mentioned at the beginning
    of the chapter, with a usage license from Amazon. Each node has 100 features.
    There are 47 categories that are used as targets in a classification task. We
    note that the edges here are undirected and unweighted.
  prefs: []
  type: TYPE_NORMAL
- en: In figure 3.21, we see that the categories with the highest counts of nodes
    are Books (668,950 nodes), CDs & Vinyl (172,199 nodes), and Toys & Games (158,771
    nodes). The lowest are Furniture and Decor (9 nodes), Digital Music (6 nodes),
    and an unknown category (#508510) with 1 node.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/3-21.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.21 Distribution of node labels in the Amazon Products dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We also observe that many categories have very low proportions in the dataset.
    The mean count of nodes per label/category is 52,107; the median count is 3,653\.
    This highlights that there is a strong class imbalance in our dataset. This can
    pose a challenge for typical tabular results.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we explored the fundamentals of graph convolutional networks
    (GCNs) and GraphSAGE, two powerful architectures for learning on graph-structured
    data. We applied these models to a practical product categorization problem using
    the Amazon Products dataset, demonstrating how to implement, train, and refine
    GNNs. We also delved into the theoretical underpinnings of these models, examining
    concepts like neighborhood aggregation, message passing, and the distinctions
    between spectral and spatial convolution methods. By combining hands-on implementation
    with theoretical insights, this chapter has provided a comprehensive foundation
    for understanding and applying convolutional GNNs to real-world graph learning
    tasks. In the next chapter, we study a special convolutional GNN that uses the
    attention mechanism, the Graph Attention Network (GAT).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GCNs and GraphSAGE are GNNs that use convolution, done by spatial and spectral
    methods, respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These GNNs can be used in supervised and semi-supervised learning problems.
    We applied them to the semi-supervised problem of predicting product categories.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Amazon Products dataset, `ogbn-products`, consists of a set of products
    (nodes) linked by being purchased in the same transaction (co-purchases). Each
    product node has a set of features, including its product-category. This dataset
    is a popular benchmark for graph classification problems. We can also study how
    it was constructed to get insights on graph creation methodology.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting subgraphs based on domain knowledge or using graph sampling techniques
    ensures more meaningful data is used for training. This can improve the performance
    of the models by focusing on relevant parts of the graph.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different aggregation methods, such as mean, max, and sum, have varied effects
    on model performance. Experimenting with multiple aggregation strategies can help
    capture various properties of the graph data, potentially enhancing model performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring more sophisticated aggregation functions or custom aggregations tailored
    to the specific characteristics of the dataset can yield performance improvements.
    Examples include `SoftmaxAggregation` and `StdAggregation`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depth in GNNs is analogous to the number of hops or message-passing steps. While
    deeper models can theoretically capture more complex patterns, they often suffer
    from over-smoothing, where node features become too similar, making it difficult
    to distinguish between different nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Empirical testing of different aggregation methods and model configurations
    is essential. Experimentation helps determine which methods best capture the relational
    dynamics and feature distributions of the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
