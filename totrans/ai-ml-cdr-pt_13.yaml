- en: Chapter 12\. Concepts of Inference
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章\. 推理概念
- en: In the previous chapters of this book, you focused on *training* models using
    PyTorch and on how to create models that manage images (aka Computer Vision),
    text content (aka NLP), and sequence modelling. For the rest of this book, you’ll
    cover a lot of content around *using trained models* to make predictions from
    new data (aka *inference*) and in particular using large generative models for
    text-to-text and text-to-image generative AI.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前几章中，你专注于使用PyTorch来*训练*模型，以及如何创建管理图像（即计算机视觉）、文本内容（即自然语言处理）和序列建模的模型。在本书的剩余部分，你将涵盖大量关于*使用训练好的模型*从新数据中进行预测（即*推理*）的内容，特别是使用大型生成模型进行文本到文本和文本到图像的生成式AI。
- en: But before you jump into that, it’s important for you to understand the underlying
    data transfer technology. We’ve touched on it a little in the training chapters,
    but as you go deeper into ML—in either training or inference—it’s important for
    you to be able to understand the underlying concepts of tensors.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 但在你深入之前，了解底层的数据传输技术非常重要。我们在训练章节中略有涉及，但随着你深入到机器学习——无论是训练还是推理——理解张量的底层概念非常重要。
- en: Ultimately, no matter what data type you have, you’ll convert it into tensors
    to pass it *into* the model. Similarly, no matter the data type in which you want
    to present answers from the model to your users, you’ll get them back as tensors
    as well!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，无论你有什么类型的数据，你都需要将其转换为张量以传递给模型。同样，无论你希望以何种数据类型向用户展示模型的结果，你都会以张量的形式得到它们！
- en: In many cases, you’ll have helper functions, such as the *transformers* that
    you’ll see in [Chapter 15](ch15.html#ch15_transformers_and_transformers_1748549808974580)
    (which covers LLMs) and the *diffusers* that you’ll see in [Chapter 19](ch19.html#ch19_using_generative_models_with_hugging_face_diffuser_1748573005765373)
    (which handles image generation). And while you won’t be touching tensors with
    them, you’ll still be using them under the hood.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，你将拥有辅助函数，例如在第15章（涵盖LLMs）中看到的*transformers*，以及在第19章（处理图像生成）中看到的*diffusers*。虽然你不会直接使用张量，但它们仍然在幕后被使用。
- en: Tensors
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 张量
- en: A *tenso*r is an array that can have any number of dimensions. Tensors are typically
    used to represent numerical data for deep-learning algorithms; they’re containers
    that can hold numbers in multiple dimensions.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*张量*是一个可以具有任意数量维度的数组。张量通常用于表示深度学习算法的数值数据；它们是可以在多个维度中容纳数字的容器。
- en: Tensors can be simple scalar values (in zero dimensions), vectors (in one dimension),
    matrices (in two dimensions), and beyond (in three dimensions or more). In PyTorch,
    they’re the fundamental data structure for all computation.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 张量可以是简单的标量值（在零维度），向量（在一维），矩阵（在二维），以及更多（在三维或更多维度）。在PyTorch中，它们是所有计算的基本数据结构。
- en: Tensors are also the source of the name *TensorFlow* for the alternative deep-learning
    framework from Google.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 张量也是谷歌的替代深度学习框架*TensorFlow*名称的来源。
- en: 'Here are some examples of tensors in PyTorch, which were created using `torch.​ten⁠sor`:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些PyTorch中张量的例子，它们是通过使用`torch.tensor`创建的：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: What makes tensors so useful for ML is this flexibility to hold different value
    types. Numbers can be 0D tensors, the embedding vectors representing text can
    be 1D, and images can be 3D, with dimensions for height, width, and pixel value.
    Plus, all of these can have an additional dimension added for batches. So, for
    example, a single image can be a 3D matrix, but 100 images instead of 100 3D matrices
    could be a single 4D tensor, with the fourth dimension being the index of the
    image!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使张量对机器学习如此有用的原因是这种能够容纳不同值类型的灵活性。数字可以是0维张量，表示文本的嵌入向量可以是1维，图像可以是3维，具有高度、宽度和像素值维度。此外，所有这些都可以添加一个额外的维度用于批次。例如，单个图像可以是一个3维矩阵，但100个图像而不是100个3维矩阵可以是一个4维张量，第四维是图像的索引！
- en: When you’re using `torch.tensor`, keep in mind that a lot of work and investment
    has been put into optimizing them to run on GPUs, which makes them extremely efficient
    for deep learning computation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用`torch.tensor`时，请记住，已经投入了大量工作和投资来优化它们在GPU上的运行，这使得它们在深度学习计算中非常高效。
- en: Image Data
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像数据
- en: Images are typically stored in formats like JPEG or PNG, which are optimized
    for *human* viewing as well as storage efficiency. Each dot (or pixel) in the
    image is usually composed of a number of values, with each value being the intensity
    of a color channel. Typically, an image will have 24 bits of data, with 8 bits
    assigned each to red, green, and blue channels. If you see 32 bits, then the additional
    8 are for an alpha, or transparency, channel.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图像通常以JPEG或PNG等格式存储，这些格式既优化了**人类**的观看效果，也提高了存储效率。图像中的每个点（或像素）通常由多个值组成，每个值代表一个颜色通道的强度。通常，一个图像将包含24位数据，每个颜色通道分配8位。如果你看到32位，那么额外的8位是用于alpha通道，或透明度通道。
- en: So, for example, a green pixel might have values 0 on the red, blue, and alpha
    channels and 255 on the green channel. If it’s semi-transparent, it might still
    have a value of 0 on red and blue, 128 on alpha, and 255 on green.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个绿色的像素可能在红色、蓝色和alpha通道上的值为0，而在绿色通道上的值为255。如果它是半透明的，它可能在红色和蓝色通道上仍然有值为0，在alpha通道上有值为128，而在绿色通道上有值为255。
- en: An image file is typically *compressed*, which means that mathematical transforms
    have been applied to it to avoid wasted data and make the image smaller. An image
    can also contain metadata, file headers, and more. Then, once the image is loaded
    into memory, it is usually uncompressed to the 32-bits-per-pixel previously described.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图像文件通常是**压缩**的，这意味着已经对其应用了数学转换以避免数据浪费并减小图像大小。图像还可以包含元数据、文件头等信息。然后，一旦图像被加载到内存中，它通常会被解压缩到之前描述的每像素32位。
- en: ML models typically use values between –1 and 1, and not 0 to 255, as the native
    values of the image are stored. If we want to learn the details of an image, it’s
    good for us to standardize the values by focusing on the meaningful *variations*
    between the pixel intensities as opposed to just their values. So, one method
    is to standardize by figuring out how far the pixel value is from the mean and
    standard deviations. This gives a broader spectrum of values that can lead to
    smoother loss curves and more effective learning.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型通常使用介于-1和1之间的值，而不是图像存储的原始值0到255。如果我们想学习图像的细节，通过关注像素强度之间的**变化**而不是仅仅关注它们的值来标准化这些值是有益的。因此，一种方法是通过对像素值与平均值和标准偏差的距离进行标准化来实现。这给出了一组更广泛的价值范围，可以导致更平滑的损失曲线和更有效的学习。
- en: 'In PyTorch, you achieve this with code like this:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch中，你可以用如下代码实现：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This code uses a very popular Python library called Pillow, or just PIL.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码使用一个非常流行的Python库，称为Pillow，或简称PIL。
- en: In this case, the `PIL Image.open` will read the image, decompress it into pixels,
    and then apply a set of transforms to those pixels. The transforms normalize the
    channels into ML-friendly values, as described earlier, and then convert them
    into tensors.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`PIL Image.open`将读取图像，将其解压缩成像素，然后对这些像素应用一系列转换。这些转换将通道归一化到机器学习友好的值，如前所述，然后将它们转换为张量。
- en: The `input_tensor` is then a 3D matrix/tensor, but if we want to have a number
    of them in a single batch, we can *unsqueeze* this tensor to add a new dimension,
    making it a 4D tensor.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`input_tensor`随后是一个3D矩阵/张量，但如果我们想在单个批次中包含多个这样的张量，我们可以通过*unsqueeze*这个张量来添加一个新维度，使其成为一个4D张量。'
- en: You can see a single image in [Figure 12-1](#ch12_figure_1_1748549754439352)
    as a 3D tensor, with one dimension for each color depth.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将[图12-1](#ch12_figure_1_1748549754439352)中的单个图像视为一个3D张量，每个维度对应一个颜色深度。
- en: '![](assets/aiml_1201.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图像](assets/aiml_1201.png)'
- en: Figure 12-1\. Tensor representing a full-color image
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图12-1\. 表示全彩图像的张量
- en: And then, if there’s a batch of images, you can see it as a fourth dimension
    in [Figure 12-2](#ch12_figure_2_1748549754439405).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果有图像批次，你可以将其视为[图12-2](#ch12_figure_2_1748549754439405)中的第四维度。
- en: '![](assets/aiml_1202.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图像](assets/aiml_1202.png)'
- en: Figure 12-2\. Tensor representing a batch of colored images
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图12-2\. 表示彩色图像批次的张量
- en: Text Data
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本数据
- en: Typically, text is stored in a string, like “The cat sat on the mat,” but training
    a model or passing text like this to a pretrained model is unfeasible. Models,
    as you saw in earlier chapters, are trained on numeric data—and the best way to
    do that is to either *tokenize* the text, by turning words or subwords into numbers,
    or to *calculate embeddings* for the text, by turning them into vectors. And if
    you choose to calculate embeddings for the text, you can also encode sentiment
    about the text into the direction of the vector (see [Chapter 6](ch06.html#ch06_clean_making_sentiment_programmable_by_using_embeddings_1748752380728888)).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，文本以字符串的形式存储，例如“猫坐在垫子上”，但训练模型或将此类文本传递给预训练模型是不切实际的。正如您在前面章节中看到的，模型是在数值数据上训练的——而做到这一点最好的方式是将文本*标记化*，通过将单词或子词转换为数字，或者通过将文本*计算嵌入*，将它们转换为向量。如果您选择计算文本的嵌入，您还可以将文本的情感编码到向量的方向中（参见[第6章](ch06.html#ch06_clean_making_sentiment_programmable_by_using_embeddings_1748752380728888)）。
- en: 'So, as a simple example, let’s consider the following sentences:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，作为一个简单的例子，让我们考虑以下句子：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can *tokenize* this text into a series of numbers by using a tokenizer.
    You can create your own tokenized series of numbers from the corpus, as you did
    in [Chapter 5](ch05.html#ch05_introduction_to_natural_language_processing_1748549080743759),
    or you can use an existing one, like this:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用标记化器将此文本标记化为一系列数字。您可以从语料库中创建自己的标记化数字序列，就像您在[第5章](ch05.html#ch05_introduction_to_natural_language_processing_1748549080743759)中所做的那样，或者您可以使用现有的一个，如下所示：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You’ll learn a lot more about transformers, including how to use them for BERT,
    starting in [Chapter 13](ch13.html#ch13_hosting_pytorch_models_for_serving_1748549772563124).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在[第13章](ch13.html#ch13_hosting_pytorch_models_for_serving_1748549772563124)开始学习更多关于transformers的知识，包括如何使用它们进行BERT。
- en: 'The important line here is the last one, in which we ask the tokenizer to return
    tensors in PyTorch format. You can see the result of this in the output of the
    encodings, like this:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这里重要的一行是最后一行，其中我们要求标记化器以PyTorch格式返回张量。您可以在编码的输出中看到这个结果，如下所示：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If you explore this closely, you’ll see that the two sentences have been turned
    into a series of numbers. The first sentence, which has four words, has six numbers,
    and the second, which has six words, has eight numbers. Each has the number 101
    at the front and 102 at the end, which gives us the two extra tokens. These are
    special tokens the encoder has added to indicate the start and end of the sentence.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您仔细探索，您会看到两个句子已经被转换成一系列数字。第一个句子有四个单词，有六个数字，第二个句子有六个单词，有八个数字。每个都有101这个数字在前面和102这个数字在后面，这给了我们两个额外的标记。这些是编码器添加的特殊标记，用于指示句子的开始和结束。
- en: A string can be represented as a 1D vector, but we have multiple strings here,
    so we can add a dimension to 1D to get 2D, and the second dimension gives us each
    string. So, value 0 in the second dimension is the first string, value 1 is the
    second string, etc.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串可以被表示为一个1D向量，但这里我们有多个字符串，所以我们可以给1D添加一个维度来得到2D，第二个维度给出了每个字符串。所以，第二个维度中的值0是第一个字符串，值1是第二个字符串，等等。
- en: The BERT model can also create embeddings from the sentence by getting an embedding
    for each word in the sentence and summing them all up to get an overall set of
    values. In the base model version of BERT, each embedding vector is a 1D matrix
    with 768 values. The embedding for a sentence is the same. Multiple sentences,
    just like the previous encodings, will have a second dimension.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: BERT模型还可以通过获取句子中每个单词的嵌入并将它们全部相加来从句子创建嵌入。在BERT的基础模型版本中，每个嵌入向量是一个包含768个值的1D矩阵。句子的嵌入也是相同的。多个句子，就像之前的编码一样，将会有一个第二维度。
- en: 'Here’s the code:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是代码：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Each embedding has 768 values, so I’m not going to print them all out, but
    for the embedding that represents the first sentence, you can see values like
    this:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每个嵌入有768个值，所以我不打算全部打印出来，但对于代表第一句子的嵌入，您可以看到这样的值：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Don’t worry if you don’t fully understand this yet—we’ll be going into it in
    more detail starting in [Chapter 13](ch13.html#ch13_hosting_pytorch_models_for_serving_1748549772563124).
    The important point here is that the idea of a *tensor* is that the very flexible
    matrix, which can have any number of dimensions, gives you a consistent input
    into a model. You don’t need to train models on different data types—they’ll always
    be tensor in, tensor out.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在还没有完全理解这一点，请不要担心——我们将在第13章开始更详细地介绍这个话题。[第13章](ch13.html#ch13_hosting_pytorch_models_for_serving_1748549772563124)的重要观点是，张量的概念是一个非常灵活的矩阵，它可以有任意数量的维度，为模型提供一致性的输入。你不需要在不同的数据类型上训练模型——它们始终是输入为张量，输出为张量。
- en: Tensors Out of a Model
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型外的张量
- en: As noted earlier, the power of tensors is in their consistency—regardless of
    what type of data you pass *into* a model, when they’re tensors, you can be consistent
    in your coding interface. The same applies for tensors *out* of a model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，张量的力量在于它们的连贯性——无论你将什么类型的数据传递到模型中，当它们是张量时，你可以在编码接口上保持一致性。同样的原则也适用于模型外的张量。
- en: So, for example, consider a dataset like `ImageNet` that contains 15 million
    images in over 21,000 classes. When you design a model to recognize images in
    this dataset, you’ll need over 21,000 output neurons, each of which gives you
    a percentage likelihood that the image is of the representative class. So, for
    example, if neuron 0 represents “goldfish,” the value coming out of it when you
    do inference will be the probability that the image contains a goldfish!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个包含超过21000个类别中1500万张图片的数据集`ImageNet`。当你设计一个用于识别该数据集中图像的模型时，你需要超过21000个输出神经元，每个神经元都会给出一个百分比，表示图像属于代表性类别的可能性。例如，如果神经元0代表“金鱼”，那么当你进行推理时从它输出的值将是图像包含金鱼的概率！
- en: So, instead of outputting the classification, the model will expose the values
    of *each* of its output neurons. These values are often called *logits*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，模型不是输出分类，而是会暴露其每个输出神经元的值。这些值通常被称为*logits*。
- en: This list of values is a 1D vector of values—so of course, a tensor is the appropriate
    data type.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个值列表是一个一维向量——因此，当然，张量是适当的数据类型。
- en: 'Here’s a simulated example, with a set of representative outputs from multiple
    images passed into the model and the list of class names:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个模拟示例，其中包含从多个图像传递到模型中的多个代表性输出和类别名称列表：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that because the output is *tensors*, we can use many of the functions
    built into PyTorch that are optimized for tensors to work with them.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，因为输出是*张量*，我们可以使用许多内置到PyTorch中且针对张量优化的函数来处理它们。
- en: 'When dealing with the output values, we want to find the best ones and maybe
    limit them to a range. Softmax is perfect for that, when it converts the raw output
    into probabilities—and TopK is used to pick the best *k* values. Here’s an example
    in which we can use Softmax and TopK functions that manage tensors, regardless
    of their dimensionality:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理输出值时，我们希望找到最好的值，并可能限制它们的范围。Softmax非常适合这个任务，当它将原始输出转换为概率时——而TopK用于选择最好的*k*个值。以下是一个示例，其中我们可以使用Softmax和TopK函数来管理张量，无论它们的维度如何：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The values can then be converted to NumPy so that other code—like printing out
    the values—will work more easily.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以将这些值转换为NumPy，这样其他代码——比如打印出这些值——将更容易工作。
- en: 'We can see the output of this here, where Softmax and TopK were used to interpret
    the data and then print it out:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这里看到这个输出，其中使用了Softmax和TopK来解释数据并打印出来：
- en: '[PRE9]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The full code for this can be found in the [GitHub repository](https://github.com/lmoroney/PyTorch-Book-FIles)
    for this book.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的完整代码可以在[GitHub仓库](https://github.com/lmoroney/PyTorch-Book-FIles)中找到。
- en: Summary
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you took a brief look at tensors and the underlying idea behind
    them—that they are a flexible data structure that can be used to represent the
    best way to put data *into* an ML model, regardless of what it represents, and
    even batch it. It also provides a consistent way to manage outputs from a model—in
    which values are typically emitted via neurons that are arranged in the output
    layer as a list. Thus, by being able to handle tensors, you can build a foundation
    for how data flows in *and* out of a model.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你简要地了解了张量及其背后的理念——它们是一种灵活的数据结构，可以用来表示将数据*放入*机器学习模型的最佳方式，无论它代表什么，甚至可以批量处理。它还提供了一种管理模型输出的连贯方式——其中值通常通过输出层中排列成列表的神经元发出。因此，通过能够处理张量，你可以为数据如何在模型中*流入*和*流出*打下基础。
- en: With that, we’re now going to switch gears from model training to inference,
    in particular with generative AI, starting with getting models from registries
    and hubs.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们现在将从模型训练切换到推理阶段，特别是使用生成式AI，首先从注册表和中心获取模型。
