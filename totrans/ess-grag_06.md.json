["```py\nurl = \"https://www.gutenberg.org/cache/epub/1727/pg1727.txt\"\nresponse = requests.get(url)\n```", "```py\ndef chunk_into_books(text: str) -> List[str]:\n    return (\n        text.split(\"PREFACE TO FIRST EDITION\")[2]\n        .split(\"FOOTNOTES\")[0]\n        .strip()\n        .split(\"\\nBOOK\")[1:]\n    )\n\nbooks = chunk_into_books(response.text)\n```", "```py\ntoken_count = [num_tokens_from_string(el) for el in books]\nprint(\n    f\"\"\"There are {len(token_count)} books with token sizes:\n- avg {sum(token_count) / len(token_count)}\n- min {min(token_count)}\n- max {max(token_count)}\n\"\"\"\n)\n```", "```py\nchunked_books = [chunk_text(book, 1000, 40) for book in books]\n```", "```py\n ENTITY_TYPES = [\"PERSON\", \"ORGANIZATION\", \"LOCATION\",\n  \"GOD\", \"EVENT\", \"CREATURE\", \"WEAPON_OR_TOOL\"]\ndef extract_entities(text: str) -> List[Dict]:      #1\n    messages = [\n        {\"role\": \"user\",\n        \"content\": ch07_tools.create_extraction_prompt(ENTITY_TYPES, text)},  #2\n    ]\n\n    output = chat(messages, model = \"gpt-4o\") #3\n\n    return ch07_tools.parse_extraction_output(output) #4\n```", "```py\n number_of_books = 1\nfor book_i, book in enumerate(                                      #1\n    tqdm(chunked_books[:number_of_books], desc=\"Processing Books\")  #1\n):                                                                  #1\n    for chunk_i, chunk in enumerate(tqdm(book, desc=f\"Book {book_i}\", leave=False)):\n\n        nodes, relationships = extract_entities(chunk) #2\n\n        neo4j_driver.execute_query( #3\n            ch07_tools.import_nodes_query,\n            data=nodes,\n            book_id=book_i,\n            text=chunk,\n            chunk_id=chunk_i,\n        )\n\n        neo4j_driver.execute_query( #4\n            ch07_tools.import_relationships_query,\n            data=relationships\n        )\n```", "```py\ndata, _, _ = neo4j_driver.execute_query(\n    \"\"\"MATCH (:`__Entity__`)\n    RETURN 'entity' AS type, count(*) AS count\n    UNION\n    MATCH ()-[:RELATIONSHIP]->()\n    RETURN 'relationship' AS type, count(*) AS count\n    \"\"\"\n)\nprint([el.data() for el in data])\n```", "```py\ndata, _, _ = neo4j_driver.execute_query(\n    \"\"\"MATCH (n:PERSON)\nWHERE n.name = \"ORESTES\"\nRETURN n.description AS description\"\"\"\n)\nprint([el.data()['description'] for el in data])\n```", "```py\ndata, _, _ = neo4j_driver.execute_query(\n    \"\"\"MATCH (n:__Entity__)-[:RELATIONSHIP]-(m:__Entity__)\nWITH n,m, count(*) AS countOfRels\nORDER BY countOfRels DESC LIMIT 1\nMATCH (n)-[r:RELATIONSHIP]-(m)\nRETURN n.name AS source, m.name AS target, countOfRels, collect(r.description) AS descriptions\n\"\"\"\n)\nprint([el.data() for el in data])\n```", "```py\n candidates_to_summarize, _, _ = neo4j_driver.execute_query(\n    \"\"\"MATCH (e:__Entity__) WHERE size(e.description) > 1    #1\n    RETURN e.name AS entity_name, e.description AS description_list\"\"\"\n)\nsummaries = []\nfor candidate in tqdm(candidates_to_summarize, desc=\"Summarizing entities\"):\n\n    messages = [ #2\n        {\n            \"role\": \"user\",\n            \"content\": ch07_tools.get_summarize_prompt(\n                candidate[\"entity_name\"], candidate[\"description_list\"]\n            ),\n        },\n    ]\n\n    summary = chat(messages, model=\"gpt-4o\") #3\n    summaries.append(\n        {\"entity\": candidate[\"entity_name\"], \"summary\": summary}\n    )\nch07_tools.import_entity_summary(neo4j_driver, summaries)\n```", "```py\nsummary, _, _ = neo4j_driver.execute_query(\n    \"\"\"MATCH (n:PERSON)\nWHERE n.name = \"ORESTES\"\nRETURN n.summary AS summary\"\"\")\nprint(summary[0]['summary'])\n```", "```py\n rels_to_summarize, _, _ = neo4j_driver.execute_query(\n    \"\"\"MATCH (s:__Entity__)-[r:RELATIONSHIP]-(t:__Entity__)  #1\n    WHERE id(s) < id(t)\n    WITH s.name AS source, t.name AS target,\n           collect(r.description) AS description_list,\n           count(*) AS count\n    WHERE count > 1\n    RETURN source, target, description_list\"\"\"\n)\nrel_summaries = []\nfor candidate in tqdm(rels_to_summarize, desc=\"Summarizing relationships\"):\n    entity_name = f\"{candidate['source']} relationship to {candidate['target']}\"\n\n    messages = [ #2\n        {\n            \"role\": \"user\",\n            \"content\": ch07_tools.get_summarize_prompt(\n                entity_name, candidate[\"description_list\"]\n            ),\n        },\n    ]\n\n    summary = chat(messages, model=\"gpt-4o\") #3\n    rel_summaries.append({\"source\": candidate[\"source\"], \"target\": candidate[\"target\"], \"summary\": summary})  \nch07_tools.import_rels_summary(neo4j_driver, summaries) #4\n```", "```py\ndata, _, _ = neo4j_driver.execute_query(\n    \"\"\"MATCH (n:__Entity__)-[r:SUMMARIZED_RELATIONSHIP]-(m:__Entity__)\nWHERE n.name = 'TELEMACHUS' AND m.name = 'MINERVA'\nRETURN r.summary AS description\n\"\"\"\n)\nprint(data[0][\"description\"])\n```", "```py\ncommunity_distribution = ch07_tools.calculate_communities(neo4j_driver)\nprint(f\"\"\"There are {community_distribution['communityCount']} communities with distribution:\n  {community_distribution['communityDistribution']}\"\"\")\n```", "```py\ncommunity_info, _, _ = neo4j_driver.execute_query(ch07_tools.community_info_query) #1\n\ncommunities = []\nfor community in tqdm(community_info, desc=\"Summarizing communities\"):\n\n    messages = [ #2\n        {\n            \"role\": \"user\",\n            \"content\": ch07_tools.get_summarize_community_prompt(\n                community[\"nodes\"], community[\"rels\"]\n            ),\n        },\n    ]\n\n    summary = chat(messages, model=\"gpt-4o\") #3\n    communities.append(\n        {    \n            \"community\": json.loads(ch07_tools.extract_json(summary)), #4\n            \"communityId\": community[\"communityId\"],\n            \"nodes\": [el[\"id\"] for el in community[\"nodes\"]],\n        }\n    )  \nneo4j_driver.execute_query(ch07_tools.import_community_query, data=communities) #5\n```", "```py\ndata, _, _ = neo4j_driver.execute_query(\n    \"\"\"MATCH (c:__Community__)\nWITH c, count {(c)<-[:IN_COMMUNITY]-()} AS size\nORDER BY size DESC LIMIT 1\nRETURN c.title AS title, c.summary AS summary\n\"\"\"\n)\nprint(f\"Title: {data[0]['title']})\nprint(f\"Summary: {data[0][\"summary\"]}\")\n```", "```py\ndef global_retriever(query: str, rating_threshold: float = 5) -> str:\n\n    community_data, _, _ = neo4j_driver.execute_query( #1\n        \"\"\"\n    MATCH (c:__Community__)\n    WHERE c.rating >= $rating\n    RETURN c.summary AS summary\n    \"\"\",\n        rating=rating_threshold,\n    )\n    print(f\"Got {len(community_data)} community summaries\")\n    intermediate_results = []\n    for community in tqdm(community_data, desc=\"Processing communities\"):\n\n        intermediate_messages = [ #2\n            {\n                \"role\": \"system\",\n                \"content\": ch07_tools.get_map_system_prompt(community[\"summary\"]),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": query,\n            },\n        ]\n        intermediate_response = chat(intermediate_messages, model=\"gpt-4o\")\n        intermediate_results.append(intermediate_response)\n\n    final_messages = [ #3\n        {\n            \"role\": \"system\",\n            \"content\": ch07_tools.get_reduce_system_prompt(intermediate_results),\n        },\n        {\"role\": \"user\", \"content\": query},\n    ]\n    summary = chat(final_messages, model=\"gpt-4o\")\n    return summary\n```", "```py\nprint(global_retriever(\"What is this story about?\"))\n```", "```py\n entities, _, _ = neo4j_driver.execute_query(\n    \"\"\"\nMATCH (e:__Entity__)\nRETURN e.summary AS summary, e.name AS name   #1\n\"\"\"\n)  \ndata = [{\"name\": el[\"name\"], \"embedding\": embed(el[\"summary\"])[0]} for el in entities]     #2\nneo4j_driver.execute_query( #3\n    \"\"\"\nUNWIND $data AS row\nMATCH (e:__Entity__ {name: row.name})\nCALL db.create.setNodeVectorProperty(e, 'embedding', row.embedding)\n\"\"\",\n    data=data,\n)    #4\nneo4j_driver.execute_query(\n    \"\"\"\nCREATE VECTOR INDEX entities IF NOT EXISTS\nFOR (n:__Entity__)\nON (n.embedding)\n\"\"\",\n    data=data,\n)\n```", "```py\nlocal_search_query = \"\"\"\nCALL db.index.vector.queryNodes('entities', $k, $embedding)\nYIELD node, score\nWITH collect(node) as nodes   #1\nWITH collect {\n    UNWIND nodes as n\n    MATCH (n)<-[:HAS_ENTITY]->(c:__Chunk__)\n    WITH c, count(distinct n) as freq\n    RETURN c.text AS chunkText\n    ORDER BY freq DESC\n    LIMIT $topChunks\n} AS text_mapping,  \ncollect { #2\n    UNWIND nodes as n\n    MATCH (n)-[:IN_COMMUNITY]->(c:__Community__)\n    WITH c, c.rank as rank, c.weight AS weight\n    RETURN c.summary\n    ORDER BY rank, weight DESC\n    LIMIT $topCommunities\n} AS report_mapping,  \ncollect { #3\n    UNWIND nodes as n\n    MATCH (n)-[r:SUMMARIZED_RELATIONSHIP]-(m)\n    WHERE m IN nodes\n    RETURN r.summary AS descriptionText\n    ORDER BY r.rank, r.weight DESC\n    LIMIT $topInsideRels\n} as insideRels,  \ncollect { #4\n    UNWIND nodes as n\n    RETURN n.summary AS descriptionText\n} as entities\nRETURN {Chunks: text_mapping, Reports: report_mapping,\n       Relationships: insideRels,\n       Entities: entities} AS text\n\"\"\"\n```", "```py\ndef local_search(query: str) -> str:\n\n    context, _, _ = neo4j_driver.execute_query( #1\n        local_search_query,\n        embedding=embed(query)[0],\n        topChunks=topChunks,\n        topCommunities=topCommunities,\n        topInsideRels=topInsideRels,\n        k=k_entities,\n    )\n\n    context_str = str(context[0][\"text\"]) #2\n\n    local_messages = [ #3\n        {\n            \"role\": \"system\",\n            \"content\": ch07_tools.get_local_system_prompt(context_str),\n        },\n        {\n            \"role\": \"user\",\n            \"content\": query,\n        },\n    ]\n\n    final_answer = chat(local_messages, model=\"gpt-4o\") #4\n    return final_answer\n```", "```py\nprint(local_search(\"Who is Ulysses?\"))\n```"]