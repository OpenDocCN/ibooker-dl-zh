- en: Chapter 1\. Your Deep Learning Journey
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。你的深度学习之旅
- en: Hello, and thank you for letting us join you on your deep learning journey,
    however far along that you may be! In this chapter, we will tell you a little
    bit more about what to expect in this book, introduce the key concepts behind
    deep learning, and train our first models on different tasks. It doesn’t matter
    if you don’t come from a technical or a mathematical background (though it’s OK
    if you do too!); we wrote this book to make deep learning accessible to as many
    people as possible.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 你好，感谢你让我们加入你的深度学习之旅，无论你已经走了多远！在本章中，我们将告诉你更多关于本书的内容，介绍深度学习背后的关键概念，并在不同任务上训练我们的第一个模型。无论你是否有技术或数学背景（尽管如果你有也没关系！），我们写这本书是为了让尽可能多的人能够接触到深度学习。
- en: Deep Learning Is for Everyone
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习适合每个人
- en: A lot of people assume that you need all kinds of hard-to-find stuff to get
    great results with deep learning, but as you’ll see in this book, those people
    are wrong. [Table 1-1](#myths) lists a few things you *absolutely don’t need*
    for world-class deep learning.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 很多人认为你需要各种难以找到的东西才能在深度学习中取得出色的结果，但正如你在本书中所看到的，这些人是错误的。表1-1列出了一些你*绝对不需要*进行世界级深度学习的东西。
- en: Table 1-1\. What you don’t need for deep learning
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-1。深度学习不需要的东西
- en: '| Myth (don’t need) | Truth |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '| 迷思（不需要） | 真相 |'
- en: '| --- | --- |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Lots of math | High school math is sufficient. |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| 大量的数学 | 高中数学就足够了。 |'
- en: '| Lots of data | We’ve seen record-breaking results with <50 items of data.
    |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 大量的数据 | 我们已经看到少于50个数据项取得了创纪录的结果。 |'
- en: '| Lots of expensive computers | You can get what you need for state-of-the-art
    work for free. |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 大量昂贵的计算机 | 你可以免费获得进行最先进工作所需的设备。 |'
- en: '*Deep learning* is a computer technique to extract and transform data—with
    use cases ranging from human speech recognition to animal imagery classification—by
    using multiple layers of neural networks. Each of these layers takes its inputs
    from previous layers and progressively refines them. The layers are trained by
    algorithms that minimize their errors and improve their accuracy. In this way,
    the network learns to perform a specified task. We will discuss training algorithms
    in detail in the next section.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*深度学习*是一种计算机技术，通过使用多层神经网络从人类语音识别到动物图像分类等用例来提取和转换数据。每个层从前一层获取输入，并逐渐完善它们。这些层通过最小化错误并提高准确性的算法进行训练。这样，网络学会执行指定的任务。我们将在下一节详细讨论训练算法。'
- en: Deep learning has power, flexibility, and simplicity. That’s why we believe
    it should be applied across many disciplines. These include the social and physical
    sciences, the arts, medicine, finance, scientific research, and many more. To
    give a personal example, despite having no background in medicine, Jeremy started
    Enlitic, a company that uses deep learning algorithms to diagnose illness and
    disease. Within months of starting the company, it was announced that its algorithm
    could identify malignant tumors [more accurately than radiologists](https://oreil.ly/aTwdE).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习具有强大、灵活和简单的特点。这就是为什么我们认为它应该应用于许多学科。这些学科包括社会科学、自然科学、艺术、医学、金融、科学研究等等。举个个人例子，尽管没有医学背景，Jeremy创办了Enlitic公司，该公司使用深度学习算法来诊断疾病。在公司成立几个月后，宣布其算法能够比放射科医生更准确地识别恶性肿瘤。
- en: 'Here’s a list of some of the thousands of tasks in different areas for which
    deep learning, or methods heavily using deep learning, is now the best in the
    world:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些不同领域中数千个任务的列表，其中深度学习或大量使用深度学习的方法现在是世界上最好的：
- en: Natural language processing (NLP)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）
- en: Answering questions; speech recognition; summarizing documents; classifying
    documents; finding names, dates, etc. in documents; searching for articles mentioning
    a concept
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 回答问题；语音识别；总结文件；分类文件；在文件中查找名称、日期等；搜索提及某一概念的文章
- en: Computer vision
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: Satellite and drone imagery interpretation (e.g., for disaster resilience),
    face recognition, image captioning, reading traffic signs, locating pedestrians
    and vehicles in autonomous vehicles
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 卫星和无人机图像解释（例如用于灾害韧性），人脸识别，图像字幕，读取交通标志，定位自动驾驶车辆中的行人和车辆
- en: Medicine
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 医学
- en: Finding anomalies in radiology images, including CT, MRI, and X-ray images;
    counting features in pathology slides; measuring features in ultrasounds; diagnosing
    diabetic retinopathy
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在放射学图像中找到异常，包括CT、MRI和X射线图像；在病理学幻灯片中计数特征；在超声波中测量特征；诊断糖尿病视网膜病变
- en: Biology
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 生物学
- en: Folding proteins; classifying proteins; many genomics tasks, such as tumor-normal
    sequencing and classifying clinically actionable genetic mutations; cell classification;
    analyzing protein/protein interactions
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 折叠蛋白;分类蛋白质;许多基因组学任务，如肿瘤-正常测序和分类临床可操作的遗传突变;细胞分类;分析蛋白质/蛋白质相互作用
- en: Image generation
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图像生成
- en: Colorizing images, increasing image resolution, removing noise from images,
    converting images to art in the style of famous artists
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 给图像上色，增加图像分辨率，去除图像中的噪音，将图像转换为著名艺术家风格的艺术品
- en: Recommendation systems
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统
- en: Web search, product recommendations, home page layout
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 网络搜索，产品推荐，主页布局
- en: Playing games
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 玩游戏
- en: Chess, Go, most Atari video games, and many real-time strategy games
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 国际象棋，围棋，大多数Atari视频游戏以及许多实时策略游戏
- en: Robotics
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人技术
- en: Handling objects that are challenging to locate (e.g., transparent, shiny, lacking
    texture) or hard to pick up
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 处理难以定位的物体（例如透明、闪亮、缺乏纹理）或难以拾取的物体
- en: Other applications
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其他应用
- en: Financial and logistical forecasting, text to speech, and much, much more…
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 金融和物流预测，文本转语音等等…
- en: 'What is remarkable is that deep learning has such varied applications, yet
    nearly all of deep learning is based on a single innovative type of model: the
    neural network.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，深度学习有如此多样的应用，然而几乎所有的深度学习都基于一种创新的模型类型：神经网络。
- en: But neural networks are not, in fact, completely new. In order to have a wider
    perspective on the field, it is worth starting with a bit of history.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 但事实上，神经网络并不是完全新的。为了对该领域有更广泛的视角，值得从一点历史开始。
- en: 'Neural Networks: A Brief History'
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络：简史
- en: 'In 1943 Warren McCulloch, a neurophysiologist, and Walter Pitts, a logician,
    teamed up to develop a mathematical model of an artificial neuron. In their paper
    “A Logical Calculus of the Ideas Immanent in Nervous Activity,” they declared
    the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 1943年，神经生理学家沃伦·麦卡洛克和逻辑学家沃尔特·皮茨联手开发了人工神经元的数学模型。在他们的论文《神经活动中内在思想的逻辑演算》中，他们宣称：
- en: Because of the “all-or-none” character of nervous activity, neural events and
    the relations among them can be treated by means of propositional logic. It is
    found that the behavior of every net can be described in these terms.
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 由于神经活动的“全有或全无”特性，神经事件及其之间的关系可以通过命题逻辑来处理。发现每个网络的行为都可以用这些术语来描述。
- en: McCulloch and Pitts realized that a simplified model of a real neuron could
    be represented using simple addition and thresholding, as shown in [Figure 1-1](#neuron).
    Pitts was self-taught, and by age 12, had received an offer to study at Cambridge
    University with the great Bertrand Russell. He did not take up this invitation,
    and indeed throughout his life did not accept any offers of advanced degrees or
    positions of authority. Most of his famous work was done while he was homeless.
    Despite his lack of an officially recognized position and increasing social isolation,
    his work with McCulloch was influential and was taken up by a psychologist named
    Frank Rosenblatt.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 麦卡洛克和皮茨意识到，可以使用简单的加法和阈值处理来表示真实神经元的简化模型，如[图1-1](#neuron)所示。皮茨是自学成才的，12岁时就收到了与伟大的伯特兰·罗素一起在剑桥大学学习的邀请。他没有接受这个邀请，事实上，他一生中没有接受任何高级学位或权威职位的邀请。他大部分著名的工作都是在无家可归时完成的。尽管他没有正式认可的职位，社交孤立日益加剧，但他与麦卡洛克的合作对心理学家弗兰克·罗森布拉特产生了影响。
- en: '![Natural and artificial neurons](Images/dlcf_0101.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![自然和人工神经元](Images/dlcf_0101.png)'
- en: Figure 1-1\. Natural and artificial neurons
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 自然和人工神经元
- en: 'Rosenblatt further developed the artificial neuron to give it the ability to
    learn. Even more importantly, he worked on building the first device that used
    these principles, the Mark I Perceptron. In “The Design of an Intelligent Automaton,”
    Rosenblatt wrote about this work: “We are now about to witness the birth of such
    a machine—a machine capable of perceiving, recognizing and identifying its surroundings
    without any human training or control.” The perceptron was built and was able
    to successfully recognize simple shapes.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 罗森布拉特进一步发展了人工神经元，使其具有学习能力。更重要的是，他致力于构建第一个使用这些原则的设备，即Mark I感知器。在《智能自动机的设计》中，罗森布拉特写道：“我们现在将见证这样一台机器的诞生——一台能够在没有任何人类训练或控制的情况下感知、识别和辨认其周围环境的机器。”感知器被建造出来，并成功地识别了简单的形状。
- en: An MIT professor named Marvin Minsky (who was a grade behind Rosenblatt at the
    same high school!), along with Seymour Papert, wrote a book called *Perceptrons*
    (MIT Press) about Rosenblatt’s invention. They showed that a single layer of these
    devices was unable to learn some simple but critical mathematical functions (such
    as XOR). In the same book, they also showed that using multiple layers of the
    devices would allow these limitations to be addressed. Unfortunately, only the
    first of these insights was widely recognized. As a result, the global academic
    community nearly entirely gave up on neural networks for the next two decades.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 麻省理工学院的教授马文·明斯基（与罗森布拉特在同一所高中，但比他晚一年）与西摩·帕帕特合著了一本名为《感知器》（麻省理工学院出版社）的书，讲述了罗森布拉特的发明。他们表明，这些设备的单层无法学习一些简单但关键的数学函数（如异或）。在同一本书中，他们还表明，使用多层设备可以解决这些限制。不幸的是，这些洞见中只有第一个被广泛认可。因此，全球学术界在接下来的两十年几乎完全放弃了神经网络。
- en: 'Perhaps the most pivotal work in neural networks in the last 50 years was the
    multi-volume *Parallel Distributed Processing* (PDP) by David Rumelhart, James
    McClelland, and the PDP Research Group, released in 1986 by MIT Press. Chapter
    1 lays out a similar hope to that shown by Rosenblatt:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去50年中，神经网络领域最具影响力的工作可能是由大卫·鲁梅尔哈特、詹姆斯·麦克莱兰和PDP研究小组于1986年由麻省理工学院出版社出版的多卷本《并行分布式处理》（PDP）。第1章提出了与罗森布拉特所展示的类似希望：
- en: People are smarter than today’s computers because the brain employs a basic
    computational architecture that is more suited to deal with a central aspect of
    the natural information processing tasks that people are so good at.…We will introduce
    a computational framework for modeling cognitive processes that seems…closer than
    other frameworks to the style of computation as it might be done by the brain.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人类比今天的计算机更聪明，因为大脑采用了一种更适合处理人类擅长的自然信息处理任务的基本计算架构。我们将介绍一个用于建模认知过程的计算框架，它似乎比其他框架更接近大脑可能进行的计算风格。
- en: The premise that PDP is using here is that traditional computer programs work
    very differently from brains, and that might be why computer programs had been
    (at that point) so bad at doing things that brains find easy (such as recognizing
    objects in pictures). The authors claimed that the PDP approach was “closer than
    other frameworks” to how the brain works, and therefore it might be better able
    to handle these kinds of tasks.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: PDP所使用的前提是，传统计算机程序与大脑的工作方式非常不同，这可能是为什么计算机程序在那时如此糟糕地执行大脑发现容易的任务（如识别图片中的物体）。作者声称PDP方法“比其他框架更接近”大脑的工作方式，因此可能更能够处理这些任务。
- en: 'In fact, the approach laid out in PDP is very similar to the approach used
    in today’s neural networks. The book defined parallel distributed processing as
    requiring the following:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，PDP中提出的方法与今天的神经网络所使用的方法非常相似。该书将并行分布式处理定义为需要以下内容：
- en: A set of *processing units*
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组*处理单元*
- en: A *state of activation*
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*激活状态*'
- en: An *output function* for each unit
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个单元的*输出函数*
- en: A *pattern of connectivity* among units
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单位之间的*连接模式*
- en: A *propagation rule* for propagating patterns of activities through the network
    of connectivities
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过网络连接传播活动模式的*传播规则*
- en: An *activation rule* for combining the inputs impinging on a unit with the current
    state of that unit to produce an output for the unit
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将输入与单位的当前状态相结合以产生单位输出的*激活规则*
- en: A *learning rule* whereby patterns of connectivity are modified by experience
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过经验修改连接模式的*学习规则*
- en: An *environment* within which the system must operate
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统必须运行的*环境*
- en: We will see in this book that modern neural networks handle each of these requirements.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书中看到现代神经网络如何处理这些要求。
- en: In the 1980s, most models were built with a second layer of neurons, thus avoiding
    the problem that had been identified by Minsky and Papert (this was their “pattern
    of connectivity among units,” to use the preceding framework). And indeed, neural
    networks were widely used during the ’80s and ’90s for real, practical projects.
    However, again a misunderstanding of the theoretical issues held back the field.
    In theory, adding just one extra layer of neurons was enough to allow any mathematical
    function to be approximated with these neural networks, but in practice such networks
    were often too big and too slow to be useful.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪80年代，大多数模型都建立了第二层神经元，从而避免了由明斯基和帕佩特（这是他们“单元之间的连接模式”，使用前面的框架）所确定的问题。事实上，神经网络在80年代和90年代被广泛用于真实的实际项目。然而，对理论问题的误解再次阻碍了该领域的发展。理论上，只需添加一个额外的神经元层就足以使这些神经网络能够近似任何数学函数，但实际上这样的网络通常太大且太慢，无法发挥作用。
- en: 'Although researchers showed 30 years ago that to get practical, good performance
    you need to use even more layers of neurons, it is only in the last decade that
    this principle has been more widely appreciated and applied. Neural networks are
    now finally living up to their potential, thanks to the use of more layers, coupled
    with the capacity to do so because of improvements in computer hardware, increases
    in data availability, and algorithmic tweaks that allow neural networks to be
    trained faster and more easily. We now have what Rosenblatt promised: “a machine
    capable of perceiving, recognizing, and identifying its surroundings without any
    human training or control.”'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管研究人员30年前就表明，要获得实际的良好性能，你需要使用更多层的神经元，但直到最近十年，这个原则才被更广泛地认可和应用。现在，由于计算机硬件的改进、数据可用性的增加以及允许神经网络更快更容易地训练的算法调整，神经网络终于实现了其潜力。我们现在拥有了Rosenblatt所承诺的：“一台能够感知、识别和辨认周围环境的机器，无需任何人类训练或控制。”
- en: This is what you will learn how to build in this book. But first, since we are
    going to be spending a lot of time together, let’s get to know each other a bit…
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你将在本书中学会如何构建的内容。但首先，因为我们将花很多时间在一起，让我们彼此稍微了解一下...
- en: Who We Are
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们是谁
- en: We are Sylvain and Jeremy, your guides on this journey. We hope that you will
    find us well suited for this position.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是Sylvain和Jeremy，是你们在这个旅程中的向导。我们希望你们认为我们非常适合这个职位。
- en: Jeremy has been using and teaching machine learning for around 30 years. He
    started using neural networks 25 years ago. During this time, he has led many
    companies and projects that have machine learning at their core, including founding
    the first company to focus on deep learning and medicine, Enlitic, and taking
    on the role of president and chief scientist at the world’s largest machine learning
    community, Kaggle. He is the cofounder, along with Dr. Rachel Thomas, of fast.ai,
    the organization that built the course this book is based on.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Jeremy已经使用和教授机器学习约30年。他在25年前开始使用神经网络。在此期间，他领导了许多以机器学习为核心的公司和项目，包括成立专注于深度学习和医学的第一家公司Enlitic，并担任全球最大的机器学习社区Kaggle的总裁兼首席科学家。他与Rachel
    Thomas博士共同创立了fast.ai，这个组织建立了本书基于的课程。
- en: 'From time to time, you will hear directly from us in sidebars, like this one
    from Jeremy:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 不时地，你会直接从我们这里听到一些侧边栏的信息，比如Jeremy在这里说的：
- en: Jeremy Says
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jeremy说
- en: Hi, everybody; I’m Jeremy! You might be interested to know that I do not have
    any formal technical education. I completed a BA with a major in philosophy, and
    didn’t have great grades. I was much more interested in doing real projects than
    theoretical studies, so I worked full time at a management consulting firm called
    McKinsey and Company throughout my university years. If you’re somebody who would
    rather get their hands dirty building stuff than spend years learning abstract
    concepts, you will understand where I am coming from! Look out for sidebars from
    me to find information most suited to people with a less mathematical or formal
    technical background—that is, people like me…
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 大家好，我是Jeremy！你可能会感兴趣知道，我没有接受过任何正式的技术教育。我获得了哲学专业的学士学位，成绩并不好。我对做实际项目比对理论研究更感兴趣，所以在大学期间我全职在一家名为麦肯锡公司的管理咨询公司工作。如果你更愿意亲自动手建造东西而不是花费数年学习抽象概念，你会理解我的想法！请留意我的侧边栏，以找到最适合没有数学或正式技术背景的人的信息，也就是像我这样的人...
- en: Sylvain, on the other hand, knows a lot about formal technical education. He
    has written 10 math textbooks, covering the entire advanced French math curriculum!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Sylvain对正式的技术教育了解很多。他已经写了10本数学教科书，涵盖了整个法国高级数学课程！
- en: Sylvain Says
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sylvain说
- en: Unlike Jeremy, I have not spent many years coding and applying machine learning
    algorithms. Rather, I recently came to the machine learning world by watching
    Jeremy’s fast.ai course videos. So, if you are somebody who has not opened a terminal
    and written commands at the command line, you will understand where I am coming
    from! Look out for sidebars from me to find information most suited to people
    with a more mathematical or formal technical background, but less real-world coding
    experience—that is, people like me…
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 与杰里米不同，我没有花很多年编写和应用机器学习算法。相反，我最近通过观看杰里米的fast.ai课程视频进入了机器学习世界。因此，如果你是一个从未打开终端并在命令行中编写命令的人，你会理解我在说什么！请留意我的旁注，以找到最适合具有更多数学或正式技术背景，但缺乏实际编码经验的人的信息，也就是像我这样的人...
- en: The fast.ai course has been studied by hundreds of thousands of students, from
    all walks of life, from all parts of the world. Sylvain stood out as the most
    impressive student of the course that Jeremy had ever seen, which led to him joining
    fast.ai and then becoming the coauthor, along with Jeremy, of the fastai software
    library.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: fast.ai课程已经被来自世界各地各行各业的数十万学生研究过。Sylvain被认为是Jeremy见过的该课程中最令人印象深刻的学生，这导致他加入了fast.ai，然后与Jeremy一起成为fastai软件库的合著者。
- en: 'All this means that between us, you have the best of both worlds: the people
    who know more about the software than anybody else, because they wrote it; an
    expert on math, and an expert on coding and machine learning; and also people
    who understand both what it feels like to be a relative outsider in math, and
    a relative outsider in coding and machine learning.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些意味着，在我们之间，你拥有最好的两个世界：那些比任何人都更了解软件的人，因为他们编写了它；数学专家，编码和机器学习专家；以及那些了解在数学中作为相对外行者和在编码和机器学习中作为相对外行者的感受的人。
- en: 'Anybody who has watched sports knows that if you have a two-person commentary
    team, you also need a third person to do “special comments.” Our special commentator
    is Alexis Gallagher. Alexis has a very diverse background: he has been a researcher
    in mathematical biology, a screenplay writer, an improv performer, a McKinsey
    consultant (like Jeremy!), a Swift coder, and a CTO.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 任何看过体育比赛的人都知道，如果有一个两人评论团队，你还需要第三个人来做“特别评论”。我们的特别评论员是亚历克西斯·加拉格尔（Alexis Gallagher）。亚历克西斯有着非常多样化的背景：他曾是数学生物学研究员，编剧，即兴表演者，麦肯锡顾问（就像Jeremy一样！），Swift编码者和首席技术官。
- en: Alexis Says
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 亚历克西斯说
- en: I’ve decided it’s time for me to learn about this AI stuff! After all, I’ve
    tried pretty much everything else.…But I don’t really have a background in building
    machine learning models. Still…how hard can it be? I’m going to be learning throughout
    this book, just like you are. Look out for my sidebars for learning tips that
    I found helpful on my journey, and hopefully you will find helpful too.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定是时候学习这个人工智能的东西了！毕竟，我几乎尝试了所有其他的东西...但我并没有建立机器学习模型的背景。不过...这有多难呢？我将在这本书中一直学习，就像你一样。请留意我的旁注，找到我在学习过程中发现有用的学习提示，希望你也会觉得有用。
- en: How to Learn Deep Learning
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何学习深度学习
- en: Harvard professor David Perkins, who wrote *Making Learning Whole* (Jossey-Bass),
    has much to say about teaching. The basic idea is to teach the *whole game*. That
    means that if you’re teaching baseball, you first take people to a baseball game
    or get them to play it. You don’t teach them how to wind twine to make a baseball
    from scratch, the physics of a parabola, or the coefficient of friction of a ball
    on a bat.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 哈佛教授大卫·帕金斯（David Perkins）在《全面学习》（Jossey-Bass）一书中有很多关于教学的观点。基本思想是教授“整个游戏”。这意味着，如果你在教棒球，你首先带人们去看一场棒球比赛或让他们玩棒球。你不会教他们如何缠绕麻线从头开始制作棒球，也不会教他们抛物线的物理学，或者球在球拍上的摩擦系数。
- en: Paul Lockhart, a Columbia math PhD, former Brown professor, and K–12 math teacher,
    imagines in the influential essay [“A Mathematician’s Lament”](https://oreil.ly/yNimZ)
    a nightmare world where music and art are taught the way math is taught. Children
    are not allowed to listen to or play music until they have spent over a decade
    mastering music notation and theory, spending classes transposing sheet music
    into a different key. In art class, students study colors and applicators, but
    aren’t allowed to actually paint until college. Sound absurd? This is how math
    is taught—we require students to spend years doing rote memorization and learning
    dry, disconnected *fundamentals* that we claim will pay off later, long after
    most of them quit the subject.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 哥伦比亚数学博士、前布朗大学教授和K-12数学教师保罗·洛克哈特（Paul Lockhart）在具有影响力的文章《数学家的悲歌》中设想了一个噩梦般的世界，在那里音乐和艺术的教学方式与数学的教学方式相同。孩子们在掌握音乐符号和理论十多年后才被允许听音乐或演奏音乐，花时间将乐谱转换到不同的音调。在艺术课上，学生学习颜色和应用工具，但直到大学才被允许真正绘画。听起来荒谬吗？这就是数学的教学方式——我们要求学生花费多年时间进行死记硬背和学习干燥、脱离实际的“基础知识”，我们声称这些知识在大多数学生放弃这门学科后才会有回报。
- en: Unfortunately, this is where many teaching resources on deep learning begin—asking
    learners to follow along with the definition of the Hessian and theorems for the
    Taylor approximation of your loss functions, without ever giving examples of actual
    working code. We’re not knocking calculus. We love calculus, and Sylvain has even
    taught it at the college level, but we don’t think it’s the best place to start
    when learning deep learning!
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这正是许多关于深度学习的教学资源开始的地方——要求学习者跟随Hessian的定义和泰勒近似定理的步伐，而从未给出实际工作代码的示例。我们并不是在抨击微积分。我们喜欢微积分，Sylvain甚至在大学教过微积分，但我们认为学习深度学习时不是最好的起点！
- en: In deep learning, it really helps if you have the motivation to fix your model
    to get it to do better. That’s when you start learning the relevant theory. But
    you need to have the model in the first place. We teach almost everything through
    real examples. As we build out those examples, we go deeper and deeper, and we’ll
    show you how to make your projects better and better. This means that you’ll be
    gradually learning all the theoretical foundations you need, in context, in such
    a way that you’ll see why it matters and how it works.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，如果你有动力修复模型使其表现更好，那真的会有帮助。那时你开始学习相关的理论。但你首先需要有模型。我们几乎所有的教学都是通过真实例子展示的。随着我们构建这些例子，我们会越来越深入，向您展示如何使您的项目变得更好。这意味着您将逐渐学习所有您需要的理论基础，以上下文方式，这样您就会明白为什么重要以及如何运作。
- en: 'So, here’s our commitment to you. Throughout this book, we follow these principles:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这是我们对您的承诺。在整本书中，我们遵循以下原则：
- en: Teaching the whole game
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 教授整个游戏
- en: We’ll start off by showing you how to use a complete, working, usable, state-of-the-art
    deep learning network to solve real-world problems using simple, expressive tools.
    And then we’ll gradually dig deeper and deeper into understanding how those tools
    are made, and how the tools that make those tools are made, and so on…
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从向您展示如何使用完整、可用、最先进的深度学习网络来解决现实世界问题，使用简单、表达力强的工具开始。然后我们将逐渐深入了解这些工具是如何制作的，以及制作这些工具的工具是如何制作的，依此类推…
- en: Always teaching through examples
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 始终通过示例教学
- en: We’ll ensure that there is a context and a purpose that you can understand intuitively,
    rather than starting with algebraic symbol manipulation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将确保您能直观理解背景和目的，而不是从代数符号操作开始。
- en: Simplifying as much as possible
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 尽可能简化
- en: We’ve spent years building tools and teaching methods that make previously complex
    topics simple.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们花了多年时间建立工具和教学方法，使以前复杂的主题变得简单。
- en: Removing barriers
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 消除障碍
- en: Deep learning has, until now, been an exclusive game. We’re breaking it open
    and ensuring that everyone can play.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习直到现在一直是一个独家游戏。我们正在打破这个局面，确保每个人都能参与。
- en: 'The hardest part of deep learning is artisanal: how do you know if you’ve got
    enough data, whether it is in the right format, if your model is training properly,
    and, if it’s not, what you should do about it? That is why we believe in learning
    by doing. As with basic data science skills, with deep learning you get better
    only through practical experience. Trying to spend too much time on the theory
    can be counterproductive. The key is to just code and try to solve problems: the
    theory can come later, when you have context and motivation.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习中最困难的部分是手工制作的：你如何知道你是否有足够的数据，数据是否以正确的格式存在，你的模型是否正确训练，如果不正确，你应该怎么做？这就是为什么我们相信通过实践学习。与基本的数据科学技能一样，通过实践经验才能变得更好。花太多时间在理论上可能会适得其反。关键是只需编写代码并尝试解决问题：理论可以稍后再来，当你有了上下文和动力时。
- en: There will be times when the journey feels hard. Times when you feel stuck.
    Don’t give up! Rewind through the book to find the last bit where you definitely
    weren’t stuck, and then read slowly through from there to find the first thing
    that isn’t clear. Then try some code experiments yourself, and Google around for
    more tutorials on whatever the issue you’re stuck with is—often you’ll find a
    different angle on the material that might help it to click. Also, it’s expected
    and normal to not understand everything (especially the code) on first reading.
    Trying to understand the material serially before proceeding can sometimes be
    hard. Sometimes things click into place after you get more context from parts
    down the road, from having a bigger picture. So if you do get stuck on a section,
    try moving on anyway and make a note to come back to it later.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在旅程中会有困难的时候。有时你会感到困惑。不要放弃！回顾一下书中你肯定没有困惑的部分，然后从那里开始慢慢阅读，找到第一个不清楚的地方。然后尝试一些代码实验，自己搜索更多关于你遇到问题的教程——通常你会找到一个不同的角度来理解材料，可能会帮助你理解。此外，第一次阅读时不理解一切（尤其是代码）是正常的。有时在继续之前按顺序理解材料有时会很困难。有时在你从后面的部分获得更多上下文后，事情就会豁然开朗，从整体上看到更多。所以如果你在某个部分卡住了，尝试继续前进，做个笔记以后再回来。
- en: 'Remember, you don’t need any particular academic background to succeed at deep
    learning. Many important breakthroughs are made in research and industry by folks
    without a PhD, such as the paper [“Unsupervised Representation Learning with Deep
    Convolutional Generative Adversarial Networks”](https://oreil.ly/JV6rL)—one of
    the most influential papers of the last decade, with over 5,000 citations—which
    was written by Alec Radford when he was an undergraduate. Even at Tesla, where
    they’re trying to solve the extremely tough challenge of making a self-driving
    car, CEO [Elon Musk says](https://oreil.ly/nQCmO):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，要在深度学习中取得成功，您不需要任何特定的学术背景。许多重要的突破是由没有博士学位的人在研究和工业领域取得的，比如Alec Radford在大学本科时写的一篇论文《使用深度卷积生成对抗网络进行无监督表示学习》，这是过去十年中最有影响力的论文之一，被引用超过5000次。甚至在特斯拉，他们正在努力解决制造自动驾驶汽车这个极具挑战性的问题，首席执行官埃隆·马斯克表示：
- en: A PhD is definitely not required. All that matters is a deep understanding of
    AI & ability to implement NNs in a way that is actually useful (latter point is
    what’s truly hard). Don’t care if you even graduated high school.
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 绝对不需要博士学位。重要的是对人工智能有深刻理解和能够实际应用神经网络（后者才是真正困难的）。甚至不在乎你是否高中毕业。
- en: What you will need to do to succeed, however, is to apply what you learn in
    this book to a personal project, and always persevere.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，要成功，您需要将本书中学到的知识应用到个人项目中，并始终坚持不懈。
- en: Your Projects and Your Mindset
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你的项目和心态
- en: Whether you’re excited to identify if plants are diseased from pictures of their
    leaves, autogenerate knitting patterns, diagnose TB from X-rays, or determine
    when a raccoon is using your cat door, we will get you using deep learning on
    your own problems (via pretrained models from others) as quickly as possible,
    and then will progressively drill into more details. You’ll learn how to use deep
    learning to solve your own problems at state-of-the-art accuracy within the first
    30 minutes of the next chapter! (And feel free to skip straight there now if you’re
    dying to get coding right away.) There is a pernicious myth out there that you
    need to have computing resources and datasets the size of those at Google to be
    able to do deep learning, but it’s not true.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是因为兴奋地想要从植物叶片的图片中识别植物是否患病，自动生成编织图案，从X射线诊断结核病，还是确定浣熊何时使用您的猫门，我们将尽快让您使用深度学习解决自己的问题（通过他人预训练的模型），然后将逐步深入更多细节。在下一章的前30分钟内，您将学会如何使用深度学习以最先进的准确性解决自己的问题！（如果您迫不及待地想要立即开始编码，请随时跳转到那里。）有一个错误的观念认为，要进行深度学习，您需要像谷歌那样拥有计算资源和数据集的规模，但这是不正确的。
- en: So, what sorts of tasks make for good test cases? You could train your model
    to distinguish between Picasso and Monet paintings or to pick out pictures of
    your daughter instead of pictures of your son. It helps to focus on your hobbies
    and passions—setting yourself four or five little projects rather than striving
    to solve a big, grand problem tends to work better when you’re getting started.
    Since it is easy to get stuck, trying to be too ambitious too early can often
    backfire. Then, once you’ve got the basics mastered, aim to complete something
    you’re really proud of!
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么样的任务适合作为良好的测试案例？您可以训练模型区分毕加索和莫奈的画作，或者挑选您女儿的照片而不是您儿子的照片。专注于您的爱好和激情有助于您设定四到五个小项目，而不是努力解决一个大问题，这在刚开始时效果更好。由于很容易陷入困境，过早野心勃勃往往会适得其反。然后，一旦掌握了基础知识，就努力完成一些让您真正自豪的事情！
- en: Jeremy Says
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 杰里米说
- en: Deep learning can be set to work on almost any problem. For instance, my first
    startup was a company called FastMail, which provided enhanced email services
    when it launched in 1999 (and still does to this day). In 2002, I set it up to
    use a primitive form of deep learning, single-layer neural networks, to help categorize
    emails and stop customers from receiving spam.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习几乎可以应用于任何问题。例如，我的第一家创业公司叫做FastMail，它于1999年推出时提供了增强的电子邮件服务（至今仍在提供）。2002年，我将其设置为使用一种原始形式的深度学习，即单层神经网络，以帮助分类电子邮件并阻止客户收到垃圾邮件。
- en: 'Common character traits in the people who do well at deep learning include
    playfulness and curiosity. The late physicist Richard Feynman is an example of
    someone we’d expect to be great at deep learning: his development of an understanding
    of the movement of subatomic particles came from his amusement at how plates wobble
    when they spin in the air.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中表现良好的人的共同特征包括好玩和好奇。已故物理学家理查德·费曼就是我们期望在深度学习方面表现出色的人的一个例子：他对亚原子粒子运动的理解来自于他对盘子在空中旋转时摇晃的好奇。
- en: Let’s now focus on what you will learn, starting with the software.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们专注于您将学到的内容，从软件开始。
- en: 'The Software: PyTorch, fastai, and Jupyter (And Why It Doesn’t Matter)'
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 软件：PyTorch、fastai和Jupyter（以及为什么这不重要）
- en: We’ve completed hundreds of machine learning projects using dozens of packages,
    and many programming languages. At fast.ai, we have written courses using most
    of the main deep learning and machine learning packages used today. After PyTorch
    came out in 2017, we spent over a thousand hours testing it before deciding that
    we would use it for future courses, software development, and research. Since
    that time, PyTorch has become the world’s fastest-growing deep learning library
    and is already used for most research papers at top conferences. This is generally
    a leading indicator of usage in industry, because these are the papers that end
    up getting used in products and services commercially. We have found that PyTorch
    is the most flexible and expressive library for deep learning. It does not trade
    off speed for simplicity, but provides both.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了数百个机器学习项目，使用了数十种软件包和多种编程语言。在fast.ai，我们编写了大多数当今主要的深度学习和机器学习软件包的课程。在2017年PyTorch发布后，我们花费了一千多个小时进行测试，然后决定将其用于未来的课程、软件开发和研究。自那时以来，PyTorch已成为全球增长最快的深度学习库，并且已经被用于顶级会议上的大多数研究论文。这通常是行业使用的领先指标，因为这些论文最终会被商业产品和服务使用。我们发现PyTorch是最灵活和表达力强的深度学习库。它不会以速度为代价而简化，而是提供了两者。
- en: PyTorch works best as a low-level foundation library, providing the basic operations
    for higher-level functionality. The fastai library is the most popular library
    for adding this higher-level functionality on top of PyTorch. It’s also particularly
    well suited to the purposes of this book, because it is unique in providing a
    deeply layered software architecture (there’s even a [peer-reviewed academic paper](https://oreil.ly/Uo3GR)
    about this layered API). In this book, as we go deeper and deeper into the foundations
    of deep learning, we will also go deeper and deeper into the layers of fastai.
    This book covers version 2 of the fastai library, which is a from-scratch rewrite
    providing many unique features.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch最适合作为低级基础库，提供高级功能的基本操作。fastai库是在PyTorch之上添加高级功能的最流行的库。它也特别适合本书的目的，因为它在提供深度分层软件架构方面是独一无二的（甚至有一篇[同行评审的学术论文](https://oreil.ly/Uo3GR)介绍了这种分层API）。在本书中，随着我们深入研究深度学习的基础，我们也将深入研究fastai的各个层次。本书涵盖了fastai库的第2版，这是一个从头开始重写的版本，提供了许多独特的功能。
- en: However, it doesn’t really matter what software you learn, because it takes
    only a few days to learn to switch from one library to another. What really matters
    is learning the deep learning foundations and techniques properly. Our focus will
    be on using code that, as clearly as possible, expresses the concepts that you
    need to learn. Where we are teaching high-level concepts, we will use high-level
    fastai code. Where we are teaching low-level concepts, we will use low-level PyTorch
    or even pure Python code.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，学习哪种软件并不重要，因为只需要几天就可以学会从一个库切换到另一个库。真正重要的是正确学习深度学习的基础和技术。我们的重点将是使用尽可能清晰地表达你需要学习的概念的代码。在教授高级概念时，我们将使用高级
    fastai 代码。在教授低级概念时，我们将使用低级 PyTorch 或甚至纯 Python 代码。
- en: Though it may seem like new deep learning libraries are appearing at a rapid
    pace nowadays, you need to be prepared for a much faster rate of change in the
    coming months and years. As more people enter the field, they will bring more
    skills and ideas, and try more things. You should assume that whatever specific
    libraries and software you learn today will be obsolete in a year or two. Just
    think about the number of changes in libraries and technology stacks that occur
    all the time in the world of web programming—a much more mature and slow-growing
    area than deep learning. We strongly believe that the focus in learning needs
    to be on understanding the underlying techniques and how to apply them in practice,
    and how to quickly build expertise in new tools and techniques as they are released.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现在似乎新的深度学习库以快速的速度出现，但你需要为未来几个月和几年内更快的变化做好准备。随着更多人进入这个领域，他们将带来更多的技能和想法，并尝试更多的事情。你应该假设你今天学到的特定库和软件将在一两年内过时。想想在网络编程领域中一直发生的库和技术栈的变化数量——这是一个比深度学习更成熟和增长缓慢的领域。我们坚信学习的重点应该放在理解基础技术以及如何将其应用于实践中，以及如何在新工具和技术发布时快速建立专业知识。
- en: By the end of the book, you’ll understand nearly all the code that’s inside
    fastai (and much of PyTorch too), because in each chapter we’ll be digging a level
    deeper to show you exactly what’s going on as we build and train our models. This
    means that you’ll have learned the most important best practices used in modern
    deep learning—not just how to use them, but how they really work and are implemented.
    If you want to use those approaches in another framework, you’ll have the knowledge
    you need to do so if needed.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 到书的结尾，你将几乎理解 fastai 中的所有代码（以及大部分 PyTorch 代码），因为在每一章中，我们都会深入挖掘，向你展示我们构建和训练模型时究竟发生了什么。这意味着你将学到现代深度学习中使用的最重要的最佳实践，不仅是如何使用它们，还有它们是如何真正工作和实现的。如果你想在另一个框架中使用这些方法，你将有必要的知识来做到这一点。
- en: Since the most important thing for learning deep learning is writing code and
    experimenting, it’s important that you have a great platform for experimenting
    with code. The most popular programming experimentation platform is called [Jupyter](https://jupyter.org).
    This is what we will be using throughout this book. We will show you how you can
    use Jupyter to train and experiment with models and introspect every stage of
    the data preprocessing and model development pipeline. Jupyter is the most popular
    tool for doing data science in Python, for good reason. It is powerful, flexible,
    and easy to use. We think you will love it!
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 由于学习深度学习最重要的是编写代码和实验，所以重要的是你有一个很好的代码实验平台。最流行的编程实验平台称为 [Jupyter](https://jupyter.org)。这是我们将在整本书中使用的工具。我们将向你展示如何使用
    Jupyter 训练和实验模型，并审查数据预处理和模型开发流程的每个阶段。Jupyter 是在 Python 中进行数据科学最流行的工具，理由充分。它功能强大、灵活且易于使用。我们相信你会喜欢它！
- en: Let’s see it in practice and train our first model.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们实践一下，训练我们的第一个模型。
- en: Your First Model
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你的第一个模型
- en: As we said before, we will teach you how to do things before we explain why
    they work. Following this top-down approach, we will begin by actually training
    an image classifier to recognize dogs and cats with almost 100% accuracy. To train
    this model and run our experiments, you will need to do some initial setup. Don’t
    worry; it’s not as hard as it looks.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所说，我们将教你如何做事情，然后再解释为什么它们有效。遵循这种自上而下的方法，我们将首先实际训练一个图像分类器，几乎可以100%准确地识别狗和猫。为了训练这个模型并运行我们的实验，你需要进行一些初始设置。不要担心，这并不像看起来那么难。
- en: Sylvain Says
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sylvain 说
- en: Do not skip the setup part even if it looks intimidating at first, especially
    if you have little or no experience using things like a terminal or the command
    line. Most of that is not necessary, and you will find that the easiest servers
    can be set up with just your usual web browser. It is crucial that you run your
    own experiments in parallel with this book in order to learn.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 即使初始设置看起来令人生畏，也不要跳过设置部分，特别是如果你很少或没有使用终端或命令行的经验。大部分并不是必要的，你会发现最简单的服务器只需使用你平常的网络浏览器就可以设置好。在学习过程中，与本书并行运行你自己的实验是至关重要的。
- en: Getting a GPU Deep Learning Server
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取 GPU 深度学习服务器
- en: To do nearly everything in this book, you’ll need access to a computer with
    an NVIDIA GPU (unfortunately, other brands of GPU are not fully supported by the
    main deep learning libraries). However, we don’t recommend you buy one; in fact,
    even if you already have one, we don’t suggest you use it just yet! Setting up
    a computer takes time and energy, and you want all your energy to focus on deep
    learning right now. Therefore, we instead suggest you rent access to a computer
    that already has everything you need preinstalled and ready to go. Costs can be
    as little as $0.25 per hour while you’re using it, and some options are even free.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中几乎所有的事情都需要使用一台带有 NVIDIA GPU 的计算机（不幸的是，其他品牌的 GPU 并没有得到主要深度学习库的全面支持）。然而，我们不建议你购买一台；事实上，即使你已经有一台，我们也不建议你立即使用！设置一台计算机需要时间和精力，而你现在想要把所有精力集中在深度学习上。因此，我们建议你租用一台已经预装并准备就绪的计算机。使用时的成本可能只需每小时
    0.25 美元，甚至有些选项是免费的。
- en: 'Jargon: Graphics Processing Unit (GPU)'
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语：图形处理单元（GPU）
- en: Also known as a *graphics card*. A special kind of processor in your computer
    that can handle thousands of single tasks at the same time, especially designed
    for displaying 3D environments on a computer for playing games. These same basic
    tasks are very similar to what neural networks do, such that GPUs can run neural
    networks hundreds of times faster than regular CPUs. All modern computers contain
    a GPU, but few contain the right kind of GPU necessary for deep learning.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 也称为*图形卡*。计算机中一种特殊类型的处理器，可以同时处理成千上万个单个任务，专门设计用于在计算机上显示3D环境以进行游戏。这些相同的基本任务与神经网络所做的非常相似，因此GPU可以比常规CPU快数百倍运行神经网络。所有现代计算机都包含GPU，但很少包含进行深度学习所需的正确类型的GPU。
- en: The best choice of GPU servers to use with this book will change over time,
    as companies come and go and prices change. We maintain a list of our recommended
    options on the [book’s website](https://book.fast.ai), so go there now and follow
    the instructions to get connected to a GPU deep learning server. Don’t worry;
    it takes only about two minutes to get set up on most platforms, and many don’t
    even require any payment or even a credit card to get started.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 随着公司的兴衰和价格的变化，与本书一起使用的GPU服务器的最佳选择将随时间而变化。我们在[书的网站](https://book.fast.ai)上维护了我们推荐选项的列表，所以现在去那里，按照说明连接到GPU深度学习服务器。不用担心；在大多数平台上，设置只需要大约两分钟，许多甚至不需要任何付款或信用卡即可开始。
- en: Alexis Says
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Alexis说
- en: 'My two cents: heed this advice! If you like computers, you will be tempted
    to set up your own box. Beware! It is feasible but surprisingly involved and distracting.
    There is a good reason this book is not titled *Everything You Ever Wanted to
    Know About Ubuntu System Administration, NVIDIA Driver Installation, apt-get,
    conda, pip, and Jupyter Notebook Configuration*. That would be a book of its own.
    Having designed and deployed our production machine learning infrastructure at
    work, I can testify it has its satisfactions, but it is as unrelated to modeling
    as maintaining an airplane is to flying one.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我的建议：听取这些建议！如果您喜欢计算机，您可能会想要设置自己的计算机。小心！这是可行的，但令人惊讶地复杂和分散注意力。这本书没有标题为*关于Ubuntu系统管理、NVIDIA驱动程序安装、apt-get、conda、pip和Jupyter笔记本配置的所有内容*。那将是一本独立的书。在工作中设计和部署我们的生产机器学习基础设施后，我可以证明它有其满足感，但与建模无关，就像维护飞机与驾驶飞机无关。
- en: Each option shown on the website includes a tutorial; after completing the tutorial,
    you will end up with a screen looking like [Figure 1-2](#notebook_init).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 网站上显示的每个选项都包括一个教程；完成教程后，您将看到一个屏幕，看起来像[图1-2](#notebook_init)。
- en: '![Initial view of Jupyter Notebook](Images/dlcf_0102.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![Jupyter笔记本的初始视图](Images/dlcf_0102.png)'
- en: Figure 1-2\. Initial view of Jupyter Notebook
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. Jupyter笔记本的初始视图
- en: You are now ready to run your first Jupyter notebook!
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已经准备好运行您的第一个Jupyter笔记本！
- en: 'Jargon: Jupyter Notebook'
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行话：Jupyter笔记本
- en: A piece of software that allows you to include formatted text, code, images,
    videos, and much more, all within a single interactive document. Jupyter received
    the highest honor for software, the ACM Software System Award, thanks to its wide
    use and enormous impact in many academic fields and in industry. Jupyter Notebook
    is the software most widely used by data scientists for developing and interacting
    with deep learning models.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 一种软件，允许您在单个交互式文档中包含格式化文本、代码、图像、视频等。Jupyter因其在许多学术领域和工业中的广泛使用和巨大影响而获得了软件的最高荣誉，ACM软件系统奖。Jupyter笔记本是数据科学家用于开发和与深度学习模型交互的最广泛使用的软件。
- en: Running Your First Notebook
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行您的第一个笔记本
- en: The notebooks are numbered by chapter in the same order as they are presented
    in this book. So, the very first notebook you will see listed is the notebook
    that you need to use now. You will be using this notebook to train a model that
    can recognize dog and cat photos. To do this, you’ll be downloading a dataset
    of dog and cat photos, and using that to *train a model*.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本按章节编号，与本书中呈现的顺序相同。因此，您将看到列出的第一个笔记本是您现在需要使用的笔记本。您将使用此笔记本来训练一个可以识别狗和猫照片的模型。为此，您将下载一组狗和猫照片的数据集，并使用该数据集*训练模型*。
- en: A *dataset* is simply a bunch of data—it could be images, emails, financial
    indicators, sounds, or anything else. There are many datasets made freely available
    that are suitable for training models. Many of these datasets are created by academics
    to help advance research, many are made available for competitions (there are
    competitions where data scientists can compete to see who has the most accurate
    model!), and some are byproducts of other processes (such as financial filings).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据集*只是一堆数据——可以是图像、电子邮件、财务指标、声音或其他任何东西。有许多免费提供的数据集适合用于训练模型。许多这些数据集是由学者创建的，以帮助推动研究，许多是为竞赛提供的（有一些竞赛，数据科学家可以竞争，看看谁有最准确的模型！），有些是其他过程的副产品（如财务申报）。'
- en: Full and Stripped Notebooks
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完整和剥离的笔记本
- en: There are two folders containing different versions of the notebooks. The *full*
    folder contains the exact notebooks used to create the book you’re reading now,
    with all the prose and outputs. The *stripped* version has the same headings and
    code cells, but all outputs and prose have been removed. After reading a section
    of the book, we recommend working through the stripped notebooks, with the book
    closed, and seeing if you can figure out what each cell will show before you execute
    it. Also try to recall what the code is demonstrating.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个包含不同版本笔记本的文件夹。*full*文件夹包含用于创建您现在阅读的书的确切笔记本，包括所有散文和输出。*stripped*版本具有相同的标题和代码单元格，但所有输出和散文都已删除。阅读书的一部分后，我们建议关闭书，通过stripped笔记本进行练习，并尝试在执行之前弄清楚每个单元格将显示什么。还要尝试回想代码正在演示什么。
- en: To open a notebook, just click it. The notebook will open, and it will look
    something like [Figure 1-3](#jupyter) (note that there may be slight differences
    in details across different platforms; you can ignore those differences).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要打开一个笔记本，只需单击它。笔记本将打开，看起来类似于[图1-3](#jupyter)（请注意，不同平台之间可能存在细节上的轻微差异；您可以忽略这些差异）。
- en: '![An example of notebook](Images/dlcf_0103.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![笔记本的示例](Images/dlcf_0103.png)'
- en: Figure 1-3\. A Jupyter notebook
  id: totrans-129
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3\. 一个Jupyter笔记本
- en: 'A notebook consists of *cells*. There are two main types of cell:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一个笔记本由*单元格*组成。有两种主要类型的单元格：
- en: Cells containing formatted text, images, and so forth. These use a format called
    *Markdown*, which you will learn about soon.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含格式化文本、图像等内容的单元格。这些使用一种称为*Markdown*的格式，您很快就会了解。
- en: Cells containing code that can be executed, and outputs will appear immediately
    underneath (which could be plain text, tables, images, animations, sounds, or
    even interactive applications).
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含可执行代码的单元格，输出将立即显示在其下方（可以是纯文本、表格、图像、动画、声音，甚至交互式应用程序）。
- en: 'Jupyter notebooks can be in one of two modes: edit mode or command mode. In
    edit mode, typing on your keyboard enters the letters into the cell in the usual
    way. However, in command mode, you will not see any flashing cursor, and each
    key on your keyboard will have a special function.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter笔记本可以处于两种模式之一：编辑模式或命令模式。在编辑模式下，键盘上的输入以通常的方式输入到单元格中。但是，在命令模式下，您将看不到任何闪烁的光标，键盘上的每个键都将具有特殊功能。
- en: Before continuing, press the Escape key on your keyboard to switch to command
    mode (if you are already in command mode, this does nothing, so press it now just
    in case). To see a complete list of all the functions available, press H; press
    Escape to remove this help screen. Notice that in command mode, unlike in most
    programs, commands do not require you to hold down Control, Alt, or similar—you
    simply press the required letter key.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，请按下键盘上的Escape键切换到命令模式（如果您已经在命令模式下，则此操作无效，因此现在请按下它）。要查看所有可用功能的完整列表，请按H；按Escape键以删除此帮助屏幕。请注意，在命令模式下，与大多数程序不同，命令不需要按住Control、Alt或类似键，您只需按下所需的字母键。
- en: You can make a copy of a cell by pressing C (the cell needs to be selected first,
    indicated with an outline around it; if it is not already selected, click it once).
    Then press V to paste a copy of it.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过按下C键（需要首先选择单元格，显示为周围有轮廓；如果尚未选择，请单击一次）来复制单元格。然后按V键粘贴副本。
- en: 'Click the cell that begins with the line “# CLICK ME” to select it. The first
    character in that line indicates that what follows is a comment in Python, so
    it is ignored when executing the cell. The rest of the cell is, believe it or
    not, a complete system for creating and training a state-of-the-art model for
    recognizing cats versus dogs. So, let’s train it now! To do so, just press Shift-Enter
    on your keyboard, or click the Play button on the toolbar. Then wait a few minutes
    while the following things happen:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 单击以“# CLICK ME”开头的单元格以选择它。该行中的第一个字符表示后面的内容是Python中的注释，因此在执行单元格时会被忽略。单元格的其余部分是一个完整的系统，用于创建和训练一个用于识别猫和狗的最先进模型。所以，现在让我们开始训练吧！要这样做，只需在键盘上按Shift-Enter，或单击工具栏上的播放按钮。然后等待几分钟，以下事情会发生：
- en: A dataset called the [Oxford-IIIT Pet Dataset](https://oreil.ly/c_4Bv) that
    contains 7,349 images of cats and dogs from 37 breeds will be downloaded from
    the fast.ai datasets collection to the GPU server you are using, and will then
    be extracted.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个名为[牛津-IIIT宠物数据集](https://oreil.ly/c_4Bv)的数据集，其中包含来自37个品种的7,349张猫和狗的图像，将从fast.ai数据集合中下载到您正在使用的GPU服务器上，然后进行提取。
- en: A *pretrained model* that has already been trained on 1.3 million images using
    a competition-winning model will be downloaded from the internet.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个*预训练模型*，已经在130万张图像上训练过，使用了一个获奖模型，将从互联网上下载。
- en: The pretrained model will be *fine-tuned* using the latest advances in transfer
    learning to create a model that is specially customized for recognizing dogs and
    cats.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预训练模型将使用迁移学习的最新进展进行*微调*，以创建一个专门定制用于识别狗和猫的模型。
- en: 'The first two steps need to be run only once on your GPU server. If you run
    the cell again, it will use the dataset and model that have already been downloaded,
    rather than downloading them again. Let’s take a look at the contents of the cell
    and the results ([Table 1-2](#first_training)):'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个步骤只需要在您的GPU服务器上运行一次。如果再次运行单元格，它将使用已经下载的数据集和模型，而不是重新下载它们。让我们看看单元格的内容和结果（[表1-2](#first_training)）：
- en: '[PRE0]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Table 1-2\. Results from the first training
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-2\. 第一次训练的结果
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | error_rate | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.169390 | 0.021388 | 0.005413 | 00:14 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.169390 | 0.021388 | 0.005413 | 00:14 |'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | error_rate | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.058748 | 0.009240 | 0.002706 | 00:19 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.058748 | 0.009240 | 0.002706 | 00:19 |'
- en: You will probably not see exactly the same results shown here. A lot of sources
    of small random variation are involved in training models. We generally see an
    error rate of well less than 0.02 in this example, however.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能不会看到这里显示的完全相同的结果。训练模型涉及许多小随机变化的来源。在这个例子中，我们通常看到错误率远低于0.02，然而。
- en: Training Time
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练时间
- en: Depending on your network speed, it might take a few minutes to download the
    pretrained model and dataset. Running `fine_tune` might take a minute or so. Often
    models in this book take a few minutes to train, as will your own models, so it’s
    a good idea to come up with good techniques to make the most of this time. For
    instance, keep reading the next section while your model trains, or open up another
    notebook and use it for some coding experiments.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的网络速度，下载预训练模型和数据集可能需要几分钟。运行`fine_tune`可能需要一两分钟。通常，本书中的模型需要几分钟来训练，您自己的模型也是如此，因此最好想出一些好的技巧来充分利用这段时间。例如，当您的模型训练时，继续阅读下一节，或者打开另一个笔记本并用它进行一些编码实验。
- en: So, how do we know if this model is any good? In the last column of the table,
    you can see the *error rate*, which is the proportion of images that were incorrectly
    identified. The error rate serves as our metric—our measure of model quality,
    chosen to be intuitive and comprehensible. As you can see, the model is nearly
    perfect, even though the training time was only a few seconds (not including the
    one-time downloading of the dataset and the pretrained model). In fact, the accuracy
    you’ve achieved already is far better than anybody had ever achieved just 10 years
    ago!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何知道这个模型是否好用？在表的最后一列中，你可以看到*错误率*，即被错误识别的图像的比例。错误率作为我们的度量标准——我们选择的模型质量的衡量标准，旨在直观和易于理解。正如你所看到的，即使训练时间只有几秒钟（不包括数据集和预训练模型的一次性下载），模型几乎是完美的。事实上，你已经取得的准确率比任何人在10年前取得的都要好得多！
- en: 'Finally, let’s check that this model actually works. Go and get a photo of
    a dog or a cat; if you don’t have one handy, just search Google Images and download
    an image that you find there. Now execute the cell with `uploader` defined. It
    will output a button you can click, so you can select the image you want to classify:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们检查一下这个模型是否真的有效。去找一张狗或猫的照片；如果你手头没有，只需搜索Google图片并下载你找到的一张图片。现在执行定义了`uploader`的单元格。它会输出一个按钮，你可以点击它，然后选择你想分类的图片：
- en: '[PRE1]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![An upload button](Images/dlcf_01in02.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![上传按钮](Images/dlcf_01in02.png)'
- en: 'Now you can pass the uploaded file to the model. Make sure that it is a clear
    photo of a single dog or a cat, and not a line drawing, cartoon, or similar. The
    notebook will tell you whether it thinks it is a dog or a cat, and how confident
    it is. Hopefully, you’ll find that your model did a great job:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以将上传的文件传递给模型。确保它是一张清晰的狗或猫的照片，而不是线描、卡通或类似的照片。笔记本会告诉你它认为这是一只狗还是一只猫，以及它的自信程度。希望你会发现你的模型表现得很好：
- en: '[PRE2]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Congratulations on your first classifier!
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你的第一个分类器！
- en: But what does this mean? What did you actually do? In order to explain this,
    let’s zoom out again to take in the big picture.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这意味着什么？你实际上做了什么？为了解释这一点，让我们再次放大，看看整体情况。
- en: What Is Machine Learning?
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: Your classifier is a deep learning model. As was already mentioned, deep learning
    models use neural networks, which originally date from the 1950s and have become
    powerful very recently thanks to recent advancements.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你的分类器是一个深度学习模型。正如已经提到的，深度学习模型使用神经网络，这些神经网络最初可以追溯到上世纪50年代，并且最近由于最新的进展变得非常强大。
- en: Another key piece of context is that deep learning is just a modern area in
    the more general discipline of *machine learning*. To understand the essence of
    what you did when you trained your own classification model, you don’t need to
    understand deep learning. It is enough to see how your model and your training
    process are examples of the concepts that apply to machine learning in general.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的背景是，深度学习只是更一般的*机器学习*领域中的一个现代领域。要理解当你训练自己的分类模型时所做的事情的本质，你不需要理解深度学习。看到你的模型和训练过程是如何成为适用于机器学习的概念的例子就足够了。
- en: So in this section, we will describe machine learning. We will explore the key
    concepts and see how they can be traced back to the original essay that introduced
    them.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本节中，我们将描述机器学习。我们将探讨关键概念，并看看它们如何可以追溯到最初介绍它们的原始文章。
- en: '*Machine learning* is, like regular programming, a way to get computers to
    complete a specific task. But how would we use regular programming to do what
    we just did in the preceding section: recognize dogs versus cats in photos? We
    would have to write down for the computer the exact steps necessary to complete
    the task.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '*机器学习*就像常规编程一样，是让计算机完成特定任务的一种方式。但是如果要用常规编程来完成前面部分我们刚刚做的事情：在照片中识别狗和猫，我们将不得不为计算机写下完成任务所需的确切步骤。'
- en: Normally, it’s easy enough for us to write down the steps to complete a task
    when we’re writing a program. We just think about the steps we’d take if we had
    to do the task by hand, and then we translate them into code. For instance, we
    can write a function that sorts a list. In general, we’d write a function that
    looks something like [Figure 1-4](#basic_program) (where *inputs* might be an
    unsorted list, and *results* a sorted list).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当我们编写程序时，很容易为我们写下完成任务的步骤。我们只需考虑如果我们必须手动完成任务时会采取的步骤，然后将它们转换为代码。例如，我们可以编写一个对列表进行排序的函数。一般来说，我们会编写一个类似于[图1-4](#basic_program)的函数（其中*inputs*可能是一个未排序的列表，*results*是一个排序后的列表）。
- en: '![Pipeline inputs, program, results](Images/dlcf_0104.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![管道输入、程序、结果](Images/dlcf_0104.png)'
- en: Figure 1-4\. A traditional program
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. 传统程序
- en: But for recognizing objects in a photo, that’s a bit tricky; what *are* the
    steps we take when we recognize an object in a picture? We really don’t know,
    since it all happens in our brain without us being consciously aware of it!
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 但是要在照片中识别物体，这有点棘手；当我们在图片中识别物体时，我们采取了什么步骤？我们真的不知道，因为这一切都发生在我们的大脑中，而我们并没有意识到！
- en: 'Right back at the dawn of computing, in 1949, an IBM researcher named Arthur
    Samuel started working on a different way to get computers to complete tasks,
    which he called *machine learning*. In his classic 1962 essay “Artificial Intelligence:
    A Frontier of Automation,” he wrote:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 早在计算机诞生之初，1949年，IBM的一位研究员阿瑟·塞缪尔开始研究一种让计算机完成任务的不同方式，他称之为*机器学习*。在他经典的1962年文章“人工智能：自动化的前沿”中，他写道：
- en: Programming a computer for such computations is, at best, a difficult task,
    not primarily because of any inherent complexity in the computer itself but, rather,
    because of the need to spell out every minute step of the process in the most
    exasperating detail. Computers, as any programmer will tell you, are giant morons,
    not giant brains.
  id: totrans-171
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为这样的计算编程对于我们来说是相当困难的，主要不是因为计算机本身的任何固有复杂性，而是因为需要详细说明过程的每一个细微步骤。任何程序员都会告诉你，计算机是巨大的白痴，而不是巨大的大脑。
- en: 'His basic idea was this: instead of telling the computer the exact steps required
    to solve a problem, show it examples of the problem to solve, and let it figure
    out how to solve it itself. This turned out to be very effective: by 1961, his
    checkers-playing program had learned so much that it beat the Connecticut state
    champion! Here’s how he described his idea (from the same essay as noted previously):'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 他的基本想法是这样的：不是告诉计算机解决问题所需的确切步骤，而是向其展示解决问题的示例，并让它自己找出如何解决。结果证明这非常有效：到1961年，他的跳棋程序学到了很多，以至于击败了康涅狄格州冠军！这是他描述自己想法的方式（与之前提到的同一篇文章）：
- en: Suppose we arrange for some automatic means of testing the effectiveness of
    any current weight assignment in terms of actual performance and provide a mechanism
    for altering the weight assignment so as to maximize the performance. We need
    not go into the details of such a procedure to see that it could be made entirely
    automatic and to see that a machine so programmed would “learn” from its experience.
  id: totrans-173
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 假设我们安排一些自动手段来测试任何当前权重分配的有效性，以实际表现为准，并提供一种机制来改变权重分配以最大化性能。我们不需要详细了解这种程序的细节，就可以看到它可以完全自动化，并且可以看到一个这样编程的机器将从中学习。
- en: 'There are a number of powerful concepts embedded in this short statement:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简短陈述中嵌入了一些强大的概念：
- en: The idea of a “weight assignment”
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “权重分配”的想法
- en: The fact that every weight assignment has some “actual performance”
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个权重分配都有一些“实际表现”的事实
- en: The requirement that there be an “automatic means” of testing that performance
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要求有一种“自动手段”来测试该性能
- en: The need for a “mechanism” (i.e., another automatic process) for improving the
    performance by changing the weight assignments
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一个“机制”（即，另一个自动过程）来通过改变权重分配来提高性能
- en: Let’s take these concepts one by one, in order to understand how they fit together
    in practice. First, we need to understand what Samuel means by a *weight assignment*.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一了解这些概念，以便了解它们在实践中如何结合。首先，我们需要了解塞缪尔所说的*权重分配*是什么意思。
- en: Weights are just variables, and a weight assignment is a particular choice of
    values for those variables. The program’s inputs are values that it processes
    in order to produce its results—for instance, taking image pixels as inputs, and
    returning the classification “dog” as a result. The program’s weight assignments
    are other values that define how the program will operate.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 权重只是变量，权重分配是这些变量的特定值选择。程序的输入是它处理以产生结果的值，例如，将图像像素作为输入，并返回分类“狗”作为结果。程序的权重分配是定义程序操作方式的其他值。
- en: Because they will affect the program, they are in a sense another kind of input.
    We will update our basic picture in [Figure 1-4](#basic_program) and replace it
    with [Figure 1-5](#weight_assignment) in order to take this into account.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它们会影响程序，它们在某种意义上是另一种输入。我们将更新我们的基本图片[图1-4](#basic_program)，并用[图1-5](#weight_assignment)替换，以便考虑到这一点。
- en: '![](Images/dlcf_0105.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: ！[](Images/dlcf_0105.png)
- en: Figure 1-5\. A program using weight assignment
  id: totrans-183
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5。使用权重分配的程序
- en: 'We’ve changed the name of our box from *program* to *model*. This is to follow
    modern terminology and to reflect that the *model* is a special kind of program:
    it’s one that can do *many different things*, depending on the *weights*. It can
    be implemented in many different ways. For instance, in Samuel’s checkers program,
    different values of the weights would result in different checkers-playing strategies.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将方框的名称从*程序*更改为*模型*。这是为了遵循现代术语并反映*模型*是一种特殊类型的程序：它可以根据*权重*做*许多不同的事情*。它可以以许多不同的方式实现。例如，在塞缪尔的跳棋程序中，不同的权重值会导致不同的跳棋策略。
- en: (By the way, what Samuel called “weights” are most generally referred to as
    model *parameters* these days, in case you have encountered that term. The term
    *weights* is reserved for a particular type of model parameter.)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: （顺便说一句，塞缪尔所说的“权重”如今通常被称为模型*参数*，以防您遇到这个术语。术语*权重*保留给特定类型的模型参数。）
- en: Next, Samuel said we need an *automatic means of testing the effectiveness of
    any current weight assignment in terms of actual performance*. In the case of
    his checkers program, the “actual performance” of a model would be how well it
    plays. And you could automatically test the performance of two models by setting
    them to play against each other, and seeing which one usually wins.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，塞缪尔说我们需要一种*自动测试任何当前权重分配的有效性的方法，以实际表现为准*。在他的跳棋程序中，“实际表现”模型的表现有多好。您可以通过让两个模型相互对战并看哪个通常获胜来自动测试两个模型的表现。
- en: Finally, he says we need *a mechanism for altering the weight assignment so
    as to maximize the performance*. For instance, we could look at the difference
    in weights between the winning model and the losing model, and adjust the weights
    a little further in the winning direction.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，他说我们需要*一种机制来改变权重分配，以最大化性能*。例如，我们可以查看获胜模型和失败模型之间的权重差异，并将权重进一步调整到获胜方向。
- en: We can now see why he said that such a procedure *could be made entirely automatic
    and…a machine so programmed would “learn” from its experience*. Learning would
    become entirely automatic when the adjustment of the weights was also automatic—when
    instead of us improving a model by adjusting its weights manually, we relied on
    an automated mechanism that produced adjustments based on performance.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以看到他为什么说这样的程序*可以完全自动化，并且...一个这样编程的机器将从中学习*。当权重的调整也是自动的时，学习将变得完全自动——当我们不再通过手动调整权重来改进模型，而是依赖于根据性能产生调整的自动化机制时。
- en: '[Figure 1-6](#training_loop) shows the full picture of Samuel’s idea of training
    a machine learning model.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-6](#training_loop)展示了塞缪尔关于训练机器学习模型的完整图景。'
- en: '![The basic training loop](Images/dlcf_0106.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: ！[基本训练循环](Images/dlcf_0106.png)
- en: Figure 1-6\. Training a machine learning model
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-6。训练机器学习模型
- en: Notice the distinction between the model’s *results* (e.g., the moves in a checkers
    game) and its *performance* (e.g., whether it wins the game, or how quickly it
    wins).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 注意模型的*结果*（例如，在跳棋游戏中的移动）和其*性能*（例如，是否赢得比赛，或者赢得比赛的速度）之间的区别。
- en: Also note that once the model is trained—that is, once we’ve chosen our final,
    best, favorite weight assignment—then we can think of the weights as being *part
    of the model*, since we’re not varying them anymore.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，一旦模型训练好了，也就是说，一旦我们选择了最终的、最好的、最喜欢的权重分配，那么我们可以将权重视为*模型的一部分*，因为我们不再对它们进行变化。
- en: Therefore, actually *using* a model after it’s trained looks like [Figure 1-7](#using_model).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，实际上在训练后*使用*模型看起来像[图1-7](#using_model)。
- en: '![](Images/dlcf_0107.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_0107.png)'
- en: Figure 1-7\. Using a trained model as a program
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-7。使用训练后的模型作为程序
- en: 'This looks identical to our original diagram in [Figure 1-4](#basic_program),
    just with the word *program* replaced with *model*. This is an important insight:
    *a trained model can be treated just like a regular computer program*.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来与我们在[图1-4](#basic_program)中的原始图表相同，只是将*程序*一词替换为*模型*。这是一个重要的观点：*训练后的模型可以像常规计算机程序一样对待*。
- en: 'Jargon: Machine Learning'
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行话：机器学习
- en: The training of programs developed by allowing a computer to learn from its
    experience, rather than through manually coding the individual steps.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 通过让计算机从经验中学习而不是通过手动编码个别步骤来开发程序的培训。
- en: What Is a Neural Network?
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是神经网络？
- en: It’s not too hard to imagine what the model might look like for a checkers program.
    There might be a range of checkers strategies encoded, and some kind of search
    mechanism, and then the weights could vary how strategies are selected, what parts
    of the board are focused on during a search, and so forth. But it’s not at all
    obvious what the model might look like for an image recognition program, or for
    understanding text, or for many other interesting problems we might imagine.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 不难想象跳棋程序的模型可能是什么样子。可能编码了一系列跳棋策略，以及某种搜索机制，然后权重可以变化以决定如何选择策略，在搜索期间关注棋盘的哪些部分等等。但是对于图像识别程序，或者理解文本，或者我们可能想象的许多其他有趣的问题，模型可能是什么样子却一点也不明显。
- en: What we would like is some kind of function that is so flexible that it could
    be used to solve any given problem, just by varying its weights. Amazingly enough,
    this function actually exists! It’s the neural network, which we already discussed.
    That is, if you regard a neural network as a mathematical function, it turns out
    to be a function that is extremely flexible depending on its weights. A mathematical
    proof called the *universal approximation theorem* shows that this function can
    solve any problem to any level of accuracy, in theory. The fact that neural networks
    are so flexible means that, in practice, they are often a suitable kind of model,
    and you can focus your effort on the process of training them—that is, of finding
    good weight assignments.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望有一种函数，它如此灵活，以至于可以通过调整其权重来解决任何给定问题。令人惊讶的是，这种函数实际上存在！这就是我们已经讨论过的神经网络。也就是说，如果您将神经网络视为数学函数，那么它将是一种极其灵活的函数，取决于其权重。一种称为*通用逼近定理*的数学证明表明，这种函数在理论上可以解决任何问题，达到任何精度水平。神经网络如此灵活的事实意味着，在实践中，它们通常是一种合适的模型，您可以将精力集中在训练过程上，即找到良好的权重分配。
- en: But what about that process? One could imagine that you might need to find a
    new “mechanism” for automatically updating weight for every problem. This would
    be laborious. What we’d like here as well is a completely general way to update
    the weights of a neural network, to make it improve at any given task. Conveniently,
    this also exists!
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这个过程呢？人们可以想象，您可能需要为每个问题找到一种新的“机制”来自动更新权重。这将是费力的。我们在这里也希望有一种完全通用的方法来更新神经网络的权重，使其在任何给定任务上都能提高。方便的是，这也存在！
- en: 'This is called *stochastic gradient descent* (SGD). We’ll see how neural networks
    and SGD work in detail in [Chapter 4](ch04.xhtml#chapter_mnist_basics), as well
    as explaining the universal approximation theorem. For now, however, we will instead
    use Samuel’s own words: *We need not go into the details of such a procedure to
    see that it could be made entirely automatic and to see that a machine so programmed
    would “learn” from its experience.*'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为*随机梯度下降*（SGD）。我们将在[第4章](ch04.xhtml#chapter_mnist_basics)中详细了解神经网络和SGD的工作原理，以及解释通用逼近定理。然而，现在，我们将使用塞缪尔自己的话来说：*我们不需要深入了解这样一个过程的细节，就可以看到它可以完全自动化，并且可以看到这样一个机器编程的机器可以从中学习经验。*
- en: Jeremy Says
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 杰里米说
- en: 'Don’t worry; neither SGD nor neural nets are mathematically complex. Both nearly
    entirely rely on addition and multiplication to do their work (but they do a *lot*
    of addition and multiplication!). The main reaction we hear from students when
    they see the details is: “Is that all it is?”'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 不要担心；无论是SGD还是神经网络，在数学上都不复杂。它们几乎完全依赖于加法和乘法来完成工作（但它们进行了*大量*的加法和乘法！）。当学生们看到细节时，我们听到的主要反应是：“就是这样吗？”
- en: In other words, to recap, a neural network is a particular kind of machine learning
    model, which fits right in to Samuel’s original conception. Neural networks are
    special because they are highly flexible, which means they can solve an unusually
    wide range of problems just by finding the right weights. This is powerful, because
    stochastic gradient descent provides us a way to find those weight values automatically.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，简而言之，神经网络是一种特殊类型的机器学习模型，它完全符合塞缪尔最初的构想。神经网络之所以特殊，是因为它们非常灵活，这意味着它们可以通过找到正确的权重来解决异常广泛的问题。这是强大的，因为随机梯度下降为我们提供了一种自动找到这些权重值的方法。
- en: Having zoomed out, let’s now zoom back in and revisit our image classification
    problem using Samuel’s framework.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 放大后，让我们现在缩小范围，重新审视使用塞缪尔框架解决我们的图像分类问题。
- en: Our inputs are the images. Our weights are the weights in the neural net. Our
    model is a neural net. Our results are the values that are calculated by the neural
    net, like “dog” or “cat.”
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的输入是图像。我们的权重是神经网络中的权重。我们的模型是一个神经网络。我们的结果是由神经网络计算出的值，比如“狗”或“猫”。
- en: 'What about the next piece, an *automatic means of testing the effectiveness
    of any current weight assignment in terms of actual performance*? Determining
    “actual performance” is easy enough: we can simply define our model’s performance
    as its accuracy at predicting the correct answers.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分是什么，一个*自动测试任何当前权重分配的有效性的手段*？确定“实际表现”很容易：我们可以简单地将模型的表现定义为其在预测正确答案时的准确性。
- en: Putting this all together, and assuming that SGD is our mechanism for updating
    the weight assignments, we can see how our image classifier is a machine learning
    model, much like Samuel envisioned.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有这些放在一起，假设SGD是我们更新权重分配的机制，我们可以看到我们的图像分类器是一个机器学习模型，就像Samuel所设想的那样。
- en: A Bit of Deep Learning Jargon
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一些深度学习术语
- en: 'Samuel was working in the 1960s, and since then terminology has changed. Here
    is the modern deep learning terminology for all the pieces we have discussed:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: Samuel在1960年代工作，自那时术语已经发生了变化。以下是我们讨论过的所有部分的现代深度学习术语：
- en: The functional form of the *model* is called its *architecture* (but be careful—sometimes
    people use *model* as a synonym of *architecture*, so this can get confusing).
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型*的功能形式被称为*架构*（但要小心—有时人们将*模型*用作*架构*的同义词，这可能会让人困惑）。'
- en: The *weights* are called *parameters*.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*权重*被称为*参数*。'
- en: The *predictions* are calculated from the *independent variable*, which is the
    *data* not including the *labels*.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测*是从*独立变量*计算出来的，这是*不包括标签*的*数据*。'
- en: The *results* of the model are called *predictions*.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的*结果*被称为*预测*。
- en: The measure of *performance* is called the *loss*.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*性能*的度量被称为*损失*。'
- en: The loss depends not only on the predictions, but also on the correct *labels*
    (also known as *targets* or the *dependent variable*); e.g., “dog” or “cat.”
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失不仅取决于预测，还取决于正确的*标签*（也称为*目标*或*因变量*）；例如，“狗”或“猫”。
- en: After making these changes, our diagram in [Figure 1-6](#training_loop) looks
    like [Figure 1-8](#detailed_loop).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行这些更改后，我们在[图1-6](#training_loop)中的图表看起来像[图1-8](#detailed_loop)。
- en: '![](Images/dlcf_0108.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_0108.png)'
- en: Figure 1-8\. Detailed training loop
  id: totrans-222
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8\. 详细训练循环
- en: Limitations Inherent to Machine Learning
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习固有的限制
- en: 'From this picture, we can now see some fundamental things about training a
    deep learning model:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 从这幅图片中，我们现在可以看到关于训练深度学习模型的一些基本事情：
- en: A model cannot be created without data.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有数据就无法创建模型。
- en: A model can learn to operate on only the patterns seen in the input data used
    to train it.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型只能学习操作训练数据中看到的模式。
- en: This learning approach creates only *predictions*, not recommended *actions*.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这种学习方法只创建*预测*，而不是推荐的*行动*。
- en: It’s not enough to just have examples of input data; we need *labels* for that
    data too (e.g., pictures of dogs and cats aren’t enough to train a model; we need
    a label for each one, saying which ones are dogs and which are cats).
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅仅拥有输入数据的示例是不够的；我们还需要为这些数据提供*标签*（例如，仅有狗和猫的图片不足以训练模型；我们需要为每个图片提供一个标签，说明哪些是狗，哪些是猫）。
- en: Generally speaking, we’ve seen that most organizations that say they don’t have
    enough data actually mean they don’t have enough *labeled* data. If any organization
    is interested in doing something in practice with a model, then presumably they
    have some inputs they plan to run their model against. And presumably they’ve
    been doing that some other way for a while (e.g., manually, or with some heuristic
    program), so they have data from those processes! For instance, a radiology practice
    will almost certainly have an archive of medical scans (since they need to be
    able to check how their patients are progressing over time), but those scans may
    not have structured labels containing a list of diagnoses or interventions (since
    radiologists generally create free-text natural language reports, not structured
    data). We’ll be discussing labeling approaches a lot in this book, because it’s
    such an important issue in practice.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，我们已经看到大多数组织声称他们没有足够的数据实际上意味着他们没有足够的*带标签*数据。如果任何组织有兴趣在实践中使用模型做一些事情，那么他们可能有一些输入数据计划运行他们的模型。并且可能他们已经以其他方式做了一段时间（例如，手动或使用一些启发式程序），因此他们有来自这些过程的数据！例如，放射学实践几乎肯定会有医学扫描的存档（因为他们需要能够检查他们的患者随时间的进展），但这些扫描可能没有包含诊断或干预措施列表的结构化标签（因为放射科医生通常创建自由文本自然语言报告，而不是结构化数据）。在本书中，我们将大量讨论标记方法，因为这在实践中是一个非常重要的问题。
- en: Since these kinds of machine learning models can only make *predictions* (i.e., attempt
    to replicate labels), this can result in a significant gap between organizational
    goals and model capabilities. For instance, in this book you’ll learn how to create
    a *recommendation system* that can predict what products a user might purchase.
    This is often used in ecommerce, such as to customize products shown on a home
    page by showing the highest-ranked items. But such a model is generally created
    by looking at a user and their buying history (*inputs*) and what they went on
    to buy or look at (*labels*), which means that the model is likely to tell you
    about products the user already has, or already knows about, rather than new products
    that they are most likely to be interested in hearing about. That’s very different
    from what, say, an expert at your local bookseller might do, where they ask questions
    to figure out your taste, and then tell you about authors or series that you’ve
    never heard of before.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这类机器学习模型只能进行*预测*（即试图复制标签），这可能导致组织目标与模型能力之间存在显著差距。例如，在本书中，您将学习如何创建一个*推荐系统*，可以预测用户可能购买的产品。这通常用于电子商务，例如通过显示排名最高的商品来定制主页上显示的产品。但这样的模型通常是通过查看用户及其购买历史（*输入*）以及他们最终购买或查看的内容（*标签*）来创建的，这意味着该模型很可能会告诉您关于用户已经拥有或已经了解的产品，而不是他们最有可能对其感兴趣的新产品。这与您当地书店的专家所做的事情大不相同，他们会询问您的口味，然后告诉您您以前从未听说过的作者或系列。
- en: 'Another critical insight comes from considering how a model interacts with
    its environment. This can create *feedback loops*, as described here:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关键的洞察来自于考虑模型如何与其环境互动。这可能会产生*反馈循环*，如此处所述：
- en: A *predictive policing* model is created based on where arrests have been made
    in the past. In practice, this is not actually predicting crime, but rather predicting
    arrests, and is therefore partially simply reflecting biases in existing policing
    processes.
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于过去的逮捕地点创建了一个*预测性执法*模型。实际上，这并不是在预测犯罪，而是在预测逮捕，因此部分地只是反映了现有执法过程中的偏见。
- en: Law enforcement officers then might use that model to decide where to focus
    their policing activity, resulting in increased arrests in those areas.
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后执法人员可能会使用该模型来决定在哪里集中他们的执法活动，导致这些地区的逮捕增加。
- en: Data on these additional arrests would then be fed back in to retrain future
    versions of the model.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些额外逮捕的数据将被反馈回去重新训练未来版本的模型。
- en: 'This is a *positive feedback loop*: the more the model is used, the more biased
    the data becomes, making the model even more biased, and so forth.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个*正反馈循环*：模型被使用得越多，数据就变得越有偏见，使模型变得更加有偏见，依此类推。
- en: Feedback loops can also create problems in commercial settings. For instance,
    a video recommendation system might be biased toward recommending content consumed
    by the biggest watchers of video (e.g., conspiracy theorists and extremists tend
    to watch more online video content than the average), resulting in those users
    increasing their video consumption, resulting in more of those kinds of videos
    being recommended. We’ll consider this topic in more detail in [Chapter 3](ch03.xhtml#chapter_ethics).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈循环也可能在商业环境中造成问题。例如，视频推荐系统可能会偏向于推荐由视频最大观看者消费的内容（例如，阴谋论者和极端分子倾向于观看比平均水平更多的在线视频内容），导致这些用户增加他们的视频消费量，进而导致更多这类视频被推荐。我们将在[第三章](ch03.xhtml#chapter_ethics)中更详细地讨论这个话题。
- en: Now that you have seen the base of the theory, let’s go back to our code example
    and see in detail how the code corresponds to the process we just described.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你已经看到了理论的基础，让我们回到我们的代码示例，详细看看代码如何与我们刚刚描述的过程相对应。
- en: How Our Image Recognizer Works
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的图像识别器是如何工作的
- en: 'Let’s see just how our image recognizer code maps to these ideas. We’ll put
    each line into a separate cell, and look at what each one is doing (we won’t explain
    every detail of every parameter yet, but will give a description of the important
    bits; full details will come later in the book). The first line imports all of
    the fastai.vision library:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的图像识别器代码如何映射到这些想法。我们将把每一行放入一个单独的单元格，并查看每一行正在做什么（我们暂时不会解释每个参数的每个细节，但会给出重要部分的描述；完整细节将在本书后面提供）。第一行导入了整个fastai.vision库：
- en: '[PRE4]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This gives us all of the functions and classes we will need to create a wide
    variety of computer vision models.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了创建各种计算机视觉模型所需的所有函数和类。
- en: Jeremy Says
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jeremy说
- en: A lot of Python coders recommend avoiding importing a whole library like this
    (using the `import *` syntax) because in large software projects it can cause
    problems. However, for interactive work such as in a Jupyter notebook, it works
    great. The fastai library is specially designed to support this kind of interactive
    use, and it will import only the necessary pieces into your environment.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 许多Python编程人员建议避免像这样导入整个库（使用`import *`语法），因为在大型软件项目中可能会引起问题。然而，在交互式工作中，比如在Jupyter笔记本中，它非常有效。fastai库专门设计用于支持这种交互式使用，它只会将必要的部分导入到您的环境中。
- en: 'The second line downloads a standard dataset from the [fast.ai datasets collection](https://course.fast.ai/datasets)
    (if not previously downloaded) to your server, extracts it (if not previously
    extracted), and returns a `Path` object with the extracted location:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 第二行从[fast.ai数据集合](https://course.fast.ai/datasets)下载一个标准数据集（如果之前没有下载），将其提取出来（如果之前没有提取），并返回一个提取位置的`Path`对象：
- en: '[PRE5]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Sylvain Says
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sylvain说
- en: Throughout my time studying at fast.ai, and even still today, I’ve learned a
    lot about productive coding practices. The fastai library and fast.ai notebooks
    are full of great little tips that have helped make me a better programmer. For
    instance, notice that the fastai library doesn’t just return a string containing
    the path to the dataset, but a `Path` object. This is a really useful class from
    the Python 3 standard library that makes accessing files and directories much
    easier. If you haven’t come across it before, be sure to check out its documentation
    or a tutorial and try it out. Note that the [book’s website](https://book.fast.ai)
    contains links to recommended tutorials for each chapter. I’ll keep letting you
    know about little coding tips I’ve found useful as we come across them.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在fast.ai学习期间，甚至到今天，我学到了很多关于高效编码实践的知识。fastai库和fast.ai笔记本中充满了许多有用的小贴士，这些贴士帮助我成为了一个更好的程序员。例如，请注意fastai库不仅返回包含数据集路径的字符串，而是一个`Path`对象。这是Python
    3标准库中一个非常有用的类，使得访问文件和目录变得更加容易。如果你之前没有接触过它，请务必查看其文档或教程并尝试使用。请注意，[书籍网站](https://book.fast.ai)包含了每章推荐教程的链接。我会继续在我们遇到时告诉你我发现有用的小编码技巧。
- en: 'In the third line, we define a function, `is_cat`, that labels cats based on
    a filename rule provided by the dataset’s creators:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三行，我们定义了一个函数`is_cat`，根据数据集创建者提供的文件名规则来标记猫：
- en: '[PRE6]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We use that function in the fourth line, which tells fastai what kind of dataset
    we have and how it is structured:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第四行使用了这个函数，告诉fastai我们拥有什么类型的数据集以及它的结构：
- en: '[PRE7]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: There are various classes for different kinds of deep learning datasets and
    problems—here we’re using `ImageDataLoaders`. The first part of the class name
    will generally be the type of data you have, such as image or text.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的深度学习数据集和问题有各种类别，这里我们使用`ImageDataLoaders`。类名的第一部分通常是你拥有的数据类型，比如图像或文本。
- en: The other important piece of information that we have to tell fastai is how
    to get the labels from the dataset. Computer vision datasets are normally structured
    in such a way that the label for an image is part of the filename or path—most
    commonly the parent folder name. fastai comes with a number of standardized labeling
    methods, and ways to write your own. Here we’re telling fastai to use the `is_cat`
    function we just defined.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须告诉fastai的另一个重要信息是如何从数据集中获取标签。计算机视觉数据集通常以标签作为文件名或路径的一部分进行结构化，最常见的是父文件夹名称。fastai带有许多标准化的标记方法，以及编写自己的方法。在这里，我们告诉fastai使用我们刚刚定义的`is_cat`函数。
- en: 'Finally, we define the `Transform`s that we need. A `Transform` contains code
    that is applied automatically during training; fastai includes many predefined
    `Transform`s, and adding new ones is as simple as creating a Python function.
    There are two kinds: `item_tfms` are applied to each item (in this case, each
    item is resized to a 224-pixel square), while `batch_tfms` are applied to a *batch*
    of items at a time using the GPU, so they’re particularly fast (we’ll see many
    examples of these throughout this book).'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们定义了我们需要的`Transform`。`Transform`包含在训练期间自动应用的代码；fastai包含许多预定义的`Transform`，添加新的`Transform`就像创建一个Python函数一样简单。有两种类型：`item_tfms`应用于每个项目（在本例中，每个项目都被调整为224像素的正方形），而`batch_tfms`应用于一次处理一批项目的GPU，因此它们特别快速（我们将在本书中看到许多这样的例子）。
- en: Why 224 pixels? This is the standard size for historical reasons (old pretrained
    models require this size exactly), but you can pass pretty much anything. If you
    increase the size, you’ll often get a model with better results (since it will
    be able to focus on more details), but at the price of speed and memory consumption;
    the opposite is true if you decrease the size.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么是224像素？出于历史原因（旧的预训练模型需要这个确切的尺寸），但你几乎可以传入任何尺寸。如果增加尺寸，通常会得到更好的模型结果（因为它可以关注更多细节），但代价是速度和内存消耗；如果减小尺寸，则相反。
- en: 'Jargon: Classification and Regression'
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语：分类和回归
- en: '*Classification* and *regression* have very specific meanings in machine learning.
    These are the two main types of model that we will be investigating in this book.
    A *classification model* is one that attempts to predict a class, or category.
    That is, it’s predicting from a number of discrete possibilities, such as “dog”
    or “cat.” A *regression model* is one that attempts to predict one or more numeric
    quantities, such as a temperature or a location. Sometimes people use the word
    *regression* to refer to a particular kind of model called a *linear regression
    model*; this is a bad practice, and we won’t be using that terminology in this
    book!'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '*分类*和*回归*在机器学习中有非常具体的含义。这两种模型是我们在本书中将要研究的两种主要类型。*分类模型*试图预测一个类别。也就是说，它从许多离散的可能性中进行预测，比如“狗”或“猫”。*回归模型*试图预测一个或多个数值，比如温度或位置。有时人们使用*回归*一词来指代一种特定类型的模型，称为*线性回归模型*；这是一个不好的做法，在本书中我们不会使用这种术语！'
- en: 'The Pet dataset contains 7,390 pictures of dogs and cats, consisting of 37
    breeds. Each image is labeled using its filename: for instance, the file *great_pyrenees_173.jpg*
    is the 173rd example of an image of a Great Pyrenees breed dog in the dataset.
    The filenames start with an uppercase letter if the image is a cat, and a lowercase
    letter otherwise. We have to tell fastai how to get labels from the filenames,
    which we do by calling `from_name_func` (which means that filenames can be extracted
    using a function applied to the filename) and passing `x[0].isupper()`, which
    evaluates to `True` if the first letter is uppercase (i.e., it’s a cat).'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Pet数据集包含7390张狗和猫的图片，包括37种品种。每个图像都使用其文件名进行标记：例如，文件*great_pyrenees_173.jpg*是数据集中大白熊犬品种的第173个示例图像。如果图像是猫，则文件名以大写字母开头，否则以小写字母开头。我们必须告诉fastai如何从文件名中获取标签，我们通过调用`from_name_func`来实现（这意味着可以使用应用于文件名的函数来提取文件名），并传递`x[0].isupper()`，如果第一个字母是大写字母（即是猫），则评估为`True`。
- en: The most important parameter to mention here is `valid_pct=0.2`. This tells
    fastai to hold out 20% of the data and *not use it for training the model at all*.
    This 20% of the data is called the *validation set*; the remaining 80% is called
    the *training set*. The validation set is used to measure the accuracy of the
    model. By default, the 20% that is held out is selected randomly. The parameter
    `seed=42` sets the *random seed* to the same value every time we run this code,
    which means we get the same validation set every time we run it—this way, if we
    change our model and retrain it, we know that any differences are due to the changes
    to the model, not due to having a different random validation set.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里提到的最重要的参数是`valid_pct=0.2`。这告诉fastai保留20%的数据，*完全不用于训练模型*。这20%的数据被称为*验证集*；剩下的80%被称为*训练集*。验证集用于衡量模型的准确性。默认情况下，被保留的20%是随机选择的。参数`seed=42`将*随机种子*设置为每次运行此代码时相同的值，这意味着每次运行时我们都会得到相同的验证集，这样，如果我们更改模型并重新训练它，我们知道任何差异都是由于对模型的更改，而不是由于有不同的随机验证集。
- en: 'fastai will *always* show you your model’s accuracy using *only* the validation
    set, *never* the training set. This is absolutely critical, because if you train
    a large enough model for a long enough time, it will eventually memorize the label
    of every item in your dataset! The result will not be a useful model, because
    what we care about is how well our model works on *previously unseen images*.
    That is always our goal when creating a model: for it to be useful on data that
    the model sees only in the future, after it has been trained.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: fastai将*始终*仅使用*验证集*显示模型的准确性，*永远不会*使用训练集。这是绝对关键的，因为如果您为足够长的时间训练足够大的模型，它最终会记住数据集中每个项目的标签！结果将不是一个有用的模型，因为我们关心的是我们的模型在*以前未见过的图像*上的工作效果。这总是我们创建模型时的目标：使其在模型仅在未来看到的数据上有用，经过训练后。
- en: Even when your model has not fully memorized all your data, earlier on in training
    it may have memorized certain parts of it. As a result, the longer you train for,
    the better your accuracy will get on the training set; the validation set accuracy
    will also improve for a while, but eventually it will start getting worse as the
    model starts to memorize the training set rather than finding generalizable underlying
    patterns in the data. When this happens, we say that the model is *overfitting*.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您的模型尚未完全记住所有数据，在训练的早期阶段可能已经记住了其中的某些部分。因此，您训练的时间越长，您在训练集上的准确性就会越好；验证集的准确性也会在一段时间内提高，但最终会开始变差，因为模型开始记住训练集而不是在数据中找到可泛化的潜在模式。当这种情况发生时，我们说模型*过拟合*。
- en: '[Figure 1-9](#img_overfit) shows what happens when you overfit, using a simplified
    example where we have just one parameter and some randomly generated data based
    on the function `x**2`. As you see, although the predictions in the overfit model
    are accurate for data near the observed data points, they are way off when outside
    of that range.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-9](#img_overfit)展示了过拟合时会发生什么，使用一个简化的例子，我们只有一个参数和一些基于函数`x**2`随机生成的数据。正如您所看到的，尽管过拟合模型在接近观察到的数据点的数据上的预测是准确的，但在该范围之外时则相差甚远。'
- en: '![Example of overfitting](Images/dlcf_0109.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![过拟合示例](Images/dlcf_0109.png)'
- en: Figure 1-9\. Example of overfitting
  id: totrans-264
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-9\. 过拟合示例
- en: '**Overfitting is the single most important and challenging issue** when training
    for all machine learning practitioners, and all algorithms. As you will see, it
    is easy to create a model that does a great job at making predictions on the exact
    data it has been trained on, but it is much harder to make accurate predictions
    on data the model has never seen before. And of course, this is the data that
    will matter in practice. For instance, if you create a handwritten digit classifier
    (as we will soon!) and use it to recognize numbers written on checks, then you
    are never going to see any of the numbers that the model was trained on—every
    check will have slightly different variations of writing to deal with.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '**过拟合是训练所有机器学习从业者和所有算法时最重要和具有挑战性的问题**。正如您将看到的，很容易创建一个在准确预测其训练数据上做得很好的模型，但要在模型从未见过的数据上做出准确预测要困难得多。当然，这些数据在实践中是重要的。例如，如果您创建一个手写数字分类器（我们很快就会！）并将其用于识别支票上写的数字，那么您永远不会看到模型训练过的任何数字——每张支票都会有稍微不同的书写变化。'
- en: You will learn many methods to avoid overfitting in this book. However, you
    should use those methods only after you have confirmed that overfitting is occurring
    (i.e., if you have observed the validation accuracy getting worse during training).
    We often see practitioners using overfitting avoidance techniques even when they
    have enough data that they didn’t need to do so, ending up with a model that may
    be less accurate than what they could have achieved.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在本书中学习许多避免过拟合的方法。但是，只有在确认发生过拟合时（即，如果您观察到训练过程中验证准确性变差）才应使用这些方法。我们经常看到从业者在有足够数据的情况下也使用过拟合避免技术，最终得到的模型可能比他们本可以实现的更不准确。
- en: Validation Set
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证集
- en: When you train a model, you must *always* have both a training set and a validation
    set, and you must measure the accuracy of your model only on the validation set.
    If you train for too long, with not enough data, you will see the accuracy of
    your model start to get worse; this is called *overfitting*. fastai defaults `valid_pct`
    to `0.2`, so even if you forget, fastai will create a validation set for you!
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 当您训练模型时，您必须*始终*同时拥有训练集和验证集，并且必须仅在验证集上测量模型的准确性。如果您训练时间过长，数据不足，您将看到模型的准确性开始变差；这被称为*过拟合*。fastai将`valid_pct`默认设置为`0.2`，因此即使您忘记了，fastai也会为您创建一个验证集！
- en: 'The fifth line of the code training our image recognizer tells fastai to create
    a *convolutional neural network* (CNN) and specifies what *architecture* to use
    (i.e., what kind of model to create), what data we want to train it on, and what
    *metric* to use:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的图像识别器训练代码的第五行告诉fastai创建一个*卷积神经网络*（CNN），并指定要使用的*架构*（即要创建的模型类型）、我们要对其进行训练的数据以及要使用的*度量标准*：
- en: '[PRE8]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Why a CNN? It’s the current state-of-the-art approach to creating computer vision
    models. We’ll be learning all about how CNNs work in this book. Their structure
    is inspired by how the human vision system works.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么使用CNN？这是创建计算机视觉模型的当前最先进方法。我们将在本书中学习有关CNN如何工作的所有知识。它们的结构受到人类视觉系统工作方式的启发。
- en: There are many architectures in fastai, which we will introduce in this book
    (as well as discussing how to create your own). Most of the time, however, picking
    an architecture isn’t a very important part of the deep learning process. It’s
    something that academics love to talk about, but in practice it is unlikely to
    be something you need to spend much time on. There are some standard architectures
    that work most of the time, and in this case we’re using one called *ResNet* that
    we’ll be talking a lot about in the book; it is both fast and accurate for many
    datasets and problems. The `34` in `resnet34` refers to the number of layers in
    this variant of the architecture (other options are `18`, `50`, `101`, and `152`).
    Models using architectures with more layers take longer to train and are more
    prone to overfitting (i.e., you can’t train them for as many epochs before the
    accuracy on the validation set starts getting worse). On the other hand, when
    using more data, they can be quite a bit more accurate.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在fastai中有许多架构，我们将在本书中介绍（以及讨论如何创建您自己的架构）。然而，大多数情况下，选择架构并不是深度学习过程中非常重要的部分。这是学术界喜欢谈论的内容，但实际上您不太可能需要花费太多时间。有一些标准架构在大多数情况下都有效，而在这种情况下，我们使用的是一种称为*ResNet*的架构，我们将在本书中大量讨论；它对许多数据集和问题都既快速又准确。`resnet34`中的`34`指的是该架构变体中的层数（其他选项是`18`、`50`、`101`和`152`）。使用层数更多的架构模型训练时间更长，更容易过拟合（即在验证集上的准确率开始变差之前无法训练多少个时期）。另一方面，当使用更多数据时，它们可能会更准确。
- en: 'What is a metric? A *metric* is a function that measures the quality of the
    model’s predictions using the validation set, and will be printed at the end of
    each epoch. In this case, we’re using `error_rate`, which is a function provided
    by fastai that does just what it says: tells you what percentage of images in
    the validation set are being classified incorrectly. Another common metric for
    classification is `accuracy` (which is just `1.0 - error_rate`). fastai provides
    many more, which will be discussed throughout this book.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是度量标准？*度量标准*是一个函数，使用验证集来衡量模型预测的质量，并将在每个时期结束时打印出来。在这种情况下，我们使用`error_rate`，这是fastai提供的一个函数，它正是它所说的：告诉您验证集中有多少百分比的图像被错误分类。分类的另一个常见度量标准是`accuracy`（即`1.0
    - error_rate`）。fastai提供了许多其他度量标准，这将在本书中讨论。
- en: The concept of a metric may remind you of *loss*, but there is an important
    distinction. The entire purpose of loss is to define a “measure of performance”
    that the training system can use to update weights automatically. In other words,
    a good choice for loss is a choice that is easy for stochastic gradient descent
    to use. But a metric is defined for human consumption, so a good metric is one
    that is easy for you to understand, and that hews as closely as possible to what
    you want the model to do. At times, you might decide that the loss function is
    a suitable metric, but that is not necessarily the case.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 度量标准的概念可能会让您想起*损失*，但有一个重要区别。损失的整个目的是定义一个“性能度量”，训练系统可以使用它来自动更新权重。换句话说，损失的一个好选择是易于随机梯度下降使用的选择。但度量标准是为人类消费而定义的，因此一个好的度量标准是您易于理解的，并且尽可能接近您希望模型执行的任务。有时，您可能会决定损失函数是一个合适的度量标准，但这并不一定是情况。
- en: '`cnn_learner` also has a parameter `pretrained`, which defaults to `True` (so
    it’s used in this case, even though we haven’t specified it), which sets the weights
    in your model to values that have already been trained by experts to recognize
    a thousand different categories across 1.3 million photos (using the famous [*ImageNet*](http://www.image-net.org)
    dataset). A model that has weights that have already been trained on another dataset
    is called a *pretrained model*. You should nearly always use a pretrained model,
    because it means that your model, before you’ve even shown it any of your data,
    is already very capable. And as you’ll see, in a deep learning model, many of
    these capabilities are things you’ll need, almost regardless of the details of
    your project. For instance, parts of pretrained models will handle edge, gradient,
    and color detection, which are needed for many tasks.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '`cnn_learner`还有一个名为`pretrained`的参数，默认值为`True`（因此在这种情况下使用，即使我们没有指定），它将您模型中的权重设置为已经由专家训练过的值，以识别130万张照片中的一千个不同类别（使用著名的[*ImageNet*](http://www.image-net.org)数据集）。具有已在另一个数据集上训练过的权重的模型称为*预训练模型*。您几乎总是应该使用预训练模型，因为这意味着您的模型在您甚至没有展示任何数据之前就已经非常有能力。正如您将看到的，在深度学习模型中，许多这些能力是您几乎无论项目细节如何都需要的。例如，预训练模型的部分将处理边缘、梯度和颜色检测，这些对许多任务都是必需的。'
- en: When using a pretrained model, `cnn_learner` will remove the last layer, since
    that is always specifically customized to the original training task (i.e., ImageNet
    dataset classification), and replace it with one or more new layers with randomized
    weights, of an appropriate size for the dataset you are working with. This last
    part of the model is known as the *head*.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预训练模型时，`cnn_learner`将移除最后一层，因为该层始终是针对原始训练任务（即ImageNet数据集分类）专门定制的，并将其替换为一个或多个具有随机权重的新层，适合您正在处理的数据集的大小。模型的最后部分被称为*头*。
- en: 'Using pretrained models is the *most* important method we have to allow us
    to train more accurate models, more quickly, with less data and less time and
    money. You might think that would mean that using pretrained models would be the
    most studied area in academic deep learning…but you’d be very, very wrong! The
    importance of pretrained models is generally not recognized or discussed in most
    courses, books, or software library features, and is rarely considered in academic
    papers. As we write this at the start of 2020, things are just starting to change,
    but it’s likely to take a while. So be careful: most people you speak to will
    probably greatly underestimate what you can do in deep learning with few resources,
    because they probably won’t deeply understand how to use pretrained models.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预训练模型是我们训练更准确、更快速、使用更少数据和更少时间和金钱的最重要方法。您可能会认为使用预训练模型将是学术深度学习中最研究的领域...但您会非常、非常错误！预训练模型的重要性通常在大多数课程、书籍或软件库功能中没有得到认可或讨论，并且在学术论文中很少被考虑。当我们在2020年初写这篇文章时，事情刚刚开始改变，但这可能需要一段时间。因此要小心：您与之交谈的大多数人可能会严重低估您可以在深度学习中使用少量资源做些什么，因为他们可能不会深入了解如何使用预训练模型。
- en: Using a pretrained model for a task different from what it was originally trained
    for is known as *transfer learning*. Unfortunately, because transfer learning
    is so under-studied, few domains have pretrained models available. For instance,
    few pretrained models are currently available in medicine, making transfer learning
    challenging to use in that domain. In addition, it is not yet well understood
    how to use transfer learning for tasks such as time series analysis.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个预训练模型来执行一个与其最初训练目的不同的任务被称为*迁移学习*。不幸的是，由于迁移学习研究不足，很少有领域提供预训练模型。例如，目前在医学领域很少有预训练模型可用，这使得在该领域使用迁移学习具有挑战性。此外，目前还不清楚如何将迁移学习应用于诸如时间序列分析之类的任务。
- en: 'Jargon: Transfer Learning'
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语：迁移学习
- en: Using a pretrained model for a task different from what it was originally trained
    for.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个预训练模型来执行一个与其最初训练目的不同的任务。
- en: 'The sixth line of our code tells fastai how to *fit* the model:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们代码的第六行告诉fastai如何*适应*模型：
- en: '[PRE9]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As we’ve discussed, the architecture only describes a *template* for a mathematical
    function; it doesn’t actually do anything until we provide values for the millions
    of parameters it contains.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所讨论的，架构只是描述数学函数的*模板*；直到我们为其包含的数百万参数提供值之前，它才会真正发挥作用。
- en: 'This is the key to deep learning—determining how to fit the parameters of a
    model to get it to solve your problem. To fit a model, we have to provide at least
    one piece of information: how many times to look at each image (known as number
    of *epochs*). The number of epochs you select will largely depend on how much
    time you have available, and how long you find it takes in practice to fit your
    model. If you select a number that is too small, you can always train for more
    epochs later.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这是深度学习的关键之处——确定如何适应模型的参数以使其解决您的问题。要适应一个模型，我们必须提供至少一条信息：每个图像查看多少次（称为*时代*数）。您选择的时代数将在很大程度上取决于您有多少时间可用，以及您发现在实践中适应模型需要多长时间。如果选择的数字太小，您可以随时稍后进行更多时代的训练。
- en: But why is the method called `fine_tune`, and not `fit`? fastai *does* have
    a method called `fit`, which does indeed fit a model (i.e., look at images in
    the training set multiple times, each time updating the parameters to make the
    predictions closer and closer to the target labels). But in this case, we’ve started
    with a pretrained model, and we don’t want to throw away all those capabilities
    that it already has. As you’ll learn in this book, there are some important tricks
    to adapt a pretrained model for a new dataset—a process called *fine-tuning*.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 但为什么这种方法被称为“fine_tune”，而不是“fit”？fastai确实有一个名为“fit”的方法，它确实适合一个模型（即，多次查看训练集中的图像，每次更新参数使预测越来越接近目标标签）。但在这种情况下，我们已经从一个预训练模型开始，并且我们不想丢弃它已经具有的所有这些功能。正如您将在本书中了解到的，有一些重要的技巧可以使预训练模型适应新数据集，这个过程称为*微调*。
- en: 'Jargon: Fine-Tuning'
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语：微调
- en: A transfer learning technique that updates the parameters of a pretrained model
    by training for additional epochs using a different task from that used for pretraining.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 一种迁移学习技术，通过使用与预训练不同的任务进行额外时代的训练来更新预训练模型的参数。
- en: 'When you use the `fine_tune` method, fastai will use these tricks for you.
    There are a few parameters you can set (which we’ll discuss later), but in the
    default form shown here, it does two steps:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用`fine_tune`方法时，fastai将为您使用这些技巧。您可以设置一些参数（我们稍后会讨论），但在此处显示的默认形式中，它执行两个步骤：
- en: Use one epoch to fit just those parts of the model necessary to get the new
    random head to work correctly with your dataset.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用一个时代来适应模型的那些部分，以使新的随机头部能够正确地与您的数据集配合工作。
- en: Use the number of epochs requested when calling the method to fit the entire
    model, updating the weights of the later layers (especially the head) faster than
    the earlier layers (which, as we’ll see, generally don’t require many changes
    from the pretrained weights).
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在调用适合整个模型的方法时，请使用请求的时代数，更快地更新后面的层（特别是头部）的权重，而不是早期的层（正如我们将看到的，通常不需要对预训练权重进行太多更改）。
- en: The *head* of a model is the part that is newly added to be specific to the
    new dataset. An *epoch* is one complete pass through the dataset. After calling
    `fit`, the results after each epoch are printed, showing the epoch number, the
    training and validation set losses (the “measure of performance” used for training
    the model), and any *metrics* you’ve requested (error rate, in this case).
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的*头部*是新添加的部分，专门针对新数据集。一个*时代*是对数据集的一次完整遍历。在调用`fit`之后，每个时代后的结果都会被打印出来，显示时代编号，训练和验证集的损失（用于训练模型的“性能度量”），以及您请求的任何*指标*（在这种情况下是错误率）。
- en: So, with all this code, our model learned to recognize cats and dogs just from
    labeled examples. But how did it do it?
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过所有这些代码，我们的模型学会了仅仅通过标记的示例来识别猫和狗。但它是如何做到的呢？
- en: What Our Image Recognizer Learned
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的图像识别器学到了什么
- en: At this stage, we have an image recognizer that is working well, but we have
    no idea what it is doing! Although many people complain that deep learning results
    in impenetrable “black box” models (that is, something that gives predictions
    but that no one can understand), this really couldn’t be further from the truth.
    There is a vast body of research showing how to deeply inspect deep learning models
    and get rich insights from them. Having said that, all kinds of machine learning
    models (including deep learning and traditional statistical models) can be challenging
    to fully understand, especially when considering how they will behave when coming
    across data that is very different from the data used to train them. We’ll be
    discussing this issue throughout this book.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们有一个工作良好的图像识别器，但我们不知道它在做什么！尽管许多人抱怨深度学习导致不可理解的“黑匣子”模型（即，可以提供预测但没有人能理解的东西），但事实并非如此。有大量研究表明如何深入检查深度学习模型并从中获得丰富的见解。话虽如此，各种机器学习模型（包括深度学习和传统统计模型）都可能难以完全理解，特别是考虑到它们在遇到与用于训练它们的数据非常不同的数据时的行为。我们将在本书中讨论这个问题。
- en: In 2013, PhD student Matt Zeiler and his supervisor, Rob Fergus, published [“Visualizing
    and Understanding Convolutional Networks”](https://oreil.ly/iP8cr), which showed
    how to visualize the neural network weights learned in each layer of a model.
    They carefully analyzed the model that won the 2012 ImageNet competition, and
    used this analysis to greatly improve the model, such that they were able to go
    on to win the 2013 competition! [Figure 1-10](#img_layer1) is the picture that
    they published of the first layer’s weights.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 2013年，博士生Matt Zeiler和他的导师Rob Fergus发表了《可视化和理解卷积网络》，展示了如何可视化模型每一层学到的神经网络权重。他们仔细分析了赢得2012年ImageNet比赛的模型，并利用这一分析大大改进了模型，使他们能够赢得2013年的比赛！[图1-10](#img_layer1)是他们发表的第一层权重的图片。
- en: '![Activations of early layers of a CNN](Images/dlcf_0110.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![CNN早期层的激活](Images/dlcf_0110.png)'
- en: Figure 1-10\. Activations of the first layer of a CNN (courtesy of Matthew D.
    Zeiler and Rob Fergus)
  id: totrans-297
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10。CNN第一层的激活（由Matthew D. Zeiler和Rob Fergus提供）
- en: This picture requires some explanation. For each layer, the image part with
    the light gray background shows the reconstructed weights, and the larger section
    at the bottom shows the parts of the training images that most strongly matched
    each set of weights. For layer 1, what we can see is that the model has discovered
    weights that represent diagonal, horizontal, and vertical edges, as well as various
    gradients. (Note that for each layer, only a subset of the features is shown;
    in practice there are thousands across all of the layers.)
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图片需要一些解释。对于每一层，具有浅灰色背景的图像部分显示了重建的权重，底部较大的部分显示了与每组权重最匹配的训练图像部分。对于第一层，我们可以看到模型发现了代表对角线、水平和垂直边缘以及各种梯度的权重。（请注意，对于每一层，只显示了部分特征；实际上，在所有层中有成千上万个特征。）
- en: These are the basic building blocks that the model has learned for computer
    vision. They have been widely analyzed by neuroscientists and computer vision
    researchers, and it turns out that these learned building blocks are very similar
    to the basic visual machinery in the human eye, as well as the handcrafted computer
    vision features that were developed prior to the days of deep learning. The next
    layer is represented in [Figure 1-11](#img_layer2).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是模型为计算机视觉学习的基本构建块。它们已经被神经科学家和计算机视觉研究人员广泛分析，结果表明，这些学习的构建块与人眼的基本视觉机制以及在深度学习之前开发的手工计算机视觉特征非常相似。下一层在[图1-11](#img_layer2)中表示。
- en: '![Activations of early layers of a CNN](Images/dlcf_0111.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![CNN早期层的激活](Images/dlcf_0111.png)'
- en: Figure 1-11\. Activations of the second layer of a CNN (courtesy of Matthew
    D. Zeiler and Rob Fergus)
  id: totrans-301
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-11。CNN第二层的激活（由Matthew D. Zeiler和Rob Fergus提供）
- en: For layer 2, there are nine examples of weight reconstructions for each of the
    features found by the model. We can see that the model has learned to create feature
    detectors that look for corners, repeating lines, circles, and other simple patterns.
    These are built from the basic building blocks developed in the first layer. For
    each of these, the righthand side of the picture shows small patches from actual
    images that these features most closely match. For instance, the particular pattern
    in row 2, column 1 matches the gradients and textures associated with sunsets.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第2层，模型找到的每个特征都有九个权重重建示例。我们可以看到模型已经学会创建寻找角、重复线条、圆圈和其他简单模式的特征检测器。这些是从第一层中开发的基本构建块构建的。对于每个特征，图片右侧显示了与这些特征最匹配的实际图像的小块。例如，第2行第1列中的特定模式与日落相关的梯度和纹理相匹配。
- en: '[Figure 1-12](#img_layer3) shows the image from the paper showing the results
    of reconstructing the features of layer 3.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-12](#img_layer3)显示了一篇论文中展示第3层特征重建结果的图片。'
- en: '![Activations of medium layers of a CNN](Images/dlcf_0112.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![CNN中间层的激活](Images/dlcf_0112.png)'
- en: Figure 1-12\. Activations of the third layer of a CNN (courtesy of Matthew D.
    Zeiler and Rob Fergus)
  id: totrans-305
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-12。CNN第三层的激活（由Matthew D. Zeiler和Rob Fergus提供）
- en: As you can see by looking at the righthand side of this picture, the features
    are now able to identify and match with higher-level semantic components, such
    as car wheels, text, and flower petals. Using these components, layers 4 and 5
    can identify even higher-level concepts, as shown in [Figure 1-13](#img_layer4).
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察图片右侧，您可以看到特征现在能够识别和匹配更高级的语义组件，如汽车车轮、文字和花瓣。利用这些组件，第4层和第5层可以识别更高级的概念，如[图1-13](#img_layer4)所示。
- en: '![Activations of end layers of a CNN](Images/dlcf_0113.png)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![CNN末端层的激活](Images/dlcf_0113.png)'
- en: Figure 1-13\. Activations of the fourth and fifth layers of a CNN (courtesy
    of Matthew D. Zeiler and Rob Fergus)
  id: totrans-308
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-13。CNN的第四和第五层的激活（由Matthew D. Zeiler和Rob Fergus提供）
- en: This article was studying an older model called *AlexNet* that contained only
    five layers. Networks developed since then can have hundreds of layers—so you
    can imagine how rich the features developed by these models can be!
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 本文研究了一个名为*AlexNet*的旧模型，该模型只包含五层。自那时以来开发的网络可以有数百层 - 所以你可以想象这些模型开发的特征有多丰富！
- en: When we fine-tuned our pretrained model earlier, we adapted what those last
    layers focus on (flowers, humans, animals) to specialize on the cats versus dogs
    problem. More generally, we could specialize such a pretrained model on many different
    tasks. Let’s have a look at some examples.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们早期微调我们的预训练模型时，我们调整了最后几层关注的内容（花朵、人类、动物），以专注于猫与狗问题。更一般地，我们可以将这样的预训练模型专门用于许多不同的任务。让我们看一些例子。
- en: Image Recognizers Can Tackle Non-Image Tasks
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像识别器可以处理非图像任务
- en: An image recognizer can, as its name suggests, only recognize images. But a
    lot of things can be represented as images, which means that an image recognizer
    can learn to complete many tasks.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图像识别器只能识别图像，顾名思义。但很多事物可以被表示为图像，这意味着图像识别器可以学会完成许多任务。
- en: For instance, a sound can be converted to a spectrogram, which is a chart that
    shows the amount of each frequency at each time in an audio file. Fast.ai student
    Ethan Sutin used this approach to [easily beat the published accuracy of a state-of-the-art
    environmental sound detection model](https://oreil.ly/747uv) using a dataset of
    8,732 urban sounds. fastai’s `show_batch` clearly shows how each sound has a quite
    distinctive spectrogram, as you can see in [Figure 1-14](#img_spect).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，声音可以转换为频谱图，这是一种图表，显示音频文件中每个时间的每个频率的数量。fast.ai学生Ethan Sutin使用这种方法，[轻松击败了一种最先进的环境声音检测模型的发布准确率](https://oreil.ly/747uv)，使用了8732个城市声音的数据集。fastai的`show_batch`清楚地显示了每个声音具有相当独特的频谱图，如[图1-14](#img_spect)所示。
- en: '![show_batch with spectrograms of sounds](Images/dlcf_0114.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![显示具有声音频谱图的show_batch](Images/dlcf_0114.png)'
- en: Figure 1-14\. show_batch with spectrograms of sounds
  id: totrans-315
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-14。显示具有声音频谱图的show_batch
- en: A time series can easily be converted into an image by simply plotting the time
    series on a graph. However, it is often a good idea to try to represent your data
    in a way that makes it as easy as possible to pull out the most important components.
    In a time series, things like seasonality and anomalies are most likely to be
    of interest.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列可以很容易地通过简单地在图表上绘制时间序列来转换为图像。然而，通常最好尝试以尽可能简单的方式表示数据，以便提取出最重要的组件。在时间序列中，季节性和异常很可能是感兴趣的。
- en: Various transformations are available for time series data. For instance, fast.ai
    student Ignacio Oguiza created images from a time series dataset for olive oil
    classification, using a technique called Gramian Angular Difference Field (GADF);
    you can see the result in [Figure 1-15](#ts_image). He then fed those images to
    an image classification model just like the one you see in this chapter. His results,
    despite having only 30 training set images, were well over 90% accurate, and close
    to the state of the art.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列数据有各种转换方法。例如，fast.ai学生Ignacio Oguiza使用一种称为Gramian Angular Difference Field（GADF）的技术，从一个时间序列数据集中为橄榄油分类创建图像，你可以在[图1-15](#ts_image)中看到结果。然后，他将这些图像输入到一个图像分类模型中，就像你在本章中看到的那样。尽管只有30个训练集图像，但他的结果准确率超过90%，接近最先进水平。
- en: '![Converting a time series into an image](Images/dlcf_0115.png)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![将时间序列转换为图像](Images/dlcf_0115.png)'
- en: Figure 1-15\. Converting a time series into an image
  id: totrans-319
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-15。将时间序列转换为图像
- en: Another interesting fast.ai student project example comes from Gleb Esman. He
    was working on fraud detection at Splunk, using a dataset of users’ mouse movements
    and mouse clicks. He turned these into pictures by drawing an image displaying
    the position, speed, and acceleration of the mouse pointer by using colored lines,
    and the clicks were displayed using [small colored circles](https://oreil.ly/6-I_X),
    as shown in [Figure 1-16](#splunk). He fed this into an image recognition model
    just like the one we’ve used in this chapter, and it worked so well that it led
    to a patent for this approach to fraud analytics!
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的fast.ai学生项目示例来自Gleb Esman。他在Splunk上进行欺诈检测，使用了用户鼠标移动和鼠标点击的数据集。他通过绘制显示鼠标指针位置、速度和加速度的图像，使用彩色线条，并使用[小彩色圆圈](https://oreil.ly/6-I_X)显示点击，将这些转换为图片，如[图1-16](#splunk)所示。他将这些输入到一个图像识别模型中，就像我们在本章中使用的那样，效果非常好，导致了这种方法在欺诈分析方面的专利！
- en: '![Converting computer mouse behavior to an image](Images/dlcf_0116.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![将计算机鼠标行为转换为图像](Images/dlcf_0116.png)'
- en: Figure 1-16\. Converting computer mouse behavior to an image
  id: totrans-322
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-16。将计算机鼠标行为转换为图像
- en: Another example comes from the paper [“Malware Classification with Deep Convolutional
    Neural Networks”](https://oreil.ly/l_knA) by Mahmoud Kalash et al., which explains
    that “the malware binary file is divided into 8-bit sequences which are then converted
    to equivalent decimal values. This decimal vector is reshaped and [a] gray-scale
    image is generated that represent[s] the malware sample,” in [Figure 1-17](#malware_proc).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子来自Mahmoud Kalash等人的论文“使用深度卷积神经网络进行恶意软件分类”，解释了“恶意软件二进制文件被分成8位序列，然后转换为等效的十进制值。这个十进制向量被重塑，生成了一个代表恶意软件样本的灰度图像”，如[图1-17](#malware_proc)所示。
- en: '![Malware classification process](Images/dlcf_0117.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![恶意软件分类过程](Images/dlcf_0117.png)'
- en: Figure 1-17\. Malware classification process
  id: totrans-325
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-17。恶意软件分类过程
- en: The authors then show “pictures” generated through this process of malware in
    different categories, as shown in [Figure 1-18](#malware_eg).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们随后展示了通过恶意软件分类生成的“图片”，如[图1-18](#malware_eg)所示。
- en: '![Malware examples](Images/dlcf_0118.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![恶意软件示例](Images/dlcf_0118.png)'
- en: Figure 1-18\. Malware examples
  id: totrans-328
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-18。恶意软件示例
- en: 'As you can see, the different types of malware look very distinctive to the
    human eye. The model the researchers trained based on this image representation
    was more accurate at malware classification than any previous approach shown in
    the academic literature. This suggests a good rule of thumb for converting a dataset
    into an image representation: if the human eye can recognize categories from the
    images, then a deep learning model should be able to do so too.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，不同类型的恶意软件在人眼中看起来非常独特。研究人员基于这种图像表示训练的模型在恶意软件分类方面比学术文献中显示的任何先前方法都更准确。这表明将数据集转换为图像表示的一个很好的经验法则：如果人眼可以从图像中识别类别，那么深度学习模型也应该能够做到。
- en: In general, you’ll find that a small number of general approaches in deep learning
    can go a long way, if you’re a bit creative in how you represent your data! You
    shouldn’t think of approaches like the ones described here as “hacky workarounds,”
    because they often (as here) beat previously state-of-the-art results. These really
    are the right ways to think about these problem domains.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，您会发现在深度学习中，少数几种通用方法可以走得很远，只要您在如何表示数据方面有点创造性！您不应该将这里描述的方法视为“巧妙的变通方法”，因为它们通常（如此处）击败了以前的最先进结果。这确实是正确思考这些问题领域的方法。
- en: Jargon Recap
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 术语回顾
- en: We just covered a lot of information, so let’s recap briefly. [Table 1-3](#dljargon)
    provides a handy vocabulary list.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚涵盖了很多信息，让我们简要回顾一下。[表1-3](#dljargon) 提供了一个方便的词汇表。
- en: Table 1-3\. Deep learning vocabulary
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-3\. 深度学习词汇表
- en: '| Term | Meaning |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| 术语 | 意义 |'
- en: '| --- | --- |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Label | The data that we’re trying to predict, such as “dog” or “cat” |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| 标签 | 我们试图预测的数据，比如“狗”或“猫” |'
- en: '| Architecture | The *template* of the model that we’re trying to fit; i.e.,
    the actual mathematical function that we’re passing the input data and parameters
    to |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| 架构 | 我们试图拟合的模型的 * 模板 *；即我们将输入数据和参数传递给的实际数学函数 |'
- en: '| Model | The combination of the architecture with a particular set of parameters
    |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 架构与特定一组参数的组合 |'
- en: '| Parameters | The values in the model that change what task it can do and
    that are updated through model training |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 模型中改变任务的值，通过模型训练进行更新 |'
- en: '| Fit | Update the parameters of the model such that the predictions of the
    model using the input data match the target labels |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| 拟合 | 更新模型的参数，使得使用输入数据的模型预测与目标标签匹配 |'
- en: '| Train | A synonym for *fit* |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 训练 | * 拟合 * 的同义词 |'
- en: '| Pretrained model | A model that has already been trained, generally using
    a large dataset, and will be fine-tuned |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 预训练模型 | 已经训练过的模型，通常使用大型数据集，并将进行微调 |'
- en: '| Fine-tune | Update a pretrained model for a different task |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| 微调 | 为不同任务更新预训练模型 |'
- en: '| Epoch | One complete pass through the input data |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 纪元 | 一次完整通过输入数据 |'
- en: '| Loss | A measure of how good the model is, chosen to drive training via SGD
    |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| 损失 | 衡量模型好坏的指标，选择以驱动通过 SGD 进行训练 |'
- en: '| Metric | A measurement of how good the model is using the validation set,
    chosen for human consumption |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 指标 | 使用验证集衡量模型好坏的测量标准，选择供人类消费 |'
- en: '| Validation set | A set of data held out from training, used only for measuring
    how good the model is |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| 验证集 | 从训练中保留的一组数据，仅用于衡量模型好坏 |'
- en: '| Training set | The data used for fitting the model; does not include any
    data from the validation set |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 训练集 | 用于拟合模型的数据；不包括验证集中的任何数据 |'
- en: '| Overfitting | Training a model in such a way that it *remembers* specific
    features of the input data, rather than generalizing well to data not seen during
    training |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| 过拟合 | 以使模型 * 记住 * 输入数据的特定特征而不是很好地泛化到训练期间未见的数据的方式训练模型 |'
- en: '| CNN | Convolutional neural network; a type of neural network that works particularly
    well for computer vision tasks |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 卷积神经网络；一种特别适用于计算机视觉任务的神经网络 |'
- en: With this vocabulary in hand, we are now in a position to bring together all
    the key concepts introduced so far. Take a moment to review those definitions
    and read the following summary. If you can follow the explanation, you’re well
    equipped to understand the discussions to come.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个词汇表，我们现在可以将迄今介绍的所有关键概念汇集在一起。花点时间回顾这些定义，并阅读以下摘要。如果您能理解解释，那么您就有能力理解接下来的讨论。
- en: '*Machine learning* is a discipline in which we define a program not by writing
    it entirely ourselves, but by learning from data. *Deep learning* is a specialty
    within machine learning that uses *neural networks* with multiple *layers*. *Image
    classification* is a representative example (also known as *image recognition*).
    We start with *labeled data*—a set of images for which we have assigned a *label*
    to each image, indicating what it represents. Our goal is to produce a program,
    called a *model*, that, given a new image, will make an accurate *prediction*
    regarding what that new image represents.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '* 机器学习 *是一种学科，我们通过从数据中学习来定义程序，而不是完全自己编写它。 * 深度学习 *是机器学习中使用具有多个 * 层 * 的 * 神经网络
    * 的专业领域。 * 图像分类 * 是一个代表性的例子（也称为 * 图像识别 *）。我们从 * 标记数据 * 开始 - 一组我们为每个图像分配了 * 标签
    * 的图像，指示它代表什么。我们的目标是生成一个称为 * 模型 * 的程序，给定一个新图像，将对该新图像代表的内容进行准确的 * 预测 *。'
- en: Every model starts with a choice of *architecture*, a general template for how
    that kind of model works internally. The process of *training* (or *fitting*)
    the model is the process of finding a set of *parameter values* (or *weights*)
    that specialize that general architecture into a model that works well for our
    particular kind of data. To define how well a model does on a single prediction,
    we need to define a *loss function*, which determines how we score a prediction
    as good or bad.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型都从选择 * 架构 * 开始，这是该类型模型内部工作方式的一般模板。 * 训练 *（或 * 拟合 *）模型的过程是找到一组 * 参数值 *（或
    * 权重 *），这些参数值将该一般架构专门化为适用于我们特定数据类型的模型。为了定义模型在单个预测上的表现如何，我们需要定义一个 * 损失函数 *，它确定我们如何将预测评分为好或坏。
- en: To make the training process go faster, we might start with a *pretrained model*—a
    model that has already been trained on someone else’s data. We can then adapt
    it to our data by training it a bit more on our data, a process called *fine-tuning*.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让训练过程更快，我们可以从一个*预训练模型*开始——一个已经在其他人的数据上训练过的模型。然后我们可以通过在我们的数据上进一步训练它来使其适应我们的数据，这个过程称为*微调*。
- en: 'When we train a model, a key concern is to ensure that our model *generalizes*:
    it learns general lessons from our data that also apply to new items it will encounter,
    so it can make good predictions on those items. The risk is that if we train our
    model badly, instead of learning general lessons, it effectively memorizes what
    it has already seen, and then it will make poor predictions about new images.
    Such a failure is called *overfitting*.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们训练一个模型时，一个关键问题是确保我们的模型*泛化*：它从我们的数据中学到的一般性教训也适用于它将遇到的新项目，这样它就可以对这些项目做出良好的预测。风险在于，如果我们训练模型不当，它实际上会记住它已经看到的内容，而不是学习一般性教训，然后它将对新图像做出糟糕的预测。这样的失败被称为*过拟合*。
- en: To avoid this, we always divide our data into two parts, the *training set*
    and the *validation set*. We train the model by showing it only the training set,
    and then we evaluate how well the model is doing by seeing how well it performs
    on items from the validation set. In this way, we check if the lessons the model
    learns from the training set are lessons that generalize to the validation set.
    In order for a person to assess how well the model is doing on the validation
    set overall, we define a *metric*. During the training process, when the model
    has seen every item in the training set, we call that an *epoch*.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，我们总是将数据分为两部分，*训练集*和*验证集*。我们通过只向模型展示训练集来训练模型，然后通过查看模型在验证集中的表现来评估模型的表现如何。通过这种方式，我们检查模型从训练集中学到的教训是否适用于验证集。为了评估模型在验证集上的整体表现，我们定义一个*度量*。在训练过程中，当模型看到训练集中的每个项目时，我们称之为一个*周期*。
- en: 'All these concepts apply to machine learning in general. They apply to all
    sorts of schemes for defining a model by training it with data. What makes deep
    learning distinctive is a particular class of architectures: the architectures
    based on *neural networks*. In particular, tasks like image classification rely
    heavily on *convolutional neural networks*, which we will discuss shortly.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些概念都适用于机器学习。它们适用于各种通过训练数据定义模型的方案。深度学习的独特之处在于一类特定的架构：基于*神经网络*的架构。特别是，像图像分类这样的任务在*卷积神经网络*上严重依赖，我们将很快讨论。
- en: Deep Learning Is Not Just for Image Classification
  id: totrans-358
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习不仅仅适用于图像分类
- en: Deep learning’s effectiveness for classifying images has been widely discussed
    in recent years, even showing *superhuman* results on complex tasks like recognizing
    malignant tumors in CT scans. But it can do a lot more than this, as we will show
    here.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习在分类图像方面的有效性已经被广泛讨论，甚至在识别CT扫描中的恶性肿瘤等复杂任务上显示出*超人类*的结果。但它可以做的远不止这些，正如我们将在这里展示的。
- en: 'For instance, let’s talk about something that is critically important for autonomous
    vehicles: localizing objects in a picture. If a self-driving car doesn’t know
    where a pedestrian is, then it doesn’t know how to avoid one! Creating a model
    that can recognize the content of every individual pixel in an image is called
    *segmentation*. Here is how we can train a segmentation model with fastai, using
    a subset of the [*CamVid* dataset](https://oreil.ly/rDy1i) from the paper [“Semantic
    Object Classes in Video: A High-Definition Ground Truth Database”](https://oreil.ly/Mqclf)
    by Gabriel J. Brostow et al.:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们谈谈对于自动驾驶汽车至关重要的一点：在图片中定位物体。如果自动驾驶汽车不知道行人在哪里，那么它就不知道如何避开！创建一个能够识别图像中每个单独像素内容的模型被称为*分割*。以下是我们如何使用fastai训练一个分割模型，使用来自Gabriel
    J. Brostow等人的论文[“视频中的语义对象类：高清实况数据库”](https://oreil.ly/Mqclf)中的[*CamVid*数据集](https://oreil.ly/rDy1i)的子集：
- en: '[PRE10]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '| epoch | train_loss | valid_loss | time |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | time |'
- en: '| --- | --- | --- | --- |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 2.906601 | 2.347491 | 00:02 |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 2.906601 | 2.347491 | 00:02 |'
- en: '| epoch | train_loss | valid_loss | time |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | time |'
- en: '| --- | --- | --- | --- |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 1.988776 | 1.765969 | 00:02 |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1.988776 | 1.765969 | 00:02 |'
- en: '| 1 | 1.703356 | 1.265247 | 00:02 |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1.703356 | 1.265247 | 00:02 |'
- en: '| 2 | 1.591550 | 1.309860 | 00:02 |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1.591550 | 1.309860 | 00:02 |'
- en: '| 3 | 1.459745 | 1.102660 | 00:02 |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1.459745 | 1.102660 | 00:02 |'
- en: '| 4 | 1.324229 | 0.948472 | 00:02 |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1.324229 | 0.948472 | 00:02 |'
- en: '| 5 | 1.205859 | 0.894631 | 00:02 |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 1.205859 | 0.894631 | 00:02 |'
- en: '| 6 | 1.102528 | 0.809563 | 00:02 |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 1.102528 | 0.809563 | 00:02 |'
- en: '| 7 | 1.020853 | 0.805135 | 00:02 |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 1.020853 | 0.805135 | 00:02 |'
- en: We are not even going to walk through this code line by line, because it is
    nearly identical to our previous example! (We will be doing a deep dive into segmentation
    models in [Chapter 15](ch15.xhtml#chapter_arch_details), along with all of the
    other models that we are briefly introducing in this chapter and many, many more.)
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至不会逐行走过这段代码，因为它几乎与我们之前的示例完全相同！（我们将在[第15章](ch15.xhtml#chapter_arch_details)深入探讨分割模型，以及本章中我们简要介绍的所有其他模型以及更多更多。）
- en: 'We can visualize how well it achieved its task by asking the model to color-code
    each pixel of an image. As you can see, it nearly perfectly classifies every pixel
    in every object. For instance, notice that all of the cars are overlaid with the
    same color, and all of the trees are overlaid with the same color (in each pair
    of images, the lefthand image is the ground truth label, and the right is the
    prediction from the model):'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过要求模型为图像的每个像素着色来可视化它的任务完成情况。正如您所看到的，它几乎完美地对每个对象中的每个像素进行分类。例如，请注意所有的汽车都被叠加着相同的颜色，所有的树都被叠加着相同的颜色（在每对图像中，左侧图像是地面实况标签，右侧是模型的预测）：
- en: '[PRE11]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](Images/dlcf_01in03.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_01in03.png)'
- en: 'One other area where deep learning has dramatically improved in the last couple
    of years is natural language processing (NLP). Computers can now generate text,
    translate automatically from one language to another, analyze comments, label
    words in sentences, and much more. Here is all of the code necessary to train
    a model that can classify the sentiment of a movie review better than anything
    that existed in the world just five years ago:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个深度学习在过去几年显著改进的领域是自然语言处理（NLP）。计算机现在可以生成文本，自动从一种语言翻译到另一种语言，分析评论，标记句子中的单词等等。以下是训练一个模型所需的所有代码，该模型可以比五年前世界上任何东西更好地分类电影评论的情感：
- en: '[PRE12]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '| epoch | train_loss | valid_loss | accuracy | time |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | accuracy | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.594912 | 0.407416 | 0.823640 | 01:35 |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.594912 | 0.407416 | 0.823640 | 01:35 |'
- en: '| epoch | train_loss | valid_loss | accuracy | time |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | accuracy | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.268259 | 0.316242 | 0.876000 | 03:03 |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.268259 | 0.316242 | 0.876000 | 03:03 |'
- en: '| 1 | 0.184861 | 0.246242 | 0.898080 | 03:10 |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.184861 | 0.246242 | 0.898080 | 03:10 |'
- en: '| 2 | 0.136392 | 0.220086 | 0.918200 | 03:16 |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.136392 | 0.220086 | 0.918200 | 03:16 |'
- en: '| 3 | 0.106423 | 0.191092 | 0.931360 | 03:15 |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.106423 | 0.191092 | 0.931360 | 03:15 |'
- en: 'This model is using the [IMDb Large Movie Review dataset](https://oreil.ly/tl-wp)
    from [“Learning Word Vectors for Sentiment Analysis”](https://oreil.ly/L9vre)
    by Andrew Maas et al. It works well with movie reviews of many thousands of words,
    but let’s test it on a short one to see how it works:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型使用了Andrew Maas等人的论文[“Learning Word Vectors for Sentiment Analysis”](https://oreil.ly/L9vre)中的[IMDb
    Large Movie Review dataset](https://oreil.ly/tl-wp)。它在许多千字长的电影评论中表现良好，但让我们在一个短评论上测试一下看看它的表现如何：
- en: '[PRE13]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here we can see the model has considered the review to be positive. The second
    part of the result is the index of “pos” in our data vocabulary, and the last
    part is the probabilities attributed to each class (99.6% for “pos” and 0.4% for
    “neg”).
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们可以看到模型认为评论是积极的。结果的第二部分是我们数据词汇中“pos”的索引，最后一部分是分配给每个类的概率（“pos”为99.6%，“neg”为0.4%）。
- en: Now it’s your turn! Write your own mini movie review, or copy one from the internet,
    and you can see what this model thinks about it.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 现在轮到你了！写下你自己的迷你电影评论，或者从互联网上复制一个，看看这个模型对它的看法。
- en: 'If you ever have any questions about a fastai method, you should use the function
    `doc`, passing it the method name:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对fastai的任何方法有任何疑问，您应该使用`doc`函数，将方法名称传递给它：
- en: '[PRE15]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](Images/dlcf_01in04.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_01in04.png)'
- en: A window pops up containing a brief one-line explanation. The “Show in docs”
    link takes you to the full [documentation](https://docs.fast.ai), where you’ll
    find all the details and lots of examples. Also, most of fastai’s methods are
    just a handful of lines, so you can click the “source” link to see exactly what’s
    going on behind the scenes.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 一个窗口弹出，包含一个简短的一行解释。 “在文档中显示”链接将带您到完整的[文档](https://docs.fast.ai)，在那里您将找到所有细节和许多示例。此外，fastai的大多数方法只是几行代码，因此您可以单击“源”链接查看幕后发生的情况。
- en: 'Let’s move on to something much less sexy, but perhaps significantly more widely
    commercially useful: building models from plain *tabular* data.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论一些不那么性感，但可能在商业上更有用的事情：从普通*表格*数据构建模型。
- en: 'Jargon: Tabular'
  id: totrans-400
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语：表格
- en: Data that is in the form of a table, such as from a spreadsheet, database, or
    a comma-separated values (CSV) file. A tabular model is a model that tries to
    predict one column of a table based on information in other columns of the table.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 表格形式的数据，例如来自电子表格、数据库或逗号分隔值（CSV）文件。表格模型是一种试图根据表格中其他列的信息来预测表格中一列的模型。
- en: 'It turns out that looks very similar too. Here is the code necessary to train
    a model that will predict whether a person is a high-income earner, based on their
    socioeconomic background:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，这看起来非常相似。以下是训练一个模型所需的代码，该模型将根据个人的社会经济背景预测一个人是否是高收入者：
- en: '[PRE16]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you see, we had to tell fastai which columns are *categorical* (contain values
    that are one of a discrete set of choices, such as `occupation`) versus *continuous*
    (contain a number that represents a quantity, such as `age`).
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们不得不告诉fastai哪些列是*分类*（包含一组离散选择之一的值，例如`occupation`）与*连续*（包含表示数量的数字，例如`age`）。
- en: 'There is no pretrained model available for this task (in general, pretrained
    models are not widely available for any tabular modeling tasks, although some
    organizations have created them for internal use), so we don’t use `fine_tune`
    in this case. Instead, we use `fit_one_cycle`, the most commonly used method for
    training fastai models *from scratch* (i.e., without transfer learning):'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 这个任务没有预训练模型可用（一般来说，预训练模型在任何表格建模任务中都不广泛可用，尽管一些组织已经为内部使用创建了这些模型），所以在这种情况下我们不使用`fine_tune`。相反，我们使用`fit_one_cycle`，这是训练fastai模型*从头开始*（即没有迁移学习）最常用的方法：
- en: '[PRE17]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '| epoch | train_loss | valid_loss | accuracy | time |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | accuracy | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.359960 | 0.357917 | 0.831388 | 00:11 |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.359960 | 0.357917 | 0.831388 | 00:11 |'
- en: '| 1 | 0.353458 | 0.349657 | 0.837991 | 00:10 |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.353458 | 0.349657 | 0.837991 | 00:10 |'
- en: '| 2 | 0.338368 | 0.346997 | 0.843213 | 00:10 |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.338368 | 0.346997 | 0.843213 | 00:10 |'
- en: 'This model is using the [*Adult*](https://oreil.ly/Gc0AR) dataset from the
    paper [“Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid”](https://oreil.ly/qFOSc)
    by Ron Kohavi, which contains some demographic data about individuals (like their
    education, marital status, race, sex and whether they have an annual income greater
    than $50k). The model is over 80% accurate and took around 30 seconds to train.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '这个模型使用了Ron Kohavi的论文[“Scaling Up the Accuracy of Naive-Bayes Classifiers: a
    Decision-Tree Hybrid”](https://oreil.ly/qFOSc)中的[*Adult*](https://oreil.ly/Gc0AR)数据集，其中包含一些关于个人的人口统计数据（如他们的教育、婚姻状况、种族、性别以及是否年收入超过5万美元）。该模型的准确率超过80%，训练时间约为30秒。'
- en: 'Let’s look at one more. Recommendation systems are important, particularly
    in ecommerce. Companies like Amazon and Netflix try hard to recommend products
    or movies that users might like. Here’s how to train a model that will predict
    movies people might like based on their previous viewing habits, using the [MovieLens
    dataset](https://oreil.ly/LCfwH):'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一个例子。推荐系统很重要，特别是在电子商务中。像亚马逊和Netflix这样的公司努力推荐用户可能喜欢的产品或电影。以下是如何训练一个模型，根据用户以前的观影习惯，预测用户可能喜欢的电影，使用[MovieLens数据集](https://oreil.ly/LCfwH)：
- en: '[PRE18]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '| epoch | train_loss | valid_loss | time |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | time |'
- en: '| --- | --- | --- | --- |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 1.554056 | 1.428071 | 00:01 |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1.554056 | 1.428071 | 00:01 |'
- en: '| epoch | train_loss | valid_loss | time |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | time |'
- en: '| --- | --- | --- | --- |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 1.393103 | 1.361342 | 00:01 |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1.393103 | 1.361342 | 00:01 |'
- en: '| 1 | 1.297930 | 1.159169 | 00:00 |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1.297930 | 1.159169 | 00:00 |'
- en: '| 2 | 1.052705 | 0.827934 | 00:01 |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 1.052705 | 0.827934 | 00:01 |'
- en: '| 3 | 0.810124 | 0.668735 | 00:01 |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.810124 | 0.668735 | 00:01 |'
- en: '| 4 | 0.711552 | 0.627836 | 00:01 |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.711552 | 0.627836 | 00:01 |'
- en: '| 5 | 0.657402 | 0.611715 | 00:01 |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 0.657402 | 0.611715 | 00:01 |'
- en: '| 6 | 0.633079 | 0.605733 | 00:01 |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 0.633079 | 0.605733 | 00:01 |'
- en: '| 7 | 0.622399 | 0.602674 | 00:01 |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 0.622399 | 0.602674 | 00:01 |'
- en: '| 8 | 0.629075 | 0.601671 | 00:00 |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 0.629075 | 0.601671 | 00:00 |'
- en: '| 9 | 0.619955 | 0.601550 | 00:01 |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 0.619955 | 0.601550 | 00:01 |'
- en: This model is predicting movie ratings on a scale of 0.5 to 5.0 to within around
    0.6 average error. Since we’re predicting a continuous number, rather than a category,
    we have to tell fastai what range our target has, using the `y_range` parameter.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型在0.5到5.0的范围内预测电影评分，平均误差约为0.6。由于我们预测的是一个连续数值，而不是一个类别，我们必须告诉fastai我们的目标范围是多少，使用`y_range`参数。
- en: Although we’re not actually using a pretrained model (for the same reason that
    we didn’t for the tabular model), this example shows that fastai lets us use `fine_tune`
    anyway in this case (you’ll learn how and why this works in [Chapter 5](ch05.xhtml#chapter_pet_breeds)).
    Sometimes it’s best to experiment with `fine_tune` versus `fit_one_cycle` to see
    which works best for your dataset.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们实际上并没有使用预训练模型（和表格模型一样的原因），但这个例子显示了fastai在这种情况下仍然让我们使用`fine_tune`（您将在[第5章](ch05.xhtml#chapter_pet_breeds)中学习到这是如何以及为什么有效）。有时最好尝试`fine_tune`和`fit_one_cycle`，看看哪个对您的数据集效果更好。
- en: 'We can use the same `show_results` call we saw earlier to view a few examples
    of user and movie IDs, actual ratings, and predictions:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用之前看到的相同的`show_results`调用来查看一些用户和电影ID、实际评分和预测：
- en: '[PRE19]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '|  | userId | movieId | rating | rating_pred |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '|  | userId | movieId | rating | rating_pred |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 157 | 1200 | 4.0 | 3.558502 |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 157 | 1200 | 4.0 | 3.558502 |'
- en: '| 1 | 23 | 344 | 2.0 | 2.700709 |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 23 | 344 | 2.0 | 2.700709 |'
- en: '| 2 | 19 | 1221 | 5.0 | 4.390801 |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 19 | 1221 | 5.0 | 4.390801 |'
- en: '| 3 | 430 | 592 | 3.5 | 3.944848 |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 430 | 592 | 3.5 | 3.944848 |'
- en: '| 4 | 547 | 858 | 4.0 | 4.076881 |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 547 | 858 | 4.0 | 4.076881 |'
- en: '| 5 | 292 | 39 | 4.5 | 3.753513 |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 292 | 39 | 4.5 | 3.753513 |'
- en: '| 6 | 529 | 1265 | 4.0 | 3.349463 |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 529 | 1265 | 4.0 | 3.349463 |'
- en: '| 7 | 19 | 231 | 3.0 | 2.881087 |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 19 | 231 | 3.0 | 2.881087 |'
- en: '| 8 | 475 | 4963 | 4.0 | 4.023387 |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 475 | 4963 | 4.0 | 4.023387 |'
- en: '| 9 | 130 | 260 | 4.5 | 3.979703 |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 130 | 260 | 4.5 | 3.979703 |'
- en: Each of the models we trained showed a training and validation loss. A good
    validation set is one of the most important pieces of the training process. Let’s
    see why and learn how to create one.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 我们训练的每个模型都显示了训练和验证损失。一个好的验证集是训练过程中最重要的部分之一。让我们看看为什么，并学习如何创建一个。
- en: Validation Sets and Test Sets
  id: totrans-447
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证集和测试集
- en: As we’ve discussed, the goal of a model is to make predictions about data. But
    the model training process is fundamentally dumb. If we trained a model with all
    our data and then evaluated the model using that same data, we would not be able
    to tell how well our model can perform on data it hasn’t seen. Without this very
    valuable piece of information to guide us in training our model, there is a very
    good chance it would become good at making predictions about that data but would
    perform poorly on new data.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所讨论的，模型的目标是对数据进行预测。但模型训练过程基本上是愚蠢的。如果我们用所有的数据训练一个模型，然后使用同样的数据评估模型，我们将无法判断我们的模型在未见过的数据上表现如何。没有这个非常宝贵的信息来指导我们训练模型，很有可能模型会擅长对这些数据进行预测，但在新数据上表现不佳。
- en: 'To avoid this, our first step was to split our dataset into two sets: the *training
    set* (which our model sees in training) and the *validation set*, also known as
    the *development set* (which is used only for evaluation). This lets us test that
    the model learns lessons from the training data that generalize to new data, the
    validation data.'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，我们的第一步是将数据集分成两组：*训练集*（模型在训练中看到的）和*验证集*，也称为*开发集*（仅用于评估）。这样我们可以测试模型是否从训练数据中学到的经验可以推广到新数据，即验证数据。
- en: One way to understand this situation is that, in a sense, we don’t want our
    model to get good results by “cheating.” If it makes an accurate prediction for
    a data item, that should be because it has learned characteristics of that kind
    of item, and not because the model has been shaped by *actually having seen that
    particular item*.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这种情况的一种方式是，在某种意义上，我们不希望我们的模型通过“作弊”来获得好的结果。如果它对一个数据项做出准确的预测，那应该是因为它已经学到了那种类型的特征，而不是因为模型已经被*实际看到那个特定项*所塑造。
- en: Splitting off our validation data means our model never sees it in training
    and so is completely untainted by it, and is not cheating in any way. Right?
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 将验证数据集分离出来意味着我们的模型在训练中从未见过它，因此完全没有被它污染，并且没有以任何方式作弊。对吧？
- en: In fact, not necessarily. The situation is more subtle. This is because in realistic
    scenarios we rarely build a model just by training its parameters once. Instead,
    we are likely to explore many versions of a model through various modeling choices
    regarding network architecture, learning rates, data augmentation strategies,
    and other factors we will discuss in upcoming chapters. Many of these choices
    can be described as choices of *hyperparameters*. The word reflects that they
    are parameters about parameters, since they are the higher-level choices that
    govern the meaning of the weight parameters.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，并非一定如此。情况更为微妙。这是因为在现实场景中，我们很少仅通过一次训练参数来构建模型。相反，我们可能通过各种建模选择来探索模型的许多版本，包括网络架构、学习率、数据增强策略等因素，我们将在接下来的章节中讨论。其中许多选择可以描述为*超参数*的选择。这个词反映了它们是关于参数的参数，因为它们是控制权重参数含义的高级选择。
- en: The problem is that even though the ordinary training process is looking at
    only predictions on the training data when it learns values for the weight parameters,
    the same is not true of us. We, as modelers, are evaluating the model by looking
    at predictions on the validation data when we decide to explore new hyperparameter
    values! So subsequent versions of the model are, indirectly, shaped by us having
    seen the validation data. Just as the automatic training process is in danger
    of overfitting the training data, we are in danger of overfitting the validation
    data through human trial and error and exploration.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，即使普通的训练过程只看训练数据的预测结果来学习权重参数的值，我们却不是这样。作为建模者，当我们决定探索新的超参数值时，我们通过查看验证数据的预测结果来评估模型！因此，模型的后续版本间接地受到我们看到验证数据的影响。就像自动训练过程有过拟合训练数据的危险一样，我们通过人为试错和探索有过拟合验证数据的危险。
- en: 'The solution to this conundrum is to introduce another level of even more highly
    reserved data: the *test set*. Just as we hold back the validation data from the
    training process, we must hold back the test set data even from ourselves. It
    cannot be used to improve the model; it can be used only to evaluate the model
    at the very end of our efforts. In effect, we define a hierarchy of cuts of our
    data, based on how fully we want to hide it from training and modeling processes:
    training data is fully exposed, the validation data is less exposed, and test
    data is totally hidden. This hierarchy parallels the different kinds of modeling
    and evaluation processes themselves—the automatic training process with backpropagation,
    the more manual process of trying different hyperparameters between training sessions,
    and the assessment of our final result.'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个难题的方法是引入另一个更高度保留数据的层级：*测试集*。就像我们在训练过程中保留验证数据一样，我们必须连自己都不使用测试集数据。它不能用来改进模型；它只能在我们努力的最后阶段用来评估模型。实际上，我们定义了一个基于我们希望如何完全隐藏数据的层次结构：训练数据完全暴露，验证数据较少暴露，测试数据完全隐藏。这种层次结构与不同种类的建模和评估过程本身相对应——自动训练过程与反向传播，尝试不同超参数之间的更手动过程，以及我们最终结果的评估。
- en: The test and validation sets should have enough data to ensure that you get
    a good estimate of your accuracy. If you’re creating a cat detector, for instance,
    you generally want at least 30 cats in your validation set. That means that if
    you have a dataset with thousands of items, using the default 20% validation set
    size may be more than you need. On the other hand, if you have lots of data, using
    some of it for validation probably doesn’t have any downsides.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 测试集和验证集应该有足够的数据来确保您对准确性有一个良好的估计。例如，如果您正在创建一个猫检测器，通常您希望验证集中至少有30只猫。这意味着如果您有数千个项目的数据集，使用默认的20%验证集大小可能超出您的需求。另一方面，如果您有大量数据，将其中一部分用于验证可能没有任何不利之处。
- en: Having two levels of “reserved data”—a validation set and a test set, with one
    level representing data that you are virtually hiding from yourself—may seem a
    bit extreme. But it is often necessary because models tend to gravitate toward
    the simplest way to do good predictions (memorization), and we as fallible humans
    tend to gravitate toward fooling ourselves about how well our models are performing.
    The discipline of the test set helps us keep ourselves intellectually honest.
    That doesn’t mean we *always* need a separate test set—if you have very little
    data, you may need just a validation set—but generally it’s best to use one if
    at all possible.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有两个级别的“保留数据”——验证集和测试集，其中一个级别代表您几乎隐藏自己的数据——可能看起来有点极端。但通常是必要的，因为模型往往倾向于朝着做出良好预测的最简单方式（记忆）发展，而我们作为易犯错误的人类往往倾向于欺骗自己关于我们的模型表现如何。测试集的纪律帮助我们保持思想上的诚实。这并不意味着我们*总是*需要一个单独的测试集——如果您的数据很少，您可能只需要一个验证集——但通常最好尽可能使用一个。
- en: This same discipline can be critical if you intend to hire a third party to
    perform modeling work on your behalf. A third party might not understand your
    requirements accurately, or their incentives might even encourage them to misunderstand
    them. A good test set can greatly mitigate these risks and let you evaluate whether
    their work solves your actual problem.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您打算雇用第三方代表您进行建模工作，这种纪律也可能至关重要。第三方可能无法准确理解您的要求，或者他们的激励甚至可能鼓励他们误解。一个好的测试集可以极大地减轻这些风险，并让您评估他们的工作是否解决了您实际的问题。
- en: 'To put it bluntly, if you’re a senior decision maker in your organization (or
    you’re advising senior decision makers), the most important takeaway is this:
    if you ensure that you really understand what test and validation sets are and
    why they’re important, you’ll avoid the single biggest source of failures we’ve
    seen when organizations decide to use AI. For instance, if you’re considering
    bringing in an external vendor or service, make sure that you hold out some test
    data that the vendor *never gets to see*. Then *you* check their model on your
    test data, using a metric that *you* choose based on what actually matters to
    you in practice, and *you* decide what level of performance is adequate. (It’s
    also a good idea for you to try out simple baseline yourself, so you know what
    a really simple model can achieve. Often it’ll turn out that your simple model
    performs just as well as one produced by an external “expert”!)'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 直截了当地说，如果你是组织中的高级决策者（或者你正在为高级决策者提供建议），最重要的要点是：如果你确保真正理解测试和验证集以及它们的重要性，你将避免我们看到的组织决定使用AI时最大的失败源。例如，如果你考虑引入外部供应商或服务，请确保保留一些测试数据，供供应商*永远看不到*。然后*你*在你的测试数据上检查他们的模型，使用*你*根据实际情况选择的度量标准，并*你*决定什么水平的性能是足够的。（你自己尝试一个简单的基线也是个好主意，这样你就知道一个真正简单的模型能够实现什么。通常情况下，你的简单模型的表现会和外部“专家”制作的模型一样好！）
- en: Use Judgment in Defining Test Sets
  id: totrans-459
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在定义测试集时要有判断力
- en: 'To do a good job of defining a validation set (and possibly a test set), you
    will sometimes want to do more than just randomly grab a fraction of your original
    dataset. Remember: a key property of the validation and test sets is that they
    must be representative of the new data you will see in the future. This may sound
    like an impossible order! By definition, you haven’t seen this data yet. But you
    usually still do know some things.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 要很好地定义验证集（以及可能的测试集），有时你需要做的不仅仅是随机抽取原始数据集的一部分。记住：验证和测试集的一个关键特性是它们必须代表你将来看到的新数据。这听起来可能像一个不可能的要求！根据定义，你还没有看到这些数据。但通常你仍然会知道一些事情。
- en: It’s instructive to look at a few example cases. Many of these examples come
    from predictive modeling competitions on the [*Kaggle* platform](https://www.kaggle.com),
    which is a good representation of problems and methods you might see in practice.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 看一些例子是很有启发性的。这些例子中的许多来自于[*Kaggle*平台](https://www.kaggle.com)上的预测建模竞赛，这是你可能在实践中看到的问题和方法的很好代表。
- en: One case might be if you are looking at time series data. For a time series,
    choosing a random subset of the data will be both too easy (you can look at the
    data both before and after the dates you are trying to predict) and not representative
    of most business use cases (where you are using historical data to build a model
    for use in the future). If your data includes the date and you are building a
    model to use in the future, you will want to choose a continuous section with
    the latest dates as your validation set (for instance, the last two weeks or last
    month of available data).
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 一个情况可能是当你在查看时间序列数据时。对于时间序列，选择数据的随机子集既太容易（你可以查看你试图预测的日期之前和之后的数据），又不代表大多数业务用例（在这些用例中，你使用历史数据构建模型以供将来使用）。如果你的数据包含日期，并且你正在构建一个将来使用的模型，你将希望选择最新日期的连续部分作为验证集（例如，可用数据的最后两周或最后一个月）。
- en: Suppose you want to split the time series data in [Figure 1-19](#timeseries1)
    into training and validation sets.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想将[图1-19](#timeseries1)中的时间序列数据分成训练集和验证集。
- en: '![A serie of values](Images/dlcf_0119.png)'
  id: totrans-464
  prefs: []
  type: TYPE_IMG
  zh: '![一系列数值](Images/dlcf_0119.png)'
- en: Figure 1-19\. A time series
  id: totrans-465
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-19. 一个时间序列
- en: A random subset is a poor choice (too easy to fill in the gaps, and not indicative
    of what you’ll need in production), as we can see in [Figure 1-20](#timeseries2).
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 一个随机子集是一个糟糕的选择（填补缺失太容易，且不代表你在生产中所需的），正如我们在[图1-20](#timeseries2)中所看到的。
- en: '![Random training subset](Images/dlcf_0120.png)'
  id: totrans-467
  prefs: []
  type: TYPE_IMG
  zh: '![随机训练子集](Images/dlcf_0120.png)'
- en: Figure 1-20\. A poor training subset
  id: totrans-468
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-20. 一个糟糕的训练子集
- en: Instead, use the earlier data as your training set (and the later data for the
    validation set), as shown in [Figure 1-21](#timeseries3).
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，使用早期数据作为训练集（以及后期数据作为验证集），如[图1-21](#timeseries3)所示。
- en: '![Training subset using the data up to a certain timestamp](Images/dlcf_0121.png)'
  id: totrans-470
  prefs: []
  type: TYPE_IMG
  zh: '![使用直到某个时间戳的数据作为训练子集](Images/dlcf_0121.png)'
- en: Figure 1-21\. A good training subset
  id: totrans-471
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-21. 一个好的训练子集
- en: For example, Kaggle had a competition to [predict the sales in a chain of Ecuadorian
    grocery stores](https://oreil.ly/UQoXe). Kaggle’s training data ran from Jan 1,
    2013 to Aug 15, 2017, and the test data spanned from Aug 16, 2017 to Aug 31, 2017\.
    That way, the competition organizer ensured that entrants were making predictions
    for a time period that was *in the future*, from the perspective of their model.
    This is similar to the way quantitative hedge fund traders do *backtesting* to
    check whether their models are predictive of future periods, based on past data.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Kaggle曾举办一场竞赛，要求[预测厄瓜多尔杂货店连锁店的销售额](https://oreil.ly/UQoXe)。 Kaggle的训练数据从2013年1月1日到2017年8月15日，测试数据跨越了2017年8月16日到2017年8月31日。这样，竞赛组织者确保参赛者在*未来*时间段进行预测，从他们模型的角度来看。这类似于量化对冲基金交易员进行*回测*，以检查他们的模型是否能够根据过去的数据预测未来的时间段。
- en: A second common case occurs when you can easily anticipate ways the data you
    will be making predictions for in production may be *qualitatively different*
    from the data you have to train your model with.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种常见情况是，当你可以很容易地预见到你将用来训练模型的数据与你将在生产中进行预测的数据可能在质量上有所不同时。
- en: In the Kaggle [distracted driver competition](https://oreil.ly/zT_tC), the independent
    variables are pictures of drivers at the wheel of a car, and the dependent variables
    are categories such as texting, eating, or safely looking ahead. Lots of pictures
    are of the same drivers in different positions, as we can see in [Figure 1-22](#img_driver).
    If you were an insurance company building a model from this data, note that you
    would be most interested in how the model performs on drivers it hasn’t seen before
    (since you would likely have training data for only a small group of people).
    In recognition of this, the test data for the competition consists of images of
    people that don’t appear in the training set.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kaggle [分心司机比赛](https://oreil.ly/zT_tC)中，自变量是司机在车轮上的照片，因变量是文本、吃东西或安全地向前看等类别。很多照片是同一司机在不同位置的照片，正如我们在[图1-22](#img_driver)中所看到的。如果你是一家保险公司根据这些数据构建模型，注意你最感兴趣的是模型在未见过的司机身上的表现（因为你可能只有一小部分人的训练数据）。为此，比赛的测试数据包括那些在训练集中没有出现的人的图像。
- en: '![Two pictures from the training data, showing the same driver](Images/dlcf_0122.png)'
  id: totrans-475
  prefs: []
  type: TYPE_IMG
  zh: '![来自训练数据的两张图片，展示同一个司机](Images/dlcf_0122.png)'
- en: Figure 1-22\. Two pictures from the training data
  id: totrans-476
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-22\. 训练数据中的两张图片
- en: If you put one of the images in [Figure 1-22](#img_driver) in your training
    set and one in the validation set, your model will have an easy time making a
    prediction for the one in the validation set, so it will seem to be performing
    better than it would on new people. Another perspective is that if you used all
    the people in training your model, your model might be overfitting to particularities
    of those specific people and not just learning the states (texting, eating, etc.).
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将[图1-22](#img_driver)中的一张图片放入训练集，另一张放入验证集，你的模型将更容易预测验证集中的那张图片，因此它看起来表现得比在新人身上更好。另一个角度是，如果你在训练模型时使用了所有人，你的模型可能会过度拟合这些特定人的特点，而不仅仅是学习状态（发短信、吃东西等）。
- en: A similar dynamic was at work in the [Kaggle fisheries competition](https://oreil.ly/iJwFf)
    to identify the species of fish caught by fishing boats in order to reduce illegal
    fishing of endangered populations. The test set consisted of images from boats
    that didn’t appear in the training data, so in this case you’d want your validation
    set to also include boats that are not in the training set.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Kaggle渔业比赛](https://oreil.ly/iJwFf)中，也存在类似的动态，目的是识别渔船捕捞的鱼类物种，以减少对濒临灭绝种群的非法捕捞。测试集包括来自训练数据中没有出现的船只的图像，因此在这种情况下，你希望你的验证集也包括训练集中没有的船只。
- en: Sometimes it may not be clear how your validation data will differ. For instance,
    for a problem using satellite imagery, you’d need to gather more information on
    whether the training set contained just certain geographic locations or came from
    geographically scattered data.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 有时可能不清楚你的验证数据会有什么不同。例如，对于使用卫星图像的问题，你需要收集更多信息，了解训练集是否只包含某些地理位置或来自地理分散的数据。
- en: Now that you have gotten a taste of how to build a model, you can decide what
    you want to dig into next.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经尝试了如何构建模型，你可以决定接下来想深入研究什么。
- en: A *Choose Your Own Adventure* Moment
  id: totrans-481
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个*选择你自己的冒险*时刻
- en: If you would like to learn more about how to use deep learning models in practice,
    including how to identify and fix errors, create a real working web application,
    and avoid your model causing unexpected harm to your organization or society more
    generally, then keep reading the next two chapters. If you would like to start
    learning the foundations of how deep learning works under the hood, skip to [Chapter 4](ch04.xhtml#chapter_mnist_basics).
    (Did you ever read *Choose Your Own Adventure* books as a kid? Well, this is kind
    of like that…except with more deep learning than that book series contained.)
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解如何在实践中使用深度学习模型，包括如何识别和修复错误、创建一个真正的工作网络应用程序，并避免你的模型对你的组织或社会造成意外伤害，那么请继续阅读接下来的两章。如果你想开始学习深度学习在幕后是如何工作的基础知识，请跳到[第四章](ch04.xhtml#chapter_mnist_basics)。（你小时候有读过*选择你自己的冒险*系列书吗？嗯，这有点像那个……只不过比那本书系列包含更多的深度学习。）
- en: You will need to read all these chapters to progress further in the book, but
    the order in which you read them is totally up to you. They don’t depend on each
    other. If you skip ahead to [Chapter 4](ch04.xhtml#chapter_mnist_basics), we will
    remind you at the end to come back and read the chapters you skipped over before
    you go any further.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要阅读所有这些章节才能在书中进一步前进，但你阅读它们的顺序完全取决于你。它们不相互依赖。如果你跳到[第四章](ch04.xhtml#chapter_mnist_basics)，我们会在最后提醒你回来阅读你跳过的章节，然后再继续前进。
- en: Questionnaire
  id: totrans-484
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问卷调查
- en: After reading pages and pages of prose, it can be hard to know which key things
    you really need to focus on and remember. So, we’ve prepared a list of questions
    and suggested steps to complete at the end of each chapter. All the answers are
    in the text of the chapter, so if you’re not sure about anything here, reread
    that part of the text and make sure you understand it. Answers to all these questions
    are also available on the [book’s website](https://book.fast.ai). You can also
    visit [the forums](https://forums.fast.ai) if you get stuck to get help from other
    folks studying this material.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读了一页又一页的散文之后，很难知道你真正需要专注和记住的关键事项。因此，我们准备了一份问题列表和建议的步骤清单，供你在每章末完成。所有答案都在章节的文本中，所以如果你对这里的任何事情不确定，重新阅读文本的那部分，并确保你理解了它。所有这些问题的答案也可以在[书的网站](https://book.fast.ai)上找到。如果你遇到困难，也可以访问[论坛](https://forums.fast.ai)寻求其他学习这些材料的人的帮助。
- en: Do you need these for deep learning?
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要这些来进行深度学习吗？
- en: Lots of math T/F
  id: totrans-487
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很多数学 T/F
- en: Lots of data T/F
  id: totrans-488
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很多数据 T/F
- en: Lots of expensive computers T/F
  id: totrans-489
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很多昂贵的电脑 T/F
- en: A PhD T/F
  id: totrans-490
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个博士学位 T/F
- en: Name five areas where deep learning is now the best tool in the world.
  id: totrans-491
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出深度学习现在是世界上最好的工具的五个领域。
- en: What was the name of the first device that was based on the principle of the
    artificial neuron?
  id: totrans-492
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个基于人工神经元原理的设备的名称是什么？
- en: Based on the book of the same name, what are the requirements for parallel distributed
    processing (PDP)?
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据同名书籍，分布式并行处理（PDP）的要求是什么？
- en: What were the two theoretical misunderstandings that held back the field of
    neural networks?
  id: totrans-494
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是什么两个理论误解阻碍了神经网络领域的发展？
- en: What is a GPU?
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是 GPU？
- en: 'Open a notebook and execute a cell containing: `1+1`. What happens?'
  id: totrans-496
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个笔记本并执行包含：`1+1` 的单元格。会发生什么？
- en: Follow through each cell of the stripped version of the notebook for this chapter.
    Before executing each cell, guess what will happen.
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟随本章笔记本的精简版本中的每个单元格。在执行每个单元格之前，猜测会发生什么。
- en: Complete the [Jupyter Notebook online appendix](https://oreil.ly/9uPZe).
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成[Jupyter Notebook在线附录](https://oreil.ly/9uPZe)。
- en: Why is it hard to use a traditional computer program to recognize images in
    a photo?
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么使用传统计算机程序来识别照片中的图像很困难？
- en: What did Samuel mean by “weight assignment”?
  id: totrans-500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 塞缪尔所说的“权重分配”是什么意思？
- en: What term do we normally use in deep learning for what Samuel called “weights”?
  id: totrans-501
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在深度学习中，我们通常用什么术语来表示塞缪尔所说的“权重”？
- en: Draw a picture that summarizes Samuel’s view of a machine learning model.
  id: totrans-502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 画一幅总结塞缪尔对机器学习模型看法的图片。
- en: Why is it hard to understand why a deep learning model makes a particular prediction?
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么很难理解深度学习模型为什么会做出特定的预测？
- en: What is the name of the theorem that shows that a neural network can solve any
    mathematical problem to any level of accuracy?
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 展示了一个定理的名称，该定理表明神经网络可以解决任何数学问题并达到任何精度水平是什么？
- en: What do you need in order to train a model?
  id: totrans-505
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了训练模型，您需要什么？
- en: How could a feedback loop impact the rollout of a predictive policing model?
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 反馈循环如何影响预测性警务模型的推出？
- en: Do we always have to use 224×224-pixel images with the cat recognition model?
  id: totrans-507
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在猫识别模型中总是需要使用 224×224 像素的图像吗？
- en: What is the difference between classification and regression?
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类和回归之间有什么区别？
- en: What is a validation set? What is a test set? Why do we need them?
  id: totrans-509
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是验证集？什么是测试集？为什么我们需要它们？
- en: What will fastai do if you don’t provide a validation set?
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果不提供验证集，fastai 会怎么做？
- en: Can we always use a random sample for a validation set? Why or why not?
  id: totrans-511
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们总是可以使用随机样本作为验证集吗？为什么或为什么不？
- en: What is overfitting? Provide an example.
  id: totrans-512
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是过拟合？举个例子。
- en: What is a metric? How does it differ from loss?
  id: totrans-513
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是度量？它与损失有什么不同？
- en: How can pretrained models help?
  id: totrans-514
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预训练模型如何帮助？
- en: What is the “head” of a model?
  id: totrans-515
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的“头”是什么？
- en: What kinds of features do the early layers of a CNN find? How about the later
    layers?
  id: totrans-516
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CNN 的早期层找到了什么样的特征？后期层呢？
- en: Are image models useful only for photos?
  id: totrans-517
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像模型仅对照片有用吗？
- en: What is an architecture?
  id: totrans-518
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是架构？
- en: What is segmentation?
  id: totrans-519
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是分割？
- en: What is `y_range` used for? When do we need it?
  id: totrans-520
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`y_range` 用于什么？什么时候需要它？'
- en: What are hyperparameters?
  id: totrans-521
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是超参数？
- en: What’s the best way to avoid failures when using AI in an organization?
  id: totrans-522
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在组织中使用 AI 时避免失败的最佳方法是什么？
- en: Further Research
  id: totrans-523
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步研究
- en: Each chapter also has a “Further Research” section that poses some questions
    that aren’t fully answered in the text, or gives more advanced assignments. Answers
    to these questions aren’t on the book’s website; you’ll need to do your own research!
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 每章还有一个“进一步研究”部分，提出了一些在文本中没有完全回答的问题，或者给出了更高级的任务。这些问题的答案不在书的网站上；您需要自己进行研究！
- en: Why is a GPU useful for deep learning? How is a CPU different, and why is it
    less effective for deep learning?
  id: totrans-525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么 GPU 对深度学习有用？CPU 有什么不同之处，为什么对深度学习效果不佳？
- en: Try to think of three areas where feedback loops might impact the use of machine
    learning. See if you can find documented examples of that happening in practice.
  id: totrans-526
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 试着想出三个反馈循环可能影响机器学习使用的领域。看看是否能找到实践中发生这种情况的文档示例。
