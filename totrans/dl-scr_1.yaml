- en: Chapter 1\. Foundations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。基础
- en: Don’t memorize these formulas. If you understand the concepts, you can invent
    your own notation.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不要死记这些公式。如果你理解了概念，你可以发明自己的符号。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: John Cochrane, [*Investments Notes*](https://oreil.ly/33CVXjg) 2006
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 约翰·科克兰，《投资笔记》2006
- en: The aim of this chapter is to explain some foundational mental models that are
    essential for understanding how neural networks work. Specifically, we’ll cover
    *nested mathematical functions and their derivatives*. We’ll work our way up from
    the simplest possible building blocks to show that we can build complicated functions
    made up of a “chain” of constituent functions and, even when one of these functions
    is a matrix multiplication that takes in multiple inputs, compute the derivative
    of the functions’ outputs with respect to their inputs. Understanding how this
    process works will be essential to understanding neural networks, which we technically
    won’t begin to cover until [Chapter 2](ch02.html#fundamentals).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是解释一些对理解神经网络工作至关重要的基础心智模型。具体来说，我们将涵盖*嵌套数学函数及其导数*。我们将从最简单的基本构建块开始，逐步展示我们可以构建由“链”组成的复杂函数，即使其中一个函数是接受多个输入的矩阵乘法，也可以计算函数输出相对于输入的导数。理解这个过程如何运作将是理解神经网络的关键，而我们实际上直到[第2章](ch02.html#fundamentals)才会开始涵盖神经网络。
- en: 'As we’re getting our bearings around these foundational building blocks of
    neural networks, we’ll systematically describe each concept we introduce from
    three perspectives:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们围绕神经网络的这些基础构建块来找到方向时，我们将系统地从三个视角描述我们引入的每个概念：
- en: Math, in the form of an equation or equations
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数学，以方程或方程组的形式
- en: Code, with as little extra syntax as possible (making Python an ideal choice)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码，尽可能少的额外语法（使Python成为理想选择）
- en: A diagram explaining what is going on, of the kind you would draw on a whiteboard
    during a coding interview
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个解释正在发生的事情的图表，就像你在编程面试中在白板上画的那种
- en: 'As mentioned in the preface, one of the challenges of understanding neural
    networks is that it requires multiple mental models. We’ll get a sense of that
    in this chapter: each of these three perspectives excludes certain essential features
    of the concepts we’ll cover, and only when taken together do they provide a full
    picture of both how and why nested mathematical functions work the way they do.
    In fact, I take the uniquely strong view that any attempt to explain the building
    blocks of neural networks that excludes one of these three perspectives is incomplete.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前言中提到的，理解神经网络的一个挑战是需要多种心智模型。在本章中，我们将感受到这一点：这三种视角中的每一种都排除了我们将要涵盖的概念的某些基本特征，只有当它们一起被考虑时，才能提供关于嵌套数学函数工作方式的完整图景。事实上，我坚定地认为，任何试图解释神经网络构建块的尝试，如果排除了这三种视角中的任何一种，都是不完整的。
- en: 'With that out of the way, it’s time to take our first steps. We’re going to
    start with some extremely simple building blocks to illustrate how we can understand
    different concepts in terms of these three perspectives. Our first building block
    will be a simple but critical concept: the function.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们要迈出第一步了。我们将从一些极其简单的基本构建块开始，以说明我们如何可以从这三个视角理解不同的概念。我们的第一个基本构建块将是一个简单但至关重要的概念：函数。
- en: Functions
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数
- en: What is a function, and how do we describe it? As with neural nets, there are
    several ways to describe functions, none of which individually paints a complete
    picture. Rather than trying to give a pithy one-sentence description, let’s simply
    walk through the three mental models one by one, playing the role of the blind
    men feeling different parts of the elephant.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是函数，我们如何描述它？与神经网络一样，有几种方法来描述函数，其中没有一种能够完整地描绘出整个图景。与其试图给出一个简洁的一句话描述，不如我们简单地逐个走过这三种心智模型，扮演感受大象不同部分的盲人的角色。
- en: Math
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'Here are two examples of functions, described in mathematical notation:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个函数的例子，用数学符号描述：
- en: '*f*[1](*x*) = *x*²'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f*[1](*x*) = *x*²'
- en: '*f*[2](*x*) = *max*(*x*, 0)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f*[2](*x*) = *max*(*x*, 0)'
- en: This notation says that the functions, which we arbitrarily call *f*[1] and
    *f*[2], take in a number *x* as input and transform it into either *x*² (in the
    first case) or *max*(*x*, 0) (in the second case).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个符号表示函数，我们任意地称为*f*[1]和*f*[2]，将一个数字*x*作为输入，并将其转换为*x*²（在第一种情况下）或*max*(*x*, 0)（在第二种情况下）。
- en: Diagrams
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: 'One way of depicting functions is to:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 描述函数的一种方式是：
- en: Draw an *x-y* plane (where *x* refers to the horizontal axis and *y* refers
    to the vertical axis).
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 画一个*x-y*平面（其中*x*指水平轴，*y*指垂直轴）。
- en: Plot a bunch of points, where the x-coordinates of the points are (usually evenly
    spaced) inputs of the function over some range, and the y-coordinates are the
    outputs of the function over that range.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制一堆点，其中点的x坐标是函数在某个范围内的（通常是均匀间隔的）输入，y坐标是该范围内函数的输出。
- en: Connect these plotted points.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接这些绘制的点。
- en: This was first done by the French philosopher René Descartes, and it is extremely
    useful in many areas of mathematics, in particular calculus. [Figure 1-1](#fig_01-01)
    shows the plot of these two functions.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这最初是由法国哲学家勒内·笛卡尔完成的，它在许多数学领域中非常有用，特别是微积分。[图1-1](#fig_01-01)显示了这两个函数的图表。
- en: '![Two continuous, mostly differentiable functions](assets/dlfs_0101.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![两个连续的、大部分可微的函数](assets/dlfs_0101.png)'
- en: Figure 1-1\. Two continuous, mostly differentiable functions
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1。两个连续的、大部分可微的函数
- en: However, there is another way to depict functions that isn’t as useful when
    learning calculus but that will be very useful for us when thinking about deep
    learning models. We can think of functions as boxes that take in numbers as input
    and produce numbers as output, like minifactories that have their own internal
    rules for what happens to the input. [Figure 1-2](#fig_01-02) shows both these
    functions described as general rules and how they operate on specific inputs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还有另一种描述函数的方式，在学习微积分时并不那么有用，但在思考深度学习模型时将非常有用。我们可以将函数看作是接受数字输入并产生数字输出的盒子，就像具有其自身内部规则的小工厂，用于处理输入。[图1-2](#fig_01-02)展示了这两个函数被描述为通用规则以及它们如何在特定输入上运行。
- en: '![Another way of looking at functions](assets/dlfs_0102.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![另一种看待函数的方式](assets/dlfs_0102.png)'
- en: Figure 1-2\. Another way of looking at these functions
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2. 另一种看待这些函数的方式
- en: Code
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Finally, we can describe these functions using code. Before we do, we should
    say a bit about the Python library on top of which we’ll be writing our functions:
    NumPy.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用代码描述这些函数。在此之前，我们应该简要介绍一下我们将在其上编写函数的Python库：NumPy。
- en: 'Code caveat #1: NumPy'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码注意事项＃1：NumPy
- en: 'NumPy is a widely used Python library for fast numeric computation, the internals
    of which are mostly written in C. Simply put: the data we deal with in neural
    networks will always be held in a *multidimensional array* that is almost always
    either one-, two-, three-, or four-dimensional, but especially two- or three-dimensional.
    The `ndarray` class from the NumPy library allows us to operate on these arrays
    in ways that are both (a) intuitive and (b) fast. To take the simplest possible
    example: if we were storing our data in Python lists (or lists of lists), adding
    or multiplying the lists elementwise using normal syntax wouldn’t work, whereas
    it does work for `ndarray`s:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy是一个广泛使用的Python库，用于快速数值计算，其内部大部分是用C编写的。简而言之：我们在神经网络中处理的数据将始终保存在一个几乎总是一维、二维、三维或四维的*多维数组*中，尤其是二维或三维。来自NumPy库的`ndarray`类允许我们以既直观又快速的方式操作这些数组。举个最简单的例子：如果我们将数据存储在Python列表（或列表的列表）中，使用正常语法逐元素添加或乘以列表是行不通的，而对于`ndarray`却是行得通的：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`ndarray`s also have several features you’d expect from an `n`-dimensional
    array; each `ndarray` has `n` axes, indexed from 0, so that the first axis is
    `0`, the second is `1`, and so on. In particular, since we deal with 2D `ndarray`s
    often, we can think of `axis = 0` as the rows and `axis = 1` as the columns—see
    [Figure 1-3](#fig_01-03).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`ndarray`还具有您从`n`维数组中期望的几个特性；每个`ndarray`都有`n`个轴，从0开始索引，因此第一个轴是`0`，第二个是`1`，依此类推。特别是，由于我们经常处理2D
    `ndarray`，我们可以将`axis = 0`看作行，`axis = 1`看作列——参见[图1-3](#fig_01-03)。'
- en: '![Simple NumPy array example](assets/dlfs_0103.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![简单的NumPy数组示例](assets/dlfs_0103.png)'
- en: Figure 1-3\. A 2D NumPy array, with axis = 0 as the rows and axis = 1 as the
    columns
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3. 一个2D NumPy数组，其中axis = 0表示行，axis = 1表示列
- en: 'NumPy’s `ndarray`s also support applying functions along these axes in intuitive
    ways. For example, summing along axis 0 (the *rows* for a 2D array) essentially
    “collapses the array” along that axis, returning an array with one less dimension
    than the original array; for a 2D array, this is equivalent to summing each column:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy的`ndarray`还支持沿着这些轴以直观方式应用函数。例如，沿着轴0（2D数组的*行*）求和基本上会沿着该轴“折叠数组”，返回一个比原始数组少一个维度的数组；对于2D数组，这相当于对每列求和：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Finally, NumPy `ndarray`s support adding a 1D array to the last axis; for a
    2D array `a` with `R` rows and `C` columns, this means we can add a 1D array `b`
    of length `C` and NumPy will do the addition in the intuitive way, adding the
    elements to each row of `a`:^([1](ch01.html#idm45732632700344))
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，NumPy的`ndarray`支持将1D数组添加到最后一个轴；对于具有`R`行和`C`列的2D数组`a`，这意味着我们可以添加长度为`C`的1D数组`b`，NumPy将以直观的方式进行加法运算，将元素添加到`a`的每一行：^([1](ch01.html#idm45732632700344))
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Code caveat #2: Type-checked functions'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码注意事项＃2：类型检查的函数
- en: 'As I’ve mentioned, the primary goal of the code we write in this book is to
    make the concepts I’m explaining precise and clear. This will get more challenging
    as the book goes on, as we’ll be writing functions with many arguments as part
    of complicated classes. To combat this, we’ll use functions with type signatures
    throughout; for example, in [Chapter 3](ch03.html#deep_learning_from_scratch),
    we’ll initialize our neural networks as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我提到的，我们在本书中编写的代码的主要目标是使我解释的概念变得精确和清晰。随着书的进行，这将变得更具挑战性，因为我们将编写具有许多参数的函数作为复杂类的一部分。为了应对这一挑战，我们将在整个过程中使用带有类型签名的函数；例如，在[第3章](ch03.html#deep_learning_from_scratch)中，我们将初始化我们的神经网络如下：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This type signature alone gives you some idea of what the class is used for.
    By contrast, consider the following type signature that we *could* use to define
    an operation:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 仅凭这个类型签名，您就可以对该类的用途有一些了解。相比之下，考虑以下类型签名，我们*可以*用来定义一个操作：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This type signature by itself gives you no hint as to what is going on; only
    by printing out each object’s type, seeing what operations get performed on each
    object, or guessing based on the names `x1` and `x2` could we understand what
    is going on in this function. I can instead define a function with a type signature
    as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 仅凭这个类型签名，您无法了解正在发生什么；只有通过打印出每个对象的类型，查看在每个对象上执行的操作，或根据名称`x1`和`x2`猜测，我们才能理解这个函数中正在发生的事情。相反，我可以定义一个带有以下类型签名的函数：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You know right away that this is a function that takes in two `ndarray`s, probably
    combines them in some way, and outputs the result of that combination. Because
    of the increased clarity they provide, we’ll use type-checked functions throughout
    this book.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您立即知道这是一个接受两个`ndarray`的函数，可能以某种方式将它们组合在一起，并输出该组合的结果。由于它们提供的更清晰性，我们将在本书中始终使用带有类型检查的函数。
- en: Basic functions in NumPy
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NumPy中的基本函数
- en: 'With these preliminaries in mind, let’s write up the functions we defined earlier
    in NumPy:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了这些基础知识之后，让我们在NumPy中编写我们之前定义的函数：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'One of NumPy’s quirks is that many functions can be applied to `ndarray`s either
    by writing `np.*function_name*(ndarray)` or by writing `ndarray.*function_name*`.
    For example, the preceding `relu` function could be written as: `x.clip(min=0)`.
    We’ll try to be consistent and use the `np.*function_name*(ndarray)` convention
    throughout—in particular, we’ll avoid tricks such as `*ndarray*.T` for transposing
    a two-dimensional `ndarray`, instead writing `np.transpose(*ndarray*, (1, 0))`.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: If you can wrap your mind around the fact that math, a diagram, and code are
    three different ways of representing the same underlying concept, then you are
    well on your way to displaying the kind of flexible thinking you’ll need to truly
    understand deep learning.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Derivatives
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Derivatives, like functions, are an extremely important concept for understanding
    deep learning that many of you are probably familiar with. Also like functions,
    they can be depicted in multiple ways. We’ll start by simply saying at a high
    level that the derivative of a function at a point is the “rate of change” of
    the output of the function with respect to its input at that point. Let’s now
    walk through the same three perspectives on derivatives that we covered for functions
    to gain a better mental model for how derivatives work.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Math
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, we’ll get mathematically precise: we can describe this number—how much
    the output of *f* changes as we change its input at a particular value *a* of
    the input—as a limit:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>=</mo> <munder><mo form="prefix"
    movablelimits="true">lim</mo> <mrow><mi>Δ</mi><mo>→</mo><mn>0</mn></mrow></munder>
    <mfrac><mrow><mi>f</mi><mfenced close=")" open="(" separators=""><mrow><mi>a</mi><mo>+</mo><mi>Δ</mi></mrow></mfenced><mo>-</mo><mi>f</mi><mfenced
    close=")" open="(" separators=""><mi>a</mi><mo>-</mo><mi>Δ</mi></mfenced></mrow>
    <mrow><mn>2</mn><mo>×</mo><mi>Δ</mi></mrow></mfrac></mrow></math>
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>=</mo> <munder><mo form="prefix"
    movablelimits="true">lim</mo> <mrow><mi>Δ</mi><mo>→</mo><mn>0</mn></mrow></munder>
    <mfrac><mrow><mi>f</mi><mfenced close=")" open="(" separators=""><mrow><mi>a</mi><mo>+</mo><mi>Δ</mi></mrow></mfenced><mo>-</mo><mi>f</mi><mfenced
    close=")" open="(" separators=""><mi>a</mi><mo>-</mo><mi>Δ</mi></mfenced></mrow>
    <mrow><mn>2</mn><mo>×</mo><mi>Δ</mi></mrow></mfrac></mrow></math>
- en: 'This limit can be approximated numerically by setting a very small value for
    *Δ*, such as 0.001, so we can compute the derivative as:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>f</mi><mo>(</mo><mi>a</mi><mo>+</mo><mn>0.001</mn><mo>)</mo><mo>-</mo><mi>f</mi><mo>(</mo><mi>a</mi><mo>-</mo><mn>0.001</mn><mo>)</mo></mrow>
    <mrow><mn>0.002</mn></mrow></mfrac></mrow></math>
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>f</mi><mo>(</mo><mi>a</mi><mo>+</mo><mn>0.001</mn><mo>)</mo><mo>-</mo><mi>f</mi><mo>(</mo><mi>a</mi><mo>-</mo><mn>0.001</mn><mo>)</mo></mrow>
    <mrow><mn>0.002</mn></mrow></mfrac></mrow></math>
- en: 'While accurate, this is only one part of a full mental model of derivatives.
    Let’s look at them from another perspective: a diagram.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: Diagrams
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, the familiar way: if we simply draw a tangent line to the Cartesian
    representation of the function *f*, the derivative of *f* at a point *a* is just
    the slope of this line at *a*. As with the mathematical descriptions in the prior
    subsection, there are two ways we can actually calculate the slope of this line.
    The first would be to use calculus to actually calculate the limit. The second
    would be to just take the slope of the line connecting *f* at *a* – 0.001 and
    *a* + 0.001\. The latter method is depicted in [Figure 1-4](#fig_01-04) and should
    be familiar to anyone who has taken calculus.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0104](assets/dlfs_0104.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
- en: Figure 1-4\. Derivatives as slopes
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'As we saw in the prior section, another way of thinking of functions is as
    mini-factories. Now think of the inputs to those factories being connected to
    the outputs by a string. The derivative is equal to the answer to this question:
    if we pull up on the input to the function *a* by some very small amount—or, to
    account for the fact that the function may be asymmetric at *a*, pull down on
    *a* by some small amount—by what multiple of this small amount will the output
    change, given the inner workings of the factory? This is depicted in [Figure 1-5](#fig_01-05).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0105](assets/dlfs_0105.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: Figure 1-5\. Another way of visualizing derivatives
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This second representation will turn out to be more important than the first
    one for understanding deep learning.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we can code up the approximation to the derivative that we saw previously:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When we say that “something is a function of something else”—for example, that
    *P* is a function of *E* (letters chosen randomly on purpose), what we mean is
    that there is some function *f* such that *f*(*E*) = *P*—or equivalently, there
    is a function *f* that takes in *E* objects and produces *P* objects. We might
    also think of this as meaning that *P* *is defined as* whatever results when we
    apply the function *f* to *E*:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '![Another way of visualizing functions](assets/dlfs_01in01.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
- en: 'And we would code this up as:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Nested Functions
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we’ll cover a concept that will turn out to be fundamental to understanding
    neural networks: functions can be “nested” to form “composite” functions. What
    exactly do I mean by “nested”? I mean that if we have two functions that by mathematical
    convention we call *f*[1] and *f*[2], the output of one of the functions becomes
    the input to the next one, so that we can “string them together.”'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most natural way to represent a nested function is with the “minifactory”
    or “box” representation (the second representation from [“Functions”](#functions-section-01)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: As [Figure 1-6](#fig_01-07) shows, an input goes into the first function, gets
    transformed, and comes out; then it goes into the second function and gets transformed
    again, and we get our final output.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '![f1 and f2 as a chain](assets/dlfs_0106.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: Figure 1-6\. Nested functions, naturally
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Math
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We should also include the less intuitive mathematical representation:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: <math><mrow><msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi>
    <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>=</mo> <mi>y</mi></mrow></math>
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: This is less intuitive because of the quirk that nested functions are read “from
    the outside in” but the operations are in fact performed “from the inside out.”
    For example, though <math><mrow><msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mi>y</mi></mrow></math> is read “f 2 of f 1 of x,”
    what it really means is to “first apply *f*[1] to *x*, and then apply *f*[2] to
    the result of applying *f*[1] to *x*.”
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, in keeping with my promise to explain every concept from three perspectives,
    we’ll code this up. First, we’ll define a data type for nested functions:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then we’ll define how data goes through a chain, first of length 2:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Another Diagram
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depicting the nested function using the box representation shows us that this
    composite function is really just a single function. Thus, we can represent this
    function as simply *f*[1] *f*[2], as shown in [Figure 1-7](#fig_01-08).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![f1f2 nested](assets/dlfs_0107.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: Figure 1-7\. Another way to think of nested functions
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Moreover, a theorem from calculus tells us that a composite function made up
    of “mostly differentiable” functions is itself mostly differentiable! Thus, we
    can think of *f*[1]*f*[2] as just another function that we can compute derivatives
    of—and computing derivatives of composite functions will turn out to be essential
    for training deep learning models.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: However, we need a formula to be able to compute this composite function’s derivative
    in terms of the derivatives of its constituent functions. That’s what we’ll cover
    next.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: The Chain Rule
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The chain rule is a mathematical theorem that lets us compute derivatives of
    composite functions. Deep learning models are, mathematically, composite functions,
    and reasoning about their derivatives is essential to training them, as we’ll
    see in the next couple of chapters.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Math
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mathematically, the theorem states—in a rather nonintuitive form—that, for a
    given value `x`,
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>
- en: where *u* is simply a dummy variable representing the input to a function.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When describing the derivative of a function *f* with one input and output,
    we can denote the *function* that represents the derivative of this function as
    <math><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac></math>
    . We could use a different dummy variable in place of *u*—it doesn’t matter, just
    as *f*(*x*) = *x*² and *f*(*y*) = *y*² mean the same thing.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, later on we’ll deal with functions that take in *multiple*
    inputs, say, both *x* and *y*. Once we get there, it will make sense to write
    <math><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>x</mi></mrow></mfrac></math>
    and have it mean something different than <math><mfrac><mrow><mi>d</mi><mi>f</mi></mrow>
    <mrow><mi>d</mi><mi>y</mi></mrow></mfrac></math> .
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，稍后我们将处理接受*多个*输入的函数，比如，*x*和*y*。一旦到达那里，编写<math><mfrac><mrow><mi>d</mi><mi>f</mi></mrow>
    <mrow><mi>d</mi><mi>x</mi></mrow></mfrac></math>并且让它意味着与<math><mfrac><mrow><mi>d</mi><mi>f</mi></mrow>
    <mrow><mi>d</mi><mi>y</mi></mrow></mfrac></math>不同的东西就会有意义。
- en: 'This is why in the preceding formula we denote *all* the derivatives with a
    *u* on the bottom: both *f*[1] and *f*[2] are functions that take in one input
    and produce one output, and in such cases (of functions with one input and one
    output) we’ll use *u* in the derivative notation.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么在前面的公式中，我们用底部的*u*表示*所有*的导数：*f*[1]和*f*[2]都是接受一个输入并产生一个输出的函数，在这种情况下（具有一个输入和一个输出的函数），我们将在导数符号中使用*u*。
- en: Diagram
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图表
- en: The preceding formula does not give much intuition into the chain rule. For
    that, the box representation is much more helpful. Let’s reason through what the
    derivative “should” be in the simple case of *f*[1] *f*[2].
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的公式并没有给出链式法则的太多直觉。对于这一点，框表示法更有帮助。让我们推理一下在简单情况下*f*[1] *f*[2]的导数“应该”是什么。
- en: '![f1f2 nested](assets/dlfs_0108.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![f1f2 nested](assets/dlfs_0108.png)'
- en: Figure 1-8\. An illustration of the chain rule
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8。链式法则的示例
- en: Intuitively, using the diagram in [Figure 1-8](#fig_01-09), the derivative of
    the composite function *should* be a sort of product of the derivatives of its
    constituent functions. Let’s say we feed the value 5 into the first function,
    and let’s say further that computing the *derivative* of the first function at
    *u* = 5 gives us a value of 3—that is, <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mn>5</mn> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math> .
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 直觉上，使用[图1-8](#fig_01-09)中的图表，复合函数的导数*应该*是其组成函数的导数的一种乘积。假设我们将值5输入到第一个函数中，再假设在*u*=5处计算第一个函数的*导数*得到一个值为3，即，<math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mn>5</mn> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math>。
- en: 'Let’s say that we then take the *value* of the function that comes out of the
    first box—let’s suppose it is 1, so that *f*[1](5) = 1—and compute the derivative
    of the second function *f*[2] at this value: that is, <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mn>1</mn> <mo>)</mo></mrow></mrow></math> . We find that this value is –2.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们然后取出第一个框中的函数的*值*，假设它是1，所以*f*[1](5) = 1，并计算在这个值处第二个函数*f*[2]的导数：即，<math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mn>1</mn> <mo>)</mo></mrow></mrow></math>。我们发现这个值是-2。
- en: 'If we think about these functions as being literally strung together, then
    if changing the input to box two by 1 unit yields a change of –2 units in the
    output of box two, changing the input to box two by 3 units should change the
    output to box two by –2 × 3 = –6 units. This is why in the formula for the chain
    rule, the final result is ultimately a product: <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow></mrow></math> *times* <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math> .'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这些函数想象成字面上串在一起，那么如果将第二个框的输入改变1个单位会导致第二个框的输出变化-2个单位，那么将第二个框的输入改变3个单位应该会导致第二个框的输出变化-2×3
    = -6个单位。这就是为什么在链式法则的公式中，最终结果最终是一个乘积：<math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow></mrow></math> *乘以* <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>。
- en: So by considering the diagram and the math, we can reason through what the derivative
    of the output of a nested function with respect to its input ought to be, using
    the chain rule. What might the code instructions for the computation of this derivative
    look like?
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过考虑图表和数学，我们可以通过链式法则推理出嵌套函数输出的导数与其输入应该是什么，代码指令可能是什么样的？
- en: Code
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Let’s code this up and show that computing derivatives in this way does in
    fact yield results that “look correct.” We’ll use the `square` function from [“Basic
    functions in NumPy”](#basic-NumPy) along with `sigmoid`, another function that
    ends up being important in deep learning:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写代码并展示以这种方式计算导数实际上会产生“看起来正确”的结果。我们将使用来自[“NumPy中的基本函数”](#basic-NumPy)的`square`函数，以及`sigmoid`，另一个在深度学习中变得重要的函数：
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'And now we code up the chain rule:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们编写链式法则的代码：
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[Figure 1-9](#fig_01-10) plots the results and shows that the chain rule works:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-9](#fig_01-10)绘制了结果，并显示链式法则有效：'
- en: '[PRE16]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Chain rule illustration](assets/dlfs_0109.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![链式法则示例](assets/dlfs_0109.png)'
- en: Figure 1-9\. The chain rule works, part 1
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-9。链式法则有效，第1部分
- en: The chain rule seems to be working. When the functions are upward-sloping, the
    derivative is positive; when they are flat, the derivative is zero; and when they
    are downward-sloping, the derivative is negative.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 链式法则似乎有效。当函数是向上倾斜时，导数是正的；当函数是平的时，导数是零；当函数是向下倾斜时，导数是负的。
- en: So we can in fact compute, both mathematically and via code, the derivatives
    of nested or “composite” functions such as *f*[1] *f*[2], as long as the individual
    functions are themselves mostly differentiable.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们实际上可以计算嵌套或“复合”函数的导数，如*f*[1] *f*[2]，只要这些单独的函数本身大部分是可微的。
- en: It will turn out that deep learning models are, mathematically, long chains
    of these mostly differentiable functions; spending time going manually through
    a slightly longer example in detail will help build your intuition about what
    is going on and how it can generalize to more complex models.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，深度学习模型在数学上是这些大部分可微函数的长链；花时间详细地手动通过一个稍微更长的例子将有助于建立您对正在发生的事情以及如何将其推广到更复杂模型的直觉。
- en: A Slightly Longer Example
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稍微长一点的例子
- en: 'Let’s closely examine a slightly longer chain: if we have three mostly differentiable
    functions—*f*[1], *f*[2], and *f*[3]—how would we go about computing the derivative
    of *f*[1] *f*[2] *f*[3]? We “should” be able to do it, since from the calculus
    theorem mentioned previously, we know that the composite of *any* finite number
    of “mostly differentiable” functions is differentiable.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细研究一个稍微更长的链条：如果我们有三个大部分可微的函数—*f*[1]、*f*[2]和*f*[3]—我们将如何计算*f*[1] *f*[2] *f*[3]的导数？我们“应该”能够做到，因为根据之前提到的微积分定理，我们知道“大部分可微”函数的复合是可微的。
- en: Math
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'Mathematically, the result turns out to be the following expression:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 数学上，结果是以下表达式：
- en: <math display="block"><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>3</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>3</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi>
    <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>3</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>3</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi>
    <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
- en: The underlying logic as to why the formula works for chains of length 2, <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>1</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    , also applies here—as does the lack of intuition from looking at the formula
    alone!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这个公式适用于长度为2的链条的基本逻辑，<math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>，在这里也适用——看公式本身缺乏直觉！
- en: Diagram
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: The best way to (literally) see why this formula makes sense is via another
    box diagram, as shown in [Figure 1-10](#fig_01-11).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 要（字面上）看到这个公式为什么是有意义的，最好的方法是通过另一个盒子图表，如[图1-10](#fig_01-11)所示。
- en: '![dlfs 0110](assets/dlfs_0110.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0110](assets/dlfs_0110.png)'
- en: Figure 1-10\. The “box model” for computing the derivative of three nested functions
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10。计算三个嵌套函数导数的“盒子模型”
- en: 'Using similar reasoning to the prior section: if we imagine the input to *f*[1]
    *f*[2] *f*[3] (call it *a*) being connected to the output (call it *b*) by a string,
    then changing *a* by a small amount *Δ* will result in a change in *f*[1](*a*)
    of <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>1</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow></mrow></math> times *Δ*, which will result in a change to <math><mrow><msub><mi>f</mi>
    <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math> (the next step along
    in the chain) of <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math> times *Δ*, and so
    on for the third step, when we get to the final change equal to the full formula
    for the preceding chain rule times *Δ*. Spend a bit of time going through this
    explanation and the earlier diagram—but not too much time, since we’ll develop
    even more intuition for this when we code it up.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用类似的推理来自前一节：如果我们想象*f*[1] *f*[2] *f*[3]的输入（称为*a*）通过一根绳子连接到输出（称为*b*），那么将*a*改变一个小量*Δ*将导致*f*[1](*a*)的变化为<math><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mrow></math>乘以*Δ*，这将导致<math><mrow><msub><mi>f</mi>
    <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>（链中的下一步）的变化为<math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>1</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow></mrow></math>乘以*Δ*，以此类推到第三步，当我们到达最终变化时，等于前述链式法则的完整公式乘以*Δ*。花一点时间阅读这个解释和之前的图表，但不要花太多时间，因为当我们编写代码时，我们将对此有更多的直觉。
- en: Code
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'How might we translate such a formula into code instructions for computing
    the derivative, given the constituent functions? Interestingly, already in this
    simple example we see the beginnings of what will become the forward and backward
    passes of a neural network:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将这样的公式转化为代码指令，以计算导数，考虑到组成函数？有趣的是，在这个简单的例子中，我们已经看到了神经网络前向和后向传递的开端：
- en: '[PRE17]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Something interesting took place here—to compute the chain rule for this nested
    function, we made two “passes” over it:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生了一些有趣的事情——为了计算这个嵌套函数的链式法则，我们进行了两次“遍历”：
- en: First, we went “forward” through it, computing the quantities `f1_of_x` and
    `f2_of_x` along the way. We can call this (and think of it as) “the forward pass.”
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们“向前走”通过它，沿途计算量`f1_of_x`和`f2_of_x`。我们可以称之为（并将其视为）“前向传递”。
- en: Then, we “went backward” through the function, using the quantities that we
    computed on the forward pass to compute the quantities that make up the derivative.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们“向后走”，使用我们在前向传递中计算的量来计算组成导数的量。
- en: Finally, we multiplied three of these quantities together to get our derivative.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将这三个量相乘以得到我们的导数。
- en: 'Now, let’s show that this works, using the three simple functions we’ve defined
    so far: `sigmoid`, `square`, and `leaky_relu`.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们展示这是如何工作的，使用我们迄今为止定义的三个简单函数：`sigmoid`、`square` 和 `leaky_relu`。
- en: '[PRE18]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[Figure 1-11](#fig_01-12) shows the result.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1-11](#fig_01-12) 显示了结果。'
- en: '![dlfs 0111](assets/dlfs_0111.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0111](assets/dlfs_0111.png)'
- en: Figure 1-11\. The chain rule works, even with triply nested functions
  id: totrans-156
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-11\. 链式法则有效，即使是三重嵌套函数
- en: Again, comparing the plots of the derivatives to the slopes of the original
    functions, we see that the chain rule is indeed computing the derivatives properly.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 再次比较导数的图与原始函数的斜率，我们看到链式法则确实正确计算了导数。
- en: Let’s now apply our understanding to composite functions with multiple inputs,
    a class of functions that follows the same principles we already established and
    is ultimately more applicable to deep learning.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将我们的理解应用于具有多个输入的复合函数，这是一类遵循我们已经建立的相同原则并且最终更适用于深度学习的函数。
- en: Functions with Multiple Inputs
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有多个输入的函数
- en: By this point, we have a conceptual understanding of how functions can be strung
    together to form composite functions. We also have a sense of how to represent
    these functions as series of boxes that inputs go into and outputs come out of.
    Finally, we’ve walked through how to compute the derivatives of these functions
    so that we understand these derivatives both mathematically and as quantities
    computed via a step-by-step process with a “forward” and “backward” component.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们对如何将函数串联起来形成复合函数有了概念上的理解。我们也知道如何将这些函数表示为一系列输入和输出的方框。最后，我们已经了解了如何计算这些函数的导数，以便我们既从数学上又从“前向”和“后向”组件计算的过程中理解这些导数的数量。
- en: 'Oftentimes, the functions we deal with in deep learning don’t have just one
    input. Instead, they have several inputs that at certain steps are added together,
    multiplied, or otherwise combined. As we’ll see, computing the derivatives of
    the outputs of these functions with respect to their inputs is still no problem:
    let’s consider a very simple scenario with multiple inputs, where two inputs are
    added together and then fed through another function.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，我们处理的函数通常不只有一个输入。相反，它们有几个输入，在某些步骤中被相加、相乘或以其他方式组合。正如我们将看到的，计算这些函数的输出对其输入的导数仍然不是问题：让我们考虑一个非常简单的具有多个输入的场景，其中两个输入被相加，然后通过另一个函数进行馈送。
- en: Math
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'For this example, it is actually useful to start by looking at the math. If
    our inputs are *x* and *y*, then we could think of the function as occurring in
    two steps. In Step 1, *x* and *y* are fed through a function that adds them together.
    We’ll denote that function as *α* (we’ll use Greek letters to refer to function
    names throughout) and the output of the function as *a*. Formally, this is simply:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，实际上从数学上看是有用的。如果我们的输入是 *x* 和 *y*，那么我们可以将函数看作是分两步进行的。在第一步中，*x* 和 *y* 被馈送到一个将它们相加的函数中。我们将这个函数表示为
    *α*（我们将使用希腊字母来引用函数名称），函数的输出为 *a*。形式上，这简单地表示为：
- en: <math display="block"><mrow><mi>a</mi> <mo>=</mo> <mi>α</mi> <mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>x</mi> <mo>+</mo> <mi>y</mi></mrow></math>
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>a</mi> <mo>=</mo> <mi>α</mi> <mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>x</mi> <mo>+</mo> <mi>y</mi></mrow></math>
- en: 'Step 2 would be to feed *a* through some function *σ* (*σ* can be any continuous
    function, such as `sigmoid`, or the `square` function, or even a function whose
    name doesn’t start with *s*). We’ll denote the output of this function as *s*:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是将 *a* 馈送到某个函数 *σ* 中（*σ* 可以是任何连续函数，如 `sigmoid`，或 `square` 函数，甚至一个名称不以 *s*
    开头的函数）。我们将这个函数的输出表示为 *s*：
- en: <math display="block"><mrow><mi>s</mi> <mo>=</mo> <mi>σ</mi> <mo>(</mo> <mi>a</mi>
    <mo>)</mo></mrow></math>
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>s</mi> <mo>=</mo> <mi>σ</mi> <mo>(</mo> <mi>a</mi>
    <mo>)</mo></mrow></math>
- en: 'We could, equivalently, denote the entire function as *f* and write:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以等价地将整个函数表示为 *f* 并写成：
- en: <math display="block"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi>
    <mo>)</mo> <mo>=</mo> <mi>σ</mi> <mo>(</mo> <mi>x</mi> <mo>+</mo> <mi>y</mi> <mo>)</mo></mrow></math>
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi>
    <mo>)</mo> <mo>=</mo> <mi>σ</mi> <mo>(</mo> <mi>x</mi> <mo>+</mo> <mi>y</mi> <mo>)</mo></mrow></math>
- en: This is more mathematically concise, but it obscures the fact that this is really
    two operations happening sequentially. To illustrate that, we need the diagram
    in the next section.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这更加数学上简洁，但它掩盖了这实际上是两个操作按顺序发生的事实。为了说明这一点，我们需要下一节中的图表。
- en: Diagram
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: 'Now that we’re at the stage where we’re examining functions with multiple inputs,
    let’s pause to define a concept we’ve been dancing around: the diagrams with circles
    and arrows connecting them that represent the mathematical “order of operations”
    can be thought of as *computational graphs*. For example, [Figure 1-12](#fig_01-13)
    shows a computational graph for the function *f* we just described.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们正在检查具有多个输入的函数，让我们暂停一下来定义一个我们一直在围绕的概念：用圆圈和连接它们的箭头表示数学“运算顺序”的图表可以被视为 *计算图*。例如，[图 1-12](#fig_01-13)
    显示了我们刚刚描述的函数 *f* 的计算图。
- en: '![dlfs 0112](assets/dlfs_0112.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0112](assets/dlfs_0112.png)'
- en: Figure 1-12\. Function with multiple inputs
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-12\. 具有多个输入的函数
- en: Here we see the two inputs going into *α* and coming out as *a* and then being
    fed through *σ*.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们看到两个输入进入 *α*，作为 *a* 出来，然后通过 *σ* 进行馈送。
- en: Code
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Coding this up is very straightforward; note, however, that we have to add
    one extra assertion:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 编写这个代码非常简单；但是请注意，我们必须添加一个额外的断言：
- en: '[PRE19]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Unlike the functions we saw earlier in this chapter, this function does not
    simply operate “elementwise” on each element of its input `ndarray`s. Whenever
    we deal with an operation that takes multiple `ndarray`s as inputs, we have to
    check their shapes to ensure they meet whatever conditions are required by that
    operation. Here, for a simple operation such as addition, all we need to check
    is that the shapes are identical so that the addition can happen elementwise.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 与本章前面看到的函数不同，这个函数不仅仅是在其输入 `ndarray` 的每个元素上“逐元素”操作。每当我们处理一个需要多个 `ndarray` 作为输入的操作时，我们必须检查它们的形状，以确保它们满足该操作所需的任何条件。在这里，对于一个简单的加法操作，我们只需要检查形状是否相同，以便可以逐元素进行加法。
- en: Derivatives of Functions with Multiple Inputs
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有多个输入的函数的导数
- en: It shouldn’t seem surprising that we can compute the derivative of the output
    of such a function with respect to both of its inputs.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不应感到惊讶，我们可以计算这样一个函数的输出对其两个输入的导数。
- en: Diagram
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: 'Conceptually, we simply do the same thing we did in the case of functions with
    one input: compute the derivative of each constituent function “going backward”
    through the computational graph and then multiply the results together to get
    the total derivative. This is shown in [Figure 1-13](#fig_01-14).'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0113](assets/dlfs_0113.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
- en: Figure 1-13\. Going backward through the computational graph of a function with
    multiple inputs
  id: totrans-184
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Math
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The chain rule applies to these functions in the same way it applied to the
    functions in the prior sections. Since this is a nested function, with <math><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>σ</mi> <mo>(</mo>
    <mi>α</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>)</mo></mrow></math>
    , we have:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>α</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>α</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>+</mo>
    <mi>y</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>α</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>α</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>α</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>+</mo>
    <mi>y</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>α</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
- en: And of course <math><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>y</mi></mrow></mfrac></math>
    would be identical.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: 'Now note that:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>α</mi></mrow> <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn></mrow></math>
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>α</mi></mrow> <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn></mrow></math>
- en: since for every unit increase in *x*, *a* increases by one unit, no matter the
    value of *x* (the same holds for *y*).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Given this, we can code up how we might compute the derivative of such a function.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: A straightforward exercise for the reader is to modify this for the case where
    `x` and `y` are multiplied instead of added.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we’ll examine a more complicated example that more closely mimics what
    happens in deep learning: a similar function to the previous example, but with
    two *vector* inputs.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Functions with Multiple Vector Inputs
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In deep learning, we deal with functions whose inputs are *vectors* or *matrices*.
    Not only can these objects be added, multiplied, and so on, but they can also
    combined via a dot product or a matrix multiplication. In the rest of this chapter,
    I’ll show how the mathematics of the chain rule and the logic of computing the
    derivatives of these functions using a forward and backward pass can still apply.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: These techniques will end up being central to understanding why deep learning
    works. In deep learning, our goal will be to fit a model to some data. More precisely,
    this means that we want to find a mathematical function that maps *observations*
    from the data—which will be inputs to the function—to some desired *predictions*
    from the data—which will be the outputs of the function—in as optimal a way as
    possible. It turns out these observations will be encoded in matrices, typically
    with row as an observation and each column as a numeric feature for that observation.
    We’ll cover this in more detail in the next chapter; for now, being able to reason
    about the derivatives of complex functions involving dot products and matrix multiplications
    will be essential.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by defining precisely what I mean, mathematically.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Math
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A typical way to represent a single data point, or “observation,” in a neural
    network is as a row with *n* features, where each feature is simply a number *x*[1],
    *x*[2], and so on, up to *x*[*n*]:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>X</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>1</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd> <mtd><mo>...</mo></mtd>
    <mtd><msub><mi>x</mi> <mi>n</mi></msub></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>X</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>1</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd> <mtd><mo>...</mo></mtd>
    <mtd><msub><mi>x</mi> <mi>n</mi></msub></mtd></mtr></mtable></mfenced></mrow></math>
- en: A canonical example to keep in mind here is predicting housing prices, which
    we’ll build a neural network from scratch to do in the next chapter; in this example,
    *x*[1], *x*[2], and so on are numerical features of a house, such as its square
    footage or its proximity to schools.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Creating New Features from Existing Features
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Perhaps the single most common operation in neural networks is to form a “weighted
    sum” of these features, where the weighted sum could emphasize certain features
    and de-emphasize others and thus be thought of as a new feature that itself is
    just a combination of old features. A concise way to express this mathematically
    is as a *dot product* of this observation, with some set of “weights” of the same
    length as the features, *w*[1], *w*[2], and so on, up to *w*[*n*]. Let’s explore
    this concept from the three perspectives we’ve used thus far in this chapter.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Math
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To be mathematically precise, if:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi>
    <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>w</mi> <mn>2</mn></msub></mtd></mtr>
    <mtr><mtd><mo>⋮</mo></mtd></mtr> <mtr><mtd><msub><mi>w</mi> <mi>n</mi></msub></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi>
    <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>w</mi> <mn>2</mn></msub></mtd></mtr>
    <mtr><mtd><mo>⋮</mo></mtd></mtr> <mtr><mtd><msub><mi>w</mi> <mi>n</mi></msub></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'then we could define the output of this operation as:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>N</mi> <mo>=</mo> <mi>ν</mi> <mrow><mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>X</mi> <mo>×</mo>
    <mi>W</mi> <mo>=</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>2</mn></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>x</mi> <mi>n</mi></msub>
    <mo>×</mo> <msub><mi>w</mi> <mi>n</mi></msub></mrow></math>
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>N</mi> <mo>=</mo> <mi>ν</mi> <mrow><mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>X</mi> <mo>×</mo>
    <mi>W</mi> <mo>=</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>2</mn></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>x</mi> <mi>n</mi></msub>
    <mo>×</mo> <msub><mi>w</mi> <mi>n</mi></msub></mrow></math>
- en: Note that this operation is a special case of a *matrix multiplication* that
    just happens to be a dot product because *X* has one row and *W* has only one
    column.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s look at a few ways we could depict this with a diagram.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A simple way of depicting this operation is shown in [Figure 1-14](#fig_01-15).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0114](assets/dlfs_0114.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
- en: Figure 1-14\. Diagram of a vector dot product
  id: totrans-217
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This diagram depicts an operation that takes in two inputs, both of which can
    be `ndarray`s, and produces one output `ndarray`.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: But this is really a massive shorthand for many operations that are happening
    on many inputs. We could instead highlight the individual operations and inputs,
    as shown in Figures [1-15](#fig_01-16) and [1-16](#fig_01-17).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0115](assets/dlfs_0115.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
- en: Figure 1-15\. Another diagram of a matrix multiplication
  id: totrans-221
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![dlfs 0116](assets/dlfs_0116.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
- en: Figure 1-16\. A third diagram of a matrix multiplication
  id: totrans-223
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The key point is that the dot product (or matrix multiplication) is a concise
    way to represent many individual operations; in addition, as we’ll start to see
    in the next section, using this operation makes our derivative calculations on
    the backward pass extremely concise as well.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, in code this operation is simply:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: where we have a new assertion that ensures that the matrix multiplication will
    work. (This is necessary since this is our first operation that doesn’t merely
    deal with `ndarray`s that are the same size and perform an operation elementwise—our
    output is now actually a different size than our input.)
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Derivatives of Functions with Multiple Vector Inputs
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For functions that simply take one input as a number and produce one output,
    like *f*(*x*) = *x*² or *f*(*x*) = sigmoid(*x*), computing the derivative is straightforward:
    we simply apply rules from calculus. For vector functions, it isn’t immediately
    obvious what the derivative is: if we write a dot product as <math><mrow><mi>ν</mi>
    <mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo> <mo>=</mo> <mi>N</mi></mrow></math>
    , as in the prior section, the question naturally arises—what would <math><mfrac><mrow><mi>∂</mi><mi>N</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac></math> and <math><mfrac><mrow><mi>∂</mi><mi>N</mi></mrow>
    <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac></math> be?'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Conceptually, we just want to do something like in [Figure 1-17](#fig_01-18).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0117](assets/dlfs_0117.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
- en: Figure 1-17\. Backward pass of a matrix multiplication, conceptually
  id: totrans-234
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Calculating these derivatives was easy when we were just dealing with addition
    and multiplication, as in the prior examples. But how can we do the analogous
    thing with matrix multiplication? To define that precisely, we’ll have to turn
    to the math.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Math
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, how would we even define “the derivative with respect to a matrix”?
    Recalling that the matrix syntax is just shorthand for a bunch of numbers arranged
    in a particular form, “the derivative with respect to a matrix” really means “the
    derivative with respect to each element of the matrix.” Since *X* is a row, a
    natural way to define it is:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mtd> <mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>2</mn></msub></mrow></mfrac></mtd> <mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>3</mn></msub></mrow></mfrac></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mtd> <mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>2</mn></msub></mrow></mfrac></mtd> <mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>3</mn></msub></mrow></mfrac></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'However, the output of *ν* is just a number: <math><mrow><mi>N</mi> <mo>=</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub></mrow></math>
    . And looking at this, we can see that if, for example, <math><msub><mi>x</mi>
    <mn>1</mn></msub></math> changes by *ϵ* units, then *N* will change by <math><mrow><msub><mi>w</mi>
    <mn>1</mn></msub> <mo>×</mo> <mi>ϵ</mi></mrow></math> units—and the same logic
    applies to the other *x*[*i*] elements. Thus:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>1</mn></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi> <mn>1</mn></msub></mrow></math><math
    display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>2</mn></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi> <mn>2</mn></msub></mrow></math><math
    display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>3</mn></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi> <mn>3</mn></msub></mrow></math>
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 'And so:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi> <mn>1</mn></msub></mtd>
    <mtd><msub><mi>w</mi> <mn>2</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>3</mn></msub></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi> <mn>1</mn></msub></mtd>
    <mtd><msub><mi>w</mi> <mn>2</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>3</mn></msub></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
- en: This is a surprising and elegant result that turns out to be a key piece of
    the puzzle to understanding both why deep learning works and how it can be implemented
    so cleanly.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'Using similar reasoning, we can see that:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi> <mn>1</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi>
    <mn>3</mn></msub></mtd></mtr></mtable></mfenced> <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup></mrow></math>
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi> <mn>1</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi>
    <mn>3</mn></msub></mtd></mtr></mtable></mfenced> <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup></mrow></math>
- en: Code
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here, reasoning mathematically about what the answer “should” be was the hard
    part. The easy part is coding up the result:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `dNdX` quantity computed here represents the partial derivative of each
    element of *X* with respect to the sum of the output *N*. There is a special name
    for this quantity that we’ll use throughout the book: we’ll call it the *gradient*
    of *X* with respect to *X*. The idea is that for an individual element of *X*—say,
    *x*[3]—the corresponding element in `dNdx` (`dNdX[2]`, to be specific) is the
    partial derivative of the output of the vector dot product *N* with respect to
    *x*[3]. The term “gradient” as we’ll use it in this book simply refers to a multidimensional
    analogue of the partial derivative; specifically, it is an array of partial derivatives
    of the output of a function with respect to each element of the input to that
    function.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 'Vector Functions and Their Derivatives: One Step Further'
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Deep learning models, of course, involve more than one operation: they include
    long chains of operations, some of which are vector functions like the one covered
    in the last section, and some of which simply apply a function elementwise to
    the `ndarray` they receive as input. Therefore, we’ll now look at computing the
    derivative of a composite function that includes *both* kinds of functions. Let’s
    suppose our function takes in the vectors *X* and *W*, performs the dot product
    described in the prior section—which we’ll denote as <math><mrow><mi>ν</mi> <mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow></math> —and then feeds the
    vectors through a function *σ*. We’ll express the same objective as before, but
    in new language: we want to compute the gradients of the output of this new function
    with respect to *X* and *W*. Again, starting in the next chapter, we’ll see in
    precise detail how this is connected to what neural networks do, but for now we
    just want to build up the idea that we can compute gradients for computational
    graphs of arbitrary complexity.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The diagram for this function, shown in [Figure 1-18](#fig_01-19), is the same
    as in [Figure 1-17](#fig_01-18), with the *σ* function simply added onto the end.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0118](assets/dlfs_0118.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
- en: Figure 1-18\. Same graph as before, but with another function tacked onto the
    end
  id: totrans-255
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Math
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Mathematically, this is straightforward as well:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>s</mi> <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>s</mi> <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>
- en: Code
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, we can code this function up as:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Vector Functions and Their Derivatives: The Backward Pass'
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The backward pass is similarly just a straightforward extension of the prior
    example.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Math
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since *f*(*X, W*) is a nested function—specifically, *f*(*X, W*) = *σ*(*ν*(*X,
    W*))—its derivative with respect to, for example, *X* should conceptually be:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow></mrow></math>
- en: 'But the first part of this is simply:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>
- en: which is well defined since *σ* is just a continuous function whose derivative
    we can evaluate at any point, and here we are just evaluating it at <math><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>3</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub></mrow></math>
    .
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, we reasoned in the prior example that <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
    . Therefore:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow> <mo>×</mo> <msup><mi>W</mi>
    <mi>T</mi></msup></mrow></math>
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow> <mo>×</mo> <msup><mi>W</mi>
    <mi>T</mi></msup></mrow></math>
- en: which, as in the preceding example, results in a vector of the same shape as
    *X*, since the final answer is a number, <math><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>
    , times a vector of the same shape as *X* in *W*^(*T*).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The diagram for the backward pass of this function, shown in [Figure 1-19](#fig_01-20),
    is similar to that of the prior example and even higher level than the math; we
    just have to add one more multiplication based on the derivative of the *σ* function
    evaluated at the result of the matrix multiplication.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0119](assets/dlfs_0119.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-19\. Graph with a matrix multiplication: the backward pass'
  id: totrans-276
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Code
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, coding up the backward pass is straightforward as well:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Notice that we see the same dynamic here that we saw in the earlier example
    with the three nested functions: we compute quantities on the forward pass (here,
    just `N`) that we then use during the backward pass.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Is this right?
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'How can we tell if these derivatives we’re computing are correct? A simple
    test is to perturb the input a little bit and observe the resulting change in
    output. For example, *X* in this case is:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: If we increase *x*[3] by *0.01*, from `-1.726` to `-1.716`, we should see an
    increase in the value produced by the forward function of *the gradient of the
    output with respect to x[3] × 0.01*. [Figure 1-20](#fig_01-21) shows this.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0120](assets/dlfs_0120.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-20\. Gradient checking: an illustration'
  id: totrans-287
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Using the `matrix_function_backward_1` function, we can see that the gradient
    is `-0.1121`:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: To test whether this gradient is correct, we should see, after incrementing
    *x*[3] by 0.01, a corresponding decrease in the *output* of the function by about
    `0.01 × -0.1121 = -0.001121`; if we saw an decrease by more or less than this
    amount, or an increase, for example, we would know that our reasoning about the
    chain rule was off. What we see when we do this calculation,^([2](ch01.html#idm45732630322664))
    however, is that increasing *x*[3] by a small amount does indeed decrease the
    value of the output of the function by `0.01 × -0.1121`—which means the derivatives
    we’re computing are correct!
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: 'To close out this chapter, we’ll cover an example that builds on everything
    we’ve done so far and directly applies to the models we’ll build in the next chapter:
    a computational graph that starts by multiplying a pair of two-dimensional matrices
    together.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Computational Graph with Two 2D Matrix Inputs
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In deep learning, and in machine learning more generally, we deal with operations
    that take as input two 2D arrays, one of which represents a batch of data *X*
    and the other of which represents the weights *W*. In the next chapter, we’ll
    dive deep into why this makes sense in a modeling context, but in this chapter
    we’ll just focus on the mechanics and the math behind this operation. Specifically.
    we’ll walk through a simple example in detail and show that even when multiplications
    of 2D matrices are involved, rather than just dot products of 1D vectors, the
    reasoning we’ve been using throughout this chapter still makes mathematical sense
    and is in fact extremely easy to code.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: As before, the math needed to derive these results gets…not difficult, but messy.
    Nevertheless, the result is quite clean. And, of course, we’ll break it down step
    by step and always connect it back to both code and diagrams.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: Math
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s suppose that:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>X</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>11</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>12</mn></msub></mtd> <mtd><msub><mi>x</mi>
    <mn>13</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi> <mn>21</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>22</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>23</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>31</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>32</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>33</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>X</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>11</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>12</mn></msub></mtd> <mtd><msub><mi>x</mi>
    <mn>13</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi> <mn>21</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>22</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>23</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>31</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>32</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>33</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'and:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi>
    <mn>11</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>12</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mn>21</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>22</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mn>31</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>32</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi>
    <mn>11</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>12</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mn>21</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>22</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mn>31</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>32</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
- en: This could correspond to a dataset in which each observation has three features,
    and the three rows could correspond to three different observations for which
    we want to make predictions.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we’ll define the following straightforward operations to these matrices:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Multiply these matrices together. As before, we’ll denote the function that
    does this as *ν*(*X*, *W*) and the output as *N*, so that *N* = *ν*(*X*, *W*).
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Feed <math><mi>N</mi></math> result through some differentiable function *σ*,
    and define (*S* = *σ*(*N*).
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'As before, the question now is: what are the gradients of the output *S* with
    respect to *X* and *W*? Can we simply use the chain rule again? Why or why not?'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: 'If you think about this for a bit, you may realize that something is different
    from the previous examples that we’ve looked at: *S is now a matrix*, not simply
    a number. And what, after all, does the gradient of one matrix with respect to
    another matrix mean?'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: 'This leads us to a subtle but important idea: we may perform whatever series
    of operations on multidimensional arrays we want, but for the notion of a “gradient”
    with respect to some output to be well defined, we need to *sum* (or otherwise
    aggregate into a single number) the final array in the sequence so that the notion
    of “how much will changing each element of *X* affect the output” will even make
    sense.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: So we’ll tack onto the end a third function, *Lambda*, that simply takes the
    elements of *S* and sums them up.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make this mathematically concrete. First, let’s multiply *X* and *W*:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>X</mi> <mo>×</mo> <mi>W</mi> <mo>=</mo> <mfenced
    close="]" open="["><mtable><mtr><mtd><mrow><msub><mi>x</mi> <mn>11</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub></mrow></mtd> <mtd><mrow><msub><mi>x</mi>
    <mn>11</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>12</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>13</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr>
    <mtr><mtd><mrow><msub><mi>x</mi> <mn>21</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>31</mn></msub></mrow></mtd> <mtd><mrow><msub><mi>x</mi> <mn>21</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr> <mtr><mtd><mrow><msub><mi>x</mi>
    <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub></mrow></mtd>
    <mtd><mrow><msub><mi>x</mi> <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>X</mi> <msub><mi>W</mi> <mn>21</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi>
    <msub><mi>W</mi> <mn>22</mn></msub></mrow></mtd></mtr> <mtr><mtd><mrow><mi>X</mi>
    <msub><mi>W</mi> <mn>31</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>X</mi> <mo>×</mo> <mi>W</mi> <mo>=</mo> <mfenced
    close="]" open="["><mtable><mtr><mtd><mrow><msub><mi>x</mi> <mn>11</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub></mrow></mtd> <mtd><mrow><msub><mi>x</mi>
    <mn>11</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>12</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>13</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr>
    <mtr><mtd><mrow><msub><mi>x</mi> <mn>21</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>31</mn></msub></mrow></mtd> <mtd><mrow><msub><mi>x</mi> <mn>21</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr> <mtr><mtd><mrow><msub><mi>x</mi>
    <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub></mrow></mtd>
    <mtd><mrow><msub><mi>x</mi> <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>X</mi> <msub><mi>W</mi> <mn>21</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi>
    <msub><mi>W</mi> <mn>22</mn></msub></mrow></mtd></mtr> <mtr><mtd><mrow><mi>X</mi>
    <msub><mi>W</mi> <mn>31</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: where we denote row *i* and column *j* in the resulting matrix as <math><mrow><mi>X</mi>
    <msub><mi>W</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math> for convenience.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we’ll feed this result through *σ*, which just means applying *σ* to
    every element of the matrix <math><mrow><mi>X</mi> <mo>×</mo> <mi>W</mi></mrow></math>
    :'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>×</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi> <mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>21</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>×</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi> <mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>21</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'Finally, we can simply sum up these elements:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>L</mi> <mo>=</mo> <mi>Λ</mi> <mrow><mo>(</mo>
    <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>×</mo> <mi>W</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mi>Λ</mi> <mrow><mo>(</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub> <mo>)</mo></mrow></mtd>
    <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub>
    <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi>
    <msub><mi>W</mi> <mn>21</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>22</mn></msub> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced> <mo>)</mo></mrow>
    <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub>
    <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi>
    <msub><mi>W</mi> <mn>21</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>22</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi>
    <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub> <mo>)</mo></mrow>
    <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>32</mn></msub>
    <mo>)</mo></mrow></mrow></math>
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>L</mi> <mo>=</mo> <mi>Λ</mi> <mrow><mo>(</mo>
    <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>×</mo> <mi>W</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mi>Λ</mi> <mrow><mo>(</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub> <mo>)</mo></mrow></mtd>
    <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub>
    <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi>
    <msub><mi>W</mi> <mn>21</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>22</mn></msub> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced> <mo>)</mo></mrow>
    <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub>
    <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi>
    <msub><mi>W</mi> <mn>21</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>22</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi>
    <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub> <mo>)</mo></mrow>
    <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>32</mn></msub>
    <mo>)</mo></mrow></mrow></math>
- en: 'Now we are back in a pure calculus setting: we have a number, *L*, and we want
    to figure out the gradient of *L* with respect to *X* and *W*; that is, we want
    to know how much changing *each element* of these input matrices (*x*[11], *w*[21],
    and so on) would change *L*. We can write this as:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>32</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>33</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>32</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>33</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: And now we understand mathematically the problem we are up against. Let’s pause
    the math for a second and catch up with our diagram and code.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Conceptually, what we are doing here is similar to what we’ve done in the previous
    examples with a computational graph with multiple inputs; thus, [Figure 1-21](#fig_01-22)
    should look familiar.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0121](assets/dlfs_0121.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
- en: Figure 1-21\. Graph of a function with a complicated forward pass
  id: totrans-322
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We are simply sending inputs forward as before. We claim that even in this more
    complicated scenario, we should be able to calculate the gradients we need using
    the chain rule.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can code this up as:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The Fun Part: The Backward Pass'
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we want to “perform the backward pass” for this function, showing how, even
    when a matrix multiplication is involved, we can end up calculating the gradient
    of `N` with respect to each of the elements of our input `ndarray`s.^([3](ch01.html#idm45732628068456))
    With this final step figured out, starting to train real machine learning models
    in [Chapter 2](ch02.html#fundamentals) will be straightforward. First, let’s remind
    ourselves what we are doing, conceptually.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Again, what we’re doing is similar to what we’ve done in the prior examples
    from this chapter; [Figure 1-22](#fig_01-23) should look as familiar as [Figure 1-21](#fig_01-22)
    did.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0122](assets/dlfs_0122.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
- en: Figure 1-22\. Backward pass through our complicated function
  id: totrans-332
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We simply need to calculate the partial derivative of each constituent function
    and evaluate it at its input, multiplying the results together to get the final
    derivative. Let’s consider each of these partial derivatives in turn; the only
    way through it is through the math.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: Math
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s first note that we could compute this directly. The value *L* is indeed
    a function of *x*[11], *x*[12], and so on, all the way up to *x*[33].
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: 'However, that seems complicated. Wasn’t the whole point of the chain rule that
    we can break down the derivatives of complicated functions into simple pieces,
    compute each of those pieces, and then just multiply the results? Indeed, that
    fact was what made it so easy to code these things up: we just went step by step
    through the forward pass, saving the results as we went, and then we used those
    results to evaluate all the necessary derivatives for the backward pass.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: I’ll show that this approach only *kind of* works when there are matrices involved.
    Let’s dive in.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: 'We can write *L* as <math><mrow><mi>Λ</mi> <mo>(</mo> <mi>σ</mi> <mo>(</mo>
    <mi>ν</mi> <mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo> <mo>)</mo> <mo>)</mo></mrow></math>
    . If this were a regular function, we would just write the chain rule:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow></mrow></math>
- en: Then we would compute each of the three partial derivatives in turn. This is
    exactly what we did before in the function of three nested functions, for which
    we computed the derivative using the chain rule, and [Figure 1-22](#fig_01-23)
    suggests that approach should work for this function as well.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: 'The first derivative is the most straightforward and thus makes the best warm-up.
    We want to know how much *L* (the output of *Λ*) will increase if each element
    of *S* increases. Since *L* is the sum of all the elements of *S*, this derivative
    is simply:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></math>
- en: since increasing any element of *S* by, say, 0.46 units would increase *Λ* by
    0.46 units.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we have <math><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow></mrow></math> . This is simply the
    derivative of whatever function *σ* is, evaluated at the elements in *N*. In the
    "*XW*" syntax we’ve used previously, this is again simple to compute:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></math>
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></math>
- en: 'Note that at this point we can say for certain that we can multiply these two
    derivatives together *elementwise* and compute <math><mrow><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow></mrow></math>
    :'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced> <mo>×</mo>
    <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>1</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced> <mo>×</mo>
    <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>1</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: Now, however, we are stuck. The next thing we want, based on the diagram and
    applying the chain rule, is <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow></mrow></math>
    . Recall, however, that *N*, the output of *ν*, was just the result of a matrix
    multiplication of *X* with *W*. Thus we want some notion of how much increasing
    each element of *X* (a 3 × 3 matrix) will increase each element of *N* (a 3 ×
    2 matrix). If you’re having trouble wrapping your mind around such a notion, that’s
    the point—it isn’t clear at all how we’d define this, or whether it would even
    be useful if we did.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Why is this a problem now? Before, we were in the fortunate situation of *X*
    and *W* being transposes of each other in terms of shape. That being the case,
    we could show that <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
    and <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup></mrow></math>
    . Is there something analogous we can say here?
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: The “?”
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'More specifically, here’s where we’re stuck. We need to figure out what goes
    in the “?”:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>N</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mo>?</mo> <mo>=</mo>
    <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced> <mo>×</mo>
    <mo>?</mo></mrow></math>
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>N</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mo>?</mo> <mo>=</mo>
    <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced> <mo>×</mo>
    <mo>?</mo></mrow></math>
- en: The answer
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It turns out that because of the way the multiplication works out, what fills
    the “?” is simply *W*^(*T*), as in the simpler example with the vector dot product
    that we just saw! The way to verify this is to compute the partial derivative
    of *L* with respect to each element of *X* directly; when we do so,^([4](ch01.html#idm45732627740296))
    the resulting matrix does indeed (remarkably) factor out into:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>×</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>×</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
- en: where the first multiplication is elementwise, and the second one is a matrix
    multiplication.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: This means that *even if the operations in our computational graph involve multiplying
    matrices with multiple rows and columns, and even if the shapes of the outputs
    of those operations are different than those of the inputs, we can still include
    these operations in our computational graph and backpropagate through them using
    “chain rule” logic*. This is a critical result, without which training deep learning
    models would be much more cumbersome, as you’ll appreciate further after the next
    chapter.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-358
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s encapsulate what we just derived using code, and hopefully solidify our
    understanding in the process:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now let’s verify that everything worked:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As in the previous example, since `dLdX` represents the gradient of *X* with
    respect to *L*, this means that, for instance, the top-left element indicates
    that <math><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>11</mn></msub></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mn>0.2489</mn></mrow></math> . Thus, if the matrix
    math for this example was correct, then increasing *x*[11] by 0.001 should increase
    *L* by `0.01 × 0.2489`. Indeed, we see that this is what happens:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Looks like the gradients were computed correctly!
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: Describing these gradients visually
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To bring this back to what we noted at the beginning of the chapter, we fed
    the element in question, *x*[11], through a function with many operations: there
    was a matrix multiplication—which was really shorthand for combining the nine
    inputs in the matrix *X* with the six inputs in the matrix *W* to create six outputs—the
    `sigmoid` function, and then the sum. Nevertheless, we can also think of this
    as a single function called, say, " <math><mrow><mi>W</mi> <mi>N</mi> <mi>S</mi>
    <mi>L</mi></mrow></math> , “as depicted in [Figure 1-23](#fig_01-24).'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0123](assets/dlfs_0123.png)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-23\. Another way of describing the nested function: as one function,
    “WNSL”'
  id: totrans-371
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Since each function is differentiable, the whole thing is just a single differentiable
    function, with *x*[11] as an input; thus, the gradient is simply the answer to
    the question, what is <math><mfrac><mrow><mi>d</mi><mi>L</mi></mrow> <mrow><mi>d</mi><msub><mi>x</mi>
    <mn>11</mn></msub></mrow></mfrac></math> ? To visualize this, we can simply plot
    how *L* changes as *x*[11] changes. Looking at the initial value of *x*[11], we
    see that it is `-1.5775`:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: If we plot the value of *L* that results from feeding *X* and *W* into the computational
    graph defined previously—or, to represent it differently, from feeding `X` and
    `W` into the function called in the preceding code—changing nothing except the
    value for *x*[11] (or `X[0, 0]`), the resulting plot looks like [Figure 1-24](#x11_vs_L_function_matrix_backward).^([5](ch01.html#idm45732627323432))
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0124](assets/dlfs_0124.png)'
  id: totrans-376
  prefs: []
  type: TYPE_IMG
- en: Figure 1-24\. L versus *x*[11], holding other values of X and W constant
  id: totrans-377
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Indeed, eyeballing this relationship in the case of *x*[11], it looks like the
    distance this function increases along the *L*-axis is roughly 0.5 (from just
    over 2.1 to just over 2.6), and we know that we are showing a change of 2 along
    the *x*[11]-axis, which would make the slope roughly <math><mrow><mfrac><mrow><mn>0.5</mn></mrow>
    <mn>2</mn></mfrac> <mo>=</mo> <mn>0.25</mn></mrow></math> —which is exactly what
    we just calculated!
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: So our complicated matrix math does in fact seem to have resulted in us correctly
    computing the partial derivative *L* with respect to each element of *X*. Furthermore,
    the gradient of *L* with respect to *W* could be computed similarly.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-380
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The expression for the gradient of *L* with respect to *W* would be *X*^(*T*).
    However, because of the order in which the *X*^(*T*) expression factors out of
    the derivative for *L*, *X*^(*T*) would be on the *left* side of the expression
    for the gradient of *L* with respect to *W*:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow></mrow></math>
- en: 'In code, therefore, while we would have `dNdW = np.transpose(X, (1, 0))`, the
    next step would be:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: instead of `dLdX = np.dot(dSdN, dNdX)` as before.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After this chapter, you should have confidence that you can understand complicated
    nested mathematical functions and reason out how they work by conceptualizing
    them as a series of boxes, each one representing a single constituent function,
    connected by strings. Specifically, you can write code to compute the derivatives
    of the outputs of such functions with respect to any of the inputs, even when
    there are matrix multiplications involving two-dimensional `ndarray`s involved,
    and understand the math behind *why* these derivative computations are correct.
    These foundational concepts are exactly what we’ll need to start building and
    training neural networks in the next chapter, and to build and train deep learning
    models from scratch in the chapters after that. Onward!
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch01.html#idm45732632700344-marker)) This will allow us to easily add
    a bias to our matrix multiplication later on.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch01.html#idm45732630322664-marker)) Throughout I’ll provide links to
    relevant supplementary material on a GitHub repo that contains the code for the
    book, including for [this chapter](https://oreil.ly/2ZUwKOZ).
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch01.html#idm45732628068456-marker)) In the following section we’ll focus
    on computing the gradient of `N` with respect to `X`, but the gradient with respect
    to `W` could be reasoned through similarly.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch01.html#idm45732627740296-marker)) We do this in [“Matrix Chain Rule”](app01.html#matrix-chain-rule).
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch01.html#idm45732627323432-marker)) The full function can be found on
    [the book’s website](https://oreil.ly/deep-learning-github); it is simply a subset
    of the `matrix function backward sum` function shown on the previous page.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
