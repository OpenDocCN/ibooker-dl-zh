- en: Chapter 1\. Foundations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。基础
- en: Don’t memorize these formulas. If you understand the concepts, you can invent
    your own notation.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不要死记这些公式。如果你理解了概念，你可以发明自己的符号。
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: John Cochrane, [*Investments Notes*](https://oreil.ly/33CVXjg) 2006
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 约翰·科克兰，《投资笔记》2006
- en: The aim of this chapter is to explain some foundational mental models that are
    essential for understanding how neural networks work. Specifically, we’ll cover
    *nested mathematical functions and their derivatives*. We’ll work our way up from
    the simplest possible building blocks to show that we can build complicated functions
    made up of a “chain” of constituent functions and, even when one of these functions
    is a matrix multiplication that takes in multiple inputs, compute the derivative
    of the functions’ outputs with respect to their inputs. Understanding how this
    process works will be essential to understanding neural networks, which we technically
    won’t begin to cover until [Chapter 2](ch02.html#fundamentals).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是解释一些对理解神经网络工作至关重要的基础心智模型。具体来说，我们将涵盖*嵌套数学函数及其导数*。我们将从最简单的基本构建块开始，逐步展示我们可以构建由“链”组成的复杂函数，即使其中一个函数是接受多个输入的矩阵乘法，也可以计算函数输出相对于输入的导数。理解这个过程如何运作将是理解神经网络的关键，而我们实际上直到[第2章](ch02.html#fundamentals)才会开始涵盖神经网络。
- en: 'As we’re getting our bearings around these foundational building blocks of
    neural networks, we’ll systematically describe each concept we introduce from
    three perspectives:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们围绕神经网络的这些基础构建块来找到方向时，我们将系统地从三个视角描述我们引入的每个概念：
- en: Math, in the form of an equation or equations
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数学，以方程或方程组的形式
- en: Code, with as little extra syntax as possible (making Python an ideal choice)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码，尽可能少的额外语法（使Python成为理想选择）
- en: A diagram explaining what is going on, of the kind you would draw on a whiteboard
    during a coding interview
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个解释正在发生的事情的图表，就像你在编程面试中在白板上画的那种
- en: 'As mentioned in the preface, one of the challenges of understanding neural
    networks is that it requires multiple mental models. We’ll get a sense of that
    in this chapter: each of these three perspectives excludes certain essential features
    of the concepts we’ll cover, and only when taken together do they provide a full
    picture of both how and why nested mathematical functions work the way they do.
    In fact, I take the uniquely strong view that any attempt to explain the building
    blocks of neural networks that excludes one of these three perspectives is incomplete.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前言中提到的，理解神经网络的一个挑战是需要多种心智模型。在本章中，我们将感受到这一点：这三种视角中的每一种都排除了我们将要涵盖的概念的某些基本特征，只有当它们一起被考虑时，才能提供关于嵌套数学函数工作方式的完整图景。事实上，我坚定地认为，任何试图解释神经网络构建块的尝试，如果排除了这三种视角中的任何一种，都是不完整的。
- en: 'With that out of the way, it’s time to take our first steps. We’re going to
    start with some extremely simple building blocks to illustrate how we can understand
    different concepts in terms of these three perspectives. Our first building block
    will be a simple but critical concept: the function.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们要迈出第一步了。我们将从一些极其简单的基本构建块开始，以说明我们如何可以从这三个视角理解不同的概念。我们的第一个基本构建块将是一个简单但至关重要的概念：函数。
- en: Functions
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数
- en: What is a function, and how do we describe it? As with neural nets, there are
    several ways to describe functions, none of which individually paints a complete
    picture. Rather than trying to give a pithy one-sentence description, let’s simply
    walk through the three mental models one by one, playing the role of the blind
    men feeling different parts of the elephant.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是函数，我们如何描述它？与神经网络一样，有几种方法来描述函数，其中没有一种能够完整地描绘出整个图景。与其试图给出一个简洁的一句话描述，不如我们简单地逐个走过这三种心智模型，扮演感受大象不同部分的盲人的角色。
- en: Math
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'Here are two examples of functions, described in mathematical notation:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个函数的例子，用数学符号描述：
- en: '*f*[1](*x*) = *x*²'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f*[1](*x*) = *x*²'
- en: '*f*[2](*x*) = *max*(*x*, 0)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f*[2](*x*) = *max*(*x*, 0)'
- en: This notation says that the functions, which we arbitrarily call *f*[1] and
    *f*[2], take in a number *x* as input and transform it into either *x*² (in the
    first case) or *max*(*x*, 0) (in the second case).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个符号表示函数，我们任意地称为*f*[1]和*f*[2]，将一个数字*x*作为输入，并将其转换为*x*²（在第一种情况下）或*max*(*x*, 0)（在第二种情况下）。
- en: Diagrams
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: 'One way of depicting functions is to:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 描述函数的一种方式是：
- en: Draw an *x-y* plane (where *x* refers to the horizontal axis and *y* refers
    to the vertical axis).
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 画一个*x-y*平面（其中*x*指水平轴，*y*指垂直轴）。
- en: Plot a bunch of points, where the x-coordinates of the points are (usually evenly
    spaced) inputs of the function over some range, and the y-coordinates are the
    outputs of the function over that range.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制一堆点，其中点的x坐标是函数在某个范围内的（通常是均匀间隔的）输入，y坐标是该范围内函数的输出。
- en: Connect these plotted points.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接这些绘制的点。
- en: This was first done by the French philosopher René Descartes, and it is extremely
    useful in many areas of mathematics, in particular calculus. [Figure 1-1](#fig_01-01)
    shows the plot of these two functions.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这最初是由法国哲学家勒内·笛卡尔完成的，它在许多数学领域中非常有用，特别是微积分。[图1-1](#fig_01-01)显示了这两个函数的图表。
- en: '![Two continuous, mostly differentiable functions](assets/dlfs_0101.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![两个连续的、大部分可微的函数](assets/dlfs_0101.png)'
- en: Figure 1-1\. Two continuous, mostly differentiable functions
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1。两个连续的、大部分可微的函数
- en: However, there is another way to depict functions that isn’t as useful when
    learning calculus but that will be very useful for us when thinking about deep
    learning models. We can think of functions as boxes that take in numbers as input
    and produce numbers as output, like minifactories that have their own internal
    rules for what happens to the input. [Figure 1-2](#fig_01-02) shows both these
    functions described as general rules and how they operate on specific inputs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还有另一种描述函数的方式，在学习微积分时并不那么有用，但在思考深度学习模型时将非常有用。我们可以将函数看作是接受数字输入并产生数字输出的盒子，就像具有其自身内部规则的小工厂，用于处理输入。[图1-2](#fig_01-02)展示了这两个函数被描述为通用规则以及它们如何在特定输入上运行。
- en: '![Another way of looking at functions](assets/dlfs_0102.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![另一种看待函数的方式](assets/dlfs_0102.png)'
- en: Figure 1-2\. Another way of looking at these functions
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2. 另一种看待这些函数的方式
- en: Code
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Finally, we can describe these functions using code. Before we do, we should
    say a bit about the Python library on top of which we’ll be writing our functions:
    NumPy.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用代码描述这些函数。在此之前，我们应该简要介绍一下我们将在其上编写函数的Python库：NumPy。
- en: 'Code caveat #1: NumPy'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码注意事项＃1：NumPy
- en: 'NumPy is a widely used Python library for fast numeric computation, the internals
    of which are mostly written in C. Simply put: the data we deal with in neural
    networks will always be held in a *multidimensional array* that is almost always
    either one-, two-, three-, or four-dimensional, but especially two- or three-dimensional.
    The `ndarray` class from the NumPy library allows us to operate on these arrays
    in ways that are both (a) intuitive and (b) fast. To take the simplest possible
    example: if we were storing our data in Python lists (or lists of lists), adding
    or multiplying the lists elementwise using normal syntax wouldn’t work, whereas
    it does work for `ndarray`s:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy是一个广泛使用的Python库，用于快速数值计算，其内部大部分是用C编写的。简而言之：我们在神经网络中处理的数据将始终保存在一个几乎总是一维、二维、三维或四维的*多维数组*中，尤其是二维或三维。来自NumPy库的`ndarray`类允许我们以既直观又快速的方式操作这些数组。举个最简单的例子：如果我们将数据存储在Python列表（或列表的列表）中，使用正常语法逐元素添加或乘以列表是行不通的，而对于`ndarray`却是行得通的：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`ndarray`s also have several features you’d expect from an `n`-dimensional
    array; each `ndarray` has `n` axes, indexed from 0, so that the first axis is
    `0`, the second is `1`, and so on. In particular, since we deal with 2D `ndarray`s
    often, we can think of `axis = 0` as the rows and `axis = 1` as the columns—see
    [Figure 1-3](#fig_01-03).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`ndarray`还具有您从`n`维数组中期望的几个特性；每个`ndarray`都有`n`个轴，从0开始索引，因此第一个轴是`0`，第二个是`1`，依此类推。特别是，由于我们经常处理2D
    `ndarray`，我们可以将`axis = 0`看作行，`axis = 1`看作列——参见[图1-3](#fig_01-03)。'
- en: '![Simple NumPy array example](assets/dlfs_0103.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![简单的NumPy数组示例](assets/dlfs_0103.png)'
- en: Figure 1-3\. A 2D NumPy array, with axis = 0 as the rows and axis = 1 as the
    columns
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3. 一个2D NumPy数组，其中axis = 0表示行，axis = 1表示列
- en: 'NumPy’s `ndarray`s also support applying functions along these axes in intuitive
    ways. For example, summing along axis 0 (the *rows* for a 2D array) essentially
    “collapses the array” along that axis, returning an array with one less dimension
    than the original array; for a 2D array, this is equivalent to summing each column:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy的`ndarray`还支持沿着这些轴以直观方式应用函数。例如，沿着轴0（2D数组的*行*）求和基本上会沿着该轴“折叠数组”，返回一个比原始数组少一个维度的数组；对于2D数组，这相当于对每列求和：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Finally, NumPy `ndarray`s support adding a 1D array to the last axis; for a
    2D array `a` with `R` rows and `C` columns, this means we can add a 1D array `b`
    of length `C` and NumPy will do the addition in the intuitive way, adding the
    elements to each row of `a`:^([1](ch01.html#idm45732632700344))
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，NumPy的`ndarray`支持将1D数组添加到最后一个轴；对于具有`R`行和`C`列的2D数组`a`，这意味着我们可以添加长度为`C`的1D数组`b`，NumPy将以直观的方式进行加法运算，将元素添加到`a`的每一行：^([1](ch01.html#idm45732632700344))
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Code caveat #2: Type-checked functions'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码注意事项＃2：类型检查的函数
- en: 'As I’ve mentioned, the primary goal of the code we write in this book is to
    make the concepts I’m explaining precise and clear. This will get more challenging
    as the book goes on, as we’ll be writing functions with many arguments as part
    of complicated classes. To combat this, we’ll use functions with type signatures
    throughout; for example, in [Chapter 3](ch03.html#deep_learning_from_scratch),
    we’ll initialize our neural networks as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我提到的，我们在本书中编写的代码的主要目标是使我解释的概念变得精确和清晰。随着书的进行，这将变得更具挑战性，因为我们将编写具有许多参数的函数作为复杂类的一部分。为了应对这一挑战，我们将在整个过程中使用带有类型签名的函数；例如，在[第3章](ch03.html#deep_learning_from_scratch)中，我们将初始化我们的神经网络如下：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This type signature alone gives you some idea of what the class is used for.
    By contrast, consider the following type signature that we *could* use to define
    an operation:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 仅凭这个类型签名，您就可以对该类的用途有一些了解。相比之下，考虑以下类型签名，我们*可以*用来定义一个操作：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This type signature by itself gives you no hint as to what is going on; only
    by printing out each object’s type, seeing what operations get performed on each
    object, or guessing based on the names `x1` and `x2` could we understand what
    is going on in this function. I can instead define a function with a type signature
    as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 仅凭这个类型签名，您无法了解正在发生什么；只有通过打印出每个对象的类型，查看在每个对象上执行的操作，或根据名称`x1`和`x2`猜测，我们才能理解这个函数中正在发生的事情。相反，我可以定义一个带有以下类型签名的函数：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You know right away that this is a function that takes in two `ndarray`s, probably
    combines them in some way, and outputs the result of that combination. Because
    of the increased clarity they provide, we’ll use type-checked functions throughout
    this book.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您立即知道这是一个接受两个`ndarray`的函数，可能以某种方式将它们组合在一起，并输出该组合的结果。由于它们提供的更清晰性，我们将在本书中始终使用带有类型检查的函数。
- en: Basic functions in NumPy
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NumPy中的基本函数
- en: 'With these preliminaries in mind, let’s write up the functions we defined earlier
    in NumPy:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了这些基础知识之后，让我们在NumPy中编写我们之前定义的函数：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'One of NumPy’s quirks is that many functions can be applied to `ndarray`s either
    by writing `np.*function_name*(ndarray)` or by writing `ndarray.*function_name*`.
    For example, the preceding `relu` function could be written as: `x.clip(min=0)`.
    We’ll try to be consistent and use the `np.*function_name*(ndarray)` convention
    throughout—in particular, we’ll avoid tricks such as `*ndarray*.T` for transposing
    a two-dimensional `ndarray`, instead writing `np.transpose(*ndarray*, (1, 0))`.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy的一个特点是许多函数可以通过写`np.*function_name*(ndarray)`或写`ndarray.*function_name*`来应用于`ndarray`。例如，前面的`relu`函数可以写成：`x.clip(min=0)`。我们将尽量保持一致，使用`np.*function_name*(ndarray)`的约定——特别是，我们将避免诸如`*ndarray*.T`用于转置二维`ndarray`的技巧，而是写成`np.transpose(*ndarray*,
    (1, 0))`。
- en: If you can wrap your mind around the fact that math, a diagram, and code are
    three different ways of representing the same underlying concept, then you are
    well on your way to displaying the kind of flexible thinking you’ll need to truly
    understand deep learning.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你能理解数学、图表和代码是表示同一基本概念的三种不同方式，那么你就已经在正确理解深度学习所需的灵活思维方面迈出了重要一步。
- en: Derivatives
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导数
- en: Derivatives, like functions, are an extremely important concept for understanding
    deep learning that many of you are probably familiar with. Also like functions,
    they can be depicted in multiple ways. We’ll start by simply saying at a high
    level that the derivative of a function at a point is the “rate of change” of
    the output of the function with respect to its input at that point. Let’s now
    walk through the same three perspectives on derivatives that we covered for functions
    to gain a better mental model for how derivatives work.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 导数，就像函数一样，是理解深度学习的一个非常重要的概念，你们中的许多人可能已经熟悉了。和函数一样，它们可以用多种方式表示。我们首先简单地说一下，函数在某一点的导数是函数输出相对于该点的输入的“变化率”。现在让我们通过相同的三个导数视角来更好地理解导数的工作原理。
- en: Math
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'First, we’ll get mathematically precise: we can describe this number—how much
    the output of *f* changes as we change its input at a particular value *a* of
    the input—as a limit:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将数学上精确描述：我们可以将这个数字描述为一个极限，即在特定值*a*的输入处改变其输入时，*f*的输出会发生多少变化：
- en: <math display="block"><mrow><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>=</mo> <munder><mo form="prefix"
    movablelimits="true">lim</mo> <mrow><mi>Δ</mi><mo>→</mo><mn>0</mn></mrow></munder>
    <mfrac><mrow><mi>f</mi><mfenced close=")" open="(" separators=""><mrow><mi>a</mi><mo>+</mo><mi>Δ</mi></mrow></mfenced><mo>-</mo><mi>f</mi><mfenced
    close=")" open="(" separators=""><mi>a</mi><mo>-</mo><mi>Δ</mi></mfenced></mrow>
    <mrow><mn>2</mn><mo>×</mo><mi>Δ</mi></mrow></mfrac></mrow></math>
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>=</mo> <munder><mo form="prefix"
    movablelimits="true">lim</mo> <mrow><mi>Δ</mi><mo>→</mo><mn>0</mn></mrow></munder>
    <mfrac><mrow><mi>f</mi><mfenced close=")" open="(" separators=""><mrow><mi>a</mi><mo>+</mo><mi>Δ</mi></mrow></mfenced><mo>-</mo><mi>f</mi><mfenced
    close=")" open="(" separators=""><mi>a</mi><mo>-</mo><mi>Δ</mi></mfenced></mrow>
    <mrow><mn>2</mn><mo>×</mo><mi>Δ</mi></mrow></mfrac></mrow></math>
- en: 'This limit can be approximated numerically by setting a very small value for
    *Δ*, such as 0.001, so we can compute the derivative as:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这个极限可以通过设置一个非常小的*Δ*值（例如0.001）来进行数值近似，因此我们可以计算导数为：
- en: <math display="block"><mrow><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>f</mi><mo>(</mo><mi>a</mi><mo>+</mo><mn>0.001</mn><mo>)</mo><mo>-</mo><mi>f</mi><mo>(</mo><mi>a</mi><mo>-</mo><mn>0.001</mn><mo>)</mo></mrow>
    <mrow><mn>0.002</mn></mrow></mfrac></mrow></math>
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>a</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>f</mi><mo>(</mo><mi>a</mi><mo>+</mo><mn>0.001</mn><mo>)</mo><mo>-</mo><mi>f</mi><mo>(</mo><mi>a</mi><mo>-</mo><mn>0.001</mn><mo>)</mo></mrow>
    <mrow><mn>0.002</mn></mrow></mfrac></mrow></math>
- en: 'While accurate, this is only one part of a full mental model of derivatives.
    Let’s look at them from another perspective: a diagram.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然准确，但这只是导数完整心智模型的一部分。让我们从另一个角度来看待它们：一个图表。
- en: Diagrams
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: 'First, the familiar way: if we simply draw a tangent line to the Cartesian
    representation of the function *f*, the derivative of *f* at a point *a* is just
    the slope of this line at *a*. As with the mathematical descriptions in the prior
    subsection, there are two ways we can actually calculate the slope of this line.
    The first would be to use calculus to actually calculate the limit. The second
    would be to just take the slope of the line connecting *f* at *a* – 0.001 and
    *a* + 0.001\. The latter method is depicted in [Figure 1-4](#fig_01-04) and should
    be familiar to anyone who has taken calculus.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，熟悉的方式：如果我们简单地在函数*f*的笛卡尔表示上画一条切线，*f*在点*a*的导数就是这条线在*a*点的斜率。与前一小节中的数学描述一样，我们实际上可以计算这条线的斜率的两种方法。第一种是使用微积分来计算极限。第二种是只需取连接*f*在*a*
    - 0.001和*a* + 0.001的线的斜率。后一种方法在[图1-4](#fig_01-04)中有所描述，对于学过微积分的人应该很熟悉。
- en: '![dlfs 0104](assets/dlfs_0104.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0104](assets/dlfs_0104.png)'
- en: Figure 1-4\. Derivatives as slopes
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. 导数作为斜率
- en: 'As we saw in the prior section, another way of thinking of functions is as
    mini-factories. Now think of the inputs to those factories being connected to
    the outputs by a string. The derivative is equal to the answer to this question:
    if we pull up on the input to the function *a* by some very small amount—or, to
    account for the fact that the function may be asymmetric at *a*, pull down on
    *a* by some small amount—by what multiple of this small amount will the output
    change, given the inner workings of the factory? This is depicted in [Figure 1-5](#fig_01-05).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一节中看到的，另一种思考函数的方式是将其视为小工厂。现在想象一下，这些工厂的输入通过一根绳子连接到输出。导数等于这个问题的答案：如果我们向上拉动函数的输入*a*一点点，或者为了考虑到函数在*a*可能是不对称的情况，向下拉动*a*一点点，根据工厂的内部运作，输出将以这个小量的多少倍改变？这在[图1-5](#fig_01-05)中有所描述。
- en: '![dlfs 0105](assets/dlfs_0105.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0105](assets/dlfs_0105.png)'
- en: Figure 1-5\. Another way of visualizing derivatives
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5\. 另一种可视化导数的方式
- en: This second representation will turn out to be more important than the first
    one for understanding deep learning.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这第二种表示将比第一种更重要，以理解深度学习。
- en: Code
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Finally, we can code up the approximation to the derivative that we saw previously:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以编写我们之前看到的导数近似的代码：
- en: '[PRE10]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'When we say that “something is a function of something else”—for example, that
    *P* is a function of *E* (letters chosen randomly on purpose), what we mean is
    that there is some function *f* such that *f*(*E*) = *P*—or equivalently, there
    is a function *f* that takes in *E* objects and produces *P* objects. We might
    also think of this as meaning that *P* *is defined as* whatever results when we
    apply the function *f* to *E*:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们说“某物是另一物的函数”时——例如，*P*是*E*的函数（故意随机选择的字母），我们的意思是存在某个函数*f*，使得*f*(*E*) = *P*——或者等价地，存在一个函数*f*，接受*E*对象并产生*P*对象。我们也可以将其理解为*P*“被定义为”将函数*f*应用于*E*时产生的结果：
- en: '![Another way of visualizing functions](assets/dlfs_01in01.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![另一种可视化函数的方式](assets/dlfs_01in01.png)'
- en: 'And we would code this up as:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将其编码为：
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Nested Functions
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌套函数
- en: 'Now we’ll cover a concept that will turn out to be fundamental to understanding
    neural networks: functions can be “nested” to form “composite” functions. What
    exactly do I mean by “nested”? I mean that if we have two functions that by mathematical
    convention we call *f*[1] and *f*[2], the output of one of the functions becomes
    the input to the next one, so that we can “string them together.”'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most natural way to represent a nested function is with the “minifactory”
    or “box” representation (the second representation from [“Functions”](#functions-section-01)).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: As [Figure 1-6](#fig_01-07) shows, an input goes into the first function, gets
    transformed, and comes out; then it goes into the second function and gets transformed
    again, and we get our final output.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '![f1 and f2 as a chain](assets/dlfs_0106.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: Figure 1-6\. Nested functions, naturally
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Math
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We should also include the less intuitive mathematical representation:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: <math><mrow><msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi>
    <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>=</mo> <mi>y</mi></mrow></math>
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: This is less intuitive because of the quirk that nested functions are read “from
    the outside in” but the operations are in fact performed “from the inside out.”
    For example, though <math><mrow><msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mi>y</mi></mrow></math> is read “f 2 of f 1 of x,”
    what it really means is to “first apply *f*[1] to *x*, and then apply *f*[2] to
    the result of applying *f*[1] to *x*.”
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, in keeping with my promise to explain every concept from three perspectives,
    we’ll code this up. First, we’ll define a data type for nested functions:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then we’ll define how data goes through a chain, first of length 2:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Another Diagram
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depicting the nested function using the box representation shows us that this
    composite function is really just a single function. Thus, we can represent this
    function as simply *f*[1] *f*[2], as shown in [Figure 1-7](#fig_01-08).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![f1f2 nested](assets/dlfs_0107.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: Figure 1-7\. Another way to think of nested functions
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Moreover, a theorem from calculus tells us that a composite function made up
    of “mostly differentiable” functions is itself mostly differentiable! Thus, we
    can think of *f*[1]*f*[2] as just another function that we can compute derivatives
    of—and computing derivatives of composite functions will turn out to be essential
    for training deep learning models.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: However, we need a formula to be able to compute this composite function’s derivative
    in terms of the derivatives of its constituent functions. That’s what we’ll cover
    next.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: The Chain Rule
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The chain rule is a mathematical theorem that lets us compute derivatives of
    composite functions. Deep learning models are, mathematically, composite functions,
    and reasoning about their derivatives is essential to training them, as we’ll
    see in the next couple of chapters.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Math
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mathematically, the theorem states—in a rather nonintuitive form—that, for a
    given value `x`,
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>
- en: where *u* is simply a dummy variable representing the input to a function.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When describing the derivative of a function *f* with one input and output,
    we can denote the *function* that represents the derivative of this function as
    <math><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac></math>
    . We could use a different dummy variable in place of *u*—it doesn’t matter, just
    as *f*(*x*) = *x*² and *f*(*y*) = *y*² mean the same thing.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, later on we’ll deal with functions that take in *multiple*
    inputs, say, both *x* and *y*. Once we get there, it will make sense to write
    <math><mfrac><mrow><mi>d</mi><mi>f</mi></mrow> <mrow><mi>d</mi><mi>x</mi></mrow></mfrac></math>
    and have it mean something different than <math><mfrac><mrow><mi>d</mi><mi>f</mi></mrow>
    <mrow><mi>d</mi><mi>y</mi></mrow></mfrac></math> .
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，稍后我们将处理接受*多个*输入的函数，比如，*x*和*y*。一旦到达那里，编写<math><mfrac><mrow><mi>d</mi><mi>f</mi></mrow>
    <mrow><mi>d</mi><mi>x</mi></mrow></mfrac></math>并且让它意味着与<math><mfrac><mrow><mi>d</mi><mi>f</mi></mrow>
    <mrow><mi>d</mi><mi>y</mi></mrow></mfrac></math>不同的东西就会有意义。
- en: 'This is why in the preceding formula we denote *all* the derivatives with a
    *u* on the bottom: both *f*[1] and *f*[2] are functions that take in one input
    and produce one output, and in such cases (of functions with one input and one
    output) we’ll use *u* in the derivative notation.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么在前面的公式中，我们用底部的*u*表示*所有*的导数：*f*[1]和*f*[2]都是接受一个输入并产生一个输出的函数，在这种情况下（具有一个输入和一个输出的函数），我们将在导数符号中使用*u*。
- en: Diagram
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图表
- en: The preceding formula does not give much intuition into the chain rule. For
    that, the box representation is much more helpful. Let’s reason through what the
    derivative “should” be in the simple case of *f*[1] *f*[2].
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的公式并没有给出链式法则的太多直觉。对于这一点，框表示法更有帮助。让我们推理一下在简单情况下*f*[1] *f*[2]的导数“应该”是什么。
- en: '![f1f2 nested](assets/dlfs_0108.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![f1f2 nested](assets/dlfs_0108.png)'
- en: Figure 1-8\. An illustration of the chain rule
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8。链式法则的示例
- en: Intuitively, using the diagram in [Figure 1-8](#fig_01-09), the derivative of
    the composite function *should* be a sort of product of the derivatives of its
    constituent functions. Let’s say we feed the value 5 into the first function,
    and let’s say further that computing the *derivative* of the first function at
    *u* = 5 gives us a value of 3—that is, <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mn>5</mn> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math> .
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 直觉上，使用[图1-8](#fig_01-09)中的图表，复合函数的导数*应该*是其组成函数的导数的一种乘积。假设我们将值5输入到第一个函数中，再假设在*u*=5处计算第一个函数的*导数*得到一个值为3，即，<math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mn>5</mn> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math>。
- en: 'Let’s say that we then take the *value* of the function that comes out of the
    first box—let’s suppose it is 1, so that *f*[1](5) = 1—and compute the derivative
    of the second function *f*[2] at this value: that is, <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mn>1</mn> <mo>)</mo></mrow></mrow></math> . We find that this value is –2.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们然后取出第一个框中的函数的*值*，假设它是1，所以*f*[1](5) = 1，并计算在这个值处第二个函数*f*[2]的导数：即，<math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mn>1</mn> <mo>)</mo></mrow></mrow></math>。我们发现这个值是-2。
- en: 'If we think about these functions as being literally strung together, then
    if changing the input to box two by 1 unit yields a change of –2 units in the
    output of box two, changing the input to box two by 3 units should change the
    output to box two by –2 × 3 = –6 units. This is why in the formula for the chain
    rule, the final result is ultimately a product: <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow></mrow></math> *times* <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math> .'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这些函数想象成字面上串在一起，那么如果将第二个框的输入改变1个单位会导致第二个框的输出变化-2个单位，那么将第二个框的输入改变3个单位应该会导致第二个框的输出变化-2×3
    = -6个单位。这就是为什么在链式法则的公式中，最终结果最终是一个乘积：<math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow></mrow></math> *乘以* <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>。
- en: So by considering the diagram and the math, we can reason through what the derivative
    of the output of a nested function with respect to its input ought to be, using
    the chain rule. What might the code instructions for the computation of this derivative
    look like?
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，通过考虑图表和数学，我们可以通过链式法则推理出嵌套函数输出的导数与其输入应该是什么，代码指令可能是什么样的？
- en: Code
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Let’s code this up and show that computing derivatives in this way does in
    fact yield results that “look correct.” We’ll use the `square` function from [“Basic
    functions in NumPy”](#basic-NumPy) along with `sigmoid`, another function that
    ends up being important in deep learning:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写代码并展示以这种方式计算导数实际上会产生“看起来正确”的结果。我们将使用来自[“NumPy中的基本函数”](#basic-NumPy)的`square`函数，以及`sigmoid`，另一个在深度学习中变得重要的函数：
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'And now we code up the chain rule:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们编写链式法则的代码：
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[Figure 1-9](#fig_01-10) plots the results and shows that the chain rule works:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-9](#fig_01-10)绘制了结果，并显示链式法则有效：'
- en: '[PRE16]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Chain rule illustration](assets/dlfs_0109.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![链式法则示例](assets/dlfs_0109.png)'
- en: Figure 1-9\. The chain rule works, part 1
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-9。链式法则有效，第1部分
- en: The chain rule seems to be working. When the functions are upward-sloping, the
    derivative is positive; when they are flat, the derivative is zero; and when they
    are downward-sloping, the derivative is negative.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 链式法则似乎有效。当函数是向上倾斜时，导数是正的；当函数是平的时，导数是零；当函数是向下倾斜时，导数是负的。
- en: So we can in fact compute, both mathematically and via code, the derivatives
    of nested or “composite” functions such as *f*[1] *f*[2], as long as the individual
    functions are themselves mostly differentiable.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们实际上可以计算嵌套或“复合”函数的导数，如*f*[1] *f*[2]，只要这些单独的函数本身大部分是可微的。
- en: It will turn out that deep learning models are, mathematically, long chains
    of these mostly differentiable functions; spending time going manually through
    a slightly longer example in detail will help build your intuition about what
    is going on and how it can generalize to more complex models.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，深度学习模型在数学上是这些大部分可微函数的长链；花时间详细地手动通过一个稍微更长的例子将有助于建立您对正在发生的事情以及如何将其推广到更复杂模型的直觉。
- en: A Slightly Longer Example
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稍微长一点的例子
- en: 'Let’s closely examine a slightly longer chain: if we have three mostly differentiable
    functions—*f*[1], *f*[2], and *f*[3]—how would we go about computing the derivative
    of *f*[1] *f*[2] *f*[3]? We “should” be able to do it, since from the calculus
    theorem mentioned previously, we know that the composite of *any* finite number
    of “mostly differentiable” functions is differentiable.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细研究一个稍微更长的链条：如果我们有三个大部分可微的函数—*f*[1]、*f*[2]和*f*[3]—我们将如何计算*f*[1] *f*[2] *f*[3]的导数？我们“应该”能够做到，因为根据之前提到的微积分定理，我们知道“大部分可微”函数的复合是可微的。
- en: Math
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'Mathematically, the result turns out to be the following expression:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 数学上，结果是以下表达式：
- en: <math display="block"><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>3</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>3</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi>
    <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>3</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>3</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi>
    <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
- en: The underlying logic as to why the formula works for chains of length 2, <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>1</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
    , also applies here—as does the lack of intuition from looking at the formula
    alone!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这个公式适用于长度为2的链条的基本逻辑，<math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>=</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math>，在这里也适用——看公式本身缺乏直觉！
- en: Diagram
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: The best way to (literally) see why this formula makes sense is via another
    box diagram, as shown in [Figure 1-10](#fig_01-11).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 要（字面上）看到这个公式为什么是有意义的，最好的方法是通过另一个盒子图表，如[图1-10](#fig_01-11)所示。
- en: '![dlfs 0110](assets/dlfs_0110.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0110](assets/dlfs_0110.png)'
- en: Figure 1-10\. The “box model” for computing the derivative of three nested functions
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10。计算三个嵌套函数导数的“盒子模型”
- en: 'Using similar reasoning to the prior section: if we imagine the input to *f*[1]
    *f*[2] *f*[3] (call it *a*) being connected to the output (call it *b*) by a string,
    then changing *a* by a small amount *Δ* will result in a change in *f*[1](*a*)
    of <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>1</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow></mrow></math> times *Δ*, which will result in a change to <math><mrow><msub><mi>f</mi>
    <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math> (the next step along
    in the chain) of <math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>2</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math> times *Δ*, and so
    on for the third step, when we get to the final change equal to the full formula
    for the preceding chain rule times *Δ*. Spend a bit of time going through this
    explanation and the earlier diagram—but not too much time, since we’ll develop
    even more intuition for this when we code it up.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 使用类似的推理来自前一节：如果我们想象*f*[1] *f*[2] *f*[3]的输入（称为*a*）通过一根绳子连接到输出（称为*b*），那么将*a*改变一个小量*Δ*将导致*f*[1](*a*)的变化为<math><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>1</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mrow></math>乘以*Δ*，这将导致<math><mrow><msub><mi>f</mi>
    <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>（链中的下一步）的变化为<math><mrow><mfrac><mrow><mi>d</mi><msub><mi>f</mi>
    <mn>2</mn></msub></mrow> <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo>
    <msub><mi>f</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>d</mi><msub><mi>f</mi> <mn>1</mn></msub></mrow>
    <mrow><mi>d</mi><mi>u</mi></mrow></mfrac> <mrow><mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow></mrow></math>乘以*Δ*，以此类推到第三步，当我们到达最终变化时，等于前述链式法则的完整公式乘以*Δ*。花一点时间阅读这个解释和之前的图表，但不要花太多时间，因为当我们编写代码时，我们将对此有更多的直觉。
- en: Code
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'How might we translate such a formula into code instructions for computing
    the derivative, given the constituent functions? Interestingly, already in this
    simple example we see the beginnings of what will become the forward and backward
    passes of a neural network:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将这样的公式转化为代码指令，以计算导数，考虑到组成函数？有趣的是，在这个简单的例子中，我们已经看到了神经网络前向和后向传递的开端：
- en: '[PRE17]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Something interesting took place here—to compute the chain rule for this nested
    function, we made two “passes” over it:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生了一些有趣的事情——为了计算这个嵌套函数的链式法则，我们进行了两次“遍历”：
- en: First, we went “forward” through it, computing the quantities `f1_of_x` and
    `f2_of_x` along the way. We can call this (and think of it as) “the forward pass.”
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们“向前走”通过它，沿途计算量`f1_of_x`和`f2_of_x`。我们可以称之为（并将其视为）“前向传递”。
- en: Then, we “went backward” through the function, using the quantities that we
    computed on the forward pass to compute the quantities that make up the derivative.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们“向后走”，使用我们在前向传递中计算的量来计算组成导数的量。
- en: Finally, we multiplied three of these quantities together to get our derivative.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将这三个量相乘以得到我们的导数。
- en: 'Now, let’s show that this works, using the three simple functions we’ve defined
    so far: `sigmoid`, `square`, and `leaky_relu`.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们展示这是如何工作的，使用我们迄今为止定义的三个简单函数：`sigmoid`、`square` 和 `leaky_relu`。
- en: '[PRE18]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[Figure 1-11](#fig_01-12) shows the result.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1-11](#fig_01-12) 显示了结果。'
- en: '![dlfs 0111](assets/dlfs_0111.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0111](assets/dlfs_0111.png)'
- en: Figure 1-11\. The chain rule works, even with triply nested functions
  id: totrans-156
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-11\. 链式法则有效，即使是三重嵌套函数
- en: Again, comparing the plots of the derivatives to the slopes of the original
    functions, we see that the chain rule is indeed computing the derivatives properly.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 再次比较导数的图与原始函数的斜率，我们看到链式法则确实正确计算了导数。
- en: Let’s now apply our understanding to composite functions with multiple inputs,
    a class of functions that follows the same principles we already established and
    is ultimately more applicable to deep learning.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将我们的理解应用于具有多个输入的复合函数，这是一类遵循我们已经建立的相同原则并且最终更适用于深度学习的函数。
- en: Functions with Multiple Inputs
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有多个输入的函数
- en: By this point, we have a conceptual understanding of how functions can be strung
    together to form composite functions. We also have a sense of how to represent
    these functions as series of boxes that inputs go into and outputs come out of.
    Finally, we’ve walked through how to compute the derivatives of these functions
    so that we understand these derivatives both mathematically and as quantities
    computed via a step-by-step process with a “forward” and “backward” component.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们对如何将函数串联起来形成复合函数有了概念上的理解。我们也知道如何将这些函数表示为一系列输入和输出的方框。最后，我们已经了解了如何计算这些函数的导数，以便我们既从数学上又从“前向”和“后向”组件计算的过程中理解这些导数的数量。
- en: 'Oftentimes, the functions we deal with in deep learning don’t have just one
    input. Instead, they have several inputs that at certain steps are added together,
    multiplied, or otherwise combined. As we’ll see, computing the derivatives of
    the outputs of these functions with respect to their inputs is still no problem:
    let’s consider a very simple scenario with multiple inputs, where two inputs are
    added together and then fed through another function.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，我们处理的函数通常不只有一个输入。相反，它们有几个输入，在某些步骤中被相加、相乘或以其他方式组合。正如我们将看到的，计算这些函数的输出对其输入的导数仍然不是问题：让我们考虑一个非常简单的具有多个输入的场景，其中两个输入被相加，然后通过另一个函数进行馈送。
- en: Math
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'For this example, it is actually useful to start by looking at the math. If
    our inputs are *x* and *y*, then we could think of the function as occurring in
    two steps. In Step 1, *x* and *y* are fed through a function that adds them together.
    We’ll denote that function as *α* (we’ll use Greek letters to refer to function
    names throughout) and the output of the function as *a*. Formally, this is simply:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，实际上从数学上看是有用的。如果我们的输入是 *x* 和 *y*，那么我们可以将函数看作是分两步进行的。在第一步中，*x* 和 *y* 被馈送到一个将它们相加的函数中。我们将这个函数表示为
    *α*（我们将使用希腊字母来引用函数名称），函数的输出为 *a*。形式上，这简单地表示为：
- en: <math display="block"><mrow><mi>a</mi> <mo>=</mo> <mi>α</mi> <mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>x</mi> <mo>+</mo> <mi>y</mi></mrow></math>
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>a</mi> <mo>=</mo> <mi>α</mi> <mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>x</mi> <mo>+</mo> <mi>y</mi></mrow></math>
- en: 'Step 2 would be to feed *a* through some function *σ* (*σ* can be any continuous
    function, such as `sigmoid`, or the `square` function, or even a function whose
    name doesn’t start with *s*). We’ll denote the output of this function as *s*:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是将 *a* 馈送到某个函数 *σ* 中（*σ* 可以是任何连续函数，如 `sigmoid`，或 `square` 函数，甚至一个名称不以 *s*
    开头的函数）。我们将这个函数的输出表示为 *s*：
- en: <math display="block"><mrow><mi>s</mi> <mo>=</mo> <mi>σ</mi> <mo>(</mo> <mi>a</mi>
    <mo>)</mo></mrow></math>
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>s</mi> <mo>=</mo> <mi>σ</mi> <mo>(</mo> <mi>a</mi>
    <mo>)</mo></mrow></math>
- en: 'We could, equivalently, denote the entire function as *f* and write:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以等价地将整个函数表示为 *f* 并写成：
- en: <math display="block"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi>
    <mo>)</mo> <mo>=</mo> <mi>σ</mi> <mo>(</mo> <mi>x</mi> <mo>+</mo> <mi>y</mi> <mo>)</mo></mrow></math>
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi>
    <mo>)</mo> <mo>=</mo> <mi>σ</mi> <mo>(</mo> <mi>x</mi> <mo>+</mo> <mi>y</mi> <mo>)</mo></mrow></math>
- en: This is more mathematically concise, but it obscures the fact that this is really
    two operations happening sequentially. To illustrate that, we need the diagram
    in the next section.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这更加数学上简洁，但它掩盖了这实际上是两个操作按顺序发生的事实。为了说明这一点，我们需要下一节中的图表。
- en: Diagram
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: 'Now that we’re at the stage where we’re examining functions with multiple inputs,
    let’s pause to define a concept we’ve been dancing around: the diagrams with circles
    and arrows connecting them that represent the mathematical “order of operations”
    can be thought of as *computational graphs*. For example, [Figure 1-12](#fig_01-13)
    shows a computational graph for the function *f* we just described.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们正在检查具有多个输入的函数，让我们暂停一下来定义一个我们一直在围绕的概念：用圆圈和连接它们的箭头表示数学“运算顺序”的图表可以被视为 *计算图*。例如，[图 1-12](#fig_01-13)
    显示了我们刚刚描述的函数 *f* 的计算图。
- en: '![dlfs 0112](assets/dlfs_0112.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0112](assets/dlfs_0112.png)'
- en: Figure 1-12\. Function with multiple inputs
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-12\. 具有多个输入的函数
- en: Here we see the two inputs going into *α* and coming out as *a* and then being
    fed through *σ*.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们看到两个输入进入 *α*，作为 *a* 出来，然后通过 *σ* 进行馈送。
- en: Code
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Coding this up is very straightforward; note, however, that we have to add
    one extra assertion:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 编写这个代码非常简单；但是请注意，我们必须添加一个额外的断言：
- en: '[PRE19]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Unlike the functions we saw earlier in this chapter, this function does not
    simply operate “elementwise” on each element of its input `ndarray`s. Whenever
    we deal with an operation that takes multiple `ndarray`s as inputs, we have to
    check their shapes to ensure they meet whatever conditions are required by that
    operation. Here, for a simple operation such as addition, all we need to check
    is that the shapes are identical so that the addition can happen elementwise.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 与本章前面看到的函数不同，这个函数不仅仅是在其输入 `ndarray` 的每个元素上“逐元素”操作。每当我们处理一个需要多个 `ndarray` 作为输入的操作时，我们必须检查它们的形状，以确保它们满足该操作所需的任何条件。在这里，对于一个简单的加法操作，我们只需要检查形状是否相同，以便可以逐元素进行加法。
- en: Derivatives of Functions with Multiple Inputs
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有多个输入的函数的导数
- en: It shouldn’t seem surprising that we can compute the derivative of the output
    of such a function with respect to both of its inputs.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不应感到惊讶，我们可以计算这样一个函数的输出对其两个输入的导数。
- en: Diagram
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: 'Conceptually, we simply do the same thing we did in the case of functions with
    one input: compute the derivative of each constituent function “going backward”
    through the computational graph and then multiply the results together to get
    the total derivative. This is shown in [Figure 1-13](#fig_01-14).'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，我们只需做与具有一个输入的函数相同的事情：通过计算图“向后”计算每个组成函数的导数，然后将结果相乘以获得总导数。如[图1-13](#fig_01-14)所示。
- en: '![dlfs 0113](assets/dlfs_0113.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0113](assets/dlfs_0113.png)'
- en: Figure 1-13\. Going backward through the computational graph of a function with
    multiple inputs
  id: totrans-184
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-13。通过具有多个输入的函数的计算图向后传递
- en: Math
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'The chain rule applies to these functions in the same way it applied to the
    functions in the prior sections. Since this is a nested function, with <math><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>σ</mi> <mo>(</mo>
    <mi>α</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>)</mo></mrow></math>
    , we have:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 链式法则适用于这些函数，就像适用于前几节中的函数一样。由于这是一个嵌套函数，<math><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>σ</mi> <mo>(</mo> <mi>α</mi> <mo>(</mo>
    <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>)</mo></mrow></math>，我们有：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>α</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>α</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>+</mo>
    <mi>y</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>α</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>α</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>α</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>x</mi> <mo>+</mo>
    <mi>y</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>α</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
- en: And of course <math><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>y</mi></mrow></mfrac></math>
    would be identical.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，<math><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>y</mi></mrow></mfrac></math>也将是相同的。
- en: 'Now note that:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在注意：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>α</mi></mrow> <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn></mrow></math>
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>α</mi></mrow> <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn></mrow></math>
- en: since for every unit increase in *x*, *a* increases by one unit, no matter the
    value of *x* (the same holds for *y*).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 因为对于*x*的每个单位增加，*a*都会增加一个单位，无论*x*的值如何（*y*的情况也是如此）。
- en: Given this, we can code up how we might compute the derivative of such a function.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们可以编写如何计算这种函数的导数。
- en: Code
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: '[PRE20]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: A straightforward exercise for the reader is to modify this for the case where
    `x` and `y` are multiplied instead of added.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 读者的一个简单练习是修改这个例子，使得`x`和`y`相乘而不是相加。
- en: 'Next, we’ll examine a more complicated example that more closely mimics what
    happens in deep learning: a similar function to the previous example, but with
    two *vector* inputs.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将研究一个更复杂的例子，更接近深度学习中发生的情况：与前一个例子类似的函数，但有两个*向量*输入。
- en: Functions with Multiple Vector Inputs
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有多个向量输入的函数
- en: In deep learning, we deal with functions whose inputs are *vectors* or *matrices*.
    Not only can these objects be added, multiplied, and so on, but they can also
    combined via a dot product or a matrix multiplication. In the rest of this chapter,
    I’ll show how the mathematics of the chain rule and the logic of computing the
    derivatives of these functions using a forward and backward pass can still apply.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，我们处理的函数的输入是*向量*或*矩阵*。这些对象不仅可以相加、相乘等，还可以通过点积或矩阵乘法进行组合。在本章的其余部分，我将展示如何使用正向和反向传递计算这些函数的导数的数学和逻辑仍然适用。
- en: These techniques will end up being central to understanding why deep learning
    works. In deep learning, our goal will be to fit a model to some data. More precisely,
    this means that we want to find a mathematical function that maps *observations*
    from the data—which will be inputs to the function—to some desired *predictions*
    from the data—which will be the outputs of the function—in as optimal a way as
    possible. It turns out these observations will be encoded in matrices, typically
    with row as an observation and each column as a numeric feature for that observation.
    We’ll cover this in more detail in the next chapter; for now, being able to reason
    about the derivatives of complex functions involving dot products and matrix multiplications
    will be essential.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术最终将成为理解为什么深度学习有效的核心。在深度学习中，我们的目标是将模型拟合到一些数据中。更准确地说，这意味着我们希望找到一个数学函数，将数据中的*观察*（将是函数的输入）映射到数据中的一些期望的*预测*（将是函数的输出），并以尽可能优化的方式。原来这些观察结果将被编码在矩阵中，通常每行作为一个观察，每列作为该观察的一个数值特征。我们将在下一章中更详细地介绍这一点；目前，能够推理复杂函数的导数，包括点积和矩阵乘法，将是至关重要的。
- en: Let’s start by defining precisely what I mean, mathematically.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先准确地定义我所说的意思。
- en: Math
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'A typical way to represent a single data point, or “observation,” in a neural
    network is as a row with *n* features, where each feature is simply a number *x*[1],
    *x*[2], and so on, up to *x*[*n*]:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络中表示单个数据点或“观察”的典型方式是将其表示为具有*n*个特征的行，其中每个特征只是一个数字*x*[1]，*x*[2]，等等，直到*x*[*n*]：
- en: <math display="block"><mrow><mi>X</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>1</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd> <mtd><mo>...</mo></mtd>
    <mtd><msub><mi>x</mi> <mi>n</mi></msub></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>X</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>1</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd> <mtd><mo>...</mo></mtd>
    <mtd><msub><mi>x</mi> <mi>n</mi></msub></mtd></mtr></mtable></mfenced></mrow></math>
- en: A canonical example to keep in mind here is predicting housing prices, which
    we’ll build a neural network from scratch to do in the next chapter; in this example,
    *x*[1], *x*[2], and so on are numerical features of a house, such as its square
    footage or its proximity to schools.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里要牢记的一个典型例子是预测房价，我们将在下一章中从头开始构建一个神经网络来实现这一点；在这个例子中，*x*[1]，*x*[2]等等是房屋的数值特征，比如房屋的面积或其与学校的距离。
- en: Creating New Features from Existing Features
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从现有特征创建新特征
- en: Perhaps the single most common operation in neural networks is to form a “weighted
    sum” of these features, where the weighted sum could emphasize certain features
    and de-emphasize others and thus be thought of as a new feature that itself is
    just a combination of old features. A concise way to express this mathematically
    is as a *dot product* of this observation, with some set of “weights” of the same
    length as the features, *w*[1], *w*[2], and so on, up to *w*[*n*]. Let’s explore
    this concept from the three perspectives we’ve used thus far in this chapter.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中可能最常见的操作之一是形成这些特征的“加权和”，其中加权和可以强调某些特征并减弱其他特征，因此可以被视为一个新特征，它本身只是旧特征的组合。数学上简洁表达这一点的方法是将这个观察结果与与特征相同长度的一组“权重”进行*点积*，*w*[1]，*w*[2]，等等，直到*w*[*n*]。让我们从我们在本章迄今使用的三个角度来探讨这个概念。
- en: Math
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'To be mathematically precise, if:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 要在数学上准确，如果：
- en: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi>
    <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>w</mi> <mn>2</mn></msub></mtd></mtr>
    <mtr><mtd><mo>⋮</mo></mtd></mtr> <mtr><mtd><msub><mi>w</mi> <mi>n</mi></msub></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi>
    <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>w</mi> <mn>2</mn></msub></mtd></mtr>
    <mtr><mtd><mo>⋮</mo></mtd></mtr> <mtr><mtd><msub><mi>w</mi> <mi>n</mi></msub></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'then we could define the output of this operation as:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以定义这个操作的输出为：
- en: <math display="block"><mrow><mi>N</mi> <mo>=</mo> <mi>ν</mi> <mrow><mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>X</mi> <mo>×</mo>
    <mi>W</mi> <mo>=</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>2</mn></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>x</mi> <mi>n</mi></msub>
    <mo>×</mo> <msub><mi>w</mi> <mi>n</mi></msub></mrow></math>
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>N</mi> <mo>=</mo> <mi>ν</mi> <mrow><mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>X</mi> <mo>×</mo>
    <mi>W</mi> <mo>=</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>2</mn></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>x</mi> <mi>n</mi></msub>
    <mo>×</mo> <msub><mi>w</mi> <mi>n</mi></msub></mrow></math>
- en: Note that this operation is a special case of a *matrix multiplication* that
    just happens to be a dot product because *X* has one row and *W* has only one
    column.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s look at a few ways we could depict this with a diagram.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A simple way of depicting this operation is shown in [Figure 1-14](#fig_01-15).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0114](assets/dlfs_0114.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
- en: Figure 1-14\. Diagram of a vector dot product
  id: totrans-217
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This diagram depicts an operation that takes in two inputs, both of which can
    be `ndarray`s, and produces one output `ndarray`.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: But this is really a massive shorthand for many operations that are happening
    on many inputs. We could instead highlight the individual operations and inputs,
    as shown in Figures [1-15](#fig_01-16) and [1-16](#fig_01-17).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0115](assets/dlfs_0115.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
- en: Figure 1-15\. Another diagram of a matrix multiplication
  id: totrans-221
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![dlfs 0116](assets/dlfs_0116.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
- en: Figure 1-16\. A third diagram of a matrix multiplication
  id: totrans-223
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The key point is that the dot product (or matrix multiplication) is a concise
    way to represent many individual operations; in addition, as we’ll start to see
    in the next section, using this operation makes our derivative calculations on
    the backward pass extremely concise as well.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: Code
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Finally, in code this operation is simply:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: where we have a new assertion that ensures that the matrix multiplication will
    work. (This is necessary since this is our first operation that doesn’t merely
    deal with `ndarray`s that are the same size and perform an operation elementwise—our
    output is now actually a different size than our input.)
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Derivatives of Functions with Multiple Vector Inputs
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For functions that simply take one input as a number and produce one output,
    like *f*(*x*) = *x*² or *f*(*x*) = sigmoid(*x*), computing the derivative is straightforward:
    we simply apply rules from calculus. For vector functions, it isn’t immediately
    obvious what the derivative is: if we write a dot product as <math><mrow><mi>ν</mi>
    <mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo> <mo>=</mo> <mi>N</mi></mrow></math>
    , as in the prior section, the question naturally arises—what would <math><mfrac><mrow><mi>∂</mi><mi>N</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac></math> and <math><mfrac><mrow><mi>∂</mi><mi>N</mi></mrow>
    <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac></math> be?'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Conceptually, we just want to do something like in [Figure 1-17](#fig_01-18).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '![dlfs 0117](assets/dlfs_0117.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
- en: Figure 1-17\. Backward pass of a matrix multiplication, conceptually
  id: totrans-234
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Calculating these derivatives was easy when we were just dealing with addition
    and multiplication, as in the prior examples. But how can we do the analogous
    thing with matrix multiplication? To define that precisely, we’ll have to turn
    to the math.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Math
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, how would we even define “the derivative with respect to a matrix”?
    Recalling that the matrix syntax is just shorthand for a bunch of numbers arranged
    in a particular form, “the derivative with respect to a matrix” really means “the
    derivative with respect to each element of the matrix.” Since *X* is a row, a
    natural way to define it is:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mtd> <mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>2</mn></msub></mrow></mfrac></mtd> <mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>3</mn></msub></mrow></mfrac></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mtd> <mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>2</mn></msub></mrow></mfrac></mtd> <mtd><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>3</mn></msub></mrow></mfrac></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'However, the output of *ν* is just a number: <math><mrow><mi>N</mi> <mo>=</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub></mrow></math>
    . And looking at this, we can see that if, for example, <math><msub><mi>x</mi>
    <mn>1</mn></msub></math> changes by *ϵ* units, then *N* will change by <math><mrow><msub><mi>w</mi>
    <mn>1</mn></msub> <mo>×</mo> <mi>ϵ</mi></mrow></math> units—and the same logic
    applies to the other *x*[*i*] elements. Thus:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>1</mn></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi> <mn>1</mn></msub></mrow></math><math
    display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>2</mn></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi> <mn>2</mn></msub></mrow></math><math
    display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>3</mn></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi> <mn>3</mn></msub></mrow></math>
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>1</mn></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi> <mn>1</mn></msub></mrow></math><math
    display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>2</mn></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi> <mn>2</mn></msub></mrow></math><math
    display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>3</mn></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi> <mn>3</mn></msub></mrow></math>
- en: 'And so:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 因此：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi> <mn>1</mn></msub></mtd>
    <mtd><msub><mi>w</mi> <mn>2</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>3</mn></msub></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi> <mn>1</mn></msub></mtd>
    <mtd><msub><mi>w</mi> <mn>2</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>3</mn></msub></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
- en: This is a surprising and elegant result that turns out to be a key piece of
    the puzzle to understanding both why deep learning works and how it can be implemented
    so cleanly.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个令人惊讶且优雅的结果，事实证明这是理解为什么深度学习有效以及如何实现得如此干净的关键部分。
- en: 'Using similar reasoning, we can see that:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 通过类似的推理，我们可以看到：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi> <mn>1</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi>
    <mn>3</mn></msub></mtd></mtr></mtable></mfenced> <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup></mrow></math>
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi> <mn>1</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi>
    <mn>3</mn></msub></mtd></mtr></mtable></mfenced> <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup></mrow></math>
- en: Code
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Here, reasoning mathematically about what the answer “should” be was the hard
    part. The easy part is coding up the result:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，对答案“应该”是什么进行数学推理是困难的部分。简单的部分是编写结果的代码：
- en: '[PRE22]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `dNdX` quantity computed here represents the partial derivative of each
    element of *X* with respect to the sum of the output *N*. There is a special name
    for this quantity that we’ll use throughout the book: we’ll call it the *gradient*
    of *X* with respect to *X*. The idea is that for an individual element of *X*—say,
    *x*[3]—the corresponding element in `dNdx` (`dNdX[2]`, to be specific) is the
    partial derivative of the output of the vector dot product *N* with respect to
    *x*[3]. The term “gradient” as we’ll use it in this book simply refers to a multidimensional
    analogue of the partial derivative; specifically, it is an array of partial derivatives
    of the output of a function with respect to each element of the input to that
    function.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这里计算的`dNdX`数量代表了*X*的每个元素相对于输出*N*的和的偏导数。我们在整本书中将使用一个特殊的名称来称呼这个数量：我们将其称为*X*相对于*X*的*梯度*。这个想法是对于*X*的每个单独元素——比如，*x*[3]——向量点积*N*的输出相对于*x*[3]的偏导数对应的元素在`dNdx`中（具体来说是`dNdX[2]`）。在本书中，我们将使用术语“梯度”来指代偏导数的多维模拟；具体来说，它是一个函数的输出相对于该函数输入的每个元素的偏导数数组。
- en: 'Vector Functions and Their Derivatives: One Step Further'
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量函数及其导数：再进一步
- en: 'Deep learning models, of course, involve more than one operation: they include
    long chains of operations, some of which are vector functions like the one covered
    in the last section, and some of which simply apply a function elementwise to
    the `ndarray` they receive as input. Therefore, we’ll now look at computing the
    derivative of a composite function that includes *both* kinds of functions. Let’s
    suppose our function takes in the vectors *X* and *W*, performs the dot product
    described in the prior section—which we’ll denote as <math><mrow><mi>ν</mi> <mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow></math> —and then feeds the
    vectors through a function *σ*. We’ll express the same objective as before, but
    in new language: we want to compute the gradients of the output of this new function
    with respect to *X* and *W*. Again, starting in the next chapter, we’ll see in
    precise detail how this is connected to what neural networks do, but for now we
    just want to build up the idea that we can compute gradients for computational
    graphs of arbitrary complexity.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，深度学习模型涉及多个操作：它们包括一系列操作，其中一些是像上一节中介绍的向量函数，一些只是将函数逐个元素应用于它们作为输入接收的`ndarray`。因此，我们现在将看看如何计算包含*两种*函数的复合函数的导数。假设我们的函数接受向量*X*和*W*，执行在前一节中描述的点积——我们将其表示为<math><mrow><mi>ν</mi>
    <mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow></math>，然后将向量通过一个函数*σ*。我们将用新的语言表达与之前相同的目标：我们想计算这个新函数的输出相对于*X*和*W*的梯度。再次强调，从下一章开始，我们将详细了解这与神经网络的关系，但现在我们只是想建立这样一个概念：我们可以计算任意复杂计算图的梯度。
- en: Diagram
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: The diagram for this function, shown in [Figure 1-18](#fig_01-19), is the same
    as in [Figure 1-17](#fig_01-18), with the *σ* function simply added onto the end.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数的图表，显示在[图1-18](#fig_01-19)中，与[图1-17](#fig_01-18)中的相同，只是在末尾简单地添加了*σ*函数。
- en: '![dlfs 0118](assets/dlfs_0118.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0118](assets/dlfs_0118.png)'
- en: Figure 1-18\. Same graph as before, but with another function tacked onto the
    end
  id: totrans-255
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-18\. 与之前相同的图表，但在末尾添加了另一个函数
- en: Math
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'Mathematically, this is straightforward as well:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学上讲，这同样很简单：
- en: <math display="block"><mrow><mi>s</mi> <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>s</mi> <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>
- en: Code
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Finally, we can code this function up as:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以将这个函数编写成：
- en: '[PRE23]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Vector Functions and Their Derivatives: The Backward Pass'
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量函数及其导数：反向传播
- en: The backward pass is similarly just a straightforward extension of the prior
    example.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播同样只是先前示例的直接扩展。
- en: Math
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数学
- en: 'Since *f*(*X, W*) is a nested function—specifically, *f*(*X, W*) = *σ*(*ν*(*X,
    W*))—its derivative with respect to, for example, *X* should conceptually be:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 由于*f*(*X, W*)是一个嵌套函数——具体来说，*f*(*X, W*) = *σ*(*ν*(*X, W*))——它对于例如*X*的导数在概念上应该是：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow></mrow></math>
- en: 'But the first part of this is simply:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 但这部分简单地是：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>
- en: which is well defined since *σ* is just a continuous function whose derivative
    we can evaluate at any point, and here we are just evaluating it at <math><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>3</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub></mrow></math>
    .
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这是很明确的，因为*σ*只是一个连续函数，我们可以在任何点评估它的导数，这里我们只是在<math><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub></mrow></math>处评估它。
- en: 'Furthermore, we reasoned in the prior example that <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
    . Therefore:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们在先前的示例中推理，<math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo>
    <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>。因此：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow> <mo>×</mo> <msup><mi>W</mi>
    <mi>T</mi></msup></mrow></math>
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>ν</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow> <mo>×</mo> <msup><mi>W</mi>
    <mi>T</mi></msup></mrow></math>
- en: which, as in the preceding example, results in a vector of the same shape as
    *X*, since the final answer is a number, <math><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>
    , times a vector of the same shape as *X* in *W*^(*T*).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 与先前示例中一样，由于最终答案是一个数字，<math><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>3</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>3</mn></msub> <mo>)</mo></mrow></mrow></math>，乘以*W*^(*T*)中与*X*相同形状的向量。
- en: Diagram
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图表
- en: The diagram for the backward pass of this function, shown in [Figure 1-19](#fig_01-20),
    is similar to that of the prior example and even higher level than the math; we
    just have to add one more multiplication based on the derivative of the *σ* function
    evaluated at the result of the matrix multiplication.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数的反向传播图，如[图1-19](#fig_01-20)所示，与先前示例的类似，甚至比数学更高级；我们只需要根据在矩阵乘法结果处评估的*σ*函数的导数再添加一个乘法。
- en: '![dlfs 0119](assets/dlfs_0119.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0119](assets/dlfs_0119.png)'
- en: 'Figure 1-19\. Graph with a matrix multiplication: the backward pass'
  id: totrans-276
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-19\. 具有矩阵乘法的图：反向传播
- en: Code
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码
- en: 'Finally, coding up the backward pass is straightforward as well:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，编写反向传播也同样简单：
- en: '[PRE24]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Notice that we see the same dynamic here that we saw in the earlier example
    with the three nested functions: we compute quantities on the forward pass (here,
    just `N`) that we then use during the backward pass.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在这里看到了与之前的三个嵌套函数示例中相同的动态：我们在正向传播中计算数量（这里只是`N`），然后在反向传播中使用它们。
- en: Is this right?
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这样对吗？
- en: 'How can we tell if these derivatives we’re computing are correct? A simple
    test is to perturb the input a little bit and observe the resulting change in
    output. For example, *X* in this case is:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何知道我们计算的这些导数是否正确？一个简单的测试是稍微扰动输入，观察输出的变化。例如，在这种情况下，*X*是：
- en: '[PRE25]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: If we increase *x*[3] by *0.01*, from `-1.726` to `-1.716`, we should see an
    increase in the value produced by the forward function of *the gradient of the
    output with respect to x[3] × 0.01*. [Figure 1-20](#fig_01-21) shows this.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将*x*[3]从*-1.726*增加到*-1.716*，我们应该看到正向函数产生的值增加了*关于x[3]的梯度 × 0.01*。[图1-20](#fig_01-21)展示了这一点。
- en: '![dlfs 0120](assets/dlfs_0120.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0120](assets/dlfs_0120.png)'
- en: 'Figure 1-20\. Gradient checking: an illustration'
  id: totrans-287
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-20\. 梯度检查：一个示例
- en: 'Using the `matrix_function_backward_1` function, we can see that the gradient
    is `-0.1121`:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`matrix_function_backward_1`函数，我们可以看到梯度是`-0.1121`：
- en: '[PRE27]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: To test whether this gradient is correct, we should see, after incrementing
    *x*[3] by 0.01, a corresponding decrease in the *output* of the function by about
    `0.01 × -0.1121 = -0.001121`; if we saw an decrease by more or less than this
    amount, or an increase, for example, we would know that our reasoning about the
    chain rule was off. What we see when we do this calculation,^([2](ch01.html#idm45732630322664))
    however, is that increasing *x*[3] by a small amount does indeed decrease the
    value of the output of the function by `0.01 × -0.1121`—which means the derivatives
    we’re computing are correct!
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试这个梯度是否正确，我们应该看到，在将*x*[3]增加0.01后，函数的*output*大约减少`0.01 × -0.1121 = -0.001121`；如果我们看到减少的数量多或少于这个量，或者出现增加，那么我们就知道我们对链式法则的推理是错误的。然而，当我们进行这个计算时，^([2](ch01.html#idm45732630322664))，我们看到增加*x*[3]一点点确实会减少函数输出的值`0.01
    × -0.1121`——这意味着我们计算的导数是正确的！
- en: 'To close out this chapter, we’ll cover an example that builds on everything
    we’ve done so far and directly applies to the models we’ll build in the next chapter:
    a computational graph that starts by multiplying a pair of two-dimensional matrices
    together.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，我们将介绍一个建立在我们迄今为止所做的一切基础上，并直接应用于我们将在下一章中构建的模型的示例：一个计算图，从将一对二维矩阵相乘开始。
- en: Computational Graph with Two 2D Matrix Inputs
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 带有两个2D矩阵输入的计算图
- en: In deep learning, and in machine learning more generally, we deal with operations
    that take as input two 2D arrays, one of which represents a batch of data *X*
    and the other of which represents the weights *W*. In the next chapter, we’ll
    dive deep into why this makes sense in a modeling context, but in this chapter
    we’ll just focus on the mechanics and the math behind this operation. Specifically.
    we’ll walk through a simple example in detail and show that even when multiplications
    of 2D matrices are involved, rather than just dot products of 1D vectors, the
    reasoning we’ve been using throughout this chapter still makes mathematical sense
    and is in fact extremely easy to code.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，以及更普遍地在机器学习中，我们处理的操作以两个二维数组作为输入，其中一个代表数据批次*X*，另一个代表权重*W*。在下一章中，我们将深入探讨为什么在建模上这是有意义的，但在本章中我们将专注于这个操作背后的机制和数学。具体来说，我们将详细介绍一个简单的例子，并展示即使涉及2D矩阵的乘法，而不仅仅是1D向量的点积，我们在本章中一直使用的推理仍然在数学上是有意义的，并且实际上非常容易编码。
- en: As before, the math needed to derive these results gets…not difficult, but messy.
    Nevertheless, the result is quite clean. And, of course, we’ll break it down step
    by step and always connect it back to both code and diagrams.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 和以前一样，推导这些结果所需的数学并不困难，但有些混乱。尽管如此，结果是相当干净的。当然，我们将一步一步地分解它，并始终将其与代码和图表联系起来。
- en: Math
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: 'Let’s suppose that:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 假设：
- en: <math display="block"><mrow><mi>X</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>11</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>12</mn></msub></mtd> <mtd><msub><mi>x</mi>
    <mn>13</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi> <mn>21</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>22</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>23</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>31</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>32</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>33</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>X</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>11</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>12</mn></msub></mtd> <mtd><msub><mi>x</mi>
    <mn>13</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi> <mn>21</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>22</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>23</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>31</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>32</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>33</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'and:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 和：
- en: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi>
    <mn>11</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>12</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mn>21</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>22</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mn>31</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>32</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi>
    <mn>11</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>12</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mn>21</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>22</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mn>31</mn></msub></mtd> <mtd><msub><mi>w</mi> <mn>32</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
- en: This could correspond to a dataset in which each observation has three features,
    and the three rows could correspond to three different observations for which
    we want to make predictions.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能对应于一个数据集，其中每个观测具有三个特征，三行可能对应于我们想要进行预测的三个不同观测。
- en: 'Now we’ll define the following straightforward operations to these matrices:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将对这些矩阵定义以下简单的操作：
- en: Multiply these matrices together. As before, we’ll denote the function that
    does this as *ν*(*X*, *W*) and the output as *N*, so that *N* = *ν*(*X*, *W*).
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些矩阵相乘。和以前一样，我们将把执行这个操作的函数表示为*ν*(*X*, *W*)，输出为*N*，所以*N* = *ν*(*X*, *W*)。
- en: Feed <math><mi>N</mi></math> result through some differentiable function *σ*,
    and define (*S* = *σ*(*N*).
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过一些可微函数*σ*将<math><mi>N</mi></math>结果传递，定义(*S* = *σ*(*N*)。
- en: 'As before, the question now is: what are the gradients of the output *S* with
    respect to *X* and *W*? Can we simply use the chain rule again? Why or why not?'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 和以前一样，现在的问题是：输出*S*对*X*和*W*的梯度是多少？我们能否再次简单地使用链式法则？为什么或为什么不？
- en: 'If you think about this for a bit, you may realize that something is different
    from the previous examples that we’ve looked at: *S is now a matrix*, not simply
    a number. And what, after all, does the gradient of one matrix with respect to
    another matrix mean?'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你稍微思考一下，你可能会意识到与我们之前看过的例子有所不同：*S现在是一个矩阵*，不再是一个简单的数字。毕竟，一个矩阵对另一个矩阵的梯度意味着什么呢？
- en: 'This leads us to a subtle but important idea: we may perform whatever series
    of operations on multidimensional arrays we want, but for the notion of a “gradient”
    with respect to some output to be well defined, we need to *sum* (or otherwise
    aggregate into a single number) the final array in the sequence so that the notion
    of “how much will changing each element of *X* affect the output” will even make
    sense.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了一个微妙但重要的想法：我们可以对多维数组执行任何系列的操作，但为了定义对某个输出的“梯度”是有意义的，我们需要*求和*（或以其他方式聚合成一个数字）序列中的最终数组，以便“改变*X*的每个元素将如何影响输出”的概念甚至有意义。
- en: So we’ll tack onto the end a third function, *Lambda*, that simply takes the
    elements of *S* and sums them up.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将在最后添加一个第三个函数*Lambda*，它只是取*S*的元素并将它们求和。
- en: 'Let’s make this mathematically concrete. First, let’s multiply *X* and *W*:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在数学上具体化。首先，让我们将*X*和*W*相乘：
- en: <math display="block"><mrow><mi>X</mi> <mo>×</mo> <mi>W</mi> <mo>=</mo> <mfenced
    close="]" open="["><mtable><mtr><mtd><mrow><msub><mi>x</mi> <mn>11</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub></mrow></mtd> <mtd><mrow><msub><mi>x</mi>
    <mn>11</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>12</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>13</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr>
    <mtr><mtd><mrow><msub><mi>x</mi> <mn>21</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>31</mn></msub></mrow></mtd> <mtd><mrow><msub><mi>x</mi> <mn>21</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr> <mtr><mtd><mrow><msub><mi>x</mi>
    <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub></mrow></mtd>
    <mtd><mrow><msub><mi>x</mi> <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>X</mi> <msub><mi>W</mi> <mn>21</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi>
    <msub><mi>W</mi> <mn>22</mn></msub></mrow></mtd></mtr> <mtr><mtd><mrow><mi>X</mi>
    <msub><mi>W</mi> <mn>31</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>X</mi> <mo>×</mo> <mi>W</mi> <mo>=</mo> <mfenced
    close="]" open="["><mtable><mtr><mtd><mrow><msub><mi>x</mi> <mn>11</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub></mrow></mtd> <mtd><mrow><msub><mi>x</mi>
    <mn>11</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>12</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>13</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr>
    <mtr><mtd><mrow><msub><mi>x</mi> <mn>21</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>31</mn></msub></mrow></mtd> <mtd><mrow><msub><mi>x</mi> <mn>21</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr> <mtr><mtd><mrow><msub><mi>x</mi>
    <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub></mrow></mtd>
    <mtd><mrow><msub><mi>x</mi> <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>X</mi> <msub><mi>W</mi> <mn>21</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi>
    <msub><mi>W</mi> <mn>22</mn></msub></mrow></mtd></mtr> <mtr><mtd><mrow><mi>X</mi>
    <msub><mi>W</mi> <mn>31</mn></msub></mrow></mtd> <mtd><mrow><mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: where we denote row *i* and column *j* in the resulting matrix as <math><mrow><mi>X</mi>
    <msub><mi>W</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math> for convenience.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 其中我们为方便起见将结果矩阵中的第*i*行第*j*列表示为<math><mrow><mi>X</mi> <msub><mi>W</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></math>。
- en: 'Next, we’ll feed this result through *σ*, which just means applying *σ* to
    every element of the matrix <math><mrow><mi>X</mi> <mo>×</mo> <mi>W</mi></mrow></math>
    :'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过*σ*将这个结果馈送，这只是意味着将*σ*应用于矩阵<math><mrow><mi>X</mi> <mo>×</mo> <mi>W</mi></mrow></math>的每个元素：
- en: <math display="block"><mrow><mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>×</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi> <mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>21</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>×</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>11</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>21</mn></msub>
    <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>12</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>22</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi> <mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>21</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'Finally, we can simply sum up these elements:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以简单地总结这些元素：
- en: <math display="block"><mrow><mi>L</mi> <mo>=</mo> <mi>Λ</mi> <mrow><mo>(</mo>
    <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>×</mo> <mi>W</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mi>Λ</mi> <mrow><mo>(</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub> <mo>)</mo></mrow></mtd>
    <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub>
    <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi>
    <msub><mi>W</mi> <mn>21</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>22</mn></msub> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced> <mo>)</mo></mrow>
    <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub>
    <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi>
    <msub><mi>W</mi> <mn>21</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>22</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi>
    <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub> <mo>)</mo></mrow>
    <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>32</mn></msub>
    <mo>)</mo></mrow></mrow></math>
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>L</mi> <mo>=</mo> <mi>Λ</mi> <mrow><mo>(</mo>
    <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <mo>×</mo> <mi>W</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <mi>Λ</mi> <mrow><mo>(</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub> <mo>)</mo></mrow></mtd>
    <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>12</mn></msub>
    <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi>
    <msub><mi>W</mi> <mn>21</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi>
    <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>22</mn></msub> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mtd> <mtd><mrow><mi>σ</mi> <mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced> <mo>)</mo></mrow>
    <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>11</mn></msub>
    <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi>
    <msub><mi>W</mi> <mn>21</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>X</mi> <msub><mi>W</mi> <mn>22</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>σ</mi>
    <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>31</mn></msub> <mo>)</mo></mrow>
    <mo>+</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi> <mn>32</mn></msub>
    <mo>)</mo></mrow></mrow></math>
- en: 'Now we are back in a pure calculus setting: we have a number, *L*, and we want
    to figure out the gradient of *L* with respect to *X* and *W*; that is, we want
    to know how much changing *each element* of these input matrices (*x*[11], *w*[21],
    and so on) would change *L*. We can write this as:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们回到了一个纯粹的微积分环境：我们有一个数字*L*，我们想要计算*L*对*X*和*W*的梯度；也就是说，我们想知道改变这些输入矩阵的*每个元素*（*x*[11]，*w*[21]等）会如何改变*L*。我们可以写成：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>32</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>33</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>11</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>21</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>22</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>23</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>31</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>32</mn></msub>
    <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>33</mn></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: And now we understand mathematically the problem we are up against. Let’s pause
    the math for a second and catch up with our diagram and code.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们从数学上理解了我们面临的问题。让我们暂停一下数学，跟上我们的图表和代码。
- en: Diagram
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: Conceptually, what we are doing here is similar to what we’ve done in the previous
    examples with a computational graph with multiple inputs; thus, [Figure 1-21](#fig_01-22)
    should look familiar.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，我们在这里所做的与我们在以前的例子中使用多个输入的计算图所做的类似；因此，[图1-21](#fig_01-22)应该看起来很熟悉。
- en: '![dlfs 0121](assets/dlfs_0121.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0121](assets/dlfs_0121.png)'
- en: Figure 1-21\. Graph of a function with a complicated forward pass
  id: totrans-322
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-21\. 具有复杂前向传递的函数的图表
- en: We are simply sending inputs forward as before. We claim that even in this more
    complicated scenario, we should be able to calculate the gradients we need using
    the chain rule.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只是像以前一样将输入向前发送。我们声称即使在这种更复杂的情况下，我们也应该能够使用链式法则计算我们需要的梯度。
- en: Code
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'We can code this up as:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以编写如下代码：
- en: '[PRE29]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The Fun Part: The Backward Pass'
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有趣的部分：反向传播
- en: Now we want to “perform the backward pass” for this function, showing how, even
    when a matrix multiplication is involved, we can end up calculating the gradient
    of `N` with respect to each of the elements of our input `ndarray`s.^([3](ch01.html#idm45732628068456))
    With this final step figured out, starting to train real machine learning models
    in [Chapter 2](ch02.html#fundamentals) will be straightforward. First, let’s remind
    ourselves what we are doing, conceptually.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想要为这个函数“执行反向传播”，展示即使涉及矩阵乘法，我们也可以计算出对输入`ndarray`的每个元素的`N`梯度。有了这一最后一步，开始在[第2章](ch02.html#fundamentals)中训练真实的机器学习模型将变得简单。首先，让我们在概念上提醒自己我们正在做什么。
- en: Diagram
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图表
- en: Again, what we’re doing is similar to what we’ve done in the prior examples
    from this chapter; [Figure 1-22](#fig_01-23) should look as familiar as [Figure 1-21](#fig_01-22)
    did.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们所做的与本章中之前的例子类似；[图1-22](#fig_01-23)应该和[图1-21](#fig_01-22)一样熟悉。
- en: '![dlfs 0122](assets/dlfs_0122.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0122](assets/dlfs_0122.png)'
- en: Figure 1-22\. Backward pass through our complicated function
  id: totrans-332
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-22\. 通过我们复杂的函数的反向传播
- en: We simply need to calculate the partial derivative of each constituent function
    and evaluate it at its input, multiplying the results together to get the final
    derivative. Let’s consider each of these partial derivatives in turn; the only
    way through it is through the math.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要计算每个组成函数的偏导数，并在其输入处评估它，将结果相乘以得到最终的导数。让我们依次考虑这些偏导数；唯一的方法就是通过数学。
- en: Math
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数学
- en: Let’s first note that we could compute this directly. The value *L* is indeed
    a function of *x*[11], *x*[12], and so on, all the way up to *x*[33].
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要注意的是我们可以直接计算这个。值*L*确实是*x*[11]、*x*[12]等等的函数，一直到*x*[33]。
- en: 'However, that seems complicated. Wasn’t the whole point of the chain rule that
    we can break down the derivatives of complicated functions into simple pieces,
    compute each of those pieces, and then just multiply the results? Indeed, that
    fact was what made it so easy to code these things up: we just went step by step
    through the forward pass, saving the results as we went, and then we used those
    results to evaluate all the necessary derivatives for the backward pass.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这似乎很复杂。链式法则的整个意义不就是我们可以将复杂函数的导数分解为简单的部分，计算每个部分，然后将结果相乘吗？确实，这个事实使得编写这些代码变得如此容易：我们只需逐步进行前向传播，保存结果，然后使用这些结果来评估反向传播所需的所有必要导数。
- en: I’ll show that this approach only *kind of* works when there are matrices involved.
    Let’s dive in.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 我将展示当涉及矩阵时，这种方法只“部分”有效。让我们深入探讨。
- en: 'We can write *L* as <math><mrow><mi>Λ</mi> <mo>(</mo> <mi>σ</mi> <mo>(</mo>
    <mi>ν</mi> <mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo> <mo>)</mo> <mo>)</mo></mrow></math>
    . If this were a regular function, we would just write the chain rule:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将*L*写成<math><mrow><mi>Λ</mi> <mo>(</mo> <mi>σ</mi> <mo>(</mo> <mi>ν</mi>
    <mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo> <mo>)</mo> <mo>)</mo></mrow></math>。如果这是一个常规函数，我们只需写出链式法则：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo>
    <mi>W</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow></mrow></math>
- en: Then we would compute each of the three partial derivatives in turn. This is
    exactly what we did before in the function of three nested functions, for which
    we computed the derivative using the chain rule, and [Figure 1-22](#fig_01-23)
    suggests that approach should work for this function as well.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们依次计算这三个偏导数。这正是我们之前在三个嵌套函数的函数中所做的，我们使用链式法则计算导数，[图1-22](#fig_01-23)表明这种方法对这个函数也应该适用。
- en: 'The first derivative is the most straightforward and thus makes the best warm-up.
    We want to know how much *L* (the output of *Λ*) will increase if each element
    of *S* increases. Since *L* is the sum of all the elements of *S*, this derivative
    is simply:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个导数是最直接的，因此是最好的热身。我们想知道*L*（*Λ*的输出）每个元素增加时*L*会增加多少。由于*L*是*S*的所有元素的和，这个导数就是：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></math>
- en: since increasing any element of *S* by, say, 0.46 units would increase *Λ* by
    0.46 units.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 因为增加*S*的任何元素，比如说，0.46个单位，会使*Λ*增加0.46个单位。
- en: 'Next, we have <math><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow></mrow></math> . This is simply the
    derivative of whatever function *σ* is, evaluated at the elements in *N*. In the
    "*XW*" syntax we’ve used previously, this is again simple to compute:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有<math><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow></mrow></math>。这只是*σ*是什么函数的导数，在*N*中的元素处进行评估。在我们之前使用的“*XW*”语法中，这也很容易计算：
- en: <math display="block"><mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></math>
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></math>
- en: 'Note that at this point we can say for certain that we can multiply these two
    derivatives together *elementwise* and compute <math><mrow><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow></mrow></math>
    :'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，此时我们可以确定我们可以将这两个导数*逐元素*相乘并计算<math><mrow><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow></mrow></math>：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced> <mo>×</mo>
    <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>1</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced> <mo>×</mo>
    <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>1</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: Now, however, we are stuck. The next thing we want, based on the diagram and
    applying the chain rule, is <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow></mrow></math>
    . Recall, however, that *N*, the output of *ν*, was just the result of a matrix
    multiplication of *X* with *W*. Thus we want some notion of how much increasing
    each element of *X* (a 3 × 3 matrix) will increase each element of *N* (a 3 ×
    2 matrix). If you’re having trouble wrapping your mind around such a notion, that’s
    the point—it isn’t clear at all how we’d define this, or whether it would even
    be useful if we did.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现在我们卡住了。根据图表和应用链式法则，我们想要的下一步是<math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow></mrow></math>。然而，请记住，*N*，*ν*的输出，只是*X*与*W*的矩阵乘法的结果。因此，我们想知道增加*X*的每个元素（一个3×3矩阵）将如何增加*N*的每个元素（一个3×2矩阵）。如果你对这种概念感到困惑，那就是关键所在——我们并不清楚如何定义这个概念，或者如果我们这样做是否有用。
- en: Why is this a problem now? Before, we were in the fortunate situation of *X*
    and *W* being transposes of each other in terms of shape. That being the case,
    we could show that <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
    and <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup></mrow></math>
    . Is there something analogous we can say here?
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么现在成为问题了？之前，我们很幸运地*X*和*W*在形状上是彼此的转置。在这种情况下，我们可以证明<math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>和<math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>W</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup></mrow></math>。这里是否有类似的说法？
- en: The “?”
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: “？”
- en: 'More specifically, here’s where we’re stuck. We need to figure out what goes
    in the “?”:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，这就是我们卡住的地方。我们需要弄清楚“？”中应该填什么：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>N</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mo>?</mo> <mo>=</mo>
    <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced> <mo>×</mo>
    <mo>?</mo></mrow></math>
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>N</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>×</mo> <mo>?</mo> <mo>=</mo>
    <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>11</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>12</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>21</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>22</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr> <mtr><mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>31</mn></msub> <mo>)</mo></mrow></mrow></mtd> <mtd><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <msub><mi>W</mi>
    <mn>32</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></mfenced> <mo>×</mo>
    <mo>?</mo></mrow></math>
- en: The answer
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 答案
- en: 'It turns out that because of the way the multiplication works out, what fills
    the “?” is simply *W*^(*T*), as in the simpler example with the vector dot product
    that we just saw! The way to verify this is to compute the partial derivative
    of *L* with respect to each element of *X* directly; when we do so,^([4](ch01.html#idm45732627740296))
    the resulting matrix does indeed (remarkably) factor out into:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，由于乘法的工作方式，填充“?”的内容只是*W*^(*T*)，就像我们刚刚看到的向量点积的简单示例一样！验证这一点的方法是直接计算*L*对*X*的每个元素的偏导数；当我们这样做时，得到的矩阵确实（令人惊讶地）分解为：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>×</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow> <mo>×</mo> <msup><mi>W</mi> <mi>T</mi></msup></mrow></math>
- en: where the first multiplication is elementwise, and the second one is a matrix
    multiplication.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个乘法是逐元素的，第二个是矩阵乘法。
- en: This means that *even if the operations in our computational graph involve multiplying
    matrices with multiple rows and columns, and even if the shapes of the outputs
    of those operations are different than those of the inputs, we can still include
    these operations in our computational graph and backpropagate through them using
    “chain rule” logic*. This is a critical result, without which training deep learning
    models would be much more cumbersome, as you’ll appreciate further after the next
    chapter.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着*即使我们计算图中的操作涉及乘以具有多行和列的矩阵，即使这些操作的输出形状与输入的形状不同，我们仍然可以将这些操作包括在我们的计算图中，并使用“链式法则”逻辑进行反向传播。这是一个关键的结果，没有它，训练深度学习模型将会更加繁琐，你将在下一章中进一步体会到。
- en: Code
  id: totrans-358
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代码
- en: 'Let’s encapsulate what we just derived using code, and hopefully solidify our
    understanding in the process:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用代码封装我们刚刚推导出的内容，并希望在这个过程中巩固我们的理解：
- en: '[PRE30]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now let’s verify that everything worked:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们验证一切是否正常：
- en: '[PRE31]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As in the previous example, since `dLdX` represents the gradient of *X* with
    respect to *L*, this means that, for instance, the top-left element indicates
    that <math><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><msub><mi>x</mi>
    <mn>11</mn></msub></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mn>0.2489</mn></mrow></math> . Thus, if the matrix
    math for this example was correct, then increasing *x*[11] by 0.001 should increase
    *L* by `0.01 × 0.2489`. Indeed, we see that this is what happens:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 与前面的例子一样，由于`dLdX`表示*X*相对于*L*的梯度，这意味着，例如，左上角的元素表示<math><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>11</mn></msub></mrow></mfrac> <mrow><mo>(</mo>
    <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <mn>0.2489</mn></mrow></math>。因此，如果这个例子的矩阵运算是正确的，那么将*x*[11]增加0.001应该使*L*增加`0.01
    × 0.2489`。实际上，我们看到这就是发生的：
- en: '[PRE33]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Looks like the gradients were computed correctly!
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来梯度计算正确！
- en: Describing these gradients visually
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 描述这些梯度的可视化
- en: 'To bring this back to what we noted at the beginning of the chapter, we fed
    the element in question, *x*[11], through a function with many operations: there
    was a matrix multiplication—which was really shorthand for combining the nine
    inputs in the matrix *X* with the six inputs in the matrix *W* to create six outputs—the
    `sigmoid` function, and then the sum. Nevertheless, we can also think of this
    as a single function called, say, " <math><mrow><mi>W</mi> <mi>N</mi> <mi>S</mi>
    <mi>L</mi></mrow></math> , “as depicted in [Figure 1-23](#fig_01-24).'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 回到本章开头我们注意到的内容，我们将问题中的元素*x*[11]通过一个包含许多操作的函数：矩阵乘法——实际上是将矩阵*X*中的九个输入与矩阵*W*中的六个输入组合在一起，得到六个输出——`sigmoid`函数，然后是求和。然而，我们也可以将这看作是一个名为“<math><mrow><mi>W</mi>
    <mi>N</mi> <mi>S</mi> <mi>L</mi></mrow></math>”的单一函数，如[图1-23](#fig_01-24)所示。
- en: '![dlfs 0123](assets/dlfs_0123.png)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0123](assets/dlfs_0123.png)'
- en: 'Figure 1-23\. Another way of describing the nested function: as one function,
    “WNSL”'
  id: totrans-371
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-23. 描述嵌套函数的另一种方式：作为一个函数，“WNSL”
- en: 'Since each function is differentiable, the whole thing is just a single differentiable
    function, with *x*[11] as an input; thus, the gradient is simply the answer to
    the question, what is <math><mfrac><mrow><mi>d</mi><mi>L</mi></mrow> <mrow><mi>d</mi><msub><mi>x</mi>
    <mn>11</mn></msub></mrow></mfrac></math> ? To visualize this, we can simply plot
    how *L* changes as *x*[11] changes. Looking at the initial value of *x*[11], we
    see that it is `-1.5775`:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个函数都是可微的，整个过程只是一个可微函数，以*x*[11]为输入；因此，梯度就是回答问题“<math><mfrac><mrow><mi>d</mi><mi>L</mi></mrow>
    <mrow><mi>d</mi><msub><mi>x</mi> <mn>11</mn></msub></mrow></mfrac></math>”的答案。为了可视化这一点，我们可以简单地绘制*L*随着*x*[11]的变化而变化的情况。看一下*x*[11]的初始值，我们看到它是`-1.5775`：
- en: '[PRE35]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: If we plot the value of *L* that results from feeding *X* and *W* into the computational
    graph defined previously—or, to represent it differently, from feeding `X` and
    `W` into the function called in the preceding code—changing nothing except the
    value for *x*[11] (or `X[0, 0]`), the resulting plot looks like [Figure 1-24](#x11_vs_L_function_matrix_backward).^([5](ch01.html#idm45732627323432))
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们绘制从先前定义的计算图中将*X*和*W*输入的结果得到的*L*的值，或者换一种表示方法，从将`X`和`W`输入到前面代码中调用的函数中得到的结果，除了*x*[11]（或`X[0,
    0]`）的值之外不改变，得到的图像看起来像[图1-24](#x11_vs_L_function_matrix_backward)所示。
- en: '![dlfs 0124](assets/dlfs_0124.png)'
  id: totrans-376
  prefs: []
  type: TYPE_IMG
  zh: '![dlfs 0124](assets/dlfs_0124.png)'
- en: Figure 1-24\. L versus *x*[11], holding other values of X and W constant
  id: totrans-377
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-24. L与*x*[11]的关系，保持X和W的其他值不变
- en: Indeed, eyeballing this relationship in the case of *x*[11], it looks like the
    distance this function increases along the *L*-axis is roughly 0.5 (from just
    over 2.1 to just over 2.6), and we know that we are showing a change of 2 along
    the *x*[11]-axis, which would make the slope roughly <math><mrow><mfrac><mrow><mn>0.5</mn></mrow>
    <mn>2</mn></mfrac> <mo>=</mo> <mn>0.25</mn></mrow></math> —which is exactly what
    we just calculated!
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在*x*[11]的情况下，通过直观观察，这个函数沿着*L*轴增加的距离大约是0.5（从略高于2.1到略高于2.6），我们知道我们正在展示*x*[11]-轴上的变化为2，这将使斜率大约为<math><mrow><mfrac><mrow><mn>0.5</mn></mrow>
    <mn>2</mn></mfrac> <mo>=</mo> <mn>0.25</mn></mrow></math> —这正是我们刚刚计算的！
- en: So our complicated matrix math does in fact seem to have resulted in us correctly
    computing the partial derivative *L* with respect to each element of *X*. Furthermore,
    the gradient of *L* with respect to *W* could be computed similarly.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们复杂的矩阵数学实际上似乎已经使我们正确计算了相对于*X*的每个元素的*L*的偏导数。此外，相对于*W*的*L*的梯度也可以类似地计算。
- en: Note
  id: totrans-380
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'The expression for the gradient of *L* with respect to *W* would be *X*^(*T*).
    However, because of the order in which the *X*^(*T*) expression factors out of
    the derivative for *L*, *X*^(*T*) would be on the *left* side of the expression
    for the gradient of *L* with respect to *W*:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 相对于*W*的*L*的梯度表达式将是*X*^(*T*)。然而，由于*X*^(*T*)表达式从*L*的导数中因子出现的顺序，*X*^(*T*)将位于相对于*W*的*L*的梯度表达式的*左侧*：
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>X</mi> <mi>T</mi></msup>
    <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>S</mi> <mo>)</mo></mrow> <mo>×</mo> <mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>)</mo></mrow></mrow></math>
- en: 'In code, therefore, while we would have `dNdW = np.transpose(X, (1, 0))`, the
    next step would be:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在代码中，虽然我们会有`dNdW = np.transpose(X, (1, 0))`，但下一步将是：
- en: '[PRE37]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: instead of `dLdX = np.dot(dSdN, dNdX)` as before.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是之前的`dLdX = np.dot(dSdN, dNdX`。
- en: Conclusion
  id: totrans-386
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: After this chapter, you should have confidence that you can understand complicated
    nested mathematical functions and reason out how they work by conceptualizing
    them as a series of boxes, each one representing a single constituent function,
    connected by strings. Specifically, you can write code to compute the derivatives
    of the outputs of such functions with respect to any of the inputs, even when
    there are matrix multiplications involving two-dimensional `ndarray`s involved,
    and understand the math behind *why* these derivative computations are correct.
    These foundational concepts are exactly what we’ll need to start building and
    training neural networks in the next chapter, and to build and train deep learning
    models from scratch in the chapters after that. Onward!
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章之后，您应该有信心能够理解复杂的嵌套数学函数，并通过将它们概念化为一系列箱子，每个代表一个单一的组成函数，通过连接的字符串来推理出它们的工作原理。具体来说，您可以编写代码来计算这些函数的输出相对于任何输入的导数，即使涉及到包含二维`ndarray`的矩阵乘法，也能理解这些导数计算背后的数学原理。这些基础概念正是我们在下一章开始构建和训练神经网络所需要的，以及在之后的章节中从头开始构建和训练深度学习模型所需要的。继续前进！
- en: ^([1](ch01.html#idm45732632700344-marker)) This will allow us to easily add
    a bias to our matrix multiplication later on.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.html#idm45732632700344-marker)) 这将使我们能够轻松地在矩阵乘法中添加偏差。
- en: ^([2](ch01.html#idm45732630322664-marker)) Throughout I’ll provide links to
    relevant supplementary material on a GitHub repo that contains the code for the
    book, including for [this chapter](https://oreil.ly/2ZUwKOZ).
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch01.html#idm45732630322664-marker)) 在整个过程中，我将提供指向GitHub存储库的相关补充材料的链接，该存储库包含本书的代码，包括[本章](https://oreil.ly/2ZUwKOZ)的代码。
- en: ^([3](ch01.html#idm45732628068456-marker)) In the following section we’ll focus
    on computing the gradient of `N` with respect to `X`, but the gradient with respect
    to `W` could be reasoned through similarly.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch01.html#idm45732628068456-marker)) 在接下来的部分中，我们将专注于计算`N`相对于`X`的梯度，但相对于`W`的梯度也可以通过类似的方式推理。
- en: ^([4](ch01.html#idm45732627740296-marker)) We do this in [“Matrix Chain Rule”](app01.html#matrix-chain-rule).
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch01.html#idm45732627740296-marker)) 我们在[“矩阵链规则”](app01.html#matrix-chain-rule)中进行了这样的操作。
- en: ^([5](ch01.html#idm45732627323432-marker)) The full function can be found on
    [the book’s website](https://oreil.ly/deep-learning-github); it is simply a subset
    of the `matrix function backward sum` function shown on the previous page.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch01.html#idm45732627323432-marker)) 完整的函数可以在[书的网站](https://oreil.ly/deep-learning-github)找到；它只是前一页显示的`matrix
    function backward sum`函数的一个子集。
