- en: Chapter 3\. AI Communication Cheat Sheet for Executives
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why Plain Language Matters in AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As an executive, using simple language helps your team understand AI concepts
    better. This cheat sheet will show you how to avoid jargon and speak plainly about
    AI. This way, everyone on your team can work together more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: At the end of this chapter, you’ll find a helpful glossary. It explains common
    AI terms in plain language.
  prefs: []
  type: TYPE_NORMAL
- en: Helps Your Team Understand and Work Together
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using simple words breaks down barriers. It makes sure everyone—no matter their
    technical skills—can join the conversation about AI projects. When people understand,
    they feel more involved and responsible. They are more likely to share ideas and
    spot problems when they know what’s going on.
  prefs: []
  type: TYPE_NORMAL
- en: Improves Problem-Solving and Decision Making
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Focusing on actions instead of fancy tools helps your team tackle real challenges.
    When we remove confusing words, it’s easier to agree on goals and make good plans.
    Clear talk leads to better problem-solving because everyone can pitch in without
    feeling left out.
  prefs: []
  type: TYPE_NORMAL
- en: Reframing AI Jargon into Plain Language
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here’s how to translate common technical terms into everyday language that anyone
    can understand.
  prefs: []
  type: TYPE_NORMAL
- en: Examples of Common Terms, Translated
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Changing technical terms into everyday words makes AI easy to understand. The
    following table shows how to say things more simply:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Instead of saying…** | **Say…** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| “We’re implementing a **RAG** approach.” | “We’re making sure the AI always
    has the right information to answer questions well.” |'
  prefs: []
  type: TYPE_TB
- en: '| “We’ll use **few-shot prompting** and **chain-of-thought reasoning**.” |
    “We’ll give examples and encourage the AI to think before it answers.” |'
  prefs: []
  type: TYPE_TB
- en: '| “Our model suffers from **hallucination** issues.” | “Sometimes, the AI makes
    things up, so we need to check its answers.” |'
  prefs: []
  type: TYPE_TB
- en: '| “Let’s adjust the **hyperparameters** to optimize performance.” | “We can
    tweak the settings to make the AI work better.” |'
  prefs: []
  type: TYPE_TB
- en: '| “We need to prevent **prompt injection** attacks.” | “We should make sure
    users can’t trick the AI into ignoring our rules.” |'
  prefs: []
  type: TYPE_TB
- en: '| “Deploy a **multimodal** model for better results.” | “Let’s use an AI that
    understands both text and images.” |'
  prefs: []
  type: TYPE_TB
- en: '| “The AI is **overfitting** on our training data.” | “The AI is too focused
    on old examples and isn’t doing well with new ones.” |'
  prefs: []
  type: TYPE_TB
- en: '| “Consider utilizing **transfer learning** techniques.” | “We can start with
    an existing AI model and adapt it for our needs.” |'
  prefs: []
  type: TYPE_TB
- en: '| “We’re experiencing high **latency** in responses.” | “The AI is taking too
    long to reply; we need to speed it up.” |'
  prefs: []
  type: TYPE_TB
- en: How This Helps Your Team
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By using plain language, everyone can understand and join in. People from all
    parts of your company can share ideas and work together. This reduces confusion
    and helps projects move faster, because everyone knows what’s happening.
  prefs: []
  type: TYPE_NORMAL
- en: Strategies for Promoting Plain Language in Your Organization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now let’s look at specific ways you can encourage clearer communication across
    your teams.
  prefs: []
  type: TYPE_NORMAL
- en: Lead by Example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use simple words when you talk and write. When you make complex ideas easy to
    understand, you show others how to do the same. Your team will likely follow your
    lead when they see that you value clear communication.
  prefs: []
  type: TYPE_NORMAL
- en: Challenge Jargon When It Comes Up
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If someone uses technical terms, ask them to explain in simple words. This helps
    everyone understand and shows that it’s okay to ask questions.
  prefs: []
  type: TYPE_NORMAL
- en: '*Example:* If a team member says, “Our AI needs better **guardrails**,” you
    might ask, “Can you tell me more about that? How can we make sure the AI gives
    safe and appropriate answers?”'
  prefs: []
  type: TYPE_NORMAL
- en: Encourage Open Conversation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Make it okay for people to ask questions and say when they don’t understand.
    Let your team know it’s good to seek clear explanations. This creates a friendly
    environment where ideas can be shared openly.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using plain language in AI isn’t just about making communication easier—it’s
    about helping everyone understand, work together, and succeed with AI projects.
    As a leader, promoting clear talk sets the tone for your whole organization. By
    focusing on actions and challenging jargon, you help your team come up with better
    ideas and solve problems more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Glossary of AI Terms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use this glossary to understand common AI terms in simple language:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Term | Short definition | Why it matters |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **AGI (artificial general intelligence)** | AI that can do any intellectual
    task a human can | While some define AGI as AI that’s as smart as a human in every
    way, this isn’t something you need to focus on right now. It’s more important
    to build AI solutions that solve your specific problems today. |'
  prefs: []
  type: TYPE_TB
- en: '| **Agents** | AI models that can perform tasks or run code without human help
    | Agents can automate complex tasks by making decisions and taking actions on
    their own. This can save time and resources, but you need to watch them carefully
    to make sure they are safe and do what you want. |'
  prefs: []
  type: TYPE_TB
- en: '| **Batch processing** | Handling many tasks at once | If you can wait for
    AI answers, you can process requests in batches at a lower cost. For example,
    OpenAI offers batch processing that’s cheaper but slower. |'
  prefs: []
  type: TYPE_TB
- en: '| **Chain of thought** | Prompting the model to think and plan before answering
    | When the model thinks first, it gives better answers but takes longer. This
    trade-off affects speed and quality. |'
  prefs: []
  type: TYPE_TB
- en: '| **Chunking** | Breaking long texts into smaller parts | Splitting documents
    helps search them better. How you divide them affects your results. |'
  prefs: []
  type: TYPE_TB
- en: '| **Context window** | The maximum text the model can use at once | The model
    has a limit on how much text it can handle. You need to manage this to fit important
    information. |'
  prefs: []
  type: TYPE_TB
- en: '| **Distillation** | Making a smaller, faster model from a big one | It lets
    you use cheaper, faster models with less delay (latency). But, the smaller model
    might not be as accurate or powerful as the big one. So, you trade some performance
    for speed and cost savings. |'
  prefs: []
  type: TYPE_TB
- en: '| **Embeddings** | Turning words into numbers that show meaning | Embeddings
    let you search documents by meaning, not just exact words. This helps you find
    information even if different words are used, making searches smarter and more
    accurate. |'
  prefs: []
  type: TYPE_TB
- en: '| **Few-shot learning** | Teaching the model with only a few examples | By
    giving the model examples, you can guide it to behave the way you want. It’s a
    simple but powerful way to teach the AI what is good or bad. |'
  prefs: []
  type: TYPE_TB
- en: '| **Fine-tuning** | Adjusting a pre-trained model for a specific job | It helps
    make the AI better for your needs by teaching it with your data, but it might
    become less good at general tasks. Fine-tuning works best for specific jobs where
    you need higher accuracy. |'
  prefs: []
  type: TYPE_TB
- en: '| **Frequency penalties** | Settings to stop the model from repeating words
    | Helps make AI responses more varied and interesting, avoiding boring repetition.
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Function calling** | Getting the model to trigger actions or code | Allows
    AI to interact with apps, making it useful for tasks like getting data or automating
    jobs. |'
  prefs: []
  type: TYPE_TB
- en: '| **Guardrails** | Safety rules to control model outputs | Guardrails help
    reduce the chance of the AI giving bad or harmful answers, but they are not perfect.
    It’s important to use them wisely and not rely on them completely. |'
  prefs: []
  type: TYPE_TB
- en: '| **Hallucination** | When AI makes up things that aren’t true | AIs sometimes
    make stuff up, and you can’t completely stop this. It’s important to be aware
    that mistakes can happen, so you should check the AI’s answers. |'
  prefs: []
  type: TYPE_TB
- en: '| **Hyperparameters** | Settings that affect how the model works | By adjusting
    these settings, you can make the AI work better. It often takes trying different
    options to find what works best. |'
  prefs: []
  type: TYPE_TB
- en: '| **Hybrid search** | Combining search methods to get better results | By using
    both keyword and meaning-based search, you get better results. Just using one
    might not work well. Combining them helps people find what they’re looking for
    more easily. |'
  prefs: []
  type: TYPE_TB
- en: '| **Inference** | Getting an answer back from the model | When you ask the
    AI a question and it gives you an answer, that’s called inference. It’s the process
    of the AI making predictions or responses. Knowing this helps you understand how
    the AI works and the time or resources it might need to give answers. |'
  prefs: []
  type: TYPE_TB
- en: '| **Inference endpoint** | Where the model is available for use | Lets you
    use the AI model in your apps or services. |'
  prefs: []
  type: TYPE_TB
- en: '| **Latency** | The time delay in getting a response | Lower latency means
    faster replies, improving user experience. |'
  prefs: []
  type: TYPE_TB
- en: '| **Latent space** | The hidden way the model represents data inside it | Helps
    us understand how the AI processes information. |'
  prefs: []
  type: TYPE_TB
- en: '| **LLM (large language model)** | A big AI model that understands and generates
    text | Powers many AI tools, like chatbots and content creators. |'
  prefs: []
  type: TYPE_TB
- en: '| **Model deployment** | Making the model available online | Needed to put
    AI into real-world use. |'
  prefs: []
  type: TYPE_TB
- en: '| **Multimodal** | Models that handle different data types, like text and images
    | People use words, pictures, and sounds. When AI can understand all these, it
    can help users better. Using multimodal AI makes your tools more powerful. |'
  prefs: []
  type: TYPE_TB
- en: '| **Overfitting** | When a model learns training data too well but fails on
    new data | If the AI is too tuned to old examples, it might not work well on new
    stuff. Getting perfect scores on tests might mean it’s overfitting. You want the
    AI to handle new things, not just repeat what it learned. |'
  prefs: []
  type: TYPE_TB
- en: '| **Pre-training** | The model’s initial learning phase on lots of data | It’s
    like giving the model a big education before it starts specific jobs. This helps
    it learn general things, but you might need to adjust it later for your needs.
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Prompt** | The input or question you give to the AI | Giving clear and
    detailed prompts helps the AI understand what you want. Just like talking to a
    person, good communication gets better results. |'
  prefs: []
  type: TYPE_TB
- en: '| **Prompt engineering** | Designing prompts to get the best results | By learning
    how to write good prompts, you can make the AI give better answers. It’s like
    improving your communication skills to get the best results. |'
  prefs: []
  type: TYPE_TB
- en: '| **Prompt injection** | A security risk where bad instructions are added to
    prompts | Users might try to trick the AI into ignoring your rules and doing things
    you don’t want. Knowing about prompt injection helps you protect your AI system
    from misuse. |'
  prefs: []
  type: TYPE_TB
- en: '| **Prompt templates** | Pre-made formats for prompts to keep inputs consistent
    | They help you communicate with the AI consistently by filling in blanks in a
    set format. This makes it easier to use the AI in different situations and ensures
    you get good results. |'
  prefs: []
  type: TYPE_TB
- en: '| **Rate limiting** | Limiting how many requests can be made in a time period
    | Prevents system overload, keeping services running smoothly. |'
  prefs: []
  type: TYPE_TB
- en: '| **Reinforcement learning from human feedback (RLHF)** | Training AI using
    people’s feedback | It helps the AI learn from what people like or don’t like,
    making its answers better. But it’s a complex method, and you might not need it
    right away. |'
  prefs: []
  type: TYPE_TB
- en: '| **Reranking** | Sorting results to pick the most important ones | When you
    have limited space (like a small context window), reranking helps you choose the
    most relevant documents to show the AI. This ensures the best information is used,
    improving the AI’s answers. |'
  prefs: []
  type: TYPE_TB
- en: '| **Retrieval-augmented generation (RAG)** | Providing relevant context to
    the LLM | A language model needs proper context to answer questions. Like a person,
    it needs access to information such as data, past conversations, or documents
    to give a good answer. Collecting and giving this info to the AI before asking
    it questions helps prevent mistakes or it saying, “I don’t know.” |'
  prefs: []
  type: TYPE_TB
- en: '| **Semantic search** | Searching based on meaning, not just words | It lets
    you search based on meaning, not just exact words, using embeddings. Combining
    it with keyword search (hybrid search) gives even better results. |'
  prefs: []
  type: TYPE_TB
- en: '| **Temperature** | A setting that controls how creative AI responses are |
    Lets you choose between predictable or more imaginative answers. Adjusting temperature
    can affect the quality and usefulness of the AI’s responses. |'
  prefs: []
  type: TYPE_TB
- en: '| **Token limits** | The max number of words or pieces the model handles |
    Affects how much information you can input or get back. You need to plan your
    AI use within these limits, balancing detail and cost. |'
  prefs: []
  type: TYPE_TB
- en: '| **Tokenization** | Breaking text into small pieces the model understands
    | It allows the AI to understand the text. Also, you pay for AI based on the number
    of tokens used, so knowing about tokens helps manage costs. |'
  prefs: []
  type: TYPE_TB
- en: '| **Top-*p* sampling** | Choosing the next word from top choices making up
    a set probability | Balances predictability and creativity in AI responses. The
    trade-off is between safe answers and more varied ones. |'
  prefs: []
  type: TYPE_TB
- en: '| **Transfer learning** | Using knowledge from one task to help with another
    | You can start with a strong AI model someone else made and adjust it for your
    needs. This saves time and keeps the model’s general abilities while making it
    better for your tasks. |'
  prefs: []
  type: TYPE_TB
- en: '| **Transformer** | A type of AI model using attention to understand language
    | They are the main type of model used in generative AI today, like the ones that
    power chatbots and language tools. |'
  prefs: []
  type: TYPE_TB
- en: '| **Vector database** | A special database for storing and searching embeddings
    | They store embeddings of text, images, and more, so you can search by meaning.
    This makes finding similar items faster and improves searches and recommendations.
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Zero-shot learning** | When the model does a new task without training
    or examples | This means you don’t give any examples to the AI. While it’s good
    for simple tasks, not providing examples might make it harder for the AI to perform
    well on complex tasks. Giving examples helps, but takes up space in the prompt.
    You need to balance prompt space with the need for examples. |'
  prefs: []
  type: TYPE_TB
- en: In [Chapter 4](ch04.html#ch04), we’ll reveal a counterintuitive approach to
    AI strategy that can save you time and resources in the long run.
  prefs: []
  type: TYPE_NORMAL
