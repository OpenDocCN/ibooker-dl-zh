<html><head></head><body>
  <div class="readable-text" id="p1"> &#13;
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">appendix A</span></span> <span class="chapter-title-text">Mathematical foundations</span></h1> &#13;
  </div> &#13;
  <div class="readable-text" id="p2"> &#13;
   <h2 class=" readable-text-h2"><span class="num-string">A.1</span> List of clustering algorithms </h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p3"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.1</span> Partitioning-based algorithms</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p4"> k-means </li> &#13;
   <li class="readable-text" id="p5"> k-medoids (PAM) </li> &#13;
   <li class="readable-text" id="p6"> CLARA (Clustering Large Applications) </li> &#13;
   <li class="readable-text" id="p7"> CLARANS (Clustering Large Applications based on Randomized Search) </li> &#13;
   <li class="readable-text" id="p8"> Mini-Batch k-means </li> &#13;
   <li class="readable-text" id="p9"> Fuzzy C-Means (FCM) </li> &#13;
   <li class="readable-text" id="p10"> k-modes </li> &#13;
   <li class="readable-text" id="p11"> k-prototypes </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p12"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.2</span> Hierarchical clustering</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p13"> Agglomerative Hierarchical Clustering </li> &#13;
   <li class="readable-text" id="p14"> Divisive Hierarchical Clustering </li> &#13;
   <li class="readable-text" id="p15"> BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies) </li> &#13;
   <li class="readable-text" id="p16"> CURE (Clustering Using Representatives) </li> &#13;
   <li class="readable-text" id="p17"> Chameleon </li> &#13;
   <li class="readable-text" id="p18"> ROCK (Robust Clustering using Links) </li> &#13;
   <li class="readable-text" id="p19"> HIERDENC (Hierarchical Density-Based Clustering) </li> &#13;
   <li class="readable-text" id="p20"> HAC-S (Hierarchical Agglomerative Clustering with Spatial Constraints) </li> &#13;
   <li class="readable-text" id="p21"> EAC (Ensemble Agglomerative Clustering) </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p22"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.3</span> Density-based algorithms</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p23"> DBSCAN (Density-Based Spatial Clustering of Applications with Noise) </li> &#13;
   <li class="readable-text" id="p24"> OPTICS (Ordering Points To Identify the Clustering Structure) </li> &#13;
   <li class="readable-text" id="p25"> HDBSCAN (Hierarchical DBSCAN) </li> &#13;
   <li class="readable-text" id="p26"> DENCLUE (Density-Based Clustering) </li> &#13;
   <li class="readable-text" id="p27"> Mean Shift </li> &#13;
   <li class="readable-text" id="p28"> VDBSCAN (Variable Density-Based Spatial Clustering) </li> &#13;
   <li class="readable-text" id="p29"> DBCLASD (Distribution-Based Clustering of Large Spatial Databases) </li> &#13;
   <li class="readable-text" id="p30"> LDBSCAN (Labeled DBSCAN) </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p31"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.4</span> Grid-based algorithms</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p32"> STING (Statistical Information Grid) </li> &#13;
   <li class="readable-text" id="p33"> WaveCluster </li> &#13;
   <li class="readable-text" id="p34"> SUBCLU (Subspace Clustering) </li> &#13;
   <li class="readable-text" id="p35"> GRIDCLUS (Grid-based Clustering Algorithm) </li> &#13;
   <li class="readable-text" id="p36"> OptiGrid </li> &#13;
   <li class="readable-text" id="p37"> CLIQUE (Clustering in Quest) </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p38"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.5</span> Model-based algorithms</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p39"> Gaussian Mixture Model (GMM) </li> &#13;
   <li class="readable-text" id="p40"> EM (Expectation Maximization) Algorithm </li> &#13;
   <li class="readable-text" id="p41"> DBEM (Density-Based EM) </li> &#13;
   <li class="readable-text" id="p42"> Bayesian Gaussian Mixture Model </li> &#13;
   <li class="readable-text" id="p43"> Hidden Markov Model (HMM) Clustering </li> &#13;
   <li class="readable-text" id="p44"> X-Means (Extended k-means) </li> &#13;
   <li class="readable-text" id="p45"> G-Means (Gaussian Means) </li> &#13;
   <li class="readable-text" id="p46"> MCLUST (Model-based Clustering using EM) </li> &#13;
   <li class="readable-text" id="p47"> AUTOCLASS (Bayesian Model-based Clustering) </li> &#13;
   <li class="readable-text" id="p48"> Mixmod (Mixture Models for Clustering) </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p49"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.6</span> Spectral clustering</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p50"> Ratio Cut Clustering </li> &#13;
   <li class="readable-text" id="p51"> Normalized Cut Clustering </li> &#13;
   <li class="readable-text" id="p52"> Multiway Spectral Clustering </li> &#13;
   <li class="readable-text" id="p53"> Spectral Biclustering </li> &#13;
   <li class="readable-text" id="p54"> Shi-Malik Clustering </li> &#13;
   <li class="readable-text" id="p55"> Laplacian Eigenmaps for Clustering </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p56"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.7</span> Graph-based clustering</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p57"> Connected Components Clustering </li> &#13;
   <li class="readable-text" id="p58"> Markov Clustering (MCL) </li> &#13;
   <li class="readable-text" id="p59"> Girvan-Newman Clustering </li> &#13;
   <li class="readable-text" id="p60"> Louvain Method for Community Detection </li> &#13;
   <li class="readable-text" id="p61"> Infomap Algorithm </li> &#13;
   <li class="readable-text" id="p62"> Walktrap Algorithm </li> &#13;
   <li class="readable-text" id="p63"> Edge Betweenness Clustering </li> &#13;
   <li class="readable-text" id="p64"> Chinese Whispers Clustering </li> &#13;
   <li class="readable-text" id="p65"> SPICi (Speed and Performance In Clustering) </li> &#13;
   <li class="readable-text" id="p66"> SCPS (Spectral Clustering on Perona &amp; Shi’s graph) </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p67"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.8</span> Subspace and high-dimensional clustering</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p68"> PROCLUS (Projected Clustering) </li> &#13;
   <li class="readable-text" id="p69"> SUBCLU (Subspace Clustering) </li> &#13;
   <li class="readable-text" id="p70"> ENCLUS (Entropy-Based Subspace Clustering) </li> &#13;
   <li class="readable-text" id="p71"> ORCLUS (Orthogonal Subspace Clustering) </li> &#13;
   <li class="readable-text" id="p72"> FSSC (Fast Subspace Clustering) </li> &#13;
   <li class="readable-text" id="p73"> P3C (Pattern-based Subspace Clustering) </li> &#13;
   <li class="readable-text" id="p74"> FIRES (Frequent Itemset Clustering) </li> &#13;
   <li class="readable-text" id="p75"> SNN (Shared Nearest Neighbor Clustering) </li> &#13;
   <li class="readable-text" id="p76"> High-Dimensional Spectral Clustering </li> &#13;
   <li class="readable-text" id="p77"> LAC (Locally Adaptive Clustering) </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p78"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.9</span> Fuzzy and soft clustering</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p79"> Fuzzy C-Means </li> &#13;
   <li class="readable-text" id="p80"> Gustafson-Kessel Algorithm </li> &#13;
   <li class="readable-text" id="p81"> Fuzzy Min-Max Clustering </li> &#13;
   <li class="readable-text" id="p82"> Possibilistic C-Means (PCM) </li> &#13;
   <li class="readable-text" id="p83"> FCM-GA (Fuzzy C-Means with Genetic Algorithms) </li> &#13;
   <li class="readable-text" id="p84"> FCM-SC (Fuzzy C-Means with Spatial Constraints) </li> &#13;
   <li class="readable-text" id="p85"> Fuzzy Subspace Clustering </li> &#13;
   <li class="readable-text" id="p86"> Fuzzy SOM (Self-Organizing Maps) </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p87"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.10</span> Constraint-based clustering</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p88"> COP-k-means (Constrained k-means) </li> &#13;
   <li class="readable-text" id="p89"> Constrained DBSCAN </li> &#13;
   <li class="readable-text" id="p90"> C-DBSCAN (ConstraintBased DBSCAN) </li> &#13;
   <li class="readable-text" id="p91"> PCKMeans (Pairwise Constrained k-means) </li> &#13;
   <li class="readable-text" id="p92"> Semisupervised k-means </li> &#13;
   <li class="readable-text" id="p93"> FCM with Must-Link and Cannot-Link Constraints </li> &#13;
   <li class="readable-text" id="p94"> Hard k-means with Constraints </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p95"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.11</span> Evolutionary and genetic clustering</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p96"> Genetic Algorithm-Based Clustering </li> &#13;
   <li class="readable-text" id="p97"> GA-KMeans (Genetic Algorithm with k-means) </li> &#13;
   <li class="readable-text" id="p98"> AGCT (Agglomerative Genetic Clustering) </li> &#13;
   <li class="readable-text" id="p99"> MEPSO (Multi-Elitist Particle Swarm Optimization for Clustering) </li> &#13;
   <li class="readable-text" id="p100"> NSGA-II (Nondominated Sorting Genetic Algorithm-II for Clustering) </li> &#13;
   <li class="readable-text" id="p101"> ACO-CLUSTER (Ant Colony Optimization for Clustering) </li> &#13;
   <li class="readable-text" id="p102"> GCUK (Genetic Clustering with Unsupervised k-means) </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p103"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.12</span> Neural network-based clustering</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p104"> Self-Organizing Maps (SOM) </li> &#13;
   <li class="readable-text" id="p105"> Neural Gas </li> &#13;
   <li class="readable-text" id="p106"> Growing Neural Gas </li> &#13;
   <li class="readable-text" id="p107"> Autoencoder-Based Clustering </li> &#13;
   <li class="readable-text" id="p108"> Deep Embedded Clustering (DEC) </li> &#13;
   <li class="readable-text" id="p109"> Generative Topographic Mapping (GTM) </li> &#13;
   <li class="readable-text" id="p110"> DeepCluster (Deep Learning for Clustering) </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p111"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.1.13</span> Other algorithms</h3> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p112"> Affinity Propagation </li> &#13;
   <li class="readable-text" id="p113"> Bisecting k-means </li> &#13;
   <li class="readable-text" id="p114"> Hybrid BIRCH-k-means </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p115"> &#13;
   <h2 class=" readable-text-h2"><span class="num-string">A.2</span> What is a centroid?</h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p116"> &#13;
   <p>A centroid is the central point in a cluster. In geometry, it is the arithmetic mean or the average of all the points in a shape. For example, in a triangle, the centroid is the point where all the medians intersect (see figure A.1). In any other shape, it would be simply an average of all the point coordinates.<span class="aframe-location"/></p> &#13;
  </div> &#13;
  <div class="browsable-container figure-container" id="p117"> &#13;
   <img alt="figure" src="../Images/APPA_F01_Verdhan.png"/> &#13;
   <h5 class=" figure-container-h5"><span class="num-string">Figure A.1</span> Examples of centroids</h5>&#13;
  </div> &#13;
  <div class="readable-text" id="p118"> &#13;
   <h2 class=" readable-text-h2"><span class="num-string">A.3</span> L1 vs. L2 norm</h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p119"> &#13;
   <p>The L1 norm is the sum of the absolute value of the entries in a vector; on the other hand, the L2 norm is the square root of the sum of the squares of the entries in the vector. It is the core difference between L1 and L2 norm.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p120"> &#13;
   <h2 class=" readable-text-h2"><span class="num-string">A.4</span> Different scaling techniques used in the industry</h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p121"> &#13;
   <p>The data we get can have different units and values. A dataset can have a variable ranging from 1 to 10 while another variable in the same dataset can range from 1,000 to 100,000. Normalizing the data allows us to normalize it or limit the data between a range. It allows us to fit machine learning better on this normalized dataset.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p122"> &#13;
   <p>We normalize a dataset to adjust the values of different variables that are at quite different scales to a common scale. An example is shown in figure A.2.<span class="aframe-location"/></p> &#13;
  </div> &#13;
  <div class="browsable-container figure-container" id="p123"> &#13;
   <img alt="figure" src="../Images/APPA_F02_Verdhan.png"/> &#13;
   <h5 class=" figure-container-h5"><span class="num-string">Figure A.2</span> In the first table, we have the mean and standard deviation for each of the variables. Once the data is normalized, then the mean and standard deviation become zero as shown in the second table. </h5>&#13;
  </div> &#13;
  <div class="readable-text" id="p124"> &#13;
   <p>There are different ways to normalize a dataset. The two most popular ones are</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p125"> <em>Standardization</em><em> </em>—This involves using the mean and standard deviation for normalizing a dataset. It is also known as <em>z-transformation</em>. It standardizes all the variables; the data becomes normally distributed, and all the features become comparable. The equation used is shown in equation A.1: </li> &#13;
  </ul> &#13;
  <div class="browsable-container figure-container" id="p126"> &#13;
   <img alt="figure" src="../Images/verdhan-appA-eqs-0x.png"/>&#13;
   <h5 class=" figure-container-h5">(A.1)</h5>&#13;
  </div> &#13;
  <div class="readable-text list-body-item" id="p127"> &#13;
   <p>where <em>μ</em> is the mean and <em class="obliqued">σ</em> is the standard deviation.</p> &#13;
  </div> &#13;
  <div class="readable-text list-body-item" id="p128"> &#13;
   <p>As we can observe in figure A.2, right, all the variables now have a mean of 0 and a standard deviation of 1.</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p129"> <em>Min-max scaling</em><em> </em>—This utilizes the maximum and minimum values of a variable using equation A.2: </li> &#13;
  </ul> &#13;
  <div class="browsable-container figure-container" id="p130"> &#13;
   <img alt="figure" src="../Images/verdhan-appA-eqs-1x.png"/>&#13;
   <h5 class=" figure-container-h5">(A.2)</h5>&#13;
  </div> &#13;
  <div class="readable-text" id="p131"> &#13;
   <p>Normalizing a dataset is one of the important steps followed during the machine learning process. </p> &#13;
  </div> &#13;
  <div class="readable-text" id="p132"> &#13;
   <h2 class=" readable-text-h2"><span class="num-string">A.5</span> Time complexity O(n) </h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p133"> &#13;
   <p>Time complexity is a computational concept used to measure and estimate the amount of time an algorithm will take to complete as a function of the length of the input. Generally expressed using Big O notation, time complexity is used to classify the algorithms as per their worst-case or average-case run-time performance.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p134"> &#13;
   <p>Key aspects of time complexity include</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p135"> <em>Constant time [O (1)]</em><em> </em>—The algorithm’s run time does not change with the size of the input. </li> &#13;
   <li class="readable-text" id="p136"> <em>Logarithmic time [O (log n)]</em><em> </em>—The run time grows logarithmically as the input size increases. This often occurs in algorithms that halve the problem size at each step, like binary search. </li> &#13;
   <li class="readable-text" id="p137"> <em>Linear time [O(n)]</em><em> </em>—The run time increases linearly with the size of the input. </li> &#13;
   <li class="readable-text" id="p138"> <em>Linearithmic time [O (n log n)]</em><em> </em>—This is common in efficient sorting algorithms like mergesort and heapsort. </li> &#13;
   <li class="readable-text" id="p139"> <em>Quadratic time [O (n²)]</em><em> </em>—The run time grows quadratically with the input size, often seen in algorithms with nested loops. </li> &#13;
   <li class="readable-text" id="p140"> <em>Exponential time [O (2^n)]</em><em> </em>—The run time doubles with each additional element in the input, typical in some recursive algorithms. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p141"> &#13;
   <p>Understanding time complexity helps in evaluating the efficiency of algorithms and choosing the right one for a given problem.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p142"> &#13;
   <h2 class=" readable-text-h2"><span class="num-string">A.6</span> How to install packages in Python</h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p143"> &#13;
   <p>In Python, generally the <code>pip</code> command is used to install packages. The steps are as follows:</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p144"> Open your command-line interface (Terminal, Command Prompt, or PowerShell). Type <code>pip</code> <code>install</code> <code>package_name</code>. For example, if you want to install <code>numpy</code>, type <code>pip install</code> <code>numpy</code>. </li> &#13;
   <li class="readable-text" id="p145"> If you want to install a specific version, use <code>pip</code> <code>install</code> <code>package_name== version_number</code>. For example, if you want to install <code>numpy</code> <code>1.21.0</code>, type <code>pip</code> <code>install numpy==1.21.0</code>. </li> &#13;
   <li class="readable-text" id="p146"> Installing from a requirement file, you can create a <code>requirements.text</code> file with all the packages’ information and then install it: <code>pip</code> <code>install</code> <code>-r</code> <code>requirements.text</code>. </li> &#13;
   <li class="readable-text" id="p147"> Sometimes you might have to upgrade a package. Then the command is <code>pip install</code> <code>–upgrade</code> <code>package_name</code>. An example is <code>pip install</code> <code>-–upgrade</code> <code>numpy</code>. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p148"> &#13;
   <h2 class=" readable-text-h2"><span class="num-string">A.7</span> Correlation </h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p149"> &#13;
   <p>Correlation is a statistical and mathematical key performance indicator to measure the extent to which two variables are related. It is used to decipher the relationship between variables, indicating whether an increase in one variable tends to result in an increase (positive correlation) or a decrease (negative correlation) in another.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p150"> &#13;
   <p>Key types of correlation are</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p151"> <em>Positive correlation</em><em> </em>—As one variable increases, the other also increases. For example, height and weight often show a positive correlation. </li> &#13;
   <li class="readable-text" id="p152"> <em>Negative correlation</em><em> </em>—As one variable increases, the other decreases. For example, many times, when the price of an item increases, the demand decreases, and that is a negative correlation. </li> &#13;
   <li class="readable-text" id="p153"> <em>No correlation</em><em> </em><em>—</em>This is when there is no apparent relationship between the two variables. For example, the amount of ice cream sold and the number of TVs sold might show no correlation. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p154"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.7.1</span> Correlation coefficient</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p155"> &#13;
   <p>The strength and direction of a correlation are quantified by the correlation coefficient, typically denoted as <em>r</em>. It ranges from –1 to 1:</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p156"> <em>r = 1</em><em> </em>—Perfect positive correlation </li> &#13;
   <li class="readable-text" id="p157"> <em>r = –1</em><em> </em><em>—</em>Perfect negative correlation </li> &#13;
   <li class="readable-text" id="p158"> <em>r = 0</em><em> </em><em>—</em>No correlation </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p159"> &#13;
   <p>Values between –1 and 1 indicate varying degrees of correlation.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p160"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.7.2</span> Uses of correlation</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p161"> &#13;
   <p>Correlation is used in many fields, including the following:</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p162"> <em>Data analysis</em><em> </em>—Correlation helps analysts identify relationships between variables and helps in further analysis or research. </li> &#13;
   <li class="readable-text" id="p163"> <em>Predictive modeling</em><em> </em>—In machine learning and predictive modeling, a model’s performance can be improved if we understand the relationship between the variables. </li> &#13;
   <li class="readable-text" id="p164"> <em>Finance</em><em> </em>—Investors and financial advisors use correlation analysis to assess the relationships between asset prices, different factors, and reasons to invest, which helps in investment and portfolio diversification strategies. </li> &#13;
   <li class="readable-text" id="p165"> <em>Healthcare</em><em> </em>—Researchers in the health sector collect the data on lifestyle factors (like diet, smoking, exercise) and demographics and examine correlations between these factors and health outcomes to identify potential risk factors like heart attack, diabetes, etc. </li> &#13;
   <li class="readable-text" id="p166"> <em>Social sciences</em><em> </em>—In fields like psychology and sociology, correlation is used to explore relationships between consumer behaviors, population attitudes, and demographic factors. These studies help uncover relationships in purchasing patterns, reviews, and feedback. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p167"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.7.3</span> Important considerations</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p168"> &#13;
   <p>Keep the following ideas in mind when considering correlation:</p> &#13;
  </div> &#13;
  <ul> &#13;
   <li class="readable-text" id="p169"> Correlation does not imply causation. Just because two variables are correlated does not mean that one causes the other. There might be other factors involved too, or it might be a coincidence. For example, we might find that the sale of ice cream is positively correlated to the number of shark attacks. Hence, we deduce that ice cream sales affect shark attacks—that is absurd. The real reason is ice cream sales increase during the summer season, which is when more people visit beaches. </li> &#13;
   <li class="readable-text" id="p170"> There may be outliers. Extreme values can distort correlation coefficients, so it’s important to be vigilant on the outliers. Many times if we simply visualize the data with scatter plots, we might get the true relationship. </li> &#13;
   <li class="readable-text" id="p171"> There may be nonlinear relationships. Correlation coefficients measure linear relationships. If the true relationship between the two variables is nonlinear, correlation might not capture it. </li> &#13;
  </ul> &#13;
  <div class="readable-text" id="p172"> &#13;
   <p>Understanding correlation is fundamental in various fields and often one of the very first steps. It can be useful to uncover insights that help further drive strategic decisions and the overall path ahead.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p173"> &#13;
   <h2 class=" readable-text-h2"><span class="num-string">A.8</span> Time-series analysis</h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p174"> &#13;
   <p>Time-series analysis involves the study of data points that are collected or recorded at specific time intervals like hourly/daily/weekly/monthly/yearly or others. It is used for examining and understanding trends and behaviors, seasonal patterns and relationships, and cyclical behaviors over time periods, and hence understanding the pattern will be helpful in forecasting. For example, if we want to predict the temperature or rainfall or if we wish to predict the demand for an item, it can involve time-series analysis. </p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p175"> &#13;
   <p>Time-series analysis is commonly used in fields like marketing, finance, environmental studies, and geographic and economic forecasting to predict future values based on historical data. Though there are quite a few techniques, the most common ones are moving averages, exponential smoothing, and ARIMA. Visualization methods, like line graphs, are essential for identifying patterns and anomalies within the data. Overall, time-series analysis is a useful technique for understanding time-based patterns in the data and for making informed predictions and forecasts.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p176"> &#13;
   <h2 class=" readable-text-h2"><span class="num-string">A.9</span> Mathematical foundation for data representation</h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p177"> &#13;
   <p>There are quite a few mathematical terms one must understand to develop a thorough understanding of algorithms. They are useful for understanding the concepts and the mathematical foundation and are imperative for dimensionality reduction methods like principal component analysis and singular value decomposition explored in chapter 3. These mathematical operations are intuitive enough, and you might have covered them in your earlier mathematical courses, but it is important that we refresh the concepts here. The concepts examined are nothing new but are sometimes complex to interpret and comprehend. </p> &#13;
  </div> &#13;
  <div class="readable-text print-book-callout" id="p178"> &#13;
   <p><span class="print-book-callout-head">NOTE </span> The coding of these concepts in Python can be tricky sometimes. Fortunately, there are quite a few robust libraries and packages that provide easier solutions, and hence we don’t have to worry about the implementation of these concepts in Python.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p179"> &#13;
   <p>We are trying to reduce the number of dimensions of a dataset. A dataset is nothing but a matrix of values; hence, a lot of the concepts are related to matrix manipulation methods, their geometrical representation, and performing transformations on such matrices. The major concepts are studied next.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p180"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.9.1</span> Scalar and vector</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p181"> &#13;
   <p>In simple language, if you walk a distance of 5 km it is scalar; if you walk a distance of 5 km in a direction, say north, it is a vector. So we can say that a vector is a mathematical object that has a magnitude and a direction. Without the direction, it is just a scalar value. We cite a few examples of each in table A.1.</p> &#13;
  </div> &#13;
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p182"> &#13;
   <h5 class=" browsable-container-h5"><span class="num-string">Table A.1</span> Examples of scalar and vector quantities </h5> &#13;
   <table> &#13;
    <thead> &#13;
     <tr> &#13;
      <th> &#13;
       <div>&#13;
        Examples of scalar quantities&#13;
       </div> </th> &#13;
      <th> &#13;
       <div>&#13;
        Examples of vector quantities&#13;
       </div> </th> &#13;
     </tr> &#13;
    </thead> &#13;
    <tbody> &#13;
     <tr> &#13;
      <td> Length, width, height, distance<br/> </td> &#13;
      <td> Displacement<br/> </td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td> Mass, area, density, volume<br/> </td> &#13;
      <td> Weight, force<br/> </td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td> Pressure, temperature, energy, entropy<br/> </td> &#13;
      <td> Lift, drag, thrust<br/> </td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td> Speed, time, work, power<br/> </td> &#13;
      <td> Velocity, acceleration, momentum<br/> </td> &#13;
     </tr> &#13;
    </tbody> &#13;
   </table> &#13;
  </div> &#13;
  <div class="readable-text" id="p183"> &#13;
   <p>In plain words, we can conclude that a vector is a scalar with a direction. </p> &#13;
  </div> &#13;
  <div class="readable-text" id="p184"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.9.2</span> Standard deviation and variance</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p185"> &#13;
   <p>The purpose of standard deviation and variance is to measure how spread the data is. Standard deviation is given by equation A.3</p> &#13;
  </div> &#13;
  <div class="browsable-container figure-container" id="p186"> &#13;
   <img alt="figure" src="../Images/verdhan-appA-eqs-2x.png"/>&#13;
   <h5 class=" figure-container-h5">(A.3)</h5>&#13;
  </div> &#13;
  <div class="readable-text" id="p187"> &#13;
   <p>where <em>x</em><sub><em>i</em></sub> is each value from the population, <em>μ</em> the mean of the population, <em>n</em> is the population size or the number of observations, and <em class="obliqued">σ</em> is the standard deviation of the population. And variance is given by equation A.4</p> &#13;
  </div> &#13;
  <div class="browsable-container figure-container" id="p188"> &#13;
   <img alt="figure" src="../Images/verdhan-appA-eqs-3x.png"/>&#13;
   <h5 class=" figure-container-h5">(A.4)</h5>&#13;
  </div> &#13;
  <div class="readable-text" id="p189"> &#13;
   <p>where <em>x</em><sub><em>i</em></sub> is each value from the population, <em>xbar</em> is the mean value of the observations, <em>n</em> is the number of observations, and <em>S</em><sup><sub>2</sub></sup> is the sample variance.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p190"> &#13;
   <p>Suppose we have five children in a class with respective heights of 50, 51, 52, 53, and 54 inches. The average height is (50+51+52+53+54)/5 = 52 inches. See table A.2.</p> &#13;
  </div> &#13;
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p191"> &#13;
   <h5 class=" browsable-container-h5"><span class="num-string">Table A.2</span> Child height and the calculated difference between the average and height</h5> &#13;
   <table> &#13;
    <thead> &#13;
     <tr> &#13;
      <th> &#13;
       <div>&#13;
        Child&#13;
       </div> </th> &#13;
      <th> &#13;
       <div>&#13;
        Height&#13;
       </div> </th> &#13;
      <th> &#13;
       <div>&#13;
        Difference &#13;
       </div> &#13;
       <div>&#13;
        (Average – Height)&#13;
       </div> </th> &#13;
     </tr> &#13;
    </thead> &#13;
    <tbody> &#13;
     <tr> &#13;
      <td> A<br/> </td> &#13;
      <td> 50<br/> </td> &#13;
      <td> 52 – 50 = 2<br/> </td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td> B<br/> </td> &#13;
      <td> 51<br/> </td> &#13;
      <td> 52 – 51 = 1<br/> </td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td> C<br/> </td> &#13;
      <td> 52<br/> </td> &#13;
      <td> 52 – 52 = 0<br/> </td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td> D<br/> </td> &#13;
      <td> 53<br/> </td> &#13;
      <td> 52 – 53 = –1<br/> </td> &#13;
     </tr> &#13;
     <tr> &#13;
      <td> E<br/> </td> &#13;
      <td> 54<br/> </td> &#13;
      <td> 52 – 54 = –2<br/> </td> &#13;
     </tr> &#13;
    </tbody> &#13;
   </table> &#13;
  </div> &#13;
  <div class="readable-text" id="p192"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.9.3</span> Covariance and correlation</h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p193"> &#13;
   <p>Covariance and correlation are the measurements of the relationship and mutual dependency between two variables. Covariance is the direction of the linear relationship, while correlation measures the strength and direction of the relationship. See figure A.3.<span class="aframe-location"/></p> &#13;
  </div> &#13;
  <div class="browsable-container figure-container" id="p194"> &#13;
   <img alt="figure" src="../Images/APPA_F03_Verdhan.png"/> &#13;
   <h5 class=" figure-container-h5"><span class="num-string">Figure A.3</span> If <em>X</em> is increasing, then the value of <em>Y</em> is also increasing (left). If <em>X</em> is increasing, <em>Y</em> is decreasing (middle). There is no observed relationship between <em>X</em> and <em>Y (right)</em>. </h5>&#13;
  </div> &#13;
  <div class="readable-text" id="p195"> &#13;
   <p>Figure A.3, left, shows that when <em>X</em> decreases, <em>Y</em> increases, and vice versa in the middle, while on the right, there seems to be no relationship between the two variables. Here, covariance will simply denote that there is a positive or a negative or no relationship between the variables. The magnitude of covariance will be difficult to comprehend as it is not a normalized result. Correlation, on the other hand, will be able to provide a magnitude of the strength too. Correlation can be calculated by dividing the covariance of the two variables by the product of the standard deviations.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p196"> &#13;
   <p>The most popular correlation coefficient is Pearson’s correlation coefficient, which only considers the linear relationship between two variables. The other widely used coefficient is Spearman’s rank correlation, which is more sensitive to nonlinear relationships. We can visualize correlation as shown in figure A.4.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p197"> &#13;
   <p>Correlation does not mean causation. This is the most common mistake made during analysis. For example, consider the statement “There is an increase in sales of shoes, and at the same time there is a decrease in the rate of drowning deaths”. If the inference made is that an increase in shoe sales leads to a decrease in drowning deaths, the result is a completely illogical result. This proves that correlation does not mean causation. </p> &#13;
  </div> &#13;
  <div class="browsable-container figure-container" id="p198"> &#13;
   <img alt="figure" src="../Images/APPA_F04_Verdhan.png"/> &#13;
   <h5 class=" figure-container-h5"><span class="num-string">Figure A.4</span> In the first case, there is a positive correlation between the two variables. In the second case, there is a negative correlation between the two variables. In the third case, there is no observed relationship between the two variables.</h5>&#13;
  </div> &#13;
  <div class="readable-text" id="p199"> &#13;
   <p>The indicators are used to test if there is any relationship between two variables in the datasets. The concept is utilized and referred to in data science quite often. We analyze the strength of the relationship and decide whether a logical trend exists.</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p200"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.9.4</span> Matrix decomposition, eigenvectors, and eigenvalues </h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p201"> &#13;
   <p>Sometimes in linear algebra we wish to factorize a matrix into a product of matrices; this process is called <em>matrix decomposition</em>. We use matrix decomposition methods if we want to represent a matrix into a product of matrices. </p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p202"> &#13;
   <p>Eigenvectors and eigenvalues are components of matrix decomposition. If we have a square matrix <em>A</em>, then the understanding is as shown in equation A.5</p> &#13;
  </div> &#13;
  <div class="browsable-container equation-container" id="p203">&#13;
   <h5 class=" browsable-container-h5">(A.5)</h5> &#13;
   <p>A*v = <em class="obliqued">λ</em>*v</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p204"> &#13;
   <p>where <em>v</em> is the eigenvector and <em class="obliqued">λ</em> is the eigenvalue.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p205"> &#13;
   <p>For example, let’s say we have a matrix, as shown in figure A.5, and we want to get the eigenvector. Here, –2 is the eigenvalue, and [1 –2 1] is the eigenvector. The eigenvector is a nonzero vector that does not change direction during the transformation. It only scales the original matrix by a factor of <em class="obliqued">λ</em>. The eigenvectors and eigenvalues are utilized for principal component analysis (PCA) implementation.<span class="aframe-location"/></p> &#13;
  </div> &#13;
  <div class="browsable-container figure-container" id="p206"> &#13;
   <img alt="figure" src="../Images/APPA_F05_Verdhan.png"/> &#13;
   <h5 class=" figure-container-h5"><span class="num-string">Figure A.5</span> Finding eigenvectors and eigenvalues</h5>&#13;
  </div> &#13;
  <div class="readable-text" id="p207"> &#13;
   <h3 class=" readable-text-h3"><span class="num-string">A.9.5</span> Special matrices </h3> &#13;
  </div> &#13;
  <div class="readable-text" id="p208"> &#13;
   <p>We next define a few special matrices. </p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p209"> &#13;
   <p>A <em>diagonal matrix</em> has all the nondiagonal elements as zero, as shown in figure A.6.<span class="aframe-location"/></p> &#13;
  </div> &#13;
  <div class="browsable-container figure-container" id="p210"> &#13;
   <img alt="figure" src="../Images/APPA_F06_Verdhan.png"/> &#13;
   <h5 class=" figure-container-h5"><span class="num-string">Figure A.6</span> An example of a diagonal matrix</h5>&#13;
  </div> &#13;
  <div class="readable-text" id="p211"> &#13;
   <p>An<em> orthogonal matrix </em>is a square matrix that fulfills the following criteria as shown in equation A.6</p> &#13;
  </div> &#13;
  <div class="browsable-container equation-container" id="p212">&#13;
   <h5 class=" browsable-container-h5">(A.6)</h5> &#13;
   <p><em>Q</em><sup><em>T</em></sup><em>Q</em> = <em>Q</em><em>Q</em><sup><em>T</em></sup> = <em>I</em></p> &#13;
  </div> &#13;
  <div class="readable-text" id="p213"> &#13;
   <p>where <em>Q</em> is the original matrix, <em>Q</em><sup><em>T</em></sup> is its transpose, and <em>I</em> is the identity matrix, represented in figure A.7.<span class="aframe-location"/></p> &#13;
  </div> &#13;
  <div class="browsable-container figure-container" id="p214"> &#13;
   <img alt="figure" src="../Images/APPA_F07_Verdhan.png"/> &#13;
   <h5 class=" figure-container-h5"><span class="num-string">Figure A.7</span> An example of an orthogonal matrix</h5>&#13;
  </div> &#13;
  <div class="readable-text" id="p215"> &#13;
   <p>A matrix is <em>symmetric</em> if its transpose is equal to itself (i.e., <em>Q</em><sup><em>T</em></sup> = <em>Q</em>).</p> &#13;
  </div> &#13;
  <div class="readable-text" id="p216"> &#13;
   <h2 class=" readable-text-h2"><span class="num-string">A.10</span> Hyperparameters vs. parameters</h2> &#13;
  </div> &#13;
  <div class="readable-text" id="p217"> &#13;
   <p>Parameters are the internal values that a model learns from the training of the machine learning model. They are, for example, coefficients in a regression model or weights/biases in a neural network. They are set automatically during the training of the machine learning model.</p> &#13;
  </div> &#13;
  <div class="readable-text intended-text" id="p218"> &#13;
   <p>Hyperparameters, on the other hand, are predefined before the training starts and control the machine learning model. Examples are the number of clusters (<em>k</em>) in k-means clustering or the distance metrics used. They are chosen manually and can be optimized using various techniques like GridSearch CV or Random Search CV.</p> &#13;
  </div>&#13;
 

  <div class="readable-text">
   <h1>index</h1>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">SYMBOLS</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p120">.info command[info command]</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p237">&lt;Emphasis&gt;Computational Network Science&lt;Default Para Font&gt; (Hexmoor)</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">A</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p57">affinity matrix</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p107">Autoencoder-Based Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p112">Affinity Propagation</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p1">autoencoders</a>, <a href="../Text/chapter-9.html#p18">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-9.html#p48">applications of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-9.html#p22">components of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-9.html#p11">feature learning</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-9.html#p95">practical next steps and suggested readings</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-9.html#p55">types of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p6">association rules</a>, <a href="../Text/chapter-4.html#p15">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p87">Apriori algorithm</a>, <a href="../Text/chapter-4.html#p163">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p25">building blocks of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p287">case study for</a>, <a href="../Text/chapter-4.html#p307">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p166">equivalence class clustering and bottom-up lattice traversal</a>, <a href="../Text/chapter-4.html#p206">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p321">practical next steps and suggested readings</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p11">technical toolkit</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p42">adjacency matrix</a></p>
  </div>
  <div class="readable-text">
   <p>Apriori algorithm</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p155">challenges with</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-10.html#p8">AI (artificial intelligence)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p39">antecedent</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p50">anomaly detection</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p133">all_records list</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p126">A/B testing</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p101">ACO-CLUSTER (Ant Colony Optimization for Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p48">ATV (average transaction value)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p129">accuracy monitoring</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p98">AGCT (Agglomerative Genetic Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p47">AUTOCLASS (Bayesian Model-based Clustering)</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">B</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p15">BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p42">Bayesian Gaussian Mixture Model</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p132">bigrams</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p33">binary data</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p94">business problem definition</a>, <a href="../Text/chapter-11.html#p23">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p122">batch deployment</a></p>
  </div>
  <div class="readable-text">
   <p>backpropagation</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p171">mathematics behind</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p26">bottleneck</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p87">business stakeholders and subject matter experts</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p281">border points</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p113">Bisecting k-means</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p262">bivariate analysis</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">C</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p88">constraint-based clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p135">class variable</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p134">continuous deployment and integration</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p43">CNNs (convolutional neural networks)</a>, <a href="../Text/chapter-8.html#p216">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p218">key concepts of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p228">use of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p176">central limit theorem</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p149">correlation</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/appendix-a.html#p155">coefficient</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/appendix-a.html#p168">important considerations</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/appendix-a.html#p161">uses of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-10.html#p93">customization</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p280">core points</a>, <a href="../Text/chapter-2.html#p291">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p17">Chameleon</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p3">clustering algorithms</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p1">clustering techniques</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p339">case study</a>, <a href="../Text/chapter-2.html#p384">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p170">connectivity-based clustering</a>, <a href="../Text/chapter-2.html#p251">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p404">practical next steps and suggested readings</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p64">contractive autoencoders</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p34">continuous data</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p37">CLIQUE (Clustering in Quest)</a></p>
  </div>
  <div class="readable-text">
   <p>centroid-based clustering</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p90">measuring accuracy of clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-10.html#p91">contextual awareness</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p272">contrastive divergence algorithm</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p64">Chinese Whispers Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p184">CBOW (continuous bag of words)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p89">Constrained DBSCAN</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p210">Calinski-Haranasz index</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p42">code size</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p116">centroids</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p193">covariance</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p390">categorical variables</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p6">CLARA (Clustering Large Applications)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-10.html#p87">ChatGPT</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-10.html#p95">applications and key features of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p16">CURE (Clustering Using Representatives)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p39">cost function</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p90">C-DBSCAN (ConstraintBased DBSCAN)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p63">conditional probability</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p125">canary deployment</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p61">cosine distance</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p7">CLARANS (Clustering Large Applications based on Randomized Search)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p60">curse of dimensionality</a>, <a href="../Text/chapter-3.html#p21">2nd</a></p>
  </div>
  <div class="readable-text">
   <p>confidence</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p56">overview of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p55">Chebyshev distance</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p17">clustering</a>, <a href="../Text/chapter-5.html#p1">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p49">centroid-based</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p386">challenges faced in</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-5.html#p234">practical next steps and suggested readings</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p13">technical toolkit</a>, <a href="../Text/chapter-5.html#p12">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p30">techniques for</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">D</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p52">drug discovery</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p49">data cleaning</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p271">DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</a>, <a href="../Text/chapter-2.html#p337">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p315">Python solution for</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p275">nuts and bolts of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p304">pros and cons of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p288">steps in</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p149">data artists</a></p>
  </div>
  <div class="readable-text">
   <p>density-based</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/appendix-a.html#p23">algorithms</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p253">clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p29">DBCLASD (Distribution-Based Clustering of Large Spatial Databases)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p41">DBEM (Density-Based EM)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p62">data encoding</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p90">DevOps team</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-10.html#p40">discriminative models</a>, <a href="../Text/chapter-10.html#p52">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p158">dataframes</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p90">data science team</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p26">DENCLUE (Density-Based Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p19">deep learning</a>, <a href="../Text/chapter-8.html#p34">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p245">Boltzmann learning rule</a>, <a href="../Text/chapter-8.html#p259">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p163">backpropagation</a>, <a href="../Text/chapter-8.html#p197">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p124">neural networks</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p307">practical next steps and suggested readings</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p65">denoizing autoencoders</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p98">data preprocessing</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p51">data compression</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p98">Dunn index</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p8">dimensionality reduction</a>, <a href="../Text/chapter-6.html#p1">2nd</a>, <a href="../Text/chapter-9.html#p49">3rd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-6.html#p194">case study</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p246">case study for</a>, <a href="../Text/chapter-3.html#p267">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p17">curse of dimensionality</a>, <a href="../Text/chapter-3.html#p37">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p43">mathematical foundation</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p39">methods for</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p274">practical next steps and suggested readings</a>, <a href="../Text/chapter-6.html#p205">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p232">pros and cons of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p14">technical toolkit</a>, <a href="../Text/chapter-6.html#p13">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p97">data discovery phase</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p14">divisive clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p34">discrete data</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p18">dimensions</a></p>
  </div>
  <div class="readable-text">
   <p>data</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p72">data engineering and management</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p50">data quality</a>, <a href="../Text/chapter-1.html#p70">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p25">defined</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p30">types of</a>, <a href="../Text/chapter-1.html#p48">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p108">DEC (Deep Embedded Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p267">DBN (deep belief networks)</a>, <a href="../Text/chapter-8.html#p276">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p269">key points of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p90">data engineering team</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p27">decoder</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p46">degree matrix</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p209">diagonal matrix</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p110">DeepCluster (Deep Learning for Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p394">distance measurement</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p284">density-reachable</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">E</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p99">EDA (exploratory data analysis)</a>, <a href="../Text/chapter-11.html#p7">2nd</a>, <a href="../Text/chapter-11.html#p101">3rd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p63">Edge Betweenness Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p53">Euclidean distance</a>, <a href="../Text/chapter-2.html#p312">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p103">elbow method</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p70">ENCLUS (Entropy-Based Subspace Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p74">ETL (export, transform, load) process</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p25">encoder</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p183">EM (Expectation Maximization) Algorithm</a>, <a href="../Text/appendix-a.html#p40">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p124">edge deployment</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p21">EAC (Ensemble Agglomerative Clustering)</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">F</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p84">FCM-SC (Fuzzy C-Means with Spatial Constraints)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p9">Fuzzy C-Means (FCM)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p100">fuzzy clustering</a>, <a href="../Text/chapter-5.html#p167">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-5.html#p106">types of</a>, <a href="../Text/chapter-5.html#p143">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p57">frequency-based removal of words</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p61">filter methods</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p194">farthest neighbor</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p85">Fuzzy Subspace Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p86">Fuzzy SOM (Self-Organizing Maps)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p72">FSSC (Fast Subspace Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p83">FCM-GA (Fuzzy C-Means with Genetic Algorithms)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p74">FIRES (Frequent Itemset Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p147">for loop</a>, <a href="../Text/chapter-6.html#p99">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p93">FCM with Must-Link and Cannot-Link Constraints</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p208">F-P algorithm</a>, <a href="../Text/chapter-4.html#p250">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p81">Fuzzy Min-Max Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p108">FCM (fuzzy c-means) algorithm</a>, <a href="../Text/chapter-5.html#p112">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p149">fit_transform method</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">G</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p96">genetic clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p57">graph-based clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p32">grid-based algorithms</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p160">groupby</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p72">get_dummies() method</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p35">GRIDCLUS (Grid-based Clustering Algorithm)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p195">group average linkage</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p97">GA-k-means (Genetic Algorithm with k-means)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p106">Growing Neural Gas</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-10.html#p42">generator networks</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p104">GenAI (generative AI)</a>, <a href="../Text/chapter-7.html#p10">2nd</a>, <a href="../Text/chapter-10.html#p7">3rd</a>, <a href="../Text/chapter-10.html#p23">4th</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-10.html#p25">discriminative models and</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-10.html#p103">integration of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p109">GTM (Generative Topographic Mapping)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p102">GCUK (Genetic Clustering with Unsupervised k-means)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p182">greedy approach</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-10.html#p79">GPT-3 (Generative Pre-trained Transformer 3)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p110">Gath-Geva algorithm</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p12">GANs (generative adversarial networks)</a>, <a href="../Text/chapter-10.html#p6">2nd</a>, <a href="../Text/chapter-10.html#p39">3rd</a>, <a href="../Text/chapter-10.html#p85">4th</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-10.html#p60">adversarial training</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-10.html#p119">practical next steps and suggested readings</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-10.html#p72">variants and applications of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p59">Girvan-Newman Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p170">Gaussian distribution</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p9">GMM (Gaussian Mixture Model)</a>, <a href="../Text/chapter-5.html#p169">2nd</a>, <a href="../Text/chapter-5.html#p229">3rd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-5.html#p185">EM technique</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p109">GK (Gaustafson-Kessel) algorithm</a>, <a href="../Text/appendix-a.html#p80">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p45">G-Means (Gaussian Means)</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">H</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p94">Hard k-means with Constraints</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p25">HDBSCAN (Hierarchical DBSCAN)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p13">hierarchical clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p202">optimal number of clusters</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p218">pros and cons of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p180">types of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p195">hyperspectral images</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p31">hard clustering</a>, <a href="../Text/chapter-5.html#p102">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p76">High-Dimensional Spectral Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p19">HIERDENC (Hierarchical Density-Based Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p43">HMM (Hidden Markov Model) Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p20">HAC-S (Hierarchical Agglomerative Clustering with Spatial Constraints)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p114">Hybrid BIRCH-k-means</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p22">Hughes phenomenon</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p72">hidden layer</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">I</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p131">if/else block</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p93">intercluster sum of squares</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p71">input layer</a>, <a href="../Text/chapter-8.html#p219">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p92">inertia</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p61">Infomap Algorithm</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p93">IQR (interquartile range)</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">J</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p59">junk or unwanted characters</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">K</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p55">KPIs (key performance indicators)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p14">Keras</a>, <a href="../Text/chapter-8.html#p284">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p69">KNN (k-nearest neighbor)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p68">k-means clustering</a>, <a href="../Text/chapter-2.html#p88">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p102">finding optimum value of &lt;Emphasis&gt;k&lt;Default Para Font&gt;</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p114">pros and cons of</a>, <a href="../Text/chapter-2.html#p128">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p213">kmeans algorithm</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p5">K-medoids (PAM)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p125">k-median clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p154">Kaiser criteria</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p37">knowledge-representation</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p126">k-medoids clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p146">keras library</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p10">K-Modes</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p124">KL (Kullback-Liebler) divergence</a>, <a href="../Text/chapter-6.html#p133">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p11">K-Prototypes</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">L</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p242">LSTM (long short-term memory)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p29">LLMs (large language models)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p51">Laplacian matrix</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p273">layer-based pretraining</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p63">lexicon normalization</a></p>
  </div>
  <div class="readable-text">
   <p>lift</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p65">overview of</a>, <a href="../Text/chapter-4.html#p85">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p210">LabelEncoder</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p77">LAC (Locally Adaptive Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p58">library-based cleaning</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p187">latent variables</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p278">libraries, deep learning</a>, <a href="../Text/chapter-8.html#p297">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p30">LDBSCAN (Labeled DBSCAN)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p68">lemma, defined</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p128">line of best fit</a>, <a href="../Text/chapter-3.html#p94">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p45">loss function</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p60">Louvain Method for Community Detection</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p192">linkage criterion</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p56">Laplacian Eigenmaps for Clustering</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">M</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p23">market basket analysis</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p58">MCL (Markov Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p133">Markov assumption</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p96">MinMaxScalar() function</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p46">MCLUST (Model-based Clustering using EM)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p111">model deployment</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-11.html#p59">duplicate values in data</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-11.html#p36">end-to-end</a>, <a href="../Text/chapter-11.html#p68">2nd</a>, <a href="../Text/chapter-11.html#p75">3rd</a>, <a href="../Text/chapter-11.html#p113">4th</a>, <a href="../Text/chapter-11.html#p128">5th</a>, <a href="../Text/chapter-11.html#p139">6th</a>, <a href="../Text/chapter-11.html#p154">7th</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-11.html#p121">types of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p99">MEPSO (Multi-Elitist Particle Swarm Optimization for Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p132">model drift</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p48">Mixmod (Mixture Models for Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p162">mpl_toolkits library</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p16">MDS (multidimensional scaling)</a>, <a href="../Text/chapter-6.html#p61">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-6.html#p69">Python implementation of</a>, <a href="../Text/chapter-6.html#p106">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-6.html#p28">classic</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-6.html#p33">nonmetric</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p236">matplotlib library</a>, <a href="../Text/chapter-2.html#p244">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p142">model maintenance and refresh</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p290">MXNet</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p53">Multiway Spectral Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p39">model-based algorithms</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p45">manual methods of dimensionality reduction</a>, <a href="../Text/chapter-3.html#p81">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p68">algorithm-based methods for reducing dimensions</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p56">correlation coefficient</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p52">manual feature selection</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p1">mathematics</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/appendix-a.html#p119">L1 vs. L2 norm</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/appendix-a.html#p177">for data representation</a>, <a href="../Text/appendix-a.html#p215">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p104">membership</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p106">model development and business approval</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p5">ML (machine learning)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p77">AI and business intelligence</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p103">algorithms</a>, <a href="../Text/chapter-1.html#p225">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p22">data</a>, <a href="../Text/chapter-1.html#p75">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p82">overview of</a>, <a href="../Text/chapter-1.html#p101">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-11.html#p10">process</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p12">technical toolkit</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p27">Mean Shift</a></p>
  </div>
  <div class="readable-text">
   <p>matrices</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/appendix-a.html#p201">decomposition</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p58">Manhattan distance</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p88">make_circles method</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-10.html#p92">multilingual capabilities</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p8">Mini-Batch k-means</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p129">min-max scaling</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">N</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p388">noisy dataset</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p44">number of nodes per layer</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p258">neighborhood</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p100">NSGA-II (Nondominated Sorting Genetic Algorithm-II for Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-10.html#p90">natural language understanding</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p150">nltk library</a>, <a href="../Text/chapter-7.html#p154">2nd</a>, <a href="../Text/chapter-7.html#p157">3rd</a>, <a href="../Text/chapter-7.html#p160">4th</a></p>
  </div>
  <div class="readable-text">
   <p>neural networks</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p84">activation functions</a>, <a href="../Text/chapter-8.html#p109">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p36">building blocks of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p43">for solutions</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p111">hyperparameters</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p67">layers in</a>, <a href="../Text/chapter-8.html#p82">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p116">optimization functions</a>, <a href="../Text/chapter-8.html#p140">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p52">Normalized Cut Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p193">nearest neighbors</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p128">n-gram model</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p33">nominal data</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p153">no correlation</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p104">neural network-based clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p105">Neural Gas</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p63">NaN (not a number)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p15">numpy library</a>, <a href="../Text/chapter-3.html#p15">2nd</a>, <a href="../Text/chapter-4.html#p114">3rd</a>, <a href="../Text/chapter-5.html#p13">4th</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p152">negative correlation</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p8">NLP (natural language processing)</a>, <a href="../Text/chapter-10.html#p16">2nd</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">O</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p211">orthogonal matrix</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p29">overfitting</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p391">one-hot encoding</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p195">optimization</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p33">ordinal data</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p24">OPTICS (Ordering Points To Identify the Clustering Structure)</a></p>
  </div>
  <div class="readable-text">
   <p>optimization functions</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p126">adaptive optimization algorithms</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p134">learning and learning rate</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p157">objective function</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p71">ORCLUS (Orthogonal Subspace Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p36">OptiGrid</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p88">operations team</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p73">output layer</a>, <a href="../Text/chapter-8.html#p225">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p286">outliers</a>, <a href="../Text/chapter-11.html#p89">2nd</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">P</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p151">positive correlation</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p287">PyTorch</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p73">P3C (Pattern-based Subspace Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p10">PCA (principal component analysis)</a>, <a href="../Text/chapter-3.html#p83">2nd</a>, <a href="../Text/chapter-6.html#p7">3rd</a>, <a href="../Text/chapter-6.html#p55">4th</a>, <a href="../Text/chapter-6.html#p114">5th</a>, <a href="../Text/chapter-9.html#p20">6th</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p133">Python solution using</a>, <a href="../Text/chapter-3.html#p181">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p126">eigenvalue decomposition</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p197">Pavia University Dataset</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p43">parameters</a>, <a href="../Text/appendix-a.html#p217">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p134">perplexity</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p84">principal components</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p82">PCM (Possibilistic C-Means)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p223">pooling layer</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p91">PCKMeans (Pairwise Constrained k-means)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p283">pyspade library</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p83">Python</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p110">Apriori algorithm</a>, <a href="../Text/chapter-4.html#p153">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-5.html#p150">FCM (fuzzy c-means) algorithm</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p191">equivalence class clustering and bottom-up lattice traversal</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p233">hierarchical clustering case study using</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-5.html#p208">implementing GMM</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-9.html#p72">implementing autoencoders</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/appendix-a.html#p143">installing packages</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-2.html#p130">k-means clustering implementation using</a>, <a href="../Text/chapter-2.html#p168">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p98">principal axis</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p4">partitioning-based algorithms</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p292">planograms</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p48">perceptrons</a>, <a href="../Text/chapter-8.html#p65">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p50">preparation, cleaning data</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">Q</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p33">qualitative data</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p34">quantitative data</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">R</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p18">ROCK (Robust Clustering using Links)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p96">Regexp tokenization</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p100">ReLU (rectified linear unit)</a>, <a href="../Text/chapter-8.html#p222">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p138">Regex (Regular Expression)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p209">RNNs (recurrent neural networks)</a>, <a href="../Text/chapter-8.html#p231">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p233">key concepts of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p150">random_state parameter</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p216">reinforcement learning</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p51">Ratio Cut Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p112">RGB (red, green, blue)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p133">reproducibility</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p270">RBM (restricted Boltzmann machine)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p123">real-time deployment</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">S</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p183">SVD (singular value decomposition)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-3.html#p203">Python solution using</a>, <a href="../Text/chapter-3.html#p230">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p274">supervised fine-tuning</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p35">similarity graphs</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p252">sequence rule mining</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p115">SNE (stochastic neighbor embedding)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p85">SimpleImputer method</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p118">SGD (stochastic gradient descent)</a>, <a href="../Text/chapter-8.html#p120">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p36">structured dataset</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p53">spectral gap</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p131">security and compliance</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p133">Shape command</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p95">silhouette value</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p129">shingles</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p395">subjective interpretations</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-5.html#p22">spectral clustering</a>, <a href="../Text/appendix-a.html#p50">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-5.html#p85">Python implementation of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-5.html#p33">building blocks of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-5.html#p64">process of</a>, <a href="../Text/chapter-5.html#p83">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p92">Semisupervised k-means</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p208">special matrices</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p121">scaling techniques</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p256">SPADE (Sequential Pattern Discovery Using Equivalence classes) algorithm</a>, <a href="../Text/chapter-4.html#p258">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-4.html#p41">support</a>, <a href="../Text/chapter-4.html#p43">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-4.html#p49">overview of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p106">softmax function</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p75">SNN (Shared Nearest Neighbor Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p55">Shi-Malik Clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p125">standardization</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p130">scalability</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p212">semisupervised learning</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p79">soft clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p13">significant variables</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p66">SCPS (Spectral Clustering on Perona &amp; Shi’s graph)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p288">Sonnet</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p173">stochastic gradient descent</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p54">stopping word removal</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p107">supervised learning</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p156">adding loss function</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p146">algorithms</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p160">calculating error</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p143">classification algorithms</a>, <a href="../Text/chapter-1.html#p169">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p142">deep learning in</a>, <a href="../Text/chapter-8.html#p161">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p151">feed-forward propagation</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-1.html#p111">regression algorithms</a>, <a href="../Text/chapter-1.html#p141">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p63">sparse autoencoders</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p34">SUBCLU (Subspace Clustering)</a>, <a href="../Text/appendix-a.html#p69">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p160">sigmoid function</a>, <a href="../Text/chapter-8.html#p86">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p68">subspace and high-dimensional clustering</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p65">SPICi (Speed and Performance In Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p146">sklearn library</a>, <a href="../Text/chapter-3.html#p159">2nd</a>, <a href="../Text/chapter-6.html#p72">3rd</a>, <a href="../Text/chapter-6.html#p74">4th</a>, <a href="../Text/chapter-6.html#p80">5th</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">T</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p90">tokenization</a></p>
  </div>
  <div class="readable-text">
   <p>text data</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p271">GenAI for</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p50">preprocessing</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p1">unsupervised learning for</a>, <a href="../Text/chapter-7.html#p99">2nd</a>, <a href="../Text/chapter-7.html#p195">3rd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p9">toolkit</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p396">time-consuming</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p93">tanh function</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p17">technical toolkit</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p155">tSNE_first_component</a></p>
  </div>
  <div class="readable-text">
   <p>training</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-9.html#p33">autoencoders</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p133">time complexity &lt;Emphasis&gt;O&lt;Default Para Font&gt;(&lt;Emphasis&gt;n&lt;Default Para Font&gt;)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p387">too much data</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p280">TF (TensorFlow)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p293">Python code for</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p9">t-SNE (t-distributed stochastic neighbor embedding)</a>, <a href="../Text/chapter-6.html#p109">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-6.html#p126">Cauchy distribution</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-6.html#p143">Python implementation of</a>, <a href="../Text/chapter-6.html#p166">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p174">time-series analysis</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p88">TF-IDF (term frequency-inverse document frequency)</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">U</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p7">unsupervised learning</a>, <a href="../Text/chapter-1.html#p171">2nd</a>, <a href="../Text/chapter-1.html#p210">3rd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p32">challenges with text data</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-8.html#p199">deep learning in</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p72">extracting features from text datasets</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p16">for text data</a>, <a href="../Text/chapter-7.html#p18">2nd</a>, <a href="../Text/chapter-7.html#p52">3rd</a>, <a href="../Text/chapter-7.html#p70">4th</a>, <a href="../Text/chapter-7.html#p113">5th</a>, <a href="../Text/chapter-7.html#p125">6th</a>, <a href="../Text/chapter-7.html#p181">7th</a>, <a href="../Text/chapter-7.html#p254">8th</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p127">language models</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p13">technical toolkit</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p256">text clustering using Python</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p1">text data</a>, <a href="../Text/chapter-7.html#p137">2nd</a>, <a href="../Text/chapter-7.html#p164">3rd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-7.html#p21">use cases for text data</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-6.html#p168">UMAP (Uniform Manifold Approximation and Projection)</a>, <a href="../Text/chapter-6.html#p192">2nd</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-6.html#p186">key points of</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 1em"><a href="../Text/chapter-6.html#p171">working with</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-1.html#p90">UI/visualization team</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p135">user feedback</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p261">univariate analysis</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p130">unigrams</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p56">undercomplete autoencoders</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">V</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-11.html#p136">versioning</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p28">VDBSCAN (Variable Density-Based Spatial Clustering)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-9.html#p70">variational autoencoders</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p181">vectors</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p185">variance</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">W</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p62">Walktrap Algorithm</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p33">WaveCluster</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p54">wrapper methods</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p91">WCSS (within the cluster sum of squares)</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p166">word embeddings</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-7.html#p182">Word2Vec</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-2.html#p196">Ward linkage method</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-8.html#p54">weights</a></p>
  </div>
  <div class="readable-text">
   <p style="font-size: 110%;">X</p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/chapter-3.html#p145">X_variables</a></p>
  </div>
  <div class=" readable-text">
   <p style="margin-left: 0em"><a href="../Text/appendix-a.html#p44">X-Means (Extended k-means)</a></p>
  </div>
 </body></html>