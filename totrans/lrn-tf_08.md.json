["```py\nfrom__future__importprint_functionimportosimporttensorflowastffromtensorflow.contrib.learn.python.learn.datasetsimportmnistsave_dir=\"*`path/to/mnist`*\"# Download data to save_dirdata_sets=mnist.read_data_sets(save_dir,dtype=tf.uint8,reshape=False,validation_size=1000)\n```", "```py\ndata_splits = [\"train\",\"test\",\"validation\"]\nfor d in range(len(data_splits)):\n print(\"saving \" + data_splits[d])\n data_set = data_sets[d]\n\n filename = os.path.join(save_dir, data_splits[d] + '.tfrecords')\n writer = tf.python_io.TFRecordWriter(filename)\n for index in range(data_set.images.shape[0]):\n  image = data_set.images[index].tostring()\n  example = tf.train.Example(features=tf.train.Features(feature={\n  'height': tf.train.Feature(int64_list=\n                 tf.train.Int64List(value=\n                 [data_set.images.shape[1]])),\n  'width': tf.train.Feature(int64_list=\n                 tf.train.Int64List(value =\n                 [data_set.images.shape[2]])),\n  'depth': tf.train.Feature(int64_list=\n                 tf.train.Int64List(value =\n                 [data_set.images.shape[3]])),\n  'label': tf.train.Feature(int64_list=\n                 tf.train.Int64List(value =\n                 [int(data_set.labels[index])])),\n  'image_raw': tf.train.Feature(bytes_list=\n                 tf.train.BytesList(value =\n                          [image]))}))\n  writer.write(example.SerializeToString())\n writer.close()\n\n```", "```py\nfilename = os.path.join(save_dir, data_splits[d] + '.tfrecords')\nwriter = tf.python_io.TFRecordWriter(filename)\n```", "```py\nimage = data_set.images[index].tostring()\n```", "```py\ntf.train.Feature(int64_list=tf.train.Int64List(value =\n                 [int(data_set.labels[index])]))\n```", "```py\ntf.train.Feature(bytes_list=tf.train.BytesList(value =[image]))\n```", "```py\nfilename = os.path.join(save_dir, 'train.tfrecords')\nrecord_iterator = tf.python_io.tf_record_iterator(filename)\nseralized_img_example= next(record_iterator)\n```", "```py\nexample = tf.train.Example()\nexample.ParseFromString(seralized_img_example)\nimage = example.features.feature['image_raw'].bytes_list.value\nlabel = example.features.feature['label'].int64_list.value[0]\nwidth = example.features.feature['width'].int64_list.value[0]\nheight = example.features.feature['height'].int64_list.value[0]\n```", "```py\nimg_flat = np.fromstring(image[0], dtype=np.uint8)\nimg_reshaped = img_flat.reshape((height, width, -1))\n```", "```py\nimport tensorflow as tf\n\nsess= tf.InteractiveSession()\nqueue1 = tf.FIFOQueue(capacity=10,dtypes=[tf.string])\n\n```", "```py\nenque_op = queue1.enqueue([\"F\"])\n\n```", "```py\nsess.run(queue1.size())\n\nOut:\n0\n\n```", "```py\nenque_op.run()\nsess.run(queue1.size())\nOut:\n1\n```", "```py\nenque_op = queue1.enqueue([\"I\"])\nenque_op.run()\nenque_op = queue1.enqueue([\"F\"])\nenque_op.run()\nenque_op = queue1.enqueue([\"O\"])\nenque_op.run()\n\nsess.run(queue1.size())\n\nOut: \n4\n\n```", "```py\nx = queue1.dequeue()\nx.eval()\n\nOut: b'F'\nx.eval()\n\nOut: b'I'\nx.eval()\n\nOut: b'F'\nx.eval()\n\nOut: b'O'\n\n```", "```py\nqueue1 = tf.FIFOQueue(capacity=10,dtypes=[tf.string],shapes=[()])\n\n```", "```py\ninputs = queue1.dequeue_many(4)\ninputs.eval()\n\n```", "```py\nOut: \narray([b'F', b'I', b'F', b'O'], dtype=object)\n```", "```py\nfrom __future__ import print_function\nimport threading\nimport time\n\ngen_random_normal = tf.random_normal(shape=())\nqueue = tf.FIFOQueue(capacity=100,dtypes=[tf.float32],shapes=())\nenque = queue.enqueue(gen_random_normal)\n\ndef add():\n  for i in range(10):\n    sess.run(enque)\n```", "```py\nthreads = [threading.Thread(target=add, args=()) for i in range(10)]\n\nthreads\nOut:\n[<Thread(Thread-77, initial)>,\n<Thread(Thread-78, initial)>,\n<Thread(Thread-79, initial)>,\n<Thread(Thread-80, initial)>,\n<Thread(Thread-81, initial)>,\n<Thread(Thread-82, initial)>,\n<Thread(Thread-83, initial)>,\n<Thread(Thread-84, initial)>,\n<Thread(Thread-85, initial)>,\n<Thread(Thread-86, initial)>]\n\n```", "```py\nfor t in threads:\n  t.start()\n\nprint(sess.run(queue.size()))\ntime.sleep(0.01)\nprint(sess.run(queue.size()))\ntime.sleep(0.01)\nprint(sess.run(queue.size()))\n\n```", "```py\nOut:\n10\n84\n100\n```", "```py\nx = queue.dequeue_many(10)\nprint(x.eval())\nsess.run(queue.size())\n\n```", "```py\nOut:\n[ 0.05863889 0.61680967 1.05087686 -0.29185265 -0.44238046 0.53796548\n-0.24784896 0.40672767 -0.88107938 0.24592835]\n90\n\n```", "```py\ngen_random_normal = tf.random_normal(shape=())\nqueue = tf.FIFOQueue(capacity=100,dtypes=[tf.float32],shapes=())\nenque = queue.enqueue(gen_random_normal)\n\ndef add(coord,i):\n  while not coord.should_stop():\n    sess.run(enque)\n    if i == 11:\n      coord.request_stop()\n\ncoord = tf.train.Coordinator()\nthreads = [threading.Thread(target=add, args=(coord,i)) for i in range(10)]\ncoord.join(threads)\n\nfor t in threads:\n  t.start()\n\nprint(sess.run(queue.size()))\ntime.sleep(0.01)\nprint(sess.run(queue.size()))\ntime.sleep(0.01)\nprint(sess.run(queue.size()))\n\n10\n100\n100\n\n```", "```py\ndef add(coord,i):\n  while not coord.should_stop():\n    sess.run(enque)\n    if i == 1:\n      coord.request_stop()\n```", "```py\nprint(sess.run(queue.size()))\ntime.sleep(0.01)\nprint(sess.run(queue.size()))\ntime.sleep(0.01)\nprint(sess.run(queue.size()))\n\n```", "```py\nOut:\n10\n17\n17\n```", "```py\ngen_random_normal = tf.random_normal(shape=())\nqueue = tf.RandomShuffleQueue(capacity=100,dtypes=[tf.float32],\n               min_after_dequeue=1)\nenqueue_op = queue.enqueue(gen_random_normal)\n\nqr = tf.train.QueueRunner(queue, [enqueue_op] * 4)\ncoord = tf.train.Coordinator()\nenqueue_threads = qr.create_threads(sess, coord=coord, start=True)\ncoord.request_stop()\ncoord.join(enqueue_threads)\n\n```", "```py\nfrom__future__importprint_functionimportosimporttensorflowastffromtensorflow.contrib.learn.python.learn.datasetsimportmnistimportnumpyasnpsave_dir=\"*`path/to/mnist`*\"# Download data to save_dirdata_sets=mnist.read_data_sets(save_dir,dtype=tf.uint8,reshape=False,validation_size=1000)data_splits=[\"train\",\"test\",\"validation\"]fordinrange(len(data_splits)):print(\"saving \"+data_splits[d])data_set=data_sets[d]filename=os.path.join(save_dir,data_splits[d]+'.tfrecords')writer=tf.python_io.TFRecordWriter(filename)forindexinrange(data_set.images.shape[0]):image=data_set.images[index].tostring()example=tf.train.Example(features=tf.train.Features(feature={'height':tf.train.Feature(int64_list=tf.train.Int64List(value=[data_set.images.shape[1]])),'width':tf.train.Feature(int64_list=tf.train.Int64List(value=[data_set.images.shape[2]])),'depth':tf.train.Feature(int64_list=tf.train.Int64List(value=[data_set.images.shape[3]])),'label':tf.train.Feature(int64_list=tf.train.Int64List(value=[int(data_set.labels[index])])),'image_raw':tf.train.Feature(bytes_list=tf.train.BytesList(value=[image]))}))writer.write(example.SerializeToString())writer.close()\n```", "```py\nfilename = os.path.join(save_dir ,\"train.tfrecords\")\nfilename_queue = tf.train.string_input_producer(\n  [filename], num_epochs=10)\n\n```", "```py\nreader = tf.TFRecordReader()\n_, serialized_example = reader.read(filename_queue)\nfeatures = tf.parse_single_example(\n  serialized_example,\n  features={\n    'image_raw': tf.FixedLenFeature([], tf.string),\n    'label': tf.FixedLenFeature([], tf.int64),\n  })\n\n```", "```py\nimage = tf.decode_raw(features['image_raw'], tf.uint8)\nimage.set_shape([784]) \nimage = tf.cast(image, tf.float32) * (1. / 255) - 0.5\nlabel = tf.cast(features['label'], tf.int32)\n# Randomly collect instances into batches \nimages_batch, labels_batch = tf.train.shuffle_batch(\n  [image, label], batch_size=128,\n  capacity=2000,\n  min_after_dequeue=1000)\n\n```", "```py\nW = tf.get_variable(\"W\", [28*28, 10])\ny_pred = tf.matmul(images_batch, W)\nloss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_pred, \n                                                      labels=labels_batch)\n\nloss_mean = tf.reduce_mean(loss)\n\ntrain_op = tf.train.AdamOptimizer().minimize(loss)\n\nsess = tf.Session()\ninit = tf.global_variables_initializer()\nsess.run(init)\ninit = tf.local_variables_initializer()\nsess.run(init)\n\n```", "```py\nfrom __future__ import print_function\n\n# Coordinator\u00a0\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(sess=sess,coord=coord)\n\n```", "```py\nthreads\n\nOut:\u00a0\n[<Thread(Thread-483, stopped daemon 13696)>,\n\u00a0<Thread(Thread-484, started daemon 16376)>,\n\u00a0<Thread(Thread-485, started daemon 4320)>,\n\u00a0<Thread(Thread-486, started daemon 13052)>,\n\u00a0<Thread(Thread-487, started daemon 7216)>,\n\u00a0<Thread(Thread-488, started daemon 4332)>,\n\u00a0<Thread(Thread-489, started daemon 16820)>]\n```", "```py\ntry:\n step = 0\n while not coord.should_stop(): \n   step += 1\n   sess.run([train_op])\n   if step%500==0:\n     loss_mean_val = sess.run([loss_mean])\n     print(step)\n     print(loss_mean_val)\nexcept tf.errors.OutOfRangeError: \n  print('Done training for %d epochs, %d steps.' % (NUM_EPOCHS, step))\nfinally:\n  # When done, ask the threads to stop\n  coord.request_stop()\n\n# Wait for threads to finish\ncoord.join(threads)\nsess.close()\n\n```", "```py\nOut:\nDone training for 10 epochs, 2299500 steps.\n\n```"]