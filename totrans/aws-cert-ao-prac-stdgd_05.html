<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 4. Understanding Generative AI"><div class="chapter" id="chapter_four_understanding_generative_a">
<h1><span class="label">Chapter 4. </span>Understanding Generative AI</h1>
<p>In late 2015, a group of Silicon Valley <a contenteditable="false" data-type="indexterm" data-primary="Musk, Elon" id="id969"/><a contenteditable="false" data-type="indexterm" data-primary="Altman, Sam" id="id970"/><a contenteditable="false" data-type="indexterm" data-primary="OpenAI" data-secondary="founding" id="id971"/><a contenteditable="false" data-type="indexterm" data-primary="artificial general intelligence (AGI)" data-secondary="OpenAI mission" id="id972"/><a contenteditable="false" data-type="indexterm" data-primary="AGI (artificial general intelligence)" data-secondary="OpenAI mission" id="id973"/>entrepreneurs—including Elon Musk and Sam Altman—cofounded OpenAI with a mission to ensure that artificial general intelligence (AGI) benefits all of humanity. After initially focusing on reinforcement learning, the company shifted to generative AI, launching the GPT-2 model in 2019. A year later, it released GPT-3, a model with 175 billion parameters trained on 570 GB of text, representing a massive leap from its predecessor.</p>
<p>The turning point came on November 30, 2022, <a contenteditable="false" data-type="indexterm" data-primary="OpenAI" data-secondary="ChatGPT" id="id974"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="launch" id="id975"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="ChatGPT launch" id="id976"/>with the launch of ChatGPT. The application’s impact was immediate and transformative, attracting over one million users in its first week and 100 million in two months, making it the fastest-growing software application in history at the time. The success of ChatGPT triggered a surge of investment in generative AI, making the technology a priority for businesses worldwide. This led to the rapid development of new models from competitors, including Google’s Gemini and xAI’s Grok, each pushing the boundaries of the field.</p>
<p>This chapter explores how generative AI works, its core technologies, and its primary use cases.</p>
<section data-type="sect1" data-pdf-bookmark="Neural Networks and Deep Learning"><div class="sect1" id="neural_networks_and_deep_learning">
<h1>Neural Networks and Deep Learning</h1>
<p>The foundational concepts behind<a contenteditable="false" data-type="indexterm" data-primary="neural networks" data-secondary="generative AI development" id="id977"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="development via neural networks" id="id978"/> modern generative AI began with early neural networks in the 1950s, which attempted to mirror the human brain. These simple networks had three components:</p>
<dl>
<dt>Input layer</dt>
<dd><p>Receives the initial data</p></dd>
<dt>Hidden layer</dt>
<dd><p>Contains nodes with random weights that process the input to find patterns</p></dd>
<dt>Output layer</dt>
<dd><p>Applies an activation function to the processed data to determine the final output</p></dd>
</dl>
<p>While these early systems were limited by the available computing power, they established the core principles for modern innovations.</p>
<p><em>Deep learning</em> is an evolution<a contenteditable="false" data-type="indexterm" data-primary="neural networks" data-secondary="deep learning of ML" data-tertiary="generative AI" id="id979"/><a contenteditable="false" data-type="indexterm" data-primary="deep learning" data-secondary="generative AI" id="id980"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="deep learning component" id="id981"/> of this structure that uses a neural network with many hidden layers, sometimes numbering in the hundreds. This complexity allows deep learning models to process vast amounts of data and detect intricate, nonlinear patterns that humans might not be able to identify. <a contenteditable="false" data-type="indexterm" data-primary="backpropagation" id="id982"/>The basic workflow of a deep learning model involves data passing through these layers, with the model refining its predictions through a process called <em>backpropagation</em>, where it learns from its mistakes by adjusting the weights in the network.</p>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Generative AI Models"><div class="sect1" id="generative_ai_models">
<h1>Generative AI Models</h1>
<p><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="about" id="id983"/>Unlike traditional AI models that classify or predict based on inputs, generative AI produces original outputs that resemble the data it was trained on. These models have been used to generate everything from realistic portraits to humanlike conversations.</p>
<p>There are different flavors of generative AI models. Most of them rely on deep learning systems. But there are often many tweaks and customizations.</p>
<p>For the AIF-C01 exam, the types of generative AI models to understand include the following:<a contenteditable="false" data-type="indexterm" data-primary="exam for AIF-C01" data-secondary="topics covered" data-tertiary="generative AI" id="id984"/><a contenteditable="false" data-type="indexterm" data-primary="topics covered in exam for AIF-C01" data-secondary="generative AI" id="id985"/></p>
<ul>
<li><p>Generative adversarial network (GAN)</p></li>
<li><p>Variational autoencoder (VAE)</p></li>
<li><p>Transformer model</p></li>
<li><p>Diffusion model</p></li>
</ul>
<p>Among these, the transformer model is the most important for the exam.</p>
<p>Let’s take a look at each of these in the following sections.</p>
<section data-type="sect2" data-pdf-bookmark="Generative Adversarial Network"><div class="sect2" id="generative_adversarial_network_left_par">
<h2>Generative Adversarial Network</h2>
<p>When Ian Goodfellow earned<a contenteditable="false" data-type="indexterm" data-primary="Goodfellow, Ian" id="id986"/><a contenteditable="false" data-type="indexterm" data-primary="generative adversarial network (GAN)" id="c04gan"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="models" data-tertiary="generative adversarial network" id="c04gan2"/><a contenteditable="false" data-type="indexterm" data-primary="neural networks" data-secondary="generative adversarial network" id="c04gan3"/><a contenteditable="false" data-type="indexterm" data-primary="Ng, Andrew" id="id987"/> his Bachelor of Science and Master of Science degrees in computer science from Stanford University, he studied under one of the leading authorities on AI, Andrew Ng. This inspired him to pursue a career in this field, and he would go on to get a PhD in machine learning from Université de Montréal. <a contenteditable="false" data-type="indexterm" data-primary="Bengio, Yoshua" id="id988"/>It was here that he studied under Yoshua Bengio, another towering figure in AI.</p>
<p class="pagebreak-before">His first job out of school was as an intern at Google. He created a neural network that could translate addresses from images, which improved Google Maps. <a contenteditable="false" data-type="indexterm" data-primary="generative adversarial network (GAN)" data-secondary="developer Ian Goodfellow" id="id989"/>But it was in 2014 that Goodfellow had his major breakthrough—the generative adversarial network. This actually came about from a discussion he had with colleagues at a <a href="https://oreil.ly/9DJb4">microbrewery in Montreal, Canada</a>. The topic was about how to improve the training for a generative model. His friends talked about an approach that would use large amounts of resources. But Goodfellow thought a better method was to have two neural networks compete against each other. This would allow for the system to create better content.</p>
<p>When Goodfellow went home later in the night, he could not stop thinking about this concept. He spent a few hours creating the GAN model, which generated compelling images.</p>
<p>The two neural networks<a contenteditable="false" data-type="indexterm" data-primary="generative adversarial network (GAN)" data-secondary="generator" id="id990"/><a contenteditable="false" data-type="indexterm" data-primary="generative adversarial network (GAN)" data-secondary="discriminator" id="id991"/> in the GAN were the generator and the discriminator, as shown in <a data-type="xref" href="#figure_four_onedot_the_gan_model">Figure 4-1</a>.</p>
<figure><div id="figure_four_onedot_the_gan_model" class="figure">
<img src="assets/awsc_0401.png" alt="" width="1238" height="593"/>
<h6><span class="label">Figure 4-1. </span>The GAN model</h6>
</div></figure>
<p>The generator creates synthetic data from random noise inputs. The discriminator, on the other hand, will evaluate the synthetic data and try to assess if it is real or not. This “adversarial” process will iterate until the generator is creating data that appears real.</p>
<p>On its face, it is a simple concept. But of course, the GAN was based on complex math and algorithms. Not long after developing the GAN, Goodfellow published a paper on it, which immediately stirred significant interest from the AI community. <a contenteditable="false" data-type="indexterm" data-primary="LeCun, Yann" id="id992"/>Meta’s chief AI scientist, Yann LeCun, called it “the coolest idea in deep learning in the last 20 years.”</p>
<p>There also emerged tools to create images using GANs. Many were posted on social media sites like Twitter. In fact, one image was auctioned on Christie’s auction, fetching a hefty <a href="https://oreil.ly/wKwnu">$432,000</a>.</p>
<p>But GANs also proved useful for diverse areas like scientific research, <a contenteditable="false" data-type="indexterm" data-primary="generative adversarial network (GAN)" data-secondary="subatomic particle behavior" id="id993"/><a contenteditable="false" data-type="indexterm" data-primary="Large Hadron Collider at CERN" id="id994"/><a contenteditable="false" data-type="indexterm" data-primary="collider at CERN (Switzerland)" id="id995"/>such as to improve the accuracy of detecting behavior of subatomic particles in the Large Hadron Collider at CERN in Switzerland.<sup><a data-type="noteref" id="ch01fn2-marker" href="ch04.html#ch01fn2">1</a></sup><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04gan" id="id996"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04gan2" id="id997"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04gan3" id="id998"/></p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Variational Autoencoder"><div class="sect2" id="variational_autoencoder_left_parenthesi">
<h2>Variational Autoencoder</h2>
<p>In a 2013 paper,<sup><a data-type="noteref" id="ch01fn3-marker" href="ch04.html#ch01fn3">2</a></sup> Diederik P. Kingma and Max Welling <a contenteditable="false" data-type="indexterm" data-primary="Welling, Max" id="id999"/><a contenteditable="false" data-type="indexterm" data-primary="Kingma, Diederik P." id="id1000"/><a contenteditable="false" data-type="indexterm" data-primary="variational autoencoder (VAE)" id="id1001"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="models" data-tertiary="variational autoencoder" id="id1002"/>introduced the variational autoencoder, as diagrammed in <a data-type="xref" href="#figure_four_twodot_the_process_of_a_vae">Figure 4-2</a>. It was a combination of a complex neural network and advanced probability theory.</p>
<figure><div id="figure_four_twodot_the_process_of_a_vae" class="figure">
<img src="assets/awsc_0402.png" alt="" width="1425" height="418"/>
<h6><span class="label">Figure 4-2. </span>The process of a VAE</h6>
</div></figure>
<p>A VAE has two main components that work together: an encoder and a decoder. The encoder acts like a smart summarizer that takes your original data and converts it into a compact representation, but unlike a simple summary,<a contenteditable="false" data-type="indexterm" data-primary="variational autoencoder (VAE)" data-secondary="probability distribution" id="id1003"/><a contenteditable="false" data-type="indexterm" data-primary="probability distribution" data-secondary="variational autoencoder" id="id1004"/> it creates what’s called a <em>probability distribution</em>. This means instead of just creating one fixed summary, it learns to capture the range of possible variations and uncertainties in the data.</p>
<p>The decoder works in reverse, taking these compressed representations and reconstructing them back into data that resembles the original input. What makes VAEs particularly powerful is that they don’t just learn to copy data perfectly. Instead, they learn the underlying patterns and relationships. This means you can sample from the probability distribution in the middle—that is, the latent space—to generate entirely new data that shares the same characteristics as your original dataset.</p>
<p class="pagebreak-before">A common use case for a VAE is to create images. But it can also be used for:</p>
<dl>
<dt>Anomaly detection</dt>
<dd><p>A VAE is effective in finding outliers, which can be critical for fraud detection and network security.</p></dd>
<dt>Drug discovery</dt>
<dd><p>A VAE can create molecular structures. This can help identify potential drug candidates quicker and more efficiently.</p></dd>
<dt>Sound</dt>
<dd><p>You can create sound effects and even new music.</p></dd>
</dl>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Transformer Model"><div class="sect2" id="transformer_model">
<h2>Transformer Model</h2>
<p>The launch of the <a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="models" data-tertiary="transformer model" id="c04tran"/><a contenteditable="false" data-type="indexterm" data-primary="transformer model" id="c04tran2"/><a contenteditable="false" data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="transformer model" id="c04tran3"/>transformer model—which is at the heart of generative AI—came in August 2017. It was published in an academic paper<sup><a data-type="noteref" id="ch01fn4-marker" href="ch04.html#ch01fn4">3</a></sup> by authors who were part of the Google Research team. The inspiration for the model actually came about from a lunch they had. The researchers debated the question: How can computers generate content that is humanlike?</p>
<p>What they came up with turned out to be one of the biggest innovations in AI—ever. The academic paper would ultimately be cited more than 80,000 times.<sup><a data-type="noteref" id="ch01fn5-marker" href="ch04.html#ch01fn5">4</a></sup></p>
<p>The irony is that Google did not initially pay much attention to the transformer. In the meantime, various startups, including OpenAI, saw this technology as the best approach for AI. Some of the Google researchers would go on to start their own AI ventures.</p>
<p>Before the introduction of the transformer model, <a contenteditable="false" data-type="indexterm" data-primary="recurrent neural networks (RNNs)" id="id1005"/><a contenteditable="false" data-type="indexterm" data-primary="neural networks" data-secondary="recurrent neural networks" id="id1006"/><a contenteditable="false" data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="recurrent neural networks" id="id1007"/>the main approach with NLP was the use of recurrent neural networks (RNNs). This processes data, like text, speech, and time series, sequentially. But there’s a problem with this: it can fail to capture the context.</p>
<p>To deal with this, there were some innovations<a contenteditable="false" data-type="indexterm" data-primary="long short-term memory (LSTM) networks" id="id1008"/> like long short-term memory (LSTM) networks, which also proved to be limited.</p>
<p>But with the transformer model, the approach was turned on its head. Instead of processing data step-by-step like RNNs, transformers used attention mechanisms to consider all parts of the input at once—allowing for a deeper and more flexible understanding of context in natural language.</p>
<p>To accomplish this, the transformer architecture relies on four main components (see <a data-type="xref" href="#figure_four_threedot_the_process_of_a_t">Figure 4-3</a>):<a contenteditable="false" data-type="indexterm" data-primary="transformer model" data-secondary="input embedding component" id="c04inem"/></p>
<dl>
<dt>Input embedding</dt>
<dd><p>Converts words into numerical vectors that can be processed by the model</p></dd>
<dt>Positional encoding</dt>
<dd><p>Adds information about the position of each word in a sentence, since the model does not process input sequentially</p></dd>
<dt>Encoder stack</dt>
<dd><p>Analyzes the entire input sequence and builds a contextual representation of it</p></dd>
<dt>Decoder stack</dt>
<dd><p>Generates the output sequence, using the encoded input and previously generated outputs to produce fluent, coherent text</p></dd>
</dl>
<figure><div id="figure_four_threedot_the_process_of_a_t" class="figure">
<img src="assets/awsc_0403.png" alt="" width="1050" height="728"/>
<h6><span class="label">Figure 4-3. </span>The process of a transformer model</h6>
</div></figure>
<p>Let’s take a look at each of the four main components.</p>
<section data-type="sect3" data-pdf-bookmark="Input embedding"><div class="sect3" id="input_embedding">
<h3>Input embedding</h3>
<p>Input embedding converts<a contenteditable="false" data-type="indexterm" data-primary="embeddings" data-secondary="input embedding" id="id1009"/><a contenteditable="false" data-type="indexterm" data-primary="tokens" data-secondary="vectors from" id="id1010"/> tokens into a vector representation, which is a string of numbers. This allows a model to analyze the data and find the patterns.</p>
<p>Suppose a model processes the following: “She ate the pizza.” The input embedding might look like the following:</p>
<ul class="list_style_type_none">
<li><p>“She” → [0.25, –0.13, 0.40, ...]</p></li>
<li><p>“ate” → [0.10, 0.22, –0.35, ...]</p></li>
<li><p>“the” → [–0.05, 0.15, 0.20, ...]</p></li>
<li><p>“pizza” → [0.30, –0.25, 0.50, ...]</p></li>
</ul>
<p>Each number in a vector is called a <em>component</em>, and together they exist within a vector space—a mathematical structure made up of multiple dimensions. Each dimension represents a different direction or feature, allowing patterns in the data to be represented and analyzed. Creating these vectors involves complex calculations based on linear algebra.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04inem" id="id1011"/></p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Positional encoding"><div class="sect3" id="positional_encoding">
<h3>Positional encoding</h3>
<p>The problem with input embedding<a contenteditable="false" data-type="indexterm" data-primary="transformer model" data-secondary="positional encoding component" id="id1012"/> is that it will jumble the order of the words. No doubt, this can mean that some of the context will be lost or confused.</p>
<p>This is where positional encoding comes in. This assigns a unique numerical vector to each position in the sequence of the words. Here’s an example based on our <span class="keep-together">sentence:</span></p>
<ul class="list_style_type_none">
<li><p>Position 1 (for “She”) → [0.01, 0.02, 0.03]</p></li>
<li><p>Position 2 (for “ate”) → [0.02, 0.03, 0.04]</p></li>
<li><p>Position 3 (for “the”) → [0.03, 0.04, 0.05]</p></li>
<li><p>Position 4 (for “pizza”) → [0.04, 0.05, 0.06]</p></li>
</ul>
<p>These are then added to the input embeddings.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Encoder stack"><div class="sect3" id="encoder_stack">
<h3>Encoder stack</h3>
<p>The encoder stack is where<a contenteditable="false" data-type="indexterm" data-primary="transformer model" data-secondary="encoder stack component" id="id1013"/> the transformer model attempts to understand the meaning of the text. This involves different layers of processing.</p>
<p>The first one uses a self-attention mechanism, which shows how each word relates to every other word. In our example, the model will evaluate the relationship between “she” and “ate.” It will understand that “she” is the subject and is performing the action of “ate.”</p>
<p>After this, there will be processing with more layers of self-attention. The goal is to get a better understanding of the meaning of the text. At the end of this process, the model should have a solid understanding of “She ate the pizza.”</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Decoder stack"><div class="sect3" id="decoder_stack">
<h3>Decoder stack</h3>
<p>The decoder stack is responsible<a contenteditable="false" data-type="indexterm" data-primary="transformer model" data-secondary="decoder stack component" id="id1014"/> for generating an output sequence. Common tasks include translation, content generation, and summarization.</p>
<p>Let’s say we want to translate the sentence “She ate the pizza” into Spanish. The decoder follows a step-by-step process for each word:</p>
<dl>
<dt>Masked self-attention</dt>
<dd><p>This allows the decoder to focus only on the words it has already generated, preventing it from “seeing” future words. For the first token, it predicts the most likely starting word.</p></dd>
<dt>Encoder-decoder attention</dt>
<dd><p>This step connects the decoder to the information from the input sentence. For example, the model recognizes that “she” is the subject of the sentence.</p></dd>
<dt>Output generation</dt>
<dd><p>Based on the previous steps, the decoder predicts the first word in Spanish—“Ella.”</p></dd>
</dl>
<p>This process continues word by word until the entire translation is complete.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="A transformer is a prediction engine"><div class="sect3" id="a_transformer_is_a_prediction_engine">
<h3>A transformer is a prediction engine</h3>
<p>The transformer model is certainly complex.<a contenteditable="false" data-type="indexterm" data-primary="transformer model" data-secondary="as prediction engine" data-secondary-sortas="prediction engine" id="id1015"/> But when you boil things down, it’s really about how it is a prediction engine. As we saw in the encoder and decoder stacks, the model is predicting the next word in a sequence.</p>
<p>The predictions are based on the complex relationships among all the words in the dataset. This is where the power of the system shines. By leveraging attention mechanisms with massive datasets—which are often most of the content on the internet—the transformer model can understand and create content in humanlike ways. There is also no need for labeling data. The reason is that the transformer is analyzing the relationships among the tokens.</p>
<p>However, there are issues with the transformer model. After all, predictions are estimates and can sometimes be wrong. We’ll discuss some of these issues with generative AI later in this chapter.</p>
<p>Something else to keep in mind: the transformer model does not have inherent knowledge. There is no hardcoded logic, database access, and so on. Again, it’s all about making predictions.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04tran" id="id1016"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04tran2" id="id1017"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04tran3" id="id1018"/></p>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Diffusion Model"><div class="sect2" id="diffusion_model">
<h2>Diffusion Model</h2>
<p>In 2015, researchers Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli <a contenteditable="false" data-type="indexterm" data-primary="Ganguli, Surya" id="id1019"/><a contenteditable="false" data-type="indexterm" data-primary="Maheswaranathan, Niru" id="id1020"/><a contenteditable="false" data-type="indexterm" data-primary="Weiss, Eric" id="id1021"/><a contenteditable="false" data-type="indexterm" data-primary="Sohl-Dickstein, Jascha" id="id1022"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="models" data-tertiary="diffusion model" id="id1023"/><a contenteditable="false" data-type="indexterm" data-primary="diffusion models" id="id1024"/>introduced the diffusion model. They set out the core principles in a paper<sup><a data-type="noteref" id="ch01fn6-marker" href="ch04.html#ch01fn6">5</a></sup> that described an innovative way to create new data, such as for images and audio.</p>

<p>As shown in <a data-type="xref" href="#figure_four_fourdot_the_diffusion_model">Figure 4-4</a>, the diffusion model has two primary phases:</p>
<dl>
<dt>Forward diffusion</dt>
<dd><p>The diffusion model gradually adds noise to the original dataset (such as images or audio). Through this process, it learns to understand the data distribution and how it transitions from structured data to pure random noise. This phase maps the pathway from meaningful data to complete noise.</p></dd>
<dt>Reverse diffusion</dt>
<dd><p>The diffusion model reverses the forward process by starting with random noise and systematically removing it through many steps. This generates new data that is different from the original dataset but retains similar characteristics and features. The reverse phase essentially learns to reconstruct structured data from noise, enabling the creation of novel samples.</p></dd>
</dl>

<figure><div id="figure_four_fourdot_the_diffusion_model" class="figure">
<img src="assets/awsc_0404.png" alt="" width="1425" height="677"/>
<h6><span class="label">Figure 4-4. </span>The diffusion model</h6>
</div></figure>

<p>Examples of popular diffusion models<a contenteditable="false" data-type="indexterm" data-primary="OpenAI" data-secondary="DALL-E" id="id1025"/><a contenteditable="false" data-type="indexterm" data-primary="DALL-E (OpenAI)" id="id1026"/><a contenteditable="false" data-type="indexterm" data-primary="Stable Diffusion (Stability AI)" id="id1027"/><a contenteditable="false" data-type="indexterm" data-primary="Midjourney" id="id1028"/> include OpenAI’s DALL-E, Stability AI’s Stable Diffusion, and Midjourney. They use the text-to-image process.</p>
<p>Let’s see how this works in DALL-E (not part of AWS). In the input box for ChatGPT, click “…” and then select Image. Enter the following prompt:</p>
<blockquote>
<p>A floating island with cascading waterfalls that fall into a swirling vortex of stars, under an aurora-lit sky.</p>
</blockquote>
<p><a data-type="xref" href="#figure_four_fivedot_an_image_created_by">Figure 4-5</a> shows the generated image.</p>
<figure><div id="figure_four_fivedot_an_image_created_by" class="figure">
<img src="assets/awsc_0405.png" alt="An image created by OpenAI’s DALL-E" width="709" height="401"/>
<h6><span class="label">Figure 4-5. </span>An image created by OpenAI’s DALL-E</h6>
</div></figure>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Foundation Models"><div class="sect1" id="foundation_models_left_parenthesisfmsri">
<h1>Foundation Models</h1>
<p>With the transformer or diffusion model,<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="generative AI" id="id1029"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="foundation models" id="id1030"/><a contenteditable="false" data-type="indexterm" data-primary="transformer model" data-secondary="foundation models" id="id1031"/><a contenteditable="false" data-type="indexterm" data-primary="diffusion models" data-secondary="foundation models" id="id1032"/> you can create foundation models (FMs). These are what you can use for your business or personal use, such as ChatGPT or Claude.</p>
<p>There are two main types of FMs.<a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="foundation models" data-tertiary="LLMs" id="id1033"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="generative AI" data-tertiary="LLMs" id="id1034"/><a contenteditable="false" data-type="indexterm" data-primary="transformer model" data-secondary="foundation models" data-tertiary="LLMs" id="id1035"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="foundation models" id="id1036"/> One is the large language model (LLM), which is built on the transformer model. An LLM can handle many NLP tasks—answer questions about history, write a poem, write code, and so on. There seems to be no end to the capabilities. By comparison, traditional AI is mostly focused on a single task, such as making a forecast about sales or churn.</p>
<p>Next, there are multimodal models.<a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="foundation models" data-tertiary="multimodal models" id="id1037"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="generative AI" data-tertiary="multimodal models" id="id1038"/><a contenteditable="false" data-type="indexterm" data-primary="multimodal models" data-secondary="foundation models" id="id1039"/><a contenteditable="false" data-type="indexterm" data-primary="transformer model" data-secondary="foundation models" data-tertiary="multimodal models" id="id1040"/><a contenteditable="false" data-type="indexterm" data-primary="diffusion models" data-secondary="foundation models" data-tertiary="multimodal models" id="id1041"/> These models can understand and generate different types of content like text, audio, images, and video. A multimodal system uses both the transformer and diffusion models.</p>
<p>The lifecycle for training FMs and developing applications for them is different from traditional machine learning workflows.<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="generative AI" data-tertiary="lifecycle of FMs" id="c04licy"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="foundation models" data-tertiary="lifecycle" id="c04licy2"/><a contenteditable="false" data-type="indexterm" data-primary="transformer model" data-secondary="foundation models" data-tertiary="lifecycle" id="c04licy3"/><a contenteditable="false" data-type="indexterm" data-primary="diffusion models" data-secondary="foundation models" data-tertiary="lifecycle" id="c04licy4"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="lifecycle" id="c04licy5"/><a contenteditable="false" data-type="indexterm" data-primary="multimodal models" data-secondary="foundation models" data-tertiary="lifecycle" id="c04licy6"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="foundation models" data-tertiary="lifecycle" id="c04licy7"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="lifecycle" data-tertiary="about" id="id1042"/> For the purposes of the exam, the steps are:</p>
<ul>
<li><p>Data selection</p></li>
<li><p>Pretraining</p></li>
<li><p>Optimization</p></li>
<li><p>Evaluation</p></li>
<li><p>Deployment</p></li>
</ul>
<p>Let’s discuss each of these steps in the following sections.</p>
<section data-type="sect2" data-pdf-bookmark="Data Selection"><div class="sect2" id="data_selection">
<h2>Data Selection</h2>
<p>The datasets for FMs are enormous.<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="lifecycle" data-tertiary="data selection" id="id1043"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="foundation models" data-tertiary="selecting data" id="id1044"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" data-tertiary="selecting data" id="id1045"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" data-tertiary="foundation models" id="id1046"/> For example, OpenAI’s GPT-4 model includes nearly 500 billion parameters—the internal values the model adjusts during training to make accurate predictions—and processes around 45 terabytes of data. <a contenteditable="false" data-type="indexterm" data-primary="WebTest" id="id1047"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" data-tertiary="WebTest" id="id1048"/><a contenteditable="false" data-type="indexterm" data-primary="Wikipedia as training data" id="id1049"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" data-tertiary="English Wikipedia" id="id1050"/>Sources for this training data include WebTest (a filtered snapshot of web pages), English Wikipedia, and large collections of public domain books.</p>
<p>What about the more recent models, such as GPT-4 or GPT-o1? There are no details on the dataset size. The main reason is to protect competitive advantages. The world of model development is certainly high-stakes, especially since it costs substantial amounts to build FMs.</p>
<p>For the data selection process, there is no need to wrangle or clean the datasets. The model will work seamlessly with unlabeled data. As we saw earlier in this chapter, the transformer model will detect the patterns, such as with attention mechanisms.</p>
<p>As a rule of thumb,<a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" data-tertiary="larger dataset better" id="id1051"/><a contenteditable="false" data-type="indexterm" data-primary="scaling laws for training data" id="id1052"/> the larger the dataset, the better. This is known as the <em>scaling laws</em>. Research has shown that there is a positive relationship between the number of parameters in the model and the performance.</p>
<p>The data must be high quality and diverse. This helps to reduce the issues with bias and toxic content. Because of this, there is usually extensive curation and filtering of the datasets, which is where data science expertise becomes essential. <a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="selecting for models" data-tertiary="Data Selection with Importance Resampling framework" id="id1053"/><a contenteditable="false" data-type="indexterm" data-primary="Data Selection with Importance Resampling (DSIR) framework" id="id1054"/><a contenteditable="false" data-type="indexterm" data-primary="DSIR (Data Selection with Importance Resampling) framework" id="id1055"/>There is also the use of various data selection methods, like the Data Selection with Importance Resampling (DSIR) framework. This helps to focus on data that is most relevant for a particular application.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Pretraining"><div class="sect2" id="pretraining">
<h2>Pretraining</h2>
<p>The pretraining stage is where<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="lifecycle" data-tertiary="pretraining" id="id1056"/><a contenteditable="false" data-type="indexterm" data-primary="pretraining of foundation models" id="id1057"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="pretraining of foundation models" id="id1058"/><a contenteditable="false" data-type="indexterm" data-primary="semisupervised learning" id="id1059"/><a contenteditable="false" data-type="indexterm" data-primary="unlabeled data" data-secondary="semisupervised learning synthetic labels" id="id1060"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="unlabeled data" data-tertiary="semisupervised learning synthetic labels" id="id1061"/> the model learns to understand and generate humanlike text. This is done by using a technique called <em>semisupervised learning</em>. This takes the unlabeled dataset and creates synthetic labels, which are based on the data itself. For example, the model can use the transformer model to predict missing words or other gaps in a sentence. Given the massive sizes of the datasets, this automated approach is absolutely critical. It would be impossible to handle this in a manual way.</p>
<p>But there is more to the process. There is also continuous pretraining, which is when the model is exposed to more data to refine and improve the learning.</p>
<p>The pretraining and continuous pretraining require significant amounts of computing resources. <a contenteditable="false" data-type="indexterm" data-primary="GPUs (Graphics Processing Units)" id="id1062"/><a contenteditable="false" data-type="indexterm" data-primary="Tensor Processing Units (TPUs)" id="id1063"/><a contenteditable="false" data-type="indexterm" data-primary="TPUs (Tensor Processing Units)" id="id1064"/>A key part of this is the use of graphics processing units (GPUs) or tensor processing units (TPUs). GPUs are designed for parallel processing and are widely used in deep learning and generative AI models, while TPUs are specialized hardware developed by Google specifically to accelerate machine learning tasks.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Optimization"><div class="sect2" id="optimization">
<h2>Optimization</h2>
<p>An FM is quite powerful.<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="lifecycle" data-tertiary="optimization" id="c04opt"/><a contenteditable="false" data-type="indexterm" data-primary="optimization of foundation models" id="c04opt2"/><a contenteditable="false" data-type="indexterm" data-primary="optimization of foundation models" data-secondary="about" id="id1065"/> But it will not be trained on proprietary data. This can certainly be limiting for businesses, which need more specialized FMs, say for handling customer support, legal, marketing, sales, and so on. What can you do? You can optimize an FM, which involves two main approaches:</p>
<ul>
<li><p>Fine-tuning</p></li>
<li><p>Retrieval-augmented generation</p></li>
</ul>
<section data-type="sect3" data-pdf-bookmark="Fine-tuning"><div class="sect3" id="fine_tuning-id000026">
<h3 class="less_space">Fine-tuning</h3>
<p>Suppose you work in<a contenteditable="false" data-type="indexterm" data-primary="optimization of foundation models" data-secondary="fine-tuning" id="id1066"/><a contenteditable="false" data-type="indexterm" data-primary="fine-tuning" data-secondary="foundation models" id="id1067"/> your company’s legal department. While FMs are useful for applications like summarization, they do not perform well when it comes to complex legal queries.</p>
<p>If you want to create a system that can effectively extract contract clauses and entities, you can use fine-tuning of an existing FM. This is also known as <em>transfer learning</em>, which is where a model developed for one purpose can be used for another.</p>
<p>Here are the main steps for fine-tuning:<a contenteditable="false" data-type="indexterm" data-primary="privacy" data-secondary="fine-tuning a foundation model" id="id1068"/><a contenteditable="false" data-type="indexterm" data-primary="labeled data" data-secondary="fine-tuning a foundation model" id="id1069"/><a contenteditable="false" data-type="indexterm" data-primary="supervised learning" data-secondary="fine-tuning a foundation model" id="id1070"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="labeled data" data-tertiary="fine-tuning a foundation model" id="id1071"/><a contenteditable="false" data-type="indexterm" data-primary="instruction fine-tuning" id="id1072"/><a contenteditable="false" data-type="indexterm" data-primary="reinforcement learning from human feedback (RLHF)" id="id1073"/></p>
<dl>
<dt>Data collection</dt>
<dd><p>Gather relevant documents that are specific to your domain or task. In our example, this would include contracts, agreements, and legal correspondence.</p></dd>
<dt>Privacy and security</dt>
<dd><p>Fine-tuning often uses proprietary or highly sensitive data. This is why there needs to be strong privacy, security policies, and guardrails in place. The data should also be evaluated to mitigate issues with bias.</p></dd>
<dt>Data labeling</dt>
<dd><p>Fine-tuning is a supervised learning process. This means you will label the dataset, such as marking specific clauses and entities.</p></dd>
</dl>
<dl>
<dt>Training</dt>
<dd><p>You will apply an algorithm to the dataset to adjust the weights and biases of the model. For this, there are two main approaches—instruction fine-tuning and reinforcement learning from human feedback (RLHF):</p>
	<dl>
<dt>Instruction fine-tuning</dt> 
<dd><p>This processes examples of how a model should respond based on certain prompts and the output to help the system learn better. It can be quite effective for applications like chatbots and virtual assistants.</p></dd>
<dt>RLHF</dt>
<dd><p>The first step in this process is to train the model using supervised learning, where it learns based on predicting humanlike responses. The next step is to refine the responses by using reinforcement learning, which is based on human feedback. It will reward or punish the responses based on this. The goal is to create a model that aligns more with human values.</p></dd>
</dl>
</dd>
<dt>Iterate and evaluate</dt>
<dd><p>You will iterate this on the dataset until the model learns to recognize and extract the clauses and entities.</p></dd>
</dl>
<p>Besides customizing the FM, <a contenteditable="false" data-type="indexterm" data-primary="bias" data-secondary="fine-tuning foundation models" id="id1074"/><a contenteditable="false" data-type="indexterm" data-primary="accuracy" data-secondary="fine-tuning foundation models" id="id1075"/>fine-tuning can also improve the overall accuracy of the responses and help to reduce the bias. There is also the benefit of efficiency. You can leverage an existing model and make much smaller modifications to get better results.</p>
<p>But there are drawbacks to fine-tuning.<a contenteditable="false" data-type="indexterm" data-primary="fine-tuning" data-secondary="foundation models" data-tertiary="drawbacks" id="id1076"/> Like with a traditional ML model, there is the risk of overfitting. The reason is that the datasets can be too narrow. Another issue is that the fine-tuning may go too far—that is, the model may lose its advantages for being general-purpose. Finally, fine-tuning can still take considerable resources, often needing sophisticated GPUs and AI platforms.</p>
<p>To help with the problems, there are more advanced fine-tuning methods:<a contenteditable="false" data-type="indexterm" data-primary="fine-tuning" data-secondary="foundation models" data-tertiary="advanced fine-tuning methods" id="id1077"/><a contenteditable="false" data-type="indexterm" data-primary="low-rank adaptation (LoRA)" id="id1078"/><a contenteditable="false" data-type="indexterm" data-primary="representation fine-tuning (ReFT)" id="id1079"/><a contenteditable="false" data-type="indexterm" data-primary="ReFT (representation fine-tuning)" id="id1080"/></p>
<dl>
<dt>Low-rank adaptation (LoRA)</dt>
<dd><p>Instead of adjusting all the model’s parameters, this technique takes a more targeted approach, using much fewer resources.</p></dd>
<dt>Representation fine-tuning (ReFT)</dt>
<dd><p>This is an even more efficient approach to fine-tuning, which modifies less than 1% of the internal weights of the model.</p></dd>
</dl>
</div></section>
<section data-type="sect3" data-pdf-bookmark="RAG"><div class="sect3" id="rag">
<h3>RAG</h3>
<p>In 2024, <em>Time</em> magazine <a contenteditable="false" data-type="indexterm" data-primary="optimization of foundation models" data-secondary="RAG" id="c04rag"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" id="c04rag2"/><a contenteditable="false" data-type="indexterm" data-primary="Lewis, Patrick" id="id1081"/>named Patrick Lewis as one of the 100 most influential people in AI.<sup><a data-type="noteref" id="ch01fn7-marker" href="ch04.html#ch01fn7">6</a></sup> The primary reason for this is a paper<sup><a data-type="noteref" id="ch01fn8-marker" href="ch04.html#ch01fn8">7</a></sup> he cowrote in 2020 with other researchers from Meta, which set forth a framework to connect data to LLMs by searching external databases.</p>
<p>The authors called it <em>retrieval-augmented generation</em>. <a contenteditable="false" data-type="indexterm" data-primary="hallucinations" data-secondary="RAG reducing" id="id1082"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="hallucinations reduced" id="id1083"/>It not only allowed for customizing LLMs but also reducing hallucinations. RAG was also generally easier to use than fine-tuning, as there were no changes to the weights of the model. The process is outlined in <a data-type="xref" href="#figure_four_sixdot_the_rag_process">Figure 4-6</a>.</p>
<figure><div id="figure_four_sixdot_the_rag_process" class="figure">
<img src="assets/awsc_0406.png" alt="" width="1064" height="1094"/>
<h6><span class="label">Figure 4-6. </span>The RAG process</h6>
</div></figure>
<p>Here’s a look at the main steps:</p>
<dl>
<dt>Data collection and indexing</dt>
<dd><p>The RAG process begins by collecting relevant data from various sources such as PDFs, reports, articles, web pages, logs, and customer feedback. This information is then prepared for processing and storage.</p></dd>
<dt>Chunking</dt>
<dd><p>Since LLMs have limits on how much data they can process at once, the collected dataset is divided into smaller, manageable chunks.</p></dd>
<dt>Embedding creation</dt>
<dd><p>Each chunk of information<a contenteditable="false" data-type="indexterm" data-primary="embeddings" data-secondary="RAG" id="id1084"/> is converted into a vector embedding using a specialized machine learning model. These embeddings capture the semantic meaning of the data and represent it in a high-dimensional mathematical format.</p></dd>
<dt>Vector database storage</dt>
<dd><p>The generated embeddings are stored in a vector database, which is a specialized system designed to manage and efficiently search through high-dimensional <span class="keep-together">vectors.</span></p></dd>
<dt>User input</dt>
<dd><p>When a user submits a query or prompt, this marks the beginning of the retrieval phase of the RAG process.</p></dd>
<dt>Processing user input</dt>
<dd><p>The user’s prompt is converted into an embedding using the same ML model that was used for the data chunks. This ensures consistency between the user query representation and the stored data representations.</p></dd>
<dt>Retrieval</dt>
<dd><p>The system performs similarity search using techniques such as k-nearest neighbors (k-NN), which finds the most similar data points, or cosine similarity, which measures how closely the direction of two vectors aligns. This process locates the chunks in the vector database that best match the user’s prompt.</p></dd>
<dt>Augmentation</dt>
<dd><p>The retrieved relevant information is combined with the original user prompt to create an augmented prompt that contains both the user’s question and the contextual information needed to answer it.</p></dd>
<dt>Response</dt>
<dd><p>The augmented prompt is submitted to the LLM for processing. The LLM generates a response that reflects both the user’s original prompt and the relevant chunks of information retrieved from the vector database. This should result in a more informed and accurate answer.</p></dd>
</dl>
<p>Keep in mind that <a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="AWS vector database capabilities" id="id1085"/><a contenteditable="false" data-type="indexterm" data-primary="vector databases" data-secondary="AWS capabilities" id="id1086"/>AWS offers numerous options for vector database capabilities. <a contenteditable="false" data-type="indexterm" data-primary="Amazon OpenSearch Service" id="id1087"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon OpenSearch Serverless" id="id1088"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Kendra" data-secondary="vector database capabilities" id="id1089"/>Examples include Amazon OpenSearch Service, Amazon OpenSearch Serverless, and Amazon Kendra.</p>
<p>There is also vector databases<a contenteditable="false" data-type="indexterm" data-primary="vector databases" data-secondary="pgvector support" id="id1090"/><a contenteditable="false" data-type="indexterm" data-primary="pgvector support in vector databases" id="id1091"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="AWS vector database capabilities" data-tertiary="pgvector support" id="id1092"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Aurora" id="id1093"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon RDS" data-secondary="vector databases" id="id1094"/> that use pgvector (this is for Amazon RDS and Amazon Aurora PostgreSQL-Compatible Edition). This is an extension for PostgreSQL, which is a popular open source database. Pgvector allows for storing, indexing, and querying of high-dimensional vector data. There are also enterprise features, such as atomicity, consistency, isolation, durability (ACID) compliance (which helps to provide for reliable transactions), point-in-time recovery, and support for complex queries.</p>
<p>RAG has seen significant adoption.<a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="broad adoption" id="id1095"/> According to a survey from <a href="https://oreil.ly/Ld7Wg">451 Research</a>, about 87% of the respondents said that they consider this method to be an effective approach for customization. Yet RAG has some disadvantages:<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04opt" id="id1096"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04opt2" id="id1097"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04rag" id="id1098"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04rag2" id="id1099"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="disadvantages of" id="id1100"/></p>
<dl>
<dt>Data</dt>
<dd><p>An organization may not use enough relevant information. Or they may choose the wrong sources. Creating a useful RAG system usually requires data science expertise.</p></dd>
<dt>Search limitations</dt>
<dd><p>Semantic search may have a good match, but it can sometimes miss the overall context of the information.</p></dd>
<dt>Chunking problems</dt>
<dd><p>The chunking process can be delicate. It’s common to make inadequate divisions.</p></dd>
</dl>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Evaluation"><div class="sect2" id="evaluation-id000027">
<h2>Evaluation</h2>
<p>With an FM—whether it is fine-tuned or uses RAG—you<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="lifecycle" data-tertiary="evaluation" id="c04evfm"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" id="c04evfm2"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="evaluation" id="c04evfm3"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" data-secondary="about" id="id1101"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="evaluation" data-tertiary="about" id="id1102"/> will need to evaluate it. Is it performing properly? Are the responses accurate? Are there hallucinations? Is there harmful or toxic content generated?</p>
<p>The evaluation process is complex and time-consuming. But it is critical, in terms of building trust with users and effectively solving business problems.</p>
<p>There are three main ways to evaluate an FM:</p>
<ul>
<li><p>Human evaluation</p></li>
<li><p>Benchmark datasets</p></li>
<li><p>Standard evaluation metrics</p></li>
</ul>
<section data-type="sect3" data-pdf-bookmark="Human evaluation"><div class="sect3" id="human_evaluation">
<h3 class="less_space">Human evaluation</h3>
<p>Human evaluation is essential<a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" data-secondary="human evaluation" id="id1103"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="evaluation" data-tertiary="human evaluation" id="id1104"/> because it helps assess aspects of a model that automated metrics may miss, such as user experience, creativity, and ethical behavior. These areas are often subjective and require nuanced human judgment. Human evaluation typically focuses on several key areas:</p>
<dl>
<dt>User experience</dt>
<dd><p>How natural, intuitive, or satisfying is the interaction? One common metric is the Net Promoter Score (NPS), which asks, how likely are you to recommend this product or service to others?—rated on a scale from 0 to 10. Participants may also be asked: Was the response easy to understand? Did it feel conversational?</p></dd>
<dt>Contextual appropriateness</dt>
<dd><p>Does the model stay on topic and provide responses that make sense in the given context? Reviewers might consider questions like, did the model understand the question? Did it refer to previous parts of the conversation accurately?</p></dd>
<dt>Creativity and flexibility</dt>
<dd><p>Are the responses varied and interesting—or repetitive and dull? Evaluators can assess whether the model provides diverse outputs when asked to generate content or brainstorm ideas.</p></dd>
<dt>Ethical considerations</dt>
<dd><p>Are there signs of bias, harmful outputs, or inappropriate content? Human reviewers play a critical role in spotting these issues that may slip past automated filters.</p></dd>
<dt>Emotional intelligence</dt>
<dd><p>Can the FM detect and respond appropriately to emotional tones, such as frustration, excitement, or sadness? Questions may include: Did the model acknowledge the user’s emotions? Did it respond in a sensitive manner?</p></dd>
</dl>
<p>Human evaluations are usually conducted through panels or focus groups, which may range from a handful of participants to over 100. Evaluators are often selected based on criteria such as:</p>
<ul>
<li><p>Target audience (e.g., specific industry professionals)</p></li>
<li><p>Diverse backgrounds (e.g., race, gender, culture)</p></li>
<li><p>Experience level (from novice users to experts)</p></li>
</ul>
<p>Participants typically spend time prompting the FM, reviewing its outputs, and providing detailed feedback. This is often followed by surveys or structured interviews.</p>
<p>There’s also a form of passive human evaluation that’s built directly into many FMs. For example, ChatGPT allows users to give a thumbs up or down after a response. Some platforms include embedded feedback forms or prompt users to rate helpfulness. This type of real-time, user-driven feedback is valuable for tracking long-term trends and improving future versions of the model.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Benchmark datasets"><div class="sect3" id="benchmark_datasets">
<h3>Benchmark datasets</h3>
<p>A benchmark dataset allows for making a quantitative evaluation of an FM. They help gauge:<a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" data-secondary="benchmark datasets" id="id1105"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="evaluation" data-tertiary="benchmark datasets" id="id1106"/><a contenteditable="false" data-type="indexterm" data-primary="robustness" data-secondary="benchmark datasets gauging" id="id1107"/></p>
<dl>
<dt>Accuracy</dt>
<dd><p>Does the FM perform tasks based on certain agreed-upon standards?</p></dd>
<dt>Speed and efficiency</dt>
<dd><p>How fast does the FM take to generate a response? How many resources does it use? For example, some FMs will need to work in real time, such as with self-driving cars.</p></dd>
<dt>Scalability</dt>
<dd><p>If the FM is serving heavy volumes, is the performance consistent?</p></dd>
<dt>Responsible AI</dt>
<dd><p>This evaluates the FM for factors like bias and fairness.</p></dd>
<dt>Robustness</dt>
<dd><p>How does the FM perform when there are unusual or adversarial prompts?</p></dd>
<dt>Generalization</dt>
<dd><p>This measures an FM’s ability to handle unseen data or tasks.</p></dd>
</dl>
<p>Creating a benchmark dataset can be challenging, as it usually takes the skills of an experienced data scientist. But there is also often the need to have one or more subject matter experts (SMEs) involved in the process. They will have the necessary experience for the domain that is being tested. For example, if a dataset benchmark is for drug discovery, then there will need to be SMEs who have a background in the pharmaceutical industry.</p>
<p><a data-type="xref" href="#figure_four_sevendot_process_for_develo">Figure 4-7</a> shows the steps to putting together a dataset benchmark.</p>
<figure><div id="figure_four_sevendot_process_for_develo" class="figure">
<img src="assets/awsc_0407.png" alt="" width="1213" height="739"/>
<h6><span class="label">Figure 4-7. </span>Process for developing dataset benchmarks</h6>
</div></figure>
<p>Let’s look at these steps in more detail:</p>
<dl>
<dt>SMEs create relevant questions</dt>
<dd><p>SMEs develop a comprehensive set of questions that are not only relevant to the domain but also challenging enough to truly evaluate the FM’s capabilities. These questions are designed to test the depth and breadth of the FM’s knowledge and reasoning abilities.</p></dd>
<dt>SMEs create answers</dt>
<dd><p>The same SMEs conduct extensive research to provide high-quality reference answers to each question.</p></dd>
<dt>FM processing</dt>
<dd><p>The created questions are submitted to the FM being evaluated. The FM generates its own answers to each question, which will later be compared against the SME-created reference answers.</p></dd>
<dt>Judge model</dt>
<dd><p>An AI model serves as the judge, comparing the FM’s generated answers against the SME reference answers. The judge model evaluates the FM’s responses across multiple criteria, including accuracy, relevance, and comprehensiveness.</p></dd>
<dt>Performance score</dt>
<dd><p>Based on the judge model’s comparative analysis, a final benchmark score is generated. This score provides a quantitative measure of the FM’s performance.</p></dd>
</dl>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Standard evaluation metrics"><div class="sect3" id="standard_evaluation_metrics">
<h3>Standard evaluation metrics</h3>
<p>A standard evaluation metric<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="evaluation" data-tertiary="standard evaluation metrics" id="c04metr"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" data-secondary="standard evaluation metrics" id="c04metr2"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" data-secondary="standard evaluation metrics" data-tertiary="about" id="id1108"/> is a widely used measurement to assess the performance of an FM. There are many available. But for the purposes of the AIF-C01 exam, these are the ones that you need to know:</p>
<ul>
<li><p>Recall-Oriented Understudy for Gisting Evaluation (ROUGE)</p></li>
<li><p>Bilingual evaluation understudy (BLEU)</p></li>
<li><p>Bidirectional encoder representations from transformers score (BERTScore)</p></li>
</ul>
<section data-type="sect4" data-pdf-bookmark="ROUGE"><div class="sect4" id="rouge">
<h4>ROUGE</h4>
<p>ROUGE is a collection of metrics<a contenteditable="false" data-type="indexterm" data-primary="Recall-Oriented Understudy for Gisting Evaluation (ROUGE)" id="c04rge"/><a contenteditable="false" data-type="indexterm" data-primary="ROUGE (Recall-Oriented Understudy for Gisting Evaluation)" id="c04rge2"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" data-secondary="standard evaluation metrics" data-tertiary="ROUGE" id="c04rge3"/> to evaluate automatic summarization of text and machine translation, such as for foreign languages. It compares the overlaps of the content generated with an LLM to reference summaries, which are usually created by humans.</p>
<p>There are different types of ROUGE metrics, and each one measures similarity between machine-generated text and reference  text in a specific way. One key category is ROUGE-N, which focuses on n-gram overlap. An <em>n</em>-gram is a sequence of <em>n</em> consecutive words.</p>
<p>For example, ROUGE-1 evaluates unigram (single word) overlap:</p>
<ul class="list_style_type_none">
<li><p>Sentence: “The car stopped suddenly”</p></li>
<li><p>Unigrams: “The,” “car,” “stopped,” “suddenly”</p></li>
</ul>
<p>Then ROUGE-2 evaluates bigram (two-word) overlap:</p>
<ul class="list_style_type_none">
<li><p>Bigrams: “The car,” “car stopped,” “stopped suddenly”</p></li>
</ul>
<p>You can continue with ROUGE-3, ROUGE-4, etc., to evaluate longer phrase matches.</p>
<p>Why use different <em>n</em> values? Because they give you different perspectives:</p>
<ul>
<li><p>ROUGE-1 captures basic word usage.</p></li>
<li><p>ROUGE-2 and higher capture more structure, phrasing, and fluency.</p></li>
</ul>
<p>These distinctions help break down what kind of similarity the model is capturing—are the right words there? Are they in the right order? This makes evaluation more granular and insightful.</p>
<p>For interpreting ROUGE-N scores, the range is 0 to 1:</p>
<dl>
<dt>Good score</dt>
<dd><p>Typically, a score above 0.5 (50%) is considered strong, especially for ROUGE-1. However, what’s “good” depends on the task.</p></dd>
<dt>Bad score</dt>
<dd><p>A score near 0 means very little overlap, suggesting the model didn’t capture important content.</p></dd>
</dl>
<p>In short, ROUGE-N helps you assess how well a model captures the key words and phrases a human would expect—step-by-step, from simple terms to full phrasing.</p>
<p>Next, there is ROUGE-L (longest common subsequence), which is a metric used to evaluate the similarity between a machine-generated text and a human-written reference by measuring the longest sequence of words that appears in both texts in the same order, though not necessarily consecutively. It is especially useful for evaluating long-form content like summaries or narratives, where exact word matches might be less important than preserving the structure and meaning of the original.</p>
<p>Let’s take an example. Suppose we have this reference that is human written:</p>
<blockquote>
<p>The quick brown fox jumps over the lazy dog.</p>
</blockquote>
<p>This is what the model generated:</p>
<blockquote>
<p>The brown fox quickly jumps over a lazy dog.</p>
</blockquote>
<p>Let’s find the longest common subsequence (LCS)—words that appear in both texts, in the same order:</p>
<blockquote>
<p>Common words: “The,” “brown,” “fox,” “jumps,” “over,” “lazy,” “dog”</p>
</blockquote>
<p>Then this is the LCS:</p>
<blockquote>
<p>The brown fox jumps over lazy dog.</p>
</blockquote>
<p>This is a strong structural match even though some words differ slightly (<em>quickly</em> versus <em>quick</em>, or missing <em>the</em>).</p>
<p class="pagebreak-before">In terms of the score:</p>
<ul>
<li><p>Scores above 0.6 are generally good, especially for complex narratives.</p></li>
<li><p>Scores in the 0.3–0.5 range may indicate decent content, but poorer structure or coherence.</p></li>
</ul>
<p>A key benefit of ROUGE is that it is fairly simple, straightforward, and based on human judgment. But it is also an effective metric in measuring similarity.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04rge" id="id1109"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04rge2" id="id1110"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04rge3" id="id1111"/></p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="BLEU"><div class="sect4" id="bleu">
<h4>BLEU</h4>
<p>BLEU is a metric <a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" data-secondary="standard evaluation metrics" data-tertiary="BLEU" id="id1112"/><a contenteditable="false" data-type="indexterm" data-primary="BLEU (bilingual evaluation understudy)" id="id1113"/>used to evaluate the quality of machine-generated text by comparing it to human-written reference text. The closer the match, the better the quality—especially in translation tasks. BLEU scores range from 0 to 1, with 1 indicating a perfect match.</p>
<p>While BLEU is similar to ROUGE in that both rely on <em>n</em>-gram analysis, there are key differences. BLEU focuses on precision, measuring how many of the generated <em>n</em>-grams appear in the reference and averaging them. It also penalizes shorter outputs through a “brevity penalty,” ensuring translations aren’t overly concise just to match key terms.</p>
<p>Introduced in the early 2000s, BLEU was one of the first automatic evaluation metrics for machine translation and remains widely used for its effectiveness and simplicity.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="BERTScore"><div class="sect4" id="bertscore">
<h4>BERTScore</h4>
<p>In 2018, researchers published a paper<sup><a data-type="noteref" id="ch01fn9-marker" href="ch04.html#ch01fn9">8</a></sup> in which<a contenteditable="false" data-type="indexterm" data-primary="BERTScore" id="id1114"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" data-secondary="standard evaluation metrics" data-tertiary="BERTScore" id="id1115"/> they created a new model called BERT, representing a major breakthrough for NLP. Google would eventually open source it. The result was that BERT became quite popular in the AI community, spawning variations on the model like RoBERTa and DistilBERT.</p>
<p>BERT also laid the foundation for a new evaluation metric: BERTScore. Unlike BLEU and ROUGE, which rely on exact or partial <em>n</em>-gram matches, BERTScore evaluates the semantic similarity between generated text and reference text. That is, it doesn’t just look at whether the same words appear—it checks whether the meaning is preserved. This is made possible through<a contenteditable="false" data-type="indexterm" data-primary="embeddings" data-secondary="BERTScore" id="id1116"/> semantic search, a technique that uses vector embeddings to compare the meanings of words or sentences rather than their surface forms. For example, if a reference sentence says, “The cat sat on the mat,” and the generated version says, “A feline rested on a rug,” traditional metrics might score this poorly due to word mismatch. But BERTScore could recognize that the meaning is nearly identical.</p>
<p>BERTScore offers a more nuanced view of text quality, which is especially useful when evaluating LLM outputs that may use different wording but convey the same idea. That said, it’s not meant to replace BLEU or ROUGE. In practice, data scientists often use multiple metrics together to get a fuller picture of model performance.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Resource for benchmark metrics: Hugging Face"><div class="sect4" id="resource_for_benchmark_metrics_hugging">
<h4>Resource for benchmark metrics: Hugging Face</h4>
<p>In 2016, Clément Delangue, Julien Chaumond, and Thomas Wolf launched Hugging Face (<em>huggingface.co</em>).<a contenteditable="false" data-type="indexterm" data-primary="Wolf, Thomas" id="id1117"/><a contenteditable="false" data-type="indexterm" data-primary="Chaumond, Julien" id="id1118"/><a contenteditable="false" data-type="indexterm" data-primary="Delangue, Clément" id="id1119"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" data-secondary="standard evaluation metrics" data-tertiary="Hugging Face resource" id="id1120"/><a contenteditable="false" data-type="indexterm" data-primary="Hugging Face resource" id="id1121"/><a contenteditable="false" data-type="indexterm" data-primary="resources online" data-secondary="Hugging Face" id="id1122"/><a contenteditable="false" data-type="indexterm" data-primary="benchmark metrics resource Hugging Face" id="id1123"/> They first developed a chatbot that allowed teens to interact with an AI pal. The startup failed to get traction. But the founders did not give up. When building their chatbot, they saw that there was a need to have a hub for open source AI models and applications.</p>
<p>Today, Hugging Face is the place that many AI people go. There are over 1.4 million AI models that you can download, and there are over 318,000 datasets. For all the AI models, there are detailed profiles, which include documentation, code samples, use cases, license information, and limitations. There are also benchmark metrics, which will often have comparisons to other models.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Issues with benchmark metrics"><div class="sect4" id="issues_with_benchmark_metrics">
<h4>Issues with benchmark metrics</h4>
<p>The use of metrics can be a <a contenteditable="false" data-type="indexterm" data-primary="benchmark metrics resource Hugging Face" data-secondary="issues with benchmark metrics" id="id1124"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation of foundation models" data-secondary="standard evaluation metrics" data-tertiary="issues with benchmark metrics" id="id1125"/>controversial topic. There has been growing concern that they are not particularly effective or may be misleading. Part of the reason is that LLMs are highly complex and their inner workings may not be disclosed. Next, the LLM developers themselves are often the ones who compute the metrics, such as by publishing a blog or a white paper. But there are other issues:</p>
<dl>
<dt>Prompts</dt>
<dd><p>Even a small change in the wording can have a major impact on the results for a metric.</p></dd>
<dt>Copying</dt>
<dd><p>The dataset for the metrics may actually be part of the training for an LLM. In a way, this is like when a student cheats on an exam.</p></dd>
<dt>Real-world application</dt>
<dd><p>Tests generally are focused on more theoretical aspects of an LLM. It may not pick up on real-world situations.</p></dd>
<dt>Narrowness</dt>
<dd><p>An evaluation metric will usually focus on one task or category.</p></dd>
<dt>Edge cases</dt>
<dd><p>It’s common for evaluation metrics to focus mostly on common use cases.</p></dd>
</dl>
<p>To help address these problems,<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="evaluation" data-tertiary="platforms for ranking LLMs" id="id1126"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="platforms for ranking LLMs" id="id1127"/><a contenteditable="false" data-type="indexterm" data-primary="Chatbot Arena" id="id1128"/><a contenteditable="false" data-type="indexterm" data-primary="Angelopoulos, Anastasios" id="id1129"/><a contenteditable="false" data-type="indexterm" data-primary="Chiang, Wei-Lin" id="id1130"/> there have emerged platforms that rank LLMs, such as Chatbot Arena. UC Berkeley roommates—Anastasios Angelopoulos and Wei-Lin Chiang—launched it in 2023. What started as a school project has turned into one of the most popular destinations for data scientists and AI companies.</p>
<p>The system uses a simple form where users ask a question and there are responses from two anonymous LLMs. They will rate which is better. Currently, there are over <a href="https://oreil.ly/GojrE">170 models</a> on the platform, and they have logged more than two million votes.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04evfm" id="id1131"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04evfm2" id="id1132"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04evfm3" id="id1133"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04metr" id="id1134"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04metr2" id="id1135"/></p>
</div></section>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Deployment"><div class="sect2" id="deployment">
<h2>Deployment</h2>
<p>After an LLM meets the<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="lifecycle" data-tertiary="deployment" id="id1136"/><a contenteditable="false" data-type="indexterm" data-primary="deploying a model" data-secondary="foundation models" id="id1137"/><a contenteditable="false" data-type="indexterm" data-primary="model deployment" data-secondary="foundation models" id="id1138"/> necessary performance criteria, it’s time to put it into production. This can mean that the model will be placed into an application or made available as an API. If the model is open source, it can be posted on a platform like Hugging Face or Grok.</p>
<p>As with any AI model, there should be ongoing monitoring and tracking, such as for accuracy, latency, and performance. There should also be evaluation of bias, energy usage, security, and potential toxic content. All this data is collected for the next model. For example, it’s typical for there to be minor updates every couple months. As for major upgrades, these may happen every six months to a year.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04licy" id="id1139"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04licy2" id="id1140"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04licy3" id="id1141"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04licy4" id="id1142"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04licy5" id="id1143"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04licy6" id="id1144"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04licy7" id="id1145"/></p>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Capabilities of Generative AI"><div class="sect1" id="capabilities_of_generative_ai">
<h1>Capabilities of Generative AI</h1>
<p>Generative AI is a powerful technology.<a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="capabilities of" id="id1146"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="generative AI" data-tertiary="capabilities of" id="id1147"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="foundation models" data-tertiary="capabilities of" id="id1148"/> But there are certain areas where it performs exceptionally well. It’s important to know about them when implementing this technology, which will allow for better results.</p>
<p>Perhaps one of the biggest capabilities of generative AI is that it can automate tedious activities. True, a person can summarize a long document. But an FM can do this in a few seconds—and often with higher accuracy. What this means is that the AI can free up time for people to work on more important tasks.</p>
<p>For the exam, here are some of the other capabilities to understand about generative AI:</p>
<dl>
<dt>Adaptability</dt>
<dd><p>An FM can span many domains. This is one of the most important advantages of generative AI. For businesses, this means that—instead of relying on multiple applications—there can be just one.</p></dd>
<dt>Responsiveness</dt>
<dd><p>Generative AI usually can generate responses in near real time, which is critical for applications like chatbots.</p></dd>
<dt>Simplicity</dt>
<dd><p>With a prompt or two, you can generate humanlike content, say a blog, memo, or email.</p></dd>
<dt>Data efficiency</dt>
<dd><p>You can help an FM learn using a few pieces of data.</p></dd>
<dt>Personalization</dt>
<dd><p>The responses can be tailored to your preferences. This can be automated based on prior interactions with the AI application.</p></dd>
<dt>Scalability</dt>
<dd><p>Generative AI can process large amounts of data. Depending on the model, it can be as large as books.<a contenteditable="false" data-type="indexterm" data-primary="scalability" data-secondary="generative AI capability" id="id1149"/></p></dd>
</dl>
<p>In fact, an FM can even<a contenteditable="false" data-type="indexterm" data-primary="creativity from a generative AI foundation model" id="id1150"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="creativity exhibited" id="id1151"/> exhibit creativity, allowing for sparking ideas. A key reason for this is that the model leverages huge amounts of data and is based on probabilistic relationships.</p>
<p>Consider a case study from a Wharton School MBA innovation course. Professors asked students to come up with a dozen ideas for new products or services. ChatGPT generated its own ideas, which included a dorm room chef kit and a collapsible laundry hamper. The professors then had an independent online panel evaluate the ideas and the results were startling. For those that were judged to be good ideas, 40% were from the students and 47% came from ChatGPT (the rest were neutral).<sup><a data-type="noteref" id="ch01fn10-marker" href="ch04.html#ch01fn10">9</a></sup> Moreover, of the 40 best ideas, only five came from the students. According to the professors:</p>
<blockquote>
<p>We predict such a human-machine collaboration will deliver better products and services to the market, and improved solutions for whatever society needs in the future.</p>
</blockquote>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Drawbacks of Generative AI"><div class="sect1" id="drawbacks_of_generative_ai">
<h1>Drawbacks of Generative AI</h1>
<p>After the launch of ChatGPT, it would not<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="generative AI" data-tertiary="drawbacks of" id="c04draw"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="about" id="id1152"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="about" id="id1153"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="letter requesting pause" id="id1154"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="letter requesting pause" id="id1155"/> take long for issues to arise. By March 2023, technology leaders and researchers wrote an open letter expressing fears that generative AI could lead to major disruptions, like job displacement, disinformation, and loss of control of critical systems.<sup><a data-type="noteref" id="ch01fn11-marker" href="ch04.html#ch01fn11">10</a></sup> The letter called for the pause—for six months—of the development of FMs that were more powerful than OpenAI’s GPT-4 (at the time, this was the company’s top model). <a contenteditable="false" data-type="indexterm" data-primary="Wozniak, Steve" id="id1156"/><a contenteditable="false" data-type="indexterm" data-primary="Harari, Yuval Noah" id="id1157"/><a contenteditable="false" data-type="indexterm" data-primary="Musk, Elon" id="id1158"/>Some of the notable signatories were Steve Wozniak, Yuval Noah Harari, and Elon Musk.</p>
<p>Of course, the AI industry did not pause development. Rather, the pace increased significantly. There were no major incidents or mishaps, but this does not imply that generative AI is not without considerable issues. Some of the main ones include:</p>
<ul>
<li><p>Hallucinations</p></li>
<li><p>Nondeterminism</p></li>
<li><p>Interpretability</p></li>
<li><p>Data security and privacy</p></li>
<li><p>Social and branding risks</p></li>
<li><p>Limited context windows</p></li>
<li><p>Recency</p></li>
<li><p>Costs</p></li>
<li><p>Data challenge</p></li>
</ul>
<section data-type="sect2" data-pdf-bookmark="Hallucinations"><div class="sect2" id="hallucinations">
<h2 class="less_space">Hallucinations</h2>
<p>A hallucination is where<a contenteditable="false" data-type="indexterm" data-primary="hallucinations" id="id1159"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="hallucinations" id="id1160"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="hallucinations" id="id1161"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="hallucinations" id="id1162"/> an FM creates a false or misleading response. Some of the reasons for this are datasets that do not have enough relevant information and the probabilistic nature of the generative AI. According to research from Vectara—which publishes a hallucination leaderboard on GitHub—the largest FMs from OpenAI, Google, and Anthropic show hallucination rates of anywhere from 2.5% to 8.5%.<sup><a data-type="noteref" id="ch01fn12-marker" href="ch04.html#ch01fn12">11</a></sup> In some cases, it can be more than 15%.</p>
<p>A way to deal with this is to customize FMs,<a contenteditable="false" data-type="indexterm" data-primary="hallucinations" data-secondary="RAG reducing" id="id1163"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="hallucinations reduced" id="id1164"/><a contenteditable="false" data-type="indexterm" data-primary="fine-tuning" data-secondary="hallucinations reduced" id="id1165"/> such as with fine-tuning and RAG. Another approach is to be more thoughtful with creating prompts, which we’ll learn about in the next chapter.</p>
<p>Some of the LLM providers have been integrating systems to help check the accuracy of the systems. This can involve doing a search of the internet to verify facts. Take ChatGPT. When you write a prompt, you can specify “Search.” This will access the internet for the response. It will also provide links to the references. <a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="deep research feature" id="id1166"/><a contenteditable="false" data-type="indexterm" data-primary="deep research feature of ChatGPT" id="id1167"/>ChatGPT also has a feature called <em>deep research</em>. This conducts a multistep research of a topic, such as by using more than 10 resources when generating a response.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Nondeterminism"><div class="sect2" id="nondeterminism">
<h2>Nondeterminism</h2>
<p>Nondeterminism is when<a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="nondeterminism" id="id1168"/><a contenteditable="false" data-type="indexterm" data-primary="nondeterminism" id="id1169"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="nondeterminism" id="id1170"/> an FM generates a different response even though the prompt is the same. This may not necessarily mean there are hallucinations. But the response may have a different sentence structure, emphasis on certain points, and not even mention certain topics.</p>
<p>A key reason for nondeterminism<a contenteditable="false" data-type="indexterm" data-primary="temperature" data-secondary="nondeterminism and" id="id1171"/> is the temperature of an FM, which is a setting for the randomness or “creativity” for the responses. For FMs like ChatGPT and Claude, you cannot set the temperature. Rather, it is an unknown value. But there are other FMs that allow you to do so. This is usually available to developers who use the APIs for these systems.</p>
<p>Nondeterminism has its advantages, though, as we saw with our example with the Wharton School MBA innovation case study. But then again, it could add too much uncertainty for certain applications, especially where there are higher stakes.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Interpretability"><div class="sect2" id="interpretability">
<h2>Interpretability</h2>
<p>Interpretability describes the<a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="interpretability" id="id1172"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="interpretability" id="id1173"/><a contenteditable="false" data-type="indexterm" data-primary="interpretability" id="id1174"/> level of understanding, explainability, and trust with an FM. This can be fairly low because of the sheer complexity of these systems. And as we’ve mentioned earlier, most of the details of the model may not be disclosed. <a contenteditable="false" data-type="indexterm" data-primary="black box" id="id1175"/>This is known as a <em>black box</em>.</p>
<p>This is even the case with open source models. It’s not uncommon for the FM developer to not disclose the weights and biases. This may also include the underlying datasets. The lack of interpretability can be difficult for industries that are highly regulated. In fact, they may even be prohibited from using a model that is not explainable.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Data Security and Privacy"><div class="sect2" id="data_security_and_privacy">
<h2>Data Security and Privacy</h2>
<p>Interacting with an FM <a contenteditable="false" data-type="indexterm" data-primary="cloud computing" data-secondary="data security and privacy risks" id="id1176"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="data security and privacy" id="id1177"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="data security and privacy" id="id1178"/><a contenteditable="false" data-type="indexterm" data-primary="privacy" data-secondary="risk with generative AI FMs" id="id1179"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="data risk with generative AI FMs" id="id1180"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="security and privacy" data-tertiary="generative AI FMs" id="id1181"/><a contenteditable="false" data-type="indexterm" data-primary="personally identifiable information (PII)" data-secondary="drawbacks of generative AI" id="id1182"/>can pose data security and privacy threats. If you enter sensitive information into a system—such as PII—this can be exposed. For some FMs, such as ChatGPT or Claude, the data is sent to the cloud. You will need to rely on their own security systems.</p>
<p>It’s true that such large organizations have extensive guardrails. In the case of OpenAI, they include:<a contenteditable="false" data-type="indexterm" data-primary="OpenAI" data-secondary="data security and privacy guardrails" id="id1183"/></p>
<dl>
<dt>Data encryption</dt>
<dd><p>This uses AES256 for data at rest—or in storage—and TLS 1.2 or higher for data in transit.</p></dd>
<dt>Internal security</dt>
<dd><p>There are rigorous access controls for authorized personnel. There are also advanced cybersecurity systems like firewalls and intrusion protection.</p></dd>
<dt>Audits</dt>
<dd><p>Open AI has been vetted by third-party evaluations, such as SOC 2 Type 2 audits.</p></dd>
<dt>Bounty program</dt>
<dd><p>OpenAI pays rewards for those who find vulnerabilities.</p></dd>
<dt>Safety and Security Committee</dt>
<dd><p>This is an independent group that evaluates the AI models and infrastructure.</p></dd>
</dl>
<p>Despite all these measures, security is never foolproof. This is why you should be careful with what information you enter into an FM. Of course, the same goes for when you use datasets when applying customization techniques like RAG and <span class="keep-together">fine-tuning.</span> <a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="security and privacy" data-tertiary="anonymization of data" id="id1184"/><a contenteditable="false" data-type="indexterm" data-primary="privacy" data-secondary="risk with generative AI FMs" data-tertiary="anonymization of data" id="id1185"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="data risk with generative AI FMs" data-tertiary="anonymization of data" id="id1186"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="data poisoning" id="id1187"/><a contenteditable="false" data-type="indexterm" data-primary="anonymization of data" id="id1188"/><a contenteditable="false" data-type="indexterm" data-primary="privacy" data-secondary="sensitive data" data-tertiary="anonymization of data" id="id1189"/><a contenteditable="false" data-type="indexterm" data-primary="data poisoning leading to toxic content" id="id1190"/><a contenteditable="false" data-type="indexterm" data-primary="content delivery" data-secondary="data poisoning leading to toxic content" id="id1191"/><a contenteditable="false" data-type="indexterm" data-primary="toxicity" data-secondary="data poisoning leading to toxic content" id="id1192"/>This may include approaches like anonymization of the data. There should also be strong cybersecurity protection systems and policies. This can help mitigate the risk of data poisoning, which is when a hacker breaches a dataset and injects malicious information into it. It can mean that a FM generates toxic content or could allow for a backdoor into the model.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Social and Branding Risks"><div class="sect2" id="social_and_branding_risks">
<h2>Social and Branding Risks</h2>
<p>In late 2023, a <a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="social and branding risks" id="id1193"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="social and branding risks" id="id1194"/><a contenteditable="false" data-type="indexterm" data-primary="branding and AI" id="id1195"/><a contenteditable="false" data-type="indexterm" data-primary="chatbots" data-secondary="risks of" id="id1196"/><a contenteditable="false" data-type="indexterm" data-primary="car dealership chatbot embarrassment" id="id1197"/>Chevrolet dealership rolled out a chatbot for its website. Unfortunately, some of the responses proved embarrassing.<sup><a data-type="noteref" id="ch01fn13-marker" href="ch04.html#ch01fn13">12</a></sup> In some cases, the chatbot recommended cars for rivals. It even offered a Chevrolet Tahoe for just $1.</p>
<p>This example was not a one-off. Generative AI does have social risks, which could damage a company’s brand and reputation. Customization techniques of an FM can certainly help. But in some cases, it may be best to not have a chatbot handle certain topics, which can be done by including filters in the chatbot.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Limited Context Windows"><div class="sect2" id="limited_context_windows">
<h2>Limited Context Windows</h2>
<p>A context window is the<a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="context window limitations" id="id1198"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="context window limitations" id="id1199"/><a contenteditable="false" data-type="indexterm" data-primary="context window" data-secondary="limitations" id="id1200"/> amount of text—expressed in tokens—a model can process at one time. For example, let’s say you are using a chatbot with a context window of 5,000 tokens. In your chat, the total number of tokens for the prompts and responses is 10,000. This means that when generating a response, the chatbot will use the last 5,000 tokens. The rest will be ignored.</p>
<p>Over the years, the context windows for FMs have expanded greatly. <a contenteditable="false" data-type="indexterm" data-primary="context window" data-secondary="example sizes" id="id1201"/>You can find some examples in <a data-type="xref" href="#table_four_onedot_context_windows">Table 4-1</a>.</p>
<table class="border" id="table_four_onedot_context_windows">
<caption><span class="label">Table 4-1. </span>Context windows</caption>
<thead>
<tr>
<th>Model</th>
<th>Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-4 Turbo</td>
<td>128,000 tokens</td>
</tr>
<tr>
<td>Meta Llama 3</td>
<td>128,000 tokens</td>
</tr>
<tr>
<td>Claude 3 Opus</td>
<td>200,000 tokens</td>
</tr>
<tr>
<td>Gemini 1.5</td>
<td>1,000,000 tokens</td>
</tr>
</tbody>
</table>
<p>To put this into perspective, Gemini 1.5’s context window would handle about 750,000 words or 2,500 pages. This would certainly be sufficient for many tasks.</p>
<p>But the context window may still not adequately capture the meaning of the text. The reason is the “lost-in-the-middle effect.” This describes how an FM can actually get lost when processing the information in the midsection of the tokens.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Recency"><div class="sect2" id="recency">
<h2>Recency</h2>
<p>FMs are pretrained, <a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="recency" id="id1202"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="recency" id="id1203"/><a contenteditable="false" data-type="indexterm" data-primary="recency issues with pretrained models" id="id1204"/><a contenteditable="false" data-type="indexterm" data-primary="pretrained models" data-secondary="recency issues" id="id1205"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="pretrained models" data-tertiary="recency issues" id="id1206"/>which means they are trained on datasets as of a certain cutoff date. But this presents a problem: recency. It means that more current information is not reflected in the FM, which can result in responses that are outdated. For example, if there has been a recent election, it may not know who the current president is.</p>
<p>But some of the leading FMs have a workaround that allows for internet queries, which we learned about earlier in this chapter.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Costs"><div class="sect2" id="costs">
<h2>Costs</h2>
<p>The costs for building FMs can be huge. These are the main categories:<a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="costs" id="c04cost"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="costs" id="c04cost2"/><a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="generative AI foundation models" id="c04cost3"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="costs for building foundation models" id="id1207"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="costs for building foundation models" id="id1208"/><a contenteditable="false" data-type="indexterm" data-primary="GPUs (Graphics Processing Units)" data-secondary="infrastructure costs of building FMs" id="id1209"/><a contenteditable="false" data-type="indexterm" data-primary="infrastructure costs of building FMs" id="id1210"/><a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="infrastructure costs of building FMs" id="id1211"/></p>
<dl>
<dt>Training</dt>
<dd><p>You will need to hire a team of highly qualified data scientists, data engineers, and software engineers. Such skilled persons can fetch hefty salaries. In some cases, companies like OpenAI are offering seven-figure compensation packages for data scientists.</p></dd>
<dt>Data</dt>
<dd><p>There are the costs for collecting and licensing of the data. For example, in 2024 OpenAI announced a <a href="https://oreil.ly/wU-us">five-year partnership for $250+ million</a> with News Corp for licensing of content from publications like the Wall Street Journal, Barron’s, the New York Post, and MarketWatch.</p></dd>
<dt>Infrastructure</dt>
<dd><p>It can take thousands of GPUs to train an FM. To run an AI model at scale, some systems require over 100,000 GPUs. These chips are not cheap either, fetching $25,000 to $30,000 each. There may even be shortages of GPUs, requiring buying systems from a third party—at higher prices—or being put on a waitlist.</p></dd>
</dl>
<p>Getting an estimate for the costs of an FM can be difficult, as the developers mostly keep this information private. <a contenteditable="false" data-type="indexterm" data-primary="Amodei, Dario" id="id1212"/>But an interview with the CEO of Anthropic, Dario Amodei, does shed some light on this.<sup><a data-type="noteref" id="ch01fn14-marker" href="ch04.html#ch01fn14">13</a></sup> He said that the training costs could be <span class="keep-together">anywhere</span> from $5 billion to $10 billion for the years 2025 to 2026. Over the long term—which he did not specify—a model could cost a staggering $100 billion.</p>
<p>Then there is the <a contenteditable="false" data-type="indexterm" data-primary="Stargate supercomputer project" id="id1213"/><a contenteditable="false" data-type="indexterm" data-primary="infrastructure costs of building FMs" data-secondary="Stargate project for next-generation" id="id1214"/><a contenteditable="false" data-type="indexterm" data-primary="OpenAI" data-secondary="Stargate supercomputer project" id="id1215"/><a contenteditable="false" data-type="indexterm" data-primary="Oracle and Stargate project" id="id1216"/><a contenteditable="false" data-type="indexterm" data-primary="Softbank and Stargate project" id="id1217"/><a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="infrastructure costs of building FMs" data-tertiary="Stargate project for next-generation" id="id1218"/>ambitious Stargate project,<sup><a data-type="noteref" id="ch01fn15-marker" href="ch04.html#ch01fn15">14</a></sup> which is a joint venture between OpenAI, Oracle, and SoftBank. The goal is to raise $500 billion for building the <span class="keep-together">infrastructure</span> for next-generation AI models. <a contenteditable="false" data-type="indexterm" data-primary="GPUs (Graphics Processing Units)" data-secondary="infrastructure costs of building FMs" data-tertiary="Stargate supercomputer system" id="id1219"/><a contenteditable="false" data-type="indexterm" data-primary="power consumption" data-secondary="Stargate supercomputer project" id="id1220"/>The Stargate supercomputer system is expected to have 2 million GPUs and use one gigawatt of power each year.<sup><a data-type="noteref" id="ch01fn16-marker" href="ch04.html#ch01fn16">15</a></sup></p>
<p>To get a sense of the sheer scale of state-of-the-art AI data centers, look at Meta.<a contenteditable="false" data-type="indexterm" data-primary="Meta data centers" id="id1221"/><a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="infrastructure costs of building FMs" data-tertiary="Meta data centers" id="id1222"/><a contenteditable="false" data-type="indexterm" data-primary="infrastructure costs of building FMs" data-secondary="Meta data centers" id="id1223"/><a contenteditable="false" data-type="indexterm" data-primary="Zuckerberg, Mark" id="id1224"/><a contenteditable="false" data-type="indexterm" data-primary="power consumption" data-secondary="Meta" id="id1225"/> The company’s CEO and cofounder, Mark Zuckerberg, had this to say about its <a href="https://oreil.ly/HW7OE">latest project</a>:</p>
<blockquote>
<p>I announced last week that we expect to bring online almost a gigawatt of capacity this year. And we’re building a two-gigawatt and potentially bigger AI data center that is so big that it will cover a significant part of Manhattan if we were placed there.</p>
</blockquote>
<p>With the escalating costs, there is a nagging question: Can AI be profitable? Many of the world’s top technology companies and venture capitalists think the answer is a clear yes.</p>
<p>In 2025, Google, Meta, Microsoft, and Amazon <a contenteditable="false" data-type="indexterm" data-primary="infrastructure costs of building FMs" data-secondary="spending in 2025 for" id="id1226"/><a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="infrastructure costs of building FMs" data-tertiary="spending in 2025 for" id="id1227"/>plan to spend at least $215 billion on the infrastructure for AI.<sup><a data-type="noteref" id="ch01fn17-marker" href="ch04.html#ch01fn17">16</a></sup> This is what Amazon CEO, Andy Jassy, said about it: “We think virtually every application that we know of today is going to be reinvented with AI inside of it.”</p>
<p>But it’s still early days with AI and the pace of innovation has been dramatic. There will also likely be innovations and breakthroughs for more efficient and optimal approaches for creating and operating this technology.</p>
<p>A notable example of this was from China. A 40-year-old Chinese billionaire investor launched his own AI startup, called DeepSeek. He believed there was an opportunity to disrupt the FM market by leveraging much better approaches to model development. With a fraction of the resources of companies like OpenAI—at least in terms of GPUs—his team was able to create a highly sophisticated model, called R1. It proved quite capable based on a variety of benchmarks. It also apparently cost less than $6 million to develop.<sup><a data-type="noteref" id="ch01fn18-marker" href="ch04.html#ch01fn18">17</a></sup><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04cost" id="id1228"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04cost2" id="id1229"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04cost3" id="id1230"/></p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Data Challenge"><div class="sect2" id="data_challenge">
<h2>Data Challenge</h2>
<p>Could we be <a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="drawbacks" data-tertiary="data challenge" id="id1231"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="drawbacks of generative AI" data-tertiary="data challenge" id="id1232"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="foundation models" data-tertiary="challenges of quality and quantity" id="id1233"/>running out of data for FMs? Well, some academic research predicts that this could be the case—at least in terms of quality data. If this turns out to be true, this would certainly represent a major issue for AI progress. If anything, there are already signs of problems. When new models are announced, they usually have minor improvements.</p>
<p>But FM developers are looking at ways to deal with this problem,<a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="synthetic data" id="id1234"/><a contenteditable="false" data-type="indexterm" data-primary="synthetic data" id="id1235"/> such as with synthetic data. This is data that is generally created by using AI models, which has proven helpful with use cases like self-driving cars. But the field of synthetic data is still in the early phases and there is much that needs to be done.</p>
<p>Besides the potential of data scarcity,<a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="AI-generated content on the internet" id="id1236"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="generative AI" data-tertiary="AI-generated content on the internet" id="id1237"/><a contenteditable="false" data-type="indexterm" data-primary="content delivery" data-secondary="AI-generated content on the internet" id="id1238"/> there is another looming issue: the proliferation of AI-generated content. A study from AWS estimates that it’s about 57% of internet text.<sup><a data-type="noteref" id="ch01fn19-marker" href="ch04.html#ch01fn19">18</a></sup> Some researchers think this could mean an adverse feedback loop for FMs, leading to model degradation or even collapse.</p>
<p>This is not to say that AI is doomed. Let’s face it, there have been many such predictions over the years—and yet the technology has continued to remain robust. But it does mean that the industry needs to be vigilant and continue to invest in ways for improvement.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c04draw" id="id1239"/></p>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Evolution of FMs"><div class="sect1" id="evolution_of_fms">
<h1>Evolution of FMs</h1>
<p>Daniel Kahneman, famous psychologist,<a contenteditable="false" data-type="indexterm" data-primary="Kahneman, Daniel" id="id1240"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="evolution of" id="id1241"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="foundation models" data-tertiary="evolution of" id="id1242"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="evolution of" id="id1243"/> won the Nobel Prize in Economics in 2002. This was for his pioneering research about human judgment under uncertainty. In fact, his ideas provide an interesting perspective on generative AI models. <a contenteditable="false" data-type="indexterm" data-primary="Thinking, Fast and Slow (Kahneman)" id="id1244"/>In his book <em>Thinking, Fast and Slow</em>, he set forth his ideas about the human thinking process. <a contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="System 1 thinking" id="id1245"/>One is System 1 thinking, which is where a person thinks quickly and automatically. In a way, this is how GPT models operate. For example, with ChatGPT, it’s a quick interactive experience—with a prompt and response.</p>
<p>Next, there is System 2 thinking, which is when a person takes more time thinking about a problem, such as with sophisticated reasoning and planning. System 2 thinking applies to next-generation generative AI models. <a contenteditable="false" data-type="indexterm" data-primary="reasoning models" id="id1246"/><a contenteditable="false" data-type="indexterm" data-primary="agentic AI" id="id1247"/>These are often referred to as reasoning models or agentic AI.</p>
<p>Besides taking a multistep approach to solving problems,<a contenteditable="false" data-type="indexterm" data-primary="autonomous agents" id="id1248"/> these models also can act autonomously—or near autonomously—and also use tools to carry out tasks. <a contenteditable="false" data-type="indexterm" data-primary="collaborative work among AI agents" id="id1249"/>There will often be multiple generative AI agents that will work collaboratively.</p>
<p>Take an example for customer support. For this, we have the following agents:</p>
<dl>
<dt>Customer interaction agent</dt>
<dd><p>A chatbot that communicates with the customer can handle common questions, such as by invoking a knowledge base agent. But for more difficult matters, the agent will delegate these to other agents.</p></dd>
<dt>Issue categorization agent</dt>
<dd><p>This will evaluate the issue and determine what it is about, such as billing, technical issues, and so on.</p></dd>
<dt>Sentiment analysis agent</dt>
<dd><p>If there are indications of frustration, then this can escalate the situation. This may mean handing off the customer to a human agent. This can be done with a task routing agent, which makes a determination based on factors like skill sets, experience, and workload.</p></dd>
<dt>Resolution monitoring agent</dt>
<dd><p>This will track the progress of all the support tickets. If there are gaps or problems, then the agent will escalate the tasks.</p></dd>
</dl>
<p>This agentic technology is still in the early phases—but it is showing much progress. It’s a major priority for many of the largest technology firms like Amazon, Microsoft, and Salesforce.</p>
<p>Consider that Gartner said that agentic AI is poised to be the biggest technology trend for 2025.<sup><a data-type="noteref" id="ch01fn20-marker" href="ch04.html#ch01fn20">19</a></sup> This is backed up with other research, such as from Deloitte. The firm predicts that 25% of companies using generative AI will <a href="https://oreil.ly/LOVKT">launch agentic AI projects or proof of concepts</a> in 2025. The adoption rate is expected to reach 50% by 2027.</p>
</div></section>
<section data-type="sect1" data-pdf-bookmark="AGI"><div class="sect1" id="agi">
<h1>AGI</h1>
<p>Earlier in this chapter, <a contenteditable="false" data-type="indexterm" data-primary="artificial general intelligence (AGI)" id="id1250"/><a contenteditable="false" data-type="indexterm" data-primary="artificial general intelligence (AGI)" data-secondary="OpenAI mission" id="id1251"/><a contenteditable="false" data-type="indexterm" data-primary="AGI (artificial general intelligence)" data-secondary="OpenAI mission" id="id1252"/><a contenteditable="false" data-type="indexterm" data-primary="AGI (artificial general intelligence)" id="id1253"/>we mentioned the vision of OpenAI, which is about AGI. The company defined it as a system that is “smarter than humans.”</p>
<p>But the topic of AGI is complicated. After all, the concept of “intelligence” is elusive, as there is no generally accepted standard. For example, a person does not have to have a genius-level IQ to be a genius.</p>
<p>Consider Richard Feynman.<a contenteditable="false" data-type="indexterm" data-primary="Feynman, Richard" id="id1254"/> In World War II, he worked on the Manhattan Project, helping to develop the atomic bomb by solving complex neutron equations. After this, he would become a professor at the California Institute of Technology (Caltech). There, he would make pioneering contributions to quantum electrodynamics and win the Nobel Prize in Physics in 1965.</p>
<p>So what was his IQ? It was <a href="https://oreil.ly/o9HHc">125</a>, which is average intelligence. By comparison, a genius level is 180+.</p>
<p>Then there are cases where people are geniuses and have fairly low IQs,<a contenteditable="false" data-type="indexterm" data-primary="Lemke, Leslie" id="id1255"/> such as Leslie Lemke. Even with an IQ of 58 and blind,<sup><a data-type="noteref" id="ch01fn21-marker" href="ch04.html#ch01fn21">20</a></sup> he was able to play complex piano pieces—after hearing them only once. So what does intelligence mean for AGI? There are other characteristics that are important for superhuman capabilities:</p>
<dl>
<dt>Efficiency</dt>
<dd><p>As we have seen in this chapter, it takes huge amounts of resources and energy for AI. But this is not practical for the proliferation of AGI. <a contenteditable="false" data-type="indexterm" data-primary="power consumption" data-secondary="human brain" id="id1256"/>After all, the human brain is only about three pounds and consumes about 20 watts of power, or the amount for a dim light bulb.</p></dd>
<dt>Interact with the environment</dt>
<dd><p>An AGI system should be able to have physical capabilities like sight, smell, and feel. This will make it much more useful. It will also allow for more learning.</p></dd>
<dt>Autonomous</dt>
<dd><p>An AGI system must be able to make effective decisions on its own.</p></dd>
<dt>Creativity</dt>
<dd><p>While generative AI has shown some capacity for this, it is far from the levels that we have seen from humans, say with Steve Jobs, Einstein, or Shakespeare.</p></dd>
</dl>
<p>There are various estimates on when AGI will be reached.<a contenteditable="false" data-type="indexterm" data-primary="Kurzweil, Ray" id="id1257"/><a contenteditable="false" data-type="indexterm" data-primary="Hassabis, Sir Demis" id="id1258"/> Ray Kurzweil, who is a futurist, says this will happen by 2029.<sup><a data-type="noteref" id="ch01fn22-marker" href="ch04.html#ch01fn22">21</a></sup> Sir Demis Hassabis, who is the CEO of Google DeepMind, is not as optimistic. He predicts AGI will be reached by 2034 or so.<sup><a data-type="noteref" id="ch01fn23-marker" href="ch04.html#ch01fn23">22</a></sup></p>
<p>It’s likely that there will need to be more major innovations to achieve AGI. It seems that the transformer model will not be enough. If anything, next-generation models will need to go beyond being prediction machines. There will also need to be new forms of chips and computer systems, like quantum computing.</p>
</div></section>
<section data-type="sect1" class="pagebreak-before" data-pdf-bookmark="Conclusion"><div class="sect1" id="conclusion-id000009">
<h1 class="less_space">Conclusion</h1>
<p>Generative AI is a key part of the AIF-C01 exam. This is why we did a deep dive—in this chapter—of this important technology. We looked at the core building blocks, like neural networks and deep learning. We also saw how generative AI has different forms: GANs, VAEs, diffusion models, and the transformer.</p>
<p>Among these, the transformer is the one that is most prominent. So, we looked at the inner workings, as well as the lifecycle, how it is a part of FMs, and the pros and cons.</p>
<p>In the next chapter, we will look at how to evaluate generative AI solutions as well as the various use cases.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Quiz"><div class="sect1" id="ch4quiz">
	<h1>Quiz</h1>

<p>To check your answers, please refer to the <a data-type="xref" href="app02.html#answers_ch_4">“Chapter 4 Answer Key”</a>.</p>

<ol>
<li><p>Which generative AI model involves two neural networks that compete against each other?</p>
<ol type="a">
<li><p>Variational autoencoder (VAE)</p></li>
<li><p>Transformer model</p></li>
<li><p>Generative adversarial network (GAN)</p></li>
<li><p>Diffusion model</p></li>
</ol>
</li>

<li><p>What is the purpose of positional encoding for a transformer model?</p>
<ol type="a">
<li><p>To enhance the performance of backpropagation</p></li>
<li><p>To process words in the original order of the text</p></li>
<li><p>To improve the reliability of GPUs</p></li>
<li><p>To make AI models more cost-effective</p></li>
</ol>
</li>

<li><p>What is a key advantage of retrieval-augmented generation (RAG) compared to the process of fine-tuning?</p>
<ol type="a">
<li><p>RAG requires less energy.</p></li>
<li><p>It significantly increases the model’s speed. </p></li>
<li><p>RAG mitigates bias in AI responses.</p></li>
<li><p>It does not require the modification of a model’s internal weights.</p></li>
</ol>
</li>
</ol>

<ol class="less_space pagebreak-before" start="4">
<li><p>What is a key advantage of a transformer model over a recurrent neural network (RNN)?</p>
<ol type="a">
<li><p>Transformers require no labeled data.</p></li>
<li><p>Transformers can process entire datasets in parallel.</p></li>
<li><p>RNNs cannot process text.</p></li>
<li><p>Transformers do not require training.</p></li>
</ol>
</li>

<li><p>Why does an AI model create hallucinations?</p>
<ol type="a">
<li><p>They rely on probabilistic predictions.</p></li>
<li><p>They use GPUs, which can be unpredictable.</p></li>
<li><p>They are based on supervised learning.</p></li>
<li><p>They are only a problem with small models.</p></li>
</ol>
</li>

<li><p>Which part of a neural network allows for detecting patterns in a dataset?</p>
<ol type="a">
<li><p>Input layer</p></li>
<li><p>Output layer</p></li>
<li><p>Hidden layer</p></li>
<li><p>Activation layer</p></li>
</ol>
</li>
</ol>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="ch01fn2"><sup><a href="ch04.html#ch01fn2-marker">1</a></sup> CERN, <a href="https://oreil.ly/eo_Ke">“Large Hadron Collider Begins Third Run”</a>, HPCwire (website), July 6, 2022.</p><p data-type="footnote" id="ch01fn3"><sup><a href="ch04.html#ch01fn3-marker">2</a></sup> Diederik P. Kingma and Max Welling, <a href="https://oreil.ly/Glgrm">“Auto-Encoding Variational Bayes”</a>, arXiv, revised December 10, 2022.</p><p data-type="footnote" id="ch01fn4"><sup><a href="ch04.html#ch01fn4-marker">3</a></sup> Ashish Vaswani et al., <a href="https://oreil.ly/AHoJR">“Attention Is All You Need”</a>, arXiv, revised August 2, 2023.</p><p data-type="footnote" id="ch01fn5"><sup><a href="ch04.html#ch01fn5-marker">4</a></sup> Parmy Olson, <a href="https://oreil.ly/cWBBa">“Meet the $4 Billion AI Superstars That Google Lost”</a>, Bloomberg (website), July 13, 2023.</p><p data-type="footnote" id="ch01fn6"><sup><a href="ch04.html#ch01fn6-marker">5</a></sup> Jascha Sohl-Dickstein et al., <a href="https://oreil.ly/IWAVQ">“Deep Unsupervised Learning Using Nonequilibrium Thermodynamics”</a>, Proceedings of the 32nd International Conference on Machine Learning, JMLR: W&amp;CP 37 (2015).</p><p data-type="footnote" id="ch01fn7"><sup><a href="ch04.html#ch01fn7-marker">6</a></sup> Harry Booth, <a href="https://oreil.ly/8E_nA">“Patrick Lewis”</a>, <em>Time</em>, September 5, 2024.</p><p data-type="footnote" id="ch01fn8"><sup><a href="ch04.html#ch01fn8-marker">7</a></sup> Aleksandra Piktus et al., <a href="https://oreil.ly/MoQye">“Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks”</a>, Meta, Conference on Neural Information Processing Systems (NeurIPS), December 6, 2020.</p><p data-type="footnote" id="ch01fn9"><sup><a href="ch04.html#ch01fn9-marker">8</a></sup> Jacob Devlin et al., <a href="https://oreil.ly/nfnkQ">“BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”</a>, preprint, arXiv, October 11, 2018.</p><p data-type="footnote" id="ch01fn10"><sup><a href="ch04.html#ch01fn10-marker">9</a></sup> Christian Terwiesch and Karl Ulrich, <a href="https://oreil.ly/WlZg8">“M.B.A. Students vs. AI: Who Comes Up with More Innovative Ideas?”</a>, <em>Wall Street Journal</em>, September 9, 2023.</p><p data-type="footnote" id="ch01fn11"><sup><a href="ch04.html#ch01fn11-marker">10</a></sup> Future of Life Institute, <a href="https://oreil.ly/FXRBX">“Pause Giant AI Experiments: An Open Letter”</a>, March 22, 2023.</p><p data-type="footnote" id="ch01fn12"><sup><a href="ch04.html#ch01fn12-marker">11</a></sup> Karen Emslie, <a href="https://oreil.ly/fA_7_">“LLM Hallucinations: A Bug or a Feature?”</a>, <em>Communications of the ACM</em>, May 23, 2024.</p><p data-type="footnote" id="ch01fn13"><sup><a href="ch04.html#ch01fn13-marker">12</a></sup> Ben Sherry, <a href="https://oreil.ly/ZvcJo">“A Chevrolet Dealership Used ChatGPT for Customer Service and Learned That AI Isn’t Always on Your Side”</a>, <em>Inc.</em>, December 18, 2023.</p><p data-type="footnote" id="ch01fn14"><sup><a href="ch04.html#ch01fn14-marker">13</a></sup> Erin Snodgrass, <a href="https://oreil.ly/Dc6cC">“CEO of Anthropic…Says It Could Cost $10 billion to Train AI in 2 Years”</a> <em>Business Insider</em>, April 30, 2024.</p><p data-type="footnote" id="ch01fn15"><sup><a href="ch04.html#ch01fn15-marker">14</a></sup> Joanna Stern, <a href="https://oreil.ly/NxHco">“OpenAI Hails $500 Billion Stargate Plan: ‘More Computer Leads to Better Models’”</a>, <em>Wall Street Journal</em>, updated January 22, 2025.</p><p data-type="footnote" id="ch01fn16"><sup><a href="ch04.html#ch01fn16-marker">15</a></sup> Jeremy Kahn, <a href="https://oreil.ly/1vWk2">“The $19.6 Billion Pivot”</a> <em>Fortune</em>, February 25, 2025.</p><p data-type="footnote" id="ch01fn17"><sup><a href="ch04.html#ch01fn17-marker">16</a></sup> Nate Rattner, <a href="https://oreil.ly/HCq32">“Tech Giants Double Down on Their Massive AI Spending”</a> <em>Wall Street Journal</em>, February 6, 2025.</p><p data-type="footnote" id="ch01fn18"><sup><a href="ch04.html#ch01fn18-marker">17</a></sup> Kif Leswing, <a href="https://oreil.ly/t76q_">“Nvidia Calls China’s DeepSeek R1 Model ‘an Excellent AI Advancement’”</a>, CNBC, January 27, 2025.</p><p data-type="footnote" id="ch01fn19"><sup><a href="ch04.html#ch01fn19-marker">18</a></sup> Tor Constantino, <a href="https://oreil.ly/p1p-x">“Is AI Quietly Killing Itself—and the Internet?”</a>, <em>Forbes</em> Australia, September 2, 2024.</p><p data-type="footnote" id="ch01fn20"><sup><a href="ch04.html#ch01fn20-marker">19</a></sup> David Ramel, <a href="https://oreil.ly/uFxHh">“Agentic AI Named Top Tech Trend for 2025”</a>, <em>Campus Technology</em>, October 23, 2024.</p><p data-type="footnote" id="ch01fn21"><sup><a href="ch04.html#ch01fn21-marker">20</a></sup> Darold Treffert, <a href="https://oreil.ly/5Mr6I">“Whatever Happened to Leslie Lemke”</a>, <em>Scientific American</em> (blog), June 17, 2014.</p><p data-type="footnote" id="ch01fn22"><sup><a href="ch04.html#ch01fn22-marker">21</a></sup> Pranav Dixit, <a href="https://oreil.ly/by-I6">“At TIME100 Impact Dinner, AI Leaders Discuss the Technology’s Transformative Potential”</a> <em>Time</em>, September 17, 2024.</p><p data-type="footnote" id="ch01fn23"><sup><a href="ch04.html#ch01fn23-marker">22</a></sup> James Hurley, <a href="https://oreil.ly/USHZW">“AI Has the Potential to ‘Cure All Diseases,’ Says DeepMind Chief”</a>, <em>Sunday Times</em>, October 2, 2024.</p></div></div></section></div></div></body></html>