- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The European Union’s Artificial Intelligence Act, which came into full effect
    in August 2024, represents a watershed moment in the global regulation of artificial
    intelligence. As the first comprehensive legal framework for AI, its stated purpose
    is clear: to foster innovation and development within the EU while effectively
    mitigating the potential risks posed by AI systems. This ambitious regulation
    establishes a uniform legal framework governing the development, placement on
    the market, putting into service, and use of AI systems across the EU.'
  prefs: []
  type: TYPE_NORMAL
- en: Navigating the complexities of the EU AI Act might, at first glance, seem like
    a task exclusively for legal teams and policy experts. The Act is indeed complex,
    featuring 113 articles that address highly technical issues, complemented by 13
    annexes that detail implementation specifics and 180 recitals (introductory statements
    providing context and guidance for interpretation). However, as the practical
    requirements of the EU AI Act reveal, *achieving and maintaining compliance with
    the Act is fundamentally an engineering problem*. This is the core message of
    this book.
  prefs: []
  type: TYPE_NORMAL
- en: Operationalizing EU AI Act compliance goes far beyond legal interpretation.
    It requires establishing roles, processes, structures, and AI engineering practices.
    Post-market compliance, for instance, directly necessitates the implementation
    of machine learning operations (MLOps) practices such as monitoring and alerting.
    Successfully achieving EU AI Act compliance is linked to understanding the design,
    development, and maintenance of AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance is not a legal stamp applied at the end of the development lifecycle,
    but a continuous process that must be engineered into the core of AI systems from
    the beginning. The Act’s foundation on the concept of “trustworthy AI” mandates
    that systems be lawful, ethical, and robust throughout their entire lifecycle.
    This necessitates embedding ethical and compliance aspects directly into the AI
    system development process.
  prefs: []
  type: TYPE_NORMAL
- en: 'This book serves as your guide to tackling EU AI Act compliance as the engineering
    challenge it is. We’ll explore various practical methodologies and frameworks
    essential for this task, including:'
  prefs: []
  type: TYPE_NORMAL
- en: AI engineering
  prefs: []
  type: TYPE_NORMAL
- en: Defined as the application of software engineering principles to the end-to-end
    lifecycle of AI systems—including design, development, deployment, and maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: CRISP-ML(Q)
  prefs: []
  type: TYPE_NORMAL
- en: This structured machine learning development process provides a blueprint for
    designing, developing, and maintaining AI systems with compliance in mind. Its
    emphasis on quality assurance and continuous risk management throughout the AI
    lifecycle is directly aligned with the EU AI Act’s risk-based approach. CRISP-ML(Q)
    requires documentation of the entire development process, including risk management
    measures, which is crucial for meeting the Act’s technical documentation and transparency
    obligations.
  prefs: []
  type: TYPE_NORMAL
- en: MLOps Stack Canvas
  prefs: []
  type: TYPE_NORMAL
- en: 'The MLOps Stack Canvas is a comprehensive and practical framework designed
    to guide organizations in architecting and managing their machine learning operations
    infrastructure. The canvas is structured around three core domains: Data and Code
    Management, Model Management, and Metadata Management. It provides a holistic
    view of the components necessary for successful ML deployment. By aligning with
    the CRISP-ML(Q) process model, the canvas ensures that each phase of the ML lifecycle
    is addressed, from data sourcing and versioning to model deployment and monitoring.
    It emphasizes critical aspects such as reproducibility, reliability, and efficiency,
    helping teams to plan infrastructure costs, select appropriate tools, and establish
    robust workflows. Serving as both a strategic and an operational tool, the MLOps
    Stack Canvas facilitates clearer communication among stakeholders for all ML and
    AI initiatives across the organization.'
  prefs: []
  type: TYPE_NORMAL
- en: SMACTR (Scoping, Mapping, Artifact Collection, Testing, and Reflection)
  prefs: []
  type: TYPE_NORMAL
- en: Introduced as an internal audit framework to guide the practical implementation
    of ethical AI development throughout its lifecycle, SMACTR promotes a proactive
    and preventive approach for AI development. Embedding audit processes into the
    design and development phases allows engineers to anticipate and address potential
    risks before deployment, aligning perfectly with the Act’s emphasis on risk mitigation.
    SMACTR’s focus on generating detailed documentation at each stage is also essential
    for meeting the Act’s technical documentation requirements for high-risk AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: The synergy between CRISP-ML(Q) and AI engineering offers a powerful framework
    for addressing EU AI Act compliance. Furthermore, the integration of SMACTR with
    the CRISP-ML(Q) methodology provides a robust and auditable process for responsibly
    developing AI systems. This combination allows for proactively engineering compliance
    into the ML lifecycle, from data collection through monitoring, rather than treating
    it as an afterthought.
  prefs: []
  type: TYPE_NORMAL
- en: The book also explores how these engineering principles apply across the Act’s
    risk classifications—prohibited, high risk, limited risk, and low risk. While
    high-risk systems face the most stringent requirements, Article 50 introduces
    transparency obligations that apply to all AI systems designed to interact directly
    with humans, regardless of their risk level. These obligations, such as informing
    users of AI interaction and marking synthetic content, demand practical engineering
    solutions for proactive compliance. Aligning AI engineering practices with SMACTR
    and CRISP-ML(Q) provides a structured and automated approach to managing the AI
    system lifecycle for transparency.
  prefs: []
  type: TYPE_NORMAL
- en: This book also addresses the particular challenges posed by general-purpose
    AI (GPAI) and generative AI (GenAI), late but significant additions to the Act.
    The concept of generative AI operations (GenAIOps) is introduced as an extension
    of traditional MLOps principles to handle the unique complexities of GPAI and
    generative AI applications. Applying AI engineering principles to implement transparency
    obligations for GPAI and integrating CRISP-ML(Q), SMACTR, and GenAIOps are crucial
    for navigating this evolving landscape.
  prefs: []
  type: TYPE_NORMAL
- en: Who Should Read This Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is intended for AI engineers, MLOps practitioners, data scientists,
    AI product managers, and anyone involved in the hands-on development and deployment
    of AI systems. It demonstrates how, through the application of robust methodologies,
    disciplined documentation, and continuous integration of ethical considerations,
    AI teams can build systems that are not only technically innovative but also demonstrably
    compliant, trustworthy, and aligned with societal expectations. I have tried to
    make this book as actionable as possible by introducing a comprehensive framework
    and practical checklists for aligning AI engineering practices with the EU AI
    Act articles throughout the CRISP-ML(Q) lifecycle.
  prefs: []
  type: TYPE_NORMAL
- en: 'As ImageNet creator Fei-Fei Li, known as the Godmother of AI, [noted recently](https://oreil.ly/_PUIb):
    “Now more than ever, AI needs a governance framework.” This book provides the
    practical engineering foundation for implementing such a framework, enabling practitioners
    to build trustworthy AI systems that meet the stringent requirements of the EU
    AI Act through empirical validation, risk-aware development, and collaborative
    practices. The law sets the requirements, but it is the engineering that delivers
    compliance.'
  prefs: []
  type: TYPE_NORMAL
- en: Navigating This Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This book has been designed as a reference for you, a guide to practicing proactive
    EU AI Act compliance through AI engineering and integrating it into the AI lifecycle,
    from data collection through monitoring. Each chapter is fairly self-contained,
    with appropriate references to other chapters identified. The chapters are organized
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 1, “Understanding the AI Regulations”](ch01.html#chapter_1_understanding_the_ai_regulations_1748539916832819),
    provides a foundational understanding of the EU AI Act and the need for trustworthy
    AI systems. It outlines seven essential requirements for building such systems:
    human agency and oversight; technical robustness and safety; privacy and data
    governance; transparency; diversity, non-discrimination, and fairness; societal
    and environmental well-being; and accountability. This chapter describes the structure
    of the Act, including definitions, key players, risk classifications, and the
    implementation timeline, and provides an overview of this significant regulatory
    framework.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 2, “AI Engineering: A Proactive Compliance Catalyst”](ch02.html#chapter_2_ai_engineering_a_proactive_compliance_catalyst_1748539917637495),
    explains how combining CRISP-ML(Q) with AI engineering helps organizations meet
    the compliance requirements of the EU AI Act. CRISP-ML(Q) guides the AI lifecycle
    through distinct phases, such as data preparation and model evaluation, while
    MLOps principles including automation, versioning, testing, and monitoring provide
    the operational backbone for ensuring AI systems are reliable, reproducible, and
    continuously compliant. In this chapter, you will also learn about the MLOps Stack
    Canvas as a framework for defining the necessary technical infrastructure, covering
    data, code, and model management, to support proactive compliance engineering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 3, “Data and AI Governance and AI Engineering”](ch03.html#chapter_3_data_and_ai_governance_and_ai_engineering_1748539918115723),
    explains the critical roles of data governance and AI governance within the context
    of the EU AI Act. In this chapter, you will learn about how these governance concepts
    can be practically integrated into the AI system development lifecycle to ensure
    trustworthy and compliant AI.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 4, “AI System Assessment and Tailoring AI Engineering for Different
    Risk Levels”](ch04.html#chapter_4_ai_system_assessment_and_tailoring_ai_engineering_1748539919034657),
    focuses on the crucial initial steps for organizations to achieve compliance with
    the EU AI Act. You will learn about creating an inventory of your existing AI
    systems and how to classify their risk level to determine the applicable obligations.
    The chapter also explains the different roles organizations can take (provider
    or deployer), which further tailors compliance requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 5, “AI Engineering for High-Risk AI Systems”](ch05.html#chapter_5_ai_engineering_for_high_risk_ai_systems_1748539922576008),
    offers a comprehensive guide to implementing the EU AI Act’s requirements for
    high-risk AI systems through AI engineering practices. It breaks down key articles
    of the Act (Articles 9–15), focusing on topics like risk management, data governance,
    documentation, recordkeeping, transparency, human oversight, accuracy, robustness,
    and security. You will learn how to map the Act’s legal requirements to specific
    quality attributes and how to integrate them into the CRISP-ML(Q) lifecycle. This
    chapter shows why documentation and metadata management are crucial for demonstrating
    compliance and ensuring the trustworthiness of high-risk AI systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 6, “AI Engineering for Limited-Risk AI Systems”](ch06.html#chapter_6_ai_engineering_for_limited_risk_ai_systems_1748539923606988),
    focuses on how to develop AI systems that meet the EU AI Act’s transparency obligations,
    which differ from the stricter conformity assessments required for high-risk systems.
    Here, you will learn about integrating the SMACTR framework with the CRISP-ML(Q)
    lifecycle. This chapter also highlights the emerging role of AI governance platforms
    and various technical tools in facilitating compliance and responsible AI deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 7, “Toward Trustworthy General-Purpose AI and Generative AI”](ch07.html#chapter_7_toward_trustworthy_general_purpose_ai_and_generati_1748539924538638),
    explains how the Act aims to balance AI innovation with risk mitigation, introducing
    concepts like GPAI and systemic risk. It outlines the specific transparency obligations
    for generative AI systems, such as informing users of AI interactions and marking
    synthetic content, and details the regulations for GPAI models, including documentation
    and risk management requirements for providers and deployers. You will also learn
    about GenAIOps, a framework for operationalizing the transparency and compliance
    aspects of GenAI development and deployment by integrating them with established
    methodologies like CRISP-ML(Q) and the SMACTR framework.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conventions Used in This Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element signifies a tip or suggestion.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element signifies a general note.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element indicates a warning or caution.
  prefs: []
  type: TYPE_NORMAL
- en: O’Reilly Online Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For more than 40 years, [*O’Reilly Media*](https://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*https://oreilly.com*](https://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: How to Contact Us
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please address comments and questions concerning this book to the publisher:'
  prefs: []
  type: TYPE_NORMAL
- en: O’Reilly Media, Inc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1005 Gravenstein Highway North
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sebastopol, CA 95472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 800-889-8969 (in the United States or Canada)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-827-7019 (international or local)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-829-0104 (fax)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*support@oreilly.com*](mailto:support@oreilly.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/AI-engineer-EU-AI-Act*](https://oreil.ly/AI-engineer-EU-AI-Act).
  prefs: []
  type: TYPE_NORMAL
- en: For news and information about our books and courses, visit [*https://oreilly.com*](https://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: 'Find us on LinkedIn: [*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Watch us on YouTube: [*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia).'
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Bringing this book to life has been a truly fulfilling experience. I’ve had
    so much support from so many people throughout the process of writing the book—thank
    you so much to everyone who helped make it a reality!
  prefs: []
  type: TYPE_NORMAL
- en: 'I would like to give an especially big thank you to the book’s technical reviewers:
    Una Galyeva, Katharine Jarmul, Janna Lipenkova, Anil Sood, and Debmalya Biswas.
    Their time and effort in reading through the initial draft and providing comments,
    suggestions, and corrections were invaluable, and they made significant contributions
    to improving the book’s overall quality.'
  prefs: []
  type: TYPE_NORMAL
- en: Everyone at O’Reilly has been fantastic to work with throughout the book’s lifecycle,
    starting with Nicole Butterfield, who immediately saw the potential of the core
    message that EU AI Act compliance is fundamentally an engineering challenge. Sara
    Hunter worked intensively with me to shape and edit the book, and when I was ready
    to move to the production process, Kristen Brown was just amazing. A big thank
    you to the entire O’Reilly team, including copyeditor Rachel Head, proofreader
    Kim Cofer, indexer Ben Hurst, illustrator Kate Dullea, and the cover design team
    of Monica Kaamsvaag and Susan Brown. You are all heroes!
  prefs: []
  type: TYPE_NORMAL
