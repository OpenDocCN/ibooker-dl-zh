["```py\nfrom fastai2.vision.all import *\npath = untar_data(URLs.PETS)\n```", "```py\npath.ls()\n```", "```py\n(#3) [Path('annotations'),Path('images'),Path('models')]\n```", "```py\n(path/\"images\").ls()\n```", "```py\n(#7394) [Path('images/great_pyrenees_173.jpg'),Path('images/wheaten_terrier_46.j\n > pg'),Path('images/Ragdoll_262.jpg'),Path('images/german_shorthaired_3.jpg'),P\n > ath('images/american_bulldog_196.jpg'),Path('images/boxer_188.jpg'),Path('ima\n > ges/staffordshire_bull_terrier_173.jpg'),Path('images/basset_hound_71.jpg'),P\n > ath('images/staffordshire_bull_terrier_37.jpg'),Path('images/yorkshire_terrie\n > r_18.jpg')...]\n```", "```py\nfname = (path/\"images\").ls()[0]\n```", "```py\nre.findall(r'(.+)_\\d+.jpg$', fname.name)\n```", "```py\n['great_pyrenees']\n```", "```py\npets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                 get_items=get_image_files,\n                 splitter=RandomSplitter(seed=42),\n                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n                 item_tfms=Resize(460),\n                 batch_tfms=aug_transforms(size=224, min_scale=0.75))\ndls = pets.dataloaders(path/\"images\")\n```", "```py\nitem_tfms=Resize(460),\nbatch_tfms=aug_transforms(size=224, min_scale=0.75)\n```", "```py\ndls.show_batch(nrows=1, ncols=3)\n```", "```py\npets1 = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                 get_items=get_image_files,\n                 splitter=RandomSplitter(seed=42),\n                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'))\npets1.summary(path/\"images\")\n```", "```py\nSetting-up type transforms pipelines\nCollecting items from /home/sgugger/.fastai/data/oxford-iiit-pet/images\nFound 7390 items\n2 datasets of sizes 5912,1478\nSetting up Pipeline: PILBase.create\nSetting up Pipeline: partial -> Categorize\n\nBuilding one sample\n  Pipeline: PILBase.create\n    starting from\n      /home/sgugger/.fastai/data/oxford-iiit-pet/images/american_bulldog_83.jpg\n    applying PILBase.create gives\n      PILImage mode=RGB size=375x500\n  Pipeline: partial -> Categorize\n    starting from\n      /home/sgugger/.fastai/data/oxford-iiit-pet/images/american_bulldog_83.jpg\n    applying partial gives\n      american_bulldog\n    applying Categorize gives\n      TensorCategory(12)\n\nFinal sample: (PILImage mode=RGB size=375x500, TensorCategory(12))\n\nSetting up after_item: Pipeline: ToTensor\nSetting up before_batch: Pipeline:\nSetting up after_batch: Pipeline: IntToFloatTensor\n\nBuilding one batch\nApplying item_tfms to the first sample:\n  Pipeline: ToTensor\n    starting from\n      (PILImage mode=RGB size=375x500, TensorCategory(12))\n    applying ToTensor gives\n      (TensorImage of size 3x500x375, TensorCategory(12))\n\nAdding the next 3 samples\n\nNo before_batch transform to apply\n\nCollating items in a batch\nError! It's not possible to collate your items in a batch\nCould not collate the 0-th members of your tuples because got the following\nshapes:\ntorch.Size([3, 500, 375]),torch.Size([3, 375, 500]),torch.Size([3, 333, 500]),\ntorch.Size([3, 375, 500])\n```", "```py\nlearn = cnn_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(2)\n```", "```py\nx,y = dls.one_batch()\n```", "```py\ny\n```", "```py\nTensorCategory([11,  0,  0,  5, 20,  4, 22, 31, 23, 10, 20,  2,  3, 27, 18, 23,\n > 33,  5, 24,  7,  6, 12,  9, 11, 35, 14, 10, 15,  3,  3, 21,  5, 19, 14, 12,\n > 15, 27,  1, 17, 10,  7,  6, 15, 23, 36,  1, 35,  6,\n         4, 29, 24, 32,  2, 14, 26, 25, 21,  0, 29, 31, 18,  7,  7, 17],\n > device='cuda:5')\n```", "```py\npreds,_ = learn.get_preds(dl=[(x,y)])\npreds[0]\n```", "```py\ntensor([7.9069e-04, 6.2350e-05, 3.7607e-05, 2.9260e-06, 1.3032e-05, 2.5760e-05,\n > 6.2341e-08, 3.6400e-07, 4.1311e-06, 1.3310e-04, 2.3090e-03, 9.9281e-01,\n > 4.6494e-05, 6.4266e-07, 1.9780e-06, 5.7005e-07,\n        3.3448e-06, 3.5691e-03, 3.4385e-06, 1.1578e-05, 1.5916e-06, 8.5567e-08,\n > 5.0773e-08, 2.2978e-06, 1.4150e-06, 3.5459e-07, 1.4599e-04, 5.6198e-08,\n > 3.4108e-07, 2.0813e-06, 8.0568e-07, 4.3381e-07,\n        1.0069e-05, 9.1020e-07, 4.8714e-06, 1.2734e-06, 2.4735e-06])\n```", "```py\nlen(preds[0]),preds[0].sum()\n```", "```py\n(37, tensor(1.0000))\n```", "```py\nplot_function(torch.sigmoid, min=-4,max=4)\n```", "```py\nacts = torch.randn((6,2))*2\nacts\n```", "```py\ntensor([[ 0.6734,  0.2576],\n        [ 0.4689,  0.4607],\n        [-2.2457, -0.3727],\n        [ 4.4164, -1.2760],\n        [ 0.9233,  0.5347],\n        [ 1.0698,  1.6187]])\n```", "```py\nacts.sigmoid()\n```", "```py\ntensor([[0.6623, 0.5641],\n        [0.6151, 0.6132],\n        [0.0957, 0.4079],\n        [0.9881, 0.2182],\n        [0.7157, 0.6306],\n        [0.7446, 0.8346]])\n```", "```py\n(acts[:,0]-acts[:,1]).sigmoid()\n```", "```py\ntensor([0.6025, 0.5021, 0.1332, 0.9966, 0.5959, 0.3661])\n```", "```py\ndef softmax(x): return exp(x) / exp(x).sum(dim=1, keepdim=True)\n```", "```py\nsm_acts = torch.softmax(acts, dim=1)\nsm_acts\n```", "```py\ntensor([[0.6025, 0.3975],\n        [0.5021, 0.4979],\n        [0.1332, 0.8668],\n        [0.9966, 0.0034],\n        [0.5959, 0.4041],\n        [0.3661, 0.6339]])\n```", "```py\ndef mnist_loss(inputs, targets):\n    inputs = inputs.sigmoid()\n    return torch.where(targets==1, 1-inputs, inputs).mean()\n```", "```py\ntarg = tensor([0,1,0,1,1,0])\n```", "```py\nsm_acts\n```", "```py\ntensor([[0.6025, 0.3975],\n        [0.5021, 0.4979],\n        [0.1332, 0.8668],\n        [0.9966, 0.0034],\n        [0.5959, 0.4041],\n        [0.3661, 0.6339]])\n```", "```py\nidx = range(6)\nsm_acts[idx, targ]\n```", "```py\ntensor([0.6025, 0.4979, 0.1332, 0.0034, 0.4041, 0.3661])\n```", "```py\n-sm_acts[idx, targ]\n```", "```py\ntensor([-0.6025, -0.4979, -0.1332, -0.0034, -0.4041, -0.3661])\n```", "```py\nF.nll_loss(sm_acts, targ, reduction='none')\n```", "```py\ntensor([-0.6025, -0.4979, -0.1332, -0.0034, -0.4041, -0.3661])\n```", "```py\nplot_function(torch.log, min=0,max=4)\n```", "```py\ny = b**a\na = log(y,b)\n```", "```py\nlog(a*b) = log(a)+log(b)\n```", "```py\nloss_func = nn.CrossEntropyLoss()\n```", "```py\nloss_func(acts, targ)\n```", "```py\ntensor(1.8045)\n```", "```py\nF.cross_entropy(acts, targ)\n```", "```py\ntensor(1.8045)\n```", "```py\nnn.CrossEntropyLoss(reduction='none')(acts, targ)\n```", "```py\ntensor([0.5067, 0.6973, 2.0160, 5.6958, 0.9062, 1.0048])\n```", "```py\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n```", "```py\ninterp.most_confused(min_val=5)\n```", "```py\n[('american_pit_bull_terrier', 'staffordshire_bull_terrier', 10),\n ('Ragdoll', 'Birman', 6)]\n```", "```py\nlearn = cnn_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(1, base_lr=0.1)\n```", "```py\nlearn = cnn_learner(dls, resnet34, metrics=error_rate)\nlr_min,lr_steep = learn.lr_find()\n```", "```py\nprint(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")\n```", "```py\nMinimum/10: 8.32e-03, steepest point: 6.31e-03\n```", "```py\nlearn = cnn_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(2, base_lr=3e-3)\n```", "```py\nlearn.fine_tune??\n```", "```py\nlearn = cnn_learner(dls, resnet34, metrics=error_rate)\nlearn.fit_one_cycle(3, 3e-3)\n```", "```py\nlearn.unfreeze()\n```", "```py\nlearn.lr_find()\n```", "```py\n(1.0964782268274575e-05, 1.5848931980144698e-06)\n```", "```py\nlearn.fit_one_cycle(6, lr_max=1e-5)\n```", "```py\nlearn = cnn_learner(dls, resnet34, metrics=error_rate)\nlearn.fit_one_cycle(3, 3e-3)\nlearn.unfreeze()\nlearn.fit_one_cycle(12, lr_max=slice(1e-6,1e-4))\n```", "```py\nlearn.recorder.plot_loss()\n```", "```py\nCuda runtime error: out of memory\n```", "```py\nfrom fastai2.callback.fp16 import *\nlearn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\nlearn.fine_tune(6, freeze_epochs=3)\n```"]