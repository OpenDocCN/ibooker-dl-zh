- en: '2 Tokenizers: How large language models see the world'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 标记化器：大型语言模型如何看待世界
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Creating tokens from sentences
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从句子中创建标记
- en: Controlling vocabulary size with normalization
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过规范化控制词汇量
- en: Avoiding risks in tokenization
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免标记化中的风险
- en: Tokenization strategies to remove ambiguity
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于消除歧义的标记化策略
- en: As discussed in chapter 1, in the world of artificial intelligence, it is often
    helpful to find analogies to human learning to explain how machines “learn.” How
    you read and understand sentences is a complex process that changes as you get
    older and involves multiple sequential and concurrent cognitive processes [1].
    Large language models (LLMs), however, use simpler processes than human cognitive
    processes. They employ algorithms based on neural networks to capture the relationships
    between words in large amounts of data and then use this information about relationships
    to interpret and generate sentences.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如第1章所述，在人工智能的世界里，找到与人类学习相关的类比来解释机器“学习”通常很有帮助。你如何阅读和理解句子是一个复杂的过程，随着年龄的增长而变化，涉及多个顺序和并发的认知过程[1]。然而，大型语言模型（LLMs）使用的处理过程比人类认知过程简单。它们使用基于神经网络的算法来捕捉大量数据中单词之间的关系，然后使用这些关于关系的信息来解释和生成句子。
- en: 'Our discussion of how these algorithms work will begin with their input: sentences
    of text. In this chapter, we explore how the LLM processes these sentences to
    become inputs for the model. Just as language is critical for how you think and
    process information, the inputs to an LLM are crucial in influencing what kinds
    of concepts and tasks LLMs can perform.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关于这些算法如何工作的讨论将从它们的输入开始：文本句子。在本章中，我们探讨LLM如何处理这些句子，使其成为模型的输入。正如语言对于你的思考和信息处理至关重要一样，LLM的输入对于影响LLM可以执行的概念和任务类型至关重要。
- en: 2.1 Tokens as numeric representations
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 标记作为数值表示
- en: It may seem obvious that LLMs should process sentences, but to fully understand,
    we must be more specific. As we talk about how LLMs work, you will see that textual
    sentences are unnatural for the neural network algorithms that power LLMs because
    neural networks fundamentally employ numbers to do their work. As shown in figure
    [2.1](#fig__tokenizationExample), the algorithms employed by LLMs must convert
    human text into a numeric representation before working with it. *Tokens* are
    the representations that LLMs use to break text into pieces that can be encoded
    as numbers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然看起来很明显LLMs应该处理句子，但要完全理解，我们必须更加具体。当我们讨论LLM的工作原理时，你会看到文本句子对于驱动LLM的神经网络算法来说是不自然的，因为神经网络本质上使用数字来完成它们的工作。如图[2.1](#fig__tokenizationExample)所示，LLM使用的算法必须将人类文本转换为数值表示，然后才能对其进行处理。“标记”是LLM用来将文本分解成可以编码为数字的片段的表示。
- en: '![figure](../Images/CH02_F01_Boozallen.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F01_Boozallen.jpg)'
- en: Figure 2.1 To understand text, LLMs must break text into tokens. Each unique
    token has a numeric identifier associated with it.
  id: totrans-11
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.1 为了理解文本，LLM必须将文本分解成标记。每个唯一的标记都与一个与之关联的数值标识符相关联。
- en: 'You can think of tokens as the smallest unit of text an LLM processes—an “atom,”
    if you will, the smallest part from which all other things are built. So what
    are the atoms of text? Consider this: As you read this book, what are the smallest
    building blocks that your brain uses to process meaning? Two natural answers are
    *letters* and *words*. It is very tempting to define letters as the atom since
    words are made of letters, but do you consciously read every letter in every word?
    For most people, the answer is “no.” (If you are dyslexic like one of the co-authors
    of this book, this is a bizarre question. But cognitive processing is complex
    and not fully understood; please bear with us on the analogies!) You look at the
    more prominent words and word parts. In fbct, yoy cn probbly unrestand ths sentnce
    ever through we diddt sue th ryght cpellng or l3ttrs. People unconsciously use
    parts of words to process text, and LLMs are built using the same principle.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将标记视为LLM处理的最小文本单元——如果你愿意，可以将其视为“原子”，所有其他事物都是由它构建的最小部分。那么文本的原子是什么？考虑一下：当你阅读这本书时，你的大脑使用什么最小的构建块来处理意义？两个自然的答案就是*字母*和*单词*。将字母定义为原子很有诱惑力，因为单词是由字母组成的，但你是否真的有意识地阅读每个单词中的每个字母？对大多数人来说，答案是“不”。（如果你像本书的一位合著者一样患有阅读障碍，这个问题可能很奇怪。但认知处理是复杂的，并且尚未完全理解；请对我们使用的类比表示理解！）你关注的是更突出的单词和词根。在fbct中，yoy
    cn probbly unrestand ths sentnce ever through we diddt sue th ryght cpellng or
    l3ttrs。人们无意识地使用单词的部分来处理文本，而LLM正是基于这个原理构建的。
- en: In this chapter, you will learn how the process of converting text to tokens
    works. First, we will discuss tokens in more detail; then, we will discuss the
    procedures used to decide how sentences are turned into tokens.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习将文本转换为分词的过程。首先，我们将更详细地讨论分词；然后，我们将讨论用于决定句子如何转换为分词的程序。
- en: 2.2 Language models see only tokens
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 语言模型只看到分词
- en: By adulthood, most English-speaking people know around 30,000 words [2]. GPT-3,
    the LLM that initially powered ChatGPT, has a vocabulary of 50,257 tokens [3].
    These tokens are not words but parts of words referred to as *subwords*, a representation
    that is somewhere between words and letters. Intuitively, a token captures language’s
    *minimum meaningful semantic unit*. For example, the word `schoolhouse` will often
    get broken into two tokens, `school` and `house`, and the word `thoughtful` as
    `thought` and `ful`. This is useful for recognizing frequent words and having
    the subwords to interpret new words we have never seen before. People often use
    a similar technique, called semantic decomposition, to understand words they’ve
    never seen before. We intuitively break new words into constituent parts to grasp
    their meaning based on words we already understand.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 到成年时，大多数讲英语的人大约知道30,000个单词[2]。最初为ChatGPT提供动力的LLM GPT-3拥有50,257个分词的词汇量[3]。这些分词不是单词，而是称为*子词*的单词的一部分，这种表示介于单词和字母之间。直观地说，一个分词捕捉了语言的*最小有意义的语义单元*。例如，单词`schoolhouse`通常会分解成两个分词，`school`和`house`，单词`thoughtful`会分解成`thought`和`ful`。这对于识别常用单词和拥有子词来解释我们以前从未见过的单词是有用的。人们经常使用类似的技术，称为语义分解，来理解他们以前从未见过的单词。我们直观地将新单词分解成组成部分，根据我们已知的单词来理解其含义。
- en: '*Feature engineering* is the process of converting your data to a form that
    is more convenient to your algorithm and the task you want to solve. To build
    an algorithm that can detect the language of a given text, you could write code
    that takes text as input and outputs the percentage of times each character occurs.
    For example, if `é` appears a lot in a document, you have a good feature to indicate
    that the document is more likely to be Spanish or French than Russian or Chinese.
    Sound feature engineering is concerned with thinking through how your model works,
    what you want to achieve, and how to prepare your data for the combination of
    model and goal.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*特征工程*是将你的数据转换为对算法和你要解决的问题更方便的形式的过程。为了构建一个可以检测给定文本语言的算法，你可以编写代码，以文本作为输入，输出每个字符出现的百分比。例如，如果`é`在一个文档中出现的频率很高，那么你就有了一个很好的特征来表明该文档更有可能是西班牙语或法语，而不是俄语或中文。良好的特征工程涉及思考你的模型是如何工作的，你想要实现什么，以及如何为模型和目标组合准备你的数据。'
- en: Tokenization is the feature engineering of LLMs; it is critically essential
    because tokens are the only information a model interacts with. Tokens are seen
    as individual, abstract *things* that are not inherently connected. The relationships
    are learned through observation of data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 分词是LLM（大型语言模型）的特征工程；它至关重要，因为分词是模型唯一与之交互的信息。分词被视为独立的、抽象的*事物*，它们本身并不具有内在联系。关系是通过观察数据来学习的。
- en: Looking back at figure [2.1](#fig__tokenizationExample), it is evident that
    the tokens for `Dis` and `dis` are related, the only difference being that one
    starts with a capital `D`. However, you can seethat the model assigns the identifier
    ![equation image](../Images/eq-chapter-2-17-1.png) to `Dis` and the identifier
    ![equation image](../Images/eq-chapter-2-17-2.png) to `dis`. That is, the model
    doesn’t inherently see any connection between the tokens representing `Dis` and
    `dis`, even if we, as humans, see an obvious connection. The model doesn’t even
    *see* `Dis` or `dis`. For an LLM to process tokens, we must convert those tokens
    into numbers so that the model will see the numbers ![equation image](../Images/eq-chapter-2-17-3.png)
    and ![equation image](../Images/eq-chapter-2-17-4.png). Importantly, the model
    doesn’t have any direct way to know that these tokens are related.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾图[2.1](#fig__tokenizationExample)，很明显，`Dis`和`dis`的分词是相关的，唯一的区别是其中一个以大写`D`开头。然而，你可以看到模型将标识符![equation
    image](../Images/eq-chapter-2-17-1.png)分配给`Dis`，将标识符![equation image](../Images/eq-chapter-2-17-2.png)分配给`dis`。也就是说，模型本身并不认为代表`Dis`和`dis`的分词之间存在任何联系，即使我们作为人类，看到的是明显的联系。模型甚至不*看到*`Dis`或`dis`。为了使LLM处理分词，我们必须将这些分词转换为数字，这样模型才能看到数字![equation
    image](../Images/eq-chapter-2-17-3.png)和![equation image](../Images/eq-chapter-2-17-4.png)。重要的是，模型没有直接的方式来知道这些分词是相关的。
- en: A token is a mapping from a subword to a unique numeric representation. In turn,
    *tokenization* is the process of converting a full-text string into a sequence
    of tokens. If you have used machine learning libraries before (especially any
    natural language processing [NLP] tools), you are probably familiar with some
    of the simpler forms of tokenization. For example, a simple tokenization process
    breaks a text into tokens by splitting a text based on spaces. However, this approach
    limits our abilities to create subwords or process languages that don’t use whitespace
    to delimit words, such as Chinese.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 标记是从子词到唯一数字表示的映射。反过来，*标记化*是将全文字符串转换为标记序列的过程。如果你之前使用过机器学习库（特别是任何自然语言处理[NLP]工具），你可能熟悉一些简单的标记化形式。例如，简单的标记化过程通过基于空格分割文本来将文本分解成标记。然而，这种方法限制了我们的能力来创建子词或处理不使用空格来分隔单词的语言，例如中文。
- en: 2.2.1 The tokenization process
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.1 标记化过程
- en: 'The generic process that tokenization follows is shown in figure [2.2](#fig__tokenizationProcess)
    with four key steps:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 标记化遵循的通用过程如图[2.2](#fig__tokenizationProcess)所示，包含四个关键步骤：
- en: '*Receiving the text to process*—This means obtaining text input as a `string`
    data type (a collection of letters, digits, or symbols) from a user, the internet,
    or whatever source that has the text you want.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*接收要处理的文本*——这意味着从用户、互联网或任何其他来源获取文本输入作为`字符串`数据类型（一组字母、数字或符号）。这是你想要文本的来源。'
- en: '*Transforming the string*—This often involves changing the string in some useful
    way, such as converting uppercase characters into lowercase. This could also be
    done for security reasons (e.g., the text came from a user, and we need to remove
    anything that might look like some malicious input) or to eliminate irrelevant
    variations in the text to help the algorithm learn better. This process is known
    as *normalization*.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*转换字符串*——这通常涉及以某种有用的方式更改字符串，例如将大写字符转换为小写。这也可能是出于安全原因（例如，文本来自用户，我们需要删除任何可能看起来像恶意输入的东西）或消除文本中的不相关变化，以帮助算法更好地学习。这个过程被称为*规范化*。'
- en: '*Breaking the string into tokens*—Once a string is available, it needs to be
    separated into a sequence of discrete substrings; these are the tokens found in
    the larger string. This is referred to as *segmentation*.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将字符串分解成标记*——一旦有字符串可用，就需要将其分离成一系列离散的子字符串；这些是较大字符串中找到的标记。这被称为*分割*。'
- en: '*Mapping each token to a unique identifier*—The unique identifier is usually
    an integer number, which produces output that the LLM can understand.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将每个标记映射到唯一的标识符*——唯一的标识符通常是整数，它产生LLM可以理解的输出。'
- en: '![figure](../Images/CH02_F02_Boozallen.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH02_F02_Boozallen.png)'
- en: Figure 2.2 Generically, tokenization involves processing input to produce numeric
    identifiers for tokens.
  id: totrans-27
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.2 通常，标记化涉及处理输入以生成标记的数字标识符。
- en: The first and last parts of this process have little room for choice or different
    behavior. First, you need input to process; last, you need a numeric identifier
    for each token to store and retrieve the information you will associate with that
    token. The two middle steps, normalization and segmentation, are where you can
    choose what happens.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程的开始和结束部分几乎没有选择或不同行为的余地。首先，你需要输入来处理；最后，你需要为每个标记存储和检索与该标记关联的信息的数字标识符。中间的两个步骤，规范化和分割，是你可以选择发生什么的地方。
- en: The last step of the tokenization process is where the vocabulary is built.
    The *vocabulary* of a model is the total number of unique tokens that are seen
    during training when we give the algorithm data to learn from. It almost always
    takes a large amount of data to build a rich vocabulary with many unique tokens.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 标记化过程的最后一步是构建词汇表。模型的*词汇表*是在训练过程中看到的独特标记的总数，当我们向算法提供学习数据时。几乎总是需要大量的数据来构建包含许多独特标记的丰富词汇表。
- en: 'Choosing the vocabulary for a model involves a series of trade-offs: the larger
    the vocabulary, the more information your model can process successfully. Consider
    a one-year-old child with a vocabulary of maybe a few dozen words. This child
    will not be a very effective communicator (but that’s okay; they have lots of
    time to learn). So a more extensive vocabulary not only helps the model understand
    more things, but it also makes the model larger. If you have a vocabulary that’s
    too large, you may make the model slower due to the number of computations required
    to use it, or the model may consume an excessive amount of memory or disk storage,
    which makes it more difficult to transfer or share to other machines—for example,
    when deploying it as a part of a software application.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为模型选择词汇涉及一系列权衡：词汇量越大，您的模型可以成功处理的信息就越多。考虑一个可能只有几十个单词词汇量的一岁孩子。这个孩子不会是一个非常有效的沟通者（但那没关系；他们有足够的时间去学习）。因此，更广泛的词汇量不仅有助于模型理解更多事物，而且还会使模型更大。如果您有一个词汇量太大，您可能会因为使用它所需的计算量而使模型变慢，或者模型可能会消耗过多的内存或磁盘存储，这使得将其转移到其他机器或作为软件应用的一部分变得更加困难。
- en: You build the model’s vocabulary by processing the training data and identifying
    tokens. Each time you see a new token, you give it a unique identifier based on
    the number of unique tokens you’ve seen. This process is often as simple as storing
    a counter set to `0` and incrementing it every time a new token is found. Once
    the process is complete, you have a tokenizer that is effectively an *encoder*.
    The tokenizer can receive text as input and return a numeric encoding of that
    text that the LLM algorithms can use as its output.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 您通过处理训练数据并识别标记来构建模型的词汇。每次您看到一个新的标记时，您都会根据您看到的唯一标记的数量给它一个唯一的标识符。这个过程通常就像存储一个设置为`0`的计数器并在每次找到新标记时递增它一样简单。一旦这个过程完成，您就拥有了一个实际上是一个*编码器*的分词器。分词器可以接收文本作为输入，并返回该文本的数值编码，LLM算法可以使用它作为其输出。
- en: 2.2.2 Controlling vocabulary size in tokenization
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.2 在分词中控制词汇量
- en: GPT-NeoX, a publicly available LLM, takes about 10 GB to store its vocabulary
    on disk. That is a lot of data, already large enough to make many real-world use
    cases challenging from the perspective of data storage and computation. It is
    so large that storing it on a micro-SD card would be prohibitively slow, making
    use on a mobile phone or some game consoles a significant challenge. It is big
    enough that it can’t be streamed in real time and must be downloaded and loaded
    into the processor’s RAM to perform tokenization. However, a vocabulary must be
    sufficiently large to represent all words and subwords the model will encounter
    during training and use. Suppose a model encounters a word that is not in its
    vocabulary and cannot be represented by combining subwords in its vocabulary.
    In that case, the model cannot capture information about that piece of text. As
    a result, it is essential to weigh concerns about vocabulary size against the
    need for models to interpret a wide variety of content. In NLP, this is often
    called the out-of-vocabulary problem, when we encounter words we can’t represent
    using the tokens available to the model.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-NeoX，一个公开可用的LLM，在磁盘上存储其词汇需要大约10 GB。这是一大批数据，已经足够大，从数据存储和计算的角度来看，使得许多实际应用案例变得具有挑战性。它如此之大，以至于存储在micro-SD卡上会非常慢，使得在手机或某些游戏机上使用它成为一个重大的挑战。它足够大，以至于不能实时流式传输，必须下载并加载到处理器的RAM中才能进行分词。然而，词汇量必须足够大，以表示模型在训练和使用过程中将遇到的全部单词和子单词。假设模型遇到一个不在其词汇表中的单词，并且无法通过其词汇表中的子单词组合来表示。在这种情况下，模型无法捕捉到该段文本的信息。因此，权衡词汇量大小与模型需要解释广泛内容的需求至关重要。在NLP中，这通常被称为词汇表外问题，当我们遇到无法使用模型可用的标记表示的单词时。
- en: Vocabulary size is one factor contributing to an LLM’s size, so discussing methods
    and tradeoffs for controlling vocabulary size is vital. In this section, we will
    describe how changing the tokenization process’s behavior can influence vocabulary
    size and affect model capabilities and accuracy.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 词汇量是影响大型语言模型（LLM）大小的一个因素，因此讨论控制词汇量的方法和权衡至关重要。在本节中，我们将描述如何改变分词过程的行为来影响词汇量，并影响模型的能力和准确性。
- en: '![figure](../Images/CH02_F03_Boozallen.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F03_Boozallen.png)'
- en: Figure 2.3 The normalization process commonly involves changing text to remove
    uppercase characters and punctuation.
  id: totrans-36
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.3 常见的归一化过程通常涉及将文本转换为删除大写字母和标点符号。
- en: In figure [2.3](#fig__normalization), we focus on the second transformation
    step, normalization, which converts the uppercase characters “H” and “W” to lowercase
    and removes punctuation. These common normalization steps originate from classical
    NLP pipelines and are still sometimes done in modern deep learning approaches
    today. They have the immediately desirable effect of reducing the size of the
    vocabulary. Instead of needing to represent “Hello” and “hello” as two separate
    tokens, they get mapped to one unique token. This mapping makes an enormous difference
    because every word that starts a sentence and gets capitalized would potentially
    duplicate a word in the vocabulary with a capitalized version. Such normalization
    can also help with various typos and misspellings.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在图[2.3](#fig__normalization)中，我们关注第二个转换步骤，归一化，它将大写字母“H”和“W”转换为小写并删除标点符号。这些常见的归一化步骤起源于经典NLP管道，并且在今天的一些现代深度学习方法中仍然有时会执行。它们具有立即期望的效果，即减少词汇量的大小。不再需要将“Hello”和“hello”作为两个不同的标记来表示，它们被映射到一个唯一的标记。这种映射产生了巨大的差异，因为每个以大写字母开头的句子都会潜在地重复词汇库中带有大写版本的那个词。这种归一化还可以帮助解决各种拼写错误和误拼。
- en: For example, while writing this book, we typed “LLMs,” “LLms,” and “llms,” and
    made various other mixed-case typos. Converting each character to lowercase in
    each variation resolves all these typos into a single, simple form, so we get
    a smaller vocabulary and decrease ambiguity.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在撰写这本书的过程中，我们输入了“LLMs”、“LLms”和“llms”，并犯了许多其他的大小写混合错误。将每个变体中的每个字符都转换为小写，可以将所有这些错误都解决成单一、简单的形式，因此我们得到一个更小的词汇量并减少了歧义。
- en: However, converting text to lowercase doesn’t always decrease ambiguity. Consider
    “Bill” and “bill.” In the first situation, capitalization is vital for understanding
    that “Bill” is probably someone’s name, and “bill” is more likely a unit of money
    (or one of the other definitions of “bill”). Capitalization is crucial not only
    for understanding the meaning of the text but also for understanding the errors
    in the text. Consider again all the various ways we miscapitalized “LLMs” in this
    book. A high-quality AI algorithm would be able to recognize that we made a typo
    and correct it! ChatGPT is capable of this and thus requires capitalization in
    the model. So there is an important tradeoff between vocabulary size and potential
    model accuracy to consider.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将文本转换为小写并不总是能减少歧义。考虑“Bill”和“bill”这两个例子。在第一种情况下，首字母大写对于理解“Bill”可能是某人的名字，而“bill”更有可能是货币单位（或其他“bill”的定义）至关重要。首字母大写不仅对于理解文本的意义至关重要，而且对于理解文本中的错误也非常重要。再次考虑一下，在这本书中我们如何错误地大写“LLMs”的所有各种方式。一个高质量的AI算法能够识别我们犯的拼写错误并纠正它！ChatGPT能够做到这一点，因此模型中需要使用大写字母。因此，在词汇量大小和潜在模型准确性之间有一个重要的权衡需要考虑。
- en: In classical NLP and even not-that-old deep learning models like BERT (a predecessor
    to the LLMs that power ChatGPT), the ability of an algorithm to recognize typos
    and fix them was extremely limited outside of solutions designed explicitly for
    that purpose. For this reason, much of the work that used to go into engineering
    a robust normalization step has been discarded for LLMs today. A more extensive
    vocabulary is desirable to produce more capable models that can learn to understand
    mistakes.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在经典NLP以及甚至不是那么老的深度学习模型如BERT（ChatGPT所使用的LLMs的前身）中，算法识别错误并修复它们的能力在专门为此目的设计的解决方案之外极为有限。因此，许多原本用于构建鲁棒的归一化步骤的工作现在已经被LLMs所摒弃。更广泛的词汇量是可取的，以产生更强大的模型，这些模型可以学会理解错误。
- en: 2.2.3 Tokenization in detail
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.3 详细说明分词
- en: 'The normalization and segmentation steps in the tokenization process largelydetermine
    the vocabulary size. In figure [2.4](#fig__segmentation), we show one of the most
    straightforward strategies for tokenization. This strategy follows a simple rule:
    any time a space is seen in the text, split the larger string into those tokens.
    In the case of “hello world,” it is as easy as calling `hello world.split( )`
    in Python. This is a reasonable approach to take; it is how we, as humans, read
    sentences. But it also adds some subtle complexity.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在分词过程中的归一化和分割步骤在很大程度上决定了词汇量的大小。在图[2.4](#fig__segmentation)中，我们展示了分词的最直接策略之一。这个策略遵循一个简单的规则：每当在文本中看到空格时，将较长的字符串分割成那些标记。在“hello
    world”的情况下，在Python中调用`hello world.split( )`就足够简单了。这是一个合理的做法；这是我们人类阅读句子的方式。但它也增加了一些微妙的复杂性。
- en: '![figure](../Images/CH02_F04_Boozallen.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F04_Boozallen.png)'
- en: Figure 2.4 The segmentation process breaks normalized text into words or tokens
    so that each can be processed independently.
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.4 分割过程将规范化文本分解成单词或标记，以便每个都可以独立处理。
- en: 'What happens when you have punctuation in your text? If we use our white space
    rule to convert the string “hello, world” into `[hello,, world]`, we run into
    a similar problem as we do with capitalization. We end up with two distinct tokens
    for the same concept: `hello` and `hello,`. The old-school approach often addressed
    this by removing and developing more complex rules for splitting strings into
    tokens. While this is a step in the right direction toward reducing vocabulary
    size, manually specifying tokenization rules does not address other concerns.
    For example, rule-based tokenization strategies are a significant struggle for
    languages like Chinese that do not use spaces to separate words.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的文本中有标点符号时会发生什么？如果我们使用我们的空白规则将字符串“hello, world”转换为 `[hello,, world]`，我们会遇到与大小写类似的问题。我们最终会得到两个代表同一概念的独立标记：`hello`
    和 `hello,`。传统的做法通常是通过删除并开发更复杂的规则来分割字符串为标记来解决这个问题。虽然这是朝着减少词汇量正确方向迈出的一步，但手动指定标记化规则并没有解决其他问题。例如，基于规则的标记化策略对于像中文这样的不使用空格分隔单词的语言来说是一个巨大的挑战。
- en: Identifying subwords with byte-pair encoding
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用字节对编码识别子词
- en: The general theme of LLMs is to do less feature engineering by hand and let
    algorithms do the heavy lifting instead. For this reason, an algorithm known as
    *byte pair encoding* (BPE) is typically used to break strings into tokens. Byte
    pair encoding is an algorithm for breaking words into common subword sequences
    of characters. BPE today is usually done with a custom segmenter and almost no
    normalization.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）的一般主题是通过手动进行更少的特征工程，让算法来做繁重的工作。因此，通常使用一种名为 *字节对编码*（BPE）的算法来将字符串分解成标记。字节对编码是一种将单词分解成常见的子词字符序列的算法。如今，BPE通常使用自定义的分割器，并且几乎不需要进行规范化。
- en: Note By experimentation, we see many ChatGPT-like products will remove some
    Unicode characters that do not print (Unicode is weird), but otherwise mostly
    take your text as-is. Most prior language models do use various flavors of normalization,
    and how to normalize text for LLMs better is, we think, a good and open question.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：通过实验，我们发现许多类似ChatGPT的产品会移除一些不打印的Unicode字符（Unicode很奇怪），但除此之外，它们基本上会以原样接受你的文本。大多数先前的语言模型确实使用了各种形式的规范化，我们认为如何更好地为LLMs规范化文本是一个好且开放的问题。
- en: Since finding the most efficient set of subwords is a computationally expensive
    task, BPE uses a heuristic to take a shortcut. It starts by looking at individual
    letters as tokens and then finds pairs of adjacent letters that occur most frequently
    and combines them into subword tokens. The algorithm repeats this process many
    times, continuing with subword tokens, until some threshold is met and the vocabulary
    is “small enough.” For example, in the first pass, the BPE algorithm examines
    the frequency of the individual letters used in English and encounters the letters
    “i,” “n,” and “g” near each other frequently. In the first pass, BPE might observe
    that “n” and “g” occur together more frequently than “i” and “n,” so it will produce
    the tokens `i` and `ng`. In a subsequent pass, it may combine those tokens into
    `ing` based on the frequency of that combination of letters versus how often “ng”
    occurs with other letters or subwords. Once BPE has reached its stopping point,
    it will have identified individual words such as “eating” and “drinking” as frequently
    occurring combinations. It may also capture “ing” as a suffix so that other words
    ending with that subword can also be represented as tokens. When the algorithm
    is complete, we end up with tokens that capture complete words and others that
    capture subwords. This process is shown at a high level in figure [2.5](#fig__bpe).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于找到最有效的子词集是一个计算成本很高的任务，BPE 使用启发式方法来简化这个过程。它首先将单个字母视为标记，然后找到出现频率最高的相邻字母对，并将它们组合成子词标记。该算法重复这个过程多次，继续使用子词标记，直到达到某个阈值，词汇表“足够小”。例如，在第一次遍历中，BPE
    算法检查英语中使用的单个字母的频率，并发现字母“i”、“n”和“g”经常出现在一起。在第一次遍历中，BPE 可能观察到“n”和“g”一起出现的频率比“i”和“n”一起出现的频率更高，因此它将生成标记
    `i` 和 `ng`。在随后的遍历中，它可能根据该字母组合的频率与“ng”与其他字母或子词一起出现的频率相比，将这些标记组合成 `ing`。一旦 BPE 达到其停止点，它将识别出诸如“eating”和“drinking”这样的单词作为频繁出现的组合。它还可能将“ing”作为后缀捕获，以便以该子词结尾的其他单词也可以表示为标记。当算法完成时，我们最终得到捕获完整单词和其他捕获子词的标记。这个过程在图
    [2.5](#fig__bpe) 中以高层次展示。
- en: '![figure](../Images/CH02_F05_Boozallen.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F05_Boozallen.png)'
- en: 'Figure 2.5 A simplified byte pair encoding algorithm for creating tokens: first,
    find the most frequent pair of characters “ng.” Next, replace all instances of
    “ng” with a placeholder token “T,” and add “ng” to the vocabulary. Repeat the
    process until no common byte pairs remain.'
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.5 创建标记的简化字节对编码算法：首先，找到出现频率最高的字符对“ng”。接下来，将所有“ng”实例替换为占位符标记“T”，并将“ng”添加到词汇表中。重复此过程，直到没有剩余的常见字节对。
- en: Note Running the BPE algorithm to create a vocabulary is surprisinglyexpensive
    because it must read the input data many times to calculate the most frequent
    combinations of letters. While LLMs are trained on over 500 million or even 1
    billion pages of text, their tokenizers are usually created using a tiny subset
    of that data. Often, a tokenizer is trained using a much smaller collection of
    text the size of a novel.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：运行 BPE 算法创建词汇表非常昂贵，因为它必须多次读取输入数据来计算字母的最频繁组合。虽然大型语言模型在超过 5 亿甚至 10 亿页的文本上进行了训练，但它们的标记器通常使用该数据的一个非常小的子集创建。通常，标记器使用一个比小说还要小的文本集合进行训练。
- en: The BPE process may seem odd at first, but you can think of it as a way of identifying
    common strings in a corpus. For example, BPE will almost always learn to represent
    `New York` as one token, which is useful since the state and city of New York
    are frequent occurrences in the text. Representing the whole concept as a single
    token makes it easier to use that kind of information. Indeed, most common words
    will become unique tokens, while rare words are hopefully captured as a combination
    of subwords. For example, `loquacious` will be tokenized by GPT-4 as `lo`, `qu`,
    and `acious`. This method is a success because “acious” is a Latin postfix for
    inclination/propensity, making it easier for the model to handle an unusual word
    correctly. It is also a failure case because the Latin prefix “`loqu`” got broken
    up into two tokens instead of one, making learning harder.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: BPE过程一开始可能看起来很奇怪，但你可以将其视为识别语料库中常见字符串的一种方式。例如，BPE几乎总是学会将`New York`表示为一个标记，这在文本中纽约州和纽约市频繁出现时很有用。将整个概念表示为一个单独的标记使得使用这类信息变得更容易。确实，大多数常见单词将变成唯一的标记，而罕见单词则希望被捕获为子词的组合。例如，`loquacious`将被GPT-4分词为`lo`、`qu`和`acious`。这种方法之所以成功，是因为“acious”是拉丁语后缀，表示倾向/倾向性，这使得模型更容易正确处理不寻常的单词。它也是一个失败案例，因为拉丁语前缀“`loqu`”被拆分为两个标记而不是一个，这使得学习变得更加困难。
- en: After BPE is used to make a vocabulary, model authors manually add additional
    tokens for various reasons, such as words that are important to a specific knowledge
    domain. As we will discuss in the next section, in some domains, having the correct
    tokens has a significant effect by capturing nuanced meaning. So often, the authors
    will make sure the necessary tokens are included. Model authors will also add
    special tokens that don’t directly represent word parts but provide auxiliary
    information to the model. Some common examples of this are the “unknown” token
    (typically represented as `[UNK]`), which is used if the tokenizer fails to process
    a symbol correctly, and the system token `[SYSTM]`, which is used to distinguish
    between a model’s built-in prompt and user-entered data, as well as other kinds
    of stylistic markers. Multimodal models that accept text and image inputs use
    unique tokens to tell the model when the input stream switches between bytes that
    represent text data and bytes that represent image data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用BPE（字节对编码）创建词汇表之后，模型作者出于各种原因手动添加额外的标记，例如对特定知识领域重要的单词。正如我们将在下一节讨论的，在某些领域，拥有正确的标记通过捕捉细微的意义具有显著的影响。因此，作者通常会确保必要的标记被包含在内。模型作者还会添加特殊的标记，这些标记不直接表示词的部分，但为模型提供辅助信息。这类标记的一些常见例子包括“未知”标记（通常表示为
    `[UNK]`），当分词器无法正确处理符号时使用，以及系统标记 `[SYSTM]`，用于区分模型的内置提示和用户输入的数据，以及其他类型的风格标记。接受文本和图像输入的多模态模型使用独特的标记来告知模型输入流何时在代表文本数据的字节和代表图像数据的字节之间切换。
- en: Open AI decided to use BPE to encode text into tokens when they developed ChatGPT
    and have released their tokenizer as the open source package `tiktoken` ([https://github.com/openai/tiktoken](https://github.com/openai/tiktoken)).
    Still, several other algorithms and implementations for automatically generating
    tokens are available, including the WordPiece and SentencePiece algorithms developed
    at Google [4]. Each of these have different tradeoffs. For example, WordPiece
    uses a different technique for counting the frequency of the candidate subwords
    when building the tokenizer’s vocabulary. One of the algorithms implemented in
    SentencePiece processes entire sentences, preserving white space when calculating
    tokens, which may improve output when building models that handle multiple languages.
    However, BPE is the most broadly used algorithm. For example, it is now used exclusively
    in Google’s recent LLMs.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI在开发ChatGPT时决定使用BPE将文本编码成标记，并已将他们的分词器作为开源包`tiktoken`（[https://github.com/openai/tiktoken](https://github.com/openai/tiktoken)）发布。尽管如此，还有其他几种自动生成标记的算法和实现，包括谷歌开发的WordPiece和SentencePiece算法[4]。这些算法各有不同的权衡。例如，WordPiece在构建分词器词汇表时，使用不同的技术来计数候选子词的频率。SentencePiece中实现的一种算法处理整个句子，在计算标记时保留空白字符，这可能在构建处理多种语言的模型时提高输出质量。然而，BPE是最广泛使用的算法。例如，它现在被谷歌最近的大型语言模型（LLMs）独家使用。
- en: Regardless of the algorithm chosen, the size of a tokenizer’s vocabulary is
    a critical model parameter determined by the data scientist or engineer in charge
    of training and augmenting the tokenizer. The following sections dive deep into
    some of the considerations on vocabulary size and other decisions made throughout
    the tokenizer development process.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 无论选择哪种算法，分词器的词汇表大小都是一个关键模型参数，由负责训练和增强分词器的数据科学家或工程师确定。以下几节将深入探讨词汇表大小和其他在分词器开发过程中做出的决策。
- en: 2.2.4 The risks of tokenization
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.4 分词的风险
- en: As mentioned in chapter 1, we won’t go much into coding in this book. The goal
    is to give you a reasonable understanding of how LLMs work and remove some of
    the magic and mystery so you can focus instead on how LLMs may be used for your
    job. Tokenization is the first piece of the puzzle. It is a simple but effective
    strategy to produce the inputs to LLMs. You have learned how the size of the vocabulary
    plays a significant role in a model’s deployability, the tradeoff in recognizing
    nuance versus the unnecessary redundancy associated with making a vocabulary,
    how the tokenization process influences the size of the vocabulary, and how the
    token selection process can be automated with BPE.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如第1章所述，本书不会过多涉及编码。目标是让你对LLMs（大型语言模型）的工作原理有一个合理的理解，并消除一些神秘感，以便你能够专注于LLMs如何应用于你的工作。分词是拼图的第一块。这是一种简单但有效的策略，用于生成LLMs的输入。你已经了解到词汇表的大小在模型的可部署性中起着重要作用，认识到在识别细微差别与制作词汇表相关的无必要冗余之间的权衡，了解到分词过程如何影响词汇表的大小，以及如何使用BPE（字节对编码）自动化标记选择过程。
- en: 'The choices made at tokenization time affect what LLMs can do today and will
    affect them in the future. These choices involve a few big-picture challenges
    to be aware of. To explore this topic further, two salient yet nuanced details
    of BPE are worth sharing some concerns about: the relationship between sentence
    length and token counts and the potential for LLMs to be confused by characters,
    known as homoglyphs, that appear identical yet have different binary encodings.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在分词时所做的选择会影响LLMs今天能做什么，并将在未来影响它们。这些选择涉及一些需要了解的大挑战。为了进一步探讨这个话题，BPE的两个显著但细微的细节值得分享一些关注点：句子长度与标记计数之间的关系，以及LLMs可能被具有相同二进制编码但外观不同的字符（称为同形异义字）所混淆的潜在可能性。
- en: Longer sentences do not mean more tokens
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 句子越长并不意味着标记越多
- en: An unintuitive aspect of BPE is that longer sentences do not mean more tokens.
    To see why, look at figure [2.6](#fig__whatIsTokenization), where we show a real
    tokenization of two different strings by GPT-3\. The string “I’m running” is longer
    by one character than the string “I’m runnin,” but it is one token shorter! If
    you don’t believe it, you can try tokenizing different strings at [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: BPE的一个不直观的方面是，句子越长并不意味着标记越多。为了理解为什么，请看图[2.6](#fig__whatIsTokenization)，其中我们展示了GPT-3对两个不同字符串的真正分词。字符串“I’m
    running”比字符串“I’m runnin”多一个字符，但它少一个标记！如果你不相信，你可以在[https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)尝试对不同的字符串进行分词。
- en: '![figure](../Images/CH02_F06_Boozallen.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F06_Boozallen.png)'
- en: Figure 2.6 Tokenizing two different sentences
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.6 分词两个不同的句子
- en: This discrepancy occurs because BPE is greedily looking for the smallest set
    of tokens for any piece of input. In this specific case, the string “running”
    occurs frequently enough in our training data that it gets its own token. In the
    case where the “g” is missing, there is no token for “runnin” in our vocabulary
    because that variation may have appeared rarely in our training data. Thus, “runnin”
    needs to be broken into at least two tokens, giving us `run` and `nin`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这种差异发生是因为BPE（字节对编码）在寻找任何输入的最小标记集时是贪婪的。在这个特定案例中，字符串“running”在我们的训练数据中出现的频率足够高，以至于它得到了自己的标记。在“g”缺失的情况下，我们的词汇表中没有“runnin”的标记，因为这种变化可能在我们训练数据中很少出现。因此，“runnin”需要被分解成至少两个标记，给我们“run”和“nin”。
- en: This nuance of tokenizer implementation is fertile ground for software bugs.
    Different tokenizers may provide different answers on how to tokenize the same
    string. When designing unit tests and infrastructure, this factor is important
    to keep in mind to avoid getting lost or confused when upgrading or converting
    between tokenizer implementations that may cause new differences in token generation.
    It can also affect evaluations of LLMs, as many models are highly sensitive to
    added white space, and inconsistent tokenization may inadvertently lead to comparisons
    not being apples to apples.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 分词器实现的这种细微差别是软件漏洞的沃土。不同的分词器可能会对如何分词相同的字符串提供不同的答案。在设计单元测试和基础设施时，这个因素需要牢记在心，以避免在升级或转换可能导致新差异的分词器实现时迷失方向或感到困惑。它也可能影响LLM的评估，因为许多模型对添加的空白空间非常敏感，不一致的分词可能会无意中导致比较不是“苹果对苹果”。
- en: Homoglyphs create confusion
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 同形异义字符会引起混淆
- en: Homoglyphs are a problem developers may encounter when working with multiple
    human languages or considering the security implications of processing externally
    provided data. When input comes from arbitrary users, sometimes it may be nefarious
    and want to trick your model into bad behavior. One way that could be done against
    an LLM is with a *homoglyph* attack.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当开发者处理多种人类语言或考虑处理外部提供数据的安全性影响时，同形异义字符可能会成为一个问题。当输入来自任意用户时，有时可能是恶意的，并试图诱使你的模型表现出不良行为。对LLM进行的一种可能的攻击方式就是使用*同形异义字符攻击*。
- en: A homoglyph is when two or more characters have different byte encodings but
    appear identical when rendered on the screen. One example is the Latin letter
    “H” used in most Western European languages and the Cyrillic “H” used throughout
    Eastern Europe and Central Asia.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个或更多字符具有不同的字节编码，但在屏幕上渲染时看起来相同，这就是同形异义字符。一个例子是大多数西欧语言中使用的拉丁字母“H”和整个东欧和中亚地区使用的西里尔字母“H”。
- en: BPE will encode homoglyphs that use different byte encodings into different
    tokens. As a result, homoglyphs can inflate the number of tokens in a text, change
    how an LLM parses the information, and run up your compute costs. An amusing example
    of a homoglyph is the Unicode character U+200B, also known as the “zero width
    space.” This character is used in typesetting and takes up space, but it does
    not print anything, show anything, or change anything about how a document is
    rendered.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: BPE会将使用不同字节编码的同形异义字符编码成不同的标记。因此，同形异义字符可能会增加文本中的标记数量，改变LLM解析信息的方式，并增加你的计算成本。一个有趣的同形异义字符例子是Unicode字符U+200B，也称为“零宽空格”。这个字符在排版中使用，占据空间，但不会打印任何内容，显示任何内容，或改变文档的渲染方式。
- en: The zero width space is one of many strange and interesting things that exist
    within the Unicode specification and could be used to cause you pain. Many services
    thus employ normalization steps that remove such strange characters and replace
    homoglyphs with a canonical representation (i.e., anything that looks like an
    “a” must be encoded as an `a`). For example, OpenAI’s current tokenizer interface
    will remove homoglyphs. You must consider homoglyphs if you want to deploy an
    LLM on your hardware or a user’s device.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 零宽空格是Unicode规范中存在许多奇怪且有趣的事物之一，可能会给你带来麻烦。因此，许多服务都采用规范化步骤来删除这些奇怪字符，并将同形异义字符替换为规范表示（即，任何看起来像“a”的字符都必须编码为`a`）。例如，OpenAI当前的分词器接口会删除同形异义字符。如果你想在你的硬件或用户的设备上部署LLM，你必须考虑同形异义字符。
- en: 2.3 Tokenization and LLM capabilities
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 分词和LLM能力
- en: If we are only concerned with the ability of an LLM to produce high-quality
    human-like text, the specific details of how you tokenize your text do not matter
    as much as the data and compute used to build these models. If you put enough
    computational power and scale into your models, they will eventually figure out
    useful representations regardless of the building blocks. But sometimes, tokenization
    dramatically affects what an LLM is capable of. In this section, we cover some
    examples.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只关心LLM产生高质量类似人类文本的能力，那么你分词文本的具体细节并不像构建这些模型所使用的数据和计算那样重要。如果你在模型中投入足够的计算能力和规模，它们最终会找到有用的表示，无论这些表示的构建块是什么。但有时，分词会极大地影响LLM的能力。在本节中，我们将介绍一些例子。
- en: It may be the case that the examples that follow are not directly relevant to
    your job or what you would like to do with an LLM. That is perfectly fine; the
    point of these examples is not to dissuade you from using an LLM. Instead, the
    goal is to help you understand that the scope of what LLMs learn is limited by
    the representation chosen, and there may not be a way around these concerns without
    major engineering work. If you start building an application with LLMs and find
    significant difficulty, think about how tokenization could be a factor in your
    goal. If tokenization is indeed the problem, there is little you can do to solve
    it, so it may be best to look at other approaches, such as manually augmenting
    the vocabulary with tokens that are important for your application.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 可能是以下例子与你的工作或你希望用LLM做什么不直接相关；这完全没问题；这些例子的目的不是让你放弃使用LLM。相反，目标是帮助你了解LLM学习的范围受所选表示的限制，并且可能没有方法绕过这些担忧而不进行大量工程工作。如果你开始用LLM构建应用程序并发现重大困难，考虑令牌化如何成为你目标的一个因素。如果令牌化确实是问题所在，那么你几乎无法解决这个问题，因此最好考虑其他方法，例如手动通过对你应用重要的令牌来增强词汇表。
- en: 2.3.1 LLMs are bad at word games
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.1 LLMs在单词游戏中表现不佳
- en: Users frequently enjoy asking LLMs to solve word puzzles or perform tasks that
    involve word games. For example, figure [2.7](#fig__badAtWordGames) shows a word
    game where the correct answer depends on the exact letter sequence and the number
    of letters in a word.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 用户经常喜欢让LLM解决单词谜题或执行涉及单词游戏的任务。例如，图[2.7](#fig__badAtWordGames)展示了一个单词游戏，正确答案取决于单词的确切字母序列和单词中的字母数量。
- en: '![figure](../Images/CH02_F07_Boozallen.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F07_Boozallen.jpg)'
- en: Figure 2.7 The tokenization approach means that ChatGPT cannot really “see”
    single characters or word lengths. If you ask questions that require subcharacter
    identification and change them in a unique and unusual way, ChatGPT starts to
    fail. The correct middle character is “a,” but ChatGPT insists that the letter
    is “e.” What ChatGPT sees is three tokens, representing `P`, `ine`, and `apple`,
    respectively.
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.7 令牌化方法意味着ChatGPT实际上无法“看到”单个字符或单词长度。如果你提出需要识别子字符并独特地改变它们的问题，ChatGPT开始失败。正确的中间字符是“a”，但ChatGPT坚持认为字母是“e”。ChatGPT看到的是三个令牌，分别代表`P`、`ine`和`apple`。
- en: Playing word games may not be something you care about for your application,
    but the reason word games fail may be highly salient to your problem. Although
    many examples like this are toy problems in that they aren’t particularly scientifically
    or commercially important, they reveal notable breakdowns in how these models
    operate. They may come into play in more practical uses, such as when models struggle
    to write poetry containing rhymes or assonance.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 玩单词游戏可能不是你应用中关心的事情，但单词游戏失败的原因可能对你的问题非常明显。尽管许多这样的例子在科学或商业上并不重要，但它们揭示了这些模型操作中的显著故障。它们可能在更实际的应用中发挥作用，例如当模型难以写出包含押韵或谐音的诗歌时。
- en: Consider, for example, that you want to build an application that answers questions
    about a user’s prescription drugs. Drugs often have longer, confusing names that
    people fail to remember or spell incorrectly, and because an LLM does not understand
    letters, it may confuse one drug’s name with a different drug’s long and strange
    name.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你想构建一个回答用户处方药问题的应用程序。药物通常有更长、更令人困惑的名称，人们难以记住或拼错，而且由于LLM不理解字母，它可能会将一种药物的名称与另一种药物的长而奇怪的名称混淆。
- en: Because drug names are uncommon, they will tokenize differently, even with minor
    misspellings. For example, in GPT-3, “Amoxicillin” and the easy misspelling “Amoxicillan”
    share no common tokens! This creates a much greater risk of the LLM responding
    incorrectly, where the risk is intrinsically higher, making an LLM application
    all the more important to thoroughly test, engineer around with extreme care,
    or potentially avoid altogether.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于药物名称不常见，即使有轻微的拼写错误，它们也会以不同的方式进行令牌化。例如，在GPT-3中，“Amoxicillin”和容易拼错的“Amoxicillan”没有共享任何公共令牌！这导致LLM响应错误的概率大大增加，风险本质上更高，因此对LLM应用进行彻底测试、极端小心地进行工程处理或可能完全避免变得尤为重要。
- en: 2.3.2 LLMs are challenged by mathematics
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.2 LLMs在数学上面临挑战
- en: Tokenization significantly affects tasks involving formal symbolic reasoning,
    including mathematics and playing board games. Both math and board games are implemented
    by LLMs as symbolic reasoning problems where individual tokens have specific rules
    governing their interactions and meaning when observed in conjunction with other
    tokens. For example, models containing individual tokens for each digit tend to
    perform better at arithmetic than models that don’t. This is because the number
    123456 will become two tokens in GPT-3, `[, ]`, based on the frequency of those
    tokens in the tokenizer’s original training data. This makes it harder for the
    model to deal with the individual digits in that number. Some system developers
    have solved this problem by normalizing numbers by inserting spaces between all
    digits, such as 1 2 3 4 5 6, which creates a new output with six tokens, one for
    each digit.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '分词对涉及形式符号推理的任务有显著影响，包括数学和玩棋类游戏。数学和棋类游戏都是由 LLM 作为符号推理问题实现的，其中单个标记具有特定的规则，这些规则控制着它们与其他标记交互和意义。例如，包含每个数字单独标记的模型在算术运算上往往比不包含这些标记的模型表现更好。这是因为数字
    123456 在 GPT-3 中将成为两个标记 `[, ]`，这是基于这些标记在分词器原始训练数据中的频率。这使得模型处理该数字中的单个数字变得更加困难。一些系统开发者通过在所有数字之间插入空格来规范化数字，例如
    1 2 3 4 5 6，这会创建一个新的输出，包含六个标记，每个数字一个。 '
- en: This difference in math capability is well-illustrated in figure [2.8](#fig__math-eval),
    which shows performance on arithmetic computations throughout training. The top
    curve is a typical BPE tokenizer, while the bottom curve, which shows better performance,
    is the same tokenizer modified to have digit-level tokenization of numbers.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数学能力差异在图 [2.8](#fig__math-eval) 中得到了很好的体现，该图显示了整个训练过程中的算术计算性能。顶部曲线是一个典型的 BPE
    分词器，而底部曲线，显示了更好的性能，是经过修改的相同分词器，它对数字进行了数字级别的分词。
- en: '![figure](../Images/CH02_F08_Boozallen.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F08_Boozallen.png)'
- en: Figure 2.8 A comparison of how two LLMs learn to perform arithmetic computations
    over time. Time is shown on the x-axis. The upper curve is a typical BPE tokenizer,
    while the lower curve is the same tokenizer modified to use tokens that represent
    individual digits. The y-axis describes the ability of the LLM to perform accurately,
    where a smaller number means fewer errors. The bottom line is that LLMs that use
    digit-level tokenization can learn how to do math better and faster.
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.8 比较了两个大型语言模型（LLM）随时间学习进行算术计算的方式。时间显示在 x 轴上。上曲线是一个典型的 BPE 分词器，而下曲线是经过修改的相同分词器，它使用代表单个数字的标记。y
    轴描述了 LLM 准确执行任务的能力，其中数字越小表示错误越少。底线是，使用数字级别分词的 LLM 可以更好地、更快地学习数学。
- en: 2.3.3 LLMs and language equity
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.3 LLMs 和语言公平性
- en: Most LLM tokenizers can represent any symbol covered by Unicode, which includes
    the characters from most of the world’s alphabets. However, how efficiently those
    tokenizers represent text in a given language varies massively, especially as
    thetokenizers are typically trained on smaller collections of text resources for
    different languages. This can cause substantial inequity in commercial services
    based on LLMs [5] because tokenization of words in languages that are rare in
    the training set defaults to a more granular set of subwords, resulting in increased
    token usage. Commercial LLM providers like OpenAI and Anthropic typically charge
    customers on a per-token basis, usually a fraction of a cent for every token input
    into the LLM and produced as output by the LLM. These costs add up when you consider
    that a high-use commercial application may process tens of millions of tokens
    daily.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 LLM 分词器可以表示 Unicode 覆盖范围内的任何符号，这包括世界上大多数字母表中的字符。然而，这些分词器在表示特定语言的文本方面的效率差异很大，尤其是在分词器通常针对不同语言的较小文本资源集合进行训练的情况下。这可能导致基于
    LLM 的商业服务存在重大不公平性 [5]，因为训练集中罕见的语言的单词分词默认为更细粒度的子词集合，从而导致标记使用量增加。像 OpenAI 和 Anthropic
    这样的商业 LLM 提供商通常按每个标记向客户收费，通常每个输入到 LLM 并由 LLM 生成的标记的费用是几分之一美分。当考虑到高使用量的商业应用可能每天处理数千万个标记时，这些成本就会累积起来。
- en: 'The time it takes for an LLM to complete a request and the amount a user is
    charged per token depends directly on the tokenizer. Therefore, languages that
    are more efficiently represented using a tokenizer are economically incentivized
    over those that are not represented efficiently. Using English as a baseline,
    researchers have found that the cost to answer a user query in German or Italian
    is about 50% more when using ChatGPT and GPT-4\. Languages that differ even more
    substantially from English can incur much larger charges: Tumbuka and Bulgarian
    are more than twice the cost, and Dzongkha, Odia, Santali, and Shan cost over
    12 times as much as English to process.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 完成请求所需的时间和用户每 token 收取的费用直接取决于分词器。因此，使用分词器更有效地表示的语言在经济上会得到激励，而那些表示效率不高的语言则不会。以英语为基准，研究人员发现，使用
    ChatGPT 和 GPT-4 回答德语或意大利语用户查询的成本大约高出 50%。与英语差异更大的语言可能会产生更大的费用：Tumbuka 和保加利亚语的成本超过两倍，而藏语、奥里亚语、桑塔尔语和掸语的处理成本是英语的
    12 倍以上。
- en: 2.4 Check your understanding
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 检查你的理解
- en: 'How would you expect the following words or phrases to be tokenized? Try breaking
    them out yourself and then running them through an actual LLM tokenizer, such
    as the one at [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer):'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你预计以下单词或短语会如何被分词？试着自己分解它们，然后通过实际的 LLM 分词器，如 [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)
    进行测试：
- en: backstopped
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: backstopped
- en: large language models
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言模型
- en: Schoolhouse
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学校
- en: How you process sentences to understand them is a complex process that changes
    as you get older and involves multiple sequential and concurrent cognitive processes
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你如何处理句子以理解它们是一个复杂的过程，这个过程会随着年龄的增长而变化，并涉及多个顺序和并发认知过程
- en: How much do you think uppercase versus lowercase letters matter for each of
    the previous examples? Try submitting them again with various casings.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你认为大写字母与小写字母在每个先前的例子中有多重要？试着用不同的格式重新提交它们。
- en: Let’s simulate how LLMs think about math using a cipher where each English letter
    corresponds to a number. For example, ![equation image](../Images/eq-chapter-2-84-1.png),
    ![equation image](../Images/eq-chapter-2-84-2.png), ![equation image](../Images/eq-chapter-2-84-3.png),
    and ![equation image](../Images/eq-chapter-2-84-4.png), so we would write *WAIT*
    to mean ![equation image](../Images/eq-chapter-2-84-5.png). Knowing this fact
    and that ![equation image](../Images/eq-chapter-2-84-6.png), can you figure out
    what ![equation image](../Images/eq-chapter-2-84-7.png) represents?
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过一个密码来模拟 LLM 如何思考数学，其中每个英语字母对应一个数字。例如，![方程式图片](../Images/eq-chapter-2-84-1.png)，![方程式图片](../Images/eq-chapter-2-84-2.png)，![方程式图片](../Images/eq-chapter-2-84-3.png)，和
    ![方程式图片](../Images/eq-chapter-2-84-4.png)，因此我们会用 *WAIT* 来表示 ![方程式图片](../Images/eq-chapter-2-84-5.png)。知道这个事实以及
    ![方程式图片](../Images/eq-chapter-2-84-6.png)，你能弄清楚 ![方程式图片](../Images/eq-chapter-2-84-7.png)
    代表什么吗？
- en: Since a token is the basic unit an LLM operates on, why does it make sense (technologically)
    that languages less efficiently represented by a tokenizer would cost more?
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于 token 是 LLM 运作的基本单元，为什么使用分词器表示效率较低的语言成本更高在技术上是有意义的？
- en: Is it an ethical problem that LLMs charge different amounts to people for the
    same service based on what language they speak? Would you consider this discrimination?
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用大型语言模型（LLM）向说不同语言的人收取相同服务的不同费用是否是一个道德问题？你会认为这是一种歧视吗？
- en: 2.5 Tokenization in context
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 上下文中的分词
- en: The details of tokenization we discuss in this chapter are the foundational
    building blocks of LLMs that govern the input they can represent effectively and
    the output they produce. Tokenization is a critical component of LLMs like ChatGPT
    in develop-ing effective representations of text so that they can be used to learn
    relationships between tokens when presented with vast amounts of information in
    the training process, interpreting user input and producing the high-quality responses
    we’ve become accustomed to. An LLM’s potential is limited or enabled by the tokenization
    strategy and vocabulary it employs, in conjunction with all of the other characteristics
    we explore in the following chapters.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论的分词细节是 LLM 的基础构建块，决定了它们可以有效地表示的输入和产生的输出。分词是 LLM（如 ChatGPT）在开发有效文本表示中的关键组成部分，以便在训练过程中处理大量信息时，可以学习
    token 之间的关系，解释用户输入并产生我们习惯的高质量响应。LLM 的潜力受限于或由其采用的分词策略和词汇表决定，以及我们在以下章节中探讨的所有其他特征。
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Tokenization is the fundamental process that LLMs use to understand text by
    converting sentences into tokens.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记化是LLM通过将句子转换为标记来理解文本的基本过程。
- en: Tokens are the smallest units of information in text that represent content.
    Sometimes, they correspond to full words, but often, they represent pieces of
    words or sub-words.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记是文本中最小的信息单位，代表内容。有时，它们对应于完整的单词，但通常，它们代表单词或子单词的部分。
- en: Tokenization involves *normalizing* text into a standard representation, which
    may involve converting characters to lowercase or translating the byte encoding
    of Unicode characters so that visibly identical characters employ the same encoding.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记化（Tokenization）涉及将文本*规范化*成标准表示，这可能包括将字符转换为小写或转换Unicode字符的字节编码，以便可见的相同字符使用相同的编码。
- en: Tokenization also involves *segmentation*, which is breaking up text into words
    or subwords. Algorithms like byte pair encoding (BPE) provide a mechanism to automatically
    learn how to efficiently segment text based on the statistical occurrence of combinations
    of letters in a training data set.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记化还涉及*分割*，即将文本分割成单词或子单词。例如字节对编码（BPE）这样的算法提供了一种机制，可以根据训练数据集中字母组合的统计出现频率自动学习如何有效地分割文本。
- en: The result of building a tokenizer is known as a *vocabulary*, which is the
    unique collection of word and subword tokens that a tokenizer can use to represent
    text it has processed.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建标记化器的结果被称为*词汇表*，这是标记化器可以用来表示其处理过的文本的唯一单词和子单词标记集合。
- en: The size of a tokenizer’s vocabulary affects the LLM’s ability to accurately
    represent data and the storage and computational resources required to understand
    and predict text.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记化器的词汇表大小会影响LLM准确表示数据的能力，以及理解和预测文本所需的存储和计算资源。
- en: Internally to the LLM, tokens are represented using numbers. As a result, there
    is no understanding of relationships between tokens, such as prefixes and suffixes,
    or the fact that two tokens share a similar set of letters.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在LLM内部，标记（tokens）是用数字来表示的。因此，没有理解标记之间关系的能力，例如前缀和后缀之间的关系，或者两个标记共享一组相似的字母的事实。
- en: To support specific domains of knowledge, tokenizers trained automatically may
    be augmented to provide tokens that are important to their application.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了支持特定的知识领域，自动训练的标记化器可能被增强以提供对其应用重要的标记。
- en: Tokenizers that do not understand individual letters or digits will have problems
    with arithmetic operations or simple word games.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不理解单个字母或数字的标记化器在算术运算或简单的文字游戏中会遇到问题。
