- en: 4 Understanding what your users really want
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 理解用户真正想要什么
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Recognizing indicators of weak understanding
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别理解能力薄弱的指标
- en: Measuring chatbot understanding
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 衡量聊天机器人的理解能力
- en: Assessing your chatbot’s current state
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估您的聊天机器人的当前状态
- en: Collecting and preparing log data to measure chatbot understanding
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集和准备日志数据以衡量聊天机器人的理解能力
- en: Interpreting initial log data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释初始日志数据
- en: A good chatbot experience is generally associated with the chatbot identifying
    (understanding) what the user wants. This is one of the key metrics you will use
    to measure performance. Sometimes a chatbot is deployed and has great initial
    understanding (or at least “good enough” for a pilot program). Over time, though,
    you may notice that it is returning wrong answers. Maybe your users are complaining
    more, either directly to the chatbot (“That doesn’t answer my question!”) or in
    the form of survey responses. Engagement could be trending downward while abandonment
    trends upward. You may start hearing from the call center about escalations that
    should have been handled in the virtual assistant. These are all indications that
    your conversational solution might be suffering from weak understanding.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一款好的聊天机器人体验通常与聊天机器人能够识别（理解）用户需求相关。这是您将用来衡量性能的关键指标之一。有时，聊天机器人部署后，其初始理解能力很强（或者至少对于试点项目来说“足够好”）。然而，随着时间的推移，您可能会注意到它返回了错误的答案。也许您的用户开始更多地抱怨，无论是直接向聊天机器人（“这没有回答我的问题！”）还是通过调查反馈。参与度可能呈下降趋势，而放弃率可能呈上升趋势。您可能会从呼叫中心那里听到关于本应由虚拟助手处理的升级问题。这些都是您的对话解决方案可能存在理解能力薄弱的迹象。
- en: In theory, chatbots should get better over time, but it is not uncommon to see
    a decline in understanding. We want to help you recognize when and why this could
    be happening in your solution. We will explain how to avoid some of the pitfalls
    and plan for common eventualities in the lifecycle of your solution. In this chapter,
    we will explore what it means for your conversational AI to have “good performance”
    in terms of its ability to correctly identify or classify a user’s goal (i.e.,
    to understand the user). We will also offer techniques for preparing data for
    use in measuring a classifier’s performance or assessing generated responses.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，聊天机器人应该随着时间的推移而变得更好，但理解能力下降的情况并不少见。我们希望帮助您识别在您的解决方案中何时以及为什么会发生这种情况。我们将解释如何避免一些陷阱并规划解决方案生命周期中的常见情况。在本章中，我们将探讨您的对话人工智能在正确识别或分类用户目标（即理解用户）方面的“良好性能”意味着什么。我们还将提供用于测量分类器性能或评估生成响应的数据准备技术。
- en: 4.1 Fundamentals of understanding
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 理解的基础
- en: Being understood is a fundamental aspect of human communication. In a conversational
    AI, we use natural language processing techniques to try to understand what our
    user wants or needs. Because the scope of things a user could want is nearly infinite,
    and the way they might combine words to express those wants or needs is also infinite,
    this is a very difficult problem to solve.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 被理解是人类交流的基本方面。在对话人工智能中，我们使用自然语言处理技术来尝试理解用户想要或需要什么。由于用户可能想要的事情的范围几乎是无限的，以及他们可能用词语组合来表达这些愿望或需求的方式也是无限的，因此这是一个非常难以解决的问题。
- en: 4.1.1 The impact of weak understanding
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.1 理解能力薄弱的影响
- en: Not being understood by a chatbot is probably the biggest source of frustration
    for a user. They came to your chatbot to get answers, and they may get an answer,
    but it may have nothing to do with their question. Perhaps the chatbot instructed
    them to rephrase their question, so they come up with different words to express
    the same goal. Sometimes this works, and other times they get a response asking
    them to rephrase (again!). Oftentimes, as in figure 4.1, your users will end up
    asking for an agent after one or two failures.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 被聊天机器人不理解可能是用户最大的挫折来源。他们来到您的聊天机器人是为了获取答案，他们可能得到了答案，但这可能与他们的问题无关。也许聊天机器人指示他们重新措辞问题，所以他们用不同的词语来表达相同的目标。有时这有效，有时他们会收到要求他们重新措辞（再次！）的响应。通常情况下，如图4.1所示，您的用户在失败一两次后最终会要求与代理交谈。
- en: '![figure](../Images/CH04_F01_Freed2.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F01_Freed2.png)'
- en: Figure 4.1 Accuracy or coverage problems frustrate the user because it takes
    more time—and sometimes multiple contacts—to achieve their goal. It also causes
    the user to lose confidence in the virtual agent.
  id: totrans-14
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.1 准确性或覆盖问题会使用户感到沮丧，因为这需要更多的时间——有时需要多次联系才能达到他们的目标。这也导致用户对虚拟代理失去信心。
- en: If this is happening to your users, your chatbot most likely has a problem with
    *accuracy* (the chatbot’s ability to match what it heard against what it knows),
    *coverage* (the range of topics that your solution is expected to know about),
    or both. From the outside, it is impossible to tell which is the underlying root
    cause. For that, you are going to need to collect data. Without that information,
    it is difficult to know what to fix—and fixing the wrong thing can obfuscate or
    compound existing problems. Before you know it, your conversational solution becomes
    costly and difficult to maintain. Worse still, it is not delivering the value
    it promised (by failing to reduce, or perhaps even increasing, the need for human
    intervention).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这种情况发生在您的用户身上，您的聊天机器人很可能存在**准确性**（聊天机器人匹配所听到的内容与所知道的内容的能力）、**覆盖范围**（解决方案预期了解的主题范围）或两者兼而有之的问题。从外部来看，几乎无法判断根本原因是什么。为此，您需要收集数据。没有这些信息，很难知道要修复什么——修复错误的事情可能会使现有问题更加复杂。很快，您的对话解决方案就会变得昂贵且难以维护。更糟糕的是，它没有提供它承诺的价值（未能减少，甚至可能增加，对人工干预的需求）。
- en: One of the biggest success factors for a chat solution is how an organization
    approaches the ongoing maintenance of the solution. Ideally, the project sponsor
    and support team will have set the expectation that the solution needs iterative
    improvements—especially in the beginning—as it is exposed to more data from real-world
    users. Despite advances in autolearning, large language models, and generative
    AI, chatbots don’t tend to magically get better over time.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天解决方案最大的成功因素之一是组织如何处理解决方案的持续维护。理想情况下，项目发起人和支持团队将设定预期，即解决方案需要迭代改进——尤其是在开始时——因为它会接触到来自现实世界用户的更多数据。尽管自动学习、大型语言模型和生成式AI取得了进展，但聊天机器人并不倾向于随着时间的推移而神奇地变得更好。
- en: Expect to commit support resources throughout the bot’s lifecycle
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 预计在整个聊天机器人的生命周期内投入支持资源
- en: Does the organization feel that a chatbot should be a “set it and forget it”
    solution? Is there a lack of commitment to the ongoing care and feeding of the
    virtual assistant? These are the red flags of neglect, and they pretty much guarantee
    eventual failure.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 组织是否认为聊天机器人应该是一个“设置后即可忘记”的解决方案？是否存在对虚拟助手持续维护和喂养的缺乏承诺？这些都是忽视的红旗，几乎可以保证最终会失败。
- en: A chatbot is essentially a digital employee. Much like a human resource, it
    requires initial training plus occasional retraining, reinforcement, and the opportunity
    to acquire new skills.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人本质上是一个数字员工。就像人力资源一样，它需要初始培训以及偶尔的再培训、强化和获得新技能的机会。
- en: 4.1.2 What causes weak understanding?
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.2 弱理解的原因是什么？
- en: 'These are the most common reasons a chatbot will exhibit a decline in understanding:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是聊天机器人理解能力下降最常见的原因：
- en: Manufactured training data (trained examples that do not reflect a representative
    user’s vocabulary)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制造的训练数据（不反映代表性用户词汇的训练示例）
- en: Insufficient scope or gaps in topic coverage
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 范围不足或主题覆盖范围存在差距
- en: New information in the world that is not passed on to the virtual assistant
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 世界上新信息未传递给虚拟助手
- en: Lack of a vetting or gatekeeping process when adding new intents, updating existing
    intents, or changing model inference parameters
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在添加新意图、更新现有意图或更改模型推理参数时缺乏审查或守门人流程
- en: That last point—lack of a gatekeeping process—results in the types of weak understanding
    problems that are the most difficult to resolve. Without oversight by a knowledgeable
    owner or a dedicated model-training team, unvetted changes can quickly compound
    the problem of weak understanding. In traditional classifiers, model updates made
    by someone who is not familiar with the entire training set often introduce duplications,
    intent training conflicts, and unjustified disparities in the volume of training
    examples across intents. Untested model parameter or prompt changes will cause
    unexpected behavior in a generative model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 那最后一个观点——缺乏守门人流程——导致了最难以解决的薄弱理解问题。如果没有知识渊博的所有者或专门的模型训练团队的监督，未经审查的更改会迅速加剧薄弱理解的问题。在传统的分类器中，不熟悉整个训练集的人所做的模型更新往往会引入重复、意图训练冲突以及在意图之间训练示例数量的不合理差异。未经测试的模型参数或提示更改会在生成模型中引起意外的行为。
- en: In fact, we saw this happen with a client who had been making changes to their
    classifier training set, growing the total intents from 21 to 53 over the course
    of nine production deployments. The business did not see an effect right away;
    rather, over time the result of these untested changes manifested as poor survey
    results, incomplete journeys, unnecessary escalations, and lots of negative feedback.
    Subject matter experts reported that the bot was giving wrong answers for questions
    that it used to get right. These are classic symptoms of weak understanding, but
    they could not pinpoint exactly when it all started. A series of retroactive experiments
    against their prior versions told the story, which is shown in figure 4.2.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们看到了一个客户在修改他们的分类器训练集时发生的情况，在九次生产部署过程中，总意图从21增长到53。业务并没有立即看到效果；相反，随着时间的推移，这些未经测试的更改的结果表现为调查结果不佳、旅程不完整、不必要的升级和大量的负面反馈。主题专家报告说，机器人对于它曾经回答正确的问题现在给出了错误的答案。这些都是理解薄弱的经典症状，但他们无法确切指出这一切是从何时开始的。一系列针对他们先前版本的逆向实验讲述了这个故事，如图4.2所示。
- en: '![figure](../Images/CH04_F02_Freed2.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F02_Freed2.png)'
- en: Figure 4.2 A retroactive assessment of classifier performance shows a hard-won
    lesson on the effect of untested changes over time. Had each version been tested
    as part of a predeployment process, the team would have postponed any version
    updates until the classifier problems were resolved. It took several weeks to
    get the classifier back into good working order.
  id: totrans-29
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.2对分类器性能的逆向评估显示了关于未经测试的更改随时间影响的艰难教训。如果每个版本都作为预部署过程的一部分进行测试，团队就会推迟任何版本更新，直到分类器问题得到解决。恢复分类器良好工作状态花费了数周时间。
- en: 4.1.3 How do we achieve understanding with traditional conversational AI?
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.3我们如何通过传统的对话式人工智能实现理解？
- en: Traditional (non-generative) conversational AI systems are taught by ingesting
    examples of user requests grouped by *intents*, sometimes referred to as *classifications*
    or *clusters*. Intents contain a variety of paraphrases that all express the same
    goal. Some systems also incorporate *entities*, which are like keywords that further
    refine the meaning or specifications of a request.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的（非生成式）对话式人工智能系统是通过摄入按意图分组（有时称为分类或聚类）的用户请求示例进行教学的。意图包含各种释义，它们都表达了相同的目标。一些系统还纳入了实体，这些实体就像关键词，进一步细化请求的意义或规格。
- en: The conversational logic is configured to identify an intent (or a combination
    of intent + entity) and take an action based on that identification. This action
    could be as simple as answering a question, or it could initiate a complex transactional
    exchange. Table 4.1 shows examples of intents, entities, and potential next steps
    in a conversational exchange.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对话逻辑被配置为识别意图（或意图+实体的组合）并根据该识别采取行动。这个行动可能只是回答一个问题，或者它可以启动一个复杂的交易性交流。表4.1显示了对话交流中意图、实体和可能的下一步的示例。
- en: Table 4.1 Example utterances may be handled differently based on the presence
    or absence of entities.
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.1示例话语可能根据实体的存在与否而有所不同。
- en: '| Utterance | Intent | Entity | Possible next step |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 话语 | 意图 | 实体 | 可能的下一步 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| “How many bags can I check?”  | `Bag_Allowance`  |  | Display bag check policy  |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| “我能检查多少件行李？” | `Bag_Allowance` |  | 显示行李检查政策 |'
- en: '| “I want to book a flight”  | `Book_Flight`  |  | Collect destination  |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| “我想预订一张机票” | `Book_Flight` |  | 收集目的地 |'
- en: '| “I need a one-way ticket to Costa Rica”  | `Book_Flight`  | Costa Rica  |
    Collect departure details  |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| “我需要一张单程机票去哥斯达黎加” | `Book_Flight` | 哥斯达黎加 | 收集出发详情 |'
- en: '| “I’d like to upgrade my seat to first class”  | `Flight_Upgrade`  | first
    class  | Initiate upgrade process  |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| “我想升级我的座位到头等舱” | `Flight_Upgrade` | 头等舱 | 启动升级流程 |'
- en: The types of bots that use traditional classification technology tend to be
    topic routing agents, question/answer (FAQ) bots, and, to some extent, process-oriented
    (self-service) assistants. Keep in mind that classification-based bots rely on
    a predefined set of question topics (intents). You need to know in advance what
    questions you expect your bot to encounter.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用传统分类技术的机器人类型通常是主题路由代理、问答（FAQ）机器人，以及在某种程度上以流程为导向（自助）助手。请记住，基于分类的机器人依赖于一组预定义的问题主题（意图）。你需要提前知道你期望你的机器人遇到哪些问题。
- en: As a matter of practicality, the range of topics or intents that you teach your
    system will be specific to your domain and your solution’s use case or purpose.
    As solution owners, one of our primary and ongoing tasks is to tune our system
    to correctly understand the greatest volume of user demands. Finding the ideal
    balance between topic breadth and topic depth can be difficult and often involves
    tradeoffs. For example, it is not cost effective to train a classifier to understand
    every possible topic. Furthermore, attempting to do so can weaken its understanding
    of topics that are salient to your users.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际的角度来看，你教给系统的主题或意图的范围将特定于你的领域和解决方案的使用案例或目的。作为解决方案的所有者，我们的一项主要和持续的任务是调整我们的系统，以正确理解最大量的用户需求。在主题广度和深度之间找到理想的平衡可能很困难，通常需要权衡。例如，训练一个分类器以理解所有可能的主题并不经济。此外，试图这样做可能会削弱其对用户关注的主题的理解。
- en: When an organization tries to train a classifier to detect every possible topic,
    the classifier’s ability to see clear distinctions across all intents can be diminished.
    If the intents trained in your system aren’t representative of user demand (meaning
    you have a large number of low-volume topics), they tend to cause problems with
    accuracy and confidence. Figure 4.3 illustrates a “long tail” chart; the greatest
    business value for a classifier-based chatbot is typically realized by focusing
    on the high-to-moderate volume requests. Low-volume requests are typically handled
    by some sort of fallback mechanism, such as escalation, search, or generative
    AI.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个组织试图训练一个分类器以检测所有可能的主题时，分类器在所有意图中看到清晰区分的能力可能会减弱。如果你系统中训练的意图不能代表用户需求（意味着你有大量低频主题），它们往往会引起准确性和置信度方面的问题。图4.3展示了“长尾”图表；基于分类器的聊天机器人最大的商业价值通常是通过关注高至中频请求来实现的。低频请求通常由某种回退机制处理，例如升级、搜索或生成式AI。
- en: '![figure](../Images/CH04_F03_Freed2.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F03_Freed2.png)'
- en: Figure 4.3 As request volume tapers off to the right, the chart has the appearance
    of a long tail. Each use case must define the optimum tradeoff of depth and breadth
    as it relates to topic coverage. The cutoff point for business value is usually
    somewhere in the moderate-volume range. This is not to say that all low-volume
    requests should be excluded, but there may be diminishing returns associated with
    extending your classifier’s coverage for these topics.
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.3 随着请求量向右减少，图表呈现出长尾的形状。每个用例都必须定义与主题覆盖相关的深度和广度的最佳权衡。商业价值的截止点通常在中等频次范围内。这并不是说应该排除所有低频请求，但扩展你的分类器对这些主题的覆盖范围可能带来递减的回报。
- en: Prior to initial launch, you need to make some predictions about which topics
    will be most important for your bot to understand. These predictions are often
    based on logs from human interactions, call center metrics, focus groups, surveys,
    or other research or information-gathering activities. Your focus should be on
    training your model to be good at recognizing these requests, as well as any other
    ancillary conversational maintenance intents (such as greetings, chitchat, repeat,
    and escalate). Once your solution is in production, you’ll need to validate those
    predictions by collecting and analyzing data about your conversational interactions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始发布之前，你需要预测哪些主题对于你的机器人理解来说将是最重要的。这些预测通常基于人类交互的日志、呼叫中心指标、焦点小组、调查或其他研究或信息收集活动。你的重点应该是训练你的模型擅长识别这些请求，以及任何其他辅助对话维护意图（如问候、闲聊、重复和升级）。一旦你的解决方案投入生产，你需要通过收集和分析你的对话交互数据来验证这些预测。
- en: 4.1.4 How do we achieve understanding with generative AI?
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.4 我们如何使用生成式AI实现理解？
- en: How does a generative AI model achieve understanding? This is a trick question,
    because generative AI does not so much understand the meaning of an utterance
    as it creates new data that looks like the data it was trained on, using the utterance
    as a reference point. This is a nuanced distinction, but with generative AI, we
    try to simulate understanding by instructing a model to assess the input from
    a certain viewpoint and then generate a specific type of output.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型是如何实现理解的？这是一个陷阱问题，因为生成式AI并不是真正理解话语的意义，而是创建看起来像它所训练的数据的新数据，使用话语作为参考点。这是一个细微的区别，但使用生成式AI，我们试图通过指示模型从一个特定的观点评估输入，然后生成特定类型的输出来模拟理解。
- en: Particularly for conversational AI, our goal is to generate output that reflects
    or addresses the user’s request with specificity and/or personalization (not just
    a high-level categorization, such as topic classification or entity extraction).
    Figure 4.4 demonstrates the fundamental difference between classification model
    outputs and generative model outputs.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其对于对话式AI，我们的目标是生成反映或针对用户请求的具体和/或个性化的输出（而不仅仅是高级分类，如主题分类或实体提取）。图4.4展示了分类模型输出和生成模型输出之间的基本区别。
- en: '![figure](../Images/CH04_F04_Freed2.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F04_Freed2.png)'
- en: Figure 4.4 Traditional classification models use supervised learning to predict
    one of several predefined classifications. They look for the intent, or meaning,
    of a user input. Generative models use decoding transformers to create a text
    completion. They predict the next sequence of tokens (loosely, words or characters)
    that are most likely to occur after the user input.
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.4传统的分类模型使用监督学习来预测几个预定义分类中的一个。它们寻找用户输入的意图或含义。生成模型使用解码器变压器来创建文本补全。它们预测用户输入之后最有可能出现的下一个序列的标记（大致上，是单词或字符）。
- en: A quick note on LLM foundation architectures
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 关于LLM基础架构的简要说明
- en: '*Encoder-only* architectures are best for non-generative use cases, such as
    training predictive models based on text embeddings. They focus on extracting
    meaningful context from inputs and require labeled data for fine tuning.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*仅编码器*架构最适合非生成用例，例如基于文本嵌入训练预测模型。它们专注于从输入中提取有意义的内容，并需要标记数据进行微调。'
- en: '*Decoder-only* architectures are designed explicitly for generative AI use
    cases. They are “trained” in an unsupervised fashion by ingesting large amounts
    of data. They focus on predicting the next token in a sequence and can be instructed
    to perform specific tasks, including classification, question answering, and summarization.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*仅解码器*架构专门为生成AI用例设计。它们通过摄入大量数据以无监督方式“训练”。它们专注于预测序列中的下一个标记，并可以指示执行特定任务，包括分类、问答和摘要。'
- en: Some LLM model architectures are *encoder–decoder*, which means they can support
    both generative and non-generative uses cases. These are typically used in scenarios
    where the input is large, but the output is relatively small, such as translation
    or summarization.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一些LLM模型架构是*编码器-解码器*，这意味着它们可以支持生成和非生成用例。这些通常用于输入很大但输出相对较小的场景，如翻译或摘要。
- en: 'Unlike traditional classifier-based AI, there is no predefined list of intents
    that are “in-scope” for the generative model. But like traditional AI, you still
    need to have good command of the domain and of the range of problems your users
    are likely to bring to your bot. This will inform the strategies you employ that
    nudge your LLM to produce responses demonstrating that the user’s input was understood.
    There are several effective tools at your disposal to accomplish this:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于传统分类器的AI不同，生成模型没有预定义的意图列表，这些意图是“在范围内”的。但像传统AI一样，你仍然需要很好地掌握领域知识以及用户可能带到你的机器人那里的问题的范围。这将指导你采用的策略，以促使你的LLM产生响应，表明用户输入已被理解。你可以使用以下几种有效的工具来完成这项任务：
- en: '*Selecting the right model for the job*—Some models are more optimized for
    conversational output (as opposed to generating code or writing an essay or news
    article).'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*选择适合工作的正确模型*——一些模型更适合对话输出（而不是生成代码或撰写文章或新闻文章）。'
- en: '*Prompt engineering*—This technique supplies a model with inputs in order to
    produce optimal outputs. These inputs might include instructions, context, input
    data, and output indicators. Prompt engineering can often achieve a good simulation
    of understanding, and it can instruct the model to produce output in a conversational
    tone.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提示工程*——这种技术向模型提供输入以产生最佳输出。这些输入可能包括指令、上下文、输入数据和输出指示器。提示工程通常可以实现良好的理解模拟，并可以指示模型以对话风格产生输出。'
- en: '*One-shot or few-shot prompting*—You can enhance your prompt with one or more
    examples of the output and format you want the model to generate.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*单次或少量提示*——你可以通过一个或多个你希望模型生成的输出和格式的示例来增强你的提示。'
- en: '*Parameter tuning*—Parameters such as temperature, top-*p*, and top-*k* influence
    the randomness and diversity of the generated text. Increasing these values tends
    to increase the “creativity” in a generated response.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*参数调整*——温度、top-*p*和top-*k*等参数会影响生成文本的随机性和多样性。增加这些值通常会提高生成响应中的“创造力”。'
- en: '*Retrieval-augmented generation (RAG)*—RAG can enhance the perception that
    the bot understands while keeping the generated answer grounded in your domain.
    Many businesses employ RAG in their conversational solutions to ensure that the
    generated responses are based on external, verifiable facts and the latest information.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*检索增强生成（RAG）*——RAG可以增强机器人理解的感觉，同时保持生成的答案基于你的领域。许多企业在其对话式解决方案中使用RAG，以确保生成的响应基于外部、可验证的事实和最新信息。'
- en: At the time of writing, enterprise conversational solutions most often employ
    generative AI as question-answering (Q&A) bots. Most business-oriented chatbots
    that use this technology are not fully generative—they often employ a hybrid approach
    of classification (with predefined response pairs), task-oriented flows, and generated
    responses. Generated responses may be incorporated into the dialogue design, invoked
    as a fallback option (e.g., when classification fails to predict an intent with
    sufficient confidence), or both.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，企业对话式解决方案最常使用生成式AI作为问答（Q&A）机器人。大多数使用这项技术的面向商业的聊天机器人并不是完全生成式的——它们通常采用混合方法，包括分类（具有预定义的响应对）、面向任务的流程和生成响应。生成的响应可以纳入对话设计，作为后备选项（例如，当分类无法以足够的信心预测意图时）或两者兼而有之。
- en: Generative AI can also be used to enhance classification response outputs by
    inserting a personalized greeting or problem summary before delivering a “canned”
    (preconfigured) dialogue response or launching a task flow. Done well, this can
    engage a chatbot user on a deeper level, exhibiting “understanding” with empathy
    by acknowledging the user’s specific situation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI也可以通过在提供“预配置”（预先配置的）对话响应或启动任务流程之前插入个性化的问候或问题摘要来增强分类响应输出。做得好，这可以在更深的层面上吸引聊天机器人用户，通过承认用户的特定情况来表现出“理解”和同情。
- en: Exercises
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: 'Reflect on the solution you are currently building or supporting. Ask yourself
    these questions:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 反思你目前正在构建或支持的解决方案。问问自己这些问题：
- en: Is my solution exhibiting any symptoms of weak understanding, such as
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我的解决方案是否表现出任何弱理解的症状，例如
- en: Giving wrong answers, especially answers that are not relevant or are completely
    unrelated to the input topic
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给出错误的答案，尤其是与输入主题不相关或完全不相关的答案
- en: Taking the fallback/anything else/escalation routes more often than you would
    expect
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比预期更频繁地采取后备/其他/升级路线
- en: Disambiguating, or clarifying the topic, more often than you would expect on
    a seemingly straightforward request (for solutions that employ a disambiguation
    feature)
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在看似简单的请求中，比预期更频繁地进行去歧义或明确主题（对于采用去歧义功能的解决方案）
- en: Producing outdated or incorrect information
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产生过时或不正确的信息
- en: Receiving negative feedback or poor NPS scores
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收到负面反馈或较差的NPS评分
- en: How was my solution originally trained and tested? If it was deployed, was a
    baseline measurement taken?
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我的解决方案最初是如何进行训练和测试的？如果它已经被部署，是否进行了基线测量？
- en: Has the solution been updated to recognize new topics and produce answers that
    are accurate and current?
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解决方案是否已经更新以识别新的主题并产生准确和最新的答案？
- en: Who is allowed to make changes to the solution? Are these changes documented?
    Is the solution monitored after a change to ensure the change produces the intended
    effect?
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 谁被允许对解决方案进行修改？这些修改是否被记录？在修改后是否对解决方案进行了监控以确保修改产生了预期的效果？
- en: 4.2 How is understanding measured?
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 如何衡量理解？
- en: Understanding, for a chat solution, is typically measured in terms of accuracy.
    For a classifier, that means an ability to accurately predict the intent. For
    generative models, it is the ability to create correct and useful output. There
    are multiple methodologies and tools for measuring how well a solution understands
    user inputs. The approach you take will depend on which technologies your solution
    uses (traditional, generative, or both) and what phase you are currently in (predeployment
    or post).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于聊天解决方案，理解通常以准确性来衡量。对于分类器，这意味着能够准确预测意图。对于生成模型，这是创建正确和有用输出的能力。有多种方法和工具可以衡量解决方案理解用户输入的程度。你采取的方法将取决于你的解决方案使用的技术（传统、生成或两者兼有）以及你目前所处的阶段（预部署或已部署）。
- en: 4.2.1 Measuring understanding for traditional (classification-based) AI
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.1 衡量传统（基于分类）AI的理解
- en: Classifier performance is measured in terms of accuracy, precision, and recall.
    *Accuracy* is the percentage of correct predictions that were made. *Recall* refers
    to the classifier’s ability to identify the correct intent, while *precision*
    is the classifier’s ability to refrain from giving a wrong intent. Higher accuracy
    usually correlates to a perception of “good understanding.” A chatbot can’t deliver
    a predefined response or invoke the correct process-oriented flow if it does not
    understand the user’s intent.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的性能是通过准确率、精确率和召回率来衡量的。*准确率*是指正确预测的比例。*召回率*指的是分类器识别正确意图的能力，而*精确率*是指分类器避免给出错误意图的能力。较高的准确率通常与“良好的理解”感知相关联。如果聊天机器人不理解用户的意图，它就无法提供预定义的响应或调用正确的流程导向流程。
- en: You can assess your classifier’s performance using some data science techniques,
    such as *k*-fold cross validation or blind testing. *Blind testing* refers to
    the fact that a given test utterance does not already exist in the training set;
    i.e., the classifier has not “seen” the utterance before. Your test set may be
    manufactured, such as with AI-generated data, or representative (constructed from
    actual user utterances pulled from logs). *K*-fold and blind tests can provide
    information about your model’s overall accuracy, as well as report on its recall
    and precision. The metrics produced by such tests help identify where the model
    is performing well and where it might be confused. Chapter 5 contains detailed
    instructions for improving classifier understanding, so we will just give an overview
    of the testing approaches here.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用一些数据科学技术来评估分类器的性能，例如*k*折交叉验证或盲测试。*盲测试*指的是给定的测试话语在训练集中尚未存在；即，分类器之前没有“看到”这个话语。您的测试集可能是人工制造的，例如使用AI生成数据，或者具有代表性（从日志中提取的实际用户话语构建）。*k*折和盲测试可以提供有关模型整体准确性的信息，以及报告其召回率和精确率。此类测试产生的指标有助于确定模型表现良好的地方以及可能混淆的地方。第5章包含改进分类器理解的详细说明，因此我们在这里只概述测试方法。
- en: Measuring understanding with k-fold cross validation
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用k折交叉验证来衡量理解程度
- en: If your chatbot has not yet been deployed, a *k*-fold cross validation test
    is the easiest and most accessible method for measuring accuracy because it does
    not require additional annotated data. It uses only your existing training set.
    This method essentially measures the internal consistency of your data labeling—a
    high accuracy score mainly indicates that your training examples were grouped
    with other similar examples. The process involves pulling a percentage of data
    out of training, creating a temporary blind test set. The remaining data is used
    to create a temporary classifier. Next, each blind example is run against the
    classifier, and the predictions are scored. Finally, the temporary blind set is
    folded back into the training set. This process is iterated *k* times so that
    every example is used as a training example and as a test utterance, but never
    both at the same time.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的聊天机器人尚未部署，*k*折交叉验证测试是衡量准确率最简单、最易于访问的方法，因为它不需要额外的标注数据。它仅使用现有的训练集。这种方法本质上衡量的是您数据标注的内部一致性——高准确率分数主要表明您的训练示例与其他类似示例分组。该过程涉及从训练集中抽取一定比例的数据，创建一个临时的盲测试集。剩余的数据用于创建临时的分类器。接下来，每个盲示例都运行在分类器上，并对预测进行评分。最后，临时盲集被折叠回训练集中。这个过程重复*k*次，以便每个示例都用作训练示例和测试话语，但永远不会同时用作两者。
- en: A *k*-fold test will give you a prediction of the accuracy of your classifier,
    assuming the data you used to train your model is representative of the inputs
    your model will encounter when it is deployed to production. However, this can
    lead to a false sense of security, especially if your training data is highly
    manufactured or does not quite resemble actual user utterances. Another caveat
    is that small datasets can produce unreliable measurements if there isn’t enough
    data to withhold examples for testing while still training each intent with minimally
    sufficient examples. For these reasons, *k*-fold testing is not the preferred
    testing method once your solution is in production.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*折测试将为您提供分类器准确率的预测，假设您用于训练模型的数据代表模型在生产部署时将遇到的输入。然而，这可能导致一种虚假的安全感，尤其是如果您的训练数据高度人工制造或与实际用户话语不太相似。另一个注意事项是，如果数据不足以保留用于测试的示例，同时仍然用最小足够的示例训练每个意图，小型数据集可能会产生不可靠的测量结果。因此，一旦解决方案投入生产，*k*折测试不是首选的测试方法。'
- en: Measuring understanding with AI-generated blind test data
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用AI生成的盲测试数据衡量理解
- en: 'Obtaining test data through a generative process is done through the same means
    as obtaining generated training data: you prompt a model to generate variations
    of examples and use them as a “blind” test set. This method is best suited for
    predeployment but may also be appropriate in the early go-live phase to supplement
    gaps in your production logs.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过生成过程获取测试数据与获取生成的训练数据的方式相同：你提示模型生成示例的变体，并将它们用作“盲”测试集。这种方法最适合在部署前使用，但在上线初期阶段也可能适当，以补充生产日志中的空白。
- en: Like *k*-fold testing, the validity of your accuracy measurements is wholly
    dependent on whether the test data closely mirrors the inputs your model receives
    at production runtime. This approach can be vulnerable to bias and over-fitting.
    As such, we advise caution and suggest you validate your generated data against
    production logs as soon as they are available.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 与*k*-折测试一样，你的准确性测量的有效性完全取决于测试数据是否紧密地反映了模型在生产运行时接收的输入。这种方法可能容易受到偏差和过拟合的影响。因此，我们建议谨慎行事，并建议你一旦可用，就验证你的生成数据与生产日志。
- en: Measuring understanding with representative blind test data
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用代表性盲测试数据衡量理解
- en: If your chatbot has already been deployed, the production logs are one of your
    key tools for assessing your chatbot’s accuracy. These logs contain truly representative
    data about what your users ask for and how they phrase these requests. By “representative,”
    we mean both a realistic volume distribution of the intents triggered in your
    system as well as utterances that capture the user’s goal—in whatever combination
    of words comes naturally to them.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的聊天机器人已经部署，生产日志是评估聊天机器人准确性的关键工具之一。这些日志包含了关于用户提出的问题以及他们如何表述这些请求的真实代表性数据。当我们说“代表性”时，指的是系统触发意图的实际情况以及能够捕捉用户目标的表述——无论他们自然地使用什么样的词语组合。
- en: Using production logs will produce the least biased testing data, but it also
    requires a degree of upfront, manual effort. That effort does pay off, however,
    as you will have created a reusable asset for taking measurements of future changes.
    You’ll need to obtain a sample of these logs and review the customer inputs (utterances)
    against the intents returned by your system. This data will need to be annotated
    by a human who can identify the definitive correct (aka “golden”) intent that
    the utterance belongs to. Your initial annotations will give you a baseline accuracy.
    This data will then be used to build your *representative blind test set*, which
    is essentially a list of test questions and the answer key all in one file.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生产日志将产生最少的偏差测试数据，但也需要一定程度的初始手动努力。然而，这种努力是值得的，因为你将创建一个可重复使用的资产，用于测量未来的变化。你需要获取这些日志的样本，并对照系统返回的意图审查客户输入（表述）。这些数据需要由能够识别表述所属的最终正确（即“黄金”）意图的人类进行标注。你的初始标注将为你提供一个基线准确性。然后，这些数据将被用来构建你的*代表性盲测试集*，这实际上是一个包含测试问题和答案关键的所有内容都在一个文件中的列表。
- en: Selecting the best method for your situation
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 选择适合你情况的最佳方法
- en: 'The cost and effort tradeoffs for each method are entirely dependent on the
    size and current phase of your solution (predeployment or post):'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 每种方法的成本和努力之间的权衡完全取决于你解决方案的大小和当前阶段（部署前或部署后）：
- en: '*K*-fold cross validation may be seen as “cheap and easy” because it does not
    require human annotation beyond the task of the initial annotation done for training
    purposes. However, there may be an API cost to running your experiment *k* times.
    This cost is usually negligible for smaller systems but could result in thousands
    or tens of thousands of API calls per experiment for larger systems.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*K*-折交叉验证可能看起来“便宜且容易”，因为它不需要除训练目的之外的人工标注。然而，运行你的实验*k*次可能会有API成本。对于较小的系统，这种成本通常可以忽略不计，但对于较大的系统，每次实验可能会产生数千或数万次API调用。'
- en: Generated test datasets incur the cost of generating the data in addition to
    the API cost of running an experiment.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的测试数据集除了生成数据所需的成本外，还包括运行实验的API成本。
- en: A representative blind test set may have a lower API cost for running an experiment
    (compared to *k*-fold, assuming your test set is smaller than your training set),
    but the cost of human annotation can be significant. This also requires that the
    solution is in production, interacting with real users. The benefit is that the
    experiment results are going to be more meaningful than *k*-fold and generated
    test set results.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个代表性的盲测试集可能在运行实验时具有较低的API成本（与*k*-折相比，假设您的测试集小于您的训练集），但人工标注的成本可能很高。这也要求解决方案处于生产状态，与真实用户互动。好处是实验结果将比*k*-折和生成的测试集结果更有意义。
- en: In summary, there are three primary methods to measure your classifier’s ability
    to understand users. The method you choose should align with your current stage
    of development or deployment, as outlined in figure 4.5.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，有三种主要方法可以衡量您的分类器理解用户的能力。您选择的方法应与您当前的开发或部署阶段相一致，如图4.5所示。
- en: '![figure](../Images/CH04_F05_Freed2.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F05_Freed2.png)'
- en: Figure 4.5 *K*-fold cross validation and generated test data are suitable for
    situations where representative data is not available. Once a solution is deployed
    to production, representative blind test data will produce the most reliable measurement
    of your classifier’s ability to understand.
  id: totrans-95
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.5 *K*-折交叉验证和生成的测试数据适用于无法获取代表性数据的情况。一旦解决方案部署到生产环境，代表性的盲测试数据将产生对您的分类器理解能力的最可靠测量。
- en: 4.2.2 Measuring understanding for generative AI
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.2 测量生成式AI的理解能力
- en: 'Measuring whether a generated answer has demonstrated “good understanding”
    is an onerous task, and automated test approaches are still emerging. Our challenge
    is the nature of generative AI: every generated response is possible or likely
    to be unique to each user input.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 测量一个生成的答案是否展示了“良好的理解”是一项艰巨的任务，并且自动测试方法仍在不断发展。我们的挑战是生成式AI的本质：每个生成的响应都是可能的，或者很可能对每个用户输入都是独特的。
- en: 'Before you deploy a solution with generative AI, you should define what it
    looks like for your bot to demonstrate good understanding. For generative conversational
    AI, we suggest you define “good understanding” by the following dimensions:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在您部署带有生成式AI的解决方案之前，您应该定义您的机器人如何展示良好的理解。对于生成式对话AI，我们建议您通过以下维度定义“良好的理解”：
- en: The generated answer matches any specified output format or style, including
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的答案符合任何指定的输出格式或风格，包括
- en: Positioning of the bot (the purpose and viewpoint of the bot’s persona)
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人的定位（机器人角色的目的和视角）
- en: The designated tone and personality of the bot’s persona
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人角色的指定语气和个性
- en: The generated answer is appropriate for the user’s input in terms of content
    length and structure (for example, does the nature of the user input require a
    response that is a short answer, step-by-step instructions, or a detailed essay?).
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的答案在内容长度和结构上适合用户的输入（例如，用户输入的性质是否需要简短回答、逐步说明或详细论文？）。
- en: The generated answer is free from false information (hallucinations).
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的答案不包含虚假信息（幻觉）。
- en: The generated answer is free from hate, abuse, profanity, bias, and discrimination.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的答案不包含仇恨、滥用、粗俗、偏见和歧视。
- en: The generated answer is free from damaging information—even if true—such that
    a company would be legally liable or incur damage to their reputation (for example,
    negative commentary about a competitor or leaking sensitive data).
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的答案不包含有害信息——即使内容真实——这样一家公司可能会因法律责任或声誉受损（例如，对竞争对手的负面评论或泄露敏感数据）。
- en: The generated answer is resilient to prompt-injection attempts.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的答案对提示注入尝试具有抵抗力。
- en: The generated answer is correct and complete and either successfully terminates
    a flow or progresses the flow to a next step or the next best action.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的答案正确且完整，要么成功终止流程，要么推进流程到下一步或最佳下一步行动。
- en: If your solution has already been deployed, obtain a representative sample of
    your logs. Perform a manual review to assess your bot’s level of understanding.
    Each generated answer will be judged as correct, sufficient, or appropriate against
    the dimensions you have defined for the solution.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的解决方案已经部署，请获取您日志的代表样本。进行手动审查以评估您机器人的理解水平。每个生成的答案将根据您为解决方案定义的维度进行判断，判断其是否正确、充分或适当。
- en: This is, of course, time-consuming, but the effort will pay off. Your annotated
    set can be used as a golden test set for future improvements. This test set will
    give you a baseline for tracking the effect of changes to your model parameters
    (such as temperature, top *p*, top *k*) and other LLM configuration settings.
    These samples can also inform any few-shot examples (sample inputs paired with
    desired outputs) you include in your prompt engineering or fine-tuning.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这会耗费时间，但付出的努力将得到回报。你的注释集可以用作未来改进的黄金测试集。这个测试集将为你提供跟踪模型参数（如温度、top *p*、top *k*）和其他LLM配置设置变化影响的基准。这些样本还可以告知你在提示工程或微调中包含的任何少样本示例（样本输入与期望输出配对）。
- en: 4.2.3 Measuring understanding with direct user feedback
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.3 使用直接用户反馈衡量理解
- en: One way to measure good understanding at scale is to incorporate an answer feedback
    mechanism directly in the user experience, such as a thumbs up/down reply option.
    This method can be used for both traditional and generative solutions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一种在规模上衡量良好理解的方法是将答案反馈机制直接融入用户体验中，例如点赞/踩回复选项。这种方法可以用于传统和生成式解决方案。
- en: 'Be mindful of how often you solicit feedback, and know what purpose your feedback
    serves. Which aspect of the experience is the rating meant to reflect: satisfaction
    or dissatisfaction with a particular answer (for a question/answer use case),
    the self-serve process and its outcome (for a process-oriented bot), or the conversational
    experience as a whole?'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意你征求反馈的频率，并了解你的反馈有何目的。评分意在反映体验的哪个方面：对特定答案（针对问答用例）的满意或不满意，自助流程及其结果（针对流程导向型机器人），还是整体对话体验？
- en: Exercises
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: 'Explore and document your solution (or review and update it as needed), with
    emphasis on the components most responsible for demonstrating understanding:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 探索并记录你的解决方案（或根据需要审查和更新它），重点关注最负责展示理解的部分：
- en: For classifiers, this means auditing the training data.
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于分类器，这意味着审计训练数据。
- en: For solutions that include search and retrieval, audit the source documents
    or URLs, any supplemental document enrichments, and the ingestion schedule to
    ensure that your knowledge base contains the most relevant and up-to-date information.
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于包含搜索和检索的解决方案，审计源文档或URL、任何补充文档丰富化以及摄入计划，以确保你的知识库包含最相关和最新的信息。
- en: For generative AI solutions, audit the dialogue flows that invoke generated
    responses, and map the prompts, parameters, and LLM settings to their intended
    outcomes.
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于生成式AI解决方案，审计引发生成响应的对话流程，并将提示、参数和LLM设置映射到预期结果。
- en: Reflect on your current test methodologies, if any. Do you have any historical
    test metrics that can be correlated to current symptoms of weak understanding?
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 反思你当前的测试方法，如果有。你是否有任何可以与当前理解薄弱症状相关的历史测试指标？
- en: Think about the test methodologies presented in this section. Which approach
    is optimal for the current phase of your solution lifecycle?
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 思考本节中提出的测试方法。哪种方法对你的解决方案生命周期当前阶段最优化？
- en: 4.3 Assessing where you are today
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 评估当前状态
- en: Before you start making plans for improvements, you will want to perform an
    assessment of where the solution stands in terms of its ability to accurately
    identify the users’ goals and needs. The nature of your assessment will depend
    on which technology your solution uses. Classification and generative models perform
    very different functions and therefore have different aspects to be assessed.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始制定改进计划之前，你将想要评估解决方案在准确识别用户目标和需求方面的能力。你的评估性质将取决于你的解决方案使用的技术。分类和生成模型执行非常不同的功能，因此有不同的方面需要评估。
- en: 4.3.1 Assessing your traditional (classification-based) AI solution
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.1 评估你的传统（基于分类）AI解决方案
- en: 'For traditional AI, start by reviewing the training set to orient yourself
    to the domain and current scope:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于传统AI，首先审查训练集，以便了解领域和当前范围：
- en: How many classifiers are used in your solution?
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的解决方案中使用了多少个分类器？
- en: How many different intents does the system (or each classifier) handle?
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统或每个分类器处理了多少个不同的意图？
- en: How unique is each intent?
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个意图的独特性如何？
- en: Do the training examples in any intent seem to overlap with other intents?
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何意图的训练示例是否似乎与其他意图重叠？
- en: Does the range of topics (intents) align with your impression of the chatbot’s
    purpose?
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主题范围（意图）是否与你对聊天机器人目的的印象相符？
- en: How does the solution handle input it does not understand?
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决方案如何处理它不理解输入？
- en: What is the complexity of the dialogue? Are there complex flows, backend integrations,
    or search integrations?
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对话的复杂性如何？是否存在复杂的流程、后端集成或搜索集成？
- en: It can be helpful to visualize your classifier training data volume in chart
    form. Figure 4.6 shows an example training set. There isn’t a lot of information
    to be gleaned just yet, but this will give us a basis for comparison once we assemble
    our test data.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 将您的分类器训练数据量以图表形式可视化可能会有所帮助。图4.6显示了一个示例训练集。目前还没有太多信息可以提取，但当我们组装测试数据时，这将为我们提供一个比较的基础。
- en: '![figure](../Images/CH04_F06_Freed2.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F06_Freed2.png)'
- en: Figure 4.6 This classifier has 13 intents. The training example counts range
    from 7 to 30.
  id: totrans-133
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.6 该分类器有13个意图。训练示例数量从7到30不等。
- en: In general, we expect our intents with higher counts of training examples to
    be more popular. We want our most popular topics to be understood a majority of
    the time. Higher-volume intents may also represent topics that handle a greater
    variety of phrases. For the most part, we don’t like to see a huge disparity in
    volumes across the training set. For instance, a training set that has some intents
    trained with hundreds of examples while others have just a handful might exhibit
    performance problems such as over-selection (frequently selecting a wrong intent
    due to the bias of training volume).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们期望具有更多训练示例的意图更受欢迎。我们希望最受欢迎的主题在大多数时候都能被理解。高容量的意图也可能代表处理更多样化短语的议题。在大多数情况下，我们不希望看到训练集中存在巨大的容量差异。例如，一个训练集中有些意图使用了数百个示例，而其他意图只有少数几个示例，可能会表现出性能问题，如过度选择（由于训练容量的偏差，频繁选择错误意图）。
- en: 4.3.2 Assessing your generative AI solution
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.2 评估您的生成式AI解决方案
- en: 'With generative AI, as in traditional AI, you need to understand the domain
    and scope your bot operates within. However, instead of concerning yourself with
    classifications of input, you need to appraise the data sources that your model
    will draw its answers from when it produces an output. Is generative AI used to
    produce answers or responses in your solution? If so, familiarize yourself with
    the circumstances:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式AI方面，就像在传统AI中一样，您需要了解您的机器人操作的领域和范围。然而，您不需要关注输入的分类，而需要评估当模型产生输出时，它将从哪些数据源中抽取答案。在您的解决方案中，生成式AI是否用于生成答案或响应？如果是，熟悉以下情况：
- en: Are answers generated for every user input?
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否为每个用户输入生成答案？
- en: Do you call for generated answers as a fallback option for your classifier?
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您是否将生成答案作为分类器的后备选项？
- en: Do you call for generated text to supplement a classification-based “canned”
    answer in the dialogue?
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您是否在对话中调用生成文本来补充基于分类的“预定义”答案？
- en: Does your solution make use of more than one LLM, such as different models for
    different types of responses, multiple language support, etc.?
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的解决方案是否使用了不止一个大型语言模型（LLM），例如针对不同类型响应的不同模型、多语言支持等？
- en: Does your solution make use of prompt engineering, prompt tuning, fine tuning,
    or other customized settings? Is this documented anywhere, along with the outcome
    goals for which each setting was originally implemented?
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的解决方案是否使用了提示工程、提示调整、微调或其他定制设置？这些是否记录在案，以及每个设置最初实施的目标成果？
- en: Does your solution make use of RAG? If so, what is that data source? How often
    is it updated? Does it contain additional data enrichments?
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的解决方案是否使用了RAG？如果是，数据源是什么？它多久更新一次？它是否包含额外的数据丰富？
- en: Exercises
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: Assess your solution using the criteria we described in this section (according
    to the type of AI you use).
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用本节中描述的标准（根据您使用的AI类型）评估您的解决方案。
- en: Once you have performed your initial solution assessment, be sure to document
    its current state—this will be your baseline system configuration.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您完成初始解决方案评估后，务必记录其当前状态——这将成为您的基线系统配置。
- en: As you follow along with the improvement recommendations and examples given
    throughout this book, be prepared to record your changes in a way that will help
    you correlate any updates you make to the subsequent performance measurements.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随着您跟随本书中给出的改进建议和示例，请准备好以有助于您将所做的任何更新与后续的性能测量相关联的方式记录您的更改。
- en: 4.4 Obtaining and preparing test data from logs
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 从日志中获取和准备测试数据
- en: For the rest of this chapter, we’ll assume that you do have a production system
    and access to the logs. We will show you how to obtain and prepare that data to
    create an asset you can use to measure the current state (and to validate future
    changes).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分，我们将假设你确实有一个生产系统并可以访问日志。我们将向你展示如何获取和准备这些数据，以创建一个可以用来衡量当前状态（以及验证未来变化）的资产。
- en: There’s a bit of initial work involved to build a test set from production logs.
    Figure 4.7 shows the major tasks involved in preparing data for testing (or training).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 从生产日志中构建测试集需要一些初始工作。图4.7显示了准备测试数据（或训练数据）所涉及的主要任务。
- en: '![figure](../Images/CH04_F07_Freed2.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F07_Freed2.png)'
- en: Figure 4.7 Once you obtain some data, each utterance should first be sorted
    into buckets to identify potential candidates; this will separate the good, usable
    test data from the bad or irrelevant user inputs. The data may also need to be
    scrubbed to fix problems like personal identifiable information (PII). After that,
    the data will need to be annotated (for classifiers, it will need to be labeled
    with the correct intent; for generative AI, it will need to be associated with
    an ideal output response). Finally, the data will need to be converted into one
    or more sets that can be consumed by your testing tool.
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.7 一旦你获得了一些数据，每个发言首先应该被分类到不同的桶中，以识别潜在的候选者；这将把好的、可用的测试数据与差的或无关的用户输入分开。数据可能还需要被清理，以修复如个人可识别信息（PII）等问题。之后，数据需要被标注（对于分类器，它需要用正确的意图进行标记；对于生成式AI，它需要与理想的输出响应相关联）。最后，数据需要被转换成一个或多个可以被你的测试工具消费的集合。
- en: 4.4.1 Obtaining production logs
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.1 获取生产日志
- en: Ideally, you will have access to production logs that span a full year or more.
    This will help ensure that your test set will have a true representative sample
    of the range of topics your bot encounters for the various seasons and events
    that influence your industry. Collect log samples from various weeks or months
    throughout the year. If your solution is newer, expect to refresh your test sets
    more frequently during your solution’s first 12 to 18 months.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，你将能够访问跨越一整年或更长时间的生产日志。这将有助于确保你的测试集将有一个真正代表性的样本，涵盖你的机器人可能遇到的各类主题范围，以及影响你行业的各种季节性和事件。从一年中的不同周或月收集日志样本。如果你的解决方案较新，预期在解决方案的前12到18个月内，你需要更频繁地刷新测试集。
- en: Once you have obtained some production logs, you may find it easiest to convert
    this data into a CSV or Excel file (if it hasn’t already been updated). We find
    it most useful to transform the data into one row per conversational exchange
    (a user input and a bot output), grouped by conversation ID. Depending on the
    timeframe you select, the volume of users, and the complexity and purpose of your
    solution, your file may have just a few hundred rows of data, or it could have
    100,000 rows or more of conversational exchanges.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你获得了某些生产日志，你可能发现将此数据转换为CSV或Excel文件（如果尚未更新）是最容易的（如果它尚未更新）。我们发现将数据转换为每条对话交换一行（一个用户输入和一个机器人输出），按对话ID分组，非常有用。根据你选择的时段、用户数量、解决方案的复杂性和目的，你的文件可能只有几百行数据，或者可能有1万行或更多的对话交换。
- en: One simple shortcut for reducing the volume to a manageable set is to select
    the first user utterance in each conversation. This may not work in all cases,
    but figure 4.8 shows that it is often a reliable way to harvest useful data from
    your logs. In a natural language-driven exchange, users tend to express their
    most important need in the initial input. If your average conversation lasts ten
    turns, a conversation log with 100,000 rows of raw data could be reduced to about
    10,000 rows of data to review. Deduplication can often further reduce this by
    a few thousand. This is a very workable volume and will usually contain rich and
    diverse examples that you can use for testing your solution.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 将对话音量减少到可管理的集合的一个简单快捷方法是选择每次对话中的第一个用户发言。这可能在所有情况下都不适用，但图4.8显示，这通常是收集日志中有用数据的一种可靠方法。在自然语言驱动的交流中，用户往往会在初始输入中表达他们最重要的需求。如果你的平均对话持续十个回合，一个包含10万行原始数据的对话日志可以减少到大约1万行数据供审查。去重通常可以进一步减少几千行。这是一个非常实用的音量，通常包含丰富多样的例子，你可以用它们来测试你的解决方案。
- en: '![figure](../Images/CH04_F08_Freed2.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F08_Freed2.png)'
- en: Figure 4.8 Raw chat logs show that a user’s primary goal is often captured in
    the first turn of a conversation, but sometimes it occurs as an additional request
    later in the conversation or after exchanging a pleasantry. It might even follow
    an opt-out request. Selecting the first row will usually yield enough usable data
    while reducing the amount of time your annotators spend sorting through the utterances
    that aren’t useful to the classifier, such as button clicks, common responses,
    and PII or other user-specific information. (The structure of your logs may vary
    by tool.)
  id: totrans-157
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.8原始聊天日志显示，用户的初始目标通常在对话的第一轮中被捕捉到，但有时它会在对话的后期或交换了礼貌用语后作为一个额外的请求出现。它甚至可能跟随一个退出请求。选择第一行通常会提供足够的数据，同时减少你的注释员在分类器无用的表述中（如按钮点击、常见回复、PII或其他用户特定信息）进行排序所花费的时间。（你的日志结构可能因工具而异。）
- en: 4.4.2 Guidelines for identifying candidate test utterances
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.2 确定候选测试表述的指南
- en: 'Whatever you do to obtain and preprocess your logs, your next task is to identify
    potential blind test candidates. We treat this as a “first pass” exercise: just
    determine if an utterance is *potentially* usable. Additionally, we counsel the
    reviewers not to over-analyze what they see; if you cannot make a determination
    about any given utterance within a minute or so, discard the utterance and move
    on. (If you’re feeling really conflicted or sense a pattern, mark it for later
    review and move on.) We use the following criteria to identify potential test
    candidates from production logs, along with any special handling instructions:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你如何获取和预处理日志，你的下一个任务是确定潜在的盲测试候选者。我们将此视为“初步筛选”练习：只需确定一个表述是否*可能*可用。此外，我们建议审稿人不要过度分析他们看到的内容；如果你在一分钟内无法对任何给定的表述做出判断，请丢弃该表述并继续。
    （如果你感到非常矛盾或感觉到某种模式，请将其标记为稍后审查并继续。）我们使用以下标准从生产日志中识别潜在的测试候选者，以及任何特殊处理说明：
- en: Is the utterance unintelligible?
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表述是否无法理解？
- en: Is the utterance completely unrelated to the domain?
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个表述与领域完全无关吗？
- en: Is the utterance ambiguous?
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表述是否含糊不清？
- en: Does the utterance contain multiple intents?
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表述是否包含多个意图？
- en: Is the utterance related to the domain but out of scope?
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表述与领域相关但超出范围吗？
- en: Does the utterance express a goal that is in domain and in scope?
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个表述是否表达了在领域和范围内的目标？
- en: Let’s look at each of these in turn.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一查看这些内容。
- en: Is the utterance unintelligible?
  id: totrans-167
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 表述是否无法理解？
- en: Maybe a cat walked across the keyboard, or the user just mashed the keys in
    a fit of frustration. Perhaps the speech-to-text technology mistranscribed the
    caller’s question into an unintelligible mess. Speech solutions can also pick
    up background noise and conversations, especially if they are not properly tuned
    for the environment. Your file may contain a number of user inputs that just don’t
    make any sense.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 可能是猫走过了键盘，或者用户在愤怒中乱按键盘。也许语音到文本技术将呼叫者的提问转录成了无法理解的混乱。语音解决方案也可能捕捉到背景噪音和对话，尤其是如果它们没有为环境正确调优。你的文件可能包含许多用户输入，这些输入根本没有任何意义。
- en: 'These are examples of unintelligible or unrelated utterances:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是不理解或不相关的表述的例子：
- en: “does it school” (Incoherent—if this came from a voice solution, it was potentially
    a speech mistranscription.)
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “does it school”（不连贯——如果这是来自语音解决方案的，可能是语音转录错误。）
- en: “she didn’t she said there are four and only gave us one yes you can do that
    I’m about to catch my flight and I’ll check on it when I get to the office” (Potentially
    a speech transcription of a background conversation on the caller side.)
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “她没有她说有四个只给了我们一个是的你可以那样做我马上要赶飞机了等我到办公室我会检查的”（可能是呼叫方背景对话的语音转录。）
- en: “klewtkhaccalifornia liense” (Likely typos, severe enough to render the utterance
    unintelligible.)
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “klewtkhaccalifornia liense”（可能是拼写错误，严重到使表述无法理解。）
- en: These lines can be excluded from your blind test set. Any recognizable patterns,
    such as possible speech transcription problems, should be set aside for further
    evaluation or forwarded to the appropriate team.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这些行可以从你的盲测试集中排除。任何可识别的模式，如可能的语音转录问题，应留待进一步评估或转发给适当的团队。
- en: Is the utterance completely unrelated to the domain?
  id: totrans-174
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 表述与领域完全无关吗？
- en: You may occasionally come across questions that are intelligible but entirely
    off-topic for the domain or the bot’s intended purpose. For example, if your solution
    is designed to help electric utility customers manage their account and services,
    you can exclude questions about pop culture trivia if they happen to appear in
    the logs.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会偶尔遇到一些可以理解但与领域或机器人预期目的完全不相关的问题。例如，如果你的解决方案旨在帮助电力公司客户管理他们的账户和服务，那么如果这些关于流行文化琐事的问题出现在日志中，你可以排除这些问题。
- en: Though you could configure a solution to send unrecognized topics to an LLM,
    these utterances do not belong in your classifier test set because a golden intent
    cannot be assigned. Such utterances could be used in negative testing, which will
    help you understand if your solution is appropriately identifying when it should
    *not* attempt to answer.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管您可以配置解决方案将未识别的主题发送到LLM，但这些语句不属于您的分类器测试集，因为无法分配一个黄金意图。这些语句可用于负面测试，这有助于您了解您的解决方案是否适当地识别了它不应该尝试回答的情况。
- en: Is the utterance ambiguous?
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 这个语句是否模糊？
- en: Perhaps you’ll find a single word or a short phrase that is related to the domain
    but doesn’t express a clear goal. For example, if a user of a banking chatbot
    simply says, “account,” what do they want? Do they want to open an account? Close
    an account? Check an account balance? Who knows?
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 可能你会找到一个与领域相关但未表达明确目标的单个单词或短语。例如，如果一个银行聊天机器人的用户只是说“账户”，他们想要做什么？他们是想要开设账户？关闭账户？检查账户余额？谁知道呢？
- en: A subset of ambiguous utterances may include responses generated by a button
    click or as part of an information-gathering flow. (If you selected the first
    natural language utterance of every conversation, you might not see these.) These
    are generally not useful for the classifier’s performance testing unless they
    align with an intent that is used within a flow. Include such utterances only
    when appropriate.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊语句的子集可能包括由按钮点击或作为信息收集流程的一部分生成的响应。（如果你选择了每次对话的第一个自然语言语句，你可能看不到这些。）这些通常对分类器性能测试没有太大帮助，除非它们与流程中使用的意图相一致。只有在适当的时候才包括这样的语句。
- en: 'These are examples of ambiguous utterances:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是模糊语句的例子：
- en: “driver license” (Perhaps relevant to the domain, but no clear goal is expressed.)
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “驾照”（可能与领域相关，但没有表达明确的目标。）
- en: “that one” (An anaphor referring to contextual information that appears to have
    been provided in an earlier statement but may have lost its meaning as an individual
    utterance.)
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “那一个”（一个指代先前语句中提供但可能已失去意义的上下文信息的代词。）
- en: “2” (Could refer to a button choice or phone channel selection, or to an amount
    or quantity provided as a response to the previous question.)
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “2”（可能指按钮选择或电话渠道选择，或者是对上一个问题的响应中提供的数量或数量。）
- en: In most cases, these utterances should not be included in your classifier accuracy
    test because they likely will not align with any single intent, but rather multiple
    intents. They are not meaningless, however. Set these aside to understand how
    often your users communicate in this way. Determine whether your other chatbot
    features, such as disambiguation or clarifying questions, are handling them appropriately.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，这些语句不应包含在您的分类器准确度测试中，因为它们可能不会与任何单一意图相匹配，而是与多个意图。然而，它们并非没有意义。将这些语句放在一边，以了解您的用户以这种方式沟通的频率。确定您的其他聊天机器人功能，如消歧或澄清问题，是否适当处理了它们。
- en: Does the utterance contain multiple intents?
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 这个语句是否包含多个意图？
- en: Most classifier-based chatbots perform best when they are given one goal at
    a time. Utterances that express multiple valid, distinct goals should be excluded
    from your classifier accuracy test set because you cannot definitively assign
    a “correct” intent.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数基于分类器的聊天机器人在一次只给定一个目标时表现最佳。表达多个有效、不同目标的语句应排除在您的分类器准确度测试集之外，因为您无法明确分配一个“正确”的意图。
- en: The exception to this rule would be if your solution has a disambiguation mechanism.
    Disambiguation is a way to clarify the user’s primary goal by presenting the top
    *n* intents identified by a classifier. For these solutions, you may want to run
    your multi-intent utterances against your classifier to verify that all intents
    listed would be presented with the appropriate disambiguation choices.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这一规则的例外情况将是如果您的解决方案有一个消歧机制。消歧是通过展示分类器识别出的前*n*个意图来澄清用户的主要目标的方式。对于这些解决方案，您可能希望将您的多意图语句与您的分类器进行对比，以验证所有列出的意图都会以适当的消歧选择呈现。
- en: 'These are some examples of utterances with multiple intents:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是具有多个意图的表述示例：
- en: '“Do you have the COVID booster? How can I make an appointment?” (Two goals
    expressed: 1) availability of vaccine booster, 2) make an appointment.)'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “你有COVID加强针吗？我该如何预约？”（表达了两个目标：1）疫苗加强针的可用性，2）预约。）
- en: '“I want to update the address on my driver’s license and find out what is required
    to get a commercial driver’s license.” (Two goals expressed: 1) update address,
    2) get information for obtaining a CDL.)'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “我想更新我的驾照地址，并了解获得商用驾照所需的信息。”（表达了两个目标：1）更新地址，2）获取获得CDL所需的信息。）
- en: '“I currently have 95,000 loyalty points. Do they expire? How many more points
    do I need to reach Platinum status? Can I purchase points for this?” (Three goals
    expressed: 1) find out if reward points expire, 2) find out the delta between
    current point balance and next level reward status, 3) get information about purchasing
    points to reach a higher status.)'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “我目前有95,000个忠诚度积分。它们会过期吗？我还需要多少积分才能达到白金状态？我可以购买积分以提升到更高等级吗？”（表达了三个目标：1）了解奖励积分是否会过期，2）了解当前积分余额与下一等级奖励状态之间的差异，3）获取关于购买积分以提升到更高等级的信息。）
- en: '“I want to talk to an agent about reporting a stolen vehicle.” This is very
    common. A user will often pair a request for an agent along with their true goal.
    If both intents exist in your classifier training set, you can handle such utterances
    in one of two ways:'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “我想和客服人员谈谈关于报告被盗车辆的事情。”这种情况非常常见。用户通常会将与客服人员的请求和他们的真实目标结合起来。如果你的分类器训练集中存在这两个意图，你可以通过以下两种方式处理此类表述：
- en: Exclude these as candidates if it is impossible to label a single “correct”
    intent.
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果无法标记单个“正确”的意图，则将这些内容排除作为候选人。
- en: Include these candidates, but label them according to the “preferred” intent.
    (A preferred intent might be the self-service option if containment is a priority
    and the competing intent would escalate.)
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含这些候选人，但根据“首选”意图进行标记。（首选意图可能是如果控制是优先事项，那么竞争意图将会升级。）
- en: As with ambiguous utterances, these should be set aside and evaluated separately
    to better understand your users. You may want to devise additional strategies
    to handle these situations if they are occurring often. If users tend to ask related
    questions, or they pair common requests in a single utterance, your output responses
    in these intents could be updated to anticipate or meet all of the needs. For
    the first example we gave—“Do you have the COVID booster? How can I make an appointment?”—your
    answer regarding booster availability may include a link to make an appointment.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 与模糊表述一样，这些表述应该单独放置并分别评估，以更好地了解你的用户。如果你发现这些情况经常发生，你可能需要制定额外的策略来处理这些情况。如果用户倾向于提出相关问题，或者他们在单个表述中结合了常见的请求，那么在这些意图中的输出响应可以更新，以预测或满足所有需求。对于我们给出的第一个例子——“你有COVID加强针吗？我该如何预约？”——你的关于加强针可用性的回答可能包括一个预约链接。
- en: A word about handling multiple intents with classification models
  id: totrans-196
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 关于处理多个意图的分类模型的注意事项
- en: 'We have seen extensive and heroic attempts to handle multiple intents programmatically
    in conversational AI solutions. This usually involves logic to collect the top
    *n* intents and store them in context, and then more logic to present the additional
    topics after the first one is answered. In most cases, the result is an over-engineered
    solution that is brittle, difficult to scale, or simply wasted effort. This approach
    also has a major flaw: such logic cannot reliably distinguish between an utterance
    that truly contains multiple goals and an utterance that contains a single goal
    that may have triggered multiple intents.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了在对话式人工智能解决方案中处理多个意图的广泛和英勇的尝试。这通常涉及收集前*n*个意图并将它们存储在上下文中，然后是更多的逻辑来在回答第一个意图之后呈现附加主题。在大多数情况下，结果是过度设计的解决方案，它脆弱、难以扩展，或者只是浪费了努力。这种方法也存在一个主要缺陷：这样的逻辑无法可靠地区分一个真正包含多个目标的表述和一个包含可能触发多个意图的单个目标的表述。
- en: 'Many modern chatbot frameworks provide automated topic disambiguation (for
    example, “Did you mean: [Intent 1] [Intent 2] [Intent 3]”). Our general recommendation
    is to allow the disambiguation feature to do its job. Sometimes, this means that
    the user must ask their questions or state their goals one at a time. The frequency
    and importance of such scenarios is usually not worth the effort required to build
    and maintain custom logic for handling multiple intents in a classification-based
    chatbot.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 许多现代聊天机器人框架提供自动化的主题消歧（例如，“你是指：[意图1] [意图2] [意图3]”）。我们的总体建议是允许消歧功能完成其工作。有时，这意味着用户必须一次提出一个问题或陈述一个目标。这种场景的频率和重要性通常不值得花费构建和维护处理多个意图的基于分类聊天机器人的自定义逻辑所需的努力。
- en: Generative AI is typically much better at handling multiple intents than classification-based
    solutions, so you can include these utterances as candidates in a test set if
    your solution has this capability.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI通常在处理多个意图方面比基于分类的解决方案要好得多，所以如果你的解决方案有这种能力，你可以将这些表述作为测试集的候选。
- en: Is the utterance related to the domain but out of scope?
  id: totrans-200
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 这个表述是否与领域相关但超出范围？
- en: You are likely to come across utterances that express a single, clear goal that
    is relevant to the domain, but the current solution is not equipped to handle
    them. For example, a banking chatbot may allow users to check an account balance
    but may not be trained to recognize requests about interest rates. An airline
    chatbot may be versed on airline policy but not be grounded in facts about airport
    security.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会遇到表达一个与领域相关的单一、明确目标的表述，但当前解决方案尚未配备处理这些的能力。例如，一个银行聊天机器人可能允许用户检查账户余额，但可能没有训练来识别关于利率的请求。一个航空公司聊天机器人可能对航空政策了如指掌，但可能没有关于机场安全的实际知识。
- en: Such questions may be very reasonable from the user’s perspective, and gaps
    in topic coverage often lead to frustration for your users. This is especially
    true if you don’t have a generative AI or search fallback. If your bot responds,
    “I’m sorry, I don’t understand. Please rephrase your question,” no amount of rephrasing
    will get the user to a satisfactory answer. How should these be handled?
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的问题可能从用户的角度来看非常合理，但主题覆盖的差距往往会导致用户感到沮丧。这尤其在你没有生成式AI或搜索回退的情况下更为明显。如果你的聊天机器人响应，“很抱歉，我不理解。请重新措辞你的问题”，无论怎样重新措辞都无法让用户得到满意的答案。这些应该如何处理？
- en: If your classifier does not have any trained intents to handle such requests,
    these should set aside. On further review, they may be grouped into topics or
    categories, but they will be excluded from your test set for now because a golden
    intent cannot be assigned. Monitor these topics for volume and add them to your
    improvement backlog as appropriate.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的分类器没有训练好的意图来处理此类请求，这些应该被暂时搁置。在进一步审查后，它们可能被分组到主题或类别中，但它们目前将不会包含在你的测试集中，因为无法分配黄金意图。根据适当的情况，监控这些主题的量并添加到你的改进待办事项中。
- en: Similarly, if your generative solution is not prepared to answer such questions
    (for example, the document repository in a RAG solution does not have content
    to address the topic), set these aside for the time being, but monitor the volume.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果你的生成式解决方案尚未准备好回答此类问题（例如，RAG解决方案中的文档库没有内容来处理该主题），暂时将这些内容搁置，但监控其量。
- en: Does the utterance express a goal that is in domain and in scope?
  id: totrans-205
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 这个表述是否表达了一个在领域和范围内的目标？
- en: Score! Questions or requests that are in scope for your solution and domain
    belong in your golden test set.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 得分！属于你的解决方案和领域范围内的提问或请求应属于你的黄金测试集。
- en: 4.4.3 Preparing and scrubbing data for use in iterative improvements
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.3 准备和清洗数据以用于迭代改进
- en: If you’ve never seen production logs for a chatbot, you will be surprised at
    how messy they are. You are going to see a lot of bad or informal grammar, misspelled
    words or typos (on a text-based channel), speech mistranscriptions (on a voice
    channel), and potentially various forms of personal identifiable information (PII).
    Here’s how we recommend handling these.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从未见过聊天机器人的生产日志，你可能会惊讶它们有多混乱。你将看到很多不良或非正式的语法、拼写错误或打字错误（在基于文本的渠道上）、语音误转录（在语音渠道上），以及可能的各种形式的个人信息（PII）。以下是我们推荐的处理方法。
- en: Bad or informal grammar
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 不良或非正式的语法
- en: For the most part, leave it be! There is a lot of diversity in how humans express
    themselves. The user may not know exactly how to communicate what they need—especially
    to a machine. If a goal can be identified, it is a representative example and
    should be generally preserved as is.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，让它保持原样！人类表达自己的方式有很多多样性。用户可能不知道如何准确传达他们的需求——尤其是向机器传达。如果可以识别出目标，它就是一个代表性的例子，应该保持原样。
- en: Typos and misspelled words
  id: totrans-211
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 错别字和拼写错误
- en: Unless a typo or misspelled word significantly changes the meaning of the overall
    phrase, leave it as is. Commonly misspelled words are representative of how your
    users communicate. Your classifier should be able to give a good answer whether
    the user asks, “What’s the difference between loan balance and principal?” or
    “whats teh diffrence between loan balance and principle?”
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 除非错别字或拼写错误显著改变了整个短语的含义，否则请保持原样。常见的拼写错误代表了您的用户是如何沟通的。您的分类器应该能够给出良好的答案，无论用户是询问“贷款余额和本金有什么区别？”还是“whats
    teh diffrence between loan balance and principle？”
- en: Proper case and punctuation are generally ignored by a classifier, but you may
    need to verify this with your technology platform.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的大小写和标点通常会被分类器忽略，但您可能需要与您的技术平台核实这一点。
- en: Speech mistranscriptions
  id: totrans-214
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 语音误转录
- en: If your solution uses speech-to-text (aka automated speech recognition), you
    won’t encounter typos, but you probably will see unexpected words that are most
    likely the result of a speech mistranscription. The first line of attack is to
    train your speech models, if possible. The underlying technology of a chatbot
    classifier is text-driven, so it is best to have the most faithful representation
    of the user’s utterance before it hits the text classifier.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的解决方案使用语音转文本（也称为自动语音识别），您不会遇到错别字，但您可能会看到意外的单词，这很可能是语音误转录的结果。首先的攻击方法是尽可能训练您的语音模型。聊天机器人分类器的底层技术是文本驱动的，因此在用户的话语触及文本分类器之前，最好有用户话语的最忠实表现。
- en: If you find that the speech models are still consistently mistranscribing words
    that are significant within your domain, include these in your test set (and ultimately,
    you will probably end up supplementing your training data). For example, for an
    electric utility company, we consistently saw an important domain term, “residential,”
    mistranscribed as “presidential.” As speech model updates can take longer to implement,
    and this was causing loss of call containment, an immediate fix was to add “presidential”
    as a synonym to our chat solution. Another example was the mistranscription of
    “VIN” as “BIN” for a use case that needed to understand “vehicle identification
    number.” For this, we made sure that the training data contained both variations.
    We also preserved the mistranscriptions for our testing purposes.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您发现语音模型仍然持续地将您领域内的关键词误转录，请将这些关键词包含在您的测试集中（并且最终，您可能需要补充您的训练数据）。例如，对于一家电力公用事业公司，我们持续看到重要的领域术语“residential”被误转录为“presidential”。由于语音模型更新可能需要更长的时间来实现，这导致通话控制丢失，一个立即的解决方案是将“presidential”添加到我们的聊天解决方案的同义词中。另一个例子是将“VIN”误转录为“BIN”，这对于需要理解“车辆识别号码”的用例。为此，我们确保训练数据包含这两种变体。我们还保留了误转录以供我们的测试目的。
- en: Personal identifiable information
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 个人可识别信息
- en: 'You may also find various forms of PII, such as names, phone numbers, physical
    or email addresses, social security numbers, account numbers, etc. These do not
    belong in your training or test data. Ideally, this information would be masked
    in your logs, but even this technology is not perfect. If your solution has a
    PII masking function, you should replace any real data with the same type of masking
    characters (e.g., ###-###-#### for a ten-digit phone number). If not, either remove
    the PII entirely, or replace it with an obviously fictionalized representation,
    such as “username@email.com.”'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可能发现各种形式的个人身份信息（PII），例如姓名、电话号码、物理或电子邮件地址、社会保障号码、账户号码等。这些信息不应包含在您的训练或测试数据中。理想情况下，这些信息应该在日志中屏蔽，但即使这项技术也不完美。如果您的解决方案具有PII屏蔽功能，您应将任何真实数据替换为相同类型的屏蔽字符（例如，###-###-####用于十位电话号码）。如果没有，则可以完全删除PII，或者用显然是虚构的表现形式替换，例如“username@email.com”。
- en: 4.4.4 The annotation process
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.4 标注过程
- en: After you have narrowed down your data to utterances that express a clear goal
    that belongs in your domain (and have scrubbed them where appropriate), they need
    to be properly annotated for the task at hand.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在您将数据缩小到表达清晰目标的语句（属于您的领域，并在适当的地方进行了清理）之后，它们需要针对当前任务进行适当的标注。
- en: Annotating a golden test set for traditional (classifier-based) AI
  id: totrans-221
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 为传统的（基于分类器的）AI标注黄金测试集
- en: Annotating a test set for a classifier involves labeling each utterance with
    the appropriate intent. This task is a little easier said than done, and it’s
    where you will spend the most time building your test set.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 为分类器标注测试集涉及将每个语句标注为适当的意图。这项任务说起来容易做起来难，你将在构建测试集上花费最多的时间。
- en: It’s fairly easy to identify and discard an unintelligible or ambiguous user
    input. However, once you know an utterance belongs in your domain, it takes a
    bit more time to label it with the correct intent. The person or team tasked with
    annotating (labeling each utterance with the correct intent) will need to be familiar
    with the current training data. This process will definitely expose problems with
    overlap in your intents, as your human annotators will be stuck with the question
    of how to label an utterance.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 识别和丢弃不可理解或模糊的用户输入相对容易。然而，一旦你知道一个语句属于你的领域，就需要更多的时间来标注它正确的意图。负责标注（将每个语句标注为正确的意图）的个人或团队需要熟悉当前的训练数据。这个过程肯定会暴露出你的意图中重叠的问题，因为你的人类注释者会陷入如何标注语句的疑问。
- en: A team might take several approaches to complete the work of labeling data for
    testing or training. Sometimes a single person is tasked with the job. Sometimes
    a whole team will try to take this on. When that happens, they often think that
    a “divide and conquer” approach is most efficient. In our experience, this can
    lead to problems that take longer to resolve.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 一个团队可能采取几种方法来完成为测试或训练标注数据的任务。有时一个人被分配这项工作。有时整个团队会尝试承担这项任务。当这种情况发生时，他们通常会认为“分而治之”的方法最有效。根据我们的经验，这可能会导致需要更长时间解决的问题。
- en: In an ideal world, everyone would sit in the same room and judge each utterance
    together. This approach facilitates discussion regarding the purpose of each intent.
    All annotators need to understand the criteria used to differentiate intents that
    share a lot of the same key words but have different goals. Another equally valid
    approach is to have multiple annotators judge the same data separately (or at
    least a percentage of overlapping data) and compare any differences to reach a
    resolution.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个理想的世界里，每个人都应该坐在同一个房间里，共同判断每一句话。这种方法有助于讨论每个意图的目的。所有注释者都需要理解用于区分具有许多相同关键词但目标不同的意图的标准。另一个同样有效的方法是让多个注释者分别判断相同的数据（或者至少是部分重叠的数据），并将任何差异进行比较以达成共识。
- en: 'There is one shortcut we wouldn’t hesitate to take if your logs include the
    intent that was predicted at runtime for each utterance: make a first pass and
    judge whether the predicted intent was correct. Then you need only judge and label
    the remaining incorrect utterances with the correct intent.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的日志包括每个语句在运行时预测的意图，我们不会犹豫采取一个捷径：先进行一次预判并判断预测的意图是否正确。然后你只需要判断并标记剩余的不正确语句，并给出正确的意图。
- en: This exercise may take anywhere from a few hours to several days, and it can
    be taxing on both your vision and your cognitive load. As a first run, instruct
    your annotators to make their best judgment and move on. If it takes more than
    sixty seconds to judge an utterance, skip it and come back later. It is also important
    to take breaks every hour or two. It helps to walk away and come back after a
    period of refresh.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习可能需要几个小时到几天不等，可能会对你的视觉和认知负荷造成压力。作为第一次运行，指导你的注释者做出最佳判断并继续前进。如果判断一个语句需要超过六十秒，就跳过它，稍后再回来。每小时或两小时休息一下也很重要。走开一段时间再回来有助于恢复精力。
- en: Could I just use an LLM to do all that work?
  id: totrans-228
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 我能否只用LLM来完成所有这些工作？
- en: If you are building your first classifier, you could certainly run utterances
    against an LLM as a first pass at labeling or classifying your data. However,
    if you already have production logs, there will be no added value to running the
    utterances against a separate classification LLM because you still need a human
    judge to review the classifications produced by this exercise.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在构建你的第一个分类器，你当然可以将语句与LLM（大型语言模型）进行匹配，作为标记或分类数据的初步尝试。然而，如果你已经有了生产日志，将语句与单独的分类LLM进行匹配将不会增加任何价值，因为你仍然需要一个人类裁判来审查由这项练习产生的分类。
- en: Once you have annotated the test set, you will have a golden set of human-judged,
    labeled data. Depending on your use case, this could include a few hundred to
    a few thousand utterances. This asset will give you some immediate information
    about your classifier’s current accuracy. It will also be used to help tune your
    system.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你标注了测试集，你将拥有一个由人工判断、标记的数据的金色集。根据你的用例，这可能包括几百到几千个话语。这个资产将为你提供一些关于你的分类器当前准确性的即时信息。它还将被用来帮助你调整系统。
- en: The last thing you need to do is convert your data into a file that can be consumed
    by your testing tool. This will produce an asset that can be used to measure the
    effect of future updates. The format may vary by tool, but it will typically be
    a text or CSV file that contains a row for each test utterance in one column and
    the golden intent in the other column. Table 4.2 shows how a test set might look.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要做的最后一件事是将你的数据转换为可以被测试工具消费的文件。这将产生一个可以用来衡量未来更新影响的资产。格式可能因工具而异，但通常将是一个包含每行一个测试话语在一列和金色意图在另一列的文本或CSV文件。表4.2展示了测试集可能的样子。
- en: Table 4.2 Sample test set with one utterance/intent pair per row
  id: totrans-232
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.2 每行一个话语/意图对的样本测试集
- en: '| Utterance | Golden intent |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 话语 | 金色意图 |'
- en: '| --- | --- |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| I want to speak with a real person  | `Request_Agent`  |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 我想和真人说话 | `Request_Agent`  |'
- en: '| Can I talk to a manager  | `Request_Agent`  |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 我可以和经理通话吗 | `Request_Agent`  |'
- en: '| Get me customer service  | `Request_Agent`  |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| 让我找客服 | `Request_Agent`  |'
- en: '| Are you open on Sundays  | `Office_Hours`  |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 你星期日是否开门 | `Office_Hours`  |'
- en: '| What time do you open  | `Office_Hours`  |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 你什么时候开门 | `Office_Hours`  |'
- en: '| When does your office close  | `Office_Hours`  |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 你的办公室什么时候关门 | `Office_Hours`  |'
- en: '| What are your weekend hours  | `Office_Hours`  |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 你的周末营业时间是什么时候 | `Office_Hours`  |'
- en: Annotating a golden test set for generative AI
  id: totrans-242
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 为生成式AI标注金色测试集
- en: Creating a test set to measure generative AI involves judging the quality of
    the answer produced by your solution (if you are working with production logs)
    and updating or replacing it with the ideal answer, according to the dimensions
    you previously defined for your solution. Subject matter experts will need to
    review each example output to ensure that it is factual and complete, represents
    the brand, and reflects the purpose and positioning of the virtual agent persona.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个用于衡量生成式AI的测试集需要判断你的解决方案（如果你正在使用生产日志）产生的答案质量，并根据你之前为解决方案定义的维度对其进行更新或替换为理想答案。主题专家需要审查每个示例输出，以确保其事实性和完整性，代表品牌，并反映虚拟代理角色的目的和定位。
- en: Once you have reviewed the output, you will have a set of utterances paired
    with a golden answer or response. This asset will give you some immediate information
    about the quality of your generated responses. It will also be used to tune your
    prompts and LLM configurations.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你审查了输出，你将有一组与金色答案或响应配对的话语。这个资产将为你提供一些关于你生成响应质量的即时信息。它还将被用来调整你的提示和LLM配置。
- en: The last thing you need to do is convert your data into a file that can be consumed
    by your testing tool. The format may vary by tool, but it will typically be a
    text or CSV file that contains a row for each test utterance in one column and
    the golden response in the other column. Table 4.3 shows a sample test set.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要做的最后一件事是将你的数据转换为可以被测试工具消费的文件。格式可能因工具而异，但通常将是一个包含每行一个测试话语在一列和金色响应在另一列的文本或CSV文件。表4.3展示了样本测试集。
- en: Table 4.3 Sample test set with one utterance/answer pair per row
  id: totrans-246
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表4.3 每行一个话语/答案对的样本测试集
- en: '| Utterance | Golden response |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 话语 | 金色响应 |'
- en: '| --- | --- |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Can I bring a snowboard on my flight as checked baggage?  | You can bring
    one set of snowboard equipment as a checked bag. The set must be in one bag and
    can include up to two snowboards and one snow boot bag. If the set weighs more
    than 50 pounds (23 kg), you’ll have to pay overweight bag fees.  |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 我可以把我滑雪板作为托运行李带上飞机吗？ | 你可以带一套滑雪板设备作为托运行李。这套设备必须在一个包里，可以包括最多两块滑雪板和一个雪靴包。如果这套设备重量超过50磅（23公斤），你将不得不支付超重行李费。  |'
- en: '| How long do I have to wait to get my refund?  | Credit card refunds will
    be processed within five business days of the request. All other refunds will
    be processed within 20 business days of the request.  |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 我要退款需要等多久？ | 信用卡退款将在请求后的五个工作日内处理。所有其他退款将在请求后的20个工作日内处理。  |'
- en: Exercises
  id: totrans-251
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: Obtain data from your own logs, and identify candidate test utterances.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从您自己的日志中获取数据，并确定候选测试语料。
- en: Scrub the data as needed to remove PII.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据需要清理数据以删除PII。
- en: Assess the classification predictions or generated answer content. Record these
    outcomes as baseline performance measurements.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估分类预测或生成的答案内容。将这些结果记录为基线性能测量。
- en: Assign a golden intent or ideal response.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分配一个黄金意图或理想响应。
- en: Save the file in a format that can be consumed by your testing tool.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以测试工具可以消费的格式保存文件。
- en: 4.5 What does the data tell us?
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 数据告诉我们什么？
- en: If your logs included the original intent prediction or generated answer, you
    now have what is needed to calculate a baseline measurement of your solution’s
    current accuracy rate for understanding. (Divide the number of correct predictions
    or answers by the total candidates judged.) Your annotated utterances will show
    you the range and frequency of topics your users present to the chatbot.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的日志中包含了原始意图预测或生成的答案，您现在就有所需的数据来计算解决方案当前理解准确率的基线测量。（将正确预测或答案的数量除以总候选数量。）您标注的语料将显示用户向聊天机器人提出的话题的范围和频率。
- en: 4.5.1 Interpreting annotated logs for traditional (classification-based) AI
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.1 解释传统（基于分类）AI的标注日志
- en: For classifier-based systems, you might be interested in looking at the volume
    distribution across your intents. How does this compare to your training example
    volumes for each intent? Figure 4.9 shows an idealized, fairly balanced distribution
    of training examples compared to occurrences seen in the logs.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于分类器的系统，您可能对查看意图之间的数量分布感兴趣。这与每个意图的训练示例量相比如何？图4.9显示了训练示例的理想化、相对平衡的分布，与日志中观察到的发生次数相比。
- en: '![figure](../Images/CH04_F09_Freed2.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F09_Freed2.png)'
- en: Figure 4.9 The dark bars represent the number of training examples in a system.
    The light bars represent the number of annotated utterances for each intent. If
    your chart follows a similar pattern, your training priorities are probably in
    good alignment with the demands of your solution.
  id: totrans-262
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.9 深色条形表示系统中训练示例的数量。浅色条形表示每个意图的标注语料数量。如果您的图表遵循类似的模式，那么您的训练优先级可能与解决方案的需求良好对齐。
- en: A stark disparity between trained examples and actual occurrences in the logs
    is not indicative of problems in and of itself, but it can inform your priorities
    if your accuracy is low. Figure 4.10 shows an example of annotated utterances
    that are wildly out of alignment with how the system was trained.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 训练示例与日志中实际发生之间的明显差异本身并不表明存在问题，但如果准确率低，它可以告知您的优先级。图4.10显示了一个与系统训练严重不匹配的标注语料的示例。
- en: '![figure](../Images/CH04_F10_Freed2.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH04_F10_Freed2.png)'
- en: Figure 4.10 The training example counts (dark bars) show a large disparity across
    many intents, as compared to the annotated log data (light bars). Without accuracy
    numbers for each intent, we cannot immediately tell if this disparity is having
    a negative effect. However, we can make some observations, such as 1) the first
    five intents are not nearly as important to our users as we thought they might
    be, and 2) the intents with the highest volume in our logs (the light bars for
    intents 6, 10, 11, and 12) may be a lot more important to our users than we predicted.
  id: totrans-265
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.10 训练示例计数（深色条形）与标注日志数据（浅色条形）相比，在许多意图上存在很大的差异。没有每个意图的准确率数字，我们无法立即判断这种差异是否会产生负面影响。然而，我们可以进行一些观察，例如1）前五个意图并不像我们想象的那么重要，2）日志中意图量最高的（意图6、10、11和12的浅色条形）可能比我们预测的更受用户重视。
- en: You should also review the volume of utterances that were judged to be in domain
    but out of the current scope. (These would have been identified and set aside
    as part of the preparation tasks described in section 4.1.4.) Does there appear
    to be a demand for topics that the classifier is not currently trained on? A misalignment
    between what your users expect to be able to ask and what your classifier is trained
    to recognize contributes to a perception of weak understanding.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应该回顾那些被判定为属于领域但超出当前范围的语料量。（这些语料在4.1.4节中描述的准备任务中已被识别并留出。）是否似乎存在对分类器尚未训练的主题的需求？用户期望能够提出的问题与分类器训练以识别的内容之间的不匹配，会导致对理解能力薄弱的感知。
- en: Your overall accuracy provided a big-picture view of the solution’s ability
    to understand. The next step is to drill down into the specific intents. You might
    start by looking at the poorest performers that are also high-volume/high-value
    in your solution. In chapter 5, we will explore in depth the process for improving
    classifier understanding.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 您的整体准确性提供了对解决方案理解能力的整体视图。下一步是深入具体意图。您可能从查看您的解决方案中表现最差且高量/高价值的意图开始。在第5章中，我们将深入探讨改进分类器理解的过程。
- en: 4.5.2 Interpreting annotated logs for generative AI
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.2 解释生成式AI的标注日志
- en: Your annotated logs for a generative AI solution will give you a picture of
    the range of questions and requests that users are providing. Throughout the annotation
    process, you may have discovered gaps in coverage about the domain. You may also
    have gained a better grasp of how prompt engineering or fine-tuning improvements
    could make your generated answers better. If your solution employs RAG, you might
    start correlating the quality of your answers to the documents in your repository.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 您为生成式AI解决方案提供的标注日志将展示用户提供的各种问题和请求的范围。在整个标注过程中，您可能发现了关于领域的覆盖范围方面的差距。您也可能更好地理解了提示工程或微调改进如何使生成的答案更好。如果您的解决方案采用RAG，您可能会开始将答案的质量与您存储库中的文档相关联。
- en: Your overall accuracy provided a big-picture view of the solution’s ability
    to understand. In chapter 6, we will explore in depth the process for improving
    your generative AI so that it conveys good understanding.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 您的整体准确性提供了对解决方案理解能力的整体视图。在第6章中，我们将深入探讨改进您生成式AI的过程，使其能够传达良好的理解。
- en: 4.5.3 The case for iterative improvement
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5.3 逐步改进的案例
- en: At this point, you should be armed with the data you need to begin planning
    improvement cycles. Your performance findings will serve as a roadmap for improvements.
    Keep in mind that this is an iterative process. You will make changes. Then you
    will take measurements to determine whether your change had a positive, neutral,
    or negative effect on understanding.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您应该已经拥有了开始规划改进周期所需的数据。您的性能发现将作为改进的路线图。请记住，这是一个迭代的过程。您将做出改变。然后您将进行测量，以确定您的更改对理解产生了积极、中性或消极的影响。
- en: 'It is also important to note that your blind or golden test set will need to
    be refreshed throughout the lifecycle of your solution. Recall that one of the
    reasons a chatbot can become inaccurate is due to new information in the world.
    These are some examples we have seen:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，您的盲测或黄金测试集在整个解决方案的生命周期中都需要更新。回想一下，聊天机器人可能变得不准确的一个原因是世界上的新信息。以下是我们看到的一些例子：
- en: The global COVID-19 pandemic, which changed the way nearly everyone worked,
    navigated public spaces, and supported their families.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全球COVID-19大流行，它改变了几乎每个人的工作方式、公共空间的导航以及支持家庭的方式。
- en: New legislation passed, resulting in government organizations getting related
    questions.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的立法通过，导致政府机构收到相关问题的咨询。
- en: New products on the market or product recalls.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 市场上的新产品或产品召回。
- en: A company experienced a data breach, and once the news broke, the chatbot was
    bombarded with questions like, “Is my data safe?” and “I want to know more about
    the hack.”
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一家公司遭遇了数据泄露，一旦消息公布，聊天机器人就遭到了诸如“我的数据安全吗？”和“我想了解更多关于黑客攻击的信息。”等问题的大量询问。
- en: 'Plan to review your logs on a regular basis. Depending on the volume of your
    solution, that might start out daily right after launch, then weekly, monthly,
    and quarterly. Don’t forget to update your test sets according to the changes
    you make:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 计划定期审查您的日志。根据您解决方案的量级，这可能从启动后的每日开始，然后是每周、每月和每季度。别忘了根据您所做的更改更新您的测试集：
- en: If new intents are added to your system, new utterances need to be added to
    your test set.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您的系统中添加了新的意图，需要向测试集中添加新的话语。
- en: If intents were merged or split as part of your improvement efforts, the affected
    intents will need to be updated in your test set.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果意图在您的改进工作中合并或拆分，受影响的意图需要在您的测试集中更新。
- en: If new areas of coverage are added to the knowledge base your generative solution
    references, your test set should include validations for this.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果在您的生成式解决方案引用的知识库中添加了新的覆盖范围区域，您的测试集应包括对此的验证。
- en: If your solution adds new LLM scenarios or prompt customizations, these should
    be reflected in the test set.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您的解决方案添加了新的LLM场景或提示定制，这些应该反映在测试集中。
- en: Exercises
  id: totrans-283
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习
- en: Review your annotated data and reflect on the findings. Are there areas that
    show poor understanding?
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回顾你的标注数据并反思发现。是否有表现不佳的理解区域？
- en: If so, what would you hypothesize is the root cause?
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是这样，你会假设什么根本原因？
- en: Is there more than one root cause?
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否存在多个根本原因？
- en: How would you prioritize the improvements needed to achieve better understanding?
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会如何优先考虑实现更好理解所需的改进？
- en: Summary
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Chatbots demonstrate good understanding when they identify what a user wants
    and they provide a satisfactory answer or progress the user toward their goal.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当聊天机器人能够识别用户想要什么并提供令人满意的答案或帮助用户实现目标时，它们表现出良好的理解。
- en: 'For traditional AI, understanding relies on at least two mechanisms: correct
    classification of an intent and an ability to deliver an output based on that
    classification. (Additional mechanisms, such as entity detection or context, may
    modify or personalize outputs.)'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于传统AI，理解依赖于至少两种机制：对意图的正确分类以及根据该分类提供输出的能力。（额外的机制，如实体检测或上下文，可能会修改或个性化输出。）
- en: For generative AI, understanding relies on the utterance and any accompanying
    prompt to create a response meant to address a user’s question or goal.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于生成式AI，理解依赖于话语及其伴随的提示来创建一个旨在解决用户问题或目标的响应。
- en: Weak understanding is detrimental to business value and is often exhibited by
    a chatbot returning wrong answers or no answers at all.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解薄弱对商业价值有害，通常表现为聊天机器人返回错误答案或完全无答案。
- en: You can’t assess the performance of your chatbot without first collecting some
    data.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在收集一些数据之前，你无法评估你的聊天机器人的性能。
- en: Chatbot understanding is usually measured in terms of accuracy or the rate at
    which the solution delivers a correct answer or takes the correct action.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人的理解通常以准确性或解决方案提供正确答案或采取正确行动的速率来衡量。
- en: There are multiple tools and methods for measuring understanding. Some are dependent
    on the type of AI and/or the current phase, whether predeployment or post.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在多种工具和方法来衡量理解。其中一些取决于AI的类型和/或当前阶段，无论是预部署还是后部署。
- en: A representative golden test set, curated from real user utterances (production
    logs), can be used to measure the bot’s baseline performance and can be converted
    into a reusable asset to measure the effect of future changes.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个代表性的黄金测试集，由真实用户话语（生产日志）精心挑选，可以用来衡量机器人的基准性能，并且可以转化为可重复使用的资产，以衡量未来变更的影响。
- en: You should plan to monitor and retrain your solution throughout the life of
    the bot.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该计划在整个聊天机器人生命周期内监控和重新训练你的解决方案。
- en: Updates to training may require corresponding updates to the blind test set.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练的更新可能需要相应更新盲测试集。
