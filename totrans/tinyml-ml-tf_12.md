# 第十二章：魔杖：训练模型

在第十一章中，我们使用了一个 20 KB 的预训练模型来解释原始加速度计数据，用它来识别执行了一组手势中的哪一个。在本章中，我们将向您展示这个模型是如何训练的，然后我们将讨论它的实际工作原理。

我们的唤醒词和人员检测模型都需要大量数据进行训练。这主要是由于它们试图解决的问题的复杂性。一个人说“是”或“不”有很多不同的方式——想想所有使某人的声音独特的口音、语调和音调的变化。同样，一个人在图像中出现的方式有无限多种可能；你可能看到他们的脸、整个身体或一个手，他们可能站在任何可能的姿势中。

为了能够准确分类如此多样的有效输入，模型需要在同样多样的训练数据集上进行训练。这就是为什么我们的唤醒词和人员检测训练数据集如此庞大，以及为什么训练需要如此长时间。

我们的魔杖手势识别问题要简单得多。在这种情况下，我们并不是试图对广泛范围的自然声音或人类外貌和姿势进行分类，而是试图理解三种特定和故意选择的手势之间的差异。虽然不同人执行每个手势的方式会有一些变化，但我们希望我们的用户会尽可能正确和统一地执行这些手势。

这意味着我们期望的有效输入变化会少得多，这使得在不需要大量数据的情况下训练准确的模型变得更加容易。事实上，我们将用来训练模型的数据集每种手势只包含大约 150 个示例，总大小仅为 1.5 MB。想到一个有用的模型可以在如此小的数据集上训练，真是令人兴奋，因为获得足够的数据通常是机器学习项目中最困难的部分。

在本章的第一部分，您将学习如何训练魔杖应用程序中使用的原始模型。在第二部分，我们将讨论这个模型的实际工作原理。最后，您将看到如何捕获自己的数据并训练一个识别不同手势的新模型。

# 训练模型

为了训练我们的模型，我们使用了位于 TensorFlow 存储库中的训练脚本。您可以在[*magic_wand/train*](https://oreil.ly/LhZGT)中找到它们。

脚本执行以下任务：

+   为训练准备原始数据。

+   生成合成数据。¹

+   将数据拆分为训练、验证和测试集。

+   执行数据增强。

+   定义模型架构。

+   运行训练过程。

+   将模型转换为 TensorFlow Lite 格式。

为了简化生活，这些脚本附带了一个 Jupyter 笔记本，演示了如何使用它们。您可以在 Colaboratory（Colab）上的 GPU 运行时中运行笔记本。使用我们的小数据集，训练只需要几分钟。

首先，让我们在 Colab 中走一遍训练过程。

## 在 Colab 中进行训练

打开[*magic_wand/train/train_magic_wand_model.ipynb*](https://oreil.ly/2BLtj)中的 Jupyter 笔记本，并单击“在 Google Colab 中运行”按钮，如图 8-1 所示。

![在 Google Colab 中运行按钮](img/timl_0403.png)

###### 图 12-1。在 Google Colab 中运行按钮

###### 注

截至目前，GitHub 存在一个错误，导致在显示 Jupyter 笔记本时会出现间歇性错误消息。如果在尝试访问笔记本时看到消息“抱歉，出了点问题。重新加载？”，请按照“构建我们的模型”中的说明操作。

本笔记本将演示训练模型的过程。它包括以下步骤：

+   安装依赖项

+   下载和准备数据

+   加载 TensorBoard 以可视化训练过程

+   训练模型

+   生成 C 源文件

### 启用 GPU 训练

训练这个模型应该非常快，但如果我们使用 GPU 运行时会更快。要启用此选项，请转到 Colab 的运行时菜单，并选择“更改运行时类型”，如图 12-2 所示。

这将打开图 12-3 所示的“笔记本设置”对话框。

从“硬件加速器”下拉列表中选择 GPU，如图 12-4 所示，然后点击保存。

现在您已经准备好运行笔记本了。

![在 Colab 中更改运行时类型的选项](img/timl_0802.png)

###### 图 12-2。在 Colab 中更改运行时类型的选项

![笔记本设置框](img/timl_0803.png)

###### 图 12-3。笔记本设置对话框

![硬件加速器下拉列表](img/timl_0804.png)

###### 图 12-4。硬件加速器下拉列表

### 安装依赖项

第一步是安装所需的依赖项。在“安装依赖项”部分，运行单元格安装正确版本的 TensorFlow 并获取训练脚本的副本。

### 准备数据

接下来，在“准备数据”部分，运行单元格下载数据集并将其分割为训练、验证和测试集。

第一个单元格下载并提取数据集到训练脚本目录。数据集包括四个目录，一个用于每个手势（“wing”，“ring”和“slope”），另一个“negative”目录用于表示没有明显手势的数据。每个目录包含代表手势执行过程中捕获的原始数据的文件：

```py
data/
├── slope
│   ├── output_slope_dengyl.txt
│   ├── output_slope_hyw.txt
│   └── ...
├── ring
│   ├── output_ring_dengyl.txt
│   ├── output_ring_hyw.txt
│   └── ...
├── negative
│   ├── output_negative_1.txt
│   └── ...
└── wing
    ├── output_wing_dengyl.txt
    ├── output_wing_hyw.txt
    └── ...
```

每个手势有 10 个文件，我们稍后会详细介绍。每个文件包含一个由命名个体演示的手势，文件名的最后部分对应其用户 ID。例如，文件*output_slope_dengyl.txt*包含了用户 ID 为`dengyl`的用户演示“slope”手势的数据。

每个文件中大约有 15 次给定手势的表演，每行一个加速度计读数，每次表演都以行`-,-,-`开头：

```py
 -,-,-
-766.0,132.0,709.0
-751.0,249.0,659.0
-714.0,314.0,630.0
-709.0,244.0,623.0
-707.0,230.0,659.0
```

每次表演包括几秒钟的数据日志，每秒 25 行。手势本身发生在该窗口内的某个时间点，设备在其余时间内保持静止。

由于测量数据的捕获方式，文件中还包含一些垃圾字符。我们的第一个训练脚本[*data_prepare.py*](https://oreil.ly/SCZe9)，将在第二个训练单元格中运行，将清理这些脏数据：

```py
# Prepare the data
!python data_prepare.py
```

该脚本旨在从文件夹中读取原始数据文件，忽略任何垃圾字符，并将它们以经过清理的形式写入到训练脚本目录内的另一个位置（*data/complete_data*）。清理混乱的数据源是训练机器学习模型时的常见任务，因为大型数据集很容易出现错误、损坏和其他问题。

除了清理数据，脚本还生成了一些*合成数据*。这是指通过算法生成的数据，而不是从现实世界中捕获的数据。在这种情况下，*data_prepare.py*中的`generate_negative_data()`函数创建了相当于加速度计移动但不对应任何特定手势的合成数据。这些数据用于训练我们的“未知”类别。

由于生成合成数据比捕获现实世界数据要快得多，因此有助于增强我们的训练过程。然而，现实世界的变化是不可预测的，因此往往不可能完全使用合成数据创建整个数据集。在我们的情况下，这有助于使我们的“未知”类别更加健壮，但对于分类已知手势并不有用。

在第二个单元格中运行的下一个脚本是[*data_split_person.py*](https://oreil.ly/1U0FW)：

```py
# Split the data by person
!python data_split_person.py
```

这个脚本将数据分成训练、验证和测试集。因为我们的数据带有创建者的标签，我们可以使用一个人的数据进行训练，另一个人的数据进行验证，最后一个人的数据进行测试。数据分割如下：

```py
train_names = [
    "hyw", "shiyun", "tangsy", "dengyl", "jiangyh", "xunkai", "negative3",
    "negative4", "negative5", "negative6"
]
valid_names = ["lsj", "pengxl", "negative2", "negative7"]
test_names = ["liucx", "zhangxy", "negative1", "negative8"]
```

我们使用六个人的数据进行训练，两个用于验证，两个用于测试。此外，我们混合了与特定用户无关的负面数据。我们的总数据在三个集合之间以大约 60%/20%/20%的比例分配，这对于机器学习来说是相当标准的。

通过按个人分割，我们试图确保我们的模型能够推广到新数据。因为模型将在未包含在训练数据集中的个体数据上进行验证和测试，所以模型需要对每个人执行每个手势的方式的个体变化具有鲁棒性。

也可以随机分割数据，而不是按个人分割。在这种情况下，训练、验证和测试数据集将分别包含每个个体的每个手势的一些样本。由此产生的模型将被训练在每个人的数据上，而不仅仅是六个人，因此它将更多地接触到人们不同的手势风格。

然而，由于验证和训练集也包含来自每个个体的数据，我们无法测试模型是否能够推广到之前未见过的新手势风格。以这种方式开发的模型可能在验证和测试过程中报告更高的准确性，但不能保证在新数据上的表现同样出色。

在继续之前，请确保您已经运行了“准备数据”部分中的两个单元格。

### 加载 TensorBoard

数据准备好后，我们可以运行下一个单元格来加载 TensorBoard，这将帮助我们监视训练过程：

```py
# Load TensorBoard
%load_ext tensorboard
%tensorboard --logdir logs/scalars
```

训练日志将被写入训练脚本目录下的*logs/scalars*子目录中，因此我们将其传递给 TensorBoard。

### 开始训练

TensorBoard 加载完成后，现在是开始训练的时候了。运行以下单元格：

```py
!python train.py --model CNN --person true
```

脚本[*train.py*](https://oreil.ly/S3w0X)设置了模型架构，使用[*data_load.py*](https://oreil.ly/aCZgu)加载数据，并开始训练过程。

当数据加载时，*load_data.py*还使用[*data_augmentation.py*](https://oreil.ly/zL6wm)中定义的代码执行数据增强。函数`augment_data()`接受表示手势的数据，并创建一些稍微修改的新版本，每个版本都与原始数据略有不同。修改包括在时间上移动和扭曲数据点，添加随机噪声，以及增加加速度的量。这些增强数据与原始数据一起用于训练模型，有助于充分利用我们的小数据集。

随着训练的加速，您将看到一些输出出现在您刚刚运行的单元格下方。那里有很多内容，让我们挑出最值得注意的部分。首先，Keras 生成了一个漂亮的表格，显示了我们模型的架构：

```py
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 128, 3, 8)         104
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 42, 1, 8)          0
_________________________________________________________________
dropout (Dropout)            (None, 42, 1, 8)          0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 42, 1, 16)         528
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 1, 16)         0
_________________________________________________________________
dropout_1 (Dropout)          (None, 14, 1, 16)         0
_________________________________________________________________
flatten (Flatten)            (None, 224)               0
_________________________________________________________________
dense (Dense)                (None, 16)                3600
_________________________________________________________________
dropout_2 (Dropout)          (None, 16)                0
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 68
=================================================================
```

它告诉我们所使用的所有层，以及它们的形状和参数数量——这是权重和偏差的另一个术语。您可以看到我们的模型使用了`Conv2D`层，因为它是一个卷积模型。在这个表中没有显示的是我们模型的输入形状是`(None, 128, 3)`。我们稍后会更仔细地查看模型的架构。

输出还将显示模型大小的估计：

```py
Model size: 16.796875 KB
```

这代表了模型可训练参数所占用的内存量。它不包括存储模型执行图所需的额外空间，因此我们的实际模型文件会稍微大一些，但这给我们一个正确数量级的概念。这绝对可以被称为一个微小模型！

最终您将看到训练过程本身开始：

```py
1000/1000 [==============================] - 12s 12ms/step - loss: 7.6510 - accuracy: 0.5207 - val_loss: 4.5836 - val_accuracy: 0.7206
```

此时，您可以查看 TensorBoard，以查看训练过程的进行情况。

### 评估结果

训练完成后，我们可以查看单元格的输出以获取一些有用的信息。首先，我们可以看到我们最终时期的验证准确率非常有希望，为 0.9743，损失也很低：

```py
Epoch 50/50
1000/1000 [==============================] - 7s 7ms/step - loss: 0.0568 -

accuracy: 0.9835 - val_loss: 0.1185 - val_accuracy: 0.9743
```

这很棒，特别是因为我们使用了按人员数据拆分，这意味着我们的验证数据来自完全不同的一组个体。然而，我们不能仅仅依靠我们的验证准确性来评估我们的模型。因为模型的超参数和架构是在验证数据集上手动调整的，我们可能已经过度拟合了。

为了更好地了解我们模型的最终性能，我们可以通过调用 Keras 的`model.evaluate()`函数来评估它与我们的测试数据集的表现。下一行输出显示了这个结果：

```py
6/6 [==============================] - 0s 6ms/step - loss: 0.2888 - accuracy: 0.9323
```

尽管验证数字没有那么惊人，但模型显示了一个足够好的准确率为 0.9323，损失仍然很低。该模型将在 93%的时间内预测正确的类别，这对我们的目的应该是可以接受的。

接下来的几行显示了结果的*混淆矩阵*，由[`tf.math.confusion_matrix()`](https://oreil.ly/xlIKj)函数计算：

```py
tf.Tensor(
[[ 75   3   0   4]
 [  0  69   0  15]
 [  0   0  85   3]
 [  0   0   1 129]], shape=(4, 4), dtype=int32)
```

混淆矩阵是评估分类模型性能的有用工具。它显示了测试数据集中每个输入的预测类别与其实际值的一致程度。

混淆矩阵的每一列对应于一个预测标签，依次为“wing”，“ring”，“slope”，然后“unknown”。从上到下，每一行对应于实际标签。从我们的混淆矩阵中，我们可以看到绝大多数预测与实际标签一致。我们还可以看到混淆发生的具体位置：最显著的是，相当多的输入被错误分类为“unknown”，特别是属于“ring”类别的输入。

混淆矩阵让我们了解模型的弱点在哪里。在这种情况下，它告诉我们，为了帮助模型更好地学习“ring”和“unknown”之间的差异，获取更多的“ring”手势的训练数据可能是有益的。

*train.py*的最后一步是将模型转换为 TensorFlow Lite 格式，包括浮点和量化变体。以下输出显示了每个变体的大小：

```py
Basic model is 19544 bytes
Quantized model is 8824 bytes
Difference is 10720 bytes
```

我们的 20 KB 模型在量化后缩小到 8.8 KB。这是一个*非常*小的模型，是一个很好的结果。

### 创建一个 C 数组

在“创建 C 源文件”部分中的下一个单元格将其转换为 C 源文件。运行此单元格以查看输出：

```py
# Install xxd if it is not available
!apt-get -qq install xxd
# Save the file as a C source file
!xxd -i model_quantized.tflite > /content/model_quantized.cc
# Print the source file
!cat /content/model_quantized.cc
```

我们可以将此文件的内容复制粘贴到我们的项目中，以便我们可以在我们的应用程序中使用新训练的模型。稍后，您将学习如何收集新数据并教导应用程序理解新的手势。现在，让我们继续前进。

## 运行脚本的其他方法

如果您不想使用 Colab，或者您正在更改模型训练脚本并希望在本地测试它们，您可以轻松地从自己的开发机器上运行这些脚本。您可以在[*README.md*](https://oreil.ly/6-KPf)中找到说明。

接下来，我们将介绍模型本身的工作原理。

# 模型的工作原理

到目前为止，我们已经确定我们的模型是一个卷积神经网络（CNN），它将表示大约五秒时间的 128 个三轴加速度计读数序列转换为四个概率数组：一个用于每个手势，一个用于“unknown”。

当相邻值之间的关系包含重要信息时，CNNs 被用来。在我们解释的第一部分中，我们将查看我们的数据并了解为什么 CNN 非常适合理解它。

## 可视化输入

在我们的时间序列加速度计数据中，相邻的加速度计读数给我们关于设备运动的线索。例如，如果一个轴上的加速度从零迅速变为正值，然后再回到零，那么设备可能已经开始朝着那个方向运动。图 12-5 展示了这种假设性示例。

![显示设备单轴加速度计值的图表](img/timl_1205.png)

###### 图 12-5. 设备单轴加速度计值

任何给定的手势由一系列运动组成，一个接着一个。例如，考虑我们的“翼”手势，如图 12-6 所示。

![显示“翼”手势的图表](img/timl_1206.png)

###### 图 12-6. “翼”手势

设备首先向下和向右移动，然后向上和向右移动，然后再向下和向右移动，然后再向上和向右移动。图 12-7 显示了在“翼”手势期间捕获的实际数据样本，以毫 G 为单位测量。

![在“翼”手势期间加速度计值的图表](img/timl_1207.png)

###### 图 12-7. “翼”手势期间的加速度计值

通过查看这个图表并将其分解为其组成部分，我们可以理解正在进行的手势。从 z 轴加速度来看，很明显设备正在上下移动，这符合我们对“翼”手势形状的预期。更微妙的是，我们可以看到 x 轴上的加速度如何与 z 轴的变化相关联，表明设备在手势的宽度方向上移动。同时，我们可以观察到 y 轴基本保持稳定。

同样，具有多层的 CNN 能够学习如何通过其特征组件部分来辨别每个手势。例如，网络可能学会区分上下运动，并且当与适当的 z 轴和 y 轴运动结合时，表示“翼”手势的两个运动。

为了做到这一点，CNN 学习一系列*滤波器*，排列在层中。每个滤波器学会在数据中发现特定类型的特征。当它注意到这个特征时，它将这个高级信息传递给网络的下一层。例如，网络的第一层中的一个滤波器可能学会发现一些简单的东西，比如一个向上加速的周期。当它识别到这样的结构时，它将这些信息传递给网络的下一层。

后续的滤波器层学习如何将早期更简单的滤波器的输出组合在一起形成更大的结构。例如，一系列四个交替的向上和向下的加速度可能组合在一起表示我们“翼”手势中的“W”形状。

在这个过程中，嘈杂的输入数据逐渐转化为高级符号表示。我们网络的后续层可以分析这个符号表示，猜测执行了哪个手势。

在接下来的部分中，我们将详细介绍实际的模型架构，并看看它如何映射到这个过程中。

## 理解模型架构

我们模型的架构在[*train.py*](https://oreil.ly/vxT1v)中定义，在`build_cnn()`函数中。这个函数使用 Keras API 逐层定义模型：

```py
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D( # input_shape=(batch, 128, 3)
        8, (4, 3),
        padding="same",
        activation="relu",
        input_shape=(seq_length, 3, 1)),  # output_shape=(batch, 128, 3, 8)
    tf.keras.layers.MaxPool2D((3, 3)),  # (batch, 42, 1, 8)
    tf.keras.layers.Dropout(0.1),  # (batch, 42, 1, 8)
    tf.keras.layers.Conv2D(16, (4, 1), padding="same",
                            activation="relu"),  # (batch, 42, 1, 16)
    tf.keras.layers.MaxPool2D((3, 1), padding="same"),  # (batch, 14, 1, 16)
    tf.keras.layers.Dropout(0.1),  # (batch, 14, 1, 16)
    tf.keras.layers.Flatten(),  # (batch, 224)
    tf.keras.layers.Dense(16, activation="relu"),  # (batch, 16)
    tf.keras.layers.Dropout(0.1),  # (batch, 16)
    tf.keras.layers.Dense(4, activation="softmax")  # (batch, 4)
])
```

这是一个顺序模型，意味着每一层的输出直接传递到下一层。让我们逐层走过并探索正在发生的事情。第一层是一个`Conv2D`：

```py
tf.keras.layers.Conv2D(
    8, (4, 3),
    padding="same",
    activation="relu",
    input_shape=(seq_length, 3, 1)),  # output_shape=(batch, 128, 3, 8)
```

这是一个卷积层；它直接接收我们网络的输入，这是一系列原始加速度计数据。输入的形状在`input_shape`参数中提供。它设置为`(seq_length, 3, 1)`，其中`seq_length`是传入的加速度计测量的总数（默认为 128）。每个测量由三个值组成，表示 x 轴、y 轴和 z 轴。输入在图 12-8 中可视化。

![模型输入的图表](img/timl_1208.png)

###### 图 12-8\. 模型的输入

我们的卷积层的工作是获取原始数据并提取一些基本特征，这些特征可以被后续层解释。`Conv2D()`函数的参数确定将提取多少特征。这些参数在[`tf.keras.layers.Conv2D()`文档](https://oreil.ly/hqXJF)中有描述。

第一个参数确定层将具有多少滤波器。在训练期间，每个滤波器学习识别原始数据中的特定特征，例如，一个滤波器可能学习识别向上运动的显著特征。对于每个滤波器，层输出一个显示它所学习的特征在输入中出现位置的*特征图*。

我们代码中定义的层有八个滤波器，这意味着它将学习识别并输出来自输入数据的八种不同类型的高级特征。您可以在输出形状`(batch_size, 128, 3, 8)`中看到这一点，它的最后一个维度有八个*特征通道*，每个特征对应一个通道。每个通道中的值表示该位置的输入中存在该特征的程度。

正如我们在第八章中学到的，卷积层在数据上滑动一个窗口，并决定该窗口中是否存在给定特征。`Conv2D()`的第二个参数是我们提供此窗口尺寸的地方。在我们的情况下，它是`(4, 3)`。这意味着我们的滤波器正在寻找的特征跨越四个连续的加速度计测量和所有三个轴。因为窗口跨越了四个测量，每个滤波器分析了一个小的时间快照，这意味着它可以生成代表随时间加速度变化的特征。您可以在图 12-9 中看到这是如何工作的。

![一个卷积窗口覆盖在数据上的图表](img/timl_1209.png)

###### 图 12-9\. 一个卷积窗口覆盖在数据上

`padding`参数确定窗口如何在数据上移动。当`padding`设置为`"same"`时，层的输出长度（128）和宽度（3）与输入相同。因为每次滤波器窗口的移动都会产生一个输出值，所以`"same"`参数意味着窗口必须在数据上移动三次，并且在下面移动 128 次。

因为窗口的宽度为 3，这意味着它必须从数据的左侧开始悬挂。空白处，即滤波器窗口未覆盖实际值的地方，用零*填充*。为了在数据的长度上总共移动 128 次，滤波器还必须悬挂在数据的顶部。您可以在图 12-10 和 12-11 中看到这是如何工作的。

一旦卷积窗口在所有数据上移动，使用每个滤波器创建八个不同的特征图，输出将传递给我们的下一层`MaxPool2D`：

```py
tf.keras.layers.MaxPool2D((3, 3)),  # (batch, 42, 1, 8)
```

![一个卷积窗口在数据上移动的图表](img/timl_1210.png)

###### 图 12-10\. 卷积窗口处于第一个位置，需要在顶部和左侧填充

![卷积窗口在数据上移动的图表](img/timl_1211.png)

###### 图 12-11\. 同一卷积窗口已移动到第二个位置，只需要在顶部填充

这个`MaxPool2D`层接收前一层的输出，一个`(128, 3, 8)`张量，并将其缩小为一个`(42, 1, 8)`张量——原始大小的三分之一。它通过查看输入数据的窗口，然后选择窗口中的最大值，并将仅该值传播到输出中来实现这一点。然后，该过程会重复下一个数据窗口。提供给[`MaxPool2D()`](https://oreil.ly/HZo0q)函数的参数`(3, 3)`指定使用一个 3×3 的窗口。默认情况下，窗口总是移动，以包含全新的数据。图 12-12 展示了这个过程是如何工作的。

![一个最大池化工作的示意图](img/timl_1212.png)

###### 图 12-12。最大池化的工作

请注意，尽管图中每个元素只显示了一个值，但我们的数据实际上每个元素有八个特征通道。

但是为什么我们需要像这样缩小我们的输入呢？当用于分类时，CNN 的目标是将一个大而复杂的输入张量转换为一个小而简单的输出。`MaxPool2D`层有助于实现这一目标。它将我们第一个卷积层的输出浓缩成一个集中的、高级别的表示，其中包含的相关信息。

通过集中信息，我们开始剥离那些与识别输入中包含的手势无关的内容。只有在第一个卷积层的输出中最大程度地表示的最重要的特征被保留下来。有趣的是，即使我们的原始输入每次测量都有三个加速度计轴，但`Conv2D`和`MaxPool2D`的组合现在已经将它们合并成一个单一的值。

在我们将数据缩小后，它经过了一个[`Dropout`层](https://oreil.ly/JuQtU)：

```py
tf.keras.layers.Dropout(0.1),  # (batch, 42, 1, 8)
```

`Dropout`层在训练期间会随机将张量的一些值设为零。在这种情况下，通过调用`Dropout(0.1)`，我们将 10%的值设为零，完全消除了这些数据。这可能看起来像是一种奇怪的做法，让我们解释一下。

*Dropout*是一种正则化技术。正如本书前面提到的，*正则化*是改进机器学习模型的过程，使其不太可能过度拟合训练数据。Dropout 是一种简单但有效的限制过拟合的方法。通过在一层和下一层之间随机删除一些数据，我们迫使神经网络学习如何应对意外的噪音和变化。在层之间添加 dropout 是一种常见且有效的做法。

Dropout 层只在训练期间激活。在推断期间，它没有任何效果；所有数据都被允许通过。

在`Dropout`层之后，我们再次通过一个`MaxPool2D`层和一个`Dropout`层传递数据：

```py
tf.keras.layers.Conv2D(16, (4, 1), padding="same",
                        activation="relu"),  # (batch, 42, 1, 16)
```

这个层有 16 个过滤器和一个窗口大小为`(4, 1)`。这些数字是模型的超参数的一部分，在模型开发过程中通过迭代过程选择。设计一个有效的架构是一个反复试验的过程，这些神奇的数字是在经过大量实验后得出的。你不太可能第一次就选择到完全正确的值。

与第一个卷积层一样，这一层也学会了发现包含有意义信息的相邻值的模式。它的输出是给定输入内容的更高级表示。它识别的特征是我们第一个卷积层识别的特征的组合。

在这个卷积层之后，我们再做一次`MaxPool2D`和`Dropout`：

```py
tf.keras.layers.MaxPool2D((3, 1), padding="same"),  # (batch, 14, 1, 16)
tf.keras.layers.Dropout(0.1),  # (batch, 14, 1, 16)
```

这继续了将原始输入精炼为更小、更易管理的表示的过程。输出的形状为`(14, 1, 16)`，是一个多维张量，象征性地表示了输入数据中只包含的最重要的结构。

如果我们愿意，我们可以继续卷积和池化的过程。CNN 中的层数只是我们可以在模型开发过程中调整的另一个超参数。然而，在开发这个模型的过程中，我们发现两个卷积层已经足够了。

到目前为止，我们一直在通过卷积层运行我们的数据，这些层只关心相邻值之间的关系——我们并没有真正考虑更大的整体情况。然而，由于我们现在有了包含在我们输入中的主要特征的高级表示，我们可以“放大”并以总体方式研究它们。为此，我们将我们的数据展平并将其输入到一个`Dense`层（也称为*全连接层*）中：

```py
tf.keras.layers.Flatten(),  # (batch, 224)
tf.keras.layers.Dense(16, activation="relu"),  # (batch, 16)
```

[`Flatten`层](https://oreil.ly/TUIZc)用于将多维张量转换为具有单个维度的张量。在这种情况下，我们的`(14, 1, 16)`张量被压缩成一个形状为`(224)`的单个维度。

然后将其输入到具有 16 个神经元的[`Dense`层](https://oreil.ly/FbpDB)中。这是深度学习工具箱中最基本的工具之一：每个输入都连接到每个神经元的层。通过一次考虑所有数据，这一层可以学习各种输入组合的含义。这个`Dense`层的输出将是一组 16 个值，代表原始输入的内容以高度压缩的形式。

我们的最后任务是将这 16 个值缩小为 4 个类。为此，我们首先添加一些更多的 dropout，然后添加一个最终的`Dense`层：

```py
tf.keras.layers.Dropout(0.1),  # (batch, 16)
tf.keras.layers.Dense(4, activation="softmax")  # (batch, 4)
```

这一层有四个神经元；每个代表一个手势类。它们中的每一个都连接到前一层的所有 16 个输出。在训练过程中，每个神经元将学习与其代表的手势相对应的前一层激活的组合。

该层配置了一个`"softmax"`激活函数，导致该层的输出是一组总和为 1 的概率。这个输出是我们在模型输出张量中看到的。

这种模型架构——卷积和全连接层的组合——在分类时间序列传感器数据方面非常有用，比如我们从加速度计获取的测量数据。该模型学习识别代表特定输入类的“指纹”的高级特征。它小巧、运行快速，训练时间不长。这种架构将是您作为嵌入式机器学习工程师的宝贵工具。

# 使用您自己的数据进行训练

在本节中，我们将向您展示如何训练自己的自定义模型，以识别新的手势。我们将逐步介绍如何捕获加速度计数据，修改训练脚本以将其纳入，训练新模型，并将其集成到嵌入式应用程序中。

## 捕获数据

要获取训练数据，我们可以使用一个简单的程序在手势执行时将加速度计数据记录到串行端口。

### SparkFun Edge

快速入门的最快方法是修改[SparkFun Edge Board Support Package (BSP)](https://oreil.ly/z4eHX)中的一个示例。首先，按照 SparkFun 的[“使用 Ambiq Apollo3 SDK 与 SparkFun Edge Board”](https://oreil.ly/QqKPa)指南设置 Ambiq SDK 和 SparkFun Edge BSP。

下载 SDK 和 BSP 后，您需要调整示例代码以使其符合我们的要求。

首先，在您选择的文本编辑器中打开文件*AmbiqSuite-Rel2.2.0/boards/SparkFun_Edge_BSP/examples/example1_edge_test/src/tf_adc/tf_adc.c*。找到文件第 61 行的`am_hal_adc_samples_read()`调用：

```py
if (AM_HAL_STATUS_SUCCESS != am_hal_adc_samples_read(g_ADCHandle,
                                                     NULL,
                                                     &ui32NumSamples,
                                                     &Sample))
```

将其第二个参数更改为`true`，使整个函数调用看起来像这样：

```py
if (AM_HAL_STATUS_SUCCESS != am_hal_adc_samples_read(g_ADCHandle,
                                                     true,
                                                     &ui32NumSamples,
                                                     &Sample))
```

接下来，您需要修改文件*AmbiqSuite-Rel2.2.0/boards/SparkFun_Edge_BSP/examples/example1_edge_test/src/main.c*。找到第 51 行的`while`循环：

```py
/*
* Read samples in polling mode (no int)
*/
while(1)
{
    // Use Button 14 to break the loop and shut down
    uint32_t pin14Val = 1;
    am_hal_gpio_state_read( AM_BSP_GPIO_14, AM_HAL_GPIO_INPUT_READ, &pin14Val);
```

更改代码以添加以下额外行：

```py
/*
* Read samples in polling mode (no int)
*/
while(1)
{
    am_util_stdio_printf("-,-,-\r\n");
    // Use Button 14 to break the loop and shut down
    uint32_t pin14Val = 1;
    am_hal_gpio_state_read( AM_BSP_GPIO_14, AM_HAL_GPIO_INPUT_READ, &pin14Val);
```

现在在`while`循环中稍后找到这行：

```py
am_util_stdio_printf("Acc [mg] %04.2f x, %04.2f y, %04.2f z,
                     Temp [deg C] %04.2f, MIC0 [counts / 2¹⁴] %d\r\n",
        acceleration_mg[0], acceleration_mg[1], acceleration_mg[2],
        temperature_degC, (audioSample) );
```

删除原始行，并替换为以下内容：

```py
am_util_stdio_printf("%04.2f,%04.2f,%04.2f\r\n", acceleration_mg[0],
                     acceleration_mg[1], acceleration_mg[2]);
```

程序现在将以训练脚本所期望的格式输出数据。

接下来，按照[SparkFun 指南](https://oreil.ly/BPJMG)中的说明构建`example1_edge_test`示例应用程序并将其刷写到设备上。

### 记录数据

在构建和刷写示例代码之后，请按照以下说明捕获一些数据。

首先，打开一个新的终端窗口。然后运行以下命令开始将终端的所有输出记录到名为*output.txt*的文件中：

```py
script output.txt
```

接下来，在同一个窗口中，使用`screen`连接到设备：

```py
screen ${DEVICENAME} 115200
```

加速度计的测量结果将显示在屏幕上，并以逗号分隔的格式保存到*output.txt*中，这是训练脚本所期望的格式。

您应该努力在单个文件中捕获同一手势的多次表演。要开始捕获手势的单次表演，请按下标记为`RST`的按钮。字符`-,-,-`将被写入串口；训练脚本使用此输出来识别手势表演的开始。表演完手势后，按下标记为`14`的按钮停止记录数据。

当您多次记录相同手势时，通过按下 Ctrl-A，紧接着按 K 键，然后按 Y 键退出`screen`。退出`screen`后，输入以下命令停止将数据记录到*output.txt*：

```py
exit
```

现在您有一个包含一个人执行单个手势数据的文件*output.txt*。要训练一个全新的模型，您应该努力收集与原始数据集中相似数量的数据，该数据集包含 10 个人每个手势约 15 次表演。

如果您不在乎您的模型是否适用于其他人，您可能只需捕获自己的表现。尽管如此，您收集的表现变化越多，效果就会越好。

为了与训练脚本兼容，您应该按照以下格式重命名捕获的数据文件：

```py
output_<*gesture_name*>_<*person_name*>.txt

```

例如，由“Daniel”制作的假设“三角形”手势的数据将具有以下名称：

```py
output_triangle_Daniel.txt
```

训练脚本将期望数据以每个手势名称的目录组织；例如：

```py
data/
├── triangle
│   ├── output_triangle_Daniel.txt
│   └── ...
├── square
│   ├── output_square_Daniel.txt
│   └── ...
└── star
    ├── output_star_Daniel.txt
    └── ...
```

您还需要为“未知”类别提供数据，存储在名为*negative*的目录中。在这种情况下，您可以重复使用原始数据集中的数据文件。

请注意，因为模型架构设计为输出四个类别（三个手势加上“未知”）的概率，您应该提供自己的三个手势。如果您想要训练更多或更少的手势，您需要更改训练脚本并调整模型架构。

## 修改训练脚本

要使用新手势训练模型，您需要对训练脚本进行一些更改。

首先，用以下文件中的手势名称替换所有手势名称：

+   [*data_load.py*](https://oreil.ly/1Tplr)

+   [*data_prepare.py*](https://oreil.ly/O7eym)

+   [*data_split.py*](https://oreil.ly/w8ORq)

接下来，用以下文件中的人员名称替换所有人员名称：

+   [*data_prepare.py*](https://oreil.ly/3swnY)

+   [*data_split_person.py*](https://oreil.ly/xhVh7)

请注意，如果您有不同数量的人员名称（原始数据集有 10 个）并且您想在训练过程中按人员拆分数据，您需要决定一个新的拆分方式。如果您只有少数人的数据，将无法在训练过程中按人员拆分数据，所以不用担心*data_split_person.py*。

## 训练

要训练一个新模型，将您的数据文件目录复制到训练脚本的目录中，并按照本章前面介绍的过程进行操作。

如果您只有少数人的数据，应该随机拆分数据而不是按人员拆分。为此，在准备训练时，运行*data_split.py*而不是*data_split_person.py*。

因为你正在训练新手势，值得尝试调整模型的超参数以获得最佳准确性。例如，你可以尝试训练更多或更少的 epochs，或者使用不同排列的层或神经元数量，或者使用不同的卷积超参数来查看是否能获得更好的结果。你可以使用 TensorBoard 来监视你的进展。

一旦你有一个准确度可接受的模型，你需要对项目进行一些更改以确保它正常运行。

## 使用新模型

首先，你需要将由`xxd -i`格式化的新模型数据复制到*magic_wand_model_data.cc*中。确保你还更新`g_magic_wand_model_data_len`的值，以匹配`xxd`输出的数字。

接下来，在数组`should_continuous_count`中，你需要更新*accelerometer_handler.cc*中指定每个手势所需的连续预测次数的值。该值对应于手势执行所需的时间。鉴于原始的“翅膀”手势需要连续计数为 15，估算一下你的新手势相对于那个需要多长时间，然后更新数组中的值。你可以通过迭代调整这些值，直到获得最可靠的性能。

最后，更新*output_handler.cc*中的代码以打印你的新手势的正确名称。完成后，你可以构建你的代码并刷写你的设备。

# 总结

在本章中，我们深入探讨了典型嵌入式机器学习模型的架构。这种卷积模型是对时间序列数据进行分类的强大工具，你将经常遇到它。

到目前为止，希望你已经了解了嵌入式机器学习应用程序的外观，以及它们的应用代码如何与模型一起工作来理解周围的世界。当你构建自己的项目时，你将开始组建一个熟悉模型的工具箱，可以用来解决不同的问题。

## 学习机器学习

本书旨在提供对嵌入式机器学习可能性的初步介绍，但它并不是机器学习本身的完整参考资料。如果你想深入了解如何构建自己的模型，有一些令人惊叹且易于访问的资源适合各种背景的学生，并将为你提供一个良好的起点。

以下是一些我们喜欢的内容，将建立在你在这里学到的基础上：

+   François Chollet 的[*Python 深度学习*](https://oreil.ly/PFF3r)（Manning）

+   Aurélien Géron 的[*使用 Scikit-Learn、Keras 和 TensorFlow 进行实践机器学习，第二版*](https://oreil.ly/M5KrN)（O’Reilly）

+   Deeplearning.ai 的[深度学习专项](https://oreil.ly/xKQMP)和[TensorFlow 实践](https://oreil.ly/4q7HY)课程

+   Udacity 的[深度学习 TensorFlow 入门](https://oreil.ly/YJlYd)课程

## 接下来是什么

本书的剩余章节将更深入地探讨嵌入式机器学习的工具和工作流程。你将学习如何思考设计自己的 TinyML 应用程序，如何优化模型和应用代码以在低功耗设备上运行良好，如何将现有的机器学习模型移植到嵌入式设备上，以及如何调试嵌入式机器学习代码。我们还将解决一些高层次的问题，如部署、隐私和安全性。

但首先，让我们更多地了解一下 TensorFlow Lite，这是本书中所有示例的框架动力源。

¹ 这是一个新术语，我们稍后会谈论。
