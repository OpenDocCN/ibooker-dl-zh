- en: Chapter 20\. Privacy, Security, and Deployment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第20章 隐私、安全和部署
- en: After working through the previous chapters in this book, you should hopefully
    be able to build an embedded application that relies on machine learning. You’ll
    still need to navigate a lot of challenges, though, to turn your project into
    a product that can be successfully deployed into the world. Two key challenges
    are protecting the privacy and the security of your users. This chapter covers
    some of the approaches we’ve found useful for overcoming those challenges.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本书之前的章节后，您希望能够构建一个依赖于机器学习的嵌入式应用程序。然而，要将您的项目转化为可以成功部署到世界上的产品，您仍然需要应对许多挑战。保护用户的隐私和安全是两个关键挑战。本章介绍了一些我们发现有用的方法来克服这些挑战。
- en: Privacy
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 隐私
- en: Machine learning on-device relies on sensor inputs. Some of these sensors, like
    microphones and cameras, [raise obvious privacy concerns](https://oreil.ly/CEcsR),
    but even others, like accelerometers, can be abused; for example, to identify
    individuals from their gait when wearing your product. We all have a responsibility
    as engineers to safeguard our users from damage that our products can cause, so
    it’s vital to think about privacy at all stages of the design. There are also
    legal implications to handling sensitive user data that are beyond the scope of
    our coverage but about which you should consult your lawyers. If you’re part of
    a large organization, you might have privacy specialists and processes that can
    help you with specialist knowledge. Even if you don’t have access to those resources,
    you should spend some time running your own privacy review at the outset of the
    project, and periodically revisit it until you launch. There isn’t widespread
    agreement on what a “privacy review” actually is, but we discuss some best practices,
    most of which revolve around building a strong Privacy Design Document (PDD).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 设备上的机器学习依赖于传感器输入。其中一些传感器，如麦克风和摄像头，引发了明显的隐私问题，但甚至其他传感器，如加速计，也可能被滥用；例如，通过识别个人的步态来识别他们在使用您的产品时。作为工程师，我们都有责任保护用户免受产品可能造成的损害，因此在设计的各个阶段都要考虑隐私是至关重要的。处理敏感用户数据还涉及法律责任，超出了我们的范围，但您应该咨询您的律师。如果您是大型组织的一部分，您可能有隐私专家和流程可以帮助您获得专业知识。即使您无法获得这些资源，您也应该花一些时间在项目开始时进行自己的隐私审查，并定期重新审查，直到项目上线。关于“隐私审查”到底是什么，目前还没有广泛的共识，但我们讨论了一些最佳实践，其中大部分围绕着建立强大的隐私设计文档（PDD）。
- en: The Privacy Design Document
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐私设计文档
- en: The field of [privacy engineering](https://oreil.ly/MEwUE) is still very new,
    and it can be difficult to find documentation on how to work through the privacy
    implications of a product. The way that many large companies handle the process
    of ensuring privacy in their applications is to create a Privacy Design Document.
    This is a single place where you can cover the important privacy aspects of your
    product. Your document should include information about all the topics raised
    in the subsections that follow.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[隐私工程](https://oreil.ly/MEwUE)领域仍然非常新颖，很难找到关于如何处理产品隐私影响的文档。许多大公司处理确保应用程序隐私的过程的方式是创建一个隐私设计文档。这是一个单一的地方，您可以涵盖产品的重要隐私方面。您的文档应包括以下各小节提到的所有主题的信息。'
- en: Data collection
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据收集
- en: The first section of the PDD should cover what data you’ll be gathering, how
    it will be gathered, and why. You should be as specific as possible and use plain
    English—for example, “collecting temperature and humidity” rather than “obtaining
    environmental atmospheric information.” While working on this section, you also
    have the opportunity to think about what you’re actually gathering, and ensure
    that it’s the minimum you need for your product. If you’re only listening for
    loud noises to wake up a more complex device, do you really need to sample audio
    at 16 KHz using a microphone, or can you use a cruder sensor that ensures you
    won’t be able to record speech even if there’s a security breach? A simple system
    diagram can be useful in this section, showing how the information flows between
    the different components in your product (including any cloud APIs). The overall
    goal of this section is to provide a good overview of what you’ll be collecting
    to a nontechnical audience, whether it’s your lawyers, executives, or board members.
    One way to think about it is how it would look on the front page of a newspaper,
    in a story written by an unsympathetic journalist. Make sure you’ve done everything
    you can to minimize your users’ exposure to malicious actions by others. In concrete
    terms, think through scenarios like “What could an abusive ex-partner do using
    this technology?” and try to be as imaginative as possible to ensure there’s as
    much protection built in as you can offer.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: PDD的第一部分应涵盖您将收集的数据、如何收集以及为什么收集。您应尽可能具体，并使用简单的英语，例如，“收集温度和湿度”而不是“获取环境大气信息”。在处理这一部分时，您还有机会思考您实际收集了什么，并确保这是您产品所需的最小数据。如果您只是在听大声噪音以唤醒更复杂的设备，您是否真的需要使用麦克风以16
    KHz采样音频，还是可以使用一个更简单的传感器，确保即使发生安全漏洞也无法录制语音？在这一部分中，一个简单的系统图可以很有用，显示信息在产品中不同组件之间的流动（包括任何云API）。这一部分的总体目标是向非技术人员提供对您将收集的内容的良好概述，无论是您的律师、高管还是董事会成员。一个思考方式是，如果由一位不友好的记者撰写的故事登在报纸头版上，会是什么样子。确保您已尽一切可能减少用户受到他人恶意行为的影响。具体而言，思考“一个虐待前任可能使用这项技术做什么？”等情景，并尽可能富有想象力，确保内置了尽可能多的保护措施。
- en: Data usage
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据使用
- en: What is done with any data after you’ve collected it? For example, many startups
    are tempted to leverage user data to train their machine learning models, but
    this is an extremely fraught process from a privacy perspective, because it requires
    storage and processing of potentially very sensitive information for long periods
    of time for only indirect user benefits. We strongly suggest treating training
    data acquisition as an entirely separate program, using paid providers with clear
    consent rather than collecting data as a side effect of product usage.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集数据后，对数据做了什么？例如，许多初创公司都会被诱惑利用用户数据来训练他们的机器学习模型，但从隐私角度来看，这是一个极其棘手的过程，因为它需要长时间存储和处理潜在非常敏感的信息，仅为间接用户利益。我们强烈建议将训练数据采集视为一个完全独立的程序，使用明确同意的付费提供者，而不是收集数据作为产品使用的副作用。
- en: One of the benefits of on-device machine learning is that you have the ability
    to process sensitive data locally and share only aggregated results. For example,
    you might have a pedestrian-counting device that captures images every second,
    but the only data that’s transmitted is a count of people and vehicles seen. If
    you can, try to engineer your hardware to ensure that these guarantees can’t be
    broken. If you’re using only 224 × 224–pixel images as inputs to a classification
    algorithm, use a camera sensor that’s also low-resolution so that it’s physically
    impossible to recognize faces or license plates. If you plan on transmitting only
    a few values as a summary (like the pedestrian counts), support only a wireless
    technology with low bit rates to avoid being able to transmit the source video
    even if your device is hacked. We’re hoping that in the future, [special-purpose
    hardware](https://oreil.ly/6E2Ya) will help enforce these guarantees, but even
    now there’s still a lot you can do at the system design level to avoid overengineering
    and make abuse more difficult.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在设备上进行机器学习的好处之一是您有能力在本地处理敏感数据并仅共享聚合结果。例如，您可能有一个行人计数设备，每秒捕获图像，但传输的唯一数据是看到的人和车辆的计数。如果可以的话，尽量设计您的硬件以确保这些保证不会被打破。如果您只使用224×224像素图像作为分类算法的输入，使用一个分辨率低的摄像头传感器，以便无法识别面孔或车牌。如果您计划仅传输几个值作为摘要（如行人计数），请仅支持低比特率的无线技术，以避免即使您的设备被黑客入侵也无法传输源视频。我们希望未来，专用硬件将有助于执行这些保证，但即使现在，在系统设计层面仍有很多事情可以做，以避免过度设计并使滥用更加困难。
- en: Data sharing and storage
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据共享和存储
- en: Who has access to the data you’ve gathered? What systems are in place to ensure
    that only those people can see it? How long is it kept, either on-device or in
    the cloud? If it is kept for any length of time, what are the policies on deleting
    it? You might think that storing information stripped of obvious user IDs like
    email addresses or names is safe, but identity can be derived from many sources,
    like IP addresses, recognizable voices, or even gaits, so you should assume that
    any sensor data you gather is personally identifiable information (PII). The best
    policy is to treat this kind of PII like radioactive waste. Avoid gathering it
    if you possibly can, keep it well guarded while you do need it, and dispose of
    it as quickly as possible after you’re done.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 谁可以访问您收集的数据？有什么系统可以确保只有这些人可以看到它？数据会保留多长时间，无论是在设备上还是在云端？如果数据被保留了一段时间，删除政策是什么？您可能认为存储剥离了明显用户ID（如电子邮件地址或姓名）的信息是安全的，但身份可以从许多来源推导出，比如IP地址、可识别的声音，甚至步态，因此您应该假设您收集的任何传感器数据都是个人可识别信息（PII）。最佳政策是将这种类型的PII视为放射性废物。如果可能的话，避免收集它，当您需要时要妥善保护它，并在完成后尽快处理它。
- en: When you think about who has access, don’t forget that all your permission systems
    can be overridden by government pressure, which can cause your users serious harm
    in repressive countries. That’s another reason to limit what is transmitted and
    stored to the bare minimum possible, to avoid that responsibility and limit your
    users’ exposure.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑谁可以访问时，不要忘记所有您的许可系统都可以被政府压力覆盖，这可能会给您的用户在压制国家造成严重伤害。这是限制传输和存储到最低限度的另一个原因，以避免这种责任并限制用户的暴露。
- en: Consent
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 同意
- en: Do the people using your product understand what information it’s gathering,
    and have they agreed to how you’ll use it? There’s a narrow legal question here
    that you might think can be answered by a click-through end-user license agreement,
    but we’d encourage you to think about this more broadly as a marketing challenge.
    Presumably you are convinced that the product benefits are worth the trade-off
    of gathering more data, so how can you communicate that to prospective customers
    clearly so that they make an informed choice? If you’re having trouble coming
    up with that message, that’s a sign you should rethink your design to reduce the
    privacy implications or increase the benefits of your product.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您的产品的人是否了解它正在收集什么信息，并且他们是否同意您将如何使用它？这里有一个狭窄的法律问题，您可能认为可以通过点击式最终用户许可协议来回答，但我们鼓励您将其更广泛地看作是一个营销挑战。假设您相信产品的好处值得收集更多数据，那么您如何清晰地向潜在客户传达这一点，以便他们做出知情选择？如果您在构思这条信息时遇到困难，那就是您应该重新考虑设计以减少隐私影响或增加产品的好处的迹象。
- en: Using a PDD
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PDD
- en: You should treat the PDD as a living document, updated constantly as your product
    evolves. It’s clearly useful for communicating product details to your lawyers
    and other business stakeholders, but it can also be useful in a lot of other contexts.
    For instance, you should collaborate with your marketing team to ensure that its
    messaging is informed by what you’re doing, and with any providers of third-party
    services (like advertising) to ensure they’re complying with what you’re promising.
    All of the engineers on the team should have access to it and be able to add comments,
    given that there might well be some hidden privacy implications that are visible
    only at the implementation level. For example, you might be using a geocoding
    cloud API that leaks the IP address of your device, or there might be a WiFi chip
    on your microcontroller that you’re not using but that could theoretically be
    enabled to transmit sensitive data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Security
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ensuring total security of an embedded device is very hard. An attacker can
    easily gain physical possession of a system, and then use all sorts of intrusive
    techniques to extract information. Your first line of defense is ensuring that
    as little sensitive information as possible is retained on your embedded system,
    which is why the PDD is so important. If you are relying on secure communications
    with a cloud service, you should think about investigating [secure cryptoprocessors](https://oreil.ly/lGLzA)
    to ensure that any keys are held safely. These chips can also be used for secure
    booting, to make sure only the program you’ve flashed will run on the device.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: As with privacy, you should try to craft your hardware design to limit the opportunities
    for any attackers. If you don’t need WiFi or Bluetooth, build a device that doesn’t
    have those capabilities. [Don’t offer debug interfaces like SWD](https://oreil.ly/X1I7x)
    on shipping products, and look into [disabling code readout on Arm platforms](https://oreil.ly/ag5Vc).
    Even though these measures [aren’t perfect](https://oreil.ly/R3YG-), they will
    raise the cost of an attack.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: You should also try to rely on established libraries and services for security
    and encryption. Rolling your own cryptography is a very bad idea, because it’s
    very easy to make mistakes that are difficult to spot but destroy the security
    of your system. The full challenge of embedded system security is beyond the scope
    of this book, but you should think about creating a security design document,
    similar to the one we recommend for privacy. You should cover what you think likely
    attacks are, their impacts, and how you’ll defend against them.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Protecting Models
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We often hear from engineers who are concerned about protecting their machine
    learning models from unscrupulous competitors, because they require a lot of work
    to create but are shipped on-device and are usually in an easy-to-understand format.
    The bad news is that there is no absolute protection against copying. In this
    sense, models are like any other software: they can be stolen and examined just
    like regular machine code. Like with software, though, the problem is not as bad
    as it might seem at first. Just as disassembling a procedural program doesn’t
    reveal the true source code, examining a quantized model doesn’t offer any access
    to the training algorithm or data, so attackers won’t be able to effectively modify
    the model for any other use. It should also be pretty easy to spot a direct copy
    of a model if it’s shipped on a competitor’s device and prove legally that the
    competitor stole your intellectual property, just as you can with any other software.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: It can still be worthwhile to make it harder for casual attackers to access
    your model. A simple technique is to store your serialized model in flash after
    XOR-ing it with a private key and then copy it into RAM and unencrypt it before
    use. That will prevent a simple dump of flash from revealing your model, but an
    attacker with access to RAM at runtime will still be able to access it. You might
    think that switching away from a TensorFlow Lite FlatBuffer to a proprietary format
    would help, but because the weight parameters themselves are large arrays of numerical
    values and it’s obvious from stepping through a debugger what operations are called
    in which order, we’ve found the value of this kind of obfuscation very limited.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: One fun approach to use for spotting misappropriation of models is deliberately
    building in subtle flaws as part of the training process, and then looking out
    for them when checking suspected infringements. As an example, you could train
    a wake-word detection model to not only listen out for “Hello,” but also secretly
    “Ahoy, sailor!” It’s extremely unlikely that an independently trained model would
    show a response for that same phrase, so if there is one, it’s a strong signal
    that the model was copied, even if you can’t access the internal workings of a
    device. This technique is based on the old idea of including a fictitious entry
    in reference works such as maps, directories, and dictionaries to help spot copyright
    infringements; it has come to be known as *mountweazeling* after the practice
    of placing [a fictitious mountain](https://oreil.ly/OpY2G), “Mountweazel,” on
    maps to help identify copies.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With modern microcontrollers it’s very tempting to enable over-the-air updates
    so you have the ability to revise the code that’s running on your device at any
    time, even long after shipping. This opens up such a wide attack surface for security
    and privacy violations that we urge you to consider whether it is truly essential
    for your product. It’s difficult to ensure that only you have the ability to upload
    new code without a well-designed secure booting system and other protections,
    and if you make a mistake, you’ve handed complete control of your device to malicious
    actors. As a default, we recommend that you don’t allow any kind of code updating
    after a device has been manufactured. This might sound draconian, given that it
    prevents updates that fix security holes, for example, but in almost all cases
    removing the possibility of attackers’ code being run on the system will help
    security much more than it hurts. It also simplifies the network architecture,
    because there’s no longer a need for any protocol to “listen” for updates; the
    device might effectively be able to operate in a transmit-only mode, which also
    greatly reduces the attack surface.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: This does mean that there’s much more of a burden on you to get the code right
    before a device is released, especially with regard to the model accuracy. We
    talked earlier about approaches like unit tests and verifying overall model accuracy
    against a dedicated test set, but they won’t catch all problems. When you’re preparing
    for a release, we highly recommend using a dog-fooding approach in which you try
    the devices in real-world environments, but under the supervision of organization
    insiders. These experiments are a lot more likely to reveal unexpected behaviors
    than engineering tests, because tests are limited by the imagination of their
    creators, and the real world is much more surprising than any of us can predict
    ahead of time. The good news is that after you have encountered undesirable behaviors,
    you can then turn them into test cases that can be tackled as part of your normal
    development process. In fact, developing this kind of institutional memory of
    the deep requirements of your product, codified into tests, can be one of your
    biggest competitive advantages, in so much as the only way to acquire it is by
    painful trial and error.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Moving from a Development Board to a Product
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从开发板转向产品
- en: The full process of turning an application running on a development board into
    a shipping product is beyond the scope of this book, but there are some things
    worth thinking about during the development process. You should research the bulk
    prices of the microcontroller you’re considering using—for example, on sites like
    [Digi-Key](https://digikey.com)—to make sure that the system you’re targeting
    will fit your budget in the end. It should be fairly straightforward to move your
    code to a production device assuming that it’s the same chip you were using during
    development, so from a programming perspective, the main imperative is to ensure
    that your development board matches your production target. Debugging any issues
    that arise will become a lot harder after your code is deployed in a final form
    factor, especially if you’ve taken the steps described earlier to secure your
    platform, so it’s worth delaying that step as long as you can.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 将在开发板上运行的应用程序转变为成品的完整过程超出了本书的范围，但在开发过程中有一些值得考虑的事项。您应该研究您考虑使用的微控制器的批量价格，例如在[Digi-Key](https://digikey.com)等网站上，以确保您最终的目标系统符合您的预算。假设您在开发过程中使用的是相同的芯片，将代码移植到生产设备应该相当简单，因此从编程的角度来看，主要任务是确保您的开发板与生产目标匹配。在您的代码以最终形式部署后，调试任何出现的问题将变得更加困难，尤其是如果您之前已经采取了保护平台的步骤，因此尽可能推迟这一步骤是值得的。
- en: Wrapping Up
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Safeguarding our users’ privacy and security is one of our most important responsibilities
    as engineers, but it’s not always clear how to decide on the best approaches.
    In this chapter, we covered the basic process of thinking about and designing
    in protections, and some more advanced security considerations. With that, we’ve
    completed the foundations of building and deploying an embedded machine learning
    application, but we know that there’s far more to this area than we could cover
    in a single book. To finish off, the final chapter discusses resources that you
    can use to continue learning more.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 保护用户的隐私和安全是我们作为工程师的最重要责任之一，但如何决定最佳方法并不总是清晰的。在本章中，我们涵盖了思考和设计保护措施的基本过程，以及一些更高级的安全考虑。通过这些内容，我们完成了构建和部署嵌入式机器学习应用的基础，但我们知道这个领域远不止我们在一本书中能涵盖的内容。最后一章讨论了您可以使用的资源，以继续学习更多。
