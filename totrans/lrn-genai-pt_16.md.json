["```py\n!pip install music21\n```", "```py\n%matplotlib inline                                          ①\nfrom music21 import midi, environment\n\nmf = midi.MidiFile()    \nmf.open(\"files/example.midi\")                               ②\nmf.read()\nmf.close()\nstream = midi.translate.midiFileToStream(mf)\nus = environment.Environment() \npath = r'C:\\Program Files\\MuseScore 4\\bin\\MuseScore4.exe'\nus['musescoreDirectPNGPath'] = path                         ③\nstream.show()                                               ④\n```", "```py\nstream.plot()\n```", "```py\nfor n in stream.recurse().notes:\n    print(n.offset, n.pitches)\n```", "```py\n0.0 (<music21.pitch.Pitch E4>,)\n0.25 (<music21.pitch.Pitch A4>,)\n0.5 (<music21.pitch.Pitch G4>,)\n0.75 (<music21.pitch.Pitch F4>,)\n1.0 (<music21.pitch.Pitch E4>,)\n1.25 (<music21.pitch.Pitch D4>,)\n1.75 (<music21.pitch.Pitch E4>,)\n2.0 (<music21.pitch.Pitch E4>,)\n2.5 (<music21.pitch.Pitch D4>,)\n3.0 (<music21.pitch.Pitch C4>,)\n3.25 (<music21.pitch.Pitch A3>,)\n3.75 (<music21.pitch.Pitch B3>,)\n0.0 (<music21.pitch.Pitch G3>,)\n0.25 (<music21.pitch.Pitch A3>,)\n0.5 (<music21.pitch.Pitch B3>,)\n…\n3.25 (<music21.pitch.Pitch F2>,)\n3.75 (<music21.pitch.Pitch E2>,)\n```", "```py\nfor n in stream.recurse().notes:\n    print(n.offset,n.pitches[0].midi)\n```", "```py\n0.0 64\n0.25 69\n0.5 67\n0.75 65\n1.0 64\n1.25 62\n1.75 64\n2.0 64\n2.5 62\n3.0 60\n3.25 57\n3.75 59\n0.0 55\n0.25 57\n0.5 59\n…\n3.25 41\n3.75 40\n```", "```py\nfrom torch.utils.data import DataLoader\nfrom utils.midi_util import MidiDataset\n\ndataset = MidiDataset('files/Jsb16thSeparated.npz')\nfirst_song=dataset[0]\nprint(first_song.shape)\nloader = DataLoader(dataset, batch_size=64, \n                        shuffle=True, drop_last=True)\n```", "```py\ntorch.Size([4, 2, 16, 84])\n```", "```py\nflat=first_song.reshape(-1,)\nprint(set(flat.tolist()))\n```", "```py\n{1.0, -1.0}\n```", "```py\nimport numpy as np\nfrom music21 import note, stream, duration, tempo\n\nparts = stream.Score()\nparts.append(tempo.MetronomeMark(number=66))\nmax_pitches = np.argmax(first_song, axis=-1)                ①\nmidi_note_score = max_pitches.reshape([2 * 16, 4])          ②\nprint(midi_note_score)\n```", "```py\ntensor([[74, 74, 74, 74],\n…\n        [70, 70, 69, 69],\n        [67, 67, 69, 69],\n        [70, 70, 70, 70],\n        [69, 69, 69, 69],\n        [69, 69, 69, 69],\n        [65, 65, 65, 65],\n        [58, 58, 60, 60],\n…\n        [53, 53, 53, 53]])\n```", "```py\nfor i in range(4):                                         ①\n    last_x = int(midi_note_score[:, i][0])\n    s = stream.Part()\n    dur = 0\n    for idx, x in enumerate(midi_note_score[:, i]):        ②\n        x = int(x)\n        if (x != last_x or idx % 4 == 0) and idx > 0:\n            n = note.Note(last_x)\n            n.duration = duration.Duration(dur)\n            s.append(n)\n            dur = 0\n        last_x = x\n        dur = dur + 0.25                                   ③\n    n = note.Note(last_x)\n    n.duration = duration.Duration(dur)\n    s.append(n)                                            ④\n    parts.append(s)  \nparts.write(\"midi\",\"files/first_song.midi\")\n```", "```py\nclass MuseCritic(nn.Module):\n    def __init__(self,hid_channels=128,hid_features=1024,\n        out_features=1,n_tracks=4,n_bars=2,n_steps_per_bar=16,\n        n_pitches=84):\n        super().__init__()\n        self.n_tracks = n_tracks\n        self.n_bars = n_bars\n        self.n_steps_per_bar = n_steps_per_bar\n        self.n_pitches = n_pitches\n        in_features = 4 * hid_channels if n_bars == 2\\\n            else 12 * hid_channels\n        self.seq = nn.Sequential(\n            nn.Conv3d(self.n_tracks, hid_channels, \n                      (2, 1, 1), (1, 1, 1), padding=0),      ①\n            nn.LeakyReLU(0.3, inplace=True),\n            nn.Conv3d(hid_channels, hid_channels, \n              (self.n_bars - 1, 1, 1), (1, 1, 1), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            nn.Conv3d(hid_channels, hid_channels, \n                      (1, 1, 12), (1, 1, 12), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            nn.Conv3d(hid_channels, hid_channels, \n                      (1, 1, 7), (1, 1, 7), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            nn.Conv3d(hid_channels, hid_channels, \n                      (1, 2, 1), (1, 2, 1), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            nn.Conv3d(hid_channels, hid_channels, \n                      (1, 2, 1), (1, 2, 1), padding=0),\n            nn.LeakyReLU(0.3, inplace=True),\n            nn.Conv3d(hid_channels, 2 * hid_channels, \n                      (1, 4, 1), (1, 2, 1), padding=(0, 1, 0)),\n            nn.LeakyReLU(0.3, inplace=True),\n            nn.Conv3d(2 * hid_channels, 4 * hid_channels,     \n                      (1, 3, 1), (1, 2, 1), padding=(0, 1, 0)),\n            nn.LeakyReLU(0.3, inplace=True),\n            nn.Flatten(),                                     ②\n            nn.Linear(in_features, hid_features),\n            nn.LeakyReLU(0.3, inplace=True),\n            nn.Linear(hid_features, out_features))            ③\n    def forward(self, x):  \n        return self.seq(x)\n```", "```py\nclass TemporalNetwork(nn.Module):\n    def __init__(self,z_dimension=32,hid_channels=1024,n_bars=2):\n        super().__init__()\n        self.n_bars = n_bars\n        self.net = nn.Sequential(\n            Reshape(shape=[z_dimension, 1, 1]),                ①\n            nn.ConvTranspose2d(z_dimension,hid_channels,\n                kernel_size=(2, 1),stride=(1, 1),padding=0,),\n            nn.BatchNorm2d(hid_channels),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(hid_channels,z_dimension,\n                kernel_size=(self.n_bars - 1, 1),stride=(1, 1),\n                padding=0,),\n            nn.BatchNorm2d(z_dimension),\n            nn.ReLU(inplace=True),\n            Reshape(shape=[z_dimension, self.n_bars]),)        ②\n    def forward(self, x):\n        return self.net(x)\n```", "```py\nclass BarGenerator(nn.Module):\n    def __init__(self,z_dimension=32,hid_features=1024,hid_channels=512,\n        out_channels=1,n_steps_per_bar=16,n_pitches=84):\n        super().__init__()\n        self.n_steps_per_bar = n_steps_per_bar\n        self.n_pitches = n_pitches\n        self.net = nn.Sequential(\n            nn.Linear(4 * z_dimension, hid_features),              ①\n            nn.BatchNorm1d(hid_features),\n            nn.ReLU(inplace=True),\n            Reshape(shape=[hid_channels,hid_features//hid_channels,1]),    \n            nn.ConvTranspose2d(hid_channels,hid_channels,\n               kernel_size=(2, 1),stride=(2, 1),padding=0),        ②\n            nn.BatchNorm2d(hid_channels),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(hid_channels,hid_channels // 2,\n                kernel_size=(2, 1),stride=(2, 1),padding=0),\n            nn.BatchNorm2d(hid_channels // 2),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(hid_channels // 2,hid_channels // 2,\n                kernel_size=(2, 1),stride=(2, 1),padding=0),\n            nn.BatchNorm2d(hid_channels // 2),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(hid_channels // 2,hid_channels // 2,\n                kernel_size=(1, 7),stride=(1, 7),padding=0),\n            nn.BatchNorm2d(hid_channels // 2),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(hid_channels // 2,out_channels,\n                kernel_size=(1, 12),stride=(1, 12),padding=0),\n            Reshape([1, 1, self.n_steps_per_bar, self.n_pitches])) ③\n    def forward(self, x):\n        return self.net(x)\n```", "```py\nclass MuseGenerator(nn.Module):\n    def __init__(self,z_dimension=32,hid_channels=1024,\n        hid_features=1024,out_channels=1,n_tracks=4,\n        n_bars=2,n_steps_per_bar=16,n_pitches=84):\n        super().__init__()\n        self.n_tracks = n_tracks\n        self.n_bars = n_bars\n        self.n_steps_per_bar = n_steps_per_bar\n        self.n_pitches = n_pitches\n        self.chords_network=TemporalNetwork(z_dimension, \n                            hid_channels, n_bars=n_bars)\n        self.melody_networks = nn.ModuleDict({})\n        for n in range(self.n_tracks):\n            self.melody_networks.add_module(\n                \"melodygen_\" + str(n),\n                TemporalNetwork(z_dimension, \n                 hid_channels, n_bars=n_bars))\n        self.bar_generators = nn.ModuleDict({})\n        for n in range(self.n_tracks):\n            self.bar_generators.add_module(\n                „bargen_\" + str(n),BarGenerator(z_dimension,\n            hid_features,hid_channels // 2,out_channels,\n            n_steps_per_bar=n_steps_per_bar,n_pitches=n_pitches))\n    def forward(self,chords,style,melody,groove):\n        chord_outs = self.chords_network(chords)\n        bar_outs = []\n        for bar in range(self.n_bars):                           ①\n            track_outs = []\n            chord_out = chord_outs[:, :, bar]\n            style_out = style\n            for track in range(self.n_tracks):                   ②\n                melody_in = melody[:, track, :]\n                melody_out = self.melody_networks[\"melodygen_\"\\\n                          + str(track)](melody_in)[:, :, bar]\n                groove_out = groove[:, track, :]\n                z = torch.cat([chord_out, style_out, melody_out,\\\n                               groove_out], dim=1)               ③\n                track_outs.append(self.bar_generators[\"bargen_\"\\\n                                          + str(track)](z))      ④\n            track_out = torch.cat(track_outs, dim=1)\n            bar_outs.append(track_out)\n        out = torch.cat(bar_outs, dim=2)                         ⑤\n        return out\n```", "```py\nimport torch\nfrom utils.MuseGAN_util import (init_weights, MuseGenerator, MuseCritic)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ngenerator = MuseGenerator(z_dimension=32, hid_channels=1024, \n              hid_features=1024, out_channels=1).to(device)\ncritic = MuseCritic(hid_channels=128,\n                    hid_features=1024,\n                    out_features=1).to(device)\ngenerator = generator.apply(init_weights)\ncritic = critic.apply(init_weights) \n```", "```py\ndef loss_fn(pred, target):\n    return -torch.mean(pred*target)\n```", "```py\nclass GradientPenalty(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, inputs, outputs):\n        grad = torch.autograd.grad(\n            inputs=inputs,\n            outputs=outputs,\n            grad_outputs=torch.ones_like(outputs),\n            create_graph=True,\n            retain_graph=True,\n        )[0]\n        grad_=torch.norm(grad.view(grad.size(0),-1),p=2,dim=1)\n        penalty = torch.mean((1\\. - grad_) ** 2)\n        return penalty\n```", "```py\nlr = 0.001\ng_optimizer = torch.optim.Adam(generator.parameters(),\n                               lr=lr, betas=(0.5, 0.9))\nc_optimizer = torch.optim.Adam(critic.parameters(),\n                               lr=lr, betas=(0.5, 0.9))\n```", "```py\nfrom utils.MuseGAN_util import loss_fn, GradientPenalty\n\nbatch_size=64\nrepeat=5\ndisplay_step=10\nepochs=500                                                         ①\nalpha=torch.rand((batch_size,1,1,1,1)).requires_grad_().to(device) ②\ngp=GradientPenalty()                                               ③\n\ndef noise():                                                       ④\n    chords = torch.randn(batch_size, 32).to(device)\n    style = torch.randn(batch_size, 32).to(device)\n    melody = torch.randn(batch_size, 4, 32).to(device)\n    groove = torch.randn(batch_size, 4, 32).to(device)\n    return chords,style,melody,groove\n```", "```py\ndef train_epoch():\n    e_gloss = 0\n    e_closs = 0\n    for real in loader:                                            ①\n        real = real.to(device)\n        for _ in range(repeat):                                    ②\n            chords,style,melody,groove=noise()\n            c_optimizer.zero_grad()\n            with torch.no_grad():\n                fake = generator(chords, style, melody,groove).detach()\n            realfake = alpha * real + (1 - alpha) * fake\n            fake_pred = critic(fake)\n            real_pred = critic(real)\n            realfake_pred = critic(realfake)\n            fake_loss =  loss_fn(fake_pred,-torch.ones_like(fake_pred))\n            real_loss = loss_fn(real_pred,torch.ones_like(real_pred))\n            penalty = gp(realfake, realfake_pred)\n            closs = fake_loss + real_loss + 10 * penalty           ③\n            closs.backward(retain_graph=True)\n            c_optimizer.step()\n            e_closs += closs.item() / (repeat*len(loader))\n        g_optimizer.zero_grad()\n        chords,style,melody,groove=noise()\n        fake = generator(chords, style, melody, groove)\n        fake_pred = critic(fake)\n        gloss = loss_fn(fake_pred, torch.ones_like(fake_pred))     ④\n        gloss.backward()\n        g_optimizer.step()\n        e_gloss += gloss.item() / len(loader)\n    return e_gloss, e_closs \n```", "```py\nfor epoch in range(1,epochs+1):\n    e_gloss, e_closs = train_epoch()\n    if epoch % display_step == 0:\n        print(f\"Epoch {epoch}, G loss {e_gloss} C loss {e_closs}\")\n```", "```py\ntorch.save(generator.state_dict(),'files/MuseGAN_G.pth')\n```", "```py\ngenerator.load_state_dict(torch.load('files/MuseGAN_G.pth',\n    map_location=device))\n```", "```py\nnum_pieces = 5\nchords = torch.rand(num_pieces, 32).to(device)\nstyle = torch.rand(num_pieces, 32).to(device)\nmelody = torch.rand(num_pieces, 4, 32).to(device)\ngroove = torch.rand(num_pieces, 4, 32).to(device)\n```", "```py\npreds = generator(chords, style, melody, groove).detach()\n```", "```py\nfrom utils.midi_util import convert_to_midi\n\nmusic_data = convert_to_midi(preds.cpu().numpy())\nmusic_data.write('midi', 'files/MuseGAN_song.midi')\n```"]