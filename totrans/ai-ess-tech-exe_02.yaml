- en: 'Chapter 2\. The #1 Mistake Companies Make with AI'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the first questions I ask tech leaders is how they plan to improve AI
    reliability, performance, or user satisfaction. If the answer is “We just bought
    XYZ tool for that, so we’re good,” I know they’re headed for trouble. Focusing
    on tools over processes is a red flag and the biggest mistake I see executives
    make when it comes to AI.
  prefs: []
  type: TYPE_NORMAL
- en: Improvement Requires Process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Assuming that buying a tool will solve your AI problems is like joining a gym
    but not actually going. You’re not going to see improvement by just throwing money
    at the problem. Tools are only the first step; the real work comes after. For
    example, the metrics that come built-in to many tools rarely correlate with what
    you actually care about. Instead, you need to design metrics that are specific
    to your business, along with tests to evaluate your AI’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: The data you get from these tests should also be reviewed regularly to make
    sure you’re on track. No matter what area of AI you’re working on—model evaluation,
    retrieval-augmented generation (RAG), or prompting strategies—the process is what
    matters most. Of course, there’s more to making improvements than just relying
    on tools and metrics. You also need to develop and follow processes.
  prefs: []
  type: TYPE_NORMAL
- en: Rechat’s Success Story
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rechat is a great example of how focusing on processes can lead to real improvements.
    The company decided to build an AI agent for real estate agents to help with a
    large variety of tasks related to different aspects of the job. However, they
    were struggling with consistency. When the agent worked, it was great, but when
    it didn’t, it was a disaster. The team would make a change to address a failure
    mode in one place but end up causing issues in other areas. They were stuck in
    a cycle of whack-a-mole. They didn’t have visibility into their AI’s performance
    beyond “vibe checks,” and their prompts were becoming increasingly unwieldy.
  prefs: []
  type: TYPE_NORMAL
- en: When I came in to help, the first thing I did was apply a systematic approach
    that is illustrated in [Figure 2-1](#fig0201).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aete_02in01.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. The virtuous cycle^([1](ch02.html#id131))
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This is a virtuous cycle for systematically improving large language models
    (LLMs). The key insight is that you need both quantitative and qualitative feedback
    loops that are *fast*. You start with LLM invocations (both synthetic and human-generated),
    then simultaneously:'
  prefs: []
  type: TYPE_NORMAL
- en: Run unit tests to catch regressions and verify expected behaviors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collect detailed logging traces to understand model behavior.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These feed into evaluation and curation (which needs to be increasingly automated
    over time). The eval process combines:'
  prefs: []
  type: TYPE_NORMAL
- en: Human review
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model-based evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A/B testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The results then inform two parallel streams:'
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning with carefully curated data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prompt engineering improvements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These both feed into model improvements, which starts the cycle again. The dashed
    line around the edge emphasizes this as a continuous, iterative process—you keep
    cycling through faster and faster to drive continuous improvement. By focusing
    on the processes outlined in this diagram, Rechat was able to reduce its error
    rate by over 50% without investing in new tools!
  prefs: []
  type: TYPE_NORMAL
- en: Check out this [~15-minute video](https://oreil.ly/M8KW2) on how we implemented
    this process-first approach at Rechat.
  prefs: []
  type: TYPE_NORMAL
- en: Avoid the Red Flags
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Instead of asking which tools you should invest in, you should be asking your
    team:'
  prefs: []
  type: TYPE_NORMAL
- en: What are our failure rates for different features or use cases?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What categories of errors are we seeing?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the AI have the proper context to help users? How is this being measured?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the impact of recent changes to the AI?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The answers to each of these questions should involve appropriate metrics and
    a systematic process for measuring, reviewing, and improving them. If your team
    struggles to answer these questions *with data and metrics*, you are in danger
    of going off the rails!
  prefs: []
  type: TYPE_NORMAL
- en: Avoiding Jargon Is Critical
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We’ve talked about why focusing on processes is better than just buying tools.
    But there’s one more thing that’s just as important: how we talk about AI. Using
    the wrong words can hide real problems and slow down progress. To focus on processes,
    we need to use clear language and ask good questions. That’s why we provide an
    AI communication cheat sheet for executives in [Chapter 3](ch03.html#ch_glossary).
    That chapter helps you:'
  prefs: []
  type: TYPE_NORMAL
- en: Understand what AI can and can’t do
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ask questions that lead to real improvements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that everyone on your team can participate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using this cheat sheet will help you talk about processes, not just tools. It’s
    not about knowing every tech word. It’s about asking the right questions to understand
    how well your AI is working and how to make it better.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch02.html#id131-marker)) Diagram adapted from my blog post, [“Your AI
    Product Needs Evals”](https://hamel.dev/blog/posts/evals).
  prefs: []
  type: TYPE_NORMAL
