- en: 'Chapter 2\. The #1 Mistake Companies Make with AI'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the first questions I ask tech leaders is how they plan to improve AI
    reliability, performance, or user satisfaction. If the answer is “We just bought
    XYZ tool for that, so we’re good,” I know they’re headed for trouble. Focusing
    on tools over processes is a red flag and the biggest mistake I see executives
    make when it comes to AI.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Improvement Requires Process
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Assuming that buying a tool will solve your AI problems is like joining a gym
    but not actually going. You’re not going to see improvement by just throwing money
    at the problem. Tools are only the first step; the real work comes after. For
    example, the metrics that come built-in to many tools rarely correlate with what
    you actually care about. Instead, you need to design metrics that are specific
    to your business, along with tests to evaluate your AI’s performance.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: The data you get from these tests should also be reviewed regularly to make
    sure you’re on track. No matter what area of AI you’re working on—model evaluation,
    retrieval-augmented generation (RAG), or prompting strategies—the process is what
    matters most. Of course, there’s more to making improvements than just relying
    on tools and metrics. You also need to develop and follow processes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Rechat’s Success Story
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rechat is a great example of how focusing on processes can lead to real improvements.
    The company decided to build an AI agent for real estate agents to help with a
    large variety of tasks related to different aspects of the job. However, they
    were struggling with consistency. When the agent worked, it was great, but when
    it didn’t, it was a disaster. The team would make a change to address a failure
    mode in one place but end up causing issues in other areas. They were stuck in
    a cycle of whack-a-mole. They didn’t have visibility into their AI’s performance
    beyond “vibe checks,” and their prompts were becoming increasingly unwieldy.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: When I came in to help, the first thing I did was apply a systematic approach
    that is illustrated in [Figure 2-1](#fig0201).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aete_02in01.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. The virtuous cycle^([1](ch02.html#id131))
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This is a virtuous cycle for systematically improving large language models
    (LLMs). The key insight is that you need both quantitative and qualitative feedback
    loops that are *fast*. You start with LLM invocations (both synthetic and human-generated),
    then simultaneously:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: Run unit tests to catch regressions and verify expected behaviors.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collect detailed logging traces to understand model behavior.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These feed into evaluation and curation (which needs to be increasingly automated
    over time). The eval process combines:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Human review
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model-based evaluation
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A/B testing
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The results then inform two parallel streams:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning with carefully curated data
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prompt engineering improvements
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These both feed into model improvements, which starts the cycle again. The dashed
    line around the edge emphasizes this as a continuous, iterative process—you keep
    cycling through faster and faster to drive continuous improvement. By focusing
    on the processes outlined in this diagram, Rechat was able to reduce its error
    rate by over 50% without investing in new tools!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这两者都会促进模型改进，从而再次启动循环。边缘的虚线强调这是一个持续、迭代的进程——你不断地更快地循环，以推动持续改进。通过关注图中概述的过程，Rechat能够将错误率降低超过50%，而无需投资新工具！
- en: Check out this [~15-minute video](https://oreil.ly/M8KW2) on how we implemented
    this process-first approach at Rechat.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 查看这个[约15分钟的视频](https://oreil.ly/M8KW2)，了解Rechat如何实施这种以过程为先的方法。
- en: Avoid the Red Flags
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免红旗
- en: 'Instead of asking which tools you should invest in, you should be asking your
    team:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是询问你应该投资哪些工具，你应该询问你的团队：
- en: What are our failure rates for different features or use cases?
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们对不同功能或用例的失败率是多少？
- en: What categories of errors are we seeing?
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们看到了哪些错误类别？
- en: Does the AI have the proper context to help users? How is this being measured?
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI是否具有适当的上下文来帮助用户？这是如何衡量的？
- en: What is the impact of recent changes to the AI?
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近AI的变化有什么影响？
- en: The answers to each of these questions should involve appropriate metrics and
    a systematic process for measuring, reviewing, and improving them. If your team
    struggles to answer these questions *with data and metrics*, you are in danger
    of going off the rails!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 每个问题的答案都应该涉及适当的指标和一套用于衡量、审查和改进它们的系统化流程。如果你的团队在*数据和指标*方面难以回答这些问题，你就有可能偏离轨道！
- en: Avoiding Jargon Is Critical
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免术语至关重要
- en: 'We’ve talked about why focusing on processes is better than just buying tools.
    But there’s one more thing that’s just as important: how we talk about AI. Using
    the wrong words can hide real problems and slow down progress. To focus on processes,
    we need to use clear language and ask good questions. That’s why we provide an
    AI communication cheat sheet for executives in [Chapter 3](ch03.html#ch_glossary).
    That chapter helps you:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了为什么关注过程比仅仅购买工具更好。但还有一件事同样重要：我们如何谈论AI。使用错误的词语可能会隐藏真正的问题并减缓进步。为了关注过程，我们需要使用清晰的语言并提出好的问题。这就是为什么我们在[第3章](ch03.html#ch_glossary)为高管们提供了一个AI沟通速查表。该章节帮助你：
- en: Understand what AI can and can’t do
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解AI能做什么和不能做什么
- en: Ask questions that lead to real improvements
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提出能带来真正改进的问题
- en: Ensure that everyone on your team can participate
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保你团队中的每个人都能参与进来
- en: Using this cheat sheet will help you talk about processes, not just tools. It’s
    not about knowing every tech word. It’s about asking the right questions to understand
    how well your AI is working and how to make it better.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个速查表将帮助你谈论过程，而不仅仅是工具。这不仅仅关于知道每个技术术语。这关乎提出正确的问题，以了解你的AI工作得如何以及如何让它变得更好。
- en: ^([1](ch02.html#id131-marker)) Diagram adapted from my blog post, [“Your AI
    Product Needs Evals”](https://hamel.dev/blog/posts/evals).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch02.html#id131-marker)) 图表改编自我的博客文章，“你的AI产品需要评估”（[“Your AI Product Needs
    Evals”](https://hamel.dev/blog/posts/evals)）。
