- en: Chapter 3\. The Build and Pre-Deployment Testing Steps of Continuous Integration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Simply put, our modern software delivery practices provide a structure to help
    us plan, write, build, test, and deploy software. In [Chapter 2](ch02.html#chapter_2_source_control_management_1749354010078326),
    we looked at how SCM systems help track and manage changes as we write code.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we turn our attention to continuous integration. [Figure 3-1](#chapter_3_figure_1_1749354010256769)
    shows a CI/CD pipeline that we’ll look at shortly and return to in Chapters [4](ch04.html#chapter_4_deploying_to_test_environments_1749354010445896)
    and [8](ch08.html#chapter_8_feature_management_and_experimentation_1749354011197288).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ansd_0301.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-1\. A CI/CD pipeline
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We’ll explore the continuous integration pipeline with emphasis on build processes
    and pre-deployment testing (static scans, unit tests, and integration tests).
    We’ll demonstrate how an AI-native approach can accelerate CI through GenAI, agentic
    AI, and open standards such as MCP implementations. These technologies enable
    automated processes, predictive optimization, standardized context management,
    and intelligent testing strategies throughout the build, cache, and testing phases.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the key continuous integration steps, we’ll review continuous
    integration tools and discuss factors to consider when selecting one. You will
    come away with an understanding of how to improve efficiency, quality, and security
    in your build pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: A Short History of Building and Testing Software
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a familiar story. In 1947, while working on the Harvard Mark II computer,
    a team of engineers discovered a moth trapped in a relay, causing the machine
    to malfunction. They removed the moth and taped it into their logbook with the
    note “First actual case of bug being found,” thus solidifying the association
    of “bug” with software errors. Finding the bug in the machine accurately characterizes
    testing in the early days of software development. Developers would write code
    independently and integrate it. Testing was typically done manually and ad hoc.
    Teams focused on finding the bugs, ridding machines of “the moths” when errors
    were discovered. Bugs were typically found in production, resulting in delays
    and unreliable software.
  prefs: []
  type: TYPE_NORMAL
- en: As software development evolved, testing became more formalized and rigorous,
    with a focus on trying to “break” the software to uncover defects. Formal testing
    methodologies and standards began to emerge, such as the IEEE 829 Standard for
    Software and System Test Documentation (1983).
  prefs: []
  type: TYPE_NORMAL
- en: Structured Software Development and Waterfall Methodologies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Waterfall methodologies introduced a structured approach to software development,
    where testing became a distinct phase. Acceptance criteria, defined during requirements
    gathering, outlined the conditions the software must meet. Test cases were then
    developed and executed at the end of development to validate these criteria. Defects
    were documented and resolved until the software met all requirements. This formal
    approach, however, often resulted in a considerable delay between coding and testing,
    making early issue detection and resolution challenging and eventually resulting
    in a slower time-to-market for new products and features.
  prefs: []
  type: TYPE_NORMAL
- en: Agile and Test-Driven Development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [Chapter 1](ch01.html#chapter_1_the_road_to_ai_native_devops_1749354009875299),
    we discussed the emergence of Agile methodologies in software development, motivated
    by the inefficiencies and limitations of the waterfall development. Agile methodologies’
    more flexible and responsive development model emphasized frequent feedback and
    iterative development, necessitating new testing approaches that could keep pace
    with the rapid development cycles. This led to new testing approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Extreme Programming (XP), developed by Kent Beck, Ward Cunningham, and Ron Jeffries,
    was a specific Agile methodology defined by a set of best practices. One fundamental
    XP practice is test-driven development (TDD). In TDD, you write tests before writing
    the associated code. Beck’s influential book *Extreme Programming Explained*(Addison-Wesley),
    first published in 1999, popularized TDD to a wide audience, and early tools like
    JUnit (for Java) and NUnit (for .NET) provided developers with frameworks to easily
    write these types of tests before writing corresponding code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing tests before code encourages developers to think deeply about desired
    code behavior, leading to better design and fewer defects. While this concept
    existed previously, TDD’s specific approach of writing failing tests first and
    then coding to pass them aligned well with Agile’s focus on short cycles and frequent
    delivery of working software. This practice redefined the notion of completeness:
    *A feature isn’t done when the code is working, but when the automated tests are
    complete and passing.*'
  prefs: []
  type: TYPE_NORMAL
- en: The automated tests created during TDD provide a safety net, allowing developers
    to refactor code with confidence, knowing that any regressions will be quickly
    caught by the tests. This enables faster iteration and more frequent releases,
    which in turn allows for quicker feedback from customers and stakeholders. The
    tests themselves also serve as a form of documentation, clearly articulating the
    expected behavior of the system.
  prefs: []
  type: TYPE_NORMAL
- en: Enter Continuous Integration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we introduced in [Chapter 1](ch01.html#chapter_1_the_road_to_ai_native_devops_1749354009875299),
    CI is the practice of automating the integration of code changes from multiple
    contributors into a shared repository, frequently triggering automated builds
    and tests to ensure the software remains in a working state. This complemented
    TDD.
  prefs: []
  type: TYPE_NORMAL
- en: The [roots of CI](https://oreil.ly/neqmf) trace back to the 1990s. Grady Booch
    first coined the term “continuous integration” in 1991, but it was Kent Beck and
    Ron Jeffries who truly put it into practice while collaborating on a project in
    1997\. Their goal was to address the “integration hell” that arose from infrequent
    code merges, where conflicts and errors would pile up and become increasingly
    difficult to resolve.
  prefs: []
  type: TYPE_NORMAL
- en: Early CI systems were often custom-built and tailored to specific projects.
    One notable example was CruiseControl, created in 2001 by ThoughtWorks. It was
    one of the first open source CI servers, allowing teams to automate the building
    and testing of software with every code commit. However, it lacked a user-friendly
    interface and flexible job scheduling, leading to the development of Hudson in
    2005 by Kohsuke Kawaguchi. Hudson quickly gained popularity due to its ease of
    use and powerful features.
  prefs: []
  type: TYPE_NORMAL
- en: In 2011, a dispute with Oracle led to [Hudson being forked into Jenkins](https://oreil.ly/MF9WD),
    which has since become one of the most widely used tools for not only continuous
    integration, but also continuous delivery and deployment. The popularity of Jenkins
    can be attributed to its flexibility, extensibility, and vast plug-in ecosystem,
    allowing it to integrate with various tools and adapt to different workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Integration Today
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Continuous integration has evolved into a foundational practice in modern software
    development, and CI/CD systems are the backbone of any delivery pipeline. Through
    the continuous integration of code changes, teams have come to depend on the following
    advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Reduced integration problems
  prefs: []
  type: TYPE_NORMAL
- en: CI eliminates the dreaded “integration hell” by ensuring developers merge their
    code changes frequently, minimizing conflicts and making them easier to resolve.
  prefs: []
  type: TYPE_NORMAL
- en: Faster feedback
  prefs: []
  type: TYPE_NORMAL
- en: CI’s automated build and test processes provide developers with rapid feedback
    on their code changes, allowing them to catch and fix errors quickly, thus maintaining
    a stable and deployable codebase.
  prefs: []
  type: TYPE_NORMAL
- en: Increased efficiency and reliability
  prefs: []
  type: TYPE_NORMAL
- en: By automating the build and testing process, CI eliminates manual errors and
    inconsistencies, leading to more reliable and predictable builds.
  prefs: []
  type: TYPE_NORMAL
- en: Improved transparency
  prefs: []
  type: TYPE_NORMAL
- en: CI dashboards and notifications provide real-time visibility into the build
    and test status, allowing everyone on the team to track progress, identify potential
    issues, and collaborate more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Accelerated releases
  prefs: []
  type: TYPE_NORMAL
- en: By streamlining and automating the build, test, and integration processes, CI
    enables faster and more frequent releases, allowing businesses to respond more
    rapidly to customer feedback and market changes.
  prefs: []
  type: TYPE_NORMAL
- en: In [“Continuous Integration in the CI/CD Pipeline”](#chapter_3_continuous_integration_in_the_ci_cd_pipeline_1749354010266620),
    we’ll look at the function of CI in the delivery pipeline and explore the landscape
    of CI tools.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Integration in the CI/CD Pipeline
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 2](ch02.html#chapter_2_source_control_management_1749354010078326),
    we introduced a CI/CD pipeline, focusing on the relationship between the code
    repository and code integration. Let’s return to this pipeline and focus on the
    continuous integration, that is, the build step and the steps to execute pre-deployment
    test types, including static analysis, unit tests, and integration tests.
  prefs: []
  type: TYPE_NORMAL
- en: The pipeline in [Figure 3-2](#chapter_3_figure_2_1749354010256797) shows a typical
    CI process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ansd_0302.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-2\. CI pipeline triggered by opening a Git PR
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This example is triggered when a developer opens a pull request. The goal of
    this pipeline is to validate the changes proposed in the PR *before the changes
    are merged into the main branch.* Let’s go through the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Code trigger
  prefs: []
  type: TYPE_NORMAL
- en: A developer or an AI agent opens a pull request on the hosted repository (e.g.,
    GitHub, GitLab, Bitbucket), which triggers the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Checkout
  prefs: []
  type: TYPE_NORMAL
- en: The pipeline checks out the source code from the branch specified in the PR.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Build
  prefs: []
  type: TYPE_NORMAL
- en: The code is compiled (if necessary) and built into an executable or deployable
    artifact.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Static analysis
  prefs: []
  type: TYPE_NORMAL
- en: Tools like linters and code analyzers scan the code for style violations, potential
    bugs, and security issues.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Unit tests
  prefs: []
  type: TYPE_NORMAL
- en: Automated tests that verify the functionality of individual code units are executed.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Integration tests
  prefs: []
  type: TYPE_NORMAL
- en: Relatively fast tests may be run to verify the interaction between different
    components of the code.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Feedback
  prefs: []
  type: TYPE_NORMAL
- en: The pipeline provides feedback to the developer about the PR’s status (success/failure)
    and any issues found. This feedback is displayed directly in the PR on the hosted
    repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'This pipeline detects and notifies developers of any issues within their code.
    The build step determines whether the code changes have broken the build. The
    test steps answer the following questions: Does this code do what is intended?
    Does this code include security vulnerabilities, unsafe operations, potential
    bugs, bad practices, deprecated features, or even inconsistent formatting?'
  prefs: []
  type: TYPE_NORMAL
- en: The code pipeline provides developers with near-real-time feedback by detecting
    issues and running fast tests when pull requests are opened or updated. It answers
    critical questions about the code’s functionality, security, and quality. Developers
    can then quickly address problems, refine the PR, or confidently merge it when
    all checks pass, accelerating development and ensuring a robust codebase.
  prefs: []
  type: TYPE_NORMAL
- en: (In [Chapter 4](ch04.html#chapter_4_deploying_to_test_environments_1749354010445896),
    we’ll explore a complementary CI pipeline triggered when a PR is merged. This
    pipeline deploys new code to test environments and executes longer-running test
    suites.)
  prefs: []
  type: TYPE_NORMAL
- en: Note that while our sample pipeline uses a code change trigger, CI/CD systems
    typically offer other trigger options, like scheduled and manual triggers, for
    more flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: The Essential Build Step
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The build step involves packaging code into a deployable artifact. Examples
    of deployable artifacts include container images (used to deploy in Kubernetes/serverless
    environments), language-specific packages (such as JAR, npm, NuGet, etc.), and
    mobile application packages (such as APK or IPA), among others. For example, code
    written in a compiled language, like C++, is first compiled and then linked to
    create machine code. Interpreted languages often require a build step to package
    code into an intermediate format, such as a Java Archive (JAR) file, for compilation
    at runtime. Other interpreted languages, including JavaScript, can be transpiled
    or minified to optimize for execution.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the type of code, this step or series of steps relies on build
    automation tools, task runners, or build scripts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Build automation tools orchestrate the entire build process. Popular examples
    of automation tools include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Make and CMake
  prefs: []
  type: TYPE_NORMAL
- en: Make is one of the oldest and most fundamental build tools. It uses a Makefile
    to define dependencies between files and the commands needed to build them. CMake
    is a newer cross-platform build system generator that can generate Makefiles,
    Visual Studio projects, and other build scripts. It’s widely used for C and C++
    projects.
  prefs: []
  type: TYPE_NORMAL
- en: Ant
  prefs: []
  type: TYPE_NORMAL
- en: An early Java-based build tool that uses XML to describe the build process.
    It’s known for its flexibility and cross-platform compatibility.
  prefs: []
  type: TYPE_NORMAL
- en: Maven
  prefs: []
  type: TYPE_NORMAL
- en: Another popular Java build tool that goes beyond just compilation. It manages
    dependencies, builds, tests, and packages projects.
  prefs: []
  type: TYPE_NORMAL
- en: Gradle
  prefs: []
  type: TYPE_NORMAL
- en: A newer build tool that combines the best of Ant and Maven. It uses a Groovy-based
    DSL to define builds and offers a more flexible and concise syntax.
  prefs: []
  type: TYPE_NORMAL
- en: Bazel
  prefs: []
  type: TYPE_NORMAL
- en: Developed by Google, Bazel is a powerful build system designed for large-scale
    projects. It’s known for its speed, scalability, and support for multiple languages.
  prefs: []
  type: TYPE_NORMAL
- en: MSBuild
  prefs: []
  type: TYPE_NORMAL
- en: A build automation platform commonly used with .NET frameworks and languages
    like C#, Visual Basic .NET, and F#.
  prefs: []
  type: TYPE_NORMAL
- en: Cargo
  prefs: []
  type: TYPE_NORMAL
- en: Cargo is a package manager for the Rust programming language, used to build,
    compile, and manage Rust projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Task runners automate repetitive tasks in the development workflow, such as
    minification, concatenation, and transpilation. Widely used task runners for JavaScript
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: npm scripts
  prefs: []
  type: TYPE_NORMAL
- en: Part of the Node Package Manager (npm), npm scripts are simple scripts defined
    in the *package.json* file that can automate common tasks like starting a development
    server, running tests, and building for production.
  prefs: []
  type: TYPE_NORMAL
- en: Gulp
  prefs: []
  type: TYPE_NORMAL
- en: A streaming build system that uses JavaScript code to define tasks. It’s known
    for its speed and efficiency in processing files.
  prefs: []
  type: TYPE_NORMAL
- en: Grunt
  prefs: []
  type: TYPE_NORMAL
- en: Another task runner for JavaScript projects, Grunt uses configuration files
    to define tasks. It’s known for its vast ecosystem of plug-ins.
  prefs: []
  type: TYPE_NORMAL
- en: Webpack
  prefs: []
  type: TYPE_NORMAL
- en: A module bundler primarily used for JavaScript applications. It can bundle JavaScript,
    CSS, and other assets into optimized files for production.
  prefs: []
  type: TYPE_NORMAL
- en: Rollup
  prefs: []
  type: TYPE_NORMAL
- en: Another module bundler that’s known for its focus on generating smaller and
    more efficient bundles than Webpack.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, build scripts are custom scripts (often written in Bash, Python, or
    other scripting languages) that define the specific steps and commands needed
    to build a project. These can be used in conjunction with build automation tools
    or task runners.
  prefs: []
  type: TYPE_NORMAL
- en: Prioritizing Quality and Security with Static Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Immediately after we build our code, we run static analysis tools, which may
    include a linter. Linters are a specific type of static analysis tool used to
    check coding style (ensuring, for example, consistent formatting and naming patterns);
    for interpreted languages like JavaScript, linters check for typos, missing semicolons,
    or incorrect language usage. These tools examine source code without executing
    it, similar to proofreading a document before publishing it. They help identify
    potential issues early in the development process. Static code analysis encompasses
    a range of techniques to evaluate code for:'
  prefs: []
  type: TYPE_NORMAL
- en: Potential bugs
  prefs: []
  type: TYPE_NORMAL
- en: Identifies common programming errors, like null pointer dereferences, resource
    leaks, or logic flaws
  prefs: []
  type: TYPE_NORMAL
- en: Security vulnerabilities
  prefs: []
  type: TYPE_NORMAL
- en: Detects insecure coding practices that could lead to SQL injections, cross-site
    scripting (XSS), or other exploits
  prefs: []
  type: TYPE_NORMAL
- en: Code smells
  prefs: []
  type: TYPE_NORMAL
- en: Flags maintainability issues, like duplicate code, excessive complexity, or
    unused variables, suggesting areas for refactoring
  prefs: []
  type: TYPE_NORMAL
- en: Adherence to standards
  prefs: []
  type: TYPE_NORMAL
- en: Enforces coding guidelines and, sometimes, best practices specific to a language
    or project, ensuring consistency and readability
  prefs: []
  type: TYPE_NORMAL
- en: By integrating these static analysis tools into the early stages of the development
    process, we not only ensure code quality but also implement a best practice referred
    to as shift-left security. Shift-left securityrefers to the strategy of implementing
    security practices in the earliest stages of development. We’ll dig into shift-left
    security and also explore how AI can help remediate security issues quickly in
    [Chapter 5](ch05.html#chapter_5_securing_applications_and_the_software_supply_chai_1749354010735711).
  prefs: []
  type: TYPE_NORMAL
- en: 'Automated Testing: Test Early, Test Often'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Automated testing is fundamental to the CI/CD pipeline. After our example pipeline
    runs static analysis checks, it executes unit and integration tests against new
    code. Let’s look at these test types:'
  prefs: []
  type: TYPE_NORMAL
- en: Unit tests
  prefs: []
  type: TYPE_NORMAL
- en: These tests validate the smallest isolated pieces of code (units), such as functions
    or methods, to verify that they behave as expected in isolation. Imagine a simple
    weather application that fetches weather data from an external API, processes
    it, and displays it to the user. Unit tests might test functions that process
    raw weather data, validating that they correctly convert the data into the desired
    formats. The tests validate the conversion logic alone.
  prefs: []
  type: TYPE_NORMAL
- en: Integration tests
  prefs: []
  type: TYPE_NORMAL
- en: These tests focus on verifying the interactions between software modules, ensuring
    proper communication and data exchange. Integration tests are relatively fast,
    often conducted after unit testing, and, like unit tests, help identify issues
    early. An integration test for the same weather app might focus on how the data
    fetching and processing modules interact. These tests could verify that the app
    correctly retrieves and handles weather data from the API, including error scenarios,
    using partial mocking to simulate real-world API responses. Unlike unit tests,
    which isolate components, integration tests assess how multiple components work
    together. Integration tests that are used early in the pipeline, such as in our
    example pipeline, should avoid slow operations such as accessing a database, file
    system, or other external systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unit and integration test frameworks are numerous and vary by language, for
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: Java
  prefs: []
  type: TYPE_NORMAL
- en: JUnit 5 and TestNG are frameworks for unit testing. Mockito and Spring are used
    for Java integration testing.
  prefs: []
  type: TYPE_NORMAL
- en: JavaScript
  prefs: []
  type: TYPE_NORMAL
- en: Jest and Mocha for JavaScript are widely used for unit testing. Jest also supports
    integration testing.
  prefs: []
  type: TYPE_NORMAL
- en: Python
  prefs: []
  type: TYPE_NORMAL
- en: pyTest and pyUnit (UnitTest) are options for both unit and integration testing.
  prefs: []
  type: TYPE_NORMAL
- en: .NET
  prefs: []
  type: TYPE_NORMAL
- en: NUnit and xUnit for .NET are options for unit testing, whereas Moq and NSubstitute
    are commonly used for integration testing.
  prefs: []
  type: TYPE_NORMAL
- en: Ruby
  prefs: []
  type: TYPE_NORMAL
- en: RSpec supports both unit and integration testing for Ruby.
  prefs: []
  type: TYPE_NORMAL
- en: Mobile (iOS/Android)
  prefs: []
  type: TYPE_NORMAL
- en: XCTest for iOS and Espresso for Android are standard bearers for mobile unit
    and integration testing.
  prefs: []
  type: TYPE_NORMAL
- en: Unit and integration tests act as a first line of defense, alerting developers
    to potential bugs or regressions in their code. These quick, automated checks
    are just the beginning of our testing strategy. In [Chapter 4](ch04.html#chapter_4_deploying_to_test_environments_1749354010445896),
    we’ll look at a subsequent pipeline that is triggered when the PR is closed and
    merged.
  prefs: []
  type: TYPE_NORMAL
- en: Thoroughly testing each unit of code, including all possible scenarios, results
    in a large but crucial suite of tests—even for seemingly simple code. However,
    since unit tests are isolated and don’t rely on external resources, they execute
    rapidly.
  prefs: []
  type: TYPE_NORMAL
- en: Our pipeline prioritizes these speedy unit tests as the foundation, followed
    by integration tests that verify how different components work together, and finally,
    a smaller number of comprehensive end-to-end tests that simulate real-world usage.
  prefs: []
  type: TYPE_NORMAL
- en: In [“The Test Pyramid”](#chapter_3_the_test_pyramid_1749354010266825), we’ll
    look at the Test Pyramid framework, which illustrates how to balance different
    test types for optimal software quality.
  prefs: []
  type: TYPE_NORMAL
- en: The Test Pyramid
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Test Pyramidprovides a model for structuring our tests strategically, prioritizing
    different types based on their scope and speed. While the Test Pyramid is sometimes
    depicted with specific test types at each layer, we prefer to conceptualize layers
    that encompass broad classes of tests, as shown in [Figure 3-3](#chapter_3_figure_3_1749354010256819).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ansd_0303.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-3\. Large sets of fast tests make up the base of the Test Pyramid;
    smaller sets of slower tests form the higher layers
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: At the base of our pyramid are pre-deployment tests, which include types like
    unit tests, integration tests, and static scans. These tests are small and execute
    quickly. Integration testing can refer to a range of test strategies. Integration
    tests that don’t interact with external systems like databases and network services
    are fast and are included at this level. The wide pyramid base reflects that the
    suite of these types of tests should be large and, ideally, cover the complete
    codebase. Tests should be designed to provide fast feedback to the developer.
  prefs: []
  type: TYPE_NORMAL
- en: Moving up the pyramid, we depict the middle layer as including any type of tests
    that we execute against deployed code in a pre-production, test environment.Generally,
    these tests are typically slower than the ones mentioned above but provide valuable
    insights into how the system functions as a whole.
  prefs: []
  type: TYPE_NORMAL
- en: At the peak of the pyramid, we find manual tests.These are slow and labor-intensive
    and occur after the code has been vetted by layers of automated testing.
  prefs: []
  type: TYPE_NORMAL
- en: Embracing the pyramid approach allows teams to balance speed, cost, and effectiveness
    in their testing efforts. By focusing on a solid foundation of small and fast
    tests and supplementing them with strategic testing against deployed code, we
    can achieve comprehensive test coverage while minimizing the time and resources
    required.
  prefs: []
  type: TYPE_NORMAL
- en: A robust testing strategy is key to a streamlined pipeline, accelerating the
    delivery of high-quality releases. In [“Continuous Integration Tools”](#chapter_3_continuous_integration_tools_1749354010266880)
    we’ll consider how the CI tool choice can prioritize that factor.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Integration Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Effective CI processes are essential for modern development teams. In this section,
    we’ll look at legacy CI tools and the features that characterize modern tools.
  prefs: []
  type: TYPE_NORMAL
- en: A major national retailer—a client of ours—anticipating a surge in digital demand
    found itself at a crossroads. Its legacy CI/CD tools, including Jenkins, were
    fragmented across client web, mobile, and backend service teams, causing long
    build times that cost the company a staggering $500,000 annually in idle developer
    time. These tools not only stifled innovation but also posed significant security
    risks, further exacerbated by the $800,000 spent yearly on maintenance and custom
    scripts. This substantial investment diverted resources away from enhancing the
    customer experience. Faced with mounting challenges and escalating costs, the
    retailer sought a unified CI/CD platform to streamline operations, accelerate
    innovation, and fortify security.
  prefs: []
  type: TYPE_NORMAL
- en: The company’s compounding challenges shed light on the inherent limitations
    of Jenkins, especially as organizations scale and digital demands intensify. Let’s
    look at some of those limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Jenkins Considered
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Jenkins deserves credit for bringing continuous integration into the mainstream.
    An open source automation server, Jenkins leverages a vast ecosystem of plug-ins
    that extend its functionality and features and give users the ability to customize
    their pipelines endlessly. The Jenkins plug-in marketplace is a central repository
    where users can find and install thousands of these community-developed plug-ins.
    The Jenkins community is large and its documentation is extensive. It is an adaptable
    solution for diverse development environments.
  prefs: []
  type: TYPE_NORMAL
- en: While Jenkins remains valuable for legacy systems due to its specialized plug-ins
    (e.g., mainframes), modern CI pipelines demand more. Today’s development environments
    require CI tools that deliver speed, security, collaborative workflows, and native
    integration with cloud technologies across multiple providers, Kubernetes orchestration,
    and containerized applications. The following sections explore specific challenges
    that make Jenkins less suitable for these modern requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Plug-in complexity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The flexibility and extensive plug-in ecosystem of Jenkins often leads to a
    complex and fragmented architecture, hindering maintainability and increasing
    developer toil. The reliance on Groovy scripts for pipeline customization can
    make troubleshooting and updates cumbersome, especially as the number of pipelines
    and their complexity grows.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, modern CI/CD solutions often embrace the “pipeline-as-code” paradigm,
    using declarative languages like YAML to define pipelines. This approach is generally
    considered more straightforward and maintainable than the scripting-heavy approach
    of Jenkins. YAML-based pipelines are generally more human-readable and easier
    to maintain (there might be exceptions) than Groovy scripts, which can become
    complex and harder to debug as pipelines grow in size and complexity. Defining
    pipelines as code allows them to be stored in VCSs alongside the application code.
    This ensures that pipeline changes are tracked, reviewed, and auditable, enabling
    better collaboration among team members. Thus, the pipeline-as-code approach allows
    for better version control, collaboration, and easier troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, the need to manage a multitude of plug-ins, each with its own configuration,
    introduces maintenance overhead. Team members find themselves spending valuable
    time on mundane tasks like resolving plug-in conflicts, updating dependencies,
    and deciphering cryptic error messages. This detracts from the focus on innovation
    and core development, slowing down innovation and delivering features.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability challenges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The architecture of Jenkins, primarily designed for single-server setups, often
    struggles to scale efficiently as the number of jobs, pipelines, and users increases.
    This can lead to performance bottlenecks, slower build times, and overall system
    instability. While Jenkins offers distributed builds and clustering options, setting
    up and maintaining these solutions can be complex and resource-intensive, requiring
    specialized expertise and significant overhead. As a result, [scaling Jenkins
    horizontally](https://oreil.ly/6qFLO) to meet the demands of large organizations
    or high-throughput CI/CD workflows often becomes a major challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Security concerns
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While Jenkins plug-ins provide extensibility, they also introduce potential
    vulnerabilities. Each plug-in, with its own codebase and dependencies, expands
    the attack surface of a Jenkins instance. Monitoring these plug-ins for vulnerabilities
    and ensuring timely updates becomes ongoing overhead for administrators. Furthermore,
    configuring Jenkins security, including user permissions, access controls, and
    network configurations, can be intricate. Misconfigurations can expose the system
    to unauthorized access or malicious activities. The dynamic nature of the plug-in
    ecosystem and the potential for misconfigurations mean you must be vigilant in
    monitoring risks and proactive in mitigating risks within your Jenkins environment.
  prefs: []
  type: TYPE_NORMAL
- en: Resource usage and efficiency concerns
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Jenkins’s resource consumption can be a significant drawback, especially as
    the number of jobs and plug-ins increases. The Java-based architecture (JVM’s
    runtime requirements, garbage collection behavior, and framework abstractions)
    often leads to high memory usage, and managing numerous concurrent builds can
    put a strain on CPU and disk resources. This can result in slower build times,
    increased infrastructure costs, and potential performance issues. In larger environments,
    scaling Jenkins horizontally can become complex and resource-intensive, requiring
    additional hardware and careful configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, building Docker images in CI pipelines can quickly become resource-intensive
    and expensive, particularly when dealing with large codebases or frequent commits
    that trigger numerous parallel builds. Each image requires computational resources,
    storage space, and network bandwidth—costs that multiply across environments and
    branches. Similarly, while comprehensive observability provides valuable system
    insights, implementing excessive logging can create its own problems: storage
    costs surge, signal-to-noise ratios decrease, and processing overhead increases.
    Finding the right balance between comprehensive coverage and resource efficiency
    remains a critical challenge.'
  prefs: []
  type: TYPE_NORMAL
- en: Beyond Jenkins
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Due to the limitations of Jenkins, companies like our national retailer often
    outgrow it and seek modern, fully managed solutions that offer:'
  prefs: []
  type: TYPE_NORMAL
- en: Built-in, fully supported building blocks
  prefs: []
  type: TYPE_NORMAL
- en: Modern CI/CD tools offer extensive libraries of built-in, fully supported building
    blocks that streamline pipeline setup. This eliminates reliance on community-maintained
    plug-ins, ensuring reliability and stability. However, recognizing the need for
    customization, most solutions still support extensibility through custom plug-ins.
    This empowers teams to automate unique workflows and tailor the CI/CD environment
    to their specific needs.
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines define declaratively
  prefs: []
  type: TYPE_NORMAL
- en: Modern CI/CD tools streamline pipeline definition using declarative code like
    YAML, making them more accessible and easier to maintain than the Groovy scripts
    for Jenkins. This accelerates setup and minimizes errors associated with manual
    scripting.
  prefs: []
  type: TYPE_NORMAL
- en: Native support for containerization and orchestration
  prefs: []
  type: TYPE_NORMAL
- en: Jenkins predates the widespread adoption of Docker and Kubernetes, and while
    Jenkins pipelines can use plug-ins to work with and orchestrate containers, the
    lack of native support often results in cumbersome configurations. Newer tools,
    in contrast, seamlessly incorporate containerization and orchestration features,
    simplifying the deployment and management of applications in containerized environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next sections, we’ll look at additional modern features that tools newer
    than Jenkins offer. Before we turn our attention to these features, let’s consider
    a fundamental question when considering CI/CD tools: whether to host and manage
    tools yourself or select a fully managed solution. The decision will impact everything
    from development velocity and cost-effectiveness to maintenance requirements.
    Given the importance of mobile, it’s essential to select a CI/CD setup that handles
    the complexities of building and deploying mobile applications and we’ll look
    at the factors specific to mobile app development to consider.'
  prefs: []
  type: TYPE_NORMAL
- en: Hosting options
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Organizations have three primary build infrastructure choices for their CI/CD
    systems: self-hosted on-premises, self-hosted cloud, and vendor-hosted (cloud).
    Each option presents unique benefits and drawbacks that should be carefully considered:'
  prefs: []
  type: TYPE_NORMAL
- en: Self-hosted, on-prem solutions
  prefs: []
  type: TYPE_NORMAL
- en: Self-hosting a CI/CD system on-premises gives you complete control and ownership
    over its infrastructure and data. This approach allows for maximum customization,
    enabling tailoring to specific security protocols and organizational needs. Additionally,
    some organizations may prefer the one-time payment model associated with on-prem
    solutions. However, this approach comes with several drawbacks. It necessitates
    substantial up-front investment in hardware and software, as well as time and
    effort to maintain and update. The demand for ongoing maintenance and potential
    scalability challenges can strain resources, particularly for smaller organizations.
  prefs: []
  type: TYPE_NORMAL
- en: Self-hosted, cloud solutions
  prefs: []
  type: TYPE_NORMAL
- en: The self-managed, cloud-hosted model strikes a balance between control and scalability.
    Organizations maintain control over their CI/CD software while leveraging the
    cloud’s flexibility and scalability. This approach reduces the need for physical
    hardware and simplifies scaling compared to on-prem solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud-hosted applications run within virtualized environments called hypervisors,
    and when considering cloud hosting, the type of hypervisor you select will impact
    simplicity and performance. The two types of hypervisors to understand are:'
  prefs: []
  type: TYPE_NORMAL
- en: Type 1 bare-metal hypervisor
  prefs: []
  type: TYPE_NORMAL
- en: These run directly on the hardware, offering superior performance and isolation
    but requiring dedicated hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Type 2, embedded hypervisors
  prefs: []
  type: TYPE_NORMAL
- en: These run on top of an operating system, providing easier setup and flexibility
    but potentially with lower performance.
  prefs: []
  type: TYPE_NORMAL
- en: Bare metal might be better for demanding, high-security setups, while embedded
    could be suitable for less intensive needs and budget constraints.
  prefs: []
  type: TYPE_NORMAL
- en: Any cloud-hosted toolset will require ongoing maintenance and updates, and your
    organization will remain responsible for managing the cloud infrastructure. This
    can lead to challenges similar to those of on-prem solutions, albeit with potentially
    reduced up-front costs.
  prefs: []
  type: TYPE_NORMAL
- en: Fully managed, vendor-hosted solutions
  prefs: []
  type: TYPE_NORMAL
- en: Vendor-hosted CI/CD solutions offer a fully managed service where the vendor
    handles infrastructure, maintenance, and updates. Your organization focuses on
    development rather than infrastructure management. These solutions are highly
    scalable, easy to use, and often follow a pay-as-you-go model, making them cost-effective.
    However, they may offer less customization than self-hosted options and potentially
    limit your organization’s ability to tailor the system to your specific needs.
    Additionally, concerns about data security and potential vendor lock-in can arise
    with this approach.
  prefs: []
  type: TYPE_NORMAL
- en: Mobile app development–specific challenges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Having a robust and efficient CI/CD solution is crucial to keep pace with the
    fast release cycles and high-quality apps that mobile users expect. Developing
    for mobile brings unique challenges: your processes and your CI/CD tools must
    be able to manage device fragmentation and frequent mobile OS updates.'
  prefs: []
  type: TYPE_NORMAL
- en: When choosing between self-hosted and fully managed CI/CD solutions, consider
    that self-hosted solutions, while offering control and customization, can lead
    to challenges like physical hardware constraints. In addition, your team will
    be responsible for constant maintenance and updates to build environments. These
    complexities can lead to unexpected costs. The frequent release cycles of tools
    like Xcode for iOS development necessitate regular hardware updates, which can
    be a significant time and resource drain for any team.
  prefs: []
  type: TYPE_NORMAL
- en: Fully managed CI/CD solutions, on the other hand, alleviate these pain points
    by providing automatic updates to build environments and predictable costs. This
    allows your team to focus on building features and improving their apps rather
    than managing infrastructure. Moreover, fully managed CI/CD solutions specifically
    optimized for mobile development offer mobile-specific integrations and features
    that streamline the development process. Many of these platforms fully manage
    challenges of mobile development, such as device fragmentation and OS updates,
    for you.
  prefs: []
  type: TYPE_NORMAL
- en: Modern Features to Accelerate Software Builds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Returning to our retailer: it researched newer options and decided to move
    on from Jenkins and the set of plug-ins and tools pieced together to work with
    it. The company selected a unified platform that simplified its toolset while
    providing the scalability and cost savings that it required. It was able to consolidate
    CI/CD processes for services, client web, and mobile teams onto this single platform.
    The new platform eliminated the need for extensive scripting, saving developers
    time and enabling them to focus on innovation. It also leveraged AI/ML for testing,
    resulting in further cost savings and much faster builds. Furthermore, a unified
    platform improved security by supporting security testing early in the pipeline,
    enabling faster detection and remediation of vulnerabilities. The efficiency,
    security, and reliability of the new platform enabled the retailer to easily handle
    its digital growth.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next sections, we will look at features in modern systems that enable
    faster, cost-effective, and secure pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Accelerate builds with caching
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Modern build environments are ephemeral, enhancing agility by providing isolated,
    cost-effective, and scalable setups that accelerate development cycles while maintaining
    consistency across stages of the CI/CD pipeline. However, ephemeral environments
    require setting up the entire build process from scratch each time, including
    downloading dependencies, compiling code, and generating artifacts. This is time-consuming.
  prefs: []
  type: TYPE_NORMAL
- en: Caching is a technique used in CI/CD to store and reuse build artifacts, dependencies,
    Docker layers, and intermediate results. This significantly reduces build times
    by avoiding redundant operations and focusing on building only what has changed,
    which not only speeds up development cycles but also conserves computational resources
    and energy. Modern CI/CD systems intelligently manage this caching process, optimizing
    builds without manual intervention. Caching can be done at different stages—caching
    software dependencies, caching Docker layers, and caching build outputs from tools
    like Bazel, Gradle, and Maven.
  prefs: []
  type: TYPE_NORMAL
- en: Streamline building, caching, and testing with AI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An AI-native CI solution will seamlessly integrate GenAI, agentic AI, and MCP
    to enhance building the software, caching required components, and testing each
    build. Let’s look at these enhancements in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Build phase enhancements
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: GenAI can automate boilerplate code creation for repetitive tasks (e.g., Dockerfile
    templates, CI configuration files), reducing manual effort. It can also analyze
    historical build data to predict dependency conflicts and suggest optimal versions,
    minimizing build failures. Another interesting use case for GenAI is generating
    optimized CI pipeline YAML configurations based on project structure, reducing
    trial-and-error setups.
  prefs: []
  type: TYPE_NORMAL
- en: Agentic AI can detect build failures (e.g., missing dependencies), and can then
    automatically retry with corrected configurations and log root causes. It can
    also dynamically scale build resources (e.g., cloud instances) based on workload
    demands, balancing speed and cost, and can dynamically split monolithic builds
    into parallelizable tasks, reducing execution time.
  prefs: []
  type: TYPE_NORMAL
- en: MCP can standardize environment variables, build flags, and toolchain versions
    across distributed teams, ensuring consistency and sharing prebuilt artifacts,
    such as compiled libraries, between related projects via MCP’s centralized cache,
    avoiding redundant builds.
  prefs: []
  type: TYPE_NORMAL
- en: Cache phase enhancements
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: GenAI can be used to make the caching techniques more intelligent. It can predict
    which dependencies (e.g., *node_modules*, *.m2* artifacts) will be needed based
    on code changes, precaching them before builds start. ML models can be used to
    identify stale caches by analyzing code diff patterns, ensuring only relevant
    artifacts are retained. Agentic AI can flag and purge poisoned caches (e.g., corrupted
    artifacts) in real time, preventing failed builds.
  prefs: []
  type: TYPE_NORMAL
- en: Using MCP in scalable infrastructure has many advantages, including enabling
    secure, low-latency cache sharing across CI pipelines via standardized APIs, and
    reducing redundant data transfers by caching intermediate build outputs (e.g.,
    Docker layers) between CI runs. MCP can enable secure cache sharing between parallel
    CI jobs through standardized APIs, eliminating redundant builds in monorepo architectures.
  prefs: []
  type: TYPE_NORMAL
- en: Test phase enhancements
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Consider a scenario where a developer modifies a single line of code in a seldom-used
    component within a large application. We have high code coverage with our large
    and robust set of unit tests; these are the foundation of our test strategy, the
    base of our Test Pyramid. Yet, when little code has changed, executing the entire
    test suite results in lengthy, resource-intensive, and very inefficient test cycles.
  prefs: []
  type: TYPE_NORMAL
- en: Modern tools can mitigate these issues with AI tooling that intelligently selects
    and executes only the tests directly relevant to the modified code. This approach
    significantly reduces the time and resources required for testing, leading to
    faster feedback loops and more efficient development processes.
  prefs: []
  type: TYPE_NORMAL
- en: '[Harness Test Intelligence (TI)](https://oreil.ly/_-jPi) is an example of this
    approach. Let’s look at how TI works under the hood. Three components work together
    to enable Harness TI:'
  prefs: []
  type: TYPE_NORMAL
- en: TI service
  prefs: []
  type: TYPE_NORMAL
- en: This service uses AI and understands your repository, Git commits, and unit
    tests and uses this data to dynamically build a graph that maps the relationships
    between code methods and their corresponding unit tests. This graph is continuously
    updated to reflect changes in the codebase.
  prefs: []
  type: TYPE_NORMAL
- en: A test runner agent
  prefs: []
  type: TYPE_NORMAL
- en: This component communicates with the service and executes tests.
  prefs: []
  type: TYPE_NORMAL
- en: A test step
  prefs: []
  type: TYPE_NORMAL
- en: This is the step you add to your CI pipeline to integrate TI into your workflow.
  prefs: []
  type: TYPE_NORMAL
- en: The TI workflow begins when a developer initiates a pull request and triggers
    the pipeline. The TI service analyzes the code changes and compares them to its
    graph to identify the tests that need to be executed. It considers not only the
    code modifications but also any changes or additions to the tests themselves.
    This ensures that all relevant aspects of the codebase are thoroughly tested while
    avoiding redundant test runs.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, by focusing on the impacted tests, intelligent testing approaches can
    significantly reduce the testing time, especially in large projects with extensive
    test suites. This translates to faster builds and faster feedback for developers,
    allowing them to identify and address issues more quickly.
  prefs: []
  type: TYPE_NORMAL
- en: AI-powered build and test insights
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Modern CI/CD tools also leverage GenAI to automate tedious tasks and provide
    insights when things go wrong. For example, a tool can autogenerate your pipelines,
    analyze code for potential issues, and troubleshoot build and deployment failures
    in real time. If a CI build fails, GenAI can analyze log files, pinpoint the error,
    and even suggest potential fixes. This saves your time, reduces downtime, and
    accelerates the software delivery process.
  prefs: []
  type: TYPE_NORMAL
- en: Agentic AI can also be used to come up with recommendations to optimize existing
    pipelines based on your organization’s golden standards. This feature would be
    extremely valuable since organizations, more often than not, optimize their current
    pipelines rather than create new pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Another excellent use case for GenAI is writing intent-based tests. Testing,
    especially UI testing, can be extremely manual and flaky if the UI changes. By
    using GenAI, developers and QA engineers can simply state the intent of a test
    and let GenAI figure out the steps. We will discuss intent-based testing in detail
    in [Chapter 4](ch04.html#chapter_4_deploying_to_test_environments_1749354010445896).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, AI can also be used to generate data for tests ethically and responsibly.
    Some examples include ensuring compliance with GDPR and other regulations when
    using production data for model training, maintaining data privacy and security
    throughout the data generation process, and using proper algorithms to generate
    synthetic data.
  prefs: []
  type: TYPE_NORMAL
- en: Unify CI/CD metrics with enterprise observability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A modern CI/CD solution should be a team player, working with the other key
    platforms in your corporate ecosystem, particularly the observability platform
    that your organization relies on to understand system behavior, identify performance
    bottlenecks, and proactively detect and resolve issues before they impact users
    or business operations. Observability platforms include Elastic with Logstash
    and Kibana, a popular open source platform, and Datadog and Splunk, well-known
    commercial options.
  prefs: []
  type: TYPE_NORMAL
- en: Modern continuous integration tools provide telemetry data to these platforms
    by implementing OpenTelemetry, an open source framework. This brings in CI/CD
    metrics to enable observability and dashboards that can help you understand what’s
    happening and improve build performance and reliability.
  prefs: []
  type: TYPE_NORMAL
- en: Modern CI/CD support for monorepos
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Versioning and dependency management become very challenging when managing complex
    codebases across several repositories. Monorepos are single repositories that
    contain all the code for a project or organization, providing a centralized approach
    to managing complex codebases. A single repository simplifies dependency management
    by keeping a single copy of any shared library or component, and simplifies code
    sharing and reuse across different projects. While monorepos increase the risk
    of merge conflicts and require careful design to avoid tightly coupled code, many
    large companies have successfully adopted them for massive codebases, demonstrating
    that an effectively managed monorepo can provide a very scalable approach.
  prefs: []
  type: TYPE_NORMAL
- en: When adopting a monorepo strategy, it’s important to understand the unique requirements
    that monorepos make of code repositories and CI tools. With potentially hundreds
    of developers contributing to a large monorepo, managing changes and pull requests
    efficiently becomes critical. Teams must be able to define appropriate access
    by subdirectories, in part to ensure that only relevant reviewers are notified
    for each change. Repositories should support subdirectory-specific ownership.
  prefs: []
  type: TYPE_NORMAL
- en: Monorepos require CI systems that enable selective building and testing of changed
    components and that support advanced dependency management, caching, and parallel
    execution. Tools like Harness CI support these needs through features like path-based
    triggers, which run pipelines only when specific directories in the repository
    change (e.g., triggering service A’s pipeline for changes to *serviceA/*), and
    sparse checkout, which clones a subdirectory instead of the entire repository.
    This optimizes resource usage and speeds up feedback loops while maintaining dependency
    integrity.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'CI has become an indispensable practice, reducing integration issues, providing
    faster feedback, and improving overall efficiency. In this chapter, we looked
    at modern, fully managed CI/CD tool features, contrasting the trade-offs with
    the costs and challenges of self-hosting. We looked at the importance of prioritizing
    faster, smaller unit tests for quick feedback, followed by slower test types for
    comprehensive coverage. The continuous integration pipeline we looked at exemplified
    this practice: in the context of opening a PR, we build, complete static scans,
    and then run quick tests to ensure our code does what it should and doesn’t introduce
    regressions. We also explored various ways in which an AI-native CI tool could
    use GenAI, agentic AI, and MCP to enhance the build, cache, and test phases of
    CI.'
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 4](ch04.html#chapter_4_deploying_to_test_environments_1749354010445896),
    we’ll continue with CI/CD and focus on deploying to test environments and executing
    the slower tests that evaluate the system’s performance, resiliency, and end-to-end
    behavior.
  prefs: []
  type: TYPE_NORMAL
