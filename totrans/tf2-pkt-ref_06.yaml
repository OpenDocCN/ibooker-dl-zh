- en: Chapter 6\. Model Creation Styles
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。模型创建风格
- en: As you may have imagined, there is more than one way to build a deep learning
    model. In the previous chapters, you learned about `tf.keras.Sequential`, known
    as the *symbolic API*, which is commonly the starting point when teaching model
    creation. Another style of API that you might come across is known as the *imperative
    API*. Both symbolic and imperative APIs are capable of building deep learning
    models.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可能想象的那样，构建深度学习模型有多种方法。在前几章中，您了解了`tf.keras.Sequential`，被称为*符号API*，通常是教授模型创建的起点。您可能遇到的另一种API风格是*命令式API*。符号API和命令式API都能够构建深度学习模型。
- en: By and large, which API you choose is a matter of style. Depending on your programming
    experience and background, one or the other might feel more natural for you. In
    this chapter, you will learn how to build the same model with both APIs. Specifically,
    you will learn how to build an image classification model using the [CIFAR-10
    image dataset](https://oreil.ly/W81qK). This dataset consists of 10 commonly seen
    *classes*, or categories, of images. Like the flower images we used previously,
    the CIFAR-10 images are available as part of the TensorFlow distribution. However,
    while the flower images came in JPEG format, the CIFAR-10 images are NumPy arrays.
    To stream them into the training process, instead of using the `flow_from_directory`
    method as you did in [Chapter 5](ch05.xhtml#data_pipelines_for_streaming_ingestion),
    you’ll use the `from_tensor_slices` method.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，选择哪种API取决于风格。根据您的编程经验和背景，其中一种可能对您来说更自然。在本章中，您将学习如何使用两种API构建相同的模型。具体来说，您将学习如何使用[CIFAR-10图像数据集](https://oreil.ly/W81qK)构建图像分类模型。该数据集包含10种常见的*类别*或图像类别。与之前使用的花卉图像一样，CIFAR-10图像作为TensorFlow分发的一部分提供。然而，花卉图像是JPEG格式，而CIFAR-10图像是NumPy数组。为了将它们流式传输到训练过程中，您将使用`from_tensor_slices`方法，而不是像在[第5章](ch05.xhtml#data_pipelines_for_streaming_ingestion)中所做的`flow_from_directory`方法。
- en: After establishing the data streaming process with `from_tensor_slices`, you’ll
    first use the symbolic API to build and train the image classification model,
    and then use the imperative API. You will see that regardless of how you build
    the model architecture, the results are very similar.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`from_tensor_slices`建立数据流程后，您将首先使用符号API构建和训练图像分类模型，然后使用命令式API。您将看到，无论如何构建模型架构，结果都非常相似。
- en: Using the Symbolic API
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用符号API
- en: You have already seen the symbolic API, `tf.keras.Sequential`, at work in this
    book’s examples. Within `tf.keras.Sequential` there are stacks of layers, each
    of which performs certain operations to input data. Since models are built layer
    by layer, this is an intuitive way to envision the process. In most cases, you
    only have one source of input (in this case, a stream of images), and the output
    is the class of input images. In [“Model Implementation with TensorFlow Hub”](ch04.xhtml#model_implementation_with_tensorflow_hub),
    you learned how to build a model with TensorFlow Hub. The model architecture is
    defined with the sequential API, as shown in [Figure 6-1](#sequential_api_pattern_and_data_flow).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经在本书的示例中看到了符号API`tf.keras.Sequential`的工作原理。在`tf.keras.Sequential`中有一堆层，每个层对输入数据执行特定操作。由于模型是逐层构建的，这是一种直观的方式来设想这个过程。在大多数情况下，您只有一个输入源（在本例中是一系列图像），输出是输入图像的类别。在[“使用TensorFlow
    Hub实现模型”](ch04.xhtml#model_implementation_with_tensorflow_hub)中，您学习了如何使用TensorFlow
    Hub构建模型。模型架构是使用顺序API定义的，如[图6-1](#sequential_api_pattern_and_data_flow)所示。
- en: '![Sequential API pattern and data flow](Images/t2pr_0601.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![顺序API模式和数据流](Images/t2pr_0601.png)'
- en: Figure 6-1\. Sequential API pattern and data flow
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-1。顺序API模式和数据流
- en: In this section, you will learn how to use this API to build and train an image
    classification model with CIFAR-10 images.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何使用此API构建和训练一个使用CIFAR-10图像的图像分类模型。
- en: Loading the CIFAR-10 Images
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载CIFAR-10图像
- en: 'The CIFAR-10 image dataset contains 10 classes: airplanes, automobiles, birds,
    cats, deer, dogs, frogs, horses, ships, and trucks. All images are 32 × 32 pixels
    and colored with three channels (RGB).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10图像数据集包含10个类别：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。所有图像大小为32×32像素，带有三个通道（RGB）。
- en: 'Start by importing the necessary libraries:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 首先导入必要的库：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This code downloads the CIFAR-10 images to your Python runtime, partitioned
    into training and test sets. You can verify the format with a `type` statement:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将CIFAR-10图像下载到您的Python运行时中，分为训练集和测试集。您可以使用`type`语句验证格式：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output will be a data type:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将是一个数据类型：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'It is also important to know the array’s shape, which you can find with the
    following command:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 还重要的是要知道数组的形状，您可以使用以下命令找到：
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here are the array shapes for the images and labels, respectively:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '以下是图像和标签的数组形状： '
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can do the same for the test data:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以对测试数据执行相同的操作：
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should get the following output:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该得到以下输出：
- en: '[PRE6]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As you can see from the outputs, the CIFAR-10 dataset consists of 50,000 training
    images, each 32 × 32 × 3 pixels. The accompanying 50,000 labels are a one-dimensional
    array of indices that denote image classes. Likewise, there are 10,000 test images
    with corresponding labels. The label indices correspond to the following names:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看出，CIFAR-10数据集包含50,000个训练图像，每个图像大小为32×32×3像素。伴随的50,000个标签是一个一维数组，表示图像类别的索引。同样，还有10,000个测试图像和相应的标签。标签索引对应以下名称：
- en: '[PRE7]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Thus, an index of 0 denotes the label “airplane,” while an index of 9 denotes
    “truck.”
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，索引0表示标签“飞机”，而索引9表示“卡车”。
- en: Inspecting Label Distribution
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查标签分布
- en: 'Now it’s time to find out the distribution of these classes and see some of
    the images. To find out how many samples each class has, look at the distribution
    of training labels by class using the NumPy `unique` function:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候找出这些类别的分布并查看一些图像了。通过查看训练标签的分布，可以了解每个类别有多少样本，使用NumPy的`unique`函数：
- en: '[PRE8]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This will return sample counts for each label. To display it:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回每个标签的样本计数。要显示它：
- en: '[PRE9]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'It will show the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 它将显示以下内容：
- en: '[PRE10]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This means that there are 5,000 images in each label (class). The training data
    is evenly distributed among all labels.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着每个标签（类）中有5,000张图片。训练数据在所有标签之间均匀分布。
- en: 'Similarly, you can verify the distribution of the test data:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，您可以验证测试数据的分布：
- en: '[PRE11]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output confirms the count of 1,000 images for each label:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认了每个标签有1,000张图片：
- en: '[PRE12]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Inspecting Images
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查图像
- en: Let’s take a look at some of the images to ensure their data quality. For this
    exercise, you’ll randomly sample and display 25 images of the 50,000 in the training
    dataset.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些图像，以确保它们的数据质量。在这个练习中，您将随机抽样并显示训练数据集中的50,000张图像中的25张。
- en: 'How does TensorFlow make this random selection? The images are indexed from
    0 to 49,999\. To randomly select a finite number of indices from this range, use
    Python’s `random` library, which takes a Python list as input and randomly selects
    a finite number of samples from it:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow如何进行这种随机选择？图像从0到49,999进行索引。要从此范围中随机选择有限数量的索引，使用Python的`random`库，该库以Python列表作为输入，并从中随机选择有限数量的样本：
- en: '[PRE13]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This code randomly selects 25 elements from `a_list` and stores the results
    in `selected_elements`. If `a_list` corresponds to the image indices, then `selected_elements`
    will contain 25 indices drawn at random from `a_list`. You will use `selected_elements`
    to access and display these 25 training images.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码从`a_list`中随机选择25个元素，并将结果存储在`selected_elements`中。如果`a_list`对应于图像索引，则`selected_elements`将包含从`a_list`中随机抽取的25个索引。您将使用`selected_elements`来访问和显示这25张训练图像。
- en: 'Now you need to create `train_idx`, the list that holds the indices for training
    images. You’ll use the Python `range` function to create an object that holds
    integers in the range 0 to 49,999:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您需要创建`train_idx`，该列表保存训练图像的索引。您将使用Python的`range`函数创建一个包含0到49,999之间整数的对象：
- en: '[PRE14]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The preceding code creates a `range` object that holds integers that start at
    0 and go up to `len(train_labels)`, or the length of the list `training_labels`.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码创建了一个`range`对象，其中包含从0开始到`len(train_labels)`或列表`training_labels`的长度的整数。
- en: 'Now, convert the `range` object to a Python list:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将`range`对象转换为Python列表：
- en: '[PRE15]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This list is now ready to serve as input to the Python `random.sample` function.
    Now you can start on your code.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表现在已准备好作为Python`random.sample`函数的输入。现在您可以开始编写代码了。
- en: 'First, create `train_idx`, which is a list of indices from 0 to 49,999:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建`train_idx`，这是一个从0到49,999的索引列表：
- en: '[PRE16]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Then use the `random` library to generate the random selection:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用`random`库生成随机选择：
- en: '[PRE17]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The seed operation in the second line ensures that your selection is reproducible,
    which is helpful for debugging purposes. You can use any integer for `seed`.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 第二行中的种子操作确保您的选择是可重现的，这对于调试很有帮助。您可以为`seed`使用任何整数。
- en: 'The `random_sel` list will hold 25 randomly selected indices that look something
    like this:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`random_sel`列表将保存25个随机选择的索引，看起来像这样：'
- en: '[PRE18]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now you can plot images based on these indices and display their labels:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以根据这些索引绘制图像并显示它们的标签：
- en: '[PRE19]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This code snippet displays a panel of 25 images along with their labels, as
    shown in [Figure 6-2](Images/#twenty-five_images_from_the_cifar-ten_da). (Because
    this is a random sample, your results will vary.)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码片段显示了一个包含25张图像及其标签的面板，如[图6-2](Images/#twenty-five_images_from_the_cifar-ten_da)所示。（由于这是一个随机样本，您的结果会有所不同。）
- en: '![Twenty-five images from the CIFAR-10 dataset, selected at random](Images/t2pr_0602.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![从CIFAR-10数据集中随机选择的25张图像](Images/t2pr_0602.png)'
- en: Figure 6-2\. Twenty-five images from the CIFAR-10 dataset, selected at random
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-2。从CIFAR-10数据集中随机选择的25张图像
- en: Building a Data Pipeline
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建数据管道
- en: 'In this section, you will build a data ingestion pipeline using `from_tensor_slices`.
    Since there are only two partitions, training and test, you’ll need to reserve
    half of the test partition for cross validation during the training process. Select
    the first 500 as cross-validation data and the remaining 500 as test data:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将使用`from_tensor_slices`构建数据摄入管道。由于只有两个分区，训练和测试，您需要在训练过程中将测试分区的一半保留为交叉验证。选择前500个作为交叉验证数据，剩下的500个作为测试数据：
- en: '[PRE20]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This code creates two dataset objects based on image indices, `validation_dataset`
    and `test_dataset`, with 500 samples in each set.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码基于图像索引创建了两个数据集对象，`validation_dataset`和`test_dataset`，每个集合中有500个样本。
- en: 'Now create a similar dataset object for the training data:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在为训练数据创建一个类似的数据集对象：
- en: '[PRE21]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'All training images are used here. You can confirm that by counting the samples
    in `train_dataset`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用了所有的训练图像。您可以通过计算`train_dataset`中的样本数量来确认：
- en: '[PRE22]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This is the expected result:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期结果：
- en: '[PRE23]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Batching the Dataset for Training
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为训练批处理数据
- en: To finish setting up the data ingestion pipeline for training, you will need
    to divide the training data into batches. The size of a batch, or number of training
    samples, is the number required for the model training process to update the model
    weights and bias, and then move along one step to reduce the error gradient.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成用于训练的数据摄入管道的设置，您需要将训练数据划分为批次。批次的大小，或训练样本的数量，是模型训练过程中更新模型权重和偏差所需的数量，然后沿着一步减少误差梯度。
- en: 'Batch your training data with the following code, which first shuffles the
    training dataset and then creates multiple batches of 200 samples each:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码对训练数据进行批处理，首先对训练数据集进行洗牌，然后创建多个包含200个样本的批次：
- en: '[PRE24]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Likewise, you’ll do the same for cross-validation and test data:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，您将对交叉验证和测试数据执行相同的操作：
- en: '[PRE25]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The cross-validation and test datasets each consist of one 500-sample batch.
    The code sets parameters to inform the training process how many batches of training
    and validation data to expect. The parameter for training data is `STEPS_PER_EPOCH`.
    The parameter for cross-validation data is `VALIDATION_STEPS` and it is set to
    1 because the data size and batch size are both 500\. Note that a double slash
    (//) denotes *floor division* (that is, rounding down to the nearest integer).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证和测试数据集各包含一个500样本批次。代码设置参数以通知训练过程应该期望多少批次的训练和验证数据。训练数据的参数是`STEPS_PER_EPOCH`。交叉验证数据的参数是`VALIDATION_STEPS`，设置为1，因为数据大小和批次大小都是500。请注意，双斜杠（//）表示*地板除法*（即向下取整到最接近的整数）。
- en: Now that your training and validation datasets are ready, your next step is
    to build the model with the symbolic API.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您的训练和验证数据集已经准备好了，下一步是使用符号API构建模型。
- en: Building the Model
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建模型
- en: 'Now you are ready to build the model. Here is example code for a deep learning,
    image-classification model, built with a stack of layers wrapped by the `tf.keras.Sequential`
    class:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经准备好构建模型了。以下是一个使用`tf.keras.Sequential`类包装的一堆层构建的深度学习图像分类模型的示例代码：
- en: '[PRE26]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Next, compile the model with the loss function designated for a classification
    task:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用为分类任务指定的损失函数编译模型：
- en: '[PRE27]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To envision how the model handles and transforms data through different layers,
    you may wish to plot the model architecture, including the input and output shapes
    of the tensors it expects. You can use this command:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了想象模型如何通过不同层处理和转换数据，您可能希望绘制模型架构，包括它期望的张量的输入和输出形状。您可以使用以下命令：
- en: '[PRE28]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You might need to install the `pydot` and `graphviz` libraries before running
    this command:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行此命令之前，您可能需要安装`pydot`和`graphviz`库：
- en: '[PRE29]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[Figure 6-3](#image_classification_model_architecture) shows the model architecture.
    The question marks indicate the dimension that denotes sample size, which is only
    known during execution. This is because the model is designed to work with training
    samples of any size. The memory required to handle sample size is irrelevant and
    need not be specified at the model architecture level. Instead, the required memory
    will be defined during the training execution.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-3](#image_classification_model_architecture)展示了模型架构。问号表示表示样本大小的维度，在执行期间才知道。这是因为模型设计为适用于任何大小的训练样本。处理样本大小所需的内存是无关紧要的，不需要在模型架构级别指定。相反，所需的内存将在训练执行期间定义。'
- en: 'Next, start the training process:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，开始训练过程：
- en: '[PRE30]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Your results should be similar to those in [Figure 6-4](#model_training_results).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您的结果应该与[图6-4](#model_training_results)中的结果类似。
- en: This is how to leverage `tf.keras.Sequential` to build and train a deep learning
    model. As you can see, as long as you specify the input and output shapes to be
    consistent with the images and labels, you can stack as many layers as you wish.
    The training process is also pretty routine; it doesn’t deviate from what you
    saw in [Chapter 5](ch05.xhtml#data_pipelines_for_streaming_ingestion).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何利用`tf.keras.Sequential`来构建和训练深度学习模型的。正如您所看到的，只要您指定输入和输出形状与图像和标签一致，您可以堆叠任意多的层。训练过程也非常常规；它不偏离您在[第5章](ch05.xhtml#data_pipelines_for_streaming_ingestion)中看到的内容。
- en: '![Image classification model architecture](Images/t2pr_0603.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图像分类模型架构](Images/t2pr_0603.png)'
- en: Figure 6-3\. Image classification model architecture
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-3. 图像分类模型架构
- en: '![Model training results](Images/t2pr_0604.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![模型训练结果](Images/t2pr_0604.png)'
- en: Figure 6-4\. Model training results
  id: totrans-98
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-4. 模型训练结果
- en: 'Before we look at the imperative API, we’re going to take a quick detour: you’ll
    need to know a bit about class inheritance in Python to understand the imperative
    API.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看命令式API之前，我们将进行一个快速的绕道：您需要了解Python中的类继承的一些知识才能理解命令式API。
- en: Understanding Inheritance
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解继承
- en: '*Inheritance* is a technique used in object-oriented programming. It uses the
    concept of *classes* to encapsulate attributes and methods associated with a particular
    type of object. It also handles relationships between different types of objects.
    Inheritance is the means by which a particular class is allowed to use methods
    in another class.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*继承*是面向对象编程中使用的一种技术。它使用*类*的概念来封装与特定类型对象相关的属性和方法。它还处理不同类型对象之间的关系。继承是允许特定类使用另一个类中的方法的手段。'
- en: 'It is much easier to see how this works with a trivial example. Imagine we
    have a base (or parent) class, called `vehicle`. We also have another class, `truck`,
    which is a *child class* of `vehicle`: this is also known as a *derived class*
    or *inherited class*. We can define the `vehicle` class as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一个简单的例子更容易理解这个工作原理。想象我们有一个名为`vehicle`的基类（或父类）。我们还有另一个类`truck`，它是`vehicle`的*子类*：这也被称为*派生类*或*继承类*。我们可以定义`vehicle`类如下：
- en: '[PRE31]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This code shows a common pattern for defining a class. It has a constructor,
    `__init__`, which initializes the class’s attributes, such as make, model, horsepower,
    and weight. Then there is a function called `horsepower_to_weight_ratio` which,
    as you probably gathered, calculates the horsepower-to-weight ratio of a vehicle
    (we’ll call this the HW ratio). This function is also accessible to any child
    class of the `vehicle` class.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码展示了定义类的常见模式。它有一个构造函数`__init__`，用于初始化类的属性，比如制造商、型号、马力和重量。然后有一个名为`horsepower_to_weight_ratio`的函数，正如您可能猜到的，它计算车辆的马力重量比（我们将其称为HW比）。这个函数也可以被`vehicle`类的任何子类访问。
- en: 'Now let’s create `truck`, the child class for `vehicle`:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建`truck`，作为`vehicle`的子类：
- en: '[PRE32]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In this definition, `class truck(vehicle)` indicates that `truck` is a child
    class of `vehicle`.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个定义中，`class truck(vehicle)`表示`truck`是`vehicle`的子类。
- en: 'In the constructor `__init__`, `super` returns a temporary object of the parent
    class `vehicle` to the `truck` class. This object then calls the parent class’s
    `__init__`, which enables the `truck` class to reuse the same attributes defined
    in the parent class: make, model, horsepower, and weight. However, a truck also
    has an attribute that is unique: payload. This attribute is *not* inherited from
    the base class; rather, it is defined in the `truck` class. You can define payload
    with `self.payload = payload`. Here, the `self` keyword refers to the instance
    of this class. In this case, it is a `truck` instance, and `payload` is an arbitrary
    name you defined for this attribute.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在构造函数`__init__`中，`super`返回父类`vehicle`的临时对象给`truck`类。然后这个对象调用父类的`__init__`，这使得`truck`类能够重用父类中定义的相同属性：制造商、型号、马力和重量。然而，卡车还有一个独特的属性：有效载荷。这个属性*不是*从基类继承的；相反，它是在`truck`类中定义的。您可以用`self.payload
    = payload`定义有效载荷。这里，`self`关键字指的是这个类的实例。在这种情况下，它是一个`truck`实例，而`payload`是您为这个属性定义的任意名称。
- en: 'Next, there is a `__call__` function. This function makes the `truck` class
    “callable.” Before we look into what `__call__` does or what it means for a class
    to be callable, let’s define a few parameters and create a `truck` instance:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是一个`__call__`函数。这个函数使`truck`类“可调用”。在我们探讨`__call__`做什么或类可调用意味着什么之前，让我们定义一些参数并创建一个`truck`实例：
- en: '[PRE33]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'To make sure this has been done properly, print these attributes:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保这样做得当，请打印这些属性：
- en: '[PRE34]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This should produce the following output:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该产生以下输出：
- en: '[PRE35]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'What does it mean to make a Python class *callable*? Let’s say that you’re
    a bricklayer and you need to haul heavy loads in your truck. For you, the most
    important attribute of a truck is its horsepower-to-payload ratio (HP ratio).
    Fortunately, you can create an instance of the `truck` object and calculate the
    ratio right away:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让一个Python类变得*可调用*意味着什么？假设您是一名砌砖工，需要在卡车上运送重物。对您来说，卡车最重要的属性是其马力与有效载荷比（HP比率）。幸运的是，您可以创建一个`truck`对象的实例，并立即计算比率：
- en: '[PRE36]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The output will be 0.5.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将是0.5。
- en: 'This means that the `MyTruck` instance actually has a value associated with
    it. This value is defined as the horsepower-to-payload ratio. The calculation
    is done by the `__call__` function of the `truck` class, which is a built-in function
    for Python classes. When this function is explicitly defined to perform a certain
    logic, it works almost like a function call. Look at this line of code again:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着`MyTruck`实例实际上有一个与之关联的值。这个值被定义为马力与有效载荷比。这个计算是由`truck`类的`__call__`函数完成的，这是Python类的内置函数。当这个函数被显式定义为执行某种逻辑时，它几乎像一个函数调用。再看一下这行代码：
- en: '[PRE37]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: If you saw only this line, you might well think that `MyTruck` is a function,
    and `HORSEPOWER` and `PAYLOAD` are the inputs.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只看到这一行，您可能会认为`MyTruck`是一个函数，而`HORSEPOWER`和`PAYLOAD`是输入。
- en: By explicitly defining the `__call__` method to calculate the HP ratio, you
    made the `truck` class callable; in other words, you made it behave like a function.
    Now it can be called like a Python function.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通过显式定义`__call__`方法来计算HP比率，您使`truck`类可调用；换句话说，您使其表现得像一个函数。现在它可以像Python函数一样被调用。
- en: 'Next we want to find the HW ratio of our object `MyTruck`. You may notice that
    no method for this is defined in the `truck` class. However, since there *is*
    such a method in the parent `vehicle` class, `horsepower_to_weight_ratio`, `MyTruck`
    can perform the calculation using this method. This is a demonstration of *class
    inheritance*, where a child class may use a method defined directly by the parent
    class. To do this, you’d use:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们想要找到我们的对象`MyTruck`的HW比率。您可能会注意到`truck`类中没有为此定义任何方法。然而，由于父类`vehicle`中确实有这样一个方法，`horsepower_to_weight_ratio`，`MyTruck`可以使用这个方法进行计算。这是*类继承*的演示，子类可以使用父类直接定义的方法。要做到这一点，您可以使用：
- en: '[PRE38]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The output is 0.26666666666666666.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是0.26666666666666666。
- en: Using the Imperative API
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用命令式API
- en: Having seen how Python’s class inheritance works, you are now ready to learn
    how to use the imperative API to build a model. The imperative API is also known
    as the *model subclassing API* because any model you build is really inherited
    from a “Model” class. If you are familiar with an object-oriented programming
    language such as C#, C++, or Java, the imperative style should feel familiar.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 看过Python的类继承如何工作后，您现在可以学习如何使用命令式API构建模型。命令式API也被称为*模型子类API*，因为您构建的任何模型实际上都是从一个“Model”类继承的。如果您熟悉面向对象编程语言，如C#、C++或Java，那么命令式风格应该感觉很熟悉。
- en: Defining a Model as a Class
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将模型定义为一个类
- en: 'How would you define the model you built in the preceding section as a class?
    Let’s look at the code:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的部分中，您如何定义您构建的模型为一个类？让我们看看代码：
- en: '[PRE39]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: As the preceding code indicates, the `myModel` class inherits from the parent
    class `tf.keras.Model` in exactly the same way our `truck` class inherits from
    the parent class `vehicle`.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面的代码所示，`myModel`类从父类`tf.keras.Model`继承，就像我们的`truck`类从父类`vehicle`继承一样。
- en: 'The layers in the model are treated as attributes in the `myModel` class. These
    attributes are defined in the constructor function `__init__`. (Recall that attributes
    are parameters, such as horsepower, make, and model, while layers are defined
    by syntax, such as `tf.keras.layers.Conv2D`.) For the first layer in the model,
    the code is:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 模型中的层被视为`myModel`类中的属性。这些属性在构造函数`__init__`中定义。（回想一下，属性是参数，如马力、制造商和型号，而层是通过语法定义的，如`tf.keras.layers.Conv2D`。）对于模型中的第一层，代码是：
- en: '[PRE40]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: As you can see, all it takes to assign the layer is an object named `conv2d_initial`.
    Another important element in this definition is that you can pass a user-defined
    parameter into an attribute. Here, the constructor function `__init__` expects
    the user to provide an argument, `input_dim`, which it will pass to the `input_shape`
    argument.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，分配层只需要一个名为`conv2d_initial`的对象。在这个定义中的另一个重要元素是，您可以将用户定义的参数传递给属性。在这里，构造函数`__init__`期望用户提供一个参数`input_dim`，它将传递给`input_shape`参数。
- en: The benefit of this style is that if you want to reuse this model architecture
    for other types of image dimensions, you don’t have to create a new model; you
    just pass the image dimension as a user argument to this class, and you will get
    an instance of the class that can handle the image dimensions of your choice.
    In fact, you can add more user arguments to the input of the constructor function
    and pass them into different parts of the object, such as `kernel_size`. This
    is one way the object-oriented programming style promotes code reuse.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at another layer definition:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This layer will be used exactly as is multiple times in the model architecture,
    but you need to define it only once. However, if you need a different hyperparameter
    value, such as a different `pool_size`, then you need to create another attribute:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Here, there is no need to do so, since our model architecture reuses `maxpool2d`
    as is.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s take a look at the `call` function. Recall that you make a class callable
    by handling certain types of logic or calculations in Python’s built-in `__call__`
    function. In a similar spirit, TensorFlow created a built-in `call` function that
    makes the model class callable. Inside this function, you can see that the order
    of layers is the same as what goes into the sequential API (as you saw in [“Building
    the Model”](#building_the_model). The only difference is that these layers are
    now represented by class attributes, instead of a hardcoded layer definition.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, notice that in the following input, the user argument `input_dim` is
    passed into the attributes:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: This can provide flexibility and reusability to your model, depending on your
    image dimension requirements.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: In the `call` function, the object `x` is used to represent the model layer
    iteratively. After the final layer, `self.fc(x)`, is declared, it returns `x`
    as the model.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'To create an instance of a model that handles CIFAR-10’s image dimension of
    32 × 32 pixels, define the instance as:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This code creates an instance of `myModel` and initializes it with the CIFAR-10
    dataset’s image dimension. This model is represented as the `mdl` object. Next,
    just as you did in [“Building the Model”](#building_the_model), you have to designate
    a loss function and optimizer choice with the same syntax:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Now you may launch the training routine:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: You can expect a training outcome similar to the one in [Figure 6-5](#imperative_api_model_training_results).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '![Imperative API model training results](Images/t2pr_0605.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
- en: Figure 6-5\. Imperative API model training results
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Models trained with the symbolic API and the imperative API should produce similar
    training results.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the API
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have seen that the symbolic and imperative APIs can be used to build models
    with the same architecture. In most instances, your choice of API will be based
    on your preferred style and your familiarity with the syntax. However, there are
    some trade-offs that are worth noting.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: The biggest advantage of the symbolic API is its code readability, which makes
    maintenance easier. It is straightforward to see the model architecture, and you
    can see the input data as a flow of tensors through different layers, like a graph.
    Models built with the symbolic API can also leverage `tf.keras.utils.plot_model`
    to show the model architecture. Typically, this is where most of us would start
    when designing a deep learning model.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: The imperative API is definitely not as straightforward as the symbolic API
    when it comes to implementing a model architecture. As you’ve learned, this style
    stems from the object-oriented programming technique of class inheritance. If
    you are more comfortable with envisioning a model as an object rather than as
    a stack of operation layers, you may find this style more intuitive, as shown
    in [Figure 6-6](#the_tensorflow_modelapostrophes_imperati).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '![The TensorFlow model’s imperative API (a.k.a. model subclassing)](Images/t2pr_0606.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
- en: Figure 6-6\. The TensorFlow model’s imperative API (a.k.a. model subclassing)
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Essentially, any model you build is an *extension*, or inherited class, of the
    base model `tf.keras.Model`. Thus, when you build a model, you are really just
    creating an instance of a class that inherits all the attributes and functions
    from that base model. To fit the model for images of different dimensions, you
    simply have to instantiate it with different hyperparameters. If reusing the same
    model architecture is a part of your workflow, then the imperative API is a sensible
    choice to keep your code clean and concise.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Using the Built-In Training Loop
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, you have seen that all it takes to launch the model training process
    is the `fit` function. This function wraps a lot of complex operations for you,
    as [Figure 6-7](#elements_in_a_built-in_training_loop) shows.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '![Elements in a built-in training loop](Images/t2pr_0607.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
- en: Figure 6-7\. Elements in a built-in training loop
  id: totrans-165
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The model object contains information about the architecture, loss function,
    optimizer, and model metrics. Inside `fit`, you provide the training and validation
    data, the number of epochs to train it for, and how often to update the model
    parameters and test them with validation data.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: That’s all you have to do. The built-in training loop knows that when an epoch
    of training is complete, it’s time to perform cross validation with batched validation
    data. This is convenient and clear, and makes your code very easy to maintain.
    The output is produced at the end of each epoch, as seen in Figures [6-4](#model_training_results)
    and [6-5](#imperative_api_model_training_results).
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: If you ever need to look into the details of the training process, such as model
    accuracy within each step of incremental improvement before an epoch reaches the
    end, or if you ever want to create your own training metrics, then you need to
    build your own training loop. Next, we’ll look at how that works.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Creating and Using a Custom Training Loop
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With custom training loops, you lose the convenience of the `fit` function;
    instead, you have to write code to orchestrate the training process. Let’s say
    you want to monitor accuracy during each step of the model parameter within an
    epoch. You can reuse the model object (`model`) from [“Building the Model”](#building_the_model).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Elements of the Loop
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, create the optimizer and loss function objects:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Then create objects to represent model metrics:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This code creates two objects for model accuracy: one for the training data
    and one for the validation data. The `SparseCategoricalAccuracy` function is used
    because the output is a metric that calculates how often predictions match labels.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, for training, you need to create a function:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: In the preceding code, `@tf.function` is a Python decorator that converts a
    function which takes a tensor as input. It helps speed up the function’s execution.
    This function also includes a new object, `tf.GradientTape`. In this scope, TensorFlow
    executes the gradient descent algorithm for you; it automatically calculates the
    gradient by differentiating the loss function with respect to training weights
    in each node.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'The following line indicates the scope of the `GradientTape` object:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'And this next line of code means that you call on `model` to map the training
    data to an output (`logits`):'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Now calculate the output of the loss function when comparing the model output
    with the true label, `train_label`:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Then use the model’s parameters (`trainable_weights`) and the loss function’s
    value (`loss_value`) to calculate the gradient and update the model’s accuracy.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll need to do the same for the validation data:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Putting the Elements Together in a Custom Training Loop
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that you have all the pieces, you’re ready to create the custom training
    loop. Here is the general procedure:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Use a `for` loop to iterate through each epoch.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Within each epoch, use another `for` loop to iterate through each batch in the
    dataset.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In each batch, open a `GradientTape` object scope.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在每个批次中，打开一个`GradientTape`对象范围。
- en: In the scope, compute the loss function.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在范围内，计算损失函数。
- en: Outside the scope, retrieve gradients of the model weights.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在范围外，检索模型权重的梯度。
- en: Use the optimizer to update the model weights based on the gradient values.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用优化器根据梯度值更新模型权重。
- en: 'Following is the code snippet for a custom training loop:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是自定义训练循环的代码片段：
- en: '[PRE54]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[Figure 6-8](#output_from_executing_the_custom_trainin) shows typical output
    of the custom training loop execution.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-8](#output_from_executing_the_custom_trainin)显示了执行自定义训练循环的典型输出。'
- en: '![Output from executing the custom training loop](Images/t2pr_0608.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![执行自定义训练循环的输出](Images/t2pr_0608.png)'
- en: Figure 6-8\. Output from executing the custom training loop
  id: totrans-201
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-8。执行自定义训练循环的输出
- en: As you can see, at the end of every batch of 200 samples, the training loop
    calculates and shows the loss function’s value, giving you a microscopic view
    of what’s going on inside the training process. If you need that kind of visibility,
    building your own custom training loop will provide it. Just know that it takes
    considerably more effort than the convenient built-in training loop of the `fit`
    function.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，每个200个样本批次结束时，训练循环会计算并显示损失函数的值，让您可以查看训练过程内部发生的情况。如果您需要这种可见性，构建自己的自定义训练循环将提供它。只需知道，这比`fit`函数的便捷内置训练循环需要更多的努力。
- en: Wrapping Up
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned how to build a deep learning model in TensorFlow
    using symbolic and imperative APIs. Very often, both are capable of accomplishing
    the same architecture, especially when the data flows from input to output in
    a straight line (meaning there are no feedbacks or multiple inputs). You may see
    models with complex architecture and customized implementations using the imperative
    API. Choose the API that suits your case, convenience, and readability.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了如何使用符号和命令式API在TensorFlow中构建深度学习模型。通常情况下，两者都能够实现相同的架构，特别是当数据从输入到输出以直线流动时（意味着没有反馈或多个输入）。您可能会看到使用命令式API的复杂架构和定制实现的模型。选择适合您情况、方便和可读性的API。
- en: 'Whichever you choose, you’ll train the model in the same manner with the built-in
    `fit` function. The `fit` function executes the built-in training loop and shields
    you from worrying about how to actually orchestrate the training process. The
    details, such as calculating the loss function, comparing the model output with
    the true label, and updating the model parameter using the value of gradients,
    all happen behind the scenes for you. What you will see is the result at the end
    of each epoch: how accurate the model is with respect to training data and cross-validation
    data.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您选择哪种方式，您都将使用内置的`fit`函数以相同的方式训练模型。`fit`函数执行内置的训练循环，并让您不必担心如何实际编排训练过程。诸如计算损失函数、将模型输出与真实标签进行比较以及使用梯度值更新模型参数等细节都在幕后为您处理。您将看到的是每个时代结束时的结果：模型相对于训练数据和交叉验证数据的准确性。
- en: If you ever need a microscopic view of what’s going on inside an epoch, such
    as how accurate the model is with each batch of training data, then you need to
    write your own training loop, which is a considerably more laborious process.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要查看每个批次训练数据中模型的准确性等时代内部发生的情况，那么您需要编写自己的训练循环，这是一个相当费力的过程。
- en: In the next chapter, you will see other options available within the model training
    process that provide even more flexibility, without the nuanced coding process
    of a custom training loop.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将看到模型训练过程中提供的其他选项，这些选项提供了更多的灵活性，而无需进行自定义训练循环的复杂编码过程。
