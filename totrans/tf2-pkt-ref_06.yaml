- en: Chapter 6\. Model Creation Styles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you may have imagined, there is more than one way to build a deep learning
    model. In the previous chapters, you learned about `tf.keras.Sequential`, known
    as the *symbolic API*, which is commonly the starting point when teaching model
    creation. Another style of API that you might come across is known as the *imperative
    API*. Both symbolic and imperative APIs are capable of building deep learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: By and large, which API you choose is a matter of style. Depending on your programming
    experience and background, one or the other might feel more natural for you. In
    this chapter, you will learn how to build the same model with both APIs. Specifically,
    you will learn how to build an image classification model using the [CIFAR-10
    image dataset](https://oreil.ly/W81qK). This dataset consists of 10 commonly seen
    *classes*, or categories, of images. Like the flower images we used previously,
    the CIFAR-10 images are available as part of the TensorFlow distribution. However,
    while the flower images came in JPEG format, the CIFAR-10 images are NumPy arrays.
    To stream them into the training process, instead of using the `flow_from_directory`
    method as you did in [Chapter 5](ch05.xhtml#data_pipelines_for_streaming_ingestion),
    you’ll use the `from_tensor_slices` method.
  prefs: []
  type: TYPE_NORMAL
- en: After establishing the data streaming process with `from_tensor_slices`, you’ll
    first use the symbolic API to build and train the image classification model,
    and then use the imperative API. You will see that regardless of how you build
    the model architecture, the results are very similar.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Symbolic API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have already seen the symbolic API, `tf.keras.Sequential`, at work in this
    book’s examples. Within `tf.keras.Sequential` there are stacks of layers, each
    of which performs certain operations to input data. Since models are built layer
    by layer, this is an intuitive way to envision the process. In most cases, you
    only have one source of input (in this case, a stream of images), and the output
    is the class of input images. In [“Model Implementation with TensorFlow Hub”](ch04.xhtml#model_implementation_with_tensorflow_hub),
    you learned how to build a model with TensorFlow Hub. The model architecture is
    defined with the sequential API, as shown in [Figure 6-1](#sequential_api_pattern_and_data_flow).
  prefs: []
  type: TYPE_NORMAL
- en: '![Sequential API pattern and data flow](Images/t2pr_0601.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-1\. Sequential API pattern and data flow
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this section, you will learn how to use this API to build and train an image
    classification model with CIFAR-10 images.
  prefs: []
  type: TYPE_NORMAL
- en: Loading the CIFAR-10 Images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The CIFAR-10 image dataset contains 10 classes: airplanes, automobiles, birds,
    cats, deer, dogs, frogs, horses, ships, and trucks. All images are 32 × 32 pixels
    and colored with three channels (RGB).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by importing the necessary libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This code downloads the CIFAR-10 images to your Python runtime, partitioned
    into training and test sets. You can verify the format with a `type` statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The output will be a data type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'It is also important to know the array’s shape, which you can find with the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the array shapes for the images and labels, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You can do the same for the test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see from the outputs, the CIFAR-10 dataset consists of 50,000 training
    images, each 32 × 32 × 3 pixels. The accompanying 50,000 labels are a one-dimensional
    array of indices that denote image classes. Likewise, there are 10,000 test images
    with corresponding labels. The label indices correspond to the following names:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Thus, an index of 0 denotes the label “airplane,” while an index of 9 denotes
    “truck.”
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting Label Distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now it’s time to find out the distribution of these classes and see some of
    the images. To find out how many samples each class has, look at the distribution
    of training labels by class using the NumPy `unique` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return sample counts for each label. To display it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'It will show the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This means that there are 5,000 images in each label (class). The training data
    is evenly distributed among all labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, you can verify the distribution of the test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The output confirms the count of 1,000 images for each label:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Inspecting Images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s take a look at some of the images to ensure their data quality. For this
    exercise, you’ll randomly sample and display 25 images of the 50,000 in the training
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'How does TensorFlow make this random selection? The images are indexed from
    0 to 49,999\. To randomly select a finite number of indices from this range, use
    Python’s `random` library, which takes a Python list as input and randomly selects
    a finite number of samples from it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: This code randomly selects 25 elements from `a_list` and stores the results
    in `selected_elements`. If `a_list` corresponds to the image indices, then `selected_elements`
    will contain 25 indices drawn at random from `a_list`. You will use `selected_elements`
    to access and display these 25 training images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you need to create `train_idx`, the list that holds the indices for training
    images. You’ll use the Python `range` function to create an object that holds
    integers in the range 0 to 49,999:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code creates a `range` object that holds integers that start at
    0 and go up to `len(train_labels)`, or the length of the list `training_labels`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, convert the `range` object to a Python list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This list is now ready to serve as input to the Python `random.sample` function.
    Now you can start on your code.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create `train_idx`, which is a list of indices from 0 to 49,999:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Then use the `random` library to generate the random selection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The seed operation in the second line ensures that your selection is reproducible,
    which is helpful for debugging purposes. You can use any integer for `seed`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `random_sel` list will hold 25 randomly selected indices that look something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can plot images based on these indices and display their labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This code snippet displays a panel of 25 images along with their labels, as
    shown in [Figure 6-2](Images/#twenty-five_images_from_the_cifar-ten_da). (Because
    this is a random sample, your results will vary.)
  prefs: []
  type: TYPE_NORMAL
- en: '![Twenty-five images from the CIFAR-10 dataset, selected at random](Images/t2pr_0602.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-2\. Twenty-five images from the CIFAR-10 dataset, selected at random
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Building a Data Pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, you will build a data ingestion pipeline using `from_tensor_slices`.
    Since there are only two partitions, training and test, you’ll need to reserve
    half of the test partition for cross validation during the training process. Select
    the first 500 as cross-validation data and the remaining 500 as test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: This code creates two dataset objects based on image indices, `validation_dataset`
    and `test_dataset`, with 500 samples in each set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now create a similar dataset object for the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'All training images are used here. You can confirm that by counting the samples
    in `train_dataset`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the expected result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Batching the Dataset for Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To finish setting up the data ingestion pipeline for training, you will need
    to divide the training data into batches. The size of a batch, or number of training
    samples, is the number required for the model training process to update the model
    weights and bias, and then move along one step to reduce the error gradient.
  prefs: []
  type: TYPE_NORMAL
- en: 'Batch your training data with the following code, which first shuffles the
    training dataset and then creates multiple batches of 200 samples each:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Likewise, you’ll do the same for cross-validation and test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The cross-validation and test datasets each consist of one 500-sample batch.
    The code sets parameters to inform the training process how many batches of training
    and validation data to expect. The parameter for training data is `STEPS_PER_EPOCH`.
    The parameter for cross-validation data is `VALIDATION_STEPS` and it is set to
    1 because the data size and batch size are both 500\. Note that a double slash
    (//) denotes *floor division* (that is, rounding down to the nearest integer).
  prefs: []
  type: TYPE_NORMAL
- en: Now that your training and validation datasets are ready, your next step is
    to build the model with the symbolic API.
  prefs: []
  type: TYPE_NORMAL
- en: Building the Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now you are ready to build the model. Here is example code for a deep learning,
    image-classification model, built with a stack of layers wrapped by the `tf.keras.Sequential`
    class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, compile the model with the loss function designated for a classification
    task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'To envision how the model handles and transforms data through different layers,
    you may wish to plot the model architecture, including the input and output shapes
    of the tensors it expects. You can use this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'You might need to install the `pydot` and `graphviz` libraries before running
    this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 6-3](#image_classification_model_architecture) shows the model architecture.
    The question marks indicate the dimension that denotes sample size, which is only
    known during execution. This is because the model is designed to work with training
    samples of any size. The memory required to handle sample size is irrelevant and
    need not be specified at the model architecture level. Instead, the required memory
    will be defined during the training execution.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, start the training process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Your results should be similar to those in [Figure 6-4](#model_training_results).
  prefs: []
  type: TYPE_NORMAL
- en: This is how to leverage `tf.keras.Sequential` to build and train a deep learning
    model. As you can see, as long as you specify the input and output shapes to be
    consistent with the images and labels, you can stack as many layers as you wish.
    The training process is also pretty routine; it doesn’t deviate from what you
    saw in [Chapter 5](ch05.xhtml#data_pipelines_for_streaming_ingestion).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image classification model architecture](Images/t2pr_0603.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-3\. Image classification model architecture
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![Model training results](Images/t2pr_0604.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-4\. Model training results
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Before we look at the imperative API, we’re going to take a quick detour: you’ll
    need to know a bit about class inheritance in Python to understand the imperative
    API.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Inheritance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Inheritance* is a technique used in object-oriented programming. It uses the
    concept of *classes* to encapsulate attributes and methods associated with a particular
    type of object. It also handles relationships between different types of objects.
    Inheritance is the means by which a particular class is allowed to use methods
    in another class.'
  prefs: []
  type: TYPE_NORMAL
- en: 'It is much easier to see how this works with a trivial example. Imagine we
    have a base (or parent) class, called `vehicle`. We also have another class, `truck`,
    which is a *child class* of `vehicle`: this is also known as a *derived class*
    or *inherited class*. We can define the `vehicle` class as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: This code shows a common pattern for defining a class. It has a constructor,
    `__init__`, which initializes the class’s attributes, such as make, model, horsepower,
    and weight. Then there is a function called `horsepower_to_weight_ratio` which,
    as you probably gathered, calculates the horsepower-to-weight ratio of a vehicle
    (we’ll call this the HW ratio). This function is also accessible to any child
    class of the `vehicle` class.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s create `truck`, the child class for `vehicle`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In this definition, `class truck(vehicle)` indicates that `truck` is a child
    class of `vehicle`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the constructor `__init__`, `super` returns a temporary object of the parent
    class `vehicle` to the `truck` class. This object then calls the parent class’s
    `__init__`, which enables the `truck` class to reuse the same attributes defined
    in the parent class: make, model, horsepower, and weight. However, a truck also
    has an attribute that is unique: payload. This attribute is *not* inherited from
    the base class; rather, it is defined in the `truck` class. You can define payload
    with `self.payload = payload`. Here, the `self` keyword refers to the instance
    of this class. In this case, it is a `truck` instance, and `payload` is an arbitrary
    name you defined for this attribute.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, there is a `__call__` function. This function makes the `truck` class
    “callable.” Before we look into what `__call__` does or what it means for a class
    to be callable, let’s define a few parameters and create a `truck` instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'To make sure this has been done properly, print these attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'This should produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'What does it mean to make a Python class *callable*? Let’s say that you’re
    a bricklayer and you need to haul heavy loads in your truck. For you, the most
    important attribute of a truck is its horsepower-to-payload ratio (HP ratio).
    Fortunately, you can create an instance of the `truck` object and calculate the
    ratio right away:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: The output will be 0.5.
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that the `MyTruck` instance actually has a value associated with
    it. This value is defined as the horsepower-to-payload ratio. The calculation
    is done by the `__call__` function of the `truck` class, which is a built-in function
    for Python classes. When this function is explicitly defined to perform a certain
    logic, it works almost like a function call. Look at this line of code again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: If you saw only this line, you might well think that `MyTruck` is a function,
    and `HORSEPOWER` and `PAYLOAD` are the inputs.
  prefs: []
  type: TYPE_NORMAL
- en: By explicitly defining the `__call__` method to calculate the HP ratio, you
    made the `truck` class callable; in other words, you made it behave like a function.
    Now it can be called like a Python function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next we want to find the HW ratio of our object `MyTruck`. You may notice that
    no method for this is defined in the `truck` class. However, since there *is*
    such a method in the parent `vehicle` class, `horsepower_to_weight_ratio`, `MyTruck`
    can perform the calculation using this method. This is a demonstration of *class
    inheritance*, where a child class may use a method defined directly by the parent
    class. To do this, you’d use:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: The output is 0.26666666666666666.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Imperative API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having seen how Python’s class inheritance works, you are now ready to learn
    how to use the imperative API to build a model. The imperative API is also known
    as the *model subclassing API* because any model you build is really inherited
    from a “Model” class. If you are familiar with an object-oriented programming
    language such as C#, C++, or Java, the imperative style should feel familiar.
  prefs: []
  type: TYPE_NORMAL
- en: Defining a Model as a Class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'How would you define the model you built in the preceding section as a class?
    Let’s look at the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: As the preceding code indicates, the `myModel` class inherits from the parent
    class `tf.keras.Model` in exactly the same way our `truck` class inherits from
    the parent class `vehicle`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The layers in the model are treated as attributes in the `myModel` class. These
    attributes are defined in the constructor function `__init__`. (Recall that attributes
    are parameters, such as horsepower, make, and model, while layers are defined
    by syntax, such as `tf.keras.layers.Conv2D`.) For the first layer in the model,
    the code is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, all it takes to assign the layer is an object named `conv2d_initial`.
    Another important element in this definition is that you can pass a user-defined
    parameter into an attribute. Here, the constructor function `__init__` expects
    the user to provide an argument, `input_dim`, which it will pass to the `input_shape`
    argument.
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of this style is that if you want to reuse this model architecture
    for other types of image dimensions, you don’t have to create a new model; you
    just pass the image dimension as a user argument to this class, and you will get
    an instance of the class that can handle the image dimensions of your choice.
    In fact, you can add more user arguments to the input of the constructor function
    and pass them into different parts of the object, such as `kernel_size`. This
    is one way the object-oriented programming style promotes code reuse.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at another layer definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'This layer will be used exactly as is multiple times in the model architecture,
    but you need to define it only once. However, if you need a different hyperparameter
    value, such as a different `pool_size`, then you need to create another attribute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Here, there is no need to do so, since our model architecture reuses `maxpool2d`
    as is.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s take a look at the `call` function. Recall that you make a class callable
    by handling certain types of logic or calculations in Python’s built-in `__call__`
    function. In a similar spirit, TensorFlow created a built-in `call` function that
    makes the model class callable. Inside this function, you can see that the order
    of layers is the same as what goes into the sequential API (as you saw in [“Building
    the Model”](#building_the_model). The only difference is that these layers are
    now represented by class attributes, instead of a hardcoded layer definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, notice that in the following input, the user argument `input_dim` is
    passed into the attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: This can provide flexibility and reusability to your model, depending on your
    image dimension requirements.
  prefs: []
  type: TYPE_NORMAL
- en: In the `call` function, the object `x` is used to represent the model layer
    iteratively. After the final layer, `self.fc(x)`, is declared, it returns `x`
    as the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create an instance of a model that handles CIFAR-10’s image dimension of
    32 × 32 pixels, define the instance as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'This code creates an instance of `myModel` and initializes it with the CIFAR-10
    dataset’s image dimension. This model is represented as the `mdl` object. Next,
    just as you did in [“Building the Model”](#building_the_model), you have to designate
    a loss function and optimizer choice with the same syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you may launch the training routine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: You can expect a training outcome similar to the one in [Figure 6-5](#imperative_api_model_training_results).
  prefs: []
  type: TYPE_NORMAL
- en: '![Imperative API model training results](Images/t2pr_0605.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-5\. Imperative API model training results
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Models trained with the symbolic API and the imperative API should produce similar
    training results.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have seen that the symbolic and imperative APIs can be used to build models
    with the same architecture. In most instances, your choice of API will be based
    on your preferred style and your familiarity with the syntax. However, there are
    some trade-offs that are worth noting.
  prefs: []
  type: TYPE_NORMAL
- en: The biggest advantage of the symbolic API is its code readability, which makes
    maintenance easier. It is straightforward to see the model architecture, and you
    can see the input data as a flow of tensors through different layers, like a graph.
    Models built with the symbolic API can also leverage `tf.keras.utils.plot_model`
    to show the model architecture. Typically, this is where most of us would start
    when designing a deep learning model.
  prefs: []
  type: TYPE_NORMAL
- en: The imperative API is definitely not as straightforward as the symbolic API
    when it comes to implementing a model architecture. As you’ve learned, this style
    stems from the object-oriented programming technique of class inheritance. If
    you are more comfortable with envisioning a model as an object rather than as
    a stack of operation layers, you may find this style more intuitive, as shown
    in [Figure 6-6](#the_tensorflow_modelapostrophes_imperati).
  prefs: []
  type: TYPE_NORMAL
- en: '![The TensorFlow model’s imperative API (a.k.a. model subclassing)](Images/t2pr_0606.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-6\. The TensorFlow model’s imperative API (a.k.a. model subclassing)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Essentially, any model you build is an *extension*, or inherited class, of the
    base model `tf.keras.Model`. Thus, when you build a model, you are really just
    creating an instance of a class that inherits all the attributes and functions
    from that base model. To fit the model for images of different dimensions, you
    simply have to instantiate it with different hyperparameters. If reusing the same
    model architecture is a part of your workflow, then the imperative API is a sensible
    choice to keep your code clean and concise.
  prefs: []
  type: TYPE_NORMAL
- en: Using the Built-In Training Loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, you have seen that all it takes to launch the model training process
    is the `fit` function. This function wraps a lot of complex operations for you,
    as [Figure 6-7](#elements_in_a_built-in_training_loop) shows.
  prefs: []
  type: TYPE_NORMAL
- en: '![Elements in a built-in training loop](Images/t2pr_0607.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-7\. Elements in a built-in training loop
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The model object contains information about the architecture, loss function,
    optimizer, and model metrics. Inside `fit`, you provide the training and validation
    data, the number of epochs to train it for, and how often to update the model
    parameters and test them with validation data.
  prefs: []
  type: TYPE_NORMAL
- en: That’s all you have to do. The built-in training loop knows that when an epoch
    of training is complete, it’s time to perform cross validation with batched validation
    data. This is convenient and clear, and makes your code very easy to maintain.
    The output is produced at the end of each epoch, as seen in Figures [6-4](#model_training_results)
    and [6-5](#imperative_api_model_training_results).
  prefs: []
  type: TYPE_NORMAL
- en: If you ever need to look into the details of the training process, such as model
    accuracy within each step of incremental improvement before an epoch reaches the
    end, or if you ever want to create your own training metrics, then you need to
    build your own training loop. Next, we’ll look at how that works.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and Using a Custom Training Loop
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With custom training loops, you lose the convenience of the `fit` function;
    instead, you have to write code to orchestrate the training process. Let’s say
    you want to monitor accuracy during each step of the model parameter within an
    epoch. You can reuse the model object (`model`) from [“Building the Model”](#building_the_model).
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Elements of the Loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First, create the optimizer and loss function objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Then create objects to represent model metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This code creates two objects for model accuracy: one for the training data
    and one for the validation data. The `SparseCategoricalAccuracy` function is used
    because the output is a metric that calculates how often predictions match labels.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, for training, you need to create a function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, `@tf.function` is a Python decorator that converts a
    function which takes a tensor as input. It helps speed up the function’s execution.
    This function also includes a new object, `tf.GradientTape`. In this scope, TensorFlow
    executes the gradient descent algorithm for you; it automatically calculates the
    gradient by differentiating the loss function with respect to training weights
    in each node.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following line indicates the scope of the `GradientTape` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'And this next line of code means that you call on `model` to map the training
    data to an output (`logits`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now calculate the output of the loss function when comparing the model output
    with the true label, `train_label`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Then use the model’s parameters (`trainable_weights`) and the loss function’s
    value (`loss_value`) to calculate the gradient and update the model’s accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll need to do the same for the validation data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Putting the Elements Together in a Custom Training Loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that you have all the pieces, you’re ready to create the custom training
    loop. Here is the general procedure:'
  prefs: []
  type: TYPE_NORMAL
- en: Use a `for` loop to iterate through each epoch.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Within each epoch, use another `for` loop to iterate through each batch in the
    dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In each batch, open a `GradientTape` object scope.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the scope, compute the loss function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Outside the scope, retrieve gradients of the model weights.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the optimizer to update the model weights based on the gradient values.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Following is the code snippet for a custom training loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 6-8](#output_from_executing_the_custom_trainin) shows typical output
    of the custom training loop execution.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Output from executing the custom training loop](Images/t2pr_0608.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-8\. Output from executing the custom training loop
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, at the end of every batch of 200 samples, the training loop
    calculates and shows the loss function’s value, giving you a microscopic view
    of what’s going on inside the training process. If you need that kind of visibility,
    building your own custom training loop will provide it. Just know that it takes
    considerably more effort than the convenient built-in training loop of the `fit`
    function.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to build a deep learning model in TensorFlow
    using symbolic and imperative APIs. Very often, both are capable of accomplishing
    the same architecture, especially when the data flows from input to output in
    a straight line (meaning there are no feedbacks or multiple inputs). You may see
    models with complex architecture and customized implementations using the imperative
    API. Choose the API that suits your case, convenience, and readability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whichever you choose, you’ll train the model in the same manner with the built-in
    `fit` function. The `fit` function executes the built-in training loop and shields
    you from worrying about how to actually orchestrate the training process. The
    details, such as calculating the loss function, comparing the model output with
    the true label, and updating the model parameter using the value of gradients,
    all happen behind the scenes for you. What you will see is the result at the end
    of each epoch: how accurate the model is with respect to training data and cross-validation
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: If you ever need a microscopic view of what’s going on inside an epoch, such
    as how accurate the model is with each batch of training data, then you need to
    write your own training loop, which is a considerably more laborious process.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will see other options available within the model training
    process that provide even more flexibility, without the nuanced coding process
    of a custom training loop.
  prefs: []
  type: TYPE_NORMAL
