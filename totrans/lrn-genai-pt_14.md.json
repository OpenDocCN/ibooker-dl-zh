["```py\nwith open(\"files/OldManAndSea.txt\",\"r\", encoding='utf-8-sig') as f:\n    text=f.read()\ntext=list(text)                                             ①\nfor i in range(len(text)):\n    if text[i]=='\"':\n        if text[i+1]==' ' or text[i+1]=='\\n':\n            text[i]='\"'                                     ②\n        if text[i+1]!=' ' and text[i+1]!='\\n':\n            text[i]='\"'                                     ③\n    if text[i]==\"'\":\n        if text[i-1]!=' ' and text[i-1]!='\\n':\n            text[i]='''                                     ④\ntext=\"\".join(text)                                          ⑤\n```", "```py\nwith open(\"files/ToWhomTheBellTolls.txt\",\"r\", encoding='utf-8-sig') as f:\n    text1=f.read()                                            ①\n\nwith open(\"files/FarewellToArms.txt\",\"r\", encoding='utf-8-sig') as f:\n    text2=f.read()                                            ②\n\ntext=text+\" \"+text1+\" \"+text2                                 ③\n\nwith open(\"files/ThreeNovels.txt\",\"w\", \n          encoding='utf-8-sig') as f:\n    f.write(text)                                             ④\nprint(text[:250])\n```", "```py\nHe was an old man who fished alone in a skiff in the Gulf Stream and he\nhad gone eighty-four days now without taking a fish. In the first\nforty days a boy had been with him. But after forty days without a\nfish the boy's parents had told him that th\n```", "```py\ntext=text.lower().replace(\"\\n\", \" \")                         ①\n\nchars=set(text.lower())\npunctuations=[i for i in chars if i.isalpha()==False\n              and i.isdigit()==False]                        ②\nprint(punctuations)\n\nfor x in punctuations:\n    text=text.replace(f\"{x}\", f\" {x} \")                      ③\ntext_tokenized=text.split()\n\nunique_tokens=set(text_tokenized)\nprint(len(unique_tokens))                                    ④\n```", "```py\n[')', '.', '&', ':', '(', ';', '-', '!', '\"', ' ', ''', '\"', '?', ',', ''']\n10599\n```", "```py\nfrom collections import Counter   \n\nword_counts=Counter(text_tokenized)    \nwords=sorted(word_counts, key=word_counts.get,\n                      reverse=True)     \nwords.append(\"UNK\")                                            ①\ntext_length=len(text_tokenized)\nntokens=len(words)                                             ②\nprint(f\"the text contains {text_length} words\")\nprint(f\"there are {ntokens} unique tokens\")  \nword_to_int={v:k for k,v in enumerate(words)}                  ③\nint_to_word={v:k for k,v in word_to_int.items()}               ④\nprint({k:v for k,v in word_to_int.items() if k in words[:10]})\nprint({k:v for k,v in int_to_word.items() if v in words[:10]})\n```", "```py\nthe text contains 698207 words\nthere are 10600 unique tokens\n{'.': 0, 'the': 1, ',': 2, '\"': 3, '\"': 4, 'and': 5, 'i': 6, 'to': 7, 'he': 8, 'it': 9}\n{0: '.', 1: 'the', 2: ',', 3: '\"', 4: '\"', 5: 'and', 6: 'i', 7: 'to', 8: 'he', 9: 'it'}\n```", "```py\nprint(text_tokenized[0:20])\nwordidx=[word_to_int[w] for w in text_tokenized]\nprint([word_to_int[w] for w in text_tokenized[0:20]])\n```", "```py\n['he', 'was', 'an', 'old', 'man', 'who', 'fished', 'alone', 'in', 'a', \n'skiff', 'in', 'the', 'gulf', 'stream', 'and', 'he', 'had', 'gone',\n 'eighty']\n[8, 16, 98, 110, 67, 85, 6052, 314, 14, 11, 1039, 14, 1, 3193, 507, 5, 8,\n25, 223, 3125] \n```", "```py\nimport torch\n\nseq_len=128                                                 ①\nxys=[]\nfor n in range(0, len(wordidx)-seq_len-1):\n    x = wordidx[n:n+seq_len]                                ②\n    y = wordidx[n+1:n+seq_len+1]                            ③\n    xys.append((torch.tensor(x),(torch.tensor(y))))         ④\n```", "```py\nfrom torch.utils.data import DataLoader\n\ntorch.manual_seed(42)\nbatch_size=32\nloader = DataLoader(xys, batch_size=batch_size, shuffle=True)\n\nx,y=next(iter(loader))\nprint(x)\nprint(y)\nprint(x.shape,y.shape)\n```", "```py\ntensor([[   3,  129,    9,  ...,   11,  251,   10],\n        [   5,   41,   32,  ...,  995,   52,   23],\n        [   6,   25,   11,  ...,   15,    0,   24],\n        ...,\n        [1254,    0,    4,  ...,   15,    0,    3],\n        [  17,    8, 1388,  ...,    0,    8,   16],\n        [  55,   20,  156,  ...,   74,   76,   12]])\ntensor([[ 129,    9,   23,  ...,  251,   10,    1],\n        [  41,   32,   34,  ...,   52,   23,    1],\n        [  25,   11,   59,  ...,    0,   24,   25],\n        ...,\n        [   0,    4,    3,  ...,    0,    3,   93],\n        [   8, 1388,    1,  ...,    8,   16, 1437],\n        [  20,  156,  970,  ...,   76,   12,   29]])\ntorch.Size([32, 128]) torch.Size([32, 128])\n```", "```py\nimport torch\nfrom torch import nn\nimport math\n\ndevice=\"cuda\" if torch.cuda.is_available() else \"cpu\"\nclass GELU(nn.Module):\n    def forward(self, x):\n        return 0.5*x*(1.0+torch.tanh(math.sqrt(2.0/math.pi)*\\\n                       (x + 0.044715 * torch.pow(x, 3.0))))\n```", "```py\nclass Config():\n    def __init__(self):\n        self.n_layer = 3\n        self.n_head = 4\n        self.n_embd = 256\n        self.vocab_size = ntokens\n        self.block_size = 128 \n        self.embd_pdrop = 0.1\n        self.resid_pdrop = 0.1\n        self.attn_pdrop = 0.1\nconfig=Config()\n```", "```py\nimport torch.nn.functional as F\nclass CausalSelfAttention(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n        self.attn_dropout = nn.Dropout(config.attn_pdrop)\n        self.resid_dropout = nn.Dropout(config.resid_pdrop)\n        self.register_buffer(\"bias\", torch.tril(torch.ones(\\\n                   config.block_size, config.block_size))\n             .view(1, 1, config.block_size, config.block_size))\n        self.n_head = config.n_head\n        self.n_embd = config.n_embd\n\n    def forward(self, x):\n        B, T, C = x.size() \n        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n        hs = C // self.n_head\n        k = k.view(B, T, self.n_head, hs).transpose(1, 2)\n        q = q.view(B, T, self.n_head, hs).transpose(1, 2)\n        v = v.view(B, T, self.n_head, hs).transpose(1, 2)\n\n        att = (q @ k.transpose(-2, -1)) *\\\n            (1.0 / math.sqrt(k.size(-1)))\n        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, \\\n                              float(‚-inf'))\n        att = F.softmax(att, dim=-1)\n        att = self.attn_dropout(att)\n        y = att @ v \n        y = y.transpose(1, 2).contiguous().view(B, T, C)\n        y = self.resid_dropout(self.c_proj(y))\n        return y\n```", "```py\nclass Block(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.ln_1 = nn.LayerNorm(config.n_embd)\n        self.attn = CausalSelfAttention(config)\n        self.ln_2 = nn.LayerNorm(config.n_embd)\n        self.mlp = nn.ModuleDict(dict(\n            c_fc   = nn.Linear(config.n_embd, 4 * config.n_embd),\n            c_proj = nn.Linear(4 * config.n_embd, config.n_embd),\n            act    = GELU(),\n            dropout = nn.Dropout(config.resid_pdrop),\n        ))\n        m = self.mlp\n        self.mlpf=lambda x:m.dropout(m.c_proj(m.act(m.c_fc(x)))) \n\n    def forward(self, x):\n        x = x + self.attn(self.ln_1(x))\n        x = x + self.mlpf(self.ln_2(x))\n        return x\n```", "```py\nclass Model(nn.Module):\n    def __init__(self, config):\n        super().__init__()\n        self.block_size = config.block_size\n        self.transformer = nn.ModuleDict(dict(\n            wte = nn.Embedding(config.vocab_size, config.n_embd),\n            wpe = nn.Embedding(config.block_size, config.n_embd),\n            drop = nn.Dropout(config.embd_pdrop),\n            h = nn.ModuleList([Block(config) \n                               for _ in range(config.n_layer)]),\n            ln_f = nn.LayerNorm(config.n_embd),))\n        self.lm_head = nn.Linear(config.n_embd,\n                                 config.vocab_size, bias=False)\n        for pn, p in self.named_parameters():\n            if pn.endswith('c_proj.weight'):    \n                torch.nn.init.normal_(p, mean=0.0, \n                  std=0.02/math.sqrt(2 * config.n_layer))\n    def forward(self, idx, targets=None):\n        b, t = idx.size()\n        pos=torch.arange(0,t,dtype=\\\n            torch.long).unsqueeze(0).to(device)              ①\n        tok_emb = self.transformer.wte(idx) \n        pos_emb = self.transformer.wpe(pos) \n        x = self.transformer.drop(tok_emb + pos_emb)\n        for block in self.transformer.h:\n            x = block(x)\n        x = self.transformer.ln_f(x)\n        logits = self.lm_head(x)\n        return logits\n```", "```py\nmodel=Model(config)\nmodel.to(device)\nnum=sum(p.numel() for p in model.transformer.parameters())\nprint(\"number of parameters: %.2fM\" % (num/1e6,))\nprint(model)\n```", "```py\nnumber of parameters: 5.12M\nModel(\n  (transformer): ModuleDict(\n    (wte): Embedding(10600, 256)\n    (wpe): Embedding(128, 256)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-2): 3 x Block(\n        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (attn): CausalSelfAttention(\n          (c_attn): Linear(in_features=256, out_features=768, bias=True)\n          (c_proj): Linear(in_features=256, out_features=256, bias=True)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (mlp): ModuleDict(\n          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n          (act): GELU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=256, out_features=10600, bias=False)\n)\n```", "```py\nlr=0.0001\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nloss_func = nn.CrossEntropyLoss()\n```", "```py\nmodel.train()  \nfor i in range(1,41):\n    tloss = 0.\n    for idx, (x,y) in enumerate(loader):                      ①\n        x,y=x.to(device),y.to(device)\n        output = model(x)\n        loss=loss_func(output.view(-1,output.size(-1)),\n                           y.view(-1))                        ②\n        optimizer.zero_grad()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(),1)        ③\n        optimizer.step()                                      ④\n        tloss += loss.item()\n    print(f'epoch {i} loss {tloss/(idx+1)}') \n    if i%10==0:\n        torch.save(model.state_dict(),f'files/GPTe{i}.pth')   ⑤\n```", "```py\ndef sample(idx, weights, max_new_tokens, temperature=1.0, top_k=None):\n    model.eval()\n    model.load_state_dict(torch.load(weights,\n        map_location=device))                                 ①\n    original_length=len(idx[0])\n    for _ in range(max_new_tokens):                           ②\n        if idx.size(1) <= config.block_size:\n            idx_cond = idx  \n        else:\n            idx_cond = idx[:, -config.block_size:]\n        logits = model(idx_cond.to(device))                   ③\n        logits = logits[:, -1, :] / temperature\n        if top_k is not None:\n            v, _ = torch.topk(logits, top_k)\n            logits[logits < v[:, [-1]]] = -float('Inf')\n        probs = F.softmax(logits, dim=-1)\n        idx_next=torch.multinomial(probs,num_samples=1)\n        idx = torch.cat((idx, idx_next.cpu()), dim=1)         ④\n    return idx[:, original_length:]                           ⑤\n```", "```py\nUNK=word_to_int[\"UNK\"]\ndef generate(prompt, weights, max_new_tokens, temperature=1.0,\n             top_k=None):\n    assert len(prompt)>0, \"prompt must contain at least one token\" ①\n    text=prompt.lower().replace(\"\\n\", \" \")\n    for x in punctuations:\n        text=text.replace(f\"{x}\", f\" {x} \")\n    text_tokenized=text.split() \n    idx=[word_to_int.get(w,UNK) for w in text_tokenized]           ②\n    idx=torch.LongTensor(idx).unsqueeze(0)\n    idx=sample(idx, weights, max_new_tokens, \n               temperature=1.0, top_k=None)                        ③\n    tokens=[int_to_word[i] for i in idx.squeeze().numpy()]         ④\n    text=\" \".join(tokens)\n    for x in '''\").:;!?,-''''':\n        text=text.replace(f\" {x}\", f\"{x}\") \n    for x in '''\"(-''''':\n        text=text.replace(f\"{x} \", f\"{x}\")     \n    return prompt+\" \"+text\n```", "```py\nprompt=\"UNK\"\nfor i in range(10):\n    torch.manual_seed(i)\n    print(generate(prompt,'files/GPTe20.pth',max_new_tokens=20)[4:]))\n```", "```py\nway.\" \"kümmel,\" i said. \"it's the way to talk about it\n--------------------------------------------------\n,\" robert jordan said. \"but do not realize how far he is ruined.\" \"pero\n--------------------------------------------------\nin the fog, robert jordan thought. and then, without looking at last, so \ngood, he \n--------------------------------------------------\npot of yellow rice and fish and the boy loved him. \"no,\" the boy said.\n--------------------------------------------------\nthe line now. it's wonderful.\" \"he's crazy about the brave.\"\n--------------------------------------------------\ncandle to us. \"and if the maria kisses thee again i will commence kissing \nthee myself. it \n--------------------------------------------------\n?\" \"do you have to for the moment.\" robert jordan got up and walked away in\n--------------------------------------------------\n. a uniform for my father, he thought. i'll say them later. just then he\n--------------------------------------------------\nand more practical to read and relax in the evening; of all the things he \nhad enjoyed the next \n--------------------------------------------------\nin bed and rolled himself a cigarette. when he gave them a log to a second \ngrenade. \" \n--------------------------------------------------\n```", "```py\nprompt=\"UNK\"\nfor i in range(10):\n    torch.manual_seed(i)\n    print(generate(prompt,'files/GPTe40.pth',max_new_tokens=20)[4:]))\n```", "```py\nway.\" \"kümmel, and i will enjoy the killing. they must have brought me a spit\n--------------------------------------------------\n,\" robert jordan said. \"but do not tell me that he saw anything.\" \"not\n--------------------------------------------------\nin the first time he had bit the ear like that and held onto it, his neck \nand jaws\n--------------------------------------------------\npot of yellow rice with fish. it was cold now in the head and he could not \nsee the\n--------------------------------------------------\nthe line of his mouth. he thought.\" \"the laughing hurt him.\" \"i can\n--------------------------------------------------\ncandle made? that was the worst day of my life until one other day.\" \"don'\n--------------------------------------------------\n?\" \"do you have to for the moment.\" robert jordan took the glasses and \nopened the\n--------------------------------------------------\n. that's what they don't marry.\" i reached for her hand. \"don\n--------------------------------------------------\nand more grenades. that was the last for next year. it crossed the river \naway from the front\n--------------------------------------------------\nin a revolutionary army,\" robert jordan said. \"that's really nonsense. it's\n--------------------------------------------------\n```", "```py\nprompt=\"the old man saw the shark near the\"\nfor i in range(10):\n    torch.manual_seed(i)\n    print(generate(prompt,'files/GPTe40.pth',max_new_tokens=20))\n    print(\"-\"*50)   \n```", "```py\nthe old man saw the shark near the old man's head with his tail out and the old man hit him squarely in the center of\n--------------------------------------------------\nthe old man saw the shark near the boat with one hand. he had no feeling of\nthe morning but he started to pull on it gently\n--------------------------------------------------\nthe old man saw the shark near the old man's head. then he went back to \nanother man in and leaned over and dipped the\n--------------------------------------------------\nthe old man saw the shark near the fish now, and the old man was asleep in \nthe water as he rowed he was out of the\n--------------------------------------------------\nthe old man saw the shark near the boat. it was a nice-boat. he saw the old\n man's head and he started\n--------------------------------------------------\nthe old man saw the shark near the boat to see him clearly and he was \nafraid that he was higher out of the water and the old\n--------------------------------------------------\nthe old man saw the shark near the old man's head and then, with his tail \nlashing and his jaws clicking, the shark plowed\n--------------------------------------------------\nthe old man saw the shark near the line with his tail which was not sweet \nsmelling it. the old man knew that the fish was coming\n--------------------------------------------------\nthe old man saw the shark near the fish with his jaws hooked and the old \nman stabbed him in his left eye. the shark still hung\n--------------------------------------------------\nthe old man saw the shark near the fish and he started to shake his head \nagain. the old man was asleep in the stern and he\n--------------------------------------------------\n```", "```py\nprompt=\"the old man saw the shark near the\"\nfor i in range(10):\n    torch.manual_seed(i)\n    print(generate(prompt,'files/GPTe20.pth',max_new_tokens=20,\n                  temperature=0.9,top_k=50))\n    print(\"-\"*50) \n```", "```py\n The old man saw the shark near the boat. then he swung the great fish that \nwas more comfortable in the sun. the old man could\n--------------------------------------------------\nthe old man saw the shark near the boat with one hand. he wore his overcoat\n and carried the submachine gun muzzle down, carrying it in\n--------------------------------------------------\nthe old man saw the shark near the boat with its long dip sharply and the \nold man stabbed him in the morning. he could not see\n--------------------------------------------------\nthe old man saw the shark near the fish that was now heavy and long and \ngrave he had taken no part in. he was still under\n--------------------------------------------------\nthe old man saw the shark near the boat. it was a nice little light. then \nhe rowed out and the old man was asleep over\n--------------------------------------------------\nthe old man saw the shark near the boat to come. \"old man's shack and i'll \nfill the water with him in\n--------------------------------------------------\nthe old man saw the shark near the boat and then rose with his lines close \nhim over the stern. \"no,\" the old man\n--------------------------------------------------\nthe old man saw the shark near the line with his tail go under. he was \ncutting away onto the bow and his face was just a\n--------------------------------------------------\nthe old man saw the shark near the fish with his tail that he swung him in.\n the shark's head was out of water and\n--------------------------------------------------\nthe old man saw the shark near the boat and he started to cry. he could \nalmost have them come down and whipped him in again.\n--------------------------------------------------\n```"]