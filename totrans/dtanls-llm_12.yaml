- en: 10 Software frameworks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 个软件框架
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Building applications with LangChain
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 LangChain 构建应用
- en: Solving complex tasks with agents
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用代理解决复杂任务
- en: Querying data with LlamaIndex
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 LlamaIndex 查询数据
- en: Up to now, we’ve mostly been using OpenAI’s Python library to interact with
    language models. This library offers basic functionality for sending prompts and
    retrieving answers from GPT and other OpenAI models (as well as options for tuning
    and fine-tuning). The libraries from other providers, such as Anthropic and Cohere,
    offer similar functionality. As long as your data-analysis tasks are simple, this
    is probably all you need. However, what if your data analysis requires a complex
    multistep pipeline, possibly integrating many different data formats?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们主要使用 OpenAI 的 Python 库与语言模型进行交互。这个库提供了向 GPT 和其他 OpenAI 模型发送提示和检索答案的基本功能（以及调整和微调的选项）。来自其他提供商的库，如
    Anthropic 和 Cohere，提供类似的功能。只要你的数据分析任务简单，这可能就是你所需要的。然而，如果你的数据分析需要复杂的、多步骤的流水线，可能需要整合许多不同的数据格式呢？
- en: 'At that point, you may want to switch to a more powerful software framework.
    Several higher-level frameworks for building complex applications on top of language
    models are currently emerging. In this chapter, we’ll discuss two of the most
    popular contenders: LangChain and LlamaIndex. The former is a general framework
    for building applications using large language models. What’s more, it comes with
    various useful built-in components that implement popular use cases for language
    models. LlamaIndex, on the other hand, specifically supports use cases where language
    models need to interact with large data sets.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到那时，你可能想切换到一个更强大的软件框架。目前，有几个用于在语言模型之上构建复杂应用的更高层次框架正在兴起。在本章中，我们将讨论两个最受欢迎的竞争者：LangChain
    和 LlamaIndex。前者是一个用于构建使用大型语言模型的应用的通用框架。更重要的是，它附带各种有用的内置组件，实现了语言模型的流行用例。另一方面，LlamaIndex
    专门支持语言模型需要与大型数据集交互的用例。
- en: To get the hang of it, we’ll first write a simple text-classification pipeline
    using LangChain. Then we’ll explore some of the advanced features of LangChain.
    More precisely, we’ll see how LangChain supports *agents* on top of language models.
    Creating an agent means putting the language model itself into the driver’s seat,
    giving it lots of freedom on how to accomplish a given task while using a collection
    of tools provided by the user. We will use such agents to solve complex data-analysis
    tasks independently, using a mix of tools to access different data sources. Next,
    we’ll see how LlamaIndex easily ingests large amounts of data in diverse data
    formats and makes them usable for language models. Internally, it uses cheap language
    models to map data snippets and analysis tasks to vector representations, after
    which it maps tasks to data based on the similarity between those vectors. Finally,
    we’ll compare the two frameworks and discuss tradeoffs between those frameworks
    and the libraries offered by OpenAI and other language model providers.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了熟悉这个工具，我们首先将使用 LangChain 编写一个简单的文本分类流水线。然后我们将探索 LangChain 的一些高级功能。更确切地说，我们将看到
    LangChain 如何在语言模型之上支持 *代理*。创建一个代理意味着将语言模型本身置于驾驶员的位置，给它在完成特定任务时使用用户提供的工具集的自由。我们将使用这样的代理独立解决复杂的数据分析任务，使用各种工具访问不同的数据源。接下来，我们将看到
    LlamaIndex 如何轻松地摄取大量不同格式的数据，并使其对语言模型可用。内部，它使用廉价的语言模型将数据片段和分析任务映射到向量表示，然后根据这些向量的相似性将任务映射到数据。最后，我们将比较这两个框架，并讨论这些框架与
    OpenAI 和其他语言模型提供商提供的库之间的权衡。
- en: 10.1 LangChain
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 LangChain
- en: If you want to create a complex application based on language models, you should
    probably check out LangChain. The framework launched in October 2022 and has been
    gaining popularity quickly (leading to the creation of a corresponding startup
    in April 2023). At the time of writing, LangChain is still developing rapidly.
    Be sure to run the code in this section with the right LangChain version (because
    future versions may change the interfaces).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要创建一个基于语言模型的复杂应用，你可能应该检查一下 LangChain。该框架于 2022 年 10 月推出，并迅速获得了人气（导致 2023
    年 4 月创建了一个相应的初创公司）。在撰写本文时，LangChain 仍在快速发展。请确保使用正确的 LangChain 版本运行本节中的代码（因为未来的版本可能会更改接口）。
- en: As the name suggests, LangChain relates to language models (Lang) and chains.
    In LangChain terminology, a *chain* is simply a sequence of steps. Each step may
    correspond to the invocation of a language model, a data-processing step, or the
    invocation of an arbitrary tool. The important point here is that we no longer
    assume that a single call to a language model will solve our problem (which was
    the case for most of the scenarios we have discussed in this book). Instead, we
    assume that we need a complex network of connected components. That’s the scenario
    where LangChain shines!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，LangChain与语言模型（Lang）和链（Chain）相关。在LangChain术语中，一个*chain*只是一个步骤序列。每个步骤可能对应于调用一个语言模型、一个数据处理步骤或调用一个任意工具。这里的重要点是，我们不再假设单次调用语言模型就能解决我们的问题（这在本书中讨论的大多数场景中都是如此）。相反，我们假设我们需要一个复杂的连接组件网络。这正是LangChain大放异彩的场景！
- en: 'To use LangChain, you first need to install it. Go to a terminal, and run the
    following command:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用LangChain，你首先需要安装它。打开终端，并运行以下命令：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As we mentioned, you need to install the right LangChain version if you want
    to run the following code samples! LangChain is currently changing so quickly
    that the code may not work with a different version.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们提到的，如果你想运行以下代码示例，你需要安装正确的LangChain版本！LangChain目前正在快速变化，所以代码可能无法与不同版本兼容。
- en: 'Beyond the LangChain core, you may want to install libraries that support language
    models from specific providers. In the following sections, we’ll be using OpenAI’s
    models. Run the following command in the terminal (and, again, make sure to use
    the version specified):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 除了LangChain的核心功能之外，你可能还需要安装支持特定提供商语言模型的库。在接下来的章节中，我们将使用OpenAI的模型。请在终端中运行以下命令（并且，再次提醒，请确保使用指定的版本）：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Support for other providers, such as Anthropic and Cohere, is equally available.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对其他提供商的支持，如Anthropic和Cohere，同样可用。
- en: Okay, that’s it! After running these commands, you’re ready to run the sample
    projects discussed next.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这就完成了！运行这些命令后，你就可以运行下一节中讨论的示例项目了。
- en: 10.2 Classifying reviews with LangChain
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 使用LangChain对评论进行分类
- en: One of the first projects we did was text analysis with language models. Remember
    chapter 4? We used language models to classify reviews based on the underlying
    sentiment (is this a recommendation or a warning?). We’ll do the same here; we
    will just use LangChain in our code. Comparing the LangChain code with the original
    should give you a first impression of how LangChain can help simplify building
    applications with language models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最早的项目之一是使用语言模型进行文本分析。还记得第4章吗？我们使用语言模型根据潜在的情感（这是推荐还是警告？）对评论进行分类。在这里，我们也将做同样的事情；我们只是会在代码中使用LangChain。将LangChain的代码与原始代码进行比较，应该能给你一个LangChain如何帮助简化使用语言模型构建应用程序的第一印象。
- en: 10.2.1 Overview
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.1 概述
- en: We will create a chain to classify text documents. A LangChain chain may involve
    many steps, each implemented by invoking a language model or a generic Python
    function (e.g., to parse the results of language model invocations into a standardized
    format). The term *chain* is actually slightly misleading. Although you may imagine
    a chain as a sequence of consecutive steps, the chains in LangChain are much more
    powerful. For instance, they may involve parallel steps as well as conditional
    execution. However, for the simple text-classification application, we won’t need
    such advanced features. Instead, we will restrict ourselves to a simple chain
    with just a few steps.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个用于分类文本文档的链。一个LangChain链可能涉及许多步骤，每个步骤通过调用一个语言模型或一个通用的Python函数（例如，将语言模型调用的结果解析成标准格式）来实现。术语*chain*实际上有些误导。虽然你可能想象链是一个连续步骤的序列，但LangChain中的链要强大得多。例如，它们可能涉及并行步骤以及条件执行。然而，对于简单的文本分类应用，我们不需要这样的高级功能。相反，我们将限制自己使用只有几个步骤的简单链。
- en: 'Our chain will integrate several standard components offered by LangChain.
    The first component in our chain is a prompt template. As in chapter 4, this template
    describes the classification task and the expected output format. You may wonder
    what has changed compared to the previous code version. After all, we have been
    discussing prompt templates all along. The difference is that LangChain introduces
    a dedicated class to represent prompt templates. This class offers various convenience
    functions for prompt templates: for example, for creating and instantiating them.
    At the same time, LangChain offers a hub allowing users to upload and download
    prompt templates (as well as many other components). In our simple scenario, we
    won’t need any of these advanced features. Instead, we just need to instantiate
    our prompt template by passing a single parameter (the text to classify) as input.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的链将集成LangChain提供的几个标准组件。我们链中的第一个组件是一个提示模板。正如第4章中所述，这个模板描述了分类任务和预期的输出格式。你可能想知道与之前的代码版本相比有什么变化。毕竟，我们一直在讨论提示模板。区别在于LangChain引入了一个专门用于表示提示模板的类。这个类为提示模板提供了各种便利函数：例如，用于创建和实例化它们。同时，LangChain提供了一个中心，允许用户上传和下载提示模板（以及许多其他组件）。在我们的简单场景中，我们不需要这些高级功能。相反，我们只需要通过传递一个参数（要分类的文本）来实例化我们的提示模板。
- en: The second step in our chain is a language model. Again, we have been using
    language models throughout this book, but LangChain adds several helpful functions
    on top of the language model object. For instance, it is easy to automatically
    log all language model invocations, and LangChain offers convenience functions
    for different invocation scenarios (e.g., batch and stream processing). Again,
    we won’t use those advanced features here. Instead, we will pass the prompt (the
    first step in our chain) to the language model to generate a reply.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们链中的第二步是一个语言模型。同样，我们在这本书的整个过程中一直在使用语言模型，但LangChain在语言模型对象之上增加了几个有用的功能。例如，自动记录所有语言模型调用变得很容易，LangChain还提供了针对不同调用场景的便利函数（例如，批处理和流处理）。再次强调，我们在这里不会使用这些高级功能。相反，我们将提示（我们链中的第一步）传递给语言模型以生成回复。
- en: The third step in our chain is a parser, extracting the answer string from the
    reply generated by the language model. You may remember from chapter 3 that OpenAI’s
    language models generate detailed replies, integrating one or multiple answers
    as well as various types of metadata (e.g., information about token usage). The
    parser automatically extracts the answer string we’re looking for from the result
    object (which works for OpenAI models as well as for all other providers). The
    result of the pipeline is a single token indicating whether the input review is
    a recommendation. Figure [10.1](#fig__LCclassification) illustrates the three
    steps of this pipeline.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们链中的第三步是一个解析器，它从语言模型生成的回复中提取答案字符串。你可能还记得第3章中提到的，OpenAI的语言模型会生成详细的回复，其中包含一个或多个答案以及各种类型的元数据（例如，关于标记使用的相关信息）。解析器会自动从结果对象中提取我们所需的答案字符串（这对于OpenAI模型以及所有其他提供商都适用）。管道的结果是一个表示输入评论是否为推荐的单一标记。图[10.1](#fig__LCclassification)展示了这个管道的三个步骤。
- en: '![figure](../Images/CH10_F01_Trummer.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F01_Trummer.png)'
- en: Figure 10.1 Components in our LangChain classification chain
  id: totrans-26
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.1 LangChain分类链中的组件
- en: 10.2.2 Creating a classification chain
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.2 创建分类链
- en: 'Time to implement our chain in Python! First we need a prompt template. We
    use the same template as in chapter 4, but this time, we use LangChain’s `ChatPromptTemplate`
    class:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候用Python实现我们的链了！首先我们需要一个提示模板。我们使用与第4章相同的模板，但这次我们使用LangChain的`ChatPromptTemplate`类：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#1 Text placeholder'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 文本占位符'
- en: You may notice the reference to chat models (after all, the class we’re instantiating
    is called `ChatPromptTemplate`). As discussed in chapter 3, chat models process
    a history of prior messages rather than a single input message. Many of the most
    recently released models are chat models. In LangChain, chat models require a
    specialized prompt template (which instantiates into a sequence of messages rather
    than a single text). This is the type of template we’re creating here. The template
    is the same as we used in chapter 4\. It contains a placeholder (**1**) for the
    input text to classify. We generally use curly braces (`{}`) to mark placeholders
    in prompt templates; they are replaced with concrete values when instantiating
    the prompt.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到对聊天模型的引用（毕竟，我们实例化的类叫做 `ChatPromptTemplate`）。在第 3 章中讨论过，聊天模型处理的是一系列先前的消息历史，而不是单个输入消息。许多最近发布的模型都是聊天模型。在
    LangChain 中，聊天模型需要一个专门的提示模板（它实例化为一系列消息而不是单个文本）。这正是我们在这里创建的模板类型。该模板与第 4 章中使用的模板相同，它包含一个用于对输入文本进行分类的占位符（**1**）。我们通常使用花括号（`{}`）在提示模板中标记占位符；在实例化提示时，它们会被具体的值替换。
- en: 'Second, we need a language model to process prompts. The following code instantiates
    the GPT-4o model from OpenAI:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，我们需要一个语言模型来处理提示。以下代码实例化了 OpenAI 的 GPT-4o 模型：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `ChatOpenAI` class covers all chat models by OpenAI. It is imported from
    the `langchain_openai` package, featuring functionality to support the use of
    OpenAI models in LangChain. Other providers, such as Anthropic and Cohere, have
    their own associated packages offering comparable functionality for their models
    (note that you need to install those packages separately via pip). The parameters
    in the constructor of `ChatOpenAI` may seem familiar: we choose the model (`gpt-4o`),
    set `temperature` to 0 (to reduce the degree of randomness in the output), and
    limit the maximum number of output tokens to one (because both possible class
    labels, `Positive` and `Negative`, consist of a single token).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`ChatOpenAI` 类涵盖了 OpenAI 的所有聊天模型。它从 `langchain_openai` 包中导入，具有在 LangChain 中使用
    OpenAI 模型的功能。其他提供商，如 Anthropic 和 Cohere，也有它们自己的相关包，为它们的模型提供类似的功能（注意，你需要通过 pip
    分别安装这些包）。`ChatOpenAI` 构造函数中的参数可能看起来很熟悉：我们选择模型（`gpt-4o`），将 `temperature` 设置为 0（以减少输出中的随机程度），并将最大输出令牌数限制为
    1（因为可能的两个类别标签，`Positive` 和 `Negative`，都由单个令牌组成）。'
- en: 'Third, we need to extract the answer string from the (more detailed) reply
    of our language model. That’s easy to do with `StrOutputParser`. LangChain output
    parsers implement a wide range of transformations on the output of a model invocation.
    In this case, we only need a very simple transformation, extracting the desired
    answer string. The following piece of code creates a corresponding parser:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，我们需要从语言模型的（更详细的）回复中提取答案字符串。使用 `StrOutputParser` 来做这件事很简单。LangChain 输出解析器实现了一系列对模型调用输出的转换。在这种情况下，我们只需要一个非常简单的转换，提取所需的答案字符串。以下代码创建了一个相应的解析器：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, we’ll put all the components together in a chain. To do so, we can
    use the LangChain Expression Language (LCEL). If you’re a Linux user, the following
    syntax should look familiar to you:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将所有组件串联在一起。为此，我们可以使用 LangChain 表达式语言（LCEL）。如果你是 Linux 用户，以下语法应该对你来说很熟悉：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: To use the output of an operation as input for the following step, we connect
    them with the pipe symbol (`|). The command creates a chain that connects the
    previously mentioned components. In addition, it specifies the input that the
    chain expects. In our case, the prompt template has a placeholder for the text
    to classify.`
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要将操作的输出用作后续步骤的输入，我们使用管道符号（`|）将它们连接起来。该命令创建了一个连接先前提到的组件的链。此外，它还指定了链期望的输入。在我们的例子中，提示模板有一个用于对文本进行分类的占位符。
- en: '[PRE6] inputs = [''This movie is great!'', ''This movie is bad!''] outputs
    = chain.batch(inputs) [PRE7] from langchain_openai import ChatOpenAI from langchain_core.prompts.chat
    import ChatPromptTemplate from langchain_core.output_parsers.string import StrOutputParser
    from langchain_core.runnables.passthrough import RunnablePassthrough  import argparse
    import pandas as pd  def create_chain():                         #1     """ Creates
    chain for text classification.          Returns:         a chain for text classification.     """     prompt
    = ChatPromptTemplate.from_template(  #2         ''{text}\n''         ''Is the
    sentiment positive or negative?\n''         ''Answer ("Positive"/"Negative")\n'')     llm
    = ChatOpenAI(              #3         model=''gpt-4o'', temperature=0,          max_tokens=1)     parser
    = StrOutputParser()  #4      #5     chain = ({''text'':RunnablePassthrough()}
    | prompt | llm | parser)     return chain  if __name__ == ''__main__'':          parser
    = argparse.ArgumentParser()     parser.add_argument(''file_path'', type=str, help=''Path
    to input file'')     args = parser.parse_args()          df = pd.read_csv(args.file_path)  #6      chain
    = create_chain()            #7     results = chain.batch(list(df[''text'']))  #8      df[''class'']
    = results  #9     df.to_csv(''result.csv'') [PRE8] python listing1.py reviews.csv
    [PRE9] pip install langchainhub==0.1.15 [PRE10] from langchain import hub prompt
    = hub.pull(''hwchase17/react'') print(prompt.template) [PRE11]  #1 Answer the
    following questions as best you can.  You have access to the following tools:  {tools}  #2  Use
    the following format:  #3  Question: the input question you must answer Thought:
    you should always think about what to do Action: the action to take, should be
    one of [{tool_names}] Action Input: the input to the action Observation: the result
    of the action ... (this Thought/Action/Action Input/Observation can repeat N times)
    Thought: I now know the final answer Final Answer: the final answer to the original
    input question  Begin!  Question: {input}      #4 Thought:{agent_scratchpad}  #5
    [PRE12] from langchain_openai import ChatOpenAI llm = ChatOpenAI(     temperature=0,
    model=''gpt-4o'') [PRE13] from langchain_community.utilities.sql_database import
    SQLDatabase db = SQLDatabase.from_uri(f''sqlite:///{dbpath}'') [PRE14] pip install
    google-search-results==2.4.2 [PRE15] from langchain.agents.load_tools import load_tools
    extra_tools = load_tools(     [''serpapi''], serpapi_api_key=serpaikey, llm=llm)
    [PRE16] from langchain_community.agent_toolkits.sql.base import create_sql_agent
    agent = create_sql_agent(     llm=llm, db=db, verbose=True,     agent_type=''openai-tools'',     extra_tools=extra_tools)
    [PRE17] agent.invoke({''input'':task}) [PRE18] import argparse  from langchain.agents.load_tools
    import load_tools from langchain_community.utilities.sql_database import SQLDatabase
    from langchain_community.agent_toolkits.sql.base import create_sql_agent from
    langchain_openai import ChatOpenAI  if __name__ == ''__main__'':      parser =
    argparse.ArgumentParser()     parser.add_argument(''serpaikey'', type=str, help=''SERP
    API access key'')     parser.add_argument(''dbpath'', type=str, help=''Path to
    SQLite database'')     parser.add_argument(''question'', type=str, help=''A question
    to answer'')     args = parser.parse_args()          llm = ChatOpenAI(              #1         temperature=0,
    model=''gpt-4o'')      #2     db = SQLDatabase.from_uri(f''sqlite:///{args.dbpath}'')     extra_tools
    = load_tools(                         #3         [''serpapi''], serpapi_api_key=args.serpaikey,
    llm=llm)     agent = create_sql_agent(     #4         llm=llm, db=db, verbose=True,         agent_type=''openai-tools'',         extra_tools=extra_tools)     agent.invoke({''input'':args.question})  #5
    [PRE19] python listing2.py [SerpAPI key] games.db ↪ ''What was the most sold game
    in 2016, and how is it played?'' [PRE20] [1m> Entering new SQL Agent Executor
    chain...[0m [32;1m[1;3m   #1 Invoking: `sql_db_list_tables` with `{''tool_input'':
    "}` [0m[38;5;200m[1;3mgames[0m[32;1m[1;3m  #2 Invoking: `sql_db_schema` with `{''table_names'':
    ''games''}`  [0m[33;1m[1;3m CREATE TABLE games (     rank INTEGER,      name TEXT,      platform
    TEXT,      year INTEGER,      genre TEXT,      publisher TEXT,      americasales
    NUMERIC,      eusales NUMERIC,      japansales NUMERIC,      othersales NUMERIC,      globalsales
    NUMERIC )  /* 3 rows from the games table: rank    name    platform    year    genre    publisher     americasales    eusales    japansales    othersales    globalsales
    1    Wii Sports    Wii    2006    Sports    Nintendo    41.4900000000     29.0200000000    3.7700000000    8.4600000000    82.7400000000
    2    Super Mario Bros.   NES   1985   Platform   Nintendo   29.0800000000     3.5800000000    6.8100000000    0.7700000000    40.2400000000
    3    Mario Kart Wii    Wii    2008    Racing    Nintendo    15.8500000000     12.8800000000    3.7900000000    3.3100000000    35.8200000000
    */[0m[32;1m[1;3m  #3 Invoking: `sql_db_query_checker` with `{''query'': ''SELECT
    name  FROM games WHERE year = 2016 ORDER BY globalsales DESC LIMIT 1''}` responded:
    The games table contains the information we need.  I will query for the game with
    the highest global sales in 2016. [0m[36;1m[1;3mSELECT name FROM games WHERE year
    = 2016  ORDER BY globalsales DESC LIMIT 1[0m[32;1m[1;3m  #4 Invoking: `sql_db_query`
    with `{''query'': ''SELECT name  FROM games WHERE year = 2016 ORDER BY globalsales
    DESC LIMIT 1''}` [0m[36;1m[1;3m[(''FIFA 17'',)][0m[32;1m[1;3m  #5 Invoking: `Search`
    with `How to play FIFA 17` [0m[33;1m[1;3m["A Beginner''s Guide To Complete FIFA
    17 Domination ... The  main steps you should take are to jump right in with a
    quick play game. ... EA Sports FIFA ...", ''Play FIFA 17 up to 5 days before launch
    for a full  10 hours when you join EA Access on Xbox One and Origin Access on
    PC.'',  "1\. Shield the ball in 360 degrees · 2\. Use Driven Shots and Driven
    Headers ·  3\. Use set piece upgrades to score with style · 4\. Make Fifa 17''s
    ...",  ''Play FIFA 17 as much as you want with EA Access or Origin Access  for
    only $4.99 per month. Now available in The Vault.'',  ''Cautiously Start An Online
    Match. Score Early After Some Self-Proclaimed  Beautiful Build Up Play. Concede
    4 Goals In A Row And Convince ...'',  ''FIFA 17 TUTORIALS & ULTIMATE TEAM ➞  Twitter:
    https://twitter.com/KrasiFIFA ➞  Instagram: http://instagram.com/KrasiFIFA How
    I record my ...'',  "Draft mode is another way to play FIFA Ultimate Team,  giving
    you the ability to play with Players you don''t own.  You''ll have the opportunity
    to draft a random ..."]  #6 [0m[32;1m[1;3mThe most sold game in 2016 was FIFA
    17\.   To play FIFA 17, you can follow these steps:  1\. Jump right in with a
    quick play game. 2\. Shield the ball in 360 degrees. 3\. Use Driven Shots and
    Driven Headers. 4\. Use set piece upgrades to score with style. 5\. Start an online
    match cautiously. 6\. Score early after some self-proclaimed beautiful build-up
    play. 7\. Draft mode is another way to play FIFA Ultimate Team,  giving you the
    ability to play with players you don''t own.  You''ll have the opportunity to
    draft a random team.  Remember, practice makes perfect![0m  [1m> Finished chain.[0m
    [PRE21] SELECT name FROM games WHERE year = 2016 ORDER BY globalsales DESC LIMIT
    1 [PRE22] import argparse  from langchain.agents.load_tools import load_tools
    from langchain.tools import tool from langchain_community.utilities.sql_database
    import SQLDatabase from langchain_community.agent_toolkits.sql.base import create_sql_agent
    from langchain_openai import ChatOpenAI from typing import Union  @tool  #1  #2
    def convert_currency(USD_amount: float, currency: str)->Union[float, str]:      #3     """
    Converts an amount in US dollars to another currency.          Args:         USD_amount:
    amount in US dollars.         currency: name of target currency (e.g., "Yen").          Returns:         input
    amount in target currency.     """     conversion_factors = {         ''Euro'':0.93,
    ''Yen'':151.28, ''Yun'':0.14,          ''Pound'':1.26, ''Won'':0.00074, ''Rupee'':0.012}          if
    currency not in conversion_factors:          #4         error_message = (             f''Unknown
    currency: {currency}!''             f''Use one of {conversion_factors.keys()}'')         return
    error_message       #5     conversion_factor = conversion_factors[currency]     converted_amount
    = USD_amount * conversion_factor     return converted_amount  if __name__ == ''__main__'':      parser
    = argparse.ArgumentParser()     parser.add_argument(''serpaikey'', type=str, help=''SERP
    API access key'')     parser.add_argument(''dbpath'', type=str, help=''Path to
    SQLite database'')     parser.add_argument(''question'', type=str, help=''A question
    to answer'')     args = parser.parse_args()          llm = ChatOpenAI(         temperature=0,
    model=''gpt-4o'')     db = SQLDatabase.from_uri(f''sqlite:///{args.dbpath}'')     extra_tools
    = load_tools(         [''serpapi''], serpapi_api_key=args.serpaikey, llm=llm)      #6     extra_tools.append(convert_currency)      agent
    = create_sql_agent(         llm=llm, db=db, verbose=True,         agent_type=''openai-tools'',         extra_tools=extra_tools)     agent.invoke({''input'':args.question})
    [PRE23] python listing3.py [SerpAPI key] games.db  ''What revenue was generated
    by computer games in 2015?  How much is it in Yen?'' [PRE24] [1m> Entering new
    SQL Agent Executor chain...[0m [32;1m[1;3m  #1 Invoking: `sql_db_list_tables`
    with `''tool_input'': "` [0m[38;5;200m[1;3mgames[0m[32;1m[1;3m  #2 Invoking: `sql_db_schema`
    with `''table_names'': ''games''` [0m[33;1m[1;3m CREATE TABLE games (     rank
    INTEGER,      name TEXT,      platform TEXT,      year INTEGER,      genre TEXT,      publisher
    TEXT,      americasales NUMERIC,      eusales NUMERIC,      japansales NUMERIC,      othersales
    NUMERIC,      globalsales NUMERIC )  /* 3 rows from the games table: rank    name    platform    year    genre    publisher    americasales
    eusales    japansales    othersales    globalsales 1    Wii Sports    Wii    2006    Sports    Nintendo    41.4900000000     29.0200000000    3.7700000000    8.4600000000    82.7400000000
    2    Super Mario Bros.   NES   1985   Platform   Nintendo   29.0800000000     3.5800000000    6.8100000000    0.7700000000    40.2400000000
    3    Mario Kart Wii    Wii    2008    Racing    Nintendo    15.8500000000     12.8800000000    3.7900000000    3.3100000000    35.8200000000
    */[0m[32;1m[1;3m  #3 Invoking: `sql_db_query_checker` with `{''query'': ''SELECT
    SUM(globalsales) as  total_revenue FROM games WHERE year = 2015''}` responded:
    The "games" table contains the information we need.  The "globalsales" column
    represents the global revenue generated by  each game. We can sum this column
    for the games released in 2015 to  get the total revenue. Let''s write and check
    the SQL query.  [0m[36;1m[1;3mSELECT SUM(globalsales) as total_revenue  FROM games
    WHERE year = 2015[0m[32;1m[1;3m  #4 Invoking: `sql_db_query` with `{''query'':
    ''SELECT SUM(globalsales) as  total_revenue FROM games WHERE year = 2015''}`  [0m[36;1m[1;3m[(264.43999999999795,)][0m[32;1m[1;3m  #5
    Invoking: `convert_currency` with `{''USD_amount'':  264.43999999999795, ''currency'':
    ''Yen''}`  [0m[38;5;200m[1;3m40004.48319999969[0m[32;1m[1;3m  #6 The total revenue
    generated by computer games in 2015  was approximately $264.44 million.  In Japanese
    Yen, this is approximately ¥40,004,483,200.[0m  [1m> Finished chain.[0m [PRE25]
    pip install llama-index==0.10.25 [PRE26] pip install torch==2.1.2 pip install
    transformers==4.36.0 pip install python-pptx==0.6.23 pip install Pillow==10.2.0
    [PRE27] import argparse import openai  from llama_index.core import VectorStoreIndex,
    SimpleDirectoryReader  if __name__ == ''__main__'':      #1     parser = argparse.ArgumentParser()     parser.add_argument(''datadir'',
    type=str, help=''Path to data directory'')     parser.add_argument(''question'',
    type=str, help=''A question to answer'')     args = parser.parse_args()      #2     documents
    = SimpleDirectoryReader(args.datadir).load_data()      #3     index = VectorStoreIndex.from_documents(documents)      #4     engine
    = index.as_query_engine()      #5     answer = engine.query(args.question)     print(answer)
    [PRE28] python listing4.py bananareports ''How much did the Plantain unit make
    ↪ in 2023?'' [PRE29] The Plantain unit made 30 million USD in 2023. [PRE30]`'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE6] 输入 = [''这部电影太棒了！'', ''这部电影太糟糕了！''] 输出 = chain.batch(inputs) [PRE7] 从
    langchain_openai 导入 ChatOpenAI 从 langchain_core.prompts.chat 导入 ChatPromptTemplate
    从 langchain_core.output_parsers.string 导入 StrOutputParser 从 langchain_core.runnables.passthrough
    导入 RunnablePassthrough 导入 argparse 导入 pandas as pd  def create_chain():                         #1     """
    创建用于文本分类的链。          返回值:         用于文本分类的链。     """     prompt = ChatPromptTemplate.from_template(  #2         ''{text}\n''         ''情感是积极还是消极？\n''         ''回答
    ("Positive"/"Negative")\n'')     llm = ChatOpenAI(              #3         model=''gpt-4o'',
    temperature=0,          max_tokens=1)     parser = StrOutputParser()  #4      #5     chain
    = ({''text'':RunnablePassthrough()} | prompt | llm | parser)     return chain  if
    __name__ == ''__main__'':          parser = argparse.ArgumentParser()     parser.add_argument(''file_path'',
    type=str, help=''输入文件路径'')     args = parser.parse_args()          df = pd.read_csv(args.file_path)  #6      chain
    = create_chain()            #7     results = chain.batch(list(df[''text'']))  #8      df[''class'']
    = results  #9     df.to_csv(''result.csv'') [PRE8] python listing1.py reviews.csv
    [PRE9] pip install langchainhub==0.1.15 [PRE10] 从 langchain 导入 hub prompt = hub.pull(''hwchase17/react'')
    print(prompt.template) [PRE11]  #1 尽可能回答以下问题。您可以使用以下工具：  {tools}  #2  使用以下格式：  #3  问题：您必须回答的输入问题
    Thought：您应该始终思考要做什么 Action：要采取的操作，应该是 [{tool_names}] 之一 Action Input：操作的输入 Observation：操作的结果
    ... (此 Thought/Action/Action Input/Observation 可以重复 N 次) Thought：我现在知道最终答案 Final
    Answer：原始输入问题的最终答案  开始！  问题：{input}      #4 Thought:{agent_scratchpad}  #5 [PRE12]
    从 langchain_openai 导入 ChatOpenAI llm = ChatOpenAI(     temperature=0, model=''gpt-4o'')
    [PRE13] 从 langchain_community.utilities.sql_database 导入 SQLDatabase db = SQLDatabase.from_uri(f''sqlite:///{dbpath}'')
    [PRE14] pip install google-search-results==2.4.2 [PRE15] 从 langchain.agents.load_tools
    导入 load_tools extra_tools = load_tools(     [''serpapi''], serpapi_api_key=serpaikey,
    llm=llm) [PRE16] 从 langchain_community.agent_toolkits.sql.base 导入 create_sql_agent
    agent = create_sql_agent(     llm=llm, db=db, verbose=True,     agent_type=''openai-tools'',     extra_tools=extra_tools)
    [PRE17] agent.invoke({''input'':task}) [PRE18] 导入 argparse  from langchain.agents.load_tools
    导入 load_tools  from langchain_community.utilities.sql_database 导入 SQLDatabase  from
    langchain_community.agent_toolkits.sql.base 导入 create_sql_agent  from langchain_openai
    导入 ChatOpenAI  if __name__ == ''__main__'':      parser = argparse.ArgumentParser()     parser.add_argument(''serpaikey'',
    type=str, help=''SERP API访问密钥'')     parser.add_argument(''dbpath'', type=str,
    help=''SQLite数据库路径'')     parser.add_argument(''question'', type=str, help=''要回答的问题'')     args
    = parser.parse_args()          llm = ChatOpenAI(              #1         temperature=0,
    model=''gpt-4o'')      #2     db = SQLDatabase.from_uri(f''sqlite:///{args.dbpath}'')     extra_tools
    = load_tools(                         #3         [''serpapi''], serpapi_api_key=args.serpaikey,
    llm=llm)     agent = create_sql_agent(     #4         llm=llm, db=db, verbose=True,         agent_type=''openai-tools'',         extra_tools=extra_tools)     agent.invoke({''input'':args.question})  #5
    [PRE19] python listing2.py [SerpAPI密钥] games.db ↪ ''2016年最畅销的游戏是什么，如何玩？'' [PRE20]
    [1m> 正在进入新的SQL代理执行器链...[0m [32;1m[1;3m   #1 调用：`sql_db_list_tables` with `{''tool_input'':
    "}` [0m[38;5;200m[1;3mgames[0m[32;1m[1;3m  #2 调用：`sql_db_schema` with `{''table_names'':
    ''games''}`  [0m[33;1m[1;3m CREATE TABLE games (     rank INTEGER,      name TEXT,      platform
    TEXT,      year INTEGER,      genre TEXT,      publisher TEXT,      americasales
    NUMERIC,      eusales NUMERIC,      japansales NUMERIC,      othersales NUMERIC,      globalsales
    NUMERIC )  /* 3 rows from the games table: rank    name    platform    year    genre    publisher     americasales    eusales    japansales    othersales    globalsales
    1    Wii Sports    Wii    2006    Sports    Nintendo    41.4900000000     29.0200000000    3.7700000000    8.4600000000    82.7400000000
    2    Super Mario Bros.   NES   1985   Platform   Nintendo    29.0800000000     3.5800000000    6.8100000000    0.7700000000    40.2400000000
    3    Mario Kart Wii    Wii    2008    Racing    Nintendo    15.8500000000     12.8800000000    3.7900000000    3.3100000000    35.8200000000
    */[0m[32;1m[1;3m  #3 调用：`sql_db_query_checker` with `{''query'': ''SELECT name  FROM
    games WHERE year = 2016 ORDER BY globalsales DESC LIMIT 1''}` responded: The games
    table contains the information we need.  I will query for the game with the highest
    global sales in 2016. [0m[36;1m[1;3mSELECT name FROM games WHERE year = 2016  ORDER
    BY globalsales DESC LIMIT 1[0m[32;1m[1;3m  #4 调用：`sql_db_query` with `{''query'':
    ''SELECT name  FROM games WHERE year = 2016 ORDER BY globalsales DESC LIMIT 1''}`
    [0m[36;1m[1;3m[(''FIFA 17'',)][0m[32;1m[1;3m  #5 调用：`Search` with `How to play
    FIFA 17` [0m[33;1m[1;3m["A Beginner''s Guide To Complete FIFA 17 Domination ...
    The main steps you should take are to jump right in with a quick play game. ...
    EA Sports FIFA ...", ''Play FIFA 17 up to 5 days before launch for a full  10
    hours when you join EA Access on Xbox One and Origin Access on PC.'',  "1\. Shield
    the ball in 360 degrees · 2\. Use Driven Shots and Driven Headers ·  3\. Use set
    piece upgrades to score with style · 4\. Make Fifa 17''s ...",  ''Play FIFA 17
    as much as you want with EA Access or Origin Access  for only $4.99 per month.
    Now available in The Vault.'',  ''Cautiously Start An Online Match. Score Early
    After Some Self-Proclaimed  Beautiful Build Up Play. Concede 4 Goals In A Row
    And Convince ...'',  ''FIFA 17 TUTORIALS & ULTIMATE TEAM ➞  Twitter: https://twitter.com/KrasiFIFA
    ➞  Instagram: http://instagram.com/KrasiFIFA How I record my ...'',  "Draft mode
    is another way to play FIFA Ultimate Team,  giving you the ability to play with
    Players you don''t own.  You''ll have the opportunity to draft a random ..."]  #6
    [0m[32;1m[1;3m2016年最畅销的游戏是FIFA 17。   要玩FIFA 17，您可以遵循以下步骤：  1\. 快速开始游戏。 2\. 用360度保护球。
    3\. 使用驱动射门和驱动角球。 4\. 使用定位球升级以优雅地得分。 5\. 谨慎地开始在线比赛。 6\. 在一些自称为美丽的 buildup play之后尽早得分。
    7\. 拟定模式是另一种玩FIFA Ultimate Team的方式，让您能够与您不拥有的球员一起玩。  您将有机会挑选一支随机队伍。  记住，熟能生巧！[0m  [1m>
    完成链。[0m [PRE21] SELECT name FROM games WHERE year = 2016 ORDER BY globalsales
    DESC LIMIT 1 [PRE22] 导入 argparse  from langchain.agents.load_tools 导入 load_tools  from
    langchain.tools 导入 tool  from langchain_community.utilities.sql_database 导入 SQLDatabase  from
    langchain_community.agent_toolkits.sql.base 导入 create_sql_agent  from langchain_openai
    导入 ChatOpenAI  from typing import Union  @tool  #1  #2 def convert_currency(USD_amount:
    float, currency: str)->Union[float, str]:      #3     """ 将美元金额转换为另一种货币。          参数:         USD_amount：美元金额。         currency：目标货币名称（例如，“日元”）。          返回值:         目标货币中的输入金额。     """     conversion_factors
    = {         ''Euro'':0.93, ''Yen'':151.28, ''Yun'':0.14,          ''Pound'':1.26,
    ''Won'':0.00074, ''Rupee'':0.012}          if currency not in conversion_factors:          #4         error_message
    = (             f''Unknown currency: {currency}!''             f''Use one of {conversion_factors.keys()}'')         return
    error_message       #5     conversion_factor = conversion_factors[currency]     converted_amount
    = USD_amount * conversion_factor     return converted_amount  if __name__ == ''__main__'':      parser
    = argparse.ArgumentParser()     parser.add_argument(''serpaikey'', type=str, help=''SERP
    API访问密钥'')     parser.add_argument(''dbpath'', type=str, help=''SQLite数据库路径'')     parser.add_argument(''question'',
    type=str, help=''要回答的问题'')     args = parser.parse_args()          llm = ChatOpenAI(         temperature=0,
    model=''gpt-4o'')     db = SQLDatabase.from_uri(f''sqlite:///{args.dbpath}'')     extra_tools
    = load_tools(         [''serpapi''], serpapi_api_key=args.serpaikey, llm=llm)      #6     extra_tools.append(convert_currency)      agent
    = create_sql_agent(         llm=llm, db=db, verbose=True,         agent_type=''openai-tools'',         extra_tools=extra_tools)     agent.invoke({''input'':args.question})
    [PRE23] python listing3.py [SerpAPI密钥] games.db  ''2015年电脑游戏产生了多少收入？  用日元表示是多少？''
    [PRE24] [1m> 正在进入新的SQL代理执行器链...[0m [32;1m[1;3m  #1 调用：`sql_db_list_tables` with
    `''tool_input'': "` [0m[38;5;200m[1;3mgames[0m[32;1m[1;3m  #2 调用：`sql_db_schema`
    with `''table_names'': ''games''` [0m[33;1m[1;3m CREATE TABLE games (     rank
    INTEGER,      name TEXT,      platform TEXT,      year INTEGER,      genre TEXT,      publisher
    TEXT,      americasales NUMERIC,      eusales NUMERIC,      japansales NUMERIC,      othersales
    NUMERIC,      globalsales NUMERIC )  /* 3 rows from the games table: rank    name    platform    year    genre    publisher    americasales
    eusales    japansales    othersales    globalsales 1    Wii Sports    Wii    2006    Sports    Nintendo    41.4900000000     29.0200000000    3.7700000000    8.4600000000    82.7400000000
    2    Super Mario Bros.   NES   1985   Platform   Nintendo    29.0800000000     3.5800000000    6.8100000000    0.7700000000    40.2400000000
    3    Mario Kart Wii    Wii    2008    Racing    Nintendo    15.8500000000     12.8800000000    3.7900000000    3.3100000000    35.8200000000
    */[0m[32;1m[1;3m  #3 调用：`sql_db_query_checker` with `{''query'': ''SELECT SUM(globalsales)
    as  total_revenue FROM games WHERE year = 2015''}` responded: The "games" table
    contains the information we need.  The "globalsales" column represents the global
    revenue generated by  each game. We can sum this column for the games released
    in 2015 to  get the total revenue. Let''s write and check the SQL query.  [0m[36;1m[1;3mSELECT
    SUM(globalsales) as total_revenue  FROM games WHERE year = 2015[0m[32;1m[1;3m  #4
    调用：`sql_db_query` with `{''query'': ''SELECT SUM(globalsales) as  total_revenue
    FROM games WHERE year = 2015''}`  [0m[36;1m[1;3m[(264.43999999999795,)][0m[32;1m[1;3m  #5
    调用：`convert_currency` with `{''USD_amount'':  264.43999999999795, ''currency'':
    ''Yen''}` [0m[38;5;200m[1;3m40004.48319999969[0m[32;1m[1;3m  #6 2015年电脑游戏产生的总收入约为264440000美元。  用日元表示，这大约是40,004,483,200日元。[0m  [1m>
    完成链。[0m [PRE25] pip install llama-index==0.10.25 [PRE26] pip install torch==2.1.2
    pip install transformers==4.36.0 pip install python-pptx==0.6.23 pip install Pillow==10.2.0
    [PRE27] 导入 argparse 导入 openai  from llama_index.core import VectorStoreIndex,
    SimpleDirectoryReader  if __name__ == ''__main__'':      #1     parser = argparse.ArgumentParser()     parser.add_argument(''datadir'',
    type=str, help=''数据目录路径'')     parser.add_argument(''question'', type=str, help=''要回答的问题'')     args
    = parser.parse_args()      #2     documents = SimpleDirectoryReader(args.datadir).load_data()      #3     index
    = VectorStoreIndex.from_documents(documents)      #4     engine = index.as_query_engine()      #5     answer
    = engine.query(args.question)     print(answer) [PRE28] python listing4.py bananareports
    ''2023年香蕉单位赚了多少钱？'' [PRE29] 香蕉单位在2023年赚了3000万美元。'
