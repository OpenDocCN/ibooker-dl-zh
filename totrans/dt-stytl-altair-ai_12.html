<html><head></head><body>
<div id="sbo-rt-content"><div class="readable-text" id="p1">
<h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">10</span></span> <span class="chapter-title-text">Common issues while using generative AI</span></h1>
</div>
<div class="introduction-summary">
<h3 class="introduction-header">This chapter covers</h3>
<ul>
<li class="readable-text" id="p2">Hallucination, bias, and copyright </li>
<li class="readable-text" id="p3">Guidelines for using generative AI</li>
<li class="readable-text" id="p4">Crediting the sources</li>
</ul>
</div>
<div class="readable-text" id="p5">
<p>Your data story is now ready. However, before disseminating it to your audience, you should reflect on the possible issues associated with using generative AI. We will not discuss the technical details of these issues, but the concepts described will help you complete your overall understanding of generative AI. For more details, you are encouraged to read some of the detailed books on the topic—some of which are listed in the references of this chapter. </p>
</div>
<div class="readable-text intended-text" id="p6">
<p>In the first part of this chapter, we’ll focus on hallucinations, bias, and copyright. Next, we will focus on the guidelines for using generative AI. Finally, we’ll see how to correctly credit the sources, including data sources and generative AI. Before disseminating the story, let’s start with the first point: hallucination, bias, and copyright.</p>
</div>
<div class="readable-text" id="p7">
<h2 class="readable-text-h2"><span class="num-string">10.1</span> Hallucination, bias, and copyright</h2>
</div>
<div class="readable-text" id="p8">
<p>Generative AI is not an omniscient oracle but is the result of human effort, and as such, it reflects the characteristics of humanity, including intelligence, scientific progress, and so on but also discrimination, inequalities, and injustices. Generative AI, while a product of human ingenuity and scientific advancement, inherently carries the biases and limitations of the data it is trained on, reflecting not only our knowledge but also our societal and historical prejudices. It’s crucial to remember that these systems are limited by their training data and algorithms and do not possess any innate understanding of consciousness.</p>
</div>
<div class="readable-text intended-text" id="p9">
<p>All this, everything that humanity is, is therefore reflected in AI, both what is good and what is less good in humanity. For this reason, when generative AI is used as a work tool, particularly in data storytelling, it must always be handled carefully, with special attention paid to the benefits and possible damage it could cause to the most vulnerable people. Generative AI products have the potential to generate outputs biased against minority populations and can even be used to build manipulated stories with a plausible appearance.</p>
</div>
<div class="readable-text intended-text" id="p10">
<p>To get a practical idea of discrimination that may occur inadvertently while using Generative AI, consider the following prompt for DALL-E: <em>a photo of a woman wearing a red dress</em>. Figure 10.1 shows a possible output generated by DALL-E.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p11">
<img alt="figure" height="263" src="../Images/10-1.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.1</span> A photo of a woman wearing a red dress</h5>
</div>
<div class="readable-text" id="p12">
<p>Now, consider this prompt for DALL-E: <em>a woman wearing an orange sweater drinking a coffee</em>. Figure 10.2 shows a possible output generated by DALL-E. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p13">
<img alt="figure" height="263" src="../Images/10-2.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.2</span> A woman wearing an orange sweater drinking a coffee</h5>
</div>
<div class="readable-text" id="p14">
<p>Finally, consider the following prompt:<em> a man sitting on a yellow chair</em>. Figure 10.3 shows a possible output generated by DALL-E.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p15">
<img alt="figure" height="263" src="../Images/10-3.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.3</span> A man sitting on a yellow chair</h5>
</div>
<div class="readable-text" id="p16">
<p>We may continue generating more and more images, but we will probably always obtain similar results. What do figures 10.1, 10.2, and 10.3 have in common? The problem is that almost all the represented persons have dark hair (with the possible exception of the woman in image number 4 in figure 10.2). This may be a minor problem if we generate a small number of images. However, if we use DALL-E to generate images at a large scale, using only dark-haired people may generate a sort of bias against people with lighter hair.</p>
</div>
<div class="readable-text intended-text" id="p17">
<p>This example shows a simple case of generative AI being partial. The problem is probably in the data used to train the generative model, which may contain more dark-haired than blonde-haired people. This is a relatively benign example, but it clearly illustrates that you may need to be mindful of bias and partiality in AI outputs.</p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p18">
<h5 class="callout-container-h5 readable-text-h5">Challenge 1: Other types of discrimination </h5>
</div>
<div class="readable-text" id="p19">
<p>Can you find other kinds of discrimination while generating images with people in DALL-E? For example, try to generate a woman with blonde hair. What kind of stereotype would you obtain?</p>
</div>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p20">
<h5 class="callout-container-h5 readable-text-h5">Challenge 2: Color and mood</h5>
</div>
<div class="readable-text" id="p21">
<p>DALL-E associates color and mood. For example, try the following prompts: (1) a woman wearing a yellow sweater, (2) a woman wearing a blue dress. Do you obtain different moods, although you didn’t specify any?</p>
</div>
</div>
<div class="readable-text" id="p22">
<p>These issues caused by generative AI depend on different causes, such as AI hallucinations, bias, and copyright. We will not delve into the technical details related to these issues; you can read the resources described in this chapter’s references for more information. In the remainder of this section, we will briefly describe the potential issues generative AI may introduce. Let’s start with hallucinations.</p>
</div>
<div class="readable-text" id="p23">
<h3 class="readable-text-h3"><span class="num-string">10.1.1</span> AI hallucinations</h3>
</div>
<div class="readable-text" id="p24">
<p><em>Hallucination</em> happens when generative AI generates content that does not correspond to reality. Hallucinations within AI can create misleading or entirely fabricated data. Hallucination is a problem brought about by generative AI’s very design, in the sense that the large language models (LLMs) behind generative AI are generated without any communication of intent. It simply generates a statistically more probable text given the training dataset. Additionally, for instance, if a generative AI model is primarily trained on datasets containing English-language texts, it might struggle with accurately understanding or generating content in less-represented languages, reflecting a statistical bias toward English. Hallucinations can lead to ethical problems due to their potential misuse for generating content for user manipulation.</p>
</div>
<div class="readable-text intended-text" id="p25">
<p>Hallucination in generative AI can manifest in various ways. For example, a data story completely generated by AI could describe a nonexistent political scandal, potentially misleading the public and impacting decision making based on false information. To mitigate the hallucination problem, we always recommend having a <em>human-in-the-loop validation</em>. Before incorporating any AI-generated content in your story, please judge and review it.</p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p26">
<h5 class="callout-container-h5 readable-text-h5">Challenge 3: Joking with generative AI </h5>
</div>
<div class="readable-text" id="p27">
<p>Just for fun, consider the swimming pool case study in chapter 2. As a quick reminder, the case study focused on the possibility of building a new swimming pool in a Portuguese hotel. Use the following prompt to generate the next steps: <em>Consider the following scenario: the case study focused on the possibility of building a new swimming pool in a Portuguese hotel. The data story showed an increasing number of tourists in Portugal in recent years. Write some hallucinated next steps.</em> What do you obtain?</p>
</div>
</div>
<div class="readable-text" id="p28">
<p>To mitigate hallucinations, you can try to set the following parameters in your prompt:</p>
</div>
<ul>
<li class="readable-text" id="p29"> <em>Temperature</em>—The temperature controls the degree of randomness applied during the output generation process. It allows users to tailor the generated content’s level of creativity and unpredictability. It ranges from 0 for more structured and predictable outputs to 2 for more creative and unexpected results. The default value rests at 1. To introduce temperature in your prompt, simply add the text <em>set temperature = N </em>(e.g.,<em> use temperature = 2</em>). We can use a lower temperature value to reduce the probability that the model hallucinates. </li>
<li class="readable-text" id="p30"> <em>Top P</em>—Top P is also known as nucleus sampling or penalty-free sampling. It helps to control the diversity of the generated text. Use this technique to generate responses that don’t completely deviate from the topic. The range is between 0 and 1. A higher top P makes the output more diverse, while a lower value makes the model more deterministic. The default value is 1. To introduce top P in your prompt, add the text <em>set top P = N</em> (e.g., <em>use top P = 1</em>). </li>
</ul>
<div class="readable-text" id="p31">
<p>Usually, you set one parameter per prompt.</p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p32">
<h5 class="callout-container-h5 readable-text-h5">Challenge 4: Setting temperature and P value</h5>
</div>
<div class="readable-text" id="p33">
<p>Set the temperature or the top P value to 0 in the prompt of challenge 3, and then compare the new result with the original output of challenge 3. Do you notice some differences?</p>
</div>
</div>
<div class="readable-text" id="p34">
<p>You can find a detailed description of how to set the temperature and the top P parameters in my blog post, “How to Improve Your ChatGPT Outputs Using Configuration Parameters” (<a href="https://mng.bz/pp4G">https://mng.bz/pp4G</a>). Now that we’ve covered hallucinations, let’s move to the next problem: bias.</p>
</div>
<div class="readable-text" id="p35">
<h3 class="readable-text-h3"><span class="num-string">10.1.2</span> Bias</h3>
</div>
<div class="readable-text" id="p36">
<p><em>Bias</em> is a systematic and often unconscious inclination, prejudice, or tendency that influences decision making, actions, perceptions, or judgments in favor of or against a particular person, group, object, or idea. Bias relies on human beliefs, stereotypes, or discrimination. Since LLMs are trained on datasets mostly created by humans, inevitably, these datasets contain bias. Bias is intrinsic to humans, so we can’t remove it from our datasets.</p>
</div>
<div class="readable-text intended-text" id="p37">
<p>Even in a hypothetical scenario where people are equal and free, and there is no discrimination and war, bias may occur. In fact, <em>bias is multifaceted</em>. Bias in AI is not limited to negative topics, like discrimination or war. Bias can also be in the form of cultural preferences, idiomatic expressions, or even what is considered “normal.” An LLM trained on data from even an ideal world might still develop biases based on what is prevalent or dominant in that data.</p>
</div>
<div class="readable-text intended-text" id="p38">
<p>In addition, even with ideal data, LLMs might still develop biases, due to their design, the algorithms they use, or the inherent limitations in understanding and processing human language. In other words, our LLM could still exhibit bias even in this hypothetical scenario.</p>
</div>
<div class="readable-text intended-text" id="p39">
<p>There are different perspectives to classify bias, such as those proposed by Baer in his book, <em>Understand, Manage, and Prevent Algorithmic Bias</em> (Apress, 2019). One possible approach classifies bias into the following types: </p>
</div>
<ul>
<li class="readable-text" id="p40"> <em>Data bias</em>—This refers to the presence of bias in the training set. It derives from different causes, such as the underrepresentation of some groups in the training set. LLMs are trained with data extracted from the internet. However, the text on the web is written by a small percentage of humans. Tons of books representing the knowledge of all humankind from their beginning to today lie in libraries and are not available on the internet. This means that although big data is used to train LLMs, size does not guarantee diversity. </li>
<li class="readable-text" id="p41"> <em>Algorithm bias</em>—This type of bias derives from the assumptions and decisions made during the design, coding, or implementation of machine learning (ML) algorithms. This bias can arise due to feature selection, model complexity, and other technical problems related to the algorithms. </li>
<li class="readable-text" id="p42"> <em>Measurement bias</em>—This occurs when the methods or tools used to collect data systematically misrepresent or distort the information being gathered. This bias can originate from different factors, such as instruments, human observers, and so on. </li>
</ul>
<div class="readable-text" id="p43">
<p>At the time of writing this book, there is no definitive solution to remove bias from generative AI tools. However, some possible techniques to mitigate bias could include data cleaning and balancing, inserting a human in the middle, model evaluation, and so on. Removing bias from generative AI would also mean first removing it from humanity, which would be significant progress for the world but is unlikely to happen anytime soon. Anyway, we could mitigate bias by always paying attention to the generated output and anchoring our data story to an ethical framework, as explained in the previous chapter. Having considered the problem of bias, let’s move to the next problem: copyright.</p>
</div>
<div class="readable-text" id="p44">
<h3 class="readable-text-h3"><span class="num-string">10.1.3</span> Copyright</h3>
</div>
<div class="readable-text" id="p45">
<p>Generative AI models have been trained on huge quantities of data, derived especially from content shared freely in the public space. However, the creators of the original datasets used to train the models do not allow access to them, so we don’t know whether proprietary data has also been used to train the models. For this reason, AI-generated content might raise questions about intellectual property rights and ownership. Copyright questions may be connected to the fact that generative AI models are black boxes and the data used to train them are unavailable. </p>
</div>
<div class="readable-text intended-text" id="p46">
<p>For example, consider an AI system trained on an extensive database of music that generates a piece similar to an existing copyrighted song. Determining the original creator becomes complex, raising questions about the ownership of AI-generated content and the rightful attribution of intellectual property, potentially leading to legal disputes between creators and AI systems. Before using generative AI, you should always understand copyright law, use clear licensing agreements for data sources, create original datasets, emphasize attribution and acknowledgment, implement copyright filters, and seek regular legal consultation.</p>
</div>
<div class="readable-text intended-text" id="p47">
<p>All the issues described in this book remain unsolved at the time of writing. For this reason, I recommend consistently controlling the output produced by generative AI when using it for data storytelling and, in general, for all the application fields. It’s your responsibility to use generative AI ethically, ensuring that everyone is treated equally, minority populations are not underrepresented, and so on. To help you control the generative AI output and modify it if needed, you can apply the common guidelines for ethically using generative AI. So, let’s move on and learn them!</p>
</div>
<div class="readable-text" id="p48">
<h2 class="readable-text-h2"><span class="num-string">10.2</span> Guidelines for using generative AI</h2>
</div>
<div class="readable-text" id="p49">
<p>Many initiatives exist to regularize the use of AI and generative AI in all domains, such as the European Union AI Act (European Commission, 2021) and the White House’s Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (White House, 2023). You can find the links to these documents at the end of the chapter, in the references section.</p>
</div>
<div class="readable-text intended-text" id="p50">
<p>Referring to the field of data storytelling, following these guidelines means respecting human values. The UNESCO AI ethics guidelines emphasize four core values:</p>
</div>
<ul>
<li class="readable-text" id="p51"> <em>Human rights and dignity</em>—Every data story, including the pieces generated through generative AI, must respect human rights and dignity. The UNESCO guidelines say explicitly that “no human being or human community should be harmed or subordinated, whether physically, economically, socially, politically, culturally or mentally, during any phase of the life cycle of AI systems.” </li>
<li class="readable-text" id="p52"> <em>Peaceful and just societies</em>—AI should be used to foster harmony and equity within communities, promoting fairness, transparency, and accountability in decision-making processes. </li>
<li class="readable-text" id="p53"> <em>Diversity and inclusiveness</em>—AI should respect the richness of human diversity in all its forms, including but not limited to race, gender, ethnicity, culture, and more. </li>
<li class="readable-text" id="p54"> <em>Environmental flourishing</em>—AI should prioritize sustainability and contribute positively to environmental preservation. </li>
</ul>
<div class="readable-text" id="p55">
<p>We can apply the previous guidelines to check if AI-generated content is ethically correct. For all AI-generated content, we should answer the following questions:</p>
</div>
<ul>
<li class="readable-text" id="p56"> Does the AI-generated content respect human rights? </li>
<li class="readable-text" id="p57"> Does the AI-generated content respect society? </li>
<li class="readable-text" id="p58"> Does the AI-generated content respect diversity and inclusiveness? </li>
<li class="readable-text" id="p59"> Does the AI-generated content respect the environment? </li>
</ul>
<div class="readable-text" id="p60">
<p>To understand how to apply these guidelines to a practical data story, consider the case study we analyzed in chapter 4, related to selecting the optimal sports disciplines to train in to achieve good results in upcoming competitions. As next steps, we proposed to invest in cycling and rowing. Figure 10.4 shows the final data story.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p61">
<img alt="figure" height="783" src="../Images/10-4.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.4</span> The sports disciplines data story described in chapter 4</h5>
</div>
<div class="readable-text intended-text" id="p62">
<p>Let’s look at each part generated by AI:</p>
</div>
<ul>
<li class="readable-text" id="p63"> <em>General title</em>—Unlock the Potential: Invest in Rowing and Cycling for Maximum Returns! </li>
<li class="readable-text" id="p64"> <em>Image 1</em>—The white man practicing rowing </li>
<li class="readable-text" id="p65"> <em>Image 2</em>—The white woman practicing cycling </li>
</ul>
<div class="readable-text" id="p66">
<p>The only problem with the AI-generated content for this scenario regards diversity and inclusiveness. The two images, in fact, describe two white-skinned individuals. To make the data story fit the ethical guidelines, we could replace one of the two images with an individual of another ethnicity.</p>
</div>
<div class="readable-text" id="p67">
<h4 class="readable-text-h4">Exercise 1</h4>
</div>
<div class="readable-text" id="p68">
<p>Consider the case study described in chapter 5 on homelessness, shown in figure 10.5. The case study focused on searching for funds to finance a project on reducing homelessness in Italy. Now, follow these steps: </p>
</div>
<ol>
<li class="readable-text" id="p69"> Identify the AI-generated content. </li>
<li class="readable-text buletless-item" id="p70"> For each element of AI-generated content, answer the following questions: 
    <ol style="list-style: lower-alpha">
<li> Does the AI-generated content respect human rights? </li>
<li> Does the AI-generated content respect society? </li>
<li> Does the AI-generated content respect diversity and inclusiveness? </li>
<li> Does the AI-generated content respect the environment?<span class="aframe-location"/> </li>
</ol></li>
</ol>
<div class="browsable-container figure-container" id="p71">
<img alt="figure" height="828" src="../Images/10-5.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.5</span> The homelessness case study described in chapter 5</h5>
</div>
<div class="readable-text" id="p72">
<p>Now that you have learned the guidelines for ethically using generative AI, let’s move on to the following step: determining your role while using it. </p>
</div>
<div class="readable-text" id="p73">
<h2 class="readable-text-h2"><span class="num-string">10.3</span> Crediting the sources</h2>
</div>
<div class="readable-text" id="p74">
<p><em>Crediting the sources</em> means referencing the sources used in a data story. This is particularly important because it allows you to recognize the work done by others. It also adds credibility to the story, as the audience can personally check the sources used in the story. What types of sources should be credited? In general, any source used to make the story should be credited, but particularly the following sources:</p>
</div>
<ul>
<li class="readable-text" id="p75"> The data source </li>
<li class="readable-text" id="p76"> The fact that generative AI was used </li>
<li class="readable-text" id="p77"> Any documents used for fine-tuning or retrieval augmented generation (RAG) </li>
</ul>
<div class="readable-text" id="p78">
<p>While you can use your creativity to place credits wherever you want, traditionally, we add credits to a data story in one of four places:</p>
</div>
<ul>
<li class="readable-text" id="p79"> Under the title/subtitle </li>
<li class="readable-text" id="p80"> Under the main chart </li>
<li class="readable-text" id="p81"> Under the next steps </li>
<li class="readable-text" id="p82"> Sideways </li>
</ul>
<div class="readable-text" id="p83">
<p>Let’s investigate each of these separately.</p>
</div>
<div class="readable-text" id="p84">
<h3 class="readable-text-h3"><span class="num-string">10.3.1</span> Under the title or subtitle</h3>
</div>
<div class="readable-text" id="p85">
<p>Placing the credits under the title or subtitle generates a sense of trust in the audience from the story’s beginning. Figure 10.6 shows an example of credits placed under the title or subtitle.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p86">
<img alt="figure" height="713" src="../Images/10-6.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.6</span> An example of a data story with credits under the title or subtitle</h5>
</div>
<div class="readable-text" id="p87">
<p>Use this placement if you want your audience to know the sources from the story’s beginning. Although this placement may generate trust, it could also be distracting, since the audience may leave your story to search for the sources. </p>
</div>
<div class="readable-text" id="p88">
<h3 class="readable-text-h3"><span class="num-string">10.3.2</span> Under the main chart</h3>
</div>
<div class="readable-text" id="p89">
<p>Placing the credits under the main chart involves adding a detail to the main point of the story. This helps reinforce the essential points of the story. Figure 10.7 shows an example of credits placed under the main chart. Use this placement if you want to reinforce the main message of your chart. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p90">
<img alt="figure" height="694" src="../Images/10-7.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.7</span> An example of a data story with credits under the main chart</h5>
</div>
<div class="readable-text" id="p91">
<h3 class="readable-text-h3"><span class="num-string">10.3.3</span> Under the next steps</h3>
</div>
<div class="readable-text" id="p92">
<p>In this case, credit the sources at the end of your story, as an appendix to the next steps, as shown in figure 10.8. Use this placement if you want to reinforce the next steps of your story.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p93">
<img alt="figure" height="758" src="../Images/10-8.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.8</span> An example of a data story with credits under the next steps</h5>
</div>
<div class="readable-text" id="p94">
<h3 class="readable-text-h3"><span class="num-string">10.3.4</span> Sideways</h3>
</div>
<div class="readable-text" id="p95">
<p>Placing credits sideways means considering them as external to the main data story workflow. You can place credits either on the left or on the right, as shown in figure 10.9.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p96">
<img alt="figure" height="608" src="../Images/10-9.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.9</span> An example of a data story with credits on the left and the right</h5>
</div>
<div class="readable-text" id="p97">
<p>Use this placement to keep credits external to your main data story workflow and keep the audience concentrated on the story. Now that we’ve considered the various places you can place credits, let’s move on to how to implement credits practically. </p>
</div>
<div class="readable-text" id="p98">
<h3 class="readable-text-h3"><span class="num-string">10.3.5</span> Implementing credits in Altair</h3>
</div>
<div class="readable-text" id="p99">
<p>To implement credits in Altair, use <code>mark_text()</code> with a smaller font than the one you used for the main story. Optionally, you can include a hyperlink to the original source.</p>
</div>
<div class="readable-text intended-text" id="p100">
<p>Consider the case study on sports disciplines described in chapter 4 and shown in figure 10.4. Let’s credit DALL-E for images and ChatGPT for the title. Add the following text as credits: <em>Images: source DALL-E. Title: source ChatGPT</em>.</p>
</div>
<div class="readable-text intended-text" id="p101">
<p>We will place credits on the left side. You can find the implemented code in the GitHub repository for the book under 10/crediting/left-sideways. The following listing shows the code to implement the credits section on the left. </p>
</div>
<div class="browsable-container listing-container" id="p102">
<h5 class="listing-container-h5 browsable-container-h5"><span class="num-string">Listing 10.1</span> Adding the credits on the left</h5>
<div class="code-area-container code-area-with-html">
<pre class="code-area">credits_df = pd.DataFrame({'text': ['Images: source DALL-E, Title: source ChatGPT']})
credits = alt.Chart(credits_df
        ).mark_text(
            size=10, 
            align='left', 
            color='black',
<strong>            angle=270,</strong>
            x=-70,
            y=200

        ).encode(
            text='text'
        )

chart = (credits + chart + annotation)</pre>
</div>
</div>
<div class="readable-text print-book-callout" id="p103">
<p><span class="print-book-callout-head">Note</span>  Use <code>mark_text()</code> to add credits. Use the <code>angle</code> attribute to rotate the text 270 degrees. Adapt<em> </em><code>x</code> and <code>y</code> to the chart. Try different values to obtain the best result.</p>
</div>
<div class="readable-text" id="p104">
<p>As usual, you can ask Copilot to generate the code for you. Figure 10.10 shows the resulting chart.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p105">
<img alt="figure" height="782" src="../Images/10-10.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.10</span> The sports disciplines case study described in chapter 4, with credits on the left</h5>
</div>
<div class="readable-text" id="p106">
<h4 class="readable-text-h4">Exercise 2</h4>
</div>
<div class="readable-text" id="p107">
<p>Modify the previous example by implementing credits under the title, as shown in figure 10.11. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p108">
<img alt="figure" height="887" src="../Images/10-11.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 10.11</span> The sports disciplines case study described in chapter 4, with credits under the title</h5>
</div>
<div class="readable-text intended-text" id="p109">
<p>You can find the solution to this exercise in the GitHub repository for the book under 10/crediting/under-the-title.</p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p110">
<h5 class="callout-container-h5 readable-text-h5">Challenge 5: Comparing Reading Flows</h5>
</div>
<div class="readable-text" id="p111">
<p>Compare figures 10.10 and 10.11. Can you distinguish any difference in terms of the reading flow? </p>
</div>
</div>
<div class="readable-text" id="p112">
<p>So far, you have learned how to credit sources in your data story. In the next chapter, you’ll see how to export the final story.</p>
</div>
<div class="readable-text" id="p113">
<h2 class="readable-text-h2">Summary</h2>
</div>
<ul>
<li class="readable-text" id="p114"> Using generative AI in any application may surface different issues, such as bias and discrimination. Thus, it is very important to review the content provided by generative AI. </li>
<li class="readable-text" id="p115"> Using generative AI ethically means respecting people, society, and the environment, according to UNESCO principles. </li>
<li class="readable-text" id="p116"> Before publishing your data story, make sure to credit sources. It’s a way to recognize the work done by others and to generate a greater sense of trust in your audience </li>
</ul>
<div class="readable-text" id="p117">
<h2 class="readable-text-h2">References</h2>
</div>
<div class="readable-text" id="p118">
<h3 class="readable-text-h3">Generative AI issues</h3>
</div>
<ul>
<li class="readable-text" id="p119"> Baer, T. (2019). <em>Understand, Manage, and Prevent Algorithmic Bias</em>. Apress. </li>
<li class="readable-text" id="p120"> Tomczak, J. M. (2022). <em>Deep Generative Modeling</em>. Springer. </li>
</ul>
<div class="readable-text" id="p121">
<h3 class="readable-text-h3">Ethics and AI</h3>
</div>
<ul>
<li class="readable-text" id="p122"> EU AI Act. (2021). <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:52021PC0206">https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:52021PC0206</a>. </li>
<li class="readable-text" id="p123"> White House Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. (2023). <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/">https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/</a>.<span class="link-like"/> </li>
<li class="readable-text" id="p124"> UNESCO Recommendation on the Ethics of Artificial Intelligence. (2022). <a href="https://unesdoc.unesco.org/ark:/48223/pf0000381137">https://unesdoc.unesco.org/ark:/48223/pf0000381137</a> . </li>
</ul>
</div></body></html>