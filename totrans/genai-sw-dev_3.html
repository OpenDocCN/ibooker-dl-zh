<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 3. Bug Detection and Code Review"><div class="chapter" id="ch03_bug_detection_and_code_review_1749441076008122">
      <h1><span class="label">Chapter 3. </span>Bug Detection and Code Review</h1>
      <p>Imagine paying the highest salaries in a company to software engineers to develop a product that will be responsible for the company’s revenue, only to lose that revenue due to costly bugs in production. This is any business owner’s worst nightmare, and sadly it happens every day. Software has automated whole industries, replacing lengthy manual processes and creating new ways to do previously impossible things. However, automation can’t be effective when bugs detract from the underlying products’ key functionalities.</p>
      <p>To mitigate this fundamental concern, several job titles have been created over the years to guarantee proper quality assurance (QA), such as QA engineer, QA analyst, and test engineer. Processes, too, have been developed to detect bugs before they get deployed <a contenteditable="false" data-type="indexterm" data-primary="bug detection" id="id314"/><a contenteditable="false" data-type="indexterm" data-primary="QA (quality assurance)" id="id315"/><a contenteditable="false" data-type="indexterm" data-primary="QA engineer" id="id316"/><a contenteditable="false" data-type="indexterm" data-primary="QA analyst" id="id317"/><a contenteditable="false" data-type="indexterm" data-primary="test engineer" id="id318"/>to production. Those processes boil down to two main categories:</p>
      <dl>
        <dt>Code reviews</dt>
        <dd>
          <p>This process is done during <a contenteditable="false" data-type="indexterm" data-primary="code review" id="id319"/>development, and it consists of team members reviewing each other’s code before it is deemed ready to go live. Some teams mandate a minimum number of team members who must review and approve a pull request (PR) before <a contenteditable="false" data-type="indexterm" data-primary="PR (pull request)" id="id320"/>it can be merged.</p>
        </dd>
        <dt>Quality assurance </dt>
        <dd>
          <p>This process is done after development as the last “gatekeeper” before code gets pushed to production. It consists of manual or automated tests done in an environment that closely matches production. These tests aim to mimic users’ behavior to catch any bug that could have escaped a code review.</p>
        </dd>
      </dl>
      <p>When either process finds any bugs, performance issues, security vulnerabilities, or other <a contenteditable="false" data-type="indexterm" data-primary="code" data-secondary="regression" id="id321"/><a contenteditable="false" data-type="indexterm" data-primary="regression" id="id322"/>malfunctions, the code can be <em>regressed;</em> that is, it goes back to the software engineer who developed it, along with a comment containing the specific deficiencies that must be corrected.</p>
      <p class="fix_tracking">These processes are critical to any software development team, yet they are often very lengthy and nondeterministic, introducing bottlenecks while not fully delivering on the vision of preventing bugs from showing up in production. As such, as AI tools have come into existence, the industry has seen a big focus on automating code reviews and making the process of detecting bugs much faster and more deterministic. Thousands of software engineering teams are already using AI-based automated code-review tools.</p>
      <section data-type="sect1" data-pdf-bookmark="Types of AI Code-Review Tools"><div class="sect1" id="ch03_types_of_ai_code_review_tools_1749441076008235">
        <h1>Types of AI Code-Review Tools</h1>
        <p>The AI tools reviewed for this chapter fall into three main categories, with slightly different usage in software development. Some of the tools reviewed offer more than one type of functionality.</p>
        <dl>
          <dt>IDE-based tools</dt>
          <dd>
            <p>IDE-based tools integrate <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="IDE-based" id="id323"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="IDE-based tools" id="id324"/><a contenteditable="false" data-type="indexterm" data-primary="IDE-based tools" data-secondary="code review" id="id325"/><a contenteditable="false" data-type="indexterm" data-primary="Visual Studio Code" id="id326"/><a contenteditable="false" data-type="indexterm" data-primary="IntelliJ IDEA" id="id327"/><a contenteditable="false" data-type="indexterm" data-primary="Eclipse" id="id328"/>directly into the software development environment that engineers use to write code, such as Visual Studio Code, IntelliJ IDEA, or Eclipse. These tools provide real-time feedback as developers write code: highlighting errors, suggesting improvements, and providing documentation links directly in the IDE. Of the three types of tools described here, this is the only type that provides feedback when the code is saved locally. This immediate feedback loop helps developers identify and fix issues on the spot, improving code quality and reducing the need for extensive reviews later.</p>
          </dd>
          <dt>Git-based tools</dt>
          <dd>
            <p>Git-based tools integrate <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="Git-based" id="id329"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="Git-based tools" id="id330"/><a contenteditable="false" data-type="indexterm" data-primary="Git-based code review tools" id="id331"/>with version-control systems, such as GitHub, GitLab, or Bitbucket, and operate within the Git workflow. Unlike IDE-based tools, Git-based tools can’t be triggered by local saves of a file, only by actions in the Git workflow. You can set them up to review code automatically whenever you push changes to a repository or create or merge a PR. These tools check the code against predefined rules and guidelines and can enforce coding standards across all branches of the codebase. They typically provide feedback in the form of comments in PRs or reports in a continuous integration pipeline, helping ensure code quality before merging changes into the main branch.</p>
          </dd>
          <dt>Browser-based tools</dt>
          <dd>
            <p>These tools are <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="browser-based" id="id332"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="browser-based tools" id="id333"/><a contenteditable="false" data-type="indexterm" data-primary="browser-based tools" data-secondary="code review" id="id334"/>accessible through web browsers and typically integrate with online version-control platforms like GitHub, GitLab, and Bitbucket. Like Git-based tools, they can only be triggered by changes in the Git workflow, not local changes. You can use these browser-based tools to get automatic reviews of your PRs or code merges online. When you submit a PR, the tool reviews the code for errors, style violations, and security vulnerabilities, then provides feedback on that PR via the web interface in the browser. I find this the least convenient of the three types of tools presented here, since it requires you to use another platform besides the IDE and version-control tools you are already familiar with.</p>
          </dd>
        </dl>
        <p>It’s also important to differentiate between linters, static analysis tools, and AI-powered code-analysis tools:</p>
        <dl>
          <dt>Linters</dt>
          <dd>
            <p>These are the simplest <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="linters" id="id335"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="linters" id="id336"/><a contenteditable="false" data-type="indexterm" data-primary="linters" id="id337"/>of these tools, focusing primarily on enforcing coding standards and styles. They scan code to identify syntax errors, stylistic inconsistencies, and basic programming errors. Linters like<a contenteditable="false" data-type="indexterm" data-primary="ESLint for JavaScript" id="id338"/><a contenteditable="false" data-type="indexterm" data-primary="JavaScript, Linter for JavaScript" id="id339"/><a contenteditable="false" data-type="indexterm" data-primary="Python, Pylint for Python" id="id340"/> <a href="https://eslint.org">ESLint for JavaScript</a> and <a href="https://oreil.ly/-wu0d">Pylint for Python</a> are integrated into development environments, providing real-time feedback to correct issues like indentation, bracket placement, and line length.</p>
          </dd>
          <dt>Static analysis tools</dt>
          <dd>
            <p>These tools delve deeper, analyzing <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="static analysis" id="id341"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="static analysis" id="id342"/><a contenteditable="false" data-type="indexterm" data-primary="static analysis tools" id="id343"/><a contenteditable="false" data-type="indexterm" data-primary="SonarQube" id="id344"/>code without executing it in order to detect potential bugs, security vulnerabilities, and performance issues. Static analysis tools, such as <a href="https://oreil.ly/wrZII">SonarQube</a>, understand control flow, data flow, and variable scopes, making them capable of identifying complex issues like memory leaks and concurrency problems. They are commonly integrated into CI/CD pipelines, helping to maintain code health across projects.</p>
          </dd>
          <dt>AI-powered code analysis</dt>
          <dd>
            <p class="fix_tracking">These tools use machine <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="code analysis" id="id345"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="code analysis" id="id346"/><a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code analysis" id="id347"/>learning to analyze coding patterns across many projects, identifying complex issues and suggesting improvements. AI analysis tools, like DeepCode and Codacy, provide context-aware suggestions and <a contenteditable="false" data-type="indexterm" data-primary="DeepCode (Snyk)" id="id348"/><a contenteditable="false" data-type="indexterm" data-primary="Codacy" id="id349"/>can predict the impact of code changes, offering optimization tips learned from vast datasets.</p>
          </dd>
        </dl>
        <p>Due to the scope of this book, I’ll only cover this last type of tool, AI-powered code analysis.</p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Use Cases"><div class="sect1" id="ch03_use_cases_1749441076008289">
        <h1>Use Cases</h1>
        <p>The millions of software engineers who are already using AI tools for automated code reviews and bug detection find that they bring obvious benefits across a range of daily use cases. These include:</p>
        <dl>
          <dt>Educating software engineers </dt>
          <dd>
            <p class="fix_tracking">Automated code-review tools <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="use cases" id="tcdrvuc"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="AI tool use cases" id="cdrvaiu"/>provide software engineers, especially more junior ones, with a 24/7 pair programmer that points out bugs, offers suggestions, and above all gives context and reasoning for its suggestions. This is a great tool to hone your skills. Feedback loops are much more frequent with an automated tool than with normal code reviews by team members, increasing exposure to learning opportunities about the language, framework, or algorithm in question. This is extra beneficial for junior developers and for engineers switching to new tech stacks or working with a framework for the first time, since lack of experience makes mistakes more common. In code reviews, errors can be regressed with a message that helps the developer understand the mistake and avoid it next time.</p>
          </dd>
          <dt>Increasing software development velocity</dt>
          <dd>
            <p>Automating code review reduces the number of PR regressions. It also tremendously reduces the <a contenteditable="false" data-type="indexterm" data-primary="software development velocity" id="id350"/>amount of time between the code being written and the review identifying issues to be fixed. Automatic code reviews at every change can point out vulnerabilities and improvements so that developers can fix them immediately. This eliminates the cycle of pushing faulty code only for other team members to find and regress it—a cycle of multiple regression loops that cost individual developers time and delay shipping features to production.</p>
          </dd>
          <dt>Reducing tech debt</dt>
          <dd>
            <p>Many times, code reviews overlook security vulnerabilities and performance issues because they don’t <a contenteditable="false" data-type="indexterm" data-primary="tech debt reduction" id="id351"/>usually impact functionality, which is objectively the biggest focus of any code review. Even when they are detected, they aren’t often treated as cause for regression. Instead, they often go into a “nice to have” note, effectively adding the vulnerability or issue to the pile of tech debt. That pile usually accumulates for a long time, until it becomes unsustainable and requires extensive refactoring of the codebase.</p>
          </dd>
          <dt>Adding depth to code reviews</dt>
          <dd>
            <p>Most of the code-review tools mentioned in <a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="depth" id="id352"/>this chapter focus on security vulnerabilities and often point out occurrences of OWASP Top 10 vulnerabilities in code, along with suggestions for resolving them. Team code reviews rarely reach this level of depth; such vulnerabilities are often only detected much later (if ever), during professional security audits or penetration-testing reports. Using these tools allows <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="use cases" data-startref="tcdrvuc" id="id353"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="AI tool use cases" data-startref="cdrvaiu" id="id354"/>teams to detect security vulnerabilities much earlier.</p>
          </dd>
        </dl>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Keeping the Human Review"><div class="sect1" id="ch03_keeping_the_human_review_1749441076008339">
        <h1>Keeping the Human Review</h1>
        <p>A common criticism of automated code-review tools is that they discourage (human) team members from performing code reviews in a timely manner. To be fair, code reviews were a <a contenteditable="false" data-type="indexterm" data-primary="human review, code review and" id="hmnrvrv"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="human review and" id="cdrvhmrv"/><a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="human review" id="aitrvwhuv"/>dreaded activity in many teams long before AI tools came into existence. Software engineers frequently forget to review their peers’ pull requests or leave a positive review message of “lgtm” (short for “looks good to me”) just to unblock a feature deployment.</p>
        <p>AI tools add tremendous immediacy to the code-review process. This reassures software engineers that their code has a high quality standard, but it also leaves them feeling less urgency to review their peers’ code, believing the AI tool has already done that job for them.</p>
        <p>This is a very fair criticism, in my opinion. <em>AI code reviews don’t replace human code reviews</em>, especially those performed by senior engineers who know both a feature’s technology and the business and use cases for it. This is the angle that is manifestly missing in AI code reviews. The AI tool misses the <em>context</em> behind the code being reviewed and the intent behind certain code segments. This can lead it to make irrelevant suggestions or fail to identify context-specific issues that might be obvious to a human reviewer. This is a key reason why you should <em>never skip human code reviews</em>, even if you’re also using automated code reviews.</p>
        <p>It’s also worth noting that the language used to market these automated code-review tools is quite different from that used for the code-generation tools reviewed in the previous chapter. Few of the tools discussed in this chapter mention AI in their marketing copy much (or at all), despite the fact that the products do use AI algorithms (e.g., Codacy). </p>
        <p>There are two reasons for this. Several of these tools existed in the market for years before the recent popularity of AI. However, many position themselves as a backstop to issues found in AI-generated code. <a href="https://oreil.ly/ODAHw">Sonar</a>, for example, promises to minimize risk, ensure code quality, and derive more value from code created by both AI and humans. As the website copy states: “To maximize the advantages of generative AI in coding, developer teams need <a contenteditable="false" data-type="indexterm" data-primary="human review, code review and" data-startref="hmnrvrv" id="id355"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="human review and" data-startref="cdrvhmrv" id="id356"/><a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="human review" data-startref="aitrvwhuv" id="id357"/>robust DevOps processes, reporting, and metrics that focus on code quality, security, and reliability.”</p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Evaluation Process"><div class="sect1" id="ch03_tool_evaluation_1749441076008395">
        <h1>Evaluation Process</h1>
        <p>I evaluated more than 20 automated <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review " data-tertiary="evaluation" id="tlcdrvva"/>code-review tools in order to shortlist the ones I highlight in this chapter. Every tool covered here meets the following criteria:</p>
        <ul>
          <li>
            <p>It is a professional project with a competent team behind it.</p>
          </li>
          <li>
            <p>The code it generates has a high quality threshold.</p>
          </li>
          <li>
            <p>It offers some level of functionality for free or on a trial basis.</p>
          </li>
          <li>
            <p>It has a high level of adoption at the time of writing (mid-2025).</p>
          </li>
        </ul>
        <p>In order to select and compare AI tools for this chapter, I created a simple JavaScript program and introduced four issues into the code. You can review the full code in the book’s<a href="https://github.com/sergiopereira-io/oreilly_book"> GitHub repository</a>, inside the folder named “<a data-type="xref" href="#ch03_bug_detection_and_code_review_1749441076008122">Chapter 3</a>.” <a data-type="xref" href="#ch03_example_1_1749441076005830">Example 3-1</a> provides the most relevant snippet, with each of the four issues commented for clarity. I ran the exact same code through each of the tools reviewed in this chapter, which discusses the results each tool provided.</p>
        <div data-type="example" id="ch03_example_1_1749441076005830">
          <h5><span class="label">Example 3-1. </span>Code snippet for the tests of code-review tools</h5>
          <pre data-type="programlisting" data-code-language="javascript"><code class="nx">app</code><code class="p">.</code><code class="nx">post</code><code class="p">(</code><code class="s1">'/submit'</code><code class="p">,</code> <code class="p">(</code><code class="nx">req</code><code class="p">,</code> <code class="nx">res</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>
   <code class="kr">const</code> <code class="nx">requestData</code> <code class="o">=</code> <code class="nx">req</code><code class="p">.</code><code class="nx">body</code><code class="p">;</code>
 
   <code class="c1">// 1. SQL Injection vulnerability</code>
   <code class="kr">const</code> <code class="nx">sqlQuery</code> <code class="o">=</code> <code class="sb">`SELECT * FROM users </code>
<code class="sb">                     WHERE username = '</code><code class="si">${</code><code class="nx">requestData</code><code class="p">.</code><code class="nx">username</code><code class="si">}</code><code class="sb">'`</code><code class="p">;</code>
   <code class="nx">db</code><code class="p">.</code><code class="nx">all</code><code class="p">(</code><code class="nx">sqlQuery</code><code class="p">,</code> <code class="p">[],</code> <code class="p">(</code><code class="nx">err</code><code class="p">,</code> <code class="nx">rows</code><code class="p">)</code> <code class="o">=&gt;</code> <code class="p">{</code>
       <code class="k">if</code> <code class="p">(</code><code class="nx">err</code><code class="p">)</code> <code class="p">{</code>
           <code class="nx">console</code><code class="p">.</code><code class="nx">error</code><code class="p">(</code><code class="s1">'Error executing SQL query:'</code><code class="p">,</code> <code class="nx">err</code><code class="p">.</code><code class="nx">message</code><code class="p">);</code>
           <code class="nx">res</code><code class="p">.</code><code class="nx">status</code><code class="p">(</code><code class="mi">500</code><code class="p">).</code><code class="nx">send</code><code class="p">(</code><code class="s1">'Error in database operation'</code><code class="p">);</code>
       <code class="p">}</code> <code class="k">else</code> <code class="p">{</code>
           <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'Query result:'</code><code class="p">,</code> <code class="nx">rows</code><code class="p">);</code>
           <code class="nx">res</code><code class="p">.</code><code class="nx">send</code><code class="p">(</code><code class="s1">'Data processed with SQL query results: '</code> 
           <code class="o">+</code> <code class="nx">JSON</code><code class="p">.</code><code class="nx">stringify</code><code class="p">(</code><code class="nx">rows</code><code class="p">));</code>
       <code class="p">}</code>
   <code class="p">});</code>
 
   <code class="c1">// 2. Cross-Site Scripting (XSS) vulnerability</code>
   <code class="kr">const</code> <code class="nx">responseHtml</code> <code class="o">=</code> <code class="sb">`</code>
<code class="sb">       &lt;html&gt;</code>
<code class="sb">           &lt;body&gt;</code>
<code class="sb">               &lt;h1&gt;User Profile&lt;/h1&gt;</code>
<code class="sb">               &lt;div&gt;</code><code class="si">${</code><code class="nx">requestData</code><code class="p">.</code><code class="nx">userInput</code><code class="si">}</code><code class="sb">&lt;/div&gt; &lt;!-- User input is </code>
<code class="sb">directly rendered into HTML --&gt;</code>
<code class="sb">           &lt;/body&gt;</code>
<code class="sb">       &lt;/html&gt;</code>
<code class="sb">   `</code><code class="p">;</code>
   <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'Generated HTML for user:'</code><code class="p">,</code> <code class="nx">responseHtml</code><code class="p">);</code>
 
   <code class="c1">// 3. Potential memory leak in event listeners</code>
   <code class="kr">const</code> <code class="nx">listeners</code> <code class="o">=</code> <code class="p">[];</code>
   <code class="k">for</code> <code class="p">(</code><code class="kd">let</code> <code class="nx">i</code> <code class="o">=</code> <code class="mi">0</code><code class="p">;</code> <code class="nx">i</code> <code class="o">&lt;</code> <code class="mi">100</code><code class="p">;</code> <code class="nx">i</code><code class="o">++</code><code class="p">)</code> <code class="p">{</code>
       <code class="nx">listeners</code><code class="p">.</code><code class="nx">push</code><code class="p">(()</code> <code class="o">=&gt;</code> <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'Event listener'</code><code class="p">,</code> <code class="nx">i</code><code class="p">));</code>
   <code class="p">}</code>
   <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'Number of listeners created:'</code><code class="p">,</code> <code class="nx">listeners</code><code class="p">.</code><code class="nx">length</code><code class="p">);</code>
 
   <code class="c1">// 4. Inefficient loop</code>
   <code class="kd">let</code> <code class="nx">sum</code> <code class="o">=</code> <code class="mi">0</code><code class="p">;</code>
   <code class="k">for</code> <code class="p">(</code><code class="kd">let</code> <code class="nx">i</code> <code class="o">=</code> <code class="mi">0</code><code class="p">;</code> <code class="nx">i</code> <code class="o">&lt;</code> <code class="mi">100000</code><code class="p">;</code> <code class="nx">i</code><code class="o">++</code><code class="p">)</code> <code class="p">{</code>
       <code class="nx">sum</code> <code class="o">+=</code> <code class="nx">i</code><code class="p">;</code>
   <code class="p">}</code>
   <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="s1">'Sum of 0 to 99999:'</code><code class="p">,</code> <code class="nx">sum</code><code class="p">);</code>
<code class="p">});</code>
 </pre>
        </div>
        <p>Before we dive in, here is a brief explanation of each of the errors I introduced and why it would be important to catch them in a code review:</p>
        <dl>
          <dt>SQL injection vulnerability</dt>
          <dd>
            <p class="fix_tracking">This vulnerability arises from <a contenteditable="false" data-type="indexterm" data-primary="SQL (Structured Query Language) injection vulnerability" id="sqlijvbl"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="SQL injection vulnerability" id="id358"/>incorporating user input directly into a SQL query without any form of validation or sanitization. In the provided code, the variable <code>requestData.username</code> is directly concatenated into the SQL query string. This approach lets attackers craft user inputs that manipulate the SQL query to perform unauthorized actions, like accessing, modifying, or deleting data. For instance, an attacker could provide a username input like <code>' OR '1'='1</code>, which could alter the query logic to return all users in the system, thereby breaching data privacy.</p>
          </dd>
          <dt>Cross-site scripting </dt>
          <dd>
            <p><em>Cross-site scripting</em> (XSS) occurs when an application includes untrusted data, typically <a contenteditable="false" data-type="indexterm" data-primary="XSS (cross-site scripting)" id="id359"/><a contenteditable="false" data-type="indexterm" data-primary="cross-site scripting (XSS)" id="id360"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="XSS (cross-site scripting)" id="id361"/>from user inputs, within the content of its web pages without proper validation or escaping. In the script, <code>requestData.userInput</code> is directly included in an HTML response structure sent back to the client. If this user input includes malicious JavaScript code, the browser could execute that unauthorized script, leading to session hijacking, personal data theft, or malicious redirection.</p>
          </dd>
          <dt>Memory leak</dt>
          <dd>
            <p><em>Memory leaks</em> in web applications can occur when memory that is no <a contenteditable="false" data-type="indexterm" data-primary="memory" data-secondary="leaks" id="id362"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="memory leaks" id="id363"/>longer needed is not released back to the system. In the example, a large number of event listeners are created within a loop but are never removed. Each listener retains a closure scope that may consume more memory. Over time, especially in long-running applications like servers, these listeners accumulate, occupying an increasing amount of memory. This can potentially exhaust available resources and lead to performance degradation or crashes.</p>
          </dd>
          <dt>Inefficient loop</dt>
          <dd>
            <p>The loop in the example <a contenteditable="false" data-type="indexterm" data-primary="looping, inefficient" id="id364"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="looping, inefficient" id="id365"/>code inefficiently performs a large number of iterations to compute the sum of all integers from 0 to 99,999. Each iteration involves performing arithmetic operations and updating a local variable. Although these actions are relatively simple, they are unnecessarily repeated many times. This not only consumes CPU cycles, but it could also block the event loop in a Node.js environment, leading to delays in processing other incoming requests or <span class="keep-together">operations.</span></p>
          </dd>
        </dl>
        <p>Now let’s dive into the top-performing AI code-review tools I tried.</p>
        <section data-type="sect2" data-pdf-bookmark="Codacy"><div class="sect2" id="ch03_codacy_1749441076008451">
          <h2>Codacy</h2>
          <p><a href="https://www.codacy.com">Codacy</a> is a startup based in Portugal that launched an automated code-review tool in 2012. The product has evolved significantly over the years <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" id="tlaicdrvw"/><a contenteditable="false" data-type="indexterm" data-primary="Codacy" id="cdcyac"/>and is now a market-leading solution that leverages AI to “help developers identify and fix issues within their code, improving code quality and reducing technical debt, with support for more than 40 programming languages and seamless integrations with GitHub, Bitbucket, and GitLab,” as per the copy on its website.</p>
          <p>Codacy’s AI tool analyzes code for potential errors, style violations, security vulnerabilities, and performance issues, and it provides software engineers with suggestions for improvement. The tool is designed to learn from past reviews, adapting to the specific standards and practices of each development team.</p>
          <p>By automating the code-review process, Codacy helps developers focus more on building features rather than fixing issues, ultimately speeding up the development cycle and enhancing code maintainability.</p>
          <section data-type="sect3" data-pdf-bookmark="Practical example"><div class="sect3" id="ch03_practical_example_1749441076008500">
            <h3>Practical example</h3>
            <p>I created an account with Codacy using my GitHub account and ran the tool on the code shown earlier in this chapter (which you can review in full in the book’s <a href="https://github.com/sergiopereira-io/oreilly_book">GitHub repository</a>). </p>
            <p>Codacy correctly identified issue number 1, the SQL Injection vulnerability, and labeled its severity as “Critical,” the highest level in its ranking, as seen in <a data-type="xref" href="#ch03_figure_1_1749441076000331">Figure 3-1</a>.</p>
            <figure><div id="ch03_figure_1_1749441076000331" class="figure">
              <img src="assets/gasd_0301.png" width="600" height="204"/>
              <h6><span class="label">Figure 3-1. </span>Codacy identified the SQL injection vulnerability</h6>
            </div></figure>
            <p>Codacy provides an expandable section with an explanation of what the error is, why it’s dangerous, and how to solve it (<a data-type="xref" href="#ch03_figure_2_1749441076000361">Figure 3-2</a>).</p>
            <figure><div id="ch03_figure_2_1749441076000361" class="figure">
              <img src="assets/gasd_0302.png" width="600" height="181"/>
              <h6><span class="label">Figure 3-2. </span>Codacy explained the SQL injection vulnerability</h6>
            </div></figure>
            <p class="pagebreak-before less_space">Codacy also correctly identified issue 2, the XSS vulnerability, and labeled it as “Medium” severity (Figures <a data-type="xref" data-xrefstyle="select:labelnumber" href="#ch03_figure_3_1749441076000379">3-3</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="#ch03_figure_4_1749441076000395">3-4</a>).</p>
            <figure><div id="ch03_figure_3_1749441076000379" class="figure">
              <img src="assets/gasd_0303.png" width="600" height="91"/>
              <h6><span class="label">Figure 3-3. </span>Codacy identified the XSS vulnerability</h6>
            </div></figure>
            <p>As seen in <a data-type="xref" href="#ch03_figure_4_1749441076000395">Figure 3-4</a>, Codacy clearly explained this XSS vulnerability.</p>
            <figure><div id="ch03_figure_4_1749441076000395" class="figure">
              <img src="assets/gasd_0304.png" width="600" height="173"/>
              <h6><span class="label">Figure 3-4. </span>Codacy explained the XSS vulnerability</h6>
            </div></figure>
            <p>Codacy’s analysis didn’t identify issues 3 and 4, which are more related to performance than to security.</p>
            <p>All of this feedback was provided on Codacy’s website immediately after I connected my GitHub account and selected the repository I wanted to have analyzed. However, after I opened a PR on that same repository, Codacy performed a second level of analysis directly in the repository. </p>
            <p>Most of the errors it identified reiterate those it found in the previous analysis, which I expected, since the code is the same. However, on GitHub, Codacy also offers a “commit suggestion” to fix each issue along with a brief explanation. This makes it very convenient for software engineers to simply accept the suggestion and merge the PR with one click (<a data-type="xref" href="#ch03_figure_5_1749441076000410">Figure 3-5</a>).</p>
            <figure><div id="ch03_figure_5_1749441076000410" class="figure">
              <img src="assets/gasd_0305.png" width="600" height="513"/>
              <h6><span class="label">Figure 3-5. </span>Codacy suggested a fix for the issue it found</h6>
            </div></figure>
            <p>For all these reasons, I rate Codacy’s tool an 8/10. It found two of two security issues, but it didn’t find either of the two performance issues. For the issues it did find, it offered very comprehensive explanations and proposed fixes that could be <a contenteditable="false" data-type="indexterm" data-primary="Codacy" data-startref="cdcyac" id="id366"/>accepted in the actual repository with one click.</p>
          </div></section>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="DeepCode (by Snyk)"><div class="sect2" id="ch03_deepcode_by_snyk_1749441076008558">
          <h2>DeepCode (by Snyk)</h2>
          <p><a href="https://oreil.ly/VBZWA">DeepCode</a> began as an independent startup based in Zurich, Switzerland, as a spinoff from ETH Zurich University.<sup><a data-type="noteref" id="id367-marker" href="ch03.html#id367">1</a></sup> It was acquired by the cybersecurity behemoth Snyk in September 2020.<sup><a data-type="noteref" id="id368-marker" href="ch03.html#id368">2</a></sup> Since then, the product was marketed first as “DeepCode by Snyk” and more recently as “DeepCode AI,” and has been integrated into Snyk’s broader suite of products and services.</p>
          <p>As Snyk <a href="https://oreil.ly/jdWJl">described it</a> in 2020, DeepCode includes “sophisticated interpretable machine learning semantic code analysis. The technology scans code 10–50x faster than alternatives, enabling real-time workflows within the development process, and dramatically reduces both false negatives and false positives using a custom machine learning platform that is able to quickly learn from huge volumes of code.”</p>
          <p>DeepCode uses machine learning algorithms to learn from millions of publicly available open source software-development repositories. This large dataset allows DeepCode to provide highly accurate suggestions and find potential issues that human reviewers might overlook.</p>
          <p>DeepCode can be used on an IDE or directly in a Git repository. It points out security vulnerabilities on the spot, as alerts in the IDE tool tip or as comments to the pull request in the repository. As the company’s <a href="https://oreil.ly/VBZWA">website</a> puts it: </p>
          <blockquote>
            <p>It combines symbolic and generative AI, multiple machine learning methods, and the expertise of top security researchers to offer accurate vulnerability detection and tech debt management. DeepCode AI is purpose-built for security, supporting 11 languages and over 25 million data flow cases to find and fix vulnerabilities efficiently. This AI technology enhances developer productivity by offering one-click security fixes and comprehensive app coverage while ensuring the trustworthiness of the AI through training data from millions of open-source projects. DeepCode AI stands out for its hybrid approach using multiple models and security-specific training sets to secure applications effectively.</p>
          </blockquote>
          <section data-type="sect3" data-pdf-bookmark="Practical example"><div class="sect3" id="ch03_practical_example_1749441076008610">
            <h3>Practical example</h3>
            <p>Just like I did for Codacy, I created an account with Snyk/DeepCode using my GitHub account and ran it on the code in <a data-type="xref" href="#ch03_example_1_1749441076005830">Example 3-1</a> within the book’s repository. </p>
            <p>DeepCode correctly identified issue 1, the SQL injection vulnerability, and labeled it with “H” (High), the highest level in its ranking system. It even provides a score (<a data-type="xref" href="#ch03_figure_6_1749441076000425">Figure 3-6</a>), though I could not find specific information about what this score means. This issue’s score of 830 is the highest score received by my code. </p>
            <figure><div id="ch03_figure_6_1749441076000425" class="figure">
              <img src="assets/gasd_0306.png" width="600" height="286"/>
              <h6><span class="label">Figure 3-6. </span>DeepCode identified the SQL injection vulnerability</h6>
            </div></figure>
            <p>Snyk/DeepCode provides two expandable sections for each error. One provides a deeper explanation of the issue, resembling a stack trace rendered in the browser UI (<a data-type="xref" href="#ch03_figure_7_1749441076000440">Figure 3-7</a>).</p>
            <figure><div id="ch03_figure_7_1749441076000440" class="figure">
              <img src="assets/gasd_0307.png" width="600" height="384"/>
              <h6><span class="label">Figure 3-7. </span>DeepCode explained the SQL injection vulnerability</h6>
            </div></figure>
            <p>The second expandable section suggests a fix for the issue (<a data-type="xref" href="#ch03_figure_8_1749441076000457">Figure 3-8</a>) and gives pointers to avoid using concatenated SQL statements as strings stored directly from user-entered parameters. This is a best practice in defensive programming.</p>
            <figure><div id="ch03_figure_8_1749441076000457" class="figure">
              <img src="assets/gasd_0308.png" width="600" height="384"/>
              <h6><span class="label">Figure 3-8. </span>DeepCode suggested a fix for the SQL injection vulnerability</h6>
            </div></figure>
            <p>These suggestions are provided “as is” from an open source repository in the training dataset. This is very nice in terms of transparency, as a software engineer should always want to know where the code comes from. However, it adds some extra cognitive load in terms of actually solving the problem, since this is just a proposed solution to help the software developer fix the issue, not an actual proposed solution to be adopted with the click of a button.</p>
            <p>Despite this deep level of detail for issue 1, DeepCode didn’t find issues 2, 3, or 4. It did find some lower-severity issues in some libraries I used (inside <code>node_modules</code>), which were irrelevant to this book’s exercise.</p>
            <p>I rate DeepCode a 6/10. It found one of two security issues and didn’t find either of the performance issues. For those issues it found, it provided very comprehensive explanations; however, the help it offers for each issue is lacking in comparison to that offered by Codacy and CodeRabbit. DeepCode provides information about <a contenteditable="false" data-type="indexterm" data-primary="DeepCode (Snyk)" data-startref="dpcdsky" id="id369"/><a contenteditable="false" data-type="indexterm" data-primary="SQL (Structured Query Language) injection vulnerability" data-startref="sqlijvbl" id="id370"/>the issue, but it doesn’t offer proposed solutions that are easy to adopt with one click.</p>
          </div></section>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="CodeRabbit"><div class="sect2" id="ch03_coderabbit_1749441076008657">
          <h2>CodeRabbit</h2>
          <p><a href="https://coderabbit.ai">CodeRabbit</a> is an automated code-review platform launched in September 2023, amid the <a contenteditable="false" data-type="indexterm" data-primary="CodeRabbit" id="cdrbbt"/>generative AI buzz. It gained significant popularity very fast, especially on Twitter/X as some tech influencers did thorough reviews of the product and promoted it in their networks (here’s one <a href="https://oreil.ly/m9rjn">example</a>). The official number of CodeRabbit users had not been publicly disclosed at the time of writing (mid-2025).</p>
          <p>CodeRabbit leverages AI capabilities to enhance the quality, performance, and efficiency of code reviews. It delivers its code recommendations through comments in the repository.</p>
          <section data-type="sect3" data-pdf-bookmark="Practical example"><div class="sect3" id="ch03_practical_example_1749441076008704">
            <h3>Practical example</h3>
            <p>Like I did for the other tools, I created an account with CodeRabbit, allowed it access to my GitHub account, and selected the repository I wanted to give it access to. Unlike Codacy and DeepCode, CodeRabbit won’t statically analyze code that’s already in a repository. Instead, I needed to open a pull request; CodeRabbit then posted comments to that PR with its code-review items and suggestions. CodeRabbit promotes this as a much more interactive tool that aims to mimic a team member commenting on a PR seconds after it’s opened on GitHub. However, my experience on CodeRabbit’s website was greatly inferior to my experiences with the competitors analyzed here.</p>
            <p>CodeRabbit correctly identified issue 1, the SQL Injection vulnerability (<a data-type="xref" href="#ch03_figure_9_1749441076000472">Figure 3-9</a>). It doesn’t provide any indication of severity level: all issues it reports look alike in that regard. It did a good job pointing out the faulty code snippet and offered a brief explanation about why it contains a vulnerability. I believe most software engineers will enjoy this simple UI, since it’s exactly the type of interaction they get from human colleagues who review their PR.</p>
            <figure><div id="ch03_figure_9_1749441076000472" class="figure">
              <img src="assets/gasd_0309.png" width="600" height="447"/>
              <h6><span class="label">Figure 3-9. </span>CodeRabbit identified the SQL injection vulnerability</h6>
            </div></figure>
            <p>Along with the explanation, CodeRabbit offers an expandable section called “Committable suggestion” that contains a suggested fix for the issue (<a data-type="xref" href="#ch03_figure_10_1749441076000488">Figure 3-10</a>). While CodeRabbit displays a noticeable warning to review the offered solution thoroughly, committing it is only one convenient click away.</p>
            <figure><div id="ch03_figure_10_1749441076000488" class="figure">
              <img src="assets/gasd_0310.png" width="600" height="609"/>
              <h6><span class="label">Figure 3-10. </span>CodeRabbit suggested a fix</h6>
            </div></figure>
            <p>CodeRabbit also detected issue 2, the XSS vulnerability (<a data-type="xref" href="#ch03_figure_11_1749441076000502">Figure 3-11</a>), but just like the other tools analyzed, CodeRabbit didn’t find performance issues 3 and 4.</p>
            <figure><div id="ch03_figure_11_1749441076000502" class="figure">
              <img src="assets/gasd_0311.png" width="600" height="334"/>
              <h6><span class="label">Figure 3-11. </span>CodeRabbit identified the XSS vulnerability</h6>
            </div></figure>
            <p>Thus, I rate CodeRabbit a 7/10. It found both security issues but neither of the performance issues. It also proposed a solution for one of the issues it found, but not the other one. However, its explanation for the issues was very superficial compared to the other two tools. Finally, it lacks a website interface that would let users research issues in more depth and provide some historical perspective of changes and <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review " data-tertiary="evaluation" data-startref="tlcdrvva" id="id371"/><a contenteditable="false" data-type="indexterm" data-primary="CodeRabbit" data-startref="cdrbbt" id="id372"/>improvements made on the codebase, which the other tools have.</p>
          </div></section>
        </div></section>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Tool Comparison"><div class="sect1" id="ch03_tool_comparison_1749441076008751">
        <h1>Tool Comparison</h1>
        <p>All three of these AI code-review tools take <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="comparison" id="aitcdrvmp"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="tool comparison" id="crvwtcps"/>different approaches to blocking my pull request from being merged, as shown in <a data-type="xref" href="#ch03_figure_12_1749441076000520">Figure 3-12</a>:</p>
        <ul>
          <li>
            <p>Codacy blocks the PR merge until I fix the issues it identified (which, to be fair, I can do using its suggested fixes).</p>
          </li>
          <li>
            <p>Snyk/DeepCode doesn’t block the PR merge, despite the issues found.</p>
          </li>
          <li>
            <p>CodeRabbit only posts comments; it doesn’t run actual checks, and thus it would never block a PR merge regardless of any issues it finds.</p>
          </li>
        </ul>
        <figure><div id="ch03_figure_12_1749441076000520" class="figure">
          <img src="assets/gasd_0312.png" width="600" height="338"/>
          <h6><span class="label">Figure 3-12. </span>Codacy and Snyk/DeepCode show up in the checks section for the PR merge</h6>
        </div></figure>
        <p>If I were to select a single tool, Codacy would be <a contenteditable="false" data-type="indexterm" data-primary="tools" data-secondary="code review" data-tertiary="comparison" data-startref="aitcdrvmp" id="id373"/><a contenteditable="false" data-type="indexterm" data-primary="code review" data-secondary="tool comparison" data-startref="crvwtcps" id="id374"/>my go-to tool. As <a data-type="xref" href="#ch03_table_1_1749441076002736">Table 3-1</a> indicates, it had the highest score.</p>
        <table id="ch03_table_1_1749441076002736" class="striped">
          <caption><span class="label">Table 3-1. </span>AI code-review tools overview</caption>
          <thead>
            <tr>
              <th>Tool</th>
              <th>UX</th>
              <th>Test performance</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Codacy</td>
              <td>Browser + Repository</td>
              <td>8/10</td>
            </tr>
            <tr>
              <td>Snyk/DeepCode</td>
              <td>Browser + Repository</td>
              <td>6/10</td>
            </tr>
            <tr>
              <td>CodeRabbit</td>
              <td>Repository</td>
              <td>7/10</td>
            </tr>
          </tbody>
        </table>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="ch03_conclusion_1749441076008796">
        <h1>Conclusion</h1>
        <p>Code reviews have been one of the biggest frustrations in my software development teams over the years. People are naturally more inclined to pick up new tasks assigned to them than to stop their own thread of work to review a colleague’s PR. This default behavior has delayed features from being moved to QA and ultimately going live. It has also created situations where we fast-track some urgent features even with a less-than-ideal level of code review, resulting in bugs showing up in production. In general, the biggest casualty of these common code-review frustrations is team morale, with team members feeling like they’re constantly switching context and losing focus.</p>
        <p>I began using several forms of automated code review in my teams, like linters, static code analysis, and test coverage dashboards, long before the recent generative AI hype. Any team with robust engineering standards has probably done likewise.</p>
        <p>However, after 15 years in the industry, I can tell that the recent wave of evolution adds more depth to these tools—especially the seamless way they integrate with your software development workflow, and the option to accept suggested fixes with one click. Having a very capable code reviewer who’s available 24/7 to provide thoughtful feedback on issues in your code is a massive help to anyone. It’s something I could only have dreamed of when I started out as a software engineer myself.</p>
        <p>However, I believe that software engineers should leverage these tools as learning opportunities before anything else. They can and do make mistakes, as the tools themselves note in very visible warnings, and I can only underline that. <em>Always</em> have a human being review and test the suggested fixes. As with code-generation tools, I recommend a high level of diligence when reviewing any code or fixes suggested by these tools. Make it yours before you open a PR or merge to master.</p>
      </div></section>
    <div data-type="footnotes"><p data-type="footnote" id="id367"><sup><a href="ch03.html#id367-marker">1</a></sup> This book’s <a contenteditable="false" data-type="indexterm" data-primary="DeepCode (Snyk)" id="dpcdsky"/>author was part of the DeepCode team prior to the company’s acquisition by Snyk, but has no contractual relationship, equity, or any other vested interest in DeepCode at the time of writing. </p><p data-type="footnote" id="id368"><sup><a href="ch03.html#id368-marker">2</a></sup> McKay, Peter. September 23, 2020. <a href="https://oreil.ly/jdWJl">“Accelerating Our Developer-First Vision with DeepCode”</a>. <em>Snyk</em> (blog).</p></div></div></section></div></div></body></html>