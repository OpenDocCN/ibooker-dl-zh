<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 6. Autonomous Agents with &#10;Memory and Tools"><div class="chapter" id="autonomous_agents_06">
<h1><span class="label">Chapter 6. </span>Autonomous Agents with 
<span class="keep-together">Memory and Tools</span></h1>


<p>This chapter dives deeper into the importance of chain-of-thought reasoning and the ability of large language models (LLMs) to reason through complex problems as agents. By breaking down complex problems into smaller, more manageable components, LLMs can provide more thorough and effective solutions. You will also learn about the components that make up autonomous agents, such as inputs, goal or reward functions, and available actions.</p>






<section data-type="sect1" data-pdf-bookmark="Chain-of-Thought"><div class="sect1" id="id93">
<h1>Chain-of-Thought</h1>

<p>The ability of AI to reason through complex problems is essential for creating effective, reliable, and user-friendly applications.</p>

<p><em>Chain-of-thought reasoning</em> (CoT) is a method <a data-type="indexterm" data-primary="CoT (chain-of-thought)" id="cotchhgh"/>of guiding LLMs through a series of steps or logical connections to reach a conclusion or solve a problem. This approach is particularly useful for tasks that require a deeper understanding of context or multiple factors to consider.</p>

<p><a href="https://oreil.ly/fAeLo">CoT</a> is asking an LLM to <em>think</em> through complex problems, breaking them down into smaller, more manageable components. This allows the LLM to focus on each part individually, ensuring a more thorough understanding of the issue at hand.</p>

<p>In practice, chain-of-thought reasoning might involve:</p>

<ul>
<li>
<p>Asking an LLM to provide explanations for its decisions</p>
</li>
<li>
<p>Planning multiple steps before deciding on a final answer</p>
</li>
</ul>

<p>In the following sections, you’ll explore examples of both ineffective and effective chain-of-thought reasoning. We will also discuss various techniques for building effective chain-of-thought reasoning and how they can be integrated into AI <span class="keep-together">applications.</span></p>

<p>Let’s imagine that a user wants the AI to generate a comprehensive marketing plan for promoting a new software product.</p>

<p>Input:</p>

<pre data-type="programlisting">Create a marketing plan for a new software product.</pre>

<p>Output:</p>

<pre data-type="programlisting">1. Launch social media campaign
2. Send out email newsletters
3. Offer limited-time discounts
4. Collaborate with influencers
5. Organize webinars</pre>

<p>In this example, GPT-4 doesn’t use chain-of-thought reasoning, and it does not address the specific aspects of the marketing plan. The LLM generates a generic list of marketing strategies that could apply to any product, rather than focusing on the unique characteristics of the new software product.</p>

<p>Input:</p>

<pre data-type="programlisting">Create a detailed marketing plan for a new project management software
product targeting small and medium-sized businesses.

The budget is $20,000, and we want to focus on digital marketing channels.

Consider the success of similar products in the market and provide a
step-by-step plan that includes the most effective promotional tactics.</pre>

<p>Output:</p>

<pre data-type="programlisting">Market Research
a. Analyze competitors and their marketing strategies
b. Identify the unique selling points of the new project management software
c. Define the target audience and their pain points

Branding and Messaging
a. Develop a consistent brand identity
b. Craft compelling messaging that addresses the target audience's pain
points
c. Create marketing assets such as website, blog, and social media content

...

Email Marketing
a. Develop an email marketing strategy to nurture leads and convert them
into customers
b. Send personalized onboarding emails to new users with helpful tips and
resources</pre>

<p>Now GPT-4 specifically addresses the unique characteristics of the new software product, demonstrating effective chain-of-thought reasoning.</p>
<div data-type="tip"><h1>Give Direction</h1>
<p>Take note of the phrase <em>step-by-step</em>, a critical <a data-type="indexterm" data-primary="Give Direction principle" data-secondary="CoT (chain-of-thought)" id="id1023"/>element in CoT. By incorporating this phrase into your prompt, you’re asking the LLM to reason through the steps that are required to generate a highly effective software product.</p>

<p>Also, by providing a $20,000 budget and the type <a data-type="indexterm" data-primary="CoT (chain-of-thought)" data-startref="cotchhgh" id="id1024"/>of software, GPT-4 is able to provide a much more relevant and contextualized response.</p>
</div>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Agents"><div class="sect1" id="id94">
<h1>Agents</h1>

<p>Generative AI models have <a data-type="indexterm" data-primary="agent-based architecture" id="id1025"/>given rise to an <em>agent-based architecture</em>. Conceptually, an agent acts, perceives, and makes decisions within a specified environment to achieve predefined objectives.</p>

<p>Agents can take various actions such as executing a Python function; afterward, the agent will observe what happens and will decide on whether it is finished or what action to take next.</p>

<p>The agent will continously loop through a <a data-type="indexterm" data-primary="loops" data-secondary="agents" id="id1026"/><a data-type="indexterm" data-primary="agents" data-secondary="loops" id="id1027"/>series of actions and observations until there are no further actions, as you can see in the following pseudocode:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">next_action</code> <code class="o">=</code> <code class="n">agent</code><code class="o">.</code><code class="n">get_action</code><code class="p">(</code><code class="o">...</code><code class="p">)</code>
<code class="k">while</code> <code class="n">next_action</code> <code class="o">!=</code> <code class="n">AgentFinish</code><code class="p">:</code>
    <code class="n">observation</code> <code class="o">=</code> <code class="n">run</code><code class="p">(</code><code class="n">next_action</code><code class="p">)</code>
    <code class="n">next_action</code> <code class="o">=</code> <code class="n">agent</code><code class="o">.</code><code class="n">get_action</code><code class="p">(</code><code class="o">...</code><code class="p">,</code> <code class="n">next_action</code><code class="p">,</code> <code class="n">observation</code><code class="p">)</code>
<code class="k">return</code> <code class="n">next_action</code></pre>

<p>The behavior of the agent is governed by three principal components:</p>
<dl>
<dt>Inputs</dt>
<dd>
<p>These are the sensory stimuli or <a data-type="indexterm" data-primary="agents" data-secondary="inputs and" id="id1028"/>data points the agent receives from its environment. Inputs can be diverse, ranging from visual (like images) and auditory (like audio files) to thermal signals and beyond.</p>
</dd>
<dt>Goal or reward function</dt>
<dd>
<p>This represents the <a data-type="indexterm" data-primary="agents" data-secondary="goal function" id="id1029"/>guiding principle for an agent’s actions. In goal-based frameworks, the agent is tasked with reaching a specific end state. In a reward-based setting, the agent is driven to maximize cumulative rewards over time, often in dynamic environments.</p>
</dd>
<dt>Available actions</dt>
<dd>
<p>The <em>action space</em> is the range of <a data-type="indexterm" data-primary="agents" data-secondary="action space" id="id1030"/>permissible actions an agent <a href="https://oreil.ly/5AVfM">can undertake at any given moment</a>. The breadth and nature of this space are contingent upon the task at hand.</p>
</dd>
</dl>

<p>To explain these concepts further, consider a self-driving car:</p>
<dl>
<dt>Inputs</dt>
<dd>
<p>The car’s sensors, such as cameras, LIDAR, and ultrasonic sensors, provide a continuous stream of data about the environment. This can include information about nearby vehicles, pedestrians, road conditions, and traffic signals.</p>
</dd>
<dt>Goal or reward function</dt>
<dd>
<p>The primary goal for a self-driving car is safe and efficient navigation from point A to point B. If we were to use a reward-based system, the car might receive positive rewards for maintaining a safe distance from other objects, adhering to speed limits, and following traffic rules. Conversely, it could receive negative rewards for risky behaviors, like hard braking or veering off the lane. Tesla specifically uses miles driven without an intervention as their reward function.</p>
</dd>
<dt>Available actions</dt>
<dd>
<p>The car’s action space includes accelerating, decelerating, turning, changing lanes, and more. Each action is chosen based on the current input data and the objective defined by the goal or reward function.</p>
</dd>
</dl>

<p>You’ll find that agents in systems like self-driving cars rely on foundational principles like inputs, goal/reward functions, and available actions. However, when delving into the realm of LLMs like GPT, there’s a bespoke set of dynamics that cater specifically to their unique nature.</p>

<p>Here’s how they align with your needs:</p>
<dl>
<dt>Inputs</dt>
<dd>
<p>For LLMs, the gateway is primarily through text. But that doesn’t restrain the wealth of information you can use. Whether you’re dealing with thermal readings, musical notations, or intricate data structures, your challenge lies in molding these into textual representations suitable for an LLM. Think about videos: while raw footage might seem incompatible, video text transcriptions allow an LLM to extract insights for you.</p>
</dd>
<dt>Harnessing goal-driven directives</dt>
<dd>
<p>LLMs primarily use goals defined within your text prompts. By creating effective prompts with objectives, you’re not just accessing the LLM’s vast knowledge; you’re effectively charting its reasoning path. Think of it as laying down a blueprint: your specific prompt instructs the model, guiding it to dissect your overarching objective into a systematic sequence of steps.</p>
</dd>
<dt>Crafting action through functional tools</dt>
<dd>
<p>LLMs are not limited to mere text generation; there’s so much more you can <a data-type="indexterm" data-primary="agents" data-secondary="ready-made tools" id="id1031"/><a data-type="indexterm" data-primary="agents" data-secondary="custom developed tools" id="id1032"/>achieve. By integrating <em>ready-made tools</em> or <em>custom-developed tools</em>, you can equip LLMs to undertake diverse tasks, from API calls to database engagements or even orchestrating external systems. Tools can be written in any programming language, and by adding more tools you are effectively <em>expanding the action space</em> of what an LLM can achieve.</p>
</dd>
</dl>

<p>There are also different components that are directly applicable to LLMs:</p>
<dl>
<dt>Memory</dt>
<dd>
<p>It’s ideal to store state between <a data-type="indexterm" data-primary="agents" data-secondary="memory and" id="id1033"/><a data-type="indexterm" data-primary="memory" data-secondary="agents and" id="id1034"/>agent steps; this is particularly useful for chatbots, where remembering the previous chat history provides a better user experience.</p>
</dd>
<dt>Agent planning/execution strategies</dt>
<dd>
<p>There are <a data-type="indexterm" data-primary="agents" data-secondary="planning/execution strategies" id="id1035"/>multiple ways to achieve a high-level goal, of which a mixture of planning and executing is essential.</p>
</dd>
<dt>Retrieval</dt>
<dd>
<p>LLMs can use different types of retrieval methods. Semantic similarity within vector databases is the most common, but there are others such as including custom information from a SQL database into prompts.</p>
</dd>
</dl>

<p>Let’s dive deeper into the shared and different components and explore the implementation details.</p>








<section data-type="sect2" data-pdf-bookmark="Reason and Act (ReAct)"><div class="sect2" id="id95">
<h2>Reason and Act (ReAct)</h2>

<p>There are many agent frameworks that <a data-type="indexterm" data-primary="agents" data-secondary="ReAct (Reason and Act)" id="agrara"/><a data-type="indexterm" data-primary="ReAct (Reason and Act) framework" id="rcarsamw"/>ultimately aim to improve LLM responses toward a goal. The original framework was <em>ReAct</em>, which is an improved version of CoT, allowing an LLM to create observations after taking actions via tools. These observations are then turned into <em>thoughts</em> about what would be the <em>right tool</em> to use within the next step (<a data-type="xref" href="#fig-6-1">Figure 6-1</a>). The LLM continues to reason until either a <code>'Final Answer'</code> string value is present or a maximum number of iterations has taken place.</p>

<figure><div id="fig-6-1" class="figure">
<img src="assets/pega_0601.png" alt="The ReAct Framework" width="600" height="174"/>
<h6><span class="label">Figure 6-1. </span>The ReAct framework</h6>
</div></figure>

<p>The <a href="https://oreil.ly/ssdnL">ReAct</a> framework uses a mixture of task decomposition, a thought loop, and multiple tools to solve questions. Let’s explore the thought loop within ReAct:</p>
<ol>
<li>
<p>Observe the environment.</p>
</li>
<li>
<p>Interpret the environment with a thought.</p>
</li>
<li>
<p>Decide on an action.</p>
</li>
<li>
<p>Act on the environment.</p>
</li>
<li>
<p>Repeat steps 1–4 until you find a solution or you’ve done too many iterations (the solution is “I’ve found the answer”).</p>
</li>

</ol>

<p>You can easily create a ReAct-style prompt by using the preceding thought loop while also providing the LLM with several inputs such as:</p>

<ul>
<li>
<p><code>{question}</code>: The query that you want answered.</p>
</li>
<li>
<p><code>{tools}</code>: These refer to functions that can be used to accomplish a step within the overall task. It is common practice to include a list of tools where each tool is a Python function, a name, and a description of the function and its purpose.</p>
</li>
</ul>

<p>The following is a prompt that implements the ReAct pattern with prompt variables wrapped in <code>{}</code> characters such as <code>{question}</code>:</p>

<pre data-type="programlisting">You will attempt to solve the problem of finding the answer to a question.
Use chain-of-thought reasoning to solve through the problem, using the
following pattern:

1. Observe the original question:
original_question: original_problem_text
2. Create an observation with the following pattern:
observation: observation_text
3. Create a thought based on the observation with the following pattern:
thought: thought_text
4. Use tools to act on the thought with the following pattern:
action: tool_name
action_input: tool_input

Do not guess or assume the tool results. Instead, provide a structured
output that includes the action and action_input.

You have access to the following tools: {tools}.

original_problem: {question}

Based on the provided tool result:

Either provide the next observation, action, action_input, or the final
answer if available.

If you are providing the final answer, you must return the following pattern:
"I've found the answer: final_answer"</pre>

<p>Here is a breakdown of the prompt:</p>
<ol>
<li>
<p>The introduction of the prompt clearly establishes the LLM’s purpose: <code>You will attempt to solve the problem of finding the answer to a question.</code></p>
</li>
<li>
<p>The problem-solving approach is then outlined: <code>Use chain-of-thought <span class="keep-together">reasoning</span> to solve through the problem, using the following pattern:</code></p>
</li>
<li>
<p>The steps in the chain-of-thought <a data-type="indexterm" data-primary="CoT (chain-of-thought)" id="id1036"/>reasoning are then laid out:</p>

<ul>
<li>
<p>The LLM starts by observing the original question and subsequently formulates an observation about it: <code>original_question: original_problem_text</code>, <code>observation: observation_text</code>.</p>
</li>
<li>
<p>Based on this observation, the AI should formulate a thought that signifies a step in the reasoning process: <code>thought: thought_text</code>.</p>
</li>
<li>
<p>Having established a thought, it then decides on an action using one of the available tools: <code>action: tool_name</code>, <code>action_input: tool_input</code>.</p>
</li>
</ul>
</li>
<li>
<p>The LLM is then reminded not to make assumptions about what a tool might return, and it should explicitly outline its intended action and the corresponding input.</p>
</li>
<li>
<p><code>You have access to the following tools: {tools}</code> communicates to the LLM what tools it has available for solving the problem.</p>
</li>
<li>
<p>The actual problem that the LLM must solve is then introduced: <code>original_​problem: {question}</code>.</p>
</li>
<li>
<p>Finally, instructions are provided on how the LLM should respond based on the results of its actions. It can either continue with new observations, actions, and inputs or, if a solution is found, provide the final answer.</p>
</li>

</ol>

<p>The prompt outlines a systematic problem-solving process in which the LLM observes a problem, thinks about it, decides on <a data-type="indexterm" data-primary="agents" data-secondary="ReAct (Reason and Act)" data-startref="agrara" id="id1037"/><a data-type="indexterm" data-primary="ReAct (Reason and Act) framework" data-startref="rcarsamw" id="id1038"/>an action, and repeats this process until a solution is discovered.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Reason and Act Implementation"><div class="sect2" id="id168">
<h2>Reason and Act Implementation</h2>

<p>Now that you’re aware of ReAct, it’s important <a data-type="indexterm" data-primary="agents" data-secondary="ReAct (Reason and Act)" data-tertiary="implementation" id="garcrapmt"/><a data-type="indexterm" data-primary="ReAct (Reason and Act) framework" data-secondary="implementation" id="rarfwkpm"/>to create a simple Python implementation that replicates what LangChain does automatically, allowing you to build the intuition about what’s truly happening between the LLM responses.</p>

<p>To keep it simple, this example will not implement looping and will assume that the output can be obtained from a single tool call.</p>

<p class="pagebreak-before">To create a basic ReAct implementation, you’ll implement the following:</p>
<ol>
<li>
<p>At every thought, you need to extract the tool that the LLM wants to use. Therefore, you’ll extract the last <code>action</code> and <code>action_input</code>. The <code>action</code> represents the tool name, while the <code>action_input</code> consists of the values of the function arguments.</p>
</li>
<li>
<p>Check whether the LLM thinks that it has found the final answer, in which case the thought loop has ended.</p>
</li>

</ol>

<p>You can use regular expressions to extract the <code>action</code> and <code>action_input</code> values from the LLM response:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">re</code>

<code class="c1"># Sample text:</code>
<code class="n">text</code> <code class="o">=</code> <code class="s2">"""</code>
<code class="s2">Action: search_on_google</code>
<code class="s2">Action_Input: Tom Hanks's current wife</code>

<code class="s2">action: search_on_wikipedia</code>
<code class="s2">action_input: How old is Rita Wilson in 2023</code>

<code class="s2">action : search_on_google</code>
<code class="s2">action input: some other query</code>
<code class="s2">"""</code>

<code class="c1"># Compile regex patterns:</code>
<code class="n">action_pattern</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="sa">r</code><code class="s2">"(?i)action\s*:\s*([^\n]+)"</code><code class="p">,</code> <code class="n">re</code><code class="o">.</code><code class="n">MULTILINE</code><code class="p">)</code>
<code class="n">action_input_pattern</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="sa">r</code><code class="s2">"(?i)action\s*_*input\s*:\s*([^\n]+)"</code><code class="p">,</code>
<code class="n">re</code><code class="o">.</code><code class="n">MULTILINE</code><code class="p">)</code>

<code class="c1"># Find all occurrences of action and action_input:</code>
<code class="n">actions</code> <code class="o">=</code> <code class="n">action_pattern</code><code class="o">.</code><code class="n">findall</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="n">action_inputs</code> <code class="o">=</code> <code class="n">action_input_pattern</code><code class="o">.</code><code class="n">findall</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>

<code class="c1"># Extract the last occurrence of action and action_input:</code>
<code class="n">last_action</code> <code class="o">=</code> <code class="n">actions</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code> <code class="k">if</code> <code class="n">actions</code> <code class="k">else</code> <code class="kc">None</code>
<code class="n">last_action_input</code> <code class="o">=</code> <code class="n">action_inputs</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code> <code class="k">if</code> <code class="n">action_inputs</code> <code class="k">else</code> <code class="kc">None</code>

<code class="nb">print</code><code class="p">(</code><code class="s2">"Last Action:"</code><code class="p">,</code> <code class="n">last_action</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="s2">"Last Action Input:"</code><code class="p">,</code> <code class="n">last_action_input</code><code class="p">)</code>
<code class="c1"># Last Action: search_on_google</code>
<code class="c1"># Last Action Input: some other query</code></pre>

<p>Let’s break down the regular expression to extract the <code>action</code>:</p>

<ul>
<li>
<p><code>action_pattern = re.compile(r"(?i)action\s*:\s*([^\n]+)", re.MULTILINE)</code></p>
</li>
<li>
<p><code>(?i)</code>: This is called an <em>inline flag</em> and makes <a data-type="indexterm" data-primary="regular expressions" data-secondary="extracting agent" id="rgxpxg"/>the regex pattern case-insensitive. It means that the pattern will match “action,” “Action,” “ACTION,” or any other combination of uppercase and lowercase letters.</p>
</li>
<li>
<p><code>action</code>: This part of the pattern matches the word <em>action</em> literally. Due to the case-insensitive flag, it will match any capitalization of the word.</p>
</li>
<li>
<p><code>\s*</code>: This part of the pattern matches zero or more whitespace characters (spaces, tabs, etc.). The <code>\*</code> means <em>zero or more</em>, and <code>\s</code> is the regex shorthand for a whitespace character.</p>
</li>
<li>
<p><code>:</code> This part of the pattern matches the colon character literally.</p>
</li>
<li>
<p><code>\s*</code>: This is the same as the previous <code>\s\*</code> part, matching zero or more whitespace characters after the colon.</p>
</li>
<li>
<p><code>+([^\n]++)</code>: This pattern is a capturing group, denoted by the parentheses. It matches one or more characters that are <em>not a newline character</em>. The <code>^</code> inside the square brackets <code>[]</code> negates the character class, and <code>\n</code> represents the newline character. The <code>+</code> means <em>one or more</em>. The text matched by this group will be extracted when using the <code>findall()</code> function.</p>
</li>
<li>
<p><code>re.MULTILINE</code>: This is a flag passed to <code>re.compile()</code> function. It tells the regex engine that the input text may have multiple lines, so the pattern should be applied line by line.</p>
</li>
<li>
<p>In regular expressions, square brackets <code>[]</code> are used to define a character class, which is a set of characters that you want to match. For example, <code>[abc]</code> would match any single character that is either <code>'a'</code>, <code>'b'</code>, or <code>'c'</code>.</p>
</li>
<li>
<p>When you add a caret <code>^</code> at the beginning of the character class, it negates the character class, meaning it will match any character that is <em>not in the character class</em>. In other words, it inverts the set of characters you want to match.</p>
</li>
<li>
<p>So, when we use <code>[^abc]</code>, it will match any single character that is <em>not</em> <code>'a'</code>, <code>'b'</code>, or <code>'c'</code>. In the regex pattern <code>+([^\n]++)</code>, the character class is <code>[^n]</code>, which means it will match any character that is <em>not</em> a newline character (<code>\n</code>). The <code>+</code> after the negated character class means that the pattern should match one or more characters that are not newlines.</p>
</li>
<li>
<p>By using the negated character class <code>[^n]</code> in the capturing group, we ensure that the regex engine captures text up to the end of the line without including the newline character itself. This is useful when we want to extract the text after the word <em>action</em> or <em>action input</em> up to the end of the line.</p>
</li>
</ul>

<p>Overall, this regular expression pattern matches the word <em>action</em> (case-insensitive) followed by optional whitespace, a colon, and optional whitespace again, and then captures any text up to the end of the line.</p>

<p>The only difference between these two regex patterns is the literal text they are looking for at the beginning:</p>
<ol>
<li>
<p><code>action_pattern</code> looks for the word <code>"action".</code></p>
</li>
<li>
<p><code>action_input_pattern</code> looks for the word <code>"action_input".</code></p>
</li>

</ol>

<p>You can now abstract the regex into a Python function that will always find the last <code>action</code> and <code>action_input</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">extract_last_action_and_input</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>
    <code class="c1"># Compile regex patterns</code>
    <code class="n">action_pattern</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="sa">r</code><code class="s2">"(?i)action\s*:\s*([^\n]+)"</code><code class="p">,</code> <code class="n">re</code><code class="o">.</code><code class="n">MULTILINE</code><code class="p">)</code>
    <code class="n">action_input_pattern</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code>
        <code class="sa">r</code><code class="s2">"(?i)action\s*_*input\s*:\s*([^\n]+)"</code><code class="p">,</code> <code class="n">re</code><code class="o">.</code><code class="n">MULTILINE</code>
    <code class="p">)</code>

    <code class="c1"># Find all occurrences of action and action_input</code>
    <code class="n">actions</code> <code class="o">=</code> <code class="n">action_pattern</code><code class="o">.</code><code class="n">findall</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
    <code class="n">action_inputs</code> <code class="o">=</code> <code class="n">action_input_pattern</code><code class="o">.</code><code class="n">findall</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>

    <code class="c1"># Extract the last occurrence of action and action_input</code>
    <code class="n">last_action</code> <code class="o">=</code> <code class="n">actions</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code> <code class="k">if</code> <code class="n">actions</code> <code class="k">else</code> <code class="kc">None</code>
    <code class="n">last_action_input</code> <code class="o">=</code> <code class="n">action_inputs</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code> <code class="k">if</code> <code class="n">action_inputs</code> <code class="k">else</code> <code class="kc">None</code>

    <code class="k">return</code> <code class="p">{</code><code class="s2">"action"</code><code class="p">:</code> <code class="n">last_action</code><code class="p">,</code> <code class="s2">"action_input"</code><code class="p">:</code> <code class="n">last_action_input</code><code class="p">}</code>

<code class="n">extract_last_action_and_input</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
<code class="c1"># {'action': 'search_on_google', 'action_input': 'some other query'}</code></pre>

<p>To determine and extract whether the LLM has <a data-type="indexterm" data-primary="regular expressions" data-secondary="extracting agent" data-startref="rgxpxg" id="id1039"/>discovered the final answer, you can also use regular expressions:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">extract_final_answer</code><code class="p">(</code><code class="n">text</code><code class="p">):</code>
    <code class="n">final_answer_pattern</code> <code class="o">=</code> <code class="n">re</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code>
        <code class="sa">r</code><code class="s2">"(?i)I've found the answer:\s*([^\n]+)"</code><code class="p">,</code> <code class="n">re</code><code class="o">.</code><code class="n">MULTILINE</code>
    <code class="p">)</code>
    <code class="n">final_answers</code> <code class="o">=</code> <code class="n">final_answer_pattern</code><code class="o">.</code><code class="n">findall</code><code class="p">(</code><code class="n">text</code><code class="p">)</code>
    <code class="k">if</code> <code class="n">final_answers</code><code class="p">:</code>
        <code class="k">return</code> <code class="n">final_answers</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>
    <code class="k">else</code><code class="p">:</code>
        <code class="k">return</code> <code class="kc">None</code>

<code class="n">final_answer_text</code> <code class="o">=</code> <code class="s2">"I've found the answer: final_answer"</code>
<code class="nb">print</code><code class="p">(</code><code class="n">extract_final_answer</code><code class="p">(</code><code class="n">final_answer_text</code><code class="p">))</code>
<code class="c1"># final_answer</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>LLMs do not always respond in the intended way, so your application needs to be able to handle regex parsing errors. Several approaches include using an LLM to fix the previous LLM response or making another new LLM request with the previous state.</p>
</div>

<p>You can now combine all of the components; here is a step-by-step explanation:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>
<code class="kn">from</code> <code class="nn">langchain.prompts.chat</code> <code class="kn">import</code> <code class="n">SystemMessagePromptTemplate</code></pre>

<p>Initialize the <code>ChatOpenAI</code> instance:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">chat</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">(</code><code class="n">model_kwargs</code><code class="o">=</code><code class="p">{</code><code class="s2">"stop"</code><code class="p">:</code> <code class="p">[</code><code class="s2">"tool_result:"</code><code class="p">],})</code></pre>

<p>Adding a <code>stop</code> sequence forces an LLM to stop generating new tokens after encounting the phrase <code>"tool_result:"</code>. This helps by stopping hallucinations for tool usage.</p>

<p>Define the available tools:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">tools</code> <code class="o">=</code> <code class="p">{}</code>

<code class="k">def</code> <code class="nf">search_on_google</code><code class="p">(</code><code class="n">query</code><code class="p">:</code> <code class="nb">str</code><code class="p">):</code>
    <code class="k">return</code> <code class="sa">f</code><code class="s2">"Jason Derulo doesn't have a wife or partner."</code>

<code class="n">tools</code><code class="p">[</code><code class="s2">"search_on_google"</code><code class="p">]</code> <code class="o">=</code> <code class="p">{</code>
    <code class="s2">"function"</code><code class="p">:</code> <code class="n">search_on_google</code><code class="p">,</code>
    <code class="s2">"description"</code><code class="p">:</code> <code class="s2">"Searches on google for a query"</code><code class="p">,</code>
<code class="p">}</code></pre>

<p>Set the base prompt template:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">base_prompt</code> <code class="o">=</code> <code class="s2">"""</code>
<code class="s2">You will attempt to solve the problem of finding the answer to a question.</code>
<code class="s2">Use chain-of-thought reasoning to solve through the problem, using the</code>
<code class="s2">following pattern:</code>

<code class="s2">1. Observe the original question:</code>
<code class="s2">original_question: original_problem_text</code>
<code class="s2">2. Create an observation with the following pattern:</code>
<code class="s2">observation: observation_text</code>
<code class="s2">3. Create a thought based on the observation with the following pattern:</code>
<code class="s2">thought: thought_text</code>
<code class="s2">4. Use tools to act on the thought with the following pattern:</code>
<code class="s2">action: tool_name</code>
<code class="s2">action_input: tool_input</code>

<code class="s2">Do not guess or assume the tool results. Instead, provide a structured</code>
<code class="s2">output that includes the action and action_input.</code>

<code class="s2">You have access to the following tools: </code><code class="si">{tools}</code><code class="s2">.</code>

<code class="s2">original_problem: </code><code class="si">{question}</code><code class="s2"/>
<code class="s2">"""</code></pre>

<p>Generate the model output:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">output</code> <code class="o">=</code> <code class="n">chat</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="n">SystemMessagePromptTemplate</code> \
<code class="o">.</code><code class="n">from_template</code><code class="p">(</code><code class="n">template</code><code class="o">=</code><code class="n">base_prompt</code><code class="p">)</code> \
<code class="o">.</code><code class="n">format_messages</code><code class="p">(</code><code class="n">tools</code><code class="o">=</code><code class="n">tools</code><code class="p">,</code> <code class="n">question</code><code class="o">=</code><code class="s2">"Is Jason Derulo with a partner?"</code><code class="p">))</code>
<code class="nb">print</code><code class="p">(</code><code class="n">output</code><code class="p">)</code></pre>

<p>Extract the last <code>action</code>, <code>action_input</code>,  and call the relevant function:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">tool_name</code> <code class="o">=</code> <code class="n">extract_last_action_and_input</code><code class="p">(</code><code class="n">output</code><code class="o">.</code><code class="n">content</code><code class="p">)[</code><code class="s2">"action"</code><code class="p">]</code>
<code class="n">tool_input</code> <code class="o">=</code> <code class="n">extract_last_action_and_input</code><code class="p">(</code><code class="n">output</code><code class="o">.</code><code class="n">content</code><code class="p">)[</code><code class="s2">"action_input"</code><code class="p">]</code>
<code class="n">tool_result</code> <code class="o">=</code> <code class="n">tools</code><code class="p">[</code><code class="n">tool_name</code><code class="p">][</code><code class="s2">"function"</code><code class="p">](</code><code class="n">tool_input</code><code class="p">)</code></pre>

<p>Print the tool details:</p>

<pre data-type="programlisting" data-code-language="python"><code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"""The agent has opted to use the following tool:</code>
<code class="s2">tool_name: </code><code class="si">{</code><code class="n">tool_name</code><code class="si">}</code><code class="s2"/>
<code class="s2">tool_input: </code><code class="si">{</code><code class="n">tool_input</code><code class="si">}</code><code class="s2"/>
<code class="s2">tool_result: </code><code class="si">{</code><code class="n">tool_result</code><code class="si">}</code><code class="s2">"""</code>
<code class="p">)</code></pre>

<p>Set the current prompt with the tool result:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">current_prompt</code> <code class="o">=</code> <code class="s2">"""</code>
<code class="s2">You are answering this query: Is Jason Derulo with a partner?</code>

<code class="s2">Based on the provided tool result:</code>
<code class="s2">tool_result: </code><code class="si">{tool_result}</code><code class="s2"/>

<code class="s2">Either provide the next observation, action, action_input, or the final</code>
<code class="s2">answer if available. If you are providing the final answer, you must return</code>
<code class="s2">the following pattern: "I've found the answer: final_answer"</code>
<code class="s2">"""</code></pre>

<p>Generate the model output for the current prompt:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">output</code> <code class="o">=</code> <code class="n">chat</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="n">SystemMessagePromptTemplate</code><code class="o">.</code> \
<code class="n">from_template</code><code class="p">(</code><code class="n">template</code><code class="o">=</code><code class="n">current_prompt</code><code class="p">)</code> \
<code class="o">.</code><code class="n">format_messages</code><code class="p">(</code><code class="n">tool_result</code><code class="o">=</code><code class="n">tool_result</code><code class="p">))</code></pre>

<p>Print the model output for the current prompt:</p>

<pre data-type="programlisting" data-code-language="python"><code class="nb">print</code><code class="p">(</code><code class="s2">"----------</code><code class="se">\n\n</code><code class="s2">The model output is:"</code><code class="p">,</code> <code class="n">output</code><code class="o">.</code><code class="n">content</code><code class="p">)</code>
<code class="n">final_answer</code> <code class="o">=</code> <code class="n">extract_final_answer</code><code class="p">(</code><code class="n">output</code><code class="o">.</code><code class="n">content</code><code class="p">)</code>
<code class="k">if</code> <code class="n">final_answer</code><code class="p">:</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"answer: </code><code class="si">{</code><code class="n">final_answer</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
<code class="k">else</code><code class="p">:</code>
    <code class="nb">print</code><code class="p">(</code><code class="s2">"No final answer found."</code><code class="p">)</code></pre>

<p>Output:</p>

<pre data-type="programlisting" data-code-language="python"><code class="sd">'''content='1. Observe the original question:\nIs Jason Derulo with a</code>
<code class="sd">partner?\n\n2. Create an observation:\nWe don\'t have any information</code>
<code class="sd">about Jason Derulo\'s relationship status.\n\n3. Create a thought based</code>
<code class="sd">on the observation:\nWe can search for recent news or interviews to find</code>
<code class="sd">out if Jason Derulo is currently with a partner.\n\n4. Use the tool to act</code>
<code class="sd">on the thought:\naction: search_on_google\naction_input: "Jason Derulo</code>
<code class="sd">current relationship status"' additional_kwargs={} example=False</code>

<code class="sd">----------</code>
<code class="sd">The agent has opted to use the following tool:</code>
<code class="sd">tool_name: search_on_google</code>
<code class="sd">tool_input: "Jason Derulo current relationship status"</code>
<code class="sd">tool_result: Jason Derulo doesn't have a wife or partner.</code>
<code class="sd">----------</code>

<code class="sd">The second prompt shows</code>
<code class="sd">Based on the provided tool result:</code>
<code class="sd">tool_result: {tool_result}</code>

<code class="sd">Either provide the next observation, action, action_input, or the final</code>
<code class="sd">answer if available. If you are providing the final answer, you must</code>
<code class="sd">return the following pattern: "I've found the answer: final_answer"</code>
<code class="sd">----------</code>

<code class="sd">The model output is: I've found the answer: Jason Derulo doesn't have a</code>
<code class="sd">wife or partner. answer: Jason Derulo doesn't have a wife or partner.'''</code></pre>

<p>The preceding steps provide a very simple ReAct implementation. In this case, the LLM decided to use the <code>search_on_google</code> tool with <code>"Jason Derulo current <span class="keep-together">relationship</span> status"</code> as the <code>action_input</code>.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>LangChain agents will automatically do all of the preceding steps in a concise manner, as well as provide multiple tool usage (through looping) and handling for tool failures when an agent can’t parse the <code>action</code> or <code>action_input</code>.</p>
</div>

<p>Before exploring LangChain agents and what <a data-type="indexterm" data-primary="agents" data-secondary="ReAct (Reason and Act)" data-tertiary="implementation" data-startref="garcrapmt" id="id1040"/><a data-type="indexterm" data-primary="ReAct (Reason and Act) framework" data-secondary="implementation" data-startref="rarfwkpm" id="id1041"/>they have to offer, it’s vital that you learn <em>tools</em> and how to create and use them.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Using Tools"><div class="sect2" id="id169">
<h2>Using Tools</h2>

<p>As large language models such as GPT-4 can only <a data-type="indexterm" data-primary="agents" data-secondary="tools" id="agttls"/><a data-type="indexterm" data-primary="tools" data-secondary="agents and" id="tlsgta"/>generate text, providing tools that can perform other actions such as interacting with a database or reading/writing files provides an effective method to increase an LLM’s capabilities. A <em>tool</em> is simply a predefined function that permits the agent to take a specific action.</p>

<p>A common part of an agent’s prompt will likely include the following:</p>

<pre data-type="programlisting">You are looking to accomplish: {goal}
You have access to the following {tools}</pre>

<p>Most tools are written as functions within a programming language.  As you explore LangChain, you’ll find that it offers three different approaches to tool creation/usage:</p>

<ul>
<li>
<p>Create your own custom tools.</p>
</li>
<li>
<p>Use preexisting tools.</p>
</li>
<li>
<p>Leverage <code>AgentToolkits</code>, which are multiple tools bundled together to accomplish a specific task.</p>
</li>
</ul>

<p>Let’s start by creating a custom tool that checks the length of a given string using LangChain:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># Import necessary classes and functions:</code>
<code class="kn">from</code> <code class="nn">langchain.agents</code> <code class="kn">import</code> <code class="n">AgentExecutor</code><code class="p">,</code> <code class="n">create_react_agent</code>
<code class="kn">from</code> <code class="nn">langchain</code> <code class="kn">import</code> <code class="n">hub</code>
<code class="kn">from</code> <code class="nn">langchain_openai</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>
<code class="kn">from</code> <code class="nn">langchain.tools</code> <code class="kn">import</code> <code class="n">Tool</code>

<code class="c1"># Defining the LLM to use:</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">()</code>

<code class="c1"># Function to count the number of characters in a string:</code>
<code class="k">def</code> <code class="nf">count_characters_in_string</code><code class="p">(</code><code class="n">string</code><code class="p">):</code>
    <code class="k">return</code> <code class="nb">len</code><code class="p">(</code><code class="n">string</code><code class="p">)</code>

<code class="c1"># Create a list of tools:</code>
<code class="c1"># Currently, only one tool is defined that counts characters in a text string.</code>
<code class="n">tools</code> <code class="o">=</code> <code class="p">[</code>
    <code class="n">Tool</code><code class="o">.</code><code class="n">from_function</code><code class="p">(</code>
        <code class="n">func</code><code class="o">=</code><code class="n">count_characters_in_string</code><code class="p">,</code>
        <code class="n">name</code><code class="o">=</code><code class="s2">"Count Characters in a text string"</code><code class="p">,</code>
        <code class="n">description</code><code class="o">=</code><code class="s2">"Count the number of characters in a text string"</code><code class="p">,</code>
    <code class="p">)</code>
<code class="p">]</code>

<code class="c1"># Download a react prompt!</code>
<code class="n">prompt</code> <code class="o">=</code> <code class="n">hub</code><code class="o">.</code><code class="n">pull</code><code class="p">(</code><code class="s2">"hwchase17/react"</code><code class="p">)</code>

<code class="c1"># Construct the ReAct agent:</code>
<code class="n">agent</code> <code class="o">=</code> <code class="n">create_react_agent</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">tools</code><code class="p">,</code> <code class="n">prompt</code><code class="p">)</code>

<code class="c1"># Initialize an agent with the defined tools and</code>
<code class="c1"># Create an agent executor by passing in the agent and tools:</code>
<code class="n">agent_executor</code> <code class="o">=</code> <code class="n">AgentExecutor</code><code class="p">(</code><code class="n">agent</code><code class="o">=</code><code class="n">agent</code><code class="p">,</code> <code class="n">tools</code><code class="o">=</code><code class="n">tools</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>

<code class="c1"># Invoke the agent with a query to count the characters in the given word:</code>
<code class="n">agent_executor</code><code class="o">.</code><code class="n">invoke</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s1">'''How many characters are in the word</code>
<code class="s1">"supercalifragilisticexpialidocious"?'''</code><code class="p">})</code>

<code class="c1"># 'There are 34 characters in the word "supercalifragilisticexpialidocious".'</code></pre>

<p>Following the import of necessary modules, you initialize a <code>ChatOpenAI</code> chat model. Then create a function called <code>count_characters_in_string</code> that computes the length of any given string. This function is encapsulated within a <code>Tool</code> object, providing a descriptive name and explanation for its role.</p>

<p class="pagebreak-before">Subsequently, you utilize <code>create_react_agent</code> to initialize your agent, combining the defined <code>Tool</code>, the <code>ChatOpenAI</code> model, and a react prompt pulled from the LangChain hub. This sets up a comprehensive interactive agent.</p>

<p>With <code>AgentExecutor</code>, the agent is equipped with the tools and verbose output is enabled, allowing for detailed logging.</p>

<p>Finally, <code>agent_executor.invoke(...)</code> is executed with a query about the character count in “supercalifragilisticexpialidocious.” The agent utilizes the defined tool to calculate and return the precise character count in the word.</p>

<p>In <a data-type="xref" href="#ex_agent_custom_tool_character">Example 6-1</a>, you can see that the agent decided to use the <code>Action</code> called <span class="keep-together"><code>Characters</code></span> <code>in a text string</code> with an <code>Action Input</code>: <code>'supercalifragilisticexpialidocious'</code>. This pattern is extremely familiar to the simplistic ReAct implementation that you previously made.</p>
<div id="ex_agent_custom_tool_character" data-type="example">
<h5><span class="label">Example 6-1. </span>A single tool, agent output</h5>

<pre data-type="programlisting">Entering new AgentExecutor change...
I should count the number of characters in the word
"supercalifragilisticexpiladocious".
Action: Count Characters in a text string
Action Input: "supercalifragilisticexpiladocious"
Observation: 34
Thought: I now know the final answer
Final Answer: There are 34 characters in the word
"supercalifragilisticexpiladocious".</pre></div>
<div data-type="tip"><h1>Give Direction</h1>
<p>Writing expressive names for your Python functions and tool descriptions will increase an LLM’s ability to effectively choose <a data-type="indexterm" data-primary="agents" data-secondary="tools" data-startref="agttls" id="id1042"/><a data-type="indexterm" data-primary="tools" data-secondary="agents and" data-startref="tlsgta" id="id1043"/><a data-type="indexterm" data-primary="tools" data-secondary="expressive names" id="id1044"/><a data-type="indexterm" data-primary="Give Direction principle" data-secondary="agents" id="id1045"/>the right tools.</p>
</div>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Using LLMs as an API (OpenAI Functions)"><div class="sect1" id="id96">
<h1>Using LLMs as an API (OpenAI Functions)</h1>

<p>As mentioned in <a data-type="xref" href="ch04.html#advanced_text_04">Chapter 4</a>, OpenAI <a href="https://oreil.ly/hYTus">released more fine-tuned LLMs</a> tailored toward function <a data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="OpenAI functions" id="llmlmpa"/><a data-type="indexterm" data-primary="OpenAI functions" data-secondary="LLMs" id="opafllm"/>calling. This is important because it offers an alternative against the standard ReAct pattern for tool use. It’s similar to ReAct in that you’re still utilizing an LLM as a <em>reasoning engine.</em></p>

<p>As shown in <a data-type="xref" href="#fig-6-2">Figure 6-2</a>, function calling allows an LLM to easily transform a user’s input into a weather API call.</p>

<figure><div id="fig-6-2" class="figure">
<img src="assets/pega_0602.png" alt="Function calling flow using OpenAI functions" width="600" height="546"/>
<h6><span class="label">Figure 6-2. </span>Function calling flow using OpenAI functions</h6>
</div></figure>

<p>LangChain allows users to effortlessly switch between different agent types including ReAct, OpenAI functions, and many more.</p>

<p>Refer to <a data-type="xref" href="#table-6-1">Table 6-1</a> for a comprehensive comparison of the different agent types.</p>
<table id="table-6-1">
<caption><span class="label">Table 6-1. </span>Comparison of agent types</caption>
<thead>
<tr>
<th>Agent type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>OpenAI Functions</p></td>
<td><p>Works with fine-tuned models like gpt-3.5-turbo-0613 and gpt-4-0613 for function calling. It intelligently <a data-type="indexterm" data-primary="agents" data-secondary="OpenAI functions" id="id1046"/>outputs JSON objects for the function calls. Best for open source models and providers adopting this format. Note: deprecated in favor of OpenAI Tools.</p></td>
</tr>
<tr>
<td><p>OpenAI Tools</p></td>
<td><p>Enhanced version for newer models, capable of <a data-type="indexterm" data-primary="agents" data-secondary="OpenAI tools" id="id1047"/>invoking one or more functions. It intelligently outputs JSON objects for these function calls, optimizing the response efficiency and reducing response times in some architectures.</p></td>
</tr>
<tr>
<td><p>XML Agent</p></td>
<td><p>Ideal for language models <a data-type="indexterm" data-primary="agents" data-secondary="XML agent" id="id1048"/><a data-type="indexterm" data-primary="XML agent" id="id1049"/>like Anthropic’s Claude, which excel in XML reasoning/writing. Best used with regular LLMs (not chat models) and unstructured tools accepting single string inputs.</p></td>
</tr>
<tr>
<td><p>JSON Chat Agent</p></td>
<td><p>Tailored for language models <a data-type="indexterm" data-primary="agents" data-secondary="JSON chat agent" id="id1050"/><a data-type="indexterm" data-primary="JSON (JavaScript Object Notation)" data-secondary="chat agent" id="id1051"/>skilled in JSON formatting. This agent uses JSON to format its outputs, supporting chat models for scenarios requiring JSON outputs.</p></td>
</tr>
<tr>
<td><p>Structured Chat</p></td>
<td><p>Capable of using multi-input tools, this <a data-type="indexterm" data-primary="agents" data-secondary="structured chat" id="id1052"/><a data-type="indexterm" data-primary="structured chat" id="id1053"/>agent is designed for complex tasks requiring structured inputs and responses.</p></td>
</tr>
<tr>
<td><p>ReAct</p></td>
<td><p>Implements ReAct logic, using <a data-type="indexterm" data-primary="agents" data-secondary="ReAct (Reason and Act)" id="id1054"/><a data-type="indexterm" data-primary="ReAct (Reason and Act) framework" id="id1055"/>tools like Tavily’s Search for interactions with a document store or search tools.</p></td>
</tr>
<tr>
<td><p>Self-Ask with Search</p></td>
<td><p>Utilizes the Intermediate Answer <a data-type="indexterm" data-primary="agents" data-secondary="self-ask with search" id="id1056"/>tool for factual question resolution, following the self-ask with search methodology. Best for scenarios requiring quick and accurate factual answers.</p></td>
</tr>
</tbody>
</table>

<p>Let’s use prepackaged tools such as a <code>Calculator</code> to answer math questions using OpenAI function calling from the LangChain documentation:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># Import necessary modules and functions from the langchain package:</code>
<code class="kn">from</code> <code class="nn">langchain.chains</code> <code class="kn">import</code> <code class="p">(</code>
    <code class="n">LLMMathChain</code><code class="p">,</code>
<code class="p">)</code>
<code class="kn">from</code> <code class="nn">langchain</code> <code class="kn">import</code> <code class="n">hub</code>
<code class="kn">from</code> <code class="nn">langchain.agents</code> <code class="kn">import</code> <code class="n">create_openai_functions_agent</code><code class="p">,</code> <code class="n">Tool</code><code class="p">,</code> <code class="n">AgentExecutor</code>
<code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>

<code class="c1"># Initialize the ChatOpenAI with temperature set to 0:</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">(</code><code class="n">temperature</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>

<code class="c1"># Create a LLMMathChain instance using the ChatOpenAI model:</code>
<code class="n">llm_math_chain</code> <code class="o">=</code> <code class="n">LLMMathChain</code><code class="o">.</code><code class="n">from_llm</code><code class="p">(</code><code class="n">llm</code><code class="o">=</code><code class="n">model</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>

<code class="c1"># Download the prompt from the hub:</code>
<code class="n">prompt</code> <code class="o">=</code> <code class="n">hub</code><code class="o">.</code><code class="n">pull</code><code class="p">(</code><code class="s2">"hwchase17/openai-functions-agent"</code><code class="p">)</code>

<code class="n">tools</code> <code class="o">=</code> <code class="p">[</code>
    <code class="n">Tool</code><code class="p">(</code>
        <code class="n">name</code><code class="o">=</code><code class="s2">"Calculator"</code><code class="p">,</code>
        <code class="n">func</code><code class="o">=</code><code class="n">llm_math_chain</code><code class="o">.</code><code class="n">run</code><code class="p">,</code> <code class="c1"># run the LLMMathChain</code>
        <code class="n">description</code><code class="o">=</code><code class="s2">"useful for when you need to answer questions about math"</code><code class="p">,</code>
        <code class="n">return_direct</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code>
    <code class="p">),</code>
<code class="p">]</code>

<code class="c1"># Create an agent using the ChatOpenAI model and the tools:</code>
<code class="n">agent</code> <code class="o">=</code> <code class="n">create_openai_functions_agent</code><code class="p">(</code><code class="n">llm</code><code class="o">=</code><code class="n">model</code><code class="p">,</code> <code class="n">tools</code><code class="o">=</code><code class="n">tools</code><code class="p">,</code> <code class="n">prompt</code><code class="o">=</code><code class="n">prompt</code><code class="p">)</code>
<code class="n">agent_executor</code> <code class="o">=</code> <code class="n">AgentExecutor</code><code class="p">(</code><code class="n">agent</code><code class="o">=</code><code class="n">agent</code><code class="p">,</code> <code class="n">tools</code><code class="o">=</code><code class="n">tools</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>

<code class="n">result</code> <code class="o">=</code> <code class="n">agent_executor</code><code class="o">.</code><code class="n">invoke</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"What is 5 + 5?"</code><code class="p">})</code>
<code class="nb">print</code><code class="p">(</code><code class="n">result</code><code class="p">)</code>
<code class="c1"># {'input': 'What is 5 + 5?', 'output': 'Answer: 10'}</code></pre>

<p>After initiating the necessary libraries, you’ll use <code>ChatOpenAI</code>, setting the <code>temperature</code> parameter to 0 for deterministic outputs. By using <code>hub.pull("...")</code>, you can easily download prompts that have been saved on LangChainHub.</p>

<p>This model is then coupled with a tool named <code>Calculator</code> that leverages the capabilities of <code>LLMMathChain</code> to compute math queries. The OpenAI functions agent then decides to use the <code>Calculator</code> tool to compute <code>5 + 5</code> and returns <code>Answer: 10</code>.</p>

<p>Following on, you can equip an agent with multiple tools, enhancing its versatility. To test this, let’s add an extra <code>Tool</code> object to our agent that allows it to perform a fake Google search:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">google_search</code><code class="p">(</code><code class="n">query</code><code class="p">:</code> <code class="nb">str</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">str</code><code class="p">:</code>
    <code class="k">return</code> <code class="s2">"James Phoenix is 31 years old."</code>

<code class="c1"># List of tools that the agent can use:</code>
<code class="n">tools</code> <code class="o">=</code> <code class="p">[</code>
    <code class="n">Tool</code><code class="p">(</code>
        <code class="c1"># The LLMMathChain tool for math calculations.</code>
        <code class="n">func</code><code class="o">=</code><code class="n">llm_math_chain</code><code class="o">.</code><code class="n">run</code><code class="p">,</code>
        <code class="n">name</code><code class="o">=</code><code class="s2">"Calculator"</code><code class="p">,</code>
        <code class="n">description</code><code class="o">=</code><code class="s2">"useful for when you need to answer questions about math"</code><code class="p">,</code>
    <code class="p">),</code>
    <code class="n">Tool</code><code class="p">(</code>
        <code class="c1"># Tool for counting characters in a string.</code>
        <code class="n">func</code><code class="o">=</code><code class="n">google_search</code><code class="p">,</code>
        <code class="n">name</code><code class="o">=</code><code class="s2">"google_search"</code><code class="p">,</code>
        <code class="n">description</code><code class="o">=</code><code class="s2">"useful for when you need to find out about someones age."</code><code class="p">,</code>
    <code class="p">),</code>
<code class="p">]</code>


<code class="c1"># Create an agent using the ChatOpenAI model and the tools:</code>
<code class="n">agent</code> <code class="o">=</code> <code class="n">create_openai_functions_agent</code><code class="p">(</code><code class="n">llm</code><code class="o">=</code><code class="n">model</code><code class="p">,</code> <code class="n">tools</code><code class="o">=</code><code class="n">tools</code><code class="p">,</code> <code class="n">prompt</code><code class="o">=</code><code class="n">prompt</code><code class="p">)</code>
<code class="n">agent_executor</code> <code class="o">=</code> <code class="n">AgentExecutor</code><code class="p">(</code><code class="n">agent</code><code class="o">=</code><code class="n">agent</code><code class="p">,</code> <code class="n">tools</code><code class="o">=</code><code class="n">tools</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>

<code class="c1"># Asking the agent to run a task and store its result:</code>
<code class="n">result</code> <code class="o">=</code> <code class="n">agent_executor</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code>
    <code class="p">{</code>
        <code class="s2">"input"</code><code class="p">:</code> <code class="s2">"""Task: Google search for James Phoenix's age.</code>
<code class="s2">        Then square it."""</code><code class="p">}</code>
<code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="n">result</code><code class="p">)</code>
<code class="c1"># {'input': "...", 'output': 'James Phoenix is 31 years old.</code>
<code class="c1"># Squaring his age, we get 961.'}</code></pre>

<p>When executed, the agent will first invoke the <code>google_search</code> function and then proceed to the <code>llm_math_chain.run</code> function. By mixing both custom and prepackaged tools, you significantly increase the flexibility of your agents.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Depending upon how many tools you provide, an LLM will either restrict or increase its ability to solve different user queries. Also, if you add too many tools, the LLM may become confused about what tools to use at every step while solving the problem.</p>
</div>

<p>Here are several recommended tools that you might want to explore:</p>
<dl>
<dt><a href="https://oreil.ly/TjrnF">Google search</a></dt>
<dd>
<p>Enables an LLM to perform web searches, which provides timely and relevant context.</p>
</dd>
<dt><a href="https://oreil.ly/5tAB0">File system tools</a></dt>
<dd>
<p>Essential for managing files, whether it involves reading, writing, or reorganizing them. Your LLM can interact with the file system more efficiently with them.</p>
</dd>
<dt><a href="https://oreil.ly/vZjm1">Requests</a></dt>
<dd>
<p>A pragmatic tool that makes an LLM capable of executing HTTP requests for create, read, update, and delete (CRUD) functionality.</p>
</dd>
<dt><a href="https://oreil.ly/ECS4r">Twilio</a></dt>
<dd>
<p>Enhance the functionality of your LLM by allowing it to send SMS messages or WhatsApp messages through Twilio.</p>
</dd>
</dl>
<div data-type="tip"><h1>Divide Labor and Evaluate Quality</h1>
<p>When using tools, make sure you divide <a data-type="indexterm" data-primary="Divide Labor principle" data-secondary="LLMs as and API" id="id1057"/><a data-type="indexterm" data-primary="Evaluate Quality principle" data-secondary="LLMs as and API" id="id1058"/>the tasks appropriately. For example, entrust Twilio with communication services, while assigning requests for HTTP-related tasks. Additionally, it is crucial to consistently evaluate the performance and quality of the tasks performed by each tool.</p>

<p>Different tools may be called more or less frequently, which will influence your LLM agent’s performance. Monitoring tool <a data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="OpenAI functions" data-startref="llmlmpa" id="id1059"/><a data-type="indexterm" data-primary="OpenAI functions" data-secondary="LLMs" data-startref="opafllm" id="id1060"/>usage will offer insights into your agent’s overall performance.</p>
</div>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Comparing OpenAI Functions and ReAct"><div class="sect1" id="id170">
<h1>Comparing OpenAI Functions and ReAct</h1>

<p>Both OpenAI functions and the ReAct framework bring unique capabilities to the table for executing tasks with <a data-type="indexterm" data-primary="OpenAI functions" data-secondary="ReAct comparison" id="pafrcp"/><a data-type="indexterm" data-primary="ReAct (Reason and Act) framework" data-secondary="OpenAI functions comparison" id="raramw"/>generative AI models. Understanding the differences between them can help you determine which is better suited for your specific use case.</p>

<p>OpenAI functions operate in a straightforward manner. In this setup, the LLM decides at runtime whether to execute a function. This is beneficial when integrated into a conversational agent, as it provides several features including:</p>
<dl>
<dt>Runtime decision making</dt>
<dd>
<p>The LLM autonomously makes the decision on whether a function(s) should be executed or not in real time.</p>
</dd>
<dt>Single tool execution</dt>
<dd>
<p>OpenAI functions are ideal for tasks requiring a single tool execution.</p>
</dd>
<dt>Ease of implementation</dt>
<dd>
<p>OpenAI functions can be easily merged with conversational agents.</p>
</dd>
<dt>Parallel function calling</dt>
<dd>
<p>For single task executions requiring multiple parses, OpenAI functions offer parallel function calling to invoke several functions within the same API request.</p>
</dd>
</dl>








<section data-type="sect2" data-pdf-bookmark="Use Cases for OpenAI Functions"><div class="sect2" id="id171">
<h2>Use Cases for OpenAI Functions</h2>

<p>If your task entails a definitive action <a data-type="indexterm" data-primary="OpenAI functions" data-secondary="use cases" id="id1061"/>such as a simple search or data extraction, OpenAI functions are an ideal choice.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="ReAct"><div class="sect2" id="id172">
<h2>ReAct</h2>

<p>If you require executions involving multiple <a data-type="indexterm" data-primary="ReAct (Reason and Act) framework" data-secondary="conversational-react" id="id1062"/>sequential tool usage and deeper introspection of previous actions, ReAct comes into play. Compared to function calling, ReAct is designed to go through many <em>thought loops</em> to accomplish a higher-level goal, making it suitable for queries with multiple intents.</p>

<p>Despite ReAct’s compatibility with <code>conversational-react</code> as an agent, it doesn’t yet offer the same level of stability as function calling and often favors toward using tools over simply responding with text. Nevertheless, if your task requires successive executions, ReAct’s ability to generate many thought loops and decide on a single tool at a time demonstrates several distinct features including:</p>
<dl>
<dt>Iterative thought process</dt>
<dd>
<p>ReAct allows agents to generate numerous thought loops for complex tasks.</p>
</dd>
<dt>Multi-intent handling</dt>
<dd>
<p>ReAct handles queries with multiple intents effectively, thus making it suitable for complex tasks.</p>
</dd>
<dt>Multiple tool execution</dt>
<dd>
<p>Ideal for tasks requiring multiple tool executions sequentially.</p>
</dd>
</dl>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Use Cases for ReAct"><div class="sect2" id="id173">
<h2>Use Cases for ReAct</h2>

<p>If you’re working on a project that <a data-type="indexterm" data-primary="ReAct (Reason and Act) framework" data-secondary="use cases" id="id1063"/>requires introspection of previous actions or uses multiple functions in succession such as saving an interview and then sending it in an email, ReAct is the best choice.</p>

<p>To aid decision making, see a comprehensive comparison in <a data-type="xref" href="#table-6-2">Table 6-2</a>.</p>
<table id="table-6-2">
<caption><span class="label">Table 6-2. </span>A feature comparison between OpenAI functions and ReAct</caption>
<thead>
<tr>
<th>Feature</th>
<th>OpenAI functions</th>
<th>ReAct</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>Runtime decision making</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr>
<td><p>Single tool execution</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr>
<td><p>Ease of implementation</p></td>
<td><p>✓</p></td>
<td><p>x</p></td>
</tr>
<tr>
<td><p>Parallel function calling</p></td>
<td><p>✓</p></td>
<td><p>x</p></td>
</tr>
<tr>
<td><p>Iterative thought process</p></td>
<td><p>x</p></td>
<td><p>✓</p></td>
</tr>
<tr>
<td><p>Multi-intent handling</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
<tr>
<td><p>Sequential tool execution</p></td>
<td><p>x</p></td>
<td><p>✓</p></td>
</tr>
<tr>
<td><p>Customizable prompt</p></td>
<td><p>✓</p></td>
<td><p>✓</p></td>
</tr>
</tbody>
</table>
<div data-type="tip"><h1>Give Direction</h1>
<p>When interacting with different AI frameworks, it’s crucial to understand that each framework has its strengths and trade-offs. Each <a data-type="indexterm" data-primary="OpenAI functions" data-secondary="ReAct comparison" data-startref="pafrcp" id="id1064"/><a data-type="indexterm" data-primary="ReAct (Reason and Act) framework" data-secondary="OpenAI functions comparison" data-startref="raramw" id="id1065"/><a data-type="indexterm" data-primary="Give Direction principle" data-secondary="ReAct (Reason and Act)" id="id1066"/>framework will provide a unique form of direction to your LLM.</p>
</div>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Agent Toolkits"><div class="sect1" id="id97">
<h1>Agent Toolkits</h1>

<p><em><a href="https://oreil.ly/_v6dm">Agent toolkits</a></em> are a LangChain integration that provides multiple tools and chains together, allowing you <a data-type="indexterm" data-primary="agent toolkits" id="agttlk"/>to quickly automate tasks.</p>

<p>First, install some more packages by typing <code><strong>pip install langchain_experimental pandas tabulate langchain-community pymongo --upgrade</strong></code> on your terminal. Popular agent toolkits include:</p>

<ul>
<li>
<p>CSV Agent</p>
</li>
<li>
<p>Gmail Toolkit</p>
</li>
<li>
<p>OpenAI Agent</p>
</li>
<li>
<p>Python Agent</p>
</li>
<li>
<p>JSON Agent</p>
</li>
<li>
<p>Pandas DataFrame Agent</p>
</li>
</ul>

<p>The CSV Agent uses a Pandas <a data-type="indexterm" data-primary="CSV Agent toolkit" id="id1067"/>DataFrame Agent and <code>python_repl_ast</code> tool to investigate a <em>.csv</em> file. You can ask it to quantify the data, identify column names, or create a correlation matrix.</p>

<p>Create a new Jupyter Notebook <a data-type="indexterm" data-primary="Jupyter Notebook" id="id1068"/>or Python file in <em>content/chapter_6</em> of the <a href="https://oreil.ly/x6FHn">shared repository</a>, then you will need to import <code>create_csv_agent</code>, <code>ChatOpenAI</code>, and <code>AgentType</code>. The <span class="keep-together"><code>create_csv_agent</code></span> function requires an LLM, dataset <code>file path</code>, and <code>agent_type</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># Importing the relevant packages:</code>
<code class="kn">from</code> <code class="nn">langchain.agents.agent_types</code> <code class="kn">import</code> <code class="n">AgentType</code>
<code class="kn">from</code> <code class="nn">langchain_experimental.agents.agent_toolkits</code> <code class="kn">import</code> <code class="n">create_csv_agent</code>
<code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>

<code class="c1"># Creating a CSV Agent:</code>
<code class="n">agent</code> <code class="o">=</code> <code class="n">create_csv_agent</code><code class="p">(</code>
    <code class="n">ChatOpenAI</code><code class="p">(</code><code class="n">temperature</code><code class="o">=</code><code class="mi">0</code><code class="p">),</code>
    <code class="s2">"data/heart_disease_uci.csv"</code><code class="p">,</code>
    <code class="n">verbose</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code>
    <code class="n">agent_type</code><code class="o">=</code><code class="n">AgentType</code><code class="o">.</code><code class="n">ZERO_SHOT_REACT_DESCRIPTION</code><code class="p">,</code>
<code class="p">)</code>

<code class="n">agent</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="s2">"How many rows of data are in the file?"</code><code class="p">)</code>
<code class="c1"># '920'</code>

<code class="n">agent</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="s2">"What are the columns within the dataset?"</code><code class="p">)</code>
<code class="c1"># "'id', 'age', 'sex', 'dataset', 'cp', 'trestbps', 'chol', 'fbs',</code>
<code class="c1"># 'restecg', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num'"</code>

<code class="n">agent</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="s2">"Create a correlation matrix for the data and save it to a file."</code><code class="p">)</code>
<code class="c1"># "The correlation matrix has been saved to a file named</code>
<code class="c1"># 'correlation_matrix.csv'."</code></pre>

<p>It’s even possible for you to interact with a SQL database via a SQLDatabase agent:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain.agents</code> <code class="kn">import</code> <code class="n">create_sql_agent</code>
<code class="kn">from</code> <code class="nn">langchain_community.agent_toolkits</code> <code class="kn">import</code> <code class="n">SQLDatabaseToolkit</code>
<code class="kn">from</code> <code class="nn">langchain.sql_database</code> <code class="kn">import</code> <code class="n">SQLDatabase</code>
<code class="kn">from</code> <code class="nn">langchain.agents.agent_types</code> <code class="kn">import</code> <code class="n">AgentType</code>
<code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>

<code class="n">db</code> <code class="o">=</code> <code class="n">SQLDatabase</code><code class="o">.</code><code class="n">from_uri</code><code class="p">(</code><code class="s2">"sqlite:///./data/demo.db"</code><code class="p">)</code>
<code class="n">toolkit</code> <code class="o">=</code> <code class="n">SQLDatabaseToolkit</code><code class="p">(</code><code class="n">db</code><code class="o">=</code><code class="n">db</code><code class="p">,</code> <code class="n">llm</code><code class="o">=</code><code class="n">ChatOpenAI</code><code class="p">(</code><code class="n">temperature</code><code class="o">=</code><code class="mi">0</code><code class="p">))</code>

<code class="c1"># Creating an agent executor:</code>
<code class="n">agent_executor</code> <code class="o">=</code> <code class="n">create_sql_agent</code><code class="p">(</code>
    <code class="n">llm</code><code class="o">=</code><code class="n">ChatOpenAI</code><code class="p">(</code><code class="n">temperature</code><code class="o">=</code><code class="mi">0</code><code class="p">),</code>
    <code class="n">toolkit</code><code class="o">=</code><code class="n">toolkit</code><code class="p">,</code>
    <code class="n">verbose</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code>
    <code class="n">agent_type</code><code class="o">=</code><code class="n">AgentType</code><code class="o">.</code><code class="n">OPENAI_FUNCTIONS</code><code class="p">,</code>
<code class="p">)</code>

<code class="c1"># Identifying all of the tables:</code>
<code class="n">agent_executor</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="s2">"Identify all of the tables"</code><code class="p">)</code>
<code class="c1"># 'The database contains the following tables:\n1. Orders\n2. Products\n3. Users'</code></pre>

<pre data-type="programlisting" data-code-language="python"><code class="n">user_sql</code> <code class="o">=</code> <code class="n">agent_executor</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code>
    <code class="sd">'''Add 5 new users to the database. Their names are:</code>
<code class="sd">    John, Mary, Peter, Paul, and Jane.'''</code>
<code class="p">)</code>
<code class="sd">'''Based on the schema of the "Users" table, I can see that the relevant</code>
<code class="sd">columns for adding new users are "FirstName", "LastName", "Email", and</code>
<code class="sd">"DateJoined". I will now run the SQL query to add the new</code>
<code class="sd">users.\n\n```sql\nINSERT INTO Users (FirstName, LastName, Email,</code>
<code class="sd">DateJoined)\nVALUES (\'John\', \'Doe\', \'john.doe@email.com\',</code>
<code class="sd">\'2023-05-01\'), \n(\'Mary\', \'Johnson\', \'mary.johnson@email.com\',</code>
<code class="sd">\'2023-05-02\'),\n (\'Peter\', \'Smith\', \'peter.smith@email.com\',</code>
<code class="sd">\'2023-05-03\'),\n (\'Paul\', \'Brown\', \'paul.brown@email.com\',</code>
<code class="sd">\'2023-05-04\'),\n (\'Jane\', \'Davis\', \'jane.davis@email.com\',</code>
<code class="sd">\'2023-05-05\');\n```\n\nPlease note that I have added the new users with</code>
<code class="sd">the specified names and email addresses. The "DateJoined" column is set to the</code>
<code class="sd">respective dates mentioned.'''</code></pre>

<p>First, the <code>agent_executor</code> inspects the SQL database to understand the database schema, and then the agent writes and executes a SQL statement that successfully adds five users into <a data-type="indexterm" data-primary="agent toolkits" data-startref="agttlk" id="id1069"/>the SQL table.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Customizing Standard Agents"><div class="sect1" id="id174">
<h1>Customizing Standard Agents</h1>

<p>It’s worth considering how to customize LangChain agents. Key function arguments can include <a data-type="indexterm" data-primary="agents" data-secondary="customizing" id="gtsctz"/>the following:</p>

<ul>
<li>
<p><code>prefix</code> and <code>suffix</code> are the prompt templates that are inserted directly into the agent.</p>
</li>
<li>
<p><code>max_iterations</code> and <code>max_execution_time</code> provide you with a way to limit API and compute costs in case an agent becomes stuck in an endless loop:</p>
</li>
</ul>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># This the function signature for demonstration purposes and is not executable.</code>
<code class="k">def</code> <code class="nf">create_sql_agent</code><code class="p">(</code>
    <code class="n">llm</code><code class="p">:</code> <code class="n">BaseLanguageModel</code><code class="p">,</code>
    <code class="n">toolkit</code><code class="p">:</code> <code class="n">SQLDatabaseToolkit</code><code class="p">,</code>
    <code class="n">agent_type</code><code class="p">:</code> <code class="n">Any</code> <code class="o">|</code> <code class="kc">None</code> <code class="o">=</code> <code class="kc">None</code><code class="p">,</code>
    <code class="n">callback_manager</code><code class="p">:</code> <code class="n">BaseCallbackManager</code> <code class="o">|</code> <code class="kc">None</code> <code class="o">=</code> <code class="kc">None</code><code class="p">,</code>
    <code class="n">prefix</code><code class="p">:</code> <code class="nb">str</code> <code class="o">=</code> <code class="n">SQL_PREFIX</code><code class="p">,</code>
    <code class="n">suffix</code><code class="p">:</code> <code class="nb">str</code> <code class="o">|</code> <code class="kc">None</code> <code class="o">=</code> <code class="kc">None</code><code class="p">,</code>
    <code class="n">format_instructions</code><code class="p">:</code> <code class="nb">str</code> <code class="o">|</code> <code class="kc">None</code> <code class="o">=</code> <code class="kc">None</code><code class="p">,</code>
    <code class="n">input_variables</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">str</code><code class="p">]</code> <code class="o">|</code> <code class="kc">None</code> <code class="o">=</code> <code class="kc">None</code><code class="p">,</code>
    <code class="n">top_k</code><code class="p">:</code> <code class="nb">int</code> <code class="o">=</code> <code class="mi">10</code><code class="p">,</code>
    <code class="n">max_iterations</code><code class="p">:</code> <code class="nb">int</code> <code class="o">|</code> <code class="kc">None</code> <code class="o">=</code> <code class="mi">15</code><code class="p">,</code>
    <code class="n">max_execution_time</code><code class="p">:</code> <code class="nb">float</code> <code class="o">|</code> <code class="kc">None</code> <code class="o">=</code> <code class="kc">None</code><code class="p">,</code>
    <code class="n">early_stopping_method</code><code class="p">:</code> <code class="nb">str</code> <code class="o">=</code> <code class="s2">"force"</code><code class="p">,</code>
    <code class="n">verbose</code><code class="p">:</code> <code class="nb">bool</code> <code class="o">=</code> <code class="kc">False</code><code class="p">,</code>
    <code class="n">agent_executor_kwargs</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">Any</code><code class="p">]</code> <code class="o">|</code> <code class="kc">None</code> <code class="o">=</code> <code class="kc">None</code><code class="p">,</code>
    <code class="n">extra_tools</code><code class="p">:</code> <code class="n">Sequence</code><code class="p">[</code><code class="n">BaseTool</code><code class="p">]</code> <code class="o">=</code> <code class="p">(),</code>
    <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code>
<code class="p">)</code> <code class="o">-&gt;</code> <code class="n">AgentExecutor</code></pre>

<p>Let’s update the previously created <code>agent_executor</code> so that the agent can perform more SQL statements. The <code>SQL_PREFIX</code> is directly inserted into the <span class="keep-together"><code>create_sql_agent</code></span> function as the <code>prefix</code>. Additionally, you’ll insert the recommended <code>user_sql</code> from the previous agent that wouldn’t directly run <code>INSERT</code>, <code>UPDATE</code>, or <code>EDIT</code> commands; however, the <a data-type="indexterm" data-primary="agents" data-secondary="customizing" data-startref="gtsctz" id="id1070"/>new agent will happily execute CRUD (create, read, update, delete) operations against the SQLite database:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">SQL_PREFIX</code> <code class="o">=</code> <code class="s2">"""You are an agent designed to interact with a SQL database.</code>
<code class="s2">Given an input question, create a syntactically correct </code><code class="si">{dialect}</code><code class="s2"> query to</code>
<code class="s2">run, then look at the results of the query and return the answer.</code>
<code class="s2">Unless the user specifies a specific number of examples they wish to obtain</code>
<code class="s2">always limit your query to at most </code><code class="si">{top_k}</code><code class="s2"> results. You can order the</code>
<code class="s2">results by a relevant column to return the most interesting examples in</code>
<code class="s2">the database. Never query for all the columns from a specific table, only</code>
<code class="s2">ask for the relevant columns given the question. You have access to tools</code>
<code class="s2">for interacting with the database. Only use the below tools. Only use the</code>
<code class="s2">information returned by the below tools to construct your final answer. You</code>
<code class="s2">MUST double-check your query before executing it. If you get an error while</code>
<code class="s2">executing a query, rewrite the query and try again. If the question does</code>
<code class="s2">not seem related to the database, just return "I don't know" as the answer.</code>
<code class="s2">"""</code>

<code class="n">agent_executor</code> <code class="o">=</code> <code class="n">create_sql_agent</code><code class="p">(</code>
    <code class="n">llm</code><code class="o">=</code><code class="n">ChatOpenAI</code><code class="p">(</code><code class="n">temperature</code><code class="o">=</code><code class="mi">0</code><code class="p">),</code>
    <code class="n">toolkit</code><code class="o">=</code><code class="n">toolkit</code><code class="p">,</code>
    <code class="n">verbose</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code>
    <code class="n">agent_type</code><code class="o">=</code><code class="n">AgentType</code><code class="o">.</code><code class="n">OPENAI_FUNCTIONS</code><code class="p">,</code>
    <code class="n">prefix</code><code class="o">=</code><code class="n">SQL_PREFIX</code><code class="p">,</code>
<code class="p">)</code>

<code class="n">agent_executor</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="n">user_sql</code><code class="p">)</code>
<code class="c1"># '...sql\nINSERT INTO Users (FirstName, LastName, Email,</code>
<code class="c1"># DateJoined)\nVALUES (...)...'</code>

<code class="c1"># Testing that Peter was inserted into the database:</code>
<code class="n">agent_executor</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="s2">"Do we have a Peter in the database?"</code><code class="p">)</code>
<code class="sd">'''Yes, we have a Peter in the database. Their details are as follows:\n-</code>
<code class="sd">First Name: Peter...'''</code></pre>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Custom Agents in LCEL"><div class="sect1" id="id175">
<h1>Custom Agents in LCEL</h1>

<p>It’s very easy to create a custom <a data-type="indexterm" data-primary="agents" data-secondary="custom, in LCEL" id="agtcmlc"/><a data-type="indexterm" data-primary="LCEL (LangChain Expression Language)" data-secondary="custom agents" id="lcxpsg"/><a data-type="indexterm" data-primary="LangChain Expression Language (LCEL)" data-secondary="custom agents" id="lgcxggel"/>agent using LCEL; let’s create a chat model with one tool:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain_openai</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>
<code class="kn">from</code> <code class="nn">langchain_core.tools</code> <code class="kn">import</code> <code class="n">tool</code>

<code class="c1"># 1. Create the model:</code>
<code class="n">llm</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">(</code><code class="n">temperature</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>

<code class="nd">@tool</code>
<code class="k">def</code> <code class="nf">get_word_length</code><code class="p">(</code><code class="n">word</code><code class="p">:</code> <code class="nb">str</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">int</code><code class="p">:</code>
    <code class="sd">"""Returns the length of a word."""</code>
    <code class="k">return</code> <code class="nb">len</code><code class="p">(</code><code class="n">word</code><code class="p">)</code>

<code class="c1"># 2. Create the tools:</code>
<code class="n">tools</code> <code class="o">=</code> <code class="p">[</code><code class="n">get_word_length</code><code class="p">]</code></pre>

<p>Next, you’ll set up the prompt with a system message, user message, and a <code>MessagesPlaceholder</code>, which allows the agent to store its intermediate steps:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain_core.prompts</code> <code class="kn">import</code> <code class="n">ChatPromptTemplate</code><code class="p">,</code> <code class="n">MessagesPlaceholder</code>

<code class="c1"># 3. Create the Prompt:</code>
<code class="n">prompt</code> <code class="o">=</code> <code class="n">ChatPromptTemplate</code><code class="o">.</code><code class="n">from_messages</code><code class="p">(</code>
    <code class="p">[</code>
        <code class="p">(</code>
            <code class="s2">"system"</code><code class="p">,</code>
            <code class="sd">"""You are very powerful assistant, but don't know current events</code>
<code class="sd">            and aren't good at calculating word length."""</code><code class="p">,</code>
        <code class="p">),</code>
        <code class="p">(</code><code class="s2">"user"</code><code class="p">,</code> <code class="s2">"</code><code class="si">{input}</code><code class="s2">"</code><code class="p">),</code>
        <code class="c1"># This is where the agent will write/read its messages from</code>
        <code class="n">MessagesPlaceholder</code><code class="p">(</code><code class="n">variable_name</code><code class="o">=</code><code class="s2">"agent_scratchpad"</code><code class="p">),</code>
    <code class="p">]</code>
<code class="p">)</code></pre>

<p>Before creating an agent, you’ll need to bind the tools directly to the LLM for function calling:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain_core.utils.function_calling</code> <code class="kn">import</code> <code class="n">convert_to_openai_tool</code>
<code class="kn">from</code> <code class="nn">langchain.agents.format_scratchpad.openai_tools</code> <code class="kn">import</code> <code class="p">(</code>
    <code class="n">format_to_openai_tool_messages</code><code class="p">,</code>
<code class="p">)</code>

<code class="c1"># 4. Formats the python function tools into JSON schema and binds</code>
<code class="c1"># them to the model:</code>
<code class="n">llm_with_tools</code> <code class="o">=</code> <code class="n">llm</code><code class="o">.</code><code class="n">bind_tools</code><code class="p">(</code><code class="n">tools</code><code class="o">=</code><code class="p">[</code><code class="n">convert_to_openai_tool</code><code class="p">(</code><code class="n">t</code><code class="p">)</code>
<code class="k">for</code> <code class="n">t</code> <code class="ow">in</code> <code class="n">tools</code><code class="p">])</code>

<code class="kn">from</code> <code class="nn">langchain.agents.output_parsers.openai_tools</code> \
<code class="kn">import</code> <code class="nn">OpenAIToolsAgentOutputParser</code>


<code class="c1"># 5. Setting up the agent chain:</code>
<code class="n">agent</code> <code class="o">=</code> <code class="p">(</code>
    <code class="p">{</code>
        <code class="s2">"input"</code><code class="p">:</code> <code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">x</code><code class="p">[</code><code class="s2">"input"</code><code class="p">],</code>
        <code class="s2">"agent_scratchpad"</code><code class="p">:</code> <code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">format_to_openai_tool_messages</code><code class="p">(</code>
            <code class="n">x</code><code class="p">[</code><code class="s2">"intermediate_steps"</code><code class="p">]</code>
        <code class="p">),</code>
    <code class="p">}</code>
    <code class="o">|</code> <code class="n">prompt</code>
    <code class="o">|</code> <code class="n">llm_with_tools</code>
    <code class="o">|</code> <code class="n">OpenAIToolsAgentOutputParser</code><code class="p">()</code>
<code class="p">)</code></pre>

<p>Here’s a step-by-step walk-through of the code:</p>
<dl>
<dt>1. Importing tool conversion function</dt>
<dd>
<p>You begin by importing <code>convert_to_openai_tool</code>. This allows you to convert Python function tools into a JSON schema, making them compatible with OpenAI’s LLMs.</p>
</dd>
<dt>2. Binding tools to your language model (LLM)</dt>
<dd>
<p>Next, you bind the tools to your LLM. By iterating over each tool in your <code>tools</code> list and converting them with <code>convert_to_openai_tool</code>, you effectively create <code>llm_with_tools</code>. This equips your LLM with the functionalities of the defined tools.</p>
</dd>
<dt>3. Importing agent formatting and parsing functions</dt>
<dd>
<p>Here, you import <code>format_to_openai_tool_messages</code> and <code>OpenAIToolsAgentOutputParser</code>. These format the agent’s scratchpad and parse the output from your LLM bound with tools.</p>
</dd>
<dt>4. Setting up your agent chain</dt>
<dd>
<p>In this final and crucial step, you set up the agent chain.</p>

<ul>
<li>
<p>You take the lead by processing the user’s input directly.</p>
</li>
<li>
<p>You then strategically format intermediate steps into OpenAI function messages.</p>
</li>
<li>
<p>The <code>llm_with_tools</code> will then be called.</p>
</li>
<li>
<p><code>OpenAIToolsAgentOutputParser</code> is used to parse the output.</p>
</li>
</ul>
</dd>
</dl>

<p>Finally, let’s create and use the <code>AgentExecutor</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain.agents</code> <code class="kn">import</code> <code class="n">AgentExecutor</code>

<code class="n">agent_executor</code> <code class="o">=</code> <code class="n">AgentExecutor</code><code class="p">(</code><code class="n">agent</code><code class="o">=</code><code class="n">agent</code><code class="p">,</code> <code class="n">tools</code><code class="o">=</code><code class="n">tools</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">agent_executor</code><code class="o">.</code><code class="n">invoke</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"How many letters in the word Software?"</code><code class="p">})</code>
<code class="c1">#{'input': 'How many letters in the word Software?',</code>
<code class="c1"># 'output': 'There are 8 letters in the word "Software".'}</code></pre>

<p>The LCEL agent uses the <code>.invoke(...)</code> function and correctly <a data-type="indexterm" data-primary="agents" data-secondary="custom, in LCEL" data-startref="agtcmlc" id="id1071"/><a data-type="indexterm" data-primary="LCEL (LangChain Expression Language)" data-secondary="custom agents" data-startref="lcxpsg" id="id1072"/><a data-type="indexterm" data-primary="LangChain Expression Language (LCEL)" data-secondary="custom agents" data-startref="lgcxggel" id="id1073"/>identifies that there are eight letters within the word <em>software</em>.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Understanding and Using Memory"><div class="sect1" id="id353">
<h1>Understanding and Using Memory</h1>

<p>When interacting with LLMs, understanding the role and importance of memory is paramount. It’s not just about how these models recall information but also about the strategic interplay between long-term (LTM) and short-term memory (STM).</p>








<section data-type="sect2" data-pdf-bookmark="Long-Term Memory"><div class="sect2" id="id98">
<h2>Long-Term Memory</h2>

<p>Think of long-term memory as the <a data-type="indexterm" data-primary="memory" data-secondary="long-term" id="id1074"/><a data-type="indexterm" data-primary="long-term memory" id="id1075"/>library of an LLM. It’s the vast, curated collection of data, storing everything from text to conceptual frameworks. This knowledge pool aids the model in comprehending and generating responses.</p>

<p>Applications include:</p>
<dl>
<dt>Vector databases</dt>
<dd>
<p>These databases can store <a data-type="indexterm" data-primary="vector databases" data-secondary="long-term memory" id="id1076"/>unstructured text data, providing the model with a reference point when generating content. By indexing and categorizing this data, LLMs can swiftly retrieve relevant information via <em>similarity distance metrics</em>.</p>
</dd>
<dt>Self-reflection</dt>
<dd>
<p>Advanced applications include an LLM that introspects, records, and stores thoughts. Imagine an LLM that meticulously observes user patterns on a book review platform and catalogs these as deep insights. Over time, it pinpoints preferences, such as favored genres and writing styles. These insights are stored and accessed using retrieval. When users seek book recommendations, the LLM, <em>powered by the retrieved context</em>, provides bespoke suggestions aligned with their tastes.</p>
</dd>
<dt>Custom retrievers</dt>
<dd>
<p>Creating specific retrieval functions can significantly boost an LLM’s efficiency. Drawing parallels with human memory systems, these functions can prioritize data based on its relevance, the elapsed time since the last memory, and its utility in achieving a particular objective.</p>
</dd>
</dl>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Short-Term Memory"><div class="sect2" id="id99">
<h2>Short-Term Memory</h2>

<p>Short-term memory in LLMs is akin to a <a data-type="indexterm" data-primary="memory" data-secondary="short-term" id="id1077"/><a data-type="indexterm" data-primary="short-term memory" id="id1078"/>temporary workspace. Here, recent interactions, active tasks, or ongoing conversations are kept at the forefront to ensure continuity and context.</p>

<p>Applications include:</p>
<dl>
<dt>Conversational histories</dt>
<dd>
<p>For chatbots, tracking <a data-type="indexterm" data-primary="conversational histories" id="id1079"/>conversational history is essential. It allows the bot to maintain context over multiple exchanges, preventing redundant queries and ensuring the conversation flows naturally.</p>
</dd>
<dt>Repetition avoidance</dt>
<dd>
<p>STM proves invaluable <a data-type="indexterm" data-primary="repetition avoidance" id="id1080"/>when similar or identical queries are posed by users. By referencing its short-term recall, the model can provide consistent answers or diversify its responses, based on the application’s requirement.</p>
</dd>
</dl>

<p>Having touched upon the foundational concepts of LTM and STM, let’s transition to practical applications, particularly in the realm of question-answer (QA) systems.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Short-Term Memory in QA Conversation Agents"><div class="sect2" id="id100">
<h2>Short-Term Memory in QA Conversation Agents</h2>

<p>Imagine Eva, a virtual customer support agent <a data-type="indexterm" data-primary="memory" data-secondary="short-term" data-tertiary="QA conversation agents" id="id1081"/><a data-type="indexterm" data-primary="short-term memory" data-secondary="QA conversation agents" id="id1082"/><a data-type="indexterm" data-primary="QA conversation agents" id="id1083"/>for an e-commerce platform. A user might have several interlinked queries:</p>
<ul class="simplelist">
<li>User: “How long is the return policy for electronics?”</li>
<li>Eva: “The return policy for electronics is 30 days.”</li>
<li>User: “What about for clothing items?”</li>
<li>Eva, leveraging STM: “For clothing items, it’s 45 days. Would you like to know about any other categories?”</li>
</ul>

<p>Notice that by utilizing short term memory (STM), Eva seamlessly continues the conversation, anticipating potential follow-up questions. This fluidity is only possible due to the effective deployment of short-term memory, allowing the agent to perceive conversations not as isolated QAs but as a cohesive interaction.</p>

<p>For developers and prompt engineers, understanding and harnessing this can significantly elevate the user experience, fostering engagements that are meaningful, efficient, and humanlike.</p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Memory in LangChain"><div class="sect1" id="id176">
<h1>Memory in LangChain</h1>

<p>LangChain provides easy techniques for <a data-type="indexterm" data-primary="memory" data-secondary="LangChain and" id="id1084"/><a data-type="indexterm" data-primary="LangChain" data-secondary="memory" id="id1085"/>adding memory to LLMs. As shown in <a data-type="xref" href="#fig-6-3">Figure 6-3</a>, every memory system in a chain is tasked with two fundamental operations: reading and storing.</p>

<p>It’s pivotal to understand that each chain has innate steps that demand particular inputs. While a user provides some of this data, the chain can also source other pieces of information from its memory.</p>

<figure><div id="fig-6-3" class="figure">
<img src="assets/pega_0603.png" alt="Memory within LangChain" width="600" height="227"/>
<h6><span class="label">Figure 6-3. </span>Memory within LangChain</h6>
</div></figure>

<p>In every operation of the chain, there are two crucial <a data-type="indexterm" data-primary="memory" data-secondary="LangChain and" data-tertiary="interactions" id="id1086"/><a data-type="indexterm" data-primary="LangChain" data-secondary="memory" data-tertiary="interactions" id="id1087"/>interactions with its memory:</p>

<ul>
<li>
<p><em>After collecting the initial user data but before executing</em>, the chain retrieves information from its memory, adding to the user’s input.</p>
</li>
<li>
<p><em>After the chain has completed but before returning the answer</em>, a chain will write the inputs and outputs of the current run to memory so that they can be referred to in future runs.</p>
</li>
</ul>

<p>There are two pivotal choices you’ll need to make when creating a memory system:</p>

<ul>
<li>
<p>The method of storing state</p>
</li>
<li>
<p>The approach to querying the memory state</p>
</li>
</ul>








<section data-type="sect2" data-pdf-bookmark="Preserving the State"><div class="sect2" id="id193">
<h2>Preserving the State</h2>

<p>Beneath the surface, the <a data-type="indexterm" data-primary="memory" data-secondary="LangChain and" data-tertiary="state and" id="mgctta"/><a data-type="indexterm" data-primary="LangChain" data-secondary="memory" data-tertiary="state and" id="lchmmst"/>foundational memory of generative AI models is structured as a sequence of chat messages. These messages can be stored in temporary in-memory lists or anchored in a more durable database. For those leaning toward long-term storage, there’s a wide range of <a href="https://oreil.ly/ECD_n">database integrations available</a>, streamlining the process and saving you from the hassle of manual integration.</p>

<p>With five to six lines of code, you can easily integrate a <code>MongoDBChatMessageHistory</code> that’s unique based on a <code>session_id</code> parameter:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># Provide the connection string to connect to the MongoDB database.</code>
<code class="n">connection_string</code> <code class="o">=</code> <code class="s2">"mongodb://mongo_user:password123@mongo:27017"</code>

<code class="n">chat_message_history</code> <code class="o">=</code> <code class="n">MongoDBChatMessageHistory</code><code class="p">(</code>
    <code class="n">session_id</code><code class="o">=</code><code class="s2">"test_session"</code><code class="p">,</code>
    <code class="n">connection_string</code><code class="o">=</code><code class="n">connection_string</code><code class="p">,</code>
    <code class="n">database_name</code><code class="o">=</code><code class="s2">"my_db"</code><code class="p">,</code>
    <code class="n">collection_name</code><code class="o">=</code><code class="s2">"chat_histories"</code><code class="p">,</code>
<code class="p">)</code>

<code class="n">chat_message_history</code><code class="o">.</code><code class="n">add_user_message</code><code class="p">(</code><code class="s2">"I love programming!!"</code><code class="p">)</code>
<code class="n">chat_message_history</code><code class="o">.</code><code class="n">add_ai_message</code><code class="p">(</code><code class="s2">"What do you like about it?"</code><code class="p">)</code>

<code class="n">chat_message_history</code><code class="o">.</code><code class="n">messages</code>
<code class="c1"># [HumanMessage(content='I love programming!!',</code>
<code class="c1"># AIMessage(content='What do you like about it?')</code></pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Querying the State"><div class="sect2" id="id194">
<h2>Querying the State</h2>

<p>A basic memory framework might merely relay the latest messages with every interaction. A slightly more nuanced setup might distill a crisp synopsis of the last set of messages. An even more advanced setup would discern specific entities from dialogue and relay only data about those entities highlighted in the ongoing session.</p>

<p>Different applications require varying demands on memory querying. LangChain’s memory toolkit will help you to create <a data-type="indexterm" data-primary="memory" data-secondary="LangChain and" data-tertiary="state and" data-startref="mgctta" id="id1088"/><a data-type="indexterm" data-primary="LangChain" data-secondary="memory" data-tertiary="state and" data-startref="lchmmst" id="id1089"/>simplistic memory infrastructures while empowering you to architect bespoke systems when necessary.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="ConversationBufferMemory"><div class="sect2" id="id101">
<h2>ConversationBufferMemory</h2>

<p>There are various types of memory <a data-type="indexterm" data-primary="memory" data-secondary="LangChain and" data-tertiary="ConversationBufferMemory" id="mlgcvbmm"/><a data-type="indexterm" data-primary="LangChain" data-secondary="memory" data-tertiary="ConversationBufferMemory" id="cvbffgc"/><a data-type="indexterm" data-primary="ConversationBufferMemory" id="cvsbfmmy"/>within LangChain, and one of the most popular is ConversationBufferMemory. This allows you to store multiple chat messages with no restriction on chat history size.</p>

<p>Start by importing <code>ConversationBufferMemory</code>, and you can then add context with the <code>save_context</code> function. The <code>load_memory_variables</code> function returns a Python dictionary containing the <code>Human</code> and <code>AI</code> messages:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain.memory</code> <code class="kn">import</code> <code class="n">ConversationBufferMemory</code>
<code class="n">memory</code> <code class="o">=</code> <code class="n">ConversationBufferMemory</code><code class="p">()</code>
<code class="n">memory</code><code class="o">.</code><code class="n">save_context</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"hi"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"output"</code><code class="p">:</code> <code class="s2">"whats up"</code><code class="p">})</code>
<code class="n">memory</code><code class="o">.</code><code class="n">load_memory_variables</code><code class="p">({})</code>
<code class="c1"># {'history': 'Human: hi\nAI: whats up'}</code></pre>

<p>You can also return the LangChain schema messages, i.e., <code>SystemMessage</code>, <code>AIMessage</code> or <code>HumanMessage</code>, by adding <code>return_messages=True</code> to <code>ConversationBufferMemory</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">memory</code> <code class="o">=</code> <code class="n">ConversationBufferMemory</code><code class="p">(</code><code class="n">return_messages</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">memory</code><code class="o">.</code><code class="n">save_context</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"hi"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"output"</code><code class="p">:</code> <code class="s2">"whats up"</code><code class="p">})</code>
<code class="n">memory</code><code class="o">.</code><code class="n">load_memory_variables</code><code class="p">({})</code>
<code class="c1"># {'history': [HumanMessage(content='hi'),</code>
<code class="c1"># AIMessage(content='whats up')]}</code></pre>

<p class="less_space pagebreak-before">Let’s add memory directly to a chain in LCEL:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># Using within a chain:</code>
<code class="kn">from</code> <code class="nn">langchain.memory</code> <code class="kn">import</code> <code class="n">ConversationBufferMemory</code>
<code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>
<code class="kn">from</code> <code class="nn">langchain_core.prompts</code> <code class="kn">import</code> <code class="n">ChatPromptTemplate</code><code class="p">,</code> <code class="n">MessagesPlaceholder</code>
<code class="kn">from</code> <code class="nn">langchain_core.output_parsers</code> <code class="kn">import</code> <code class="n">StrOutputParser</code>
<code class="kn">from</code> <code class="nn">langchain_core.runnables</code> <code class="kn">import</code> <code class="n">RunnableLambda</code>
<code class="kn">from</code> <code class="nn">operator</code> <code class="kn">import</code> <code class="n">itemgetter</code>

<code class="n">memory</code> <code class="o">=</code> <code class="n">ConversationBufferMemory</code><code class="p">(</code><code class="n">return_messages</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>

<code class="n">model</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">(</code><code class="n">temperature</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>
<code class="n">prompt</code> <code class="o">=</code> <code class="n">ChatPromptTemplate</code><code class="o">.</code><code class="n">from_messages</code><code class="p">(</code>
    <code class="p">[</code>
        <code class="p">(</code><code class="s2">"system"</code><code class="p">,</code> <code class="s2">"Act as a chatbot that helps users with their queries."</code><code class="p">),</code>
        <code class="c1"># The history of the conversation</code>
        <code class="n">MessagesPlaceholder</code><code class="p">(</code><code class="n">variable_name</code><code class="o">=</code><code class="s2">"history"</code><code class="p">),</code>
        <code class="p">(</code><code class="s2">"human"</code><code class="p">,</code> <code class="s2">"</code><code class="si">{input}</code><code class="s2">"</code><code class="p">),</code>
    <code class="p">]</code>
<code class="p">)</code>
<code class="n">chain</code> <code class="o">=</code> <code class="p">(</code>
    <code class="p">{</code>
        <code class="s2">"input"</code><code class="p">:</code> <code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">x</code><code class="p">[</code><code class="s2">"input"</code><code class="p">],</code>
        <code class="s2">"history"</code><code class="p">:</code> <code class="n">RunnableLambda</code><code class="p">(</code><code class="n">memory</code><code class="o">.</code><code class="n">load_memory_variables</code><code class="p">)</code> <code class="o">|</code> \
        <code class="n">itemgetter</code><code class="p">(</code><code class="s2">"history"</code><code class="p">),</code>
    <code class="p">}</code>
    <code class="o">|</code> <code class="n">prompt</code>
    <code class="o">|</code> <code class="n">model</code>
    <code class="o">|</code> <code class="n">StrOutputParser</code><code class="p">()</code>
<code class="p">)</code></pre>

<p>Notice the <code>MessagesPlaceholder</code> has a <code>variable_name</code> of
<code>"history"</code>. This is aligned with the <code>memory</code> key within <code>ConversationBufferMemory</code>, allowing the previous chat history to be directly formatted into the <code>ChatPromptTemplate</code>.</p>

<p>After setting up the LCEL chain, let’s invoke it and save the messages to the <code>memory</code> variable:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">inputs</code> <code class="o">=</code> <code class="p">{</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"Hi my name is James!"</code><code class="p">}</code>
<code class="n">result</code> <code class="o">=</code> <code class="n">chain</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="n">inputs</code><code class="p">)</code>
<code class="n">memory</code><code class="o">.</code><code class="n">save_context</code><code class="p">(</code><code class="n">inputs</code><code class="p">,</code> <code class="p">{</code><code class="s2">"outputs"</code><code class="p">:</code> <code class="n">result</code><code class="p">})</code>
<code class="nb">print</code><code class="p">(</code><code class="n">memory</code><code class="o">.</code><code class="n">load_memory_variables</code><code class="p">({}))</code>

<code class="c1"># {'history': [HumanMessage(content='Hi my name is James!'),</code>
<code class="c1"># AIMessage(content='Hello James! How can I assist you today?')]}</code></pre>

<p>The memory has two messages, a <code>HumanMessage</code> and an <code>AIMessage</code>; both are saved to memory by using the <code>save_context</code> function. Let’s test whether the LCEL chain is able to use previous context to answer new questions:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">inputs</code> <code class="o">=</code> <code class="p">{</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"What is my name?"</code><code class="p">}</code>
<code class="n">second_result</code> <code class="o">=</code> <code class="n">chain</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="n">inputs</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="n">second_result</code><code class="p">)</code>
<code class="c1"># Your name is James.</code></pre>

<p>The LCEL chain is now able to use previous messages to answer new queries!</p>

<p>Furthermore, you can easily add memory to an agent by adding a <code>MessagesPlaceHolder</code> to the <code>ChatPromptTemplate</code> and adding memory to the <code>AgentExecutor</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">prompt</code> <code class="o">=</code> <code class="n">ChatPromptTemplate</code><code class="o">.</code><code class="n">from_messages</code><code class="p">(</code>
    <code class="p">[</code>
        <code class="p">(</code>
            <code class="s2">"system"</code><code class="p">,</code>
            <code class="sd">"""You are a very powerful assistant, but don't know current events</code>
<code class="sd">and aren't good at calculating word length."""</code><code class="p">,</code>
        <code class="p">),</code>
        <code class="c1"># This is where the agent will write/read its messages from</code>
        <code class="n">MessagesPlaceholder</code><code class="p">(</code><code class="n">variable_name</code><code class="o">=</code><code class="s2">"agent_scratchpad"</code><code class="p">),</code>
        <code class="n">MessagesPlaceholder</code><code class="p">(</code><code class="n">variable_name</code><code class="o">=</code><code class="s2">"history"</code><code class="p">),</code>
        <code class="p">(</code><code class="s2">"user"</code><code class="p">,</code> <code class="s2">"</code><code class="si">{input}</code><code class="s2">"</code><code class="p">),</code>
    <code class="p">]</code>
<code class="p">)</code>

<code class="c1"># ... The rest of the code remains the same as before ...</code>

<code class="c1"># Create an agent executor by passing in the agent, tools, and memory:</code>
<code class="n">memory</code> <code class="o">=</code> <code class="n">ConversationBufferMemory</code><code class="p">(</code><code class="n">return_messages</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">agent_executor</code> <code class="o">=</code> <code class="n">AgentExecutor</code><code class="p">(</code><code class="n">agent</code><code class="o">=</code><code class="n">agent</code><code class="p">,</code> <code class="n">tools</code><code class="o">=</code><code class="n">tools</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code>
<code class="n">memory</code><code class="o">=</code><code class="n">memory</code><code class="p">)</code></pre>

<p>You can view the full implementation within this <a href="https://oreil.ly/LXQNy">Jupyter Notebook</a>.</p>

<p>By leveraging this memory, your agent delivers a more context-aware and fluid conversational experience, negating the need for additional tools to recall past interactions.</p>

<p>ConversationBufferMemory doesn’t have a buffer limit, but different memory types such as ConversationSummaryBufferMemory allow you specify a maximum token limit, after which the conversation is summarized:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain.memory</code> <code class="kn">import</code> <code class="n">ConversationBufferMemory</code>

<code class="n">memory</code> <code class="o">=</code> <code class="n">ConversationBufferMemory</code><code class="p">()</code>
<code class="n">memory</code><code class="o">.</code><code class="n">save_context</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"hi"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"output"</code><code class="p">:</code> <code class="s2">"whats up"</code><code class="p">})</code>
<code class="n">memory</code><code class="o">.</code><code class="n">load_memory_variables</code><code class="p">({})</code>
<code class="c1"># {'history': 'Human: hi\nAI: whats up'}</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>By default, memory is stored locally within the Python process. This approach is inherently transient and limited by the session or process lifespan. For applications requiring continuity over time and the ability to learn from historical data, a shift to database-backed memory <a data-type="indexterm" data-primary="memory" data-secondary="LangChain and" data-tertiary="ConversationBufferMemory" data-startref="mlgcvbmm" id="id1090"/><a data-type="indexterm" data-primary="LangChain" data-secondary="memory" data-tertiary="ConversationBufferMemory" data-startref="cvbffgc" id="id1091"/><a data-type="indexterm" data-primary="ConversationBufferMemory" data-startref="cvsbfmmy" id="id1092"/>becomes essential.</p>

<p>There are several integrations available for <a href="https://oreil.ly/nTBox">database-backed memory</a>, which transition the memory usage from a short-term, session-specific context to a more robust, long-term storage solution.</p>
</div>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Other Popular Memory Types in LangChain"><div class="sect1" id="id354">
<h1>Other Popular Memory Types in LangChain</h1>

<p>While ConversationBufferMemory is a well-known memory type, it has limitations such as context length limits, potential lack of relevance, and lack of summarization. To address these issues, LangChain offers several other memory types.</p>








<section data-type="sect2" data-pdf-bookmark="ConversationBufferWindowMemory"><div class="sect2" id="id102">
<h2>ConversationBufferWindowMemory</h2>

<p>This type maintains a sliding window of the <a data-type="indexterm" data-primary="memory" data-secondary="LangChain and" data-tertiary="ConversationBufferWindowMemory" id="id1093"/><a data-type="indexterm" data-primary="LangChain" data-secondary="memory" data-tertiary="ConversationBufferWindowMemory" id="id1094"/><a data-type="indexterm" data-primary="ConversationBufferWindowMemory" id="id1095"/>most recent interactions, ensuring the buffer doesn’t grow excessively large. Features include the following:</p>

<ul>
<li>
<p>Keeps only the last <code>K</code> interactions</p>
</li>
<li>
<p>Can return history as either a string or a list of messages</p>
</li>
</ul>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain.memory</code> <code class="kn">import</code> <code class="n">ConversationBufferWindowMemory</code>

<code class="n">memory</code> <code class="o">=</code> <code class="n">ConversationBufferWindowMemory</code><code class="p">(</code><code class="n">k</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="n">memory</code><code class="o">.</code><code class="n">save_context</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"hi"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"output"</code><code class="p">:</code> <code class="s2">"whats up"</code><code class="p">})</code>
<code class="n">memory</code><code class="o">.</code><code class="n">save_context</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"not much you"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"output"</code><code class="p">:</code> <code class="s2">"not much"</code><code class="p">})</code>
<code class="c1"># Returns: {'history': 'Human: not much you\nAI: not much'}</code>
<code class="n">memory</code><code class="o">.</code><code class="n">load_memory_variables</code><code class="p">({})</code></pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="ConversationSummaryMemory"><div class="sect2" id="id103">
<h2>ConversationSummaryMemory</h2>

<p>This one condenses and summarizes the conversation <a data-type="indexterm" data-primary="memory" data-secondary="LangChain and" data-tertiary="ConversationSummaryMemory" id="id1096"/><a data-type="indexterm" data-primary="LangChain" data-secondary="memory" data-tertiary="ConversationSummaryMemory" id="id1097"/><a data-type="indexterm" data-primary="ConversationSummaryMemory" id="id1098"/>over time and is ideal for longer conversations where verbatim message history would be token-expensive. Features include the following:</p>

<ul>
<li>
<p>Summarizes conversation on the fly</p>
</li>
<li>
<p>Can return history as a summary string or a list of system messages</p>
</li>
<li>
<p>Allows direct prediction of new summaries</p>
</li>
<li>
<p>Can be initialized with existing messages or summaries</p>
</li>
</ul>

<pre data-type="programlisting" data-code-language="python" class="less_space pagebreak-before"><code class="kn">from</code> <code class="nn">langchain.memory</code> <code class="kn">import</code> <code class="n">ConversationSummaryMemory</code><code class="p">,</code> <code class="n">ChatMessageHistory</code>
<code class="kn">from</code> <code class="nn">langchain_openai</code> <code class="kn">import</code> <code class="n">OpenAI</code>

<code class="n">memory</code> <code class="o">=</code> <code class="n">ConversationSummaryMemory</code><code class="p">(</code><code class="n">llm</code><code class="o">=</code><code class="n">OpenAI</code><code class="p">(</code><code class="n">temperature</code><code class="o">=</code><code class="mi">0</code><code class="p">))</code>
<code class="n">memory</code><code class="o">.</code><code class="n">save_context</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"hi"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"output"</code><code class="p">:</code> <code class="s2">"whats up"</code><code class="p">})</code>
<code class="n">memory</code><code class="o">.</code><code class="n">load_memory_variables</code><code class="p">({})</code>
<code class="c1"># Returns: {'history': '\nThe human greets the AI, to which the AI responds.'}</code></pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="ConversationSummaryBufferMemory"><div class="sect2" id="id104">
<h2>ConversationSummaryBufferMemory</h2>

<p>This is a hybrid memory that maintains <a data-type="indexterm" data-primary="memory" data-secondary="LangChain and" data-tertiary="ConversationSummaryBufferMemory" id="id1099"/><a data-type="indexterm" data-primary="LangChain" data-secondary="memory" data-tertiary="ConversationSummaryBufferMemory" id="id1100"/><a data-type="indexterm" data-primary="ConversationSummaryBufferMemory" id="id1101"/>a buffer of recent interactions but also compiles older interactions into a summary.</p>

<p>Features include the following:</p>

<ul>
<li>
<p>Uses token length to determine when to flush interactions</p>
</li>
<li>
<p>Can return history as a summary with recent interactions or a list of messages</p>
</li>
<li>
<p>Allows direct prediction of new summaries</p>
</li>
</ul>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain.memory</code> <code class="kn">import</code> <code class="n">ConversationSummaryBufferMemory</code>
<code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>

<code class="n">memory</code> <code class="o">=</code> <code class="n">ConversationSummaryBufferMemory</code><code class="p">(</code><code class="n">llm</code><code class="o">=</code><code class="n">ChatOpenAI</code><code class="p">(),</code> <code class="n">max_token_limit</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>
<code class="n">memory</code><code class="o">.</code><code class="n">save_context</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"hi"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"output"</code><code class="p">:</code> <code class="s2">"whats up"</code><code class="p">})</code>
<code class="n">memory</code><code class="o">.</code><code class="n">load_memory_variables</code><code class="p">({})</code>
<code class="c1"># Returns: {'history': 'System: \nThe human says "hi", and the AI responds with</code>
<code class="c1"># "whats up".\nHuman: not much you\nAI: not much'}</code></pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="ConversationTokenBufferMemory"><div class="sect2" id="id105">
<h2>ConversationTokenBufferMemory</h2>

<p>This one keeps a buffer of recent <a data-type="indexterm" data-primary="memory" data-secondary="LangChain and" data-tertiary="ConversationTokenBufferMemory" id="id1102"/><a data-type="indexterm" data-primary="LangChain" data-secondary="memory" data-tertiary="ConversationTokenBufferMemory" id="id1103"/><a data-type="indexterm" data-primary="ConversationTokenBufferMemory" id="id1104"/>interactions using token length to determine when to flush interactions.</p>

<p>Features include the following:</p>

<ul>
<li>
<p>Uses token length for flushing</p>
</li>
<li>
<p>Can return history as a string or a list of messages</p>
</li>
</ul>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain.memory</code> <code class="kn">import</code> <code class="n">ConversationTokenBufferMemory</code>
<code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>

<code class="n">memory</code> <code class="o">=</code> <code class="n">ConversationTokenBufferMemory</code><code class="p">(</code><code class="n">llm</code><code class="o">=</code><code class="n">ChatOpenAI</code><code class="p">(),</code>
<code class="n">max_token_limit</code><code class="o">=</code><code class="mi">50</code><code class="p">)</code>
<code class="n">memory</code><code class="o">.</code><code class="n">save_context</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"hi"</code><code class="p">},</code> <code class="p">{</code><code class="s2">"output"</code><code class="p">:</code> <code class="s2">"whats up"</code><code class="p">})</code>
<code class="n">memory</code><code class="o">.</code><code class="n">load_memory_variables</code><code class="p">({})</code>
<code class="c1"># Returns: {'history': 'Human: not much you\nAI: not much'}</code></pre>

<p class="less_space pagebreak-before">You’ve learned about the importance of memory in LangChain. Also, you now understand how to build and customize a memory system using LangChain’s memory toolkit, including methods of storing state and querying memory; you’ve seen examples on integrating MongoDBChatMessageHistory and utilizing the versatile ConversationBufferMemory.</p>

<p>Let’s summarize the different memory types available in LangChain and when they might be particularly useful:</p>
<dl>
<dt>ConversationBufferWindowMemory</dt>
<dd>
<p>This memory type maintains the most recent interactions, thus proving useful in cases where the context of the conversation is essential without letting the buffer grow extensively large.</p>
</dd>
<dt>ConversationSummaryMemory</dt>
<dd>
<p>Ideal for extended conversations, this memory type provides summarized versions of the conversation, saving valuable token space.</p>
</dd>
<dt>ConversationSummaryBufferMemory</dt>
<dd>
<p>Convenient for situations where you not only want to maintain a record of recent interactions but also want to compile older interactions into a summary, thereby offering a hybrid approach.</p>
</dd>
<dt>ConversationTokenBufferMemory</dt>
<dd>
<p>This memory type is useful when defining a specific token length is vital and a buffer of recent interactions needs to be maintained. It determines when to flush interactions based on token length.</p>
</dd>
</dl>

<p>Understanding the different memory options available can help you choose the most suitable one for your exact needs, depending on the situation.</p>
<div data-type="tip"><h1>Give Direction</h1>
<p>Even as you’re determining which <a data-type="indexterm" data-primary="Give Direction principle" data-secondary="LangChain memory types" id="id1105"/>memory type to use, remember to direct the AI model appropriately. For instance, with ConversationBufferWindowMemory, you would need to specify the number of recent interactions (<code>K</code>) you want to keep. Be clear about your requirements for optimal results.</p>
</div>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="OpenAI Functions Agent with Memory"><div class="sect1" id="id177">
<h1>OpenAI Functions Agent with Memory</h1>

<p>Dive deeper into agents with a comprehensive <a data-type="indexterm" data-primary="memory" data-secondary="OpenAI functions agent" id="mopafgnt"/><a data-type="indexterm" data-primary="OpenAI functions" data-secondary="memory and" id="opfmy"/><a data-type="indexterm" data-primary="agents" data-secondary="OpenAI memory" id="gtpmmy"/>example available on <a href="https://oreil.ly/jyLab">GitHub</a>. In this example, you’ll uncover how OpenAI integrates several <span class="keep-together">essential</span> components:</p>

<ul class="less_space pagebreak-before">
<li>
<p>Memory management using chat messages</p>
</li>
<li>
<p>Use tools such as API requests and file saving that can handle multiple function parameters</p>
</li>
<li>
<p>Integrate a custom <code>SystemMessage</code> to guide and define the agent’s behavior</p>
</li>
</ul>

<p>To illustrate, consider how a Python function’s docstring is utilized to provide a tool’s description:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain.tools</code> <code class="kn">import</code> <code class="n">StructuredTool</code>

<code class="k">def</code> <code class="nf">save_interview</code><code class="p">(</code><code class="n">raw_interview_text</code><code class="p">:</code> <code class="nb">str</code><code class="p">):</code>
    <code class="sd">"""Tool to save the interview. You must pass the entire interview and</code>
<code class="sd">    conversation in here. The interview will then be saved to a local file.</code>
<code class="sd">    Remember to include all of the previous chat messages. Include all of</code>
<code class="sd">    the messages with the user and the AI, here is a good response:</code>
<code class="sd">    AI: some text</code>
<code class="sd">    Human: some text</code>
<code class="sd">    ...</code>
<code class="sd">    ---</code>
<code class="sd">    """</code>
    <code class="c1"># Save to local file:</code>
    <code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="s2">"interview.txt"</code><code class="p">,</code> <code class="s2">"w"</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>
        <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">raw_interview_text</code><code class="p">)</code>
    <code class="k">return</code> <code class="sa">f</code><code class="s1">'''Interview saved! Content: </code><code class="si">{</code><code class="n">raw_interview_text</code><code class="si">}</code><code class="s1">. File:</code>
<code class="s1">    interview.txt. You must tell the user that the interview is saved.'''</code>

<code class="n">save_interview</code> <code class="o">=</code> <code class="n">StructuredTool</code><code class="o">.</code><code class="n">from_function</code><code class="p">(</code><code class="n">save_interview</code><code class="p">)</code></pre>

<p><code>StructuredTool.from_function()</code> will create a LangChain tool that’s capable of accepting multiple function arguments.</p>
<div data-type="tip"><h1>Give Direction and Specify Format</h1>
<p>The docstring within the Python function <a data-type="indexterm" data-primary="Give Direction principle" data-secondary="OpenAI functions agent" id="id1106"/><a data-type="indexterm" data-primary="Specify Format principle" data-secondary="OpenAI functions agent" id="id1107"/>showcases a designated format guiding the LLM on the content to use for the <code>raw_interview_text</code> parameter.</p>

<p>Additionally, the <code>return</code> statement emphasizes instructing the LLM to inform the user that the interview has been stored. This ensures the agent returns a more conversational response post-tool execution.</p>
</div>

<p>To further demonstrate prompt engineering techniques, let’s examine another Python code snippet from the notebook:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">pydantic.v1</code> <code class="kn">import</code> <code class="n">BaseModel</code>
<code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">Union</code><code class="p">,</code> <code class="n">Literal</code><code class="p">,</code> <code class="n">Type</code>
<code class="kn">from</code> <code class="nn">langchain_core.tools</code> <code class="kn">import</code> <code class="n">BaseTool</code>

<code class="k">class</code> <code class="nc">ArgumentType</code><code class="p">(</code><code class="n">BaseModel</code><code class="p">):</code>
    <code class="n">url</code><code class="p">:</code> <code class="nb">str</code>
    <code class="n">file_type</code><code class="p">:</code> <code class="n">Union</code><code class="p">[</code><code class="n">Literal</code><code class="p">[</code><code class="s2">"pdf"</code><code class="p">],</code> <code class="n">Literal</code><code class="p">[</code><code class="s2">"txt"</code><code class="p">]]</code>

<code class="k">class</code> <code class="nc">SummarizeFileFromURL</code><code class="p">(</code><code class="n">BaseTool</code><code class="p">):</code>
    <code class="n">name</code> <code class="o">=</code> <code class="s2">"SummarizeFileFromURL"</code>
    <code class="n">description</code> <code class="o">=</code> <code class="s2">"Summarize a file from a URL."</code>
    <code class="n">args_schema</code><code class="p">:</code> <code class="n">Type</code><code class="p">[</code><code class="n">ArgumentType</code><code class="p">]</code> <code class="o">=</code> <code class="n">ArgumentType</code></pre>

<p>In this example, <code>args_schema</code> is used within the <code>SummarizeFileFromURL</code> class. This attribute leverages the <code>ArgumentType</code> class, ensuring that the tool’s arguments are validated before execution. Specifically, it enforces that a valid URL string be provided and that the <code>file_type</code> argument should be either <code>"pdf"</code> or <code>"txt"</code>.</p>

<p>By adding validation checks, you can guarantee that the agent processes functional arguments correctly, which, in turn, enhances the overall reliability and efficiency of tool <a data-type="indexterm" data-primary="memory" data-secondary="OpenAI functions agent" data-startref="mopafgnt" id="id1108"/><a data-type="indexterm" data-primary="OpenAI functions" data-secondary="memory and" data-startref="opfmy" id="id1109"/><a data-type="indexterm" data-primary="agents" data-secondary="OpenAI memory" data-startref="gtpmmy" id="id1110"/>execution.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Advanced Agent Frameworks"><div class="sect1" id="id355">
<h1>Advanced Agent Frameworks</h1>

<p>You now know about ReAct and OpenAI functions, but there are several other agent frameworks. Two other popular frameworks include <em>plan and execute agents</em> and <em>tree of thoughts</em>.</p>








<section data-type="sect2" data-pdf-bookmark="Plan-and-Execute Agents"><div class="sect2" id="id106">
<h2>Plan-and-Execute Agents</h2>

<p>Rather than have the LLM do the <a data-type="indexterm" data-primary="agents" data-secondary="plan-and-execute" id="agplaxc"/><a data-type="indexterm" data-primary="plan-and-execute agent frameworks" id="plxgrfwk"/>task planning and tool execution, you can separate this into two separate modules. Each module can be handled separately by an individual LLM that has access to the objective, current tasks, and completed tasks.</p>

<p>Two popular versions of the plan-and-execute framework include <a href="https://oreil.ly/xeijG">BabyAGI</a> and <a href="https://oreil.ly/M4z8K">AutoGPT</a>.</p>

<p><a data-type="xref" href="#fig-6-4">Figure 6-4</a> showcases BabyAGI’s agent setup, which is designed to merge OpenAI LLMs with vector databases such as Chroma/Weaviate to create a robust, adaptive task management system.</p>

<p>In a continuous loop, the agent starts by fetching a task and passes it to the <code>execution_agent</code>, which taps into OpenAI to perform the task based on contextual data. After this, the outcomes are enriched and archived in Chroma/Weaviate.</p>

<p>The <code>task_creation_agent</code> then steps in, utilizing OpenAI to discern new tasks from the objective and results of the prior task. These tasks are presented as a list of dictionaries, giving structure to the resultant tasks.</p>

<p>The <code>prioritization_agent</code> then interacts with OpenAI to rearrange the task list, ensuring alignment with the main objective. The synergy of these agents ensures that the system is always evolving, continuously generating and prioritizing tasks in an informed manner. Integrating <a href="https://oreil.ly/9R3pU">Chroma</a> or <span class="keep-together"><a href="https://oreil.ly/2wu-y">Weaviate</a> plays</span>  a crucial role by offering a reservoir of contextual data, ensuring that tasks are always aligned with their predefined goals.</p>

<figure><div id="fig-6-4" class="figure">
<img src="assets/pega_0604.png" alt="BabyAGI" width="600" height="549"/>
<h6><span class="label">Figure 6-4. </span>BabyAGI’s agent architecture</h6>
</div></figure>

<p>The <a href="https://oreil.ly/8vYF5">plan-and-execute agent type</a> does <a data-type="indexterm" data-primary="agents" data-secondary="plan-and-execute" data-startref="agplaxc" id="id1111"/><a data-type="indexterm" data-primary="plan-and-execute agent frameworks" data-startref="plxgrfwk" id="id1112"/>exist within LangChain, though it’s still experimental.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Tree of Thoughts"><div class="sect2" id="id107">
<h2>Tree of Thoughts</h2>

<p>As the application of language models <a data-type="indexterm" data-primary="agents" data-secondary="ToT (Tree of Thoughts)" id="gttrghs"/><a data-type="indexterm" data-primary="ToT (Tree of Thoughts) agent frameworks" id="tttghmw"/>in problem-solving expands across diverse tasks, their inference method remains bound to token-level, linear processing. This approach, while effective in many contexts, is limited when faced with tasks that need advanced strategic foresight or where the initial decisions are crucial. The <a href="https://oreil.ly/1rYDI">Tree of Thoughts (ToT) framework</a> is a novel way to harness language models that goes beyond the conventional chain-of-thought prompting technique (<a data-type="xref" href="#fig-6-5">Figure 6-5</a>).</p>

<p>The central premise of ToT is to enable exploration across coherent text chunks, termed <em>thoughts</em>. These thoughts represent stages in problem-solving, facilitating the language model to undertake a more deliberate decision-making process. Instead of sticking to one reasoning path, the model can explore various reasoning trajectories, self-assessing its decisions at each step. The framework is designed to allow for forward planning, revisiting past decisions, and making overarching choices.</p>

<figure><div id="fig-6-5" class="figure">
<img src="assets/pega_0605.png" alt="Tree of Thoughts" width="600" height="352"/>
<h6><span class="label">Figure 6-5. </span>Tree of Thoughts (ToT)</h6>
</div></figure>

<p>Evidence of its success comes from experimental results on tasks requiring intricate planning or searching capabilities. In a game like <em>game of 24</em>, the traditional GPT-4, when prompted using chain-of-thought, managed a 4% success rate. In contrast, the ToT approach skyrocketed this figure to an impressive 74%. This paradigm shift isn’t limited to games. The ToT method also showed promise in areas like creative writing and mini crosswords, underscoring its versatility.</p>

<p>Complementing the theory is a <a href="https://oreil.ly/fub1z">LangChain implementation</a>, which gives a glimpse into how ToT can be actualized. A sudoku puzzle serves as the illustrative example, with the main aim to replace wildcard characters (*) with numbers, while adhering to sudoku rules.</p>

<p>ToT is not just a new method; it’s a paradigm shift in how we envision language model inference. By providing models the capacity to think, backtrack, and strategize, ToT is redefining the boundaries of AI problem-solving.</p>

<p>If you consider ToT as a strategy for commanding LLMs, LangChain callbacks can be viewed as tools to diagnose and ensure the smooth operation of these strategies. Let’s dive into how you <a data-type="indexterm" data-primary="agents" data-secondary="ToT (Tree of Thoughts)" data-startref="gttrghs" id="id1113"/><a data-type="indexterm" data-primary="ToT (Tree of Thoughts) agent frameworks" data-startref="tttghmw" id="id1114"/>can harness this feature effectively.</p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Callbacks"><div class="sect1" id="id108">
<h1>Callbacks</h1>

<p>LangChain’s <a href="https://oreil.ly/8EhXl"><em>callbacks</em></a> empower you <a data-type="indexterm" data-primary="LangChain" data-secondary="callbacks" id="id1115"/><a data-type="indexterm" data-primary="callbacks" id="id1116"/>to seamlessly monitor and pinpoint issues within your application. Until now, you’ve encountered the parameter <code>verbose=True</code> in <code>AgentExecutor</code> chains:</p>

<pre data-type="programlisting">AgentExecutor(.., verbose=True)</pre>

<p>This parameter logs useful outputs for debugging purposes, but what if you’re keen on tracking specific events? Enter callbacks, your go-to solution.</p>

<p>The <code>BaseCallbackHandler</code> class acts as a foundation for monitoring and responding to various events during the execution of your generative AI models. Each method in this class corresponds to specific stages like the start, end, or even errors during the model’s runtime. For instance, the <code>on_llm_start</code> gets triggered when an LLM begins its operation. Similarly, methods like <code>on_chain_error</code> and <code>on_tool_end</code> react to errors in chains or after using a tool:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">BaseCallbackHandler</code><code class="p">:</code>
    <code class="sd">"""Base callback handler that can be used to handle callbacks from</code>
<code class="sd">    langchain."""</code>

    <code class="k">def</code> <code class="nf">on_llm_start</code><code class="p">(</code>
        <code class="bp">self</code><code class="p">,</code> <code class="n">serialized</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">Any</code><code class="p">],</code> <code class="n">prompts</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="nb">str</code><code class="p">],</code>
        <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code>
    <code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run when LLM starts running."""</code>

    <code class="k">def</code> <code class="nf">on_chat_model_start</code><code class="p">(</code>
        <code class="bp">self</code><code class="p">,</code> <code class="n">serialized</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">Any</code><code class="p">],</code>
        <code class="n">messages</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="n">List</code><code class="p">[</code><code class="n">BaseMessage</code><code class="p">]],</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code>
    <code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run when Chat Model starts running."""</code>

    <code class="k">def</code> <code class="nf">on_llm_new_token</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">token</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run on new LLM token. Only available when streaming is enabled."""</code>

    <code class="k">def</code> <code class="nf">on_llm_end</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">response</code><code class="p">:</code> <code class="n">LLMResult</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run when LLM ends running."""</code>

    <code class="k">def</code> <code class="nf">on_llm_error</code><code class="p">(</code>
        <code class="bp">self</code><code class="p">,</code> <code class="n">error</code><code class="p">:</code> <code class="n">Union</code><code class="p">[</code><code class="ne">Exception</code><code class="p">,</code> <code class="ne">KeyboardInterrupt</code><code class="p">],</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code>
    <code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run when LLM errors."""</code>

    <code class="k">def</code> <code class="nf">on_chain_start</code><code class="p">(</code>
        <code class="bp">self</code><code class="p">,</code> <code class="n">serialized</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">Any</code><code class="p">],</code> <code class="n">inputs</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">Any</code><code class="p">],</code>
        <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code>
    <code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run when chain starts running."""</code>

    <code class="k">def</code> <code class="nf">on_chain_end</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">outputs</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">Any</code><code class="p">],</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run when chain ends running."""</code>

    <code class="k">def</code> <code class="nf">on_chain_error</code><code class="p">(</code>
        <code class="bp">self</code><code class="p">,</code> <code class="n">error</code><code class="p">:</code> <code class="n">Union</code><code class="p">[</code><code class="ne">Exception</code><code class="p">,</code> <code class="ne">KeyboardInterrupt</code><code class="p">],</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code>
    <code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run when chain errors."""</code>

    <code class="k">def</code> <code class="nf">on_tool_start</code><code class="p">(</code>
        <code class="bp">self</code><code class="p">,</code> <code class="n">serialized</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">Any</code><code class="p">],</code> <code class="n">input_str</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code>
    <code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run when tool starts running."""</code>

    <code class="k">def</code> <code class="nf">on_tool_end</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">output</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run when tool ends running."""</code>

    <code class="k">def</code> <code class="nf">on_tool_error</code><code class="p">(</code>
        <code class="bp">self</code><code class="p">,</code> <code class="n">error</code><code class="p">:</code> <code class="n">Union</code><code class="p">[</code><code class="ne">Exception</code><code class="p">,</code> <code class="ne">KeyboardInterrupt</code><code class="p">],</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code>
    <code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run when tool errors."""</code>

    <code class="k">def</code> <code class="nf">on_text</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">text</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run on arbitrary text."""</code>

    <code class="k">def</code> <code class="nf">on_agent_action</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">action</code><code class="p">:</code> <code class="n">AgentAction</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run on agent action."""</code>

    <code class="k">def</code> <code class="nf">on_agent_finish</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">finish</code><code class="p">:</code> <code class="n">AgentFinish</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">:</code> <code class="n">Any</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="sd">"""Run on agent end."""</code></pre>

<p>Each callback can be scoped to either the class or individual requests.</p>








<section data-type="sect2" data-pdf-bookmark="Global (Constructor) Callbacks"><div class="sect2" id="id178">
<h2>Global (Constructor) Callbacks</h2>

<p>When defining callbacks within a <a data-type="indexterm" data-primary="LangChain" data-secondary="callbacks" data-tertiary="global" id="id1117"/><a data-type="indexterm" data-primary="callbacks" data-secondary="global" id="id1118"/><a data-type="indexterm" data-primary="LangChain" data-secondary="callbacks" data-tertiary="constructor" id="id1119"/><a data-type="indexterm" data-primary="callbacks" data-secondary="constructor" id="id1120"/>constructor, like <code>AgentExecutor(callbacks=[handler], tags=['a-tag'])</code>, they are activated for every call made on that instance. These callbacks are limited to that specific instance. To illustrate, when a handler is passed to an <code>LLMChain</code> during its creation, it won’t interact with any children chains:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain.agents</code> <code class="kn">import</code> <code class="n">AgentExecutor</code>
<code class="kn">from</code> <code class="nn">langchain.callbacks</code> <code class="kn">import</code> <code class="n">StdOutCallbackHandler</code>

<code class="n">agent_executor</code> <code class="o">=</code> <code class="n">AgentExecutor</code><code class="p">(</code>
    <code class="n">agent</code><code class="o">=</code><code class="n">agent</code><code class="p">,</code>
    <code class="n">tools</code><code class="o">=</code><code class="n">tools</code><code class="p">,</code>
    <code class="n">verbose</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code>
    <code class="n">callbacks</code><code class="o">=</code><code class="p">[</code><code class="n">StdOutCallbackHandler</code><code class="p">()],</code>
    <code class="n">tags</code><code class="o">=</code><code class="p">[</code><code class="s1">'a-tag'</code><code class="p">])</code>

<code class="n">agent_executor</code><code class="o">.</code><code class="n">invoke</code><code class="p">({</code><code class="s2">"input"</code><code class="p">:</code> <code class="s2">"How many letters in the word Software?"</code><code class="p">})</code></pre>

<p>The tags you include, such as <code>'a-tag'</code>, can be tremendously useful in tracing and sorting the outputs of your generative AI setup. Especially in large projects with numerous chains, utilizing tags can significantly streamline your workflow.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Request-Specific Callbacks"><div class="sect2" id="id179">
<h2>Request-Specific Callbacks</h2>

<p>On the other hand, callbacks can be <a data-type="indexterm" data-primary="LangChain" data-secondary="callbacks" data-tertiary="request-specific" id="id1121"/><a data-type="indexterm" data-primary="callbacks" data-secondary="request-specific" id="id1122"/>defined within the <code>invoke()</code> method. For instance, a request to an <code>LLMChain</code> might subsequently trigger another <code>LLMChain</code> request, and the same handler would be applied:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain.callbacks</code> <code class="kn">import</code> <code class="n">StdOutCallbackHandler</code>
<code class="kn">from</code> <code class="nn">langchain.chains</code> <code class="kn">import</code> <code class="n">LLMChain</code>
<code class="kn">from</code> <code class="nn">langchain_openai</code> <code class="kn">import</code> <code class="n">OpenAI</code>
<code class="kn">from</code> <code class="nn">langchain_core.prompts</code> <code class="kn">import</code> <code class="n">PromptTemplate</code>

<code class="n">handler</code> <code class="o">=</code> <code class="n">StdOutCallbackHandler</code><code class="p">()</code>
<code class="n">llm</code> <code class="o">=</code> <code class="n">OpenAI</code><code class="p">()</code>
<code class="n">prompt</code> <code class="o">=</code> <code class="n">PromptTemplate</code><code class="o">.</code><code class="n">from_template</code><code class="p">(</code><code class="s2">"What is 1 + </code><code class="si">{number}</code><code class="s2"> = "</code><code class="p">)</code>
<code class="n">chain</code> <code class="o">=</code> <code class="n">LLMChain</code><code class="p">(</code><code class="n">llm</code><code class="o">=</code><code class="n">llm</code><code class="p">,</code> <code class="n">prompt</code><code class="o">=</code><code class="n">prompt</code><code class="p">)</code>
<code class="n">chain</code><code class="o">.</code><code class="n">invoke</code><code class="p">({</code><code class="s2">"number"</code><code class="p">:</code> <code class="mi">2</code><code class="p">},</code> <code class="p">{</code><code class="s2">"callbacks"</code><code class="p">:</code> <code class="p">[</code><code class="n">handler</code><code class="p">]})</code></pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="The Verbose Argument"><div class="sect2" id="id180">
<h2>The Verbose Argument</h2>

<p>A common utility, the <code>verbose</code> argument, is accessible <a data-type="indexterm" data-primary="LangChain" data-secondary="callbacks" data-tertiary="verbose argument" id="id1123"/><a data-type="indexterm" data-primary="callbacks" data-secondary="verbose argument" id="id1124"/>for most API objects. When you use <code>AgentExecutor(verbose=True)</code>, it’s the same as integrating a <code>ConsoleCallbackHandler</code> into the callbacks argument of the object and its descendants. It acts as a useful debugging tool by logging every event directly to your console.</p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="When to Use Which?"><div class="sect2" id="id181">
<h2>When to Use Which?</h2>
<dl>
<dt>Constructor callbacks</dt>
<dd>
<p>Ideal for overarching tasks like logging or monitoring across an entire chain. If tracking all <a data-type="indexterm" data-primary="LangChain" data-secondary="callbacks" data-tertiary="global" id="id1125"/><a data-type="indexterm" data-primary="callbacks" data-secondary="global" id="id1126"/><a data-type="indexterm" data-primary="LangChain" data-secondary="callbacks" data-tertiary="constructor" id="id1127"/><a data-type="indexterm" data-primary="callbacks" data-secondary="constructor" id="id1128"/>interactions within agents is your goal, attach the handler during its initiation.</p>
</dd>
<dt>Request callbacks</dt>
<dd>
<p>Tailored for specific use cases like streaming, where outputs from a single request are relayed to dedicated endpoints, say a websocket. So, for a scenario where the output from a singular request needs to be streamed to a websocket, the handler should be linked to the <code>invoke()</code> method.</p>
</dd>
<dt>Verbose arguments</dt>
<dd>
<p>Useful for debugging and local LLM development, but it can generate a large number of logs.</p>
</dd>
</dl>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Token Counting with LangChain"><div class="sect2" id="id182">
<h2>Token Counting with LangChain</h2>

<p>LangChain provides an effective method for <a data-type="indexterm" data-primary="LangChain" data-secondary="token counting" id="lgcnktct"/><a data-type="indexterm" data-primary="tokens" data-secondary="counting" id="tknsctg"/>token counting during your interactions with generative AI models.</p>

<p>You need to set up the necessary modules; import the <code>asyncio</code> module and the relevant functions from the LangChain package:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">asyncio</code>
<code class="kn">from</code> <code class="nn">langchain.callbacks</code> <code class="kn">import</code> <code class="n">get_openai_callback</code>
<code class="kn">from</code> <code class="nn">langchain_core.messages</code> <code class="kn">import</code> <code class="n">SystemMessage</code>
<code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">()</code></pre>

<p>Now, employ the <code>get_openai_callback</code> context manager to make a request and count the tokens used:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">get_openai_callback</code><code class="p">()</code> <code class="k">as</code> <code class="n">cb</code><code class="p">:</code>
    <code class="n">model</code><code class="o">.</code><code class="n">invoke</code><code class="p">([</code><code class="n">SystemMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"My name is James"</code><code class="p">)])</code>
<code class="n">total_tokens</code> <code class="o">=</code> <code class="n">cb</code><code class="o">.</code><code class="n">total_tokens</code>
<code class="nb">print</code><code class="p">(</code><code class="n">total_tokens</code><code class="p">)</code>
<code class="c1"># 25</code>
<code class="k">assert</code> <code class="n">total_tokens</code> <code class="o">&gt;</code> <code class="mi">0</code></pre>

<p>After executing this code, <code>total_tokens</code> will store the number of tokens used for your request.</p>

<p>When making multiple requests within the context manager, you can verify that the total tokens counted are accurate:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">get_openai_callback</code><code class="p">()</code> <code class="k">as</code> <code class="n">cb</code><code class="p">:</code>
    <code class="n">model</code><code class="o">.</code><code class="n">invoke</code><code class="p">([</code><code class="n">SystemMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"My name is James"</code><code class="p">)])</code>
    <code class="n">model</code><code class="o">.</code><code class="n">invoke</code><code class="p">([</code><code class="n">SystemMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"My name is James"</code><code class="p">)])</code>
<code class="k">assert</code> <code class="n">cb</code><code class="o">.</code><code class="n">total_tokens</code> <code class="o">&gt;</code> <code class="mi">0</code>
<code class="nb">print</code><code class="p">(</code><code class="n">cb</code><code class="o">.</code><code class="n">total_tokens</code><code class="p">)</code>
<code class="c1"># 50</code></pre>

<p>As you can observe, making the same request twice often results in <code>cb.total_tokens</code> being twice the value of <code>total_tokens</code>.</p>

<p>LangChain supports concurrent runs, letting you execute multiple requests at the same time:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># Async callbacks:</code>
<code class="k">with</code> <code class="n">get_openai_callback</code><code class="p">()</code> <code class="k">as</code> <code class="n">cb</code><code class="p">:</code>
    <code class="k">await</code> <code class="n">asyncio</code><code class="o">.</code><code class="n">gather</code><code class="p">(</code>
        <code class="n">model</code><code class="o">.</code><code class="n">agenerate</code><code class="p">(</code>
            <code class="p">[</code>
                <code class="p">[</code><code class="n">SystemMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"Is the meaning of life 42?"</code><code class="p">)],</code>
                <code class="p">[</code><code class="n">SystemMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"Is the meaning of life 42?"</code><code class="p">)],</code>
            <code class="p">],</code>
        <code class="p">)</code>
    <code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="n">cb</code><code class="o">.</code><code class="vm">__dict__</code><code class="p">)</code>
<code class="c1"># {'successful_requests': 2, 'total_cost': 0.000455,</code>
<code class="c1"># 'total_tokens': 235, 'prompt_tokens': 30,</code>
<code class="c1"># 'completion_tokens': 205}</code></pre>

<p><code>cb</code> provides a detailed breakdown of your interaction with the AI model, offering key metrics that are pivotal for prompt engineering:</p>

<ul>
<li>
<p><code>cb.successful_requests</code> tracks the number of requests that have been executed successfully. It’s a direct indicator of how many API requests were effectively processed without encountering errors.</p>
</li>
<li>
<p>With <code>cb.total_cost</code>, you get a transparent view of the cost associated with your requests. This can be a crucial metric for budgeting and managing expenses when working extensively with the AI.</p>
</li>
<li>
<p><code>cb.total_tokens</code> denotes the cumulative number of tokens used in both the prompt and the completion. This provides a holistic view of token consumption.</p>
</li>
<li>
<p><code>cb.prompt_tokens</code> gives insight into how many tokens were used in the prompts you provided. This can guide you in optimizing your prompts to be concise yet effective.</p>
</li>
<li>
<p><code>cb.completion_tokens</code> highlights the number of tokens taken up by the AI’s response. This can be beneficial <a data-type="indexterm" data-primary="LangChain" data-secondary="token counting" data-startref="lgcnktct" id="id1129"/><a data-type="indexterm" data-primary="tokens" data-secondary="counting" data-startref="tknsctg" id="id1130"/>when analyzing the verbosity or depth of the AI’s answers.</p>
</li>
</ul>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="id356">
<h1>Summary</h1>

<p>In this chapter, you learned about the concept of chain-of-thought reasoning and its importance in autonomous agents. You discovered how LLMs can break down complex problems into smaller components to provide effective solutions.</p>

<p>Additionally, you explored the agent-based architecture in generative AI models and gained valuable insights into memory integration and advanced agent frameworks. You investigated several agent frameworks such as ReAct and OpenAI function calling and learned that these frameworks enhance LLM model responses by utilizing external tools.</p>

<p>In <a data-type="xref" href="ch07.html#intro_image_07">Chapter 7</a>, you’ll be introduced to image generation using generative AI. You will learn the history of generative AI image models, including the strengths and weaknesses of each vendor.</p>
</div></section>
</div></section></div></div></body></html>