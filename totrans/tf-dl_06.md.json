["```py\ndef download(filename):\n  \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n  if not os.path.exists(WORK_DIRECTORY):\n    os.makedirs(WORK_DIRECTORY)\n  filepath = os.path.join(WORK_DIRECTORY, filename)\n  if not os.path.exists(filepath):\n    filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n    size = os.stat(filepath).st_size\n    print('Successfully downloaded', filename, size, 'bytes.')\n  return filepath\n```", "```py\ndef extract_data(filename, num_images):\n  \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n\n Values are rescaled from [0, 255] down to [-0.5, 0.5].\n \"\"\"\n  print('Extracting', filename)\n  with gzip.open(filename) as bytestream:\n    bytestream.read(16)\n    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n    data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n    data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n    return data\n```", "```py\ndef extract_labels(filename, num_images):\n  \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n  print('Extracting', filename)\n  with gzip.open(filename) as bytestream:\n    bytestream.read(8)\n    buf = bytestream.read(1 * num_images)\n    labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)\n  return labels\n```", "```py\n# Get the data.\ntrain_data_filename = download('train-images-idx3-ubyte.gz')\ntrain_labels_filename = download('train-labels-idx1-ubyte.gz')\ntest_data_filename = download('t10k-images-idx3-ubyte.gz')\ntest_labels_filename = download('t10k-labels-idx1-ubyte.gz')\n\n# Extract it into NumPy arrays.\ntrain_data = extract_data(train_data_filename, 60000)\ntrain_labels = extract_labels(train_labels_filename, 60000)\ntest_data = extract_data(test_data_filename, 10000)\ntest_labels = extract_labels(test_labels_filename, 10000)\n```", "```py\nVALIDATION_SIZE = 5000  # Size of the validation set.\n\n# Generate a validation set.\nvalidation_data = train_data[:VALIDATION_SIZE, ...]\nvalidation_labels = train_labels[:VALIDATION_SIZE]\ntrain_data = train_data[VALIDATION_SIZE:, ...]\ntrain_labels = train_labels[VALIDATION_SIZE:]\n```", "```py\ntf.nn.conv2d(\n    input,\n    filter,\n    strides,\n    padding,\n    use_cudnn_on_gpu=None,\n    data_format=None,\n    name=None\n)\n```", "```py\ntf.nn.max_pool(\n    value,\n    ksize,\n    strides,\n    padding,\n    data_format='NHWC',\n    name=None\n)\n```", "```py\nNUM_CHANNELS = 1\nIMAGE_SIZE = 28\nNUM_LABELS = 10\n```", "```py\nconv1_weights = tf.Variable(\n    tf.truncated_normal([5, 5, NUM_CHANNELS, 32],  # 5x5 filter, depth 32.\n                        stddev=0.1,\n                        seed=SEED, dtype=tf.float32))\nconv1_biases = tf.Variable(tf.zeros([32], dtype=tf.float32))\nconv2_weights = tf.Variable(tf.truncated_normal(\n    [5, 5, 32, 64], stddev=0.1,\n    seed=SEED, dtype=tf.float32))\nconv2_biases = tf.Variable(tf.constant(0.1, shape=[64], dtype=tf.float32))\n```", "```py\nfc1_weights = tf.Variable(  # fully connected, depth 512.\n    tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],\n                        stddev=0.1,\n                        seed=SEED,\n                        dtype=tf.float32))\nfc1_biases = tf.Variable(tf.constant(0.1, shape=[512], dtype=tf.float32))\nfc2_weights = tf.Variable(tf.truncated_normal([512, NUM_LABELS],\n                                              stddev=0.1,\n                                              seed=SEED,\n                                              dtype=tf.float32))\nfc2_biases = tf.Variable(tf.constant(\n    0.1, shape=[NUM_LABELS], dtype=tf.float32))\n```", "```py\ndef model(data, train=False):\n  \"\"\"The Model definition.\"\"\"\n  # 2D convolution, with 'SAME' padding (i.e. the output feature map has\n  # the same size as the input). Note that {strides} is a 4D array whose\n  # shape matches the data layout: [image index, y, x, depth].\n  conv = tf.nn.conv2d(data,\n                      conv1_weights,\n                      strides=[1, 1, 1, 1],\n                      padding='SAME')\n  # Bias and rectified linear non-linearity.\n  relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n  # Max pooling. The kernel size spec {ksize} also follows the layout of\n  # the data. Here we have a pooling window of 2, and a stride of 2.\n  pool = tf.nn.max_pool(relu,\n                        ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1],\n                        padding='SAME')\n  conv = tf.nn.conv2d(pool,\n                      conv2_weights,\n                      strides=[1, 1, 1, 1],\n                      padding='SAME')\n  relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n  pool = tf.nn.max_pool(relu,\n                        ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1],\n                        padding='SAME')\n  # Reshape the feature map cuboid into a 2D matrix to feed it to the\n  # fully connected layers.\n  pool_shape = pool.get_shape().as_list()\n  reshape = tf.reshape(\n      pool,\n      [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n  # Fully connected layer. Note that the '+' operation automatically\n  # broadcasts the biases.\n  hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n  # Add a 50% dropout during training only. Dropout also scales\n  # activations such that no rescaling is needed at evaluation time.\n  if train:\n    hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n  return tf.matmul(hidden, fc2_weights) + fc2_biases\n```", "```py\nBATCH_SIZE = 64\nEVAL_BATCH_SIZE = 64\n\ntrain_data_node = tf.placeholder(\n    tf.float32,\n    shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\ntrain_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))\neval_data = tf.placeholder(\n    tf.float32,\n    shape=(EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n```", "```py\n# Create a local session to run the training.\nstart_time = time.time()\nwith tf.Session() as sess:\n  # Run all the initializers to prepare the trainable parameters.\n  tf.global_variables_initializer().run()\n  # Loop through training steps.\n  for step in xrange(int(num_epochs * train_size) // BATCH_SIZE):\n    # Compute the offset of the current minibatch in the data.\n    # Note that we could use better randomization across epochs.\n    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n    batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n    # This dictionary maps the batch data (as a NumPy array) to the\n    # node in the graph it should be fed to.\n    feed_dict = {train_data_node: batch_data,\n                 train_labels_node: batch_labels}\n    # Run the optimizer to update weights.\n    sess.run(optimizer, feed_dict=feed_dict)\n```", "```py\ndef error_rate(predictions, labels):\n  \"\"\"Return the error rate based on dense predictions and sparse labels.\"\"\"\n  return 100.0 - (\n      100.0 *\n      numpy.sum(numpy.argmax(predictions, 1) == labels) /\n      predictions.shape[0])\n```", "```py\ndef eval_in_batches(data, sess):\n  \"\"\"Get predictions for a dataset by running it in small batches.\"\"\"\n  size = data.shape[0]\n  if size < EVAL_BATCH_SIZE:\n    raise ValueError(\"batch size for evals larger than dataset: %d\"\n                     % size)\n  predictions = numpy.ndarray(shape=(size, NUM_LABELS),\n                              dtype=numpy.float32)\n  for begin in xrange(0, size, EVAL_BATCH_SIZE):\n    end = begin + EVAL_BATCH_SIZE\n    if end <= size:\n      predictions[begin:end, :] = sess.run(\n          eval_prediction,\n          feed_dict={eval_data: data[begin:end, ...]})\n    else:\n      batch_predictions = sess.run(\n          eval_prediction,\n          feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})\n      predictions[begin:, :] = batch_predictions[begin - size:, :]\n  return predictions\n```", "```py\n# Create a local session to run the training.\nstart_time = time.time()\nwith tf.Session() as sess:\n  # Run all the initializers to prepare the trainable parameters.\n  tf.global_variables_initializer().run()\n  # Loop through training steps.\n  for step in xrange(int(num_epochs * train_size) // BATCH_SIZE):\n    # Compute the offset of the current minibatch in the data.\n    # Note that we could use better randomization across epochs.\n    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n    batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n    # This dictionary maps the batch data (as a NumPy array) to the\n    # node in the graph it should be fed to.\n    feed_dict = {train_data_node: batch_data,\n                 train_labels_node: batch_labels}\n    # Run the optimizer to update weights.\n    sess.run(optimizer, feed_dict=feed_dict)\n    # print some extra information once reach the evaluation frequency\n    if step % EVAL_FREQUENCY == 0:\n      # fetch some extra nodes' data\n      l, lr, predictions = sess.run([loss, learning_rate,\n                                     train_prediction],\n                                    feed_dict=feed_dict)\n      elapsed_time = time.time() - start_time\n      start_time = time.time()\n      print('Step %d (epoch %.2f), %.1f ms' %\n            (step, float(step) * BATCH_SIZE / train_size,\n             1000 * elapsed_time / EVAL_FREQUENCY))\n      print('Minibatch loss: %.3f, learning rate: %.6f' % (l, lr))\n      print('Minibatch error: %.1f%%'\n            % error_rate(predictions, batch_labels))\n      print('Validation error: %.1f%%' % error_rate(\n          eval_in_batches(validation_data, sess), validation_labels))\n      sys.stdout.flush()\n  # Finally print the result!\n  test_error = error_rate(eval_in_batches(test_data, sess),\n                          test_labels)\n  print('Test error: %.1f%%' % test_error)\n```"]