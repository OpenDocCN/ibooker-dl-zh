["```py\n! cd ~\n! git clone https://github.com/tensorflow/models.git\n```", "```py\n! pip install contextlib2\nimport os\nnew_python_path = (os.environ.get(\"PYTHONPATH\") or '') + \":models/research/slim\"\n%env PYTHONPATH=$new_python_path\n```", "```py\necho 'export PYTHONPATH=$PYTHONPATH:models/research/slim' >> ~/.bashrc\nsource ~/.bashrc\n```", "```py\n! python download_and_convert_data.py \\\n  --dataset_name=visualwakewords \\\n  --dataset_dir=data/visualwakewords\n```", "```py\n! python models/research/slim/train_image_classifier.py \\\n    --train_dir=vww_96_grayscale \\\n    --dataset_name=visualwakewords \\\n    --dataset_split_name=train \\\n    --dataset_dir=data/visualwakewords \\\n    --model_name=mobilenet_v1_025 \\\n    --preprocessing_name=mobilenet_v1 \\\n    --train_image_size=96 \\\n    --use_grayscale=True \\\n    --save_summaries_secs=300 \\\n    --learning_rate=0.045 \\\n    --label_smoothing=0.1 \\\n    --learning_rate_decay_factor=0.98 \\\n    --num_epochs_per_decay=2.5 \\\n    --moving_average_decay=0.9999 \\\n    --batch_size=96 \\\n    --max_number_of_steps=1000000\n```", "```py\nINFO:tensorflow:global step 4670: loss = 0.7112 (0.251 sec/step)\n  I0928 00:16:21.774756 140518023943616 learning.py:507] global step 4670: loss\n  = 0.7112 (0.251 sec/step)\nINFO:tensorflow:global step 4680: loss = 0.6596 (0.227 sec/step)\n  I0928 00:16:24.365901 140518023943616 learning.py:507] global step 4680: loss\n  = 0.6596 (0.227 sec/step)\n```", "```py\n! python models/research/slim/eval_image_classifier.py \\\n    --alsologtostderr \\\n    --checkpoint_path=vww_96_grayscale/model.ckpt-698580 \\\n    --dataset_dir=data/visualwakewords \\\n    --dataset_name=visualwakewords \\\n    --dataset_split_name=val \\\n    --model_name=mobilenet_v1_025 \\\n    --preprocessing_name=mobilenet_v1 \\\n    --use_grayscale=True \\\n    --train_image_size=96\n```", "```py\nINFO:tensorflow:Evaluation [406/406]\nI0929 22:52:59.936022 140225887045056 evaluation.py:167] Evaluation [406/406]\neval/Accuracy[0.717438412]eval/Recall_5[1]\n```", "```py\n! python models/research/slim/export_inference_graph.py \\\n    --alsologtostderr \\\n    --dataset_name=visualwakewords \\\n    --model_name=mobilenet_v1_025 \\\n    --image_size=96 \\\n    --use_grayscale=True \\\n    --output_file=vww_96_grayscale_graph.pb\n```", "```py\n! git clone https://github.com/tensorflow/tensorflow\n! python tensorflow/tensorflow/python/tools/freeze_graph.py \\\n    --input_graph=vww_96_grayscale_graph.pb \\\n    --input_checkpoint=vww_96_grayscale/model.ckpt-1000000 \\\n    --input_binary=true --output_graph=vww_96_grayscale_frozen.pb \\\n    --output_node_names=MobilenetV1/Predictions/Reshape_1\n```", "```py\nimport tensorflow as tf\nimport io\nimport PIL\nimport numpy as np\n\ndef representative_dataset_gen():\n\n  record_iterator = tf.python_io.tf_record_iterator\n      (path='data/visualwakewords/val.record-00000-of-00010')\n\n  count = 0\n  for string_record in record_iterator:\n    example = tf.train.Example()\n    example.ParseFromString(string_record)\n    image_stream = io.BytesIO\n        (example.features.feature['image/encoded'].bytes_list.value[0])\n    image = PIL.Image.open(image_stream)\n    image = image.resize((96, 96))\n    image = image.convert('L')\n    array = np.array(image)\n    array = np.expand_dims(array, axis=2)\n    array = np.expand_dims(array, axis=0)\n    array = ((array / 127.5) - 1.0).astype(np.float32)\n    yield([array])\n    count += 1\n    if count > 300:\n        break\n\nconverter = tf.lite.TFLiteConverter.from_frozen_graph \\\n    ('vww_96_grayscale_frozen.pb', ['input'],  ['MobilenetV1/Predictions/ \\\n Reshape_1'])\nconverter.inference_input_type = tf.lite.constants.INT8\nconverter.inference_output_type = tf.lite.constants.INT8\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = representative_dataset_gen\n\ntflite_quant_model = converter.convert()\nopen(\"vww_96_grayscale_quantized.tflite\", \"wb\").write(tflite_quant_model)\n```", "```py\n# Install xxd if it is not available\n! apt-get -qq install xxd\n# Save the file as a C source file\n! xxd -i vww_96_grayscale_quantized.tflite > person_detect_model_data.cc\n```", "```py\n! python models/research/slim/datasets/build_visualwakewords_data.py \\\n   --logtostderr \\\n   --train_image_dir=coco/raw-data/train2014 \\\n   --val_image_dir=coco/raw-data/val2014 \\\n   --train_annotations_file=coco/raw-data/annotations/instances_train2014.json \\\n   --val_annotations_file=coco/raw-data/annotations/instances_val2014.json \\\n   --output_dir=coco/processed_cars \\\n   --small_object_area_threshold=0.005 \\\n   --foreground_class_of_interest='car'\n```"]