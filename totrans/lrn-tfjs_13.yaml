- en: 'Chapter 12\. Dicify: Capstone Project'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: “Everybody has a plan until they get punched in the mouth.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Iron Mike Tyson
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: All of your training has gotten you through a variety of theories and exercises.
    As of right now, you know enough to come up with a plan to build new and creative
    uses for machine learning in TensorFlow.js. In this chapter, you’ll develop your
    capstone project. Rather than learning yet another aspect of machine learning
    with TensorFlow.js, you’ll start this chapter with a challenge, and you’ll use
    your existing skills to build a solution that works. From idea to completion,
    this chapter will guide you through the execution of solving a problem. Whether
    this is your first book on machine learning or your 10th, this capstone is your
    time to shine.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will:'
  prefs: []
  type: TYPE_NORMAL
- en: Research the problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create and augment data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Train a model that will solve the problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement the solution in a website
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you finish this chapter, you’ll have applied your skills from beginning
    to end to solve a fun machine learning project.
  prefs: []
  type: TYPE_NORMAL
- en: A Dicey Challenge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ll be using your newfound skill to blur the line between art and science.
    Engineers have been using machines for impressive visual feats for years. Most
    notably, the camera obscura technique (as shown in [Figure 12-1](#camera_obscura))
    allowed mad scientists to trace live scenery with a lens and a mirror.^([1](ch12.html#idm45049236364264))
  prefs: []
  type: TYPE_NORMAL
- en: '![person looking into dark box camera obscura](assets/ltjs_1201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-1\. Camera obscura
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Today, people are making art from the strangest things. At my college, the art
    department created a whole scene from *Super Mario Bros.* using nothing but sticky
    notes as pixels. While some of us have the divine inspiration of art, others can
    produce similar works by wielding their other talents.
  prefs: []
  type: TYPE_NORMAL
- en: Your challenge, should you choose to accept it and get everything you can from
    this book, is to teach an AI how to draw using dice. By lining up six-sided dice
    and choosing the correct number to show, you can replicate any image. Artists
    will buy hundreds of dice and re-create images using their skills. In this chapter,
    you’ll bring all the skills you’ve learned to bear and teach an AI how to do a
    decent job at breaking down images into dice art, as shown in [Figure 12-2](#dicify_tfjs).
  prefs: []
  type: TYPE_NORMAL
- en: '![Image to dice version](assets/ltjs_1202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-2\. Converting graphics into dice
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Once you have the AI capable of converting black-and-white images to dice, you
    can do all kinds of things, like create a cool webcam filter, make an excellent
    website, or even print the directions for a fun craft project for yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Take 10 minutes before you continue, and strategize how you can use your skills
    to build a decent image-to-dice converter from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: The Plan
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Ideally, you came up with something similar to me. First, you’ll need the data,
    then you’ll need to train a model, and lastly, you’ll need to create a website
    that utilizes the trained model.
  prefs: []
  type: TYPE_NORMAL
- en: The Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While dice aren’t terribly complicated, what each patch of pixels should be
    isn’t an existing dataset. You’ll need to generate a dataset that’s good enough
    to map a patch of pixels of an image into what die would best fit. You’ll create
    data like that in [Figure 12-3](#pixel_to_die).
  prefs: []
  type: TYPE_NORMAL
- en: '![the vertical line is converted to the number three in dice](assets/ltjs_1203.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-3\. Teach the AI how to pick which die works
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Some dice can be rotated. The two, three, and six will have to be repeated in
    the dataset, so they are specific to each configuration. While they are interchangeable
    in games, they are not in art. [Figure 12-4](#three_ne_three) demonstrates how
    these numbers are visually mirrored.
  prefs: []
  type: TYPE_NORMAL
- en: '![Three and three rotated](assets/ltjs_1204.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-4\. Angles matter; these two are not equal
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This means you’ll need nine possible configurations total. That’s six dice,
    with three of them rotated 90 degrees. [Figure 12-5](#nine_config) demonstrates
    all the possible configurations for your average six-sided game die.
  prefs: []
  type: TYPE_NORMAL
- en: '![The nine possible configurations of a six sided die illustrated with actual
    dice](assets/ltjs_1205.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-5\. The nine possible configurations
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: These are the patterns available for re-creating any image with one style of
    dice that must sit flat. While this is imperfect for directly representing an
    image, the resolution improves with quantity and distance from the dice.
  prefs: []
  type: TYPE_NORMAL
- en: The Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Two big questions come to mind when designing the model:'
  prefs: []
  type: TYPE_NORMAL
- en: Is there anything out there that would be useful for transfer learning?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Should the model have convolutional layers?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First, I don’t believe I’ve ever seen anything like this before. When creating
    the model, we’ll need to assure a validation and a testing set to verify the model
    is training well because we’ll be designing it from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Second, the model should probably avoid convolutions. Convolutions help you
    extract complicated features regardless of their positions, but this model is
    very position-specific. Two patches of pixels could be a two or a two rotated.
    For this exercise, I’m going to go with no convolutional layers.
  prefs: []
  type: TYPE_NORMAL
- en: We won’t know until we’re finished if skipping convolutions was a good plan
    or not. Unlike most programming, there’s a layer of experimentation in machine
    learning architecture. We can always go back and try other architectures.
  prefs: []
  type: TYPE_NORMAL
- en: The Website
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the model is capable of categorizing a small patch of pixels into a corresponding
    die, you’ll need to activate your tensor skills to break images into small chunks
    to be converted. The fragments of images will be stacked, predicted, and reconstructed
    with pictures of dice.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Because the concepts covered in this chapter are applications of previously
    explained concepts, this chapter will discuss problems at a high level and might
    skip some of the details of the code to solve this capstone. If you’re unable
    to follow along, please review previous chapters for concepts and [the associated
    source code](https://oreil.ly/PjNLO) for specifics. *This chapter will not show
    every line of code.*
  prefs: []
  type: TYPE_NORMAL
- en: Generating Training Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of this section is to create a multitude of data to use in training
    a model. This is more art than science. We want to have plenty of data. To generate
    hundreds of images, we can slightly modify existing dice pixels. For this section,
    I’ve created 12 x 12 prints of dice with simple rank-two tensors. The nine configurations
    of dice can be created with a little patience. Look at [Example 12-1](#dice_array_example)
    and notice blocks of zeros that represent the dark pips of the dice.
  prefs: []
  type: TYPE_NORMAL
- en: Example 12-1\. An array representation of the dice one and two
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can create a `[9, 12, 12]` float of ones with `tf.ones` and then manually
    convert spots to `0` to make the black spots for each die.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have all nine configurations, you can consider image augmentation to
    create new data. Standard image augmentation libraries won’t work here, but you
    can use your tensor skills to write a function to slightly shift each dice position
    by one pixel. This small mutation turns a single die into nine variations. You’d
    then have nine variations of nine dice in your dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this in code, imagine increasing the size of the die and then sliding
    a 12 x 12 window around to slightly cut new versions of the image off-center:
    this a *pad and crop augmentation*.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_dicify__capstone_project_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The `.pad` adds a `1` value white border to the existing tensor.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_dicify__capstone_project_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: To generate nine new shifted values, the origin of the slice position is shifted
    each time.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_dicify__capstone_project_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The sliced subtensor becomes a new 12 x 12 value with each origin.
  prefs: []
  type: TYPE_NORMAL
- en: The results of the `pixelShift` create small variations that should all still
    be solved with the original die. [Figure 12-6](#mods) shows the visual representation
    of shifted pixels.
  prefs: []
  type: TYPE_NORMAL
- en: '![Nine new images from one](assets/ltjs_1206.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-6\. Shifting the pixels creates new dice
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: While nine versions of each die are better than one, it’s still a very small
    dataset. You’ve got to come up with a way to create new data.
  prefs: []
  type: TYPE_NORMAL
- en: You can create new variations by randomly combining the nine shifted images.
    There are a lot of ways you can combine any two of these images. One way is to
    use `tf.where` and keep the lesser of the two images in their new combined image.
    This keeps the dark pixels from any two shifted dice.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_dicify__capstone_project_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: '`tf.where` is like running a conditional on each element.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_dicify__capstone_project_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: '`tf.less` returns true when the first parameter is less than the second parameter.'
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_dicify__capstone_project_CO2-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The value in `arrCopy[i]` is returned if the condition in the `where` is true.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_dicify__capstone_project_CO2-4)'
  prefs: []
  type: TYPE_NORMAL
- en: The value in `arrCopy[j]` is returned if the condition in the `where` is false.
  prefs: []
  type: TYPE_NORMAL
- en: When you overlap these dice, you get new tensors that look like small mutations
    of the dice you had before. The 4 x 4 pips on the dice get combined to create
    quite a few new dice you can add to your dataset.
  prefs: []
  type: TYPE_NORMAL
- en: You can even run the mutation twice. Mutations of mutations are still distinguishable
    by the human eye. As you look at the four generated dice in [Figure 12-7](#combos),
    it’s still apparent that these are generated from the side showing value one.
    The new dice are still significantly visually distant from all other dice combinations,
    even though they are made-up second-generation mutations.
  prefs: []
  type: TYPE_NORMAL
- en: '![Mutations via combinations of the previous dice to make new dice](assets/ltjs_1207.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-7\. Four mutations via combinations of dice
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you might have assumed, there will be some accidental duplication as we create
    these wild Tetris-like shapes. Rather than trying to avoid repeating configurations,
    you can remove duplicates with a call to `tf.unique`.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The GPU currently does not support `tf.unique`, so you might have to set the
    backend to CPU to call `unique`. Afterward, you can return the backend to GPU
    if you’d like.
  prefs: []
  type: TYPE_NORMAL
- en: 'At a high level, shifting and then mutating an image of a die generated over
    more than two hundred dice from a single die. Here is the high-level recap:'
  prefs: []
  type: TYPE_NORMAL
- en: Shift the image one pixel in every direction.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Combine the shifted tensors in all possible combinations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform the same mutation combination on the previous set.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Consolidate the data with only the unique results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now we have more than two hundred tensors for each of the nine possible combinations.
    Not bad, considering you had only nine tensors a moment ago. Are two hundred images
    enough? We’ll have to test to find out.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can jump immediately into training, or you can save the data to a file.
    [The code associated with this chapter](https://oreil.ly/Vr98u) writes a file.
    The primary function of this section can be summarized at a high level with the
    following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Training
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have nearly two thousand images total, you can try to train your
    model. The data should be stacked and shuffled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_dicify__capstone_project_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: You’re creating large arrays of data by concatenating individual arrays of data.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_dicify__capstone_project_CO3-2)'
  prefs: []
  type: TYPE_NORMAL
- en: You’re then creating answer arrays of the exact same size as each dataset and
    filling them with the answer using `Array`’s `.fill`.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_dicify__capstone_project_CO3-3)'
  prefs: []
  type: TYPE_NORMAL
- en: You can then randomize these two arrays together.
  prefs: []
  type: TYPE_NORMAL
- en: 'From here, you can peel off a test set or not. Look at the associated code
    if you’d like help on how to do so. Once you have your data broken up how you’d
    like, you then convert these two JavaScript arrays into proper tensors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_dicify__capstone_project_CO4-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The stacked tensor is created, and for simplicity it is returned to rank-three
    images by expanding the dimensions at index three.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_dicify__capstone_project_CO4-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The numeric answers are then one-hot encoded into tensors to fit a softmax model
    output.
  prefs: []
  type: TYPE_NORMAL
- en: The model is constructed in a straightforward and small design. You might find
    a better structure, but for this, I went with two hidden layers. Feel free to
    come back and experiment with the architecture and see what you can get for speed
    and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The model starts by flattening the image input to connect them to a neural network,
    and then you have a `64`- and an `8`-unit layer. The last layer is nine possible
    dice configurations.
  prefs: []
  type: TYPE_NORMAL
- en: This model was able to attain near-perfect accuracy in a few epochs. This is
    promising for the generated data, but in the next section, we’ll see how it fares
    against actual images.
  prefs: []
  type: TYPE_NORMAL
- en: The Site Interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you have a trained model, it’s time to test it with nongenerated data.
    There are sure to be some mistakes, but if the model performs decently, this will
    be quite a success!
  prefs: []
  type: TYPE_NORMAL
- en: Your website will need to be told how many dice to use and then break an input
    image into that many patches. The patches will be resized into 12 x 12 inputs
    (like our training data), and then you run the model on the images for predictions.
    In the example shown in [Figure 12-8](#convert_img), an image of an X has been
    told to be converted into four dice. So the image is cut into four quadrants,
    and each of those is then predicted. They should ideally align the die to draw
    the X.
  prefs: []
  type: TYPE_NORMAL
- en: '![TensorFlow logo to 32 x 32 dice before and after](assets/ltjs_1208.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-8\. TensorFlow logo to 32 x 32 dice
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Once you have the resulting predictions, you can reconstruct a new tensor composed
    of the designated image tensors.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The images were trained on zeros and ones. This means, for you to expect a decent
    result, your input image should also be composed of zeros and ones. Color or even
    shades of gray will have spurious results.
  prefs: []
  type: TYPE_NORMAL
- en: 'The core of the application code should look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The prediction of the results is your classic “data in, data out” model behavior.
    The two most complicated parts will be `cutData` and the `displayPredictions`
    methods. Here, your tensor skills are ready to shine.
  prefs: []
  type: TYPE_NORMAL
- en: Cut into Dice
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `cutData` method will utilize `tf.split`, which splits a tensor into N subtensors
    along an axis. You can split an image up by using `tf.split` along each axis to
    make a patch or grid of images to predict.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_dicify__capstone_project_CO5-1)'
  prefs: []
  type: TYPE_NORMAL
- en: You will only need a grayscale version of the image converted from pixels.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_dicify__capstone_project_CO5-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The image is resized so it can be evenly split by the number of dice you require.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_dicify__capstone_project_CO5-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The image is cut along the first axis (height).
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_dicify__capstone_project_CO5-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Those columns are then cut along the width axis to create a grid of tensors.
  prefs: []
  type: TYPE_NORMAL
- en: The `grid` variable now contains an array of images. You can resize the images
    and stack them for prediction when needed. For example, [Figure 12-9](#tf_grid)
    is a grid of slices because the black-and-white cut of the TensorFlow logo would
    create lots of smaller images that will be converted to dice.
  prefs: []
  type: TYPE_NORMAL
- en: '![TensorFlow logo to 27x27 patches](assets/ltjs_1209.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-9\. The slices of a black-and-white TensorFlow logo
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Reconstruct the Image
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have your predictions, you’ll want to reconstruct the image, but you’ll
    want to switch the original patches out for their predicted dice.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code to reconstruct and create a large tensor from the predicted answers
    could work like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_dicify__capstone_project_CO6-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The `diceTensors` to draw are loaded from the `diceData` and converted.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_dicify__capstone_project_CO6-2)'
  prefs: []
  type: TYPE_NORMAL
- en: To go from a 1D back to a 2D, the index is calculated for each row.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_dicify__capstone_project_CO6-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The rows are made by concatenating along the width axis.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_dicify__capstone_project_CO6-4)'
  prefs: []
  type: TYPE_NORMAL
- en: The columns are made by concatenating the rows along the default (height) axis.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_dicify__capstone_project_CO6-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Ta-da! The newly constructed tensor can be displayed.
  prefs: []
  type: TYPE_NORMAL
- en: If you load a black-and-white image and process it, it’s time for the moment
    of truth. Were 200ish generated images for each class sufficient?
  prefs: []
  type: TYPE_NORMAL
- en: I set the `numDice` variable to 27\. A 27 x 27 dice image is pretty low-resolution
    and would cost around $80 in dice on Amazon. Let’s see what it looks like with
    the TensorFlow logo. [Figure 12-10](#tf) shows the result.
  prefs: []
  type: TYPE_NORMAL
- en: '![TensorFlow logo to 27 x 27 dice before and after](assets/ltjs_1210.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-10\. TensorFlow logo to 27 x 27 dice
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It works! Not bad at all. You just taught an AI how to be an artist. If you
    bump the number of dice even higher, the image becomes more apparent.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter Review
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using the strategies from this chapter, I trained an AI to handle red-and-white
    dice. I don’t have a lot of patience, so I only made a 19x19 image for a friend.
    The result was quite impressive. It took me about 30 minutes to put all the dice
    into the shadow box shown in [Figure 12-11](#ir_dice). I can’t say I would have
    braved this effort if I didn’t have printed instructions.
  prefs: []
  type: TYPE_NORMAL
- en: '![image of the 19 x 19 finished product.](assets/ltjs_1211.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-11\. The completed 19 x 19 red-and-white dice with a backlight
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can go much further. What mad scientist doesn’t have a portrait of themselves?
    Now your portrait can be made from dice. Maybe you can teach a small robot how
    to lay the dice out for you, so you can build huge frames full of hundreds of
    pounds of dice (see [Figure 12-12](#dice_wall)).
  prefs: []
  type: TYPE_NORMAL
- en: '![person looking at a wall of dice that makes an image](assets/ltjs_1212.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-12\. The perfect mad science portrait
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can continue to improve the data and build better results, and you’re not
    just limited to plain old black-and-white dice. You can use your AI skills to
    draw with decorative dice, sticky notes, Rubik’s Cubes, Legos, coins, wood chips,
    cookies, stickers, or anything.
  prefs: []
  type: TYPE_NORMAL
- en: While this experiment was a success for version 1.0, we’ve identified countless
    experiments you can take on to improve your model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter Challenge: Easy as 01, 10, 11'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now you have a powerful new model that can be an artist for any photo that is
    composed of black `0` and white `1` pixels. Unfortunately, most images, even grayscale,
    have intermediate values. If only there was a way to take an image and convert
    it to black and white efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Converting images to binary black and white is called *binarization*. The world
    of computer vision has all kinds of impressive algorithms on how to best binarize
    an image. Let’s focus on the simplest.
  prefs: []
  type: TYPE_NORMAL
- en: In this Chapter Challenge, take the `tf.where` method and use it to check if
    a pixel is beyond a given threshold. Using that threshold, you can convert each
    pixel of a grayscale image to `1` or `0`. This will prepare normal graphics input
    into your dice model.
  prefs: []
  type: TYPE_NORMAL
- en: With a few lines of code, you can convert images with thousands of variations
    of light and condense them down to black-and-white pixels, as shown in [Figure 12-13](#binarize).
  prefs: []
  type: TYPE_NORMAL
- en: '![A skull turned into black-and-white pixels.](assets/ltjs_1213.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 12-13\. The binarized skull
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can find the answer to this challenge in [Appendix B](app02.html#appendix_b).
  prefs: []
  type: TYPE_NORMAL
- en: Review Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s review the lessons you’ve learned from the code you’ve written in this
    chapter. Take a moment to answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What TensorFlow.js method allows you to break a tensor into an equal set of
    sub-tensors?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the name of the process with which you create slightly modified alternatives
    of data to grow your data set?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is Gant Laborde so amazing?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Solutions to these exercises are available in [Appendix A](app01.html#book_appendix).
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch12.html#idm45049236364264-marker)) If you’d like to learn more about
    camera obscura, watch the documentary [*Tim’s Vermeer*](https://oreil.ly/IrjNM).
  prefs: []
  type: TYPE_NORMAL
