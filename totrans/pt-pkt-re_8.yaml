- en: Chapter 8\. The PyTorch Ecosystem and Additional Resources
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, you’ve learned everything you need to design and deploy
    deep learning models with PyTorch. You have learned how to build, train, test,
    and accelerate your models across different platforms and how to deploy those
    models to the cloud and edge devices. As you’ve seen, PyTorch has powerful capabilities
    in both development and deployment environments and is highly extensible, allowing
    you to create customizations tailored to your needs.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: To conclude this reference guide, we’ll explore the PyTorch Ecosystem, other
    supporting libraries, and additional resources. The PyTorch Ecosystem is one of
    the most powerful advantages of PyTorch. It provides a rich set of projects, tools,
    models, libraries, and platforms to explore AI and accelerate your AI development.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The PyTorch Ecosystem includes projects and libraries created by researchers,
    third-party vendors, and the PyTorch community. These projects are well maintained
    and have been vetted by the PyTorch team to ensure their quality and utility.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the PyTorch project includes other libraries that support specific
    domains, including Torchvision for computer vision and Torchtext for NLP. PyTorch
    also supports other packages like TensorBoard for visualization, and there’s an
    abundance of learning resources for further study, like Papers with Code and PyTorch
    Academy.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll begin with an overview of the PyTorch Ecosystem and a
    high-level view of its supported projects and tools. Then we’ll dig a little deeper
    into some of the most powerful and popular resources, with reference material
    about their usage and APIs provided along the way. Finally, I’ll show you how
    to learn more with a variety of tutorials, books, courses, and other training
    resources.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by looking at all the Ecosystem has to offer.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: The PyTorch Ecosystem
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As of early 2021, the [PyTorch Ecosystem](https://pytorch.tips/ecosystem) features
    over 50 libraries and projects, and the list continues to grow. Some of these
    are domain-specific projects, such as those specifically for computer vision or
    NLP solutions. Other projects, such as PyTorch Lightning and fastai, provide frameworks
    for writing concise code, while projects like PySyft and Crypten support security
    and privacy. There are also projects that support reinforcement learning, gaming
    models, model interpretability, and acceleration. In this section, we’ll explore
    projects included in the PyTorch Ecosystem.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 8-1](#table_eco_cv) provides a list of the Ecosystem projects that support
    *computer vision* applications.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-1\. Computer vision projects
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '| Project | Description |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
- en: '| Torchvision | PyTorch’s computer vision library that provides common transforms,
    models, and utilities to support computer vision applications ([*https://pytorch.tips/torchvision*](https://pytorch.tips/torchvision))
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
- en: '| Detectron2 | Facebook’s objection detection and segmentation platform ([*https://pytorch.tips/detectron2*](https://pytorch.tips/detectron2))
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
- en: '| Albumentations | Image augmentation library ([*https://pytorch.tips/albumentations*](https://pytorch.tips/albumentations))
    |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
- en: '| PyTorch3D | Collection of reusable components for 3D computer vision ([*https://pytorch.tips/pytorch3d*](https://pytorch.tips/pytorch3d))
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
- en: '| Kornia | Library of differentiable modules for computer vision ([*https://pytorch.tips/kornia*](https://pytorch.tips/kornia))
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
- en: '| MONAI | Framework for deep learning in healthcare imaging ([*https://pytorch.tips/monai*](https://pytorch.tips/monai))
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
- en: '| TorchIO | Toolkit for 3D medical images ([*https://pytorch.tips/torchio*](https://pytorch.tips/torchio))
    |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
- en: Torchvision is one of the most powerful libraries for computer vision applications
    and is included in the PyTorch project. It’s also maintained by the PyTorch development
    team. We’ll cover the Torchvision API in more detail later in this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch3D and TorchIO provide additional support for 3D imaging, while TorchIO
    and MONAI focus on medical imaging applications. Detectron2 is a powerful platform
    for object detection. If you’re conducting computer vision research and development,
    these extensions may help accelerate your results.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: As with computer vision, there have been major advances in NLP research over
    the past decade, and NLP applications are also well supported by PyTorch.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 8-2](#table_eco_nlp) provides a list of the Ecosystem projects that
    support *NLP and audio-based* applications.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-2\. NLP and audio projects
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '| Project | Description |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
- en: '| Torchtext | PyTorch’s NLP and text processing library ([*https://pytorch.tips/torchtext*](https://pytorch.tips/torchtext))
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: '| Flair | Simple framework for NLP ([*https://pytorch.tips/flair*](https://pytorch.tips/flair))
    |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: '| AllenNLP | Library for designing and evaluating NLP models ([*https://pytorch.tips/allennlp*](https://pytorch.tips/allennlp))
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: '| ParlAI | Framework for sharing, training, and testing dialogue models ([*https://pytorch.tips/parlai*](https://pytorch.tips/parlai))
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
- en: '| NeMo | Toolkit for conversational AI ([*https://pytorch.tips/nemo*](https://pytorch.tips/nemo))
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
- en: '| PyTorch NLP | Basic utilities for NLP ([*https://pytorch.tips/pytorchnlp*](https://pytorch.tips/pytorchnlp))
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: '| Translate | Facebook’s machine translation platform ([*https://pytorch.tips/translate*](https://pytorch.tips/translate))
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: '| TorchAudio | PyTorch’s library for audio preprocessing ([*https://pytorch.tips/torchaudio*](https://pytorch.tips/torchaudio))
    |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
- en: Like Torchvision, Torchtext is included as part of the PyTorch project and is
    maintained by the PyTorch development team. Torchtext provides powerful functionality
    for processing text data and developing NLP-based models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Flair, AllenNLP, and PyTorch NLP provide additional capabilities for text-based
    processing and NLP model development. ParlAI and NeMo provide tools to develop
    dialogue and conversational AI systems, while Translate focuses on machine translation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: TorchAudio provides functions for handling audio files like speech and music.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning and gaming are also rapidly growing fields of research,
    and there are tools to support them using PyTorch.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 8-3](#table_eco_gaming) provides a list of the Ecosystem projects that
    support *gaming and reinforcement learning* applications.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-3\. Gaming and reinforcement learning projects
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '| Project | Description |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
- en: '| ELF | Project for training and testing algorithms in game environments ([*https://pytorch.tips/elf*](https://pytorch.tips/elf))
    |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
- en: '| PFRL | Library of deep reinforcement algorithms ([*https://pytorch.tips/pfrl*](https://pytorch.tips/pfrl))
    |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
- en: ELF (extensive, lightweight, and flexible platform for game research) is an
    open source project developed by Facebook that reimplements gaming algorithms
    like AlphaGoZero and AlphaZero. PFRL (preferred reinforcement learning) is a PyTorch-based
    open source deep reinforcement learning library developed by Preferred Networks,
    the creators of Chainer and ChainerRL. It can be used to create baseline algorithms
    for reinforcement learning. PFRL currently has reproducibility scripts for 11
    key deep reinforcement learning algorithms based on original research papers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: As you’ve seen in this book, PyTorch is a highly customizable framework. This
    characteristic sometimes results in the need to write the same boilerplate code
    often for common tasks. To help developers write code faster and eliminate the
    need for boilerplate code, several PyTorch projects provide high-level programming
    APIs or compatibility with other high-level frameworks like scikit-learn.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 8-4](#table_eco_hlp) provides a list of the Ecosystem projects that
    support *high-level programming*.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-4\. High-level programming projects
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '| Project | Description |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
- en: '| fastai | Library that simplifies training using modern practices ([*https://pytorch.tips/fastai*](https://pytorch.tips/fastai))
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| fastai | 简化使用现代实践进行训练的库（[*https://pytorch.tips/fastai*](https://pytorch.tips/fastai)）
    |'
- en: '| PyTorch Lightning | Customizable Keras-like ML library that eliminates boilerplate
    code ([*https://pytorch.tips/lightning*](https://pytorch.tips/lightning)) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch Lightning | 可定制的类Keras ML库，消除样板代码（[*https://pytorch.tips/lightning*](https://pytorch.tips/lightning)）
    |'
- en: '| Ignite | Library for writing compact, full-featured training loops ([*https://pytorch.tips/ignite*](https://pytorch.tips/ignite))
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Ignite | 用于编写紧凑、功能齐全的训练循环的库（[*https://pytorch.tips/ignite*](https://pytorch.tips/ignite)）
    |'
- en: '| Catalyst | Framework for compact reinforcement learning pipelines ([*https://pytorch.tips/catalyst*](https://pytorch.tips/catalyst))
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| Catalyst | 用于紧凑强化学习流水线的框架（[*https://pytorch.tips/catalyst*](https://pytorch.tips/catalyst)）
    |'
- en: '| skorch | Provides PyTorch compatibility with scikit-learn ([*https://pytorch.tips/skorch*](https://pytorch.tips/skorch))
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| skorch | 提供与scikit-learn兼容的PyTorch（[*https://pytorch.tips/skorch*](https://pytorch.tips/skorch)）
    |'
- en: '| Hydra | Framework for configuring complex applications ([*https://pytorch.tips/hydra*](https://pytorch.tips/hydra))
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| Hydra | 用于配置复杂应用程序的框架（[*https://pytorch.tips/hydra*](https://pytorch.tips/hydra)）
    |'
- en: '| higher | Facilitates the implementation of complex meta-learning algorithms
    ([*https://pytorch.tips/higher*](https://pytorch.tips/higher)) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| higher | 促进复杂元学习算法实现的库（[*https://pytorch.tips/higher*](https://pytorch.tips/higher)）
    |'
- en: '| Poutyne | Keras-like framework for boilerplate code ([*https://pytorch.tips/poutyne*](https://pytorch.tips/poutyne))
    |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| Poutyne | 用于样板代码的类Keras框架（[*https://pytorch.tips/poutyne*](https://pytorch.tips/poutyne)）
    |'
- en: Fastai is a research and learning framework built on PyTorch. It has comprehensive
    documentation and has provided a high-level API for PyTorch since the library’s
    early days. You can get up to speed with the framework quickly by consultng its
    documentation and free [online courses](https://pytorch.tips/fastai) or reading
    the book [*Deep Learning for Coders with fastai and PyTorch*](https://pytorch.tips/fastai-book)
    by Jeremy Howard and Sylvain Gugger (O’Reilly).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Fastai是建立在PyTorch上的研究和学习框架。它有全面的文档，并自早期提供了PyTorch的高级API。您可以通过查阅其文档和免费的[在线课程](https://pytorch.tips/fastai)或阅读Jeremy
    Howard和Sylvain Gugger（O'Reilly）合著的书籍[*使用fastai和PyTorch进行编码的深度学习*](https://pytorch.tips/fastai-book)来快速掌握该框架。
- en: PyTorch Lightning has also become one a very popular high-level programming
    API for PyTorch. It provides all the necessary boilerplate code for training,
    validation, and test loops while allowing you to easily add customizations for
    your methods.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Lightning也已成为PyTorch非常受欢迎的高级编程API之一。它为训练、验证和测试循环提供了所有必要的样板代码，同时允许您轻松添加自定义方法。
- en: Ignite and Catalyst are also popular high-level frameworks, while skorch and
    Poutyne provide scikit-learn and Keras-like interfaces, respectively. Hydra and
    higher are used to simplify the configuration of complex applications.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Ignite和Catalyst也是流行的高级框架，而skorch和Poutyne分别提供了类似于scikit-learn和Keras的接口。Hydra和higher用于简化复杂应用程序的配置。
- en: In addition to high-level frameworks, there are packages in the Ecosystem that
    support hardware acceleration and optimized inference.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 除了高级框架外，生态系统中还有支持硬件加速和优化推理的软件包。
- en: '[Table 8-5](#table_eco_inference) provides a list of ecosystem projects that
    support *inference acceleration* applications.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-5提供了支持*推理加速*应用程序的生态系统项目列表。
- en: Table 8-5\. Inference projects
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-5。推理项目
- en: '| Project | Description |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Glow | ML compiler for hardware acceleration ([*https://pytorch.tips/glow*](https://pytorch.tips/glow))
    |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| Glow | 用于硬件加速的ML编译器（[*https://pytorch.tips/glow*](https://pytorch.tips/glow)）
    |'
- en: '| Hummingbird | Compiles trained models for faster inference ([*https://pytorch.tips/hummingbird*](https://pytorch.tips/hummingbird))
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| Hummingbird | 编译经过训练的模型以实现更快推理的库（[*https://pytorch.tips/hummingbird*](https://pytorch.tips/hummingbird)）
    |'
- en: Glow is a machine learning compiler and execution engine for hardware accelerators,
    and it can be used as a backend for high-level deep learning frameworks. The compiler
    allows state-of-the-art optimizations and code generation of neural network graphs.
    Hummingbird is an open source project developed by Microsoft. It is a library
    for compiling trained, traditional ML models into tensor computations and seamlessly
    leverages PyTorch to accelerate traditional ML models.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Glow是用于硬件加速器的机器学习编译器和执行引擎，可以用作高级深度学习框架的后端。该编译器允许进行最先进的优化和神经网络图的代码生成。Hummingbird是由微软开发的开源项目，是一个库，用于将经过训练的传统ML模型编译为张量计算，并无缝地利用PyTorch加速传统ML模型。
- en: In addition to accelerating inference, the PyTorch Ecosystem also contains projects
    to accelerate training and optimize models using distributed training.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 除了加速推理外，PyTorch生态系统还包含用于加速训练和使用分布式训练优化模型的项目。
- en: '[Table 8-6](#table_eco_distributed) provides a list of ecosystem projects that
    support *distributed training and model optimization*.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-6提供了支持*分布式训练和模型优化*的生态系统项目列表。
- en: Table 8-6\. Distributed training and model optimization projects
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-6。分布式训练和模型优化项目
- en: '| Project | Description |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Ray | Fast, simple framework for building and running distributed applications
    ([*https://pytorch.tips/ray*](https://pytorch.tips/ray)) |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| Ray | 用于构建和运行分布式应用程序的快速、简单框架（[*https://pytorch.tips/ray*](https://pytorch.tips/ray)）
    |'
- en: '| Horovod | Distributed deep learning training framework for TensorFlow, Keras,
    PyTorch, and Apache MXNet ([*https://pytorch.tips/horovod*](https://pytorch.tips/horovod))
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| Horovod | 用于TensorFlow、Keras、PyTorch和Apache MXNet的分布式深度学习训练框架（[*https://pytorch.tips/horovod*](https://pytorch.tips/horovod)）
    |'
- en: '| DeepSpeed | Optimization library ([*https://pytorch.tips/deepspeed*](https://pytorch.tips/deepspeed))
    |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| DeepSpeed | 优化库（[*https://pytorch.tips/deepspeed*](https://pytorch.tips/deepspeed)）
    |'
- en: '| Optuna | Automated hyperparameter search and optimization ([*https://pytorch.tips/optuna*](https://pytorch.tips/optuna))
    |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| Optuna | 自动化超参数搜索和优化（[*https://pytorch.tips/optuna*](https://pytorch.tips/optuna)）
    |'
- en: '| Polyaxon | Platform for building, training, and monitoring large-scale deep
    learning applications ([*https://pytorch.tips/polyaxon*](https://pytorch.tips/polyaxon))
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| Polyaxon | 用于构建、训练和监控大规模深度学习应用程序的平台（[*https://pytorch.tips/polyaxon*](https://pytorch.tips/polyaxon))
    |'
- en: '| Determined | Platform that trains models using shared GPUs and collaboration
    ([*https://pytorch.tips/determined*](https://pytorch.tips/determined)) |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| Determined | 使用共享GPU和协作训练模型的平台（[*https://pytorch.tips/determined*](https://pytorch.tips/determined))
    |'
- en: '| Allegro Trains | Library that contains a deep learning experiment manager,
    versioning, and machine learning ops ([*https://pytorch.tips/allegro*](https://pytorch.tips/allegro))
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| Allegro Trains | 包含深度学习实验管理器、版本控制和机器学习操作的库（[*https://pytorch.tips/allegro*](https://pytorch.tips/allegro))
    |'
- en: Ray is a Python API for building distributed applications and is packaged with
    other libraries for accelerating machine learning workloads. We used one of these
    packages, Ray Tune, in [Chapter 6](ch06.xhtml#pytorth_acceleration_and_optimization)
    to tune hyperparameters on a distributed system. Ray is a very powerful package
    that can also support scalable reinforcement learning, distributed training, and
    scalable serving. Horovod is another distributed framework. It is focused on distributed
    training and can be used with Ray.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Ray是一个用于构建分布式应用程序的Python API，并打包了其他库以加速机器学习工作负载。我们在[第6章](ch06.xhtml#pytorth_acceleration_and_optimization)中使用了其中一个软件包Ray
    Tune来在分布式系统上调整超参数。Ray是一个非常强大的软件包，还可以支持可扩展的强化学习、分布式训练和可扩展的服务。Horovod是另一个分布式框架。它专注于分布式训练，并可与Ray一起使用。
- en: DeepSpeed, Optuna, and Allegro Trains also support hyperparameter tuning and
    model optimization. Polyaxon can be used to train and monitor models at scale,
    and Determined focuses on sharing GPUs for accelerated training.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: DeepSpeed、Optuna和Allegro Trains还支持超参数调优和模型优化。Polyaxon可用于规模化训练和监控模型，而Determined专注于共享GPU以加速训练。
- en: With the growth in PyTorch’s popularity, there have been quite a few specialized
    packages developed to support niche domains and specific tools. Many of these
    tools aim to improve models or the preprocessing of data.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 随着PyTorch的流行，已经开发了许多专门的软件包来支持特定领域和特定工具。这些工具中的许多旨在改进模型或数据的预处理。
- en: '[Table 8-7](#table_eco_modeling) provides a list of the Ecosystem projects
    that support *modeling and data processing*.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-7](#table_eco_modeling)提供了支持*建模和数据处理*的生态系统项目列表。'
- en: Table 8-7\. Modeling and data processing projects
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-7. 建模和数据处理项目
- en: '| Project | Description |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 项目 | 描述 |'
- en: '| --- | --- |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| TensorBoard | TensorBoard’s data and model visualization tool is integrated
    into PyTorch ([*https://pytorch.tips/pytorch-tensorboard*](https://pytorch.tips/pytorch-tensorboard))
    |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| TensorBoard | TensorBoard的数据和模型可视化工具已集成到PyTorch中（[*https://pytorch.tips/pytorch-tensorboard*](https://pytorch.tips/pytorch-tensorboard))
    |'
- en: '| PyTorch Geometric | Geometric deep learning extension library for PyTorch
    ([*https://pytorch.tips/geometric*](https://pytorch.tips/geometric)) |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| PyTorch Geometric | 用于PyTorch的几何深度学习扩展库（[*https://pytorch.tips/geometric*](https://pytorch.tips/geometric))
    |'
- en: '| Pyro | Flexible and extensible deep probabilistic modeling ([*https://pytorch.tips/pyro*](https://pytorch.tips/pyro))
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| Pyro | 灵活且可扩展的深度概率建模（[*https://pytorch.tips/pyro*](https://pytorch.tips/pyro))
    |'
- en: '| Deep Graph Library (DGL) | Library for implementation of graph neural networks
    ([*https://pytorch.tips/dgl*](https://pytorch.tips/dgl)) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| Deep Graph Library (DGL) | 用于实现图神经网络的库（[*https://pytorch.tips/dgl*](https://pytorch.tips/dgl))
    |'
- en: '| MMF | Facebook’s modular framework for multi-model deep learning (vision
    and language) ([*https://pytorch.tips/mmf*](https://pytorch.tips/mmf)) |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| MMF | Facebook的多模型深度学习（视觉和语言）模块化框架（[*https://pytorch.tips/mmf*](https://pytorch.tips/mmf))
    |'
- en: '| GPyTorch | Library for creating scalable Gaussian process models ([*https://pytorch.tips/gpytorch*](https://pytorch.tips/gpytorch))
    |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| GPyTorch | 用于创建可扩展高斯过程模型的库（[*https://pytorch.tips/gpytorch*](https://pytorch.tips/gpytorch))
    |'
- en: '| BoTorch | Library for Bayesian optimization ([*https://pytorch.tips/botorch*](https://pytorch.tips/botorch))
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| BoTorch | 用于贝叶斯优化的库（[*https://pytorch.tips/botorch*](https://pytorch.tips/botorch))
    |'
- en: '| Torch Points 3D | Framework for unstructured 3D spatial data ([*https://pytorch.tips/torchpoints3d*](https://pytorch.tips/torchpoints3d))
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Torch Points 3D | 用于非结构化3D空间数据的框架（[*https://pytorch.tips/torchpoints3d*](https://pytorch.tips/torchpoints3d))
    |'
- en: '| TensorLy | High level API for tensor methods and deep tensorized neural networks
    ([*https://pytorch.tips/tensorly*](https://pytorch.tips/tensorly))([*https://pytorch.tips/advertorch*](https://pytorch.tips/advertorch))
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| TensorLy | 用于张量方法和深度张量神经网络的高级API（[*https://pytorch.tips/tensorly*](https://pytorch.tips/tensorly))([*https://pytorch.tips/advertorch*](https://pytorch.tips/advertorch))
    |'
- en: '| BaaL | Implements active learning from Bayesian theory ([*https://pytorch.tips/baal*](https://pytorch.tips/baal))
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| BaaL | 从贝叶斯理论中实现主动学习（[*https://pytorch.tips/baal*](https://pytorch.tips/baal))
    |'
- en: '| PennyLane | Library for quantum ML ([*https://pytorch.tips/pennylane*](https://pytorch.tips/pennylane))
    |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| PennyLane | 量子机器学习库（[*https://pytorch.tips/pennylane*](https://pytorch.tips/pennylane))
    |'
- en: TensorBoard is a very popular visualization tool developed for TensorFlow that
    can be used for PyTorch as well. We’ll cover this tool and its PyTorch API later
    in this chapter.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard是为TensorFlow开发的非常流行的可视化工具，也可以用于PyTorch。我们将在本章后面介绍这个工具及其PyTorch API。
- en: PyTorch Geometric, Pyro, GPyTorch, BoTorch, and BaaL all support different types
    of modeling, such as geometric, probabilistic, Gaussian modeling, and Bayesian
    optimization.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Geometric、Pyro、GPyTorch、BoTorch和BaaL都支持不同类型的建模，如几何建模、概率建模、高斯建模和贝叶斯优化。
- en: Facebook’s MMF is a feature-rich package for multi-modal modeling, and Torch
    Points 3D can be used to model generic 3D spatial data.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Facebook的MMF是一个功能丰富的多模态建模软件包，而Torch Points 3D可用于对通用的3D空间数据进行建模。
- en: PyTorch’s maturity and stability as a tool shows in the advent of packages used
    to support security and privacy. Security and privacy concerns are becoming more
    important as regulations require systems to be compliant in these domains.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch作为一个工具的成熟和稳定性体现在用于支持安全和隐私的软件包的出现。随着法规要求系统在这些领域合规，安全和隐私问题变得更加重要。
- en: '[Table 8-8](#table_eco_sec) provides a list of ecosystem projects that support
    *security and privacy*.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-8\. Security and privacy projects
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '| Project | Description |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
- en: '| AdverTorch | Modules for adversarial examples and defending against attacks
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
- en: '| PySyft | Library for model encryption and privacy ([*https://pytorch.tips/pysyft*](https://pytorch.tips/pysyft))
    |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
- en: '| Opacus | Library for training models with differential privacy ([*https://pytorch.tips/opacus*](https://pytorch.tips/opacus))
    |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
- en: '| CrypTen | Framework for privacy preserving ML ([*https://pytorch.tips/crypten*](https://pytorch.tips/crypten))
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
- en: PySyft, Opacus, and CrypTen are PyTorch packages that support security and privacy.
    They add features to protect and encrypt models and the data used to create them.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'Often deep learning seems like a black box, where developers have no idea why
    models make the decisions they make. Today, however, this lack of transparency
    is no longer acceptable: there is a growing awareness that companies and their
    executives must be held accountable for the fairness and operations of their algorithms.
    Model interpretability is important for researchers, developers, and company executives
    to understand why models produce their results.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 8-9](#table_eco_interpret) shows the ecosystem project that support
    *model* *interpretability*.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-9\. Model interpretability projects
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '| Project | Description |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: '| Captum | Library for model interpretability ([*https://pytorch.tips/captum*](https://pytorch.tips/captum))
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
- en: '| Visual attribution | PyTorch implementation of recent visual attribution
    methods for model interpretability ([*https://pytorch.tips/visual-attribution*](https://pytorch.tips/visual-attribution))
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
- en: Currently, Captum is the premier PyTorch project that supports model interpretability.
    The Visual attribution package is useful for interpreting computer vision models
    and identifying image saliency. As the field expands, more projects are sure to
    enter this space.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the PyTorch Ecosystem includes a broad range of open source
    projects that can assist you in many different ways. Perhaps you are working on
    a project that could benefit other researchers. If you’d like to make your project
    a part of the official PyTorch Ecosystem, visit the [PyTorch Ecosystem application
    page](https://pytorch.tips/join-ecosystem).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'When considering applications, the PyTorch team looks for projects that meet
    the following requirements:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Your project uses PyTorch to improve the user experience, add new capabilities,
    or speed up training/inference.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Your project is stable, well maintained, and includes adequate infrastructure,
    documentation, and technical support.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Ecosystem is constantly growing. To access the latest list of projects,
    visit the [PyTorch Ecosystem website.](https://pytorch.tips/ecosystem) To update
    us on new projects for the book, please email the author at [jpapa@joepapa.ai](mailto:jpapa@joepapa.ai).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will go a little deeper into some of the PyTorch project’s supporting
    tools and libraries. We obviously can’t cover all of the available libraries and
    tools in this book, but in the following sections we’ll explore a few of the most
    popular and useful ones to give you a deeper understanding of their APIs and usage.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: Torchvision for Image and Video
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve used Torchvision through this book, and it is one of the most powerful
    and useful PyTorch libraries for computer vision research. Technically, the Torchvision
    package is part of the PyTorch project. It consists of a selection of popular
    datasets, model architectures, and common image transformations.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Datasets and I/O
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Torchvision provides a large assortment of datasets. They are included in the
    `torchvision.datasets` library and can be accessed by creating a dataset object,
    as shown in the following code:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You simply call the constructor function and pass in the appropriate options.
    This code creates a dataset object from the CIFAR-10 dataset using the training
    data with no transforms. It look for the dataset files in the current directory,
    and if they don’t exist, it will download them.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您只需调用构造函数并传入适当的选项。此代码使用训练数据从CIFAR-10数据集创建数据集对象，不使用任何转换。它会在当前目录中查找数据集文件，如果文件不存在，它将下载它们。
- en: '[Table 8-10](#table_torchvision_datasets) provides a comprehensive list of
    datasets available from Torchvision.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-10](#table_torchvision_datasets)提供了Torchvision提供的数据集的全面列表。'
- en: Table 8-10\. Torchvision datasets
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-10。Torchvision数据集
- en: '| Dataset | Description |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 描述 |'
- en: '| --- | --- |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| CelebA | Large-scale face attributes dataset with more than 200,000 celebrity
    images, each with 40 attribute annotations. |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| CelebA | 大规模人脸属性数据集，包含超过200,000张名人图像，每张图像有40个属性注释。 |'
- en: '| CIFAR-10 | CIFAR-10 dataset consisting of 60,000 32 × 32 color images in
    10 classes, split into 50,000 training and 10,000 test images. The CIFAR-100 dataset,
    which has 100 classes, is also available. |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-10 | CIFAR-10数据集包含60,000个32×32彩色图像，分为10个类别，分为50,000个训练图像和10,000个测试图像。还提供了包含100个类别的CIFAR-100数据集。
    |'
- en: '| Cityscapes | Large-scale dataset containing video sequences recorded in street
    scenes from 50 different cities, with annotations. |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| Cityscapes | 包含来自50个不同城市街景记录的视频序列的大规模数据集，带有注释。 |'
- en: '| COCO | Large-scale object detection, segmentation, and captioning dataset.
    |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| COCO | 大规模目标检测、分割和字幕数据集。 |'
- en: '| DatasetFolder | Used to create any dataset from files in a folder structure.
    |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| DatasetFolder | 用于从文件夹结构中创建任何数据集。 |'
- en: '| EMNIST | An extension of MNIST to handwritten letter. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| EMNIST | MNIST的手写字母扩展。 |'
- en: '| FakeData | A fake dataset that returns randomly generated images as PIL images.
    |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| FakeData | 一个返回随机生成图像作为PIL图像的虚假数据集。 |'
- en: '| Fashion-MNIST | Dataset of Zalando’s clothing images matching the MNIST format
    (60,000 training examples, 10,000 test examples, 28 × 28 grayscale images, 10
    classes). |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| Fashion-MNIST | Zalando服装图像数据集，符合MNIST格式（60,000个训练示例，10,000个测试示例，28×28灰度图像，10个类别）。
    |'
- en: '| Flickr | Flickr 8,000-image dataset. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| Flickr | Flickr 8,000张图像数据集。 |'
- en: '| HMDB51 | Large human motion database of video sequences. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| HMDB51 | 大型人体运动视频序列数据库。 |'
- en: '| ImageFolder | Used to create an image dataset from files in a folder structure.
    |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| ImageFolder | 用于从文件夹结构中创建图像数据集。 |'
- en: '| ImageNet | Image classification dataset with 14,197,122 images and 21,841
    word phrases. |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| ImageNet | 包含14,197,122张图像和21,841个单词短语的图像分类数据集。 |'
- en: '| Kinetics-400 | Large-scale action recognition video dataset with 650,000
    10-second video clips that cover up to 700 human action classes such as playing
    instruments, shaking hands, and hugging. |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Kinetics-400 | 大规模动作识别视频数据集，包含650,000个持续10秒的视频剪辑，涵盖高达700个人类动作类别，如演奏乐器、握手和拥抱。
    |'
- en: '| KMNIST | Kuzushiji-MNIST, a drop-in replacement for the MNIST dataset (70,000
    28 × 28 grayscale images) where one character represents each of the 10 rows of
    Hiragana. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| KMNIST | Kuzushiji-MNIST，MNIST数据集的替代品（70,000个28×28灰度图像），其中每个字符代表平假名的10行之一。
    |'
- en: '| LSUN | One million labeled images for each of 10 scene categories and 20
    object categories. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| LSUN | 每个10个场景类别和20个对象类别的一百万标记图像。 |'
- en: '| MNIST | Handwritten, single-digit numbers as 28 × 28 grayscale images with
    60,000 training and 10,000 test samples. |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| MNIST | 手写的单个数字，28×28灰度图像，有60,000个训练和10,000个测试样本。 |'
- en: '| Omniglot | Human-generated dataset of 1,623 different handwritten characters
    from 50 different alphabets. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| Omniglot | 由50种不同字母表的1,623个不同手写字符生成的数据集。 |'
- en: '| PhotoTour | Photo tourism dataset consisting of 1,024 × 1,024 bitmap images,
    each containing a 16 × 16 array of image patches. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| PhotoTour | 包含1,024×1,024位图图像的照片旅游数据集，每个图像包含一个16×16的图像块数组。 |'
- en: '| Places365 | Dataset of 10 million images comprising 400+ unique scene categories
    with 5,000 to 30,000 training images per class. |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| Places365 | 包含400多个独特场景类别的10,000,000张图像数据集，每个类别有5,000至30,000张训练图像。 |'
- en: '| QMNIST | Facebook’s project to generate an MNIST dataset from the original
    data found in the NIST Special Database 19. |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| QMNIST | Facebook的项目，从NIST特殊数据库19中找到的原始数据生成MNIST数据集。 |'
- en: '| SBD | Semantic boundaries dataset that contains annotations from 11,355 images
    for semantic segmentation. |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| SBD | 包含11,355张图像的语义分割注释的语义边界数据集。 |'
- en: '| SBU | Stony Brook University (SBU) captioned photo dataset containing over
    1 million captioned images. |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| SBU | Stony Brook大学（SBU）标题照片数据集，包含超过1,000,000张带标题的图像。 |'
- en: '| STL10 | CIFAR-10-like dataset used for unsupervised learning. 10 classes
    of 96 × 96 color images with 5,000 training, 8,000 test, and 100,000 unlabeled
    images. |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| STL10 | 用于无监督学习的类似于CIFAR-10的数据集。96×96彩色图像的10个类别，包括5,000个训练图像，8,000个测试图像和100,000个未标记图像。
    |'
- en: '| SVHN | Street view house numbers dataset, similar to MNIST but with 10× more
    data in natural scene color images. |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| SVHN | 街景房屋号码数据集，类似于MNIST，但是在自然场景彩色图像中有10倍的数据。 |'
- en: '| UCF101 | Action recognition dataset with 13,320 videos from 101 action categories.
    |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| UCF101 | 包含来自101个动作类别的13,320个视频的动作识别数据集。 |'
- en: '| USPS | Dataset of 16 × 16 handwritten text images with 10 classes, 7,291
    training and 2,007 test images. |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| USPS | 包含16×16手写文本图像的数据集，有10个类别，7,291个训练图像和2,007个测试图像。 |'
- en: '| VOC | PASCAL visual object classes image datasets for object class recognition.
    The 2012 version has 20 classes, 11,530 training/validation images with 27,450
    region of interest (ROI) annotated objects and 6,929 segmentations. |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| VOC | 用于目标类别识别的PASCAL视觉对象类别图像数据集。2012年版本有20个类别，11,530个训练/验证图像，27,450个感兴趣区域（ROI）标注对象和6,929个分割。
    |'
- en: More datasets are being added to Torchvision all the time. For an up-to-date
    list, visit the [Torchvision documentation](https://pytorch.tips/torchvision-datasets).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision不断添加更多数据集。要获取最新列表，请访问[Torchvision文档](https://pytorch.tips/torchvision-datasets)。
- en: Models
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: 'Torchvision also provides an extensive list of models, containing both the
    module architectures and pretrained weights if available. The model object is
    easily created by calling the corresponding constructor function, as shown here:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision还提供了一个广泛的模型列表，包括模块架构和预训练权重（如果有的话）。通过调用相应的构造函数，可以轻松创建模型对象，如下所示：
- en: '[PRE1]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This code creates a VGG16 model with random weights since the pretrained weights
    are not used. You can instantiate many different computer vision models by using
    a similar constructor and setting the appropriate parameters. Torchvision provides
    pretrained models using the PyTorch `torch.utils.model_zoo`. These can be constructed
    by passing `pretrained=True`.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码创建了一个带有随机权重的VGG16模型，因为没有使用预训练权重。通过使用类似的构造函数并设置适当的参数，可以实例化许多不同的计算机视觉模型。Torchvision使用PyTorch的`torch.utils.model_zoo`提供预训练模型。可以通过传递`pretrained=True`来构建这些模型。
- en: '[Table 8-11](#table_torchvision_models) provides a comprehensive list of models
    included in Torchvision, by category. These models are well known in the research
    community, and the table includes references to the research papers associated
    with each model.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[表8-11](#table_torchvision_models)提供了Torchvision中包含的模型的全面列表，按类别分类。这些模型在研究界广为人知，表中包含了与每个模型相关的研究论文的参考文献。'
- en: Table 8-11\. Torchvision models
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 表8-11. Torchvision模型
- en: '| Model | Paper |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 论文 |'
- en: '| --- | --- |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Classification** |  |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| **分类** |  |'
- en: '| AlexNet | “One Weird Trick for Parallelizing Convolutional Neural Networks,”
    by Alex Krizhevsky |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| AlexNet | “用于并行化卷积神经网络的一个奇怪技巧,” 作者：Alex Krizhevsky |'
- en: '| VGG | “Very Deep Convolutional Networks for Large-Scale Image Recognition,”
    by Karen Simonyan and Andrew Zisserman |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| VGG | “用于大规模图像识别的非常深度卷积网络,” 作者：Karen Simonyan和Andrew Zisserman |'
- en: '| ResNet | “Deep Residual Learning for Image Recognition,” by Kaiming He et
    al. |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| ResNet | “用于图像识别的深度残差学习,” 作者：Kaiming He等 |'
- en: '| SqueezeNet | “SqueezeNet: AlexNet-Level Accuracy with 50x Fewer Parameters
    and <0.5MB Model Size,” by Forrest N. Iandola et al. |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| SqueezeNet | “SqueezeNet: AlexNet级别的准确性，参数减少50倍，模型大小<0.5MB,” 作者：Forrest N.
    Iandola等 |'
- en: '| DenseNet | “Densely Connected Convolutional Networks,” by Gao Huang et al.
    |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| DenseNet | “密集连接的卷积网络,” 作者：Gao Huang等 |'
- en: '| Inception v3 | “Rethinking the Inception Architecture for Computer Vision,”
    by Christian Szegedy et al. |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Inception v3 | “重新思考计算机视觉中的Inception架构,” 作者：Christian Szegedy等 |'
- en: '| GoogLeNet | “Going Deeper with Convolutions,” by Christian Szegedy et al.
    |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| GoogLeNet | “使用卷积深入研究,” 作者：Christian Szegedy等 |'
- en: '| ShuffleNet v2 | “ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture
    Design,” by Ningning Ma et al. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| ShuffleNet v2 | “ShuffleNet V2: 高效CNN架构设计的实用指南,” 作者：马宁宁等 |'
- en: '| MobileNet v2 | “MobileNetV2: Inverted Residuals and Linear Bottlenecks,”
    by Mark Sandler et al. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| MobileNet v2 | “MobileNetV2: 反向残差和线性瓶颈,” 作者：Mark Sandler等 |'
- en: '| ResNeXt | “Aggregated Residual Transformations for Deep Neural Networks,”
    by Saining Xie et al. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| ResNeXt | “用于深度神经网络的聚合残差变换,” 作者：Saining Xie等 |'
- en: '| Wide ResNet | “Wide Residual Networks,” by Sergey Zagoruyko and Nikos Komodakis
    |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| Wide ResNet | “宽残差网络,” 作者：Sergey Zagoruyko和Nikos Komodakis |'
- en: '| MNASNet | “MnasNet: Platform-Aware Neural Architecture Search for Mobile,”
    by Mingxing Tan et al. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| MNASNet | “MnasNet: 面向移动设备的神经架构搜索,” 作者：Mingxing Tan等 |'
- en: '| **Semantic segmentation** |  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| **语义分割** |  |'
- en: '| FCN ResNet50 | “Fully Convolutional Networks for Semantic Segmentation,”
    by Jonathan Long et al. |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| FCN ResNet50 | “用于语义分割的全卷积网络,” 作者：Jonathan Long等 |'
- en: '| FCN ResNet101 | See above |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| FCN ResNet101 | 参见上文 |'
- en: '| DeepLabV3 ResNet50 | “Rethinking Atrous Convolution for Semantic Image Segmentation,”
    by Liang-Chieh Chen et al. |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| DeepLabV3 ResNet50 | “重新思考空洞卷积用于语义图像分割,” 作者：Liang-Chieh Chen等 |'
- en: '| DeepLabV3 ResNet101 | See above |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| DeepLabV3 ResNet101 | 参见上文 |'
- en: '| **Object detection** |  |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| **目标检测** |  |'
- en: '| Faster R-CNN ResNet-50 | “FPNFaster R-CNN: Towards Real-Time Object Detection
    with Region Proposal Networks,” by Shaoqing Ren et al. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Faster R-CNN ResNet-50 | “FPNFaster R-CNN: 实时目标检测与区域建议网络,” 作者：Shaoqing Ren等
    |'
- en: '| Mask R-CNN ResNet-50 FPN | “Mask R-CNN,” by Kaiming He et al. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| Mask R-CNN ResNet-50 FPN | “Mask R-CNN,” 作者：Kaiming He等 |'
- en: '| **Video classification** |  |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| **视频分类** |  |'
- en: '| ResNet 3D 18 | “A Closer Look at Spatiotemporal Convolutions for Action Recognition,”
    by Du Tran et al. |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| ResNet 3D 18 | “仔细研究时空卷积用于动作识别,” 作者：Du Tran等 |'
- en: '| ResNet MC 18 | See above |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| ResNet MC 18 | 参见上文 |'
- en: '| ResNet (2+1)D | See above |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| ResNet (2+1)D | 参见上文 |'
- en: New computer vision models are also being added to Torchvision all the time.
    For an up-to-date list, visit the [Torchvision documentation](https://pytorch.tips/torchvision-models).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision还在不断添加新的计算机视觉模型。要获取最新列表，请访问[Torchvision文档](https://pytorch.tips/torchvision-models)。
- en: Transforms, Operations, and Utilities
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变换、操作和实用程序
- en: 'Torchvision also provides a comprehensive collection of transforms, operations,
    and utilities to assist in image preprocessing and data preparation. A common
    approach to applying transforms is to form a composition of transforms and pass
    this `transforms` object into the dataset constructor function, as shown in the
    following code:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision还提供了一套全面的变换、操作和实用程序集合，以帮助图像预处理和数据准备。应用变换的常见方法是形成一组变换的组合，并将这个`transforms`对象传递给数据集构造函数，如下面的代码所示：
- en: '[PRE2]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, we create a composite transform that converts the data to a tensor using
    `ToTensor()` then normalizes the image data using predetermined means and standard
    deviations for each channel. Setting the `transform` parameter to this `train_transforms`
    object configures the dataset to apply the sequence of transforms when data is
    accessed.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个复合变换，使用`ToTensor()`将数据转换为张量，然后使用预定的均值和标准差对图像数据进行归一化。将`transform`参数设置为`train_transforms`对象会配置数据集在访问数据时应用一系列变换。
- en: '[Table 8-12](#table_torchvision_transforms) provides a complete list of available
    transforms from `torchvision.transforms`. Transforms that appear in *`italics`*
    in this and [Table 8-13](#table_torchvision_transforms_pil) are currently not
    supported by TorchScript.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-12\. Torchvision transforms
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '| Transform | Description |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
- en: '| **Operational transforms** |  |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
- en: '| `Compose()` | Creates a transform based on a sequence of other transforms
    |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
- en: '| `CenterCrop(size)` | Crops an image in the center with the given size |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
- en: '| `ColorJitter(brightness=0,` `contrast=0,` `saturation=0, hue=0)` | Randomly
    changes the brightness, contrast, saturation, and hue of an image |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
- en: '| `FiveCrop(size)` | Crops an image into four corners and the center crop |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
- en: '| `Grayscale(num_output_channels=1)` | Converts a color image to grayscale
    |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
- en: '| `Pad(`*`padding`*`,` `fill=0,` `padding_mode=constant)` | Pads the edges
    of an image with the given value |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
- en: '| `RandomAffine(`*`degrees`*`,` `translate=None,` `scale=None, shear=None,
    resample=0, fillcolor=0)` | Randomly applies an affine transformation |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
- en: '| `RandomApply(transforms, p=0.5)` | Randomly applies a list of transforms
    with a given probability |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
- en: '| `RandomCrop(`*`size`*`,` `padding=None, pad_if_needed=False, fill=0,` `padding_mode=constant)`
    | Crops an image at a random location |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
- en: '| `RandomGrayscale(p=0.1)` | Randomly converts an image to grayscale with a
    given probability |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
- en: '| `RandomHorizontalFlip(p=0.5)` | Randomly flips an image horizontally with
    a given probability |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
- en: '| `RandomPerspective(distor⁠⁠tion_​scale=0.5, p=0.5,` `interpolation=2,` `fill=0)`
    | Applies a random perspective transformation |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
- en: '| `RandomResizedCrop(`*`size`*`,` `scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333),`
    `interpolation=2)` | Resizes an image with a random size and aspect ratio |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
- en: '| `RandomRotation(`*`degrees`*`,` `resample=False,` `expand=False,` `center=None,`
    `fill=None)` | Rotates an image randomly |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
- en: '| `RandomVerticalFlip(p=0.5)` | Randomly flips an image vertically with a given
    probability |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
- en: '| `Resize(`*`size`*`,` `interpolation=2)` | Resizes an image to a random size
    |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
- en: '| `TenCrop(`*`size`*`,` `vertical_flip=False)` | Crops an image into four corners
    and the center crop and additionally provides a flipped version of each |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
- en: '| `GaussianBlur(`*`kernel_size`*`,` `sigma=(0.1, 2.0))` | Applies a Gaussian
    blur with a random kernel |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
- en: '| **Conversion transforms** |  |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
- en: '| *`ToPILImage(mode=None)`* | Converts a tensor or `numpy.ndarray` to a PIL
    image |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
- en: '| *`ToTensor()`* | Converts a PIL image or `ndarray` to a tensor |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
- en: '| **Generic transforms** |  |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
- en: '| *`Lambda(lambda)`* | Applies a user-defined `lambda` as a transform |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
- en: Most of the transforms can operate on images in tensor or PIL format with a
    `[..., C, H, W]` shape, where `...` means an arbitrary number of leading dimensions.
    However, some transforms only operate on PIL images or tensor image data.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: The transforms listed in [Table 8-13](#table_torchvision_transforms_pil) operate
    only on PIL images. These transforms are currently not supported by TorchScript.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-13\. Torchvision PIL-only transforms
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '| Transform | Description |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
- en: '| *`RandomChoice(transforms)`* | Applies a single transform picked randomly
    from a list |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
- en: '| *`RandomOrder(transforms)`* | Applies a sequence of transforms in random
    order |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
- en: The transforms listed in [Table 8-14](#table_torchvision_transforms_tensor)
    operate only on tensor images.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-14\. Torchvision tensor-only transforms
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '| Transform | Description |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
- en: '| `LinearTransformation(​trans⁠⁠formation_matrix,` `mean_vector)` | Applies
    a linear transformation to a tensor image based on a square transformation matrix
    and a `mean_vector` computed offline. |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
- en: '| `Normalize(mean, std, inplace=False)` | Normalizes a tensor image with a
    given mean and standard deviation. |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
- en: '| `RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)`
    | Randomly chooses a rectangle region and erases its pixels. |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
- en: '| `ConvertImageDtype(dtype: torch.dtype)` | Converts a tensor image to a new
    data type and automatically scales its values to match the type |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
- en: Note
  id: totrans-246
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Use `torch.nn.Sequential()` instead of `torchvi⁠sion.​transforms.Compose()`
    when scripting transforms for C++ usage. The following code shows an example:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Many of the transforms listed in the previous tables contain a random number
    generator for specifying the parameter. For example, `RandomResizedCrop()` crops
    an image to a random size and aspect ratio.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Torchvision also provides functional transforms as part of the `torchvision.transforms.functional`
    package. You can use these transforms to perform transformations with a specific
    set of parameters that you choose. For example, you could call `torchvision.transforms.functional.adjust_brightness()`
    to adjust the brightness of one on more images.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 8-15](#table_torchvision_functional) provides a list of the supported
    functional transforms.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-15\. Torchvision functional transforms
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '| Functional transforms and utilities |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
- en: '| `adjust_brightness(`*`img: torch.Tensor,`* *`brightness_factor: float`*`)`
    |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
- en: '| `adjust_contrast(`*`img: torch.Tensor,`* *`contrast_factor: float`*`)` |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
- en: '| `adjust_gamma(`*`img: torch.Tensor, gamma: float,`* *`gain: float = 1`*`)`
    |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
- en: '| `adjust_hue(`*`img: torch.Tensor, hue_factor: float`*`)` → *`torch.Tensor`*
    |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
- en: '| `adjust_saturation(`*`img: torch.Tensor,`* *`saturation_factor: float`*`)`
    |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
- en: '| `affine(`*`img: torch.Tensor, angle: float,`* *`translate: List[int],`* *`scale:
    float, shear: List[float],`* *`resample: int = 0, fillcolor: Optional[int] = None`*`)`
    |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
- en: '| `center_crop(`*`img: torch.Tensor, output_size: List[int]`*`)` |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
- en: '| `convert_image_dtype(`*`image: torch.Tensor,`* *`dtype: torch.dtype = torch.float32`*`)`
    |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
- en: '| `crop(`*`img: torch.Tensor, top: int, left: int,`* *`height: int, width:
    int`*`)` |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
- en: '| `erase(`*`img: torch.Tensor, i: int, j: int, h: int,`* *`w: int, v: torch.Tensor,
    inplace: bool = False`*`)` |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
- en: '| `five_crop(`*`img: torch.Tensor, size: List[int]`*`)` |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
- en: '| `gaussian_blur(`*`img: torch.Tensor, kernel_size: List[int], sigma: Optional[List[float]]
    = None`*`)` |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
- en: '| `hflip(`*`img: torch.Tensor`*`)` |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
- en: '| `normalize(`*`tensor: torch.Tensor, mean: List[float], std: List[float],
    inplace: bool = False`*`)` |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
- en: '| `pad(`*`img: torch.Tensor, padding: List[int],`* *`fill: int = 0, padding_mode:
    str = constant`*`)` |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
- en: '| `perspective(`*`img: torch.Tensor, startpoints: List[List[int]], endpoints:
    List[List[int]],`* *`interpolation: int = 2, fill: Optional[int] = None`*`)` |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
- en: '| `pil_to_tensor(`*`pic`*`)` |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
- en: '| `resize(`*`img: torch.Tensor, size: List[int],`* *`interpolation: int = 2`*`)`
    |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
- en: '| `resized_crop(`*`img: torch.Tensor, top: int, left: int, height: int, width:
    int, size: List[int],`* *`interpolation: int = 2`*`)` |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
- en: '| `rgb_to_grayscale(`*`img: torch.Tensor,`* *`num_output_channels: int = 1`*`)`
    |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
- en: '| `rotate(`*`img: torch.Tensor, angle: float,`* *`resample: int = 0, expand:
    bool = False,`* *`center: Optional[List[int]] = None,`* *`fill: Optional[int]
    = None`*`)` |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
- en: '| `ten_crop(`*`img: torch.Tensor, size: List[int],`* *`vertical_flip: bool
    = False`*`)` |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
- en: '| `to_grayscale(`*`img, num_output_channels=1`*`)` |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
- en: '| `to_pil_image(`*`pic, mode=None`*`)` |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
- en: '| `to_tensor(`*`pic`*`)` |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
- en: '| `vflip(`*`img: torch.Tensor`*`)` |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
- en: '| `utils.save_image(`*`tensor: Union[torch.Tensor, List[torch.Tensor]], fp:
    Union[str, pathlib.Path,`* *`BinaryIO],`* *`nrow: int = 8, padding: int = 2, normalize:
    bool = False, range: Optional[Tuple[int, int]] = None, scale_each: bool = False,
    pad_value: int = 0, format: Optional[str] = None`*`)` |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
- en: '| `utils.make_grid(`*`tensor: Union[torch.Tensor, List[torch.Tensor]], nrow:
    int = 8, padding: int = 2, normalize: bool = False, range: Optional[Tuple[int,
    int]] = None, scale_each: bool = False,`* *`pad_value: int = 0`*`)` |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
- en: As you can see in the table above, Torchvision provides a robust set of functional
    operations that you can use to process your image data. Each one has its own set
    of parameters for robust control.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: In addition, Torchvision provides functions to facilitate I/O and operations.
    [Table 8-16](#table_torchvision_io_ops) provides a list of some of these functions.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-16\. Torchvision functions for I/O and operations
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '| Function |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
- en: '| **Video** |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
- en: '| `io.read_video(`*`filename: str, start_pts: int = 0, end_pts: Optional[float]
    = None, pts_unit: str = pts`*`)` |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
- en: '| `io.read_video_timestamps9`*`filename: str, pts_unit: str = pts`*`)` |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
- en: '| `io.write_video9`*`filename: str, video_array:`* *`torch.Tensor,`* *`_fps:
    float, video_codec: str = *libx264*, options: Optional[Dict[str, Any]] = None`*`)`
    |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
- en: '| **Fine-grained video** |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
- en: '| `io.VideoReader(`*`path, stream=video`*`)` |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
- en: '| **Image** |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
- en: '| `io.decode_image(`*`input: torch.Tensor`*`)` |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
- en: '| `io.encode_jpeg(`*`input: torch.Tensor, quality: int = 75`*`)` |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
- en: '| `io.read_image(`*`path: str`*`)` |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
- en: '| `io.write_jpeg(`*`input: torch.Tensor, filename: str,`* *`quality: int =
    75`*`)` |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
- en: '| `io.encode_png(`*`input: torch.Tensor, compression_level: int = 6`*`)` |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
- en: '| `io.write_png(`*`input: torch.Tensor, filename: str,`* *`compression_level:
    int = 6`*`)` |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
- en: The preceding functions are provided so that you can quickly read and write
    video and image files in multiple formats. They allow you to speed up your image
    and video processing without the need to write these functions from scratch.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, Torchvision is a feature-rich, well-supported, and mature PyTorch
    package. This section provided a quick reference to the Torchvision API. In the
    next section, we’ll explore another popular PyTorch package for NLP and text applications
    called Torchtext.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Torchtext for NLP
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Torchtext package consists of a collection of data-processing utilities
    and popular datasets for NLP. The Torchtext API is slightly different from the
    Torchvision API, but the overall approach is the same.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Create a Dataset Object
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'First you create a dataset and describe a preprocessing pipeline, as we did
    with Torchvision transforms. Torchtext provides a set of well-known datasets out
    of the box. For example, we can load the IMDb dataset as shown in the following
    code:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We automatically create an iterator and can access the data using `next()`.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  id: totrans-309
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Torchtext significantly changed its API in PyTorch 1.8\. If the code in this
    section returns errors, you may need to upgrade your version of PyTorch.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Preprocess Data
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Torchtext also provides features to preprocess text and create data pipelines.
    Preprocessing tasks may include defining tokenizers, vocabularies, and numerical
    embeddings.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: 'In the new Torchtext API, you can access different tokenizers using the `data.get_tokenizer()`
    function, as shown in the following code:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Creating vocabularies in the new API is also flexible. You can build a vocabulary
    directly with the `Vocab` class, as shown in the following code:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see, we can set the `min_freq` to specify the cutoff frequency in
    the vocabulary. We can also assign tokens to special symbols like `<BOS>` and
    `<EOS>`, as shown in the constructor of the `Vocab` class.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: 'Another useful feature is to define transforms for text and labels, as shown
    in the following code:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We pass in a text string to our transforms, and we use the vocabulary and tokenizer
    to preprocess the data.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: Create a Dataloader for Batching
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have loaded and preprocessed our data, the last step is to create
    a dataloader to sample and batch data from the dataset. We can create a dataloader
    with the following code:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You may notice that this code is similar to the code with which we created a
    dataloader in Torchvision. Instead of passing in the dataset object, we pass the
    `train_iter` cast as a `list()`. The `DataLoader()` constructor also accepts `batch_sampler`
    and `collate_fcn` parameters (not shown in the preceding code; see the [documentation](https://pytorch.tips/data))
    so you can customize how the dataset is sampled and collated. After you create
    the dataloader, use it to train your model, as shown in the preceding code comments.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Torchtext has many useful features. Let’s explore what’s available from the
    API.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Data (torchtext.data)
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `torchtext.data` API provides functions for creating text-based dataset
    objects in PyTorch. [Table 8-17](#table_torchtext_data) lists the available functions
    in `torchtext.data`.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-17\. Torchtext data
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '| Function | Description |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
- en: '| **`torchtext.data.utils`** |  |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
- en: '| `get_tokenizer(`*`tokenizer,`* *`language=en`*`)` | Generates a tokenizer
    function for a string sentence |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
- en: '| `ngrams_itera⁠⁠tor(`*`token_​list, ngrams`*`)` | Returns an iterator that
    yields the given tokens and their ngrams |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
- en: '| **`torchtext.data.functional`** |  |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
- en: '| `generate_sp_model(​`*`file⁠⁠name, vocab_size=20000, model_type=unigram,
    model_prefix=m_user`*`)` | Trains a `SentencePiece` tokenizer |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
- en: '| `load_sp_model(`*`spm`*`)` | Loads a `SentencePiece` model from a file |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
- en: '| `sentencepiece_​numeri⁠⁠cal⁠⁠izer(`*`sp_model`*`)` | Creates a generator
    that takes in a text sentence and outputs the corresponding identifiers based
    on a `SentencePiece` model |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
- en: '| `sentencepiece_​token⁠⁠izer(`*`sp_model`*`)` | Creates a generator that takes
    in a text sentence and outputs the corresponding tokens based on a `SentencePiece`
    model |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
- en: '| `custom_replace(`*`replace_​pat⁠⁠tern`*`)` | Acts as a transform to convert
    text strings |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
- en: '| `simple_space_split(​`*`itera⁠⁠tor`*`)` | Acts as a transform to split text
    strings by spaces |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
- en: '| `numerical⁠⁠ize_tokens_​from_iterator(`*`vocab,`* *`iterator,`* *`removed_tokens=None`*`)`
    | Yields a list of identifiers from a token iterator with a `vocab` |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
- en: '| **`torchtext.data.metrics`** |  |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
- en: '| `bleu_score(`*`candidate_​cor⁠⁠pus, references_corpus, max_n=4, weights=[0.25,
    0.25, 0.25, 0.25]`*`)` | Computes the BLEU score between a candidate translation
    corpus and a reference translation corpus |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
- en: As you can see, the `torchtext.data` submodule supports functions for creating
    dataset objects based on fields aas well as for loading, preprocessing, and iterating
    through batches. Next let’s see what NLP datasets are available from the Torchtext
    library.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: Datasets (torchtext.datasets)
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Torchtext supports loading datasets from popular papers and research. You can
    find datasets for language modeling, sentiment analysis, text classification,
    question classification, entailment, machine translation, sequence tagging, question
    answering, and unsupervised learning.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 8-18](#table_torchtext_datasets) provides a comprehensive list of the
    datasets included in Torchtext.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-18\. Torchtext datasets
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '| Function | Description |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
- en: '| **Text classification** |  |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
- en: '| `TextClassificationDataset(`*`vocab, data, labels`*`)` | Generic text-classification
    dataset |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
- en: '| `IMDB(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | Binary sentiment
    analysis dataset consisting of 50,000 reviews labeled as positive or negative
    from IMDb |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
- en: '| `AG_NEWS(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | Dataset of
    news articles labeled with four topics |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
- en: '| `SogouNews(`*`root=*.data*, split=(*train*, *test*`*`))` | Dataset of news
    articles labeled with five topics |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
- en: '| `DBpedia(`*`root=*.data*, split=(*train*, *test*`*`))` | Dataset of news
    articles labeled with 14 categories |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
- en: '| `YelpReviewPolarity(`*`root=*.data*, split=(*train*, *test*`*`))` | Dataset
    of 500,000 Yelp reviews with binary classification |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
- en: '| `YelpReviewFull(`*`root=*.data*, split=(*train*, *test*`*`))` | Dataset of
    500,000 Yelp reviews with fine-grained (five-class) classification |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
- en: '| `YahooAnswers(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | Dataset
    of Yahoo answers labeled in 10 different categories |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
- en: '| `AmazonReviewPolarity(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))`
    | Dataset of Amazon reviews with binary classification |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
- en: '| `AmazonReviewFull(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` | Dataset
    of Amazon reviews with fine-grained (five-class) classification |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
- en: '| **Language modeling** |  |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
- en: '| `LanguageModelingDataset(`*`path, text_field, newline_eos=True,`* *`encoding=*utf-8*,
    **kwargs`*`)` | General language modeling dataset class |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
- en: '| `WikiText2(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))` |
    WikiText long-term dependency language modeling dataset, a collection of over
    100 million tokens extracted from the set of verified “Good” and “Featured” articles
    on Wikipedia |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
- en: '| `WikiText103(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))`
    | Larger WikiText dataset |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
- en: '| `PennTreebank(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))`
    | A relatively small dataset originally created for part of speech (POS) tagging
    |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
- en: '| **Machine translation** |  |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
- en: '| `TranslationDataset(`*`path, exts, fields, **kwargs`*`)` | Generic translation
    dataset class |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
- en: '| `IWSLT2016(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`)`*`,`*
    *`language_pair=`*`(`*`*de*, *en*`*`)`*`,`* *`valid_set=*tst2013*, test_set=*tst2014*`*`)`
    | International Conference on Spoken Language Translation (IWSLT) 2016 TED talk
    translation task |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
- en: '| `IWSLT2017(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`)`*`,`*
    *`language_pair=`*`(`*`*de*, *en*`*`))` | International Conference on Spoken Language
    Translation (IWSLT) 2017 TED talk translation task |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
- en: '| **Sequence tagging** |  |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
- en: '| `SequenceTaggingDataset(`*`path, fields, encoding=*utf-8*,`* *`separator=*t*,
    **kwargs`*`)` | Generic sequence-tagging dataset class |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
- en: '| `UDPOS(`*`root=*.data*, split=`*`(`*`*train*, *valid*, *test*`*`))` | Universal
    dependencies version 2 POS-tagged data |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
- en: '| `CoNLL2000Chunking(`*`root=*.data*, split=`*`(`*`*train*, *test*`*`))` |
    Command that downloads and loads the Conference on Computational Natural Language
    Learning (CoNLL) 2000 chunking dataset |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
- en: '| **Question answering** |  |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
- en: '| `SQuAD1(`*`root=*.data*, split=`*`(`*`*train*, *dev*`*`))` | Creates the
    Stanford Question Answering Dataset (SQuAD) 1.0 dataset, a reading comprehension
    dataset consisting of questions posed by crowdworkers on a set of Wikipedia articles
    |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
- en: '| `SQuAD2(`*`root=.data, split=`*`(`*`train, dev`*`))` | Creates the Stanford
    Question Answering Dataset (SQuAD) 2.0 dataset, a dataset that extends the 1.0
    dataset by adding over 50,000 unanswerable questions |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
- en: Torchtext developers are always adding new datasets. For the most updated list,
    visit the [Torchtext datasets documentation](https://pytorch.tips/torchtext-datasets).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: Once you load data, whether from existing datasets or ones that you create,
    you will need to convert the text data to numeric data before training a model
    and running inference. To do so, we use vocabularies and word embeddings that
    provide the maps to perform these conversions. Next, we’ll examine the Torchtext
    functions used to support vocabularies.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: Vocabularies (torchtext.vocab)
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Torchtext provides generic classes and specific classes for popular vocabularies.
    [Table 8-19](#table_torchtext_vocab) provides a list of classes in `torchtext.vocab`
    to support the creation and use of vocabularies.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-19\. Torchtext vocabularies
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: '| Function | Description |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
- en: '| **Vocabulary classes** |  |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
- en: '| `Vocab(counter, max_size=None, min_freq=1,` `specials=(<unk>,` `<pad>),`
    *`vectors=None,`* *`unk_init=None,`* *`vectors_cache=None,`* *`specials_first=True`*`)`
    | Defines a vocabulary object that will be used to numericalize a field |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
- en: '| `SubwordVocab(`*`counter, max_size=None,`* *`specials=<pad>,`* *`vectors=None,`*
    *`unk_init=<method zero_of torch._C._TensorBase objects>`*`)` | Creates a `revtok`
    subword vocabulary from a `collections.Counter` |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
- en: '| `Vectors(`*`name, cache=None, url=None, unk_init=None,`* *`max_vectors=None`*`)`
    | Generic class for word vector embeddings |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
- en: '| **Pretrained word embeddings** |  |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
- en: '| `GloVe(`*`name=*840B*, dim=300, **kwargs`*`)` | Global vectors (GloVe) model
    for distributed word representation, developed at Stanford |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
- en: '| `FastText(`*`language=en, **kwargs`*`)` | Pretrained word embeddings for
    294 languages, created by Facebook’s AI Research lab |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
- en: '| `CharNGram(`*`**kwargs`*`)` | CharNGram embeddings, a simple approach for
    learning character-based compositional models to embed textual sequences |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
- en: '| **Miscellaneous** |  |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
- en: '| `build_vocab_from_​itera⁠⁠tor(​`*`iter⁠⁠ator, num_lines=None`*`)` | Builds
    a vocabulary by cycling through an iterator |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
- en: As you can see, Torchtext provides a robust set of functionality to support
    text-based modeling and NLP research. For more information, visit the [Torchtext
    documentation](https://pytorch.tips/torchtext).
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: Whether you’re developing deep learning models for NLP, computer vision, or
    another field, it’s helpful to be able to visualize models, data, and performance
    metrics as you go. In the next section, we’ll explore another powerful package
    for visualization called TensorBoard.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: TensorBoard for Visualization
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: TensorBoard is a visualization toolkit that’s included in PyTorch’s major competing
    deep learning framework, TensorFlow. Instead of developing its own visualization
    toolkit, PyTorch integrates with TensorBoard and leverages its visualization capabilities
    natively.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: With TensorBoard, you can visualize learning curves, scalar data, model architectures,
    weight distributions, and 3D data embeddings, as well as keep track of hyperparameter
    experiment results. This section will show you how to use TensorBoard with PyTorch
    and provide a reference to the TensorBoard API.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: The TensorBoard application is run on a local or remote server, and the display
    and user interface run in a browser. We can also run TensorBoard inside Jupyter
    Notebook or Google Colab.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: 'I’ll use Colab in this book to demonstrate the capabilities of TensorBoard,
    but the process is very similar for running it locally or remotely in the cloud.
    Colab comes with TensorBoard preinstalled, and you can run it directly in a cell
    using magic commands, as shown in the following code:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: First we load the `tensorboard` extension and then we run `tensorboard` and
    specify the log directory that holds the event files. Event files hold the data
    from PyTorch that will be displayed in the TensorBoard application.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: Since we haven’t created any event files yet, you will see an empty display,
    as shown in [Figure 8-1](#fig_0801).
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: '![“TensorBoard Application”](Images/ptpr_0801.png)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
- en: Figure 8-1\. TensorBoard application
  id: totrans-406
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: By clicking on the arrow next to INACTIVE in the upper-right menu, you will
    see the possible display tabs. One commonly used display tab is the SCALARS tab.
    This tab can display any scalar value over time. We often use the SCALARS display
    to view loss and accuracy training curves. Let’s see how you can save scalar values
    for TensorBoard in your PyTorch code.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-408
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The  PyTorch  integration  with  TensorBoard  was  originally  implemented  by
     an  open  source  project  called  TensorBoardX.  Since  then,  TensorBoard  support
     has  been  integrated into the PyTorch project as the `torch.utils.tensorboard`
     package  and  it’s  actively  maintained  by  the  PyTorch  development  team.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: 'First let’s import PyTorch’s TensorBoard interface and set up PyTorch for use
    with TensorBoard, as shown in the following code:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[![1](Images/1.png)](#co_the_pytorch_ecosystem_and_additional_resources_CO1-1)'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: The writer will output to the *./runs/* directory by default.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: 'We simply import the `SummaryWriter` class from the PyTorch `tensorboard` package
    and instantiate a `SummaryWriter` object. To write data to TensorBoard, all we
    need to do is call methods from the `SummaryWriter` object. To save our loss values
    while our model is training, we use the `add_scalar()` method, as shown in the
    following code:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](Images/1.png)](#co_the_pytorch_ecosystem_and_additional_resources_CO2-1)'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: Log `loss.item()` as an event to `tensorboard`.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: This is just an example training loop. You can assume the `model` has already
    been defined and the `trainloader` has been created. Not only does the code print
    the loss every epoch, but it also logs it to a `tensorboard` event. We can either
    refresh the TensorBoard application in the previous cell or create another cell
    altogether using the `%tensorboard` command.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: Learning Curves with SCALARS
  id: totrans-419
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: TensorBoard provides the ability to plot one or more scalar values over time.
    This is useful in deep learning development to display metrics as your model trains.
    By viewing metrics like loss or accuracy it’s easy to see if your model’s training
    is stable and continues to improve.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-2](#fig_0802) shows an example display of learning curves using TensorBoard.'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: You can interact with the display by sliding the smoothing factor, and you can
    also see the curve at each epoch by mousing over the plots. TensorBoard allows
    you to apply smoothing to iron out instabilities and show the overall progress.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '![“Visualizing Learning Curves with TensorBoard”](Images/ptpr_0802.png)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
- en: Figure 8-2\. TensorBoard learning curves
  id: totrans-424
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Model Architectures with GRAPHS
  id: totrans-425
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Another useful feature of TensorBoard is visualizing your deep learning model
    using graphs. To save a graph to the event file, we will use the `add_graph()`
    method, as shown in the following code:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this code we instantiate a VGG16 model and write the model to an event file.
    We can display the model graph by either refreshing an existing TensorBoard cell
    or creating a new one. [Figure 8-3](#fig_0803) shows the graph visualization tool
    in TensorBoard.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: '![“Visualizing Model Graphs with TensorBoard”](Images/ptpr_0803.png)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
- en: Figure 8-3\. TensorBoard model graph
  id: totrans-430
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The graph is interactive. You can click on each module and expand it to view
    the underlying modules. This tool is useful for understanding existing models
    and verifying that your model graphs match their intended designs.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: Data with IMAGES, TEXT, and PROJECTOR
  id: totrans-432
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also use TensorBoard to view different types of data, such as images,
    text, and 3D embeddings. In these cases, you would use the `add_image()`, `add_text()`,
    and `add_projection()` methods, respectively, to write data to the event file.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-4](#fig_0804) shows a batch of image data from the Fashion-MNIST
    dataset.'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: By examining batches of image data, you can verify that the data looks as expected
    or identify errors in your data or results. TensorBoard also provides the ability
    to listen to audio data, display text data, and view 3D projections of multidimensional
    data or data embeddings.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: '![“Visualizing Image Data with TensorBoard”](Images/ptpr_0804.png)'
  id: totrans-436
  prefs: []
  type: TYPE_IMG
- en: Figure 8-4\. TensorBoard image display
  id: totrans-437
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Weight Distributions with DISTRIBUTIONS and HISTOGRAMS
  id: totrans-438
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another useful feature of TensorBoard is the ability to display distributions
    and histograms. This allows you to view large amounts of data to verify expected
    behavior or identify issues.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: One common task in model development is making sure you avoid the *vanishing
    gradient problem*. Vanishing gradients occur when the model weights become zero
    or close to zero. When this occurs the neurons essentially die off and can no
    longer be updated.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: If we visualize the distribution of our weights, it’s easy to see when a large
    portion of the weight values have reached zero.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-5](#fig_0805) shows the DISTRIBUTIONS tab in TensorBoard. Here we
    can examine the distributions of our weight values.'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: As you see in [Figure 8-5](#fig_0805), TensorBoard can display distributions
    in 3D so it’s easy to see how the distributions change over time or over each
    epoch.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: '![“Weight Distributions with TensorBoard”](Images/ptpr_0805.png)'
  id: totrans-444
  prefs: []
  type: TYPE_IMG
- en: Figure 8-5\. TensorBoard weight distributions
  id: totrans-445
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Hyperparameters with HPARAMS
  id: totrans-446
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When running deep learning experiments, it’s easy to lose track of the different
    hyperparameter sets used to try a hypothesis. TensorBoard provides a way to keep
    track of the hyperparameter values during each experiment and tabularizes the
    values and their results.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-6](#fig_0806) displays an example of how we track experiments and
    their corresponding hyperparameters and results.'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: In the HPARAMS tab, you can view the results in table view, parallel coordinates
    view, or scatter plot matrix view. Each experiment is identified by its session
    group name, hyperparameters such as dropout percentage and optimizer algorithm,
    and the resulting metric, such as accuracy. The HPARAMS tables help you keep track
    of your experiments and results.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: 'When you’re finished writing data to TensorBoard event files, you should use
    the `close()` method, as shown here:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This will call the destructor function and release any memory that was used
    for the summary writer.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: '![“Tracking Hyperparameters in TensorBoard”](Images/ptpr_0806.png)'
  id: totrans-453
  prefs: []
  type: TYPE_IMG
- en: Figure 8-6\. TensorBoard hyperparameter tracking
  id: totrans-454
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The TensorBoard API
  id: totrans-455
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The PyTorch TensorBoard API is pretty simple. It’s included as part of the `torch.utils`
    package as `torch.utils.tensorboard`. [Table 8-20](#table_tensorboard_api) shows
    a comprehensive list of functions used to interface PyTorch to TensorBoard.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-20\. PyTorch TensorBoard API
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Description |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
- en: '| `SummaryWriter(`*`log_dir=None, comment='''', purge_step=None, max_queue=10,
    flush_secs=120, filename_suffix=''''`*`)` | Creates a `SummaryWriter` object |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
- en: '| `flush()` | Flushes the event file to disk; makes sure that all pending events
    have been written to disk |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
- en: '| `close()` | Frees the `SummaryWriter` object and closes event files |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
- en: '| `add_scalar(`*`tag, scalar_value, global_step=None, walltime=None`*`)` |
    Writes a scalar to the event file |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
- en: '| `add_scalars(`*`main_tag, tag_scalar_dict, global_step=None, walltime=None`*`)`
    | Writes multiple scalars to the event file to display multiple scalars on the
    same plot |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
- en: '| `add_custom_scalars(`*`layout`*`)` | Creates a special chart by collecting
    chart tags in scalars |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
- en: '| `add_histogram(`*`tag, values, global_step=None, bins=tensorflow, walltime=None,
    max_bins=None`*`)` | Writes data for a histogram display |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
- en: '| `add_image(`*`tag, img_tensor, global_step=None, walltime=None, dataformats=CHW`*`)`
    | Writes image data |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
- en: '| `add_images(`*`tag, img_tensor, global_step=None, walltime=None, dataformats=NCHW`*`)`
    | Writes multiple images to the same display |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
- en: '| `add_figure(`*`tag, figure, global_step=None, close=True, walltime=None`*`)`
    | Writes a `matplotlib`-type plot as an image |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
- en: '| `add_video(`*`tag, vid_tensor, global_step=None, fps=4, walltime=None``)`*
    | Writes a video |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
- en: '| `add_audio(`*`tag, snd_tensor, global_step=None, sample_rate=44100, walltime=None`*`)`
    | Writes an audio file to the event summary |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
- en: '| `add_text(`*`tag, text_string, global_step=None, walltime=None`*`)` | Writes
    text data to summary |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
- en: '| `add_graph(`*`model, input_to_model=None, verbose=False`*`)` | Writes a model
    graph or computational graph to summary |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
- en: '| `add_embedding(`*`mat, metadata=None, label_img=None, global_step=None, tag=default,
    metadata_header=None`*`)` | Writes embedding projector data tto summary |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
- en: '| `add_pr_curve(`*`tag, labels, predictions, global_step=None, num_thresholds=127,
    weights=None, walltime=None`*`)` | Writes the precision/recall curve under different
    thresholds |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
- en: '| `add_mesh(`*`tag, vertices, colors=None, faces=None, config_dict=None, global_step=None,
    walltime=None`*`)` | Adds meshes or 3D point clouds to TensorBoard |'
  id: totrans-476
  prefs: []
  type: TYPE_TB
- en: '| `add_hparams(`*`hparam_dict, metric_dict, hparam_domain_discrete=None, run_name=None`*`)`
    | Adds a set of hyperparameters for comparison in TensorBoard |'
  id: totrans-477
  prefs: []
  type: TYPE_TB
- en: As shown in [Table 8-20](#table_tensorboard_api), the API is simple. You can
    use the `SummaryWriter()`, `flush()`, and `close()` methods to manage the writer
    object and use the other functions to add data to the TensorBoard event file.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: For more details on the TensorBoard PyTorch API, visit the [TensorBoard API
    documentation](https://pytorch.tips/pytorch-tensorboard). For more details on
    using the TensorBoard application itself, visit the [TensorBoard documentation](https://pytorch.tips/tensorboard).
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: TensorBoard solves one major challenge with developing deep learning models
    in PyTorch by providing a visualization tool. Another major challenge is keeping
    up with the latest research and state-of-the art solutions. Researchers often
    need to reproduce the results and leverage the code for benchmarking their own
    designs. In the next section we explore Papers with Code, a resource you can use
    to solve this problem.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: Papers with Code
  id: totrans-481
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Papers with Code (PwC) is a website that organizes access to machine learning
    research papers and their corresponding code, which is often written in PyTorch.
    PwC allows you to easily reproduce experiments and extend current research, and
    the website allows you to find the best-performing research papers for a given
    machine learning topic. For example, want to find the best image classification
    models and their code? Just click on the Image Classification tile and you’ll
    see a summary of the research area as well as benchmarks and links to corresponding
    papers and code on GitHub. [Figure 8-7](#fig_0807) shows an example listing for
    Image Classification.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: '![“Papers With Code Image Classification Listing”](Images/ptpr_0807.png)'
  id: totrans-483
  prefs: []
  type: TYPE_IMG
- en: Figure 8-7\. Papers with Code
  id: totrans-484
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: PwC is not an exclusive PyTorch project; however, most of the code provided
    on PwC uses PyTorch. It may be able to help you build awareness of the current
    state-of-the-art research and solve your problems in deep learning and AI. Explore
    more at the [PwC website](https://pytorch.tips/pwc).
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: Additional PyTorch Resources
  id: totrans-486
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After reading this book, you should have a good understanding of PyTorch and
    its features. However, there are always new aspects to explore and practice. In
    this section, I’ll provide a list of additional resources that you can check out
    to learn more and grow your skills with PyTorch.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: Tutorials
  id: totrans-488
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The [PyTorch website](https://pytorch.tips/pytorch) provides an extensive set
    of documentation and tutorials. If you’re looking for more code examples, this
    resource is a good place to start. [Figure 8-8](#fig_0808) shows the [PyTorch
    Tutorials website](https://pytorch.tips/tutorials), where you can select tags
    to help you find tutorials that interest you.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: '![“PyTorch Tutorials Website”](Images/ptpr_0808.png)'
  id: totrans-490
  prefs: []
  type: TYPE_IMG
- en: Figure 8-8\. PyTorch Tutorials
  id: totrans-491
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The site includes a 60-min blitz, PyTorch recipes, tutorials, and a PyTorch
    Cheat Sheet. Most of the code and tutorials are available on GitHub, and can be
    run in VS Code, Jupyter Notebook, and Colab.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: The 60-min Blitz is a good place to start, refresh your skills, or review the
    basics of PyTorch. PyTorch recipes are bite-sized, actionable examples of how
    to use specific PyTorch features. PyTorch tutorials are slightly longer than recipes
    and are composed of multiple steps to achieve or demonstrate an outcome.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: 'Currently, you can find tutorials related to the following topics:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: Audio
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best Practice
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: C++
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CUDA
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extending PyTorch
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FX
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Frontend APIs
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting Started
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image/Video
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpretability
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory Format
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mobile
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model Optimization
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel and Distributed Training
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Production
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Profiling
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantization
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinforcement Learning
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorBoard
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TorchScript
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The PyTorch team is continually adding new resources and this list is certainly
    subject to change. For more information and the latest tutorials, visit the PyTorch
    Tutorials website.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: Books
  id: totrans-517
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tutorials are a great for learning, but perhaps you’d prefer to read more about
    PyTorch and gain different perspectives from multiple authors. [Table 8-21](#table_pytorch_books)
    provides a list of other books related to PyTorch.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-21\. PyTorch books
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: '| Book | Publisher, year | Summary |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
- en: '| *Cloud Native Machine Learning* by Carl Osipov | Manning, 2021 | Learn how
    to deploy PyTorch models on AWS |'
  id: totrans-522
  prefs: []
  type: TYPE_TB
- en: '| *Deep Learning for Coders with fastai and PyTorch* by Jeremy Howard and Sylvain
    Gugger | O’Reilly, 2020 | Learn how to build AI applications without a PhD |'
  id: totrans-523
  prefs: []
  type: TYPE_TB
- en: '| *Deep Learning with PyTorch* by Eli Stevens et al. | Manning, 2019 | Learn
    how to build, train, and tune NNs using Python tools |'
  id: totrans-524
  prefs: []
  type: TYPE_TB
- en: '| *Deep Learning with PyTorch* by Vishnu Subramanian | Packt, 2018 | Learn
    how to build NN models using PyTorch |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
- en: '| *Hands-On Generative Adversarial Networks with PyTorch 1.x* by John Hany
    and Greg Walters | Packt, 2019 | Learn how to implement next-generation NNs to
    build powerful GAN models using Python |'
  id: totrans-526
  prefs: []
  type: TYPE_TB
- en: '| *Hands-On Natural Language Processing with PyTorch 1.x* by Thomas Dop | Packt,
    2020 | Learn how to build smart, AI-driven linguistic applications using deep
    learning and NLP techniques |'
  id: totrans-527
  prefs: []
  type: TYPE_TB
- en: '| *Hands-On Neural Networks with PyTorch 1.0* by Vihar Kurama | Packt, 2019
    | Learn how to implement deep learning architectures in PyTorch |'
  id: totrans-528
  prefs: []
  type: TYPE_TB
- en: '| *Natural Language Processing with PyTorch* by Delip Rao and Brian McMahan
    | O’Reilly, 2019 | Learn how to build intelligent language applications using
    deep learning |'
  id: totrans-529
  prefs: []
  type: TYPE_TB
- en: '| *Practical Deep Learning with PyTorch* by Nihkil Ketkar | Apress, 2020 |
    Learn how to optimize GANs with Python |'
  id: totrans-530
  prefs: []
  type: TYPE_TB
- en: '| *Programming PyTorch for Deep Learning* by Ian Pointer | O’Reilly, 2019 |
    Learn how to create and deploy deep learning applications |'
  id: totrans-531
  prefs: []
  type: TYPE_TB
- en: '| *PyTorch Artificial Intelligence Fundamentals* by Jibin Mathew | Packt, 2020
    | Learn how to design, build, and deploy your own AI models with PyTorch 1.x |'
  id: totrans-532
  prefs: []
  type: TYPE_TB
- en: '| *PyTorch Recipes* by Pradeepta Mishra | Apress, 2019 | Learn how to solve
    problems in PyTorch |'
  id: totrans-533
  prefs: []
  type: TYPE_TB
- en: Online Courses and Live Training
  id: totrans-534
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you prefer online video courses and live training workshops, there are options
    available for you to expand your PyTorch knowledge and skills. You can continue
    learning from me and other online instructors at PyTorch Academy, Udemy, Coursera,
    Udacity, Skillshare, DataCamp, Pluralsight, edX, O’Reilly Learning, and LinkedIn
    Learning. Some courses are free while others require a fee or a subscription.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 8-22](#table_pytorch_courses) lists a selection of online courses on
    PyTorch available at the time of writing.'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-22\. PyTorch courses
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
- en: '| Course | Instructor | Platform |'
  id: totrans-538
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-539
  prefs: []
  type: TYPE_TB
- en: '| Getting Started with PyTorch Development | Joe Papa | [PyTorch Academy](https://pytorchacademy.com)
    |'
  id: totrans-540
  prefs: []
  type: TYPE_TB
- en: '| PyTorch Fundamentals | Joe Papa | [PyTorch Academy](https://pytorchacademy.com)
    |'
  id: totrans-541
  prefs: []
  type: TYPE_TB
- en: '| Advanced PyTorch | Joe Papa | [PyTorch Academy](https://pytorchacademy.com)
    |'
  id: totrans-542
  prefs: []
  type: TYPE_TB
- en: '| Introduction to Deep Learning with PyTorch | Ismail Elezi | [DataCamp](https://www.datacamp.com/courses/deep-learning-with-pytorch)
    |'
  id: totrans-543
  prefs: []
  type: TYPE_TB
- en: '| Foundations of PyTorch | Janani Ravi | [Pluralsight](https://www.pluralsight.com/courses/foundations-pytorch)
    |'
  id: totrans-544
  prefs: []
  type: TYPE_TB
- en: '| Deep Neural Networks with PyTorch | IBM | [Coursera](https://www.coursera.org/learn/deep-neural-networks-with-pytorch)
    |'
  id: totrans-545
  prefs: []
  type: TYPE_TB
- en: '| PyTorch Basics for Machine Learning | IBM | [edX](https://www.edx.org/course/pytorch-basics-for-machine-learning)
    |'
  id: totrans-546
  prefs: []
  type: TYPE_TB
- en: '| Intro to Deep Learning with PyTorch | Facebook AI | [Udacity](https://www.udacity.com/course/deep-learning-pytorch%E2%80%94ud188)
    |'
  id: totrans-547
  prefs: []
  type: TYPE_TB
- en: '| PyTorch: Deep Learning and Artificial Intelligence | Lazy Programmer | [Udemy](https://www.udemy.com/course/pytorch-deep-learning/)
    |'
  id: totrans-548
  prefs: []
  type: TYPE_TB
- en: '| PyTorch for Deep Learning and Computer Vision | Rayan Slim et al. | [Udemy](https://www.udemy.com/course/pytorch-for-deep-learning-and-computer-vision)
    |'
  id: totrans-549
  prefs: []
  type: TYPE_TB
- en: '| PyTorch for Beginners | Dan We | [Skillshare](https://www.skillshare.com/classes/Pytorch-for-beginners-how-machine-learning-with-pytorch-really-works/1042152565)
    |'
  id: totrans-550
  prefs: []
  type: TYPE_TB
- en: '| PyTorch Essential Training: Deep Learning | Jonathan Fernandes | [LinkedIn
    Learning](https://www.linkedin.com/learning/pytorch-essential-training-deep-learning)
    |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
- en: '| Introduction to Deep Learning Using PyTorch | Goku Mohandas and Alfredo Canziani
    | [O’Reilly Learning](https://learning.oreilly.com/videos/introduction-to-deep/9781491989944/)
    |'
  id: totrans-552
  prefs: []
  type: TYPE_TB
- en: This chapter has provided resources for expanding your learning, research, and
    development with PyTorch. You can use this material as a quick reference for the
    numerous packages within the PyTorch project and the PyTorch Ecosystem. When you
    are looking to expand your skills and knowledge, you can return to this chapter
    to get ideas on other training materials available to you.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations on completing the book! You’ve come a long way, getting to grips
    with tensors, understanding the model development process, and exploring reference
    designs using PyTorch. In addition, you’ve learned how to customize PyTorch, create
    your own features, accelerate training, optimize your models, and deploy your
    NNs to the cloud and edge devices. Finally, we explored the PyTorch Ecosystem,
    investigated key packages like Torchvision, Torchtext, and TensorBoard, and learned
    about additional ways to expand your knowledge with tutorials, books, and online
    courses.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
- en: No matter what projects you tackle in the future, I hope you’ll be able to return
    to this book again and again. I also hope you continue to expand your skills and
    master PyTorch’s capabilities to develop innovative new deep learning tools and
    systems. Don’t let your new knowledge and skills dwindle away. Go build something
    interesting, and make a difference in the world!
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
- en: Let me know what you create! I hope to see you in one of my courses at [PyTorch
    Academy](https://pytorchacademy.com) and feel free to reach out to me via email
    ([jpapa@joepapa.ai](mailto:jpapa@joepapa.ai)), Twitter (@JoePapaAI), or LinkedIn
    (@MrJoePapa).
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
