- en: 9 Personalized search
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 个性化搜索
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The personalization spectrum between search and recommendations
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索与推荐之间的个性化范围
- en: Implementing collaborative filtering and personalization using latent features
    from users’ signals
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用用户信号的潜在特征实现协同过滤和个性化
- en: Using embeddings to create personalization profiles
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用嵌入创建个性化配置文件
- en: Multimodal personalization from content and behavior
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从内容和行为的多模态个性化
- en: Applying clustering-based personalization guardrails
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用基于聚类的个性化限制
- en: Avoiding the pitfalls of personalized search
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免个性化搜索的陷阱
- en: 'The better your search engine understands your users, the more likely it will
    be able to successfully interpret their queries. In chapter 1, we introduced the
    three key contexts needed to properly interpret query intent: content understanding,
    domain understanding, and user understanding. In this chapter, we’ll dive into
    the user understanding context.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎越了解您的用户，就越有可能成功解释他们的查询。在第1章中，我们介绍了正确解释查询意图所需的三个关键上下文：内容理解、领域理解和用户理解。在本章中，我们将深入探讨用户理解上下文。
- en: We’ve already focused on learning domain-specific context from documents (chapter
    5) and on the most popular results according to many different users (chapter
    8), but it’s not always reasonable to assume that the “best” result is agreed
    upon across all users. Whereas signals-boosting models find the most *popular*
    answers across all users, personalized search instead attempts to learn about
    each *specific* user’s interests and to return search results catering to those
    interests.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经关注了从文档中学习特定领域上下文（第5章）以及根据许多不同用户的流行结果（第8章），但并不总是合理地假设“最佳”结果在所有用户中都是一致的。而信号增强模型在所有用户中找到最*流行*的答案，而个性化搜索则试图了解每个*特定*用户的兴趣，并返回满足这些兴趣的搜索结果。
- en: For example, when searching for restaurants, a user’s location clearly matters.
    When searching for a job, each user’s employment history (previous job titles,
    experience level, salary range) and location may matter. When searching for products,
    particular brand affinities, colors of appliances, complementary items purchased,
    and similar personal tastes may matter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当搜索餐厅时，用户的位置显然很重要。当搜索工作时，每个用户的就业历史（以前的职位，经验水平，薪资范围）和位置可能很重要。当搜索产品时，特定的品牌偏好，家电颜色，互补商品购买以及类似个人品味可能很重要。
- en: In this chapter, we’ll use user signals to learn latent features describing
    users’ interests. *Latent features* are features hidden within data, but which
    can be inferred about users or items by modeling the data. These latent features
    will be used to generate product recommendations and boosts to personalized search
    results. We’ll also use content-based embeddings to relate products and we’ll
    use embeddings of the products each user interacts with to generate vector-based
    personalization profiles to personalize search results.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用用户信号来学习描述用户兴趣的潜在特征。*潜在特征*是隐藏在数据中的特征，但可以通过对数据进行建模来推断关于用户或物品的信息。这些潜在特征将被用于生成产品推荐和提升个性化搜索结果。我们还将使用基于内容的嵌入来关联产品，并使用每个用户交互的产品的嵌入来生成基于向量的个性化配置文件，以个性化搜索结果。
- en: Finally, we’ll cluster products by their embeddings to generate personalization
    guardrails to ensure that users don’t see personalized search results based on
    products from unrelated categories.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将根据其嵌入对产品进行聚类，以生成个性化限制，确保用户不会看到基于无关类别产品的个性化搜索结果。
- en: Personalization should be applied to search results very carefully. It’s easy
    to frustrate users by overriding their explicit intent (usually specified as search
    keywords) with assumptions based on their previous search activity. We’ll dive
    into the nuances of balancing the benefits of better-personalized search against
    potential user frustration caused by an engine trying too hard to read their minds.
    Not all searches should be personalized, but when it’s done well, you’ll see how
    it can greatly improve the search experience.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 应非常谨慎地将个性化应用于搜索结果。通过基于他们之前的搜索活动所做的假设来覆盖他们的明确意图（通常指定为搜索关键词），很容易让用户感到沮丧。我们将深入探讨在更好地个性化搜索的好处与由引擎过度努力读取用户想法而可能引起的用户挫败感之间取得平衡的细微差别。并非所有搜索都应该个性化，但做得好的时候，您会看到它如何极大地改善搜索体验。
- en: 9.1 Personalized search vs. recommendations
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 个性化搜索与推荐
- en: Search engines and recommendation engines represent two ends of a personalization
    spectrum, which we introduced in chapter 1 (see figure 1.5). We also discussed
    the dimensions of user intent in chapter 1 (see figure 1.7), noting that fully
    understanding user intent requires content understanding, user understanding,
    and domain understanding. Figure 9.1 resurfaces these two mental models.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎和推荐引擎代表了个人化范围的两端，我们在第一章中介绍了这一概念（见图1.5）。我们也在第一章中讨论了用户意图的维度（见图1.7），指出要完全理解用户意图需要内容理解、用户理解和领域理解。图9.1重新提出了这两个心智模型。
- en: While keyword search represents only content understanding, and collaborative
    recommendations represent only user understanding, they both can and should be
    combined when possible. *Personalized search* lies at the intersection between
    keyword search and collaborative recommendations.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然关键词搜索只代表内容理解，协同推荐只代表用户理解，但在可能的情况下，它们都可以也应该被结合。*个性化搜索*位于关键词搜索和协同推荐之间的交叉点。
- en: '![figure](../Images/CH09_F01_Grainger.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F01_Grainger.png)'
- en: Figure 9.1 The personalization spectrum and the dimensions of user intent
  id: totrans-18
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.1 个人化范围和用户意图的维度
- en: Figure 9.2 superimposes the personalization spectrum on top of the diagram of
    the dimensions of user intent to paint a more nuanced picture of how personalized
    search fits along the personalization spectrum.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 将个人化范围叠加在用户意图维度的图上，以描绘出个性化搜索如何在个人化范围内更细腻的图景。
- en: '![figure](../Images/CH09_F02_Grainger.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F02_Grainger.png)'
- en: Figure 9.2 Personalized search lies at the intersection between keyword search
    and collaborative recommendations
  id: totrans-21
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.2 个性化搜索位于关键词搜索和协同推荐之间的交叉点
- en: The key differentiating factor between search engines and recommendation engines
    is that search engines are typically guided by users and match their explicitly
    entered queries, whereas recommendation engines typically accept no direct user
    input and instead recommend content based on already known or inferred knowledge.
    The reality, however, is that these two kinds of systems form two sides of the
    same coin. The goal in both cases is to understand what a user is looking for
    and deliver relevant results to meet that user’s information need. In this section,
    we’ll discuss the broad spectrum of capabilities that lie within the personalization
    spectrum between search and recommendation systems.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎和推荐引擎之间的关键区别在于，搜索引擎通常由用户引导并匹配他们明确输入的查询，而推荐引擎通常不接受直接的用户输入，而是根据已知或推断的知识推荐内容。然而，现实情况是这两种系统构成了同一枚硬币的两面。在两种情况下，目标都是理解用户在寻找什么，并交付相关结果以满足用户的信息需求。在本节中，我们将讨论搜索和推荐系统之间个人化范围内广泛的能力范围。
- en: 9.1.1 Personalized queries
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 个性化查询
- en: Let’s imagine we’re running a restaurant search engine. Our user, Michelle,
    is on her phone in New York at lunchtime, and she types in a keyword search for
    `steamed bagels`. She sees top-rated steamed bagel shops in Greenville, South
    Carolina (USA); Columbus, Ohio (USA); and London (UK).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象我们正在运行一个餐厅搜索引擎。我们的用户，米歇尔，在纽约午餐时间用手机进行关键词搜索，她输入了“蒸面包圈”这个关键词。她看到了位于美国南卡罗来纳州格林维尔、俄亥俄州哥伦布和英国伦敦的顶级蒸面包圈店。
- en: What’s wrong with these search results? Well, in this case, the answer is clear—Michelle
    is looking for lunch in New York, but the search engine is showing her results
    hundreds to thousands of kilometers away. But Michelle never *told* the search
    engine she only wanted to see results in New York, nor did she tell the search
    engine that she was looking for a lunch place close by because she wants to eat
    now. Nevertheless, the search engine should be able to infer this information
    and personalize the search results accordingly.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些搜索结果有什么问题？嗯，在这种情况下，答案很明确——米歇尔正在纽约寻找午餐，但搜索引擎却显示了她数百到数千公里之外的结果。但米歇尔从未*告诉*搜索引擎她只想看到纽约的结果，也没有告诉搜索引擎她正在寻找附近的午餐地点，因为她想吃现在。尽管如此，搜索引擎应该能够推断出这些信息并根据这些信息个性化搜索结果。
- en: Consider another scenario—Michelle is at the airport after a long flight, and
    she searches on her phone for `driver`. The top results that come back are for
    a golf club for hitting the ball off a tee, followed by a link to printer drivers,
    followed by a screwdriver. If the search engine knows Michelle’s location, shouldn’t
    it be able to infer her intended meaning—that she is searching for a ride?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑另一种场景——米歇尔在长途飞行后到达机场，并在手机上搜索`司机`。返回的顶部结果是高尔夫球场的击球杆，接着是打印机驱动程序的链接，然后是螺丝刀。如果搜索引擎知道米歇尔的位置，它是否应该能够推断出她的意图——她在寻找一辆车？
- en: Using our job search example from earlier, let’s assume Michelle goes to her
    favorite job search engine and types in `nursing jobs`. Like our restaurant example
    earlier, wouldn’t it be ideal if nursing jobs in New York showed up at the top
    of the list? What if she later types `jobs in Seattle`? Wouldn’t it be ideal if—instead
    of seeing random jobs in Seattle (doctor, engineer, chef, etc.)—nursing jobs now
    showed up at the top of the list, since the engine previously learned that she
    is a nurse?
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以我们之前提到的职位搜索为例，假设米歇尔访问她最喜欢的职位搜索引擎并输入了`护士职位`。就像我们之前的餐厅例子一样，如果纽约的护士职位能出现在列表的顶部，那岂不是理想的情况？如果她后来输入了`西雅图的工作`，那岂不是理想的情况——不是看到随机的西雅图工作（医生、工程师、厨师等），而是由于引擎之前了解到她是一名护士，护士职位现在出现在列表的顶部？
- en: 'Each of these is an example of a personalized query: the combining of both
    an explicit user query *and* an implicit understanding of the user’s intent and
    preferences into a search that serves results specifically catering to that user.
    Doing this kind of personalized search well is tricky, as you must carefully balance
    your understanding of the user without overriding anything they explicitly want
    to query. When it’s done well, though, personalized queries can significantly
    improve search relevance.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是个性化查询的例子：将用户的明确查询与对用户意图和偏好的隐含理解结合起来，形成一个专门针对该用户的搜索结果。做好这种个性化搜索是棘手的，因为你必须仔细平衡对用户的理解，同时不覆盖他们明确想要查询的内容。然而，当做得好的时候，个性化查询可以显著提高搜索的相关性。
- en: 9.1.2 User-guided recommendations
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 用户引导推荐
- en: Just as it’s possible to sprinkle an implicit understanding of user-specific
    attributes into an explicit keyword search to generate personalized search results,
    it’s also possible to enable user-guided recommendations by allowing user-overrides
    of the inputs into automatically generated recommendations.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如可以在显式关键词搜索中添加对用户特定属性的隐含理解来生成个性化搜索结果一样，也可以通过允许用户覆盖自动生成的推荐输入来启用用户引导的推荐。
- en: 'It is becoming increasingly common for recommendation engines to allow users
    to see and edit their recommendation preferences. These preferences usually include
    a list of items the user interacted with before by viewing, clicking, or purchasing
    them. Across a wide array of use cases, these preferences could include both specific
    item preferences, like favorite movies, restaurants, or places, as well as aggregated
    or inferred preferences, like clothing sizes, brand affinities, favorite colors,
    preferred local stores, desired job titles and skills, preferred salary ranges,
    and so on. These preferences make up a user profile: they define what is known
    about a customer, and the more control you can give a user to see, adjust, and
    improve this profile, the better you’ll be able to understand your users and the
    happier they’ll likely be with the results.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐引擎允许用户查看和编辑他们的推荐偏好变得越来越普遍。这些偏好通常包括用户之前通过查看、点击或购买而与之互动的项目列表。在广泛的应用场景中，这些偏好可能包括特定项目偏好，如喜欢的电影、餐厅或地点，以及汇总或推断出的偏好，如服装尺码、品牌偏好、喜欢的颜色、偏好的本地商店、期望的职位和技能、偏好的薪资范围等等。这些偏好构成了用户档案：它们定义了关于客户所知的内容，而你能够给予用户更多查看、调整和改进此档案的控制权，你就越能更好地理解你的用户，他们可能也会对结果更加满意。
- en: 9.2 Recommendation algorithm approaches
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 推荐算法方法
- en: In this section, we’ll discuss the different types of recommendation algorithms.
    Recommendation engine implementations come in different flavors depending on what
    data is available to drive their recommendations. Some systems only have user
    behavioral signals and very little content or information about the items being
    recommended, whereas other systems have rich content about items, but very few
    user interactions with the items. We’ll cover content-based, behavior-based, and
    multimodal recommenders.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论不同类型的推荐算法。推荐引擎的实现取决于可用于驱动其推荐的数据。一些系统只有用户行为信号，以及非常少的关于被推荐项目的内 容或信息，而其他系统则有关于项目的丰富内容，但与项目的用户交互非常少。我们将介绍基于内容、基于行为和多模态推荐器。
- en: 9.2.1 Content-based recommenders
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 基于内容的推荐器
- en: Content-based recommendation algorithms recommend new content based on attributes
    shared between different entities (often between users and items, between items
    and items, or between users and users). For example, imagine a job search website.
    Jobs may have properties on them like “job title”, “industry”, “salary range”,
    “years of experience”, and “skills”. Users will have similar attributes on their
    profile or resume/CV. Based upon these properties, a content-based recommendation
    algorithm can figure out which of these features are most important and can then
    rank the best matching jobs for any given user based on the user’s desired attributes.
    This is what’s known as a user-item (or user-to-item) recommender.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内容的推荐算法根据不同实体（通常在用户和项目之间、项目与项目之间或用户与用户之间）共享的属性来推荐新内容。例如，想象一个求职网站。工作可能具有诸如“职位名称”、“行业”、“薪资范围”、“工作经验年限”和“技能”等属性。用户在其个人资料或简历/简历中将有类似的属性。基于这些属性，基于内容的推荐算法可以确定哪些特征最重要，然后根据用户的期望属性为任何给定用户排名最佳匹配的工作。这被称为用户-项目（或用户到项目）推荐器。
- en: Similarly, if a user likes a particular job, it is possible to use this same
    process to recommend similar jobs based on how well those jobs match the attributes
    of the first job. This type of recommendation is popular on product details pages,
    where a user is already looking at an item and it may be desirable to help them
    explore related items. This kind of recommendation algorithm is known as an item-item
    (or item-to-item) recommender.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，如果一个用户喜欢某个特定的工作，可以使用这个相同的过程根据这些工作与第一个工作的属性匹配程度来推荐类似的工作。这种推荐在产品详情页上很受欢迎，因为用户已经在查看一个项目，可能希望帮助他们探索相关项目。这种推荐算法被称为项目-项目（或项目到项目）推荐器。
- en: Figure 9.3 demonstrates how a content-based recommender might use attributes
    about items with which a user has previously interacted to match similar items
    for that user. In this case, our user viewed the “detergent” product and was then
    recommended “fabric softener” and “dryer sheets” based upon these items matching
    within the same category field (the “laundry” category) and containing similar
    text to the “detergent” product within their product descriptions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3演示了基于内容的推荐器如何使用用户先前交互的项目属性来匹配对该用户相似的项目。在这种情况下，我们的用户查看了“洗涤剂”产品，然后根据这些项目在相同类别字段（“洗衣”类别）中的匹配以及在其产品描述中包含与“洗涤剂”产品相似的文本，推荐了“织物柔软剂”和“烘干剂”。
- en: We demonstrated this kind of related attribute and category matching in chapter
    5 when covering knowledge graph learning and in chapter 6 when covering query
    expansion using knowledge graphs. In those cases, we were mostly expanding the
    keyword query to include additional related terms, but you could match items based
    on any other attributes, like brand, color, or size.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在第5章介绍知识图谱学习时以及在第6章介绍使用知识图谱的查询扩展时，我们展示了这种相关属性和类别匹配的类型。在那两种情况下，我们主要是扩展关键字查询以包含额外的相关术语，但你可以根据任何其他属性进行项目匹配，如品牌、颜色或尺寸。
- en: '![figure](../Images/CH09_F03_Grainger.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F03_Grainger.png)'
- en: Figure 9.3 Content-based recommendations based upon matching attributes of an
    item of interest to a user, such as categories and text keywords
  id: totrans-40
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.3 基于用户感兴趣的项目属性（如类别和文本关键词）的基于内容的推荐
- en: It’s also possible to match users to other users, or any entity to any other
    entity. In the context of content-based recommenders, all recommendations can
    be seen as item-item recommendations, where each item is an arbitrary entity that
    shares attributes with the other entities being recommended.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以将用户匹配到其他用户，或将任何实体匹配到任何其他实体。在基于内容推荐的上下文中，所有推荐都可以看作是项目-项目推荐，其中每个项目是一个与其他被推荐实体共享属性的任意实体。
- en: 9.2.2 Behavior-based recommenders
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 基于行为的推荐器
- en: Behavior-based recommenders use user interactions with items (documents) to
    discover similar patterns of interest among groups of items. This process is called
    *collaborative filtering*, referring to the use of a multiple-person (collaborative)
    voting process to filter matches to those demonstrating the highest similarity,
    as measured by how many overlapping users interacted with the same items. The
    idea here is that similar users (i.e., those with similar preferences) tend to
    interact with the same items, and when users interact with multiple items, they
    are more likely to be interacting with similar items as opposed to unrelated items.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 基于行为的推荐器利用用户与物品（文档）的交互来发现物品组中相似的兴趣模式。这个过程被称为 *协同过滤*，指的是使用多人（协同）投票过程来过滤匹配项，这些匹配项通过有多少重叠用户与相同物品的交互来衡量相似度。这里的想法是，相似的用户（即具有相似偏好的用户）倾向于与相同的物品进行交互，当用户与多个物品交互时，他们更有可能与相似物品而不是无关物品进行交互。
- en: One amazing characteristic of collaborative filtering algorithms is that they
    fully crowdsource the relevance scoring process from your end users. In fact,
    features of the items themselves (name, brand, color, text, and so on) are not
    needed—all that is required is a unique ID for each item and knowledge of which
    users interacted with which items. Further, the more user-interaction signals
    you have, the smarter these algorithms tend to get, because more people are continually
    voting and informing your ranking algorithm. This often leads to collaborative
    filtering algorithms significantly outperforming content-based algorithms.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤算法的一个令人惊讶的特性是，它们完全从您的最终用户那里众包了相关性评分过程。事实上，不需要物品本身的特征（名称、品牌、颜色、文本等）——所需的是每个物品的唯一ID以及知道哪些用户与哪些物品进行了交互。此外，您拥有的用户交互信号越多，这些算法通常越智能，因为更多的人在不断地投票并告知您的排名算法。这通常导致协同过滤算法在性能上显著优于基于内容的算法。
- en: Figure 9.4 demonstrates how overlapping behavioral signals from multiple users
    can be used to drive collaborative recommendations. In this figure, a new user
    is expressing interest in fertilizer, and because other users who have previously
    expressed interest in fertilizer tended to also click on, add-to-cart, or purchase
    soil and mulch, then soil or mulch will be returned as recommendations. Another
    behavior-based cluster of items including a screwdriver, hammer, and nails is
    also depicted, but they don’t sufficiently overlap with the user’s current interest
    (fertilizer), so they are not returned as recommendations.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4展示了如何使用来自多个用户的重叠行为信号来驱动协同推荐。在这个图中，一位新用户表示对肥料感兴趣，因为之前表示对肥料感兴趣的其他用户倾向于也点击、加入购物车或购买土壤和覆盖物，因此土壤或覆盖物将被作为推荐返回。另一个包括螺丝刀、锤子和钉子的基于行为的项目簇也被描绘出来，但它们与用户当前的兴趣（肥料）没有足够重叠，因此它们不会被作为推荐返回。
- en: '![figure](../Images/CH09_F04_Grainger.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F04_Grainger.png)'
- en: Figure 9.4 Recommendations based on collaborative filtering, a technique using
    the overlap between behavioral signals across multiple users
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.4 基于协同过滤的推荐，这是一种使用多个用户之间行为信号重叠的技术
- en: We’ll implement an end-to-end collaborative filtering example in section 9.3,
    covering the process of discovering latent user and item features from user behavioral
    signals and using those to generate item recommendations for users. Because collaborative
    filtering is completely crowdsourced, it is immune to data quality problems with
    your documents or associated content attributes that may be missing or incorrect.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第9.3节中实现一个端到端的协同过滤示例，涵盖从用户行为信号中发现潜在用户和物品特征的过程，并使用这些特征为用户生成物品推荐。由于协同过滤是完全众包的，因此它对您的文档或相关内容属性可能缺失或不正确的数据质量问题具有免疫力。
- en: Unfortunately, the same dependence upon user behavioral signals that makes collaborative
    filtering so powerful also turns out to be its weakness. What happens when there
    are only a few interactions with a particular item—or possibly none at all? The
    answer is that the item either never gets recommended (when there are no signals),
    or it will be likely to generate poor recommendations or show up as a bad match
    for other items (when there are few signals). This situation is known as the *cold-start
    problem*, and it’s a major challenge for behavior-based recommenders. To solve
    this problem, you typically need to combine behavior-based recommenders with content-based
    recommenders, as we’ll discuss next.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，正是这种对用户行为信号的依赖使得协同过滤如此强大，同时也暴露了其弱点。当只有少量与特定项目的互动，或者完全没有互动时会发生什么？答案是，该项目要么永远不会被推荐（当没有信号时），要么很可能会产生糟糕的推荐或显示为与其他项目的糟糕匹配（当信号很少时）。这种情况被称为*冷启动问题*，这是基于行为推荐者面临的主要挑战。为了解决这个问题，你通常需要将基于行为的推荐者与基于内容的推荐者结合起来，正如我们接下来将要讨论的。
- en: 9.2.3 Multimodal recommenders
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 多模态推荐者
- en: '*Multimodal recommenders* (also sometimes called *hybrid recommenders*) combine
    both content-based and behavior-based recommender approaches. Since collaborative
    filtering tends to work best for items with many signals, but works poorly when
    few or no signals are present, it is often most effective to use content-based
    features as a baseline and then layer a collaborative filtering model on top.
    This way, if few signals are present, the content-based matcher will still return
    results, whereas if there are many signals, the collaborative filtering algorithm
    will take greater prominence when ranking results. Incorporating both approaches
    can give you the best of both worlds: high-quality crowdsourced matching, while
    avoiding the cold-start problem for newer and less-well-discovered content. Figure
    9.5 demonstrates how this can work in practice.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*多模态推荐者*（有时也称为*混合推荐者*）结合了基于内容和基于行为推荐方法。由于协同过滤通常适用于具有许多信号的物品，但在信号很少或没有信号的情况下表现不佳，因此通常最有效的方法是将基于内容的特征作为基线，然后在上面叠加协同过滤模型。这样，如果信号很少，基于内容的匹配器仍然会返回结果；如果信号很多，协同过滤算法在排名结果时将更加突出。结合两种方法可以让你兼得两者之长：高质量的众包匹配，同时避免新内容和不太为人所知的内容的冷启动问题。图9.5展示了这在实践中是如何工作的。'
- en: '![figure](../Images/CH09_F05_Grainger.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F05_Grainger.png)'
- en: Figure 9.5 Multimodal recommendations combine both content-based matching and
    collaborative filtering into a hybrid matching algorithm.
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.5 多模态推荐将基于内容的匹配和协同过滤结合到一个混合匹配算法中。
- en: You can see in figure 9.5 that the user could interact with either the drill
    (which has no signals) or the screwdriver (which has previous signals from other
    users, as well as content), and the user would receive recommendations in both
    cases. This provides the benefit that signals-based collaborative filtering can
    be used, while also enabling content-based matching for items with insufficient
    signals.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图9.5中看到，用户可以与钻头（没有信号）或螺丝刀（有来自其他用户的先前信号，以及内容）进行互动，并且在这两种情况下用户都会收到推荐。这提供了基于信号的协同过滤可以使用的优势，同时也允许对信号不足的物品进行基于内容的匹配。
- en: We’ll implement a collaborative filtering model in the next section, followed
    by a hybrid personalized search system in section 9.4\.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将实现一个协同过滤模型，然后在9.4节中实现一个混合个性化搜索系统。
- en: 9.3 Implementing collaborative filtering
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 实现协同过滤
- en: In this section, we’ll implement a collaborative filtering algorithm. We’ll
    use user-item interaction signals and demonstrate how to learn latent (hidden)
    features from those signals that represent users’ preferences. We’ll then use
    those learned preferences to generate recommendations.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将实现一个协同过滤算法。我们将使用用户-项目互动信号，并演示如何从这些信号中学习表示用户偏好的潜在（隐藏）特征。然后我们将使用这些学习到的偏好来生成推荐。
- en: Pure collaborative filtering, as in figure 9.2, allows us to learn the similarity
    between items based entirely on user-interaction patterns with those items. This
    is a powerful concept, as it allows learning about items without any knowledge
    of the items themselves (such as titles, text, or other attributes).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 纯协同过滤，如图9.2所示，使我们能够根据用户与这些项目的互动模式来学习项目之间的相似性。这是一个强大的概念，因为它允许在不了解项目本身的情况下（如标题、文本或其他属性）了解项目。
- en: 9.3.1 Learning latent user and item features through matrix factorization
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 通过矩阵分解学习潜在用户和项目特征
- en: 'Collaborative filtering often uses a technique called *matrix factorization*
    to learn latent features about items based on user interactions. Latent features
    are features that are not directly observed but are inferred from other observed
    features. For example, assume you have four users with the following movie purchase
    history:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤通常使用一种称为*矩阵分解*的技术来根据用户交互学习关于项目的潜在特征。潜在特征是那些没有直接观察到但可以从其他观察到的特征推断出来的特征。例如，假设你有四个用户，以下是他们购买电影的历史记录：
- en: 'User 1—*Avengers: Endgame*, *Black Panther*, and *Black Widow*'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户1—*复仇者联盟4：终局之战*，*黑豹*和*黑寡妇*
- en: User 2—*Black Widow*, *Captain Marvel*, and *Black Panther*
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户2—*黑寡妇*，*惊奇队长*和*黑豹*
- en: User 3—*Black Widow*, *The Dark Knight*, and *The Batman*
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户3—*黑寡妇*，*黑暗骑士*和*蝙蝠侠*
- en: User 4—*The Little Mermaid*, *The Lion King*, and *Toy Story*
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户4—*小美人鱼*，*狮子王*和*玩具总动员*
- en: User 5—*Frozen*, *Toy Story*, and *The Lion King*
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户5—*冰雪奇缘*，*玩具总动员*和*狮子王*
- en: 'Are there patterns to these purchases? If you know the titles or descriptions,
    you could infer the following:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这些购买行为中有没有什么模式？如果你知道标题或描述，你可以推断出以下内容：
- en: 'Users 1–3:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 用户1–3：
- en: All of these are movies about superheroes.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有这些电影都是关于超级英雄的。
- en: Most of them were made by Marvel Studios, though some were made by Warner Brothers
    (DC Comics).
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其中大部分是由漫威工作室制作的，尽管也有一些是由华纳兄弟（DC漫画）制作的。
- en: They are all action movies.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们都是动作电影。
- en: They are not suitable for small children due to violence and/or language.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于暴力和/或语言问题，它们都不适合小孩子们。
- en: 'Users 4–5:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 用户4–5：
- en: All of them are animated movies.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有这些都是动画电影。
- en: All of them are suitable for small children.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有这些都很适合小孩子们。
- en: All of them are made by Disney/Pixar.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有这些都是由迪士尼/皮克斯制作的。
- en: Imagine you don’t have access to anything other than the product IDs, though.
    By using matrix factorization, it is possible to observe how users interact with
    items and to infer latent features about those items. If the features listed in
    the previous bullet points are the most predictive of the purchasing behavior
    of similar users, they are likely to be represented in the latent features learned
    by matrix factorization. Matrix factorization is also likely to discover other
    features that are not as obvious.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你除了产品ID之外没有其他任何信息。通过使用矩阵分解，可以观察到用户如何与项目互动，并推断出关于这些项目的潜在特征。如果前面提到的特征是最能预测类似用户购买行为的，那么它们很可能会在矩阵分解学习的潜在特征中体现出来。矩阵分解还可能发现其他不那么明显的特征。
- en: As a different example, in the RetroTech dataset, user signals may show one
    group of users purchasing stainless-steel microwaves, stainless-steel refrigerators,
    and stainless-steel dishwashers. Another group of users may be purchasing black
    microwaves, black refrigerators, and black dishwashers. By clustering the user-item
    interactions together, it’s possible to statistically determine a latent feature
    that separates these items by color. Additionally, one group may be purchasing
    televisions, PlayStations, and DVD players, and another group may be purchasing
    iPhones, phone cases, and screen protectors. By clustering these behaviors together,
    we can differentiate these product categories (home theaters versus mobile phones)
    into one or more latent features.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，在RetroTech数据集中，用户信号可能显示一组用户购买不锈钢微波炉、不锈钢冰箱和不锈钢铁锅，而另一组用户可能购买黑色微波炉、黑色冰箱和黑色铁锅。通过将用户-项目交互聚类在一起，可以统计地确定一个将颜色区分这些项目的潜在特征。此外，一组用户可能购买电视、PlayStation和DVD播放器，而另一组用户可能购买iPhone、手机壳和屏幕保护器。通过将这些行为聚类在一起，我们可以将这些产品类别（家庭影院与移动电话）区分为一或多个潜在特征。
- en: Figure 9.6 demonstrates an example user-item interaction matrix for a few products
    and users. The numbers are ratings representing how strongly a user (*y*-axis)
    is interested in an item (*x*-axis), with a purchase being weighted higher than
    an add-to-cart action, and an add-to-cart signal being weighted higher than a
    click. The empty cells represent no interaction between the user and the item.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6展示了几个产品和用户之间的示例用户-项目交互矩阵。这些数字是评分，表示用户（*y*-轴）对项目（*x*-轴）的兴趣强度，购买行为比加入购物车动作更重要，而加入购物车信号比点击更重要。空单元格表示用户和项目之间没有交互。
- en: '![figure](../Images/CH09_F06_Grainger.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F06_Grainger.png)'
- en: Figure 9.6 A user-item interaction matrix. Numbers represent a user’s preference
    for an item on a scale of 1 (very unfavorable) to 10 (very favorable). Empty cells
    represent no interaction between the user and the item.
  id: totrans-80
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.6 用户-项目交互矩阵。数字代表用户对项目的偏好，范围从1（非常不利）到10（非常有利）。空单元格表示用户和项目之间没有交互。
- en: Given the user-item interaction matrix, our goal is to figure out *why* particular
    items are preferred by each user. We assume that some combination of user interests
    and item similarities explain these preferences. Matrix factorization, therefore,
    takes the user-item ratings matrix and breaks it into two separate matrices—one
    mapping each user to a set of features, and one mapping each item to a set of
    features.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 给定用户-项目交互矩阵，我们的目标是找出特定项目为什么被每个用户所偏好。我们假设某些用户兴趣和项目相似性的组合解释了这些偏好。因此，矩阵分解将用户-项目评分矩阵分解成两个独立的矩阵——一个将每个用户映射到一组特征，另一个将每个项目映射到一组特征。
- en: Figure 9.7 demonstrates the matrix factorization process, resulting in the conversion
    of the user-item rankings matrix `R` into a corresponding user feature matrix
    `U` and item feature matrix `I`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7展示了矩阵分解过程，将用户-项目排名矩阵`R`转换为相应的用户特征矩阵`U`和项目特征矩阵`I`。
- en: '![figure](../Images/CH09_F07_Grainger.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F07_Grainger.png)'
- en: Figure 9.7 Matrix factorization. The user-item matrix `R` is decomposed into
    two matrices, a user matrix `U` and an item matrix `I`. The product of these two
    matrices (`U` `.` `I`) should be as close as possible to the original user-item
    matrix `R`.
  id: totrans-84
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.7 矩阵分解。用户-项目矩阵`R`被分解成两个矩阵，一个用户矩阵`U`和一个项目矩阵`I`。这两个矩阵的乘积（`U` `.` `I`）应尽可能接近原始的用户-项目矩阵`R`。
- en: Each row in the user matrix (`U`) is a vector representing one user, with each
    column representing one of three latent user features (labeled `Latent` `User`
    `Feature` `1`, `Latent` `User` `Feature` `2`, and `Latent` `User` `Feature` `3`).
    In the item matrix (`I`), each column is a vector representing one item, with
    each row representing one of three latent item features (labeled `Latent` `Item`
    `Feature` `1`, `Latent` `Item` `Feature` `2`, and `Latent` `Item` `Feature` `3`).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 用户矩阵（`U`）中的每一行代表一个用户，每一列代表三个潜在用户特征之一（标记为`潜在用户特征1`、`潜在用户特征2`和`潜在用户特征3`）。在项目矩阵（`I`）中，每一列代表一个项目，每一行代表三个潜在项目特征之一（标记为`潜在项目特征1`、`潜在项目特征2`和`潜在项目特征3`）。
- en: We don’t have names for these latent features or know exactly what they represent,
    but they are discovered mathematically and are predictive of actual user-item
    interests. The number of latent features is a hyperparameter that can be tuned,
    but it is set to `3` in this example. This means that each user is represented
    by a vector with three dimensions (latent features), and each item is also represented
    by a vector with three dimensions (latent features).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有为这些潜在特征命名，也不知道它们的确切含义，但它们是通过数学方法发现的，并且可以预测实际的用户-项目兴趣。潜在特征的数量是一个可以调整的超参数，但在这个例子中设置为`3`。这意味着每个用户由一个有三个维度（潜在特征）的向量表示，每个项目也由一个有三个维度（潜在特征）的向量表示。
- en: Once matrices `U` and `I` are learned, they can thereafter be used independently
    to predict the similarity between any user and item (by comparing users in `U`
    with items in `I`), between any two users (by comparing a user in `U` with another
    user in `U`), or between any two items (by comparing an item in `I` with another
    item in `I`). We will focus only on the user-item similarity as a means of personalizing
    recommendations for each user. Figure 9.8 demonstrates how to generate an item
    rating prediction for any user.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦学习到矩阵`U`和`I`，它们之后可以独立使用来预测任何用户和项目之间的相似性（通过比较`U`中的用户与`I`中的项目），任何两个用户之间的相似性（通过比较`U`中的用户与另一个`U`中的用户），或者任何两个项目之间的相似性（通过比较`I`中的项目与另一个`I`中的项目）。我们将只关注用户-项目相似性，作为为每个用户个性化推荐的手段。图9.8展示了如何为任何用户生成项目评分预测。
- en: '![figure](../Images/CH09_F08_Grainger.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F08_Grainger.png)'
- en: Figure 9.8 Calculating a user-item preference from the factorized matrices.
    Multiply each latent user feature value (first, second, and third values in the
    row for the user) by the corresponding latent item feature value (first, second,
    and third values in the column for the item), and then sum the results. This is
    the predicted user-item preference for the chosen user and item.
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.8 从分解矩阵中计算用户-项目偏好。将每个潜在用户特征值（用户行的第一个、第二个和第三个值）乘以相应的潜在项目特征值（项目列的第一个、第二个和第三个值），然后将结果相加。这是所选用户和项目的预测用户-项目偏好。
- en: 'For the first user (first row in `U`), we can generate a predicted rating for
    the movie *Avengers: Endgame* (first column in `I`) by performing a dot product
    between the first row of the user matrix `U` (`0.67`, `-0.51`, `2.81`) and the
    first column of the item matrix `I` (`0.09`, `0.75`, `3.43`), which results in
    a predicted rating of `(0.67` `*` `0.09)` `+` `(-0.51` `*` `0.75)` `+` `(2.81`
    `*` `3.43)` `=` `9.32`. Likewise, for the second user (second row in `U`), we
    can generate a predicted rating for the movie *The Notebook* (fourth column in
    `I`) by performing a dot product between the second row of the user matrix `U`
    (`1.13`, `3.18`, `-0.13`) and the fourth column of the item matrix `I` (`1.74`,
    `2.54`, `0.46`), which results in a predicted rating of `9.98`.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个用户（`U` 中的第一行），我们可以通过在用户矩阵 `U` 的第一行（`0.67`, `-0.51`, `2.81`）和项目矩阵 `I` 的第一列（`0.09`,
    `0.75`, `3.43`）之间执行点积来生成电影《复仇者联盟4：终局之战》（`I` 中的第一列）的预测评分，结果为 `(0.67` `*` `0.09)`
    `+` `(-0.51` `*` `0.75)` `+` `(2.81` `*` `3.43)` `=` `9.32`。同样，对于第二个用户（`U` 中的第二行），我们可以通过在用户矩阵
    `U` 的第二行（`1.13`, `3.18`, `-0.13`）和项目矩阵 `I` 的第四列（`1.74`, `2.54`, `0.46`）之间执行点积来生成电影《恋恋笔记本》（`I`
    中的第四列）的预测评分，结果为 `9.98`。
- en: While performing individual predictions between a single user and item may be
    helpful in some cases, such as for generating real-time recommendations immediately
    after an incremental user interaction, it is often more useful to generate a full
    user-item matrix `R'` of predicted ratings for all users and items. Figure 9.9
    demonstrates a final user-item matrix `R'` generated (on the far-right) by performing
    a dot product of the user matrix `U` with the item matrix `I`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在某些情况下，例如在增量用户交互后立即生成实时推荐时，对单个用户和项目进行单独预测可能有所帮助，但通常更有用的是生成一个包含所有用户和项目的预测评分的完整用户-项目矩阵
    `R'`。图9.9展示了通过执行用户矩阵 `U` 与项目矩阵 `I` 的点积生成的最终用户-项目矩阵 `R'`（在右侧）。
- en: '![figure](../Images/CH09_F09_Grainger.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F09_Grainger.png)'
- en: Figure 9.9 Reconstituted user-item matrix `R'`, with previous calculations from
    figure 9.8 highlighted. Note that the empty values from the original user-item
    matrix `R` are now filled in with predicted values (highlighted in black).
  id: totrans-93
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.9 重构的用户-项目矩阵 `R'`，其中图9.8中的先前计算突出显示。请注意，原始用户-项目矩阵 `R` 中的空值现在用预测值填充（以黑色突出显示）。
- en: When taking the dot product of the user matrix and the item matrix (`U` `.`
    `I`), the resulting user-item matrix `R'` should be as close as possible to the
    original user-item matrix `R`. Minimizing the difference between the original
    matrix `R` and predicted matrix `R'` is the training optimization goal of matrix
    factorization. The closer the two matrices are, the better the model’s ability
    to predict similar personalized recommendations in the future.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算用户矩阵和项目矩阵（`U` `.` `I`）的点积时，得到的结果用户-项目矩阵 `R'` 应尽可能接近原始用户-项目矩阵 `R`。最小化原始矩阵
    `R` 和预测矩阵 `R'` 之间的差异是矩阵分解的训练优化目标。两个矩阵越接近，模型预测未来相似个性化推荐的能力就越好。
- en: In practice, the latent features don’t perfectly represent all the potentially
    relevant features. By training with a loss function that reduces the difference
    between the original `R` and predicted `R'`, however, the model will maximize
    the chances of representing `R` and thus be able to best predict future recommendations
    based upon past user-item interactions.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，潜在特征并不能完美地代表所有可能的相关特征。然而，通过使用一个减少原始 `R` 和预测 `R'` 之间差异的损失函数进行训练，模型将最大化代表
    `R` 的可能性，从而能够根据过去用户-项目交互最佳预测未来的推荐。
- en: 9.3.2 Implementing collaborative filtering with Alternating Least Squares
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 使用交替最小二乘法实现协同过滤
- en: One popular algorithm for pure collaborative filtering (based only on user interaction
    with items) is *Alternating Least Squares* (ALS). ALS is an iterative algorithm
    that performs matrix factorization by alternating between learning the latent
    features of items and the latent features of users.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于用户与项目交互的纯协同过滤（仅基于用户与项目的交互）的一种流行算法是**交替最小二乘法**（ALS）。ALS是一种迭代算法，通过交替学习项目和用户的潜在特征来执行矩阵分解。
- en: The logic behind ALS is that latent features in a user-item ratings matrix are
    a combination of the user’s latent features and the items’ latent features. While
    the relative weights between users and items for each latent feature are not known
    upfront, it is possible to begin learning user feature weights by initially using
    random item weights and freezing them (keeping them constant). As the user feature
    weights begin to coalesce, they can be frozen and used as inputs when learning
    the item feature weights. ALS then continues to alternate between further training
    the user features matrix (with the latest item feature weights frozen) and the
    item features matrix (with the latest user feature weights frozen). This process
    is repeated for a configurable number of iterations until the weights of both
    matrices are well-balanced and optimized. By alternating between learning the
    latent features of items and users, ALS can iteratively learn the best combined
    weights of both matrices to improve the predictive power of the model.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ALS背后的逻辑是用户-项目评分矩阵中的潜在特征是用户潜在特征和项目潜在特征的组合。虽然每个潜在特征的相对权重在开始时并不知道，但可以通过最初使用随机的项目权重并冻结它们（保持它们恒定）来开始学习用户特征权重。随着用户特征权重开始合并，它们可以被冻结并用作学习项目特征权重的输入。然后，ALS继续交替训练用户特征矩阵（冻结最新的项目特征权重）和项目特征矩阵（冻结最新的用户特征权重）。这个过程会重复进行一定次数的迭代，直到两个矩阵的权重都得到很好的平衡和优化。通过交替学习项目和用户的潜在特征，ALS可以迭代地学习两个矩阵的最佳组合权重，以提高模型的预测能力。
- en: The number of latent features learned using matrix factorization is a hyperparameter,
    called the *rank*. The higher the rank, the more granular the features you can
    learn, but you also tend to need more data points to reliably learn more granular
    features. While you won’t be able to apply a label to each latent feature (features
    are just represented as numbers), it’s still possible to discover meaningful categories
    in the data that best predict similar items. ALS is a popular algorithm for collaborative
    filtering because it is relatively easy to implement and can scale to large datasets.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 使用矩阵分解学习到的潜在特征的数量是一个超参数，称为**秩**。秩越高，你能够学习的特征越细粒度，但你也倾向于需要更多的数据点来可靠地学习更细粒度的特征。虽然你无法为每个潜在特征应用标签（特征仅以数字表示），但仍然有可能在数据中发现有意义的类别，这些类别最能预测相似的项目。ALS是一种流行的协同过滤算法，因为它相对容易实现，并且可以扩展到大型数据集。
- en: In this section, we’ll discuss how to implement ALS using Spark to generate
    a recommendations model based on user-item interactions. We’ll use the RetroTech
    dataset, since it contains user-item interactions for a set of products. We’ll
    use user-item interactions to learn latent features about both users and items,
    and then we’ll use those latent features to generate future recommendations.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论如何使用Spark实现ALS（交替最小二乘法），以基于用户-项目交互生成推荐模型。我们将使用RetroTech数据集，因为它包含了一组产品的用户-项目交互。我们将利用用户-项目交互来学习关于用户和项目的潜在特征，然后我们将使用这些潜在特征来生成未来的推荐。
- en: We’ll start by generating a list of implicit preferences for each user-item
    pair using Spark’s built-in ALS implementation. Listing 9.1 generates a `user_product_
    implicit_preferences` collection, assigning a rating based on the strength of
    the user interaction.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用Spark内置的ALS实现生成每个用户-项目对的隐式偏好列表。列表9.1生成了一个`user_product_implicit_preferences`集合，根据用户交互的强度分配评分。
- en: Listing 9.1 Generating implicit user-item ratings from user signals
  id: totrans-102
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.1 从用户信号生成隐式用户-项目评分
- en: '[PRE0]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Only click signals are currently weighted, but weights can be set per signal
    type.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 目前只有点击信号被加权，但可以为每种信号类型设置权重。'
- en: '#2 Aggregates all signals to generate a single rating per user-item pair'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 对所有信号进行聚合，为每个用户-项目对生成一个单一评分'
- en: We modeled support for clicks, add-to-cart, and purchase signals, though we
    only assigned a weight of `1` to clicks and `0` to both add-to-cart and purchase
    signals. We did this to keep the math more straightforward for the ALS algorithm,
    but you can experiment with turning on add-to-cart or purchase signals by increasing
    their weights to a positive number. These weights are somewhat arbitrary, but
    the idea is to differentiate the strength of the user’s product interest based
    on their level of interaction. You could also simplify by just assigning a rating
    of `1` for each user-item pair if you don’t have confidence that more interactions
    by a user necessarily indicates a stronger rating or that the weights you’ve chosen
    are meaningful.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对点击、添加到购物车和购买信号进行了建模支持，尽管我们只给点击分配了权重`1`，给添加到购物车和购买信号分配了`0`。我们这样做是为了使ALS算法的数学更简单，但您可以尝试通过将它们的权重增加到正数来打开添加到购物车或购买信号。这些权重有些随意，但目的是根据用户的交互程度区分用户对产品的兴趣强度。如果您对用户更多的交互不一定表示更强的评分或您选择的权重有意义的信心不足，您也可以通过为每个用户-项目对分配评分`1`来简化处理。
- en: With our user-item ratings prepared, we’ll generate a dataframe from the prepared
    collection to train and test the model. Our dataset contains less than 50,000
    products, and we’ll be using all of them in listing 9.2; however, you may want
    to modify the `top_product_count_for_recs` to a substantially lower number if
    you want to run through it quickly. Depending on your hardware and Docker resource
    configuration, it could take anywhere from several minutes to several days to
    run. For a quick (but low-quality) run, consider testing with 1,000 products initially
    (`top_product_count_ for_recs=1000`) and then scaling up as you feel comfortable.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的用户-项目评分准备就绪后，我们将从准备好的集合中生成一个数据框来训练和测试模型。我们的数据集包含不到50,000个产品，我们将在列表9.2中使用它们全部；然而，如果您想快速运行，可以将`top_product_count_for_recs`修改为一个显著更低的数字。根据您的硬件和Docker资源配置，运行时间可能从几分钟到几天不等。为了快速（但质量较低）的运行，可以考虑最初用1,000个产品进行测试（`top_product_count_for_recs=1000`），然后根据您的舒适度进行扩展。
- en: Listing 9.2 Preparing the user-product-ratings data for training
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.2 准备用于训练的用户-产品-评分数据
- en: '[PRE1]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#1 Decreasing the number of products can speed up training, but with reduced
    accuracy.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 减少产品数量可以加快训练速度，但会降低准确性。'
- en: '#2 Returns the user, product, and rating'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 返回用户、产品和评分'
- en: '#3 Limits the number recommendations to the most popular products'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 限制推荐数量到最受欢迎的产品'
- en: 'Our dataframe contains three columns: `user`, `product`, and `rating`. For
    performance reasons, many machine learning algorithms (including Spark’s ALS implementation,
    which we will be using) prefer to deal with numeric IDs instead of strings. Spark
    contains a `StringIndexer` helper object that can be used to convert string IDs
    to numeric IDs, and a corresponding `IndexToString` object that can be used to
    convert the numeric IDs back to string IDs. Listing 9.3 integrates this ID conversion
    into our dataframe.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据框包含三列：`user`、`product`和`rating`。出于性能考虑，许多机器学习算法（包括我们将要使用的Spark的ALS实现）更愿意处理数字ID而不是字符串。Spark包含一个`StringIndexer`辅助对象，可以用来将字符串ID转换为数字ID，以及一个相应的`IndexToString`对象，可以用来将数字ID转换回字符串ID。列表9.3将这种ID转换整合到我们的数据框中。
- en: Listing 9.3 Converting IDs to integers for Spark’s ALS algorithm
  id: totrans-114
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.3 将ID转换为整数以供Spark的ALS算法使用
- en: '[PRE2]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#1 Transforms user and product columns into index columns for the dataframe'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将用户和产品列转换为数据框的索引列'
- en: '#2 The numeric index-to-string mappings for product and user'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 产品和用户的数字索引到字符串映射'
- en: '#3 Performs the index-to-string transformation for the user identifier'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 对用户标识符执行索引到字符串的转换'
- en: '#4 Maps the string user field to an integer index named userIndex'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将字符串用户字段映射到名为userIndex的整数索引'
- en: '#5 Maps the string product field to an integer index named productIndex'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 将字符串产品字段映射到名为productIndex的整数索引'
- en: 'Output:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE3]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As you can see from listing 9.3, our dataframe now contains two additional
    columns: `userIndex` and `productIndex`. We’ll use these numeric IDs going forward
    in the ALS implementation code, before we call the `indexes_to_strings` function
    at the very end to convert back to our original string IDs.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从列表9.3中可以看到，我们的数据框现在包含了两列额外的列：`userIndex`和`productIndex`。在最后调用`indexes_to_strings`函数将它们转换回原始字符串ID之前，我们将使用这些数字ID在ALS实现代码中继续使用。
- en: 'Now that our user-item preferences dataframe is prepared, it’s time to invoke
    the ALS algorithm. ALS requires three parameters: `userCol`, `itemCol`, and `ratingCol`,
    which correspond to the `userIndex`, `productIndex`, and `rating` columns in our
    dataframe. We’ll also set a few other parameters, including the following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了用户-项目偏好数据框，是时候调用ALS算法了。ALS需要三个参数：`userCol`、`itemCol`和`ratingCol`，它们分别对应于我们数据框中的`userIndex`、`productIndex`和`rating`列。我们还会设置一些其他参数，包括以下内容：
- en: '`maxIter=3` (the maximum number of iterations to run)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxIter=3`（运行的最大迭代次数）'
- en: '`rank=10` (the number of latent features to learn)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rank=10`（要学习的潜在特征数量）'
- en: '`regParam=0.15` (the regularization parameter)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regParam=0.15`（正则化参数）'
- en: '`implicitPrefs=True` (whether to treat the ratings as implicit or explicit)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`implicitPrefs=True`（是否将评分视为隐式或显式）'
- en: '`coldStartStrategy=drop` (how to handle new users or items that were not present
    in the training data)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`coldStartStrategy=drop`（如何处理训练数据中不存在的新用户或项目）'
- en: Listing 9.4 demonstrates how to invoke ALS with these parameters.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.4展示了如何使用这些参数调用ALS。
- en: Listing 9.4 Training an ALS model using Spark
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.4 使用Spark训练ALS模型
- en: '[PRE4]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#1 Splits the preferences, 95% as training data and 5% as test data'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将偏好分为95%的训练数据和5%的测试数据'
- en: '#2 Trains the ALS model with the user preferences in the training set'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用训练集中的用户偏好训练ALS模型'
- en: '#3 Measures the trained model against the user preferences in the test set'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将训练好的模型与测试集中的用户偏好进行比较'
- en: 'Output:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE5]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You have now trained a recommendation model! We split the data into a training
    set (95%) and a test set (5%), built the ALS model, and then ran an evaluator
    to calculate a root mean square error (RMSE) loss function to measure the quality
    of the model. The RMSE is a measure of how far off the predicted ratings are from
    the actual ratings, so the lower the RMSE, the better the model. The absolute
    value of the RMSE is less important than the relative value across different model
    training passes, as the calculation depends on the scale used in the underlying
    data. If you increase the `maxIter`, find an optimal `rank`, and increase the
    `top_product_count_for_recs` when preparing the user-product-ratings data, you’ll
    likely see the RMSE decrease a bit due to improvement in the model.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经训练了一个推荐模型！我们将数据分为训练集（95%）和测试集（5%），构建了ALS模型，然后运行评估器来计算均方根误差（RMSE）损失函数以衡量模型的质量。RMSE是预测评分与实际评分之间差异的度量，因此RMSE越低，模型越好。RMSE的绝对值相对于不同模型训练过程中的相对值来说不太重要，因为计算依赖于底层数据使用的尺度。如果你增加`maxIter`，找到最优的`rank`，并在准备用户-产品-评分数据时增加`top_product_count_for_recs`，你可能会看到RMSE略有下降，这是由于模型改进导致的。
- en: Now that the model is trained, we can use it to generate recommendations. Listing
    9.5 demonstrates how to generate item recommendations for all users. We’ll generate
    10 recommendations for each user and display the top 5 users’ recommendations.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经训练好了，我们可以用它来生成推荐。列表9.5展示了如何从ALS模型生成所有用户的物品推荐。我们将为每个用户生成10个推荐，并显示前5个用户的推荐。
- en: Listing 9.5 Generating user-item recommendations from the ALS model
  id: totrans-140
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.5 从ALS模型生成用户-项目推荐
- en: '[PRE6]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Output:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE7]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that the format of the recommendations is a bit awkward. We’re stuck with
    the `userIndex` instead of our original `user`, and the `recommendations` column
    is an array of structs, with each struct containing a `productIndex` and a `rating`.
    Let’s clean this up by converting each user-item recommendation into a row and
    replacing the `userIndex` and `productIndex` values with our original `user` and
    `product` IDs. Listing 9.6 demonstrates how to do this.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，推荐的格式有点尴尬。我们只能使用`userIndex`而不是原始的`user`，而`recommendations`列是一个结构体数组，每个结构体包含一个`productIndex`和一个`rating`。让我们通过将每个用户-项目推荐转换为行，并用我们的原始`user`和`product`
    ID替换`userIndex`和`productIndex`值来清理它。列表9.6展示了如何做到这一点。
- en: Listing 9.6 Converting recommendations into a final, cleaned-up format
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.6 将推荐转换为最终、清理过的格式
- en: '[PRE8]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In this listing, we first `explode` the recommendations into separate rows for
    each recommendation with `rec.productIndex` and `rec.rating` columns. After selecting
    `userIndex` onto each row, we select `rec.productIndex` as `productIndex` and
    `rec .rating` as `rating`. Finally, we convert back to `user` and `product` from
    `userIndex` and `productIndex`, and we return `user`, `product`, and `boost`.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个列表中，我们首先使用`rec.productIndex`和`rec.rating`列将推荐`explode`到每个推荐的单独行。然后，我们将`userIndex`选择到每一行上，选择`rec.productIndex`作为`productIndex`，将`rec.rating`作为`rating`。最后，我们将从`userIndex`和`productIndex`转换回`user`和`product`，并返回`user`、`product`和`boost`。
- en: Let’s save our recommendations to a collection for future use. This will enable
    us to serve the recommendations instantly from the search engine or to use them
    as boosts to personalize search results. Listing 9.7 writes our user-item recommendations
    dataframe to a `user_item_recommendations` collection in the search engine, following
    a data format similar to the one we used in chapter 8 to represent signal boosts.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将我们的推荐保存到集合中以便将来使用。这将使我们能够从搜索引擎中即时提供推荐，或者将它们用作增强以个性化搜索结果。列表9.7将我们的用户-项目推荐数据框写入搜索引擎中的`user_item_recommendations`集合，遵循与第8章中我们用来表示信号增强类似的数据格式。
- en: Listing 9.7 Indexing the recommendations into the search engine
  id: totrans-149
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.7 将推荐索引到搜索引擎中
- en: '[PRE9]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You have now generated item recommendations for users based on their interactions
    with items, and you’ve saved them for future use in the `user_item_recommendations`
    collection in the search engine. Next, we’ll demonstrate how we can serve these
    recommendations and use them to personalize search results.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已经根据用户与项目的交互生成了项目推荐，并将它们保存在搜索引擎中的`user_item_recommendations`集合中供将来使用。接下来，我们将演示我们如何提供这些推荐并使用它们来个性化搜索结果。
- en: 9.3.3 Personalizing search results with recommendation boosting
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.3 使用推荐增强个性化搜索结果
- en: With user-item recommendations generated, we can now personalize search results.
    The only difference between our collection schema for the `signals_boosts` collection
    in chapter 8 and the `user_item_recommendations` collection here is the replacement
    of the `query` column with a `user` column. In other words, whereas signals boosting
    is based on matching a particular keyword query and applying associated item relevance
    boosts, personalization is based on matching a particular user and applying associated
    item relevance boosts.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 生成用户-项目推荐后，我们现在可以个性化搜索结果。第8章中`signals_boosts`集合和这里的`user_item_recommendations`集合之间的唯一区别是将`query`列替换为`user`列。换句话说，信号增强是基于匹配特定的关键字查询并应用相关项目相关性增强，而个性化是基于匹配特定的用户并应用相关项目相关性增强。
- en: With our recommendations collection now populated from listing 9.7, we can either
    serve the recommendations directly (no keyword query) or use the recommendations
    to personalize search results by boosting them based on the user’s recommendations.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在根据列表9.7填充了我们的推荐集合后，我们可以直接提供推荐（无关键字查询）或使用推荐根据用户的推荐进行增强以个性化搜索结果。
- en: Pure collaborative recommendations
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 纯协同推荐
- en: Serving recommendations directly is straightforward, so we’ll start there. Listing
    9.8 shows recent signals for one of our users, for whom we’ll demonstrate these
    personalization techniques.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 直接提供推荐很简单，所以我们将从这里开始。列表9.8显示了我们的一个用户的最近信号，我们将演示这些个性化技术。
- en: Listing 9.8 Interaction history for our target user
  id: totrans-157
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.8 目标用户的交互历史
- en: '[PRE10]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 User for whom we’ll be personalizing results'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 我们将为谁个性化结果'
- en: Based on the user’s history, it’s clear that they are interested in Apple products,
    tablets, and computers. The following listing demonstrates how to serve up recommendations
    for this user from our `user_item_recommendations` collection.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 根据用户的历史记录，很明显他们对苹果产品、平板电脑和计算机感兴趣。以下列表演示了如何从我们的`user_item_recommendations`集合为该用户提供推荐。
- en: Listing 9.9 Serving recommendations using a signals boosting query
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.9 使用信号增强查询提供推荐
- en: '[PRE11]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#1 Function omitted for brevity; it can be seen in listing 4.3.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 为了简洁，省略了函数；它可以在列表4.3中看到。'
- en: '#2 Queries the recommendation collection for indexed product boosts'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 查询推荐集合以索引产品增强'
- en: Figure 9.10 shows the output from listing 9.9\. At the top, you’ll notice a
    “Boost Query” listed, showing the top-recommended products for the user, along
    with their relative boost for the user (which was calculated as `rating * 100`).
    Under that boost query, you’ll see the boosted search results for this blank keyword
    search, which are the raw recommendations for the user.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.10显示了列表9.9的输出。在顶部，你会注意到一个“提升查询”的条目，显示了为用户推荐的最推荐产品及其对用户的相对提升（计算为`rating *
    100`）。在提升查询下方，你会看到针对此空白关键词搜索的增强搜索结果，这是用户的原始推荐。
- en: '![figure](../Images/CH09_F10_Grainger.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F10_Grainger.png)'
- en: Figure 9.10 Recommendations for a user based only on collaborative filtering
  id: totrans-167
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.10 仅基于协同过滤的用户推荐
- en: The recommendations boost a 16 GB iPad to the top, which makes sense given that
    the user previously searched for and clicked on the 16 GB iPad, with another Apple
    iPad (a 32 GB model) ranked fourth. You also see other tablets made by competing
    manufacturers with similar configurations within the top recommendations. This
    is a good example of how collaborative filtering can help surface items that might
    not directly match the user’s previous interactions (with only an Apple laptop
    and iPads), but which may still be relevant to the user’s interests (similar tablets
    to iPads).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐将16GB的iPad提升到顶部，这是有道理的，因为用户之前搜索并点击了16GB的iPad，另一款苹果iPad（32GB型号）排名第四。你还会看到其他制造商生产的具有类似配置的平板电脑在顶级推荐中。这是一个很好的例子，说明了协同过滤如何帮助展示可能不直接匹配用户先前互动（只有苹果笔记本电脑和iPad）的项目，但这些项目可能仍然与用户的兴趣相关（与iPad类似的平板电脑）。
- en: Recommendations like these can be useful to integrate alongside traditional
    search results, or possibly to even insert into a set of search results. But it’s
    also possible to use them as boosts to your keyword ranking algorithm to personalize
    search results, which we’ll explore next.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '这样的推荐可以与传统的搜索结果集成使用，或者甚至可以插入到一组搜索结果中。但也可以将它们用作关键词排名算法的增强，以个性化搜索结果，我们将在下一节探讨。 '
- en: Pure keyword search vs. personalized search
  id: totrans-170
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 纯关键词搜索与个性化搜索
- en: Instead of serving recommendations independently of keyword search, it can also
    be useful to blend them in as additional signals in your search ranking algorithm
    to personalize the results. Going back to our last example, imagine that our user
    who is interested in iPads and MacBooks from Apple performs a keyword search for
    `tablet`. How would this look different than if the tablet recommendations were
    used to personalize the search results? Listing 9.10 runs the query before and
    after applying signals boosts based on the user’s personalized recommendations.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 除了独立于关键词搜索提供推荐外，还可以将它们作为额外的信号融入搜索排名算法中，以个性化结果。回到我们上一个例子，想象一下，如果我们的用户对苹果的iPad和MacBook感兴趣，他执行了“平板”的关键词搜索。如果使用平板推荐来个性化搜索结果，这会有什么不同？列表9.10在应用基于用户个性化推荐的信号提升之前和之后运行了查询。
- en: Listing 9.10 Non-personalized vs. personalized search results
  id: totrans-172
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.10 非个性化与个性化搜索结果
- en: '[PRE12]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#1 Non-personalized search results (keyword search only)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 非个性化搜索结果（仅关键词搜索）'
- en: '#2 Personalized search results (keyword + user-item recommendations boosting)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 个性化搜索结果（关键词 + 用户-项目推荐提升）'
- en: Figure 9.11 shows the output of the non-personalized query for `tablet`, whereas
    figure 9.12 shows the output once the recommendation boosts have been applied
    to personalize the search results.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.11显示了针对“平板”的非个性化查询输出，而图9.12显示了应用推荐提升以个性化搜索结果后的输出。
- en: The personalized search results are likely much more relevant for this user
    than the non-personalized results. It’s worth noting that in our implementation,
    the personalization is *only* applied as a relevance boost. This means products
    that don’t match the user’s explicit query will not be returned, and all items
    that do match the query will still be returned; the only difference is the ordering
    of the products, as items personalized to the user should now show up on the first
    page.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 个性化搜索结果可能比非个性化结果对用户的相关性更大。值得注意的是，在我们的实现中，个性化仅作为相关性提升应用。这意味着与用户明确查询不匹配的产品将不会返回，并且所有匹配查询的项目仍然会返回；唯一的区别是产品的排序，因为针对用户个性化的项目现在应该显示在第一页。
- en: '![figure](../Images/CH09_F11_Grainger.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F11_Grainger.png)'
- en: Figure 9.11 Traditional keyword search for `tablet` with no personalization
    applied
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.11 无个性化应用的“平板”传统关键词搜索
- en: '![figure](../Images/CH09_F12_Grainger.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F12_Grainger.png)'
- en: Figure 9.12 Personalized search for `tablet`, where the user has shown an interest
    in the Apple brand
  id: totrans-181
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.12 个人化搜索“tablet”，其中用户对Apple品牌表示了兴趣
- en: Also note that after the boosted recommendations (tablets from the recommendation
    example) the fifth search result is an item from the non-personalized search results,
    the “Memorial Tablet” titled CD.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 还请注意，在增强推荐（推荐示例中的平板电脑）之后，第五个搜索结果是来自非个性化搜索结果的项目，“纪念平板”标题为CD。
- en: 'This implies two things:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着两件事：
- en: If you are personalizing search results and not just serving pure recommendations,
    you’ll likely want to generate more than 10 recommendations per user, particularly
    since recommendations only show up if they also match a user’s explicit query.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在个性化搜索结果，而不仅仅是提供纯推荐，你可能希望为每个用户生成超过10个推荐，尤其是当推荐只有在它们也匹配用户的明确查询时才会显示出来。
- en: The non-personalized relevance algorithm is still critical. If signals boosting
    based on the query (per chapter 8) was applied in addition to recommendations
    boosting (based on the user), you would see popular tablets at the top (and not
    the tablet sleeve and CD), with the personalized tablets then moving up higher
    among the popular results because of the personalization.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非个性化相关性算法仍然至关重要。如果在基于查询（第8章所述）的信号增强（基于用户）的基础上，再加上基于用户的推荐增强（基于用户），你将看到最上面的热门平板电脑（而不是平板电脑套和CD），而个性化的平板电脑由于个性化而将在热门结果中上升更高。
- en: We’ve now learned how collaborative filtering works through matrix factorization,
    we’ve implemented recommendations based on a collaborative filtering algorithm
    (ALS), and we’ve demonstrated how to use those recommendations to personalize
    search results. In the next section, we’ll explore another technique for personalization
    based on document embeddings.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经了解了协同过滤是如何通过矩阵分解工作的，我们已经实现了基于协同过滤算法（ALS）的推荐，并展示了如何使用这些推荐来个性化搜索结果。在下一节中，我们将探讨另一种基于文档嵌入的个性化技术。
- en: 9.4 Personalizing search using content-based embeddings
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 使用基于内容的嵌入个性化搜索
- en: In the previous section, we used user signals to learn personalized boosts for
    particular items. These boosts were generated by learning latent features about
    users and items using matrix factorization on user-item interaction patterns.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们使用了用户信号来学习特定项目的个性化增强。这些增强是通过在用户-项目交互模式上使用矩阵分解来学习用户和项目的潜在特征生成的。
- en: You could also use these latent factors directly to cluster users or items together.
    Unfortunately, there isn’t a great way to reliably map queries into particular
    clusters of items based only on user-interaction signals without having already
    seen the corresponding queries before (the cold-start problem, again). Thankfully,
    it is quite rare for a search engine to *not* have additional knowledge of items
    such as titles, descriptions, and other attributes.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以直接使用这些潜在因素将用户或项目聚在一起。不幸的是，没有一种可靠的方法仅基于用户交互信号将查询映射到特定项目的集群中，而不需要事先看到相应的查询（再次是冷启动问题）。幸运的是，搜索引擎没有关于项目（如标题、描述和其他属性）的额外知识是非常罕见的。
- en: In this section, we’ll look at a hybrid approach using both content-based understanding
    and user-interaction patterns to build an evolving user profile to personalize
    search results.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨一种混合方法，结合基于内容的理解和用户交互模式来构建一个不断发展的用户配置文件以个性化搜索结果。
- en: 9.4.1 Generating content-based latent features
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.1 生成基于内容的潜在特征
- en: We’ve covered many techniques for utilizing fields to filter and boost on explicit
    attributes in documents. Chapters 5–7, in particular, focused on generating knowledge
    graphs and parsing domain-specific entities to help with context-dependent relevance.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了许多利用字段来过滤和增强文档中显式属性的技术。第5章至第7章特别关注生成知识图谱和解析特定领域的实体，以帮助实现上下文相关的相关性。
- en: While those techniques can certainly be useful for implementing personalized
    search (and we encourage you to experiment with them), we’re going to explore
    a different approach in this section. Instead of using explicit attributes, we’re
    going to use latent features learned from the content of documents to generate
    personalized search results. We’ll use a large language model (LLM) to generate
    embeddings for each document, and then we’ll use those embeddings along with user
    interactions with documents to build an evolving user profile. Finally, we’ll
    use that user profile to personalize search results.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些技术确实可以用于实现个性化搜索（并且我们鼓励您尝试它们），但在这个部分，我们将探索一种不同的方法。我们不会使用显式属性，而是将使用从文档内容中学习的潜在特征来生成个性化搜索结果。我们将使用大型语言模型（LLM）为每个文档生成嵌入，然后我们将使用这些嵌入以及用户与文档的交互来构建一个不断发展的用户档案。最后，我们将使用该用户档案来个性化搜索结果。
- en: Figure 9.13 demonstrates conceptually how using an LLM to generate embeddings
    for documents works. Similar to how we used matrix factorization in section 9.3.1
    to create a matrix that mapped each item to its list of latent features, we’ll
    use an LLM to generate a vector of latent features for each document. We’ll extract
    these latent features based on the text of the document mapped into a vector space
    that has already been learned by the LLM. Don’t worry for now about the mechanics
    of *how* the LLM is trained—we will cover that in depth in chapters 14 and 15\.
    Just know that it is trained on a large corpus of text, and it learns how to map
    words and phrases into a vector space using some number of latent features that
    represent the meaning of the text. Each of the dimensions in the vector space
    represents a latent feature, and the value of each dimension represents how strongly
    that latent feature is represented in the text.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.13从概念上展示了如何使用LLM为文档生成嵌入。类似于我们在9.3.1节中使用矩阵分解创建一个映射每个项目到其潜在特征列表的矩阵，我们将使用LLM为每个文档生成一个潜在特征的向量。我们将根据文档文本映射到一个LLM已经学习过的向量空间中提取这些潜在特征。现在不必担心LLM是如何训练的机制——我们将在第14章和第15章中深入探讨这一点。只需知道它是在一个大型文本语料库上训练的，并且它学会了如何使用一些代表文本意义的潜在特征将单词和短语映射到向量空间。向量空间中的每个维度代表一个潜在特征，每个维度的值代表该潜在特征在文本中的表示强度。
- en: '![figure](../Images/CH09_F13_Grainger.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F13_Grainger.png)'
- en: Figure 9.13 Item embeddings from an LLM. Each dimension in the vector space
    represents a latent feature, and the value of each dimension represents how strongly
    that latent feature is represented in the text for that item.
  id: totrans-196
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.13展示了来自一个LLM的项目嵌入。向量空间中的每个维度代表一个潜在特征，每个维度的值代表该潜在特征在文本中对该项目的表示强度。
- en: The values in figure 9.13 are for illustration purposes and are not the actual
    values that would be generated by our LLM. We have assigned simplified labels
    to the features to describe what they seem to represent (“size”, “color”, “computer-like”,
    and “cost”), but in a real-world scenario, these features would be unlabeled and
    would represent more complex latent features combining many different aspects
    learned by the LLM’s deep neural network during its training process.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.13中的值仅用于说明目的，并不是我们LLM实际生成的值。我们为这些特征分配了简化的标签来描述它们似乎代表的内容（“大小”、“颜色”、“类似计算机”和“成本”），但在现实世界的场景中，这些特征将是未标记的，并且将代表LLM在训练过程中学习到的更复杂的潜在特征，这些潜在特征结合了许多不同的方面。
- en: For our examples, we’ll be using the `all-mpnet-base-v2` LLM, a publicly available
    model ([https://huggingface.co/sentence-transformers/all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2))
    that serves as a good general-purpose LLM for semantic search and clustering over
    sentences and short paragraphs, like those in our RetroTech dataset. It is a lightweight
    model (only 768 dimensions) that was trained on over 1.17 billion sentence pairs
    from across the web, providing a good general-knowledge base.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们将使用`all-mpnet-base-v2` LLM，这是一个公开可用的模型（[https://huggingface.co/sentence-transformers/all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2)），它是一个适用于语义搜索和句子及短段落（如我们RetroTech数据集中的段落）的通用LLM。这是一个轻量级模型（只有768个维度），它基于来自整个网络的超过11.7亿个句子对进行训练，提供了一个良好的通用知识库。
- en: The following listing retrieves the fields we need to pass to the LLM.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表检索了我们需要传递给LLM的字段。
- en: Listing 9.11 Retrieving product data to generate embeddings
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.11检索产品数据以生成嵌入
- en: '[PRE13]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: To generate embeddings, we first use Spark to create a new `products_samples`
    table containing a subset of fields useful for generating embeddings and identifying
    the associated products. Listing 9.12 demonstrates how we can generate embeddings
    for each product using the `all-mpnet-base-v2` LLM and the `Sentence_Transformers`
    library. We’ll generate a `product_embeddings` object containing a 768-dimension
    vector for each product, along with a `product_names` object containing the name
    of each product and a `product_ids` object containing the ID of each product.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成嵌入，我们首先使用Spark创建一个新的`products_samples`表，其中包含用于生成嵌入和识别相关产品的字段子集。列表9.12展示了我们如何使用`all-mpnet-base-v2`
    LLM和`Sentence_Transformers`库为每个产品生成嵌入。我们将生成一个包含每个产品的768维向量的`product_embeddings`对象，以及一个包含每个产品名称的`product_names`对象和一个包含每个产品ID的`product_ids`对象。
- en: Listing 9.12 Generating product embeddings
  id: totrans-203
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.12 生成产品嵌入
- en: '[PRE14]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#1 Loads the all-mpnet-base-v2 LLM'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 加载all-mpnet-base-v2 LLM'
- en: '#2 Optimization code to cache generated embeddings is omitted for brevity.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 为了简洁起见，省略了缓存生成的嵌入的优化代码。'
- en: '#3 Generates the 768-dimension vector embedding for all products'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 为所有产品生成768维向量嵌入'
- en: Because we’re using the out-of-the-box `all-mpnet-base-v2` model, loading and
    generating embeddings for all our products is as simple as the code in listing
    9.12\. Because the process of generating embeddings for all products can take
    a while, the notebooks additionally contain some omitted code optimizations to
    cache and reuse embeddings to save extra processing time.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用的是现成的`all-mpnet-base-v2`模型，因此为所有产品加载和生成嵌入的过程就像列表9.12中的代码一样简单。因为为所有产品生成嵌入的过程可能需要一些时间，笔记本中还包含了一些省略的代码优化，用于缓存和重用嵌入以节省额外的处理时间。
- en: If we want to compare the similarity of two products, we can directly compare
    their vectors using dot product or cosine similarity calculations. The 768 features
    in the vector are pretrained latent features of each document, similar to the
    latent features represented in the item feature matrix in figure 9.7\. This means
    that we can now
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想比较两个产品的相似度，我们可以直接使用点积或余弦相似度计算来比较它们的向量。向量中的768个特征是每个文档的预训练潜在特征，类似于图9.7中项目特征矩阵中表示的潜在特征。这意味着我们现在可以
- en: Generate embeddings for any item or query to get a vector representation of
    that item or query.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为任何项目或查询生成嵌入以获取该项目或查询的向量表示。
- en: Perform semantic search starting with any query embedding and find the closest
    (cosine or dot product) other embeddings.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从任何查询嵌入开始进行语义搜索，找到最接近（余弦或点积）的其他嵌入。
- en: Use an item’s embedding to generate recommendations for other items by finding
    the ones with the most similar (cosine or dot product) embeddings.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一个项目的嵌入来生成其他项目的推荐，通过找到与最相似（余弦或点积）嵌入的项目。
- en: But what about generating user-based recommendations or personalized search
    results? In figure 9.7, we not only factored out latent item features, but we
    also factored out latent user features. The whole idea behind collaborative filtering
    in section 9.2 is that similar users interact with similar items precisely *because*
    the items share features that overlap with those users’ interest. In other words,
    a vector representing a user’s interests should be similar to the vectors representing
    the items for which the user has expressed interest.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 但关于基于用户生成推荐或个性化搜索结果怎么办？在图9.7中，我们不仅提取了潜在的项目特征，还提取了潜在的用户特征。第9.2节中协同过滤背后的整个想法是，相似的用户与相似的项目互动，正是因为这些项目具有与用户兴趣重叠的特征。换句话说，代表用户兴趣的向量应该与代表用户表示兴趣的项目向量相似。
- en: To personalize search results based on embedding vectors, we thus need to generate
    a vector representing the user’s interests. One way to do this is by taking the
    average of the vectors representing the items with which the user has interacted.
    This is a simple way to generate a vector representing *all* the user’s past interests,
    and it works surprisingly well in practice. Unfortunately, personalizing *every*
    future search based on every past search can be a bit too aggressive, as users
    often perform unrelated searches for different types of items at different times.
    To avoid unhelpful over-personalization in these cases, it can be useful to first
    apply some guardrails across different item categories, which we’ll cover next.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了根据嵌入向量个性化搜索结果，我们需要生成一个代表用户兴趣的向量。一种方法是取用户已与之互动的商品表示向量的平均值。这是一种简单的方法来生成一个代表用户所有过去兴趣的向量，并且在实践中效果惊人。不幸的是，基于每次过去搜索来个性化每次未来搜索可能会有些过于激进，因为用户经常在不同时间进行与不同类型商品无关的搜索。为了避免在这些情况下出现无用的过度个性化，首先在不同商品类别上应用一些防护栏可能是有用的，我们将在下一节中介绍。
- en: 9.4.2 Implementing categorical guardrails for personalization
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.2 实现个性化分类的防护栏
- en: The fact that someone searches for an item doesn’t always mean they want to
    see similar items. But if they do want personalization, it is usually a very bad
    idea to apply personalization across conceptual or categorical boundaries. For
    example, if someone watches the movie *The Terminator*, which contains violent
    time-traveling robots, it doesn’t mean they want to purchase a robot vacuum cleaner
    or a gun. As a concrete example from our dataset, imagine that someone previously
    expressed interest in a “Hello Kitty Water Bottle”, a “GE Electric Razor (Black)”,
    “GE Bright White Light Bulbs”, and a “Samsung Stainless-steel Refrigerator”. If
    they subsequently perform a search for `microwave`, which of the items from figure
    9.14 would be most appropriate to recommend?
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 某人搜索某件商品并不总是意味着他们想看到类似商品。但如果他们确实想要个性化，通常在概念或类别边界上应用个性化是一个非常糟糕的想法。例如，如果某人观看了包含暴力时间旅行的机器人的电影《终结者》，这并不意味着他们想购买机器人吸尘器或枪。作为一个来自我们数据集的具体例子，想象一下，如果某人之前对“Hello
    Kitty 水瓶”、“GE 黑色电动剃须刀”、“GE 明亮白灯泡”和“三星不锈钢冰箱”表示了兴趣。如果他们随后搜索“微波炉”，图 9.14 中的哪些商品最合适推荐？
- en: '![figure](../Images/CH09_F14_Grainger.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F14_Grainger.png)'
- en: Figure 9.14 Personalization guardrails can help prevent unrelated past interests
    from unexpectedly influencing future searches
  id: totrans-218
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.14 个性化防护栏可以帮助防止无关过去的兴趣意外影响未来的搜索
- en: While the user previously looked at “white” lights and a “black” electric shaver,
    there is no good reason to apply those color preferences to the unrelated category
    of “kitchen appliances”. Additionally, it is questionable whether the interest
    in a “Hello Kitty Water Bottle” would transfer over to an interest in a “Hello
    Kitty microwave”, or whether looking at “light bulbs” and an “electric shaver”
    made by the company “GE” would in any way translate into a user having a brand
    affinity for “GE” when looking at “kitchen appliances”. Given that this particular
    user has already shown an interest in another appliance (a refrigerator that is
    “stainless-steel”) made by the company “Samsung”, however, it is very reasonable
    to assume they would be more interested in other “stainless-steel” appliances
    made by “Samsung” (or at least by other companies beyond “GE”), such as the microwave
    for which they are now searching.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户之前查看“白色”灯和“黑色”电动剃须刀时，没有充分的理由将那些颜色偏好应用到无关的“厨房电器”类别中。此外，是否将“Hello Kitty 水瓶”的兴趣转移到“Hello
    Kitty 微波炉”上，或者查看“灯泡”和由“GE”公司制造的“电动剃须刀”是否以任何方式转化为用户在查看“厨房电器”时对“GE”品牌的品牌忠诚度，这都是值得怀疑的。然而，鉴于这位特定用户已经对另一件电器（由“三星”公司制造的“不锈钢”冰箱）表示了兴趣，因此，他们可能会对“三星”公司（或至少是“GE”公司以外的其他公司）制造的“不锈钢”电器更感兴趣，例如他们现在正在搜索的微波炉。
- en: Personalization should be applied with a light touch. It is easy to make mistakes
    and to apply personalization in ways that are not helpful to the user (or are
    even frustrating and counterproductive), so it’s usually better to err on the
    side of caution and ensure that personalization is only applied when it is likely
    to be helpful. One simple way to do this is to only apply personalization within
    similar categories as the query. This is one way of applying *guardrails* to personalization,
    and it is a very effective way to avoid applying personalization in ways that
    are likely to be unhelpful to the user.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 应该轻触应用个性化。很容易出错，并以对用户无益（甚至可能令人沮丧和适得其反）的方式应用个性化，因此通常最好谨慎行事，并确保只有在可能有益的情况下才应用个性化。一种简单的方法是在与查询相似的类别内应用个性化。这是应用*护栏*的一种方式，并且是一种非常有效的方法，可以避免以可能对用户无益的方式应用个性化。
- en: While your data may or may not have an explicit category field to filter on,
    it’s also possible to dynamically generate categories by clustering items together
    based on their similarity. This can be done by taking the embeddings for all items
    and clustering them to dynamically create a data-driven set of categories. The
    following listing demonstrates a simple method for generating clusters of items
    from their embeddings.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你的数据可能或可能没有明确的类别字段用于过滤，但也可以通过根据它们的相似性将项目聚在一起来动态生成类别。这可以通过对所有项目的嵌入进行聚类来实现，以动态创建一个数据驱动的类别集。以下列表演示了从项目的嵌入中生成簇的简单方法。
- en: Listing 9.13 Generating dynamic categories from clustered products
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.13 从聚类产品生成动态类别
- en: '[PRE15]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#1 Generates 100 clusters using a KMeans clustering algorithm'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用KMeans聚类算法生成100个簇'
- en: '#2 Assigns each product name to its corresponding cluster label'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将每个产品名称分配给其对应的簇标签'
- en: To ensure that our clustering worked well, we can inspect the top words in each
    cluster to ensure they are related and form a coherent category. Listing 9.14
    demonstrates code to identify the top words in each cluster and to generate a
    2D visualization of the clusters using principal component analysis (PCA) to map
    the 768-dimension embeddings down to two dimensions for visualization purposes.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们的聚类效果良好，我们可以检查每个簇中的顶级单词，以确保它们相关并形成一个连贯的类别。列表9.14展示了识别每个簇中的顶级单词并使用主成分分析（PCA）将768维嵌入映射到二维以进行可视化的代码。
- en: Listing 9.14 Inspecting popular terms from each product cluster
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.14 检查每个产品簇中的流行术语
- en: '[PRE16]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '#1 Performs PCA to reduce embeddings down to two dimensions for visualization'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 执行PCA将嵌入降低到二维以进行可视化'
- en: '#2 Loops through each cluster and plots it on the graph'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 遍历每个簇并在图上绘制它'
- en: '#3 The top words function gets the most common words from a cluster.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 顶级单词函数从簇中获取最常见的单词。'
- en: '#4 Adds a text label for each cluster with the cluster ID and top-N words in
    each cluster'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 为每个簇添加一个文本标签，包括簇ID和每个簇中的顶级-N个单词'
- en: '#5 Display improvement: adjusts the text labels to minimize overlap'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 显示改进：调整文本标签以最小化重叠'
- en: Figure 9.15 shows the output of listing 9.14\. Each dot represents a cluster,
    with the text label for each cluster including the cluster ID and the top words
    in that cluster.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.15显示了列表9.14的输出。每个点代表一个簇，每个簇的文本标签包括簇ID和该簇中的顶级单词。
- en: While figure 9.15 may appear chaotic, representing all 100 clusters into which
    our nearly 50,000 products are categorized, you can see clear patterns in the
    semantic space. The top left of the graph contains kitchen appliances, and music
    tends to be at the top right of the remaining populated area of the graph (CDs
    in the top right, musical instruments and speakers in the top middle), and items
    related to video and data storage tend to be at the bottom of the graph (DVDs
    and Blu-ray at the bottom right, home theaters and cameras in the bottom middle,
    computer memory cards and storage in the bottom left along with other computer
    peripherals). Feel free to inspect the various categories and relationships between
    the clusters, but realize that they have been mapped down from 768 dimensions
    into 2 dimensions, so much of the richness represented by the KMeans clustering
    algorithm will be lost in the visualization.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然图 9.15 可能看起来很混乱，它代表了我们的近 50,000 个产品被分类到其中的 100 个簇，但在语义空间中你可以看到清晰的模式。图的左上角包含厨房电器，音乐倾向于位于图的右上角剩余的已填充区域（右上角是
    CD，右上中间是乐器和扬声器），与视频和数据存储相关的项目倾向于位于图的底部（右下角是 DVD 和蓝光，右下中间是家庭影院和相机，左下角是计算机内存卡和存储，以及其他计算机外围设备）。请随意检查各种类别和簇之间的关系，但请意识到它们已经被从
    768 维映射到 2 维，因此 KMeans 聚类算法所表示的丰富性在可视化中会丢失很多。
- en: '![figure](../Images/CH09_F15_Grainger.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH09_F15_Grainger.png)'
- en: Figure 9.15 Clusters generated by KMeans clustering of all product embeddings,
    to be used for categorizing all queries and products
  id: totrans-237
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.15 由 KMeans 聚类生成的所有产品嵌入簇，用于对查询和产品进行分类
- en: 'Now that we have clusters available to categorize products (and signals corresponding
    to interacted-with products), we need to ensure that we can map queries into the
    correct clusters. There are multiple ways to do this:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了可用于分类产品的簇（以及与交互过的产品对应的信号），我们需要确保我们可以将查询映射到正确的簇中。有多种方法可以实现这一点：
- en: '*Model-driven*—Just pass the query through the LLM, and use the resulting embedding
    vector to find the closest categories.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型驱动*—只需将查询通过LLM，并使用生成的嵌入向量来找到最近的类别。'
- en: '*Behavior-driven*—Use query signals and corresponding interaction signals (such
    as clicks) to determine the most likely categories for popular queries.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*行为驱动*—使用查询信号和相应的交互信号（如点击）来确定热门查询最可能的类别。'
- en: '*Content-driven*—Run a keyword or semantic search, and find the top categories
    in the results.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*内容驱动*—运行关键词或语义搜索，并在结果中找到顶级类别。'
- en: '*Hybrid*—Use any combination of these approaches.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*混合*—使用这些方法的任意组合。'
- en: The behavior-driven approach follows the signals-boosting methodology from chapter
    8, but it aggregates by the categories associated with the top boosted documents
    instead of by queries. The content-driven approach enables you to use the other
    semantic search techniques explored in chapters 5–7\. For simplicity, we’ll use
    the model-driven approach here and give deference to the LLM to determine the
    meaning of the query. The following listing demonstrates three different approaches
    for deriving the top categories for a query based on the embedding vectors.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 行为驱动的方法遵循第 8 章中提到的信号增强方法，但它通过与顶级增强文档相关的类别进行聚合，而不是通过查询。内容驱动的方法使您能够使用第 5-7 章中探索的其他语义搜索技术。为了简单起见，我们将在这里使用模型驱动的方法，并让大型语言模型（LLM）来确定查询的含义。以下列表展示了三种不同的方法，用于根据嵌入向量推导查询的顶级类别。
- en: Listing 9.15 Comparing techniques for mapping queries to clusters
  id: totrans-244
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.15 比较将查询映射到簇的技术
- en: '[PRE17]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#1 Gets the top N clusters based on cosine similarity with the cluster centroids'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 基于与簇质心的余弦相似度获取顶级 N 个簇'
- en: '#2 Gets the cluster based on the KMeans model’s prediction'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 基于KMeans模型的预测获取簇'
- en: '#3 Option 1: Predicts the nearest cluster (KMeans)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 选项 1：预测最近的簇（KMeans）'
- en: '#4 Option 2: Finds the most-similar cluster (cosine similarity)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 选项 2：找到最相似的簇（余弦相似度）'
- en: '#5 Option 3 (recommended): Finds N-most-similar clusters (cosine similarity)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 选项 3（推荐）：找到 N 个最相似的簇（余弦相似度）'
- en: 'Output:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE18]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'In listing 9.15, we see three predictions being calculated: nearest cluster
    (K-means), most-similar cluster (cosine similarity), and the *N*-most-similar
    clusters (cosine similarity). The `get_top_labels_centers` function calculates
    the top *N* clusters based on the cosine similarity with the cluster centroids.
    The clustering function `get_query_ cluster` calculates a cluster based on a K-means
    prediction.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表9.15中，我们看到计算了三个预测：最近簇（K-means）、最相似簇（余弦相似度）和*N*个最相似簇（余弦相似度）。`get_top_labels_centers`函数根据与簇质心的余弦相似度计算前*N*个簇。聚类函数`get_query_cluster`根据K-means预测计算一个簇。
- en: The output from these three approaches demonstrates an important point. While
    the query is for `microwave`, we know that the categories were generated dynamically
    and may have overlap between products. The K-means model and cosine similarity
    approaches both choose category `44` `(Microwave_Cu._Ft._Stainless-Steel_Oven)`
    in this example. While you’re likely to find better results by relying on the
    cosine similarity to measure semantic similarity versus the K-means prediction,
    the categories returned from each are likely to be closely related. Thus, any
    personalization would benefit by being applied *across* each of the relevant categories
    instead of only one. Products can be split across multiple, related categories,
    and meaningful categories can be arbitrarily split based upon the number of items
    and nuances of the item descriptions.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这三种方法输出的结果展示了一个重要的观点。虽然查询是针对`微波`，但我们知道类别是动态生成的，产品之间可能存在重叠。K-means模型和余弦相似度方法在这个例子中都选择了类别`44`（`Microwave_Cu._Ft._Stainless-Steel_Oven`）。虽然依靠余弦相似度来衡量语义相似度比K-means预测可能找到更好的结果，但每个返回的类别可能都密切相关。因此，任何个性化都应该应用于相关的每个类别，而不仅仅是其中一个。产品可以分布在多个相关类别中，并且可以根据物品数量和描述的细微差别任意划分有意义的类别。
- en: 'To overcome the overlaps between similar categories, we recommend using the
    top-*N* cosine predicted clusters (Knn, option 3) instead of filtering to a single
    cluster. In the results from listing 9.15, this miscellaneous approach returns
    five related categories: `44` (“microwaves”), `52` (“stoves”), `5` (“miscellaneous
    appliances”), `83` (“counter appliances”), and `33` (“ovens”).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服相似类别之间的重叠，我们建议使用前*N*个余弦预测簇（Knn，选项3）而不是过滤到单个簇。在列表9.15的结果中，这种混合方法返回了五个相关类别：`44`（“微波炉”）、`52`（“炉灶”）、`5`（“杂项电器”）、`83`（“柜台电器”）和`33`（“烤箱”）。
- en: We’ll next use these predicted categories, along with the embeddings from a
    user’s previous interactions, to personalize search results.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用这些预测类别，以及用户之前交互的嵌入，来个性化搜索结果。
- en: 9.4.3 Integrating embedding-based personalization into search results
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.3 将基于嵌入的个性化集成到搜索结果中
- en: 'The final step in our personalization journey is to execute the personalized
    search. We could accomplish this in many different ways:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们个性化旅程的最终一步是执行个性化搜索。我们可以用许多不同的方式来完成这项任务：
- en: Perform a weighted average between the query vector (embedding for `microwave`)
    and the vectors for the user’s previous interactions within the predicted clusters.
    This would generate a single vector representing a personalized version of the
    user’s query, so all results would be personalized.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在预测的簇中，对查询向量（`微波`的嵌入）和用户之前交互的向量进行加权平均。这将生成一个代表用户个性化查询的单个向量，因此所有结果都将个性化。
- en: Perform a standard search, but then boost the results based on the average of
    the embeddings from a user’s previous interactions within the predicted clusters.
    This would be a hybrid keyword- and vector-based ranking function, where the keyword
    search would be the primary driver of the results, but the user’s previous interactions
    would be used to boost related results higher.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行标准搜索，但然后根据用户在预测簇中之前交互的嵌入的平均值来提升结果。这将是一个混合关键字和基于向量的排名函数，其中关键字搜索将是结果的主要驱动因素，但用户的先前交互将用于提升相关结果。
- en: Do one of the above, but then only personalize a few items in the search results
    instead of all the results. This follows a light-touch mentality so as not to
    disturb all of the user’s search results, while still injecting novelty to enable
    the user to discover personalized items they may not have otherwise found.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 做上述之一，但然后在搜索结果中只个性化几个项目，而不是所有结果。这遵循轻触心态，以免打扰所有用户的搜索结果，同时仍然注入新颖性，使用户能够发现他们可能否则找不到的个性化项目。
- en: Perform a standard search (keyword or vector), but then rerank the results based
    on the weighted average between the query vector and the vectors for the user’s
    previous interactions within the predicted clusters. This uses the original search
    to find the candidate results using the default relevance algorithm, but those
    results are reranked to boost personalized preferences higher.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行标准搜索（关键字或向量），但随后根据查询向量和用户在预测簇内先前交互的向量之间的加权平均重新排序结果。这使用原始搜索通过默认的相关性算法找到候选结果，但这些结果被重新排序以提升个性化的偏好。
- en: We’ll demonstrate the last technique, as it is easy to replicate across any
    search engine, since the personalization/reranking pass can be done as a final
    step after the original search. This technique will thus work well with both traditional
    search engines and vector databases.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示最后一种技术，因为它很容易在任何搜索引擎中复制，因为个性化/重新排序步骤可以在原始搜索之后作为一个最终步骤来完成。因此，这项技术将很好地与传统的搜索引擎和向量数据库一起工作。
- en: 'Listing 9.16 demonstrates the two key functions we’ll use to generate our personalization
    vector: a `get_user_embeddings` function that looks up the embeddings for a list
    of products and also returns the cluster associated with each product, and a `get_personalization_vector`
    function that can combine embeddings between a query and all relevant user-item
    interaction vectors.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.16 展示了我们用于生成个性化向量的两个关键函数：一个 `get_user_embeddings` 函数，该函数查找产品列表的嵌入并返回每个产品的关联簇，以及一个
    `get_personalization_vector` 函数，该函数可以结合查询和所有相关用户-项目交互向量之间的嵌入。
- en: Listing 9.16 Functions for generating personalization vectors
  id: totrans-265
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.16 生成个性化向量的函数
- en: '[PRE19]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '#1 Returns a dataframe with the embedding and guardrail cluster for each product'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 返回一个包含每个产品的嵌入和护栏簇的数据框'
- en: '#2 Returns a vector that combines (weighted average) an embedding for the query
    with the embeddings for the passed-in user_items'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 返回一个向量，该向量结合了（加权平均）查询的嵌入和传递的用户_items 的嵌入'
- en: '#3 You can optionally specify a query_weight and user_item_ weights to influence
    how much each embedding influences the personalization vector.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 可以可选地指定查询权重和用户_item 权重以影响每个嵌入对个性化向量的影响程度。'
- en: '#4 By default, the weight is split 1:1 (50% each) between the query embedding
    and the user_items_weight.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 默认情况下，权重在查询嵌入和用户_items 权重之间平分（各占50%）。'
- en: With the ability to combine embeddings and to look up the guardrail cluster
    for any product, it’s time to generate a personalization vector for a user based
    on their incoming query and past product interactions. We’ll generate a personalization
    vector with guardrails as well as one without guardrails to compare the results
    side by side.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在能够组合嵌入并查找任何产品的护栏簇之后，我们现在可以根据用户的查询和过去的产品交互生成一个个性化向量。我们将生成带有护栏和无护栏的个性化向量以比较结果。
- en: 'Listing 9.17 demonstrates how to generate personalization vectors. In this
    case, the user has previously interacted with two products: a Hello Kitty water
    bottle and a stainless-steel electric range. They are now running a new query
    for the keyword `microwave`.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.17 展示了如何生成个性化向量。在这种情况下，用户之前与两个产品进行了交互：一个Hello Kitty水壶和一个不锈钢电炉。他们现在正在运行一个新的以关键字
    `microwave` 为查询的查询。
- en: Listing 9.17 Generating personalization vectors from user queries
  id: totrans-273
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.17 从用户查询生成个性化向量
- en: '[PRE20]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#1 Personalization vector with no guardrails (uses query and all past item
    interactions)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 无护栏的个性化向量（使用查询和所有过去的项目交互）'
- en: '#2 Gets the top 5 clusters for the query to use as guardrails'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 获取查询的前5个簇作为护栏使用'
- en: '#3 Filters down to only items in the guardrail query clusters'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 过滤到仅包含护栏查询簇中的项目'
- en: '#4 Generates a personalization vector with guardrails (uses query and only
    items related to the query)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 生成带有护栏的个性化向量（使用查询和仅与查询相关的项目）'
- en: 'Output:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE21]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Listing 9.17 performs a four-step process for generating a personalization
    vector for a user’s query:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.17 对用户查询生成个性化向量执行了四个步骤的过程：
- en: Get the list of product interactions, along with the associated product embeddings
    and clusters.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取产品交互列表，以及相关的产品嵌入和簇。
- en: Find the *N* (5 in this case) most similar clusters for the query.
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到查询最相似的 *N*（本例中为5）个簇。
- en: Filter the list of user interactions down to only items in the query clusters.
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将用户交互列表过滤到仅包含查询簇中的项目。
- en: 'Generate the personalization vector (`filtered_personalization_vector`) by
    combining the query and filtered user-item interaction vectors. (Note: we also
    generated an `unfiltered_personalization_vector` that does not apply categorical
    guardrails, for later side-by-side comparison.)'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过组合查询和过滤的用户-项目交互向量生成个性化向量（`filtered_personalization_vector`）。（注意：我们还生成了一个`unfiltered_personalization_vector`，它不应用分类保护措施，以便稍后进行对比。）
- en: The final `filtered_personalization_vector` could be used directly for a vector
    search across embeddings, as it represents an embedding for the query that has
    been pulled toward the user’s interests in the 768-dimension embedding vector
    space. In our case, we are going to run an independent search for the query instead,
    and then use the `filtered_personalization_vector` to rerank the top results.
    The following listing demonstrates this search and reranking process.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的`filtered_personalization_vector`可以直接用于在嵌入中进行向量搜索，因为它代表了一个在768维嵌入向量空间中将查询拉向用户兴趣的嵌入。在我们的案例中，我们打算对查询进行独立搜索，然后使用`filtered_personalization_vector`来重新排序顶级结果。以下列表展示了这个搜索和重新排序的过程。
- en: Listing 9.18 Using the personalization vector to rerank results
  id: totrans-287
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.18 使用个性化向量重新排序结果
- en: '[PRE22]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '#1 Reranks all search results based upon cosine similarity to the personalized
    query vector'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 根据与个性化查询向量的余弦相似度重新排序所有搜索结果'
- en: '#2 Displays the original search results (no personalization)'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 显示原始搜索结果（无个性化）'
- en: '#3 Personalized search with no guardrails (uses unfiltered_personalization_vector)'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 无保护措施的个性化搜索（使用unfiltered_personalization_vector）'
- en: '#4 Personalized search with guardrails (uses filtered_personalization_vector)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 带有保护措施的个性化搜索（使用filtered_personalization_vector）'
- en: 'Listing 9.18 walks through the entire process of applying personalization vectors
    to rerank the search results. The `rerank_with_personalization` function takes
    the original search results and a personalization vector and then reranks the
    search results based on the cosine similarity between the personalization vector
    and the embedding vectors for each search result. We invoke reranking twice for
    comparison purposes: once with and once without guardrails applied to the personalization
    vector. The final sets of ranked results are each passed to the `display_product_search`
    function to render the three result sets compared in figure 9.16: the non-personalized
    search results, personalized search results with no guardrails, and personalized
    search results with guardrails.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.18展示了将个性化向量应用于重新排序搜索结果的全过程。`rerank_with_personalization`函数接收原始搜索结果和个性化向量，然后根据个性化向量与每个搜索结果嵌入向量之间的余弦相似度重新排序搜索结果。为了比较，我们进行了两次重新排序：一次是在应用了保护措施的情况下，另一次则没有。最终的排序结果集分别传递给`display_product_search`函数以渲染图9.16中比较的三个结果集：未个性化搜索结果、无保护措施的个性化搜索结果以及带有保护措施的个性化搜索结果。
- en: '![figure](../Images/CH09_F16_Grainger.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH09_F16_Grainger.png)'
- en: Figure 9.16 Comparing non-personalized, always personalized (no guardrails),
    and contextually personalized (with guardrails) search results
  id: totrans-295
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.16 比较非个性化、始终个性化（无保护措施）和上下文个性化（有保护措施）的搜索结果
- en: On the left, we see the original search results for `microwave`, including a
    microwave cover, some stainless-steel microwaves, and a basic microwave. In the
    middle, we see personalized search results with no categorical guardrails. The
    user’s personalization vector includes embeddings for a stainless-steel microwave,
    as well as a Hello Kitty water bottle. As you can see, the Hello Kitty microwave
    jumped straight to the top of the results, even though the user has previously
    looked at a stainless-steel refrigerator, and their interest in a water bottle
    is unlikely to translate into an interest in a Hello Kitty microwave. On the right,
    we see personalization with guardrails applied. We see that all of these results
    are now for stainless-steel microwaves, reflecting the user’s previous interest
    in a stainless-steel refrigerator, which was automatically identified as a similar
    category.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧，我们看到`microwave`的原始搜索结果，包括微波炉盖、一些不锈钢微波炉和一个基本的微波炉。在中间，我们看到无分类保护措施的个性化搜索结果。用户的个性化向量包括不锈钢微波炉和Hello
    Kitty水瓶的嵌入。正如您所看到的，Hello Kitty微波炉直接跳到了结果的最顶部，尽管用户之前查看过不锈钢冰箱，而且他们对水瓶的兴趣不太可能转化为对Hello
    Kitty微波炉的兴趣。在右侧，我们看到应用了保护措施的个性化。我们看到所有这些结果现在都是不锈钢微波炉，反映了用户之前对不锈钢冰箱的兴趣，这被自动识别为相似类别。
- en: You have now implemented an end-to-end personalized search algorithm. Personalized
    search can significantly improve relevance when implemented carefully and with
    a light touch, but it is important to not frustrate your users by over-personalizing.
    In the next section, we’ll review some of the pitfalls and challenges with personalization
    that you’ll need to keep in mind to avoid potential user frustration.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已经实现了一个端到端的个性化搜索算法。如果谨慎且轻柔地实施，个性化搜索可以显著提高相关性，但重要的是不要通过过度个性化来令用户沮丧。在下一节中，我们将回顾一些需要记住的个性化陷阱和挑战，以避免潜在的用户沮丧。
- en: 9.5 Challenges with personalizing search results
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.5 个性化搜索结果的挑战
- en: 'Throughout this chapter, we’ve highlighted many of the challenges with personalizing
    search results. While personalization can be a powerful tool for driving more
    relevant search results, it is important to be aware of the potential pitfalls
    and to ensure that personalization is only applied when it is likely to be helpful
    to the user. We touched on the following key challenges in this chapter:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们强调了个性化搜索结果所面临的许多挑战。虽然个性化可以是一个强大的工具，用于推动更相关的搜索结果，但了解潜在的陷阱并确保仅在可能对用户有帮助时应用个性化是很重要的。在本章中，我们简要讨论了以下关键挑战：
- en: '*The cold-start problem*—When using collaborative filtering, users who have
    interacted with no items lack any information on which to base personalization.
    For such users, it’s important to fall back to non-personalized search results.
    Combining a content-based filtering approach (search or attribute-based matching)
    with collaborative filtering can help overcome the cold-start problem.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*冷启动问题*—在使用协同过滤时，未与任何物品互动的用户缺乏任何基于个性化所需的信息。对于这类用户，退回到非个性化搜索结果是重要的。将基于内容的过滤方法（搜索或基于属性的匹配）与协同过滤相结合可以帮助克服冷启动问题。'
- en: '*Guardrails are important*—Applying personalization across categorical boundaries
    is generally a bad idea. Otherwise, as a user switches context to look at unrelated
    items, search results are going to look strange and be counterproductive. Looking
    at “white paper” or “white light bulbs” doesn’t mean a user wants to later see
    “white” refrigerators when searching for appliances. Similarly, liking the movie
    *The Terminator* doesn’t mean someone wants to purchase a gun or a robot vacuum.
    When personalizing search results, it is important to understand the relevant
    scope in which learned user preferences should be applied. Modeling related categories
    for items and queries and restricting personalization to only using items related
    to the query is a good way to avoid these problems.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*边界限制很重要*—在类别边界上应用个性化通常是一个坏主意。否则，当用户切换上下文查看不相关的物品时，搜索结果看起来会很奇怪，并且会适得其反。查看“白皮书”或“白灯泡”并不意味着用户在搜索家电时想要看到“白色”冰箱。同样，喜欢电影《终结者》并不意味着某人想要购买枪支或机器人吸尘器。在个性化搜索结果时，了解相关范围，在这个范围内应该应用学习到的用户偏好，是很重要的。为物品和查询建模相关类别，并将个性化限制为仅使用与查询相关的物品，是避免这些问题的良好方法。'
- en: '*Over-personalization is frustrating*—When someone types in a search query,
    they expect the search engine to return the most relevant results for their specific
    query. While applying personalization can be very helpful in certain use cases
    (e.g., location personalization in a restaurant), it can also be very frustrating
    if the amount of personalization interferes with the user’s control over the search
    experience. As an extreme case, imagine if every query were boosted by features
    from every previous query or item interaction; the search experience would quickly
    degrade into an unusable mess that would prevent the user from finding what they’re
    looking for. Consider only personalizing a few of the top results instead of the
    entire set of search results so that if the personalization is ever wrong, the
    non-personalized results are still available. Also, consider providing a way for
    users to turn off personalization if they find it frustrating.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*过度个性化令人沮丧*—当某人输入一个搜索查询时，他们期望搜索引擎返回与他们的特定查询最相关的结果。虽然个性化在某些用例中（例如，在餐厅中的位置个性化）可能非常有帮助，但如果个性化的程度干扰了用户的搜索体验控制，它也可能非常令人沮丧。作为一个极端案例，想象一下，如果每个查询都由每个先前查询或物品交互的特征所增强；搜索体验将迅速退化成一个无法使用的混乱，这将阻止用户找到他们想要的东西。考虑只对前几个结果进行个性化，而不是整个搜索结果集，这样如果个性化出错，非个性化的结果仍然可用。此外，考虑为用户提供一种关闭个性化功能的方法，如果他们觉得这令人沮丧。'
- en: '*Feedback loops are critical*—User interests change over time. Whether you’re
    showing recommendations or building personalization profiles for search, users
    need to be able to provide feedback to the system to help it learn and adapt to
    their changing interests. This can be done by allowing users to provide explicit
    feedback (e.g., thumbs up or thumbs down) on recommendations, or by just continuing
    to collect implicit feedback from behavioral signals (clicks, purchases, and so
    on) and using newer interactions to update the personalization profile. In either
    case, it is important to provide a way for users to provide feedback to the system
    so that it can learn and adapt to their changing interests over time.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*反馈循环至关重要*——用户兴趣会随时间变化。无论你是展示推荐内容还是为搜索构建个性化配置文件，用户都需要能够向系统提供反馈，以帮助系统学习和适应他们不断变化的需求。这可以通过允许用户对推荐内容提供明确的反馈（例如，点赞或踩）来实现，或者通过持续收集来自行为信号（点击、购买等）的隐式反馈，并使用新的交互来更新个性化配置文件。在两种情况下，提供一种让用户向系统提供反馈的方式都至关重要，这样系统才能随着时间的推移学习和适应用户不断变化的需求。'
- en: '*Privacy can be a concern*—Because personalization is based on previous user-interaction
    patterns, showing personalized recommendations and search results means collecting
    and exposing a user’s past behavior. Imagine a movie-streaming service suggesting
    violent or adult-themed movies, a bookstore suggesting romance novels or self-improvement
    titles, or a grocery store boosting junk food and alcohol. This could both be
    embarrassing and demoralizing for the user, eroding both trust and confidence
    in the service. It is important to be transparent about what signals are being
    collected and how they are being used. It is also important to provide a way for
    users to opt out of personalization if they are concerned about their privacy.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*隐私可能成为问题*——因为个性化基于之前的用户交互模式，展示个性化推荐和搜索结果意味着收集和暴露用户的过去行为。想象一下，一个电影流媒体服务推荐暴力或成人主题的电影，一家书店推荐浪漫小说或自我提升的书籍，或者一家杂货店推广垃圾食品和酒精。这可能会让用户感到尴尬和沮丧，损害对服务的信任和信心。重要的是要透明地说明正在收集哪些信号以及如何使用它们。同样重要的是，如果用户对隐私问题感到担忧，应提供一种让他们退出个性化服务的方式。'
- en: '*Apply personalization with a light touch*—Most search engines do not personalize
    search results, leaving the user in full control of expressing their interests
    through their current query. Deviating from this paradigm can be beneficial in
    many cases, but it is important to ensure that personalization is only applied
    when it is likely to be helpful to the user. One strategy for ensuring a light
    touch is to apply personalization only to the top few results. It is usually better
    to err on the side of caution with personalization and apply it very conservatively.
    Most users will be less frustrated by a lack of personalization than by a search
    engine that tries too hard to read their minds and gets it wrong.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*轻触式应用个性化*——大多数搜索引擎不个性化搜索结果，让用户完全控制通过当前查询表达他们的兴趣。偏离这种范式在很多情况下可能有益，但重要的是要确保只有在可能对用户有帮助的情况下才应用个性化。确保轻触式应用的一种策略是仅对前几个结果应用个性化。在个性化方面，通常更谨慎地应用它，非常保守地应用。大多数用户对缺乏个性化不如对试图过度解读他们的想法并出错搜索引擎感到沮丧。'
- en: Out of all the techniques in AI-powered search, personalization is both one
    of the most underutilized ways to better understand user intent and one of the
    most challenging. While recommendation engines are prevalent, the personalization
    spectrum between search and recommendations is more nuanced and less explored.
    So long as personalized search is implemented with care, it can be a powerful
    tool to drive more relevant search results and save the user time discovering
    the items that best meet their particular interests.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有基于人工智能的搜索技术中，个性化既是理解用户意图最未被充分利用的方法之一，也是最具挑战性的方法之一。虽然推荐引擎很普遍，但搜索和推荐之间的个性化范围更加微妙且探索较少。只要个性化搜索得到妥善实施，它就可以成为一个强大的工具，推动更相关的搜索结果，并节省用户发现最符合他们特定兴趣的项目的时间。
- en: Summary
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Personalized search sits in the middle of the personalization spectrum between
    keyword search (driven by explicit user input) and collaborative recommendations
    (driven by implicit input derived from user behavior).
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个性化搜索位于个性化范围的中部，介于关键字搜索（由显式用户输入驱动）和基于用户行为的协同推荐（由隐式输入驱动）之间。
- en: Collaborative recommendations can be learned entirely from user-interaction
    patterns across documents, but they suffer from the cold-start problem. Combining
    collaborative filtering with content-based attributes can overcome the cold-start
    problem and drive more flexible personalized search experiences.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过文档间的用户交互模式学习协同推荐，但它们存在冷启动问题。将协同过滤与基于内容的属性相结合可以克服冷启动问题，并驱动更灵活的个性化搜索体验。
- en: Representing documents and users as embedding vectors enables building dynamic
    personalization profiles that can be used to drive better-personalized search
    results.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将文档和用户表示为嵌入向量，可以构建动态的个性化配置文件，这些配置文件可用于驱动更好的个性化搜索结果。
- en: Clustering products by their embedding vectors can be used to generate dynamic
    categories to serve as guardrails for personalized search, ensuring that users
    are not shown results that are personalized too far outside of their interests.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过嵌入向量对产品进行聚类，可以生成动态类别，作为个性化搜索的护栏，确保用户不会看到与其兴趣相差太远的个性化结果。
- en: Incorporating feedback loops to learn from user interactions is important, as
    long as user privacy is preserved and it is applied with a light touch to avoid
    over-personalizing.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将反馈循环纳入以从用户互动中学习是很重要的，只要保护用户隐私，并且轻柔地应用以避免过度个性化。
- en: Personalized search can drive more relevant search results, but it’s important
    to balance the benefits of personalization with the potential for user frustration
    if the personalization is too aggressive. Striking the right balance can drive
    significant improvements to your search engine’s understanding of user intent.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个性化搜索可以驱动更相关的搜索结果，但重要的是要在个性化的好处与用户因个性化过于激进而可能产生的挫败感之间取得平衡。找到正确的平衡点可以显著提高搜索引擎对用户意图的理解。
