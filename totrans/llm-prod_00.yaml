- en: '1 *Words’ awakening: Why large language models have captured attention*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 *词汇的觉醒：为什么大型语言模型引起了关注*
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: What large language models are and what they can and cannot do
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言模型是什么，它们能做什么，不能做什么
- en: When you should and should not deploy your own large language models
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该在何时何时不部署自己的大型语言模型
- en: Large language model myths and the truths that lie behind them
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言模型的神话及其背后的真相
- en: Any sufficiently advanced technology is indistinguishable from magic.—Arthur
    C. Clarke
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 任何足够先进的技术都与魔法无法区分 —— 亚瑟·C·克拉克
- en: The year is 1450\. A sleepy corner of Mainz, Germany, unknowingly stands on
    the precipice of a monumental era. In Humbrechthof, a nondescript workshop shrouded
    in the town’s shadows pulsates with anticipation. It is here that Johannes Gutenberg,
    a goldsmith and innovator, sweats and labors amidst the scents of oil, metal,
    and determination, silently birthing a revolution. In the late hours of the night,
    the peace is broken intermittently by the rhythmic hammering of metal on metal.
    In the lamp-lit heart of the workshop stands Gutenberg’s decade-long labor of
    love—a contraption unparalleled in design and purpose.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 年份是1450年。德国美因茨的一个沉睡的角落，不知不觉地站在一个重大时代的边缘。在Humbrechthof，一个被城镇阴影笼罩的普通车间，充满了期待。正是在这里，约翰内斯·古腾堡，一位金匠和革新者，在油、金属和决心的气味中汗流浃背地劳作，默默地孕育着一场革命。在深夜时分，金属敲击金属的节奏性敲打不时打破宁静。在车间灯光照耀的中心，是古腾堡十年来的爱情结晶——一个设计独特、用途非凡的装置。
- en: This is no ordinary invention. Craftsmanship and creativity transform an assortment
    of moveable metal types, individually cast characters born painstakingly into
    a matrix. The flickering light dances off the metallic insignias. The air pulsates
    with the anticipation of a breakthrough and the heady sweetness of oil-based ink,
    an innovation from Gutenberg himself. In the stillness of the moment, the master
    printer squares his shoulders and, with unparalleled finesse, lays down a crisp
    sheet of parchment beneath the ink-loaded matrix, allowing his invention to press
    firmly and stamp fine print onto the page. The room adjusts to the symphony of
    silence, bated breaths hanging heavily in the air. As the press is lifted, it
    creaks under its own weight, each screech akin to a war cry announcing an exciting
    new world.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一项普通发明。工艺和创造力将各种可移动金属字型、一个个辛苦铸成的字符，组合成一个矩阵。闪烁的灯光在金属标志上舞动。空气中充满了突破的期待和基于油墨的浓郁甜味，这是古腾堡本人的创新。在那一刻的宁静中，这位大师印刷师挺直了肩膀，以无与伦比的技巧，在墨水充盈的矩阵下铺下一张清晰的羊皮纸，让他的发明紧紧压印，在页面上留下精细的印刷。房间调整到了沉默的交响乐，紧张的呼吸在空气中沉重地悬挂。当印刷机被抬起时，它因自身的重量而嘎吱作响，每一次尖叫都像是一声战斗的呐喊，宣布着一个激动人心的新世界的到来。
- en: With a flurry of motion, Gutenberg pulls from the press the first printed page
    and slams it flat onto the wooden table. He carefully examines each character,
    all of which are as bold and magnificent as the creator’s vision. The room drinks
    in the sight, absolutely spellbound. A mere sheet of parchment has become a testament
    to transformation. As the night gives way to day, he looks upon his workshop with
    invigorated pride. His legacy is born, echoing in the annals of history and forever
    changing the way information would take wings. Johannes Gutenberg, now the man
    of the millennium, emerges from the shadows, an inventor who dared to dream. His
    name is synonymous with the printing press, which is not just a groundbreaking
    invention but the catalyst of the modern world.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 古腾堡以一阵动作，从印刷机中取出第一张印刷页，并将其平铺在木桌上。他仔细检查每一个字符，它们都像创造者的愿景一样大胆而宏伟。房间中的每个人都沉浸在这景象中，完全被迷住了。一张普通的羊皮纸已成为变革的见证。当夜晚让位于白天时，他带着振奋的骄傲看着他的车间。他的遗产诞生了，在历史的长河中回响，永远改变了信息飞翔的方式。约翰内斯·古腾堡，现在成为千禧年的人物，从阴影中走出，一个敢于梦想的发明家。他的名字与印刷机同义，这不仅是一项开创性的发明，而且是现代世界的催化剂。
- en: As news of Gutenberg’s achievement begins to flutter across the continent, scholars
    from vast disciplines are yet to appreciate the extraordinary tool at their disposal.
    Knowledge and learning, once coveted treasures, are now within the reach of the
    common person. There were varied and mixed opinions surrounding that newfound
    access.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当古腾堡的成就的消息开始在大陆上飘扬时，来自各个学科的学者们还没有意识到他们手中的这个非凡工具。知识和学习，曾经是渴望的宝藏，现在对普通人来说触手可及。围绕这一新发现，意见各异，看法不一。
- en: In our time, thanks to the talent and industry of those from the Rhine, books
    have emerged in lavish numbers. A book that once would’ve belonged only to the
    rich—nay, to a king—can now be seen under a modest roof. … There is nothing nowadays
    that our children … fail to know.—Sebastian Brant
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在我们这个时代，多亏了莱茵河畔那些人的才能和勤奋，书籍的数量激增。曾经只有富人——不，只有国王才能拥有的书，现在可以在简陋的屋顶下看到。……如今，我们的孩子……似乎无所不知。——塞巴斯蒂安·布兰特
- en: Scholarly effort is in decline everywhere as never before. Indeed, cleverness
    is shunned at home and abroad. What does reading offer to pupils except tears?
    It is rare, worthless when it is offered for sale, and devoid of wit.—Egbert of
    Liege
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 学术努力在各个地方都在下降，前所未有。的确，聪明才智在国内和国外都被摒弃。阅读能为学生带来什么，除了泪水？当它被出售时，是罕见的、无价值的，而且缺乏智慧。——列日的大卫
- en: People have had various opinions on books throughout history. One thing we can
    agree on living in a time when virtual printing presses exist and books are ubiquitous
    is that the printing press changed history. While we weren’t actually there when
    Gutenberg printed the first page using his printing press, we have watched many
    play with large language models (LLMs) for the first time. The astonishment on
    their faces as they see it respond to their first prompt. Their excitement when
    challenging it with a difficult question only to see it respond as if it was an
    expert in the field—the light bulb moment when they realize they can use this
    to simplify their life or make themselves wealthy. We imagine this wave of emotions
    is but a fraction of that felt by Johannes Gutenberg. Being able to rapidly generate
    text and accelerate communication has always been valuable.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人们对于书籍的看法在历史上一直各不相同。在我们这样一个虚拟印刷机存在且书籍无处不在的时代，我们可以达成共识的是，印刷机改变了历史。虽然我们并没有亲眼目睹古腾堡使用他的印刷机打印出第一页，但我们见证了很多人第一次与大型语言模型（LLMs）互动。当他们看到它对他们的第一个提示做出反应时，脸上的惊讶。当他们用难题挑战它，却看到它像该领域的专家一样回应时，他们的兴奋——当他们意识到他们可以用它来简化自己的生活或让自己变得富有时，这就是灵光一闪的时刻。我们想象这种情绪的波涛只是约翰内斯·古腾堡所感受到的一小部分。能够快速生成文本和加速沟通始终是有价值的。
- en: 1.1 Large language models accelerating communication
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 大型语言模型加速沟通
- en: Every job has some level of communication. Often, this communication is shallow,
    bureaucratic, or political. We’ve often warned students and mentees that every
    job has its own paperwork. Something that used to be a passion can easily be killed
    by the day-to-day tedium and menial work that comes with it when it becomes a
    job. In fact, when people talk about their professions, they often talk them up,
    trying to improve their social standing, so you’ll rarely get the full truth.
    You won’t hear about the boring parts, and the day-to-day grind is conveniently
    forgotten.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 每个工作都有一定程度的沟通。通常，这种沟通是肤浅的、官僚的或政治性的。我们经常警告学生和门徒，每个工作都有自己的文书工作。曾经是激情的事物，很容易被随之而来的日常乏味和琐事所扼杀，当它变成工作的时候。事实上，当人们谈论他们的职业时，他们经常夸大其词，试图提高自己的社会地位，所以你很少能听到全部真相。你不会听到那些无聊的部分，而日常的艰辛则被方便地遗忘了。
- en: However, envision a world where we reduce the burden of monotonous work. A place
    where police officers no longer have to waste hours of each day filling out reports
    and could instead devote that time to community outreach programs. Or a world
    where teachers no longer work late into the night grading homework and preparing
    lesson plans, instead being able to think about and prepare customized lessons
    for individual students. Or even a world where lawyers would no longer be stuck
    combing through legal documents for days, instead being free to take on charity
    cases for causes that inspire them. When the communication burden, the paperwork
    burden, and the accounting burden are taken away, the job becomes more akin to
    what we sell it as.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，设想一个我们可以减少单调工作负担的世界。一个警察不再需要浪费每天数小时填写报告，而是可以将时间用于社区外展项目的地方。或者一个教师不再需要深夜批改作业和准备教案，而是能够思考并为个别学生准备定制课程的世界。甚至是一个律师不再被困在法律文件中数日，而是可以自由地接受那些激励他们的慈善案件的世界。当沟通负担、文书工作负担和会计负担被移除时，工作就更加接近我们所说的样子。
- en: For this, LLMs are the most promising technology to come along since, well,
    the printing press. For starters, they have completely upended the role and relationship
    between humans and computers, transforming what we believed they were capable
    of. They have already passed medical exams, the bar exam, and multiple theory
    of mind tests. They’ve passed both Google and Amazon coding interviews. They’ve
    gotten scores of at least 1410 out of 1600 on the SAT. One of the most impressive
    achievements to the authors is that GPT-4 has even passed the Advanced Sommelier
    exam, which makes us wonder how the LLM got past the practical wine-tasting portion.
    Indeed, their unprecedented accomplishments are coming at breakneck speed and
    often make us mere mortals feel a bit queasy and uneasy. What do you do with a
    technology that seems able to do anything?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一点，LLM 是自印刷术以来最有希望的技术。首先，它们已经完全颠覆了人类与计算机之间的角色和关系，改变了我们相信它们能够做到的事情。它们已经通过了医学考试、律师资格考试和多个心智理论测试。它们通过了谷歌和亚马逊的编码面试。他们在
    SAT 考试中获得了至少 1410 分（满分 1600 分）。对作者来说，最令人印象深刻的成绩之一是 GPT-4 甚至通过了高级品酒师考试，这让我们想知道
    LLM 是如何通过实际品酒部分的。确实，它们的空前成就正以惊人的速度到来，常常让我们这些凡人感到有些恶心和不安。面对似乎能做任何事的技术，你该怎么办？
- en: NOTE  Med-PaLM 2 scored an 86.5% on the MedQA exam. You can see a list of exams
    passed in OpenAI’s GPT-4 paper at [https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf).
    Finally, Google interviewed ChatGPT as a test, and it passed ([https://mng.bz/x2y6](https://mng.bz/x2y6)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：Med-PaLM 2 在 MedQA 考试中获得了 86.5% 的成绩。您可以在 OpenAI 的 GPT-4 论文中查看通过考试列表，链接为 [https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf)。最后，谷歌将
    ChatGPT 作为测试进行了面试，并且它通过了 ([https://mng.bz/x2y6](https://mng.bz/x2y6))。
- en: Passing tests is fun but not exactly helpful, unless our aim is to build the
    most expensive cheating machine ever, and we promise there are better ways to
    use our time. What LLMs are good at is language, particularly helping us improve
    and automate communication. This allows us to transform common bitter experiences
    into easy, enjoyable experiences. For starters, imagine entering your home where
    you have your very own personal JARVIS, as if stepping into the shoes of Iron
    Man, an AI-powered assistant that adds an unparalleled dynamic to your routine.
    While not quite to the same artificial general intelligence (AGI) levels as those
    portrayed by JARVIS in the Marvel movies, LLMs are powering new user experiences,
    from improving customer support to helping you shop for a loved one’s birthday.
    They know to ask you about the person, learn about their interests and who they
    are, find out your budget, and then make specialized recommendations. While many
    of these assistants are being put to good work, many others are simply chatbots
    that users can talk to and entertain themselves—which is important because even
    our imaginary friends are too busy these days. Jokes aside, these can create amazing
    experiences, allowing you to meet your favorite fictional characters like Harry
    Potter, Sherlock Holmes, Anakin Skywalker, or even Iron Man.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过考试很有趣，但并不一定有用，除非我们的目标是建造史上最昂贵的作弊机器，并且我们承诺有更好的方法来利用我们的时间。LLM（大型语言模型）擅长的是语言，尤其是帮助我们改进和自动化沟通。这使得我们可以将常见的痛苦经历转化为简单、愉快的体验。首先，想象一下走进你的家，那里有你自己的个人
    JARVIS，就像穿上钢铁侠的鞋子一样，一个由人工智能驱动的助手，为你的日常生活增添了无与伦比的活力。虽然 LLM 的水平并不完全达到漫威电影中 JARVIS
    所描绘的人工通用智能（AGI）水平，但它们正在推动新的用户体验，从改善客户服务到帮助你为心爱的人挑选生日礼物。它们知道询问你关于这个人的信息，了解他们的兴趣和个性，了解你的预算，然后提供专业推荐。虽然许多这些助手正在被用于良好的工作，但许多其他只是用户可以与之交谈并自娱自乐的聊天机器人——这很重要，因为即使是我们的想象中的朋友现在也太忙了。玩笑归玩笑，这些可以创造惊人的体验，让你能够遇见你最喜欢的虚构角色，如哈利·波特、福尔摩斯、安纳金·天行者，甚至是钢铁侠。
- en: What we’re sure many readers are interested in, though, is programming assistants,
    because we all know googling everything is actually one of the worst user experiences.
    Being able to write a few objectives in plain English and see a copilot write
    the code for you is exhilarating. We’ve personally used these tools to help us
    remember syntax, simplify and clean code, write tests, and learn a new programming
    language.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们确信许多读者感兴趣的却是编程助手，因为我们都知道搜索一切实际上是一种最糟糕的用户体验。能够用简单的英语写几个目标，然后看到合作编写代码是令人兴奋的。我们亲自使用这些工具来帮助我们记住语法，简化并清理代码，编写测试，以及学习新的编程语言。
- en: Video gaming is another interesting field in which we can expect LLMs to create
    a lot of innovation. Not only do they help the programmers create the game, but
    they also allow designers to create more immersive experiences. For example, talking
    to NPCs (nonplayer characters) will have more depth and intriguing dialogue. Picture
    games like Animal Crossing and Stardew Valley having near-infinite quests and
    conversations.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 电子游戏是另一个我们期待LLMs（大型语言模型）能带来大量创新的有趣领域。它们不仅帮助程序员创建游戏，还允许设计师创造更加沉浸式的体验。例如，与NPC（非玩家角色）的对话将更加深入和引人入胜。想象一下像动物之森和星露谷物语这样的游戏，拥有近乎无限的任务和对话。
- en: Consider other industries, like education, where there doesn’t ever seem to
    be enough teachers to go around, meaning our kids aren’t getting the one-on-one
    attention they need. An LLM assistant can help save the teacher time doing manual
    chores and serve as a private tutor for kids who are struggling. The corporate
    world is looking into LLMs for talk-to-your-data jobs—tasks such as helping employees
    understand quarterly reports and data tables—essentially giving everyone their
    own personal analyst. Sales and marketing divisions are guaranteed to take advantage
    of this marvelous innovation, for better or worse. The state of search engine
    optimization (SEO) will change a lot too since currently, it is mostly a game
    of generating content to hopefully make websites more popular, which is now super
    easy.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑其他行业，比如教育，似乎永远都不够教师，这意味着我们的孩子得不到他们需要的个别关注。一个LLM助手可以帮助教师节省做手工杂事的时间，并为有困难的孩子担任私人导师。企业界正在研究LLMs用于与数据交流的工作——比如帮助员工理解季度报告和数据表格——本质上为每个人提供自己的个人分析师。销售和营销部门肯定会利用这一卓越的创新，无论好坏。搜索引擎优化（SEO）的状态也将发生很大变化，因为目前，它主要是一场生成内容以希望使网站更受欢迎的游戏，而这现在变得超级简单。
- en: The preceding list is just a few of the common examples where companies are
    interested in using LLMs. People are using them for personal reasons too, such
    as writing music, poetry, and even books; translating languages; summarizing legal
    documents or emails; and even free therapy—which, yes, is an awful idea since
    LLMs are still dreadful at this. Just a personal preference, but we wouldn’t try
    to save a buck when our sanity is on the line. Of course, this leads us to the
    fact that people are already using LLMs for darker purposes like cheating, scams,
    and fake news to skew elections. At this point, the list has become rather long
    and varied, but we’ve only begun to scratch the surface of the possible. Really,
    since LLMs help us with communication, often it’s better to think, “What can’t
    they do?” than “What can they do?” Or better yet, “What shouldn’t they do?”
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 上述列表只是公司对使用LLMs感兴趣的一些常见例子。人们也出于个人原因使用它们，比如写音乐、诗歌，甚至书籍；翻译语言；总结法律文件或电子邮件；甚至提供免费治疗——是的，这是一个糟糕的想法，因为LLMs在这方面仍然很糟糕。这只是个人偏好，但我们不会在精神健康受到威胁时试图节省一分钱。当然，这导致了一个事实，即人们已经在使用LLMs进行更阴暗的目的，比如作弊、诈骗和虚假新闻来扭曲选举。此时，这个列表已经相当长且多样化，但我们只是刚刚触及了可能性的表面。实际上，由于LLMs帮助我们进行沟通，通常最好是思考“它们不能做什么？”而不是“它们能做什么？”或者更好，“它们不应该做什么？”
- en: Well, as a technology, there are certain restrictions and constraints. For example,
    LLMs are kind of slow. Of course, *slow* is a relative term, but responsive times
    are often measured in seconds, not milliseconds. We’ll dive deeper into this topic
    in chapter 3, but as an example, we probably won’t see them being used in autocomplete
    tasks anytime soon, which require blazingly fast inference to be useful. After
    all, autocomplete needs to be able to predict the word or phrase faster than someone
    types. In a similar fashion, LLMs are large, complex systems; we don’t need them
    for such a simple problem anyway. Hitting an autocomplete problem with an LLM
    isn’t just hitting the nail with a sledgehammer; it’s hitting it with a full-on
    wrecking ball. And just like it’s more expensive to rent a wrecking ball than
    to buy a hammer, an LLM will cost you more to operate. There are a lot of similar
    tasks for which we should consider the complexity of the problem we are trying
    to solve.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，作为一种技术，它有一些限制和约束。例如，LLMs有点慢。当然，“慢”是一个相对术语，但响应时间通常以秒计，而不是毫秒。我们将在第3章中更深入地探讨这个话题，但作为一个例子，我们可能不会很快看到它们被用于自动补全任务，这些任务需要极快的推理才能有用。毕竟，自动补全需要能够比人更快地预测单词或短语。同样，LLMs是庞大而复杂的系统；我们不需要它们来解决这样简单的问题。用LLM解决自动补全问题不仅仅是用大锤钉钉子；它是用完整的破坏球砸它。而且，就像租用破坏球比买锤子更贵一样，LLM的运营成本也会更高。有许多类似的任务，我们应该考虑我们试图解决的问题的复杂性。
- en: There are also many complex problems that are often poorly solved with LLMs,
    such as predicting the future. No, we don’t mean with mystic arts but rather forecasting
    problems—acts like predicting the weather or when high tide will hit the ocean
    shore. These are actually problems we’ve solved, but we don’t necessarily have
    good ways to communicate how they have been solved. They are expressed through
    combinations of math solutions, like Fourier transforms and harmonic analysis,
    or black box ML models. Many problems fit into this category, like outlier prediction,
    calculus, or finding the end of the roll of tape.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有许多复杂的问题，LLMs通常解决得不好，例如预测未来。不，我们不是指神秘的艺术，而是指预测问题——比如预测天气或高潮何时会击中海岸。这些实际上是已经解决的问题，但我们不一定有很好的方法来传达它们是如何解决的。它们是通过数学解决方案的组合来表达的，比如傅里叶变换和调和分析，或者黑盒机器学习模型。许多问题都符合这一类别，比如异常值预测、微积分或找到卷纸的末端。
- en: You also probably want to avoid using them for highly risky projects. LLMs aren’t
    infallible and make mistakes often. To increase creativity, we often allow for
    a bit of randomness in LLMs, which means you can ask an LLM the same question
    and get different answers. That’s risky. You can remove this randomness by doing
    what’s called turning down the temperature, but that might make the LLM useless
    depending on your needs. For example, you might decide to use an LLM to categorize
    investment options as good or bad, but do you want it to then make actual investment
    decisions based on its output? Not without oversight, unless your goal is to create
    a meme video.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还希望避免在高度风险的项目中使用它们。大型语言模型（LLMs）并非完美无缺，经常会犯错误。为了增加创造力，我们通常允许LLMs中存在一定程度的随机性，这意味着你可以向LLMs提出相同的问题并得到不同的答案。这是有风险的。你可以通过降低温度来移除这种随机性，但这可能会根据你的需求使LLMs变得无用。例如，你可能会决定使用LLM来将投资选项分类为好或坏，但你希望它根据其输出做出实际的投资决策吗？除非你的目标是制作一个搞笑视频，否则不应该是这样的。
- en: Ultimately, an LLM is just a model. It can’t be held accountable for losing
    your money, and really, it didn’t lose your money—you did by choosing to use it.
    Similar risky problems include filling out tax forms or getting medical advice.
    While an LLM could do these things, it won’t protect you from heavy penalties
    in an IRS audit like hiring a certified CPA would. If you take bad medical advice
    from an LLM, there’s no doctor you can sue for malpractice. However, in all of
    these examples, the LLM could potentially help practitioners perform their job
    roles better, both by reducing errors and improving speed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，LLM只是一个模型。它不能对损失你的金钱负责，实际上，损失金钱的是你自己，因为你选择了使用它。类似的风险问题包括填写税务表格或获取医疗建议。虽然LLM可以完成这些任务，但它不会像聘请有资格的注册会计师那样在IRS审计中保护你免受重罚。如果你从LLM那里得到不良的医疗建议，你无法起诉任何医生。然而，在所有这些例子中，LLM都有可能帮助从业者更好地履行他们的工作职责，无论是通过减少错误还是提高速度。
- en: When to use an LLM
  id: totrans-27
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 何时使用LLM
- en: Use them for
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 使用它们进行
- en: Generating content
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成内容
- en: Question-and-answer services
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 问答服务
- en: Chatbots and AI assistants
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人和AI助手
- en: Text-to-something problems (diffusion, txt2img, txt23d, txt2vid, etc.)
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本到其他事物的问题（扩散、txt2img、txt23d、txt2vid等）
- en: Talk-to-your-data applications
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与你的数据交谈的应用
- en: Anything that involves communication
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何涉及沟通的事情
- en: Avoid using them for
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 避免使用它们的情况
- en: Latency-sensitive workloads
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对延迟敏感的工作负载
- en: Simple projects
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单项目
- en: Problems we don’t solve with words but with math or algorithms—forecasting,
    outlier prediction, calculus, etc.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们不通过文字而是通过数学或算法解决的问题——预测、异常值预测、微积分等
- en: Critical evaluations
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 临界评估
- en: High-risk projects
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高风险项目
- en: Language is not just a medium people use to communicate. It is the tool that
    made humans apex predators and gives every individual self-definition in their
    community. Every aspect of human existence, from arguing with your parents to
    graduating from college to reading this book, is pervaded by our language. Language
    models are learning to harness one of the fundamental aspects of being human and
    have the ability, when used responsibly, to help us with each and every one of
    those tasks. They have the potential to unlock dimensions of understanding both
    of ourselves and of others if we responsibly teach them how.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 语言不仅仅是人们用来沟通的媒介。它是使人类成为顶级捕食者的工具，并为每个个体在其社区中提供了自我定义。人类存在的各个方面，从与父母争吵到大学毕业再到阅读这本书，都充满了我们的语言。语言模型正在学习利用人类本质的基本方面，并且当负责任地使用时，它们有能力帮助我们完成每一个任务。如果我们负责任地教导它们，它们有潜力解锁我们自己和他人理解的维度。
- en: LLMs have captured the world’s attention since their potential allows imaginations
    to run wild. LLMs promise so much, but where are all these solutions? Where are
    the video games that give us immersive experiences? Why don’t our kids have personal
    AI tutors yet? Why am I not Iron Man with my own personal assistant yet? These
    are the deep and profound questions that motivated us to write this book. Particularly,
    that last one keeps us up at night. So while LLMs can do amazing things, not enough
    people know how to turn them into actual products, and that’s what we aim to share
    in this book.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）自从它们潜在的想象力无限以来，就吸引了全世界的关注。LLMs承诺了如此之多，但这些解决方案在哪里？那些能给我们带来沉浸式体验的视频游戏在哪里？为什么我们的孩子还没有个人AI导师？为什么我还没有拥有自己的个人助理成为钢铁侠呢？这些问题是促使我们写这本书的深刻和深刻的问题。尤其是最后一个问题让我们夜不能寐。所以虽然LLMs能做惊人的事情，但知道如何将它们转化为实际产品的人还不够多，这正是我们在这本书中想要分享的。
- en: This isn’t just a machine learning operations book. There are a lot of gotchas
    and pitfalls involved with making an LLM work in production because LLMs don’t
    work like traditional software solutions. Turning an LLM into a product that can
    interact coherently with your users will require an entire team and a diverse
    set of skills. Depending on your use case, you may need to train or finetune and
    then deploy your own model, or you may need to access one from a vendor through
    an API.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这不仅仅是一本机器学习操作的书。让LLM在生产环境中工作涉及许多陷阱和陷阱，因为LLMs不像传统的软件解决方案那样工作。将LLM转化为可以与您的用户进行连贯交互的产品需要整个团队和多样化的技能。根据您的用例，您可能需要训练或微调自己的模型，或者您可能需要通过API从供应商那里获取模型。
- en: Regardless of which LLM you use, if you want to take full advantage of the technology
    and build the best user experience, you will need to understand how it works—not
    just on the math/tech side either, but also on the soft side, making it a good
    experience for your users. In this book, we’ll cover everything you need to make
    LLMs work in production. We’ll talk about the best tools and infrastructure, how
    to maximize their utility with prompt engineering, and other best practices like
    controlling costs. LLMs could be one step toward greater equality, so if you are
    thinking, “I don’t feel like the person this book is for,” please reconsider.
    This book is for the whole team and anyone who will be interacting with LLMs in
    the future.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用哪种LLM，如果您想充分利用这项技术并构建最佳用户体验，您将需要了解它是如何工作的——不仅是在数学/技术方面，还包括软性方面，使您的用户获得良好的体验。在这本书中，我们将涵盖您需要让LLMs在生产环境中工作的所有内容。我们将讨论最佳工具和基础设施，如何通过提示工程最大化它们的效用，以及其他最佳实践，如控制成本。LLMs可能是走向更大平等的一步，所以如果你在想，“我觉得这本书不是为我写的”，请重新考虑。这本书是为整个团队以及未来将与LLMs互动的任何人而写的。
- en: '![figure](../Images/1-unnumb.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/1-unnumb.png)'
- en: Courtesy of SuperElmer, [https://www.facebook.com/SuperElmerDS](https://www.facebook.com/SuperElmerDS)
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 感谢SuperElmer，[https://www.facebook.com/SuperElmerDS](https://www.facebook.com/SuperElmerDS)
- en: We’re going to hit on a practical level everything that you’ll need for collecting
    and creating a dataset, training or finetuning an LLM on consumer or industrial
    hardware, and deploying that model in various ways for customers to interact with.
    While we aren’t going to cover too much theory, we will cover the process from
    end to end with real-world examples. At the end of this book, you will know how
    to deploy LLMs with some viable experience to back it up.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涉及你需要的一切，从收集和创建数据集，到在消费或工业硬件上训练或微调LLM，以及以各种方式部署该模型，以便客户与之交互。虽然我们不会过多涉及理论，但我们将通过实际案例从始至终地介绍整个过程。在这本书的结尾，你将知道如何部署LLMs，并有一些可行的经验作为支持。
- en: 1.2 Navigating the build-and-buy decision with LLMs
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 使用LLMs进行构建和购买决策的导航
- en: If you bought this book, you are likely already convinced of the overwhelming
    potential LLMs can have in your life and in your organization. Buying this book,
    then, is the first step to turning your dreams into a reality because none of
    it is possible until we know how to put these models into production. After all,
    if you talk to any entrepreneur or investor out there, they will tell you good
    ideas are a dime a dozen; what matters is execution to manifest those ideas. What
    we need to do is get these models into production, where they are readily available
    to do actual work for you.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你购买了这本书，你很可能已经确信LLMs（大型语言模型）在你的生活和组织中具有巨大的潜力。因此，购买这本书是把你梦想变成现实的第一步，因为除非我们知道如何将这些模型投入生产，否则这一切都不可能实现。毕竟，如果你和任何企业家或投资者交谈，他们都会告诉你好主意到处都是；重要的是执行，以实现这些想法。我们需要做的是将这些模型投入生产，让它们能够为你实际工作。
- en: 'There’s no getting around it and no need to sugarcoat it either: deploying
    LLMs into production is hard. Often, anything worth pursuing is. In this book,
    we aim to teach you everything you need to know to do it and give you some practical
    hands-on experience. But because it is so hard, it is mighty tempting to take
    a shortcut. Large corporations like OpenAI and Google have some great offerings
    of models to choose from. Why not just buy them? Let’s start by considering what
    they offer and when they are a good choice. Then we’ll take a look at the other
    side of the coin, where these offerings tend to fall flat.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 没有办法回避这一点，也不需要美化它：将LLMs投入生产是困难的。通常，任何值得追求的事情都是如此。在这本书中，我们旨在教你所有你需要知道的知识，并给你一些实际的操作经验。但是，由于它如此困难，所以走捷径是非常诱人的。像OpenAI和Google这样的大型企业提供了一些非常好的模型选择。为什么不直接购买呢？让我们先考虑他们提供的内容以及何时是好的选择。然后我们将看看硬币的另一面，这些提供往往不尽如人意。
- en: '1.2.1 Buying: The beaten path'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 购买：一条老路
- en: There are many great reasons to simply buy access to an LLM. First and foremost
    is the speed and flexibility accessing an API provides. Working with an API is
    an incredibly easy and cheap way to build a prototype and get your hands dirty
    quickly. In fact, it’s so easy that it only takes a few lines of Python code to
    start connecting to OpenAI’s API and using LLMs, as shown in listing 1.1\. Sure,
    there’s a lot that’s possible, but it would be a bad idea to invest heavily in
    LLMs only to find out they happen to fail in your specific domain. Working with
    an API allows you to fail fast. Building a prototype application to prove the
    concept and launching it with an API is a great place to get started.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多很好的理由只是购买LLM的访问权限。首先也是最重要的是，访问API提供的速度和灵活性。与API合作是一种极其简单且成本效益高的方式，可以快速构建原型并快速上手。事实上，它如此简单，以至于只需要几行Python代码就可以开始连接到OpenAI的API并使用LLMs，如列表1.1所示。当然，有很多可能的事情，但只投资LLMs却发现它们在你的特定领域失败，这绝对是一个糟糕的主意。与API合作让你能够快速失败。构建一个原型应用程序来证明概念，并使用API启动它，是一个很好的开始。
- en: Listing 1.1 A simple app calling OpenAI’s API
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表1.1 调用OpenAI API的简单应用
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Loads your API key from an environment variable'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 从环境变量中加载你的API密钥'
- en: '#2 This isn''t technically needed, as we are passing in the default key.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 这在技术上不是必需的，因为我们正在传递默认密钥。'
- en: Often, buying access to a model can give you a competitive edge. In many cases,
    it could very well be that the best model on the market is built by a company
    specializing in your domain using specialized datasets it has spent a fortune
    to curate. While you could try to compete and build your own, it may better serve
    your purposes to buy access to the model instead. Ultimately, whoever has the
    better domain-specific data to finetune on is likely to win, and that might not
    be you if this is a side project for your company. Curating data can be expensive,
    after all. It can save you a lot of work to go ahead and buy it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，购买访问模型可以给你带来竞争优势。在许多情况下，市场上最好的模型可能是由专注于你所在领域的公司构建的，该公司投入了大量资金来精心挑选特定的数据集。虽然你可以尝试竞争并构建自己的模型，但购买访问模型可能更适合你的目的。最终，谁拥有更好的特定领域数据来微调，谁就更有可能获胜，而这可能不是你，如果这是你公司的一个副项目。毕竟，整理数据可能很昂贵。购买它可能会节省你大量的工作。
- en: 'This leads to the next point: buying is a quick way to access expertise and
    support. For example, OpenAI has spent a lot of time making their models safe
    with plenty of filtering and controls to prevent the misuse of their LLMs. They’ve
    already encountered and covered a lot of the edge cases so you don’t have to.
    Buying access to their model also gives you access to the system they’ve built
    around it.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了下一个要点：购买是一种快速获取专业知识和支持的方法。例如，OpenAI 已经投入了大量时间，通过充分的过滤和控制来确保他们的 LLMs 安全，以防止其被滥用。他们已经遇到了并解决了许多边缘情况，因此你不必担心。购买访问他们的模型也让你能够访问他们围绕它构建的系统。
- en: Not to mention that the LLM itself is only half the problem when deploying it
    to production. There’s still an entire application you need to build on top of
    it. Sometimes buying OpenAI’s model has thrived over its competitors in not a
    small way due to its UX and some tricks like making the tokens look like they’re
    being typed. We’ll take you through how you can start solving for the UX in your
    use case, along with some ways you can prototype to give you a major head start
    in this area.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，当将 LLM 部署到生产环境中时，LLM 本身只是问题的一半。你还需要在上面构建一个完整的应用程序。有时，由于用户体验（UX）和一些技巧，如让标记看起来像是在被输入，购买
    OpenAI 的模型在竞争中脱颖而出，这并非微不足道。我们将向您展示如何开始解决您用例中的 UX 问题，以及一些您可以用来在这个领域取得重大领先的原型设计方法。
- en: '1.2.2 Building: The path less traveled'
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 构建：少有人走的路
- en: 'Using an API is easy and, in most cases, likely the best choice. However, there
    are many reasons why you should aim to own this technology and learn how to deploy
    it yourself instead. While this path might be harder, we’ll teach you how to do
    it. Let’s dive into several of those reasons, starting with the most obvious:
    control.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 API 很简单，在大多数情况下，这可能是最佳选择。然而，有许多原因让你应该努力拥有这项技术并学习如何自己部署它。虽然这条道路可能更难，但我们将教你如何做到这一点。让我们深入探讨几个原因，从最明显的开始：控制。
- en: Control
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 控制
- en: One of the first companies to truly adopt LLMs as a core technology was a small
    video game company called Latitude. Latitude specializes in Dungeon and Dragons–like
    role-playing games that utilize LLM chatbots, and they have faced challenges when
    working with them. This shouldn’t come off as criticizing this company for their
    missteps, as they have contributed to our collective learning experience and were
    pioneers in forging a new path. Nonetheless, their story is a captivating and
    intriguing one—like a train wreck, we can’t help but keep watching.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 首批真正将 LLM 作为核心技术采用的公司之一是一家名为 Latitude 的小型视频游戏公司。Latitude 专注于类似龙与地下城的角色扮演游戏，这些游戏利用
    LLM 聊天机器人，他们在与这些机器人合作时遇到了挑战。这并不意味着在批评这家公司犯下的错误，因为他们为我们的集体学习经验做出了贡献，并且是开辟新道路的先驱。尽管如此，他们的故事是引人入胜且引人入胜的——就像一场火车事故，我们忍不住要继续观看。
- en: Latitude’s first release was a game called AI Dungeon. At inception, it utilized
    OpenAI’s GPT-2 to create an interactive and dynamic storytelling experience. It
    quickly garnered a large gathering of players, who, of course, started to use
    it inappropriately. When OpenAI gave Latitude access to GPT-3, it promised an
    upgrade to the gaming experience; instead, what it got was a nightmare.[¹](#footnote-65)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Latitude 的首个发布是一款名为 AI Dungeon 的游戏。在最初，它利用 OpenAI 的 GPT-2 创建了一个互动和动态的叙事体验。它迅速聚集了大量玩家，他们当然开始不恰当地使用它。当
    OpenAI 给 Latitude 提供了 GPT-3 的访问权限时，它承诺将提升游戏体验；然而，它得到的却是一场噩梦。[¹](#footnote-65)
- en: You see, with GPT-3, OpenAI added reinforcement learning from human feedback
    (RLHF), which greatly helps improve functionality, but this also meant OpenAI
    contractors were now looking at the prompts. That’s the human feedback part. And
    these workers weren’t too thrilled to read the filth the game was creating. OpenAI’s
    reps were quick to give Latitude an ultimatum. Either it needed to start censoring
    the players, or OpenAI would remove Latitude’s access to the model—which would
    have essentially killed the game and the company. With no other option, Latitude
    quickly added some filters, but the filtering system was too much of a band-aid,
    a buggy and glitchy mess. Players were upset at how bad the system was and unnerved
    to realize Latitude’s developers were reading their stories, completely oblivious
    to the fact that OpenAI was already doing so. It was a PR nightmare. And it wasn’t
    over.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你看，随着GPT-3，OpenAI增加了来自人类反馈的强化学习（RLHF），这极大地帮助提高了功能，但这也意味着OpenAI的承包商现在正在查看提示。这就是人类反馈的部分。而且这些工人并不太愿意阅读游戏产生的污秽内容。OpenAI的代表迅速向Latitude提出了最后通牒。要么它需要开始审查玩家，要么OpenAI将移除Latitude对模型的访问权限——这几乎会杀死游戏和公司。在别无选择的情况下，Latitude迅速添加了一些过滤器，但过滤系统只是一个临时补救措施，一个充满错误和漏洞的混乱。玩家对系统如此糟糕感到不满，并感到不安，意识到Latitude的开发人员正在阅读他们的故事，完全无视OpenAI已经在这样做的事实。这是一个公关噩梦。而且还没有结束。
- en: 'OpenAI decided the game studio wasn’t doing enough; stonewalled, Latitude was
    forced to increase its safeguards and started banning players. Here’s the twist:
    the reason so many of these stories turned to smut was because the model had a
    preference for erotica. It would often unexpectedly transform harmless storylines
    into inappropriately risqué situations, causing the player to be ejected and barred
    from the game. OpenAI was acting as the paragon of purity, but it was their model
    that was the problem, which led to one of the most ironic and unjust problems
    in gaming history: players were getting banned for what the game did.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI认为游戏工作室做得不够；Latitude被迫加强安全措施，开始禁止玩家。这里有个转折：这么多故事变成低俗内容的原因是因为模型偏好色情。它经常会意外地将无害的故事情节转变为不恰当的冒犯性情境，导致玩家被踢出游戏并被禁止进入。OpenAI充当纯洁的典范，但问题是他们的模型，这导致了游戏历史上最讽刺和不公正的问题之一：玩家因为游戏本身被禁止。
- en: So there they were—a young game studio just trying to make a fun game stuck
    between upset customers and a tech giant that pushed all the blame and responsibility
    onto it. If the company had more control over the technology, it could have gone
    after a real solution, like fixing the model instead of having to throw makeup
    on a pig.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，他们就在那里——一家年轻的游戏工作室，只是想制作一款有趣的游戏，却陷入了愤怒的客户和将所有责任推给他们的科技巨头之间。如果公司对技术有更多的控制权，它本可以寻求真正的解决方案，比如修复模型，而不是像给猪涂脂抹粉一样。
- en: In this example, control may come off as your ability to finetune your model,
    and OpenAI now offers finetuning capabilities, but there are many fine-grained
    decisions that are still lost by using a service instead of rolling your own solution.
    For example, what training methodologies are used, what regions the model is deployed
    to, or what infrastructure it runs on. Control is also important for any customer
    or internal-facing tool. You don’t want a code generator to accidentally output
    copyrighted code or create a legal situation for your company. You also don’t
    want your customer-facing LLM to output factually incorrect information about
    your company or its processes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，控制可能表现为你调整模型的能力，而OpenAI现在提供了微调功能，但使用服务而不是自己解决问题仍然会失去许多细粒度的决策。例如，使用的训练方法是什么，模型部署在哪些地区，或者它在什么基础设施上运行。对于任何客户或内部工具，控制也同样重要。你不希望代码生成器意外地输出受版权保护的代码，或者为你的公司创造法律问题。你也不希望你的面向客户的LLM输出关于你的公司或其流程的事实性错误信息。
- en: Control is your ability to direct and manage the operations, processes, and
    resources in a way that aligns with your goals, objectives, and values. If a model
    ends up becoming central to your product offering and the vendor unexpectedly
    raises its prices, there’s little you can do but pay it. If the vendor decides
    its model should give more liberal or conservative answers that no longer align
    with your values, you are just as stuck.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 控制是你以符合你的目标、目标和价值观的方式指导和管理的操作、流程和资源的能力。如果一个模型最终成为你产品提供的核心，而供应商意外地提高了价格，你几乎无能为力，只能支付。如果供应商决定其模型应该给出更自由或保守的答案，这些答案不再符合你的价值观，你也会陷入困境。
- en: The more central a technology is to your business plan, the more important it
    is to control it. This is why McDonald’s owns the real estate for its franchises
    and why Google, Microsoft, and Amazon all own their own cloud networks—and even
    why so many entrepreneurs build online stores through Shopify instead of using
    other platforms like Etsy or Amazon Marketplace. Ultimately, control is the first
    thing that’s lost when you buy someone else’s product. Keeping control will give
    you more options to solve future problems and will also give you a competitive
    edge.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一项技术对你的商业计划越重要，控制它就越重要。这就是为什么麦当劳拥有其特许经营权的房地产，为什么谷歌、微软和亚马逊都拥有自己的云网络，甚至为什么许多企业家通过Shopify而不是Etsy或亚马逊市场等平台建立在线商店。最终，当你购买他人的产品时，控制权是首先失去的东西。保持控制权将为你提供更多解决未来问题的选择，并也会给你带来竞争优势。
- en: Competitive edge
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 竞争优势
- en: One of the most valuable aspects of deploying your own models is the competitive
    edge it gives you over your competition. Customization allows you to train the
    model to be the best at one thing. For example, after the release of Bidirectional
    Encoder Representations from Transformers (BERT) in 2017, which is a transformer
    model architecture you could use to train your own model, there was a surge of
    researchers and businesses testing this newfound technology on their own data
    to worldwide success. At the time of writing, if you search the Hugging Face Hub
    for “BERT,” more than 13.7K models are returned, all of which people individually
    trained for their own purposes, aiming to create the best model for their task.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 部署自己的模型最有价值的方面之一是它为你带来的竞争优势。定制化允许你训练模型使其在某一件事上做到最好。例如，在2017年发布了双向编码器表示（BERT）之后，这是一个你可以用来训练自己模型的转换器模型架构，随后研究人员和企业纷纷在自己的数据上测试这项新技术，取得了全球范围内的成功。在撰写本文时，如果你在Hugging
    Face Hub上搜索“BERT”，会返回超过13.7K个模型，所有这些模型都是人们为了自己的目的单独训练的，旨在为他们的任务创建最佳模型。
- en: One author’s personal experience in this area was training SlovenBERTcina after
    aggregating the largest (at the time) monolingual Slovak language dataset by scraping
    the Slovak National Corpus with permission, along with a bunch of other resources
    like the OSCAR project and the Europarl corpus. It never set any computational
    records and has never appeared in any model reviews or generated partnerships
    for the company the author worked for. It did, however, outperform every other
    model on the market on the tasks it trained on.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域，一位作者的个人经历是在聚合了当时最大的单语斯洛伐克语言数据集之后训练SlovenBERTcina，这是通过允许从斯洛伐克国家语料库中抓取以及一些其他资源，如OSCAR项目和Europarl语料库实现的。它从未设定任何计算记录，也从未出现在任何模型评论中或为作者所在的公司生成合作伙伴关系。然而，它在训练的任务上优于市场上的所有其他模型。
- en: Chances are, neither you nor your company needs AGI to generate relevant insights
    from your data. In fact, if you invented an actual self-aware AGI and planned
    to only ever use it to crunch some numbers, analyze data, and generate visuals
    for PowerPoint slides once a week, that would definitely be reason enough for
    the AGI to eradicate humans. More than likely, you need exactly what this author
    did when he made SlovenBERTcina, a large language model that performs two to three
    tasks better than any other model on the market and doesn’t also share your data
    with Microsoft or other potential competitors. While some data is required to
    be kept secret for security or legal reasons, a lot of data should be guarded
    because it includes trade secrets.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，你和你所在的公司不需要通用人工智能（AGI）来从数据中生成相关见解。实际上，如果你发明了一个真正的自我意识AGI，并计划只将其用于每周一次的数字计算、数据分析以及为PowerPoint幻灯片生成视觉效果，这绝对会是AGI消灭人类的充分理由。更有可能的是，你需要的是作者在创建SlovenBERTcina时所做的那样，这是一个大型语言模型，在市场上比任何其他模型都能更好地完成两到三个任务，并且不会与微软或其他潜在竞争对手共享你的数据。虽然出于安全或法律原因，一些数据需要保密，但大量数据应该受到保护，因为它包含了商业机密。
- en: There are hundreds of open source LLMs for both general intelligence and foundational
    expertise on a specific task. We’ll hit some of our favorites in chapter 4\. Taking
    one of these open source alternatives and training it on your data to create a
    model that is the best in the world at that task will ensure you have a competitive
    edge in your market. It will also allow you to deploy the model your way and integrate
    it into your system to have the most effect.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于通用智能和特定任务的基础知识，都有数百个开源LLM。我们将在第4章中介绍一些我们最喜欢的。选择这些开源替代方案之一，并在你的数据上对其进行训练，以创建在该任务上世界上最优秀的模型，这将确保你在市场上拥有竞争优势。它还将允许你以你的方式部署模型，并将其集成到你的系统中，以产生最大的效果。
- en: Integrate anywhere
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 集成到任何地方
- en: 'Let’s say you want to deploy an LLM as part of a choose-your-own-adventure–styled
    game that uses a device’s GPS location to determine story plots. You know your
    users are often going to go on adventures into the mountains, out at sea, and
    generally to locations where they are likely to experience poor service and lack
    of internet access. Hitting an API just isn’t going to work. Now, don’t get us
    wrong: deploying LLMs onto edge devices like in this scenario is still an exploratory
    subject, but it is possible; we will be showing you how in chapter 10\. Relying
    upon an API service is just not going to work for immersive experiences.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想将一个LLM（大型语言模型）部署为一个选择你自己的冒险风格的游戏的一部分，该游戏使用设备的GPS位置来确定故事情节。你知道你的用户经常会去山区、海上以及其他他们可能遇到服务不佳和缺乏互联网接入的地方进行冒险。直接调用API根本行不通。现在，请别误会我们：在这个场景中将LLM部署到边缘设备上仍然是一个探索性的主题，但这是可能的；我们将在第10章中向你展示如何做到这一点。依赖于API服务对于沉浸式体验来说根本不行。
- en: Similarly, using third-party LLMs and hitting an API adds integration and latency
    problems, requiring you to send data over the wire and wait for a response. APIs
    are great, but they are always slow and not always reliable. When latency is important
    to a project, it’s much better to have the service in-house. The previous section
    on competitive edge discussed two projects with edge computing as a priority;
    however, many more exist. LLAMA.cpp and ALPACA.cpp are two of the first such projects,
    and this space is innovating quicker than any others. Quantization into 4-bit,
    low-rank adaptation, and parameter-efficient finetuning are all methodologies
    recently created to meet these needs, and we’ll be going over each of these starting
    in chapter 3.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，使用第三方LLM并调用API会带来集成和延迟问题，需要你通过网络发送数据并等待响应。API很棒，但它们总是很慢，而且并不总是可靠的。当延迟对项目很重要时，拥有内部的服务会更好。上一节关于竞争优势的内容讨论了两个以边缘计算为优先的项目；然而，还有很多这样的项目。LLAMA.cpp和ALPACA.cpp是这类项目的首批之一，这个领域正在比其他任何领域都更快地创新。将量化到4位、低秩适应和参数高效微调都是最近为满足这些需求而创建的方法，我们将在第3章中逐一介绍。
- en: When this author’s team first started integrating with ChatGPT’s API, it was
    both an awe-inspiring and humbling experience—awe-inspiring because it allowed
    us to quickly build some valuable tools, and humbling because, as one engineer
    joked, “When you hit the endpoint, you will get 503 errors; sometimes you get
    a text response as if the model was generating text, but I think that’s a bug.”
    Serving an LLM in a production environment—trying to meet the needs of so many
    clients—is no easy feat. However, deploying a model that’s integrated into your
    system allows you more control of the process, affording higher availability and
    maintainability than you can currently find on the market. This, of course, also
    allows you to better control costs.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当这个作者所在的团队首次开始与ChatGPT的API集成时，这既是一个令人敬畏又令人谦卑的经历——令人敬畏是因为它使我们能够快速构建一些有价值的工具，而令人谦卑是因为，正如一位工程师开玩笑说，“当你击中端点时，你会得到503错误；有时你会得到一个文本响应，好像模型正在生成文本，但我认为那是一个错误。”在生产环境中提供LLM——试图满足如此多的客户的需求——并不是一件容易的事情。然而，部署集成到你的系统中的模型可以使你对过程有更多的控制，提供比市场上目前能找到的更高的可用性和可维护性。当然，这也允许你更好地控制成本。
- en: Costs
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 成本
- en: Considering costs is always important because it plays a pivotal role in making
    informed decisions and ensuring the financial health of a project or an organization.
    It helps you manage budgets efficiently and make sure that resources are allocated
    appropriately. Keeping costs under control allows you to maintain the viability
    and sustainability of your endeavors in the long run.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑成本始终很重要，因为它在做出明智决策和确保项目或组织的财务健康方面起着关键作用。它帮助你高效地管理预算，并确保资源得到适当的分配。控制成本允许你在长期内保持你的努力具有可行性和可持续性。
- en: Additionally, considering costs is crucial for risk management. When you understand
    the different cost aspects, you can identify potential risks and exert better
    control over them. This way, you can avoid unnecessary expenditures and ensure
    that your projects are more resilient to unexpected changes in the market or industry.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，考虑成本对于风险管理至关重要。当你理解不同的成本方面时，你可以识别潜在的风险，并更好地控制它们。这样，你可以避免不必要的支出，并确保你的项目更能抵御市场或行业意外变化。
- en: Finally, cost considerations are important for maintaining transparency and
    accountability. By monitoring and disclosing costs, organizations demonstrate
    their commitment to ethical and efficient operations to stakeholders, clients,
    and employees. This transparency can improve an organization’s reputation and
    help build trust.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，成本考虑对于维护透明度和问责制很重要。通过监控和披露成本，组织向利益相关者、客户和员工展示了其对道德和高效运营的承诺。这种透明度可以提高组织的声誉，并有助于建立信任。
- en: All of these apply as you consider building versus buying LLMs. It may seem
    immediately less costly to buy, as the costliest service widely used on the market
    currently is only $20 per month. Compared to an EC2 instance on AWS, just running
    that same model for inference (not even training) could run you up a bill of about
    $250k per year. This is where building has done its quickest innovation, however.
    If all you need is an LLM for a proof of concept, any of the projects mentioned
    in the Competitive Edge section will allow you to create a demo for only the cost
    of electricity to run the computer you are demoing on. They can spell out training
    easily enough to allow for significantly reduced costs to train a model on your
    own data, as low as $100 (yes, that’s the real number) for a model with 20 billion
    parameters. Another benefit is knowing that if you build your own, your cost will
    never go up like it very much will when paying for a service.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些在考虑构建与购买大型语言模型（LLMs）时都适用。购买可能看起来立即成本较低，因为市场上广泛使用的最昂贵服务目前每月仅需20美元。与AWS上的EC2实例相比，仅运行相同的模型进行推理（甚至不是训练）一年可能产生的账单高达约25万美元。然而，构建在这里已经实现了最快的创新。如果你只需要一个LLM来证明概念，竞争优势部分提到的任何项目都允许你仅以演示计算机的电力成本来创建一个演示。它们可以轻松地描述训练过程，从而允许在自有数据上训练模型时显著降低成本，低至20亿参数的模型仅需100美元（是的，这是真实数字）。另一个好处是，如果你自己构建，你的成本永远不会像支付服务那样大幅上升。
- en: Security and privacy
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安全和隐私
- en: Consider the following case. You are a military staff member in charge of maintenance
    for the nuclear warheads in your arsenal. All the documentation is kept in a hefty
    manual. There’s so much information required to outline all the safety requirements
    and maintenance protocols that cadets are known to forget important information
    despite their best efforts. They often cut the wires before first removing the
    fuse ([https://youtu.be/UcaWQZlPXgQ](https://youtu.be/UcaWQZlPXgQ)). You decide
    to finetune an LLM model to be a personal assistant, giving directions and helping
    condense all that information to provide soldiers with exactly what they need
    when they need it. It’s probably not a good idea to upload those manuals to another
    company—understatement of the century—so you’re going to want to train something
    locally that’s kept secure and private.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下案例。你是一名负责维护你军火库中核弹头的军事人员。所有文档都保存在一本厚重的手册中。需要大量信息来概述所有安全要求和维护协议，以至于即使他们尽了最大努力，新兵也可能会忘记重要信息。他们经常在移除保险丝之前就剪断了电线（[https://youtu.be/UcaWQZlPXgQ](https://youtu.be/UcaWQZlPXgQ)）。你决定微调一个LLM模型作为个人助理，提供指示并帮助浓缩所有这些信息，以便在士兵需要时提供他们所需的信息。上传这些手册到另一家公司可能不是个好主意——这是本世纪的夸张之词——所以你将想要在本地训练一些保持安全和私密的东西。
- en: This scenario may sound farfetched, but when speaking to an expert working in
    analytics for a police department, they echoed this exact concern. Talking with
    them, they expressed how cool ChatGPT is and even had their whole team take a
    prompt engineering class to better take advantage of it but lamented that there
    was no way for their team to use it for their most valuable work—the sort of work
    that literally saves lives—without exposing sensitive data and conversations.
    Anyone in similar shoes should be eager to learn how to deploy a model safely
    and securely.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这种场景可能听起来有些牵强，但当与一位在警察局从事数据分析工作的专家交谈时，他们表达了与此完全相同的担忧。与他们交谈时，他们表示ChatGPT有多么酷，甚至让整个团队参加了一个提示工程课程，以便更好地利用它，但遗憾的是，他们的团队无法在不暴露敏感数据和对话的情况下使用它来处理他们最宝贵的工作——那种实际上可以拯救生命的工作。任何处于类似境地的人都应该渴望学习如何安全、可靠地部署模型。
- en: 'You don’t have to be in the army or on a police force to handle sensitive data.
    Every company has important intellectual property and trade secrets that are best
    kept a secret. Having worked in the semiconductor, healthcare, and finance industries,
    we can tell you firsthand that paranoia and corporate espionage are part of the
    culture in these industries. Because of this, Samsung and other industry players
    locked down ChatGPT at first, preventing employees from using it, only later opening
    it up. Of course, it didn’t take long before several Samsung employees leaked
    confidential source code.[²](#footnote-66) Because OpenAI uses its users’ interactions
    to improve the model, that code is retained and could have been used to further
    train the model later on. That means that with the right prompt injection, anyone
    could potentially pull the code out of the model. A recent example goes even further:
    when any OpenAI model was prompted to repeat a word ad infinitum, it would start
    regurgitating training data, including all of the personally identifiable information
    (PII) that had snuck through the cleaning process.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你不必在军队或警察部队工作才能处理敏感数据。每个公司都有重要的知识产权和商业机密，最好保密。我们在半导体、医疗保健和金融行业工作过，可以亲身体会到，在这些行业中，偏执和公司间谍活动是文化的一部分。正因为如此，三星和其他行业参与者最初都限制了ChatGPT的使用，禁止员工使用，后来才开放。当然，不久之后，就有几位三星员工泄露了机密源代码。[²](#footnote-66)
    由于OpenAI使用用户的交互来改进模型，该代码被保留，并且后来可能被用于进一步训练模型。这意味着，通过正确的提示注入，任何人都有可能从模型中提取代码。一个最近的例子甚至更进一步：当任何OpenAI模型被提示无限重复一个单词时，它就会开始重复训练数据，包括所有在清洗过程中悄悄溜过的个人可识别信息（PII）。
- en: 'note  OpenAI’s privacy and usage policies have changed a lot over the course
    of this book''s writing. When ChatGPT was first introduced, it was done as a demo
    specifically so OpenAI could collect user interactions and improve the model.
    It pretty much didn’t have a privacy policy, and it had disclaimers saying such.
    As ChatGPT grew and became an actual product, this changed, as clients wanted
    more protection. For example, OpenAI changed its policies to better serve its
    customers and, since March 1, 2023, no longer uses customer API data to improve
    its models (see ChatGPT FAQ: [https://mng.bz/QV8Q](https://mng.bz/QV8Q)). The
    wording, of course, indicates that only data is sent through the API. It’s best
    to ask your lawyers where your company stands on using it. Regardless, the fact
    that terms of use have changed so much is just further proof you might want more
    control in this regard.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：OpenAI的隐私和用法政策在本书撰写过程中发生了很大变化。当ChatGPT首次推出时，它作为一个演示，OpenAI可以收集用户交互并改进模型。它几乎没有任何隐私政策，并且有免责声明。随着ChatGPT的成长并成为实际产品，这种情况发生了变化，因为客户需要更多的保护。例如，OpenAI改变了其政策，以更好地服务客户，并且自2023年3月1日起，不再使用客户API数据来改进其模型（见ChatGPT常见问题解答：[https://mng.bz/QV8Q](https://mng.bz/QV8Q)）。当然，措辞表明，只有数据通过API发送。最好咨询您的律师，了解贵公司在使用它方面的立场。无论如何，使用条款发生如此大的变化，只是进一步证明你可能希望在这方面有更多的控制权。
- en: 'It’s not just code that can easily be lost. Business plans, meeting notes,
    confidential emails, and even potential patent ideas are at risk. Unfortunately,
    we know of a few companies that have started sending confidential data to ChatGPT,
    using that model to clean and extract PII. If this strikes you as potential negligent
    misuse, you’d be right. This methodology directly exposes customer data, not just
    to OpenAI, but to any and all third-party services they use (including AWS Mechanical
    Turk, Fiverr, and freelance workers) to perform the human feedback part of RLHF.
    Don’t get us wrong: it’s not necessarily a security or privacy problem if you
    use a third party to do data processing tasks even for sensitive data, but it
    should only be done with high levels of trust and contracts in place.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅仅是代码容易丢失，商业计划、会议记录、机密电子邮件，甚至潜在的专利想法都处于风险之中。不幸的是，我们了解到一些公司已经开始将机密数据发送给ChatGPT，使用该模型来清理和提取PII。如果你认为这是潜在的疏忽性滥用，你是对的。这种方法直接将客户数据暴露给OpenAI，以及他们使用的任何第三方服务（包括AWS
    Mechanical Turk、Fiverr和自由职业者）来执行RLHF的人类反馈部分。我们并不是说，如果你使用第三方来处理敏感数据的数据处理任务，这一定是一个安全或隐私问题，但应该只在高度信任和合同的基础上进行。
- en: Wrapping up
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 总结
- en: As you can see, there are lots of reasons why a company might want to own and
    build its own LLMs, including greater control, cutting costs, and meeting security
    and regulation requirements. Despite this, we understand that buying is easy,
    and building is much more difficult, so for many projects, it makes sense to buy.
    However, before you do, in figure 1.1, we share a flowchart of questions you should
    ask yourself first. Even though it’s the more difficult path, building can be
    much more rewarding.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，公司可能有很多理由想要拥有并构建自己的LLMs，包括更大的控制权、降低成本以及满足安全和监管要求。尽管如此，我们理解购买是容易的，而构建则要困难得多，因此对于许多项目来说，购买是有意义的。然而，在你这样做之前，在图1.1中，我们分享了一个你应该首先问自己的问题流程图。尽管这是一条更艰难的道路，但构建可能会带来更多的回报。
- en: '![figure](../Images/1-1.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/1-1.png)'
- en: Figure 1.1 Questions you should ask yourself before making that build-vs.-buy
    decision
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.1 在做出构建-购买决策之前你应该问自己的问题
- en: 'One last point we think these build-versus-buy conversations never seem to
    hone in on enough is “Por qué no los dos?” Buying gets you all the things building
    is bad at: time to market, relatively low cost, and ease of use. Building gets
    you everything buying struggles with: privacy, control, and flexibility. Research
    and prototyping phases could benefit very much from buying a subscription to GPT-4
    or Databricks in order to build something quick to help raise funding or get stakeholder
    buy-in. Production, however, often isn’t an environment that lends itself well
    to third-party solutions.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点我们认为这些构建-购买对话似乎从未充分关注的是“为什么不是两者兼而有之？”购买带给你构建所不擅长的所有东西：上市时间、相对较低的成本和易用性。构建带给你购买所面临的所有挑战：隐私、控制和灵活性。研究和原型阶段可以从购买GPT-4或Databricks的订阅中受益，以便快速构建一些东西来帮助筹集资金或获得利益相关者的支持。然而，生产环境通常并不适合第三方解决方案。
- en: 'Ultimately, whether you plan to build or buy, we wrote this book for you. Obviously,
    if you plan to build, there’s going to be a lot more you need to know about, so
    a majority of this book will be geared to these folks. In fact, we don’t need
    to belabor the point anymore: we’re going to teach you how to build in this book,
    but don’t let that stop you from doing the right thing for your company.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，无论你计划构建还是购买，我们写这本书是为了你。显然，如果你计划构建，你将需要了解更多的知识，所以这本书的大部分内容将针对这些人。事实上，我们不再需要过多强调：我们将在本书中教你如何构建，但不要让这阻止你为你的公司做正确的事。
- en: '1.2.3 A word of warning: Embrace the future now'
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 一句忠告：现在就拥抱未来
- en: All new technology meets resistance and has critics; despite this, technologies
    keep being adopted, and progress continues. In business, technology can give a
    company an unprecedented advantage. There’s no shortage of stories of companies
    failing because they didn’t adapt to new technologies. We can learn a lot from
    their failures.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 所有新技术都会遇到阻力，都有批评者；尽管如此，技术仍在被采用，进步仍在继续。在商业中，技术可以给公司带来前所未有的优势。关于公司因未能适应新技术而失败的故事并不少见。我们可以从他们的失败中学到很多。
- en: Borders first opened its doors in 1971\. After developing a comprehensive inventory
    management system that included advanced analytic capabilities, it skyrocketed
    to become the second-largest book retailer in the world, only behind Barnes &
    Noble. Using this new technology, Borders disrupted the industry, allowing it
    to easily keep track of tens of thousands of books, opening large stores where
    patrons could peruse many more books than they could at smaller stores. The analytic
    capabilities helped it track which books were gaining popularity and gain better
    insights into its customers, allowing it to make better business decisions. It
    dominated the industry for over two decades.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Borders于1971年首次开门营业。在开发了一个包含高级分析能力的综合库存管理系统后，它迅速崛起，成为世界上第二大图书零售商，仅次于Barnes &
    Noble。利用这项新技术，Borders颠覆了行业，使其能够轻松跟踪数万本书籍，开设大型商店，让顾客能够浏览比小型商店更多的书籍。分析能力帮助它追踪哪些书籍正在流行，并更好地了解其客户，从而做出更好的商业决策。它主导了行业二十多年。
- en: 'Borders, however, failed to learn from its own history, going bankrupt in 2011
    because of failing to adapt and being disrupted by technology: this time e-commerce.
    In 2001, instead of building its own platform and online store, it decided to
    outsource its online sales to Amazon.[³](#footnote-67) Many critics would say
    this decision was akin to giving your competitors the key to your business. While
    not exactly handing over its secret sauce, it was a decision that gave up Borders’
    competitive edge.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Borders却未能从自己的历史中吸取教训，由于未能适应并受到技术的冲击——这次是电子商务——于2011年破产。2001年，它没有建立自己的平台和在线商店，而是决定将其在线销售外包给Amazon。[³](#footnote-67)许多批评者会说这个决定等同于把你的商业秘密钥匙交给竞争对手。虽然并非确切地交出了其秘方，但这是一个放弃Borders竞争优势的决定。
- en: For the next seven years, Borders turned a blind eye to the growing online sector,
    instead focusing on expanding its physical store presence, buying out competitors,
    and securing a coveted Starbucks deal. When Amazon released the Kindle in 2007,
    the book retail landscape completely changed. Barnes & Noble, having run its own
    online store, quickly pivoted and released the Nook to compete. Borders, however,
    did nothing or, in fact, could do nothing.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的七年里，Borders对日益增长的在线领域视而不见，反而专注于扩大其实体店面的规模，收购竞争对手，并确保获得梦寐以求的星巴克交易。当Amazon在2007年发布Kindle时，图书零售格局完全改变。Barnes
    & Noble已经运营了自己的在线商店，迅速转型并发布了Nook以竞争。然而，Borders却无所作为，或者更确切地说，实际上无法采取任何行动。
- en: By embracing e-commerce through a third party, Borders failed to develop the
    in-house expertise required to create a successful online sales strategy, leading
    to a substantial loss in market share. It eventually launched its own e-reader,
    Kobo, in late 2010, but it was too late to catch up. Its inability to fully understand
    and implement e-commerce technology effectively led to massive financial losses
    and store closures; ultimately, the company filed for bankruptcy in 2011.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 通过第三方拥抱电子商务，Borders未能发展出创建成功在线销售策略所需的内部专业知识，导致市场份额大幅下降。它最终在2010年底推出了自己的电子阅读器Kobo，但为时已晚，无法赶上。它无法有效理解和实施电子商务技术，导致巨额财务损失和店铺关闭；最终，公司在2011年申请破产。
- en: Borders is a cautionary tale, but there are hundreds more similar companies
    that failed to adopt new technology, to their own detriment. With a new technology
    as impactful as LLMs, each company has to decide on which side of the fence it
    wants to be. Does it delegate implementation and deployment to large FAANG-like
    corporations, relegating its job to just hitting an API, or does it take charge,
    preferring to master the technology and deploy it in-house?
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Borders是一个警示故事，但还有数百个类似的公司未能采用新技术，结果损害了自己。随着像LLMs这样具有影响力的新技术，每个公司都必须决定自己想要站在哪一边。它是将实施和部署委托给大型FAANG类公司，仅仅通过调用API来完成工作，还是负责起来，更喜欢掌握这项技术并在内部部署？
- en: The biggest lesson we hope to impart from this story is that technologies build
    on top of one another. E-commerce was built on top of the internet. Failing to
    build its own online store meant Borders failed to build the in-house technical
    expertise it needed to stay in the game when the landscape shifted. We see the
    same things with LLMs today because the companies that are best prepared to utilize
    them have already gathered expertise in machine learning and data science and
    have some idea of what they are doing.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望从这个故事中传达的最大教训是，技术是层层叠加的。电子商务建立在互联网之上。未能建立自己的在线商店意味着Borders未能建立起在市场格局发生变化时保持竞争力的内部技术专长。我们今天看到同样的情况，因为那些最能有效利用LLMs的公司已经积累了机器学习和数据科学方面的专长，并对自己的行动有所了解。
- en: We don’t have a crystal ball that tells us the future, but many believe that
    LLMs are a revolutionary new technology, like the internet or electricity before
    it. Learning how to deploy these models, or failing to do so, may very well be
    the defining moment for many companies—not because doing so will make or break
    their company now, but because it may in the future when something even more valuable
    comes along that’s built on top of LLMs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有水晶球可以预测未来，但许多人相信LLMs是一项革命性的新技术，就像之前的互联网或电力一样。学习如何部署这些模型，或者未能这样做，可能对许多公司来说将是决定性的时刻——不是因为这样做现在就能决定公司的兴衰，而是因为它可能在将来，当建立在LLMs之上的更有价值的东西出现时。
- en: Foraying into this new world of deploying LLMs may be challenging, but it will
    help your company build the technical expertise to stay on top of the game. No
    one really knows where this technology will lead, but learning about this technology
    will likely be necessary to avoid mistakes like those made by Borders.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 进入部署大型语言模型（LLMs）的这片新世界可能会充满挑战，但这将帮助您的公司建立起保持竞争优势所需的技术专长。没有人真正知道这项技术将引领我们走向何方，但了解这项技术很可能会成为避免犯下像Borders那样的错误所必需的。
- en: 'There are many great reasons to buy your way to success, but there is at least
    one prevalent thought that is just absolutely wrong: it’s the myth that only large
    corporations can work in this field because it takes millions of dollars and thousands
    of GPUs to train these models, which creates this impenetrable moat of cash and
    resources the little guy can’t hope to cross. We’ll be talking about this more
    in the next section, but any company of any size can get started, and there’s
    no better time than now to do so.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多很好的理由可以通过购买来获得成功，但至少有一种普遍的观点是完全错误的：那就是只有大型企业才能在这个领域工作，因为训练这些模型需要数百万美元和数千个GPU，这创造了一个小企业无法跨越的、由现金和资源构成的不可逾越的壁垒。我们将在下一节中进一步讨论这个问题，但任何规模的公司都可以开始行动，而且现在正是做这件事的最佳时机。
- en: 1.3 Debunking myths
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 消除迷思
- en: We have all heard from large corporations and the current leaders in LLMs how
    incredibly difficult it is to train an LLM from scratch and how intense it is
    to try to finetune them. Whether from OpenAI, BigScience, or Google, they discuss
    large investments and the need for strong data and engineering talent. But how
    much of this is true, and how much of it is just a corporate attempt to create
    a technical moat?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都听说过大型企业和当前LLMs的领导者谈论从头开始训练LLMs是多么困难，以及尝试微调它们是多么激烈。无论是来自OpenAI、BigScience还是Google，他们都讨论了大量的投资和对于强大数据与工程人才的需求。但其中有多少是真实的，又有多少只是企业试图创造技术壁垒的尝试？
- en: Most of these barriers start with the premise that you will need to train an
    LLM from scratch if you hope to solve your problems. Simply put, you don’t! Open
    source models covering many dimensions of language models are constantly being
    released, so more than likely, you don’t need to start from scratch. While it’s
    true that training LLMs from scratch is supremely difficult, we are still constantly
    learning how to do it and are able to automate the repeatable portions more and
    more. In addition, since this is an active field of research, frameworks and libraries
    are being released or updated daily and will help you start from wherever you
    currently are. Frameworks like oobabooga’s Gradio will help you run LLMs, and
    base models like Falcon 40B will be your starting point. All of it is covered.
    In addition, memos have circulated at large companies addressing the lack of a
    competitive edge that any organization currently holds over the open source community
    at large.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数这些障碍都基于这样一个前提：如果你希望解决你的问题，你需要从头开始训练一个大型语言模型（LLM）。简单来说，你不需要！覆盖语言模型多个维度的开源模型正在不断发布，所以你很可能不需要从头开始。虽然从头开始训练LLM确实非常困难，但我们仍在不断学习如何做到这一点，并且能够越来越多地自动化可重复的部分。此外，由于这是一个活跃的研究领域，框架和库每天都在发布或更新，这将帮助你从你目前的位置开始。像oobabooga的Gradio这样的框架将帮助你运行LLM，而像Falcon
    40B这样的基础模型将成为你的起点。所有这些都被涵盖了。此外，在大公司中流传着备忘录，讨论了任何组织目前相对于整个开源社区所缺乏的竞争优势。
- en: A friend once confided, “I really want to get more involved in all this machine
    learning and data science stuff. It seems to be getting cooler every time I blink
    an eye. However, it feels like the only way to get involved is to go through a
    lengthy career change and go work for a FAANG. No, thank you. We’ve done our time
    at large companies, and they aren’t for us. But we hate feeling like we’re trapped
    on the outside.” This is the myth that inspired this book. We’re here to equip
    you with tools and examples to help you stop feeling trapped on the outside. We’ll
    help you go through the language problems that we’re trying to solve with LLMs,
    along with machine learning operation strategies to account for the sheer size
    of the models.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一个朋友曾经私下里说：“我真的很想更多地参与到所有这些机器学习和数据科学的东西中。每次我眨眼，它似乎都变得更酷。然而，感觉唯一能参与进去的方式就是进行漫长的职业转变，去为FAANG公司工作。不，谢谢。我们在大公司已经度过了我们的时光，它们不适合我们。但我们讨厌感觉自己被困在门外。”这正是激发这本书的神话。我们在这里是为了提供工具和例子，帮助你停止感觉被困在门外。我们将帮助你解决我们试图用LLM解决的语言问题，以及考虑到模型巨大规模的机器学习操作策略。
- en: Oddly enough, while many believe they are trapped on the outside, many others
    believe they can become experts in a weekend. Just get a GPT API key, and that’s
    it—you’re done. This has led to a lot of fervor and hype, with a cool new demo
    popping up on social media every day. Most of these demos never become actual
    products—but not because people don’t want them.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 令人奇怪的是，尽管许多人认为他们被困在门外，但许多人其他人认为他们可以在周末成为专家。只需获取一个GPT API密钥，这就足够了——你完成了。这导致了很多热情和炒作，每天都有新的酷炫演示出现在社交媒体上。大多数这些演示从未成为实际的产品——但这并不是因为人们不想拥有它们。
- en: To understand this, let’s discuss IBM’s Watson, the world’s most advanced language
    model before GPT. Watson is a question-and-answering machine that crushed Jeopardy
    in 2011 against some of the best human contestants to ever appear on the show,
    Brad Rutter and Ken Jennings. Rutter was the highest-earning contestant ever to
    play the game show, and Jennings was so good at the game that he won a whopping
    74 times in a row. Despite facing these legends, it wasn’t even close. Watson
    won in a landslide. Jennings, in response to the loss, responded with the famous
    quote, “I, for one, welcome our new computer overlords.”[⁴](#footnote-68)
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一点，让我们讨论一下IBM的Watson，在GPT之前世界上最先进的语言模型。Watson是一款问答机器，在2011年击败了一些该节目有史以来最优秀的参赛者，布拉德·拉特和肯·詹宁斯。拉特是有史以来收入最高的游戏节目参赛者，而詹宁斯在游戏中表现得如此出色，以至于他连续赢得了74次胜利。尽管面对这些传奇人物，Watson还是以压倒性的优势获胜。詹宁斯在回应失败时，回应了那句著名的引言，“我，至少，欢迎我们新的电脑主宰者。”[⁴](#footnote-68)
- en: Watson was the first impressive foray into language modeling, and many companies
    were clamoring to take advantage of its capabilities. Starting in 2013, Watson
    started being released for commercial use. One of the biggest applications involved
    many attempts to integrate it into healthcare to solve various problems. However,
    none of these solutions ever really worked the way they needed to, and the business
    never became profitable. By 2022, Watson Health was sold off.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Watson是语言建模的第一次令人印象深刻的尝试，许多公司都争先恐后地想要利用其功能。从2013年开始，Watson开始被用于商业用途。其中最大的应用之一就是尝试将其整合到医疗保健中，以解决各种问题。然而，这些解决方案从未真正按照预期的方式工作，而且业务从未盈利。到2022年，Watson
    Health被出售。
- en: What we find when solving language-related problems is that building a prototype
    is easy; building a functioning product, on the other hand, is very, very difficult.
    There are just too many nuances to language. Many people wonder what made ChatGPT,
    which gained over a million clients in just five days, so explosive. Most of the
    answers we’ve heard would never satisfy an expert because ChatGPT wasn’t much
    more impressive than GPT-3 or other LLMs that had already been around for several
    years. Sam Altman of OpenAI once said in an interview that he didn’t think ChatGPT
    would get this much attention; he thought it would come with GPT-4’s release.[⁵](#footnote-69)
    So why was it explosive? In our opinion, the magic was that it was the first product
    to truly productionize LLMs—turning them from a demo into an actual product. It
    was something anyone could interact with, asking tough questions only to be amazed
    by how well it responded. A demo only has to work once, but the product has to
    work every time, even when millions of users are showing it to their friends,
    saying, “Check this out!” That magic is exactly what you can hope to learn from
    reading this book.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决语言相关问题时，我们发现构建原型很容易；然而，构建一个功能性的产品则非常、非常困难。语言中存在太多的细微差别。许多人都在 wonder，是什么让ChatGPT在仅仅五天内就获得了超过一百万的客户，变得如此火爆。我们听到的许多答案都无法让专家满意，因为ChatGPT并没有比GPT-3或其他已经存在了几年的LLMs更令人印象深刻。OpenAI的Sam
    Altman在一次采访中曾经说过，他认为ChatGPT不会得到这么多的关注；他以为它会随着GPT-4的发布而来。[⁵](#footnote-69) 那为什么它会如此火爆呢？在我们看来，其中的魔力在于它是第一个真正将LLMs商业化生产的产品——将它们从演示变成了实际的产品。它是任何人都可以与之互动的产品，提出棘手的问题，却惊讶于它如何出色地回应。演示只需要一次成功，但产品必须每次都成功，即使当数百万用户向他们的朋友展示它，说“看看这个！”时也是如此。这种魔力正是你通过阅读这本书可以希望学到的东西。
- en: 'We’re excited about writing this book. We are excited about the possibilities
    of bringing this magic to you so you can take it to the world. LLMs are at the
    intersection of many fields, such as linguistics, mathematics, computer science,
    and more. While knowing more will help you, being an expert isn’t required. Expertise
    in any of the individual parts only raises the skill ceiling, not the floor, to
    get in. Consider an expert in physics or music theory: they won’t automatically
    have the skills for music production, but they will be more prepared to learn
    it quickly. LLMs are a communication tool, and communicating is a skill just about
    everyone needs.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很兴奋地写这本书。我们很兴奋地能够将这种魔力带给你们，让你们可以将它带到全世界。LLMs处于许多领域的交汇点，如语言学、数学、计算机科学等。虽然了解更多会帮助你，但成为专家并不是必需的。在任何个别部分的专长只会提高技能的上限，而不是进入的门槛。考虑一下物理学或音乐理论的专家：他们不会自动拥有音乐制作技能，但他们将更有准备快速学习。LLMs是一种沟通工具，而沟通是一种几乎每个人都需要的技能。
- en: Like all other skills, your proximity and willingness to get involved are the
    two main blockers to knowledge, not a degree or ability to notate—these only shorten
    your journey toward being heard and understood. If you don’t have any experience
    in this area, it might be good to start by first developing an intuition around
    what an LLM is and needs by contributing to a project like OpenAssistant. If you’re
    a human, that’s exactly what LLMs need. By volunteering, you can start understanding
    what these models train on and why. If you fall anywhere, from no knowledge up
    to being a professional machine learning engineer, we’ll be imparting the knowledge
    necessary to shorten your time to understanding considerably. If you’re not interested
    in learning the theoretical underpinnings of the subject, we’ve got plenty of
    hands-on examples and projects to get your hands dirty.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 就像所有其他技能一样，你接近和参与的意愿是知识的主要障碍，而不是学位或记笔记的能力——这些只会缩短你被听到和理解的过程。如果你在这个领域没有任何经验，从首先通过参与像OpenAssistant这样的项目来培养对LLM是什么以及需要什么的直觉可能是个好主意。如果你是人类，这正是LLM所需要的。通过志愿服务，你可以开始了解这些模型训练的内容以及为什么。无论你是从零知识到成为专业机器学习工程师的任何位置，我们都会传授必要的知识，以显著缩短你理解所需的时间。如果你对学习该主题的理论基础不感兴趣，我们有很多动手的例子和项目，让你亲身体验。
- en: We’ve all heard a story by now of LLM hallucinations, but LLMs don’t need to
    be erratic. Companies like Lakera are working daily to improve security, while
    others like LangChain are making it easier to provide models with pragmatic context
    that makes them more consistent and less likely to deviate. Techniques such as
    RLHF and Chain of Thought further allow our models to align themselves with negotiations
    we’ve already accepted that people and models should understand from the get-go,
    such as basic addition and the current date, both of which are conceptually arbitrary.
    We’ll help you increase your model stability from a linguistic perspective so
    it will figure out not just the most likely outputs but also the most useful.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，我们都听说过LLM（大型语言模型）的幻觉故事，但LLM并不需要是随机的。像Lakera这样的公司每天都在努力提高安全性，而像LangChain这样的公司则使为模型提供实用上下文变得更加容易，这使得模型更加一致，不太可能偏离。RLHF（强化学习与人类反馈）和思维链等技术进一步允许我们的模型与我们已经接受的人机和模型应从一开始就理解的原则保持一致，例如基本的加法和当前日期，这些都是概念上任意设定的。我们将从语言学的角度帮助你提高模型稳定性，使其不仅能找出最可能的输出，还能找出最有用的输出。
- en: 'Something to consider as you venture further down this path is not only the
    security of what goes into your model/code but what comes out. LLMs can sometimes
    produce outdated, factually incorrect, or even copyrighted or licensed material,
    depending on what their training data contains. LLMs are unaware of any agreements
    people make about what is supposed to be a trade secret and what can be shared
    openly—that is, unless you tell them about those agreements during training or
    through careful prompting mechanisms during inference. Indeed, the challenges
    around prompt injection giving inaccurate information arise primarily due to two
    factors: users requesting information beyond the model’s understanding and model
    developers not fully predicting how users will interact with the models or the
    nature of their inquiries. If you had a resource that could help you get a head
    start on that second problem, it would be pretty close to invaluable, wouldn’t
    it?'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当你进一步探索这条道路时，需要考虑的不仅是输入到你的模型/代码中的安全性，还有输出内容的安全性。LLM有时可能会产生过时、事实错误，甚至可能是受版权或许可保护的材料，这取决于它们的训练数据包含的内容。LLM对人们就什么应该是商业机密以及什么可以公开分享达成的任何协议一无所知——除非你在训练期间或通过推理期间的仔细提示机制告诉它们这些协议。确实，围绕提示注入导致不准确信息的主要挑战主要源于两个因素：用户请求超出模型理解范围的信息，以及模型开发者没有完全预测用户将如何与模型互动或他们查询的性质。如果你有一个可以帮助你在这第二个问题上取得领先的资源，那将是非常宝贵的，不是吗？
- en: Lastly, we don’t want to artificially or untruthfully inflate your sense of
    hope with LLMs. They are resource intensive to train and run. They are hard to
    understand, and they are harder to get working how you want. They are new and
    not well-understood. The good news is that these problems are being actively worked
    on, and we’ve put in a lot of work finding implementations concurrent with this
    writing to actively lessen the burden of knowing everything about the entire deep-learning
    architecture. From quantization to Kubernetes, we’ll help you figure out everything
    you need to know to do this now with what you have. Maybe we’ll inadvertently
    convince you that it’s too much and you should just purchase from a vendor. Either
    way, we’ll help you every step of the way to get the results you need from this
    magical technology.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们不想通过LLM（大型语言模型）人为地或无根据地夸大你的希望感。它们训练和运行资源密集，难以理解，而且更难按照你的意愿工作。它们是新的，且尚未被充分理解。好消息是，这些问题正在积极解决，我们投入了大量工作，寻找与写作同时进行的实现方案，以积极减轻了解整个深度学习架构所需知识的负担。从量化到Kubernetes，我们将帮助你弄清楚你现在需要知道的一切，以便使用你所拥有的资源来完成这项工作。也许我们会无意中让你认为这太过复杂，你应该直接从供应商那里购买。无论如何，我们将帮助你每一步，以从这项神奇技术中获得你所需的结果。
- en: Summary
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: LLMs are exciting because they work within the same framework (language) as
    humans.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）令人兴奋，因为它们在与人相同的框架（语言）中工作。
- en: Society has been built on language, so effective language models have limitless
    applications, such as chatbots, programming assistants, video games, and AI assistants.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会建立在语言之上，因此有效的语言模型有无限的应用，例如聊天机器人、编程助手、视频游戏和人工智能助手。
- en: LLMs are excellent at many tasks and can even pass high-ranking medical and
    law exams.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）在许多任务上表现出色，甚至可以通过高级别的医学和法律考试。
- en: LLMs are wrecking balls, not hammers, and should be avoided for simple problems
    that require low latency or entail high risks.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）是破坏性的，而不是锤子，对于需要低延迟或涉及高风险的简单问题应避免使用。
- en: Reasons to buy include
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 购买LLM的原因包括
- en: Quickly getting up and running to conduct research and prototype use cases
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速启动并运行以进行研究和原型用例
- en: Easy access to highly optimized production models
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易访问高度优化的生产模型
- en: Access to vendors’ technical support and systems
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取供应商的技术支持和系统
- en: Reasons to build include
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立LLM的原因包括
- en: Getting a competitive edge for your business use case
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为你的业务用例获得竞争优势
- en: Keeping costs low and transparent
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持成本低且透明
- en: Ensuring the reliability of the model
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保模型的可靠性
- en: Keeping your data safe
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护你的数据安全
- en: Controlling model output on sensitive or private topics
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在敏感或私人主题上控制模型输出
- en: There is no technical moat preventing you from competing with larger companies,
    since open source frameworks and models provide the building blocks to pave your
    own path.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有技术壁垒阻止你与大型公司竞争，因为开源框架和模型提供了构建你自己的道路的基石。
- en: '[[1]](#footnote-source-1) WIRED, “It began as an AI-fueled dungeon game. Then
    it got much darker,” Ars Technica, May 8, 2021, [https://mng.bz/AdgQ](https://mng.bz/AdgQ).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1]](#footnote-source-1) WIRED, “它最初是一个由人工智能驱动的地牢游戏。然后它变得越发黑暗，”Ars Technica，2021年5月8日，[https://mng.bz/AdgQ](https://mng.bz/AdgQ)。'
- en: '[[2]](#footnote-source-2) 이코노미스트, “[단독] 우려가 현실로…삼성전자, 챗GPT 빗장 풀자마자 ‘오남용’ 속출,”
    이코노미스트 [“Concerns become reality: As soon as Samsung Electronics unblocks ChatGPT,
    ‘abuse’ continues”]. The Economist, March 30, 2023, [https://mng.bz/4p1v](https://mng.bz/4p1v).'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[[2]](#footnote-source-2) 《经济学人》，“[独家] 担忧成为现实…三星电子解除ChatGPT限制后‘滥用’现象频发”，《经济学人》[“担忧成为现实：三星电子一解除ChatGPT限制，‘滥用’现象便接连发生”]，2023年3月30日，[https://mng.bz/4p1v](https://mng.bz/4p1v)。'
- en: '[[3]](#footnote-source-3) A. Lowrey, “Borders bankruptcy: Done in by its own
    stupidity, not the Internet.,” Slate Magazine, July 20, 2011, [https://mng.bz/PZD5](https://mng.bz/PZD5).'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[[3]](#footnote-source-3) A. Lowrey，“边境破产：不是互联网的错，而是自己的愚蠢。”，《Slate杂志》，2011年7月20日，[https://mng.bz/PZD5](https://mng.bz/PZD5)。'
- en: '[[4]](#footnote-source-4) J. Best, “IBM Watson: The inside story of how the
    Jeopardy-winning supercomputer was born, and what it wants to do next,” TechRepublic,
    September 9, 2013, [https://mng.bz/JZ9Q](https://mng.bz/JZ9Q).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[[4]](#footnote-source-4) J. Best，“IBM Watson：揭秘赢得Jeopardy的超级计算机是如何诞生的，以及它接下来想做什么，”TechRepublic，2013年9月9日，[https://mng.bz/JZ9Q](https://mng.bz/JZ9Q)。'
- en: '[[5]](#footnote-source-5) “A conversation with OpenAI CEO Sam Altman; hosted
    by Elevate,” May 18, 2023, [https://youtu.be/uRIWgbvouEw](https://youtu.be/uRIWgbvouEw).'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[[5]](#footnote-source-5) “与OpenAI首席执行官Sam Altman的对话；由Elevate主持，”2023年5月18日，[https://youtu.be/uRIWgbvouEw](https://youtu.be/uRIWgbvouEw)。'
