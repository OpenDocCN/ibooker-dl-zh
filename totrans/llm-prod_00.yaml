- en: '1 *Words’ awakening: Why large language models have captured attention*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 *词汇的觉醒：为什么大型语言模型引起了关注*
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: What large language models are and what they can and cannot do
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言模型是什么，它们能做什么，不能做什么
- en: When you should and should not deploy your own large language models
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该在何时何时不部署自己的大型语言模型
- en: Large language model myths and the truths that lie behind them
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型语言模型的神话及其背后的真相
- en: Any sufficiently advanced technology is indistinguishable from magic.—Arthur
    C. Clarke
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 任何足够先进的技术都与魔法无法区分 —— 亚瑟·C·克拉克
- en: The year is 1450\. A sleepy corner of Mainz, Germany, unknowingly stands on
    the precipice of a monumental era. In Humbrechthof, a nondescript workshop shrouded
    in the town’s shadows pulsates with anticipation. It is here that Johannes Gutenberg,
    a goldsmith and innovator, sweats and labors amidst the scents of oil, metal,
    and determination, silently birthing a revolution. In the late hours of the night,
    the peace is broken intermittently by the rhythmic hammering of metal on metal.
    In the lamp-lit heart of the workshop stands Gutenberg’s decade-long labor of
    love—a contraption unparalleled in design and purpose.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 年份是1450年。德国美因茨的一个沉睡的角落，不知不觉地站在一个重大时代的边缘。在Humbrechthof，一个被城镇阴影笼罩的普通车间，充满了期待。正是在这里，约翰内斯·古腾堡，一位金匠和革新者，在油、金属和决心的气味中汗流浃背地劳作，默默地孕育着一场革命。在深夜时分，金属敲击金属的节奏性敲打不时打破宁静。在车间灯光照耀的中心，是古腾堡十年来的爱情结晶——一个设计独特、用途非凡的装置。
- en: This is no ordinary invention. Craftsmanship and creativity transform an assortment
    of moveable metal types, individually cast characters born painstakingly into
    a matrix. The flickering light dances off the metallic insignias. The air pulsates
    with the anticipation of a breakthrough and the heady sweetness of oil-based ink,
    an innovation from Gutenberg himself. In the stillness of the moment, the master
    printer squares his shoulders and, with unparalleled finesse, lays down a crisp
    sheet of parchment beneath the ink-loaded matrix, allowing his invention to press
    firmly and stamp fine print onto the page. The room adjusts to the symphony of
    silence, bated breaths hanging heavily in the air. As the press is lifted, it
    creaks under its own weight, each screech akin to a war cry announcing an exciting
    new world.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一项普通发明。工艺和创造力将各种可移动金属字型、一个个辛苦铸成的字符，组合成一个矩阵。闪烁的灯光在金属标志上舞动。空气中充满了突破的期待和基于油墨的浓郁甜味，这是古腾堡本人的创新。在那一刻的宁静中，这位大师印刷师挺直了肩膀，以无与伦比的技巧，在墨水充盈的矩阵下铺下一张清晰的羊皮纸，让他的发明紧紧压印，在页面上留下精细的印刷。房间调整到了沉默的交响乐，紧张的呼吸在空气中沉重地悬挂。当印刷机被抬起时，它因自身的重量而嘎吱作响，每一次尖叫都像是一声战斗的呐喊，宣布着一个激动人心的新世界的到来。
- en: With a flurry of motion, Gutenberg pulls from the press the first printed page
    and slams it flat onto the wooden table. He carefully examines each character,
    all of which are as bold and magnificent as the creator’s vision. The room drinks
    in the sight, absolutely spellbound. A mere sheet of parchment has become a testament
    to transformation. As the night gives way to day, he looks upon his workshop with
    invigorated pride. His legacy is born, echoing in the annals of history and forever
    changing the way information would take wings. Johannes Gutenberg, now the man
    of the millennium, emerges from the shadows, an inventor who dared to dream. His
    name is synonymous with the printing press, which is not just a groundbreaking
    invention but the catalyst of the modern world.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 古腾堡以一阵动作，从印刷机中取出第一张印刷页，并将其平铺在木桌上。他仔细检查每一个字符，它们都像创造者的愿景一样大胆而宏伟。房间中的每个人都沉浸在这景象中，完全被迷住了。一张普通的羊皮纸已成为变革的见证。当夜晚让位于白天时，他带着振奋的骄傲看着他的车间。他的遗产诞生了，在历史的长河中回响，永远改变了信息飞翔的方式。约翰内斯·古腾堡，现在成为千禧年的人物，从阴影中走出，一个敢于梦想的发明家。他的名字与印刷机同义，这不仅是一项开创性的发明，而且是现代世界的催化剂。
- en: As news of Gutenberg’s achievement begins to flutter across the continent, scholars
    from vast disciplines are yet to appreciate the extraordinary tool at their disposal.
    Knowledge and learning, once coveted treasures, are now within the reach of the
    common person. There were varied and mixed opinions surrounding that newfound
    access.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当古腾堡的成就的消息开始在大陆上飘扬时，来自各个学科的学者们还没有意识到他们手中的这个非凡工具。知识和学习，曾经是渴望的宝藏，现在对普通人来说触手可及。围绕这一新发现，意见各异，看法不一。
- en: In our time, thanks to the talent and industry of those from the Rhine, books
    have emerged in lavish numbers. A book that once would’ve belonged only to the
    rich—nay, to a king—can now be seen under a modest roof. … There is nothing nowadays
    that our children … fail to know.—Sebastian Brant
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在我们这个时代，多亏了莱茵河畔那些人的才能和勤奋，书籍的数量激增。曾经只有富人——不，只有国王才能拥有的书，现在可以在简陋的屋顶下看到。……如今，我们的孩子……似乎无所不知。——塞巴斯蒂安·布兰特
- en: Scholarly effort is in decline everywhere as never before. Indeed, cleverness
    is shunned at home and abroad. What does reading offer to pupils except tears?
    It is rare, worthless when it is offered for sale, and devoid of wit.—Egbert of
    Liege
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 学术努力在各个地方都在下降，前所未有。的确，聪明才智在国内和国外都被摒弃。阅读能为学生带来什么，除了泪水？当它被出售时，是罕见的、无价值的，而且缺乏智慧。——列日的大卫
- en: People have had various opinions on books throughout history. One thing we can
    agree on living in a time when virtual printing presses exist and books are ubiquitous
    is that the printing press changed history. While we weren’t actually there when
    Gutenberg printed the first page using his printing press, we have watched many
    play with large language models (LLMs) for the first time. The astonishment on
    their faces as they see it respond to their first prompt. Their excitement when
    challenging it with a difficult question only to see it respond as if it was an
    expert in the field—the light bulb moment when they realize they can use this
    to simplify their life or make themselves wealthy. We imagine this wave of emotions
    is but a fraction of that felt by Johannes Gutenberg. Being able to rapidly generate
    text and accelerate communication has always been valuable.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人们对于书籍的看法在历史上一直各不相同。在我们这样一个虚拟印刷机存在且书籍无处不在的时代，我们可以达成共识的是，印刷机改变了历史。虽然我们并没有亲眼目睹古腾堡使用他的印刷机打印出第一页，但我们见证了很多人第一次与大型语言模型（LLMs）互动。当他们看到它对他们的第一个提示做出反应时，脸上的惊讶。当他们用难题挑战它，却看到它像该领域的专家一样回应时，他们的兴奋——当他们意识到他们可以用它来简化自己的生活或让自己变得富有时，这就是灵光一闪的时刻。我们想象这种情绪的波涛只是约翰内斯·古腾堡所感受到的一小部分。能够快速生成文本和加速沟通始终是有价值的。
- en: 1.1 Large language models accelerating communication
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 大型语言模型加速沟通
- en: Every job has some level of communication. Often, this communication is shallow,
    bureaucratic, or political. We’ve often warned students and mentees that every
    job has its own paperwork. Something that used to be a passion can easily be killed
    by the day-to-day tedium and menial work that comes with it when it becomes a
    job. In fact, when people talk about their professions, they often talk them up,
    trying to improve their social standing, so you’ll rarely get the full truth.
    You won’t hear about the boring parts, and the day-to-day grind is conveniently
    forgotten.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 每个工作都有一定程度的沟通。通常，这种沟通是肤浅的、官僚的或政治性的。我们经常警告学生和门徒，每个工作都有自己的文书工作。曾经是激情的事物，很容易被随之而来的日常乏味和琐事所扼杀，当它变成工作的时候。事实上，当人们谈论他们的职业时，他们经常夸大其词，试图提高自己的社会地位，所以你很少能听到全部真相。你不会听到那些无聊的部分，而日常的艰辛则被方便地遗忘了。
- en: However, envision a world where we reduce the burden of monotonous work. A place
    where police officers no longer have to waste hours of each day filling out reports
    and could instead devote that time to community outreach programs. Or a world
    where teachers no longer work late into the night grading homework and preparing
    lesson plans, instead being able to think about and prepare customized lessons
    for individual students. Or even a world where lawyers would no longer be stuck
    combing through legal documents for days, instead being free to take on charity
    cases for causes that inspire them. When the communication burden, the paperwork
    burden, and the accounting burden are taken away, the job becomes more akin to
    what we sell it as.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，设想一个我们可以减少单调工作负担的世界。一个警察不再需要浪费每天数小时填写报告，而是可以将时间用于社区外展项目的地方。或者一个教师不再需要深夜批改作业和准备教案，而是能够思考并为个别学生准备定制课程的世界。甚至是一个律师不再被困在法律文件中数日，而是可以自由地接受那些激励他们的慈善案件的世界。当沟通负担、文书工作负担和会计负担被移除时，工作就更加接近我们所说的样子。
- en: For this, LLMs are the most promising technology to come along since, well,
    the printing press. For starters, they have completely upended the role and relationship
    between humans and computers, transforming what we believed they were capable
    of. They have already passed medical exams, the bar exam, and multiple theory
    of mind tests. They’ve passed both Google and Amazon coding interviews. They’ve
    gotten scores of at least 1410 out of 1600 on the SAT. One of the most impressive
    achievements to the authors is that GPT-4 has even passed the Advanced Sommelier
    exam, which makes us wonder how the LLM got past the practical wine-tasting portion.
    Indeed, their unprecedented accomplishments are coming at breakneck speed and
    often make us mere mortals feel a bit queasy and uneasy. What do you do with a
    technology that seems able to do anything?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  Med-PaLM 2 scored an 86.5% on the MedQA exam. You can see a list of exams
    passed in OpenAI’s GPT-4 paper at [https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf).
    Finally, Google interviewed ChatGPT as a test, and it passed ([https://mng.bz/x2y6](https://mng.bz/x2y6)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Passing tests is fun but not exactly helpful, unless our aim is to build the
    most expensive cheating machine ever, and we promise there are better ways to
    use our time. What LLMs are good at is language, particularly helping us improve
    and automate communication. This allows us to transform common bitter experiences
    into easy, enjoyable experiences. For starters, imagine entering your home where
    you have your very own personal JARVIS, as if stepping into the shoes of Iron
    Man, an AI-powered assistant that adds an unparalleled dynamic to your routine.
    While not quite to the same artificial general intelligence (AGI) levels as those
    portrayed by JARVIS in the Marvel movies, LLMs are powering new user experiences,
    from improving customer support to helping you shop for a loved one’s birthday.
    They know to ask you about the person, learn about their interests and who they
    are, find out your budget, and then make specialized recommendations. While many
    of these assistants are being put to good work, many others are simply chatbots
    that users can talk to and entertain themselves—which is important because even
    our imaginary friends are too busy these days. Jokes aside, these can create amazing
    experiences, allowing you to meet your favorite fictional characters like Harry
    Potter, Sherlock Holmes, Anakin Skywalker, or even Iron Man.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: What we’re sure many readers are interested in, though, is programming assistants,
    because we all know googling everything is actually one of the worst user experiences.
    Being able to write a few objectives in plain English and see a copilot write
    the code for you is exhilarating. We’ve personally used these tools to help us
    remember syntax, simplify and clean code, write tests, and learn a new programming
    language.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Video gaming is another interesting field in which we can expect LLMs to create
    a lot of innovation. Not only do they help the programmers create the game, but
    they also allow designers to create more immersive experiences. For example, talking
    to NPCs (nonplayer characters) will have more depth and intriguing dialogue. Picture
    games like Animal Crossing and Stardew Valley having near-infinite quests and
    conversations.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 电子游戏是另一个我们期待LLMs（大型语言模型）能带来大量创新的有趣领域。它们不仅帮助程序员创建游戏，还允许设计师创造更加沉浸式的体验。例如，与NPC（非玩家角色）的对话将更加深入和引人入胜。想象一下像动物之森和星露谷物语这样的游戏，拥有近乎无限的任务和对话。
- en: Consider other industries, like education, where there doesn’t ever seem to
    be enough teachers to go around, meaning our kids aren’t getting the one-on-one
    attention they need. An LLM assistant can help save the teacher time doing manual
    chores and serve as a private tutor for kids who are struggling. The corporate
    world is looking into LLMs for talk-to-your-data jobs—tasks such as helping employees
    understand quarterly reports and data tables—essentially giving everyone their
    own personal analyst. Sales and marketing divisions are guaranteed to take advantage
    of this marvelous innovation, for better or worse. The state of search engine
    optimization (SEO) will change a lot too since currently, it is mostly a game
    of generating content to hopefully make websites more popular, which is now super
    easy.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑其他行业，比如教育，似乎永远都不够教师，这意味着我们的孩子得不到他们需要的个别关注。一个LLM助手可以帮助教师节省做手工杂事的时间，并为有困难的孩子担任私人导师。企业界正在研究LLMs用于与数据交流的工作——比如帮助员工理解季度报告和数据表格——本质上为每个人提供自己的个人分析师。销售和营销部门肯定会利用这一卓越的创新，无论好坏。搜索引擎优化（SEO）的状态也将发生很大变化，因为目前，它主要是一场生成内容以希望使网站更受欢迎的游戏，而这现在变得超级简单。
- en: The preceding list is just a few of the common examples where companies are
    interested in using LLMs. People are using them for personal reasons too, such
    as writing music, poetry, and even books; translating languages; summarizing legal
    documents or emails; and even free therapy—which, yes, is an awful idea since
    LLMs are still dreadful at this. Just a personal preference, but we wouldn’t try
    to save a buck when our sanity is on the line. Of course, this leads us to the
    fact that people are already using LLMs for darker purposes like cheating, scams,
    and fake news to skew elections. At this point, the list has become rather long
    and varied, but we’ve only begun to scratch the surface of the possible. Really,
    since LLMs help us with communication, often it’s better to think, “What can’t
    they do?” than “What can they do?” Or better yet, “What shouldn’t they do?”
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 上述列表只是公司对使用LLMs感兴趣的一些常见例子。人们也出于个人原因使用它们，比如写音乐、诗歌，甚至书籍；翻译语言；总结法律文件或电子邮件；甚至提供免费治疗——是的，这是一个糟糕的想法，因为LLMs在这方面仍然很糟糕。这只是个人偏好，但我们不会在精神健康受到威胁时试图节省一分钱。当然，这导致了一个事实，即人们已经在使用LLMs进行更阴暗的目的，比如作弊、诈骗和虚假新闻来扭曲选举。此时，这个列表已经相当长且多样化，但我们只是刚刚触及了可能性的表面。实际上，由于LLMs帮助我们进行沟通，通常最好是思考“它们不能做什么？”而不是“它们能做什么？”或者更好，“它们不应该做什么？”
- en: Well, as a technology, there are certain restrictions and constraints. For example,
    LLMs are kind of slow. Of course, *slow* is a relative term, but responsive times
    are often measured in seconds, not milliseconds. We’ll dive deeper into this topic
    in chapter 3, but as an example, we probably won’t see them being used in autocomplete
    tasks anytime soon, which require blazingly fast inference to be useful. After
    all, autocomplete needs to be able to predict the word or phrase faster than someone
    types. In a similar fashion, LLMs are large, complex systems; we don’t need them
    for such a simple problem anyway. Hitting an autocomplete problem with an LLM
    isn’t just hitting the nail with a sledgehammer; it’s hitting it with a full-on
    wrecking ball. And just like it’s more expensive to rent a wrecking ball than
    to buy a hammer, an LLM will cost you more to operate. There are a lot of similar
    tasks for which we should consider the complexity of the problem we are trying
    to solve.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: There are also many complex problems that are often poorly solved with LLMs,
    such as predicting the future. No, we don’t mean with mystic arts but rather forecasting
    problems—acts like predicting the weather or when high tide will hit the ocean
    shore. These are actually problems we’ve solved, but we don’t necessarily have
    good ways to communicate how they have been solved. They are expressed through
    combinations of math solutions, like Fourier transforms and harmonic analysis,
    or black box ML models. Many problems fit into this category, like outlier prediction,
    calculus, or finding the end of the roll of tape.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: You also probably want to avoid using them for highly risky projects. LLMs aren’t
    infallible and make mistakes often. To increase creativity, we often allow for
    a bit of randomness in LLMs, which means you can ask an LLM the same question
    and get different answers. That’s risky. You can remove this randomness by doing
    what’s called turning down the temperature, but that might make the LLM useless
    depending on your needs. For example, you might decide to use an LLM to categorize
    investment options as good or bad, but do you want it to then make actual investment
    decisions based on its output? Not without oversight, unless your goal is to create
    a meme video.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, an LLM is just a model. It can’t be held accountable for losing
    your money, and really, it didn’t lose your money—you did by choosing to use it.
    Similar risky problems include filling out tax forms or getting medical advice.
    While an LLM could do these things, it won’t protect you from heavy penalties
    in an IRS audit like hiring a certified CPA would. If you take bad medical advice
    from an LLM, there’s no doctor you can sue for malpractice. However, in all of
    these examples, the LLM could potentially help practitioners perform their job
    roles better, both by reducing errors and improving speed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: When to use an LLM
  id: totrans-27
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Use them for
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Generating content
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Question-and-answer services
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chatbots and AI assistants
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text-to-something problems (diffusion, txt2img, txt23d, txt2vid, etc.)
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Talk-to-your-data applications
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anything that involves communication
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid using them for
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Latency-sensitive workloads
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simple projects
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Problems we don’t solve with words but with math or algorithms—forecasting,
    outlier prediction, calculus, etc.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Critical evaluations
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High-risk projects
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Language is not just a medium people use to communicate. It is the tool that
    made humans apex predators and gives every individual self-definition in their
    community. Every aspect of human existence, from arguing with your parents to
    graduating from college to reading this book, is pervaded by our language. Language
    models are learning to harness one of the fundamental aspects of being human and
    have the ability, when used responsibly, to help us with each and every one of
    those tasks. They have the potential to unlock dimensions of understanding both
    of ourselves and of others if we responsibly teach them how.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: LLMs have captured the world’s attention since their potential allows imaginations
    to run wild. LLMs promise so much, but where are all these solutions? Where are
    the video games that give us immersive experiences? Why don’t our kids have personal
    AI tutors yet? Why am I not Iron Man with my own personal assistant yet? These
    are the deep and profound questions that motivated us to write this book. Particularly,
    that last one keeps us up at night. So while LLMs can do amazing things, not enough
    people know how to turn them into actual products, and that’s what we aim to share
    in this book.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: This isn’t just a machine learning operations book. There are a lot of gotchas
    and pitfalls involved with making an LLM work in production because LLMs don’t
    work like traditional software solutions. Turning an LLM into a product that can
    interact coherently with your users will require an entire team and a diverse
    set of skills. Depending on your use case, you may need to train or finetune and
    then deploy your own model, or you may need to access one from a vendor through
    an API.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of which LLM you use, if you want to take full advantage of the technology
    and build the best user experience, you will need to understand how it works—not
    just on the math/tech side either, but also on the soft side, making it a good
    experience for your users. In this book, we’ll cover everything you need to make
    LLMs work in production. We’ll talk about the best tools and infrastructure, how
    to maximize their utility with prompt engineering, and other best practices like
    controlling costs. LLMs could be one step toward greater equality, so if you are
    thinking, “I don’t feel like the person this book is for,” please reconsider.
    This book is for the whole team and anyone who will be interacting with LLMs in
    the future.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/1-unnumb.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: Courtesy of SuperElmer, [https://www.facebook.com/SuperElmerDS](https://www.facebook.com/SuperElmerDS)
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We’re going to hit on a practical level everything that you’ll need for collecting
    and creating a dataset, training or finetuning an LLM on consumer or industrial
    hardware, and deploying that model in various ways for customers to interact with.
    While we aren’t going to cover too much theory, we will cover the process from
    end to end with real-world examples. At the end of this book, you will know how
    to deploy LLMs with some viable experience to back it up.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涉及你需要的一切，从收集和创建数据集，到在消费或工业硬件上训练或微调LLM，以及以各种方式部署该模型，以便客户与之交互。虽然我们不会过多涉及理论，但我们将通过实际案例从始至终地介绍整个过程。在这本书的结尾，你将知道如何部署LLMs，并有一些可行的经验作为支持。
- en: 1.2 Navigating the build-and-buy decision with LLMs
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 使用LLMs进行构建和购买决策的导航
- en: If you bought this book, you are likely already convinced of the overwhelming
    potential LLMs can have in your life and in your organization. Buying this book,
    then, is the first step to turning your dreams into a reality because none of
    it is possible until we know how to put these models into production. After all,
    if you talk to any entrepreneur or investor out there, they will tell you good
    ideas are a dime a dozen; what matters is execution to manifest those ideas. What
    we need to do is get these models into production, where they are readily available
    to do actual work for you.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你购买了这本书，你很可能已经确信LLMs（大型语言模型）在你的生活和组织中具有巨大的潜力。因此，购买这本书是把你梦想变成现实的第一步，因为除非我们知道如何将这些模型投入生产，否则这一切都不可能实现。毕竟，如果你和任何企业家或投资者交谈，他们都会告诉你好主意到处都是；重要的是执行，以实现这些想法。我们需要做的是将这些模型投入生产，让它们能够为你实际工作。
- en: 'There’s no getting around it and no need to sugarcoat it either: deploying
    LLMs into production is hard. Often, anything worth pursuing is. In this book,
    we aim to teach you everything you need to know to do it and give you some practical
    hands-on experience. But because it is so hard, it is mighty tempting to take
    a shortcut. Large corporations like OpenAI and Google have some great offerings
    of models to choose from. Why not just buy them? Let’s start by considering what
    they offer and when they are a good choice. Then we’ll take a look at the other
    side of the coin, where these offerings tend to fall flat.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 没有办法回避这一点，也不需要美化它：将LLMs投入生产是困难的。通常，任何值得追求的事情都是如此。在这本书中，我们旨在教你所有你需要知道的知识，并给你一些实际的操作经验。但是，由于它如此困难，所以走捷径是非常诱人的。像OpenAI和Google这样的大型企业提供了一些非常好的模型选择。为什么不直接购买呢？让我们先考虑他们提供的内容以及何时是好的选择。然后我们将看看硬币的另一面，这些提供往往不尽如人意。
- en: '1.2.1 Buying: The beaten path'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 购买：一条老路
- en: There are many great reasons to simply buy access to an LLM. First and foremost
    is the speed and flexibility accessing an API provides. Working with an API is
    an incredibly easy and cheap way to build a prototype and get your hands dirty
    quickly. In fact, it’s so easy that it only takes a few lines of Python code to
    start connecting to OpenAI’s API and using LLMs, as shown in listing 1.1\. Sure,
    there’s a lot that’s possible, but it would be a bad idea to invest heavily in
    LLMs only to find out they happen to fail in your specific domain. Working with
    an API allows you to fail fast. Building a prototype application to prove the
    concept and launching it with an API is a great place to get started.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多很好的理由只是购买LLM的访问权限。首先也是最重要的是，访问API提供的速度和灵活性。与API合作是一种极其简单且成本效益高的方式，可以快速构建原型并快速上手。事实上，它如此简单，以至于只需要几行Python代码就可以开始连接到OpenAI的API并使用LLMs，如列表1.1所示。当然，有很多可能的事情，但只投资LLMs却发现它们在你的特定领域失败，这绝对是一个糟糕的主意。与API合作让你能够快速失败。构建一个原型应用程序来证明概念，并使用API启动它，是一个很好的开始。
- en: Listing 1.1 A simple app calling OpenAI’s API
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表1.1 调用OpenAI API的简单应用
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Loads your API key from an environment variable'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 从环境变量中加载你的API密钥'
- en: '#2 This isn''t technically needed, as we are passing in the default key.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 这在技术上不是必需的，因为我们正在传递默认密钥。'
- en: Often, buying access to a model can give you a competitive edge. In many cases,
    it could very well be that the best model on the market is built by a company
    specializing in your domain using specialized datasets it has spent a fortune
    to curate. While you could try to compete and build your own, it may better serve
    your purposes to buy access to the model instead. Ultimately, whoever has the
    better domain-specific data to finetune on is likely to win, and that might not
    be you if this is a side project for your company. Curating data can be expensive,
    after all. It can save you a lot of work to go ahead and buy it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'This leads to the next point: buying is a quick way to access expertise and
    support. For example, OpenAI has spent a lot of time making their models safe
    with plenty of filtering and controls to prevent the misuse of their LLMs. They’ve
    already encountered and covered a lot of the edge cases so you don’t have to.
    Buying access to their model also gives you access to the system they’ve built
    around it.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Not to mention that the LLM itself is only half the problem when deploying it
    to production. There’s still an entire application you need to build on top of
    it. Sometimes buying OpenAI’s model has thrived over its competitors in not a
    small way due to its UX and some tricks like making the tokens look like they’re
    being typed. We’ll take you through how you can start solving for the UX in your
    use case, along with some ways you can prototype to give you a major head start
    in this area.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '1.2.2 Building: The path less traveled'
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Using an API is easy and, in most cases, likely the best choice. However, there
    are many reasons why you should aim to own this technology and learn how to deploy
    it yourself instead. While this path might be harder, we’ll teach you how to do
    it. Let’s dive into several of those reasons, starting with the most obvious:
    control.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Control
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the first companies to truly adopt LLMs as a core technology was a small
    video game company called Latitude. Latitude specializes in Dungeon and Dragons–like
    role-playing games that utilize LLM chatbots, and they have faced challenges when
    working with them. This shouldn’t come off as criticizing this company for their
    missteps, as they have contributed to our collective learning experience and were
    pioneers in forging a new path. Nonetheless, their story is a captivating and
    intriguing one—like a train wreck, we can’t help but keep watching.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Latitude’s first release was a game called AI Dungeon. At inception, it utilized
    OpenAI’s GPT-2 to create an interactive and dynamic storytelling experience. It
    quickly garnered a large gathering of players, who, of course, started to use
    it inappropriately. When OpenAI gave Latitude access to GPT-3, it promised an
    upgrade to the gaming experience; instead, what it got was a nightmare.[¹](#footnote-65)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: You see, with GPT-3, OpenAI added reinforcement learning from human feedback
    (RLHF), which greatly helps improve functionality, but this also meant OpenAI
    contractors were now looking at the prompts. That’s the human feedback part. And
    these workers weren’t too thrilled to read the filth the game was creating. OpenAI’s
    reps were quick to give Latitude an ultimatum. Either it needed to start censoring
    the players, or OpenAI would remove Latitude’s access to the model—which would
    have essentially killed the game and the company. With no other option, Latitude
    quickly added some filters, but the filtering system was too much of a band-aid,
    a buggy and glitchy mess. Players were upset at how bad the system was and unnerved
    to realize Latitude’s developers were reading their stories, completely oblivious
    to the fact that OpenAI was already doing so. It was a PR nightmare. And it wasn’t
    over.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 'OpenAI decided the game studio wasn’t doing enough; stonewalled, Latitude was
    forced to increase its safeguards and started banning players. Here’s the twist:
    the reason so many of these stories turned to smut was because the model had a
    preference for erotica. It would often unexpectedly transform harmless storylines
    into inappropriately risqué situations, causing the player to be ejected and barred
    from the game. OpenAI was acting as the paragon of purity, but it was their model
    that was the problem, which led to one of the most ironic and unjust problems
    in gaming history: players were getting banned for what the game did.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: So there they were—a young game studio just trying to make a fun game stuck
    between upset customers and a tech giant that pushed all the blame and responsibility
    onto it. If the company had more control over the technology, it could have gone
    after a real solution, like fixing the model instead of having to throw makeup
    on a pig.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: In this example, control may come off as your ability to finetune your model,
    and OpenAI now offers finetuning capabilities, but there are many fine-grained
    decisions that are still lost by using a service instead of rolling your own solution.
    For example, what training methodologies are used, what regions the model is deployed
    to, or what infrastructure it runs on. Control is also important for any customer
    or internal-facing tool. You don’t want a code generator to accidentally output
    copyrighted code or create a legal situation for your company. You also don’t
    want your customer-facing LLM to output factually incorrect information about
    your company or its processes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Control is your ability to direct and manage the operations, processes, and
    resources in a way that aligns with your goals, objectives, and values. If a model
    ends up becoming central to your product offering and the vendor unexpectedly
    raises its prices, there’s little you can do but pay it. If the vendor decides
    its model should give more liberal or conservative answers that no longer align
    with your values, you are just as stuck.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: The more central a technology is to your business plan, the more important it
    is to control it. This is why McDonald’s owns the real estate for its franchises
    and why Google, Microsoft, and Amazon all own their own cloud networks—and even
    why so many entrepreneurs build online stores through Shopify instead of using
    other platforms like Etsy or Amazon Marketplace. Ultimately, control is the first
    thing that’s lost when you buy someone else’s product. Keeping control will give
    you more options to solve future problems and will also give you a competitive
    edge.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Competitive edge
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the most valuable aspects of deploying your own models is the competitive
    edge it gives you over your competition. Customization allows you to train the
    model to be the best at one thing. For example, after the release of Bidirectional
    Encoder Representations from Transformers (BERT) in 2017, which is a transformer
    model architecture you could use to train your own model, there was a surge of
    researchers and businesses testing this newfound technology on their own data
    to worldwide success. At the time of writing, if you search the Hugging Face Hub
    for “BERT,” more than 13.7K models are returned, all of which people individually
    trained for their own purposes, aiming to create the best model for their task.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: One author’s personal experience in this area was training SlovenBERTcina after
    aggregating the largest (at the time) monolingual Slovak language dataset by scraping
    the Slovak National Corpus with permission, along with a bunch of other resources
    like the OSCAR project and the Europarl corpus. It never set any computational
    records and has never appeared in any model reviews or generated partnerships
    for the company the author worked for. It did, however, outperform every other
    model on the market on the tasks it trained on.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Chances are, neither you nor your company needs AGI to generate relevant insights
    from your data. In fact, if you invented an actual self-aware AGI and planned
    to only ever use it to crunch some numbers, analyze data, and generate visuals
    for PowerPoint slides once a week, that would definitely be reason enough for
    the AGI to eradicate humans. More than likely, you need exactly what this author
    did when he made SlovenBERTcina, a large language model that performs two to three
    tasks better than any other model on the market and doesn’t also share your data
    with Microsoft or other potential competitors. While some data is required to
    be kept secret for security or legal reasons, a lot of data should be guarded
    because it includes trade secrets.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: There are hundreds of open source LLMs for both general intelligence and foundational
    expertise on a specific task. We’ll hit some of our favorites in chapter 4\. Taking
    one of these open source alternatives and training it on your data to create a
    model that is the best in the world at that task will ensure you have a competitive
    edge in your market. It will also allow you to deploy the model your way and integrate
    it into your system to have the most effect.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Integrate anywhere
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s say you want to deploy an LLM as part of a choose-your-own-adventure–styled
    game that uses a device’s GPS location to determine story plots. You know your
    users are often going to go on adventures into the mountains, out at sea, and
    generally to locations where they are likely to experience poor service and lack
    of internet access. Hitting an API just isn’t going to work. Now, don’t get us
    wrong: deploying LLMs onto edge devices like in this scenario is still an exploratory
    subject, but it is possible; we will be showing you how in chapter 10\. Relying
    upon an API service is just not going to work for immersive experiences.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, using third-party LLMs and hitting an API adds integration and latency
    problems, requiring you to send data over the wire and wait for a response. APIs
    are great, but they are always slow and not always reliable. When latency is important
    to a project, it’s much better to have the service in-house. The previous section
    on competitive edge discussed two projects with edge computing as a priority;
    however, many more exist. LLAMA.cpp and ALPACA.cpp are two of the first such projects,
    and this space is innovating quicker than any others. Quantization into 4-bit,
    low-rank adaptation, and parameter-efficient finetuning are all methodologies
    recently created to meet these needs, and we’ll be going over each of these starting
    in chapter 3.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: When this author’s team first started integrating with ChatGPT’s API, it was
    both an awe-inspiring and humbling experience—awe-inspiring because it allowed
    us to quickly build some valuable tools, and humbling because, as one engineer
    joked, “When you hit the endpoint, you will get 503 errors; sometimes you get
    a text response as if the model was generating text, but I think that’s a bug.”
    Serving an LLM in a production environment—trying to meet the needs of so many
    clients—is no easy feat. However, deploying a model that’s integrated into your
    system allows you more control of the process, affording higher availability and
    maintainability than you can currently find on the market. This, of course, also
    allows you to better control costs.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: Costs
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Considering costs is always important because it plays a pivotal role in making
    informed decisions and ensuring the financial health of a project or an organization.
    It helps you manage budgets efficiently and make sure that resources are allocated
    appropriately. Keeping costs under control allows you to maintain the viability
    and sustainability of your endeavors in the long run.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, considering costs is crucial for risk management. When you understand
    the different cost aspects, you can identify potential risks and exert better
    control over them. This way, you can avoid unnecessary expenditures and ensure
    that your projects are more resilient to unexpected changes in the market or industry.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Finally, cost considerations are important for maintaining transparency and
    accountability. By monitoring and disclosing costs, organizations demonstrate
    their commitment to ethical and efficient operations to stakeholders, clients,
    and employees. This transparency can improve an organization’s reputation and
    help build trust.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: All of these apply as you consider building versus buying LLMs. It may seem
    immediately less costly to buy, as the costliest service widely used on the market
    currently is only $20 per month. Compared to an EC2 instance on AWS, just running
    that same model for inference (not even training) could run you up a bill of about
    $250k per year. This is where building has done its quickest innovation, however.
    If all you need is an LLM for a proof of concept, any of the projects mentioned
    in the Competitive Edge section will allow you to create a demo for only the cost
    of electricity to run the computer you are demoing on. They can spell out training
    easily enough to allow for significantly reduced costs to train a model on your
    own data, as low as $100 (yes, that’s the real number) for a model with 20 billion
    parameters. Another benefit is knowing that if you build your own, your cost will
    never go up like it very much will when paying for a service.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Security and privacy
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Consider the following case. You are a military staff member in charge of maintenance
    for the nuclear warheads in your arsenal. All the documentation is kept in a hefty
    manual. There’s so much information required to outline all the safety requirements
    and maintenance protocols that cadets are known to forget important information
    despite their best efforts. They often cut the wires before first removing the
    fuse ([https://youtu.be/UcaWQZlPXgQ](https://youtu.be/UcaWQZlPXgQ)). You decide
    to finetune an LLM model to be a personal assistant, giving directions and helping
    condense all that information to provide soldiers with exactly what they need
    when they need it. It’s probably not a good idea to upload those manuals to another
    company—understatement of the century—so you’re going to want to train something
    locally that’s kept secure and private.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: This scenario may sound farfetched, but when speaking to an expert working in
    analytics for a police department, they echoed this exact concern. Talking with
    them, they expressed how cool ChatGPT is and even had their whole team take a
    prompt engineering class to better take advantage of it but lamented that there
    was no way for their team to use it for their most valuable work—the sort of work
    that literally saves lives—without exposing sensitive data and conversations.
    Anyone in similar shoes should be eager to learn how to deploy a model safely
    and securely.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'You don’t have to be in the army or on a police force to handle sensitive data.
    Every company has important intellectual property and trade secrets that are best
    kept a secret. Having worked in the semiconductor, healthcare, and finance industries,
    we can tell you firsthand that paranoia and corporate espionage are part of the
    culture in these industries. Because of this, Samsung and other industry players
    locked down ChatGPT at first, preventing employees from using it, only later opening
    it up. Of course, it didn’t take long before several Samsung employees leaked
    confidential source code.[²](#footnote-66) Because OpenAI uses its users’ interactions
    to improve the model, that code is retained and could have been used to further
    train the model later on. That means that with the right prompt injection, anyone
    could potentially pull the code out of the model. A recent example goes even further:
    when any OpenAI model was prompted to repeat a word ad infinitum, it would start
    regurgitating training data, including all of the personally identifiable information
    (PII) that had snuck through the cleaning process.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'note  OpenAI’s privacy and usage policies have changed a lot over the course
    of this book''s writing. When ChatGPT was first introduced, it was done as a demo
    specifically so OpenAI could collect user interactions and improve the model.
    It pretty much didn’t have a privacy policy, and it had disclaimers saying such.
    As ChatGPT grew and became an actual product, this changed, as clients wanted
    more protection. For example, OpenAI changed its policies to better serve its
    customers and, since March 1, 2023, no longer uses customer API data to improve
    its models (see ChatGPT FAQ: [https://mng.bz/QV8Q](https://mng.bz/QV8Q)). The
    wording, of course, indicates that only data is sent through the API. It’s best
    to ask your lawyers where your company stands on using it. Regardless, the fact
    that terms of use have changed so much is just further proof you might want more
    control in this regard.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s not just code that can easily be lost. Business plans, meeting notes,
    confidential emails, and even potential patent ideas are at risk. Unfortunately,
    we know of a few companies that have started sending confidential data to ChatGPT,
    using that model to clean and extract PII. If this strikes you as potential negligent
    misuse, you’d be right. This methodology directly exposes customer data, not just
    to OpenAI, but to any and all third-party services they use (including AWS Mechanical
    Turk, Fiverr, and freelance workers) to perform the human feedback part of RLHF.
    Don’t get us wrong: it’s not necessarily a security or privacy problem if you
    use a third party to do data processing tasks even for sensitive data, but it
    should only be done with high levels of trust and contracts in place.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As you can see, there are lots of reasons why a company might want to own and
    build its own LLMs, including greater control, cutting costs, and meeting security
    and regulation requirements. Despite this, we understand that buying is easy,
    and building is much more difficult, so for many projects, it makes sense to buy.
    However, before you do, in figure 1.1, we share a flowchart of questions you should
    ask yourself first. Even though it’s the more difficult path, building can be
    much more rewarding.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/1-1.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 Questions you should ask yourself before making that build-vs.-buy
    decision
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'One last point we think these build-versus-buy conversations never seem to
    hone in on enough is “Por qué no los dos?” Buying gets you all the things building
    is bad at: time to market, relatively low cost, and ease of use. Building gets
    you everything buying struggles with: privacy, control, and flexibility. Research
    and prototyping phases could benefit very much from buying a subscription to GPT-4
    or Databricks in order to build something quick to help raise funding or get stakeholder
    buy-in. Production, however, often isn’t an environment that lends itself well
    to third-party solutions.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'Ultimately, whether you plan to build or buy, we wrote this book for you. Obviously,
    if you plan to build, there’s going to be a lot more you need to know about, so
    a majority of this book will be geared to these folks. In fact, we don’t need
    to belabor the point anymore: we’re going to teach you how to build in this book,
    but don’t let that stop you from doing the right thing for your company.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '1.2.3 A word of warning: Embrace the future now'
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All new technology meets resistance and has critics; despite this, technologies
    keep being adopted, and progress continues. In business, technology can give a
    company an unprecedented advantage. There’s no shortage of stories of companies
    failing because they didn’t adapt to new technologies. We can learn a lot from
    their failures.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Borders first opened its doors in 1971\. After developing a comprehensive inventory
    management system that included advanced analytic capabilities, it skyrocketed
    to become the second-largest book retailer in the world, only behind Barnes &
    Noble. Using this new technology, Borders disrupted the industry, allowing it
    to easily keep track of tens of thousands of books, opening large stores where
    patrons could peruse many more books than they could at smaller stores. The analytic
    capabilities helped it track which books were gaining popularity and gain better
    insights into its customers, allowing it to make better business decisions. It
    dominated the industry for over two decades.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'Borders, however, failed to learn from its own history, going bankrupt in 2011
    because of failing to adapt and being disrupted by technology: this time e-commerce.
    In 2001, instead of building its own platform and online store, it decided to
    outsource its online sales to Amazon.[³](#footnote-67) Many critics would say
    this decision was akin to giving your competitors the key to your business. While
    not exactly handing over its secret sauce, it was a decision that gave up Borders’
    competitive edge.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: For the next seven years, Borders turned a blind eye to the growing online sector,
    instead focusing on expanding its physical store presence, buying out competitors,
    and securing a coveted Starbucks deal. When Amazon released the Kindle in 2007,
    the book retail landscape completely changed. Barnes & Noble, having run its own
    online store, quickly pivoted and released the Nook to compete. Borders, however,
    did nothing or, in fact, could do nothing.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: By embracing e-commerce through a third party, Borders failed to develop the
    in-house expertise required to create a successful online sales strategy, leading
    to a substantial loss in market share. It eventually launched its own e-reader,
    Kobo, in late 2010, but it was too late to catch up. Its inability to fully understand
    and implement e-commerce technology effectively led to massive financial losses
    and store closures; ultimately, the company filed for bankruptcy in 2011.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: Borders is a cautionary tale, but there are hundreds more similar companies
    that failed to adopt new technology, to their own detriment. With a new technology
    as impactful as LLMs, each company has to decide on which side of the fence it
    wants to be. Does it delegate implementation and deployment to large FAANG-like
    corporations, relegating its job to just hitting an API, or does it take charge,
    preferring to master the technology and deploy it in-house?
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: The biggest lesson we hope to impart from this story is that technologies build
    on top of one another. E-commerce was built on top of the internet. Failing to
    build its own online store meant Borders failed to build the in-house technical
    expertise it needed to stay in the game when the landscape shifted. We see the
    same things with LLMs today because the companies that are best prepared to utilize
    them have already gathered expertise in machine learning and data science and
    have some idea of what they are doing.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: We don’t have a crystal ball that tells us the future, but many believe that
    LLMs are a revolutionary new technology, like the internet or electricity before
    it. Learning how to deploy these models, or failing to do so, may very well be
    the defining moment for many companies—not because doing so will make or break
    their company now, but because it may in the future when something even more valuable
    comes along that’s built on top of LLMs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Foraying into this new world of deploying LLMs may be challenging, but it will
    help your company build the technical expertise to stay on top of the game. No
    one really knows where this technology will lead, but learning about this technology
    will likely be necessary to avoid mistakes like those made by Borders.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many great reasons to buy your way to success, but there is at least
    one prevalent thought that is just absolutely wrong: it’s the myth that only large
    corporations can work in this field because it takes millions of dollars and thousands
    of GPUs to train these models, which creates this impenetrable moat of cash and
    resources the little guy can’t hope to cross. We’ll be talking about this more
    in the next section, but any company of any size can get started, and there’s
    no better time than now to do so.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 1.3 Debunking myths
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have all heard from large corporations and the current leaders in LLMs how
    incredibly difficult it is to train an LLM from scratch and how intense it is
    to try to finetune them. Whether from OpenAI, BigScience, or Google, they discuss
    large investments and the need for strong data and engineering talent. But how
    much of this is true, and how much of it is just a corporate attempt to create
    a technical moat?
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Most of these barriers start with the premise that you will need to train an
    LLM from scratch if you hope to solve your problems. Simply put, you don’t! Open
    source models covering many dimensions of language models are constantly being
    released, so more than likely, you don’t need to start from scratch. While it’s
    true that training LLMs from scratch is supremely difficult, we are still constantly
    learning how to do it and are able to automate the repeatable portions more and
    more. In addition, since this is an active field of research, frameworks and libraries
    are being released or updated daily and will help you start from wherever you
    currently are. Frameworks like oobabooga’s Gradio will help you run LLMs, and
    base models like Falcon 40B will be your starting point. All of it is covered.
    In addition, memos have circulated at large companies addressing the lack of a
    competitive edge that any organization currently holds over the open source community
    at large.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: A friend once confided, “I really want to get more involved in all this machine
    learning and data science stuff. It seems to be getting cooler every time I blink
    an eye. However, it feels like the only way to get involved is to go through a
    lengthy career change and go work for a FAANG. No, thank you. We’ve done our time
    at large companies, and they aren’t for us. But we hate feeling like we’re trapped
    on the outside.” This is the myth that inspired this book. We’re here to equip
    you with tools and examples to help you stop feeling trapped on the outside. We’ll
    help you go through the language problems that we’re trying to solve with LLMs,
    along with machine learning operation strategies to account for the sheer size
    of the models.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Oddly enough, while many believe they are trapped on the outside, many others
    believe they can become experts in a weekend. Just get a GPT API key, and that’s
    it—you’re done. This has led to a lot of fervor and hype, with a cool new demo
    popping up on social media every day. Most of these demos never become actual
    products—but not because people don’t want them.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: To understand this, let’s discuss IBM’s Watson, the world’s most advanced language
    model before GPT. Watson is a question-and-answering machine that crushed Jeopardy
    in 2011 against some of the best human contestants to ever appear on the show,
    Brad Rutter and Ken Jennings. Rutter was the highest-earning contestant ever to
    play the game show, and Jennings was so good at the game that he won a whopping
    74 times in a row. Despite facing these legends, it wasn’t even close. Watson
    won in a landslide. Jennings, in response to the loss, responded with the famous
    quote, “I, for one, welcome our new computer overlords.”[⁴](#footnote-68)
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Watson was the first impressive foray into language modeling, and many companies
    were clamoring to take advantage of its capabilities. Starting in 2013, Watson
    started being released for commercial use. One of the biggest applications involved
    many attempts to integrate it into healthcare to solve various problems. However,
    none of these solutions ever really worked the way they needed to, and the business
    never became profitable. By 2022, Watson Health was sold off.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: What we find when solving language-related problems is that building a prototype
    is easy; building a functioning product, on the other hand, is very, very difficult.
    There are just too many nuances to language. Many people wonder what made ChatGPT,
    which gained over a million clients in just five days, so explosive. Most of the
    answers we’ve heard would never satisfy an expert because ChatGPT wasn’t much
    more impressive than GPT-3 or other LLMs that had already been around for several
    years. Sam Altman of OpenAI once said in an interview that he didn’t think ChatGPT
    would get this much attention; he thought it would come with GPT-4’s release.[⁵](#footnote-69)
    So why was it explosive? In our opinion, the magic was that it was the first product
    to truly productionize LLMs—turning them from a demo into an actual product. It
    was something anyone could interact with, asking tough questions only to be amazed
    by how well it responded. A demo only has to work once, but the product has to
    work every time, even when millions of users are showing it to their friends,
    saying, “Check this out!” That magic is exactly what you can hope to learn from
    reading this book.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re excited about writing this book. We are excited about the possibilities
    of bringing this magic to you so you can take it to the world. LLMs are at the
    intersection of many fields, such as linguistics, mathematics, computer science,
    and more. While knowing more will help you, being an expert isn’t required. Expertise
    in any of the individual parts only raises the skill ceiling, not the floor, to
    get in. Consider an expert in physics or music theory: they won’t automatically
    have the skills for music production, but they will be more prepared to learn
    it quickly. LLMs are a communication tool, and communicating is a skill just about
    everyone needs.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Like all other skills, your proximity and willingness to get involved are the
    two main blockers to knowledge, not a degree or ability to notate—these only shorten
    your journey toward being heard and understood. If you don’t have any experience
    in this area, it might be good to start by first developing an intuition around
    what an LLM is and needs by contributing to a project like OpenAssistant. If you’re
    a human, that’s exactly what LLMs need. By volunteering, you can start understanding
    what these models train on and why. If you fall anywhere, from no knowledge up
    to being a professional machine learning engineer, we’ll be imparting the knowledge
    necessary to shorten your time to understanding considerably. If you’re not interested
    in learning the theoretical underpinnings of the subject, we’ve got plenty of
    hands-on examples and projects to get your hands dirty.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: We’ve all heard a story by now of LLM hallucinations, but LLMs don’t need to
    be erratic. Companies like Lakera are working daily to improve security, while
    others like LangChain are making it easier to provide models with pragmatic context
    that makes them more consistent and less likely to deviate. Techniques such as
    RLHF and Chain of Thought further allow our models to align themselves with negotiations
    we’ve already accepted that people and models should understand from the get-go,
    such as basic addition and the current date, both of which are conceptually arbitrary.
    We’ll help you increase your model stability from a linguistic perspective so
    it will figure out not just the most likely outputs but also the most useful.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'Something to consider as you venture further down this path is not only the
    security of what goes into your model/code but what comes out. LLMs can sometimes
    produce outdated, factually incorrect, or even copyrighted or licensed material,
    depending on what their training data contains. LLMs are unaware of any agreements
    people make about what is supposed to be a trade secret and what can be shared
    openly—that is, unless you tell them about those agreements during training or
    through careful prompting mechanisms during inference. Indeed, the challenges
    around prompt injection giving inaccurate information arise primarily due to two
    factors: users requesting information beyond the model’s understanding and model
    developers not fully predicting how users will interact with the models or the
    nature of their inquiries. If you had a resource that could help you get a head
    start on that second problem, it would be pretty close to invaluable, wouldn’t
    it?'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we don’t want to artificially or untruthfully inflate your sense of
    hope with LLMs. They are resource intensive to train and run. They are hard to
    understand, and they are harder to get working how you want. They are new and
    not well-understood. The good news is that these problems are being actively worked
    on, and we’ve put in a lot of work finding implementations concurrent with this
    writing to actively lessen the burden of knowing everything about the entire deep-learning
    architecture. From quantization to Kubernetes, we’ll help you figure out everything
    you need to know to do this now with what you have. Maybe we’ll inadvertently
    convince you that it’s too much and you should just purchase from a vendor. Either
    way, we’ll help you every step of the way to get the results you need from this
    magical technology.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs are exciting because they work within the same framework (language) as
    humans.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Society has been built on language, so effective language models have limitless
    applications, such as chatbots, programming assistants, video games, and AI assistants.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are excellent at many tasks and can even pass high-ranking medical and
    law exams.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are wrecking balls, not hammers, and should be avoided for simple problems
    that require low latency or entail high risks.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reasons to buy include
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quickly getting up and running to conduct research and prototype use cases
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy access to highly optimized production models
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to vendors’ technical support and systems
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Reasons to build include
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting a competitive edge for your business use case
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping costs low and transparent
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring the reliability of the model
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping your data safe
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Controlling model output on sensitive or private topics
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no technical moat preventing you from competing with larger companies,
    since open source frameworks and models provide the building blocks to pave your
    own path.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[[1]](#footnote-source-1) WIRED, “It began as an AI-fueled dungeon game. Then
    it got much darker,” Ars Technica, May 8, 2021, [https://mng.bz/AdgQ](https://mng.bz/AdgQ).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[[2]](#footnote-source-2) 이코노미스트, “[단독] 우려가 현실로…삼성전자, 챗GPT 빗장 풀자마자 ‘오남용’ 속출,”
    이코노미스트 [“Concerns become reality: As soon as Samsung Electronics unblocks ChatGPT,
    ‘abuse’ continues”]. The Economist, March 30, 2023, [https://mng.bz/4p1v](https://mng.bz/4p1v).'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[[3]](#footnote-source-3) A. Lowrey, “Borders bankruptcy: Done in by its own
    stupidity, not the Internet.,” Slate Magazine, July 20, 2011, [https://mng.bz/PZD5](https://mng.bz/PZD5).'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[[4]](#footnote-source-4) J. Best, “IBM Watson: The inside story of how the
    Jeopardy-winning supercomputer was born, and what it wants to do next,” TechRepublic,
    September 9, 2013, [https://mng.bz/JZ9Q](https://mng.bz/JZ9Q).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[[5]](#footnote-source-5) “A conversation with OpenAI CEO Sam Altman; hosted
    by Elevate,” May 18, 2023, [https://youtu.be/uRIWgbvouEw](https://youtu.be/uRIWgbvouEw).'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
