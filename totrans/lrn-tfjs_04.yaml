- en: Chapter 3\. Introducing Tensors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章 引入张量
- en: “Whoa!”
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “哇！”
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Keanu Reeves *(Bill & Ted’s Excellent Adventure*)
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: —基努·里维斯（《比尔和特德的冒险》）
- en: We’ve mentioned the word *tensor* a few times, and it resides as the predominant
    word in TensorFlow.js, so it’s time we get to know what these structures are.
    This critical chapter will give you hands-on experience with the fundamental concept
    of managing and accelerating data, which is at the heart of teaching machines
    with data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经多次提到*张量*这个词，它是TensorFlow.js中的主要词汇，所以是时候了解这些结构是什么了。这一关键章节将让您亲身体验管理和加速数据的基本概念，这是教机器学习的核心。
- en: 'We will:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将：
- en: Explain the concept and terminology of tensors
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释张量的概念和术语
- en: Create, read, and destroy tensors
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建、读取和销毁张量
- en: Practice concepts of structured data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习结构化数据的概念
- en: Take the leap into utilizing tensors to build something useful
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跨越使用张量来构建有用的东西的鸿沟
- en: Take your time with this chapter if you’re new to tensors. Being comfortable
    with this aspect of data will help you be comfortable with machine learning altogether.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对张量还不熟悉，请花些时间阅读本章。熟悉数据的这一方面将有助于您全面了解机器学习。
- en: Why Tensors?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要使用张量？
- en: We live in a world full of data, and deep down, we all know it ends in 1s and
    0s. To many of us, this happens quite magically. You take a photo with your phone,
    and some complex binary file gets created. Then, you swipe up and down, and our
    binary file changes from JPG to PNG within an instant. Thousands of unknown bytes
    are generated and destroyed in microseconds as files resize, reformat, and, for
    you hip kids, filter. You can’t be mollycoddled anymore. As you venture into actually
    touching, feeling, and feeding data, you have to wave goodbye to ignorant bliss.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生活在一个充满数据的世界中，我们都知道数据最终都是由1和0组成的。对于我们许多人来说，这似乎是一种魔法。你用手机拍照，就会生成一些复杂的二进制文件。然后，你上下滑动，我们的二进制文件在瞬间从JPG变成PNG。成千上万个未知的字节在微秒内生成和销毁，文件调整大小、重新格式化，对于你这些时髦的孩子，还有滤镜。你不能再被宠坏了。当你开始实际接触、感受和处理数据时，你必须告别无知的幸福。
- en: 'To quote the 1998 movie *Blade*:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 引用1998年电影《刀锋》中的一句台词：
- en: “You better wake up. The world you live in is nothing but a sugarcoated topping.
    There is another world beneath it.”
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “你最好醒醒。你生活的世界只是一层糖衣。下面还有另一个世界。”
- en: OK, it’s like that but not as intense. To train an AI, you’ll need to make sure
    your data is uniform, and you’ll need to understand and see it. You’re not training
    your AI to do the task of decoding PNGs and JPGs uniformly; you’re training it
    on the decoded and imitated versions of what’s actually in a photo.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，就像那样，但没有那么激烈。要训练一个人工智能，您需要确保您的数据是统一的，并且您需要理解和看到它。您不是在训练您的人工智能来统一解码PNG和JPG文件；您是在训练它对照片中实际内容的解码和模仿版本。
- en: This means images, music, statistics, and whatever else you’re using in your
    TensorFlow.js models all need a uniform and optimized data format. Ideally, our
    data would be converted into numeric containers that quickly scale and work directly
    with calculation optimizations in the GPU or Web Assembly. You need something
    clean and straightforward for our informational data in and out. These containers
    should be unopinionated so they can hold anything. Welcome to tensors!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着图像、音乐、统计数据以及您在TensorFlow.js模型中使用的任何其他内容都需要统一和优化的数据格式。理想情况下，我们的数据应该转换为数字容器，这些容器可以快速扩展，并直接与GPU或Web
    Assembly中的计算优化一起工作。您需要为我们的信息数据提供清晰简单的输入和输出。这些容器应该是无偏见的，可以容纳任何内容。欢迎来到张量的世界！
- en: Tip
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Understanding the use and properties of tensors is an ongoing exercise for even
    the most adept TensorFlow.js expert. While this chapter serves as an excellent
    introduction, you shouldn’t feel laggardly for having difficulty with wielding
    tensors. This chapter can serve as a reference as you progress.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是最熟练的TensorFlow.js专家，理解张量的用途和属性也是一个持续的练习。虽然本章作为一个出色的介绍，但如果您在使用张量方面遇到困难，也不必感到懈怠。随着您的进步，本章可以作为一个参考。
- en: Hello, Tensors
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你好，张量
- en: Tensors are collections of data in a structured type. It’s nothing new for a
    framework to convert everything to numbers, but it might be a new concept to realize
    that it’s up to you to choose how the data is ultimately formed.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 张量是一种结构化类型的数据集合。将一切转换为数字对于一个框架来说并不新鲜，但意识到最终数据如何形成取决于您可能是一个新概念。
- en: As mentioned in [Chapter 1](ch01.html#the_chapter_1), all data needs to be distilled
    into numbers for the machines to understand it. Tensors are the preferred format
    of information, and they even have small abstractions for nonnumeric types. They
    are like electrical signals from the physical world to our AI’s brain. While there’s
    no specification of how your data should be structured, you do need to stay consistent
    to keep your signals organized so our brain can see the same pattern over and
    over. People generally organize their data in groups, like arrays and multidimensional
    arrays.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[第1章](ch01.html#the_chapter_1)中提到的，所有数据都需要转化为数字，以便机器能够理解。张量是首选的信息格式，它们甚至为非数值类型提供了小的抽象。它们就像来自物理世界的电信号传输到我们人工智能大脑中一样。虽然没有规定数据应该如何结构化，但您需要保持一致以保持信号有序，这样我们的大脑就可以一遍又一遍地看到相同的模式。人们通常将他们的数据组织成组，比如数组和多维数组。
- en: But what is a tensor? A *tensor*, as defined mathematically, is simply a structured
    set of values of any dimension. Ultimately, this resolves to an optimized grouping
    of data as numbers that are ready for calculation. That means, mathematically
    speaking, a traditional JavaScript array is a tensor, a 2D array is a tensor,
    and a 512D array is a tensor. TensorFlow.js tensors are the embodiment of these
    mathematical structures that hold the accelerated signals that feed data into
    and out of a machine learning model.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但是张量是什么？从数学上定义，*张量*只是任意维度的一组结构化数值。最终，这将解决为计算准备好的数据的优化分组。这意味着，从数学角度来看，传统的JavaScript数组是一个张量，2D数组是一个张量，512D数组也是一个张量。TensorFlow.js张量是这些数学结构的具体体现，它们保存着加速信号，将数据输入和输出到机器学习模型中。
- en: If you’re familiar with multidimensional arrays in JavaScript, you should feel
    right at home with the syntax for tensors. As you add a new dimension to each
    array, it’s often said you are increasing the *rank* of a tensor.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: Creating Tensors
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regardless of how you imported TensorFlow.js, the code in this book assumes
    you’ve consolidated the library to a variable named `tf`, which will be used to
    represent TensorFlow.js in all examples.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can read along or write the code from scratch, or even run these fundamental
    examples in the browser-based `/tfjs` solution available with the book source
    code. For simplicity, we’ll be avoiding the repetition of the `<script>` or `import`
    tags required to set up these examples and instead simply write the shared code.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: To create your first tensor, we’ll keep things simple, and you’ll build it with
    a 1D JavaScript array ([Example 3-1](#create_tensor_example)). The array syntax
    and structure are carried over to tensors.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-1\. Creating your first tensors
  id: totrans-29
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_introducing_tensors_CO1-1)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '`tf.tensor` creates a 1D tensor if passed a 1D array. It would create a 2D
    tensor if passed a 2D array.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_introducing_tensors_CO1-2)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '`tf.tensor1d` creates a 1D tensor if passed a 1D array. It would error if passed
    a 2D array.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: This code creates a 1D tensor data structure of seven numbers in memory. Now
    those seven numbers are ready for manipulation, accelerated operations, or simply
    input. However, I’m sure you noticed we supplied two ways to perform the same
    action.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: The second method provides an extra level of runtime checking since you’ve defined
    the expected dimensionality. Determining the desired dimensionality is useful
    when you’re looking to ensure the number of dimensions in the data you’re working
    with. Methods exist for verifying up to six dimensions with `tf.tensor6d`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we’ll mostly be working with the generic `tf.tensor`, but if you
    find yourself deep into a complex project, don’t forget you can save yourself
    the headache of receiving unexpected dimensions by explicitly identifying your
    desired dimensionality of a tensor.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: As an extra note, while the tensors in [Example 3-1](#create_tensor_example)
    were an array of natural numbers, the default data type to store numbers is Float32\.
    Floating-point numbers (that’s numbers with decimal places, e.g., 2.71828) are
    quite dynamic and impressive. They can usually handle most numbers you’ll need
    and be ready for values between. Unlike JavaScript arrays, a tensor’s data type
    must be homogeneous (all the same type). These types can be only `Float32`, `Int32`,
    bool, `complex64`, or string, with no mixing between.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: If you’d like to enforce that your tensor is created as a particular type, feel
    free to utilize the third parameter of the `tf.tensor` function, which explicitly
    defines the tensor’s type structure.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_introducing_tensors_CO2-1)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: This tensor is created as a `Float32` tensor. The third parameter was redundant
    in this case.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_introducing_tensors_CO2-2)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: The resulting tensor is Int32, and without the third parameter, it would have
    been a `Float32`.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_introducing_tensors_CO2-3)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: The resulting tensor is a Boolean tensor.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_introducing_tensors_CO2-4)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: The resulting tensor is an Int32 tensor, with the Boolean values cast to `0`
    for false, and `1` for true. So, the variable guess contains the data `[1, 0,
    0]`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_introducing_tensors_CO2-5)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: You might think this wild array will error, but each of the input values gets
    converted to its corresponding `Float32` with the resulting tensor data `[1, 3.1415927,
    0]`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: How can you identify the tensor type that was created? Just like any JavaScript
    array, tensors are equipped with methods to explain their properties. Useful properties
    include length (`size`), dimensionality (`rank`), and data type (`dtype`).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s apply what we’ve learned:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_introducing_tensors_CO3-1)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introducing_tensors_CO3-1)'
- en: This creates a successful tensor. You should know the data type, dimension,
    and size.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个成功的张量。您应该知道数据类型，维度和大小。
- en: '[![2](assets/2.png)](#co_introducing_tensors_CO3-2)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introducing_tensors_CO3-2)'
- en: Since you’re using `tensor1d` to create a rank-two tensor, this will throw and
    cause the `catch` to run and log a message.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您正在使用`tensor1d`创建一个秩为二的张量，这将导致`catch`运行并记录一条消息。
- en: '[![3](assets/3.png)](#co_introducing_tensors_CO3-3)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_introducing_tensors_CO3-3)'
- en: The simple array is rank one, so it will print `1`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 简单数组的秩为一，因此它将打印`1`。
- en: '[![4](assets/4.png)](#co_introducing_tensors_CO3-4)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_introducing_tensors_CO3-4)'
- en: The size is the length of the array and will print `7`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 大小是数组的长度，将打印`7`。
- en: '[![5](assets/5.png)](#co_introducing_tensors_CO3-5)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_introducing_tensors_CO3-5)'
- en: The tensor’s data type from an array of numbers will print `float32`.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从数字数组的张量数据类型将打印`float32`。
- en: Congratulations on creating your first few tensors! It’s safe to say that being
    a master of tensors is at the core of taming data for TensorFlow.js. These structured
    buckets of values are the foundation for getting data into and back out of machine
    learning.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 祝贺您创建了您的第一批张量！可以肯定地说，掌握张量是驯服TensorFlow.js数据的核心。这些结构化的值桶是将数据输入和输出机器学习的基础。
- en: Tensors for Data Exercises
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据练习的张量
- en: Let’s say you want to make an AI to play tic-tac-toe (noughts & crosses to my
    friends across the pond). As always with data, it’s time to get a coffee or tea
    and think of the right way to convert real-world data to tensor data.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您想制作一个AI来玩井字游戏（对于我在池塘对岸的朋友来说，这是零和叉）。与数据一样，现在是时候喝杯咖啡或茶，思考将真实世界数据转换为张量数据的正确方法了。
- en: You could store images of games, strings of tutorials, or simply the Xs and
    Os of the game. Images and tutorials would be pretty impressive, but for now,
    let’s just consider the idea of storing a game board’s state. There are only nine
    possible boxes to play in, so a simple array of nine values should represent any
    given state of the board.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以存储游戏图像，教程字符串，或者只是游戏中的X和O。图像和教程可能会令人印象深刻，但现在，让我们只考虑存储游戏板状态的想法。只有九个可能的方框可供玩耍，因此九个值的简单数组应该代表棋盘的任何给定状态。
- en: Should the values read left to right and top to bottom? It rarely matters as
    long as you’re consistent. All encodings are made up. However, keep in mind a
    tensor resolves to numbers! This means that while you can store strings “X” and
    “O,” they would have to turn into numbers anyway. Let’s store our Xs and Os by
    mapping them to some kind of numeric value that makes sense. Does that mean you
    just assign one of them to 0 and the other to 42? I’m sure you can find a strategy
    that appropriately reflects the game state.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 值应该从左到右，从上到下读取吗？只要您保持一致，很少有关系。所有编码都是虚构的。但是，请记住张量解析为数字！这意味着虽然您可以存储字符串“X”和“O”，但它们最终还是会变成数字。让我们通过将它们映射到某种有意义的数字值来存储我们的X和O。这是否意味着您只需将其中一个分配为0，另一个分配为42？我相信您可以找到一个适当反映游戏状态的策略。
- en: Let’s evaluate the state of an active game for an exercise. Take a moment to
    review the grid of a match in progress, as shown in [Figure 3-1](#ttt_example).
    How could this be converted to tensors and numbers?
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们评估一个活动游戏的状态作为练习。花点时间回顾一下正在进行中的比赛的网格，如[图3-1](#ttt_example)所示。如何将其转换为张量和数字？
- en: '![TicTacToe Game](assets/ltjs_0301.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![TicTacToe Game](assets/ltjs_0301.png)'
- en: Figure 3-1\. A game with data
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1。带有数据的游戏
- en: Perhaps the board displayed here could be read and represented as a one-dimensional
    tensor. You could read the values left to right, top to bottom. As for numbers,
    let’s choose -1, 0, and 1 to represent the three possible values for any square.
    [Table 3-1](#value_number_table) shows the lookup for each possible value.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 也许这里显示的棋盘可以被读取并表示为一维张量。您可以从左到右，从上到下读取值。至于数字，让我们选择-1、0和1来表示任何一个方格的三个可能值。[表3-1](#value_number_table)显示了每个可能值的查找。
- en: Table 3-1\. Value-to-number table
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-1。值到数字表
- en: '| Board value | Tensor value |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 棋盘值 | 张量值 |'
- en: '| --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| X | 1 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| X | 1 |'
- en: '| O | -1 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| O | -1 |'
- en: '| Empty | 0 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 空 | 0 |'
- en: 'This would create a tensor like so: `[1, 0, 0, 0, -1, 0, 1, 0, 0]`. Or, it
    would create a 2D tensor, like so: `[[1, 0, 0],[0, -1, 0],[1, 0, 0]]`.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个张量，如下所示：`[1, 0, 0, 0, -1, 0, 1, 0, 0]`。或者，它将创建一个2D张量，如下所示：`[[1, 0, 0],[0,
    -1, 0],[1, 0, 0]]`。
- en: Now that you have a goal, let’s write some code to convert the board into a
    tensor. We’ll even explore the additional parameters of tensor creation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 既然您有了一个目标，让我们编写一些代码将棋盘转换为张量。我们甚至将探索张量创建的附加参数。
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_introducing_tensors_CO4-1)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introducing_tensors_CO4-1)'
- en: The second parameter of a tensor can identify the desired shape of the input
    data. Here, you convert the 1D array into a 2D tensor by specifying you would
    like the data to be rank-two structured as 3 x 3.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 张量的第二个参数可以标识输入数据的期望形状。在这里，通过指定希望数据为3 x 3的秩二结构，将1D数组转换为2D张量。
- en: '[![2](assets/2.png)](#co_introducing_tensors_CO4-2)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introducing_tensors_CO4-2)'
- en: The third parameter of the tensor identifies the data type you would like to
    use over the inferred data type. Since you are storing round numbers, you can
    specify the type `int32`. However, the range of the default `float32` type is
    massive and can comfortably handle our numbers.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 张量的第三个参数标识您想要在推断的数据类型上使用的数据类型。由于您正在存储整数，因此可以指定类型`int32`。但是，默认的`float32`类型的范围非常大，可以轻松处理我们的数字。
- en: When you’re creating tensors to represent data, it’s up to you to decide how
    you’re formatting the input data and what the resulting tensor structure should
    be. As you grasp the concepts of machine learning, you are always honing your
    intuition of what kind of data works best.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当您创建用于表示数据的张量时，您可以决定如何格式化输入数据以及生成的张量结构应该是什么。随着您掌握机器学习的概念，您始终在磨练哪种数据效果最佳的直觉。
- en: We’ll come back to this tic-tac-toe problem later in this book.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的后面回到这个井字棋问题。
- en: Tensors on Tour
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 巡回张量
- en: We’re going to get deeper into tensors as the book progresses, so it’s essential
    to take a moment and discuss why they’re so important. Without understanding the
    magnitude of the calculations we’re leveraging, it’s hard to understand the benefits
    of leaving the safety of the familiar JavaScript variables and engine for little
    old math.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 随着本书的进展，我们将深入研究张量，因此现在是时候花点时间讨论它们为什么如此重要了。如果不了解我们正在利用的计算的规模，很难理解离开熟悉的JavaScript变量和引擎去使用老旧的数学的好处。
- en: Tensors Provide Speed
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量提供速度
- en: Now that you know you can make tensors and represent data as tensors, what’s
    the benefit of performing this conversion? We’ve mentioned that calculations with
    tensors are optimized by the TensorFlow.js framework. When you convert JavaScript
    arrays of numbers to tensors, you can perform matrix operations at breakneck speeds,
    but what does that really mean?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道你可以制作张量并将数据表示为张量，那么进行这种转换有什么好处呢？我们已经提到，使用张量进行计算是由TensorFlow.js框架优化的。当你将JavaScript数字数组转换为张量时，你可以以极快的速度执行矩阵运算，但这到底意味着什么呢？
- en: Computers are excellent at doing a single calculation, and there are benefits
    to performing mass groupings of calculations. Tensors are engineered for an immense
    number of side-by-side calculations. If you’ve ever performed matrix and vector
    calculations by hand, you can start to appreciate the benefits of accelerated
    calculations.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机在进行单个计算方面表现出色，并且进行大量计算有其好处。张量被设计用于大量并行计算。如果你曾经手动执行过矩阵和向量计算，你就会开始意识到加速计算的好处。
- en: Tensors Provide Direct Access
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量提供直接访问
- en: Without machine learning, you can still use tensors to make 3D graphics, content
    recommendation systems, and beautiful [iterated function systems (IFSs)](https://oreil.ly/jjnvk)
    like the Sierpiński triangle illustrated in [Figure 3-2](#sierpinski).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 即使没有机器学习，你仍然可以使用张量制作3D图形、内容推荐系统以及美丽的[迭代函数系统（IFSs）](https://oreil.ly/jjnvk)，比如[图3-2](#sierpinski)中所示的谢尔宾斯基三角形。
- en: '![Sierpiński triangle](assets/ltjs_0302.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![谢尔宾斯基三角形](assets/ltjs_0302.png)'
- en: 'Figure 3-2\. IFS example: the Sierpiński triangle'
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2. IFS示例：谢尔宾斯基三角形
- en: There are plenty of libraries out there for images, sound, 3D models, video,
    and more. They all have one thing in common. Despite all the formats that exist,
    the libraries get you data in a universal format. Tensors are like that raw, unrolled
    data format, and with that access you can build, read, or predict anything you’d
    like.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多关于图像、声音、3D模型、视频等的库。它们都有一个共同点。尽管存在各种格式，但这些库会将数据以通用格式提供给你。张量就像那种原始、展开的数据格式，通过这种访问，你可以构建、读取或预测任何你想要的东西。
- en: You can even use these advanced structures to modify image data (you begin doing
    this in [Chapter 4](ch04.html#the_chapter_4)). You’ll start having more fun with
    tensor functions after you’ve graduated from the basics.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你甚至可以使用这些高级结构来修改图像数据（你将在[第4章](ch04.html#the_chapter_4)开始这样做）。在掌握了基础知识后，你将开始更多地享受张量函数。
- en: Tensors Batch Data
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量批处理数据
- en: In the data realm, you might find yourself looping through mountains of data
    and worrying about text editors crashing. Tensors are optimized for batch processing
    at high speeds. The small project at the end of this chapter has only four users
    to keep things simple, but any production environment needs to be ready to handle
    hundreds of thousands.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据领域，你可能会发现自己在循环处理大量数据并担心文本编辑器崩溃。张量被优化用于高速批处理。本章末尾的小项目只有四个用户，以保持简单，但任何生产环境都需要准备好处理数十万的数据。
- en: Most of the benefits of tensors will be recognized when you ask trained models
    to perform the calculations to predict human-like operations in milliseconds.
    You’ll start to see examples of this as early as [Chapter 5](ch05.html#the_chapter_5).
    We’ve identified that tensors are impressive structures that bring a lot of acceleration
    and mathematical power to JavaScript, so it makes sense that you’ll commonly use
    this beneficial structure in batches.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当你要求经过训练的模型在毫秒内执行类似人类操作的计算时，你将意识到张量的大部分好处。你将在[第5章](ch05.html#the_chapter_5)中早早看到这些例子。我们已经确定张量是令人印象深刻的结构，为JavaScript带来了大量加速和数学能力，因此你通常会在批处理中使用这种有益的结构。
- en: Tensors in Memory
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存中的张量
- en: Tensor speed comes with an overhead cost. Usually, when we’re done with a variable
    in JavaScript, the memory is cleanly removed when all references to that variable
    are completed. This is called *automatic garbage detection and collection* (AGDC),
    and it happens without most JavaScript developers understanding or caring how
    this works. However, your tensors don’t get that same kind of automatic care.
    They persist long after the variable that uses them has been collected.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 张量速度是有代价的。通常，当我们在JavaScript中完成一个变量时，当所有对该变量的引用完成时，内存会被干净地移除。这被称为*自动垃圾检测和收集*（AGDC），大多数JavaScript开发人员在不理解或关心这是如何工作的情况下就会发生。然而，你的张量并没有得到同样类型的自动关照。它们会在使用它们的变量被收集后继续存在。
- en: Deallocating Tensors
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 释放张量
- en: Because tensors survive garbage collection, they behave differently from standard
    JavaScript and have to be accounted for and deallocated manually. Even if a variable
    is garbage-collected in JavaScript, the associated tensor is then orphaned in
    memory. You can access the current count and size using `tf.memory()`. This function
    returns an object with a report of active tensors.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 由于张量在垃圾回收中幸存，它们的行为与标准JavaScript不同，必须手动进行核算和释放。即使在JavaScript中一个变量被垃圾回收，与之关联的张量仍然会在内存中被孤立。你可以使用`tf.memory()`来访问当前计数和大小。这个函数返回一个报告活动张量的对象。
- en: The code in [Example 3-2](#source_memory_leak) illustrates noncollected tensor
    memory.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例3-2](#source_memory_leak)中的代码展示了未收集的张量内存。'
- en: Example 3-2\. Tensors left in memory
  id: totrans-107
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例3-2. 内存中遗留的张量
- en: '[PRE4]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The code from [Example 3-2](#source_memory_leak) will result in printing the
    following in the logs:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例3-2](#source_memory_leak)中的代码将在日志中打印以下内容：'
- en: '[PRE5]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Since you already know tensors are for handling large accelerated data, the
    idea of leaving these sizable chunks in memory is a problem. With one small loop,
    you could leak an entire computer’s available RAM and GPU.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Fortunately, all tensors and models have a `.dispose()` method that purges a
    tensor from memory. When you call `.dispose()` on a tensor, the `numTensors` will
    go down by the number of tensors you just released.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: This does mean you will have to think of tensors as managed in two ways, yielding
    four possible states. [Table 3-2](#tensor_var_table) shows all the combinations
    of what happens when JavaScript variables and TensorFlow.js tensors are created
    and destroyed.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-2\. Tensor states
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Tensor live | Tensor disposed |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
- en: '| **JavaScript variable is live** | This variable is live; you can read the
    tensor. | An error will be raised if you attempt to use this tensor. |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: '| **JavaScript variable has no reference** | This is a memory leak. | This
    is a properly destroyed tensor. |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
- en: To put it succinctly, keep your variables and your tensors alive to access them,
    and when you’re done, dispose the tensor and do not attempt to access it.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Automatic Tensor Cleanup
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fortunately, tensors do have an auto-clean option called `tidy()`. You can use
    `tidy` to create a functional encapsulation that will clean all tensors that aren’t
    returned or flagged for being kept with `keep()`. We’ll do a demo in a moment
    to help you grasp `tidy`, and we’ll be using it throughout the book.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll get used to cleaning up tensors in no time. Make sure to study the following
    code, which will demonstrate `tidy()` and `keep()` in action:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_introducing_tensors_CO6-1)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: The `tidy` method takes a synchronous function and monitors the tensors created
    in this enclosure. You cannot use an async function or promise here. If you’re
    going to need anything async, you will have to call `.dispose` explicitly.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_introducing_tensors_CO6-2)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: All four tensors are effectively loaded into memory.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_introducing_tensors_CO6-3)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Even though you haven’t called `dispose` explicitly, `tidy` has properly destroyed
    two of the created tensors (the two that weren’t kept or returned). If you try
    to access them now, you will get an error.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_introducing_tensors_CO6-4)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Explicitly destroy the tensor that you saved with `tf.keep` from inside `tidy`.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_introducing_tensors_CO6-5)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Explicitly destroy the tensor that you returned from `tidy`.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: If all of that makes sense, you’ve learned the practice of creating and removing
    tensors from their magical place in memory.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Tensors Come Home
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s worth noting that you can even mix tensors and JavaScript where applicable.
    The code in [Example 3-3](#mix_tensor_code) creates a normal JavaScript array
    of tensors.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-3\. Mixing JS and tensors
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The result of [Example 3-3](#mix_tensor_code) is an array of 10 tensors, with
    values `[0,0,0]` up to `[9,9,9]`. Unlike creating a 2D tensor to hold these values,
    you access a particular tensor with ease by retrieving a normal JavaScript index
    in the array. So if you want `[4,4,4]`, you can get it with `tensorArray[4]`.
    You can then destroy the whole collection from memory with a simple `tf.dispose(tensorArray)`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: After the dust settles, we’ve learned how to create and remove tensors, but
    we’re missing the critical part where tensors return their data to JavaScript.
    Tensors are great for large calculations and speed, but JavaScript has its benefits
    too. With JavaScript you can iterate, grab a specific index, or perform a world
    of NPM library calculations that are far more cumbersome in tensor form.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: It’s safe to say that after you’ve reaped the benefits of calculating with a
    tensor, you’ll always need the results of that data to end up back in JavaScript.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving Tensor Data
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you try to print a tensor to the console, you can see the object, but not
    the underlying data values. To print a tensor’s data, you can call the tensor’s
    `.print()` method, but that will send the values directly to `console.log` and
    not a variable. While viewing the values of a tensor is helpful to the developer,
    we’ll need to ultimately get these values into JavaScript variables to use them.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您尝试将张量打印到控制台，您可以看到对象，但看不到底层数据值。要打印张量的数据，您可以调用张量的`.print()`方法，但这将直接将值发送到`console.log`而不是一个变量。查看张量的值对开发人员是有帮助的，但我们最终需要将这些值带入JavaScript变量中以便使用。
- en: There are two ways you retrieve tensors. Each of these methods has a synchronous
    method and an asynchronous method. First, if you’d like your data to be delivered
    in the same multidimensional array structure, you can use `.array()` for an asynchronous
    result or simply use `.arraySync()` for a sync value. Second, if you’d like to
    keep your values with extreme precision and flattened to a 1D typed array, you
    can use the synchronous `dataSync()` and an asynchronous method `data()`.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以检索张量。每种方法都有一个同步方法和一个异步方法。首先，如果您希望数据以相同的多维数组结构传递，您可以使用`.array()`获得异步结果，或者简单地使用`.arraySync()`获得同步值。其次，如果您希望保持极高精度的值，并将其展平为1D类型化数组，您可以使用同步的`dataSync()`和异步方法`data()`。
- en: 'The following code explores converting, printing, and resolving tensors using
    the methods described earlier:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码探讨了使用先前描述的方法转换、打印和解析张量并进行张量操作的过程：
- en: '[PRE8]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](assets/1.png)](#co_introducing_tensors_CO7-1)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introducing_tensors_CO7-1)'
- en: 'This log shows the JavaScript structure that holds the tensor and its associated
    properties. You can see the shape, and `isDisposedInternal` is false because it
    hasn’t been disposed, but this serves as a pointer to the data rather than containing
    the data. This log prints the following:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这个日志显示了保存张量及其相关属性的JavaScript结构。您可以看到形状，`isDisposedInternal`为false，因为它尚未被处理，但这只是一个指向数据的指针，而不是包含数据。这个日志打印如下：
- en: '[PRE9]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![2](assets/2.png)](#co_introducing_tensors_CO7-2)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introducing_tensors_CO7-2)'
- en: 'Calling `.print` on the tensor gives us an actual printout of the internal
    value directly to the console. This prints the following:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在张量上调用`.print`会直接将内部值的实际打印输出到控制台。这个日志打印如下：
- en: '[PRE10]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[![3](assets/3.png)](#co_introducing_tensors_CO7-3)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_introducing_tensors_CO7-3)'
- en: '`.arraySync` gives us the values of the 2D tensor back as a 2D JavaScript array.
    This log prints the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '`.arraySync`将2D张量的值作为2D JavaScript数组返回给我们。这个日志打印如下：'
- en: '[PRE11]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![4](assets/4.png)](#co_introducing_tensors_CO7-4)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_introducing_tensors_CO7-4)'
- en: '`.dataSync` gives us the values of the 2D tensor as a 1D [Float32Array](https://oreil.ly/ozV2H)
    object, effectively flattening the data. Logging a typed array looks like an object
    with indices as properties. This log prints:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`.dataSync`给我们提供了2D张量的值作为一个1D [Float32Array](https://oreil.ly/ozV2H)对象，有效地将数据展平。记录一个类型化数组看起来像一个具有索引作为属性的对象。这个日志打印：'
- en: '[PRE12]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now you know how to manage tensors. You can take any JavaScript data and bring
    it into TensorFlow.js tensors for manipulation and then bring it back out cleanly
    when you’re done.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您知道如何管理张量了。您可以将任何JavaScript数据带入TensorFlow.js张量进行操作，然后在完成后将其清晰地带出来。
- en: Tensor Manipulation
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 张量操作
- en: It’s time to cash in on the value of moving all this data around. You now know
    how to move large amounts of data to and from tensors, but let’s get the perks
    of having done such a process. Machine learning models are driven by math. Any
    mathematical process that relies on linear algebra is going to benefit from tensors.
    You will also benefit because you don’t have to write any complex mathematical
    operations.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候充分利用移动所有这些数据的价值了。您现在知道如何将大量数据移动到张量中，但让我们享受这个过程带来的好处。机器学习模型是由数学驱动的。任何依赖于线性代数的数学过程都将受益于张量。您也将受益，因为您不必编写任何复杂的数学运算。
- en: Tensors and Mathematics
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量和数学
- en: Let’s say you had to multiply the contents of one array by another. In JavaScript,
    you’d have to write some iterative code. Additionally, if you’re familiar with
    matrix multiplication, you know that code isn’t as simple as you first thought.
    No developer at any level should resolve linear algebra for tensor manipulation.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您必须将一个数组的内容乘以另一个数组。在JavaScript中，您必须编写一些迭代代码。此外，如果您熟悉矩阵乘法，您会知道该代码并不像您最初想的那样简单。任何级别的开发人员都不应该为张量操作解决线性代数。
- en: Remember how to multiply matrices correctly? I forgot, too.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得如何正确地相乘矩阵吗？我也忘了。
- en: <math><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>91</mn></mtd>
    <mtd><mn>82</mn></mtd> <mtd><mn>13</mn></mtd></mtr> <mtr><mtd><mn>15</mn></mtd>
    <mtd><mn>23</mn></mtd> <mtd><mn>62</mn></mtd></mtr> <mtr><mtd><mn>25</mn></mtd>
    <mtd><mn>66</mn></mtd> <mtd><mn>63</mn></mtd></mtr></mtable></mfenced> <mi>X</mi>
    <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>23</mn></mtd>
    <mtd><mn>83</mn></mtd></mtr> <mtr><mtd><mn>33</mn></mtd> <mtd><mn>12</mn></mtd>
    <mtd><mn>5</mn></mtd></mtr> <mtr><mtd><mn>7</mn></mtd> <mtd><mn>23</mn></mtd>
    <mtd><mn>61</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mo>?</mo></mrow></math>
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>91</mn></mtd>
    <mtd><mn>82</mn></mtd> <mtd><mn>13</mn></mtd></mtr> <mtr><mtd><mn>15</mn></mtd>
    <mtd><mn>23</mn></mtd> <mtd><mn>62</mn></m></mtr> <mtr><mtd><mn>25</mn></mtd>
    <mtd><mn>66</mn></m></mtd> <mtd><mn>63</mn></m></mtr></mtable></mfenced> <mi>X</mi>
    <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>23</mn></mtd>
    <mtd><mn>83</mn></mtd></mtr> <mtr><mtd><mn>33</mn></mtd> <mtd><mn>12</m></mtd>
    <mtd><mn>5</mn></m></mtr> <mtr><mtd><mn>7</mn></mtd> <mtd><mn>23</mn></mtd> <mtd><mn>61</mn></m></mtr></mtable></mfenced>
    <mo>=</mo> <mo>?</mo></mrow></math>
- en: It’s not as simple as multiplying each number by the corresponding position;
    as some of you may recall, there’s multiplication and addition involved. Calculating
    the top-left value would be 91 x 1 + 82 x 33 + 13 x 7 = 2888\. Now do that eight
    more times for each index of the new matrix. The JavaScript to calculate that
    simple multiplication isn’t completely trivial.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 将每个数字乘以相应位置并不像你们中的一些人可能想的那样简单；因为涉及到乘法和加法。计算左上角的值将是 91 x 1 + 82 x 33 + 13 x 7
    = 2888。现在对新矩阵的每个索引重复八次这样的计算。计算这种简单乘法的JavaScript并不完全琐碎。
- en: 'Tensors have mathematical benefits. I don’t have to write any code to perform
    the previous calculation. While writing custom code would not be complicated,
    it would be unoptimized and redundant. Useful, scalable mathematical operations
    are builtin. TensorFlow.js makes linear algebra accessible and optimized for structures
    like tensors. I can get a speedy answer for the previous matrix with the following
    code:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In [Chapter 2](ch02.html#the_chapter_2) the Toxicity detector downloaded megabytes
    and megabytes of numbers that are used in each classification calculation. The
    act of handling these large calculations in milliseconds is the power behind tensors.
    While we will continue to expand on the benefits of calculations in tensors, the
    whole reason for TensorFlow.js is that the complexity of such a large calculation
    is the domain of the framework and not the programmer.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Recommending Tensors
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the skills you’ve learned so far, you can construct a simple example of
    how TensorFlow.js can handle calculations for a real-world scenario. The following
    example has been chosen as an illustration of the power of tensors that welcomes
    the elite as well as the mathematical avoiders.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-172
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This section is probably the furthest you’ll get into mathematics. If you’d
    like to dig further into the linear algebra and calculus that fuels machine learning,
    there’s a fantastic free [online course, offered by Stanford and taught by Andrew
    Ng,](https://oreil.ly/OhvzW) that I recommend.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Let’s build something real with some tensor data. You’ll do a simple group of
    calculations to identify some user preferences. These systems are often called
    *recommendation engines*. You might be familiar with recommendation engines as
    they suggest everything from what you should buy to what movie you should watch
    next. These algorithms are at the heart of digital product giants like YouTube,
    Amazon, and Netflix. Recommendation engines are quite popular with any business
    that sells anything and could probably fill a book by themselves. We’ll be implementing
    a simple “content-based” recommendation system. Use your imagination because in
    a production system these tensors are significantly larger.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what you’ll do, at a high level:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Ask users to rank bands from `1` to `10`.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Any unknown bands get a `0`.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bands and music styles will be our “features.”
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the matrix dot product to identify what styles each user likes!
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Let’s get started creating a recommender! This small dataset will serve as an
    example of what you need. As you’ll notice, you mix JavaScript arrays with tensors
    in the code. It’s quite common for labels to remain in JavaScript and calculations
    to be pushed into tensors. This not only keeps tensors focused on numbers; it
    also has the benefit of internationalizing the tensor results. The labels are
    the only language-dependent part of this operation. You’ll see this theme continue
    in several examples throughout the book and in the real world of practical machine
    learning.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the data:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_introducing_tensors_CO8-1)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: The four name labels are simply stored in a normal JavaScript array.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_introducing_tensors_CO8-2)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: You’ve asked our users to rate seven bands.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_introducing_tensors_CO8-3)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Some simple music genres can be used to describe our seven bands, again in a
    JavaScript array.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_introducing_tensors_CO8-4)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: This is our first tensor, a rank-two description of each user’s vote from `1`
    to `10`, with “I don’t know this band” as `0`.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_introducing_tensors_CO8-5)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: This tensor is also a 2D tensor that identifies the genres that match each given
    band. Each line index represents an encoding of true/false for the genres it can
    be classified as.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Now you have all the data you need in tensors. As a quick review, you can see
    the way the information is organized. By reading the `user_votes` variable, you
    can see each user’s votes. For example, you can see user `0`, which maps to Gant,
    has rated Nirvana a `10` and Apashe `7`, while Jed has given Backstreet Boys a
    `10`.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经拥有了张量中所需的所有数据。快速回顾一下，你可以看到信息的组织方式。通过阅读`user_votes`变量，你可以看到每个用户的投票。例如，你可以看到用户`0`，对应Gant，给Nirvana评了`10`分，Apashe评了`7`分，而Jed给了Backstreet
    Boys`10`分。
- en: The `band_feats` variable maps each band to the genres they fulfill. For example,
    the second band at index `1` is Nine Inch Nails and has a positive scoring for
    Grunge and Industrial styles of music. To keep this example simple, you’re using
    a binary `1` and `0` per genre, but a normalized scale of numbers would work here,
    too. In other words, `[1, 1, 0, 0, 0, 0]` would represent Grunge and Rock for
    the 0th band, which is Nirvana.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`band_feats`变量将每个乐队映射到它们满足的流派。例如，索引`1`处的第二个乐队是Nine Inch Nails，对Grunge和工业音乐风格有积极评分。为了简单起见，你使用了每种流派的二进制`1`和`0`，但在这里也可以使用一种标准化的数字比例。换句话说，`[1,
    1, 0, 0, 0, 0]`代表了Grunge和Rock对于第0个乐队，也就是Nirvana。'
- en: 'Next, you’ll calculate each user’s favorite genres based on their votes:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将根据他们的投票计算每个用户最喜欢的流派：
- en: '[PRE15]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now `user_feats` contains a dot product of the user’s votes across the features
    of each band. The result from our print will look like this:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在`user_feats`包含用户在每个乐队的特征上的点积。我们打印的结果将如下所示：
- en: '[PRE16]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This tensor shows the value of the features (in this case, genres) of each user.
    User `0`, which aligns with Gant, has their highest value as `27` at index `0`,
    which means their top preferred genre from the surveyed data is Grunge. This data
    looks pretty good. Using this tensor, you can identify each user’s preferred tastes.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这个张量显示了每个用户特征（在本例中是流派）的价值。用户`0`，对应Gant，其最高价值在索引`0`处为`27`，这意味着他们在调查数据中最喜欢的流派是Grunge。这些数据看起来相当不错。使用这个张量，你可以确定每个用户的喜好。
- en: While the data is in tensor form, you can use a method called `topk` to help
    us identify the top values for each user with size *k*. To get the top *k* tensors
    or simply identify where the top values are via identifying their indices, you
    can call the function `topk` with the desired tensor and size. For this exercise,
    you’ll set *k* to be the full feature set size.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数据以张量形式存在，但你可以使用一个叫做`topk`的方法来帮助我们识别每个用户的前*k*个值。要获取前*k*个张量或者仅仅通过识别它们的索引来确定前*k*个值的位置，你可以调用带有所需张量和大小的函数`topk`。在这个练习中，你将把*k*设置为完整特征集大小。
- en: 'Finally, let’s take this data home to JavaScript. The code to do this can be
    written like so:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们把这些数据带回JavaScript。编写这段代码可以这样写：
- en: '[PRE17]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[![1](assets/1.png)](#co_introducing_tensors_CO9-1)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introducing_tensors_CO9-1)'
- en: You are returning the index tensor to a rank-two JavaScript array for the results.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 你将索引张量返回到一个二维JavaScript数组以获取结果。
- en: '[![2](assets/2.png)](#co_introducing_tensors_CO9-2)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introducing_tensors_CO9-2)'
- en: You are mapping the indices back to musical genres.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 你正在将索引映射回音乐流派。
- en: 'The resulting log looks like this:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 结果日志如下所示：
- en: '[PRE18]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the results, you can see Todd should check out more Industrial music, and
    Jed should brush up on his Boy Bands. Both will be happy with their recommendations.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在结果中，你可以看到Todd应该多听工业音乐，而Jed应该加强对男孩乐队的了解。两者都会对他们的推荐感到满意。
- en: What did you just do?
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你刚刚做了什么？
- en: You successfully loaded data into tensors in a way that makes sense, and then
    you applied a mathematical calculation to the entire set, rather than an iterative
    approach across each person. Once you got your answers, you sorted the entire
    set and brought the data back to JavaScript for recommendations!
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 你成功地将数据加载到张量中，这样做是有意义的，然后你对整个集合应用了数学计算，而不是对每个人进行迭代式的处理。一旦你得到了答案，你对整个集合进行了排序，并将数据带回JavaScript进行推荐！
- en: Can you do more?
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你还能做更多吗？
- en: You can do plenty more. From here, you can even use the 0s from each user’s
    votes to identify what bands the user has never listened to and recommend them
    in order of most-liked genre! There’s a really cool mathematical way to do this,
    but that’s a bit outside the scope of our first tensor exercise. Regardless, congratulations
    on implementing one of the most demanded and trending features of online sales!
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以做很多事情。从这里开始，你甚至可以使用每个用户投票中的0来确定用户从未听过的乐队，并按照最喜欢的流派顺序推荐给他们！有一种非常酷的数学方法可以做到这一点，但这有点超出了我们第一个张量练习的范围。不过，恭喜你实现了在线销售中最受欢迎和流行的功能之一！
- en: Chapter Review
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 章节回顾
- en: In this chapter, you’ve done more than scratch the surface of tensors. You’ve
    dug your hands deep into the fundamental structure of TensorFlow.js and grasped
    the roots. You’re on your way to wielding machine learning in JavaScript. Tensors
    are a concept that permeates all machine learning frameworks and fundamentals.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你不仅仅是浅尝辄止地了解了张量。你深入了解了TensorFlow.js的基本结构，并掌握了根本。你正在掌握在JavaScript中应用机器学习的方法。张量是一个贯穿所有机器学习框架和基础知识的概念。
- en: 'Chapter Challenge: What Makes You So Special?'
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 章节挑战：你有何特别之处？
- en: 'Now that you’re no longer a tensor-newb and you can manage tensors like a pro,
    let’s attempt a small exercise to solidify your skills. As of the time of this
    writing, JavaScript has no built-in method for clearing duplicates in an array.
    While other languages like Ruby have had the `uniq` method for more than a decade,
    JavaScript developers have either hand-rolled their solutions or imported popular
    libraries like Lodash. For fun, let’s use TensorFlow.js to solve the problem of
    unique values. As an exercise on lessons learned, muse over this problem:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你不再是一个张量新手，你可以像专业人士一样管理张量，让我们尝试一个小练习来巩固你的技能。在撰写本文时，JavaScript没有内置的方法来清除数组中的重复项。虽然其他语言如Ruby已经有了`uniq`方法超过十年，JavaScript开发人员要么手动编写解决方案，要么导入像Lodash这样的流行库。为了好玩，让我们使用TensorFlow.js来解决唯一值的问题。作为一个学到的教训的练习，思考一下这个问题：
- en: Given this array of US phone numbers, remove the duplicates.
  id: totrans-218
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 给定这个美国电话号码数组，删除重复项。
- en: '[PRE19]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Make sure your answer is a JavaScript array. If you get stuck with this exercise,
    you can review the [TensorFlow.js online documentation](https://oreil.ly/9thOd).
    Searching the documentation for key terms will point you in the right direction.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您的答案是一个JavaScript数组。如果您在这个练习中遇到困难，可以查阅[TensorFlow.js在线文档](https://oreil.ly/9thOd)。搜索关键术语的文档将指引您正确方向。
- en: You can find the answer to this challenge in [Appendix B](app02.html#appendix_b).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[附录B](app02.html#appendix_b)中找到这个挑战的答案。
- en: Review Questions
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复习问题
- en: 'Let’s review the lessons you’ve learned from the code you’ve written in this
    chapter. Take a moment to answer the following questions:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下您在本章编写的代码中学到的教训。花点时间回答以下问题：
- en: Why do we even use tensors?
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为什么要使用张量？
- en: Which one of these is not a tensor data type?
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪一个不是张量数据类型？
- en: '`Int32`'
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Int32`'
- en: '`Float32`'
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Float32`'
- en: Object
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对象
- en: Boolean
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 布尔值
- en: What is the rank of a six-dimensional tensor?
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 六维张量的秩是多少？
- en: What is the dimensionality of the return array for the method `dataSync`?
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 方法`dataSync`的返回数组的维数是多少？
- en: What happens when you pass a 3D tensor to `tf.tensor1d`?
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当您将一个三维张量传递给`tf.tensor1d`时会发生什么？
- en: What is the difference between `rank` and `size` in relation to a tensor’s shape?
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在张量形状方面，`rank`和`size`之间有什么区别？
- en: What is the data type of the tensor `tf.tensor([1])`?
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 张量`tf.tensor([1])`的数据类型是什么？
- en: Is the input array dimension for a tensor always the resulting tensor dimension?
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 张量的输入数组维度总是结果张量维度吗？
- en: How can you identify the number of tensors in memory?
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何确定内存中张量的数量？
- en: Can `tf.tidy` handle an async function?
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`tf.tidy`能处理异步函数吗？'
- en: How can I keep a tensor created inside of `tf.tidy`?
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何在`tf.tidy`内部创建的张量？
- en: Can I see the values of a tensor with `console.log`?
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我可以用`console.log`看到张量的值吗？
- en: What does the `tf.topk` method do?
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`tf.topk`方法是做什么的？'
- en: Do tensors optimize for batch or iterative calculation?
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 张量是为批量还是迭代计算进行优化的？
- en: What is a recommendation engine?
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推荐引擎是什么？
- en: Solutions to these exercises are available in [Appendix A](app01.html#book_appendix).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这些练习的解决方案可以在[附录A](app01.html#book_appendix)中找到。
