- en: Appendix A. Hyperparameters for classical machine learning models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Table A.1 Hyperparameters for linear models
  prefs: []
  type: TYPE_NORMAL
- en: '| Hyperparameter | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `C`  | Inversely related to regularization, smaller values correspond to
    stronger regularization. Search in the range `np.logspace(-4, 4, 10)`. |'
  prefs: []
  type: TYPE_TB
- en: '| `alpha`  | Constant that multiplies the regularization term, larger values
    correspond to stronger regularization. Search in the range `np.logspace(-2, 2,
    10)`. |'
  prefs: []
  type: TYPE_TB
- en: '| `l1_ratio`  | Blending L1 and L2 regularization in Elasticnet, pick from
    the values [.1, .5, .7, .9, .95, .99]. |'
  prefs: []
  type: TYPE_TB
- en: Table A.2 Hyperparameters for random forests and ERTs
  prefs: []
  type: TYPE_NORMAL
- en: '| Hyperparameter | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `max_features`  | Lower this parameter to increase bias and lower variance.
    Try values such as `sqrt`, `log2`, and integer numbers representing 1/10th and
    1/20th of the features. |'
  prefs: []
  type: TYPE_TB
- en: '| `min_samples_leaf`  | A way to regularize trees, usually set to 1; try growing
    it up to 30. |'
  prefs: []
  type: TYPE_TB
- en: '| `bootstrap`  | A boolean indicating if to use bootstrap for resampling. Sometimes
    subsampling may be more effective than bootstrap if noise or outliers are present.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `n_estimators`  | The more trees, the better, but you are wasting computational
    power beyond a certain point. Start from 100 and grow up to 1,000\. It works for
    most problems. |'
  prefs: []
  type: TYPE_TB
- en: Table A.3 Hyperparameters for Scikit-learn’s HistGradientBoosting
  prefs: []
  type: TYPE_NORMAL
- en: '| Hyperparameter | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `learning_rate`  | Multiplicative value for the results of the decision trees.
    A real number between 0.001 and 0.1. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_iter`  | The maximum number of trees built in the boosting process.
    An integer between 100 and 1,000. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_depth`  | The maximum depth of each tree acts as a regularization applied
    to the tree growth. Choose an integer between 1 and 12. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_leaf_nodes`  | The maximum number of leaves for each tree. Related to
    `max_depth`, it also controls tree growth. Optimize this or `max_depth`, not both.
    Choose an integer between 2 and 4,096. |'
  prefs: []
  type: TYPE_TB
- en: '| `min_samples_leaf`  | The minimum number of samples per leaf is a regularization
    applied to the tree growth. Choose an integer between 2 and 300. |'
  prefs: []
  type: TYPE_TB
- en: '| `l2_regularization`  | L2 regularization parameter for ensembling. Choose
    a float between 0.0 and 100.0. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_bins`  | The maximum number of bins to use in histograms. An indirect
    way to regularize trees. Choose an integer between 32 and 512. |'
  prefs: []
  type: TYPE_TB
- en: Table A.4 Hyperparameters for XGBoost
  prefs: []
  type: TYPE_NORMAL
- en: '| Hyperparameter | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `learning_rate`  | Multiplicative value to shrink the results from the decision
    trees. A real number between 0.001 and 0.1. |'
  prefs: []
  type: TYPE_TB
- en: '| `n_estimators`  | Number of trees in the boosting ensemble. An integer between
    100 and 1,000. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_depth`  | The maximum depth of a tree is a way to control the estimates’
    variance. An integer between 1 and 12. |'
  prefs: []
  type: TYPE_TB
- en: '| `min_child_weight`  | The minimum sum of instance weight (hessian) needed
    in a child. The default is one. The larger `min_child_weight` is, the more conservative
    the algorithm will be. We suggest an integer between 1 and 10. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_delta_step`  | Usually at zero, meaning no constraints, if set to a
    positive number, it acts as a regularizer because it sets a limit to the updates.
    It is beneficial when there is an imbalance among the classes in a classification
    because it prevents a class from dominating the others. We recommend a float between
    0 and 10. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_bin`  | Maximum number of bins used by histograms. An integer between
    32 and 512. |'
  prefs: []
  type: TYPE_TB
- en: '| `subsample`  | Sampling ratio of the training instance. A real number between
    0.1 and 1.0. |'
  prefs: []
  type: TYPE_TB
- en: '| `colsample_bytree`  | The subsample ratio of columns when constructing each
    tree. A real number between 0.1 and 1.0. |'
  prefs: []
  type: TYPE_TB
- en: '| `reg_lambda`  | L2 regularization term on weights. A real number between
    1e-9 and 100.0. |'
  prefs: []
  type: TYPE_TB
- en: '| `reg_alpha`  | L1 regularization term on weights. A real number between 1e-9
    and 100.0. |'
  prefs: []
  type: TYPE_TB
- en: '| `gamma`  | Another regularizer limiting the tree partitioning by setting
    a minimum loss reduction. Set this to a real number between 0 and 0.5. |'
  prefs: []
  type: TYPE_TB
- en: '| `scale_pos_weight`  | A weight value controlling the balance of positive
    and negative weights is useful for unbalanced binary classification problems.
    Set to 1 by default; a typical value to consider: number of negative instances/number
    of positive instances. We suggest a real number between 1e-6 and 500. |'
  prefs: []
  type: TYPE_TB
- en: Table A.5 Hyperparameters for LightGBM
  prefs: []
  type: TYPE_NORMAL
- en: '| Hyperparameter | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `learning_rate`  | Multiplicative value to shrink the results from the decision
    trees. A real number between 0.001 and 0.1. |'
  prefs: []
  type: TYPE_TB
- en: '| `n_estimators`  | Number of boosting iterations. An integer between 100 and
    1,000. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_depth`  | Limit to the maximum depth for decision trees. A way to control
    complexity and overfitting. An integer between 1 and 12. |'
  prefs: []
  type: TYPE_TB
- en: '| `num_leaves`  | An integer between 2 and 2`max_depth`, it represents the
    number of final leaves a tree will have, and if set low, it acts as a regularization
    for tree complexity. |'
  prefs: []
  type: TYPE_TB
- en: '| `min_data_in_leaf`  | Minimal number of data in one leaf. Setting this helps
    to deal with overfitting. Zero implies no constraint. An integer between 0 and
    300. |'
  prefs: []
  type: TYPE_TB
- en: '| `min_gain_to_split`  | The minimal gain to perform a split in the decision
    trees. A float between 0 and 15. |'
  prefs: []
  type: TYPE_TB
- en: '| `max_bin`  | Maximum number of bins used for histograms. An indirect way
    to deal with overfitting is by setting it lower. An integer between 32 and 512.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `subsample`  | A random percentage of data is to be selected without resampling.
    A real number between 0.1 and 1.0. |'
  prefs: []
  type: TYPE_TB
- en: '| `subsample_freq`  | Frequency for subsampling: An integer between 0 and 10\.
    If set to zero, the algorithm will ignore any setting related to the subsample
    and won’t perform subsampling. |'
  prefs: []
  type: TYPE_TB
- en: '| `feature_fraction`  | Fraction of features to be used on each iteration.
    A real number between 0.1 and 1.0. |'
  prefs: []
  type: TYPE_TB
- en: '| `reg_lambda`  | L2 regularization. A real number between 0.0 and 100.0. |'
  prefs: []
  type: TYPE_TB
- en: '| `reg_alpha`  | L1 regularization. A real number between 0.0 and 100.0. |'
  prefs: []
  type: TYPE_TB
- en: '| `scale_pos_weight`  | Weight of labels with positive class used to counterbalance
    when in an unbalanced binary classification. A real number between 1e-6 and 500.
    |'
  prefs: []
  type: TYPE_TB
