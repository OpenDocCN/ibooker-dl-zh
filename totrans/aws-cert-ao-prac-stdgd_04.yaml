- en: Chapter 3\. AI and Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI is not a new field; its origins date back decades. In the 1940s, researchers
    like Warren McCulloch and Walter Pitts developed foundational concepts for neural
    networks. This was followed by the pioneering work of mathematician Alan Turing,
    who in 1950 authored the paper “Computing Machinery and Intelligence.” In it,
    he introduced the Turing test, a method for evaluating a machine’s ability to
    exhibit intelligent behavior equivalent to, or indistinguishable from, that of
    a human.
  prefs: []
  type: TYPE_NORMAL
- en: The term *artificial intelligence* was coined in 1956 by computer scientist
    John McCarthy for a conference at Dartmouth College. The event gathered luminaries
    such as Marvin Minsky and Claude Shannon. Two attendees, Allen Newell and Herbert
    A. Simon, demonstrated the Logic Theorist, an AI program that could solve mathematical
    theorems. While today’s AI developments are far more advanced, the fundamental
    concepts established by these early pioneers remain critical building blocks.
  prefs: []
  type: TYPE_NORMAL
- en: No doubt, today’s AI developments are light-years ahead of these early applications.
    Yet some of their underlying fundamentals have been worked on for many years.
    They were the critical building blocks.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll focus on the fundamentals, which are a major part of
    the AIF-C01 exam. This will include focusing on a core topic of AI—that is, machine
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI can seem overwhelming. Part of this is due to the complexity of the technology.
    After all, it often involves advanced mathematics, complex algorithms, and large
    amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, AI is undergoing significant change and innovation. It’s extremely
    difficult—if not impossible—to keep up with everything. This is the case even
    for the world’s top data scientists.
  prefs: []
  type: TYPE_NORMAL
- en: Then there is the hype, as it seems like every tech company is about AI. Even
    many traditional companies boast about their own AI.
  prefs: []
  type: TYPE_NORMAL
- en: Given all this, it should be no surprise that it’s common for people to have
    misunderstandings about AI. This even includes its definition!
  prefs: []
  type: TYPE_NORMAL
- en: 'But of course, when it comes to the AIF-C01 exam, you need to have a good one.
    What to do? The best is to see how [AWS defines AI](https://oreil.ly/vniGg):'
  prefs: []
  type: TYPE_NORMAL
- en: AI, also known as artificial intelligence, is a technology with humanlike problem-solving
    capabilities. AI in action appears to simulate human intelligence—it can recognize
    images, write poems, and make data-based predictions.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is certainly a good, high-level definition. Yet we need to dig deeper.
    And a good way to do this is to get a visual of AI, as shown in [Figure 3-1](#figure_three_onedot_the_various_compone).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/awsc_0301.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-1\. The various components of AI
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For the most part, AI is a collection of different approaches and fields. In
    some cases, they can work on their own. In other situations, there is a combination.
  prefs: []
  type: TYPE_NORMAL
- en: A subset of AI is ML, which is where a computer learns from data. The ML algorithms
    find the patterns in the data and use these as the basis for predictions. Generally,
    the more data, the better—especially if it is high quality. Some of the common
    use cases for ML include fraud detection, predictive analytics, and recommendation
    engines.
  prefs: []
  type: TYPE_NORMAL
- en: Next, a subset of ML is *deep learning*. This is a flavor of ML that uses neural
    networks. These are essentially modeled on the human brain. The processing of
    data is based on analyzing data across layers and connections. This can often
    detect complex patterns and relationships. In some cases, they do what humans
    are not able to do. Thanks to deep learning, we have seen advances in categories
    like speech processing, NLP, and image recognition.
  prefs: []
  type: TYPE_NORMAL
- en: A subset of deep learning is generative AI. This is at the cutting-edge of AI.
    It’s what powers breakout applications like OpenAI’s ChatGPT and Anthropic’s Claude.
  prefs: []
  type: TYPE_NORMAL
- en: A generative AI model also processes data, but the scale is usually massive.
    With this, it can create new content like text, software code, images, audio,
    and video. It can often seem humanlike.
  prefs: []
  type: TYPE_NORMAL
- en: Even though generative AI is powerful, it is not a silver bullet. Sometimes
    it’s better to use ML or deep learning, depending on the use case and requirements.
    Knowing some of these is important for the book.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During the 1950s and 1960s, Arthur Samuel was a noted computer scientist and
    researcher at IBM. He created one of the first pioneering AI applications, which
    learned how to play checkers. He also coined *machine learning*, which he [defined](https://oreil.ly/l32nO)
    as “the field of study that gives computers the ability to learn without explicitly
    being programmed.”
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand this, let’s walk through an example. Suppose you’re working at
    a real estate agency, and you want to predict how much house 5 in [Table 3-1](#table_three_onedot_house_values_example)
    will sell for. You know that many factors go into pricing: location, the size
    of the house, the number of bedrooms, and how close it is to good schools. Instead
    of trying to create a long list of rules for calculating prices, you can use ML
    to handle the heavy lifting.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-1\. House values example
  prefs: []
  type: TYPE_NORMAL
- en: '| House | Location | Size (in sq. ft.) | Number of bedrooms | Price |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Tier 1 | 500 | 1 | $500,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Tier 2 | 500 | 1 | $350,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Tier 2 | 1,000 | 2 | $700,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Tier 2 | 1,500 | 3 | $1,500,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | Tier 1 | 1,000 | 2 | To be predicted |'
  prefs: []
  type: TYPE_TB
- en: 'Here’s how it works: you gather a bunch of data on homes—maybe thousands of
    records—including details about their features and their actual sale prices. Then,
    you feed all of this into an ML algorithm. It analyzes the data and learns the
    patterns. For example, it might understand that homes in a certain neighborhood
    are worth more or that every extra bedroom adds a specific amount to the price.'
  prefs: []
  type: TYPE_NORMAL
- en: Once the algorithm is trained, it’s ready to make predictions. Even though it’s
    never seen house 5 before, the model can estimate its price based on what it learned
    from the previous data.
  prefs: []
  type: TYPE_NORMAL
- en: That’s the beauty of machine learning. It lets computers learn from data and
    improve over time, instead of relying on hard-coded rules.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ll explore Amazon SageMaker, which is a platform for anyone
    working with ML on AWS. SageMaker is powerful, but with so many tools and features,
    it can feel overwhelming at first. This is why we’ll start with a high-level overview
    to make the components easier to understand.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker is a fully managed service that helps you build, train, and
    deploy ML models at scale. Instead of worrying about setting up infrastructure,
    you can focus on what matters most—developing and improving your models.
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker supports the entire ML lifecycle, from preparing data to monitoring
    deployed models. It also integrates smoothly with other AWS services like Amazon
    S3, Amazon Redshift, and Kinesis.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3-2](#figure_three_twodot_key_components_of_s) shows the key components
    that make up the SageMaker ecosystem.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/awsc_0302.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-2\. Key components of SageMaker
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s look at each component (we’ll also cover these in more detail in this
    chapter):'
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker Studio Classic
  prefs: []
  type: TYPE_NORMAL
- en: A web-based development environment where you can manage every step of your
    ML workflow in one place. It supports team collaboration and automation.
  prefs: []
  type: TYPE_NORMAL
- en: Notebook instances
  prefs: []
  type: TYPE_NORMAL
- en: Managed Jupyter notebooks for writing code, running experiments, and visualizing
    results—no setup required.
  prefs: []
  type: TYPE_NORMAL
- en: JumpStart
  prefs: []
  type: TYPE_NORMAL
- en: A library of pretrained models and built-in algorithms to help you get started
    quickly or fine-tune models for your specific use case.
  prefs: []
  type: TYPE_NORMAL
- en: Data Wrangler
  prefs: []
  type: TYPE_NORMAL
- en: A tool for cleaning, transforming, and exploring data. It connects to over 50
    data sources, making preprocessing faster and easier.
  prefs: []
  type: TYPE_NORMAL
- en: Model Monitor
  prefs: []
  type: TYPE_NORMAL
- en: Keeps an eye on deployed models, automatically detecting issues like data drift
    or declining performance.
  prefs: []
  type: TYPE_NORMAL
- en: MLOps tools
  prefs: []
  type: TYPE_NORMAL
- en: Includes services to manage ML workflows with automation, governance, and version
    control.
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker is built for flexibility and scale. There are also strong systems
    for security, compliance, and access controls.
  prefs: []
  type: TYPE_NORMAL
- en: The ML Lifecycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The ML lifecycle is a fancy way of describing the process for building AI systems.
    There is no right way to do this, as there are various approaches and flavors.
    But AWS does offer its own flow, which includes the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Business goal identification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML problem framing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s go through each of these steps.
  prefs: []
  type: TYPE_NORMAL
- en: Business Goal Identification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first step in the ML lifecycle is about answering a straightforward question:
    What’s the goal of the project? Usually, it’s senior leaders and managers who
    hammer out the key details and make the final decision. They have the authority
    and budget to make things happen. When it comes to AI, these projects can be expensive.
    They are also often considered strategic for a company.'
  prefs: []
  type: TYPE_NORMAL
- en: A plan may not necessarily be detailed. For example, it could be a PowerPoint
    with 5 to 10 slides or so. However, it should be clear what the goal is. A way
    to express this is with key performance indicators (KPIs), which are the metrics
    to measure whether the ML project is hitting its mark or not.
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose you work at a traditional retail company. During the past
    year, there have been problems with customer churn. However, you believe that
    AI can help solve the problem. You work with senior executives but also include
    domain experts in the organization, such as from the customer success department.
    From all this, you and the team come up with the KPI to reduce churn by 15% in
    the next year and set aside a budget of $200,000 for building and deploying the
    ML model.
  prefs: []
  type: TYPE_NORMAL
- en: This is not to imply that this KPI is set in stone. It may need to be adjusted
    because of the complexities of AI. This is especially the case for organizations
    that do not have much or any experience with AI projects. Regardless, it’s important
    to set specific KPIs to help guide the project and provide for accountability.
  prefs: []
  type: TYPE_NORMAL
- en: ML Problem Framing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After you’ve settled on a business objective, the next step is to translate
    this into something that ML can handle. This is known as ML *problem framing*.
  prefs: []
  type: TYPE_NORMAL
- en: This stage of the process involves a team of technical experts, such as data
    scientists, data engineers, and ML architects. There are also subject matter experts
    (SMEs), who have a strong understanding of a particular process in an organization
    or industry-specific expertise.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important that this team take an open-minded approach. The fact is that
    ML may not be the right solution—or any other AI technique. Rather, a problem
    could be solved by using traditional data analytics or process automation.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if ML is the right choice, then there needs to be an evaluation of
    important factors like:'
  prefs: []
  type: TYPE_NORMAL
- en: Is there quality data for the ML model?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the organization have the skills needed for success for the project?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are there enough resources?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, suppose a healthcare company wants to predict patient readmission
    rates to improve care and reduce costs. The business problem is clear: fewer readmissions
    lead to better outcomes and lower expenses. During ML problem framing, the team
    decides that this can be formulated as a classification problem. The goal is to
    predict whether a patient is likely to be readmitted within 30 days after discharge.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, it’s equally important to recognize situations where ML may not be
    the right solution. For instance, if the task can be solved using a straightforward
    rule-based system—like calculating a patient’s BMI from weight and height—then
    ML introduces unnecessary complexity. In such cases, traditional programming is
    faster, cheaper, and easier to maintain. Similarly, ML may not be suitable when
    full transparency and explainability are nonnegotiable. In regulatory-heavy environments
    such as healthcare or finance, decisions affecting patient eligibility or loan
    approval may demand a clear, auditable logic path—something that many ML models,
    especially deep learning ones, struggle to provide. Before jumping into model
    development, teams should ask: Can a rules engine handle this? And will we be
    able to confidently explain the output to users or auditors? If the answer is
    no, machine learning may not be the right tool for the job.'
  prefs: []
  type: TYPE_NORMAL
- en: After this, the team will evaluate the data requirements. In this case, there
    will likely need to be historical patient records, discharge summaries, and demographic
    details. Are these available? And if they are, does the team have the right to
    use the data?
  prefs: []
  type: TYPE_NORMAL
- en: In the meantime, there needs to be a focus on putting together the team to carry
    out the project. However, there may not be enough employees. In this case, there
    needs to be a realistic analysis of what it would take to hire people or bring
    on contractors. How long would this take? What are the costs?
  prefs: []
  type: TYPE_NORMAL
- en: This process can take some time, but it is well worth the effort. It can greatly
    mitigate the potential for failure of an ML project.
  prefs: []
  type: TYPE_NORMAL
- en: Data Processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Data processing is about converting data into a usable format. This includes
    these main steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Data collection and integration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data preprocessing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feature engineering, which is the process of selecting, creating, or modifying
    input variables (features) to improve model performance by making the data more
    meaningful and predictive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll cover each of these steps in the next few sections.
  prefs: []
  type: TYPE_NORMAL
- en: Data collection and integration
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When collecting and integrating data for an ML project, you want to have it
    in a central place. This helps to streamline the process, providing for more consistency,
    accuracy, and speed.
  prefs: []
  type: TYPE_NORMAL
- en: With AWS, there is the advantage of using different types of data stores like
    Amazon S3 and Amazon EBS, which we covered in [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).
    For more sophisticated workloads, you can use data warehouses. These can store
    large amounts of structured data from many sources. Amazon Redshift has this capability.
  prefs: []
  type: TYPE_NORMAL
- en: Or you can use a lakehouse. This is a modern architecture for storage, which
    stores any type of data. Amazon SageMaker Lakehouse exemplifies this by integrating
    Amazon S3 data lakes and Amazon Redshift data warehouses. This allows for access
    and management of diverse data types.
  prefs: []
  type: TYPE_NORMAL
- en: Then there is Kinesis. This is designed to handle large amounts of real-time
    data processing. While Kinesis is not a lakehouse, it integrates seamlessly into
    a lakehouse architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'Regardless of these storage options, the fact remains that all data is not
    created equal. Simply put, if your data is low quality, the results of the ML
    model will likely fall short. This goes to the famous rule of thumb: garbage in,
    garbage out. This is why it is critical to choose your data sources thoughtfully.
    Some questions to ask:'
  prefs: []
  type: TYPE_NORMAL
- en: Does the data relate to the problem to be solved?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the data accurate?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is it diverse? Is it representative of the real world?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is there enough data for the model?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the data up-to-date?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It’s important to know that data comes in two main categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Labeled data
  prefs: []
  type: TYPE_NORMAL
- en: This is where the data has a description. For instance, in a spam filter, emails
    are labeled as “spam” or “not spam.” These labels usually come from human input.
  prefs: []
  type: TYPE_NORMAL
- en: Unlabeled data
  prefs: []
  type: TYPE_NORMAL
- en: This is raw data.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are also two formats of data:'
  prefs: []
  type: TYPE_NORMAL
- en: Structured data
  prefs: []
  type: TYPE_NORMAL
- en: This is organized data. The most common format is for rows and columns in a
    spreadsheet or database (which is also called *tabular data*). This type of data
    is certainly useful for ML projects. But structured data can also be expressed
    as time-series data. This is where it is collected over time, such as stock prices
    or weather information.
  prefs: []
  type: TYPE_NORMAL
- en: Unstructured data
  prefs: []
  type: TYPE_NORMAL
- en: This data doesn’t have a predefined format. Examples of this include text, images,
    audio, and video. To make sense of it, you’ll need more advanced AI techniques
    to uncover patterns and insights.
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing, feature engineering, and data visualization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data is messy. Missing values, outliers, errors, and inconsistencies are common.
    To deal with these problems, there is data preprocessing or data preparation.
    But there’s a hitch—this process can be time-consuming and costly. According to
    a survey by Anaconda,^([1](ch03.html#ch01fn1)) data scientists spend about 45%
    of their time wrestling with these tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Even when the data is cleaned up, there is more to do. The next step is feature
    engineering. This is where data scientists will determine the meaningful aspects
    of the data. The focus is on finding those values that have the biggest impact
    on accurate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: To help with this, there is data visualization. Data scientists will try to
    get a better understanding of the dataset by using scatterplots, histograms, and
    box plots. This is known as exploratory data analysis (EDA).
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing, feature engineering, and data visualization can be labor-intensive.
    But with SageMaker you can use Data Wrangler to streamline the process. It provides
    access to all AWS data sources, but there are also integrations with 50+ third-party
    data providers, such as Snowflake and Databricks. Next, Data Wrangler verifies
    data quality and detects anomalies. This is done with 300+ built-in transformations.
    This means there is no need to learn tools like PySpark or Apache Spark. Data
    Wrangler also provides visualization templates and reports. What may take weeks—using
    traditional approaches—can take only minutes using Data Wrangler.
  prefs: []
  type: TYPE_NORMAL
- en: Model Development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Model development has three main steps, which we’ll cover in the following
    sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Training involves teaching a model to learn patterns and making predictions.
    This is based on using ML algorithms on datasets. The process is iterative, as
    it will require adjustments to the model parameters to improve the predictions
    of the model. There are three types of algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Evaluating these types of models requires expertise in data science. There
    are rules of thumb as to which to use for certain use cases. We’ll look at these
    in the next few sections of this book. But before doing this, it’s important that
    the dataset is split up into three sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Training data (70% to 80% of the dataset)
  prefs: []
  type: TYPE_NORMAL
- en: This is where you use the data with the ML algorithms to teach it to understand
    patterns and make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Validating data (10% to 15%)
  prefs: []
  type: TYPE_NORMAL
- en: This is for tuning the data to get better performance.
  prefs: []
  type: TYPE_NORMAL
- en: Testing data (10% to 15%)
  prefs: []
  type: TYPE_NORMAL
- en: Here, the model is evaluated based on unseen data. This helps to provide a sense
    of how it may work with real-world applications.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In supervised learning, the model learns using labeled data. Basically, the
    labels act as a guide, helping the model understand the relationship between inputs
    and their matching outputs. Think of it as a teacher supervising a student—hence
    the name “supervised learning.” For example, let’s say there’s a dataset full
    of images of fruits, each labeled as an apple, banana, or orange. After training
    on this data, the model can take a new, unlabeled image of a banana and identify
    it correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Supervised learning can be divided into two main tasks: classification and
    regression.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Classification.*** Classification is about sorting data into predefined
    categories. The model learns patterns from labeled data so it can categorize new
    examples. An example is credit risk assessment. A classification model can analyze
    a loan applicant’s credit history, income, and debts to determine whether they
    fall into the “low risk” or “high risk” category. This helps financial institutions
    make smarter lending decisions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other examples of classification include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Fraud detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer churn prediction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image recognition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Medical diagnostics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spam filtering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Regression.*** Regression refers to predicting continuous values rather
    than categories. It looks at the relationship between variables to make forecasts.
    Here are some examples of use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting sales numbers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimating stock market trends
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predicting population growth
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating life expectancy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s take a more detailed look with an example. Suppose you are building an
    ML model to predict hourly energy consumption of a building. In the feature engineering
    stage, you determine the independent variables. These are values that are not
    changed by other values in the algorithm. For our example, we come up with the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Outdoor temperature
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Humidity levels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time of day
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Day of the week
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Occupancy levels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Historical energy consumption data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then we have the dependent variable. This is the value we are predicting in
    our ML model, which is the energy consumption or kWh (kilowatt-hour).
  prefs: []
  type: TYPE_NORMAL
- en: There are different types of regression algorithms like linear regression, random
    forest regression, or support vector regression (SVR). Then which one to use?
    Evaluation can be a complex process. You need to know the intricacies of the algorithms.
    But generally, when it comes to a regression model, it’s about understanding the
    relationship between the independent and dependent variables. In our example,
    the linear regression model would probably not be a good option. The reason is
    that it assumes a straight-line relationship between input features and the target
    variable, which may not capture the complex, nonlinear patterns often present
    in building energy consumption data. Rather, a random forest regression and SVR
    are better suited for modeling such complexities.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Unsupervised learning is where a model is trained on unlabeled datasets. The
    algorithms will analyze the structure of the data, such as to find the underlying
    patterns, groupings, and relationships. This is done without any prior guidance.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main approaches to unsupervised learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Clustering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dimensionality reduction
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '***Clustering.*** Clustering groups data based on similarities. This is usually
    done by using a measurement technique. The closer two points are, the more similar
    they are. Here are common approaches to this:'
  prefs: []
  type: TYPE_NORMAL
- en: Euclidean distance
  prefs: []
  type: TYPE_NORMAL
- en: This measures the straight-line distance between two points. It’s done in multidimensional
    space. This refers to areas that extend beyond the typical three dimensions of
    length, width, and height.
  prefs: []
  type: TYPE_NORMAL
- en: Cosine similarity
  prefs: []
  type: TYPE_NORMAL
- en: This measures the angle between two points (the cosine). If the two are in the
    same direction, then they are similar.
  prefs: []
  type: TYPE_NORMAL
- en: Manhattan distance
  prefs: []
  type: TYPE_NORMAL
- en: This is the sum of the absolute differences of two points. Yes, it’s based on
    how a taxicab navigates through a city grid.
  prefs: []
  type: TYPE_NORMAL
- en: As for the algorithms for clustering, one of the most popular is *k*-means clustering.
    It often uses Euclidean distance to cluster the data points that are the closest.
    For example, a retail company can use *k*-means clustering to group customers
    based on the spending amount, product preferences, or purchase frequency. This
    can be used for more personalized marketing, say with relevant product selections
    and discounts.
  prefs: []
  type: TYPE_NORMAL
- en: Another algorithm for clustering is density-based spatial clustering of applications
    with noise (DBSCAN), which often uses Euclidean or Manhattan measurements. A common
    example of this is fraud detection. By using DBSCAN, outliers can be detected,
    which may indicate fraudulent behavior. It could find that generally the transactions
    are in the range of $100 to $200, with a few that are for more than $10,000.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon’s Random Cut Forest (RCF) algorithm is particularly effective for identifying
    outliers in financial transaction data. Unlike clustering algorithms that group
    similar data points, RCF focuses on detecting anomalies by assigning an anomaly
    score to each data point based on how easily it can be isolated. For instance,
    in a dataset where most transactions range between $100 and $200, an unexpected
    transaction of $10,000 would likely receive a high anomaly score, flagging it
    for further investigation.
  prefs: []
  type: TYPE_NORMAL
- en: '***Dimensionality reduction.*** High-dimensional data is when a dataset has
    a large number of features. However, this can cause problems for ML models. This
    phenomenon is referred to as the “curse of dimensionality.”'
  prefs: []
  type: TYPE_NORMAL
- en: A typical issue with high-dimensional data is high computational costs. This
    requires more processing power, memory, and time to analyze the data.
  prefs: []
  type: TYPE_NORMAL
- en: Next, there is the issue with overfitting, which is when an ML model learns
    too much from the training data and does not generalize well on unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: To understand this, let’s take an example. Suppose we have a spam filter that
    has training data with a high frequency of the word *free*. Overfitting would
    mean that the model will detect spam, even though the word has many legitimate
    uses.
  prefs: []
  type: TYPE_NORMAL
- en: To deal with these problems, you can use dimensionality reduction. Simply put,
    this is the process of reducing the number of features in a dataset, but the changes
    must not materially impact the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Principal component analysis (PCA), t-SNE, and autoencoders are some of the
    other algorithms that can be used.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You did not use a guidebook or take lessons to ride a bike, right? Of course
    not. Instead, you watched others and then tried it yourself. There was lots of
    falling and some scraped knees and hands. But ultimately, you were able to figure
    it out. Riding a bike would soon become natural.
  prefs: []
  type: TYPE_NORMAL
- en: This process is similar to reinforcement learning. This is how an ML model learns
    by trial and error—that is, there is positive and negative reinforcement based
    on interacting with an environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reinforcement learning has been shown to be particularly effective with:'
  prefs: []
  type: TYPE_NORMAL
- en: Games
  prefs: []
  type: TYPE_NORMAL
- en: They have the benefit of clear rules, scores, and constraints (like a game board).
    With this environment, an ML model can run millions of simulations, which will
    allow for learning. This has been key for systems like AlphaGo, which beat the
    world champion of the game Go.
  prefs: []
  type: TYPE_NORMAL
- en: Robotics
  prefs: []
  type: TYPE_NORMAL
- en: Since robotics navigate in the real world, reinforcement learning can allow
    these systems to understand their environment.
  prefs: []
  type: TYPE_NORMAL
- en: The three types of ML learning—supervised learning, unsupervised learning, and
    reinforcement learning—are shown in [Figure 3-3](#figure_three_threedot_the_three_main_ty).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/awsc_0303.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-3\. The three main types of ways for machines to learn using ML
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Using AWS for model development
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Model development in ML involves the process of designing, training, and refining
    algorithms to analyze data and make predictions or decisions. This includes selecting
    appropriate models, preparing data, training the models, and evaluating their
    performance to ensure they meet the desired objectives.
  prefs: []
  type: TYPE_NORMAL
- en: 'With Amazon SageMaker, there are three main options for model development:'
  prefs: []
  type: TYPE_NORMAL
- en: Pretrained models
  prefs: []
  type: TYPE_NORMAL
- en: There are hundreds of pretrained models available, which require little fine-tuning
    or configuration. You can access them using SageMaker JumpStart (see [Figure 3-4](#figure_three_fourdot_foundation_models)).
    FMs, computer vision models, and NLP models are available.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/awsc_0304.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-4\. Foundation models section of the SageMaker JumpStart dashboard
    for pretrained models
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Built-in algorithms
  prefs: []
  type: TYPE_NORMAL
- en: These are tailored for large datasets and where there is a need for scalability
    and performance optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Docker images
  prefs: []
  type: TYPE_NORMAL
- en: Docker images are for popular ML frameworks like TensorFlow, PyTorch, and scikit-learn.
    There are also images for your own models. This is when you want customization.
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Before a model goes into production, there needs to be extensive evaluation
    of the performance. There are various metrics for this, and many of these depend
    on the type of model you use. The metrics are not foolproof but provide general
    guidance. We’ll take a look at the following metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: Model fit
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model fit
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Model fit refers to how well a model captures patterns in the data. The goal
    is to strike a balance between overfitting and underfitting to achieve optimal
    accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'To mitigate overfitting, you can:'
  prefs: []
  type: TYPE_NORMAL
- en: Reduce the number of features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increase the size of the training dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apply regularization techniques like L1 (lasso regression) and L2 (ridge regression)
    to simplify the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Underfitting happens when a model is too simple to capture the underlying patterns
    in the data. For example, if you’re building a model to recognize handwritten
    digits and use logistic regression, it may struggle because handwritten digits
    have complex, nonlinear patterns. In such cases, a more complex algorithm, like
    a neural network or decision tree, may be more appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: There are other causes of underfitting. One is that the data does not have enough
    features. There may also be too few iterations—or epochs—for the training.
  prefs: []
  type: TYPE_NORMAL
- en: To measure overfitting and underfitting, you can use bias and variance, which
    are statistical calculations. Bias is the difference between the average predicted
    values and actual values. It’s a way to gauge a model’s tendency to make errors
    based on simplistic assumptions, which means there is underfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Variance, on the other hand, measures the fluctuations in the predicted values.
    A high variance means that the model is sensitive to small changes in the training,
    which can indicate overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Again, the goal is to strike a balance—that is, to have a model with low bias
    and low variance.
  prefs: []
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Classification metrics are used to measure the performance of ML models that
    assign labels to data points. These metrics help evaluate how accurately a model
    makes predictions and where it might be going wrong. For example, if you’re developing
    a model to predict whether a patient has a certain disease based on medical test
    results, classification metrics can show how often the model makes correct diagnoses,
    misses true cases, or raises false alarms.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a classification problem, you can evaluate the model by using techniques
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Confusion matrix
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accuracy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Precision
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recall
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Area under the curve-receiver operating curve (AUC-ROC)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To understand these metrics, we’ll use an example. Suppose you are building
    an ML model to detect credit card fraud. It will use the binary classification
    approach, which will indicate whether a transaction is either fraudulent or legitimate.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s next apply the metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '***Confusion matrix.*** A confusion matrix is a way to understand the reasons
    why an outcome of an ML model is wrong. After the training is complete, you will
    get the number of occurrences of true positives, false positives, false negatives,
    and true negatives (see [Table 3-2](#table_three_twodot_confusion_matrix_for)).'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-2\. Confusion matrix for a fraud deduction ML model
  prefs: []
  type: TYPE_NORMAL
- en: '| Actual/predicted values | Fraudulent (positive) | Legitimate (negative) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Fraudulent | 70 | 30 |'
  prefs: []
  type: TYPE_TB
- en: '| Legitimate | 20 | 880 |'
  prefs: []
  type: TYPE_TB
- en: 'Let’s analyze this confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: True positives
  prefs: []
  type: TYPE_NORMAL
- en: 70 transactions classified as fraudulent.
  prefs: []
  type: TYPE_NORMAL
- en: False negatives
  prefs: []
  type: TYPE_NORMAL
- en: 30 fraudulent transactions incorrectly identified as legitimate.
  prefs: []
  type: TYPE_NORMAL
- en: False positives
  prefs: []
  type: TYPE_NORMAL
- en: 20 legitimate transactions incorrectly identified as fraudulent.
  prefs: []
  type: TYPE_NORMAL
- en: True negatives (TN)
  prefs: []
  type: TYPE_NORMAL
- en: 880 transactions correctly classified as legitimate.
  prefs: []
  type: TYPE_NORMAL
- en: The takeaway? While the model is effective in detecting fraud, there can be
    improvement in minimizing the false negative and false positives.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the confusion matrix is also the basis for calculating accuracy,
    precision, and recall.
  prefs: []
  type: TYPE_NORMAL
- en: '***Accuracy.*** The accuracy of the model is also called the *score*. It is
    the sum of the correct predictions, which are divided by the number of predictions.
    In our credit card fraud example, the accuracy is 95%:'
  prefs: []
  type: TYPE_NORMAL
- en: True positives (TP) = 70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: False negatives (FN) = 30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: False positives (FP) = 20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: True negatives (TN) = 880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accuracy = (TP + TN) / (TP + FN + FP + TN)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: = (70 + 880) / (70 + 30 + 20 + 880) = 950 / 1000 = 95%
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: But this metric can be deceiving. It can be less useful when there are many
    true negatives in the dataset. This is why it’s important to use several metrics
    when evaluating a model.
  prefs: []
  type: TYPE_NORMAL
- en: '***Precision.*** Precision focuses on the true and false positives. That is,
    it is calculated as the number of true positives divided by the true positives
    and false positives. For our credit card fraud example, the precision is 77.8%:'
  prefs: []
  type: TYPE_NORMAL
- en: 70 / (70 + 20)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally, precision is useful when the cost of false positives is high. This
    is certainly the case with fraud detection. If a false positive happens when a
    transaction is legitimate—tagging it as fraudulent—this can lead to lower customer
    satisfaction. Or if a false negative occurs—where the machine learning model classifies
    a fraudulent transaction as legitimate—it can lead to financial losses.
  prefs: []
  type: TYPE_NORMAL
- en: '***Recall.*** With recall, the focus is the positives for the confusion matrix.
    It’s calculated as the true positives divided by the sum of the true positives
    and false negatives. For our credit card fraud example, it’s 70%:'
  prefs: []
  type: TYPE_NORMAL
- en: 70 / (70 + 30)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This essentially measures a model’s ability to classify actual fraudulent transactions.
  prefs: []
  type: TYPE_NORMAL
- en: '***Area under the curve-receiver operating curve (AUC-ROC).*** AUC-ROC plots
    the recall against the false positive rate, as shown in [Figure 3-5](#figure_three_fivedot_the_curve_receiver).
    This is done at different threshold settings. For example, with our credit card
    fraud example, we could have a lower threshold. This means that more transactions
    will be classified as fraudulent, which will increase the detection rate of actual
    frauds or true positives. Or we could do the opposite. It depends on the goals
    and requirements.'
  prefs: []
  type: TYPE_NORMAL
- en: Generally, the higher the AUC, the better the model is at distinguishing between
    fraudulent and legitimate transactions. An AUC close to 1.0 indicates strong performance,
    while an AUC near 0.5 means the model isn’t much better than random guessing.
  prefs: []
  type: TYPE_NORMAL
- en: '![The curve-receiver operating curve (AUC-ROC)](assets/awsc_0305.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-5\. The curve-receiver operating curve (AUC-ROC)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There are numerous metrics for regression. But for purposes of the exam, you
    should focus on these two: mean squared error (MSE) and R squared (R²).'
  prefs: []
  type: TYPE_NORMAL
- en: Of these two, MSE is generally the most common.
  prefs: []
  type: TYPE_NORMAL
- en: '***Mean squared error.*** With MSE, you compare the differences between the
    predictions and actual outcomes. To calculate it, you square each difference,
    sum them, and take the average.'
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you are creating a regression model to predict annual salaries based
    on an employee’s experience with the company. [Table 3-3](#table_three_threedot_regression_model_f)
    shows the data.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-3\. Regression model for salaries
  prefs: []
  type: TYPE_NORMAL
- en: '| Employee ID | Years of experience | Actual salary ($1,000s) | Predicted salary
    ($1,000s) | Error (actual/predicted) | Squared error |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 2 | 50 | 55 | –5 | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 5 | 80 | 75 | 5 | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 7 | 100 | 95 | 5 | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 10 | 150 | 140 | 10 | 100 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 12 | 150 | 140 | 10 | 100 |'
  prefs: []
  type: TYPE_TB
- en: Based on this, the MSE is 40\. What does this mean? It’s the average of the
    square difference between the predicted and actual values. Generally, the lower
    this is, the more accurate the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '***R squared.*** R² is a value from 0 to 1\. It shows how much of a regression
    model is explained by the variability of the prediction. The closer the value
    is to 1, the more accurate the model.'
  prefs: []
  type: TYPE_NORMAL
- en: But this also depends on the category. For example, a relatively lower R squared—such
    a 0.40 or 0.50—may be fine for social studies. But for physics and engineering,
    you would probably want something like 0.9 or higher.
  prefs: []
  type: TYPE_NORMAL
- en: Tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Tuning is the process of adjusting a model’s parameters and settings to improve
    its performance. When you first train an ML model, the initial results are often
    underwhelming because the default settings may not capture the underlying patterns
    in the data or may not be well-suited to the specific problem. That’s why tuning
    is typically necessary—to refine the model so it can make more accurate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'One approach is hyperparameter optimization. A hyperparameter is a setting
    in an ML model, which is to control how it learns. This can be done by adjusting:'
  prefs: []
  type: TYPE_NORMAL
- en: Batch size
  prefs: []
  type: TYPE_NORMAL
- en: The number of training examples that are processed at a time
  prefs: []
  type: TYPE_NORMAL
- en: Learning rate
  prefs: []
  type: TYPE_NORMAL
- en: How quickly the model adapts to the new data
  prefs: []
  type: TYPE_NORMAL
- en: Neural network
  prefs: []
  type: TYPE_NORMAL
- en: The number and size of layers
  prefs: []
  type: TYPE_NORMAL
- en: How does a hyperparameter differ from a parameter? A parameter is learned during
    training, whereas a hyperparameter must be defined before the training and will
    remain fixed.
  prefs: []
  type: TYPE_NORMAL
- en: 'As for hyperparameter optimization, this is where you adjust the hyperparameter
    to improve the performance of the model. Keep in mind that even a small change
    can make a big difference. There are various methods to help with this:'
  prefs: []
  type: TYPE_NORMAL
- en: Grid search
  prefs: []
  type: TYPE_NORMAL
- en: This is where you process multiple combinations of hyperparameters.
  prefs: []
  type: TYPE_NORMAL
- en: Random search
  prefs: []
  type: TYPE_NORMAL
- en: Process random combinations within defined ranges.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian optimization
  prefs: []
  type: TYPE_NORMAL
- en: Use probability models for the search.
  prefs: []
  type: TYPE_NORMAL
- en: Optuna
  prefs: []
  type: TYPE_NORMAL
- en: This is a modern, open source optimization framework that uses a smarter sampling
    strategy to efficiently search the hyperparameter space. It’s known for being
    fast, flexible, and easy to integrate into Python-based ML workflows.
  prefs: []
  type: TYPE_NORMAL
- en: Model Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When the ML model finally meets your requirements after the development phase,
    the next step is to put it into production. There are two main ways for this:'
  prefs: []
  type: TYPE_NORMAL
- en: Self-hosted API
  prefs: []
  type: TYPE_NORMAL
- en: This is when you deploy the ML model on your own IT infrastructure. This can
    be in a private cloud, on-premises, or a cloud platform, such as AWS. You will
    need to set up VMs, web servers, networking, storage, and databases.
  prefs: []
  type: TYPE_NORMAL
- en: Managed API
  prefs: []
  type: TYPE_NORMAL
- en: This is where a platform—like SageMaker—handles the infrastructure, deployment,
    and automatic scaling.
  prefs: []
  type: TYPE_NORMAL
- en: There are pros and cons for each option. With the self-hosted API, you have
    much more control. This can allow for customization, unique requirements, and
    implementing security. Then again, this option can be expensive and time-consuming.
    You will also need IT personnel who are experienced with infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: The managed API, on the other hand, is much more simplified. You can focus more
    time on building ML models, not managing the underlying infrastructure. The costs
    are usually lower as well. Then again, there is not as much flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: Once deployed—whether through a self-hosted API or a managed platform like SageMaker—your
    model is ready for inferencing, making predictions based on new input data.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different ways to do this. For example, with SageMaker you can do
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Real-time inference
  prefs: []
  type: TYPE_NORMAL
- en: Use this when an ML application needs to act near instantaneously. This is for
    high-stakes use cases, such as self-driving cars, healthcare monitoring, and fraud
    detection.
  prefs: []
  type: TYPE_NORMAL
- en: Batch transform
  prefs: []
  type: TYPE_NORMAL
- en: Batch transform is generally for large datasets that don’t require immediate
    responses. For instance, a marketing team might use batch transform to segment
    thousands of customers overnight, enabling targeted email campaigns the next morning.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous inference
  prefs: []
  type: TYPE_NORMAL
- en: This is for large payloads or long-running jobs; for example, an image recognition
    app that analyzes high-resolution photos uploaded by users. While the image is
    being processed, the user can continue browsing the app without delay.
  prefs: []
  type: TYPE_NORMAL
- en: On-demand serverless inference
  prefs: []
  type: TYPE_NORMAL
- en: Applications with intermittent traffic, as with a small business chatbot, for
    example, can use serverless inference to respond to customer inquiries, automatically
    scaling resources based on the volume of users at any given time—without needing
    a permanently running server.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Monitoring is about tracking an ML model to ensure it is working as intended.
    Part of this is to look at KPIs, as we mentioned earlier in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'But it’s important to understand that even high-quality models will degrade
    in accuracy. This is due to factors like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Data drift
  prefs: []
  type: TYPE_NORMAL
- en: Features of the model change over time, yet the relationships remain the same.
    For example, suppose you have built an ML model for predictive maintenance, where
    the system will try to anticipate needs for repairs for machines. However, after
    a few years, the model may show lower performance levels since the machines will
    be older, which can lead to changes in the characteristics of the features like
    vibration levels and temperature readings.
  prefs: []
  type: TYPE_NORMAL
- en: Concept drift
  prefs: []
  type: TYPE_NORMAL
- en: The relationship between the features has changed. For example, this can be
    the case when a spam filter becomes less effective because spammers find ways
    to game the system.
  prefs: []
  type: TYPE_NORMAL
- en: Label shift
  prefs: []
  type: TYPE_NORMAL
- en: There is a shift in the labels of a dataset over time, but the relationships
    of the labels remain the same. To understand this, let’s look again at the spam
    filter scenario. Suppose the ML model was built with a dataset that has 30% of
    emails labeled as spam. But in the next year, there’s a notable increase in spam
    activities. This can have an adverse impact on performance of the ML model since
    it may not be able to pick up on the higher proportion of spam.
  prefs: []
  type: TYPE_NORMAL
- en: Feature drift
  prefs: []
  type: TYPE_NORMAL
- en: This is similar to data drift. With feature drift, the distribution of features
    in a dataset change over time, but the relationships remain constant. An example
    is with credit scores. Let’s say a model is basing its predictions on income of
    $30,000 to $50,000\. But in a couple years, the population has seen improved gains,
    with income ranging from $50,000 to $70,000\. This means that the distribution
    of the feature has changed. This could easily mean inaccurate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: There are many monitoring systems available to detect these problems. As for
    AWS, there is SageMaker Model Monitor. It provides continuous monitoring of real-time
    endpoints, batch transform jobs that run regularly, and asynchronous batch transform
    jobs that are on schedule.
  prefs: []
  type: TYPE_NORMAL
- en: The system is highly configurable, allowing for setting alerts for when there
    are issues with an ML model. You can then be proactive in taking actions. These
    may be to retrain the model or fix quality issues.
  prefs: []
  type: TYPE_NORMAL
- en: MLOps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Machine learning operations (MLOps) is about a set of practices, processes,
    and automations to better manage the ML lifecycle. It is for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing and validating models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MLOps is based on underlying concepts of DevOps, which is focused on the integration
    of software development and IT teams.
  prefs: []
  type: TYPE_NORMAL
- en: However, with MLOps, it must deal with the unique aspects of ML models. These
    include the experimental nature of these systems, the reliance of large datasets,
    and the continuous monitoring. Then there are the challenges of finding skilled
    employees.
  prefs: []
  type: TYPE_NORMAL
- en: A key advantage of MLOps is that an application can get to market faster. It
    provides a framework to organize a project and leverage repeatable processes.
    The planning can go a long way in avoiding wasted efforts and expenses. This also
    includes using automation systems, like SageMaker.
  prefs: []
  type: TYPE_NORMAL
- en: MLOps can be integrated with CI/CD. This is for the automations of building,
    testing, and deploying the ML models. This will also include versioning of the
    inputs and outputs of the model, which allows for better understanding of the
    performance of the models. Versioning also provides for rollbacks, which means
    that the system will be returned to the prior setup.
  prefs: []
  type: TYPE_NORMAL
- en: Another advantage of MLOps is that it can help promote a culture of collaboration
    among data scientists, data engineers, software engineers, and IT personnel. This
    is no easy feat given that each role has specialized backgrounds. But there needs
    to be a focus on strong governance. This means having clear documentation and
    ways to provide constructive feedback. Of course, there must be systems in place
    to provide for data, privacy, and security compliance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon SageMaker has numerous tools for MLOps. Some of them we have already
    covered, such as Data Wrangler and Model Monitor. Here are some others:'
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker Feature Store
  prefs: []
  type: TYPE_NORMAL
- en: This assists in creating, sharing, and managing ML features.
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker Experiments
  prefs: []
  type: TYPE_NORMAL
- en: You can experiment with mixes of datasets, models, and parameters. The system
    will then evaluate the accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker Processing
  prefs: []
  type: TYPE_NORMAL
- en: This automates data preprocessing, feature engineering, and model evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker Model Registry
  prefs: []
  type: TYPE_NORMAL
- en: With this, you can catalog models, manage model versions, process the approvals,
    or deploy models to production.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Development Tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To support development, SageMaker provides two key environments: SageMaker
    Notebook Instances and SageMaker Studio Classic.'
  prefs: []
  type: TYPE_NORMAL
- en: SageMaker Notebook Instances
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Jupyter notebook is an open source system, which is accessible from the internet.
    You can create documents that have live code, documentation, equations, and visualizations.
    Jupyter Notebooks are popular for building ML models.
  prefs: []
  type: TYPE_NORMAL
- en: You can use these in AWS with SageMaker Notebook Instances. These are fully
    managed Jupyter notebooks that you can launch from the SageMaker console.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through an example to see how it works. First, you will log in to
    your AWS account, which we learned about in [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai),
    and then click the menu icon (sometimes called the “burger” icon) on the top left.
    From the menu, you will click “Create notebook instance.”
  prefs: []
  type: TYPE_NORMAL
- en: You’ll see a configuration screen. Here, you can fill out details like access
    permissions, GitHub integration, and network settings. But at a minimum, you will
    enter a name for the notebook and use the default role.
  prefs: []
  type: TYPE_NORMAL
- en: AWS will spin up a VM instance to host your notebook. It might take a couple
    of minutes to set up. When it’s ready, click the name of your instance, and then
    select Open Jupyter. On the left side of the screen, choose New, and from the
    drop-down menu, select conda_python_3\. The notebook will show up (see [Figure 3-6](#figure_three_sixdot_jupyter_notebook_in)).
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, I put in some sample code. This program loads and displays the
    Iris dataset, a well-known dataset used for ML.
  prefs: []
  type: TYPE_NORMAL
- en: Each line in the notebook is called a *cell*. It can be for either documentation
    or description, which is in a Markdown format. This is similar to how you would
    format a web page. Then there is a cell for the code. For ML projects, this is
    usually Python, Scala, or R.
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 3-6](#figure_three_sixdot_jupyter_notebook_in), the title for the
    project—at the top—is in Markdown; the code is Python.
  prefs: []
  type: TYPE_NORMAL
- en: To run the code in a cell, you will click it and then press Shift+Enter. The
    output—if there is any—will appear below it.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When you are using SageMaker Notebook Instances—or any other AWS service—you
    need to be careful. In some cases, the billing will continue. For a notebook,
    this may be less than a dollar per month. But this can still add up, as you add
    more. Because of this, if you do not expect to use any in the future, then you
    should delete them.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/awsc_0306.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-6\. Jupyter Notebook in SageMaker
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: SageMaker Studio Classic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SageMaker Studio Classic is an IDE for creating and deploying ML models. It’s
    user-friendly, supports team collaboration, and doesn’t use VMs, which helps to
    lower the costs. It is also compatible with tools like Jupyter Notebook, VS Code,
    and RStudio.
  prefs: []
  type: TYPE_NORMAL
- en: To use SageMaker Studio Classic, log in to your AWS account and select the icon
    on the top left. Choose “Create a SageMaker domain” and then select the “Quick
    setup” option, which is for a single user. It will then take a few minutes for
    SageMaker to be initialized.
  prefs: []
  type: TYPE_NORMAL
- en: After this, go to User Profiles and choose Launch. You’ll see the dashboard
    for SageMaker Studio Classic, as shown in [Figure 3-7](#figure_three_sevendot_dashboard_for_the).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/awsc_0307.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-7\. Dashboard for the SageMaker Studio Classic
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: On the left side of the screen, you’ll find a navigation panel with applications
    like JupyterLab and the Code Editor. Below that, you can access key ML services,
    including Data, Auto ML, and Experiments.
  prefs: []
  type: TYPE_NORMAL
- en: For the rest of this book, we’ll focus on SageMaker Studio Classic.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move on and explore other AWS services.
  prefs: []
  type: TYPE_NORMAL
- en: AWS ML Services
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we’ll focus on ready-to-use AWS ML services that don’t require
    extensive model building or training. These solutions can be quickly integrated
    into applications to add powerful AI capabilities—such as language understanding,
    translation, speech recognition, and personalization—without deep ML expertise.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Comprehend
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Comprehend is an NLP tool. It can extract insights from data, such as
    documents, product reviews, social media feeds, and customer support tickets.
    The tool will try to understand the content by focusing on key phrases, entities,
    places, people, sentiment, and topics. Amazon Comprehend also has security features
    to identify and redact personally identifiable information (PII).
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Translate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Translate is for language translation. It can understand 75 languages.
    The system uses neural translation, which is based on sophisticated deep learning
    models. This allows for more accurate and natural-sounding translations.
  prefs: []
  type: TYPE_NORMAL
- en: The tool leverages Active Custom Translation (ACT). This means you can use your
    own data to customize the translations. But there is no need to create a new model.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Textract
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Textract extracts text and handwriting from scanned documents, PDFs,
    and images. But this is more than a typical optical character recognition (OCR)
    system. Amazon Textract can also identify and understand the information that
    is extracted.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Lex
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Lex is a fully managed AI service that allows for the creation, testing,
    and deployment of conversational interfaces, such as chatbots. The core engine
    is the Alexa platform. Amazon Lex also uses Lambda, which allows for customization
    based on an organization’s internal data.
  prefs: []
  type: TYPE_NORMAL
- en: This system can be easily deployed on mobile, IoT devices, and call centers.
    There are also integrations with Facebook Messenger, Slack, and Twilio SMS.
  prefs: []
  type: TYPE_NORMAL
- en: On the backend, there is a dashboard, which provides extensive analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Polly
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Polly provides tools to allow applications to have lifelike speech. It
    comes with more than 100 male and female voices. They span more than 40 languages
    and language variants.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Polly has many use cases. For example, you can use it to allow text-to-speech
    with blog posts, PDFs, and web pages.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Transcribe
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Transcribe is known as an automatic speech recognition (ASR) service.
    This means it can convert speech into text, such as from WAV and MP3 files. The
    service provides timestamps for every word, which allows for search capabilities.
    Amazon Transcribe can also be used in real time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the use cases include:'
  prefs: []
  type: TYPE_NORMAL
- en: Transcriptions of customer support calls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creation of subtitles for audio and video files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Rekognition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Rekognition is a sophisticated computer vision tool. It makes it possible
    to identify objects, people, scenes, and activities in images and videos. This
    system also allows for facial search and analysis, helping with user verification
    and people counting.
  prefs: []
  type: TYPE_NORMAL
- en: 'These are other use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Detect unsafe or inappropriate content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify video segments that help to lower costs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide alerts when an unknown person is detected near your home
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon Kendra
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Kendra is an enterprise search system that works across various structured
    and unstructured repositories. This can be easily implemented into corporate websites
    and applications.
  prefs: []
  type: TYPE_NORMAL
- en: A powerful feature is the Kendra GenAI index. This uses RAG, which leverages
    generative AI for searching proprietary documents. With this, you can create personalized
    digital assistants.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Personalize
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon Personalize helps create AI applications that are customized based on
    the interests and behaviors of users. Setup of the system can take a few hours.
    But this is fairly low compared to many others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Amazon Personalize is built to be highly adaptable. In real time, it will incorporate
    user data to improve recommendations. Some of the use cases for this tool are:'
  prefs: []
  type: TYPE_NORMAL
- en: Customer sentiment analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Targeted marketing campaigns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identification of market trends
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS DeepRacer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AWS DeepRacer is a 3D simulation application of a fully autonomous race car.
    This provides a fun way to learn about reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: In [Table 3-4](#table_three_fourdot_aws_ai_services), you’ll find a summary
    of the AWS AI services.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-4\. AWS AI services
  prefs: []
  type: TYPE_NORMAL
- en: '| Service | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Comprehend | Extracts insights from text using NLP, including sentiment
    and PII detection |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Kendra | Provides intelligent enterprise search across document repositories
    |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Lex | Creates conversational chatbots using speech and text input
    |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Personalize | Generates real-time, personalized recommendations using
    user data |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Polly | Converts text into lifelike speech in multiple voices and
    languages |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Rekognition | Detects objects, scenes, and faces in images and videos
    |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Textract | Extracts and understands text and handwriting from documents
    and images |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Transcribe | Converts speech to text with support for real-time transcription
    |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Translate | Provides real-time language translation for over 75 languages
    |'
  prefs: []
  type: TYPE_TB
- en: '| AWS DeepRacer | Simulates autonomous driving to teach reinforcement learning
    |'
  prefs: []
  type: TYPE_TB
- en: AWS services, including Amazon SageMaker, are continuously updated with new
    features and capabilities. For the latest information, always refer to the official
    [AWS documentation](https://oreil.ly/_49DF).
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we had an overview of ML. It’s certainly a big topic with many
    moving parts. To help make this more understandable, we focused on the ML lifecycle,
    which has phases like data processing, model deployment, and monitoring. In each
    step, we learned about the key concepts and use cases along with the relevant
    AWS tools.
  prefs: []
  type: TYPE_NORMAL
- en: After this, we covered MLOps, which is a comprehensive approach to managing
    ML projects. We also looked at the numerous other AWS ML services for specific
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’ll take a look at generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: Quiz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To check your answers, please refer to the [“Chapter 3 Answer Key”](app02.html#answers_ch_3).
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following best describes the role of feature engineering in machine
    learning (ML)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It creates new variables or transforms data to improve model performance.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It trains the model using labeled data.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It evaluates the accuracy of a trained model.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It ensures that the model is not biased.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the primary purpose of reinforcement learning in AI?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To learn patterns from labeled data
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To optimize decisions based on rewards and penalties
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To detect anomalies in datasets
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To reduce dimensionality in high-dimensional datasets
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A company is using Amazon SageMaker to build a machine learning (ML) model.
    What is the primary advantage of using SageMaker over traditional on-premises
    ML infrastructure?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It eliminates the need for data preprocessing.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It requires more manual intervention than on-premises solutions.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It provides pretrained models that cannot be customized.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It automates the entire ML lifecycle, from training to deployment.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the primary difference between supervised and unsupervised learning?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Supervised learning does not require labeled data, while unsupervised learning
    does.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Supervised learning focuses on reinforcement learning, while unsupervised learning
    does not.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Supervised learning uses labeled data, while unsupervised learning finds patterns
    in unlabeled data.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Supervised learning is only used for classification tasks, while unsupervised
    learning is used for all other ML applications.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: A retailer wants to group its customers based on purchasing behavior without
    using predefined labels. Which machine learning (ML) approach should they use?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Semisupervised learning
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Why is model monitoring important in machine learning (ML)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It prevents overfitting by reducing the number of features in a dataset.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It ensures that a deployed model maintains accuracy and adapts to data changes.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It eliminates the need for retraining models over time.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: It guarantees that predictions will always be correct.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: ^([1](ch03.html#ch01fn1-marker)) Alex Woodie, [“Data Prep Still Dominates Data
    Scientists’ Time, Survey Finds”](https://oreil.ly/K1mvn), BigDATAwire, July 6,
    2020.
  prefs: []
  type: TYPE_NORMAL
