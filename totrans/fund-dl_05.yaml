- en: Chapter 5\. Implementing Neural Networks in PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。在PyTorch中实现神经网络
- en: Introduction to PyTorch
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch简介
- en: In this chapter, you will learn the basics of PyTorch, one of the most popular
    deep learning frameworks in use today. PyTorch was introduced by Facebook’s AI
    Research Lab in 2016 and gained users rapidly, both in industry and in research,
    through the following years. One reason for PyTorch’s widespread adoption was
    its intuitive, Pythonic feel, which fit naturally into the preexisting workstreams
    and coding paradigms followed by deep learning practitioners.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习PyTorch的基础知识，这是当今最流行的深度学习框架之一。PyTorch由Facebook的人工智能研究实验室于2016年推出，并在随后的几年中迅速获得用户，无论是在工业界还是研究领域。PyTorch被广泛采用的一个原因是其直观的、Pythonic的感觉，这与深度学习从业者遵循的现有工作流程和编码范式自然契合。
- en: In particular, this chapter will discuss the data structures utilized by PyTorch,
    how to define neural models in PyTorch, and how to connect data with models for
    training and testing. Finally, we implement a practical example in PyTorch—a classifier
    for the MNIST digits dataset, complete with code for training and testing the
    classifier.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，本章将讨论PyTorch使用的数据结构，如何在PyTorch中定义神经模型，以及如何将数据与模型连接起来进行训练和测试。最后，我们在PyTorch中实现一个实际的示例——一个用于MNIST数字数据集的分类器，包括用于训练和测试分类器的代码。
- en: Installing PyTorch
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装PyTorch
- en: Installing a CPU-compatible version of PyTorch is relatively simple. The PyTorch
    docs recommend using conda, a package management system. Within conda, you can
    create multiple environments, where an environment is a context that encapsulates
    all of your package installs. Access to a package does not transfer across environments—this
    allows the user to have a clean separation between different contexts by downloading
    packages within individual environments. We recommend that you create a conda
    environment for deep learning purposes that you can switch into whenever necessary.
    We refer you to the conda docs for guidance on how to download conda and further
    notes on environments.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 安装与CPU兼容的PyTorch版本相对简单。PyTorch文档建议使用conda，一个包管理系统。在conda中，您可以创建多个环境，其中环境是封装所有包安装的上下文。包的访问权限不会跨环境传递，这允许用户通过在各个环境中下载包来实现不同上下文的清晰分离。我们建议您为深度学习目的创建一个conda环境，以便在必要时切换到该环境。我们建议您参考conda文档，了解如何下载conda以及有关环境的进一步说明。
- en: 'Once you have installed conda, created your deep learning environment, and
    switched into it, the PyTorch docs recommend running the following code from your
    command line to download a CPU-compatible version of PyTorch on macOS:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您安装了conda，创建了深度学习环境并切换到该环境，PyTorch文档建议从命令行运行以下代码来下载macOS上与CPU兼容的PyTorch版本：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Note that with this install come torchvision and torchaudio, which are specialized
    packages for working with image data and audio data, respectively. If you are
    on a Linux system, the docs recommend running the following code from your command
    line:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，随此安装而来的还有torchvision和torchaudio，它们分别是用于处理图像数据和音频数据的专门包。如果您使用的是Linux系统，文档建议从命令行中运行以下代码：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, you can navigate to a Python shell (still in your deep learning environment),
    and the following command should run with no issues:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以转到Python shell（仍然在您的深度学习环境中），以下命令应该可以无问题运行：
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: It is important to get this command running with no errors in your Python shell
    before moving on to running the code in the following sections, as they all require
    the ability to import the PyTorch package.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续运行以下部分的代码之前，重要的是在Python shell中确保此命令无错误运行，因为它们都需要能够导入PyTorch包。
- en: PyTorch Tensors
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch张量
- en: Tensors are the primary data structure by which PyTorch stores and manipulates
    numerical information. Tensors can be seen as a generalization of arrays and matrices,
    which we covered in detail in our introduction to linear algebra in [Chapter 1](ch01.xhtml#fundamentals_of_linear_algebra_for_deep_learning).
    Specifically, tensors, as a generalization of 2D matrices and 1D arrays, can store
    multidimensional data such as batches of three-channel images. Note that this
    requires 4D data storage, since each image is 3D (including the channel dimension),
    and a fourth dimension that is required to index each individual image. Tensors
    can even represent dimensionalities beyond the 4D space, although the usage of
    such tensors in practice is uncommon.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 张量是PyTorch存储和操作数值信息的主要数据结构。张量可以被看作是数组和矩阵的泛化，我们在[第1章](ch01.xhtml#fundamentals_of_linear_algebra_for_deep_learning)中详细介绍了数组和矩阵。具体来说，张量作为2D矩阵和1D数组的泛化，可以存储多维数据，例如批量的三通道图像。请注意，这需要4D数据存储，因为每个图像是3D的（包括通道维度），还需要第四个维度来索引每个单独的图像。张量甚至可以表示超过4D空间的维度，尽管在实践中使用这样的张量是不常见的。
- en: In PyTorch, tensors are utilized universally. They are used to represent the
    inputs to models, the weight layers within the models themselves, and the outputs
    of models. The standard linear algebra operations of transposition, addition,
    multiplication, inversion, etc., can all be run on tensors.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch中，张量被广泛使用。它们用于表示模型的输入，模型内部的权重层以及模型的输出。张量上可以运行所有标准的线性代数操作，如转置、加法、乘法、求逆等。
- en: Tensor Init
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量初始化
- en: 'How do we initialize tensors? We can initialize a tensor from a variety of
    data types. Some examples are Python lists and Python numerical primitives:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何初始化张量？我们可以从各种数据类型初始化张量。一些示例是Python列表和Python数值原语：
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Tensors can also be initialized from NumPy arrays, allowing PyTorch to be integrated
    easily into existing data science and machine learning workflows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 张量也可以从NumPy数组中初始化，这使得PyTorch可以轻松地集成到现有的数据科学和机器学习工作流中：
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Additionally, tensors can be formed via some common PyTorch API endpoints:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，张量还可以通过一些常见的PyTorch API端点来形成：
- en: '[PRE5]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Tensor Attributes
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量属性
- en: 'In the examples we just saw, we passed a tuple as the argument to each function
    call. The number of indices in the tuple is the dimensionality of the tensor to
    be created, while the number at each index represents the desired size of that
    particular dimension. To access the dimensionality of a tensor, we can call its
    shape attribute:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们刚刚看到的例子中，我们将一个元组作为每个函数调用的参数传递。元组中的索引数量是要创建的张量的维度，而每个索引处的数字表示该特定维度的期望大小。要访问张量的维度，我们可以调用其形状属性：
- en: '[PRE6]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Calling the shape attribute on any of the previous examples should return the
    same tuple as the input argument, assuming the tensor has not been significantly
    modified in-between.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何先前示例中调用形状属性应该返回与输入参数相同的元组，假设张量在此期间没有被显着修改。
- en: 'What are some other attributes of tensors? In addition to dimension, tensors
    also store information on the type of data being stored: floating point, complex,
    integer, and boolean. There exist subtypes within each of these categories, but
    we won’t go into the differences between each subtype here. It’s also important
    to note that a tensor cannot contain a mix and match of various data types—all
    data within a single tensor must be of the same data type. To access the data
    type of a tensor, we can call its `dtype` attribute:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 张量还有哪些其他属性？除了维度，张量还存储有关存储的数据类型的信息：浮点数、复数、整数和布尔值。在每个类别中存在子类型，但我们不会在这里讨论每个子类型之间的区别。还要注意的是，张量不能包含各种数据类型的混合和匹配-单个张量中的所有数据必须是相同的数据类型。要访问张量的数据类型，我们可以调用其`dtype`属性：
- en: '[PRE7]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Additionally, although we haven’t shown this yet, we can set the data type
    of a tensor during initialization. Extending one of our previous examples:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，尽管我们尚未展示这一点，但我们可以在初始化期间设置张量的数据类型。扩展我们先前的一个示例：
- en: '[PRE8]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In addition to the data type and shape of a tensor, we can also learn the device
    on which the tensor is allocated. These devices include the famous CPU, which
    is standard with any computer and is the default storage for any tensor, and the
    GPU, or graphics processing unit, which is a specialized data processing unit
    often used in the image space. GPUs massively speed up many common tensor operations
    such as multiplication via parallel processing over hundreds of small, specialized
    cores, thus making them immensely useful for most deep learning applications.
    To access the tensor device, we can call its device attribute:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了张量的数据类型和形状，我们还可以了解张量所分配的设备。这些设备包括著名的CPU，它是任何计算机的标准设备，也是任何张量的默认存储设备，以及GPU，即图形处理单元，它是专门用于图像空间的数据处理单元。
    GPU通过在数百个小型专用核心上进行并行处理，大大加快了许多常见张量操作，例如乘法，因此使它们在大多数深度学习应用中非常有用。要访问张量设备，我们可以调用其设备属性：
- en: '[PRE9]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Similarly to data type, we can set the device of a tensor upon initialization:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 与数据类型类似，我们可以在初始化时设置张量的设备：
- en: '[PRE10]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This is a common approach to checking whether a GPU is available via code and
    using a GPU if it is available.  If the GPU is not available, it will use a CPU
    without error.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过代码检查GPU是否可用并在可用时使用GPU的常见方法。如果GPU不可用，它将在没有错误的情况下使用CPU。
- en: 'If you have defined a tensor with a certain set of attributes and would like
    to modify these attributes, you can use the `to` function:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经定义了具有一组特定属性的张量，并希望修改这些属性，可以使用`to`函数：
- en: '[PRE11]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: And finally, as we’ll cover in [“Gradients in PyTorch”](#gradients-in-pytorch),
    PyTorch tensors can be initialized with the argument `requires_grad`, which when
    set to `True`, stores the tensor’s gradient in an attribute called `grad`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，正如我们将在[“PyTorch中的梯度”](#gradients-in-pytorch)中介绍的那样，PyTorch张量可以使用参数`requires_grad`进行初始化，当设置为`True`时，将张量的梯度存储在名为`grad`的属性中。
- en: Tensor Operations
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量操作
- en: The PyTorch API provides us with many possible tensor operations, ranging from
    tensor arithmetic to tensor indexing. In this section we will cover some of the
    more useful tensor operations—ones that you will likely use often in your deep
    learning applications.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch API为我们提供了许多可能的张量操作，从张量算术到张量索引。在本节中，我们将介绍一些更有用的张量操作-这些操作在深度学习应用中经常使用。
- en: 'One of the most basic operations is multiplying a tensor by some scalar `c`.
    This can be achieved via the code:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的操作之一是将张量乘以某个标量`c`。这可以通过以下代码实现：
- en: '[PRE12]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This results in an element-wise product of the scalar with the entries of the
    tensor. Another one of the most basic tensor operations is tensor addition and
    subtraction. To do this, we can simply add tensors via `+`. Subtraction follows
    directly from being able to do addition and multiplying the second tensor by the
    scalar –1:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致标量与张量条目的逐元素乘积。张量加法和减法是最基本的张量操作之一。要做到这一点，我们可以通过`+`简单地添加张量。减法直接来自能够进行加法并将第二个张量乘以标量-1：
- en: '[PRE13]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The result is an element-wise sum of the two tensors. This can be seen as a
    direct generalization of matrix addition for any dimensionality. Note that this
    direct generalization implicitly assumes the same constraint we discussed for
    matrix addition a while ago: that the two tensors being summed are of the same
    dimension. PyTorch, similarly, will accept any two broadcastable inputs with no
    issues, where broadcasting is a procedure by which the two inputs are resolved
    to a common shape, and broadcastable refers to whether it is even possible for
    the two inputs to be resolved to a common shape. If the two tensors are already
    of the same shape, no broadcasting is necessary. We refer you to the [PyTorch
    documentation](https://oreil.ly/rHEdO) for more information on how the API determines
    if the two inputs are broadcastable, and how broadcasting is performed in such
    cases.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: 'Tensor multiplication is another useful operation to become familiar with.
    Tensor multiplication works the same as matrix and vector multiplication when
    the dimensionality of each tensor is less than or equal to 2\. However, tensor
    multiplication also works on tensors of arbitrarily high dimensionality, given
    the two tensors are compatible. We can think of tensor multiplication in high
    dimensions as batched matrix multiplications: imagine we have two tensors, the
    first is of shape (2,1,2) and the second is of shape (2,2,2). We can further represent
    the first tensor as a length-two list of 1 × 2 matrices, while the second is a
    length-two list of 2 × 2 matrices. Their product is a length-two list, where index
    *i* of the product is the matrix product of index *i* of the first tensor and
    index *i* of the second tensor, as shown in [Figure 5-1](#to_help_visualize_the_general_tensor).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/fdl2_0501.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: Figure 5-1\. To help visualize the general tensor multiplication method, this
    figure shows the matrix multiplication that occurs before restacking.
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Restacking the resultant list into a 3D tensor, we see that the product is
    of shape (2,1,2). Now, we can generalize this to four dimensions, where instead
    of imagining we have a list of matrices, we represent each 4D tensor as a grid
    of matrices and the *(i,j)*-th index of the product is the matrix product of the
    *(i,j)*-th indices of the two 4D input tensors. We represent this mathematically:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P Subscript i comma j comma x comma z Baseline equals sigma-summation
    Underscript y Endscripts upper A Subscript i comma j comma x comma y Baseline
    asterisk upper B Subscript i comma j comma y comma z"><mrow><msub><mi>P</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>x</mi><mo>,</mo><mi>z</mi></mrow></msub>
    <mo>=</mo> <msub><mo>∑</mo> <mi>y</mi></msub> <msub><mi>A</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>x</mi><mo>,</mo><mi>y</mi></mrow></msub>
    <mo>*</mo> <msub><mi>B</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi></mrow></msub></mrow></math>
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P Subscript i comma j comma x comma z Baseline equals sigma-summation
    Underscript y Endscripts upper A Subscript i comma j comma x comma y Baseline
    asterisk upper B Subscript i comma j comma y comma z"><mrow><msub><mi>P</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>x</mi><mo>,</mo><mi>z</mi></mrow></msub>
    <mo>=</mo> <msub><mo>∑</mo> <mi>y</mi></msub> <msub><mi>A</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>x</mi><mo>,</mo><mi>y</mi></mrow></msub>
    <mo>*</mo> <msub><mi>B</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo>,</mo><mi>y</mi><mo>,</mo><mi>z</mi></mrow></msub></mrow></math>
- en: 'This procedure is generalizable to any dimensionality, assuming that the two
    input tensors follow the constraints of matrix multiplication. As with tensor
    addition, there are exceptions that involve broadcasting, though we won’t cover
    those in detail here. We refer you to the PyTorch documentation for detailed information
    on broadcasting. To multiply two tensors in PyTorch, you can use the `torch matmul`
    function:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In addition to arithmetic operations on tensors, we can also index and slice
    tensors. If you have prior experience with NumPy, you’ll notice that PyTorch indexing
    is very similar and is based on linear algebra fundamentals. If you have a 3D
    tensor, you can access the value at position *(i,j,k)* via the following code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To access larger slices of the tensor, say the matrix at position 0 in a 3D
    tensor, you can use the following code:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'where the two lines of code are interpreted to be equivalent by the PyTorch
    API. This is because using a single indexer, such as `x3_t[0]`, implicitly assumes
    that the user would like to access all indices *(i,j,k)* that satisfy the condition
    *i* = 0 (i.e., the top matrix in the stack of matrices that is the original 3D
    tensor). Usage of the `:` symbol makes this implicit assumption clear by telling
    PyTorch directly that the user would not like to subset the data at that dimension.
    We can also use the `:` symbol to subset the data, for example:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'where the last line of code is interpreted as: find all indices *(i,j,k)* such
    that *i* = 0, <math alttext="j greater-than-or-equal-to 1"><mrow><mi>j</mi> <mo>≥</mo>
    <mn>1</mn></mrow></math> , and <math alttext="j less-than 3"><mrow><mi>j</mi>
    <mo><</mo> <mn>3</mn></mrow></math> (`:` follows the standard Python list indexing
    convention of being inclusive at the start of the defined range and exclusive
    at the end). In plain English, we want to access the second and third rows of
    the top matrix in the stack of matrices that is the original 3D tensor. Note that
    this usage of `:` is consistent with standard Python list indexing.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 其中代码的最后一行被解释为：找到所有索引*(i,j,k)*，使得*i* = 0，*j*大于或等于1，并且*j*小于3（`:`遵循标准的Python列表索引约定，在定义范围的开始处是包含的，结束处是不包含的）。简单来说，我们想要访问原始3D张量中堆叠的矩阵的顶部矩阵的第二行和第三行。请注意，这种对`:`的使用与标准的Python列表索引一致。
- en: 'In addition to accessing indices or slices of a tensor, we can also set those
    indices and slices to new values. In the single index case, this is as simple
    as:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 除了访问张量的索引或切片之外，我们还可以将这些索引和切片设置为新值。在单索引的情况下，这很简单：
- en: '[PRE18]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'To set larger slices of the tensor, the most straightforward way is to define
    a tensor that is of the same dimensionality as the slice, and use the following
    code:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置张量的较大切片，最直接的方法是定义一个与切片具有相同维度的张量，并使用以下代码：
- en: '[PRE19]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Additionally, via broadcasting, we can do things like:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过广播，我们可以做如下操作：
- en: '[PRE20]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The first line sets the entirety of those two rows to 1, and the second sets
    both rows of the slice to the single row passed in as `sub_tensor`. In the next
    section, we will show how to compute the gradients of a function in PyTorch, and
    how to access the values of those gradients.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行将这两行的全部设置为1，第二行将切片的两行都设置为传入的单行`sub_tensor`。在下一节中，我们将展示如何在PyTorch中计算函数的梯度，以及如何访问这些梯度的值。
- en: Gradients in PyTorch
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch中的梯度
- en: 'Just as a recap, let’s recall derivatives and partial derivatives from calculus.
    The partial derivative of a function, which could be as simple as a polynomial
    function of a few variables to something as complex as a neural network, with
    respect to one of the function’s inputs represents the rate of change of the output
    of the function as that input’s value changes slightly. So, large magnitude derivatives
    indicate that the output is very volatile with small changes in the input (think
    <math alttext="f left-parenthesis x right-parenthesis equals x Superscript 10"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>x</mi> <mn>10</mn></msup></mrow></math>
    when x is of moderate size), while small magnitude derivatives indicate that the
    output is relatively stable with small changes in the input (think <math alttext="f
    left-parenthesis x right-parenthesis equals StartFraction x Over 10 EndFraction"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mfrac><mi>x</mi> <mn>10</mn></mfrac></mrow></math>
    ). If the function takes in more than one input, the gradient is the vector that
    is composed of all of these partial derivatives:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作为回顾，让我们回顾一下微积分中的导数和偏导数。函数的偏导数，可以是简单的多变量多项式函数，也可以是复杂的神经网络，相对于函数的一个输入表示函数输出随着该输入值稍微变化的变化速率。因此，大幅度的导数表示输出在输入稍微变化时非常不稳定（当*x*是适度大小时，考虑*f(x)
    = x^10*），而小幅度的导数表示输出在输入稍微变化时相对稳定（考虑*f(x) = x/10*）。如果函数接受多个输入，则梯度是由所有这些偏导数组成的向量：
- en: <math alttext="f left-parenthesis x comma y comma z right-parenthesis equals
    x squared plus y squared plus z squared"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>,</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>x</mi>
    <mn>2</mn></msup> <mo>+</mo> <msup><mi>y</mi> <mn>2</mn></msup> <mo>+</mo> <msup><mi>z</mi>
    <mn>2</mn></msup></mrow></math>
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="f left-parenthesis x comma y comma z right-parenthesis equals
    x squared plus y squared plus z squared"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>,</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>x</mi>
    <mn>2</mn></msup> <mo>+</mo> <msup><mi>y</mi> <mn>2</mn></msup> <mo>+</mo> <msup><mi>z</mi>
    <mn>2</mn></msup></mrow></math>
- en: <math alttext="StartFraction normal partial-differential f Over normal partial-differential
    x EndFraction equals normal nabla Subscript x Baseline f left-parenthesis x comma
    y comma z right-parenthesis equals 2 x"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mo>=</mo> <msub><mi>∇</mi> <mi>x</mi></msub>
    <mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>,</mo> <mi>z</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mn>2</mn> <mi>x</mi></mrow></math>
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential f Over normal partial-differential
    x EndFraction equals normal nabla Subscript x Baseline f left-parenthesis x comma
    y comma z right-parenthesis equals 2 x"><mrow><mfrac><mrow><mi>∂</mi><mi>f</mi></mrow>
    <mrow><mi>∂</mi><mi>x</mi></mrow></mfrac> <mo>=</mo> <msub><mi>∇</mi> <mi>x</mi></msub>
    <mi>f</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>,</mo> <mi>z</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mn>2</mn> <mi>x</mi></mrow></math>
- en: <math alttext="normal nabla f equals left-bracket 2 x Baseline 2 y Baseline
    2 z right-bracket"><mrow><mi>∇</mi> <mi>f</mi> <mo>=</mo> <mo>[</mo> <mn>2</mn>
    <mi>x</mi> <mn>2</mn> <mi>y</mi> <mn>2</mn> <mi>z</mi> <mo>]</mo></mrow></math>
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal nabla f equals left-bracket 2 x Baseline 2 y Baseline
    2 z right-bracket"><mrow><mi>∇</mi> <mi>f</mi> <mo>=</mo> <mo>[</mo> <mn>2</mn>
    <mi>x</mi> <mn>2</mn> <mi>y</mi> <mn>2</mn> <mi>z</mi> <mo>]</mo></mrow></math>
- en: 'Continuing from this example, how would we represent this in PyTorch? We can
    use the following code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 继续这个例子，我们如何在PyTorch中表示这个呢？我们可以使用以下代码：
- en: '[PRE21]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The call to `backward()` computes the partial derivative of the output *f* with
    respect to each of the input variables. We should expect the values for `x.grad`,
    `y.grad`, and `z.grad` to be 4.0, 6.0, and 3.0, respectively. In the case of neural
    networks, we can represent the neural network as <math alttext="f left-parenthesis
    x comma theta right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo>
    <mi>θ</mi> <mo>)</mo></mrow></math> , where *f* is the neural network, *x* is
    some vector representing the input, and  <math alttext="theta"><mi>θ</mi></math>
    is the parameters of *f*. Instead of computing the gradient of the output of *f*
    with respect to *x* as done in the previous example, we compute the gradient of
    the loss of the output of *f* with respect to <math alttext="theta"><mi>θ</mi></math>
    . Adjusting <math alttext="theta"><mi>θ</mi></math>  via the gradient will eventually
    lead to a setting of <math alttext="theta"><mi>θ</mi></math>  that results in
    a small loss for the training data and one that hopefully generalizes to data
    that *f* hasn’t seen before. In the next section, we will introduce the building
    blocks of neural networks.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`backward()`计算输出*f*相对于每个输入变量的偏导数。我们应该期望`x.grad`，`y.grad`和`z.grad`的值分别为4.0，6.0和3.0。在神经网络的情况下，我们可以将神经网络表示为*f(x,θ)*，其中*f*是神经网络，*x*是表示输入的向量，*θ*是*f*的参数。与前面的例子中计算*f*输出相对于*x*的梯度不同，我们计算*f*输出的损失相对于*θ*的梯度。通过梯度调整*θ*最终将导致*θ*的设置使得训练数据的损失很小，并且希望泛化到*f*之前没有见过的数据。在下一节中，我们将介绍神经网络的构建模块。
- en: The PyTorch nn Module
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch nn模块
- en: 'The PyTorch `nn` module provides all of the baseline functionality necessary
    for defining, training, and testing a model. To import the `nn` module, all you
    need to do is run the following line of code:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的`nn`模块提供了定义、训练和测试模型所需的所有基本功能。要导入`nn`模块，您只需要运行以下代码行：
- en: '[PRE22]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In this section, we will cover some of the most common uses of the `nn` module.
    For example, to initialize a weight matrix needed for a feed-forward neural network,
    you can use the following code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍`nn`模块的一些最常见用法。例如，要初始化前馈神经网络所需的权重矩阵，可以使用以下代码：
- en: '[PRE23]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This defines a single layer with bias in a feed-forward neural network, which
    is a matrix of weights that takes as input a vector of dimension 256 and outputs
    a vector of dimension 10\. The last line of code demonstrates how we can easily
    apply this layer to an input vector and store the output in a new tensor. If we
    wanted to do the same thing using only our knowledge from prior sections, we would
    need to manually define a weight matrix `W` and bias vector `b` via `torch`.tensor
    and explicitly compute:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这定义了一个带有偏置的前馈神经网络中的单层，它是一个权重矩阵，接受维度为256的向量作为输入，并输出维度为10的向量。代码的最后一行演示了如何将这一层轻松应用于输入向量，并将输出存储在一个新的张量中。如果我们想要仅使用我们之前章节的知识来做同样的事情，我们需要手动定义一个权重矩阵`W`和偏置向量`b`，通过`torch`.tensor并显式计算：
- en: '[PRE24]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `nn` module’s Linear layer allows us to abstract away these manual operations
    so we can write clean, concise code.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`nn`模块的Linear层允许我们将这些手动操作抽象化，以便编写干净、简洁的代码。'
- en: 'A feed-forward neural network can be thought of as simply a composition of
    such layers, for example:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 前馈神经网络可以简单地被视为这些层的组合，例如：
- en: '[PRE25]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This code represents a neural network that is the function composition `layer2(layer1(vec))`,
    or mathematically: <math alttext="upper W 2 left-parenthesis upper W 1 asterisk
    x plus b 1 right-parenthesis plus b 2"><mrow><msub><mi>W</mi> <mn>2</mn></msub>
    <mrow><mo>(</mo> <msub><mi>W</mi> <mn>1</mn></msub> <mo>*</mo> <mi>x</mi> <mo>+</mo>
    <msub><mi>b</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <msub><mi>b</mi>
    <mn>2</mn></msub></mrow></math> . To represent more complex, nonlinear functions,
    the `nn` module additionally provides nonlinearities such as ReLU, which can be
    accessed via `nn.ReLU`, and tanh, which can be accessed via `nn.Tanh`. These nonlinearities
    are applied in between layers, as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码表示一个神经网络，即函数组合`layer2(layer1(vec))`，或者数学上：<math alttext="upper W 2 left-parenthesis
    upper W 1 asterisk x plus b 1 right-parenthesis plus b 2"><mrow><msub><mi>W</mi>
    <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi>W</mi> <mn>1</mn></msub> <mo>*</mo>
    <mi>x</mi> <mo>+</mo> <msub><mi>b</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>+</mo>
    <msub><mi>b</mi> <mn>2</mn></msub></mrow></math>。为了表示更复杂、非线性的函数，`nn`模块还提供了诸如ReLU（通过`nn.ReLU`访问）和tanh（通过`nn.Tanh`访问）等非线性。这些非线性应用在层之间，如下所示：
- en: '[PRE26]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We’ve gone over almost everything necessary to define a model in PyTorch. The
    last thing to cover is the `nn.Module` class—the base class from which all neural
    networks are subclassed in PyTorch.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经几乎涵盖了在PyTorch中定义模型所需的一切。最后要介绍的是`nn.Module`类——所有神经网络在PyTorch中都是从这个基类继承的。
- en: 'The `nn.Module` class has one important method that your specific model’s subclass
    will override. This method is the forward method, and it defines how the layers
    initialized in your model’s constructor interact with the input to generate the
    model’s output. Here is an example of some code that can be used to encapsulate
    the simple two-layer neural network we just defined:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`nn.Module`类有一个重要的方法，你特定模型的子类将覆盖这个方法。这个方法是前向方法，它定义了在模型的构造函数中初始化的层如何与输入交互以生成模型的输出。这里是一个可以用来封装我们刚刚定义的简单两层神经网络的代码示例：'
- en: '[PRE27]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We’ve written our first neural network in PyTorch! `BaseClassifier` is a bug-free
    model class that can be instantiated after defining `in_dim`, `feature_dim`, and
    `out_dim`. The constructor takes in these three variables as arguments in the
    constructor, which makes the model flexible in terms of layer size. This is the
    sort of model that can be used effectively as a first-pass classifier for datasets
    such as MNIST, as we will demonstrate in [“Building the MNIST Classifier in PyTorch”](#building-mnist-sect1).
    To generate the output of a model on some input, we can use the model as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在PyTorch中编写了我们的第一个神经网络！`BaseClassifier`是一个无bug的模型类，可以在定义`in_dim`、`feature_dim`和`out_dim`之后实例化。构造函数将这三个变量作为参数传入构造函数，这使得模型在层大小方面更加灵活。这种模型可以有效地用作诸如MNIST之类的数据集的第一次分类器，正如我们将在[“在PyTorch中构建MNIST分类器”](#building-mnist-sect1)中演示的那样。要在某些输入上生成模型的输出，我们可以按照以下方式使用模型：
- en: '[PRE28]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note that we implicitly call the forward function when using the classifier
    model as a function in the final line. Comparing this to the initial approach
    of manually defining each layer’s parameters as a torch tensor and computing the
    output via `matmul` operations, this is a much more clean, modular, and reusable
    approach to defining neural networks.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在最后一行中将分类器模型作为函数使用时，我们隐式调用了前向函数。与最初手动定义每个层参数并通过`matmul`操作计算输出的方法相比，这是一种更加清晰、模块化和可重用的定义神经网络的方法。
- en: 'In addition to being able to define the model, instantiate it, and run data
    through it, we must be able to train and test the model. To train (and test) the
    model, we need a loss metric to evaluate the model. During training, once we calculate
    this loss metric, we can use our knowledge from the previous section and call
    `backward()` on the computed loss. This will store the gradient in each parameter
    p’s `grad` attribute. Since we have defined a classifier model, we can use the
    cross-entropy `loss` metric from PyTorch `nn`:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 除了能够定义模型、实例化它并通过数据运行它之外，我们还必须能够训练和测试模型。要训练（和测试）模型，我们需要一个损失度量来评估模型。在训练过程中，一旦计算了这个损失度量，我们可以利用上一节的知识，并在计算的损失上调用`backward()`。这将把每个参数p的梯度存储在`grad`属性中。由于我们已经定义了一个分类器模型，我们可以使用PyTorch
    `nn`中的交叉熵`loss`度量：
- en: '[PRE29]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In the preceding code, `target` is a tensor of shape (`no_examples`), and each
    index represents the ground truth class of the input corresponding with that index.
    Now that we’ve computed the gradient of the loss of the minibatch of examples
    with respect to all of the parameters in the classifier, we can perform the gradient
    descent step. When defining a neural network as a subclass of `nn.Module`, we
    can access all of its parameters via the `parameters()` function—another convenience
    provided by the PyTorch API. To view the shape of each parameter in the neural
    network, you can run the code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，`target`是一个形状为(`no_examples`)的张量，每个索引表示与该索引对应的输入的地面真实类。现在我们已经计算出了相对于分类器中所有参数的小批量示例的损失的梯度，我们可以执行梯度下降步骤。当将神经网络定义为`nn.Module`的子类时，我们可以通过`parameters()`函数访问其所有参数——这是PyTorch
    API提供的另一个便利。要查看神经网络中每个参数的形状，您可以运行以下代码：
- en: '[PRE30]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: As we can see, the first layer has 256 × 784 weights and a bias vector of length
    256\. The last layer has 10 × 256 weights and a bias vector of length 10.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，第一层有256×784个权重和长度为256的偏置向量。最后一层有10×256个权重和长度为10的偏置向量。
- en: 'During gradient descent, we need to adjust the parameters based on their gradients.
    We could do this manually, but PyTorch has abstracted away this functionality
    into the `torch.optim` module. This module provides functionality for determining
    the optimizer, which may be more complex than classic gradient descent, and updating
    the parameters of the model. You can define the optimizer as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在梯度下降过程中，我们需要根据梯度调整参数。我们可以手动执行此操作，但PyTorch将此功能抽象为`torch.optim`模块。该模块提供了确定优化器的功能，这可能比经典梯度下降更复杂，并更新模型的参数。您可以按照以下方式定义优化器：
- en: '[PRE31]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This code creates an optimizer that will update the parameters of the classifier
    via SGD at the end of each minibatch. To actually perform this update, you can
    use the following code:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码创建了一个优化器，它将在每个小批量结束时通过SGD更新分类器的参数。要实际执行此更新，您可以使用以下代码：
- en: '[PRE32]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In the simple case of a feed-forward network as defined in `BaseClassifier`,
    the testing mode of such a network is the same as the training mode—we can just
    call `classifier(test_x)` on any minibatch in the test set to evaluate the model.
    However, as we’ll discuss later, this is not true for all neural architectures.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在`BaseClassifier`中定义的前馈网络的简单情况下，这种网络的测试模式与训练模式相同——我们只需在测试集中的任何小批量上调用`classifier(test_x)`来评估模型。然而，正如我们将在后面讨论的那样，这并不适用于所有神经网络架构。
- en: This code works for a single minibatch—performing training over the entire dataset
    would require manually shuffling the dataset at each epoch and splitting the dataset
    into minibatches that can be iterated through. Thankfully, PyTorch has also abstracted
    this process out into what are called PyTorch datasets and dataloaders. In the
    next section, we will cover these modules in detail.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码适用于单个小批量——在整个数据集上进行训练需要在每个epoch手动洗牌数据集并将数据集分成可以迭代的小批量。幸运的是，PyTorch还将这个过程抽象成了所谓的PyTorch数据集和数据加载器。在下一节中，我们将详细介绍这些模块。
- en: PyTorch Datasets and Dataloaders
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch数据集和数据加载器
- en: 'The PyTorch `Dataset` is a base class that can be used to access your specific
    data. In practice, you would subclass the `Dataset` class by overriding two important
    methods: `__len__()` and `__getitem__()`. The first method, as you can probably
    tell from its name, refers to the length of the dataset—i.e., the number of examples
    that the model will be trained or tested on. If we think of the dataset as a list
    of examples, the second method takes as input an index and returns the example
    at that index. Each example consists of both the data point (e.g., image) and
    label (e.g., value from 0 to 9 in the case of MNIST). Here is some example code
    for a dataset:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的`Dataset`是一个基类，可用于访问您的特定数据。在实践中，您可以通过覆盖两个重要方法`__len__()`和`__getitem__()`来子类化`Dataset`类。第一个方法，从其名称中您可能已经猜到，是指数据集的长度——即模型将在其上进行训练或测试的示例数量。如果我们将数据集视为示例列表，则第二个方法接受一个索引并返回该索引处的示例。每个示例包括数据点（例如图像）和标签（例如MNIST中从0到9的值）。以下是一个数据集的示例代码：
- en: '[PRE33]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: In this example, we assume that the directory containing our dataset consists
    of images that follow the naming convention *img-idx.png*, where *idx* refers
    to the index of the image. Additionally, we assume that our ground-truth labels
    are stored in a saved NumPy array, which can be loaded and indexed using *idx*
    to find each image’s corresponding label.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们假设包含数据集的目录包含遵循命名约定*img-idx.png*的图像，其中*idx*是图像的索引。此外，我们假设我们的地面真实标签存储在一个保存的NumPy数组中，可以使用*idx*加载和索引以找到每个图像对应的标签。
- en: 'The `DataLoader` class in PyTorch takes as input a dataset instantiation, and
    abstracts away all of the heavy lifting required to load in the dataset by the
    minibatch and shuffle the dataset between epochs. Although we won’t go behind
    the scenes in too much depth, the `DataLoader` class does make use of Python’s
    multiprocessing built-in module to efficiently load minibatches in parallel. Here
    is some example code that puts everything together:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch中的`DataLoader`类以数据集实例作为输入，并将加载数据集所需的所有繁重工作抽象化，通过小批量加载数据集并在不同epoch之间对数据集进行洗牌。虽然我们不会深入了解背后的细节，`DataLoader`类确实利用了Python的内置多进程模块来并行高效地加载小批量数据。以下是将所有内容整合在一起的一些示例代码：
- en: '[PRE34]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To iterate through these dataloaders, use the following code as a template:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要遍历这些数据加载器，请使用以下代码作为模板：
- en: '[PRE35]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The data returned is a tensor of shape (64,784) and the labels returned are
    of shape (64,). As you can tell, the dataloader also does the work of stacking
    all of the examples into a single tensor that can simply be run through the network:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的数据是形状为(64,784)的张量，返回的标签是形状为(64,)的张量。正如您所看到的，数据加载器还会将所有示例堆叠到一个可以简单通过网络运行的单个张量中：
- en: '[PRE36]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: where `out` is of shape (64,10) in the case of MNIST. In the next section, we
    will put together all of our learnings to build a neural architecture that can
    be trained and tested on the MNIST dataset, provide code samples for training
    and testing the model by building off of work in this section, and show example
    training and testing loss curves.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 其中`out`在MNIST的情况下是形状为（64,10）。在下一节中，我们将汇总所有的学习成果，构建一个可以在MNIST数据集上进行训练和测试的神经架构，提供训练和测试模型的代码示例，通过在本节的工作基础上构建，并展示示例训练和测试损失曲线。
- en: Building the MNIST Classifier in PyTorch
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在PyTorch中构建MNIST分类器
- en: 'It’s time to build an MNIST classifier in PyTorch. For the most part, we can
    reuse a lot of the code presented and explained earlier:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是在PyTorch中构建一个MNIST分类器的时候了。在很大程度上，我们可以重用之前介绍和解释的大部分代码：
- en: '[PRE37]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Note that, by default, the minibatch tensors and model parameters are on CPU,
    so there was no need to call the `to` function on each of these to change the
    device. Also, the MNIST dataset provided by PyTorch unfortunately does not come
    with a validation set, so we’ll do our best to use insights solely from the training
    loss curve to inform our final hyperparameter decision for the test set:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，默认情况下，小批量张量和模型参数都在CPU上，因此不需要在每个上调用`to`函数来更改设备。此外，PyTorch提供的MNIST数据集不幸地没有提供验证集，因此我们将尽力仅使用训练损失曲线的见解来为测试集的最终超参数决策提供信息：
- en: '[PRE38]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Additionally, note that we call `classifier.train()` and `classifier.eval()`
    at the beginning of the training and test functions, respectively. The calls to
    these functions communicate to the PyTorch backend whether the model is in training
    mode or inference mode. You might be wondering why we need to call `classifier.train()`
    and `classifier.eval()` if there is no difference between the behavior of the
    neural network at train and test time. Although this is true in our first-pass
    example, the training and testing modes for other neural architectures are not
    necessarily the same. For example, if dropout layers are added to the model architecture,
    the dropout layers need to be ignored during the testing phase. We add in the
    calls to `train()` and `eval()` here since it is generally considered good practice
    to do so.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请注意，在训练和测试函数的开始分别调用`classifier.train()`和`classifier.eval()`。对这些函数的调用向PyTorch后端传达了模型是处于训练模式还是推理模式。您可能会想知道为什么我们需要调用`classifier.train()`和`classifier.eval()`，如果在训练和测试时间神经网络的行为没有区别。尽管在我们的第一次尝试中是这样，但其他神经架构的训练和测试模式并不一定相同。例如，如果在模型架构中添加了dropout层，则在测试阶段需要忽略dropout层。我们在这里添加`train()`和`eval()`的调用，因为通常认为这样做是一个好习惯。
- en: As a first step, we need to set some starting hyperparameters for model training.
    We start with a slightly conservative learning rate in `1e-4` and inspect the
    training loss curve and testing accuracy after 40 epochs, or iterations through
    the entire dataset. [Figure 5-2](#we_see_signs_of_underfitting_as_the_model_performance)
    shows a graph of the training loss curve through the epochs.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一步，我们需要为模型训练设置一些起始超参数。我们从稍微保守的学习率`1e-4`开始，并在40个epochs或整个数据集的迭代后检查训练损失曲线和测试准确率。[图5-2](#we_see_signs_of_underfitting_as_the_model_performance)显示了通过epochs的训练损失曲线的图表。
- en: '![](Images/fdl2_0502.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/fdl2_0502.png)'
- en: Figure 5-2\. We see signs of underfitting as the model performance on the training
    set is failing to level out, meaning we have not yet settled into a local optimum
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-2。我们看到欠拟合的迹象，因为模型在训练集上的表现未能平稳下来，这意味着我们尚未进入局部最优解
- en: We can see that this loss curve is not particularly close to leveling out near
    the end of training, which we’d hope to start seeing for a model training at a
    sufficient learning rate. And although we don’t have a validation set to confirm
    our suspicions, we have strong reason to suspect that a higher learning rate would
    help. After setting the learning rate to a slightly more aggressive `1e-3`, we
    observe a training loss curve that is much more in line with what we’d hope to
    see ([Figure 5-3](#this_leveling_out_of_the_loss_curve_is_more_like_what_wed_expect_to_see_with_an_appropriate_learning_rate)).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这个损失曲线在训练结束时并没有接近平稳，我们希望看到的是一个以足够学习率训练的模型开始出现的情况。虽然我们没有验证集来确认我们的怀疑，但我们有充分的理由怀疑更高的学习率会有所帮助。将学习率设置为稍微更积极的`1e-3`后，我们观察到训练损失曲线更符合我们所期望看到的情况（[图5-3](#this_leveling_out_of_the_loss_curve_is_more_like_what_wed_expect_to_see_with_an_appropriate_learning_rate)）。
- en: '![](Images/fdl2_0503.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/fdl2_0503.png)'
- en: Figure 5-3\. This leveling out of the loss curve is more like what we’d expect
    to see with an appropriate learning rate for the problem
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-3。损失曲线的平稳是我们对于问题的合适学习率所期望看到的更多的情况
- en: The loss curve starts to level out only near the end of training. This trend
    indicates that the model is likely in the sweet spot between underfitting to the
    training data, like our previous attempt, and overfitting to the training data.
    Evaluating the trained model at 40 epochs on the test set achieves an accuracy
    of 91%! Although this is nowhere close to the top performers on MNIST today, which
    primarily use convolutional neural classifiers, it is a great start. We recommend
    you try some extensions to the code, such as increasing the number of hidden layers
    and substituting in a more sophisticated optimizer.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 损失曲线仅在训练结束时开始平稳下来。这种趋势表明模型很可能处于欠拟合训练数据和过拟合训练数据之间的最佳状态，就像我们之前的尝试一样。在测试集上对40个epochs训练的模型进行评估，准确率达到91％！虽然这与今天MNIST的顶尖表现者相去甚远，后者主要使用卷积神经分类器，但这是一个很好的开始。我们建议您尝试对代码进行一些扩展，例如增加隐藏层的数量并替换更复杂的优化器。
- en: Summary
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the basics of PyTorch and its functionality. Specifically,
    we learned the concept of tensors in PyTorch, and how these tensors store numerical
    information. Additionally, we learned how to manipulate tensors via tensor operations,
    access the data within a tensor, and set a few important attributes. We also discussed
    gradients in PyTorch and how they can be stored within a tensor. We built our
    first neural network via standard `nn` functionality in the the PyTorch `nn` module
    section. Comparing the `nn`-based approach with an approach that used PyTorch
    tensors solely out of the box showed much of the effective abstraction that the
    `nn` module provides, lending to its ease of use. And finally, we put all of our
    learnings together in the final section, where we trained and tested an MNIST
    digits feed-forward neural classifier to 91% accuracy on the PyTorch-provided
    test set. Although we covered much of the fundamentals and have equipped you with
    the knowledge you need to get your hands dirty, we have only scratched the surface
    of all that the PyTorch API has to offer—we encourage you to explore further and
    improve upon the models we built in this section. We recommend that you visit
    the PyTorch documentation to learn more and build your own neural nets, including
    trying other architectures, on a variety of online datasets, such as the CIFAR-10
    image recognition datasets. In the next section, we will cover neural network
    implementation, one of the other most popular deep learning frameworks in use
    today.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们涵盖了PyTorch及其功能的基础知识。具体来说，我们学习了PyTorch中张量的概念，以及这些张量如何存储数值信息。此外，我们还学习了如何通过张量操作来操作张量，访问张量中的数据，并设置一些重要的属性。我们还讨论了PyTorch中的梯度以及它们如何存储在张量中。我们通过PyTorch
    `nn`模块部分的标准`nn`功能构建了我们的第一个神经网络。将基于`nn`的方法与仅使用PyTorch张量的方法进行比较，显示了`nn`模块提供的有效抽象，使其易于使用。最后，在最后一节中，我们将所有学到的知识结合起来，在PyTorch提供的测试集上训练和测试了一个MNIST手写数字前馈神经分类器，准确率达到了91%。虽然我们涵盖了许多基础知识，并为您提供了您需要动手实践的知识，但我们只是触及了PyTorch
    API所提供的所有内容的表面—我们鼓励您进一步探索并改进我们在本节中构建的模型。我们建议您访问PyTorch文档以了解更多信息，并构建自己的神经网络，包括尝试其他架构，应用于各种在线数据集，如CIFAR-10图像识别数据集。在下一节中，我们将涵盖神经网络实现，这是当今另一个最流行的深度学习框架之一。
