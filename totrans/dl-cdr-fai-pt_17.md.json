["```py\ntop_edge = tensor([[-1,-1,-1],\n                   [ 0, 0, 0],\n                   [ 1, 1, 1]]).float()\n```", "```py\npath = untar_data(URLs.MNIST_SAMPLE)\n```", "```py\nim3 = Image.open(path/'train'/'3'/'12.png')\nshow_image(im3);\n```", "```py\nim3_t = tensor(im3)\nim3_t[0:3,0:3] * top_edge\n```", "```py\ntensor([[-0., -0., -0.],\n        [0., 0., 0.],\n        [0., 0., 0.]])\n```", "```py\n(im3_t[0:3,0:3] * top_edge).sum()\n```", "```py\ntensor(0.)\n```", "```py\ndf = pd.DataFrame(im3_t[:10,:20])\ndf.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')\n```", "```py\n(im3_t[4:7,6:9] * top_edge).sum()\n```", "```py\ntensor(762.)\n```", "```py\n(im3_t[7:10,17:20] * top_edge).sum()\n```", "```py\ntensor(-29.)\n```", "```py\ndef apply_kernel(row, col, kernel):\n    return (im3_t[row-1:row+2,col-1:col+2] * kernel).sum()\n```", "```py\napply_kernel(5,7,top_edge)\n```", "```py\ntensor(762.)\n```", "```py\n[[(i,j) for j in range(1,5)] for i in range(1,5)]\n```", "```py\n[[(1, 1), (1, 2), (1, 3), (1, 4)],\n [(2, 1), (2, 2), (2, 3), (2, 4)],\n [(3, 1), (3, 2), (3, 3), (3, 4)],\n [(4, 1), (4, 2), (4, 3), (4, 4)]]\n```", "```py\nrng = range(1,27)\ntop_edge3 = tensor([[apply_kernel(i,j,top_edge) for j in rng] for i in rng])\n\nshow_image(top_edge3);\n```", "```py\nleft_edge = tensor([[-1,1,0],\n                    [-1,1,0],\n                    [-1,1,0]]).float()\n\nleft_edge3 = tensor([[apply_kernel(i,j,left_edge) for j in rng] for i in rng])\n\nshow_image(left_edge3);\n```", "```py\ndiag1_edge = tensor([[ 0,-1, 1],\n                     [-1, 1, 0],\n                     [ 1, 0, 0]]).float()\ndiag2_edge = tensor([[ 1,-1, 0],\n                     [ 0, 1,-1],\n                     [ 0, 0, 1]]).float()\n\nedge_kernels = torch.stack([left_edge, top_edge, diag1_edge, diag2_edge])\nedge_kernels.shape\n```", "```py\ntorch.Size([4, 3, 3])\n```", "```py\nmnist = DataBlock((ImageBlock(cls=PILImageBW), CategoryBlock),\n                  get_items=get_image_files,\n                  splitter=GrandparentSplitter(),\n                  get_y=parent_label)\n\ndls = mnist.dataloaders(path)\nxb,yb = first(dls.valid)\nxb.shape\n```", "```py\ntorch.Size([64, 1, 28, 28])\n```", "```py\nxb,yb = to_cpu(xb),to_cpu(yb)\n```", "```py\n[*channels*, *rows*, *columns*]\n```", "```py\n[*channels_in*, *features_out*, *rows*, *columns*]\n```", "```py\nedge_kernels.shape,edge_kernels.unsqueeze(1).shape\n```", "```py\n(torch.Size([4, 3, 3]), torch.Size([4, 1, 3, 3]))\n```", "```py\nedge_kernels = edge_kernels.unsqueeze(1)\n```", "```py\nbatch_features = F.conv2d(xb, edge_kernels)\nbatch_features.shape\n```", "```py\ntorch.Size([64, 4, 26, 26])\n```", "```py\nshow_image(batch_features[0,0]);\n```", "```py\n(n + 2*pad - ks) // stride + 1\n```", "```py\nsimple_net = nn.Sequential(\n    nn.Linear(28*28,30),\n    nn.ReLU(),\n    nn.Linear(30,1)\n)\n```", "```py\nsimple_net\n```", "```py\nSequential(\n  (0): Linear(in_features=784, out_features=30, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=30, out_features=1, bias=True)\n)\n```", "```py\nbroken_cnn = sequential(\n    nn.Conv2d(1,30, kernel_size=3, padding=1),\n    nn.ReLU(),\n    nn.Conv2d(30,1, kernel_size=3, padding=1)\n)\n```", "```py\nbroken_cnn(xb).shape\n```", "```py\ntorch.Size([64, 1, 28, 28])\n```", "```py\ndef conv(ni, nf, ks=3, act=True):\n    res = nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)\n    if act: res = nn.Sequential(res, nn.ReLU())\n    return res\n```", "```py\nsimple_cnn = sequential(\n    conv(1 ,4),            #14x14\n    conv(4 ,8),            #7x7\n    conv(8 ,16),           #4x4\n    conv(16,32),           #2x2\n    conv(32,2, act=False), #1x1\n    Flatten(),\n)\n```", "```py\nsimple_cnn(xb).shape\n```", "```py\ntorch.Size([64, 2])\n```", "```py\nlearn = Learner(dls, simple_cnn, loss_func=F.cross_entropy, metrics=accuracy)\n```", "```py\nlearn.summary()\n```", "```py\nSequential (Input shape: ['64 x 1 x 28 x 28'])\n================================================================\nLayer (type)         Output Shape         Param #    Trainable\n================================================================\nConv2d               64 x 4 x 14 x 14     40         True\n________________________________________________________________\nReLU                 64 x 4 x 14 x 14     0          False\n________________________________________________________________\nConv2d               64 x 8 x 7 x 7       296        True\n________________________________________________________________\nReLU                 64 x 8 x 7 x 7       0          False\n________________________________________________________________\nConv2d               64 x 16 x 4 x 4      1,168      True\n________________________________________________________________\nReLU                 64 x 16 x 4 x 4      0          False\n________________________________________________________________\nConv2d               64 x 32 x 2 x 2      4,640      True\n________________________________________________________________\nReLU                 64 x 32 x 2 x 2      0          False\n________________________________________________________________\nConv2d               64 x 2 x 1 x 1       578        True\n________________________________________________________________\nFlatten              64 x 2               0          False\n________________________________________________________________\n\nTotal params: 6,722\nTotal trainable params: 6,722\nTotal non-trainable params: 0\n\nOptimizer used: <function Adam at 0x7fbc9c258cb0>\nLoss function: <function cross_entropy at 0x7fbca9ba0170>\n\nCallbacks:\n  - TrainEvalCallback\n  - Recorder\n  - ProgressCallback\n```", "```py\nlearn.fit_one_cycle(2, 0.01)\n```", "```py\nm = learn.model[0]\nm\n```", "```py\nSequential(\n  (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (1): ReLU()\n)\n```", "```py\nm[0].weight.shape\n```", "```py\ntorch.Size([4, 1, 3, 3])\n```", "```py\nm[0].bias.shape\n```", "```py\ntorch.Size([4])\n```", "```py\nim = image2tensor(Image.open('images/grizzly.jpg'))\nim.shape\n```", "```py\ntorch.Size([3, 1000, 846])\n```", "```py\nshow_image(im);\n```", "```py\n_,axs = subplots(1,3)\nfor bear,ax,color in zip(im,axs,('Reds','Greens','Blues')):\n    show_image(255-bear, ax=ax, cmap=color)\n```", "```py\npath = untar_data(URLs.MNIST)\n```", "```py\npath.ls()\n```", "```py\n(#2) [Path('testing'),Path('training')]\n```", "```py\ndef get_dls(bs=64):\n    return DataBlock(\n        blocks=(ImageBlock(cls=PILImageBW), CategoryBlock),\n        get_items=get_image_files,\n        splitter=GrandparentSplitter('training','testing'),\n        get_y=parent_label,\n        batch_tfms=Normalize()\n    ).dataloaders(path, bs=bs)\n\ndls = get_dls()\n```", "```py\ndls.show_batch(max_n=9, figsize=(4,4))\n```", "```py\ndef conv(ni, nf, ks=3, act=True):\n    res = nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)\n    if act: res = nn.Sequential(res, nn.ReLU())\n    return res\n```", "```py\ndef simple_cnn():\n    return sequential(\n        conv(1 ,8, ks=5),        #14x14\n        conv(8 ,16),             #7x7\n        conv(16,32),             #4x4\n        conv(32,64),             #2x2\n        conv(64,10, act=False),  #1x1\n        Flatten(),\n    )\n```", "```py\nfrom fastai.callback.hook import *\n```", "```py\ndef fit(epochs=1):\n    learn = Learner(dls, simple_cnn(), loss_func=F.cross_entropy,\n                    metrics=accuracy, cbs=ActivationStats(with_hist=True))\n    learn.fit(epochs, 0.06)\n    return learn\n```", "```py\nlearn = fit()\n```", "```py\nlearn.activation_stats.plot_layer_stats(0)\n```", "```py\nlearn.activation_stats.plot_layer_stats(-2)\n```", "```py\ndls = get_dls(512)\n```", "```py\nlearn = fit()\n```", "```py\nlearn.activation_stats.plot_layer_stats(-2)\n```", "```py\ndef fit(epochs=1, lr=0.06):\n    learn = Learner(dls, simple_cnn(), loss_func=F.cross_entropy,\n                    metrics=accuracy, cbs=ActivationStats(with_hist=True))\n    learn.fit_one_cycle(epochs, lr)\n    return learn\n```", "```py\nlearn = fit()\n```", "```py\nlearn.recorder.plot_sched()\n```", "```py\nlearn.activation_stats.plot_layer_stats(-2)\n```", "```py\nlearn.activation_stats.color_dim(-2)\n```", "```py\nlearn.activation_stats.color_dim(-2)\n```", "```py\ndef conv(ni, nf, ks=3, act=True):\n    layers = [nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)]\n    layers.append(nn.BatchNorm2d(nf))\n    if act: layers.append(nn.ReLU())\n    return nn.Sequential(*layers)\n```", "```py\nlearn = fit()\n```", "```py\nlearn.activation_stats.color_dim(-4)\n```", "```py\nlearn = fit(5, lr=0.1)\n```", "```py\nlearn = fit(5, lr=0.1)\n```"]