["```py\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimage = Image.open(\"images/doge.jpg\")\nplt.imshow(image)\nplt.axis(\"off\")\nplt.show()\n```", "```py\nimport pandas as pd\nfrom transformers import pipeline\n\nimage_classifier = pipeline(\"image-classification\")\npreds = image_classifier(image)\npreds_df = pd.DataFrame(preds)\npreds_df\n```", "```py\nbook_data = [\n    {\"chapter\": 0, \"name\": \"Introduction\", \"start_page\": 1, \"end_page\": 11},\n    {\"chapter\": 1, \"name\": \"Text classification\", \"start_page\": 12,\n     \"end_page\": 48},\n    {\"chapter\": 2, \"name\": \"Named Entity Recognition\", \"start_page\": 49,\n     \"end_page\": 73},\n    {\"chapter\": 3, \"name\": \"Question Answering\", \"start_page\": 74,\n     \"end_page\": 120},\n    {\"chapter\": 4, \"name\": \"Summarization\", \"start_page\": 121,\n     \"end_page\": 140},\n    {\"chapter\": 5, \"name\": \"Conclusion\", \"start_page\": 141,\n     \"end_page\": 144}\n]\n```", "```py\ntable = pd.DataFrame(book_data)\ntable['number_of_pages'] = table['end_page']-table['start_page']\ntable = table.astype(str)\ntable\n```", "```py\ntable_qa = pipeline(\"table-question-answering\")\n```", "```py\ntable_qa = pipeline(\"table-question-answering\")\nqueries = [\"What's the topic in chapter 4?\",\n           \"What is the total number of pages?\",\n           \"On which page does the chapter about question-answering start?\",\n           \"How many chapters have more than 20 pages?\"]\npreds = table_qa(table, queries)\n```", "```py\nfor query, pred in zip(queries, preds):\n    print(query)\n    if pred[\"aggregator\"] == \"NONE\":\n        print(\"Predicted answer: \" + pred[\"answer\"])\n    else:\n        print(\"Predicted answer: \" + pred[\"answer\"])\n    print('='*50)\n```", "```py\nWhat's the topic in chapter 4?\nPredicted answer: Summarization\n==================================================\nWhat is the total number of pages?\nPredicted answer: SUM > 10, 36, 24, 46, 19, 3\n==================================================\nOn which page does the chapter about question-answering start?\nPredicted answer: AVERAGE > 74\n==================================================\nHow many chapters have more than 20 pages?\nPredicted answer: COUNT > 1, 2, 3\n==================================================\n```", "```py\nasr = pipeline(\"automatic-speech-recognition\")\n```", "```py\nfrom datasets import load_dataset\n\nds = load_dataset(\"superb\", \"asr\", split=\"validation[:1]\")\nprint(ds[0])\n```", "```py\n{'chapter_id': 128104, 'speaker_id': 1272, 'file': '~/.cache/huggingf\nace/datasets/downloads/extracted/e4e70a454363bec1c1a8ce336139866a39442114d86a433\n6014acd4b1ed55e55/LibriSpeech/dev-clean/1272/128104/1272-128104-0000.flac',\n'id': '1272-128104-0000', 'text': 'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE\nCLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'}\n```", "```py\nimport soundfile as sf\n\ndef map_to_array(batch):\n    speech, _ = sf.read(batch[\"file\"])\n    batch[\"speech\"] = speech\n    return batch\n\nds = ds.map(map_to_array)\n```", "```py\nfrom IPython.display import Audio\n\ndisplay(Audio(ds[0]['speech'], rate=16000))\n```", "```py\npred = asr(ds[0][\"speech\"])\nprint(pred)\n```", "```py\n{'text': 'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO\nWELCOME HIS GOSPEL'}\n```", "```py\nfrom transformers import CLIPProcessor, CLIPModel\n\nclip_ckpt = \"openai/clip-vit-base-patch32\"\nmodel = CLIPModel.from_pretrained(clip_ckpt)\nprocessor = CLIPProcessor.from_pretrained(clip_ckpt)\n```", "```py\nimage = Image.open(\"images/optimusprime.jpg\")\nplt.imshow(image)\nplt.axis(\"off\")\nplt.show()\n```", "```py\nimport torch\n\ntexts = [\"a photo of a transformer\", \"a photo of a robot\", \"a photo of agi\"]\ninputs = processor(text=texts, images=image, return_tensors=\"pt\", padding=True)\nwith torch.no_grad():\n    outputs = model(**inputs)\nlogits_per_image = outputs.logits_per_image\nprobs = logits_per_image.softmax(dim=1)\nprobs\n```", "```py\ntensor([[0.9557, 0.0413, 0.0031]])\n```"]