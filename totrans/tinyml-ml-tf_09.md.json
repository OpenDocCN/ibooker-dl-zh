["```py\nnamespace tflite {\nnamespace ops {\nnamespace micro {\nTfLiteRegistration* Register_DEPTHWISE_CONV_2D();\nTfLiteRegistration* Register_CONV_2D();\nTfLiteRegistration* Register_AVERAGE_POOL_2D();\n}  // namespace micro\n}  // namespace ops\n}  // namespace tflite\n```", "```py\nconst int tensor_arena_size = 70 * 1024;\nuint8_t tensor_arena[tensor_arena_size];\n```", "```py\n// Set up logging.\ntflite::MicroErrorReporter micro_error_reporter;\ntflite::ErrorReporter* error_reporter = &micro_error_reporter;\n\n// Map the model into a usable data structure. This doesn't involve any\n// copying or parsing, it's a very lightweight operation.\nconst tflite::Model* model = ::tflite::GetModel(g_person_detect_model_data);\nif (model->version() != TFLITE_SCHEMA_VERSION) {\nerror_reporter->Report(\n    \"Model provided is schema version %d not equal \"\n    \"to supported version %d.\\n\",\n    model->version(), TFLITE_SCHEMA_VERSION);\n}\n\n// Pull in only the operation implementations we need.\ntflite::MicroMutableOpResolver micro_mutable_op_resolver;\nmicro_mutable_op_resolver.AddBuiltin(\n    tflite::BuiltinOperator_DEPTHWISE_CONV_2D,\n    tflite::ops::micro::Register_DEPTHWISE_CONV_2D());\nmicro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_CONV_2D,\n                                     tflite::ops::micro::Register_CONV_2D());\nmicro_mutable_op_resolver.AddBuiltin(\n    tflite::BuiltinOperator_AVERAGE_POOL_2D,\n    tflite::ops::micro::Register_AVERAGE_POOL_2D());\n\n// Build an interpreter to run the model with.\ntflite::MicroInterpreter interpreter(model, micro_mutable_op_resolver,\n                                     tensor_arena, tensor_arena_size,\n                                     error_reporter);\ninterpreter.AllocateTensors();\n```", "```py\n// Get information about the memory area to use for the model's input.\nTfLiteTensor* input = interpreter.input(0);\n\n// Make sure the input has the properties we expect.\nTF_LITE_MICRO_EXPECT_NE(nullptr, input);\nTF_LITE_MICRO_EXPECT_EQ(4, input->dims->size);\nTF_LITE_MICRO_EXPECT_EQ(1, input->dims->data[0]);\nTF_LITE_MICRO_EXPECT_EQ(kNumRows, input->dims->data[1]);\nTF_LITE_MICRO_EXPECT_EQ(kNumCols, input->dims->data[2]);\nTF_LITE_MICRO_EXPECT_EQ(kNumChannels, input->dims->data[3]);\nTF_LITE_MICRO_EXPECT_EQ(kTfLiteUInt8, input->type);\n```", "```py\nconstexpr int kNumCols = 96;\nconstexpr int kNumRows = 96;\nconstexpr int kNumChannels = 1;\n```", "```py\n// Copy an image with a person into the memory area used for the input.\nconst uint8_t* person_data = g_person_data;\nfor (int i = 0; i < input->bytes; ++i) {\n    input->data.uint8[i] = person_data[i];\n}\n```", "```py\n// Run the model on this input and make sure it succeeds.\nTfLiteStatus invoke_status = interpreter.Invoke();\nif (invoke_status != kTfLiteOk) {\n    error_reporter->Report(\"Invoke failed\\n\");\n}\nTF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, invoke_status);\n```", "```py\nTfLiteTensor* output = interpreter.output(0);\nTF_LITE_MICRO_EXPECT_EQ(4, output->dims->size);\nTF_LITE_MICRO_EXPECT_EQ(1, output->dims->data[0]);\nTF_LITE_MICRO_EXPECT_EQ(1, output->dims->data[1]);\nTF_LITE_MICRO_EXPECT_EQ(1, output->dims->data[2]);\nTF_LITE_MICRO_EXPECT_EQ(kCategoryCount, output->dims->data[3]);\nTF_LITE_MICRO_EXPECT_EQ(kTfLiteUInt8, output->type);\n```", "```py\nconstexpr int kCategoryCount = 3;\nconstexpr int kPersonIndex = 1;\nconstexpr int kNotAPersonIndex = 2;\nextern const char* kCategoryLabels[kCategoryCount];\n```", "```py\nconst char* kCategoryLabels[kCategoryCount] = {\n    \"unused\",\n    \"person\",\n    \"notperson\",\n};\n```", "```py\nuint8_t person_score = output->data.uint8[kPersonIndex];\nuint8_t no_person_score = output->data.uint8[kNotAPersonIndex];\nerror_reporter->Report(\n    \"person data.  person score: %d, no person score: %d\\n\", person_score,\n    no_person_score);\nTF_LITE_MICRO_EXPECT_GT(person_score, no_person_score);\n```", "```py\nconst uint8_t* no_person_data = g_no_person_data;\nfor (int i = 0; i < input->bytes; ++i) {\n    input->data.uint8[i] = no_person_data[i];\n}\n```", "```py\nperson_score = output->data.uint8[kPersonIndex];\nno_person_score = output->data.uint8[kNotAPersonIndex];\nerror_reporter->Report(\n    \"no person data.  person score: %d, no person score: %d\\n\", person_score,\n    no_person_score);\nTF_LITE_MICRO_EXPECT_GT(no_person_score, person_score);\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  test_person_detection_test\n```", "```py\nTfLiteStatus GetImage(tflite::ErrorReporter* error_reporter, int image_width,\n                      int image_height, int channels, uint8_t* image_data);\n```", "```py\nuint8_t image_data[kMaxImageSize];\n```", "```py\nTfLiteStatus get_status =\n    GetImage(error_reporter, kNumCols, kNumRows, kNumChannels, image_data);\nTF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, get_status);\nTF_LITE_MICRO_EXPECT_NE(image_data, nullptr);\n```", "```py\nuint32_t total = 0;\nfor (int i = 0; i < kMaxImageSize; ++i) {\n    total += image_data[i];\n}\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  test_image_provider_test\n```", "```py\nvoid RespondToDetection(tflite::ErrorReporter* error_reporter,\n                        uint8_t person_score, uint8_t no_person_score);\n```", "```py\nRespondToDetection(error_reporter, 100, 200);\nRespondToDetection(error_reporter, 200, 100);\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  test_detection_responder_test\n```", "```py\nnamespace tflite {\nnamespace ops {\nnamespace micro {\nTfLiteRegistration* Register_DEPTHWISE_CONV_2D();\nTfLiteRegistration* Register_CONV_2D();\nTfLiteRegistration* Register_AVERAGE_POOL_2D();\n}  // namespace micro\n}  // namespace ops\n}  // namespace tflite\n```", "```py\ntflite::ErrorReporter* g_error_reporter = nullptr;\nconst tflite::Model* g_model = nullptr;\ntflite::MicroInterpreter* g_interpreter = nullptr;\nTfLiteTensor* g_input = nullptr;\n```", "```py\nconstexpr int g_tensor_arena_size = 70 * 1024;\nstatic uint8_t tensor_arena[kTensorArenaSize];\n```", "```py\nvoid setup() {\n  // Set up logging.\n  static tflite::MicroErrorReporter micro_error_reporter;\n  g_error_reporter = &micro_error_reporter;\n\n  // Map the model into a usable data structure. This doesn't involve any\n  // copying or parsing, it's a very lightweight operation.\n  g_model = tflite::GetModel(g_person_detect_model_data);\n  if (g_model->version() != TFLITE_SCHEMA_VERSION) {\n    g_error_reporter->Report(\n        \"Model provided is schema version %d not equal \"\n        \"to supported version %d.\",\n        g_model->version(), TFLITE_SCHEMA_VERSION);\n    return;\n  }\n\n  // Pull in only the operation implementations we need.\n  static tflite::MicroMutableOpResolver micro_mutable_op_resolver;\n  micro_mutable_op_resolver.AddBuiltin(\n      tflite::BuiltinOperator_DEPTHWISE_CONV_2D,\n      tflite::ops::micro::Register_DEPTHWISE_CONV_2D());\n  micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_CONV_2D,\n                                       tflite::ops::micro::Register_CONV_2D());\n  micro_mutable_op_resolver.AddBuiltin(\n      tflite::BuiltinOperator_AVERAGE_POOL_2D,\n      tflite::ops::micro::Register_AVERAGE_POOL_2D());\n\n  // Build an interpreter to run the model with.\n  static tflite::MicroInterpreter static_interpreter(\n      model, micro_mutable_op_resolver, tensor_arena, kTensorArenaSize,\n      error_reporter);\n  interpreter = &static_interpreter;\n\n  // Allocate memory from the tensor_arena for the model's tensors.\n  TfLiteStatus allocate_status = interpreter->AllocateTensors();\n  if (allocate_status != kTfLiteOk) {\n    error_reporter->Report(\"AllocateTensors() failed\");\n    return;\n  }\n\n  // Get information about the memory area to use for the model's input.\n  input = interpreter->input(0);\n}\n```", "```py\nvoid loop() {\n  // Get image from provider.\n  if (kTfLiteOk != GetImage(g_error_reporter, kNumCols, kNumRows, kNumChannels,\n                            g_input->data.uint8)) {\n    g_error_reporter->Report(\"Image capture failed.\");\n  }\n```", "```py\n  // Run the model on this input and make sure it succeeds.\n  if (kTfLiteOk != g_interpreter->Invoke()) {\n    g_error_reporter->Report(\"Invoke failed.\");\n  }\n\n  TfLiteTensor* output = g_interpreter->output(0);\n\n  // Process the inference results.\n  uint8_t person_score = output->data.uint8[kPersonIndex];\n  uint8_t no_person_score = output->data.uint8[kNotAPersonIndex];\n  RespondToDetection(g_error_reporter, person_score, no_person_score);\n}\n```", "```py\nint main(int argc, char* argv[]) {\n  setup();\n  while (true) {\n    loop();\n  }\n}\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile person_detection\n```", "```py\ntensorflow/lite/micro/tools/make/gen/osx_x86_64/bin/ \\\nperson_detection\n```", "```py\nperson score:129 no person score 202\nperson score:129 no person score 202\nperson score:129 no person score 202\nperson score:129 no person score 202\nperson score:129 no person score 202\nperson score:129 no person score 202\n```", "```py\n  static bool g_is_camera_initialized = false;\n  if (!g_is_camera_initialized) {\n    TfLiteStatus init_status = InitCamera(error_reporter);\n    if (init_status != kTfLiteOk) {\n      error_reporter->Report(\"InitCamera failed\");\n      return init_status;\n    }\n    g_is_camera_initialized = true;\n  }\n```", "```py\nTfLiteStatus capture_status = PerformCapture(error_reporter);\n```", "```py\n  TfLiteStatus read_data_status = ReadData(error_reporter);\n```", "```py\n  TfLiteStatus decode_status = DecodeAndProcessImage(\n      error_reporter, image_width, image_height, image_data);\n```", "```py\nvoid RespondToDetection(tflite::ErrorReporter* error_reporter,\n                        uint8_t person_score, uint8_t no_person_score) {\n  static bool is_initialized = false;\n  if (!is_initialized) {\n    pinMode(led_green, OUTPUT);\n    pinMode(led_blue, OUTPUT);\n    is_initialized = true;\n  }\n```", "```py\n  // Note: The RGB LEDs on the Arduino Nano 33 BLE\n  // Sense are on when the pin is LOW, off when HIGH.\n\n  // Switch the person/not person LEDs off\n  digitalWrite(led_green, HIGH);\n  digitalWrite(led_red, HIGH);\n\n  // Flash the blue LED after every inference.\n  digitalWrite(led_blue, LOW);\n  delay(100);\n  digitalWrite(led_blue, HIGH);\n```", "```py\n  // Switch on the green LED when a person is detected,\n  // the red when no person is detected\n  if (person_score > no_person_score) {\n    digitalWrite(led_green, LOW);\n    digitalWrite(led_red, HIGH);\n  } else {\n    digitalWrite(led_green, HIGH);\n    digitalWrite(led_red, LOW);\n  }\n```", "```py\n  error_reporter->Report(\"Person score: %d No person score: %d\", person_score,\n                         no_person_score);\n}\n```", "```py\n//Step 1: select the hardware platform, only one at a time\n//#define OV2640_MINI_2MP\n//#define OV3640_MINI_3MP\n//#define OV5642_MINI_5MP\n//#define OV5642_MINI_5MP_BIT_ROTATION_FIXED\n#define OV2640_MINI_2MP_PLUS\n//#define OV5642_MINI_5MP_PLUS\n//#define OV5640_MINI_5MP_PLUS\n```", "```py\n// Comment out the next #defines if you are not using an SD Card to store\n// the JPEGs\n// Commenting out the line is NOT essential but will save some FLASH space if\n// SD Card access is not needed. Note: use of SdFat is currently untested!\n\n//#define LOAD_SD_LIBRARY // Default SD Card library\n//#define LOAD_SDFAT_LIBRARY // Use SdFat library instead, so SD Card SPI can\n                             // be bit bashed\n```", "```py\n14:17:50.714 -> Starting capture\n14:17:50.714 -> Image captured\n14:17:50.784 -> Reading 3080 bytes from ArduCAM\n14:17:50.887 -> Finished reading\n14:17:50.887 -> Decoding JPEG and converting to greyscale\n14:17:51.074 -> Image decoded and processed\n14:18:09.710 -> Person score: 246 No person score: 66\n```", "```py\n// Capture single frame.  Frame pointer passed in to reduce memory usage.  This\n// allows the input tensor to be used instead of requiring an extra copy.\nTfLiteStatus GetImage(tflite::ErrorReporter* error_reporter, int frame_width,\n                      int frame_height, int channels, uint8_t* frame) {\n  if (!g_is_camera_initialized) {\n    TfLiteStatus init_status = InitCamera(error_reporter);\n    if (init_status != kTfLiteOk) {\n      am_hal_gpio_output_set(AM_BSP_GPIO_LED_RED);\n      return init_status;\n    }\n```", "```py\n    // Drop a few frames until auto exposure is calibrated.\n    for (int i = 0; i < kFramesToInitialize; ++i) {\n      hm01b0_blocking_read_oneframe_scaled(frame, frame_width, frame_height,\n                                           channels);\n    }\n    g_is_camera_initialized = true;\n  }\n```", "```py\nhm01b0_blocking_read_oneframe_scaled(frame, frame_width, frame_height,\n                                     channels);\n```", "```py\nvoid RespondToDetection(tflite::ErrorReporter* error_reporter,\n                        uint8_t person_score, uint8_t no_person_score) {\n  static bool is_initialized = false;\n  if (!is_initialized) {\n    // Setup LED's as outputs.  Leave red LED alone since that's an error\n    // indicator for sparkfun_edge in image_provider.\n    am_hal_gpio_pinconfig(AM_BSP_GPIO_LED_BLUE, g_AM_HAL_GPIO_OUTPUT_12);\n    am_hal_gpio_pinconfig(AM_BSP_GPIO_LED_GREEN, g_AM_HAL_GPIO_OUTPUT_12);\n    am_hal_gpio_pinconfig(AM_BSP_GPIO_LED_YELLOW, g_AM_HAL_GPIO_OUTPUT_12);\n    is_initialized = true;\n  }\n```", "```py\n// Toggle the blue LED every time an inference is performed.\nstatic int count = 0;\nif (++count & 1) {\n    am_hal_gpio_output_set(AM_BSP_GPIO_LED_BLUE);\n} else {\n    am_hal_gpio_output_clear(AM_BSP_GPIO_LED_BLUE);\n}\n```", "```py\nam_hal_gpio_output_clear(AM_BSP_GPIO_LED_YELLOW);\nam_hal_gpio_output_clear(AM_BSP_GPIO_LED_GREEN);\nif (person_score > no_person_score) {\n    am_hal_gpio_output_set(AM_BSP_GPIO_LED_GREEN);\n} else {\n    am_hal_gpio_output_set(AM_BSP_GPIO_LED_YELLOW);\n}\n\nerror_reporter->Report(\"person score:%d no person score %d\", person_score,\n                        no_person_score);\n```", "```py\ngit clone https://github.com/tensorflow/tensorflow.git\ncd tensorflow\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  TARGET=sparkfun_edge person_detection_bin\n```", "```py\ntensorflow/lite/micro/tools/make/gen/\n  sparkfun_edge_cortex-m4/bin/person_detection.bin\n```", "```py\ntest -f tensorflow/lite/micro/tools/make/gen \\\n  /sparkfun_edge_cortex-m4/bin/person_detection.bin \\\n  &&  echo \"Binary was successfully created\" || echo \"Binary is missing\"\n```", "```py\ncp tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0 \\\n  /tools/apollo3_scripts/keys_info0.py \\\ntensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0 \\\n  /tools/apollo3_scripts/keys_info.py\n```", "```py\npython3 tensorflow/lite/micro/tools/make/downloads/ \\\n  AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_image_blob.py \\\n  --bin tensorflow/lite/micro/tools/make/gen/ \\\n  sparkfun_edge_cortex-m4/bin/person_detection.bin \\\n  --load-address 0xC000 \\\n  --magic-num 0xCB \\\n  -o main_nonsecure_ota \\\n  --version 0x0\n```", "```py\npython3 tensorflow/lite/micro/tools/make/downloads/ \\\n  AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_wireupdate_blob.py \\\n  --load-address 0x20000 \\\n  --bin main_nonsecure_ota.bin \\\n  -i 6 \\\n  -o main_nonsecure_wire \\\n  --options 0x1\n```", "```py\n# macOS:\nls /dev/cu*\n\n# Linux:\nls /dev/tty*\n```", "```py\n/dev/cu.Bluetooth-Incoming-Port\n/dev/cu.MALS\n/dev/cu.SOC\n```", "```py\n# macOS:\nls /dev/cu*\n\n# Linux:\nls /dev/tty*\n```", "```py\n/dev/cu.Bluetooth-Incoming-Port\n/dev/cu.MALS\n/dev/cu.SOC\n/dev/cu.wchusbserial-1450\n```", "```py\nexport DEVICENAME=<*your device name here*>\n\n```", "```py\nexport BAUD_RATE=921600\n```", "```py\npython3 tensorflow/lite/micro/tools/make/downloads/ \\\n  AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/uart_wired_update.py -b \\\n  ${BAUD_RATE} ${DEVICENAME} -r 1 -f main_nonsecure_wire.bin -i 6\n```", "```py\nConnecting with Corvette over serial port /dev/cu.usbserial-1440...\nSending Hello.\nReceived response for Hello\nReceived Status\nlength =  0x58\nversion =  0x3\nMax Storage =  0x4ffa0\nStatus =  0x2\nState =  0x7\nAMInfo =\n0x1\n0xff2da3ff\n0x55fff\n0x1\n0x49f40003\n0xffffffff\n[...lots more 0xffffffff...]\nSending OTA Descriptor =  0xfe000\nSending Update Command.\nnumber of updates needed =  1\nSending block of size  0x158b0  from  0x0  to  0x158b0\nSending Data Packet of length  8180\nSending Data Packet of length  8180\n[...lots more Sending Data Packet of length  8180...]\n```", "```py\n[...lots more Sending Data Packet of length  8180...]\nSending Data Packet of length  8180\nSending Data Packet of length  6440\nSending Reset Command.\nDone.\n```", "```py\nscreen ${DEVICENAME} 115200\n```", "```py\nApollo3 Burst Mode is Available\n\n                               Apollo3 operating in Burst Mode (96MHz)\n```", "```py\nPerson score: 130 No person score: 204\nPerson score: 220 No person score: 87\n```"]