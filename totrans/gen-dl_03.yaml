- en: Chapter 1\. Generative Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is a general introduction to the field of generative modeling.
  prefs: []
  type: TYPE_NORMAL
- en: We will start with a gentle theoretical introduction to generative modeling
    and see how it is the natural counterpart to the more widely studied discriminative
    modeling. We will then establish a framework that describes the desirable properties
    that a good generative model should have. We will also lay out the core probabilistic
    concepts that are important to know, in order to fully appreciate how different
    approaches tackle the challenge of generative modeling.
  prefs: []
  type: TYPE_NORMAL
- en: This will lead us naturally to the penultimate section, which lays out the six
    broad families of generative models that dominate the field today. The final section
    explains how to get started with the codebase that accompanies this book.
  prefs: []
  type: TYPE_NORMAL
- en: What Is Generative Modeling?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Generative modeling can be broadly defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Generative modeling is a branch of machine learning that involves training a
    model to produce new data that is similar to a given dataset.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: What does this mean in practice? Suppose we have a dataset containing photos
    of horses. We can *train* a generative model on this dataset to capture the rules
    that govern the complex relationships between pixels in images of horses. Then
    we can *sample* from this model to create novel, realistic images of horses that
    did not exist in the original dataset. This process is illustrated in [Figure¬†1-1](#generative_model).
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0101.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-1\. A generative model trained to generate realistic photos of horses
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In order to build a generative model, we require a dataset consisting of many
    examples of the entity we are trying to generate. This is known as the *training
    data*, and one such data point is called an *observation*.
  prefs: []
  type: TYPE_NORMAL
- en: Each observation consists of many *features*. For an image generation problem,
    the features are usually the individual pixel values; for a text generation problem,
    the features could be individual words or groups of letters. It is our goal to
    build a model that can generate new sets of features that look as if they have
    been created using the same rules as the original data. Conceptually, for image
    generation this is an incredibly difficult task, considering the vast number of
    ways that individual pixel values can be assigned and the relatively tiny number
    of such arrangements that constitute an image of the entity we are trying to generate.
  prefs: []
  type: TYPE_NORMAL
- en: A generative model must also be *probabilistic* rather than *deterministic*,
    because we want to be able to sample many different variations of the output,
    rather than get the same output every time. If our model is merely a fixed calculation,
    such as taking the average value of each pixel in the training dataset, it is
    not generative. A generative model must include a random component that influences
    the individual samples generated by the model.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, we can imagine that there is some unknown probabilistic distribution
    that explains why some images are likely to be found in the training dataset and
    other images are not. It is our job to build a model that mimics this distribution
    as closely as possible and then sample from it to generate new, distinct observations
    that look as if they could have been included in the original training set.
  prefs: []
  type: TYPE_NORMAL
- en: Generative Versus Discriminative Modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to truly understand what generative modeling aims to achieve and why
    this is important, it is useful to compare it to its counterpart, *discriminative
    modeling*. If you have studied machine learning, most problems you will have faced
    will have most likely been discriminative in nature. To understand the difference,
    let‚Äôs look at an example.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we have a dataset of paintings, some painted by Van Gogh and some by
    other artists. With enough data, we could train a discriminative model to predict
    if a given painting was painted by Van Gogh. Our model would learn that certain
    colors, shapes, and textures are more likely to indicate that a painting is by
    the Dutch master, and for paintings with these features, the model would upweight
    its prediction accordingly. [Figure¬†1-2](#discriminative_model) shows the discriminative
    modeling process‚Äînote how it differs from the generative modeling process shown
    in [Figure¬†1-1](#generative_model).
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0102.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-2\. A discriminative model trained to predict if a given image is painted
    by Van Gogh
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When performing discriminative modeling, each observation in the training data
    has a *label*. For a binary classification problem such as our artist discriminator,
    Van Gogh paintings would be labeled 1 and non‚ÄìVan Gogh paintings labeled 0\. Our
    model then learns how to discriminate between these two groups and outputs the
    probability that a new observation has label 1‚Äîi.e., that it was painted by Van
    Gogh.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, generative modeling doesn‚Äôt require the dataset to be labeled because
    it concerns itself with generating entirely new images, rather than trying to
    predict a label of a given image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs define these types of modeling formally, using mathematical notation:'
  prefs: []
  type: TYPE_NORMAL
- en: Conditional Generative Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Note that we can also build a generative model to model the conditional probability
    <math alttext="p left-parenthesis bold x vertical-bar y right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <mi>ùê±</mi> <mo>|</mo> <mi>y</mi> <mo>)</mo></mrow></math> ‚Äîthe probability
    of seeing an observation <math alttext="bold x"><mi>ùê±</mi></math> with a specific
    label <math alttext="y"><mi>y</mi></math> .
  prefs: []
  type: TYPE_NORMAL
- en: For example, if our dataset contains different types of fruit, we could tell
    our generative model to specifically generate an image of an apple.
  prefs: []
  type: TYPE_NORMAL
- en: An important point to note is that even if we were able to build a perfect discriminative
    model to identify Van Gogh paintings, it would still have no idea how to create
    a painting that looks like a Van Gogh. It can only output probabilities against
    existing images, as this is what it has been trained to do. We would instead need
    to train a generative model and sample from this model to generate images that
    have a high chance of belonging to the original training dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The Rise of Generative Modeling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Until recently, discriminative modeling has been the driving force behind most
    progress in machine learning. This is because for any discriminative problem,
    the corresponding generative modeling problem is typically much more difficult
    to tackle. For example, it is much easier to train a model to predict if a painting
    is by Van Gogh than it is to train a model to generate a Van Gogh‚Äìstyle painting
    from scratch. Similarly, it is much easier to train a model to predict if a page
    of text was written by Charles Dickens than it is to build a model to generate
    a set of paragraphs in the style of Dickens. Until recently, most generative challenges
    were simply out of reach and many doubted that they could ever be solved. Creativity
    was considered a purely human capability that couldn‚Äôt be rivaled by AI.
  prefs: []
  type: TYPE_NORMAL
- en: However, as machine learning technologies have matured, this assumption has
    gradually weakened. In the last 10 years many of the most interesting advancements
    in the field have come through novel applications of machine learning to generative
    modeling tasks. For example, [Figure¬†1-3](#face_generation) shows the striking
    progress that has already been made in facial image generation since 2014.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0103.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-3\. Face generation using generative modeling has improved significantly
    over the last decade (adapted from [Brundage et al., 2018](https://www.eff.org/files/2018/02/20/malicious_ai_report_final.pdf))^([1](ch01.xhtml#idm45387027355040))
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As well as being easier to tackle, discriminative modeling has historically
    been more readily applicable to practical problems across industry than generative
    modeling. For example, a doctor may benefit from a model that predicts if a given
    retinal image shows signs of glaucoma, but wouldn‚Äôt necessarily benefit from a
    model that can generate novel pictures of the back of an eye.
  prefs: []
  type: TYPE_NORMAL
- en: However, this is also starting to change, with the proliferation of companies
    offering generative services that target specific business problems. For example,
    it is now possible to access APIs that generate original blog posts given a particular
    subject matter, produce a variety of images of your product in any setting you
    desire, or write social media content and ad copy to match your brand and target
    message. There are also clear positive applications of generative AI for industries
    such as game design and cinematography, where models trained to output video and
    music are beginning to add value.
  prefs: []
  type: TYPE_NORMAL
- en: Generative Modeling and AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As well as the practical uses of generative modeling (many of which are yet
    to be discovered), there are three deeper reasons why generative modeling can
    be considered the key to unlocking a far more sophisticated form of artificial
    intelligence that goes beyond what discriminative modeling alone can achieve.
  prefs: []
  type: TYPE_NORMAL
- en: Firstly, purely from a theoretical point of view, we shouldn‚Äôt limit our machine
    training to simply categorizing data. For completeness, we should also be concerned
    with training models that capture a more complete understanding of the data distribution,
    beyond any particular label. This is undoubtedly a more difficult problem to solve,
    due to the high dimensionality of the space of feasible outputs and the relatively
    small number of creations that we would class as belonging to the dataset. However,
    as we shall see, many of the same techniques that have driven development in discriminative
    modeling, such as deep learning, can be utilized by generative models too.
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, as we shall see in [Chapter¬†12](ch12.xhtml#chapter_world_models),
    generative modeling is now being used to drive progress in other fields of AI,
    such as reinforcement learning (the study of teaching agents to optimize a goal
    in an environment through trial and error). Suppose we want to train a robot to
    walk across a given terrain. A traditional approach would be to run many experiments
    where the agent tries out different strategies in the terrain, or a computer simulation
    of the terrain. Over time the agent would learn which strategies are more successful
    than others and therefore gradually improve. A challenge with this approach is
    that it is fairly inflexible because it is trained to optimize the policy for
    one particular task. An alternative approach that has recently gained traction
    is to instead train the agent to learn a *world model* of the environment using
    a generative model, independent of any particular task. The agent can quickly
    adapt to new tasks by testing strategies in its own world model, rather than in
    the real environment, which is often computationally more efficient and does not
    require retraining from scratch for each new task.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, if we are to truly say that we have built a machine that has acquired
    a form of intelligence that is comparable to a human‚Äôs, generative modeling must
    surely be part of the solution. One of the finest examples of a generative model
    in the natural world is the person reading this book. Take a moment to consider
    what an incredible generative model you are. You can close your eyes and imagine
    what an elephant would look like from any possible angle. You can imagine a number
    of plausible different endings to your favorite TV show, and you can plan your
    week ahead by working through various futures in your mind‚Äôs eye and taking action
    accordingly. Current neuroscientific theory suggests that our perception of reality
    is not a highly complex discriminative model operating on our sensory input to
    produce predictions of what we are experiencing, but is instead a generative model
    that is trained from birth to produce simulations of our surroundings that accurately
    match the future. Some theories even suggest that the output from this generative
    model is what we directly perceive as reality. Clearly, a deep understanding of
    how we can build machines to acquire this ability will be central to our continued
    understanding of the workings of the brain and general artificial intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Our First Generative Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With this in mind, let‚Äôs begin our journey into the exciting world of generative
    modeling. To begin with, we‚Äôll look at a toy example of a generative model and
    introduce some of the ideas that will help us to work through the more complex
    architectures that we will encounter later in the book.
  prefs: []
  type: TYPE_NORMAL
- en: Hello World!
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let‚Äôs start by playing a generative modeling game in just two dimensions. I
    have chosen a rule that has been used to generate the set of points <math alttext="bold
    upper X"><mi>ùêó</mi></math> in [Figure¬†1-4](#world_map_points). Let‚Äôs call this
    rule <math alttext="p Subscript d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    . Your challenge is to choose a different point <math alttext="bold x equals left-parenthesis
    x 1 comma x 2 right-parenthesis"><mrow><mi>ùê±</mi> <mo>=</mo> <mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>
    in the space that looks like it has been generated by the same rule.
  prefs: []
  type: TYPE_NORMAL
- en: '![A set of two points in 2-dimensions](Images/gdl2_0104.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-4\. A set of points in two dimensions, generated by an unknown rule
    <math alttext="p Subscript d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Where did you choose? You probably used your knowledge of the existing data
    points to construct a mental model, <math alttext="p Subscript m o d e l"><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    , of whereabouts in the space the point is more likely to be found. In this respect,
    <math alttext="p Subscript m o d e l"><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    is an *estimate* of <math alttext="p Subscript d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    . Perhaps you decided that <math alttext="p Subscript m o d e l"><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    should look like [Figure¬†1-5](#world_map_model)‚Äîa rectangular box where points
    may be found, and an area outside of the box where there is no chance of finding
    any points.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0105.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-5\. The orange box, <math alttext="p Subscript m o d e l"><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    , is an estimate of the true data-generating distribution, <math alttext="p Subscript
    d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To generate a new observation, you can simply choose a point at random within
    the box, or more formally, *sample* from the distribution <math alttext="p Subscript
    m o d e l"><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    . Congratulations, you have just built your first generative model! You have used
    the training data (the black points) to construct a model (the orange region)
    that you can easily sample from to generate other points that appear to belong
    to the training set.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs now formalize this thinking into a framework that can help us understand
    what generative modeling is trying to achieve.
  prefs: []
  type: TYPE_NORMAL
- en: The Generative Modeling Framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can capture our motivations and goals for building a generative model in
    the following framework.
  prefs: []
  type: TYPE_NORMAL
- en: Let‚Äôs now reveal the true data-generating distribution, <math alttext="p Subscript
    d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    , and see how the framework applies to this example. As we can see from [Figure¬†1-6](#world_map_model_data),
    the data-generating rule is simply a uniform distribution over the land mass of
    the world, with no chance of finding a point in the sea.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0106.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-6\. The orange box, <math alttext="p Subscript m o d e l"><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    , is an estimate of the true data-generating distribution, <math alttext="p Subscript
    d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    (the gray area)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Clearly, our model, <math alttext="p Subscript m o d e l"><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    , is an oversimplification of <math alttext="p Subscript d a t a"><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math> . We can inspect
    points A, B, and C to understand the successes and failures of our model in terms
    of how accurately it mimics <math alttext="p Subscript d a t a"><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math> :'
  prefs: []
  type: TYPE_NORMAL
- en: Point A is an observation that is generated by our model but does not appear
    to have been generated by <math alttext="p Subscript d a t a"><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math> as it‚Äôs in
    the middle of the sea.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Point B could never have been generated by <math alttext="p Subscript m o d
    e l"><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    as it sits outside the orange box. Therefore, our model has some gaps in its ability
    to produce observations across the entire range of potential possibilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Point C is an observation that could be generated by <math alttext="p Subscript
    m o d e l"><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></math>
    and also by <math alttext="p Subscript d a t a"><msub><mi>p</mi> <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></math>
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despite its shortcomings, the model is easy to sample from, because it is simply
    a uniform distribution over the orange box. We can easily choose a point at random
    from inside this box, in order to sample from it.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we can certainly say that our model is a simple representation of the
    underlying complex distribution that captures some of the underlying high-level
    features. The true distribution is separated into areas with lots of land mass
    (continents) and those with no land mass (the sea). This is a high-level feature
    that is also true of our model, except we have one large continent, rather than
    many.
  prefs: []
  type: TYPE_NORMAL
- en: This example has demonstrated the fundamental concepts behind generative modeling.
    The problems we will be tackling in this book will be far more complex and high-dimensional,
    but the underlying framework through which we approach the problem will be the
    same.
  prefs: []
  type: TYPE_NORMAL
- en: Representation Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is worth delving a little deeper into what we mean by learning a *representation*
    of the high-dimensional data, as it is a topic that will recur throughout this
    book.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose you wanted to describe your appearance to someone who was looking for
    you in a crowd of people and didn‚Äôt know what you looked like. You wouldn‚Äôt start
    by stating the color of pixel 1 of a photo of you, then pixel 2, then pixel 3,
    etc. Instead, you would make the reasonable assumption that the other person has
    a general idea of what an average human looks like, then amend this baseline with
    features that describe groups of pixels, such as *I have very blond hair* or *I
    wear glasses*. With no more than 10 or so of these statements, the person would
    be able to map the description back into pixels to generate an image of you in
    their head. The image wouldn‚Äôt be perfect, but it would be a close enough likeness
    to your actual appearance for them to find you among possibly hundreds of other
    people, even if they‚Äôve never seen you before.
  prefs: []
  type: TYPE_NORMAL
- en: This is the core idea behind *representation learning*. Instead of trying to
    model the high-dimensional sample space directly, we describe each observation
    in the training set using some lower-dimensional *latent space* and then learn
    a mapping function that can take a point in the latent space and map it to a point
    in the original domain. In other words, each point in the latent space is a *representation*
    of some high-dimensional observation.
  prefs: []
  type: TYPE_NORMAL
- en: What does this mean in practice? Let‚Äôs suppose we have a training set consisting
    of grayscale images of biscuit tins ([Figure¬†1-7](#biscuit_tins)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0107.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-7\. The biscuit tin dataset
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To us, it is obvious that there are two features that can uniquely represent
    each of these tins: the height and width of the tin. That is, we can convert each
    image of a tin to a point in a latent space of just two dimensions, even though
    the training set of images is provided in high-dimensional pixel space. Notably,
    this means that we can also produce images of tins that do not exist in the training
    set, by applying a suitable mapping function <math alttext="f"><mi>f</mi></math>
    to a new point in the latent space, as shown in [Figure¬†1-8](#biscuit_tin_generation).'
  prefs: []
  type: TYPE_NORMAL
- en: Realizing that the original dataset can be described by the simpler latent space
    is not so easy for a machine‚Äîit would first need to establish that height and
    width are the two latent space dimensions that best describe this dataset, then
    learn the mapping function <math alttext="f"><mi>f</mi></math> that can take a
    point in this space and map it to a grayscale biscuit tin image. Machine learning
    (and specifically, deep learning) gives us the ability to train machines that
    can find these complex relationships without human guidance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0108.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-8\. The 2D latent space of biscuit tins and the function <math alttext="f"><mi>f</mi></math>
    that maps a point in the latent space back to the original image domain
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: One of the benefits of training models that utilize a latent space is that we
    can perform operations that affect high-level properties of the image by manipulating
    its representation vector within the more manageable latent space. For example,
    it is not obvious how to adjust the shading of every single pixel to make an image
    of a biscuit tin *taller*. However, in the latent space, it‚Äôs simply a case of
    increasing the *height* latent dimension, then applying the mapping function to
    return to the image domain. We shall see an explicit example of this in the next
    chapter, applied not to biscuit tins but to faces.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of encoding the training dataset into a latent space so that we
    can sample from it and decode the point back to the original domain is common
    to many generative modeling techniques, as we shall see in later chapters of this
    book. Mathematically speaking, *encoder-decoder* techniques try to transform the
    highly nonlinear *manifold* on which the data lies (e.g., in pixel space) into
    a simpler latent space that can be sampled from, so that it is likely that any
    point in the latent space is the representation of a well-formed image, as shown
    in [Figure¬†1-9](#manifold).
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0109.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-9\. The *dog* manifold in high-dimensional pixel space is mapped to
    a simpler latent space that can be sampled from
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Core Probability Theory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have already seen that generative modeling is closely connected to statistical
    modeling of probability distributions. Therefore, it now makes sense to introduce
    some core probabilistic and statistical concepts that will be used throughout
    this book to explain the theoretical background of each model.
  prefs: []
  type: TYPE_NORMAL
- en: If you have never studied probability or statistics, don‚Äôt worry. To build many
    of the deep learning models that we shall see later in this book, it is not essential
    to have a deep understanding of statistical theory. However, to gain a full appreciation
    of the task that we are trying to tackle, it‚Äôs worth trying to build up a solid
    understanding of basic probabilistic theory. This way, you will have the foundations
    in place to understand the different families of generative models that will be
    introduced later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first step, we shall define five key terms, linking each one back to our
    earlier example of a generative model that models the world map in two dimensions:'
  prefs: []
  type: TYPE_NORMAL
- en: Sample space
  prefs: []
  type: TYPE_NORMAL
- en: The *sample space* is the complete set of all values an observation <math alttext="bold
    x"><mi>ùê±</mi></math> can take.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In our previous example, the sample space consists of all points of latitude
    and longitude <math alttext="bold x equals left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><mi>ùê±</mi>
    <mo>=</mo> <mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow></math> on the world map. For example, <math
    alttext="bold x"><mi>ùê±</mi></math> = (40.7306, ‚Äì73.9352) is a point in the sample
    space (New York City) that belongs to the true data-generating distribution. <math
    alttext="bold x"><mi>ùê±</mi></math> = (11.3493, 142.1996) is a point in the sample
    space that does not belong to the true data-generating distribution (it‚Äôs in the
    sea).
  prefs: []
  type: TYPE_NORMAL
- en: Probability density function
  prefs: []
  type: TYPE_NORMAL
- en: A *probability density function* (or simply *density function*) is a function
    <math alttext="p left-parenthesis bold x right-parenthesis"><mrow><mi>p</mi> <mo>(</mo>
    <mi>ùê±</mi> <mo>)</mo></mrow></math> that maps a point <math alttext="bold x"><mi>ùê±</mi></math>
    in the sample space to a number between 0 and 1\. The integral of the density
    function over all points in the sample space must equal 1, so that it is a well-defined
    probability distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the world map example, the density function of our generative model is 0
    outside of the orange box and constant inside of the box, so that the integral
    of the density function over the entire sample space equals 1.
  prefs: []
  type: TYPE_NORMAL
- en: While there is only one true density function <math alttext="p Subscript d a
    t a Baseline left-parenthesis bold x right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math> that is assumed to have generated the
    observable dataset, there are infinitely many density functions <math alttext="p
    Subscript m o d e l Baseline left-parenthesis bold x right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math> that we can use to estimate <math alttext="p
    Subscript d a t a Baseline left-parenthesis bold x right-parenthesis"><mrow><msub><mi>p</mi>
    <mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: Parametric modeling
  prefs: []
  type: TYPE_NORMAL
- en: '*Parametric modeling* is a technique that we can use to structure our approach
    to finding a suitable <math alttext="p Subscript m o d e l Baseline left-parenthesis
    bold x right-parenthesis"><mrow><msub><mi>p</mi> <mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub>
    <mrow><mo>(</mo> <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math> . A *parametric model*
    is a family of density functions <math alttext="p Subscript theta Baseline left-parenthesis
    bold x right-parenthesis"><mrow><msub><mi>p</mi> <mi>Œ∏</mi></msub> <mrow><mo>(</mo>
    <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math> that can be described using a finite
    number of parameters, <math alttext="theta"><mi>Œ∏</mi></math> .'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If we assume a uniform distribution as our model family, then the set all possible
    boxes we could draw on [Figure¬†1-5](#world_map_model) is an example of a parametric
    model. In this case, there are four parameters: the coordinates of the bottom-left
    <math alttext="left-parenthesis theta 1 comma theta 2 right-parenthesis"><mrow><mo>(</mo>
    <msub><mi>Œ∏</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>Œ∏</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></math> and top-right <math alttext="left-parenthesis theta 3
    comma theta 4 right-parenthesis"><mrow><mo>(</mo> <msub><mi>Œ∏</mi> <mn>3</mn></msub>
    <mo>,</mo> <msub><mi>Œ∏</mi> <mn>4</mn></msub> <mo>)</mo></mrow></math> corners
    of the box.'
  prefs: []
  type: TYPE_NORMAL
- en: Thus, each density function <math alttext="p Subscript theta Baseline left-parenthesis
    bold x right-parenthesis"><mrow><msub><mi>p</mi> <mi>Œ∏</mi></msub> <mrow><mo>(</mo>
    <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math> in this parametric model (i.e., each
    box) can be uniquely represented by four numbers, <math alttext="theta equals
    left-parenthesis theta 1 comma theta 2 comma theta 3 comma theta 4 right-parenthesis"><mrow><mi>Œ∏</mi>
    <mo>=</mo> <mo>(</mo> <msub><mi>Œ∏</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>Œ∏</mi>
    <mn>2</mn></msub> <mo>,</mo> <msub><mi>Œ∏</mi> <mn>3</mn></msub> <mo>,</mo> <msub><mi>Œ∏</mi>
    <mn>4</mn></msub> <mo>)</mo></mrow></math> .
  prefs: []
  type: TYPE_NORMAL
- en: Likelihood
  prefs: []
  type: TYPE_NORMAL
- en: 'The *likelihood* <math alttext="script upper L left-parenthesis theta vertical-bar
    bold x right-parenthesis"><mrow><mi>‚Ñí</mi> <mo>(</mo> <mi>Œ∏</mi> <mo>|</mo> <mi>ùê±</mi>
    <mo>)</mo></mrow></math> of a parameter set <math alttext="theta"><mi>Œ∏</mi></math>
    is a function that measures the plausibility of <math alttext="theta"><mi>Œ∏</mi></math>
    , given some observed point <math alttext="bold x"><mi>ùê±</mi></math> . It is defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="script upper L left-parenthesis theta vertical-bar bold x right-parenthesis
    equals p Subscript theta Baseline left-parenthesis bold x right-parenthesis" display="block"><mrow><mi>‚Ñí</mi>
    <mrow><mo>(</mo> <mi>Œ∏</mi> <mo>|</mo> <mi>ùê±</mi> <mo>)</mo></mrow> <mo>=</mo>
    <msub><mi>p</mi> <mi>Œ∏</mi></msub> <mrow><mo>(</mo> <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'That is, the likelihood of <math alttext="theta"><mi>Œ∏</mi></math> given some
    observed point <math alttext="bold x"><mi>ùê±</mi></math> is defined to be the value
    of the density function parameterized by <math alttext="theta"><mi>Œ∏</mi></math>
    , at the point <math alttext="bold x"><mi>ùê±</mi></math> . If we have a whole dataset
    <math alttext="bold upper X"><mi>ùêó</mi></math> of independent observations, then
    we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="script upper L left-parenthesis theta vertical-bar bold upper
    X right-parenthesis equals product Underscript bold x element-of bold upper X
    Endscripts p Subscript theta Baseline left-parenthesis bold x right-parenthesis"
    display="block"><mrow><mi>‚Ñí</mi> <mrow><mo>(</mo> <mi>Œ∏</mi> <mo>|</mo> <mi>ùêó</mi>
    <mo>)</mo></mrow> <mo>=</mo> <munder><mo>‚àè</mo> <mrow><mi>ùê±</mi><mo>‚àà</mo><mi>ùêó</mi></mrow></munder>
    <msub><mi>p</mi> <mi>Œ∏</mi></msub> <mrow><mo>(</mo> <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the world map example, an orange box that only covered the left half of the
    map would have a likelihood of 0‚Äîit couldn‚Äôt possibly have generated the dataset,
    as we have observed points in the right half of the map. The orange box in [Figure¬†1-5](#world_map_model)
    has a positive likelihood, as the density function is positive for all data points
    under this model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the product of a large number of terms between 0 and 1 can be quite computationally
    difficult to work with, we often use the *log-likelihood* ‚Ñì instead:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="script l left-parenthesis theta vertical-bar bold upper X right-parenthesis
    equals sigma-summation Underscript bold x element-of bold upper X Endscripts log
    p Subscript theta Baseline left-parenthesis bold x right-parenthesis" display="block"><mrow><mi>‚Ñì</mi>
    <mrow><mo>(</mo> <mi>Œ∏</mi> <mo>|</mo> <mi>ùêó</mi> <mo>)</mo></mrow> <mo>=</mo>
    <munder><mo>‚àë</mo> <mrow><mi>ùê±</mi><mo>‚àà</mo><mi>ùêó</mi></mrow></munder> <mo form="prefix">log</mo>
    <msub><mi>p</mi> <mi>Œ∏</mi></msub> <mrow><mo>(</mo> <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: There are statistical reasons why the likelihood is defined in this way, but
    we can also see that this definition intuitively makes sense. The likelihood of
    a set of parameters <math alttext="theta"><mi>Œ∏</mi></math> is defined to be the
    probability of seeing the data if the true data-generating distribution was the
    model parameterized by <math alttext="theta"><mi>Œ∏</mi></math> .
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note that the likelihood is a function of the *parameters*, not the data. It
    should *not* be interpreted as the probability that a given parameter set is correct‚Äîin
    other words, it is not a probability distribution over the parameter space (i.e.,
    it doesn‚Äôt sum/integrate to 1, with respect to the parameters).
  prefs: []
  type: TYPE_NORMAL
- en: It makes intuitive sense that the focus of parametric modeling should be to
    find the optimal value <math alttext="ModifyingAbove theta With caret"><mover
    accent="true"><mi>Œ∏</mi> <mo>^</mo></mover></math> of the parameter set that maximizes
    the likelihood of observing the dataset <math alttext="bold upper X"><mi>ùêó</mi></math>
    .
  prefs: []
  type: TYPE_NORMAL
- en: Maximum likelihood estimation
  prefs: []
  type: TYPE_NORMAL
- en: '*Maximum likelihood estimation* is the technique that allows us to estimate
    <math alttext="ModifyingAbove theta With caret"><mover accent="true"><mi>Œ∏</mi>
    <mo>^</mo></mover></math> ‚Äîthe set of parameters <math alttext="theta"><mi>Œ∏</mi></math>
    of a density function <math alttext="p Subscript theta Baseline left-parenthesis
    bold x right-parenthesis"><mrow><msub><mi>p</mi> <mi>Œ∏</mi></msub> <mrow><mo>(</mo>
    <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math> that is most likely to explain some
    observed data <math alttext="bold upper X"><mi>ùêó</mi></math> . More formally:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="ModifyingAbove theta With caret equals arg max Underscript bold
    x Endscripts script l left-parenthesis theta vertical-bar bold upper X right-parenthesis"
    display="block"><mrow><mover accent="true"><mi>Œ∏</mi> <mo>^</mo></mover> <mo>=</mo>
    <munder><mrow><mo form="prefix">arg</mo><mo movablelimits="true" form="prefix">max</mo></mrow>
    <mi>ùê±</mi></munder> <mi>‚Ñì</mi> <mrow><mo>(</mo> <mi>Œ∏</mi> <mo>|</mo> <mi>ùêó</mi>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="ModifyingAbove theta With caret"><mover accent="true"><mi>Œ∏</mi>
    <mo>^</mo></mover></math> is also called the *maximum likelihood estimate* (MLE).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the world map example, the MLE is the smallest rectangle that still contains
    all of the points in the training set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Neural networks typically *minimize* a loss function, so we can equivalently
    talk about finding the set of parameters that *minimize the negative log-likelihood*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="ModifyingAbove theta With caret equals arg min Underscript theta
    Endscripts left-parenthesis minus script l left-parenthesis theta vertical-bar
    bold upper X right-parenthesis right-parenthesis equals arg min Underscript theta
    Endscripts left-parenthesis minus log p Subscript theta Baseline left-parenthesis
    bold upper X right-parenthesis right-parenthesis" display="block"><mrow><mover
    accent="true"><mi>Œ∏</mi> <mo>^</mo></mover> <mo>=</mo> <munder><mrow><mo form="prefix">arg</mo><mo
    movablelimits="true" form="prefix">min</mo></mrow> <mi>Œ∏</mi></munder> <mfenced
    separators="" open="(" close=")"><mo>-</mo> <mi>‚Ñì</mi> <mo>(</mo> <mi>Œ∏</mi> <mo>|</mo>
    <mi>ùêó</mi> <mo>)</mo></mfenced> <mo>=</mo> <munder><mrow><mo form="prefix">arg</mo><mo
    movablelimits="true" form="prefix">min</mo></mrow> <mi>Œ∏</mi></munder> <mfenced
    separators="" open="(" close=")"><mo>-</mo> <mo form="prefix">log</mo> <msub><mi>p</mi>
    <mi>Œ∏</mi></msub> <mrow><mo>(</mo> <mi>ùêó</mi> <mo>)</mo></mrow></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Generative modeling can be thought of as a form of maximum likelihood estimation,
    where the parameters <math alttext="theta"><mi>Œ∏</mi></math> are the weights of
    the neural networks contained in the model. We are trying to find the values of
    these parameters that maximize the likelihood of observing the given data (or
    equivalently, minimize the negative log-likelihood).
  prefs: []
  type: TYPE_NORMAL
- en: However, for high-dimensional problems, it is generally not possible to directly
    calculate <math alttext="p Subscript theta Baseline left-parenthesis bold x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>Œ∏</mi></msub> <mrow><mo>(</mo> <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math>
    ‚Äîit is *intractable*. As we shall see in the next section, different families
    of generative models take different approaches to tackling this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Generative Model Taxonomy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While all types of generative models ultimately aim to solve the same task,
    they all take slightly different approaches to modeling the density function <math
    alttext="p Subscript theta Baseline left-parenthesis bold x right-parenthesis"><mrow><msub><mi>p</mi>
    <mi>Œ∏</mi></msub> <mrow><mo>(</mo> <mi>ùê±</mi> <mo>)</mo></mrow></mrow></math>
    . Broadly speaking, there are three possible approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Explicitly model the density function, but constrain the model in some way,
    so that the density function is tractable (i.e., it can be calculated).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explicitly model a tractable approximation of the density function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implicitly model the density function, through a stochastic process that directly
    generates data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These are shown in [Figure¬†1-10](#gm_taxonomy) as a taxonomy, alongside the
    six families of generative models that we will explore in [Part¬†II](part02.xhtml#part_methods)
    of this book. Note that these families are not mutually exclusive‚Äîthere are many
    examples of models that are hybrids between two different kinds of approaches.
    You should think of the families as different general approaches to generative
    modeling, rather than explicit model architectures.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/gdl2_0110.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-10\. A taxonomy of generative modeling approaches
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The first split that we can make is between models where the probability density
    function <math alttext="p left-parenthesis bold x right-parenthesis"><mrow><mi>p</mi>
    <mo>(</mo> <mi>ùê±</mi> <mo>)</mo></mrow></math> is modeled *explicitly* and those
    where it is modeled *implicitly*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Implicit density models* do not aim to estimate the probability density at
    all, but instead focus solely on producing a stochastic process that directly
    generates data. The best-known example of an implicit generative model is a *generative
    adversarial network*. We can further split *explicit density models* into those
    that directly optimize the density function (tractable models) and those that
    only optimize an approximation of it.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Tractable models* place constraints on the model architecture, so that the
    density function has a form that makes it easy to calculate. For example, *autoregressive
    models* impose an ordering on the input features, so that the output can be generated
    sequentially‚Äîe.g., word by word, or pixel by pixel. *Normalizing flow models*
    apply a series of tractable, invertible functions to a simple distribution, in
    order to generate more complex distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Approximate density models* include *variational autoencoders*, which introduce
    a latent variable and optimize an approximation of the joint density function.
    *Energy-based models* also utilize approximate methods, but do so via Markov chain
    sampling, rather than variational methods. *Diffusion models* approximate the
    density function by training a model to gradually denoise a given image that has
    been previously corrupted.'
  prefs: []
  type: TYPE_NORMAL
- en: A common thread that runs through all of the generative model family types is
    *deep learning*. Almost all sophisticated generative models have a deep neural
    network at their core, because they can be trained from scratch to learn the complex
    relationships that govern the structure of the data, rather than having to be
    hardcoded with information a priori. We‚Äôll explore deep learning in [Chapter¬†2](ch02.xhtml#chapter_deep_learning),
    with practical examples of how to get started building your own deep neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: The Generative Deep Learning Codebase
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final section of this chapter will get you set up to start building generative
    deep learning models by introducing the codebase that accompanies this book.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Many of the examples in this book are adapted from the excellent open source
    implementations that are available through [the Keras website](https://oreil.ly/1UTwa).
    I highly recommend you check out this resource, as new models and examples are
    constantly being added.
  prefs: []
  type: TYPE_NORMAL
- en: Cloning the Repository
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To get started, you‚Äôll first need to clone the Git repository. *Git* is an open
    source version control system and will allow you to copy the code locally so that
    you can run the notebooks on your own machine, or in a cloud-based environment.
    You may already have this installed, but if not, follow the [instructions relevant
    to your operating system](https://oreil.ly/tFOdN).
  prefs: []
  type: TYPE_NORMAL
- en: 'To clone the repository for this book, navigate to the folder where you would
    like to store the files and type the following into your terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`You should now be able to see the files in a folder on your machine.`  `##
    Using Docker'
  prefs: []
  type: TYPE_NORMAL
- en: The codebase for this book is intended to be used with *Docker*, a free containerization
    technology that makes getting started with a new codebase extremely easy, regardless
    of your architecture or operating system. If you have never used Docker, don‚Äôt
    worry‚Äîthere is a description of how to get started in the *README* file in the
    book repository.
  prefs: []
  type: TYPE_NORMAL
- en: Running on a GPU
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you don‚Äôt have access to your own GPU, that‚Äôs also no problem! All of the
    examples in this book will train on a CPU, though this will take longer than if
    you use a GPU-enabled machine. There is also a section in the *README* about setting
    up a Google Cloud environment that gives you access to a GPU on a pay-as-you-go
    basis.`  `# Summary
  prefs: []
  type: TYPE_NORMAL
- en: This chapter introduced the field of generative modeling, an important branch
    of machine learning that complements the more widely studied discriminative modeling.
    We discussed how generative modeling is currently one of the most active and exciting
    areas of AI research, with many recent advances in both theory and applications.
  prefs: []
  type: TYPE_NORMAL
- en: We started with a simple toy example and saw how generative modeling ultimately
    focuses on modeling the underlying distribution of the data. This presents many
    complex and interesting challenges, which we summarized into a framework for understanding
    the desirable properties of any generative model.
  prefs: []
  type: TYPE_NORMAL
- en: We then walked through the key probabilistic concepts that will help to fully
    understand the theoretical foundations of each approach to generative modeling
    and laid out the six different families of generative models that we will explore
    in [Part¬†II](part02.xhtml#part_methods) of this book. We also saw how to get started
    with the *Generative Deep Learning* codebase, by cloning the repository.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter¬†2](ch02.xhtml#chapter_deep_learning), we will begin our exploration
    of deep learning and see how to use Keras to build models that can perform discriminative
    modeling tasks. This will give us the necessary foundation to tackle generative
    deep learning problems in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: '^([1](ch01.xhtml#idm45387027355040-marker)) Miles Brundage et al., ‚ÄúThe Malicious
    Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation,‚Äù February
    20, 2018, [*https://www.eff.org/files/2018/02/20/malicious_ai_report_final.pdf*](https://www.eff.org/files/2018/02/20/malicious_ai_report_final.pdf).`'
  prefs: []
  type: TYPE_NORMAL
