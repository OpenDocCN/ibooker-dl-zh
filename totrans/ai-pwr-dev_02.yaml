- en: 2 Getting started with large language models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Engaging with ChatGPT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning the basics of using Copilot
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning the basics of using CodeWhisperer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring prompt engineering patterns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contrasting the differences between these three Generative AI offerings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this chapter, we embark on a practical journey through the landscape of
    Generative AI, harnessing the power of three groundbreaking tools: ChatGPT, GitHub
    Copilot, and AWS CodeWhisperer. As we navigate the intricacies of these technologies,
    we’ll apply them to a series of challenging scenarios modeled after the rigorous
    interview questions posed by leading tech giants. Whether you’re a seasoned developer
    or a curious enthusiast, prepare to unlock innovative strategies that could give
    you the edge in your next technical interview. Get ready to transform abstract
    concepts into tangible solutions right at the forefront of AI’s evolving role
    in tech hiring.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will begin by using two currently available models for ChatGPT: GPT-4 and
    GPT-3.5\. The purpose is twofold: it will allow us to appreciate the engagement
    model of ChatGPT, and it will also let us establish a baseline against which we
    can compare and contrast the other two. Using two models will also allow us to
    appreciate the generational sea change between these model versions. Finally,
    throughout this chapter, we will use some common patterns in prompt engineering.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 A foray into ChatGPT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Context is one of the most important aspects of working with ChatGPT. Your previous
    *prompts* can drastically change the results from your current prompt. In language
    models like ChatGPT, a prompt refers to the input provided to the model to generate
    a response. It can be a single sentence, a paragraph, or even a longer text. It
    serves as the instruction or query to the model, guiding its response. Given the
    quality of the prompt and the context in which the model responds, it is essential
    always to be aware of the prompts you have issued in the current session. Therefore,
    starting with a new session every time you begin a new project is advised. Appendix
    A will walk you through setting up an account, logging in to ChatGPT, and writing
    your first prompt.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.1 Navigating nuances with GPT-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will work toward finding a solution to the following question:
    “How would you reserve a singly linked list in Python?”'
  prefs: []
  type: TYPE_NORMAL
- en: What is a singly linked list?
  prefs: []
  type: TYPE_NORMAL
- en: A *singly linked list* is a fundamental data structure in computer science that
    consists of a sequence of elements, each stored in a node. Generally, singly linked
    lists consist of nodes in which the data is stored and a reference to the next
    node in the linked list.
  prefs: []
  type: TYPE_NORMAL
- en: With a singly linked list, you can only travel in one direction. Common operations
    on a singly linked list include insertion (adding a new node), deletion (removing
    a node), searching (finding a node), and traversal (accessing each node sequentially).
  prefs: []
  type: TYPE_NORMAL
- en: 'We will start with this simple prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/logo-NC.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Going forward, when I ask a question, try to formulate a better question.
    As an intern who studied computer science in college, how would you define a singly
    linked list in pseudocode? |'
  prefs: []
  type: TYPE_TB
- en: 'Okay, this may not be such a simple prompt. First, we have directed ChatGPT
    to enhance and reformulate our questions based on its training data so we will
    get better prompts. Better prompts make for better output. You may be asking,
    what makes for a better prompt? Great question! General prompts produce general
    results. Specific prompts produce specific results. As we engage with large language
    models (LLMs) generally and ChatGPT specifically, we will go from general to specific,
    refining the output as we go. This is known as the *Refinement Pattern in prompt
    engineering*: iteratively refining or improving the prompt to get more accurate,
    relevant, or sophisticated responses.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second part of the prompt introduces a prompting pattern we will see throughout
    this book: the *Persona Pattern*. In the context of prompt engineering, mainly
    related to AI and LLMs, the Persona Pattern refers to a strategy of designing
    prompts that establish a specific persona or role for the AI to assume. This approach
    guides the model’s responses consistently and contextually appropriately. One
    of the key benefits of using the Persona Pattern is maintaining consistency in
    responses. Adhering to a defined persona makes the AI’s replies more predictable
    and aligned with the user’s expectations. In this case, we have asked ChatGPT
    to assume the persona of an intern with a background in computer science. Why
    an intern? We want a persona who will do the work.'
  prefs: []
  type: TYPE_NORMAL
- en: It bears repeating that when working with LLMs, even when applying personas,
    the same input will not always produce the same output. For this reason, your
    output may not match the following exactly, but hopefully it is similar. (Note
    that these listings are pseudocode.)
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.1 ChatGPT’s reformulation of our question about reversing a linked
    list
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: When asked the refined question, ChatGPT will provide the following code listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.2 ChatGPT’s answer about how to reverse a linked list
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: One of the excellent quality-of-life-enhancing features of working with ChatGPT
    is that it will usually provide documentation about the code in question. Figure
    2.1 is a screenshot of the textual description provided by ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH02_F01_Crocker2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 ChatGPT Model 4’s explanation of the pseudocode definition of a singly
    linked list
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now have ChatGPT assume a new role—that of a computer science intern:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/logo-NC.png)'
  prefs: []
  type: TYPE_IMG
- en: '| As an intern with a background in computer science, how would you define
    the structure and basic operations of a singly linked list using the programming
    language Python? This definition should include the essential components of the
    list, such as nodes and links, and outline fundamental operations like creating
    a node, adding a node to the list, and traversing the list. |'
  prefs: []
  type: TYPE_TB
- en: Listing 2.3 ChatGPT’s implementation of a singly linked list in Python
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: ChatGPT will likely include a sample test harness to run this code.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.4 Python-based method to implement and run the singly linked list
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we can refine the persona to be an interviewee for an engineering
    job. The switch in personas will signal to the ChatGPT-3.5 model that it should
    explain the code as well as an approach to solving the problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/logo-NC.png)'
  prefs: []
  type: TYPE_IMG
- en: '| You are a student with a background in computer science who is interviewing
    for an engineering job at a software company. You are asked the following question,
    based on the previous definition of a singly linked list (in Python), how would
    you write a method that would reverse the output of the traversal method. How
    would you implement such a method? |'
  prefs: []
  type: TYPE_TB
- en: Listing 2.5 ChatGPT’s explanation of how to reverse a singly linked list
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: ChatGPT will likely output text similar to what is shown in figure 2.2, explaining
    the method and the approach to solving the problem.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH02_F02_Crocker2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 ChatGPT Model 4’s explanation of the pseudocode definition of a reversing
    a linked list
  prefs: []
  type: TYPE_NORMAL
- en: This implementation effectively reverses the singly linked list in place, and
    the traversal method will output the elements in reverse order compared to their
    original insertion sequence.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.2 Charting paths with GPT-3.5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will explore how to harness the capabilities of ChatGPT-3.5
    to create a singly linked list in Python. ChatGPT-3.5 excels at generating human-like
    text based on the input it receives. This makes it a valuable tool for coding
    assistance, as it can provide step-by-step guidance, suggest improvements, and
    offer detailed explanations of complex programming concepts.
  prefs: []
  type: TYPE_NORMAL
- en: To create a singly linked list, we will use ChatGPT-3.5 to generate the necessary
    Python code. A singly linked list is a data structure consisting of nodes, where
    each node contains a value and a reference to the next node in the sequence. This
    structure is particularly useful for dynamic memory allocation and efficient insertions
    and deletions. Using ChatGPT-3.5, we can simplify the process of coding a singly
    linked list, ensuring that our implementation is both efficient and easy to understand.
    The following example demonstrates how to define the `Node` and `LinkedList` classes,
    initialize a list, and perform basic operations such as insertion and traversal.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.6 Implementation of a singly linked list by ChatGPT-3.5
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You can apply the Persona Pattern in either direction: you can tell the LLM
    to respond as though it were someone or something within a given role, or you
    can ask the LLM to assume that you are a certain persona. This can be very useful
    when you need to explain some code in simplified terms or are attempting to understand
    complex or complicated topics. For example, we can ask ChatGPT to explain our
    code to us in a simplified manner with this prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/logo-NC.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Assume that I am an adult who graduated from college with a degree in communications.
    I have no experience with computer science. How would you explain that method
    to me? |'
  prefs: []
  type: TYPE_TB
- en: Let’s examine how ChatGPT would explain our method to someone without a computer
    science background.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.7 ChatGPT explanation for someone who is not a computer scientist
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: When you use the Persona Pattern in reverse, it is commonly referred to as the
    *Audience Persona Pattern* in the context of prompt engineering. This refers to
    a predefined profile or representation of the intended audience for a particular
    application or use case. It helps in tailoring the responses generated by LLMs
    to better suit the needs and expectations of a specific group of users or individuals.
    Before we move on to GitHub CoPilot, let’s compare the output quality of each
    model.
  prefs: []
  type: TYPE_NORMAL
- en: '2.1.3 Navigating the AI seas: From the shores of GPT-3.5 to the horizons of
    GPT-4'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the significant differences between the output of these two models is
    in the sophistication and transparency of their outputs, particularly in how these
    models interact with and modify data structures. The difference between the approaches
    used by GPT-3.5 and GPT-4 underscores a broader shift toward greater clarity and
    predictability in AI-generated code. As AI models become more advanced, their
    output increasingly reflects the nuances of good programming practices, mirroring
    the evolution of human programmers’ skills and sensibilities. This evolution is
    crucial for AI to be a reliable partner in software development, where clarity
    and precision are not just ideals but necessities.
  prefs: []
  type: TYPE_NORMAL
- en: With GPT-3.5, the approach taken in the `reverse_and_display` method was somewhat
    opaque in its execution. This version of the model altered the underlying data
    structure of the linked list, effectively reversing the nodes. However, it did
    so without explicitly signaling this change to the user. From a developer’s standpoint,
    this could lead to unexpected side effects. For instance, if we were to call `reverse_and_display`
    with the assumption of merely displaying the reversed list, we would find that
    the original list structure had been permanently altered. This lack of transparency
    in the operation could easily lead to confusion and bugs, especially in more complex
    applications where the integrity of the original data structure is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast, GPT-4 exhibits a more refined approach with its `reverse` method.
    This method explicitly reverses the linked list, and any seasoned programmer could
    infer from the name and structure of the method that it would modify the underlying
    data structure. GPT-4’s methodology aligns more closely with clear and maintainable
    code principles. It embodies the idea that each function or method should perform
    a well-defined task. The separation of concerns is evident here: the reversal
    of the list and its display are treated as distinct operations. This enhances
    code readability and reduces the likelihood of unintended side effects, as the
    developer is fully aware of the changes applied to the data structure.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Let Copilot take control
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now let’s use GitHub Copilot to tackle the same problem. Appendix B has instructions
    on creating an account and installing the plugin into your favorite integrated
    development environment (IDE; assuming your favorite IDE is either VS Code or
    PyCharm). Once you have completed the installation, you should create a new project
    in your IDE. First, create a new file named main.py. At the beginning of this
    file, enter the following comment/prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Note the hash character at the beginning; it denotes a Python comment. What
    is particularly interesting is that we used the same prompt in ChatGPT and GitHub
    Copilot.
  prefs: []
  type: TYPE_NORMAL
- en: Next, note that as you begin to type the definition of the `ListNode` class,
    Copilot will make code suggestions. This is the inline mode of engagement. Alternatively,
    you can activate the interactive model by pressing Ctrl-Enter and have Copilot
    generate up to 10 recommendations based on the current context.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE Throughout the book, we will mainly use inline mode, in which you use the
    Tab key to accept a given suggestion.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will likely get code resembling the source code created by ChatGPT. Let’s
    try a slightly different programming challenge rather than reprint the same code
    from the previous section. We will ask the following of Copilot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: After a few carriage returns, Copilot should add some comments that discuss
    this code’s time and space complexity and the problem in general. Fascinating!
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.8 ChatGPT calculating and reporting the complexity of this code
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Copilot’s suggestion is admirable and completely valid, but it would not likely
    be an acceptable answer during an interview. It feels like a cheat. We should
    expect that there would be a follow-up question about how to do this without sorting
    the entire list. Let’s refine the prompt to ensure that the list is not sorted
    before taking the *k*th element:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The code that Copilot provides looks very similar to a binary search, which
    is certainly an interesting choice.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.9 Copilot’s approach to solving the *k*th element problem
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 2.3 Let CodeWhisperer speak loudly
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we begin using CodeWhisperer, we should disable Copilot. Click the Extensions
    tab, and search for Copilot. Once you have found it, click the Disable button.
    You will need to restart the application. When the application has restarted,
    you can begin to use CodeWhisperer. If you need assistance installing or configuring
    CodeWhisperer, refer to appendix C. Once the plugin is installed and you are logged
    in to your developer account, create a file called asset.py. Figure 2.3 shows
    how to locate and disable this plug-in.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH02_F03_Crocker2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 Before we can switch to CodeWhisperer, we must disable Copilot. We
    turn off the extension in the Extensions tab.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the same prompt that we used for Copilot. It is reprinted here
    for convenience:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The code that CodeWhisperer provides implements the Quickselect algorithm, which
    is closely related to the QuickSort sorting algorithm. Quickselect is specifically
    designed to efficiently find the *k*th smallest element in an unsorted array.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.10 CodeWhisperer’s approach to solving the *k*th element problem
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: There is a fascinating distinction between the code created by Copilot and that
    of CodeWhisperer. CodeWhisperer interprets `k` as the index of the element in
    the sorted array. Because array indices in most programming languages start at
    0, if `k` is 2, CodeWhisperer will find the third-smallest element (because indices
    0, 1, and 2 correspond to the first, second, and third smallest elements, respectively).
    On the other hand, Copilot assumes that `k` refers to the rank of the element,
    not the index. So, if `k` is 2, Copilot will return the second-smallest element
    in the array. This is akin to saying “second place” rather than “index 2.”
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we introduced AWS CodeWhisperer into the mix. Like its predecessors,
    CodeWhisperer capably generated code that solves the problem, reinforcing AI’s
    transformative potential in software development.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given the striking similarity of the code produced by these tools, an intriguing
    question naturally arises: how do these products truly compare? Given each tool’s
    unique strengths and limitations, the answer is not as straightforward as you
    may think.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we’ll delve into this question, comparing these three
    tools—ChatGPT, Copilot, and AWS CodeWhisperer—in a bid to understand their unique
    offerings, optimal use cases, and how they may reshape the future of software
    development. We aim to provide a comprehensive guide that can help software developers
    navigate this rapidly evolving landscape of AI-driven tools.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Comparing ChatGPT, Copilot, and CodeWhisperer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first dimension we will consider is the engagement model: how we engage
    with AI. In the case of ChatGPT, we log in to the chat website and enter prompts
    into a chat input box. Then we refine our requirements in subsequent prompts.
    The feedback loop takes the context from the previous prompts, applies it to the
    current prompt, and generates output to which the user reacts and refires. If
    we contrast this engagement model against that of Copilot and CodeWhisperer, we
    note that the latter two tools work within an IDE. We can’t use it outside our
    IDE, try as we may. The approach is not inherently inferior; it just differs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The way that Copilot and CodeWhisperer keep you in your IDE can be seen as
    a benefit rather than a deficiency. In later chapters, we will get acquainted
    with Copilot Chat, the best of both worlds: ChatGPT and GPT-4, all in your IDE.
    These tools keep you in your code without distraction for longer. Working distraction-free
    is one of the keys to productivity. Copilot and CodeWhisperer excel at getting
    out of your way, keeping you from switching contexts, freeing you from distraction,
    and keeping you in the flow state longer. They do this well. You engage ChatGPT
    in a dialog; Copilot and CodeWhisperer advise you. The dialog takes longer; advice
    comes fast and free.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will examine how the code is presented and generated. ChatGPT can create
    the code as a block, method, class, or project. ChatGPT reveals projects deliberatively
    if asked. But it does create the project behind the scenes. ChatGPT, after all,
    likes to talk. With Copilot and CodeWhisperer, the code unfolds one method at
    a time, at least initially. As you use these tools more, you will notice that
    they can write more and more of the code for a given class. But unfortunately,
    they can’t write an entire project with a tiny prompt.
  prefs: []
  type: TYPE_NORMAL
- en: One item that they all share is their ability to respond to prompts. With ChatGPT,
    prompts are the only way to engage with the tool. With Copilot and CodeWhisperer,
    responding to prompts is not strictly necessary, but coding such prompts will
    make the output correspond more closely to what you initially had in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Combining these factors, you may conclude that ChatGPT is an excellent choice
    for exploration and prototyping. However, ChatGPT can introduce unnecessary distractions,
    partly because you have left your IDE and are now in a web browser with all of
    the accompanying temptations that come with it. ChatGPT itself is part of the
    inclusion of unnecessary distractions. You will eventually fall into the proverbial
    rabbit hole. The tool makes it too easy not to. Don’t let that scare you off.
    It is a beautiful resource.
  prefs: []
  type: TYPE_NORMAL
- en: Copilot and CodeWhisperer require that you have a desired outcome in mind. Therefore,
    these tools are perfect for when you want to go head down, coding with precise
    requirements and tight deadlines. Copilot and CodeWhisperer work best when you
    know the language and the framework. They can automate much of the drudgery, allowing
    you to focus on the business requirements, which add value and are likely why
    you are writing the software in the first place. Figure 2.4 briefly summarizes
    the benefits and limitations of all three generative AIs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH02_F04_Crocker2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 A comparison of the positives and negatives of ChatGPT, Copilot,
    and CodeWhisperer
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we went through a lot, implementing basic data structures and
    solving some classic computer science problems. The work in this chapter is foundational,
    allowing us to better recognize when it makes sense to use ChatGPT as opposed
    to when to use the other IDE-focused tools such as Copilot and CodeWhisperer.
    In subsequent chapters, we will use this knowledge to choose the most suitable
    tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'One final note: these tools work best when they work together. ChatGPT is an
    excellent tool for example and structure. Copilot and CodeWhisperer allow you
    to extend and customize the code.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ChatGPT is a prompt-based Generative AI that engages the user in a dialogue
    that helps them explore ideas to aid in the design and development of entire projects.
    In addition, ChatGPT artfully generates documentation for each method it writes.
    One of the reasons we began the chapter using it is that it helped define a template
    we used throughout the remainder of the chapter. It is a fascinating product,
    one that can lead to unnecessary albeit enjoyable distractions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Copilot and CodeWhisperer are head-down tools that work best when you know what
    you want to do and need some advice about how best to get it done. You engage
    with these tools in a way that is remarkably similar, as are the results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ChatGPT (as of this writing) does not support development within an IDE. However,
    unlike GitHub Copilot and AWS CodeWhisperer, it can produce entire projects and
    easily translate code from one programming language to another. Copilot and CodeWhisperer
    take hints from your comments to infer what code you want to write. With ChatGPT,
    you explicitly write prompts that ChatGPT uses to create the code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The purpose of the Persona Pattern is to design prompts that establish a specific
    persona or role for the AI to assume, which guides the model’s responses in a
    consistent and contextually appropriate manner. By adhering to a defined persona,
    the AI’s replies become more predictable and aligned with the user’s expectations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The intern persona is often characterized by eagerness to learn, a basic to
    intermediate level of knowledge in the field, and a willingness to take on various
    tasks for learning and experience. The intern may ask clarifying questions, seek
    guidance, and demonstrate a proactive approach to problem-solving. They are often
    resourceful but may lack the deep expertise of more experienced professionals
    in the field. This persona is useful in scenarios where the AI needs to simulate
    a learning and growth-oriented mindset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Refinement Pattern involves iteratively refining or improving the prompt
    to get more accurate, relevant, or sophisticated responses. It’s about going from
    general to specific, enhancing the output quality as the interaction progresses
    with large language models like ChatGPT.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Audience Persona Pattern is a variation of the Persona Pattern in prompt
    engineering. It involves defining a profile or representation of the intended
    audience for a particular application or use case, which helps tailor the responses
    generated by LLMs to better suit the needs and expectations of a specific group
    of users or individuals.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
