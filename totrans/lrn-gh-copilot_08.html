<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 7. Keeping Copilot Timely and Relevant"><div class="chapter" id="ch07">
<h1><span class="label">Chapter 7. </span>Keeping Copilot Timely and Relevant</h1>

<p><a contenteditable="false" data-primary="GitHub Copilot" data-secondary="relevance of" data-type="indexterm" id="xi_GitHubCopilotrelevanceof744"/><a contenteditable="false" data-primary="GitHub Copilot" data-secondary="timeliness of" data-type="indexterm" id="xi_GitHubCopilottimelinessof744"/><a contenteditable="false" data-primary="relevance" data-type="indexterm" id="xi_relevanceofGithubCopilot744"/><a contenteditable="false" data-primary="timeliness" data-type="indexterm" id="xi_timelinessofGithubCopilot744"/>The range of functionality and interactivity provided by GitHub Copilot is truly impressive. However, the responses it generates can sometimes be less impressive (and less useful) if they are not timely and relevant. As good as the AI can be, at times you may need to take extra steps to <em>steer</em> it.</p>

<p>For example, in certain instances, you may need to direct Copilot to focus on certain portions of your content to get targeted answers. Or you may need to augment its training to get responses more relevant to your codebase. And you may need to pay extra attention to be aware when Copilot is suggesting code that may be out of date or referencing features that are no longer supported.</p>

<p>In this chapter, we’re going to look at how to manage interaction with Copilot in these situations. You can leverage certain strategies and functionality to help ensure relevancy and timeliness in your interactions with Copilot. Certain approaches can compensate when Copilot may not be aware of recent changes or referencing the right sources.</p>

<p>All of this is aimed at helping Copilot have the most usable set of context in order to provide the most useful responses for what we’re asking of it. In the next few pages, we’ll look at the following areas related to Copilot’s use of context:</p>

<ul>
	<li>Where context originates</li>
	<li>How timeliness and relevancy may be affected</li>
	<li>User-based coping strategies</li>
	<li>Adding context to make code more relevant</li>
</ul>

<p>By its very definition, <em>generative</em> implies generating new content in part based on gathering and processing context. So, let’s start with a reminder of where the context that Copilot uses comes from.</p>

<section data-type="sect1" data-pdf-bookmark="Where Context Originates"><div class="sect1" id="id76">
<h1>Where Context Originates</h1>

<p><a contenteditable="false" data-primary="context" data-secondary="origins of" data-type="indexterm" id="xi_contextoriginsof7244"/>As we’ve discussed in previous chapters, in the IDE, Copilot draws context from your immediate working environment—specifically, from the files you have in your workspace and the content associated with them. This includes typical items like the name of the file, the comments in them, and the code before and after the cursor. But Copilot also draws from more dynamic interactions, such as whether or not you accepted its last code suggestion. And by automatically creating an index of your repository, Copilot gains a larger understanding of your project. Copilot can also be directed to take other content into consideration.</p>

<p>For quickly generating coding suggestions in your IDE/editor, targeting the files you have open is a useful strategy used by Copilot. The focus allows it to quickly get a good sense of what is presumably most important (since you have those files readily accessible).</p>

<p>In this <em>inline<a contenteditable="false" data-primary="inline mode" data-type="indexterm" id="id783"/></em> mode, Copilot uses multiple strategies to ensure a fast response. The client (extension installed in your interface) asks the model for very few suggestions (one to three). Copilot is aggressive in caching results and adapts the suggestions if you continue typing. It also has some built-in checks, preventing sending requests if you are typing in the middle of a line, for example, unless there is whitespace to the right of the cursor. Then the index we’ve discussed is updated based on changes.</p>

<p>In this mode, scoring also happens to determine whether the prompt assembled to send to the model is even worthwhile (worth invoking the model). This decision is based on factors like previous responses to suggestions. This approach helps exclude repetitive prompts or ones that already exist in the code.</p>

<p>Most of these same strategies are not needed when you switch to the chat interface. Within that, Copilot has more time to come up with responses, and so more completion suggestions can be requested by the client. For gathering context when working in this interface, you can also be more directive of where to get the context. Copilot includes methods like chat variables and chat participants (as discussed in <a data-type="xref" href="ch03.html#ch03">Chapter 3</a> and other chapters) to focus Copilot on particular items.</p>

<p>Regardless of where the user is working, the client collects the context, processes it into a prompt, and sends it to the model you’ve selected. After doing some quick validation of what the model returns and generating the requested set of responses, those are then displayed to the user. The responses can include multiple options in the IDE if multiple completion suggestions were available.</p>

<p>The <em>quick validation<a contenteditable="false" data-primary="quick validation" data-type="indexterm" id="id784"/></em> just referred to involves quickly looking for patterns in the response that are repetitive or might indicate a security issue (such as hardcoded credentials). These are beneficial checks, but they don’t prevent other factors that may lead to relevancy and timeliness being off. Let’s look at some of those other factors next<a contenteditable="false" data-primary="" data-startref="xi_contextoriginsof7244" data-type="indexterm" id="id785"/>.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="How Timeliness and Relevancy May Be Affected"><div class="sect1" id="id378">
<h1>How Timeliness and Relevancy May Be Affected</h1>

<p>When you first open up Copilot’s chat interface, you get a notification:</p>

<pre data-type="programlisting" translate="no">
I'm powered by AI, so surprises and mistakes are possible. Make 
sure to verify any generated code or suggestions, and share 
feedback so that we can learn and improve.
</pre>

<p>This disclaimer is a reminder that generative AI can be inaccurate and problematic. Ultimately, it’s up to the user to ensure that the generated content is correct and relevant. (This is also why you should always use standard validation methods like testing and code reviews to check any content produced with the assistance of the AI.)</p>

<p>The disclaimer is necessary because several kinds of challenges can affect the timeliness and relevancy of Copilot’s suggestions and responses. These include the <span class="keep-together">following</span>:</p>

<ul>
	<li>Training cutoffs</li>
	<li>Hallucinations</li>
	<li>Lack of real-time validation</li>
	<li>Mistaken context</li>
</ul>

<p>Let’s look at each of these in more detail.</p>

<section data-type="sect2" data-pdf-bookmark="Training Cutoffs"><div class="sect2" id="id77">
<h2>Training Cutoffs</h2>

<p><a contenteditable="false" data-primary="training cutoffs" data-type="indexterm" id="xi_trainingcutoffs7664"/>LLMs are trained on data that is current as of the time the training occurs. Beyond that date, the model has no <em>built-in</em> knowledge of changes that have occurred in the areas it was trained in. The further away from the training cutoff your use of the tool occurs, the more likely some of the responses and suggestions will be out of date. This can manifest as Copilot producing deprecated code or code that was more relevant for a previous version of a framework or language. And, of course, results will vary depending on which model you choose to use.</p>

<div data-type="note" epub:type="note">
<h1>Training Frequency</h1>

<p><a contenteditable="false" data-primary="training frequency" data-type="indexterm" id="id786"/><a contenteditable="false" data-primary="frequency, of training" data-type="indexterm" id="id787"/>If you’re wondering why these models aren’t kept more up to date, it’s important to understand that they have billions of parameters and huge corpora of data to process for any training. This requires significant compute cost and time to accomplish. So, updates to the wider underlying training are expensive in multiple ways.</p>
</div>

<p>Let’s look at a simple example of challenges that may occur from training cutoffs (as surfaced through Copilot as of the time of this writing). We’ll ask Copilot to write a function to seed a random number generator in Go (<a data-type="xref" href="#asking-copilot-to-cre">Figure 7-1</a>).</p>

<figure><div id="asking-copilot-to-cre" class="figure"><img alt="" src="assets/lghc_0701.png" width="896" height="543"/>
<h6><span class="label">Figure 7-1. </span>Asking Copilot to create a random number generator in Go</h6>
</div></figure>

<p class="pagebreak-before">While this looks fine and is syntactically correct, there is a problem. The <code translate="no">Seed<a contenteditable="false" data-primary="Seed function" data-type="indexterm" id="id788"/></code> function was <a href="https://oreil.ly/D2hpj">deprecated in Go</a><a contenteditable="false" data-primary="Go code" data-type="indexterm" id="id789"/> as of version 1.20. Let’s see if Copilot understands that this is deprecated. We can ask it in the Chat interface “Is the Seed function deprecated in Go?” The response, as shown in <a data-type="xref" href="#asking-copilot-if-the">Figure 7-2</a>, shows that, based on the model’s training, it doesn’t have the information that the function is <span class="keep-together">deprecated</span>.</p>

<figure><div id="asking-copilot-if-the" class="figure"><img alt="" src="assets/lghc_0702.png" width="883" height="602"/>
<h6><span class="label">Figure 7-2. </span>Asking Copilot if the <code translate="no">Seed</code> function is deprecated</h6>
</div></figure>

<p>So although the function is no longer meant to be used, Copilot was not aware of that. This illustrates the point about the training cutoff. We’ll look at some ways to deal with these kind of challenges later in the chapter.</p>

<aside data-type="sidebar" epub:type="sidebar" class="pagebreak-before"><div class="sidebar" id="id790">
<h1 class="less_space">Detecting Deprecated Contents</h1>

<p><a contenteditable="false" data-primary="deprecated contents" data-type="indexterm" id="id791"/><a contenteditable="false" data-primary="contents" data-secondary="deprecated" data-type="indexterm" id="id792"/>In some IDEs, other installed tools may detect that code is deprecated and then alert you. <a data-type="xref" href="#figure-7-3">Figure 7-3</a> shows an example of a deprecation issue being detected and flagged by another tool.</p>

<figure><div id="figure-7-3" class="figure"><img alt="" src="assets/lghc_0703.png" width="886" height="547"/>
<h6><span class="label">Figure 7-3. </span>Deprecation detection by another tool</h6>
</div></figure>

<p>In a case like this, you <em>may </em>be able<em> </em>to use Copilot’s Fix functionality<a contenteditable="false" data-primary="Fix functionality" data-type="indexterm" id="id793"/> to have it generate alternative code.</p>
</div></aside>

<p>Out-of-date results represent one category of problems; results would have been valid at one time but no longer are. Another category of issues arises when results look valid for the current context but may not reflect real data or references.<em> </em>These are known as <em>hallucinations<a contenteditable="false" data-primary="" data-startref="xi_trainingcutoffs7664" data-type="indexterm" id="id794"/></em>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Hallucinations"><div class="sect2" id="id78">
<h2>Hallucinations</h2>

<p><a contenteditable="false" data-primary="hallucinations" data-type="indexterm" id="xi_hallucinations71064"/>LLMs are subject to creating responses with data that looks legitimate but isn’t. These are referred to as <em>hallucinations</em>. In general chat interfaces, this can take the form of referencing nonexistent items or stating as fact things that simply aren’t true. In more critical systems, such as threat detection, an AI model may flag something as a threat when it is not.</p>

<p class="pagebreak-before">In the context of coding, hallucinations can take several forms:</p>

<ul>
	<li>Coding suggestions that may reference identifiers (names, variables, constants, etc.) or related code that does not exist</li>
	<li>Generated data that may not be accurate</li>
	<li>Functions or methods that don’t exist</li>
	<li>Incorrect library or API usage (or use of libraries or APIs that don’t exist at all)</li>
	<li>Made-up types or classes</li>
	<li>Plausible but incorrect business logic</li>
	<li>Bad assumptions about surrounding code</li>
	<li>Tests that don’t actually test the intended behavior</li>
</ul>

<p>While hallucinations in the first category can certainly still occur in output produced from Copilot, they seem less common now than in Copilot’s early days due to improvements with the underlying models. These kinds of hallucinations (referencing identifiers or code that doesn’t exist) tend to be more obvious and can usually be caught quickly by user reviews. If these hallucinations do end up getting accepted and overlooked, compilers, linters, or other tools that check syntax will likely flag them at some point.</p>

<p>The second type of hallucination (involving generated data) is more subtle. It occurs in part because there is no real-time automatic validation of generated data<a contenteditable="false" data-primary="" data-startref="xi_hallucinations71064" data-type="indexterm" id="id795"/>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Lack of Real-Time Validation"><div class="sect2" id="id79">
<h2>Lack of Real-Time Validation</h2>

<p><a contenteditable="false" data-primary="validation" data-secondary="lack of real-time" data-type="indexterm" id="xi_validationlackofrealtime71294"/>Generated data that Copilot returns may not be accurate. Copilot itself sometimes reminds you of that, as shown in <a data-type="xref" href="#copilot-disclaimer-on">Figure 7-4</a>. In this case, we asked Copilot to generate a mapping of area codes to states. After completing the tasks, Copilot adds the disclaimer that “The above code is just a placeholder and may not represent the actual area codes for each state.”</p>

<figure><div id="copilot-disclaimer-on" class="figure"><img alt="" src="assets/lghc_0704.png" width="917" height="488"/>
<h6><span class="label">Figure 7-4. </span>A Copilot disclaimer on the accuracy of the generated data</h6>
</div></figure>

<p>Why is this the case? Keep these four points in mind:</p>

<ul>
	<li>Copilot is trained on data which may or may not contain accurate, actual values.</li>
	<li>Copilot is generating results to match syntax and structure.</li>
	<li>Copilot does not run code that it generates and doesn’t validate logic.</li>
	<li>Copilot does not have mechanisms to look up and check data to see if it is accurate or up-to-date. </li>
</ul>

<p>The first three items are self-explanatory. The fourth item indicates that Copilot has no mechanism to cross-check results it generates against other sources such as the web. While some AI techniques can leverage tools to do this, they are not integrated with Copilot for the purpose of validating responses from the model. The data may be correct, but there is no guarantee. In short, Copilot has no way of knowing if something is true or false.</p>

<p>For this reason, you should not assume correctness when using information generated by Copilot. Data generation from Copilot is better suited for content that needs correct form but not necessarily correct values, like testing scenarios.</p>

<div data-type="note" epub:type="note">
<h1>Copilot Extensions</h1>

<p>You can create Copilot Extensions<a contenteditable="false" data-primary="Extensions (GitHub Copilot)" data-type="indexterm" id="id796"/> that call APIs or other tools to get more relevant, up-to-date information for particular use cases. You can either find an existing extension that already addresses what you’re looking to do or build your own. Copilot Extensions are covered in detail in <a data-type="xref" href="ch10.html#ch10">Chapter 10</a>.</p>
</div>

<p>Another challenge you may encounter is having Copilot use context you did not intend for it to reference for its responses<a contenteditable="false" data-primary="" data-startref="xi_validationlackofrealtime71294" data-type="indexterm" id="id797"/>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Misplaced Context"><div class="sect2" id="id80">
<h2>Misplaced Context</h2>

<p><a contenteditable="false" data-primary="misplaced context" data-type="indexterm" id="xi_misplacedcontext71604"/><a contenteditable="false" data-primary="context" data-secondary="misplaced" data-type="indexterm" id="xi_contextmisplaced71604"/>Most of the time, when you are chatting with Copilot in the IDE’s chat interface, you will have a file active in the editor. You may also have a portion of it selected. In those cases, Copilot assumes this is the main context that any open-ended questions (such as “How do I test this?”) refer to.</p>

<p>Having Copilot use that specific content may be exactly what you intend. Or you might have intended for Copilot to respond based on a different file or a different portion of the active file. If Copilot assumes a different context, Copilot’s answers may not be what you are looking for.</p>

<p class="pagebreak-before">Imagine you are using multiple languages or frameworks in a project and have context set that doesn’t align with your prompt. Such a project is shown in <a data-type="xref" href="#wrong-context-for-pro">Figure 7-5</a>. In this project, we have a Python file (<em>fibonacci.py</em>) and one written in Go (<em>prime.go</em>), as shown in the upper left of the IDE.</p>

<p>With the Python file selected (and thus used as context), we ask Copilot, “How do I test the Go code here?” Copilot responds by telling us about the mismatch between the context and the prompt. It then provides information about how to do Python testing to align with the active file.</p>

<figure><div id="wrong-context-for-pro" class="figure"><img alt="" src="assets/lghc_0705.png" width="1636" height="686"/>
<h6><span class="label">Figure 7-5. </span>Indicating the wrong context for a prompt</h6>
</div></figure>

<p>Another type of issue can arise when no context is implied<a contenteditable="false" data-primary="" data-startref="xi_misplacedcontext71604" data-type="indexterm" id="id798"/><a contenteditable="false" data-primary="" data-startref="xi_contextmisplaced71604" data-type="indexterm" id="id799"/>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Missing Context"><div class="sect2" id="id81">
<h2>Missing Context</h2>

<p><a contenteditable="false" data-primary="context" data-secondary="missing" data-type="indexterm" id="xi_contextmissing71784"/><a contenteditable="false" data-primary="missing context" data-type="indexterm" id="xi_missingcontext71784"/>If we prompt Copilot and have no files open in the workspace and nothing else in the prompt for it to draw on, Copilot will usually offer a more generic response. For example, assume we have a workspace with Go code to implement a Kubernetes operator, and we have no files actively open and nothing selected. Now, we prompt Copilot in chat with “How can I test the Go code here?”</p>

<p>Because no context is indicated, Copilot either will tell you to select context or will supply a response about how you can answer the question generally. <a data-type="xref" href="#generic-advice-per-mi">Figure 7-6</a> shows an example response for the case we just discussed. Here, Copilot provides guidance on how to test Go code generally.</p>

<figure><div id="generic-advice-per-mi" class="figure"><img alt="" src="assets/lghc_0706.png" width="1085" height="562"/>
<h6><span class="label">Figure 7-6. </span>Generic advice per missing context</h6>
</div></figure>

<p>This type of response also happens for other types of queries, such as trying to determine where imports are used in the codebase (<a data-type="xref" href="#another-example">Figure 7-7</a>).</p>

<figure><div id="another-example" class="figure"><img alt="" src="assets/lghc_0707.png" width="1093" height="618"/>
<h6><span class="label">Figure 7-7. </span>Another example of a generic response</h6>
</div></figure>

<p>The bottom line is that without enough implicit context (open files) or explicit context (references supplied in the prompt), Copilot defaults to generic answers.</p>

<p>When you start working with Copilot for any length of time, you will run into these classes of issues. The impact will vary depending on your particular situation. Fortunately, you, as a user, can employ a few strategies when you encounter these scenarios<a contenteditable="false" data-primary="" data-startref="xi_contextmissing71784" data-type="indexterm" id="id800"/><a contenteditable="false" data-primary="" data-startref="xi_missingcontext71784" data-type="indexterm" id="id801"/>.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="User-Based Coping Strategies"><div class="sect1" id="id82">
<h1>User-Based Coping Strategies</h1>

<p><a contenteditable="false" data-primary="user-based coping strategies" data-type="indexterm" id="xi_userbasedcopingstrategies72024"/><a contenteditable="false" data-primary="coping strategies, user-based" data-type="indexterm" id="xi_copingstrategiesuserbased72024"/>In general, we have three strategies to help when Copilot’s responses are not as accurate or timely as we may need:</p>

<ul>
	<li>Explicitly telling Copilot what to use for context</li>
	<li>Changing the model</li>
	<li>Augmenting the data that Copilot has available for context</li>
</ul>

<p>Let’s look at each of these in turn.</p>

<section data-type="sect2" data-pdf-bookmark="Telling Copilot What to Use for Context"><div class="sect2" id="telling-copilot-what">
<h2>Telling Copilot What to Use for Context</h2>

<p><a contenteditable="false" data-primary="GitHub Copilot" data-secondary="telling it what to use for context" data-type="indexterm" id="xi_GitHubCopilottellingitwhattouseforcontext72154"/><a contenteditable="false" data-primary="context" data-secondary="telling Copilot what to use for" data-type="indexterm" id="xi_contexttellingCopilotwhattousefor72154"/>As we outlined earlier in this chapter, absent more explicit direction, Copilot tries to gather context from what’s being actively used in the editor. If we are working directly in the editor, this may be correct in most cases. However, when we are working with the chat interface, we may want to have Copilot focus on other parts of the project or answer a generic question such as “Where is X used?”</p>

<p>Since we are dealing with the chat interface, we can leverage Copilot’s built-in features of chat participants and chat variables. These features were covered in detail in <a data-type="xref" href="ch03.html#ch03">Chapter 3</a>. Here, we’ll provide a simple reminder of how to use them to help with cases like these.</p>

<p>The chat participants have knowledge of different domains that Copilot may need to work with, including the overall workspace, the terminal, and VS Code. When we use a participant in a query, it steers Copilot to use that domain for context with the prompt.</p>

<p>In an earlier section, when we were looking at a project, we asked Copilot, “Where are imports used in this code?” We got a generic response telling us the steps to find imports for any Go project rather than for our project. The same was true for the “How can I test the Go code here?” prompt. Copilot responded with generic instructions for how we could determine the information for ourselves.</p>

<p>However, if instead we explicitly use the <code translate="no">@workspace</code> participant in the prompt, Copilot provides information from the files we have as part of the workspace (see <a data-type="xref" href="#context-with-workspa">Figure 7-8</a>). The prompt is “@workspace Where are imports used in this code?” This matches the original intent.</p>

<figure><div id="context-with-workspa" class="figure"><img alt="" src="assets/lghc_0708.png" width="1111" height="611"/>
<h6><span class="label">Figure 7-8. </span>Context with <code>@workspace</code></h6>
</div></figure>

<p>You can also implicitly direct Copilot to use <code translate="no">@workspace<a contenteditable="false" data-primary="@workspace chat participant" data-type="indexterm" id="id802"/></code>. Certain keywords or phrases in your prompt can trigger Copilot to add <code translate="no">@workspace</code> to the prompt. For instance, we can modify our previous prompt about testing to “How can I test the Go code in this project?” The reference to <em>project</em> is enough for Copilot to understand that we mean the larger context. It then automatically runs our prompt by using <code translate="no">@workspace </code>and the shortcut command <code translate="no">/setupTests<a contenteditable="false" data-primary="/setupTests" data-type="indexterm" id="id803"/></code>, as shown in <a data-type="xref" href="#implicitly-using-wor">Figure 7-9</a>.</p>

<figure><div id="implicitly-using-wor" class="figure"><img alt="" src="assets/lghc_0709.png" width="1136" height="611"/>
<h6><span class="label">Figure 7-9. </span>Implicitly using <code>@workspace</code> based on the prompt text</h6>
</div></figure>

<p>If we need to further zero in on content, we can include one of the chat variables in the prompt to specify context, like <code translate="no">#file </code>or <code translate="no">#selection</code>. For example, we can specifically ask Copilot how to test the code in a file in our project by using the <code translate="no">#file</code> chat variable (see <a data-type="xref" href="#testing-go-with-file">Figure 7-10</a>).</p>

<figure><div id="testing-go-with-file" class="figure"><img alt="" src="assets/lghc_0710.png" width="1134" height="663"/>
<h6><span class="label">Figure 7-10. </span>Testing Go with the <code>#file</code> chat variable</h6>
</div></figure>

<div data-type="warning" epub:type="warning">
<h1>Specifying Chat Variables and Arguments</h1>

<p><a contenteditable="false" data-primary="variables" data-secondary="specifying for chat" data-type="indexterm" id="id804"/><a contenteditable="false" data-primary="Copilot Chat" data-secondary="specifying variables for" data-type="indexterm" id="id805"/><a contenteditable="false" data-primary="arguments, specifying" data-type="indexterm" id="id806"/>Simply typing in chat variables and arguments directly does not always work. What does always work is starting to type the chat variable (#) and then selecting the chat variable from the pop-up list by using the arrow keys to move, if needed, and the Enter key to select one. You should make sure to select any intended files from the list that pops up.</p>
</div>

<p>Notice that by using the <code translate="no">#file</code> chat variable, we did not need to have the file actually open or active in the editor. This mechanism then affords you a way to direct Copilot to the relevant content in the project for context. This overrides Copilot’s default mechanisms for determining which content you want.</p>

<p>Even with a directed context, Copilot may still respond with out-of-date code or information, depending on when the model was trained. Or the responses it returns may not seem as relevant or comprehensive as you want. But since Copilot provides multiple models to choose from, there may be a simple way to deal with that<a contenteditable="false" data-primary="" data-startref="xi_GitHubCopilottellingitwhattouseforcontext72154" data-type="indexterm" id="id807"/><a contenteditable="false" data-primary="" data-startref="xi_contexttellingCopilotwhattousefor72154" data-type="indexterm" id="id808"/>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Changing the Model"><div class="sect2" id="id84">
<h2>Changing the Model</h2>

<p><a contenteditable="false" data-primary="models" data-secondary="changing" data-type="indexterm" id="xi_modelschanging72574"/>Copilot allows you to choose from more than one AI model for code suggestions and chat responses. Each model will have its pros and cons. For example, some models may be better at code generation. In addition, each model will have been trained at a different point in time, so newer models will be more up-to-date and less likely to produce deprecated code than older models.</p>

<p>As a reminder, changing models in the chat interface is easy. You just select the model name that you want to use from the drop-down list in whichever chat interface you’re using. See <a data-type="xref" href="#switching-models-in-t">Figure 7-11</a> for an example.</p>

<figure><div id="switching-models-in-t" class="figure"><img alt="" src="assets/lghc_0711.png" width="848" height="834"/>
<h6><span class="label">Figure 7-11. </span>Switching models in the chat interface</h6>
</div></figure>

<p>Earlier in the chapter, we showed an example of Copilot generating a random number function by using a deprecated method (<a data-type="xref" href="#asking-copilot-to-cre">Figure 7-1</a>). This was generated with the GPT-4o model.</p>

<p class="pagebreak-before">If we switch instead to a more recent model, such as Gemini 2.5 Pro<a contenteditable="false" data-primary="Gemini 2.5 Pro" data-type="indexterm" id="id809"/>, and issue the same prompt, Copilot produces code using the newer standard <code translate="no">rand.NewSource<a contenteditable="false" data-primary="rand.NewSource function" data-type="indexterm" id="id810"/></code> function instead of trying to use the deprecated <code translate="no">rand.Seed<a contenteditable="false" data-primary="rand.Seed function" data-type="indexterm" id="id811"/></code> function. Also, if we query Copilot about whether the <em>Seed </em>function is deprecated in the main chat area, it <span class="keep-together">correctly</span> responds that the <code translate="no">rand.Seed</code> function is deprecated as of Go 1.20. <a data-type="xref" href="#using-a-newer-model-r">Figure 7-12</a> shows the response from using the newer model.</p>

<figure><div id="using-a-newer-model-r" class="figure"><img alt="" src="assets/lghc_0712.png" width="1569" height="808"/>
<h6><span class="label">Figure 7-12. </span>Using a newer model results in correct code and response</h6>
</div></figure>

<p>If you choose a different model, how do you know whether it will be more up to date? Typically, the models list will be updated as newer models become available—usually marked as <em>Preview </em>for some period of time. But you can also do some simple searching on the web or with a site like <a href="http://huggingface.co">Hugging Face</a><a contenteditable="false" data-primary="Hugging Face Spaces" data-type="indexterm" id="id812"/> to find which models are more recent.</p>

<p>You can also try querying the model itself through Copilot to find out more about which version of something was current when the model was being trained<a contenteditable="false" data-primary="" data-startref="xi_modelschanging72574" data-type="indexterm" id="id813"/>.</p>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Querying the Model to Determine Which Version Is Current"><div class="sect2" id="id85">
<h2>Querying the Model to Determine Which Version Is Current</h2>

<p><a contenteditable="false" data-primary="models" data-secondary="querying" data-type="indexterm" id="xi_modelsquerying72834"/><a contenteditable="false" data-primary="queries and querying" data-secondary="models" data-type="indexterm" id="xi_queriesandqueryingmodels72834"/>Still looking at the example where Copilot generated deprecated code, let’s see what other details we can find to help. Since Copilot didn’t recognize that the function was deprecated, it would be useful to know what version of Go Copilot thinks is current. We can ask it in the chat interface with a simple “As of your last training date, what was the current version of Go?” prompt, as shown in <a data-type="xref" href="#asking-copilot-which">Figure 7-13</a>.</p>

<figure><div id="asking-copilot-which" class="figure"><img alt="" src="assets/lghc_0713.png" width="927" height="371"/>
<h6><span class="label">Figure 7-13. </span>Asking Copilot which version of Go is current</h6>
</div></figure>

<div data-type="note" epub:type="note">
<h1>Framing the Question Appropriately</h1>

<p><a contenteditable="false" data-primary="framing questions" data-type="indexterm" id="id814"/><a contenteditable="false" data-primary="questions" data-secondary="framing" data-type="indexterm" id="id815"/>The question we asked Copilot was framed as “As of your last training date....” This is deliberate. If we simply asked Copilot, “What version of Go is current?,” it would likely tell us how to find the information ourselves about our local Go installation instead.</p>
</div>

<p>The model that is active in Copilot responds that its last training update was in October 2023—and that, as of that date, the latest stable version of Go <em>was </em>1.21.1.</p>

<p>An obvious question that comes up is why, if Copilot knew about 1.21.1 as the most recent version, it still does not recognize that something was deprecated in 1.20. Keep in mind the question we asked Copilot was which version was current when the model was last trained, not which version was used in the repositories when it was trained. In fact, if you ask Copilot a similar question via comments inline in the editor multiple times, you will likely get a different answer (see <a data-type="xref" href="#asking-copilot-which2">Figure 7-14</a>). The reason for the differences is that the answer returned in the editor is based on version references present in the training data.</p>

<figure><div id="asking-copilot-which2" class="figure"><img alt="" src="assets/lghc_0714.png" width="945" height="227"/>
<h6><span class="label">Figure 7-14. </span>Asking Copilot which version of Go is current in the editor</h6>
</div></figure>

<p class="pagebreak-before">So, assuming the answer returned by the chat query is the most recent version that the model knows about, but the model was trained on various other versions, what does that buy you? </p>

<p>What the version information returned in the chat tells you is the most recent version that could be represented in the model’s training data. So, any code generated strictly from the model’s training will not incorporate any deprecations or use any new features or version-specific changes since that version.</p>

<div data-type="warning" epub:type="warning">
<h1>Query Results May Vary</h1>

<p>Not all models may return a discrete answer for the <em>latest version</em> question. Some models may just respond that they don’t have access to that information or suggest you look up what the latest version is.</p>

<p>We can extend Copilot to have capabilities to find out information about the latest versions of languages or platforms. <a data-type="xref" href="ch10.html#ch10">Chapter 10</a> guides you through implementing an extension to find out the latest version of Go as an example.</p>
</div>

<p>When you have this awareness, you can take measures to help Copilot understand updates by switching to a different model or via the method we discuss in the next section.</p>

<div data-type="warning" epub:type="warning">
<h1>Premium Requests</h1>

<p><a contenteditable="false" data-primary="premium requests" data-type="indexterm" id="id816"/>While switching models may be a good option to address certain issues, remember that use of some advanced models count as <em>premium requests. </em>Using these models can use up quotas faster and incur additional costs on some plans.</p>
</div>

<p>What if you can’t avoid the AI producing deprecated or incomplete code because you’re restricted to a particular model or because the models that you use do not have training on a newer feature? You can use one other approach to get Copilot to generate the kind of code you want with the context you need<a contenteditable="false" data-primary="" data-startref="xi_modelsquerying72834" data-type="indexterm" id="id817"/><a contenteditable="false" data-primary="" data-startref="xi_queriesandqueryingmodels72834" data-type="indexterm" id="id818"/>.</p>
</div></section>

<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Guiding Copilot by Example"><div class="sect2" id="id86">
<h2 class="less_space">Guiding Copilot by Example</h2>

<p><a contenteditable="false" data-primary="GitHub Copilot" data-secondary="guiding by example" data-type="indexterm" id="xi_GitHubCopilotguidingbyexample73304"/>Looking at our deprecation example again, Copilot created a function to seed a random number generator by using a deprecated method (<a data-type="xref" href="#created-function-usin">Figure 7-15</a>).</p>

<figure><div id="created-function-usin" class="figure"><img alt="" src="assets/lghc_0715.png" width="817" height="357"/>
<h6><span class="label">Figure 7-15. </span>A function created using a deprecated method</h6>
</div></figure>

<p>If we want to get Copilot to produce code that is using the replacement for the deprecation, we can teach it by example. We can take the updated code snippet from the <a href="https://oreil.ly/4vDIl">Go documentation</a> and temporarily paste it into the same file in our workspace. (Or we could paste it into a prompt if we’re using the chat <span class="keep-together">interface</span>.)</p>

<p>After that, if we repeat our prompt, Copilot will generate updated code that is based on the code snippet we included (<a data-type="xref" href="#updated-code-generate">Figure 7-16</a>).</p>

<figure><div id="updated-code-generate" class="figure"><img alt="" src="assets/lghc_0716.png" width="1001" height="423"/>
<h6><span class="label">Figure 7-16. </span>Updated code generated with the code example in place</h6>
</div></figure>

<p>Obviously, this is a very simple example. In this case, Copilot essentially copied the code verbatim. But, regardless, the end result was still what we needed. After getting the desired result, the example code can then be removed.</p>

<div data-type="note" epub:type="note">
<h1>Making Updated Code Available</h1>

<p>In some cases, for Copilot to draw on separate content, it may be enough to put the content in another file that is opened in your IDE. In other cases, it may be necessary to put the content directly in the file that you’re working with. If that is the case, you can add in the content and then remove it when the code generation is <span class="keep-together">correct</span>.</p>
</div>

<p>The examples in this section have focused on ways to deal with questions and challenges with content already generated by Copilot. However, you can also employ similar strategies before Copilot generates results to get better results up front. We’ll look more at that aspect in the last section of this chapter<a contenteditable="false" data-primary="" data-startref="xi_userbasedcopingstrategies72024" data-type="indexterm" id="id819"/><a contenteditable="false" data-primary="" data-startref="xi_copingstrategiesuserbased72024" data-type="indexterm" id="id820"/><a contenteditable="false" data-primary="" data-startref="xi_GitHubCopilotguidingbyexample73304" data-type="indexterm" id="id821"/>.</p>
</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Adding Context to Make Code More Relevant"><div class="sect1" id="addingContextCh7">
<h1>Adding Context to Make Code More Relevant</h1>

<p><a contenteditable="false" data-primary="context" data-secondary="adding to make code relevant" data-type="indexterm" id="xi_contextaddingtomakecoderelevant73594"/>In addition to compensating for deprecations and missing new features, additional content that you supply to Copilot can help in another way. When you provide more detailed context in terms of definitions or coding examples that are relevant to your project, Copilot can draw on those to generate more thorough, richer, and relevant coding suggestions.</p>

<p>As an example, let’s look at creating some SQL content with Copilot. Revisiting a previous example, suppose we are working on implementing a system to manage university courses, students, instructors, registrations, etc. Without any other context, let’s ask Copilot to create a general <code>SELECT<a contenteditable="false" data-primary="SELECT statement" data-type="indexterm" id="id822"/></code> statement to get students enrolled in a course. We can do this as simply as adding an SQL comment like this in the editor: <code translate="no"><strong>-- define a select statement to get all the students enrolled in a course</strong></code>.</p>

<p>Given this generic directive and no other context, Copilot will produce a reasonable, generalized query like the following: </p>

<pre translate="no">
SELECT * FROM students WHERE course_id = 1;</pre>

<p>There is nothing wrong with this query. It is perfectly valid given the limited context we’ve provided for Copilot. Assuming that we have the corresponding table and field names in place in our schema, this would work fine.</p>

<p>However, suppose we already have a more extensive set of databases in place for our system (with appropriate tables, data, etc.). We would really like Copilot to generate suggestions that are relevant to those and use the elements that we already have defined. How can we accomplish this?</p>

<p>The mechanism for doing this is similar to what we did for the deprecation example in the last section, adding more context for Copilot to pick up in the workspace. In this case, while we don’t have a way for Copilot to dynamically examine our data stores, indices, or stored procedures, we can provide a static representation of them via the schema definitions. We can use either an original SQL definition if we have one or a dump of the schemas from the existing content. A portion of a file that we might use is shown in <a data-type="xref" href="#example-extended-sche">Figure 7-17</a>.</p>

<figure><div id="example-extended-sche" class="figure"><img alt="" src="assets/lghc_0717.png" width="1319" height="905"/>
<h6><span class="label">Figure 7-17. </span>Example extended schema definitions to use for context</h6>
</div></figure>

<p>This file has specific tables defined for the domains we’re working with, along with relevant fields, keys, etc.</p>

<p>Let’s add this file to our workspace so that it is part of our project and open it in the editor. Copilot now has this additional context available to draw from. We can go back and provide the same directive in comment form as before: <code translate="no">-- define a select statement to get all the students enrolled in a course</code>. This time, Copilot produces the following response:</p>

<pre data-type="programlisting" translate="no">
SELECT students.first_name, students.last_name, students.email,
 students.phone, students.city, students.state, students.zip_code
FROM courses.students
JOIN courses.registrations
ON students.student_id = registrations.student_id
JOIN courses.registration_items
ON registrations.registration_id = 
registration_items.registration_id
WHERE registration_items.course_id = 1;
</pre>

<p>Notice that now, with the additional context from the other file available in the workspace, Copilot produced a much richer, more detailed, and more relevant query. It also used specific table and field names provided in the other file.</p>

<p class="pagebreak-before">The key here is that Copilot prioritizes the context you’re using in the IDE for deciding how to generate code. Leveraging this kind of approach is a useful and simple strategy to getting much more usable and pertinent coding suggestions and answers from Copilot than would be possible if you simply relied on the model’s training data.</p>

<div data-type="note" epub:type="note">
<h1>Adding the Additional File as Context</h1>

<p><a contenteditable="false" data-primary="context" data-secondary="adding additional files as" data-type="indexterm" id="id823"/>In the SQL example shown here, we added the file as an additional one in the workspace and opened it in the IDE. We did not take the contents of the file and paste it into the active file as we did for the deprecation example. While we could have done that, it was not necessary here.</p>

<p>Depending on the use case, you may find that one or the other of these two approaches (inserting content directly into the active file or opening the content as a <em>peer<a contenteditable="false" data-primary="peer file" data-type="indexterm" id="id824"/></em> file) works better for you. You can always start by opening the content as a peer file and trying that. If you don’t get the expected results, then you can add the content directly into the active file.</p>

<p>Another option is to paste relevant examples directly into Copilot Chat for it to work from—if the scope of the example is a good fit for that.</p>

<p>If you are adding content into the IDE either as a new file or an addition to an existing file, be sure to save the changes before querying or prompting Copilot. Copilot relies on persisted (saved) content in the workspace to draw on for context.</p>
</div>

<p>The point is that adding richer context up front for Copilot can produce improved results in the form of suggestions or completions. In some cases, it may be more time-consuming to generate files like the schema one we used here, but the trade-off is less time and effort remediating Copilot’s suggestions to get to the detail you need.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id825">
<h1>Miscellaneous Tips for Steering Copilot</h1>

<p>Here are a few other tips on ways to help steer Copilot if you encounter content that isn’t what you expected and other strategies fail<a contenteditable="false" data-primary="" data-startref="xi_contextaddingtomakecoderelevant73594" data-type="indexterm" id="id826"/>:</p>

<ul>
	<li>Switching from the inline suggestions to prompting in chat (or vice versa) if you’re not getting good results</li>
	<li>If the code that Copilot generates keeps coming up as incorrect, you can try writing part of it (a stub) and then letting Copilot generate a completion to see if you get a better end result</li>
	<li>Adding a more directive comment with clear intent to steer the generation</li>
	<li>Isolating the code temporarily in its own window to remove other context that may be interfering</li>
	<li>Prompting Copilot to explain rather than having it generate</li>
	<li>Changing the filename or even file type to update the context</li>
</ul>
</div></aside>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="id88">
<h1>Conclusion</h1>

<p>In this chapter, we’ve covered the various aspects about how Copilot determines context for its code suggestions and responses, why those may not be up-to-date or accurate, and some ways you can help deal with those situations.</p>

<p>Copilot’s core context comes from the training in the underlying models it uses. Since these models are only as current as the point in time when they were last trained, they are missing any updates or changes in the languages and frameworks that were not part of their training. In addition, the content they were trained on will be using older versions of tooling. So, suggestions or responses generated from those can be substantially out of date. This is a key aspect to be aware of and watch out for. One possible quick fix for this is to switch to an updated model if one is available.</p>

<p>Fortunately, Copilot also pulls in context from the available content in the editor and workspace you’re using. This context is prioritized over the training data since it reflects what you are doing and using currently. Because of this approach, you can provide Copilot with more up-to-date and more relevant context to draw on. You do this by including your own relevant content in the IDE and workspace. This can be done in most cases by having a file with relevant information open in the IDE. For more explicit direction, the relevant information can be added to the current file for as long as needed for Copilot to draw from.</p>

<p>GitHub Copilot also includes ways to focus the AI on specific content you have. Chat participants can define overall context areas for Copilot to answer questions and respond about. The current set of participants include ones for VS Code, the active terminal, and your workspace.</p>

<p>At a more detailed level, you can steer Copilot’s context to particular items within your workspace via chat variables. Examples include the current selection in the editor, the content open in the editor, the last command in the terminal, and more.</p>

<p>In this chapter, you learned how to supply more context for GitHub Copilot when you’re working with SQL. This is an example of a nontypical language/framework that you can also use Copilot for. The next chapter explores more examples of how to use Copilot for such nontypical areas<a contenteditable="false" data-primary="" data-startref="xi_GitHubCopilotrelevanceof744" data-type="indexterm" id="id827"/><a contenteditable="false" data-primary="" data-startref="xi_GitHubCopilottimelinessof744" data-type="indexterm" id="id828"/><a contenteditable="false" data-primary="" data-startref="xi_relevanceofGithubCopilot744" data-type="indexterm" id="id829"/><a contenteditable="false" data-primary="" data-startref="xi_timelinessofGithubCopilot744" data-type="indexterm" id="id830"/>.</p>
</div></section>
</div></section></div></div></body></html>