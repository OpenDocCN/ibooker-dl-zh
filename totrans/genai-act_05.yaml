- en: 5 What else can AI generate?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 AI还能生成什么？
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Using generative AI for code creation and code-related tasks
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI进行代码创建和相关任务
- en: Tools that allow code generation and how to use them
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许代码生成的工具及其使用方法
- en: Best code generation practices
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳代码生成实践
- en: Generating video and related tools
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成视频和相关工具
- en: Generating audio, music, and related tools
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成音频、音乐和相关工具
- en: Code that writes itself with little prompting and without much input seems magical,
    resembling a holy grail, at least to those working in computing. Given the advancements
    in artificial intelligence (AI) with generative AI, this endeavor seems possible
    today. We have seen some amazing and interesting things AI can generate—from language
    to images to holding an ongoing back-and-forth multiturn conversation—and many
    of them have strong use cases in enterprises. This chapter outlines the remaining
    things we can generate using AI.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎不需要提示和输入就能自动编写的代码看起来很神奇，至少对那些从事计算工作的人来说如此，它类似于圣杯。鉴于人工智能（AI）和生成式AI的进步，这项努力在今天似乎成为可能。我们已经看到了一些令人惊叹和有趣的事情，AI可以生成从语言到图像，甚至进行多轮对话，并且许多这些都拥有强大的企业用例。本章概述了我们还可以使用AI生成的事物。
- en: We will first talk about code generation, what it means, how one should go about
    it, and the tools enterprises use. For example, Andrej Karpathy, one of the OpenAI
    cofounders, who used to lead Tesla’s AI and Vision team, recently said that GitHub
    Copilot helps him write approximately 80% of his code, which is a huge boost in
    productivity. Then, we will cover a few very early generations and explore application
    in videos and music. Let’s see how code generation works.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先讨论代码生成，它的含义，如何进行，以及企业使用的工具。例如，OpenAI的联合创始人之一安德烈·卡帕西，曾领导特斯拉的AI和视觉团队，最近表示GitHub
    Copilot帮助他编写了大约80%的代码，这极大地提高了生产力。然后，我们将探讨一些非常早期的生成式，并探索其在视频和音乐中的应用。让我们看看代码生成是如何工作的。
- en: 5.1 Code generation
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 代码生成
- en: 'Generative AI is not just about completions, chats, or generating images. It’s
    a technology that can significantly enhance developers’ productivity and improve
    software development processes in enterprises. One of its most intriguing aspects
    is the ability to generate code and aid in code understanding and documentation.
    From a development lifecycle perspective, the term “code generation” can be misleading,
    as it encompasses much more than code generation itself. It spans various aspects
    of software development. Here are a few examples of how enterprises employ code
    generation:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI不仅仅是关于完成、聊天或生成图像。它是一种可以显著提高开发者生产力并改善企业软件开发流程的技术。其最引人入胜的方面之一是生成代码并帮助理解代码和文档。从开发生命周期角度来看，“代码生成”这个术语可能会误导，因为它不仅包括代码生成本身，还涵盖了软件开发的各种方面。以下是企业如何使用代码生成的一些示例：
- en: '*Code generation*—Augments development by generating code for a given prompt.
    This isn’t complete code for whatever is being built but code at the function
    level.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*代码生成*—通过为给定提示生成代码来增强开发。这不是正在构建的任何内容的完整代码，而是函数级别的代码。'
- en: '*Productivity improvements*—Tools based on generative AI can help improve developers’
    productivity, especially when using new libraries and software develop-ment kits
    (SDKs) or programming languages that might be new for a developer. We can also
    improve the speed of implementation of much of the scaffolding (such as AI wrappers,
    database queries, etc.) that many enterprise applications need to implement, such
    as access control, encryption, and security, to name a few.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提高生产力*—基于生成式AI的工具可以帮助提高开发者的生产力，尤其是在使用对开发者可能来说是新的库和软件开发套件（SDKs）或编程语言时。我们还可以提高许多企业应用需要实现的大量框架（如AI包装器、数据库查询等）的实施速度，例如访问控制、加密和安全等。'
- en: '*Onboarding new employees*—For enterprises, it is quite common to have internal
    proprietary development standards, internal libraries, and SDKs that encapsulate
    a lot of domain and institutional knowledge and IP. Generative AI tools can help
    new full-time employees (FTEs) get ramped up and trained quickly using these SDKs
    and libraries. New FTEs can also serve as a model to explain snippets, helping
    developers learn quickly.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*新员工入职*—对于企业来说，拥有内部专有开发标准、内部库和SDK是很常见的，这些SDK和库封装了大量领域和机构知识以及知识产权。生成式AI工具可以帮助新全职员工（FTEs）快速熟悉并使用这些SDK和库进行培训。新FTEs还可以作为模型来解释代码片段，帮助开发者快速学习。'
- en: '*Automation*—Many development tasks are repetitive, and it is common for many
    developers to skip them or take shortcuts, which can cause problems down the road.
    Generative AI can help automate repetitive tasks such as code reviews, testing,
    documentation, design iterations, UI mockups, and so forth.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动化*——许多开发任务是重复性的，许多开发者通常会跳过它们或走捷径，这可能会在将来造成问题。生成式AI可以帮助自动化诸如代码审查、测试、文档、设计迭代、UI原型等重复性任务。'
- en: '*Fostering creativity*—Generative AI tools can help developers see different
    approaches and ideas when coding or rapidly prototyping, encouraging them to explore
    newer techniques that might be better and help teach.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*培养创造力*——生成式AI工具可以帮助开发者看到在编码或快速原型设计时不同的方法和想法，鼓励他们探索可能更好并有助于教学的新的技术。'
- en: Before we get into the details, we will start with code generation examples.
    Say we want to write a function to calculate its time complexity. Time complexity
    measures the length (i.e., the time) a function will take to execute. It is often
    expressed using Big O notations—constant, linear, quadratic, and exponential time.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入细节之前，我们将从代码生成示例开始。假设我们想要编写一个函数来计算其时间复杂度。时间复杂度衡量函数执行所需的时间长度（即时间）。它通常使用大O符号表示——常数、线性、二次和指数时间。
- en: Note  For brevity, we won’t show the full test code generation here; this can
    be found in the books accompanying the GitHub repository at [https://bit.ly/GenAIBook](https://bit.ly/GenAIBook).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：为了简洁，我们在这里不会展示完整的测试代码生成；这可以在GitHub仓库附带的书籍中找到，[https://bit.ly/GenAIBook](https://bit.ly/GenAIBook)。
- en: Let’s start with a simple toy example using GitHub Copilot in our IDE. A comment
    is the prompt, and the model completes the code generation, as shown in figure
    5.1\. Regarding the developers’ experience, this might seem like a fancier version
    of autocomplete, but it is much more than that. We can think of the code generation
    as the completion API we saw earlier, with the difference being that what will
    be generated will be code.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从使用我们IDE中的GitHub Copilot的一个简单玩具示例开始。注释是提示，模型完成代码生成，如图5.1所示。关于开发者的体验，这可能会看起来像是自动完成的一个更花哨的版本，但它远不止于此。我们可以将代码生成看作是我们之前看到的完成API，区别在于将要生成的是代码。
- en: '![figure](../Images/CH05_F01_Bahree.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH05_F01_Bahree.png)'
- en: Figure 5.1 Code generation to calculate time complexity
  id: totrans-20
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.1 计算时间复杂度的代码生成
- en: The first suggestion, in the grey text (also called ghost text), seems good;
    if we want, we can get up to 10 suggestions and find a better one. Figure 5.2
    shows a snippet of these alternate generations.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在灰色文本（也称为幽灵文本）中的第一个建议看起来不错；如果我们愿意，我们可以获得多达10个建议并找到一个更好的。图5.2显示了这些替代生成的一个片段。
- en: '![figure](../Images/CH05_F02_Bahree.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH05_F02_Bahree.png)'
- en: Figure 5.2 GitHub Copilot code completion suggestions
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.2 GitHub Copilot代码完成建议
- en: In this instance, the last suggestion (number 10) seems better and is what we
    will use, as shown in figure 5.3.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，最后一个建议（第10个）看起来更好，这就是我们将要使用的，如图5.3所示。
- en: '![figure](../Images/CH05_F03_Bahree.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH05_F03_Bahree.png)'
- en: Figure 5.3 AI-generated code to calculate the time complexity of a function
  id: totrans-26
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.3 AI生成的计算函数时间复杂性的代码
- en: 5.1.1 Can I trust the code?
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 我能信任这段代码吗？
- en: In the context of code generation, one of the areas that many enterprises are
    considering is how to trust the generated code. Let’s take the example of generating
    complex code, such as implementing OAuth2 for a web application, as shown in figure
    5.4\. In general, code-generation tools are becoming increasingly reliable and
    accurate. However, it is still important to be aware of the code limitations;
    whether one can trust generated code depends on several factors, including
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码生成的背景下，许多企业正在考虑的一个领域是如何信任生成的代码。让我们以生成复杂代码的例子为例，例如为Web应用实现OAuth2，如图5.4所示。一般来说，代码生成工具正变得越来越可靠和准确。然而，仍然重要的是要意识到代码的限制；是否可以信任生成的代码取决于几个因素，包括
- en: '![figure](../Images/CH05_F04_Bahree.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH05_F04_Bahree.png)'
- en: Figure 5.4 Code generation showing OAuth2 implementation
  id: totrans-30
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.4 显示OAuth2实现的代码生成
- en: The quality of the tool and underlying model pinning that code generation tool.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具的质量和支撑该代码生成工具的底层模型。
- en: The complexity of the task the code is being generated for; some tools are better
    suited for well-defined tasks than complex logic and reasoning tasks that can
    result in error.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码生成所针对的任务的复杂性；有些工具更适合定义明确的任务，而不是可能导致错误的复杂逻辑和推理任务。
- en: When using AI-generated code, trust and review are paramount. The code and associated
    tools should always be used with other development tools and processes, such as
    code reviews and unit tests, which ensure that the generated code meets the required
    standards and is free from errors or vulnerabilities.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用AI生成的代码时，信任和审查至关重要。代码和相关工具应始终与其他开发工具和流程一起使用，例如代码审查和单元测试，以确保生成的代码符合所需标准且无错误或漏洞。
- en: It is important to note that GitHub Copilot does not guarantee that the code
    it generates is correct, bug-free, or secure. The developer is still responsible
    for reviewing, testing, and verifying the code before using it.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，GitHub Copilot不能保证它生成的代码是正确的、无错误的或安全的。开发者在使用代码之前仍需负责审查、测试和验证代码。
- en: GitHub Copilot does provide some features to help developers ensure the quality
    of the code, such as code review, testing, and feedback. In addition, it has several
    guardrails in place to help prevent it from generating incorrect or harmful code.
    For example, GitHub Copilot has filters that block offensive words and code that
    is likely biased or discriminatory.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub Copilot确实提供了一些功能来帮助开发者确保代码质量，例如代码审查、测试和反馈。此外，它还设置了几个安全措施来帮助防止生成错误或有害的代码。例如，GitHub
    Copilot有过滤器可以阻止冒犯性词汇和可能存在偏见或歧视的代码。
- en: In addition, GitHub Copilot also performs several safety checks before generating
    code, such as for potential syntax errors and security vulnerabilities. GitHub
    Copilot’s AI-based vulnerability prevention system is a feature that aims to make
    the code suggestions more secure and help developers avoid common security flaws
    in their code. It works using a machine learning model that can detect insecure
    coding patterns in real time and block them from being suggested. It also generates
    a new suggestion that does not contain the vulnerability. Some of the vulnerabilities
    that the system can protect against are
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，GitHub Copilot在生成代码之前也会执行几个安全检查，例如潜在的语法错误和安全漏洞。GitHub Copilot基于AI的漏洞预防系统是一个旨在使代码建议更加安全并帮助开发者避免代码中的常见安全缺陷的功能。它通过一个能够实时检测不安全编码模式并阻止其被建议的机器学习模型来工作。它还会生成一个不包含漏洞的新建议。该系统可以保护的一些漏洞包括
- en: '*Hardcoded credentials*—This is when sensitive information such as passwords,
    API keys, or tokens is embedded in the source code, meaning attackers can access
    it easily. The system can identify hardcoded credentials and replace them with
    placeholders or environment variables.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*硬编码凭证*——这是指敏感信息，如密码、API密钥或令牌被嵌入到源代码中，这意味着攻击者可以轻易访问它。系统可以识别硬编码凭证并将它们替换为占位符或环境变量。'
- en: '*SQL injection*—This is when user input is directly inserted into a SQL query,
    allowing attackers to execute malicious commands on the database. The system can
    identify SQL injection vulnerabilities and suggest using parameterized queries
    or prepared statements instead.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*SQL注入*——这是指用户输入被直接插入到SQL查询中，允许攻击者在数据库上执行恶意命令。系统可以识别SQL注入漏洞并建议使用参数化查询或预编译语句代替。'
- en: '*Path injection*—This occurs when user input is used to construct a file path,
    allowing attackers to access or modify files outside the intended scope. The system
    can identify path injection vulnerabilities and suggest using sanitization functions
    or validation checks before using the input.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*路径注入*——这发生在用户输入被用来构造文件路径时，允许攻击者访问或修改预期范围之外的文件。系统可以识别路径注入漏洞并建议在使用输入之前使用净化函数或验证检查。'
- en: Code generation tools can be powerful allies for enterprise developers but require
    careful and responsible use. As outlined by the National Institute of Standards
    and Technology, one of the best ways to secure code is to use a secure software
    development lifecycle.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 代码生成工具可以成为企业开发者的强大盟友，但需要谨慎和负责任地使用。根据国家标准与技术研究院的概述，确保代码的最佳方式之一是使用安全的软件开发生命周期。
- en: Now that we have seen a simple example of what is possible, let’s see how we
    can do this. The next section will explore common tools such as Tabnine, Code
    Llama, and Amazon’s CodeWhisperer. However, in this section, we will talk about
    GitHub Copilot.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了一个简单的例子，展示了可能实现的内容，接下来我们将探讨一些常见的工具，如Tabnine、Code Llama和亚马逊的CodeWhisperer。然而，在本节中，我们将讨论GitHub
    Copilot。
- en: 5.1.2 GitHub Copilot
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2 GitHub Copilot
- en: A few tools are now available for code generation. Most enterprises use GitHub
    Copilot, one of the first code-generation tools on the market. GitHub Copilot
    is a cloud-based generative AI tool that helps developers by generating code based
    on natural language prompts. It uses models from OpenAI, has been trained on billions
    of lines of code, and is positioned as our new AI pair programmer—one that helps
    us write code better, solve problems, understand new APIs, and write tests without
    trawling through a ton of information and sites searching for answers. The high-level
    flow is shown in figure 5.5.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 目前已有一些工具可用于代码生成。大多数企业使用GitHub Copilot，这是市场上最早的代码生成工具之一。GitHub Copilot是一款基于云的生成式AI工具，通过根据自然语言提示生成代码来帮助开发者。它使用OpenAI的模型，经过数十亿行代码的训练，定位为我们新的AI代码伙伴——帮助我们更好地编写代码、解决问题、理解新的API以及编写测试，无需在大量信息和网站上搜索答案。高级流程如图5.5所示。
- en: '![figure](../Images/CH05_F05_Bahree.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_F05_Bahree.png)'
- en: Figure 5.5 GitHub Copilot high-level flow using Visual Studio Code
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.5 使用Visual Studio Code的GitHub Copilot高级流程
- en: GitHub Copilot runs as an add-in and supports many of the leading programming
    languages available for some of the leading IDEs (e.g., Visual Studio, Visual
    Studio Code, Neovim, and JetBrains). It supports about a dozen primary programming
    languages, such as C, C++, Java, C#, Python, Go, Ruby, and many more, as well
    as secondary and relatively less-supported languages (such as COBOL). All the
    languages that GitHub Copilot supports are listed at [https://docs.github.com/](https://docs.github.com/).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub Copilot作为插件运行，并支持许多领先的IDE（例如Visual Studio、Visual Studio Code、Neovim和JetBrains）中的一些主要编程语言。它支持大约十种主要编程语言，如C、C++、Java、C#、Python、Go、Ruby等，以及次要和相对较少支持的编程语言（如COBOL）。GitHub
    Copilot支持的所有语言均列在[https://docs.github.com/](https://docs.github.com/)。
- en: As we have seen, the current version of GitHub Copilot takes a prompt via a
    comment, considers the context of the file a developer works on in the IDE, and
    then helps make the suggestions in the code. The results for developers across
    the board have been amazing. According to research published by GitHub, 96% of
    developers are faster on repetitive tasks, 88% feel more productive, and nearly
    75% focus on more satisfying things. Code generation is not about creating complete
    solutions or end-to-end code but rather about creating parts of code that can
    help with a specific function or some core logic within a function.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，GitHub Copilot的当前版本通过注释接收提示，考虑开发者在IDE中工作的文件上下文，然后帮助在代码中提出建议。对于所有开发者的结果都令人惊叹。根据GitHub发布的研究，96%的开发者在重复性任务上更快，88%感觉更有效率，近75%专注于更令人满意的事情。代码生成不仅仅是创建完整的解决方案或端到端代码，而是创建可以帮助特定功能或函数中某些核心逻辑的代码部分。
- en: Copilot requires a subscription and comes in two versions, one targeting individuals
    and the other targeting enterprises. The underlying model powering both is the
    same, the main differences being that the enterprise version has additional controls
    for managing telemetry and enterprises can enforce organization-wide policies.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Copilot需要订阅，并提供两种版本，一种针对个人用户，另一种针对企业用户。两者背后的模型相同，主要区别在于企业版具有额外的控制功能，用于管理遥测数据，并且企业可以强制执行组织范围内的政策。
- en: 'When considering privacy and data protection, GitHub Copilot (the business
    edition) collects information in three areas, as outlined in the following list.
    These help with the overall service health, experience-latency, and feature engagement
    and also help fine-tune and improve the algorithms for ranking and sorting completions.
    In addition, they can aid in detecting abuse of the service and policy violations:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑隐私和数据保护时，GitHub Copilot（商业版）在以下三个领域收集信息，具体如下。这些信息有助于整体服务健康、体验延迟和功能参与，并有助于微调和改进排序和排序的算法。此外，它们还可以帮助检测服务滥用和政策违规：
- en: '*End-user engagement data*—GitHub Copilot collects the end-user’s interaction
    with the IDE when using Copilot. This includes usage and error details, as well
    as data on actions taken by the user, such as which of the generated completions
    was accepted. Some personal data might be included but is not tied directly to
    the user.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*终端用户参与数据*——GitHub Copilot收集终端用户在使用Copilot时与IDE的交互。这包括使用情况和错误详情，以及用户采取的行动的数据，例如哪些生成的补全被接受。可能包含一些个人数据，但并不直接与用户相关。'
- en: '*Prompts*—For enterprise users, the prompts are ephemeral, employed only when
    using the service, and not retained. For individual users, the prompts persist,
    but the user has the option of deactivating them.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*提示*——对于企业用户，提示是短暂的，仅在使用服务时使用，并且不会被保留。对于个人用户，提示会保留，但用户可以选择禁用它们。'
- en: '*Completions (i.e., suggestions)*—The completions, similar to the prompts,
    are ephemeral, transmitted back to the Copilot extension running in the IDE, and
    are not persisted.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*完成（即建议）*——与提示类似，完成是短暂的，被传输回在IDE中运行的Copilot扩展，并且不会被持久化。'
- en: Copilot uses more than just the prompt when trying to create suggestions. In
    addition to the prompt, it also factors in the edited file and the other tabs
    and files in the solutions open for context. Furthermore, it combines all of that
    as grounding and context information to allow for more meaningful and better generations.
    And this generation goes beyond the code, stylistic patterns, and syntactic sugar.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Copilot在尝试创建建议时不仅仅使用提示。除了提示之外，它还会考虑编辑的文件以及为上下文而打开的其他选项卡和文件。此外，它将所有这些信息作为基础和上下文信息结合起来，以便进行更有意义和更好的生成。这种生成不仅限于代码、风格模式和语法糖。
- en: Let us use a simple example. Say we want to generate a function that we will
    employ to generate an image using Stability AI, which we did in the previous chapter.
    We use the following prompt.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个简单的例子来说明。假设我们想要生成一个函数，我们将使用这个函数来使用稳定性AI生成图像，就像我们在上一章中做的那样。我们使用以下提示。
- en: '**![image](../Images/Prompt.png)**Write a Python function that takes a prompt
    and uses stability AI to generate an image and save it to a file.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Prompt.png**) 编写一个Python函数，该函数接受一个提示并使用稳定性AI生成图像并将其保存到文件中。'
- en: When we have an empty solution with just a few lines of code to get this started,
    we get the code shown in figure 5.6 with the `generate()` function generated by
    GitHub Copilot. As we can see, this is rather simple and goes through the mechanics
    of first encoding the prompt to a `base64` format. It calls the completion API,
    extracts the image from the API response, decodes it from `base64`, and then finally
    saves it to a file using a date–time stamp as the file name. This was discussed
    in detail in the previous chapter, and there is nothing wrong with the code. It
    is a pretty vanilla implementation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有一个仅包含几行代码的空解决方案来开始时，我们得到了图5.6中由GitHub Copilot生成的`generate()`函数。正如我们所见，这相当简单，它首先将提示编码为`base64`格式。它调用完成API，从API响应中提取图像，将其从`base64`解码，然后最终使用日期-时间戳作为文件名将其保存到文件中。这在上一章中已有详细讨论，代码没有问题。这是一个相当简单的实现。
- en: '![figure](../Images/CH05_F06_Bahree.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F06_Bahree.png)'
- en: Figure 5.6 GitHub Copilot code generation
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.6 GitHub Copilot代码生成
- en: However, we must follow programming standards, architecture patterns, and methodologies.
    Otherwise, the code shown in the previous example would not work and would require
    more manual effort. So how can we address this?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们必须遵循编程标准、架构模式和开发方法。否则，前一个示例中显示的代码将无法工作，并且需要更多的手动工作。那么我们该如何解决这个问题呢？
- en: Let’s generate another function using the same prompt. This time, we open a
    file in our existing solution for image generation that we used in the previous
    chapter. Listing 5.1 shows the generated code. This code seems quite familiar,
    as it closely follows our syntax and patterns for generating images from the previous
    chapter.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用相同的提示生成另一个函数。这次，我们打开我们在上一章中用于图像生成的现有解决方案中的一个文件。列表5.1显示了生成的代码。这段代码看起来相当熟悉，因为它与我们上一章中生成图像的语法和模式非常相似。
- en: The interesting thing in this example is how GitHub Copilot generated the helper
    functions to check for paths, clean up filenames, and so forth, even when we did
    not explicitly ask for it. This pattern was common across a few files in the image
    generation solution (from the last chapter), which was picked up as context. The
    updated code saves the prompt as part of the filename, not just a date–time stamp.
    Again, this was not explicitly asked, and while it might seem like syntactic sugar,
    patterns and architecture requirements such as these make the codebase maintainable,
    robust, and familiar in an enterprise setting.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，有趣的是GitHub Copilot如何生成了检查路径、清理文件名等辅助函数，即使我们没有明确要求。这种模式在图像生成解决方案的几个文件中很常见（来自上一章），并被作为上下文捕捉。更新后的代码将提示作为文件名的一部分保存，而不仅仅是日期-时间戳。同样，这并不是明确要求的，尽管它可能看起来像是语法糖，但这样的模式和架构要求使得代码库在企业环境中易于维护、健壮且熟悉。
- en: Listing 5.1 GitHub Copilot generation in an existing solution
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.1 GitHub Copilot在现有解决方案中的生成
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 5.1.3 How Copilot works
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.3 Copilot的工作原理
- en: When GitHub Copilot was first released, GitHub worked closely with OpenAI to
    create a special version of GPT3 called Codex. This version was trained on both
    natural language and billions of lines of code. Codex supports multiple programming
    languages and can be used for multiple code-related tasks. Today, Codex is deprecated,
    as the same learnings have been incorporated into the mainline GPT models.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当GitHub Copilot首次发布时，GitHub与OpenAI紧密合作，创建了一个名为Codex的特殊版本的GPT3。这个版本在自然语言和数十亿行代码上进行了训练。Codex支持多种编程语言，可用于多种与代码相关的任务。如今，Codex已被弃用，因为同样的学习成果已经被整合到主线GPT模型中。
- en: Copilot is building a separate prompt all the time in the background, which
    is one reason we see completions not only when prompted but throughout when writing
    code—starting or in the middle of something else. Starting with a prompt line
    and the corresponding code file using Codex was just the beginning. Copilot now
    looks at several things when suggesting generations. The prompt library is where
    algorithms take into account the broader context of what a developer is doing
    and create the prompt used by the model. In addition to the code file and the
    prompts we enter, this also considers the other open tabs and the broader solution,
    as shown in our earlier demo. Figure 5.7 illustrates this high-level flow and
    the life cycle.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Copilot一直在后台构建一个单独的提示，这也是我们为什么不仅在提示时看到补全，在整个编写代码的过程中也能看到补全的原因之一——从提示行和相应的代码文件使用Codex开始，这只是个开始。现在，Copilot在建议生成时会考虑几个方面。提示库是算法考虑开发者所做事情更广泛上下文的地方，并创建模型使用的提示。除了代码文件和输入的提示外，这还考虑了其他打开的标签页和更广泛的解决方案，如我们之前的演示所示。图5.7展示了这一高级流程和生命周期。
- en: One behavior of particular interest is a feature called fill-in-the-middle (or
    FIM). As the name suggests, the code is not generated at the end of a file, but
    in the middle. Before FIM was implemented, the code after the cursor’s current
    position was ignored; now it helps fill in the missing code, considering the code
    before and after the insertion point, taken in the full context.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一个特别有趣的行为是被称为“填充中间”（或FIM）的功能。正如其名所示，代码不是在文件末尾生成，而是在中间生成。在FIM实现之前，光标当前位置之后的代码被忽略；现在，它有助于填补缺失的代码，考虑到插入点之前和之后的代码，在完整上下文中进行。
- en: '![figure](../Images/CH05_F07_Bahree.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F07_Bahree.png)'
- en: Figure 5.7 Copilot completion lifecycle
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.7 Copilot补全生命周期
- en: The newer version, Copilot Chat, uses a chat-like interface similar to ChatGPT.
    This chat-like feature offers a much richer experience and modality from a developer’s
    perspective and allows us to take in more than just the prompt or the code. It
    helps us with much richer context (of the code and errors) and lets us spot any
    possible problems. This is also extensible to other aspects that developers use
    daily—from helping understand legacy code to unit test generation. The original
    version of Copilot used Codex, a fine-tuned version of GPT-3\. Codex is now retired,
    and the newer versions of Copilot Chat use newer models. Let’s examine some of
    these areas in more depth.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 新版本，Copilot Chat，使用类似于ChatGPT的聊天界面。这种聊天功能从开发者的角度来看提供了更加丰富和多样的体验，并使我们能够接收不仅仅是提示或代码。它帮助我们获得更丰富的上下文（代码和错误），并让我们发现任何可能的问题。这一特性也可以扩展到开发者日常使用的其他方面——从帮助理解遗留代码到单元测试生成。Copilot的原始版本使用的是Codex，这是GPT-3的一个微调版本。现在，Codex已经退役，Copilot
    Chat的新版本使用的是更新的模型。让我们更深入地考察这些领域。
- en: 5.2 Additional code-related tasks
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 其他与代码相关的任务
- en: In addition to code generation, there are other use cases that can be utilized
    in the context of code and improving developer productivity. Some of these are
    the generation of other aspects, such as unit tests or documentation. Let’s start
    with one of the features called code explanation.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 除了代码生成外，还有一些其他可以在代码和提升开发者生产力方面使用的用例。其中一些是生成其他方面，如单元测试或文档。让我们从一个被称为代码解释的功能开始。
- en: 5.2.1 Code explanation
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 代码解释
- en: One of the powerful features of GitHub Copilot Chat is that it offers a more
    expressive medium to interact with the code. One example is being able to chat
    and ask for an explanation of the selected code in the IDE.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub Copilot Chat的一个强大功能是它提供了一个更丰富的媒介来与代码交互。一个例子就是能够在IDE中聊天并请求对所选代码的解释。
- en: Figure 5.8 illustrates an example of code explanation where we use one of our
    earlier completions and naturally interact with and use the AI to help us generate
    an explanation. The screenshot doesn’t show it, but GitHub Copilot Chat explains
    different parameters and their meaning.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 展示了一个代码解释示例，我们使用我们之前的一个完成结果，并自然地与 AI 互动和使用，以帮助我们生成解释。截图没有显示，但 GitHub Copilot
    Chat 解释了不同的参数及其含义。
- en: '![figure](../Images/CH05_F08_Bahree.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F08_Bahree.png)'
- en: Figure 5.8 GitHub Copilot explanation example
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.8 GitHub Copilot 解释示例
- en: As outlined earlier, Copilot can also help explain legacy code, which might
    be in legacy languages such as COBOL, as shown in figure 5.9.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Copilot 还可以帮助解释遗留代码，如图 5.9 所示，这些代码可能是在遗留语言（如 COBOL）中。
- en: '![figure](../Images/CH05_F09_Bahree.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F09_Bahree.png)'
- en: Figure 5.9 Copilot Chat explaining the COBOL code
  id: totrans-80
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.9 Copilot Chat 解释 COBOL 代码
- en: 5.2.2 Generate tests
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 生成测试
- en: We can build on the previous example to demonstrate how to help generate tests
    for a given code set, as shown in figure 5.10\. This feature helps developers
    save precious time and effort in writing unit tests, making them more productive.
    It can also help produce novel and diverse test cases that cover different scenarios
    and edge cases compared to what most developers could create themselves.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以基于之前的示例来演示如何为给定的代码集生成测试，如图 5.10 所示。此功能帮助开发者节省宝贵的时间和精力来编写单元测试，使他们更有效率。它还可以帮助产生新颖且多样化的测试用例，这些测试用例涵盖了与大多数开发者自己创建的相比不同的场景和边缘情况。
- en: '![figure](../Images/CH05_F10_Bahree.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F10_Bahree.png)'
- en: Figure 5.10 Generating unit tests
  id: totrans-84
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.10 生成单元测试
- en: 'GitHub Copilot Chat helps generate unit tests and will test whether the `openai
    .completion.create()` method works as expected if the print statements output
    the correct strings. The unit tests can handle the nondeterministic behavior of
    AI by using mocking, following the steps as listed:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub Copilot Chat 帮助生成单元测试，并检查 `openai .completion.create()` 方法是否按预期工作，如果打印语句输出了正确的字符串。单元测试可以通过模拟来处理
    AI 的非确定性行为，按照以下步骤进行：
- en: Import the necessary modules for testing, such as `unittest` and `mock`.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入测试所需的必要模块，例如 `unittest` 和 `mock`。
- en: Create a new class for the test case, inheriting from `unittest.TestCase`.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为测试用例创建一个新的类，继承自 `unittest.TestCase`。
- en: Within this class, create a setup method to initialize the environment for the
    tests.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个类中，创建一个设置方法来初始化测试环境。
- en: Create a test method to test the `openai.completion.create()` method. Use `'mock'`
    to simulate the response from the OpenAI API.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个测试方法来测试 `openai.completion.create()` 方法。使用 `'mock'` 来模拟来自 OpenAI API 的响应。
- en: Create a test method to test the output of the `print` statements.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个测试方法来测试 `print` 语句的输出。
- en: At the end of the script, add a line to run all the tests when the script is
    executed.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在脚本末尾添加一行，以便在执行脚本时运行所有测试。
- en: Of course, a developer still needs to check the tests and ensure they fit the
    purpose. Generated tests can have many limitations, from covering only some possible
    scenarios (e.g., complex data behavior or accounting for user interactions) at
    one end to code maintainability.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，开发者仍然需要检查测试，并确保它们符合目的。生成的测试可能存在许多限制，从只覆盖一些可能的场景（例如，复杂的数据行为或考虑用户交互）一端到代码的可维护性。
- en: 5.2.3 Code referencing
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 代码引用
- en: Code referencing is a feature that helps developers detect the code generated
    by Copilot against public repositories on GitHub for any matches. This action
    is not default and is a setting that needs to be enabled in the Copilot configuration.
    The advantage of code referencing is that it helps developers make more informed
    decisions about their code. Code referencing shows when a code suggestion matches
    public code on GitHub and provides information about the repositories where that
    code appears and their licenses.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 代码引用是一个帮助开发者检测 Copilot 生成的代码与 GitHub 公共仓库中任何匹配的功能。此操作不是默认的，需要在 Copilot 配置中启用此设置。代码引用的优势在于它帮助开发者做出更明智的代码决策。代码引用显示代码建议与
    GitHub 上的公共代码匹配，并提供有关该代码出现在哪些存储库及其许可证的信息。
- en: This way, developers can learn from others’ work, discover documentation, avoid
    potential legal problems, and give or receive credit for similar work. Furthermore,
    code referencing allows developers to ask GitHub Copilot to rewrite the code if
    they want a different implementation.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，开发者可以从他人的工作中学习，发现文档，避免潜在的法律问题，并为类似的工作给予或接受认可。此外，代码引用还允许开发者要求 GitHub Copilot
    重新编写代码，如果他们想要不同的实现。
- en: GitHub Copilot automatically matches the (approximately 150 characters) code
    it generates against repositories. It finds similar code and outlines its associated
    licensing terms, if any. This allows us to accept or reject the code suggestion.
    We can also ask Copilot to rewrite and create a new generation that differs from
    the matching one.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub Copilot 自动将其生成的（大约 150 个字符）代码与存储库进行匹配。它找到类似的代码并概述其相关的许可条款（如果有）。这允许我们接受或拒绝代码建议。我们还可以要求
    Copilot 重写并创建一个与匹配的代码不同的新版本。
- en: According to research released by GitHub [1], less than 1% of code generation
    ends up matching, and while that is a small percentage, it is not evenly distributed
    across the spectrum. Most of it occurs when the code file is new and empty, as
    there is little additional context for the solution. This is rare in cases when
    there are multiple files and existing solutions, as the code generation is much
    more specific to the situation and prompt.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 GitHub [1] 发布的研究，不到 1% 的代码生成最终匹配，虽然这是一个很小的比例，但它并不是均匀分布在整个范围内。大多数情况发生在代码文件是新的且为空的时候，因为解决方案的上下文很少。在存在多个文件和现有解决方案的情况下，这种情况很少见，因为代码生成更具体于情况和建议。
- en: 'In addition, many of these matches are patterns of libraries that are code
    fragments posted to popular sites such as Stack Overflow, often without attribution.
    Frequently, many are also core APIs of common libraries used across many projects
    that are taking a dependency on those specific libraries. From an enterprise and
    developers’ perspective, there are several benefits to using code referencing:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，许多这些匹配都是库的模式，这些代码片段被发布到像 Stack Overflow 这样的流行网站上，通常没有注明出处。经常，其中许多也是许多项目中使用的常见库的核心
    API，这些项目依赖于这些特定的库。从企业和开发者的角度来看，使用代码引用有以下几个好处：
- en: It helps enterprises make a build-versus-buy decision by understanding whether
    they can depend on an existing open source library to reduce the need for new
    business logic and cost.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它帮助企业通过了解他们是否可以依赖现有的开源库来减少对新业务逻辑和成本的需求来做出构建或购买的决定。
- en: It helps developers improve their coding skills, especially by examining how
    others have solved similar problems.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它帮助开发者提高他们的编码技能，特别是通过检查他人如何解决类似问题。
- en: For many enterprises, the default position is often to avoid code matching public
    repositories; thus, code referencing allows them to choose the source appropriately
    and give credit to the author.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于许多企业来说，通常的立场是避免与公共存储库匹配代码；因此，代码引用允许他们适当选择来源并给予作者应有的认可。
- en: It helps developers understand the relevance and quality of the code before
    taking a dependency and accepting a suggestion that matches the public code.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它帮助开发者在使用依赖项和接受与公共代码匹配的建议之前，理解代码的相关性和质量。
- en: When the topic or library is new, it helps developers explore new projects and
    collaborate with other developers.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当主题或库是新的时，它帮助开发者探索新项目并与其他开发者合作。
- en: 5.2.4 Code refactoring
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.4 代码重构
- en: GitHub Copilot Chat helps with code refactoring by providing intelligent suggestions
    across the solution, thus improving the code’s structure, readability, and maintainability.
    Some ways it can assist with code refactoring are
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub Copilot Chat 通过在整个解决方案中提供智能建议来帮助代码重构，从而提高代码的结构、可读性和可维护性。以下是一些它可以协助代码重构的方法
- en: Simplifying complex expressions or statements
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简化复杂表达式或语句
- en: Extracting repeated code into functions or methods
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将重复的代码提取到函数或方法中
- en: Adding comments or documentation to explain the code logic
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加注释或文档来解释代码逻辑
- en: Renaming variables or functions to follow naming conventions
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重命名变量或函数以遵循命名约定
- en: Another set of experimental features of Copilot is called Labs, where we can
    use different aspects to understand the code and help refactor it—whether by making
    it more readable, more robust, or more error-proof or even by helping us isolate
    and understand a bug in the existing code (figure 5.11).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Copilot 另一套实验性功能被称为 Labs，在那里我们可以使用不同的方面来理解代码并帮助重构它——无论是使其更易读、更健壮、更不易出错，甚至帮助我们隔离和理解现有代码中的错误（图
    5.11）。
- en: '![figure](../Images/CH05_F11_Bahree.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH05_F11_Bahree.png)'
- en: Figure 5.11 Copilot tools for refactoring
  id: totrans-112
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.11 Copilot 重构工具
- en: 5.3 Other code generation tools
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 其他代码生成工具
- en: GitHub Copilot is one of the first and, as of now, most commonly used code generation
    tools, especially in enterprises. However, other code generation tools are learning
    from Copilot and are starting to appear. While the details of how each works differ
    slightly, using different language learning models (LLMs) at a high level, they
    all operate very similarly to what we outlined earlier in the chapter. This section
    provides a quick overview of some of the other code generation tools available
    on the market. The intent is not to go deeply into them, as many are clones and
    offer the same functionality. It is to show how enterprises can evaluate and choose
    the ones that work best in their context and work more easily with their organizational
    development culture.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub Copilot 是最早且目前最常用的代码生成工具之一，尤其是在企业中。然而，其他代码生成工具正在从 Copilot 学习并开始出现。虽然每个工具的工作细节略有不同，但它们在高级别上使用不同的语言学习模型（LLM），它们的操作方式与我们之前在章节中概述的非常相似。本节简要概述了市场上一些其他代码生成工具。目的是展示企业如何评估和选择最适合其环境和与组织发展文化更易协作的工具。
- en: 5.3.1 Amazon CodeWhisperer
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 亚马逊代码建议者
- en: Amazon has CodeWhisperer, AWS’s answer to GitHub Copilot. It can generate code
    based on prompts and help write functions. It supports a narrower set of programming
    languages than Copilot and similar IDEs. CodeWhisperer is available via the AWS
    toolkit extensions, as shown in figure 5.12\.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊拥有代码建议者，这是 AWS 对 GitHub Copilot 的回应。它可以基于提示生成代码并帮助编写函数。它支持的编程语言集合比 Copilot
    和类似的 IDE 更窄。代码建议者可通过 AWS 工具包扩展获得，如图 5.12 所示。
- en: We don’t know the technical details of how CodeWhisperer works, so we can’t
    compare it directly with GitHub Copilot. However, we can say that CodeWhisperer
    and GitHub Copilot focus on different things. CodeWhisperer is more specialized
    for AWS services (such as EC2, S3, Lambda, etc.), while GitHub Copilot is more
    general purpose.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不知道代码建议者如何工作的技术细节，因此无法直接将其与 GitHub Copilot 进行比较。然而，我们可以说代码建议者和 GitHub Copilot
    关注的点不同。代码建议者更专注于 AWS 服务（如 EC2、S3、Lambda 等），而 GitHub Copilot 则更通用。
- en: '![figure](../Images/CH05_F12_Bahree.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH05_F12_Bahree.png)'
- en: Figure 5.12 Amazon CodeWhisperer
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.12 亚马逊代码建议者
- en: Additional details on Amazon CodeWhisperer can be found at [https://aws.amazon.com/codewhisperer/](https://aws.amazon.com/codewhisperer/).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 有关亚马逊代码建议者的更多详细信息，请参阅[https://aws.amazon.com/codewhisperer/](https://aws.amazon.com/codewhisperer/)。
- en: Amazon Q AI assistant
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 亚马逊 Q AI 助手
- en: Amazon recently announced Amazon Q as a new AI assistant for AWS that targets
    enterprise customers. It can do more than help with coding. It can talk, offer
    advice, create content, and access different data sources and systems. Developers
    can use it to fix, improve, and understand code.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊最近宣布亚马逊 Q 作为针对企业客户的新 AWS AI 助手。它不仅能帮助进行编码，还能交谈、提供建议、创建内容，并访问不同的数据源和系统。开发者可以使用它来修复、改进和理解代码。
- en: Amazon Q is an AI assistant that helps with coding and AWS tasks. It depends
    on CodeWhisperer. To use Amazon Q, you must pay for the Amazon CodeWhisperer Professional
    tier and install the latest AWS Toolkit. Amazon Q understands AWS better than
    CodeWhisperer, which mainly helps with coding. More details on Amazon Q can be
    found at [https://aws.amazon.com/q](https://aws.amazon.com/q).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊 Q 是一个帮助进行编码和 AWS 任务的 AI 助手。它依赖于代码建议者。要使用亚马逊 Q，您必须支付亚马逊代码建议者专业版费用并安装最新的 AWS
    工具包。亚马逊 Q 对 AWS 的理解优于代码建议者，后者主要帮助进行编码。有关亚马逊 Q 的更多详细信息，请参阅[https://aws.amazon.com/q](https://aws.amazon.com/q)。
- en: 5.3.2 Code Llama
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 代码骆驼
- en: Meta recently released Code Llama, an LLM model targeting coding similar to
    Codex. Code Llama builds on Llama 2 by training it on more code-specific datasets.
    It can generate code and understand natural language about code. Like Codex and
    GPT4, it supports some of the more popular programming languages—Python, C++,
    Java, C#, and so forth.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Meta 最近发布了代码骆驼，这是一个类似于 Codex 的面向编码的 LLM 模型。代码骆驼通过在更多针对代码的特定数据集上训练 Llama 2 来构建。它可以生成代码并理解关于代码的自然语言。像
    Codex 和 GPT4 一样，它支持一些更流行的编程语言——Python、C++、Java、C# 等等。
- en: 'Code Llama is released as an OSS model, including the weights, and is free
    for commercial and research purposes, although it has a special license. It is
    available in three sizes: 7B-, 13B-, and 30B-parameter base models. Each base
    model is further fine-tuned and available in two variants—one specifically for
    Python and another for Instruct. Code Llama also supports input sequences of 100K
    tokens, allowing sending a longer application code base as context.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Code Llama作为一个开源模型发布，包括权重，并且对商业和研究目的免费，尽管它有一个特殊的许可证。它有三种大小：7B-、13B-和30B参数的基础模型。每个基础模型都进一步微调，并提供两种变体——一个专门用于Python，另一个用于Instruct。Code
    Llama还支持100K个token的输入序列，允许发送更长的应用程序代码库作为上下文。
- en: NOTE  Meta has chosen to release Code Llama under the same license as Llama
    2, which is permissive. This also ensures that enthusiasts, researchers, and businesses
    can use these models in academic research and commercial applications without
    restrictions. However, the license forbids using Llama 2 to train other LLMs,
    requiring a special license from Meta if the model is used in an app or service
    with over 700 million monthly users.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：Meta选择在Llama 2相同的许可证下发布Code Llama，这是一个许可宽松的许可证。这也确保了爱好者、研究人员和商业公司可以在学术研究和商业应用中使用这些模型而无需限制。然而，该许可证禁止使用Llama
    2训练其他LLM，如果模型用于拥有超过7亿月活跃用户的app或服务，则需要从Meta获得特殊许可证。
- en: Being smaller in a production deployment, the 7B and 13B base models require
    fewer resources in the sense of computing power (GPU), memory, and power; therefore,
    these models can be faster for inference and are better suited for low-latency
    scenarios where faster responses are required. Note that the exact definition
    of low-latency, of course, would be dependent on the use case and scenarios at
    hand. These two base models and their fine-tuned versions also support FIM capabilities,
    which Meta calls infilling.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产部署中体积较小，7B和13B的基础模型在计算能力（GPU）、内存和电力方面的资源需求更少；因此，这些模型在推理速度上可以更快，更适合需要快速响应的低延迟场景。需要注意的是，低延迟的确切定义当然会取决于具体的使用案例和场景。这两个基础模型及其微调版本也支持FIM功能，Meta将其称为填充。
- en: Note  Consumer-class GPUs are for general consumers who want to play games or
    edit videos. They are cheaper, use less power, and have less memory than data-center-class
    GPUs. Data-center-class GPUs are for professionals who need high performance and
    reliability. They are more expensive, powerful, and have more memory and special
    features than consumer-class GPUs.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：消费级GPU是针对希望玩游戏或编辑视频的一般消费者。它们价格较低，功耗更低，内存也少于数据中心级GPU。数据中心级GPU是为需要高性能和可靠性的专业人士设计的。它们价格更高，性能更强，内存更大，并且具有比消费级GPU更多的特殊功能。
- en: This is the model itself, and as of publication, there isn’t a toolset around
    it like GitHub Copilot. Enterprises and other companies would need to take the
    model, host it themselves, and require GPUs for inference and managing lifecycles.
    The small models can be run on a consumer-class GPU when quantized. Quantization
    is a technique that reduces the number of bits used to represent the model’s parameters,
    which can save memory, speed up inference, and improve energy efficiency. However,
    quantization can also introduce accuracy loss or hardware inefficiency if not
    done properly.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这是模型本身，截至出版时，还没有像GitHub Copilot这样的工具集。企业和其他公司需要自行托管该模型，并需要GPU进行推理和管理生命周期。当模型量化后，小型模型可以在消费级GPU上运行。量化是一种减少表示模型参数所使用的位数的技术，可以节省内存、加快推理速度并提高能源效率。然而，如果操作不当，量化也可能导致精度损失或硬件效率低下。
- en: Figure 5.13 shows the generation using the chat completion of Code Llama. While
    it is a little different, it is still similar to what we have seen thus far. The
    full generated code can be found in books accompanying the GitHub repository at
    [https://bit.ly/GenAIBook](https://bit.ly/GenAIBook).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13展示了使用Code Llama的聊天完成功能进行生成。虽然略有不同，但仍然与我们迄今为止所见相似。完整的生成代码可以在GitHub仓库附带的书籍中找到，链接为[https://bit.ly/GenAIBook](https://bit.ly/GenAIBook)。
- en: '![figure](../Images/CH05_F13_Bahree.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F13_Bahree.png)'
- en: Figure 5.13 Code Llama generating function
  id: totrans-133
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.13 Code Llama生成函数
- en: You can find more details on Code LLama at Meta’s site ([https://llama.meta.com/code-llama](https://llama.meta.com/code-llama)).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在Meta网站上找到更多关于Code LLama的详细信息([https://llama.meta.com/code-llama](https://llama.meta.com/code-llama))。
- en: 5.3.3 Tabnine
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.3 Tabnine
- en: Tabnine is another AI-powered assistant that helps a developer, similar to GitHub
    Copilot. It provides real-time completions, and it has recently announced a chat-like
    feature. Tabnine can help complete code blocks and functions (see figure 5.14).
    As an advantage, Tabnine offers an option to be run locally or in the cloud, although
    its default mode is hybrid (i.e., using both). Tabnine supports more IDEs and
    the same programming languages, including C, C++, C#, Java, Python, React, NodeJS,
    and so forth. Tabnine uses a proprietary LLM trained on OSS libraries, and enterprises
    can run in a Kubernetes cluster on-premises. More details on Tabnine can be found
    at [https://www.tabnine.com/install](https://www.tabnine.com/install).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Tabnine 是另一个类似于 GitHub Copilot 的 AI 辅助工具，它帮助开发者，最近还宣布了类似聊天的功能。Tabnine 可以帮助完成代码块和函数（见图
    5.14）。作为一个优势，Tabnine 提供了本地或云端运行的选择，尽管其默认模式是混合模式（即使用两者）。Tabnine 支持更多的 IDE 和相同的编程语言，包括
    C、C++、C#、Java、Python、React、NodeJS 等等。Tabnine 使用基于 OSS 库训练的专有 LLM，企业可以在本地 Kubernetes
    集群中运行。更多关于 Tabnine 的详细信息可以在 [https://www.tabnine.com/install](https://www.tabnine.com/install)
    找到。
- en: '![figure](../Images/CH05_F14_Bahree.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH05_F14_Bahree.png)'
- en: Figure 5.14 Tabnine code generation in Visual Studio Code
  id: totrans-138
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.14 Visual Studio Code 中的 Tabnine 代码生成
- en: Note that this is not an exhaustive list of tools that enterprises and developers
    can use as AI-based tools for code generation and other code-related tasks. It
    does show the more commonly used ones in the context of enterprises. A few additional
    notable ones are
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这并不是企业开发者可以使用作为基于 AI 的代码生成和其他代码相关任务的工具的完整列表。它确实显示了在企业环境中更常用的工具。一些额外的值得注意的工具包括
- en: '*Codey**—Google’s foundation code generation model supports over 20 languages.*'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Codey**——谷歌的基础代码生成模型支持超过 20 种语言。*'
- en: '**   *Gemini**—Google’s answer to ChatGPT now supports code generation. At
    the time of publication, it still did not offer integration into an IDE. It was
    a standalone in the chat paradigm that allowed the copy and exporting of the code
    into Google Colab notebooks. Google launched this feature as Bard, which was rebranded
    and powered by a new multimodality model called Gemini.***   *CodeT5+**—Salesforce
    has a new family of code LLMs that are OSS and can support both generation and
    understanding; these can be adapted to downstream tasks.***   *StableCode**—Stability
    AI, the company behind the Vision models we saw earlier, recently announced a
    code-based base LLM. This is an OSS model that also supports multiple programming
    languages. In addition to the base model, there is an instruct model that would
    be more useful for most developers. Out of the box, it has no IDE integration.****'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**Gemini**——谷歌对 ChatGPT 的回应，现在支持代码生成。在出版时，它还没有提供集成到 IDE 中。它是一个独立的聊天范式，允许将代码复制并导出到
    Google Colab 笔记本中。谷歌将这个功能命名为 Bard，并重新命名，由一个名为 Gemini 的新多模态模型提供支持。***   *CodeT5+**——Salesforce
    有一个新的代码 LLM 家族，是 OSS 的，可以支持生成和理解；这些可以适应下游任务。***   *StableCode**——Stability AI
    公司，我们之前看到的视觉模型背后的公司，最近宣布了一个基于代码的基础 LLM。这是一个支持多种编程语言的 OSS 模型。除了基础模型外，还有一个指令模型，对大多数开发者来说更有用。它出厂时没有
    IDE 集成。****'
- en: '***Note Many of the OSS models that do not have an IDE integration can be hosted
    on Hugging Face and called by another Visual Studio Code extension—`huggingface-vscode`.
    This code completion extension allows us to use most OSS models. More details
    on the extension can be found at the GitHub repository ([https://github.com/huggingface/huggingface-vscode](https://github.com/huggingface/huggingface-vscode)).
    This extension can also be configured to call a custom endpoint that is not a
    Hugging Face interference API.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '***注意** 许多没有 IDE 集成的 OSS 模型可以托管在 Hugging Face 上，并通过另一个 Visual Studio Code 扩展——`huggingface-vscode`
    调用。这个代码补全扩展允许我们使用大多数 OSS 模型。更多关于这个扩展的详细信息可以在 GitHub 仓库中找到 ([https://github.com/huggingface/huggingface-vscode](https://github.com/huggingface/huggingface-vscode))。这个扩展也可以配置为调用一个自定义端点，该端点不是
    Hugging Face 干扰 API。'
- en: 5.3.4 Check yourself
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.4 自我检查
- en: 'Code generation tools can be very helpful for enterprise developers, as they
    can save time, reduce errors, and improve productivity. However, code generation
    tools are imperfect and require human oversight, and validation. Here are some
    tips on how to trust and use these code generation tools effectively:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 代码生成工具对企业的开发者非常有帮助，因为它们可以节省时间，减少错误，并提高生产力。然而，代码生成工具并不完美，需要人工监督和验证。以下是一些关于如何信任和有效使用这些代码生成工具的提示：
- en: '*Choose the right tool for the right task*. Code generation tools vary in their
    capabilities, quality, and suitability for domains and languages. Developers should
    evaluate the available tools and select the ones that best suit their needs and
    preferences. For example, some tools may be better for generating UI components,
    while others may be better for generating business logic or data access layers.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*选择适合任务的正确工具*。代码生成工具在功能、质量和适合领域和语言方面各不相同。开发者应评估可用的工具，并选择最适合他们需求和偏好的工具。例如，某些工具可能更适合生成
    UI 组件，而其他工具可能更适合生成业务逻辑或数据访问层。'
- en: '*Follow the best practices and guidelines for code generation*. Code generation
    tools often provide documentation and examples of using them properly and efficiently.
    Developers should follow these best practices and guidelines to ensure the quality
    and consistency of the generated code. For instance, some tools may require certain
    naming conventions, annotations, or templates to work correctly.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*遵循代码生成的最佳实践和指南*。代码生成工具通常提供有关如何正确和高效使用它们的文档和示例。开发者应遵循这些最佳实践和指南，以确保生成的代码的质量和一致性。例如，某些工具可能需要特定的命名约定、注释或模板才能正确工作。'
- en: '*Review, test, and verify the generated code*. Code generation tools are not
    a substitute for human expertise and judgment. Developers should always review,
    test, and verify the generated code before production. They should check for errors,
    bugs, security vulnerabilities, performance problems, readability, maintainability,
    and compliance with standards and regulations. They should also compare the generated
    code with similar snippets and suggest improvements if needed.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*审查、测试和验证生成的代码*。代码生成工具不能替代人类的专长和判断。开发者应在生产前始终审查、测试和验证生成的代码。他们应检查错误、漏洞、安全漏洞、性能问题、可读性、可维护性以及是否符合标准和法规。他们还应将生成的代码与类似的片段进行比较，并在必要时提出改进建议。'
- en: '*Provide feedback and report problems to the tool providers*. Code generation
    tools are constantly learning from new code and feedback from developers. Developers
    should provide feedback and report problems to the tool providers to help them
    improve their products and services. They should also keep track of the updates
    and enhancements of the tools and learn how to use them effectively.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*向工具提供商提供反馈并报告问题*。代码生成工具不断从新的代码和开发者的反馈中学习。开发者应向工具提供商提供反馈并报告问题，以帮助他们改进他们的产品和服务。他们还应跟踪工具的更新和改进，并学习如何有效地使用它们。'
- en: 5.3.5 Best practices for code generation
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.5 代码生成的最佳实践
- en: Irrespective of the tool we use, the concept of using LLMs for code generation
    and other code-related tasks is still very novel. Some best practices that should
    be considered in an enterprise when thinking about using generative AI and LLMs
    are
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 不论我们使用什么工具，使用 LLMs 进行代码生成和其他与代码相关的任务的概念仍然非常新颖。在考虑使用生成 AI 和 LLMs 时，企业应考虑以下最佳实践
- en: '*Design for imperfections*—The LLMs will be wrong and will hallucinate. The
    generated code could outline APIs that look good at the surface but might not
    be real. They also can be wrong and produce code that doesn’t compile and execute.
    In addition to being incorrect, sometimes the generated code can be inefficient.
    It is important to be aware of these limitations and take steps to mitigate them,
    including checking yourself as outlined earlier and using a technique called prompt
    engineering, which we will cover later in chapter 6\.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*为不完美而设计*——LLMs 可能会出错并产生幻觉。生成的代码可能概述看起来不错的 API，但可能不是真实的。它们也可能出错并生成无法编译和执行的代码。除了不正确之外，有时生成的代码可能效率低下。重要的是要意识到这些限制并采取措施减轻它们，包括检查自己，如前所述，并使用一种称为提示工程的技术，我们将在第
    6 章中介绍。'
- en: '*Clear and specific goals*—For the code generation task, ensure the goal is
    clear and specific. Consider the code needed, the inputs and outputs, and specific
    quality criteria. A clear vision of the desired outcome can help our code generation
    more effectively. This includes adding details on specific libraries and packages
    the code should use when not obvious, as it cannot guess our intent.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*明确和具体的目标*——对于代码生成任务，确保目标是明确和具体的。考虑所需的代码、输入和输出以及特定的质量标准。对期望结果的清晰愿景可以帮助我们的代码生成更有效地进行。这包括在代码应使用特定库和包但不是显而易见的情况下添加详细信息，因为它无法猜测我们的意图。'
- en: '*Iterative prompts*—Small changes in the prompt can significantly change the
    generation. Consequently, iterating through prompts in small steps and their generated
    results would be important to managing this. The vaguer the prompt, the poorer
    the resulting generated code. Understanding the prompts is a combination of both
    art and science. We will cover details of prompt engineering later in the book.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*迭代提示*—提示中的微小变化可以显著改变生成结果。因此，通过小步骤迭代提示及其生成的结果对于管理这一点非常重要。提示越模糊，生成的代码质量越差。理解提示是艺术和科学的结合。本书稍后我们将讨论提示工程的细节。'
- en: '*Evaluatio**n*—Use multiple metrics and methods to evaluate the quality of
    the generated code. This has many attributes, for example, syntax, semantics,
    functionality, readability, and maintainability. Where possible, we should use
    different dimensions of automated metrics (e.g., BLEU, ROUGE), human evaluation
    (e.g., surveys, interviews), testing (e.g., unit tests, integration tests), debugging
    (e.g., static analysis, dynamic analysis), and so forth.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*评估*—使用多个指标和方法来评估生成的代码质量。这有许多属性，例如语法、语义、功能、可读性和可维护性。在可能的情况下，我们应该使用自动指标的不同维度（例如BLEU、ROUGE）、人工评估（例如调查、访谈）、测试（例如单元测试、集成测试）、调试（例如静态分析、动态分析）等等。'
- en: '*Development standards*—Follow coding standards and best practices for the
    target programming language or framework you want to generate code for; if there
    are enterprise or industry standards, including them in existing code solutions
    will provide the context and hints for the generated code.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开发标准*—遵循您想要为其生成代码的目标编程语言或框架的编码标准和最佳实践；如果存在企业或行业标准，将它们纳入现有的代码解决方案中将为生成的代码提供上下文和提示。'
- en: Let us switch modalities and outline a few areas of video and music generation
    that are still quite new and cover science and research. Given the speed of innovation,
    it won’t be long before these are more commonly available. Both generative AI
    music and video generation have the potential to revolutionize the way enterprises
    create and distribute content. As technology continues to develop and become more
    accessible, we can expect to see more and more enterprises using it to create
    innovative and engaging experiences for their customers and employees.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们转换一下模式，概述一下视频和音乐生成的一些仍相当新颖的领域，并涵盖科学和研究。鉴于创新的步伐，这些领域很快就会更加普遍可用。生成式AI音乐和视频生成都有可能彻底改变企业创造和分发内容的方式。随着技术的持续发展和变得更加易于获取，我们可以期待越来越多的企业使用它为客户和员工创造创新和吸引人的体验。
- en: 5.4 Video generation
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 视频生成
- en: Video generation using generative AI is a young but rapidly developing field,
    with many potential applications. Some organizations use video generation to enhance
    creativity and innovation by generating novel and original content that can attract
    and engage customers. Others use it to personalize customer experience by creating
    video content according to the preferences and needs of individual customers,
    such as their mood, taste, location, or behavior.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生成式AI进行视频生成是一个年轻但快速发展的领域，具有许多潜在应用。一些组织使用视频生成通过生成新颖和原创的内容来增强创造力和创新，这些内容可以吸引和吸引客户。其他人则通过根据个别客户的偏好和需求（如情绪、品味、位置或行为）创建视频内容来个性化客户体验。
- en: Some companies are already using this in production. YouTube is using generative
    AI to create personalized video thumbnails for its creators. Walmart uses generative
    AI to create personalized video ads for its customers. Some use cases are even
    more compelling. For example, ALICE Receptionist is a company that provides a
    virtual receptionist service for businesses. They use generative AI to create
    videos of multilingual customer support agents that can greet and assist visitors
    in different languages. Ran is a sports broadcasting company that covers various
    sports events and leagues. They use generative AI to create sports coverage with
    virtual anchors that can commentate and analyze the games in real time. Some of
    the key use cases for video generation are
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 一些公司已经开始在生产中使用这项技术。YouTube正在使用生成式AI为创作者创建个性化的视频缩略图。沃尔玛正在使用生成式AI为客户创建个性化的视频广告。一些用例甚至更加引人注目。例如，ALICE接待员是一家为商业提供虚拟接待员服务的企业。他们使用生成式AI创建多语言客户支持代理的视频，可以在不同语言中问候和协助访客。Ran是一家覆盖各种体育赛事和联赛的体育广播公司。他们使用生成式AI创建带有虚拟主播的体育报道，这些主播可以实时评论和分析比赛。视频生成的一些关键用例包括
- en: '*Marketing content*—Generative AI can be used to create marketing videos that
    are more personalized and targeted, such as videos that promote a product to a
    specific audience based on their interests.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*营销内容*—生成式AI可以用来创建更加个性化和有针对性的营销视频，例如根据受众的兴趣向特定受众推广产品的视频。'
- en: '*Entertainment content*—Generative AI can be used to create entertainment videos
    that are more creative and innovative. For example, it is possible to create videos
    that help enhance a movie or TV program, tell a story, or play a game.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*娱乐内容*—生成式AI可以用来创建更具创造性和创新性的娱乐视频。例如，可以创建帮助增强电影或电视节目、讲述故事或玩游戏的视频。'
- en: '*Educational content*—Generative AI can be used to create educational videos
    that are more engaging and interactive than traditional ones. For example, a generative
    AI model could be used to create a video that explains a complex concept by using
    animation and narration and can be used in the context of the difficulty level
    of the student.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*教育内容*—生成式AI可以用来创建比传统教育视频更具吸引力和互动性的教育视频。例如，可以使用生成式AI模型创建一个视频，通过动画和旁白解释复杂的概念，并可以根据学生的难度水平使用。'
- en: '*Synthetic data*—Generative AI is capable of generating data that is not real
    (i.e., synthetic data) and that can be used as the input training data for other
    ML model creation. This is helpful in scenarios where the real data is impossible
    or impractical. For example, NVIDIA uses generative AI to create synthetic training
    data for its self-driving cars, allowing them to obtain data on various edge cases.
    Disney is using synthetic data to develop new ride and attraction concepts and
    optimize the layout of its theme parks, which allows it to use synthetic data
    to test and refine new products and services before releasing them to the public.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*合成数据*—生成式AI能够生成非真实数据（即合成数据），这些数据可以用作其他机器学习模型创建的输入训练数据。这在真实数据无法获取或不切实际的情况下非常有用。例如，NVIDIA使用生成式AI为其自动驾驶汽车创建合成训练数据，使它们能够获取各种边缘情况的数据。迪士尼正在使用合成数据来开发新的游乐设施和景点概念，并优化其主题公园的布局，这使得它能够在向公众发布之前，使用合成数据测试和改进新产品和服务。'
- en: Some of the most common methods that allow this video generation are
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 允许这种视频生成的最常见方法包括
- en: '*Text-to-video synthesis*—This method follows the paradigm we have seen so
    far: generating a video using a prompt. Like image generation, the model learns
    to associate words and phrases with visual concepts and then uses this knowledge
    to create a video that matches the text description.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文本到视频合成*—这种方法遵循我们之前看到的范式：使用提示信息生成视频。与图像生成类似，模型学会将单词和短语与视觉概念关联起来，然后利用这些知识来创建与文本描述相匹配的视频。'
- en: '*Image-to-video synthesis*—This method generates a video from a source image
    instead of a prompt. The model learns to associate image features with visual
    concepts and then uses this knowledge to create a video that matches the image.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图像到视频合成*—这种方法从源图像生成视频，而不是从提示信息生成。模型学会将图像特征与视觉概念关联起来，然后利用这些知识来创建与图像相匹配的视频。'
- en: '*Video-to-video synthesis*—Similar to the earlier method, this method uses
    a source video to create a new video. The model learns to identify the underlying
    structure of the original video and then uses this knowledge to create a new video
    with the same structure but different content.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*视频到视频合成*—与早期方法类似，这种方法使用源视频来创建新的视频。模型学会识别原始视频的底层结构，然后利用这些知识来创建具有相同结构但不同内容的视频。'
- en: '*GAN-based video generation*—This method uses a generative adversarial network
    (GAN) to create a video.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于GAN的视频生成*—这种方法使用生成对抗网络（GAN）来创建视频。'
- en: 'Several AI video generators are available that can help you easily create videos.
    Here are some examples of AI video generators that use generative AI:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种AI视频生成器可供使用，可以帮助您轻松创建视频。以下是一些使用生成式AI的AI视频生成器示例：
- en: '*Sora*—A diffusion model that differs from usual video generation methods that
    directly predict each frame. OpenAI announced this new AI model to make realistic
    and creative video scenes from text instructions. Sora begins with a basic static
    noise pattern and slowly changes it into a detailed video, frame by frame. It
    starts with noisy video frames. Each step removes noise to produce fine details.
    This process ensures the videos are visually pleasing and contextually correct
    based on the input text. When Sora was published, it was not given access by Open
    AI.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Sora*—一个与通常的视频生成方法不同的扩散模型，它不是直接预测每一帧。OpenAI宣布了这一新的AI模型，可以从文本指令生成逼真和富有创意的视频场景。Sora从一个基本的静态噪声模式开始，逐渐将其转换为详细的视频，一帧一帧。它从噪声视频帧开始。每一步都会去除噪声以产生精细的细节。这个过程确保视频在视觉上令人愉悦，并且基于输入文本在上下文中正确。当Sora发布时，它没有得到Open
    AI的访问权限。'
- en: '*Pictory*—An AI-powered video creation tool that allows users to create videos
    from text, images, and videos. It offers various features for editing and customizing
    videos, such as adding captions, transitions, and music. Pictory can also help
    summarize long videos into shorter ones.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Pictory*—一个AI驱动的视频创作工具，允许用户从文本、图像和视频创建视频。它提供各种编辑和自定义视频的功能，如添加字幕、过渡和音乐。Pictory还可以帮助将长视频总结成更短的版本。'
- en: '*Synthesia*—A cloud-based platform that allows users to create videos with
    AI-generated presenters. Users can choose from various avatars and voices and
    add text, images, and gestures to their videos.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Synthesia*—一个基于云的平台，允许用户使用AI生成的演讲者创建视频。用户可以从各种头像和声音中选择，并在视频中添加文本、图像和手势。'
- en: '*NVIDIA Canvas*—A cloud-based AI tool that allows users to create realistic
    paintings from text descriptions. It uses a GAN-based approach to generate paintings
    and can be used to create paintings of various subjects.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*NVIDIA Canvas*—一个基于云的AI工具，允许用户根据文本描述创建逼真的绘画。它使用基于GAN的方法生成绘画，可以用于创建各种主题的绘画。'
- en: '*Meta Make-a-Video*—A generative AI system that can create videos from text
    or image inputs. It uses many text-image pairs and unlabeled videos to learn how
    to generate realistic and diverse videos that match the given prompts. It can
    also create variations of existing videos or add motion to static images.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Meta Make-a-Video*—一个生成式AI系统，可以从文本或图像输入创建视频。它使用许多文本-图像对和无标签视频来学习如何生成与给定提示相匹配的逼真且多样化的视频。它还可以创建现有视频的变体或为静态图像添加动作。'
- en: '*Viddyoze*—A desktop application that allows users to create videos from text,
    images, and audio. Viddyoze uses various AI techniques to generate realistic videos,
    giving users more control over the creative process, including features such as
    transitions, effects, graphics, and so forth.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Viddyoze*—一款桌面应用程序，允许用户从文本、图像和音频创建视频。Viddyoze使用各种AI技术生成逼真的视频，使用户能够更好地控制创作过程，包括过渡、效果、图形等功能。'
- en: '*Powtoon*—A cloud-based platform that allows users to create videos from text,
    images, and audio. It uses various AI techniques to generate realistic videos
    using a variety of templates and features that can be used to create videos for
    different purposes.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Powtoon*—一个基于云的平台，允许用户从文本、图像和音频创建视频。它使用各种AI技术，利用多种模板和功能来生成适用于不同目的的视频。'
- en: '*Dream*—An app by WOMBO that uses AI to generate images and videos based on
    a user’s input of a keyword or phrase. Wombo Dream will generate a creative and
    visually appealing image or video.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Dream*—WOMBO开发的一款应用程序，使用AI根据用户输入的关键词或短语生成图像和视频。Wombo Dream将生成一个创意丰富且视觉上吸引人的图像或视频。'
- en: '*Wochit*—A cloud-based platform that allows users to create videos from text,
    images, and videos. It focuses on making the process as collaborative as possible.
    Wochit allows users to work together to create videos and offers various features
    for sharing and distributing videos.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Wochit*—一个基于云的平台，允许用户从文本、图像和视频创建视频。它专注于使创作过程尽可能协作。Wochit允许用户共同创作视频，并提供各种视频分享和分发功能。'
- en: 'Some of these tools make it very simple to interact with and edit via a GUI
    before generating a video. Figure 5.15 shows that by using Wochit, we can edit
    scenes, including music being used, the look and feel of text, and any other elements
    in a generated video. In our example, we use the following prompt:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具中的一些使得通过GUI与视频交互和编辑变得非常简单。图5.15显示，通过使用Wochit，我们可以编辑场景，包括使用的音乐、文本的外观和感觉以及生成视频中任何其他元素。在我们的示例中，我们使用了以下提示：
- en: '**![image](../Images/Prompt.png)**Top 5 places I should visit when on a trip
    to Seattle.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Prompt.png)**西雅图旅行时应访问的五大景点。'
- en: The video generated can be found in the books accompanying the GitHub repository
    at [https://bit.ly/GenAIBook](https://bit.ly/GenAIBook).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的视频可以在GitHub存储库附带的书籍中找到，[https://bit.ly/GenAIBook](https://bit.ly/GenAIBook)。
- en: '![figure](../Images/CH05_F15_Bahree.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F15_Bahree.png)'
- en: Figure 5.15 Wochit AI video generation
  id: totrans-183
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.15 Wochit AI视频生成
- en: These are just a few examples of how generative AI is used to create videos.
    Now let’s explore music generation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是生成式AI用于创建视频的几个例子。现在让我们来探索音乐生成。
- en: 5.5 Audio and music generation
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 音频和音乐生成
- en: If we thought video generation was in its infancy, in the context of enterprises,
    audio and music generation is much earlier in its lifecycle. Generative AI can
    generate audio, speech, music, or sound effects. Audio and music generation share
    many of the same AI methods, such as autoregressive models, GANs, and transformer
    models.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们认为视频生成还处于初级阶段，那么在企业的背景下，音频和音乐生成在其生命周期中还要早得多。生成式AI可以生成音频、语音、音乐或音效。音频和音乐生成共享许多相同的AI方法，例如自回归模型、GAN和Transformer模型。
- en: 'Although audio and music generation is a very new area, some of the potential
    applications of generative AI audio generation are quite interesting for enterprises
    to explore:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管音频和音乐生成是一个非常新的领域，但生成式AI音频生成的某些潜在应用对企业来说非常有趣，值得探索：
- en: Generating realistic sound effects for entertainment, such as movies and video
    games
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为娱乐生成逼真的音效，如电影和视频游戏
- en: Creating personalized audio experiences for users
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为用户创建个性化的音频体验
- en: Generating music for movies, video games, and other media
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为电影、视频游戏和其他媒体生成音乐
- en: Improving the quality of speech recognition and translation systems
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高语音识别和翻译系统的质量
- en: Developing new ways to communicate with computers, either by using new modalities
    or helping differently abled people
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发新的与计算机交流的方式，无论是通过使用新的模态还是帮助有不同能力的人
- en: Some of the examples of generative AI tools for music and audio are
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI音乐和音频工具的一些例子
- en: '*OpenAI''s Jukebox*—Jukebox is a generative AI model that can create music
    in various classical, jazz, and pop styles. It has been trained on a massive music
    dataset, and it can generate new music indistinguishable from human-created music.
    This builds on OpenAI’s work for MuseNet; for more details on Jukebox, visit [https://openai.com/research/jukebox](https://openai.com/research/jukebox).'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenAI的Jukebox*—Jukebox是一个可以创作古典、爵士和流行风格音乐的生成式AI模型。它是在庞大的音乐数据集上训练的，能够生成与人类创作音乐难以区分的新音乐。这建立在OpenAI对MuseNet的工作之上；有关Jukebox的更多详细信息，请访问[https://openai.com/research/jukebox](https://openai.com/research/jukebox)。'
- en: '*OpenAI''s MuseNet*—MuseNet is another generative AI model that can create
    music in various styles. It has been trained on a dataset of over 1.5 million
    songs, and it can generate new music that is both creative and original.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenAI的MuseNet*—MuseNet是另一个可以创作多种风格音乐的生成式AI模型。它是在超过150万首歌曲的数据集上训练的，能够生成既具有创意又原创的新音乐。'
- en: '*Meta''s AudioCraft*—AudioCraft is a generative AI tool that can create music
    from text prompts. It has been trained on a dataset of over 20,000 hours of music
    and can generate music tailored to the specific text prompt.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Meta的AudioCraft*—AudioCraft是一个生成式AI工具，可以从文本提示创建音乐。它是在超过20,000小时的音频数据集上训练的，能够根据特定的文本提示生成音乐。'
- en: '*NVIDIA’s Vocoder*—Vocoder is a generative AI tool that can generate realistic
    speech from text prompts. It has been trained on a dataset of human speech, and
    it can generate natural and intelligible speech.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*NVIDIA的Vocoder*—Vocoder是一个生成式AI工具，可以从文本提示生成逼真的语音。它是在人类语音数据集上训练的，能够生成自然且易于理解的语音。'
- en: '*Google MusicLM*—This language model was created by Google to generate music
    compositions based on text prompts. This is an experimental tool that, at the
    time of publication, was only available as part of Google’s AI Test Kitchen program,
    which essentially is a playground for Google and its customers to try things out
    ([https://mng.bz/0MmJ](https://mng.bz/0MmJ)).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Google MusicLM*—这个语言模型是由谷歌创建的，可以根据文本提示生成音乐作品。这是一个实验性工具，在出版时，它仅作为谷歌AI测试厨房计划的一部分提供，这个计划本质上是一个谷歌及其客户尝试新事物的游乐场（[https://mng.bz/0MmJ](https://mng.bz/0MmJ)）。'
- en: '*MusicGen*—This language model uses prompts to create and generate music based
    on the provided prompt. Meta developed it as part of their AudioCraft research
    project, and it is an open source tool that anyone can use to create their music
    using Hugging Face Spaces. You can hear demos and read more details at [https://ai.honu.io/papers/musicgen/](https://ai.honu.io/papers/musicgen/).'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MusicGen*—这个语言模型使用提示词根据提供的提示创建和生成音乐。Meta将其作为其AudioCraft研究项目的一部分开发，是一个开源工具，任何人都可以使用Hugging
    Face Spaces来创建自己的音乐。您可以在[https://ai.honu.io/papers/musicgen/](https://ai.honu.io/papers/musicgen/)听到演示并了解更多详情。'
- en: '*Riffusion*—This audio and music generation library works with stable diffusion.
    It essentially is a fine-tuned version of stable diffusion, where instead of images,
    the library creates images of spectrograms; these spectrograms can then be converted
    into audio clips. Riffusion supports different styles of music generation, such
    as funk, jazz, and so forth. More details can be found at [https://about.riffusion.com/](https://about.riffusion.com/).'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Riffusion*—这个音频和音乐生成库与稳定扩散一起工作。它本质上是一个微调后的稳定扩散版本，其中库创建的不是图像，而是声谱图；这些声谱图随后可以转换为音频剪辑。Riffusion支持不同风格的音乐生成，如放克、爵士乐等。更多详情可在[https://about.riffusion.com/](https://about.riffusion.com/)找到。'
- en: '*Mo**û**sai*—This text-to-music generation system uses diffusion models to
    create high-quality music using prompts. It has two sets of diffusion models—one
    for generating melody and harmony and the second for generating the timbre and
    dynamics. Combining them allows us to handle complex musical notes and helps generate
    music in various genres and styles. More info is available at [https://mng.bz/j04a](https://mng.bz/j04a).'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Mo**û**sai*—这个文本转音乐生成系统使用扩散模型，通过提示词创建高质量的音乐。它包含两套扩散模型——一套用于生成旋律和和声，另一套用于生成音色和动态。将它们结合起来，我们可以处理复杂的音乐音符，并帮助生成各种风格和流派的音乐。更多信息可在[https://mng.bz/j04a](https://mng.bz/j04a)找到。'
- en: Summary
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Generative AI allows us to generate code snippets and functions using a prompt.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI允许我们使用提示词生成代码片段和函数。
- en: Code generation is influenced by the context of the software solution, including
    the libraries being used, programming languages, code, and design patterns implemented.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码生成受到软件解决方案上下文的影响，包括使用的库、编程语言、代码和实现的设计模式。
- en: Generative AI can also generate other software development lifecycle artifacts
    such as code understanding and documentation, testing code, and code refactoring.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI还可以生成其他软件开发生命周期工件，如代码理解、文档、测试代码和代码重构。
- en: Code generation can help enterprises by augmenting developers, improving productivity,
    onboarding new employees, automating repetitive tasks, and fostering creativity.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码生成可以通过增强开发者、提高生产力、入职新员工、自动化重复性任务和激发创造力来帮助企业。
- en: GitHub Copilot and Copilot Chat are the leading tools enterprises use and give
    a big productivity boost.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub Copilot和Copilot Chat是企业使用的领先工具，并提供了巨大的生产力提升。
- en: There are additional code generation tools and open source models, such as AWS’s
    CodeWhisperer, Tabine, and Code Lama, as examples that are also available to enterprises.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，还有其他代码生成工具和开源模型，例如AWS的CodeWhisperer、Tabine和Code Lama，这些工具企业也可以使用。
- en: Video generation is in its infancy, but several AI video generation tools, such
    as Pictory and Synethica, let enterprises use them.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频生成还处于起步阶段，但Pictory和Synethica等几个AI视频生成工具允许企业使用它们。
- en: Similarly, audio and sound generation are still early in their development,
    but many tools and associated models, such as Jukebox, MuseNet, and AudioCraft,
    are available to enterprises.***
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同样，音频和声音生成仍处于早期发展阶段，但许多工具和相关模型，如Jukebox、MuseNet和AudioCraft，可供企业使用。
