- en: Chapter 1\. Introduction to PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to creating artificial intelligence (AI), machine learning (ML)
    and deep learning are great places to begin. When you’re getting started, however,
    it’s easy to get overwhelmed by the options and all the new terminology. This
    book aims to demystify things for you as a programmer. It takes you through writing
    code to implement concepts of ML and deep learning, and it also takes you through
    building models that behave more as a human does, with scenarios like computer
    vision, natural language processing (NLP), and more. Thus, these models become
    a form of synthesized, or artificial, intelligence.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: But when we refer to *machine learning*, what exactly is it? Let’s take a quick
    look at that and consider it from a programmer’s perspective before we go any
    further. After that, in the rest of this chapter, we’ll show you how to install
    the tools of the trade, from PyTorch itself to environments where you can code
    and debug your PyTorch-based models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: What Is Machine Learning?
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we get into the ins and outs of ML, let’s consider how it evolved from
    traditional programming. We’ll start by examining what traditional programming
    is, and then we’ll consider cases where it’s limited. After that, we’ll see how
    ML evolved to handle those cases and thus opened up new opportunities to implement
    new scenarios, thereby unlocking many of the concepts of AI.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Traditional programming involves writing rules that are expressed in a programming
    language and that act on data and give us answers. This applies just about everywhere
    we can program something with code.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: For example, consider a game like the popular Breakout. Code determines the
    movement of the ball, the score, and the various conditions for winning or losing
    the game. Think about the scenario where the ball bounces off a brick, like in
    [Figure 1-1](#ch01_figure_1_1748548870009162).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0101.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
- en: Figure 1-1\. Code in a Breakout game
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Here, the motion of the ball can be determined by its `dx` and `dy` properties.
    When the ball hits a brick, the brick is removed, the velocity of the ball increases,
    and the direction of the ball’s movement changes. The code acts on data about
    the game situation.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, consider a financial services scenario. Say you have data about
    the company, such as its current stock price and earnings. By using code like
    that in [Figure 1-2](#ch01_figure_2_1748548870009198), you can calculate a valuable
    ratio called the *price-to-earnings ratio* (or P/E, which stands for price divided
    by earnings).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0102.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
- en: Figure 1-2\. Code in a financial services scenario
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Your code reads the price, reads the earnings, and returns a value that is the
    former divided by the latter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: If I were to try to sum up traditional programming like this in a single diagram,
    it might look like [Figure 1-3](#ch01_figure_3_1748548870009219).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0103.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
- en: Figure 1-3\. High-level view of traditional programming
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, you have rules expressed in a programming language. These rules
    act on data, and the result is answers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of Traditional Programming
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The model from [Figure 1-3](#ch01_figure_3_1748548870009219) has been the backbone
    of development since its inception. But it has an inherent limitation: namely,
    the only scenarios that you can implement are ones for which you can derive rules.
    But what about other scenarios? Usually, it’s unfeasible to develop them because
    the code is too complex. It’s just not possible to write code to handle them.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: Consider, for example, activity detection. Fitness monitors that can detect
    our activity are a recent innovation, not just because of the availability of
    cheap and small hardware but also because the algorithms to handle detection weren’t
    previously feasible. Let’s explore why.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 1-4](#ch01_figure_4_1748548870009237) shows a naive activity detection
    algorithm for walking. It can consider the person’s speed and if that speed is
    less than a particular value, we can determine that they are probably walking.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0104.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: Figure 1-4\. Algorithm for activity detection
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Given that our data is speed, we could also extend this to detect whether they
    are running, as in [Figure 1-5](#ch01_figure_5_1748548870009255).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0105.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
- en: Figure 1-5\. Extending the algorithm for running
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, going by the speed, we might say that if it is less than a particular
    value (say, 4 mph) the person is walking, and otherwise, they are running. It
    still sort of works.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Now, suppose we want to extend this to another popular fitness activity, biking.
    The algorithm could look like the one in [Figure 1-6](#ch01_figure_6_1748548870009270).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0106.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
- en: Figure 1-6\. Extending the algorithm for biking
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: I know this algorithm is naive in that it just detects speed—some people run
    faster than others, and you might run downhill faster than you can cycle uphill—but
    on the whole, it still works. However, what happens if we want to implement another
    scenario, such as golfing (see [Figure 1-7](#ch01_figure_7_1748548870009286))?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '![How do we write a golfing algorithm?](assets/aiml_0107.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
- en: Figure 1-7\. How do we write a golfing algorithm?
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now, we’re stuck. Whether a person is golfing or not, they might walk for a
    bit, stop, do some activity, walk for a bit more, stop, etc. So how can we use
    this methodology to tell whether they’re playing golf?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Our ability to detect this activity using traditional rules has hit a wall.
    But maybe there’s a better way.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Enter ML.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: From Programming to Learning
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s look back at the diagram that we used to demonstrate what traditional
    programming is (see [Figure 1-8](#ch01_figure_8_1748548870009301)). Here, we have
    rules that act on data and give us answers. In our activity detection scenario,
    the data was the speed at which the person was moving—and from that, we could
    write rules to detect their activity, be it walking, biking, or running. However,
    we hit a wall when it came to golfing because we couldn’t come up with rules to
    determine what that activity looks like.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0108.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Figure 1-8\. The traditional programming flow
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: But what would happen if we were to flip the axes around on this diagram? Instead
    of us coming up with the *rules*, what if we were to come up with the *answers*
    and, along with the data, have a way of figuring out what the rules might be?
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 1-9](#ch01_figure_9_1748548870009316) shows what this would look like,
    and we can say that this high-level diagram defines *machine learning*.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0109.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: Figure 1-9\. Changing the axes to get ML
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: So, what are the implications of this? Well, now, instead of *us* trying to
    figure out what the rules are, we can get lots of data about our scenario and
    label that data, and then the computer can figure out what the rules are that
    make one piece of data match a particular label and another piece of data match
    a different label.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: How would this work for our activity detection scenario? Well, we can look at
    all the sensors that give us data about this person. If the person has a wearable
    device that detects information such as heart rate, location, and speed—and if
    we collect a lot of instances of this data while they’re doing different activities—then
    we end up with a scenario of having data that says, “This is what walking looks
    like,” “This is what running looks like,” and so on (see [Figure 1-10](#ch01_figure_10_1748548870009331)).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![From coding to ML: gathering and labeling data](assets/aiml_0110.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1-10\. From coding to ML: gathering and labeling data'
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now, our job as programmers changes from figuring out the rules, to determining
    the activities, to writing the code that matches the data to the labels. If we
    can do this, then we can expand the scenarios that we can implement with code.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: ML is a technique that enables us to do this, but to get started, we’ll need
    a framework—that’s where TensorFlow enters the picture. In the next section, we’ll
    take a look at what TensorFlow is and how to install it. Then, later in this chapter,
    you’ll write your first code that learns the pattern between two values, like
    in the preceding scenario. It’s a simple “Hello World” scenario, but it has the
    same foundational code pattern that’s used in extremely complex ones.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: The field of AI is large and abstract, encompassing everything that has to do
    with making computers think and act the way human beings do. One of the ways a
    human takes on new behaviors is through learning by example, and the discipline
    of ML can thus be thought of as an on-ramp to the development of AI. By way of
    an ML field called *computer vision*, a machine can learn to see like a human,
    and by way of another ML field called *natural language processing*, it can learn
    to read text like a human. Many more such applications of ML are possible, and
    we’ll be covering the basics of ML in this book by using the TensorFlow framework.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能领域庞大而抽象，包括与使计算机像人类一样思考和行动有关的一切。人类采取新行为的一种方式是通过示例学习，因此可以将机器学习学科视为通往人工智能发展的途径。通过名为*计算机视觉*的ML领域，机器可以学会像人类一样看，通过名为*自然语言处理*的另一个ML领域，它可以学会像人类一样阅读文本。还有许多其他可能的ML应用，我们将通过使用TensorFlow框架来介绍ML的基础知识。
- en: What Is PyTorch?
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是PyTorch？
- en: PyTorch is an ML library that is based on a previous library called *Torch*,
    which is an open source ML framework and scripting language that is itself based
    on a programming language called Lua. In 2017, development of Torch moved to PyTorch,
    which is a port of the framework in Python.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是一个基于之前名为*Torch*的库的ML库，而*Torch*是一个开源的ML框架和脚本语言，它本身是基于名为Lua的编程语言。2017年，Torch的开发转移到了PyTorch，这是一个在Python中移植的框架。
- en: So, when installing PyTorch, you’ll often see it referred to as “torch.”
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当安装PyTorch时，您通常会看到它被称为“torch”。
- en: PyTorch was originally developed by Meta AI, but it was moved out to the Linux
    Foundation as a way of building developer confidence that it wasn’t made by and
    for a big tech company. It’s one of the two most popular ML libraries, alongside
    the TensorFlow/Keras ecosystem.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch最初由Meta AI开发，但它被移至Linux Foundation，作为建立开发者信心的一种方式，表明它不是由大型科技公司制作和为大型科技公司制作的。它是两个最受欢迎的ML库之一，与TensorFlow/Keras生态系统并列。
- en: With the emergence of generative AI, and in particular the “open sourcing” of
    generative text and image models, PyTorch has exploded in popularity. It’s often
    used for training models (which we cover in Part I of this book) as well as for
    inference of models (which we cover in Part II of this book).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式AI的出现，特别是生成文本和图像模型的“开源”，PyTorch在受欢迎程度上爆炸式增长。它通常用于训练模型（我们在本书的第一部分中介绍），以及用于模型的推理（我们在本书的第二部分中介绍）。
- en: 'PyTorch could also be seen as an ecosystem of libraries, each of which is tailored
    to specific scenarios. The important libraries and scenarios to consider are as
    follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch也可以被视为一个库生态系统，每个库都针对特定场景进行了定制。以下是一些重要的库和需要考虑的场景：
- en: TorchServe
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: TorchServe
- en: This is an easy-to-use tool that lets you deploy PyTorch models at scale. It’s
    designed to run in multiple environments, and it’s generally technology agnostic.
    It supports features such as multimodel serving, logging, metrics, and the easy
    creation of RESTful endpoints that let you do inference on models from a variety
    of clients.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个易于使用的工具，可以让您大规模部署PyTorch模型。它设计用于在多个环境中运行，并且通常是技术无关的。它支持多模型服务、日志记录、指标以及轻松创建RESTful端点，让您可以从各种客户端对模型进行推理。
- en: Distributed training
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式训练
- en: When larger models don’t fit onto a single chip or machine, there are technologies
    and techniques that allow you to share them across multiple devices. The `torch.distributed`
    libraries allow you easy and native support of asynchronous execution across multiple
    devices.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当较大的模型无法适应单个芯片或机器时，有一些技术和技术可以让您在多个设备之间共享它们。`torch.distributed`库允许您轻松且本地地在多个设备上支持异步执行。
- en: Mobile
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 移动
- en: An important surface for inference is, of course, mobile. It’s important for
    you to be able to deploy your AI work to Android and iOS devices, and PyTorch
    supports this through PyTorch Mobile.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对于推理来说，一个重要的表面当然是移动设备。您能够将AI工作部署到Android和iOS设备上非常重要，PyTorch通过PyTorch Mobile支持这一点。
- en: Pretrained models
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型
- en: An active community of researchers and developers have created a rich ecosystem
    of models that you can simply use with one line of code, wrapped in the torchvision.models
    library.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一群活跃的研究人员和开发者创建了一个丰富的模型生态系统，您只需一行代码即可使用，这些代码被包含在torchvision.models库中。
- en: '[Figure 1-11](#fig-1-11) provides a high-level representation of this.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-11](#fig-1-11)提供了这一概念的高级表示。'
- en: '![](assets/aiml_0111.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aiml_0111.png)'
- en: Figure 1-11\. PyTorch ecosystem
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-11\. PyTorch生态系统
- en: The process of creating ML models is called *training*, and it’s where a computer
    uses a set of algorithms to learn about inputs and what distinguishes them from
    one another. So, for example, if you want a computer to recognize cats and dogs,
    you can use lots of pictures of both to create a model, and the computer will
    use that model to try to figure out what makes a cat a cat and what makes a dog
    a dog. Once the model is trained, the process of having it recognize or categorize
    future inputs is called *inference*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 创建机器学习模型的过程称为**训练**，这是计算机使用一系列算法来了解输入以及它们之间区别的过程。例如，如果您想让计算机识别猫和狗，您可以使用大量两者的图片来创建模型，然后计算机将使用该模型来尝试找出什么使猫成为猫，什么使狗成为狗。一旦模型训练完成，让模型识别或分类未来输入的过程称为**推理**。
- en: 'So, for training models, there are several things that you need to consider,
    and we will cover them in this book. Primarily, your choice will boil down to
    one of three things:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于训练模型，您需要考虑几个方面，我们将在本书中介绍它们。主要来说，您的选择将归结为以下三个选项之一：
- en: Creating the model entirely from scratch yourself
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从头开始自己创建模型
- en: Using someone else’s model because it’s enough for your task
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用他人的模型，因为这对您的任务来说已经足够了
- en: Using parts of another person’s model that have already been trained and building
    on top of them
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用已经训练过的人的模型的部分，并在其基础上构建
- en: The last option on the list is called *transfer learning*, and we’ll cover it
    later in the book.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 列表中的最后一个选项被称为**迁移学习**，我们将在本书的后面部分介绍它。
- en: There are many ways to train a model. For the most part, you’ll probably just
    use a single chip, whether it’s a central processing unit (CPU), a graphics processing
    unit (GPU), or something new called a tensor processing unit (TPU). In more advanced
    working and research environments, you can use parallel training across multiple
    chips, employing a distributed training where training is intelligently spanned
    across multiple chips. PyTorch supports this, too, through “distributed training”
    libraries, as shown in [Figure 1-11](#fig-1-11).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型有许多方法。大多数情况下，您可能只会使用单个芯片，无论是中央处理器（CPU）、图形处理器（GPU）还是称为张量处理单元（TPU）的新设备。在更高级的工作和研究环境中，您可以使用跨多个芯片的并行训练，采用智能跨多个芯片的分布式训练。PyTorch也通过“分布式训练”库支持这一点，如图1-11所示。
- en: The lifeblood of any model is its data. As we discussed earlier, if you want
    to create a model that can recognize cats and dogs, you need to train it with
    lots of examples of cats and dogs. But how can you manage these examples? Over
    time, you’ll see that this can often involve a lot more coding than the creation
    of the models themselves.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 任何模型的命脉是其数据。正如我们之前讨论的，如果您想创建一个可以识别猫和狗的模型，您需要用大量猫和狗的示例来训练它。但您如何管理这些示例呢？随着时间的推移，您会发现这往往比创建模型本身需要更多的编码。
- en: But luckily, the PyTorch ecosystem includes a number of built-in datasets that
    make this easy for you. We will also explore these throughout this book.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，PyTorch生态系统包含了许多内置数据集，这使得对您来说变得非常容易。我们也会在本书中探讨这些内容。
- en: Beyond creating models, you’ll need to be able to get them into people’s hands
    so they can use them. To this end, PyTorch includes libraries for serving, where
    you can provide model inference over an HTTP connection for cloud or web users.
    For models to run on mobile or embedded systems, there’s PyTorch Mobile, which
    provides tools for model inference on Android and iOS.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 除了创建模型之外，您还需要能够将它们带给人们，让他们可以使用它们。为此，PyTorch包括用于服务的库，您可以通过HTTP连接提供模型推理，供云或网络用户使用。对于在移动或嵌入式系统上运行的模型，有PyTorch
    Mobile，它提供了在Android和iOS上进行模型推理的工具。
- en: Next, I’ll show you how to install PyTorch so that you can get started creating
    and using ML models with it!
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将向您展示如何安装PyTorch，这样您就可以开始使用它创建和使用机器学习模型了！
- en: Using PyTorch
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyTorch
- en: In this section, we’ll look at the three main ways you can install and use PyTorch.
    We’ll start with how to install it on your developer box using the command line.
    Then, we’ll explore using the popular PyCharm IDE to install and use PyTorch.
    Finally, we’ll look at Google Colab and how you can use it to access your PyTorch
    code with a cloud-based backend in your browser.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨您安装和使用PyTorch的三个主要方法。我们将从如何在您的开发箱上使用命令行安装它开始。然后，我们将探讨如何使用流行的PyCharm
    IDE来安装和使用PyTorch。最后，我们将探讨Google Colab以及如何使用它通过浏览器中的基于云的后端访问您的PyTorch代码。
- en: Installing Porch in Python
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Python中安装Porch
- en: The *Py* in PyTorch stands for Python, so it’s important to have a Python environment
    already set up. If you don’t have Python already, I strongly recommend you visit
    [the Python website](https://python.org) to get up and running with it and [the
    Learn Python website](https://learnpython.org) to learn the Python language syntax.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: With Python, there are many ways to install frameworks, but the default one
    supported by the TensorFlow team is `pip`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'So, in your Python environment, installing PyTorch is as easy as using this:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once you’re up and running, you can test your PyTorch version with the following
    code:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You should then see output like that in [Figure 1-12](#ch01_figure_12_1748548870009360).
    It will print the currently running version of PyTorch—here, you can see that
    version 2.4.1 is installed.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0112.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
- en: Figure 1-12\. Running PyTorch in Python
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you look closely at [Figure 1-12](#ch01_figure_12_1748548870009360), you’ll
    see a note that shows that the torch device is “cpu.” In this case, I natively
    installed it on my Mac, and it is configured to use the CPU. However, this is
    not optimal for complex models, where an accelerator like a GPU or Metal may be
    necessary. We will cover installation of PyTorch for accelerators later in this
    book.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Using PyTorch in PyCharm
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I’m particularly fond of using the [free community version of PyCharm](https://oreil.ly/I2mP2)
    for building models using PyTorch. PyCharm is useful for many reasons, but one
    of my favorites is that it makes the management of virtual environments easy.
    This means you can have Python environments with versions of tools such as PyTorch
    that are specific to your particular project. So, for example, if you want to
    use PyTorch 1.x in one project and PyTorch 2.x in another, you can separate them
    with virtual environments and not have to deal with installing/uninstalling dependencies
    when you switch between them. Additionally, with PyCharm, you can do step-by-step
    debugging of your Python code—which is a must, especially if you’re just getting
    started!
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: For example, in [Figure 1-13](#ch01_figure_13_1748548870009375), I have a new
    project that’s called *example1*, and I’m specifying that I’m going to create
    a new environment using Conda. When I create the project, I’ll have a clean, new,
    virtual Python environment into which I can install any version of PyTorch I want.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you’ve created a project, you can open the File → Settings dialog and
    choose the entry for “Project: *<your project name>*” from the menu on the left.
    In the menu on the left, you’ll see choices to change the settings for the Python
    Interpreter and the Project Structure. If you choose the Python Interpreter link,
    you’ll see the interpreter that you’re using, as well as a list of packages that
    are installed in this virtual environment (see [Figure 1-14](#ch01_figure_14_1748548870009389)).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0113.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
- en: Figure 1-13\. Creating a new virtual environment using PyCharm
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![](assets/aiml_0114.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
- en: Figure 1-14\. Adding packages to a virtual environment
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can then click the + button at the upper left, and a dialog will open showing
    the packages that are currently available. Type **`torch`** into the search box
    and you’ll see all available packages with *torch* in the name (see [Figure 1-15](#ch01_figure_15_1748548870009404)).
    Remember that the name of the package is *torch*, even if the technology is PyTorch.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0115.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
- en: Figure 1-15\. Installing torch with PyCharm
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Once you’ve selected torch or any other package you want to install, you can
    click the Install Package button and PyCharm will do the rest. Then, once torch
    is installed, you can write and debug your PyTorch code in Python.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Using PyTorch in Google Colab
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another option, perhaps the easiest one for getting started, is to use [*Google
    Colab*](https://oreil.ly/c0lab), which is a hosted Python environment that you
    can access via a browser. What’s really neat about Colab is that it provides GPU
    and TPU backends so you can train models using state-of-the-art hardware at no
    cost.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: When you visit the Colab website, you’ll be given the option to open previous
    Colabs or start a new notebook (see [Figure 1-16](#ch01_figure_16_1748548870009418)).
    If you click the + New notebook button, it will open the editor, where you can
    add panes of code or text (see [Figure 1-17](#ch01_figure_17_1748548870009451)).
    You ⁠ can then execute the code by clicking the Play button (the arrow) to the
    left of the pane.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0116.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
- en: Figure 1-16\. Getting started with Google Colab
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![](assets/aiml_0117.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: Figure 1-17\. Running PyTorch code in Colab
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It’s always a good idea to check the PyTorch version, as shown here, to be sure
    you’re running the correct version for the task at hand.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: You can also see that in [Figure 1-17](#ch01_figure_17_1748548870009451) the
    version shown is 2.4.1+cu121, and you might want to know what the *cu121* part
    is! The *cu* stands for *Cuda*, which is Nvidia’s library for accelerated ML on
    GPUs. So, the preceding message demonstrates that PyTorch 2.4.1 is installed,
    along with accelerators for Cuda version 12.1.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: 'Often, Colab’s built-in versions of various libraries, including PyTorch, will
    be a version or two behind the latest release. If that’s the case, you can update
    it with `pip install` as shown earlier, by simply using a block of code like this,
    where you specify the desired version:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Once you run this command, your current environment within Colab will use the
    desired version of PyTorch. However, you should be careful when doing this in
    Colab because the version of PyTorch you change to may not have Cuda drivers installed,
    meaning you could downgrade to using the CPU.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started with Machine Learning
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw earlier in the chapter, the ML paradigm is one in which you have data,
    that data is labeled, and you want to figure out the rules that match the data
    to the labels. The simplest possible scenario to show this in code is as follows.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider these two sets of numbers:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: There’s a relationship between the *x* and *y* values (for example, if *x* is
    –1, then *y* is –3; if *x* is 3, then *y* is 5; and so on). Can you see it?
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: After a few seconds, you probably saw that the pattern here is *y* = 2*x* –
    1\. How did you get that? Different people work it out in different ways, but
    I typically hear the observation that *x* increases by 1 in its sequence and *y*
    increases by 2; thus, *y* = 2*x* +/– something. Then, they look at when *x* =
    0 and see that *y* = –1, so they figure that the answer could be *y* = 2*x* –
    1\. Next, they look at the other values and see that this hypothesis “fits,” and
    the answer is *y* = 2*x* – 1.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: That’s very similar to the ML process. Let’s take a look at some code that you
    could write to have a neural network figure this out for you.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the full code, using PyTorch. Don’t worry if it doesn’t make sense yet;
    we’ll go through it line by line:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The first few lines are the importers that ensure the correct libraries are
    available, so let’s jump to this line:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You’ve probably heard of neural networks, and you’ve probably seen diagrams
    that explain them by using layers of interconnected neurons, a little like in
    [Figure 1-18](#ch01_figure_18_1748548870009467).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0118.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: Figure 1-18\. A typical neural network
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'When you see a neural network like this, you should consider each of the circles
    to be a *neuron* and each of the columns of circles to be a *layer*. So, in [Figure 1-18](#ch01_figure_18_1748548870009467),
    there are three layers: the first has five neurons, the second has four, and the
    third has two.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: These layers are organized in a sequence through which the data flows from left
    to right.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if we look back at our code, you’ll see that we’re defining a sequence
    of something, with what’s contained in the brackets being the definition of the
    sequence:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When using PyTorch, you define your layers by using a `Sequential`, and inside
    the `Sequential`, you then specify what each layer looks like. We have only one
    line inside our `Sequential`, so the neural network this code defines will have
    only one layer.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Then, you define what the layer looks like by using the `torch.nn` libraries.
    There are lots of different layer types, but here, we’re using a `Linear` layer,
    in which a linear relationship (where the definition of a line is *y* = *wx* +
    *b*) can be defined or learned.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Our `Linear` layer has the (1,1) parameters specified, which indicates one feature
    “in” and one feature “out.” So ultimately, we have just one layer with one neuron
    in our entire neural network.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: In other words, the Sequential containing a Linear with the parameters (1,1)
    ultimately looks like [Figure 1-19](#ch01_figure_19_1748548870009483).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0119.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
- en: Figure 1-19\. A neural network with one layer, containing one neuron
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The next lines are where the fun really begins. Let’s look at them again:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If you’ve done anything with ML before, you’ve probably seen that it involves
    a lot of mathematics—and if you haven’t done calculus in years, it might have
    seemed like a barrier to entry. Here’s the part where the math comes in—it’s the
    core of ML.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: In a scenario such as this one, the computer has *no idea* what the relationship
    between *x* and *y* is. So, it will make a guess. Say, for example, it guesses
    that *y* = 10*x* + 10\. Then, it needs to measure how good or how bad that guess
    is—and that’s the job of the *loss function*.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: The computer already knows the answers when *x* is –1, 0, 1, 2, 3, and 4, so
    the loss function can compare these to the answers for the guessed relationship.
    If it guessed *y* = 10*x* + 10, then when *x* is –1, *y* will be 0\. However,
    the correct answer there was –3, so it’s a bit off. But when *x* is 4, the guessed
    answer is 50, whereas the correct one is 7\. That’s really far off.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Armed with this knowledge, the computer can then make another guess. That’s
    the job of the *optimizer*. This is where the heavy calculus is used, but with
    PyTorch, that can be hidden from you. You just pick the appropriate optimizer
    to use for different scenarios. In this case, we picked one called `sgd`, which
    stands for *stochastic gradient descent*—a complex mathematical function that,
    when given the values, the previous guess, and the results of calculating the
    errors (or loss) on that guess, can then generate another guess. Over time, its
    job is to minimize the loss, and by doing so bring the guessed formula closer
    and closer to the correct answer.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we simply format our numbers into the data format that the layers expect:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You’ll see the word *tensor* a lot in ML; it gives the TensorFlow framework
    its name. Think of a tensor as a way of storing data that’s like an array that
    is optimized for flexibility in array size. To have PyTorch understand our data,
    we will load the values into tensors representing the *x* and *y* values.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'The *learning* process will then begin with the training loop like this:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: If you’re new to ML, this is probably the most difficult part to understand,
    so let’s go through it line by line.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the ML process looks like [Figure 1-20](#ch01_figure_20_1748548870009497).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0120.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
- en: Figure 1-20\. The ML process
  id: totrans-156
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'So, the preceding code implements this as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This line reads as “zero the gradients” of the optimizer. The calculus of learning
    involves navigating down a curve to find its minimum, and to do that, we need
    the gradient of the curve. The curve is calculated when we measure our accuracy,
    so we need to reset it at the beginning of each loop:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This line creates an array of the outputs that we calculate for the input *x*
    values. Even though we have given the computer the *correct* answers in our *Y*
    array, we want to measure the accuracy of the guess that the computer has made
    for the parameters defining this line. The first time through the loop, the *w*
    and *b* parameters within the neuron will be randomly initialized, so our guess
    might be *Y* = 10*x* + 10, for example:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This line then compares the outputs (aka our guesses) with the correct answers
    to calculate the *loss*—which is effectively a value that tells us how good or
    bad the guess is:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This line is the essential part of the learning process where a process called
    *backpropagation* happens. It’s where the math from the optimizer and the loss
    function combine to figure out the gradients for the new set of parameters. In
    our case, the error from *Y* = 10*x* + 10 is really high and not even close to
    our desired values, so the calculations done in figuring out the loss will give
    us a *direction* or gradient in which we should go to get closer to our desired
    results:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This line of code finishes the job by updating the model parameters to the values
    based on the gradients calculated in the preceding backpropagation step.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: We then repeat this process five hundred times, with the goal of finding a set
    of parameters for our single neuron that will give us *y* values that are close
    to our desired *y* values. If the set of parameters does so, it can then infer
    the *y* value for *x* values that the computer has never previously seen. Thus,
    it will have learned the relationship between the *x* and *y* values we provided.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 1-21](#ch01_figure_21_1748548870009510) shows a screenshot of this
    running in a Colab notebook. Take a look at the loss values over time.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0121.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
- en: Figure 1-21\. Training the neural network
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can see that over the first 10 epochs, the loss went from 5.64 to 0.86\.
    That is, after only 10 tries, the network was performing about six times better
    than with its initial guess.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Then take a look at what happens by the 500th epoch (see [Figure 1-22](#ch01_figure_22_1748548870009531)).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aiml_0122.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
- en: Figure 1-22\. Training the neural network—the last few epochs
  id: totrans-175
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can now see that the loss is 9.52 × 10^(-6). The loss has gotten so small
    that the model has pretty much figured out that the relationship between the numbers
    is *y* = 2*x* – 1\. This means that the *machine* has *learned* the pattern between
    them.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want our neural network to try to predict a new value, we can use code
    like this:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note
  id: totrans-179
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The term *prediction* is typically used when dealing with ML models—but don’t
    think of it as looking into the future! We use this term because we’re dealing
    with a certain amount of uncertainty. Think back to the activity detection scenario
    we spoke about earlier. When the person was moving at a certain speed, she was
    *probably* walking. Similarly, when a model learns about the patterns that exist
    between two things, it will tell us what the answer *probably* is. In other words,
    it is *predicting* the answer. (Later, you’ll also learn about *inference*, in
    which the model picks one answer among many and *infers* that it has picked the
    correct one.)
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: What do you think the answer will be when we ask the model to predict *y* when
    *x* is 10? You might instantly think 19, but that’s not correct. The model will
    pick a value *very close* to 19, and there are several reasons for this. First
    of all, our loss wasn’t 0\. It was a very small amount, so we should expect any
    predicted answer to be off by a very small amount. Second, the neural network
    is trained on only a small amount of data—and in this case, it’s only six pairs
    of (*x*, *y*) values.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: The model only has a single neuron in it, and that neuron learns a *weight*
    and a *bias* so that *y* = *wx* + *b*. This looks exactly like the desired *y*
    = 2*x* – 1 relationship, in which we want the model to learn that *w* = 2 and
    *b* = –1\. Given that the model was trained on only six items of data, we’d never
    expect the answer to be exactly these values; instead, we’d expect it to be something
    very close to them.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, run the code for yourself to see what you get. I got 18.991 when I ran
    it, but your answer may differ slightly because when the neural network is first
    initialized, there’s a random element: your initial guess will be slightly different
    from mine and from a third person’s.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Seeing What the Network Learned
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is obviously a very simple scenario in which we are matching *x’*s to *y’*s
    in a linear relationship. As mentioned in the previous section, neurons have weight
    and bias parameters. That makes a single neuron fine for learning a relationship
    like this; namely, when *y* = 2*x* – 1, the weight is 2 and the bias is –1.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: 'With PyTorch, we can actually take a look at the weights and biases that are
    learned, with code like this:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Once the network finishes learning, you can print out the values (or weights)
    that the layer learned. In my case, the output was as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Thus, the learned relationship between *x* and *y* was *y* = 1.998695 *x* –
    0.9959542.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: This is pretty close to what we’d expect (*y* = 2*x* – 1), and we could argue
    that it’s even closer to reality because we’re *assuming* that the relationship
    will hold for other values!
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: That’s it for your first “Hello World” of ML. You might be thinking that this
    seems like massive overkill for something as simple as determining a linear relationship
    between two values—and you’d be right. But the cool thing about this is that the
    pattern of code we’ve created here is the same pattern that’s used for far more
    complex scenarios. You’ll see those scenarios starting in [Chapter 2](ch02.html#ch02_introduction_to_computer_vision_1748548889076080),
    where we’ll explore some basic computer vision techniques—in which the machine
    will learn to “see” patterns in pictures and identify what’s in them!
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你的第一个机器学习“Hello World”。你可能觉得这好像是对如此简单的事情——确定两个值之间的线性关系——过度杀鸡用牛刀——你是对的。但有趣的是，我们在这里创建的代码模式与用于更复杂场景的模式是相同的。你将在[第二章](ch02.html#ch02_introduction_to_computer_vision_1748548889076080)中看到这些场景，我们将探讨一些基本的计算机视觉技术——在这些技术中，机器将学会“看到”图片中的模式并识别其中的内容！
