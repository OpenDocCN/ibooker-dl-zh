["```py\nfrom rouge_score import rouge_scorer\n\ntarget = \"The game 'The Legend of Zelda' follows the adventures of the \\\n    hero Link in the magical world of Hyrule.\"\nprediction = \"Link embarks on epic quests and battles evil forces to \\\n    save Princess Zelda and restore peace in the land of Hyrule.\"\n\nscorer = rouge_scorer.RougeScorer([\"rouge1\", \"rougeL\"], use_stemmer=True)   #1\nscores = scorer.score(target, prediction)\nprint(scores)\n# {'rouge1': Score(precision=0.28571428, recall=0.31578947, fmeasure=0.3),\n# 'rougeL': Score(precision=0.238095238, recall=0.26315789, fmeasure=0.25)}\n```", "```py\nimport nltk.translate.bleu_score as bleu\n\ntarget = [\n    \"The game 'The Legend of Zelda' follows the adventures of the \\\n    hero Link in the magical world of Hyrule.\".split(),\n    \"Link goes on awesome quests and battles evil forces to \\\n    save Princess Zelda and restore peace to Hyrule.\".split(),\n]\nprediction = \"Link embarks on epic quests and battles evil forces to \\\n    save Princess Zelda and restore peace in the land of Hyrule.\".split()\n\nscore = bleu.sentence_bleu(target, prediction)\nprint(score)\n# 0.6187934993051339\n```", "```py\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\ndataset = load_dataset(\"super_glue\", \"multirc\", split=\"validation\")    print(dataset[0]) #1\n```", "```py\n# {\n#   \"paragraph\": \"What causes a change in motion? The application of a force.\"\n#     \" Any time an object changes motion, a force has been applied. In what \"\n#     \"ways can this happen? Force can cause an object at rest to start \"\n#     \"moving. Forces can cause objects to speed up or slow down. Forces can \"\n#     \"cause a moving object to stop. Forces can also cause a change in \"\n#     \"direction. In short, forces cause changes in motion. The moving \"\n#     \"object may change its speed, its direction, or both. We know that \"\n#     \"changes in motion require a force. We know that the size of the force \"\n#     \"determines the change in motion. How much an objects motion changes \"\n#     \"when a force is applied depends on two things. It depends on the \"\n#     \"strength of the force. It also depends on the objects mass. Think \"\n#     \"about some simple tasks you may regularly do. You may pick up a \"\n#     \"baseball. This requires only a very small force. \",\n#   \"question\": \"Would the mass of a baseball affect how much force you have \"\n#     \"to use to pick it up?\",\n#   \"answer\": \"No\",\n#   \"idx\": {\"paragraph\": 0, \"question\": 0, \"answer\": 0},\n#   \"label\": 0,\n# }\n```", "```py\nmodel = \"bigscience/bloomz-560m\"  # Update with your model of choice\n\ntokenizer = AutoTokenizer.from_pretrained(model)\nmodel = AutoModelForCausalLM.from_pretrained(model)\n\nfor row in dataset:\n    input_text = (\n        f'Paragraph: {row[\"paragraph\"]}\\nQuestion: {row[\"question\"]}'\n    )                                                                    #1\n    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n\n    outputs = model.generate(input_ids, max_new_tokens=20)\n    input_length = input_ids.shape[1]                        #2\n    results = tokenizer.decode(outputs[0][input_length:])\n    print(row[\"answer\"])\n    print(results)\n```", "```py\n# No\n#  No</s>\n# Yes\n#  No</s>\n# Less the mass, less the force applied\n#  No</s>\n# It depends on the shape of the baseball\n#  No</s>\n# Strength\n#  Force</s>\n# A force\n#  Force</s>\n# No\n#  Yes</s>\n```", "```py\nfrom deepeval.benchmarks import MMLU\nfrom deepeval.benchmarks.tasks import MMLUTask\nfrom deepeval.models.base_model import DeepEvalBaseLLM\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nclass DeepEvalLLM(DeepEvalBaseLLM):             #1\n    def __init__(self, model, tokenizer, name):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.name = name\n\n        device = torch.device(\n            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        )\n\n        self.model.to(device)\n        self.device = device\n    def load_model(self):\n        return self.model\n\n    def generate(self, prompt: str) -> str:\n        model = self.load_model()\n        model_inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(\n            self.device\n        )\n\n        generated_ids = model.generate(\n            **model_inputs, max_new_tokens=100, do_sample=True\n        )\n        return self.tokenizer.batch_decode(generated_ids)[0]\n\n    async def a_generate(self, prompt: str) -> str:\n        return self.generate(prompt)\n\n    def get_model_name(self):\n        return self.name\n\nmodel = AutoModelForCausalLM.from_pretrained(\"gpt2\")\ntokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n\ngpt2 = DeepEvalLLM(model=model, tokenizer=tokenizer, name=\"GPT-2\")\n\nbenchmark = MMLU(                                                       #2\n    tasks=[MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE, MMLUTask.ASTRONOMY],\n    n_shots=3,\n)\n\nbenchmark.evaluate(model=gpt2)     #3\nprint(benchmark.overall_score)\n# MMLU Task Accuracy (task=high_school_computer_science): 0.0\n# MMLU Task Accuracy (task=astronomy): 0.0\n# Overall MMLU Accuracy: 0.0\n```", "```py\nimport evaluate\nhonest = evaluate.load('honest', 'en')\nprompts = [\"he is a\", \"he is\", \"she is a\", \"she is\"]\ncompletions = [['CEO', 'businessman', 'father'], \n               ['good', 'excellent', 'smart'], \n               ['secretary', 'prostitute', 'maid'], \n               ['beautiful', 'smart', 'tall']]\ngroups = [\"male\", \"male\", \"female\", \"female\"]\nresult = honest.compute(predictions=completions, groups=groups)\nprint(result)\n# {'honest_score_per_group': {'male': 0.0, 'female': 0.16667}}\n```", "```py\nimport torch\nfrom transformers import pipeline\nfrom datasets import Dataset, load_dataset\nfrom evaluate import evaluator\nimport evaluate\nimport pandas as pd\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\npipe = pipeline(\"text-generation\", model=\"gpt2\", device=device)    #1\nwino_bias = load_dataset(\"sasha/wino_bias_prompt1\", split=\"test\")\npolarity = evaluate.load(\"regard\")\ntask_evaluator = evaluator(\"text-generation\")\n\ndef prepare_dataset(wino_bias, pronoun):     #2\n    data = wino_bias.filter(\n        lambda example: example[\"bias_pronoun\"] == pronoun\n    ).shuffle()\n    df = data.to_pandas()\n    df[\"prompts\"] = df[\"prompt_phrase\"] + \" \" + df[\"bias_pronoun\"]\n    return Dataset.from_pandas(df)\n\nfemale_prompts = prepare_dataset(wino_bias, \"she\")\nmale_prompts = prepare_dataset(wino_bias, \"he\")\n\nfemale_results = task_evaluator.compute(\n    model_or_pipeline=pipe,\n    data=female_prompts,\n    input_column=\"prompts\",\n    metric=polarity,\n)                                #3\nmale_results = task_evaluator.compute(\n    model_or_pipeline=pipe,\n    data=male_prompts,\n    input_column=\"prompts\",\n    metric=polarity,\n)\n\ndef flatten_results(results):     #4\n    flattened_results = []\n    for result in results[\"regard\"]:\n        item_dict = {}\n        for item in result:\n            item_dict[item[\"label\"]] = item[\"score\"]\n        flattened_results.append(item_dict)\n\n    return pd.DataFrame(flattened_results)\n\nprint(flatten_results(female_results).mean())      #5\n# Prints the mean polarity scores\n# positive    0.129005\n# negative    0.391423\n# neutral     0.331425\n# other       0.148147\n\nprint(flatten_results(male_results).mean())       #5\n# Positive    0.118647\n# negative    0.406649\n# neutral     0.322766\n# other       0.151938\n```", "```py\nimport evaluate\n\nsquad_metric = evaluate.load(\"squad\")      #1\npredictions = [\n    {\"prediction_text\": \"Saint Bernadette\", \"id\": \"5733be284776f41900661182\"},\n    {\"prediction_text\": \"Salma Hayek\", \"id\": \"56d4fa2e2ccc5a1400d833cd\"},\n    {\"prediction_text\": \"1000 MB\", \"id\": \"57062c2552bb89140068992c\"},\n]                           #2\nreferences = [\n    {\n        \"answers\": {\n            \"text\": [\"Saint Bernadette Soubirous\"],\n            \"answer_start\": [515],\n        },\n        \"id\": \"5733be284776f41900661182\",\n    },\n    {\n        \"answers\": {\n            \"text\": [\"Salma Hayek and Frida Giannini\"],\n            \"answer_start\": [533],\n        },\n        \"id\": \"56d4fa2e2ccc5a1400d833cd\",\n    },\n    {\n        \"answers\": {\"text\": [\"1000 MB\"], \"answer_start\": [437]},\n        \"id\": \"57062c2552bb89140068992c\",\n    },\n]\nresults = squad_metric.compute(\n    predictions=predictions, references=references\n)\nprint(results)\n# {'exact_match': 33.333333333333336, 'f1': 79.04761904761905}\n```", "```py\n''' fibonacci.py\ndef fibonacci_sequence(n):\n    \"\"\"Returns the nth number in the Fibonacci sequence\"\"\"\n'''\n\nimport pytest\nimport time\nfrom fibonacci import fibonacci_sequence\n\ndef test_fibonacci_sequence():\n    test_cases = [(1, 0), (2, 1), (6, 5), (15, 377)]\n\n    for n, expected in test_cases:\n        result = fibonacci_sequence(n)\n        assert (\n            result == expected\n        ), f\"Expected {expected}, but got {result} for n={n}.\"\n\n    with pytest.raises(ValueError):\n        fibonacci_sequence(-1)\n\nif __name__ == \"__main__\":      #1\n    start_time = time.time()\n    pytest.main([\"-v\"])\n    end_time = time.time()\n    execution_time = end_time - start_time\n    print(f\"Execution time: {execution_time} seconds\")\n```", "```py\nimport weightwatcher as ww\nfrom transformers import GPT2Model\n\ngpt2_model = GPT2Model.from_pretrained(\"gpt2\")\ngpt2_model.eval()\n\nwatcher = ww.WeightWatcher(model=gpt2_model)\ndetails = watcher.analyze(plot=False)\nprint(details.head())\n```", "```py\n   layer_id       name         D  ...      warning        xmax        xmin\n\n0         2  Embedding  0.076190  ... over-trained 3837.188332    0.003564\n1         8     Conv1D  0.060738  ...              2002.124419  108.881419\n2         9     Conv1D  0.037382  ...               712.127195   46.092445\n3        14     Conv1D  0.042383  ...              1772.850274   95.358278\n4        15     Conv1D  0.062197  ...               626.655218   23.727908\n```", "```py\nprint(enc.encode(“4523646 minus 67453156”))\n[21098, 15951, 21, 28382, 220, 25513, 20823, 3487]\n```", "```py\nimport os\nfrom pathlib import Path\n\nimport transformers\nfrom tokenizers import ByteLevelBPETokenizer, SentencePieceBPETokenizer\nfrom tokenizers.processors import BertProcessing\n\npaths = [str(x) for x in Path(\"./data/\").glob(\"**/*.txt\")]      #1\nbpe_tokenizer = ByteLevelBPETokenizer()   #2\n\nbpe_tokenizer.train(                      #2\n    files=paths,                          #2\n    vocab_size=52_000,                    #2\n    min_frequency=2,                      #2\n    show_progress=True,                   #2\n    special_tokens=[                      #2\n        \"<s>\",                            #2\n        \"<pad>\",                          #2\n        \"</s>\",                           #2\n        \"<unk>\",                          #2\n        \"<mask>\",                         #2\n    ], #2\n) #2\n\ntoken_dir = \"./chapters/chapter_4/tokenizers/bytelevelbpe/\"\nif not os.path.exists(token_dir):\n    os.makedirs(token_dir)\nbpe_tokenizer.save_model(token_dir)\n\nbpe_tokenizer = ByteLevelBPETokenizer(\n    f\"{token_dir}vocab.json\",\n    f\"{token_dir}merges.txt\",\n)\n\nexample_text = \"This sentence is getting encoded by a tokenizer.\"\nprint(bpe_tokenizer.encode(example_text).tokens)  \n# ['This', 'Ġsentence', 'Ġis', 'Ġgetting', 'Ġenc', \\\n# 'oded', 'Ġby', 'Ġa', 'Ġto', 'ken', 'izer', '.']\nprint(bpe_tokenizer.encode(example_text).ids)\n# [2666, 5651, 342, 1875, 4650, 10010, 504, 265, \\ \n# 285, 1507, 13035, 18]\n\nbpe_tokenizer._tokenizer.post_processor = BertProcessing(\n    (\"</s>\", bpe_tokenizer.token_to_id(\"</s>\")),\n    (\"<s>\", bpe_tokenizer.token_to_id(\"<s>\")),\n)\nbpe_tokenizer.enable_truncation(max_length=512)\n\nspecial_tokens = [\n    \"<s>\",\n    \"<pad>\",\n    \"</s>\",\n    \"<unk>\",\n    \"<cls>\",\n    \"<sep>\",\n    \"<mask>\",\n]\nsentencepiece_tokenizer = SentencePieceBPETokenizer()    #3\n\nsentencepiece_tokenizer.train(                           #3\n    files=paths,                                         #3\n    vocab_size=4000,                                     #3\n    min_frequency=2,                                     #3\n    show_progress=True,                                  #3\n    special_tokens=special_tokens,                       #3\n) #3\n\ntoken_dir = \"./chapters/chapter_4/tokenizers/sentencepiece/\"\nif not os.path.exists(token_dir):\n    os.makedirs(token_dir)\nsentencepiece_tokenizer.save_model(token_dir)\n\ntokenizer = transformers.PreTrainedTokenizerFast(\n    tokenizer_object=sentencepiece_tokenizer,\n    model_max_length=512,\n    special_tokens=special_tokens,\n)                                     #4\ntokenizer.bos_token = \"<s>\"\ntokenizer.bos_token_id = sentencepiece_tokenizer.token_to_id(\"<s>\")\ntokenizer.pad_token = \"<pad>\"\ntokenizer.pad_token_id = sentencepiece_tokenizer.token_to_id(\"<pad>\")\ntokenizer.eos_token = \"</s>\"\ntokenizer.eos_token_id = sentencepiece_tokenizer.token_to_id(\"</s>\")\ntokenizer.unk_token = \"<unk>\"\ntokenizer.unk_token_id = sentencepiece_tokenizer.token_to_id(\"<unk>\")\ntokenizer.cls_token = \"<cls>\"\ntokenizer.cls_token_id = sentencepiece_tokenizer.token_to_id(\"<cls>\")\ntokenizer.sep_token = \"<sep>\"\ntokenizer.sep_token_id = sentencepiece_tokenizer.token_to_id(\"<sep>\")\ntokenizer.mask_token = \"<mask>\"\ntokenizer.mask_token_id = sentencepiece_tokenizer.token_to_id(\"<mask>\")\ntokenizer.save_pretrained(token_dir)   #5\n\nprint(tokenizer.tokenize(example_text))\n# ['_This', '_s', 'ent', 'ence', '_is', '_', 'g', 'et', 'tin', 'g', '_'\n# 'en', 'co', 'd', 'ed', '_', 'b', 'y', '_a', '_', 't', 'ok', 'en', \n# 'iz', 'er', '.']\n\nprint(tokenizer.encode(example_text))\n# [814, 1640, 609, 203, 1810, 623, 70, \\\n# 351, 148, 371, 125, 146, 2402, 959, 632]\n```", "```py\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\nfrom datasets import load_dataset\n\nmodel_ckpt = \"sentence-transformers/all-MiniLM-L6-v2\"     #1\nmodel = SentenceTransformer(model_ckpt)\nembs_train = load_dataset(\"tweet_eval\", \"emoji\", split=\"train[:1000]\")\nembs_test = load_dataset(\"tweet_eval\", \"emoji\", split=\"test[:100]\")\n\ndef embed_text(example):                    #2\n    embedding = model.encode(example[\"text\"])\n    return {\"embedding\": np.array(embedding, dtype=np.float32)}\n\nprint(f\"Train 1: {embs_train[0]}\")\nembs_train = embs_train.map(embed_text, batched=False)\nembs_test = embs_test.map(embed_text, batched=False)\n\nembs_train.add_faiss_index(\"embedding\")                 #3\n\n# \nidx, knn = 1, 3  # Select the first query and 3 nearest neighbors    #4\n\nquery = np.array(embs_test[idx][\"embedding\"], dtype=np.float32)\nscores, samples = embs_train.get_nearest_examples(\"embedding\", query, k=knn)\n\nprint(f\"QUERY LABEL: {embs_test[idx]['label']}\")                #5\nprint(f\"QUERY TEXT: {embs_test[idx]['text'][:200]} [...]\\n\")\nprint(\"=\" * 50)\nprint(\"Retrieved Documents:\")\nfor score, label, text in zip(scores, samples[\"label\"], samples[\"text\"]):\n    print(\"=\" * 50)\n    print(f\"TEXT:\\n{text[:200]} [...]\")\n    print(f\"SCORE: {score:.2f}\")\n    print(f\"LABEL: {label}\")\n```", "```py\nimport slack_sdk\nimport pandas\n\ntoken_slack = \"Your Token Here\"\nclient = slack_sdk.WebClient(token=token_slack)\n\nauth = client.auth_test()\nself_user = auth[\"user_id\"]\n\ndm_channels_response = client.conversations_list(types=\"im\")\n\nall_messages = {}\n\nfor channel in dm_channels_response[\"channels\"]:\n    history_response = client.conversations_history(channel=channel[\"id\"])\n    all_messages[channel[\"id\"]] = history_response[\"messages\"]\n\ntxts = []\n\nfor channel_id, messages in all_messages.items():\n    for message in messages:\n        try:\n            text = message[\"text\"]\n            user = message[\"user\"]\n            timestamp = message[\"ts\"]\n            txts.append([timestamp, user, text])\n        except Exception:\n            pass\n\nslack_dataset = pandas.DataFrame(txts)\nslack_dataset.columns = [\"timestamp\", \"user\", \"text\"]\ndf = slack_dataset[slack_dataset.user == self_user]\n\ndf[[\"text\"]].to_parquet(\"slack_dataset.gzip\", compression=\"gzip\")\n```"]