- en: '7 Function approximation: How neural networks model the world'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 函数近似：神经网络如何模拟世界
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Expressing real-world problems as mathematical functions
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将现实世界问题表达为数学函数
- en: Understanding the building blocks of a neural network
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解神经网络的基本构建块
- en: Approximating functions via neural networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过神经网络近似函数
- en: Computing to date has been dominated by the von Neumann architecture in which
    the processor and the program are separate. The program sits in memory and is
    fetched and executed by the processor. The advantage of this approach is that
    different programs solving unrelated problems can be loaded into memory, and the
    same processor can execute them. But neural networks have a fundamentally different
    architecture. There are no separate processors and programs; instead, there is
    a single entity called, well, the neural network, which can run on dedicated hardware
    or a Von Neumann computer. In this chapter, we discuss this paradigm in detail.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，计算一直由冯·诺伊曼架构主导，其中处理器和程序是分开的。程序存储在内存中，由处理器取回并执行。这种方法的优点是，可以加载内存中解决不同问题的不同程序，并且相同的处理器可以执行它们。但神经网络具有根本不同的架构。没有独立的处理器和程序；相反，有一个单一的实体，称为神经网络，它可以在专用硬件或冯·诺伊曼计算机上运行。在本章中，我们将详细讨论这一范式。
- en: NOTE The complete PyTorch code for this chapter is available at [http://mng.bz/K4zj](http://mng.bz/K4zj)
    in the form of fully functional and executable Jupyter notebooks.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本章的完整PyTorch代码以功能齐全和可执行的Jupyter笔记本形式，可在[http://mng.bz/K4zj](http://mng.bz/K4zj)找到。
- en: '7.1 Neural networks: A 10,000-foot view'
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 神经网络：从10,000英尺的高度看
- en: 'In section [1.7](../Text/01.xhtml#sec-multi-layered-nn), we provided an overview
    of neural networks. (You may want to do a quick refresher on chapter [1](../Text/01.xhtml#chap-overview)
    at this point.) There we indicated that most intelligent tasks performed by humans
    can be expressed in terms of mathematical functions that we will refer to as *target
    functions*. So, to develop machines that perform intelligent tasks, we need to
    have machines that model target functions. While that gives us hope of developing
    automated solutions, we are hobbled by two serious difficulties:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在[1.7](../Text/01.xhtml#sec-multi-layered-nn)节中，我们概述了神经网络。 (此时，你可能想快速复习一下[1](../Text/01.xhtml#chap-overview)章。)
    我们指出，人类执行的大多数智能任务都可以用我们称之为*目标函数*的数学函数来表示。因此，为了开发执行智能任务的机器，我们需要拥有能够模拟目标函数的机器。虽然这让我们对开发自动化解决方案抱有希望，但我们面临着两个严重的困难：
- en: In addition to being arbitrarily complicated, the target functions underlying
    various real-life problems are completely different from one another. There is
    hardly any common pattern.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了任意复杂外，各种现实生活问题的底层目标函数彼此完全不同。几乎没有任何共同模式。
- en: For most problems, we do *not* know the underlying target function.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于大多数问题，我们*不知道*其底层的目标函数。
- en: 'Despite all this, we want to come up with a mechanized repeatable solution
    for performing real-life intelligent tasks. And we do not want to start from scratch
    and design the underlying function for each such problem. This is where neural
    networks help:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们仍希望为执行现实生活中的智能任务找到一个机械化的可重复解决方案。我们不想从头开始，为每个这样的问题设计底层功能。这正是神经网络发挥作用的地方：
- en: Neural networks provide a unified framework to model an extremely wide variety
    of arbitrarily complicated functions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络提供了一个统一的框架来模拟极其广泛的任意复杂函数。
- en: While the overall neural network models a complicated function, its building
    block is a fairly basic unit called a *neuron*. The neuron represents a relatively
    simple function. The full neural network is made up of many neurons with weighted
    connections between them. It can be made to approximate any arbitrary target function
    underlying a particular problem of interest by manipulating the number of neurons,
    the connectivity between them, and the connection weights.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然整体神经网络模拟了一个复杂的函数，但其构建块是一个相当基本的单元，称为*神经元*。神经元代表一个相对简单的函数。完整的神经网络由许多神经元组成，它们之间有加权连接。通过操纵神经元的数量、它们之间的连接性和连接权重，可以使其近似任何特定问题的任意目标函数。
- en: 'The variety and complexity of the functions a neural network can represent
    are known as its *expressive power*. Expressive power increases with the number
    of neurons in the neural network and the number of connections between them. The
    more complex the target function, the more expressive power will be needed in
    the neural network modeling it. How can we make a neural network model/approximate/express
    a specific target function corresponding to a particular problem of interest?
    Answer: we can adjust the following two aspects of the neural network:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络可以表示的函数的多样性和复杂性被称为其**表达能力**。表达能力随着神经网络中神经元数量的增加以及它们之间连接数量的增加而增加。目标函数越复杂，神经网络建模所需的表达能力就越多。我们如何使神经网络模型/近似/表达与特定感兴趣问题的特定目标函数相对应？答案：我们可以调整神经网络的以下两个方面：
- en: '*Architecture*—The number of neurons and the connections between them'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**架构**——神经元数量以及它们之间的连接'
- en: '*Parameter values*—The weights of the connection between neurons'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参数值**——神经元之间连接的权重'
- en: The architecture is typically chosen based on the nature of the problem. Some
    popular architectures are reused frequently, and a neural network engineer typically
    chooses an architecture that is historically known to be effective for a problem
    similar to the problem at hand. We look at several popular architectures later
    in this book—for instance, in chapter [11](../Text/11.xhtml#ch-deep-learning-object-recognition-detection).
    Once the architecture is set, we determine the parameter values through a process
    called *training*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 架构通常是根据问题的性质来选择的。一些流行的架构被频繁地重用，神经网络工程师通常会选择一个历史上已知对类似当前问题的有效架构。我们将在本书的后面部分查看几个流行的架构——例如，在第
    [11](../Text/11.xhtml#ch-deep-learning-object-recognition-detection) 章节中。
- en: 'Neural networks can be classified into two major classes: *supervised* and
    *unsupervised*. In supervised neural networks, we identify the desired output
    values corresponding to a set of sampled input values for the problem we are trying
    to solve. The desired output for these sampled inputs is typically chosen manually
    using a process called *labeling* (aka *manual annotation* or *manual curation*).
    The overall set of <sampled input, desired output> pairs constitutes the *supervised
    training data*. The set of desired outputs for training data inputs is sometimes
    collectively referred to as the *ground truth* or *target output*.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络可以分为两大类：**监督学习**和**无监督学习**。在监督神经网络中，我们为试图解决的问题中一组采样输入值识别所需的输出值。这些采样输入的期望输出通常通过称为**标记**（又称**人工标注**或**人工整理**）的过程手动选择。一组<采样输入，期望输出>对构成了**监督训练数据**。训练数据输入的期望输出集有时被统称为**真实值**或**目标输出**。
- en: During training, the parameter values (aka weights) are adjusted such that the
    network’s outputs on training inputs match the corresponding ground truth as closely
    as possible. If all goes well, at the end of training, we are left with a neural
    network whose outputs on training inputs are close to the ground truth. This *trained*
    neural network is then deployed to the real world, where it performs *inferencing*—it
    generates output on inputs it has never seen before. If we have chosen the architecture
    with enough expressive power and properly trained the network with adequate training
    data, it should emit accurate results during inferencing. Note that we cannot
    *guarantee* correct results during inferencing; we can only make a probabilistic
    statement that our output has a *p* probability of being correct.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，参数值（又称权重）被调整，以便网络在训练输入上的输出尽可能接近相应的真实值。如果一切顺利，在训练结束时，我们将得到一个神经网络，其在训练输入上的输出接近真实值。这个**训练好的**神经网络随后被部署到现实世界，在那里它执行**推理**——它对从未见过的输入生成输出。如果我们选择了具有足够表达能力的架构，并且用足够的训练数据正确训练了网络，那么在推理过程中它应该会发出准确的结果。请注意，我们无法**保证**推理过程中的正确结果；我们只能做出概率性陈述，即我们的输出有*p*的概率是正确的。
- en: Unsupervised neural networks do not need the manually labeled ground truth—they
    just work on the training inputs. The manual labor involved in labeling the training
    data is expensive and bothersome. Consequently, considerable research effort is
    going into neural networks that are unsupervised, semi-supervised (a fraction
    of the training data is labeled manually), or self-supervised (labeled training
    data is created programmatically rather than manually). However, unsupervised
    and semi-supervised neural network technology is less mature at the time of this
    writing, and it is harder to achieve desired accuracy levels with them. Later
    in this book, we examine unsupervised approaches, including *variational autoencoders*
    (chapter [14](../Text/14.xhtml#ch-ae-vae)). But for now, we mostly talk about
    supervised approaches.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督神经网络不需要手动标记的地面真实数据——它们只需在训练输入上工作。标记训练数据的劳动成本高昂且麻烦。因此，相当多的研究工作投入到无监督、半监督（训练数据中的一部分是手动标记的）或自监督（标记的训练数据是通过程序而不是手动创建的）神经网络中。然而，在撰写本文时，无监督和半监督神经网络技术还不够成熟，使用它们达到期望的准确度水平更困难。本书后面我们将探讨无监督方法，包括*变分自编码器*（第[14](../Text/14.xhtml#ch-ae-vae)章）。但就目前而言，我们主要讨论监督方法。
- en: It is important to note that nowhere in the architecture selection or training
    process do we need a closed-form representation of either the function being approximated
    (the target function) or the approximator function (the modeling function). This
    is important. In most cases, it is impossible to know the target function—all
    we know are sample input and ground-truth pairs (training data). As for the modeling
    function, even when we know the architecture of the modeling neural network, the
    overall function it represents is so complicated that it is virtually intractable.
    Thus, the fact that we do not need to know the target or modeling function in
    closed form is what makes the technology practical.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，在架构选择或训练过程中，我们不需要被逼近的函数（目标函数）或逼近函数（建模函数）的封闭形式表示。这是非常重要的。在大多数情况下，我们无法知道目标函数——我们只知道样本输入和真实值对（训练数据）。至于建模函数，即使我们知道建模神经网络的架构，它所表示的整体函数如此复杂，以至于几乎无法处理。因此，我们不需要知道目标或建模函数的封闭形式，这使得这项技术变得实用。
- en: '7.2 Expressing real-world problems: Target functions'
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 表达现实世界问题：目标函数
- en: 'Consider the classic investor’s problem: to sell or not sell a stock. The problem
    inputs could be the purchase price, current price, whether the investor’s favorite
    expert is advising to sell or not, and so on. The problem can be solved by a function
    that takes these inputs and outputs as 0 (do not sell) or 1 (sell). If we could
    model this function, we would have a mechanical solution to this real-world problem.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑经典的投资者问题：是否卖出股票。问题输入可能包括购买价格、当前价格、投资者是否喜欢专家建议卖出或不出售等。可以通过一个函数来解决该问题，该函数接受这些输入并输出0（不卖）或1（卖）。如果我们能够模拟这个函数，我们就会有一个解决这个现实世界问题的机械解决方案。
- en: 'Like this example, most real-world problems can be expressed as target functions.
    We collect all quantifiable variables that can have a bearing on the outcome:
    these constitute the *input variables*. The input variables are expressed as numeric
    entities: scalars, vectors, matrices, and so on. The outputs are also expressed
    as numeric variables called the *output variables*. Given a specific input (say,
    specific values for purchase price and current price), our model function emits
    an output (0 or 1 indicating do not sell or sell) that is a solution to the problem
    for that specific input.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 就像这个例子一样，大多数现实世界问题都可以表达为目标函数。我们收集所有可能影响结果的可量化变量：这些构成了*输入变量*。输入变量以数值实体表示：标量、向量、矩阵等。输出也以称为*输出变量*的数值变量表示。给定一个特定的输入（例如，购买价格和当前价格的特定值），我们的模型函数会输出一个输出（0或1表示不卖或卖），这是针对该特定输入的问题解决方案。
- en: We usually denote input variables with the symbol *x*; a sequence of input variables
    is often expressed as a vector ![](../../OEBPS/Images/AR_x.png). Output variables
    are denoted with the symbol *y*. The overall target function is usually expressed
    as *y* = *f*(![](../../OEBPS/Images/AR_x.png)). We will often use subscripts to
    denote various elements of a vector (*x*[0], *x*[1], ⋯, *x[i]*) and superscripts
    to denote input instances, as in *y*^((0)) = *f*(![](../../OEBPS/Images/AR_x.png)^((0))),
    *y*^((1)) = *f*(![](../../OEBPS/Images/AR_x.png)^((1))), ⋯, *y*^((*i*)) = *f*(![](../../OEBPS/Images/AR_x.png)^((*i*))).
    But in some cases, we will use subscripts to denote different items of the training
    data. The usage should be obvious from the context.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常用符号 *x* 表示输入变量；一系列输入变量通常表示为一个向量 ![向量x](../../OEBPS/Images/AR_x.png)。输出变量用符号
    *y* 表示。整体目标函数通常表示为 *y* = *f*(![向量x](../../OEBPS/Images/AR_x.png))。我们经常使用下标来表示向量的各种元素
    (*x*[0]，*x*[1]，⋯，*x[i]*)，并使用上标来表示输入实例，如 *y*^((0)) = *f*(![向量x](../../OEBPS/Images/AR_x.png)^((0))),
    *y*^((1)) = *f*(![向量x](../../OEBPS/Images/AR_x.png)^((1))), ⋯, *y*^((*i*)) = *f*(![向量x](../../OEBPS/Images/AR_x.png)^((*i*)))。但在某些情况下，我们将使用下标来表示训练数据的不同项。具体用法应从上下文中明显看出。
- en: 'Numeric quantities can occur in two distinct forms: continuous and categorical.
    *Continuous variables* can take any of the infinitely many real number values
    in a given range. For instance, the stock price in our “to sell or not sell a
    stock” problem can take any value greater than zero. *Categorical variables* can
    take one of a finite set of allowed values, where the value represents a category.
    A special categorical case is a binary variable, where there are only two categories.
    For instance, expert advice in our stock-selling problem can take only two values:
    0 or 1, corresponding to the two categories of advice, “do not sell” and “sell,”
    respectively.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数值量可以以两种不同的形式出现：连续和分类。*连续变量*可以取给定范围内的无限多个实数值。例如，在我们“卖或不卖股票”的问题中，股票价格可以取任何大于零的值。*分类变量*可以取一组有限允许值中的一个，其中值代表一个类别。一个特殊的分类情况是二元变量，其中只有两个类别。例如，在我们股票销售问题中的专家建议只能取两个值：0或1，分别对应建议的两个类别，“不卖”和“卖”。
- en: 'In this section, we discuss three distinct families of target functions: logical
    functions, general functions, and classifiers.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论三种不同的目标函数家族：逻辑函数、通用函数和分类器。
- en: 7.2.1 Logical functions in real-world problems
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.1 实际问题中的逻辑函数
- en: 'These are functions whose inputs and outputs are binary variables: variables
    that can take only two values, 0 (aka “no” or “don’t fire”) and 1 (aka “yes” or
    “fire”). Machines emulating logical functions are often added on top of separate
    machines performing other tasks, as will be evident from the following examples:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是输入和输出都是二元变量的函数：只能取两个值，0（即“否”或“不触发”）和1（即“是”或“触发”）。模拟逻辑函数的机器通常被添加到执行其他任务的独立机器之上，以下例子将清楚地说明这一点：
- en: '*Logical OR*—To look at logical OR functions, let’s bring back the mythical
    cat whose brain we discussed in chapter [1](../Text/01.xhtml#chap-overview). Say
    we are trying to build a machine that helps the poor creature make the binary
    decision whether to run away from the object in front of it or approach the object
    and purr. Being very timid, this cat runs away from anything that looks hard or
    sharp. The only time it will approach and purr is when the object in front of
    it looks neither hard nor sharp. Let’s assume a separate machine outputs a binary
    decision 0 not hard) or 1 (hard). Another machine outputs a binary decision 0
    (not sharp) or 1 (sharp). The logical OR machine combines the binary decisions
    from the two separate machines, as shown in figure [7.1a](#fig-func-logical-or).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*逻辑或*—要了解逻辑或函数，让我们回顾一下第一章中讨论过的那个神话中的猫。假设我们正在尝试构建一台机器，帮助这只可怜的生物做出二进制决策：是逃跑还是接近面前的事物并发出咕噜声。由于非常胆小，这只猫会避开任何看起来坚硬或尖锐的东西。只有当面前的事物既不坚硬也不尖锐时，它才会靠近并发出咕噜声。让我们假设有一个独立的机器输出一个二进制决策0（不坚硬）或1（坚硬）。另一个机器输出一个二进制决策0（不尖锐）或1（尖锐）。逻辑或机器将两个独立机器的二元决策结合起来，如图[7.1a](#fig-func-logical-or)所示。'
- en: '![](../../OEBPS/Images/CH07_F02a_Chaudhury.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F02a_Chaudhury.png)'
- en: '(a) Logical OR: a timid cat that runs away from things whose hardness exceeds
    threshold *t*[0] **OR** whose sharpness exceeds threshold *t*[1]'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 逻辑或：一只胆小的猫，如果面前的事物硬度超过阈值 *t*[0] **或**尖锐度超过阈值 *t*[1] 就会逃跑
- en: '![](../../OEBPS/Images/CH07_F02b_Chaudhury.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F02b_Chaudhury.png)'
- en: '(b) Logical AND: a less timid cat that runs away from things whose hardness
    exceeds threshold *t*[0] **AND** whose sharpness exceeds threshold *t*[1]'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 逻辑与：一只不那么胆小的猫，它会避开硬度超过阈值*t*[0] **且**尖锐度超过阈值*t*[1]的东西
- en: '![](../../OEBPS/Images/CH07_F02c_Chaudhury.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH07_F02c_Chaudhury.png)'
- en: '(c) Multi-input logical OR: A self-driving car that applies the brake if it
    sees a person, vehicle, or bend in the road in front of it'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 多输入逻辑或：如果自动驾驶汽车看到前方有行人、车辆或道路弯曲，它就会刹车
- en: Figure 7.1 Examples of logical operators (OR, AND) in real-life problems
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1 逻辑运算符（或、与）在现实生活中的例子
- en: '*Logical AND*—We also exemplify this in terms of the cat brain. Imagine a slightly
    less timid cat that runs away from things that are both hard and sharp. But it
    is not scared by hardness and sharpness alone. Its brain can be modeled by the
    system of machines shown in figure [7.1b](#fig-func-logical-and).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*逻辑与*—我们也在猫脑的例子中展示了这一点。想象一只稍微不那么胆小的猫，它会避开又硬又尖的东西。但它不仅仅害怕硬和尖。它的脑部可以被图7.1b中显示的机器系统所模拟。'
- en: '*Logical NOT*—Consider a machine that sounds an alarm if it sees any unauthorized
    person in a restricted access area. Let’s assume that we also have a separate
    machine: a face detector that can recognize the faces of all authorized personnel.
    It emits a binary decision 1 (recognized face) or 0 (unrecognized face). The overall
    system takes the output of the face detector and performs a logical NOT operationon
    it.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*逻辑非*—考虑一个机器，如果它看到任何未经授权的人进入受限区域，就会发出警报。假设我们还有一个独立的机器：一个面部识别器，它可以识别所有授权人员的面孔。它会发出一个二进制决策1（识别到的面孔）或0（未识别到的面孔）。整个系统接收面部识别器的输出，并对其执行逻辑非操作。'
- en: '*Multi-input logical OR*—Imagine a machine that decides whether a self-driving
    car needs to brake. Assume that three separate detectors emit 1 if a person, vehicle,
    or bend in the road, respectively, is seen in front of the car. A brake must be
    applied if any of these separate detectors emits a 1. This is shown in figure
    [7.3](#fig-func-multi-input-or).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多输入逻辑或*—想象一个机器，它决定自动驾驶汽车是否需要刹车。假设有三个独立的探测器，如果汽车前方看到人、车辆或道路弯曲，它们分别发出1。如果这些独立的探测器中的任何一个发出1，就必须刹车。这如图7.3所示。'
- en: '*Multi-input logical AND*—Consider a machine that helps a venture capitalist
    decide whether to invest in a startup. Assume that three separate machines emit
    1 when the following conditions are met: (1) the CEO has a track record of success,
    (2) the product elicits interest from targeted customers, and 3) the product is
    sufficiently novel, respectively. The machine will decide to invest if all three
    separate machines emit 1. Thus, the machine outputs 1 when condition (1) is met
    AND condition (2) is met AND condition (3) is met. This is an example of a three-input
    AND.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多输入逻辑与*—考虑一个帮助风险投资家决定是否投资初创企业的机器。假设有三个独立的机器，当以下条件满足时，它们会发出1：（1）CEO有成功的记录，（2）产品引起了目标客户的兴趣，（3）产品足够新颖。如果所有三个独立的机器都发出1，机器将决定投资。因此，当条件（1）满足且条件（2）满足且条件（3）满足时，机器输出1。这是一个三输入与的例子。'
- en: '*Logical XOR*—Suppose we are building a social media site. Assume we have a
    separate detector that, for any person, emits 1 if they like rock music and 0
    otherwise. Using this information about two people, the problem is to decide whether
    they should be recommended as friends to each other. Friendship potential is high
    if they both like rock music or both dislike it. But if one person likes rock
    and the other dislikes it, they will probably not be good friends. Thus condition
    1 is high rock-music affinity for person 1, and condition 2 is high rock-music
    affinity for person 2\. The exclusive OR of the two conditions is 1 when one is
    true but the other is not. This machine outputs 1 if the NOT of the exclusive
    OR is true, meaning neither person likes rock music or both people like rock music.
    Figure [7.4](#fig-func-logical-xor) depicts this.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*逻辑异或*—假设我们正在构建一个社交媒体网站。假设我们有一个独立的探测器，对于任何一个人，如果他们喜欢摇滚音乐，就发出1，否则发出0。使用关于两个人的这些信息，问题是要决定他们是否应该被推荐为彼此的朋友。如果他们两人都喜欢摇滚音乐或都讨厌它，那么友谊潜力就很高。但如果一个人喜欢摇滚而另一个人不喜欢，他们可能不是好朋友。因此，条件1是第一个人对摇滚音乐的亲和力高，条件2是第二个人对摇滚音乐的亲和力高。当其中一个条件为真而另一个不为真时，这两个条件的异或为1。这个机器在异或的非为真时输出1，这意味着两个人都不喜欢摇滚音乐或两个人都喜欢摇滚音乐。图7.4描述了这一点。'
- en: '*m-out-of-n trigger*—Imagine we are trying to create a face detector. We have
    already created separate part detectors for noses, eyes, lips, and ears. If we
    detect, say, any two of these together, we feel confident enough to declare a
    face. In computer vision, we often have a problem called *occlusion*, where an
    important object becomes invisible to the camera because another object blocks
    the camera’s line of sight. Computer vision algorithms always try to be robust
    against occlusion, meaning they want to emit the right output even when occlusion
    occurs. This is why we do not want to mandate a positive signal from all the part
    detectors; we want to detect the face even when a few of the parts are occluded.
    Hence, our machine emits 1 when, say, two of the *n* parts (such as eyes and lips)
    are detected.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*m-out-of-n触发器*——想象我们正在尝试创建一个人脸检测器。我们已经有鼻子、眼睛、嘴唇和耳朵的独立部分检测器。如果我们检测到，比如说，这些部分中的任意两个一起，我们就足够自信地宣布检测到人脸。在计算机视觉中，我们经常遇到*遮挡*问题，其中一个重要对象因为另一个对象挡住了摄像机的视线而变得对摄像机不可见。计算机视觉算法总是试图对遮挡具有鲁棒性，这意味着即使在遮挡发生时，它们也希望输出正确的结果。这就是为什么我们不希望强制所有部分检测器都发出正信号；我们希望在部分遮挡的情况下也能检测到人脸。因此，当，比如说，检测到*n*个部分（如眼睛和嘴唇）中的两个时，我们的机器输出1。'
- en: '![](../../OEBPS/Images/CH07_F03_Chaudhury.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F03_Chaudhury.png)'
- en: Figure 7.2 Example of logical NOT and XOR in a real-life problem. A social media
    system makes a friendship recommendation between persons A and B if and only if
    they both like or both dislike rock music. friendship = ¬ (rock-music-affinity-of-A
    ⊕ rock-music-affinity-of-B) where ¬ ⟹ logical NOT and ⊕ ⟹ logical XOR.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 逻辑非和异或在实际问题中的应用示例。一个社交媒体系统只有在A和B两人都喜欢或都不喜欢摇滚音乐时，才会向他们推荐友谊。友谊 = ¬ (A的摇滚音乐亲和力
    ⊕ B的摇滚音乐亲和力)，其中 ¬ 表示逻辑非，⊕ 表示逻辑异或。
- en: '![](../../OEBPS/Images/CH07_F01a_Chaudhury.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F01a_Chaudhury.png)'
- en: (a) Discriminative face detector classifier). The output is categorical (face
    or not face).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 判别式人脸检测器分类器）。输出是分类的（人脸或非人脸）。
- en: '![](../../OEBPS/Images/CH07_F01b_Chaudhury.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F01b_Chaudhury.png)'
- en: (b) Generative face detector. The output is continuous (the probability of an
    image containing a face).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 生成式人脸检测器。输出是连续的（图像包含人脸的概率）。
- en: Figure 7.3 The face detector takes an image as input and outputs a categorical
    or continuous variable.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 人脸检测器以图像为输入，输出一个分类的或连续的变量。
- en: 7.2.2 Classifier functions in real-world problems
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.2 实际问题中的分类函数
- en: 'A classifier is a function whose output is categorical. Inputs can be either
    continuous or categorical. Thus, given an input, the function chooses one category
    (aka class) or another. For instance, a face detector can be a classifier. Its
    input is an image, and its output is a categorical (binary) variable that takes
    one of two possible values: 1 (face) or 0 (not face). This is shown in figure
    [7.3a](#fig-box-face-detector-discriminative). As we saw in section [2.3](02.xhtml#sec-matrices),
    any image can be represented by a vector ![](../../OEBPS/Images/AR_x.png). Accordingly,
    the classifier function for the face detectorcan be written as the function'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器是一个输出为分类的函数。输入可以是连续的或分类的。因此，给定一个输入，函数会选择一个类别（即类）或另一个类别。例如，人脸检测器可以是一个分类器。它的输入是一个图像，它的输出是一个分类的（二元）变量，可以取两个可能的值之一：1（人脸）或0（非人脸）。这如图[7.3a](#fig-box-face-detector-discriminative)所示。正如我们在第[2.3](02.xhtml#sec-matrices)节中看到的，任何图像都可以表示为一个向量![图片](../../OEBPS/Images/AR_x.png)。因此，人脸检测器的分类函数可以写成如下函数
- en: '![](../../OEBPS/Images/eq_07-00-a.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/eq_07-00-a.png)'
- en: How to design the function *ϕ*(![](../../OEBPS/Images/AR_x.png)) is one of the
    primary topics of this chapter.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如何设计函数*ϕ*(![图片](../../OEBPS/Images/AR_x.png))是本章的主要话题之一。
- en: Geometrically, each scalar input variable forms a separate dimension in the
    input space. All possible combinations of these scalar input variables together
    form a multidimensional space called the *input space* (or feature space). Each
    specific combination of input values is a point (represented by the input vector
    ![](../../OEBPS/Images/AR_x.png)) in this space.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 几何上，每个标量输入变量在输入空间中形成一个单独的维度。所有这些标量输入变量的所有可能组合共同形成一个多维空间，称为*输入空间*（或特征空间）。每个特定的输入值组合是这个空间中的一个点（由输入向量![图片](../../OEBPS/Images/AR_x.png)表示）。
- en: For instance, in an image, each pixel can be taken as a separate input scalar
    variable that can take any 3-byte pixel color value between RGB = ![](../../OEBPS/Images/o_00.png),
    ![](../../OEBPS/Images/o_00.png), ![](../../OEBPS/Images/o_00.png) (hex) (black)
    and RGB = ![](../../OEBPS/Images/o_FF.png), ![](../../OEBPS/Images/o_FF.png),
    ![](../../OEBPS/Images/o_FF.png) (hex) (white), with successive bytes (demarcated
    by an overline) representing red, green, and blue components of the pixel, respectively.
    The input has as many dimensions as the number of pixels in the image. For instance,
    a 224 × 224 image forms a 50, 176-dimensional input space. Each specific image
    is a single point in this space. The face-classifier function *ϕ*(![](../../OEBPS/Images/AR_x.png))
    maps that point to either 0 (not face) or 1 (face).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在图像中，每个像素可以被视为一个单独的输入标量变量，它可以取任何介于 RGB = ![图片](../../OEBPS/Images/o_00.png),
    ![图片](../../OEBPS/Images/o_00.png), ![图片](../../OEBPS/Images/o_00.png) (十六进制)
    (黑色) 和 RGB = ![图片](../../OEBPS/Images/o_FF.png), ![图片](../../OEBPS/Images/o_FF.png),
    ![图片](../../OEBPS/Images/o_FF.png) (十六进制) (白色) 之间的 3 字节像素颜色值。输入的维度与图像中的像素数量相同。例如，一个
    224 × 224 的图像形成一个 50, 176 维的输入空间。每个特定的图像是这个空间中的一个点。面分类函数 *ϕ*(![图片](../../OEBPS/Images/AR_x.png))
    将该点映射到 0（非面部）或 1（面部）。
- en: 'For a simpler instance, consider our familiar cat brain example from section
    [1.4](../Text/01.xhtml#sec-geom-view-ml). There are two input variables: *x*[0],
    indicating *hardness*; and *x*[1], indicating *sharpness*. The overall input space
    is two-dimensional, in which a specific input combination is denoted by the 2D
    vector ![](../../OEBPS/Images/eq_07-00-b.png). Our goal is to construct a machine
    that, given any input combination of hardness and sharpness, classifies it as
    either *threatening* or *nonthreatening*. This is equivalent to designing a function
    that maps arbitrary input vectors ![](../../OEBPS/Images/AR_x.png) ∈ ℝ² to 0 or
    1:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个更简单的例子，考虑我们熟悉的来自第 [1.4](../Text/01.xhtml#sec-geom-view-ml) 节的猫脑示例。有两个输入变量：*x*[0]，表示
    *硬度*；和 *x*[1]，表示 *尖锐度*。整体输入空间是二维的，其中特定的输入组合由 2D 向量 ![图片](../../OEBPS/Images/eq_07-00-b.png)
    表示。我们的目标是构建一个机器，给定任何硬度与尖锐度的输入组合，将其分类为 *威胁性* 或 *非威胁性*。这相当于设计一个函数，将任意输入向量 ![图片](../../OEBPS/Images/AR_x.png)
    ∈ ℝ² 映射到 0 或 1：
- en: '![](../../OEBPS/Images/eq_07-00-c.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/eq_07-00-c.png)'
- en: 'Geometrical view of classifiers: Decision boundaries'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的几何视图：决策边界
- en: Geometrically speaking, a classifier partitions the feature space into separate
    regions, each corresponding to a class. For instance, consider the simple cat-brain
    model from section [1.4](../Text/01.xhtml#sec-geom-view-ml). There are two input
    variables, hardness (*x*[0]) and sharpness (*x*[1]). Hence we have a two-dimensional
    input feature space that geometrically corresponds to a plane. Each combination
    of hardness and sharpness is represented by a specific vector ![](../../OEBPS/Images/AR_x.png)
    = [*x*[0], *x*[1]] corresponding to a *point* on the plane. Note that unlike the
    machines shown in figures [7.1a](#fig-func-logical-or) and [7.1b](#fig-func-logical-and),
    here we are talking about a machine that takes as input a *pair* of continuous
    values hardness and sharpness)—that is, a point on the two-dimensional feature
    plane—and maps it to a discrete space corresponding to the *threat* versus *not
    a threat* categorical decision. This is illustrated in figure [7.4a](#fig-cat_brain_decision_boundaries_nonlinear_and_linear).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 从几何学的角度来看，分类器将特征空间划分为不同的区域，每个区域对应一个类别。例如，考虑第 [1.4](../Text/01.xhtml#sec-geom-view-ml)
    节中的简单猫脑模型。有两个输入变量，硬度 (*x*[0]) 和尖锐度 (*x*[1])。因此，我们有一个二维的输入特征空间，在几何上对应于一个平面。硬度与尖锐度的每一种组合都由一个特定的向量
    ![图片](../../OEBPS/Images/AR_x.png) = [*x*[0], *x*[1]] 表示，对应于平面上的一个 *点*。请注意，与图
    [7.1a](#fig-func-logical-or) 和 [7.1b](#fig-func-logical-and) 中显示的机器不同，这里我们谈论的是一个以硬度与尖锐度——即二维特征平面上的一个点——作为输入的机器，并将其映射到对应于
    *威胁* 与 *非威胁* 的分类决策的离散空间。这如图 [7.4a](#fig-cat_brain_decision_boundaries_nonlinear_and_linear)
    所示。
- en: The solid curve separates the *threat* and *not-threat* regions. Such curves
    that separate regions in input space belonging to different classes are known
    as *decision boundaries*. Estimating the decision boundary is effectively the
    same as building the classifier.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 实线将 *威胁* 和 *非威胁* 区域分开。这种将属于不同类别的输入空间中的区域分开的曲线称为 *决策边界*。估计决策边界实际上等同于构建分类器。
- en: '![](../../OEBPS/Images/CH07_F04a_Chaudhury.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F04a_Chaudhury.png)'
- en: '(a) Cat brain threat model decision boundary. The solid curve corresponds to
    the true decision boundary separating the *threat* and *non-threat* regions. The
    dashed line represents an approximate linear decision boundary: it classifies
    most points correctly but misclassifies points in the region between itself and
    the true decision boundary.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 猫脑威胁模型决策边界。实线曲线对应于分隔*威胁*和*非威胁*区域的真实决策边界。虚线代表一个近似的线性决策边界：它正确分类了大多数点，但错误地将实线和虚线之间的点分类。
- en: In practice, we get some sample points from each region through manual labeling.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们通过手动标记从每个区域获取一些样本点。
- en: '![](../../OEBPS/Images/CH07_F04b_Chaudhury.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F04b_Chaudhury.png)'
- en: (b) Good training data. Sample points from each class roughly span the region
    of input space belonging to the class. This yields a good decision boundary (solid
    line).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 好的训练数据。来自每个类别的样本点大致覆盖了属于该类别的输入空间区域。这导致了一个良好的决策边界（实线）。
- en: '![](../../OEBPS/Images/CH07_F04c_Chaudhury.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F04c_Chaudhury.png)'
- en: (c) Bad training data. Sample points from individual classes do not span the
    region of input space belonging to the class. This yields a bad decision boundary
    (dashed line).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 坏的训练数据。来自单个类别的样本点没有覆盖属于该类别的输入空间区域。这导致了一个不良的决策边界（虚线）。
- en: Figure 7.4 Classifiers, decision boundaries, and training data. Data points
    from different classes are marked with different symbols (plus and dot).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 分类器、决策边界和训练数据。来自不同类别的数据点用不同的符号（加号和点）标记。
- en: The dashed line represents an approximate linear decision boundary that does
    the job crudely but misclassifies the points between the solid and dashed curves.
    (Linear decision boundaries are easier to represent with neural networks, but
    they are inadequate for complex problems.)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 虚线代表一个近似的线性决策边界，它粗略地完成了工作，但错误地将实线和虚线之间的点分类。（线性决策边界更容易用神经网络表示，但它们对于复杂问题是不够的。）
- en: 'Let’s look briefly at the solid curve in figure [7.4a](#fig-cat_brain_decision_boundaries_nonlinear_and_linear).
    At low hardness values, the sharpness threshold is high (if the object in front
    of the cat is not very hard, it must be very sharp to qualify as a threat). As
    hardness increases from *x*[0] = 0 to *x*[0] = 20, this threshold the sharpness
    required to qualify as a threat) drops more or less linearly. Beyond *x*[0] =
    20, the threshold drops at a much faster pace—if the object in front of the cat
    is sufficiently hard, it need not be very sharp to pose a threat. Beyond *x*[0]
    = 52 or so, sharpness ceases to matter: sufficiently hard objects are threats
    even if they are not sharp. This is inherently a nonlinear situation.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要地看一下图[7.4a](#fig-cat_brain_decision_boundaries_nonlinear_and_linear)中的实线曲线。在硬度值较低时，尖锐度阈值较高（如果猫前面的物体不是很硬，它必须非常尖锐才能被认定为威胁）。从*x*[0]
    = 0增加到*x*[0] = 20，这个阈值（作为威胁所需的尖锐度）大致线性下降。超过*x*[0] = 20，阈值以更快的速度下降——如果猫前面的物体足够硬，它不需要非常尖锐就能构成威胁。超过*x*[0]
    = 52左右，尖锐度就不再重要了：足够硬的物体即使不尖锐也是威胁。这本质上是一个非线性情况。
- en: To simplify neural network implementation, we might want to approximate the
    solid curve with a straight line—the dashed line is not too bad an approximation—but
    doing so entails errors. As shown in figure [7.4a](#fig-cat_brain_decision_boundaries_nonlinear_and_linear),
    the region between the true and approximate curves will be wrongly classified.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化神经网络实现，我们可能想要用直线来近似实线曲线——虚线并不是一个太差的近似，但这样做会引入误差。如图[7.4a](#fig-cat_brain_decision_boundaries_nonlinear_and_linear)所示，真实曲线和近似曲线之间的区域将被错误分类。
- en: 'Figure [7.4a](#fig-cat_brain_decision_boundaries_nonlinear_and_linear) is only
    a schematic. In reality, we do not know the exact regions in the input space that
    correspond to the classes of interest. We identify—via human labeling—some sample
    points on the input space, along with their correct class (the ground truth).
    Such a sampled set of <input point, correct output aka ground truth> pairs is
    called *training data*. An example training data set for the cat brain problem
    is shown in figure [7.4b](#fig-cat-brain-good-training-data) (ground-truth training
    data points from different classes are marked with separate symbols: plus and
    dot, respectively). The decision boundary we create by training a neural network
    is optimized to classify the training data points (and nothing more) as nicely
    as possible. If the training data points’ distribution is a reasonable reflection
    of the true distribution—that is, the sample points from each class more or less
    span the entire region in the input space corresponding to that class—the decision
    boundary obtained by training on that data set will be good. But if, as illustrated
    in figure [7.4c](#fig-cat-brain-bad-training-data), the training data does not
    reflect the true distribution of the classes in the input space, the decision
    boundary learned by training on that data maybe bad.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [7.4a](#fig-cat_brain_decision_boundaries_nonlinear_and_linear) 只是一个示意图。在现实中，我们并不知道输入空间中与感兴趣类别相对应的确切区域。我们通过人工标注识别了一些输入空间上的样本点，以及它们的正确类别（即真实情况）。这样的样本集，即
    <输入点，正确输出也称为真实情况> 对，被称为 *训练数据*。猫脑问题的示例训练数据集如图 [7.4b](#fig-cat-brain-good-training-data)
    所示（来自不同类别的真实情况训练数据点用不同的符号标记：加号和点）。我们通过训练神经网络创建的决策边界被优化以尽可能好地分类训练数据点（仅此而已）。如果训练数据点的分布是真实分布的合理反映——也就是说，每个类别的样本点大致覆盖了输入空间中对应类别的整个区域——那么在该数据集上训练得到的决策边界将是好的。但如果，如图
    [7.4c](#fig-cat-brain-bad-training-data) 所示，训练数据没有反映输入空间中类别的真实分布，那么在该数据上训练得到的决策边界可能是不好的。
- en: Unlike the cat brain example, most real-life input spaces have hundreds or even
    thousands of dimensions. The idea of a decision boundary as a hypersurface continues
    to hold in higher dimensions. For higher-dimensional input spaces, hyperplanes
    function as linear separators. In simpler problems with higher-dimensional input
    spaces, such linear separators suffice. In more complicated cases, we can have
    other curved hypersurfaces as nonlinear separators. We may not be able to visualize
    hyperspaces in our head, but we can form mental pictures with 3D analogs. Figure
    [7.5](#fig-decision-boundary) shows some planar decision boundaries in 3D input
    space.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 与猫脑示例不同，大多数现实生活中的输入空间有数百甚至数千个维度。决策边界作为超曲面的想法在更高维度中仍然成立。对于更高维度的输入空间，超平面充当线性分离器。在更高维输入空间的简单问题中，这样的线性分离器就足够了。在更复杂的情况下，我们可以有其他曲线超曲面作为非线性分离器。我们可能无法在脑海中可视化超空间，但我们可以用三维类似物来形成心理图像。图
    [7.5](#fig-decision-boundary) 显示了三维输入空间中的一些平面决策边界。
- en: '![](../../OEBPS/Images/CH07_F05a_Chaudhury.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F05a_Chaudhury.png)'
- en: (a) Training data. Sample points from regions on the input space for each class
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 训练数据。来自每个类别的输入空间区域的样本点
- en: '![](../../OEBPS/Images/CH07_F05b_Chaudhury.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F05b_Chaudhury.png)'
- en: (b) Bad decision boundary. The plane has the wrong orientation. ![](../../OEBPS/Images/AR_w.png)
    needs to be fixed.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 差的决策边界。平面方向错误。![图片](../../OEBPS/Images/AR_w.png) 需要修正。
- en: '![](../../OEBPS/Images/CH07_F05c_Chaudhury.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F05c_Chaudhury.png)'
- en: (c) Bad decision boundary. The plane has the correct orientation but the wrong
    position. *b* needs to be fixed.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 差的决策边界。平面有正确的方向但位置错误。*b* 需要修正。
- en: '![](../../OEBPS/Images/CH07_F05d_Chaudhury.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F05d_Chaudhury.png)'
- en: (d) Optimal decision boundary. The plane has correct ![](../../OEBPS/Images/AR_w.png),
    *b*. Properly trained.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 最佳决策边界。平面有正确的 ![图片](../../OEBPS/Images/AR_w.png)，*b*。适当训练。
- en: Figure 7.5 Classifiers with a linear decision boundary hyperplane). Such decision
    boundaries are created by perceptrons introduced in section [7.3.3](#sec-perceptron)).
    Data points from different classes are marked with different symbols plus and
    dot).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5 具有线性决策边界超平面的分类器）。这种决策边界是通过第 [7.3.3](#sec-perceptron) 节中介绍的感知器创建的。来自不同类别的数据点用不同的符号标记（加号和点）。
- en: Figure [7.5a](#fig-perceptron-training-data) shows a 3D space of input vectors
    along with a set of training data points. The task is to classify them into two
    classes. In this simple situation, the training points can be partitioned with
    a hyperplanar decision boundary. Figures [7.5b](#fig-perceptron-bad-planar-separator-0)
    and [7.5c](#fig-perceptron-bad-planar-separator-1) show some planes that partition
    the training data poorly, and figure [7.5d](#fig-perceptron-good-planar-separator)
    shows an optimal planar separator. The only differences between these planes are
    the values of ![](../../OEBPS/Images/AR_w.png) and *b*. This indicates that there
    are values of ![](../../OEBPS/Images/AR_w.png) and *b* that optimally partition
    the training data. These optimal values are determined by a process called *training*,
    which we discuss in detail in the nextchapter.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [7.5a](#fig-perceptron-training-data) 展示了输入向量的三维空间以及一组训练数据点。任务是将其分类为两个类别。在这种情况下，训练点可以通过超平面决策边界进行划分。图
    [7.5b](#fig-perceptron-bad-planar-separator-0) 和 [7.5c](#fig-perceptron-bad-planar-separator-1)
    展示了一些划分训练数据不佳的平面，而图 [7.5d](#fig-perceptron-good-planar-separator) 展示了一个最优的平面分离器。这些平面之间的唯一区别是
    ![](../../OEBPS/Images/AR_w.png) 和 *b* 的值。这表明存在 ![](../../OEBPS/Images/AR_w.png)
    和 *b* 的值，这些值可以最优地划分训练数据。这些最优值是通过称为 *训练* 的过程确定的，我们将在下一章详细讨论。
- en: 'Significance of sign: Mathematical expressions for decision boundaries'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 符号的重要性：决策边界的数学表达式
- en: In a space with input vectors ![](../../OEBPS/Images/AR_x.png), the equation
    *ϕ*(![](../../OEBPS/Images/AR_x.png)) = 0 represents a surface. If the space is
    2D, the surface becomes a curve. For instance, the straight dashed line in figure
    [7.4b](#fig-cat-brain-good-training-data) can be viewed as a special case of *ϕ*(![](../../OEBPS/Images/AR_x.png))
    ≡ ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) + *b* =
    0, which in this case becomes
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在输入向量 ![](../../OEBPS/Images/AR_x.png) 的空间中，*ϕ*(![](../../OEBPS/Images/AR_x.png))
    = 0 的方程代表一个表面。如果空间是二维的，表面就变成了一条曲线。例如，图 [7.4b](#fig-cat-brain-good-training-data)
    中的实线虚线可以看作是 *ϕ*(![](../../OEBPS/Images/AR_x.png)) ≡ ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b* = 0 的特殊情况，在这种情况下变为
- en: '![](../../OEBPS/Images/eq_07-00-d.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/eq_07-00-d.png)'
- en: That is,
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 那是，
- en: '![](../../OEBPS/Images/eq_07-00-e.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/eq_07-00-e.png)'
- en: In 3D, we have surfaces like planes and spheres. In more than three dimensions,
    we have hyperplanes, hyperspheres, and so on. For instance, the plane in figure
    [7.6](#fig-hyperplane-sign) corresponds to
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在三维空间中，我们有平面和球面等表面。在超过三个维度的情况下，我们有超平面、超球面等等。例如，图 [7.6](#fig-hyperplane-sign)
    中的平面对应于
- en: '![](../../OEBPS/Images/eq_07-01.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/eq_07-01.png)'
- en: Equation 7.1
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 方程 7.1
- en: That is,
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 那是，
- en: '![](../../OEBPS/Images/eq_07-01-a.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/eq_07-01-a.png)'
- en: In section [3.1.4](../Text/03.xhtml#sec-sign-sep-surface), we saw that given
    any point ![](../../OEBPS/Images/AR_x.png) in the space, the sign of *ϕ*(![](../../OEBPS/Images/AR_x.png))
    tells us which side of the surface *ϕ*(![](../../OEBPS/Images/AR_x.png)) = 0 the
    point ![](../../OEBPS/Images/AR_x.png) belongs to. Thus, if we estimate the surface
    corresponding to the decision boundary, given any point, we can determine the
    partition to which that point belongs. In other words, we can classify the point.
    Estimating the decision boundary is equivalent to building the classifier. For
    instance, the line in figure [7.4b](#fig-cat-brain-good-training-data) corresponds
    to 0.62*x*[0] + *x*[1] − 26.14 = 0. The points with 0.62*x*[0] + *x*[1] − 26.14
    < 0 are on one side and are indicated with dots. The points with 0.62*x*[0] +
    *x*[1] − 26.14 > 0 are on the other side and indicated with plus signs (+).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [3.1.4](../Text/03.xhtml#sec-sign-sep-surface) 节中，我们了解到，对于空间中的任意点 ![](../../OEBPS/Images/AR_x.png)，*ϕ*(![](../../OEBPS/Images/AR_x.png))
    的符号告诉我们点 ![](../../OEBPS/Images/AR_x.png) 属于 *ϕ*(![](../../OEBPS/Images/AR_x.png))
    = 0 的表面哪一侧。因此，如果我们估计与决策边界对应的表面，给定任意点，我们可以确定该点属于哪个划分。换句话说，我们可以对点进行分类。估计决策边界等同于构建分类器。例如，图
    [7.4b](#fig-cat-brain-good-training-data) 中的线对应于 0.62*x*[0] + *x*[1] − 26.14 =
    0。0.62*x*[0] + *x*[1] − 26.14 < 0 的点位于一侧，并用点表示。0.62*x*[0] + *x*[1] − 26.14 > 0
    的点位于另一侧，并用加号（+）表示。
- en: The idea extends to higher dimensions. Figure [7.6](#fig-hyperplane-sign) shows
    the same idea in a 3D input space. The plane corresponds to the equation *x*[0]
    + *x*[1] + *x*[2] = 0. The points with *x*[0] + *x*[1] + *x*[2] < 0 are on one
    side (indicated by – in figure [7.6](#fig-hyperplane-sign)), and points with *x*[0]
    + *x*[1] + *x*[2] > 0 are on the other side (indicated by + in figure [7.6](#fig-hyperplane-sign)).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法可以扩展到更高维度。图[7.6](#fig-hyperplane-sign)展示了在3D输入空间中的相同概念。平面对应于方程*x*[0] + *x*[1]
    + *x*[2] = 0。*x*[0] + *x*[1] + *x*[2] < 0的点位于一个侧面（如图[7.6](#fig-hyperplane-sign)中的-所示），而*x*[0]
    + *x*[1] + *x*[2] > 0的点位于另一侧面（如图[7.6](#fig-hyperplane-sign)中的+所示）。
- en: '![](../../OEBPS/Images/CH07_F06_Chaudhury.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F06_Chaudhury.png)'
- en: Figure 7.6 Significance of sign for *ϕ*(![](../../OEBPS/Images/AR_x.png)) ≡
    ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) + *b*. Note
    that *ϕ*(![](../../OEBPS/Images/AR_x.png)) = 0 implies that ![](../../OEBPS/Images/AR_x.png)
    lies *on* the plane, *ϕ*(![](../../OEBPS/Images/AR_x.png)) negative implies one
    side of the plane, and *ϕ*(![](../../OEBPS/Images/AR_x.png)) positive implies
    the other side of the plane.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 *ϕ*(![](../../OEBPS/Images/AR_x.png))的符号意义 ≡ ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b*。注意，*ϕ*(![](../../OEBPS/Images/AR_x.png)) = 0意味着![](../../OEBPS/Images/AR_x.png)位于平面上，*ϕ*(![](../../OEBPS/Images/AR_x.png))为负意味着平面的一个侧面，*ϕ*(![](../../OEBPS/Images/AR_x.png))为正意味着平面的另一侧面。
- en: 7.2.3 General functions in real-world problems
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.3 现实世界问题中的通用函数
- en: 'There are problems where a categorical output variable will not do and a continuous
    output variable is called for: for instance, estimating the speed at which a self-driving
    vehicle should run. Using inputs like the speed limit for the road being traversed,
    speeds of neighboring vehicles, and so on, we need to estimate how fast the self-driving
    vehicle should go.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一些问题，分类输出变量不足以解决问题，需要连续输出变量：例如，估计自动驾驶车辆应该行驶的速度。使用诸如正在穿越的道路的速度限制、相邻车辆的速度等信息作为输入，我们需要估计自动驾驶车辆应该行驶多快。
- en: Another noteworthy situation where the output needs to be a continuous rather
    than a categorical variable is when we are modeling the *probability* of some
    event occurring. For instance, let’s again consider the face detector. Given an
    image as input, the face classification function emits 0 to indicate *not a face*
    and 1 to indicate *face*. Such functions are called *discriminative*. We could
    also have a function that outputs the probability of the image containing a face.
    Such functions are called *generative*, and an example is shown in figure [7.6](#fig-box-face-detector-generative).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要注意的情况是，当我们需要将输出变量建模为连续变量而不是分类变量时，例如，当我们建模某个事件发生的概率时。例如，再次考虑人脸检测器。给定一个图像作为输入，人脸分类函数输出0表示“不是人脸”，输出1表示“是人脸”。这样的函数被称为“判别函数”。我们也可以有一个输出图像包含人脸概率的函数。这样的函数被称为“生成函数”，一个例子如图[7.6](#fig-box-face-detector-generative)所示。
- en: '7.3 The basic building block or neuron: The perceptron'
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 基本构建块或神经元：感知器
- en: In section [7.2](#sec-real-world-problems-func), we saw that most real-world
    problems can be expressed as functions. This is good news, but the bad news is
    that these functions are usually unknown, and the functions underlying various
    problems are wildly different from each other. It may be possible to estimate
    them, but if we attack them individually without adopting a generic framework,
    there is little hope of developing a repeatable solution.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在[7.2](#sec-real-world-problems-func)节中，我们了解到大多数现实世界问题都可以表示为函数。这是一个好消息，但坏消息是，这些函数通常是未知的，而且各种问题背后的函数彼此之间差异很大。虽然可能估计它们，但如果我们不采用通用框架而单独攻击它们，几乎没有希望开发出可重复的解决方案。
- en: 'Neural networks provide an effective framework that can mechanically model
    an extremely wide variety of complicated functions. Furthermore, the target function
    need not be known in a closed form—sample input-output pairs are enough. They
    can represent (model) very complicated functions by connecting instances of a
    fairly simple building block, unsurprisingly called a *neuron*. In other words,
    the complete neural network can have huge *expressive power* even though a single
    neuron is very simple. Later, in sections [7.3.4](#sec-logic-gates-via-perceptrons),
    [7.4](#sec-MLPs), [7.5](../Text/07.xhtml#sec-layering), and so on, we discuss
    how neural networks model functions of increasing complexity. But first, in this
    section, we examine the building block: the neuron.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络提供了一个有效的框架，可以机械地模拟极其广泛的复杂函数。此外，目标函数不必是封闭形式的——样本输入输出对就足够了。它们可以通过连接相当简单的构建块实例（不出所料地称为*神经元*）来表示（建模）非常复杂的函数。换句话说，完整的神经网络可以具有巨大的*表达能力*，尽管单个神经元非常简单。稍后，在第
    [7.3.4](#sec-logic-gates-via-perceptrons)、[7.4](#sec-MLPs)、[7.5](../Text/07.xhtml#sec-layering)
    等节中，我们将讨论神经网络如何模拟越来越复杂的函数。但首先，在本节中，我们检查构建块：神经元。
- en: 7.3.1 The Heaviside step function
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.1 海维塞德阶跃函数
- en: 'The *Heaviside step function*, often referred to as simply the *step function*,
    is a function that takes the value 0 for negative arguments and the value 1 for
    positive arguments:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 海维塞德阶跃函数，通常简称为*阶跃函数*，是一个对于负数参数取值为0，对于正数参数取值为1的函数：
- en: '![](../../OEBPS/Images/eq_07-02.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/eq_07-02.png)'
- en: Equation 7.2
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 方程 7.2
- en: Equation [7.2](#eq-heaviside-step-func) is equivalent to the following algorithm.
    Figure [7.7](../Text/07.xhtml#fig-step-1D) shows the graph of this equation.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 方程 [7.2](#eq-heaviside-step-func) 等价于以下算法。图 [7.7](../Text/07.xhtml#fig-step-1D)
    显示了此方程的图形。
- en: Algorithm 7.4 Heaviside step function as an algorithm
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 7.4 海维塞德阶跃函数作为算法
- en: '**if** *x* < 0 **then**'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**if** *x* < 0 **then**'
- en: return 0
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 返回 0
- en: '**else**'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**else**'
- en: return 1
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 返回 1
- en: '**end** **if**'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**结束** **if**'
- en: '![](../../OEBPS/Images/CH07_F07_Chaudhury.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH07_F07_Chaudhury.png)'
- en: Figure 7.7 Heaviside step function graph
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7 海维塞德阶跃函数图
- en: 7.3.2 Hyperplanes
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.2 超平面
- en: In section [2.8](02.xhtml#sec-hyperplanes), we discussed hyperplanes. They are
    represented by equation [2.14](02.xhtml#eq-plane-1). In figure [2.9](02.xhtml#fig-planar-classifier),
    we saw the role that hyperplanes play in classifiers; we briefly revisit the idea
    here.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 [2.8](02.xhtml#sec-hyperplanes) 节中，我们讨论了超平面。它们由方程 [2.14](02.xhtml#eq-plane-1)
    表示。在第 [2.9](02.xhtml#fig-planar-classifier) 节的图中，我们看到了超平面在分类器中的作用；我们在这里简要回顾这个概念。
- en: In section [2.1.1](02.xhtml#subsec-vec-geom-ml), we saw that *d*-element vectors
    are geometrical analogs of points in a *d*-dimensional space. Let ![](../../OEBPS/Images/AR_x.png)
    denote the vectors (or, equivalently, points) in the space of input vectors. For
    a fixed vector ![](../../OEBPS/Images/AR_w.png) and fixed scalar *b*, the equation
    for a hyperplane in that space is
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 [2.1.1](02.xhtml#subsec-vec-geom-ml) 节中，我们看到了*d*-元素向量是*d*-维空间中点的几何类比。用 ![](../../OEBPS/Images/AR_x.png)
    表示输入向量空间中的向量（或等价地，点）。对于固定的向量 ![](../../OEBPS/Images/AR_w.png) 和固定的标量 *b*，该空间中超平面的方程是
- en: '![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) + *b*
    = 0'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) + *b*
    = 0'
- en: (meaning all points ![](../../OEBPS/Images/AR_x.png) satisfying this equation
    lie on the plane). The vector ![](../../OEBPS/Images/AR_w.png) is the normal to
    the plane. This becomes intuitively obvious when we observe that if we take any
    two points on the plane, say ![](../../OEBPS/Images/AR_x.png)[0] and ![](../../OEBPS/Images/AR_x.png)[1],
    then
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: （意味着满足此方程的所有点 ![](../../OEBPS/Images/AR_x.png) 都位于平面上）。向量 ![](../../OEBPS/Images/AR_w.png)
    是平面的法线。当我们观察到如果我们取平面上的任意两点，比如说 ![](../../OEBPS/Images/AR_x.png)[0] 和 ![](../../OEBPS/Images/AR_x.png)[1]，那么
- en: '*![](../../OEBPS/Images/AR_w.png)^T*![](../../OEBPS/Images/AR_x.png)[0] + *b*
    = 0'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../../OEBPS/Images/AR_w.png)^T*![](../../OEBPS/Images/AR_x.png)[0] + *b*
    = 0'
- en: '*![](../../OEBPS/Images/AR_w.png)^T*![](../../OEBPS/Images/AR_x.png)[1] + *b*
    = 0'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../../OEBPS/Images/AR_w.png)^T*![](../../OEBPS/Images/AR_x.png)[1] + *b*
    = 0'
- en: Subtracting, we get
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 相减，我们得到
- en: '*![](../../OEBPS/Images/AR_w.png)^T*(![](../../OEBPS/Images/AR_x.png)[1] -
    ![](../../OEBPS/Images/AR_x.png)[0]) = 0'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](../../OEBPS/Images/AR_w.png)^T*(![](../../OEBPS/Images/AR_x.png)[1] -
    ![](../../OEBPS/Images/AR_x.png)[0]) = 0'
- en: But (![](../../OEBPS/Images/AR_x.png)[1] - ![](../../OEBPS/Images/AR_x.png)[0]) is
    the vector joining two arbitrary points on the plane. This means the *line joining
    any pair of points on the plane is perpendicular to ![](../../OEBPS/Images/AR_w.png)*
    (in section [2.5.2](02.xhtml#subsec-dotprod-ml), we discussed dot products, and
    in section [2.6](02.xhtml#section-orthogonality), we saw that if the dot product
    between two vectors is zero, the vectors are orthogonal—perpendicular to each
    other). Hence, ![](../../OEBPS/Images/AR_w.png) is orthogonal to all lines lying
    on the plane. In other words, ![](../../OEBPS/Images/AR_w.png) is normal to the
    plane.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 但 (![](../../OEBPS/Images/AR_x.png)[1] - ![](../../OEBPS/Images/AR_x.png)[0])
    是连接平面上两个任意点的向量。这意味着连接平面上任何一对点的线垂直于 ![](../../OEBPS/Images/AR_w.png)*（在第 [2.5.2](02.xhtml#subsec-dotprod-ml)
    节中，我们讨论了点积，在第 [2.6](02.xhtml#section-orthogonality) 节中，我们看到了如果两个向量的点积为零，则这两个向量是正交的——相互垂直）。因此，![](../../OEBPS/Images/AR_w.png)
    垂直于平面上的所有线。换句话说，![](../../OEBPS/Images/AR_w.png) 垂直于平面。
- en: 'The hyperplane ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b* = 0 partitions the space into two regions with distinct signs for the expression
    ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) + *b*. That
    is to say, the hyperplane can serve as a decision boundary, as shown in figure
    [7.6](#fig-hyperplane-sign). Not just a hyperplane but any hypersurface can partition
    space in this fashion. This is true for any dimensionality of ![](../../OEBPS/Images/AR_x.png):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 超平面 ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) + *b*
    = 0 将空间划分为两个区域，这两个区域的 ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b* 表达式的符号不同。也就是说，超平面可以作为决策边界，如图 [7.6](#fig-hyperplane-sign) 所示。不仅超平面，任何超曲面都可以以这种方式划分空间。这对于任何维度的
    ![](../../OEBPS/Images/AR_x.png) 都成立：
- en: If the expression ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b* evaluates to *zero*, the point ![](../../OEBPS/Images/AR_x.png) lies *on
    the hyperplane* ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b* = 0.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果表达式 ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) +
    *b* 的值为 *零*，则点 ![](../../OEBPS/Images/AR_x.png) 位于 *超平面* ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b* = 0 上。
- en: If the sign of the expression ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b* is *negative*, the point ![](../../OEBPS/Images/AR_x.png) lies on *one side
    of the hyperplane*.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果表达式 ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) +
    *b* 的符号为 *负*，则点 ![](../../OEBPS/Images/AR_x.png) 位于 *超平面* 的 *一侧*。
- en: If the sign of the expression ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b* is *positive*, the point ![](../../OEBPS/Images/AR_x.png) lies on the *other
    side of the hyperplane*.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果表达式 ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) +
    *b* 的符号为 *正*，则点 ![](../../OEBPS/Images/AR_x.png) 位于 *超平面* 的 *另一侧*。
- en: 7.3.3 Perceptrons and classification
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.3 感知器和分类
- en: The perceptron combines the step function and a hyperplane into a single function.
    It represents the function
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器将步进函数和超平面结合成一个单一函数。它表示的函数
- en: '*P*(![](../../OEBPS/Images/AR_x.png)) ≡ *ϕ*(![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b*)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*P*(![](../../OEBPS/Images/AR_x.png)) ≡ *ϕ*(![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png)
    + *b*)'
- en: Equation 7.3
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 方程 7.3
- en: 'where *ϕ* is the Heaviside step function from equation [7.2](#eq-heaviside-step-func).
    Combining our insights from sections [7.3.1](../Text/07.xhtml#step-func) and [7.3.2](#sec-hyperplanes-recap),
    we can see that the perceptron function maps all points on one side of the (![](../../OEBPS/Images/AR_w.png),
    *b*) plane to zero and all points on the other side of the same plane to 1. In
    other words, it performs as a linear classifier, with the (![](../../OEBPS/Images/AR_w.png),
    *b*) plane as the decision boundary. Figure [7.8](#fig-perceptron-graph) graphs
    the perceptron function for a 2D input space (the graph itself is in 3D space:
    it maps points on one side of the decision boundary to the plane *Z* = 0 and points
    on the other side to the plane *Z* = 1).'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *ϕ* 是来自方程 [7.2](#eq-heaviside-step-func) 的 Heaviside 步进函数。结合我们在第 [7.3.1](../Text/07.xhtml#step-func)
    和 [7.3.2](#sec-hyperplanes-recap) 节中的见解，我们可以看到感知器函数将 (![](../../OEBPS/Images/AR_w.png),
    *b*) 平面一侧的所有点映射到零，并将同一平面另一侧的所有点映射到 1。换句话说，它作为一个线性分类器，将 (![](../../OEBPS/Images/AR_w.png),
    *b*) 平面作为决策边界。图 [7.8](#fig-perceptron-graph) 绘制了 2D 输入空间的感知器函数（该图本身是在 3D 空间中的：它将决策边界一侧的点映射到
    *Z* = 0 平面，并将另一侧的点映射到 *Z* = 1 平面）。
- en: '![](../../OEBPS/Images/CH07_F08_Chaudhury.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH07_F08_Chaudhury.png)'
- en: Figure 7.8 although the input space is 2D, the perceptron graph is 3D. The decision
    boundary is indicated by the long diagonal straight line. It maps points on one
    side of the decision boundary to the *Z* = 0 plane and the points on the other
    side to the *Z* = 1 plane.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8 虽然输入空间是 2D 的，但感知器图是 3D 的。决策边界由长对角线直线表示。它将决策边界一侧的点映射到 *Z* = 0 平面，另一侧的点映射到
    *Z* = 1 平面。
- en: Of course, in real life, we do not know the exact regions corresponding to classes.
    Rather, we have sampled input points with their manually labeled classes as training
    data. The decision surface must be constructed based on this training data only.
    In figure [7.4](#fig-2d-decision-boundary-training-data), we saw an example decision
    boundary in 2D along with some good and bad training data sets. To get a mental
    picture of sampled training data sets in higher dimensions, look at figure [7.5a](#fig-perceptron-training-data)
    again. In this simple situation, a single hyperplanar decision boundary is sufficient
    to partition the training points. This means a single perceptron-based neural
    network will suffice as a classifier. Figures [7.5b](#fig-perceptron-bad-planar-separator-0)
    and [7.5c](#fig-perceptron-bad-planar-separator-1) depict some planes (perceptrons
    with specific (![](../../OEBPS/Images/AR_w.png), *b*) values) that poorly partition
    the training data. Figure [7.5d](#fig-perceptron-good-planar-separator) shows
    an optimal perceptron (planar separator). This tells us that there are good values
    of ![](../../OEBPS/Images/AR_w.png) and *b* that optimally partition the training
    data, as well as bad values. As mentioned earlier, good values are determined
    through training, which we cover in chapter 8.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在现实生活中，我们不知道与类别对应的精确区域。相反，我们采样了带有手动标记类别的输入点作为训练数据。决策表面必须仅基于此训练数据构建。在图 [7.4](#fig-2d-decision-boundary-training-data)
    中，我们看到了一个二维示例决策边界和一些好的和坏的训练数据集。为了在更高维度的采样训练数据集中获得心理图像，请再次查看图 [7.5a](#fig-perceptron-training-data)。在这种情况下，单个超平面决策边界足以划分训练点。这意味着单个基于感知器的神经网络就足以作为分类器。图
    [7.5b](#fig-perceptron-bad-planar-separator-0) 和 [7.5c](#fig-perceptron-bad-planar-separator-1)
    描述了一些（具有特定 (![](../../OEBPS/Images/AR_w.png), *b*) 值的感知器）划分训练数据不佳的平面。图 [7.5d](#fig-perceptron-good-planar-separator)
    显示了一个最优感知器（平面分离器）。这告诉我们，存在最优的 ![](../../OEBPS/Images/AR_w.png) 和 *b* 值，可以最优地划分训练数据，以及不良的值。如前所述，好的值是通过训练确定的，我们将在第
    8 章中介绍。
- en: The perceptron effectively partitions with a *planar* decision surface. This
    works only in simple problems. For an instance of a situation where a planar decision
    surface will *not* work, see figure [7.9](#fig-multiplane-decision-boundary).
    It depicts a problem where one class maps to the set of points sandwiched between
    two planes and the other class to the rest of the points in the input space. It
    is impossible to achieve the required partitioning with a single plane, so such
    a decision boundary cannot be modeled with a single perceptron. Later we will
    see how to model such complex decision boundaries with multiple perceptrons.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器有效地使用 *平面* 决策表面进行划分。这仅在简单问题中有效。对于平面决策表面将 *不会* 适用的情形，请参见图 [7.9](#fig-multiplane-decision-boundary)。它描述了一个问题，其中一个类别映射到两个平面之间的点集（标记为
    +），另一个类别映射到输入空间中的其余点。使用单个平面无法实现所需的划分，因此无法用单个感知器来模拟这种决策边界。稍后我们将看到如何使用多个感知器来模拟这种复杂的决策边界。
- en: '![](../../OEBPS/Images/CH07_F09_Chaudhury.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F09_Chaudhury.png)'
- en: Figure 7.9 Multiplane decision boundary. One class corresponds to the points
    in the region sandwiched between the planes (marked +). The remaining points correspond
    to the other class marked –). This decision boundary **cannot** be represented
    with a single plane.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9 多平面决策边界。一个类别对应于两个平面之间的区域中的点（标记为 +）。其余的点对应于其他类别（标记为 –）。这种决策边界 **不能** 用单个平面表示。
- en: NOTE Fully functional code for perceptrons, executable via Jupyter Notebook,
    can be found at [http://mng.bz/9Ne7](http://mng.bz/9Ne7).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：感知器的完整功能代码，可通过 Jupyter Notebook 执行，可在 [http://mng.bz/9Ne7](http://mng.bz/9Ne7)
    找到。
- en: The following listing shows the PyTorch code for a perceptron.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表展示了感知器的 PyTorch 代码。
- en: Listing 7.1 Perceptron
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.1 感知器
- en: '[PRE0]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '① *X* : *n* × *d* tensor; each row is an input vector of size d. *w* : *m*
    × *d* tensor.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '① *X* : *n* × *d* 张量；每一行是一个大小为 d 的输入向量。*w* : *m* × *d* 张量。'
- en: ② Adds a column of 1s. *X* ↦ *n* × (*d*+1) tensor.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ② 添加一列 1。*X* ↦ *n* × (*d*+1) 张量。
- en: ③ Combines weights and biases
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 结合权重和偏差
- en: ④ Matrix multiplication of X and W
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ④ X 和 W 的矩阵乘法
- en: ⑤ Applies the Heaviside step function
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 应用Heaviside阶跃函数
- en: ⑥ A single perceptron
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 单个感知器
- en: 7.3.4 Modeling common logic gates with perceptrons
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.4 使用感知器建模常见逻辑门
- en: 'Neural networks provide a structured way of modeling complex functions by connecting—via
    weighted edges—repeated instances of a simple building block called the perceptron.
    In this section, we explore the idea of function modeling via perceptrons. We
    start with modeling extremely simple logical functions (AND, OR, NOT, voting)
    that can be represented with single perceptrons. Then we look at the XOR function,
    one of the simplest functions that *cannot* be represented with a single perceptron;
    we see that it *can* be modeled with *multiple* perceptrons. Next we discuss Cybenko’s
    theorem, which states that most functions of interest can be modeled with as much
    accuracy as we want via perceptrons, with a single hidden layer between inputs
    and outputs. Unfortunately, this is less practical than it sounds: the catch is
    that although any function can be modeled to any accuracy, there is no limit on
    how many perceptrons are required to do the modeling. The more complicated the
    target function is, the more perceptrons are required. In practice, we often use
    many layers instead of one.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络通过连接称为感知器的简单构建块的重复实例（通过加权边连接）提供了一种结构化的方式来建模复杂函数。在本节中，我们探讨了通过感知器进行函数建模的想法。我们首先从使用单个感知器表示的极其简单的逻辑函数（与、或、非、投票）建模开始。然后我们来看XOR函数，这是不能使用单个感知器表示的简单函数之一；我们看到它可以用*多个*感知器来建模。接下来我们讨论Cybenko定理，该定理表明，大多数感兴趣的函数可以通过感知器以我们想要的任何精度进行建模，输入和输出之间有一个隐藏层。不幸的是，这比听起来要少一些实际应用：关键在于，尽管任何函数都可以建模到任何精度，但建模所需的感知器数量没有限制。目标函数越复杂，所需的感知器就越多。在实践中，我们通常使用多层而不是一层。
- en: A perceptron for logical AND
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器用于逻辑与
- en: 'Figure [7.18](#fig-perceptron-logical-and) depicts this perceptron. It takes
    two inputs, *x*[0] and *x*[1], which are weighted with *w*[0] = 1 and *w*[1] =
    1, respectively; the bias is −1.5 actually, a wide range of bias values will do).
    Overall, the perceptron implements the function *ϕ*(*x*[0] + *x*[1]−1.5). This
    function emits 1 when *x*[0] + *x*[1] − 1.5 ≥ 0: that is, *x*[0] + *x*[1] ≥ 1.5.
    Since the variables are binary (meaning they can only take the value 0 or 1),
    this can happen only when both inputs are 1. If either is zero, their sum is less
    than 1.5, and *y* is 0.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图[7.18](#fig-perceptron-logical-and)展示了这个感知器。它接受两个输入，*x*[0]和*x*[1]，分别用*w*[0]
    = 1和*w*[1] = 1加权；偏置为-1.5（实际上，广泛的偏置值都可以）。总的来说，感知器实现了函数*ϕ*(*x*[0] + *x*[1]−1.5)。当*x*[0]
    + *x*[1] − 1.5 ≥ 0时，该函数发出1：也就是说，*x*[0] + *x*[1] ≥ 1.5。由于变量是二元的（意味着它们只能取0或1的值），这只有在两个输入都是1的情况下才会发生。如果其中一个是零，它们的和就小于1.5，*y*就是0。
- en: '![](../../OEBPS/Images/CH07_F10a_Chaudhury.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F10a_Chaudhury.png)'
- en: '(a) Perceptron for a logical AND function: *y* = *x*[0] ∨ *x*[1]'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 逻辑与函数的感知器：*y* = *x*[0] ∨ *x*[1]
- en: '![](../../OEBPS/Images/CH07_F10b_Chaudhury.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F10b_Chaudhury.png)'
- en: '(b) Perceptron for a logical OR function: *y* = *x*[0] ∧ *x*[1]'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 逻辑或函数的感知器：*y* = *x*[0] ∧ *x*[1]
- en: '![](../../OEBPS/Images/CH07_F10c_Chaudhury.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F10c_Chaudhury.png)'
- en: '(c) Perceptron for a logical NOT function: *y* = ¬*x*[0]'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 逻辑非函数的感知器：*y* = ¬*x*[0]
- en: Figure 7.10 functions are binary, meaning they can be either 0 or 1.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10中的函数是二元的，意味着它们可以是0或1。
- en: 'The situation is depicted geometrically in figure [7.11a](#fig-perceptron-logical-and-geom).
    The thick diagonal line corresponds to *x*[0] + *x*[1] ≥ 1.5. It partitions the
    plane into unshaded and shaded All points on the unshaded half-plane have an output
    value *y* = 0, and all points on the shaded half-plane have the output value *y*
    = 1. There are only four possible input points: (*x*[0] = 1, *x*[1] = 1), (*x*[0]
    = 1, *x*[1] = 1), (*x*[0] = 1, *x*[1] = 1), (*x*[0]=1, *x*[1] = 1). The point
    (*x*[0]=1, *x*[1] = 1) falls on the shaded side and the others on the unshaded
    side—which is exactly the logical AND function.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况在图[7.11a](#fig-perceptron-logical-and-geom)中用几何方式表示。粗对角线对应于*x*[0] + *x*[1]
    ≥ 1.5。它将平面分为无阴影和阴影部分。无阴影半平面的所有点输出值*y* = 0，阴影半平面的所有点输出值*y* = 1。只有四个可能的输入点：(*x*[0]
    = 1, *x*[1] = 1)，(*x*[0] = 1, *x*[1] = 1)，(*x*[0] = 1, *x*[1] = 1)，(*x*[0]=1,
    *x*[1] = 1)。点(*x*[0]=1, *x*[1] = 1)位于阴影侧，其他点位于无阴影侧——这正是逻辑与函数。
- en: '![](../../OEBPS/Images/CH07_F11a_Chaudhury.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F11a_Chaudhury.png)'
- en: '(a) Logical AND decision boundary: *x*[0] + *x*[1] = 1.5'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 逻辑与决策边界：*x*[0] + *x*[1] = 1.5
- en: '![](../../OEBPS/Images/CH07_F11b_Chaudhury.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F11b_Chaudhury.png)'
- en: '(b) Logical OR decision boundary: *x*[0] + *x*[1] = 0.5'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 逻辑或决策边界：*x*[0] + *x*[1] = 0.5
- en: '![](../../OEBPS/Images/CH07_F11c_Chaudhury.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH07_F11c_Chaudhury.png)'
- en: '(c) Logical NOT decision boundary: *x*[0] = 0.5'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 逻辑非决策边界：*x*[0] = 0.5
- en: Figure 7.11 Geometrical views for the perceptrons in figure [7.10](#fig-perceptron-logical-functions).
    Each dot represents an input point(a [*x*[0] *x*[1]] vector). The shaded dots
    map to an output value of 1, and the unshaded dots map to an output value of 0.
    The thick line indicates the decision boundary.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11 展示了图 [7.10](#fig-perceptron-logical-functions) 中的感知器的几何视图。每个点代表一个输入点（[*x*[0]
    *x*[1]] 矢量）。阴影点映射到输出值为 1，无阴影点映射到输出值为 0。粗线表示决策边界。
- en: A perceptron for logical OR
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑或感知器
- en: 'Figure [7.10b](#fig-perceptron-logical-or) depicts this perceptron. It takes
    two inputs, *x*[0] and *x*[1], which are weighted with *w*[0] = 1 and *w*[1] =
    1, respectively; the bias is −0.5. Overall, the perceptron implements the function
    *ϕ*(*x*[0] + *x*[1]−0.5). This function emits 1 when *x*[0] + *x*[1] − 0.5 ≥ 0:
    that is, *x*[0] + *x*[1] ≥ 0.5. Since the variables are binary (0 or 1), this
    can happen when either or both inputs are 1. If and only if both of them are zero,
    their sum is zero (less than 0.5), and *y* is 0.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [7.10b](#fig-perceptron-logical-or) 展示了该感知器。它接受两个输入，*x*[0] 和 *x*[1]，分别乘以 *w*[0]
    = 1 和 *w*[1] = 1，偏置为 −0.5。总体而言，感知器实现了函数 *ϕ*(*x*[0] + *x*[1]−0.5)。当 *x*[0] + *x*[1]
    − 0.5 ≥ 0 时，该函数输出 1：即 *x*[0] + *x*[1] ≥ 0.5。由于变量是二进制（0 或 1），这只有在输入为 1 或两个输入都为
    1 时才会发生。只有当两者都为零时，它们的和为零（小于 0.5），并且 *y* 为 0。
- en: The situation is shown geometrically in figure [7.11b](#fig-perceptron-logical-or-geom).
    The thick line corresponds to *x*[0] + *x*[1] ≥ 0.5, partitioning the input plane
    into an unshaded half-plane (all points on this half-plane have output *y* = 0)
    and a shaded half-plane output *y* = 1). Of the four possible input points, (0,0)
    falls on the unshaded side (*y* = 1) and the remaining three on the shaded side
    (*y* = 1)—which is exactly the logical OR function.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况在图 [7.11b](#fig-perceptron-logical-or-geom) 中以几何方式表示。粗线对应于 *x*[0] + *x*[1]
    ≥ 0.5，将输入平面分为无阴影的半平面（该半平面上的所有点输出 *y* = 0）和有阴影的半平面输出 *y* = 1。在四个可能的输入点中，（0,0）位于无阴影的一侧（*y*
    = 1），其余三个位于阴影一侧（*y* = 1），这正是逻辑或函数。
- en: A perceptron for logical NOT
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑非感知器
- en: This perceptron is shown in figures [7.10c](#fig-perceptron-logical-not) and
    [7.11c](#fig-perceptron-logical-not-geom), which should be self-explanatory by
    now.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 该感知器在图 [7.10c](#fig-perceptron-logical-not) 和 [7.11c](#fig-perceptron-logical-not-geom)
    中展示，现在应该已经很直观了。
- en: NOTE Fully functional code for modeling various logical gates using perceptrons,
    executable via Jupyter Notebook, can be found at [http://mng.bz/jBRr](http://mng.bz/jBRr).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：使用感知器建模各种逻辑门的全功能代码，可通过 Jupyter Notebook 执行，可在 [http://mng.bz/jBRr](http://mng.bz/jBRr)
    找到。
- en: Listing 7.2 Modeling logical gates using perceptrons
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.2 使用感知器建模逻辑门
- en: '[PRE1]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ① Input data points
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ① 输入数据点
- en: ② Instantiates the weights
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ② 实例化权重
- en: ③ Instantiates the bias
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 实例化偏置
- en: ④ Output
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 输出
- en: '7.4 Toward more expressive power: Multilayer perceptrons (MLPs)'
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 向更强大的表达力：多层感知器（MLPs）
- en: 'There is a remarkably simple logical function that, somewhat surprisingly,
    cannot be modeled with a single perceptron: XOR. We discuss it now.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个非常简单的逻辑函数，出人意料的是，不能用单个感知器来建模：异或。我们现在来讨论它。
- en: '![](../../OEBPS/Images/CH07_F12b_Chaudhury.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH07_F12b_Chaudhury.png)'
- en: (a) Geometric view of the logical XOR perceptron. The decision boundary has
    *two* lines, so using a single perceptron is impossible.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 逻辑异或感知器的几何视图。决策边界有 *两条* 线，因此使用单个感知器是不可能的。
- en: '![](../../OEBPS/Images/CH07_F12a_Chaudhury.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH07_F12a_Chaudhury.png)'
- en: (b) MLP for the logical XOR function. Note that weights and biases have superscripts
    in parentheses indicating the layer index. This is a two-layered network. Layer
    0 is hidden.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 逻辑异或函数的MLP。注意，权重和偏置在括号中有上标，表示层索引。这是一个两层网络。层 0 是隐藏层。
- en: 'Figure 7.12 Logical XOR: Geometric and perceptron view'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12 逻辑异或：几何和感知器视图
- en: 7.4.1 MLP for logical XOR
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.1 逻辑异或的MLP
- en: Figure [7.12a](#fig-xor) shows the four possible input points on the plane and
    how the plane needs to be partitioned to model the XOR function. The points (0,0),
    (1,1) (unshaded) both map to output 0 and should be on the same side of the decision
    boundary, while the points (0,1), (1,0) shaded) map to output value 1 and should
    be on the other side of the decision boundary.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图[7.12a](#fig-xor)显示了平面上可能的四个输入点以及如何划分平面以建模XOR函数。点(0,0)、(1,1)（未着色）都映射到输出0，应该在决策边界的同一侧，而点(0,1)、(1,0)（着色）映射到输出值1，应该在决策边界的另一侧。
- en: It is easy to see that it is impossible to draw a single straight line in this
    plane such that the shaded points are on one side and the unshaded points are
    on the other. Remember, a perceptron essentially introduces a linear decision
    boundary. Hence it is impossible to have a single perceptron modeling this function.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易看出，在这个平面上不可能画一条直线，使得着色点在一侧，未着色点在另一侧。记住，感知器本质上引入了一个线性决策边界。因此，不可能有一个单独的感知器来模拟这个函数。
- en: However, it is possible to model the logical XOR function via multiple perceptrons.
    One such model is shown in figure [7.12b](#fig-xor).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通过多个感知器可以建模逻辑XOR函数。其中一个这样的模型在图[7.12b](#fig-xor)中展示。
- en: '7.5 Layered networks of perceptrons: MLPs or neural networks'
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.5 感知器的分层网络：MLP或神经网络
- en: The XOR example tells us that we cannot do much with single perceptrons. We
    must connect more than one perceptron into a network to solve practical problems.
    This is a *neural network*. How do we organize such a network of connected perceptrons?
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: XOR示例告诉我们，我们无法仅用单个感知器做很多事情。我们必须将多个感知器连接成一个网络来解决实际问题。这是一个**神经网络**。我们如何组织这样一个连接的感知器网络？
- en: 7.5.1 Layering
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.1 分层
- en: '*Layering* is the most popular way to organize perceptrons into a neural network.
    Figure [7.12b](#fig-perceptron-logical-xor) is our first example of an MLP—most
    of the remainder of the book talks about MLPs.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '**分层**是将感知器组织成神经网络的流行方式。图[7.12b](#fig-perceptron-logical-xor)是我们第一个MLP的例子——本书的其余部分大部分都在讨论MLP。'
- en: 'Note how the perceptrons in the XOR network (figure [7.12b](#fig-perceptron-logical-xor))
    are organized:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意XOR网络（图[7.12b](#fig-perceptron-logical-xor)）中的感知器是如何组织的：
- en: The layers are numbered with increasing integers from input to output.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层从输入到输出用递增的整数编号。
- en: The output of a perceptron in layer *i* is only fed as input to perceptrons
    in layer *i* + 1. No other connections are allowed. This keeps the network manageable
    andfacilitates updating the weights during training via a technique called *backpropagation*,
    which we discuss in the next chapter.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层*i*中感知器的输出仅作为输入提供给层*i* + 1中的感知器。不允许其他连接。这使网络易于管理，并便于通过称为**反向传播**的技术在训练期间更新权重，我们将在下一章讨论这一技术。
- en: Outputs of all layers but the last are invisible (do not directly contribute
    tothe output). Such layers are called *hidden layers*. In figure [7.12b](#fig-perceptron-logical-xor),
    layer 0 ishidden.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了最后一层之外的所有层的输出都是不可见的（不直接贡献于输出）。这样的层被称为**隐藏层**。在图[7.12b](#fig-perceptron-logical-xor)中，层0是隐藏的。
- en: Each weight and bias element belongs to one and only one layer. Throughout this
    book, we indicate the layer index for a weight or bias element as a superscript
    within parentheses.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个权重和偏置元素只属于一个层。在本书中，我们用括号内的上标表示权重或偏置元素的层索引。
- en: MLPs with two or more hidden layers can be called *deep neural networks*. This
    is the origin of the word *deep* in *deep learning*.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有两个或更多隐藏层的MLP可以称为**深度神经网络**。这是“深度学习”中“深度”一词的起源。
- en: 7.5.2 Modeling logical functions with MLPs
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.2 使用MLP建模逻辑函数
- en: Any logical function can be expressed as a truth table. Hence, if we can prove
    that all truth tables can be implemented via MLPs, we are done. This is the approach
    we take here.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 任何逻辑函数都可以表示为真值表。因此，如果我们能证明所有真值表都可以通过MLP实现，我们就完成了。这是我们采取的方法。
- en: NOTE In the following discussion, no symbol (à la multiplication) between two
    variables indicates logical AND, and a + symbol indicates logical OR.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在以下讨论中，两个变量之间的符号（如乘法）不表示逻辑与，而加号表示逻辑或。
- en: Table 7.1 Truth table for the logical function *y* = *x̄*[0]*x*[1] ¸ *x*[0]*x̄*[1]
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 表7.1逻辑函数*y* = *x̄*[0]*x*[1] ¸ *x*[0]*x̄*[1]的真值表
- en: '| *x*[0] | *x*[1] | *y*   |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| *x*[0] | *x*[1] | *y*   |'
- en: '| --- | --- | --- |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0 | 0 | 0 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 0 |'
- en: '| 0 | 1 | 1 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1 | 1 |'
- en: '| 1 | 0 | 1 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0 | 1 |'
- en: '| 1 | 1 | 0 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 0 |'
- en: Let’s start with a simple two-variable logical functions *y* = *x̄*[0]*x*[1]
    + *x*[0]*x̄*[1]. Table [7.1](#tab-logical-xor-truthtable) shows the corresponding
    truth table. To create the equivalent MLP, we must pick the rows corresponding
    to *y* = 1. Each row can be expressed as an AND of the input variables or their
    complements. For instance, the row *x*[0] = 0 and *x*[1] = 1, *y* = 1 corresponds
    to *x̄*[0]*x*[1]—the first term of the function we are trying to implement—and
    can be implemented by the perceptron shown in figure [7.13a](#fig-logical-xor-truthtable-perceptron-and-0).
    The row *x*[0] = 1 and *x*[1] = 0, *y* = 1 corresponds to *x*[0]*x̄*[1]—the second
    term of the function we are trying to implement—and can be implemented by the
    perceptron shown in figure [7.13b](#fig-logical-xor-truthtable-perceptron-and-1).
    We have implemented the individual terms of the function; all that remains is
    to OR them together into a final MLP, as shown in figure [7.13c](#fig-logical-xor-truthtable-perceptron-orofands).
    This logical function is our old friend, logical XOR, and the overall function
    in figure [7.13](#fig-logical-xor-truthtable-perceptron) is the same as figure
    [7.12](#fig-xor). In this fashion, arbitrary logical expressions in any number
    of variables can be modeled using MLPs.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从简单的二维逻辑函数 *y* = *x̄*[0]*x*[1] + *x*[0]*x̄*[1] 开始。表 [7.1](#tab-logical-xor-truthtable)
    展示了相应的真值表。为了创建等效的 MLP，我们必须选择对应于 *y* = 1 的行。每一行都可以表示为输入变量或其补码的 AND。例如，行 *x*[0]
    = 0 和 *x*[1] = 1，*y* = 1 对应于 *x̄*[0]*x*[1]——我们试图实现的函数的第一个项——可以通过图 [7.13a](#fig-logical-xor-truthtable-perceptron-and-0)
    中显示的感知器实现。行 *x*[0] = 1 和 *x*[1] = 0，*y* = 1 对应于 *x*[0]*x̄*[1]——我们试图实现的函数的第二个项——可以通过图
    [7.13b](#fig-logical-xor-truthtable-perceptron-and-1) 中显示的感知器实现。我们已经实现了函数的各个项；剩下的只是将它们
    OR 到一起形成一个最终的 MLP，如图 [7.13c](#fig-logical-xor-truthtable-perceptron-orofands)
    所示。这个逻辑函数是我们熟悉的逻辑 XOR，图 [7.13](#fig-logical-xor-truthtable-perceptron) 中的整体函数与图
    [7.12](#fig-xor) 相同。以这种方式，可以使用 MLP 对任意数量的变量中的任意逻辑表达式进行建模。
- en: '![](../../OEBPS/Images/CH07_F13a_Chaudhury.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../../OEBPS/Images/CH07_F13a_Chaudhury.png)'
- en: (a) Perceptron for *x̄*[0]*x*[1]
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 对于 *x̄*[0]*x*[1] 的感知器
- en: '![](../../OEBPS/Images/CH07_F13b_Chaudhury.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../../OEBPS/Images/CH07_F13b_Chaudhury.png)'
- en: (b) Perceptron for *x*[0]*x̄*[1]
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 对于 *x*[0]*x̄*[1] 的感知器
- en: '![](../../OEBPS/Images/CH07_F13c_Chaudhury.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../../OEBPS/Images/CH07_F13c_Chaudhury.png)'
- en: (c) MLP for *x̄*[0]*x*[1] + *x*[0]*x̄*[1]
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 对于 *x̄*[0]*x*[1] + *x*[0]*x̄*[1] 的 MLP
- en: Figure 7.13 MLP for the logical function corresponding to table [7.1](#tab-logical-xor-truthtable)
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13 对应于表 [7.1](#tab-logical-xor-truthtable) 的逻辑函数的 MLP
- en: Listing 7.3 Multilayered perceptron (MLP)
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.3 多层感知器 (MLP)
- en: '[PRE2]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ① MLP
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ① MLP
- en: 7.5.3 Cybenko’s universal approximation theorem
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.3 Cybenko 的通用近似定理
- en: Any function *y* = *f*(*x*) that is continuous in an interval *x* ∈ (*a*, *b*)
    can be approximated with a set of towers (vertical rectangles) in that interval.
    This is a direct consequence of the *mean value for integrals* theorem in calculus.
    The idea is depicted in figure [7.14](#fig-approx-with-rect-1d), where a complicated
    function (depicted by the curve) is approximated by a sequence of towers of various
    heights. The thinner the towers, the greater the number of towers, and the more
    accurate the approximation.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 任何在区间 *x* ∈ (*a*, *b*) 上连续的函数 *y* = *f*(*x*) 都可以用该区间内的一组塔（垂直矩形）来近似。这是微积分中积分平均值定理的直接结果。这一想法在图
    [7.14](#fig-approx-with-rect-1d) 中得到展示，其中复杂函数（由曲线表示）被一系列不同高度的塔近似。塔越细，塔的数量越多，近似就越准确。
- en: '![](../../OEBPS/Images/CH07_F14_Chaudhury.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../../OEBPS/Images/CH07_F14_Chaudhury.png)'
- en: Figure 7.14 Approximating a complicated function with towers
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14 使用塔近似复杂函数
- en: In section [7.5.3.1](#sec-towers), we show that any tower (with arbitrary height
    and location) can be constructed with MLPs. By summing these MLPs for individual
    towers, we can approximate the entire function. This is Cybenko’s theorem in a
    nutshell.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [7.5.3.1](#sec-towers) 节中，我们展示了任何塔（具有任意高度和位置）都可以用 MLP 构建出来。通过将这些 MLP 相加，我们可以近似整个函数。这就是
    Cybenko 定理的精髓。
- en: NOTE Although Cybenko’s theorem guarantees that any continuous function can
    be modeled using an MLP with a single hidden layer, the number of perceptrons
    in that MLP can become arbitrarily impracticably large. This is why, in real life,
    we rarely try to approximate complicated functions with a single hidden layer.
    We see later that additional layers help us cut down the number of perceptrons
    required.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：尽管Cybenko定理保证了任何连续函数都可以使用具有单个隐藏层的MLP进行建模，但该MLP中的感知器数量可能变得任意大而不切实际。这就是为什么在现实生活中，我们很少尝试用单个隐藏层来近似复杂函数。我们稍后会看到，额外的层可以帮助我们减少所需的感知器数量。
- en: In particular, any decision boundary can be modeled in this fashion. Of course,
    the number of perceptrons needed may become impossibly large for many problems,
    making such a model practically unattainable.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，任何决策边界都可以用这种方式进行建模。当然，对于许多问题，所需的感知器数量可能变得无法实现，使得这种模型实际上无法实现。
- en: '![](../../OEBPS/Images/CH07_F15a_Chaudhury.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F15a_Chaudhury.png)'
- en: '(a) *ϕ*(*x*): positive *w* yields a regular step'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: (a) *ϕ*(*x*)：正*w*产生正常步进
- en: '![](../../OEBPS/Images/CH07_F15b_Chaudhury.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F15b_Chaudhury.png)'
- en: (b) Perceptron for a regular step
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 正常步进的感知器
- en: '![](../../OEBPS/Images/CH07_F15c_Chaudhury.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F15c_Chaudhury.png)'
- en: '(c) *ϕ*(−*x*): negative *w* yields a laterally flipped step'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: (c) *ϕ*(−*x*)：负*w*产生横向翻转步进
- en: '![](../../OEBPS/Images/CH07_F15d_Chaudhury.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F15d_Chaudhury.png)'
- en: (d) Perceptron for a laterally flipped step
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 翻转步进的感知器
- en: '![](../../OEBPS/Images/CH07_F15e_Chaudhury.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F15e_Chaudhury.png)'
- en: '(e) *ϕ*(−*x*+5): changing the bias shifts the step left or right'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: (e) *ϕ*(−*x*+5)：改变偏置将步进向左或向右移动
- en: '![](../../OEBPS/Images/CH07_F15f_Chaudhury.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F15f_Chaudhury.png)'
- en: (f) Perceptron for a laterally shifted step
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: (f) 横向移动的步进感知器
- en: '![](../../OEBPS/Images/CH07_F15g_Chaudhury.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F15g_Chaudhury.png)'
- en: '(g) (*ϕ*(*x*+5)+*ϕ*(−*x*+5)−1.5): ANDing a left-shifted step with a flipped,
    right-shifted step yields a tower'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: (g) (*ϕ*(*x*+5)+*ϕ*(−*x*+5)−1.5)：将左移的步进与翻转的右移步进进行AND操作得到一个塔
- en: '![](../../OEBPS/Images/CH07_F15h_Chaudhury.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F15h_Chaudhury.png)'
- en: (h) MLP for a 1D tower
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: (h) 1D塔的MLP
- en: Figure 7.15 Generating a 1D tower with perceptrons.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.15 使用感知器生成1D塔
- en: '![](../../OEBPS/Images/CH07_F16a_Chaudhury.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16a_Chaudhury.png)'
- en: (a) 2D step function along the *x*[0] (x) direction
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 沿*x*[0] (x)方向的2D步进函数
- en: '![](../../OEBPS/Images/CH07_F16b_Chaudhury.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16b_Chaudhury.png)'
- en: (b) Perceptron for a 2D step function along the *x*[0] (x) direction
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 沿*x*[0] (x)方向的2D步进函数感知器
- en: '![](../../OEBPS/Images/CH07_F16c_Chaudhury.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16c_Chaudhury.png)'
- en: (c) Equation for a 2D step function along the *x*[0] (x) direction
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 沿*x*[0] (x)方向的2D步进函数方程
- en: '![](../../OEBPS/Images/CH07_F16d_Chaudhury.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16d_Chaudhury.png)'
- en: (d) Flipped 2D step along the *x*[0] (x) direction
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 沿*x*[0] (x)方向的翻转2D步进
- en: '![](../../OEBPS/Images/CH07_F16e_Chaudhury.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16e_Chaudhury.png)'
- en: (e) Perceptron for a flipped 2D step along the *x*[0] (x) direction
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: (e) 沿*x*[0] (x)方向的翻转2D步进感知器
- en: '![](../../OEBPS/Images/CH07_F16f_Chaudhury.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16f_Chaudhury.png)'
- en: (f) Equation for a flipped 2D step along the *x*[0] (x) direction
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: (f) 沿*x*[0] (x)方向的翻转2D步进方程
- en: '![](../../OEBPS/Images/CH07_F16g_Chaudhury.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16g_Chaudhury.png)'
- en: (g) 2D wave along the *x*[0] x) direction
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: (g) 沿*x*[0] (x)方向的2D波
- en: '![](../../OEBPS/Images/CH07_F16h_Chaudhury.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16h_Chaudhury.png)'
- en: (h) MLP for a 2D wave along the *x*[0] (x) direction
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: (h) 沿*x*[0] (x)方向的2D波MLP
- en: '![](../../OEBPS/Images/CH07_F16i_Chaudhury.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16i_Chaudhury.png)'
- en: (i) Equation for a 2D wave along the *x*[0] (x) direction
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: (i) 沿*x*[0] (x)方向的2D波方程
- en: '![](../../OEBPS/Images/CH07_F16j_Chaudhury.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16j_Chaudhury.png)'
- en: (j) 2D wave along the *x*[1] y) direction
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: (j) 沿*x*[1] (y)方向的2D波
- en: '![](../../OEBPS/Images/CH07_F16k_Chaudhury.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16k_Chaudhury.png)'
- en: (k) MLP for a 2D wave along the *x*[1] (y) direction
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: (k) 沿*x*[1] (y)方向的2D波MLP
- en: '![](../../OEBPS/Images/CH07_F16l_Chaudhury.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F16l_Chaudhury.png)'
- en: (l) MLP for a 2D wave along the *x*[1] (y) direction
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: (l) 沿*x*[1] (y)方向的2D波MLP
- en: Figure 7.16 Generating 2D steps and waves with perceptrons.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.16 使用感知器生成2D步进和波
- en: Generating towers with MLPs
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 使用MLP生成塔
- en: The basic idea is depicted in figure [7.15](#fig-tower1d-all). We can obviously
    generate a regular step with a perceptron implementing *y* = *ϕ*(*x*). The corresponding
    graph is shown in figure [7.15a](#fig-pos-wt-step-1d). By imparting a bias of
    5, we can shift this step leftwards. The corresponding function is *y* = *ϕ*(*x*+5).
    Furthermore, using negative weight laterally flips the step. The corresponding
    function is *y* = *ϕ*(−*x*), whose graph is shown in figure [7.15c](#fig-neg-wt-step-1d).
    By imparting a bias of 5, we can shift the flipped step rightwards. Figure [7.15e](#fig-bias-change-1d)
    shows a flipped and right-shifted step corresponding to the function *y* = *ϕ*(−*x*+5),
    whose perceptron is shown in figure [7.15f](#fig-bias-change-1d-perceptron). Logically
    ANDing a left-shifted step with a flipped and right-shifted step yields a tower
    in 1D. This corresponds to the function *y* = *ϕ*(*ϕ*(*x*+5)+*ϕ*(−*x*+5)−1.5),
    whose graph is shown in figure [7.15g](#fig-tower1d).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: The same idea also works for higher-dimensional inputs. We can generate a step
    in two variables (a 2D step) aligned to the *x*[0] direction using equation [7.4](#eq-step2dx).
    This equation’s graph is shown in figure [7.16a](#fig-pos-wt-step-2dx), and the
    perceptron implementing the equation is shown in figure [7.16b](#fig-pos-wt-step-2dx-perceptron).
    The flipped version of the same step can be generated via equation [7.5](#eq-flipped_step2dx).
    This equation’s graph is shown in figure [7.16d](#fig-neg-wt-step-2dx), and the
    perceptron implementation is shown in figure [7.16e](#fig-neg-wt-step-2dx-perceptron).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: In the 1D case, we combine a regular step with its flipped and shifted version
    to generate a tower. The process is slightly more complicated in 2D. Here, combining
    a step along a specific coordinate axis with its flipped and shifted version generates
    a wave function along that axis. Thus, we have separate waves in each dimension.
    The wave along the *x*[0] axis corresponds to equation [7.6](#eq-wave2dx); its
    graph is shown in figure [7.16g](#fig-wave-2dx). It is implemented by the MLP
    in figure [7.16h](#fig-wave-2dx-mlp). Similarly, a 2D wave along the *x*[1] axis
    can be generated via equation [7.7](#eq-wave2dy) and is graphed in figure [7.16j](#fig-wave-2dy).
    The corresponding MLP is shown in figure [7.16k](#fig-wave-2dy-mlp).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a tower, we have to AND a pair of waves along the two separate dimensions.
    The final tower function is shown in equation [7.8](#eq-tower2d); the corresponding
    tower graph is shown in figure [7.17a](#fig-tower-2d); the MLP is shown in figure
    [7.17b](#fig-tower-2d-mlp). Any continuous 2D surface can be approximated to arbitrary
    levels of accuracy by combining such 2D towers:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH07_F17a_Chaudhury.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
- en: (a) 2D tower
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH07_F17b_Chaudhury.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
- en: (b) MLP for a 2D tower (equation [7.8](#eq-tower2d))
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.17 Generating a 2D tower with perceptrons
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_07-04.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
- en: Equation 7.4
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_07-05.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/eq_07-05.png)'
- en: Equation 7.5
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式 7.5
- en: '![](../../OEBPS/Images/eq_07-06.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/eq_07-06.png)'
- en: Equation 7.6
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式 7.6
- en: '![](../../OEBPS/Images/eq_07-07.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/eq_07-07.png)'
- en: Equation 7.7
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式 7.7
- en: '![](../../OEBPS/Images/eq_07-08.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/eq_07-08.png)'
- en: Equation 7.8
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式 7.8
- en: NOTE Fully functional code for approximating surfaces using perceptrons, executable
    via Jupyter Notebook, can be found at [http://mng.bz/WrKa](http://mng.bz/WrKa).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：使用感知器近似表面的完整功能代码，可通过 Jupyter Notebook 执行，可在 [http://mng.bz/WrKa](http://mng.bz/WrKa)
    找到。
- en: Listing 7.4 Perceptrons and MLPs in 1D
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.4 1D 中的感知器和 MLP
- en: '[PRE3]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ① 100D array
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: ① 100D 数组
- en: ② See figures [7.15a](#fig-pos-wt-step-1d) and [7.15b](#fig-pos-wt-step-1d-perceptron).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: ② 参见图 [7.15a](#fig-pos-wt-step-1d) 和 [7.15b](#fig-pos-wt-step-1d-perceptron)。
- en: ③ See figures [7.15e](#fig-bias-change-1d) and [7.15f](#fig-bias-change-1d-perceptron).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 参见图 [7.15e](#fig-bias-change-1d) 和 [7.15f](#fig-bias-change-1d-perceptron)。
- en: ④ See figures [7.15g](#fig-tower1d) and [7.15h](#fig-tower1d-mlp).
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 参见图 [7.15g](#fig-tower1d) 和 [7.15h](#fig-tower1d-mlp)。
- en: Listing 7.5 Perceptrons and MLPs in 2D
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.5 2D 中的感知器和 MLP
- en: '[PRE4]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ① 100D array
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: ① 100D 数组
- en: ② 100 × 100 matrix
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: ② 100 × 100 矩阵
- en: ③ 10,000 × 1 matrix
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 10,000 × 1 矩阵
- en: ④ See equation [7.4](#eq-step2dx) and figures [7.16a](#fig-pos-wt-step-2dx)
    and [7.16b](#fig-pos-wt-step-2dx-perceptron)
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 参见方程式 [7.4](#eq-step2dx) 和图 [7.16a](#fig-pos-wt-step-2dx) 以及 [7.16b](#fig-pos-wt-step-2dx-perceptron)。
- en: ⑤ See equation [7.5](#eq-flipped_step2dx) and figures [7.16d](#fig-neg-wt-step-2dx)
    and [7.16e](#fig-neg-wt-step-2dx-perceptron)
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 参见方程式 [7.5](#eq-flipped_step2dx) 和图 [7.16d](#fig-neg-wt-step-2dx) 以及 [7.16e](#fig-neg-wt-step-2dx-perceptron)。
- en: ⑥ See equation [7.6](#eq-wave2dx) and figures [7.16g](#fig-wave-2dx) and [7.16h](#fig-wave-2dx-mlp)
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 参见方程式 [7.6](#eq-wave2dx) 和图 [7.16g](#fig-wave-2dx) 以及 [7.16h](#fig-wave-2dx-mlp)。
- en: ⑦ See equation [7.7](#eq-wave2dy) and figures [7.16j](#fig-wave-2dy) and [7.16k](#fig-wave-2dy-mlp)
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 参见方程式 [7.7](#eq-wave2dy) 和图 [7.16j](#fig-wave-2dy) 以及 [7.16k](#fig-wave-2dy-mlp)。
- en: ⑧ See equation [7.8](#eq-tower2d) and figures [7.17a](#fig-tower-2d) and [7.17b](#fig-tower-2d-mlp)
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 参见方程式 [7.8](#eq-tower2d) 和图 [7.17a](#fig-tower-2d) 以及 [7.17b](#fig-tower-2d-mlp)。
- en: 7.5.4 MLPs for polygonal decision boundaries
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.4 多边形决策边界的 MLP
- en: We have seen that classifiers form an important use case for neural networks.
    In section [7.2.2.1](#sec-decision-boundaries), we also saw that classifiers essentially
    model decision boundaries in high-dimensional feature spaces. In this section,
    we model a simple class bounded with a fixed polygon to understand the process.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，分类器是神经网络的一个重要用例。在第 [7.2.2.1](#sec-decision-boundaries) 节中，我们还看到分类器本质上是在高维特征空间中建模决策边界。在本节中，我们通过一个固定多边形界定的简单类别来建模，以理解这个过程。
- en: 'Figure [7.18a](#fig-feature-space-with-decision-boundaries) shows a feature
    space with the class to be identified corresponding to a rectangular region (shaded)
    bounded by the four straight lines:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [7.18a](#fig-feature-space-with-decision-boundaries) 显示了一个特征空间，其中要识别的类别对应于由四条直线界定的矩形区域（阴影部分）：
- en: '*x*[0] = –5        *x*[0] = 5'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '*x*[0] = –5      *x*[0] = 5'
- en: '*x*[1] = –2        *x*[1] = 2'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '*x*[1] = –2      *x*[1] = 2'
- en: Each of these lines partitions the feature space into two half-planes, indicated
    by minus and plus signs in figure [7.18a](#fig-feature-space-with-decision-boundaries).
    The region containing the feature points for the class of interest is indicated
    by all + signs.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 这些线中的每一行都将特征空间划分为两个半平面，如图 [7.18a](#fig-feature-space-with-decision-boundaries)
    中的负号和正号所示。包含感兴趣类别特征点的区域由所有正号表示。
- en: '![](../../OEBPS/Images/CH07_F18a_Chaudhury.png)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F18a_Chaudhury.png)'
- en: (a) Example feature space with decision boundaries enclosing the class of interest
    (shaded)
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 包围感兴趣类别的决策边界的示例特征空间（阴影部分）
- en: '![](../../OEBPS/Images/CH07_F18b_Chaudhury.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH07_F18b_Chaudhury.png)'
- en: (b) MLP that fires only on points in the shaded region
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 仅在阴影区域内的点触发的 MLP
- en: Figure 7.18 Modeling a rectangular decision region with MLPs
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.18 使用 MLP 建模矩形决策区域
- en: 'The shaded region corresponding to the class of interest is the region where
    *x*[0] ≥ − 5 AND *x*[0] ≤ 5 AND *x*[1] ≥ − 2 AND *x*[1] ≤ 2. Now consider the
    perceptron *ϕ*(*x*[0]+5). It fires (outputs 1) on the region *x*[0] ≥ − 5. Similarly,
    the perceptrons *ϕ*(−*x*[0]+5), *ϕ*(*x*[1]+2), and *ϕ*(−*x*[1]+2) fire on the
    regions *x*[0] ≤ 5, *x*[1] ≥ − 2, and *x*[1] ≤ 2, respectively. Hence, by logically
    ANDing the outputs of these perceptrons, we get an MLP that fires only on the
    shaded region of interest. Figure [7.53](#fig-feature-space-with-decision-boundaries-mlp)
    shows this MLP. It implements the following function:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 对应于感兴趣类别的阴影区域是满足 *x*[0] ≥ − 5 AND *x*[0] ≤ 5 AND *x*[1] ≥ − 2 AND *x*[1] ≤ 2
    的区域。现在考虑感知器 *ϕ*(*x*[0]+5)。它在 *x*[0] ≥ − 5 的区域触发（输出 1）。同样，感知器 *ϕ*（- *x*[0]+5）、*ϕ*（*x*[1]+2）和
    *ϕ*（- *x*[1]+2）分别在 *x*[0] ≤ 5、*x*[1] ≥ − 2 和 *x*[1] ≤ 2 的区域触发。因此，通过逻辑上 AND 这些感知器的输出，我们得到一个只在感兴趣阴影区域触发的多层感知器（MLP）。图
    [7.53](#fig-feature-space-with-decision-boundaries-mlp) 展示了此 MLP。它实现了以下函数：
- en: '![](../../OEBPS/Images/eq_07-08-a.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/eq_07-08-a.png)'
- en: All shapes on a plane can be approximated by polygons. Hence, given sufficient
    perceptrons, any shape on a plane can be depicted to an arbitrary level of accuracy.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 平面上的所有形状都可以用多边形来近似。因此，给定足够的感知器，平面上的任何形状都可以以任意精度描绘出来。
- en: Summary
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we outlined how a large variety of real-world problems can
    be modeled as function evaluation:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们概述了如何将各种现实世界问题建模为函数评估：
- en: 'Any intelligent task can be modeled by a function. Of particular interest are
    classification tasks where, given an input, we estimate from a predetermined list
    of possible classes the class to which the input belongs. For instance, a binary
    classifier can group input images into two classes: those that contain a human
    face and those that do not. Classification tasks can be approximated by functions
    with categorical outputs.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何智能任务都可以通过一个函数来建模。特别值得注意的是分类任务，在这种任务中，给定一个输入，我们从预定的可能类别列表中估计输入所属的类别。例如，二元分类器可以将输入图像分为两类：包含人脸的和不包含人脸的。分类任务可以通过具有分类输出的函数来近似。
- en: Neural networks provide a structured way to approximate arbitrary functions
    (including classifier functions). This is how they mimic intelligence.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络提供了一种结构化的方法来近似任意函数（包括分类函数）。这就是它们模仿智能的方式。
- en: Neural networks are created by combining a basic building block called a perceptron.
    A perceptron is a simple function that returns a step function applied to the
    weighted sum of its inputs (plus a bias). A perceptron is effectively a linear
    classifier that divides space into two half-spaces with a hyperplane. The weights
    and bias of the perceptron correspond to the orientation and position of the hyperplane—they
    can be adjusted to separate the regions corresponding to individual classes as
    much as possible.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络是通过组合一个称为感知器的基本构建块来创建的。感知器是一个简单的函数，它返回对输入加权总和（加上偏差）应用步进函数的结果。感知器实际上是一个线性分类器，它通过超平面将空间分为两个半空间。感知器的权重和偏差对应于超平面的方向和位置——它们可以被调整到尽可能多地分离对应于单个类别的区域。
- en: A single perceptron can approximate only relatively simple functions, such as
    a classifier whose feature points are separable by a hyperplane. Perceptrons cannot
    approximate more complex functions, like classifiers whose input regions are to
    be separated with curved surfaces. Multilayer perceptrons (MLPs) are combinations
    of perceptrons where the outputs of one set (layer) of perceptrons are fed as
    input to the next set (layer). A neural network is essentially an MLP and can
    approximate such arbitrarily complex functions.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个感知器只能近似相对简单的函数，例如可以通过超平面分离特征点的分类器。感知器不能近似更复杂的函数，例如需要用曲面分离输入区域的分类器。多层感知器（MLP）是感知器的组合，其中一层感知器的输出作为下一层感知器的输入。神经网络本质上是一个
    MLP，可以近似这样的任意复杂函数。
- en: Simple logical functions like AND, OR, and NOT can be emulated with a single
    perceptron. A logical XOR cannot be. For XORs and other complicated logical functions,
    we need MLPs. There is a mechanical way to construct an MLP for any logical function.
    A logical function can always be represented by a truth table. Each row of the
    truth table can be viewed as a logical AND function of the inputs, and the final
    output is a logical OR of the inputs. Since ANDs and ORs can be emulated with
    perceptrons, any truth table can be emulated as a combination of perceptrons (an
    MLP).
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的逻辑函数，如AND、OR和NOT，可以用单个感知器来模拟。逻辑XOR不能。对于XOR和其他复杂的逻辑函数，我们需要MLPs。有一种机械的方法可以构建任何逻辑函数的MLP。逻辑函数总是可以用真值表来表示。真值表的每一行可以看作是输入的逻辑AND函数，最终输出是输入的逻辑OR。由于AND和OR可以用感知器来模拟，任何真值表都可以模拟为感知器的组合（一个MLP）。
- en: The ability of an MLP to represent arbitrary functions is known as its expressive
    power. The larger the number of perceptrons and/or connections, the greater the
    expressive power of a neural network.
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLP表示任意函数的能力被称为其表达能力。感知器数量和/或连接数量越多，神经网络的表达能力就越强。
- en: Cybenko’s theorem proves that a neural network is a universal approximator (meaning
    it can approximate any function). The basic idea is that any function can be approximated
    to an arbitrary degree of accuracy as a sum of rectangles (towers). The theorem
    demonstrates that a tower can be constructed in any dimensional space using MLPs.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cybenko定理证明了神经网络是一个通用逼近器（意味着它可以逼近任何函数）。基本思想是任何函数都可以被逼近到任意程度的精度，作为矩形（塔）的总和。该定理表明，可以使用MLPs在任何维度的空间中构建塔。
- en: Neural networks can approximate any shape on a plane to arbitrary accuracy.
    This is because all shapes can be approximated by rectangles, and we can demonstrably
    approximate a rectangle on a plane with MLPs.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络可以逼近平面上任何形状到任意精度。这是因为所有形状都可以用矩形逼近，并且我们可以用MLPs在平面上逼近矩形。
- en: In real-life problems, the regions corresponding to classes are unknown, but
    we manually label sample input points with desired outputs (ground truth) to create
    supervised training data. We tune the weights and biases to approximate the training
    data as closely as possible. This process of tuning is known as training. If the
    training data set is not a good representative of the real dataset, the neural
    network will be inaccurate even after training.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在现实生活中的问题中，对应于类别的区域是未知的，但我们会手动标记样本输入点带有期望的输出（真实值）来创建监督训练数据。我们调整权重和偏差，尽可能逼近训练数据。这个过程被称为训练。如果训练数据集不能很好地代表真实数据集，即使经过训练，神经网络也可能不准确。
