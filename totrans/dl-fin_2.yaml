- en: Chapter 3\. Descriptive Statistics and Data Analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Descriptive statistics* is a field that describes data and extracts as much
    information as possible from it. Basically, descriptive statistics can act like
    the representative of the data since it briefs up its tendencies, behavior, and
    trends.'
  prefs: []
  type: TYPE_NORMAL
- en: Trading and analysis borrows a lot from the metrics of this field. You will
    see in this chapter the main concepts that you need in order to have a solid grasp
    on data analysis. I always found that the best educational tools are practical
    examples, therefore, I will present this chapter using one example of an economic
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take inflation numbers coming from the USA. The consumer price index (CPI) measures
    the prices paid by urban consumers for a selection of products and services on
    a monthly basis (meaning that every month, a new observation is released to the
    public, thus forming a continuous time series). The inflation rate between any
    two time periods is measured by percentage changes in the price index. For example,
    if the price of bread last year was $1.00 and the price today is $1.01, then the
    inflation is 1.00%.
  prefs: []
  type: TYPE_NORMAL
- en: The code that you can use to get the CPI data resembles the one you have used
    to get the VIX data in Chapter 1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: By now, you should have a data frame that contains the yearly changes on the
    CPI. The year-on-year change is the most observed transformation on the CPI as
    it gives a clear and simple measurement of the change in the overall price level
    over a sufficiently enough period of time to account for short-term swings and
    seasonal impacts (recall the bread example).
  prefs: []
  type: TYPE_NORMAL
- en: Hence, the yearly change of the CPI serves as a gauge of the general trend in
    inflation. It is also simple to comprehend and compare across other nations and
    historical times, making it a popular measure among policymakers and economists
    (albeit the flaw of element weightings in the baskets between different countries).
    Let’s see how to analyze the dataset from a statistical point of view.
  prefs: []
  type: TYPE_NORMAL
- en: Measures of Central Tendency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Central tendency* refers to the calculations that summarize the dataset into
    a value that can represent them. The first and most known central tendency measure
    is the mean (average). The *mean* is simply the sum of the values divided by their
    quantity. It is the center point of the dataset and most likely the value that
    represents it the best. The mathematical formula of the mean is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x overbar equals StartFraction 1 Over n EndFraction sigma-summation
    Underscript n Overscript i equals 1 Endscripts x Subscript i Baseline equals StartFraction
    1 Over n EndFraction left-parenthesis x 1 plus period period period plus x Subscript
    n Baseline right-parenthesis"><mrow><mover accent="true"><mi>x</mi> <mo>¯</mo></mover>
    <mo>=</mo> <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mi>n</mi></mfrac></mstyle>
    <msubsup><mo>∑</mo> <mrow><mi>n</mi></mrow> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow></msubsup>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>=</mo> <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn>
    <mi>n</mi></mfrac></mstyle> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>+</mo> <msub><mi>x</mi> <mi>n</mi></msub>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a simple example of two datasets. Suppose you want to calculate the
    mean on dataset A and dataset B. How would you do it?
  prefs: []
  type: TYPE_NORMAL
- en: Dataset A = [1, 2, 3, 4, 5]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset B = [1, 1, 1, 1]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset A contains 5 values (quantity) with a total sum of 15\. This means that
    the mean is equal to 3\. Dataset B contains 4 values with a total sum of 4\. This
    means that the mean is equal to 1.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When all the values in a dataset are the same, the mean is the same as the values.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3-1 shows the US CPI year-on-year values for the last twenty years. The
    higher dashed line is the monthly mean calculated over the past twenty years.
    The lower dashed line symbolizes zero where below it are deflationary periods.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0220.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-1\. US CPI year-on-year changes for the last twenty years
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You can create Figure 3-1 by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The output of the mean should be as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: This means that the average observation of the CPI’s change on a yearly basis
    is around 2.50%. Even though the Federal Reserve does not have an explicit inflation
    target, it is generally believed that there is a consensus to maintain the annual
    change in inflation around 2.00%, hence not far from the historical observations.
    With the recent high inflation numbers since 2021 as a result of political and
    economic turmoil, it becomes necessary to revert back to the mean to stabilize
    the current situation. This examples gives a numerical value to what is referred
    to as normality (~2.50%) in the past 10 years.
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, with the high inflation numbers (~6.00%) around the beginning of 2023,
    the situation is a bit far from normality, but how far? This question is answered
    in the next section that discusses measures of variability. For now, let’s continue
    the discussion on central tendency.
  prefs: []
  type: TYPE_NORMAL
- en: The next measure is the *median* which in simple terms is the value that splits
    the data set into two equal sides. In other words, if you arrange the dataset
    in an ascending order, the middle value is the median. The median is used whenever
    there are many outliers or skew in the distribution (which may bias the mean and
    make it less representative).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are generally two topics associated with calculating the median, the
    first one relates to a dataset that contains an even number of values (for example,
    24 rows) and the second one relates to a dataset that contains an uneven number
    of values (for example, 47 rows):'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the median of an even data set
  prefs: []
  type: TYPE_NORMAL
- en: If the arranged dataset has an even number of values, the median is the average
    of the two middle values.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the median of an uneven data set
  prefs: []
  type: TYPE_NORMAL
- en: If the arranged dataset has an uneven (odd) number of values, the median is
    simply the middle value.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a simple example of two datasets. Suppose you want to calculate the
    median on dataset A and dataset B. How would you do it?
  prefs: []
  type: TYPE_NORMAL
- en: Dataset A = [1, 2, 3, 4, 5]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset B = [1, 2, 3, 4]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset A contains five values which is an uneven number. This means that the
    middle value is the median. In this case, it is 3 (notice how it is also the mean
    of the dataset). Dataset B contains four values which is an even number. This
    means that the average between the two middle values is the median. In this case,
    it is 2.5 which is the average between 2 and 3.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3-2 shows the US CPI year-on-year values for the last twenty years. The
    higher dashed line is the monthly median calculated over the past twenty years.
    The lower dashed line symbolizes zero. Basically, this is like Figure 3-1 but
    instead of the mean, the median is charted.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0225.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-2\. US CPI year-on-year changes for the last twenty years with the
    median
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You can create Figure 3-2 by using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the median should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Clearly, the median is less impacted by the recent outliers that are coming
    from unusual environments. The median is around 2.10% which more in line with
    the implied target of 2.00%.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Remember that Chapter 6 will give you all you need to know about the Python
    snippets you are seeing in this chapter, so you don’t need to worry if you are
    missing out on the coding concepts.
  prefs: []
  type: TYPE_NORMAL
- en: The last central tendency measure in this section is the mode. The *mode* is
    the value that is the most frequently observed (but also the least used in data
    analysis).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a simple example of two datasets. Suppose you want to calculate the
    mode on the following datasets. How would you do it?
  prefs: []
  type: TYPE_NORMAL
- en: Dataset A = [1, 2, 2, 4, 5]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset B = [1, 2, 3, 4]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset C = [1, 1, 2, 2, 3]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset A contains two times the value 2 which makes it the mode. Dataset B
    doesn’t have a mode as every value is observed once. Dataset C is multimodal since
    it contains more than one mode (which are 1 and 2).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The mode is useful with categorical variables (like credit rankings) as opposed
    to continuous variables (like price and returns time series)
  prefs: []
  type: TYPE_NORMAL
- en: 'You are unlikely to use the mode in analyzing time series as the mean and the
    median are more useful. To list a few examples that use the mean and the median
    in financial analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating a moving mean (average) on the price data to detect the underlying
    trend.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating a rolling median on a price-derived indicator to know its neutral
    zone.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculating the expected return of a security using the historical mean.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking for the normality of the returns distribution by comparing the mean
    to the median.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The discussion on central tendency metrics is very important especially that
    the mean and the median are heavily used not only as standalone indicators but
    also as ingredients in more complex measures.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The key takeaways from this section are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are mainly three central tendency measures: the mean, the median, and
    the mode.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The mean is the sum divided by the quantity while the median is the value that
    splits the data in half. The mode is the most frequent value in the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measures of Variability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Measures of variability* describe how spread out the values in a dataset are
    relative to the central tendency measures. The first and most known measure of
    variability is the variance. The *variance* describes a set of numbers’ variability
    from their mean. The idea behind the variance’s formula is to determine how far
    away from the mean each data point is, then square those deviations to make sure
    that all numbers are positive (this is because distance cannot be negative).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula to find the variance is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sigma squared equals StartFraction 1 Over n EndFraction sigma-summation
    Underscript n Overscript i equals 1 Endscripts left-parenthesis x Subscript i
    Baseline minus x overbar right-parenthesis squared"><mrow><msup><mi>σ</mi> <mn>2</mn></msup>
    <mo>=</mo> <mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mi>n</mi></mfrac></mstyle>
    <msubsup><mo>∑</mo> <mrow><mi>n</mi></mrow> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow></msubsup>
    <msup><mrow><mo>(</mo><msub><mi>x</mi> <mi>i</mi></msub> <mo>-</mo><mover accent="true"><mi>x</mi>
    <mo>¯</mo></mover><mo>)</mo></mrow> <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The intuition behind this formula is to calculate the sum of the squared deviations
    of each data point from the mean thus giving different distance observations and
    then calculating the mean of these distance observations.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a simple example of two datasets. Suppose you want to calculate the
    variance on dataset A and dataset B. How would you do it?
  prefs: []
  type: TYPE_NORMAL
- en: Dataset A = [1, 2, 3, 4, 5]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset B = [5, 5, 5, 5]
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first step is to calculate the mean of the dataset as that is the benchmark
    from where you will calculate the dispersion of the data. Dataset A has a mean
    of 3\. The next step is to use the variance formula step by step as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="left-parenthesis x 1 minus x overbar right-parenthesis squared
    equals left-parenthesis 1 minus 3 right-parenthesis squared equals 4"><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mn>3</mn><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <mn>4</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="left-parenthesis x 2 minus x overbar right-parenthesis squared
    equals left-parenthesis 2 minus 3 right-parenthesis squared equals 1"><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>(</mo><mn>2</mn><mo>-</mo><mn>3</mn><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <mn>1</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="left-parenthesis x 3 minus x overbar right-parenthesis squared
    equals left-parenthesis 3 minus 3 right-parenthesis squared equals 0"><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>3</mn></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>(</mo><mn>3</mn><mo>-</mo><mn>3</mn><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="left-parenthesis x 4 minus x overbar right-parenthesis squared
    equals left-parenthesis 4 minus 3 right-parenthesis squared equals 1"><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>4</mn></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>(</mo><mn>4</mn><mo>-</mo><mn>3</mn><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <mn>1</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="left-parenthesis x 5 minus x overbar right-parenthesis squared
    equals left-parenthesis 5 minus 3 right-parenthesis squared equals 4"><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>5</mn></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>(</mo><mn>5</mn><mo>-</mo><mn>3</mn><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <mn>4</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The previous results are summed up as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="4 plus 1 plus 0 plus 1 plus 4 equals 10"><mrow><mn>4</mn> <mo>+</mo>
    <mn>1</mn> <mo>+</mo> <mn>0</mn> <mo>+</mo> <mn>1</mn> <mo>+</mo> <mn>4</mn> <mo>=</mo>
    <mn>10</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'And finally, the result is divided by the quantity of the observations to find
    the variance:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sigma squared equals StartFraction 10 Over 5 EndFraction equals
    2"><mrow><msup><mi>σ</mi> <mn>2</mn></msup> <mo>=</mo> <mstyle scriptlevel="0"
    displaystyle="false"><mfrac><mn>10</mn> <mn>5</mn></mfrac></mstyle> <mo>=</mo>
    <mn>2</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: As for dataset B, you should think about it intuitively. If the observations
    are all equal, they all represent the dataset which also means that they are their
    own mean. What would you say about the variance of the data in this case, considering
    that all the values are equal to the mean?
  prefs: []
  type: TYPE_NORMAL
- en: 'If your response is that the variance is zero, then you are correct. Mathematically,
    you can calculate it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="left-parenthesis x 1 minus x overbar right-parenthesis squared
    equals left-parenthesis 5 minus 5 right-parenthesis squared equals 0"><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>(</mo><mn>5</mn><mo>-</mo><mn>5</mn><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="left-parenthesis x 2 minus x overbar right-parenthesis squared
    equals left-parenthesis 5 minus 5 right-parenthesis squared equals 0"><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>2</mn></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>(</mo><mn>5</mn><mo>-</mo><mn>5</mn><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="left-parenthesis x 3 minus x overbar right-parenthesis squared
    equals left-parenthesis 5 minus 5 right-parenthesis squared equals 0"><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>3</mn></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>(</mo><mn>5</mn><mo>-</mo><mn>5</mn><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="left-parenthesis x 4 minus x overbar right-parenthesis squared
    equals left-parenthesis 5 minus 5 right-parenthesis squared equals 0"><mrow><msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mn>4</mn></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>(</mo><mn>5</mn><mo>-</mo><mn>5</mn><mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>=</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The previous results sum up to zero and if you divide zero by 4 (the quantity
    of the dataset), you will get zero. Intuitively, there is no variance because
    the all the values are constant and they do not deviate from their mean.
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sigma squared equals StartFraction 0 Over 5 EndFraction equals
    0"><mrow><msup><mi>σ</mi> <mn>2</mn></msup> <mo>=</mo> <mstyle scriptlevel="0"
    displaystyle="false"><mfrac><mn>0</mn> <mn>5</mn></mfrac></mstyle> <mo>=</mo>
    <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'You can calculate the variance in Python using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the variance should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: There is a flaw nonetheless, and it is that the variance represent squared values
    and are not comparable to the mean since they use different units. This is easily
    fixable by taking the square root of the variance. Doing so brings the next measure
    of variability, the *standard deviation.* It is the square root of the variance
    and is the average deviation of the values from the mean.
  prefs: []
  type: TYPE_NORMAL
- en: A low standard deviation indicates that the values tend to be close to the mean
    (low volatility), while a high standard deviation indicates that the values are
    spread out over a wider range relative to their mean (high volatility).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The words standard deviation and volatility are used interchangeably. They refer
    to the same thing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula to find the standard deviation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sigma equals StartRoot StartFraction 1 Over n EndFraction sigma-summation
    Underscript n Overscript i equals 1 Endscripts left-parenthesis x Subscript i
    Baseline minus x overbar right-parenthesis squared EndRoot"><mrow><mi>σ</mi> <mo>=</mo>
    <msqrt><mrow><mstyle scriptlevel="0" displaystyle="false"><mfrac><mn>1</mn> <mi>n</mi></mfrac></mstyle>
    <msubsup><mo>∑</mo> <mrow><mi>n</mi></mrow> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow></msubsup>
    <msup><mrow><mo>(</mo><msub><mi>x</mi> <mi>i</mi></msub> <mo>-</mo><mover accent="true"><mi>x</mi>
    <mo>¯</mo></mover><mo>)</mo></mrow> <mn>2</mn></msup></mrow></msqrt></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If you consider the previous examples with the variance, then the standard
    deviation can be found as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sigma Subscript upper D a t a s e t upper A Baseline equals StartRoot
    2 EndRoot equals 1.41"><mrow><msub><mi>σ</mi> <mrow><mi>D</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>s</mi><mi>e</mi><mi>t</mi><mi>A</mi></mrow></msub>
    <mo>=</mo> <msqrt><mn>2</mn></msqrt> <mo>=</mo> <mn>1</mn> <mo>.</mo> <mn>41</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sigma Subscript upper D a t a s e t upper B Baseline equals StartRoot
    0 EndRoot equals 0"><mrow><msub><mi>σ</mi> <mrow><mi>D</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>s</mi><mi>e</mi><mi>t</mi><mi>B</mi></mrow></msub>
    <mo>=</mo> <msqrt><mn>0</mn></msqrt> <mo>=</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Standard deviation is commonly used with the mean since they use the same units.
    You will soon understand the importance of this stat when I discuss the normal
    distribution function, a key concept in descriptive statistics.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can calculate the standard deviation in Python using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the standard deviation should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: How are you supposed to interpret the standard deviation? On average, the CPI
    year-on-year values tend to be ±1.90% from the mean of the same period which is
    at 2.48%.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the coming section, you will see how to make better use of standard deviation
    numbers. The last measure of variability in this section is the range. The *range*
    is a very simple stat that shows the distance between the greatest value and the
    lowest value in the dataset. This gives you quick glance about the two historical
    extreme values. The range is used in the normalization formula that you will see
    later chapters. The formula to find the range is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper R a n g e equals m a x left-parenthesis x right-parenthesis
    minus m i n left-parenthesis x right-parenthesis"><mrow><mi>R</mi> <mi>a</mi>
    <mi>n</mi> <mi>g</mi> <mi>e</mi> <mo>=</mo> <mi>m</mi> <mi>a</mi> <mi>x</mi> <mo>(</mo>
    <mi>x</mi> <mo>)</mo> <mo>-</mo> <mi>m</mi> <mi>i</mi> <mi>n</mi> <mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take the same example and calculate the range. In Python, you can easily
    do this as there are built-in functions that show the maximum and the minimum
    value given a set of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the following code should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Figure 3-3 shows the CPI values since 1950\. The diagonal dashed line represents
    the range.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0224.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-3\. US CPI year-on-year change since 1950 with a diagonal dashed line
    that represents the range
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The range of the CPI shows the size of the variations in inflation measures
    from one period to another considering that the range occurred in 30 years. Yearly
    changes in inflation numbers vary from one country to another. Generally, developed
    world countries such as France and the United States have stable variations (in
    times of stability) while emerging and frontier world countries such as Argentina
    and Turkey have more volatile and more extreme inflation numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Make sure to retain the following points as you continue to the next section:'
  prefs: []
  type: TYPE_NORMAL
- en: Three key variability metrics that you should know are the variance, the standard
    deviation, and the range.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The standard deviation is the square root of the variance. This is done so that
    it becomes comparable to the mean.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The range is the difference between the highest and the lowest value in a dataset.
    It is a quick snapshot of the overall volatility of the observations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measures of Shape
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Measures of shape describe the distribution of the values around the central
    tendency measures in a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The mean and the standard deviation are the two factors that describe the normal
    distribution. The standard deviation depicts the spread or dispersion of the data
    and the mean reflects the distribution’s center.
  prefs: []
  type: TYPE_NORMAL
- en: A *probability distribution* is a mathematical function that describes the likelihood
    of different outcomes or events in a random experiment. In other words, it gives
    the probabilities of all possible values of a random variable.
  prefs: []
  type: TYPE_NORMAL
- en: There are many types of probability distributions, including discrete and continuous
    distributions. *Discrete distributions* take on a finite number of values. The
    most known discrete distributions are the Bernoulli distribution, Binomial distribution,
    and Poisson distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '*Continuous distributions* are used for random variables that can take on any
    value within a given range (such as stock prices). The most known continuous distribution
    is the normal distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: The normal distribution (also known as the Gaussian distribution) is a type
    of continuous probability distribution that is symmetrical around the mean and
    has a bell shape. It is one of the most widely used distributions in statistical
    analysis and is often used to describe natural phenomena such as age, weight,
    and test scores. Figure 3-4 shows the shape of a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0280.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-4\. A normal distribution plot with mean = 0 and standard deviation
    = 1
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You can generate Figure 3-4 using the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Since normally distributed variables are common, most statistical tests and
    models assume that the analyzed data is normal. With financial returns, they are
    assumed normal even though they experience a form of skew and kurtosis, two measures
    of shape discussed in this section.
  prefs: []
  type: TYPE_NORMAL
- en: In a normal distribution, the data is distributed symmetrically around the mean
    which also means that the mean is equal to the median and to the mode. Furthermore,
    around 68% of the data fall within one standard deviation of the mean, around
    95% fall within two standard deviations, and around 99.7% fall within three standard
    deviations. This property makes the normal distribution a useful tool for making
    inferences.
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, what you should retain from the normal distribution is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The mean and the standard deviation describe the distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The mean splits the distribution halfway making it equal to the median. Due
    to the symmetrical property, the mode is also equal to the mean and the median.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s discuss the measures of shape. The first measure of shape is skewness.
    *Skewness *describes a distribution’s asymmetry. It analyzes how far from being
    symmetrical the distribution deviates.
  prefs: []
  type: TYPE_NORMAL
- en: As you may have already understood, the skewness of a normal distribution is
    equal to zero. This means that the distribution is perfectly symmetrical around
    its mean, with an equal number of data points on either side of the mean.
  prefs: []
  type: TYPE_NORMAL
- en: A *positive skew* indicates that the distribution has a long tail to the right
    which means the the mean is greater than the median due to the fact that the mean
    is sensible to outliers which will push it upwards (therefore, to the right of
    the x-axis). Similarly, the mode which represents the most frequent observations
    will be the lowest value between the three central tendency measures. Figure 3-5
    shows a positive skew.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_11.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-5\. An example of a positively skewed distribution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A *negative skew* indicates that the distribution has a long tail to the left
    which means the the mean is lower than the median for the reasons mentionned when
    discussing the positive skew. Similarly, the mode will be the greatest value between
    the three central tendency measures. Figure 3-6 shows a negative skew.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_10.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-6\. An example of a negatively skewed distribution
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: How can skewness be interpreted in the world of financial markets? If the distribution
    is positively skewed, it means that there are more returns above the mean than
    below it (the tail of the distribution is longer on the positive side).
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if the distribution is negatively skewed, it means that there
    are more returns below the mean than above it (the tail of the distribution is
    longer on the negative side).
  prefs: []
  type: TYPE_NORMAL
- en: The skew of a returns series can provide information about the risk and return
    of an investment. For example, a positively skewed returns series may indicate
    that the investment has a higher potential for high returns, but also a higher
    risk of large losses. In contrast, a negatively skewed returns series may indicate
    that the investment has a lower potential for high returns, but also a lower risk
    of large losses.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula to find skewness is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="mu overTilde Subscript 3 Baseline equals StartFraction sigma-summation
    Underscript n equals 1 Overscript i Endscripts left-parenthesis x Subscript i
    Baseline minus x overbar right-parenthesis cubed Over upper N sigma cubed EndFraction"><mrow><msub><mover
    accent="true"><mi>μ</mi> <mo>˜</mo></mover> <mn>3</mn></msub> <mo>=</mo> <mstyle
    scriptlevel="0" displaystyle="false"><mfrac><mrow><msubsup><mo>∑</mo> <mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>i</mi></msubsup> <msup><mrow><mo>(</mo><msub><mi>x</mi> <mi>i</mi></msub>
    <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>3</mn></msup></mrow> <mrow><mi>N</mi><msup><mi>σ</mi> <mn>3</mn></msup></mrow></mfrac></mstyle></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula divides the third central moment by the standard deviation to the
    power of three. Let’s check the skewness of the US CPI year-on-year data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the following code should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The skew of the data is 1.46 but what does that mean? Let’s chart the distribution
    of the data so that the interpretation becomes easier. You can do this using the
    following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Figure 3-7 shows the result of the previous code snippet. The data is clearly
    positively skewed since the mean is greater than the median and the skewness is
    positive (above zero).
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-7\. Data distribution of the US CPI year-on-year
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Remember, skewness is a measure of the asymmetry of a probability distribution. It
    therefore, measures the degree to which the distribution deviates from normality.
    The rules of thumb to interpret skewness are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: If skewness is between -0.5 and 0.5, the data is considered symmetrical.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If skewness is between -1.0 and – 0.5 or between 0.5 and 1.0, the data is considered
    mildly skewed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If skewness is less than -1.0 or greater than 1.0, the data is considered highly
    skewed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What does a positive skew mean? 1.17 is a highly skewed data (in the positive
    side) which is in line with a monetary policy that favors inflation as the economy
    grows (with a few inflationary spikes that cause the skew).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It may be interesting to know that with a skewed distribution, the median is
    the preferred metric since the mean tends to be pulled by outliers, thus distorting
    its value.
  prefs: []
  type: TYPE_NORMAL
- en: The next measure of shape is *kurtosis* which a measure of the peakedness or
    flatness of a distribution relative to a normal distribution. Kurtosis describes
    the tails of a distribution, in particular, whether the tails are thicker or thinner
    than those of a normal distribution. Mathematically, kurtosis is the fourth central
    moment divided by the fourth power of the standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: A normal distribution has a kurtosis of 3, which means it is a mesokurtic distribution.
    If a distribution has a kurtosis greater than 3, it is referred to as leptokurtic,
    meaning it has a higher peak and fatter tails than a normal distribution. If a
    distribution has a kurtosis less than 3, it is referred to as platykurtic, meaning
    it has a flatter peak and thinner tails than a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula to find kurtosis is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="k equals StartFraction sigma-summation Underscript n equals 1
    Overscript i Endscripts left-parenthesis x Subscript i Baseline minus x overbar
    right-parenthesis Superscript 4 Baseline Over upper N sigma Superscript 4 Baseline
    EndFraction"><mrow><mi>k</mi> <mo>=</mo> <mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><msubsup><mo>∑</mo>
    <mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow> <mi>i</mi></msubsup> <msup><mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>4</mn></msup></mrow> <mrow><mi>N</mi><msup><mi>σ</mi> <mn>4</mn></msup></mrow></mfrac></mstyle></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Sometimes, kurtosis is measured as excess kurtosis to give it a starting value
    of zero (for a normal distribution). This means that the kurtosis measure is subtracted
    from 3 so as to calculate the excess kurtosis. Let’s calculate excess kurtosis
    for the US CPI year-on-year data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the following code should be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The excess kurtosis obtained from `pandas` should be zero in the case of a normal
    distribution. In the case of the US CPI year-on-year values, it is 2.23 which
    is more in line with a leptokurtic (peakier with fatter tails) distribution. A
    positive value indicates a distribution more peaked than normal and a negative
    kurtosis indicates a shape flatter than normal.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Independent from statistics, it is interesting to know the terminology of what
    you are analyzing. *Inflation* is the decrease in the purchasing power of the
    economic agents (such as households). The decrease in the purchasing power means
    that agents can buy less over time with the same amount of money, otherwise referred
    to as a general price increase. Inflation in the economic sense has the following
    forms:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Inflation*: Controlled inflation is associated with a steady economic growth
    and expasion. It is a desired attribute for a growing economy. Regulators monitor
    inflation and try to stabilize it in order to prevent social and economic issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deflation*: Whenever inflation is in the negative territory, it is referred
    to as deflation. Deflation is very dangerous for the economy and as tempting as
    it may be for consumers who see a price decrease, deflation is a growth killer
    and may cause extended economic gluts which lead to unemployment and bearish stock
    markets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Stagflation*: This occurs where inflation is either high or rising while the
    economic growth is slowing down. Simultaneously, unemployment remains high. It
    is one of the worst possible case scenarios.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Disinflation*: This is a decrease in inflation but in the positive territory.
    For example, if this year’s inflation is 2% while last year’s inflation is 3%,
    you can say that there was a disinflation situation on a yearly basis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hyper inflation*: This is the nightmarish scenario that occurs when inflation
    goes out of control and experiences astronomical percent changes such as millions
    of percentage change from year to year (famous cases include Zimbabwe, Yugoslavia,
    and Greece).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, one last metric to see in the descriptive statistics department, the
    quantiles. *Quantiles* are measures of both shape and variability since they provide
    information about the distribution of values (shape) and provide information about
    the dispersion of such values (variability). The most used type of quantiles are
    called quartiles.
  prefs: []
  type: TYPE_NORMAL
- en: '*Quartiles* divide the dataset into four equal parts. This is done by arranging
    the data in order and then performing the split. Consider table 3-1 as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Value |'
  prefs: []
  type: TYPE_TB
- en: '| 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 |'
  prefs: []
  type: TYPE_TB
- en: 'The quartiles are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The lower quartile (Q1) is the first quarter which in this case is 2.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The midde quartile (Q2) which is also the median which in this case is 5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The upper quartile (Q3) in this case is 8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mathematically, you can calculate Q1 and Q3 using the following formulas:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper Q 1 equals left-parenthesis StartFraction n plus 1 Over
    4 EndFraction right-parenthesis"><mrow><msub><mi>Q</mi> <mn>1</mn></msub> <mo>=</mo>
    <mrow><mo>(</mo> <mfrac><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow> <mn>4</mn></mfrac>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper Q 3 equals 3 left-parenthesis StartFraction n plus 1 Over
    4 EndFraction right-parenthesis"><mrow><msub><mi>Q</mi> <mn>3</mn></msub> <mo>=</mo>
    <mn>3</mn> <mrow><mo>(</mo> <mfrac><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow>
    <mn>4</mn></mfrac> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Keep in mind that the result of the formulae gives you the ranking of the values
    but not the values themselves:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper Q 1 equals left-parenthesis StartFraction 7 plus 1 Over
    4 EndFraction right-parenthesis equals 2 Superscript n d Baseline t e r m equals
    2"><mrow><msub><mi>Q</mi> <mn>1</mn></msub> <mo>=</mo> <mrow><mo>(</mo> <mfrac><mrow><mn>7</mn><mo>+</mo><mn>1</mn></mrow>
    <mn>4</mn></mfrac> <mo>)</mo></mrow> <mo>=</mo> <msup><mn>2</mn> <mrow><mi>n</mi><mi>d</mi></mrow></msup>
    <mi>t</mi> <mi>e</mi> <mi>r</mi> <mi>m</mi> <mo>=</mo> <mn>2</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper Q 3 equals 3 left-parenthesis StartFraction 7 plus 1 Over
    4 EndFraction right-parenthesis equals 6 Superscript t h Baseline t e r m equals
    8"><mrow><msub><mi>Q</mi> <mn>3</mn></msub> <mo>=</mo> <mn>3</mn> <mrow><mo>(</mo>
    <mfrac><mrow><mn>7</mn><mo>+</mo><mn>1</mn></mrow> <mn>4</mn></mfrac> <mo>)</mo></mrow>
    <mo>=</mo> <msup><mn>6</mn> <mrow><mi>t</mi><mi>h</mi></mrow></msup> <mi>t</mi>
    <mi>e</mi> <mi>r</mi> <mi>m</mi> <mo>=</mo> <mn>8</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The *interquartile range* (IQR), is the difference between Q3 and Q1 and provides
    a measure of the spread of the middle 50% of the values in a data set. The IQR
    is robust to outliers (since it relies on middle values) and provides a brief
    summary of the spread of the bulk of the values. The IQR of the data in table
    3-1 is 6 as per the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper I upper Q upper R equals upper Q 3 minus upper Q 1"><mrow><mi>I</mi>
    <mi>Q</mi> <mi>R</mi> <mo>=</mo> <msub><mi>Q</mi> <mn>3</mn></msub> <mo>-</mo>
    <msub><mi>Q</mi> <mn>1</mn></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper I upper Q upper R equals 8 minus 2 equals 6"><mrow><mi>I</mi>
    <mi>Q</mi> <mi>R</mi> <mo>=</mo> <mn>8</mn> <mo>-</mo> <mn>2</mn> <mo>=</mo> <mn>6</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The IQR is a valuable indicator and can be used as an input or a risk metric
    in many different models. It can also be used to detect outliers in the data since
    it is immune to them. Also, the IQR can help evaluate the current volatility of
    the analyzed asset which in turn can be used with other methods to create more
    powerful models. As understood, the IQR outperforms the range metric in terms
    of usefulness and interpretation as the former is prone to outliers.
  prefs: []
  type: TYPE_NORMAL
- en: Be careful with calculating quartiles as there are many methods that use different
    calculations for the same dataset. The most important thing is to use a consistent
    way all throughout your analyses. The method used to calculate the quartiles in
    table 3-1 is called the *Tukey’s hinges* method. By default, when you want to
    calculate the quartiles using `pandas`, the default method is the *linear interpolation* method
    which will give different results.
  prefs: []
  type: TYPE_NORMAL
- en: The key diffences between the methods is that some may fit better with smaller
    datasets or normal-sized datasets with different distribution characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The key takeways from this section are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The normal distribution is a continuous probability distribution that has a
    bell-shaped curve. The majority of the data cluster around the mean. The mean,
    median, and the mode of a normal distribution curve are all equal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Skewness measures the asymmetry of a probability distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kurtosis measures the peakedness of a probability distribution. Excess kurtosis
    is commonly used to describe the current probability distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quantiles divide the arranged dataset into equal parts. The most famous quantiles
    are quartiles which divide the data into four equal parts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The IQR is the difference between the third quartile and the first quartile.
    It is immune to outliers and thus, very helpful in data analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you remember from the previous chapter, I have presented a six-phase process
    in data science. Phase four dealt with data visualization. This section will show
    you a few ways to present the data in a clear visual manner that allows you to
    interpret it.
  prefs: []
  type: TYPE_NORMAL
- en: There are many types of statistical plots that are commonly used to visualize
    data such as scatter plots and line plots. Let’s discuss these plots and create
    them using the same inflation data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first data visualization method is *scatter plots*, which are used to graph
    the relationship between two variables through points that correspond to the intersection
    between the variables. Let’s create and visualize a scatter plot using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Figure 3-8 shows the result of a scatter plot in time. This means that you have
    the CPI data as the first variable (y-axis) and time as the second variable (x-axis).
    However, scatter plots are more commonly used to compare variables, thus removing
    the time variable can give more insights.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0228.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-8\. Scatter plot of US CPI versus the time axis
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If you take the UK CPI year-on-year change and want to compare it with the
    US CPI year-on-year change, you will should get Figure 3-9\. Notice the positive
    association between the two, as higher values of one are correlated with higher
    values of another. Correlation is a key measure that you will see in detail in
    the next section. The code to plot Figure 3-9 is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlf_0229.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-9\. Scatter plot of UK CPI versus US CPI
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Scatter plots are good when visualizing the correlation between data. They are
    also easy to draw and interpret. Generally, when the points are scattered in such
    a way that when a diagonal upwards sloping line can be drawn to represent them,
    the correlation is assumed to be positive since whenever variables on the x-axis
    increase, variables on the y-axis also increase.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, when a diagonal downwards sloping line can be drawn to represent
    the different variables, a negative correlation may exist. A negative correlation
    implies that whenever variables on the x-axis move, it is likely that variables
    on the y-axis move the other way. Figure 3-10 draw a best fit line (generated
    through code) between the two inflation data. Notice how it is upwards sloping:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_4.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-10\. Scatter plot of UK CPI versus US CPI with a best fit line
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let’s now move to another charting method. *Line plots* are basically scatter
    plots that are joined and are mostly charted against the time axis (x-axis). You
    have already seen line plots in previous charts such as Figure 3-1 and Figure
    3-2 as it is the most basic form of plotting.
  prefs: []
  type: TYPE_NORMAL
- en: '​The advantage of line plots is their simplicity and ease of implementation.
    They also show the evolution of the series through time which helps detecting
    trends and patterns. In Chapter 5, you will see a more elaborate version of plotting
    financial time series called *candlestick plots*. Figure 3-11 shows a basic line
    plot on the US CPI since 1950:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-11\. Line plot of US CPI versus the time axis
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To create Figure 3-11, you can use the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Next up are *bar plots* which display the distribution of variables (generally,
    categorical).  Figure 3-12 shows a bar plot on the US CPI since the beginning
    of 2022:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0778.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-12\. Bar plot of US CPI versus the time axis
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To create Figure 3-12, you can use the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Bar plots are easy to implement and are versatile. However, they can be limited
    for plotting continuous data such as the US CPI or stock prices. They can also
    be misleading when the scale is off. Bar plots are also not recommended for large
    datasets since they clutter up the space. For the latter reason, histograms are
    a better fit.
  prefs: []
  type: TYPE_NORMAL
- en: A *histogram* is a specific sort of bar chart that is used to display the frequency
    distribution of continuous data by using bars to represent statistical information.
    It indicates the number of observations that fall into the class or bin of values.
    An example of a histogram is Figure 3-13 (and Figure 3-7 from the last section):​
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-13\. Histogram plot of US CPI
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the bar plot is charted against the time axis while the histogram
    does not have a time horizon because it is a group of values with the aim of showing
    the overall distribution points. Visually, you can see the positive skewness of
    the distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: An example of a *categorical variable* is gender while an example of a *continuous
    variable* is a commodity’s price.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another classic plotting technique in statistics is the famous *box and whisker
    plot*. It used to visualize the distribution of continuous variables while including
    the median and the quartiles, as well as the outliers. The way to understand the
    box and whisker plot is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The box represents the IQR. The box is drawn between the first quartile and
    the third quartile. The height of the box indicates the spread of the data in
    this range.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The line inside the box represents the median.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The whiskers extend from the top and bottom of the box to the highest and lowest
    data points that are still within 1.5 times the IQR. These data points are called
    *outliers* and are represented as individual points on the plot.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Figure 3-14 shows a box and whisker plot on the US CPI since 1950:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_080.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-14\. Box and whisker plot of US CPI
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You can also plot it without the outliers (any value that lies more than one
    and a half times the length of the box from either end of the box). To create
    Figure 3-14, you can use the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'To remove the outliers from the plot, you simply use the following tweak:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Which will give you Figure 3-15:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0.81.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-15\. Box and whisker plot of US CPI with no outliers
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: ​Many more data visualization techniques exist such as *heatmaps* (commonly
    used with correlation data and temperature mapping) and *pie charts* (commonly
    used for budgeting and segmentation). It all depends on what you need to understand
    and what fits better with your needs. For example, a line plot is better suited
    for time series that only have one feature (for example, only the close price
    of a certain security is available). A histogram plot is better suited with probability
    distribution data.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s do a summary of everything you need to retain:'
  prefs: []
  type: TYPE_NORMAL
- en: Data visualization depends on the type of analysis and interpretation you want
    to do. Some plots are better suited with certain types of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data visualization helps with an initial interpretation of data before confirming
    it numerically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You are more likely to use line plots and candlestick plots when dealing with
    financial time series.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Correlation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Correlation* is a measure used to calculate the degree of the linear relationship
    between two variables. It is a number between -1.0 and 1.0 with -1.0 designating
    a strong negative relationship between the variables and 1.0 designating a strong
    positive relationship.'
  prefs: []
  type: TYPE_NORMAL
- en: A value of zero indicates that there is no linear association between the variables.
    However, correlation does not imply causation. Two variables are said to be correlated
    if they move in the same direction, but this does not imply that one causes the
    other to move or that they move as a result of the same events.
  prefs: []
  type: TYPE_NORMAL
- en: Most people agree that some assets have natural correlations. For instance,
    because they are both part of the same industry and are affected by the same trends
    and events, the stocks of Apple and Microsoft are positively connected (which
    means their general trend is in the same direction). Figure 3-16 shows the chart
    between the two stocks. Notice how they move together.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0569.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-16\. Apple and Microsoft stock prices since 2021
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The tops and bottoms of both stocks occur at almost the exact same time. Similarly,
    as the United States and the UK have similar economic drivers and impacts, they
    are also likely to have positively correlated inflation numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Checking for correlation is done through visual interpretation and mathematical
    formulae. Before seeing an example, let’s deeply understand the roots of calculating
    correlation so that you know where it comes from and what are its limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Simply put, to calculate correlation, you need to measure how close the points
    in a scatter plot of the two variables are to a straight line. The more they look
    like a straight line, the more they are positively correlated, hence the term,
    *linear correlation*.
  prefs: []
  type: TYPE_NORMAL
- en: There are two main^([1](ch03.xhtml#idm46147470912384)) ways to calculate correlation,
    it is either by using the Spearman method or the Pearson method.
  prefs: []
  type: TYPE_NORMAL
- en: The *Pearson* correlation coefficient, is a measure of the linear association
    between two variables calculated from the standard deviation and the covariance
    between two variables. But, what is covariance?
  prefs: []
  type: TYPE_NORMAL
- en: '*Covariance* calculates the average of the difference between the means of
    the two variables. If the two variables have a tendency to move together, the
    covariance is positive and if the two variables typically move in opposite directions,
    the covariance is negative. It ranges between infinity and negative infinity with
    values close to zero representing no linear correlation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula for calculating the covariance between variables *x* and *y* is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="c o v Subscript x y Baseline equals StartFraction sigma-summation
    Underscript i equals 1 Overscript n Endscripts left-parenthesis x Subscript i
    Baseline minus x overbar right-parenthesis left-parenthesis y Subscript i Baseline
    minus y overbar right-parenthesis Over n EndFraction"><mrow><mi>c</mi> <mi>o</mi>
    <msub><mi>v</mi> <mrow><mi>x</mi><mi>y</mi></mrow></msub> <mo>=</mo> <mstyle scriptlevel="0"
    displaystyle="false"><mfrac><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <mrow><mo>(</mo><msub><mi>x</mi> <mi>i</mi></msub> <mo>-</mo><mover
    accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow><mrow><mo>(</mo><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>-</mo><mover accent="true"><mi>y</mi> <mo>¯</mo></mover><mo>)</mo></mrow></mrow>
    <mi>n</mi></mfrac></mstyle></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, covariance is the sum of the products of the average deviations
    between the variables and their respective means (which measures the degree of
    their association). An average is taken to normalize this calculation. The Pearson
    correlation coefficient is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="r Subscript x y Baseline equals StartFraction sigma-summation
    Underscript i equals 1 Overscript n Endscripts left-parenthesis x Subscript i
    Baseline minus x overbar right-parenthesis left-parenthesis y Subscript i Baseline
    minus y overbar right-parenthesis Over StartRoot sigma-summation Underscript i
    equals 1 Overscript n Endscripts left-parenthesis x Subscript i Baseline minus
    x overbar right-parenthesis squared EndRoot StartRoot sigma-summation Underscript
    i equals 1 Overscript n Endscripts left-parenthesis y Subscript i Baseline minus
    y overbar right-parenthesis squared EndRoot EndFraction"><mrow><msub><mi>r</mi>
    <mrow><mi>x</mi><mi>y</mi></mrow></msub> <mo>=</mo> <mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup> <mrow><mo>(</mo><msub><mi>x</mi>
    <mi>i</mi></msub> <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow><mrow><mo>(</mo><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>-</mo><mover accent="true"><mi>y</mi> <mo>¯</mo></mover><mo>)</mo></mrow></mrow>
    <mrow><msqrt><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <msup><mrow><mo>(</mo><msub><mi>x</mi> <mi>i</mi></msub>
    <mo>-</mo><mover accent="true"><mi>x</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></msqrt> <msqrt><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <msup><mrow><mo>(</mo><msub><mi>y</mi> <mi>i</mi></msub>
    <mo>-</mo><mover accent="true"><mi>y</mi> <mo>¯</mo></mover><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></msqrt></mrow></mfrac></mstyle></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Simplifying the previous correlation formula gives you the following:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="r Subscript x y Baseline equals StartFraction c o v Subscript
    x y Baseline Over sigma Subscript x Baseline sigma Subscript y Baseline EndFraction"><mrow><msub><mi>r</mi>
    <mrow><mi>x</mi><mi>y</mi></mrow></msub> <mo>=</mo> <mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi>c</mi><mi>o</mi><msub><mi>v</mi>
    <mrow><mi>x</mi><mi>y</mi></mrow></msub></mrow> <mrow><msub><mi>σ</mi> <mi>x</mi></msub>
    <msub><mi>σ</mi> <mi>y</mi></msub></mrow></mfrac></mstyle></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, Pearson correlation coefficient is simply the covariance between
    two variables divided by the product of their standard deviation. Let’s calculate
    the correlation between the US CPI year-on-year changes and the UK CPI year-on-year
    changes. The intuition is that the correlation is above zero as economically,
    the UK and the US are related. The following code block calculates the Pearson
    correlation coefficient for the two time series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The correlation between the two is a whopping 0.73\. This is in line with the
    expectations. Pearson correlation is usually used with variables that have proportional
    changes and are normally distributed. This may be an issue as financial data is
    not normally distributed. Therefore, it is interesting to discuss Spearman correlation.
  prefs: []
  type: TYPE_NORMAL
- en: '*Spearman correlation* is a non-parametric rank correlation that measures the
    strength of the relationship between the variables. It is suitable for variables
    that do not follow a normal distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Remember, financial returns are not normally distributed but are sometimes treated
    that way for simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unlike Pearson correlation, the Spearman rank correlation takes into account
    the order of the values, rather than the actual values. To calculate Spearman
    correlation, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Rank the values of each variable. This is done by inputing 1 instead of the
    smallest variable and inputing the length of the dataset instead of the largest
    number.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the difference in ranks. Mathematically, the difference in ranks is
    represented by the letter *d* in the mathematical formula to come. Then, calculate
    their squared differences.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sum the squared differences you have calculated from step 2.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the following formula to calculate Spearman correlation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="rho equals 1 minus StartFraction 6 sigma-summation Underscript
    i equals 1 Overscript n Endscripts d Subscript i Superscript 2 Baseline Over n
    cubed minus n EndFraction"><mrow><mi>ρ</mi> <mo>=</mo> <mn>1</mn> <mo>-</mo> <mfrac><mrow><mn>6</mn><msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup> <msubsup><mi>d</mi>
    <mrow><mi>i</mi></mrow> <mn>2</mn></msubsup></mrow> <mrow><msup><mi>n</mi> <mn>3</mn></msup>
    <mo>-</mo><mi>n</mi></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: As with Pearson correlation, Spearman correlation also ranges from -1.00 to
    1.00 with the same interpretation.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Strong positive correlations are generally upwards of 0.70, while strong negative
    correlations are generally downwards of -0.70.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block calculates the Spearman rank correlation coefficient
    for the two time series:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Let’s answer a very important question after getting this difference in results.
    Why are the two measures so different?
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to keep in mind is what they measure. Pearson correlation measures
    the linear relationship (trend) between the variables while Spearman rank correlation
    measures the monotonic trend. The word *monotonic* refers to moving in the same
    direction but not exactly at the same rate or magnitude. Also, Spearman correlation
    transforms the data to an ordinal type (through the ranks) as opposed to Pearson
    correlation which uses the actual values.
  prefs: []
  type: TYPE_NORMAL
- en: '*Autocorrelation* (also referred to as serial correlation) is a statistical
    method used to look at the relationship between a given time series and a lagged
    version of it. It is generally used to predict future values through patterns
    in data, such as seasonality or trends. Autocorrelation is therefore the values’
    relationship with the previous values. For example, comparing each day’s Microsoft
    stock price to the preceding day and see if there is a discernible correlation
    there. Algorithmically speaking, this can be represented in table 3-2:'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-1\. Lagged values table
  prefs: []
  type: TYPE_NORMAL
- en: '|      t |      t-1 |'
  prefs: []
  type: TYPE_TB
- en: '|  $       1.25 |  $       1.65 |'
  prefs: []
  type: TYPE_TB
- en: '|  $       1.77 |  $       1.25 |'
  prefs: []
  type: TYPE_TB
- en: '|  $       1.78 |  $       1.77 |'
  prefs: []
  type: TYPE_TB
- en: '|  $       1.25 |  $       1.78 |'
  prefs: []
  type: TYPE_TB
- en: '|  $       1.90 |  $       1.25 |'
  prefs: []
  type: TYPE_TB
- en: Each row represents a time period. Column *t* is the current price and column
    *t-1* is the previous price put on the row that represents the present. This is
    done when creating machine learning models so as to understand the relationship
    between the current values and the previous ones at every time step (row).
  prefs: []
  type: TYPE_NORMAL
- en: Positive auto correlation frequently occurs in trending assets and is associated
    with the idea of persistence (trend following). On the other hand, ranging markets
    exhibit negative auto correlation, which is associated with the idea of anti-persistence
    (mean reversion).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Measures of short-term correlation are typically computed using returns on prices
    rather than real prices. However, it is possible to utilize the prices directly
    to identify long-term trends.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block calculates the autocorrelation of the US CPI year-on-year:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'A lag of 12 means that every data is compared to the data from twelve periods
    ago and then a calculation measure is calculated. The output of the code is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Now, before proceeding to the next section, let’s revert back to information
    theory and discuss one interesting correlation coefficient that is able to pick-up
    on non-linear relationships. One of these ways is the maximal information coefficient
    (MIC).
  prefs: []
  type: TYPE_NORMAL
- en: The *maximal information coefficient* (MIC) is a non-parametric measure of association
    between two variables designed to handle large and complex data. It is generally
    seen as a more robust alternative to traditional measures of correlation, such
    as Pearson correlation and Spearman rank correlation. Introduced by *Reshef et
    al.*, the MIC uses concepts from information theory that you have seen in Chapter
    2.
  prefs: []
  type: TYPE_NORMAL
- en: The MIC measures the strength of the association between two variables by counting
    the number of cells in a contingency table that are maximally informative about
    the relationship between the variables. The MIC value ranges from 0 to 1, with
    higher values indicating stronger associations. It can handle high-dimensional
    data and can identify non-linear relationships between variables. It is however
    non-directional which means that values close to 1 only suggest a strong correlation
    between the two variables but it does not say whether the correlation is positive
    or negative.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In other words, the mutual information between the two variables within each
    bin is calculated after the range of each variable has been divided into a set
    of bins.
  prefs: []
  type: TYPE_NORMAL
- en: The strength of the association between the two variables is then estimated
    using the maximum mutual information value across all bins.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s check out a practical example that showcases the strength of the MIC in
    detecting non-linear relationships. The following example simulate a Sinus and
    Cosinus time series. Intuitively, looking at Figure 3-17, it seems that there
    is a lag-lead relationship between the two.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0230.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-17\. The two wave series showing a form of non-linear relationship
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The following Python code snippet creates the two time series and plots Figure
    3-17:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, the job is to calculate the three correlation measures and analyze their
    results. This can be done using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that since the code creates an array (and not a data frame), it is mandatory
    to import the required libraries before calculating the measures. This will be
    made clear in the next chapter. The following is the output of the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s interpret the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Pearson correlation*: Notice the absence of any type of correlation here due
    to it missing out on the non-linear association.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Spearman correlation*: The same situation applies here with an extremely weak
    correlation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*MIC*: The measure returned a strong relationship of 0.60 between the two which
    is closer to reality. It seems that the MIC states that both waves have a strong
    relationship albeit non-linear.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You may need to update Microsoft Visual C++ (at least version 14.0 or greater)
    to avoid any errors in trying to run `minepy`library.
  prefs: []
  type: TYPE_NORMAL
- en: The MIC is very useful in economic analysis, financial analysis, and even finding
    trading signals if used properly. Non-linear relationships are abundant in such
    complex fields and being able to detect them may give a sizable edge.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The main takeaways from the correlation section are the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: Correlation is a measure used to calculate the degree of the linear relationship
    between two variables. It is a number between -1.0 and 1.0 with -1.0 designating
    a strong negative relationship between the variables and 1.0 designating a strong
    positive relationship.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are two main types of correlation measures, Spearman and Pearson. Both
    have their advantages and limitations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autocorrelation is the correlation of the variable with its own lagged values.
    For example, if the autocorrelation of Nvidia’s stock returns is positive, it
    denotes a trending configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Correlation measures can also refer to non-linear relationships when you use
    the right tool, for example, the MIC.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Concept of Stationarity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stationarity is one of the key concepts in statistical analysis and machine
    learning. *Stationarity* is when the statistical characteristics of the time series
    (mean, variance, etc.) are constant over time. In other words, no discernable
    trend is detectable when plotting the data across time.
  prefs: []
  type: TYPE_NORMAL
- en: The different learning models rely on data stationarity as it is one of the
    basics of statistical modelling and this is mainly for simplicity. In finance,
    price time series are not stationary as they show trends with varying variance
    (volatility). Take a look at Figure 3-18 and see if you can detect a trend. Would
    you say that this time series is stationary?
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0211.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-18\. Simulated data with a varying mean across time
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Naturally, the answer is no as a rising trend is clearly in progress. States
    like this are undesirable for statistical analyses and machine learning. Luckily,
    there are transformations that you can apply to the time series to make them stationary.
    But first, let’s see how to check for stationarity the mathematical way as the
    visual way does not prove anything. The right process to deal with data stationarity
    problem is to follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Check for stationarity using the different statistical tests that you will see
    in this section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the tests show data stationarity, you are ready to use the data for the different
    learning algorithms. If the tests show that the data is not stationary, you have
    to proceed to the next step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Apply the price transformation technique that you will see in this section.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Re-check for stationarity using the same tests on the new transformed data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the test shows data stationarity, then you have successfully transformed
    your data. Otherwise, re-do the transformation and check again until you have
    stationary data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Ascending or descending time series have varying mean and variances through
    time and are therefore most likely non-stationary. There are exceptions to this
    and you will see later why.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, the aim of stationarity is stable and constant mean and variance over
    time. Therefore, when you look at Figure 3-19, what can you say about it?
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_0210.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-19\. Simulated data with a mean around zero across time
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Visually, it looks like the data does not have a trend and it also looks like
    it fluctuates around a stable mean with stable variance around it. The first impression
    is that the data is stationary. Of course, this must be proved by statistical
    tests.
  prefs: []
  type: TYPE_NORMAL
- en: The first and most basic test is the *Augmented-Dickey-Fuller* (ADF) test. The
    ADF tests for stationarity using hypothesis testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ADF test searches for a unit root in the data. A *unit root* is a property
    of non-stationary data and in the context of time series analysis, refers to a
    characteristic of a stochastic process where the series has a root equal to 1\.
    In simpler terms, it means that its statistical properties, such as the mean and
    variance, change over time. Here’s what you need to know:'
  prefs: []
  type: TYPE_NORMAL
- en: The null hypothesis assumes the presence of a unit root. This means that if
    you are trying to prove that the data is stationary, you are looking to reject
    the null hypothesis (as seen in the hypothesis testing section from Chapter 2).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The alternative hypothesis is therefore the absence of a unit root and the stationarity
    of the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The p-value obtained from the test must be less than the significance level
    chosen (in most cases, it is 5%).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s take the US CPI year-on-year data and test it for stationarity. The following
    code snippet checks for stationarity using the ADF test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Assuming a 5% significance level, it seems that it is possible to accept that
    the year-on-year data is stationary (however, if you want to be more strict and
    use a 1% significance level, then the p-value suggests that the data is non-stationary).
    In any way, even looking at the chart can make you scratch your head. Remember
    that in Figure 3-11, the yearly changes in the US CPI seem to be stable but does
    not resemble stationary data. This is why numerical and statistical tests are
    used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s the do the same thing but omit taking the yearly changes. In other
    words, applying the code on the raw US CPI data and not taking year-on-year changes.
    Here’s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Clearly, the p-value is greater than all significance levels which means that
    the time series is non-stationary. Let’s sum up these results:'
  prefs: []
  type: TYPE_NORMAL
- en: It seems that you can reject the null hypothesis using a 5% significance level
    when it comes to the year-on-year changes on the US CPI. The dataset is assumed
    to be stationary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It seems that you cannot reject the null hypothesis using a 5% significance
    level when it comes to the raw values of the US CPI. The dataset is assumed to
    be non-stationary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This becomes obvious when you plot the raw values of the US CPI, as shown in
    Figure 3-20.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_5.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-20\. Absolute values of the US CPI showing a clearly trending nature
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The other test that you must be aware of is called the The *Kwiatkowski-Phillips-Schmidt-Shin*
    (KPSS) which is also a statistical test with the aim of determining whether the
    time series is stationary or non-stationary. However, the KPSS test can detect
    stationarity in trending time series which makes it a powerful tool.
  prefs: []
  type: TYPE_NORMAL
- en: Trending time series can actually be stationary on the condition they have a
    stable mean.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ADF test has a a null hypothesis that argues for non-stationarity and an
    alternative hypothesis that argues for stationarity. The KPSS test on the other
    hand, has a null hypothesis that argues for stationarity and an alternative hypothesis
    that argues for non-stationarity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before analyzing the inflation data, let’s see how can a trending time series
    be stationary. Remember that stationarity refers to a stable mean and standard
    deviation so if somehow, you have a gradually ascending or descending time series
    with stable statistical properties, it may be stationary. The next code snippet
    simulates a sine wave and then adds a touch of a trending nature to it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Plotting the two series as shown in Figure 3-21 shows how the trending sinewave
    seems to be stable. But let’s prove this through statistical tests.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlf_6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-21\. A normal sine wave simulated series with a trending sine wave
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Figure 3-21 is generated using the following code (make sure you have defined
    the series using the previous code block):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s try the ADF test on both series and see what the results are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Clearly, the ADF test is consistent with the idea that trending markets cannot
    be stationary. But what about the KPSS test? The following code uses the KPSS
    on the same data to check for stationarity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Remember that the null hypothesis of the KPSS test is that the data is stationary,
    therefore if the p-value is greater than the significance level, the data is considered
    stationary since it is not possible to reject the null hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: The KPSS statistic when taking into account the trend, states that the ascending
    sine wave is a stationary time series. This is a basic example on how you can
    find stationary data in trending time series.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take the US CPI year-on-year data and test it for stationarity. The following
    code snippet checks for stationarity using the KPSS test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: It seems that the results from the KPSS test are in contradiction with the results
    from the ADF test. This may happen from time to time and differencing may solve
    the issue (bear in mind, that the year-on-year data is already a differenced time
    series from the absolute CPI values but some time series may need more than one
    differencing to become stationary and it also depends on the period of differencing).
    The safest solution in contradiction is to transform once more the data.
  prefs: []
  type: TYPE_NORMAL
- en: Before finishing this section on stationarity, let’s discuss a complex topic
    that you will later see in action in Chapter 7. Transforming the data may cause
    an unusual problem that is, *memory loss*. In his book, *Marco Lopez de Prado*
    proposed a technique called fractional differentiation with the aim of making
    data stationary while preserving some memory.
  prefs: []
  type: TYPE_NORMAL
- en: When a non-stationary time series is differenced in the aim of making it stationary,
    memory loss occurs which is another way of saying that the autocorrelation between
    the values is greatly reduced, thus removing the trend component and the DNA of
    the underlying asset. The degree of differencing and the persistence of the autocorrelation
    structure in the original series determines how much memory loss occurs.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This section has presented many complex concepts. You should retain the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Stationarity refers to the concept of stable mean and variance through time.
    It is a desired characteristic as most machine learning models rely on it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Financial price time series are most likely non-stationary and require a first
    order transformation to become stationary and ready for statistical modelling.
    Some may even require a second order transformation to become stationary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ADF and KPSS tests check for stationarity in the data with the latter being
    able to check for stationarity in trending data, thus being more thorough.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trending data may be stationary. Although this characteristic is rare, the KPSS
    is able to detect the stationarity as opposed to the ADF test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression Analysis and Statistical Inference
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Inference, *as Oxford Languages defines it, is a conclusion reached on the
    basis of evidence and reasoning. Therefore, as opposed to descriptive statistics,
    inferential statistics use the data or a sample of the data to make inferences
    (forecasts). The main tool in statistical inference is linear regression.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Linear regression* is a basic machine learning algorithm you will see in this
    book as of Chapter 7 with the other machine learning algorithms. Hence, let’s
    present the intuition of regression analysis in this section.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The most basic form of a linear regression equation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="y equals alpha plus beta x plus epsilon"><mrow><mi>y</mi> <mo>=</mo>
    <mi>α</mi> <mo>+</mo> <mi>β</mi> <mi>x</mi> <mo>+</mo> <mi>ϵ</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="y i s t h e d e p e n d e n t v a r i a b l e comma i t i s w
    h a t y o u w a n t t o f o r e c a s t"><mrow><mi>y</mi> <mi>i</mi> <mi>s</mi>
    <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>d</mi> <mi>e</mi> <mi>p</mi> <mi>e</mi> <mi>n</mi>
    <mi>d</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>v</mi> <mi>a</mi> <mi>r</mi> <mi>i</mi>
    <mi>a</mi> <mi>b</mi> <mi>l</mi> <mi>e</mi> <mo>,</mo> <mi>i</mi> <mi>t</mi> <mi>i</mi>
    <mi>s</mi> <mi>w</mi> <mi>h</mi> <mi>a</mi> <mi>t</mi> <mi>y</mi> <mi>o</mi> <mi>u</mi>
    <mi>w</mi> <mi>a</mi> <mi>n</mi> <mi>t</mi> <mi>t</mi> <mi>o</mi> <mi>f</mi> <mi>o</mi>
    <mi>r</mi> <mi>e</mi> <mi>c</mi> <mi>a</mi> <mi>s</mi> <mi>t</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x i s t h e i n d e p e n d e n t v a r i a b l e comma i t i
    s w h a t y o u u s e a s a n i n p u t t o f o r e c a s t y"><mrow><mi>x</mi>
    <mi>i</mi> <mi>s</mi> <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>i</mi> <mi>n</mi> <mi>d</mi>
    <mi>e</mi> <mi>p</mi> <mi>e</mi> <mi>n</mi> <mi>d</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi>
    <mi>v</mi> <mi>a</mi> <mi>r</mi> <mi>i</mi> <mi>a</mi> <mi>b</mi> <mi>l</mi> <mi>e</mi>
    <mo>,</mo> <mi>i</mi> <mi>t</mi> <mi>i</mi> <mi>s</mi> <mi>w</mi> <mi>h</mi> <mi>a</mi>
    <mi>t</mi> <mi>y</mi> <mi>o</mi> <mi>u</mi> <mi>u</mi> <mi>s</mi> <mi>e</mi> <mi>a</mi>
    <mi>s</mi> <mi>a</mi> <mi>n</mi> <mi>i</mi> <mi>n</mi> <mi>p</mi> <mi>u</mi> <mi>t</mi>
    <mi>t</mi> <mi>o</mi> <mi>f</mi> <mi>o</mi> <mi>r</mi> <mi>e</mi> <mi>c</mi> <mi>a</mi>
    <mi>s</mi> <mi>t</mi> <mi>y</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="alpha i s t h e e x p e c t e d v a l u e o f t h e d e p e n
    d e n t v a r i a b l e w h e n t h e i n d e p e n d e n t v a r i a b l e s
    a r e e q u a l t o z e r o"><mrow><mi>α</mi> <mi>i</mi> <mi>s</mi> <mi>t</mi>
    <mi>h</mi> <mi>e</mi> <mi>e</mi> <mi>x</mi> <mi>p</mi> <mi>e</mi> <mi>c</mi> <mi>t</mi>
    <mi>e</mi> <mi>d</mi> <mi>v</mi> <mi>a</mi> <mi>l</mi> <mi>u</mi> <mi>e</mi> <mi>o</mi>
    <mi>f</mi> <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>d</mi> <mi>e</mi> <mi>p</mi> <mi>e</mi>
    <mi>n</mi> <mi>d</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>v</mi> <mi>a</mi> <mi>r</mi>
    <mi>i</mi> <mi>a</mi> <mi>b</mi> <mi>l</mi> <mi>e</mi> <mi>w</mi> <mi>h</mi> <mi>e</mi>
    <mi>n</mi> <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>i</mi> <mi>n</mi> <mi>d</mi> <mi>e</mi>
    <mi>p</mi> <mi>e</mi> <mi>n</mi> <mi>d</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>v</mi>
    <mi>a</mi> <mi>r</mi> <mi>i</mi> <mi>a</mi> <mi>b</mi> <mi>l</mi> <mi>e</mi> <mi>s</mi>
    <mi>a</mi> <mi>r</mi> <mi>e</mi> <mi>e</mi> <mi>q</mi> <mi>u</mi> <mi>a</mi> <mi>l</mi>
    <mi>t</mi> <mi>o</mi> <mi>z</mi> <mi>e</mi> <mi>r</mi> <mi>o</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="beta r e p r e s e n t s t h e c h a n g e i n t h e d e p e
    n d e n t v a r i a b l e p e r u n i t c h a n g e i n t h e i n d e p e n d
    e n t v a r i a b l e"><mrow><mi>β</mi> <mi>r</mi> <mi>e</mi> <mi>p</mi> <mi>r</mi>
    <mi>e</mi> <mi>s</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>s</mi> <mi>t</mi> <mi>h</mi>
    <mi>e</mi> <mi>c</mi> <mi>h</mi> <mi>a</mi> <mi>n</mi> <mi>g</mi> <mi>e</mi> <mi>i</mi>
    <mi>n</mi> <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>d</mi> <mi>e</mi> <mi>p</mi> <mi>e</mi>
    <mi>n</mi> <mi>d</mi> <mi>e</mi> <mi>n</mi> <mi>t</mi> <mi>v</mi> <mi>a</mi> <mi>r</mi>
    <mi>i</mi> <mi>a</mi> <mi>b</mi> <mi>l</mi> <mi>e</mi> <mi>p</mi> <mi>e</mi> <mi>r</mi>
    <mi>u</mi> <mi>n</mi> <mi>i</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>a</mi> <mi>n</mi>
    <mi>g</mi> <mi>e</mi> <mi>i</mi> <mi>n</mi> <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>i</mi>
    <mi>n</mi> <mi>d</mi> <mi>e</mi> <mi>p</mi> <mi>e</mi> <mi>n</mi> <mi>d</mi> <mi>e</mi>
    <mi>n</mi> <mi>t</mi> <mi>v</mi> <mi>a</mi> <mi>r</mi> <mi>i</mi> <mi>a</mi> <mi>b</mi>
    <mi>l</mi> <mi>e</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="epsilon i s t h e r e s i d u a l o r t h e u n e x p l a i n
    e d v a r i a t i o n"><mrow><mi>ϵ</mi> <mi>i</mi> <mi>s</mi> <mi>t</mi> <mi>h</mi>
    <mi>e</mi> <mi>r</mi> <mi>e</mi> <mi>s</mi> <mi>i</mi> <mi>d</mi> <mi>u</mi> <mi>a</mi>
    <mi>l</mi> <mi>o</mi> <mi>r</mi> <mi>t</mi> <mi>h</mi> <mi>e</mi> <mi>u</mi> <mi>n</mi>
    <mi>e</mi> <mi>x</mi> <mi>p</mi> <mi>l</mi> <mi>a</mi> <mi>i</mi> <mi>n</mi> <mi>e</mi>
    <mi>d</mi> <mi>v</mi> <mi>a</mi> <mi>r</mi> <mi>i</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi>
    <mi>o</mi> <mi>n</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The basic linear regression equation states that a dependent variable (what
    you want to forecast) is explained by a constant, a sensitivity-adjusted variable,
    and a residual (error term to account for unexplained variations). Consider table
    3-3:'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-2\. Prediction table
  prefs: []
  type: TYPE_NORMAL
- en: '| y | x |'
  prefs: []
  type: TYPE_TB
- en: '| 100 | 49 |'
  prefs: []
  type: TYPE_TB
- en: '| 200 | 99 |'
  prefs: []
  type: TYPE_TB
- en: '| 300 | 149 |'
  prefs: []
  type: TYPE_TB
- en: '| 400 | 199 |'
  prefs: []
  type: TYPE_TB
- en: '| ? | 249 |'
  prefs: []
  type: TYPE_TB
- en: 'The linear equation to predict *y* given *x*, is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="y Subscript i Baseline equals 2 plus 2 x Subscript i"><mrow><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>=</mo> <mn>2</mn> <mo>+</mo> <mn>2</mn> <msub><mi>x</mi>
    <mi>i</mi></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, the latest *y* given *x* = 249 should be 500:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="y Subscript i Baseline equals 2 plus 2 x Subscript i Baseline
    equals 2 plus left-parenthesis 2 times 249 right-parenthesis equals 500"><mrow><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>=</mo> <mn>2</mn> <mo>+</mo> <mn>2</mn> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>=</mo> <mn>2</mn> <mo>+</mo> <mrow><mo>(</mo> <mn>2</mn>
    <mo>×</mo> <mn>249</mn> <mo>)</mo></mrow> <mo>=</mo> <mn>500</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Notice how linear regression perfectly captures the linear relationship between
    the two variables since there is no residual (unexplained variations). When a
    linear regression perfectly captures the relationship between two variables, it
    means that their coordinate points are perfectly aligned on a linear line across
    the x-axis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Multiple linear regression can take the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="y Subscript i Baseline equals alpha plus beta 1 x 1 plus period
    period period plus beta Subscript n Baseline x Subscript n Baseline plus epsilon
    Subscript i Baseline"><mrow><msub><mi>y</mi> <mi>i</mi></msub> <mo>=</mo> <mi>α</mi>
    <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>+</mo> <msub><mi>β</mi> <mi>n</mi></msub>
    <msub><mi>x</mi> <mi>n</mi></msub> <mo>+</mo> <msub><mi>ϵ</mi> <mi>i</mi></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This basically means that the dependent variable *y* may be impacted by more
    than one variable. For instance, if you want to estimate housing prices, you may
    want to take into account the number of rooms, the surface area, the neighborhood,
    and any other variable that is likely to impact the price.  Similarly, if you
    want to predict commodity prices, you may want to take into account the different
    macroeconomic factors, currency values, and any other alternative data.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is important to understand what every variable refers to. Make sure to memorize
    the previous formula. Linear regression has a few assumptions:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear relationship
  prefs: []
  type: TYPE_NORMAL
- en: The relationship between the dependent variable and the independent variable(s)
    should be linear, meaning that a straight line across the plane can describe the
    relationship. This is rare in real life when dealing with complex financial variables.
  prefs: []
  type: TYPE_NORMAL
- en: Independence of variables
  prefs: []
  type: TYPE_NORMAL
- en: The observations should be independent of each other, meaning that the value
    of one observation does not influence the value of another observation.
  prefs: []
  type: TYPE_NORMAL
- en: Homoscedasticity
  prefs: []
  type: TYPE_NORMAL
- en: The variance of the residuals (the difference between the predicted and actual
    values of the dependent variable) should be constant across all levels of the
    independent variable(s).
  prefs: []
  type: TYPE_NORMAL
- en: Normality of the residuals
  prefs: []
  type: TYPE_NORMAL
- en: The residuals should be normally distributed, meaning that the majority of the
    residuals are close to zero and the distribution is symmetrical.
  prefs: []
  type: TYPE_NORMAL
- en: ​In case of a multiple linear regression, you can add a new assumption, that
    is the absence of *multicollinearity*. ​The independent variables should not be
    highly correlated with each other, otherwise it can make it difficult to determine
    the unique effect of each independent variable on the dependent variable. In other
    words, this prevents redundancy. You will see linear regression in detail with
    more in-depth examples in Chapter 7 as this section only introduces it as part
    of the statistics field.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, you should have a solid understanding in the key concepts of statistics.
    Let’s do a summary of everything you need to retain:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear regression is part of the inferential statistics field and it is a linear
    equation that describes the relationship between variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linear regression interprets and predicts data following an equation that you
    obtain when you train past data and expect the relationship to hold in the future.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Being able to perform data analysis is key towards deploying the right algorithms
    in order to predict the future values of the time series. Understanding data is
    done through a wide selection of tools coming from the statistics world. Make
    sure you understand what stationarity and what correlation are as they offer extremely
    valuable insights in modeling.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch03.xhtml#idm46147470912384-marker)) Among others but these two ways
    are the most popular representations.
  prefs: []
  type: TYPE_NORMAL
