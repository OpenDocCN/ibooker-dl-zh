- en: Chapter 2\. Designing Cloud Native Architectures for Generative AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章\. 为生成式人工智能设计云原生架构
- en: Cloud native architecture is a way of designing and building applications that
    can take advantage of the cloud’s unique capabilities and constraints. Cloud native
    applications are typically composed of microservices that run in containers, orchestrated
    by platforms like Kubernetes, and use DevOps and continuous integration and continuous
    deployment (CI/CD) practices to enable rapid delivery and scalability. Cloud native
    architectures are at the core of the generative AI era.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生架构是一种设计和构建应用的方式，能够利用云的独特能力和限制。云原生应用通常由运行在容器中的微服务组成，由像 Kubernetes 这样的平台进行编排，并使用
    DevOps 和持续集成/持续部署（CI/CD）实践来实现快速交付和可扩展性。云原生架构是生成式人工智能时代的核心。
- en: Organizations such as the [Cloud Native Computing Foundation (CNCF)](https://oreil.ly/dUsAO)
    are great catalysts of cloud native best practices and community development.
    Their goal is to be *“*the vendor-neutral hub of cloud native computing, to make
    cloud native universal and sustainable.” CNCF is a great source of information
    and learning material for these topics. Another great resource is the [twelve-factor
    app](https://oreil.ly/AFEgd), a public methodology for building cloud native applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 像云原生计算基金会（Cloud Native Computing Foundation，CNCF）这样的组织是云原生最佳实践和社区发展的伟大催化剂。他们的目标是成为“*云原生计算的供应商中立中心，使云原生普遍且可持续。”
    CNCF 是这些主题的信息和学习材料的绝佳来源。另一个很好的资源是 [十二要素应用](https://oreil.ly/AFEgd)，这是一种构建云原生应用的公开方法论。
- en: As part of the cloud native movement, there are several projects and communities
    oriented to the use of cloud native architecture to enable scalable, reliable,
    and robust AI systems. They often require large amounts of data, complex algorithms,
    and specialized hardware to perform tasks such as image recognition, natural language
    processing, or recommendation systems. This is not always possible with traditional
    IT architecture patterns (e.g., [monolithic applications](https://oreil.ly/TrFNL)).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作为云原生运动的一部分，有几个项目和社区致力于使用云原生架构来实现可扩展、可靠和强大的人工智能系统。它们通常需要大量数据、复杂算法和专用硬件来执行图像识别、自然语言处理或推荐系统等任务。这并不总是传统
    IT 架构模式（例如，[单体应用](https://oreil.ly/TrFNL)）所能实现的。
- en: 'The need for cloud native architecture for AI systems arises from the following
    reasons:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统需要云原生架构的原因如下：
- en: System performance
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 系统性能
- en: AI systems need to process large volumes of data and run complex computations
    in a fast and efficient manner. Cloud native architecture enables AI systems to
    leverage the cloud’s elastic resources, such as compute, storage, and network,
    to scale up or down according to demand. It also allows AI systems to use specialized
    hardware, such as graphics processing units (GPUs) or tensor processing units
    (TPUs), that are optimized for AI workloads.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统需要以快速和高效的方式处理大量数据并运行复杂的计算。云原生架构使人工智能系统能够利用云的弹性资源，如计算、存储和网络，根据需求进行扩展或缩减。它还允许人工智能系统使用针对人工智能工作负载优化的专用硬件，如图形处理单元（GPUs）或张量处理单元（TPUs）。
- en: Agility
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 灵活性
- en: AI systems need to adapt to changing business requirements, user feedback, and
    data quality. Cloud native architecture enables AI systems to deploy new features,
    models, or updates quickly and reliably using DevOps and CI/CD practices. It also
    allows AI systems to experiment with different architectures, algorithms, or parameters
    using techniques such as A/B testing or canary deployments.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统需要适应不断变化的企业需求、用户反馈和数据质量。云原生架构使人工智能系统能够通过 DevOps 和 CI/CD 实践快速、可靠地部署新功能、模型或更新。它还允许人工智能系统使用
    A/B 测试或金丝雀部署等技术来尝试不同的架构、算法或参数。
- en: Innovation and integrability
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 创新和可集成性
- en: AI systems need to leverage the latest advances in AI research and technology.
    Cloud native architecture enables AI systems to access the cloud’s rich ecosystem
    of AI services, tools, and frameworks that offer state-of-the-art functionality
    and performance. It also allows AI systems to integrate with other cloud services,
    such as data analytics, Internet of Things, or edge computing, that can enhance
    the value and intelligence of AI systems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统需要利用人工智能研究和技术的最新进展。云原生架构使人工智能系统能够访问云的丰富生态系统中的 AI 服务、工具和框架，这些服务、工具和框架提供最先进的功能和性能。它还允许人工智能系统与其他云服务集成，如数据分析、物联网或边缘计算，从而增强人工智能系统的价值和智能。
- en: The most important areas for cloud native are described by CNCF as CI/CD, DevOps,
    microservices, and containers, as shown in [Figure 2-1](#fig_1__cloud_native_building_blocks_for_generative_ai_a).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: CNCF将云原生最重要的领域描述为CI/CD、DevOps、微服务和容器，如图2-1所示。
- en: '![](assets/aoas_0201.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0201.png)'
- en: 'Figure 2-1\. Cloud native building blocks for generative AI (source: adapted
    from an image by CNCF)'
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-1. 生成式AI的云原生构建块（来源：改编自CNCF的图像）
- en: 'These four areas are relevant to generative AI applications:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个领域与生成式AI应用相关：
- en: CI/CD
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: CI/CD
- en: Enables a streamlined and automated process for integrating code changes, building,
    testing, and deploying AI models and applications, and facilitates faster iterations
    and reduces time to market for generative AI developments.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 实现了集成代码更改、构建、测试和部署AI模型和应用的简化流程，并促进了生成式AI开发的快速迭代，缩短了上市时间。
- en: DevOps
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps
- en: Combines the principles and practices of DevOps for AI technologies to improve
    the development, deployment, and operations of AI systems, and facilitates the
    integration of generative AI into the overall software development lifecycle.
    It also ensures reliable monitoring, logging, and feedback loops, enabling quick
    identification and resolution of issues in generative AI systems.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 将AI技术的DevOps原则和实践相结合，以改善AI系统的开发、部署和运营，并促进生成式AI集成到整个软件开发生命周期中。它还确保了可靠的监控、日志记录和反馈循环，使问题在生成式AI系统中能够快速识别和解决。
- en: Microservices
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务
- en: Allows complex generative AI systems to be broken down into smaller, independent
    services, which enables modular development and deployment of different components
    of the AI system. It also enhances scalability and flexibility, as individual
    microservices can be developed, deployed, and scaled independently.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 允许复杂的生成式AI系统被分解成更小、独立的微服务，这有助于模块化开发和部署AI系统的不同组件。它还增强了可扩展性和灵活性，因为单个微服务可以独立地进行开发、部署和扩展。
- en: Containers
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 容器
- en: Offers a lightweight and portable way to package and deploy generative AI models
    and applications, and enables easy scaling, replication, and orchestration of
    generative AI workloads.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了一种轻量级且便携的方式来打包和部署生成式AI模型和应用，并使生成式AI工作负载的扩展、复制和编排变得容易。
- en: Cloud native architecture is a key enabler for developing advanced, intelligent
    AI systems that can deliver high performance, agility, and innovation on the cloud
    platform. In this chapter, we will explore how to prepare a cloud native architecture
    for an AI-enabled system that leverages Azure OpenAI Service, regardless of the
    kind of application you are planning to develop. Let’s start by digging into some
    typical scenarios for AI cloud native development.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生架构是开发能够提供高性能、敏捷性和创新的云平台的高级智能AI系统的关键推动力。在本章中，我们将探讨如何为利用Azure OpenAI服务的AI赋能系统准备云原生架构，无论你计划开发哪种类型的应用。让我们从深入研究AI云原生开发的典型场景开始。
- en: Modernizing Applications for Generative AI
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为生成式AI现代化应用
- en: 'This book focuses on the development of new cloud native applications with
    Azure OpenAI Service and the rest of the Microsoft Azure stack. However, there
    may be scenarios in which a company tries to leverage these capabilities for their
    existing applications. Let’s compare both scenarios and see the approaches:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本书重点介绍使用Azure OpenAI服务和Microsoft Azure堆栈开发新的云原生应用。然而，可能存在公司试图利用这些能力来改造现有应用的场景。让我们比较这两种场景，并看看方法：
- en: New cloud native applications
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 新云原生应用
- en: Designed from scratch using [containerization](https://oreil.ly/U0o9G) and a
    microservices architecture, enabling scalability, resilience, and elasticity.
    They leverage the four areas previously mentioned, and they make the deployment
    and maintenance of generative AI applications a bit simpler.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始使用[容器化](https://oreil.ly/U0o9G)和微服务架构设计，实现可扩展性、弹性和容错性。它们利用前面提到的四个领域，并使生成式AI应用的部署和维护变得更加简单。
- en: Existing apps
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现有应用
- en: Likely require migration or modernization. This means they’ll either be migrated
    to the cloud, or modified to align with cloud native principles, such as breaking
    down a monolithic architecture into microservices or introducing containerization.
    The modernization process involves step-by-step upgrades, addressing scalability,
    resilience, and fault tolerance, and adopting DevOps practices gradually.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '[*Learning Microsoft Azure* (O’Reilly)](https://oreil.ly/Rqw0P) by Jonah Carrio
    Andersson lays out some different strategies, and Microsoft’s [modernization guide](https://oreil.ly/5Sm8X)
    describes the process for migrating and modernizing existing on-prem/monolithic
    applications to the cloud, with specific cloud native features. [Figure 2-2](#fig_2_cloud_native_modernization_levels_moving_towards_g)
    illustrates the different levels of cloud modernization.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aoas_0202.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2-2\. Cloud native modernization levels moving toward generative AI
    (source: adapted from an image by Microsoft)'
  id: totrans-32
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Based on the modernization steps, there are different levels of maturity that
    range from existing on-premises applications to full cloud native ones. This is
    relevant for implementations with Azure OpenAI Service, as a native cloud-enabled
    PaaS, because new and existing applications will need some level of cloud readiness
    before integrating generative AI capabilities. Think of this as the way the rest
    of the application blocks connect with Azure OpenAI Service in a cloud-enabled
    way, with native and simple integrations.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'The levels of maturity are as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Cloud infrastructure–ready applications
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: With this migration strategy, you simply transfer or relocate your existing
    on-site applications to an infrastructure-as-a-service (IaaS) environment. While
    the structure of your applications remains largely unchanged, they are now hosted
    on virtual machines in the cloud. This straightforward migration method is commonly
    referred to as “lift and shift” within the sector, but it only gets a portion
    of the cloud value you can get from managed PaaS/SaaS services.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Cloud-optimized applications
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, without making major code changes or redesigning, you can tap
    into the advantages of running your application in the cloud using contemporary
    technologies like containers and other cloud-managed services. This enhances your
    application’s flexibility, allowing for quicker releases by optimizing your business’s
    DevOps practices. This enhancement is made possible by tools like Windows containers,
    rooted in the Docker Engine. Containers address the challenges posed by application
    dependencies during multistage deployments. In this maturity framework, you have
    the option to deploy containers on either IaaS or PaaS, leveraging additional
    cloud-managed services such as database solutions, caching services, monitoring,
    and CI/CD workflows.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Cloud native applications
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: This migration approach typically is driven by business needs and targets modernizing
    your mission-critical applications. At this level, you use cloud services to move
    your apps to PaaS computing platforms. You implement cloud native applications
    and microservices architecture to evolve applications with long-term agility,
    and to scale to new limits. This type of modernization usually requires architecting
    specifically for the cloud, and even writing new code (or rewriting it), especially
    when you move to cloud native application and microservice-based models. This
    approach can help you gain benefits that are difficult to achieve in your monolithic
    and on-premises application environment.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这种迁移方法通常是由业务需求驱动的，目标是现代化您的关键任务应用程序。在这个层面，您使用云服务将您的应用程序迁移到PaaS计算平台。您实现云原生应用程序和微服务架构，以实现长期敏捷性和扩展到新的极限。这种类型的现代化通常需要专门针对云进行架构设计，甚至需要编写新代码（或重写代码），尤其是在您迁移到云原生应用程序和基于微服务的模型时。这种方法可以帮助您获得在单体和本地应用程序环境中难以实现的好处。
- en: The last level is the end goal for optimal generative AI–enabled applications,
    but any of these levels (especially the last two) would be “good enough” for any
    application to “connect” to Azure OpenAI Service. The rest of the chapter will
    focus on new cloud native applications, but if you plan to leverage Azure OpenAI
    Service for existing applications, please start by evaluating them and analyzing
    the next migration or modernization steps towards AI adoption.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一级是最佳生成AI启用应用程序的最终目标，但任何这些级别（尤其是最后两级）对于任何应用程序“连接”到Azure OpenAI服务来说都“足够好”。本章的其余部分将专注于新的云原生应用程序，但如果您计划利用Azure
    OpenAI服务为现有应用程序提供支持，请首先评估它们并分析向AI采用迈进的下一迁移或现代化步骤。
- en: Now, let’s focus on the key advantages of cloud native, and the key Azure-enabled
    building blocks that will allow you to build your Azure OpenAI solutions.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们关注云原生的主要优势以及关键的Azure启用构建块，这将使您能够构建您的Azure OpenAI解决方案。
- en: Cloud Native Development with Azure OpenAI Service
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Azure OpenAI服务的云原生开发
- en: 'Part of the idea behind cloud native architectures is to split code development
    into different pieces called microservices, so all modules communicate based on
    a functional flow, without being part of the same technical block. This has a
    series of advantages, not only for Azure OpenAI–enabled development, but any cloud
    native implementation. We can imagine several reasons to leverage a microservices
    architecture:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生架构背后的部分想法是将代码开发拆分为不同的部分，称为微服务，这样所有模块都基于功能流程进行通信，而不属于同一个技术块。这有一系列优势，不仅适用于Azure
    OpenAI启用的开发，也适用于任何云原生实现。我们可以想象出利用微服务架构的几个原因：
- en: Modular and granular AI functionality
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 模块化和细粒度的AI功能
- en: In AI applications, different tasks such as data preprocessing, feature extraction,
    model training, inference, and result visualization may be involved. By implementing
    each of these functionalities as separate microservices, the AI system becomes
    more modular and granular. This allows developers to focus on building and maintaining
    individual services, making it easier to understand, develop, test, and deploy
    specific AI components. This also allows reusability of components as there might
    be certain cleaning pipelines or even models that could be used for different
    applications within the same company. Last but not least, it supports team specialization
    depending on the task (e.g., model output processing tends to be an integration
    or data engineering task, while model implementation a data science one).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI应用程序中，可能涉及不同的任务，如数据预处理、特征提取、模型训练、推理和结果可视化。通过将这些功能作为独立的微服务实现，AI系统变得更加模块化和细粒度。这允许开发者专注于构建和维护单个服务，使其更容易理解、开发、测试和部署特定的AI组件。这也允许组件的可重用性，因为可能存在某些清理管道或甚至模型，可以在同一公司内的不同应用程序中使用。最后但同样重要的是，它支持根据任务进行团队专业化（例如，模型输出处理往往是一个集成或数据工程任务，而模型实现是一个数据科学任务）。
- en: Scalability and performance optimization
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性和性能优化
- en: AI workloads can vary in intensity, with some tasks requiring more computational
    resources than others. By breaking down an AI application into microservices,
    each service can be scaled independently based on its specific resource needs.
    This scalability ensures efficient resource utilization and improved performance.
    For example, model training and inference services can be scaled independently
    to handle varying workloads, providing better response times and overall system
    performance.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: AI工作负载的强度可能会有所不同，有些任务可能需要比其他任务更多的计算资源。通过将AI应用程序分解为微服务，每个服务可以根据其特定的资源需求独立扩展。这种可扩展性确保了高效的资源利用和性能提升。例如，模型训练和推理服务可以独立扩展以处理不同的工作负载，提供更好的响应时间和整体系统性能。
- en: AI algorithm lifecycle management
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: AI算法生命周期管理
- en: AI applications often require experimenting with different algorithms, models,
    or data sources to achieve the desired outcome. With microservices, developers
    can easily swap out or update individual AI services without affecting the rest
    of the system. This flexibility enables rapid prototyping, experimentation, and
    iteration with different AI approaches, facilitating the discovery of the most
    effective algorithms or models for specific tasks. Also, certain systems might
    run algorithms in parallel to obtain a better result by selecting the best answers
    of those algorithms.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: AI应用程序通常需要尝试不同的算法、模型或数据源以达到预期的结果。使用微服务，开发者可以轻松地替换或更新单个AI服务，而不会影响系统的其余部分。这种灵活性使得快速原型设计、实验和迭代不同的AI方法变得容易，从而有助于发现针对特定任务最有效的算法或模型。此外，某些系统可能会并行运行算法以通过选择这些算法的最佳答案来获得更好的结果。
- en: Integration with external services
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 与外部服务的集成
- en: Microservices architecture promotes loose coupling and well-defined APIs, making
    it easier to integrate AI services with external systems, tools, or services.
    This allows AI functionality to be leveraged across different applications, domains,
    or platforms. For instance, an AI service for NLP can be exposed via an API and
    utilized by multiple applications or integrated into a chatbot or customer support
    system.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构促进了松散耦合和定义良好的API，这使得将AI服务与外部系统、工具或服务集成变得更加容易。这允许AI功能在不同的应用程序、领域或平台上得到利用。例如，一个用于NLP的AI服务可以通过API公开，并由多个应用程序使用，或集成到聊天机器人或客户支持系统中。
- en: Now, if we think about generative AI–enabled applications with Azure OpenAI
    Service, the goal is to structure the end-to-end architecture in a way that makes
    sense and connects the “AI pieces” to both backend elements (code, cloud resources),
    and frontend interfaces (one or several, depending on the application), as you
    can see in [Figure 2-3](#fig_3_microservice_enabled_ai_development).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们考虑由Azure OpenAI Service启用的生成式AI应用程序，目标是结构化端到端架构，使其合理且将“AI组件”连接到后端元素（代码、云资源）和前端界面（一个或多个，取决于应用程序），正如您在[图2-3](#fig_3_microservice_enabled_ai_development)中看到的那样。
- en: '![](assets/aoas_0203.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0203.png)'
- en: Figure 2-3\. Microservice-enabled AI development
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-3\. 微服务支持的AI开发
- en: All the involved elements need to be interoperable, replaceable, and available.
    For that purpose, organizing the building blocks in microservices is key. The
    next two sections look at the containerization and serverless approaches. Let’s
    discuss their role as cloud native enablers.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 所有涉及到的元素都需要是互操作、可替换和可用的。为此，将构建块组织在微服务中是关键。接下来的两个部分将探讨容器化和无服务器方法。让我们讨论它们作为云原生使能者的作用。
- en: Microservice-Based Apps and Containers
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于微服务的应用程序和容器
- en: Cloud native development approaches leverage the power of the cloud, by choosing
    the right way to develop and to deploy applications. They rely on containerization,
    which often refers to Docker-type containers, and Kubernetes orchestration. As
    they are both based on international standards (e.g., the [Open Container Initiative
    [OCI]](https://oreil.ly/JKa4L)), cloud native applications are usually portable
    and scalable to different public and private cloud providers.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生开发方法通过选择合适的方式来开发和部署应用程序，利用了云的力量。它们依赖于容器化，通常指的是Docker类型的容器，以及Kubernetes编排。由于它们都基于国际标准（例如，[开放容器倡议（OCI）](https://oreil.ly/JKa4L)），云原生应用程序通常可以在不同的公共和私有云提供商之间进行移植和扩展。
- en: 'For Microsoft Azure, the key managed containerization services are [Azure Kubernetes
    Service (AKS)](https://oreil.ly/ymIkj) and [Azure Red Hat OpenShift (ARO)](https://oreil.ly/SXs9T).
    While both are managed Kubernetes services offered by Microsoft, there are some
    key differences:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Microsoft Azure 来说，关键的托管容器化服务是 [Azure Kubernetes 服务 (AKS)](https://oreil.ly/ymIkj)
    和 [Azure Red Hat OpenShift (ARO)](https://oreil.ly/SXs9T)。虽然两者都是微软提供的托管 Kubernetes
    服务，但它们之间有一些关键的区别：
- en: '[AKS](https://oreil.ly/YqfZ3)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[AKS](https://oreil.ly/YqfZ3)'
- en: A managed Kubernetes service provided by Microsoft Azure, utilizing native Kubernetes
    technology. It offers a fully managed Kubernetes cluster on Azure infrastructure
    and focuses on providing a streamlined and simplified Kubernetes experience on
    Azure. It provides essential Kubernetes features, including scaling, load balancing,
    and deployment management. AKS integrates well with other Azure services and provides
    native Azure resource management and monitoring capabilities. You can find pricing
    information [online](https://oreil.ly/OoChO).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Microsoft Azure 提供的托管 Kubernetes 服务，利用原生 Kubernetes 技术。它提供在 Azure 基础设施上的完全托管
    Kubernetes 集群，并专注于在 Azure 上提供简化和流畅的 Kubernetes 体验。它提供了基本的 Kubernetes 功能，包括扩展、负载均衡和部署管理。AKS
    与其他 Azure 服务集成良好，并提供了原生的 Azure 资源管理和监控功能。您可以在 [网上](https://oreil.ly/OoChO) 找到定价信息。
- en: '[ARO](https://oreil.ly/mM0MD)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[ARO](https://oreil.ly/mM0MD)'
- en: A joint offering between Microsoft and Red Hat, built on the [Red Hat OpenShift](https://oreil.ly/AftCs)
    Container Platform. ARO incorporates Kubernetes technology but provides additional
    features and integrations from the OpenShift platform. It provides a more comprehensive
    and enterprise-focused platform with additional security, compliance, and management
    capabilities.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 微软和红帽联合提供的产品，基于 [Red Hat OpenShift](https://oreil.ly/AftCs) 容器平台构建。ARO 集成了 Kubernetes
    技术，但提供了来自 OpenShift 平台的其他功能和集成。它提供了一个更全面且以企业为中心的平台，具有额外的安全、合规性和管理功能。
- en: In summary, they differ in terms of the underlying technology, vendor, and platform
    features. The choice between AKS and ARO depends on the specific requirements
    and preferences of your organization, such as the need for additional enterprise
    features and any existing investments or partnerships with Red Hat. Other related
    services you may want to explore are [Azure Container Apps](https://oreil.ly/QDzs2)
    and [Azure Arc for Kubernetes](https://oreil.ly/X5vd_) (for hybrid cloud scenarios).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，它们在底层技术、供应商和平台功能方面存在差异。AKS 和 ARO 之间的选择取决于您组织的具体需求和偏好，例如对额外企业功能的需求以及与红帽的现有投资或合作关系。您可能还想探索的其他相关服务包括
    [Azure 容器应用](https://oreil.ly/QDzs2) 和 [Azure Arc for Kubernetes](https://oreil.ly/X5vd_)（用于混合云场景）。
- en: Now that we have explored the containerization options in Azure, let’s understand
    the notion of serverless and its relevance for microservice-based implementations.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了 Azure 中的容器化选项，让我们了解无服务器概念及其在基于微服务实现中的相关性。
- en: Serverless Workflows
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无服务器工作流
- en: An alternative or complementary option is the serverless approach. Serverless
    computing is a cloud computing model that allows developers to build and run applications
    without the need to manage underlying infrastructure. It is particularly beneficial
    for AI workloads, including generative AI, as it provides a scalable and cost-effective
    solution.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种或补充的选项是无服务器方法。无服务器计算是一种云计算模型，允许开发者构建和运行应用程序，而无需管理底层基础设施。它对于人工智能工作负载，包括生成式人工智能特别有益，因为它提供了一个可扩展且成本效益高的解决方案。
- en: In serverless architecture, developers focus on writing code for specific functions
    or tasks, known as serverless functions, with [Azure Functions](https://oreil.ly/Gm-h9)
    being the native Microsoft option. These functions are executed in containers
    that are managed and scaled automatically by the cloud provider, as you can see
    in [Figure 2-4](#fig_4_managed_cloud_as_a_service_levels). This eliminates the
    need for developers to provision and manage servers, making it easier to deploy
    and maintain AI applications.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在无服务器架构中，开发者专注于编写特定功能或任务的代码，这些功能或任务被称为无服务器函数，[Azure Functions](https://oreil.ly/Gm-h9)
    是原生微软选项。这些函数在由云提供商自动管理和扩展的容器中执行，正如您在 [图 2-4](#fig_4_managed_cloud_as_a_service_levels)
    中所看到的。这消除了开发者配置和管理服务器的需求，使得部署和维护人工智能应用程序变得更加容易。
- en: '![](assets/aoas_0204.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0204.png)'
- en: Figure 2-4\. Managed cloud–as-a-service levels
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-4\. 管理云作为服务级别
- en: Much like other cloud native elements, one of the key advantages of serverless
    for AI workloads is scalability. Generative AI models often require significant
    computational resources, especially when training large models or generating complex
    outputs. Serverless platforms automatically scale resources on demand, allowing
    AI applications to handle fluctuations in workload without manual intervention.
    This scalability enables efficient resource utilization and cost optimization,
    as developers pay for only the actual compute resources used during execution.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他云原生元素类似，无服务器对于AI工作负载的关键优势之一是其可伸缩性。生成式AI模型通常需要大量的计算资源，尤其是在训练大型模型或生成复杂输出时。无服务器平台会自动根据需求扩展资源，允许AI应用程序在无需人工干预的情况下处理工作负载的波动。这种可伸缩性使得资源利用效率更高，成本优化更好，因为开发者只需为执行期间实际使用的计算资源付费。
- en: Another advantage of serverless computing is its event-driven nature. Serverless
    functions are triggered by specific events, such as HTTP requests or messages
    from message queues. This event-driven architecture is well-suited for AI workloads
    that require real-time or asynchronous processing. For example, generative AI
    applications can be triggered by user interactions or scheduled tasks, allowing
    them to generate outputs on demand or periodically. Additionally, serverless can
    be used to perform actions within a generative AI pipeline. For that purpose,
    [Azure Logic Apps](https://oreil.ly/Qvt6X) can be used to trigger orchestration
    and workflows, and it has integration with other Microsoft 365 and Azure services,
    which can be useful in triggering generative AI pipelines or events.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器计算的优势之一是其事件驱动的特性。无服务器函数由特定事件触发，例如HTTP请求或来自消息队列的消息。这种事件驱动架构非常适合需要实时或异步处理的AI工作负载。例如，生成式AI应用程序可以由用户交互或计划任务触发，允许它们按需或定期生成输出。此外，无服务器还可以用于在生成式AI管道中执行操作。为此，可以使用[Azure
    Logic Apps](https://oreil.ly/Qvt6X)来触发编排和工作流，并且它与Microsoft 365和Azure服务集成，这在触发生成式AI管道或事件时可能很有用。
- en: There are some limitations related to serverless platforms, such as execution
    time limits, memory constraints, and deployment package size limits. However,
    techniques like function composition, caching, and parallel execution can help
    improve the efficiency and responsiveness of generative AI applications running
    on serverless architectures. Fine-tuning resource allocation and optimizing data
    processing pipelines can also contribute to better overall performance.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 与无服务器平台相关的局限性包括执行时间限制、内存约束和部署包大小限制。然而，像函数组合、缓存和并行执行这样的技术可以帮助提高在无服务器架构上运行的生成式AI应用程序的效率和响应速度。微调资源分配和优化数据处理管道也有助于提高整体性能。
- en: In general terms, you will be combining a PaaS such as Azure OpenAI, plus containerized
    and/or serverless pieces, depending on your implementation approach. We will now
    explore the web development part of your applications, to get an initial idea
    of the services that Azure OpenAI leverages to deploy generative AI–enabled web-based
    applications.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从一般意义上讲，您将结合一个PaaS（平台即服务）如Azure OpenAI，以及根据您的实施方法，加上容器化和/或无服务器组件。现在，我们将探讨您应用程序的Web开发部分，以获得Azure
    OpenAI部署具有生成式AI功能的Web应用程序所利用的服务的一个初步概念。
- en: Azure-Based Web Development and CI/CD
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于 Azure 的 Web 开发和 CI/CD
- en: Now, let’s focus on development building blocks that go beyond core AI capabilities.
    As a cloud native practitioner, you will likely split your application code into
    several pieces. As you have already seen, those blocks are microservices that
    could contain backend and frontend modules (mobile applications, websites, intranets,
    etc.).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们关注那些超越核心AI能力的开发构建块。作为一名云原生实践者，您可能会将您的应用程序代码分成几个部分。正如您已经看到的，这些块是微服务，可能包含后端和前端模块（移动应用、网站、内网等）。
- en: The interesting part comes when you discover you can host web-based applications
    directly via Azure App Service. Azure App Service is a PaaS, a fully managed service
    that allows adopters to build, deploy, and scale web applications and APIs without
    the need to manage underlying infrastructure. It supports various programming
    languages and frameworks and enables web, mobile, and API app development, as
    well as workflows (Logic Apps), CI/CD, and monitoring, while offering simple integration
    with the whole Microsoft Azure suite.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的部分在于您会发现您可以直接通过Azure App Service托管基于Web的应用程序。Azure App Service是一个PaaS，一个完全托管的服务，允许采用者构建、部署和扩展Web应用程序和API，而无需管理底层基础设施。它支持各种编程语言和框架，并使Web、移动和API应用程序开发以及工作流（逻辑应用程序）、CI/CD和监控成为可能，同时提供与整个Microsoft
    Azure套件的简单集成。
- en: Overall, Azure App Service simplifies the process of building, deploying, and
    scaling web applications and APIs in the Azure cloud. It offers a robust and feature-rich
    platform that enables developers to focus on application development while benefiting
    from the scalability, availability, and management capabilities provided by the
    Azure platform.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，Azure App Service简化了在Azure云中构建、部署和扩展Web应用程序和API的过程。它提供了一个强大且功能丰富的平台，使开发者能够专注于应用程序开发，同时受益于Azure平台提供的可扩展性、可用性和管理能力。
- en: You will see in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure)
    how Azure OpenAI offers simple deployment options that leverage Azure App Service
    to create chat-based applications with preexisting templates.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在[第3章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中看到，Azure
    OpenAI提供了利用Azure App Service创建基于聊天应用程序的简单部署选项，这些应用程序具有预定义的模板。
- en: Note
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you want to dive deeper into any of these topics, please visit the following
    links:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想深入了解这些主题中的任何一个，请访问以下链接：
- en: 'Application hosting: [Azure App Service Overview | Microsoft Learn](https://oreil.ly/moBFz)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序托管：[Azure App Service概述 | Microsoft Learn](https://oreil.ly/moBFz)
- en: 'GitHub for CI/CD: [Deploy to App Service Using GitHub Actions | Microsoft Learn](https://oreil.ly/Z9EBe)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'GitHub for CI/CD: [使用GitHub Actions部署到App Service | Microsoft Learn](https://oreil.ly/Z9EBe)'
- en: 'YouTube video: [How to Deploy Your Web App Using GitHub Actions | Azure Portal
    Series](https://oreil.ly/dSe0R)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YouTube视频：[如何使用GitHub Actions部署您的Web应用程序 | Azure门户系列](https://oreil.ly/dSe0R)
- en: We will now cover the fundamentals of the Azure portal, mostly for readers with
    no or low Azure experience, as a way to help you understand how to search, configure,
    and deploy Azure OpenAI and other related services. If you have already worked
    with Azure and its portal, you may skip this section.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将介绍Azure门户的基础知识，主要面向没有或很少使用Azure的读者，作为帮助您了解如何搜索、配置和部署Azure OpenAI和其他相关服务的一种方式。如果您已经使用过Azure及其门户，您可以跳过这一部分。
- en: Understanding the Azure Portal
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Azure门户
- en: The Azure portal is a web-based UI provided by Microsoft Azure that allows users
    to manage and interact with their Azure resources. It serves as a central hub
    for accessing and managing various Azure services and functionalities, including
    Azure OpenAI Service. The portal provides a visually appealing and intuitive interface
    that simplifies the management and monitoring of Azure resources ([Figure 2-5](#fig_5_azure_portal_main_interface)).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Azure门户是Microsoft Azure提供的一个基于Web的UI，允许用户管理和交互他们的Azure资源。它作为访问和管理各种Azure服务和功能的中心枢纽，包括Azure
    OpenAI服务。门户提供了一个视觉上吸引人且直观的界面，简化了Azure资源的管理和监控（[图2-5](#fig_5_azure_portal_main_interface)）。
- en: '![](assets/aoas_0205.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0205.png)'
- en: 'Figure 2-5\. Azure portal: main interface'
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-5\. Azure门户：主界面
- en: As you can see in [Figure 2-5](#fig_5_azure_portal_main_interface), it includes
    a customizable dashboard that provides an overview of your Azure resources, recent
    activities, and personalized tiles for quick access to frequently used services.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在[图2-5](#fig_5_azure_portal_main_interface)中看到的，它包括一个可定制的仪表板，提供了您Azure资源的概览、最近的活动以及用于快速访问常用服务的个性化瓷砖。
- en: The navigation pane on the left side of the portal allows you to access different
    categories of Azure services, including Compute, Storage, Networking, Security
    + Identity, AI + Machine Learning, and more. You can see the sequence in [Figure 2-6](#fig_6_azure_portal_left_panel).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 门户左侧的导航面板允许您访问不同的Azure服务类别，包括计算、存储、网络、安全 + 身份、AI + 机器学习等。您可以在[图2-6](#fig_6_azure_portal_left_panel)中看到顺序。
- en: '![](assets/aoas_0206.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0206.png)'
- en: 'Figure 2-6\. Azure portal: left panel'
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-6\. Azure门户：左侧面板
- en: Also, clicking on a specific category expands a menu with subcategories and
    services within that category. You can actually find Azure OpenAI Service within
    the AI + Machine Learning category ([Figure 2-7](#fig_7_azure_portal_resources_azure_openai_example)).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，点击特定类别可以展开一个包含该类别子类别和服务的菜单。您实际上可以在 AI + 机器学习类别中找到 Azure OpenAI 服务（[图 2-7](#fig_7_azure_portal_resources_azure_openai_example)）。
- en: '![](assets/aoas_0207.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0207.png)'
- en: 'Figure 2-7\. Azure portal: resources (Azure OpenAI Service example)'
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-7\. Azure 门户：资源（Azure OpenAI 服务示例）
- en: Alternatively, the Azure portal offers a search bar at the top, allowing you
    to quickly find services, resources, or documentation. As you can see in [Figure 2-8](#fig_8_azure_portal_search_azure_openai_example),
    you can search by keywords or use the natural language query to locate specific
    functionalities or resources within Azure. Basically, you can find Azure OpenAI
    by just typing it there.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，Azure 门户在顶部提供了一个搜索栏，允许您快速查找服务、资源或文档。如图 2-8 所示，您可以通过关键词搜索或使用自然语言查询在 Azure
    中定位特定的功能或资源。基本上，您只需在搜索栏中键入即可找到 Azure OpenAI。
- en: '![](assets/aoas_0208.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0208.png)'
- en: 'Figure 2-8\. Azure portal: search (Azure OpenAI Service example)'
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-8\. Azure 门户：搜索（Azure OpenAI 服务示例）
- en: Each Azure service has its own dedicated blade, which is essentially a panel
    that provides detailed information and management options for that service. If
    you choose Azure OpenAI from either the search engine or the left panel, you will
    enter your resource details ([Figure 2-9](#fig_9_azure_portal_resource_details_azure_openai_examp)).
    Basically, you are able to create new resources for Azure OpenAI, or manage those
    previously deployed. If you choose Create, you can see the required information
    to deploy a new Azure OpenAI Service.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 Azure 服务都有自己的专用面板，这本质上是一个提供该服务详细信息和管理选项的面板。如果您从搜索引擎或左侧面板中选择 Azure OpenAI，您将进入您的资源详情（[图
    2-9](#fig_9_azure_portal_resource_details_azure_openai_examp)）。基本上，您可以为 Azure
    OpenAI 创建新的资源，或管理之前部署的资源。如果您选择创建，您可以看到部署新的 Azure OpenAI 服务所需的信息。
- en: '![](assets/aoas_0209.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0209.png)'
- en: 'Figure 2-9\. Azure portal: resource details (Azure OpenAI Service example)'
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-9\. Azure 门户：资源详情（Azure OpenAI 服务示例）
- en: You can find details related to your subscription, geographic region preferences,
    the unique name chosen for your Azure resource, and the pricing tier. (Tiers are
    the level of pricing based on estimated usage; for now there is only one option
    for Azure OpenAI, called “Standard S0.” Any update should be available via the
    [official pricing page](https://oreil.ly/7Gmq6), and the [Azure calculator](https://oreil.ly/2SQ4C).)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以找到与您的订阅、地理位置偏好、为您的 Azure 资源选择的唯一名称以及定价层相关的详细信息。（层是根据估计的使用量来划分的定价级别；目前 Azure
    OpenAI 只有一个选项，称为“标准 S0”。任何更新都应通过[官方定价页面](https://oreil.ly/7Gmq6)和[Azure 计算器](https://oreil.ly/2SQ4C)提供。）
- en: In addition to managing individual resources, the Azure portal allows you to
    create [resource groups](https://oreil.ly/J2LMM) to logically organize and manage
    related resources together. This is an interesting feature, and a recommended
    best practice to group the required resources for your generative AI implementations
    with Azure, including Azure OpenAI Service and others we will need for our projects.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 除了管理个人资源外，Azure 门户还允许您创建[资源组](https://oreil.ly/J2LMM)以逻辑上组织和管理相关资源。这是一个有趣的功能，也是将您为
    Azure 生成式 AI 实现所需的资源（包括 Azure OpenAI 服务以及其他我们项目所需的服务）分组的一个推荐的最佳实践。
- en: Note
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you haven’t created an Azure account before, the first step is to [create
    a free one](https://oreil.ly/WVIm2). It usually includes credits with a value
    of USD $200 for initial experimentation. It requires a corporate email for the
    specific account and payment information.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您之前还没有创建 Azure 账户，第一步是[创建一个免费的账户](https://oreil.ly/WVIm2)。通常包括价值 200 美元的信用额度，用于初始实验。它需要一个特定账户的商务电子邮件和支付信息。
- en: 'We will explore the details of generative AI implementation approaches with
    Microsoft Azure in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure),
    but the idea behind the Azure portal is to facilitate the deployment, management,
    and maintenance process of the different resources required to create these architectures,
    regardless of the type of service. Deploying any Azure services from the Azure
    portal involves several steps, so remember the high-level process:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第 3 章 [实现 Azure 上的云原生生成式 AI](ch03.html#implementing_cloud_native_generative_ai_with_azure)
    中探讨生成式 AI 实现方法的细节，但 Azure 门户背后的理念是简化创建这些架构所需的不同资源的部署、管理和维护过程，无论服务类型如何。从 Azure
    门户部署任何 Azure 服务都涉及多个步骤，所以请记住以下高级流程：
- en: 1\. Sign in to the Azure portal.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 在 Azure 门户中登录。
- en: Open a web browser, navigate to the Azure portal, and sign up with your Azure
    account credentials.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 打开网页浏览器，导航到 Azure 门户，并使用您的 Azure 账户凭据进行注册。
- en: 2\. Create a resource.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 创建资源。
- en: To deploy an Azure service, you need to create a resource. A resource represents
    a service or component in Azure, such as a virtual machine, a storage account,
    or a database. Click on the “Create a resource” button in the Azure portal.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署 Azure 服务，您需要创建资源。资源代表 Azure 中的服务或组件，例如虚拟机、存储账户或数据库。在 Azure 门户中点击“创建资源”按钮。
- en: 3\. Select a service.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 选择服务。
- en: In the resource creation wizard, you’ll see a list of available Azure services.
    Choose the service you want to deploy by browsing through the categories or using
    the search bar.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在资源创建向导中，您将看到可用的 Azure 服务列表。通过浏览类别或使用搜索栏选择您想要部署的服务。
- en: 4\. Configure the resource.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 配置资源。
- en: Once you’ve selected a service, you’ll be taken to a configuration page where
    you can specify the settings for the resource. The options available depend on
    the specific service you’re deploying. Fill in the required information, such
    as resource name, region, pricing tier, and any other relevant settings.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 选择服务后，您将被带到配置页面，您可以在此指定资源的设置。可用的选项取决于您要部署的具体服务。填写所需信息，例如资源名称、区域、定价层以及其他相关设置。
- en: 5\. Review and create.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 5. 查看并创建。
- en: After configuring the resource, review the settings to ensure they are correct.
    You can also enable additional features or add-ons if available. Once you’re satisfied,
    click the “Review + Create” button.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 配置资源后，请查看设置以确保它们正确。如果可用，您还可以启用其他功能或附加组件。满意后，请点击“查看 + 创建”按钮。
- en: 6\. Validation and deployment.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 6. 验证和部署。
- en: Azure will validate the configuration settings and check for any potential issues.
    If everything is in order, click the “Create” button to initiate the deployment
    process.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 将验证配置设置并检查任何潜在问题。如果一切正常，请点击“创建”按钮以启动部署过程。
- en: 7\. Monitor the deployment.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 7. 监控部署。
- en: Azure will start provisioning the resources based on your configuration. You
    can monitor the deployment progress in the Azure portal. Depending on the service,
    the deployment may take a few minutes to complete.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 将根据您的配置开始预配资源。您可以在 Azure 门户中监控部署进度。根据服务类型，部署可能需要几分钟才能完成。
- en: 8\. Access and manage the deployed service.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 8. 访问和管理已部署的服务。
- en: Once the deployment is finished, you can access and manage the deployed service
    through the Azure portal. You can view its properties, make changes to its configuration,
    monitor its performance, and perform other administrative tasks as needed.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 部署完成后，您可以通过 Azure 门户访问和管理已部署的服务。您可以查看其属性、更改其配置、监控其性能，并根据需要执行其他管理任务。
- en: This is the process for most of the Azure resources, but there are other deployment
    methods such as [Azure Resource Manager templates](https://oreil.ly/TZXTy), [API-enabled
    resource orchestration](https://oreil.ly/jezRs), [Azure Bicep](https://oreil.ly/aZOxZ),
    [Terraform on Azure](https://oreil.ly/Wi9xy), or command-line tools such as [Azure
    CLI](https://oreil.ly/Mm4N1) or [Azure PowerShell](https://oreil.ly/22BEd), all
    of them for more advanced admin/technical users. Feel free to explore them if
    you want to learn more.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对大多数 Azure 资源的过程，但还有其他部署方法，例如 [Azure 资源管理器模板](https://oreil.ly/TZXTy)、[API
    启用资源编排](https://oreil.ly/jezRs)、[Azure Bicep](https://oreil.ly/aZOxZ)、[Azure 上的
    Terraform](https://oreil.ly/Wi9xy) 或命令行工具，如 [Azure CLI](https://oreil.ly/Mm4N1)
    或 [Azure PowerShell](https://oreil.ly/22BEd)，所有这些工具都是为更高级的行政/技术用户设计的。如果您想了解更多，请随时探索。
- en: For Azure OpenAI Service, you can always visit the [official resource deployment
    guide](https://oreil.ly/hSPh3), which summarizes the steps we just walked through.
    Other information you may want to review before deploying the service includes
    the [main product page](https://oreil.ly/MDBhf), the previously mentioned [pricing
    guide](https://oreil.ly/7Gmq6), the service [availability by geographic region](https://oreil.ly/tYnCe)
    (for example, if you deploy the service from the European Union, you may want
    to use a closer region, such as West Europe in Amsterdam, for better latency,
    performance, and maybe pricing), and the [general documentation](https://oreil.ly/3oNQU).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Azure OpenAI服务，您始终可以访问[官方资源部署指南](https://oreil.ly/hSPh3)，其中总结了我们刚刚走过的步骤。在部署服务之前，您可能还想查看的其他信息包括[主要产品页面](https://oreil.ly/MDBhf)、之前提到的[定价指南](https://oreil.ly/7Gmq6)、服务[按地理区域可用性](https://oreil.ly/tYnCe)（例如，如果您从欧盟部署服务，您可能希望使用更近的区域，例如阿姆斯特丹的西欧，以获得更好的延迟、性能，也许还有定价），以及[一般文档](https://oreil.ly/3oNQU)。
- en: Now that you know how to use the Azure portal, and the key information about
    the Azure OpenAI Service deployment process, let’s analyze some important considerations
    at the model and general architecture levels. This will be key to creating the
    end-to-end implementations we will see in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了如何使用Azure门户，以及Azure OpenAI服务部署过程的关键信息，让我们分析一些在模型和一般架构层面的重要考虑因素。这将是我们在[第3章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中看到的端到端实现的关键。
- en: General Azure OpenAI Service Considerations
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure OpenAI服务的一般注意事项
- en: Now that we have explored the notion of cloud native development with Azure,
    and the fundamentals of the Azure portal for Azure OpenAI Service, let’s go deeper
    into the different AI models that are available and the high-level architectures
    so you can know how to make sense of the Azure-enabled generative AI offerings.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了使用Azure进行云原生开发的理念，以及Azure OpenAI服务的Azure门户基础，让我们更深入地了解可用的不同AI模型和高级架构，这样您就可以了解如何理解Azure启用的生成式AI产品。
- en: Available Azure OpenAI Service Models
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可用的Azure OpenAI服务模型
- en: Most cloud-enabled PaaS resources from any public cloud, including those from
    Microsoft Azure, leverage native endpoints and APIs as a way to connect and to
    consume their models. This is the case for Azure OpenAI Service and the rest of
    the Azure AI Services we have seen in this chapter.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 任何公共云（包括微软Azure）的大多数云启用PaaS资源都利用本地端点和API作为连接和消费其模型的方式。这对于Azure OpenAI服务以及我们在本章中看到的其余Azure
    AI服务也是如此。
- en: Also, there are visual elements such as [Azure AI Studio](https://oreil.ly/PCMD3)
    and [Azure ML Studio](https://oreil.ly/kdZhY) (not to be confused with [Azure
    OpenAI Studio](https://oreil.ly/LWQO1), which we will explain and leverage in
    [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure)) that
    provide access to different proprietary and open source AI/foundation models.
    This includes a model catalog to leverage the curated selection of models, including
    those from Azure OpenAI, Meta, and Hugging Face (e.g., the [Hugging Face Hub in
    Azure](https://oreil.ly/96mAx), announced by both Microsoft and Hugging Face during
    Microsoft Build 2023). This also allows us to test and deploy those models in
    a very simple way.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一些视觉元素，如[Azure AI Studio](https://oreil.ly/PCMD3)和[Azure ML Studio](https://oreil.ly/kdZhY)（不要与[Azure
    OpenAI Studio](https://oreil.ly/LWQO1)混淆，我们将在[第3章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中解释并利用它），它们提供了访问不同专有和开源AI/基础模型的方式。这包括一个模型目录，可以利用经过精选的模型选择，包括来自Azure
    OpenAI、Meta和Hugging Face的模型（例如，由微软和Hugging Face在Microsoft Build 2023期间宣布的[Azure中的Hugging
    Face Hub](https://oreil.ly/96mAx)）。这也允许我们以非常简单的方式测试和部署这些模型。
- en: As you can see in [Figure 2-10](#fig_10_azure_ai_studio_main_interface), if
    you visit the [Studio page](https://oreil.ly/kdZhY), you will get access to your
    existing workspaces, or you will be able to create a new one if it is your first
    time connecting to the studio.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在[图2-10](#fig_10_azure_ai_studio_main_interface)中看到的，如果您访问[工作室页面](https://oreil.ly/kdZhY)，您将能够访问您现有的工作空间，或者如果您是第一次连接到工作室，您将能够创建一个新的工作空间。
- en: '![](assets/aoas_0210.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0210.png)'
- en: 'Figure 2-10\. Azure AI Studio: main interface'
  id: totrans-134
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-10\. Azure AI Studio：主界面
- en: 'If you access the workspace, you will see the same kind of visual interface
    we reviewed earlier in this chapter. In [Figure 2-11](#fig_11_azure_ai_studio_left_panel),
    the left panel for the workspace menu offers all options related to data, models,
    endpoints, required resources, etc. For the sake of simplicity, we will focus
    on two main features: the [model catalog](https://oreil.ly/BYkuc), and later in
    [Chapter 4](ch04.html#additional_cloud_and_ai_capabilities), the prompt flow functionality.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你访问工作区，你会看到我们在本章前面审查过的相同类型的可视化界面。在 [图 2-11](#fig_11_azure_ai_studio_left_panel)
    中，工作区菜单的左侧面板提供了与数据、模型、端点、所需资源等相关的一切选项。为了简化，我们将关注两个主要功能：[模型目录](https://oreil.ly/BYkuc)，以及在
    [第 4 章](ch04.html#additional_cloud_and_ai_capabilities) 中稍后讨论的提示流功能。
- en: '![](assets/aoas_0211.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0211.png)'
- en: 'Figure 2-11\. Azure AI Studio: left panel'
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-11\. Azure AI Studio：左侧面板
- en: If you choose the model catalog option and search “Azure OpenAI” or click directly
    on the tile as shown in [Figure 2-12](#fig_12_azure_ai_studio_model_catalog),
    you will get access to the updated list of available Azure OpenAI models.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你选择模型目录选项并搜索“Azure OpenAI”或直接点击如图 [图 2-12](#fig_12_azure_ai_studio_model_catalog)
    所示的磁贴，你将能够访问可用的 Azure OpenAI 模型更新列表。
- en: '![](assets/aoas_0212.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0212.png)'
- en: 'Figure 2-12\. Azure AI Studio: model catalog'
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-12\. Azure AI Studio：模型目录
- en: The models in [Figure 2-13](#fig_13_azure_ai_studio_azure_openai_models) are
    those available at the time of writing, but depending on when you check the catalog,
    you will likely find these and/or others. An alternative way to check all the
    available models at the moment is to use the [List API](https://oreil.ly/bk7Zd).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-13](#fig_13_azure_ai_studio_azure_openai_models) 中的模型是撰写本文时的可用模型，但根据你检查目录的时间，你可能会发现这些和/或其他的模型。检查当前所有可用模型的一种替代方法是使用
    [List API](https://oreil.ly/bk7Zd)。'
- en: '![](assets/aoas_0213.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0213.png)'
- en: 'Figure 2-13\. Azure AI Studio: Azure OpenAI Service models'
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-13\. Azure AI Studio：Azure OpenAI 服务模型
- en: Now, keeping in mind the evolving nature of the availability of Azure OpenAI
    models, explore the key model families and some examples of specific models that
    you will leverage for your generative AI projects. This will certainly change
    over time, but it is a good beginning.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑到 Azure OpenAI 模型可用性的演变性质，探索关键模型系列和一些特定模型示例，这些模型将用于你的生成式 AI 项目。这肯定会随着时间的推移而变化，但这是一个良好的开始。
- en: 'Azure OpenAI Service splits its capabilities into different *model families*.
    A model family typically associates AI models by their intended task, such as
    natural language understanding, code generation, or image synthesis. Some of the
    most popular Azure OpenAI model families are as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: Azure OpenAI 服务将其功能分为不同的 *模型系列*。一个模型系列通常根据其预期任务将 AI 模型关联起来，例如自然语言理解、代码生成或图像合成。以下是一些最受欢迎的
    Azure OpenAI 模型系列：
- en: Language-related models
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 语言相关模型
- en: 'Popular language-related models include the following:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 流行的语言相关模型包括以下：
- en: GPT-3.5 Turbo and GPT-3.5 Turbo Instruct
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5 Turbo 和 GPT-3.5 Turbo Instruct
- en: Models that improve on previous GPT-3 versions and can understand and generate
    natural language and code. There are several versions with different context length
    limits, including those for 4K and 16K tokens, which is the measure of the maximum
    text input.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 改进先前 GPT-3 版本的模型，能够理解和生成自然语言和代码。有几个版本具有不同的上下文长度限制，包括 4K 和 16K 令牌，这是最大文本输入的度量。
- en: GPT-4, GPT-4 Turbo, GPT-4o
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4，GPT-4 Turbo，GPT-4o
- en: Models with better performance (and higher cost) than 3.5 Turbo, which can handle
    more complex tasks and generate more accurate and diverse outputs. They can also
    handle bigger text inputs (which we usually define as “context”) than their predecessors.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 性能更好（且成本更高）的模型，比 3.5 Turbo 能够处理更复杂的任务，并生成更准确和多样化的输出。它们还可以处理比前辈更大的文本输入（我们通常将其定义为“上下文”）。
- en: Speech
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 语音
- en: There are other options in Azure, but Azure AI Studio includes the speech-to-text
    [Whisper model](https://oreil.ly/9si-P) from OpenAI (i.e., by typing “whisper”
    and selecting the model). It is not directly available from Azure OpenAI Studio,
    but it can be integrated with the rest of GPT models to create voice-to-text scenarios.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 中还有其他选项，但 Azure AI Studio 包含了来自 OpenAI 的语音转文本 [Whisper 模型](https://oreil.ly/9si-P)（即通过输入“whisper”并选择模型）。它不是直接从
    Azure OpenAI Studio 可用的，但它可以与其他 GPT 模型集成，以创建语音转文本场景。
- en: Other models
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 其他模型
- en: 'Other popular models include the following:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 其他流行的模型包括以下：
- en: Codex for programming code
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Codex 用于编程代码
- en: A series of models that can understand and generate code, including translating
    natural language to code. The reality is that Codex was initially a separate model,
    but after some time OpenAI added its capabilities to the regular GPT-3.5 Turbo
    and GPT-4 language models. This means the same models handle both natural language
    and programming code.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 一系列可以理解和生成代码的模型，包括将自然语言转换为代码。现实情况是，Codex最初是一个独立的模型，但经过一段时间后，OpenAI将其功能添加到了常规的GPT-3.5
    Turbo和GPT-4语言模型中。这意味着相同的模型可以处理自然语言和编程代码。
- en: DALL·E for images
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: DALL·E for images
- en: A series of models that can generate original images from natural language.
    This is the model behind tools like [Bing Create](https://oreil.ly/YwDy-) and
    [Microsoft Designer](https://oreil.ly/oIRon), and it is directly available from
    Azure OpenAI Studio, as we will see in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 一系列可以从自然语言生成原始图像的模型。这是[Bing Create](https://oreil.ly/YwDy-)和[Microsoft Designer](https://oreil.ly/oIRon)等工具背后的模型，并且它直接从Azure
    OpenAI Studio提供，正如我们将在[第3章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中看到的。
- en: It is important to differentiate the different model families and their specific
    capabilities to understand which ones we will use for our generative AI projects.
    Also, the trade-off of different Azure OpenAI models depends on the use case and
    the available budget. Generally speaking, more capable models like GPT-4o can
    handle more complex tasks and generate more accurate and diverse outputs, but
    they also consume more resources and incur higher costs. We will explore several
    scenarios in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure)
    that can work with all these GPT models. You can also explore the whole set of
    OpenAI models, including some deprecated ones that are still [traced via OpenAI’s
    documentation](https://oreil.ly/SG-fe).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要区分不同的模型家族及其具体功能，以便了解我们将为我们的生成式AI项目使用哪些模型。此外，不同Azure OpenAI模型的权衡取决于用例和可用预算。一般来说，更强大的模型如GPT-4o可以处理更复杂的任务，并生成更准确和多样化的输出，但它们也消耗更多资源并产生更高的成本。我们将在[第3章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中探讨几个可以与所有这些GPT模型协同工作的场景。您还可以探索整个OpenAI模型集，包括一些已弃用的模型，这些模型仍然可以通过OpenAI的文档[追踪](https://oreil.ly/SG-fe)。
- en: Besides all these functionalities, one of the key features for LLM-enabled systems
    is *embeddings*. This is a general term related to NLP and LLMs. Embeddings are
    a way of representing data in a multidimensional space. They are often used to
    capture the semantic meaning of words, images, or other types of data. For example,
    in [Figure 2-14](#fig_14_embedding_model), an embedding model can map a word to
    a vector of numbers, such that words with similar meanings have similar vectors.
    This means we can connect pieces of information that are not directly connected,
    but that may have a mathematical or linguistic connection (e.g., several knowledge
    bases from companies of the same sector, internal and external sources, etc.).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 除了所有这些功能之外，对于启用LLM的系统来说，一个关键特性是*嵌入*。这是一个与NLP和LLM相关的一般术语。嵌入是在多维空间中表示数据的一种方式。它们通常用于捕捉单词、图像或其他类型数据的语义意义。例如，在[图2-14](#fig_14_embedding_model)中，嵌入模型可以将一个单词映射到一个数字向量，使得具有相似意义的单词具有相似的向量。这意味着我们可以连接那些没有直接连接但可能存在数学或语言联系的信息片段（例如，来自同一行业公司的多个知识库、内部和外部来源等）。
- en: '![](assets/aoas_0214.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![AOAS_0214](assets/aoas_0214.png)'
- en: Figure 2-14\. Embedding model
  id: totrans-163
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-14\. 嵌入模型
- en: 'This example illustrates the typical *generation and search process*:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例说明了典型的*生成和搜索过程*：
- en: We collect different data inputs (PDFs, text files, URLs, etc.) to create our
    knowledge base. This is a simplified view as sources are previously processed
    to extract the text-based information. We will see options for this such as official
    accelerators and Azure AI Document Intelligence in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure).
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们收集不同的数据输入（PDF文件、文本文件、URL等）来创建我们的知识库。这是一个简化的视图，因为来源已经被预先处理以提取基于文本的信息。我们将在[第3章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中看到此类选项，例如官方加速器和Azure
    AI文档智能。
- en: We leverage the [Embeddings API](https://oreil.ly/bhgTY) to generate the embeddings
    from diverse sources. We can use a basic API call with the text input that returns
    the generated vectors.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们利用[嵌入API](https://oreil.ly/bhgTY)从不同的来源生成嵌入。我们可以使用带有文本输入的基本API调用，它返回生成的向量。
- en: The generated vectors/embeddings are stored in a vector database. We will explore
    several database options in Azure in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure).
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成的向量/嵌入存储在向量数据库中。我们将在[第3章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中探讨Azure中的几个数据库选项。
- en: 'After the generation process, we can assume end users will want to search for
    specific topics or information that will be included as part of the different
    data inputs we have collected and vectorized. For that purpose, we will use the
    same embeddings API to generate the embeddings of the questions itself (note:
    we need the same embedding model for both knowledge and questions).'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在生成过程之后，我们可以假设最终用户将想要搜索特定主题或信息，这些主题或信息将作为我们收集和向量化的不同数据输入的一部分。为此，我们将使用相同的嵌入API来生成问题的嵌入（注意：我们需要相同的嵌入模型来处理知识和问题）。
- en: The vector database will support search functions. This means we will use the
    vectorized user questions as input to find information from the vector database
    that contains our knowledge base.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向量数据库将支持搜索功能。这意味着我们将使用向量化的用户问题作为输入，从包含我们的知识库的向量数据库中查找信息。
- en: If there are related topics, the search function will return a Top-k variety
    of results that we can use to generate the answer (either by directly printing
    the results or by passing them as input for a chat-based scenario).
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果有相关主题，搜索功能将返回Top-k种类的结果，我们可以使用这些结果来生成答案（无论是直接打印结果还是将它们作为基于聊天的场景的输入）。
- en: 'The embeddings use cases available in Azure OpenAI Service are as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Azure OpenAI服务中可用的嵌入用例如下：
- en: Text similarity
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 文本相似度
- en: A set of models that provide embeddings that capture the semantic similarity
    of pieces of text. These models are useful for many tasks such as clustering,
    regression, anomaly detection, and visualization.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一组提供嵌入（embeddings）的模型，这些嵌入能够捕捉文本片段的语义相似性。这些模型在许多任务中非常有用，例如聚类、回归、异常检测和可视化。
- en: Text search
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 文本搜索
- en: A set of models that provide embeddings that enable semantic information retrieval
    over documents. These models are useful for tasks such as search, context relevance,
    and information retrieval.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 一组提供嵌入的模型，这些嵌入能够对文档进行语义信息检索。这些模型在搜索、上下文相关性和信息检索等任务中非常有用。
- en: Code search
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 代码搜索
- en: A set of models that provide embeddings that enable finding relevant code with
    a query in natural language. These models are useful for tasks such as code search
    and relevance.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一组提供嵌入的模型，这些嵌入能够通过自然语言查询找到相关的代码。这些模型在代码搜索和相关性等任务中非常有用。
- en: At a technical level, the recommended model option for embeddings with Azure
    OpenAI Service is called “Ada”; this is an [improved and more cost-effective](https://oreil.ly/6m7SL)
    model than its predecessors. This is pretty useful to increase the knowledge scope
    of Azure OpenAI, by consuming information from PDFs, websites, text files, etc.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术层面上，使用Azure OpenAI服务进行嵌入推荐的选择是“Ada”；这是一个比其前辈更改进且成本效益更高的[模型](https://oreil.ly/6m7SL)。这对于通过消耗来自PDF、网站、文本文件等信息来增加Azure
    OpenAI的知识范围非常有用。
- en: 'As previously mentioned, embeddings generation is based on a very simple API
    call/response dynamic, and the specific details on how to generate embeddings
    for a given source are available in [the official documentation](https://oreil.ly/2cxWx),
    as well as the specific [context length limits](https://oreil.ly/SQSGw) (e.g.,
    8K tokens for Ada version 2). Generating embeddings is as simple as calling the
    embedding API with the desired text input you want to vectorize. For example,
    in Python:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，嵌入生成基于一个非常简单的API调用/响应动态，特定源如何生成嵌入的详细信息可以在[官方文档](https://oreil.ly/2cxWx)中找到，以及具体的[上下文长度限制](https://oreil.ly/SQSGw)（例如，Ada版本2的8K个令牌）。生成嵌入就像调用嵌入API并使用您想要向量化的所需文本输入一样简单。例如，在Python中：
- en: '[PRE0]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output of this would be a numerical representation, where each number in
    the list corresponds to a dimension in the embedding space. The exact values will
    depend on the specific model and its training data, but it could look like this:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出一个数值表示，列表中的每个数字对应于嵌入空间中的一个维度。确切值将取决于特定模型及其训练数据，但可能看起来像这样：
- en: '[PRE1]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We have completed the review of Azure OpenAI models and their capabilities.
    While we will cover the details of project examples and architectures in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure),
    the next section will explore general architectural building blocks for Azure
    OpenAI–enabled implementations, as well as general cloud infrastructure topics.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了对 Azure OpenAI 模型和其功能的审查。虽然我们将涵盖项目示例和架构的细节[第 3 章](ch03.html#implementing_cloud_native_generative_ai_with_azure)，但下一节将探讨
    Azure OpenAI 启用实现的一般架构构建块，以及一般云基础设施话题。
- en: Architectural Elements of Generative AI Systems
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成式人工智能系统的架构元素
- en: Azure-based architectures rely on a series of interconnected services that can
    communicate with each other for a specific purpose. In this case, Azure OpenAI
    plays a crucial role to enable interactions between any customer-side application,
    but we rely on more building blocks to build our generative AI solutions. In [Figure 2-15](#fig_15_high_level_architecture_building_blocks),
    you can see the main building blocks of an Azure OpenAI–enabled (simplified) architecture.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 Azure 的架构依赖于一系列相互连接的服务，这些服务可以为了特定目的相互通信。在这种情况下，Azure OpenAI 在使任何客户端应用程序之间进行交互方面发挥着关键作用，但我们依赖于更多构建块来构建我们的生成式人工智能解决方案。在[图
    2-15](#fig_15_high_level_architecture_building_blocks)中，你可以看到 Azure OpenAI 启用（简化）架构的主要构建块。
- en: '![](assets/aoas_0215.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0215.png)'
- en: Figure 2-15\. High-level architecture building blocks
  id: totrans-187
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-15\. 高级架构构建块
- en: 'Let’s take a look at these pieces in a little more detail:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看这些部分：
- en: Application frontend
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 应用前端
- en: Any app-side element that leverages generative AI capabilities.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 任何利用生成式人工智能能力的应用端元素。
- en: Middleware/orchestration
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 中间件/协调
- en: We will explore this element in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure),
    but the orchestration piece basically allows us to connect different Azure OpenAI
    skills with other relevant services. Also, the middleware can include API management
    and other topics that we will see in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第 3 章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中探讨这个元素，但协调部分基本上允许我们将不同的
    Azure OpenAI 技能与其他相关服务连接起来。此外，中间件还可以包括 API 管理和其他我们将在[第 3 章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中看到的话题。
- en: Azure OpenAI Service
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Azure OpenAI 服务
- en: For text-based skills, such as explaining the answer to a complex question,
    for both completion and chat-based scenarios.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于文本的技能，例如解释复杂问题的答案，无论是完成还是基于聊天的场景。
- en: Additional knowledge base
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的知识库
- en: This is a combination of the core data sources (databases, blob storage, etc.)
    and knowledge extraction elements such as embeddings, Azure Cognitive Search,
    Bing Search, etc. For now, we will define them as “grounding blocks,” but we will
    see the details in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这是由核心数据源（数据库、blob 存储等）和知识提取元素（如嵌入、Azure 认知搜索、必应搜索等）的组合。目前，我们将它们定义为“基础块”，但我们将看到[第
    3 章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中的详细内容。
- en: If you develop an application that leverages Azure OpenAI and other Azure services,
    and that implementation is part of a bigger data/AI-enabled platform, the end-to-end
    architecture might start to look something like [Figure 2-16](#fig_16_end_to_end_azure_platform_including_azure_openai).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你开发的应用程序利用了 Azure OpenAI 和其他 Azure 服务，并且该实现是更大数据/人工智能平台的一部分，端到端架构可能看起来像[图
    2-16](#fig_16_end_to_end_azure_platform_including_azure_openai)。
- en: '![](assets/aoas_0216.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0216.png)'
- en: Figure 2-16\. End-to-end Azure platform (including Azure OpenAI Service)
  id: totrans-199
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-16\. 端到端 Azure 平台（包括 Azure OpenAI 服务）
- en: In this case, Azure OpenAI Service is just part of a bigger end-to-end that
    includes data sources, integration processes, SQL/NoSQL databases, containerization,
    analytics, etc. The final setup depends on the structure of the platform itself,
    but this is a good overview to understand where Azure OpenAI sits for any data
    and AI implementation with Microsoft Azure.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，Azure OpenAI 服务只是更大端到端解决方案的一部分，该解决方案包括数据源、集成过程、SQL/NoSQL 数据库、容器化、分析等。最终的设置取决于平台本身的架构，但这是一个很好的概述，了解
    Azure OpenAI 在任何与 Microsoft Azure 的数据和人工智能实现中的位置。
- en: If you want to learn more about Azure-enabled architectures and the details
    of all these cloud services, please check out [*Learning Microsoft Azure*](https://oreil.ly/G2U08)
    by Jonah Carrio Andersson. Also, the main reference for architecture is the official
    [Microsoft Architecture Center](https://oreil.ly/0jzik) for specific [Azure OpenAI
    scenarios](https://oreil.ly/y-gPD). You may want to bookmark this resource as
    the Microsoft teams continuously update the content with new visual architectures
    and explanations, including some examples with Azure OpenAI Service.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于Azure启用架构和所有这些云服务的详细信息，请查看Jonah Carrio Andersson所著的[*学习Microsoft Azure*](https://oreil.ly/G2U08)。此外，架构的主要参考是针对特定[Azure
    OpenAI场景](https://oreil.ly/y-gPD)的官方[Microsoft架构中心](https://oreil.ly/0jzik)。你可能想将这个资源加入书签，因为微软团队会持续更新内容，包括一些带有Azure
    OpenAI服务的示例视觉架构和解释。
- en: Another interesting architecture you can explore is the [Azure OpenAI Landing
    Zone reference architecture](https://oreil.ly/xLs8X), which includes end-to-end
    cloud considerations, including core infrastructure topics such as identity and
    security, monitorization, cost management, user and API management, FinOps, etc.
    This is a very rich and complete overview of what an enterprise-grade implementation
    would include, beyond the core generative AI capabilities.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个你可以探索的有趣架构是[Azure OpenAI Landing Zone参考架构](https://oreil.ly/xLs8X)，它包括了端到端云考虑因素，包括核心基础设施主题，如身份和安全、监控、成本管理、用户和API管理、FinOps等。这是一个非常丰富和完整的概述，超出了核心生成式AI能力的范畴。
- en: Last but not least, don’t forget to explore the [CNCF Cloud Native AI Whitepaper](https://oreil.ly/qd4lq)
    from the [AI Working Group](https://oreil.ly/8k0bc), which includes technology
    building blocks, techniques, and cloud native resources for generative AI topics.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，不要忘记探索[CNCF云原生AI白皮书](https://oreil.ly/qd4lq)，它来自[AI工作组](https://oreil.ly/8k0bc)，其中包括生成式AI主题的技术构建块、技术和云原生资源。
- en: Conclusion
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: As you can see, cloud native architectures are valuable for generative AI development,
    as they seamlessly integrate with Azure OpenAI and other Azure services. We will
    explore different implementation approaches in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure),
    but all of them rely on the capabilities and key building blocks discussed here.
    As an adopter, you may face situations where you will need to optimize existing
    applications so they can incorporate generative AI capabilities (as we reviewed
    in the modernization section), but you will also have the opportunity to develop
    new Azure OpenAI–enabled applications from scratch. In this case, leveraging containerization,
    serverless, and PaaS pieces will help you design well-architected and scalable
    architectures and solutions. Depending on your current level of knowledge, it
    will be important for you to understand the cloud fundamentals behind Microsoft
    Azure and specific services for development, APIs, and Kubernetes container orchestration.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，云原生架构对于生成式AI开发非常有价值，因为它们可以无缝集成到Azure OpenAI和其他Azure服务中。我们将在[第3章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中探讨不同的实现方法，但所有这些方法都依赖于这里讨论的能力和关键构建块。作为采用者，你可能会遇到需要优化现有应用程序以使其能够集成生成式AI能力的情况（如我们在现代化部分所回顾的），但你也将有机会从头开始开发新的Azure
    OpenAI启用应用程序。在这种情况下，利用容器化、无服务器和PaaS组件将帮助你设计良好架构和可扩展的架构和解决方案。根据你当前的知识水平，了解微软Azure背后的云基础以及特定于开发、API和Kubernetes容器编排的服务将非常重要。
- en: '[Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure) will
    focus on different alternatives for enhancing your Azure OpenAI applications with
    specific company knowledge, as well as the main features and interfaces that you
    will leverage for your next projects. It also includes new terms that we briefly
    explored in this, such as vector database and orchestration. Let’s continue.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[第3章](ch03.html#implementing_cloud_native_generative_ai_with_azure)将专注于增强你的Azure
    OpenAI应用程序的不同替代方案，以及你将在下一个项目中利用的主要功能和接口。它还包括了我们在此简要探讨的新术语，如向量数据库和编排。让我们继续。'
