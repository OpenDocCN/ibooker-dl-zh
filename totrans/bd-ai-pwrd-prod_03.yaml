- en: Chapter 3\. Essential AI PM Knowledge
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 2](ch02.html#ch02_the_ai_product_development_lifecycle_1736793245641371),
    we mapped the AI PM’s role to each phase of the AIPDL. Unlike their counterparts
    in traditional product management, AI PMs must carefully navigate advancing AI
    technologies in ever-changing market demands. Marrying unique product value propositions
    with a precise market fit gives products a competitive edge and propels industries
    toward groundbreaking innovations. As businesses increasingly use AI to drive
    decision making, optimize operations, and personalize customer interactions, the
    demand for skilled AI PMs has surged. These professionals are at the forefront,
    developing innovative products to solve unmet needs.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we explore the essential skills that product managers need
    to transition into roles focused on AI. Moving from traditional to AI product
    management can be done without starting from scratch. Many core skills you have
    honed—such as project oversight, stakeholder communication, and strategic thinking—serve
    as a solid foundation in this new arena. However, AI product management also demands
    specialized capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: AI PMs must possess technical understanding and strategic foresight to navigate
    the unique challenges of AI products. As an AI PM, you will be more than a project
    overseer; you will be the visionary who can discern and balance human needs with
    machine possibilities. This role requires an in-depth understanding of AI technology’s
    potential and boundaries. While a flair for innovative solutions is valuable,
    successful AI PMs are pragmatic and focused, ensuring that each product in development
    is novel but also marketable and profitable.
  prefs: []
  type: TYPE_NORMAL
- en: As AI reshapes industries such as healthcare, finance, and entertainment, the
    need for adept PMs who can bridge the gap between traditional product management
    and AI-driven initiatives is crucial. In the following sections, I will detail
    how to leverage your existing skills and identify which new skills you need to
    master to be a successful AI PM.
  prefs: []
  type: TYPE_NORMAL
- en: 'Four buckets (shown in [Figure 3-1](#ch03_figure_1_1736793246780877)) encompass
    the skills needed to be an AI PM: core product management craft and practices,
    engineering foundations, essential leadership and collaboration skills, and AI
    lifecycle and operational awareness. Each bucket has a list of relevant skills
    for the job. Whether you aspire to be an AI PM or just seek to sharpen your existing
    expertise, the insights shared here will guide you to the core skills and knowledge
    needed to stay sharp in the industry. In this chapter, consider how you will use
    these skills throughout the AIPDL.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0301.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-1\. The different buckets of the AI PM skill set
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Core Product Management Craft and Practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This bucket discusses the core competencies that form the backbone of any successful
    PM’s skill set. This section will confirm that much of an AI PM’s responsibilities
    parallel those of a generic PM. So, in this section, prioritize understanding
    how these foundational skills translate into the context of managing AI-driven
    products. This understanding will enhance your effectiveness and ensure a smoother
    transition into the specialized field of AI product management.
  prefs: []
  type: TYPE_NORMAL
- en: A lot of these practices are covered in depth throughout the book. I’ve already
    discussed ideation and AI’s unique superpowers in the previous chapter, and you
    will find more information on strategy and road mapping in [Chapter 5](ch05.html#ch05_strategic_thinking_in_ai_1736793247595024).
    The goal of this section is not only to recap these fundamental skills, but also
    to guide you on how to amplify them with an AI perspective and bridge the gap
    between conventional product management practices and the novel demands of AI.
    This section aims to help you maintain and enhance your role in an AI-forward
    market.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying User Segments, User Personas, Pain Points, and User Needs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Understanding your users is of the utmost importance. A proficient PM should
    be adept at breaking down their broader audience into distinct segments or personas.
    This granularity helps tailor product features to address specific needs or pain
    points. For an AI product, this might mean discerning and hypothesizing which
    user group will benefit most from a smart algorithm or which segment might need
    a more intuitive interface.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, user segmentation is the initial and critical step in understanding
    your audience. *User segmentation* involves dividing a more extensive user base
    into smaller, more defined groups based on shared characteristics. The ultimate
    aim is to refine product strategies to cater to these groups. To achieve this,
    one must analyze user data, which can encompass demographics, behavior on the
    platform, purchasing histories, or levels of engagement.
  prefs: []
  type: TYPE_NORMAL
- en: Writing User Stories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*User stories* are a fundamental tool in product management. They serve as
    concise, straightforward descriptions of a feature from the end user’s perspective.
    By centering the narrative on the user’s needs and experiences, user stories ensure
    that product development focuses on delivering real value.'
  prefs: []
  type: TYPE_NORMAL
- en: In AI, where the interplay between human requirements and machine functionality
    is intricate, user stories help maintain this balance. They compel the development
    team to consider the user’s context in every design and implementation phase,
    fostering a user-centric approach that is crucial for the success of AI applications.
    Compelling user stories in AI also act as a bridge, translating complex technical
    possibilities into accessible benefits that resonate with users, thus driving
    greater adoption and satisfaction.
  prefs: []
  type: TYPE_NORMAL
- en: As an AI PM, crafting compelling user stories is even more critical. AI-driven
    solutions can be complex, often integrating advanced technologies that could easily
    drift away from practical user applications if not correctly anchored.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some hypothetical user stories for various AI features that follow
    a particular three-line template:'
  prefs: []
  type: TYPE_NORMAL
- en: Who the user is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What their use case is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What their expectation or desired outcome is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example 1: Improved recommendation system on Netflix**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Story: Avoiding Repeated Recommendations'
  prefs: []
  type: TYPE_NORMAL
- en: “As a Netflix viewer who often ignores specific show recommendations,
  prefs: []
  type: TYPE_NORMAL
- en: I want the system to notice that I’m not interested in that show and to stop
    suggesting it,
  prefs: []
  type: TYPE_NORMAL
- en: So that my recommendations are more relevant to my tastes.”
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 2: Peer recommendation feature for Spotify**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Story: Peer Recommendations'
  prefs: []
  type: TYPE_NORMAL
- en: “As a listener who trusts my friends’ music tastes,
  prefs: []
  type: TYPE_NORMAL
- en: I want an option to see what songs my friends are currently listening to,
  prefs: []
  type: TYPE_NORMAL
- en: So that I can discover songs and playlists I will enjoy.”
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 3: Improved matching algorithm for a dating app such as Tinder or
    Bumble**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Story: Deeper Interest Alignment'
  prefs: []
  type: TYPE_NORMAL
- en: “As a user of a dating app who values shared hobbies and interests,
  prefs: []
  type: TYPE_NORMAL
- en: I want the matching algorithm to prioritize profiles based on mutual hobbies
    and core beliefs,
  prefs: []
  type: TYPE_NORMAL
- en: So that I can find matches with whom I have more in common, leading to potentially
    more meaningful connections.”
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 4: Personalized design template for an invitation on design software
    such as Canva**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Story: Customized Invitation Templates'
  prefs: []
  type: TYPE_NORMAL
- en: “As an event organizer looking to create unique invitations,
  prefs: []
  type: TYPE_NORMAL
- en: I want a system that generates personalized design templates based on the theme,
    color scheme, and tone of my event,
  prefs: []
  type: TYPE_NORMAL
- en: So that I can quickly create and send out appealing invitations and reflect
    the event’s atmosphere.”
  prefs: []
  type: TYPE_NORMAL
- en: '**Example 5: Self-driving safety feature enhancement for Tesla**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Story: Advanced Safety in Varied Conditions'
  prefs: []
  type: TYPE_NORMAL
- en: “As a Tesla owner interested in autonomous driving,
  prefs: []
  type: TYPE_NORMAL
- en: I want the self-driving car system to recognize and adjust to different weather
    and road conditions adaptively,
  prefs: []
  type: TYPE_NORMAL
- en: So that I can ensure a safer and more reliable autonomous driving experience
    in various environments.”
  prefs: []
  type: TYPE_NORMAL
- en: Once the user story is defined, brainstorm the technologies and products to
    address user needs. The status quo is often insufficient in an ever-evolving tech
    landscape, particularly AI. AI PMs must think outside the box while developing
    ideas and tapping into creative solutions to address user needs.
  prefs: []
  type: TYPE_NORMAL
- en: Innovation keeps products relevant and competitive, whether it’s a novel way
    of interacting with an AI-driven assistant or a groundbreaking algorithmic approach.
    We will discuss some innovation and problem-solving strategies in [“Essential
    Leadership and Collaboration Skills”](#ch03_essential_leadership_and_collaboration_skills_1736793246809671).
  prefs: []
  type: TYPE_NORMAL
- en: Assessing Trade-offs and Prioritizing in AI Product Management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Not all features or solutions, even if feasible, should be pursued. One of the
    key responsibilities of an AI PM is to carefully assess trade-offs and prioritize
    decisions based on business goals, technical feasibility, and ethical implications.
    This process is not straightforward, because AI systems often present a unique
    set of challenges that require balancing multiple competing factors. Assessing
    trade-offs means weighing the benefits of one feature against its costs and potential
    risks, while always aligning decisions with the company’s long-term strategy and
    user needs. Let’s break down some of the common types of trade-offs faced during
    decision making.
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy versus speed
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In AI, particularly when designing systems that make real-time decisions, there
    is often a tension between the accuracy of an algorithm and the time it takes
    to process data. For example, in autonomous vehicles, object recognition algorithms
    must be accurate enough to detect pedestrians, vehicles, and obstacles. However,
    these algorithms also need to process that data in milliseconds to enable the
    car to make split-second decisions on the road. An AI PM must decide how much
    accuracy can be sacrificed to ensure that the system operates within the required
    time constraints. Too much emphasis on accuracy could delay the system’s response,
    making it unsafe. Conversely, prioritizing speed without sufficient accuracy could
    lead to errors, compromising safety and trust in the technology.
  prefs: []
  type: TYPE_NORMAL
- en: Complexity versus simplicity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AI models range from highly complex, deep-learning networks to more straightforward,
    rule-based systems. Balancing complexity and simplicity often revolves around
    balancing ease of understanding and performance. For instance, in customer support
    chatbots, a complex NLP model might handle nuanced queries better, and give more
    humanlike responses. However, such a system can be harder to explain, debug, and
    maintain. Simpler models, on the other hand, may be more transparent and easier
    to troubleshoot but could fall short in performance. PMs need to decide if the
    added complexity is justified by the incremental improvements in user experience
    or operational outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Data quality versus quantity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AI systems are data hungry. However, there is a significant trade-off between
    gathering large volumes of data and ensuring that the data is of high quality,
    relevant, and ethically sourced. In fields such as healthcare, AI models require
    extensive patient data to improve diagnosis accuracy. However, ensuring that this
    data is accurate, properly labeled, and compliant with privacy regulations such
    as GDPR s critical. Collecting large amounts of low-quality or biased data can
    introduce problems that significantly undermine the model’s performance. The role
    of the AI PM here is to ensure that the data pipeline is robust, and that the
    focus is not just on volume but also on the quality and ethical considerations
    of data collection.
  prefs: []
  type: TYPE_NORMAL
- en: Generalization versus specificity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the central dilemmas in AI development is deciding whether to build *general-purpose
    models*that can adapt to a range of tasks or *specialized models*optimized for
    specific tasks. For instance, in a recommendation system, a general-purpose model
    might provide suggestions across various domains (movies, books, music), but could
    lose some accuracy in each domain compared to a specialized model that only focuses
    on one domain, such as recommending movies. AI PMs must assess whether the broader
    reach of a general model is worth the potential loss in performance for more specialized
    needs or whether a suite of specialized models offers better results despite increased
    development complexity and cost.
  prefs: []
  type: TYPE_NORMAL
- en: User privacy versus personalization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As AI increasingly drives personalized experiences, PMs face tough decisions
    around user privacy. AI systems that analyze user data—such as targeted advertising
    platforms—are highly effective at providing tailored experiences, but they raise
    significant privacy concerns. Users are often concerned about how much personal
    data is being collected and how it is used, especially in light of tightening
    regulations such as GDPR. Striking a balance between delivering personalized experiences
    and safeguarding user privacy is paramount. In some cases, this trade-off might
    mean forgoing certain data-rich personalization features to maintain user trust,
    or investing in privacy-preserving AI techniques such as differential privacy.
  prefs: []
  type: TYPE_NORMAL
- en: Ethical considerations versus business goals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As AI systems become more sophisticated, ethical concerns around bias, fairness,
    and transparency are increasingly pressing. For example, in AI-driven hiring tools,
    PMs must ensure that the algorithms used to screen candidates are free from bias,
    ensuring fairness in the recruitment process. However, there may be business pressure
    to accelerate the hiring process, reduce costs, or meet specific quotas, which
    could tempt decision makers to overlook some of these ethical concerns. AI PMs
    must balance meeting business objectives with creating products that are fair,
    unbiased, and ethically sound, even if this means slowing down certain initiatives
    to mitigate risks.
  prefs: []
  type: TYPE_NORMAL
- en: Explainability versus performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another significant trade-off is between the performance of AI models and their
    explainability. Complex models such as deep neural networks or ensemble models
    may deliver higher accuracy but are often referred to as “black-box” models due
    to their lack of interpretability. In domains such as credit scoring and medical
    diagnostics, where the rationale behind a decision is critical, PMs must balance
    the need for high-performing models with the demand for models that can explain
    their decisions to users and regulators. A highly accurate model that cannot be
    explained may not be viable in environments where transparency and accountability
    are key.
  prefs: []
  type: TYPE_NORMAL
- en: Building or Buying? Strategic Trade-offs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Beyond the technical trade-offs in model development, AI PMs also frequently
    face higher-level strategic trade-offs, particularly when, for example, we need
    to determine whether to build AI systems in-house or buy existing solutions. Here
    are key factors to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: Cost-benefit ratio
  prefs: []
  type: TYPE_NORMAL
- en: Building an in-house AI system offers more control and customization, but it’s
    expensive and time-consuming. Buying a third-party solution may save time and
    resources, but it might not fully align with your business’s specific needs or
    long-term strategy.
  prefs: []
  type: TYPE_NORMAL
- en: Expertise and talent
  prefs: []
  type: TYPE_NORMAL
- en: Developing AI systems requires specialized talent, such as data scientists and
    ML engineers. If your company lacks the expertise to build sophisticated AI models,
    you might opt to buy a solution or partner with external vendors. However, if
    AI is core to your business, investing in talent and building internally can provide
    a competitive advantage.
  prefs: []
  type: TYPE_NORMAL
- en: Time to market
  prefs: []
  type: TYPE_NORMAL
- en: Buying a prebuilt AI solution can drastically reduce the time it takes to bring
    a product to market, which might be critical in fast-moving industries. However,
    this may limit future flexibility, as prebuilt systems often lack the adaptability
    that in-house solutions can offer.
  prefs: []
  type: TYPE_NORMAL
- en: Risk and uncertainty
  prefs: []
  type: TYPE_NORMAL
- en: Building in-house often involves more risk due to uncertainties around data
    availability, model performance, and scalability. A ready-made solution mitigates
    these risks by offering a proven product, but it may introduce dependencies on
    third-party vendors.
  prefs: []
  type: TYPE_NORMAL
- en: Data privacy and ethics
  prefs: []
  type: TYPE_NORMAL
- en: Building an AI system internally allows full control over data handling and
    privacy protocols, which is critical for industries with strict regulatory requirements.
    A third-party solution may not offer the same level of transparency and control
    over how data is used and processed.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability and maintenance
  prefs: []
  type: TYPE_NORMAL
- en: Buying a scalable solution can accelerate growth, but maintenance and customization
    may become an issue as your company evolves. Building internally allows for a
    solution that is scalable and tailored to your company’s growth trajectory, but
    it comes with ongoing development and maintenance costs.
  prefs: []
  type: TYPE_NORMAL
- en: Competitive landscape
  prefs: []
  type: TYPE_NORMAL
- en: If AI is a core differentiator for your business, building an in-house system
    may provide a competitive edge. However, if AI is not central to your value proposition,
    buying a reliable, off-the-shelf solution might be the smarter, more cost-effective
    choice.
  prefs: []
  type: TYPE_NORMAL
- en: Alignment with core business goals
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, the decision to build or buy hinges on whether AI is central to
    your company’s long-term goals. If AI is a key driver of innovation and competitive
    advantage, building in-house might be the better investment. If AI is a supporting
    technology, buying an external solution could be more efficient.
  prefs: []
  type: TYPE_NORMAL
- en: In reality, trade-offs aren’t just about choosing between A or B; the contrast
    might not always be obvious. I like to think of the different factors almost like
    sliders in a 3D trade space that you need to position precisely, as discussed
    next in [“Defining Your Trade Space”](#ch03_defining_your_trade_space_1736793246809320).
    You can calibrate your approach across multiple dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Defining Your Trade Space
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Imagine you’re building an AI-powered feature. Your trade space could involve
    any of the aforementioned trade-offs. To give a quick example, let’s pick three
    trade-offs: balancing cost versus benefit, time to market, and risk versus reward.
    For this example project, you might decide that faster time to market is essential,
    which could mean choosing an off-the-shelf AI solution. But this choice might
    sacrifice some control and customization, pushing you to balance these losses
    by investing more in other areas, such as user experience or customer support.'
  prefs: []
  type: TYPE_NORMAL
- en: This trade space isn’t static. As your project evolves, so do the trade-offs.
    Early in development, you might prioritize quick wins, but as the project matures,
    long-term sustainability and scalability might take precedence. Visualizing your
    trade space as a dynamic, shifting landscape allows you to make more informed
    strategic decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Your trade space will be unique to your product, your market, and your organization’s
    goals. For example, a small startup might prioritize speed and agility, while
    a large enterprise might focus more on scalability and long-term ROI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is my six-step guide to defining your own trade space:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Identify key factors'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start by listing the main trade-offs relevant to your product, such as the factors
    mentioned earlier. At the very minimum, you will want to include cost, time, expertise,
    and risk. Some trade-offs will be more obvious and common, such as balancing privacy
    with personalization, but there might be different trade-offs that you will need
    to capture on a case-by-case basis by talking to your stakeholders. Research scientists
    might bring up new factors that you haven’t thought about; for example, aspects
    of the product that can be improved to ensure that the solution is robust and
    scalable and to keep computational costs low. It is a good practice to talk to
    your scientists, engineers, and UX designers to paint a full, accurate picture
    of your trade space.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Step 2: Rank priorities'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Determine the relative importance of each factor. What’s non-negotiable? What
    are you willing to compromise on? Note that your stakeholders will have different
    goals. For example, stakeholder 1 might want to optimize for quality, whereas
    stakeholder 2 wants to optimize for time to market. Ultimately, you are responsible
    for painting the full picture by adding your vision and strategic thinking.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Step 3: Map out interdependencies'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Understand how each trade-off influences the others. For example, reducing cost
    might increase time to market or decrease customization. You will definitely need
    to talk to your scientist, engineering, and marketing/PR teams.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Step 4: Visualize the trade space'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a visual representation of your trade space, such as a matrix or graph,
    where you can plot different scenarios and outcomes, as shown in [Figure 3-2](#ch03_figure_2_1736793246780913).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Step 5: Test different scenarios'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use this trade-space model to simulate different decisions and their impacts.
    Adjust your strategy based on these simulations.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Step 6: Iterate and adjust'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As your project progresses, revisit your trade space regularly. Adjust your
    priorities and strategies as new information becomes available or as market conditions
    change.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[Figure 3-2](#ch03_figure_2_1736793246780913) is an abstract graph that visualizes
    the trade space with various constraints factored in. It can help you during ideation
    and decision making. To create a trade space, identify all relevant constraints
    (such as resources, ethics, technology, or regulations) and trade-offs for your
    problem, then map these constraints as boundaries to define a solution space,
    visualizing where acceptable solutions lie within these intersecting limits. Your
    solution follows somewhere in the solution space. Make sure to explicitly call
    out the risks and opportunities of each trade-off.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0302.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3-2\. Sample trade space of trade-offs in AI applications (source: [Christian
    Kaestner](https://oreil.ly/v6MTu))'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Incorporating Trade-offs in a Product Review
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Determining the right path forward for complex AI solutions is a collaborative
    process that requires input from cross-functional partners and leadership. A product
    review is one of the most effective ways to align on trade-offs, constraints,
    and strategic priorities. [Chapter 5](ch05.html#ch05_strategic_thinking_in_ai_1736793247595024)
    provides a detailed guide to conducting product reviews. In the [Appendix](app01.html#appa_appendix_1736793244857323),
    I introduce a template for crafting product reviews that you can use as part of
    the product review document. It’s a good practice to include an executive summary
    at the top, with the goal of discussing the trade space with your leadership.
    These summaries are designed to present multiple options, their trade-offs, and
    recommendations in a clear, structured way to ensure informed decision making.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 3-1](#ch03_table_1_1736793246789805) provides an example of how I visually
    represent different solutions for an AI product, including key factors, trade-offs,
    and potential outcomes. The example depicted is for a decision between on-device
    processing and cloud processing that weighs key factors and their pros (+) and
    cons (–). For this hypothetical scenario, the factors I chose are User Experience,
    Ethics and Privacy, Compliance, Resource Constraints, and Technology Constraints.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-1\. Executive summary example listing pros and cons of decision options
  prefs: []
  type: TYPE_NORMAL
- en: '| Factor | Option A: On-device processing | Option B: Cloud processing |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| User Experience | + Fast response times (low latency), ideal for real-time
    applications.+ Offline functionality ensures reliability in areas with poor connectivity.–
    Limited by device hardware, restricting model complexity. | + Supports more advanced
    AI models with better accuracy and features.+ Scales easily for multiple users
    without device limitations.– Dependent on consistent network quality; latency
    may impact experience. |'
  prefs: []
  type: TYPE_TB
- en: '| Ethics and Privacy | + User data stays local, improving privacy and reducing
    risks of breaches.– Higher risk of exposure if the device is lost or hacked. |
    + Centralized oversight simplifies data auditing and security monitoring.– Data
    aggregation increases risk of misuse or regulatory violations. |'
  prefs: []
  type: TYPE_TB
- en: '| Compliance | + Easier to comply with strict regulations such as GDPR or HIPAA
    by keeping data local.– Device-based compliance may vary based on hardware and
    software partnerships. | + Simplifies global compliance management by centralizing
    control.– Cross-border data flow restrictions may complicate deployment. |'
  prefs: []
  type: TYPE_TB
- en: '| Resource Constraints | + Lower ongoing costs after the initial investment.–
    Significant up-front hardware investment to enable on-device processing. | + Flexible
    pay-as-you-go pricing model reduces waste during idle periods.– Ongoing operational
    expenses for server infrastructure and cloud scaling. |'
  prefs: []
  type: TYPE_TB
- en: '| Technology Constraints | + Independent of network availability, ensuring
    robustness.– Requires lightweight AI models optimized for constrained hardware.
    | + Supports cutting-edge AI models and technologies that demand high compute
    power.– Dependent on stable internet connections, which may create failure points.
    |'
  prefs: []
  type: TYPE_TB
- en: After the table, add your recommendation and a justification. Visit the [Appendix](app01.html#appa_appendix_1736793244857323)
    for the full product review template.
  prefs: []
  type: TYPE_NORMAL
- en: Setting a clear direction and charting a path are essential to ensuring a successful
    AI product launch and market acceptance. PMs define the strategic vision for the
    product, ensuring alignment with organizational goals. This involves laying out
    a road map and a visual representation of the product’s journey over time, detailing
    what features to develop and when. Setting the strategic vision can also encompass
    milestones such as data acquisition or model refinement for AI products. I will
    discuss road mapping in detail in [Chapter 4](ch04.html#ch04_the_ai_pm_s_day_to_day_1736793247322408),
    which focuses on the day-to-day management of AI products.
  prefs: []
  type: TYPE_NORMAL
- en: How to Develop General Product Management Skills
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The necessary skills to be a successful PM are constantly changing. For any
    successful professional, it is essential to keep learning and to brush up on existing
    skills. Recognizing the unique challenges and opportunities within AI product
    management, this section is structured to guide you through various educational
    and practical experiences that enhance your analytical reasoning, decision making,
    and hands-on capabilities, which are essential for thriving in this dynamic field.
    Here, you’ll find actionable advice to start and continuously advance your journey
    in mastering the skills needed for effective AI product management.
  prefs: []
  type: TYPE_NORMAL
- en: Educational Pursuits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AI PMs need a foundation built on educational pursuits that equip them with
    analytical and decision-making skills. Formal courses play a crucial role in this
    development. These courses range from broad classes focusing on analytical reasoning
    to more specialized ones explicitly tailored for the tech and AI sectors. Such
    educational offerings enhance critical thinking and provide you with robust analytical
    tools to effectively drive AI projects forward. You can take these courses at
    a traditional university or through online learning platforms such as [Coursera](https://www.coursera.org),
    [edX](https://www.edx.org), and [Udacity](https://www.udacity.com). These platforms
    offer specialized programs developed by experts in their fields, ensuring that
    learners can access cutting-edge knowledge irrespective of their geographic location.
  prefs: []
  type: TYPE_NORMAL
- en: Hands-on Experience
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Beyond formal courses, workshops and bootcamps offer practical, hands-on experience
    in a condensed format, making them an excellent way for you to deepen your understanding
    of specific areas, particularly in data analytics. Platforms such as [Maven](https://maven.com)
    (where I teach), [General Assembly](https://generalassemb.ly), and [Le Wagon](https://www.lewagon.com)
    host workshops that are highly regarded in the tech community for their focus
    on current industry practices and technologies.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to bootcamps, participating in hackathons is another excellent way
    for AI PMs to gain hands-on experience while leveraging community knowledge and
    networking. Platforms such as [Devpost](https://devpost.com) and [Kaggle](https://www.kaggle.com)
    host numerous hackathons, offering opportunities to work on specific problems,
    often with datasets that mimic real-world scenarios. These events not only challenge
    participants to apply their skills under time constraints, but also foster a spirit
    of collaboration and innovation, providing a learning platform that is both competitive
    and educational.
  prefs: []
  type: TYPE_NORMAL
- en: Finding ways to engage in diverse projects is essential for AI PMs. PMs encounter
    challenges requiring innovative solutions and adaptive thinking by participating
    in various AI projects. This exposure enhances their problem-solving capabilities
    and deepens their understanding of different AI applications and their potential
    impacts. Such experiences are invaluable as they prepare AI PMs to handle real-world
    AI product development complexities.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The field of AI is remarkably dynamic, making continuous learning a cornerstone
    of success for any AI PM. Following breakthrough research, changing methodologies,
    and relevant industry news is essential. Regularly consult AI blogs from major
    tech companies, such as [Meta’s AI Blog](https://ai.meta.com/blog) and [Google’s
    AI Blog](https://oreil.ly/bb_N_), where people discuss new advances, research
    outcomes, and case studies. Additionally, subscribing to well-curated newsletters
    such as MIT Technology Review’s [*The Algorithm*](https://oreil.ly/AWtWx), [*AI-Weekly*](https://ai-weekly.ai),
    [O’Reilly’s AI Newsletter](https://oreil.ly/2SzI4), and [*Last Week in AI*](https://lastweekin.ai)
    can provide a steady stream of current and relevant information. These resources
    help you stay informed about the latest trends, cutting-edge technologies, and
    the competitive landscape to build strategies and tools for managing AI-driven
    products.
  prefs: []
  type: TYPE_NORMAL
- en: Essential Leadership and Collaboration Skills
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As experienced product managers, you must possess various soft skills crucial
    for successful AI product management. This section builds on those existing abilities,
    focusing on how to adapt and enhance them for the specific challenges of managing
    AI products.
  prefs: []
  type: TYPE_NORMAL
- en: While technical knowledge in AI development is essential, the role of an AI
    PM also heavily relies on your ability to empathize with users and apply your
    interpersonal skills to bridge the complex gap between advanced AI technologies
    and practical, user-centric applications. Here, we’ll dive into which soft skills
    are vital for AI PMs and how you can further develop these skills to effectively
    create and launch solutions that incorporate cutting-edge technology and that
    genuinely resonate with and meet the needs of your users. This approach will enable
    you to leverage your existing strengths to foster innovation and ensure that your
    AI products are as impactful and user-focused as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Creativity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creativity empowers PMs to ideate unique solutions, envision novel product features,
    and think outside the box to meet user needs. In the rapidly evolving landscape
    where new capabilities and possibilities emerge faster than we can keep track
    of them, a creative approach can distinguish a successful product from a mediocre
    one. Creativity allows AI PMs to envision not just the immediate functionalities
    of a product, but also its potential to transform industries or even create entirely
    new ones. It’s about seeing beyond the current technology to what could be possible,
    and making bold decisions that pave the way for innovation. To foster such creativity,
    you can immerse yourself in diverse experiences, from arts to travel, enhancing
    your ability to think outside the box. Regular brainstorming sessions, like those
    we discussed in [Chapter 2](ch02.html#ch02_the_ai_product_development_lifecycle_1736793245641371),
    further stimulate creative thinking, making it a critical practice for innovation.
  prefs: []
  type: TYPE_NORMAL
- en: The following subsections explore different ways to channel creativity into
    the management of AI products, highlighting how creativity manifests in innovative
    problem-solving, product differentiation, and storytelling. By delving into these
    topics, you’ll see that creativity is about more than generating 100 ideas; more
    importantly, it contributes to developing unique solutions, distinguishing your
    product in a competitive market, and effectively communicating its value.
  prefs: []
  type: TYPE_NORMAL
- en: Innovative problem-solving and design thinking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the primary ways creativity manifests in AI product management is through
    innovative problem-solving. Often, solutions aren’t clear and they require outside-the-box
    ideas. Practicing design thinking is a great way to be a creative problem solver.
    The heart of practical design thinking involves empathizing with users, defining
    pain points, and testing to solve user-centered problems. Consider the example
    where you are an AI PM tasked with improving user experience and customer sentiment
    for public transportation. By creatively applying AI technologies to reduce the
    pain points from the frustration of wait times, you can create a valuable product
    that dramatically enhances the customer service experience.
  prefs: []
  type: TYPE_NORMAL
- en: Product differentiation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Creativity also plays a crucial role in product differentiation. A creative
    AI PM might integrate seemingly unrelated data sources to provide unique insights
    in a market crowded with AI solutions. For instance, an AI PM in the retail sector
    could innovate by combining weather forecast data with consumer purchasing patterns
    to predict and respond to changes in purchasing behavior due to weather conditions.
    Knowing how to deliver value and set a competitive advantage through differentiation
    is a creative challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Storytelling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Storytelling is a strategy for securing stakeholder buy-in, fostering team cohesion,
    enhancing communication, and building a solid brand identity. By articulating
    a clear and compelling narrative, PMs ensure that everyone—from team members to
    stakeholders—aligns with the product’s goals. This narrative approach helps build
    empathy toward users, facilitate better communication within teams, and create
    solutions that meet user needs. A consistent story that resonates across all user
    touchpoints establishes a memorable brand identity, making the product a part
    of the user’s story.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: By fostering creativity, AI PMs ensure that they keep up with technological
    advancements and have a vision for the direction of innovation. They turn abstract
    ideas into tangible products that can significantly impact businesses and consumers,
    ensuring that their projects meet current market needs and shape future trends.
  prefs: []
  type: TYPE_NORMAL
- en: Communication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Effective communication is crucial for translating complex AI concepts into
    clear, understandable narratives that resonate with stakeholders and users. For
    example, an AI PM should be able to effectively explain the benefits of a new
    AI algorithm to nontechnical board members, resulting in full project backing.
    You can develop this skill through regular interaction with diverse audiences.
    Practice breaking down intricate AI functionalities into simpler terms during
    team meetings, stakeholder presentations, and informal discussions. Not only will
    this ensure clarity, but it will also help build confidence in your ability to
    bridge the technical and business worlds.
  prefs: []
  type: TYPE_NORMAL
- en: Leadership
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the core qualities of a successful leader is the ability to unify diverse
    teams around a shared vision. Leadership requires domain expertise and a profound
    understanding of the product’s trajectory and goals. An AI PM will collaborate
    across various business functions and must bridge multiple departments—such as
    engineering, design, and marketing—to build alignment on the product vision and
    milestones. Collaboration is essential when integrating AI technologies into products
    loved by the masses. Meaningful and effective collaboration hinges on the PM’s
    ability to lead teams to a common finish line.
  prefs: []
  type: TYPE_NORMAL
- en: To enhance leadership capabilities, an AI PM should actively pursue mentorship
    from experienced professionals in the industry. Mentorship offers invaluable insights
    into successful leadership strategies and equips managers with the tools to tackle
    the unique challenges of leading AI-focused initiatives. Mentorship can manifest
    in various forms, including one-on-one conversations, leadership workshops, and
    industry conferences.
  prefs: []
  type: TYPE_NORMAL
- en: Analytical Thinking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Analytical thinking is a cornerstone skill for AI PMs, empowering them to leverage
    data to aid decision making. I believe that data-driven decision making is paramount
    in any role. As a product leader, I am more confident in making decisions using
    relevant data from market due diligence or pilot experiments than from instinct
    or gut feeling. Begin by identifying key metrics relevant to your product’s success.
    Use analytics tools or custom dashboards to track these metrics. Regularly review
    data trends and anomalies. When deciding, use A/B testing to determine the best
    course of action.
  prefs: []
  type: TYPE_NORMAL
- en: Develop a habit of questioning assumptions and backing decisions with data.
    While understanding how to interpret results from predictive models and simulations
    is of the utmost importance, a successful AI PM will also know the different types
    of ML models and the scenarios in which they are best deployed. For example, regression
    analysis is a simple model used to predict user behavior, and clustering techniques
    effectively segment users based on usage patterns. These data science methods
    help PMs evaluate the best approach to solving different aspects of a complex
    problem. A strong foundation in data analysis will help a PM find the right balance
    when faced with difficult trade-offs.
  prefs: []
  type: TYPE_NORMAL
- en: Enrolling in specialized courses focused on key data science concepts, such
    as statistical analysis, predictive modeling, and ML, is a great way to strengthen
    analytical skills. Many data science classes and curriculums are available in
    person and online. Educational platforms such as Coursera and the [O’Reilly AI
    Academy](https://www.oreilly.com) are accessible and provide the latest methodologies
    in the field from many qualified industry professionals and scholars.
  prefs: []
  type: TYPE_NORMAL
- en: Of the many data science courses available, every aspiring AI PM should take
    classes on data analytics and visualization, statistics and probability, and ML
    and AI. These courses equip PMs with a robust analytical toolkit for effective
    decision making. PMs need basic technical skills to work effectively and discuss
    complex concepts and trade-offs with engineers and scientists. Knowledge of ML
    and AI technologies prepares managers to accurately understand the feasibilities
    and possibilities of the technology.
  prefs: []
  type: TYPE_NORMAL
- en: Empathy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the heart of every AI product lies the user. Practicing empathy ensures that
    AI solutions are built with a deep understanding of user emotions, needs, and
    challenges. Great ways to polish this skill are to engage directly with users,
    conduct interviews, immerse oneself in user feedback, and regularly practice perspective-taking
    exercises to resonate with diverse user segments. We are looking for ways to make
    our lives better, and practicing empathy is the best way to learn about one another
    and find ways to be a team player. By establishing these soft skills, AI PMs can
    use novel technologies to build experiences that resonate with the users.
  prefs: []
  type: TYPE_NORMAL
- en: Next, I’ll share the relevant engineering and AI-based knowledge that an AI
    PM must grasp quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Engineering Foundations for Product Managers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Due to the technical complexity and ongoing evolution of AI technologies, a
    foundational understanding of engineering principles is especially critical for
    AI PMs. Basic engineering knowledge is crucial for effectively communicating with
    engineering teams and creating feasible and impactful product road maps. While
    this book won’t go deep into the engineering foundations listed in [Figure 3-1](#ch03_figure_1_1736793246780877),
    the following overview will equip you with the necessary basics to enhance your
    collaborative efforts and understanding of AI product management.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will discuss why understanding coding practices is crucial
    for managing AI products. As AI technologies increasingly underpin product functionalities,
    AI PMs must possess a practical grasp of coding to effectively oversee development
    processes and ensure seamless integration of new technologies. I will break down
    the best coding practices for developing new AI-driven products. From understanding
    version control to recognizing clean code practices to appreciating the nuances
    of algorithm optimization, each subsection will build on the one preceding it
    to provide a comprehensive guide on how to work effectively with code. This knowledge
    facilitates better communication with technical teams and empowers PMs to make
    informed decisions that influence the product’s technical strategy and execution.
  prefs: []
  type: TYPE_NORMAL
- en: Version control
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Version control is pivotal for any collaborative project, and it’s even more
    critical in code-extensive projects. Having a system to manage document changes
    is imperative to monitoring and storing documentation, and is even more important
    in minimizing risk from errors or unforeseen negative impacts from changes. Having
    a systematic version control tool allows cross-functional teams to collaborate
    more effectively. Systems such as [Git](https://git-scm.com) enable teams to manage
    changes to source code over time, tracking who made what changes and when. These
    tools ensure that anyone can recall a prior software version at any time. Comprehensive
    version control systems allow for better bug tracking and feature development;
    for example, you can use Git to review the progress on specific features or to
    understand the impact of certain changes in the project’s history. This tool is
    essential for individual accountability and enabling collaborative reviews and
    contributions through platforms such as [GitHub](https://github.com) or [GitLab](https://about.gitlab.com).
  prefs: []
  type: TYPE_NORMAL
- en: Build process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Understanding the product build process is essential for any PM to set and manage
    realistic project timelines and expectations. PMs must have a complete scope of
    the tools and processes used to build the product. Becoming familiar with the
    leading build systems and workflow optimizers is a great way to start. For PMs,
    processes and technologies used in the build are constantly improved, so expertise
    in new technologies is a continuous learning process for any PM. [MLflow](https://mlflow.org)
    and [Zapier](https://zapier.com) are popular GenAI build-process technologies.
  prefs: []
  type: TYPE_NORMAL
- en: MLflow plays a crucial role in managing AI model training and deployment complexities
    and is most frequently used to track experiments, package code into reproducible
    runs, and manage the deployment of models from various ML libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Zapier is known for automating workflows by compiling, linking, and packaging
    them into executable products called *Zaps*, which use specific events in one
    app as triggers to perform tasks in another app, streamlining processes and boosting
    efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: By understanding these tools, you can better anticipate delays or issues that
    might arise from dependencies or the integration of new code in your AI product,
    ensuring smoother project flows and more accurate scheduling.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Testing exists in all workflows. A thorough understanding of testing methodologies
    is crucial for ensuring the quality and robustness of the final product. Knowing
    the unit-testing frameworks [pytest](https://oreil.ly/wA8uM) and [TensorFlow](https://oreil.ly/K_wH0)
    can help you simulate different scenarios for AI models to test for the robustness
    and accuracy of AI-driven applications before they go into production. Unit tests
    are designed to test individual software components, ensuring performance in isolation.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in an AI-driven application, unit tests might validate ML models’
    accuracy and response time under various conditions. This understanding helps
    you advocate for adequate testing phases and ensures that the product meets quality
    standards before it reaches customers.
  prefs: []
  type: TYPE_NORMAL
- en: Resource management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Computational resources can significantly impact the performance and costs of
    AI projects. Having robust resource management systems is imperative to effective
    and efficient resource allocation. Tools such as [Kubernetes](https://kubernetes.io)
    and [Docker](https://docker.com) are commonly used to manage server loads and
    optimize resource allocation efficiently. Kubernetes, for example, allows for
    automatically scaling applications based on the server load, which can be crucial
    for deploying AI models that may require significant computational power. Understanding
    these tools and principles enables you to make informed decisions about resource
    allocation, anticipate potential bottlenecks, and manage operational costs effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Understanding how your engineers interact with code and the models they build
    should give you a foundation to collaborate knowledgeably and build rapport with
    your technical team.
  prefs: []
  type: TYPE_NORMAL
- en: Key Technical Concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section will explore fundamental technical concepts for managing AI products
    effectively. As AI continues to integrate into various industries, understanding
    these concepts will help you effectively oversee the design, development, and
    integration of AI technologies. This section provides a comprehensive look into
    the technical backbone of AI products, from the mechanics of APIs that facilitate
    seamless software interactions to the intricacies of algorithms that drive AI
    functionality. These concepts enhance a manager’s ability to make informed decisions
    and enable effective communication with technical teams and stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: APIs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: APIs are crucial for building connections between disparate software systems,
    making them essential for AI PMs who must integrate AI models with existing systems
    or third-party applications. Understanding APIs allows AI PMs to leverage external
    services and data and to make their own AI functionalities available in a way
    that other applications can easily consume. For example, an AI PM might oversee
    the integration of an ML model into a broader CRM system using APIs to enhance
    predictive customer analytics. You can ensure seamless data exchange and functionality
    between disparate software components by understanding how APIs work, leading
    to more robust and versatile AI solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Algorithms are the heart of what drives AI systems and experiences. An educated
    understanding of ML models such as regression models, neural networks, and reinforcement
    learning is important when building AI products. Knowing how these algorithms
    process data and learn from inputs allows AI PMs to decide which techniques best
    suit specific tasks. For example, understanding the differences between supervised
    and unsupervised learning algorithms^([1](ch03.html#id752)) can help you choose
    the right approach for customer segmentation or anomaly detection tasks. This
    foundational knowledge not only aids in strategic product decision making but
    also enhances communication with data scientists and engineers. I provide a deeper
    dive into algorithms and the model-training process later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: System architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: System architecture affects every aspect of product development and deployment.
    *System architecture* refers to the structured design of the overall system that
    outlines how various software components, hardware elements, and integration with
    other systems interact to form a complete product. System architecture sets the
    foundation for the product’s functionality, performance, and scalability. It ensures
    that all parts of the product work together cohesively and efficiently, meeting
    both the technical requirements and the user needs.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing the ins and outs of the system architecture helps you design scalable
    and resilient products capable of handling increased computational demands. For
    instance, an AI PM must understand how to structure a system that integrates a
    real-time ML model without impacting the overall system performance.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This detailed exploration of APIs, algorithms, and system architecture has underscored
    their critical roles in successfully managing AI products. By understanding how
    APIs enable interoperability between systems and comprehending the significance
    of robust system architecture, you will be better equipped to develop novel products
    that leverage the power of AI.
  prefs: []
  type: TYPE_NORMAL
- en: Software development methodologies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are two popular development methodologies: Waterfall and Agile.'
  prefs: []
  type: TYPE_NORMAL
- en: The [Waterfall methodology](https://oreil.ly/_nwjh)is a traditional, sequential
    software development approach characterized by its linear and structured phases.
    This model divides the development process into requirements gathering, design,
    implementation, verification, and maintenance. Each phase must be completed before
    the next one begins, with little room for revisiting a phase once it’s closed.
    While the Waterfall model provides a clear, predefined path that can simplify
    planning and execution, its rigidity is a notable limitation, particularly in
    projects requiring flexibility due to changing requirements or technologies. In
    environments where project specifications are unlikely to change and clarity is
    crucial from the outset, the Waterfall methodology can be highly effective.
  prefs: []
  type: TYPE_NORMAL
- en: The [Agile methodology](https://oreil.ly/xIkS9) is a dynamic and collaborative
    software development approach designed to quickly accommodate change and deliver
    value. Unlike the Waterfall model, Agile breaks the project down into smaller,
    manageable increments known as *sprints*, typically lasting a few weeks. This
    approach emphasizes continuous planning, testing, and iterations.
  prefs: []
  type: TYPE_NORMAL
- en: Agile fosters a collaborative work pattern that highly values feedback. Feedback
    loops help ensure that the development aligns closely with user needs and that
    adjustments to a model can be made in real time. Agile’s iterative nature allows
    for rapid releases and swift change, making it ideal for dynamic and uncertain
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: Estimation frameworks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Estimation frameworks accurately forecast the time and resources required for
    various tasks and projects. This section looks at several frameworks and techniques
    that provide a high-level approach to planning.
  prefs: []
  type: TYPE_NORMAL
- en: Top-down estimation.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This method starts with the overall scope of a project and estimates its total
    effort or cost based on past projects of a similar scale. Top-down estimation
    is particularly useful in the early stages of project planning when detailed information
    about the specific tasks and deliverables is unavailable. It’s an effective approach
    for setting initial budgets, timelines, or project feasibility, especially when
    speed is a priority and the granular details are not yet defined. However, it
    may be less accurate for complex or highly detailed projects, as it makes generalizations
    that might not account for unique challenges or nuances.
  prefs: []
  type: TYPE_NORMAL
- en: Bottom-up estimation.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Often used jointly with top-down estimation, [*bottom-up estimation*](https://oreil.ly/4lCT5)involves
    breaking a project down into smaller, detailed components and estimating the effort
    for each before summing them to get a total project estimate. This granular approach
    allows PMs to assess the scope and needs of a project more accurately, considering
    specific factors and complexities of each component. By implementing bottom-up
    estimation, you can set realistic expectations and timelines, allocate resources
    more effectively, and mitigate the risks associated with project overruns.
  prefs: []
  type: TYPE_NORMAL
- en: Parametric evaluation.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another valuable technique is [*parametric estimation*](https://oreil.ly/tX6kT),
    which relies on mathematical models and historical data to generate precise forecasts.
    By identifying key variables—such as cost per unit, time per task, or labor hours—and
    applying them to the scope of a project, parametric estimation provides a systematic
    way to assess resource needs. This approach is most effective when dealing with
    repetitive or scalable projects, where robust historical data and clear metrics
    are available. For example, in construction, manufacturing, or software development,
    parametric estimation can deliver reliable and consistent results. It’s less suitable
    for one-of-a-kind projects or innovative tasks where historical data or clear
    metrics might be unavailable.
  prefs: []
  type: TYPE_NORMAL
- en: Expert judgment evaluation.
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another widely used approach, [*expert judgment estimation*](https://oreil.ly/N4uh_)
    involves leveraging the insights and experience of professionals with deep knowledge
    of the domain. Experts evaluate the scope, challenges, and requirements of a project
    to provide an informed estimate based on their prior experience with similar initiatives.
    Expert judgment is especially useful in scenarios where historical data is limited,
    the project involves innovation or unique elements, or the environment is uncertain.
    For example, when launching a novel product, developing a prototype, or managing
    a high-risk project, the nuanced perspectives of experienced professionals can
    help anticipate challenges and provide practical estimates. However, it’s less
    ideal when objective, quantitative data is available and could provide greater
    accuracy or consistency.
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis software
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data analysis software equips AI PMs with the tools to dive deep into data,
    enabling them to uncover patterns and derive actionable insights.
  prefs: []
  type: TYPE_NORMAL
- en: Python, with libraries such as [Pandas](https://oreil.ly/zwEhR) and [NumPy](https://numpy.org),
    is particularly popular for data manipulation and analysis capabilities. [R](https://www.r-project.org)
    is another statistical software tool offering data analysis and visualization
    options and is ideal for more statistical work. SQL remains indispensable for
    efficiently querying large databases, allowing PMs to retrieve and analyze data
    directly from the source.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, visualization platforms like [Tableau](https://www.tableau.com)
    transform complex datasets into understandable, interactive visual representations,
    facilitating more accessible communication of insights to stakeholders. Mastering
    these tools enhances your analytical capabilities to make data-driven decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: While an AI PM doesn’t need to be a seasoned engineer, foundational knowledge
    of these engineering principles and practices is indispensable. It ensures a more
    cohesive, informed, and efficient product development process, especially in the
    fast-paced, intricate world of AI.
  prefs: []
  type: TYPE_NORMAL
- en: The AI Product Development Lifecycle and Operational Awareness
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Comprehending fundamental concepts such as ML algorithms, model training, fine-tuning,
    LLMs, model quality, and data management is crucial for effectively managing AI
    products. Grasping these concepts enables you to make informed decisions about
    designing, developing, and deploying AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding ML algorithms helps you select the right approach to solve specific
    problems, while knowing model-training processes ensures that these algorithms
    perform optimally. You need to be able to assess model quality—this is essential
    to guaranteeing that AI products meet the required standards and deliver reliable
    predictions. Additionally, effective data management strategies are vital to maintain
    the integrity and efficiency of the data used for training AI models. These competencies
    form the backbone of successful AI product management, ensuring that products
    function efficiently and align with broader business goals and ethical standards.
    To understand these concepts, let’s dive into the lifecycle of AI.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 2](ch02.html#ch02_the_ai_product_development_lifecycle_1736793245641371)
    introduced the AI Product Development Lifecycle and talked about the AI MVP. In
    this section, we’ll take a closer look at the AIPDL. Understanding its stages
    is crucial, because they outline the path from an initial idea to a functioning
    AI product that can be iterated on and improved over time. [Figure 3-3](#ch03_figure_3_1736793246780937)
    shows the phases of the AI lifecycle. The lifecycle reiterates until the project
    reaches a fair minimum viable quality (MVQ), which represents the threshold at
    which the product provides sufficient value to address users’ needs effectively
    and can be released to the market.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0303.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-3\. Stages of the AI lifecycle
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Project Scoping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before any development begins, you need to have a clear and actionable plan.
    This is where project scoping comes in. By this point, you should have a finalized
    PRD, as mentioned in [Chapter 2](ch02.html#ch02_the_ai_product_development_lifecycle_1736793245641371),
    that defines the objectives, user needs, success metrics, and constraints of your
    AI product. *Project scoping* is all about the engineering team translating the
    product requirements into technical boundaries and expectations. What problems
    are you trying to solve? What outcomes are you aiming for? What data sources will
    be involved?
  prefs: []
  type: TYPE_NORMAL
- en: For example, if you’re building an AI-powered personalized content recommendation
    system for a video streaming platform, the project scope might involve identifying
    key user interaction data to capture (such as viewing history, genre preferences,
    and watch duration) and setting a clear objective to increase user engagement
    by recommending relevant content. The PRD in this case would detail the types
    of data needed, the integration points with the existing platform, and the key
    performance indicators (KPIs) to measure success.
  prefs: []
  type: TYPE_NORMAL
- en: This phase also includes setting up initial alignment with cross-functional
    teams (engineering, data science, legal, design). Clear project scoping avoids
    scope creep and allows everyone to have a shared understanding of the project’s
    goals and the path forward. It’s a good practice to explicitly call out what is
    *out* of scope, which will help you set the right expectations for your cross-functional
    partners.
  prefs: []
  type: TYPE_NORMAL
- en: Data Collection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: During the data collection phase, your scientist counterparts will have an initial
    plan for how much data is needed to train the model that will provide the desired
    output. In larger companies, an ML operations (MLOps) team is often responsible
    for gathering the necessary datasets that will feed into the AI models. The quality
    and diversity of the data you collect will directly impact the model’s performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some different sources from which you can acquire data:'
  prefs: []
  type: TYPE_NORMAL
- en: Internal databases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For personalized recommendation systems (such as a content streaming platform),
    collect *user activity data* such as clicks, search queries, watch history, or
    purchasing behavior.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer support chatbots can utilize *data from existing CRM platforms*, including
    past interactions, support tickets, chat logs, and customer profiles.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: To optimize AI-driven business processes, use *internal operational data*, such
    as sales numbers, inventory records, transaction logs, or production metrics.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Third-party APIs and platforms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Social media platforms such as X, Meta, and Instagram offer *APIs* that provide
    access to public posts, user profiles, hashtags, and engagement metrics. This
    is particularly useful for sentiment analysis and social media monitoring tools.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Government websites, educational institutions, and nonprofits often provide
    *free public datasets*. For instance, the [US Census Bureau](https://data.census.gov),
    [World Bank](https://oreil.ly/DO_iQ), and [UN](https://data.un.org) datasets are
    great sources for demographic, economic, and geographical data.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Weather and geolocation APIs* such as [OpenWeather](https://oreil.ly/AWkWL)
    and [Google Maps Platform](https://oreil.ly/Bc-QR) provide real-time weather conditions
    and location-based information, which can be integrated into various predictive
    models (such as for supply-chain forecasting or personalized marketing).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: User-generated content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Platforms such as [Amazon](https://www.amazon.com), [Yelp](https://www.yelp.com),
    and app stores have rich *datasets of user reviews*, *ratings*, and *comments*,
    useful for building sentiment analysis tools or recommendation engines.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You can collect direct feedback from users through *surveys*, *product feedback
    forms*, or *in-app feedback prompts* to gather insights into their preferences
    and behaviors.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Public repositories and open source data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For image recognition or computer vision tasks, *image datasets* such as [ImageNet](https://oreil.ly/HBWTz),
    [COCO (Common Objects in Context)](https://oreil.ly/OxXj7), and [Open Images](https://oreil.ly/Bg8qF)
    provide thousands of labeled images. For *video data*, YouTube and similar platforms
    can provide a source of labeled and unlabeled video content.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For NLP projects, *open text corpora* such as Wikipedia dumps, Common Crawl,
    news articles, and the Enron email dataset provide vast amounts of text for model
    training.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Scientific and medical datasets* from medical institutions such as the [National
    Institutes of Health (NIH)](https://www.nih.gov) and journal aggregators such
    as [PubMed](https://oreil.ly/JuXg8) can be invaluable for training AI models in
    healthcare, such as diagnostic tools or patient risk assessments.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Sensor and IoT data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usage patterns and sensor data from *smart devices* such as smart refrigerators
    (e.g., temperature, humidity, and door sensors) and user interactions can be collected
    to train AI models for smart home systems.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Wearable devices* such as fitness trackers and smart watches provide data
    on factors such as physical activity, heart rate, and sleep patterns, which can
    be used to develop personalized health and wellness applications.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Data vendors and marketplaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data marketplaces such as [Kaggle](https://www.kaggle.com), [Amazon Web Services
    (AWS) Data Exchange](https://oreil.ly/DQarv), and [Data.gov](http://data.gov)
    provide access to a wide range of datasets, from consumer behavior to financial
    markets.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Commercial data providers such as [Nielsen](https://www.nielsen.com), [Experian](https://www.experian.com),
    and [Acxiom](https://www.acxiom.com) sell data on consumer behavior, market trends,
    and audience demographics, which can be useful for targeted marketing and advertising
    models.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Synthetic data generation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In cases where real-world data is scarce or sensitive (such as with medical
    data), you can generate *synthetic data* to simulate possible scenarios. This
    can involve creating artificial images for computer vision models, generating
    customer behavior scenarios for recommendation engines, or synthesizing voice
    data for speech recognition models. (This is a suboptimal data source and should
    be used as a last resort, when you lack better data or resources.)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: When collecting user data, especially for products such as content recommendation
    systems or social media tools, you must ensure compliance with regulations like
    GDPR. This involves implementing robust safeguards to protect user information
    throughout the data handling process. The need for such measures stems not only
    from legal requirements, but also from the ethical responsibility to respect user
    privacy and trust.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring data protection serves several critical functions. First, it helps
    maintain user trust, a vital component of user retention and brand reputation.
    Users are more likely to engage with platforms that they believe handle their
    data securely and transparently. Second, compliance with data protection laws
    helps avoid significant legal and financial penalties that can arise from data
    breaches or misuse. These regulations require that data be collected for specified,
    explicit, and legitimate purposes and handled in a way that is secure, which minimizes
    the risk of breaches and misuse.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, ethical data use involves more than just compliance; it includes a
    commitment to fairness and nondiscrimination in automated decisions made by algorithms.
    This is particularly important in content recommendation and social media, where
    algorithms can potentially shape public opinion or impact individual behaviors.
    By adopting ethical data practices, companies ensure that their systems do not
    perpetuate biases or lead to unfair outcomes, thereby fostering a more inclusive
    digital environment.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s continue with the example of building a content recommendation system.
    In the data collection phase, you’d gather data from various sources, such as
    user behavior logs (clicks, watch history), content metadata (genres, directors,
    and actors), and user-generated information (ratings, reviews).
  prefs: []
  type: TYPE_NORMAL
- en: For a different example, if you were developing an AI image recognition tool
    for a social media app, you’d rely on open source image datasets, publicly available
    photos, or even user-uploaded content to build your dataset. This would involve
    collecting and manually labeling thousands of images into various categories to
    train the model to accurately identify objects in new images. The process might
    also include pulling data from image repositories.
  prefs: []
  type: TYPE_NORMAL
- en: Data collection is just the starting point. The value of data comes from how
    we label, classify, and make meaning out of information. In data science, the
    task of cleaning, labeling, and structuring data in a format suitable for model
    training is known as *data preprocessing*. This process starts with data cleaning.
    This involves removing or correcting inaccurate, incomplete, or irrelevant data
    points, which can significantly skew the outcomes of any analysis. Once we have
    a clean dataset, we continue to label data. By classifying data, we help the model
    learn to correctly identify input data. Moreover, classifying data into appropriate
    categories makes it easier to apply specific analyses and predictive models that
    require structured inputs. This classification might involve sorting data into
    predefined categories or creating new ones that better represent the underlying
    patterns and relationships.
  prefs: []
  type: TYPE_NORMAL
- en: Data collection and processing is not a one-time task; it’s an evolving process.
    As you gather more user interactions or receive more content, you’ll need to refine
    your data pipeline continually. As the environment changes and user behaviors
    evolve, routine updates to the datasets help ensure that models are trained on
    quality data.
  prefs: []
  type: TYPE_NORMAL
- en: Model Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Model training is the core phase of developing your product. This is where the
    magic happens, as your data is fed into the algorithms to create a model that
    can make predictions or provide insights. You need to embrace an experimental
    mindset, because you might try different algorithms, adjust hyperparameters, and
    evaluate initial performance to find the best approach.
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, it’s important to state the difference between an algorithm and
    a model in the context of data science and ML. While these terms are often used
    interchangeably, they refer to distinct concepts.
  prefs: []
  type: TYPE_NORMAL
- en: An *algorithm* is a set of rules that defines how to perform a task, in many
    instances, to make decisions. For example, decision trees, regression, and clustering
    are types of algorithms that describe the steps needed to solve a problem.
  prefs: []
  type: TYPE_NORMAL
- en: A *model*, on the other hand, is the specific use case of an algorithm that
    has been trained on data to solve a unique problem. A model is what you get when
    you feed data through an algorithm and allow it to learn from that data. It includes
    not only the algorithm’s structure but also the optimized parameters that make
    predictions or decisions based on similar data to the ones it was trained on.
    For instance, a model might be a specific decision tree that classifies whether
    an image is a cat or a dog determined by learning from a set of training images.
  prefs: []
  type: TYPE_NORMAL
- en: While an algorithm can remain the same, different models can be developed from
    it by training on different datasets. This flexibility allows models to be optimized
    for unique business applications. For instance, if you’re building a chatbot for
    customer support, you might start by training a simple NLP model using a dataset
    of past customer interactions. During this phase, you would select a relevant
    model (perhaps a transformer-based model, like GPT) and train it to understand
    and respond to various customer queries. You might need to revisit this step multiple
    times, tweaking the model to improve accuracy and relevance.
  prefs: []
  type: TYPE_NORMAL
- en: As an AI PM, understanding the basics of this phase and the trade-offs among
    the different approaches will help you communicate effectively with your data
    scientists. While you will never need to code as an AI PM, you will need to demonstrate
    AI awareness, especially when it comes to algorithms. At the end of this chapter
    you will find [Figure 3-5](#ch03_figure_6_1736793246781037), a map of AI algorithms
    and applications, to help you understand what goes into model training and algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Validation and Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once your model is trained, the next step is validation and testing. This phase
    is crucial because it determines how well your model generalizes to new, unseen
    data. You’ll use separate validation datasets to test the model’s accuracy, reliability,
    and overall performance.
  prefs: []
  type: TYPE_NORMAL
- en: For the content recommendation system, you might test the model by running it
    on a separate set of user data that wasn’t included in the training phase. This
    will help you see how well the model can predict user preferences and identify
    any biases or gaps in its recommendations. Similarly, for the chatbot, validation
    might involve testing the model with a variety of real-world queries to see if
    it provides helpful, accurate responses.
  prefs: []
  type: TYPE_NORMAL
- en: Testing is an iterative process. You might find that the model doesn’t perform
    as expected or that it introduces unintended biases. In these cases, you’ll need
    to go back to the previous phase—model training—and refine your approach. The
    cycle of training, validation, and adjustment is repeated until the model meets
    the MVQ required to launch.
  prefs: []
  type: TYPE_NORMAL
- en: Setting the MVQ is a critical decision, and there’s no single “right” or “wrong”
    threshold. As the PM, you determine this based on several factors, including user
    expectations, business goals, risk tolerance, and the specific use case of the
    AI product. For example, an MVQ for an AI-driven content recommendation system
    might be achieving a certain level of user satisfaction (often measured by qualitative
    metrics such as NPS and CSAT). In contrast, the MVQ for an AI medical diagnostic
    tool might require a higher threshold for accuracy to ensure patient safety, such
    as a 95% success rate in identifying a particular condition.
  prefs: []
  type: TYPE_NORMAL
- en: This iterative loop is key to building a robust AI product that provides reliable,
    valuable outcomes for users.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the model has been validated and meets the MVQ, it’s time for deployment.
    Deployment is when the model moves from the development environment into a production
    environment and eventually goes live to the users. This step involves integrating
    the trained model into the product’s infrastructure, setting up the necessary
    environments (such as cloud services and APIs), and ensuring that the model can
    interact with other system components effectively.
  prefs: []
  type: TYPE_NORMAL
- en: In our content recommendation system example, deployment would involve connecting
    the model to the streaming platform, where it can access user interaction data
    in real time to make personalized content suggestions. For the chatbot, deployment
    might mean integrating it with a company’s customer support platform, allowing
    it to handle customer queries directly while learning from new interactions.
  prefs: []
  type: TYPE_NORMAL
- en: Remember to Keep Humans in the Loop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One “horizontal” aspect that cuts across all stages of the AI lifecycle is the
    necessity of keeping humans in the loop. While AI brings powerful capabilities,
    it’s essential to remember that these systems function best when working alongside
    human expertise and oversight. Keeping humans in the loop ensures that your AI
    product not only learns from the data but also aligns with user needs, ethical
    standards, and business goals. Each stage of the AI lifecycle benefits from human
    involvement.
  prefs: []
  type: TYPE_NORMAL
- en: During the model-training phase, human input is crucial. Data labeling often
    requires human expertise, especially in complex domains such as medical imaging
    and financial analysis. Involving human experts helps ensure that the model is
    trained on accurate, contextually relevant data, reducing biases and errors in
    the outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: In the validation phase, human evaluation is essential for interpreting results
    and understanding the model’s strengths and limitations. Humans can identify subtle
    errors or biases that automated metrics might overlook, which is crucial for models
    deployed in high-stakes environments such as healthcare and autonomous driving.
  prefs: []
  type: TYPE_NORMAL
- en: Even after deployment, human feedback loops are necessary. AI products should
    allow users to provide real-time feedback on recommendations or decisions. This
    feedback can then be fed back into the data collection and model retraining phases,
    creating an ongoing cycle of improvement.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 3-4](#ch03_figure_4_1736793246780958) illustrates where human input
    fits into the AI lifecycle. You’ll notice that human involvement isn’t isolated
    to a single phase; rather, it’s interwoven throughout the entire lifecycle. This
    ongoing collaboration ensures that the AI product remains adaptable, ethical,
    and aligned with user needs.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0304.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3-4\. Human interaction in each stage of the AIPDL (source: Dr. Marily
    Nika)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Mapping AI Algorithms and Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I often say that AI is not a product. Rather, it’s a suite of technologies and
    methodologies that empower a wide range of products and solutions across various
    industries. The map I created, shown in [Figure 3-5](#ch03_figure_6_1736793246781037)
    (larger version [available online](https://oreil.ly/KDanI)), provides an overview
    of how these technologies converge to create impactful and innovative applications.
    We’ll explore the map, moving from core concepts to practical applications, to
    see how AI components integrate into real-world scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: This map will help you understand what kind of AI *superpower* enables what
    kind of *AI-powered user experience*. There is, of course, no one-size-fits-all
    recipe, and there is significant overlap in these categories. However, my hope
    in creating this for you is to help you map out the different types of learning
    methods, algorithms, applications, use cases, and real-world examples. Please
    note this is not meant to serve as an engineering resource, and there are really
    infinite ways to visualize this, so I am not optimizing for accuracy, just for
    knowledge sharing (and fun!).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0305.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3-5\. AI applications and algorithms map (source: Dr. Marily Nika)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s break down these categories:'
  prefs: []
  type: TYPE_NORMAL
- en: Learning method
  prefs: []
  type: TYPE_NORMAL
- en: The term *learning method* in AI refers to an approach or technique used to
    train an ML model. This method determines how a model learns from data to make
    predictions or decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm or model
  prefs: []
  type: TYPE_NORMAL
- en: An *algorithm* in AI is a set of rules or instructions designed to perform a
    specific task or solve a particular problem. A *model* in AI is a specific implementation
    of an algorithm that has been trained on data to predict outcomes or understand
    patterns. (I’ve bundled these two concepts due to their intertwined nature.)
  prefs: []
  type: TYPE_NORMAL
- en: Applications
  prefs: []
  type: TYPE_NORMAL
- en: The term *application* refers to the practical use of an AI model or algorithm
    to perform specific tasks that are valuable in real-world scenarios, or in other
    words, the AI product itself.
  prefs: []
  type: TYPE_NORMAL
- en: Use cases
  prefs: []
  type: TYPE_NORMAL
- en: 'You know what a *use case* is: how a product or feature can solve a problem
    or fulfill a need for its users. It’s a scenario in which AI technology can be
    applied to solve a problem or enhance a process in a specific context.'
  prefs: []
  type: TYPE_NORMAL
- en: This is a high-level graph that maps algorithms to use cases from a product
    perspective, purely for illustrative purposes. The reality of AI product development
    often involves a more nuanced and complex interplay between different algorithms
    and use cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by looking into each of the foundational AI learning methods that
    form the quadrants of the map: supervised learning, self-supervised learning,
    unsupervised learning, and reinforcement learning.'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Supervised learning*involves training a model on a labeled dataset, which
    means that each piece of data in the training set is paired with the correct answer
    or outcome. This is the most common type of learning used in AI and it is suitable
    for a wide range of applications, from image recognition to predicting consumer
    behavior. It requires a substantial amount of labeled data and is generally used
    where the outputs are known and need to be predicted based on new inputs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Supervised learning is suitable for classification tasks, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment analysis
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing text data from reviews or social media to determine their sentiment
    (positive, negative, neutral)
  prefs: []
  type: TYPE_NORMAL
- en: Smart matching
  prefs: []
  type: TYPE_NORMAL
- en: Using AI to match users or products in services such as dating apps or job portals
    based on learned preferences
  prefs: []
  type: TYPE_NORMAL
- en: Image classification
  prefs: []
  type: TYPE_NORMAL
- en: Identifying objects within an image and categorizing them into predefined classes
  prefs: []
  type: TYPE_NORMAL
- en: Diagnostics
  prefs: []
  type: TYPE_NORMAL
- en: In healthcare, using image data to diagnose diseases from scans or tests
  prefs: []
  type: TYPE_NORMAL
- en: 'It is also helpful for regression tasks, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Forecasting
  prefs: []
  type: TYPE_NORMAL
- en: Predicting future values such as sales or stock prices based on historical data
  prefs: []
  type: TYPE_NORMAL
- en: Optimization
  prefs: []
  type: TYPE_NORMAL
- en: Adjusting inputs to maximize or minimize certain outcomes, useful in logistics
    and resource allocation
  prefs: []
  type: TYPE_NORMAL
- en: Time-series analysis
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing time-ordered data points to predict future points or trends
  prefs: []
  type: TYPE_NORMAL
- en: There are many applications and use cases for supervised learning models. For
    example, logistic regression and decision trees have become essential tools across
    various industries, with financial services being one of the most prominent adopters.
    These models are particularly effective in fraud detection, where they are trained
    on preclassified historical data—transactions that have already been labeled as
    either fraudulent or legitimate.
  prefs: []
  type: TYPE_NORMAL
- en: By analyzing this data, the model learns to identify subtle patterns and anomalies
    that may suggest fraudulent activity. For example, if a credit card transaction
    differs significantly from a customer’s typical spending habits or takes place
    in an unexpected geographic location, the system can flag it for further review.
    This predictive capability helps protect both consumers and financial institutions,
    reducing losses and contributing to a more secure banking experience. Similarly,
    healthcare companies apply supervised learning in medical diagnostics, especially
    through image classification techniques. These models can analyze medical images,
    such as scans or X-rays, to help diagnose diseases, offering invaluable support
    to healthcare professionals in delivering accurate and timely care.
  prefs: []
  type: TYPE_NORMAL
- en: Self-supervised learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Self-supervised learning* is a type of ML in which the system learns to understand
    data by itself, without explicit labels provided by humans. Instead, it generates
    its own labels from the data by predicting missing parts or properties of the
    data. LLMs and transformers are crucial in self-supervised learning for understanding
    and generating humanlike text. These models, trained on vast amounts of unlabeled
    text data, can predict text continuation and generate coherent pieces of text.
    Self-supervised learning is especially useful for tasks such as natural language
    understanding, where labeled data can be scarce or expensive to produce.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Self-supervised learning performs functions such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Speech processing
  prefs: []
  type: TYPE_NORMAL
- en: Used to develop models that can transcribe speech without needing labeled data,
    by predicting the next word or sound in sequences
  prefs: []
  type: TYPE_NORMAL
- en: Multimodal learning
  prefs: []
  type: TYPE_NORMAL
- en: Involves training models to process and integrate information from different
    types of data, such as text and images, to perform tasks like automatic captioning
  prefs: []
  type: TYPE_NORMAL
- en: NLP
  prefs: []
  type: TYPE_NORMAL
- en: Used extensively to improve language models that power applications such as
    sentiment analysis and language translation
  prefs: []
  type: TYPE_NORMAL
- en: 'Its applications and use cases include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Chatbots
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing advanced NLP capabilities, helps chatbots generate more relevant and
    context-aware responses
  prefs: []
  type: TYPE_NORMAL
- en: Content synthesis
  prefs: []
  type: TYPE_NORMAL
- en: Enables the automated creation of content, such as articles and reports, that
    feels natural and humanlike
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Unsupervised learning* involves training a model on data that has not been
    labeled, annotated, or classified. The model learns without any guidance, finding
    patterns and relationships in the input data. This method is crucial for discovering
    hidden patterns or intrinsic structures within data. It is often used for clustering,
    association, and dimensionality reduction tasks in datasets where we do not know
    the outcome in advance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unsupervised learning is strong at clustering tasks, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection
  prefs: []
  type: TYPE_NORMAL
- en: Identifying unusual patterns or outliers in data, useful in fraud detection
  prefs: []
  type: TYPE_NORMAL
- en: Image segmentation
  prefs: []
  type: TYPE_NORMAL
- en: Dividing an image into multiple segments based on the similarity of pixels
  prefs: []
  type: TYPE_NORMAL
- en: Customer segmentation
  prefs: []
  type: TYPE_NORMAL
- en: Grouping customers based on purchasing behavior or preferences to tailor marketing
    strategies
  prefs: []
  type: TYPE_NORMAL
- en: 'It also helps in dimensionality reduction tasks such as these:'
  prefs: []
  type: TYPE_NORMAL
- en: Compression
  prefs: []
  type: TYPE_NORMAL
- en: Reducing the size of data while maintaining its essential features, crucial
    for storage and analysis
  prefs: []
  type: TYPE_NORMAL
- en: Visualization
  prefs: []
  type: TYPE_NORMAL
- en: Transforming high-dimensional data into visual formats that are easier to understand
    and analyze
  prefs: []
  type: TYPE_NORMAL
- en: 'Applications and use cases for unsupervised learning include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection
  prefs: []
  type: TYPE_NORMAL
- en: Identifying fraudulent credit card transactions
  prefs: []
  type: TYPE_NORMAL
- en: Customer segmentation
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing user recommendations and targeted advertising
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Reinforcement learning* (RL) is where an *agent*, a decision-making entity
    that takes actions to achieve a goal, learns by interacting with its environment
    and receiving rewards or penalties based on its actions. Neural networks and deep
    learning enhance RL by processing complex data inputs, allowing the agent to learn
    more sophisticated strategies. Neural networks and deep learning are key components
    in RL, especially in complex scenarios such as autonomous driving. *Neural networks*,
    structured like the human brain, consist of interconnected layers that process
    information. *Deep learning* uses multiple layers to enable sophisticated decision
    making.'
  prefs: []
  type: TYPE_NORMAL
- en: 'RL is good for prediction and evaluation tasks such as personalized medicine,
    which involves tailoring healthcare treatments to individual patients based on
    predicted outcomes from different treatment plans. It is also strong for control
    and optimization tasks such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Financial trading
  prefs: []
  type: TYPE_NORMAL
- en: Using AI to make buy or sell decisions in real-time trading scenarios
  prefs: []
  type: TYPE_NORMAL
- en: Robotics and automation
  prefs: []
  type: TYPE_NORMAL
- en: Programming robots to perform tasks independently in manufacturing or service
    environments
  prefs: []
  type: TYPE_NORMAL
- en: 'Exploration and exploitation tasks aided by RL include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Multi-armed bandits
  prefs: []
  type: TYPE_NORMAL
- en: A problem setup in which an algorithm must choose among multiple options with
    uncertain returns, optimizing for maximum reward
  prefs: []
  type: TYPE_NORMAL
- en: Curiosity-driven exploration
  prefs: []
  type: TYPE_NORMAL
- en: Encouraging AI systems to explore new or less-understood environments or datasets
    to improve learning
  prefs: []
  type: TYPE_NORMAL
- en: 'Applications and use cases for RL ​include ​the ​following:'
  prefs: []
  type: TYPE_NORMAL
- en: Netflix
  prefs: []
  type: TYPE_NORMAL
- en: Uses [multi-armed bandit algorithms](https://oreil.ly/qwFQf) for personalized
    viewing recommendations
  prefs: []
  type: TYPE_NORMAL
- en: Autonomous vehicles
  prefs: []
  type: TYPE_NORMAL
- en: Use deep learning and neural networks to process real-time data from cameras
    and sensors, helping the vehicle navigate safely by recognizing pedestrians, vehicles,
    and traffic signs
  prefs: []
  type: TYPE_NORMAL
- en: RL algorithms
  prefs: []
  type: TYPE_NORMAL
- en: Empower robots to explore and perform tasks autonomously in manufacturing and
    service environments
  prefs: []
  type: TYPE_NORMAL
- en: Responsible AI Practices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Responsible AI practices are essential for ensuring that AI technologies are
    developed and deployed in ways that prioritize human welfare, fairness, and transparency.
    For AI PMs, this means embedding ethical considerations into every stage of the
    product and AI lifecycle. Lead your team by asking critical questions such as
    “Who will this product impact?” and “What potential harms might arise?”
  prefs: []
  type: TYPE_NORMAL
- en: When you identify potential risks, leverage ethical frameworks such as [FATE](https://oreil.ly/2__Yz)
    (fairness, accountability, transparency, ethics) and the [AI Ethics Canvas](https://oreil.ly/v5YYH)
    to guide the choice of algorithms, data collection methods, and model architectures.
    Don’t stop there; be sure to monitor product performance and social impact metrics
    to detect and correct bias, errors, or misuse of the product in real-world settings.
    Regular audits and updates to the model based on ethical guidelines and user feedback
    are necessary to maintain responsible AI practices throughout the product’s lifecycle.
  prefs: []
  type: TYPE_NORMAL
- en: Proactively identifying risks in AI systems is critical to preventing unintended
    societal harms, which can range from algorithmic bias to violating privacy and
    perpetuating stereotypes. You can conduct various risk assessments by evaluating
    the fairness of datasets, testing for potential biases in model outputs, and conducting
    scenario analysis to identify unintended use cases. For example, an AI-based hiring
    tool could unintentionally favor certain demographics if the training data is
    skewed, leading to discriminatory hiring practices. Similarly, a predictive policing
    algorithm might disproportionately target minority communities if trained on historically
    biased data. These risks, if unaddressed, can lead to public backlash, loss of
    trust, and even regulatory penalties.
  prefs: []
  type: TYPE_NORMAL
- en: You can mitigate these risks by creating diverse datasets. AI models are only
    as good as the data they are trained on, and ensuring that datasets represent
    a wide range of demographic, geographic, and contextual diversity is essential
    to minimizing biases. For example, a face recognition system trained predominantly
    on images of lighter-skinned individuals may fail to accurately identify darker-skinned
    individuals, leading to inequitable outcomes. To ensure robustness, AI PMs should
    stress-test the product using a wide array of edge cases.
  prefs: []
  type: TYPE_NORMAL
- en: Ethics and compliance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Compliance isn’t just about checking boxes; it’s about ensuring that AI products
    are trustworthy, are ethical, and meet the legal standards that protect users.
    This means you and your team must prioritize how data is collected, stored, and
    used; especially when handling sensitive information. The best practice is to
    anonymize, encrypt, and limit data collection and usage to only what is absolutely
    necessary to power the product. There are various policies that set guidelines
    for ethical AI practices. Proactively accounting for regulations such as GDPR
    and the AI Act ensures that the products are designed to be transparent and robust.
  prefs: []
  type: TYPE_NORMAL
- en: Explainable AI (XAI)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: XAI is about designing AI systems to be easily understandable to the people
    who use them. At its core, it ensures that AI decisions don’t feel like they’re
    coming out of a “black box,” where the user doesn’t know why or how the system
    reached the decision it provided. XAI is especially important when designing AI
    products for high-risk situations; for instance, doctors diagnosing patients,
    financial advisors assessing risk, or customer service systems that interact with
    users directly. People need to trust the technology. That trust hinges on understanding
    not just what the AI decided, but also how it got there.
  prefs: []
  type: TYPE_NORMAL
- en: Making AI explainable means implementing methods that can break down algorithms
    and decisions into human-friendly explanations. For instance, feature importance
    scores can highlight which factors mattered most to the AI in making a prediction,
    such as showing that a patient’s age and medical history were key in suggesting
    a diagnosis. Visualization tools, such as decision trees or heatmaps, can also
    help demystify the inner workings of complex models. Counterfactual explanations
    are another useful strategy to communicate what would need to change to achieve
    a different outcome; for example, “If your income were $5,000 higher, your loan
    application would be more likely to get approved.” These methods make AI decisions
    more transparent, helping users and stakeholders understand what’s happening under
    the hood.
  prefs: []
  type: TYPE_NORMAL
- en: But explainability isn’t just about the user; it’s a key component for the teams
    building the technology. Engineers and data scientists rely on XAI techniques
    to debug and refine models. If something goes wrong, like the AI making biased
    predictions, explainability tools can quickly pinpoint the issue. XAI practices
    reduce development risks and help ensure that AI systems comply with ethical guidelines
    and regulatory requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter discussed the essential skills required for managing an AI product,
    covering the spectrum from general project management principles to the specific
    technical knowledge of AI. We explored crucial AI concepts such as ML algorithms,
    model training, model quality, and data management—each vital for developing,
    deploying, and maintaining reliable and effective AI systems. The discussions
    highlighted the importance of understanding these technical elements, the need
    for adherence to ethical standards, and the value of transparency in building
    user trust.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of a solution trade space highlights the importance of making informed
    strategic decisions that account for multiple interconnected factors. By defining
    your unique trade space, you can more effectively navigate the complexities of
    AI product development, ensuring that your final product is innovative and aligned
    with your long-term goals.
  prefs: []
  type: TYPE_NORMAL
- en: After establishing the multifaceted skill set required by AI PMs, it’s clear
    that this role demands a unique blend of technical acumen and broad management
    skills. This role acts as the crucial link between AI’s technological capabilities
    and users’ real-world needs, ensuring that AI solutions are both impactful and
    sustainable. In [Chapter 4](ch04.html#ch04_the_ai_pm_s_day_to_day_1736793247322408),
    we will take a closer look at what a typical day in the life of an AI PM entails,
    providing a practical perspective on how these skills are applied to navigate
    daily challenges and opportunities in the field.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch03.html#id752-marker)) *Supervised learning* is a type of ML in which
    models are trained using labeled data, allowing the algorithm to predict outcomes
    based on defined criteria. *Unsupervised learning* involves training models on
    data without labels, asking the algorithm to identify patterns and structures
    from the data itself.
  prefs: []
  type: TYPE_NORMAL
