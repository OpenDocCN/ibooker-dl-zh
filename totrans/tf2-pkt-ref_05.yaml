- en: Chapter 5\. Data Pipelines for Streaming Ingestion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。流摄入的数据管道
- en: Data ingestion is an important part of your workflow. There are several steps
    to perform before raw data is in the correct input format expected by the model.
    These steps are known as the *data pipeline*. Steps in a data pipeline are important
    because they will also be applied to the production data, which is the data consumed
    by the model when the model is deployed. Whether you are in the process of building
    and debugging a model or getting it ready for deployment, you need to format the
    raw data for the model’s consumption.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据摄入是你工作流程中的一个重要部分。在原始数据达到模型期望的正确输入格式之前，需要执行几个步骤。这些步骤被称为 *数据管道*。数据管道中的步骤很重要，因为它们也将应用于生产数据，这是模型在部署时使用的数据。无论你是在构建和调试模型还是准备部署模型，你都需要为模型的消费格式化原始数据。
- en: It is important to use the same series of steps in the model-building process
    as you do in deployment planning, so that the test data is processed the same
    way as the training data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型构建过程中使用与部署规划相同的一系列步骤是很重要的，这样测试数据就会与训练数据以相同的方式处理。
- en: In [Chapter 3](ch03.xhtml#data_preprocessing) you learned how the Python generator
    works, and in [Chapter 4](ch04.xhtml#reusable_model_elements) you learned how
    to use the `flow_from_directory` method for transfer learning. In this chapter,
    you will see more of the tools that TensorFlow provides to handle other data types,
    such as text and numeric arrays. You’ll also learn how to handle another type
    of file structure for images. File organization becomes especially important when
    handling text or images for model training because it is common to use directory
    names as labels. This chapter will recommend a practice for directory organization
    when it comes to building and training a text or image classification model.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](ch03.xhtml#data_preprocessing)中，你学习了Python生成器的工作原理，在[第4章](ch04.xhtml#reusable_model_elements)中，你学习了如何使用
    `flow_from_directory` 方法进行迁移学习。在本章中，你将看到 TensorFlow 提供的更多处理其他数据类型（如文本和数值数组）的工具。你还将学习如何处理另一种图像文件结构。当处理文本或图像进行模型训练时，文件组织变得尤为重要，因为通常会使用目录名称作为标签。本章将在构建和训练文本或图像分类模型时推荐一种目录组织实践。
- en: Streaming Text Files with the text_dataset_from_directory Function
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 `text_dataset_from_directory` 函数流式文本文件
- en: You can stream pretty much any files in a pipeline, as long as you organize
    the directory structure correctly. In this section we’ll look at an example using
    text files, which would apply in use cases such as text classification and sentiment
    analysis. Here we are interested in the `text_dataset_from_directory` function,
    which works similarly to the `flow_from_directory` method that we used for streaming
    images.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 只要正确组织目录结构，你几乎可以在管道中流式传输任何文件。在本节中，我们将看一个使用文本文件的示例，这在文本分类和情感分析等用例中会很有用。这里我们感兴趣的是
    `text_dataset_from_directory` 函数，它的工作方式类似于我们用于流式传输图像的 `flow_from_directory` 方法。
- en: 'In order to use this function for a text classification problem, you have to
    follow the directory organization described in this section. In your current working
    directory, you must have subdirectories with names that match the labels or class
    names for your text. For example, if you are doing text classification model training,
    you have to organize your training texts into positives and negatives. This is
    the process of training data labeling; it has to be done to set up the data for
    the model to learn what a positive or negative comment looks like. If the text
    is a corpus of movie reviews classified as positive or negative, then the subdirectory
    names might be *pos* and *neg*. Within each subdirectory, you have all the text
    files for that class. Therefore, your directory structure would be similar to
    this:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将这个函数用于文本分类问题，你必须按照本节中描述的目录组织。在你当前的工作目录中，你必须有与文本标签或类名匹配的子目录。例如，如果你正在进行文本分类模型训练，你必须将训练文本组织成积极和消极。这是训练数据标记的过程；必须这样做以设置数据，让模型学习积极或消极评论的样子。如果文本是被分类为积极或消极的电影评论语料库，那么子目录的名称可能是
    *pos* 和 *neg*。在每个子目录中，你有该类别的所有文本文件。因此，你的目录结构将类似于这样：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As an example, let’s try building a data ingestion pipeline for text data using
    a corpus of movie reviews from the Internet Movie Database (IMDB).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，让我们尝试使用来自互联网电影数据库（IMDB）的电影评论语料库构建一个文本数据摄入管道。
- en: Downloading Text Data and Setting Up Directories
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载文本数据并设置目录
- en: 'The text data you will use for this section is the [Large Movie Review Dataset](https://oreil.ly/EabEP).
    You can download it directly or use the `get_file` function to do so. Let’s start
    by importing the necessary libraries and then downloading the file:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本节中使用的文本数据是[大型电影评论数据集](https://oreil.ly/EabEP)。你可以直接下载它，也可以使用 `get_file`
    函数来下载。让我们首先导入必要的库，然后下载文件：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Conveniently, by passing `untar=True`, the `get_file` function also decompresses
    the file. This will create a directory called *aclImdb* in the current directory.
    Let’s encode this file path as a variable for future reference:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通过传递 `untar=True`，`get_file` 函数也会解压文件。这将在当前目录中创建一个名为 *aclImdb* 的目录。让我们将这个文件路径编码为一个变量以供将来参考：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'List this directory to see what’s inside:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 列出这个目录以查看里面有什么：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'There is one directory (*unsup*) not in use, so you’ll need to get rid of it:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个目录（*unsup*）没有在使用中，所以你需要将其删除：
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now take a look at the content in the training directory:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在看一下训练目录中的内容：
- en: '[PRE5]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The two directories are *pos* and *neg*. These names will be encoded as categorical
    variables in the text classification task.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个目录是 *pos* 和 *neg*。这些名称将在文本分类任务中被编码为分类变量。
- en: It’s important to clean up your subdirectories and ensure that all directories
    contain text for the classification training. If we had not removed that unused
    directory, its name would have become a categorical variable, which is not our
    intention at all. The other files there are fine and don’t impact the outcome
    here. Again, remember that directory names are used as labels, so make sure you
    have *only* directories that are intended for the model to learn and map to labels.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 清理子目录并确保所有目录都包含用于分类训练的文本非常重要。如果我们没有删除那个未使用的目录，它的名称将成为一个分类变量，这绝不是我们的意图。那里的其他文件都很好，不会影响这里的结果。再次提醒，目录名称用作标签，因此请确保*只有*用于模型学习和映射到标签的目录。
- en: Creating the Data Pipeline
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建数据流水线
- en: 'Now that your files are properly organized, you’re ready to create the data
    pipeline. Let’s set up a few variables:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您的文件已经正确组织，可以开始创建数据流水线了。让我们设置一些变量：
- en: '[PRE6]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The batch size tells the generator how many samples to use in one iteration
    of training. It’s also a good idea to assign a seed so that each time you execute
    the generator, it streams the files in the same order. Without the seed assignment,
    the generator will output the files in random order.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 批量大小告诉生成器在训练的一个迭代中使用多少样本。还可以分配一个种子，以便每次执行生成器时，它以相同的顺序流式传输文件。如果不分配种子，生成器将以随机顺序输出文件。
- en: 'Then define a pipeline using the `test_dataset_from_directory` function. It
    will return a dataset object:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用`test_dataset_from_directory`函数定义一个流水线。它将返回一个数据集对象：
- en: '[PRE7]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In this case, the directory that contains subdirectories is *aclImdb/train.*
    This pipeline definition is for 80% of the training dataset, which is designated
    by `subset='training'`. The other 20% is reserved for cross validation.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，包含子目录的目录是*aclImdb/train*。此流水线定义用于80%的训练数据集，由`subset='training'`指定。其他20%用于交叉验证。
- en: 'For the cross-validation data, you’ll define the pipeline in a similar fashion:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于交叉验证数据，您将以类似的方式定义流水线：
- en: '[PRE8]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Once you execute the two pipelines in the preeding code, this is the expected
    output:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您在上述代码中执行了这两个流水线，这就是预期的输出：
- en: '[PRE9]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Because there are two subdirectories in *aclImdb/train*, the generator recognizes
    them as classes. And because of the 20% split, 5,000 files are held for cross
    validation.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因为*aclImdb/train*中有两个子目录，生成器将其识别为类。由于20%的拆分，有5,000个文件用于交叉验证。
- en: Inspecting the Dataset
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查数据集
- en: 'With the generator in place, let’s take a look at the contents of these files.
    The way to inspect a TensorFlow dataset is to iterate through it and select a
    few samples. The following code snippet takes the first batch of samples and then
    randomly selects five rows of movie reviews:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有了生成器，让我们来查看这些文件的内容。检查TensorFlow数据集的方法是遍历它并选择一些样本。以下代码片段获取第一批样本，然后随机选择五行电影评论：
- en: '[PRE10]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, `idx` is a list that holds five randomly generated integers within the
    range of `batch_size`. Then `idx` is used as the index to select the text and
    label from the dataset.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`idx`是一个列表，其中包含在`batch_size`范围内生成的五个随机整数。然后，`idx`被用作索引，从数据集中选择文本和标签。
- en: 'The dataset will yield a tuple consisting of `text_batch` and `label_batch`;
    a tuple is useful here because it keeps track of the text and its label (class).
    These are five randomly selected rows of text and corresponding labels:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集将产生一个元组，包含`text_batch`和`label_batch`；元组在这里很有用，因为它跟踪文本及其标签（类）。这是五个随机选择的文本行和相应的标签：
- en: '[PRE11]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The first two are positive reviews (indicated by the digit 1), and the last
    three are negative reviews (indicated by 0). This method is called *grouping by
    class.*
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个是正面评价（由数字1表示），最后三个是负面评价（由0表示）。这种方法称为*按类分组*。
- en: Summary
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this section, you learned how to stream text datasets. The method is similar
    to how images are streamed, with the exception of using the `text_dataset_from_directory`
    function. You learned grouping by class and the recommended directory organization
    for your data, which is important because directory names are used as labels for
    the model training process. In both image and text classification, you saw that
    directory names are used as labels.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您学习了如何流式传输文本数据集。该方法类似于图像的流式传输，唯一的区别是使用`text_dataset_from_directory`函数。您学习了按类分组以及数据的推荐目录组织方式，这很重要，因为目录名称用作模型训练过程中的标签。在图像和文本分类中，您看到目录名称被用作标签。
- en: Streaming Images with a File List Using the flow_from_dataframe Method
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用flow_from_dataframe方法流式传输图像文件列表
- en: How your data is organized affects how you deal with the data ingestion pipeline.
    This is especially important with image data. During the image classification
    task in [Chapter 4](ch04.xhtml#reusable_model_elements), you saw how different
    types of flowers were organized into directories with names corresponding to each
    flower type.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的组织方式影响您处理数据摄入流水线的方式。这在处理图像数据时尤为重要。在[第4章](ch04.xhtml#reusable_model_elements)中的图像分类任务中，您看到不同类型的花卉是如何组织到与每种花卉类型对应的目录中的。
- en: Grouping by class is not the only file organization method you will encounter
    in the real world. In another common style, shown in [Figure 5-1](#another_directory_structure_for_storing),
    all images are thrown into one directory (which means it doesn’t matter what you
    name the directory).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 按类分组不是您在现实世界中会遇到的唯一文件组织方法。在另一种常见风格中，如[图5-1](#another_directory_structure_for_storing)所示，所有图像都被放入一个目录中（这意味着您命名目录的方式并不重要）。
- en: '![Another directory structure for storing image files](Images/t2pr_0501.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: 另一种存储图像文件的目录结构
- en: Figure 5-1\. Another directory structure for storing image files
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1。另一种存储图像文件的目录结构
- en: 'In this organization, you see that at the same level as the directory *flowers*,
    which contains all the images, there is a CSV file called *all_labels.csv*. This
    file contains two columns: one with all the filenames and one with the labels
    for those files:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个组织中，您会看到与包含所有图像的目录*flowers*在同一级别的位置，有一个名为*all_labels.csv*的CSV文件。该文件包含两列：一个包含所有文件名，另一个包含这些文件的标签：
- en: '[PRE12]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: To use image files stored in this format, you’ll need to use *all_labels.csv*
    to train the model to recognize each image’s label. This is where the `flow_from_dataframe`
    method comes in.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用以这种格式存储的图像文件，您需要使用*all_labels.csv*来训练模型以识别每个图像的标签。这就是`flow_from_dataframe`方法的用武之地。
- en: Downloading Images and Setting Up Directories
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载图像并设置目录
- en: Let’s start with an example in which images are organized into a single directory.
    [Download the file](https://oreil.ly/WtKvA) *flower_photos.zip*, unzip it, and
    you will see the directory structure shown in [Figure 5-1](#another_directory_structure_for_storing).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个示例开始，其中图像组织在一个单独的目录中。[下载文件](https://oreil.ly/WtKvA) *flower_photos.zip*，解压缩后，您将看到[图5-1](#another_directory_structure_for_storing)中显示的目录结构：
- en: 'Alternatively, if you’re working in a Jupyter Notebook environment, run the
    Linux command `wget` to download *flower_photos.zip*. Following is the command
    for a Jupyter Notebook’s cell:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您在Jupyter Notebook环境中工作，请运行Linux命令`wget`来下载*flower_photos.zip*。以下是Jupyter
    Notebook单元格的命令：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The preceding command downloads the file and places it in the current directory.
    Unzip the file with this Linux command:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令下载文件并将其放在当前目录中。使用此Linux命令解压缩文件：
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This creates a directory with the same name as the ZIP file:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个与ZIP文件同名的目录：
- en: '[PRE15]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As you can see, there is a directory named *flower_photos*. List its contents
    with the following command, and you will see exactly what’s shown in [Figure 5-1](#another_directory_structure_for_storing):'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，有一个名为*flower_photos*的目录。使用以下命令列出其内容，您将看到与[图5-1](#another_directory_structure_for_storing)中显示的内容完全相同：
- en: '[PRE16]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now that you have the directory structure and image files you need to work through
    this section’s example, you can start building a data pipeline to feed these images
    into an image classification model for training. And to make it easy on yourself,
    you’ll use the ResNet feature vector, a prebuilt model in TensorFlow Hub, so you
    don’t have to design a model,. You’ll stream these images into the training process
    with `ImageDataGenerator`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有了目录结构和图像文件，可以开始构建数据流水线，将这些图像馈送到用于训练的图像分类模型中。为了简化操作，您将使用ResNet特征向量，这是TensorFlow
    Hub中的一个预构建模型，因此您无需设计模型。您将使用`ImageDataGenerator`将这些图像流式传输到训练过程中。
- en: Creating the Data Ingestion Pipeline
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建数据摄入管道
- en: 'As usual, the first thing to do is import the necessary libraries:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，首先要做的是导入必要的库：
- en: '[PRE17]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Notice that you need the pandas library in this example. This library is used
    to parse the label files as a dataframe. This is how to read the label file into
    a pandas DataFrame:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在此示例中您需要pandas库。此库用于将标签文件解析为数据框。以下是如何将标签文件读取到pandas DataFrame中：
- en: '[PRE18]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: And if you take a look at the dataframe `traindf`, you will see the following
    content.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看数据框`traindf`，您将看到以下内容。
- en: '|   | **Filename** | **Label** |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|   | **文件名** | **标签** |'
- en: '| --- | --- | --- |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0 | 7176723954_e41618edc1_n.jpg | sunflowers |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 7176723954_e41618edc1_n.jpg | 向日葵 |'
- en: '| 1 | 2788276815_8f730bd942.jpg | roses |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2788276815_8f730bd942.jpg | 玫瑰 |'
- en: '| 2 | 6103898045_e066cdeedf_n.jpg | dandelion |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 6103898045_e066cdeedf_n.jpg | 蒲公英 |'
- en: '| 3 | 1441939151_b271408c8d_n.jpg | daisy |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 1441939151_b271408c8d_n.jpg | 雏菊 |'
- en: '| 4 | 2491600761_7e9d6776e8_m.jpg | roses |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 2491600761_7e9d6776e8_m.jpg | 玫瑰 |'
- en: '| ... | ... | ... |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... | ... |'
- en: '| 3615 | 9558628596_722c29ec60_m.jpg | sunflowers |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 3615 | 9558628596_722c29ec60_m.jpg | 向日葵 |'
- en: '| 3616 | 4580206494_9386c81ed8_n.jpg | tulips |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 3616 | 4580206494_9386c81ed8_n.jpg | 郁金香 |'
- en: 'Next, you need to create some variables to hold parameters to be used later:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要创建一些变量来保存稍后使用的参数：
- en: '[PRE19]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Also, remember that when we use the ResNet feature vector, we have to rescale
    the image pixel intensity to a range of [0, 1], which means for each image pixel,
    the intensity has to be divided by 255\. Also, we need to reserve a portion of
    the images for cross validation—say, 20%. So let’s define these criteria in a
    dictionary, which we can use as an input for our `ImageDataGenerator` definition:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，请记住，当我们使用ResNet特征向量时，我们必须将图像像素强度重新缩放到[0, 1]的范围内，这意味着对于每个图像像素，强度必须除以255。此外，我们需要保留一部分图像用于交叉验证，比如20%。因此，让我们在一个字典中定义这些标准，我们可以将其用作`ImageDataGenerator`定义的输入：
- en: '[PRE20]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Another dictionary will hold a few other arguments. The ResNet feature vector
    expects images to have pixel dimensions of 224 × 224, and we need to specify the
    batch size and resample algorithm as well:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个字典将保存一些其他参数。ResNet特征向量期望图像具有224×224的像素尺寸，我们还需要指定批处理大小和重采样算法：
- en: '[PRE21]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This dictionary will be used as an input in the data flow definition.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这个字典将作为数据流定义的输入。
- en: 'For training the images, this is how you would set up the generator definition:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练图像的生成器定义如下：
- en: '[PRE22]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Notice that we passed `datagen_kwargs` into the `ImageDataGenerator` instance.
    Next, we use the `flow_from_dataframe` method to create a data flow pipeline:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们将`datagen_kwargs`传递给`ImageDataGenerator`实例。接下来，我们使用`flow_from_dataframe`方法创建数据流水线：
- en: '[PRE23]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `ImageDataGenerator` we defined as `train_datagen` is used to invoke the
    `flow_from_dataframe` method. Let’s take a look a the input parameters. The first
    argument is `dataframe`, which is designated as `traindf`. Then `directory` specifies
    where images may be found in the directory path. `x_col` and `y_col` are the headers
    in `traindf`: `x_col` corresponds to column “file_name” as defined in *all_labels.csv*,
    and `y_col` is the column “label.” Now our generator knows how to match images
    to their labels.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义的`train_datagen`是用来调用`flow_from_dataframe`方法的。让我们看一下输入参数。第一个参数是`dataframe`，被指定为`traindf`。然后`directory`指定了在目录路径中可以找到图像的位置。`x_col`和`y_col`是`traindf`中的标题：`x_col`对应于在*all_labels.csv*中定义的列“file_name”，而`y_col`是列“label”。现在我们的生成器知道如何将图像与它们的标签匹配。
- en: Next, it specifies a subset to be `training`, as this is the training image
    generator. Seed is provided for reproducibility of batches. Images are shuffled,
    and image classes are designated to be categorical. Finally, `dataflow_kwargs`
    is passed into this `flow_from_dataframe` method so that raw images are resampled
    from their original resolution to 224 × 224 pixels.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，它指定了一个要进行`training`的子集，因为这是训练图像生成器。提供了种子以便批次的可重现性。图像被洗牌，图像类别被指定为分类。最后，`dataflow_kwargs`被传递到这个`flow_from_dataframe`方法中，以便将原始图像从其原始分辨率重新采样为224×224像素。
- en: 'This procedure is repeated for the validation image generator:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程对验证图像生成器也是重复的：
- en: '[PRE24]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Inspecting the Dataset
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查数据集
- en: 'Right now, the only way to examine the contents of a TensorFlow dataset is
    by iterating through it:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，检查TensorFlow数据集内容的唯一方法是通过迭代：
- en: '[PRE25]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The preceding code snippet acquires the first batch of images from `train_generator`,
    the output of which is a tuple consisting of `image_batch` and `label_batch`.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段从`train_generator`中获取了第一批图像，其输出是一个由`image_batch`和`label_batch`组成的元组。
- en: You will see 32 images (that’s the batch size). Some will look like [Figure 5-2](Images/#some_of_the_flower_images_in_the_dataset).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到32张图像（这是批处理大小）。有些看起来像[图5-2](Images/#some_of_the_flower_images_in_the_dataset)。
- en: '![Some of the flower images in the dataset](Images/t2pr_0502.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![数据集中一些花的图像](Images/t2pr_0502.png)'
- en: Figure 5-2\. Some of the flower images in the dataset
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-2\. 数据集中一些花的图像
- en: Now that the data ingestion pipeline is set up, you are ready to use it in the
    training process.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据摄入管道已经设置好，您可以在训练过程中使用它了。
- en: Building and Training the tf.keras Model
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建和训练tf.keras模型
- en: 'The following classification model is an example of how to use a prebuilt model
    in TensorFlow Hub:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 以下分类模型是如何在TensorFlow Hub中使用预构建模型的示例：
- en: '[PRE26]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Once the model architecture is ready, compile it:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型架构准备好，就编译它：
- en: '[PRE27]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Then launch the training process:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后启动训练过程：
- en: '[PRE28]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Notice that `train_generator` and `valid_generator` are passed into our `fit`
    function. These will generate samples of images as the training process progresses,
    until all epochs are completed. You should expect to see output similar to this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`train_generator`和`valid_generator`被传递到我们的`fit`函数中。这些将在训练过程中生成图像样本，直到所有时代完成。您应该期望看到类似于这样的输出：
- en: '[PRE29]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This indicates that you’ve successfully passed the training image generator
    and validation image generator into the training process, and that both generators
    can ingest data at training time. The result for validation data accuracy, `val_accuracy`,
    is a good indication that our choice of the ResNet feature vector works well for
    our use case of classifying flower images.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明您已成功将训练图像生成器和验证图像生成器传递到训练过程中，并且两个生成器都可以在训练时摄入数据。验证数据准确性`val_accuracy`的结果表明，我们选择的ResNet特征向量对于我们的用于分类花卉图像的用例效果很好。
- en: Streaming a NumPy Array with the from_tensor_slices Method
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用from_tensor_slices方法流式传输NumPy数组
- en: You can also create a data pipeline that streams a NumPy array. You *could*
    pass a NumPy array into the model training process directly, but to utilize RAM
    and other system resources efficiently, it’s better to build a data pipeline.
    Further, once you are happy with the model and are ready to scale it up to handle
    a larger volume of data in production, you’ll need to have a data pipeline anyway.
    Therefore, it is a good idea to build one, even for simple data structures such
    as a NumPy array.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以创建一个流式传输NumPy数组的数据管道。您*可以*直接将NumPy数组传递到模型训练过程中，但为了有效利用RAM和其他系统资源，最好建立一个数据管道。此外，一旦您对模型满意并准备好将其扩展以处理更大量的数据以供生产使用，您将需要一个数据管道。因此，建立一个数据管道是一个好主意，即使是像NumPy数组这样简单的数据结构也是如此。
- en: Python’s NumPy array is a versatile data structure. It can be used to represent
    numeric vectors and tabular data as well as raw images. In this section, you will
    learn how to use the `from_tensor_slices` method to stream NumPy data as a dataset.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Python的NumPy数组是一种多功能的数据结构。它可以用来表示数值向量和表格数据，也可以用来表示原始图像。在本节中，您将学习如何使用`from_tensor_slices`方法将NumPy数据流式传输为数据集。
- en: The example NumPy data you will use for this section is the [Fashion-MNIST dataset](https://oreil.ly/CaUbq),
    which consists of 10 types of garments in grayscale images. The images are represented
    using a NumPy structure instead of a typical image format, such as JPEG or PNG.
    There are 70,000 images in total. The dataset is available in TensorFlow’s distribution
    and can be easily loaded using the `tf.keras` API.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在本节中使用的示例NumPy数据是[Fashion-MNIST数据集](https://oreil.ly/CaUbq)，其中包含10种服装类型的灰度图像。这些图像使用NumPy结构表示，而不是典型的图像格式，如JPEG或PNG。总共有70,000张图像。该数据集在TensorFlow的分发中可用，并且可以使用`tf.keras`API轻松加载。
- en: Loading Example Data and Libraries
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载示例数据和库
- en: 'To start, let’s load the necessary libraries and the Fashion-MNIST data:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们加载必要的库和Fashion-MNIST数据：
- en: '[PRE30]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This data is loaded with the `load_data` function in the `tf.keras` API. The
    data is partitioned into two tuples. Each tuple consists of two NumPy arrays,
    images and labels, as confirmed by the following command:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据是使用`tf.keras`API中的`load_data`函数加载的。数据被分成两个元组。每个元组包含两个NumPy数组，图像和标签，如下面的命令所确认的：
- en: '[PRE31]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This confirms the data type. It is important to know the array dimension, which
    you can display using the `shape` command:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这确认了数据类型。了解数组维度很重要，您可以使用`shape`命令显示：
- en: '[PRE32]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: As you can see, `train_images` is made up of 60,000 records, each a 28 × 28
    NumPy array, while `train_labels` is a 60,000-record label index. TensorFlow provides
    a [useful tutorial](https://oreil.ly/7d85v) on how these indices map to class
    names, but here is a quick look.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，`train_images`由60,000条记录组成，每条记录都是一个28×28的NumPy数组，而`train_labels`是一个60,000条记录的标签索引。TensorFlow提供了一个[有用的教程](https://oreil.ly/7d85v)，介绍了这些索引如何映射到类名，但这里是一个快速查看。
- en: '| **Label** | **Class** |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| **标签** | **类别** |'
- en: '| --- | --- |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0 | T-shirt/top |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 0 | T恤/上衣 |'
- en: '| 1 | Trouser |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 裤子 |'
- en: '| 2 | Pullover |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 套衫 |'
- en: '| 3 | Dress |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 连衣裙 |'
- en: '| 4 | Coat |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 外套 |'
- en: '| 5 | Sandal |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 凉鞋 |'
- en: '| 6 | Shirt |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 衬衫 |'
- en: '| 7 | Sneaker |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 运动鞋 |'
- en: '| 8 | Bag |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 包 |'
- en: '| 9 | Ankle boot |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 短靴 |'
- en: Inspecting the NumPy Array
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查NumPy数组
- en: 'Next, inspect one of the records to see the images for yourself. To display
    a NumPy array as a color scale, you’ll need to use the `matplotlib` library, which
    you imported earlier. The object `plt` represents this library:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，检查其中一条记录，看看图像。要将NumPy数组显示为颜色刻度，您需要使用之前导入的`matplotlib`库。对象`plt`代表这个库：
- en: '[PRE33]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[Figure 5-3](#an_example_record_from_the_fashion-mnist) displays the NumPy
    array for `train_images[5]`.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-3](#an_example_record_from_the_fashion-mnist)显示了`train_images[5]`的NumPy数组。'
- en: '![An example record from the Fashion-MNIST dataset](Images/t2pr_0503.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![来自Fashion-MNIST数据集的示例记录](Images/t2pr_0503.png)'
- en: Figure 5-3\. An example record from the Fashion-MNIST dataset
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-3。来自Fashion-MNIST数据集的示例记录
- en: Unlike color images in JPEG format, which contain three separate channels (RGB),
    each image in the Fashion-MNIST dataset is represented as a flat, two-dimensional
    structure of 28 × 28 pixels. Notice that the pixel values are between 0 and 255;
    we need to normalize them to [0, 1].
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 与JPEG格式中包含三个独立通道（RGB）的彩色图像不同，Fashion-MNIST数据集中的每个图像都表示为一个扁平的、二维的28×28像素结构。请注意，像素值介于0和255之间；我们需要将它们归一化为[0,
    1]。
- en: Building the Input Pipeline for NumPy Data
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为NumPy数据构建输入管道
- en: 'Now you are ready to build a streaming pipeline. First you need to normalize
    each pixel in the image to within the range [0, 1]:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经准备好构建一个流水线。首先，您需要将图像中的每个像素归一化到范围[0, 1]内：
- en: '[PRE34]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now the data value is correct, and it is ready to be passed to the `from_tensor_slices`
    method:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据值是正确的，并且准备传递给`from_tensor_slices`方法：
- en: '[PRE35]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next, split this dataset into training and validation sets. In the following
    code snippet, I specify that the validation set is 10,000 images, with the remaining
    50,000 images going into the training set:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将此数据集拆分为训练集和验证集。在以下代码片段中，我指定验证集为10,000张图像，剩下的50,000张图像进入训练集：
- en: '[PRE36]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'When cross validation is part of the training process, you also need to define
    a couple of parameters so that the model knows when to stop and evaluate the cross-validation
    data during the training iteration:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当交叉验证是训练过程的一部分时，您还需要定义一些参数，以便模型知道何时停止并在训练迭代期间评估交叉验证数据：
- en: '[PRE37]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The following is a small classification model:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个小型分类模型：
- en: '[PRE38]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now you can start the training:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以开始训练：
- en: '[PRE39]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Your output should look similar to this:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 您的输出应该类似于这样：
- en: '[PRE40]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Notice that you can pass train_ds and validation_ds to the fit function directly.
    This is exactly the same method you learned in [Chapter 4](ch04.xhtml#reusable_model_elements),
    when you built an image generator and trained the image classification model to
    classify five types of flowers.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您可以直接将train_ds和validation_ds传递给fit函数。这正是您在[第4章](ch04.xhtml#reusable_model_elements)中学到的方法，当时您构建了一个图像生成器并训练了图像分类模型以对五种类型的花进行分类。
- en: Wrapping Up
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned how to build data pipelines for text, numeric arrays,
    and images. As you have seen, data and directory structure are important to set
    up before applying different APIs to ingest the data to a model. We started with
    a text data example, using the `text_dataset_from_directory` function that TensorFlow
    provides to handle text files. You also learned that the `flow_from_dataframe`
    method is specifically designed for image files grouped by class, a totally different
    file structure than what you saw in [Chapter 4](ch04.xhtml#reusable_model_elements).
    Finally, for numeric arrays in a NumPy array structure, you learned to use the
    `from_tensor_slices` method to build a dataset for streaming. When you build a
    data ingestion pipeline, you have to understand the file structure as well as
    the data type in order to use the right method.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了如何为文本、数值数组和图像构建数据流水线。正如您所见，数据和目录结构在应用不同的API将数据摄入模型之前是很重要的。我们从一个文本数据示例开始，使用了TensorFlow提供的`text_dataset_from_directory`函数来处理文本文件。您还学到了`flow_from_dataframe`方法是专门为按类别分组的图像文件设计的，这是与您在[第4章](ch04.xhtml#reusable_model_elements)中看到的完全不同的文件结构。最后，对于NumPy数组结构中的数值数组，您学会了使用`from_tensor_slices`方法构建用于流式传输的数据集。当构建数据摄入管道时，您必须了解文件结构以及数据类型，以便使用正确的方法。
- en: Now that you have seen how to build data pipelines, you’ll learn more about
    building the model in the next chapter.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经看到如何构建数据流水线，接下来将在下一章中学习更多关于构建模型的内容。
