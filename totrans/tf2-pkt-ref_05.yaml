- en: Chapter 5\. Data Pipelines for Streaming Ingestion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data ingestion is an important part of your workflow. There are several steps
    to perform before raw data is in the correct input format expected by the model.
    These steps are known as the *data pipeline*. Steps in a data pipeline are important
    because they will also be applied to the production data, which is the data consumed
    by the model when the model is deployed. Whether you are in the process of building
    and debugging a model or getting it ready for deployment, you need to format the
    raw data for the model’s consumption.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to use the same series of steps in the model-building process
    as you do in deployment planning, so that the test data is processed the same
    way as the training data.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 3](ch03.xhtml#data_preprocessing) you learned how the Python generator
    works, and in [Chapter 4](ch04.xhtml#reusable_model_elements) you learned how
    to use the `flow_from_directory` method for transfer learning. In this chapter,
    you will see more of the tools that TensorFlow provides to handle other data types,
    such as text and numeric arrays. You’ll also learn how to handle another type
    of file structure for images. File organization becomes especially important when
    handling text or images for model training because it is common to use directory
    names as labels. This chapter will recommend a practice for directory organization
    when it comes to building and training a text or image classification model.
  prefs: []
  type: TYPE_NORMAL
- en: Streaming Text Files with the text_dataset_from_directory Function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can stream pretty much any files in a pipeline, as long as you organize
    the directory structure correctly. In this section we’ll look at an example using
    text files, which would apply in use cases such as text classification and sentiment
    analysis. Here we are interested in the `text_dataset_from_directory` function,
    which works similarly to the `flow_from_directory` method that we used for streaming
    images.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to use this function for a text classification problem, you have to
    follow the directory organization described in this section. In your current working
    directory, you must have subdirectories with names that match the labels or class
    names for your text. For example, if you are doing text classification model training,
    you have to organize your training texts into positives and negatives. This is
    the process of training data labeling; it has to be done to set up the data for
    the model to learn what a positive or negative comment looks like. If the text
    is a corpus of movie reviews classified as positive or negative, then the subdirectory
    names might be *pos* and *neg*. Within each subdirectory, you have all the text
    files for that class. Therefore, your directory structure would be similar to
    this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As an example, let’s try building a data ingestion pipeline for text data using
    a corpus of movie reviews from the Internet Movie Database (IMDB).
  prefs: []
  type: TYPE_NORMAL
- en: Downloading Text Data and Setting Up Directories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The text data you will use for this section is the [Large Movie Review Dataset](https://oreil.ly/EabEP).
    You can download it directly or use the `get_file` function to do so. Let’s start
    by importing the necessary libraries and then downloading the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Conveniently, by passing `untar=True`, the `get_file` function also decompresses
    the file. This will create a directory called *aclImdb* in the current directory.
    Let’s encode this file path as a variable for future reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'List this directory to see what’s inside:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'There is one directory (*unsup*) not in use, so you’ll need to get rid of it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now take a look at the content in the training directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The two directories are *pos* and *neg*. These names will be encoded as categorical
    variables in the text classification task.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to clean up your subdirectories and ensure that all directories
    contain text for the classification training. If we had not removed that unused
    directory, its name would have become a categorical variable, which is not our
    intention at all. The other files there are fine and don’t impact the outcome
    here. Again, remember that directory names are used as labels, so make sure you
    have *only* directories that are intended for the model to learn and map to labels.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Data Pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that your files are properly organized, you’re ready to create the data
    pipeline. Let’s set up a few variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The batch size tells the generator how many samples to use in one iteration
    of training. It’s also a good idea to assign a seed so that each time you execute
    the generator, it streams the files in the same order. Without the seed assignment,
    the generator will output the files in random order.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then define a pipeline using the `test_dataset_from_directory` function. It
    will return a dataset object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the directory that contains subdirectories is *aclImdb/train.*
    This pipeline definition is for 80% of the training dataset, which is designated
    by `subset='training'`. The other 20% is reserved for cross validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the cross-validation data, you’ll define the pipeline in a similar fashion:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you execute the two pipelines in the preeding code, this is the expected
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Because there are two subdirectories in *aclImdb/train*, the generator recognizes
    them as classes. And because of the 20% split, 5,000 files are held for cross
    validation.
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting the Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the generator in place, let’s take a look at the contents of these files.
    The way to inspect a TensorFlow dataset is to iterate through it and select a
    few samples. The following code snippet takes the first batch of samples and then
    randomly selects five rows of movie reviews:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Here, `idx` is a list that holds five randomly generated integers within the
    range of `batch_size`. Then `idx` is used as the index to select the text and
    label from the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset will yield a tuple consisting of `text_batch` and `label_batch`;
    a tuple is useful here because it keeps track of the text and its label (class).
    These are five randomly selected rows of text and corresponding labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The first two are positive reviews (indicated by the digit 1), and the last
    three are negative reviews (indicated by 0). This method is called *grouping by
    class.*
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you learned how to stream text datasets. The method is similar
    to how images are streamed, with the exception of using the `text_dataset_from_directory`
    function. You learned grouping by class and the recommended directory organization
    for your data, which is important because directory names are used as labels for
    the model training process. In both image and text classification, you saw that
    directory names are used as labels.
  prefs: []
  type: TYPE_NORMAL
- en: Streaming Images with a File List Using the flow_from_dataframe Method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How your data is organized affects how you deal with the data ingestion pipeline.
    This is especially important with image data. During the image classification
    task in [Chapter 4](ch04.xhtml#reusable_model_elements), you saw how different
    types of flowers were organized into directories with names corresponding to each
    flower type.
  prefs: []
  type: TYPE_NORMAL
- en: Grouping by class is not the only file organization method you will encounter
    in the real world. In another common style, shown in [Figure 5-1](#another_directory_structure_for_storing),
    all images are thrown into one directory (which means it doesn’t matter what you
    name the directory).
  prefs: []
  type: TYPE_NORMAL
- en: '![Another directory structure for storing image files](Images/t2pr_0501.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-1\. Another directory structure for storing image files
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In this organization, you see that at the same level as the directory *flowers*,
    which contains all the images, there is a CSV file called *all_labels.csv*. This
    file contains two columns: one with all the filenames and one with the labels
    for those files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: To use image files stored in this format, you’ll need to use *all_labels.csv*
    to train the model to recognize each image’s label. This is where the `flow_from_dataframe`
    method comes in.
  prefs: []
  type: TYPE_NORMAL
- en: Downloading Images and Setting Up Directories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start with an example in which images are organized into a single directory.
    [Download the file](https://oreil.ly/WtKvA) *flower_photos.zip*, unzip it, and
    you will see the directory structure shown in [Figure 5-1](#another_directory_structure_for_storing).
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, if you’re working in a Jupyter Notebook environment, run the
    Linux command `wget` to download *flower_photos.zip*. Following is the command
    for a Jupyter Notebook’s cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command downloads the file and places it in the current directory.
    Unzip the file with this Linux command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This creates a directory with the same name as the ZIP file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, there is a directory named *flower_photos*. List its contents
    with the following command, and you will see exactly what’s shown in [Figure 5-1](#another_directory_structure_for_storing):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Now that you have the directory structure and image files you need to work through
    this section’s example, you can start building a data pipeline to feed these images
    into an image classification model for training. And to make it easy on yourself,
    you’ll use the ResNet feature vector, a prebuilt model in TensorFlow Hub, so you
    don’t have to design a model,. You’ll stream these images into the training process
    with `ImageDataGenerator`.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the Data Ingestion Pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As usual, the first thing to do is import the necessary libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that you need the pandas library in this example. This library is used
    to parse the label files as a dataframe. This is how to read the label file into
    a pandas DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: And if you take a look at the dataframe `traindf`, you will see the following
    content.
  prefs: []
  type: TYPE_NORMAL
- en: '|   | **Filename** | **Label** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 7176723954_e41618edc1_n.jpg | sunflowers |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 2788276815_8f730bd942.jpg | roses |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 6103898045_e066cdeedf_n.jpg | dandelion |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 1441939151_b271408c8d_n.jpg | daisy |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 2491600761_7e9d6776e8_m.jpg | roses |'
  prefs: []
  type: TYPE_TB
- en: '| ... | ... | ... |'
  prefs: []
  type: TYPE_TB
- en: '| 3615 | 9558628596_722c29ec60_m.jpg | sunflowers |'
  prefs: []
  type: TYPE_TB
- en: '| 3616 | 4580206494_9386c81ed8_n.jpg | tulips |'
  prefs: []
  type: TYPE_TB
- en: 'Next, you need to create some variables to hold parameters to be used later:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, remember that when we use the ResNet feature vector, we have to rescale
    the image pixel intensity to a range of [0, 1], which means for each image pixel,
    the intensity has to be divided by 255\. Also, we need to reserve a portion of
    the images for cross validation—say, 20%. So let’s define these criteria in a
    dictionary, which we can use as an input for our `ImageDataGenerator` definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Another dictionary will hold a few other arguments. The ResNet feature vector
    expects images to have pixel dimensions of 224 × 224, and we need to specify the
    batch size and resample algorithm as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: This dictionary will be used as an input in the data flow definition.
  prefs: []
  type: TYPE_NORMAL
- en: 'For training the images, this is how you would set up the generator definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that we passed `datagen_kwargs` into the `ImageDataGenerator` instance.
    Next, we use the `flow_from_dataframe` method to create a data flow pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ImageDataGenerator` we defined as `train_datagen` is used to invoke the
    `flow_from_dataframe` method. Let’s take a look a the input parameters. The first
    argument is `dataframe`, which is designated as `traindf`. Then `directory` specifies
    where images may be found in the directory path. `x_col` and `y_col` are the headers
    in `traindf`: `x_col` corresponds to column “file_name” as defined in *all_labels.csv*,
    and `y_col` is the column “label.” Now our generator knows how to match images
    to their labels.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, it specifies a subset to be `training`, as this is the training image
    generator. Seed is provided for reproducibility of batches. Images are shuffled,
    and image classes are designated to be categorical. Finally, `dataflow_kwargs`
    is passed into this `flow_from_dataframe` method so that raw images are resampled
    from their original resolution to 224 × 224 pixels.
  prefs: []
  type: TYPE_NORMAL
- en: 'This procedure is repeated for the validation image generator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Inspecting the Dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Right now, the only way to examine the contents of a TensorFlow dataset is
    by iterating through it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The preceding code snippet acquires the first batch of images from `train_generator`,
    the output of which is a tuple consisting of `image_batch` and `label_batch`.
  prefs: []
  type: TYPE_NORMAL
- en: You will see 32 images (that’s the batch size). Some will look like [Figure 5-2](Images/#some_of_the_flower_images_in_the_dataset).
  prefs: []
  type: TYPE_NORMAL
- en: '![Some of the flower images in the dataset](Images/t2pr_0502.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-2\. Some of the flower images in the dataset
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now that the data ingestion pipeline is set up, you are ready to use it in the
    training process.
  prefs: []
  type: TYPE_NORMAL
- en: Building and Training the tf.keras Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following classification model is an example of how to use a prebuilt model
    in TensorFlow Hub:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the model architecture is ready, compile it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Then launch the training process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Notice that `train_generator` and `valid_generator` are passed into our `fit`
    function. These will generate samples of images as the training process progresses,
    until all epochs are completed. You should expect to see output similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This indicates that you’ve successfully passed the training image generator
    and validation image generator into the training process, and that both generators
    can ingest data at training time. The result for validation data accuracy, `val_accuracy`,
    is a good indication that our choice of the ResNet feature vector works well for
    our use case of classifying flower images.
  prefs: []
  type: TYPE_NORMAL
- en: Streaming a NumPy Array with the from_tensor_slices Method
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can also create a data pipeline that streams a NumPy array. You *could*
    pass a NumPy array into the model training process directly, but to utilize RAM
    and other system resources efficiently, it’s better to build a data pipeline.
    Further, once you are happy with the model and are ready to scale it up to handle
    a larger volume of data in production, you’ll need to have a data pipeline anyway.
    Therefore, it is a good idea to build one, even for simple data structures such
    as a NumPy array.
  prefs: []
  type: TYPE_NORMAL
- en: Python’s NumPy array is a versatile data structure. It can be used to represent
    numeric vectors and tabular data as well as raw images. In this section, you will
    learn how to use the `from_tensor_slices` method to stream NumPy data as a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The example NumPy data you will use for this section is the [Fashion-MNIST dataset](https://oreil.ly/CaUbq),
    which consists of 10 types of garments in grayscale images. The images are represented
    using a NumPy structure instead of a typical image format, such as JPEG or PNG.
    There are 70,000 images in total. The dataset is available in TensorFlow’s distribution
    and can be easily loaded using the `tf.keras` API.
  prefs: []
  type: TYPE_NORMAL
- en: Loading Example Data and Libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To start, let’s load the necessary libraries and the Fashion-MNIST data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'This data is loaded with the `load_data` function in the `tf.keras` API. The
    data is partitioned into two tuples. Each tuple consists of two NumPy arrays,
    images and labels, as confirmed by the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'This confirms the data type. It is important to know the array dimension, which
    you can display using the `shape` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `train_images` is made up of 60,000 records, each a 28 × 28
    NumPy array, while `train_labels` is a 60,000-record label index. TensorFlow provides
    a [useful tutorial](https://oreil.ly/7d85v) on how these indices map to class
    names, but here is a quick look.
  prefs: []
  type: TYPE_NORMAL
- en: '| **Label** | **Class** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | T-shirt/top |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | Trouser |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | Pullover |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | Dress |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | Coat |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | Sandal |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | Shirt |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | Sneaker |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | Bag |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | Ankle boot |'
  prefs: []
  type: TYPE_TB
- en: Inspecting the NumPy Array
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Next, inspect one of the records to see the images for yourself. To display
    a NumPy array as a color scale, you’ll need to use the `matplotlib` library, which
    you imported earlier. The object `plt` represents this library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 5-3](#an_example_record_from_the_fashion-mnist) displays the NumPy
    array for `train_images[5]`.'
  prefs: []
  type: TYPE_NORMAL
- en: '![An example record from the Fashion-MNIST dataset](Images/t2pr_0503.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-3\. An example record from the Fashion-MNIST dataset
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Unlike color images in JPEG format, which contain three separate channels (RGB),
    each image in the Fashion-MNIST dataset is represented as a flat, two-dimensional
    structure of 28 × 28 pixels. Notice that the pixel values are between 0 and 255;
    we need to normalize them to [0, 1].
  prefs: []
  type: TYPE_NORMAL
- en: Building the Input Pipeline for NumPy Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now you are ready to build a streaming pipeline. First you need to normalize
    each pixel in the image to within the range [0, 1]:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now the data value is correct, and it is ready to be passed to the `from_tensor_slices`
    method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, split this dataset into training and validation sets. In the following
    code snippet, I specify that the validation set is 10,000 images, with the remaining
    50,000 images going into the training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'When cross validation is part of the training process, you also need to define
    a couple of parameters so that the model knows when to stop and evaluate the cross-validation
    data during the training iteration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a small classification model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can start the training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Your output should look similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Notice that you can pass train_ds and validation_ds to the fit function directly.
    This is exactly the same method you learned in [Chapter 4](ch04.xhtml#reusable_model_elements),
    when you built an image generator and trained the image classification model to
    classify five types of flowers.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to build data pipelines for text, numeric arrays,
    and images. As you have seen, data and directory structure are important to set
    up before applying different APIs to ingest the data to a model. We started with
    a text data example, using the `text_dataset_from_directory` function that TensorFlow
    provides to handle text files. You also learned that the `flow_from_dataframe`
    method is specifically designed for image files grouped by class, a totally different
    file structure than what you saw in [Chapter 4](ch04.xhtml#reusable_model_elements).
    Finally, for numeric arrays in a NumPy array structure, you learned to use the
    `from_tensor_slices` method to build a dataset for streaming. When you build a
    data ingestion pipeline, you have to understand the file structure as well as
    the data type in order to use the right method.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have seen how to build data pipelines, you’ll learn more about
    building the model in the next chapter.
  prefs: []
  type: TYPE_NORMAL
