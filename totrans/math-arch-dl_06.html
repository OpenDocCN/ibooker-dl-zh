<html><head></head><body>
<div class="calibre1" id="sbo-rt-content"><h1 class="tochead" id="ch-func-approx">7 Function approximation: How neural networks model the world</h1>
<p class="co-summary-head">This chapter covers</p>
<ul class="calibre6">
<li class="co-summary-bullet">Expressing real-world problems as mathematical functions</li>
<li class="co-summary-bullet">Understanding the building blocks of a neural network</li>
<li class="co-summary-bullet">Approximating functions via neural networks</li>
</ul>
<p class="body"><a id="marker-239"/>Computing to date has been dominated by the von Neumann architecture in which the processor and the program are separate. The program sits in memory and is fetched and executed by the processor. The advantage of this approach is that different programs solving unrelated problems can be loaded into memory, and the same processor can execute them. But neural networks have a fundamentally different architecture. There are no separate processors and programs; instead, there is a single entity called, well, the neural network, which can run on dedicated hardware or a Von Neumann computer. In this chapter, we discuss this paradigm in detail.</p>
<p class="fm-callout"><span class="fm-callout-head">NOTE</span> The complete PyTorch code for this chapter is available at <a class="url" href="http://mng.bz/K4zj">http://mng.bz/K4zj</a> in the form of fully functional and executable Jupyter notebooks.</p>
<h2 class="fm-head" id="neural-networks-a-10000-foot-view">7.1 Neural networks: A 10,000-foot view</h2>
<p class="body">In section <a class="url" href="../Text/01.xhtml#sec-multi-layered-nn">1.7</a>, we provided an overview of neural networks. (You may want to do a quick refresher on chapter <a class="url" href="../Text/01.xhtml#chap-overview">1</a> at this point.) There we indicated that most intelligent tasks performed by humans can be expressed in terms of mathematical functions that we will refer to as <i class="fm-italics">target functions</i>. So, to develop machines that perform intelligent tasks, we need to have machines that model target functions. While that gives us hope of developing automated solutions, we are hobbled by two serious difficulties:<a id="marker-240"/></p>
<ul class="calibre6">
<li class="fm-list-bullet">
<p class="list">In addition to being arbitrarily complicated, the target functions underlying various real-life problems are completely different from one another. There is hardly any common pattern.</p>
</li>
<li class="fm-list-bullet">
<p class="list">For most problems, we do <i class="fm-italics">not</i> know the underlying target function.</p>
</li>
</ul>
<p class="body">Despite all this, we want to come up with a mechanized repeatable solution for performing real-life intelligent tasks. And we do not want to start from scratch and design the underlying function for each such problem. This is where neural networks help:</p>
<p class="fm-quote">Neural networks provide a unified framework to model an extremely wide variety of arbitrarily complicated functions.</p>
<p class="body">While the overall neural network models a complicated function, its building block is a fairly basic unit called a <i class="fm-italics">neuron</i>. The neuron represents a relatively simple function. The full neural network is made up of many neurons with weighted connections between them. It can be made to approximate any arbitrary target function underlying a particular problem of interest by manipulating the number of neurons, the connectivity between them, and the connection weights.</p>
<p class="body">The variety and complexity of the functions a neural network can represent are known as its <i class="fm-italics">expressive power</i>. Expressive power increases with the number of neurons in the neural network and the number of connections between them. The more complex the target function, the more expressive power will be needed in the neural network modeling it. How can we make a neural network model/approximate/express a specific target function corresponding to a particular problem of interest? Answer: we can adjust the following two aspects of the neural network:</p>
<ul class="calibre6">
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Architecture</i>—The number of neurons and the connections between them</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Parameter values</i>—The weights of the connection between neurons</p>
</li>
</ul>
<p class="body">The architecture is typically chosen based on the nature of the problem. Some popular architectures are reused frequently, and a neural network engineer typically chooses an architecture that is historically known to be effective for a problem similar to the problem at hand. We look at several popular architectures later in this book—for instance, in chapter <a class="url" href="../Text/11.xhtml#ch-deep-learning-object-recognition-detection">11</a>. Once the architecture is set, we determine the parameter values through a process called <i class="fm-italics">training</i>.</p>
<p class="body">Neural networks can be classified into two major classes: <i class="fm-italics">supervised</i> and <i class="fm-italics">unsupervised</i>. In supervised neural networks, we identify the desired output values corresponding to a set of sampled input values for the problem we are trying to solve. The desired output for these sampled inputs is typically chosen manually using a process called <i class="fm-italics">labeling</i> (aka <i class="fm-italics">manual annotation</i> or <i class="fm-italics">manual curation</i>). The overall set of &lt;sampled input, desired output&gt; pairs constitutes the <i class="fm-italics">supervised training data</i>. The set of desired outputs for training data inputs is sometimes collectively referred to as the <i class="fm-italics">ground truth</i> or <i class="fm-italics">target output</i>.</p>
<p class="body">During training, the parameter values (aka weights) are adjusted such that the network’s outputs on training inputs match the corresponding ground truth as closely as possible. If all goes well, at the end of training, we are left with a neural network whose outputs on training inputs are close to the ground truth. This <i class="fm-italics">trained</i> neural network is then deployed to the real world, where it performs <i class="fm-italics">inferencing</i>—it generates output on inputs it has never seen before. If we have chosen the architecture with enough expressive power and properly trained the network with adequate training data, it should emit accurate results during inferencing. Note that we cannot <i class="fm-italics">guarantee</i> correct results during inferencing; we can only make a probabilistic statement that our output has a <i class="timesitalic">p</i> probability of being correct.</p>
<p class="body"><a id="marker-241"/>Unsupervised neural networks do not need the manually labeled ground truth—they just work on the training inputs. The manual labor involved in labeling the training data is expensive and bothersome. Consequently, considerable research effort is going into neural networks that are unsupervised, semi-supervised (a fraction of the training data is labeled manually), or self-supervised (labeled training data is created programmatically rather than manually). However, unsupervised and semi-supervised neural network technology is less mature at the time of this writing, and it is harder to achieve desired accuracy levels with them. Later in this book, we examine unsupervised approaches, including <i class="fm-italics">variational autoencoders</i> (chapter <a class="url" href="../Text/14.xhtml#ch-ae-vae">14</a>). But for now, we mostly talk about supervised approaches.</p>
<p class="body">It is important to note that nowhere in the architecture selection or training process do we need a closed-form representation of either the function being approximated (the target function) or the approximator function (the modeling function). This is important. In most cases, it is impossible to know the target function—all we know are sample input and ground-truth pairs (training data). As for the modeling function, even when we know the architecture of the modeling neural network, the overall function it represents is so complicated that it is virtually intractable. Thus, the fact that we do not need to know the target or modeling function in closed form is what makes the technology practical.</p>
<h2 class="fm-head" id="sec-real-world-problems-func">7.2 Expressing real-world problems: Target functions</h2>
<p class="body">Consider the classic investor’s problem: to sell or not sell a stock. The problem inputs could be the purchase price, current price, whether the investor’s favorite expert is advising to sell or not, and so on. The problem can be solved by a function that takes these inputs and outputs as <span class="math">0</span> (do not sell) or <span class="math">1</span> (sell). If we could model this function, we would have a mechanical solution to this real-world problem.</p>
<p class="body">Like this example, most real-world problems can be expressed as target functions. We collect all quantifiable variables that can have a bearing on the outcome: these constitute the <i class="fm-italics">input variables</i>. The input variables are expressed as numeric entities: scalars, vectors, matrices, and so on. The outputs are also expressed as numeric variables called the <i class="fm-italics">output variables</i>. Given a specific input (say, specific values for purchase price and current price), our model function emits an output (0 or 1 indicating do not sell or sell) that is a solution to the problem for that specific input.</p>
<p class="body">We usually denote input variables with the symbol <i class="timesitalic">x</i>; a sequence of input variables is often expressed as a vector <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>. Output variables are denoted with the symbol <i class="timesitalic">y</i>. The overall target function is usually expressed as <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">f</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>)</span>. We will often use subscripts to denote various elements of a vector (<span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span>, <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span>, <span class="math">⋯</span>, <i class="timesitalic">x<sub class="fm-subscript">i</sub></i>) and superscripts to denote input instances, as in <span class="math"><i class="fm-italics">y</i><sup class="fm-superscript">(0)</sup> = <i class="fm-italics">f</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sup class="fm-superscript">(0)</sup>)</span>, <span class="math"><i class="fm-italics">y</i><sup class="fm-superscript">(1)</sup> = <i class="fm-italics">f</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sup class="fm-superscript">(1)</sup>)</span>, <span class="math">⋯</span>, <span class="math"><i class="fm-italics">y</i><sup class="fm-superscript">(<i class="fm-italics1">i</i>)</sup> = <i class="fm-italics">f</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sup class="fm-superscript">(<i class="fm-italics1">i</i>)</sup>)</span>. But in some cases, we will use subscripts to denote different items of the training data. The usage should be obvious from the context.</p>
<p class="body">Numeric quantities can occur in two distinct forms: continuous and categorical. <i class="fm-italics">Continuous variables</i> can take any of the infinitely many real number values in a given range. For instance, the stock price in our “to sell or not sell a stock” problem can take any value greater than zero. <i class="fm-italics">Categorical variables</i> can take one of a finite set of allowed values, where the value represents a category. A special categorical case is a binary variable, where there are only two categories. For instance, expert advice in our stock-selling problem can take only two values: <span class="math">0</span> or <span class="math">1</span>, corresponding to the two categories of advice, “do not sell” and “sell,” respectively.</p>
<p class="body">In this section, we discuss three distinct families of target functions: logical functions, general functions, and classifiers.<a id="marker-242"/></p>
<h3 class="fm-head1" id="logical-functions-in-real-world-problems">7.2.1 Logical functions in real-world problems</h3>
<p class="body">These are functions whose inputs and outputs are binary variables: variables that can take only two values, <span class="math">0</span> (aka “no” or “don’t fire”) and <span class="math">1</span> (aka “yes” or “fire”). Machines emulating logical functions are often added on top of separate machines performing other tasks, as will be evident from the following examples:</p>
<ul class="calibre6">
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Logical OR</i>—To look at logical OR functions, let’s bring back the mythical cat whose brain we discussed in chapter <a class="url" href="../Text/01.xhtml#chap-overview">1</a>. Say we are trying to build a machine that helps the poor creature make the binary decision whether to run away from the object in front of it or approach the object and purr. Being very timid, this cat runs away from anything that looks hard or sharp. The only time it will approach and purr is when the object in front of it looks neither hard nor sharp. Let’s assume a separate machine outputs a binary decision <span class="math">0</span> not hard) or <span class="math">1</span> (hard). Another machine outputs a binary decision <span class="math">0</span> (not sharp) or <span class="math">1</span> (sharp). The logical OR machine combines the binary decisions from the two separate machines, as shown in figure <a class="url" href="#fig-func-logical-or">7.1a</a>.</p>
</li>
</ul>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre5" height="187" id="fig-func-logical-or" src="../../OEBPS/Images/CH07_F02a_Chaudhury.png" width="1020"/></p>
<p class="figurecaption">(a) Logical OR: a timid cat that runs away from things whose hardness exceeds threshold <span class="math"><i class="fm-italics">t</i><sub class="fm-subscript">0</sub></span> <b class="fm-bold">OR</b> whose sharpness exceeds threshold <span class="math"><i class="fm-italics">t</i><sub class="fm-subscript">1</sub></span></p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre5" height="187" id="fig-func-logical-and" src="../../OEBPS/Images/CH07_F02b_Chaudhury.png" width="1020"/></p>
<p class="figurecaption">(b) Logical AND: a less timid cat that runs away from things whose hardness exceeds threshold <span class="math"><i class="fm-italics">t</i><sub class="fm-subscript">0</sub></span> <b class="fm-bold">AND</b> whose sharpness exceeds threshold <span class="math"><i class="fm-italics">t</i><sub class="fm-subscript">1</sub></span></p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre5" height="791" id="fig-func-multi-input-or" src="../../OEBPS/Images/CH07_F02c_Chaudhury.png" width="1023"/></p>
<p class="figurecaption">(c) Multi-input logical OR: A self-driving car that applies the brake if it sees a person, vehicle, or bend in the road in front of it</p>
</div>
<p class="fm-table-caption" id="fig-func-logical-or-and">Figure 7.1 Examples of logical operators (OR, AND) in real-life problems <a id="marker-243"/></p>
<ul class="calibre6">
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Logical AND</i>—We also exemplify this in terms of the cat brain. Imagine a slightly less timid cat that runs away from things that are both hard and sharp. But it is not scared by hardness and sharpness alone. Its brain can be modeled by the system of machines shown in figure <a class="url" href="#fig-func-logical-and">7.1b</a>.<a id="marker-244"/></p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Logical NOT</i>—Consider a machine that sounds an alarm if it sees any unauthorized person in a restricted access area. Let’s assume that we also have a separate machine: a face detector that can recognize the faces of all authorized personnel. It emits a binary decision <span class="math">1</span> (recognized face) or <span class="math">0</span> (unrecognized face). The overall system takes the output of the face detector and performs a logical NOT operationon it.</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Multi-input logical OR</i>—Imagine a machine that decides whether a self-driving car needs to brake. Assume that three separate detectors emit <span class="math">1</span> if a person, vehicle, or bend in the road, respectively, is seen in front of the car. A brake must be applied if any of these separate detectors emits a <span class="math">1</span>. This is shown in figure <a class="url" href="#fig-func-multi-input-or">7.3</a>.</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Multi-input logical AND</i>—Consider a machine that helps a venture capitalist decide whether to invest in a startup. Assume that three separate machines emit <span class="math">1</span> when the following conditions are met: (1) the CEO has a track record of success, (2) the product elicits interest from targeted customers, and 3) the product is sufficiently novel, respectively. The machine will decide to invest if all three separate machines emit <span class="math">1</span>. Thus, the machine outputs <span class="math">1</span> when condition (1) is met AND condition (2) is met AND condition (3) is met. This is an example of a three-input AND.</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Logical XOR</i>—Suppose we are building a social media site. Assume we have a separate detector that, for any person, emits <span class="math">1</span> if they like rock music and <span class="math">0</span> otherwise. Using this information about two people, the problem is to decide whether they should be recommended as friends to each other. Friendship potential is high if they both like rock music or both dislike it. But if one person likes rock and the other dislikes it, they will probably not be good friends. Thus condition 1 is high rock-music affinity for person 1, and condition 2 is high rock-music affinity for person 2. The exclusive OR of the two conditions is <span class="math">1</span> when one is true but the other is not. This machine outputs <span class="math">1</span> if the NOT of the exclusive OR is true, meaning neither person likes rock music or both people like rock music. Figure <a class="url" href="#fig-func-logical-xor">7.4</a> depicts this.</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">m-out-of-n trigger</i>—Imagine we are trying to create a face detector. We have already created separate part detectors for noses, eyes, lips, and ears. If we detect, say, any two of these together, we feel confident enough to declare a face. In computer vision, we often have a problem called <i class="fm-italics">occlusion</i>, where an important object becomes invisible to the camera because another object blocks the camera’s line of sight. Computer vision algorithms always try to be robust against occlusion, meaning they want to emit the right output even when occlusion occurs. This is why we do not want to mandate a positive signal from all the part detectors; we want to detect the face even when a few of the parts are occluded. Hence, our machine emits <span class="math">1</span> when, say, two of the <i class="timesitalic">n</i> parts (such as eyes and lips) are detected.</p>
</li>
</ul>
<div class="figure" id="fig-func-logical-xor">
<p class="figure1"><img alt="" class="calibre27" height="508" src="../../OEBPS/Images/CH07_F03_Chaudhury.png" width="1023"/></p>
<p class="figurecaption">Figure 7.2 Example of logical NOT and XOR in a real-life problem. A social media system makes a friendship recommendation between persons A and B if and only if they both like or both dislike rock music. friendship <span class="math">= <span class="cambria">¬</span></span> (rock-music-affinity-of-A <span class="times2">⊕</span> rock-music-affinity-of-B) where <span class="math"><span class="cambria">¬</span> <span class="cambria">⟹</span></span> logical NOT and <span class="math"><span class="cambria">⊕</span> <span class="cambria">⟹</span></span> logical XOR.</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre23" height="218" id="fig-box-face-detector-discriminative" src="../../OEBPS/Images/CH07_F01a_Chaudhury.png" width="1023"/></p>
<p class="figurecaption">(a) Discriminative face detector classifier). The output is categorical (face or not face).</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre23" height="218" id="fig-box-face-detector-generative" src="../../OEBPS/Images/CH07_F01b_Chaudhury.png" width="1023"/></p>
<p class="figurecaption">(b) Generative face detector. The output is continuous (the probability of an image containing a face).</p>
</div>
<p class="fm-table-caption" id="fig-box-face-detector">Figure 7.3 The face detector takes an image as input and outputs a categorical or continuous variable.</p>
<h3 class="fm-head1" id="classifier-functions-in-real-world-problems">7.2.2 Classifier functions in real-world problems</h3>
<p class="body"><a id="marker-245"/>A classifier is a function whose output is categorical. Inputs can be either continuous or categorical. Thus, given an input, the function chooses one category (aka class) or another. For instance, a face detector can be a classifier. Its input is an image, and its output is a categorical (binary) variable that takes one of two possible values: <span class="math">1</span> (face) or <span class="math">0</span> (not face). This is shown in figure <a class="url" href="#fig-box-face-detector-discriminative">7.3a</a>. As we saw in section <a class="url" href="02.xhtml#sec-matrices">2.3</a>, any image can be represented by a vector <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>. Accordingly, the classifier function for the face detectorcan be written as the function</p><!--<p class="Body"><span class="times">$$\phi\left(\vec{x}\right) =
\begin{cases} 0\;\;\;\;\quad\text{not a face}\\ 1\;\;\;\;\quad\text{face}
\end{cases}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="62" src="../../OEBPS/Images/eq_07-00-a.png" width="189"/></p>
</div>
<p class="body">How to design the function <span class="math"><i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>)</span> is one of the primary topics of this chapter.</p>
<p class="body"><a id="marker-246"/>Geometrically, each scalar input variable forms a separate dimension in the input space. All possible combinations of these scalar input variables together form a multidimensional space called the <i class="fm-italics">input space</i> (or feature space). Each specific combination of input values is a point (represented by the input vector <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>) in this space.</p>
<p class="body">For instance, in an image, each pixel can be taken as a separate input scalar variable that can take any 3-byte pixel color value between <span class="math">RGB = <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/o_00.png" width="23"/></span>, <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/o_00.png" width="23"/></span>, <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/o_00.png" width="23"/></span></span> (hex) (black) and <span class="math">RGB = <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/o_FF.png" width="33"/></span>, <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/o_FF.png" width="33"/></span>, <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/o_FF.png" width="33"/></span></span> (hex) (white), with successive bytes (demarcated by an overline) representing red, green, and blue components of the pixel, respectively. The input has as many dimensions as the number of pixels in the image. For instance, a <span class="math">224 × 224</span> image forms a <span class="math">50, 176</span>-dimensional input space. Each specific image is a single point in this space. The face-classifier function <span class="math"><i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>)</span> maps that point to either <span class="math">0</span> (not face) or <span class="math">1</span> (face).</p>
<p class="body">For a simpler instance, consider our familiar cat brain example from section <a class="url" href="../Text/01.xhtml#sec-geom-view-ml">1.4</a>. There are two input variables: <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span>, indicating <i class="fm-italics">hardness</i>; and <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span>, indicating <i class="fm-italics">sharpness</i>. The overall input space is two-dimensional, in which a specific input combination is denoted by the <span class="math">2</span>D vector <!--<span class="times">$\vec{x}=\begin{bmatrix}x_{0}\\x_{1}\end{bmatrix}$</span>--><span class="infigure"><img alt="" class="calibre5" height="32" src="../../OEBPS/Images/eq_07-00-b.png" width="59"/></span>. Our goal is to construct a machine that, given any input combination of hardness and sharpness, classifies it as either <i class="fm-italics">threatening</i> or <i class="fm-italics">nonthreatening</i>. This is equivalent to designing a function that maps arbitrary input vectors <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> <span class="cambria">∈</span> ℝ<sup class="fm-superscript">2</sup></span> to <span class="math">0</span> or <span class="math">1</span>:</p><!--<p class="Body"><span class="times">$$\phi\left(\vec{x}\right) =
\begin{cases} 0\;\;\;\;\quad\text{not a threat}\\ 1\;\;\;\;\quad\text{threat}
\end{cases}$$</span></p>>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="61" src="../../OEBPS/Images/eq_07-00-c.png" width="204"/></p>
</div>
<p class="fm-head2" id="sec-decision-boundaries">Geometrical view of classifiers: Decision boundaries</p>
<p class="body">Geometrically speaking, a classifier partitions the feature space into separate regions, each corresponding to a class. For instance, consider the simple cat-brain model from section <a class="url" href="../Text/01.xhtml#sec-geom-view-ml">1.4</a>. There are two input variables, hardness (<span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span>) and sharpness (<span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span>). Hence we have a two-dimensional input feature space that geometrically corresponds to a plane. Each combination of hardness and sharpness is represented by a specific vector <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> = [<i class="fm-italics">x</i><sub class="fm-subscript">0</sub>, <i class="fm-italics">x</i><sub class="fm-subscript">1</sub>]</span> corresponding to a <i class="fm-italics">point</i> on the plane. Note that unlike the machines shown in figures <a class="url" href="#fig-func-logical-or">7.1a</a> and <a class="url" href="#fig-func-logical-and">7.1b</a>, here we are talking about a machine that takes as input a <i class="fm-italics">pair</i> of continuous values hardness and sharpness)—that is, a point on the two-dimensional feature plane—and maps it to a discrete space corresponding to the <i class="fm-italics">threat</i> versus <i class="fm-italics">not a threat</i> categorical decision. This is illustrated in figure <a class="url" href="#fig-cat_brain_decision_boundaries_nonlinear_and_linear">7.4a</a>.</p>
<p class="body">The solid curve separates the <i class="fm-italics">threat</i> and <i class="fm-italics">not-threat</i> regions. Such curves that separate regions in input space belonging to different classes are known as <i class="fm-italics">decision boundaries</i>. Estimating the decision boundary is effectively the same as building the classifier.</p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre18" height="827" id="fig-cat_brain_decision_boundaries_nonlinear_and_linear" src="../../OEBPS/Images/CH07_F04a_Chaudhury.png" width="900"/></p>
<p class="figurecaption">(a) Cat brain threat model decision boundary. The solid curve corresponds to the true decision boundary separating the <i class="fm-italics">threat</i> and <i class="fm-italics">non-threat</i> regions. The dashed line represents an approximate linear decision boundary: it classifies most points correctly but misclassifies points in the region between itself and the true decision boundary.<br class="calibre20"/>
    In practice, we get some sample points from each region through manual labeling.</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre18" height="740" id="fig-cat-brain-good-training-data" src="../../OEBPS/Images/CH07_F04b_Chaudhury.png" width="900"/></p>
<p class="figurecaption">(b) Good training data. Sample points from each class roughly span the region of input space belonging to the class. This yields a good decision boundary (solid line).</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre18" height="943" id="fig-cat-brain-bad-training-data" src="../../OEBPS/Images/CH07_F04c_Chaudhury.png" width="1102"/></p>
<p class="figurecaption">(c) Bad training data. Sample points from individual classes do not span the region of input space belonging to the class. This yields a bad decision boundary (dashed line).<a id="marker-248"/></p>
</div>
<p class="fm-table-caption" id="fig-2d-decision-boundary-training-data">Figure 7.4 Classifiers, decision boundaries, and training data. Data points from different classes are marked with different symbols (plus and dot).</p>
<p class="body"><a id="marker-247"/>The dashed line represents an approximate linear decision boundary that does the job crudely but misclassifies the points between the solid and dashed curves. (Linear decision boundaries are easier to represent with neural networks, but they are inadequate for complex problems.)</p>
<p class="body">Let’s look briefly at the solid curve in figure <a class="url" href="#fig-cat_brain_decision_boundaries_nonlinear_and_linear">7.4a</a>. At low hardness values, the sharpness threshold is high (if the object in front of the cat is not very hard, it must be very sharp to qualify as a threat). As hardness increases from <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 0</span> to <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 20</span>, this threshold the sharpness required to qualify as a threat) drops more or less linearly. Beyond <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 20</span>, the threshold drops at a much faster pace—if the object in front of the cat is sufficiently hard, it need not be very sharp to pose a threat. Beyond <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 52</span> or so, sharpness ceases to matter: sufficiently hard objects are threats even if they are not sharp. This is inherently a nonlinear situation.</p>
<p class="body">To simplify neural network implementation, we might want to approximate the solid curve with a straight line—the dashed line is not too bad an approximation—but doing so entails errors. As shown in figure <a class="url" href="#fig-cat_brain_decision_boundaries_nonlinear_and_linear">7.4a</a>, the region between the true and approximate curves will be wrongly classified.</p>
<p class="body"><a id="marker-249"/>Figure <a class="url" href="#fig-cat_brain_decision_boundaries_nonlinear_and_linear">7.4a</a> is only a schematic. In reality, we do not know the exact regions in the input space that correspond to the classes of interest. We identify—via human labeling—some sample points on the input space, along with their correct class (the ground truth). Such a sampled set of &lt;input point, correct output aka ground truth&gt; pairs is called <i class="fm-italics">training data</i>. An example training data set for the cat brain problem is shown in figure <a class="url" href="#fig-cat-brain-good-training-data">7.4b</a> (ground-truth training data points from different classes are marked with separate symbols: plus and dot, respectively). The decision boundary we create by training a neural network is optimized to classify the training data points (and nothing more) as nicely as possible. If the training data points’ distribution is a reasonable reflection of the true distribution—that is, the sample points from each class more or less span the entire region in the input space corresponding to that class—the decision boundary obtained by training on that data set will be good. But if, as illustrated in figure <a class="url" href="#fig-cat-brain-bad-training-data">7.4c</a>, the training data does not reflect the true distribution of the classes in the input space, the decision boundary learned by training on that data maybe bad.</p>
<p class="body">Unlike the cat brain example, most real-life input spaces have hundreds or even thousands of dimensions. The idea of a decision boundary as a hypersurface continues to hold in higher dimensions. For higher-dimensional input spaces, hyperplanes function as linear separators. In simpler problems with higher-dimensional input spaces, such linear separators suffice. In more complicated cases, we can have other curved hypersurfaces as nonlinear separators. We may not be able to visualize hyperspaces in our head, but we can form mental pictures with <span class="math">3</span>D analogs. Figure <a class="url" href="#fig-decision-boundary">7.5</a> shows some planar decision boundaries in <span class="math">3</span>D input space.</p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="395" id="fig-perceptron-training-data" src="../../OEBPS/Images/CH07_F05a_Chaudhury.png" width="432"/></p>
<p class="figurecaption">(a) Training data. Sample points from regions on the input space for each class</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="395" id="fig-perceptron-bad-planar-separator-0" src="../../OEBPS/Images/CH07_F05b_Chaudhury.png" width="432"/></p>
<p class="figurecaption">(b) Bad decision boundary. The plane has the wrong orientation. <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span> needs to be fixed.</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="395" id="fig-perceptron-bad-planar-separator-1" src="../../OEBPS/Images/CH07_F05c_Chaudhury.png" width="432"/></p>
<p class="figurecaption">(c) Bad decision boundary. The plane has the correct orientation but the wrong position. <i class="timesitalic">b</i> needs to be fixed.</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="452" id="fig-perceptron-good-planar-separator" src="../../OEBPS/Images/CH07_F05d_Chaudhury.png" width="456"/></p>
<p class="figurecaption">(d) Optimal decision boundary. The plane has correct <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span>, <i class="timesitalic">b</i>. Properly trained.</p>
</div>
<p class="fm-table-caption" id="fig-decision-boundary">Figure 7.5 Classifiers with a linear decision boundary hyperplane). Such decision boundaries are created by perceptrons introduced in section <a class="url" href="#sec-perceptron">7.3.3</a>). Data points from different classes are marked with different symbols plus and dot).<a id="marker-250"/></p>
<p class="body">Figure <a class="url" href="#fig-perceptron-training-data">7.5a</a> shows a <span class="math">3</span>D space of input vectors along with a set of training data points. The task is to classify them into two classes. In this simple situation, the training points can be partitioned with a hyperplanar decision boundary. Figures <a class="url" href="#fig-perceptron-bad-planar-separator-0">7.5b</a> and <a class="url" href="#fig-perceptron-bad-planar-separator-1">7.5c</a> show some planes that partition the training data poorly, and figure <a class="url" href="#fig-perceptron-good-planar-separator">7.5d</a> shows an optimal planar separator. The only differences between these planes are the values of <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span> and <i class="timesitalic">b</i>. This indicates that there are values of <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span> and <i class="timesitalic">b</i> that optimally partition the training data. These optimal values are determined by a process called <i class="fm-italics">training</i>, which we discuss in detail in the nextchapter.</p>
<p class="fm-head2" id="significance-of-sign-mathematical-expressions-for-decision-boundaries">Significance of sign: Mathematical expressions for decision boundaries</p>
<p class="body">In a space with input vectors <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>, the equation <span class="math"><i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>) = 0</span> represents a surface. If the space is <span class="math">2</span>D, the surface becomes a curve. For instance, the straight dashed line in figure <a class="url" href="#fig-cat-brain-good-training-data">7.4b</a> can be viewed as a special case of <span class="math"><i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>) ≡ <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> + <i class="fm-italics">b</i> = 0</span>, which in this case becomes</p><!--<p class="Body"><span class="times">$$\begin{aligned}
&amp;0.62 x_{0} + x_{1} - 26.14 =
\begin{bmatrix} 0.62\\[-3pt] 1
\end{bmatrix}^{T}
\begin{bmatrix}
x_{0}\\[-3pt] x_{1}
\end{bmatrix} - 26.14
= 0\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="76" src="../../OEBPS/Images/eq_07-00-d.png" width="352"/></p>
</div>
<p class="body">That is,</p><!--<p class="Body"><span class="times">$$\begin{aligned}
\vec{w} &amp;= \begin{bmatrix} 0.62\\1
\end{bmatrix}\\ b &amp;= -26.14\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="94" src="../../OEBPS/Images/eq_07-00-e.png" width="91"/></p>
</div>
<p class="body">In <span class="math">3</span>D, we have surfaces like planes and spheres. In more than three dimensions, we have hyperplanes, hyperspheres, and so on. For instance, the plane in figure <a class="url" href="#fig-hyperplane-sign">7.6</a> corresponds to</p><!--<p class="Body"><span class="times">$$\phi\left(\vec{x}\right)  \equiv  x_{0}
+ x_{1} + x_{2} =
\begin{bmatrix} 1\\1\\1
\end{bmatrix}^{T}\begin{bmatrix}
x_{0}\\x_{1}\\x_{1}
\end{bmatrix}  + 0 = 0$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="112" src="../../OEBPS/Images/eq_07-01.png" width="284"/></p>
</div>
<p class="fm-equation-caption">Equation 7.1</p>
<p class="body">That is,</p><!--<p class="Body"><span class="times">$$\begin{aligned}
\vec{w} &amp;= \begin{bmatrix} 1\\1\\1
\end{bmatrix}\\ b &amp;= 0
\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="127" src="../../OEBPS/Images/eq_07-01-a.png" width="62"/></p>
</div>
<p class="body"><a id="marker-251"/>In section <a class="url" href="../Text/03.xhtml#sec-sign-sep-surface">3.1.4</a>, we saw that given any point <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> in the space, the sign of <span class="math"><i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>)</span> tells us which side of the surface <span class="math"><i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>) = 0</span> the point <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> belongs to. Thus, if we estimate the surface corresponding to the decision boundary, given any point, we can determine the partition to which that point belongs. In other words, we can classify the point. Estimating the decision boundary is equivalent to building the classifier. For instance, the line in figure <a class="url" href="#fig-cat-brain-good-training-data">7.4b</a> corresponds to <span class="math">0.62<i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> − 26.14 = 0</span>. The points with <span class="math">0.62<i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> − 26.14 &lt; 0</span> are on one side and are indicated with dots. The points with <span class="math">0.62<i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> − 26.14 &gt; 0</span> are on the other side and indicated with plus signs (+).</p>
<p class="body">The idea extends to higher dimensions. Figure <a class="url" href="#fig-hyperplane-sign">7.6</a> shows the same idea in a <span class="math">3</span>D input space. The plane corresponds to the equation <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">2</sub> = 0</span>. The points with <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">2</sub> &lt; 0</span> are on one side (indicated by – in figure <a class="url" href="#fig-hyperplane-sign">7.6</a>), and points with <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">2</sub> &gt; 0</span> are on the other side (indicated by + in figure <a class="url" href="#fig-hyperplane-sign">7.6</a>).</p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre17" height="531" id="fig-hyperplane-sign" src="../../OEBPS/Images/CH07_F06_Chaudhury.png" width="534"/></p>
<p class="figurecaption">Figure 7.6 Significance of sign for <span class="math"><i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>) ≡ <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> + <i class="fm-italics">b</i></span>. Note that <span class="math"><i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>) = 0</span> implies that <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> lies <i class="fm-italics">on</i> the plane, <span class="math"><i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>)</span> negative implies one side of the plane, and <span class="math"><i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>)</span> positive implies the other side of the plane.</p>
</div>
<h3 class="fm-head1" id="general-functions-in-real-world-problems">7.2.3 General functions in real-world problems</h3>
<p class="body">There are problems where a categorical output variable will not do and a continuous output variable is called for: for instance, estimating the speed at which a self-driving vehicle should run. Using inputs like the speed limit for the road being traversed, speeds of neighboring vehicles, and so on, we need to estimate how fast the self-driving vehicle should go.</p>
<p class="body">Another noteworthy situation where the output needs to be a continuous rather than a categorical variable is when we are modeling the <i class="fm-italics">probability</i> of some event occurring. For instance, let’s again consider the face detector. Given an image as input, the face classification function emits <span class="math">0</span> to indicate <i class="fm-italics">not a face</i> and <span class="math">1</span> to indicate <i class="fm-italics">face</i>. Such functions are called <i class="fm-italics">discriminative</i>. We could also have a function that outputs the probability of the image containing a face. Such functions are called <i class="fm-italics">generative</i>, and an example is shown in figure <a class="url" href="#fig-box-face-detector-generative">7.6</a>.</p>
<h2 class="fm-head" id="the-basic-building-block-or-neuron-the-perceptron">7.3 The basic building block or neuron: The perceptron</h2>
<p class="body"><a id="marker-252"/>In section <a class="url" href="#sec-real-world-problems-func">7.2</a>, we saw that most real-world problems can be expressed as functions. This is good news, but the bad news is that these functions are usually unknown, and the functions underlying various problems are wildly different from each other. It may be possible to estimate them, but if we attack them individually without adopting a generic framework, there is little hope of developing a repeatable solution.</p>
<p class="body">Neural networks provide an effective framework that can mechanically model an extremely wide variety of complicated functions. Furthermore, the target function need not be known in a closed form—sample input-output pairs are enough. They can represent (model) very complicated functions by connecting instances of a fairly simple building block, unsurprisingly called a <i class="fm-italics">neuron</i>. In other words, the complete neural network can have huge <i class="fm-italics">expressive power</i> even though a single neuron is very simple. Later, in sections <a class="url" href="#sec-logic-gates-via-perceptrons">7.3.4</a>, <a class="url" href="#sec-MLPs">7.4</a>, <a class="url" href="../Text/07.xhtml#sec-layering">7.5</a>, and so on, we discuss how neural networks model functions of increasing complexity. But first, in this section, we examine the building block: the neuron.</p>
<h3 class="fm-head1" id="step-func">7.3.1 The Heaviside step function</h3>
<p class="body">The <i class="fm-italics">Heaviside step function</i>, often referred to as simply the <i class="fm-italics">step function</i>, is a function that takes the value <span class="math">0</span> for negative arguments and the value <span class="math">1</span> for positive arguments:</p><!--<p class="Body"><span class="times">$$\phi\left(x\right) =
\begin{cases}
&amp; 0 \text{\;\;\;if } x &lt; 0\\
&amp; 1 \text{\;\;\;if } x &gt;= 0
\end{cases}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="62" src="../../OEBPS/Images/eq_07-02.png" width="176"/></p>
</div>
<p class="fm-equation-caption">Equation 7.2 <span class="calibre" id="eq-heaviside-step-func"/></p>
<p class="body">Equation <a class="url" href="#eq-heaviside-step-func">7.2</a> is equivalent to the following algorithm. Figure <a class="url" href="../Text/07.xhtml#fig-step-1D">7.7</a> shows the graph of this equation.</p>
<div class="calibre3">
<p class="fm-algorithm-caption">Algorithm 7.4 Heaviside step function as an algorithm</p>
<p class="algorithm-body"><b class="fm-bold">if</b> <span class="math"><i class="fm-italics">x</i> &lt; 0</span> <b class="fm-bold">then</b></p>
<p class="algorithm-body">      return 0</p>
<p class="algorithm-body"><b class="fm-bold">else</b>  </p>
<p class="algorithm-body">      return 1</p>
<p class="algorithm-body"><b class="fm-bold">end</b> <b class="fm-bold">if</b></p>
</div>
<div class="figure">
<p class="figure1"><img alt="" class="calibre18" height="713" id="fig-step-1D" src="../../OEBPS/Images/CH07_F07_Chaudhury.png" width="900"/></p>
<p class="figurecaption">Figure 7.7 Heaviside step function graph</p>
</div>
<h3 class="fm-head1" id="sec-hyperplanes-recap">7.3.2 Hyperplanes</h3>
<p class="body"><a id="marker-253"/>In section <a class="url" href="02.xhtml#sec-hyperplanes">2.8</a>, we discussed hyperplanes. They are represented by equation <a class="url" href="02.xhtml#eq-plane-1">2.14</a>. In figure <a class="url" href="02.xhtml#fig-planar-classifier">2.9</a>, we saw the role that hyperplanes play in classifiers; we briefly revisit the idea here.</p>
<p class="body">In section <a class="url" href="02.xhtml#subsec-vec-geom-ml">2.1.1</a>, we saw that <i class="timesitalic">d</i>-element vectors are geometrical analogs of points in a <i class="timesitalic">d</i>-dimensional space. Let <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> denote the vectors (or, equivalently, points) in the space of input vectors. For a fixed vector <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span> and fixed scalar <i class="timesitalic">b</i>, the equation for a hyperplane in that space is</p>
<p class="fm-equation"><span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> + <i class="fm-italics">b</i> = 0</span></p>
<p class="body">(meaning all points <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> satisfying this equation lie on the plane). The vector <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span> is the normal to the plane. This becomes intuitively obvious when we observe that if we take any two points on the plane, say <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">0</sub></span> and <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">1</sub></span>, then</p>
<p class="fm-equation"><span class="math"><i class="fm-italics"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">0</sub> + <i class="fm-italics">b</i> = 0</span><br class="calibre20"/>
<span class="math"><i class="fm-italics"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">1</sub> + <i class="fm-italics">b</i> = 0</span></p>
<p class="body">Subtracting, we get</p>
<p class="fm-equation"><span class="math"><i class="fm-italics"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><sup class="fm-superscript">T</sup></i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">1</sub> - <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">0</sub>) = 0</span></p>
<p class="body">But <span class="math">(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">1</sub> - <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">0</sub>)</span> is the vector joining two arbitrary points on the plane. This means the <i class="fm-italics">line joining any pair of points on the plane is perpendicular to <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span></i> (in section <a class="url" href="02.xhtml#subsec-dotprod-ml">2.5.2</a>, we discussed dot products, and in section <a class="url" href="02.xhtml#section-orthogonality">2.6</a>, we saw that if the dot product between two vectors is zero, the vectors are orthogonal—perpendicular to each other). Hence, <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span> is orthogonal to all lines lying on the plane. In other words, <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span> is normal to the plane.</p>
<p class="body">The hyperplane <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> + <i class="fm-italics">b</i> = 0</span> partitions the space into two regions with distinct signs for the expression <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> + <i class="fm-italics">b</i></span>. That is to say, the hyperplane can serve as a decision boundary, as shown in figure <a class="url" href="#fig-hyperplane-sign">7.6</a>. Not just a hyperplane but any hypersurface can partition space in this fashion. This is true for any dimensionality of <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>:</p>
<ul class="calibre6">
<li class="fm-list-bullet">
<p class="list">If the expression <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> + <i class="fm-italics">b</i></span> evaluates to <i class="fm-italics">zero</i>, the point <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> lies <i class="fm-italics">on the hyperplane</i> <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> + <i class="fm-italics">b</i> = 0</span>.</p>
</li>
<li class="fm-list-bullet">
<p class="list">If the sign of the expression <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> + <i class="fm-italics">b</i></span> is <i class="fm-italics">negative</i>, the point <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> lies on <i class="fm-italics">one side of the hyperplane</i>.</p>
</li>
<li class="fm-list-bullet">
<p class="list">If the sign of the expression <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> + <i class="fm-italics">b</i></span> is <i class="fm-italics">positive</i>, the point <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> lies on the <i class="fm-italics">other side of the hyperplane</i>.</p>
</li>
</ul>
<h3 class="fm-head1" id="sec-perceptron">7.3.3 Perceptrons and classification</h3>
<p class="body"><a id="marker-254"/>The perceptron combines the step function and a hyperplane into a single function. It represents the function</p>
<p class="fm-equation"><span class="math"><i class="fm-italics">P</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>) ≡ <i class="fm-italics">ϕ</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span> + <i class="fm-italics">b</i>)</span></p>
<p class="fm-equation-caption">Equation 7.3 <span class="calibre" id="eq-perceptron"/></p>
<p class="body">where <i class="timesitalic">ϕ</i> is the Heaviside step function from equation <a class="url" href="#eq-heaviside-step-func">7.2</a>. Combining our insights from sections <a class="url" href="../Text/07.xhtml#step-func">7.3.1</a> and <a class="url" href="#sec-hyperplanes-recap">7.3.2</a>, we can see that the perceptron function maps all points on one side of the <span class="math">(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span>, <i class="fm-italics">b</i>)</span> plane to zero and all points on the other side of the same plane to <span class="math">1</span>. In other words, it performs as a linear classifier, with the (<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span>, <i class="timesitalic">b</i>) plane as the decision boundary. Figure <a class="url" href="#fig-perceptron-graph">7.8</a> graphs the perceptron function for a <span class="math">2</span>D input space (the graph itself is in <span class="math">3</span>D space: it maps points on one side of the decision boundary to the plane <span class="math"><i class="fm-italics">Z</i> = 0</span> and points on the other side to the plane <span class="math"><i class="fm-italics">Z</i> = 1</span>).</p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre13" height="713" id="fig-perceptron-graph" src="../../OEBPS/Images/CH07_F08_Chaudhury.png" width="901"/></p>
<p class="figurecaption">Figure 7.8 although the input space is <span class="math">2</span>D, the perceptron graph is <span class="math">3</span>D. The decision boundary is indicated by the long diagonal straight line. It maps points on one side of the decision boundary to the <span class="math"><i class="fm-italics">Z</i> = 0</span> plane and the points on the other side to the <span class="math"><i class="fm-italics">Z</i> = 1</span> plane.</p>
</div>
<p class="body">Of course, in real life, we do not know the exact regions corresponding to classes. Rather, we have sampled input points with their manually labeled classes as training data. The decision surface must be constructed based on this training data only. In figure <a class="url" href="#fig-2d-decision-boundary-training-data">7.4</a>, we saw an example decision boundary in <span class="math">2</span>D along with some good and bad training data sets. To get a mental picture of sampled training data sets in higher dimensions, look at figure <a class="url" href="#fig-perceptron-training-data">7.5a</a> again. In this simple situation, a single hyperplanar decision boundary is sufficient to partition the training points. This means a single perceptron-based neural network will suffice as a classifier. Figures <a class="url" href="#fig-perceptron-bad-planar-separator-0">7.5b</a> and <a class="url" href="#fig-perceptron-bad-planar-separator-1">7.5c</a> depict some planes (perceptrons with specific <span class="math">(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span>, <i class="fm-italics">b</i>)</span> values) that poorly partition the training data. Figure <a class="url" href="#fig-perceptron-good-planar-separator">7.5d</a> shows an optimal perceptron (planar separator). This tells us that there are good values of <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_w.png" width="15"/></span> and <i class="timesitalic">b</i> that optimally partition the training data, as well as bad values. As mentioned earlier, good values are determined through training, which we cover in chapter 8.</p>
<p class="body"><a id="marker-255"/>The perceptron effectively partitions with a <i class="fm-italics">planar</i> decision surface. This works only in simple problems. For an instance of a situation where a planar decision surface will <i class="fm-italics">not</i> work, see figure <a class="url" href="#fig-multiplane-decision-boundary">7.9</a>. It depicts a problem where one class maps to the set of points sandwiched between two planes and the other class to the rest of the points in the input space. It is impossible to achieve the required partitioning with a single plane, so such a decision boundary cannot be modeled with a single perceptron. Later we will see how to model such complex decision boundaries with multiple perceptrons.</p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre5" height="343" id="fig-multiplane-decision-boundary" src="../../OEBPS/Images/CH07_F09_Chaudhury.png" width="496"/></p>
<p class="figurecaption">Figure 7.9 Multiplane decision boundary. One class corresponds to the points in the region sandwiched between the planes (marked +). The remaining points correspond to the other class marked –). This decision boundary <b class="fm-bold">cannot</b> be represented with a single plane.</p>
</div>
<p class="fm-callout"><span class="fm-callout-head">NOTE</span> Fully functional code for perceptrons, executable via Jupyter Notebook, can be found at <a class="url" href="http://mng.bz/9Ne7">http://mng.bz/9Ne7</a>.</p>
<p class="body">The following listing shows the PyTorch code for a perceptron.</p>
<p class="fm-code-listing-caption" id="listing-7.1-perceptron">Listing 7.1 Perceptron</p>
<pre class="programlisting">def fully_connected_layer(X, w,  b):                         <span class="fm-combinumeral">①</span>

    X = torch.cat((X, torch.ones(
             [X.shape[0], 1], dtype=torch.float32)), dim=1)  <span class="fm-combinumeral">②</span>

    W = torch.cat((W, b.unsqueeze(dim=1)), dim=1)            <span class="fm-combinumeral">③</span>

    y = torch.matmul(W, X.transpose(0, 1))                   <span class="fm-combinumeral">④</span>

    y = torch.heaviside(y, torch.tensor(1.0))                <span class="fm-combinumeral">⑤</span>

    return y.transpose(0, 1)

def Perceptron(X, W, b):                                     <span class="fm-combinumeral">⑥</span>
    return fully_connected_layer(X, W, b)</pre>
<p class="fm-code-annotation"><span class="fm-combinumeral">①</span> <span class="math"><i class="fm-italics">X</i> : <i class="fm-italics">n</i> × <i class="fm-italics">d</i></span> tensor; each row is an input vector of size d. <span class="math"><i class="fm-italics">w</i> : <i class="fm-italics">m</i> × <i class="fm-italics">d</i></span> tensor.</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Adds a column of 1s. <span class="math"><i class="fm-italics">X</i> ↦ <i class="fm-italics">n</i> × (<i class="fm-italics">d</i>+1)</span> tensor.</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Combines weights and biases</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Matrix multiplication of X and W</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Applies the Heaviside step function</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> A single perceptron</p>
<h3 class="fm-head1" id="sec-logic-gates-via-perceptrons">7.3.4 Modeling common logic gates with perceptrons</h3>
<p class="body"><a id="marker-256"/>Neural networks provide a structured way of modeling complex functions by connecting—via weighted edges—repeated instances of a simple building block called the perceptron. In this section, we explore the idea of function modeling via perceptrons. We start with modeling extremely simple logical functions (AND, OR, NOT, voting) that can be represented with single perceptrons. Then we look at the XOR function, one of the simplest functions that <i class="fm-italics">cannot</i> be represented with a single perceptron; we see that it <i class="fm-italics">can</i> be modeled with <i class="fm-italics">multiple</i> perceptrons. Next we discuss Cybenko’s theorem, which states that most functions of interest can be modeled with as much accuracy as we want via perceptrons, with a single hidden layer between inputs and outputs. Unfortunately, this is less practical than it sounds: the catch is that although any function can be modeled to any accuracy, there is no limit on how many perceptrons are required to do the modeling. The more complicated the target function is, the more perceptrons are required. In practice, we often use many layers instead of one.</p>
<p class="fm-head2" id="a-perceptron-for-logical-and">A perceptron for logical AND</p>
<p class="body">Figure <a class="url" href="#fig-perceptron-logical-and">7.18</a> depicts this perceptron. It takes two inputs, <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> and <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span>, which are weighted with <span class="math"><i class="fm-italics">w</i><sub class="fm-subscript">0</sub> = 1</span> and <span class="math"><i class="fm-italics">w</i><sub class="fm-subscript">1</sub> = 1</span>, respectively; the bias is <span class="math">−1.5</span> actually, a wide range of bias values will do). Overall, the perceptron implements the function <span class="math"><i class="fm-italics">ϕ</i>(<i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub>−1.5)</span>. This function emits <span class="math">1</span> when <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> − 1.5 ≥ 0</span>: that is, <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> ≥ 1.5</span>. Since the variables are binary (meaning they can only take the value <span class="math">0</span> or <span class="math">1</span>), this can happen only when both inputs are <span class="math">1</span>. If either is zero, their sum is less than <span class="math">1.5</span>, and <i class="timesitalic">y</i> is <span class="math">0</span>.</p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre13" height="194" id="fig-perceptron-logical-and" src="../../OEBPS/Images/CH07_F10a_Chaudhury.png" width="533"/></p>
<p class="figurecaption">(a) Perceptron for a logical AND function: <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">x</i><sub class="fm-subscript">0</sub> ∨ <i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span></p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre13" height="192" id="fig-perceptron-logical-or" src="../../OEBPS/Images/CH07_F10b_Chaudhury.png" width="529"/></p>
<p class="figurecaption">(b) Perceptron for a logical OR function: <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">x</i><sub class="fm-subscript">0</sub> ∧ <i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span></p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre13" height="247" id="fig-perceptron-logical-not" src="../../OEBPS/Images/CH07_F10c_Chaudhury.png" width="552"/></p>
<p class="figurecaption">(c) Perceptron for a logical NOT function: <span class="math"><i class="fm-italics">y</i> = <span class="cambria">¬</span><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span></p>
</div>
<p class="figurecaption" id="fig-perceptron-logical-functions">Figure 7.10 functions are binary, meaning they can be either <span class="math">0</span> or <span class="math">1</span>.</p>
<p class="body">The situation is depicted geometrically in figure <a class="url" href="#fig-perceptron-logical-and-geom">7.11a</a>. The thick diagonal line corresponds to <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> ≥ 1.5</span>. It partitions the plane into unshaded and shaded All points on the unshaded half-plane have an output value <span class="math"><i class="fm-italics">y</i> = 0</span>, and all points on the shaded half-plane have the output value <span class="math"><i class="fm-italics">y</i> = 1</span>. There are only four possible input points: <span class="math">(<i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 1, <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = 1)</span>, <span class="math">(<i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 1, <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = 1)</span>, <span class="math">(<i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 1, <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = 1)</span>, <span class="math">(<i class="fm-italics">x</i><sub class="fm-subscript">0</sub>=1, <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = 1)</span>. The point <span class="math">(<i class="fm-italics">x</i><sub class="fm-subscript">0</sub>=1, <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = 1)</span> falls on the shaded side and the others on the unshaded side—which is exactly the logical AND function.<a id="marker-257"/></p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="364" id="fig-perceptron-logical-and-geom" src="../../OEBPS/Images/CH07_F11a_Chaudhury.png" width="331"/></p>
<p class="figurecaption">(a) Logical AND decision boundary: <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = 1.5</span></p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="371" id="fig-perceptron-logical-or-geom" src="../../OEBPS/Images/CH07_F11b_Chaudhury.png" width="337"/></p>
<p class="figurecaption">(b) Logical OR decision boundary: <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = 0.5</span></p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="368" id="fig-perceptron-logical-not-geom" src="../../OEBPS/Images/CH07_F11c_Chaudhury.png" width="336"/></p>
<p class="figurecaption">(c) Logical NOT decision boundary: <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 0.5</span></p>
</div>
<p class="fm-table-caption" id="fig-perceptron">Figure 7.11 Geometrical views for the perceptrons in figure <a class="url" href="#fig-perceptron-logical-functions">7.10</a>. Each dot represents an input point(a <span class="math">[<i class="fm-italics">x</i><sub class="fm-subscript">0</sub> <i class="fm-italics">x</i><sub class="fm-subscript">1</sub>]</span> vector). The shaded dots map to an output value of <span class="math">1</span>, and the unshaded dots map to an output value of <span class="math">0</span>. The thick line indicates the decision boundary.</p>
<p class="fm-head2" id="a-perceptron-for-logical-or">A perceptron for logical OR</p>
<p class="body">Figure <a class="url" href="#fig-perceptron-logical-or">7.10b</a> depicts this perceptron. It takes two inputs, <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> and <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span>, which are weighted with <span class="math"><i class="fm-italics">w</i><sub class="fm-subscript">0</sub> = 1</span> and <span class="math"><i class="fm-italics">w</i><sub class="fm-subscript">1</sub> = 1</span>, respectively; the bias is <span class="math">−0.5</span>. Overall, the perceptron implements the function <span class="math"><i class="fm-italics">ϕ</i>(<i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub>−0.5)</span>. This function emits <span class="math">1</span> when <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> − 0.5 ≥ 0</span>: that is, <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> ≥ 0.5</span>. Since the variables are binary (<span class="math">0</span> or <span class="math">1</span>), this can happen when either or both inputs are <span class="math">1</span>. If and only if both of them are zero, their sum is zero (less than <span class="math">0.5</span>), and <i class="timesitalic">y</i> is <span class="math">0</span>.</p>
<p class="body">The situation is shown geometrically in figure <a class="url" href="#fig-perceptron-logical-or-geom">7.11b</a>. The thick line corresponds to <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> ≥ 0.5</span>, partitioning the input plane into an unshaded half-plane (all points on this half-plane have output <span class="math"><i class="fm-italics">y</i> = 0</span>) and a shaded half-plane output <span class="math"><i class="fm-italics">y</i> = 1</span>). Of the four possible input points, <span class="math">(0,0)</span> falls on the unshaded side (<span class="math"><i class="fm-italics">y</i> = 1</span>) and the remaining three on the shaded side (<span class="math"><i class="fm-italics">y</i> = 1</span>)—which is exactly the logical OR function.</p>
<p class="fm-head2" id="a-perceptron-for-logical-not">A perceptron for logical NOT</p>
<p class="body"><a id="marker-258"/>This perceptron is shown in figures <a class="url" href="#fig-perceptron-logical-not">7.10c</a> and <a class="url" href="#fig-perceptron-logical-not-geom">7.11c</a>, which should be self-explanatory by now.</p>
<p class="fm-callout"><span class="fm-callout-head">NOTE</span> Fully functional code for modeling various logical gates using perceptrons, executable via Jupyter Notebook, can be found at <a class="url" href="http://mng.bz/jBRr">http://mng.bz/jBRr</a>.</p>
<p class="fm-code-listing-caption" id="listing-7.2-modeling-logical-gates-using-perceptrons">Listing 7.2 Modeling logical gates using perceptrons</p>
<pre class="programlisting"># Logical AND
X = torch.tensor([[0., 0.],                               <span class="fm-combinumeral">①</span>
                 [0., 1.],
                 [1., 0.],
                 [1., 1.]], dtype=torch.float32) 
W = torch.tensor([[1.0, 1.0]], dtype=torch.float32)       <span class="fm-combinumeral">②</span>
b = torch.tensor([-1.5])                                  <span class="fm-combinumeral">③</span>
Y = Perceptron(X=X, W=W, b=b, activation=torch.heaviside) <span class="fm-combinumeral">④</span>

# Logical OR
X = torch.tensor([[0., 0.],
                 [0., 1.],
                 [1., 0.],
                 [1., 1.]], dtype=torch.float32)
W = torch.tensor([[1.0, 1.0]], dtype=torch.float32)
b = torch.tensor([-1.5])
Y = Perceptron(X=X, W=W, b=b, activation=torch.heaviside)

# Logical NOT
X = torch.tensor([[0],
                 [1.]
                 ], dtype=torch.float32)
W = torch.tensor([[-1.0]], dtype=torch.float32)
b = torch.tensor([0.5])
Y = Perceptron(X=X, W=W, b=b, activation=torch.heaviside)</pre>
<p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Input data points</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Instantiates the weights</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Instantiates the bias</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Output</p>
<h2 class="fm-head" id="sec-MLPs">7.4 Toward more expressive power: Multilayer perceptrons (MLPs)</h2>
<p class="body">There is a remarkably simple logical function that, somewhat surprisingly, cannot be modeled with a single perceptron: XOR. We discuss it now.</p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="441" id="fig-perceptron-logical-xor-geom" src="../../OEBPS/Images/CH07_F12b_Chaudhury.png" width="399"/></p>
<p class="figurecaption">(a) Geometric view of the logical XOR perceptron. The decision boundary has <i class="fm-italics">two</i> lines, so using a single perceptron is impossible.</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre8" height="556" id="fig-perceptron-logical-xor" src="../../OEBPS/Images/CH07_F12a_Chaudhury.png" width="1022"/></p>
<p class="figurecaption">(b) MLP for the logical XOR function. Note that weights and biases have superscripts in parentheses indicating the layer index. This is a two-layered network. Layer 0 is hidden.</p>
</div>
<p class="fm-table-caption" id="fig-xor">Figure 7.12 Logical XOR: Geometric and perceptron view</p>
<h3 class="fm-head1" id="sec-mlp-xor">7.4.1 MLP for logical XOR</h3>
<p class="body"><a id="marker-259"/>Figure <a class="url" href="#fig-xor">7.12a</a> shows the four possible input points on the plane and how the plane needs to be partitioned to model the XOR function. The points <span class="math">(0,0)</span>, <span class="math">(1,1)</span> (unshaded) both map to output <span class="math">0</span> and should be on the same side of the decision boundary, while the points <span class="math">(0,1)</span>, <span class="math">(1,0)</span> shaded) map to output value <span class="math">1</span> and should be on the other side of the decision boundary.</p>
<p class="body">It is easy to see that it is impossible to draw a single straight line in this plane such that the shaded points are on one side and the unshaded points are on the other. Remember, a perceptron essentially introduces a linear decision boundary. Hence it is impossible to have a single perceptron modeling this function.</p>
<p class="body">However, it is possible to model the logical XOR function via multiple perceptrons. One such model is shown in figure <a class="url" href="#fig-xor">7.12b</a>.</p>
<h2 class="fm-head" id="sec-layering">7.5 Layered networks of perceptrons: MLPs or neural networks</h2>
<p class="body"><a id="marker-260"/>The XOR example tells us that we cannot do much with single perceptrons. We must connect more than one perceptron into a network to solve practical problems. This is a <i class="fm-italics">neural network</i>. How do we organize such a network of connected perceptrons?</p>
<h3 class="fm-head1" id="layering">7.5.1 Layering</h3>
<p class="body"><i class="fm-italics">Layering</i> is the most popular way to organize perceptrons into a neural network. Figure <a class="url" href="#fig-perceptron-logical-xor">7.12b</a> is our first example of an MLP—most of the remainder of the book talks about MLPs.</p>
<p class="body">Note how the perceptrons in the XOR network (figure <a class="url" href="#fig-perceptron-logical-xor">7.12b</a>) are organized:</p>
<ul class="calibre6">
<li class="fm-list-bullet">
<p class="list">The layers are numbered with increasing integers from input to output.</p>
</li>
<li class="fm-list-bullet">
<p class="list">The output of a perceptron in layer <i class="timesitalic">i</i> is only fed as input to perceptrons in layer <span class="math"><i class="fm-italics">i</i> + 1</span>. No other connections are allowed. This keeps the network manageable andfacilitates updating the weights during training via a technique called <i class="fm-italics">backpropagation</i>, which we discuss in the next chapter.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Outputs of all layers but the last are invisible (do not directly contribute tothe output). Such layers are called <i class="fm-italics">hidden layers</i>. In figure <a class="url" href="#fig-perceptron-logical-xor">7.12b</a>, layer <span class="math">0</span> ishidden.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Each weight and bias element belongs to one and only one layer. Throughout this book, we indicate the layer index for a weight or bias element as a superscript within parentheses.</p>
</li>
<li class="fm-list-bullet">
<p class="list">MLPs with two or more hidden layers can be called <i class="fm-italics">deep neural networks</i>. This is the origin of the word <i class="fm-italics">deep</i> in <i class="fm-italics">deep learning</i>.</p>
</li>
</ul>
<h3 class="fm-head1" id="modeling-logical-functions-with-mlps">7.5.2 Modeling logical functions with MLPs</h3>
<p class="body">Any logical function can be expressed as a truth table. Hence, if we can prove that all truth tables can be implemented via MLPs, we are done. This is the approach we take here.</p>
<p class="fm-callout"><span class="fm-callout-head">NOTE</span> In the following discussion, no symbol (à la multiplication) between two variables indicates logical AND, and a <span class="math">+</span> symbol indicates logical OR.</p>
<p class="fm-table-caption">Table 7.1 Truth table for the logical function <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">x̄</i><sub class="fm-subscript">0</sub><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> ¸ <i class="fm-italics">x</i><sub class="fm-subscript">0</sub><i class="fm-italics">x̄</i><sub class="fm-subscript">1</sub></span></p>
<table border="1" class="contenttable-1-table" id="tab-logical-xor-truthtable" width="100%">
<thead class="contenttable-1-thead">
<tr class="contenttable-0-tr">
<th class="contenttable-1-th">
<p class="fm-table-body"><span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span></p>
</th>
<th class="contenttable-1-th">
<p class="fm-table-body"><span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span></p>
</th>
<th class="contenttable-1-th">
<p class="fm-table-body"><i class="timesitalic">y</i>  </p>
</th>
</tr>
</thead>
<tbody class="contenttable-1-thead">
<tr class="contenttable-0-tr">
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">0</span></p>
</td>
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">0</span></p>
</td>
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">0</span></p>
</td>
</tr>
<tr class="contenttable-0-tr">
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">0</span></p>
</td>
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">1</span></p>
</td>
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">1</span></p>
</td>
</tr>
<tr class="contenttable-0-tr">
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">1</span></p>
</td>
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">0</span></p>
</td>
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">1</span></p>
</td>
</tr>
<tr class="contenttable-0-tr">
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">1</span></p>
</td>
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">1</span></p>
</td>
<td class="contenttable-1-td">
<p class="fm-table-body"><span class="math">0</span></p>
</td>
</tr>
</tbody>
</table>
<p class="body">Let’s start with a simple two-variable logical functions <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">x̄</i><sub class="fm-subscript">0</sub><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">0</sub><i class="fm-italics">x̄</i><sub class="fm-subscript">1</sub></span>. Table <a class="url" href="#tab-logical-xor-truthtable">7.1</a> shows the corresponding truth table. To create the equivalent MLP, we must pick the rows corresponding to <span class="math"><i class="fm-italics">y</i> = 1</span>. Each row can be expressed as an AND of the input variables or their complements. For instance, the row <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 0</span> and <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = 1</span>, <span class="math"><i class="fm-italics">y</i> = 1</span> corresponds to <span class="math"><i class="fm-italics">x̄</i><sub class="fm-subscript">0</sub><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span>—the first term of the function we are trying to implement—and can be implemented by the perceptron shown in figure <a class="url" href="#fig-logical-xor-truthtable-perceptron-and-0">7.13a</a>. The row <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 1</span> and <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = 0</span>, <span class="math"><i class="fm-italics">y</i> = 1</span> corresponds to <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub><i class="fm-italics">x̄</i><sub class="fm-subscript">1</sub></span>—the second term of the function we are trying to implement—and can be implemented by the perceptron shown in figure <a class="url" href="#fig-logical-xor-truthtable-perceptron-and-1">7.13b</a>. We have implemented the individual terms of the function; all that remains is to OR them together into a final MLP, as shown in figure <a class="url" href="#fig-logical-xor-truthtable-perceptron-orofands">7.13c</a>. This logical function is our old friend, logical XOR, and the overall function in figure <a class="url" href="#fig-logical-xor-truthtable-perceptron">7.13</a> is the same as figure <a class="url" href="#fig-xor">7.12</a>. In this fashion, arbitrary logical expressions in any number of variables can be modeled using MLPs.<a id="marker-261"/></p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre28" height="229" id="fig-logical-xor-truthtable-perceptron-and-0" src="../../OEBPS/Images/CH07_F13a_Chaudhury.png" width="336"/></p>
<p class="figurecaption">(a) Perceptron for <span class="math"><i class="fm-italics">x̄</i><sub class="fm-subscript">0</sub><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span></p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre28" height="229" id="fig-logical-xor-truthtable-perceptron-and-1" src="../../OEBPS/Images/CH07_F13b_Chaudhury.png" width="335"/></p>
<p class="figurecaption">(b) Perceptron for <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub><i class="fm-italics">x̄</i><sub class="fm-subscript">1</sub></span></p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre28" height="192" id="fig-logical-xor-truthtable-perceptron-orofands" src="../../OEBPS/Images/CH07_F13c_Chaudhury.png" width="333"/></p>
<p class="figurecaption">(c) MLP for <span class="math"><i class="fm-italics">x̄</i><sub class="fm-subscript">0</sub><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> + <i class="fm-italics">x</i><sub class="fm-subscript">0</sub><i class="fm-italics">x̄</i><sub class="fm-subscript">1</sub></span></p>
</div>
<p class="fm-table-caption" id="fig-logical-xor-truthtable-perceptron">Figure 7.13 MLP for the logical function corresponding to table <a class="url" href="#tab-logical-xor-truthtable">7.1</a></p>
<p class="fm-code-listing-caption" id="listing-7.3-multilayered-perceptron-mlp">Listing 7.3 Multilayered perceptron (MLP)</p>
<pre class="programlisting">def MLP(X, W0, W1, b0, b1): <span class="fm-combinumeral">①</span>
    y0 = fully_connected_layer(X=X, W=W0, b=b0)
    return fully_connected_layer(X=y0, W=W1, b=b1)</pre>
<p class="fm-code-annotation"><span class="fm-combinumeral">①</span> MLP</p>
<h3 class="fm-head1" id="sec-cybenko-uat">7.5.3 Cybenko’s universal approximation theorem</h3>
<p class="body">Any function <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">f</i>(<i class="fm-italics">x</i>)</span> that is continuous in an interval <span class="math"><i class="fm-italics">x</i> <span class="cambria">∈</span> (<i class="fm-italics">a</i>, <i class="fm-italics">b</i>)</span> can be approximated with a set of towers (vertical rectangles) in that interval. This is a direct consequence of the <i class="fm-italics">mean value for integrals</i> theorem in calculus. The idea is depicted in figure <a class="url" href="#fig-approx-with-rect-1d">7.14</a>, where a complicated function (depicted by the curve) is approximated by a sequence of towers of various heights. The thinner the towers, the greater the number of towers, and the more accurate the approximation.</p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre8" height="697" id="fig-approx-with-rect-1d" src="../../OEBPS/Images/CH07_F14_Chaudhury.png" width="1163"/></p>
<p class="figurecaption">Figure 7.14 Approximating a complicated function with towers</p>
</div>
<p class="body">In section <a class="url" href="#sec-towers">7.5.3.1</a>, we show that any tower (with arbitrary height and location) can be constructed with MLPs. By summing these MLPs for individual towers, we can approximate the entire function. This is Cybenko’s theorem in a nutshell.</p>
<p class="fm-callout"><span class="fm-callout-head">NOTE</span> Although Cybenko’s theorem guarantees that any continuous function can be modeled using an MLP with a single hidden layer, the number of perceptrons in that MLP can become arbitrarily impracticably large. This is why, in real life, we rarely try to approximate complicated functions with a single hidden layer. We see later that additional layers help us cut down the number of perceptrons required.</p>
<p class="body"><a id="marker-262"/>In particular, any decision boundary can be modeled in this fashion. Of course, the number of perceptrons needed may become impossibly large for many problems, making such a model practically unattainable.</p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="397" id="fig-pos-wt-step-1d" src="../../OEBPS/Images/CH07_F15a_Chaudhury.png" width="496"/></p>
<p class="figurecaption">(a) <span class="math"><i class="fm-italics">ϕ</i>(<i class="fm-italics">x</i>)</span>: positive <i class="timesitalic">w</i> yields a regular step</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="211" id="fig-pos-wt-step-1d-perceptron" src="../../OEBPS/Images/CH07_F15b_Chaudhury.png" width="472"/></p>
<p class="figurecaption">(b) Perceptron for a regular step</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="397" id="fig-neg-wt-step-1d" src="../../OEBPS/Images/CH07_F15c_Chaudhury.png" width="496"/></p>
<p class="figurecaption">(c) <span class="math"><i class="fm-italics">ϕ</i>(−<i class="fm-italics">x</i>)</span>: negative <i class="timesitalic">w</i> yields a laterally flipped step</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="201" id="fig-neg-wt-step-1d-perceptron" src="../../OEBPS/Images/CH07_F15d_Chaudhury.png" width="471"/></p>
<p class="figurecaption">(d) Perceptron for a laterally flipped step</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="394" id="fig-bias-change-1d" src="../../OEBPS/Images/CH07_F15e_Chaudhury.png" width="496"/></p>
<p class="figurecaption">(e) <span class="math"><i class="fm-italics">ϕ</i>(−<i class="fm-italics">x</i>+5)</span>: changing the bias shifts the step left or right</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="209" id="fig-bias-change-1d-perceptron" src="../../OEBPS/Images/CH07_F15f_Chaudhury.png" width="471"/></p>
<p class="figurecaption">(f) Perceptron for a laterally shifted step</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="391" id="fig-tower1d" src="../../OEBPS/Images/CH07_F15g_Chaudhury.png" width="496"/></p>
<p class="figurecaption">(g) <span class="math">(<i class="fm-italics">ϕ</i>(<i class="fm-italics">x</i>+5)+<i class="fm-italics">ϕ</i>(−<i class="fm-italics">x</i>+5)−1.5)</span>: ANDing a left-shifted step with a flipped, right-shifted step yields a tower</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="368" id="fig-tower1d-mlp" src="../../OEBPS/Images/CH07_F15h_Chaudhury.png" width="528"/></p>
<p class="figurecaption">(h) MLP for a 1D tower</p>
</div>
<p class="figurecaption" id="fig-tower1d-all">Figure 7.15 Generating a <span class="math">1</span>D tower with perceptrons.<a id="marker-263"/></p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="541" id="fig-pos-wt-step-2dx" src="../../OEBPS/Images/CH07_F16a_Chaudhury.png" width="650"/></p>
<p class="figurecaption">(a) <span class="math">2</span>D step function along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> (x) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="246" id="fig-pos-wt-step-2dx-perceptron" src="../../OEBPS/Images/CH07_F16b_Chaudhury.png" width="447"/></p>
<p class="figurecaption">(b) Perceptron for a <span class="math">2</span>D step function along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> (x) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre5" height="72" id="fig-step2dx" src="../../OEBPS/Images/CH07_F16c_Chaudhury.png" width="312"/></p>
<p class="figurecaption">(c) Equation for a <span class="math">2</span>D step function along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> (x) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="542" id="fig-neg-wt-step-2dx" src="../../OEBPS/Images/CH07_F16d_Chaudhury.png" width="652"/></p>
<p class="figurecaption">(d) Flipped <span class="math">2</span>D step along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> (x) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="245" id="fig-neg-wt-step-2dx-perceptron" src="../../OEBPS/Images/CH07_F16e_Chaudhury.png" width="446"/></p>
<p class="figurecaption">(e) Perceptron for a flipped <span class="math">2</span>D step along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> (x) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre5" height="66" id="fig-flipped_step2dx" src="../../OEBPS/Images/CH07_F16f_Chaudhury.png" width="312"/></p>
<p class="figurecaption">(f) Equation for a flipped <span class="math">2</span>D step along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> (x) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="541" id="fig-wave-2dx" src="../../OEBPS/Images/CH07_F16g_Chaudhury.png" width="657"/></p>
<p class="figurecaption">(g) <span class="math">2</span>D wave along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> x) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="364" id="fig-wave-2dx-mlp" src="../../OEBPS/Images/CH07_F16h_Chaudhury.png" width="560"/></p>
<p class="figurecaption">(h) MLP for a <span class="math">2</span>D wave along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> (x) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre5" height="60" id="fig-wave2dx" src="../../OEBPS/Images/CH07_F16i_Chaudhury.png" width="312"/></p>
<p class="figurecaption">(i) Equation for a <span class="math">2</span>D wave along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> (x) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="538" id="fig-wave-2dy" src="../../OEBPS/Images/CH07_F16j_Chaudhury.png" width="653"/></p>
<p class="figurecaption">(j) <span class="math">2</span>D wave along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span> y) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="363" id="fig-wave-2dy-mlp" src="../../OEBPS/Images/CH07_F16k_Chaudhury.png" width="560"/></p>
<p class="figurecaption">(k) MLP for a <span class="math">2</span>D wave along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span> (y) direction</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre5" height="55" id="fig-wave2dy" src="../../OEBPS/Images/CH07_F16l_Chaudhury.png" width="312"/></p>
<p class="figurecaption">(l) MLP for a <span class="math">2</span>D wave along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span> (y) direction<a id="marker-265"/></p>
</div>
<p class="figurecaption" id="fig-tower2d-waves-all">Figure 7.16 Generating <span class="math">2</span>D steps and waves with perceptrons.</p>
<p class="fm-head2" id="sec-towers">Generating towers with MLPs</p>
<p class="body">The basic idea is depicted in figure <a class="url" href="#fig-tower1d-all">7.15</a>. We can obviously generate a regular step with a perceptron implementing <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">ϕ</i>(<i class="fm-italics">x</i>)</span>. The corresponding graph is shown in figure <a class="url" href="#fig-pos-wt-step-1d">7.15a</a>. By imparting a bias of 5, we can shift this step leftwards. The corresponding function is <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">ϕ</i>(<i class="fm-italics">x</i>+5)</span>. Furthermore, using negative weight laterally flips the step. The corresponding function is <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">ϕ</i>(−<i class="fm-italics">x</i>)</span>, whose graph is shown in figure <a class="url" href="#fig-neg-wt-step-1d">7.15c</a>. By imparting a bias of 5, we can shift the flipped step rightwards. Figure <a class="url" href="#fig-bias-change-1d">7.15e</a> shows a flipped and right-shifted step corresponding to the function <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">ϕ</i>(−<i class="fm-italics">x</i>+5)</span>, whose perceptron is shown in figure <a class="url" href="#fig-bias-change-1d-perceptron">7.15f</a>. Logically ANDing a left-shifted step with a flipped and right-shifted step yields a tower in 1D. This corresponds to the function <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">ϕ</i>(<i class="fm-italics">ϕ</i>(<i class="fm-italics">x</i>+5)+<i class="fm-italics">ϕ</i>(−<i class="fm-italics">x</i>+5)−1.5)</span>, whose graph is shown in figure <a class="url" href="#fig-tower1d">7.15g</a>.</p>
<p class="body"><a id="marker-264"/>The same idea also works for higher-dimensional inputs. We can generate a step in two variables (a <span class="math">2</span>D step) aligned to the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> direction using equation <a class="url" href="#eq-step2dx">7.4</a>. This equation’s graph is shown in figure <a class="url" href="#fig-pos-wt-step-2dx">7.16a</a>, and the perceptron implementing the equation is shown in figure <a class="url" href="#fig-pos-wt-step-2dx-perceptron">7.16b</a>. The flipped version of the same step can be generated via equation <a class="url" href="#eq-flipped_step2dx">7.5</a>. This equation’s graph is shown in figure <a class="url" href="#fig-neg-wt-step-2dx">7.16d</a>, and the perceptron implementation is shown in figure <a class="url" href="#fig-neg-wt-step-2dx-perceptron">7.16e</a>.</p>
<p class="body">In the <span class="math">1</span>D case, we combine a regular step with its flipped and shifted version to generate a tower. The process is slightly more complicated in <span class="math">2</span>D. Here, combining a step along a specific coordinate axis with its flipped and shifted version generates a wave function along that axis. Thus, we have separate waves in each dimension. The wave along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub></span> axis corresponds to equation <a class="url" href="#eq-wave2dx">7.6</a>; its graph is shown in figure <a class="url" href="#fig-wave-2dx">7.16g</a>. It is implemented by the MLP in figure <a class="url" href="#fig-wave-2dx-mlp">7.16h</a>. Similarly, a <span class="math">2</span>D wave along the <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub></span> axis can be generated via equation <a class="url" href="#eq-wave2dy">7.7</a> and is graphed in figure <a class="url" href="#fig-wave-2dy">7.16j</a>. The corresponding MLP is shown in figure <a class="url" href="#fig-wave-2dy-mlp">7.16k</a>.</p>
<p class="body">To create a tower, we have to AND a pair of waves along the two separate dimensions. The final tower function is shown in equation <a class="url" href="#eq-tower2d">7.8</a>; the corresponding tower graph is shown in figure <a class="url" href="#fig-tower-2d">7.17a</a>; the MLP is shown in figure <a class="url" href="#fig-tower-2d-mlp">7.17b</a>. Any continuous <span class="math">2</span>D surface can be approximated to arbitrary levels of accuracy by combining such <span class="math">2</span>D towers:<a id="marker-266"/></p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="410" id="fig-tower-2d" src="../../OEBPS/Images/CH07_F17a_Chaudhury.png" width="480"/></p>
<p class="figurecaption">(a) <span class="math">2</span>D tower</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre29" height="680" id="fig-tower-2d-mlp" src="../../OEBPS/Images/CH07_F17b_Chaudhury.png" width="758"/></p>
<p class="figurecaption">(b) MLP for a <span class="math">2</span>D tower (equation <a class="url" href="#eq-tower2d">7.8</a>)</p>
</div>
<p class="figurecaption" id="fig-tower2d-all">Figure 7.17 Generating a 2D tower with perceptrons</p><!--<p class="Body"><span class="times">$$\begin{aligned}
&amp; y= \phi\left( \begin{bmatrix} 1 &amp; 0
\end{bmatrix}
\begin{bmatrix}
x_{0}\\x_{1}
\end{bmatrix}
\right) \Rightarrow \text{2D step along $x_{0}$}  \\[5pt]
%\tag{Eq:2D step, axis 0}
&amp;y = \phi\left( \begin{bmatrix}
-1 &amp; 0
\end{bmatrix}
\begin{bmatrix}
x_{0}\\x_{1}
\end{bmatrix}
\right) \Rightarrow \text{Flipped 2D step along $x_{0}$}   \\[10pt]
% \tag{Eq:Flipped 2D step, axis 0}
%\end{align}
%\begin{align}
&amp; y = \phi\left( \begin{bmatrix} 1 &amp; 1
\end{bmatrix}
\phi
\left(
\begin{bmatrix} 1 &amp; 0\\
-1 &amp; 0
\end{bmatrix}
\begin{bmatrix}
x_{0}\\x_{1}
\end{bmatrix} +
\begin{bmatrix} 0.5\\0.5
\end{bmatrix}
\right) -1.5\right) \Rightarrow \text{2D wave along $x_{0}$}   \\[12pt]
% \tag{Eq:2D wave, axis 0}
&amp; y = \phi \left(
\begin{bmatrix} 1 &amp; 1
\end{bmatrix}
\phi
\left(
\begin{bmatrix} 0 &amp; 1\\ 0 &amp; -1
\end{bmatrix}
\begin{bmatrix}
x_{0}\\x_{1}
\end{bmatrix} +
\begin{bmatrix} 0.5\\0.5
\end{bmatrix}
\right) -1.5\right) \Rightarrow \text{2D wave along $x_{1}$}  \\[8pt]
% \tag{Eq:2D wave, axis 1}
%\end{align}
%\begin{align}
%&amp; y =
%\begin{bmatrix}
%1 &amp; 1 &amp; 1 &amp; 1
%\end{bmatrix}
%\phi
%\left(
%\begin{bmatrix}
%1 &amp; 0\\
%-1 &amp; 0\\
%0 &amp; 1\\
%0 &amp; -1
%\end{bmatrix}
%\begin{bmatrix}
%x_{0}\\x_{1}
%\end{bmatrix} +
%\begin{bmatrix}
%0.4\\0.4\\0.4\\0.4
%\end{bmatrix}
%\right) -2 \Rightarrow \text{2D plateau}    \\[8pt]
%%\tag{Eq:2D tower with plateaus}
&amp; y =
\phi\left(
\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1
\end{bmatrix}
\phi
\left(
\begin{bmatrix} 1 &amp; 0\\
-1 &amp; 0\\ 0 &amp; 1\\ 0 &amp; -1
\end{bmatrix}
\begin{bmatrix}
x_{0}\\x_{1}
\end{bmatrix} +
\begin{bmatrix} 0.5\\0.5\\0.5\\0.5
\end{bmatrix}
\right) -3.5
\right) \Rightarrow \text{2D tower}
%\tag{Eq:2D tower}\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="76" src="../../OEBPS/Images/eq_07-04.png" width="319"/></p>
</div>
<p class="fm-equation-caption">Equation 7.4 <span class="calibre" id="eq-step2dx"/></p>
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="69" src="../../OEBPS/Images/eq_07-05.png" width="397"/></p>
</div>
<p class="fm-equation-caption">Equation 7.5 <span class="calibre" id="eq-flipped_step2dx"/></p>
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="77" src="../../OEBPS/Images/eq_07-06.png" width="519"/></p>
</div>
<p class="fm-equation-caption">Equation 7.6 <span class="calibre" id="eq-wave2dx"/></p>
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="76" src="../../OEBPS/Images/eq_07-07.png" width="512"/></p>
</div>
<p class="fm-equation-caption">Equation 7.7 <span class="calibre" id="eq-wave2dy"/></p>
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="142" src="../../OEBPS/Images/eq_07-08.png" width="517"/></p>
</div>
<p class="fm-equation-caption">Equation 7.8 <span class="calibre" id="eq-tower2d"/></p>
<p class="fm-callout"><span class="fm-callout-head">NOTE</span> Fully functional code for approximating surfaces using perceptrons, executable via Jupyter Notebook, can be found at <a class="url" href="http://mng.bz/WrKa">http://mng.bz/WrKa</a>.<a id="marker-267"/></p>
<p class="fm-code-listing-caption" id="listing-7.4-perceptrons-and-mlps-in-1d">Listing 7.4 Perceptrons and MLPs in 1D</p>
<pre class="programlisting">x = torch.linspace(start=-10, end=10, steps=100) <span class="fm-combinumeral">①</span>

# 1D S curves - positive weight                  <span class="fm-combinumeral">②</span>
w = torch.tensor([1.0], dtype=torch.float32)
b = torch.tensor([0.0])
y = Perceptron(X=x.unsqueeze(dim=1), W=w.unsqueeze(dim=1), b=b) 

# 1D S curves - negative weight + shift\quad     <span class="fm-combinumeral">③</span>
w = torch.tensor([-1.0], dtype=torch.float32)
b = torch.tensor([5.0])
y = Perceptron(X=x.unsqueeze(dim=1), W=w.unsqueeze(dim=1), b=b) 

# 1D towers (Cybenko) - various W0\quad          <span class="fm-combinumeral">④</span>
W0 = torch.tensor([[1.0], [-1.0]], dtype=torch.float32)
b0 = torch.tensor([5.0, 5.0])
W1 = torch.tensor([[1.0, 1.0]], dtype=torch.float32)
b1 = torch.tensor([0.0])
y = MLP(X=x.unsqueeze(dim=1), W0=W0, W1=W1, b0=b0, b1=b1)</pre>
<p class="fm-code-annotation"><span class="fm-combinumeral">①</span> 100D array</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">②</span> See figures <a class="url" href="#fig-pos-wt-step-1d">7.15a</a> and <a class="url" href="#fig-pos-wt-step-1d-perceptron">7.15b</a>.</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">③</span> See figures <a class="url" href="#fig-bias-change-1d">7.15e</a> and <a class="url" href="#fig-bias-change-1d-perceptron">7.15f</a>.</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">④</span> See figures <a class="url" href="#fig-tower1d">7.15g</a> and <a class="url" href="#fig-tower1d-mlp">7.15h</a>.</p>
<p class="fm-code-listing-caption" id="listing-7.5-perceptrons-and-mlps-in-2d">Listing 7.5 Perceptrons and MLPs in 2D</p>
<pre class="programlisting">X = torch.linspace(start=-1, end=1, steps=100)      <span class="fm-combinumeral">①</span>
Y = torch.linspace(start=-1, end=1, steps=100)      <span class="fm-combinumeral">①</span>

gridX, gridY = torch.meshgrid(X, Y)                 <span class="fm-combinumeral">②</span>
X = torch.tensor([(y, x) for y, x in
         zip(gridY.reshape(-1), gridX.reshape(-1))) <span class="fm-combinumeral">③</span>

# 2D Step function in X-direction                   <span class="fm-combinumeral">④</span>
W = torch.tensor([[1.0, 0.0]], dtype=torch.float32)
b = torch.tensor([0.0], dtype=torch.float32)
Z = Perceptron(X=X, W=W, b=b)

# 2D Flipped Step function along X-direction        <span class="fm-combinumeral">⑤</span>
W = torch.tensor([[-1.0, 0.0]], dtype=torch.float32)
b = torch.tensor([0.0], dtype=torch.float32)
Z = Perceptron(X=X, W=W, b=b)

# 2D wave along X-direction                         <span class="fm-combinumeral">⑥</span>
W0 = torch.tensor([[1.0, 0.0],
                   [-1.0, 0.0]], dtype=torch.float32)
b0 = torch.tensor([0.5, 0.5], dtype=torch.float32)
W1 = torch.tensor([[1.0, 1.0]], dtype=torch.float32)
b1 = torch.tensor([-1.0])
Z = MLP(X=X, W0=W0, W1=W1, b0=b0, b1=b1) 

# 2D wave along Y-direction                          <span class="fm-combinumeral">⑦</span>
W0 = torch.tensor([[0.0, 1.0],
                   [0.0, -1.0]], dtype=torch.float32)
b0 = torch.tensor([0.5, 0.5], dtype=torch.float32)
W1 = torch.tensor([[1.0, 1.0]], dtype=torch.float32)
b1 = torch.tensor([-1.0])
Z = MLP(X=X, W0=W0, W1=W1, b0=b0, b1=b1)

# 2D Tower                                           <span class="fm-combinumeral">⑧</span>
W0 = torch.tensor([[1.0, 0.0],
                   [-1.0, 0.0],
                   [0.0, 1.0],
                   [0.0, -1.0]], dtype=torch.float32)
b0 = torch.tensor([0.5, 0.5, 0.5, 0.5], dtype=torch.float32)
W1 = torch.tensor([[1.0, 1.0, 1.0, 1.0]], dtype=torch.float32)
b1 = torch.tensor([-3.5])
Z = MLP(X=X, W0=W0, W1=W1, b0=b0, b1=b1)</pre>
<p class="fm-code-annotation"><span class="fm-combinumeral">①</span> 100D array</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">②</span> 100 <span class="math">×</span> 100 matrix</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">③</span> 10,000 <span class="math">×</span> 1 matrix</p>
<p class="fm-code-annotation"><span class="fm-combinumeral">④</span> See equation <a class="url" href="#eq-step2dx">7.4</a> and figures <a class="url" href="#fig-pos-wt-step-2dx">7.16a</a> and <a class="url" href="#fig-pos-wt-step-2dx-perceptron">7.16b</a></p>
<p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> See equation <a class="url" href="#eq-flipped_step2dx">7.5</a> and figures <a class="url" href="#fig-neg-wt-step-2dx">7.16d</a> and <a class="url" href="#fig-neg-wt-step-2dx-perceptron">7.16e</a></p>
<p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> See equation <a class="url" href="#eq-wave2dx">7.6</a> and figures <a class="url" href="#fig-wave-2dx">7.16g</a> and <a class="url" href="#fig-wave-2dx-mlp">7.16h</a></p>
<p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> See equation <a class="url" href="#eq-wave2dy">7.7</a> and figures <a class="url" href="#fig-wave-2dy">7.16j</a> and <a class="url" href="#fig-wave-2dy-mlp">7.16k</a></p>
<p class="fm-code-annotation"><span class="fm-combinumeral">⑧</span> See equation <a class="url" href="#eq-tower2d">7.8</a> and figures <a class="url" href="#fig-tower-2d">7.17a</a> and <a class="url" href="#fig-tower-2d-mlp">7.17b</a></p>
<h3 class="fm-head1" id="mlps-for-polygonal-decision-boundaries">7.5.4 MLPs for polygonal decision boundaries</h3>
<p class="body"><a id="marker-268"/>We have seen that classifiers form an important use case for neural networks. In section <a class="url" href="#sec-decision-boundaries">7.2.2.1</a>, we also saw that classifiers essentially model decision boundaries in high-dimensional feature spaces. In this section, we model a simple class bounded with a fixed polygon to understand the process.</p>
<p class="body">Figure <a class="url" href="#fig-feature-space-with-decision-boundaries">7.18a</a> shows a feature space with the class to be identified corresponding to a rectangular region (shaded) bounded by the four straight lines:</p>
<p class="fm-equation"><span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = –5        <i class="fm-italics">x</i><sub class="fm-subscript">0</sub> = 5</span><br class="calibre20"/>
<span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = –2        <i class="fm-italics">x</i><sub class="fm-subscript">1</sub> = 2</span></p>
<p class="body">Each of these lines partitions the feature space into two half-planes, indicated by minus and plus signs in figure <a class="url" href="#fig-feature-space-with-decision-boundaries">7.18a</a>. The region containing the feature points for the class of interest is indicated by all <span class="math">+</span> signs.</p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre22" height="235" id="fig-feature-space-with-decision-boundaries" src="../../OEBPS/Images/CH07_F18a_Chaudhury.png" width="416"/></p>
<p class="figurecaption">(a) Example feature space with decision boundaries enclosing the class of interest (shaded)</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre13" height="676" id="fig-feature-space-with-decision-boundaries-mlp" src="../../OEBPS/Images/CH07_F18b_Chaudhury.png" width="743"/></p>
<p class="figurecaption">(b) MLP that fires only on points in the shaded region</p>
</div>
<p class="figurecaption" id="fig-MLP-rect">Figure 7.18 Modeling a rectangular decision region with MLPs</p>
<p class="body">The shaded region corresponding to the class of interest is the region where <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> ≥ − 5</span> AND <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> ≤ 5</span> AND <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> ≥ − 2</span> AND <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> ≤ 2</span>. Now consider the perceptron <span class="math"><i class="fm-italics">ϕ</i>(<i class="fm-italics">x</i><sub class="fm-subscript">0</sub>+5)</span>. It fires (outputs <span class="math">1</span>) on the region <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> ≥ − 5</span>. Similarly, the perceptrons <span class="math"><i class="fm-italics">ϕ</i>(−<i class="fm-italics">x</i><sub class="fm-subscript">0</sub>+5)</span>, <span class="math"><i class="fm-italics">ϕ</i>(<i class="fm-italics">x</i><sub class="fm-subscript">1</sub>+2)</span>, and <span class="math"><i class="fm-italics">ϕ</i>(−<i class="fm-italics">x</i><sub class="fm-subscript">1</sub>+2)</span> fire on the regions <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">0</sub> ≤ 5</span>, <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> ≥ − 2</span>, and <span class="math"><i class="fm-italics">x</i><sub class="fm-subscript">1</sub> ≤ 2</span>, respectively. Hence, by logically ANDing the outputs of these perceptrons, we get an MLP that fires only on the shaded region of interest. Figure <a class="url" href="#fig-feature-space-with-decision-boundaries-mlp">7.53</a> shows this MLP. It implements the following function:<a id="marker-269"/></p><!--<p class="FM-Equation"><span class="times">$$y =
\phi\left(
\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1
\end{bmatrix}
\phi
\left(
\begin{bmatrix}
&amp;1 &amp; 0\\[-3pt]
&amp;-1 &amp; 0\\[-3pt]
&amp;0 &amp; 1\\[-3pt]
&amp;0 &amp; -1\\
\end{bmatrix}
\begin{bmatrix}
x_0\\[-3pt] x_1
\end{bmatrix} +
\begin{bmatrix} 5\\[-3pt] 5\\[-3pt] 2 \\[-3pt] 2
\end{bmatrix}
\right)
- 3.5
\right)$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="122" src="../../OEBPS/Images/eq_07-08-a.png" width="432"/></p>
</div>
<p class="body">All shapes on a plane can be approximated by polygons. Hence, given sufficient perceptrons, any shape on a plane can be depicted to an arbitrary level of accuracy.</p>
<h2 class="fm-head" id="summary-6">Summary</h2>
<p class="body">In this chapter, we outlined how a large variety of real-world problems can be modeled as function evaluation:<a id="marker-270"/></p>
<ul class="calibre6">
<li class="fm-list-bullet">
<p class="list">Any intelligent task can be modeled by a function. Of particular interest are classification tasks where, given an input, we estimate from a predetermined list of possible classes the class to which the input belongs. For instance, a binary classifier can group input images into two classes: those that contain a human face and those that do not. Classification tasks can be approximated by functions with categorical outputs.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Neural networks provide a structured way to approximate arbitrary functions (including classifier functions). This is how they mimic intelligence.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Neural networks are created by combining a basic building block called a perceptron. A perceptron is a simple function that returns a step function applied to the weighted sum of its inputs (plus a bias). A perceptron is effectively a linear classifier that divides space into two half-spaces with a hyperplane. The weights and bias of the perceptron correspond to the orientation and position of the hyperplane—they can be adjusted to separate the regions corresponding to individual classes as much as possible.</p>
</li>
<li class="fm-list-bullet">
<p class="list">A single perceptron can approximate only relatively simple functions, such as a classifier whose feature points are separable by a hyperplane. Perceptrons cannot approximate more complex functions, like classifiers whose input regions are to be separated with curved surfaces. Multilayer perceptrons (MLPs) are combinations of perceptrons where the outputs of one set (layer) of perceptrons are fed as input to the next set (layer). A neural network is essentially an MLP and can approximate such arbitrarily complex functions.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Simple logical functions like AND, OR, and NOT can be emulated with a single perceptron. A logical XOR cannot be. For XORs and other complicated logical functions, we need MLPs. There is a mechanical way to construct an MLP for any logical function. A logical function can always be represented by a truth table. Each row of the truth table can be viewed as a logical AND function of the inputs, and the final output is a logical OR of the inputs. Since ANDs and ORs can be emulated with perceptrons, any truth table can be emulated as a combination of perceptrons (an MLP).</p>
</li>
<li class="fm-list-bullet">
<p class="list">The ability of an MLP to represent arbitrary functions is known as its expressive power. The larger the number of perceptrons and/or connections, the greater the expressive power of a neural network.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Cybenko’s theorem proves that a neural network is a universal approximator (meaning it can approximate any function). The basic idea is that any function can be approximated to an arbitrary degree of accuracy as a sum of rectangles (towers). The theorem demonstrates that a tower can be constructed in any dimensional space using MLPs.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Neural networks can approximate any shape on a plane to arbitrary accuracy. This is because all shapes can be approximated by rectangles, and we can demonstrably approximate a rectangle on a plane with MLPs.</p>
</li>
<li class="fm-list-bullet">
<p class="list">In real-life problems, the regions corresponding to classes are unknown, but we manually label sample input points with desired outputs (ground truth) to create supervised training data. We tune the weights and biases to approximate the training data as closely as possible. This process of tuning is known as training. If the training data set is not a good representative of the real dataset, the neural network will be inaccurate even after training.<a id="marker-271"/></p>
</li>
</ul>
</div></body></html>