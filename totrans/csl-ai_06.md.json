["```py\nimport torch   \nUSE_CUDA = False   #1\nDEVICE_TYPE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n```", "```py\nfrom torch.utils.data import Dataset\n\nimport numpy as np\nimport pandas as pd\nfrom torchvision import transforms\n\nclass CombinedDataset(Dataset):    #1\n    def __init__(self, csv_file):\n        self.dataset = pd.read_csv(csv_file)\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        images = self.dataset.iloc[idx, 3:]     #2\n        images = np.array(images, dtype='float32')/255\\.   #2\n        images = images.reshape(28, 28)    #2\n        transform = transforms.ToTensor()     #2\n        images = transform(images)     #2\n        digits = self.dataset.iloc[idx, 2]     #3\n        digits = np.array([digits], dtype='int')     #3\n        is_handwritten = self.dataset.iloc[idx, 1]     #4\n        is_handwritten = np.array([is_handwritten], dtype='float32')    #4\n        return images, digits, is_handwritten    #5\n```", "```py\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\n\ndef setup_dataloaders(batch_size=64, use_cuda=USE_CUDA):     #1\n    combined_dataset = CombinedDataset(\n\"https://raw.githubusercontent.com/altdeep/causalML/master/datasets\nâ†ª/combined_mnist_tmnist_data.csv\"\n    )\n    n = len(combined_dataset)     #2\n    train_size = int(0.8 * n)    #2\n    test_size = n - train_size    #2\n    train_dataset, test_dataset = random_split(     #2\n        combined_dataset,   #2\n        [train_size, test_size],    #2\n        generator=torch.Generator().manual_seed(42)   #2\n    )     #2\n    kwargs = {'num_workers': 1, 'pin_memory': use_cuda} #2\n    train_loader = DataLoader(     #3\n        train_dataset,     #3\n        batch_size=batch_size,     #3\n        shuffle=True,     #3\n        **kwargs    #3\n    )     #3\n    test_loader = DataLoader(   #3\n        test_dataset,    #3\n        batch_size=batch_size,    #3\n        shuffle=True,     #3\n        **kwargs   #3\n    )     #3\n    return train_loader, test_loader\n```", "```py\nfrom torch import nn\n\nclass Decoder(nn.Module):    #1\n    def __init__(self, z_dim, hidden_dim):\n        super().__init__()\n        img_dim = 28 * 28     #2\n        digit_dim = 10    #3\n        is_handwritten_dim = 1    #4\n        self.softplus = nn.Softplus()     #5\n        self.sigmoid = nn.Sigmoid()    #5\n        encoding_dim = z_dim + digit_dim + is_handwritten_dim     #6\n        self.fc1 = nn.Linear(encoding_dim, hidden_dim)   #6\n        self.fc2 = nn.Linear(hidden_dim, img_dim)    #7\n\n    def forward(self, z, digit, is_handwritten):     #8\n        input = torch.cat([z, digit, is_handwritten], dim=1) #9\n        hidden = self.softplus(self.fc1(input))    #10\n        img_param = self.sigmoid(self.fc2(hidden))    #11\n        return img_param\n```", "```py\nimport pyro\nimport pyro.distributions as dist\n\ndist.enable_validation(False)    #1\ndef model(self, data_size=1):     #2\n    pyro.module(\"decoder\", self.decoder)    #2\n    options = dict(dtype=torch.float32, device=DEVICE_TYPE)\n    z_loc = torch.zeros(data_size, self.z_dim, **options)    #3\n    z_scale = torch.ones(data_size, self.z_dim, **options)   #3\n    z = pyro.sample(\"Z\", dist.Normal(z_loc, z_scale).to_event(1))    #3\n    p_digit = torch.ones(data_size, 10, **options)/10     #4\n    digit = pyro.sample(     #4\n        \"digit\",    #4\n        dist.OneHotCategorical(p_digit)     #4\n    )    #4\n    p_is_handwritten = torch.ones(data_size, 1, **options)/2     #5\n    is_handwritten = pyro.sample(    #5\n        \"is_handwritten\",     #5\n        dist.Bernoulli(p_is_handwritten).to_event(1)     #5\n    )     #5\n    img_param = self.decoder(z, digit, is_handwritten)   #6\n    img = pyro.sample(\"img\", dist.Bernoulli(img_param).to_event(1))   #7\n    return img, digit, is_handwritten\n```", "```py\ndef training_model(self, img, digit, is_handwritten, batch_size):     #1\n    conditioned_on_data = pyro.condition(     #2\n        self.model,\n        data={\n            \"digit\": digit,\n            \"is_handwritten\": is_handwritten,\n            \"img\": img\n        }\n    )\n    with pyro.plate(\"data\", batch_size): #3\n        img, digit, is_handwritten = conditioned_on_data(batch_size)\n    return img, digit, is_handwritten\n```", "```py\nclass Encoder(nn.Module):     #1\n    def __init__(self, z_dim, hidden_dim):\n        super().__init__()\n        img_dim = 28 * 28     #2\n        digit_dim = 10  #3\n        is_handwritten_dim = 1\n        self.softplus = nn.Softplus()    #4\n        input_dim = img_dim + digit_dim + is_handwritten_dim     #5\n        self.fc1 = nn.Linear(input_dim, hidden_dim)   #5\n        self.fc21 = nn.Linear(hidden_dim, z_dim) #6\n        self.fc22 = nn.Linear(hidden_dim, z_dim)    #6\n\n    def forward(self, img, digit, is_handwritten):    #7\n        input = torch.cat([img, digit, is_handwritten], dim=1)     #8\n        hidden = self.softplus(self.fc1(input))    #9\n        z_loc = self.fc21(hidden)     #10\n        z_scale = torch.exp(self.fc22(hidden))  #10\n        return z_loc, z_scale\n```", "```py\ndef training_guide(self, img, digit, is_handwritten, batch_size):     #1\n    pyro.module(\"encoder\", self.encoder)    #2\n    options = dict(dtype=torch.float32, device=DEVICE_TYPE)\n    with pyro.plate(\"data\", batch_size):     #3\n        z_loc, z_scale = self.encoder(img, digit, is_handwritten)    #4\n        normal_dist = dist.Normal(z_loc, z_scale).to_event(1)    #4\n        z = pyro.sample(\"Z\", normal_dist)     #5\n```", "```py\nclass VAE(nn.Module):\n    def __init__(\n        self,\n        z_dim=50,    #1\n        hidden_dim=400,    #2\n        use_cuda=USE_CUDA,\n    ):\n        super().__init__()\n        self.use_cuda = use_cuda\n        self.z_dim = z_dim\n        self.hidden_dim = hidden_dim\n        self.setup_networks()\n\n    def setup_networks(self):     #3\n        self.encoder = Encoder(self.z_dim, self.hidden_dim)\n        self.decoder = Decoder(self.z_dim, self.hidden_dim)\n        if self.use_cuda:\n            self.cuda()\n\n    model = model     #4\n    training_model = training_model    #4\n    training_guide = training_guide    #4\n```", "```py\ndef plot_image(img, title=None):     #1\n    fig = plt.figure()\n    plt.imshow(img.cpu(), cmap='Greys_r', interpolation='nearest')\n    if title is not None:\n        plt.title(title)\n    plt.show()\n```", "```py\nimport matplotlib.pyplot as plt\n\ndef reconstruct_img(vae, img, digit, is_hw, use_cuda=USE_CUDA):     #1\n    img = img.reshape(-1, 28 * 28)\n    digit = F.one_hot(torch.tensor(digit), 10)\n    is_hw = torch.tensor(is_hw).unsqueeze(0)\n    if use_cuda:\n        img = img.cuda()\n        digit = digit.cuda()\n        is_hw = is_hw.cuda()\n    z_loc, z_scale = vae.encoder(img, digit, is_hw)\n    z = dist.Normal(z_loc, z_scale).sample()\n    img_expectation = vae.decoder(z, digit, is_hw)\n    return img_expectation.squeeze().view(28, 28).detach()\n\ndef compare_images(img1, img2):    #2\n    fig = plt.figure()\n    ax0 = fig.add_subplot(121)\n    plt.imshow(img1.cpu(), cmap='Greys_r', interpolation='nearest')\n    plt.axis('off')\n    plt.title('original')\n    ax1 = fig.add_subplot(122)\n    plt.imshow(img2.cpu(), cmap='Greys_r', interpolation='nearest')\n    plt.axis('off')\n    plt.title('reconstruction')\n    plt.show()\n```", "```py\nimport torch.nn.functional as F\n\ndef get_random_example(loader):    #1\n    random_idx = np.random.randint(0, len(loader.dataset))    #1\n    img, digit, is_handwritten = loader.dataset[random_idx]     #1\n    return img.squeeze(), digit, is_handwritten    #1\n\ndef reshape_data(img, digit, is_handwritten):     #2\n    digit = F.one_hot(digit, 10).squeeze()     #2\n    img = img.reshape(-1, 28*28)     #2\n    return img, digit, is_handwritten     #2\n\ndef generate_coded_data(vae, use_cuda=USE_CUDA):     #3\n    z_loc = torch.zeros(1, vae.z_dim)     #3\n    z_scale = torch.ones(1, vae.z_dim)     #3\n    z = dist.Normal(z_loc, z_scale).to_event(1).sample()     #3\n    p_digit = torch.ones(1, 10)/10     #3\n    digit = dist.OneHotCategorical(p_digit).sample()     #3\n    p_is_handwritten = torch.ones(1, 1)/2     #3\n    is_handwritten = dist.Bernoulli(p_is_handwritten).sample()    #3\n    if use_cuda:     #3\n        z = z.cuda() #3\n        digit = digit.cuda() #3\n        is_handwritten = is_handwritten.cuda()     #3\n    img = vae.decoder(z, digit, is_handwritten)     #3\n    return img, digit, is_handwritten    #3\n\ndef generate_data(vae, use_cuda=USE_CUDA):     #4\n    img, digit, is_handwritten = generate_coded_data(vae, use_cuda)    #4\n    img = img.squeeze().view(28, 28).detach()    #4\n    digit = torch.argmax(digit, 1)   #4\n    is_handwritten = torch.argmax(is_handwritten, 1)     #4\n    return img, digit, is_handwritten     #4\n```", "```py\nfrom pyro.infer import SVI, Trace_ELBO\nfrom pyro.optim import Adam\n\npyro.clear_param_store()     #1\nvae = VAE()    #2\ntrain_loader, test_loader = setup_dataloaders(batch_size=256)    #3\nsvi_adam = Adam({\"lr\": 1.0e-3})     #4\nmodel = vae.training_model    #5\nguide = vae.training_guide    #5\nsvi = SVI(model, guide, svi_adam, loss=Trace_ELBO())     #5\n```", "```py\ndef test_epoch(vae, test_loader):\n    epoch_loss_test = 0     #1\n    for img, digit, is_hw in test_loader:    #1\n        batch_size = img.shape[0]    #1\n        if USE_CUDA:    #1\n            img = img.cuda()    #1\n            digit = digit.cuda()     #1\n            is_hw = is_hw.cuda()  #1\n        img, digit, is_hw = reshape_data(     #1\n            img, digit, is_hw     #1\n        )   #1\n        epoch_loss_test += svi.evaluate_loss(     #1\n            img, digit, is_hw, batch_size    #1\n        )    #1\n    test_size = len(test_loader.dataset)    #1\n    avg_loss = epoch_loss_test/test_size     #1\n    print(\"Epoch: {} avg. test loss: {}\".format(epoch, avg_loss))     #1\n    print(\"Comparing a random test image to its reconstruction:\")    #2\n    random_example = get_random_example(test_loader)     #2\n    img_r, digit_r, is_hw_r = random_example    #2\n    img_recon = reconstruct_img(vae, img_r, digit_r, is_hw_r)     #2\n    compare_images(img_r, img_recon)     #2\n    print(\"Generate a random image from the model:\")    #3\n    img_gen, digit_gen, is_hw_gen = generate_data(vae)    #3\n    plot_image(img_gen, \"Generated Image\")     #3\n    print(\"Intended digit: \", int(digit_gen))    #3\n    print(\"Intended as handwritten: \", bool(is_hw_gen == 1))     #3\n```", "```py\nNUM_EPOCHS = 2500\nTEST_FREQUENCY = 10\n\ntrain_loss = []\ntrain_size = len(train_loader.dataset)\n\nfor epoch in range(0, NUM_EPOCHS+1):   #1\n    loss = 0\n    for img, digit, is_handwritten in train_loader:\n        batch_size = img.shape[0]\n        if USE_CUDA:\n            img = img.cuda()\n            digit = digit.cuda()\n            is_handwritten = is_handwritten.cuda()\n        img, digit, is_handwritten = reshape_data(\n            img, digit, is_handwritten\n        )\n        loss += svi.step(    #2\n            img, digit, is_handwritten, batch_size     #2\n        )     #2\n    avg_loss = loss / train_size\n    print(\"Epoch: {} avgs training loss: {}\".format(epoch, loss))\n    train_loss.append(avg_loss)\n    if epoch % TEST_FREQUENCY == 0:    #3\n        test_epoch(vae, test_loader)    #3\n```"]