- en: 9 The general counterfactual inference algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Implementing the general counterfactual inference algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Directly implementing a parallel world DAG as a causal graphical model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a variational inference to implement the algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building counterfactual deep generative models of images
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The previous chapter taught you how to formalize counterfactuals and use the
    parallel world graph to reason across possible worlds. In this chapter, I’ll introduce
    an algorithm for inferring counterfactual queries. Then I’ll present three case
    studies showing implementations of the algorithm using different probabilistic
    ML approaches.
  prefs: []
  type: TYPE_NORMAL
- en: I call the algorithm we’ll discuss in this chapter the “general” algorithm for
    probabilistic counterfactual inference because you can infer any counterfactual
    query with this algorithm. The catch is that you need an SCM. Moreover, differences
    between your SCM and the ground-truth SCM can lead to inaccuracies in your counterfactual
    inferences. We’ll look more closely at this issue when we discuss identification
    in chapter 10, where you’ll also learn ways of inferring counterfactuals without
    knowing the ground-truth SCM. In this chapter, you’ll see the power of this SCM-based
    approach, especially in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Algorithm walkthrough
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we’ll do a high-level walkthrough of the general algorithm
    probabilistic counterfactual inference. The algorithm has three steps commonly
    called *abduction*, *action*, and *prediction*:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Abduction*—Infer the distribution of the exogenous variables given the factual
    conditions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Action*—Implement the hypothetical condition as an ideal intervention (graph
    surgery) in the hypothetical world.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Prediction*—Use the conditional distribution on the exogenous variables from
    step 1 to derive the distributions of the hypothetical outcomes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I’ll illustrate how we can perform these steps using the parallel world graph
    for our online gaming example, shown again as a parallel world graph in figure
    9.1.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F01_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 A parallel world graph for the online gaming example
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Recall that in this example, guild member *G* is a cause of side-quest engagement
    *E* and in-game purchases *I*. Side-quest engagement is also a cause of in-game
    purchases.
  prefs: []
  type: TYPE_NORMAL
- en: Note  This example changes the condition *I* < $50 used in chapter 8 to *I*
    = $50 in order to make the explanations a bit less verbose. Either condition would
    work with the algorithm we’re discussing.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s suppose our counterfactual question is “For a player with low side-quest
    engagement and $50 of in-game purchases, what would their level of in-game purchases
    be if their side-quest engagement were high?” The corresponding query is *P*(*IE*
    =“high”|*E*=“low”, *I*=50). Let’s examine how to apply the algorithm to this query.
  prefs: []
  type: TYPE_NORMAL
- en: '9.1.1 Abduction: Infer the exogenous variables given the observed endogenous
    variables'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The term “abduction” refers to doing *abductive inference*, meaning we’re inferring
    causes from observed outcomes. In our online gaming SCM, we want to infer the
    latent exogenous variables (*N*[*G*], *N*[*E*], and *N*[*I*]) from the factual
    conditions (*E*=“low” and *I*=50).
  prefs: []
  type: TYPE_NORMAL
- en: In our probabilistic modeling approach, we treat the exogenous variables as
    latent variables and target them with probabilistic inference. In our example,
    we infer *N*[*E*] from observing *E*=“low”. Figures 9.2 and 9.3 illustrate the
    d-connected paths to inference of *N*[*G*] and *N*[*I*], respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see in figure 9.2, we have a path from *E* to *N*[*G*] through the
    path *E*←*G*←*N*[*G*]. Further, observing both *E* and *I* opens a collider path
    to *N*[*G*]: *E*→*I*←*G*←*N*[*G*]. Similarly, in figure 9.3, observing *E* and
    *I* also opens a collider path to *N*[*I*] via *E*→*I*←*N*[*I*].'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F02_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 To infer the counterfactual outcomes, we infer the exogenous variables
    conditional on observed outcomes in the actual world. There is a path from *E*
    to *N**[G]* through the path *E*←*G*←*N**[G]*. Also, observing *E* and *I* opens
    a collider path *E*→*I*←*G*←*N**[G]*.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F03_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 Observing *E* and *I* opens a collider path to *N**[I]* via *E*→*I*←*N**[I]*.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Finally, observing *E* has a directly connecting path to *N*[*E*], as shown
    in figure 9.4.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F04_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 *E* is a direct child of *N**[E]*, so observing *E* gives direct
    information about *N**[E]*.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Our SCM is a probabilistic model. In the abduction step, we use this model to
    infer *P*(*N*[*G*], *N*[*E*], *N*[*I*]| *E*=“low”, *I*=50). That inference will
    follow these paths of dependence.
  prefs: []
  type: TYPE_NORMAL
- en: '9.1.2 Action: Implementing the hypothetical causes'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recall from chapter 8 that we use the ideal intervention to implement hypothetical
    conditions. Our hypothetical condition is “if their side-quest engagement were
    high,” and we implement this with an ideal intervention that sets *E* to “high”
    in the hypothetical world. Since we’re using a graph, we implement the intervention
    with graph surgery as in figure 9.5.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F05_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 Implement the hypothetical condition as an ideal intervention (via
    graph surgery) in the hypothetical world.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now the parallel worlds differ. Note that the probability distributions on the
    exogenous variables have been updated with information from the actual world during
    the abduction step. In the final step, we’ll propagate this information through
    this modified hypothetical world.
  prefs: []
  type: TYPE_NORMAL
- en: '9.1.3 Prediction: Inferring hypothetical outcomes'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’re working with an SCM, so the values of the variables in the hypothetical
    world are set deterministically by the exogenous variables. Having updated the
    exogenous variable distributions conditional on observations in the actual world,
    we’ll now propagate that actual world information from the exogenous variables
    to the endogenous variables in the hypothetical world. If we hadn’t applied the
    intervention in the hypothetical world, the hypothetical world would mirror everything
    we observed in the actual world by the law of consistency (see the definition
    in chapter 8). However, since we applied an intervention in the hypothetical world,
    the hypothetical variable distributions downstream of that intervention can differ
    from those in the actual world.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F06_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 Paths for inferring the hypothetical distribution of *I* from the
    conditional distribution *P*(*N**[G]*, *N**[E]*, *N**[I]*| *E*=“low”, *I*=50)
    on the exogenous variables, given the observed actual world outcomes
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In our gaming example, our query *P*(*I*[*E*][=“high”]|*E*=“low”, *I* = 50)
    targets the hypothetical value of *I*[*E*][=“high”]. Figure 9.6 illustrates the
    path of inference from the exogenous variables to the hypothetical value of *I*[*E*][=][“high”].
    Note that in this example, the paths of influence only come from *N*[*G*] and
    *N*[*I*], since the intervention on *E* cut *N*[*E*]’s bridge to the hypothetical
    world.
  prefs: []
  type: TYPE_NORMAL
- en: Be careful about d-connection and d-separation on parallel world graphs
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Recall that with a causal DAG, we can use a graphical criterion called d-separation/d-connection
    to reason about conditional independence in the data generating process using
    a causal DAG. Indeed, this is what I do when I highlight paths of inference to
    *I**[E]*[=“high”] given *E* and *I* via *N**[I]* and *N**[G]*. I do this to explain
    the abduction and prediction steps of the algorithm. However, in general, one
    cannot rely on d-separation and d-connection to reason about the dependence between
    endogenous variables across worlds. That’s because the law of consistency requires
    that the same endogenous variables across worlds must have the same value (unless
    one of the pairs is impacted by an intervention). Two variables always having
    the same value is a *perfect* dependence; the rules of d-separation do not capture
    that dependence on the parallel world graph.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, I’ll introduce *counterfactual graphs*, a causal DAG derived
    from a parallel world graph where the connections between d-separation and independence
    hold across worlds.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see how information flows during inference from factual conditions *E*=“low”
    and *I*=50 in the actual world, through the exogenous variables, to our target
    variable *I*[*E*][=“high”] in the hypothetical world. How we implement the inference
    depends on our preference for inference algorithms. For example, suppose *f*[*G*],
    and *f*[*I*] represent the SCM’s assignment functions for *G* and *I*. We could
    use a simple forward-sampling algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Draw a sample of exogenous values *n*[*G*], *n*[*E*], and *n*[*I*] from *P*(*N*[*G*],
    *N*[*E*], *N*[*I*]| *E*=“low”, *I*=50).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Derive a sample of the hypothetical value of guild membership *g*^* = *f*[*G*](*n*[*G*]).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Derive a sample of the hypothetical value of in-game purchases *i*^* = *f*[*I*](*E*=“high”,
    *g*^*, *n*[*I*]).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat many times to get samples from the distribution *P*(*I*[*E*][=“high”]|*E*=“low”,
    *I* = 50).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This would give us samples from our target *P*(*I*[*E*][=“high”]|*E*=“low”,
    *I* = 50).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 9.1.4 Counterfactual Monte Carlo
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The output of the general probabilistic counterfactual inference algorithm produces
    samples from a distribution. Recall from chapter 2 that once you can sample from
    a distribution, you can apply the Monte Carlo techniques to make inferences based
    on that distribution. That same is true with counterfactual distributions.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in chapter 8, I introduced the idea of regret, where we compare
    counterfactual outcomes. For our player who had low engagement and only spent
    $50, we might ask how much *more* their in-game purchases would have been had
    engagement been high. Given the gamer spent $50, we can define a regret variable
    as *R*[*E*][=][*e*] = *I*[*E*][=][*e*] – 50\. By taking our samples from *P*(*I*[*E*][=“high”]
    |*E*=“low”, *I*=50) and subtracting 50, we get samples from *P*(*R*[*E*][=“high”]
    |*E*=“low”, *I* = 50). We can also take the average of those differences to estimate
    expected regret *E*(*R*[*E*][=“high”] |*E*=“low”, *I* = 50). Note that *E*(…)
    here refers to the expectation operator, not to side-quest engagement.
  prefs: []
  type: TYPE_NORMAL
- en: When we want to use these counterfactual Monte Carlo techniques in automated
    decision-making algorithms, we are typically posing counterfactual questions about
    *policies*. Suppose, for example, a recommendation algorithm recommends certain
    content to a player based on their profile. We can contrast the amount of in-game
    purchases they made under one recommendation policy to the amount they would have
    made under a different policy. We can then adjust the recommendation algorithm
    in a way that would have minimized cumulative regret across players. We’ll look
    at automated decision-making more closely in chapter 12.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll explore a few case studies of various ways to implement this algorithm
    in code.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1.5 Introduction to the case studies
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are several ways we can implement this algorithm using modern probabilistic
    ML tools. In sections 9.2–9.4, we’ll explore three case studies.
  prefs: []
  type: TYPE_NORMAL
- en: Monty Hall problem
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The first case study will focus on the Monty Hall problem discussed earlier
    in section 6.3\. We’ll use the pgmpy library to implement a full parallel-world
    graphical SCM. We’ll use pgmpy’s `TabularCPD` to implement SCM assignment functions,
    something it wasn’t designed to do. In exchange for this awkwardness, we’ll be
    able to leverage pgmpy’s graph-based inference algorithm (`VariableElimination`)
    to collapse the abduction and prediction steps into one inference step. Using
    graph-based inference will save us from implementing an inference algorithm for
    abduction; we only have to build the model, apply the action step, and run inference.
  prefs: []
  type: TYPE_NORMAL
- en: Femur length and height
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Next, we’ll revisit the forensics example from section 6.1, where we have an
    SCM in which femur length is a cause of height. This example will show us how
    to do the abduction step with variational inference, a modern and popular probabilistic
    inference technique that works well with cutting-edge deep learning frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we’ll implement the SCM in Pyro, a PyTorch-based library for
    probabilistic ML. Using Pyro will feel less awkward than pgmpy because Pyro modeling
    abstractions are more flexible. The trade-off is that we must write explicit inference
    code for the abduction step.
  prefs: []
  type: TYPE_NORMAL
- en: 'The example is simple: the data is small, each variable has only one dimension,
    and the relationships are linear. However, we can use the same variational inference-based
    abduction technique with the large, high-dimensional, and nonlinear data settings
    where variational inference shines.'
  prefs: []
  type: TYPE_NORMAL
- en: Semantic image editing with counterfactuals
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the final case study, we’ll examine how we’d apply the counterfactual inference
    algorithm using a pretrained generative image model in PyTorch. While the Monty
    Hall and femur length problems are simple problems with simple math, this case
    study demonstrates the use of the algorithm on a modern problem with image generation
    in deep generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: '9.2 Case study 1: Monty Hall problem'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ll start by revisiting the SCM for the Monty Hall problem. Summarizing again,
    there is a game show where the player starts with a choice of three doors. Behind
    one door is a car. The player picks a door, say the first door, and the host,
    who knows what’s behind the doors, opens another door, say the third, which does
    not have the car. The host gives the player the opportunity to switch doors. In
    this case, since the player picked the first door and the host revealed that the
    car is not behind the third door, the player can switch to the second door. The
    question is whether a strategy of staying with the original choice or switching
    doors is better.
  prefs: []
  type: TYPE_NORMAL
- en: The answer is, counterintuitively to many, that a switching strategy is better—two
    times out of three, the switching strategy leads to a win. Figure 9.7 illustrates
    the possible outcomes of switching.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F07_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 The Monty Hall problem. Assuming the player initially chooses the
    first door, two out of three times the switching strategy will lead to a win.
    This illustration assumes the first door is chosen, but the results are the same
    regardless of the initial choice of door.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We’ll explore two counterfactual questions:'
  prefs: []
  type: TYPE_NORMAL
- en: For a player who stayed with their first door and lost, what is the probability
    that they would have won if they switched doors?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a player who lost, what is the probability that they would have won if they
    switched doors?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We’ll answer these questions with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Build the parallel world model as a generative graphical model in pgmpy.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Condition on evidence in one world to do inference of outcomes in the other.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Before we start, we’ll download some tools to help us with the analysis. Listing
    9.1 downloads some helper functions for working with pgmpy: the `do` function
    for implementing ideal interventions and `clone` for duplicating a `TabularCPD`
    object. Also, to generate the visualizations, you’ll need to install the Graphviz
    visualization library.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up your environment
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The code in this chapter was tested with pgmpy version 0.1.25 and Pyro version
    1.9.1\. I use Matplotlib 3.7 for plotting. Plotting of the DAGs relies on Graphviz.
  prefs: []
  type: TYPE_NORMAL
- en: Graphviz installation depends on your environment. Using Ubuntu 22.04, I installed
    graphvizl via libgraphviz-dev, and then I installed the Python libraries Graphviz
    version 0.20.3, PyGraphviz version 1.13, and NetworkX version 3.3\.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your environment, you may need to install pydot version 3.0\. Graphviz
    and pydot are for plotting only, so if you get stuck, you could forgo plotting
    in the rest of the code.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.1 Installing Graphviz and helper functions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Install Graphviz libraries for visualization, and create a helper function
    for plotting graphs. This was tested in Ubuntu 22.04.3 but may depend on your
    environment. If you have trouble, you can forgo graph plotting and run the rest
    of the code.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Helper function for downloading some utilities from GitHub'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Download code for a “do” function for applying ideal interventions.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Download code for a “clone” helper function for cloning assignment functions
    across worlds.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 It’s good security practice to inspect the downloaded code before executing.
    Uncomment the “exec” calls to execute the downloaded code.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll build the full parallel world model as a graphical model. Our first
    step is to specify the exogenous variable distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.1 Specifying the exogenous variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We want to implement the model as an SCM, so we’ll create exogenous variables
    with distributions that entail all the random elements of the game. In other words,
    given the outcomes of these random elements and the host’s and player’s choices,
    the outcome of the game will be deterministic.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, we’ll introduce two rolls of three-sided dice and a coin flip.
    We’ll call the first die roll *Car Door Die Roll*; it selects a door for placement
    of the car. The player rolls the second die, a variable we’ll call *1st Choice
    Die Roll*, to select the player’s first door selection. Both dice rolls assign
    a 1/3 probability to each outcome. Next, we have a coin flip, which we’ll just
    call *Coin Flip*, which I’ll explain shortly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 9.2 Model building: Specify distributions for exogenous variables'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Prior distribution on exogenous variable for the three-sided die roll that
    selects which door gets the car'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Prior distribution on the exogenous variable for the three-sided die roll
    that selects the player’s first choice of door'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Prior distribution on the exogenous variable for the coin flip. The host
    flips a coin that determines which door the host chooses to reveal as carless
    and whether the player chooses a stay or switch strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll build assignment functions for our endogenous variables.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.2 Specifying the assignment functions for the endogenous variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our endogenous variables will be *Host Door Selection*, *Strategy* (whether
    taking a switch or stay strategy), *2nd Choice* (choosing door 1, 2, 3 based on
    one’s strategy), and *Win or Lose* (the outcome of the game).
  prefs: []
  type: TYPE_NORMAL
- en: 'Our definition of the SCM in chapter 6 assumes a one-to-one pairing between
    endogenous and exogenous variables—we typically make that assumption of independent
    exogenous variables because if we knew of a common cause, we’d usually model it
    explicitly. Here, we’ll relax that assumption and match each exogenous variable
    to two endogenous variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '*1st Choice Die Roll* will drive *Host Door Selection* and *2nd Choice*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Coin Flip* will drive *Host Door Selection* and *Strategy*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Car Door Die Roll* will drive *Host Door Selection* and *Win or Lose*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll use this simplified approach of matching one exogenous variable to two
    endogenous variables because it will require less code. This shortcut works well
    in this case because the exogenous variables precisely encode all the exogenous
    random elements of the game—these elements completely determine the game’s outcome.
    We could use the traditional formulation (where each endogenous variable has a
    unique exogenous variable) and get the same results.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s walk through the steps of the game and then construct the DAG.
  prefs: []
  type: TYPE_NORMAL
- en: Strategy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The player will use *Coin Flip* as the basis of their *Strategy* decision—if
    the host flips heads, the player will adopt a switch door strategy. Otherwise,
    they’ll adopt a strategy of keeping their original choice.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.3 Create the assignment function for *Strategy*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Host door selection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Host Door Selection* depends on which door has the car (*Car Door Die Roll*)
    and the player’s initial choice of door (*1st Choice Die Roll*). The host will
    use *Coin Flip* to select a door from two available doors in the event that the
    winning door and the first choice door are the same. If *Coin Flip* is heads,
    they’ll choose the right-most door, otherwise the left-most.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.4 Create the assignment function for *Host Door Selection*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 2nd choice
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*2nd Choice*, the player’s choice of which door to pick in the second round,
    depends on *Strategy*, *Host Door Selection* (the player can’t switch to the door
    the host opened), and *1st Choice Die Roll* (the player must stay with or switch
    from the door selected in the first round).'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.5 Create an assignment function for *2nd Choice*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Win or Lose
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Win or Lose* depends on which door the player picked in *2nd Choice* and whether
    that door is the winning door (*Car Door Die Roll*).'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.6 Create an assignment function for *Win or Lose*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: With the exogenous variable distributions and the assignment functions complete,
    we can build the full parallel world graphical model.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.3 Building the parallel world graphical model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can now begin building the full parallel world model. First we’ll add the
    edges that are in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.7 Build the parallel world graphical model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Specify lists of the exogenous and endogenous variables in the causal DAG.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Specify the edges of the SCM.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Clone the edges for the hypothetical world.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll compile and plot the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.8 Compiling and visualizing the parallel world graph
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Create the parallel world graph.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Plot the parallel world graph.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Add probability distributions on exogenous variables.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Add assignment functions from the SCM.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Clone the assignment functions.'
  prefs: []
  type: TYPE_NORMAL
- en: The preceding code prints the parallel world graph in figure 9.8.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F08_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 The full parallel world graph for our counterfactual question. Hypothetical
    world variables have the suffix “Hyp.”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Before we answer our counterfactual questions, we’ll do a quick sanity check
    to confirm that our model can generate the result that the switching strategy
    leads to a win two-thirds of the time.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.9 Confirm correct probability of winning given a switch strategy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Instantiate the inference algorithm with variable elimination.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Infer the probability distribution of “Win or Lose” given that the player
    uses a switch strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: This prints the following table.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: As we expect, we win two-thirds of the time when we adopt a strategy of switching
    doors.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.4 Running the counterfactual inference algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, we’ll use inference to answer our counterfactual questions:'
  prefs: []
  type: TYPE_NORMAL
- en: For a player who stayed with their first door and lost, what is the probability
    that they would have won if they switched doors?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a player who lost, what is the probability that they would have won if they
    switched doors?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Again, we use variable elimination as our choice of inference algorithm. We’ll
    use the `do` function to do the action step and implement the hypothetical condition
    of switching. Then we’ll use the `VariableElimination` inference algorithm to
    do the abduction and prediction steps all in one go.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.10 Infer the counterfactual distributions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Action step: Set “Strategy Hyp” to “switch” using “do”, an implementation
    of an ideal intervention.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Apply variable elimination as our inference algorithm on the parallel world
    graph.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 This inference query answers “For a player who used the stay strategy and
    lost, would they have won if they used the switch strategy?” Conditional on “Strategy
    == stay” and “Win or Lose == lose,” we infer the probability distribution of “Win
    or Lose Hyp” on the parallel world graph.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 This inference query answers “For a player who lost, would they have won
    if they used the switch strategy?” Conditional on “Win or Lose == lose,” we infer
    the probability distribution of “Win or Lose Hyp” on the parallel world graph.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the question “For a player who stayed with their first door and lost, what
    is the probability that they would have won if they switched doors?” we have the
    following probability table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The result of the first question is obvious. If the player lost on a stay strategy,
    their first choice did not have the car. Therefore, one of the other two doors
    must have had the car. Of those two, the host would have had to open the one without
    the car. The remaining door would then have had the car. That is the only door
    the player could switch to on a switch strategy. So, conditional on losing with
    a stay strategy, the chances they would have won with a switch strategy are 100%.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the question “For a player who lost, what is the probability that they
    would have won if they switched doors?” we have the following probability table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The answer to the second question extends from the first. We know from the original
    results of the model that if a player lost, there is a 2/3 chance they used a
    stay strategy. As we saw from the first question, in this case, flipping to a
    switch strategy has a 100% chance of winning. There is a 1/3 chance it was a stay
    strategy, in which case, by the consistency rule, there is 100% chance of losing.
  prefs: []
  type: TYPE_NORMAL
- en: Using pgmpy’s graphical model inference algorithms enables counterfactual reasoning
    for discrete variable problems like the Monty Hall problem. In the next case study,
    we will solve the abduction step with variational inference, which generalizes
    to a broader class of problems and leverages modern deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: '9.3 Case study 2: Counterfactual variational inference'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this next case study, we’ll implement the counterfactual inference algorithm
    using a generative model in the PyTorch-based probabilistic modeling library Pyro.
    Here we’ll focus on the example of a forensic SCM where femur length is a cause
    of human height (discussed earlier in section 6.1).
  prefs: []
  type: TYPE_NORMAL
- en: In the Monty Hall example, all the variables were discrete, and the exogenous
    causes completely captured the game’s random elements. That allowed us to implement
    the SCM (albeit awkwardly) using `TabularCPD` for assignment functions in pgmpy,
    and then explicitly create a parallel world graphical model. Once that was accomplished,
    the graphical modeling inference algorithm `VariableElimination` handled the abduction
    and prediction steps for us.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, our second case study presents an approach that generalizes to
    more types of problems. We’ll use the PyTorch-based deep probabilistic modeling
    library Pyro. We’ll handle the abduction step using variational inference, a popular
    inference algorithm in the deep learning era.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we’ll use this modeling approach to contrast two questions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A conditional hypothetical: “What would an individual’s height be if their
    femur length was 46 cm?” *P*(*H*[*F*][=46])'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A parallel-world counterfactual: “An individual’s femur is 44 cm, and their
    height is 165 cm. What would their height be if femur length was 46 cm?” *P*(*H*[*F*][=46]|*F*=44,
    *H*=165)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In both cases, we infer a distribution on *H*[*F*][=46] (where *H* is height
    and *F* is femur length), but in the counterfactual case, we condition on having
    observed *F*=44 and *H*=165\. Implementing code that contrasts these two distributions
    on *H*[*F*][=46] will help us understand what makes counterfactual queries unique.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.1 Building the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To make things more interesting, we’ll modify the model by adding a variable
    for biological sex, which drives both femur length and height. Figure 9.9 illustrates
    the new causal DAG. Notice that our questions do not mention anything about sex,
    so we’ll expect to see sex-related variance in our distributions *P*(*H*[*F*][=46])
    and *P*(*H*[*F*][=46]|*F*=44, *H*=165).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F09_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.9 The causal DAG for the relationship between femur length and height.
    Both are driven by biological sex.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The following code below implements the model in Pyro. Note the creation and
    use of a `PseudoDelta` distribution function. Endogenous variables are deterministic
    functions of the exogenous variables, but for variational inference to work, we
    must assign the endogenous variables a distribution using `pyro.sample`. We could
    use the Dirac delta distribution, which would assign all probability value to
    the output of a variable’s assignment function. But gradient-based optimization
    won’t work in this case. Instead, we’ll approximate inference with a “pseudo-delta”
    distribution—a normal distribution with a very small scale parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.11 Implement the femur SCM in Pyro
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Enable approximate inference with a “pseudo-delta” distribution to emulate
    a deterministic delta distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The assignment function for biological sex'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 The assignment function for femur length in cm. The assignment uses two
    linear functions, one for each sex.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 The assignment function for height. Again, it uses two linear functions,
    one for each sex.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Sample from the exogenous variable prior distributions'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Obtain the endogenous variables given the exogenous variables.'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Specify the prior distributions for the exogenous variables.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Again, there are three steps to our counterfactual inference algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: Abduction
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Action
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prediction
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Unlike our pgmpy model, we won’t need to clone all the variables for the parallel
    world. We’ll just use the intervention operator `pyro.do` to apply the intervention
    and get an intervention model. For *P*(*H*[*F*][=][46]), we’ll generate from the
    intervention model based on samples from *P*(*N*[*Sex*], *N*[*Femur*], *N*[*Height*]).
    For the counterfactual distribution, we’ll do the abduction step using a variational
    inference algorithm to learn *P*(*N*[*Sex*], *N*[*Femur*], *N*[*Height*]|F=44,
    H=165). Then we’ll generate from the intervention model again, but this time based
    on samples from *P*(*N*[*Sex*], *N*[*Femur*], *N*[*Height*]|F=44, H=165).
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with intractable likelihoods
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We use variational inference to do the abduction step, inferring the exogenous
    variables given observed endogenous variables. Variational inference is a likelihood-based
    technique. Typically, we get likelihoods by sampling from a distribution and then
    getting the probability value for that sampled value using the distribution’s
    probability mass/density function. But we can’t do that for SCMs because endogenous
    variable values are set by the assignment functions rather than being sampled.
    The code in this forensic example uses sampling from a “pseudo”-Dirac delta distribution,
    meaning a normal distribution with a very small scale parameter. This approach,
    which provides likelihood values from a normal distribution, falls into a class
    of methods called *approximate Bayesian computation**, a*nd it shares some of
    the trade-offs with other members of that class.
  prefs: []
  type: TYPE_NORMAL
- en: One alternative is to use *amortized inference*. In this method, you sample
    many exogenous variable values and use these to calculate many endogenous variable
    values. Finally, you use these samples to train a model that predicts the exogenous
    variable value, given the endogenous variable value. You then use this trained
    model during the abduction step.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with intractable likelihoods is a broader challenge in probabilistic
    machine learning, which is beyond the scope of this book. See the chapter notes
    at [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for links to additional references and resources.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.2 Implementing an intervention with pyro.do
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now let’s pose the conditional hypothetical, “What would height be if femur
    length was 46 cm?” Figure 9.10 illustrates the modified DAG representing the ideal
    intervention that sets femur length to 46.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F10_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.10 We represent the hypothetical condition with an ideal intervention
    and graph surgery on the causal DAG.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In Pyro, we’ll apply `pyro.do` to the original model and get an intervention
    model. We’ll then repeatedly call the algorithm with the prior on the exogenous
    variable distribution and return generated endogenous values. We’ll repeat this
    several times and visualize the intervention distribution on height with a histogram.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.12 Sampling from the intervention distribution of “if femur length
    were 46cm”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Implement the hypothetical condition “...if femur length were 46 cm” with
    pyro.do, which returns a new model that implements the intervention.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Sample from the intervention distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Visualize the intervention distribution with a histogram of samples.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.11 shows the resulting histogram of samples from *P*(*H*[*F*][=46]).
    We’ll contrast this with the histogram from *P*(*H*[*F*][=46]|*F*=44, *H*=165).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F11_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.11 This histogram of samples visualizes the interventional distribution—the
    *x*-axis corresponds to different ranges of height values, and the *y*-axis is
    proportions of the sampled heights that fall within each range.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now we’ll do the counterfactual inference.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.3 Implementing the abduction step with variational inference
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F12_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.12 The parallel world graph for the femur length counterfactual
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Our conditional hypothetical question was, “What would an individual’s height
    be if their femur length was 46 cm?” Now we want to answer the counterfactual:
    “An individual’s femur is 44 cm, and their height is 165 cm. What would their
    height be if their femur length was 46 cm?” In other words, we want to extend
    *P*(*H*[*F*][=][46]) to *P*(*H*[*F*][=][46]|*F*=44, *H*=165). Figure 9.12 illustrates
    the corresponding parallel world graph.'
  prefs: []
  type: TYPE_NORMAL
- en: Following the counterfactual inference algorithm, we need to do the abduction
    step and infer *P*(*N*[*Sex*], *N*[*Femur*], *N*[*Height*]|*F*=44, *H*=165). We’ll
    use variational inference, where we’ll specify a *guide function*—a function with
    trainable parameters representing a distribution *Q*(*N*[*Sex*], *N*[*Femur*],
    *N*[*Height*]). The training procedure optimizes the parameters of the guide such
    that *Q*(*N*[*Sex*], *N*[*Femur*], *N*[*Height*]) closely approximates *P*(*N*[*Sex*],
    *N*[*Femur*], *N*[*Height*]|*F*=44, *H*=165).
  prefs: []
  type: TYPE_NORMAL
- en: 'Refresher: Proposal distributions and Pyro’s guide function'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Pyro’s use of “guide functions” enables the developer to write their own proposal
    distributions that “propose” values for variables in the target distributions.
    Sampling-based inference algorithms (e.g., importance sampling or MCMC) use the
    proposal to generate samples and then operate on the samples so they represent
    the target distribution. Variational inference optimizes the parameters of the
    proposal distribution such that it becomes close to (or “approximates”) the target
    distribution. In contrast to pgmpy’s automatic inference algorithms, guide functions
    let the developer “guide” inference as they see fit.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.13 Specifying the guide function for variational inference
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '#1 The exogenous prior distribution is passed to the guide function. The function
    won’t use this argument, but the signatures of the guide and the model functions
    must match.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The guide function tries to approximate P(N_sex|femur, height) from a Bernoulli
    distribution. Optimization targets the parameter of this Bernoulli distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 n_sex is either 0 or 1\. When passed as a parameter to a Bernoulli, the
    outcome is deterministic.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 The guide function tries to approximate P(N_femur|femur, height) from a
    normal distribution. Optimization targets the location and scale parameters of
    this normal distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 The guide function tries to approximate P(N_height|femur, height), also
    from a normal distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Since we condition on femur and height, they are not needed in the guide
    function. But it is useful to have them in case we want to condition on different
    outcomes in a new analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: Deterministic abduction
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'A special case of the abduction step is when both of the following are true:'
  prefs: []
  type: TYPE_NORMAL
- en: You observe all the endogenous variables.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The SCM assignment functions are invertible.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In that case, given observations of all the endogenous variables, you can calculate
    exact point values for the exogenous variables with the inverted assignment functions.
    Consequently, you apply the assignment functions in the hypothetical world to
    get point values of the hypothetical outcomes. However, most practical examples
    fall in the following general case:'
  prefs: []
  type: TYPE_NORMAL
- en: You only condition on some endogenous variables.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The SCM assignment functions are not invertible.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In our abduction step, we first condition the model on observed values of femur
    and height.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.14 Conditioning on actual values of femur and height
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Next, we infer the exogenous variable, given femur and height, using variational
    inference.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.15 Implementing the abduction step with variational inference
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Set a seed for reproducibility.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Clear any current parameter values.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Initialize the stochastic variational inference algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Optimize the parameters with a learning rate of .003.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Use (negative) evidence lower bound (ELBO) as the loss function.'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Initialize a list to store loss values for plotting.'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Run the optimization for 5,000 steps. The SVI’s step object has the same
    signature as the model and the guide, so any model/guide arguments must be passed
    in here.'
  prefs: []
  type: TYPE_NORMAL
- en: '#8 Plot the loss during training.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.13 shows loss during training indicating variational inference converged.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F13_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.13 Loss during optimization of the parameters of the distribution approximating
    *P*(*N**[Sex]*, *N**[Femur]*, *N**[Height]*|*F*=44, *H*=165)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: After training is completed, we extract the optimized parameters for our updated
    exogenous variable distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.16 Extract parameters of updated exogenous distribution
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Extract the parameter values.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Do the abduction by using the optimized parameters to create new “posterior”
    exogenous variable distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: One thing to note is that while we typically specify independent prior distributions
    for exogenous variables in an SCM, exogenous variables are generally conditionally
    dependent given endogenous variables (because of collider paths!). However, I
    wrote a guide function that samples the exogenous variables independently, ignoring
    this conditional dependence. Writing a guide that treats dependent variables as
    independent is convenient and is common practice, but doing so will add some bias
    to the results. You can avoid this by doing the extra work of writing a guide
    function that maintains the dependencies implied by the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Counterfactual modeling with ChiRho
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: ChiRho is a causal extension of Pyro that seeks to more seamlessly blend the
    probabilistic modeling approach of Pyro with causal inference. ChiRho has parallel
    world abstractions and abstractions for implementing counterfactual inference
    with normalizing flows and the variational inference approach discussed in this
    example. As an extension to Pyro, the modeling techniques discussed in this case
    study will also work with ChiRho.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3.4 Implementing the action and prediction steps
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the Monty Hall example, we built the parallel world model explicitly. In
    this example, we can just perform the action step by using `pyro.do` to get the
    hypothetical world model, and sample from this model using the updated exogenous
    variable distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll repeat the procedure of generating samples from the intervention model
    that set femur length to 46 cm. Recall that we already created the intervention
    model in listing 9.11 with this line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: To sample from the intervention distribution, we called `int_model` on our original
    `exogenous` variable distribution. Now, for the prediction step, we’ll call it
    again, this time with `exogenous_posterior` instead of `exogenous`, because `exogenous_posterior`
    encodes all the information from the actual world.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.17 Sampling from the counterfactual distribution
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we overlay a histogram of samples from the counterfactual distribution
    against the interventional distribution histogram in figure 9.14, and we can see
    the clear differences between these distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.18 Comparing the interventional and counterfactual distributions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: The resulting plot, shown in figure 9.14, contrasts histograms of the interventional
    and counterfactual samples.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F14_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.14 Histograms of generated samples from the interventional and counter-factual
    distributions encoded by the causal model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Figure 9.14 illustrates how the counterfactual distribution generally has much
    less spread than an interventional distribution representing the same hypothetical
    conditions. The counterfactual distribution essentially filters the interventional
    distribution down to cases where the conditions observed in the actual world are
    true. In this case, we have two height bell curves corresponding to two sexes.
    Those bell curves have a stronger overlap in the interventional distribution.
  prefs: []
  type: TYPE_NORMAL
- en: In a final example, we’ll evaluate how to run the counterfactual inference algorithm
    in the context of a generative AI image model.
  prefs: []
  type: TYPE_NORMAL
- en: '9.4 Case study 3: Counterfactual image generation with a deep generative model'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In generative AI, the user provides an input, and the algorithm generates some
    output. For example, suppose I wanted to write a script for an alternative history
    where Harriet Tubman was a pirate captain. I turned to a generative image model
    for some concept art, posing the text question, “What would Harriet Tubman look
    like as a pirate captain?” The model generated the image in figure 9.15.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F15_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.15 The output of a generative AI image model, given the natural language
    input prompt “What would Harriet Tubman look like as a pirate captain?”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The question itself is a counterfactual—Harriet Tubman was not a pirate. We’ll
    explore natural language counterfactuals with large language models in chapter
    13\. Here, we’ll reason counterfactually about the image in figure 9.15.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose I like this image, but I want to make an edit—I want to change this
    image to remove the glasses. One way of doing this is to use a tool like “in-fill,”
    where I select the pixels with the glasses and indicate that I want whatever is
    in the pixels to go away. This would be directly editing the form of the image.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative approach would be *semantic editing*, where rather than manipulating
    the pixels in the image, I manipulate some latent representation of the image
    corresponding to “glasses.” In effect, I pose the counterfactual question, “what
    would this image look like if the subject were not wearing glasses?” Figure 9.16
    contrasts the original and “counterfactual” versions of the image.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F16_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.16 Given the generated image on the left, the user might prompt the
    generative AI with the counterfactual question, “What would this image look like
    without the glasses?” They would expect something like the image on the right,
    where conceptual elements of the image not causally downstream of glasses removal
    should be unaffected.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This is an attractive use case, as manipulating underlying concepts is often
    preferable to manipulating form, especially when the edits you want to make aren’t
    all located in the same specific area of pixels. This is especially attractive
    if our conceptual model is a causal model, so the downstream causal consequences
    of changing a concept are reflected in the image, while the law of consistency
    prevents change in the parts of the image that should be unaffected by the change
    in concept.
  prefs: []
  type: TYPE_NORMAL
- en: With this use case in mind, this section will use our counterfactual algorithm
    to implement a form of semantic editing. We’ll start with the actual image. In
    the abduction step, we’ll infer some latent representation of the image. In the
    action step, we’ll propose the desired edit, and in the prediction step, we’ll
    generate the new image.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we’ll use an SCM built with a variational autoencoder in PyTorch.
    We’ll also use a simple dataset called dSprites for proof of concept. The dSprites
    data demonstrates the idea and is simple enough to train a model quickly on an
    ordinary laptop. See the chapter notes at [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for references with more practical counterfactual image modeling examples.
  prefs: []
  type: TYPE_NORMAL
- en: 9.4.1 The dSprites data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The dSprites dataset consists of 2D shapes, each rendered in 8 possible positions,
    6 possible scales, and 40 possible rotations. The shapes are composed of 5 independent
    factors: shape, scale, rotation, *x*-position, and *y*-position. Figure 9.17 demonstrates
    samples from the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F17_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.17 The dSprites data features images causally determined by five independent
    causal factors: shape, scale, rotation, *x*-position, and *y*-position.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We’ll treat each of these factors as causes of an image variable, as illustrated
    in the causal DAG in figure 9.18.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F18_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.18 The causal DAG for a dSprites image, displayed as a plate model
    to highlight the shape of *N**[I]* and *I*. *N**[i]* is the exogenous variable
    for the image. The model is trained with an encoder-decoder framework that uses
    a 50 × 1 dimensional image encoding to represent *N**[I]*.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In the following code, we load a specific image from the dSprites dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.19 Load a dSprites image
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Download dSprites example from GitHub and load it.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Plot the dSprites image.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 The causal factors of the example are [0 0 1 13 26 14], the first element
    is always 0, and the second element corresponds to “square” and is represented
    by 0\. The remaining elements correspond to scale, orientation, and X and Y positions.'
  prefs: []
  type: TYPE_NORMAL
- en: This plots the image in figure 9.19.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F19_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.19 A single example from the dSprites data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Printing `causal_factor` produces `tensor ([[ 0, 0, 1, 13, 26, 14`]]). The first
    element is 0 for all examples in the data. The second element of the causal factor
    vector corresponds to shape. Square, ellipse, and heart are represented by 0,
    1, and 2, respectively. The image contains a square (*P*=0) with scale *S*=1,
    orientation *O*=13, and position *X*=26 and *Y*=14\.
  prefs: []
  type: TYPE_NORMAL
- en: In this case study, we’ll ask, “What would this image look like if the shape
    were a heart instead of a square?” This suggests the parallel-world network in
    figure 9.20.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F20_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.20 The parallel world graph implied by the question “Given the image,
    what would it look like if the shape were a heart?”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: First, we’ll load a pretrained encoder to map from the image to the exogenous
    variable for the causal factors. In this simple model, we’ll assume the assignment
    functions for the exogenous variables of the causal factors are identity functions,
    i.e., the causal factors and their exogenous variables will have the same values.
    Let’s start by initializing the encoder.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.20 Load the encoder of causal factors
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Cardinality in each dimensionality of the causal factors'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Encoder for the vector of exogenous parents of the causal factors'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 The hidden layers have a length of 1,000.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Using linear transforms passed through Softplus activation functions'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 The final activation is a sigmoid function.'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Flatten the image.'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Calculate the hidden layers.'
  prefs: []
  type: TYPE_NORMAL
- en: '#8 The output layer generates a probability vector that Is used as the parameter
    of a OneHotCategorical distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '#9 Initialize the encoder. The image dimension is 64 × 64 pixels, and the six
    elements of the causal factor vector are one-hot encoded into a vector of length
    1 + 3 + 6 + 40 + 32 + 32 = 114.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll download and load pretrained weights into this encoder from the
    book’s GitHub repo.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.21 Download and load pretrained weights into the encoder of causal
    factors
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: First, we’ll test that the encoder can recover the causal factors from the image.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.22 Generate examples of causal exogenous factors
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Helper function that decodes the one-hot encoded output of the encoder'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Samples from the output probability vector of encoder_causal_factors'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Use the encoder to predict causal factors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Encoding the sampled image prints the causal factors: `[ 0, 0, 1, 13, 26, 14].`
    The encoder accurately recovers the causal factors from the image.'
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll initialize an encoder that we’ll use for inference of *N*[*I*],
    the exogenous variable for the image. This encoder takes an image and an instance
    of the causal factor vector as an input.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.23 An encoder for inference of *N**[I]*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Encoder used for inference of N [I], which serves as both the exogenous
    variable for the image in causal terms, and the encoding of the image in VAE terms'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Using linear transforms passed into a Softplus activation function'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Flatten the image.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Concatenate the image and the causal factor vector.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Calculate the hidden layers.'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Calculate the location and scale parameter of multivariate normal distribution
    on N [I].'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Initialize the encoder.'
  prefs: []
  type: TYPE_NORMAL
- en: The encoder of the noise variable requires the causal factors to be one-hot
    encoded, so we’ll create a helper function to do just that.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.24 Create a function for one-hot encoding
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Again, we’ll download and load pretrained weights for the encoder.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.25 Load pretrained weights for encoder for inference of *N**[I]*
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Load the pretrained weights.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Pass the image and causal factors into the encoder, and obtain N [I] location
    and scale parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Generate from the posterior distribution on N [I].'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we’ll load a decoder that maps from *N*[*I*] and a causal factor back
    to an image. In causal terms, the decoder is part of the assignment function for
    the image.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.26 Load and initialize the decoder that maps causes and *N**[I]* to
    images
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '#1 The decoder maps from causal factors and N_image to generate a parameter
    for a multivariate Bernoulli distribution on images.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The model uses linear transforms, a Softplus activate for hidden layers,
    and sigmoid activate on the output layer.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 The network concatenates n_image and factors in the input layer.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 The input is passed through three hidden layers with Softplus activation
    functions.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 The output is a probability parameter passed to a multivariate Bernoulli
    distribution on image pixels.'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Initialize the encoder.'
  prefs: []
  type: TYPE_NORMAL
- en: Again, we’ll download and load pretrained weights into the decoder.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.27 Download and load the decoder weights
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Before we generate the counterfactual image, we’ll create a helper function
    to plot it.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.28 Helper function for plotting the counterfactual image
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Now, we’ll specify the SCM. We’ll write a `p_n_image` function that generates
    from *P*(*N*[*image*]) and an `f_image` assignment function for the image.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.29 Create an exogenous distribution and assignment function for the
    image
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '#1 A function that generates a variate from the N_image exogenous distribution'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The parameters of N_image’s distribution include location and scale parameters
    for a normal distribution and the upper bound of a uniform distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Sample a normal random variate from the normal distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Sample a uniform random variate from a uniform distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Combine these into a single n_image object.'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Assignment function for the image'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 The exogenous noise variable decomposes into one normal and one uniform
    random variate.'
  prefs: []
  type: TYPE_NORMAL
- en: '#8 The normal random variate is passed through the decoder to get a probability
    vector for the pixels.'
  prefs: []
  type: TYPE_NORMAL
- en: '#9 Each pixel is set deterministically with an indicator function that returns
    1 if an element of the uniform variate is less than the corresponding element
    of the probability vector, or otherwise returns 0.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can run through the steps of the counterfactual inference algorithm
    to answer the question, “What would this image look like if it was a heart?”
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.30 Generate a counterfactual image
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Abduction step: infer the exogenous variable given the image.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Infer the parameters of N_I. First, this includes two parameters of a normal
    distribution.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Second, we infer the upper bound of a uniform distribution and apply smoothing
    so it is not exactly 1 or 0.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Combine these together into one inferred parameter set.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Action step: Apply the intervention that sets the shape element to “heart”
    (represented by the integer 2).'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Prediction step: Generate n_image from P(N_image), and pass this through
    an assignment function to generate an image.'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Apply all three steps: abduct the n_image, apply the intervention, and forward
    generate the counterfactual image.'
  prefs: []
  type: TYPE_NORMAL
- en: '#8 Plot the result.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.21 shows the results.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH09_F21_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.21 The original (left) and counterfactually generated image (right)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This is a proof of concept—there is additional nuance in counterfactual image
    generation. I’m cheating a bit with this dSprites example. The counterfactual
    generation works because the causal factors are independent and because the data
    is quite simple. For counterfactual image generation to work in general, we need
    to understand and satisfy certain assumptions.
  prefs: []
  type: TYPE_NORMAL
- en: 9.4.2 Assumptions needed for counterfactual image generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the next chapter, we’ll tackle the problem of identification. Identification
    is determining what causal questions we can answer, given our modeling assumptions
    and the data available to us. The counterfactual inference algorithm assumes you
    have the ground-truth SCM. If you can make that assumption, you can use the algorithm
    to answer any counterfactual (or interventional) query.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, we can’t practicably assume we have the ground-truth SCM. At
    best, you’ll have an SCM that acts as an approximation of the ground truth. For
    example, the true process that generated the dSprites images certainly didn’t
    involve a decoder neural network—we used deep learning with this decoder architecture
    to approximate that process. As you’ll see in the next chapter, such learned approximations
    are not guaranteed to produce counterfactuals faithful to the ground-truth data
    generating process.
  prefs: []
  type: TYPE_NORMAL
- en: But there is something special about the counterfactual generation of images
    and other media modalities (e.g., text, audio, video). In these cases, mathematical
    guarantees are less critical when we can simply *look* (read, listen, etc.) at
    the generated counterfactual media and evaluate whether it aligns with what we
    imagine it *should* be. Does the image in figure 9.21 look like what you imagined
    replacing the square with a heart would look like? Does the image of pirate captain
    Harriet Tubman without the spectacles align with your expectations? If so, the
    tool is quite useful, even without identification guarantees. Here, utility is
    in terms of aligning with human counterfactual imagination rather than ground-truth
    accuracy. I have the concept image of Captain Tubman that I wanted, and I can
    move on to my next creative task.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The counterfactual inference algorithm requires an SCM and involves three steps:
    abduction, action, and prediction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the abduction step, we infer the exogenous variables, given observed endogenous
    variables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the action step, we use an ideal intervention to implement the hypothetical
    condition in the counterfactual query.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the prediction step, we predict the hypothetical outcomes given the hypothetical
    condition and the distribution of the exogenous variables learned in the abduction
    step.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can implement the counterfactual inference algorithm using different probabilistic
    machine learning frameworks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use a causal graphical modeling library like pgmpy to directly implement
    a generative SCM on a parallel world graph, and use graphical model inference
    algorithms with graph surgery to infer the counterfactual query.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use modern probabilistic deep learning techniques such as variational
    inference and normalizing flows to do the abduction step of the counterfactual
    inference algorithm.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep generative models can often be modified to enable counterfactual generation
    of media (text, images, audio, video, etc.). While there may be identification
    questions, you can typically examine the generated counterfactual artifact and
    validate that it matches your expectations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
