<html><head></head><body>
  <h1 class="tochead" id="heading_id_2">9 <a id="idTextAnchor000"/><a id="idTextAnchor001"/><a id="idTextAnchor002"/><a id="idTextAnchor003"/><a id="idTextAnchor004"/><a id="idTextAnchor005"/><a id="idTextAnchor006"/>Deep learning best practices</h1>

  <p class="co-summary-head">This chapter covers<a id="idIndexMarker000"/><a id="marker-326"/></p>

  <ul class="calibre5">
    <li class="co-summary-bullet">An introduction to the Kuala Lumpur real estate dataset</li>

    <li class="co-summary-bullet">Processing the dataset</li>

    <li class="co-summary-bullet">Defining the deep learning model</li>

    <li class="co-summary-bullet">Training the deep learning model</li>

    <li class="co-summary-bullet">Exercising the deep learning model</li>
  </ul>

  <p class="body">In chapter 8 we examined a set of stacks for doing deep learning with tabular data. In this chapter, we use one of these stacks, Keras, to explore some best practices for deep learning with tabular data, including how to prepare the data, how to design the model, and how to train the model. We introduce a new problem to demonstrate all these best practices: predicting whether real estate properties in Kuala Lumpur will have a price above or below the median price for the market. We selected this dataset because it is messier and more challenging to prepare than the Airbnb NYC dataset we have used so far. Consequently, we’ll be able to demonstrate a wider range of techniques for applying deep learning to tabular datasets.</p>

  <p class="body">If you are new to training deep learning models, the examples in this chapter will help you learn some best practices. If you already have extensive experience with defining and training deep learning architectures, this chapter could be beneficial for you as a review of principles.<a id="idTextAnchor007"/></p>

  <h2 class="fm-head" id="heading_id_3">9.1 Introduction to the Kuala Lumpur real estate dataset</h2>

  <p class="body">In this chapter, we will use the Kuala Lumpur real estate dataset to explain the best practices for deep learning with tabular data. This dataset consists of records that describe properties sold in Kuala Lumpur, the capital of Malaysia. Figure 9.1 presents a sample of the records in this dataset from the output of <code class="fm-code-in-text">df.head()</code>. The code illustrated in this chapter is at <a class="url" href="https://mng.bz/yWQp">https://mng.bz/yWQp</a>.<a id="idIndexMarker001"/><a id="idIndexMarker002"/><a id="idIndexMarker003"/><a id="marker-327"/><a id="idTextAnchor008"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F01_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.1 Sample of the Kuala Lumpur real estate dataset</p>
  </div>

  <p class="body">In the next section, we’ll go through the steps we need to take to clean up each of the columns in this dataset. To prepare for those descriptions, let’s first review what’s in each column of the dataset:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Locat<a class="calibre" id="idTextAnchor009"/>ion</code>—The neighborhood in which the property is located.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Price</code>—The listed price for the property in Ringgit, including RM, the conventional symbol for Malaysian currency.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Rooms</code>—The number of rooms in the property. Values like “2 + 1” in this column mean the property has two bedrooms and one room that cannot be classified as a bedroom.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Bathrooms</code>—The number of washrooms in the property.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Car Parks</code>—The number of parking spaces on the property.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Property Type</code>—The category of property, such as “Condominium,” “Serviced Residence,” etc.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Size</code>—The dimensions of the property. There are several aspects of the property that values in this column could refer to, including the overall land area or the built-up area within the property.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Furnishing</code>—Whether the property is furnished or not.</p>
    </li>
  </ul>

  <p class="body">One of the basic questions we need to answer about this dataset is what columns are continuous or categorical. By looking at figure 9.1, we can spot a subset of columns that contain numeric values. Let’s take a closer look at this subset of the dataset to see if we can determine which columns are continuous. Figure 9.2 shows values from the subset of columns in the dataset that appear to contain numeric data.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F02_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.2 Subset of columns that look like they contain numeric data<a id="idTextAnchor010"/></p>
  </div>

  <p class="body"><a id="marker-323"/>We can validate which of these columns have numeric data by using the following command:</p>
  <pre class="programlisting">df.describe()</pre>

  <p class="body">This command returns descriptive statistics for all numeric columns in the DataFrame, providing insights into the data distribution, central tendency, and spread within each numeric column. By examining the output of this command, you can identify which columns indeed contain numerical values. The output of this command is shown in figure 9.3.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F03_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.3 Output of <code class="fm-code-in-text">describe()</code> for this dataset</p>
  </div>

  <p class="body"><a id="idTextAnchor011"/>Figure 9.3 indicates that only <code class="fm-code-in-text">Bathrooms</code> and <code class="fm-code-in-text">Car Parks</code> are numeric columns and that <code class="fm-code-in-text">Price</code>, <code class="fm-code-in-text">Rooms</code>, and <code class="fm-code-in-text">Size</code> are not numeric columns even though they contain some data that looks numeric. In the next section, as part of processing the dataset, we will describe the steps to extract the numeric data from the <code class="fm-code-in-text">Price</code>, <code class="fm-code-in-text">Rooms</code>, and <code class="fm-code-in-text">Size</code> features and make it available to train a model.</p>

  <p class="body">Another way of evaluating which columns are categorical or continuous is to count the number of unique values in each column. If a column contains a large number of unique values, that may be an indication that we should treat it as continuous, and if it contains a relatively small number of values, that may be an indication that we should treat it as categorical. In fact, features presenting few unique values are often considered categorical because they typically represent discrete categories or groups rather than continuous numerical measurements. This is not a hard and fast rule, as we shall see. The output of the <code class="fm-code-in-text">df.unique()</code> command gives the number of unique values in each column in the dataset.<a id="idTextAnchor012"/><a id="marker-329"/><a id="idIndexMarker004"/></p>

  <p class="fm-code-listing-caption">Listing 9.1 Getting the count of unique values in each column</p>
  <pre class="programlisting">counts = df.nunique()                                  <span class="fm-combinumeral">①</span>
print("unique value counts:\n",counts)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Returns the number of unique values in each column of the dataframe df</p>

  <p class="body">The output of the command in listing 9.1 looks like the following:</p>
  <pre class="programlisting">unique value counts:  
Location          112                                  <span class="fm-combinumeral">①</span>
Price            4280                                  <span class="fm-combinumeral">②</span>
Rooms              43                                  <span class="fm-combinumeral">③</span>
Bathrooms          17                                  <span class="fm-combinumeral">④</span>
Car Parks          21                                  <span class="fm-combinumeral">④</span>
Property Type      99                                  <span class="fm-combinumeral">⑤</span>
Size             6190                                  <span class="fm-combinumeral">⑥</span>
Furnishing          4                                  <span class="fm-combinumeral">⑦</span>
dtype: int64</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> The limited number of values in this column reinforces our intuition that this column is categorical.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> This column is continuous.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> This column requires further investigation.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> This column is continuous.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> This column is categorical.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> This column is continuous, but it requires special treatment, as we will see later in this chapter.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> This column is categorical.</p>

  <p class="body">To summarize what the output of the command in listing 9.1 tells us about the dataset:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Columns that appear to be categorical</i>—<code class="fm-code-in-text">Location,</code> <code class="fm-code-in-text">Property</code> <code class="fm-code-in-text">Type,</code> <code class="fm-code-in-text">Furnishing.</code> </p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Columns that appear to be continuous</i>—<code class="fm-code-in-text">Price,</code> <code class="fm-code-in-text">Bathrooms,</code> <code class="fm-code-in-text">Car</code> <code class="fm-code-in-text">Parks,</code> <code class="fm-code-in-text">Size.</code> Of these columns, <code class="fm-code-in-text">Size</code> also requires further investigation.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Columns that need further investigation to determine whether they should be treated as continuous or categorical</i>—<code class="fm-code-in-text">Rooms.</code> </p>
    </li>
  </ul>

  <p class="body">Two of these columns require further investigation: <code class="fm-code-in-text">Rooms</code> and <code class="fm-code-in-text">Size.</code> In the following section on processing the dataset, we will dig deeper into these two columns to determine how to deal with them.</p>

  <p class="body">Now that we have a sense of the columns in the dataset and what kind of information they offer, let’s explore some more aspects of the dataset. First, let’s check the dimensions of the dataset, as shown in the following listing<a id="marker-330"/><a id="idTextAnchor013"/>.</p>

  <p class="fm-code-listing-caption">Listing 9.2 Code to check the dimensions of the dataset</p>
  <pre class="programlisting">print("shape ",df.shape)                                 <span class="fm-combinumeral">①</span>
shape  (53883, 8)                                        <span class="fm-combinumeral">②</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Statement to get the dimensions of the input dataframe</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Output of the statement</p>

  <p class="body">Listing 9.2 shows that this dataset has over 53,000 rows and eight columns. In chapter 12, we will examine the relationship between the number of rows in a dataset, the nature of the columns in a dataset, and the applicability of a deep learning model to the data. For now, it is safe to say that while this dataset is on the small side, it is big enough for us to have a decent chance of training a deep learning model with it.</p>

  <p class="body">The following listing contains the statements that list the number of missing values in each column of the dataset<a id="idTextAnchor014"/>.</p>

  <p class="fm-code-listing-caption">Listing 9.3 Statements to list missing values in each column</p>
  <pre class="programlisting">missing_values_count = df.isnull().sum()                  <span class="fm-combinumeral">①</span>
print("missing values before cleanup:\n",missing_values_count)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> The output of this statement is a count of the number of missing values by column.</p>

  <p class="body">The following is the output of the commands in listing 9.3:</p>
  <pre class="programlisting">missing values before cleanup:
Location             0                                    <span class="fm-combinumeral">①</span>
Price              248
Rooms             1706
Bathrooms         2013
Car Parks        17567                                    <span class="fm-combinumeral">②</span>
Property Type       25
Size              1063
Furnishing        6930
dtype: int64</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Location is the only column with no missing values.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Car Parks is the column with the most missing values.</p>

  <p class="body">From the output of the command in listing 9.3, we can see that all but one of the columns in this dataset have missing values. This is an early sign of some of the problems we will need to correct to get this dataset ready to train with a deep learning model. In comparison, the Airbnb NYC dataset only had missing values in four columns:</p>
  <pre class="programlisting">Missing values:  
id                                    0
name                                 16                  <span class="fm-combinumeral">①</span>
host_id                               0
host_name                            21                  <span class="fm-combinumeral">②</span>
neighbourhood_group                   0
neighbourhood                         0
latitude                              0
longitude                             0
room_type                             0
price                                 0
minimum_nights                        0
number_of_reviews                     0
last_review                       10052                  <span class="fm-combinumeral">③</span>
reviews_per_month                 10052                  <span class="fm-combinumeral">④</span>
calculated_host_listings_count        0
availability_365                      0</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Missing values in the name column</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Missing values in the host_name column</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Missing values in the last_review column</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Missing values in the reviews_per_month column</p>

  <p class="body">As shown here, almost every column in the Kuala Lumpur dataset is missing values, which warns us that, as often happens with real-world data, we will have to perform a lot of work to clean up this dataset before we can start using it with a model.</p>

  <p class="body">In this section, we have taken a first look at the Kuala Lumpur real estate dataset. In the next section, we will review the process of preparing this dataset to train a deep learning model<a id="idTextAnchor015"/>.<a id="idIndexMarker005"/><a id="idIndexMarker006"/><a id="marker-331"/></p>

  <h2 class="fm-head" id="heading_id_4">9.2 Processing the dataset</h2>

  <p class="body">Now that we’ve looked at the Kuala Lumpur real estate dataset and seen that it has a large number of missing values, we have some idea that it will require a good deal of processing before we can use it to train a model. In this section, we will look at the features of the dataset one by one to describe the cleanup required. <a id="idIndexMarker007"/><a id="idIndexMarker008"/></p>

  <p class="body">At this point, we haven’t decided yet if we are going to use a subset or the full set of columns. Initially, our approach defaults to utilizing all available features. As we progress and examine the model’s performance and behavior, we may decide to exclude some features, for example, because these features have undetected invalid values that effect the model’s performance. It is not just because we cannot anticipate what features will work and what won’t that we strive to obtain the full set of clean features available to the model for training. It is also a way to get the most out of data, as we will learn more about the dataset through processing it entirely and rendering it reusable for other projects as well. This comprehensive approach ensures better results than we would have obtained if we only cleaned up the features that we ultimately use to train the model.</p>

  <p class="body">The code highlighted in this section is availa<a id="idTextAnchor016"/>ble at <a class="url" href="https://mng.bz/MDBQ">https://mng.bz/MDBQ</a> and the config file is at <a class="url" href="https://mng.bz/av1j">https://mng.bz/av1j</a>.</p>

  <p class="body">We will begin by addressing columns that only involve handling missing values: <code class="fm-code-in-text">Bathrooms,</code> <code class="fm-code-in-text">Car</code> <code class="fm-code-in-text">Parks,</code> <code class="fm-code-in-text">Furnishing,</code> <code class="fm-code-in-text">Property Type,</code> <code class="fm-code-in-text">Location</code>. Next, we will describe the process for the columns that require more cleanup than simply dealing with missing information: <code class="fm-code-in-text">Price</code>, <code class="fm-code-in-text">Rooms</code>, and <a id="idTextAnchor017"/><code class="fm-code-in-text">Size</code>.</p>

  <h3 class="fm-head1" id="heading_id_5">9.2.1 Processing Bathrooms, Car Parks, Furnishing, Property Type, and Location columns</h3>

  <p class="body">For a subset of the columns in the dataset (<code class="fm-code-in-text">Bathrooms,</code> <code class="fm-code-in-text">Car</code> <code class="fm-code-in-text">Parks,</code> <code class="fm-code-in-text">Furnishing, Property</code> <code class="fm-code-in-text">Type,</code> <code class="fm-code-in-text">Location</code>), we can accomplish an effective cleanup by simply dealing with missing values. The config file contains default values to replace missing values for these columns that we determined based on their characteristics and domain knowl<a id="idTextAnchor018"/>edge.<a id="idIndexMarker009"/><a id="idIndexMarker010"/><a id="idIndexMarker011"/><a id="idIndexMarker012"/><a id="idIndexMarker013"/><a id="idIndexMarker014"/><a id="idIndexMarker015"/><a id="idIndexMarker016"/><a id="idIndexMarker017"/><a id="marker-332"/></p>

  <p class="fm-code-listing-caption">Listing 9.4 Defining the default replacement values for missing values</p>
  <pre class="programlisting">misc_col_dict: # default values to replace missing values for general columns 
   Bathrooms: median                                     <span class="fm-combinumeral">①</span>
   Car Parks: 0                                          <span class="fm-combinumeral">②</span>
   Furnishing: unknown_furnishing                        <span class="fm-combinumeral">③</span>
   Property Type: unknown_property
   Location: unknown_location</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> For the Bathrooms columns, sets the median value for the column as the default value</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> For the Car Parks column, sets the default value to zero</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> For the categorical columns, sets a placeholder category as the default value</p>

  <p class="body">Listing 9.4 shows that we set missing values for the <code class="fm-code-in-text">Bathrooms</code> column in this dictionary to the median value for the column. For the <code class="fm-code-in-text">Car</code> <code class="fm-code-in-text">Parks</code> column, we set missing values to zero. The reason for the difference between these is due to the specific use case of real estate listings. Residential properties will rarely have no washrooms, so picking the median value as the default for <code class="fm-code-in-text">Bathrooms</code> makes sense. On the other hand, many properties will have no parking spaces. If a property does have a parking space, it is in the best interests of the seller and the seller’s agent to include this in the listing to ensure they get the best selling price for the property. Thus, when <code class="fm-code-in-text">Car</code> <code class="fm-code-in-text">Parks</code> is missing a value, it makes sense to assume that this property does not have any parking spaces, so we set missing values in this column to zero.<a id="idIndexMarker018"/><a id="idIndexMarker019"/></p>

  <p class="body">In this dictionary, we also have distinct placeholder category values for the categorical columns. The code for obtaining this simple cleanup is placed in the data cleanup notebook’s function <code class="fm-code-in-text">clean<a class="calibre" id="idTextAnchor019"/>_up_misc_cols()</code>.<a id="idIndexMarker020"/></p>

  <p class="fm-code-listing-caption">Listing 9.5 Function to replace general missing values</p>
  <pre class="programlisting">def clean_up_misc_cols(df,misc_col_dict): 
 for col in misc_col_dict:                           <span class="fm-combinumeral">①</span>
    if misc_col_dict[col] == 'median':               <span class="fm-combinumeral">②</span>
      df[col] = df[col].fillna(df[col].median())
    else:
      df[col] = df[col].fillna(misc_col_dict[col])   <span class="fm-combinumeral">③</span>
  return(df)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Iterates through the columns that have simple data cleanup</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Replaces missing values with the median for the column where specified</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> For the other columns, replaces missing values in the column with the default value for that column</p>

  <p class="body">In the <code class="fm-code-in-text">clean_up_misc_cols()</code> function shown in listing 9.5, the dictionary defined in the config file, as shown in listing 9.4, is used to replace missing values in the columns that require a simple cleanup.<a id="idIndexMarker021"/></p>

  <p class="body">Now that we have described how the cleanup is done for the columns that only require missing values to be dealt with, the subsequent subsections in this section will describe the more intensive data operations that are required for the remaining three columns: <code class="fm-code-in-text">Price<a class="calibre" id="idTextAnchor020"/></code>, <code class="fm-code-in-text">Rooms</code>, and <code class="fm-code-in-text">Size</code>.</p>

  <h3 class="fm-head1" id="heading_id_6">9.2.2 Processing the Price column</h3>

  <p class="body">Before we get into what needs to be cleaned up in the <code class="fm-code-in-text">Price</code> column, let’s review some examples of values in this column, as shown<a id="idTextAnchor021"/> in figure 9.4.<a id="idIndexMarker022"/><a id="marker-333"/><a id="idIndexMarker023"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F04_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.4 Examples of values in the Price column</p>
  </div>

  <p class="body">The values in figure 9.4 show a few items that need to be dealt with in the <code class="fm-code-in-text">Price</code> column:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Values including the symbol “RM”, representing Ringgit, the Malaysian currency</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Missing values</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Values needing to be converted to float</p>
    </li>
  </ul>

  <p class="body">Listing 9.6 presents the <code class="fm-code-in-text">clean_up_price_col()</code> function, which contains a code snippet to effectively clean u<a id="idTextAnchor022"/>p the <code class="fm-code-in-text">Price</code> column.<a id="idIndexMarker024"/></p>

  <p class="fm-code-listing-caption">Listing 9.6 Function to clean up the <code class="fm-code-in-text">Price</code> column</p>
  <pre class="programlisting">def clean_up_price_col(df):
  df.dropna(subset=['Price'], inplace=True)            <span class="fm-combinumeral">①</span>
  df['Price'] = \
df['Price'].apply(lambda x:\ 
remove_currency_symbol("RM ",x))                       <span class="fm-combinumeral">②</span>
  df['Price'] = \
pd.to_numeric(df['Price'].\
str.replace(',',''), errors='coerce')                  <span class="fm-combinumeral">③</span>
  return(df)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Drops rows in the dataframe that are missing a value in the Price column</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Removes the currency symbol</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Removes commas and convert the values to float</p>

  <p class="body">As shown in listing 9.6, the <code class="fm-code-in-text">clean_up_price_col()</code> function removes rows with missing <code class="fm-code-in-text">Price</code> values. The rationale for removing these rows (as opposed to replacing missing <code class="fm-code-in-text">Price</code> values with some placeholder) is that <code class="fm-code-in-text">Price</code> is the target for our model; hence it won’t work to keep rows where such a value is missing. The output of the <code class="fm-code-in-text">clean_up_price_col()</code> function is a dataframe with valid numeric values in all rows fo<a id="idTextAnchor023"/>r the <code class="fm-code-in-text">Price</code> column. <a id="idIndexMarker025"/></p>

  <h3 class="fm-head1" id="heading_id_7">9.2.3 Processing the Rooms column</h3>

  <p class="body">Before we get into what needs to be cleaned up in the <code class="fm-code-in-text">Rooms</code> column, let’s review what some of the values in this column look like, as <a id="idTextAnchor024"/>sh<a id="idTextAnchor025"/>own in figure 9.5.<a id="idIndexMarker026"/><a id="idIndexMarker027"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F05_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.5 Examples of values in the <code class="fm-code-in-text">Rooms</code> column</p>
  </div>

  <p class="body">The values in figure 9.5 present some examples of the problems that need to be dealt with in the <code class="fm-code-in-text">Price</code> column:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Missing values.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Double-barrelled values that contain more than one constituent value. In the Kuala Lumpur real estate dataset, some such values include string expressions such as “4 + 1.” These values require parsing to extract usable values for the model training.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">As for the missing values, we can opt to replace the <code class="fm-code-in-text">NaN</code> values with zero.</p>
    </li>
  </ul>

  <p class="body">At this point, we have the urge to make a choice about how to deal with the <code class="fm-code-in-text">Rooms</code> column overall: should we treat it as a categorical column or a continuous column? To help us decide, let’s review the count of unique values in the <code class="fm-code-in-text">Rooms</code> column:</p>
  <pre class="programlisting">Rooms              43</pre>

  <p class="body">With around 40 values in the <code class="fm-code-in-text">Rooms</code> column, which is a not-too-large number of categories, we could convert it into a categorical column if we wished. Suppose we opt to treat it as a numeric column; let’s check the necessary steps to take. To begin with, let’s look at the first few unique va<a id="idTextAnchor026"/>lues and their counts.<a id="marker-334"/></p>

  <p class="fm-code-listing-caption">Listing 9.7 Count of the most common values in the <code class="fm-code-in-text">Rooms</code> column</p>
  <pre class="programlisting">3           14249      <span class="fm-combinumeral">①</span>
3+1          8070      <span class="fm-combinumeral">②</span>
2            5407
4            5018
4+1          4404
5+1          2340
1            2322
5            2065
2+1          1938
1+1          1191
6             937
Studio        874      <span class="fm-combinumeral">③</span>
6+1           807
4+2           479
3+2           477
5+2           410
7             358
7+1           237
2+2           132
8             125
6+             86      <span class="fm-combinumeral">④</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Example of a value that is immediately convertible to a numeric value</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Example of a value that can be turned into a numeric value by treating it as an equation</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Example of a value that is a string that is not convertible to a numeric value</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Example of a value that could be converted to a numeric value with some extrapolation</p>

  <p class="body">If we want to treat <code class="fm-code-in-text">Rooms</code> as a continuous column, we can deal with the representative examples shown in listing 9.7 in the following ways:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Values like <code class="fm-code-in-text">3</code> that can be converted directly to numeric: convert to numeric.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Values like <code class="fm-code-in-text">3</code> <code class="fm-code-in-text">+</code> <code class="fm-code-in-text">1</code> that we can use the built-in <code class="fm-code-in-text">eval()</code> Python function to evaluate the string value as if it were an equation.<a id="idIndexMarker028"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Values like <code class="fm-code-in-text">Studio</code>: replace them with a reasonable numeric value, such as 1.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Values like <code class="fm-code-in-text">6+</code> should be treated as if they were <code class="fm-code-in-text">6+1</code>. This is not a perfect approach—the dataset does not clarify whether <code class="fm-code-in-text">6+</code> is a short form of <code class="fm-code-in-text">6+1</code> or if it means “6 plus an unspecified number of additional rooms.”</p>
    </li>
  </ul>

  <p class="body">Note that the <code class="fm-code-in-text">treat_rooms_as_numeric</code> setting in the config file for data preparation controls whether <code class="fm-code-in-text">Rooms</code> is prepared as a continuous column or a categorical column. If you set this value to <code class="fm-code-in-text">True</code>, <code class="fm-code-in-text">Rooms</code> is prepared as a continuous column, and if you set it to <code class="fm-code-in-text">False</code> then <code class="fm-code-in-text">Rooms</code> is prepared as a categorical column. In addition to updating the data preparation config file, you also need to ensure that <code class="fm-code-in-text">Rooms</code> is in the appropriate list in the model training config file so that the model training notebook knows whether to treat <code class="fm-code-in-text">Rooms</code> as categorical or continuous, as shown in the following:<a id="idIndexMarker029"/><a id="marker-335"/></p>
  <pre class="programlisting">categorical: # categorical columns
      - 'Location'
#     - 'Rooms'
      - 'Property Type'
      - 'Furnishing'
      - 'Size_type_bin'
continuous: # continuous columns
      - 'Bathrooms'
      - 'Car Parks'
      - 'Rooms'
      - 'Size'</pre>

  <p class="body">Now that we have looked at the transformations we would make to treat <code class="fm-code-in-text">Rooms</code> as a numeric column, we can look at the <code class="fm-code-in-text">clean_<a class="calibre" id="idTextAnchor027"/>up_rooms_col()</code> function.<a id="idIndexMarker030"/></p>

  <p class="fm-code-listing-caption">Listing 9.8 Count of the most common values in the <code class="fm-code-in-text">Rooms</code> column</p>
  <pre class="programlisting">def clean_up_rooms_col(df,treat_rooms_as_numeric):
  if treat_rooms_as_numeric:                                <span class="fm-combinumeral">①</span>
    print("Rooms treated as numeric")
    df['Rooms'] = df['Rooms'].fillna("0")                   <span class="fm-combinumeral">②</span>
    df['Rooms'] = \
df['Rooms'].apply(lambda x: x+"1" \
if x.endswith('+') else x)                                  <span class="fm-combinumeral">③</span>
    df['Rooms'] = df['Rooms'].replace("Studio", "1")        <span class="fm-combinumeral">④</span>
    df['Rooms']= \
df['Rooms'].replace("20 Above", "21")                       <span class="fm-combinumeral">⑤</span>
    df['Rooms']=\
df['Rooms'].apply(lambda x:eval(str(x)))                    <span class="fm-combinumeral">⑥</span>
    df['Rooms'] = pd.to_numeric(df['Rooms'], 
errors='coerce')                                            <span class="fm-combinumeral">⑦</span>
    # replace missing values with 0
    df['Rooms'] = df['Rooms'].fillna(0)                     <span class="fm-combinumeral">⑧</span>
  else:
    print("Rooms treated as non-numeric")
    df['Rooms'] = df['Rooms'].fillna("unknown_rooms")       <span class="fm-combinumeral">⑨</span>
  return(df)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Checks the parameter to determine whether Rooms will be treated as a continuous column</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Deals with values like “6+”</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> If a value ends with +, adds 1 to the end of the string.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> If the value is Studio, replaces it with 1.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Example of a value that could be converted to a numeric value with some extrapolation</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Replaces strings that are valid equations with the numeric result of the equation</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> Converts all values in the column to numeric</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑧</span> If any NaNs have been introduced in these transformations, replaces them with 0.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑨</span> If the column is being treated as categorical, replaces missing values with a placeholder value.</p>

  <p class="body">Listing 9.8 shows that we need to perform many transformations if we want to treat the <code class="fm-code-in-text">Rooms</code> column as a continuous column. In particular, we need to replace one-off nonnumeric values (<code class="fm-code-in-text">Studio</code>, <code class="fm-code-in-text">20</code> <code class="fm-code-in-text">Above</code>) with our best guess of the corresponding numeric value, and we need to replace values that include <code class="fm-code-in-text">+</code> with the evaluation of the string as if it were an equation. For values that end with <code class="fm-code-in-text">+</code>, we assume it’s valid for the string to end with <code class="fm-code-in-text">+1</code> so that the value can be treated as an equation by the <code class="fm-code-in-text">eval()</code> function. We’ve made some assumptions about what values like <code class="fm-code-in-text">6+</code>, <code class="fm-code-in-text">Studio</code>, and <code class="fm-code-in-text">20 Above</code> mean. <a id="idIndexMarker031"/></p>

  <p class="body">In a real-world scenario, we might have access to a subject matter expert, or we may have to make similar guesses to see whether we can get a signal out of these values. Given the expected importance of the <code class="fm-code-in-text">Rooms</code> column (more rooms typically mean more surface area, which can often contribute to higher property values), the acid test will be when we train the model and compare the resulting performance based on treating this column differently, either as categorical or continuous. When we get to train the model later in the chapter, we will try it using both variations of the <code class="fm-code-in-text">Rooms</code> column to determine which one <a id="idTextAnchor028"/>produces the best results.<a id="idIndexMarker032"/><a id="marker-336"/><a id="idIndexMarker033"/></p>

  <h3 class="fm-head1" id="heading_id_8">9.2.4 Processing the Size column</h3>

  <p class="body">Among all the potential features for the Kuala Lumpur real estate price prediction problem, the <code class="fm-code-in-text">Size</code> column is the most problematic. Before going into the details of how to clean up this specific column, let’s review some samples of values in the <code class="fm-code-in-text">Size</code> column<a id="idTextAnchor029"/>, as shown in figure 9.6.<a id="idIndexMarker034"/><a id="idIndexMarker035"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F06_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.6 Examples of values in the <code class="fm-code-in-text">Size</code> column</p>
  </div>

  <p class="body">Along with some missing values, this column contains as a string the classification of the size type (<code class="fm-code-in-text">Built-up</code> or <code class="fm-code-in-text">Land</code> <code class="fm-code-in-text">area</code>) as well as the area of the property and the area metric (“sq. ft”). But that’s not all. As you can see in figure 9.7, there are entries in the <code class="fm-code-in-text">Size</code> column that express th<a id="idTextAnchor030"/>e area as length by width.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F07_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.7 Examples of values in the <code class="fm-code-in-text">Size</code> column with area expressed in length by width</p>
  </div>

  <p class="body">There is still more to be done with the <code class="fm-code-in-text">Size</code> column. Figure 9.8 shows examples of values in the <code class="fm-code-in-text">Size</code> column where the area of the property is expres<a id="idTextAnchor031"/>sed in various equations.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F08_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.8 Examples of values in the <code class="fm-code-in-text">Size</code> column with area expressed in complex equations</p>
  </div>

  <p class="body">So it appears that the <code class="fm-code-in-text">Size</code> column combines three or more different pieces of information for each entry:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Size type (<code class="fm-code-in-text">Land area</code> or <code class="fm-code-in-text">Built</code> <code class="fm-code-in-text">up</code>).</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Area, which can be formatted as a numeric value (e.g., <code class="fm-code-in-text">6900</code>), length by width (e.g., <code class="fm-code-in-text">20</code> <code class="fm-code-in-text">×</code> <code class="fm-code-in-text">80</code>), or length by width with an equation in one or both dimensions (e.g., <code class="fm-code-in-text">10</code> <code class="fm-code-in-text">+</code> <code class="fm-code-in-text">24</code> <code class="fm-code-in-text">×</code> <code class="fm-code-in-text">80</code>). We are assuming that the property is rectangular. Note that this assumption needs to be validated by a real estate professional, and this is an essential point. To conduct a thorough analysis of a dataset, it’s crucial to have access to a subject matter expert who can verify assumptions. For instance, an expert could suggest using missing value replacements such as the median number of bathrooms, which is a good default value to replace missing values in the <code class="fm-code-in-text">Bathrooms</code> column, or 0, which is a good replacement for missing values in the <code class="fm-code-in-text">Car</code> <code class="fm-code-in-text">Parks</code> column. We have set up config files for the data preparation and model training notebooks to make it easy to make changes if our assumptions don’t match what the subject matter expert says. By putting parameters like this in config files, we can update the behavior of the system without touching the Python code and run experiments methodically.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Area metric (e.g., <code class="fm-code-in-text">sq.</code> <code class="fm-code-in-text">ft.</code>).</p>
    </li>
  </ul>

  <p class="body"><a id="marker-337"/>You may be asking now how we were able to identify that the <code class="fm-code-in-text">Size</code> column contained all these anomalies and find a remedy. The answer is through trial and error. First, we separated the size type from the area and area metric. Next, we removed the area metric (since it is always the same). Then, we iterated through the remaining area values, removing or replacing characters until every area value could be applied to <code class="fm-code-in-text">eval()</code>.</p>

  <p class="body">This meticulous iterative process is not uncommon for real-world datasets. We chose the Kuala Lumpur real estate dataset for this section of the book because it presents these kinds of real-world challenges, and working through them illustrates the approaches that need to be taken, some systematic and some tactical, to squeeze as much useful signal as possible out of a dataset.</p>

  <p class="body">We need to separate the three kinds of values in the <code class="fm-code-in-text">Size</code> column. We will discard the area metric because it is always a variation of “square feet” and create a new categorical column that combines the size type value with an identifier for the bin that the area value falls into. To do this, we will need to</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Convert the area values to numeric values by discarding extraneous characters and using the <code class="fm-code-in-text">eval()</code> function to convert the string representation of equations into the numeric result of evaluating the equation. That is, 20 × 80 is replaced with 160.<a id="idIndexMarker036"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Get bins for the resulting numeric area values and add a new column to the dataset with the bin value for each row.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Create a new categorical column that combines size type and bin number.</p>
    </li>
  </ul>

  <p class="body">The following listing shows the <code class="fm-code-in-text">clean_up_size_col()</code> function, which implements the changes we have descr<a id="idTextAnchor032"/>ibed so far in this section.<a id="idIndexMarker037"/><a id="marker-338"/></p>

  <p class="fm-code-listing-caption">Listing 9.9 Code to clean up the <code class="fm-code-in-text">Size</code> column</p>
  <pre class="programlisting">def clean_up_size_col(df,clean_up_list,size_bin_count):
    df.dropna(subset=['Size'], inplace=True)                  <span class="fm-combinumeral">①</span>
    df['Size'] = df['Size'].str.lower()                       <span class="fm-combinumeral">②</span>
    df[['Size_type','Size']] = \
    df['Size'].str.split(':',expand=True)                     <span class="fm-combinumeral">③</span>
    df['Size'] = df['Size'].fillna("0")                       <span class="fm-combinumeral">④</span>
    df = df[df.Size.str.contains(r'\d')]                      <span class="fm-combinumeral">⑤</span>
 
    for string in clean_up_list:                              <span class="fm-combinumeral">⑥</span>
        df = df[~df.Size.str.contains(string,na=False)]
                             
    df['Size'] = (df['Size'].str.replace(',','')
                            .str.replace('`','')
                            .str.replace('@','x')
                            .str.replace('\+ sq. ft.','')
                            )                                 <span class="fm-combinumeral">⑦</span>
    df['Size'] = (df['Size'].str.replace(' sq. ft.','')
                            .str.replace('sf sq.ft.','')
                            .str.replace('ft','')
                            .str.replace('sq','')
                            .str.replace("xx","*")
                            .str.replace("x ","*")
                            .str.replace(" x","*")
                            .str.replace("x","*")
                            .str.replace("X","*")
                            .replace('\'','')
                            )                                 <span class="fm-combinumeral">⑧</span>
    df['Size'] = \
    df['Size'].apply(lambda x: remove_after_space(x))         <span class="fm-combinumeral">⑨</span>
    df['Size'] = \
df['Size'].apply(lambda x: eval(str(x)))                      <span class="fm-combinumeral">⑩</span>
    df['Size'] = df['Size'].fillna(0.0)
    print("min is: ",df['Size'].min())
    print("max is: ",df['Size'].max())
    bins = np.linspace(df['Size'].min(), 
    df['Size'].max(), size_bin_count)                         <span class="fm-combinumeral">⑪</span>
    print("bins is: ",bins)
    bin_labels = range(1,size_bin_count+1)                    <span class="fm-combinumeral">⑫</span>
    print("bin_labels is: ",bin_labels)
    df['Size_bin'] = pd.qcut(df['Size'],
    size_bin_count, labels=bin_labels)                        <span class="fm-combinumeral">⑬</span>
    df['Size_type_bin'] = \
    df['Size_type']+df['Size_bin'].astype(str)                <span class="fm-combinumeral">⑭</span>
    return(df)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Removes rows that are missing Size values</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Changes all values in the Size column to lowercase</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Splits the Size column by moving the size type values into a new column”</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Replaces any remaining missing values with 0</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Removes any rows where the size column contains no digits</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Removes any rows where the size column cannot be converted to a numeric value</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> Replaces characters that will cause problems treating multiplications correctly</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑧</span> Removes remaining characters that will cause problems treating the remaining Size values as numeric</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑨</span> Removes extraneous characters following spaces</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑩</span> Evaluates the remaining Size values as equations</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑪</span> Defines bins for the Size values</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑫</span> Defines bin names</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑬</span> Creates a new column that contains the bin value for the Size value in that row</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑭</span> Creates a new categorical column that combines the Size type value and the Size_bin value</p>

  <p class="body">The <code class="fm-code-in-text">clean_up_size_col()</code> function shown in listing 9.9 comprises a series of transformations that allow the evaluation of the area information from the <code class="fm-code-in-text">Size</code> column as a numeric value. To do this, we need to remove the rows where the area cannot be interpreted. The area of the property is so fundamental to determining its pricing value that it does not make sense to train a model using examples from listings where it is impossible to extract the area information; hence, we simply drop those rows. Next, we need to clean up the remaining area values so that they can be evaluated as numeric values, either because they can be directly converted to numeric values or because they can be interpreted as equations that can be applied to the <code class="fm-code-in-text">eval()</code> function. <a id="idIndexMarker038"/><a id="idIndexMarker039"/><a id="marker-339"/></p>

  <p class="body">Given the significant influence of a listing’s area on its price, it’s worthwhile to invest a lot of effort into extracting the area information in any way we can. For this purpose, we create new categorical columns containing the bin number corresponding to the size of the listing. Utilizing this bin value makes it possible to evaluate the area portion of the <code class="fm-code-in-text">Size</code> column as a numeric value. In doing this, we need to remove rows where the area cannot be interpreted. The area of the property is so fundamental to its value that it does not make sense to train the model with the data from listings where it is impossible to extract the area information because it is concatenated with the size type (<code class="fm-code-in-text">built-up</code> or <code class="fm-code-in-text">land</code> <code class="fm-code-in-text">area</code>).</p>

  <p class="body">Figure 9.9 displays examples of values in the revised <code class="fm-code-in-text">Size</code> column along with the new columns (<code class="fm-code-in-text">Size_type</code>, <code class="fm-code-in-text">Size_bin</code>, and <code class="fm-code-in-text">Size_type_bin</code>) created by <a id="idTextAnchor033"/>the function in listing 9.9.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F09_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.9 Examples of values in the new columns generated from the <code class="fm-code-in-text">Size</code> column</p>
  </div>

  <p class="body">Let’s look at each column in figure 9.9:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Size</code>—Replacing the original values in the <code class="fm-code-in-text">Size</code> column are single continuous values that correspond to the land area from the original <code class="fm-code-in-text">Size</code> column.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Size_type</code>—This new column contains the size type (<code class="fm-code-in-text">built-up</code> or <code class="fm-code-in-text">land</code> <code class="fm-code-in-text">area</code>) portion of the original <code class="fm-code-in-text">Size</code> column value.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Size_bin</code>—This new column contains the bin number that the <code class="fm-code-in-text">Size</code> column value belongs to. Notice that for the examples in figure 9.9, the row with the smallest <code class="fm-code-in-text">Size</code> value has the smallest bin number, and the rows with the largest <code class="fm-code-in-text">Size</code> values have the largest bin number.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Size_type_bin</code>—This new column contains a combination of the values in the other two new columns.</p>
    </li>
  </ul>

  <p class="body"><a id="marker-340"/>Consider a specific value from the original <code class="fm-code-in-text">Size</code> column and how it gets processed to create the values in the new <code class="fm-code-in-text">Size</code>, <code class="fm-code-in-text">Size_type</code>, <code class="fm-code-in-text">Size_bin</code>, and <code class="fm-code-in-text">Size_type_bin</code> column<a id="idTextAnchor034"/>s, as shown in figure 9.10.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F10_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.10 Original <code class="fm-code-in-text">Size</code> column and values in the new columns</p>
  </div>

  <p class="body">We started with a <code class="fm-code-in-text">Size</code> column that contained a jumble of two kinds of critical information jammed into a single column and that had numeric data (the area of the property), sometimes as a number and sometimes as an equation. After applying the cleanup steps, we have split the <code class="fm-code-in-text">Size</code> column into four columns: one continuous (<code class="fm-code-in-text">Size</code>) and three categorical (<code class="fm-code-in-text">Size_type</code>, <code class="fm-code-in-text">Size_bin</code>, and <code class="fm-code-in-text">Size_type_bin</code>) that we can ch<a id="idTextAnchor035"/>oose from to train the model.<a id="idIndexMarker040"/><a id="idIndexMarker041"/><a id="idIndexMarker042"/><a id="idIndexMarker043"/></p>

  <h2 class="fm-head" id="heading_id_9">9.3 Defining the deep learning model</h2>

  <p class="body">In this section, we will go through the code that defines the deep learning model for the Kuala Lumpur real estate price prediction model. First, we’ll compare the approach for defining the model used in this chapter, with Keras preprocessing layers, to the approach that we saw in chapter 3, which used custom layers. Then we’ll review in detail the code that makes up the model definition. Finally, we’ll wrap up this section by discussing the rationale for using Keras preprocessing layers as a best practice for deep learning with tabular data.<a id="marker-341"/><a id="idIndexMarker044"/><a id="idIndexMarker045"/></p>

  <p class="body">The code in this section is available at <a class="url" href="https://mng.bz/gaBe">https://mng.bz/gaBe</a>, and the con<a id="idTextAnchor036"/>fig file is at <a class="url" href="https://mng.bz/ey19">https://mng.bz/ey19</a>.</p>

  <h3 class="fm-head1" id="heading_id_10">9.3.1 Contrasting the custom layer and Keras preprocessing layer approaches</h3>

  <p class="body">Starting in chapter 3, we have examined the Keras-based solution for the Airbnb NYC price prediction problem. In that solution, we created a deep learning model and the associated pipelines “from scratch.” That is, we didn’t use any functions from TensorFlow or Keras specifically designed for tabular data. In the solution we propose for the Kuala Lumpur real estate problem, we are going to switch gears and take advantage of Keras preprocessing layers to make it easier to handle the tabular dataset. To provide some context on the differences between the two approaches, let’s compare:<a id="idIndexMarker046"/><a id="idIndexMarker047"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Using custom layers</i>—This is the approach we used for the Airbnb NYC price prediction problem in chapter 3 and the baseline for comparison with other deep learning approaches in chapter 8.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Using Keras preprocessing layers</i>—This is the approach we will use for this chapter and the subsequent <a id="idTextAnchor037"/>chapters in this book.</p>
    </li>
  </ul>

  <p class="body">See table 9.1.</p>

  <p class="fm-table-caption">Table 9.1 Comparison of the Kuala Lumpur real solutions using custom classes and using Keras preprocessing layers</p>

  <table border="1" class="contenttable-1-table" id="table001" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="20%"/>
      <col class="contenttable-0-col" span="1" width="40%"/>
      <col class="contenttable-0-col" span="1" width="40%"/>
    </colgroup>

    <thead class="contenttable-1-thead">
      <tr class="contenttable-c-tr">
        <th class="contenttable-1-th"/>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Using custom layers</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Using Keras preprocessing layers</p>
        </th>
      </tr>
    </thead>

    <tbody class="contenttable-1-thead">
      <tr class="contenttable-c-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Pipeline</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">Custom pipeline classes based on Scikit-learn Pipeline class (<a class="url" href="https://mng.bz/pKP5">https://mng.bz/pKP5</a>); requires classes to be defined in a separate file so they can be used at training and inference (<a class="url" href="https://mng.bz/OBxK">https://mng.bz/OBxK</a>); complex code to define, train, invoke, and save the pipelines.</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">The standard, off-the-shelf Keras preprocessing layers, available at <a class="url" href="https://mng.bz/YD1o">https://mng.bz/YD1o</a>. The code to define, train, and invoke the pipeline is much simpler and more robust.</p>
        </td>
      </tr>

      <tr class="contenttable-c-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Model definition</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">A complex set of layers, specified to work with categorical, continuous, and text inputs</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">A simple set of layers, capable of working with generic categorical and continuous inputs</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">Figure 9.11 shows the layers that make up the Kuala Lumpur real estate price prediction model using Keras preprocessing layers.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F11_Ryan2.png"/></p>

    <p class="figurecaption">F<a id="idTextAnchor038"/>igure 9.11 Kuala Lumpur real estate price prediction model with Keras preprocessing layers</p>
  </div>

  <p class="body">Figure 9.12 shows the layers that make up the Kuala Lumpur real estate price prediction model using custom layers; the code is available at <a class="url" href="https://mng.bz/KGeP">https://mng.bz/KGeP</a>.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F12_Ryan2.png"/></p>

    <p class="figurecaption">Fi<a id="idTextAnchor039"/>gure 9.12 Kuala Lumpur real estate price prediction model with custom layers</p>
  </div>

  <p class="body"><a id="marker-342"/>The overall structure for the Keras model with custom layers in figure 9.12 looks more complex than the structure in figure 9.11 for the model with Keras preprocessing layers, but there is a lot going on, so it’s not easy to see the details. Let’s zoom into the layers that just process the <code class="fm-code-in-text">Size</code> column to get a more specific idea of how these two architectures differ. Figure 9.13 shows the layers for the <code class="fm-code-in-text">Size</code> column in the model with Keras preprocessing layers.<a id="idIndexMarker048"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F13_Ryan2.png"/></p>

    <p class="figurecaption">Fi<a id="idTextAnchor040"/>gure 9.13 Layers for the <code class="fm-code-in-text">Size</code> column with Keras preprocessing layers<a id="marker-343"/></p>
  </div>

  <p class="body">We can see that there are four layers between the input layer for <code class="fm-code-in-text">Size</code> and the final output layer. Compare this to the layers for the <code class="fm-code-in-text">Size</code> column for the Keras model with custom layers, as shown in figure 9.14.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F14_Ryan2.png"/></p>

    <p class="figurecaption">Fig<a id="idTextAnchor041"/>ure 9.14 Layers for the <code class="fm-code-in-text">Size</code> column with custom layers</p>
  </div>

  <p class="body">For the Keras model defined with custom layers, there are seven layers between the input layer for <code class="fm-code-in-text">Size</code> and the final output layer, compared to four layers for the model that uses Keras preprocessing layers. Because of the way that the layers are chained together in the model with customer layers, there is a series of individual concatenation operations layer by layer. In contrast, the model with Keras preprocessing layers has a single concatenation layer that pulls together all layers coming in from each input. This difference in the number of intermediate layers between the input of the <code class="fm-code-in-text">Size</code> column and the final layer reflects the overall additional complexity of the Keras model with custom layers compared to the model with Keras preprocessing layers.</p>

  <h3 class="fm-head1" id="heading_id_11">9.3.2 Exa<a id="idTextAnchor042"/>mining the code for model definition using Keras preprocessing layers</h3>

  <p class="body"><a id="marker-344"/>In general, the code for defining and training the model using Keras preprocessing is simpler and more streamlined than the deep learning code you read about in previous chapters that used custom layers and Scikit-learn based pipelines. However, a small price is to be paid in exchange for the increased simplicity of a model based on Keras preprocessing layers. To avoid getting an error when saving the model using <code class="fm-code-in-text">model.save()</code> and in the model saving callback, we need to ensure that all column names are lowercase and contain no spaces (this can be achieved using the <code class="fm-code-in-text">snake_case</code> naming convention instead) for the model using Keras preprocessing layers. The code in the following listing automatically does this.<a id="idIndexMarker049"/><a id="idIndexMarker050"/><a id="idIndexMarker051"/><a id="idIndexMarker052"/><a id="idTextAnchor043"/></p>

  <p class="fm-code-listing-caption">Listing 9.10 Lowercase column names and replacing spaces</p>
  <pre class="programlisting">merged_data.columns = \
merged_data.columns.str.replace(' ', '_')               <span class="fm-combinumeral">①</span>
merged_data.columns  = merged_data.columns.str.lower()  <span class="fm-combinumeral">②</span>
config['categorical'] = \
[x.replace(" ", "_") for x in \
config['categorical']]                                  <span class="fm-combinumeral">③</span>
config['continuous'] = \
[x.replace(" ", "_") for x in \
config['continuous']]                                   <span class="fm-combinumeral">④</span>
config['categorical'] = \
[x.lower() for x in config['categorical']]              <span class="fm-combinumeral">⑤</span>
config['continuous'] = \
[x.lower() for x in config['continuous']]               <span class="fm-combinumeral">⑥</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> For columns in the input dataframe, replaces spaces in column names with underscores</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Lowercase column names in the input dataframe</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> For the list of categorical column names, replaces spaces with underscores</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> For the list of continuous column names, replaces spaces with underscores</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Lowercases the list of categorical column names</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Lowercases the list of continuous column names</p>

  <p class="body">The code shown in listing 9.10 replaces spaces in the column names in the input DataFrame and the lists of categorical and continuous column names. For example, the variable name <code class="fm-code-in-text">Car</code> <code class="fm-code-in-text">Parks</code> becomes <code class="fm-code-in-text">Car_Parks</code>. <a id="idIndexMarker053"/></p>

  <p class="body">The following listing presents the definition of the <code class="fm-code-in-text">df_to_dataset</code> function, which creates an input pipeline for the model that uses Keras preprocessing layers<a id="idTextAnchor044"/>.<a id="marker-345"/><a id="idIndexMarker054"/></p>

  <p class="fm-code-listing-caption">Listing 9.11 Function to create an input pipeline</p>
  <pre class="programlisting"># function from https:
//www.tensorflow.org/tutorials/structured_data/preprocessing_layers
def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  df = dataframe.copy()
  labels = df.pop('target')                              <span class="fm-combinumeral">①</span>
  df = {key: value[:,tf.newaxis] for key, 
    value in dataframe.items()}                          <span class="fm-combinumeral">②</span>
  ds = tf.data.Dataset.from_tensor_slices((dict(df), 
    labels))                                             <span class="fm-combinumeral">③</span>
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))          <span class="fm-combinumeral">④</span>
  ds = ds.batch(batch_size)                              <span class="fm-combinumeral">⑤</span>
  ds = ds.prefetch(batch_size)                           <span class="fm-combinumeral">⑥</span>
  return ds</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Gets the target column from the local copy of the dataframe</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Creates a new dictionary df with the same keys and values but with a new axis added to it</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Creates a TensorFlow Dataset ds using the from_tensor_slices method</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Shuffles the elements of the dataset to avoid overfitting if the data has some intrinsic sorting</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Groups the elements of the dataset into batches of size batch_size</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Applies prefetch() to the dataset</p>

  <p class="body">The <code class="fm-code-in-text">df_to_dataset</code> function shown in listing 9.11, which is taken directly from <a class="url" href="https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers">https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers</a>, will be applied to the training, validation, and test datasets to convert them into <code class="fm-code-in-text">tf.data.Dataset</code> objects, then shuffle and batch the datasets. Note that the definition of the dataset <code class="fm-code-in-text">ds</code> takes two arguments: <code class="fm-code-in-text">dict(df)</code>, a dictionary version of the input dataframe, and <code class="fm-code-in-text">labels</code>, the target values from the input dataframe. Also, note that applying <code class="fm-code-in-text">prefetch()</code> to the dataset allows the dataset to be processed more efficiently by overlaying the preprocessing and model execution of one batch while the next batch is being loaded.<a id="idIndexMarker055"/><a id="idIndexMarker056"/><a id="idIndexMarker057"/></p>

  <p class="body">The following listing defines the <code class="fm-code-in-text">get_normalization_layer()</code> function, which defines a normalization layer for a given feat<a id="idTextAnchor045"/>ure. <a id="idIndexMarker058"/><a id="marker-346"/></p>

  <p class="fm-code-listing-caption">Listing 9.12 Creating normalization layers for continuous columns</p>
  <pre class="programlisting"># function from 
https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers
def get_normalization_layer(name, dataset):
  normalizer = layers.Normalization(axis=None)            <span class="fm-combinumeral">①</span>
  feature_ds = dataset.map(lambda x, y: x[name])          <span class="fm-combinumeral">②</span>
  normalizer.adapt(feature_ds)                            <span class="fm-combinumeral">③</span>
  return normalizer</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Defines a normalization object</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Creates a dataset from the input dataset with only the input feature</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Trains the normalizer using the specified input feature</p>

  <p class="body">The <code class="fm-code-in-text">get_normalization_layer()</code> function defined in listing 9.12, which is taken directly from <a class="url" href="https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers">https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers</a>, will be applied to all the continuous columns that we want to use to train the model. This function scales input values with a distribution centered around 0 with a standard deviation of 1. For details about the normalization object defined in this function, see <a class="url" href="https://mng.bz/9YDx">https://mng.bz/9YDx</a>. Note that for gradient boosting solutions, normalization would not be needed.<a id="idIndexMarker059"/></p>

  <p class="body">The following listing presents the definition of the <code class="fm-code-in-text">get_category_encoding_layer()</code> function, which specifies an encoding layer for a given categorical <a id="idTextAnchor046"/>column.<a id="idIndexMarker060"/></p>

  <p class="fm-code-listing-caption">Listing 9.13 Creating encoding layers for categorical columns</p>
  <pre class="programlisting"># function from 
https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers
def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):
  if dtype == 'string':                                     <span class="fm-combinumeral">①</span>
    index = layers.StringLookup(max_tokens=max_tokens)
  else:
    index = layers.IntegerLookup(max_tokens=max_tokens)
  feature_ds = dataset.map(lambda x, y: x[name])            <span class="fm-combinumeral">②</span>
  index.adapt(feature_ds)                                   <span class="fm-combinumeral">③</span>
  encoder = \
layers.CategoryEncoding(num_tokens= \
index.vocabulary_size())                                    <span class="fm-combinumeral">④</span>
  return lambda feature: encoder(index(feature))            <span class="fm-combinumeral">⑤</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Creates layers for the column depending on whether or not it’s a string column</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Creates a dataset from the input dataset with only the input feature</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Learns the set of possible values for the column and assigns them a fixed numeric index</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Encodes the numeric indices</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Applies multi-hot encoding to the indices</p>

  <p class="body">The <code class="fm-code-in-text">get_category_encoding_layer()</code> function defined in listing 9.13, which is taken direc<a id="idTextAnchor047"/><a id="idTextAnchor048"/>tly from <a class="url" href="https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers">https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers</a>, will be applied to all the categorical columns that we want to use to train the model. In this function, if a column is a string column, a layer is generated that turns strings into numeric indices; otherwise, a layer is created that turns integer values into numeric indices.<a id="idIndexMarker061"/></p>

  <p class="body">The following listing shows the code to apply the <code class="fm-code-in-text">df_to_dataset()</code> function to the training, validation, and testing <a id="idTextAnchor049"/>datasets.<a id="idIndexMarker062"/><a id="marker-347"/></p>

  <p class="fm-code-listing-caption">Listing 9.14 Applying <code class="fm-code-in-text">df_to_dataset()</code> to train, validate, and test datasets</p>
  <pre class="programlisting"># function from 
# https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers
train_ds = df_to_dataset(train, batch_size=batch_size)      <span class="fm-combinumeral">①</span>
val_ds = df_to_dataset(val, shuffle=False, 
    batch_size=batch_size)                                  <span class="fm-combinumeral">②</span>
test_ds = df_to_dataset(test, shuffle=False, 
    batch_size=batch_size)                                  <span class="fm-combinumeral">③</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Generates training dataset</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Generates validation dataset</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Generates test dataset</p>

  <p class="body">Once the code in listing 9.14 is applied, we will obtain the datasets and be ready to start the training process.</p>

  <p class="body">The following listing shows the code to apply the <code class="fm-code-in-text">df_to_dataset()</code> function to the training, validation, and testing<a id="idTextAnchor050"/> datasets.<a id="idIndexMarker063"/></p>

  <p class="fm-code-listing-caption">Listing 9.15 Defining layers for continuous and categorical columns</p>
  <pre class="programlisting">all_inputs = []                                              <span class="fm-combinumeral">①</span>
encoded_features = []                                        <span class="fm-combinumeral">②</span>
 
for header in config['continuous']:                          <span class="fm-combinumeral">③</span>
  numeric_col = tf.keras.Input(shape=(1,), name=header)
  normalization_layer = get_normalization_layer(header, train_ds)
  encoded_numeric_col = normalization_layer(numeric_col)
  all_inputs.append(numeric_col)
  encoded_features.append(encoded_numeric_col)
 
for header in config['categorical']:                         <span class="fm-combinumeral">④</span>
  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')
  encoding_layer = get_category_encoding_layer(name=header,
                                               dataset=train_ds,
                                               dtype='string',
                                               max_tokens=5)
  encoded_categorical_col = encoding_layer(categorical_col)
  all_inputs.append(categorical_col)
  encoded_features.append(encoded_categorical_col)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> List for input features</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> List for encoded features</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Creates a normalization layer for each continuous column</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Creates an encoding layer for each categorical column</p>

  <p class="body"><a id="marker-348"/>In the code in listing 9.15, for each continuous column, <code class="fm-code-in-text">get_normalization_layer()</code> defines a normalization layer for the column. The new layer is added to the <code class="fm-code-in-text">encoded_features</code> list, and the column name is appended to the <code class="fm-code-in-text">all_inputs</code> list. For each categorical column, <code class="fm-code-in-text">get_category_encoding_layer()</code> defines an encoding layer for the column. The new layer is added to the <code class="fm-code-in-text">encoded_features</code> list, and the column name is appended to the <code class="fm-code-in-text">all_inputs</code> list. Once the code in listing 9.15 is run, the <code class="fm-code-in-text">all_features</code> list contains the following values:<a id="idIndexMarker064"/><a id="idIndexMarker065"/><a id="idIndexMarker066"/><a id="idIndexMarker067"/><a id="idIndexMarker068"/><a id="idIndexMarker069"/><a id="idIndexMarker070"/></p>
  <pre class="programlisting">[&lt;KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Bathrooms')&gt;,
 &lt;KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Car_Parks')&gt;,
 &lt;KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Rooms')&gt;,
 &lt;KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'Size')&gt;,
 &lt;KerasTensor: shape=(None, 1) dtype=string (created by layer 'Location')&gt;,
 &lt;KerasTensor: shape=\
(None, 1) dtype=string \
(created by layer 'Property_Type')&gt;,
 &lt;KerasTensor: shape=(None, 1) dtype=string (created by layer 'Furnishing')&gt;,
 &lt;KerasTensor: shape=\
(None, 1) dtype=string \
(created by layer 'Size_type_bin')&gt;]</pre>

  <p class="body">If we look at the settings in the config file that specify the continuous and categorical columns used to train the model, we see that they match the layers specified in the <code class="fm-code-in-text">all_features</code> list:<a id="idIndexMarker071"/></p>
  <pre class="programlisting">categorical: # categorical columns
      - 'Location'
      - 'Property Type'
      - 'Furnishing'
      - 'Size_type_bin'
continuous: # continuous columns
      - 'Bathrooms'
      - 'Car Parks'
      - 'Rooms'
      - 'Size'</pre>

  <p class="body">Now that we have defined the layers that correspond with the columns of the input dataset, we can define the model. The following listing shows the code that<a id="idTextAnchor051"/> defines the model.</p>

  <p class="fm-code-listing-caption">Listing 9.16 Code to define the model</p>
  <pre class="programlisting">all_features = \
tf.keras.layers.concatenate(encoded_features)         <span class="fm-combinumeral">①</span>
x = \
tf.keras.layers.Dense(32, 
    activation="relu")(all_features)                  <span class="fm-combinumeral">②</span>
x = tf.keras.layers.Dropout(dropout_rate)(x)          <span class="fm-combinumeral">③</span>
output = tf.keras.layers.Dense(1)(x)                  <span class="fm-combinumeral">④</span>
 
model = tf.keras.Model(all_inputs, output) </pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Concatenates the features from the encoded_features list created in the code in listing 9.15</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Adds a dense layer to the model. It corresponds with layer 2 in figure 9.15.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Adds a dropout layer to the model. It corresponds with layer 3 in figure 9.15.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Adds a dense layer to the model. It corresponds with layer 4 in figure 9.15.</p>

  <p class="body">Listing 9.16 includes concatenating the features from the <code class="fm-code-in-text">encoded_features</code> list with the <code class="fm-code-in-text">concatenate()</code> function. It corresponds with layer 1 in figure 9.15.<a id="idIndexMarker072"/><a id="idIndexMarker073"/></p>

  <p class="body"><a id="marker-349"/>Once the code in listing 9.16 is applied, the set of layers for the model is defined. As shown in figure 9.15, every categorical column has an input layer, a <code class="fm-code-in-text">StringLookup</code> layer, and a <code class="fm-code-in-text">CategoryEncoding</code> layer, and every continuous column has an input layer and a nor<a id="idTextAnchor052"/>malization layer. <a id="idIndexMarker074"/><a id="idIndexMarker075"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F15_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.15 Diagram of the layers in the model</p>
  </div>

  <p class="body">Figure 9.15 shows the layers rendered in the default vertical arrangement. To get a horizontal arrangement, we can use the <code class="fm-code-in-text">rankdir='LR'</code> parameter in the <code class="fm-code-in-text">plot_model</code> function:<a id="idIndexMarker076"/><a id="idIndexMarker077"/></p>
  <pre class="programlisting">tf.keras.utils.plot_model(model, show_shapes=True, rankdir="LR")</pre>

  <p class="body">In addition, note that the architecture shown in figure 9.15 is simple enough for the modest number of features in the Kuala Lumpur dataset. The architecture will get complicated if you are working with a dataset with a large number of features. In addition, the approach described in this chapter for categorical columns depends on one-hot encoding. This approach works out for the Kuala Lumpur real estate dataset since the maximum number of unique values in any categorical column is just a bit over 100:</p>
  <pre class="programlisting">Rooms              18
Location          108
Property Type      97
Furnishing          5
Size_type_bin      20</pre>

  <p class="body">However, if we had a dataset with hundreds or thousands of values in some of its categorical columns, using one-hot encoding could cause memory problems. In that case, we may have to consider using embeddings for categorical columns, as we did for the categorical columns in the Keras model with custom layers.</p>

  <p class="body">In this section, we have reviewed the code to define the model. In the next section, we will go over the <a id="idTextAnchor053"/>code to train the model.<a id="idIndexMarker078"/><a id="idIndexMarker079"/><a id="idIndexMarker080"/><a id="marker-350"/><a id="idIndexMarker081"/></p>

  <h2 class="fm-head" id="heading_id_12">9.4 Training the deep learning model</h2>

  <p class="body">In the previous section, we examined the code to define the model and examined how the layers in the model were built up based on the input columns. In this section, we’ll describe the process of training the model that we defined in the previous section.<a id="idIndexMarker082"/></p>

  <p class="body">The code in this section is available at <a class="url" href="https://mng.bz/gaBe">https://mng.bz/gaBe</a> and the config file at <a class="url" href="https://mng.bz/ey19">https://mng.bz/ey19</a>. The following listing shows the code necessary to<a id="idTextAnchor054"/> compile and train the model.</p>

  <p class="fm-code-listing-caption">Listing 9.17 Code to compile and train the model</p>
  <pre class="programlisting">model.compile(optimizer=config['hyperparameters']['optimizer'],
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=config['metrics'])                      <span class="fm-combinumeral">①</span>
if config['general']['early_stop']:
   callback_list, save_model_path = set_early_stop(es_monitor, es_mode)
   model.fit(train_ds, 
             epochs=config['hyperparameters']['epochs'],    
             validation_data=val_ds,
             callbacks=callback_list)                         <span class="fm-combinumeral">②</span>
else:
   model.fit(train_ds, 
             epochs=config['hyperparameters']['epochs'], 
             validation_data=val_ds)                          <span class="fm-combinumeral">③</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Compiles the model defined in listing 9.16 using the hyperparameters from the config file</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Creates the list of callbacks and uses it in the call to fit to train the model</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Calls fit to train the model without the callback list</p>

  <p class="body">Listing 9.17 shows that the hyperparameter values are from the config file. By defining the hyperparameters in the config file, we can adjust them and rerun the model training notebook without touching the Python code. Maintaining the config values in a file separate from the Python code reduces the chance of regressions caused by touching the code and makes it easier to track the results of experiments.</p>

  <p class="body">Note also that we can call <code class="fm-code-in-text">fit()</code> to train the model with callbacks. The code in listing 9.17 shows that we can call <code class="fm-code-in-text">fit()</code> using a set of callbacks if we want to control the training process or without callbacks to let the training process run through all the specified epochs without interruption. Using callbacks to control the training process is a best practice for deep learning models with Keras because it allows us to use the resources to train the model more efficiently. Instead of running through all the specified epochs and getting the performance of the model from whatever it happened to be in the last epoch, we can use callbacks to stop the training process if it stops improving for a given number of epochs. We can ensure that the outcome of the training process is optimal for the whole training process.</p>

  <p class="body">Now that the model has been trained, the following listing presents how to perform a quick eva<a id="idTextAnchor055"/>luation of the trained model.<a id="marker-351"/></p>

  <p class="fm-code-listing-caption">Listing 9.18 Code to get a quick evaluation of the trained model</p>
  <pre class="programlisting">loss, accuracy = model.evaluate(test_ds)                  <span class="fm-combinumeral">①</span>
print("Test Loss", loss)
print("Test Accuracy", accuracy)
Test Loss 0.2754836082458496                              <span class="fm-combinumeral">②</span>
Test Accuracy 0.8765323758125305                          <span class="fm-combinumeral">③</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Uses the evaluate() function to get the loss and accuracy for the trained model with the test dataset</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Tests loss for this training run</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Tests accuracy for this training run</p>

  <p class="body">The output from running listing 9.18 presents decent results on the test<a id="idTextAnchor056"/> set using the trained model.</p>

  <h3 class="fm-head1" id="heading_id_13">9.4.1 Cross-validation in the training process</h3>

  <p class="body">In chapter 4 we highlighted cross-validation (that is, segmenting the dataset and repeatedly training the model on different subsets of the data with different holdouts to validate the model) as a best practice for classic machine learning approaches. Do we need to worry about cross-validation for deep learning with tabular data? The short answer is “no.” In Keras, by default, when we do repeated training runs with proportions of the dataset specified to use for training, validation, and testing, the subsets of the dataset that get put in each category are randomized, so we will get the benefits of cross-validation with Keras naturally if we do repeated training <a id="idTextAnchor057"/>runs (<a class="url" href="https://mng.bz/jpPz">https://mng.bz/jpPz</a>). <a id="idIndexMarker083"/><a id="idIndexMarker084"/></p>

  <h3 class="fm-head1" id="heading_id_14">9.4.2 Regularization in the training process</h3>

  <p class="body">Another technique we highlighted in chapter 4 was regularization (that is, preventing overfitting by reducing the complexity of the model to improve its generalization performance). Do we need to be concerned the same about overfitting using deep learning as we do with classic machine learning? The answer is “absolutely,” and you can see in figure 9.16 a subset of the diagram for the model that highlights the part of the model that is specifically concerned with avoiding overfitting, the dropout layer. The dropout layer randomly sets inputs to 0 to reduce overfi<a id="idTextAnchor058"/>tting (<a class="url" href="https://mng.bz/W2z4">https://mng.bz/W2z4</a>).<a id="idIndexMarker085"/><a id="marker-352"/><a id="idIndexMarker086"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F16_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.16 Regulariza<a id="idTextAnchor059"/>tion in the deep learning model</p>
  </div>

  <h3 class="fm-head1" id="heading_id_15">9.4.3 Normalization in the training process</h3>

  <p class="body">Normalization refers to adjusting continuous values across features so that their values fall into a consistent range. In chapter 4, we covered using this technique (also known as standardization) in classic machine learning. In listing 9.12, we showed the Kuala Lumpur solution code that uses normalization layers.<a id="idIndexMarker087"/><a id="idIndexMarker088"/></p>

  <p class="body">There are examples of continuous columns in the Kuala Lumpur dataset whose values have significantly different ranges. For example, in the Kuala Lumpur dataset, the <code class="fm-code-in-text">Bathrooms</code> feature ranges between 0 and 20 while <code class="fm-code-in-text">Size</code> ranges from 0 to 11 million. Leaving the continuous columns with such disparate ranges can make the training process less efficient. Figure 9.17 shows the normalization layers that make the ranges of values for the continuous features fall within more consistent ranges.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F17_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.17 Normalization in the deep learning model</p>
  </div>

  <p class="body">The normalization layers adjust the values in each of the continuous columns into a distribution centered around 0 with a standard deviation of 1 (<a class="url" href="https://mng.bz/0QKp">https://mng.bz/0QKp</a>).</p>

  <p class="body">In this section, we have reviewed the code for training the Kuala Lumpur real estate price prediction model, along with a set of best practices demonstrated in the model: regularization to avoid overfitting, and normalization to bring the values of continuous columns into consistent ranges. In the next section, we will put all our work together by exercising the trained deep learning <a id="idTextAnchor060"/>model with brand-new data points.<a id="idIndexMarker089"/></p>

  <h2 class="fm-head" id="heading_id_16">9.5 Exercising the deep learning model</h2>

  <p class="body">So far in this chapter, we have prepared the Kuala Lumpur real estate dataset, defined a deep learning model using Keras preprocessing layers, and trained the model. In this section, we’ll exercise the trained model.<a id="idIndexMarker090"/><a id="marker-353"/></p>

  <p class="body">The c<a id="idTextAnchor061"/>ode in this section is available at <a class="url" href="https://mng.bz/gaBe">https://mng.bz/gaBe</a> and the <a id="idTextAnchor062"/>config file at <a class="url" href="https://mng.bz/ey19">https://mng.bz/ey19</a>.</p>

  <h3 class="fm-head1" id="heading_id_17">9.5.1 Rationale for exercising the trained model on some new data points</h3>

  <p class="body">The process of deploying a model is complex, and we will examine it in more depth in chapters 10 and 11. It can be a big investment to complete the initial deployment, so we want to ensure that deployment goes smoothly and we don’t have to backtrack to earlier points in the process if we don’t have to. If we exercise the trained model on a few real-world data points as soon as possible, we can save more problems from appearing later in the process. There are two key benefits to exercising the trained model on new data points as soon as possible:<a id="idIndexMarker091"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">It’s an eas<a id="idTextAnchor063"/>y way of detecting data leakage (see <a class="url" href="https://mng.bz/zZXw">https://mng.bz/zZXw</a>). It can take months between the start of a data science project and the deployment of the trained model, particularly if you are dealing with the demands of deep learning. During that time, it’s possible to lose track of exactly what data will be available to the trained model once it has been deployed. Exercising the trained model with a few data points is an easy way of uncovering potential data leakage before the project has gone too far. The reason for this is that exercising the model will force you to think about what a new data point looks like.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">It provides a way to validate the performance of the model on the test dataset. For example, if you exercise the trained model with some brand-new data points from the Kuala Lumpur real estate market, you get a sense of whether the performance of the model on the test dataset is consistent with its performance with brand-new data points.</p>
    </li>
  </ul>

  <p class="body"><a id="marker-354"/>To illustrate how exercising the trained model on a few new, real-world examples can help to prevent data leakage, let’s look at how we would exercise the trained model to predict whether a brand-new listing would have a selling price above or below the median for Kuala Lumpur. For the Kuala Lumpur real estate dataset, suppose there was a column called <code class="fm-code-in-text">Weeks</code> <code class="fm-code-in-text">on</code> <code class="fm-code-in-text">the</code> <code class="fm-code-in-text">market</code> that had the number of weeks the property had been on the market before it was sold. If we included such a column in the training of the model, what would happen when we tried to exercise the trained model with a handful of new data points? Figure 9.18 illustrate<a id="idTextAnchor064"/>s the problem we would run into. <a id="idIndexMarker092"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH09_F18_Ryan2.png"/></p>

    <p class="figurecaption">Figure 9.18 Validating the features used to train the model with a new data point</p>
  </div>

  <p class="body">On the left side of figure 9.18, we have the list of features used to train the model as they would be specified in the config file, including the <code class="fm-code-in-text">Weeks</code> <code class="fm-code-in-text">on</code> <code class="fm-code-in-text">the</code> <code class="fm-code-in-text">market</code> feature. On the right is an extract from a real Kuala Lumpur real estate listing. If we want to be able to use the trained model to get a price prediction for actual real estate listings, then we should be able to find values for all the features on the left in the listing on the right. <a id="idIndexMarker093"/></p>

  <p class="body">As shown by the numbers in figure 9.18, for most of the features we will use to train the model, there is a value in the real Kuala Lumpur real estate listing. However, there are two features where we can’t get the values from the real estate listing:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Car</code> <code class="fm-code-in-text">Parks</code>—This particular listing mentions covered parking for the building overall but doesn’t include any information about parking spaces for this particular unit. For the sake of a quick test, we can assume that the value of <code class="fm-code-in-text">Car</code> <code class="fm-code-in-text">Parks</code> for this listing should be 0.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><code class="fm-code-in-text">Weeks</code> <code class="fm-code-in-text">on</code> <code class="fm-code-in-text">the</code> <code class="fm-code-in-text">market</code>—The listing does not include the number of weeks it was on the market before it was sold because we won’t know this value until after the listing has sold. We cannot include <code class="fm-code-in-text">Weeks</code> <code class="fm-code-in-text">on</code> <code class="fm-code-in-text">the</code> <code class="fm-code-in-text">market</code> in the training process.</p>
    </li>
  </ul>

  <p class="body">Now that we have explained why it’s important to exercise the trained model on a handful of real data points, we will review the code for exercis<a id="idTextAnchor065"/>ing the model in the next subsection.<a id="idIndexMarker094"/></p>

  <h3 class="fm-head1" id="heading_id_18">9.5.2 Exercising the trained model on some new data points</h3>

  <p class="body">Now that we have established the benefits of exercising the trained model on new data points, let’s review the code for doing this. <a id="idIndexMarker095"/><a id="marker-355"/></p>

  <p class="body">The following listing shows the code to save the model to the file system, define a new data point by specifying values for all the features used to train and ex<a id="idTextAnchor066"/>ercise the model on the new data point.</p>

  <p class="fm-code-listing-caption">Listing 9.19 Code to exercise the trained model on a new data point</p>
  <pre class="programlisting">model_file_name = \
os.path.join(get_model_path(),config['file_names']['saved_model'])
model.save(model_file_name)                                      <span class="fm-combinumeral">①</span>
reloaded_model = \
tf.keras.models.load_model(model_file_name)                      <span class="fm-combinumeral">②</span>
sample = {                                                       <span class="fm-combinumeral">③</span>
    'location': 'Dutamas, Kuala Lumpur',
    'rooms': 7.0,
    'property_type': 'Serviced Residence (Intermediate)',
    'furnishing': 'Partly Furnished',
    'size_type_bin': 'built-up 1',
    'bathrooms': 1.0,
    'car_parks': 1.0,
    'size': 16805.0,
}
input_dict = \
{name: tf.convert_to_tensor([value]) for name, 
value in sample.items()}                                         <span class="fm-combinumeral">④</span>
predictions = reloaded_model.predict(input_dict)                 <span class="fm-combinumeral">⑤</span>
prob = tf.nn.sigmoid(predictions[0]) 
  
print(
    "This property has a %.1f percent probability of "
    "having a price over the median." % (100 * prob)
)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Saves the trained model to the file system</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Reloads the saved model</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Defines a new data point point</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Puts the new data point into the format expected by the model</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Gets a prediction for the new data point</p>

  <p class="body">If we run the code shown in listing 9.19, we get an output like the following:</p>
  <pre class="programlisting">This property has a 99.4 percent probability
of having a price over the median.</pre>

  <p class="body">The model seems certain that this listing will be over the median price. Can you think of a reason why? It could be because the size shown in this property is huge—over 16,000 square feet. Suppose we rerun this code with a size value of 1,500 and leave all the other values the same. We get output as follows:</p>
  <pre class="programlisting">This property has a 47.5 percent probability 
of having a price over the median.</pre>

  <p class="body"><a id="marker-356"/>This seems roughly in line with our expectations. When we reduce the size to a more reasonable value and leave all the other feature values the same, we get a prediction that is roughly what we expect. With the code shown in listing 9.19, we can exercise a wide variety of data points. For example, a data point for the real Kuala Lumpur listing shown in figure 9.18 would look something like the following:</p>
  <pre class="programlisting">sample = {
    'location': 'Sentul, Kuala Lumpur',
    'rooms': 3.0,
    'property_type': 'Condominium For Sale',
    'furnishing': 'Partly Furnished',
    'size_type_bin': 'built-up 1',
    'bathrooms': 2.0,
    'car_parks': 0.0,
    'size': 950.0,
}</pre>

  <p class="body">And if we get a prediction for this data point, the output looks like the following:</p>
  <pre class="programlisting">This property has a 12.6 percent probability 
of having a price over the median.</pre>

  <p class="body">This prediction seems to be on the low side. We can check the median price value from the input dataset to see how it compares with the prediction:</p>
  <pre class="programlisting">merged_data['price'].median()
980000.0</pre>

  <p class="body">So, the median price from the input dataset is RM 980,000, and the list price for the brand-new property is RM 450,000. This one data point does not prove that the model is good—the dataset was collected four years prior to this new listing, and the list price for this new listing could be well below what the listing actually sells for. However, by trying out several data points, including some with extremes in an important feature (i.e., size, along with a brand-new real-world data point), we can get some assurance that the model’s performance on the test set is not a fluke. By exercising a real-world example of a real estate listing, we have proved that the pipeline in the model is capable of handling real-world data and that the model has not been trained on features that are not available at the point when we want to get a prediction.</p>

  <p class="body">There is one complication with getting the prediction for the brand-new listing that goes back to the way that we created the <code class="fm-code-in-text">size_type_bin</code> column when we prepared the data. Recall that the values in this column are a combination of the <code class="fm-code-in-text">Size_type</code> value (<code class="fm-code-in-text">built-up</code> or <code class="fm-code-in-text">land</code> <code class="fm-code-in-text">area</code>) and the bin value for the area. We reasonably guess the <code class="fm-code-in-text">Size_type</code> value for the new listing, but getting the <code class="fm-code-in-text">bin</code> value requires some work. Now that we have seen a real-world value, one thing to consider is whether we need this combined feature. Perhaps we could refactor this feature so that it is only the <code class="fm-code-in-text">Size_type</code> value without the <code class="fm-code-in-text">bin</code> value for the area. After all, a signal for the area of the listing is already in the <code class="fm-code-in-text">Size</code> column. In the next chapter, we will revisit this problem when we go through the end-to-end process for a deep learn<a id="idTextAnchor067"/>ing solution to a tabular data problem.<a id="idIndexMarker096"/><a id="idIndexMarker097"/><a id="idIndexMarker098"/><a id="marker-357"/><a id="idIndexMarker099"/></p>

  <h2 class="fm-head" id="heading_id_19">Summary</h2>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">To train a model effectively, it is necessary to clean up the dataset. In this chapter, we examined a range of processes used to clean up the dataset.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Deep learning algorithms cannot deal with missing values, so we must fill in values (such as the mean value for a continuous column) or eliminate records.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Strings that express numeric values (such as <code class="fm-code-in-text">24</code> <code class="fm-code-in-text">x</code> <code class="fm-code-in-text">12</code>) can be converted into numeric values using the built-in Python <code class="fm-code-in-text">eval()</code> function. By converting such strings into numeric values, we can extract useful information that can improve the performance of the model.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Columns that contain multiple types of data (such as the original <code class="fm-code-in-text">Size</code> column) can be separated into columns with distinct categories of data. By separating such columns into distinct columns with just one kind of data, we can use each of the new columns as a feature to train the model.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">By taking advantage of the postprocessing layers that are built into Keras, we can define a deep learning model that is simpler and easier to maintain than a Keras model, where the tabular data characteristics are coded from scratch.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Keras callbacks allow us to control the training process and ensure that we don’t waste resources on training iterations when the model is no longer improving. Callbacks also ensure that the model we get at the end of the training run is the peak performance achieved during training.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Many of the best practices from classic machine learning also apply to deep learning, including regularization to avoid overfitting and normalization to adjust values in continuous columns to fall within consistent ranges.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Exercising the trained model on a handful of real-world examples helps avoid data leakage and validate the model’s performance on the test dataset.<a id="marker-358"/></p>
    </li>
  </ul>
</body></html>