- en: 1 LLMs and the need for RAG
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The limits of LLMs and the need for RAG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The RAG basics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Popular use cases of RAG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a short time, large language models (LLMs) have found widespread application
    in modern language processing tasks and autonomous AI agents. OpenAI’s GPT, Anthropic’s
    Claude, Google’s Gemini, and Meta’s Llama series are notable LLMs integrated into
    various platforms and techniques. Retrieval-augmented generation, or RAG, plays
    a pivotal role in the LLM application by enhancing the accuracy and relevance
    of responses. According to Grand View Research ([https://mng.bz/BzKg](https://mng.bz/BzKg)),
    in 2023, the global RAG market was estimated at some $1 billion USD, and it has
    been projected to grow by 44.7% annually, which makes it one of the fastest-growing
    AI methodologies.
  prefs: []
  type: TYPE_NORMAL
- en: This book aims to demystify the idea of RAG and its application. Chapter by
    chapter, the book will present the RAG definition, design, implementation, evaluation,
    and evolution. To kick things off, this chapter begins by highlighting the limitations
    of LLMs and the need for an approach such as RAG. It then introduces the concept
    of RAG and builds toward a definition. The chapter ends by listing the popular
    use cases enabled by RAG.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you will gain foundational knowledge to be ready
    for a deeper exploration of the RAG system components. In addition, you should
  prefs: []
  type: TYPE_NORMAL
- en: Have a strong hold on the RAG definition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand the limitations of LLMs and the need for RAG.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be ready to dive into the components of a RAG system.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: November 30, 2022, will be remembered as a watershed moment in the field of
    artificial intelligence. This was the day OpenAI released ChatGPT, and the world
    became mesmerized by it. ChatGPT turned out to be the fastest app ever to reach
    a million users. Interest in previously obscure terms such as generative AI and
    LLMs skyrocketed over the following 12 months (see figure 1.1).
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph with a line and orange dots'
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH01_F01_Kimothi.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.1  Google trends of “Generative AI” and “Large Language Models” from
    November 2022 to November 2024\. Source: Created by the author using data from
    [trends.google.com](https://trends.google.com/trends/).'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As the use of platforms such as ChatGPT exploded, the weaknesses of LLMs were
    exposed.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Curse of the LLMs and the idea of RAG
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs such as those powering ChatGPT, Ask Gemini, and similar have been shown
    to store knowledge. You can ask them questions, and they tend to respond with
    answers that seem correct. However, despite their unprecedented ability to generate
    text, their responses are not always accurate. Upon more careful observation,
    you may notice that LLM responses are plagued with suboptimal information and
    inherent memory limitations.
  prefs: []
  type: TYPE_NORMAL
- en: To understand the limitations, we will use a simple example. Those familiar
    with the wonderful sport of cricket will recall that the Men’s ODI Cricket World
    Cup tournament was held in 2023\. The Australian cricket team emerged as the winner.
    Now, imagine you are interacting with ChatGPT, and you ask, *“*Who won the 2023
    Cricket World Cup*?”* You are, in truth, interacting with GPT-4o, or o1, LLMs
    developed and maintained by OpenAI that power ChatGPT. In the first few sections
    of this chapter, we will use the terms ChatGPT and LLMs interchangeably for simplicity*.*
    So, you ask the question and, most likely, you will get a response as the one
    in figure 1.2.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer'
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH01_F02_Kimothi.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.2  ChatGPT (GPT 3.5) response to the question, “Who won the 2023 Cricket
    World Cup?” Source: Screenshot of the author’s account on [https://chat.openai.com](https://chat.openai.com).'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: ChatGPT does not have any memory of the 2023 Cricket World Cup, and it tells
    you to check the information from other sources. This is not ideal, but at least
    ChatGPT is honest in its response. The same question asked again might also provide
    a factually inaccurate result. Look at the response in figure 1.3\. ChatGPT falsely
    responds that India was the winner of the tournament.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer'
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH01_F03_Kimothi.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.3  An example of hallucination. ChatGPT’s (GPT 3.5) inaccurate response
    to the question, “Who won the 2023 cricket World Cup?” Source: Screenshot of the
    author’s account on [https://chat.openai.com](https://chat.openai.com).'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This is problematic. Despite not having any memory of the 2023 Cricket World
    Cup, ChatGPT still generates the answer in a seemingly confident tone, but it
    does so inaccurately. This is what is called a “hallucination,” and it has become
    a major point of criticism for LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE In September 2023, ChatGPT’s “Browse with Bing” feature was introduced,
    which allows ChatGPT Plus users to fetch live information from the web for more
    accurate and up-to-date responses. This is a feature of the application, which
    is enabled via agentic search and retrieval mechanisms. The underlying LLM doesn’t
    inherently have the latest information.
  prefs: []
  type: TYPE_NORMAL
- en: Many users treat LLMs as a source of information as an alternative to Google
    Search. In our example, we also expected ChatGPT (GPT 3.5 model) to know the answer
    to the simple question. Why does an LLM fail to meet this expectation?
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.1 LLMs are not trained for facts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generally, LLMs can be thought of as a next-token (loosely, next word) prediction
    model. They are machine learning models that have learned from massive datasets
    of human-generated text, finding statistical patterns to replicate human-like
    language abilities.
  prefs: []
  type: TYPE_NORMAL
- en: To simplify, think of the model first being shown a sentence such as “The teacher
    teaches the student.” Then, we hide the last few words of this sentence (i.e.,
    “teaches the student”) and ask the model what the next word should be. The model
    should learn to predict “teaches” as the next word, “the” as the word after that,
    and so on. There are various methods of teaching the model, including causal language
    modeling (CLM) and masked language modeling (MLM). Figure 1.4 shows the idea behind
    these two techniques.
  prefs: []
  type: TYPE_NORMAL
- en: The training data can have billions of sentences of different kinds. The next
    token (or word) is chosen from a probability distribution observed in the training
    data. There are different means and methods to choose the next token from the
    ones for which a probability has been calculated. Crudely, you can assume that
    a probability is calculated for all the words in the vocabulary, and one among
    the high-probability words is selected. Figure 1.5 shows the probability distribution
    for our example, “The teacher ____ .” The word “teaches” is selected because it
    has the highest probability. Other words could also have been selected.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the model is just trying to predict a word in sequence. It is
    almost magical how LLMs can store knowledge from the data they have been trained
    on and present that knowledge (in most cases) in a coherent and understandable
    language. This ability is possible thanks to a neural network architecture based
    on an attention mechanism known as “transformers.” The nuances of transformers’
    architecture and building LLMs from scratch offer a wide area of study. It is
    out of the scope of this book, but you’re encouraged to find out more about LLM
    training and transformers.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to the limitations of LLMs, their training process introduces three
    major characteristic drawbacks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH01_F04_Kimothi.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.4  Two token prediction techniques: CLM and MLM. In the CLM approach,
    the model predicts the next token based on the preceding tokens. In MLM, the model
    predicts the masked token based on both the preceding and the succeeding tokens.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![](../Images/CH01_F05_Kimothi.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.5  Illustrative probability distribution of words after “The teacher”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Knowledge cut-off date
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Training an LLM is an expensive and time-consuming process. It takes massive
    volumes of data and several weeks, or even months, to train an LLM. The data that
    LLMs are trained on is, therefore, not always up to date. For instance, OpenAI’s
    flagship model, GPT-4.1, released in April 2025, has knowledge only until June
    1, 2024\. Any event that happened after this knowledge cut-off date is not available
    to the model.
  prefs: []
  type: TYPE_NORMAL
- en: Hallucinations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is observed that LLMs sometimes provide factually incorrect responses. (We
    saw this in the 2023 Cricket World Cup example at the beginning of this chapter.)
    Despite being factually incorrect, the LLM responses sound extremely confident
    and legitimate. This characteristic of “lying with confidence,” called hallucinations,
    has proved to be one of the biggest criticisms of LLMs. The reason for hallucinations
    can be traced back to LLMs being a next-token prediction model that selects the
    most probable word from a distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge limitation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As you have already seen, LLMs have been trained on large volumes of data obtained
    from a variety of sources, including the open internet. However, they do not have
    any knowledge of information that is not public. The LLMs have not been trained
    on information such as internal company documents, customer information, product
    documents, confidential personnel information, and so forth. Therefore, LLMs cannot
    be expected to respond to any query about them.
  prefs: []
  type: TYPE_NORMAL
- en: This characteristic raises significant questions about the general adoption
    and value of this technology. But if these limitations are inherent to the nature
    of LLMs and their training process, does this mean the LLM is not usable as a
    technology?
  prefs: []
  type: TYPE_NORMAL
- en: Not at all! Let’s now go ahead and understand how an approach such as RAG comes
    to the rescue.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.2 What is RAG?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Recall the question we used to begin this discussion: “Who won the 2023 Cricket
    World Cup?” What can be done to improve the response?'
  prefs: []
  type: TYPE_NORMAL
- en: Even if ChatGPT doesn’t have this information, the world (aka the internet)
    knows about the 2023 Cricket World Cup with no uncertainty. A simple Google Search
    will tell you about the winner of the 2023 Cricket World Cup if you don’t already
    know it. The Wikipedia article (figure 1.6) on the 2023 Cricket World Cup accurately
    provides this information in the opening section itself. If only there were a
    way to tell the LLM about this Wikipedia article.
  prefs: []
  type: TYPE_NORMAL
- en: How can we give this information to ChatGPT, you ask? The answer is quite simple.
    We just paste this piece of text with our question (see figure 1.7).
  prefs: []
  type: TYPE_NORMAL
- en: And there it is! ChatGPT has now responded with the correct answer. It was able
    to comprehend the piece of additional information we provided, distill the information
    about the winner of the tournament, and respond with a precise and factually accurate
    answer.
  prefs: []
  type: TYPE_NORMAL
- en: It may appear juvenile, but in an oversimplified manner, this example illustrates
    the basic concept of RAG. Let’s look back at what we did here. We understood that
    the question is about the winner of the 2023 Cricket World Cup. We searched for
    information about the question and identified Wikipedia as a source of information.
    We then copied that information and passed it onto ChatGPT (and the LLM powering
    it) along with the original question. In a way, we added to ChatGPT’s knowledge.
    As a technique,
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a web page'
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH01_F06_Kimothi.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.6  Wikipedia article on 2023 Cricket World Cup. Source: [https://mng.bz/yN4J](https://mng.bz/yN4J).'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![A screenshot of a chat'
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH01_F07_Kimothi.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.7  ChatGPT (GPT 3.5) response to the question, augmented with external
    context. Source: Screenshot of the author’s account on [https://chat.openai.com](https://chat.openai.com).'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: RAG does the same thing programmatically. It overcomes the limitations of LLMs
    by providing them with previously unknown information and, consequently, enhances
    the overall memory of the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'As the name implies, “retrieval augmented generation” can be explained through
    three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: It *retrieves* relevant information from a data source external to the LLMs
    (Wikipedia, in our example).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It *augments* the input to the LLM with that external information.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the LLM *generates*a more accurate result.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A simple definition for RAG, illustrated in figure 1.8, can therefore be as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval Augmented Generation is the technique of retrieving relevant information
    from an external source, augmenting the input to the LLM with that external information,
    thereby enabling the LLM to generate a response that is contextual, reliable,
    and factually accurate.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![A diagram of a data flow'
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH01_F08_Kimothi.png)
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.8  RAG (a simple definition): retrieval of information, augmentation
    with the query, and the generation using an LLM form the three RAG focal points'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The example that we have been looking at so far is oversimplified. We manually
    searched for the external information, and the search was for this one specific
    question only. In practice, all these processes are automated, which allows the
    system to scale up to a diverse range of queries and data sources. We will now
    unravel this idea further.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 The novelty of RAG
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The main idea is to provide additional context or knowledge to the LLMs. Essentially,
    it meant creating a ChatGPT-like system with three main objectives:'
  prefs: []
  type: TYPE_NORMAL
- en: Make LLMs respond with up-to-date information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make LLMs respond with factually accurate information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make LLMs aware of proprietary information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These objectives can be achieved using diverse techniques. A new LLM can be
    trained from scratch that includes the new data. An existing model can also be
    fine-tuned with additional data. However, both approaches require a significant
    amount of data and computational resources. Furthermore, updating the model with
    new information at regular intervals is prohibitively costly.
  prefs: []
  type: TYPE_NORMAL
- en: RAG is a cheaper, more effective, and more dynamic technique used to attain
    the three objectives. LLMs respond with information that is up-to-date and factually
    accurate, and they are aware of proprietary information, so they have no knowledge
    gaps.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2.1 The RAG discovery
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In a paper titled “Retrieval-Augmented Generation for Knowledge-Intensive NLP
    Tasks” ([https://arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)),
    Patrick Lewis and his coauthors explored the recipe for RAG models, which combine
    pretrained “parametric” and “non-parametric” memory for language generation. Let’s
    pay some attention to the terms “parametric” and “non-parametric.”
  prefs: []
  type: TYPE_NORMAL
- en: Parameters in machine learning parlance refer to the model weights or variables
    that the model learns during the training process. In simple terms, they are settings
    or configurations that the model adjusts to perform the assigned task. For language
    generation, LLMs are trained with billions of parameters (the GPT 4 model is rumored
    to have over 1 trillion parameters, and the largest Llama 3 model has 405 billion
    parameters). The ability of an LLM to retain information it has been trained on
    is based solely on its parameters. It can therefore be said that LLMs store factual
    information in their parameters. An LLM’s internal memory is referred to as “parametric
    memory.” The parametric memory is limited. It depends on the number of parameters
    and is a factor of the data on which the LLM has been trained.
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, we can provide information to an LLM that it does not have in its
    parametric memory. We saw in the example of the Cricket World Cup that when we
    provided information from an external source to ChatGPT, it was able to get rid
    of the hallucination. This information that is external to the LLM but can be
    provided to the LLM is termed “non-parametric.” If we can gather information from
    external sources as and when desired and use it with the LLM, it forms the “non-parametric”
    memory of the system. In the aforementioned paper, Lewis and his coauthors stored
    Wikipedia data and used a retriever to access the information. They demonstrated
    that this RAG approach outperformed the parametric-only baseline in generating
    more specific, diverse, and factual language. We will discuss vector databases
    and retrievers in chapters 3 and 4.
  prefs: []
  type: TYPE_NORMAL
- en: In 2025, RAG became one of the most used techniques in the LLM domain. With
    the addition of a non-parametric memory, the LLM responses are more grounded and
    factual. Let’s discuss the advantages of RAG.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2.2 How does RAG help?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the introduction of non-parametric memory, the LLM does not remain limited
    to its internal knowledge. We can conclude, at least theoretically, that this
    non-parametric memory can be extended as much as we want. It can store any volume
    of proprietary documents or data and access all sorts of sources, such as the
    intranet and the open internet. In a way, through RAG, we open up the possibility
    of embellishing the LLM with unlimited knowledge. There will always be some effort
    required to create this non-parametric memory or the knowledge base, and we will
    look at it in detail later. Chapter 3 is dedicated to the creation of the non-parametric
    knowledge base.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a consequence of overcoming the challenge of limited parametric memory,
    RAG also builds user confidence in the LLM responses. The three advantages of
    RAG are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Deep contextual awarenes**s*—The added information assists the LLM in generating
    contextually appropriate responses, and the users can be relatively more confident.
    For example, if the non-parametric memory contains information about a particular
    company’s products, users can be assured that the LLM will generate responses
    about those products from the provided sources and not from elsewhere.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Source citatio**n*—In addition to being context aware, because the information
    is being fetched from a known source, these sources can be cited in the response.
    This makes the responses more reliable since the users have the choice of validating
    the information from the source.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Lesser hallucinatio**n*—With contextual awareness, the tendency of LLM responses
    to be factually inaccurate is greatly reduced. The LLMs hallucinate less in RAG
    systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We have already seen a simple RAG definition. Let’s now expand that definition:'
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval Augmented Generation is the methodological approach of enhancing the
    parametric memory of an LLM by creating access to an explicit non-parametric memory,
    from which a retriever can fetch relevant information, augment that information
    to the prompt, pass the prompt to an LLM to enable the LLM to generate a response
    that is contextual, reliable, and factually accurate.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This definition is illustrated in figure 1.9.
  prefs: []
  type: TYPE_NORMAL
- en: RAG has acted as a catalyst in the propagation and acceptance of LLM-powered
    applications. Before concluding this chapter and getting into the design of RAG
    systems, let’s look at some popular use cases where RAG is being adopted.
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a computer process'
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH01_F09_Kimothi.png)
  prefs: []
  type: TYPE_NORMAL
- en: Figure 1.9  RAG enhances the parametric memory of an LLM by creating access
    to non-parametric memory.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 1.3 Popular RAG use cases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RAG is not just a theoretical concept but a technique that is as popular as
    the LLM technology itself. Software developers started using language models as
    soon as Google released BERT in 2018\. Today, there are thousands of applications
    that use LLMs to solve language-intensive tasks. Whenever you come across an application
    using LLMs, it will often have an internal RAG system in some shape or form. Common
    applications are described in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.1 Search Engine Experience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Conventional search results are shown as a list of page links ordered by relevance.
    Modern search engines integrate RAG to combine live information retrieval with
    generative answers. Google’s Search Generative Experience (SGE) augments queries
    with relevant results and citations. AI-based search engines such as Perplexity.ai
    and ChatGPT’s search are built on a RAG framework that fetches up-to-date web
    information and then generates responses with sources attached. By grounding answers
    in real-time results, these search engines provide more accurate, source-backed
    answers than standalone LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.2 Personalized marketing content generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The widest use of LLMs has probably been in content generation. Content creation
    tools employ RAG to tailor marketing copy using current data and user-specific
    context. Yarnit, for instance, uses RAG to generate marketing copy, blog posts,
    and other content types based on up-to-the-moment information and user inputs.
    Yarnit can pull in fresh facts or trending material while drafting the text, ensuring
    the output is relevant and factual. By pulling in the right information (e.g.,
    a brand’s style guide or latest stats) at generation time, these platforms produce
    personalized, on-brand marketing content that resonates with audiences.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.3 Real-time event commentary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Imagine an event such as a sport or a news event. A retriever can connect to
    real-time updates/data via APIs and pass this information to the LLM to create
    a virtual commentator. These can further be augmented with text-to-speech models.
    A prime example is IBM’s Watson AI at the US Open—it generates audio and text
    tennis commentary by pulling in live match data and even thousands of news articles
    for context. This RAG approach allowed Watson to mention player stats, head-to-head
    records, and match highlights as it narrated, creating fact-driven commentary
    on the fly. In financial markets, vendors are doing something similar—Bloomberg’s
    AI-driven tools use RAG to ground their insights in up-to-date proprietary data.
    Bloomberg’s platforms explicitly employ a RAG framework so that any generative
    output (market summaries, answers to trader queries, etc.) is based on recent,
    authoritative content rather than the model’s memory alone.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.4 Conversational agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLMs can be customized to product/service manuals, domain knowledge, guidelines,
    and so forth using RAG and serve as support agents, resolving user complaints
    and problems. These agents can also route users to more specialized agents, depending
    on the nature of the query. Almost all LLM-based chatbots on websites or as internal
    tools use RAG. Intercom’s Fin AI agent is a notable example—it was specifically
    designed with a “bespoke and enhanced” RAG architecture to generate answers from
    a company’s support content. Support platforms such as Zendesk follow a similar
    pattern by retrieving help-center articles to answer customer queries. Industry
    observers note that these companies use basic RAG to quickly fetch relevant support
    docs and generate customized responses from them.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.5 Document question answering systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As discussed, one of the LLMs’ limitations is that they don’t have access to
    proprietary nonpublic information such as product documents, customer profiles,
    and similar information specific to an organization. With access to such proprietary
    documents, a RAG system becomes an intelligent AI system that can answer all questions
    about the organization. In the legal domain, for example, researchers have highlighted
    that domain-specific RAG enables far more nuanced and trustworthy answers in tools
    for legal research. A legal Q&A system can retrieve relevant case law or statutes
    and feed those into an LLM to answer a question, ensuring the answer cites the
    correct precedent. This technique was at the heart of products such as ROSS Intelligence,
    which aimed to answer lawyers’ queries by retrieving passages from law databases
    and then generating an answer. More generally, enterprise knowledge management
    is being transformed by RAG—instead of relying on an LLM’s limited training data,
    companies can equip AI assistants to search internal documents, wikis, or manuals
    on the fly.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.6 Virtual assistants
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Virtual personal assistants such as Siri, Alexa, and others are beginning to
    use LLMs to enhance the user’s experience. Coupled with more context on user behavior
    using RAG, these assistants are set to become more personalized. Amazon’s next-generation
    Alexa, for instance, incorporates retrieval techniques, so it can answer with
    information beyond its core training. By augmenting voice assistant answers with
    retrieved facts, RAG helps virtual assistants such as Alexa and Google Assistant
    give far more accurate and current answers to user queries.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.7 AI-powered research
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AI agents have been gaining traction in research-intensive fields such as law
    and finance. RAG has been extensively used to retrieve and analyze case law to
    assist lawyers. A lot of portfolio management companies are introducing RAG systems
    to analyze scores of documents to research investment opportunities. ESGReveal
    is a framework developed by researchers at Alibaba Group that employs RAG to extract
    and evaluate environmental, social, and governance (ESG) data from corporate reports.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.8 Social media monitoring and sentiment analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Analyzing the firehose of social media data is another task suited to RAG. Social
    listening platforms such as Brandwatch use generative AI to summarize trends and
    sentiments from millions of posts, but they ground those summaries in the underlying
    data. Brandwatch’s system, for example, scans over 100 million sources, and then
    its generative AI integration transforms data into easy-to-understand summaries
    for the user.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.9 News generation and content curation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'News organizations have been using RAG to automate and assist in news writing,
    while maintaining accuracy. Reuters, for instance, offers a solution to feed its
    trusted news data into generative models so they produce fact-based outputs. By
    using Reuters’ real-time news feeds as the retrieval source, an AI system can
    generate a news summary or answer questions with the latest verified facts. Reuters
    asserts that this approach keeps your answers reliable and accurate with a RAG
    system extracting trusted facts from the latest Reuters stories. The Associated
    Press (AP) has similarly been a pioneer in automating news: AP has used templates
    and data to auto-generate sports recaps and earnings reports for years, and now,
    with generative AI, they are augmenting those systems with LLMs. Thanks to RAG,
    an AI writer can ingest box score data or financial results and then produce a
    readable article, grounding every statement in the provided data.'
  prefs: []
  type: TYPE_NORMAL
- en: These are only a few select examples. RAG has been extensively used in other
    domains such as customer support automation, financial market insights, healthcare
    diagnostics, legal document drafting, learning systems, and supply chain optimization.
  prefs: []
  type: TYPE_NORMAL
- en: This introductory chapter dealt with the RAG concept. Overcoming the limitations
    of LLMs, RAG addresses these challenges by providing access to a non-parametric
    knowledge base to the system. With this foundational understanding of RAG, in
    the next chapter, we take the first step toward understanding how RAG systems
    are built by looking at the different components of their design.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RAG enhances the memory of LLMs by providing access to external information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are next-word (or token) prediction models trained on massive amounts of
    text data to generate human-like text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs face challenges of having a knowledge cut-off date and being trained only
    on public data. They are also prone to generating factually incorrect information
    (i.e., hallucinating).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RAG overcomes the LLM limitations by incorporating non-parametric memory and
    increases context awareness and reliability of responses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Popular use cases of RAG include search engines, document question-answering
    systems, conversational agents, personalized content generation, virtual assistants,
    and so forth.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
