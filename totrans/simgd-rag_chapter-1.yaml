- en: 1 LLMs and the need for RAG
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 LLMs和RAG的需求
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The limits of LLMs and the need for RAG
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs的局限性和RAG的需求
- en: The RAG basics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG基础知识
- en: Popular use cases of RAG
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG的流行用例
- en: In a short time, large language models (LLMs) have found widespread application
    in modern language processing tasks and autonomous AI agents. OpenAI’s GPT, Anthropic’s
    Claude, Google’s Gemini, and Meta’s Llama series are notable LLMs integrated into
    various platforms and techniques. Retrieval-augmented generation, or RAG, plays
    a pivotal role in the LLM application by enhancing the accuracy and relevance
    of responses. According to Grand View Research ([https://mng.bz/BzKg](https://mng.bz/BzKg)),
    in 2023, the global RAG market was estimated at some $1 billion USD, and it has
    been projected to grow by 44.7% annually, which makes it one of the fastest-growing
    AI methodologies.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在短时间内，大型语言模型（LLMs）在现代语言处理任务和自主AI代理中得到了广泛应用。OpenAI的GPT、Anthropic的Claude、Google的Gemini和Meta的Llama系列是值得注意的LLMs，它们被集成到各种平台和技术中。检索增强生成（RAG）在LLM应用中发挥着关键作用，通过提高响应的准确性和相关性。根据Grand
    View Research([https://mng.bz/BzKg](https://mng.bz/BzKg))，到2023年，全球RAG市场规模估计约为10亿美元，预计年增长率为44.7%，这使得它成为增长最快的AI方法之一。
- en: This book aims to demystify the idea of RAG and its application. Chapter by
    chapter, the book will present the RAG definition, design, implementation, evaluation,
    and evolution. To kick things off, this chapter begins by highlighting the limitations
    of LLMs and the need for an approach such as RAG. It then introduces the concept
    of RAG and builds toward a definition. The chapter ends by listing the popular
    use cases enabled by RAG.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在揭示RAG及其应用的概念。章节逐一介绍RAG的定义、设计、实现、评估和演变。为了开篇，本章首先强调了LLMs的局限性以及需要像RAG这样的方法。然后介绍了RAG的概念，并逐步构建定义。本章最后列出了RAG带来的流行用例。
- en: By the end of this chapter, you will gain foundational knowledge to be ready
    for a deeper exploration of the RAG system components. In addition, you should
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将获得对RAG系统组件进行更深入探索的基础知识。此外，你还应该
- en: Have a strong hold on the RAG definition.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对RAG的定义要有深刻的理解。
- en: Understand the limitations of LLMs and the need for RAG.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解LLMs的局限性和对RAG的需求。
- en: Be ready to dive into the components of a RAG system.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备深入了解RAG系统的组成部分。
- en: November 30, 2022, will be remembered as a watershed moment in the field of
    artificial intelligence. This was the day OpenAI released ChatGPT, and the world
    became mesmerized by it. ChatGPT turned out to be the fastest app ever to reach
    a million users. Interest in previously obscure terms such as generative AI and
    LLMs skyrocketed over the following 12 months (see figure 1.1).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年11月30日将被铭记为人工智能领域的一个分水岭时刻。这是OpenAI发布ChatGPT的那一天，全世界都被它迷住了。ChatGPT成为有史以来最快达到百万用户的APP。在接下来的12个月里，对之前鲜为人知的术语如生成AI和LLMs的兴趣急剧上升（见图1.1）。
- en: '![A graph with a line and orange dots'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![包含线条和橙色点的图形](../Images/CH01_F01_Kimothi.png)'
- en: AI-generated content may be incorrect.](../Images/CH01_F01_Kimothi.png)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。(图片来源：[trends.google.com](https://trends.google.com/trends/))
- en: 'Figure 1.1  Google trends of “Generative AI” and “Large Language Models” from
    November 2022 to November 2024\. Source: Created by the author using data from
    [trends.google.com](https://trends.google.com/trends/).'
  id: totrans-14
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.1  “生成AI”和“大型语言模型”的Google趋势图，时间范围从2022年11月到2024年11月。来源：作者根据[trends.google.com](https://trends.google.com/trends/)的数据创建。
- en: As the use of platforms such as ChatGPT exploded, the weaknesses of LLMs were
    exposed.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着ChatGPT等平台的使用激增，LLMs的弱点被暴露出来。
- en: 1.1 Curse of the LLMs and the idea of RAG
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 LLMs的诅咒和RAG的概念
- en: LLMs such as those powering ChatGPT, Ask Gemini, and similar have been shown
    to store knowledge. You can ask them questions, and they tend to respond with
    answers that seem correct. However, despite their unprecedented ability to generate
    text, their responses are not always accurate. Upon more careful observation,
    you may notice that LLM responses are plagued with suboptimal information and
    inherent memory limitations.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动ChatGPT、Ask Gemini和类似应用的LLMs已被证明可以存储知识。你可以向它们提问，它们往往会以看似正确的答案回应。然而，尽管它们在生成文本方面具有前所未有的能力，但它们的回答并不总是准确的。经过更仔细的观察，你可能会注意到LLMs的回应受到次优信息和固有的记忆限制的困扰。
- en: To understand the limitations, we will use a simple example. Those familiar
    with the wonderful sport of cricket will recall that the Men’s ODI Cricket World
    Cup tournament was held in 2023\. The Australian cricket team emerged as the winner.
    Now, imagine you are interacting with ChatGPT, and you ask, *“*Who won the 2023
    Cricket World Cup*?”* You are, in truth, interacting with GPT-4o, or o1, LLMs
    developed and maintained by OpenAI that power ChatGPT. In the first few sections
    of this chapter, we will use the terms ChatGPT and LLMs interchangeably for simplicity*.*
    So, you ask the question and, most likely, you will get a response as the one
    in figure 1.2.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解局限性，我们将使用一个简单的例子。那些熟悉这项美妙运动板球的人会记得，2023年男子ODI板球世界杯锦标赛在2023年举行。澳大利亚板球队获得了冠军。现在，想象你正在与ChatGPT互动，你问，“*谁赢得了2023年板球世界杯*？”实际上，你是在与GPT-4o或o1
    LLM互动，这是OpenAI开发和维护的，为ChatGPT提供动力。在本章的前几节中，为了简单起见，我们将交替使用ChatGPT和LLMs这两个术语。所以，你提出问题，很可能会得到如图1.2所示的回答。
- en: '![A screenshot of a computer'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![A screenshot of a computer'
- en: AI-generated content may be incorrect.](../Images/CH01_F02_Kimothi.png)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: AI-generated content may be incorrect.](../Images/CH01_F02_Kimothi.png)
- en: 'Figure 1.2  ChatGPT (GPT 3.5) response to the question, “Who won the 2023 Cricket
    World Cup?” Source: Screenshot of the author’s account on [https://chat.openai.com](https://chat.openai.com).'
  id: totrans-21
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '图1.2  ChatGPT (GPT 3.5) response to the question, “Who won the 2023 Cricket
    World Cup?” Source: Screenshot of the author’s account on [https://chat.openai.com](https://chat.openai.com).'
- en: ChatGPT does not have any memory of the 2023 Cricket World Cup, and it tells
    you to check the information from other sources. This is not ideal, but at least
    ChatGPT is honest in its response. The same question asked again might also provide
    a factually inaccurate result. Look at the response in figure 1.3\. ChatGPT falsely
    responds that India was the winner of the tournament.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT does not have any memory of the 2023 Cricket World Cup, and it tells
    you to check the information from other sources. This is not ideal, but at least
    ChatGPT is honest in its response. The same question asked again might also provide
    a factually inaccurate result. Look at the response in figure 1.3\. ChatGPT falsely
    responds that India was the winner of the tournament.
- en: '![A screenshot of a computer'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![A screenshot of a computer'
- en: AI-generated content may be incorrect.](../Images/CH01_F03_Kimothi.png)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: AI-generated content may be incorrect.](../Images/CH01_F03_Kimothi.png)
- en: 'Figure 1.3  An example of hallucination. ChatGPT’s (GPT 3.5) inaccurate response
    to the question, “Who won the 2023 cricket World Cup?” Source: Screenshot of the
    author’s account on [https://chat.openai.com](https://chat.openai.com).'
  id: totrans-25
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '图1.3  An example of hallucination. ChatGPT’s (GPT 3.5) inaccurate response
    to the question, “Who won the 2023 cricket World Cup?” Source: Screenshot of the
    author’s account on [https://chat.openai.com](https://chat.openai.com).'
- en: This is problematic. Despite not having any memory of the 2023 Cricket World
    Cup, ChatGPT still generates the answer in a seemingly confident tone, but it
    does so inaccurately. This is what is called a “hallucination,” and it has become
    a major point of criticism for LLMs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是有问题的。尽管ChatGPT没有关于2023年板球世界杯的记忆，但它仍然以一种看似自信的语气生成答案，但这是不准确的。这被称为“幻觉”，并且已经成为LLMs的主要批评点。
- en: NOTE In September 2023, ChatGPT’s “Browse with Bing” feature was introduced,
    which allows ChatGPT Plus users to fetch live information from the web for more
    accurate and up-to-date responses. This is a feature of the application, which
    is enabled via agentic search and retrieval mechanisms. The underlying LLM doesn’t
    inherently have the latest information.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：在2023年9月，ChatGPT的“使用Bing浏览”功能被引入，允许ChatGPT Plus用户从网络获取实时信息，以提供更准确和更新的回答。这是应用程序的一个功能，通过代理搜索和检索机制启用。底层LLM本身并不具有最新的信息。
- en: Many users treat LLMs as a source of information as an alternative to Google
    Search. In our example, we also expected ChatGPT (GPT 3.5 model) to know the answer
    to the simple question. Why does an LLM fail to meet this expectation?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 许多用户将LLM视为信息来源，作为Google Search的替代品。在我们的例子中，我们也期待ChatGPT（GPT 3.5模型）能回答这个简单的问题。为什么LLM无法满足这一期望？
- en: 1.1.1 LLMs are not trained for facts
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 LLMs are not trained for facts
- en: Generally, LLMs can be thought of as a next-token (loosely, next word) prediction
    model. They are machine learning models that have learned from massive datasets
    of human-generated text, finding statistical patterns to replicate human-like
    language abilities.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，LLMs可以被视为一种下一个标记（大致上，下一个单词）预测模型。它们是学习了大量人类生成文本数据集的机器学习模型，寻找统计模式以复制类似人类的语言能力。
- en: To simplify, think of the model first being shown a sentence such as “The teacher
    teaches the student.” Then, we hide the last few words of this sentence (i.e.,
    “teaches the student”) and ask the model what the next word should be. The model
    should learn to predict “teaches” as the next word, “the” as the word after that,
    and so on. There are various methods of teaching the model, including causal language
    modeling (CLM) and masked language modeling (MLM). Figure 1.4 shows the idea behind
    these two techniques.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，首先想象模型被展示了一个句子，例如“老师教学生。”然后，我们隐藏这个句子的最后几个词（即，“教学生”），并询问模型下一个词应该是什么。模型应该学会预测下一个词是“教”，然后是“the”，以此类推。有各种方法来教授模型，包括因果语言模型（CLM）和掩码语言模型（MLM）。图1.4展示了这两种技术背后的理念。
- en: The training data can have billions of sentences of different kinds. The next
    token (or word) is chosen from a probability distribution observed in the training
    data. There are different means and methods to choose the next token from the
    ones for which a probability has been calculated. Crudely, you can assume that
    a probability is calculated for all the words in the vocabulary, and one among
    the high-probability words is selected. Figure 1.5 shows the probability distribution
    for our example, “The teacher ____ .” The word “teaches” is selected because it
    has the highest probability. Other words could also have been selected.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据可以包含数十亿种不同类型的句子。下一个标记（或词）是从训练数据中观察到的概率分布中选择。有不同方法和手段从已经计算过概率的标记中选择下一个标记。粗略地说，你可以假设词汇表中的所有词都计算了概率，并从中选择了一个高概率的词。图1.5展示了我们例子“老师____”的概率分布。选择“teaches”这个词是因为它的概率最高。其他词也可能被选中。
- en: In this case, the model is just trying to predict a word in sequence. It is
    almost magical how LLMs can store knowledge from the data they have been trained
    on and present that knowledge (in most cases) in a coherent and understandable
    language. This ability is possible thanks to a neural network architecture based
    on an attention mechanism known as “transformers.” The nuances of transformers’
    architecture and building LLMs from scratch offer a wide area of study. It is
    out of the scope of this book, but you’re encouraged to find out more about LLM
    training and transformers.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，模型只是在尝试按顺序预测一个词。LLMs如何能够从它们训练的数据中存储知识，并以连贯和可理解的语言呈现这些知识（在大多数情况下）几乎是一种魔法。这种能力得益于一种基于称为“transformers”的注意力机制的神经网络架构。transformers架构的细微差别以及从头开始构建LLMs是一个广泛的研究领域。这超出了本书的范围，但鼓励你了解更多关于LLM训练和transformers的信息。
- en: Returning to the limitations of LLMs, their training process introduces three
    major characteristic drawbacks.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到LLMs的局限性，它们的训练过程引入了三个主要的特点缺点。
- en: '![](../Images/CH01_F04_Kimothi.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F04_Kimothi.png)'
- en: 'Figure 1.4  Two token prediction techniques: CLM and MLM. In the CLM approach,
    the model predicts the next token based on the preceding tokens. In MLM, the model
    predicts the masked token based on both the preceding and the succeeding tokens.'
  id: totrans-36
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.4 两种标记预测技术：CLM和MLM。在CLM方法中，模型根据前面的标记预测下一个标记。在MLM中，模型根据前面的和后面的标记预测掩码标记。
- en: '![](../Images/CH01_F05_Kimothi.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F05_Kimothi.png)'
- en: Figure 1.5  Illustrative probability distribution of words after “The teacher”
  id: totrans-38
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.5  “老师”之后的词语概率分布示意图
- en: Knowledge cut-off date
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 知识截止日期
- en: Training an LLM is an expensive and time-consuming process. It takes massive
    volumes of data and several weeks, or even months, to train an LLM. The data that
    LLMs are trained on is, therefore, not always up to date. For instance, OpenAI’s
    flagship model, GPT-4.1, released in April 2025, has knowledge only until June
    1, 2024\. Any event that happened after this knowledge cut-off date is not available
    to the model.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 训练一个LLM是一个昂贵且耗时的过程。训练一个LLM需要大量的数据，可能需要几周甚至几个月。因此，LLMs训练的数据并不总是最新的。例如，OpenAI的旗舰模型GPT-4.1，于2025年4月发布，其知识只到2024年6月1日。在此知识截止日期之后发生的事件对模型是不可用的。
- en: Hallucinations
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 幻觉
- en: It is observed that LLMs sometimes provide factually incorrect responses. (We
    saw this in the 2023 Cricket World Cup example at the beginning of this chapter.)
    Despite being factually incorrect, the LLM responses sound extremely confident
    and legitimate. This characteristic of “lying with confidence,” called hallucinations,
    has proved to be one of the biggest criticisms of LLMs. The reason for hallucinations
    can be traced back to LLMs being a next-token prediction model that selects the
    most probable word from a distribution.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 观察发现，大型语言模型（LLM）有时会提供事实错误的信息。（我们可以在本章开头提到的2023年板球世界杯的例子中看到这一点。）尽管这些信息在事实上是错误的，但LLM的回答听起来却非常自信且合法。这种被称为“自信地撒谎”的特征，即幻觉，已被证明是LLM最大的批评之一。幻觉的原因可以追溯到LLM作为一个下一标记预测模型，它会从分布中选择最可能的单词。
- en: Knowledge limitation
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 知识限制
- en: As you have already seen, LLMs have been trained on large volumes of data obtained
    from a variety of sources, including the open internet. However, they do not have
    any knowledge of information that is not public. The LLMs have not been trained
    on information such as internal company documents, customer information, product
    documents, confidential personnel information, and so forth. Therefore, LLMs cannot
    be expected to respond to any query about them.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您已经看到的，LLM已经在来自各种来源的大量数据上进行了训练，包括开放的互联网。然而，它们对非公开信息一无所知。LLM没有在内部公司文件、客户信息、产品文档、机密人员信息等方面的信息上进行过训练。因此，不能期望LLM对任何关于它们的问题做出回应。
- en: This characteristic raises significant questions about the general adoption
    and value of this technology. But if these limitations are inherent to the nature
    of LLMs and their training process, does this mean the LLM is not usable as a
    technology?
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这种特征引发了关于这项技术普遍采用和价值的重要问题。但如果这些限制是LLM本质及其训练过程固有的，那么这是否意味着LLM作为技术不可用？
- en: Not at all! Let’s now go ahead and understand how an approach such as RAG comes
    to the rescue.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 完全不是！现在让我们继续了解像RAG这样的方法是如何解决问题的。
- en: 1.1.2 What is RAG?
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.2 什么是RAG？
- en: 'Recall the question we used to begin this discussion: “Who won the 2023 Cricket
    World Cup?” What can be done to improve the response?'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下我们用来开始这次讨论的问题：“2023年板球世界杯的获胜者是谁？”我们能做些什么来改善这个回答？
- en: Even if ChatGPT doesn’t have this information, the world (aka the internet)
    knows about the 2023 Cricket World Cup with no uncertainty. A simple Google Search
    will tell you about the winner of the 2023 Cricket World Cup if you don’t already
    know it. The Wikipedia article (figure 1.6) on the 2023 Cricket World Cup accurately
    provides this information in the opening section itself. If only there were a
    way to tell the LLM about this Wikipedia article.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 即使ChatGPT没有这个信息，世界（即互联网）对2023年板球世界杯的信息没有不确定性。如果你不知道，简单的谷歌搜索就会告诉你2023年板球世界杯的获胜者。关于2023年板球世界杯的维基百科文章（图1.6）在开头部分就准确提供了这些信息。如果有一种方法可以告诉LLM关于这篇文章的维基百科信息。
- en: How can we give this information to ChatGPT, you ask? The answer is quite simple.
    We just paste this piece of text with our question (see figure 1.7).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，我们如何将这个信息给ChatGPT？答案是相当简单的。我们只需将这段文本连同我们的问题一起粘贴（见图1.7）。
- en: And there it is! ChatGPT has now responded with the correct answer. It was able
    to comprehend the piece of additional information we provided, distill the information
    about the winner of the tournament, and respond with a precise and factually accurate
    answer.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！ChatGPT现在给出了正确的答案。它能够理解我们提供的额外信息，提炼关于锦标赛获胜者的信息，并给出精确且事实准确性的回答。
- en: It may appear juvenile, but in an oversimplified manner, this example illustrates
    the basic concept of RAG. Let’s look back at what we did here. We understood that
    the question is about the winner of the 2023 Cricket World Cup. We searched for
    information about the question and identified Wikipedia as a source of information.
    We then copied that information and passed it onto ChatGPT (and the LLM powering
    it) along with the original question. In a way, we added to ChatGPT’s knowledge.
    As a technique,
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子可能看起来很幼稚，但以过于简化的方式，它说明了RAG的基本概念。让我们回顾一下我们在这里做了什么。我们理解这个问题是关于2023年板球世界杯的获胜者。我们搜索了关于这个问题的信息，并确定了维基百科作为信息来源。然后我们复制了这些信息，并将其与原始问题一起传递给了ChatGPT（以及它背后的LLM）。从某种意义上说，我们增加了ChatGPT的知识。作为一种技术，
- en: '![A screenshot of a web page'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![网页截图'
- en: AI-generated content may be incorrect.](../Images/CH01_F06_Kimothi.png)
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能生成的内容可能是错误的。](../Images/CH01_F06_Kimothi.png)
- en: 'Figure 1.6  Wikipedia article on 2023 Cricket World Cup. Source: [https://mng.bz/yN4J](https://mng.bz/yN4J).'
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.6 2023 年板球世界杯的维基百科文章。来源：[https://mng.bz/yN4J](https://mng.bz/yN4J)。
- en: '![A screenshot of a chat'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![聊天截图'
- en: AI-generated content may be incorrect.](../Images/CH01_F07_Kimothi.png)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能生成的内容可能是错误的。](../Images/CH01_F07_Kimothi.png)
- en: 'Figure 1.7  ChatGPT (GPT 3.5) response to the question, augmented with external
    context. Source: Screenshot of the author’s account on [https://chat.openai.com](https://chat.openai.com).'
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.7  ChatGPT（GPT 3.5）对问题的响应，增加了外部上下文。来源：作者在 [https://chat.openai.com](https://chat.openai.com)
    的账户截图）。
- en: RAG does the same thing programmatically. It overcomes the limitations of LLMs
    by providing them with previously unknown information and, consequently, enhances
    the overall memory of the system.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 以编程方式做同样的事情。它通过提供先前未知的信息来克服 LLM 的局限性，从而增强系统的整体记忆。
- en: 'As the name implies, “retrieval augmented generation” can be explained through
    three steps:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名所示，“检索增强生成”（RAG）可以通过以下三个步骤来解释：
- en: It *retrieves* relevant information from a data source external to the LLMs
    (Wikipedia, in our example).
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它从 LLM 外部的数据源（在我们的例子中是维基百科）**检索**相关信息。
- en: It *augments* the input to the LLM with that external information.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它通过添加外部信息来**增强**LLM 的输入。
- en: Finally, the LLM *generates*a more accurate result.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，LLM 生成的结果更加准确。
- en: 'A simple definition for RAG, illustrated in figure 1.8, can therefore be as
    follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 的简单定义，如图 1.8 所示，可以如下所示：
- en: Retrieval Augmented Generation is the technique of retrieving relevant information
    from an external source, augmenting the input to the LLM with that external information,
    thereby enabling the LLM to generate a response that is contextual, reliable,
    and factually accurate.
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 检索增强生成是从外部来源检索相关信息的技术，通过将外部信息添加到 LLM 的输入中，从而使得 LLM 能够生成一个上下文相关、可靠且事实准确的反应。
- en: '![A diagram of a data flow'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![数据流图'
- en: AI-generated content may be incorrect.](../Images/CH01_F08_Kimothi.png)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能生成的内容可能是错误的。](../Images/CH01_F08_Kimothi.png)
- en: 'Figure 1.8  RAG (a simple definition): retrieval of information, augmentation
    with the query, and the generation using an LLM form the three RAG focal points'
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.8  RAG（简单定义）：信息检索、查询增强以及使用 LLM 生成形成 RAG 的三个焦点
- en: The example that we have been looking at so far is oversimplified. We manually
    searched for the external information, and the search was for this one specific
    question only. In practice, all these processes are automated, which allows the
    system to scale up to a diverse range of queries and data sources. We will now
    unravel this idea further.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止所看到的例子过于简化。我们手动搜索外部信息，而且搜索仅针对这个问题。在实践中，所有这些过程都是自动化的，这使得系统可以扩展到各种查询和数据源。我们现在将进一步阐述这个想法。
- en: 1.2 The novelty of RAG
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 RAG 的新颖性
- en: 'The main idea is to provide additional context or knowledge to the LLMs. Essentially,
    it meant creating a ChatGPT-like system with three main objectives:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 主要思想是为 LLM 提供额外的上下文或知识。本质上，这意味着创建一个具有三个主要目标的 ChatGPT 类似系统：
- en: Make LLMs respond with up-to-date information.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使 LLM 能够响应最新信息。
- en: Make LLMs respond with factually accurate information.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使大型语言模型（LLM）能够响应事实准确的信息。
- en: Make LLMs aware of proprietary information.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使 LLM 了解专有信息。
- en: These objectives can be achieved using diverse techniques. A new LLM can be
    trained from scratch that includes the new data. An existing model can also be
    fine-tuned with additional data. However, both approaches require a significant
    amount of data and computational resources. Furthermore, updating the model with
    new information at regular intervals is prohibitively costly.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用不同的技术来实现这些目标。可以从头开始训练一个新的 LLM，其中包括新的数据。也可以使用额外的数据对现有模型进行微调。然而，这两种方法都需要大量的数据和计算资源。此外，定期用新信息更新模型成本高昂。
- en: RAG is a cheaper, more effective, and more dynamic technique used to attain
    the three objectives. LLMs respond with information that is up-to-date and factually
    accurate, and they are aware of proprietary information, so they have no knowledge
    gaps.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 是一种更便宜、更有效、更动态的技术，用于实现三个目标。LLM 以最新和事实准确的信息响应，并且它们了解专有信息，因此没有知识空白。
- en: 1.2.1 The RAG discovery
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 RAG 的发现
- en: In a paper titled “Retrieval-Augmented Generation for Knowledge-Intensive NLP
    Tasks” ([https://arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)),
    Patrick Lewis and his coauthors explored the recipe for RAG models, which combine
    pretrained “parametric” and “non-parametric” memory for language generation. Let’s
    pay some attention to the terms “parametric” and “non-parametric.”
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在一篇题为“用于知识密集型NLP任务的检索增强生成”（[https://arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)）的论文中，帕特里克·刘易斯和他的合著者探讨了RAG模型的配方，这些模型结合了用于语言生成的预训练“参数”和“非参数”记忆。让我们关注一下“参数”和“非参数”这两个术语。
- en: Parameters in machine learning parlance refer to the model weights or variables
    that the model learns during the training process. In simple terms, they are settings
    or configurations that the model adjusts to perform the assigned task. For language
    generation, LLMs are trained with billions of parameters (the GPT 4 model is rumored
    to have over 1 trillion parameters, and the largest Llama 3 model has 405 billion
    parameters). The ability of an LLM to retain information it has been trained on
    is based solely on its parameters. It can therefore be said that LLMs store factual
    information in their parameters. An LLM’s internal memory is referred to as “parametric
    memory.” The parametric memory is limited. It depends on the number of parameters
    and is a factor of the data on which the LLM has been trained.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的术语中，参数指的是模型在训练过程中学习的模型权重或变量。简单来说，它们是模型调整以执行分配任务的设置或配置。对于语言生成，大型语言模型（LLMs）经过数十亿参数的训练（据传闻GPT
    4模型拥有超过1000亿参数，最大的Llama 3模型有4050亿参数）。LLM保留其训练信息的能力完全基于其参数。因此，可以说LLMs在其参数中存储了事实信息。LLM的内部记忆被称为“参数记忆”。参数记忆是有限的，它取决于参数的数量，并且是LLM所训练数据的一个因素。
- en: Conversely, we can provide information to an LLM that it does not have in its
    parametric memory. We saw in the example of the Cricket World Cup that when we
    provided information from an external source to ChatGPT, it was able to get rid
    of the hallucination. This information that is external to the LLM but can be
    provided to the LLM is termed “non-parametric.” If we can gather information from
    external sources as and when desired and use it with the LLM, it forms the “non-parametric”
    memory of the system. In the aforementioned paper, Lewis and his coauthors stored
    Wikipedia data and used a retriever to access the information. They demonstrated
    that this RAG approach outperformed the parametric-only baseline in generating
    more specific, diverse, and factual language. We will discuss vector databases
    and retrievers in chapters 3 and 4.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可以向LLM提供其参数记忆中不存在的信息。在板球世界杯的例子中，我们看到当我们向ChatGPT提供外部来源的信息时，它能够摆脱幻觉。这种对LLM来说是外部信息但可以提供给LLM的信息被称为“非参数”。如果我们能够根据需要从外部来源收集信息并将其与LLM一起使用，它就形成了系统的“非参数”记忆。在上述论文中，刘易斯和他的合著者存储了维基百科数据，并使用检索器访问信息。他们证明了这种RAG方法在生成更具体、多样和事实性的语言方面优于仅参数的基线。我们将在第三章和第四章中讨论向量数据库和检索器。
- en: In 2025, RAG became one of the most used techniques in the LLM domain. With
    the addition of a non-parametric memory, the LLM responses are more grounded and
    factual. Let’s discuss the advantages of RAG.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 到2025年，RAG已成为LLM领域最常用的技术之一。随着非参数记忆的加入，LLM的回答更加贴近事实。让我们讨论RAG的优势。
- en: 1.2.2 How does RAG help?
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 RAG如何帮助？
- en: With the introduction of non-parametric memory, the LLM does not remain limited
    to its internal knowledge. We can conclude, at least theoretically, that this
    non-parametric memory can be extended as much as we want. It can store any volume
    of proprietary documents or data and access all sorts of sources, such as the
    intranet and the open internet. In a way, through RAG, we open up the possibility
    of embellishing the LLM with unlimited knowledge. There will always be some effort
    required to create this non-parametric memory or the knowledge base, and we will
    look at it in detail later. Chapter 3 is dedicated to the creation of the non-parametric
    knowledge base.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 随着非参数记忆的引入，LLM不再局限于其内部知识。至少从理论上讲，我们可以得出结论，这种非参数记忆可以扩展到我们想要的程度。它可以存储任何数量的专有文档或数据，并访问各种来源，如内网和公开互联网。从某种意义上说，通过RAG，我们打开了将无限知识添加到LLM的可能性。创建这种非参数记忆或知识库总需要一些努力，我们将在稍后详细探讨。第三章专门讨论非参数知识库的创建。
- en: 'As a consequence of overcoming the challenge of limited parametric memory,
    RAG also builds user confidence in the LLM responses. The three advantages of
    RAG are as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于克服了参数化内存有限的挑战，RAG 还增强了用户对 LLM 响应的信心。RAG 的三个优点如下：
- en: '*Deep contextual awarenes**s*—The added information assists the LLM in generating
    contextually appropriate responses, and the users can be relatively more confident.
    For example, if the non-parametric memory contains information about a particular
    company’s products, users can be assured that the LLM will generate responses
    about those products from the provided sources and not from elsewhere.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深度上下文意识*—添加的信息有助于 LLM 生成上下文适当的响应，用户可以相对更有信心。例如，如果非参数化内存包含有关特定公司产品的信息，用户可以确信
    LLM 将从提供的来源生成有关这些产品的响应，而不是从其他地方。'
- en: '*Source citatio**n*—In addition to being context aware, because the information
    is being fetched from a known source, these sources can be cited in the response.
    This makes the responses more reliable since the users have the choice of validating
    the information from the source.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*来源引用*—除了上下文意识外，由于信息是从已知来源检索的，这些来源可以在响应中引用。这使得响应更加可靠，因为用户可以选择从来源验证信息。'
- en: '*Lesser hallucinatio**n*—With contextual awareness, the tendency of LLM responses
    to be factually inaccurate is greatly reduced. The LLMs hallucinate less in RAG
    systems.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*较少的幻觉*—通过上下文意识，LLM 响应中出现事实不准确性的倾向大大减少。在 RAG 系统中，LLM 的幻觉更少。'
- en: 'We have already seen a simple RAG definition. Let’s now expand that definition:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了一个简单的 RAG 定义。现在让我们扩展这个定义：
- en: Retrieval Augmented Generation is the methodological approach of enhancing the
    parametric memory of an LLM by creating access to an explicit non-parametric memory,
    from which a retriever can fetch relevant information, augment that information
    to the prompt, pass the prompt to an LLM to enable the LLM to generate a response
    that is contextual, reliable, and factually accurate.
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 生成式检索增强是通过对显式非参数化内存的访问来增强 LLM 参数化内存的方法论方法，检索器可以从其中检索相关信息，将信息增强到提示中，然后将提示传递给
    LLM，以使 LLM 能够生成上下文相关、可靠且事实准确的响应。
- en: This definition is illustrated in figure 1.9.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定义在图 1.9 中得到了说明。
- en: RAG has acted as a catalyst in the propagation and acceptance of LLM-powered
    applications. Before concluding this chapter and getting into the design of RAG
    systems, let’s look at some popular use cases where RAG is being adopted.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 在 LLM 驱动的应用的传播和接受中起到了催化剂的作用。在结束本章并进入 RAG 系统的设计之前，让我们看看一些 RAG 被采用的流行用例。
- en: '![A diagram of a computer process'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![计算机处理流程图](../Images/CH01_F09_Kimothi.png)'
- en: AI-generated content may be incorrect.](../Images/CH01_F09_Kimothi.png)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能生成的内容可能是错误的。
- en: Figure 1.9  RAG enhances the parametric memory of an LLM by creating access
    to non-parametric memory.
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.9  RAG 通过创建对非参数化内存的访问来增强 LLM 的参数化内存。
- en: 1.3 Popular RAG use cases
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 流行的 RAG 应用场景
- en: RAG is not just a theoretical concept but a technique that is as popular as
    the LLM technology itself. Software developers started using language models as
    soon as Google released BERT in 2018\. Today, there are thousands of applications
    that use LLMs to solve language-intensive tasks. Whenever you come across an application
    using LLMs, it will often have an internal RAG system in some shape or form. Common
    applications are described in the following sections.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 不仅仅是一个理论概念，它是一种与 LLM 技术本身一样流行的技术。软件开发商自 2018 年 Google 发布 BERT 以来就开始使用语言模型。如今，有成千上万的应用程序使用
    LLM 来解决语言密集型任务。每当您遇到使用 LLM 的应用程序时，它通常会在某种形式下拥有一个内部 RAG 系统。常见应用将在以下章节中描述。
- en: 1.3.1 Search Engine Experience
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 搜索引擎体验
- en: Conventional search results are shown as a list of page links ordered by relevance.
    Modern search engines integrate RAG to combine live information retrieval with
    generative answers. Google’s Search Generative Experience (SGE) augments queries
    with relevant results and citations. AI-based search engines such as Perplexity.ai
    and ChatGPT’s search are built on a RAG framework that fetches up-to-date web
    information and then generates responses with sources attached. By grounding answers
    in real-time results, these search engines provide more accurate, source-backed
    answers than standalone LLMs.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 传统搜索结果以按相关性排序的页面链接列表形式显示。现代搜索引擎整合RAG，将实时信息检索与生成式答案相结合。谷歌的搜索生成体验（SGE）通过相关结果和引文增强查询。基于AI的搜索引擎，如Perplexity.ai和ChatGPT的搜索，建立在RAG框架之上，该框架检索最新的网络信息，然后生成带有来源的响应。通过将答案建立在实时结果之上，这些搜索引擎提供了比独立LLM更准确、有来源支持的答案。
- en: 1.3.2 Personalized marketing content generation
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.2 个性化营销内容生成
- en: The widest use of LLMs has probably been in content generation. Content creation
    tools employ RAG to tailor marketing copy using current data and user-specific
    context. Yarnit, for instance, uses RAG to generate marketing copy, blog posts,
    and other content types based on up-to-the-moment information and user inputs.
    Yarnit can pull in fresh facts or trending material while drafting the text, ensuring
    the output is relevant and factual. By pulling in the right information (e.g.,
    a brand’s style guide or latest stats) at generation time, these platforms produce
    personalized, on-brand marketing content that resonates with audiences.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最广泛的应用LLM可能是内容生成。内容创作工具使用RAG来根据当前数据和用户特定上下文定制营销文案。例如，Yarnit使用RAG根据最新信息和用户输入生成营销文案、博客文章和其他内容类型。在撰写文本的同时，Yarnit可以引入新鲜事实或趋势材料，确保输出内容的相关性和事实性。通过在生成时引入正确的信息（例如，品牌风格指南或最新统计数据），这些平台能够产生与受众产生共鸣的个性化、品牌化的营销内容。
- en: 1.3.3 Real-time event commentary
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.3 实时事件解说
- en: Imagine an event such as a sport or a news event. A retriever can connect to
    real-time updates/data via APIs and pass this information to the LLM to create
    a virtual commentator. These can further be augmented with text-to-speech models.
    A prime example is IBM’s Watson AI at the US Open—it generates audio and text
    tennis commentary by pulling in live match data and even thousands of news articles
    for context. This RAG approach allowed Watson to mention player stats, head-to-head
    records, and match highlights as it narrated, creating fact-driven commentary
    on the fly. In financial markets, vendors are doing something similar—Bloomberg’s
    AI-driven tools use RAG to ground their insights in up-to-date proprietary data.
    Bloomberg’s platforms explicitly employ a RAG framework so that any generative
    output (market summaries, answers to trader queries, etc.) is based on recent,
    authoritative content rather than the model’s memory alone.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个体育赛事或新闻事件。检索器可以通过API连接到实时更新/数据，并将这些信息传递给LLM以创建虚拟解说员。这些还可以通过文本到语音模型进行增强。一个典型的例子是IBM的Watson
    AI在美网上的应用——它通过引入实时比赛数据和数千篇新闻文章来生成音频和文本形式的网球解说。这种RAG方法允许Watson在叙述时提及球员统计数据、交锋记录和比赛亮点，从而即时创建基于事实的解说。在金融市场，供应商正在做类似的事情——彭博社的AI驱动工具使用RAG将他们的洞察建立在最新的专有数据上。彭博社的平台明确采用RAG框架，以确保任何生成式输出（市场摘要、交易员查询的答案等）都是基于最新的权威内容，而不是仅仅基于模型的记忆。
- en: 1.3.4 Conversational agents
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.4 对话式代理
- en: LLMs can be customized to product/service manuals, domain knowledge, guidelines,
    and so forth using RAG and serve as support agents, resolving user complaints
    and problems. These agents can also route users to more specialized agents, depending
    on the nature of the query. Almost all LLM-based chatbots on websites or as internal
    tools use RAG. Intercom’s Fin AI agent is a notable example—it was specifically
    designed with a “bespoke and enhanced” RAG architecture to generate answers from
    a company’s support content. Support platforms such as Zendesk follow a similar
    pattern by retrieving help-center articles to answer customer queries. Industry
    observers note that these companies use basic RAG to quickly fetch relevant support
    docs and generate customized responses from them.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RAG，LLM可以被定制为产品/服务手册、领域知识、指南等，并可作为支持代理，解决用户投诉和问题。这些代理还可以根据查询的性质将用户路由到更专业的代理。几乎所有的基于LLM的网站或内部工具的聊天机器人都使用了RAG。Intercom的Fin
    AI代理是一个值得注意的例子——它被特别设计为具有“定制和增强”的RAG架构，可以从公司的支持内容中生成答案。像Zendesk这样的支持平台通过检索帮助中心文章来回答客户查询，遵循类似的模式。行业观察家指出，这些公司使用基本的RAG快速检索相关的支持文档，并从中生成定制的响应。
- en: 1.3.5 Document question answering systems
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.5 文档问答系统
- en: As discussed, one of the LLMs’ limitations is that they don’t have access to
    proprietary nonpublic information such as product documents, customer profiles,
    and similar information specific to an organization. With access to such proprietary
    documents, a RAG system becomes an intelligent AI system that can answer all questions
    about the organization. In the legal domain, for example, researchers have highlighted
    that domain-specific RAG enables far more nuanced and trustworthy answers in tools
    for legal research. A legal Q&A system can retrieve relevant case law or statutes
    and feed those into an LLM to answer a question, ensuring the answer cites the
    correct precedent. This technique was at the heart of products such as ROSS Intelligence,
    which aimed to answer lawyers’ queries by retrieving passages from law databases
    and then generating an answer. More generally, enterprise knowledge management
    is being transformed by RAG—instead of relying on an LLM’s limited training data,
    companies can equip AI assistants to search internal documents, wikis, or manuals
    on the fly.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，LLM（大型语言模型）的一个局限性是它们无法访问专有非公开信息，例如产品文档、客户档案以及特定于组织的类似信息。一旦能够访问这些专有文档，RAG（检索增强生成）系统就变成了一种智能AI系统，能够回答有关组织的所有问题。例如，在法律领域，研究人员强调，特定领域的RAG能够使法律研究工具提供更加细致和可靠的答案。一个法律问答系统可以检索相关案例法或法规，并将这些内容输入到LLM中回答问题，确保答案引用了正确的先例。这种技术是诸如ROSS
    Intelligence等产品核心，旨在通过从法律数据库中检索段落来回答律师的查询，然后生成答案。更普遍地，企业知识管理正在被RAG所改变——公司不再依赖于LLM有限的训练数据，而是可以配备AI助手即时搜索内部文档、维基或手册。
- en: 1.3.6 Virtual assistants
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.6 虚拟助手
- en: Virtual personal assistants such as Siri, Alexa, and others are beginning to
    use LLMs to enhance the user’s experience. Coupled with more context on user behavior
    using RAG, these assistants are set to become more personalized. Amazon’s next-generation
    Alexa, for instance, incorporates retrieval techniques, so it can answer with
    information beyond its core training. By augmenting voice assistant answers with
    retrieved facts, RAG helps virtual assistants such as Alexa and Google Assistant
    give far more accurate and current answers to user queries.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟个人助手，如Siri、Alexa等，开始使用LLM来增强用户体验。结合RAG提供的更多用户行为上下文，这些助手将变得更加个性化。例如，亚马逊下一代Alexa集成了检索技术，因此它能够回答超出其核心训练的信息。通过将检索到的事实添加到语音助手答案中，RAG帮助虚拟助手如Alexa和Google
    Assistant为用户查询提供更加准确和最新的答案。
- en: 1.3.7 AI-powered research
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.7 AI驱动的研发
- en: AI agents have been gaining traction in research-intensive fields such as law
    and finance. RAG has been extensively used to retrieve and analyze case law to
    assist lawyers. A lot of portfolio management companies are introducing RAG systems
    to analyze scores of documents to research investment opportunities. ESGReveal
    is a framework developed by researchers at Alibaba Group that employs RAG to extract
    and evaluate environmental, social, and governance (ESG) data from corporate reports.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能代理在法律和金融等研究密集型领域越来越受欢迎。RAG被广泛用于检索和分析案例法，以协助律师。许多投资组合管理公司正在引入RAG系统，以分析大量文件来研究投资机会。ESGReveal是由阿里巴巴集团的研究人员开发的一个框架，它使用RAG从企业报告中提取和评估环境、社会和治理（ESG）数据。
- en: 1.3.8 Social media monitoring and sentiment analysis
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.8 社交媒体监控和情感分析
- en: Analyzing the firehose of social media data is another task suited to RAG. Social
    listening platforms such as Brandwatch use generative AI to summarize trends and
    sentiments from millions of posts, but they ground those summaries in the underlying
    data. Brandwatch’s system, for example, scans over 100 million sources, and then
    its generative AI integration transforms data into easy-to-understand summaries
    for the user.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 分析社交媒体数据洪流是RAG适用的另一个任务。例如，Brandwatch这样的社交媒体监听平台使用生成式AI从数百万条帖子中总结趋势和情感，但他们将这些总结建立在底层数据之上。Brandwatch的系统扫描超过1亿个来源，然后其生成式AI集成将数据转换为用户易于理解的摘要。
- en: 1.3.9 News generation and content curation
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.9 新闻生成和内容编辑
- en: 'News organizations have been using RAG to automate and assist in news writing,
    while maintaining accuracy. Reuters, for instance, offers a solution to feed its
    trusted news data into generative models so they produce fact-based outputs. By
    using Reuters’ real-time news feeds as the retrieval source, an AI system can
    generate a news summary or answer questions with the latest verified facts. Reuters
    asserts that this approach keeps your answers reliable and accurate with a RAG
    system extracting trusted facts from the latest Reuters stories. The Associated
    Press (AP) has similarly been a pioneer in automating news: AP has used templates
    and data to auto-generate sports recaps and earnings reports for years, and now,
    with generative AI, they are augmenting those systems with LLMs. Thanks to RAG,
    an AI writer can ingest box score data or financial results and then produce a
    readable article, grounding every statement in the provided data.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 新闻机构一直在使用RAG来自动化和协助新闻写作，同时保持准确性。例如，路透社提供了一种解决方案，将受信任的新闻数据输入到生成模型中，以便它们产生基于事实的输出。通过使用路透社的实时新闻源作为检索来源，一个AI系统可以生成新闻摘要或用最新的核实事实来回答问题。路透社声称，这种方法通过RAG系统从最新的路透社故事中提取可信事实，保持了答案的可靠性和准确性。美联社（AP）在自动化新闻方面也是一个先驱：AP多年来一直使用模板和数据来自动生成体育综述和收益报告，现在，随着生成式AI的出现，他们正在用LLMs增强这些系统。多亏了RAG，一个AI作家可以摄取比分数据或财务结果，然后生成一篇可读的文章，将每个陈述都建立在提供的数据之上。
- en: These are only a few select examples. RAG has been extensively used in other
    domains such as customer support automation, financial market insights, healthcare
    diagnostics, legal document drafting, learning systems, and supply chain optimization.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是少数精选示例。RAG在其他领域如客户支持自动化、金融市场洞察、医疗诊断、法律文件起草、学习系统和供应链优化等方面也得到了广泛的应用。
- en: This introductory chapter dealt with the RAG concept. Overcoming the limitations
    of LLMs, RAG addresses these challenges by providing access to a non-parametric
    knowledge base to the system. With this foundational understanding of RAG, in
    the next chapter, we take the first step toward understanding how RAG systems
    are built by looking at the different components of their design.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这章介绍了RAG概念。RAG通过向系统提供非参数化知识库的访问，克服了LLMs（大型语言模型）的限制，从而解决这些挑战。在下一章中，我们基于对RAG的基础理解，通过研究其设计中的不同组件，迈出了理解RAG系统构建的第一步。
- en: Summary
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: RAG enhances the memory of LLMs by providing access to external information.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG通过提供访问外部信息来增强LLMs的记忆能力。
- en: LLMs are next-word (or token) prediction models trained on massive amounts of
    text data to generate human-like text.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs是训练在大量文本数据上以生成类似人类文本的下一词（或标记）预测模型。
- en: LLMs face challenges of having a knowledge cut-off date and being trained only
    on public data. They are also prone to generating factually incorrect information
    (i.e., hallucinating).
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs面临着知识截止日期和仅基于公共数据进行训练的挑战。它们也容易生成事实错误的信息（即，产生幻觉）。
- en: RAG overcomes the LLM limitations by incorporating non-parametric memory and
    increases context awareness and reliability of responses.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG通过整合非参数记忆克服了LLM的限制，并提高了响应的上下文意识和可靠性。
- en: Popular use cases of RAG include search engines, document question-answering
    systems, conversational agents, personalized content generation, virtual assistants,
    and so forth.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG的常见应用场景包括搜索引擎、文档问答系统、对话机器人、个性化内容生成、虚拟助手等等。
