# 第18章。调试

当您将机器学习集成到您的产品中时，无论是嵌入式还是其他方式，您都很可能会遇到一些令人困惑的错误，而且可能会比您想象的要早。在本章中，我们将讨论一些在事情出错时理解发生了什么的方法。

# 训练和部署之间的准确性损失

当您将一个机器学习模型从TensorFlow等创作环境部署到应用程序中时，问题可能会悄然而至。即使您能够构建和运行模型而不报告任何错误，您可能仍然无法获得您期望的准确性结果。这可能会非常令人沮丧，因为神经网络推断步骤似乎是一个黑匣子，没有内部发生的可见性或导致任何问题的原因。

## 预处理差异

在机器学习研究中很少受到关注的一个领域是如何将训练样本转换为神经网络可以操作的形式。如果您尝试对图像进行对象分类，那么这些图像必须转换为张量，即数字的多维数组。您可能会认为这应该很简单，因为图像已经以2D数组的形式存储，通常具有红色、绿色和蓝色值的三个通道。即使在这种情况下，您仍然需要进行一些更改。分类模型期望它们的输入具有特定的宽度和高度，例如宽224像素，高224像素，而相机或其他输入源不太可能以正确的尺寸产生它们。这意味着您需要将捕获的数据重新缩放以匹配。对于训练过程也必须做类似的处理，因为数据集可能是磁盘上一组任意大小的图像。

一个经常出现的微妙问题是，用于部署的重新缩放方法与用于训练模型的方法不匹配。例如，早期版本的[Inception](https://oreil.ly/rGKnL)使用双线性缩放来缩小图像，这让具有图像处理背景的人感到困惑，因为这种方式的缩小会降低图像的视觉质量，通常应该避免。因此，许多开发人员在应用程序中使用这些模型进行推断时，改用了更*正确*的区域采样方法，但事实证明，这实际上降低了结果的准确性！直觉是，训练模型已经学会寻找双线性缩放产生的伪影，而它们的缺失导致了前一错误率增加了几个百分点。

图像预处理并不仅止于重新缩放步骤。还有一个问题，即如何将通常编码为0到255的图像值转换为训练期间使用的浮点数。出于几个原因，这些值通常会线性缩放到一个较小的范围内：要么是-1.0到1.0，要么是0.0到1.0。如果您要输入浮点值，您需要在应用程序中进行相同的值缩放。如果您直接输入8位值，您在运行时不需要执行此操作——原始的8位值可以不经转换地使用，但您仍需要通过`toco`导出工具通过`--mean_values`和`--std_values`标志将它们传递进去。对于-1.0到1.0的范围，您可以使用`--mean_values=128 --std_values=128`。

令人困惑的是，从模型代码中往往不明显知道输入图像值的正确比例应该是多少，因为这通常是隐藏在所使用API的实现中的细节。许多发布的Google模型使用的Slim框架默认为-1.0到1.0，因此这是一个不错的尝试范围，但如果没有记录，您可能最终不得不通过训练Python实现进行调试以找出其他情况下的正确比例。

更糟糕的是，即使调整大小或值缩放有点错误，您也可能得到*大部分*正确的结果，但会降低准确性。这意味着您的应用程序在初步检查时可能看起来正常运行，但最终体验可能不如预期那样令人印象深刻。图像预处理周围的挑战实际上比其他领域（如音频或加速度计数据）要简单得多，因为可能存在将原始数据转换为神经网络数字数组的复杂特征生成管道。如果查看`micro_speech`示例的预处理代码，您将看到我们必须实现许多信号处理阶段，以从音频样本获得可馈送到模型中的频谱图，任何此代码与训练中使用的版本之间的差异都会降低结果的准确性。

## 调试预处理

鉴于这些输入数据转换很容易出错，您可能甚至很难发现问题，即使发现了问题，也可能很难找出原因。您应该怎么办？我们发现有一些方法可以帮助。

如果可能的话，最好有一个可以在桌面机器上运行的代码版本，即使外围设备被存根。在Linux、macOS或Windows环境中，您将拥有更好的调试工具，并且可以轻松在训练工具和应用程序之间传输测试数据。对于TensorFlow Lite for Microcontrollers中的示例代码，我们将应用程序的不同部分拆分为模块，并为Linux和macOS目标启用了Makefile构建，因此我们可以分别运行推断和预处理阶段。

调试预处理问题最重要的工具是比较训练环境和应用程序中所看到的结果。最困难的部分是在训练过程中提取您关心的节点的正确值并控制输入是什么。本书的范围无法详细介绍如何做到这一点，但您需要识别与核心神经网络阶段对应的操作的名称（在文件解码、预处理和接收预处理结果的第一个操作之后）。接收预处理结果的第一个操作对应于`toco`的`--input_arrays`参数。如果您能识别这些操作，请在Python中在每个操作后插入一个`tf.print`操作，其中`summarize`设置为`-1`。然后，如果运行训练循环，您将能够在调试控制台中看到每个阶段张量内容的打印输出。

然后，您应该能够将这些张量内容转换为C数据数组，然后将其编译到您的程序中。在`micro_speech`代码中有一些示例，比如[一个说“yes”的一秒音频样本](https://oreil.ly/qFoMn)，以及[预处理该输入的预期结果](https://oreil.ly/uKYWo)。在获得这些参考值之后，您应该能够将它们作为输入馈送到保存每个阶段的模块（预处理、神经网络推断）中，并确保输出与您的预期相匹配。如果时间不足，您可以使用临时代码来完成此操作，但将其转换为[单元测试](https://oreil.ly/t2E03)是值得额外投资的，以确保随着代码随时间变化，您的预处理和模型推断仍然得到验证。

## 设备上的评估

在训练结束时，神经网络会使用一组测试输入进行评估，将预测结果与期望结果进行比较，以表征模型的整体准确性。这是训练过程的正常部分，但很少对已部署在设备上的代码进行相同的评估。通常最大的障碍只是将构成典型测试数据集的成千上万个输入样本传输到资源有限的嵌入式系统上。然而，这是一种遗憾；确保设备上的准确性与训练结束时看到的准确性相匹配是确保模型已正确部署的唯一方法，因为有很多方式可以引入难以察觉的细微错误。我们没有设法为`micro_speech`演示实现完整的测试集评估，但至少有[端到端测试](https://oreil.ly/4372z)，确保我们对两个不同输入获得正确的标签。

# 数值差异

神经网络是对大量数字数组执行的一系列复杂数学操作。原始训练通常是以浮点数进行的，但我们尝试将其转换为嵌入式应用程序的低精度整数表示。这些操作本身可以以许多不同的方式实现，取决于平台和优化权衡。所有这些因素意味着您不能期望从不同设备上的网络获得位级相同的结果，即使给定相同的输入。这意味着您必须确定您可以容忍的差异，并且如果这些差异变得太大，如何追踪其来源。

## 差异是否是问题？

我们有时开玩笑说，唯一真正重要的度量标准是应用商店评分。我们的目标应该是生产让人们满意的产品，因此所有其他度量标准只是用户满意度的代理。由于训练环境总会存在数值差异，第一个挑战是了解它们是否影响产品体验。如果您从网络中获得的值毫无意义，这可能很明显，但如果它们与预期值仅有几个百分点的差异，值得尝试将生成的网络作为具有现实用例的完整应用程序的一部分。也许准确性损失不是问题，或者有其他更重要的问题应该优先考虑。

## 建立一个度量标准

当您确定确实存在问题时，量化问题会有所帮助。可能会诱人选择一个数值度量，比如输出得分向量与期望结果之间的百分差异。然而，这可能并不很好地反映用户体验。例如，如果您正在进行图像分类，所有得分都比您期望的低5%，但结果的相对排序保持不变，那么最终结果对于许多应用程序可能是完全合适的。

相反，我们建议设计一个反映产品需求的度量标准。在图像分类案例中，您可能会选择所谓的*top-one*分数，跨一组测试图像，因为这将显示模型选择正确标签的频率。top-one度量标准是模型将地面真实标签选为最高得分预测的频率（*top-five*类似，但涵盖地面真实标签在五个最高得分预测中的频率）。然后，您可以使用top-one度量标准来跟踪您的进展，并且重要的是，了解您所做的更改何时足够好。

您还应小心组装一组标准输入，以反映实际输入到神经网络处理的内容，因为正如我们之前讨论的，预处理可能会引入错误。

## 与基准比较

TensorFlow Lite for Microcontrollers被设计为具有其所有功能的参考实现，我们这样做的原因之一是为了能够将它们的结果与优化代码进行比较，以调试潜在的差异。一旦您有了一些标准输入，您应该尝试通过桌面版本的框架运行它们，不启用任何优化，以便调用参考操作符实现。如果您想要这种独立测试的起点，请查看[micro_speech_test.cc](https://oreil.ly/x5QYp)。如果您将结果通过您建立的度量标准运行，您应该会看到您期望的分数。如果没有，可能在转换过程中出现了一些错误，或者在您的工作流程中的早期阶段出现了其他问题，因此您需要调试回到训练阶段以了解问题所在。

如果您看到使用参考代码获得了良好的结果，那么您应该尝试在目标平台上启用所有优化构建并运行相同的测试。当然，这可能并不像这么简单，因为通常嵌入式设备没有足够的内存来保存所有输入数据，如果您只有调试日志连接，输出结果可能会很棘手。然而，值得坚持，即使您必须将测试分成多次运行。当您获得结果时，请通过您的度量标准运行它们，以了解实际的差距是什么。

## 替换实现

许多平台默认启用优化，因为参考实现在嵌入式设备上运行时间太长，实际上无法使用。有很多方法可以禁用这些优化，但我们发现最简单的方法通常是找到当前正在使用的所有内核实现，通常在[tensorflow/lite/micro/kernels](https://oreil.ly/k3lln)的子文件夹中，并用该父目录中的参考版本覆盖它们（确保您备份要替换的文件）。作为第一步，替换所有优化实现并重新运行设备上的测试，以确保您看到您期望的更好分数。

在进行全面替换之后，尝试仅覆盖一半的优化内核，看看这如何影响度量标准。在大多数情况下，您可以使用二分搜索方法确定哪个优化内核实现导致分数最大下降。一旦您将其缩小到特定的优化内核，然后应该能够通过捕获*坏*运行之一的输入值和来自参考实现的这些输入的预期输出值来创建一个最小可重现案例。在测试运行期间从内核实现中进行调试日志记录是最简单的方法。

现在您有了一个可重现的案例，您应该能够从中创建一个单元测试。您可以查看[标准内核测试之一](https://oreil.ly/0rnPW)以开始，并创建一个新的独立测试，或将其添加到该内核的现有文件中。这样，您就可以使用这个工具将问题传达给负责优化实现的团队，因为您将能够展示他们的代码和参考版本之间存在差异，并且这影响了您的应用程序。如果您将其贡献回去，同样的测试也可以添加到主代码库中，并确保没有其他优化实现会导致相同的问题。这也是一个很好的用于自行调试实现的工具，因为您可以在隔离的代码中进行实验并快速迭代。

# 神秘的崩溃和卡顿

在嵌入式系统中最难修复的情况之一是当你的程序无法运行，但没有明显的日志输出或错误来解释出了什么问题。理解问题的最简单方法是连接调试器（如GDB），然后查看堆栈跟踪（如果挂起）或逐步执行代码，看看执行出了问题的地方。然而，设置调试器并不总是容易的，或者即使使用调试器后问题的根源仍然不明确，所以还有一些其他技术可以尝试。

## 桌面调试

像Linux、macOS和Windows这样的完整操作系统都有广泛的调试工具和错误报告机制，所以如果可能的话，尽量保持你的程序可以在这些平台之一上运行，即使你需要用虚拟实现替换一些硬件特定功能。这就是TensorFlow Lite for Microcontrollers的设计方式，这意味着我们可以首先尝试在我们的Linux机器上重现任何出现问题的情况。如果在这个环境中发生了相同的错误，通常使用标准工具进行跟踪会更容易更快速，而且无需刷写设备，加快迭代速度。即使维护整个应用程序作为桌面构建太困难，至少看看是否可以为你的模块创建可以在桌面上编译的单元测试和集成测试。然后你可以尝试给它们提供与你遇到问题的情况类似的输入，看看是否也会导致类似的错误。

## 日志追踪

TensorFlow Lite for Microcontrollers唯一需要的平台特定功能是`DebugLog()`的实现。我们有这个要求是因为在开发过程中理解发生了什么是如此重要，即使在生产部署中并不需要。在理想的情况下，任何崩溃或程序错误都应该触发日志输出，例如，我们为STM32设备提供的裸机支持有一个[故障处理程序](https://oreil.ly/dsHG8)来实现这一点，但这并不总是可行的。

你应该始终能够自己向代码中注入日志语句。这些语句不需要有意义，只需要说明代码中的位置。你甚至可以定义一个自动跟踪宏，就像这样：

```py
#define TRACE DebugLog(__FILE__ ":" __LINE__)
```

然后在你的代码中像这样使用它：

```py
int main(int argc, char**argv) {
  TRACE;
  InitSomething();
  TRACE;
  while (true) {
    TRACE;
    DoSomething();
    TRACE;
  }
}
```

你应该在调试控制台中看到输出，显示代码执行到了哪个位置。通常最好从代码的最高级别开始，然后看看日志停在哪里。这将让你大致了解崩溃或挂起发生的区域，然后你可以添加更多的`TRACE`语句来进一步确定问题发生的具体位置。

## 散弹式调试

有时候追踪并不能提供足够的信息来解释出现问题的原因，或者问题可能只会在你无法访问日志的环境中发生，比如生产环境。在这种情况下，我们建议使用所谓的“散弹式调试”。这类似于我们在第15章中介绍的“散弹式性能分析”，只需要注释掉代码的部分部分，看看错误是否仍然发生。如果你从应用程序的顶层开始，逐步向下工作，通常可以做到类似于二分查找的方式来确定哪些代码行导致了问题。例如，你可以从主循环中的某些内容开始：

```py
int main(int argc, char**argv) {
  InitSomething();
  while (true) {
    // DoSomething();
  }
}
```

如果使用注释掉`DoSomething()`成功运行，那么你就知道问题发生在该函数内部。然后你可以取消注释，并递归地在其内部执行相同的操作，以便集中关注出现问题的代码。

## 内存损坏

最痛苦的错误是由于内存中的值被意外覆盖而引起的。嵌入式系统没有与台式机或移动CPU相同的硬件来防止这种情况，因此这些问题可能特别难以调试。即使跟踪或注释掉代码也可能产生令人困惑的结果，因为覆盖可能发生在使用损坏值的代码运行之前很久，因此崩溃可能与其原因相距甚远。它们甚至可能依赖于传感器输入或硬件定时，使问题变得间歇性且难以复现。

我们的经验中，导致这种情况的头号原因是超出程序堆栈。这是存储本地变量的地方，而TensorFlow Lite for Microcontrollers广泛使用这些变量来存储相对较大的对象；因此，它需要比许多其他嵌入式应用程序更多的空间。不幸的是，确切的所需大小并不容易确定。通常，最大的贡献者是您需要传递给`SimpleTensorAllocator`的内存区域，该区域在示例中被分配为本地数组：

```py
  // Create an area of memory to use for input, output, and intermediate arrays.
  // The size of this will depend on the model you're using, and may need to be
  // determined by experimentation.
  const int tensor_arena_size = 10 * 1024;
  uint8_t tensor_arena[tensor_arena_size];
  tflite::SimpleTensorAllocator tensor_allocator(tensor_arena,
                                                 tensor_arena_size);
```

如果您使用相同的方法，您需要确保堆栈大小大约等于该区域的大小，再加上运行时使用的几千字节的杂项变量。如果您的区域存放在其他地方（可能作为全局变量），则您只需要几千字节的堆栈。所需的确切内存量取决于您的架构、编译器和正在运行的模型，因此不幸的是，事先很难给出确切的值。如果您遇到神秘的崩溃，值得尽可能增加此值，以查看是否有所帮助。

如果您仍然遇到问题，您应该首先尝试确定哪个变量或内存区域被覆盖。希望可以使用之前描述的日志记录或代码消除方法来实现这一点，将问题缩小到似乎已被损坏的值的读取。一旦您知道哪个变量或数组条目被破坏，您可以编写一个类似于`TRACE`宏的变体，该宏输出该内存位置的值以及调用它的文件和行。您可能需要执行特殊技巧，例如将内存地址存储在全局变量中，以便在本地时可以从更深的堆栈帧中访问。然后，就像您追踪普通崩溃一样，您可以在运行程序并尝试确定哪些代码负责覆盖它时，`TRACE`出该位置的内容。

# 总结

在训练环境中正常工作但在实际设备上失败时提出解决方案可能是一个漫长而令人沮丧的过程。在本章中，我们为您提供了一套工具，当您发现自己陷入困境并一筹莫展时，可以尝试使用这些方法。不幸的是，在调试中没有太多捷径，但通过使用这些方法系统地解决问题，我们确信您可以追踪到任何嵌入式机器学习问题。

一旦您在产品中使一个模型正常工作，您可能会开始思考如何调整它，甚至创建一个全新的模型来解决不同的问题。[第19章](ch19.xhtml#ch19)讨论了如何将您自己的模型从TensorFlow训练环境转移到TensorFlow Lite推断引擎中。
