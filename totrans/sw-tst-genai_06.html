<html><head></head><body>
<div class="calibre1" id="sbo-rt-content"><h1 class="tochead" id="heading_id_2">5 <a id="idTextAnchor000"/><a id="idTextAnchor001"/><a id="idTextAnchor002"/>Test planning with AI support</h1>
<p class="co-summary-head">This chapter covers<a id="idIndexMarker000"/><a id="marker-89"/></p>
<ul class="calibre5">
<li class="co-summary-bullet">How the value of models is associated with the use of LLMs</li>
<li class="co-summary-bullet">Using models with LLMs in test planning</li>
<li class="co-summary-bullet">Evaluating the suitability of suggestions generated by LLMs</li>
</ul>
<p class="body">Now that we’ve started to see how large language models (LLMs) can help support quality in development, it’s time to tackle the question of whether LLMs can generate test cases. On the surface, the answer is simple: yes, they can. But the deeper and more important question is why would you want them to generate test cases? What are we hoping to achieve by generating swathes of test cases without thought or direction? Just because we can create test cases doesn’t necessarily mean it’s the right thing to do in a given situation.</p>
<p class="body">The motivation behind the question comes from a desire to use LLMs to direct the required testing for a feature, an epic, or a project. Although LLMs may be valuable in terms of advising us what testing we should carry out, there are concerns about how trusting we should be and how much we should rely on LLMs. Much like other activities we’ve explored and will explore, there is a balance to be struck. On one hand, we must keep a healthy skepticism in place whenever we use LLMs to aid in testing, but we shouldn’t outright dismiss their potential value (as long as we keep that critical eye for when they might lead us astray). Therefore, this chapter will explore two questions at the core of how LLMs can guide the direction of the testing, focusing on how test planning is conducted:</p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">Can LLMs support us in our test planning?</p>
</li>
<li class="fm-list-bullet">
<p class="list">How can LLMs be used effectively to support said planning?</p>
</li>
</ul>
<p class="body">Specifically, we’ll be looking at the activities we need to carry out when determining what type of testing is necessary for a feature, an epic, or a project. To do this, we’ll examine what test planning looks like in a modern software development team. But before that, we will identify how LLMs can best support us during the planning phase.</p>
<h2 class="fm-head" id="heading_id_3">5.1 Defining test planning in modern testing</h2>
<p class="body">For most of us, a test plan implies detailed documentation that attempts to meticulously define how we will carry out our testing. But if you are someone who works in a modern, agile, software development team, ask yourself: When was the last time you documented a test plan for upcoming work? If so, what did it look like?<a id="marker-90"/><a id="idIndexMarker001"/></p>
<p class="body">Test planning these days comes in a myriad of forms. Some of us might say that we haven’t written a test plan for a long time, and others might capture key details in a one-page test plan or rely on acceptance criteria to determine what testing takes place. Others may still create formal test plans following stringent test plan templates. Whether our planning is conducted formally or informally, what drives a test plan are the risks to our product and project, and this relationship is illustrated in figure 5.1.</p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre20" src="../../OEBPS/Images/CH05_F01_Winteringham2.png"/></p>
<p class="figurecaption">Figure 5.1 A diagram showing the relationship of risk and test planning</p>
</div>
<p class="body">Therefore, when we are planning the testing we intend to carry out, our core goal is to define and mitigate specific, measurable risks. The risks we define inform us of what testing we will do, and depending on the type of intended testing, we can consider different test ideas.</p>
<h3 class="fm-head1" id="heading_id_4">5.1.1 Test planning, LLMs, and area of effect</h3>
<p class="body">Considering that risk is at the core of our testing, we need to establish a relationship with LLMs that helps elevate a risk-based planning approach, while ensuring that we aren’t too biased by an LLM’s output. A lot of discussion has been around how LLMs can be used to direct our testing by having them generate test cases for us. (For the sake of this discussion, we’ll include both automated and nonautomated test cases.) But just because an LLM can generate test cases doesn’t mean that they are necessary or relevant to mitigating the risks we care about. The result may be that some suggested test cases are of value, but using an LLM greatly increases the risk of running wasteful or misleading testing.<a id="idIndexMarker002"/><a id="idIndexMarker003"/></p>
<p class="body">We want to be directed and efficient in our testing, so focusing on using an LLM to support us in identifying risks is key. First, it opens up how we conduct our testing. Asking an LLM to generate test cases ties us to one type of testing activity, and although there is a case for using test cases as part of a holistic strategy of different testing techniques, we shouldn’t rely on a monoculture of test cases alone. Instead, we should focus on risks to explore different concerns we might have without the bias of choosing a testing technique. Once we understand what risks we care about, we can select a suitable testing activity to mitigate said risks.</p>
<p class="body">Second, and most importantly, focusing on risk changes the way we use an LLM. In figure 5.2, the area of effect model demonstrates how we can tell the LLM what features we are focusing on and what risks we have identified already.<a id="marker-91"/></p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre19" src="../../OEBPS/Images/CH05_F02_Winteringham2.png"/></p>
<p class="figurecaption">Figure 5.2 Area of the effect model demonstrating the core roles of the human and the LLM as an assistant</p>
</div>
<p class="body">As demonstrated in the figure, the LLM serves as an assistant that expands our ideas around risk and potentially help us uncover new risks that hadn’t been considered already, helping us expand our risk coverage, while ensuring we control the direction of our testing.</p>
<h2 class="fm-head" id="heading_id_5">5.2 Focused prompts with the use of models</h2>
<p class="body">If we want to use LLMs to help us identify risks, we need to be aware of the hazards of an overreliance on them when determining what to focus on. To better understand this, let’s take a look at a common example of how LLMs are said to help with testing, why they can be problematic, and how we can better direct our use of LLMs to increase their value and decrease the risk of misdirected testing.<a id="idIndexMarker004"/><a id="idIndexMarker005"/><a id="idIndexMarker006"/></p>
<h3 class="fm-head1" id="heading_id_6">5.2.1 Weak prompts mean weak suggestions</h3>
<p class="body">Throughout Part 1 of this book, we’ve seen how poorly framed prompts such as<a id="idIndexMarker007"/><a id="idIndexMarker008"/><a id="idIndexMarker009"/><a id="marker-92"/><a id="idIndexMarker010"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Create tests for a file upload feature</p>
</td>
</tr>
</tbody>
</table>
<p class="body">return a generic list of actionable results not rooted in a context, which means that they require a large amount of reworking or risk affecting the quality of our testing (reduced in size for readability):</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Implementing a file upload feature can introduce several risks, including:</p>
<p class="body-table-list-a">   1.  Security Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Malicious Files: Users might upload files containing malware or viruses, which can infect the system and compromise security.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Injection Attacks: If the system doesn’t properly validate file types and content, it could be vulnerable to injection attacks such as cross-site scripting (XSS) or SQL injection.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Denial of Service (DoS) Attacks: Attackers may upload large or numerous files to overwhelm the system’s storage or processing capacity, leading to a denial of service.</p>
<p class="body-table-list-a">   2.  Privacy Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Sensitive Data Exposure: Users might inadvertently upload files containing sensitive information, such as personal identification, financial data, or confidential documents.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Data Leakage: Improper handling of uploaded files could result in unintended exposure of data, especially if the files are accessible to unauthorized users.</p>
<p class="body-table-list-a">   3.  Compliance Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Regulatory Compliance: Failure to comply with regulations like GDPR or HIPAA regarding the handling of personal or sensitive data could result in legal consequences.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Copyright Infringement: Users may upload copyrighted material without permission, exposing the platform to potential legal actions for copyright infringement.</p>
<p class="body-table-list-a">   4.  Performance Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Bandwidth and Storage: Large file uploads can consume significant bandwidth and storage resources, potentially impacting system performance and scalability.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Concurrency: Multiple users uploading large files simultaneously could strain server resources and degrade system responsiveness.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">If we put garbage in, we get garbage out, and if we’re not critical of how we’re interacting with LLMs, then trouble will ensue. We already know that to obtain value successfully from an LLM, we need to create prompts that are specific to the problem we want solved. When generating suitable risks, the challenge is being able to create those specific prompts for a complex system. The skills required to get to this point don’t lie in our ability to write a prompt but to break down a system into more manageable chunks. By doing this, we can then create more targeted and focused prompts. So, the question then turns to breaking a system down to create better prompts.</p>
<h3 class="fm-head1" id="heading_id_7">5.2.2 What are models and why can they help</h3>
<p class="body"><a id="marker-93"/>Before we go into the process of using models to help us with our prompting, let’s clarify what is meant by models. When we use the term <i class="fm-italics">model</i> in the context of testing and software development in general, we are referring to an abstract representation of some information. It can be something that is visualized (for example, a data flow diagram of an application), or it can be something held in our mind. We say that it is abstract because although it is based on information found in reality, a model usually simplifies, accentuates, or ignores certain aspects of the information it’s based upon. It provides a partial representation of the truth. This is why the aphorism “All models are wrong, but some are useful,” based on a quote from George Box, is used when discussing models. Models tend to be used to focus on specific attributes or concepts within a wider context. This might seem like criticism, but when put to good use, it can help us with problem-solving. For example, consider the model of an application shown in figure 5.3.<a id="idIndexMarker011"/><a id="idIndexMarker012"/><a id="idIndexMarker013"/></p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre21" src="../../OEBPS/Images/CH05_F03_Winteringham2.png"/></p>
<p class="figurecaption">Figure 5.3 A basic visualization of a model of a system</p>
</div>
<p class="body">This visual model of an application has been designed to help its reader ascertain the dependencies between APIs. Notice how it doesn’t contain every detail of the platform. The APIs are abstracted into boxes that summarize the details of what code lives inside each API, and the front end of the system is simply summarized into a box titled ”User interface.” This model is flawed because it doesn’t give us an accurate picture of every aspect of the platform, but it is still useful because it accentuates the details that the reader cares about—the relationships between APIs on a platform. If the reader wants to understand APIs dependencies, then this model has value. However, if the reader wants to understand the implementation of the front end or the specific behavior of functions within each API, the model is worthless.</p>
<p class="body">So, when creating a model, we lean into the idea of a model giving us only a partial picture by highlighting the information we want and discarding other details. This approach to modeling systems can help us make our prompts generate suggested risks that are more contextual and valuable.<a id="idIndexMarker014"/><a id="idIndexMarker015"/><a id="idIndexMarker016"/></p>
<h2 class="fm-head" id="heading_id_8">5.3 Combining models and LLMs to assist test planning</h2>
<p class="body">Now that you better understand the dangers of creating prompts that aren’t focused on a specific part of a system, let’s look at how we can mitigate this risk by using models. To demonstrate our model-based approach, let’s imagine we are using an LLM to help inform our test-planning process.<a id="marker-94"/><a id="idIndexMarker017"/><a id="idIndexMarker018"/></p>
<h3 class="fm-head1" id="heading_id_9">5.3.1 Creating a model to identify prompts</h3>
<p class="body">Unsurprisingly, our first step is to create a model of the application. We’ll explore different formats we can use to create models shortly, but in the meantime, let’s imagine we’ve created a model that looks like the one shown in figure 5.4.</p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre22" src="../../OEBPS/Images/CH05_F04_Winteringham2.png"/></p>
<p class="figurecaption">Figure 5.4 A visual model of an application</p>
</div>
<p class="body">The model uses a data flow diagram to outline how data is handled in the process of requesting a collection of bookings from API. The model itself is not of an entire system, but of a specific piece of functionality that exists in a wider B&amp;B/hotel booking management system. To break down what the model is specifying, when an administrator wants to see the lists of bookings stored in the database, the following steps take place:</p>
<ol class="calibre18">
<li class="fm-list-bullet">
<p class="list">A request is sent to view the list of bookings, and a token is attached to the request.</p>
</li>
<li class="fm-list-bullet">
<p class="list">The token is then extracted from the initial request and sent to be validated against a list of valid sessions.</p>
</li>
<li class="fm-list-bullet">
<p class="list">If the token is confirmed as a valid session, then a positive response is returned to part of the system that is managing the view bookings request.</p>
</li>
<li class="fm-list-bullet">
<p class="list">The list of bookings is then collated and sent back to the administrator.<a id="idIndexMarker019"/><a id="idIndexMarker020"/></p>
</li>
</ol>
<p class="body">Considering this flow, let’s first look at the type of response we might get from an LLM if we were to build a prompt that attempts to encompass everything in the model at once. First, we would create a prompt:<a id="marker-95"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are an expert software tester. Generate a list of risks for an application that uses session-based tokens to authorize access to view a list of bookings.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">When the prompt is sent to an LLM, such as ChatGPT, we receive something like the following response:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Session Token Generation Flaws: The process of generating session tokens may have vulnerabilities, such as predictable token patterns, leading to token guessing attacks.<a id="idIndexMarker021"/></p>
<p class="body-table">Session Token Leakage: Session tokens might inadvertently get exposed in logs, error messages, or through insecure transmission channels, potentially leading to unauthorized access.<a id="idIndexMarker022"/></p>
<p class="body-table">Session Token Storage: Improper storage of session tokens, such as in cookies without secure flags or local storage susceptible to XSS attacks, could result in token theft.<a id="idIndexMarker023"/></p>
<p class="body-table">Session Hijacking: Lack of proper mechanisms to prevent session hijacking attacks, such as session fixation, where an attacker sets a user’s session token, or session replay attacks.<a id="idIndexMarker024"/></p>
<p class="body-table">Session Expiration: Inadequate session timeout configurations might lead to prolonged session exposures, increasing the window of opportunity for attackers to exploit stolen tokens.<a id="idIndexMarker025"/></p>
<p class="body-table">Session Fixation: Failure to invalidate and regenerate session tokens upon authentication events or significant state changes, enabling attackers to fixate sessions to known tokens.<a id="idIndexMarker026"/></p>
<p class="body-table">Insufficient Token Entropy: Session tokens generated with insufficient entropy may be susceptible to brute-force or dictionary attacks.<a id="idIndexMarker027"/></p>
<p class="body-table">Token Lifetime Management: Lack of proper mechanisms to manage token lifetimes, including revocation, renewal, and rotation, could result in prolonged exposure and increased risk of unauthorized access.<a id="idIndexMarker028"/></p>
<p class="body-table">Insecure Token Transmission: Session tokens transmitted over insecure channels, such as HTTP instead of HTTPS, are prone to interception and sniffing attacks.<a id="idIndexMarker029"/></p>
<p class="body-table">Cross-Site Request Forgery (CSRF): Inadequate CSRF protection could allow attackers to forge requests, leading to unauthorized actions using valid session tokens.<a id="idIndexMarker030"/></p>
<p class="body-table">Session Token Injection: Lack of proper input validation and output encoding might expose the application to session token injection attacks, allowing attackers to manipulate session states.<a id="idIndexMarker031"/></p>
<p class="body-table">Insecure Session Termination: Improper session termination mechanisms, such as failing to invalidate session tokens upon logout or session expiration, may lead to lingering session vulnerabilities.<a id="idIndexMarker032"/></p>
<p class="body-table">Session Data Integrity: Absence of integrity checks on session data may allow attackers to tamper with session parameters or payloads, leading to unauthorized access or data manipulation.<a id="idIndexMarker033"/></p>
<p class="body-table">Insufficient Logging and Monitoring: Inadequate logging of session-related events and insufficient monitoring for suspicious activities may impede timely detection and response to session-based attacks.<a id="idIndexMarker034"/></p>
<p class="body-table">Session Token Forensics: Lack of forensic capabilities to trace and investigate session-related incidents may hinder post-incident analysis and remediation efforts.<a id="idIndexMarker035"/><a id="marker-96"/></p>
</td>
</tr>
</tbody>
</table>
<p class="body">The returned list looks quite long at first glance, but after reading it, there appear to be some problems. First, looking over the list of suggested risks, they are predominantly focused on security risks. Although security risks are important to consider, there are minimal risks focused on the interaction between the auth and booking components, or the compilation of the booking list. The LLM has taken the token portion of the prompt and focused too heavily on it. So, let’s consider a prompt created by focusing on a specific slice of the model we created:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are an expert software tester. Generate as many risks as possible for the behavior delimited by three hashes.</p>
<p class="body-table">###</p>
<p class="body-table">A Booking API that, once authorized, sends a list of bookings that are stored within a database to a user for review.</p>
<p class="body-table">###</p>
</td>
</tr>
</tbody>
</table>
<p class="body">With this prompt, we’re attempting to describe a specific part of the system that has been captured in our model. Instead of asking for suggestions that cover all parts of the functionality at once, we select one part of the system to see if we can get better suggestions. This means that if we send this to an LLM such as ChatGPT, we might see the following list of suggestions (again reduced for readability):</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table-list-a">   1.  Data Security Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Unauthorized access to sensitive booking data due to insufficient authentication or authorization mechanisms.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of data breaches if the API doesn’t encrypt data transmission between the server and the user, leaving data vulnerable to interception.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of SQL injection attacks if the API doesn’t sanitize inputs properly, leading to unauthorized access or manipulation of the database.</p>
<p class="body-table-list-a">   2.  Data Accuracy Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Inaccurate or outdated booking information being transmitted to users if the API doesn’t synchronize properly with the database.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of data corruption during transmission, leading to inconsistencies between the database and the information sent to users.</p>
<p class="body-table-list-a">   3.  Performance Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Slow response times or timeouts if the API doesn’t handle a large volume of booking requests efficiently.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of service degradation or downtime if the API cannot handle concurrent requests effectively, leading to performance bottlenecks.<a id="marker-97"/></p>
<p class="body-table-list-a">   4.  Scalability Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Inability to handle increased traffic during peak booking periods, leading to system overload or crashes.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of resource exhaustion if the API doesn’t scale dynamically to accommodate growing user demands, resulting in degraded performance.</p>
<p class="body-table-list-a">   5.  Dependency Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of service disruptions if the API relies on external dependencies (e.g., third-party APIs, libraries, or services) that may experience downtime or changes in functionality.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of version incompatibility if the API is built on outdated or deprecated frameworks, leading to compatibility issues with other systems or libraries.</p>
<p class="body-table-list-a">   6.  Error Handling Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Inadequate error handling mechanisms that may result in ambiguous or misleading error messages, making it difficult for users to diagnose and troubleshoot issues.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of exposing sensitive system information in error messages, potentially aiding attackers in exploiting vulnerabilities.</p>
<p class="body-table-list-a">   7.  Concurrency Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of data corruption or race conditions if the API doesn’t handle concurrent access to the database properly, leading to inconsistencies or data loss.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Inconsistent behavior or unexpected outcomes if the API doesn’t implement proper locking mechanisms to manage concurrent access to shared resources.</p>
<p class="body-table-list-a">   8.  Regulatory Compliance Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of non-compliance with data protection regulations (e.g., GDPR, HIPAA) if the API doesn’t adhere to industry standards for handling sensitive user data.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Potential legal consequences if the API fails to comply with industry-specific regulations (e.g., PCI DSS for payment data).</p>
<p class="body-table-list-a">   9.  Load Testing Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of performance degradation or system failure under heavy load if the API hasn’t been adequately tested for scalability and endurance.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Inaccurate capacity planning leading to under-provisioning or over-provisioning of resources, resulting in suboptimal performance or unnecessary costs.</p>
<p class="body-table-list-a">10.  Documentation Risks:</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Risk of misunderstanding or misusing the API functionality if the documentation is incomplete, outdated, or unclear.</p>
<p class="body-table-list-b">   <span class="cambria">−</span>   Potential delays in development or troubleshooting efforts if developers cannot rely on accurate and up-to-date API documentation.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Let’s compare this response against the previous one we got from ChatGPT and see if there is an improvement. First, there was the problem of the initial prompt focusing too much on specific aspects of the functionality and ignoring other parts. Given that we’ve explicitly selected a distinct part of the system based on our model, it makes sense that a lot of focus in the new prompt response is on ways to test booking lists. We asked it to do that. But what stands out is the diversity of suggestions. In the initial prompt, most of the suggestions were based on different states that a token could be in; this prompt offers not only more suggestions, but also a mix of ideas around the correctness of bookings, boundaries, invalid data, and caching. Next, there was the problem of some suggestions being too vague to be actionable. Reviewing the suggestions that sit under each header, we can see they are more explicit—for example, the negative test suggestions mention specific types of status codes to consider.</p>
<p class="body">The results are improved because LLMs respond better when more context is added to a prompt, and by using a model, we can slice up the behavior, focus on specific components, and capture and communicate the context in our prompt. This does mean we are ignoring other components in the model in favor of being focused so that we can communicate how a part of the system works. But if we iterate this process, we can change up which part of a model we want to create a prompt for. For example, we could run a second prompt that focuses exclusively on the token validation portion of the system to create a prompt like this:<a id="idIndexMarker036"/><a id="idIndexMarker037"/><a id="marker-98"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are an expert software tester. Generate as many risks as possible for the behavior delimited by three hashes.</p>
<p class="body-table">###</p>
<p class="body-table">An Authorization API that will take a token from a different API and check to see if the token is valid and in date before either responding positively or negatively depending on the result.</p>
<p class="body-table">###</p>
</td>
</tr>
</tbody>
</table>
<p class="body">When sent to an LLM like ChatGPT, it would return something like this:<a id="marker-99"/><a id="idIndexMarker038"/><a id="idIndexMarker039"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table-list-a">   1.  Token Validation Failure: The Authorization API may fail to properly validate the token received from the different API, leading to unauthorized access.</p>
<p class="body-table-list-a">   2.  Expired Token: The Authorization API may not accurately detect expired tokens, allowing access to users who should no longer have permissions.</p>
<p class="body-table-list-a">   3.  False Positive/Negative Responses: There is a risk of the API providing incorrect responses, either granting access to unauthorized users or denying access to authorized ones.</p>
<p class="body-table-list-a">   4.  Performance Degradation: If the token validation process is resource-intensive, it may lead to performance degradation or even downtime during high traffic periods.</p>
<p class="body-table-list-a">   5.  Dependency Failure: If the different API providing tokens experiences downtime or issues, the Authorization API may not be able to perform its function correctly.</p>
<p class="body-table-list-a">   6.  Security Vulnerabilities: The Authorization API could be susceptible to security vulnerabilities such as injection attacks or improper access control mechanisms.</p>
<p class="body-table-list-a">   7.  Lack of Logging/Monitoring: Without proper logging and monitoring, it may be challenging to identify unauthorized access attempts or diagnose issues with token validation.</p>
<p class="body-table-list-a">   8.  Inadequate Error Handling: Poor error handling could result in ambiguous or misleading error messages, making it difficult for developers to troubleshoot integration issues.</p>
<p class="body-table-list-a">   9.  Token Spoofing: Malicious actors may attempt to spoof tokens to gain unauthorized access, exploiting weaknesses in the token validation process.</p>
<p class="body-table-list-a"> 10.  Token Replay Attacks: Attackers could intercept valid tokens and replay them to gain unauthorized access, highlighting the importance of implementing measures to prevent token replay attacks.</p>
<p class="body-table-list-a"> 11.  Token Expiry Race Condition: A race condition may occur if a token expires between the time it’s validated and the time access is granted, potentially allowing unauthorized access.</p>
<p class="body-table-list-a"> 12.  Inconsistent Token Validation Logic: If the token validation logic differs between the Authorization API and the different API, it could lead to inconsistencies and unexpected behavior.</p>
<p class="body-table-list-a"> 13.  Regulatory Compliance Issues: Failure to properly secure and validate tokens could result in non-compliance with industry regulations or data protection laws.</p>
<p class="body-table-list-a"> 14.  Scalability Concerns: As the number of users and tokens increases, the scalability of the Authorization API may become a concern, potentially leading to performance issues or service disruptions.</p>
<p class="body-table-list-a"> 15.  Integration Challenges: Integrating the Authorization API with the different API and other systems may present technical challenges, such as compatibility issues or data format mismatches.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We would then pick suggestions from this list and add them to those we selected from the previous prompt response to build a list of risks that we might want to consider in our test planning.</p>
<p class="body"><a id="marker-100"/>This demonstrates that to improve the quality of risk suggestions from an LLM, we need to understand system under test. Simply picking a requirement or feature and asking an LLM to generate risks will not work. The lack of context being provided to an LLM means it will rely on common patterns of behavior in similar feature requirements it has been trained on, which results in vague responses and hallucinations. To get something of value from an LLM, we need to be specific so that we provide rich contextual information for it to use, which we can get using models. By creating a model of the system, we not only improve our understanding of what we’re testing, but also compartmentalize parts of the system into specific areas that we can use to inform the type of prompts we write. We can then iterate through each part of the system, creating prompts to return suggestions that build up a collage of risks that are more relevant and more targeted on specific components and how they might behave.</p>
<p class="body">All of this can once again be summarized using the area of effect model, as shown in figure 5.5.</p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre19" src="../../OEBPS/Images/CH05_F05_Winteringham2.png"/></p>
<p class="figurecaption">Figure 5.5 Area of effect model showing the skills required to get valuable outputs from an LLM</p>
</div>
<p class="body">The area of effect model shows how our modeling and analysis skills are what drive the LLM’s ability to provide value. If our understanding is weak, then so are our prompts, which means the results we get will be weak.</p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 5.1</p>
<p class="fm-sidebar-text">Pick a part of a system you are testing and create a model of how it works. Either create a data flow diagram or pick a different modeling technique. Once you’ve created your model, pick a specific part of the model and use it to create a targeted prompt to generate suggested risks.</p>
</div>
<h3 class="fm-head1" id="heading_id_10">5.3.2 Experimenting with different model types</h3>
<p class="body">In the example we have just explored, we used a data flow diagram approach to model how our system worked. However, as mentioned before, models are flawed, meaning the model we used previously helped us identify potential prompts from the perspective of how data is being handled in our application, but it omits other perspectives in the process. It’s therefore useful to experiment with different types of models to help us consider how our application works from different perspectives, which allows us to prompt an LLM to suggest a wide range of risks to use. So, let’s take a look at a few different types of modeling techniques to help us expand our work.<a id="idIndexMarker040"/><a id="marker-101"/><a id="idIndexMarker041"/></p>
<p class="fm-head2">Formal modeling techniques</p>
<p class="body">When using the data flow diagram format (DTD), we employ explicit symbols and rules that belong to that format so that our model can visually explain what is happening as clearly as possible. DTDs, however, are just one of many different types of formal models that we can borrow and steal from to create models that work for us. For example, UML, or Unified Modeling Language, contains many different modeling approaches to look at an application from different perspectives. Structural UML diagrams such as component diagrams can be used to break down a system’s architecture and help us use LLMs to generate risks focused on specific parts of the system. For example, figure 5.6 demonstrates how we might interpret our booking list functionality as a component diagram.<a id="idIndexMarker042"/><a id="idIndexMarker043"/><a id="idIndexMarker044"/><a id="idIndexMarker045"/><a id="idIndexMarker046"/></p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre23" src="../../OEBPS/Images/CH05_F06_Winteringham2.png"/></p>
<p class="figurecaption">Figure 5.6 A component diagram of the booking list functionality</p>
</div>
<p class="body">It would result in a prompt that looks something like this:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are an expert software tester. Generate as many risks as possible for the behavior delimited by three hashes.</p>
<p class="body-table">###</p>
<p class="body-table">A <code class="fm-code-in-text1">BookingRequest</code> class that sends out a request to an Auth API to confirm whether <code class="fm-code-in-text1">BookingService</code> can complete its request</p>
<p class="body-table">###</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We can also use behavioral diagrams such as sequence and use case diagrams to help us capture user flows through a system and create prompts that generate user-focused prompts (for example, a model like the one in figure 5.7).<a id="marker-102"/></p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre24" src="../../OEBPS/Images/CH05_F07_Winteringham2.png"/></p>
<p class="figurecaption">Figure 5.7 A user flow diagram of the booking list functionality</p>
</div>
<p class="body">It might help us create a prompt like this:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are an expert software tester. Generate as many risks as possible for the behavior delimited by three hashes.</p>
<p class="body-table">###</p>
<p class="body-table">A user wants to view a list of bookings after logging into an application. They have logged in with the correct credentials and are requesting the booking list before their authorization has expired.</p>
<p class="body-table">###</p>
</td>
</tr>
</tbody>
</table>
<p class="body">The options for formal-based models and diagrams are vast, so experimentation is recommended. Exploring how different models work and what types of prompting they trigger can help us determine the ones more suitable for us. We can also use what we learn from formal modeling techniques to build custom models that work for us.</p>
<p class="fm-head2">Mental models</p>
<p class="body">Although different formal modeling techniques can help us analyze our system from different perspectives, it is an expensive activity to carry out. Taking the time to model a system in different ways takes time and requires us to carry out extensive research to build up enough knowledge to frame our application in different ways. However, we can approach interpretations of models from another angle, in which we focus on changing our perception of a single model using heuristics.<a id="idIndexMarker047"/><a id="idIndexMarker048"/><a id="idIndexMarker049"/></p>
<p class="body">If we return to figure 5.7, the model is designed to walk us through the flow of how conditional actions determine what happens next. So, we create prompts that focus on those conditions because that’s what the model is designed to highlight. But what if we were to change our perception by adopting a different mental model? One example would be to use the mnemonic SFDIPOT, sometimes known as San Francisco Depot. Created by James Bach as part of the Heuristic Test Strategy Model (<a class="url" href="https://mng.bz/o0lN">https://mng.bz/o0lN</a>), SFDIPOT is designed to help us consider a product from different perspectives; each letter in the mnemonic stands for a different perspective:<a id="marker-103"/><a id="idIndexMarker050"/></p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Structure</i>—What the product is made of</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Function</i>—What the product does</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Data</i>—What the product processes</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Interfaces</i>—Ways in which the product can be interacted with</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Platform</i>—What the product depends on</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Operations</i>—How the product will be used</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Time</i>—How time affects the product</p>
</li>
</ul>
<p class="body">Although this mnemonic can be used on a strategic level, we can also apply it to smaller sections of a system, as shown in figure 5.7. We can use these different types of perspectives to re-evaluate our product through different lenses. For example, we might review figure 5.7 by asking how time might affect our functionality. It might inspire a prompt such as the following, which sets out initial instructions to generate risks and use the delimiter tactic:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are an expert software tester. Generate as many risks as possible for the behavior delimited by three hashes.</p>
<p class="body-table">Focus on risks around the speed at which the user is using the system (fast or slow) and the amount of users who are using the system at a point in time.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We can use the time to think of tactics to avoid off-topic suggestions:<a id="marker-104"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Check that each suggestion matches the time conditions before outputting them.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Then we’ll provide the context to work from:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">###</p>
<p class="body-table">A user wants to view a list of bookings after logging into an application. They have logged in with the correct credentials and are requesting the booking list before their authorization has expired.</p>
<p class="body-table">###</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Using a prompt like this can result in the following response:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table-list-a">   1.  Single User - Normal Speed: One user logs in, accesses the booking list immediately after successful login, ensuring it displays within an acceptable response time.</p>
<p class="body-table-list-a">   2.  Single User - Slow Speed: A single user, with a slower internet connection, logs in and requests the booking list, examining how the system handles a delayed response.</p>
<p class="body-table-list-a">   3.  Multiple Users - Normal Speed: Multiple users simultaneously log in and request the booking list within a short time frame to observe if the system slows down or if there’s any impact on response time due to concurrent requests.</p>
<p class="body-table-list-a">   4.  Multiple Users - Slow Speed: Simulate multiple users accessing the system with slower connections, attempting to view the booking list concurrently to assess the system’s performance under slower network conditions and concurrent user requests.</p>
<p class="body-table-list-a">   5.  User Authorization Timing: A user attempts to access the booking list right before their authorization expires to verify if the system allows access or handles the request appropriately in this critical time window.</p>
<p class="body-table-list-a">   6.  Expiry of Authorization During Access: Simulate a scenario where a user’s authorization expires while they are viewing the booking list to ensure the system handles this expiration gracefully without crashing or showing sensitive information after the authorization has lapsed.</p>
<p class="body-table-list-a">   7.  Heavy Load Scenario: Generate a heavy load by increasing the number of simultaneous users significantly and assess how the system manages to provide the booking list without compromising response time or crashing due to the load.</p>
<p class="body-table-list-a">   8.  Concurrent Access and Authorization Renewal: Multiple users access the system simultaneously while some of their authorizations are expiring and getting renewed. This test verifies the system’s behavior when dealing with concurrent access and authorization renewal processes.</p>
<p class="body-table-list-a">   9.  Intermittent User Access: Users log in at different intervals, some requesting the booking list immediately after login while others perform various activities first. This test ensures that the system maintains consistent response times despite varied user behaviors.</p>
<p class="body-table-list-a"> 10.  Randomized Access Timing: Randomly timed user requests for the booking list to emulate real-world scenarios, testing how the system copes with unpredictable and irregular access patterns.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">The results of this response are much more focused on how a user or users might interact with a system. They are also much more detailed than some of the earlier high-level suggestions of load testing. The prompt includes explicit information about how the system is expected to work, but we’ve added focus for the prompt based on a shifted perspective of how we think the functionality in figure 5.7 would work over time.</p>
<p class="body">Using heuristics such as SFDIPOT means we can quickly iterate over the same part of a model, but also shift our perspectives and read models in different ways to help us identify new instructions we can add to our prompts.<a id="idIndexMarker051"/><a id="idIndexMarker052"/><a id="idIndexMarker053"/><a id="idIndexMarker054"/><a id="idIndexMarker055"/><a id="idIndexMarker056"/><a id="idIndexMarker057"/><a id="marker-105"/></p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 5.2</p>
<p class="fm-sidebar-text">Create a new model using a different modeling technique of the same feature modeled in the earlier activity, or use the mental modeling technique to re-evaluate your existing model. Use them to come up with new prompts that can suggest unique ideas for the previous prompts that you created.</p>
</div>
<h2 class="fm-head" id="heading_id_11">5.4 LLMs and test cases</h2>
<p class="body">We began this chapter by asking whether LLMs can be used to generate test cases. Instead, we’ve taken a journey using risk as our guide to determine what type of testing we might do. The purpose was to show that we are in control of the direction we want our testing to take. Based on the risks that we identified and the ones suggested by an LLM, we might determine that the testing we carry out doesn’t need to rely on test cases at all.<a id="idIndexMarker058"/><a id="idIndexMarker059"/></p>
<p class="body">However, if our planning has identified that test cases are indeed required, whether they are run manually or through automation, we have done the due diligence in identifying smaller, more focused segments of a feature through modeling that we can use in our prompts. For example, we might create a prompt that combines the modeling work we’ve done earlier, risks we’ve identified, and even example test cases we’ve already captured. We use the delimiter tactic to outline two sections of data:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are an expert software tester. Generate suggested test cases based on the behavior delimited by three hashes and the test cases delimited by three back ticks.</p>
<p class="body-table">Focus on risks around the speed at which the user is using the system (fast or slow) and the amount of users who are using the system at a point in time.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We can take the time to think to stop repetition and focus on risk:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Check that each suggestion matches the proposed risks before outputting them and that they are not a repeat of the test cases found in the section delimited by three backticks.</p>
</td>
</tr>
</tbody>
</table>
<p class="body"><a id="marker-106"/>We then provide a capture area in the delimited section:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">###</p>
<p class="body-table">A user wants to view a list of bookings after logging into an application. They have logged in with the correct credentials and are requesting the booking list before their authorization has expired.</p>
<p class="body-table">###</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Finally, we provide test cases in delimited section:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">```</p>
<p class="body-table">Test Case 1: Single User - Normal Speed:</p>
<p class="body-table-list-a">   •   Test accessing the booking list immediately after logging in with valid credentials, within a typical speed range.</p>
<p class="body-table-list-a">   •   Verify that the booking list is displayed correctly without any delay or errors.</p>
<p class="body-table">Test Case 2: Single User - Slow Speed:</p>
<p class="body-table-list-a">   •   Simulate a slow network connection or system performance.</p>
<p class="body-table-list-a">   •   Attempt to access the booking list immediately after logging in with valid credentials, but at a slower pace.</p>
<p class="body-table-list-a">   •   Ensure that the system responds appropriately, perhaps with a loading indicator or progress bar, and eventually displays the booking list without timing out or crashing.</p>
<p class="body-table">Test Case 3: Multiple Concurrent Users:</p>
<p class="body-table-list-a">   •   Have one user login and request the booking list while another user performs a different action (e.g., making a booking).</p>
<p class="body-table-list-a">   •   Verify that the system can handle concurrent requests without performance degradation or conflicts.</p>
<p class="body-table">```</p>
</td>
</tr>
</tbody>
</table>
<p class="body">When sent to ChatGPT, it returned the following proposed test cases for me:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Test Case 4: Single User - Fast Speed:</p>
<p class="body-table-list-a">   •   Test accessing the booking list immediately after logging in with valid credentials, but at a very fast pace.</p>
<p class="body-table-list-a">   •   Verify that the system can handle rapid requests without causing errors or unexpected behavior.</p>
<p class="body-table">Test Case 5: Multiple Concurrent Users - Normal Speed:</p>
<p class="body-table-list-a">   •   Have multiple users log in simultaneously and request the booking list.</p>
<p class="body-table-list-a">   •   Ensure that each user receives the correct booking list without delays or interference from other users’ requests.</p>
<p class="body-table">Test Case 6: Authorization Expiry:</p>
<p class="body-table-list-a">   •   Login with valid credentials and wait until the authorization expires.</p>
<p class="body-table-list-a">   •   Attempt to access the booking list again.</p>
<p class="body-table-list-a">   •   Verify that the system denies access or prompts the user to reauthenticate instead of displaying the booking list.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Again, the goal here isn’t to blindly generate an exhaustive list of test cases but to critically evaluate what is suggested and see if it generates useful, novel ideas or inspires us to identify new test cases of our own.</p>
<h3 class="fm-head1" id="heading_id_12">5.4.1 Having a healthy skepticism of generated risks and test cases</h3>
<p class="body">Codifying explicit steps about how to approach the testing of an application is no match for the complex, intuitive testing we do as humans. Test cases can help to a certain point, especially in the automation space, but we must avoid a monoculture of test cases that runs the risk of affecting the quality of our products rather than helping improve it. Therefore, we must be mindful that LLMs provide value as an assistant to our test-planning activities and are not an authority on what to test. The alternative is overrelying on LLMs to do our work, which makes users naively think that they can be trusted completely to replicate our testing, which in turn may make us generate thousands of test cases rapidly without thought and/or value. However, the danger doesn’t stem from LLMs alone. Instead, we must think carefully and methodically about what we are asking LLMs to create for us and be skeptical of what is returned. <a id="idIndexMarker060"/><a id="idIndexMarker061"/><a id="marker-107"/></p>
<h2 class="fm-head" id="heading_id_13">Summary</h2>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">Test planning can range from informal notes to formal documentation on how testing will take place.</p>
</li>
<li class="fm-list-bullet">
<p class="list">All test planning, however, is rooted in the risks we care about in our testing.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Generic and vague prompting can harm our planning rather than assist it. Instead, we need to develop more accurate and specific prompting to generate useful suggestions.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Using visual and mental models can help us break down a system to create better prompts.</p>
</li>
<li class="fm-list-bullet">
<p class="list">All models are flawed, but this can be used to our advantage to create models that accentuate details we care about to help us solve problems.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Creating models allows us to break down a feature or segment of a system to better understand how its parts work.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Building prompts based on specific parts of a model can help us produce valuable, accurate, and actionable suggestions.</p>
</li>
<li class="fm-list-bullet">
<p class="list">We can use a range of different modeling techniques to obtain different perspectives on a system’s behavior.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Experimenting with different formal modeling approaches can help us generate different types of prompts.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Reviewing a single model with different mental models can help us shift our own internal biases and perspectives regarding what types of prompts to write.</p>
</li>
<li class="fm-list-bullet">
<p class="list">We should focus on what to test and use LLMs to suggest ideas, not the other way around.<a id="marker-108"/></p>
</li>
</ul>
</div></body></html>