- en: Chapter 4\. Training Feed-Forward Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Fast-Food Problem
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We’re beginning to understand how we can tackle some interesting problems using
    deep learning, but one big question still remains: how exactly do we figure out
    what the parameter vectors (the weights for all of the connections in our neural
    network) should be? This is accomplished by a process commonly referred to as
    *training* (see [Figure 4-1](#fig0201)). During training, we show the neural net
    a large number of training examples and iteratively modify the weights to minimize
    the errors we make on the training examples. After enough examples, we expect
    that our neural network will be quite effective at solving the task it’s been
    trained to do.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0401.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
- en: Figure 4-1\. This is the neuron we want to train for the fast-food problem
  id: totrans-4
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s continue with an example from [Chapter 3](ch03.xhtml#the_neural_network)
    involving a linear neuron: every single day, we purchase a restaurant meal consisting
    of burgers, fries, and sodas. We buy some number of servings for each item. We
    want to be able to predict how much a meal is going to cost us, but the items
    don’t have price tags. The only thing the cashier will tell us is the total price
    of the meal. We want to train a single linear neuron to solve this problem. How
    do we do it?'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: One idea is to be intelligent about picking our training cases. For one meal
    we could buy only a single serving of burgers, for another we could buy only a
    single serving of fries, and then for our last meal we could buy a single serving
    of soda. In general, intelligently selecting training examples is a good idea.
    Lots of research shows that by engineering a clever training set, you can make
    your neural network a lot more effective. The issue with using this approach alone
    is that in real situations, it rarely ever gets you close to the solution. For
    example, there’s no clear analog of this strategy in image recognition. It’s just
    not a practical solution.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, we try to motivate a solution that works well in general. Let’s say
    we have a large set of training examples. Then we can calculate what the neural
    network will output on the <math alttext="i Superscript t h"><msup><mi>i</mi>
    <mrow><mi>t</mi><mi>h</mi></mrow></msup></math> training example using the simple
    formula in the diagram. We want to train the neuron so that we pick the most optimal
    weights possible—the weights that minimize the errors we make on the training
    examples. In this case, let’s say we want to minimize the square error over all
    of the training examples that we encounter. More formally, if we know that <math
    alttext="t Superscript left-parenthesis i right-parenthesis"><msup><mi>t</mi>
    <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math> is the true answer for
    the <math alttext="i Superscript t h"><msup><mi>i</mi> <mrow><mi>t</mi><mi>h</mi></mrow></msup></math>
    training example, and <math alttext="y Superscript left-parenthesis i right-parenthesis"><msup><mi>y</mi>
    <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math> is the value computed
    by the neural network, we want to minimize the value of the error function *E*:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper E equals one-half sigma-summation Underscript i Endscripts
    left-parenthesis t Superscript left-parenthesis i right-parenthesis Baseline minus
    y Superscript left-parenthesis i right-parenthesis Baseline right-parenthesis
    squared"><mrow><mi>E</mi> <mo>=</mo> <mfrac><mn>1</mn> <mn>2</mn></mfrac> <msub><mo>∑</mo>
    <mi>i</mi></msub> <msup><mrow><mo>(</mo><msup><mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>-</mo><msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>)</mo></mrow> <mn>2</mn></msup></mrow></math>
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper E equals one-half sigma-summation Underscript i Endscripts
    left-parenthesis t Superscript left-parenthesis i right-parenthesis Baseline minus
    y Superscript left-parenthesis i right-parenthesis Baseline right-parenthesis
    squared"><mrow><mi>E</mi> <mo>=</mo> <mfrac><mn>1</mn> <mn>2</mn></mfrac> <msub><mo>∑</mo>
    <mi>i</mi></msub> <msup><mrow><mo>(</mo><msup><mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>-</mo><msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>)</mo></mrow> <mn>2</mn></msup></mrow></math>
- en: The squared error is zero when our model makes a perfectly correct prediction
    on every training example. Moreover, the closer *E* is to 0, the better our model
    is. As a result, our goal is to select our parameter vector <math alttext="theta"><mi>θ</mi></math>
    (the values for all the weights in our model) such that *E* is as close to 0 as
    possible.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Now at this point you might be wondering why we need to bother ourselves with
    error functions when we can treat this problem as a system of equations. After
    all, we have a bunch of unknowns (weights) and we have a set of equations (one
    for each training example). That would automatically give us an error of 0, assuming
    that we have a consistent set of training examples.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: That’s a smart observation, but the insight unfortunately doesn’t generalize
    well. Remember that although we’re using a linear neuron here, linear neurons
    aren’t used very much in practice because they’re constrained in what they can
    learn. And the moment we start using nonlinear neurons like the sigmoidal, tanh,
    or ReLU neurons we talked about at the end of [Chapter 3](ch03.xhtml#the_neural_network),
    we can no longer set up a system of linear equations. Clearly, we need a better
    strategy to tackle the training process.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Gradient Descent
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s visualize how we might minimize the squared error over all of the training
    examples by simplifying the problem. Say our linear neuron has only two inputs
    (and thus only two weights, <math alttext="w 1"><msub><mi>w</mi> <mn>1</mn></msub></math>
    and <math alttext="w 2"><msub><mi>w</mi> <mn>2</mn></msub></math> ). Then we can
    imagine a 3D space where the horizontal dimensions correspond to the weights <math
    alttext="w 1"><msub><mi>w</mi> <mn>1</mn></msub></math> and <math alttext="w 2"><msub><mi>w</mi>
    <mn>2</mn></msub></math> , and the vertical dimension corresponds to the value
    of the error function *E*. In this space, points in the horizontal plane correspond
    to different settings of the weights, and the height at those points corresponds
    to the incurred error. If we consider the errors we make over all possible weights,
    we get a surface in this 3D space, in particular, a quadratic bowl as shown in
    [Figure 4-2](#quadratic_error_surface).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0402.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
- en: Figure 4-2\. The quadratic error surface for a linear neuron
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can also conveniently visualize this surface as a set of elliptical contours,
    where the minimum error is at the center of the ellipses. In this setup, we are
    working in a 2D plane where the dimensions correspond to the two weights. Contours
    correspond to settings of <math alttext="w 1"><msub><mi>w</mi> <mn>1</mn></msub></math>
    and <math alttext="w 2"><msub><mi>w</mi> <mn>2</mn></msub></math> that evaluate
    to the same value of *E*. The closer the contours are to each other, the steeper
    the slope. In fact, it turns out that the direction of the steepest descent is
    always perpendicular to the contours. This direction is expressed as a vector
    known as the *gradient*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Now we can develop a high-level strategy for how to find the values of the weights
    that minimizes the error function. Suppose we randomly initialize the weights
    of our network so we find ourselves somewhere on the horizontal plane. By evaluating
    the gradient at our current position, we can find the direction of steepest descent,
    and we can take a step in that direction. Then we’ll find ourselves at a new position
    that’s closer to the minimum than we were before. We can reevaluate the direction
    of steepest descent by taking the gradient at this new position and taking a step
    in this new direction. It’s easy to see that, as shown in [Figure 4-3](#visualizing_the_error_surface),
    following this strategy will eventually get us to the point of minimum error.
    This algorithm is known as *gradient descent*, and we’ll use it to tackle the
    problem of training individual neurons and the more general challenge of training
    entire networks.^([1](ch04.xhtml#idm45934168846800))
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0403.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
- en: Figure 4-3\. Visualizing the error surface as a set of contours
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The Delta Rule and Learning Rates
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we derive the exact algorithm for training our fast-food neuron, we have
    a quick note on *hyperparameters*. In addition to the weight parameters defined
    in our neural network, learning algorithms also require a couple of additional
    parameters to carry out the training process. One of these so-called hyperparameters
    is the *learning rate*.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: In practice, at each step of moving perpendicular to the contour, we need to
    determine how far we want to walk before recalculating our new direction. This
    distance needs to depend on the steepness of the surface. Why? The closer we are
    to the minimum, the shorter we want to step forward. We know we are close to the
    minimum because the surface is a lot flatter, so we can use the steepness as an
    indicator of how close we are to the minimum. However, if our error surface is
    rather mellow, training can potentially take a large amount of time. As a result,
    we often multiply the gradient by a factor <math alttext="epsilon"><mi>ϵ</mi></math>
    , the learning rate. Picking the learning rate is a hard problem ([Figure 4-4](#fig0204)).
    As we just discussed, if we pick a learning rate that’s too small, we risk taking
    too long during the training process. But if we pick a learning rate that’s too
    big, we’ll mostly likely start diverging away from the minimum. In [Chapter 5](ch05.xhtml#neural_networks_in_pytorch),
    we’ll learn about various optimization techniques that utilize adaptive learning
    rates to automate the process of selecting learning rates.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0404.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
- en: Figure 4-4\. Convergence is difficult when our learning rate is too large
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Now, we are finally ready to derive the *delta rule* for training our linear
    neuron. In order to calculate how to change each weight, we evaluate the gradient,
    which is essentially the partial derivative of the error function with respect
    to each of the weights. In other words, we want:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="normal upper Delta w Subscript k Baseline equals minus epsilon
    StartFraction normal partial-differential upper E Over normal partial-differential
    w Subscript k Baseline EndFraction"><mrow><mi>Δ</mi> <msub><mi>w</mi> <mi>k</mi></msub>
    <mo>=</mo> <mo>-</mo> <mi>ϵ</mi> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow> <mrow><mi>∂</mi><msub><mi>w</mi>
    <mi>k</mi></msub></mrow></mfrac></mrow></math><math alttext="equals minus epsilon
    StartFraction normal partial-differential Over normal partial-differential w Subscript
    k Baseline EndFraction left-parenthesis one-half sigma-summation Underscript i
    Endscripts left-parenthesis t Superscript left-parenthesis i right-parenthesis
    Baseline minus y Superscript left-parenthesis i right-parenthesis Baseline right-parenthesis
    squared right-parenthesis"><mrow><mo>=</mo> <mo>-</mo> <mi>ϵ</mi> <mfrac><mi>∂</mi>
    <mrow><mi>∂</mi><msub><mi>w</mi> <mi>k</mi></msub></mrow></mfrac> <mfenced separators=""
    open="(" close=")"><mfrac><mn>1</mn> <mn>2</mn></mfrac> <msub><mo>∑</mo> <mi>i</mi></msub>
    <msup><mrow><mo>(</mo><msup><mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>-</mo><msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>)</mo></mrow> <mn>2</mn></msup></mfenced></mrow></math><math alttext="equals
    sigma-summation Underscript i Endscripts epsilon left-parenthesis t Superscript
    left-parenthesis i right-parenthesis Baseline minus y Superscript left-parenthesis
    i right-parenthesis Baseline right-parenthesis StartFraction normal partial-differential
    y Subscript i Baseline Over normal partial-differential w Subscript k Baseline
    EndFraction"><mrow><mo>=</mo> <msub><mo>∑</mo> <mi>i</mi></msub> <mi>ϵ</mi> <mrow><mo>(</mo>
    <msup><mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup> <mo>-</mo>
    <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup> <mo>)</mo></mrow>
    <mfrac><mrow><mi>∂</mi><msub><mi>y</mi> <mi>i</mi></msub></mrow> <mrow><mi>∂</mi><msub><mi>w</mi>
    <mi>k</mi></msub></mrow></mfrac></mrow></math><math alttext="equals sigma-summation
    Underscript i Endscripts epsilon x Subscript k Superscript left-parenthesis i
    right-parenthesis Baseline left-parenthesis t Superscript left-parenthesis i right-parenthesis
    Baseline minus y Superscript left-parenthesis i right-parenthesis Baseline right-parenthesis"><mrow><mo>=</mo>
    <msub><mo>∑</mo> <mi>i</mi></msub> <mi>ϵ</mi> <msubsup><mi>x</mi> <mi>k</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup>
    <mrow><mo>(</mo> <msup><mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>-</mo> <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>)</mo></mrow></mrow></math>
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节和下一节中，我们将处理训练神经元和利用非线性的神经网络。我们使用S形神经元作为模型，并将其他非线性神经元的推导留给您作为练习。为简单起见，我们假设神经元不使用偏置项，尽管我们的分析很容易扩展到这种情况。我们只需要假设偏置是一个权重，其输入值始终为一。
- en: Applying this method of changing the weights at every iteration, we are finally
    able to utilize gradient descent.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下逻辑神经元如何从其输入计算输出值的机制：
- en: Gradient Descent with Sigmoidal Neurons
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 具有S形神经元的梯度下降
- en: In this section and the next, we will deal with training neurons and neural
    networks that utilize nonlinearities. We use the sigmoidal neuron as a model,
    and leave the derivations for other nonlinear neurons as an exercise for you.
    For simplicity, we assume that the neurons do not use a bias term, although our
    analysis easily extends to this case. We merely need to assume that the bias is
    a weight on an incoming connection whose input value is always one.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 应用这种在每次迭代中改变权重的方法，我们最终能够利用梯度下降。
- en: 'Let’s recall the mechanism by which logistic neurons compute their output value
    from their inputs:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: z = Σw_k x_k
- en: <math alttext="z equals sigma-summation Underscript k Endscripts w Subscript
    k Baseline x Subscript k"><mrow><mi>z</mi> <mo>=</mo> <msub><mo>∑</mo> <mi>k</mi></msub>
    <msub><mi>w</mi> <mi>k</mi></msub> <msub><mi>x</mi> <mi>k</mi></msub></mrow></math><math
    alttext="y equals StartFraction 1 Over 1 plus e Superscript negative z Baseline
    EndFraction"><mrow><mi>y</mi> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow></math>
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: y = 1 / (1 + e^(-z))
- en: 'The neuron computes the weighted sum of its inputs, the logit *z*. It then
    feeds its logit into the input function to compute *y*, its final output. Fortunately
    for us, these functions have nice derivatives, which makes learning easy! For
    learning, we want to compute the gradient of the error function with respect to
    the weights. To do so, we start by taking the derivative of the logit with respect
    to the inputs and the weights:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartFraction normal partial-differential z Over normal partial-differential
    w Subscript k Baseline EndFraction equals x Subscript k"><mrow><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>w</mi> <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mi>x</mi>
    <mi>k</mi></msub></mrow></math>
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential z Over normal partial-differential
    w Subscript k Baseline EndFraction equals x Subscript k"><mrow><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>w</mi> <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mi>x</mi>
    <mi>k</mi></msub></mrow></math>
- en: <math alttext="StartFraction normal partial-differential z Over normal partial-differential
    x Subscript k Baseline EndFraction equals w Subscript k"><mrow><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi>
    <mi>k</mi></msub></mrow></math>
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential z Over normal partial-differential
    x Subscript k Baseline EndFraction equals w Subscript k"><mrow><mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mi>w</mi>
    <mi>k</mi></msub></mrow></math>
- en: 'Also, quite surprisingly, the derivative of the output with respect to the
    logit is quite simple if you express it in terms of the output:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartFraction d y Over d z EndFraction equals StartFraction e
    Superscript negative z Baseline Over left-parenthesis 1 plus e Superscript negative
    z Baseline right-parenthesis squared EndFraction"><mrow><mfrac><mrow><mi>d</mi><mi>y</mi></mrow>
    <mrow><mi>d</mi><mi>z</mi></mrow></mfrac> <mo>=</mo> <mfrac><msup><mi>e</mi> <mrow><mo>-</mo><mi>z</mi></mrow></msup>
    <msup><mfenced separators="" open="(" close=")"><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup></mfenced> <mn>2</mn></msup></mfrac></mrow></math>
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction d y Over d z EndFraction equals StartFraction e
    Superscript negative z Baseline Over left-parenthesis 1 plus e Superscript negative
    z Baseline right-parenthesis squared EndFraction"><mrow><mfrac><mrow><mi>d</mi><mi>y</mi></mrow>
    <mrow><mi>d</mi><mi>z</mi></mrow></mfrac> <mo>=</mo> <mfrac><msup><mi>e</mi> <mrow><mo>-</mo><mi>z</mi></mrow></msup>
    <msup><mfenced separators="" open="(" close=")"><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup></mfenced> <mn>2</mn></msup></mfrac></mrow></math>
- en: <math alttext="equals StartFraction 1 Over 1 plus e Superscript negative z Baseline
    EndFraction StartFraction e Superscript negative z Baseline Over 1 plus e Superscript
    negative z Baseline EndFraction"><mrow><mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac> <mfrac><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow></math>
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="equals StartFraction 1 Over 1 plus e Superscript negative z Baseline
    EndFraction StartFraction e Superscript negative z Baseline Over 1 plus e Superscript
    negative z Baseline EndFraction"><mrow><mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac> <mfrac><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow></math>
- en: <math alttext="equals StartFraction 1 Over 1 plus e Superscript negative z Baseline
    EndFraction left-parenthesis 1 minus StartFraction 1 Over 1 plus e Superscript
    negative z Baseline EndFraction right-parenthesis"><mrow><mo>=</mo> <mfrac><mn>1</mn>
    <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi> <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac>
    <mfenced separators="" open="(" close=")"><mn>1</mn> <mo>-</mo> <mfrac><mn>1</mn>
    <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi> <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac></mfenced></mrow></math>
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="equals StartFraction 1 Over 1 plus e Superscript negative z Baseline
    EndFraction left-parenthesis 1 minus StartFraction 1 Over 1 plus e Superscript
    negative z Baseline EndFraction right-parenthesis"><mrow><mo>=</mo> <mfrac><mn>1</mn>
    <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi> <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac>
    <mfenced separators="" open="(" close=")"><mn>1</mn> <mo>-</mo> <mfrac><mn>1</mn>
    <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi> <mrow><mo>-</mo><mi>z</mi></mrow></msup></mrow></mfrac></mfenced></mrow></math>
- en: <math alttext="equals y left-parenthesis 1 minus y right-parenthesis"><mrow><mo>=</mo>
    <mi>y</mi> <mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>y</mi> <mo>)</mo></mrow></math>
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="equals y left-parenthesis 1 minus y right-parenthesis"><mrow><mo>=</mo>
    <mi>y</mi> <mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>y</mi> <mo>)</mo></mrow></math>
- en: 'We then use the chain rule to get the derivative of the output with respect
    to each weight:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartFraction normal partial-differential y Over normal partial-differential
    w Subscript k Baseline EndFraction equals StartFraction d y Over d z EndFraction
    StartFraction normal partial-differential z Over normal partial-differential w
    Subscript k Baseline EndFraction equals x Subscript k Baseline y left-parenthesis
    1 minus y right-parenthesis"><mrow><mfrac><mrow><mi>∂</mi><mi>y</mi></mrow> <mrow><mi>∂</mi><msub><mi>w</mi>
    <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>d</mi><mi>y</mi></mrow>
    <mrow><mi>d</mi><mi>z</mi></mrow></mfrac> <mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>w</mi> <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mi>x</mi>
    <mi>k</mi></msub> <mi>y</mi> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>y</mi>
    <mo>)</mo></mrow></mrow></math>
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential y Over normal partial-differential
    w Subscript k Baseline EndFraction equals StartFraction d y Over d z EndFraction
    StartFraction normal partial-differential z Over normal partial-differential w
    Subscript k Baseline EndFraction equals x Subscript k Baseline y left-parenthesis
    1 minus y right-parenthesis"><mrow><mfrac><mrow><mi>∂</mi><mi>y</mi></mrow> <mrow><mi>∂</mi><msub><mi>w</mi>
    <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>d</mi><mi>y</mi></mrow>
    <mrow><mi>d</mi><mi>z</mi></mrow></mfrac> <mfrac><mrow><mi>∂</mi><mi>z</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>w</mi> <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mi>x</mi>
    <mi>k</mi></msub> <mi>y</mi> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>y</mi>
    <mo>)</mo></mrow></mrow></math>
- en: 'Putting all of this together, we can now compute the derivative of the error
    function with respect to each weight:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartFraction normal partial-differential upper E Over normal
    partial-differential w Subscript k Baseline EndFraction equals sigma-summation
    Underscript i Endscripts StartFraction normal partial-differential upper E Over
    normal partial-differential y Superscript left-parenthesis i right-parenthesis
    Baseline EndFraction StartFraction normal partial-differential y Superscript left-parenthesis
    i right-parenthesis Baseline Over normal partial-differential w Subscript k Baseline
    EndFraction equals minus sigma-summation Underscript i Endscripts x Subscript
    k Superscript left-parenthesis i right-parenthesis Baseline y Superscript left-parenthesis
    i right-parenthesis Baseline left-parenthesis 1 minus y Superscript left-parenthesis
    i right-parenthesis Baseline right-parenthesis left-parenthesis t Superscript
    left-parenthesis i right-parenthesis Baseline minus y Superscript left-parenthesis
    i right-parenthesis Baseline right-parenthesis"><mrow><mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>w</mi> <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mo>∑</mo>
    <mi>i</mi></msub> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow> <mrow><mi>∂</mi><msup><mi>y</mi>
    <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow></mfrac> <mfrac><mrow><mi>∂</mi><msup><mi>y</mi>
    <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow> <mrow><mi>∂</mi><msub><mi>w</mi>
    <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <mo>-</mo> <msub><mo>∑</mo> <mi>i</mi></msub>
    <msubsup><mi>x</mi> <mi>k</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup>
    <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup> <mfenced separators=""
    open="(" close=")"><mn>1</mn> <mo>-</mo> <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mfenced>
    <mfenced separators="" open="(" close=")"><msup><mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>-</mo> <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mfenced></mrow></math>
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential upper E Over normal
    partial-differential w Subscript k Baseline EndFraction equals sigma-summation
    Underscript i Endscripts StartFraction normal partial-differential upper E Over
    normal partial-differential y Superscript left-parenthesis i right-parenthesis
    Baseline EndFraction StartFraction normal partial-differential y Superscript left-parenthesis
    i right-parenthesis Baseline Over normal partial-differential w Subscript k Baseline
    EndFraction equals minus sigma-summation Underscript i Endscripts x Subscript
    k Superscript left-parenthesis i right-parenthesis Baseline y Superscript left-parenthesis
    i right-parenthesis Baseline left-parenthesis 1 minus y Superscript left-parenthesis
    i right-parenthesis Baseline right-parenthesis left-parenthesis t Superscript
    left-parenthesis i right-parenthesis Baseline minus y Superscript left-parenthesis
    i right-parenthesis Baseline right-parenthesis"><mrow><mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>w</mi> <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mo>∑</mo>
    <mi>i</mi></msub> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow> <mrow><mi>∂</mi><msup><mi>y</mi>
    <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow></mfrac> <mfrac><mrow><mi>∂</mi><msup><mi>y</mi>
    <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow> <mrow><mi>∂</mi><msub><mi>w</mi>
    <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <mo>-</mo> <msub><mo>∑</mo> <mi>i</mi></msub>
    <msubsup><mi>x</mi> <mi>k</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup>
    <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup> <mfenced separators=""
    open="(" close=")"><mn>1</mn> <mo>-</mo> <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mfenced>
    <mfenced separators="" open="(" close=")"><msup><mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>-</mo> <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mfenced></mrow></math>
- en: 'Thus, the final rule for modifying the weights becomes:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="normal upper Delta w Subscript k Baseline equals sigma-summation
    Underscript i Endscripts epsilon x Subscript k Superscript left-parenthesis i
    right-parenthesis Baseline y Superscript left-parenthesis i right-parenthesis
    Baseline left-parenthesis 1 minus y Superscript left-parenthesis i right-parenthesis
    Baseline right-parenthesis left-parenthesis t Superscript left-parenthesis i right-parenthesis
    Baseline minus y Superscript left-parenthesis i right-parenthesis Baseline right-parenthesis"><mrow><mi>Δ</mi>
    <msub><mi>w</mi> <mi>k</mi></msub> <mo>=</mo> <msub><mo>∑</mo> <mi>i</mi></msub>
    <mi>ϵ</mi> <msubsup><mi>x</mi> <mi>k</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup>
    <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup> <mfenced separators=""
    open="(" close=")"><mn>1</mn> <mo>-</mo> <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mfenced>
    <mfenced separators="" open="(" close=")"><msup><mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>-</mo> <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mfenced></mrow></math>
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal upper Delta w Subscript k Baseline equals sigma-summation
    Underscript i Endscripts epsilon x Subscript k Superscript left-parenthesis i
    right-parenthesis Baseline y Superscript left-parenthesis i right-parenthesis
    Baseline left-parenthesis 1 minus y Superscript left-parenthesis i right-parenthesis
    Baseline right-parenthesis left-parenthesis t Superscript left-parenthesis i right-parenthesis
    Baseline minus y Superscript left-parenthesis i right-parenthesis Baseline right-parenthesis"><mrow><mi>Δ</mi>
    <msub><mi>w</mi> <mi>k</mi></msub> <mo>=</mo> <msub><mo>∑</mo> <mi>i</mi></msub>
    <mi>ϵ</mi> <msubsup><mi>x</mi> <mi>k</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msubsup>
    <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup> <mfenced separators=""
    open="(" close=")"><mn>1</mn> <mo>-</mo> <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mfenced>
    <mfenced separators="" open="(" close=")"><msup><mi>t</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup>
    <mo>-</mo> <msup><mi>y</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mfenced></mrow></math>
- en: As you may notice, the new modification rule is just like the delta rule, except
    with extra multiplicative terms included to account for the logistic component
    of the sigmoidal neuron.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: The Backpropagation Algorithm
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now we’re finally ready to tackle the problem of training multilayer neural
    networks (instead of just single neurons). To accomplish this task, we’ll use
    an approach known as *backpropagation*, pioneered by David E. Rumelhart, Geoffrey
    E. Hinton, and Ronald J. Williams in 1986.^([2](ch04.xhtml#idm45934168789808))
    So what’s the idea behind backpropagation? We don’t know what the hidden units
    ought to be doing, but what we can do is compute how fast the error changes as
    we change a hidden activity. From there, we can figure out how fast the error
    changes when we change the weight of an individual connection. Essentially, we’ll
    be trying to find the path of steepest descent. The only catch is that we’re going
    to be working in an extremely high-dimensional space. We start by calculating
    the error derivatives with respect to a single training example.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Each hidden unit can affect many output units. Thus, we’ll have to combine many
    separate effects on the error in an informative way. Our strategy will be one
    of dynamic programming. Once we have the error derivatives for one layer of hidden
    units, we’ll use them to compute the error derivatives for the activities of the
    layer below. And once we find the error derivatives for the activities of the
    hidden units, it’s quite easy to get the error derivatives for the weights leading
    into a hidden unit. We’ll redefine some notation for ease of discussion and refer
    to [Figure 4-5](#fig0205).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0405.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: Figure 4-5\. Reference diagram for the derivation of the backpropagation algorithm
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The subscript we use will refer to the layer of the neuron. The symbol *y*
    will refer to the activity of a neuron, as usual. Similarly, the symbol *z* will
    refer to the logit of the neuron. We start by taking a look at the base case of
    the dynamic programming problem. Specifically, we calculate the error function
    derivatives at the output layer:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper E equals one-half sigma-summation Underscript j element-of
    o u t p u t Endscripts left-parenthesis t Subscript j Baseline minus y Subscript
    j Baseline right-parenthesis squared long right double arrow StartFraction normal
    partial-differential upper E Over normal partial-differential y Subscript j Baseline
    EndFraction equals minus left-parenthesis t Subscript j Baseline minus y Subscript
    j Baseline right-parenthesis"><mrow><mi>E</mi> <mo>=</mo> <mfrac><mn>1</mn> <mn>2</mn></mfrac>
    <msub><mo>∑</mo> <mrow><mi>j</mi><mo>∈</mo><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow></msub>
    <msup><mfenced separators="" open="(" close=")"><msub><mi>t</mi> <mi>j</mi></msub>
    <mo>-</mo><msub><mi>y</mi> <mi>j</mi></msub></mfenced> <mn>2</mn></msup> <mo>⇒</mo>
    <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow> <mrow><mi>∂</mi><msub><mi>y</mi> <mi>j</mi></msub></mrow></mfrac>
    <mo>=</mo> <mo>-</mo> <mrow><mo>(</mo> <msub><mi>t</mi> <mi>j</mi></msub> <mo>-</mo>
    <msub><mi>y</mi> <mi>j</mi></msub> <mo>)</mo></mrow></mrow></math>
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper E equals one-half sigma-summation Underscript j element-of
    o u t p u t Endscripts left-parenthesis t Subscript j Baseline minus y Subscript
    j Baseline right-parenthesis squared long right double arrow StartFraction normal
    partial-differential upper E Over normal partial-differential y Subscript j Baseline
    EndFraction equals minus left-parenthesis t Subscript j Baseline minus y Subscript
    j Baseline right-parenthesis"><mrow><mi>E</mi> <mo>=</mo> <mfrac><mn>1</mn> <mn>2</mn></mfrac>
    <msub><mo>∑</mo> <mrow><mi>j</mi><mo>∈</mo><mi>o</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi></mrow></msub>
    <msup><mfenced separators="" open="(" close=")"><msub><mi>t</mi> <mi>j</mi></msub>
    <mo>-</mo><msub><mi>y</mi> <mi>j</mi></msub></mfenced> <mn>2</mn></msup> <mo>⇒</mo>
    <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow> <mrow><mi>∂</mi><msub><mi>y</mi> <mi>j</mi></msub></mrow></mfrac>
    <mo>=</mo> <mo>-</mo> <mrow><mo>(</mo> <msub><mi>t</mi> <mi>j</mi></msub> <mo>-</mo>
    <msub><mi>y</mi> <mi>j</mi></msub> <mo>)</mo></mrow></mrow></math>
- en: 'Now we tackle the inductive step. Let’s presume we have the error derivatives
    for layer <math alttext="j"><mi>j</mi></math> . We next aim to calculate the error
    derivatives for the layer below it, layer <math alttext="i"><mi>i</mi></math>
    . To do so, we must accumulate information about how the output of a neuron in
    layer <math alttext="i"><mi>i</mi></math> affects the logits of every neuron in
    layer <math alttext="j"><mi>j</mi></math> . This can be done as follows, using
    the fact that the partial derivative of the logit with respect to the incoming
    output data from the layer beneath is merely the weight of the connection <math
    alttext="w Subscript i j"><msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub></math>
    :'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartFraction normal partial-differential upper E Over normal
    partial-differential y Subscript i Baseline EndFraction equals sigma-summation
    Underscript j Endscripts StartFraction normal partial-differential upper E Over
    normal partial-differential z Subscript j Baseline EndFraction StartFraction d
    z Subscript j Baseline Over d y Subscript i Baseline EndFraction equals sigma-summation
    Underscript j Endscripts w Subscript i j Baseline StartFraction normal partial-differential
    upper E Over normal partial-differential z Subscript j Baseline EndFraction"><mrow><mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>y</mi> <mi>i</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mo>∑</mo>
    <mi>j</mi></msub> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow> <mrow><mi>∂</mi><msub><mi>z</mi>
    <mi>j</mi></msub></mrow></mfrac> <mfrac><mrow><mi>d</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow>
    <mrow><mi>d</mi><msub><mi>y</mi> <mi>i</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mo>∑</mo>
    <mi>j</mi></msub> <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow></mfrac></mrow></math>
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential upper E Over normal
    partial-differential y Subscript i Baseline EndFraction equals sigma-summation
    Underscript j Endscripts StartFraction normal partial-differential upper E Over
    normal partial-differential z Subscript j Baseline EndFraction StartFraction d
    z Subscript j Baseline Over d y Subscript i Baseline EndFraction equals sigma-summation
    Underscript j Endscripts w Subscript i j Baseline StartFraction normal partial-differential
    upper E Over normal partial-differential z Subscript j Baseline EndFraction"><mrow><mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>y</mi> <mi>i</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mo>∑</mo>
    <mi>j</mi></msub> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow> <mrow><mi>∂</mi><msub><mi>z</mi>
    <mi>j</mi></msub></mrow></mfrac> <mfrac><mrow><mi>d</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow>
    <mrow><mi>d</mi><msub><mi>y</mi> <mi>i</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mo>∑</mo>
    <mi>j</mi></msub> <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow></mfrac></mrow></math>
- en: 'Furthermore, we observe the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartFraction normal partial-differential upper E Over normal
    partial-differential z Subscript j Baseline EndFraction equals StartFraction normal
    partial-differential upper E Over normal partial-differential y Subscript j Baseline
    EndFraction StartFraction d y Subscript j Baseline Over d z Subscript j Baseline
    EndFraction equals y Subscript j Baseline left-parenthesis 1 minus y Subscript
    j Baseline right-parenthesis StartFraction normal partial-differential upper E
    Over normal partial-differential y Subscript j Baseline EndFraction"><mrow><mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>y</mi> <mi>j</mi></msub></mrow></mfrac> <mfrac><mrow><mi>d</mi><msub><mi>y</mi>
    <mi>j</mi></msub></mrow> <mrow><mi>d</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow></mfrac>
    <mo>=</mo> <msub><mi>y</mi> <mi>j</mi></msub> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo>
    <msub><mi>y</mi> <mi>j</mi></msub> <mo>)</mo></mrow> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>y</mi> <mi>j</mi></msub></mrow></mfrac></mrow></math>
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential upper E Over normal
    partial-differential z Subscript j Baseline EndFraction equals StartFraction normal
    partial-differential upper E Over normal partial-differential y Subscript j Baseline
    EndFraction StartFraction d y Subscript j Baseline Over d z Subscript j Baseline
    EndFraction equals y Subscript j Baseline left-parenthesis 1 minus y Subscript
    j Baseline right-parenthesis StartFraction normal partial-differential upper E
    Over normal partial-differential y Subscript j Baseline EndFraction"><mrow><mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>y</mi> <mi>j</mi></msub></mrow></mfrac> <mfrac><mrow><mi>d</mi><msub><mi>y</mi>
    <mi>j</mi></msub></mrow> <mrow><mi>d</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow></mfrac>
    <mo>=</mo> <msub><mi>y</mi> <mi>j</mi></msub> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo>
    <msub><mi>y</mi> <mi>j</mi></msub> <mo>)</mo></mrow> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>y</mi> <mi>j</mi></msub></mrow></mfrac></mrow></math>
- en: 'Combining these two, we can finally express the error derivatives of layer
    <math alttext="i"><mi>i</mi></math> in terms of the error derivatives of layer
    <math alttext="j"><mi>j</mi></math> :'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartFraction normal partial-differential upper E Over normal
    partial-differential y Subscript i Baseline EndFraction equals sigma-summation
    Underscript j Endscripts w Subscript i j Baseline y Subscript j Baseline left-parenthesis
    1 minus y Subscript j Baseline right-parenthesis StartFraction normal partial-differential
    upper E Over normal partial-differential y Subscript j Baseline EndFraction"><mrow><mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>y</mi> <mi>i</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mo>∑</mo>
    <mi>j</mi></msub> <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub> <msub><mi>y</mi>
    <mi>j</mi></msub> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <msub><mi>y</mi> <mi>j</mi></msub>
    <mo>)</mo></mrow> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow> <mrow><mi>∂</mi><msub><mi>y</mi>
    <mi>j</mi></msub></mrow></mfrac></mrow></math>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential upper E Over normal
    partial-differential y Subscript i Baseline EndFraction equals sigma-summation
    Underscript j Endscripts w Subscript i j Baseline y Subscript j Baseline left-parenthesis
    1 minus y Subscript j Baseline right-parenthesis StartFraction normal partial-differential
    upper E Over normal partial-differential y Subscript j Baseline EndFraction"><mrow><mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>y</mi> <mi>i</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mo>∑</mo>
    <mi>j</mi></msub> <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub> <msub><mi>y</mi>
    <mi>j</mi></msub> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <msub><mi>y</mi> <mi>j</mi></msub>
    <mo>)</mo></mrow> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow> <mrow><mi>∂</mi><msub><mi>y</mi>
    <mi>j</mi></msub></mrow></mfrac></mrow></math>
- en: 'Once we’ve gone through the whole dynamic programming routine, having filled
    up the table appropriately with all of our partial derivatives (of the error function
    with respect to the hidden unit activities), we can then determine how the error
    changes with respect to the weights. This gives us a way to modify the weights
    after each training example:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartFraction normal partial-differential upper E Over normal
    partial-differential w Subscript i j Baseline EndFraction equals StartFraction
    normal partial-differential z Subscript j Baseline Over normal partial-differential
    w Subscript i j Baseline EndFraction StartFraction normal partial-differential
    upper E Over normal partial-differential z Subscript j Baseline EndFraction equals
    y Subscript i Baseline y Subscript j Baseline left-parenthesis 1 minus y Subscript
    j Baseline right-parenthesis StartFraction normal partial-differential upper E
    Over normal partial-differential y Subscript j Baseline EndFraction"><mrow><mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow> <mrow><mi>∂</mi><msub><mi>w</mi>
    <mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mi>y</mi>
    <mi>i</mi></msub> <msub><mi>y</mi> <mi>j</mi></msub> <mrow><mo>(</mo> <mn>1</mn>
    <mo>-</mo> <msub><mi>y</mi> <mi>j</mi></msub> <mo>)</mo></mrow> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>y</mi> <mi>j</mi></msub></mrow></mfrac></mrow></math>
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction normal partial-differential upper E Over normal
    partial-differential w Subscript i j Baseline EndFraction equals StartFraction
    normal partial-differential z Subscript j Baseline Over normal partial-differential
    w Subscript i j Baseline EndFraction StartFraction normal partial-differential
    upper E Over normal partial-differential z Subscript j Baseline EndFraction equals
    y Subscript i Baseline y Subscript j Baseline left-parenthesis 1 minus y Subscript
    j Baseline right-parenthesis StartFraction normal partial-differential upper E
    Over normal partial-differential y Subscript j Baseline EndFraction"><mrow><mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mi>∂</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow> <mrow><mi>∂</mi><msub><mi>w</mi>
    <mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfrac> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>z</mi> <mi>j</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mi>y</mi>
    <mi>i</mi></msub> <msub><mi>y</mi> <mi>j</mi></msub> <mrow><mo>(</mo> <mn>1</mn>
    <mo>-</mo> <msub><mi>y</mi> <mi>j</mi></msub> <mo>)</mo></mrow> <mfrac><mrow><mi>∂</mi><mi>E</mi></mrow>
    <mrow><mi>∂</mi><msub><mi>y</mi> <mi>j</mi></msub></mrow></mfrac></mrow></math>
- en: 'Finally, to complete the algorithm, just as before, we merely sum up the partial
    derivatives over all the training examples in our dataset. This gives us the following
    modification formula:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="normal upper Delta w Subscript i j Baseline equals minus sigma-summation
    Underscript k element-of d a t a s e t Endscripts epsilon y Subscript i Superscript
    left-parenthesis k right-parenthesis Baseline y Subscript j Superscript left-parenthesis
    k right-parenthesis Baseline left-parenthesis 1 minus y Subscript j Superscript
    left-parenthesis k right-parenthesis Baseline right-parenthesis StartFraction
    normal partial-differential upper E Superscript left-parenthesis k right-parenthesis
    Baseline Over normal partial-differential y Subscript j Superscript left-parenthesis
    k right-parenthesis Baseline EndFraction"><mrow><mi>Δ</mi> <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub>
    <mo>=</mo> <mo>-</mo> <msub><mo>∑</mo> <mrow><mi>k</mi><mo>∈</mo><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>s</mi><mi>e</mi><mi>t</mi></mrow></msub>
    <mi>ϵ</mi> <msubsup><mi>y</mi> <mi>i</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <mo>)</mo></mrow> <mfrac><mrow><mi>∂</mi><msup><mi>E</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msup></mrow>
    <mrow><mi>∂</mi><msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup></mrow></mfrac></mrow></math>
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal upper Delta w Subscript i j Baseline equals minus sigma-summation
    Underscript k element-of d a t a s e t Endscripts epsilon y Subscript i Superscript
    left-parenthesis k right-parenthesis Baseline y Subscript j Superscript left-parenthesis
    k right-parenthesis Baseline left-parenthesis 1 minus y Subscript j Superscript
    left-parenthesis k right-parenthesis Baseline right-parenthesis StartFraction
    normal partial-differential upper E Superscript left-parenthesis k right-parenthesis
    Baseline Over normal partial-differential y Subscript j Superscript left-parenthesis
    k right-parenthesis Baseline EndFraction"><mrow><mi>Δ</mi> <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub>
    <mo>=</mo> <mo>-</mo> <msub><mo>∑</mo> <mrow><mi>k</mi><mo>∈</mo><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>s</mi><mi>e</mi><mi>t</mi></mrow></msub>
    <mi>ϵ</mi> <msubsup><mi>y</mi> <mi>i</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <mo>)</mo></mrow> <mfrac><mrow><mi>∂</mi><msup><mi>E</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msup></mrow>
    <mrow><mi>∂</mi><msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup></mrow></mfrac></mrow></math>
- en: This completes our description of the backpropagation algorithm.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic and Minibatch Gradient Descent
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the algorithms we described in [“The Backpropagation Algorithm”](#backpropogation_algo),
    we used a version of gradient descent known as *batch* *gradient descent*. The
    idea behind batch gradient descent is that we use our entire dataset to compute
    the error surface and then follow the gradient to take the path of steepest descent.
    For a simple quadratic error surface, this works quite well. But in most cases,
    our error surface may be a lot more complicated. Let’s consider the scenario in
    [Figure 4-6](#batch_gradient_descent).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/fdl2_0406.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: Figure 4-6\. Batch gradient descent is sensitive to saddle points, which can
    lead to premature convergence
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We have only a single weight, and we use random initialization and batch gradient
    descent to find its optimal setting. The error surface, however, has a flat region
    (also known as saddle point in high-dimensional spaces), and if we get unlucky,
    we might find ourselves getting stuck while performing gradient descent.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Another potential approach is *stochastic gradient descent* (SGD), where at
    each iteration, our error surface is estimated with respect to only a single example.
    This approach is illustrated by [Figure 4-7](#stochastic_error_surface), where
    instead of a single static error surface, our error surface is dynamic. As a result,
    descending on this stochastic surface significantly improves our ability to navigate
    flat regions.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/fdl2_0407.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: Figure 4-7\. The stochastic error surface fluctuates with respect to the batch
    error surface, enabling saddle point avoidance
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The major pitfall of SGD, however, is that looking at the error incurred one
    example at a time may not be a good enough approximation of the error surface.
    This, in turn, could potentially make gradient descent take a significant amount
    of time. One way to combat this problem is using *minibatch gradient descent*.
    In minibatch gradient descent, at every iteration we compute the error surface
    with respect to some subset of the total dataset (instead of just a single example).
    This subset is called a *minibatch*, and in addition to the learning rate, minibatch
    size is another hyperparameter. Minibatches strike a balance between the efficiency
    of batch gradient descent and the local-minima avoidance afforded by stochastic
    gradient descent. In the context of backpropagation, our weight update step becomes:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="normal upper Delta w Subscript i j Baseline equals minus sigma-summation
    Underscript k element-of m i n i b a t c h Endscripts epsilon y Subscript i Superscript
    left-parenthesis k right-parenthesis Baseline y Subscript j Superscript left-parenthesis
    k right-parenthesis Baseline left-parenthesis 1 minus y Subscript j Superscript
    left-parenthesis k right-parenthesis Baseline right-parenthesis StartFraction
    normal partial-differential upper E Superscript left-parenthesis k right-parenthesis
    Baseline Over normal partial-differential y Subscript j Superscript left-parenthesis
    k right-parenthesis Baseline EndFraction"><mrow><mi>Δ</mi> <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub>
    <mo>=</mo> <mo>-</mo> <msub><mo>∑</mo> <mrow><mi>k</mi><mo>∈</mo><mi>m</mi><mi>i</mi><mi>n</mi><mi>i</mi><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub>
    <mi>ϵ</mi> <msubsup><mi>y</mi> <mi>i</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <mo>)</mo></mrow> <mfrac><mrow><mi>∂</mi><msup><mi>E</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msup></mrow>
    <mrow><mi>∂</mi><msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup></mrow></mfrac></mrow></math>
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal upper Delta w Subscript i j Baseline equals minus sigma-summation
    Underscript k element-of m i n i b a t c h Endscripts epsilon y Subscript i Superscript
    left-parenthesis k right-parenthesis Baseline y Subscript j Superscript left-parenthesis
    k right-parenthesis Baseline left-parenthesis 1 minus y Subscript j Superscript
    left-parenthesis k right-parenthesis Baseline right-parenthesis StartFraction
    normal partial-differential upper E Superscript left-parenthesis k right-parenthesis
    Baseline Over normal partial-differential y Subscript j Superscript left-parenthesis
    k right-parenthesis Baseline EndFraction"><mrow><mi>Δ</mi> <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub>
    <mo>=</mo> <mo>-</mo> <msub><mo>∑</mo> <mrow><mi>k</mi><mo>∈</mo><mi>m</mi><mi>i</mi><mi>n</mi><mi>i</mi><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub>
    <mi>ϵ</mi> <msubsup><mi>y</mi> <mi>i</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup>
    <mo>)</mo></mrow> <mfrac><mrow><mi>∂</mi><msup><mi>E</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msup></mrow>
    <mrow><mi>∂</mi><msubsup><mi>y</mi> <mi>j</mi> <mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></msubsup></mrow></mfrac></mrow></math>
- en: This is identical to what we derived in the previous section, but instead of
    summing over all the examples in the dataset, we sum over the examples in the
    current minibatch. For a more theoretical discussion of why SGD and minibatch
    gradient descent result in an unbiased estimate of the gradient over the total
    dataset, please refer to [“Neural Net Learning Theory”](#neural-net-learning-theory-aside).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Test Sets, Validation Sets, and Overfitting
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the major issues with artificial neural networks is that the models are
    quite complicated. For example, let’s consider a neural network that pulls data
    from an image from the MNIST database (28 × 28 pixels), feeds into two hidden
    layers with 30 neurons, and finally reaches a softmax layer of 10 neurons. The
    total number of parameters in the network is nearly 25,000\. This can be quite
    problematic, and to understand why, let’s consider a new toy example, illustrated
    in [Figure 4-8](#two_potential_models).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0408.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4-8\. Two potential models that might describe our dataset: a linear
    model versus a degree 12 polynomial'
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We are given a bunch of data points on a flat plane, and our goal is to find
    a curve that best describes this dataset (i.e., will allow us to predict the *y*
    coordinate of a new point given its *x* coordinate). Using the data, we train
    two different models: a linear model and a degree 12 polynomial. Which curve should
    we trust? The line that gets almost no training example correct? Or the complicated
    curve that hits every single point in the dataset? At this point we might trust
    the linear fit because it seems much less contrived. But just to be sure, let’s
    add more data to our dataset. The result is shown in [Figure 4-9](#linear_fit_is_better_model).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: 'Now the verdict is clear: the linear model is not only better subjectively
    but also quantitatively (measured using the squared error metric). This leads
    to an interesting point about training and evaluating machine learning models.
    By building a very complex model, it’s quite easy to perfectly fit our training
    dataset because we give our model enough degrees of freedom to contort itself
    to fit the observations in the training set. But when we evaluate such a complex
    model on new data, it performs poorly. In other words, the model does not *generalize*
    well. This is a phenomenon called *overfitting*, and it is one of the biggest
    challenges that a machine learning engineer must combat. This becomes an even
    more significant issue in deep learning, where our neural networks have large
    numbers of layers containing many neurons. The number of connections in these
    models is astronomical, reaching the millions. As a result, overfitting is commonplace.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0409.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
- en: Figure 4-9\. Evaluating our model on new data indicates that the linear fit
    is a much better model than the degree 12 polynomial
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Let’s see how this looks in the context of a neural network. Say we have a neural
    network with two inputs, a softmax output of size 2, and a hidden layer with 3,
    6, or 20 neurons. We train these networks using minibatch gradient descent (batch
    size 10), and the results, visualized using [ConvNetJS](http://stanford.io/2pOdNhy),
    are shown in [Figure 4-10](#visualization_of_neural_networks).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0410.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
- en: Figure 4-10\. A visualization of neural networks with 3, 6, and 20 neurons (in
    that order) in their hidden layer
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: It’s already quite apparent from these images that as the number of connections
    in our network increases, so does our propensity to overfit to the data. We can
    similarly see the phenomenon of overfitting as we make our neural networks deep.
    These results are shown in [Figure 4-11](#with_one_two_and_four_hidden_layers).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0411.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
- en: Figure 4-11\. Neural networks with one, two, and four hidden layers (in that
    order) of three neurons each
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This leads to three major observations. First, the machine learning engineer
    is always working with a direct trade-off between overfitting and model complexity.
    If the model isn’t complex enough, it may not be powerful enough to capture all
    of the useful information necessary to solve a problem. However, if our model
    is very complex (especially if we have a limited amount of data at our disposal),
    we run the risk of overfitting. Deep learning takes the approach of solving complex
    problems with complex models and taking additional countermeasures to prevent
    overfitting. We’ll see a lot of these measures in this and later chapters.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Second, it is misleading to evaluate a model using the data we used to train
    it. Using the example in [Figure 4-8](#two_potential_models), this would falsely
    suggest that the degree 12 polynomial model is preferable to a linear fit. As
    a result, we almost never train our model on the entire dataset. Instead, we split
    up our data into a *training set* and a *test set* ([Figure 4-12](#non_overlapping_training_and_test_sets)).
    This enables us to make a fair evaluation of our model by directly measuring how
    well it generalizes on new data it has not yet seen.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In the real world, large datasets are hard to come by, so it might seem like
    a waste to not use all of the data at our disposal during the training process.
    Consequently, it may be tempting to reuse training data for testing or cut corners
    while compiling test data. Be forewarned: if the test set isn’t well constructed,
    we won’t be able draw any meaningful conclusions about our model.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0412.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
- en: Figure 4-12\. Nonoverlapping training and test sets
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Third, it’s quite likely that while we’re training our data, there’s a point
    in time when instead of learning useful features, we start overfitting to the
    training set. To avoid that, we want to be able to stop the training process as
    soon as we start overfitting to prevent poor generalization. To do this, we divide
    our training process into *epochs*. An epoch is a single iteration over the entire
    training set. If we have a training set of size <math alttext="d"><mi>d</mi></math>
    and we are doing minibatch gradient descent with batch size <math alttext="b"><mi>b</mi></math>
    , then an epoch would be equivalent to <math alttext="StartFraction d Over b EndFraction"><mfrac><mi>d</mi>
    <mi>b</mi></mfrac></math> model updates. At the end of each epoch, we want to
    measure how well our model is generalizing. To do this, we use an additional *validation
    set*, which is shown in [Figure 4-13](#validation_set_to_prevent_overfitting).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0413.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
- en: Figure 4-13\. A validation set to prevent overfitting during the training process
  id: totrans-98
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: At the end of an epoch, the validation set will tell us how the model does on
    data it has yet to see. If the accuracy on the training set continues to increase
    while the accuracy on the validation set stays the same (or decreases), it’s a
    good sign that it’s time to stop training because we’re overfitting.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: The validation set is also helpful as a proxy measure of accuracy during the
    process of *hyperparameter optimization*. We’ve covered several hyperparameters
    so far (learning rate, minibatch size, etc.), but we have yet to develop a framework
    for how to find the optimal values for these hyperparameters. One potential way
    to find the optimal setting of hyperparameters is by applying a *grid search,*
    where we pick a value for each hyperparameter from a finite set of options (e.g.,
    <math alttext="epsilon element-of StartSet 0.001 comma 0.01 comma 0.1 EndSet comma
    batch size element-of StartSet 16 comma 64 comma 128 EndSet comma ellipsis"><mrow><mi>ϵ</mi>
    <mo>∈</mo> <mo>{</mo> <mn>0</mn> <mo>.</mo> <mn>001</mn> <mo>,</mo> <mn>0</mn>
    <mo>.</mo> <mn>01</mn> <mo>,</mo> <mn>0</mn> <mo>.</mo> <mn>1</mn> <mo>}</mo>
    <mo>,</mo> <mtext>batch</mtext> <mtext>size</mtext> <mo>∈</mo> <mo>{</mo> <mn>16</mn>
    <mo>,</mo> <mn>64</mn> <mo>,</mo> <mn>128</mn> <mo>}</mo> <mo>,</mo> <mo>...</mo></mrow></math>
    ), and train the model with every possible permutation of hyperparameter choices.
    We elect the combination of hyperparameters with the best performance on the validation
    set and report the accuracy of the model trained with the best combination on
    the test set.^([3](ch04.xhtml#idm45934164422064))
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: With this in mind, before we jump into describing the various ways to directly
    combat overfitting, let’s outline the workflow we use when building and training
    deep learning models. The workflow is described in detail in [Figure 4-14](#detailed_workflow_for_training_and_evaluating).
    It is a tad intricate, but it’s critical to understand the pipeline to ensure
    that we’re properly training our neural networks.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0414.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: Figure 4-14\. Detailed workflow for training and evaluating a deep learning
    model
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'First, we define our problem rigorously. This involves determining our inputs,
    the potential outputs, and the vectorized representations of both. For instance,
    let’s say our goal was to train a deep learning model to identify cancer. Our
    input would be an RBG image, which can be represented as a vector of pixel values.
    Our output would be a probability distribution over three mutually exclusive possibilities:
    (1) normal, (2) benign tumor (a cancer that has yet to metastasize), or (3) malignant
    tumor (a cancer that has already metastasized to other organs).'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: After we define our problem, we need to build a neural network architecture
    to solve it. Our input layer would have to be of appropriate size to accept the
    raw data from the image, and our output layer would have to be a softmax of size
    3\. We will also have to define the internal architecture of the network (number
    of hidden layers, the connectivities, etc.). We’ll further discuss the architecture
    of image recognition models when we talk about convolutional neural networks in
    [Chapter 6](ch06.xhtml#beyond_gradient_descent). At this point, we also want to
    collect a significant amount of data for training or modeling. This data would
    probably be in the form of uniformly sized pathological images that have been
    labeled by a medical expert. We shuffle and divide this data up into separate
    training, validation, and test sets.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we’re ready to begin gradient descent. We train the model on our training
    set for an epoch at a time. At the end of each epoch, we ensure that our error
    on the training set and validation set is decreasing. When one of these stops
    improving, we terminate and make sure we’re happy with the model’s performance
    on the test data. If we’re unsatisfied, we need to rethink our architecture or
    reconsider whether the data we collect has the information required to make the
    prediction we’re interested in making. If our training set error stopped improving,
    we probably need to do a better job of capturing the important features in our
    data. If our validation set error stopped improving, we probably need to take
    measures to prevent overfitting.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: If, however, we are happy with the performance of our model on the training
    data, then we can measure its performance on the test data, which the model has
    never seen before this point. If it is unsatisfactory, we need more data in our
    dataset because the test set seems to consist of example types that weren’t well
    represented in the training set. Otherwise, we are finished!
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Preventing Overfitting in Deep Neural Networks
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Several techniques have been proposed to prevent overfitting during the training
    process. In this section, we’ll discuss these techniques in detail.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: One method of combatting overfitting is called *regularization*. Regularization
    modifies the objective function that we minimize by adding additional terms that
    penalize large weights. We change the objective function so that it becomes <math
    alttext="upper E r r o r plus lamda f left-parenthesis theta right-parenthesis"><mrow><mi>E</mi>
    <mi>r</mi> <mi>r</mi> <mi>o</mi> <mi>r</mi> <mo>+</mo> <mi>λ</mi> <mi>f</mi> <mo>(</mo>
    <mi>θ</mi> <mo>)</mo></mrow></math> , where <math alttext="f left-parenthesis
    theta right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <mi>θ</mi> <mo>)</mo></mrow></math>
    grows larger as the components of <math alttext="theta"><mi>θ</mi></math> grow
    larger, and <math alttext="lamda"><mi>λ</mi></math> is the regularization strength
    (another hyperparameter). The value we choose for <math alttext="lamda"><mi>λ</mi></math>
    determines how much we want to protect against overfitting. A <math alttext="lamda
    equals 0"><mrow><mi>λ</mi> <mo>=</mo> <mn>0</mn></mrow></math> implies that we
    do not take any measures against the possibility of overfitting. If <math alttext="lamda"><mi>λ</mi></math>
    is too large, then our model will prioritize keeping <math alttext="theta"><mi>θ</mi></math>
    as small as possible over trying to find the parameter values that perform well
    on our training set. As a result, choosing <math alttext="lamda"><mi>λ</mi></math>
    is a very important task and can require some trial and error.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: The most common type of regularization in machine learning is *L2* *regularization*.^([4](ch04.xhtml#idm45934164388480))
    It can be implemented by augmenting the error function with the squared magnitude
    of all weights in the neural network. In other words, for every weight <math alttext="w"><mi>w</mi></math>
    in the neural network, we add <math alttext="one-half lamda w squared"><mrow><mfrac><mn>1</mn>
    <mn>2</mn></mfrac> <mi>λ</mi> <msup><mi>w</mi> <mn>2</mn></msup></mrow></math>
    to the error function. The L2 regularization has the intuitive interpretation
    of heavily penalizing peaky weight vectors and preferring diffuse weight vectors.
    This has the appealing property of encouraging the network to use all of its inputs
    a little rather than using only some of its inputs a lot. Of particular note is
    that during the gradient descent update, using the L2 regularization ultimately
    means that every weight is decayed linearly to zero. Because of this phenomenon,
    L2 regularization is also commonly referred to as *weight decay*.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: We can visualize the effects of L2 regularization using ConvNetJS. Similar to
    Figures [2-10](#visualization_of_neural_networks) and [2-11](#with_one_two_and_four_hidden_layers),
    we use a neural network with 2 inputs, a softmax output of size 2, and a hidden
    layer with 20 neurons. We train the networks using minibatch gradient descent
    (batch size 10) and regularization strengths of 0.01, 0.1, and 1\. The results
    can be seen in [Figure 4-15](#trained_with_regularization_strengths).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0415.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
- en: Figure 4-15\. A visualization of neural networks trained with regularization
    strengths of 0.01, 0.1, and 1 (in that order)
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Another common type of regularization is *L1 regularization.* Here, we add the
    term <math alttext="lamda StartAbsoluteValue w EndAbsoluteValue"><mrow><mi>λ</mi>
    <mfenced open="|" close="|"><mi>w</mi></mfenced></mrow></math> for every weight
    <math alttext="w"><mi>w</mi></math> in the neural network. The L1 regularization
    has the intriguing property that it leads the weight vectors to become sparse
    during optimization (i.e., close to exactly zero). Neurons with L1 regularization
    end up using only a small subset of their most important inputs and become quite
    resistant to noise in the inputs. In comparison, weight vectors from L2 regularization
    are usually diffuse, small numbers. L1 regularization is useful when you want
    to understand exactly which features are contributing to a decision. If this level
    of feature analysis isn’t necessary, we prefer to use L2 regularization because
    it empirically performs better.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '*Max norm constraints* have a similar goal of attempting to restrict <math
    alttext="theta"><mi>θ</mi></math> from becoming too large, but they do this more
    directly.^([5](ch04.xhtml#idm45934164370368)) Max norm constraints enforce an
    absolute upper bound on the magnitude of the incoming weight vector for every
    neuron and use projected gradient descent to enforce the constraint. So any time
    a gradient descent step moves the incoming weight vector such that <math alttext="StartAbsoluteValue
    EndAbsoluteValue w StartAbsoluteValue EndAbsoluteValue Subscript 2 Baseline greater-than
    c"><mrow><msub><mfenced open="|" close="|"><mfenced open="|" close="|"><mi>w</mi></mfenced></mfenced>
    <mn>2</mn></msub> <mo>></mo> <mi>c</mi></mrow></math> , we project the vector
    back onto the ball (centered at the origin) with radius <math alttext="c"><mi>c</mi></math>
    . Typical values of <math alttext="c"><mi>c</mi></math> are 3 and 4\. One of the
    nice properties is that the parameter vector cannot grow out of control (even
    if the learning rates are too high) because the updates to the weights are always
    bounded.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '*Dropout* is a different kind of method for preventing overfitting that has
    become one of the most favored methods of preventing overfitting in deep neural
    networks.^([6](ch04.xhtml#idm45934164363488)) While training, dropout is implemented
    by only keeping a neuron active with some probability <math alttext="p"><mi>p</mi></math>
    (a hyperparameter), or setting it to zero otherwise. Intuitively, this forces
    the network to be accurate even in the absence of certain information. It prevents
    the network from becoming too dependent on any one neuron (or any small combination
    of neurons). Expressed more mathematically, it prevents overfitting by providing
    a way of approximately combining exponentially many different neural network architectures
    efficiently. The process of dropout is expressed in [Figure 4-16](#dropout_sets_each_neuron).'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Dropout is pretty intuitive, but there are some important intricacies to consider.
    First, we’d like the outputs of neurons during test time to be equivalent to their
    expected outputs at training time. We could fix this naively by scaling the output
    at test time. For example, if <math alttext="p equals 0.5"><mrow><mi>p</mi> <mo>=</mo>
    <mn>0</mn> <mo>.</mo> <mn>5</mn></mrow></math> , neurons must halve their outputs
    at test time in order to have the same (expected) output they would have during
    training. This is easy to see because a neuron’s output is set to 0 with probability
    <math alttext="1 minus p"><mrow><mn>1</mn> <mo>-</mo> <mi>p</mi></mrow></math>
    . This means that if a neuron’s output prior to dropout was *x*, then after dropout,
    the expected output would be <math alttext="upper E left-bracket output right-bracket
    equals p x plus left-parenthesis 1 minus p right-parenthesis dot 0 equals p x"><mrow><mi>E</mi>
    <mo>[</mo> <mtext>output</mtext> <mo>]</mo> <mo>=</mo> <mi>p</mi> <mi>x</mi> <mo>+</mo>
    <mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>p</mi> <mo>)</mo> <mo>·</mo> <mn>0</mn> <mo>=</mo>
    <mi>p</mi> <mi>x</mi></mrow></math> . This naive implementation of dropout is
    undesirable, however, because it requires scaling of neuron outputs at test time.
    Test-time performance is extremely critical to model evaluation, so it’s always
    preferable to use *inverted dropout*, where the scaling occurs at training time
    instead of at test time. In inverted dropout, any neuron whose activation hasn’t
    been silenced has its output divided by <math alttext="p"><mi>p</mi></math> before
    the value is propagated to the next layer. With this fix, <math alttext="upper
    E left-bracket output right-bracket equals p dot StartFraction x Over p EndFraction
    plus left-parenthesis 1 minus p right-parenthesis dot 0 equals x"><mrow><mi>E</mi>
    <mrow><mo>[</mo> <mtext>output</mtext> <mo>]</mo></mrow> <mo>=</mo> <mi>p</mi>
    <mo>·</mo> <mfrac><mi>x</mi> <mi>p</mi></mfrac> <mo>+</mo> <mrow><mo>(</mo> <mn>1</mn>
    <mo>-</mo> <mi>p</mi> <mo>)</mo></mrow> <mo>·</mo> <mn>0</mn> <mo>=</mo> <mi>x</mi></mrow></math>
    , and we can avoid arbitrarily scaling neuronal output at test time.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '![ ](Images/fdl2_0416.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
- en: Figure 4-16\. Dropout sets each neuron in the network as inactive with some
    random probability during each minibatch of training
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Summary
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ve learned all of the basics involved in training feed-forward
    neural networks. We’ve talked about gradient descent, the backpropagation algorithm,
    as well as various methods we can use to prevent overfitting. In the next chapter,
    we’ll put these lessons into practice when we use the PyTorch library to efficiently
    implement our first neural networks. Then in [Chapter 6](ch06.xhtml#beyond_gradient_descent),
    we’ll return to the problem of optimizing objective functions for training neural
    networks and design algorithms to significantly improve performance. These improvements
    will enable us to process much more data, which means we’ll be able to build more
    comprehensive models.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch04.xhtml#idm45934168846800-marker)) Rosenbloom, P. “The Method of Steepest
    Descent.” *Proceedings of Symposia in Applied Mathematics*. Vol. 6\. 1956.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](ch04.xhtml#idm45934168789808-marker)) Rumelhart, David E., Geoffrey E.
    Hinton, and Ronald J. Williams. “Learning Representations by Back-Propagating
    Errors.” *Cognitive Modeling* 5.3 (1988): 1.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '^([3](ch04.xhtml#idm45934164422064-marker)) Nelder, John A., and Roger Mead.
    “A Simplex Method for Function Minimization.” *The Computer Journal* 7.4 (1965):
    308-313.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '^([4](ch04.xhtml#idm45934164388480-marker)) Tikhonov, Andrei Nikolaevich, and
    Vladlen Borisovich Glasko. “Use of the Regularization Method in Non-Linear Problems.”
    *USSR Computational Mathematics and Mathematical Physics* 5.3 (1965): 93-107.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch04.xhtml#idm45934164370368-marker)) Srebro, Nathan, Jason DM Rennie,
    and Tommi S. Jaakkola. “Maximum-Margin Matrix Factorization.” *NIPS*, Vol. 17,
    2004.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '^([6](ch04.xhtml#idm45934164363488-marker)) Srivastava, Nitish, et al. “Dropout:
    A Simple Way to Prevent Neural Networks from Overfitting.” *Journal of Machine
    Learning Research* 15.1 (2014): 1929-1958.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
