<html><head></head><body><section data-pdf-bookmark="Chapter 4. Using LangGraph to Add Memory to Your Chatbot" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch04_using_langgraph_to_add_memory_to_your_chatbot_1736545668266431">
<h1><span class="label">Chapter 4. </span>Using LangGraph to Add Memory <span class="keep-together">to Your Chatbot</span></h1>

<p>In <a data-type="xref" href="ch03.html#ch03_rag_part_ii_chatting_with_your_data_1736545666793580">Chapter 3</a>, you learned how to provide your AI chatbot application with up-to-date and relevant context. This enables your chatbot to generate accurate responses based on the user’s input. But that’s not enough to build a production-ready application. How can you enable your application to actually “chat” back and forth with the user, while remembering prior conversations and relevant context?</p>

<p>Large language models are<a contenteditable="false" data-primary="statelessness" data-type="indexterm" id="id632"/> <em>stateless</em>, which means that each time the model is prompted to generate a new response it has no memory of the prior prompt or model response. In order to provide this historical information to the model, we need a<a contenteditable="false" data-primary="memory systems" data-secondary="purpose of" data-type="indexterm" id="id633"/> robust memory system that will keep track of previous conversations and context. This historical information can then be included in the final prompt sent to the LLM, thus giving it “memory.” <a data-type="xref" href="#ch04_figure_1_1736545668257395">Figure 4-1</a> illustrates this.</p>

<figure class="width-70"><div class="figure" id="ch04_figure_1_1736545668257395"><img alt="A diagram of a brain  Description automatically generated" src="assets/lelc_0401.png"/>
<h6><span class="label">Figure 4-1. </span>Memory and retrieval used to generate context-aware answers from an LLM</h6>
</div></figure>

<p>In this chapter, you’ll learn how to build this essential memory system using LangChain’s built-in modules to make this development process easier.</p>

<section data-pdf-bookmark="Building a Chatbot Memory System" data-type="sect1"><div class="sect1" id="ch04_building_a_chatbot_memory_system_1736545668266616">
<h1>Building a Chatbot Memory System</h1>

<p>There<a contenteditable="false" data-primary="memory systems" data-secondary="building chatbot memory systems" data-type="indexterm" id="MSmemory04"/><a contenteditable="false" data-primary="chatbots" data-secondary="building chatbot memory systems" data-type="indexterm" id="Cmemory04"/><a contenteditable="false" data-primary="LangGraph" data-secondary="building chatbot memory systems" data-type="indexterm" id="LGcmemory04"/> are two core design decisions behind any robust memory system:</p>

<ul>
	<li>
	<p>How state is stored</p>
	</li>
	<li>
	<p>How state is queried</p>
	</li>
</ul>

<p>A simple way to build a chatbot memory system that incorporates effective solutions to these design decisions is to store and reuse the history of all chat interactions between the user and the model. The state of this memory system can be:</p>

<ul>
	<li>
	<p>Stored as a list of messages (refer to <a data-type="xref" href="ch01.html#ch01_llm_fundamentals_with_langchain_1736545659776004">Chapter 1</a> to learn more about messages)</p>
	</li>
	<li>
	<p>Updated by appending recent messages after each turn</p>
	</li>
	<li>
	<p>Appended into the prompt by inserting the messages into the prompt</p>
	</li>
</ul>

<p><a data-type="xref" href="#ch04_figure_2_1736545668257433">Figure 4-2</a> illustrates this simple memory system.</p>

<figure><div class="figure" id="ch04_figure_2_1736545668257433"><img alt="A diagram of a memory  Description automatically generated" src="assets/lelc_0402.png"/>
<h6><span class="label">Figure 4-2. </span>A simple memory system utilizing chat history in prompts to generate model answers</h6>
</div></figure>

<p>Here’s a code example that illustrates a simple version of this memory system using LangChain:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="chatbot memory systems" data-type="indexterm" id="id634"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">langchain_core.prompts</code> <code class="kn">import</code> <code class="n">ChatPromptTemplate</code>
<code class="kn">from</code> <code class="nn">langchain_openai</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>

<code class="n">prompt</code> <code class="o">=</code> <code class="n">ChatPromptTemplate</code><code class="o">.</code><code class="n">from_messages</code><code class="p">([</code>
    <code class="p">(</code><code class="s2">"system"</code><code class="p">,</code> <code class="s2">"""You are a helpful assistant. Answer all questions to the best </code>
<code class="s2">        of your ability."""</code><code class="p">),</code>
    <code class="p">(</code><code class="s2">"placeholder"</code><code class="p">,</code> <code class="s2">"</code><code class="si">{messages}</code><code class="s2">"</code><code class="p">),</code>
<code class="p">])</code>

<code class="n">model</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">()</code>

<code class="n">chain</code> <code class="o">=</code> <code class="n">prompt</code> <code class="o">|</code> <code class="n">model</code>

<code class="n">chain</code><code class="o">.</code><code class="n">invoke</code><code class="p">({</code>
    <code class="s2">"messages"</code><code class="p">:</code> <code class="p">[</code>
        <code class="p">(</code><code class="s2">"human"</code><code class="p">,</code><code class="s2">"""Translate this sentence from English to French: I love </code>
<code class="s2">            programming."""</code><code class="p">),</code>
        <code class="p">(</code><code class="s2">"ai"</code><code class="p">,</code> <code class="s2">"J'adore programmer."</code><code class="p">),</code>
        <code class="p">(</code><code class="s2">"human"</code><code class="p">,</code> <code class="s2">"What did you just say?"</code><code class="p">),</code>
    <code class="p">],</code>
<code class="p">})</code></pre>

<p><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="chatbot memory systems" data-type="indexterm" id="id635"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">import</code> <code class="p">{</code><code class="nx">ChatPromptTemplate</code><code class="p">}</code> <code class="nx">from</code> <code class="s1">'@langchain/core/prompts'</code>
<code class="kr">import</code> <code class="p">{</code><code class="nx">ChatOpenAI</code><code class="p">}</code> <code class="nx">from</code> <code class="s1">'@langchain/openai'</code>

<code class="kr">const</code> <code class="nx">prompt</code> <code class="o">=</code> <code class="nx">ChatPromptTemplate</code><code class="p">.</code><code class="nx">fromMessages</code><code class="p">([</code>
  <code class="p">[</code><code class="s2">"system"</code><code class="p">,</code> <code class="sb">`You are a helpful assistant. Answer all questions to the best </code>
<code class="sb">    of your ability.`</code><code class="p">],</code>
  <code class="p">[</code><code class="s2">"placeholder"</code><code class="p">,</code> <code class="s2">"{messages}"</code><code class="p">],</code>
<code class="p">])</code>

<code class="kr">const</code> <code class="nx">model</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">ChatOpenAI</code><code class="p">()</code>

<code class="kr">const</code> <code class="nx">chain</code> <code class="o">=</code> <code class="nx">prompt</code><code class="p">.</code><code class="nx">pipe</code><code class="p">(</code><code class="nx">model</code><code class="p">)</code>

<code class="nx">await</code> <code class="nx">chain</code><code class="p">.</code><code class="nx">invoke</code><code class="p">({</code>
  <code class="s2">"messages"</code><code class="o">:</code> <code class="p">[</code>
    <code class="p">[</code><code class="s2">"human"</code><code class="p">,</code><code class="sb">`Translate this sentence from English to French: I love </code>
<code class="sb">      programming.`</code><code class="p">],</code>
    <code class="p">[</code><code class="s2">"ai"</code><code class="p">,</code> <code class="s2">"J'adore programmer."</code><code class="p">],</code>
    <code class="p">[</code><code class="s2">"human"</code><code class="p">,</code> <code class="s2">"What did you just say?"</code><code class="p">],</code>
  <code class="p">],</code>
<code class="p">})</code></pre>

<p><em>The output:</em></p>

<pre data-type="programlisting">
I said, "J'adore programmer," which means "I love programming" in French.</pre>

<p>Note how the incorporation of the previous conversation in the chain enabled the model to answer the follow-up question in a context-aware manner.</p>

<p>While this is simple and it works, when taking your application to production, you’ll face some more challenges related to managing memory at scale, such as:</p>

<ul>
	<li>
	<p>You’ll need to update the memory after every interaction, atomically (i.e., don’t record only the question or only the answer in the case of failure).</p>
	</li>
	<li>
	<p>You’ll want to store these memories in durable storage, such as a relational database.</p>
	</li>
	<li>
	<p>You’ll want to control how many and which messages are stored for later, and how many of these are used for new interactions.</p>
	</li>
	<li>
	<p>You’ll want to inspect and modify this state (for now, just a list of messages) outside a call to an LLM.</p>
	</li>
</ul>

<p>We’ll now introduce some better tooling, which will help with this and all later chapters.<a contenteditable="false" data-primary="" data-startref="Cmemory04" data-type="indexterm" id="id636"/><a contenteditable="false" data-primary="" data-startref="MSmemory04" data-type="indexterm" id="id637"/><a contenteditable="false" data-primary="" data-startref="LGcmemory04" data-type="indexterm" id="id638"/></p>
</div></section>

<section data-pdf-bookmark="Introducing LangGraph" data-type="sect1"><div class="sect1" id="ch04_introducing_langgraph_1736545668266690">
<h1>Introducing LangGraph</h1>

<p>For<a contenteditable="false" data-primary="LangGraph" data-secondary="purpose of" data-type="indexterm" id="id639"/><a contenteditable="false" data-primary="LangGraph" data-secondary="basics of" data-type="indexterm" id="LGbasic04"/> the remainder of this chapter and the following chapters, we’ll start to make use of <a href="https://oreil.ly/TKCb6">LangGraph</a>, an open source library authored by LangChain. LangGraph was designed to enable developers to implement<a contenteditable="false" data-primary="LLM applications" data-secondary="multiactor applications" data-type="indexterm" id="id640"/><a contenteditable="false" data-primary="multiactor applications" data-type="indexterm" id="id641"/> <span class="keep-together">multiactor,</span> <span class="keep-together">multistep,</span> stateful<a contenteditable="false" data-primary="statefulness" data-type="indexterm" id="id642"/> cognitive architectures, called<a contenteditable="false" data-primary="graphs" data-type="indexterm" id="id643"/> <em>graphs</em>. That’s a lot of words packed into a short sentence; let’s take them one at a time. <a data-type="xref" href="#ch04_figure_3_1736545668257457">Figure 4-3</a> illustrates the <span class="keep-together">multiactor</span> aspect.</p>

<figure><div class="figure" id="ch04_figure_3_1736545668257457"><img alt="A diagram of a computer  Description automatically generated" src="assets/lelc_0403.png"/>
<h6><span class="label">Figure 4-3. </span>From single-actor applications to multiactor applications</h6>
</div></figure>

<p>A team of specialists can build something together that none of them could build alone. The same is true of LLM applications: an LLM prompt (great for answer generation and task planning and many more things) is much more powerful when paired up with a search engine (best at finding current facts), or even when paired with different LLM prompts. We have seen developers build some amazing applications, like<a contenteditable="false" data-primary="Perplexity" data-type="indexterm" id="id644"/><a contenteditable="false" data-primary="ArcSearch" data-type="indexterm" id="id645"/> <a href="https://oreil.ly/bVlu7">Perplexity</a> or <a href="https://oreil.ly/NPOlF">Arc Search</a>, when they combine those two building blocks (and others) in novel ways.</p>

<p class="pagebreak-before less_space">And just as a human team needs more coordination than one person working by themselves, an application with multiple actors needs a coordination layer to do these things:</p>

<ul>
	<li>
	<p>Define the actors involved (the nodes in a graph) and how they hand off work to each other (the edges in that graph).</p>
	</li>
	<li>
	<p>Schedule execution of each actor at the appropriate time—in parallel if needed—with deterministic results.</p>
	</li>
</ul>

<p><a data-type="xref" href="#ch04_figure_4_1736545668257478">Figure 4-4</a> illustrates the multistep dimension.</p>

<figure><div class="figure" id="ch04_figure_4_1736545668257478"><img alt="A screenshot of a computer screen  Description automatically generated" src="assets/lelc_0404.png"/>
<h6><span class="label">Figure 4-4. </span>From multiactor to multistep applications</h6>
</div></figure>

<p>As each actor hands off work to another (for example, an LLM prompt asking a search tool for the results of a given search query), we need to make sense of the back-and-forth between multiple actors. We need to know what order it happens in, how many times each actor is called, and so on. To do this, we can model the interaction between the actors as happening across multiple discrete steps in time. When one actor hands off work to another actor, it results in the scheduling of the next step of the computation, and so on, until no more actors hand off work to others, and the final result is reached.</p>

<p class="pagebreak-before less_space"><a data-type="xref" href="#ch04_figure_5_1736545668257500">Figure 4-5</a> illustrates the stateful aspect.</p>

<figure><div class="figure" id="ch04_figure_5_1736545668257500"><img alt="A screenshot of a computer  Description automatically generated" src="assets/lelc_0405.png"/>
<h6><span class="label">Figure 4-5. </span>From multistep to stateful applications</h6>
</div></figure>

<p>Communication across steps requires tracking some state—otherwise, when you call the LLM actor the second time, you’d get the same result as the first time. It is very helpful to pull this state out of each of the actors and have all actors collaborate on updating a single central state. With a single central state, we can:</p>

<ul>
	<li>
	<p>Snapshot and store the central state during or after each computation.</p>
	</li>
	<li>
	<p>Pause and resume execution, which makes it easy to recover from errors.</p>
	</li>
	<li>
	<p>Implement human-in-the-loop controls (more on this in <a data-type="xref" href="ch08.html#ch08_patterns_to_make_the_most_of_llms_1736545674143600">Chapter 8</a>).</p>
	</li>
</ul>

<p>Each <em>graph</em> is then made up of the following:</p>

<dl>
	<dt>State</dt>
	<dd>
	<p>The<a contenteditable="false" data-primary="state" data-type="indexterm" id="id646"/> data received from outside the application, modified and produced by the application while it’s running.</p>
	</dd>
	<dt>Nodes</dt>
	<dd>
	<p>Each<a contenteditable="false" data-primary="nodes" data-type="indexterm" id="id647"/> step to be taken. Nodes are simply Python/JS functions, which receive the current state as input and can return an update to that state (that is, they can add to it and modify or remove existing data).</p>
	</dd>
	<dt>Edges</dt>
	<dd>
	<p>The<a contenteditable="false" data-primary="edges" data-type="indexterm" id="id648"/> connections between nodes. Edges determine the path taken from the first node to the last, and they can be fixed (that is, after Node B, always visit node D) or conditional (evaluate a function to decide the next node to visit after node C).</p>
	</dd>
</dl>

<p>LangGraph offers utilities to visualize these graphs and numerous features to debug their workings while in development. These graphs can then easily be deployed to serve production workloads at high scale.</p>

<p>If<a contenteditable="false" data-primary="LangGraph" data-secondary="installing" data-type="indexterm" id="id649"/> you followed the instructions in <a data-type="xref" href="ch01.html#ch01_llm_fundamentals_with_langchain_1736545659776004">Chapter 1</a>, you’ll already have LangGraph installed. If not, you can install it by running one of the following commands in your terminal:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="LangGraph" data-tertiary="installation" data-type="indexterm" id="id650"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">pip</code> <code class="n">install</code> <code class="n">langgraph</code></pre>

<p><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="LangGraph" data-tertiary="installation" data-type="indexterm" id="id651"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="nx">npm</code> <code class="nx">i</code> <code class="err">@</code><code class="nx">langchain</code><code class="o">/</code><code class="nx">langgraph</code></pre>

<p>To help get you familiar with using LangGraph, we’ll create a simple chatbot using LangGraph, which is a great example of the LLM call architecture with a single use of an LLM. This chatbot will respond directly to user messages. Though simple, it does illustrate the core concepts of building with LangGraph.<a contenteditable="false" data-primary="" data-startref="LGbasic04" data-type="indexterm" id="id652"/></p>
</div></section>

<section data-pdf-bookmark="Creating a StateGraph" data-type="sect1"><div class="sect1" id="ch04_creating_a_stategraph_1736545668266762">
<h1>Creating a StateGraph</h1>

<p>Start<a contenteditable="false" data-primary="LangGraph" data-secondary="creating a StateGraph" data-type="indexterm" id="LGstategraph04"/><a contenteditable="false" data-primary="StateGraph" data-secondary="creation" data-type="indexterm" id="stategraph04"/> by creating a <code>StateGraph</code>. We’ll add a node to represent the LLM call:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="StateGraph" data-tertiary="creating" data-type="indexterm" id="id653"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">Annotated</code><code class="p">,</code> <code class="n">TypedDict</code>

<code class="kn">from</code> <code class="nn">langgraph.graph</code> <code class="kn">import</code> <code class="n">StateGraph</code><code class="p">,</code> <code class="n">START</code><code class="p">,</code> <code class="n">END</code>
<code class="kn">from</code> <code class="nn">langgraph.graph.message</code> <code class="kn">import</code> <code class="n">add_messages</code>


<code class="k">class</code> <code class="nc">State</code><code class="p">(</code><code class="n">TypedDict</code><code class="p">):</code>
    <code class="c1"># Messages have the type "list". The `add_messages` </code>
    <code class="c1"># function in the annotation defines how this state should </code>
    <code class="c1"># be updated (in this case, it appends new messages to the </code>
    <code class="c1"># list, rather than replacing the previous messages)</code>
	<code class="n">messages</code><code class="p">:</code> <code class="n">Annotated</code><code class="p">[</code><code class="nb">list</code><code class="p">,</code> <code class="n">add_messages</code><code class="p">]</code>

<code class="n">builder</code> <code class="o">=</code> <code class="n">StateGraph</code><code class="p">(</code><code class="n">State</code><code class="p">)</code></pre>

<p class="pagebreak-before less_space"><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="StateGraph" data-tertiary="creating" data-type="indexterm" id="id654"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">import</code> <code class="p">{</code>
  <code class="nx">StateGraph</code><code class="p">,</code>
  <code class="nx">StateType</code><code class="p">,</code>
  <code class="nx">Annotation</code><code class="p">,</code>
  <code class="nx">messagesStateReducer</code><code class="p">,</code>
  <code class="nx">START</code><code class="p">,</code> <code class="nx">END</code>
<code class="p">}</code> <code class="nx">from</code> <code class="s1">'@langchain/langgraph'</code>

<code class="kr">const</code> <code class="nx">State</code> <code class="o">=</code> <code class="p">{</code>
  <code class="cm">/**</code>
<code class="cm">  * The State defines three things:</code>
<code class="cm">  * 1. The structure of the graph's state (which "channels" are available to</code>
<code class="cm">  * read/write)</code>
<code class="cm">  * 2. The default values for the state's channels</code>
<code class="cm">  * 3. The reducers for the state's channels. Reducers are functions that</code>
<code class="cm">  * determine how to apply updates to the state. Below, new messages are</code>
<code class="cm">  * appended to the messages array.</code>
<code class="cm">  */</code>
  <code class="nx">messages</code><code class="o">:</code> <code class="nx">Annotation</code><code class="p">({</code>
    <code class="nx">reducer</code><code class="o">:</code> <code class="nx">messagesStateReducer</code><code class="p">,</code>
    <code class="k">default</code><code class="o">:</code> <code class="p">()</code> <code class="o">=&gt;</code> <code class="p">[]</code>
  <code class="p">}),</code>
<code class="p">}</code>

<code class="kr">const</code> <code class="nx">builder</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">StateGraph</code><code class="p">(</code><code class="nx">State</code><code class="p">)</code></pre>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The first thing you do when you define a graph is define the state of the graph. The<a contenteditable="false" data-primary="state" data-type="indexterm" id="id655"/> <em>state</em> consists of the shape, or schema, of the graph state, as well as reducer functions that specify how to apply updates to the state. In this example, the state is a dictionary with a single key: <code>messages</code>. The <code>messages</code> key is annotated with the <code>add_messages</code> reducer function, which tells LangGraph to append new messages to the existing list, rather than overwrite it. State keys without an annotation will be overwritten by each update, storing the most recent value. You can write your own reducer functions, which are simply functions that receive as arguments—argument 1 is the current state, and argument 2 is the next value being written to the state—and should return the next state, that is, the result of merging the current state with the new value. The simplest example is a function that appends the next value to a list and returns that list.</p>
</div>

<p class="pagebreak-before less_space">So now our graph knows two things:</p>

<ul>
	<li>
	<p>Every <code>node</code> we define will receive the current <code>State</code> as input and return a value that updates that state.</p>
	</li>
	<li>
	<p><code>messages</code> will<a contenteditable="false" data-primary="messages" data-secondary="appending" data-type="indexterm" id="id656"/> be <em>appended</em> to the current list, rather than directly overwritten. This is communicated via the prebuilt <a href="https://oreil.ly/sK-Ry"><code>add_messages</code></a> function in the <code>Annotated</code> syntax in the Python example or the reducer function for the JavaScript example.</p>
	</li>
</ul>

<p>Next, add the <code>chatbot</code> node. Nodes represent units of work. They are typically just functions:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="chatbot nodes, adding" data-type="indexterm" id="id657"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">langchain_openai</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>

<code class="n">model</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">()</code>

<code class="k">def</code> <code class="nf">chatbot</code><code class="p">(</code><code class="n">state</code><code class="p">:</code> <code class="n">State</code><code class="p">):</code>
    <code class="n">answer</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="n">state</code><code class="p">[</code><code class="s2">"messages"</code><code class="p">])</code>
    <code class="k">return</code> <code class="p">{</code><code class="s2">"messages"</code><code class="p">:</code> <code class="p">[</code><code class="n">answer</code><code class="p">]}</code>

<code class="c1"># The first argument is the unique node name</code>
<code class="c1"># The second argument is the function or Runnable to run</code>
<code class="n">builder</code><code class="o">.</code><code class="n">add_node</code><code class="p">(</code><code class="s2">"chatbot"</code><code class="p">,</code> <code class="n">chatbot</code><code class="p">)</code></pre>

<p><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="chatbot nodes, adding" data-type="indexterm" id="id658"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">import</code> <code class="p">{</code><code class="nx">ChatOpenAI</code><code class="p">}</code> <code class="nx">from</code> <code class="s1">'@langchain/openai'</code>
<code class="kr">import</code> <code class="p">{</code>
  <code class="nx">AIMessage</code><code class="p">,</code>
  <code class="nx">SystemMessage</code><code class="p">,</code>
  <code class="nx">HumanMessage</code>
<code class="p">}</code> <code class="nx">from</code> <code class="s2">"@langchain/core/messages"</code><code class="p">;</code>

<code class="kr">const</code> <code class="nx">model</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">ChatOpenAI</code><code class="p">()</code>

<code class="nx">async</code> <code class="kd">function</code> <code class="nx">chatbot</code><code class="p">(</code><code class="nx">state</code><code class="p">)</code> <code class="p">{</code>
  <code class="kr">const</code> <code class="nx">answer</code> <code class="o">=</code> <code class="nx">await</code> <code class="nx">model</code><code class="p">.</code><code class="nx">invoke</code><code class="p">(</code><code class="nx">state</code><code class="p">.</code><code class="nx">messages</code><code class="p">)</code>
  <code class="k">return</code> <code class="p">{</code><code class="s2">"messages"</code><code class="o">:</code> <code class="nx">answer</code><code class="p">}</code>
<code class="p">}</code>

<code class="nx">builder</code> <code class="o">=</code> <code class="nx">builder</code><code class="p">.</code><code class="nx">addNode</code><code class="p">(</code><code class="s1">'chatbot'</code><code class="p">,</code> <code class="nx">chatbot</code><code class="p">)</code></pre>

<p>This node receives the current state, does one LLM call, and then returns an update to the state containing the new message produced by the LLM. The <code>add_messages</code> reducer appends this message to the messages already in the state.</p>

<p class="pagebreak-before less_space">And finally let’s add the edges:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="chatbot edges, adding" data-type="indexterm" id="id659"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">builder</code><code class="o">.</code><code class="n">add_edge</code><code class="p">(</code><code class="n">START</code><code class="p">,</code> <code class="s1">'chatbot'</code><code class="p">)</code>
<code class="n">builder</code><code class="o">.</code><code class="n">add_edge</code><code class="p">(</code><code class="s1">'chatbot'</code><code class="p">,</code> <code class="n">END</code><code class="p">)</code>

<code class="n">graph</code> <code class="o">=</code> <code class="n">builder</code><code class="o">.</code><code class="n">compile</code><code class="p">()</code></pre>

<p><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="chatbot edges, adding" data-type="indexterm" id="id660"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="nx">builder</code> <code class="o">=</code> <code class="nx">builder</code>
  <code class="p">.</code><code class="nx">addEdge</code><code class="p">(</code><code class="nx">START</code><code class="p">,</code> <code class="s1">'chatbot'</code><code class="p">)</code>
  <code class="p">.</code><code class="nx">addEdge</code><code class="p">(</code><code class="s1">'chatbot'</code><code class="p">,</code> <code class="nx">END</code><code class="p">)</code>

<code class="kd">let</code> <code class="nx">graph</code> <code class="o">=</code> <code class="nx">builder</code><code class="p">.</code><code class="nx">compile</code><code class="p">()</code></pre>

<p>This does a few things:</p>

<ul>
	<li>
	<p>It tells the graph where to start its work each time you run it.</p>
	</li>
	<li>
	<p>This instructs the graph where it should exit (this is optional, as LangGraph will stop execution once there’s no more nodes to run).</p>
	</li>
	<li>
	<p>It compiles the graph into a runnable object, with the familiar <code>invoke</code> and <code>stream</code> methods.</p>
	</li>
</ul>

<p>We can also draw a visual representation of the graph:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="LangGraph" data-tertiary="visual representation" data-type="indexterm" id="id661"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">graph</code><code class="o">.</code><code class="n">get_graph</code><code class="p">()</code><code class="o">.</code><code class="n">draw_mermaid_png</code><code class="p">()</code></pre>

<p><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="LangGraph" data-tertiary="visual representation" data-type="indexterm" id="id662"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="nx">await</code> <code class="nx">graph</code><code class="p">.</code><code class="nx">getGraph</code><code class="p">().</code><code class="nx">drawMermaidPng</code><code class="p">()</code></pre>

<p>The graph we just made looks like <a data-type="xref" href="#ch04_figure_6_1736545668257524">Figure 4-6</a>.</p>

<figure><div class="figure" id="ch04_figure_6_1736545668257524"><img alt="A diagram of a chatbot  Description automatically generated" src="assets/lelc_0406.png"/>
<h6><span class="label">Figure 4-6. </span>A simple chatbot</h6>
</div></figure>

<p class="pagebreak-before less_space">You can run it with the familiar <code>stream()</code> method you’ve seen in earlier chapters:</p>

<p><em>Python</em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="nb">input</code> <code class="o">=</code> <code class="p">{</code><code class="s2">"messages"</code><code class="p">:</code> <code class="p">[</code><code class="n">HumanMessage</code><code class="p">(</code><code class="s1">'hi!)]}</code>
<code class="k">for</code> <code class="n">chunk</code> <code class="ow">in</code> <code class="n">graph</code><code class="o">.</code><code class="n">stream</code><code class="p">(</code><code class="nb">input</code><code class="p">):</code>
    <code class="nb">print</code><code class="p">(</code><code class="n">chunk</code><code class="p">)</code></pre>

<p><em>JavaScript</em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">const</code> <code class="nx">input</code> <code class="o">=</code> <code class="p">{</code><code class="nx">messages</code><code class="o">:</code> <code class="p">[</code><code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">(</code><code class="err">'</code><code class="nx">hi</code><code class="o">!</code><code class="p">)]}</code>
<code class="k">for</code> <code class="nx">await</code> <code class="p">(</code><code class="kr">const</code> <code class="nx">chunk</code> <code class="k">of</code> <code class="nx">await</code> <code class="nx">graph</code><code class="p">.</code><code class="nx">stream</code><code class="p">(</code><code class="nx">input</code><code class="p">))</code> <code class="p">{</code>
  <code class="nx">console</code><code class="p">.</code><code class="nx">log</code><code class="p">(</code><code class="nx">chunk</code><code class="p">)</code>
<code class="p">}</code></pre>

<p><em>The output:</em></p>

<pre data-type="programlisting">
{ "chatbot": { "messages": [AIMessage("How can I help you?")] } }</pre>

<p>Notice how the input to the graph was in the same shape as the <code>State</code> object we defined earlier; that is, we sent in a list of messages in the <code>messages</code> key of a dictionary. In addition, the <code>stream</code> function streams the full value of the state after each step of the graph.<a contenteditable="false" data-startref="LGstategraph04" data-type="indexterm" id="id663"/><a contenteditable="false" data-primary="" data-startref="stategraph04" data-type="indexterm" id="id664"/></p>
</div></section>

<section data-pdf-bookmark="Adding Memory to StateGraph" data-type="sect1"><div class="sect1" id="ch04_adding_memory_to_stategraph_1736545668266831">
<h1>Adding Memory to StateGraph</h1>

<p>LangGraph<a contenteditable="false" data-primary="StateGraph" data-secondary="adding memory to" data-type="indexterm" id="SGmemory04"/><a contenteditable="false" data-primary="memory systems" data-secondary="adding memory to StateGraph" data-type="indexterm" id="MSaddingmemory04"/><a contenteditable="false" data-primary="LangGraph" data-secondary="adding memory to chatbots" data-type="indexterm" id="LGmemadd04"/><a contenteditable="false" data-primary="chatbots" data-secondary="adding memory to chatbots" data-type="indexterm" id="CBaddmem04"/> has built-in<a contenteditable="false" data-primary="persistence" data-type="indexterm" id="id665"/> persistence, which is used in the same way for the simplest graph to the most complex. Let’s see what it looks like to apply it to this first architecture. We’ll recompile our graph, now attaching a<a contenteditable="false" data-primary="checkpointers" data-type="indexterm" id="id666"/> <em>checkpointer</em>, which is a storage adapter for LangGraph. LangGraph ships with a base class that any user can subclass to create an adapter for their favorite database; at the time of writing, LangGraph ships with several adapters maintained by LangChain:</p>

<ul>
	<li>
	<p>An in-memory adapter, which we’ll use for our examples here</p>
	</li>
	<li>
	<p>A SQLite adapter, using the popular in-process database, appropriate for local apps and testing</p>
	</li>
	<li>
	<p>A Postgres adapter, optimized for the popular relational database and appropriate for large-scale applications.</p>
	</li>
</ul>

<p>Many developers have written adapters for other database systems, such as Redis or MySQL:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="StateGraph" data-tertiary="memory addition" data-type="indexterm" id="id667"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">langgraph.checkpoint.memory</code> <code class="kn">import</code> <code class="n">MemorySaver</code>

<code class="n">graph</code> <code class="o">=</code> <code class="n">builder</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">checkpointer</code><code class="o">=</code><code class="n">MemorySaver</code><code class="p">())</code></pre>

<p class="pagebreak-before less_space"><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="StateGraph" data-tertiary="memory addition" data-type="indexterm" id="id668"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">import</code> <code class="p">{</code><code class="nx">MemorySaver</code><code class="p">}</code> <code class="nx">from</code> <code class="s1">'@langchain/langgraph'</code>

<code class="kr">const</code> <code class="nx">graph</code> <code class="o">=</code> <code class="nx">builder</code><code class="p">.</code><code class="nx">compile</code><code class="p">({</code> <code class="nx">checkpointer</code><code class="o">:</code> <code class="k">new</code> <code class="nx">MemorySaver</code><code class="p">()</code> <code class="p">})</code></pre>

<p>This returns a runnable object with the same methods as the one used in the previous code block. But now, it stores the state at the end of each step, so every invocation after the first doesn’t start from a blank slate. Any time the graph is called, it starts by using the checkpointer to fetch the most recent saved state, if any, and combines the new input with the previous state. And only then does it execute the first nodes.</p>

<p>Let’s see the difference in action:</p>

<p><em>Python</em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">thread1</code> <code class="o">=</code> <code class="p">{</code><code class="s2">"configurable"</code><code class="p">:</code> <code class="p">{</code><code class="s2">"thread_id"</code><code class="p">:</code> <code class="s2">"1"</code><code class="p">}}</code>
<code class="n">result_1</code> <code class="o">=</code> <code class="n">graph</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code>
    <code class="p">{</code> <code class="s2">"messages"</code><code class="p">:</code> <code class="p">[</code><code class="n">HumanMessage</code><code class="p">(</code><code class="s2">"hi, my name is Jack!"</code><code class="p">)]</code> <code class="p">},</code> 
    <code class="n">thread1</code>
<code class="p">)</code>
<code class="o">//</code> <code class="p">{</code> <code class="s2">"chatbot"</code><code class="p">:</code> <code class="p">{</code> <code class="s2">"messages"</code><code class="p">:</code> <code class="p">[</code><code class="n">AIMessage</code><code class="p">(</code><code class="s2">"How can I help you, Jack?"</code><code class="p">)]</code> <code class="p">}</code> <code class="p">}</code>

<code class="n">result_2</code> <code class="o">=</code> <code class="n">graph</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code>
    <code class="p">{</code> <code class="s2">"messages"</code><code class="p">:</code> <code class="p">[</code><code class="n">HumanMessage</code><code class="p">(</code><code class="s2">"what is my name?"</code><code class="p">)]</code> <code class="p">},</code> 
    <code class="n">thread1</code>
<code class="p">)</code>
<code class="o">//</code> <code class="p">{</code> <code class="s2">"chatbot"</code><code class="p">:</code> <code class="p">{</code> <code class="s2">"messages"</code><code class="p">:</code> <code class="p">[</code><code class="n">AIMessage</code><code class="p">(</code><code class="s2">"Your name is Jack"</code><code class="p">)]</code> <code class="p">}</code> <code class="p">}</code></pre>

<p><em>JavaScript</em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">const</code> <code class="nx">thread1</code> <code class="o">=</code> <code class="p">{</code><code class="nx">configurable</code><code class="o">:</code> <code class="p">{</code><code class="nx">thread_id</code><code class="o">:</code> <code class="s1">'1'</code><code class="p">}}</code>
<code class="kr">const</code> <code class="nx">result_1</code> <code class="o">=</code> <code class="nx">await</code> <code class="nx">graph</code><code class="p">.</code><code class="nx">invoke</code><code class="p">(</code>
  <code class="p">{</code> <code class="s2">"messages"</code><code class="o">:</code> <code class="p">[</code><code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">(</code><code class="s2">"hi, my name is Jack!"</code><code class="p">)]</code> <code class="p">},</code>
  <code class="nx">thread1</code>
<code class="p">)</code>
<code class="c1">// { "chatbot": { "messages": [AIMessage("How can I help you, Jack?")] } }</code>

<code class="kr">const</code> <code class="nx">result_2</code> <code class="o">=</code> <code class="nx">await</code> <code class="nx">graph</code><code class="p">.</code><code class="nx">invoke</code><code class="p">(</code>
  <code class="p">{</code> <code class="s2">"messages"</code><code class="o">:</code> <code class="p">[</code><code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">(</code><code class="s2">"what is my name?"</code><code class="p">)]</code> <code class="p">},</code>
  <code class="nx">thread1</code>
<code class="p">)</code>
<code class="c1">// { "chatbot": { "messages": [AIMessage("Your name is Jack")] } }</code></pre>

<p>Notice the object <code>thread1</code>, which identifies the current interaction as belonging to a particular history of interactions—which are called<a contenteditable="false" data-primary="threads" data-type="indexterm" id="id669"/> <em>threads</em> in LangGraph. Threads are created automatically when first used. Any string is a valid identifier for a thread<a contenteditable="false" data-primary="Universally Unique Identifiers (UUIDs)" data-type="indexterm" id="id670"/> (usually, Universally Unique Identifiers [UUIDs] are used). The existence of threads helps you achieve an important milestone in your LLM application; it can now be used by multiple users with independent conversations that are never mixed up.</p>

<p>As before, the <code>chatbot</code> node is first called with a single message (the one we just passed in) and returns another message, both of which are then saved in the state.</p>

<p>The second time we execute the graph on the same thread, the <code>chatbot</code> node is called with three messages, the two saved from the first execution, and the next question from the user. This is the essence of memory: the previous state is still there, which makes it possible, for instance, to answer questions about something said before (and do many more interesting things, of which we will see more later).</p>

<p>You can also inspect and update the state directly; let’s see how:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="state inspection and updating" data-type="indexterm" id="id671"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">graph</code><code class="o">.</code><code class="n">get_state</code><code class="p">(</code><code class="n">thread1</code><code class="p">)</code></pre>

<p><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="state inspection and updating" data-type="indexterm" id="id672"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="nx">await</code> <code class="nx">graph</code><code class="p">.</code><code class="nx">getState</code><code class="p">(</code><code class="nx">thread1</code><code class="p">)</code></pre>

<p>This returns the current state of this thread.</p>

<p>And you can update the state like this:</p>

<p><em>Python</em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">graph</code><code class="o">.</code><code class="n">update_state</code><code class="p">(</code><code class="n">thread1</code><code class="p">,</code> <code class="p">[</code><code class="n">HumanMessage</code><code class="p">(</code><code class="s1">'I like LLMs!)])</code></pre>

<p><em>JavaScript</em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="nx">await</code> <code class="nx">graph</code><code class="p">.</code><code class="nx">updateState</code><code class="p">(</code><code class="nx">thread1</code><code class="p">,</code> <code class="p">[</code><code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">(</code><code class="err">'</code><code class="nx">I</code> <code class="nx">like</code> <code class="nx">LLMs</code><code class="o">!</code><code class="p">)])</code></pre>

<p>This would add one more message to the list of messages in the state, to be used the next time you invoke the graph on this thread.<a contenteditable="false" data-startref="MSaddingmemory04" data-type="indexterm" id="id673"/><a contenteditable="false" data-startref="SGmemory04" data-type="indexterm" id="id674"/><a contenteditable="false" data-primary="" data-startref="CBaddmem04" data-type="indexterm" id="id675"/><a contenteditable="false" data-primary="" data-startref="LGmemadd04" data-type="indexterm" id="id676"/></p>
</div></section>

<section data-pdf-bookmark="Modifying Chat History" data-type="sect1"><div class="sect1" id="ch04_modifying_chat_history_1736545668266898">
<h1>Modifying Chat History</h1>

<p>In<a contenteditable="false" data-primary="LangGraph" data-secondary="modifying chat history" data-type="indexterm" id="LGmod04"/><a contenteditable="false" data-primary="chatbots" data-secondary="modifying chat history" data-type="indexterm" id="CBhist04"/><a contenteditable="false" data-primary="chatbots" data-secondary="conversation history" data-type="indexterm" id="CBconhist04"/> many cases, the chat history messages aren’t in the best state or format to generate an accurate response from the model. To overcome this problem, we can modify the chat history in three main ways: trimming, filtering, and merging messages.</p>

<section data-pdf-bookmark="Trimming Messages" data-type="sect2"><div class="sect2" id="ch04_trimming_messages_1736545668266970">
<h2>Trimming Messages</h2>

<p>LLMs have<a contenteditable="false" data-primary="messages" data-secondary="trimming" data-type="indexterm" id="Mtrim04"/><a contenteditable="false" data-primary="trimming messages" data-type="indexterm" id="trimmes04"/><a contenteditable="false" data-primary="context windows" data-type="indexterm" id="id677"/> limited <em>context windows</em>; in other words, there is a maximum number of tokens that LLMs can receive as a prompt. As such, the final prompt sent to the model shouldn’t exceed that limit (particular to each mode), as models will either refuse an overly long prompt or truncate it. In addition, excessive prompt information can distract the model and lead to<a contenteditable="false" data-primary="hallucinations" data-type="indexterm" id="id678"/> hallucination.</p>

<p class="pagebreak-before less_space">An effective solution to this problem is to limit the number of messages that are retrieved from chat history and appended to the prompt. In practice, we need only to load and store the most recent messages. Let’s use an example chat history with some preloaded messages.</p>

<p>Fortunately, LangChain provides the built-in <code>trim_messages</code> helper that incorporates various strategies to meet these requirements. For example, the trimmer helper enables specifying how many tokens we want to keep or remove from chat history.</p>

<p>Here’s an example that retrieves the last <code>max_tokens</code> in the list of messages by setting a strategy parameter to <code>"last"</code>:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="messages" data-tertiary="trimming" data-type="indexterm" id="id679"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">langchain_core.messages</code> <code class="kn">import</code> <code class="n">SystemMessage</code><code class="p">,</code> <code class="n">trim_messages</code>
<code class="kn">from</code> <code class="nn">langchain_openai</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>

<code class="n">trimmer</code> <code class="o">=</code> <code class="n">trim_messages</code><code class="p">(</code>
    <code class="n">max_tokens</code><code class="o">=</code><code class="mi">65</code><code class="p">,</code>
    <code class="n">strategy</code><code class="o">=</code><code class="s2">"last"</code><code class="p">,</code>
    <code class="n">token_counter</code><code class="o">=</code><code class="n">ChatOpenAI</code><code class="p">(</code><code class="n">model</code><code class="o">=</code><code class="s2">"gpt-4o"</code><code class="p">),</code>
    <code class="n">include_system</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code>
    <code class="n">allow_partial</code><code class="o">=</code><code class="kc">False</code><code class="p">,</code>
    <code class="n">start_on</code><code class="o">=</code><code class="s2">"human"</code><code class="p">,</code>
<code class="p">)</code>

<code class="n">messages</code> <code class="o">=</code> <code class="p">[</code>
    <code class="n">SystemMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"you're a good assistant"</code><code class="p">),</code>
    <code class="n">HumanMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"hi! I'm bob"</code><code class="p">),</code>
    <code class="n">AIMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"hi!"</code><code class="p">),</code>
    <code class="n">HumanMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"I like vanilla ice cream"</code><code class="p">),</code>
    <code class="n">AIMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"nice"</code><code class="p">),</code>
    <code class="n">HumanMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"what's 2 + 2"</code><code class="p">),</code>
    <code class="n">AIMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"4"</code><code class="p">),</code>
    <code class="n">HumanMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"thanks"</code><code class="p">),</code>
    <code class="n">AIMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"no problem!"</code><code class="p">),</code>
    <code class="n">HumanMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"having fun?"</code><code class="p">),</code>
    <code class="n">AIMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="s2">"yes!"</code><code class="p">),</code>
<code class="p">]</code>

<code class="n">trimmer</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="n">messages</code><code class="p">)</code></pre>

<p><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="messages" data-tertiary="trimming" data-type="indexterm" id="id680"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">import</code> <code class="p">{</code>
  <code class="nx">AIMessage</code><code class="p">,</code>
  <code class="nx">HumanMessage</code><code class="p">,</code>
  <code class="nx">SystemMessage</code><code class="p">,</code>
  <code class="nx">trimMessages</code><code class="p">,</code>
<code class="p">}</code> <code class="nx">from</code> <code class="s2">"@langchain/core/messages"</code><code class="p">;</code>
<code class="kr">import</code> <code class="p">{</code> <code class="nx">ChatOpenAI</code> <code class="p">}</code> <code class="nx">from</code> <code class="s2">"@langchain/openai"</code><code class="p">;</code>

<code class="kr">const</code> <code class="nx">trimmer</code> <code class="o">=</code> <code class="nx">trimMessages</code><code class="p">({</code>
  <code class="nx">maxTokens</code><code class="o">:</code> <code class="mi">65</code><code class="p">,</code>
  <code class="nx">strategy</code><code class="o">:</code> <code class="s2">"last"</code><code class="p">,</code>
  <code class="nx">tokenCounter</code><code class="o">:</code> <code class="k">new</code> <code class="nx">ChatOpenAI</code><code class="p">({</code> <code class="nx">modelName</code><code class="o">:</code> <code class="s2">"gpt-4o"</code> <code class="p">}),</code>
  <code class="nx">includeSystem</code><code class="o">:</code> <code class="kc">true</code><code class="p">,</code>
  <code class="nx">allowPartial</code><code class="o">:</code> <code class="kc">false</code><code class="p">,</code>
  <code class="nx">startOn</code><code class="o">:</code> <code class="s2">"human"</code><code class="p">,</code>
<code class="p">});</code>

<code class="kr">const</code> <code class="nx">messages</code> <code class="o">=</code> <code class="p">[</code>
  <code class="k">new</code> <code class="nx">SystemMessage</code><code class="p">(</code><code class="s2">"you're a good assistant"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">(</code><code class="s2">"hi! I'm bob"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">AIMessage</code><code class="p">(</code><code class="s2">"hi!"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">(</code><code class="s2">"I like vanilla ice cream"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">AIMessage</code><code class="p">(</code><code class="s2">"nice"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">(</code><code class="s2">"what's 2 + 2"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">AIMessage</code><code class="p">(</code><code class="s2">"4"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">(</code><code class="s2">"thanks"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">AIMessage</code><code class="p">(</code><code class="s2">"no problem!"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">(</code><code class="s2">"having fun?"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">AIMessage</code><code class="p">(</code><code class="s2">"yes!"</code><code class="p">),</code>
<code class="p">]</code>

<code class="kr">const</code> <code class="nx">trimmed</code> <code class="o">=</code> <code class="nx">await</code> <code class="nx">trimmer</code><code class="p">.</code><code class="nx">invoke</code><code class="p">(</code><code class="nx">messages</code><code class="p">);</code></pre>

<p><em>The output:</em></p>

<pre data-type="programlisting">
[SystemMessage(content="you're a good assistant"),
 HumanMessage(content='what's 2 + 2'),
 AIMessage(content='4'),
 HumanMessage(content='thanks'),
 AIMessage(content='no problem!'),
 HumanMessage(content='having fun?'),
 AIMessage(content='yes!')]</pre>

<p>Note the following:</p>

<ul>
	<li>
	<p class="fix_tracking">The parameter <code>strategy</code> controls whether to start from the beginning or the end of the list. Usually, you’ll want to prioritize the most recent messages and cut older messages if they don’t fit. That is, start from the end of the list. For this behavior, choose the value <code>last</code>. The other available option is <code>first</code>, which would prioritize the oldest messages and cut more recent messages if they don’t fit.</p>
	</li>
	<li>
	<p>The <code>token_counter</code> is an LLM or chat model, which will be used to count tokens using the tokenizer appropriate to that model.</p>
	</li>
	<li>
	<p>We can add the parameter <code>include_system=True</code> to ensure that the trimmer keeps the system message.</p>
	</li>
	<li>
	<p>The parameter <code>allow_partial</code> determines whether to cut the last message’s content to fit within the limit. In our example, we set this to <code>false</code>, which completely removes the message that would send the total over the limit.</p>
	</li>
	<li>
	<p>The parameter <code>start_on="human"</code> ensures that we never remove an <code>AIMessage</code> (that is, a response from the model) without also removing a corresponding <code>HumanMessage</code> (the question for that response).<a contenteditable="false" data-primary="" data-startref="Mtrim04" data-type="indexterm" id="id681"/><a contenteditable="false" data-primary="" data-startref="trimmes04" data-type="indexterm" id="id682"/></p>
	</li>
</ul>
</div></section>

<section data-pdf-bookmark="Filtering Messages" data-type="sect2"><div class="sect2" id="ch04_filtering_messages_1736545668267036">
<h2>Filtering Messages</h2>

<p>As<a contenteditable="false" data-primary="messages" data-secondary="filtering" data-type="indexterm" id="Mfilter04"/> the list of chat history messages grows, a wider variety of types, subchains, and models may be utilized. LangChain’s <code>filter_messages</code> helper makes it easier to filter the chat history messages by type, ID, or name.</p>

<p>Here’s an example where we filter for human messages:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="messages" data-tertiary="filtering" data-type="indexterm" id="id683"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">langchain_core.messages</code> <code class="kn">import</code> <code class="p">(</code>
    <code class="n">AIMessage</code><code class="p">,</code>
    <code class="n">HumanMessage</code><code class="p">,</code>
    <code class="n">SystemMessage</code><code class="p">,</code>
    <code class="n">filter_messages</code><code class="p">,</code>
<code class="p">)</code>

<code class="n">messages</code> <code class="o">=</code> <code class="p">[</code>
    <code class="n">SystemMessage</code><code class="p">(</code><code class="s2">"you are a good assistant"</code><code class="p">,</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"1"</code><code class="p">),</code>
    <code class="n">HumanMessage</code><code class="p">(</code><code class="s2">"example input"</code><code class="p">,</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"2"</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"example_user"</code><code class="p">),</code>
    <code class="n">AIMessage</code><code class="p">(</code><code class="s2">"example output"</code><code class="p">,</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"3"</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"example_assistant"</code><code class="p">),</code>
    <code class="n">HumanMessage</code><code class="p">(</code><code class="s2">"real input"</code><code class="p">,</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"4"</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"bob"</code><code class="p">),</code>
    <code class="n">AIMessage</code><code class="p">(</code><code class="s2">"real output"</code><code class="p">,</code> <code class="nb">id</code><code class="o">=</code><code class="s2">"5"</code><code class="p">,</code> <code class="n">name</code><code class="o">=</code><code class="s2">"alice"</code><code class="p">),</code>
<code class="p">]</code>

<code class="n">filter_messages</code><code class="p">(</code><code class="n">messages</code><code class="p">,</code> <code class="n">include_types</code><code class="o">=</code><code class="s2">"human"</code><code class="p">)</code></pre>

<p><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="messages" data-tertiary="filtering" data-type="indexterm" id="id684"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">import</code> <code class="p">{</code>
  <code class="nx">HumanMessage</code><code class="p">,</code>
  <code class="nx">SystemMessage</code><code class="p">,</code>
  <code class="nx">AIMessage</code><code class="p">,</code>
  <code class="nx">filterMessages</code><code class="p">,</code>
<code class="p">}</code> <code class="nx">from</code> <code class="s2">"@langchain/core/messages"</code><code class="p">;</code>

<code class="kr">const</code> <code class="nx">messages</code> <code class="o">=</code> <code class="p">[</code>
  <code class="k">new</code> <code class="nx">SystemMessage</code><code class="p">({</code><code class="nx">content</code><code class="o">:</code> <code class="s2">"you are a good assistant"</code><code class="p">,</code> <code class="nx">id</code><code class="o">:</code> <code class="s2">"1"</code><code class="p">}),</code>
  <code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">({</code><code class="nx">content</code><code class="o">:</code> <code class="s2">"example input"</code><code class="p">,</code> <code class="nx">id</code><code class="o">:</code> <code class="s2">"2"</code><code class="p">,</code> <code class="nx">name</code><code class="o">:</code> <code class="s2">"example_user"</code><code class="p">}),</code>
  <code class="k">new</code> <code class="nx">AIMessage</code><code class="p">({</code><code class="nx">content</code><code class="o">:</code> <code class="s2">"example output"</code><code class="p">,</code> <code class="nx">id</code><code class="o">:</code> <code class="s2">"3"</code><code class="p">,</code> <code class="nx">name</code><code class="o">:</code> <code class="s2">"example_assistant"</code><code class="p">}),</code>
  <code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">({</code><code class="nx">content</code><code class="o">:</code> <code class="s2">"real input"</code><code class="p">,</code> <code class="nx">id</code><code class="o">:</code> <code class="s2">"4"</code><code class="p">,</code> <code class="nx">name</code><code class="o">:</code> <code class="s2">"bob"</code><code class="p">}),</code>
  <code class="k">new</code> <code class="nx">AIMessage</code><code class="p">({</code><code class="nx">content</code><code class="o">:</code> <code class="s2">"real output"</code><code class="p">,</code> <code class="nx">id</code><code class="o">:</code> <code class="s2">"5"</code><code class="p">,</code> <code class="nx">name</code><code class="o">:</code> <code class="s2">"alice"</code><code class="p">}),</code>
<code class="p">];</code>

<code class="nx">filterMessages</code><code class="p">(</code><code class="nx">messages</code><code class="p">,</code> <code class="p">{</code> <code class="nx">includeTypes</code><code class="o">:</code> <code class="p">[</code><code class="s2">"human"</code><code class="p">]</code> <code class="p">});</code></pre>

<p class="pagebreak-before less_space"><em>The output:</em></p>

<pre data-type="programlisting">
[HumanMessage(content='example input', name='example_user', id='2'),
 HumanMessage(content='real input', name='bob', id='4')]</pre>

<p>Let’s try another example where we filter to exclude users and IDs, and include message types:</p>

<p><em>Python</em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">filter_messages</code><code class="p">(</code><code class="n">messages</code><code class="p">,</code> <code class="n">exclude_names</code><code class="o">=</code><code class="p">[</code><code class="s2">"example_user"</code><code class="p">,</code> <code class="s2">"example_assistant"</code><code class="p">])</code>

<code class="sd">"""</code>
<code class="sd">[SystemMessage(content='you are a good assistant', id='1'),</code>
<code class="sd">HumanMessage(content='real input', name='bob', id='4'),</code>
<code class="sd">AIMessage(content='real output', name='alice', id='5')]</code>
<code class="sd">"""</code>

<code class="n">filter_messages</code><code class="p">(</code>
    <code class="n">messages</code><code class="p">,</code> 
    <code class="n">include_types</code><code class="o">=</code><code class="p">[</code><code class="n">HumanMessage</code><code class="p">,</code> <code class="n">AIMessage</code><code class="p">],</code> 
    <code class="n">exclude_ids</code><code class="o">=</code><code class="p">[</code><code class="s2">"3"</code><code class="p">]</code>
<code class="p">)</code>

<code class="sd">"""</code>
<code class="sd">[HumanMessage(content='example input', name='example_user', id='2'),</code>
<code class="sd"> HumanMessage(content='real input', name='bob', id='4'),</code>
<code class="sd"> AIMessage(content='real output', name='alice', id='5')]</code>
<code class="sd">"""</code></pre>

<p><em>JavaScript</em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="nx">filterMessages</code><code class="p">(</code>
  <code class="nx">messages</code><code class="p">,</code> 
  <code class="p">{</code> <code class="nx">excludeNames</code><code class="o">:</code> <code class="p">[</code><code class="s2">"example_user"</code><code class="p">,</code> 
  <code class="s2">"example_assistant"</code><code class="p">]</code> <code class="p">}</code>
<code class="p">);</code>

<code class="cm">/*</code>
<code class="cm">[SystemMessage(content='you are a good assistant', id='1'),</code>
<code class="cm">HumanMessage(content='real input', name='bob', id='4'),</code>
<code class="cm">AIMessage(content='real output', name='alice', id='5')]</code>
<code class="cm">*/</code>

<code class="nx">filterMessages</code><code class="p">(</code><code class="nx">messages</code><code class="p">,</code> <code class="p">{</code> <code class="nx">includeTypes</code><code class="o">:</code> <code class="p">[</code><code class="s2">"human"</code><code class="p">,</code> <code class="s2">"ai"</code><code class="p">],</code> <code class="nx">excludeIds</code><code class="o">:</code> <code class="p">[</code><code class="s2">"3"</code><code class="p">]</code> <code class="p">});</code>

<code class="cm">/*</code>
<code class="cm">[HumanMessage(content='example input', name='example_user', id='2'),</code>
<code class="cm"> HumanMessage(content='real input', name='bob', id='4'),</code>
<code class="cm"> AIMessage(content='real output', name='alice', id='5')]</code>
<code class="cm">*/</code></pre>

<p class="pagebreak-before less_space">The <code>filter_messages</code> helper can also be used imperatively or declaratively, making it easy to compose with other components in a chain:</p>

<p><em>Python</em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">model</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">()</code>

<code class="n">filter_</code> <code class="o">=</code> <code class="n">filter_messages</code><code class="p">(</code><code class="n">exclude_names</code><code class="o">=</code><code class="p">[</code><code class="s2">"example_user"</code><code class="p">,</code> <code class="s2">"example_assistant"</code><code class="p">])</code>

<code class="n">chain</code> <code class="o">=</code> <code class="n">filter_</code> <code class="o">|</code> <code class="n">model</code></pre>

<p><em>JavaScript</em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">const</code> <code class="nx">model</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">ChatOpenAI</code><code class="p">()</code>

<code class="kr">const</code> <code class="nx">filter</code> <code class="o">=</code> <code class="nx">filterMessages</code><code class="p">({</code>
  <code class="nx">excludeNames</code><code class="o">:</code> <code class="p">[</code><code class="s2">"example_user"</code><code class="p">,</code> <code class="s2">"example_assistant"</code><code class="p">]</code>
<code class="p">})</code>

<code class="kr">const</code> <code class="nx">chain</code> <code class="o">=</code> <code class="nx">filter</code><code class="p">.</code><code class="nx">pipe</code><code class="p">(</code><code class="nx">model</code><code class="p">)</code></pre>
</div></section>

<section data-pdf-bookmark="Merging Consecutive Messages" data-type="sect2"><div class="sect2" id="ch04_merging_consecutive_messages_1736545668267098">
<h2>Merging Consecutive Messages</h2>

<p class="fix_tracking">Certain<a contenteditable="false" data-primary="" data-startref="Mfilter04" data-type="indexterm" id="id685"/><a contenteditable="false" data-primary="messages" data-secondary="merging" data-type="indexterm" id="Mmerg04"/> models don’t support inputs, including consecutive messages of the same type (for instance, Anthropic chat models). LangChain’s <span class="keep-together"><code>merge_message_runs</code></span> utility makes it easy to merge consecutive messages of the same type:</p>

<p><em>Python<a contenteditable="false" data-primary="Python" data-secondary="messages" data-tertiary="merging" data-type="indexterm" id="id686"/></em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="kn">from</code> <code class="nn">langchain_core.messages</code> <code class="kn">import</code> <code class="p">(</code>
    <code class="n">AIMessage</code><code class="p">,</code>
    <code class="n">HumanMessage</code><code class="p">,</code>
    <code class="n">SystemMessage</code><code class="p">,</code>
    <code class="n">merge_message_runs</code><code class="p">,</code>
<code class="p">)</code>

<code class="n">messages</code> <code class="o">=</code> <code class="p">[</code>
    <code class="n">SystemMessage</code><code class="p">(</code><code class="s2">"you're a good assistant."</code><code class="p">),</code>
    <code class="n">SystemMessage</code><code class="p">(</code><code class="s2">"you always respond with a joke."</code><code class="p">),</code>
    <code class="n">HumanMessage</code><code class="p">(</code>
        <code class="p">[{</code><code class="s2">"type"</code><code class="p">:</code> <code class="s2">"text"</code><code class="p">,</code> <code class="s2">"text"</code><code class="p">:</code> <code class="s2">"i wonder why it's called langchain"</code><code class="p">}]</code>
    <code class="p">),</code>
    <code class="n">HumanMessage</code><code class="p">(</code><code class="s2">"and who is harrison chasing anyway"</code><code class="p">),</code>
    <code class="n">AIMessage</code><code class="p">(</code>
        <code class="sd">'''Well, I guess they thought "WordRope" and "SentenceString" just </code>
<code class="sd">        didn\'t have the same ring to it!'''</code>
    <code class="p">),</code>
    <code class="n">AIMessage</code><code class="p">(</code><code class="s2">"""Why, he's probably chasing after the last cup of coffee in the </code>
<code class="s2">        office!"""</code><code class="p">),</code>
<code class="p">]</code>

<code class="n">merge_message_runs</code><code class="p">(</code><code class="n">messages</code><code class="p">)</code></pre>

<p><em>JavaScript<a contenteditable="false" data-primary="JavaScript" data-secondary="messages" data-tertiary="merging" data-type="indexterm" id="id687"/></em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">import</code> <code class="p">{</code>
  <code class="nx">HumanMessage</code><code class="p">,</code>
  <code class="nx">SystemMessage</code><code class="p">,</code>
  <code class="nx">AIMessage</code><code class="p">,</code>
  <code class="nx">mergeMessageRuns</code><code class="p">,</code>
<code class="p">}</code> <code class="nx">from</code> <code class="s2">"@langchain/core/messages"</code><code class="p">;</code>

<code class="kr">const</code> <code class="nx">messages</code> <code class="o">=</code> <code class="p">[</code>
  <code class="k">new</code> <code class="nx">SystemMessage</code><code class="p">(</code><code class="s2">"you're a good assistant."</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">SystemMessage</code><code class="p">(</code><code class="s2">"you always respond with a joke."</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">({</code>
    <code class="nx">content</code><code class="o">:</code> <code class="p">[{</code> <code class="nx">type</code><code class="o">:</code> <code class="s2">"text"</code><code class="p">,</code> <code class="nx">text</code><code class="o">:</code> <code class="s2">"i wonder why it's called langchain"</code> <code class="p">}],</code>
  <code class="p">}),</code>
  <code class="k">new</code> <code class="nx">HumanMessage</code><code class="p">(</code><code class="s2">"and who is harrison chasing anyway"</code><code class="p">),</code>
  <code class="k">new</code> <code class="nx">AIMessage</code><code class="p">(</code>
    <code class="sb">`Well, I guess they thought "WordRope" and "SentenceString" just didn</code><code class="err">\</code><code class="sb">'t </code>
<code class="sb">      have the same ring to it!`</code>
  <code class="p">),</code>
  <code class="k">new</code> <code class="nx">AIMessage</code><code class="p">(</code>
    <code class="s2">"Why, he's probably chasing after the last cup of coffee in the office!"</code>
  <code class="p">),</code>
<code class="p">];</code>

<code class="nx">mergeMessageRuns</code><code class="p">(</code><code class="nx">messages</code><code class="p">);</code></pre>

<p><em>The output:</em></p>

<pre data-type="programlisting">
[SystemMessage(content="you're a good assistant.\nyou always respond with a 
    joke."),
 HumanMessage(content=[{'type': 'text', 'text': "i wonder why it's called
    langchain"}, 'and who is harrison chasing anyway']),
 AIMessage(content='Well, I guess they thought "WordRope" and "SentenceString" 
    just didn\'t have the same ring to it!\nWhy, he\'s probably chasing after 
    the last cup of coffee in the office!')]</pre>

<p>Notice that if the contents of one of the messages to merge is a list of content blocks, then the merged message will have a list of content blocks. And if both messages to merge have string contents, then those are concatenated with a newline character.</p>

<p>The <code>merge_message_runs</code> helper can be used imperatively or declaratively, making it easy to compose with other components in a chain:</p>

<p><em>Python</em></p>

<pre data-code-language="python" data-type="programlisting">
<code class="n">model</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">()</code>
<code class="n">merger</code> <code class="o">=</code> <code class="n">merge_message_runs</code><code class="p">()</code>
<code class="n">chain</code> <code class="o">=</code> <code class="n">merger</code> <code class="o">|</code> <code class="n">model</code></pre>

<p class="pagebreak-before less_space"><em>JavaScript</em></p>

<pre data-code-language="javascript" data-type="programlisting">
<code class="kr">const</code> <code class="nx">model</code> <code class="o">=</code> <code class="k">new</code> <code class="nx">ChatOpenAI</code><code class="p">()</code>
<code class="kr">const</code> <code class="nx">merger</code> <code class="o">=</code> <code class="nx">mergeMessageRuns</code><code class="p">()</code>
<code class="kr">const</code> <code class="nx">chain</code> <code class="o">=</code> <code class="nx">merger</code><code class="p">.</code><code class="nx">pipe</code><code class="p">(</code><code class="nx">model</code><code class="p">)</code></pre>
</div></section>
</div></section>

<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="ch04_summary_1736545668267155">
<h1>Summary</h1>

<p>This<a contenteditable="false" data-primary="" data-startref="LGmod04" data-type="indexterm" id="id688"/><a contenteditable="false" data-primary="" data-startref="CBhist04" data-type="indexterm" id="id689"/><a contenteditable="false" data-primary="" data-startref="Mmerg04" data-type="indexterm" id="id690"/><a contenteditable="false" data-primary="" data-startref="CBconhist04" data-type="indexterm" id="id691"/> chapter covered the fundamentals of building a simple memory system that enables your AI chatbot to remember its conversations with a user. We discussed how to automate the storage and updating of chat history using LangGraph to make this easier. We also discussed the importance of modifying chat history and explored various strategies to trim, filter, and summarize chat messages.</p>

<p>In <a data-type="xref" href="ch05.html#ch05_cognitive_architectures_with_langgraph_1736545670030774">Chapter 5</a>, you’ll learn how to enable your AI chatbot to do more than just chat back: for instance, your new model will be able to make decisions, pick actions, and reflect on its past outputs.</p>
</div></section>
</div></section></body></html>