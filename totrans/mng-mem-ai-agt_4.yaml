- en: 'Chapter 4\. Navigating Agent Trade-Offs: Custom Builds, Frameworks, and Hosted
    Solutions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Digital organizations shift the primary focus of integration from the systems
    to the capabilities, emphasizing clean interfaces over those capabilities.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Brandon Byars
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Whether you are an insurance company or a startup, the fundamental considerations
    at the start of the process of deploying an AI agent are largely the same: build
    versus buy, frameworks versus customization, and of course, cost and scalability
    concerns. If these trade-offs and considerations sound familiar, they should.
    Despite AI agents being a wholly new category of technology, their *fundamentals*
    are those of most software products. That should give us heart because we have
    decades of precedent upon which we can rely to build resilient solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Developer’s Dilemma: Framework Versus Custom Architecture'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Not all projects involving or centered around AI agents require the same tooling
    considerations. Ultimately, the choice between, say, using LangGraph to build
    out an agent and turning to a hosted service such as Glean AI comes down to one
    thing: scope. Is the project you’re about to undertake existential to your company’s
    future, or is it experimental and exploratory? How much data will you need to
    ingest and process regularly? Will your initial user base begin as large or small?
    Is this purely an internal tool, or will it be customer facing? Does your company
    already have a robust infrastructure supporting AI agents, or is this project
    the first of its kind? All of these questions and more must be, if not answered,
    at least understood in order to reasonably select a proper AI agent architecture
    for your project.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-1](#ch04_figure_1_1758256567994933) shows a helpful decision framework
    for considering some of the most common questions that arise when considering
    the build-versus-buy decision for AI agents.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram of an AI agent architecture decision grid, showing pros and cons
    for using custom build, framework, or hosted solution across different use case
    scenarios.](assets/mmai_0401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-1\. AI agent architecture decision framework
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: But a simple chart only scratches the surface of the complexities involved.
    The following three sections break down the case for build, the case for frameworks,
    and the case for hosted solutions respectively.
  prefs: []
  type: TYPE_NORMAL
- en: The Case for Build
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Whether to build from scratch is likely the most consequential decision you
    can make when starting an AI agent project. It demands significant resources,
    both in labor and capital. However, it offers unmatched control, and if agents
    are core to your business, there’s no better decision you can make. Here are a
    few considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: “If it’s a core business function—do it yourself no matter what.”
  prefs: []
  type: TYPE_NORMAL
- en: This time-tested principle from Joel Spolsky’s classic essay on build-versus-buy
    decisions is especially relevant for AI agents. When AI becomes core to your competitive
    advantage, frameworks and hosted solutions can turn into strategic liabilities
    by limiting your ability to differentiate and iterate rapidly.^([1](ch04.html#id74))
  prefs: []
  type: TYPE_NORMAL
- en: Unparalleled flexibility and customization
  prefs: []
  type: TYPE_NORMAL
- en: 'When you build AI agents from scratch, you’re limited only by the ability of
    your engineers to code the system you desire and the availability of the integrations
    you hope to access. This empowers unique and specific solutions to your business
    problems and software systems that most frameworks will be unable to match. Consider
    this: the more bespoke software systems you have in place, the less likely an
    open source framework will meet all your needs.'
  prefs: []
  type: TYPE_NORMAL
- en: The AI agent becomes more valuable as it becomes more extensible
  prefs: []
  type: TYPE_NORMAL
- en: The entire point of the AI agent revolution isn’t simply that AI agents are
    dynamic chatbots—it’s that their dynamism extends to their ability to call and
    access tools. But as Brandon Byars notes in his essay “You Can’t Buy Integration,”
    we shouldn’t think of this as merely “connecting systems together, or sharing
    data to keep systems in sync.” The real goal is to create “clean interfaces between
    capabilities” that drive organizational agility. For AI agents, this distinction
    is foundational to the agility they enable organizations to achieve. When you
    build from scratch, you have complete control over how these interfaces are designed
    and optimized. As Byars states, success should be measured “by increasing digital
    agility over time,” where “those digital capabilities become the primary value
    driver, arguably even more important than the systems themselves.”^([2](ch04.html#id75))
  prefs: []
  type: TYPE_NORMAL
- en: Performance and cost optimization at scale
  prefs: []
  type: TYPE_NORMAL
- en: 'While not every company should build its own foundational models or infrastructure,
    there’s a compelling economic case for custom AI agents as usage scales. External
    services typically charge per API call or token, meaning costs grow linearly (or
    worse) with success. Custom builds flip this equation: after the initial development
    investment, increased usage often reduces per-interaction costs through economies
    of scale. Your infrastructure costs become more predictable and controllable,
    and performance can be optimized specifically for your use patterns rather than
    generic workloads. For companies expecting high-volume AI agent interactions,
    this cost-structure advantage can become substantial over time.'
  prefs: []
  type: TYPE_NORMAL
- en: The Case for Frameworks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using frameworks to build agents is often the best starting point for new projects.
    If you’re new to agents, frameworks provide guidance through up-to-date documentation,
    state-of-the-art capabilities, and fast iteration. If you’re more experienced,
    frameworks still help you build quickly and gather feedback for proof-of-concept
    work. Here’s a breakdown of their main benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Accelerated development and prototyping
  prefs: []
  type: TYPE_NORMAL
- en: 'When you are building an AI agent, start with the fundamentals: what is the
    project scope? If scope remains unclear but stakeholder demos are critical, consider
    established frameworks like LangGraph, AutoGen, and CrewAI, which have quick tutorials
    on building agents zero-to-one on their websites. Remember, you can always refactor
    code from a framework to a customization. But it’s much more difficult to refactor
    the other way around—from a customization to a framework.'
  prefs: []
  type: TYPE_NORMAL
- en: Lower barrier to entry
  prefs: []
  type: TYPE_NORMAL
- en: 'The greatest benefit of a good framework is its lower barrier to entry—that’s
    the whole point of an abstraction. What’s easier: building a car from scratch
    or buying one premade? The same logic applies to AI agents. If your team is new
    to agents, it’s much wiser to leverage a prewritten open source framework that
    thousands of people have tried, tested, and kicked the tires on.'
  prefs: []
  type: TYPE_NORMAL
- en: Encapsulation of best practices
  prefs: []
  type: TYPE_NORMAL
- en: So long as you are careful, frameworks will be the encapsulation of industry
    best practices. In the best-case scenario, adopting a modern, popular framework
    will put you in an advantageous position to leverage proven patterns and tools.
    But be careful in your choice of frameworks. Always scope out the potential use
    cases for your AI agent. Ask any seasoned developer about the pains of having
    chosen (or been forced into) the wrong framework—suddenly, a simple integration
    turns into weeks of work that could have been written manually in hours.
  prefs: []
  type: TYPE_NORMAL
- en: The Case for Hosted Solutions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Hosted solutions are arguably the most straightforward cases to consider. If
    your organization lacks robust experience or infrastructure to build AI agents,
    they’re usually a safe bet:'
  prefs: []
  type: TYPE_NORMAL
- en: Fastest time to value
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to zero-to-one deployments of an AI system, you’re usually not
    going to get faster results than a hosted solution. Hosted platforms such as Glean
    or Cognigy focus solely on providing customers with the ability to deploy agents
    with minimal overhead. Cloud providers such as Amazon Web Services (AWS), Google
    Cloud, and Azure all offer their own versions of agent platforms that, while typically
    requiring more intensive work, will more easily integrate into existing enterprise
    cloud networks.
  prefs: []
  type: TYPE_NORMAL
- en: No infrastructure overhead
  prefs: []
  type: TYPE_NORMAL
- en: The primary value of hosted solutions is the lack of infrastructure management
    required. For every hour spent managing infrastructure, users could be focusing
    on core tasks that drive business value instead.
  prefs: []
  type: TYPE_NORMAL
- en: Professional support and service-level agreements (SLAs)
  prefs: []
  type: TYPE_NORMAL
- en: Most hosted solutions include professional support and SLAs that severely derisk
    the reliance on such tools, especially by enterprise staff who have less experience
    with generative AI and machine learning engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous updates and improvements
  prefs: []
  type: TYPE_NORMAL
- en: These solutions regularly enhance their features and product offerings, soliciting
    feedback from their user base to maintain feature parity with the competition
    and to retain best practices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Designing for the Future: Preventing Architectural and Vendor Lock-In'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the allure of rapid deployment and expansive capabilities makes AI vendor
    solutions attractive, understanding how these systems create dependencies is crucial
    for maintaining long-term flexibility and control over your technology stack.
  prefs: []
  type: TYPE_NORMAL
- en: The Nature of AI Lock-In
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are many manifestations and flavors of vendor lock-in. Here are three
    of the most common:'
  prefs: []
  type: TYPE_NORMAL
- en: Proprietary model APIs
  prefs: []
  type: TYPE_NORMAL
- en: Some API designs require you to code around certain frameworks and specifications
    that are vendor and framework specific and are not adopted industrywide. Avoid
    this if you can. The only appropriate time is if you are in a niche industry or
    require niche data that simply cannot be returned another way.
  prefs: []
  type: TYPE_NORMAL
- en: Nonexportable fine-tuned models
  prefs: []
  type: TYPE_NORMAL
- en: Some vendors provide the option to fine-tune models on their systems but do
    not provide the option to export their model weights in hopes you will simply
    use their APIs. This can come up when resource-constrained companies look for
    quick fixes but can leave your IP held hostage.
  prefs: []
  type: TYPE_NORMAL
- en: Integrated data and memory systems
  prefs: []
  type: TYPE_NORMAL
- en: By far the most consequential lock-in occurs in the storage of critical data
    on external AI vendor systems—data such as conversation histories, user metadata,
    and vector embeddings for memory. Migrating this data can become costly because
    of substantial egress fees, technical challenges, and even the inability to host
    that data on your own systems.
  prefs: []
  type: TYPE_NORMAL
- en: These lock-in phenomena are not mutually exclusive, nor are they collectively
    exhaustive. Only by planning ahead can you mitigate these risks effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Architectural Strategies for Portability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Beyond understanding lock-in risks, successful organizations implement concrete
    architectural patterns that preserve flexibility while still leveraging the power
    of modern AI services:'
  prefs: []
  type: TYPE_NORMAL
- en: Modularity and abstraction
  prefs: []
  type: TYPE_NORMAL
- en: The most effective strategy to avoid vendor lock-in (and overcomplexity) is
    to design agent systems with modular, composable architectures. This enables easy
    swapping between different vendors or even between external vendors and nascent
    and growing internal services that could eventually replace the vendors altogether.
    The easiest way to achieve this is to build abstractions around vendor APIs such
    that the internal API remains consistent and agnostic to the external API call.
    Such an abstraction can serve as, say, a generative AI (GenAI) chat-completion
    service that is able to route its calls dynamically between GPT-5, Sonnet 4, and
    an internally hosted model. If your organization later decided to switch models
    from Anthropic to, say, Google Gemini, or even to abandon external LLMs altogether,
    only the internal GenAI service would need to be updated, while the core application
    code would remain unchanged.
  prefs: []
  type: TYPE_NORMAL
- en: Open standards
  prefs: []
  type: TYPE_NORMAL
- en: Whenever possible, reduce dependency risks by building on well-established standards
    and protocols rather than proprietary ones. This ensures greater interoperability
    between your systems and vendors. This does not mean you should integrate the
    bleeding edge of open source tooling—the field of GenAI is too tumultuous to lock
    yourself in. For example, while MCP has garnered a great deal of interest, there’s
    no guarantee it will become the industry norm. Balance innovation with stability.
  prefs: []
  type: TYPE_NORMAL
- en: Containerization
  prefs: []
  type: TYPE_NORMAL
- en: A tried-and-true method, containerization is one of the key architectural decisions
    a team can make to ensure flexibility and portability of their app—flexibility
    that can be used to avoid vendor lock-in. When we containerize an app, we encapsulate
    our entire application and its dependencies into a single portable unit. This
    container can then be deployed on almost any cloud platform (AWS, Google Cloud,
    Azure, etc.) or even on premises for those companies who anticipate their agents
    becoming central to their business. This approach maximizes deployment options
    and effectively decouples an agent application from its underlying host environment.
  prefs: []
  type: TYPE_NORMAL
- en: By leaning on the fundamentals of software engineering, teams can more confidently
    navigate the build-versus-buy decision space for AI agents. The key is to anchor
    decisions in the function of the agent and its strategic relevance to your business.
    If your goal is to run a quick proof of concept, a hosted solution offers a fast
    and low-risk path to user feedback. If you’re experimenting with new paradigms,
    agent frameworks provide a flexible and low-friction starting point. But if your
    company is committed to riding the agent wave for the long haul, it’s essential
    to start with a framework, iterate quickly, and then graduate to your own custom
    stack—one that protects your independence and positions you for long-term agility
    and control.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch04.html#id74-marker)) Joel Spolsky, “In Defense of Not-Invented-Here
    Syndrome,” Joel on Software, October 14, 2001, [*https://www.joelonsoftware.com/2001/10/14/in-defense-of-not-invented-here-syndrome*](https://www.joelonsoftware.com/2001/10/14/in-defense-of-not-invented-here-syndrome).
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch04.html#id75-marker)) Brandon Byars, “You Can’t Buy Integration,” MartinFowler.com,
    December 14, 2021, [*https://martinfowler.com/articles/cant-buy-integration.html*](https://martinfowler.com/articles/cant-buy-integration.html).
  prefs: []
  type: TYPE_NORMAL
