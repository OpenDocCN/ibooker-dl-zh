- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: What I cannot create, I do not understand.
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “我不能创造的东西，我就不理解。”
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Richard Feynman
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 理查德·费曼
- en: Generative AI is one of the most revolutionary technologies of our time, transforming
    the way we interact with machines. Its potential to revolutionize the way we live,
    work, and play has been the subject of countless conversations, debates, and predictions.
    But what if there was an even greater potential to this powerful technology? What
    if the possibilities of generative AI extend beyond our current imagination? The
    future of generative AI may be more exciting than we ever thought possible…​
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能是我们这个时代最具革命性的技术之一，改变了我们与机器互动的方式。它有潜力彻底改变我们生活、工作和娱乐的方式，已经成为无数对话、辩论和预测的主题。但如果这种强大技术还有更大的潜力呢？生成式人工智能的可能性是否超出了我们当前的想象？生成式人工智能的未来可能比我们想象的更令人兴奋...
- en: Since our earliest days, we have sought opportunities to generate original and
    beautiful creations. For early humans, this took the form of cave paintings depicting
    wild animals and abstract patterns, created with pigments placed carefully and
    methodically onto rock. The Romantic Era gave us the mastery of Tchaikovsky symphonies,
    with their ability to inspire feelings of triumph and tragedy through sound waves,
    woven together to form beautiful melodies and harmonies. And in recent times,
    we have found ourselves rushing to bookshops at midnight to buy stories about
    a fictional wizard, because the combination of letters creates a narrative that
    wills us to turn the page and find out what happens to our hero.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 自我们早期以来，我们一直在寻找创造原创和美丽作品的机会。对早期人类来说，这体现在洞穴壁画上，描绘着野生动物和抽象图案，用谨慎和有条不紊地放置在岩石上的颜料创作而成。浪漫主义时代赋予我们柴可夫斯基交响曲的掌握，通过声波激发胜利和悲剧感情的能力，编织在一起形成美丽的旋律和和谐。最近，我们发现自己在午夜赶往书店购买关于虚构巫师的故事，因为字母的组合创造了一个叙述，激励我们翻开页面，看看我们的英雄会发生什么。
- en: 'It is therefore not surprising that humanity has started to ask the ultimate
    question of creativity: can we create something that is in itself creative?'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，毫不奇怪，人类已经开始提出创造力的终极问题：我们能否创造出本身具有创造力的东西？
- en: This is the question that generative AI aims to answer. With recent advances
    in methodology and technology, we are now able to build machines that can paint
    original artwork in a given style, write coherent blocks of text with long-term
    structure, compose music that is pleasant to listen to, and develop winning strategies
    for complex games by generating imaginary future scenarios. This is just the start
    of a generative revolution that will leave us with no choice but to find answers
    to some of the biggest questions about the mechanics of creativity, and ultimately,
    what it means to be human.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是生成式人工智能试图回答的问题。随着方法和技术的最新进展，我们现在能够构建能够以给定风格绘制原创艺术作品、写出有长期结构的连贯文本块、创作令人愉悦的音乐，以及通过生成虚构未来场景来制定复杂游戏的获胜策略的机器。这只是生成式革命的开始，将迫使我们不得不寻找关于创造力机制的一些最大问题的答案，最终，这意味着什么是人类。
- en: In short, there has never been a better time to learn about generative AI—so
    let’s get started!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，现在学习生成式人工智能再也没有比现在更好的时机了，所以让我们开始吧！
- en: Objective and Approach
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标和方法
- en: This book assumes no prior knowledge of generative AI. We will build up all
    of the key concepts from scratch in a way that is intuitive and easy to follow,
    so don’t worry if you have no experience with generative AI. You have come to
    the right place!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书假设读者对生成式人工智能没有先前的知识。我们将从头开始逐步建立所有关键概念，以一种直观易懂的方式进行讲解，所以如果你对生成式人工智能没有经验也不用担心。你来对地方了！
- en: 'Rather than only covering the techniques that are currently in vogue, this
    book serves as a complete guide to generative modeling that covers a broad range
    of model families. There is no one technique that is objectively *better* or *worse*
    than any other—in fact, many state-of-the-art models now mix together ideas from
    across the broad spectrum of approaches to generative modeling. For this reason,
    it is important to keep abreast of developments across all areas of generative
    AI, rather than focusing on one particular kind of technique. One thing is certain:
    the field of generative AI is moving fast, and you never know where the next groundbreaking
    idea will come from!'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本书不仅涵盖当前流行的技术，还作为生成建模的完整指南，涵盖了广泛的模型系列。没有一种技术在客观上比其他技术更好或更差——事实上，许多最先进的模型现在混合了来自生成建模各种方法的想法。因此，重要的是要及时了解生成式人工智能各个领域的发展，而不是专注于某一种特定的技术。有一点是肯定的：生成式人工智能领域发展迅速，你永远不知道下一个突破性想法将从何而来！
- en: With this in mind, the approach I will take is to show you how to train your
    own generative models on your own data, rather than relying on pre-trained off-the-shelf
    models. While there are now many impressive open source generative models that
    can be downloaded and run in a few lines of code, the aim of this book is to dig
    deeper into their architecture and design from first principles, so that you gain
    a complete understanding of how they work and can code up examples of each technique
    from scratch using Python and Keras.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，我将采取的方法是向您展示如何在自己的数据上训练自己的生成模型，而不是依赖预训练的现成模型。虽然现在有许多令人印象深刻的开源生成模型可以下载并在几行代码中运行，但本书的目的是从第一原则深入挖掘它们的架构和设计，以便您完全了解它们的工作原理，并可以使用Python和Keras从头开始编写每种技术的示例。
- en: In summary, this book can be thought of as a map of the current generative AI
    landscape that covers both theory and practical applications, including full working
    examples of key models from the literature. We will walk through the code for
    each step by step, with clear signposts that show how the code implements the
    theory underpinning each technique. This book can be read cover to cover or used
    as a reference book that you can dip into. Above all, I hope you find it a useful
    and enjoyable read!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，这本书可以被看作是当前生成式人工智能领域的地图，涵盖了理论和实际应用，包括文献中关键模型的完整工作示例。我们将逐步演示每个步骤的代码，清晰地标明代码如何实现支撑每种技术的理论。这本书可以从头到尾阅读，也可以作为您随时查阅的参考书。最重要的是，我希望您觉得这本书有用且愉快！
- en: Note
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Throughout the book, you will find short, allegorical stories that help explain
    the mechanics of some of the models we will be building. I believe that one of
    the best ways to teach a new abstract theory is to first convert it into something
    that isn’t quite so abstract, such as a story, before diving into the technical
    explanation. The story and the model explanation are just the same mechanics explained
    in two different domains—you might therefore find it useful to refer back to the
    relevant story while learning about the technical details of each model!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，您将找到一些简短的寓言故事，帮助解释我们将构建的一些模型的机制。我认为教授新的抽象理论的最佳方法之一是首先将其转化为不那么抽象的东西，比如一个故事，然后再深入技术解释。故事和模型解释只是在两个不同领域中解释相同机制，因此在学习每个模型的技术细节时，参考相关故事可能会很有帮助！
- en: Prerequisites
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 先决条件
- en: This book assumes that you have experience coding in Python. If you are not
    familiar with Python, the best place to start is through [LearnPython.org](https://www.learnpython.org).
    There are many free resources online that will allow you to develop enough Python
    knowledge to work with the examples in this book.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书假定您有Python编程经验。如果您对Python不熟悉，最好的起点是通过[LearnPython.org](https://www.learnpython.org)开始。在线有许多免费资源，可以让您掌握足够的Python知识，以便使用本书中的示例。
- en: Also, since some of the models are described using mathematical notation, it
    will be useful to have a solid understanding of linear algebra (for example, matrix
    multiplication) and general probability theory. A useful resource is Deisenroth
    et al.’s book [*Mathematics for Machine Learning*](https://mml-book.com) (Cambridge
    University Press), which is freely available.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，由于一些模型使用数学符号描述，对线性代数（例如矩阵乘法）和一般概率论有扎实的理解将会很有帮助。一本有用的资源是Deisenroth等人的书籍[*Mathematics
    for Machine Learning*](https://mml-book.com)（剑桥大学出版社），可以免费获取。
- en: The book assumes no prior knowledge of generative modeling (we will examine
    the key concepts in [Chapter 1](ch01.xhtml#chapter_generative_modelling)) or TensorFlow
    and Keras (these libraries will be introduced in [Chapter 2](ch02.xhtml#chapter_deep_learning)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本书假定您对生成建模（我们将在[第一章](ch01.xhtml#chapter_generative_modelling)中探讨关键概念）或TensorFlow和Keras没有先验知识（这些库将在[第二章](ch02.xhtml#chapter_deep_learning)中介绍）。
- en: Roadmap
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 路线图
- en: This book is divided into three parts.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书分为三个部分。
- en: '[Part I](part01.xhtml#part_introduction) is a general introduction to generative
    modeling and deep learning, where we explore the core concepts that underpin all
    of the techniques in later parts of the book:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[第一部分](part01.xhtml#part_introduction)是生成建模和深度学习的一般介绍，我们在其中探讨了贯穿本书后续部分所有技术的核心概念：'
- en: In [Chapter 1, “Generative Modeling”](ch01.xhtml#chapter_generative_modelling),
    we define generative modeling and consider a toy example that we can use to understand
    some of the key concepts that are important to all generative models. We also
    lay out the taxonomy of generative model families that we will explore in [Part II](part02.xhtml#part_methods)
    of this book.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第一章，“生成建模”](ch01.xhtml#chapter_generative_modelling)中，我们定义生成建模，并考虑一个玩具示例，我们可以用来理解一些对所有生成模型都重要的关键概念。我们还列出了我们将在本书的[第二部分](part02.xhtml#part_methods)中探索的生成模型家族的分类法。
- en: In [Chapter 2, “Deep Learning”](ch02.xhtml#chapter_deep_learning), we begin
    our exploration of deep learning and neural networks by building our first example
    of a multilayer perceptron (MLP) using Keras. We then adapt this to include convolutional
    layers and other improvements, to observe the difference in performance.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第二章，“深度学习”](ch02.xhtml#chapter_deep_learning)中，我们通过使用Keras构建我们的第一个多层感知器（MLP）来开始探索深度学习和神经网络。然后，我们将其调整以包括卷积层和其他改进，以观察性能上的差异。
- en: '[Part II](part02.xhtml#part_methods) walks through the six key techniques that
    we will be using to build generative models, with practical examples for each:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[第二部分](part02.xhtml#part_methods)介绍了我们将用于构建生成模型的六种关键技术，每种技术都有实际示例：'
- en: In [Chapter 3, “Variational Autoencoders”](ch03.xhtml#chapter_vae), we consider
    the variational autoencoder (VAE) and see how it can be used to generate images
    of faces and morph between faces in the model’s latent space.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第三章，“变分自编码器”](ch03.xhtml#chapter_vae)中，我们考虑变分自编码器（VAE），看看它如何用于生成人脸图像，并在模型的潜在空间中在人脸之间进行变形。
- en: In [Chapter 4, “Generative Adversarial Networks”](ch04.xhtml#chapter_gan), we
    explore generative adversarial networks (GANs) for image generation, including
    deep convolutional GANs, conditional GANs, and improvements such as the Wasserstein
    GAN that make the training process more stable.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第四章，“生成对抗网络”](ch04.xhtml#chapter_gan)中，我们探索生成对抗网络（GAN）用于图像生成，包括深度卷积GAN，条件GAN以及改进的Wasserstein
    GAN，使训练过程更加稳定。
- en: In [Chapter 5, “Autoregressive Models”](ch05.xhtml#chapter_autoregressive),
    we turn our attention to autoregressive models, starting with an introduction
    to recurrent neural networks such as long short-term memory networks (LSTMs) for
    text generation and PixelCNN for image generation.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[第五章，“自回归模型”](ch05.xhtml#chapter_autoregressive)中，我们将注意力转向自回归模型，从介绍循环神经网络（如长短期记忆网络（LSTM））开始，用于文本生成，以及用于图像生成的PixelCNN。
- en: In [Chapter 6, “Normalizing Flow Models”](ch06.xhtml#chapter_flow), we focus
    on normalizing flows, including an intuitive theoretical exploration of the technique
    and a practical example of how to build a RealNVP model to generate images.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第6章“归一化流模型”中，我们专注于归一化流，包括对该技术的直观理论探索以及如何构建 RealNVP 模型生成图像的实际示例。
- en: In [Chapter 7, “Energy-Based Models”](ch07.xhtml#chapter_energy_based_models),
    we cover energy-based models, including important methods such as how to train
    using contrastive divergence and sample using Langevin dynamics.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第7章“基于能量的模型”中，我们涵盖了基于能量的模型，包括如何使用对比散度进行训练以及如何使用 Langevin 动力学进行采样等重要方法。
- en: In [Chapter 8, “Diffusion Models”](ch08.xhtml#chapter_diffusion), we dive into
    a practical guide to building diffusion models, which drive many state-of-the-art
    image generation models such as DALL.E 2 and Stable Diffusion.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第8章“扩散模型”中，我们深入探讨了构建扩散模型的实用指南，这些模型驱动着许多最先进的图像生成模型，如 DALL.E 2 和 Stable Diffusion。
- en: 'Finally, in [Part III](part03.xhtml#part_applications) we build on these foundations
    to explore the inner workings of state-of-the-art models for image generation,
    writing, composing music, and model-based reinforcement learning:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在第三部分中，我们基于这些基础探索了最先进的图像生成、写作、音乐创作和基于模型的强化学习模型的内部运作：
- en: In [Chapter 9, “Transformers”](ch09.xhtml#chapter_transformer), we explore the
    lineage and technical details of the StyleGAN models, as well as other state-of-the-art
    GANs for image generation such as VQ-GAN.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第9章“变压器”中，我们探讨了 StyleGAN 模型的渊源和技术细节，以及其他用于图像生成的最先进 GANs，如 VQ-GAN。
- en: In [Chapter 10, “Advanced GANs”](ch10.xhtml#chapter_image_generation), we consider
    the Transformer architecture, including a practical walkthrough for building your
    own version of GPT for text generation.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第10章“高级 GANs”中，我们考虑了 Transformer 架构，包括一个实用的指南，教你如何构建自己的 GPT 版本用于文本生成。
- en: In [Chapter 11, “Music Generation”](ch11.xhtml#chapter_music), we turn our attention
    to music generation, including a guide to working with music data and application
    of techniques such as Transformers and MuseGAN.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第11章“音乐生成”中，我们将注意力转向音乐生成，包括如何处理音乐数据以及应用技术如 Transformers 和 MuseGAN 的指南。
- en: In [Chapter 12, “World Models”](ch12.xhtml#chapter_world_models), we see how
    generative models can be used in the context of reinforcement learning, with the
    application of world models and Transformer-based methods.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第12章“世界模型”中，我们看到生成模型如何在强化学习的背景下使用，应用世界模型和基于 Transformer 的方法。
- en: In [Chapter 13, “Multimodal Models”](ch13.xhtml#chapter_multimodal), we explain
    the inner workings of four state-of-the-art multimodal models that incorporate
    more than one type of data, including DALL.E 2, Imagen, and Stable Diffusion for
    text-to-image generation and Flamingo, a visual language model.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第13章“多模态模型”中，我们解释了四种最先进的多模态模型的内部运作，这些模型结合了多种类型的数据，包括 DALL.E 2、Imagen 和 Stable
    Diffusion 用于文本到图像生成以及 Flamingo，一种视觉语言模型。
- en: In [Chapter 14, “Conclusion”](ch14.xhtml#chapter_conclusion), we recap the key
    milestones of generative AI to date and discuss the ways in which generative AI
    will revolutionize our daily lives in years to come.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第14章“结论”中，我们回顾了迄今为止生成式人工智能的关键里程碑，并讨论了生成式人工智能将如何在未来几年彻底改变我们的日常生活方式。
- en: Changes in the Second Edition
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二版的变化
- en: Thank you to everyone who read the first edition of this book—I am really pleased
    that so many of you have found it a useful resource and provided feedback on things
    that you would like to see in the second edition. The field of generative deep
    learning has progressed significantly since the first edition was published in
    2019, so as well as refreshing the existing content I have added several new chapters
    to bring the material in line with the current state of the art.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢所有阅读本书第一版的人们——我很高兴看到这么多人发现它是一个有用的资源，并提供了关于第二版中希望看到的内容的反馈。自2019年第一版出版以来，生成式深度学习领域取得了显著进展，因此除了更新现有内容外，我还添加了几个新章节，以使材料与当前的最新技术保持一致。
- en: 'The following is a summary of the main updates, in terms of the individual
    chapters and general book improvements:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于各个章节和整体书籍改进的主要更新摘要：
- en: '[Chapter 1](ch01.xhtml#chapter_generative_modelling) now includes a section
    on the different families of generative models and a taxonomy of how they are
    related.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第1章现在包括了有关不同生成模型家族的部分以及它们之间关系的分类法。
- en: '[Chapter 2](ch02.xhtml#chapter_deep_learning) contains improved diagrams and
    more detailed explanations of key concepts.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第2章包含了改进的图表和更详细的关键概念解释。
- en: '[Chapter 3](ch03.xhtml#chapter_vae) is refreshed with a new worked example
    and accompanying explanations.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第3章通过一个新的实例和相关解释进行了更新。
- en: '[Chapter 4](ch04.xhtml#chapter_gan) now includes an explanation of conditional
    GAN architectures.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第4章现在包括了对条件 GAN 架构的解释。
- en: '[Chapter 5](ch05.xhtml#chapter_autoregressive) now includes a section on autoregressive
    models for images (e.g., PixelCNN).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第5章现在包括了有关图像自回归模型（例如 PixelCNN）的部分。
- en: '[Chapter 6](ch06.xhtml#chapter_flow) is an entirely new chapter, describing
    the RealNVP model.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第6章是一个全新的章节，描述了 RealNVP 模型。
- en: '[Chapter 7](ch07.xhtml#chapter_energy_based_models) is also a new chapter,
    focusing on techniques such as Langevin dynamics and contrastive divergence.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7章也是一个新章节，重点介绍了诸如 Langevin 动力学和对比散度等技术。
- en: '[Chapter 8](ch08.xhtml#chapter_diffusion) is a newly written chapter on denoising
    the diffusion models that power many of today’s state-of-the-art applications.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第8章是一个新撰写的章节，介绍了驱动当今许多最先进应用的去噪扩散模型。
- en: '[Chapter 9](ch09.xhtml#chapter_transformer) is an expansion of the material
    provided in the conclusion of the first edition, with deeper focus on architectures
    of the various StyleGAN models and new material on VQ-GAN.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第9章](ch09.xhtml#chapter_transformer)是第一版结尾提供的材料的扩展，更深入地关注了各种StyleGAN模型的架构以及关于VQ-GAN的新材料。'
- en: '[Chapter 10](ch10.xhtml#chapter_image_generation) is a new chapter that explores
    the Transformer architecture in detail.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第10章](ch10.xhtml#chapter_image_generation)是一个探索Transformer架构细节的新章节。'
- en: '[Chapter 11](ch11.xhtml#chapter_music) includes modern Transformer architectures,
    replacing the LSTM models from the first edition.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第11章](ch11.xhtml#chapter_music)包括现代Transformer架构，取代了第一版中的LSTM模型。'
- en: '[Chapter 12](ch12.xhtml#chapter_world_models) includes updated diagrams and
    descriptions, with a section on how this approach is informing state-of-the-art
    reinforcement learning today.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第12章](ch12.xhtml#chapter_world_models)包括更新的图表和描述，其中有一节介绍了这种方法如何影响当今最先进的强化学习。'
- en: '[Chapter 13](ch13.xhtml#chapter_multimodal) is a new chapter that explains
    in detail how impressive models like DALL.E 2, Imagen, Stable Diffusion, and Flamingo
    work.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第13章](ch13.xhtml#chapter_multimodal)是一个新章节，详细解释了像DALL.E 2、Imagen、Stable Diffusion和Flamingo这样令人印象深刻的模型是如何工作的。'
- en: '[Chapter 14](ch14.xhtml#chapter_conclusion) is updated to reflect the outstanding
    progress in the field since the first edition and give a more complete and detailed
    view of where generative AI is heading in the future.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第14章](ch14.xhtml#chapter_conclusion)已更新，以反映自第一版以来该领域取得的杰出进展，并更全面详细地展示生成式人工智能未来的发展方向。'
- en: All comments given as feedback to the first edition and typos identified have
    been addressed (to the best of my knowledge!).
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有对第一版的反馈和发现的拼写错误都已经得到了解决（尽我所知！）。
- en: Chapter goals have been added at the start of each chapter, so that you can
    see the key topics covered in the chapter before you start reading.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每章的开头都添加了章节目标，这样您在开始阅读之前就可以看到章节涵盖的关键主题。
- en: Some of the allegorical stories have been rewritten to be more concise and clear—I
    am pleased that so many readers have said that the stories have helped them to
    better understand the key concepts!
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些寓言故事已经被重新编写，更加简洁和清晰——我很高兴许多读者说这些故事帮助他们更好地理解关键概念！
- en: The headings and subheadings of each chapter have been aligned so that is it
    clear which parts of the chapter are focused on explanation and which are focused
    on building your own models.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每章的标题和副标题都已对齐，以便清楚地显示章节中哪些部分是解释重点，哪些部分是关于构建自己模型的重点。
- en: Other Resources
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他资源
- en: 'I highly recommend the following books as general introductions to machine
    learning and deep learning:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我强烈推荐以下书籍作为机器学习和深度学习的一般介绍：
- en: '[*Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts,
    Tools, and Techniques to Build Intelligent Systems*](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781098125967)
    by Aurélien Géron (O’Reilly)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*使用Scikit-Learn、Keras和TensorFlow进行实践机器学习：构建智能系统的概念、工具和技术*](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781098125967)
    by Aurélien Géron（O’Reilly）'
- en: '*Deep Learning with Python* by Francois Chollet (Manning)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《Python深度学习》* by Francois Chollet（Manning）'
- en: Most of the papers in this book are sourced through [arXiv](https://arxiv.org),
    a free repository of scientific research papers. It is now common for authors
    to post papers to arXiv before they are fully peer-reviewed. Reviewing the recent
    submissions is a great way to keep on top of the most cutting-edge developments
    in the field.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书中的大部分论文都是通过[arXiv](https://arxiv.org)获取的，这是一个免费的科学研究论文库。现在，作者们通常会在论文完全经过同行评审之前将论文发布到arXiv上。查看最新提交的论文是了解该领域最前沿发展的绝佳方式。
- en: I also highly recommend the website [Papers with Code](https://paperswithcode.com),
    where you can find the latest state-of-the-art results in a variety of machine
    learning tasks, alongside links to the papers and official GitHub repositories.
    It is an excellent resource for anyone wanting to quickly understand which techniques
    are currently achieving the highest scores in a range of tasks and has certainly
    helped me to decide which techniques to include in this book.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我还强烈推荐网站[Papers with Code](https://paperswithcode.com)，在那里您可以找到各种机器学习任务中最新的最先进结果，以及指向论文和官方GitHub存储库的链接。这是一个极好的资源，适合任何想快速了解当前哪些技术在各种任务中取得最高分数的人，并且肯定帮助我决定在本书中包含哪些技术。
- en: Conventions Used in This Book
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书中使用的约定
- en: 'The following typographical conventions are used in this book:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了以下排版约定：
- en: '*Italic*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*斜体*'
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 指示新术语、URL、电子邮件地址、文件名和文件扩展名。
- en: '`Constant width`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`等宽`'
- en: Used for commands and program listings, as well as within paragraphs to refer
    to program elements such as variable or function names.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 用于命令和程序清单，以及在段落中引用程序元素，如变量或函数名。
- en: '*`Constant width italic`*'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*`等宽斜体`*'
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 显示应该用用户提供的值或上下文确定的值替换的文本。
- en: Tip
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: This element signifies a tip or suggestion.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个元素表示一个提示或建议。
- en: Note
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This element signifies a general note.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个元素表示一个一般性说明。
- en: Warning
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: This element signifies a warning or caution.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这个元素表示一个警告或注意。
- en: Codebase
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码库
- en: The code examples in this book can be found in a GitHub [repository](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition).
    I have deliberately ensured that none of the models require prohibitively large
    amounts of computational resources to train, so that you can start training your
    own models without having to spend lots of time or money on expensive hardware.
    There is a comprehensive guide in the repository on how to get started with Docker
    and set up cloud resources with GPUs on Google Cloud if required.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的代码示例可以在GitHub [存储库](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition)中找到。我特意确保没有任何模型需要大量的计算资源来训练，这样您就可以开始训练自己的模型，而不必花费大量时间或金钱购买昂贵的硬件。如果需要，存储库中有一个全面的指南，介绍如何使用Docker开始以及如何在Google
    Cloud上设置带有GPU的云资源。
- en: 'The following changes have been made to the codebase since the first edition:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 自第一版以来，对代码库进行了以下更改：
- en: All examples are now runnable from within a single notebook, instead of some
    code being imported from modules across the codebase. This is so that you can
    run each example cell by cell and delve into exactly how each model is built,
    piece by piece.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在所有示例都可以在单个笔记本中运行，而不是从代码库中导入模块。这样您可以逐个单元格运行每个示例，并深入了解每个模型是如何逐步构建的。
- en: The sections of each notebook are now broadly aligned between examples.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个笔记本的部分现在在示例之间基本对齐。
- en: Many of the examples in this book now utilize code snippets from the amazing
    [open source Keras repository](https://oreil.ly/1UTwa)—this is to avoid creating
    a completely detached open source repository of Keras generative AI examples,
    when there already exist excellent implementations available through the Keras
    website. I have added references and links to the original authors of code that
    I have utilized from the Keras website throughout this book and in the repository.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书中的许多示例现在利用了来自惊人的[开源Keras存储库](https://oreil.ly/1UTwa)的代码片段，这是为了避免创建一个完全独立的Keras生成AI示例的开源存储库，因为Keras网站已经有了优秀的实现。我在整本书和存储库中添加了参考和链接，指向我从Keras网站中利用的代码的原始作者。
- en: I have added new data sources and improved the data collection process from
    the first edition—now, there is a script that can be easily run to collect data
    from the required sources in order to train the examples in the book, using tools
    such as the [Kaggle API](https://oreil.ly/8ibPw).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我添加了新的数据来源，并改进了第一版的数据收集过程——现在，有一个脚本可以轻松运行，从所需的来源收集数据，以便训练本书中的示例，使用诸如[Kaggle
    API](https://oreil.ly/8ibPw)之类的工具。
- en: Using Code Examples
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用代码示例
- en: Supplemental material (code examples, exercises, etc.) is available for download
    at [*https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition*](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 补充材料（代码示例、练习等）可在[*https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition*](https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition)下载。
- en: If you have a technical question or a problem using the code examples, please
    send email to [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有技术问题或在使用代码示例时遇到问题，请发送电子邮件至[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)。
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing examples
    from O’Reilly books does require permission. Answering a question by citing this
    book and quoting example code does not require permission. Incorporating a significant
    amount of example code from this book into your product’s documentation does require
    permission.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在帮助您完成工作。一般来说，如果本书提供了示例代码，您可以在程序和文档中使用它。除非您复制了代码的大部分内容，否则无需征得我们的许可。例如，编写一个使用本书中几个代码块的程序不需要许可。销售或分发O’Reilly图书中的示例需要许可。通过引用本书回答问题并引用示例代码不需要许可。将本书中大量示例代码合并到产品文档中需要许可。
- en: 'We appreciate, but do not require, attribution. An attribution usually includes
    the title, author, publisher, and ISBN. For example: “*Generative Deep Learning*,
    2nd edition, by David Foster (O’Reilly). Copyright 2023 Applied Data Science Partners
    Ltd., 978-1-098-13418-1.”'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢您的致谢，但不要求。致谢通常包括标题、作者、出版商和ISBN。例如：“*生成式深度学习*，第2版，作者David Foster（O’Reilly）。版权所有2023年应用数据科学合作伙伴有限公司，978-1-098-13418-1。”
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您认为您使用的代码示例超出了合理使用范围或上述许可，请随时联系我们[*permissions@oreilly.com*](mailto:permissions@oreilly.com)。
- en: O’Reilly Online Learning
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O’Reilly在线学习
- en: Note
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For more than 40 years, [*O’Reilly Media*](https://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[*O’Reilly Media*](https://oreilly.com)已经提供技术和商业培训、知识和见解，帮助公司取得成功超过40年。'
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*https://oreilly.com*](https://oreilly.com).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们独特的专家和创新者网络通过书籍、文章和我们的在线学习平台分享他们的知识和专长。O’Reilly的在线学习平台为您提供按需访问实时培训课程、深入学习路径、交互式编码环境以及来自O’Reilly和其他200多家出版商的大量文本和视频。欲了解更多信息，请访问[*https://oreilly.com*](https://oreilly.com)。
- en: How to Contact Us
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何联系我们
- en: 'Please address comments and questions concerning this book to the publisher:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 请将有关此书的评论和问题发送至出版商：
- en: O’Reilly Media, Inc.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: O’Reilly Media, Inc.
- en: 1005 Gravenstein Highway North
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1005 Gravenstein Highway North
- en: Sebastopol, CA 95472
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sebastopol, CA 95472
- en: 800-998-9938 (in the United States or Canada)
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 800-998-9938（美国或加拿大）
- en: 707-829-0515 (international or local)
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0515（国际或本地）
- en: 707-829-0104 (fax)
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0104（传真）
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/generative-dl*](https://oreil.ly/generative-dl).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为这本书制作了一个网页，列出勘误、示例和任何额外信息。您可以访问[*https://oreil.ly/generative-dl*](https://oreil.ly/generative-dl)查看这个页面。
- en: Email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com) to comment
    or ask technical questions about this book.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 发送电子邮件[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)评论或提出关于这本书的技术问题。
- en: For news and information about our books and courses, visit [*https://oreilly.com*](https://oreilly.com).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 有关我们的图书和课程的新闻和信息，请访问[*https://oreilly.com*](https://oreilly.com)。
- en: 'Find us on LinkedIn: [*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在LinkedIn上找到我们：[*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)
- en: 'Follow us on Twitter: [*https://twitter.com/oreillymedia*](https://twitter.com/oreillymedia)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在Twitter上关注我们：[*https://twitter.com/oreillymedia*](https://twitter.com/oreillymedia)
- en: 'Watch us on YouTube: [*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在YouTube上关注我们：[*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)
- en: Acknowledgments
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: There are so many people I would like to thank for helping me write this book.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多人我想要感谢他们帮助我写这本书。
- en: First, I would like to thank everyone who has taken time to technically review
    the book—in particular Vishwesh Ravi Shrimali, Lipi Deepaakshi Patnaik, Luba Elliot,
    and Lorna Barclay. Thanks also to Samir Bico for helping to review and test the
    codebase that accompanies this book. Your input has been invaluable.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我想感谢所有抽出时间来技术审查这本书的人，特别是Vishwesh Ravi Shrimali、Lipi Deepaakshi Patnaik、Luba
    Elliot和Lorna Barclay。还要感谢Samir Bico帮助审查和测试伴随这本书的代码库。你们的意见和建议是无价的。
- en: Also, a huge thanks to my colleagues at [Applied Data Science Partners](https://adsp.ai),
    Ross Witeszczak, Amy Bull, Ali Parandeh, Zine Eddine, Joe Rowe, Gerta Salillari,
    Aleshia Parkes, Evelina Kireilyte, Riccardo Tolli, Mai Do, Khaleel Syed, and Will
    Holmes. Your patience with me while I have taken time to finish the book is hugely
    appreciated, and I am greatly looking forward to all the machine learning projects
    we will complete together in the future! Particular thanks to Ross—had we not
    decided to start a business together, this book might never have taken shape,
    so thank you for believing in me as your business partner!
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，特别感谢我的同事们在[Applied Data Science Partners](https://adsp.ai)，Ross Witeszczak、Amy
    Bull、Ali Parandeh、Zine Eddine、Joe Rowe、Gerta Salillari、Aleshia Parkes、Evelina
    Kireilyte、Riccardo Tolli、Mai Do、Khaleel Syed和Will Holmes。感谢你们在我完成这本书时对我的耐心，我非常期待我们将来一起完成的所有机器学习项目！特别感谢Ross——如果我们没有决定一起创业，这本书可能永远不会成形，所以感谢你相信我作为你的商业伙伴！
- en: I also want to thank anyone who has ever taught me anything mathematical—I was
    extremely fortunate to have fantastic math teachers at school, who developed my
    interest in the subject and encouraged me to pursue it further at university.
    I would like to thank you for your commitment and for going out of your way to
    share your knowledge of the subject with me.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我还要感谢任何曾经教过我任何数学知识的人——我在学校非常幸运地有出色的数学老师，他们培养了我对这门学科的兴趣，并鼓励我在大学进一步深造。我要感谢你们的奉献和不辞辛劳地与我分享你们对这门学科的知识。
- en: A huge thank you goes to the staff at O’Reilly for guiding me through the process
    of writing this book. A special thanks goes to Michele Cronin, who has been there
    at each step, providing useful feedback and sending me friendly reminders to keep
    completing chapters! Also to Nicole Butterfield, Christopher Faucher, Charles
    Roumeliotis, and Suzanne Huston for getting the book into production, and Mike
    Loukides for first reaching out to ask if I’d be interested in writing a book.
    You have all been so supportive of this project from the start, and I want to
    thank you for providing me with a platform on which to write about something that
    I love.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 非常感谢O'Reilly的工作人员在引导我写这本书的过程中。特别感谢Michele Cronin，在每一步都在那里，提供有用的反馈并发送友好的提醒，让我继续完成章节！还要感谢Nicole
    Butterfield、Christopher Faucher、Charles Roumeliotis和Suzanne Huston将这本书制作出版，以及Mike
    Loukides首先联系我询问我是否有兴趣写书。你们从一开始就对这个项目非常支持，我要感谢你们为我提供一个平台，让我写我热爱的事物。
- en: Throughout the writing process, my family has been a constant source of encouragement
    and support. A huge thank you goes to my mum, Gillian Foster, for checking every
    single line of text for typos and for teaching me how to add up in the first place!
    Your attention to detail has been extremely helpful while proofreading this book,
    and I’m really grateful for all the opportunities that both you and dad have given
    me. My dad, Clive Foster, originally taught me how to program a computer—this
    book is full of practical examples, and that’s thanks to his early patience while
    I fumbled around in BASIC trying to make football games as a teenager. My brother,
    Rob Foster, is the most modest genius you will ever find, particularly within
    linguistics—chatting with him about AI and the future of text-based machine learning
    has been amazingly helpful. Last, I would like to thank my Nana, who was always
    a constant source of inspiration and fun for all of us. Her love of literature
    was one of the reasons I first decided that writing a book would be an exciting
    thing to do.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在写作过程中，我的家人一直是我不断鼓励和支持的源泉。非常感谢我的妈妈Gillian Foster，她检查了每一行文字中的拼写错误，并教会我如何首先进行加法运算！你的注重细节在校对这本书时非常有帮助，我真的很感激你和爸爸给予我的所有机会。我的爸爸Clive
    Foster最初教会了我如何编程——这本书充满了实用示例，这要归功于他在我十几岁时在BASIC中摸索时的耐心，试图制作足球游戏。我的哥哥Rob Foster是你能找到的最谦逊的天才，尤其在语言学领域——和他聊天关于人工智能和基于文本的机器学习的未来一直非常有帮助。最后，我要感谢我的奶奶，她一直是我们所有人的灵感和乐趣源泉。她对文学的热爱是我第一次决定写书会是一件令人兴奋的事情的原因之一。
- en: I would also like to thank my wife, Lorna Barclay. As well as providing me with
    endless support and cups of tea throughout the writing process, you have rigorously
    checked every word of this book in meticulous detail. I couldn’t have done it
    without you. Thank you for always being there for me, and for making this journey
    so much more enjoyable. I promise I won’t talk about generative AI at the dinner
    table for at least a few days after the book is published.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我还想感谢我的妻子Lorna Barclay。在写作过程中，除了给我无尽的支持和茶水外，你还细致地检查了这本书的每一个字。没有你，我无法完成这本书。感谢你一直在我身边，让这段旅程变得更加愉快。我保证在书出版后的几天内，我不会在餐桌上谈论生成式人工智能。
- en: Lastly, I would like to thank our beautiful baby daughter Alina for providing
    endless entertainment during the long nights of book-writing. Your adorable giggles
    have been the perfect background music to my typing. Thanks for being my inspiration
    and for always keeping me on my toes. You’re the real brains behind this operation.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我要感谢我们可爱的宝贝女儿Alina，在写书的漫长夜晚里给予无尽的娱乐。你可爱的笑声成为我打字时完美的背景音乐。谢谢你给予我的灵感，让我时刻保持警惕。你才是这次行动的真正智囊。
