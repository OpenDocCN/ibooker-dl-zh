- en: Capitolo 12\. Distribuzione dei servizi di intelligenza artificiale
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 12 章\. 人工智能服务分发
- en: 'Questo lavoro è stato tradotto utilizzando l''AI. Siamo lieti di ricevere il
    tuo feedback e i tuoi commenti: [translation-feedback@oreilly.com](mailto:translation-feedback@oreilly.com)'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作使用 AI 进行翻译。我们很高兴收到你的反馈和评论：[translation-feedback@oreilly.com](mailto:translation-feedback@oreilly.com)
- en: In questo capitolo finale, è il momento di completare la tua soluzione GenAI
    distribuendola. Go imparerà diverse strategie di distribuzione e, come parte della
    distribuzione, conterrà i suoi servizi con Docker seguendo le sue migliori pratiche.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后一章，是时候完成你的 GenAI 解决方案并通过分发来实现。Go 将学习多种分发策略，作为分发的一部分，它将遵循最佳实践使用 Docker
    来容器化其服务。
- en: Opzioni di distribuzione
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分发选项
- en: 'Ora hai un servizio GenAI funzionante che vuoi rendere accessibile ai tuoi
    utenti. Quali sono le opzioni di distribuzione? Ci sono alcune strategie di distribuzione
    comuni che puoi adattare per rendere le tue app accessibili agli utenti:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有一个正在运行的 GenAI 服务，你想要使其对你的用户可用。有哪些分发选项？有一些常见的分发策略你可以适应，以使你的应用程序对用户可用：
- en: Macchine virtuali (VM)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟机（VM）
- en: Funzioni serverless
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器功能
- en: Piattaforme applicative gestite
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理应用程序平台
- en: Containerizzazione
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器化
- en: Analizziamo ciascuno di essi in modo più dettagliato.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将更详细地分析每一个。
- en: Distribuzione su macchine virtuali
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 虚拟机上的分发
- en: Se intendi utilizzare i tuoi server on-premises o preferisci distribuire i tuoi
    servizi sullo stesso hardware che ospita le altre applicazioni per ottenere un
    elevato isolamento e sicurezza, puoi distribuire il tuo servizio GenAI in una
    VM.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算使用你的本地服务器，或者更愿意将你的服务部署在同一硬件上，以获得高隔离性和安全性，你可以将你的 GenAI 服务部署在一个虚拟机（VM）中。
- en: Una macchina virtuale è un'emulazione software di un computer fisico che esegue
    un sistema operativo (OS) e delle applicazioni. Non è diversa da un computer fisico
    come un laptop, uno smartphone o un server.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机是物理计算机的软件模拟，它运行操作系统（OS）和应用程序。它并不像笔记本电脑、智能手机或服务器这样的物理计算机。
- en: Il sistema *host* della VM fornisce risorse come CPU, memoria e storage, mentre
    un livello software chiamato *hypervisor* gestisce la VM e alloca le risorse dall'host
    alla VM. Le risorse che l'hypervisor alloca alla VM sono l'*hardware virtuale*
    su cui girano il sistema operativo e le applicazioni.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机的 *宿主* 系统提供 CPU、内存和存储等资源，而一个名为 *虚拟机管理程序* 的软件层管理虚拟机，并将资源从宿主机分配到虚拟机。虚拟机管理程序分配给虚拟机的资源是操作系统和应用程序运行的
    *虚拟硬件*。
- en: La macchina virtuale può essere eseguita direttamente sull'hardware dell'host
    (bare metal) o su un sistema operativo convenzionale (cioè essere ospitata). Di
    conseguenza, il sistema operativo installato all'interno della macchina virtuale
    viene chiamato *sistema operativo guest*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机可以直接在宿主机的硬件上运行（裸金属）或在一个常规操作系统（即托管）上运行。因此，虚拟机内部安装的操作系统被称为 *客户操作系统*。
- en: La[Figura 12-1](#deployment_vm_architecture) mostra l'architettura del sistema
    della tecnologia di virtualizzazione.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-1](#deployment_vm_architecture) 展示了虚拟化技术的系统架构。'
- en: '![bgai 1201](assets/bgai_1201.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1201](assets/bgai_1201.png)'
- en: Figura 12-1\. Architettura del sistema di virtualizzazione
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-1\. 虚拟化系统架构
- en: I provider Cloud o il tuo data center possono essere costituiti da diversi server
    fisici, ognuno dei quali ospita più macchine virtuali con il proprio sistema operativo
    guest e le proprie applicazioni ospitate. Per una condivisione delle risorse efficace
    dal punto di vista dei costi, queste macchine virtuali possono condividere la
    stessa unità di archiviazione fisica montata, anche se sono contenute in ambienti
    completamente isolati, come puoi vedere nella [Figura 12-2](#deployment_vm_data_center).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商或你的数据中心可能由多个物理服务器组成，每个服务器都托管多个虚拟机，每个虚拟机都有自己的客户操作系统和托管的应用程序。为了在成本方面有效共享资源，这些虚拟机可以共享同一个物理存储单元，即使它们被完全隔离的环境所包含，如图
    12-2 所示。
- en: '![bgai 1202](assets/bgai_1202.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 1202](assets/bgai_1202.png)'
- en: Figura 12-2\. Macchine virtuali ospitate in un data center
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-2\. 数据中心中的虚拟机
- en: Il vantaggio di usare una macchina virtuale è che hai accesso diretto al sistema
    operativo guest, alle risorse hardware virtuali e ai driver della GPU. Se ci sono
    problemi con l'implementazione, puoi connetterti alla macchina virtuale tramite
    il protocollo *Secure Shell Transfer* (SHH) per ispezionare i log dell'applicazione,
    impostare l'ambiente dell'applicazione e fare il debug dei problemi di produzione.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用虚拟机的优势在于，你可以直接访问客户操作系统、虚拟硬件资源和GPU驱动器。如果实施过程中出现问题，你可以通过*Secure Shell Transfer*（SSH）协议连接到虚拟机，检查应用程序日志、设置应用程序环境以及调试生产问题。
- en: Per distribuire i tuoi servizi sulle macchine virtuali è sufficiente clonare
    il repository del codice sulla macchina virtuale e installare le dipendenze, i
    pacchetti e i driver necessari per avviare con successo l'applicazione. Tuttavia,
    il metodo consigliato è quello di utilizzare una piattaforma di containerizzazione
    come Docker in esecuzione sulla macchina virtuale per consentire distribuzioni
    continue e altri vantaggi. Dovresti anche assicurarti di dimensionare le risorse
    della macchina virtuale in modo appropriato, in modo che i tuoi servizi non siano
    affamati di core CPU/GPU, memoria o spazio su disco.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要在虚拟机上部署你的服务，只需在虚拟机上克隆代码仓库并安装启动应用程序所需的依赖项、软件包和驱动器即可。然而，推荐的方法是使用运行在虚拟机上的容器化平台，如Docker，以实现持续部署和其他优势。你还应该确保适当地调整虚拟机的资源，以确保你的服务不会因为CPU/GPU核心、内存或磁盘空间而受限。
- en: Con le macchine virtuali on-premises puoi risparmiare sui costi di hosting on-cloud
    o di noleggio dei server e puoi proteggere completamente i tuoi ambienti applicativi
    per una manciata di utenti, isolati dalla rete internet pubblica. Questi vantaggi
    sono ottenibili anche con le macchine virtuali in cloud, ma richiedonouna configurazioneaggiuntiva
    delle reti e delle risorse da configurare. Inoltre, puoi avere accesso all'hardware
    delle GPU e configurare i driver per i requisiti delle tue applicazioni.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本地部署的虚拟机，你可以节省云托管或服务器租赁的成本，并可以完全保护你的应用环境，为少数用户提供一个隔离于公共互联网的网络环境。这些优势也可以通过云虚拟机获得，但需要额外的网络和资源配置配置。此外，你可以访问GPU硬件并配置满足你应用程序要求的驱动器。
- en: Tieni presente che l'utilizzo del modello di distribuzione VM potrebbe non essere
    facilmente scalabile e richiede un notevole sforzo di manutenzione. Inoltre, i
    server VM funzionano normalmente 24 ore su 24, 7 giorni su 7, comportando costi
    di gestione costanti, a meno che tu non ne automatizzi l'avvio e lo spegnimento
    in base alle tue esigenze. Sarai responsabile dell'applicazione delle patch di
    sicurezza, degli aggiornamenti del sistema operativo e degli aggiornamenti dei
    pacchetti, oltre che delle configurazioni di rete. Con l'accesso diretto alle
    risorse hardware, dovrai anche prendere un maggior numero di decisioni che possono
    rallentare la tua attività, portandoti alla stanchezza decisionale.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，使用虚拟机分布模型可能不太容易扩展，并且需要大量的维护工作。此外，虚拟机服务器通常每周7天，每天24小时运行，除非你根据需要自动化其启动和关闭，否则将产生持续的管理成本。你将负责应用安全补丁、操作系统更新、软件包更新以及网络配置。由于直接访问硬件资源，你还需要做出更多可能减缓你业务活动的决策，从而导致决策疲劳。
- en: Il mio consiglio è quello di implementare una macchina virtuale se non hai intenzione
    di scalare i tuoi servizi a breve o se hai bisogno di mantenere bassi i costi
    dei server e un ambiente applicativo isolato e sicuro per una manciata di utenti.
    Inoltre, assicurati di aver pianificato un tempo sufficiente per l'implementazione,
    il collegamento in rete e la configurazione delle macchine virtuali.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我的建议是，如果你没有打算在短期内扩展你的服务，或者你需要保持服务器成本较低并为一个用户群体提供一个隔离和安全的应用环境，那么请实施一个虚拟机。此外，确保你已经为实施、网络连接和虚拟机的配置计划了足够的时间。
- en: Distribuire le funzioni Serverless
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式无服务器功能
- en: Oltre alle macchine virtuali, puoi anche distribuire i tuoi servizi su funzioni
    cloud che i provider cloud forniscono come sistemi *serverless*. Nel serverless
    computing, il tuo codice viene eseguito in risposta a eventi come le modifiche
    al database, gli aggiornamenti dei blob in uno storage, le richieste HTTP o i
    messaggi aggiunti a una coda. Questo significa che paghi solo per le richieste
    o le risorse di calcolo che i tuoi servizi utilizzano, invece che per un intero
    server come nel caso di una macchina virtuale in esecuzione continua.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 除了虚拟机之外，你还可以将你的服务部署到云服务提供商提供的无服务器系统中。在无服务器计算中，你的代码会在响应于事件时执行，例如数据库的更改、存储中blob的更新、HTTP请求或队列中添加的消息。这意味着你只为你的服务使用的请求或计算资源付费，而不是像持续运行的虚拟机那样为整个服务器付费。
- en: 'Le implementazioni serverless sono spesso utili quando:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当以下情况发生时，无服务器实现通常很有用：
- en: Vuoi avere sistemi guidati dagli eventi invece di una macchina virtuale in esecuzione,
    che potrebbe essere attiva 24 ore su 24, 7 giorni su 7.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要的是事件驱动的系统，而不是一个全天候、每周7天都在运行的虚拟机。
- en: Vuoi distribuire i tuoi servizi API utilizzando un'architettura serverless che
    sia altamente efficiente dal punto di vista dei costi.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你想要使用一个在成本效率方面高度优化的无服务器架构来分发你的API服务。
- en: I tuoi servizi devono eseguire lavori di elaborazione batch
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的服务需要执行批处理工作
- en: Hai bisogno dell'automazione del flusso di lavoro
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要工作流自动化
- en: Il termine *serverless* non significa che le funzioni del cloud non richiedono
    risorse hardware per essere eseguite, ma piuttosto che la gestione di queste risorse
    è gestita dal provider del cloud. Questo ti permette di concentrarti sulla scrittura
    del codice dell'applicazione senza preoccuparti dei dettagli a livello di server
    e di sistema operativo.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: “无服务器”这个术语并不意味着云函数不需要硬件资源来执行，而是说这些资源的管理是由云服务提供商负责。这让你可以专注于编写应用程序的代码，而无需担心服务器和操作系统的细节。
- en: I Cloud provider istanziano le risorse di calcolo per soddisfare la domanda
    dei loro clienti. Spesso si verifica un'impennata della domanda, che richiede
    la creazione di risorse aggiuntive in anticipo per gestire il picco di richieste.
    Tuttavia, una volta che la domanda diminuisce, rimangono risorse di calcolo non
    allocate in eccesso che devono essere chiuse o condivise tra altri clienti.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商根据客户的需求实例化计算资源。通常会出现需求激增的情况，这需要提前创建额外的资源来处理高峰需求。然而，一旦需求减少，就会有多余的计算资源未被分配，这些资源需要关闭或与其他客户共享。
- en: La rimozione e la creazione di risorse è un'operazione di calcolo intensiva
    da eseguire. Su scala, queste operazioni comportano costi significativi per i
    cloud provider. Per questo motivo, i cloud provider preferiscono mantenere queste
    risorse attive il più possibile e distribuirle tra i clienti esistenti per massimizzare
    la fatturazione.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 资源的创建和删除是一项计算密集型操作。在规模上，这些操作会给云服务提供商带来显著的成本。因此，云服务提供商更愿意尽可能保持这些资源活跃，并在现有客户之间分配，以最大化收入。
- en: Per incoraggiare i clienti a utilizzare questi calcoli in eccesso, hanno creato
    dei servizi di funzioni cloud che puoi sfruttare per eseguire i tuoi servizi backend
    su calcoli in eccesso (cioè serverless). Fortunatamente, esistono pacchetti come
    Magnum che ti permettono di pacchettizzare i serviziFastAPI su funzioni cloud
    AWS. Vedrai presto che i servizi FastAPI possono essere distribuiti anche come
    funzioni cloud Azure.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了鼓励客户使用这些额外的计算，他们创建了云函数服务，你可以利用这些服务在额外的计算上运行你的后端服务（即无服务器）。幸运的是，存在像Magnum这样的包，它允许你将FastAPI服务打包成AWS云函数。你很快就会发现，FastAPI服务也可以作为Azure云函数进行部署。
- en: Devi tenere presente che a queste funzioni viene assegnata solo una piccola
    quantità di risorse e hanno un timeout breve. Tuttavia, puoi richiedere timeout
    più lunghi e l'assegnazione di risorse di calcolo, ma potrebbe essere necessario
    più tempo per ricevere queste allocazioni, con conseguenti latenze più elevate
    per i tuoi utenti.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须记住，这些函数只分配了少量资源，并且有较短的超时时间。然而，你可以请求更长的超时时间和计算资源的分配，但这可能需要更多时间来接收这些分配，从而导致用户延迟更高。
- en: Avvertenze
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意事项
- en: Se la tua logica aziendale consuma molte risorse o richiede più di una manciata
    di minuti per essere eseguita, le funzioni cloud potrebbero non essere un'opzione
    di distribuzione adatta a te.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的业务逻辑消耗大量资源或需要超过几分钟的时间来执行，云函数可能不是适合你的部署选项。
- en: Tuttavia, puoi dividere i tuoi servizi FastAPI in più funzioni, con ogni funzione
    che gestisce un singolo endpoint esposto. In questo modo, puoi distribuire parti
    del tuo servizio come funzioni Cloud, riducendo la parte del servizio FastAPI
    che deve essere distribuita con altri metodi.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你可以将你的FastAPI服务分割成多个函数，每个函数处理一个公开的端点。这样，你可以将服务的一部分作为云函数进行部署，从而减少需要通过其他方法部署的FastAPI服务部分。
- en: 'Il vantaggio principale dell''utilizzo di funzioni serverless per l''implementazione
    dei tuoi servizi è la loro scalabilità: puoi scalare le tue applicazioni in base
    alle esigenze e pagare solo una frazione del costo rispetto alla prenotazione
    di risorse VM dedicate. I fornitori di Cloud solitamente applicano tariffe basate
    sul numero di esecuzioni delle funzioni e sul runtime, spesso con generose quote
    mensili. Questo significa che se le tue funzioni vengono eseguite rapidamente
    e hai un numero moderato di utenti contemporanei, potresti essere in grado di
    ospitare tutti i tuoi servizi gratuitamente.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用无服务器函数实现你的服务的主要优势是它们的可伸缩性：你可以根据需求伸缩你的应用程序，并且只需支付与预订专用虚拟机相比的一小部分成本。云服务提供商通常根据函数的执行次数和运行时来收费，通常提供慷慨的月度配额。这意味着如果你的函数执行速度快，并且同时用户数量适中，你可能会免费托管所有服务。
- en: Inoltre, i fornitori di cloud forniscono anche runtime di funzioni che puoi
    installare localmente per i test e lo sviluppo locale, in modo da accorciare notevolmente
    le iterazioni di sviluppo.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，云服务提供商还提供可以在本地安装的函数运行时，以便进行本地测试和开发，这样可以显著缩短开发迭代周期。
- en: Ogni cloud provider ha un proprio approccio alla distribuzione delle funzioni
    serverless. Spesso è necessario uno script di ingresso, come *main.py*, che può
    importare le dipendenze da altri moduli secondo le necessità. Oltre allo script
    di ingresso, dovrai caricare un file di configurazione JSON dell'host della funzione
    insieme al *file requirements.txt* per le dipendenze necessarie da installare
    al momento della distribuzione su un runtime Python.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 每个云服务提供商都有自己的无服务器函数部署方法。通常需要一个入口脚本，如*main.py*，它可以根据需要从其他模块导入依赖项。除了入口脚本之外，你还需要上传一个函数宿主的JSON配置文件以及*requirements.txt*文件，以便在部署到Python运行时安装必要的依赖项。
- en: Puoi quindi distribuire le funzioni caricando tutti i file necessari in una
    cartella zippata o utilizzando pipeline CI/CD che si autenticano con il provider
    ed eseguono i comandi di distribuzione all'interno del tuo progetto cloud.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以通过将所有必要的文件打包到一个压缩文件夹中或使用CI/CD管道（该管道与提供商进行身份验证并在你的云项目内部执行部署命令）来部署函数。
- en: 'A titolo di esempio, proviamo a distribuire un''applicazione FastAPI semplice
    e semplice che restituisca risposte LLM. La struttura del progetto sarà la seguente:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个例子，我们来尝试部署一个简单且简单的FastAPI应用程序，该应用程序返回LLM的响应。项目结构如下：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Puoi quindi pacchettizzare un'applicazione FastAPI come [funzione Azure serverless](https://oreil.ly/ZaOuF)
    seguendo i prossimi esempi di codice.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以按照以下代码示例将FastAPI应用程序打包为[Azure无服务器函数](https://oreil.ly/ZaOuF)。
- en: 'Dovrai installare il pacchetto `azure-functions` per eseguire il runtime delle
    funzioni serverless di Azure per lo sviluppo e i test locali:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要安装`azure-functions`包来执行Azure的无服务器函数的本地运行时，以便进行开发和测试：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2][PRE3] `"extensions"``:` `{` [PRE4] `"http"``:` `{` [PRE5]`py [PRE6]
    [PRE7]`` [PRE8]` Successivamente, implementa il tuo servizio GenAI con il servizio
    FastAPI come di consueto seguendo l''[Esempio 12-2](#deployment_function_azure_app).    #####
    Esempio 12-2\. Semplice applicazione FastAPI che serve le risposte LLM    [PRE9]    Infine,
    avvolgi il tuo FastAPI `app` all''interno di `func.AsgiFunctionApp` in modo che
    il runtime delle funzioni serverless di Azure possa agganciarsi ad esso, come
    mostrato nell''[Esempio 12-3](#deployment_function_azure_function).    ##### Esempio
    12-3\. Distribuzione di un servizio FastAPI con Azure Functions    [PRE10]    Puoi
    quindi avviare l''applicazione della funzione eseguendo il comando `func start`,
    che dovrebbe essere disponibile come comando CLI una volta installato ilpacchetto
    `azure-functions`:    [PRE11] >> Functions: `` >>        http_app_func: `[`GET,POST,DELETE,HEAD,PATCH,PUT,OPTIONS`]`
    `\`                           http://localhost:7071//`{`*route`}` `>> Job host
    started` `` [PRE12]   [PRE13] [PRE14]`py [PRE15]py`` [PRE16]py[PRE17][PRE18][PRE19][PRE20][PRE21]
    [PRE22][PRE23][PRE24][PRE25][PRE26] [PRE27]`py[PRE28]py[PRE29]`py[PRE30]py[PRE31]py[PRE32]py[PRE33][PRE34][PRE35][PRE36][PRE37]py[PRE38]py[PRE39]py[PRE40][PRE41]
    ### Gestione dei permessi del filesystem    Una grande fonte di frustrazione e
    un problema di sicurezza per molti sviluppatori alle prime armi con Docker è la
    gestione dei permessi delle directory quando si utilizzano i mount bind del filesystem
    tra il sistema operativo host e il container.    Per impostazione predefinita,
    Docker esegue i container come utente `root` e di conseguenza i container hanno
    pieno accesso in lettura/scrittura alle directory montate sul sistema operativo
    host. Se l''utente `root` all''interno del container crea directory o file, questi
    saranno di proprietà di `root` anche sull''host. Puoi quindi incorrere in problemi
    di permessi se hai un account utente non root sull''host quando cerchi di accedere
    o modificare queste directory o file.    ###### Avvertenze    L''esecuzione dei
    container come utente predefinito di `root` è anche un grande rischio per la sicurezza
    se un malintenzionato riesce ad accedere al container, poiché avrà accesso al
    sistema host come `root`. Inoltre, se esegui un''immagine compromessa, potresti
    rischiare di eseguire codice maligno sul sistema host con i privilegi di `root`.    Per
    attenuare i problemi di permessi durante l''esecuzione di container con mount
    bind, puoi utilizzare il flag `--user` per eseguire il container come utente non
    root:    [PRE42]py   [PRE43] In alternativa, puoi creare e passare a un utente
    non root nei livelli finali della creazione dell''immagine all''interno del file
    Docker, come mostrato nell''[Esempio 12-6](#docker_permissions).    ##### Esempio
    12-6\. Creazione e passaggio all''utente non root durante la creazione delle immagini
    del container (solo container Ubuntu/Debian)    [PRE44]    [![1](assets/1.png)](#co_deployment_of_ai_services_CO3-1)      Usa
    gli argomenti di compilazione per specificare le variabili durante la creazione
    dell''immagine.      [![2](assets/2.png)](#co_deployment_of_ai_services_CO3-2)      Crea
    un gruppo di utenti con il nome `USER_GID`.      [![3](assets/3.png)](#co_deployment_of_ai_services_CO3-3)      Disabilita
    completamente il login degli utenti, compreso quello basato sulla password.      [![4](assets/4.png)](#co_deployment_of_ai_services_CO3-4)      Evita
    di creare una home directory per l''utente.      [![5](assets/5.png)](#co_deployment_of_ai_services_CO3-5)      Crea
    un account utente non root con il nome `$USER_UID` e assegnalo al gruppo `USER_GID`
    appena creato. Imposta il nome dell''account utente su `fastapi`.      [![6](assets/6.png)](#co_deployment_of_ai_services_CO3-6)      Passa
    all''utente non root `fastapi`.      ###### Suggerimento    Spesso dovrai installare
    dei pacchetti o aggiungere delle configurazioni che richiedono un accesso privilegiato
    al disco o dei permessi. Dovresti passare a un utente non root solo alla fine
    della creazione di un''immagine, una volta completate queste installazioni e configurazioni.
    Evita di passare da un utente root a uno non root per evitare inutili complessità
    e livelli di immagine in eccesso.    Se hai problemi con la creazione di nuovi
    gruppi o utenti nell''[Esempio 12-6](#docker_permissions), prova a cambiare gli
    ID `USER_UID` e `USER_GID` perché potrebbero essere già utilizzati da un altro
    utente non root nell''immagine.    Supponiamo che durante la creazione dell''immagine,
    l''utente `root` nel container abbia creato la cartella `myscripts`. Puoi controllare
    i permessi del filesystem utilizzando il comando `ls -l`, che restituisce il seguente
    output:    [PRE45]   [PRE46][PRE47]``py[PRE48]`` In alternativa, se hai bisogno
    di eseguire gli script solo nella directory `myscripts`, usa il comando `chmod`
    per modificare i permessi dei file o delle directory:    [PRE49]   [PRE50]`` [PRE51]`
    ###### Suggerimento    Il flag `-R` imposta ricorsivamente la proprietà o i permessi
    di una directory annidata.    Questo comando permette ai membri del gruppo `root`
    e ad altri utenti di eseguire i file presenti nella directory `myscripts`. Altri
    utenti possono eseguire i file solo se utilizzano il comando `bash`. Tuttavia,
    solo il proprietario può modificarli.    Se ispezioni nuovamente i permessi del
    filesystem utilizzando `ls -l`, vedrai il seguente output:    [PRE52]   [PRE53]
    [PRE54]`py [PRE55]py`` [PRE56]py[PRE57][PRE58][PRE59][PRE60]py[PRE61]py`  [PRE62]`py[PRE63]py`
    [PRE64]`py[PRE65]py [PRE66]`py[PRE67]py [PRE68]py`` Il *bridge di rete* in Docker
    è un dispositivo software di livello link che gira all''interno del kernel della
    macchina host e che permette ai container collegati di comunicare isolando i container
    non collegati. Il driver del bridge installa automaticamente delle regole nella
    macchina host in modo che i container su reti bridge diverse non possano comunicare
    direttamente.    ###### Suggerimento    Le reti bridge si applicano solo ai container
    in esecuzione sullo stesso motore Docker/ host demone. Per collegare i container
    in esecuzione su altri host demone, puoi gestire il routing a livello del sistema
    operativo host o utilizzare un driver *overlay*.    Oltre alle reti bridge predefinite,
    puoi creare le tue reti personalizzate, che possono offrire un isolamento e un''esperienza
    di routing dei pacchetti superiori.    #### Configurare reti ponte definite dall''utente    Se
    hai bisogno di ambienti di rete più avanzati o isolati per i tuoi container, puoi
    creare una rete separata definita dall''utente.    Le reti definite dall''utente
    sono superiori alle reti di bridge predefinite in quanto garantiscono un migliore
    isolamento. Inoltre, i container possono risolversi l''un l''altro tramite nome
    o alias sulle reti di bridge definite dall''utente, a differenza della rete predefinita
    in cui possono comunicare solo tramite indirizzi IP.    ###### Avvertenze    Se
    esegui i container senza specificare `--network`, verranno collegati alla rete
    bridge predefinita, il che può rappresentare un problema di sicurezza in quanto
    i servizi non correlati possono comunicare e accedere l''uno all''altro.    Per
    creare una rete, puoi utilizzare il comando `docker network create`, che utilizzerà
    il flag `--driver bridge` per impostazione predefinita:    [PRE69]py   [PRE70]py
    [PRE71]`py [PRE72]py [PRE73]`py [PRE74]py[PRE75][PRE76]`  [PRE77]` [PRE78] [PRE79]`py
    [PRE80]py[PRE81]py[PRE82]``py[PRE83]py [PRE84]`py[PRE85]py` [PRE86]py`` `# ...`
    [PRE87]py `watch``:` [PRE88]`py [PRE89]py`` [PRE90]py[PRE91]py [PRE92]py`` [PRE93]py[PRE94][PRE95][PRE96][PRE97]py[PRE98]py[PRE99]``py[PRE100]py[PRE101]py[PRE102]`py[PRE103]py[PRE104]`
    [PRE105] FROM python:3.12-slim as base `COPY` requirements.txt requirements.txt
    [PRE106] [PRE107] `` `Ora qualsiasi modifica ai file sorgente non influirà sulla
    lunga fase di installazione delle dipendenze, velocizzando drasticamente il processo
    di compilazione.` `` [PRE108]` [PRE109][PRE110][PRE111][PRE112][PRE113] RUN apt-get
    update && apt-get install -y [PRE114]`` #### Mantenere un contesto di costruzione
    piccolo    Il *contesto di compilazione* è l''insieme dei file e delle directory
    che verranno inviati al costruttore per eseguire l''istruzione Dockerfile. Un
    contesto di compilazione più piccolo riduce la quantità di dati inviati al costruttore
    e diminuisce la possibilità di invalidare la cache, rendendo le compilazioni più
    veloci.    Quando usi il comando `COPY . .` in un file Docker per copiare la tua
    directory di lavoro in un''immagine, potresti anche aggiungere cache di strumenti,
    dipendenze di sviluppo, ambienti virtuali e file inutilizzati nel contesto di
    compilazione. Non solo le dimensioni dell''immagine aumenteranno, ma anche il
    costruttore Docker metterà in cache questi file non necessari. Qualsiasi modifica
    a questi file invaliderà la compilazione, riavviando l''intero processo di compilazione.    Per
    evitare di invalidare inutilmente la cache, puoi aggiungere un file *.dockerignore*
    accanto al tuo file Docker, elencando tutti i file e le directory di cui i tuoi
    servizi non avranno bisogno in produzione. A titolo di esempio, ecco gli elementi
    che puoi includere in un file *.dockerignore*:    [PRE115]    Docker builder ignorerà
    questi file anche quando eseguirai il comando `COPY` su tutta la tua directory
    di lavoro.    #### Usa la cache e i montaggi bind    Puoi utilizzare i *montaggi
    bind* per evitare di aggiungere livelli non necessari all''immagine e i *montaggi
    cache* per velocizzare le build successive.    I montaggi Bind includono temporaneamente
    i file nel contesto di compilazione per una singola istruzione `RUN` e non persisteranno
    come livelli di immagine in seguito. I montaggi Cache specificano una posizione
    persistente della cache in cui puoi leggere e scrivere dati in più build.    Ecco
    un esempio in cui puoi scaricare un modello pre-addestrato da Hugging Face in
    una cache montata per ottimizzare la cache dei livelli:    [PRE116]   ``Questa
    istruzione `RUN` crea una cache del modello preaddestrato scaricato all''indirizzo`/root/.cache/huggingface`,
    che può essere condivisa in più build. Questo aiuta a evitare download ridondanti
    e ottimizza il processo di creazione riutilizzando i livelli in cache.    Puoi
    anche utilizzare il flag `--no-cache-dir` quando utilizzi il gestore di pacchetti
    `pip` per evitare del tutto la cache e ridurre al minimo le dimensioni dell''immagine.
    Tuttavia, il processo di compilazione sarà significativamente più lento perché
    le compilazioni successive dovranno essere riscaricate ogni volta.``  [PRE117]
    docker buildx build --cache-from type=registry,ref=user/app:buildcache . [PRE118]`
    [PRE119][PRE120][PRE121][PRE122][PRE123][PRE124]``py[PRE125]py` ### Costruzioni
    in più fasi    Utilizzando le *build multi-stadio*, puoi ridurre le dimensioni
    dell''immagine finale suddividendo le istruzioni del file Docker in fasi distinte.
    Le fasi comuni possono essere riutilizzate per includere componenti condivisi
    e fungere da punto di partenza per le fasi successive.    Puoi anche copiare selettivamente
    gli artefatti da una fase all''altra, lasciando indietro tutto ciò che non vuoi
    nell''immagine finale. Questo assicura che solo gli output necessari siano inclusi
    nell''immagine finale dalle fasi precedenti, evitando gli artefatti non essenziali.
    Inoltre, puoi anche eseguire più fasi di creazione in parallelo per accelerare
    il processo di creazione delle tue immagini.    Un modello di compilazione multi-stadio
    comune è quello che prevede un''immagine di test/sviluppo e una di produzione
    più snella, che partono entrambe da un''immagine condivisa del primo stadio. L''immagine
    di sviluppo o di test può includere ulteriori livelli di strumenti (ad esempio,
    compilatori, sistemi di compilazione e strumenti di debug) per supportare i flussi
    di lavoro richiesti.    Immagina di dover servire un modello di trasformatore
    bert da Hugging Face in un servizio FastAPI. Puoi scrivere le istruzioni del tuo
    Dockerfile in modo da utilizzare tre fasi sequenziali distinte.    La prima fase
    scarica il modello del trasformatore su `/root/.cache/huggingface` e crea un ambiente
    virtuale Python su `/opt/venv`:    [PRE126]py`` `RUN` python -m venv /opt/venv
    [PRE127]` [PRE128][PRE129][PRE130]``py[PRE131]`py` La seconda fase copia gli artefatti
    del modello e l''ambiente virtuale Python `/opt/ven` dalla fase `base` prima di
    copiare i file sorgente e creare una versione di produzione del servizio FastAPI:    [PRE132]py[PRE133]py
    [PRE134]`py`` [PRE135]`py [PRE136]`py` [PRE137]`py`` [PRE138]`py[PRE139][PRE140][PRE141]
    [PRE142][PRE143][PRE144][PRE145][PRE146]``  [PRE147] [PRE148]`py [PRE149]`py[PRE150]py[PRE151]py[PRE152]py[PRE153]py[PRE154]py[PRE155]py`
    [PRE156]`py[PRE157]py[PRE158]py[PRE159][PRE160][PRE161][PRE162][PRE163]``py[PRE164]py[PRE165]py[PRE166]py[PRE167][PRE168][PRE169][PRE170][PRE171]
    [PRE172][PRE173][PRE174][PRE175][PRE176]` [PRE177] [PRE178][PRE179][PRE180][PRE181][PRE182]``
    [PRE183][PRE184][PRE185][PRE186][PRE187] [PRE188]`py[PRE189]py[PRE190]`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
