- en: 4 Association rules
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Association rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different types of algorithms for association rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of different algorithms for association rules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequence learning using SPADE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The power of association is stronger than the power of beauty; therefore, the
    power of association is the power of beauty.—John Ruskin
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Congratulations on finishing the first part of the book! You explored the basics
    of unsupervised learning and algorithms like k-means clustering, hierarchical
    clustering, DBSCAN, principal component analysis, and others. It is expected that
    you have covered the mathematical concepts in the first part and created the Python
    codes to solve the exercise given at the end of each chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Welcome to the second part of the book where we use the concepts learned in
    the first part and explore slightly more complex topics. We start with association
    rules in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next time you visit a nearby grocery store, look around inside the store and
    notice the arrangements of various items. You would find shelves with items like
    milk, eggs, bread, sugar, washing powder, soaps, fruits, vegetables, cookies,
    and various other items neatly stacked. Have you ever wondered about the logic
    of these arrangements and how these items are laid out? Why are certain products
    kept near each other while others are quite far from one another? Obviously, the
    arrangement cannot be done in a random manner, and there has to be scientific
    reasoning behind it. Or do you wonder: How does Netflix recommend movies to you
    based on your movie history like a sequence? We are going to find the answers
    to these questions in this chapter. Like always, we study the concepts first.
    We go through the mathematical logic for different algorithms, the pros and cons
    of each, and practical implementations using Python. A business case study is
    provided at the end of the chapter to complement the knowledge. Welcome to the
    fourth chapter and all the very best!'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Technical toolkit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will continue to use the same version of Python and Jupyter Notebook we have
    used so far. The codes and datasets used in this chapter have been checked in
    at the same Github location.
  prefs: []
  type: TYPE_NORMAL
- en: You will need to install a few Python libraries for this chapter, including
    `apyori`, `pyECLAT`, `fpgrowth_py`, and  `pyspade`. Along with this, you will
    need `numpy` and `pandas`. Using libraries, we can implement the algorithms very
    quickly. Otherwise, coding these algorithms from scratch is quite a time-consuming
    and painstaking task.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started with association rules.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Association rule overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might have heard the famous “beer and diaper story.” As per this anecdote,
    customers (mostly young men) in a supermarket who buy diapers also buy beer in
    the same invoice. In other words, young men who are buying diapers for their babies
    have quite a high probability of buying beer in the same transaction. We will
    not comment on the authenticity of the story, but *association rule learning*
    can be attributed as the logic derived from this story.
  prefs: []
  type: TYPE_NORMAL
- en: Formally put, association rules can be used to find compelling relationships
    between the variables that are present in the datasets. We can use association
    rules for measuring the correlations and co-occurrences between the variables
    in a dataset. In the example given here (assuming the story is true), one could
    analyze the daily customer transactions. And if a relationship emerges between
    beer and diapers, it is a very strong insight for the supermarket, which can allow
    it to customize their placements of beer and diapers or tailor the marketing strategy
    or even alter the prices.
  prefs: []
  type: TYPE_NORMAL
- en: We can understand by a different example in a supermarket. Assume that by analyzing
    five invoices generated in a supermarket, we get the data as shown in table 4.1\.
    In this example, in invoice number 1001 milk is purchased and thus has a value
    of 1, whereas cheese is not purchased and thus is 0.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.1 Examples of invoices generated in a supermarket
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Invoice number | Milk | Eggs | Bread | Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 1  | 1  | 1  | 0  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 0  | 0  | 0  | 1  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 1  | 1  | 1  | 0  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 0  | 1  | 0  | 1  |'
  prefs: []
  type: TYPE_TB
- en: '| 1005  | 1  | 1  | 0  | 1  |'
  prefs: []
  type: TYPE_TB
- en: So, in invoice number 1001, milk, eggs, and bread are purchased while in invoice
    number 1002, only cheese is purchased. Here we can see that whenever milk and
    eggs are purchased together, bread is always purchased in the same invoice. It
    is an important discovery indeed.
  prefs: []
  type: TYPE_NORMAL
- en: Now scale up this understanding to thousands of transactions made in a day.
    It will lead to very strong relationships that human eyes are generally oblivious
    to, but association rule algorithms can uncover them for us. This can lead to
    better product placements, better prices on the products, and much more optimized
    marketing spending. Such patterns will enhance the customer experience and prove
    quite handy to improve overall customer satisfaction.
  prefs: []
  type: TYPE_NORMAL
- en: We can visualize association rules as shown in figure 4.1\. Here there are some
    incoming variables represented as nodes 1, 2, 3, 4, etc. These nodes are related
    to each other as shown by the arrows. This relationship between them gives rise
    to rules A and B. If we relate back to the beer/diaper story we mentioned at the
    start of this section, rule A can be that when a young male customer buys diapers,
    they also often buy beer, while rule B can be that when milk and eggs are purchased,
    often bread is bought too.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F01_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 An association rule can be visualized as the relationship between
    various variables in the dataset. These variables are linked to each other, and
    significant relationships are established between them.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The example of the supermarket is sometimes referred to as *market basket analysis.*
    But association rules are applicable not only in grocery retail. Their utility
    has been proven in other sectors like bioinformatics, the medical industry, intrusion
    detection, etc. They can be utilized by Netflix or Spotify to analyze historical
    user behavior and then recommend the content the user most likely is going to
    like. Web developers can analyze the historical clicks and usages of the customers
    on their websites. By identifying the patterns, they can find out what users tend
    to click and which features will maximize their engagement. Medical practitioners
    can use association rules to better diagnose patients. The doctors can compare
    the probability of the symptoms in relationship with other symptoms and provide
    more accurate diagnoses. The use cases occur across multiple business domains
    and business functions.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 The building blocks of association rules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We covered the definition of an association rule in the last section. Now let’s
    understand the mathematical concept behind association rules. Assume that we have
    the following datasets in a retail store:'
  prefs: []
  type: TYPE_NORMAL
- en: Let X = {x[1], x[2], x[3], x[4], x[5] …., x[*n*]} are the *n* items available
    in the retail store. For example, they can be milk, eggs, bread, cheese, apples,
    and so on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let Y = {y[1], y[2], y[3], y[4], y[5] …., y[*m*]} are the *m* transactions generated
    in that retail store. Each transaction could have all or some items from the retail
    store.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obviously, each item in the transaction will be bought from the retail store
    only. In other words, every item in transactions in set Y will be a subset of
    items in set X. At the same time, each item would have a unique identifier attached
    to it, and each transaction would have a unique invoice number attached to it.
  prefs: []
  type: TYPE_NORMAL
- en: Now we are interested in analyzing the patterns and discovering the relationships.
    This will be used to generate any rule or insight. So let’s define the meaning
    of the rule first.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assume that we find a rule that whenever items in list P are bought, items
    in list Q are also bought. This rule can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The rule is P -> Q. It means that whenever items defined in P are bought, it
    leads to a purchase in Q too.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Items in P will be a subset of X or P Í X.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Similarly, items in Q will be a subset of X or Q Í X.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: P and Q cannot have any common element or P Ç Q = 0
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now let’s understand these mathematical concepts with a real-world example.
    Assume that X = {milk, bananas, eggs, cheese, apples, bread, salt, sugar, cookies,
    butter, cold drinks, water}. These are the total items available in the retail
    shop.
  prefs: []
  type: TYPE_NORMAL
- en: Y = {1001, 1002, 1003, 1004, 1005} are the five invoices generated in that retail
    store. The respective items purchased in each of these invoices are given in figure
    4.2. Note how for each invoice, we have 0 and 1 associated for each of the items.
    These invoices are just for illustration purposes. In the actual invoices, the
    number of items can be much more. Using this dataset, let’s assume we create two
    rules that {milk, bananas} -> {eggs} and {milk, bananas} -> {bread}.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F02_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 Example of five invoices generated in a retail store
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The first rule means that whenever milk and bananas are bought together, eggs
    are also purchased in the same transaction. The second rule means that whenever
    milk and bananas are bought together, bread is also bought in the same transaction.
    By analyzing the dataset, we can clearly see that rule 1 is always true whereas
    rule 2 is not.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  The items on the left side of a rule are called the *antecedent* or the
    LHS and the ones on the right side of a rule are called the *consequents* or the
    RHS.
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, for any such rule to have significance, the same pattern
    must repeat itself across several hundreds and thousands of transactions. Only
    then would we conclude that the rule is indeed true and can be generalized across
    the entire database.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, there can be many such rules. In a retail shop where thousands
    of invoices are generated daily, there can be hundreds of such rules. How can
    we find out which rules are significant and which are not? This can be understood
    using the concepts of *support, confidence, lift,* and *conviction,* which we
    will study in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.1 Support, confidence, lift, and conviction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We identified the meaning of a rule in an association rule in the last section.
    We also understand that there can be hundreds of rules based on the transactional
    dataset. In this section, we will explore how we can measure the effectiveness
    of such rules and shortlist the most interesting ones. This can be achieved using
    the concepts of support, confidence, lift, and conviction.
  prefs: []
  type: TYPE_NORMAL
- en: Recall in the last section we discussed the generalization of a rule. Support,
    confidence, lift, and conviction allow us to measure the level of generalization.
    In simple terms, using these four parameters, we can determine how useful the
    rule can be in our pragmatic real-world business. After all, if a rule is not
    useful or is not powerful enough, it is not required to be implemented. Support,
    confidence, lift, and conviction are the parameters to check the efficacy of the
    rule. We look at these concepts in detail next.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the dataset in table 4.2 to understand the concepts of support,
    confidence, lift, and conviction. The first invoice, 1001, has milk, eggs, and
    bread while cheese is not purchased. Again, for the sake of this example, we have
    taken only four items in total.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.2 Dataset to understand the concept of support, confidence, lift, and
    conviction
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Invoice Number | Milk | Eggs | Bread | Cheese |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 1  | 1  | 1  | 0  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 0  | 1  | 1  | 1  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 1  | 1  | 1  | 0  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 0  | 1  | 0  | 1  |'
  prefs: []
  type: TYPE_TB
- en: '| 1005  | 0  | 1  | 1  | 0  |'
  prefs: []
  type: TYPE_TB
- en: Here, for an invoice, 1 represents if an item is present in that invoice while
    0 shows that the item was not purchased in that particular invoice. For example,
    invoice number 1001 has milk, eggs, and bread while 1002 has eggs, bread, and
    cheese.
  prefs: []
  type: TYPE_NORMAL
- en: Support
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Support measures the frequency percentage of the items in the datasets. In simpler
    terms, it measures the percentage of transactions in which the items are occurring
    in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Support can be denoted as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/verdhan-ch4-eqs-0x.png)'
  prefs: []
  type: TYPE_IMG
- en: Refer to table 4.2\. Say we are interested in the rule {milk, eggs} -> {bread}.
    In such a scenario, there are two transactions in which all three items (milk,
    eggs, and bread) are present. The total number of transactions is five. This means
    that the support for the rule is 2/5, which is 0.4 or 40%.
  prefs: []
  type: TYPE_NORMAL
- en: Now say we are interested in the rule {bread, eggs} -> {cheese}. In such a scenario,
    there is only one transaction in which all three items are present. The total
    number of transactions is five. This means that the support for the rule is 1/5,
    which is 0.2 or 20%.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  The higher the support for a rule, the better it is. Generally, we put
    a minimum threshold to get support. A minimum threshold is generally determined
    in consultation with the business stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: Confidence
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Confidence measures how often the rule is true; that is, it measures the percentage
    of transactions that contain antecedents that also contain consequents.
  prefs: []
  type: TYPE_NORMAL
- en: 'So if we wish to measure the confidence of the rule A -> B:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/verdhan-ch4-eqs-1x.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, the numerator is supported when both *A* and *B* are present in the transaction,
    while the denominator refers to the support only for *A*.
  prefs: []
  type: TYPE_NORMAL
- en: Refer to table 4.2\. Again, say we are interested in the rule {milk, eggs} ->
    {bread}. In such a scenario, there are two transactions in which both milk and
    eggs are present. Hence, the support is 2/5 = 0.4\. It is the denominator. There
    are two transactions in which all three (milk, eggs, bread) are present. Hence,
    support is 2/5 = 0.4, which is the numerator. Putting in the preceding equation,
    the confidence for the rule {milk, eggs} -> {bread} is 0.4/0.4 = 1.
  prefs: []
  type: TYPE_NORMAL
- en: Now say we are interested in the rule {eggs, bread} -> {cheese}. In such a scenario,
    there are four transactions in which (eggs, bread) are present. The total number
    of transactions is five. This means that the support is 4/5, which is 0.8\. There
    is only one transaction in which all three items (eggs, bread, cheese) are present.
    So the support is 1/5 = 0.2\. Hence the confidence for the rule {eggs, bread}
    -> {cheese} is 0.2/0.8 = 0.25.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  The higher the confidence in the rule, the better it is. Like support,
    we put a minimum threshold on confidence.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes this is also referred to as the *conditional probability* of *A* on
    *B*. It can be understood as the probability of *B* occurring provided *A* has
    already occurred and can be written as *P*(*A*|*B*). So, in the preceding examples,
    the probability of cheese to be bought provided eggs, bread is already bought
    is 25% while the probability of bread to be purchased, provided milk, eggs are
    already purchased is 100%.
  prefs: []
  type: TYPE_NORMAL
- en: Lift and conviction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Lift is a very important measurement criterium for a rule. Lift for a rule *A*
    -> *B* can be defined as
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/verdhan-ch4-eqs-2x.png)'
  prefs: []
  type: TYPE_IMG
- en: Here the numerator is supported when both *A* and *B* are present in the transaction,
    while the denominator refers to the support for *A* multiplied by the support
    for *B*.
  prefs: []
  type: TYPE_NORMAL
- en: Again, refer to table 4.2 and say we are interested in the rule {milk, eggs}
    -> {bread}. In such a scenario, there are two transactions in which all three
    (milk, eggs, bread) are present. Hence, support is again 2/5 = 0.4, which is the
    numerator. There are two transactions in which only (milk, eggs) are present,
    so the support is 2/5 = 0.4\. There are four transactions in which bread is present,
    hence the support is 4/5 = 0.8\. Putting in the preceding equation, the lift for
    the rule {milk, eggs} -> {bread} is 0.4/(0.4 x 0.8) = 1.25.
  prefs: []
  type: TYPE_NORMAL
- en: Then say we are interested in the rule {eggs, bread} -> {cheese}. In such a
    scenario, there is only one transaction in which (eggs, bread, cheese) are present.
    The total number of transactions is five. This means that the support is 1/5,
    which is 0.2\. There are two transactions in which (cheese) is present. So the
    support is 2/5 = 0.4\. There are four transactions in which (eggs, bread) are
    present, so the support is 4/5 = 0.8\. Putting in the preceding equation, the
    lift for the rule {eggs, bread} -> {cheese} is 0.2/(0.4 x 0.8) = 0.625.
  prefs: []
  type: TYPE_NORMAL
- en: If the value of the lift is *equal to 1*, it means that the antecedent and precedent
    are independent of each other, and no rule can be drawn from it.
  prefs: []
  type: TYPE_NORMAL
- en: If the value of lift is *greater than 1*, it means that the antecedent and precedent
    are dependent on each other. This rule can be used for predicting the antecedent
    in future transactions. This is the insight we want to draw from the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: If the value of lift is *less than 1*, it means that the antecedent and precedent
    are substitutes of each other. The presence of one can have a negative effect
    on the other. It is also an important insight that can be used by the business
    teams for strategic planning.
  prefs: []
  type: TYPE_NORMAL
- en: While we evaluate any rule using the lift, it is imperative that we apply domain
    knowledge to it. For example, if we evaluate the rule {eggs, bread} -> {cheese}
    and if we find that eggs, bread can be a substitute for cheese, we know that it
    is not true in real life. Hence, in such a scenario we cannot make any decision
    for this role. We must use domain knowledge to draw any conclusions for this rule.
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, rule {milk, eggs} -> {bread} might be a rule that can be true
    many times. For many customers, when they purchase milk and eggs together, it
    is highly likely that bread will be purchased in the same transaction. Hence this
    rule makes much more sense for such customers. The objective is to have a strong
    business logic to either support or disapprove a rule identified using the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conviction is another important parameter, which is given by the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/verdhan-ch4-eqs-3x.png)'
  prefs: []
  type: TYPE_IMG
- en: Refer to table 4.2\. Again, say we are interested in the rule {eggs, bread}
    -> {cheese}. In such a scenario, there is only one transaction in which (cheese)
    is present. The total number of transactions is five. So, it means that the support
    is 1/5, which is 0.2 and will be used in the numerator. We have already calculated
    the confidence as 0.625\. Putting back in the formula, we can calculate conviction
    as (1 – 0.2)/(1 – 0.625) = 2.13
  prefs: []
  type: TYPE_NORMAL
- en: 'We can interpret the conviction as: the rule {eggs, bread} -> {cheese} would
    be incorrect 2.13 times more often if the association between {eggs, bread, cheese}
    was purely chosen at random.'
  prefs: []
  type: TYPE_NORMAL
- en: In most of the business scenarios, lift is the measurement criteria used. There
    are other measurement parameters, too, like leverage, collective strength, etc.
    But most of the time, confidence, support, lift, and conviction are used to measure
    the effectiveness of any rule.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 4.1
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Answer these questions to check your understanding:'
  prefs: []
  type: TYPE_NORMAL
- en: Support measures how often the rule is present in the dataset. True or False?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the lift is greater than 1, it means that the two items are independent of
    each other. True or False?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The lower the value of confidence, the better the rule. True or False?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While we evaluate any rule while analyzing the dataset, most of the time, we
    set a threshold for the confidence, support, lift, and conviction. It allows us
    to reduce the number of rules and filter out the irrelevant ones. In other words,
    we are interested in only the rules that are very frequent. We will study this
    in more detail when we create a Python solution for a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Apriori algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Apriori algorithm is one of the most popular algorithms used for association
    rules. It was proposed by Agrawal and Shrikant in 1994\. The link to the paper
    is given at the end of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Apriori is used to understand and analyze the frequent items in a transactional
    database. It utilizes a “bottom-up” approach where the first candidates are generated
    based on the frequency of the subsets. Let us understand the entire process by
    means of an example. We will use the same dataset we have discussed earlier (see
    table 4.2). The process used in the Apriori algorithm will look like figure 4.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F03_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 The Apriori algorithm process
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let us say we wish to analyze the relationship of bread with all the other items
    in the dataset. In this case, level 1 is bread, and we find its frequency of occurrence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we move to the next layer, which is layer 2\. Now we find the relationship
    of bread with each of the other items: milk, eggs, and cheese, which are at layer
    2\. Here again we find the respective frequencies of occurrence for all the possible
    combinations, which are {bread, milk}, {bread, eggs}, and {bread, cheese}. See
    figure 4.4.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F04_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 We have bread at level 1 while the other items (milk, eggs, and cheese)
    are kept at level 2\. Bread is kept at level 1 since we wish to analyze the relationship
    of bread with all the other items.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: After layer 2 has been analyzed, we move to the third layer and fourth layer
    and so on. This process continues until we reach the last layer wherein all the
    items have been exhausted.
  prefs: []
  type: TYPE_NORMAL
- en: As a result of this process, we can calculate the support for all the possible
    combinations. For example, we would know the support for
  prefs: []
  type: TYPE_NORMAL
- en: '{bread} -> {milk},'
  prefs: []
  type: TYPE_NORMAL
- en: '{bread} -> {eggs}, and'
  prefs: []
  type: TYPE_NORMAL
- en: '{bread} -> {cheese}.'
  prefs: []
  type: TYPE_NORMAL
- en: For the next level, we would also get the support for
  prefs: []
  type: TYPE_NORMAL
- en: '{bread, milk} -> {eggs},'
  prefs: []
  type: TYPE_NORMAL
- en: '{bread, eggs} -> {milk},'
  prefs: []
  type: TYPE_NORMAL
- en: '{bread, milk} -> {cheese},'
  prefs: []
  type: TYPE_NORMAL
- en: '{bread, cheese} -> {milk},'
  prefs: []
  type: TYPE_NORMAL
- en: '{bread, cheese} -> {eggs}, and'
  prefs: []
  type: TYPE_NORMAL
- en: '{bread, eggs} -> {cheese}.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, using the same process, all the possible combinations for the next level
    are calculated. For example, {bread, eggs, milk} -> {cheese}, {bread, eggs, cheese}
    -> {milk}, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: When all the item sets have been exhausted, the process will stop. The complete
    architecture can look like figure 4.5.
  prefs: []
  type: TYPE_NORMAL
- en: Now we can easily understand that the possible number of combinations is quite
    high, which is one of the challenges with Apriori. But Apriori is quite a powerful
    algorithm and is very popular too. Now it’s time to implement Apriori using Python.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F05_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 The complete architecture for the Apriori algorithm. Here we would
    have calculated support for all the possible combinations. The relationships between
    all the items are explored, and because of this entire database scan, the speed
    of Apriori gets hampered.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 4.4.1 Python implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will now proceed with Python implementation of the Apriori algorithm. The
    dataset and Python Jupyter Notebook are checked in at the GitHub repository. You
    might have to install `apyori`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install the libraries, simply do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the necessary libraries for the use case. We are importing `numpy` and
    `pandas`. For implementing Apriori, we have a library called `apyori`, which is
    also imported:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '2\. Import the dataset `store_data.csv` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You are also advised to have a look at the dataset by opening the .csv file.
    It will look like the screenshot in figure 4.6\. The first 25 rows are shown in
    the screenshot. Each row represents an invoice.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F06_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.6 Screenshot of the .csv file
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '3\. Next we perform some basic checks on the data by the `.info` and`.head`
    commands (see figure 4.7):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/CH04_UN01_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/CH04_F07_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.7 Output for `.info` and `.head` commands
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '4\. Here we can see that the first transaction has been considered the header
    by the code. Hence, we would import the data again, but this time we would specify
    that headers are equal to `None`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '5\. Let’s look at the head again (see figure 4.8). This time it looks correct:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/CH04_F08_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.8 Correct results for `.head()`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '6\. The library we are using for the code accepts the dataset as a list of
    lists. The entire dataset must be a big list while each transaction is an inner
    list in the big list. So, to achieve it, we first convert our `store_dataset`
    dataframe into a list:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 7\. Next, we implement the Apriori algorithm.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For the algorithm, we are working on the `all_records` list we created in step
    6\. The minimum support specified is 0.5 or 50%, the minimum confidence is 25%,
    the minimum lift is 4, and the minimum length of the rule is 2.
  prefs: []
  type: TYPE_NORMAL
- en: 'The output of this step is the `apriori_rules` class object. This object is
    then converted into a list that we can understand. Finally, we print this list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The output of the code will be 0\. This means that no such rules exist that
    satisfy the condition we have set for the rules.
  prefs: []
  type: TYPE_NORMAL
- en: 'We again try to execute the same code, albeit by reducing the minimum support
    to 25%:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, no rules are generated and the output is 0\. Even reducing the minimum
    support to 10% does not lead to any rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we reduce the minimum lift to 2\. This time we get 200 as the output. This
    means that there are 200 such rules that fulfill the criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '8\. Let’s look at the first rule (see figure 4.9):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/CH04_F09_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.9 Output from `print(apriori_rules[0])`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The rule explains the relationship between almonds and burgers. The support
    is .005, and the confidence is 0.25\. Lift, which is 2.92, indicates that this
    rule is quite strong.
  prefs: []
  type: TYPE_NORMAL
- en: '9\. We will now look at all the rules in detail. For that, loop through the
    rules and extract information from each of the iterations. Each of the rules has
    the items constituting the rule and respective values for support, confidence,
    lift, and conviction. We have shown an example in step 8\. Now, in step 9, we
    are just extracting that information for all the rules using a `for` loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The output for this step is shown in figure 4.10\. Here we can observe each
    rule is listed along with the respective values of support, confidence, lift,
    and conviction.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F10_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.10 Output for step 9
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We can interpret the rules easily. For example, the rule almonds -> burgers
    has a lift of 2.92 with a confidence of 25.49% and support of 0.51%. This concludes
    our implementation using Python. This example can be extended to any other real-world
    business dataset.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  Not all the rules generated are not worth using. We will examine how to
    get the best rules from all the rules generated when we deal with the case study
    in the last section of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The Apriori algorithm is a robust and very insightful algorithm. But, like any
    other solution, it has a few shortcomings.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4.2 Challenges with the Apriori algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have seen, the number of subsets generated in the Apriori algorithm is
    quite high (see figure 4.5). It is very tedious to generate candidates’ item sets,
    and hence it becomes quite cumbersome to analyze the dataset. Apriori scans the
    entire dataset multiple times, and hence it requires the database to be loaded
    in the memory. We can safely deduce that it requires a lot of time to make the
    computations. This problem is magnified when we are dealing with a very large
    dataset. In fact, for real-world problems where millions of transactions are generated,
    quite a huge number of candidate item sets are generated, and it is very time-consuming
    to use Apriori on the entire dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Due to this very reason, generally, a minimum value of support is set to reduce
    the number of possible rules. In the previous example, we can calculate the support
    for level 1 combinations, as shown in table 4.3\. Here, if we set the minimum
    value of support as 0.5, only one rule will be shortlisted. Support is calculated
    for each of the combination of the items. For example, for milk and bread, the
    number of transactions is 2, while the total number of transactions is 5\. So
    the support is 2/5, which is 0.4.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.3 Support for level 1 combinations
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Combination | Number of transactions | Total transactions | Support |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Eggs  | 2  | 5  | 0.4  |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Bread  | 2  | 5  | 0.4  |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Cheese  | 0  | 5  | 0  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs, Bread  | 4  | 5  | 0.8  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs, Cheese  | 2  | 5  | 0.4  |'
  prefs: []
  type: TYPE_TB
- en: '| Bread, Cheese  | 1  | 5  | 0.2  |'
  prefs: []
  type: TYPE_TB
- en: Setting up a minimum value of support is hence an intelligent tactic to make
    the rules much more manageable. It reduces the time and generates rules that are
    much more significant. After all, the rules generated from the analysis should
    be generalizable enough so that they can be implemented across the entire database.
  prefs: []
  type: TYPE_NORMAL
- en: Exercise 4.2
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Answer these questions to check your understanding:'
  prefs: []
  type: TYPE_NORMAL
- en: The Apriori algorithm scans the database only once. True or False?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If bananas are present in 5 transactions out of a total of 12 transactions,
    it means the support for bananas is 5/12\. True or False?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: But the Apriori algorithm is indeed a great solution. It is still highly popular
    and generally one of the very first algorithms brought up whenever association
    rules are discussed.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  Data preparation is one of the key steps and quite a challenge. We will
    explore this challenge during the case study in section 4.8\.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5 Equivalence class clustering and bottom-up lattice traversal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will now study the equivalence class clustering and bottom-up lattice traversal
    algorithm (ECLAT), which sometimes is considered better than Apriori in terms
    of speed and ease of implementation. ECLAT uses a depth-first search approach.
    This means that ECLAT performs the search in a vertical fashion throughout the
    dataset. It starts at the root node and then goes one level deep and continues
    until it reaches the first terminal note. Let’s say the terminal node is at level
    *X*. Once the terminal node is reached, the algorithm then takes a step back and
    reaches level (*X* – 1) and continues until it finds a terminal node again. Let’s
    understand this process by means of a tree diagram, as shown in figure 4.11.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F11_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.11 Tree diagram to understand the process of the ECLAT algorithm. It
    starts with 1 and ends at 16.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'ECLAT will take the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: The algorithm starts at the root node 1\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It then goes one level deep to root node 2\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It will then continue one more level deep until it reaches terminal node 11\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once it reaches terminal node 11, it then takes a step back and goes to node
    5\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The algorithm then searches if there is any node available that can be used.
    At node 5 we can see that there is no such node available.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Hence, the algorithm again takes a step back and reaches node 2\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At node 2, the algorithm explores again. It finds that it is possible to go
    to node 6\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So, the algorithm goes to node 6 and starts exploring again until it reaches
    terminal node 12\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This process continues until all the combinations have been exhausted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Obviously, the speed of computation depends on the total number of distinct
    items present in the dataset. This is because the number of distinct items defines
    the width of the tree. The items purchased in each of the transactions would define
    the relationship between each node.
  prefs: []
  type: TYPE_NORMAL
- en: During the execution time of ECLAT, each item (either individually or in a pair)
    is analyzed. Let us use the same example we have used for Apriori to understand
    ECLAT better. Refer to table 4.2.
  prefs: []
  type: TYPE_NORMAL
- en: 'ECLAT will undergo the following steps to analyze the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: In the first run, ECLAT will find the invoice numbers for all single items.
    In other words, it will find the invoice numbers for all the items individually.
    It is shown in table 4.4, wherein milk is present in invoice numbers 1001 and
    1003, while eggs are present in all five invoices.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.4 Respective invoices in which each item is present
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Item | Invoice numbers |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Milk  | 1001, 1003  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs  | 1001, 1002, 1003, 1004, 1005  |'
  prefs: []
  type: TYPE_TB
- en: '| Bread  | 1001, 1002, 1003, 1005  |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese  | 1002, 1004  |'
  prefs: []
  type: TYPE_TB
- en: 2\. In the next step, all the two-item datasets are explored as shown in table
    4.5\. For example, milk and eggs are present in invoice numbers 1001 and 1003,
    while milk and cheese are not present in any invoice.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.5 Two-item datasets
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Item | Invoice numbers |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Eggs  | 1001 ,1003  |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Bread  | 1001, 1003  |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Cheese  | —  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs, Bread  | 1001, 1002, 1003, 1005  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs, Cheese  | 1002, 1004  |'
  prefs: []
  type: TYPE_TB
- en: '| Bread, Cheese  | 1002  |'
  prefs: []
  type: TYPE_TB
- en: 3\. In the next step, all three-item datasets are explored, as shown in table
    4.6\. Here we have two combinations only.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.6 Three-item datasets
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Item | Invoice numbers |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Milk, Eggs, Bread  | 1001, 1003  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs, Bread, Cheese  | 1002  |'
  prefs: []
  type: TYPE_TB
- en: 4\. There are no invoices present in our dataset that contain four items.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 5\. Now, depending on the threshold we set for the value of the support count,
    we can choose the rules. So, if we want the minimum number of transactions in
    which the rule should be true to be three, then only one rule qualifies, which
    is {eggs, bread}. If we decide the threshold for the minimum number of transactions
    is two, then rules like {milk, eggs, bread}, {milk, eggs}, {milk, bread}, {eggs,
    bread}, and {eggs, cheese} qualify as the rules.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will now create a Python solution for ECLAT.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5.1 Python implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will now work on the execution of ECLAT using Python. We use the `pyECLAT`
    library here. The dataset looks like figure 4.12\.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F12_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.12 ECLAT for the `pyECLAT` library using Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '2\. Import the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '3\. Generate an ECLAT instance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: There are some properties of ECLAT instance `eclat` generated in the last step
    like `eclat.df_bin`, which is a binary dataframe, and `eclat.uniq_`, which is
    a list of all the unique items.
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Fit the model. We give a minimum support of 0.02 here. After that, we print
    the support:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The output is shown in figure 4.13.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F13_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.13 Output for step 4
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We can interpret the results provided based on the support. For each of the
    items and combination of items, we are getting the value of the support. For example,
    for french fries and eggs, the value of support is 3.43%.
  prefs: []
  type: TYPE_NORMAL
- en: ECLAT has some advantages over the Apriori algorithm. Since it uses a depth-search
    approach, it is faster than Apriori and requires less memory to compute. It does
    not scan the dataset iteratively, and that makes it even faster than Apriori.
    We will compare these algorithms once more after we have studied the last algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 4.6 F-P algorithm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The F-P algorithm is the third algorithm we discuss in this chapter. It is an
    improvement over the Apriori algorithm. Recall in Apriori we face the challenges
    of time-consuming and costly computations. F-P resolves these problems by representing
    the database in the form of a tree called a *frequent pattern tree* or *FP tree*.
    Because of this frequent pattern, there is no need to generate the candidates
    as done in the Apriori algorithm. Let’s discuss F-P in detail now.
  prefs: []
  type: TYPE_NORMAL
- en: An F-P tree is a tree-shaped structure, and it mines the most frequent items
    in the datasets. This is visualized in figure 4.14\.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F14_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.14 An F-P algorithm can be depicted in a tree-diagram structure. Each
    node represents a unique item. The root node is `NULL`.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Each node represents a unique item in the dataset. The root node of the tree
    is generally kept as `NULL`. The other nodes in the tree are the items in the
    dataset. The nodes are connected with each other if they are in the same invoice.
    We will study the entire process in a step-by-step fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Assume we are using the dataset shown in table 4.7\. So we have the unique items
    as Apples, Milk, Eggs, Cheese, and Bread. There are nine transactions, and the
    respective items in each of the transactions are shown in table 4.7\.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.7 Dataset to understand the F-P algorithm
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Transactions | Item sets |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| T1  | Apples, Milk, Eggs  |'
  prefs: []
  type: TYPE_TB
- en: '| T2  | Milk, Cheese  |'
  prefs: []
  type: TYPE_TB
- en: '| T3  | Milk, Bread  |'
  prefs: []
  type: TYPE_TB
- en: '| T4  | Apples, Milk, Cheese  |'
  prefs: []
  type: TYPE_TB
- en: '| T5  | Apples, Bread  |'
  prefs: []
  type: TYPE_TB
- en: '| T6  | Milk, Bread  |'
  prefs: []
  type: TYPE_TB
- en: '| T7  | Apples, Bread  |'
  prefs: []
  type: TYPE_TB
- en: '| T8  | Apples, Milk, Bread, Eggs  |'
  prefs: []
  type: TYPE_TB
- en: '| T9  | Apples, Milk, Bread  |'
  prefs: []
  type: TYPE_TB
- en: 'Let’s apply the F-P algorithm on this dataset now. The steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Like Apriori, the entire dataset is scanned first. Occurrences for each of the
    items is counted, and a frequency is generated. The results are suggested in table
    4.8\. We have arranged the items in descending order of the frequency or the respective
    support count in the entire dataset. For example, apples have been purchased in
    six transactions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.8 Respective frequency for each of the item sets
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Item | Frequency or support count |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Milk  | 7  |'
  prefs: []
  type: TYPE_TB
- en: '| Apples  | 6  |'
  prefs: []
  type: TYPE_TB
- en: '| Bread  | 6  |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese  | 2  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs  | 2  |'
  prefs: []
  type: TYPE_TB
- en: If two items have exactly same frequency, either can be ordered first. In the
    example here, Bread and Apples have the same frequency. So we can keep either
    Bread or Apples as the first one.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Start the construction of the F-P tree. We start with creating the root
    node, which is generally the `NULL` node, in figure 4.15.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F15_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.15 The root node for the tree is generally kept NULL.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 3\. Analyze the first transaction, T1\. Here we have Apples, Milk, and Eggs
    in the first transaction. Out of these three, Milk has the highest support count,
    which is 7\. So a connection is extended from the root node to Milk, and we denote
    it as Milk:1 (see figure 4.16).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F16_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.16 Connection from the root node to Milk. Milk has the highest support;
    hence we have chosen Milk.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 4\. Now look at the other items in T1\. Apples has a support count of 6 and
    Eggs have a support count of 2\. So we will extend the connection from Milk to
    Apples and name it Apples:1 and then from Apples to Eggs and call it Eggs:1 (see
    figure 4.17).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 5\. Look at T2 now. It has Milk and Cheese. Milk is already connected to the
    root node. So the count for Milk becomes 2, and it becomes Milk:2\. Next, we will
    create a branch from Milk to Cheese and name it Cheese:1\. The addition is shown
    in figure 4.18\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F17_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.17 Step 4 of the process where we have finished all the items in T1\.
    All the items—Milk, Apples, and Eggs—are now connected.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F18_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.18 Step 5 of the process where we started to analyze T2\. Milk is already
    connected, so its count increases by 2 while Cheese gets added to the tree.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 6\. Consider T3\. T3 has Milk and Bread. So, similar to step 5, the count for
    Milk is 3, and it becomes Milk:3\. And, similar to step 5, we add another connection
    from Milk to Bread and call it Bread:1\. The updated tree is shown in figure 4.19.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F19_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.19 In step 6, T3 is analyzed. Milk’s count increased by 1 more and
    becomes 3, while Bread is added as a new connection.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 7\. In T4, we have Apples, Milk, and Cheese. The count for Milk becomes 4; for
    Apples it is now 2\. Then we create a branch from Apples to Cheese, calling it
    Cheese:1 (see figure 4.20).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F20_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.20 In step 7 of the process, T4 is being analyzed. The count of Milk
    becomes 4, for Apples it increases to 2, and a new branch from Apples to Cheese
    is added.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 8\. We find in T5 that we have Apples and Bread. Both are not directly connected
    to the root node and have an equal frequency of 6\. So we can take either to be
    connected to the root node. The figure gets updated to figure 4.21\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F21_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.21 After analyzing T5, the diagram changes, as shown here. We have
    Apples and Bread, which get added to the tree.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 9\. This process continues until we exhaust all the transactions, resulting
    in the final figure as shown in figure 4.22\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F22_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.22 The final tree once we have exhausted all the possible combinations
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Great job so far! But there are more steps after this. So far, we have created
    only the tree. Now we need to generate the dataset as shown in table 4.9\. This
    is the output we wish to generate.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.9 Table for the F-P algorithm
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Items | Conditional pattern base | Conditional F-P tree | Frequent pattern
    generated |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Bread  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Apples  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: You might be wondering why there are only four items listed. Since Milk has
    directly originated from the root node and there is no other way to reach it,
    we need not have a separate row for Milk.
  prefs: []
  type: TYPE_NORMAL
- en: 10\. Before continuing, we must fix the minimum support count as 2 for any rule
    to be acceptable. We do this for simplicity’s sake as the dataset is quite small.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: NOTE  For real-life business problems, you are advised to test with multiple
    and even much higher values for the support counts; otherwise, the number of rules
    generated can be very high.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with Cheese as the first item. We can reach cheese through {NULL-Milk-Cheese}
    and {NULL-Milk-Apples-Cheese}. For both paths, the count of Cheese is 1\. Hence,
    (if we ignore NULL) our conditional pattern base is {Milk-Cheese} or {Milk:1}
    and {Milk-Apples:Cheese} or {Milk-Apples:1}. The complete conditional pattern
    base becomes {{Milk:1}, {Milk-Apples:1}}. This information is added to the second
    column of table 4.10\.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.10 Step 10 of the process where we have filled the first cell for Cheese
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Items | Conditional pattern base | Conditional F-P tree | Frequent pattern
    generated |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese  | {{Milk:1}, {Milk-Apples:1}}  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Bread  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Apples  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: 11\. Now if we add the two values in a conditional pattern base, we would get
    Milk as 2 and Apples as 1\. Since we have set up a threshold for the frequency
    count of 2, we will ignore the count of Apples. The value for the conditional
    F-P tree, which is the third column in the table, becomes {Milk:2}. Now we simply
    add the original item to this, which becomes the frequent patten generated or
    column 4\. See table 4.11\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.11 Step 11 of the process where we have finished the details for the
    item Cheese
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Items | Conditional pattern base | Conditional F-P tree | Frequent pattern
    generated |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese  | {{Milk:1}, {Milk-Apples:1}}  | {Milk:2}  | {Milk-Cheese:2}  |'
  prefs: []
  type: TYPE_TB
- en: '| Bread  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Apples  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: 12\. In a similar fashion, all the other cells are filled in the table, resulting
    in the final table (table 4.12).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.12 Final table after we have analyzed all the combinations for the items
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Items | Conditional pattern base | Conditional F-P tree | Frequent pattern
    generated |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Cheese  | {{Milk:1}, {Milk-Apples:1}}  | {Milk:2}  | {Milk-Cheese:2}  |'
  prefs: []
  type: TYPE_TB
- en: '| Bread  | {{Milk-Apples:2}, {Milk:2}, {Apples:2}}  | {{Milk:4, Apples:2},
    {Apples:2}}  | {{Milk-Bread:4}, {Apples-Bread:4}, {Milk-Apples-Bread:2}}  |'
  prefs: []
  type: TYPE_TB
- en: '| Eggs  | {{Milk-Apples:1}, {Milk-Apples-Bread:1}}  | {Milk:2, Apples:2}  |
    {{Milk-Eggs:2}, {Milk-Apples:2}, {Milk-Apples:2}}  |'
  prefs: []
  type: TYPE_TB
- en: '| Apples  | {Milk:4}  | {Milk:4}  | {Milk-Apples:4}  |'
  prefs: []
  type: TYPE_TB
- en: It is a complex process indeed. But once the steps are clear, it is straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: As a result of this exercise, we have received the final set of rules as depicted
    in the final column Frequent Pattern Generated.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  Notice that none of the rules are similar to each other.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the final column, Frequent Pattern Generated, as the rules for our
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The Python implementation for the F-P growth algorithm is quite simple and is
    easy to compute using the libraries. In the interest of space, we have uploaded
    the Jupyter notebook to the GitHub repository of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now explore another interesting topic: sequence rule mining. It is
    a very powerful solution that allows a business to tailor its marketing strategies
    and product recommendations to the customers.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.7 Sequence rule mining
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Consider this: Netflix has a transactional database of all the movies ordered
    by customers over time. If it analyzes and finds that 65% of customers who viewed
    a war movie *X* also viewed a romantic comedy *Y* in the following month, then
    this is very insightful and actionable information. It will allow Netflix to recommend
    its offerings to customers and customize its marketing strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: So far in the chapter, we have covered three algorithms for association rules.
    But all the data points were limited to the same dataset, and there was no sequencing
    involved. Sequential pattern mining allows us to analyze a dataset that has a
    sequence of events happening. By analyzing the dataset, we can find statistically
    relevant patterns, which allows us to decipher the entire sequence of events.
    Obviously, the sequence of events is in a particular order, which is a very important
    property to be considered during sequence rule mining.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  Sequence rule mining is different from time-series analysis. To learn
    more about time-series analysis, refer to the appendix.
  prefs: []
  type: TYPE_NORMAL
- en: Sequence rule mining is utilized across multiple domains and functions. It can
    be used in biology to extract information during DNA sequencing, or it can be
    used to understand the online search pattern of a user. Sequence rule mining would
    help us understand what the user is going to search next. During the discussion
    of association rules, we used the transactions in which milk, bread, and eggs
    were purchased in the same transaction. Sequence rule mining is an extension to
    that wherein we analyze consecutive transactions and try to decipher the sequence
    present, if any.
  prefs: []
  type: TYPE_NORMAL
- en: While studying the Sequential Pattern Discovery Using Equivalence classes (SPADE)
    algorithm, we cover the mathematical concepts that form the base of the algorithm.
    These concepts are a little tricky and might require more than one reading to
    grasp.
  prefs: []
  type: TYPE_NORMAL
- en: 4.7.1 Sequential Pattern Discovery Using Equivalence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We now explore sequence rule mining using SPADE. It was suggested by Mohammed
    J. Zaki; the link to the paper is at the end of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: So we wish to analyze a sequence of events. For example, a customer bought a
    mobile phone and a charger. After a week, they bought earphones, and after two
    weeks, they bought a mobile phone cover and screen guard. So, in each of the transactions,
    there were items purchased. And each transaction can be called an event. Let’s
    understand it in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Let us assume we have the complete list of items for the discussion. It will
    contain items like i[1], i[2], i[3], i[4], i[5], and so on. So we can write *I*
    = {i[1], i[2], i[3], i[4], i[5]………, i[*n*]} where we have *n* distinct items in
    total.
  prefs: []
  type: TYPE_NORMAL
- en: Items can be anything. If we consider the same example of a grocery store, items
    can be milk, eggs, cheese, bread, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: An event will be a collection of items in the same transaction. An event can
    contain items like (i[1], i[5], i[4], i[8]). For example, an event can contain
    items bought in the same transaction (milk, sugar, cheese, bread). We will denote
    an event by ⍺.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s understand a sequence. A sequence is nothing but events in an order.
    In other words, ⍺[1] -> ⍺[2] -> ⍺[3] -> ⍺[4] can be termed a sequence of events.
    For example, (Milk, Cheese) -> (Bread, Eggs) -> (Cheese, Bread, Sugar) -> (Milk,
    Bread) is a sequence of transactions. It means that in the first transaction,
    milk and cheese were bought. In the following transaction, bread and eggs were
    bought, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: A sequence with *k* items is a k-item sequence. For example, sequence (Milk,
    Bread) -> (Eggs) contains three items. Now let’s explore the SPADE algorithm step
    by step.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say we have the following sequences generated. In the first sequence,
    ID 1001, Milk is bought in the very first transaction. In the second one, Milk,
    Eggs, and Bread are bought. They are followed by Milk and Bread. In the fourth
    one, only Sugar is purchased. In the fifth and final transaction of sequence 1001,
    Bread and Apples are purchased; this is applicable to all the respective sequences.
    For example, in sequence ID 1001, we have multiple events. In the first purchase,
    Milk is bought. Then (Milk, Eggs, Bread) are bought and so on. See table 4.13.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.13 The dataset for sequence mining
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Sequence ID | Sequence |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | <(Milk) (Milk, Eggs, Bread) (Milk, Bread) (Sugar) (Bread, Apples)>  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | <(Milk, Sugar) (Bread) (Eggs, Bread) (Milk, Cheese)>  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | <(Cheese, Apples) (Milk, Eggs) (Sugar, Apples) (Bread) (Eggs)>  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | <(Cheese, Bananas) (Milk, Apples) (Bread) (Eggs) (Bread)>  |'
  prefs: []
  type: TYPE_TB
- en: Table 4.13 can be converted into a vertical data format as shown in table 4.14\.
    In this step, we calculate the frequencies for one-sequence items, which are sequences
    with only one item. For this, only a single database scan is required. We simply
    have the sequence ID and element ID for each of the items.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.14 Vertical format for table 4.13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Sequence ID | Element ID | Items |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 1  | Milk  |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 2  | Milk, Eggs, Bread  |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 3  | Milk, Bread  |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 4  | Sugar  |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 5  | Bread, Apples  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 1  | Milk, Sugar  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 2  | Bread  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 3  | Eggs, Bread  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 4  | Milk, Cheese  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 1  | Cheese, Apples  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 2  | Milk, Eggs  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 3  | Sugar, Apples  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 4  | Bread  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 5  | Eggs  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 1  | Cheese, Bananas  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 2  | Milk, Apples  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 3  | Bread  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 4  | Eggs  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 5  | Bread  |'
  prefs: []
  type: TYPE_TB
- en: Table 4.14 is nothing but a vertical tabular representation of table 4.13\.
    For example, in sequence ID 1001, at the element ID 1 we have Milk. For sequence
    ID 1001, at the element ID 2 we have Milk, Eggs, Bread, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: For the purpose of explanation, we are considering only two items—0 Milk and
    Eggs—and the support threshold of 2\.
  prefs: []
  type: TYPE_NORMAL
- en: Then, in the next step, we will break it down for each of the items. For example,
    Milk appears in sequence ID 1001 and element ID 1, sequence ID 1001 and element
    ID 2, sequence ID 1001 and element ID 3, sequence ID 1002 and element ID 1, and
    so on. It results in a table like table 4.15 where we have shown Milk and Eggs.
    It needs to be applied to all the items in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.15 Respective sequence IDs for Milk and Eggs
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Milk | Eggs |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence ID | Element ID | Sequence ID | Element ID |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 1  | 1001  | 2  |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 2  | 1002  | 3  |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 3  | 1003  | 2  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 1  | 1003  | 5  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 4  | 1004  | 4  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 2  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 2  |  |  |'
  prefs: []
  type: TYPE_TB
- en: 'Now we wish to count two sequences or those with two-item sequences. We can
    have two sequences: either Milk -> Eggs or Eggs -> Milk. Let’s first take Milk
    -> Eggs.'
  prefs: []
  type: TYPE_NORMAL
- en: For Milk -> Eggs, we need to have Milk in front of Eggs. For the same sequence
    ID, if the element ID of Milk is less than the element ID of Eggs, then it is
    an eligible sequence. In the preceding example, for sequence ID 1001, the element
    ID of Milk is 1, while the element ID of Eggs is 2\. So we can add that as the
    first eligible pair, as shown in the first row of table 4.16\. The same is true
    for sequence ID 1002\. In table 4.15, row 4, we have sequence ID 1002\. The element
    ID of Milk is 1, while that of Eggs in row 2 is 3\. Again, the element ID of Milk
    is lesser than the element ID of Eggs, so it becomes the second entry, and the
    process continues. The key point is to have the same sequence ID while comparing
    the respective element IDs of Milk and Eggs.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.16 Sequence for Milk and Eggs
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Milk and Eggs |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence ID | Element ID (Milk) | Element ID (Eggs) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 1  | 2  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 1  | 3  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 2  | 5  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 2  | 4  |'
  prefs: []
  type: TYPE_TB
- en: By using the same logic, we can create the table for Eggs -> Milk, which is
    shown in table 4.17\. Again, the key point is to have the same sequence ID while
    comparing the respective element IDs of Milk and Eggs.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.17 Sequence for Eggs and Milk
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Eggs and Milk |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence ID | Element ID (Eggs) | Element ID (Milk) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 2  | 3  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 3  | 4  |'
  prefs: []
  type: TYPE_TB
- en: This can be done for each of the possible combinations. We now move to creating
    three-item sequences, and we will create Milk, Eggs -> Milk. For this purpose,
    we have to join the two tables. See table 4.18.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.18 Combining the sequence Milk -> Eggs and Eggs -> Milk to join the
    tables
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Milk and Eggs |  | Eggs and Milk |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence ID | Element ID (Milk) | Element ID(Eggs) |  | Sequence ID | Element
    ID (Eggs) | Element ID (Milk) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 1  | 2  |  | 1001  | 2  | 3  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 1  | 3  |  | 1002  | 3  | 4  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 2  | 5  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 2  | 4  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: The logic of joining is matching the sequence ID and the element ID. We have
    highlighted the matching ones in red and green, respectively, although this will
    not show up in the printed book. For sequence ID 1001, the element ID of Eggs
    in the left table matches the element ID of Eggs in the right table, and that
    becomes the first entry of table 4.19, which shows the results. Similarly, for
    sequence ID 1002, element ID 3 matches.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4.19 Final table after we have analyzed all the combinations for the items
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Milk, Eggs -> Milk |'
  prefs: []
  type: TYPE_TB
- en: '| --- |'
  prefs: []
  type: TYPE_TB
- en: '| Sequence ID | Element ID (Milk) | Element ID (Eggs) | Element ID (Milk) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 1  | 2  | 3  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 1  | 3  | 4  |'
  prefs: []
  type: TYPE_TB
- en: This process continues. The algorithm stops when no frequent sequences can be
    found.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now implement SPADE on a dataset using Python. We use the `pyspade`
    library, and thus we have to load the dataset and call the function. It generates
    the result for us. The support is kept as 0.6 here, and then we print the results
    (see figure 4.23):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '![figure](../Images/CH04_F24_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.23 SPADE implemented on the `pyspade` library using Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 4.8 Case study for association rules
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Association rule mining is quite a helpful and powerful solution. Next, we are
    going to solve an actual case study using association rules. Recall that, at the
    start of the chapter, we suggested you study the pattern of a grocery store. What
    is the logic of such arrangements in the store?
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this: you are working for a grocery retailer like Walmart, Tesco,
    Spar, Marks & Spencer’s, etc., and you are planning the visual layout of a new
    store. Obviously, it is imperative that retail stores utilize the space in the
    store wisely and to the maximum capacity. At the same time, it is vital that the
    movement of the customers is not hindered. Customers should have access to all
    the items on display and be able to navigate easily. You might have experienced
    some stores where you feel choked and bombarded with displays while others are
    neatly stacked.'
  prefs: []
  type: TYPE_NORMAL
- en: How do we solve this problem? There can be multiple solutions. Some retailers
    might wish to group the items based on their categories. For example, they might
    want to keep all the baking products on one shelf or use some other condition.
    We are studying the machine learning example here.
  prefs: []
  type: TYPE_NORMAL
- en: Using market basket analysis, we can generate the rules that indicate the respective
    relationships between various items. We can predict which items are frequently
    bought together, and they can be kept together in the store. For example, if we
    know that milk and bread are bought together, then bread can be kept near the
    milk counter. The customer purchasing milk can locate bread easily and continue
    with their purchase.
  prefs: []
  type: TYPE_NORMAL
- en: 'But it is not as easy as it sounds. Let us solve this case step by step:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Business problem definition*—The very first step is defining the business
    problem, which is clear to us. We wish to discover the relationships between various
    items so that the arrangement in the store can be made better. Here, *planograms*
    come into the picture. Planograms help the retailer plan the utilization of the
    space in the store in a wise manner so that the customer can also navigate and
    access the products easily. It can be considered a visual layout of the store.
    An example is shown in figure 4.24.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![figure](../Images/CH04_F25_Verdhan.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.24 An example of a planogram. Planograms are very useful for visual
    merchandising.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In the figure, we can see that there are specific areas for each item category.
    Association rules are quite insightful to help generate directions for planograms.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. *Data discovery*—The next step is data discovery, wherein the historical
    transactions are scouted and loaded into a database. Typically, a transaction
    can look like table 4.20\. Note it is quite a challenge to convert this data format
    into one that can be consumed by the association rule algorithms.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Table 4.20 Example of invoices generated in a real-world retail store
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Invoice number | Date | Items | Amount |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1001  | 01-Jun-21  | Milk, Eggs, Cheese, Bread  | $10  |'
  prefs: []
  type: TYPE_TB
- en: '| 1002  | 01-Jun-21  | Bread, Bananas, Apples, Butter  | $15  |'
  prefs: []
  type: TYPE_TB
- en: '| 1003  | 01-Jun-21  | Butter, Carrots, Cheese, Eggs, Bread, Milk, Bananas  |
    $19  |'
  prefs: []
  type: TYPE_TB
- en: '| 1004  | 01-Jun-21  | Milk  | $1  |'
  prefs: []
  type: TYPE_TB
- en: '| 1005  | 01-Jun-21  | Bread  | $0.80  |'
  prefs: []
  type: TYPE_TB
- en: 3\. *Data preparation*—This step perhaps is the most difficult step. As we have
    seen, association rules model creation is a very simple task. We have libraries
    that can do the heavy lifting for us. But the dataset expected by them is in a
    particular format. This is a tedious task; it is quite time-consuming and requires
    a lot of data preprocessing skills.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'There are a few considerations you should keep in mind while preparing the
    dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes we get NULL or blank values during the data preparation phase. Missing
    values in the datasets can lead to problems while computing. In other machine
    learning solutions, we would advise to treat the missing values. In the case of
    association rules, we suggest ignoring the respective transactions and not considering
    them in the final dataset.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Many times, we get junk values in the data. Special characters like !@%^&*()_
    are found in the datasets. This can be attributed to incorrect entries in the
    system. Hence, data cleaning is required. We cover the data preprocessing step
    in detail in chapter 11, wherein we deal with NULL values and junk values.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Converting a table into a format that can be understood and consumed by the
    association rule learning algorithms is an imperative but arduous step. Go through
    the concept of SQL pivoting to understand the concept better.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 4\. *Model preparation*—Perhaps the easiest of the steps is modeling. We have
    already solved Python solutions for different algorithms, so you should be quite
    comfortable with it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '5\. *Model interpretation*—Creating the model might be easy, but interpretation
    of the rules is not. Sometimes, you have rules like #NA -> (Milk, Cheese). Such
    a rule is obviously not usable and does not make any sense. It indicates that
    the data preparation was not correct and some junk values are still present in
    the dataset. Another example is (Some items) -> (Packaging material); this is
    perhaps the most obvious rule but, again, not usable. This rule indicates that
    whenever shopping is done, packaging material is also purchased. That’s obvious,
    right? A final example is (Potatoes, Tomatoes) -> (Onions). This kind of rule
    might look correct, but it is a common-sense fact that the retailer would already
    know. Obviously, most of the customers who are buying vegetables will buy potatoes,
    tomatoes, and onions together. Such rules might not add much value to the business.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The threshold for support, confidence, lift, and conviction allows us to filter
    out the most important rules. We can sort the rules in the descending order of
    the lift and then remove the most obvious ones.
  prefs: []
  type: TYPE_NORMAL
- en: It is of vital importance that business stakeholders and subject matter experts
    are involved at every step. In this case study, the operations team, visual merchandising
    team, product teams, and marketing teams are the key players, which should be
    closely aligned at each step.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. *Improving the planogram*—Once the rules are generated and accepted, then
    we can use them to improve the planogram for the retail space. The retailer can
    use them to improve the marketing strategy and improve product promotions. For
    example, if a rule like (A, B) -> (C) is accepted, the retailer might wish to
    create a bundle of the products and sell them as a single entity. It will increase
    the average number of items purchased in the same transaction for the business.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This case study can be extended to any other domain or business function. For
    example, the same steps can be used if we wish to examine user’s movement across
    web pages. Web developers can analyze the historical clicks and usages of the
    customers on their websites. By identifying the patterns, they can find out what
    users tend to click and which features will maximize their engagement. Medical
    practitioners can use association rules to better diagnose patients. The doctors
    can compare the probability of the symptoms in relationship with other symptoms
    and provide a more accurate diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: 4.9 Concluding thoughts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are some assumptions and limitations in the association rules and sequence
    rules we have studied:'
  prefs: []
  type: TYPE_NORMAL
- en: The respective significance of an item is ignored while we generate the rules.
    For example, if a customer purchased five cans of milk and 1 kg of apples in a
    transaction, it is treated similarly to an invoice in which one can of milk and
    5 kg of apples are purchased. Hence, we should bear in mind that the respective
    *weight* of an item is not being considered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cost of an item indicates the perceived value of a product. Some products
    that are costly are more important, and hence, if they are purchased by the customer,
    more revenue can be generated. While analyzing the invoices, we ignore the cost
    associated with an item.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While analyzing the sequence, we have not considered the respective time periods
    between the two transactions. For example, if between T1 and T2 there were 10
    days while between T2 and T3 there were 40 days, both are considered as the same.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In all the analyses, we have considered different categories as the same. Perishable
    items and nonperishable items are treated in a similar fashion. For example, fresh
    milk with a shelf life of two to three days is treated similarly to washing powder,
    which has a much longer shelf life.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many times, we receive noninteresting rules after analysis. These results are
    from common sense (Potatoes, Tomatoes) -> (Onion). Such rules are not of much
    use. We face such a problem a lot of the time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While noninteresting rules are a challenge, a huge number of discovered rules
    are again one of the problems. We get hundreds of rules, and it becomes difficult
    to understand and analyze each one of them. Here the thresholding becomes handy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The time and memory requirements for computations are huge. The algorithms require
    scanning the datasets many times, and hence it is quite a time-consuming exercise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The rules generated are dependent on the dataset that has been used for analysis.
    For example, if we analyze the dataset generated during summers only, we cannot
    use the rules for winters as consumers’ preferences change between different weather
    conditions. Moreover, we should refresh the algorithms over time since with the
    passage of time, the macro- and micro-economic factors change and hence the algorithms
    should be refreshed too.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are some other algorithms that are also of interest. For association rules,
    we can have multirelation association rules, k-optimal pattern discovery, approximate
    frequent datasets, generalized association rules, high-order pattern discovery,
    etc. For sequence mining, we have Generalized Sequence Pattern, FreeSpan, PrefixSpan,
    mining associated patterns, etc. These algorithms are quite interesting and can
    be studied for knowledge enhancement.
  prefs: []
  type: TYPE_NORMAL
- en: Association rules and sequence mining are quite interesting topics. Various
    business domains and functions are increasingly using association rules to understand
    the pattern of events. These insights allow the teams to make sound and scientific
    decisions to improve the customer experience and overall engagement. In this chapter,
    we have explored association rules and sequence mining. These were studied using
    Apriori, F-P, and ECLAT algorithms, and for sequence mining we used SPADE.
  prefs: []
  type: TYPE_NORMAL
- en: 4.10 Practical next steps and suggested readings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following provides suggestions for what to do next and offers some helpful
    reading:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go through these research papers for the association rules algorithm:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fast Discovery of Association Rules: [https://mng.bz/eyqv](https://mng.bz/eyqv)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fast Algorithms for Mining Association Rules: [https://mng.bz/64GZ](https://mng.bz/64GZ)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Efficient Analysis of Pattern and Association Rule Mining Approaches: [https://arxiv.org/pdf/1402.2892.pdf](https://arxiv.org/pdf/1402.2892.pdf)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A Review of Association Rule Mining Techniques with Respect to their Privacy-Preserving
    Capabilities: [https://mng.bz/0Q0N](https://mng.bz/0Q0N)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For sequence mining, go through these research papers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SPADE: An Efficient Algorithm for Mining Frequent Sequences: [https://mng.bz/9YG7](https://mng.bz/9YG7)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sequential Mining: Patterns and Algorithm Analysis: [https://arxiv.org/pdf/1311.0350.pdf](https://arxiv.org/pdf/1311.0350.pdf)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sequential Pattern Mining Algorithm Based on Interestingness: [https://ieeexplore.ieee.org/document/8567170](https://ieeexplore.ieee.org/document/8567170)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A New Approach for Problem of Sequential Pattern Mining: [https://mng.bz/jpxr](https://mng.bz/jpxr)'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Association rule learning identifies relationships between variables in datasets,
    like the beer and diaper example.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Through data analysis, such associations can inform marketing strategies, product
    placement, and pricing in supermarkets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Market basket analysis in retail uses association rules to find buying patterns
    and is applicable in other industries like bioinformatics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Association rules consist of antecedents leading to consequents, denoted as
    P -> Q, with no common elements between them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rule significance depends on support (frequency), confidence (accuracy), lift
    (dependence measurement), and conviction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High support, confidence, lift, and conviction indicate stronger, more useful
    rules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Apriori algorithm generates item sets for association rules using a “bottom-up”
    approach but faces challenges with large datasets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ECLAT algorithm uses a depth-first search for faster, memory-efficient computation
    of frequent item sets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The F-P growth algorithm improves on Apriori by using a frequent pattern tree
    to eliminate candidate generation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequence rule mining helps explain user behavior over time, distinct from time-series
    analysis.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The SPADE algorithm analyzes sequences of events and dependencies over time
    for sequence rule mining.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python implementations of the Apriori, ECLAT, F-P growth, and SPADE algorithms
    are achievable with appropriate libraries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluation metrics and threshold settings for support, confidence, and lift
    are crucial for efficient rule generation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sequence rule mining has applications in marketing, bioinformatics, and user
    interaction analysis, allowing for actionable insights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
