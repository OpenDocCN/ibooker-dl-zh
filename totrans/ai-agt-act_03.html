<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div class="readable-text" id="p1"> 
   <h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">4</span></span> <span class="chapter-title-text">Exploring multi-agent systems</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header sigil_not_in_toc">This chapter covers</h3> 
   <ul> 
    <li class="readable-text" id="p2">Building multi-agent systems using AutoGen Studio </li> 
    <li class="readable-text" id="p3">Building a simple multi-agent system</li> 
    <li class="readable-text" id="p4">Creating agents that can work collaboratively over a group chat</li> 
    <li class="readable-text" id="p5">Building an agent crew and multi-agent systems using CrewAI</li> 
    <li class="readable-text" id="p6">Extending the number of agents and exploring processing patterns with CrewAI </li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p7"> 
   <p>Now let’s take a journey from AutoGen to CrewAI, two well-established multi-agent platforms. We’ll start with AutoGen, a Microsoft project that supports multiple agents and provides a studio for working with them. We’ll explore a project from Microsoft called AutoGen, which supports multiple agents but also provides a studio to ease you into working with agents. From there, we’ll get more hands-on coding of AutoGen agents to solve tasks using conversations and group chat collaborations. </p> 
  </div> 
  <div class="readable-text intended-text" id="p8"> 
   <p>Then, we’ll transition to CrewAI, a self-proposed enterprise agentic system that takes a different approach. CrewAI balances role-based and autonomous agents that can be sequentially or hierarchically flexible task management systems. We’ll explore how CrewAI can solve diverse and complex problems.</p> 
  </div> 
  <div class="readable-text intended-text" id="p9"> 
   <p>Multi-agent systems incorporate many of the same tools single-agent systems use but benefit from the ability to provide outside feedback and evaluation to other agents. This ability to support and criticize agent solutions internally gives multi-agent systems more power. We’ll explore an introduction to multi-agent systems, beginning with AutoGen Studio in the next section.</p> 
  </div> 
  <div class="readable-text" id="p10"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_41"><span class="num-string">4.1</span> Introducing multi-agent systems with AutoGen Studio</h2> 
  </div> 
  <div class="readable-text" id="p11"> 
   <p>AutoGen Studio is a powerful tool that employs multiple agents behind the scenes to solve tasks and problems a user directs. This tool has been used to develop some of the more complex code in this book. For that reason and others, it’s an excellent introduction to a practical multi-agent system.</p> 
  </div> 
  <div class="readable-text intended-text" id="p12"> 
   <p>Figure 4.1 shows a schematic diagram of the agent connection/communication patterns AutoGen employs. AutoGen is a conversational multi-agent platform because communication is done using natural language. Natural language conversation seems to be the most natural pattern for agents to communicate, but it’s not the only method, as you’ll see later.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p13">  
   <img alt="figure" src="../Images/4-1.png" width="839" height="464"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.1</span> How AutoGen agents communicate through conversations (Source: AutoGen)</h5>
  </div> 
  <div class="readable-text" id="p14"> 
   <p>AutoGen supports various conversational patterns, from group and hierarchical to the more common and simpler proxy communication. In proxy communication, one agent acts as a proxy and directs communication to relevant agents to complete tasks. A proxy is similar to a waiter taking orders and delivering them to the kitchen, which cooks the food. Then, the waiter serves the cooked food.</p> 
  </div> 
  <div class="readable-text intended-text" id="p15"> 
   <p>The basic pattern in AutoGen uses a <code>UserProxy</code> and one or more assistant agents. Figure 4.2 shows the user proxy taking direction from a human and then directing an assistant agent enabled to write code to perform the tasks. Each time the assistant completes a task, the proxy agent reviews, evaluates, and provides feedback to the assistant. This iteration loop continues until the proxy is satisfied with the results.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p16">  
   <img alt="figure" src="../Images/4-2.png" width="1009" height="444"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.2</span> The user proxy agent and assistant agent communication (Source: AutoGen)</h5>
  </div> 
  <div class="readable-text" id="p17"> 
   <p>The benefit of the proxy is that it works to replace the required human feedback and evaluation, and, in most cases, it does a good job. While it doesn’t eliminate the need for human feedback and evaluation, it produces much more complete results overall. And, while the iteration loop is time consuming, it’s time you could be drinking a coffee or working on other tasks.</p> 
  </div> 
  <div class="readable-text intended-text" id="p18"> 
   <p>AutoGen Studio is a tool developed by the AutoGen team that provides a helpful introduction to conversable agents. In the next exercise, we’ll install Studio and run some experiments to see how well the platform performs. These tools are still in a rapid development cycle, so if you encounter any problems, consult the documentation on the AutoGen GitHub repository.</p> 
  </div> 
  <div class="readable-text" id="p19"> 
   <h3 class="readable-text-h3" id="sigil_toc_id_42"><span class="num-string">4.1.1</span> Installing and using AutoGen Studio</h3> 
  </div> 
  <div class="readable-text" id="p20"> 
   <p>Open the <code>chapter_04</code> folder in Visual Studio Code (VS Code), create a local Python virtual environment, and install the <code>requirements.txt</code> file. If you need assistance with this, consult appendix B to install all of this chapter’s exercise requirements.</p> 
  </div> 
  <div class="readable-text intended-text" id="p21"> 
   <p>Open a terminal in VS Code (Ctrl-`, Cmd-`) pointing to your virtual environment, and run AutoGen Studio using the command shown in listing 4.1. You’ll first need to define an environment variable for your OpenAI key. Because ports 8080 and 8081 are popular, and if you have other services running, change the port to 8082 or something you choose.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p22"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.1</span> Launching AutoGen Studio </h5> 
   <div class="code-area-container"> 
    <pre class="code-area"># set environment variable on Bash (Git Bash)
export OPENAI_API_KEY=”&lt;your API key&gt;”         <span class="aframe-location"/> #1

# sent environment variable with PowerShell
$env:VAR_NAME =”&lt;your API key&gt;"                #1

autogenstudio ui --port 8081    <span class="aframe-location"/> #2</pre> 
    <div class="code-annotations-overlay-container">
     #1 Use the appropriate command for your terminal type.
     <br/>#2 Change the port if you expect or experience a conflict on your machine.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p23"> 
   <p>Navigate your browser to the AutoGen Studio interface shown in figure 4.3 (as of this writing). While there may be differences, one thing is for sure: the primary interface will still be chat. Enter a complex task that requires coding. The example used here is <code>Create</code> <code>a</code> <code>plot</code> <code>showing</code> <code>the</code> <code>popularity</code> <code>of</code> <code>the</code> <code>term</code> <code>GPT</code> <code>Agents</code> <code>in</code> <code>Google</code> <code>search.<span class="aframe-location"/></code></p> 
  </div> 
  <div class="browsable-container figure-container" id="p24">  
   <img alt="figure" src="../Images/4-3.png" width="1012" height="664"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.3</span> Entering a task for the agents to work on in the AutoGen interface</h5>
  </div> 
  <div class="readable-text" id="p25"> 
   <p>The agent assistant generates code snippets to perform or complete various subtasks as the agents work together through the task in the example. The user proxy agent then attempts to execute those code snippets and assesses the output. In many cases, proving the code runs and produces the required output is sufficient for the user proxy agent to approve the task’s completion.</p> 
  </div> 
  <div class="readable-text intended-text" id="p26"> 
   <p>If you encounter any problems with the assistant agent requests, ask the proxy agent to try a different method or another problem. This highlights a bigger problem with agentic systems using packages or libraries that have expired and no longer work. For this reason, it’s generally better to get agents to execute actions rather than build code to perform actions as tools.</p> 
  </div> 
  <div class="readable-text print-book-callout" id="p27"> 
   <p><span class="print-book-callout-head">Tip</span>  Executing AutoGen and AutoGen Studio using Docker is recommended, especially when working with code that may affect the operating system. Docker can isolate and virtualize the agents’ environment, thus isolating potentially harmful code. Using Docker can help alleviate any secondary windows or websites that may block the agent process from running. </p> 
  </div> 
  <div class="readable-text" id="p28"> 
   <p>Figure 4.4 shows the agent’s completion of the task. The proxy agent will collect any generated code snippet, images, or other documents and append<span class="aframe-location"/> them to the message. You can also review the agent conversation by opening the Agent Messages expander. In many cases, if you ask the agent to generate plots or applications, secondary windows will open showing those results.</p> 
  </div> 
  <div class="browsable-container figure-container" id="p29">  
   <img alt="figure" src="../Images/4-4.png" width="1012" height="559"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.4</span> The output after the agents complete the task</h5>
  </div> 
  <div class="readable-text intended-text" id="p30"> 
   <p>Amazingly, the agents will perform most tasks nicely and complete them well. Depending on the complexity of the task, you may need to further iterate with the proxy. Sometimes, an agent may only go so far to complete a task because it lacks the required skills. In the next section, we’ll look at how to add skills to agents.</p> 
  </div> 
  <div class="readable-text" id="p31"> 
   <h3 class="readable-text-h3" id="sigil_toc_id_43"><span class="num-string">4.1.2</span> Adding skills in AutoGen Studio</h3> 
  </div> 
  <div class="readable-text" id="p32"> 
   <p>Skills and tools, or <em>actions,</em> as we refer to them in this book, are the primary means by which agents can extend themselves. Actions give agents the ability to execute code, call APIs, or even further evaluate and inspect generated output. AutoGen Studio currently begins with just a basic set of tools to fetch web content or generate images.</p> 
  </div> 
  <div class="readable-text print-book-callout" id="p33"> 
   <p><span class="print-book-callout-head">Note </span> Many agentic systems employ the practice of allowing agents to code to solve goals. However, we discovered that code can be easily broken, needs to be maintained, and can change quickly. Therefore, as we’ll discuss in later chapters, it’s better to provide agents with skills/actions/tools to solve problems. </p> 
  </div> 
  <div class="readable-text" id="p34"> 
   <p>In the following exercise scenario, we’ll add a skill/action to inspect an image using the OpenAI vision model. This will allow the proxy agent to provide feedback if we ask the assistant to generate an image with particular content.</p> 
  </div> 
  <div class="readable-text intended-text" id="p35"> 
   <p>With AutoGen Studio running, go to the Build tab and click Skills, as shown in figure 4.5. Then, click the New Skill button to open a code panel where you can copy–paste code to. From this tab, you can also configure models, agents, and agent workflows.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p36">  
   <img alt="figure" src="../Images/4-5.png" width="1100" height="966"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.5</span> Steps to creating a new skill on the Build tab</h5>
  </div> 
  <div class="readable-text intended-text" id="p37"> 
   <p>Enter the code shown in listing 4.2 and also provided in the book’s source code as <code>describe_image.py</code>. Copy and paste this code into the editor window, and then click the Save button at the bottom.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p38"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.2</span> <code>describe_image.py</code> </h5> 
   <div class="code-area-container"> 
    <pre class="code-area">import base64
import requests
import os

def describe_image(image_path='animals.png') -&gt; str:
    """
    Uses GPT-4 Vision to inspect and describe the contents of the image.

    :param input_path: str, the name of the PNG file to describe.
    """
    api_key = os.environ['OPEN_API_KEY']

    # Function to encode the image
    def encode_image(image_path):     <span class="aframe-location"/> #1
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    # Getting the base64 string
    base64_image = encode_image(image_path)

    headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {api_key}"
    }

    payload = {
    "model": "gpt-4-turbo",
    "messages": [
        {
        "role": "user",
        "content": [
            {
            "type": "text",
            "text": "What’s in this image?"
            },
            {
            "type": "image_url",
            "image_url": {
         "url": f"data:image/jpeg;base64,{base64_image}"     <span class="aframe-location"/> #2
            }
            }
        ]
        }
    ],
    "max_tokens": 300
    }

    response = requests.post(
        "https://api.openai.com/v1/chat/completions",
        headers=headers,
        json=payload)

    return response.json()["choices"][0]["message"] <span class="aframe-location"/> #3
["content"]                                          #3</pre> 
    <div class="code-annotations-overlay-container">
     #1 Function to load and encode the image as a Base64 string
     <br/>#2 Including the image string along with the JSON payload
     <br/>#3 Unpacking the response and returning the content of the reply
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p39"> 
   <p>The <code>describe_image</code> function uses the OpenAI GPT-4 vision model to describe what is in the image. This skill can be paired with the existing generate_image skill as a quality assessment. The agents can confirm that the generated image matches the user’s requirements.</p> 
  </div> 
  <div class="readable-text intended-text" id="p40"> 
   <p>After the skill is added, it must be added to the specific agent workflow and agent for use. Figure 4.6 demonstrates adding the new skill to the primary assistant agent in the general or default agent workflow. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p41">  
   <img alt="figure" src="../Images/4-6.png" width="1012" height="749"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.6</span> Configuring the primary_assistant agent with the new skill</h5>
  </div> 
  <div class="readable-text intended-text" id="p42"> 
   <p>Now that the skill is added to the primary assistant, we can task the agent with creating a specific image and validating it using the new describe_image skill. Because image generators notoriously struggle with correct text, we’ll create an exercise task to do just that.</p> 
  </div> 
  <div class="readable-text intended-text" id="p43"> 
   <p>Enter the text shown in listing 4.3 to prompt the agents to create a book image cover for this book. We’ll explicitly say that the text needs to be correct and insist that the agent uses the new <code>describe_image</code> function to verify the image.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p44"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.3</span> Prompting for a book cover</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">Please create a cover for the book GPT Agents In Action, use the 
describe_image skill to make sure the title of the book is spelled 
correctly on the cover</pre>  
   </div> 
  </div> 
  <div class="readable-text" id="p45"> 
   <p>After the prompt is entered, wait for a while, and you may get to see some dialogue exchanged about the image generation and verification process. In the end, though, if everything works correctly, the agents will return with the results shown in figure 4.7.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p46">  
   <img alt="figure" src="../Images/4-7.png" width="1012" height="669"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.7</span> The generated file outputs from the agent work on the image generation task</h5>
  </div> 
  <div class="readable-text intended-text" id="p47"> 
   <p>Remarkably, the agent coordination completed the task in just a couple of iterations. Along with the images, you can also see the various helper code snippets generated to assist with task completion. AutoGen Studio is impressive in its ability to integrate skills that the agents can further adapt to complete some goal. The following section will show how these powerful agents are implemented in code.</p> 
  </div> 
  <div class="readable-text" id="p48"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_44"><span class="num-string">4.2</span> Exploring AutoGen</h2> 
  </div> 
  <div class="readable-text" id="p49"> 
   <p>While AutoGen Studio is a fantastic tool for understanding multi-agent systems, we must look into the code. Fortunately, coding multiple agent examples with AutoGen is simple and easy to run. We’ll cover the basic AutoGen setup in the next section.</p> 
  </div> 
  <div class="readable-text" id="p50"> 
   <h3 class="readable-text-h3" id="sigil_toc_id_45"><span class="num-string">4.2.1</span> Installing and consuming AutoGen</h3> 
  </div> 
  <div class="readable-text" id="p51"> 
   <p>This next exercise will look at coding a basic multi-agent system that uses a user proxy and conversable agent. Before we do that, though, we want to make sure AutoGen is installed and configured correctly.</p> 
  </div> 
  <div class="readable-text intended-text" id="p52"> 
   <p>Open a terminal in VS Code, and run the entire chapter 4 install directions per appendix B, or run the <code>pip</code> command in listing 4.4. If you’ve installed the <code>requirements.txt</code> file, you’ll also be ready to run AutoGen.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p53"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.4</span> Installing AutoGen</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">pip install pyautogen</pre>  
   </div> 
  </div> 
  <div class="readable-text" id="p54"> 
   <p>Next, copy the <code>chapter_04/OAI_CONFIG_LIST.example</code> to <code>OAI_CONFIG_LIST</code>, removing <code>.example</code> from the file name. Then, open the new file in VS Code, and enter your OpenAI or Azure configuration in the <code>OAI_CONFIG_LIST</code> file in listing 4.5. Fill in your API key, model, and other details per your API service requirements. AutoGen will work with any model that adheres to the OpenAI client. That means you can use local LLMs via LM Studio or other services such as Groq, Hugging Face, and more.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p55"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.5</span> <code>OAI_CONFIG_LIST</code> </h5> 
   <div class="code-area-container"> 
    <pre class="code-area">[
    {
        "model": "gpt-4",                    <span class="aframe-location"/> #1
        "api_key": "&lt;your OpenAI API key here&gt;",           <span class="aframe-location"/> #2
        "tags": ["gpt-4", "tool"]
    },
    {
        "model": "&lt;your Azure OpenAI deployment name&gt;",     <span class="aframe-location"/> #3
        "api_key": "&lt;your Azure OpenAI API key here&gt;",     <span class="aframe-location"/> #4
        "base_url": "&lt;your Azure OpenAI API base here&gt;",    <span class="aframe-location"/> #5
        "api_type": "azure",
        "api_version": "2024-02-15-preview"
    }    
]</pre> 
    <div class="code-annotations-overlay-container">
     #1 Select the model; GPT-4 is recommended.
     <br/>#2 Use the service key you would typically use.
     <br/>#3 Select the model; GPT-4 is recommended.
     <br/>#4 Use the service key you would typically use.
     <br/>#5 Changing the base URL allows you to point to other services, not just Azure OpenAI.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p56"> 
   <p>Now, we can look at the code for a basic multi-agent chat using the out-of-the-box <code>UserProxy</code> and <code>ConversableAgent</code> agents. Open <code>autogen_start.py</code> in VS Code, shown in the following listing, and review the parts before running the file.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p57"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.6</span> <code>autogen_start.py</code> </h5> 
   <div class="code-area-container code-area-with-html"> 
    <pre class="code-area">from autogen import ConversableAgent, UserProxyAgent, config_list_from_json


   config_list = config_list_from_json(
        env_or_file="OAI_CONFIG_LIST")     <span class="aframe-location"/> #1

   assistant = ConversableAgent(
        "agent", 
        llm_config={"config_list": config_list})     <span class="aframe-location"/> #2

   user_proxy = UserProxyAgent(     <span class="aframe-location"/> #3
        "user",
        code_execution_config={
            "work_dir": "working",
            "use_docker": False,
        },
        human_input_mode="ALWAYS",
        is_termination_msg=lambda x: x.get("content", "")
        .rstrip()
        .endswith("TERMINATE"),     <span class="aframe-location"/> #4
    )    
    user_proxy.initiate_chat(assistant, message="write a solution 
<span class="">↪</span> for fizz buzz in one line?")    <span class="aframe-location"/> #5</pre> 
    <div class="code-annotations-overlay-container">
     #1 Loads your LLM configuration from the JSON file OAI_CONFIG_LIST
     <br/>#2 This agent talks directly to the LLM.
     <br/>#3 This agent proxies conversations from the user to the assistant.
     <br/>#4 Setting the termination message allows the agent to iterate.
     <br/>#5 A chat is initiated with the assistant through the user_proxy to complete a task.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p58"> 
   <p>Run the code by running the file in VS Code in the debugger (F5). The code in listing 4.6 uses a simple task to demonstrate code writing. Listing 4.7 shows a few examples to choose from. These coding tasks are also some of the author’s regular baselines to assess an LLMs’ strength in coding.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p59"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.7</span> Simple coding task examples</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">write a Python function to check if a number is prime
code a classic sname game using Pygame                  <span class="aframe-location"/> #1
code a classic asteroids game in Python using Pygame  #1</pre> 
    <div class="code-annotations-overlay-container">
     #1 To enjoy iterating over these tasks, use Windows Subsystem for Linux (WSL) on Windows, or use Docker.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p60"> 
   <p>After the code starts in a few seconds, the assistant will respond to the proxy with a solution. At this time, the proxy will prompt you for feedback. Press Enter, essentially giving no feedback, and this will prompt the proxy to run the code to verify it operates as expected. </p> 
  </div> 
  <div class="readable-text intended-text" id="p61"> 
   <p>Impressively, the proxy agent will even take cues to install required packages such as Pygame. Then it will run the code, and you’ll see the output in the terminal or as a new window or browser. You can play the game or use the interface if the code shelled a new window/browser.</p> 
  </div> 
  <div class="readable-text intended-text" id="p62"> 
   <p>Note that the spawned window/browser won’t close on Windows and will require exiting the entire program. To avoid this problem, run the code through Windows Subsystem for Linux (WSL) or Docker. AutoGen explicitly recommends using Docker for code execution agents, and if you’re comfortable with containers, this is a good option.</p> 
  </div> 
  <div class="readable-text intended-text" id="p63"> 
   <p>Either way, after the proxy generates and runs the code, the <code>working_dir</code> folder set earlier in listing 4.6 should now have a Python file with the code. This will allow you to run the code at your leisure, make changes, or even ask for improvements, as we’ll see. In the next section, we’ll look at how to improve the capabilities of the coding agents.</p> 
  </div> 
  <div class="readable-text" id="p64"> 
   <h3 class="readable-text-h3" id="sigil_toc_id_46"><span class="num-string">4.2.2</span> Enhancing code output with agent critics</h3> 
  </div> 
  <div class="readable-text" id="p65"> 
   <p>One powerful benefit of multi-agent systems is the multiple roles/personas you can automatically assign when completing tasks. Generating or helping to write code can be an excellent advantage to any developer, but what if that code was also reviewed and tested? In the next exercise, we’ll add another agent critic to our agent system to help with coding tasks. Open <code>autogen_coding_critic.py</code>, as shown in the following listing.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p66"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.8</span> <code>autogen_coding_critic.py</code> </h5> 
   <div class="code-area-container"> 
    <pre class="code-area">from autogen import AssistantAgent, UserProxyAgent, config_list_from_json

config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")

user_proxy = UserProxyAgent(
    "user",
    code_execution_config={
        "work_dir": "working",
        "use_docker": False,
        "last_n_messages": 1,
    },
    human_input_mode="ALWAYS",
    is_termination_msg=lambda x: 
x.get("content", "").rstrip().endswith("TERMINATE"),
)

engineer = AssistantAgent(
    name="Engineer",
    llm_config={"config_list": config_list},
    system_message="""
    You are a profession Python engineer, known for your expertise in 
software development.
    You use your skills to create software applications, tools, and 
games that are both functional and efficient.
    Your preference is to write clean, well-structured code that is easy 
to read and maintain.    
    """,     <span class="aframe-location"/> #1
)

critic = AssistantAgent(
    name="Reviewer",
    llm_config={"config_list": config_list},
    system_message="""
    You are a code reviewer, known for your thoroughness and commitment 
to standards.
    Your task is to scrutinize code content for any harmful or 
substandard elements.
    You ensure that the code is secure, efficient, and adheres to best 
practices.
    You will identify any issues or areas for improvement in the code 
and output them as a list.
    """,     <span class="aframe-location"/> #2
)

def review_code(recipient, messages, sender, config):     <span class="aframe-location"/> #3
    return f"""
            Review and critque the following code.

            {recipient.chat_messages_for_summary(sender)[-1]['content']}
            """                       #3                    

user_proxy.register_nested_chats(     <span class="aframe-location"/> #4
    [
        {
            "recipient": critic,
            "message": review_code,
            "summary_method": "last_msg",
            "max_turns": 1,
        }
    ],
    trigger=engineer,                 #4
)
task = """Write a snake game using Pygame."""

res = user_proxy.initiate_chat(
    recipient=engineer, 
    message=task, 
    max_turns=2, 
    summary_method="last_msg"     <span class="aframe-location"/> #5
)</pre> 
    <div class="code-annotations-overlay-container">
     #1 This time, the assistant is given a system/persona message.
     <br/>#2 A second assistant critic agent is created with a background.
     <br/>#3 A custom function helps extract the code for review by the critic.
     <br/>#4 A nested chat is created between the critic and the engineer.
     <br/>#5 The proxy agent initiates a chat with a max delay and explicit summary method.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p67"> 
   <p>Run the <code>autogen_coding_critic.py</code> file in VS Code in debug mode, and watch the dialog between the agents. This time, after the code returns, the critic will also be triggered to respond. Then, the critic will add comments and suggestions to improve the code.</p> 
  </div> 
  <div class="readable-text intended-text" id="p68"> 
   <p>Nested chats work well for supporting and controlling agent interactions, but we’ll see a better approach in the following section. Before that though, we’ll review the importance of the AutoGen cache in the next section.</p> 
  </div> 
  <div class="readable-text" id="p69"> 
   <h3 class="readable-text-h3" id="sigil_toc_id_47"><span class="num-string">4.2.3</span> Understanding the AutoGen cache</h3> 
  </div> 
  <div class="readable-text" id="p70"> 
   <p>AutoGen can consume many tokens over chat iterations as a conversable multi-agent platform. If you ask AutoGen to work through complex or novel problems, you may even encounter token limits on your LLM; because of this, AutoGen supports several methods to reduce token usage.</p> 
  </div> 
  <div class="readable-text intended-text" id="p71"> 
   <p>AutoGen uses caching to store progress and reduce token usage. Caching is enabled by default, and you may have already encountered it. If you check your current working folder, you’ll notice a <code>.cache</code> folder, as shown in figure 4.8. Caching allows your agents to continue conversations if they get interrupted.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p72">  
   <img alt="figure" src="../Images/4-8.png" width="472" height="409"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.8</span> AutoGen cache and working folders</h5>
  </div> 
  <div class="readable-text" id="p73"> 
   <p>In code, you can control the cache folder for your agent’s run, as shown in listing 4.9. By wrapping the <code>initiate_chat</code> call with the <code>with</code> statement, you can control the location and seed for the cache. This will allow you to save and return to long-running AutoGen tasks in the future by just setting the <code>cache_seed</code> for the previous cache.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p74"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.9</span> Setting the cache folder</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">with Cache.disk(cache_seed=42) as cache:    <span class="aframe-location"/> #1
    res = user_proxy.initiate_chat(
        recipient=engineer,
        message=task,
        max_turns=2,
        summary_method="last_msg",
        cache=cache,     <span class="aframe-location"/> #2
    )</pre> 
    <div class="code-annotations-overlay-container">
     #1 Setting the seed_cache denotes the individual location.
     <br/>#2 Sets the cache as a parameter
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p75"> 
   <p>This caching ability allows you to continue operations from the previous cache location and captures previous runs. It can also be a great way to demonstrate and inspect how an agent conversation generated the results. In the next section, we’ll look at another conversational pattern in which AutoGen supports group chat.</p> 
  </div> 
  <div class="readable-text" id="p76"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_48"><span class="num-string">4.3</span> Group chat with agents and AutoGen</h2> 
  </div> 
  <div class="readable-text" id="p77"> 
   <p>One problem with chat delegation and nested chats or conversations is the conveyance of information. If you’ve ever played the telephone game, you’ve witnessed this firsthand and experienced how quickly information can change over iterations. With agents, this is certainly no different, and chatting through nested or sequential conversations can alter the task or even the desired result.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p78"> 
    <h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">The telephone game</h5> 
   </div> 
   <div class="readable-text" id="p79"> 
    <p>The telephone game is a fun but educational game that demonstrates information and coherence loss. Children form a line, and the first child receives a message only they can hear. Then, in turn, the children verbally pass the message on to the next child, and so on. At the end, the last child announces the message to the whole group, which often isn’t even close to the same message.</p> 
   </div> 
   <div class="readable-text" id="p80"> 
    <p>To counter this, AutoGen provides a group chat, a mechanism by which agents participate in a shared conversation. This allows agents to review all past conversations and better collaborate on long-running and complex tasks.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p81"> 
   <p>Figure 4.9 shows the difference between nested and collaborative group chats. We used the nested chat feature in the previous section to build a nested agent chat. In this section, we use the group chat to provide a more collaborative experience.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p82">  
   <img alt="figure" src="../Images/4-9.png" width="1012" height="499"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.9</span> The difference between nested and group chat for conversable agents</h5>
  </div> 
  <div class="readable-text intended-text" id="p83"> 
   <p>Open <code>autogen_coding_group.py</code> with relevant parts, as shown in listing 4.10. The code is similar to the previous exercise but now introduces <code>GroupChat</code> and <code>GroupChatManager</code>. The agents and messages are held with the group chat, similar to a messaging channel in applications such as Slack or Discord. The chat manager coordinates the message responses to reduce conversation overlap.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p84"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.10</span> <code>autoget_coding_group.py</code> (relevant sections)</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">user_proxy = UserProxyAgent(
    "user",
    code_execution_config={
        "work_dir": "working",
        "use_docker": False,
        "last_n_messages": 3,
    },
    human_input_mode="NEVER",    <span class="aframe-location"/> #1
)

llm_config = {"config_list": config_list}

engineer = AssistantAgent(…     <span class="aframe-location"/> #2


critic = AssistantAgent(…       #2


groupchat = GroupChat(agents=[user_proxy, 
                              engineer, 
                              critic], 
                              messages=[], 
                              max_round=20)     <span class="aframe-location"/> #3
manager = GroupChatManager(groupchat=groupchat, 
                           llm_config=llm_config)    <span class="aframe-location"/> #4

task = """Write a snake game using Pygame."""

with Cache.disk(cache_seed=43) as cache:
    res = user_proxy.initiate_chat(
        recipient=manager,
        message=task,
        cache=cache,
    )</pre> 
    <div class="code-annotations-overlay-container">
     #1 Human input is now set to never, so no human feedback.
     <br/>#2 Code omitted, but consult changes to the persona in the file
     <br/>#3 This object holds the connection to all the agents and stores the messages.
     <br/>#4 The manager coordinates the conversation as a moderator would.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p85"> 
   <p>Run this exercise, and you’ll see how the agents collaborate. The engineer will now take feedback from the critic and undertake operations to address the critic’s suggestions. This also allows the proxy to engage in all of the conversation.</p> 
  </div> 
  <div class="readable-text intended-text" id="p86"> 
   <p>Group conversations are an excellent way to strengthen your agents’ abilities as they collaborate on tasks. However, they are also substantially more verbose and token expensive. Of course, as LLMs mature, so do the size of their context token windows and the price of token processing. As token windows increase, concerns over token consumption may eventually go away.</p> 
  </div> 
  <div class="readable-text intended-text" id="p87"> 
   <p>AutoGen is a powerful multi-agent platform that can be experienced using a web interface or code. Whatever your preference, this agent collaboration tool is an excellent platform for building code or other complex tasks. Of course, it isn’t the only platform, as you’ll see in the next section, where we explore a newcomer called CrewAI.</p> 
  </div> 
  <div class="readable-text" id="p88"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_49"><span class="num-string">4.4</span> Building an agent crew with CrewAI</h2> 
  </div> 
  <div class="readable-text" id="p89"> 
   <p>CrewAI is relatively new to the realm of multi-agent systems. Where AutoGen was initially developed from research and then extended, CrewAI is built with enterprise systems in mind. As such, the platform is more robust, making it less extensible in some areas.</p> 
  </div> 
  <div class="readable-text intended-text" id="p90"> 
   <p>With CrewAI, you build a crew of agents to focus on specific areas of a task goal. Unlike AutoGen, CrewAI doesn’t require the use of the user proxy agent but instead assumes the agents only work among themselves.</p> 
  </div> 
  <div class="readable-text intended-text" id="p91"> 
   <p>Figure 4.10 shows the main elements of the CrewAI platform, how they connect together, and their primary function. It shows a sequential-processing agent system with generic researcher and writer agents. Agents are assigned tasks that may also include tools or memory to assist them.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p92">  
   <img alt="figure" src="../Images/4-10.png" width="1100" height="937"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.10</span> The composition of a CrewAI system</h5>
  </div> 
  <div class="readable-text intended-text" id="p93"> 
   <p>CrewAI supports two primary forms of processing: sequential and hierarchical. Figure 4.10 shows the sequential process by iterating across the given agents and their associated tasks. In the next section, we dig into some code to set up a crew and employ it to complete a goal and create a good joke.</p> 
  </div> 
  <div class="readable-text" id="p94"> 
   <h3 class="readable-text-h3" id="sigil_toc_id_50"><span class="num-string">4.4.1</span> Creating a jokester crew of CrewAI agents</h3> 
  </div> 
  <div class="readable-text" id="p95"> 
   <p>CrewAI requires more setup than AutoGen, but this also allows for more control and additional guides, which provide more specific context to guide the agents in completing the given task. This isn’t without problems, but it does offer more control than AutoGen out of the box.</p> 
  </div> 
  <div class="readable-text intended-text" id="p96"> 
   <p>Open <code>crewai_introduction.py</code> in VS Code and look at the top section, as shown in listing 4.11. Many settings are required to configure an agent, including the role, goal, verboseness, memory, backstory, delegation, and even tools (not shown). In this example, we’re using two agents: a senior joke researcher and a joke writer.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p97"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.11</span> <code>crewai_introduction.py</code> (agent section)</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">from crewai import Agent, Crew, Process, Task
from dotenv import load_dotenv

load_dotenv()

joke_researcher = Agent(     <span class="aframe-location"/> #1
    role="Senior Joke Researcher",
    goal="Research what makes things funny about the following {topic}",
    verbose=True,     <span class="aframe-location"/> #2
    memory=True,     <span class="aframe-location"/> #3
    backstory=(     <span class="aframe-location"/> #4
        "Driven by slapstick humor, you are a seasoned joke researcher"
        "who knows what makes people laugh. You have a knack for finding"
        "the funny in everyday situations and can turn a dull moment into"
        "a laugh riot."
    ),
    allow_delegation=True,    <span class="aframe-location"/> #5
)

joke_writer = Agent(    <span class="aframe-location"/> #6
    role="Joke Writer",
    goal="Write a humourous and funny joke on the following {topic}",
    verbose=True,    <span class="aframe-location"/> #7
    memory=True,     <span class="aframe-location"/> #8
    backstory=(    <span class="aframe-location"/> #9
        "You are a joke writer with a flair for humor. You can turn a"
        "simple idea into a laugh riot. You have a way with words and"
        "can make people laugh with just a few lines."
    ),
    allow_delegation=False,    #5
)</pre> 
    <div class="code-annotations-overlay-container">
     #1 Creates the agents and provides them a goal
     <br/>#2 verbose allows the agent to emit output to the terminal.
     <br/>#3 Supports the use of memory for the agents
     <br/>#4 The backstory is the agent’s background—its persona.
     <br/>#5 The agents can either be delegated to or are allowed to delegate; True means they can delegate.
     <br/>#6 Creates the agents and provides them a goal
     <br/>#7 verbose allows the agent to emit output to the terminal.
     <br/>#8 Supports the use of memory for the agents
     <br/>#9 The backstory is the agent’s background—its persona.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p98"> 
   <p>Moving down the code, we next see the tasks, as shown in listing 4.12. Tasks denote an agent’s process to complete the primary system goal. They also link an agent to work on a specific task, define the output from that task, and may include how it’s executed.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p99"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.12</span> <code>crewai_introduction.py</code> (task section)</h5> 
   <div class="code-area-container code-area-with-html"> 
    <pre class="code-area">research_task = Task(        <span class="aframe-location"/> #1
    description=(
        "Identify what makes the following topic:{topic} so funny."
        "Be sure to include the key elements that make it humourous."
        "Also, provide an analysis of the current social trends,"
        "and how it impacts the perception of humor."
    ),
    expected_output="A comprehensive 3 paragraphs long report 
<span class="">↪</span>     on the latest jokes.",              <span class="aframe-location"/> #2
    agent=joke_researcher,     <span class="aframe-location"/> #3
)

write_task = Task(  <span class="aframe-location"/> #4
    description=(
        "Compose an insightful, humourous and socially aware joke on {topic}."
        "Be sure to include the key elements that make it funny and"
        "relevant to the current social trends."
    ),
    expected_output="A joke on {topic}.",  <span class="aframe-location"/> #5
    agent=joke_writer,        #3
    async_execution=False,         <span class="aframe-location"/> #6
    output_file="the_best_joke.md",     <span class="aframe-location"/> #7
)</pre> 
    <div class="code-annotations-overlay-container">
     #1 The Task description defines how the agent will complete the task.
     <br/>#2 Explicitly defines the expected output from performing the task
     <br/>#3 The agent assigned to work on the task
     <br/>#4 The Task description defines how the agent will complete the task.
     <br/>#5 Explicitly defines the expected output from performing the task
     <br/>#6 If the agent should execute asynchronously
     <br/>#7 Any output the agent will generate
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p100"> 
   <p>Now, we can see how everything comes together as the <code>Crew</code> at the bottom of the file, as shown in listing 4.13. Again, many options can be set when building the <code>Crew</code>, including the agents, tasks, process type, memory, cache, maximum requests per minute (<code>max_rpm</code>), and whether the crew shares.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p101"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.13</span> <code>crewai_introduction.py</code> (crew section)</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">crew = Crew(
    agents=[joke_researcher, joke_writer],   <span class="aframe-location"/> #1
    tasks=[research_task, write_task],    <span class="aframe-location"/> #2
    process=Process.sequential,     <span class="aframe-location"/> #3
    memory=True,     <span class="aframe-location"/> #4
    cache=True,    <span class="aframe-location"/> #5
    max_rpm=100,    <span class="aframe-location"/> #6
    share_crew=True,    <span class="aframe-location"/> #7
)

result = crew.kickoff(inputs={"topic": "AI engineer jokes"})
print(result)</pre> 
    <div class="code-annotations-overlay-container">
     #1 The agents assembled into the crew
     <br/>#2 The tasks the agents can work on
     <br/>#3 Defining how the agents will interact
     <br/>#4 Whether the system should use memory; needs to be set if agents/tasks have it on
     <br/>#5 Whether the system should use a cache, similar to AutoGen
     <br/>#6 Maximum requests per minute the system should limit itself to
     <br/>#7 Whether the crew should share information, similar to group chat
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p102"> 
   <p>When you’re done reviewing, run the file in VS Code (F5), and watch the terminal for conversations and messages from the crew. As you can probably tell by now, the goal of this agent system is to craft jokes related to AI engineering. Here are some of the funnier jokes generated over a few runs of the agent system:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p103"> Why was the computer cold? It left Windows open. </li> 
   <li class="readable-text" id="p104"> Why don’t AI engineers play hide and seek with their algorithms? Because no matter where they hide, the algorithms always find them in the “overfitting” room! </li> 
   <li class="readable-text" id="p105"> What is an AI engineer’s favorite song? “I just called to say I love yo… . and to collect more data for my voice recognition software.” </li> 
   <li class="readable-text" id="p106"> Why was the AI engineer broke? Because he spent all his money on cookies, but his browser kept eating them. </li> 
  </ul> 
  <div class="readable-text" id="p107"> 
   <p>Before you run more iterations of the joke crew, you should read the next section. This section shows how to add observability to the multi-agent system.</p> 
  </div> 
  <div class="readable-text" id="p108"> 
   <h3 class="readable-text-h3" id="sigil_toc_id_51"><span class="num-string">4.4.2</span> Observing agents working with AgentOps</h3> 
  </div> 
  <div class="readable-text" id="p109"> 
   <p>Observing a complex assemblage such as a multi-agent system is critical to understanding the myriad of problems that can happen. Observability through application tracing is a key element of any complex system, especially one engaged in enterprise use.</p> 
  </div> 
  <div class="readable-text intended-text" id="p110"> 
   <p>CrewAI supports connecting to a specialized agent operations platform appropriately called AgentOps. This observability platform is generic and designed to support observability with any agent platform specific to LLM usage. Currently, no pricing or commercialization details are available.</p> 
  </div> 
  <div class="readable-text intended-text" id="p111"> 
   <p>Connecting to AgentOps is as simple as installing the package, getting an API key, and adding a line of code to your crew setup. This next exercise will go through the steps to connect and run AgentOps.</p> 
  </div> 
  <div class="readable-text intended-text" id="p112"> 
   <p>Listing 4.14 shows installing the <code>agentops</code> package using <code>pip</code>. You can install the package alone or as an additional component of the <code>crewai</code> package. Remember that AgentOps can also be connected to other agent platforms for observability.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p113"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.14</span> Installing AgentOps</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">pip install agentops

or as an option with CrewAI

pip install crewai[agentops]</pre>  
   </div> 
  </div> 
  <div class="readable-text" id="p114"> 
   <p>Before using AgentOps, you need to sign up for an API key. Following are the general steps to sign up for a key at the time of writing:</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p115"> Visit <a href="https://app.agentops.ai">https://app.agentops.ai</a> in your browser. </li> 
   <li class="readable-text" id="p116"> Sign up for an account. </li> 
   <li class="readable-text" id="p117"> Create a project, or use the default. </li> 
   <li class="readable-text" id="p118"> Go to Settings &gt; Projects and API Keys. </li> 
   <li class="readable-text" id="p119"> Copy and/or generate a new API key; this will copy the key to your browser. </li> 
   <li class="readable-text" id="p120"> Paste the key to your <code>.env</code> file in your project. </li> 
  </ol> 
  <div class="readable-text" id="p121"> 
   <p>After the API key is copied, it should resemble the example shown in the following listing.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p122"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.15</span> <code>env.</code>: Adding an AgentOps key</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">AGENTOPS_API_KEY="your API key"</pre>  
   </div> 
  </div> 
  <div class="readable-text" id="p123"> 
   <p>Now, we need to add a few lines of code to the CrewAI script. Listing 4.16 shows the additions as they are added to the <code>crewai_agentops.py</code> file. When creating your own scripts, all you need to do is add the <code>agentops</code> package and initialize it when using CrewAI.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p124"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.16</span> <code>crewai_agentops.py</code> (AgentOps additions)</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">import agentops     <span class="aframe-location"/> #1
from crewai import Agent, Crew, Process, Task
from dotenv import load_dotenv

load_dotenv()
agentops.init()    <span class="aframe-location"/> #2</pre> 
    <div class="code-annotations-overlay-container">
     #1 The addition of the required package
     <br/>#2 Make sure to initialize the package after the environment variables are loaded.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p125"> 
   <p>Run the <code>crewai_agentops.py</code> file in VS Code (F5), and watch the agents work as before. However, you can now go to the AgentOps dashboard and view the agent interactions at various levels.</p> 
  </div> 
  <div class="readable-text intended-text" id="p126"> 
   <p>Figure 4.11 shows the dashboard for running the joke crew to create the best joke. Several statistics include total duration, the run environment, prompt and completion tokens, LLM call timings, and estimated cost. Seeing the cost can be both sobering and indicative of how verbose agent conversations can become.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p127">  
   <img alt="figure" src="../Images/4-11.png" width="1012" height="684"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.11</span> The AgentOps dashboard for running the joke crew</h5>
  </div> 
  <div class="readable-text" id="p128"> 
   <p>The AgentOps platform is an excellent addition to any agent platform. While it’s built into CrewAI, it’s helpful that the observability could be added to AutoGen or other frameworks. Another attractive thing about AgentOps is that it’s dedicated to observing agent interactions and not transforming from a machine learning operations platform. In the future, we’ll likely see the spawn of more agent observability patterns.</p> 
  </div> 
  <div class="readable-text intended-text" id="p129"> 
   <p>One benefit that can’t be overstated is the cost observation that an observability platform can provide. Did you notice in figure 4.11 that creating a single joke costs a little over 50 cents? Agents can be very powerful, but they can also become very costly, and it’s essential to observe what those costs are in terms of practicality and commercialization.</p> 
  </div> 
  <div class="readable-text intended-text" id="p130"> 
   <p>In the last section of this chapter, we’ll return to CrewAI and revisit building agents that can code games. This will provide an excellent comparison between the capabilities of AutoGen and CrewAI.</p> 
  </div> 
  <div class="readable-text" id="p131"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_52"><span class="num-string">4.5</span> Revisiting coding agents with CrewAI</h2> 
  </div> 
  <div class="readable-text" id="p132"> 
   <p>A great way to compare capabilities between multi-agent platforms is to implement similar tasks in a bot. In this next set of exercises, we’ll employ CrewAI as a game programming team. Of course, this could be adapted to other coding tasks as well.</p> 
  </div> 
  <div class="readable-text intended-text" id="p133"> 
   <p>Open <code>crewai_coding_crew.py</code> in VS Code, and we’ll first review the agent section in listing 4.17. Here, we’re creating a senior engineer, a QA engineer, and a chief QA engineer with a role, goal, and backstory. </p> 
  </div> 
  <div class="browsable-container listing-container" id="p134"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.17</span> <code>crewai_coding_crew.py</code> (agent section)</h5> 
   <div class="code-area-container code-area-with-html"> 
    <pre class="code-area">print("## Welcome to the Game Crew")     <span class="aframe-location"/> #1
print("-------------------------------")
game = input("What is the game you would like to build?
<span class="">↪</span> What will be the mechanics?\n")


senior_engineer_agent = Agent(
    role="Senior Software Engineer",
    goal="Create software as needed",
    backstory=dedent(
        """
        You are a Senior Software Engineer at a leading tech think tank.
        Your expertise in programming in python. and do your best to
        produce perfect code
        """
    ),
    allow_delegation=False,
    verbose=True,
)

qa_engineer_agent = Agent(
    role="Software Quality Control Engineer",
    goal="create prefect code, by analizing the code 
<span class="">↪</span> that is given for errors",
    backstory=dedent(
        """
        You are a software engineer that specializes in checking code
        for errors. You have an eye for detail and a knack for finding
        hidden bugs.
        You check for missing imports, variable declarations, mismatched
        brackets and syntax errors.
        You also check for security vulnerabilities, and logic errors
        """
    ),
    allow_delegation=False,
    verbose=True,
)

chief_qa_engineer_agent = Agent(
    role="Chief Software Quality Control Engineer",
    goal="Ensure that the code does the job that it is supposed to do",
    backstory=dedent(
        """
        You are a Chief Software Quality Control Engineer at a leading
        tech think tank. You are responsible for ensuring that the code
        that is written does the job that it is supposed to do.
        You are responsible for checking the code for errors and ensuring
        that it is of the highest quality.
        """
    ),
    allow_delegation=True,    <span class="aframe-location"/> #2
    verbose=True,
)</pre> 
    <div class="code-annotations-overlay-container">
     #1 Allows the user to input the instructions for their game
     <br/>#2 Only the chief QA engineer can delegate tasks.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p135"> 
   <p>Scrolling down in the file will display the agent tasks, as shown in listing 4.18. The task descriptions and expected output should be easy to follow. Again, each agent has a specific task to provide better context when working to complete the task.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p136"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.18</span> <code>crewai_coding_crew.py</code> (task section)</h5> 
   <div class="code-area-container code-area-with-html"> 
    <pre class="code-area">code_task = Task(
    description=f"""
You will create a game using python, these are the instructions:
        Instructions
        ------------
        {game}            <span class="aframe-location"/> #1
        You will write the code for the game using python.""",
    expected_output="Your Final answer must be the 
<span class="">↪</span> full python code, only the python code and nothing else.",
    agent=senior_engineer_agent,
)

qa_task = Task(
    description=f"""You are helping create a game 
<span class="">↪</span> using python, these are the instructions:
        Instructions
        ------------
        {game}            #1
        Using the code you got, check for errors. Check for logic errors,
        syntax errors, missing imports, variable declarations, 
mismatched brackets,
        and security vulnerabilities.""",
    expected_output="Output a list of issues you found in the code.",
    agent=qa_engineer_agent,
)

evaluate_task = Task(
    description=f"""You are helping create a game 
<span class="">↪</span> using python, these are the instructions:
        Instructions
        ------------
        {game}            #1
        You will look over the code to insure that it is complete and
        does the job that it is supposed to do. """,
    expected_output="Your Final answer must be the 
<span class="">↪</span> corrected a full python code, only the python code and nothing else.",
    agent=chief_qa_engineer_agent,
)</pre> 
    <div class="code-annotations-overlay-container">
     #1 The game instructions are substituted into the prompt using Python formatting.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p137"> 
   <p>Finally, we can see how this comes together by going to the bottom of the file, as shown in listing 4.19. This crew configuration is much like what we’ve seen before. Each agent and task are added, as well as the verbose and process attributes. For this example, we’ll continue to use sequential methods. </p> 
  </div> 
  <div class="browsable-container listing-container" id="p138"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.19</span> <code>crewai_coding_crew.py</code> (crew section)</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">crew = Crew(
    agents=[senior_engineer_agent, 
            qa_engineer_agent, 
            chief_qa_engineer_agent],
    tasks=[code_task, qa_task, evaluate_task],
    verbose=2,  
    process=Process.sequential,     <span class="aframe-location"/> #1
)

# Get your crew to work!
result = crew.kickoff()   <span class="aframe-location"/> #2

print("######################")
print(result)</pre> 
    <div class="code-annotations-overlay-container">
     #1 Process is sequential.
     <br/>#2 No additional context is provided in the kickoff.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p139"> 
   <p>When you run the VS Code (F5) file, you’ll be prompted to enter the instructions for writing a game. Enter some instructions, perhaps the snake game or another game you choose. Then, let the agents work, and observe what they produce.</p> 
  </div> 
  <div class="readable-text intended-text" id="p140"> 
   <p>With the addition of the chief QA engineer, the results will generally look better than what was produced with AutoGen, at least out of the box. If you review the code, you’ll see that it generally follows good patterns and, in some cases, may even include tests and unit tests.</p> 
  </div> 
  <div class="readable-text intended-text" id="p141"> 
   <p>Before we finish the chapter, we’ll make one last change to the crew’s processing pattern. Previously, we employed sequential processing, as shown in figure 4.10. Figure 4.12 shows what hierarchical processing looks like in CrewAI. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p142">  
   <img alt="figure" src="../Images/4-12.png" width="1100" height="1142"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.12</span> Hierarchical processing of agents coordinated through a crew manager</h5>
  </div> 
  <div class="readable-text intended-text" id="p143"> 
   <p>Adding this manager is a relatively simple process. Listing 4.20 shows the additional code changes to a new file that uses the coding crew in a hierarchical method. Aside from importing a class for connecting to OpenAI from LangChain, the other addition is adding this class as the crew manger, <code>manager_llm</code>.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p144"> 
   <h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 4.20</span> <code>crewai_hierarchy.py</code> (crew manager sections)</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">from langchain_openai import ChatOpenAI     <span class="aframe-location"/> #1

crew = Crew(
    agents=[senior_engineer_agent, 
            qa_engineer_agent, 
            chief_qa_engineer_agent],
    tasks=[code_task, qa_task, evaluate_task],
    verbose=2,  
    process=Process.hierarchical,    <span class="aframe-location"/> #2
    manager_llm=ChatOpenAI(    <span class="aframe-location"/>           #3
        temperature=0, model="gpt-4"      #3
    ),   <span class="aframe-location"/> #4
)         #4</pre> 
    <div class="code-annotations-overlay-container">
     #1 Imports the LLM connector from LangChain
     <br/>#2 You must set a crew manager when selecting hierarchical processing.
     <br/>#3 Sets the crew manager to be the LLM connector
     <br/>#4 You must set a crew manager when selecting hierarchical processing.
     <br/>
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p145"> 
   <p>Run this file in VS Code (F5). When prompted, enter a game you want to create. Try using the same game you tried with AutoGen; the snake game is also a good baseline example. Observe the agents work through the code and review it repeatedly for problems.</p> 
  </div> 
  <div class="readable-text intended-text" id="p146"> 
   <p>After you run the file, you can also jump on AgentOps to review the cost of this run. Chances are, it will cost over double what it would have without the agent manager. The output will also likely not be significantly better. This is the trap of building agent systems without understanding how quickly things can spiral.</p> 
  </div> 
  <div class="readable-text intended-text" id="p147"> 
   <p>An example of this spiral that often happens when agents continually iterate over the same actions is frequently repeating tasks. You can view this problem in AgentOps, as shown in figure 4.13, by viewing the Repeat Thoughts plot. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p148">  
   <img alt="figure" src="../Images/4-13.png" width="672" height="444"/> 
   <h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 4.13</span> The repetition of thoughts as they occurred within an agent run</h5>
  </div> 
  <div class="readable-text" id="p149"> 
   <p>The Repeat Thoughts plot from AgentOps is an excellent way to measure the repetition your agent system encounters. Overly repetitive thought patterns typically mean the agent isn’t being decisive enough and instead keeps trying to generate a different answer. If you encounter this problem, you want to change the agents’ processing patterns, tasks, and goals. You may even want to alter the system’s type and number of agents.</p> 
  </div> 
  <div class="readable-text intended-text" id="p150"> 
   <p>Multi-agent systems are an excellent way to break up work in terms of work patterns of jobs and tasks. Generally, the job role is allocated to an agent role/persona, and the tasks it needs to complete may be implicit, as in AutoGen, or more explicit, as in CrewAI.</p> 
  </div> 
  <div class="readable-text intended-text" id="p151"> 
   <p>In this chapter, we covered many useful tools and platforms that you can use right away to improve your work, life, and more. That completes our journey through multi-agent platforms, but it doesn’t conclude our exploration and use of multiple agents, as we’ll discover in later chapters.</p> 
  </div> 
  <div class="readable-text" id="p152"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_53"><span class="num-string">4.6</span> Exercises</h2> 
  </div> 
  <div class="readable-text" id="p153"> 
   <p>Use the following exercises to improve your knowledge of the material:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p154"> <em>Exercise 1</em> —Basic Agent Communication with AutoGen </li> 
  </ul> 
  <div class="readable-text list-body-item" id="p155"> 
   <p><em>Objective</em> —Familiarize yourself with basic agent communications and setup in AutoGen.</p> 
  </div> 
  <div class="readable-text list-body-item" id="p156"> 
   <p><em>Tasks</em>:</p> 
  </div> 
  <ul> 
   <li class=" buletless-item" style="list-style-type: none;"> 
    <ul> 
     <li class="readable-text" id="p157"> Set up AutoGen Studio on your local machine, following the instructions provided in this chapter. </li> 
     <li class="readable-text" id="p158"> Create a simple multi-agent system with a user proxy and two assistant agents. </li> 
     <li class="readable-text" id="p159"> Implement a basic task where the user proxy coordinates between the assistant agents to generate a simple text output, such as summarizing a short paragraph. </li> 
    </ul></li> 
   <li class="readable-text" id="p160"> <em>Exercise 2</em> —Implementing Advanced Agent Skills in AutoGen Studio </li> 
  </ul> 
  <div class="readable-text list-body-item" id="p161"> 
   <p><em>Objective</em> —Enhance agent capabilities by adding advanced skills.</p> 
  </div> 
  <div class="readable-text list-body-item" id="p162"> 
   <p><em>Tasks</em>:</p> 
  </div> 
  <ul> 
   <li class=" buletless-item" style="list-style-type: none;"> 
    <ul> 
     <li class="readable-text" id="p163"> Develop and integrate a new skill into an AutoGen agent that allows it to fetch and display real-time data from a public API (e.g., weather information or stock prices). </li> 
     <li class="readable-text" id="p164"> Ensure the agent can ask for user preferences (e.g., city for weather, type of stocks) and display the fetched data accordingly. </li> 
    </ul></li> 
   <li class="readable-text" id="p165"> <em>Exercise 3</em> —Role-Based Task Management with CrewAI </li> 
  </ul> 
  <div class="readable-text list-body-item" id="p166"> 
   <p><em>Objective</em> —Explore role-based task management in CrewAI.</p> 
  </div> 
  <div class="readable-text list-body-item" id="p167"> 
   <p><em>Tasks</em>:</p> 
  </div> 
  <ul> 
   <li class=" buletless-item" style="list-style-type: none;"> 
    <ul> 
     <li class="readable-text" id="p168"> Design a CrewAI setup where multiple agents are assigned specific roles (e.g., data fetcher, analyzer, presenter). </li> 
     <li class="readable-text" id="p169"> Configure a task sequence where the data fetcher collects data, the analyzer processes the data, and the presenter generates a report. </li> 
     <li class="readable-text" id="p170"> Execute the sequence and observe the flow of information and task delegation among agents. </li> 
    </ul></li> 
   <li class="readable-text" id="p171"> <em>Exercise 4</em> —Multi-Agent Collaboration in Group Chat Using AutoGen </li> 
  </ul> 
  <div class="readable-text list-body-item" id="p172"> 
   <p><em>Objective</em> —Understand and implement a group chat system in AutoGen to facilitate agent collaboration.</p> 
  </div> 
  <div class="readable-text list-body-item" id="p173"> 
   <p><em>Tasks</em>:</p> 
  </div> 
  <ul> 
   <li class=" buletless-item" style="list-style-type: none;"> 
    <ul> 
     <li class="readable-text" id="p174"> Set up a scenario where multiple agents need to collaborate to solve a complex problem (e.g., planning an itinerary for a business trip). </li> 
     <li class="readable-text" id="p175"> Use the group chat feature to allow agents to share information, ask questions, and provide updates to each other. </li> 
     <li class="readable-text" id="p176"> Monitor the agents’ interactions and effectiveness in collaborative problem solving. </li> 
    </ul></li> 
   <li class="readable-text" id="p177"> <em>Exercise 5</em> —Adding and Testing Observability with AgentOps in CrewAI </li> 
  </ul> 
  <div class="readable-text list-body-item" id="p178"> 
   <p><em>Objective</em> —Implement and evaluate the observability of agents using AgentOps in a CrewAI environment.</p> 
  </div> 
  <div class="readable-text list-body-item" id="p179"> 
   <p><em>Tasks</em>:</p> 
  </div> 
  <ul> 
   <li class=" buletless-item" style="list-style-type: none;"> 
    <ul> 
     <li class="readable-text" id="p180"> Integrate AgentOps into a CrewAI multi-agent system. </li> 
     <li class="readable-text" id="p181"> Design a task for the agents that involves significant computation or data processing (e.g., analyzing customer reviews to determine sentiment trends). </li> 
     <li class="readable-text" id="p182"> Use AgentOps to monitor the performance, cost, and output accuracy of the agents. Identify any potential inefficiencies or errors in agent interactions. </li> 
    </ul></li> 
  </ul> 
  <div class="readable-text" id="p183"> 
   <h2 class="readable-text-h2" id="sigil_toc_id_54">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p184"> AutoGen, developed by Microsoft, is a conversational multi-agent platform that employs a variety of agent types, such as user proxies and assistant agents, to facilitate task execution through natural language interactions. </li> 
   <li class="readable-text" id="p185"> AutoGen Studio acts as a development environment that allows users to create, test, and manage multi-agent systems, enhancing the usability of AutoGen. </li> 
   <li class="readable-text" id="p186"> AutoGen supports multiple communication patterns, including group chats and hierarchical and proxy communications. Proxy communication involves a primary agent (proxy) that interfaces between the user and other agents to streamline task completion. </li> 
   <li class="readable-text" id="p187"> CrewAI offers a structured approach to building multi-agent systems with a focus on enterprise applications. It emphasizes role-based and autonomous agent functionalities, allowing for flexible, sequential, or hierarchical task management. </li> 
   <li class="readable-text" id="p188"> Practical exercises in the chapter illustrate how to set up and use AutoGen Studio, including installing necessary components and running basic multi-agent systems. </li> 
   <li class="readable-text" id="p189"> Agents in AutoGen can be equipped with specific skills to perform tasks such as code generation, image analysis, and data retrieval, thereby broadening their application scope. </li> 
   <li class="readable-text" id="p190"> CrewAI is distinguished by its ability to structure agent interactions more rigidly than AutoGen, which can be advantageous in settings that require precise and controlled agent behavior. </li> 
   <li class="readable-text" id="p191"> CrewAI supports integrating memory and tools for agents to consume through task completion. </li> 
   <li class="readable-text" id="p192"> CrewAI supports integration with observability tools such as AgentOps, which provides insights into agent performance, interaction efficiency, and cost management. </li> 
   <li class="readable-text" id="p193"> AgentOps is an agent observability platform that can help you easily monitor extensive agent interactions. </li> 
  </ul>
 </div></div></body></html>