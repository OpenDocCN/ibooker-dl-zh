<html><head></head><body><section data-pdf-bookmark="Preface" data-type="preface" epub:type="preface"><div class="preface" id="preface_preface_1748539924709958">&#13;
      <h1>Preface</h1>&#13;
      <p>The European Union’s Artificial Intelligence Act, which came into full effect in August 2024, represents a watershed moment in the global regulation of artificial intelligence. As the first comprehensive legal framework for AI, its stated purpose is clear: to foster innovation and development within the EU while effectively mitigating the potential risks posed by AI systems. This ambitious regulation establishes a uniform legal framework governing the development, placement on the market, putting into service, and use of AI systems across the EU.</p>&#13;
      <p>Navigating the complexities of the EU AI Act might, at first glance, seem like a task exclusively for legal teams and policy experts. The Act is indeed complex, featuring 113 articles that address highly technical issues, complemented by 13 annexes that detail implementation specifics and 180 recitals (introductory statements providing context and guidance for interpretation). However, as the practical requirements of the EU AI Act reveal, <em>achieving and maintaining compliance with the Act is fundamentally an engineering problem</em>. This is the core message of this book.</p>&#13;
      <p>Operationalizing EU AI Act compliance goes far beyond legal interpretation. It requires establishing roles, processes, structures, and AI engineering practices. Post-market compliance, for instance, directly necessitates the implementation of machine learning operations (MLOps) practices such as monitoring and alerting. Successfully achieving EU AI Act compliance is linked to understanding the design, development, and maintenance of AI systems.</p>&#13;
      <p>Compliance is not a legal stamp applied at the end of the development lifecycle, but a continuous process that must be engineered into the core of AI systems from the beginning. The Act’s foundation on the concept of “trustworthy AI” mandates that systems be lawful, ethical, and robust throughout their entire lifecycle. This necessitates embedding ethical and compliance aspects directly into the AI system development process.</p>&#13;
      <p>This book serves as your guide to tackling EU AI Act compliance as the engineering challenge it is. We’ll explore various practical methodologies and frameworks essential for this task, including:</p>&#13;
      <dl>&#13;
        <dt>AI engineering</dt>&#13;
        <dd>&#13;
          <p>Defined as the application of software engineering principles to the end-to-end lifecycle of AI systems—including design, development, deployment, and <span class="keep-together">maintenance</span>. </p>&#13;
        </dd>&#13;
        <dt>CRISP-ML(Q)</dt>&#13;
        <dd>&#13;
          <p>This structured machine learning development process provides a blueprint for designing, developing, and maintaining AI systems with compliance in mind. Its emphasis on quality assurance and continuous risk management throughout the AI lifecycle is directly aligned with the EU AI Act’s risk-based approach. CRISP-ML(Q) requires documentation of the entire development process, including risk management measures, which is crucial for meeting the Act’s technical documentation and transparency obligations. </p>&#13;
        </dd>&#13;
        <dt>MLOps Stack Canvas</dt>&#13;
        <dd>&#13;
          <p>The MLOps Stack Canvas is a comprehensive and practical framework designed to guide organizations in architecting and managing their machine learning operations infrastructure. The canvas is structured around three core domains: Data and Code Management, Model Management, and Metadata Management. It provides a holistic view of the components necessary for successful ML deployment. By aligning with the CRISP-ML(Q) process model, the canvas ensures that each phase of the ML lifecycle is addressed, from data sourcing and versioning to model deployment and monitoring. It emphasizes critical aspects such as reproducibility, reliability, and efficiency, helping teams to plan infrastructure costs, select appropriate tools, and establish robust workflows. Serving as both a <span class="keep-together">strategic</span> and an operational tool, the MLOps Stack Canvas facilitates clearer communication among stakeholders for all ML and AI initiatives across the <span class="keep-together">organization</span>. </p>&#13;
        </dd>&#13;
        <dt>SMACTR (Scoping, Mapping, Artifact Collection, Testing, and Reflection)</dt>&#13;
        <dd>&#13;
          <p>Introduced as an internal audit framework to guide the practical implementation of ethical AI development throughout its lifecycle, SMACTR promotes a proactive and preventive approach for AI development. Embedding audit processes into the design and development phases allows engineers to anticipate and address potential risks before deployment, aligning perfectly with the Act’s emphasis on risk mitigation. SMACTR’s focus on generating detailed documentation at each stage is also essential for meeting the Act’s technical documentation requirements for high-risk AI systems.</p>&#13;
        </dd>&#13;
      </dl>&#13;
      <p class="pagebreak-before">The synergy between CRISP-ML(Q) and AI engineering offers a powerful framework for addressing EU AI Act compliance. Furthermore, the integration of SMACTR with the CRISP-ML(Q) methodology provides a robust and auditable process for responsibly developing AI systems. This combination allows for proactively engineering compliance into the ML lifecycle, from data collection through monitoring, rather than treating it as an afterthought.</p>&#13;
      <p>The book also explores how these engineering principles apply across the Act’s risk classifications—prohibited, high risk, limited risk, and low risk. While high-risk systems face the most stringent requirements, Article 50 introduces transparency obligations that apply to all AI systems designed to interact directly with humans, regardless of their risk level. These obligations, such as informing users of AI interaction and marking synthetic content, demand practical engineering solutions for proactive compliance. Aligning AI engineering practices with SMACTR and CRISP-ML(Q) provides a structured and automated approach to managing the AI system lifecycle for transparency.</p>&#13;
      <p>This book also addresses the particular challenges posed by general-purpose AI (GPAI) and generative AI (GenAI), late but significant additions to the Act. The concept of generative AI operations (GenAIOps) is introduced as an extension of traditional MLOps principles to handle the unique complexities of GPAI and generative AI applications. Applying AI engineering principles to implement transparency obligations for GPAI and integrating CRISP-ML(Q), SMACTR, and GenAIOps are crucial for navigating this evolving landscape.</p>&#13;
      <section data-pdf-bookmark="Who Should Read This Book" data-type="sect1"><div class="sect1" id="preface_who_should_read_this_book_1748539924710048">&#13;
        <h1>Who Should Read This Book</h1>&#13;
        <p>This book is intended for AI engineers, MLOps practitioners, data scientists, AI product managers, and anyone involved in the hands-on development and deployment of AI systems. It demonstrates how, through the application of robust methodologies, disciplined documentation, and continuous integration of ethical considerations, AI teams can build systems that are not only technically innovative but also demonstrably compliant, trustworthy, and aligned with societal expectations. I have tried to make this book as actionable as possible by introducing a comprehensive framework and practical checklists for aligning AI engineering practices with the EU AI Act articles throughout the CRISP-ML(Q) lifecycle.</p>&#13;
        <p>As ImageNet creator Fei-Fei Li, known as the Godmother of AI, <a href="https://oreil.ly/_PUIb">noted recently</a>: “Now more than ever, AI needs a governance framework.” This book provides the practical engineering foundation for implementing such a framework, enabling practitioners to build trustworthy AI systems that meet the stringent requirements of the EU AI Act through empirical validation, risk-aware development, and collaborative practices. The law sets the requirements, but it is the engineering that delivers compliance.</p>&#13;
      </div></section>&#13;
      <section data-pdf-bookmark="Navigating This Book" data-type="sect1"><div class="sect1" id="preface_navigating_this_book_1748539924710109">&#13;
        <h1>Navigating This Book</h1>&#13;
        <p>This book has been designed as a reference for you, a guide to practicing proactive EU AI Act compliance through AI engineering and integrating it into the AI lifecycle, from data collection through monitoring. Each chapter is fairly self-contained, with appropriate references to other chapters identified. The chapters are organized as <span class="keep-together">follows</span>:</p>&#13;
        <ul>&#13;
          <li>&#13;
            <p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch01.html#chapter_1_understanding_the_ai_regulations_1748539916832819">Chapter 1, “Understanding the AI Regulations”</a>, provides a foundational understanding of the EU AI Act and the need for trustworthy AI systems. It outlines seven essential requirements for building such systems: human agency and oversight; technical robustness and safety; privacy and data governance; transparency; diversity, non-discrimination, and fairness; societal and environmental well-being; and accountability. This chapter describes the structure of the Act, including definitions, key players, risk classifications, and the implementation timeline, and provides an overview of this significant regulatory framework.</p>&#13;
          </li>&#13;
          <li>&#13;
            <p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch02.html#chapter_2_ai_engineering_a_proactive_compliance_catalyst_1748539917637495">Chapter 2, “AI Engineering: A Proactive <span class="keep-together">Compliance Catalyst</span>”</a>, explains how combining CRISP-ML(Q) with AI engineering helps organizations meet the compliance requirements of the EU AI Act. CRISP-ML(Q) guides the AI lifecycle through distinct phases, such as data preparation and model evaluation, while MLOps principles including automation, versioning, testing, and monitoring provide the operational backbone for ensuring AI systems are reliable, reproducible, and continuously compliant. In this chapter, you will also learn about the MLOps Stack Canvas as a framework for defining the necessary technical infrastructure, covering data, code, and model management, to support proactive compliance engineering.</p>&#13;
          </li>&#13;
          <li>&#13;
            <p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch03.html#chapter_3_data_and_ai_governance_and_ai_engineering_1748539918115723">Chapter 3, “Data and AI Governance and AI Engineering”</a>, explains the critical roles of data governance and AI governance within the context of the EU AI Act. In this chapter, you will learn about how these governance concepts can be practically integrated into the AI system development lifecycle to ensure trustworthy and compliant AI.</p>&#13;
          </li>&#13;
          <li>&#13;
            <p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch04.html#chapter_4_ai_system_assessment_and_tailoring_ai_engineering_1748539919034657">Chapter 4, “AI System Assessment and Tailoring AI Engineering for Different Risk Levels”</a>, focuses on the crucial initial steps for organizations to achieve compliance with the EU AI Act. You will learn about creating an inventory of your existing AI systems and how to classify their risk level to determine the applicable obligations. The chapter also explains the different roles organizations can take (provider or deployer), which further tailors compliance requirements.</p>&#13;
          </li>&#13;
          <li>&#13;
            <p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch05.html#chapter_5_ai_engineering_for_high_risk_ai_systems_1748539922576008">Chapter 5, “AI Engineering for High-Risk AI Systems”</a>, offers a comprehensive guide to implementing the EU AI Act’s requirements for high-risk AI systems through AI engineering practices. It breaks down key articles of the Act (Articles 9–15), focusing on topics like risk management, data governance, <span class="keep-together">documentation</span>, recordkeeping, transparency, human oversight, accuracy, robustness, and security. You will learn how to map the Act’s legal requirements to specific quality attributes and how to integrate them into the CRISP-ML(Q) lifecycle. This chapter shows why documentation and metadata management are crucial for demonstrating compliance and ensuring the trustworthiness of high-risk AI systems.</p>&#13;
          </li>&#13;
          <li>&#13;
            <p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch06.html#chapter_6_ai_engineering_for_limited_risk_ai_systems_1748539923606988">Chapter 6, “AI Engineering for Limited-Risk AI Systems”</a>, focuses on how to develop AI systems that meet the EU AI Act’s transparency obligations, which differ from the stricter conformity assessments required for high-risk systems. Here, you will learn about integrating the SMACTR framework with the CRISP-ML(Q) lifecycle. This chapter also highlights the emerging role of AI governance platforms and various technical tools in facilitating compliance and responsible AI deployment.</p>&#13;
          </li>&#13;
          <li>&#13;
            <p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch07.html#chapter_7_toward_trustworthy_general_purpose_ai_and_generati_1748539924538638">Chapter 7, “Toward Trustworthy General-Purpose AI and Generative AI”</a>, explains how the Act aims to balance AI innovation with risk mitigation, introducing concepts like GPAI and systemic risk. It outlines the specific transparency obligations for generative AI systems, such as informing users of AI interactions and marking synthetic content, and details the regulations for GPAI models, including documentation and risk management requirements for providers and deployers. You will also learn about GenAIOps, a framework for operationalizing the transparency and compliance aspects of GenAI development and deployment by integrating them with established methodologies like CRISP-ML(Q) and the SMACTR framework.</p>&#13;
          </li>&#13;
        </ul>&#13;
      </div></section>&#13;
&#13;
      <section data-pdf-bookmark="Conventions Used in This Book" data-type="sect1"><div class="sect1" id="_conventions_used_in_this_book">&#13;
<h1>Conventions Used in This Book</h1>&#13;
&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>This element signifies a tip or suggestion.</p>&#13;
</div>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>This element signifies a general note.</p>&#13;
</div>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>This element indicates a warning or caution.</p>&#13;
</div>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="O’Reilly Online Learning" data-type="sect1"><div class="sect1" id="_safari_books_online">&#13;
<h1>O’Reilly Online Learning</h1>&#13;
<div class="ormenabled" data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>For more than 40 years, <a class="orm:hideurl" href="https://oreilly.com"><em class="hyperlink">O’Reilly Media</em></a> has provided technology and business training, knowledge, and insight to help companies succeed.</p>&#13;
</div>&#13;
<p>Our unique network of experts and innovators share their knowledge and expertise through books, articles, and our online learning platform. O’Reilly’s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from O’Reilly and 200+ other publishers. For more information, visit <a class="orm:hideurl" href="https://oreilly.com"><em>https://oreilly.com</em></a>.</p>&#13;
</div></section>&#13;
<section data-pdf-bookmark="How to Contact Us" data-type="sect1"><div class="sect1" id="_how_to_contact_us">&#13;
<h1>How to Contact Us</h1>&#13;
<p>Please address comments and questions concerning this book to the publisher:</p>&#13;
<ul class="simplelist">&#13;
  <li>O’Reilly Media, Inc.</li>&#13;
  <li>1005 Gravenstein Highway North</li>&#13;
  <li>Sebastopol, CA 95472</li>&#13;
  <li>800-889-8969 (in the United States or Canada)</li>&#13;
  <li>707-827-7019 (international or local)</li>&#13;
  <li>707-829-0104 (fax)</li>&#13;
  <li><a class="email" href="mailto:support@oreilly.com"><em>support@oreilly.com</em></a></li>&#13;
  <li><a href="https://oreilly.com/about/contact.html"><em>https://oreilly.com/about/contact.html</em></a></li>&#13;
</ul>&#13;
<p>We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at <a href="https://oreil.ly/AI-engineer-EU-AI-Act"><em>https://oreil.ly/AI-engineer-EU-AI-Act</em></a>.</p>&#13;
<!--Don't forget to update the link above.-->&#13;
&#13;
<p>For news and information about our books and courses, visit <a href="https://oreilly.com"><em class="hyperlink">https://oreilly.com</em></a>.</p>&#13;
<p>Find us on LinkedIn: <a href="https://linkedin.com/company/oreilly-media"><em class="hyperlink">https://linkedin.com/company/oreilly-media</em></a>.</p>&#13;
<p>Watch us on YouTube: <a href="https://youtube.com/oreillymedia"><em class="hyperlink">https://youtube.com/oreillymedia</em></a>.</p>&#13;
</div></section>&#13;
&#13;
      <section data-pdf-bookmark="Acknowledgments" data-type="sect1"><div class="sect1" id="preface_acknowledgments_1748539924710165">&#13;
        <h1>Acknowledgments</h1>&#13;
        <p>Bringing this book to life has been a truly fulfilling experience. I’ve had so much support from so many people throughout the process of writing the book—thank you so much to everyone who helped make it a reality! </p>&#13;
        <p>I would like to give an especially big thank you to the book’s technical reviewers: Una Galyeva, Katharine Jarmul, Janna Lipenkova, Anil Sood, and Debmalya Biswas. Their time and effort in reading through the initial draft and providing comments, <span class="keep-together">suggestions</span>, and corrections were invaluable, and they made significant contributions to improving the book’s overall quality.</p>&#13;
        <p>Everyone at O’Reilly has been fantastic to work with throughout the book’s lifecycle, starting with Nicole Butterfield, who immediately saw the potential of the core message that EU AI Act compliance is fundamentally an engineering challenge. Sara Hunter worked intensively with me to shape and edit the book, and when I was ready to move to the production process, Kristen Brown was just amazing. A big thank you to the entire O’Reilly team, including copyeditor Rachel Head, proofreader Kim Cofer, indexer Ben Hurst, illustrator Kate Dullea, and the cover design team of Monica Kaamsvaag and Susan Brown. You are all heroes!</p>&#13;
      </div></section>&#13;
    </div></section></body></html>