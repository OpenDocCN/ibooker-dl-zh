["```py\nfrom sklearn.datasets import fetch_openml\n\nmnist = fetch_openml('mnist_784', as_frame=False)\n```", "```py\n>>> X, y = mnist.data, mnist.target\n>>> X\narray([[0., 0., 0., ..., 0., 0., 0.],\n [0., 0., 0., ..., 0., 0., 0.],\n [0., 0., 0., ..., 0., 0., 0.],\n ...,\n [0., 0., 0., ..., 0., 0., 0.],\n [0., 0., 0., ..., 0., 0., 0.],\n [0., 0., 0., ..., 0., 0., 0.]])\n>>> X.shape\n(70000, 784)\n>>> y\narray(['5', '0', '4', ..., '4', '5', '6'], dtype=object)\n>>> y.shape\n(70000,)\n```", "```py\nimport matplotlib.pyplot as plt\n\ndef plot_digit(image_data):\n    image = image_data.reshape(28, 28)\n    plt.imshow(image, cmap=\"binary\")\n    plt.axis(\"off\")\n\nsome_digit = X[0]\nplot_digit(some_digit)\nplt.show()\n```", "```py\n>>> y[0]\n'5'\n```", "```py\nX_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n```", "```py\ny_train_5 = (y_train == '5')  # True for all 5s, False for all other digits\ny_test_5 = (y_test == '5')\n```", "```py\nfrom sklearn.linear_model import SGDClassifier\n\nsgd_clf = SGDClassifier(random_state=42)\nsgd_clf.fit(X_train, y_train_5)\n```", "```py\n>>> sgd_clf.predict([some_digit])\narray([ True])\n```", "```py\n>>> from sklearn.model_selection import cross_val_score\n>>> cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\narray([0.95035, 0.96035, 0.9604 ])\n```", "```py\nfrom sklearn.dummy import DummyClassifier\n\ndummy_clf = DummyClassifier()\ndummy_clf.fit(X_train, y_train_5)\nprint(any(dummy_clf.predict(X_train)))  # prints False: no 5s detected\n```", "```py\n>>> cross_val_score(dummy_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\narray([0.90965, 0.90965, 0.90965])\n```", "```py\nfrom sklearn.model_selection import cross_val_predict\n\ny_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n```", "```py\n>>> from sklearn.metrics import confusion_matrix\n>>> cm = confusion_matrix(y_train_5, y_train_pred)\n>>> cm\narray([[53892,   687],\n [ 1891,  3530]])\n```", "```py\n>>> y_train_perfect_predictions = y_train_5  # pretend we reached perfection\n>>> confusion_matrix(y_train_5, y_train_perfect_predictions)\narray([[54579,     0],\n [    0,  5421]])\n```", "```py\n>>> from sklearn.metrics import precision_score, recall_score\n>>> precision_score(y_train_5, y_train_pred)  # == 3530 / (687 + 3530)\n0.8370879772350012\n>>> recall_score(y_train_5, y_train_pred)  # == 3530 / (1891 + 3530)\n0.6511713705958311\n```", "```py\n>>> from sklearn.metrics import f1_score\n>>> f1_score(y_train_5, y_train_pred)\n0.7325171197343846\n```", "```py\n>>> y_scores = sgd_clf.decision_function([some_digit])\n>>> y_scores\narray([2164.22030239])\n>>> threshold = 0\n>>> y_some_digit_pred = (y_scores > threshold)\narray([ True])\n```", "```py\n>>> threshold = 3000\n>>> y_some_digit_pred = (y_scores > threshold)\n>>> y_some_digit_pred\narray([False])\n```", "```py\ny_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n                             method=\"decision_function\")\n```", "```py\nfrom sklearn.metrics import precision_recall_curve\n\nprecisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n```", "```py\nplt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\nplt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\nplt.vlines(threshold, 0, 1.0, \"k\", \"dotted\", label=\"threshold\")\n[...]  # beautify the figure: add grid, legend, axis, labels, and circles\nplt.show()\n```", "```py\nplt.plot(recalls, precisions, linewidth=2, label=\"Precision/Recall curve\")\n[...]  # beautify the figure: add labels, grid, legend, arrow, and text\nplt.show()\n```", "```py\n>>> idx_for_90_precision = (precisions >= 0.90).argmax()\n>>> threshold_for_90_precision = thresholds[idx_for_90_precision]\n>>> threshold_for_90_precision\n3370.0194991439557\n```", "```py\ny_train_pred_90 = (y_scores >= threshold_for_90_precision)\n```", "```py\n>>> precision_score(y_train_5, y_train_pred_90)\n0.9000345901072293\n>>> recall_at_90_precision = recall_score(y_train_5, y_train_pred_90)\n>>> recall_at_90_precision\n0.4799852425751706\n```", "```py\nfrom sklearn.metrics import roc_curve\n\nfpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n```", "```py\nidx_for_threshold_at_90 = (thresholds <= threshold_for_90_precision).argmax()\ntpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]\n\nplt.plot(fpr, tpr, linewidth=2, label=\"ROC curve\")\nplt.plot([0, 1], [0, 1], 'k:', label=\"Random classifier's ROC curve\")\nplt.plot([fpr_90], [tpr_90], \"ko\", label=\"Threshold for 90% precision\")\n[...]  # beautify the figure: add labels, grid, legend, arrow, and text\nplt.show()\n```", "```py\n>>> from sklearn.metrics import roc_auc_score\n>>> roc_auc_score(y_train_5, y_scores)\n0.9604938554008616\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\n\nforest_clf = RandomForestClassifier(random_state=42)\n```", "```py\ny_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n                                    method=\"predict_proba\")\n```", "```py\n>>> y_probas_forest[:2]\narray([[0.11, 0.89],\n [0.99, 0.01]])\n```", "```py\ny_scores_forest = y_probas_forest[:, 1]\nprecisions_forest, recalls_forest, thresholds_forest = precision_recall_curve(\n    y_train_5, y_scores_forest)\n```", "```py\nplt.plot(recalls_forest, precisions_forest, \"b-\", linewidth=2,\n         label=\"Random Forest\")\nplt.plot(recalls, precisions, \"--\", linewidth=2, label=\"SGD\")\n[...]  # beautify the figure: add labels, grid, and legend\nplt.show()\n```", "```py\n>>> y_train_pred_forest = y_probas_forest[:, 1] >= 0.5  # positive proba \u2265 50%\n>>> f1_score(y_train_5, y_pred_forest)\n0.9242275142688446\n>>> roc_auc_score(y_train_5, y_scores_forest)\n0.9983436731328145\n```", "```py\nfrom sklearn.svm import SVC\n\nsvm_clf = SVC(random_state=42)\nsvm_clf.fit(X_train[:2000], y_train[:2000])  # y_train, not y_train_5\n```", "```py\n>>> svm_clf.predict([some_digit])\narray(['5'], dtype=object)\n```", "```py\n>>> some_digit_scores = svm_clf.decision_function([some_digit])\n>>> some_digit_scores.round(2)\narray([[ 3.79,  0.73,  6.06,  8.3 , -0.29,  9.3 ,  1.75,  2.77,  7.21,\n 4.82]])\n```", "```py\n>>> class_id = some_digit_scores.argmax()\n>>> class_id\n5\n```", "```py\n>>> svm_clf.classes_\narray(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object)\n>>> svm_clf.classes_[class_id]\n'5'\n```", "```py\nfrom sklearn.multiclass import OneVsRestClassifier\n\novr_clf = OneVsRestClassifier(SVC(random_state=42))\novr_clf.fit(X_train[:2000], y_train[:2000])\n```", "```py\n>>> ovr_clf.predict([some_digit])\narray(['5'], dtype='<U1')\n>>> len(ovr_clf.estimators_)\n10\n```", "```py\n>>> sgd_clf = SGDClassifier(random_state=42)\n>>> sgd_clf.fit(X_train, y_train)\n>>> sgd_clf.predict([some_digit])\narray(['3'], dtype='<U1')\n```", "```py\n>>> sgd_clf.decision_function([some_digit]).round()\narray([[-31893., -34420.,  -9531.,   1824., -22320.,  -1386., -26189.,\n -16148.,  -4604., -12051.]])\n```", "```py\n>>> cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\narray([0.87365, 0.85835, 0.8689 ])\n```", "```py\n>>> from sklearn.preprocessing import StandardScaler\n>>> scaler = StandardScaler()\n>>> X_train_scaled = scaler.fit_transform(X_train.astype(\"float64\"))\n>>> cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\narray([0.8983, 0.891 , 0.9018])\n```", "```py\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\ny_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\nConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\nplt.show()\n```", "```py\nConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,\n                                        normalize=\"true\", values_format=\".0%\")\nplt.show()\n```", "```py\nsample_weight = (y_train_pred != y_train)\nConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,\n                                        sample_weight=sample_weight,\n                                        normalize=\"true\", values_format=\".0%\")\nplt.show()\n```", "```py\ncl_a, cl_b = '3', '5'\nX_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\nX_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\nX_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\nX_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n[...]  # plot all images in X_aa, X_ab, X_ba, X_bb in a confusion matrix style\n```", "```py\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\n\ny_train_large = (y_train >= '7')\ny_train_odd = (y_train.astype('int8') % 2 == 1)\ny_multilabel = np.c_[y_train_large, y_train_odd]\n\nknn_clf = KNeighborsClassifier()\nknn_clf.fit(X_train, y_multilabel)\n```", "```py\n>>> knn_clf.predict([some_digit])\narray([[False,  True]])\n```", "```py\n>>> y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n>>> f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")\n0.976410265560605\n```", "```py\nfrom sklearn.multioutput import ClassifierChain\n\nchain_clf = ClassifierChain(SVC(), cv=3, random_state=42)\nchain_clf.fit(X_train[:2000], y_multilabel[:2000])\n```", "```py\n>>> chain_clf.predict([some_digit])\narray([[0., 1.]])\n```", "```py\nnp.random.seed(42)  # to make this code example reproducible\nnoise = np.random.randint(0, 100, (len(X_train), 784))\nX_train_mod = X_train + noise\nnoise = np.random.randint(0, 100, (len(X_test), 784))\nX_test_mod = X_test + noise\ny_train_mod = X_train\ny_test_mod = X_test\n```", "```py\nknn_clf = KNeighborsClassifier()\nknn_clf.fit(X_train_mod, y_train_mod)\nclean_digit = knn_clf.predict([X_test_mod[0]])\nplot_digit(clean_digit)\nplt.show()\n```"]