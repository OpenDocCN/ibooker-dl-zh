- en: 'Chapter 4\. The “Hello World” of TinyML: Building and Training a Model'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 3](ch03.xhtml#chapter_get_up_to_speed), we learned the basic concepts
    of machine learning and the general workflow that machine learning projects follow.
    In this chapter and the next, we’ll start putting our knowledge into practice.
    We’re going to build and train a model from scratch and then integrate it into
    a simple microcontroller program.
  prefs: []
  type: TYPE_NORMAL
- en: In the process, you’ll get your hands dirty with some powerful developer tools
    that are used every day by cutting-edge machine learning practitioners. You’ll
    also learn how to integrate a machine learning model into a C++ program and deploy
    it to a microcontroller to control current flowing in a circuit. This might be
    your first taste of mixing hardware and ML, and it should be fun!
  prefs: []
  type: TYPE_NORMAL
- en: 'You can test the code that we write in these chapters on your Mac, Linux, or
    Windows machine, but for the full experience, you’ll need one of the embedded
    devices mentioned in [“What Hardware Do You Need?”](ch02.xhtml#getting_started_hardware_requirements):'
  prefs: []
  type: TYPE_NORMAL
- en: '[Arduino Nano 33 BLE Sense](https://oreil.ly/6qlMD)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[SparkFun Edge](https://oreil.ly/-hoL-)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[ST Microelectronics STM32F746G Discovery kit](https://oreil.ly/cvm4J)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To create our machine learning model, we’ll use Python, TensorFlow, and Google’s
    Colaboratory, which is a cloud-based interactive notebook for experimenting with
    Python code. These are some of the most important tools for real-world machine
    learning engineers, and they’re all free to use.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Wondering about the title of this chapter? It’s a tradition in programming that
    new technologies are introduced with example code that demonstrates how to do
    something very simple. Often, the simple task is to make a program output the
    words, [“Hello, world.”](https://oreil.ly/zK06G) There’s no clear equivalent in
    ML, but we’re using the term “hello world” to refer to a simple, easy-to-read
    example of an end-to-end TinyML application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Over the course of this chapter, we will do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Obtain a simple dataset.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Train a deep learning model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Evaluate the model’s performance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert the model to run on-device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write code to perform on-device inference.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the code into a binary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the binary to a microcontroller.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All the code that we will use is available in [TensorFlow’s GitHub repository](https://oreil.ly/TQ4CC).
  prefs: []
  type: TYPE_NORMAL
- en: We recommend that you walk through each part of this chapter and then try running
    the code. There are instructions on how to do this along the way. But before we
    start, let’s discuss exactly what we’re going to build.
  prefs: []
  type: TYPE_NORMAL
- en: What We’re Building
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 3](ch03.xhtml#chapter_get_up_to_speed), we discussed how deep learning
    networks learn to model patterns in their training data so they can make predictions.
    We’re now going to train a network to model some very simple data. You’ve probably
    heard of the [sine](https://oreil.ly/jxAmF) function. It’s used in trigonometry
    to help describe the properties of right-angled triangles. The data we’ll be training
    with is a [sine wave](https://oreil.ly/XDvJu), which is the graph obtained by
    plotting the result of the sine function over time (see [Figure 4-1](#sine_wave)).
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to train a model that can take a value, `x`, and predict its sine,
    `y`. In a real-world application, if you needed the sine of `x`, you could just
    calculate it directly. However, by training a model to approximate the result,
    we can demonstrate the basics of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: The second part of our project will be to run this model on a hardware device.
    Visually, the sine wave is a pleasant curve that runs smoothly from –1 to 1 and
    back. This makes it perfect for controlling a visually pleasing light show! We’ll
    be using the output of our model to control the timing of either some flashing
    LEDs or a graphical animation, depending on the capabilities of the device.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graph of a sine function over time](Images/timl_0401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-1\. A sine wave
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Online, you can see an [animated GIF](https://oreil.ly/XhqG9) of this code flashing
    the LEDs of a SparkFun Edge. [Figure 4-2](#sparkfun_edge_hello_world) is a still
    from this animation, showing a couple of the device’s LEDs lit. This may not be
    a particularly useful application of machine learning, but in the spirit of a
    “hello world” example, it’s simple, fun, and will help demonstrate the basic principles
    you need to know.
  prefs: []
  type: TYPE_NORMAL
- en: 'After we get our basic code working, we’ll be deploying it to three different
    devices: the SparkFun Edge, an Arduino Nano 33 BLE Sense, and an ST Microelectronics
    STM32F746G Discovery kit.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Since TensorFlow is an actively developed open source project that is continually
    evolving, you might notice some slight differences between the code printed here
    and the code hosted online. Don’t worry—even if a few lines of code change, the
    basic principles remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: '![A still from a video showing the SparkFun Edge with two LEDs lit](Images/timl_0402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-2\. The code running on a SparkFun Edge
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Our Machine Learning Toolchain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To build the machine learning parts of this project, we’re using the same tools
    used by real-world machine learning practitioners. This section introduces them
    to you.
  prefs: []
  type: TYPE_NORMAL
- en: Python and Jupyter Notebooks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Python is the favorite programming language of machine learning scientists and
    engineers. It’s easy to learn, works well for many different applications, and
    has a ton of libraries for useful tasks involving data and mathematics. The vast
    majority of deep learning research is done using Python, and researchers often
    release the Python source code for the models they create.
  prefs: []
  type: TYPE_NORMAL
- en: Python is especially great when combined with something called [*Jupyter Notebooks*](https://jupyter.org/).
    This is a special document format that allows you to mix writing, graphics, and
    code that can be run at the click of a button. Jupyter notebooks are widely used
    as a way to describe, explain, and explore machine learning code and problems.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll be creating our model inside of a Jupyter notebook, which permits us to
    do awesome things to visualize our data during development. This includes displaying
    graphs that show our model’s accuracy and convergence.
  prefs: []
  type: TYPE_NORMAL
- en: If you have some programming experience, Python is easy to read and learn. You
    should be able to follow this tutorial without any trouble.
  prefs: []
  type: TYPE_NORMAL
- en: Google Colaboratory
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To run our notebook we’ll use a tool called [Colaboratory](https://oreil.ly/ZV7NK),
    or *Colab* for short. Colab is made by Google, and it provides an online environment
    for running Jupyter notebooks. It’s provided for free as a tool to encourage research
    and development in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Traditionally, you needed to create a notebook on your own computer. This required
    installing a lot of dependencies, such as Python libraries, which can be a headache.
    It was also difficult to share the resulting notebook with other people, since
    they might have different versions of the dependencies, meaning the notebook might
    not run as expected. In addition, machine learning can be computationally intensive,
    so training models might be slow on your development computer.
  prefs: []
  type: TYPE_NORMAL
- en: Colab allows you to run notebooks on Google’s powerful hardware, at zero cost.
    You can edit and view your notebooks from any web browser, and you can share them
    with other people, who are guaranteed to get the same results when they run them.
    You can even configure Colab to run your code on specially accelerated hardware
    that can perform training more quickly than a normal computer.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow and Keras
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[TensorFlow](https://tensorflow.org) is a set of tools for building, training,
    evaluating, and deploying machine learning models. Originally developed at Google,
    TensorFlow is now an open source project built and maintained by thousands of
    contributors across the world. It is the most popular and widely used framework
    for machine learning. Most developers interact with TensorFlow via its Python
    library.'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow does many different things. In this chapter we’ll use [Keras](https://oreil.ly/JgNtS),
    TensorFlow’s high-level API that makes it easy to build and train deep learning
    networks. We’ll also use [TensorFlow Lite](https://oreil.ly/LbDBK), a set of tools
    for deploying TensorFlow models to mobile and embedded devices, to run our model
    on-device.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 13](ch13.xhtml#chapter_tensorflow_lite_for_microcontrollers) will
    cover TensorFlow in much more detail. For now, just know that it is an extremely
    powerful and industry-standard tool that will continue to serve your needs as
    you go from beginner to deep learning expert.'
  prefs: []
  type: TYPE_NORMAL
- en: Building Our Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’re now going to walk through the process of building, training, and converting
    our model. We include all of the code in this chapter, but you can also follow
    along in Colab and run the code as you go.
  prefs: []
  type: TYPE_NORMAL
- en: First, [load the notebook](https://oreil.ly/NN6Mj). After the page loads, at
    the top, click the “Run in Google Colab” button, as shown in [Figure 4-3](#run_in_google_colab).
    This copies the notebook from GitHub into Colab, allowing you to run it and make
    edits.
  prefs: []
  type: TYPE_NORMAL
- en: '![The ''Run in Google Colab'' button](Images/timl_0403.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-3\. The “Run in Google Colab” button
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: By default, in addition to the code, the notebook contains a sample of the output
    you should expect to see when the code is run. Since we’ll be running through
    the code in this chapter, let’s clear this output so the notebook is in a pristine
    state. To do this, in Colab’s menu, click Edit and then select “Clear all outputs,”
    as shown in [Figure 4-4](#clear_all_outputs).
  prefs: []
  type: TYPE_NORMAL
- en: '![The ''Clear all outputs'' option](Images/timl_0404.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-4\. The “Clear all outputs” option
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Nice work. Our notebook is now ready to go!
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you’re already familiar with machine learning, TensorFlow, and Keras, you
    might want to skip ahead to the part where we convert our model to use with TensorFlow
    Lite. In the book, jump to [“Converting the Model for TensorFlow Lite”](#converting_the_model).
    In Colab, scroll down to the heading “Convert to TensorFlow Lite.”
  prefs: []
  type: TYPE_NORMAL
- en: Importing Dependencies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our first task is to import the dependencies we need. In Jupyter notebooks,
    code and text are arranged in *cells*. There are *code* cells, which contain executable
    Python code, and *text* cells, which contain formatted text.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our first code cell is located under “Import dependencies.” It sets up all
    of the libraries that we need to train and convert our model. Here’s the code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'In Python, the `import` statement loads a library so that it can be used from
    our code. You can see from the code and comments that this cell does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Installs the TensorFlow 2.0 library using `pip`, a package manager for Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Imports TensorFlow, NumPy, Matplotlib, and Python’s `math` library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we import a library, we can give it an alias so that it’s easy to refer
    to later. For example, in the preceding code, we use `import numpy as np` to import
    NumPy and give it the alias `np`. When we use it in our code, we can refer to
    it as `np`.
  prefs: []
  type: TYPE_NORMAL
- en: The code in code cells can be run by clicking the button that appears at the
    upper left when the cell is selected. In the “Import dependencies” section, click
    anywhere in the first code cell so that it becomes selected. [Figure 4-5](#import_dependencies)
    shows what a selected cell looks like.
  prefs: []
  type: TYPE_NORMAL
- en: '![The ''Import dependencies'' cell in its selected state](Images/timl_0405.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-5\. The “Import dependencies” cell in its selected state
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To run the code, click the button that appears in the upper left. As the code
    is being run, the button will animate with a circle as depicted in [Figure 4-6](#import_dependencies_running).
  prefs: []
  type: TYPE_NORMAL
- en: 'The dependencies will begin to be installed, and you’ll see some output appearing.
    You should eventually see the following line, meaning that the library was installed
    successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![The ''Import dependencies'' cell in its running state](Images/timl_0406.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-6\. The “Import dependencies” cell in its running state
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: After a cell has been run in Colab, you’ll see that a `1` is now displayed in
    the upper-left corner when it is no longer selected, as illustrated in [Figure 4-7](#import_dependencies_counter).
    This number is a counter that is incremented each time the cell is run.
  prefs: []
  type: TYPE_NORMAL
- en: '![The cell run counter in the upper-left corner](Images/timl_0407.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-7\. The cell run counter in the upper-left corner
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can use this to understand which cells have been run, and how many times.
  prefs: []
  type: TYPE_NORMAL
- en: Generating Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning networks learn to model patterns in underlying data. As we mentioned
    earlier, we’re going to train a network to model data generated by a sine function.
    This will result in a model that can take a value, `x`, and predict its sine,
    `y`.
  prefs: []
  type: TYPE_NORMAL
- en: Before we go any further, we need some data. In a real-world situation, we might
    be collecting data from sensors and production logs. For this example, however,
    we’re using some simple code to generate a dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The next cell is where this will happen. Our plan is to generate 1,000 values
    that represent random points along a sine wave. Let’s take a look at [Figure 4-8](#sine_wave_2)
    to remind ourselves what a sine wave looks like.
  prefs: []
  type: TYPE_NORMAL
- en: Each full cycle of a wave is called its *period*. From the graph, we can see
    that a full cycle is completed approximately every six units on the `x`-axis.
    In fact, the period of a sine wave is 2 × π, or 2π.
  prefs: []
  type: TYPE_NORMAL
- en: So that we have a full sine wave worth of data to train on, our code will generate
    random `x` values from 0 to 2π. It will then calculate the sine for each of these
    values.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graph of a sine function over time](Images/timl_0401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-8\. A sine wave
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here’s the full code for this cell, which uses NumPy (`np`, which we imported
    earlier) to generate random numbers and calculate their sine:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: In addition to what we discussed earlier, there are a few things worth pointing
    out in this code. First, you’ll see that we use `np.random.uniform()` to generate
    our `x` values. This method returns an array of random numbers in the specified
    range. NumPy contains a lot of useful methods that operate on entire arrays of
    values, which is very convenient when dealing with data.
  prefs: []
  type: TYPE_NORMAL
- en: Second, after generating the data, we shuffle it. This is important because
    the training process used in deep learning depends on data being fed to it in
    a truly random order. If the data were in order, the resulting model would be
    less accurate.
  prefs: []
  type: TYPE_NORMAL
- en: Next, notice that we use NumPy’s `sin()` method to calculate our sine values.
    NumPy can do this for all of our `x` values at once, returning an array. NumPy
    is great!
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, you’ll see some mysterious code invoking `plt`, which is our alias
    for Matplotlib:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: What does this code do? It plots a graph of our data. One of the best things
    about Jupyter notebooks is their ability to display graphics that are output by
    the code you run. Matplotlib is an excellent tool for creating graphs from data.
    Since visualizing data is a crucial part of the machine learning workflow, this
    will be incredibly helpful as we train our model.
  prefs: []
  type: TYPE_NORMAL
- en: To generate the data and render it as a graph, run the code in the cell. After
    the code cell finishes running, you should see a beautiful graph appear underneath,
    like the one shown in [Figure 4-9](#smooth_data_graph).
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of our generated data](Images/timl_0409.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-9\. A graph of our generated data
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This is our data! It is a selection of random points along a nice, smooth sine
    curve. We could use this to train our model. However, this would be too easy.
    One of the exciting things about deep learning networks is their ability to sift
    patterns from noise. This allows them to make predictions even when trained on
    messy, real-world data. To show this off, let’s add some random noise to our datapoints
    and draw another graph:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Run this cell and take a look at the results, as shown in [Figure 4-10](#noisy_data_graph).
  prefs: []
  type: TYPE_NORMAL
- en: Much better! Our points are now randomized, so they represent a distribution
    around a sine wave instead of a smooth, perfect curve. This is much more reflective
    of a real-world situation, in which data is generally quite messy.
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of our data with noise added](Images/timl_0410.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-10\. A graph of our data with noise added
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Splitting the Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From the previous chapter, you might remember that a dataset is often split
    into three parts: *training*, *validation*, and *test*. To evaluate the accuracy
    of the model we train, we need to compare its predictions to real data and check
    how well they match up.'
  prefs: []
  type: TYPE_NORMAL
- en: This evaluation happens during training (where it is referred to as validation)
    and after training (referred to as testing). It’s important in each case that
    we use fresh data that was not already used to train the model.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure that we have data to use for evaluation, we’ll set some aside before
    we begin training. Let’s reserve 20% of our data for validation, and another 20%
    for testing. We’ll use the remaining 60% to train the model. This is a typical
    split used when training models.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code splits our data and then plots each set as a different color:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'To split our data, we use another handy NumPy method: `split()`. This method
    takes an array of data and an array of indices and then chops the data into parts
    at the indices provided.'
  prefs: []
  type: TYPE_NORMAL
- en: Run this cell to see the results of our split. Each type of data will be represented
    by a different color (or shade, if you’re reading the print version of this book),
    as demonstrated in [Figure 4-11](#split_data_graph).
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of our data split into training, validation, and test sets](Images/timl_0411.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-11\. A graph of our data split into training, validation, and test
    sets
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Defining a Basic Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have our data, it’s time to create the model that we’ll train to
    fit it.
  prefs: []
  type: TYPE_NORMAL
- en: We’re going to build a model that will take an input value (in this case, `x`)
    and use it to predict a numeric output value (the sine of `x`). This type of problem
    is called a *regression*. We can use regression models for all sorts of tasks
    that require a numeric output. For example, a regression model could attempt to
    predict a person’s running speed in miles per hour based on data from an accelerometer.
  prefs: []
  type: TYPE_NORMAL
- en: To create our model, we’re going to design a simple neural network. It uses
    layers of neurons to attempt to learn any patterns underlying the training data
    so that it can make predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code to do this is actually quite straightforward. It uses [*Keras*](https://oreil.ly/IpFqC),
    TensorFlow’s high-level API for creating deep learning networks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'First, we create a `Sequential` model using Keras, which just means a model
    in which each layer of neurons is stacked on top of the next, as we saw in [Figure 3-1](ch03.xhtml#network_layers).
    We then define two layers. Here’s where the first layer is defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The first layer has a single input—our `x` value—and 16 neurons. It’s a `Dense`
    layer (also known as a *fully connected* layer), meaning the input will be fed
    into every single one of its neurons during inference, when we’re making predictions.
    Each neuron will then become *activated* to a certain degree. The amount of activation
    for each neuron is based on both its *weight* and *bias* values, learned during
    training, and its *activation function*. The neuron’s activation is output as
    a number.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activation is calculated by a simple formula, shown in Python. We won’t ever
    need to code this ourselves, since it is handled by Keras and TensorFlow, but
    it will be helpful to know as we go further into deep learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: To calculate the neuron’s activation, its input is multiplied by the weight,
    and the bias is added to the result. The calculated value is passed into the activation
    function. The resulting number is the neuron’s activation.
  prefs: []
  type: TYPE_NORMAL
- en: The activation function is a mathematical function used to shape the output
    of the neuron. In our network, we’re using an activation function called *rectified
    linear unit*, or *ReLU* for short. This is specified in Keras by the argument
    `activation=relu`.
  prefs: []
  type: TYPE_NORMAL
- en: 'ReLU is a simple function, shown here in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'ReLU returns whichever is the larger value: its input, or zero. If its input
    value is negative, ReLU returns zero. If its input value is above zero, ReLU returns
    it unchanged.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 4-12](#relu) shows the output of ReLU for a range of input values.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of ReLU for inputs from –10 to 10](Images/timl_0412.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-12\. A graph of ReLU for inputs from –10 to 10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Without an activation function, the neuron’s output would always be a linear
    function of its input. This would mean that the network could model only linear
    relationships in which the ratio between `x` and `y` remains the same across the
    entire range of values. This would prevent a network from modeling our sine wave,
    because a sine wave is nonlinear.
  prefs: []
  type: TYPE_NORMAL
- en: Since ReLU is nonlinear, it allows multiple layers of neurons to join forces
    and model complex nonlinear relationships, in which the `y` value doesn’t increase
    by the same amount for every increment of `x`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: There are other activation functions, but ReLU is the most commonly used. You
    can see some of the other options in the [Wikipedia article on activation functions](https://oreil.ly/Yxe-N).
    Each activation function has different trade-offs, and machine learning engineers
    experiment to find which options work best for a given architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'The activation numbers from our first layer will be fed as inputs to our second
    layer, which is defined in the following line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Because this layer is a single neuron, it will receive 16 inputs, one for each
    of the neurons in the previous layer. Its purpose is to combine all of the activations
    from the previous layer into a single output value. Since this is our output layer,
    we don’t specify an activation function—we just want the raw result.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because this neuron has multiple inputs, it has a corresponding weight value
    for each. The neuron’s output is calculated by the following formula, shown in
    Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The output value is obtained by multiplying each input with its corresponding
    weight, summing the results, and then adding the neuron’s bias.
  prefs: []
  type: TYPE_NORMAL
- en: 'The network’s weights and biases are learned during training. The `compile()`
    step in the code shown earlier in the chapter configures some important arguments
    used in the training process, and prepares the model to be trained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `optimizer` argument specifies the algorithm that will adjust the network
    to model its input during training. There are several choices, and finding the
    best one often comes down to experimentation. You can read about the options in
    the [Keras documentation](https://oreil.ly/oT-pU).
  prefs: []
  type: TYPE_NORMAL
- en: The `loss` argument specifies the method used during training to calculate how
    far the network’s predictions are from reality. This method is called a *loss
    function*. Here, we’re using `mse`, or *mean squared error*. This loss function
    is used in the case of regression problems, for which we’re trying to predict
    a number. There are various loss functions available in Keras. You can see some
    of the options listed in the [Keras docs](https://keras.io/losses).
  prefs: []
  type: TYPE_NORMAL
- en: The `metrics` argument allows us to specify some additional functions that are
    used to judge the performance of our model. We specify `mae`, or *mean absolute
    error*, which is a helpful function for measuring the performance of a regression
    model. This metric will be measured during training, and we’ll have access to
    the results after training is done.
  prefs: []
  type: TYPE_NORMAL
- en: 'After we compile our model, we can use the following line to print some summary
    information about its architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the cell in Colab to define the model. You’ll see the following output
    printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This table shows the layers of the network, their output shapes, and their numbers
    of *parameters*. The size of a network⁠—how much memory it takes up—depends mostly
    on its number of parameters, meaning its total number of weights and biases. This
    can be a useful metric when discussing model size and complexity.
  prefs: []
  type: TYPE_NORMAL
- en: For simple models like ours, the number of weights can be determined by calculating
    the number of connections between neurons in the model, given that each connection
    has a weight.
  prefs: []
  type: TYPE_NORMAL
- en: The network we’ve just designed consists of two layers. Our first layer has
    16 connections—one between its input and each of its neurons. Our second layer
    has a single neuron, which also has 16 connections—one to each neuron in the first
    layer. This makes the total number of connections 32.
  prefs: []
  type: TYPE_NORMAL
- en: Since every neuron has a bias, the network has 17 biases, meaning it has a total
    of 32 + 17 = 49 parameters.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now walked through the code that defines our model. Next, we’ll begin
    the training process.
  prefs: []
  type: TYPE_NORMAL
- en: Training Our Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After we define our model, it’s time to train it and then evaluate its performance
    to see how well it works. When we see the metrics, we can decide if it’s good
    enough, or if we should make changes to our design and train it again.
  prefs: []
  type: TYPE_NORMAL
- en: 'To train a model in Keras we just call its `fit()` method, passing all of our
    data and some other important arguments. The code in the next cell shows how:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the code in the cell to begin training. You’ll see some logs start to appear:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Our model is now training. This will take a little while, so while we wait
    let’s walk through the details of our call to `fit()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: First, you’ll notice that we assign the return value of our `fit()` call to
    a variable named `history_1`. This variable contains a ton of information about
    our training run, and we’ll use it later to investigate how things went.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let’s take a look at the `fit()` function’s arguments:'
  prefs: []
  type: TYPE_NORMAL
- en: '`x_train`, `y_train`'
  prefs: []
  type: TYPE_NORMAL
- en: The first two arguments to `fit()` are the `x` and `y` values of our training
    data. Remember that parts of our data are kept aside for validation and testing,
    so only the training set is used to train the network.
  prefs: []
  type: TYPE_NORMAL
- en: '`epochs`'
  prefs: []
  type: TYPE_NORMAL
- en: The next argument specifies how many times our entire training set will be run
    through the network during training. The more epochs, the more training will occur.
    You might think that the more training happens, the better the network will be.
    However, some networks will start to overfit their training data after a certain
    number of epochs, so we might want to limit the amount of training we do.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, even if there’s no overfitting, a network will stop improving after
    a certain amount of training. Since training costs time and computational resources,
    it’s best not to train if the network isn’t getting better!
  prefs: []
  type: TYPE_NORMAL
- en: We’re starting out with 1,000 epochs of training. When training is complete,
    we can dig into our metrics to discover whether this is the correct number.
  prefs: []
  type: TYPE_NORMAL
- en: '`batch_size`'
  prefs: []
  type: TYPE_NORMAL
- en: The `batch_size` argument specifies how many pieces of training data to feed
    into the network before measuring its accuracy and updating its weights and biases.
    If we wanted, we could specify a `batch_size` of `1`, meaning we’d run inference
    on a single datapoint, measure the loss of the network’s prediction, update the
    weights and biases to make the prediction more accurate next time, and then continue
    this cycle for the rest of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Because we have 600 datapoints, each epoch would result in 600 updates to the
    network. This is a lot of computation, so our training would take ages! An alternative
    might be to select and run inference on multiple datapoints, measure the loss
    in aggregate, and then updating the network accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: If we set `batch_size` to `600`, each batch would include all of our training
    data. We’d now have to make only one update to the network every epoch—much quicker.
    The problem is, this results in less accurate models. Research has shown that
    models trained with large batch sizes have less ability to generalize to new data—they
    are more likely to overfit.
  prefs: []
  type: TYPE_NORMAL
- en: The compromise is to use a batch size that is somewhere in the middle. In our
    training code, we use a batch size of 16\. This means that we’ll choose 16 datapoints
    at random, run inference on them, calculate the loss in aggregate, and update
    the network once per batch. If we have 600 points of training data, the network
    will be updated around 38 times per epoch, which is far better than 600.
  prefs: []
  type: TYPE_NORMAL
- en: When choosing a batch size, we’re making a compromise between training efficiency
    and model accuracy. The ideal batch size will vary from model to model. It’s a
    good idea to start with a batch size of 16 or 32 and experiment to see what works
    best.
  prefs: []
  type: TYPE_NORMAL
- en: '`validation_data`'
  prefs: []
  type: TYPE_NORMAL
- en: This is where we specify our validation dataset. Data from this dataset will
    be run through the network throughout the training process, and the network’s
    predictions will be compared with the expected values. We’ll see the results of
    validation in the logs and as part of the `history_1` object.
  prefs: []
  type: TYPE_NORMAL
- en: Training Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hopefully, by now, training has finished. If not, wait a few moments for it
    to complete.
  prefs: []
  type: TYPE_NORMAL
- en: We’re now going to check various metrics to see how well our network has learned.
    To begin, let’s look at the logs written during training. This will show how the
    network has improved during training from its random initial state.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the logs for our first and last epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The `loss`, `mae`, `val_loss`, and `val_mae` tell us various things:'
  prefs: []
  type: TYPE_NORMAL
- en: '`loss`'
  prefs: []
  type: TYPE_NORMAL
- en: This is the output of our loss function. We’re using mean squared error, which
    is expressed as a positive number. Generally, the smaller the loss value, the
    better, so this is a good thing to watch as we evaluate our network.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing the first and last epochs, the network has clearly improved during
    training, going from a loss of ~0.7 to a smaller value of ~0.15\. Let’s look at
    the other numbers to see whether this improvement is enough!
  prefs: []
  type: TYPE_NORMAL
- en: '`mae`'
  prefs: []
  type: TYPE_NORMAL
- en: This is the mean absolute error of our training data. It shows the average difference
    between the network’s predictions and the expected `y` values from the training
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can expect our initial error to be pretty dismal, given that it’s based
    on an untrained network. This is certainly the case: the network’s predictions
    are off by an average of ~0.78, which is a large number when the range of acceptable
    values is only from –1 to 1!'
  prefs: []
  type: TYPE_NORMAL
- en: However, even after training, our mean absolute error is ~0.30\. This means
    that our predictions are off by an average of ~0.30, which is still quite awful.
  prefs: []
  type: TYPE_NORMAL
- en: '`val_loss`'
  prefs: []
  type: TYPE_NORMAL
- en: This is the output of our loss function on our validation data. In our final
    epoch, the training loss (~0.15) is slightly lower than the validation loss (~0.17).
    This is a hint that our network might be overfitting, because it is performing
    worse on data it has not seen before.
  prefs: []
  type: TYPE_NORMAL
- en: '`val_mae`'
  prefs: []
  type: TYPE_NORMAL
- en: This is the mean absolute error for our validation data. With a value of ~0.32,
    it’s worse than the mean absolute error on our training set, which is another
    sign that the network might be overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Graphing the History
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, it’s clear that our model is not doing a great job of making accurate
    predictions. Our task now is to figure out why. To do so, let’s make use of the
    data collected in our `history_1` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next cell extracts the training and validation loss data from the history
    object and plots it on a chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The `history_1` object contains an attribute called, `history_1.history`, which
    is a dictionary recording metric values during training and validation. We use
    this to collect the data we’re going to plot. For our x-axis we use the epoch
    number, which we determine by looking at the number of loss datapoints. Run the
    cell and you’ll see the graph in [Figure 4-13](#training_validation_loss).
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of training and validation loss](Images/timl_0413.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-13\. A graph of training and validation loss
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, the amount of loss rapidly decreases over the first 50 epochs,
    before flattening out. This means that the model is improving and producing more
    accurate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Our goal is to stop training when either the model is no longer improving or
    the training loss is less than the validation loss, which would mean that the
    model has learned to predict the training data so well that it can no longer generalize
    to new data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The loss drops precipitously in the first few epochs, which makes the rest
    of the graph quite difficult to read. Let’s skip the first 100 epochs by running
    the next cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 4-14](#training_validation_loss_skip) presents the graph produced by
    this cell.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of training and validation loss, skipping the first 100 epochs](Images/timl_0414.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-14\. A graph of training and validation loss, skipping the first 100
    epochs
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now that we’ve zoomed in, you can see that loss continues to reduce until around
    600 epochs, at which point it is mostly stable. This means that there’s probably
    no need to train our network for so long.
  prefs: []
  type: TYPE_NORMAL
- en: However, you can also see that the lowest loss value is still around 0.15\.
    This seems relatively high. In addition, the validation loss values are consistently
    even higher.
  prefs: []
  type: TYPE_NORMAL
- en: 'To gain more insight into our model’s performance we can plot some more data.
    This time, let’s plot the mean absolute error. Run the next cell to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 4-15](#training_validation_mae) shows the resulting graph.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of mean absolute error during training and validation](Images/timl_0415.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-15\. A graph of mean absolute error during training and validation
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This graph of mean absolute error gives us some further clues. We can see that
    on average, the training data shows lower error than the validation data, which
    means that the network might have overfit, or learned the training data so rigidly
    that it can’t make effective predictions about new data.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, the mean absolute error values are quite high, around ~0.31, which
    means that some of the model’s predictions are wrong by at least 0.31\. Since
    our expected values only range in size from –1 to +1, an error of 0.31 means we
    are very far from accurately modeling the sine wave.
  prefs: []
  type: TYPE_NORMAL
- en: To get more insight into what is happening, we can plot our network’s predictions
    for the training data against the expected values.
  prefs: []
  type: TYPE_NORMAL
- en: 'This happens in the following cell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: By calling `model_1.predict(x_train)`, we run inference on all of the `x` values
    from the training data. The method returns an array of predictions. Let’s plot
    this on the graph alongside the actual `y` values from our training set. Run the
    cell to see the graph in [Figure 4-16](#training_predicted_actual).
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of predicted versus actual values for our training data](Images/timl_0416.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-16\. A graph of predicted versus actual values for our training data
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Oh, dear! The graph makes it clear that our network has learned to approximate
    the sine function in a very limited way. The predictions are highly linear, and
    only very roughly fit the data.
  prefs: []
  type: TYPE_NORMAL
- en: The rigidity of this fit suggests that the model does not have enough capacity
    to learn the full complexity of the sine wave function, so it’s able to approximate
    it only in an overly simplistic way. By making our model bigger, we should be
    able to improve its performance.
  prefs: []
  type: TYPE_NORMAL
- en: Improving Our Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Armed with the knowledge that our original model was too small to learn the
    complexity of our data, we can try to make it better. This is a normal part of
    the machine learning workflow: design a model, evaluate its performance, and make
    changes in the hope of seeing improvement.'
  prefs: []
  type: TYPE_NORMAL
- en: An easy way to make the network bigger is to add another layer of neurons. Each
    layer of neurons represents a transformation of the input that will hopefully
    get it closer to the expected output. The more layers of neurons a network has,
    the more complex these transformations can be.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following cell to redefine our model in the same way as earlier, but
    with an additional layer of 16 neurons in the middle:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the code is basically the same as for our first model, but
    with an additional `Dense` layer. Let’s run the cell to see the `summary()` results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: With two layers of 16 neurons, our new model is a lot larger. It has (1 * 16)
    + (16 * 16) + (16 * 1) = 288 weights, plus 16 + 16 + 1 = 33 biases, for a total
    of 288 + 33 = 321 parameters. Our original model had only 49 total parameters,
    so this is a 555% increase in model size. Hopefully, this extra capacity will
    help represent the complexity of our data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following cell will train our new model. Since our first model stopped
    improving so quickly, let’s train for fewer epochs this time—only 600\. Run this
    cell to begin training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'When training is complete, we can take a look at the final log to get a quick
    feel for whether things have improved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Wow! You can see that we’ve already achieved a huge improvement—validation loss
    has dropped from 0.17 to 0.01, and validation mean absolute error has dropped
    from 0.32 to 0.08\. This looks very promising.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see how things are going, let’s run the next cell. It’s set up to generate
    the same graphs we used last time. First, we draw a graph of the loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 4-17](#training_validation_loss_2) shows the result.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we draw the same loss graph but with the first 100 epochs skipped so
    that we can better see the detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '![A graph of training and validation loss](Images/timl_0417.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-17\. A graph of training and validation loss
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 4-18](#training_validation_loss_skip_2) presents the output.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we plot the mean absolute error for the same set of epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: '![A graph of training and validation loss, skipping the first 100 epochs](Images/timl_0418.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-18\. A graph of training and validation loss, skipping the first 100
    epochs
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 4-19](#training_validation_mae_2) depicts the graph.'
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of mean absolute error during training and validation](Images/timl_0419.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-19\. A graph of mean absolute error during training and validation
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Great results! From these graphs, we can see two exciting things:'
  prefs: []
  type: TYPE_NORMAL
- en: The metrics are broadly better for validation than training, which means the
    network is not overfitting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The overall loss and mean absolute error are much better than in our previous
    network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You might be wondering why the metrics for validation are better than those
    for training, and not merely identical. The reason is that validation metrics
    are calculated at the end of each epoch, meanwhile training metrics are calculated
    while the epoch of training is still in progress. This means validation happens
    on a model that has been trained for slightly longer.
  prefs: []
  type: TYPE_NORMAL
- en: Based on our validation data, our model seems to be performing great. However,
    to be sure of this, we need to run one final test.
  prefs: []
  type: TYPE_NORMAL
- en: Testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earlier, we set aside 20% of our data to use for testing. As we discussed, it’s
    very important to have separate validation and test data. Since we fine-tune our
    network based on its validation performance, there’s a risk that we might accidentally
    tune the model to overfit its validation set and that it might not be able to
    generalize to new data. By retaining some fresh data and using it for a final
    test of our model, we can make sure that this has not happened.
  prefs: []
  type: TYPE_NORMAL
- en: After we’ve used our test data, we need to resist the urge to tune our model
    further. If we did make changes with the goal of improving test performance, we
    might cause it to overfit our test set. If we did this, we wouldn’t be able to
    know, because we’d have no fresh data left to test with.
  prefs: []
  type: TYPE_NORMAL
- en: This means that if our model performs badly on our test data, it’s time to go
    back to the drawing board. We’ll need to stop optimizing the current model and
    come up with a brand new architecture.
  prefs: []
  type: TYPE_NORMAL
- en: 'With that in mind, the following cell will evaluate our model against our test
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: First, we call the model’s `evaluate()` method with the test data. This will
    calculate and print the loss and mean absolute error metrics, informing us as
    to how far the model’s predictions deviate from the actual values. Next, we make
    a set of predictions and plot them on a graph alongside the actual values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can run the cell to learn how our model is performing! First, let’s
    see the results of `evaluate()`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: This shows that 200 datapoints were evaluated, which is our entire test set.
    The model took 71 microseconds to make each prediction. The loss metric was 0.0103,
    which is excellent, and very close to our validation loss of 0.0104\. Our mean
    absolute error, 0.0718, is also very small and fairly close to its equivalent
    in validation, 0.0806.
  prefs: []
  type: TYPE_NORMAL
- en: This means that our model is working great, and it isn’t overfitting! If the
    model had overfit our validation data, we could expect that the metrics on our
    test set would be significantly worse than those resulting from validation.
  prefs: []
  type: TYPE_NORMAL
- en: The graph of our predictions against our actual values, shown in [Figure 4-20](#test_predicted_actual),
    makes it clear how well our model is performing.
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph of predicted versus actual values for our test data](Images/timl_0420.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-20\. A graph of predicted versus actual values for our test data
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can see that, for the most part, the dots representing *predicted* values
    form a smooth curve along the center of the distribution of *actual* values. Our
    network has learned to approximate a sine curve, even though the dataset was noisy!
  prefs: []
  type: TYPE_NORMAL
- en: 'If you look closely, however, you’ll see that there are some imperfections.
    The peak and trough of our predicted sine wave are not perfectly smooth, like
    a real sine wave would be. Variations in our training data, which is randomly
    distributed, have been learned by our model. This is a mild case of overfitting:
    instead of learning the smooth sine function, our model has learned to replicate
    the exact shape of our data.'
  prefs: []
  type: TYPE_NORMAL
- en: For our purposes, this overfitting isn’t a major problem. Our goal is for this
    model to gently fade an LED on and off, and it doesn’t need to be perfectly smooth
    to achieve this. If we thought the level of overfitting was problematic, we could
    attempt to address it through regularization techniques or by obtaining more training
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’re happy with our model, let’s get it ready to deploy on-device!
  prefs: []
  type: TYPE_NORMAL
- en: Converting the Model for TensorFlow Lite
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the beginning of this chapter we briefly touched on TensorFlow Lite, which
    is a set of tools for running TensorFlow models on “edge devices”—meaning everything
    from mobile phones down to microcontroller boards.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 13](ch13.xhtml#chapter_tensorflow_lite_for_microcontrollers) goes
    into detail on TensorFlow Lite for Microcontrollers. For now, we can think of
    it as having two main components:'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Lite Converter
  prefs: []
  type: TYPE_NORMAL
- en: This converts TensorFlow models into a special, space-efficient format for use
    on memory-constrained devices, and it can apply optimizations that further reduce
    the model size and make it run faster on small devices.
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow Lite Interpreter
  prefs: []
  type: TYPE_NORMAL
- en: This runs an appropriately converted TensorFlow Lite model using the most efficient
    operations for a given device.
  prefs: []
  type: TYPE_NORMAL
- en: Before we use our model with TensorFlow Lite, we need to convert it. We use
    the TensorFlow Lite Converter’s Python API to do this. It takes our Keras model
    and writes it to disk in the form of a *FlatBuffer*, which is a special file format
    designed to be space-efficient. Because we’re deploying to devices with limited
    memory, this will come in handy! We’ll look at FlatBuffers in more detail in [Chapter 12](ch12.xhtml#chapter_magic_wand_training).
  prefs: []
  type: TYPE_NORMAL
- en: In addition to creating a FlatBuffer, the TensorFlow Lite Converter can also
    apply optimizations to the model. These optimizations generally reduce the size
    of the model, the time it takes to run, or both. This can come at the cost of
    a reduction in accuracy, but the reduction is often small enough that it’s worthwhile.
    You can read more about optimizations in [Chapter 13](ch13.xhtml#chapter_tensorflow_lite_for_microcontrollers).
  prefs: []
  type: TYPE_NORMAL
- en: One of the most useful optimizations is *quantization*. By default, the weights
    and biases in a model are stored as 32-bit floating-point numbers so that high-precision
    calculations can occur during training. Quantization allows you to reduce the
    precision of these numbers so that they fit into 8-bit integers—a four times reduction
    in size. Even better, because it’s easier for a CPU to perform math with integers
    than with floats, a quantized model will run faster.
  prefs: []
  type: TYPE_NORMAL
- en: The coolest thing about quantization is that it often results in minimal loss
    in accuracy. This means that when deploying to low-memory devices, it is nearly
    always worthwhile.
  prefs: []
  type: TYPE_NORMAL
- en: In the following cell, we use the converter to create and save two new versions
    of our model. The first is converted to the TensorFlow Lite FlatBuffer format,
    but without any optimizations. The second is quantized.
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the cell to convert the model into these two variants:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: To create a quantized model that runs as efficiently as possible, we need to
    provide a *representative dataset*—a set of numbers that represent the full range
    of input values of the dataset on which the model was trained.
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding cell, we can use our test dataset’s `x` values as a representative
    dataset. We define a function, `representative_dataset_generator()`, that uses
    the `yield` operator to return them one by one.
  prefs: []
  type: TYPE_NORMAL
- en: To prove these models are still accurate after conversion and quantization,
    we use both of them to make predictions and compare these against our test results.
    Given that these are TensorFlow Lite models, we need to use the TensorFlow Lite
    interpreter to do so.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because it’s designed primarily for efficiency, the TensorFlow Lite interpreter
    is slightly more complicated to use than the Keras API. To make predictions with
    our Keras model, we could just call the `predict()` method, passing an array of
    inputs. With TensorFlow Lite, we need to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Instantiate an `Interpreter` object.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Call some methods that allocate memory for the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the input to the input tensor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Invoke the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read the output from the output tensor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This sounds like a lot, but don’t worry about it too much for now; we’ll walk
    through it in detail in [Chapter 5](ch05.xhtml#chapter_building_an_application).
    For now, run the following cell to make predictions with both models and plot
    them on a graph, alongside the results from our original, unconverted model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Running this cell yields the graph in [Figure 4-21](#test_predicted_actual_converted).
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph comparing models'' predictions against the actual values](Images/timl_0421.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-21\. A graph comparing models’ predictions against the actual values
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can see from the graph that the predictions for the original model, the converted
    model, and the quantized model are all close enough to be indistinguishable. Things
    are looking good!
  prefs: []
  type: TYPE_NORMAL
- en: 'Since quantization makes models smaller, let’s compare both converted models
    to see the difference in size. Run the following cell to calculate their sizes
    and compare them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'You should see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Our quantized model is 224 bytes smaller than the original version, which is
    great—but it’s only a minor reduction in size. At around 2.4 KB, this model is
    already so small that the weights and biases make up only a fraction of the overall
    size. In addition to weights, the model contains all the logic that makes up the
    architecture of our deep learning network, known as its *computation graph*. For
    truly tiny models, this can add up to more size than the model’s weights, meaning
    quantization has little effect.
  prefs: []
  type: TYPE_NORMAL
- en: More complex models have many more weights, meaning the space saving from quantization
    will be much higher. It can be expected to approach four times for most sophisticated
    models.
  prefs: []
  type: TYPE_NORMAL
- en: Regardless of its exact size, our quantized model will take less time to execute
    than the original version, which is important on a tiny microcontroller.
  prefs: []
  type: TYPE_NORMAL
- en: Converting to a C File
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final step in preparing our model for use with TensorFlow Lite for Microcontrollers
    is to convert it into a C source file that can be included in our application.
  prefs: []
  type: TYPE_NORMAL
- en: So far during this chapter, we’ve been using TensorFlow Lite’s Python API. This
    means that we’ve been able to use the `Interpreter` constructor to load our model
    files from disk.
  prefs: []
  type: TYPE_NORMAL
- en: However, most microcontrollers don’t have a filesystem, and even if they did,
    the extra code required to load a model from disk would be wasteful given our
    limited space. Instead, as an elegant solution, we provide the model in a C source
    file that can be included in our binary and loaded directly into memory.
  prefs: []
  type: TYPE_NORMAL
- en: In the file, the model is defined as an array of bytes. Fortunately, there’s
    a convenient Unix tool named `xxd` that is able to convert a given file into the
    required format.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following cell runs `xxd` on our quantized model, writes the output to
    a file called *sine_model_quantized.cc*, and prints it to the screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is very long, so we won’t reproduce it all here, but here’s a snippet
    that includes just the beginning and end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: To use this model in a project, you could either copy and paste the source or
    download the file from the notebook.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: And with that, we’re done building our model. We’ve trained, evaluated, and
    converted a TensorFlow deep learning network that can take a number between 0
    and 2π and output a good-enough approximation of its sine.
  prefs: []
  type: TYPE_NORMAL
- en: This was our first taste of using Keras to train a tiny model. In future projects,
    we’ll be training models that are still tiny, but *far* more sophisticated.
  prefs: []
  type: TYPE_NORMAL
- en: For now, let’s move on to [Chapter 5](ch05.xhtml#chapter_building_an_application),
    where we’ll write code to run our model on microcontrollers.
  prefs: []
  type: TYPE_NORMAL
