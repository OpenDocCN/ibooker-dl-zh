["```py\nimport torch\n\n# Scalar (0D tensor)\nscalar = torch.tensor(42)  # Single number\n\n# Vector (1D tensor)\nvector = torch.tensor([1, 2, 3, 4])  # Array of numbers\n\n# Matrix (2D tensor)\nmatrix = torch.tensor([[1, 2, 3],\n                      [4, 5, 6]])  # 2x3 grid of numbers\n\n# 3D tensor\ncube = torch.tensor([[[1, 2], [3, 4]],\n                    [[5, 6], [7, 8]]])  # 2x2x2 cube of numbers\n```", "```py\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\n\ndef prepare_image(image_path):\n    # Load the image using PIL\n    raw_image = Image.open(image_path)\n\n    # Define the transformations\n    preprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225]\n        )\n    ])\n\n    # Apply transformations\n    input_tensor = preprocess(raw_image)\n\n    # Add batch dimension\n    input_batch = input_tensor.unsqueeze(0)\n    return input_batch\n```", "```py\ntexts = [\n    \"I love my dog\",\n    \"The manatee became a doctor\"\n]\n```", "```py\nimport torch\nfrom transformers import BertTokenizer, BertModel\n\ndef text_to_embeddings(texts):\n    # Load pretrained BERT tokenizer and model\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    model = BertModel.from_pretrained('bert-base-uncased')\n    model.eval()  # Set to evaluation mode\n\n    # Tokenize the input texts\n    encoded = tokenizer(\n        texts,\n        padding=True,      # Pad shorter sequences to match longest\n        truncation=True,   # Truncate sequences that are too long\n        return_tensors='pt'  # Return PyTorch tensors\n    )\n\n```", "```py\nEncodings: \ntensor([[  101,  1045,  2293,  2026,  3899,   102,     0,     0],\n        [  101,  1996, 24951, 17389,  2150,  1037,  3460,   102]])\n```", "```py\n# Generate embeddings\nwith torch.no_grad():  # No need to calculate gradients\n    outputs = model(**encoded)\n    embeddings = outputs.last_hidden_state\n\n```", "```py\nFirst word embedding (first 5 values): \n        tensor([ 0.0401,  0.3046,  0.0669, –0.1975, –0.0103])\n```", "```py\n# ImageNet class labels (simplified - just a few examples)\nclass_names = [\n    'tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark',\n    'electric ray', 'stingray', 'rooster', 'hen', 'ostrich', 'brambling',\n    'goldfinch', 'house finch', 'junco', 'indigo bunting', 'robin', 'bulbul',\n    'jay', 'magpie', 'chickadee'\n]\n\n# Simulate model output for demonstration\n# This would normally come from model(input_tensor)\nexample_output = torch.tensor([\n    [ 1.2,  4.5, –0.8,  2.1,  0.3,  # First image predictions\n     –1.5,  0.9,  3.2, –0.4,  1.1,\n      0.5, –0.2,  1.8,  0.7, –1.0,\n      2.8,  1.6, –0.6,  0.4,  1.3],\n    [–0.5,  5.2,  0.3,  1.4, –0.8,  # Second image predictions\n      0.9,  1.2,  2.8,  0.6,  1.5,\n     –1.1,  0.4,  2.1,  0.2, –0.7,\n      1.9,  0.8, –0.3,  1.6,  0.5]\n])\n\n```", "```py\ndef interpret_output(output_tensor, top_k=5):\n    # Apply softmax to convert logits to probabilities\n    probabilities = torch.nn.functional.softmax(output_tensor, dim=1)\n\n    # Get top k probabilities and class indices\n    top_probs, top_indices = torch.topk(probabilities, k=top_k)\n\n    # Convert to numpy for easier handling\n    top_probs = top_probs.numpy()\n    top_indices = top_indices.numpy()\n\n    return top_probs, top_indices\n```", "```py\nImage 1 Predictions:\n------------------------\nRaw logits (first 5): [1.2000000476837158, 4.5, –0.800000011920929, \n                       2.0999999046325684, 0.30000001192092896]\n\nTop 5 Predictions:\n1. goldfish: 52.3%\n2. rooster: 14.2%\n3. robin: 9.5%\n4. tiger shark: 4.7%\n5. house finch: 3.5%\n```"]