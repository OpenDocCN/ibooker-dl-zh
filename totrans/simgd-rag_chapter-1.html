<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"><html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <title>chapter-1</title>
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css" />
 </head>
 <body>
  <div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">1</span> </span><span class="chapter-title-text">LLMs and the need for RAG </span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header"><span class="CharOverride-2">This chapter covers</span></h3> 
   <ul> 
    <li class="readable-text" id="p2"><span class="CharOverride-3">The limits of LLMs and the need for RAG</span></li> 
    <li class="readable-text" id="p3"><span class="CharOverride-3">The RAG basics</span></li> 
    <li class="readable-text" id="p4"><span class="CharOverride-3">Popular use cases of RAG</span></li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p5"> 
   <p>In a short time, large language models (LLMs) have found widespread application in modern language processing tasks and autonomous AI agents. OpenAI’s GPT, Anthropic’s Claude, Google’s Gemini, and Meta’s Llama series are notable LLMs integrated into various platforms and techniques. Retrieval-augmented generation, or RAG, plays a pivotal role in the LLM application by enhancing the accuracy and relevance of responses. According to Grand View Research (<a href="https://mng.bz/BzKg"><span class="Hyperlink">https:</span><span class="Hyperlink">/</span><span class="Hyperlink">/mng.bz/BzKg</span></a>), in 2023, the global RAG market was estimated at some $1 billion USD, and it has been projected to grow by 44.7% annually, which makes it one of the fastest-growing AI methodologies. </p> 
  </div> 
  <div class="readable-text intended-text" id="p6"> 
   <p>This book aims to demystify the idea of RAG and its application. Chapter by chapter, the book will present the RAG definition, design, implementation, evaluation, and evolution. To kick things off, this chapter begins by highlighting the limitations of LLMs and the need for an approach such as RAG. It then introduces the concept of RAG and builds toward a definition. The chapter ends by listing the popular use cases enabled by RAG.</p> 
  </div> 
  <div class="readable-text intended-text" id="p7"> 
   <p>By the end of this chapter, you will gain foundational knowledge to be ready for a deeper exploration of the RAG system components. In addition, you should</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p8">Have a strong hold on the RAG definition.</li> 
   <li class="readable-text" id="p9">Understand the limitations of LLMs and the need for RAG.</li> 
   <li class="readable-text" id="p10">Be ready to dive into the components of a RAG system.</li> 
  </ul> 
  <div class="readable-text" id="p11"> 
   <p>November 30, 2022, will be remembered as a watershed moment in the field of artificial intelligence. This was the day OpenAI released ChatGPT, and the world became mesmerized by it. ChatGPT turned out to be the fastest app ever to reach a million users. Interest in previously obscure terms such as generative AI and LLMs skyrocketed over the following 12 months (see figure 1.1). </p> 
  </div> 
  <div class="browsable-container figure-container " id="p12">  
   <img src="../Images/CH01_F01_Kimothi.png" alt="A graph with a line and orange dots

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 1.1</span><span class=""> </span><span class="">Google trends of “Generative AI” and “Large Language Models” from November 2022 to November 2024. Source: Created by the author using data from </span><a href="https://trends.google.com/trends/"><span class=""><span class="Hyperlink CharOverride-4">trends.google.com</span></span></a><span class="">. </span></h5>
  </div> 
  <div class="readable-text" id="p13"> 
   <p>As the use of platforms such as ChatGPT exploded, the weaknesses of LLMs were exposed. </p> 
  </div> 
  <div class="readable-text" id="p14"> 
   <h2 class=" readable-text-h2"><span class="num-string">1.1</span> Curse of the LLMs and the idea of RAG</h2> 
  </div> 
  <div class="readable-text" id="p15"> 
   <p>LLMs such as those powering ChatGPT, Ask Gemini, and similar have been shown to store knowledge. You can ask them questions, and they tend to respond with answers that seem correct. However, despite their unprecedented ability to generate text, their responses are not always accurate. Upon more careful observation, you may notice that LLM responses are plagued with suboptimal information and inherent memory limitations. </p> 
  </div> 
  <div class="readable-text intended-text" id="p16"> 
   <p>To understand the limitations, we will use a simple example. Those familiar with the wonderful sport of cricket will recall that the Men’s ODI Cricket World Cup tournament was held in 2023. The Australian cricket team emerged as the winner. Now, imagine you are interacting with ChatGPT, and you ask, <em>“</em>Who won the 2023 Cricket World Cup<em>?”</em> You are, in truth, interacting with GPT-4o, or o1, LLMs developed and maintained by OpenAI that power ChatGPT. In the first few sections of this chapter, we will use the terms ChatGPT and LLMs interchangeably for simplicity<em>. </em>So, you ask the question and, most likely, you will get a response as the one in figure 1.2.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p17">  
   <img src="../Images/CH01_F02_Kimothi.png" alt="A screenshot of a computer

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 1.2</span><span class=""> </span><span class="">ChatGPT (GPT 3.5) response to the question, “Who won the 2023 Cricket World Cup?” Source: Screenshot of the author’s account on </span><a href="https://chat.openai.com"><span class=""><span class="Hyperlink CharOverride-4">https:</span></span><span class=""><span class="Hyperlink CharOverride-4">/</span></span><span class=""><span class="Hyperlink CharOverride-4">/chat.openai.com</span></span></a><span class="">.</span></h5>
  </div> 
  <div class="readable-text" id="p18"> 
   <p>ChatGPT does not have any memory of the 2023 Cricket World Cup, and it tells you to check the information from other sources. This is not ideal, but at least ChatGPT is honest in its response. The same question asked again might also provide a factually inaccurate result. Look at the response in figure 1.3. ChatGPT falsely responds that India was the winner of the tournament.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p19">  
   <img src="../Images/CH01_F03_Kimothi.png" alt="A screenshot of a computer

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 1.3</span><span class=""> </span><span class="">An example of hallucination. ChatGPT’s (GPT 3.5) inaccurate response to the question, “Who won the 2023 cricket World Cup?” Source: Screenshot of the author’s account on </span><a href="https://chat.openai.com"><span class=""><span class="Hyperlink CharOverride-4">https:</span></span><span class=""><span class="Hyperlink CharOverride-4">/</span></span><span class=""><span class="Hyperlink CharOverride-4">/chat.openai.com</span></span></a><span class="">.</span></h5>
  </div> 
  <div class="readable-text" id="p20"> 
   <p>This is problematic. Despite not having any memory of the 2023 Cricket World Cup, ChatGPT still generates the answer in a seemingly confident tone, but it does so inaccurately. This is what is called a “hallucination,” and it has become a major point of criticism for LLMs.</p> 
  </div> 
  <div class="readable-text print-book-callout" id="p21"> 
   <p><span class="print-book-callout-head">NOTE</span> In September 2023, ChatGPT’s “Browse with Bing” feature was introduced, which allows ChatGPT Plus users to fetch live information from the web for more accurate and up-to-date responses. This is a feature of the application, which is enabled via agentic search and retrieval mechanisms. The underlying LLM doesn’t inherently have the latest information. </p> 
  </div> 
  <div class="readable-text" id="p22"> 
   <p>Many users treat LLMs as a source of information as an alternative to Google Search. In our example, we also expected ChatGPT (GPT 3.5 model) to know the answer to the simple question. Why does an LLM fail to meet this expectation?</p> 
  </div> 
  <div class="readable-text" id="p23"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.1.1</span> LLMs are not trained for facts</h3> 
  </div> 
  <div class="readable-text" id="p24"> 
   <p>Generally, LLMs can be thought of as a next-token (loosely, next word) prediction model. They are machine learning models that have learned from massive datasets of human-generated text, finding statistical patterns to replicate human-like language abilities. </p> 
  </div> 
  <div class="readable-text intended-text" id="p25"> 
   <p>To simplify, think of the model first being shown a sentence such as “The teacher teaches the student.” Then, we hide the last few words of this sentence (i.e., “teaches the student”) and ask the model what the next word should be. The model should learn to predict “teaches” as the next word, “the” as the word after that, and so on. There are various methods of teaching the model, including causal language modeling (CLM) and masked language modeling (MLM). Figure 1.4 shows the idea behind these two techniques.</p> 
  </div> 
  <div class="readable-text" id="p26"> 
   <p>The training data can have billions of sentences of different kinds. The next token (or word) is chosen from a probability distribution observed in the training data. There are different means and methods to choose the next token from the ones for which a probability has been calculated. Crudely, you can assume that a probability is calculated for all the words in the vocabulary, and one among the high-probability words is selected. Figure 1.5 shows the probability distribution for our example, “The teacher ____ .” The word “teaches” is selected because it has the highest probability. Other words could also have been selected.</p> 
  </div> 
  <div class="readable-text" id="p27"> 
   <p>In this case, the model is just trying to predict a word in sequence. It is almost magical how LLMs can store knowledge from the data they have been trained on and present that knowledge (in most cases) in a coherent and understandable language. This ability is possible thanks to a neural network architecture based on an attention mechanism known as “transformers.” The nuances of transformers’ architecture and building LLMs from scratch offer a wide area of study. It is out of the scope of this book, but you’re encouraged to find out more about LLM training and transformers.</p> 
  </div> 
  <div class="readable-text intended-text" id="p28"> 
   <p>Returning to the limitations of LLMs, their training process introduces three major characteristic drawbacks.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p29">  
   <img src="../Images/CH01_F04_Kimothi.png" alt="" style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 1.4</span><span class=""> </span><span class="">Two token prediction techniques: CLM and MLM. In the CLM approach, the model predicts the next token based on the preceding tokens. In MLM, the model predicts the masked token based on both the preceding and the succeeding tokens.</span></h5>
  </div> 
  <div class="browsable-container figure-container " id="p30">  
   <img src="../Images/CH01_F05_Kimothi.png" alt="" style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 1.5</span><span class=""> </span><span class="">Illustrative probability distribution of words after “The teacher” </span></h5>
  </div> 
  <div class="readable-text" id="p31"> 
   <h4 class=" readable-text-h4">Knowledge cut-off date</h4> 
  </div> 
  <div class="readable-text" id="p32"> 
   <p>Training an LLM is an expensive and time-consuming process. It takes massive volumes of data and several weeks, or even months, to train an LLM. The data that LLMs are trained on is, therefore, not always up to date. For instance, OpenAI’s flagship model, GPT-4.1, released in April 2025, has knowledge only until June 1, 2024. Any event that happened after this knowledge cut-off date is not available to the model.</p> 
  </div> 
  <div class="readable-text" id="p33"> 
   <h4 class=" readable-text-h4">Hallucinations</h4> 
  </div> 
  <div class="readable-text" id="p34"> 
   <p>It is observed that LLMs sometimes provide factually incorrect responses. (We saw this in the 2023 Cricket World Cup example at the beginning of this chapter.) Despite being factually incorrect, the LLM responses sound extremely confident and legitimate. This characteristic of “lying with confidence,” called hallucinations, has proved to be one of the biggest criticisms of LLMs. The reason for hallucinations can be traced back to LLMs being a next-token prediction model that selects the most probable word from a distribution. </p> 
  </div> 
  <div class="readable-text" id="p35"> 
   <h4 class=" readable-text-h4">Knowledge limitation</h4> 
  </div> 
  <div class="readable-text" id="p36"> 
   <p>As you have already seen, LLMs have been trained on large volumes of data obtained from a variety of sources, including the open internet. However, they do not have any knowledge of information that is not public. The LLMs have not been trained on information such as internal company documents, customer information, product documents, confidential personnel information, and so forth. Therefore, LLMs cannot be expected to respond to any query about them. </p> 
  </div> 
  <div class="readable-text intended-text" id="p37"> 
   <p>This characteristic raises significant questions about the general adoption and value of this technology. But if these limitations are inherent to the nature of LLMs and their training process, does this mean the LLM is not usable as a technology? </p> 
  </div> 
  <div class="readable-text intended-text" id="p38"> 
   <p>Not at all! Let’s now go ahead and understand how an approach such as RAG comes to the rescue.</p> 
  </div> 
  <div class="readable-text" id="p39"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.1.2</span> What is RAG?</h3> 
  </div> 
  <div class="readable-text" id="p40"> 
   <p>Recall the question we used to begin this discussion: “Who won the 2023 Cricket World Cup?” What can be done to improve the response? </p> 
  </div> 
  <div class="readable-text intended-text" id="p41"> 
   <p>Even if ChatGPT doesn’t have this information, the world (aka the internet) knows about the 2023 Cricket World Cup with no uncertainty. A simple Google Search will tell you about the winner of the 2023 Cricket World Cup if you don’t already know it. The Wikipedia article (figure 1.6) on the 2023 Cricket World Cup accurately provides this information in the opening section itself. If only there were a way to tell the LLM about this Wikipedia article. </p> 
  </div> 
  <div class="readable-text" id="p42"> 
   <p>How can we give this information to ChatGPT, you ask? The answer is quite simple. We just paste this piece of text with our question (see figure 1.7). </p> 
  </div> 
  <div class="readable-text" id="p43"> 
   <p>And there it is! ChatGPT has now responded with the correct answer. It was able to comprehend the piece of additional information we provided, distill the information about the winner of the tournament, and respond with a precise and factually accurate answer.</p> 
  </div> 
  <div class="readable-text intended-text" id="p44"> 
   <p>It may appear juvenile, but in an oversimplified manner, this example illustrates the basic concept of RAG. Let’s look back at what we did here. We understood that the question is about the winner of the 2023 Cricket World Cup. We searched for information about the question and identified Wikipedia as a source of information. We then copied that information and passed it onto ChatGPT (and the LLM powering it) along with the original question. In a way, we added to ChatGPT’s knowledge. As a technique, </p> 
  </div> 
  <div class="browsable-container figure-container " id="p45">  
   <img src="../Images/CH01_F06_Kimothi.png" alt="A screenshot of a web page

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 1.6</span><span class=""> </span><span class="">Wikipedia article on 2023 Cricket World Cup. Source: </span><a href="https://mng.bz/yN4J"><span class=""><span class="Hyperlink CharOverride-4">https:</span></span><span class=""><span class="Hyperlink CharOverride-4">/</span></span><span class=""><span class="Hyperlink CharOverride-4">/mng.bz/yN4J</span></span></a><span class="">.</span></h5>
  </div> 
  <div class="browsable-container figure-container " id="p46">  
   <img src="../Images/CH01_F07_Kimothi.png" alt="A screenshot of a chat

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 1.7</span><span class=""> </span><span class="">ChatGPT (GPT 3.5) response to the question, augmented with external context. Source: Screenshot of the author’s account on </span><a href="https://chat.openai.com"><span class=""><span class="Hyperlink CharOverride-4">https:</span></span><span class=""><span class="Hyperlink CharOverride-4">/</span></span><span class=""><span class="Hyperlink CharOverride-4">/chat.openai.com</span></span></a><span class="">.</span></h5>
  </div> 
  <div class="readable-text" id="p47"> 
   <p>RAG does the same thing programmatically. It overcomes the limitations of LLMs by providing them with previously unknown information and, consequently, enhances the overall memory of the system. </p> 
  </div> 
  <div class="readable-text intended-text" id="p48"> 
   <p>As the name implies, “retrieval augmented generation” can be explained through three steps:</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p49">It <em>retrieves</em> relevant information from a data source external to the LLMs (Wikipedia, in our example).</li> 
   <li class="readable-text" id="p50">It<em> augments</em> the input to the LLM with that external information.</li> 
   <li class="readable-text" id="p51">Finally, the LLM <em>generates</em><strong> </strong>a more accurate result. </li> 
  </ol> 
  <div class="readable-text" id="p52"> 
   <p>A simple definition for RAG, illustrated in figure 1.8, can therefore be as follows:</p> 
  </div> 
  <div class="readable-text" id="p53"> 
   <blockquote>
    <div>
     Retrieval Augmented Generation is the technique of retrieving relevant information from an external source, augmenting the input to the LLM with that external information, thereby enabling the LLM to generate a response that is contextual, reliable, and factually accurate.
    </div>
   </blockquote> 
  </div> 
  <div class="browsable-container figure-container " id="p54">  
   <img src="../Images/CH01_F08_Kimothi.png" alt="A diagram of a data flow

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 1.8</span><span class=""> </span><span class="">RAG (a simple definition): retrieval of information, augmentation with the query, and the generation using an LLM form the three RAG focal points </span></h5>
  </div> 
  <div class="readable-text" id="p55"> 
   <p>The example that we have been looking at so far is oversimplified. We manually searched for the external information, and the search was for this one specific question only. In practice, all these processes are automated, which allows the system to scale up to a diverse range of queries and data sources. We will now unravel this idea further.</p> 
  </div> 
  <div class="readable-text" id="p56"> 
   <h2 class=" readable-text-h2"><span class="num-string">1.2</span> The novelty of RAG</h2> 
  </div> 
  <div class="readable-text" id="p57"> 
   <p>The main idea is to provide additional context or knowledge to the LLMs. Essentially, it meant creating a ChatGPT-like system with three main objectives:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p58">Make LLMs respond with up-to-date information.</li> 
   <li class="readable-text" id="p59">Make LLMs respond with factually accurate information.</li> 
   <li class="readable-text" id="p60">Make LLMs aware of proprietary information.</li> 
  </ul> 
  <div class="readable-text" id="p61"> 
   <p>These objectives can be achieved using diverse techniques. A new LLM can be trained from scratch that includes the new data. An existing model can also be fine-tuned with additional data. However, both approaches require a significant amount of data and computational resources. Furthermore, updating the model with new information at regular intervals is prohibitively costly. </p> 
  </div> 
  <div class="readable-text intended-text" id="p62"> 
   <p>RAG is a cheaper, more effective, and more dynamic technique used to attain the three objectives. LLMs respond with information that is up-to-date and factually accurate, and they are aware of proprietary information, so they have no knowledge gaps.</p> 
  </div> 
  <div class="readable-text" id="p63"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.2.1</span> The RAG discovery</h3> 
  </div> 
  <div class="readable-text" id="p64"> 
   <p>In a paper titled “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks” (<a href="https://arxiv.org/abs/2005.11401"><span class="Hyperlink">https:</span><span class="Hyperlink">/</span><span class="Hyperlink">/arxiv.org/abs/2005.11401</span></a>), Patrick Lewis and his coauthors explored the recipe for RAG models, which combine pretrained “parametric” and “non-parametric” memory for language generation. Let’s pay some attention to the terms “parametric” and “non-parametric.” </p> 
  </div> 
  <div class="readable-text intended-text" id="p65"> 
   <p>Parameters in machine learning parlance refer to the model weights or variables that the model learns during the training process. In simple terms, they are settings or configurations that the model adjusts to perform the assigned task. For language generation, LLMs are trained with billions of parameters (the GPT 4 model is rumored to have over 1 trillion parameters, and the largest Llama 3 model has 405 billion parameters). The ability of an LLM to retain information it has been trained on is based solely on its parameters. It can therefore be said that LLMs store factual information in their parameters. An LLM’s internal memory is referred to as “parametric memory.” The parametric memory is limited. It depends on the number of parameters and is a factor of the data on which the LLM has been trained.</p> 
  </div> 
  <div class="readable-text intended-text" id="p66"> 
   <p>Conversely, we can provide information to an LLM that it does not have in its parametric memory. We saw in the example of the Cricket World Cup that when we provided information from an external source to ChatGPT, it was able to get rid of the hallucination. This information that is external to the LLM but can be provided to the LLM is termed “non-parametric.” If we can gather information from external sources as and when desired and use it with the LLM, it forms the “non-parametric” memory of the system. In the aforementioned paper, Lewis and his coauthors stored Wikipedia data and used a retriever to access the information. They demonstrated that this RAG approach outperformed the parametric-only baseline in generating more specific, diverse, and factual language. We will discuss vector databases and retrievers in chapters 3 and 4.</p> 
  </div> 
  <div class="readable-text intended-text" id="p67"> 
   <p>In 2025, RAG became one of the most used techniques in the LLM domain. With the addition of a non-parametric memory, the LLM responses are more grounded and factual. Let’s discuss the advantages of RAG.</p> 
  </div> 
  <div class="readable-text" id="p68"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.2.2</span> How does RAG help?</h3> 
  </div> 
  <div class="readable-text" id="p69"> 
   <p>With the introduction of non-parametric memory, the LLM does not remain limited to its internal knowledge. We can conclude, at least theoretically, that this non-parametric memory can be extended as much as we want. It can store any volume of proprietary documents or data and access all sorts of sources, such as the intranet and the open internet. In a way, through RAG, we open up the possibility of embellishing the LLM with unlimited knowledge. There will always be some effort required to create this non-parametric memory or the knowledge base, and we will look at it in detail later. Chapter 3 is dedicated to the creation of the non-parametric knowledge base.</p> 
  </div> 
  <div class="readable-text intended-text" id="p70"> 
   <p>As a consequence of overcoming the challenge of limited parametric memory, RAG also builds user confidence in the LLM responses. The three advantages of RAG are as follows: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p71"><em>Deep contextual awarenes</em><em>s</em>—The added information assists the LLM in generating contextually appropriate responses, and the users can be relatively more confident. For example, if the non-parametric memory contains information about a particular company’s products, users can be assured that the LLM will generate responses about those products from the provided sources and not from elsewhere.</li> 
   <li class="readable-text" id="p72"><em>Source citatio</em><em>n</em>—In addition to being context aware, because the information is being fetched from a known source, these sources can be cited in the response. This makes the responses more reliable since the users have the choice of validating the information from the source.</li> 
   <li class="readable-text" id="p73"><em>Lesser hallucinatio</em><em>n</em>—With contextual awareness, the tendency of LLM responses to be factually inaccurate is greatly reduced. The LLMs hallucinate less in RAG systems. </li> 
  </ul> 
  <div class="readable-text" id="p74"> 
   <p>We have already seen a simple RAG definition. Let’s now expand that definition:</p> 
  </div> 
  <div class="readable-text" id="p75"> 
   <blockquote>
    <div>
     Retrieval Augmented Generation is the methodological approach of enhancing the parametric memory of an LLM by creating access to an explicit non-parametric memory, from which a retriever can fetch relevant information, augment that information to the prompt, pass the prompt to an LLM to enable the LLM to generate a response that is contextual, reliable, and factually accurate.
    </div>
   </blockquote> 
  </div> 
  <div class="readable-text" id="p76"> 
   <p>This definition is illustrated in figure 1.9.</p> 
  </div> 
  <div class="readable-text" id="p77"> 
   <p>RAG has acted as a catalyst in the propagation and acceptance of LLM-powered applications. Before concluding this chapter and getting into the design of RAG systems, let’s look at some popular use cases where RAG is being adopted.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p78">  
   <img src="../Images/CH01_F09_Kimothi.png" alt="A diagram of a computer process

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 1.9</span><span class=""> </span><span class="">RAG enhances the parametric memory of an LLM by creating access to non-parametric memory.</span></h5>
  </div> 
  <div class="readable-text" id="p79"> 
   <h2 class=" readable-text-h2"><span class="num-string">1.3</span> Popular RAG use cases</h2> 
  </div> 
  <div class="readable-text" id="p80"> 
   <p>RAG is not just a theoretical concept but a technique that is as popular as the LLM technology itself. Software developers started using language models as soon as Google released BERT in 2018. Today, there are thousands of applications that use LLMs to solve language-intensive tasks. Whenever you come across an application using LLMs, it will often have an internal RAG system in some shape or form. Common applications are described in the following sections.</p> 
  </div> 
  <div class="readable-text" id="p81"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.3.1</span> Search Engine Experience</h3> 
  </div> 
  <div class="readable-text" id="p82"> 
   <p>Conventional search results are shown as a list of page links ordered by relevance. Modern search engines integrate RAG to combine live information retrieval with generative answers. Google’s Search Generative Experience (SGE) augments queries with relevant results and citations. AI-based search engines such as Perplexity.ai and ChatGPT’s search are built on a RAG framework that fetches up-to-date web information and then generates responses with sources attached. By grounding answers in real-time results, these search engines provide more accurate, source-backed answers than standalone LLMs.</p> 
  </div> 
  <div class="readable-text" id="p83"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.3.2</span> Personalized marketing content generation</h3> 
  </div> 
  <div class="readable-text" id="p84"> 
   <p>The widest use of LLMs has probably been in content generation. Content creation tools employ RAG to tailor marketing copy using current data and user-specific context. Yarnit, for instance, uses RAG to generate marketing copy, blog posts, and other content types based on up-to-the-moment information and user inputs. Yarnit can pull in fresh facts or trending material while drafting the text, ensuring the output is relevant and factual. By pulling in the right information (e.g., a brand’s style guide or latest stats) at generation time, these platforms produce personalized, on-brand marketing content that resonates with audiences.</p> 
  </div> 
  <div class="readable-text" id="p85"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.3.3</span> Real-time event commentary</h3> 
  </div> 
  <div class="readable-text" id="p86"> 
   <p>Imagine an event such as a sport or a news event. A retriever can connect to real-time updates/data via APIs and pass this information to the LLM to create a virtual commentator. These can further be augmented with text-to-speech models. A prime example is IBM’s Watson AI at the US Open—it generates audio and text tennis commentary by pulling in live match data and even thousands of news articles for context. This RAG approach allowed Watson to mention player stats, head-to-head records, and match highlights as it narrated, creating fact-driven commentary on the fly. In financial markets, vendors are doing something similar—Bloomberg’s AI-driven tools use RAG to ground their insights in up-to-date proprietary data. Bloomberg’s platforms explicitly employ a RAG framework so that any generative output (market summaries, answers to trader queries, etc.) is based on recent, authoritative content rather than the model’s memory alone.</p> 
  </div> 
  <div class="readable-text" id="p87"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.3.4</span> Conversational agents</h3> 
  </div> 
  <div class="readable-text" id="p88"> 
   <p>LLMs can be customized to product/service manuals, domain knowledge, guidelines, and so forth using RAG and serve as support agents, resolving user complaints and problems. These agents can also route users to more specialized agents, depending on the nature of the query. Almost all LLM-based chatbots on websites or as internal tools use RAG. Intercom’s Fin AI agent is a notable example—it was specifically designed with a “bespoke and enhanced” RAG architecture to generate answers from a company’s support content. Support platforms such as Zendesk follow a similar pattern by retrieving help-center articles to answer customer queries. Industry observers note that these companies use basic RAG to quickly fetch relevant support docs and generate customized responses from them.</p> 
  </div> 
  <div class="readable-text" id="p89"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.3.5</span> Document question answering systems</h3> 
  </div> 
  <div class="readable-text" id="p90"> 
   <p>As discussed, one of the LLMs’ limitations is that they don’t have access to proprietary nonpublic information such as product documents, customer profiles, and similar information specific to an organization. With access to such proprietary documents, a RAG system becomes an intelligent AI system that can answer all questions about the organization. In the legal domain, for example, researchers have highlighted that domain-specific RAG enables far more nuanced and trustworthy answers in tools for legal research. A legal Q&amp;A system can retrieve relevant case law or statutes and feed those into an LLM to answer a question, ensuring the answer cites the correct precedent. This technique was at the heart of products such as ROSS Intelligence, which aimed to answer lawyers’ queries by retrieving passages from law databases and then generating an answer. More generally, enterprise knowledge management is being transformed by RAG—instead of relying on an LLM’s limited training data, companies can equip AI assistants to search internal documents, wikis, or manuals on the fly.</p> 
  </div> 
  <div class="readable-text" id="p91"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.3.6</span> Virtual assistants</h3> 
  </div> 
  <div class="readable-text" id="p92"> 
   <p>Virtual personal assistants such as Siri, Alexa, and others are beginning to use LLMs to enhance the user’s experience. Coupled with more context on user behavior using RAG, these assistants are set to become more personalized. Amazon’s next-generation Alexa, for instance, incorporates retrieval techniques, so it can answer with information beyond its core training. By augmenting voice assistant answers with retrieved facts, RAG helps virtual assistants such as Alexa and Google Assistant give far more accurate and current answers to user queries.</p> 
  </div> 
  <div class="readable-text" id="p93"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.3.7</span> AI-powered research</h3> 
  </div> 
  <div class="readable-text" id="p94"> 
   <p>AI agents have been gaining traction in research-intensive fields such as law and finance. RAG has been extensively used to retrieve and analyze case law to assist lawyers. A lot of portfolio management companies are introducing RAG systems to analyze scores of documents to research investment opportunities. ESGReveal is a framework developed by researchers at Alibaba Group that employs RAG to extract and evaluate environmental, social, and governance (ESG) data from corporate reports. </p> 
  </div> 
  <div class="readable-text" id="p95"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.3.8</span> Social media monitoring and sentiment analysis</h3> 
  </div> 
  <div class="readable-text" id="p96"> 
   <p>Analyzing the firehose of social media data is another task suited to RAG. Social listening platforms such as Brandwatch use generative AI to summarize trends and sentiments from millions of posts, but they ground those summaries in the underlying data. Brandwatch’s system, for example, scans over 100 million sources, and then its generative AI integration transforms data into easy-to-understand summaries for the user.</p> 
  </div> 
  <div class="readable-text" id="p97"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.3.9</span> News generation and content curation</h3> 
  </div> 
  <div class="readable-text" id="p98"> 
   <p>News organizations have been using RAG to automate and assist in news writing, while maintaining accuracy. Reuters, for instance, offers a solution to feed its trusted news data into generative models so they produce fact-based outputs. By using Reuters’ real-time news feeds as the retrieval source, an AI system can generate a news summary or answer questions with the latest verified facts. Reuters asserts that this approach keeps your answers reliable and accurate with a RAG system extracting trusted facts from the latest Reuters stories. The Associated Press (AP) has similarly been a pioneer in automating news: AP has used templates and data to auto-generate sports recaps and earnings reports for years, and now, with generative AI, they are augmenting those systems with LLMs. Thanks to RAG, an AI writer can ingest box score data or financial results and then produce a readable article, grounding every statement in the provided data.</p> 
  </div> 
  <div class="readable-text intended-text" id="p99"> 
   <p>These are only a few select examples. RAG has been extensively used in other domains such as customer support automation, financial market insights, healthcare diagnostics, legal document drafting, learning systems, and supply chain optimization.</p> 
  </div> 
  <div class="readable-text intended-text" id="p100"> 
   <p>This introductory chapter dealt with the RAG concept. Overcoming the limitations of LLMs, RAG addresses these challenges by providing access to a non-parametric knowledge base to the system. With this foundational understanding of RAG, in the next chapter, we take the first step toward understanding how RAG systems are built by looking at the different components of their design.</p> 
  </div> 
  <div class="readable-text" id="p101"> 
   <h2 class=" readable-text-h2">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p102">RAG enhances the memory of LLMs by providing access to external information.</li> 
   <li class="readable-text" id="p103">LLMs are next-word (or token) prediction models trained on massive amounts of text data to generate human-like text.</li> 
   <li class="readable-text" id="p104">LLMs face challenges of having a knowledge cut-off date and being trained only on public data. They are also prone to generating factually incorrect information (i.e., hallucinating).</li> 
   <li class="readable-text" id="p105">RAG overcomes the LLM limitations by incorporating non-parametric memory and increases context awareness and reliability of responses.</li> 
   <li class="readable-text" id="p106">Popular use cases of RAG include search engines, document question-answering systems, conversational agents, personalized content generation, virtual assistants, and so forth.</li> 
  </ul>
 </body>
</html>