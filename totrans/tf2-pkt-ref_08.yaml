- en: Chapter 8\. Distributed Training
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Training a machine learning model may take a long time, especially if your training
    dataset is huge or you are using a single machine to do the training. Even if
    you have a GPU card at your disposal, it can still take weeks to train a complex
    model such as ResNet50, a computer vision model with 50 convolution layers, trained
    to classify objects into a thousand categories.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'Reducing model training time requires a different approach. You already saw
    some of the options available: in [Chapter 5](ch05.xhtml#data_pipelines_for_streaming_ingestion),
    for example, you learned to leverage datasets in a data pipeline. Then there are
    more powerful accelerators, such as GPUs and TPUs (which are exclusively available
    in Google Cloud).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover a different way to train your model, known as *distributed
    training*. Distributed training runs a model training process in parallel on a
    cluster of devices, such as CPUs, GPUs, and TPUs, to speed up the training process.
    (In this chapter, for the sake of concision, I will refer to hardware accelerators
    such as GPUs, CPUs, and TPUs as *workers* or *devices*.) After you read this chapter,
    you will know how to refactor your single-node training routine for distributed
    training. (Every example you have seen in this book up to this point has been
    single node: that is, they have all used a machine with one CPU to train the model.)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: In distributed training, your model is trained by multiple independent processes.
    You can think of each process as an independent training endeavor. Each process
    runs the training routine on a separate device, using a subset (called a *shard*)
    of the training data. This means that each process uses different training data.
    As each process completes an epoch of training, it sends the results back to a
    *master routine*, which collects and aggregates the results and then issues updates
    to all of the processes. Each process then resumes training with the updated weights
    and biases.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Before we dive into the implementation code, let’s take a closer look at the
    heart of distributed ML model training. We will start with the concept of data
    parallelism.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Data Parallelism
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first thing you need to understand about distributed training is how training
    data is handled. The predominant architecture in distributed training is known
    as *data parallelism*. In this architecture, you run the same model and computation
    logic on each worker. Each worker computes the loss and gradients using a shard
    of data that is different from those of the other workers, then uses these gradients
    to update the model parameters. The updated model in each individual worker is
    then used in the next round of computation. This concept is illustrated in [Figure 8-1](#data_parallelism_architecture_left_paren).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: 'Two common approaches are designed to update the model with these gradients:
    asynchronous parameter servers and synchronous allreduce. We’ll look at each in
    turn.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![Data parallelism architecture (adapted from Distributed TensorFlow training
    in Google I/O 2018 video)](Images/t2pr_0801.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
- en: Figure 8-1\. Data parallelism architecture (Adapted from [Distributed TensorFlow
    training](https://oreil.ly/beSob) in Google I/O 2018 video)
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Asynchronous Parameter Server
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s look first at the *asynchronous parameter server* approach, shown in [Figure 8-2](#distributed_training_using_asynchronous).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: '![Distributed training using asynchronous parameter servers (adapted from Distributed
    TensorFlow training in Google I/O 2018 video)](Images/t2pr_0802.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
- en: Figure 8-2\. Distributed training using asynchronous parameter servers. (Adapted
    from [Distributed TensorFlow training](https://oreil.ly/beSob) in Google I/O 2018
    video)
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The devices labeled PS0 and PS1 in [Figure 8-2](#distributed_training_using_asynchronous)
    are *parameter servers*; these servers hold the parameters of your model. Other
    devices are designated as workers, as labeled in [Figure 8-2](#distributed_training_using_asynchronous).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图8-2](#distributed_training_using_asynchronous)中标记为PS0和PS1的设备是*参数服务器*；这些服务器保存模型的参数。其他设备被指定为工人，如[图8-2](#distributed_training_using_asynchronous)中标记的那样。
- en: The workers do the bulk of the computation. Each worker fetches the parameters
    from the server, computes loss and gradients, and then sends the gradients back
    to the parameter server, which uses them to update the model’s parameters. Each
    worker does this independently, so this approach can be scaled up to use a large
    number of workers. The advantage here is that if training workers are preempted
    by high-priority production jobs, if there is asymmetry between the workers, or
    if a machine goes down for maintenance, it doesn’t hurt your scaling, because
    the workers are not waiting on each other.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 工人们承担了大部分计算工作。每个工人从服务器获取参数，计算损失和梯度，然后将梯度发送回参数服务器，参数服务器使用这些梯度来更新模型的参数。每个工人都独立完成这个过程，因此这种方法可以扩展到使用大量工人。这里的优势在于，如果训练工人被高优先级的生产工作抢占，如果工人之间存在不对称，或者如果一台机器因维护而宕机，都不会影响你的扩展，因为工人们不需要等待彼此。
- en: 'However, there is a downside: the workers can get out of sync. This can lead
    to computing gradients on stale parameter values, which can delay model convergence
    and therefore delay training toward the best model. With the recent popularity
    and prevalence of hardware accelerators, this approach is implemented less frequently
    than synchronous allreduce, which we’ll discuss next.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，存在一个缺点：工人可能会失去同步。这可能导致在过时的参数值上计算梯度，从而延迟模型收敛，因此延迟朝着最佳模型的训练。随着硬件加速器的普及和流行，这种方法比同步全局归约实现得更少，接下来我们将讨论同步全局归约。
- en: Synchronous Allreduce
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 同步全局归约
- en: The *synchronous allreduce* approach has become more common as fast hardware
    accelerators such as GPUs and TPUs have become more widely available.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 随着GPU和TPU等快速硬件加速器变得更加普遍，*同步全局归约*方法变得更加常见。
- en: In a synchronous allreduce architecture (shown in [Figure 8-3](#distributed_training_using_a_synchronous)),
    each worker holds a copy of the model’s parameters in its own memory. There are
    no parameter servers. Instead, each worker computes the loss and gradients based
    on a shard of training samples. Once that computation is complete, the workers
    communicate among themselves to propagate the gradients and update the model parameters.
    All workers are synchronized, which means the next round of computation begins
    *only* when each worker has received the new gradients and updated the model parameters
    in its memory accordingly.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在同步全局归约架构中（如[图8-3](#distributed_training_using_a_synchronous)所示），每个工人在自己的内存中保存模型的参数副本。没有参数服务器。相反，每个工人根据一部分训练样本计算损失和梯度。一旦计算完成，工人们相互通信以传播梯度并更新模型参数。所有工人都是同步的，这意味着下一轮计算仅在每个工人接收到新梯度并相应地更新模型参数后才开始。
- en: '![Distributed training using a synchronous allreduce architecture (Adapted
    from Distributed TensorFlow training in Google I/O 2018 video)](Images/t2pr_0803.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![使用同步全局归约架构进行分布式训练（改编自Google I/O 2018视频中的分布式TensorFlow培训）](Images/t2pr_0803.png)'
- en: Figure 8-3\. Distributed training using a synchronous allreduce architecture
    (adapted from [Distributed TensorFlow training](https://oreil.ly/beSob) in Google
    I/O 2018 video)
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-3. 使用同步全局归约架构的分布式训练（改编自[分布式TensorFlow培训](https://oreil.ly/beSob)在Google I/O
    2018视频中）
- en: With these fast devices in a connected cluster, differences in processing time
    between workers are not an issue. As a result, this approach usually leads to
    a faster convergence on the best model than the asynchronous parameter server
    architecture.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个连接的集群中，工人之间的处理时间差异不是问题。因此，这种方法通常比异步参数服务器架构更快地收敛到最佳模型。
- en: '*Allreduce* is a type of algorithm that combines gradients across different
    workers. This algorithm aggregates gradient values from different workers by,
    for example, summing them and then copying them to different workers. Its implementation
    can be very efficient as it reduces the overhead involved in synchronizing the
    gradients. Many allreduce algorithm implementations are available, depending on
    the types of communication available between workers and on the architecture’s
    topology. A common implementation of this algorithm, known as *ring-allreduce*,
    is shown in [Figure 8-4](#ring-allreduce_implementation_left_paren).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*全局归约*是一种算法，它将不同工人的梯度合并在一起。这种算法通过汇总不同工人的梯度值，例如将它们求和，然后将它们复制到不同的工人中。它的实现可以非常高效，因为它减少了同步梯度所涉及的开销。根据工人之间可用的通信类型和架构的拓扑结构，有许多全局归约算法的实现。这种算法的常见实现被称为*环形全局归约*，如[图8-4](#ring-allreduce_implementation_left_paren)所示。'
- en: In a ring-allreduce implementation, each worker sends its gradient to its successor
    on the ring and receives a gradient from its predecessor. Eventually, each worker
    receives a copy of the combined gradients. Ring-allreduce uses network bandwidth
    optimally, because it uses both the upload and download bandwidth of each worker.
    It’s fast whether working with multiple workers on a single machine or a small
    number of machines.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在环形全局归约实现中，每个工人将其梯度发送给环上的后继者，并从前任者接收梯度。最终，每个工人都会收到合并梯度的副本。环形全局归约能够最优地利用网络带宽，因为它同时使用每个工人的上传和下载带宽。无论是在单台机器上与多个工人一起工作，还是在少量机器上工作，都能快速完成。
- en: '![Ring-allreduce implementation (adapted from Distributed TensorFlow training
    in Google I/O 2018 video)](Images/t2pr_0804.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![环形全局归约实现（改编自Google I/O 2018视频中的分布式TensorFlow培训）](Images/t2pr_0804.png)'
- en: Figure 8-4\. Ring-allreduce implementation (Adapted from [Distributed TensorFlow
    training](https://oreil.ly/beSob) in Google I/O 2018 video)
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-4. 环形全局归约实现（改编自[分布式TensorFlow培训](https://oreil.ly/beSob)在Google I/O 2018视频中）
- en: Now let’s see how you can do all this in TensorFlow. We’re going to focus on
    scaling to multiple GPUs with a synchronous allreduce architecture. You’ll see
    how easy it is to refactor your single-node training code for allreduce. That’s
    because these high-level APIs handle a lot of the aforementioned complexity and
    nuances of data parallelism for you, behind the scenes.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何在TensorFlow中完成所有这些。我们将专注于使用同步allreduce架构扩展到多个GPU。您将看到将单节点训练代码重构为allreduce有多么容易。这是因为这些高级API在幕后处理了许多数据并行性的复杂性和细微差别。
- en: Using the Class tf.distribute.MirroredStrategy
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用`tf.distribute.MirroredStrategy`类
- en: The easiest way to implement distributed training is to use the `tf.distribute.MirroredStrategy`
    class provided by TensorFlow. (For the details of various distributed training
    strategies supported by TensorFlow, see [“Types of strategies” in the TensorFlow
    documentation](https://oreil.ly/0jQed)). As you will see, implementing this class
    requires only minimal changes in your source code, and you will still be able
    to run in single-node mode, so you don’t have to worry about backward compatibility.
    It also takes care of updating weights and biases, metrics, and model checkpoints
    for you. Further, you don’t have to worry about how to split training data into
    shards for each device. You don’t need to write code to handle retrieving or updating
    parameters from each device. Nor do you need to worry about how to ensure that
    gradients and losses across devices are aggregated correctly. The distribution
    strategy does all of that for you.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 实现分布式训练的最简单方法是使用TensorFlow提供的`tf.distribute.MirroredStrategy`类。（有关TensorFlow支持的各种分布式训练策略的详细信息，请参见[TensorFlow文档中的“策略类型”](https://oreil.ly/0jQed)）。正如您将看到的，实现此类仅需要在源代码中进行最小更改，您仍然可以在单节点模式下运行，因此您无需担心向后兼容性。它还负责为您更新权重和偏差、指标和模型检查点。此外，您无需担心如何将训练数据分割为每个设备的碎片。您无需编写代码来处理从每个设备检索或更新参数。您也无需担心如何确保跨设备聚合梯度和损失。分发策略会为您处理所有这些。
- en: 'We’ll look briefly at a few code snippets that demonstrate the changes you
    need to make in your training code for a case of one machine with multiple devices:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将简要查看一些代码片段，演示在一个机器上使用多个设备时需要对训练代码进行的更改：
- en: 'Create an object to handle distributed training. You can do this at the beginning
    of the source code:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个对象来处理分布式训练。您可以在源代码的开头执行此操作：
- en: '[PRE0]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `strategy` object contains a property that holds the number of devices
    available in the machine. You may use this command to show how many GPUs or TPUs
    are at your disposal:'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`strategy`对象包含一个属性，其中包含机器上可用设备的数量。您可以使用此命令显示您可以使用多少个GPU或TPU：'
- en: '[PRE1]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If you are using a GPU cluster, such as through Databricks or a cloud provider’s
    environment, you will see the number of GPUs to which you have access:'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果您正在使用GPU集群，例如通过Databricks或云提供商的环境，您将看到您可以访问的GPU数量：
- en: '[PRE2]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that Google Colab only provides one GPU for each user.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，Google Colab仅为每个用户提供一个GPU。
- en: 'Wrap your model definition and loss function in a `strategy` scope. You just
    need to make sure the model definition and compilation, including the loss function
    of your choice, are encapsulated in a specific scope:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的模型定义和损失函数包装在`strategy`范围内。您只需确保模型定义和编译，包括您选择的损失函数，封装在特定范围内：
- en: '[PRE3]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: These are the only two places you need to make code changes.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是您需要进行代码更改的唯一两个地方。
- en: The `tf.distribute.MirroredStrategy` class is the workhorse behind the curtain.
    As you have seen, the `strategy` object we created knows how many devices are
    available. This information enables it to split the training data into different
    shards and feed each shard into a particular device. Since the model architecture
    is wrapped in this object’s scope, it is also held in each device’s memory. This
    allows each device to run the training routine on the same model architecture,
    minimize the same loss function, and update the gradients according to its specific
    shard of training data. The model architecture and parameters are replicated,
    or *mirrored*, across all devices. The `MirroredStrategy` class also implements
    the ring-allreduce algorithm behind the scenes, so you don’t have to worry about
    aggregating all the gradients from each device.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.distribute.MirroredStrategy`类是幕后的工作马。正如您所见，我们创建的`strategy`对象知道有多少设备可用。这些信息使其能够将训练数据分成不同的碎片，并将每个碎片馈送到特定设备中。由于模型架构包装在此对象的范围内，因此它也保存在每个设备的内存中。这使得每个设备可以在相同的模型架构上运行训练例程，最小化相同的损失函数，并根据其特定的训练数据碎片更新梯度。模型架构和参数被复制，或*镜像*，在所有设备上。`MirroredStrategy`类还在幕后实现了环形allreduce算法，因此您无需担心从每个设备聚合所有梯度。'
- en: The class is aware of your hardware settings and their potential for distributed
    training, so there is no need for you to change your `model.fit` training routine
    or data ingestion method. Saving model checkpoints and model summaries works the
    same way as it does in single-node training, as we saw in [“ModelCheckpoint”](ch07.xhtml#modelcheckpoint).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 该类知道您的硬件设置及其潜力进行分布式训练，因此您无需更改`model.fit`训练例程或数据摄入方法。保存模型检查点和模型摘要的方式与单节点训练中相同，正如我们在[“ModelCheckpoint”](ch07.xhtml#modelcheckpoint)中看到的那样。
- en: Setting Up Distributed Training
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置分布式训练
- en: To try the distributed training examples in this chapter, you will need access
    to multiple GPUs or TPUs. For simplicity, consider using one of the various commercial
    platforms that offer GPU clusters, such as [Databricks](https://databricks.com)
    and [Paperspace](https://www.paperspace.com). Other choices include major cloud
    vendors, which offer a wide variety of platforms, from managed services to containers.
    For the sake of simplicity and ease of availability, the examples in this chapter
    are done in Databricks, a cloud-based compute vendor. It allows you to set up
    a distributed compute cluster of either GPUs or CPUs to run heavy workloads that
    a single-node machine cannot handle.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要尝试本章中的分布式训练示例，您需要访问多个GPU或TPU。为简单起见，考虑使用提供GPU集群的各种商业平台之一，例如[Databricks](https://databricks.com)和[Paperspace](https://www.paperspace.com)。其他选择包括主要的云供应商，它们提供各种平台，从托管服务到容器。为了简单起见和易于获取，本章中的示例是在Databricks中完成的，这是一个基于云的计算供应商。它允许您设置一个分布式计算集群，可以是GPU或CPU，以运行单节点机器无法处理的重型工作负载。
- en: 'While Databricks offers a free “community edition,” it does not provide access
    to GPU clusters; for that you will need to [create a paid account](https://oreil.ly/byE1d).
    Then you can associate Databricks with a cloud vendor of your choice and create
    a GPU cluster with the configuration shown in [Figure 8-5](#setting_up_a_databricks_gpu_cluster).
    My advice: once you’re done with your work, download your notebook and delete
    the clusters you created.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Databricks提供免费的“社区版”，但它不提供访问GPU集群的权限；为此，您需要[创建一个付费账户](https://oreil.ly/byE1d)。然后，您可以将Databricks与您选择的云供应商关联，并使用[图8-5](#setting_up_a_databricks_gpu_cluster)中显示的配置创建GPU集群。我的建议是：完成工作后，下载您的笔记本并删除您创建的集群。
- en: '![Setting up a Databricks GPU cluster](Images/t2pr_0805.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![设置Databricks GPU集群](Images/t2pr_0805.png)'
- en: Figure 8-5\. Setting up a Databricks GPU cluster
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-5。设置Databricks GPU集群
- en: You may notice in [Figure 8-5](#setting_up_a_databricks_gpu_cluster) that there
    are Autopilot Options. The Enable autoscaling option will automatically scale
    to more workers as needed, based on the workload. To save costs, I also set the
    option for this cluster to terminate after 120 minutes of inactivity. (Note that
    terminating the cluster does *not* mean you have deleted it. It remains and continues
    incurring a small charge in your account until you delete it.) Once you complete
    the configuration, click the Create Cluster button at the top. It usually takes
    about 10 minutes to complete the process.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会注意到[图8-5](#setting_up_a_databricks_gpu_cluster)中有自动驾驶选项。启用自动缩放选项将根据工作负载的需要自动扩展到更多的工作节点。为了节约成本，我还设置了此集群在120分钟不活动后自动终止的选项。（请注意，终止集群并不意味着您已经删除它。它将继续存在并在您的账户中产生一小笔费用，直到您删除它。）完成配置后，点击顶部的“创建集群”按钮。通常需要大约10分钟来完成整个过程。
- en: Next, create a notebook ([Figure 8-6](#creating_a_notebook_in_the_databricks_en)).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个笔记本（[图8-6](#creating_a_notebook_in_the_databricks_en)）。
- en: '![Creating a notebook in the Databricks environment](Images/t2pr_0806.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![在Databricks环境中创建笔记本](Images/t2pr_0806.png)'
- en: Figure 8-6\. Creating a notebook in the Databricks environment
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-6。在Databricks环境中创建笔记本
- en: Give your notebook a name, ensure the default language is set to Python, and
    select the cluster that you just created ([Figure 8-7](#setting_up_your_notebook)).
    Click the Create button to generate a blank notebook.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 给您的笔记本命名，确保默认语言设置为Python，并选择您刚刚创建的集群（[图8-7](#setting_up_your_notebook)）。点击“创建”按钮生成一个空白笔记本。
- en: '![Setting up your notebook](Images/t2pr_0807.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![设置您的笔记本](Images/t2pr_0807.png)'
- en: Figure 8-7\. Setting up your notebook
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-7。设置您的笔记本
- en: Now make sure your notebook is attached to the GPU cluster ([Figure 8-8](#attaching_your_notebook_to_an_active_clu)).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在确保您的笔记本已连接到GPU集群（[图8-8](#attaching_your_notebook_to_an_active_clu)）。
- en: '![Attaching your notebook to an active cluster](Images/t2pr_0808.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![将您的笔记本附加到活动集群](Images/t2pr_0808.png)'
- en: Figure 8-8\. Attaching your notebook to an active cluster
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-8。将您的笔记本附加到活动集群
- en: Now go ahead and start the GPU cluster. Then go to the Libraries tab and click
    the Install New button, as shown in [Figure 8-9](#installing_libraries_in_a_databricks_clu).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在继续启动GPU集群。然后转到“库”选项卡，点击“安装新”按钮，如[图8-9](#installing_libraries_in_a_databricks_clu)所示。
- en: '![Installing libraries in a Databricks cluster](Images/t2pr_0809.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![在Databricks集群中安装库](Images/t2pr_0809.png)'
- en: Figure 8-9\. Installing libraries in a Databricks cluster
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-9。在Databricks集群中安装库
- en: When the Install Library prompt appears ([Figure 8-10](#installing_the_tensorflow-datasets_libra)),
    select PyPl as the Library Source, and in the Package field type `**tensorflow-datasets**`,
    and then click the Install button.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当出现“安装库”提示时（[图8-10](#installing_the_tensorflow-datasets_libra)），选择PyPl作为库源，在“包”字段中输入`**tensorflow-datasets**`，然后点击“安装”按钮。
- en: Once you have done this, you will be able to use TensorFlow’s dataset API to
    work through the examples in this chapter. In the next section, you are going
    to see how to use a Databricks notebook to try out distributed training with the
    GPU cluster you just created.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您将能够使用TensorFlow的数据集API来完成本章中的示例。在下一节中，您将看到如何使用Databricks笔记本来尝试使用您刚刚创建的GPU集群进行分布式训练。
- en: '![Installing the tensorflow-datasets library in a Databricks cluster](Images/t2pr_0810.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![在Databricks集群中安装tensorflow-datasets库](Images/t2pr_0810.png)'
- en: Figure 8-10\. Installing the tensorflow-datasets library in a Databricks cluster
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-10。在Databricks集群中安装tensorflow-datasets库
- en: Using a GPU Cluster with tf.distribute.MirroredStrategy
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用tf.distribute.MirroredStrategy的GPU集群
- en: In [Chapter 7](ch07.xhtml#monitoring_the_training_process-id00010), you used
    the CIFAR-10 image dataset to build an image classifier with single-node training.
    In this example, you will instead train a classifier using the distributed training
    method.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](ch07.xhtml#monitoring_the_training_process-id00010)中，您使用CIFAR-10图像数据集构建了一个单节点训练的图像分类器。在这个例子中，您将使用分布式训练方法来训练分类器。
- en: 'As usual, the first thing you need to do is import the necessary libraries:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，您需要做的第一件事是导入必要的库：
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now is a good time to create a `MirroredStrategy` object to handle distributed
    training:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是创建`MirroredStrategy`对象以处理分布式训练的好时机：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Your output should look something like this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 您的输出应该看起来像这样：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This shows that there are two GPUs. You can confirm this with the following
    statement, as we did previously:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明有两个GPU。您可以使用以下语句确认这一点，就像我们之前做过的那样：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now load the training data and normalize each image pixel range to be between
    0 and 1:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在加载训练数据并将每个图像像素范围归一化为0到1之间：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can define plain-text labels in a list:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在列表中定义纯文本标签：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'These plain-text labels, from the [CIFAR-10 dataset](https://oreil.ly/fCvCX),
    are in alphabetical order: “airplane” maps to the value 0 in `train_labels`, while
    “truck” maps to 9.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这些纯文本标签来自[CIFAR-10数据集](https://oreil.ly/fCvCX)，按字母顺序排列：“airplane”映射到`train_labels`中的值0，而“truck”映射到9。
- en: 'Since there is a separate partition for `test_images`, extract the first 500
    images in `test_images` to use as validation images, while keeping the remainder
    for testing. Also, to more efficiently using compute resources, convert these
    images and labels from their native NumPy array format to the dataset format:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`test_images`有一个单独的分区，从`test_images`中提取前500个图像用作验证图像，同时保留其余部分用于测试。此外，为了更有效地使用计算资源，将这些图像和标签从其原生NumPy数组格式转换为数据集格式：
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: After you execute these commands, you’ll have all of the images in the formats
    of training dataset, validation dataset, and test dataset.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 执行这些命令后，您将拥有训练数据集、验证数据集和测试数据集的所有图像格式。
- en: 'It would be nice to know your dataset’s size. To find out the sample size of
    a TensorFlow dataset, convert it to a list, then find the length of the list using
    the `len` function:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 了解数据集的大小将是很好的。要找出TensorFlow数据集的样本大小，将其转换为列表，然后使用`len`函数找到列表的长度：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You can expect these results:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以期待这些结果：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, shuffle and batch the three datasets:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，对三个数据集进行洗牌和分批处理：
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Notice that `train_dataset` will be split into multiple batches, where each
    batch contains `TRAIN_BATCH_SIZE` samples. Each training batch is fed to the model
    during the training process to enable incremental updates to the weights and biases.
    There is no need to create multiple batches for validation and testing: these
    will be used as one batch, for the purposes of metrics logging and testing only.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`train_dataset`将被分成多个批次，每个批次包含`TRAIN_BATCH_SIZE`个样本。每个训练批次在训练过程中被馈送到模型中，以实现对权重和偏差的增量更新。无需为验证和测试创建多个批次：这些将作为一个批次使用，仅用于指标记录和测试。
- en: 'Next, specify how often weight updates and validation should occur:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，指定权重更新和验证应该发生的频率：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The preceding code means that after the model has seen `STEPS_PER_EPOCH` batches
    of training data, it’s time to test it with the validation dataset, used as one
    batch.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码意味着在模型看到`STEPS_PER_EPOCH`批次的训练数据后，是时候用作一个批次的验证数据集进行测试了。
- en: 'Now you need to wrap the model definition, model compilation, and loss function
    inside the strategy scope:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您需要将模型定义、模型编译和损失函数包含在策略范围内：
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The remaining sections are the same as what you did in [Chapter 7](ch07.xhtml#monitoring_the_training_process-id00010).
    You can define the directory name pattern to checkpoint the model during the training
    routine:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 其余部分与您在[第7章](ch07.xhtml#monitoring_the_training_process-id00010)中所做的相同。您可以定义目录名称模式以在训练例程中检查点模型：
- en: '[PRE16]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The preceding command specifies the directory path to be something like *./
    myCIFAR10-20210302-014804/ckpt-{epoch}*.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令指定目录路径类似于*./ myCIFAR10-20210302-014804/ckpt-{epoch}*。
- en: 'Once you define the checkpoint directory, simply pass the definition to `ModelCheckpoint`.
    For simplicity, we’ll only save the checkpoint if an epoch of training improves
    the model’s accuracy on validation data over a previous epoch:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了检查点目录，只需将定义传递给`ModelCheckpoint`。为简单起见，我们只会在训练时代提高模型在验证数据上的准确性时保存检查点：
- en: '[PRE17]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Then wrap the definition around a list:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将定义包装在一个列表中：
- en: '[PRE18]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now launch the training routine with the `fit` function, just like you have
    done in our other examples throughout the book:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用`fit`函数启动训练例程，就像您在本书中的其他示例中所做的那样：
- en: '[PRE19]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the preceding command, the `hist` object contains information about the
    training results in a Python dictionary format. The property of interest in this
    dictionary is the item `val_accuracy`:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的命令中，`hist`对象以Python字典格式包含有关训练结果的信息。这个字典中感兴趣的属性是`val_accuracy`项：
- en: '[PRE20]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This will display the validation accuracy from the first to the last epoch
    of training. From this list, we can determine the epoch with the highest accuracy
    in scoring the validation data. That’s the model you want to use for scoring:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示从训练的第一个到最后一个时代的验证准确性。从这个列表中，我们可以确定在评分验证数据时具有最高准确性的时代。这就是您要用于评分的模型：
- en: '[PRE21]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Since you set the checkpoint to save the best model rather than every epoch,
    a simpler alternative is to load the latest epoch:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您设置了检查点以保存最佳模型而不是每个时代，一个更简单的替代方法是加载最新的时代：
- en: '[PRE22]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This will give you the latest checkpoint under `checkpoint_dir`. Load the model
    with the weights from that checkpoint as:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为您提供`checkpoint_dir`下的最新检查点。从该检查点加载具有该检查点权重的模型如下：
- en: '[PRE23]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Use the model loaded with the best weights to score the test data:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 使用加载了最佳权重的模型对测试数据进行评分：
- en: '[PRE24]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Typical results look something like this:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的结果看起来像这样：
- en: '[PRE25]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Summary
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: What you have seen is the easiest way to get started with distributed TensorFlow
    model training. You learned how to create a cluster of GPUs from a commercial
    vendor’s platform and how to refactor your single-node training code to a distributed
    training routine. In addition, you learned about the essentials of distributed
    machine learning and its different system architectures.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 您所看到的是使用分布式TensorFlow模型训练的最简单方法。您学会了如何从商业供应商的平台创建一个GPU集群，以及如何将单节点训练代码重构为分布式训练例程。此外，您还了解了分布式机器学习的基本知识以及不同的系统架构。
- en: In the next section, you will learn another way to implement distributed training.
    You’ll be using an open source library known as Horovod, created by Uber, which
    at its core also leverages the ring-allreduce algorithm. While this library requires
    more refactoring, it may serve as another option for you, in case you would like
    to compare the training time differences.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将学习另一种实现分布式训练的方法。您将使用由Uber创建的开源库Horovod，该库在其核心也利用了环形全局归约算法。虽然这个库需要更多的重构，但如果您想比较训练时间差异，它可能会作为另一个选项为您提供服务。
- en: The Horovod API
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Horovod API
- en: In the preceding section, you learned how allreduce works. You also saw how
    the `tf.distribute` API automates facets of distributed training for you behind
    the scenes, so all you need to do is create a distributed training object and
    wrap the training code around the object’s scope. In this section, you will learn
    about Horovod, an older distributed training API that requires you to handle these
    facets of distributed training in code. Since `tf.distribute` is popular and easy
    to use, the Horovod API isn’t usually the first choice among programmers. The
    purpose of presenting it here is to give you another option for distributed training.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，您学习了allreduce的工作原理。您还看到了`tf.distribute` API如何在幕后自动化分布式训练的各个方面，因此您只需要创建一个分布式训练对象，并将训练代码包装在对象的范围内。在本节中，您将了解Horovod，这是一个较旧的分布式训练API，需要您在代码中处理这些分布式训练的方面。由于`tf.distribute`很受欢迎且易于使用，Horovod
    API通常不是程序员的首选。在这里介绍它的目的是为您提供另一个分布式训练的选项。
- en: As in the previous section, we’ll use Databricks as the platform for learning
    the basics of Horovod for distributed model training. If you followed my instructions,
    you will have a cluster consisting of two GPUs.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一节一样，我们将使用Databricks作为学习分布式模型训练Horovod基础知识的平台。如果您按照我的说明操作，您将拥有一个由两个GPU组成的集群。
- en: 'To understand how the Horovod API works, there are two critical parameters
    you need to know: each GPU’s identity and the number of processes for parallel
    training. Each parameter is assigned to a Horovod environment variable, which
    will be used in your code. In this particular case, you should have two GPUs.
    Each will train on a shard of data, so there will be two training processes. You
    can retrieve Horovod environment variables using the following functions:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解Horovod API的工作原理，您需要了解两个关键参数：每个GPU的标识和用于并行训练的进程数。每个参数都分配给一个Horovod环境变量，该变量将在您的代码中使用。在这种特殊情况下，您应该有两个GPU。每个GPU将在一个数据片段上进行训练，因此将有两个训练进程。您可以使用以下函数检索Horovod环境变量：
- en: Rank
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 等级
- en: Rank denotes a GPU’s identity. If there are two GPUs, one GPU will be designated
    a rank value of 0 and the other a rank value of 1\. And if there are more, the
    designated rank values will be 2, 3, and so forth.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 等级表示GPU的标识。如果有两个GPU，则一个GPU将被指定为等级值0，另一个GPU将被指定为等级值1。如果有更多GPU，则指定的等级值将是2、3等。
- en: Size
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 大小
- en: Size denotes the total number of GPUs. If there are two, then Horovod’s scope
    size is 2 and the training data will be split into two shards. Similarly, if there
    are four GPUs, this value will be 4 and the data will be split into four shards.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 大小表示GPU的总数。如果有两个GPU，则Horovod的范围大小为2，训练数据将被分成两个片段。同样，如果有四个GPU，则该值将为4，数据将被分成四个片段。
- en: You will see these two functions being used very often. You can refer to the
    [Horovod documentation](https://oreil.ly/KC893) for more details.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 您将经常看到这两个函数被使用。您可以参考[Horovod文档](https://oreil.ly/KC893)获取更多详细信息。
- en: Code Pattern for Implementing the Horovod API
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现Horovod API的代码模式
- en: 'Before I show the full source code for running Horovod in Databricks, let’s
    take a look at how to run a Horovod training job. The general pattern for running
    distributed training using Horovod in Databricks is:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在我展示在Databricks中运行Horovod的完整源代码之前，让我们看一下如何运行Horovod训练作业。在Databricks中使用Horovod进行分布式训练的一般模式是：
- en: '[PRE26]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: With Databricks, you need to run Horovod distributed training according to the
    preceding pattern. Basically, you create a `HorovodRunner` object called `hr`
    that allocates two GPUs. This object then executes a `run` function, which distributes
    a `train_hvd` function to each GPU. The `train_hvd` function is responsible for
    executing data ingestion and training routines at each GPU. Also, `checkpoint_path`
    is used to save the model at every training epoch, and `learning_rate` is used
    during the back propagation step of the training process.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Databricks，您需要根据上述模式运行Horovod分布式训练。基本上，您创建一个名为`hr`的`HorovodRunner`对象，该对象分配两个GPU。然后，该对象执行一个`run`函数，该函数将`train_hvd`函数分发到每个GPU。`train_hvd`函数负责在每个GPU上执行数据摄入和训练例程。此外，`checkpoint_path`用于在每个训练时代保存模型，`learning_rate`用于训练过程的反向传播步骤中使用。
- en: As training proceeds through each epoch, the model weights and biases are aggregated,
    updated, and stored at the GPU ranked 0\. `learning_rate` is another parameter
    designated by the Databricks driver and propagated to each GPU. Before you use
    the preceding pattern, though, you need to organize and implement several functions,
    which we’ll go through next.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 随着每个时代的训练进行，模型的权重和偏差被聚合、更新并存储在GPU 0上。`learning_rate`是由Databricks驱动程序指定的另一个参数，并传播到每个GPU。然而，在使用上述模式之前，您需要组织和实现几个函数，接下来我们将详细介绍。
- en: Encapsulating the Model Architecture
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 封装模型架构
- en: 'The job of Databricks’ main driver is to distribute training data and model
    architecture blueprints to each GPU. Therefore, you need to wrap the model architecture
    in a function. As `hr.run` is executed, the `train_hvd` function is executed at
    each GPU. In `train_hvd`, a model architecture wrapper function such as this one
    is invoked:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Databricks的主驱动程序的工作是将训练数据和模型架构蓝图分发到每个GPU。因此，您需要将模型架构包装在一个函数中。当执行`hr.run`时，`train_hvd`函数将在每个GPU上执行。在`train_hvd`中，将调用一个类似于这样的模型架构包装函数：
- en: '[PRE27]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: As you can see, this is the same model architecture you used in the previous
    section, except it is wrapped as a function. The function will return the model
    object to the execution process in each GPU.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，这是您在前一节中使用的相同模型架构，只是包装为一个函数。该函数将在每个GPU中将模型对象返回给执行过程。
- en: Encapsulating the Data Separation and Sharding Processes
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 封装数据分离和分片过程
- en: To ensure each GPU receives a shard of training data, you also need to wrap
    the data processing steps as a function that can be passed into each GPU, just
    as the model architecture is passed.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保每个GPU接收到一部分训练数据，您还需要将数据处理步骤封装为一个函数，该函数可以传递到每个GPU中，就像模型架构一样。
- en: 'As an example, let’s use the same dataset, CIFAR-10, to illustrate how to ensure
    that each GPU gets a different shard of training data. Take a look at the following
    function:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，让我们使用相同的数据集CIFAR-10来说明如何确保每个GPU获得不同的训练数据片段。看一下以下函数：
- en: '[PRE28]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Notice the input parameters `rank` and `size` in the function signature. `rank`
    is defaulted to a value of 0, and `size` is defaulted to 1, so there is compatibility
    with single-node training. In distributed training with more than one GPU, each
    GPU will pass `hvd.rank` and `hvd.size` as inputs into this function. Since each
    GPU’s identity is represented by `hvd.rank` through the double-colon (::) notation,
    images and labels are sliced and sharded according to how many steps to skip from
    one record to the next. As a result, the arrays returned by this function—`train_images`,
    `train_labels`, `test_images`, and `test_labels`—are different for each GPU, depending
    on its `hvd.rank`. (For a detailed explanation about NumPy array skipping and
    slicing, see [this Colab notebook](https://oreil.ly/23bmZ).)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 注意函数签名中的输入参数`rank`和`size`。`rank`默认为0，`size`默认为1，因此与单节点训练兼容。在具有多个GPU的分布式训练中，每个GPU将`hvd.rank`和`hvd.size`作为输入传递到此函数中。由于每个GPU的身份由`hvd.rank`通过双冒号(::)表示，图像和标签根据从一个记录到下一个跳过多少步来切片和分片。因此，此函数返回的数组`train_images`、`train_labels`、`test_images`和`test_labels`对于每个GPU都是不同的，取决于其`hvd.rank`。（有关NumPy数组跳过和切片的详细解释，请参见[此Colab笔记本](https://oreil.ly/23bmZ)。）
- en: Parameter Synchronization Among Workers
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参数同步在工作节点之间
- en: 'It is important to initialize and synchronize the initial states of weights
    and biases among all workers (devices) before starting the training. This is done
    with a callback:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练之前，重要的是初始化和同步所有工作节点（设备）之间的权重和偏置的初始状态。这是通过一个回调函数完成的：
- en: '[PRE29]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This effectively broadcasts variable states from the 0-ranked GPU to all other
    GPUs.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是将变量状态从排名为0的GPU广播到所有其他GPU。
- en: 'Error metrics for all workers need to be averaged between each training step.
    This is done with another callback:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 所有工作节点的错误指标需要在每个训练步骤之间进行平均。这是通过另一个回调函数完成的：
- en: '[PRE30]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This is also passed into a callback list during training.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这也在训练期间传递到回调函数列表中。
- en: 'It’s best to use a low learning rate early on and then switch to a preferred
    learning rate after, say, the first five epochs, which you can do by specifying
    the number of warm-up epochs with the following code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最好在早期使用低学习率，然后在前5个时期之后切换到首选学习率，您可以通过以下代码指定热身时期的数量来实现：
- en: '[PRE31]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Also, include a way to reduce the learning rate during training when the model
    metric stops improving:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在训练过程中，当模型指标停止改善时，包括一种减小学习率的方法：
- en: '[PRE32]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In this example, you’ll start to reduce the learning rate by a factor of 0.2
    if there is no improvement in the model metric after 10 epochs.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，如果模型指标在10个时期后没有改善，您将开始将学习率降低0.2倍。
- en: 'To make things simpler, I recommend putting all these callbacks together as
    a list:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化事情，我建议将所有这些回调函数放在一个列表中：
- en: '[PRE33]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Model Checkpoint as a Callback
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型检查点作为回调
- en: 'As mentioned, after all workers complete an epoch of training, the model parameters
    are saved as a checkpoint in the 0-ranked worker. This is done using the following
    code snippet:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，当所有工作节点完成一个时期的训练后，模型参数将作为检查点保存在排名为0的工作节点中。这是使用以下代码片段完成的：
- en: '[PRE34]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This is necessary to prevent conflicts between workers, so that there is only
    one version of truth when it comes to model performance and validation metrics.
    As shown in the preceding code, with `save_best_only` set to True, the model and
    trained parameters will be saved only if the validation metric in that epoch is
    an improvement over the previous epoch. Therefore, not all epochs will result
    in a model being saved, and you can be sure that the latest checkpoint is the
    best model.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为了防止工作节点之间的冲突，确保在模型性能和验证指标方面只有一个真相版本。如前面的代码所示，当`save_best_only`设置为True时，只有在该时期的验证指标优于上一个时期时，模型和训练参数才会被保存。因此，并非所有时期都会导致模型被保存，您可以确保最新的检查点是最佳模型。
- en: Distributed Optimizer for Gradient Aggregation
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 梯度聚合的分布式优化器
- en: 'The gradient computation is also distributed, as each worker does its own training
    routine and calculates the gradient individually. You need to aggregate and then
    average all the gradients from different workers, then apply the average to all
    workers for the next step of training. This is accomplished with the following
    code snippet:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度计算也是分布式的，因为每个工作节点都会执行自己的训练例程并单独计算梯度。您需要聚合然后平均来自不同工作节点的所有梯度，然后将平均值应用于所有工作节点，用于下一步训练。这是通过以下代码片段实现的：
- en: '[PRE35]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Here, `hvd.DistributedOptimizer` wraps the single-node optimizer’s signature
    in Horovod’s scope.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`hvd.DistributedOptimizer`将单节点优化器的签名包装在Horovod的范围内。
- en: Distributed Training Using the Horovod API
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Horovod API进行分布式训练
- en: 'Now let’s take a look at a full implementation of distributed training using
    the Horovod API in Databricks. This implementation uses the same dataset (CIFAR-10)
    and model architecture you saw in [“Using the Class tf.distribute.MirroredStrategy”](#using_the_tfdotdistributedotmirroredstra):'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一下在Databricks中使用Horovod API进行分布式训练的完整实现。此实现使用与[“使用类tf.distribute.MirroredStrategy”](#using_the_tfdotdistributedotmirroredstra)中看到的相同数据集（CIFAR-10）和模型架构：
- en: '[PRE36]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The preceding code will be executed at each worker. Each worker receives its
    own `train_images`, `train_labels`, `test_images`, and `test_labels`.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码将在每个工作人员上执行。每个工作人员都会收到自己的`train_images`、`train_labels`、`test_images`和`test_labels`。
- en: 'The following code is a function that wraps the model architecture; it will
    be built into each worker:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是一个包装模型架构的函数；它将构建到每个工作人员中：
- en: '[PRE37]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Next is the main training function, `train_hvd`, which invokes the two functions
    just shown. This function is rather lengthy, so I’ll explain it in blocks.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是主要的训练函数`train_hvd`，它调用了刚刚展示的两个函数。这个函数相当冗长，所以我会分块解释它。
- en: 'Inside `train_hvd`, a Horovod object is created and initialized with the command
    `hvd.init`. This function takes `checkpoint_path` and `learning_rate` as inputs
    for the distributed training routine to store models at each epoch and set the
    rate for gradient descent during the back propagation process. In the beginning,
    all libraries are imported:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在`train_hvd`内部，使用命令`hvd.init`创建并初始化了一个Horovod对象。此函数将`checkpoint_path`和`learning_rate`作为输入，用于存储每个时代的模型并在反向传播过程中设置梯度下降的速率。一开始，导入所有库：
- en: '[PRE38]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then you create and initialize a Horovod object and use it to access your workers’
    configurations, so the data can be sharded properly later:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，创建并初始化一个Horovod对象，并使用它来访问您的工作人员的配置，以便稍后可以正确分片数据：
- en: '[PRE39]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Now that you’ve created your `hvd` object, use it to provide worker identification
    (`hvd.rank`) and the number of parallel processes (`hvd.size`) to the `get_dataset`
    function, which will return the training and validation data in shards.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经创建了`hvd`对象，使用它来提供工作人员标识（`hvd.rank`）和并行进程数（`hvd.size`）给`get_dataset`函数，该函数将以分片返回训练和验证数据。
- en: 'Once you have these shards, convert them to a dataset so you can stream the
    training data, just as you did in [“Using a GPU Cluster with tf.distribute.MirroredStrategy”](#using_a_gpu_cluster_with_tfdotdistribute):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了这些分片，将它们转换为数据集，以便您可以像在[“使用tf.distribute.MirroredStrategy的GPU集群”](#using_a_gpu_cluster_with_tfdotdistribute)中那样流式传输训练数据：
- en: '[PRE40]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Shuffle and batch the training and validation datasets:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 对训练和验证数据集进行洗牌和分批处理：
- en: '[PRE41]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now define batch size, training steps, and training epochs:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在定义批量大小、训练步数和训练时代：
- en: '[PRE42]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Create a model using the `get_model` function, set the optimizer, designate
    a learning rate, and then compile the model with the proper loss function for
    this classification task. Notice that the optimizer is wrapped by `DistributedOptimizer`
    for distributed training:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`get_model`函数创建一个模型，设置优化器，指定学习率，然后使用适合此分类任务的正确损失函数编译模型。请注意，优化器被`DistributedOptimizer`包装以进行分布式训练：
- en: '[PRE43]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Here you will create a callback list to synchronize variables across workers,
    to aggregate and average gradients for synchronous updates, and to adjust the
    learning rate according to epochs or training performance:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您将创建一个回调列表，以在工作人员之间同步变量，对梯度进行聚合和平均以进行同步更新，并根据时代或训练性能调整学习率：
- en: '[PRE44]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Finally, here is the callback for model checkpoints at each epoch. This callback
    is only executed in the 0-ranked worker ( `hvd.rank() == 0` ):'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这是每个时代模型检查点的回调。此回调仅在0级工作人员（`hvd.rank() == 0`）中执行：
- en: '[PRE45]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Now comes the final `fit` function that will launch the model training routine:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是最终的`fit`函数，将启动模型训练例程：
- en: '[PRE46]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: This concludes the `train_hvd` function.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了`train_hvd`函数。
- en: 'In the next cell of your Databricks notebook, specify a checkpoint directory
    for each epoch of training:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的Databricks笔记本的下一个单元格中，为每个训练时代指定一个检查点目录：
- en: '[PRE47]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '`checkpoint_dir` will look something like */dbfs/ml/CIFAR10DistributedDemo/train/1615074200.2146788/*.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`checkpoint_dir`将看起来像*/dbfs/ml/CIFAR10DistributedDemo/train/1615074200.2146788/*。'
- en: 'In the next cell, go ahead and launch the distributed training routine:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个单元格中，继续启动分布式训练例程：
- en: '[PRE48]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: In the runner definition, `HorovodRunner(np=2)`, the number of processes is
    specified as two per setup (see [“Setting Up Distributed Training”](#setting_up_distributed_training)),
    which sets up two Standard_NC12 worker GPUs.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行器定义中，`HorovodRunner(np=2)`，将进程数指定为每个设置的两个（请参阅[“设置分布式训练”](#setting_up_distributed_training)），这将设置两个Standard_NC12工作人员GPU。
- en: 'Once the training routine is complete, take a look at the checkpoint directories
    using the following command:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 训练例程完成后，请使用以下命令查看检查点目录：
- en: '[PRE49]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'You should see something like this:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到类似于这样的内容：
- en: '[PRE50]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Some checkpoints are skipped if there is no model improvement over previous
    epochs. The latest checkpoint represents the model with the best validation metrics.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有模型在先前的时代中有所改进，则会跳过一些检查点。最新的检查点代表具有最佳验证指标的模型。
- en: Wrapping Up
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, you learned what it takes for distributed model training to
    work in an environment with multiple workers. With a data parallelism framework,
    there are two major patterns for distributed training: asynchronous parameter
    server and synchronous allreduce. Today synchronous allreduce is more popular
    because of the general availability of high-performance accelerators.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了在具有多个工作人员的环境中使分布式模型训练正常工作所需的内容。在数据并行框架中，有两种主要的分布式训练模式：异步参数服务器和同步allreduce。如今，由于高性能加速器的普遍可用性，同步allreduce更受欢迎。
- en: 'You learned how to use a Databricks GPU cluster to perform two types of synchronous
    allreduce APIs: TensorFlow’s own `tf.distribute` API and Uber’s Horovod API. The
    TensorFlow option provides the most elegant and convenient use and requires the
    least amount of code refactoring, whereas the Horovod API requires users to manually
    handle data sharding, distribution pipelines, gradient aggregation and averaging,
    and model checkpoints. Both options perform distributed training by ensuring that
    each worker performs its own training, and then, at the end of each training step,
    updating the gradients synchronously and consistently among all workers. This
    is the hallmark of distributed training.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 通过学习如何使用Databricks GPU集群执行两种类型的同步allreduce API：TensorFlow自己的`tf.distribute`
    API和Uber的Horovod API。TensorFlow选项提供了最优雅和方便的使用方式，并且需要最少的代码重构，而Horovod API需要用户手动处理数据分片、分发管道、梯度聚合和平均以及模型检查点。这两种选项通过确保每个工作节点执行自己的训练，然后在每个训练步骤结束时，在所有工作节点之间同步和一致地更新梯度来执行分布式训练。这是分布式训练的标志。
- en: Congratulations—by working your way through this chapter, you learned how to
    train a deep-learning model with a distributed data pipeline and distributed training
    routine, using a cluster of GPUs in the cloud. In the next chapter, you will learn
    how to serve a TensorFlow model for inferencing.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！通过学习本章内容，您学会了如何使用云中的一组GPU训练具有分布式数据管道和分布式训练例程的深度学习模型。在下一章中，您将学习如何为推理服务一个TensorFlow模型。
