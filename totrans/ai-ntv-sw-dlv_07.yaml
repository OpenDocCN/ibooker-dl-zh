- en: Chapter 7\. Deploying to Production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The [Knight Capital incident](https://oreil.ly/pTAIv) of August 1, 2012, stands
    as a stark example of how a software deployment gone wrong can have catastrophic
    consequences. On that day, Knight Capital, then one of the largest trading firms
    in the US, deployed a large update to its automated trading system. Due to a confluence
    of factors, including limited automation, human error in deployments, and poor
    feature flag management, outdated code was accidentally reactivated, causing the
    system to [rapidly place erroneous orders in the stock market](https://oreil.ly/efPYb).
  prefs: []
  type: TYPE_NORMAL
- en: Within just 45 minutes, the faulty algorithm had executed over 4 million trades,
    resulting in a staggering loss of $460 million for the firm. This incident not
    only nearly bankrupted Knight Capital, leading to its eventual acquisition, but
    also caused significant market disruption. It highlighted the critical importance
    of robust deployment practices, thorough testing, governance, and fail-safe mechanisms
    in high-stakes software environments.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying to production can be a high-stakes activity. While not every application
    is a market-making trading platform, applications worth updating have people who
    depend on them, and changing anything introduces risk. Although we might prefer
    to avoid this risk by deploying less often, we face business demands for more
    frequent change. Moreover, certain types of risk increase as we delay and accumulate
    more and more changes into our planned release, making the continuous delivery
    approach more valuable.
  prefs: []
  type: TYPE_NORMAL
- en: In previous chapters, as we’ve navigated the software delivery process, we’ve
    hit upon strategies to mitigate the risk of finally deploying to production. In
    [Chapter 2](ch02.html#chapter_2_source_control_management_1749354010078326), we
    discussed the importance of code reviews. In [Chapter 3](ch03.html#chapter_3_the_build_and_pre_deployment_testing_steps_of_cont_1749354010266208),
    we looked at how to use early scans and unit testing to detect issues quickly.
    [Chapter 4](ch04.html#chapter_4_deploying_to_test_environments_1749354010445896)
    described additional types of testing to harden your software and reviewed best
    practices in deploying to test environments. By using consistent tooling, pipeline
    steps, and deployment strategies, and by parameterizing for differences in environments,
    we use our deployments to test environments to vet our deployments to production.
    In [Chapter 5](ch05.html#chapter_5_securing_applications_and_the_software_supply_chai_1749354010735711),
    we dived deep into security, reviewing the practices that help secure our production
    deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Today, artificial intelligence is transforming how organizations approach production
    deployments to prevent such disasters. ML systems now analyze deployment patterns,
    detect anomalies during rollouts, and verify application health with greater precision
    than traditional monitoring. Unlike rule-based verification, which relies on predefined
    thresholds, AI systems can learn normal behavior patterns unique to each application
    and detect subtle deviations that might indicate emerging problems. These capabilities
    allow teams to deploy faster while paradoxically reducing risk—the opposite of
    the traditional speed-versus-safety trade-off.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, in addition to covering the transformative role of AI, we’ll
    look at best practices for governing production deployments and strategies to
    safely deploy to production, and we’ll discuss observability to validate the quality
    of production deployments. We’ll explore how modern AI-powered deployment tooling
    helps mitigate risk through intelligent verification rather than just reactive
    monitoring, and how AI-powered systems evaluate multiple signals simultaneously
    to determine deployment health, catching issues that might slip past human operators.
  prefs: []
  type: TYPE_NORMAL
- en: Governing Production Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Knight Capital incident is a good reminder: the consequences of deploying
    software with defects can be nothing short of catastrophic financial ruin. Your
    organization’s trust and credibility are also at risk. For the organization, the
    cost of fixing defects post-deployment can skyrocket, far exceeding the expense
    of addressing them during development.'
  prefs: []
  type: TYPE_NORMAL
- en: To deploy with confidence, we need to understand what code changed and who made
    those changes. We need to validate that the code review processes we put in place
    were conducted, and understand who conducted those reviews. For any dependencies
    that were introduced, we want to understand them and know that they comply with
    our policies. We want to know if they were reviewed for any known defects. We
    need assurance that the builds, scans, and test processes that we require were
    executed against all code changes. And of course, we want to ensure that the results
    of the scans and tests, in fact, met our criteria for passing. Lastly, we require
    evidence that our development processes themselves remain in compliance with the
    frameworks and requirements relevant to our organization.
  prefs: []
  type: TYPE_NORMAL
- en: Stringent code reviews, thorough and robust testing practices, and automated,
    repeatable deployment procedures are essential to avoiding deployment failures.
    However, without appropriate governance and controls to ensure thatwe’ve adhered
    to our processes, all of our efforts can be rendered ineffective.
  prefs: []
  type: TYPE_NORMAL
- en: AI is beginning to transform deployment governance, though most applications
    are still emerging. Current AI systems focus primarily on analyzing deployment
    patterns to identify risk factors and policy violations rather than making autonomous
    decisions. These systems can process more deployment variables simultaneously
    than humans, helping to identify subtle correlations between code changes, deployment
    configurations, and historical incidents. Organizations are beginning to use these
    insights to refine their governance frameworks, though human oversight remains
    essential for final approval decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Deployment governance is simply the systematic oversight and control of the
    software deployment process to ensure the rules and policies we’ve defined are
    enforced. Fundamentally, governance is about reducing the risk of change. Governance
    includes the policies, processes, and tools that organizations use to ensure that
    software deployments are carried out in a consistent, controlled, secure, and
    compliant manner. The challenge in governance is balancing the need for agility
    and innovation with the need for stability and risk management.
  prefs: []
  type: TYPE_NORMAL
- en: In the next few sections, we’ll discuss traditional and modern approaches to
    deployment governance. We’ll investigate how to automate the enforcement of our
    governing policies to make our delivery process more efficient. We’ll review tools
    and strategies that support our governance processes, and lastly, we’ll look at
    the future of deployment governance.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional Approaches to Deployment Governance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Traditional approaches to deployment governance are those built for a pre-DevOps
    world. In this world, changes to production were infrequent, risky, and executed
    by a traditional operations team. Decision making was centralized and involved
    rigid processes.
  prefs: []
  type: TYPE_NORMAL
- en: The Information Technology Infrastructure Library (ITIL) is one widely adopted
    framework that characterizes a traditional approach. ITIL originally emerged in
    the 1980s as a response to the need for standardized IT management practices,
    evolving from a collection of best practices into a comprehensive framework. It
    includes several processes and practices that are directly relevant to deployment
    governance.
  prefs: []
  type: TYPE_NORMAL
- en: One of these is the change management process, which defines a structured approach
    for managing all changes to services and infrastructure, including deployments.
    It prescribes formal documentation of a proposed change, including its purpose,
    scope, impact, and risk assessment. A Change Advisory Board (CAB) or a similar
    body assesses changes. The change request is formally authorized or denied based
    on its merits and potential risks. If the change is approved and executed, a post-implementation
    assessment is conducted to ensure the change achieved its objectives and identify
    any lessons learned.
  prefs: []
  type: TYPE_NORMAL
- en: The release management process is similarly formal and orders the planning,
    scheduling, and controlling of releases into production environments. It’s closely
    related to the change management process and is intended to ensure that deployments
    are executed in a controlled and transparent manner.
  prefs: []
  type: TYPE_NORMAL
- en: CABs are a typical feature of approaches like those defined by ITIL. A CAB is
    a committee of individuals responsible for formally assessing and approving or
    rejecting proposed changes to software. This board might include a change manager
    responsible for coordinating change request reviews and tracking change implementation,
    as well as technical experts, business stakeholders, security specialists, compliance
    officers, and others. The intention is to reduce risk through thorough evaluation
    of requests from several perspectives.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, CABs ensure accountability if anything does go wrong. While a highly
    functioning CAB will provide the intended oversight, at their worst CABs consist
    of inattentive reviewers that rubber-stamp reviews with little to no assessment.
    Or a CAB may be nominally effective but hopelessly inefficient. Email-driven approval
    processes are slowed by ignored emails, approvers being out of the office with
    no delegation, and review meetings getting rescheduled.
  prefs: []
  type: TYPE_NORMAL
- en: Research shows that these traditional CAB processes aren’t just inefficient,
    they’re actually counterproductive to the stability they aim to ensure. Writing
    about their landmark study of high-performing organizations in their book *Accelerate*,
    Forsgren, Humble, and Kim explain that “external approvals were negatively correlated
    with lead time, deployment frequency, and restore time and had no correlation
    with change fail rate.” In other words, approval by external bodies like CABs
    demonstrably slows down delivery without improving stability.
  prefs: []
  type: TYPE_NORMAL
- en: This occurs because CABs divorce responsibility from knowledge; the people with
    the deepest understanding of the changes aren’t the ones making approval decisions.
    While these committees create the appearance of due diligence, they often function
    as compliance theater, giving organizations someone to point to when things go
    wrong rather than actually preventing failures. The illusion of control they provide
    can even reduce vigilance among those implementing changes, since “the CAB approved
    it” becomes a shield against accountability.
  prefs: []
  type: TYPE_NORMAL
- en: The expense of CAB meetings, coupled with the ineffectiveness and delay, was
    tolerable when applications were released infrequently. As release frequencies
    have increased, the trouble with CABs is increasingly clear.
  prefs: []
  type: TYPE_NORMAL
- en: Modern Approaches to Deployment Governance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In previous chapters, we explored how to streamline the development process
    by automating steps at every stage, enabling faster and more frequent software
    releases. Modern approaches to deployment governance are similarly focused on
    automating the manual steps that are an unnecessary obstacle to releasing software.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of relying on committees and manual approvals for deployment decisions,
    modern approaches favor automated decision making and deployments. Because the
    stakes of production deployment are so high, this must be done with great care.
    In this section we’ll explore how.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to automation, modern governance approaches also leverage contemporary
    strategies and tools to manage compliance. We’ll look at how to use audit logs
    to simplify compliance, and tools like Open Policy Agent (OPA) to enforce security
    and regulatory standards.
  prefs: []
  type: TYPE_NORMAL
- en: Automating decision making
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With modern CI/CD tools we can empower our pipelines to make autonomous deployment
    decisions. If we can ensure that our pipelines can adequately enforce governance
    policies to maintain our standards, we can accelerate software delivery by removing
    or minimizing manual approvals.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider these steps to automate deployment decision making in your delivery
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Identify your “pass” criteria
  prefs: []
  type: TYPE_NORMAL
- en: Identifying clear criteria for promoting builds is crucial for automating your
    deployment process, but this can be challenging. One bank that we worked with
    documented its controls in a three-inch-thick binder containing hundreds of pages
    of regulations and policy. Often, decision makers may rely on both objective data
    and subjective judgment. Ambiguity can make it challenging to translate human
    decision making into a set of rigid, automated rules. For example, a decision
    maker might promote a build with a few minor test failures if they believe the
    issues are low risk and unlikely to impact users. However, translating this intuition
    into an automated rule that accurately assesses risk and user impact can be complex.
    AI has a growing role in bringing the fuzzier elements of human decision making
    into fully or mostly automated flows. If used this way, it should be required
    to explain its recommendations and insights.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Use “quality gates” to implement complex criteria to automate as many controls
    as possible
  prefs: []
  type: TYPE_NORMAL
- en: Gates are checkpoints within a CI/CD pipeline that evaluate specific criteria
    to determine whether a build should proceed to the next stage. Gates can take
    into account test results, code quality metrics based on static analysis results,
    code coverage, and adherence to coding standards, security scans results, and
    performance metrics. Other tools allow you to introduce a pipeline step that fails
    if the decision is “no,” or you can set up conditional execution based on your
    specific criteria. Often, the simplest approach is to configure each set of tests
    to fail if it doesn’t meet your standards. This way, if any step fails, the entire
    pipeline halts, preventing the promotion of a substandard build.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Consider historical results when automating nuanced decisions
  prefs: []
  type: TYPE_NORMAL
- en: For instance, security initiatives often start with a zero-tolerance policy
    for new high-priority issues but tolerate existing ones while the team works through
    them. This requires considering historical data, not just the most recent results.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Finally, standardize on that automation
  prefs: []
  type: TYPE_NORMAL
- en: Use the choice of standardization or painful manual compliance as an incentive
    to use standardized tooling. Teams at the bank that we worked with were given
    a choice to deploy to production by certifying that a release complies with all
    of the controls detailed in the binder, or by using their standardized automated
    processes and tooling. This became an easy choice.
  prefs: []
  type: TYPE_NORMAL
- en: Building strong audit trails to automate compliance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deployment governance and compliance are closely related. Effective governance
    practices are crucial in achieving and maintaining compliance with various regulatory
    standards and frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: We reviewed several frameworks in [Chapter 5](ch05.html#chapter_5_securing_applications_and_the_software_supply_chai_1749354010735711),
    specifically security-related ones. PCI DSS is one widely applicable example.
    It’s used to ensure that all companies that accept, process, store, or transmit
    credit card information maintain a secure environment. Regardless of the size
    or number of transactions you process, if your organization handles cardholder
    data then you are subject to its requirements. The major card brands (Visa, Mastercard,
    etc.) may impose fines or restrict your ability to process card payments if compliance
    cannot be demonstrated.
  prefs: []
  type: TYPE_NORMAL
- en: While PCI DSS primarily focuses on securing cardholder data, several requirements
    directly pertain to the software development and deployment process. This is to
    ensure the overall security of the environment where this data is handled. For
    example, PCI DSS requires that you develop and maintain secure systems and applications
    by taking steps such as conducting reviews of custom code prior to release to
    production and addressing common coding vulnerabilities. PCI DSS also includes
    testing requirements, mandating internal and external penetration testing after
    any significant infrastructure or application upgrade or modification.
  prefs: []
  type: TYPE_NORMAL
- en: A strong and comprehensive audit trail is essential to demonstrating the practices
    that compliance requires. And while your organization may not be subject to PCI
    DSS requirements, many other frameworks that may be relevant will have similar
    requirements of your development and deployment processes.
  prefs: []
  type: TYPE_NORMAL
- en: Your source control and CI/CD systems play a vital role here by capturing the
    granular details of every action taken within the delivery pipeline, from code
    commits and builds to test results, deployments, and environment configurations,
    along with the associated user, timestamp, and any relevant metadata. This includes
    logging user actions, system events, artifact tracking, configuration changes,
    and external integrations. By storing this information in a structured and accessible
    format, CI/CD tools provide a versatile audit trail that is adaptable to any number
    of security and regulatory frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Tools that support a strong audit trail allow your organization to demonstrate
    compliance without maintaining separate logs for each framework. It also enables
    you to proactively address potential security or compliance concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Managing enforcement with Policy as Code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Policy as Code (PaC) can be instrumental in automating your production deployments
    while maintaining robust governance. PaC is the practice of defining and managing
    security, compliance, and operational policies *as code*, allowing for automated
    enforcement. Policies are defined in a declarative language and can be managed
    like any other critical piece of code: versioned in source control, allowing for
    tracking, collaboration and required code reviews, and rollback capabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: OPA is a popular open source policy engine used to implement PaC. With OPA,
    every deployment is automatically evaluated against your defined policies, ensuring
    consistent enforcement without slowing down your delivery process. Imagine your
    deployment policy requires all container images to be scanned for critical vulnerabilities
    before reaching production. Using OPA, you can express this PaC, and integrate
    it into your pipeline. Now, every time a deployment is triggered, OPA automatically
    scans the image and either allows the deployment to proceed if the image is clean
    or halts it if vulnerabilities are found. This eliminates manual security checks
    and ensures consistent adherence to your security standards without human intervention.
  prefs: []
  type: TYPE_NORMAL
- en: OPA’s versatility extends beyond security checks. You can codify various deployment
    policies, such as enforcing canary deployments, requiring approvals for specific
    changes, or validating resource configurations. By automating these checks, you
    gain confidence that every deployment adheres to your organization’s standards
    and regulatory requirements. This not only accelerates your delivery process but
    also reduces the risk of human error and noncompliance.
  prefs: []
  type: TYPE_NORMAL
- en: Safeguarding the Deployment Process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tightly controlling your governance mechanisms helps protect your deployment.
    Developer empowerment is also critical in modern deployments. In practice, you
    need to strike a balance between the two. While you want to enable developers
    to adapt their deployment pipelines, you also need to safeguard against potential
    risks. Malicious actors can tamper with or bypass the very governance mechanisms
    you put in place, or they can be corrupted by human error. Alternatively, overly
    tight controls on deployments can create another obstacle to efficient deployments.
  prefs: []
  type: TYPE_NORMAL
- en: OPA can help here too. With OPA you apply strict controls on the policy update
    process itself, ensuring that any changes to your governance framework are carefully
    vetted and compliant. By centralizing policy rules in OPA and applying them to
    pipelines, you create a separation of concerns. This makes it more difficult for
    individual developers to circumvent policies, as they would need to modify the
    central OPA policies, which can be subject to stricter access controls, peer reviews,
    and audit trails.
  prefs: []
  type: TYPE_NORMAL
- en: As we increasingly rely on AI to generate our pipelines for us, OPA policies
    provide both directional input to the AI as to what we want, and protection ensuring
    that the output of the AI is in compliance with our standards.
  prefs: []
  type: TYPE_NORMAL
- en: Another important control in safeguarding your deployment process is implementing
    robust RBAC. As discussed in [Chapter 2](ch02.html#chapter_2_source_control_management_1749354010078326),
    RBAC allows you to granularly control who has access to modify pipelines and sensitive
    configuration settings within your CI/CD platform. This ensures that only authorized
    personnel can make changes to your deployment process, minimizing the risk of
    malicious activities.
  prefs: []
  type: TYPE_NORMAL
- en: By combining these approaches, you can centralize policy enforcement, ensuring
    your deployments are tamper-proof and effectively monitored.
  prefs: []
  type: TYPE_NORMAL
- en: Future Trends in Deployment Governance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As in nearly every area of software development, AI and ML will drive important
    future trends in deployment governance. Predictive analytics, for example, is
    a branch of data analytics that applies ML techniques for analyzing historical
    data to predict future outcomes. Applied to software deployments, predictive analytics
    can be used to identify patterns and risk factors to flag potential issues. Vendors
    are creating dashboards, such as Digital.ai’s “Change Risk Prediction,” based
    on trends like team failure rates and defects found in testing. Today, most of
    these solutions are relatively straightforward correlations found in broad sets.
    It’s not unreasonable to expect more insights from models as we go forward, especially
    from DevOps platforms with easy access to wider data sets.
  prefs: []
  type: TYPE_NORMAL
- en: Your team can proactively address problems before they impact users. AI and
    ML can be used to automatically enforce governance policies in real time, analyzing
    code changes, configurations, and deployments to ensure compliance with security
    and operational standards. These advancements will empower organizations to deliver
    software with increased speed, confidence, and resilience.
  prefs: []
  type: TYPE_NORMAL
- en: Reconciling Traditional and Modern Approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Within a traditional governance approach, ITIL defines a standard change as
    a pre-approved, low-risk change with a well-defined procedure, allowing for quicker
    implementation with minimal formal authorization. By using modern DevOps practices,
    relying on quality gates and modern policy enforcement, we can significantly de-risk
    even complex software deployments. This level of control and reliability allows
    these deployments to be treated as standard changes. Essentially, the inherent
    risk mitigation within modern DevOps practices aligns with ITIL’s goal of standardized,
    predictable change management, enabling faster and more frequent deployments without
    compromising stability or compliance.
  prefs: []
  type: TYPE_NORMAL
- en: In [“Production Deployment Strategies”](#chapter_7_production_deployment_strategies_1749354011063200)
    we’ll explore using progressive deployments to further de-risk production deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Production Deployment Strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 4](ch04.html#chapter_4_deploying_to_test_environments_1749354010445896)
    we covered how to automate our deployment processes, and we have now looked at
    how to mitigate risk through deployment governance practices. Next we turn our
    attention to the actual business of deploying our software to production. In this
    section we’ll look at how to further mitigate risk with progressive deployment
    techniques. With even the strongest governance and the most cautious progressive
    deployments, our deployments may still fail. We must come prepared with a rollback
    strategy, so we’ll look at approaches to revert quickly. Lastly, we’ll look at
    tool selection. Choosing modern tools can help you make governance, progressive
    deployments, and rolling back easy.
  prefs: []
  type: TYPE_NORMAL
- en: The Traditional Big-Bang Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we look at modern approaches, we can remind ourselves of the traditional
    approach—and what still may be required for some elements of stateful applications.
    Traditionally, we would take our application offline, upgrade every instance of
    every component of the application, and start the application back up. After a
    quick validation, we would expose it back to users, and watch it for a period
    of time to make sure it looked healthy before deeming the deployment a success.
    If there was a problem, we would take the application back offline and roll back
    the application to the best of our ability—often a daunting challenge.
  prefs: []
  type: TYPE_NORMAL
- en: This traditional approach required application downtime, introduced significant
    risk, and demanded significant attention from engineers. The opportunities to
    do better are abundant.
  prefs: []
  type: TYPE_NORMAL
- en: Using a Progressive Delivery Strategy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Software deployments can be like walking a tightrope—one wrong step and the
    consequences can be severe. But progressive deployment strategies offer you a
    safety net. By gradually rolling out changes and closely monitoring their impact,
    these strategies minimize risks and allow for quick course correction if problems
    arise. In this section we’ll look at a number of popular deployment strategies
    including rolling updates, blue-green deployments, canary deployments, and the
    use of feature flags.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying rolling updates
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Rolling deployments are a very common delivery strategy in which you gradually
    update an application or service by incrementally replacing instances of the old
    version with the new version. This is done in a controlled manner, ensuring that
    a certain number of instances are always available to handle user traffic during
    the update process.
  prefs: []
  type: TYPE_NORMAL
- en: Rolling deployments have distinct advantages. They minimize downtime as the
    application remains accessible throughout the update process. Importantly, rolling
    deployments reduce risk. By updating instances incrementally, potential issues
    with the new version can be detected and addressed early on, limiting their impact.
    And this type of deployment can be customized to fit specific application needs,
    allowing for endless adjustments to the speed and scale of the update process.
  prefs: []
  type: TYPE_NORMAL
- en: However, implementing and managing rolling deployments can be more complex than
    other deployment strategies, especially for large-scale or distributed systems.
    There is also potential for inconsistencies. During the update process, two different
    versions of the application, running simultaneously, could lead to differences
    in data or user experience. In addition, rolling back an ongoing deployment can
    be complicated, and additional steps to preserve data integrity are required.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation options are numerous. Kubernetes provides built-in support for
    rolling updates through its Deployment object. New pods with the updated version
    are gradually created, and old pods are terminated once the new ones are ready.
    Container orchestration platforms (e.g., Docker Swarm, Nomad) offer similar mechanisms
    for rolling updates, allowing for incremental replacement of containers or services.
    Load balancers can be used to implement rolling updates by gradually shifting
    traffic from old instances to new instances as they become available. In some
    cases, rolling deployments might be implemented using custom scripts or automation
    tools that manage the update process and monitor the health of the application.
  prefs: []
  type: TYPE_NORMAL
- en: While rolling deployments require effort to implement, they offer a valuable
    option for minimizing downtime and risk during application updates.
  prefs: []
  type: TYPE_NORMAL
- en: Using blue-green deployments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A blue-green deployment is a release strategy that involves maintaining two
    identical environments, typically referred to as “blue” and “green.” At any given
    time, only one of these environments (usually blue) is live, serving production
    traffic.
  prefs: []
  type: TYPE_NORMAL
- en: When a new version of your application is ready, it is deployed to the inactive
    environment (green). After testing and verification in the green environment,
    traffic is switched over from the blue environment to the green environment, making
    the new version live. Where a rolling deployment makes updates over time and different
    traffic will experience different versions of the service, a blue-green typically
    features a hard cutover. A switch is flipped and traffic, or at least new traffic,
    is moved immediately from the old to the new. [Figure 7-1](#chapter_7_figure_1_1749354011054693)
    depicts blue and green environments before and after deploying an update.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ansd_0701.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. Blue-green deployments involve running two identical environments
    for seamless updates and rollback options (in the print book, blue appears in
    dark gray and green appears in light gray)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The previous live environment (now blue) can be used for the next deployment,
    kept as a backup in case a rollback is needed, or decommissioned.
  prefs: []
  type: TYPE_NORMAL
- en: 'A blue-green strategy offers distinct advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Reduced downtime
  prefs: []
  type: TYPE_NORMAL
- en: Traffic is switched between environments, minimizing any disruption to users
    and reducing downtime.
  prefs: []
  type: TYPE_NORMAL
- en: Easy rollbacks
  prefs: []
  type: TYPE_NORMAL
- en: If there are issues with the new deployment, traffic can be quickly switched
    back to the previous version.
  prefs: []
  type: TYPE_NORMAL
- en: Improved testing
  prefs: []
  type: TYPE_NORMAL
- en: The new version can be tested in a production-like environment before going
    live.
  prefs: []
  type: TYPE_NORMAL
- en: The main disadvantage lies in the increased infrastructure cost, as maintaining
    two separate, identical environments can be expensive. Additionally, blue-green
    deployments might not be suitable for applications with complex state management
    or database schema changes, because synchronizing data between environments can
    be challenging.
  prefs: []
  type: TYPE_NORMAL
- en: A more advanced blue-green model can overcome most of the infrastructure cost
    challenge by integrating IaCM practices. During steady-state production, only
    one instance is in existence. At the start of the deployment, the deployment triggers
    an IaCM tool to provision a new instance, so both blue and green exist. At the
    conclusion of the process, the excess instance is de-provisioned. As a result,
    the excess infrastructure only needs to exist for the duration of the blue-green
    deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Using canary releases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Canary releases offer another progressive strategy similar to rolling updates.
    A new version of the application is rolled out to a small subset of users or servers.
    This “canary” group acts as a test bed, allowing you to monitor the new version’s
    performance and stability in a real-world production environment before making
    it available to all users.
  prefs: []
  type: TYPE_NORMAL
- en: In a typical canary deployment, only a small portion of traffic (e.g., 5% to
    10%) might be directed to the newly deployed version. The performance, stability,
    and error rates of the new version are closely monitored and compared with those
    of the existing version. Metrics like response times, CPU usage, and error logs
    are analyzed to identify any potential issues. If the new version performs well
    in the canary environment, the percentage of traffic directed to it is gradually
    increased, allowing more users to access it. This process continues until the
    new version completely replaces the old one. If any issues or performance degradation
    are detected during the canary phase, the deployment can be rolled back quickly,
    minimizing the impact on users.
  prefs: []
  type: TYPE_NORMAL
- en: Canary deployments may be implemented with simple metric thresholds, but they
    increasingly leverage AI or ML capabilities to determine whether the new version
    performs satisfactorily. Traditionally, canary deployments have focused on performance
    benchmarks, but we can expect that in the future they will increasingly also tap
    into business metrics, stopping the rollout if the new version of the application
    is harming the business, even if it is not crashing.
  prefs: []
  type: TYPE_NORMAL
- en: While both canary deployments and rolling updates aim for gradual and controlled
    software releases, they differ in their focus. Rolling updates solve for minimizing
    downtime and service disruption across a service infrastructure. Canary deployments
    focus on metric-guided decision making about whether to gradually increase traffic
    to a new release or roll back to the previous version.
  prefs: []
  type: TYPE_NORMAL
- en: Using feature flags
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Feature flags provide a strategy for deploying *features* in a progressive manner.
    Think of feature flags like hidden switches within your code, allowing you to
    turn features on or off for specific users or groups without deploying new code.
    This gives you granular control over who sees what, enabling A/B testing and targeted
    rollouts. Feature flags are similar to other progressive deployment strategies
    in that they allow you to monitor performance and gather feedback in a real-world
    environment and use this information to mitigate risks. However, feature flags
    operate at different levels; they control functionality within a single version.
    Other progressive strategies test an entirely new version.
  prefs: []
  type: TYPE_NORMAL
- en: Feature flags offer benefits beyond deployment risk mitigation, and we’ll return
    to them in [Chapter 8](ch08.html#chapter_8_feature_management_and_experimentation_1749354011197288).
  prefs: []
  type: TYPE_NORMAL
- en: Rolling back
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We’ve explored a few progressive deployment strategies, but your options are
    innumerable. Variations and hybrid approaches that blend elements of rolling updates,
    blue-green deployments, canary releases, and feature flags are all possibilities.
    The common thread among these strategies is a controlled rollout, allowing you
    to stop a deployment and roll back to a previous version if you need to. With
    a strategy like blue-green deployments, this is an easy proposition: your previous
    version stands at the ready. With a rolling update or a canary deployment, the
    rollback process is a matter of removing traffic from nodes with the defective
    software and then systematically replacing those nodes with the previous software
    version.'
  prefs: []
  type: TYPE_NORMAL
- en: Rolling back involves not only redeploying the previous stable version of software,
    but also its associated configurations, dependencies, and data. Rolling back to
    a previous state can be as complex or more complex than the deployment itself.
    Certain deployment approaches will facilitate dependable rollbacks. For example,
    if the deployment is idempotent, meaning it can be repeated and achieve the same,
    nondestructive results, a redeploy of a prior version will be equivalent to a
    rollback.
  prefs: []
  type: TYPE_NORMAL
- en: Testing rollbacks is crucial to ensuring you can roll back without fear. It’s
    not enough to simply have a rollback mechanism in place; you need to regularly
    validate its readiness. This involves simulating various failure scenarios and
    then executing the rollback procedure to ensure it swiftly and reliably restores
    the previous stable version. Thorough rollback testing verifies that the application,
    its data, and its dependencies are correctly reverted. Depending on the application
    and its data storage mechanisms, rollbacks may require data restoration or migration
    to ensure data consistency. Regularly test procedures to ensure they work as expected
    in all scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: With complete confidence in your rollback procedures, you can then configure
    rollbacks to trigger automatically based on deployment health. Verifying deployment
    health is a topic we’ll get into in the next section. Instead of relying on manual
    intervention, the system automatically reverts to the previous stable version
    when predefined thresholds are breached. This not only reduces the burden on your
    operations team but also takes human error out of the equation to minimize downtime.
  prefs: []
  type: TYPE_NORMAL
- en: Special considerations for specific architectures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deployment and rollback complexities vary significantly depending on the software
    architecture. Monoliths, with their tightly coupled codebase, often require complete
    deployments and rollbacks that impact the entire system. Microservices, on the
    other hand, offer more granular deployments and rollbacks, targeting individual
    services. However, this interconnectedness means that dependencies must be carefully
    managed to ensure consistency across services. Distributed monoliths share characteristics
    of both monolithic architecture and microservices and combine the deployment complexities
    of microservices with the interdependency issues of monoliths.
  prefs: []
  type: TYPE_NORMAL
- en: Databases add another layer of complexity. When updates involve breaking changes
    to the structure of persistent data, strategies like “expand and contract” are
    needed. This strategy involves adding new database fields or tables alongside
    the existing ones, deploying the updated application to utilize the new structure,
    and eventually phasing out the old fields. The approach is complex to implement,
    but it is often required to ensure data integrity when supporting progressive
    deployment strategies and clean rollbacks.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing the Right Tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Armed with a progressive deployment strategy and robust rollback capabilities,
    you can deploy to production with confidence. But to truly unlock the power of
    these strategies, you need the right tools at your disposal. Modern deployment
    tools make all the difference, offering seamless support for progressive deployment
    strategies out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: When selecting a tool to orchestrate your software deployments, it’s essential
    to look beyond the basics and consider how well a given tool aligns with your
    specific needs. If you’re planning a transition to automated deployment decisions
    alongside adopting new continuous delivery tools, understanding all the factors
    that go into your promotion decisions up front will help you choose the right
    tool with the required governance and gate capabilities. In addition, ensure that
    the deployment tool seamlessly integrates with your target environments, whether
    it’s the cloud, on-premise servers, or a hybrid setup. Equally important is the
    tool’s ability to handle your specific application types and architectures, including
    any complex database deployments or coordinated multiservice releases.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond infrastructure and architecture compatibility, the deployment tool should
    include out-of-the-box support for your preferred progressive deployment strategies,
    ensuring you can easily implement canary releases, rolling updates, or other techniques.
    Robust rollback mechanisms should be a first-class concern, because they allow
    you to quickly revert to a previous stable version in case of unexpected issues.
    Furthermore, consider whether the tool integrates with your existing feature flag
    management system or offers its own feature flagging capabilities, giving you
    granular control over feature releases.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying Production Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even the most diligent governance doesn’t eliminate the need for robust practices
    to systematically verify your production deployments. In this section we’ll look
    at the role of observability. We’ll discuss modernizing your verification processes
    and look at testing strategies specific to production deployment verifications.
  prefs: []
  type: TYPE_NORMAL
- en: Observability in Deployments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Verifying your deployment starts with observability. [Observability](https://oreil.ly/94AtC)
    simply refers to the ability to understand a system’s internal state by examining
    its external outputs. Observability gets you from knowing that something is wrong
    to understanding why it’s wrong, which enables faster troubleshooting and more
    effective root cause analysis. Observability data encompasses three key pillars:'
  prefs: []
  type: TYPE_NORMAL
- en: Metrics
  prefs: []
  type: TYPE_NORMAL
- en: These provide quantitative measurements of system performance, such as response
    times, error rates, and resource utilization. By tracking trends and anomalies
    in these metrics, teams can quickly identify potential issues and assess the impact
    of a new deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Logs
  prefs: []
  type: TYPE_NORMAL
- en: Logs offer detailed records of events and errors occurring within the application
    and its infrastructure. Analyzing log data helps pinpoint the root cause of problems
    and understand the sequence of events leading to an issue.
  prefs: []
  type: TYPE_NORMAL
- en: Traces
  prefs: []
  type: TYPE_NORMAL
- en: Traces provide a visual representation of how requests flow through the system,
    highlighting bottlenecks, latency issues, and dependencies between different services.
    This helps identify performance issues and optimize application architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Modernizing the War Room
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Traditional deployment verification often resembles a high-stakes war room scenario
    with engineers monitoring dashboards and logs, ready to manually intervene at
    the first sign of trouble. The process is highly manual, relying on human interpretation
    of observability data. It is also reactive, with teams often only scrambling to
    address issues after they have impacted users.
  prefs: []
  type: TYPE_NORMAL
- en: This approach is not only stressful and inefficient but also prone to misses
    and slow response times. Moreover, it often leads to inconsistent verification
    procedures and limited visibility into the root cause of issues.
  prefs: []
  type: TYPE_NORMAL
- en: Modernizing deployment verification involves automating these manual tasks and
    human decisions. Instead of relying on engineers to monitor dashboards and logs,
    automated systems take over, continuously analyzing telemetry data and triggering
    alerts when anomalies are detected. The shift from reactive to proactive monitoring
    reduces the need for human intervention and accelerates response times.
  prefs: []
  type: TYPE_NORMAL
- en: The trick to achieve this automation is to integrate your deployment tools with
    your observability platforms. The integration can take different forms depending
    on the tools used. In one approach, your CI/CD tool notifies the observability
    platform when a deployment is in progress, providing a “hook” that can be used
    to trigger a rollback. The observability platform then analyzes telemetry data
    and decides whether to initiate a rollback, calling the hook provided by the CD
    tool.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, CD tools like Harness can be configured to watch one or more
    observability tools for signs of trouble during the deployment process. If issues
    are detected, the CD tool can automatically trigger its own rollback mechanism,
    halting the deployment and reverting to a previous stable version. This tight
    integration between deployment and observability tools enables a seamless and
    automated verification process, minimizing downtime and ensuring faster feedback
    loops.
  prefs: []
  type: TYPE_NORMAL
- en: In either case, the industry no longer tolerates outages and seeks to detect
    indicators that trouble is brewing before an application fails. As a result, AI/ML
    is used to analyze multiple data sources to identify anomalies that indicate a
    likelihood of failure. AI anomaly detection has become a central component in
    modern deployment verification. Unlike traditional monitoring, which relies on
    predefined thresholds, these systems build statistical models of normal application
    behavior across hundreds of metrics and can detect complex, multidimensional anomalies
    that would be impossible to define with static rules. This capability is particularly
    valuable during the critical minutes following a production deployment, when subtle
    performance issues might otherwise go unnoticed until they escalate into user-impacting
    incidents.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment verification systems integrate these AI capabilities into automated
    verification gates, providing continuous assessment throughout the deployment
    process rather than point-in-time checks. When anomalies are detected, these systems
    can automatically pause progressive rollouts, or even automatically trigger the
    rollback process.
  prefs: []
  type: TYPE_NORMAL
- en: Testing Production Deployments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discussed testing at length in [Chapter 4](ch04.html#chapter_4_deploying_to_test_environments_1749354010445896).
    We return now to look at test strategies particularly suited to verifying in production.
    Verifying production deployments requires a layered testing approach.
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic testing can be paired with phased or progressive deployments. By simulating
    typical user interactions and transactions in a production environment, synthetic
    tests run through scenarios to catch issues quickly. This allows teams to address
    problems early on, either by rolling back the deployment or by implementing necessary
    fixes.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the initial deployment phase, ongoing testing in production is essential
    for ensuring long-term stability and performance. Synthetic testing continues
    to play a valuable role, providing continuous monitoring of critical user journeys
    and identifying any regressions or performance degradations. Chaos engineering,
    which we covered in [Chapter 6](ch06.html#chapter_6_chaos_engineering_and_service_reliability_1749354010916149),
    takes this a step further by deliberately injecting failures into the system to
    test its resilience and ability to recover.
  prefs: []
  type: TYPE_NORMAL
- en: Another important aspect of ongoing testing is progressive feature disclosure.
    This involves gradually rolling out new features to a subset of users, allowing
    teams to gather feedback and monitor performance before a full release. Techniques
    like A/B testing enable comparisons between different versions of a feature, helping
    identify the most effective implementation. This controlled approach to feature
    releases minimizes risk and allows for data-driven decisions based on real user
    behavior. By combining synthetic testing, chaos engineering, and progressive feature
    disclosure, organizations can establish a comprehensive testing strategy that
    ensures continuous verification and improvement of their production deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As AI continues to transform production deployments, the connection between
    deployment strategies and feature management becomes increasingly important. AI-powered
    deployment verification systems don’t just monitor overall application health;
    they can now track the impact of individual features within a deployment, providing
    granular insights that inform both rollback decisions and future feature releases.
    These systems create a continuous feedback loop where deployment data feeds into
    feature flag decisions, and feature behavior informs deployment strategies. Modern
    platforms analyze feature performance patterns across deployments to recommend
    which features should be gradually released through feature flags versus those
    that can be safely deployed traditionally. This intelligence helps teams balance
    development velocity with operational stability, creating a more sophisticated
    approach to managing both deployments and features in production environments.
    In [Chapter 8](ch08.html#chapter_8_feature_management_and_experimentation_1749354011197288),
    we will focus in depth on feature management.
  prefs: []
  type: TYPE_NORMAL
