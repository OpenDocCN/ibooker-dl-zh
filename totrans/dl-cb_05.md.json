["```py\n05.1 Generating Text in the Style of an Example Text\n```", "```py\nshakespeare = load_etext(100)\nshakespeare = strip_headers(shakespeare)\n```", "```py\ncache = get_metadata_cache()\ncache.populate()\n```", "```py\nfor text_id in get_etexts('author', 'Shakespeare, William'):\n    print(text_id, list(get_metadata('title', text_id))[0])\n```", "```py\nshakespeare = strip_headers(load_etext(100))\nplays = shakespeare.split('\\nTHE END\\n', 1)[-1]\n```", "```py\nchars = list(sorted(set(plays)))\nchar_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n```", "```py\ndef char_rnn_model(num_chars, num_layers, num_nodes=512, dropout=0.1):\n    input = Input(shape=(None, num_chars), name='input')\n    prev = input\n    for i in range(num_layers):\n        prev = LSTM(num_nodes, return_sequences=True)(prev)\n    dense = TimeDistributed(Dense(num_chars, name='dense',\n                                  activation='softmax'))(prev)\n    model = Model(inputs=[input], outputs=[dense])\n    optimizer = RMSprop(lr=0.01)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizer, metrics=['accuracy'])\n    return model\n```", "```py\ndef data_generator(all_text, num_chars, batch_size):\n    X = np.zeros((batch_size, CHUNK_SIZE, num_chars))\n    y = np.zeros((batch_size, CHUNK_SIZE, num_chars))\n    while True:\n        for row in range(batch_size):\n            idx = random.randrange(len(all_text) - CHUNK_SIZE - 1)\n            chunk = np.zeros((CHUNK_SIZE + 1, num_chars))\n            for i in range(CHUNK_SIZE + 1):\n                chunk[i, char_to_idx[all_text[idx + i]]] = 1\n            X[row, :, :] = chunk[:CHUNK_SIZE]\n            y[row, :, :] = chunk[1:]\n        yield X, y\n```", "```py\nmodel.fit_generator(\n    data_generator(plays, len(chars), batch_size=256),\n    epochs=10,\n    steps_per_epoch=2 * len(plays) / (256 * CHUNK_SIZE),\n    verbose=2\n)\n```", "```py\ndef generate_output(model, start_index=None, diversity=1.0, amount=400):\n    if start_index is None:\n        start_index = random.randint(0, len(plays) - CHUNK_SIZE - 1)\n    fragment = plays[start_index: start_index + CHUNK_SIZE]\n    generated = fragment\n    for i in range(amount):\n        x = np.zeros((1, CHUNK_SIZE, len(chars)))\n        for t, char in enumerate(fragment):\n            x[0, t, char_to_idx[char]] = 1.\n        preds = model.predict(x, verbose=0)[0]\n        preds = np.asarray(preds[len(generated) - 1])\n        next_index = np.argmax(preds)\n        next_char = chars[next_index]\n\n        generated += next_char\n        fragment = fragment[1:] + next_char\n    return generated\n\nfor line in generate_output(model).split('\\n'):\n    print(line)\n```", "```py\nFOURTH CITIZEN. They were all the summer hearts.\n  The King is a virtuous mistress.\nCLEOPATRA. I do not know what I have seen him damn'd in no man\n  That we have spoken with the season of the world,\n  And therefore I will not speak with you.\n  I have a son of Greece, and my son\n  That we have seen the sea, the seasons of the world\n  I will not stay the like offence.\n```", "```py\nOLIVIA. If it be aught and servants, and something\n  have not been a great deal of state)) of the world, I will not stay\n  the forest was the fair and not by the way.\nSECOND LORD. I will not serve your hour.\nFIRST SOLDIER. Here is a princely son, and the world\n  in a place where the world is all along.\nSECOND LORD. I will not see thee this:\n  He hath a heart of men to men may strike and starve.\n  I have a son of Greece, whom they say,\n  The whiteneth made him like a deadly hand\n  And make the seasons of the world,\n  And then the seasons and a fine hands are parted\n  To the present winter's parts of this deed.\n  The manner of the world shall not be a man.\n  The King hath sent for thee.\n  The world is slain.\n```", "```py\ndef find_python(rootdir):\n    matches = []\n    for root, dirnames, filenames in os.walk(rootdir):\n        for fn in filenames:\n            if fn.endswith('.py'):\n                matches.append(os.path.join(root, fn))\n\n    return matches\nsrcs = find_python(random.__file__.rsplit('/', 1)[0])\n```", "```py\nCOMMENT_RE = re.compile('#.*')\nsrc = COMMENT_RE.sub('', src)\n```", "```py\ndef replacer(value):\n    if ' ' in value and sum(1 for ch in value if ch.isalpha()) > 6:\n        return 'MSG'\n    return value\n```", "```py\ndef replace_literals(st):\n    res = []\n    start_text = start_quote = i = 0\n    quote = ''\n    while i < len(st):\n        if quote:\n            if st[i: i + len(quote)] == quote:\n                quote = ''\n                start_text = i\n                res.append(replacer(st[start_quote: i]))\n        elif st[i] in '\"\\'':\n            quote = st[i]\n            if i < len(st) - 2 and st[i + 1] == st[i + 2] == quote:\n                quote = 3 * quote\n            start_quote = i + len(quote)\n            res.append(st[start_text: start_quote])\n        if st[i] == '\\n' and len(quote) == 1:\n            start_text = i\n            res.append(quote)\n            quote = ''\n        if st[i] == '\\\\':\n            i += 1\n        i += 1\n    return ''.join(res) + st[start_text:]\n```", "```py\ndef generate_code(model, start_with='\\ndef ',\n                  end_with='\\n\\n', diversity=1.0):\n    generated = start_with\n    yield generated\n    for i in range(2000):\n        x = np.zeros((1, len(generated), len(chars)))\n        for t, char in enumerate(generated):\n            x[0, t, char_to_idx[char]] = 1.\n        preds = model.predict(x, verbose=0)[0]\n\n        preds = np.asarray(preds[len(generated) - 1]).astype('float64')\n        preds = np.log(preds) / diversity\n        exp_preds = np.exp(preds)\n        preds = exp_preds / np.sum(exp_preds)\n        probas = np.random.multinomial(1, preds, 1)\n        next_index = np.argmax(probas)\n        next_char = chars[next_index]\n        yield next_char\n\n        generated += next_char\n        if generated.endswith(end_with):\n            break\n```", "```py\ndef _calculate_ratio(val):\n    \"\"\"MSG\"\"\"\n    if value and value[0] != '0':\n        raise errors.HeaderParseError(\n            \"MSG\".format(Storable))\n    return value\n```", "```py\nflat_model = char_rnn_model(len(py_chars), num_layers=1, num_nodes=512)\n```", "```py\ndef activations(model, code):\n    x = np.zeros((1, len(code), len(py_char_to_idx)))\n    for t, char in enumerate(code):\n        x[0, t, py_char_to_idx[char]] = 1.\n    output = model.get_layer('lstm_3').output\n    f = K.function([model.input], [output])\n    return f([x])[0][0]\n```", "```py\nimg = np.full((len(neurons) + 1, len(code), 3), 128)\nscores = (act[:, neurons].T + 1) / 2\nimg[1:, :, 0] = 255 * (1 - scores)\nimg[1:, :, 1] = 255 * scores\n```"]