- en: Chapter 9\. Securing AI Services
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In earlier chapters, you learned how to build GenAI services that serve various
    AI generators while supporting concurrency and data streaming in real time. Additionally,
    you integrated external systems like databases and implemented your own authentication
    and authorization mechanisms. Finally, you wrote a test suite to verify the functionality
    and performance of your entire system.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you’ll learn how to implement usage moderation and abuse-protection
    mechanisms to secure your GenAI services.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Usage Moderation and Abuse Protection
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When deploying your GenAI services, you’ll need to consider how your services
    will be misused and abused by malicious users. This is essential to protect user
    safety and your own reputation. You won’t know how the users will use your system,
    so you need to assume the worst and implement *guardrails* to protect against
    any misuse or abuse.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: According to a [recent study on nefarious applications of GenAI](https://oreil.ly/ihmzR),
    your services may potentially be used with *malicious intents*, as described in
    [Table 9-1](#malicious_intents).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Table 9-1\. Malicious intents behind abusing GenAI services
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '| Intent | Examples | Real-world cases |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
- en: '| **Dishonesty**Supporting lies and untruthfulness | Plagiarism, faking competency
    and knowledge, document forgery, cheating in exams and in interviews, etc. | Increasing
    cases of students cheating with AI at UK and Australian universities^([a](ch09.html#id1032))
    |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
- en: '| **Propaganda**Skewing perceptions of reality to advance an agenda | Impersonating
    others, promoting extremism, influencing campaigns, etc. | Fake AI news anchors
    spreading misinformation or propaganda^([b](ch09.html#id1033)) |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
- en: '| **Deception**Misleading others and creating false impressions | Generating
    fake reviews, scam ads and phishing emails, and synthetic profiles (i.e., sockpuppeting),
    etc. | Engineering firm Arup revealed as a victim of a $25 million deepfake scam^([c](ch09.html#id1034))
    |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
- en: '| ^([a](ch09.html#id1032-marker)) Sources: *Times Higher Education* and *The
    Guardian*^([b](ch09.html#id1033-marker)) Sources: *The Guardian*, *MIT Technology
    Review*, and *The Washington Post*^([c](ch09.html#id1034-marker)) Sources: CNN
    and *The Guardian* |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
- en: 'The same study categorizes GenAI application abuse into the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '*Misinformation and disinformation* to spread propaganda and fake news'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Bias amplification and discrimination* to advance racist agendas and societal
    discrimination'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Malicious content generation* by creating toxic, deceptive, and radicalizing
    content'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data privacy attacks* to fill in gaps in stolen private data and leak sensitive
    information'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Automated cyberattacks* to personalize phishing and ransomware attacks'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Identity theft and social engineering* to increase the success rate of scams'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deepfakes and multimedia manipulation* to make a profit and skew perceptions
    of reality and social beliefs'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Scam and fraud* by manipulating stock markets and crafting targeted scams'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*诈骗和欺诈* 通过操纵股市和制定有针对性的诈骗'
- en: This may not be an exhaustive list but should give you a few ideas on what usage
    moderation measures to consider.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能不是一份详尽的清单，但它应该能给您一些关于考虑哪些使用监管措施的思路。
- en: '[Another study on the taxonomy of GenAI misuse tactics](https://oreil.ly/jbG01)
    investigated abuse by modality and found that:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[关于GenAI滥用策略分类法的另一项研究](https://oreil.ly/jbG01)调查了按模式进行的滥用，并发现：'
- en: '*Audio and video generators* were used for the majority of impersonation attempts.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*音频和视频生成器* 被用于大多数模仿尝试。'
- en: '*Image and text generators* were used for the majority of sockpuppeting, content
    farming for opinion manipulation at scale, and falsification attempts.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图像和文本生成器* 被用于大多数假身份尝试、大规模意见操纵的内容农场和伪造尝试。'
- en: '*Image and video generators* were used for the majority of steganography, (i.e.,
    hiding coded messages in model outputs), and nonconsensual intimate content (NCII)
    generation attempts.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图像和视频生成器* 被用于大多数隐写术尝试（即在模型输出中隐藏编码信息）和非自愿亲密内容（NCII）生成尝试。'
- en: If you’re building services supporting such modalities, you should consider
    their associated forms of abuse and implement relevant protection mechanisms.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在构建支持此类模式的服务，您应该考虑其相关的滥用形式并实施相关保护机制。
- en: Aside from misuse and abuse, you’ll also need to consider security vulnerabilities.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 除了滥用和误用之外，您还需要考虑安全漏洞。
- en: Securing GenAI services is still an area of research at the time of writing.
    For instance, if your services leverage LLMs, OWASP has categorized the [top 10
    LLM vulnerabilities](https://oreil.ly/4zob2), as shown in [Table 9-2](#llm_vulnerabilities).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，确保GenAI服务仍然是一个研究领域。例如，如果您的服务利用LLM，OWASP已将[前10大LLM漏洞](https://oreil.ly/4zob2)分类，如[表9-2](#llm_vulnerabilities)所示。
- en: Table 9-2\. OWASP top 10 LLM vulnerabilities
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 表9-2\. OWASP前10大LLM漏洞
- en: '| Risk | Description |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 风险 | 描述 |'
- en: '| --- | --- |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Prompt injection | Manipulating inputs to control the LLM’s responses leading
    to unauthorized access, data breaches, and compromised decision-making. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 提示注入 | 操作输入以控制LLM的响应，导致未经授权的访问、数据泄露和决策受损。|'
- en: '| Insecure output handling | Failing to sanitize or validate LLM outputs causing
    remote code execution on downstream systems. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 不安全的输出处理 | 未对LLM的输出进行清理或验证，导致下游系统上的远程代码执行。|'
- en: '| Training data poisoning | Injecting data in sources that models get trained
    on to compromise security, accuracy, or ethical behavior. Open source models and
    RAG services that rely on web data are most prone to these attacks. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 训练数据中毒 | 在模型训练的数据源中注入数据，以损害安全性、准确性或道德行为。开源模型和依赖网络数据的RAG服务最容易受到这些攻击。|'
- en: '| Model denial of service | Causing service disruption and cost explosions
    by overloading the LLMs with heavy payloads and concurrent requests. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 模型拒绝服务 | 通过向LLM加载大量有效载荷和并发请求，导致服务中断和成本激增。|'
- en: '| Supply chain vulnerabilities | Causing various components, including data
    sources, to be compromised, undermining system integrity. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 供应链漏洞 | 导致各种组件，包括数据源，被破坏，损害系统完整性。|'
- en: '| Sensitive information leakage | Leading to accidental exposure of private
    data, legal liabilities and loss of competitive advantage. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 敏感信息泄露 | 导致私人数据意外泄露，法律责任和竞争优势丧失。|'
- en: '| Insecure plug-in design | Vulnerabilities in third-party integrations cause
    remote code execution. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 不安全的插件设计 | 第三方集成中的漏洞导致远程代码执行。|'
- en: '| Excessive agency | Where LLMs have too much autonomy to take actions can
    lead to unintended consequences and harmful actions. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 过度代理 | 当LLM有太多自主权采取行动时，可能导致意外后果和有害行为。|'
- en: '| Overreliance on LLM | Compromising decision-making, contributing to security
    vulnerabilities and legal liabilities. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 过度依赖LLM | 危害决策，导致安全漏洞和法律责任。|'
- en: '| Model theft | Related to unauthorized copying or usage of your models. |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 模型盗窃 | 与未经授权复制或使用您的模型相关。|'
- en: Tip
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Similar vulnerabilities exist for other types of GenAI systems such as image,
    audio, video, and geometry generators.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他类型的GenAI系统，如图像、音频、视频和几何生成器，也存在类似的安全漏洞。
- en: I recommend researching and identifying software vulnerabilities relevant to
    your own use cases.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议研究和识别与您自己的用例相关的软件漏洞。
- en: Without guardrails, your services can be abused to cause personal and financial
    harm, identity theft, economic damage, spread misinformation, and contribute to
    societal problems. As a result, it’s crucial to implement several safety measures
    and guardrails to protect your services against such attacks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you’ll learn usage moderation and security measures you
    can implement to protect your GenAI services prior to deployment.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Guardrails
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Guardrails* refer to *detective controls* that aim to guide your application
    toward the intended outcomes. They are incredibly diverse and can be configured
    to fit any situation that may go wrong with your GenAI systems.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: As an example, *I/O guardrails* are designed to verify data entering a GenAI
    model and outputs sent to the downstream systems or users. Such guardrails can
    flag inappropriate user queries and validate output content against toxicity,
    hallucinations, or banned topics. [Figure 9-1](#guardrails) shows how an LLM system
    looks once you add I/O guardrails to it.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![bgai 0901](assets/bgai_0901.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: Figure 9-1\. Comparison of an LLM system without and with guardrails
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You don’t have to implement guardrails from scratch. At the time of writing,
    prebuilt open source guardrail frameworks exist like NVIDIA NeMo Guardrails, LLM-Guard,
    and Guardrails AI to protect your services. However, they may require learning
    framework-related languages and have a trade-off of slowing down your services
    and bloating your application due to various external dependencies.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Other commercial guardrails available on the market, such as Open AI’s Moderation
    API, Microsoft Azure AI Content Safety API, and Google’s Guardrails API are either
    not open source or lack details and contents to measure quality constraints.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Guardrails remain an active area of research. While such defenses can counter
    some attacks, powerful attacks backed by AI can still bypass them. This may lead
    to an [ongoing and endless loop of assaults and defenses](https://oreil.ly/xlUmw).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: While engineering application-level I/O guardrails may not provide perfect protection,
    upcoming GenAI models may include baked-in guardrails inside the model to improve
    security guarantees. However, such guardrails may have a performance impact on
    response times by introducing latency to the system.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Input Guardrails
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The purpose of input guardrails is to prevent malicious or inappropriate content
    from reaching your model. [Table 9-3](#guardrails_input) shows common input guardrails.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: Table 9-3\. Common input guardrails
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '| Input guardrails | Examples |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
- en: '| **Topical**Steer inputs away from off-topic or sensitive content. | Preventing
    a user from discussing political topics and explicit content. |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
- en: '| **Direct prompt injection** (jail-breaking)Prevent users from revealing or
    overriding system prompts and secrets. The longer the input content, the more
    prone your system will be to these attacks. | Blocking attempts to override system
    prompts and manipulating the system into revealing internal API keys or configuration
    settings.^([a](ch09.html#id1036)) |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
- en: '| **Indirect prompt injection**Prevent acceptance of malicious content from
    external sources such as files or websites that may cause model confusion or remote
    code execution on downstream systems.Malicious content may be invisible to the
    human eye and encoded within input text or images. | Sanitizing encoded payloads
    in upload images, hidden characters or prompt overrides in uploaded documents,
    hidden scripts in remote URLs or even YouTube video transcripts. |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
- en: '| **Moderation**Comply with brand guidelines, legal, and branding requirements.
    | Flag and refuse invalid user queries if user queries include mentions of profanity,
    competitor, explicit content, personally identifiable information (PII), self-harm,
    etc. |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
- en: '| **Attribute**Validate input properties. | Check query length, file size,
    choices, range, data format and structure, etc. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
- en: '| ^([a](ch09.html#id1036-marker)) Although guardrails are useful, best practice
    is to avoid giving your GenAI models direct knowledge of secrets or sensitive
    configuration settings in the first place. |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: The input guardrails can also be combined with content sanitizers to clean bad
    inputs.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: If you want to implement your own guardrails, you can start off with using advanced
    prompt engineering techniques within your system prompts. Additionally, you can
    use auto-evaluation techniques, (i.e., AI models).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 9-1](#guardrail_topical_prompt) shows an example system prompt for
    an AI guardrail auto-evaluator to reject off-topic queries.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Example 9-1\. Topical input guardrail system prompt
  id: totrans-72
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You can see an implementation of an input topical guardrail in [Example 9-2](#guardrail_topical)
    using the LLM auto-evaluation technique.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Example 9-2\. Topical input guardrail
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_securing_ai_services_CO1-1)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Handle cases where the LLM doesn’t return a valid classification
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Using the technique shown in [Example 9-2](#guardrail_topical), you can implement
    auto-evaluators to check for jail-breaking and prompt injection attempts or even
    detect the presence of PII and profanity in the inputs.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: As discussed in [Chapter 5](ch05.html#ch05), you can leverage async programming
    as much as possible even when using auto-evaluation techniques in your guardrails.
    This is because AI guardrails require sending multiple model API calls per user
    query. To improve user experience, you can run these guardrails in parallel to
    the model inference process.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Once you have an auto-evaluator guardrail for checking allowed topics, you can
    execute it in parallel to your data generation^([1](ch09.html#id1037)) using `asyncio.wait`,
    as shown in [Example 9-3](#guardrail_concurrent_execution).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Be mindful that implementing async guardrails may trigger model provider API
    rate-limiting and throttling mechanisms. Depending on your application requirements,
    you may want to request higher rate limits or reduce the rate of API calls within
    a short time frame.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，实现异步防护栏可能会触发模型提供者API的速率限制和节流机制。根据您的应用需求，您可能需要请求更高的速率限制或在短时间内减少API调用的频率。
- en: Example 9-3\. Running AI guardrails in parallel to response generation
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例9-3\. 并行运行AI防护栏以生成响应
- en: '[PRE2]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_securing_ai_services_CO2-1)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_securing_ai_services_CO2-1)'
- en: Create two asyncio tasks to run in parallel using `asyncio.wait`. The operation
    returns as soon as a task is completed.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`asyncio.wait`创建两个并行运行的asyncio任务。操作会在任一任务完成时返回。
- en: '[![2](assets/2.png)](#co_securing_ai_services_CO2-2)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_securing_ai_services_CO2-2)'
- en: If the guardrail is triggered, cancel the chat operation and return a hard-coded
    response. You can log the trigger in a database and send notification emails here.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果触发防护栏，取消聊天操作并返回硬编码的响应。您可以在数据库中记录触发事件并发送通知电子邮件。
- en: '[![3](assets/3.png)](#co_securing_ai_services_CO2-3)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_securing_ai_services_CO2-3)'
- en: Keep checking in with the asyncio event loop every 100 ms until a task is done.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 每100毫秒检查一次asyncio事件循环，直到任务完成。
- en: '[![4](assets/4.png)](#co_securing_ai_services_CO2-4)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_securing_ai_services_CO2-4)'
- en: Leverage dependency injection to return the model response if guardrails aren’t
    triggered.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有触发防护栏，利用依赖注入返回模型响应。
- en: Since GenAI-enabled guardrails like those you implemented in [Example 9-3](#guardrail_concurrent_execution)
    remain probabilistic, your GenAI services can still be vulnerable to prompt injection
    and jail-breaking attacks. For instance, attackers can use more advanced prompt
    injection techniques to get around your AI guardrails too. On the other hand,
    your guardrails may also incorrectly over-refuse valid user queries, leading to
    false positives that can downgrade your user experience.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 由于像在[示例9-3](#guardrail_concurrent_execution)中实现的GenAI启用防护栏仍然是概率性的，您的GenAI服务仍然可能容易受到提示注入和越狱攻击。例如，攻击者可以使用更高级的提示注入技术来绕过您的AI防护栏。另一方面，您的防护栏也可能错误地过度拒绝有效用户查询，导致假阳性，从而降低用户体验。
- en: Tip
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Combining guardrails with rules-based or traditional machine learning models
    for detection can help mitigate some of the aforementioned risks.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 将防护栏与基于规则的或传统的机器学习模型结合用于检测可以帮助减轻一些上述风险。
- en: Additionally, you can use guardrails that only consider the latest message to
    reduce the risk of the model being confused by a long conversation.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还可以使用仅考虑最新消息的防护栏来降低模型被长时间对话所混淆的风险。
- en: When designing guardrails, you need to consider trade-offs between *accuracy*,
    *latency*, and *cost* to balance user experience with your required security controls.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计防护栏时，您需要考虑*准确性*、*延迟*和*成本*之间的权衡，以平衡用户体验与您所需的安全控制。
- en: Output Guardrails
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出防护栏
- en: The purpose of output guardrails is to validate GenAI-produced content before
    it’s passed to users or downstream systems. [Table 9-4](#guardrails_output) shows
    common output guardrails.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 输出防护栏的目的是在内容传递给用户或下游系统之前验证由GenAI生成的内容。[表9-4](#guardrails_output)显示了常见的输出防护栏。
- en: Table 9-4\. Common output guardrails
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 表9-4\. 常见输出防护栏
- en: '| Output guardrails | Examples |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 输出防护栏 | 示例 |'
- en: '| --- | --- |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Hallucination/fact-checking**Block hallucinations and return canned responses
    such as “I don’t know.” | Measuring metrics such as *relevancy*, *coherence*,
    *consistency*, *fluency*, etc., on the model outputs against a corpus of ground
    truth in RAG applications. |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| **幻觉/事实核查**阻止幻觉并返回如“我不知道”之类的标准响应 | 在RAG应用中，在真实数据集的语料库上对模型输出进行如*相关性*、*连贯性*、*一致性*、*流畅性*等指标的测量。|'
- en: '| **Moderation**Apply brand and corporate guidelines to govern the model outputs,
    either filtering or rewriting responses that breach them. | Checking against metrics
    such as *readability*, *toxicity*, *sentiment*, *count of competitor mentions*,
    etc. |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| **审查**应用品牌和公司指南来管理模型输出，过滤或重写违反这些指南的响应。 | 与如*可读性*、*毒性*、*情感*、*竞争对手提及次数*等指标进行核对。|'
- en: '| **Syntax checks**Verify the structure and content of model outputs. These
    guardrails can either detect and retry or gracefully handle exceptions to prevent
    failures in the downstream systems. | Validating JSON schemas and function parameters
    in *function calling* workflows when models invoke functions.Checking tool/agent
    selections in *agentic workflows*. |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
- en: Any of the aforementioned output guardrails will rely on *threshold value* to
    detect invalid responses.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Guardrail Thresholds
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Guardrails can use various metrics such as *readability*, *toxicity*, etc.,
    to measure and validate the quality of the model outputs. For each metric, you’ll
    need to experiment to identify the appropriate *threshold value* for your use
    case, bearing in mind that:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: More *false positives* can annoy your users and reduce the usability of your
    services.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More *false negatives* can cause lasting harm to your reputation and explode
    costs since malicious users can abuse the system or perform prompt injection/jail-breaking
    attacks.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Normally, you should assess the risks and worst cases of having false negatives
    and whether you’re happy to trade off a few false negatives in your use case for
    enhanced user experience. For instance, you can reduce instances of blocking outputs
    if they include more jargon and aren’t as readable.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a Moderation Guardrail
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s implement a moderation guardrail using a version of the [*G-Eval* evaluation
    method](https://oreil.ly/7Nent) to measure the presence of unwanted content in
    the model output.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'The G-Eval framework uses the following components to score invalid content:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: A *domain* name specifying the type of content to be moderated
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of *criteria* to clearly outline what is considered valid versus invalid
    content
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An ordered list of *instruction steps* for grading the content
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *content* to grade between a discrete score of 1 to 5
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Example 9-4](#guardrail_moderation_prompt) shows a system prompt implementing
    the *G-Eval* framework that an LLM auto-evaluator will use.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Example 9-4\. Moderation guardrail system prompt
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Using the system prompt implemented in [Example 9-4](#guardrail_moderation_prompt),
    you can now implement a moderation guardrail following [Example 9-2](#guardrail_topical).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s integrate the moderation guardrail with your existing chat invocation
    logic, as shown in [Example 9-5](#guardrail_moderation).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Example 9-5\. Integrating moderation guardrail
  id: totrans-126
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_securing_ai_services_CO3-1)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Use a Pydantic constrained integer type to validate LLM auto-evaluator G-Eval
    score.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_securing_ai_services_CO3-2)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Flag content that is scored above the threshold as not passing moderation.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_securing_ai_services_CO3-3)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Integrate and run the output moderation guardrail with other guardrails.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-134
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Beyond the novel *G-Eval* framework implemented using an LLM auto-evaluator,
    you can also use more traditional automatic evaluation frameworks such as [ROUGE](https://oreil.ly/_9Q9g),
    [BERTScore](https://oreil.ly/jRTeL), and [SummEval](https://oreil.ly/5YtJG) for
    moderating output content.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用LLM自动评估器实现的创新**G-Eval**框架之外，您还可以使用更传统的自动评估框架，如[ROUGE](https://oreil.ly/_9Q9g)、[BERTScore](https://oreil.ly/jRTeL)和[SummEval](https://oreil.ly/5YtJG)来调节输出内容。
- en: Well done. You have now implemented two I/O guardrails, one to verify topics
    of user queries and another to moderate the LLM outputs.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好。您现在已经实现了两个I/O安全栏，一个用于验证用户查询的主题，另一个用于调节LLM输出。
- en: 'To improve your guardrail system even further, you can:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步提高您的安全栏系统，您可以：
- en: Adopt the *fast failure* approach by exiting early if a guardrail is triggered
    to optimize response times.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采用**快速失败**方法，如果触发安全栏则提前退出，以优化响应时间。
- en: Only select *appropriate guardrails* for your use cases instead of using them
    all together, which could overwhelm your services.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只为您的用例选择**合适的**安全栏，而不是全部一起使用，这可能会压倒您的服务。
- en: Run guardrails *asynchronously* instead of sequentially to optimize latency.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将安全栏**异步**运行而不是顺序运行，以优化延迟。
- en: Implement *request sampling* by running slower guardrails on a sample of requests
    to reduce overall latency when your services are under a heavy load.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在请求样本上运行较慢的安全栏来**实现请求采样**，以减少在服务负载过重时的整体延迟。
- en: You should now feel more confident implementing your own guardrails using classical
    or LLM auto-evaluation techniques without relying on external tools and libraries.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您应该更有信心使用经典或LLM自动评估技术来实施自己的安全栏，而不依赖于外部工具和库。
- en: In the next section, you’ll learn about API rate limiting so that you can protect
    your services against model overloading and scraping attempts.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将了解API速率限制，以便您可以为保护您的服务免受模型过载和抓取尝试而采取行动。
- en: API Rate Limiting and Throttling
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: API速率限制和节流
- en: When deploying GenAI services, you will need to consider service exhaustion
    and model overloading issues in production. Best practice is to implement rate
    limiting and potentially throttling into your services.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署GenAI服务时，您需要考虑生产中的服务耗尽和模型过载问题。最佳实践是在您的服务中实施速率限制和可能的节流。
- en: '*Rate limiting* controls the amount of incoming and outgoing traffic to and
    from a network to prevent abuse, ensure fair usage, and avoid overloading the
    server. On the other hand, *throttling* controls the API throughput by temporarily
    slowing down the rate of request processing to stabilize the server.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**速率限制**控制网络到和从的入出流量，以防止滥用，确保公平使用，并避免服务器过载。另一方面，**节流**通过暂时减慢请求处理速率来控制API吞吐量，以稳定服务器。'
- en: 'Both techniques can help you:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种技术都可以帮助您：
- en: '*Prevent abuse* by blocking malicious users or bots from overwhelming your
    services from data scraping and brute-force attacks that involve too many requests
    or large payloads.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**防止滥用**，通过阻止恶意用户或机器人通过数据抓取和涉及过多请求或大负载的暴力攻击来压倒您的服务。'
- en: '*Enforce fair usage policies* so that capacity is shared among multiple users
    and a handful of users are prevented from monopolizing server resources.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强制执行公平使用政策**，以便多个用户共享容量，并防止少数用户垄断服务器资源。'
- en: '*Maintain server stability* by regulating incoming traffic to maintain consistent
    performance and prevent crashes during peak periods.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过调节入站流量来**维持服务器稳定性**，以保持一致的性能并防止在高峰期崩溃。
- en: To implement rate limiting, you will need to monitor incoming requests within
    a time period and use a queue to balance the load.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现速率限制，您需要在一段时间内监控入站请求，并使用队列来平衡负载。
- en: There are several rate-limiting strategies you can choose from, which are compared
    in [Table 9-5](#rate_limiting_strategies) and shown in [Figure 9-2](#rate_limiting_strategies_comparison).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择几种速率限制策略，这些策略在[表9-5](#rate_limiting_strategies)中进行了比较，并在[图9-2](#rate_limiting_strategies_comparison)中显示。
- en: Table 9-5\. Rate-limiting strategies
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 表9-5\. 速率限制策略
- en: '| Strategy | Benefits | Limitations | Use cases |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 策略 | 利益 | 局限性 | 用例 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **Token Bucket**A list is filled with tokens at a constant rate, and every
    incoming request consumes a token. If there aren’t enough tokens for incoming
    requests, they’ll be rejected. |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| **令牌桶**一个列表以恒定速率填充令牌，每个入站请求消耗一个令牌。如果入站请求没有足够的令牌，它们将被拒绝。|'
- en: Handles temporary bursts and dynamic traffic patterns
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理临时突增和动态流量模式
- en: Granular control over request processing
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Complex to implement | Commonly used in most APIs and services, and interactive
    or event-driven GenAI systems where request rates can be irregular |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
- en: '| **Leaky Bucket**Incoming requests are added to a queue and processed at a
    constant rate to smooth the traffic. If the queue overflows, any new incoming
    requests are rejected. |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
- en: Simple to implement
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintains consistent traffic flow
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Less flexible to dynamic traffic
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: May reject valid requests during sudden spikes
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| Services that require maintaining consistent response times in AI inference
    services |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
- en: '| **Fixed Window**Limits requests within fixed time windows (e.g., 100 requests
    per minute). | Simple to implement | Does not handle burst traffic well |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
- en: Enforcing strict usage policies for expensive AI inferences and API calls
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ideal for free tier users or batch-processing systems with predictable usage
    patterns
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each request is treated equally
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '| **Sliding Window**Counts requests over a rolling time frame. | Provides better
    flexibility, granularity, and burst traffic smoothing |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
- en: More complex to implement
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requires higher memory usage for tracking requests
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Much better at handling burst traffic
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ideal for conversational AI or premium-tier users who expect flexible, high-frequency
    access over time
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![bgai 0902](assets/bgai_0902.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
- en: Figure 9-2\. Comparison of rate-limiting strategies
  id: totrans-180
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now that you’re more familiar with rate-limiting concepts, let’s try to implement
    rate limiting in FastAPI.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Rate Limits in FastAPI
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The fastest approach to add rate limiting within FastAPI is to use a library
    such as `slowapi` that is a wrapper over the `limits` package, supporting most
    of the strategies mentioned in [Table 9-5](#rate_limiting_strategies). First,
    install the `slowapi` library:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Once you’ve installed the `slowapi` package, you can follow [Example 9-6](#rate_limiting_slowapi_configurations)
    to apply global API or endpoint rate limiting. You can also track and limit usage
    per IP address.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-186
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Without configuring an external data store, `slowapi` stores and tracks IP addresses
    in the application memory for rate limiting.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Example 9-6\. Configuring global rate limits
  id: totrans-188
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_securing_ai_services_CO4-1)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Create rate limiter that tracks usage across each IP address and rejects requests
    if they exceed specified limits across the application.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_securing_ai_services_CO4-2)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Add a custom exception handler for rate-limited requests to compute and provide
    waiting times before requests are accepted again.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: With the `limiter` decorator configured, you can now use it on your API handlers,
    as shown in [Example 9-7](#rate_limiting_slowapi).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Example 9-7\. Setting API rate limits for each API handler
  id: totrans-195
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](assets/1.png)](#co_securing_ai_services_CO5-1)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Specify more granular rate limits at endpoint level using a rate-limiting decorator.
    The `limiter` decorator must be ordered last.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_securing_ai_services_CO5-2)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Pass the `Request` object to each controller so that the `slowapi` limiter decorator
    can hook into the incoming request. Otherwise, rate limiting will not function.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_securing_ai_services_CO5-3)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Exclude the `/health` endpoint from rate-limiting logic as cloud providers or
    Docker daemons may ping this endpoint continually to check the status of your
    application.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_securing_ai_services_CO5-4)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: Avoid rate limiting the `/health` endpoint as external systems may frequently
    trigger it to check the current status of your service.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Now that you’ve implemented the rate limits, you can run load tests using the
    `ab` (Apache Benchmarking) CLI tool, as shown in [Example 9-8](#rate_limiting_load_testing).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Example 9-8\. API load testing with Apache Benchmark CLI
  id: totrans-206
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](assets/1.png)](#co_securing_ai_services_CO6-1)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: Send 100 requests with a rate of 2 parallel requests per second.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'Your terminal outputs should show the following:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Your global and local limiting system should now be working as intended based
    on incoming IPs.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: User-based rate limits
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With an IP rate limit, you’re limiting excess usage based on IP, but users can
    get around IP rate limiting by using VPNs, proxies, or rotating IP addresses.
    Instead, you want each user to have a dedicated quota to prevent a single user
    from consuming all available resources. Adding user-based limits can help you
    prevent abuse, as shown in [Example 9-9](#rate_limiting_slowapi_users).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: Example 9-9\. User-based rate limiting
  id: totrans-215
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Your system will now be limiting users based on their account IDs alongside
    their IP addresses.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Rate limits across instances in production
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since you may run multiple instances of your application in production as you
    scale your services, you’ll also want to centralize your usage tracking. Otherwise,
    each instance will provide their own counters to users, and a load balancer distributes
    requests between instances; usage won’t be capped as you’d expect. To rectify
    this issue, you can switch the `slowapi` in-memory storage backend with a centralized
    in-memory database such as Redis, as shown in [Example 9-10](#rate_limiting_slowapi_redis).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To run [Example 9-10](#rate_limiting_slowapi_redis), you will need a Redis
    database to store user API usage data:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Example 9-10\. Adding a centralized usage memory store (Redis) across multiple
    instances
  id: totrans-223
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You now have a working rate-limited API that functions as intended across multiple
    instances.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: You can get around this issue by implementing your own limiter supported by
    the `limits` package instead. Alternatively, you can apply rate limiting via a
    *load balancer*, a *reverse proxy*, or an *API gateway* instead.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Each solution can route requests while performing rate limits, protocol translation,
    and traffic monitoring at an infrastructure layer. Applying rate limiting externally
    may be more suitable for your use case if you don’t require a customized rate-limiting
    logic.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Limiting WebSocket connections
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unfortunately the `slowapi` package also doesn’t support limiting async and
    WebSocket endpoints at the time of writing.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Because WebSocket connections are likely to be long-lived, you may want to limit
    the data transition rate sent over the socket. You can rely on external packages
    such as `fastapi-limiter` to rate limit WebSocket connections, as shown in [Example 9-11](#rate_limiting_websocket).
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Example 9-11\. Rate-limiting WebSocket connections with the `fastapi_limiter`
    package
  id: totrans-231
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](assets/1.png)](#co_securing_ai_services_CO7-1)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Configure the `FastAPILimiter` application lifespan with a Redis storage backend.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_securing_ai_services_CO7-2)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: Configure a WebSocket rate limiter to allow one request per second.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_securing_ai_services_CO7-3)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Use the user’s ID as the unique identifier for rate limiting.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 9-11](#rate_limiting_websocket) shows how to limit the number of active
    WebSocket connections for a given user.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Beyond rate-limiting WebSocket endpoints, you may also want to limit the data
    streaming rate of your GenAI models. Let’s look at how you can throttle real-time
    data streams next.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Throttling Real-Time Streams
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When working with real-time streams, you may need to slow down the streaming
    rate to give clients enough time to consume the stream and improve streaming throughput
    across multiple clients. In addition, throttling can help you manage the network
    bandwidth, server load, and resource utilization.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Applying a *throttle* at the stream generation layer, as shown in [Example 9-12](#throttling_stream),
    is an effective approach to managing throughput if your services are under pressure.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: Example 9-12\. Throttling streams
  id: totrans-244
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_securing_ai_services_CO8-1)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Set a fixed throttling rate or dynamically adjust based on usage.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_securing_ai_services_CO8-2)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Slow down the streaming rate without blocking the event loop.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: You can then use the throttled stream within an SSE or WebSocket endpoint. Or,
    you can limit the number of active WebSocket connections per your own custom policies.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: Alongside the application-level throttling for real-time streams, you can also
    leverage *traffic shaping* at the infrastructure layer.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: Using safeguards, rate limits, and throttles should provide enough barriers
    in protecting your services from abuse and misuse.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you’ll learn more about optimization techniques that can
    help you reduce latency, increase response quality, and throughput alongside reducing
    the costs of your GenAI services.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provided a comprehensive summary of attack vectors for GenAI services
    and how to safeguard them against adversarial attempts, misuse, and abuse.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: You learned to implement input and output guardrails alongside evaluation and
    content filtering mechanisms to moderate service usage. Alongside guardrails,
    you also developed API rate-limiting and throttling protections to manage server
    load and prevent abuse.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will learn about optimizing AI services through various
    techniques such as caching, batch processing, model quantizing, prompt engineering,
    and model fine-tuning.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习通过各种技术优化 AI 服务，例如缓存、批量处理、模型量化、提示工程和模型微调。
- en: ^([1](ch09.html#id1037-marker)) Inspired by [OpenAI Cookbook’s “How to Implement
    LLM Guardrails”](https://oreil.ly/UQV6i).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch09.html#id1037-marker)) 受到[《OpenAI 烹饪手册》中的“如何实现 LLM 防护栏”](https://oreil.ly/UQV6i)的启发。
