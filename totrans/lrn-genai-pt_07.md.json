["```py\n!pip install pandas albumentations\n```", "```py\nimport pandas as pd\nimport os, shutil\n\ndf=pd.read_csv(\"files/list_attr_celeba.csv\")         ①\nos.makedirs(\"files/black\", exist_ok=True)  \nos.makedirs(\"files/blond\", exist_ok=True)            ②\nfolder=\"files/img_align_celeba/img_align_celeba\"\nfor i in range(len(df)):\n    dfi=df.iloc[i]\n    if dfi['Black_Hair']==1:                         ③\n        try:\n            oldpath=f\"{folder}/{dfi['image_id']}\"\n            newpath=f\"files/black/{dfi['image_id']}\"\n            shutil.move(oldpath, newpath)\n        except:\n            pass\n    elif dfi['Blond_Hair']==1:                       ④\n        try:\n            oldpath=f\"{folder}/{dfi['image_id']}\"\n            newpath=f\"files/blond/{dfi['image_id']}\"\n            shutil.move(oldpath, newpath)\n        except:\n            pass\n```", "```py\nclass LoadData(Dataset):\n    def __init__(self, root_A, root_B, transform=None):    ①\n        super().__init__()\n        self.root_A = root_A\n        self.root_B = root_B\n        self.transform = transform\n        self.A_images = []\n        for r in root_A:\n            files=os.listdir(r)\n            self.A_images += [r+i for i in files]\n        self.B_images = []\n        for r in root_B:                                   ②\n            files=os.listdir(r)\n            self.B_images += [r+i for i in files]\n        self.len_data = max(len(self.A_images),\n                            len(self.B_images))\n        self.A_len = len(self.A_images)\n        self.B_len = len(self.B_images)\n    def __len__(self):                                     ③\n        return self.len_data\n    def __getitem__(self, index):                          ④\n        A_img = self.A_images[index % self.A_len]\n        B_img = self.B_images[index % self.B_len]\n        A_img = np.array(Image.open(A_img).convert(\"RGB\"))\n        B_img = np.array(Image.open(B_img).convert(\"RGB\"))\n        if self.transform:\n            augmentations = self.transform(image=B_img,\n                                           image0=A_img)\n            B_img = augmentations[\"image\"]\n            A_img = augmentations[\"image0\"]\n        return A_img, B_img\n```", "```py\ntransforms = albumentations.Compose(\n    [albumentations.Resize(width=256, height=256),        ①\n        albumentations.HorizontalFlip(p=0.5),\n        albumentations.Normalize(mean=[0.5, 0.5, 0.5],\n        std=[0.5, 0.5, 0.5],max_pixel_value=255),         ②\n        ToTensorV2()],\n    additional_targets={\"image0\": \"image\"}) \ndataset = LoadData(root_A=[\"files/black/\"],\n    root_B=[\"files/blond/\"],\n    transform=transforms)                                 ③\nloader=DataLoader(dataset,batch_size=1,\n    shuffle=True, pin_memory=True)                        ④\n```", "```py\nclass Discriminator(nn.Module):\n    def __init__(self, in_channels=3, features=[64,128,256,512]):\n        super().__init__()\n        self.initial = nn.Sequential(\n            nn.Conv2d(in_channels,features[0],                  ①\n                kernel_size=4,stride=2,padding=1,\n                padding_mode=\"reflect\"),\n            nn.LeakyReLU(0.2, inplace=True))\n        layers = []\n        in_channels = features[0]\n        for feature in features[1:]:                            ②\n            layers.append(Block(in_channels, feature, \n                stride=1 if feature == features[-1] else 2))\n            in_channels = feature\n        layers.append(nn.Conv2d(in_channels,1,kernel_size=4,    ③\n                stride=1,padding=1,padding_mode=\"reflect\"))\n        self.model = nn.Sequential(*layers)\n    def forward(self, x):\n        out = self.model(self.initial(x))\n        return torch.sigmoid(out)                               ④\n```", "```py\nfrom utils.ch06util import Discriminator, weights_init    ①\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndisc_A = Discriminator().to(device)\ndisc_B = Discriminator().to(device)                       ②\nweights_init(disc_A)\nweights_init(disc_B)                                      ③\n```", "```py\nclass Generator(nn.Module):\n    def __init__(self, img_channels, num_features=64,\n                 num_residuals=9):\n        super().__init__()     \n        self.initial = nn.Sequential(\n            nn.Conv2d(img_channels,num_features,kernel_size=7,\n                stride=1,padding=3,padding_mode=\"reflect\",),\n            nn.InstanceNorm2d(num_features),\n            nn.ReLU(inplace=True))\n        self.down_blocks = nn.ModuleList(\n            [ConvBlock(num_features,num_features*2,kernel_size=3,\n                       stride=2, padding=1),\n            ConvBlock(num_features*2,num_features*4,kernel_size=3, ①\n                stride=2,padding=1)])\n        self.res_blocks = nn.Sequential(                           ②\n            *[ResidualBlock(num_features * 4) \n            for _ in range(num_residuals)])\n        self.up_blocks = nn.ModuleList(\n            [ConvBlock(num_features * 4, num_features * 2,\n                    down=False, kernel_size=3, stride=2,\n                    padding=1, output_padding=1),\n                ConvBlock(num_features * 2, num_features * 1,      ③\n                    down=False,kernel_size=3, stride=2,\n                    padding=1, output_padding=1)])\n        self.last = nn.Conv2d(num_features * 1, img_channels,\n            kernel_size=7, stride=1,\n            padding=3, padding_mode=\"reflect\")\n\n    def forward(self, x):\n        x = self.initial(x)\n        for layer in self.down_blocks:\n            x = layer(x)\n        x = self.res_blocks(x)\n        for layer in self.up_blocks:\n            x = layer(x)\n        return torch.tanh(self.last(x))                            ④\n```", "```py\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, \n                 down=True, use_act=True, **kwargs):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, \n                      padding_mode=\"reflect\", **kwargs)\n            if down\n            else nn.ConvTranspose2d(in_channels, \n                                    out_channels, **kwargs),\n            nn.InstanceNorm2d(out_channels),\n            nn.ReLU(inplace=True) if use_act else nn.Identity())\n    def forward(self, x):\n        return self.conv(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.block = nn.Sequential(\n            ConvBlock(channels,channels,kernel_size=3,padding=1),\n            ConvBlock(channels,channels,\n                      use_act=False, kernel_size=3, padding=1))\n    def forward(self, x):\n        return x + self.block(x)\n```", "```py\nfrom utils.ch06util import Generator\n\ngen_A = Generator(img_channels=3, num_residuals=9).to(device)\ngen_B = Generator(img_channels=3, num_residuals=9).to(device)\nweights_init(gen_A)\nweights_init(gen_B)\n```", "```py\nimport torch.nn as nn\n\nl1 = nn.L1Loss()\nmse = nn.MSELoss()\ng_scaler = torch.cuda.amp.GradScaler()\nd_scaler = torch.cuda.amp.GradScaler()\n```", "```py\nlr = 0.00001\nopt_disc = torch.optim.Adam(list(disc_A.parameters()) + \n  list(disc_B.parameters()),lr=lr,betas=(0.5, 0.999))\nopt_gen = torch.optim.Adam(list(gen_A.parameters()) + \n  list(gen_B.parameters()),lr=lr,betas=(0.5, 0.999))\n```", "```py\ndef test(i,A,B,fake_A,fake_B):\n    save_image(A*0.5+0.5,f\"files/A{i}.png\")\n    save_image(B*0.5+0.5,f\"files/B{i}.png\")               ①\n    save_image(fake_A*0.5+0.5,f\"files/fakeA{i}.png\")\n    save_image(fake_B*0.5+0.5,f\"files/fakeB{i}.png\")      ②\n```", "```py\ndef train_epoch(disc_A, disc_B, gen_A, gen_B, loader, opt_disc,\n        opt_gen, l1, mse, d_scaler, g_scaler,device):\n    loop = tqdm(loader, leave=True)\n    for i, (A,B) in enumerate(loop):                       ①\n        A=A.to(device)\n        B=B.to(device)\n        with torch.cuda.amp.autocast():                    ②\n            fake_A = gen_A(B)\n            D_A_real = disc_A(A)\n            D_A_fake = disc_A(fake_A.detach())\n            D_A_real_loss = mse(D_A_real, \n                                torch.ones_like(D_A_real))\n            D_A_fake_loss = mse(D_A_fake,\n                                torch.zeros_like(D_A_fake))\n            D_A_loss = D_A_real_loss + D_A_fake_loss\n            fake_B = gen_B(A)\n            D_B_real = disc_B(B)\n            D_B_fake = disc_B(fake_B.detach())\n            D_B_real_loss = mse(D_B_real,\n                                torch.ones_like(D_B_real))\n            D_B_fake_loss = mse(D_B_fake,\n                                torch.zeros_like(D_B_fake))\n            D_B_loss = D_B_real_loss + D_B_fake_loss\n            D_loss = (D_A_loss + D_B_loss) / 2             ③\n        opt_disc.zero_grad()\n        d_scaler.scale(D_loss).backward()\n        d_scaler.step(opt_disc)\n        d_scaler.update()\n        …\n```", "```py\ndef train_epoch(disc_A, disc_B, gen_A, gen_B, loader, opt_disc,\n        opt_gen, l1, mse, d_scaler, g_scaler,device):\n        …\n        with torch.cuda.amp.autocast():\n            D_A_fake = disc_A(fake_A)\n            D_B_fake = disc_B(fake_B)\n            loss_G_A = mse(D_A_fake, torch.ones_like(D_A_fake))\n            loss_G_B = mse(D_B_fake, torch.ones_like(D_B_fake))      ①\n            cycle_B = gen_B(fake_A)\n            cycle_A = gen_A(fake_B)\n            cycle_B_loss = l1(B, cycle_B)\n            cycle_A_loss = l1(A, cycle_A)                            ②\n            G_loss=loss_G_A+loss_G_B+cycle_A_loss*10+cycle_B_loss*10 ③\n        opt_gen.zero_grad()\n        g_scaler.scale(G_loss).backward()\n        g_scaler.step(opt_gen)\n        g_scaler.update()\n        if i % 100 == 0:\n            test(i,A,B,fake_A,fake_B)                                ④\n        loop.set_postfix(D_loss=D_loss.item(),G_loss=G_loss.item())\n```", "```py\nfrom utils.ch06util import train_epoch\n\nfor epoch in range(1):\n    train_epoch(disc_A, disc_B, gen_A, gen_B, loader, opt_disc,\n    opt_gen, l1, mse, d_scaler, g_scaler, device)                   ①\ntorch.save(gen_A.state_dict(), \"files/gen_black.pth\")\ntorch.save(gen_B.state_dict(), \"files/gen_blond.pth\")               ②\n```", "```py\ngen_A.load_state_dict(torch.load(\"files/gen_black.pth\",\n    map_location=device))\ngen_B.load_state_dict(torch.load(\"files/gen_blond.pth\",\n    map_location=device))\ni=1\nfor black,blond in loader:\n    fake_blond=gen_B(black.to(device))\n    save_image(black*0.5+0.5,f\"files/black{i}.png\")             ①\n    save_image(fake_blond*0.5+0.5,f\"files/fakeblond{i}.png\") \n    fake2black=gen_A(fake_blond)\n    save_image(fake2black*0.5+0.5,\n        f\"files/fake2black{i}.png\")                             ②\n    fake_black=gen_A(blond.to(device))\n    save_image(blond*0.5+0.5,f\"files/blond{i}.png\")             ③\n    save_image(fake_black*0.5+0.5,f\"files/fakeblack{i}.png\")\n    fake2blond=gen_B(fake_black)\n    save_image(fake2blond*0.5+0.5,\n        f\"files/fake2blond{i}.png\")                             ④\n    i=i+1\n    if i>10:\n        break\n```"]