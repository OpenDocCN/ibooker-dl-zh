- en: Chapter 7\. Machine Learning for Microscopy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduce you to deep learning techniques for microscopy.
    In such applications, we seek to understand the biological structure of a microscopic
    image. For example, we might be interested in counting the number of cells of
    a particular type in a given image, or we might seek to identify particular organelles.
    Microscopy is one of the most fundamental tools for the life sciences, and advances
    in microscopy have greatly advanced human science. Seeing is believing even for
    skeptical scientists, and being able to visually inspect biological entities such
    as cells builds an intuitive understanding of the underlying mechanisms of life.
    A vibrant visualization of cell nuclei and cytoskeletons (as in [Figure 7-1](#human-derived-sk818))
    builds a much deeper understanding than a dry discussion in a textbook.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: '![Human-derived SK8/18-2 cells. These cells are stained to highlight their
    nuclei and cytoskeletons and imaged using fluorescence microscopy.](Images/dlls_0701.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-1\. Human-derived SK8/18-2 cells. These cells are stained to highlight
    their nuclei and cytoskeletons and imaged using fluorescence microscopy. (Source:
    [Wikimedia](https://commons.wikimedia.org/wiki/File:SK8-18-2_human_derived_cells,_fluorescence_microscopy_(29942101073).jpg).)'
  id: totrans-3
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The question remains how deep learning can make a difference in microscopy.
    Until recently, the only way to analyze microscopy images was to have humans (often
    graduate students or research associates) manually inspect these images for useful
    patterns. More recently, tools such as [CellProfiler](https://cellprofiler.org/)
    have made it possible for biologists to automatically assemble pipelines for handling
    imaging data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Automated High-Throughput Microscopy Image Analysis
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Advances in automation in the last few decades have made it feasible to perform
    automated high-throughput microscopy on some systems. These systems use a combination
    of simple robotics (for automated handling of samples) and image processing algorithms
    to automatically process images. These image processing applications such as separating
    the foreground and background of cells and obtaining simple cell counts and other
    basic measurements. In addition, tools like CellProfiler have allowed biologists
    without programming experience to construct new automated pipelines for handling
    cellular data.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: However, automated microscopy systems have traditionally faced a number of limitations.
    For one, complex visual tasks couldn’t be performed by existing computer vision
    pipelines. In addition, properly preparing samples for analysis takes considerable
    sophistication on the part of the scientist running the experiment. For these
    reasons, automated microscopy has remained a relatively niche technique, despite
    its considerable success in enabling sophisticated new experiments.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning consequently holds considerable promise for extending the capabilities
    of tools such as CellProfiler. If deep analysis methods can perform more complex
    analyses, automated microscopy could become a considerably more effective tool.
    For this reason, there has been considerable research interest in deep microscopy,
    as we shall see in the remainder of this chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: The hope of deep learning techniques is that they will enable automated microscopy
    pipelines to become significantly more flexible. Deep learning systems show promise
    at being able to perform nearly any task a human image analyst can. In addition,
    early research suggests that deep learning techniques could considerably expand
    the capabilities of inexpensive microscopy hardware, potentially allowing cheap
    microscopes to perform analyses currently possible only using very sophisticated
    and expensive apparatuses.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Looking forward, it is even possible to train deep models that “simulate” experimental
    assays. Such systems are capable of predicting the outcomes of experiments (in
    some limited cases) without even running the experiment in question. This is a
    very powerful capability, and one which has spurred much excitement about the
    potential for deep networks in image-based biology.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will teach you the basics of deep microscopy. We will demonstrate
    how deep learning systems can learn to perform simple tasks such as cell counting
    and cellular segmentation. In addition, we will discuss how to build extensible
    systems that could serve to handle more sophisticated image processing pipelines.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: A Brief Introduction to Microscopy
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we dive into algorithms, let’s first talk basics. Microscopy is the science
    of using physical systems to view small objects. Traditionally, microscopes were
    purely optical devices, using finely ground lenses to expand the resolution of
    samples. More recently, the field of microscopy has started to lean heavily on
    technologies such as electron beams or even physical probes to produce high-resolution
    samples.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Microscopy has been tied intimately to the life sciences for centuries. In the
    17th century, Anton van Leeuwenhoek used early optical microscopes (of his own
    design and construction) to describe microorganisms in unprecedented detail (as
    shown in [Figure 7-2](#a-reproduction-of-van)). These observations depended critically
    on van Leeuwenhoek’s advances in microscopy, and in particular on his invention
    of a new lens which allowed for significantly improved resolution over the microscopes
    available at the time.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '![A reproduction of van Leeuwenhoek''s microscope constructed in the modern
    era. Van Leeuwenhoek kept key details of his lens grinding process private, and
    a successful reproduction of the microscope wasn''t achieved until the 1950s by
    scientists in the United States and the Soviet Union.](Images/dlls_0702.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-2\. A reproduction of van Leeuwenhoek’s microscope constructed in
    the modern era. Van Leeuwenhoek kept key details of his lens grinding process
    private, and a successful reproduction of the microscope wasn’t achieved until
    the 1950s by scientists in the United States and the Soviet Union. (Source: [Wikimedia](https://en.wikipedia.org/wiki/Antonie_van_Leeuwenhoek#/media/File:Leeuwenhoek_Microscope.png).)'
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The invention of high-resolution optical microscopes triggered a revolution
    in microbiology. The spread of microscopy techniques and the ability to view cells,
    bacteria, and other microorganisms at scale enabled the entire field of microbiology
    and the pathogenic model of disease. It’s hard to overstate the effect of microscopy
    on the modern life sciences.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Optical microscopes are either simple or compound. Simple microscopes use only
    a single lens for magnification. Compound microscopes use multiple lenses to achieve
    higher resolution, but at the cost of additional complexity in construction. The
    first practical compound microscopes weren’t achieved until the middle of the
    19th century! Arguably, the next major shift in optical microscopy system design
    didn’t happen until the 1980s, with the advent of digital microscopes, which enabled
    the images captured by a microscope to be written to computer storage. As we mentioned
    in the previous section, automated microscopy uses digital microscopes to capture
    large volumes of images. These can be used to conduct large-scale biological experiments
    that capture the effects of experimental perturbations.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Modern Optical Microscopy
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Despite the fact that optical microscopy has been around for centuries, there’s
    still considerable innovation happening in the field. One of the most fundamental
    techniques is *optical sectioning*. An optical microscope has focal planes where
    the microscope is currently focused. A variety of techniques to focus the image
    on a chosen focal plane have been developed. These focused images can then be
    stitched together algorithmically to create a high-resolution image or even a
    3D reconstruction of the original image. [Figure 7-3](#pollen-grain) visually
    demonstrates how sectioned images of a grain of pollen can be combined to yield
    a high-fidelity image.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '*Confocal microscopes* are a common solution to the problem of optical sectioning.
    They use a pinhole to block light coming in from out of focus, allowing a confocal
    microscope to achieve better depth perception. By shifting the focus of the microscope
    and doing a horizontal scan, you can get a full picture of the entire sample with
    increased optical resolution and contrast. In an interesting historical aside,
    the concept of confocal imaging was first patented by the AI pioneer Marvin Minsky
    (see [Figure 7-4](#an-image-from-minsky)).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '![Pollen grain imaging: (a) optically sectioned fluorescence images of a pollen
    grain; (b) combined image; (c) combined image of a group of pollen grains.](Images/dlls_0703.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-3\. Pollen grain imaging: (a) optically sectioned fluorescence images
    of a pollen grain; (b) combined image; (c) combined image of a group of pollen
    grains. (Source: [Wikimedia](https://commons.wikimedia.org/wiki/File:Optical_sectioning_of_pollen.jpg).)'
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![An image from Minsky''s original patent introducing a confocal scanning microscope.
    In a curious twist of history, Minsky is better known for his pioneering work
    in AI. ](Images/dlls_0704.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-4\. An image from Minsky’s original patent introducing a confocal
    scanning microscope. In a curious twist of history, Minsky is better known for
    his pioneering work in AI. (Source: [Wikimedia](https://en.wikipedia.org/wiki/Confocal_microscopy#/media/File:Minsky_Confocal_Reflection_Microscope.png).)'
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Well-designed optical sectioning microscopes excel at capturing 3D images of
    biological systems since scans can be used to focus on multiple parts of the image.
    These focused images can be stitched together algorithmically, yielding beautiful
    3D reconstructions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explore some of the fundamental limits that constrain
    optical microscopy and survey some of the techniques that have been designed to
    work around these limitations. This material isn’t directly related to deep learning
    yet (for reasons we shall discuss), but we think it will give you a valuable understanding
    of the challenges facing microscopy today. This intuition will prove useful if
    you want to help design the next generation of machine learning–powered microscopy
    systems. However, if you’re in a hurry to get to some code, we encourage you to
    skip forward to the subsequent sections where we dive into more immediate applications.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: What Can Deep Learning Not Do?
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It seems intuitively obvious that deep learning can make an impact in microscopy,
    since deep learning excels at image handling and microscopy is all about image
    capture. But it’s worth asking: what parts of microscopy can’t deep learning do
    much for now? As we see later in this chapter, preparing a sample for microscopic
    imaging can require considerable sophistication. In addition, sample preparation
    requires considerable physical dexterity, because the experimenter must be capable
    of fixing the sample as a physical object. How could we possibly automate or speed
    up this process with deep learning?'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: The unfortunate truth right now is that robotic systems are still very limited.
    While simple tasks like confocal scans of a sample are easy to handle, cleaning
    and preparing a sample requires considerable expertise. It’s unlikely that any
    robotic systems available in the near future will have this ability.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在不幸的事实是，机器人系统仍然非常有限。虽然像对样本进行共焦扫描这样的简单任务很容易处理，但清洁和准备样本需要相当的专业知识。在可预见的未来，任何可用的机器人系统都不太可能具有这种能力。
- en: Whenever you hear forecasts about the future impact of learning techniques,
    it’s useful to keep examples like sample preparation in mind. Many of the pain
    points in the life sciences involve tasks such as sample preparation that just
    aren’t feasible for today’s machine learning. That may well change, but likely
    not for the next few years at the least.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每当您听到关于学习技术未来影响的预测时，将示例准备工作等示例记在心中是很有用的。生命科学中的许多痛点涉及诸如样本准备之类的任务，这些任务对今天的机器学习来说根本不可行。这可能会改变，但至少在未来几年内可能不会发生。
- en: The Diffraction Limit
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 衍射极限
- en: 'When studying a new physical instrument such as a microscope, it can be useful
    to start by trying to understand its limits. What can’t microscopes do? It turns
    out this question has been studied in great depth by previous generations of physicists
    (with some recent surprises too!). The first place to start is the *diffraction
    limit*, a theoretical limit on the resolution possible with a microscope:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当研究新的物理仪器，如显微镜时，从尝试了解其限制开始是有用的。显微镜做不到什么？事实证明，这个问题已经被以前的物理学家世代深入研究过（也有一些最近的惊喜！）。开始的地方是*衍射极限*，这是显微镜可能具有的分辨率的理论极限：
- en: <math><mrow><mi>d</mi> <mo>=</mo> <mfrac><mi>λ</mi> <mrow><mn>2</mn><mi>n</mi><mo
    form="prefix">sin</mo><mi>θ</mi></mrow></mfrac></mrow></math>
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: <math><mrow><mi>d</mi> <mo>=</mo> <mfrac><mi>λ</mi> <mrow><mn>2</mn><mi>n</mi><mo
    form="prefix">sin</mo><mi>θ</mi></mrow></mfrac></mrow></math>
- en: The quantity <math><mrow><mi>n</mi><mo form="prefix">sin</mo><mi>θ</mi></mrow></math>
    is often rewritten as the numerical aperture, NA. <math><mi>λ</mi></math> is the
    wavelength of light. Note the implicit assumptions here. We assume that the sample
    is illuminated with some form of light. Let’s take a quick look at the spectrum
    of light waves out there (see [Figure 7-5](#the-wavelengths-of-li)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 量<math><mrow><mi>n</mi><mo form="prefix">sin</mo><mi>θ</mi></mrow></math>经常被重写为数值孔径NA。<math><mi>λ</mi></math>是光的波长。请注意这里的隐含假设。我们假设样本是用某种形式的光照射的。让我们快速看一下那里的光波谱（参见[图7-5](#the-wavelengths-of-li)）。
- en: '![Wavelengths of light. Note that low-wavelength light sources such as X-rays
    are increasingly energetic. As a result, they will often destroy delicate biological
    samples.](Images/dlls_0705.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![光的波长。请注意，低波长光源如X射线具有越来越高的能量。因此，它们经常会破坏精细的生物样本。](Images/dlls_0705.png)'
- en: Figure 7-5\. Wavelengths of light. Note that low-wavelength light sources such
    as X-rays are increasingly energetic. As a result, they will often destroy delicate
    biological samples.
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-5。光的波长。请注意，低波长光源如X射线具有越来越高的能量。因此，它们经常会破坏精细的生物样本。
- en: Note how visible light forms only a tiny fraction of this spectrum. In principle,
    we should be able to make the desired resolution arbitrarily good using light
    at a low enough wavelength. To some extent this has happened already. A number
    of microscopes use electromagnetic waves of higher energy. For example, ultraviolet
    microscopes use the fact that UV rays have smaller wavelengths to allow for higher
    resolution. Couldn’t we take this pattern further and use light of even smaller
    wavelength? For example, why not an X-ray or gamma-ray microscope? The main issue
    here is *phototoxicity*. Light with small wavelengths is highly energetic. Shining
    such light upon a sample can destroy the structure of the sample. In addition,
    high-wavelength light is dangerous for the experimenter and requires special experimental
    facilities.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，可见光仅占此光谱的一小部分。原则上，我们应该能够使用波长足够低的光使所需的分辨率任意好。在某种程度上，这已经发生了。许多显微镜使用能量更高的电磁波。例如，紫外显微镜利用紫外线波长较小的事实来实现更高的分辨率。我们不能进一步采用这种模式并使用波长更小的光吗？例如，为什么不使用X射线或γ射线显微镜？这里的主要问题是*光毒性*。波长较小的光具有高能量。将这种光照射到样本上可能会破坏样本的结构。此外，高波长光对实验者是危险的，并且需要特殊的实验设施。
- en: Luckily, though, there exist a number of other techniques for bypassing the
    diffraction limit. One uses electrons (which have wavelengths too!) to image samples.
    Another uses physical probes instead of light. Yet another method for avoiding
    the resolution limit is to make use of near-field electromagnetic waves. Tricks
    with multiple illuminated fluorophores can also allow the limit to be lowered.
    We’ll discuss these techniques in the following sections.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，还存在许多其他绕过衍射极限的技术。其中一种使用电子（它们也有波长！）来成像样本。另一种使用物理探针而不是光。避免分辨率限制的另一种方法是利用近场电磁波。使用多个照明荧光物质的技巧也可以降低限制。我们将在接下来的部分讨论这些技术。
- en: Electron and Atomic Force Microscopy
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 电子和原子力显微镜
- en: 'In the 1930s, the advent of the electron microscope triggered a dramatic leap
    in modern microscopy. The electron microscope uses electron beams instead of visible
    light in order to obtain images of objects. Since the wavelengths of electrons
    are much smaller than those of visible light, using electron beams instead of
    light waves allows much more detailed images. Why does this make any sense? Well,
    aren’t electrons particles? Remember that matter can exhibit wave-like properties.
    This is known as the de Broglie wavelength, which was first proposed by Louis
    de Broglie:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在1930年代，电子显微镜的出现引发了现代显微镜的巨大飞跃。电子显微镜使用电子束而不是可见光来获取物体的图像。由于电子的波长比可见光的波长小得多，使用电子束而不是光波可以获得更详细的图像。为什么这有意义呢？嗯，电子不是粒子吗？请记住，物质可以表现出波动性质。这就是所谓的德布罗意波长，由路易斯·德布罗意首次提出：
- en: <math><mrow><mi>λ</mi> <mo>=</mo> <mfrac><mi>h</mi> <mi>p</mi></mfrac> <mo>=</mo>
    <mfrac><mi>h</mi> <mrow><mi>m</mi><mi>v</mi></mrow></mfrac></mrow></math>
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Here, <math><mi>h</mi></math> is Planck’s constant and <math><mi>m</mi></math>
    and <math><mi>v</mi></math> are the mass and velocity of the particle in question.
    (For the physicists, note that this formula doesn’t account for relativistic effects.
    There are modified versions of the formula that do so.) Electron microscopes make
    use of the wave-like nature of electrons to image physical objects. The wavelength
    of an electron depends on its energy, but is easily subnanometer at wavelengths
    achievable by a standard electron gun. Plugging into the diffraction limit model
    discussed previously, it’s easy to see how electron microscopy can be a powerful
    tool. The first prototype electron microscopes were constructed in the early 1930s.
    While these constructions have been considerably refined, today’s electron microscopes
    still depend on the same core principles (see [Figure 7-6](#a-diagram-of-the-comp)).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '![The components of a modern transmission electron microscope.](Images/dlls_0706.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-6\. The components of a modern transmission electron microscope. (Source:
    [Wikimedia](https://commons.wikimedia.org/wiki/File:Electron_Microscope.png).)'
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note that we haven’t entirely bypassed the issues with phototoxicity here. To
    get electrons with very small wavelengths, we need to increase their energy—and
    at very high energy, we will again destroy samples. In addition, the process of
    preparing samples for imaging by an electron microscope can be quite involved.
    Nevertheless, the use of electron microscopes has allowed for stunning images
    of microscopic systems (see [Figure 7-7](#pollen-magnified-500x)). Scanning electron
    microscopes, which scan the input sample to achieve larger fields of view,allow
    for images with resolution as small as one nanometer.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '![Pollen magnified 500x by a scanning electron microscope.](Images/dlls_0707.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-7\. Pollen magnified 500x by a scanning electron microscope. (Source:
    [Wikimedia](https://commons.wikimedia.org/wiki/File:Misc_pollen.jpg).)'
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Atomic force microscopy (AFM) provides another way of breaking through the optical
    diffraction limit. This technique leverages a cantilever which probes a given
    surface physically. The direct physical contact between the cantilever and the
    sample allows for pictures with resolutions at fractions of a nanometer. Indeed,
    it is sometimes possible to image single atoms! Atomic force microscopes also
    provide for 3D images of a surface due to the direct contact of the cantilever
    with the surface at hand.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Force microscopy broadly is a recent technique. The first atomic force microscopes
    were only invented in the 1980s, after nanoscale manufacturing techniques had
    matured to a point where the probes involved could be accurately made. As a result,
    applications in the life sciences are still emergent. There has been some work
    on imaging cells and biomolecules with AFM probes, but these techniques are still
    early.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Super-Resolution Microscopy
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ve discussed a number of ways to stretch the diffraction limit so far in
    this chapter, including using higher-wavelength light or physical probes to allow
    for greater resolution. However, in the second half of the 20th century came a
    scientific breakthrough, led by the realization that there existed entire families
    of methods for breaking past the diffraction limit. Collectively, these techniques
    are called super-resolution microscopy techniques:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Functional super-resolution microscopy
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Makes use of physical properties of light-emitting substances embedded in the
    sample being imaged. For example, fluorescent tags (more on these later) in biological
    microscopy can highlight particular biological molecules. These techniques allow
    standard optical microscopes to detect light emitters. Functional super-resolution
    techniques can be broadly split into deterministic and stochastic techniques.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Deterministic super-resolution microscopy
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Some light-emitting substances have a nonlinear response to excitation. What
    does this actually mean? The idea is that arbitrary focus on a particular light
    emitter can be achieved by “turning off” the other emitters nearby. The physics
    behind this is a little tricky, but well-developed techniques such as stimulated
    emission depletion (STED) microscopy have demonstrated this technique.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic super-resolution microscopy
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Light-emitting molecules in biological systems are subject to random motion.
    This means that if the motion of a light-emitting particle is tracked over time,
    its measurements can be averaged to yield a low error estimate of its true position.
    There are a number of techniques (such as STORM, PALM, and BALM microscopy) that
    refine this basic idea. These super-resolution techniques have had a dramatic
    effect in modern biology and chemistry because they allow relatively cheap optical
    equipment to probe the behavior of nanoscale systems. The 2014 Nobel Prize in
    Chemistry was awarded to pioneers of functional super-resolution techniques.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: Deep Super-Resolution Techniques
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recent research has started to leverage the power of deep learning techniques
    to reconstruct super-resolution views.^([1](ch07.xhtml#idm45806168013304)) These
    techniques claim orders of magnitude improvements in the speed of super-resolution
    microscopy by enabling reconstructions from sparse, rapidly acquired images. While
    still in its infancy, this shows promise as a future application area for deep
    learning.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Near-field microscopy is another super-resolution technique that makes use of
    local electromagnetic information in a sample. These “evanescent waves” don’t
    obey the diffraction limit, so higher resolution is possible. However, the trade-off
    is that the microscope has to gather light from extremely close to the sample
    (within one wavelength of light from the sample). This means that although near-field
    techniques make for extremely interesting physics, practical use remains challenging.
    Very recently, it has also become possible to construct “metamaterials” which
    have a negative refractive index. In effect, the properties of these materials
    mean that near-field evanescent waves can be amplified to allow imaging further
    away from the sample. Research in this field is still early but very exciting.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning and the Diffraction Limit?
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tantalizing hints suggest that deep learning may facilitate the spread of super-resolution
    microscopy. A few early papers have shown that it might be possible for deep learning
    algorithms to speed up the construction of super-resolution images or enable effective
    super-resolution with relatively cheap hardware. (We point to one such paper in
    the previous note.)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: These hints are particularly compelling because deep learning can effectively
    perform tasks such as image deblurring.^([2](ch07.xhtml#idm45806167992424)) This
    evidence suggests that it may be possible to build a robust set of super-resolution
    tools based on deep learning that could dramatically facilitate the adoption of
    such techniques. At present this research is still immature, and compelling tooling
    doesn’t yet exist. However, we hope that this state of affairs will change over
    the coming years.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Preparing Biological Samples for Microscopy
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most critical steps in applying microscopy in the life sciences is
    preparing the sample for the microscope. This can be a highly nontrivial process
    that requires considerable experimental sophistication. We discuss a number of
    techniques for preparing samples in this section and comment on the ways in which
    such techniques can go wrong and create unexpected experimental artifacts.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在生命科学中应用显微镜的一个至关重要的步骤是为显微镜准备样本。这可能是一个非常复杂的过程，需要相当多的实验经验。我们在本节中讨论了几种准备样本的技术，并评论了这些技术可能出错并产生意外实验性伪迹的方式。
- en: Staining
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 染色
- en: The earliest optical microscopes allowed for magnified views of microscopic
    objects. This power enabled amazing improvements in the understanding of small
    objects, but it had the major limitation that it was not possible to highlight
    certain areas of the image for contrast. This led to the development of chemical
    stains which permitted scientists to view regions of the image for contrast.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最早的光学显微镜可以放大观察微观物体。这种功能使对小物体的理解有了惊人的提升，但它的主要局限是无法突出图像中的某些区域以增加对比度。这导致了化学染料的发展，使科学家们能够查看图像中的区域以增加对比度。
- en: A wide variety of stains have been developed to handle different types of samples.
    The staining procedures themselves can be quite involved, with multiple steps.
    Stains can be extraordinarily influential scientifically. In fact, it’s common
    to classify to bacteria as “gram-positive” or “gram-negative” depending on their
    response to the well known Gram stain for bacteria. A task for a deep learning
    system might be to segment and label the gram-positive and gram-negative bacteria
    in microscopy samples. If you had a potential antibiotic in development, this
    would enable you to study its effect on gram-positive and gram-negative species
    separately.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 已经开发了各种各样的染料来处理不同类型的样本。染色程序本身可能非常复杂，包含多个步骤。染料在科学上可能具有极大的影响力。事实上，根据细菌对细菌革兰氏染色的反应，通常将细菌分类为“革兰阳性”或“革兰阴性”。深度学习系统的一个任务可能是在显微镜样本中分割和标记革兰阳性和革兰阴性细菌。如果您正在开发潜在的抗生素，这将使您能够分别研究其对革兰阳性和革兰阴性物种的影响。
- en: Why Should I Care as a Developer?
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 作为开发者，我为什么要关心这个问题？
- en: Some of you reading this section may be developers interested in dealing with
    the challenges of building and deploying deep microscopy pipelines. You might
    reasonably be asking yourself whether you should care about the biology of sample
    preparation.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读本节的一些人可能是开发人员，对处理构建和部署深度显微镜流水线的挑战感兴趣。您可能会合理地问自己是否应该关心样本准备的生物学。
- en: If you are indeed laser-focused on the challenges of building pipelines, skipping
    ahead to the case studies in this chapter will probably help you most. However,
    building an understanding of basic sample preparation may save you headaches later
    on and give you the vocabulary to effectively communicate with your biologist
    peers. If biology requests that you add metadata fields for stains, this section
    will give you a good idea of what they’re actually asking for. That’s worth a
    few minutes of your time!
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您确实专注于构建流水线的挑战，直接跳到本章的案例研究可能会对您最有帮助。然而，了解基本样本准备可能会在以后避免麻烦，并使您具备有效与生物学家同行沟通的词汇。如果生物学要求您为染料添加元数据字段，这一部分将让您对他们实际要求的内容有一个很好的了解。这值得您花几分钟的时间！
- en: Developing Antibacterial Agents for Gram-Negative Bacteria
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为革兰阴性细菌开发抗菌剂
- en: One of the major challenges in drug discovery at this time is developing effective
    antibiotics for gram-negative bacteria. Gram-negative bacteria have an additional
    cell wall that prevents common antibacterial agents which target the peptidoglycan
    cell walls of gram-positive bacteria from functioning effectively.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 目前药物发现中的一个主要挑战是为革兰阴性细菌开发有效的抗生素。革兰阴性细菌有一个额外的细胞壁，阻止了针对革兰阳性细菌的肽聚糖细胞壁的常见抗菌剂有效发挥作用。
- en: This challenge is becoming more urgent because many bacterial strains are picking
    up gram-negative resistance through methods such as horizontal gene transfer,
    and deaths from bacterial infections are once again on the rise after decades
    of control.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这一挑战变得更加紧迫，因为许多细菌菌株通过水平基因转移等方法获得了革兰阴性抗性，细菌感染导致的死亡再次上升，这是在控制几十年后的情况。
- en: It might well be possible to combine the deep learning methods for molecular
    design you’ve seen already with some of the imaging-based techniques you’ll learn
    in this chapter to make progress on this problem. We encourage those of you curious
    about the possibilities to explore this area more carefully.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 可能很可能将您已经看到的分子设计深度学习方法与您将在本章学习的一些基于成像的技术相结合，以在这个问题上取得进展。我们鼓励那些对可能性感到好奇的人更仔细地探索这个领域。
- en: Sample Fixation
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 样本固定
- en: Large biological samples such as tissue will often degrade rapidly if left to
    their own devices. Metabolic processes in the sample will consume and damage the
    structure of the organs, cells, and organelles in the sample. The process of “fixation”
    seeks to stop this process, and stabilize the contents of the sample so that it
    can be imaged properly. A number of *fixative* agents have been designed which
    aid in this process. One of the core functions of fixatives is to denature proteins
    and turn off proteolytic enzymes. Such enzymes will consume the sample if allowed.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 大型生物样本，如组织，如果任其自生自灭，往往会迅速降解。样本中的代谢过程会消耗并破坏样本中的器官、细胞和细胞器的结构。"固定"的过程旨在阻止这一过程，并稳定样本的内容，以便正确成像。已经设计了许多*固定*剂，这些剂有助于这一过程。固定剂的一个核心功能是变性蛋白质并关闭蛋白酶。如果允许，这些酶会消耗样本。
- en: In addition, the process of fixation seeks to kill microorganisms that may damage
    the sample. For example, in heat fixation the sample is passed through a Bunsen
    burner. This process can damage the internal structures of the sample as a side
    effect. Another common technique is that of immersion fixation, where samples
    are immersed in a fixative solution and allowed to soak. For example, a sample
    could be soaked in cold formalin for a span of time, such as 24 hours.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，固定的过程旨在杀死可能损坏样本的微生物。例如，在热固定中，样本通过巴塞尔燃烧器。这个过程可能会损坏样本的内部结构。另一种常见的技术是浸泡固定，样本被浸泡在固定液中并允许浸泡。例如，一个样本可以在冷甲醛中浸泡一段时间，比如24小时。
- en: '*Perfusion* is a technique for fixing tissue samples from larger animals such
    as mice. Experimenters inject fixative into the heart and wait for the mouse to
    die before extracting the tissue sample. This process allows for the fixative
    agent to spread through the tissue naturally and often yields superior results.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*灌注* 是一种固定大型动物（如小鼠）组织样本的技术。实验者将固定剂注入心脏，等待小鼠死亡后提取组织样本。这个过程允许固定剂自然地在组织中传播，通常会产生更好的结果。'
- en: Sectioning Samples
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分段样本
- en: 'An important part of viewing a biological sample is being able to slice out
    a thin part of the sample for the microscope. There exist a number of ingenious
    tools to facilitate this process, including the microtome (see [Figure 7-8](#an-early-diagram-from)),
    which slices biological samples into thin slices for easy viewing. The microtome
    has its limitations: it’s hard to slice very small objects this way. For such
    small objects, it might be better to use a technique such as confocal microscopy
    instead.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 查看生物样本的一个重要部分是能够切出样本的薄片供显微镜观察。有许多巧妙的工具来促进这个过程，包括显微切片机（见[图7-8](#an-early-diagram-from)），它将生物样本切成薄片以便观察。显微切片机有其局限性：用这种方式很难切割非常小的物体。对于这样的小物体，最好使用共焦显微镜等技术。
- en: It’s worth pausing and asking why it’s useful to know that devices such as a
    microtome exist. Well, let’s say that as an engineer, you’re constructing a pipeline
    to handle a number of brain imaging samples. The sample brain was likely sliced
    into thin pieces using a microtome or similar cutting device. Knowing the physical
    nature of this process will aid you if you’re (for example) building a schema
    to organize such images consistently.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 值得停下来问一下为什么知道有显微切片机这样的设备是有用的。嗯，假设你是一名工程师，正在建造一个处理多个脑成像样本的管道。样本大脑很可能是使用显微切片机或类似的切割设备切成薄片的。了解这个过程的物理特性将有助于你，如果你（例如）正在构建一个用于一致组织这样的图像的模式。
- en: '![An early diagram from 1770 depicting a microtome.](Images/dlls_0708.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![一幅早期的图示了1770年的显微切片机。](Images/dlls_0708.png)'
- en: 'Figure 7-8\. An early diagram from 1770 depicting a microtome. (Source: [Wikimedia](https://commons.wikimedia.org/wiki/File:Cummings_1774_Microtome.jpg).)'
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-8. 一幅早期的图示了1770年的显微切片机。 (来源：[维基共享资源](https://commons.wikimedia.org/wiki/File:Cummings_1774_Microtome.jpg).)
- en: Fluorescence Microscopy
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 荧光显微镜
- en: A fluorescence microscope is an optical microscope that makes use of the phenomenon
    of fluorescence, where a sample of material absorbs light at one wavelength and
    emits it at another wavelength. This is a natural physical phenomenon; for example,
    a number of minerals fluoresce when exposed to ultraviolet light. It gets particularly
    interesting when applied to biology, though. A number of bacteria fluoresce naturally
    when their proteins absorb high-energy light and emit lower-energy light.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 荧光显微镜是一种利用荧光现象的光学显微镜，其中材料样本吸收一种波长的光并以另一种波长发射。这是一种自然的物理现象；例如，一些矿物质在暴露在紫外光下时会发出荧光。然而，当应用于生物学时，情况就变得特别有趣。许多细菌在其蛋白质吸收高能光并发射低能光时会自然发出荧光。
- en: Fluorophores and fluorescent tags
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 荧光物质和荧光标记
- en: A fluorophore is a chemical compound that can reemit light at a certain wavelength.
    These compounds are a critical tool in biology because they allow experimentalists
    to image particular components of a given cell in detail. Experimentally, the
    fluorophore is commonly applied as a dye to a particular cell. [Figure 7-9](#dapi-46-diamidino)
    shows the molecular structure of a common fluorophore.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 荧光物质是一种可以在特定波长重新发射光的化合物。这些化合物在生物学中是至关重要的工具，因为它们允许实验者详细地成像给定细胞的特定组分。在实验中，荧光物质通常作为染料应用到特定细胞上。[图7-9](#dapi-46-diamidino)展示了一种常见荧光物质的分子结构。
- en: '![DAPI (4'',6-diamidino-2-phenylindole) is a common fluorescent stain that
    binds to adenine-thymine–rich regions of DNA. Because it passes through cell membranes,
    it is commonly used to stain the insides of cells.](Images/dlls_0709.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![DAPI（4''，6-二胺基二苯基吲哚）是一种常见的荧光染料，结合到DNA的腺嘧啶-胸腺嘧啶富集区域。因为它可以穿过细胞膜，所以常用来染色细胞内部。](Images/dlls_0709.png)'
- en: 'Figure 7-9\. DAPI (4'',6-diamidino-2-phenylindole) is a common fluorescent
    stain that binds to adenine-thymine–rich regions of DNA. Because it passes through
    cell membranes, it is commonly used to stain the insides of cells. (Source: [Wikimedia](https://commons.wikimedia.org/wiki/File:DAPI.svg).)'
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-9. DAPI（4'，6-二胺基二苯基吲哚）是一种常见的荧光染料，结合到DNA的腺嘧啶-胸腺嘧啶富集区域。因为它可以穿过细胞膜，所以常用来染色细胞内部。
    (来源：[维基共享资源](https://commons.wikimedia.org/wiki/File:DAPI.svg).)
- en: Fluorescent tagging is a technique for attaching a fluorophore to a biomolecule
    of interest in the body. There are a variety of techniques to do this effectively.
    It’s useful in microscopy imaging, where it’s common to want to highlight a particular
    part of the image. Fluorescent tagging can enable this very effectively.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 荧光标记是一种将荧光物质附着到体内感兴趣的生物分子的技术。有多种有效的技术可以实现这一点。在显微镜成像中很有用，常常希望突出图像的特定部分。荧光标记可以非常有效地实现这一点。
- en: Fluorescent microscopy has proven a tremendous boon for biological research
    because it permits researchers to zoom in on specific subsystems in a given biological
    sample, as opposed to dealing with the entirety of the sample. When studying individual
    cells, or individual molecules within a cell, the use of tagging can prove invaluable
    for focusing attention on interesting subsystems. [Figure 7-10](#an-image-of-a-human-l)
    shows how a fluorescent stain can be used to selectively visualize particular
    chromosomes within a human cell nucleus.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '![An image of a human lymphocyte nucleus with chromosomes 13 and 21 stained
    with DAPI (a popular fluorescent stain) to emit light.](Images/dlls_0710.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-10\. An image of a human lymphocyte nucleus with chromosomes 13 and
    21 stained with DAPI (a popular fluorescent stain) to emit light. (Source: [Wikimedia](https://commons.wikimedia.org/wiki/File:FISH_13_21.jpg).)'
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Fluorescence microscopy can be a very precise tool, used to track events like
    single binding events of molecules. For example, binding events of proteins to
    ligands (as discussed in [Chapter 5](ch05.xhtml#biophysical_machine_learning))
    can be detected by a fluorescence assay.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Sample Preparation Artifacts
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It’s important to note that sample preparation can be a deeply tricky process.
    It’s common for the preparation of the original sample to induce distortions in
    the object being imaged, which can lead to some confusion. An interesting example
    is the case of the mesosome, discussed in the following warning note.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 'The Mesosome: An Imaginary Organelle'
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The process of fixing a cell for electron microscopy introduces a crucial artifact,
    the *mesosome* in gram-positive bacteria (see [Figure 7-11](#mesosomes)). Degradations
    in the cell wall, caused by the process of preparing the sample for the electron
    microscope, were originally thought to be natural structures instead of artifacts.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Be warned that similar artifacts likely exist in your own samples. In addition,
    it’s entirely possible that a deep network could train itself to detect such artifacts
    rather than training itself to find real biology.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![Mesosomes are artifacts introduced by preparation for electron microscopy
    that were once believed to be real structures in cells.](Images/dlls_0711.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: Figure 7-11\. Mesosomes are artifacts introduced by preparation for electron
    microscopy that were once believed to be real structures in cells. (Adapted from
    [Wikimedia](https://en.wikipedia.org/wiki/Mesosome#/media/File:Mesosome_formation.svg).)
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Tracking Provenance of Microscopy Samples
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you’re designing systems to handle microscopy data, it will be critical
    to track the provenance of your samples. Each image should be annotated with information
    about the conditions in which it was gathered. This might include the physical
    device that was used to capture the image, the technician who supervised the imaging
    process, the sample that was imaged, and the physical location at which the sample
    was gathered. Biology is extraordinarily tricky to “debug.” Issues such as the
    one described in the previous warning can go untracked, potentially for decades.
    Making sure to maintain adequate metadata around the provenance of your images
    could save you and your team from major issues down the line.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning Applications
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section we briefly review various applications of deep learning to microscopy,
    such as cell counting, cell segmentation, and computational assay construction.
    As we’ve noted previously in the chapter, this is a limited subset of the applications
    possible for deep microscopy. However, understanding these basic applications
    will give you the understanding needed to invent new deep microscopy applications
    of your own.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Cell Counting
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A simple task is to count the number of cells that appear in a given image.
    You might reasonably ask why this is an interesting task. For a number of biological
    experiments, it can be quite useful to track the number of cells that survive
    after a given intervention. For example, perhaps the cells are drawn from a cancer
    cell line, and the intervention is the application of an anticancer compound.
    A successful intervention would reduce the number of living cancer cells, so it
    would be useful to have a deep learning system that can count the number of such
    living cells accurately without human intervention.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: What Is a Cell Line?
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Often in biology, it’s useful to study cells of a given type. The first step
    in running an experiment against a collection of cells is to gain a plentiful
    supply of such cells. Enter the cell line. Cell lines are cells cultivated from
    a given source and that can grow stably in laboratory conditions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Cell lines have been used in countless biological papers, but there are often
    serious concerns about the science done on them. To start, removing a cell from
    its natural environment can radically change its biology. A growing line of evidence
    shows that the environment of a cell can fundamentally shape its response to stimuli.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Even more seriously, cell lines are often contaminated. Cells from one cell
    line may contaminate cells from another cell line, so results on a “breast cancer”
    cell line may, in fact, tell the researcher absolutely nothing about breast cancer!
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: For these reasons, studies on cell lines are often treated with caution, with
    the results intended simply as spur to attempt duplication with animal or human
    tests. Nevertheless, cell line studies provide an invaluable easy entry point
    to biological research and remain ubiquitous.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '![Samples of Drosophila cells. Note how the image conditions in microscopy
    images can be significantly different from image conditions in photographs.](Images/dlls_0712.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-12\. Samples of Drosophila cells. Note how the image conditions in
    microscopy images can be significantly different from image conditions in photographs.
    (Source: [Cell Image Library](http://cellimagelibrary.org/images/21780).)'
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As [Figure 7-12](#samples-of-drosophila) shows, image conditions in cell microscopy
    can be significantly different from standard image conditions, so it is not immediately
    obvious that technologies such as convolutional neural networks can be adapted
    to tasks such as cell counting. Luckily, significant experimental work has shown
    that convolutional networks do quite well at learning from microscopy datasets.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Implementing cell counting in DeepChem
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section walks through the construction of a deep learning model for cell
    counting using DeepChem. We’ll start by loading and featurizing a cell counting
    dataset. We use the [Broad Bioimage Benchmark Collection](https://data.broadinstitute.org/bbbc/)
    (BBBC) to get access to a useful microscopy dataset for this purpose.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: BBBC Datasets
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The BBBC datasets contain a useful collection of annotated bioimage datasets
    from various cellular assays.  It is a useful resource as you work on training
    your own deep microscopy models. DeepChem has a collection of image processing
    resources to make it easier to work with these datasets. In particular, DeepChem’s
    `ImageLoader` class facilitates loading of the datasets.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Processing Image Datasets
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Images are usually stored on disk in standard image file formats (PNG, JPEG,
    etc.). The processing pipeline for image datasets typically reads in these files
    from disk and transforms them into a suitable in-memory representation, typically
    a multidimensional array. In Python processing pipelines, this array is often
    simply a NumPy array. For an image `*N*` pixels high, `*M*` pixels wide, and with
    3 RGB color channels, you would get an array of shape `(*N*, *M*, 3)`. If you
    have 10 such images, these images would typically be batched into an array of
    shape `(10, *N*, *M*, 3).`
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you can load the dataset into DeepChem, you’ll first need to download
    it locally. The BBBC005 dataset that we’ll use for this task is reasonably large
    (a little under 2 GB), so make sure your development machine has sufficient space
    available:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'With the dataset downloaded to your local machine, you can now load this dataset
    into DeepChem by using `ImageLoader`:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This code walks through the downloaded directory of images and pulls out the
    image files. The labels are encoded in the filenames themselves, so we use a simple
    regular expression to extract the number of cells in each image. We use `ImageLoader`
    to transform this into a DeepChem dataset.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now split this dataset into training, validation, and test sets:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'With this split in place, we can now define the model itself. In this case,
    let’s make a simple convolutional architecture with a fully connected layer at
    the end:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that we use `L2Loss` to train our model as a regression task. Even though
    cell counts are whole numbers, we don’t have a natural upper bound on the number
    of cells in an image.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'Training this model will take some computational effort (more on this momentarily),
    so to start, we recommend using our pretrained model for basic experimentation.
    This model can be used to make predictions out of the box. There are directions
    on downloading the pretrained model in the [code repository associated with the
    book](https://github.com/deepchem/DeepLearningLifeSciences). Once you’ve downloaded
    it, you can load the pretrained weights into the model with:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s take this pretrained model out for a whirl. First, we’ll compute the
    average prediction error on our test set for our cell counting task:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: What accuracy do you get when you try running the model?
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, how can you train this model for yourself? You can fit the model by training
    it for 50 epochs on the dataset:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This learning task will take some amount of computing horsepower. On a good
    GPU, it should complete within an hour or so. It may not be feasible to easily
    train the model on a CPU system.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Once trained, test the accuracy of the model on the validation and test sets.
    Does it match that of the pretrained model?
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Cell Segmentation
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The task of cellular segmentation involves annotating a given cellular microscopy
    image to denote where cells appear and where background appears. Why is this useful?
    If you recall our earlier discussion of gram-positive and gram-negative bacteria,
    you can probably guess why an automated system for separating out the two types
    of bacteria might prove useful. It turns out that similar problems arise through
    all of cellular microscopy (and in other fields of imaging, as we will see in
    [Chapter 8](ch08.xhtml#deep_learning_for_medicine)).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Segmentation masks provide significantly finer-grained resolution and permit
    for more refined analysis than cell counting. For example, it might be useful
    to understand what fraction of a given plate is covered with cells. Such analysis
    is easy to perform once segmentation masks have been generated. [Figure 7-13](#a-synthetic-dataset-o)
    provides an example of a segmentation mask that is generated from a synthetic
    dataset.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '![A synthetic dataset of cells (on the left) along with foreground/background
    masks annotating where cells appear in the image.](Images/dlls_0713.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7-13\. A synthetic dataset of cells (on the left) along with foreground/background
    masks annotating where cells appear in the image. (Source: [Broad Institute](https://data.broadinstitute.org/bbbc/BBBC005/).)'
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: That said, segmentation asks for significantly more from a machine learning
    model than counting. Being able to precisely differentiate cellular and noncellular
    regions requires greater precision in learning. For that reason, it’s not surprising
    that machine learning segmentation approaches are still harder to get working
    than simpler cellular counting approaches. We will experiment with a segmentation
    model later in this chapter.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: Where Do Segmentation Masks Come From?
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s worth pausing to note that segmentation masks are complex objects. There
    don’t exist good algorithms (except for deep learning techniques) for generating
    such masks in general. How then can we bootstrap the training data needed to refine
    a deep segmentation technique? One possibility is to use synthetic data, as in
    [Figure 7-13](#a-synthetic-dataset-o). Because the cellular image is generated
    in a synthetic fashion, the mask can also be synthetically generated. This is
    a useful trick, but it has obvious limitations because it will limit our learned
    segmentation methods to similar images.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: A more general procedure is to have human annotators generate suitable segmentation
    masks. Similar procedures are used widely to train self-driving cars. In that
    task, finding segmentations that annotate pedestrians and street signs is critical,
    and armies of human segmenters are used to generate needed training data. As machine-learned
    microscopy grows in importance, it is likely that similar human pipelines will
    become critical.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Implementing cell segmentation in DeepChem
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will train a cellular segmentation model on the same BBBC005
    dataset that we used previously for the cell counting task. There’s a crucial
    subtlety here, though. In the cell counting challenge, each training image has
    a simple count as a label. However, in the cellular segmentation task, each label
    is itself an image. This means that a cellular segmentation model is actually
    a form of “image transformer” rather than a simple classification or regression
    model. Let’s start by obtaining this dataset. We have to retrieve the segmentation
    masks from the BBBC website, using the following commands:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The ground-truth data is something like 10 MB, so it should be easier to download
    than the full BBBC005 dataset. Now let’s load this dataset into DeepChem. Luckily
    for us, `ImageLoader` is set up to handle image segmentation datasets without
    much extra hassle:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now that we have our datasets loaded and processed, let’s hop into building
    some deep learning models for them. As before, we’ll split this dataset into training,
    validation, and test sets:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: What architecture can we use for the task of image segmentation? It’s not just
    a matter of using a straightforward convolutional architecture since our output
    needs to itself be an image (the segmentation mask). Luckily for us, there has
    been some past work on suitable architectures for this task. The U-Net architecture
    uses a stacked series of convolutions to progressively “downsample” and then “upsample”
    the source image, as illustrated in [Figure 7-14](#net-architecture). This architecture
    does well at the task of image segmentation.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '![A representation of the U-Net architecture for biomedical image segmentation.](Images/dlls_0714.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
- en: Figure 7-14\. A representation of the U-Net architecture for biomedical image
    segmentation. (Adapted from [the University of Freiburg](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/).)
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s now implement the U-Net in DeepChem:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This architecture is somewhat more complex than that for cell counting, but
    we use the same basic code structure and stack convolutional layers to achieve
    our desired architecture. As before, let’s use a pretrained model to give this
    architecture a try. Directions for downloading the pretrained model are available
    in the book’s [code repository](https://github.com/deepchem/DeepLearningLifeSciences).
    Once you’ve got the pretrained weights in place, you can load the weights as before:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let’s use this model to create some masks. Calling `model.predict_on_batch()`
    allows us to predict the output mask for a batch of inputs. We can check the accuracy
    of our predictions by comparing our masks against the ground-truth masks and checking
    the overlap fraction:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This should return approximately 0.9899\. This means nearly 99% of pixels are
    correctly predicted! It’s a neat result, but we should emphasize that this is
    a toy learning task. A simple image processing algorithm with a brightness threshold
    could likely do almost as well. Still, the principles exposed here should carry
    over to more complex image datasets.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'OK, now that we’ve explored with the pretrained model, let’s train a U-Net
    from scratch for 50 epochs and see what results we obtain:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As before, this training is computationally intensive and will take a couple
    of hours on a good GPU. It may not be feasible to train this model on a CPU system.
    Once the model is trained, try running the results for yourself and seeing what
    you get. Can you match the accuracy of the pretrained model?
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Computational Assays
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cell counting and segmentation are fairly straightforward visual tasks, so it’s
    perhaps unsurprising that machine learning models are capable of performing well
    on such datasets. It could reasonably be asked if that’s all machine learning
    models are capable of.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Luckily, it turns out the answer is no! Machine learning models are capable
    of picking up on subtle signals in the dataset. For example, one study demonstrated
    that deep learning models are capable of predicting the outputs of fluorescent
    labels from the raw image.^([3](ch07.xhtml#idm45806166492536)) It’s worth pausing
    to consider how surprising this result is. As we saw in [“Preparing Biological
    Samples for Microscopy”](#bio-samples-for-microscopy), fluorescent staining can
    be a considerably involved procedure. It’s astonishing that deep learning might
    be able to remove some of the needed preparation work.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: This is an exciting result, but it’s worth noting that it’s still an early one.
    Considerable work will have to be done to “robustify” these techniques so they
    can be applied more broadly.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ve introduced you to the basics of microscopy and to some
    basic machine learning approaches to microscopy systems. We’ve provided a broad
    introduction to some of the fundamental questions of modern microscopy (especially
    as applied to biological problems) and have discussed where deep learning has
    already had an impact and hinted at places where it could have an even greater
    impact in the future.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: We’ve also provided a thorough overview of some of the physics and biology surrounding
    microscopy, and tried to convey why this information might be useful even if to
    developers who are primarily interested in building effective pipelines for handling
    microscopy images and models. Knowledge of physical principles such as the diffraction
    limit will allow you to understand why different microscopy techniques are used
    and how deep learning might prove critical for the future of the field. Knowledge
    of biological sample preparation techniques will help you understand the types
    of metadata and annotations that will be important to track when designing a practical
    microscopy system.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: While we’re very excited about the potential applications of deep learning techniques
    in microscopy, it’s important for us to emphasize that these methods come with
    a number of caveats. For one, a number of recent studies have highlighted the
    brittleness of visual convolutional models.^([4](ch07.xhtml#idm45806166581224))
    Simple artifacts can trip up such models and cause significant issues. For example,
    the image of a stop sign could be slightly perturbed so that a model classifies
    it as a green traffic light. That would be disastrous for a self-driving car!
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Given this evidence, it’s worth asking what the potential pitfalls are with
    models for deep microscopy. Is it possible that deep microscopy models are simply
    backfilling from memorized previous data points? Even if this isn’t the entire
    explanation for their performance, it is likely that at least part of the power
    of such deep models comes from such regurgitation of memorized data. This could
    very well result in imputation of spurious correlations. As a result, when doing
    scientific analysis on microscopic datasets, it will be critical to stop and question
    whether your results are due to model artifacts or genuine biological phenomena.
    We will provide some tools for you to critically probe models in upcoming chapters
    so you can better determine what your model has actually learned.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore applications of deep learning for medicine.
    We will reuse many of the skills for visual deep learning that we covered in this
    chapter.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '^([1](ch07.xhtml#idm45806168013304-marker)) Ouyang, Wei, et al. “Deep Learning
    Massively Accelerates Super-Resolution Localization Microscopy.” *Nature Biotechnology*
    36 (April 2018): 460–468\. [*https://doi.org/10.1038/nbt.4106*](https://doi.org/10.1038/nbt.4106).'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch07.xhtml#idm45806167992424-marker)) Tao, Xin, et al. “Scale-Recurrent
    Network for Deep Image Deblurring.” [*https://arxiv.org/pdf/1802.01770.pdf*](https://arxiv.org/pdf/1802.01770.pdf).
    2018.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '^([3](ch07.xhtml#idm45806166492536-marker)) Christensen, Eric. “In Silico Labeling:
    Predicting Fluorescent Labels in Unlabeled Images.” [*https://github.com/google/in-silico-labeling*](https://github.com/google/in-silico-labeling).'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch07.xhtml#idm45806166581224-marker)) Rosenfeld, Amir, Richard Zemel,
    and John K. Tsotsos. “The Elephant in the Room.” [*https://arxiv.org/abs/1808.03305*](https://arxiv.org/abs/1808.03305).
    2018.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
