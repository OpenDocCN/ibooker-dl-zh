["```py\np * loss(image1) + (1-p) * loss(image2)\n```", "```py\ndef train(model, optimizer, loss_fn, train_loader, val_loader,\nepochs=20, device, mix_loader):\n  for epoch in range(epochs):\n    model.train()\n    for batch in zip(train_loader,mix_loader):\n      ((inputs, targets),(inputs_mix, targets_mix)) = batch\n      optimizer.zero_grad()\n      inputs = inputs.to(device)\n      targets = targets.to(device)\n      inputs_mix = inputs_mix.to(device)\n      target_mix = targets_mix.to(device)\n\n      distribution = torch.distributions.beta.Beta(0.5,0.5)\n      beta = distribution.expand(torch.zeros(batch_size).shape).sample().to(device)\n\n      # We need to transform the shape of beta\n      # to be in the same dimensions as our input tensor\n      # [batch_size, channels, height, width]\n\n      mixup = beta[:, None, None, None]\n\n      inputs_mixed = (mixup * inputs) + (1-mixup * inputs_mix)\n\n      # Targets are mixed using beta as they have the same shape\n\n      targets_mixed = (beta * targets) + (1-beta * inputs_mix)\n\n      output_mixed = model(inputs_mixed)\n\n      # Multiply losses by beta and 1-beta,\n      # sum and get average of the two mixed losses\n\n      loss = (loss_fn(output, targets) * beta\n             + loss_fn(output, targets_mixed)\n             * (1-beta)).mean()\n\n      # Training method is as normal from herein on\n\n      loss.backward()\n      optimizer.step()\n      \u2026\n```", "```py\nshuffle = torch.randperm(inputs.size(0))\ninputs_mix = inputs[shuffle]\ntargets_mix = targets[shuffle]\n```", "```py\nmix_parameters = torch.max(mix_parameters, 1 - mix_parameters)\n```", "```py\nclass LabelSmoothingCrossEntropyLoss(nn.Module):\n    def __init__(self, epsilon=0.1):\n        super(LabelSmoothingCrossEntropyLoss, self).__init__()\n        self.epsilon = epsilon\n\n    def forward(self, output, target):\n        num_classes = output.size()[-1]\n        log_preds = F.log_softmax(output, dim=-1)\n        loss = (-log_preds.sum(dim=-1)).mean()\n        nll = F.nll_loss(log_preds, target)\n        final_loss = self.epsilon * loss / num_classes +\n                     (1-self.epsilon) * nll\n        return final_loss\n```", "```py\nclass OurFirstSRNet(nn.Module):\n\n  def __init__(self):\n      super(OurFirstSRNet, self).__init__()\n      self.features = nn.Sequential(\n          nn.Conv2d(3, 64, kernel_size=8, stride=4, padding=2),\n          nn.ReLU(inplace=True),\n          nn.Conv2d(64, 192, kernel_size=2, padding=2),\n          nn.ReLU(inplace=True),\n          nn.Conv2d(192, 256, kernel_size=2, padding=2),\n          nn.ReLU(inplace=True)\n      )\n\n  def forward(self, x):\n      x = self.features(x)\n      return x\n```", "```py\nclass OurFirstSRNet(nn.Module):\n  def __init__(self):\n      super(OurFirstSRNet, self).__init__()\n      self.features = nn.Sequential(\n          nn.Conv2d(3, 64, kernel_size=8, stride=4, padding=2),\n          nn.ReLU(inplace=True),\n          nn.Conv2d(64, 192, kernel_size=2, padding=2),\n          nn.ReLU(inplace=True),\n          nn.Conv2d(192, 256, kernel_size=2, padding=2),\n          nn.ReLU(inplace=True)\n\n      )\n      self.upsample = nn.Sequential(\n          nn.ConvTranspose2d(256,192,kernel_size=2, padding=2),\n          nn.ReLU(inplace=True),\n          nn.ConvTranspose2d(192,64,kernel_size=2, padding=2),\n          nn.ReLU(inplace=True),\n          nn.ConvTranspose2d(64,3, kernel_size=8, stride=4,padding=2),\n          nn.ReLU(inplace=True)\n      )\n\n  def forward(self, x):\n      x = self.features(x)\n      x = self.upsample(x)\n      return x\n```", "```py\nself.upsample = nn.Sequential(...\nnn.ConvTranspose2d(3,3, kernel_size=2, stride=2)\nnn.ReLU(inplace=True))\n```", "```py\nself.upsample = nn.Sequential(......\nnn.ConvTranspose2d(3,3, kernel_size=2, stride=2),\nnn.ReLU(inplace=True),\nnn.Conv2d(3,3, kernel_size=2, stride=2),\nnn.ReLU(inplace=True))\n```", "```py\ngenerator = Generator()\ndiscriminator = Discriminator()\n\n# Set up separate optimizers for each network\ngenerator_optimizer = ...\ndiscriminator_optimizer = ...\n\ndef gan_train():\n  for epoch in num_epochs:\n    for batch in real_train_loader:\n      discriminator.train()\n      generator.eval()\n      discriminator.zero_grad()\n\n      preds = discriminator(batch)\n      real_loss = criterion(preds, torch.ones_like(preds))\n      discriminator.backward()\n\n      fake_batch = generator(torch.rand(batch.shape))\n      fake_preds = discriminator(fake_batch)\n      fake_loss = criterion(fake_preds, torch.zeros_like(fake_preds))\n      discriminator.backward()\n\n      discriminator_optimizer.step()\n\n      discriminator.eval()\n      generator.train()\n      generator.zero_grad()\n\n      forged_batch = generator(torch.rand(batch.shape))\n      forged_preds = discriminator(forged_batch)\n      forged_loss = criterion(forged_preds, torch.ones_like(forged_preds))\n\n      generator.backward()\n      generator_optimizer.step()\n```", "```py\ngit clone https://github.com/xinntao/ESRGAN\n```", "```py\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nimport numpy as np\nimport sys\nfrom maskrcnn_benchmark.config import cfg\nfrom predictor import COCODemo\n\nconfig_file = \"../configs/caffe2/e2e_faster_rcnn_R_101_FPN_1x_caffe2.yaml\"\n\ncfg.merge_from_file(config_file)\ncfg.merge_from_list([\"MODEL.DEVICE\", \"cpu\"])\n\ncoco_demo = COCODemo(\n    cfg,\n    min_image_size=500,\n    confidence_threshold=0.7,\n)\n\npil_image = Image.open(sys.argv[1])\nimage = np.array(pil_image)[:, :, [2, 1, 0]]\npredictions = coco_demo.run_on_opencv_image(image)\npredictions = predictions[:,:,::-1]\n\nplt.imsave(sys.argv[2], predictions)\n```", "```py\ndocker build docker/\n```", "```py\nfrom maskrcnn_benchmark.structures.bounding_box import BoxList\n\nclass MyDataset(object):\n    def __init__(self, path, transforms=None):\n        self.images = # set up image list\n        self.boxes = # read in boxes\n        self.labels = # read in labels\n\n    def __getitem__(self, idx):\n        image = # Get PIL image from self.images\n        boxes = # Create a list of arrays, one per box in x1, y1, x2, y2 format\n        labels = # labels that correspond to the boxes\n\n        boxlist = BoxList(boxes, image.size, mode=\"xyxy\")\n        boxlist.add_field(\"labels\", labels)\n\n        if self.transforms:\n            image, boxlist = self.transforms(image, boxlist)\n\n        return image, boxlist, idx\n\n    def get_img_info(self, idx):\n        return {\"height\": img_height, \"width\": img_width\n```", "```py\nclass ModelToBreak(nn.Module):\n    def __init__(self):\n        super(ModelToBreak, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n```", "```py\ndef fgsm(input_tensor, labels, epsilon=0.02, loss_function, model):\n    outputs = model(input_tensor)\n    loss = loss_function(outputs, labels)\n    loss.backward(retain_graph=True)\n    fsgm = torch.sign(inputs.grad) * epsilon\n    return fgsm\n```", "```py\nmodel_to_break = # load our model to break here\nadversarial_mask = fgsm(frog_image.unsqueeze(-1),\n                        batch_labels,\n                        loss_function,\n                        model_to_break)\nadversarial_image = adversarial_mask.squeeze(0) + frog_image\n```", "```py\nmodel_to_break(adversarial_image.unsqueeze(-1))\n# look up in labels via argmax()\n>> 'cat'\n```", "```py\npip install pytorch-transformers\nconda install pytorch-transformers\n```", "```py\npip install fast-bert\n```", "```py\nimport torch\nimport logger\n\nfrom pytorch_transformers.tokenization import BertTokenizer\nfrom fast_bert.data import BertDataBunch\nfrom fast_bert.learner import BertLearner\nfrom fast_bert.metrics import accuracy\n\ndevice = torch.device('cuda')\nlogger = logging.getLogger()\nmetrics = [{'name': 'accuracy', 'function': accuracy}]\n\ntokenizer = BertTokenizer.from_pretrained\n                ('bert-base-uncased',\n                  do_lower_case=True)\n\ndatabunch = BertDataBunch([PATH_TO_DATA],\n                          [PATH_TO_LABELS],\n                          tokenizer,\n                          train_file=[TRAIN_CSV],\n                          val_file=[VAL_CSV],\n                          test_data=[TEST_CSV],\n                          text_col=[TEST_FEATURE_COL], label_col=[0],\n                          bs=64,\n                          maxlen=140,\n                          multi_gpu=False,\n                          multi_label=False)\n\nlearner = BertLearner.from_pretrained_model(databunch,\n                      'bert-base-uncased',\n                      metrics,\n                      device,\n                      logger,\n                      is_fp16=False,\n                      multi_gpu=False,\n                      multi_label=False)\n\nlearner.fit(3, lr='1e-2')\n```", "```py\n!pip3 install gpt-2-simple\n```", "```py\n!wget http://www.gutenberg.org/cache/epub/8164/pg8164.txt\n```", "```py\nimport gpt_2_simple as gpt2\n\ngpt2.download_gpt2(model_name=\"117M\")\n\nsess = gpt2.start_tf_sess()\ngpt2.finetune(sess,\n              \"pg8164.txt\",model_name=\"117M\",\n              steps=1000)\n```", "```py\ngpt2.copy_checkpoint_to_gdrive()\n```", "```py\nmv encoder.json vocab.json\nmv vocab.bpe merges.txt\n```", "```py\n python [REPO_DIR]/pytorch_transformers/convert_gpt2_checkpoint_to_pytorch.py\n --gpt2_checkpoint_path [SAVED_TENSORFLOW_MODEL_DIR]\n --pytorch_dump_folder_path [SAVED_TENSORFLOW_MODEL_DIR]\n```", "```py\nfrom pytorch_transformers import GPT2LMHeadModel\n\nmodel = GPT2LMHeadModel.from_pretrained([SAVED_TENSORFLOW_MODEL_DIR])\n```", "```py\npython [REPO_DIR]/pytorch-transformers/examples/run_gpt2.py\n--model_name_or_path [SAVED_TENSORFLOW_MODEL_DIR]\n```", "```py\ndata_lm = (TextList\n           .from_csv(\"./twitter-data/\",\n           'train-processed.csv', cols=5,\n           vocab=data_lm.vocab)\n           .split_by_rand_pct()\n           .label_from_df(cols=0)\n           .databunch())\n```", "```py\nlearn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n```", "```py\nlearn.lr_find()\nlearn.recorder.plot()\n```", "```py\nlearn.fit_one_cycle(1, 1e-2)\nlearn.save_encoder('twitter_encoder')\n```", "```py\ntwitter_classifier_bunch = TextList\n           .from_csv(\"./twitter-data/\",\n           'train-processed.csv', cols=5,\n           vocab=data_lm.vocab)\n           .split_by_rand_pct()\n           .label_from_df(cols=0)\n           .databunch())\n```", "```py\nlearn = text_classifier_learner(data_clas, drop_mult=0.5)\nlearn.load_encoder('fine_tuned_enc')\n\nlearn.lr_find()\nlearn.recorder.plot()\n\nlearn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n```"]