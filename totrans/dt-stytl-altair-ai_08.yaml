- en: '7 From information to knowledge: Building textual context'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Introducing context
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calibrating the story to the audience
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using ChatGPT for commentaries and annotations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using large language models for textual context
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A case study: From information to knowledge (part 1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Talking about knowledge in a computer science book might seem completely out
    of place. The word *knowledge* could inspire philosophical concepts or even intimidate.
    But in this chapter (and the next), we will not be talking about philosophical
    knowledge but, rather, the knowledge that helps the reader understand the context
    of a story. It is, therefore, knowledge applied to the context of our data story,
    rather than general knowledge. In these chapters, we will review the basic concepts
    behind context in a data story and how to adapt it based on the audience. First,
    we will focus on textual context in this chapter, and in the next one, we will
    cover images. We will introduce large language models (LLMs) and use ChatGPT as
    an example of LLM implementation for data storytelling. Finally, we will explore
    a practical example.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Introducing context
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When I was a child, I often heard my parents discussing some topic and did not
    understand anything. Their words rang in my ears as meaningless until, eager to
    understand what they were talking about, I entered the conversation and asked
    for explanations. Then, my father or mother, very patiently, explained to me what
    they were talking about, adapting their adult reasoning to my child’s mind so
    that I, too, could understand. Years later, I found myself in the same situation
    as a mother. My children often ask me to explain more complex speech *in words
    they can understand*. And the satisfaction is enormous when I see their faces
    light up and understand what I’m saying.
  prefs: []
  type: TYPE_NORMAL
- en: The examples described show us the need to adapt the words we use according
    to the audience we are addressing. If we ignore who will receive our story, we
    risk talking in a way that may make perfect sense to ourselves but which excludes
    our audience from the message we want to communicate.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we looked at how to extract and represent an insight
    through a chart. The next step is to enrich the chart with context (text and images),
    making reading easier for the reference audience. *Context* refers to the surrounding
    elements allowing the audience to understand the displayed information, such as
    texts, images, and symbols. Data context should prepare the scene of your data
    story and raise interest in your audience. In this chapter, we’ll primarily be
    dealing with textual context, while in the next chapter, we’ll look more at visual
    context.
  prefs: []
  type: TYPE_NORMAL
- en: Context depends on the type of audience you are addressing. For example, if
    you are talking with an adult about how much you paid for a product, you don’t
    need to explain how money works. On the other hand, if you are talking to your
    kids about the same topic, you probably need to explain the denominations of the
    different banknotes and how the monetary system works.
  prefs: []
  type: TYPE_NORMAL
- en: You can use generative AI tools, such as ChatGPT for text and DALL-E for images,
    to ease context building. You have already learned the basic techniques for building
    context using generative AI tools. This chapter will focus on more advanced techniques
    to write an impactful context tailored to your audience.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will consider the following types of context:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Commentary* —The text that precedes your insight. It includes the background
    that helps the audience to set the scene and understand the insight. In the example
    of the product cost explained to your kids, the commentary includes banknotes
    denominations, and how the monetary system works.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Annotation* —A short text that explains a detail of your chart, for example,
    an anomalous point or a trend line. Consider adding annotations only when necessary.
    Don’t overload your chart with unnecessary annotations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Image* —A picture enforcing the commentary or the annotation. In the example
    of the product cost, you could add banknote images to help your kids understand
    the different denominations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Symbols* —Arrows, circles, lines, and so on, combined with annotations. They
    help the audience focus on particular points of your chart.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the remainder of this chapter, we will use ChatGPT for commentaries and annotations.
    In the next chapter, we will focus on DALL-E for images and symbols. In addition,
    we will introduce LLMs and how to use them for commentaries and annotations. But
    first, let’s describe how to calibrate the story to our audience.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Calibrating the story to the audience
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A few years ago, I was invited to give a seminar to master’s students. The seminar
    topic concerned the implementation of web applications for the construction of
    data journalism projects. Unfortunately, I found myself faced with a somewhat
    embarrassing situation. My seminar topic was very technical, even commenting on
    some pieces of code. As I began to speak, I realized that the audience couldn’t
    follow me because they didn’t have the technical skills required to properly understand.
    My presentation was technically correct, but having spoken too technically to
    a non-technical audience, the result of my talk was that the audience learned
    very little. The experience I gained from that episode taught me to always learn
    about the audience I will be addressing before communicating any message.
  prefs: []
  type: TYPE_NORMAL
- en: The *audience* is the person or the group of persons reading your data story.
    Understanding the target audience is crucial to building data stories that convey
    information effectively. In the previous chapter, we saw that you can use multiple
    types of charts to convey information (table 6.4). Once you’ve chosen the set
    of charts that answer your question, you can refine your choice, tailoring the
    chart to your audience.
  prefs: []
  type: TYPE_NORMAL
- en: 'In chapter 4, you learned that there are different types of audiences. For
    simplicity, in this chapter, we group them into three common types of audiences:'
  prefs: []
  type: TYPE_NORMAL
- en: General public
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executives
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Professionals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s investigate each type of audience separately. To explain how you can
    calibrate the chart to the target audience, we will use the case study described
    in chapter 4\. The objective of this case study was to understand which athletic
    disciplines our hypothetical team needed to continue to train to achieve the best
    possible results in the upcoming competitions. For convenience, figure 7.1 shows
    the complete data story we implemented: moving from data to wisdom.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 The use case described in chapter 4
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 7.2.1 General public
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This audience includes individuals from various backgrounds and levels of knowledge.
    They may have little to no previous knowledge of your topic. When crafting data
    stories for the general public, use precise language, avoid overwhelming them
    with too much information, and focus on presenting the most relevant insights
    visually and engagingly. The general public could find the chart shown in figure
    7.1 complex, with an unnecessary baseline. As an alternative to the chart in figure
    7.1, you could draw the chart shown in figure 7.2, which some audiences may find
    more appealing.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 The use case adapted to the general public
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This chart is called a multi-layer donut chart. We could have placed the images
    close to the relevant bars, but in this case, there wasn’t enough space, so we
    placed them in the center of the chart. In other scenarios, you might consider
    placing images next to the bars. You can find the complete code to generate this
    chart in the GitHub repository for the book under 07/general-public.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.2 Executives
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Executives are typically high-level decision makers in organizations, who rely
    on data-driven insights to make essential business choices. They often have limited
    time and need concise and actionable information. When creating data stories for
    executives, it is essential to present key findings, trends, and recommendations
    up front.
  prefs: []
  type: TYPE_NORMAL
- en: Use visualizations highlighting the most critical data points and providing
    a straightforward narrative linking the data to strategic goals. It can also be
    helpful to provide additional context or industry benchmarks to support your analysis.
    The chart shown in figure 7.1 could be great for executives because it does not
    contain many details and describes why we chose some sports, thanks to its baseline
    of 50%.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.3 Professionals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This audience consists of individuals with a specific domain expertise or professional
    background. They have a deeper understanding of data and require more analytical
    information. When creating data stories for professionals, explain the methodology,
    assumptions, and limitations of the data analysis. Consider including additional
    supporting data and references, allowing professionals to explore the data further.
  prefs: []
  type: TYPE_NORMAL
- en: As an alternative to the chart in figure 7.1, you could draw the chart shown
    in figure 7.3, which some audiences may understand easily. The figure shows only
    the chart, without any annotation or context. You can find the complete code to
    generate this chart in the GitHub repository for the book under 07/professionals.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 The use case adapted to professionals
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Table 7.1 summarizes what to represent in a chart based on the audience type.
    Now that you have learned how to adapt your chart based on the audience type,
    let’s move on to the next step: using ChatGPT for commentaries and annotations.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.1 What to represent in a chart based on the audience type
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Audience Type | Requirements | What to Represent |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| General public  | Understand data  | An appealing overview of insights  |'
  prefs: []
  type: TYPE_TB
- en: '| Executives  | High-level overview of data trends to aid strategic decision
    making  | Highlight critical metrics and trends influencing business outcomes.  |'
  prefs: []
  type: TYPE_TB
- en: '| Professionals  | Detailed insights to understand the phenomenon behind data  |
    Add numbers, statistics, and useful information to understand insights deeply.  |'
  prefs: []
  type: TYPE_TB
- en: 7.3 Using ChatGPT for commentaries and annotations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In his novella, *Metamorphosis*, Franz Kafka tells the story of Gregor Samsa,
    a traveling salesman who wakes up one morning transformed into a giant insect.
    Encased in this insect’s guise, Samsa cannot interact with his family or communicate
    his thoughts. Gregor’s family struggles to accept his transformation, leading
    to their relationship with Gregor deteriorating and Gregor becoming increasingly
    isolated. The novella unearths the fundamental isolation that emerges when one’s
    inner world remains inaccessible to others. Data analysts could find themselves
    in a situation quite similar to that experienced by Gregor Samsa in Kafka’s novella
    when they have to add text to a data visualization chart. The data analyst, by
    nature, is a technician and could encounter some difficulties in writing engaging
    text.
  prefs: []
  type: TYPE_NORMAL
- en: 'ChatGPT can assist you in adding textual context to your data visualization
    chart. You have already learned that a prompt’s basic structure for ChatGPT comprises
    three main elements: role, audience, and task.'
  prefs: []
  type: TYPE_NORMAL
- en: For example, you can write *Act as an entertainer* (role)*, writing for decision
    makers* (audience)*. Write 5 titles about <topic>* (task). The topic could be
    whatever you want. The main problem is structuring the topic so that ChatGPT produces
    the correct context. To include the topic in the ChatGPT prompt as well, we will
    generate context following the schema shown in figure 7.4.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-4.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 The schema used to generate context
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In a prompt, we specify the following four main elements:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Role* —The role you want ChatGPT to take. You learned about many role types
    in chapter 4, including entertainer, educator, informer, inspirer, inviter to
    action, and relationship builder.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Audience* —The audience of your chart. There are different types of audiences,
    such as the general public, executives, and professionals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Topic* —The subject of your chart.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Type* —The text type to generate, including annotations and commentaries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The process of generating context is iterative, in the sense that you can generate
    the context multiple times if you are not satisfied with the produced result.
    For example, you can adjust one or more elements to make ChatGPT converge on the
    desired output.
  prefs: []
  type: TYPE_NORMAL
- en: In the remainder of this section, we will focus on how to write the topic and
    type elements of the schema while keeping the role and the audience simple. However,
    you can adapt the strategies described for the topic and the audience to the other
    elements.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example of how to build the context, we will focus on the case study
    described in chapter 4 and shown in figure 7.1\. The following text summarizes
    the scenario for convenience: *Imagine you work in a sports company. You are training
    a team of young athletes in various disciplines. For each discipline, you have
    noted the world record and recorded the best time achieved by your team for comparison.
    Unfortunately, your company has limited investment funds available. Your boss
    asks you to understand which disciplines are worth training in, hoping to achieve
    good results in the upcoming competitions.*'
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.1 Describing the topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Describing the topic* means composing simple words that precisely depict for
    ChatGPT what you have discovered and shown in your chart. The more precise you
    are, the better the output will be.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To describe the topic, focus on three aspects: scenario, data, and insight,
    as shown in figure 7.5\. Let’s go through each of those three aspects in a bit
    more detail.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-5.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 The elements used to describe the topic
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Scenario
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Describe an overview of your scenario, including the background and objective
    of the analysis. For the scenario in figure 7.1, we could write the following
    prompt for ChatGPT: *We are training a team of young athletes in various disciplines.
    For each discipline, we have calculated the percentage improvement of each discipline
    compared to the world record in that discipline. The objective is to search for
    the best two disciplines to fund.*'
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Provide an overview of your data. This may include explaining the type of data,
    its source, and any manipulations you performed.
  prefs: []
  type: TYPE_NORMAL
- en: Describe the data using your own words, providing a more personalized description.
    By manually describing the data, you can highlight important patterns, trends,
    or correlations that may not be apparent through automated methods alone. Additionally,
    through manual descriptions, you can incorporate domain expertise observations.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the scenario in figure 7.1, write the following prompt text: *There are
    five sports disciplines: Rowing (percentage improvement = 62.32%), Cycling (57.64%),
    Sprinting (42.69%), Long-distance running (18.31%), and Swimming (12.38%).* Now
    that you have learned how to describe the data, let’s move on to the last step:
    describing insights.'
  prefs: []
  type: TYPE_NORMAL
- en: Insights
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Describe the central insights you have derived from the analysis, such as key
    patterns, trends, correlations, or relationships you have discovered. For the
    scenario in figure 7.2, include the following text: *Rowing and Cycling percentages
    are more significant than the baseline of 50%.* Before illustrating how we can
    build the audience description, let’s test the prompt built so far on ChatGPT.'
  prefs: []
  type: TYPE_NORMAL
- en: Test
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We write the following prompt: *Act as an inspirer. Write 5 titles for the
    following topic. There are five sports disciplines: Rowing (percentage improvement
    = 62.32%), Cycling (57.64%), Sprinting (42.69%), Long-distance running (18.31%),
    and Swimming (12.38%). Rowing and Cycling percentages are more significant than
    the baseline of 50%.* Figure 7.6 shows a possible output produced by ChatGPT.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 The five titles generated by ChatGPT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'As an alternative, you can ask ChatGPT to produce the context as follows: *Act
    as an inspirer. Write the context of a chart using 30 words for the following
    topic. There are five sports* *disciplines: Rowing (percentage improvement = 62.32%),
    Cycling (57.64%), Sprinting (42.69%),* *Long-distance running (18.31%), and Swimming
    (12.38%). Rowing and Cycling percentages are greater than the baseline of 50%.*
    Figure 7.7 shows a possible output produced by ChatGPT.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-7.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 The context generated by ChatGPT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Now that you have learned how to describe the topic, try to generate the context
    for the case studies described in chapter 1: the pets scenario. For example, you
    can act as an informer. For convenience, we summarize the scenario: *The organizers
    of an event dedicated to pets are collecting the type of pets that will participate.
    For each pet category, the organizers advertise the event on specific websites
    dedicated to that category. The organizers ask you to build a quick report about
    the current situation.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'For more details, please refer to chapter 1\. You can find a prompt with the
    generated context here: [https://mng.bz/EZvJ](https://mng.bz/EZvJ). For further
    practice, write the topic for the other scenarios described in the previous chapters.
    Now that you have learned how to describe the topic, let’s move on to the next
    element: describing the type.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.2 Describing the type
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We consider the following types: commentary and annotations. In the previous
    sections, you have seen different ways to instruct ChatGPT to generate context
    types, such as writing the context of a chart using 30 words.'
  prefs: []
  type: TYPE_NORMAL
- en: 'When describing the type, be as precise as possible, specifying the following
    aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: The type (commentary, annotation, or general text)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum number of words to generate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: My suggestion is to try different types and evaluate the results based on your
    needs.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.3 Setting custom instructions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ChatGPT enables you to configure custom instructions for all your new chats.
    For example, if we build our charts for the same audience type and act with the
    same role, we can use this property as a default configuration for ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: To enable custom instructions, access the ChatGPT web interface, click the three
    dots near your profile, and then click Custom Instructions. In the new window,
    write the custom instructions. For example, you can use the first box to configure
    your role as well as the target audience and the second box for more details,
    such as the number of words to generate, the tone, and the style, as shown in
    figure 7.8.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 The Custom Instructions dialog box
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Click the Save button to enable the custom instructions for new chats. If you
    want to disable this property, deselect the Enable for New Chats property in the
    dialog box. Then, click the Save button.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try the custom instructions with the previous text (we have removed the
    number of words to generate, since we have configured them in the custom instructions):
    *Write the context of a chart for the following topic. There are five sports disciplines:
    Rowing (percentage improvement = 62.32%), Cycling (57.64%), Sprinting (42.69%),
    Long-distance running (18.31%), and Swimming (12.38%). Rowing and Cycling percentages
    are greater than the baseline of 50%.*'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.9 shows a possible output. Notice, for example, the informal tone we
    have set in the custom instructions.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-9.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 A possible output produced when configuring custom instructions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For optimal usage of custom instructions in data storytelling, I suggest using
    them to configure the role and the audience. In addition, you can configure other
    specific details correlated to your job or data, as specified in the ChatGPT documentation
    ([https://mng.bz/8wAP](https://mng.bz/8wAP)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have learned how to use ChatGPT for commentaries and annotations,
    let’s move on to the next step: using large language models in a different way.
    So far, you have used the web interface provided by OpenAI to write your prompt
    for ChatGPT. Now, we will cover an advanced use of LLMs, based on APIs calls.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.4 Using large language models for context
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far, you have used three generative AI tools: Copilot for code generation,
    ChatGPT for text generation, and DALL-E for image generation. All these tools
    are examples of application usage of a *large language model* (LLM). An LLM is
    a machine learning (ML) model aimed at predicting plausible language. LLMs have
    exploded in popularity since 2017, when Google researchers introduced the concept
    of transformers, a revolutionary architecture that allowed the training of large
    language models, such as generative pretrained transformers (GPTs), on which ChatGPT
    is based, and bidirectional encoder representations from transformers (BERT).
    Transformers allowed for the training of LLMs on massive datasets, resulting in
    models with incredible language generation capabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will not focus on how LLMs work. Instead, we aim to demonstrate
    how you can use them effectively for data storytelling. However, if you’re interested
    in delving deeper into the technical aspects, a vast bibliography is available
    on the topic (Vaswani, 2017; Koenigstein, 2024).
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you embark on using LLM to build your data-driven story, it’s essential
    to ask yourself whether the model needs to know specific information related to
    your domain of work, as shown in figure 7.10\. If the answer is no, then you can
    safely continue using ChatGPT. If, however, your answer is yes, then you can apply
    one of the following techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Fine-tuning* —This technique adapts a pretrained LLM to a specific domain
    by updating its parameters on task-specific data, optimizing its performance for
    that domain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Retrieval augmented generation* —This technique combines information retrieval
    and language generation, enabling LLMs to incorporate external knowledge sources
    during the generation process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![figure](../Images/7-10.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 A criterion to establish whether to extend an LLM or not
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In the remainder of this section, we assume that your answer is yes and that
    you must tailor your LLM to your specific domain. A practical case where fine-tuning
    is useful could be when you must generate different data stories for the same
    type of audience or even the same audience. In this case, you could build your
    database with the same structure of annotations so that all new annotations have
    the same structure as the previous ones. This may generate some familiarity for
    your audience when they read your data stories. In other cases, you may need to
    use RAG, for example, when you have a long document and you want to build a short
    annotation for your data story based on it. Using RAG could help you to build
    textual summaries. Now that you have learned the potential benefits of extending
    the LLM, let’s start by analyzing the first strategy: fine-tuning.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.1 Fine-tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GPT-3 was trained on 17 gigabytes of data, and GPT-4, the most recent model
    of OpenAI, has 45 gigabytes of training data. This means they contain a variety
    of information you can use in almost all cases. However, in some cases, fine-tuning
    your model could provide better results.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning is the process of further training a pretrained language model on
    a specific dataset that is more relevant to your specific domain. During fine-tuning,
    you use a smaller dataset, which typically contains examples and specific input–output
    pairs relevant to your task. In practice, the dataset is a collection of samples,
    each containing the prompt and the suggested completion.
  prefs: []
  type: TYPE_NORMAL
- en: When you apply fine-tuning to data storytelling, you can build a different dataset
    for each audience type, leading to better results. For example, you can build
    a dataset for the general public, one for professionals, and another for decision
    makers. You can even create a different dataset for each scenario you work with
    (products, topic, and so on) and for each type of text you want to generate (title,
    annotation, and commentary). The more specific your dataset is, the better your
    results will be.
  prefs: []
  type: TYPE_NORMAL
- en: 'Preparing the dataset is the most significant effort during the process of
    fine-tuning. In the remainder of this section, we will describe two strategies
    to prepare the dataset: manual building and building from sources. In both cases,
    we will use the OpenAI API. For more details on the installation, refer to appendix
    A.'
  prefs: []
  type: TYPE_NORMAL
- en: Manual building
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Manual building involves defining each pair (prompt, completion) manually.
    This solution enables you to obtain the best results since you specify the exact
    behavior of your model, given a specific input. Consider, for example, the following
    pair:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Prompt* —Generate a title for the general public about topic X.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Completion* —X revealed to you!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, imagine that you have fine-tuned your model with that pair and want to
    use your model to generate titles for the general public. If you give *the theory
    of relativity* topic as input to your fine-tuned model, it will probably generate
    a title similar to the following one: *The theory of relativity revealed to you!*
    The drawback of this strategy is that it is time consuming because you must write
    each pair manually.'
  prefs: []
  type: TYPE_NORMAL
- en: To start, you can define a minimum number of curated samples covering all your
    possible cases. The OpenAI model requires you to represent at least 10 samples.
    Next, train the model. After that, proceed with the model evaluation by considering
    the original model (i.e., without fine-tuning) as a reference. Provide the same
    prompt to the two models, original and fine-tuned, and compare the produced outputs.
    Use your new model if your fine-tuned model performs better than the original
    one. Instead, if it performs worse than or has the same behavior as the original
    model, try to add new samples or improve the existing ones. Repeat this procedure
    until you reach a good result.
  prefs: []
  type: TYPE_NORMAL
- en: To show how manual building works, we will build a dataset tailored for the
    general public and generate a commentary as an output. In the previous chapter,
    you saw that you should use a different chart based on the information you want
    to convey. Here, we will build a different output based on the information to
    convey. We will build one or more (prompt–completion) pairs for each type of information
    to convey. Table 7.2 shows a possible dataset representing the described scenario.
    You can find the code described in this section in the GitHub repository for the
    book under 07/manual-chatgpt-fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.2 The samples based on the information to convey
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Information to Convey | Prompt | Completion ^a |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Parts of a whole  | Percentage of participants in the conference by type
    (researchers 5%, students 30%, professors 65%)  | More professors participated
    in the conference (65%). Researchers were not interested in the event (5%).  |'
  prefs: []
  type: TYPE_TB
- en: '| Comparison among entities  | Comparison between red (80%), yellow, and green
    performance  | Compared to yellow and green, red experienced an improvement in
    performance of 80%.  |'
  prefs: []
  type: TYPE_TB
- en: '| Trend  | Sales changed in the last 12 months (–12%), due to fewer subscribers
    and video views.  | Over the last 12 months, sales decreased by 12% based on various
    metrics, including subscribers and video views.  |'
  prefs: []
  type: TYPE_TB
- en: '| Outcomes of a survey or a questionnaire  | Questionnaire: 3 positive answers,
    7 negative answers  | Three out of 10 people answered the questionnaire with a
    positive answer.  |'
  prefs: []
  type: TYPE_TB
- en: '| Distribution  | Sales of product A (+30%) and product B over the last 12
    months  | Compared to product B, sales of product A have increased by 30% over
    the last 12 months.  |'
  prefs: []
  type: TYPE_TB
- en: '| Spatial information  | Sales in North Europe (+23%) compared to South Europe  |
    Compared to South Europe, sales in North Europe increased by 23%.  |'
  prefs: []
  type: TYPE_TB
- en: '| Relationship  | The sales trend line from 1990 to 2020 increased by 120%.  |
    Between 1990 and 2020, sales increased by 120%.  |'
  prefs: []
  type: TYPE_TB
- en: '| Comparison among entities  | Top ingredients for our recipe: sugar and salt  |
    The chosen ingredients for our recipe are sugar and salt.  |'
  prefs: []
  type: TYPE_TB
- en: '| Comparison among entities  | Comparison between gold (30), silver (20), and
    bronze (40)  | Bronze beats silver and gold with 40\.  |'
  prefs: []
  type: TYPE_TB
- en: '| Distribution  | Distribution of household chores (cooking 35%, cleaning 30%,
    laundry 20%, and yard work 15%)  | Cooking takes up the most significant portion
    at 35%. Cleaning follows at 30%, while laundry and yard work account for 20% and
    15%, respectively.  |'
  prefs: []
  type: TYPE_TB
- en: '| a. The word *completion* may be confusing, but it is used by the OpenAI API.
    *Completion* refers to the output produced by the model. |'
  prefs: []
  type: TYPE_TB
- en: Once you have built the dataset, you must format it as a JSONL file. This file
    contains a list of messages. Consider each message as a separate chat where you
    can specify a general configuration, the user prompt, and the assistant (model)
    output, as shown in the following listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.1 The structure of a JSONL file
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Note  Use the keyword `messages` to define the list of samples. Imagine each
    sample as a separate chat, where you can specify the model role: `system`, for
    general configuration; `user`, for user prompt; and `assistant`, for model output.'
  prefs: []
  type: TYPE_NORMAL
- en: If your dataset is saved as a CSV file, use the code shown in the following
    listing, which is also available in prepare-data.py, to convert it into JSONL.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.2 How to convert the CSV file into JSONL
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Note  First, load the dataset as a pandas DataFrame. Next, format it in the
    JSONL format, as described in listing 7.1\. Finally, save the generated JSONL
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are ready to fine-tune our model. We need an `OPENAI_API_KEY`, as specified
    in appendix A. If you are transitioning from a free to a for-fee plan, you might
    need to generate a new API key because the initial key does not work after the
    switch to a for-fee plan. Open a terminal, and export your `OPENAI_API_KEY` as
    an environment variable (`export` `OPENAI_API_KEY='my` `key'`). Next, upload the
    produced file to the OpenAI server, and when the uploading process is complete,
    create a job for fine-tuning. The following listing shows the code to perform
    these operations. Alternatively, read the tune-model.py script in the GitHub repository
    for the book. Remember that this option is exclusively available with the for-fee
    version.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.3 How to fine-tune the model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#1 An alternative way to get your key: openai.api_key = ‘MY_KEY’'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Creates a new dataset and uploads it to the OpenAI server'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Enters into a loop until the model is fine-tuned'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Create a new fine-tuning job'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Prints the model ID'
  prefs: []
  type: TYPE_NORMAL
- en: Note  First, use the `openai.File.create()` method to create a new dataset and
    upload it to the OpenAI server. Next, use the `openai.FineTuningJob.create()`
    method to create a fine-tuning job using GPT-3.5 Turbo. Wait until the job is
    completed. This could take a long time, depending on the dataset size. Once the
    model is trained, use the `fine_tuned_model` variable to print the information
    associated with the fine-tuned model.
  prefs: []
  type: TYPE_NORMAL
- en: The following listing shows an example of information printed after the execution
    of the fine-tune-model.py script. This fine-tuning would cost around $0.05.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.4 An example of information associated with a fine-tuned model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note  Some helpful information is provided, including the model type, the model
    ID, the hyperparameters used, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can use the fine-tuned model to generate new commentaries tailored to
    the general public. Use the value corresponding to the `fine_tuned_model` key
    of the previous listing to refer to your model (`"ft:gpt-3.5-turbo-0613:personal::7t1Xuct5"`
    in the example).
  prefs: []
  type: TYPE_NORMAL
- en: To generate a new commentary, start a new chat session by using the `openai.ChatCompletion.create()`
    method, as shown in the following listing and in the generate-description.py script
    of the GitHub repository for the book. As a use case, consider again the example
    of figure 7.1.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.5 How to generate a new commentary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Note  Create a new `ChatCompletion` instance by specifying the model ID and
    the list of messages. The example defines only one message with the same system
    role as the fine-tuning dataset and the user role with a short description of
    our scenario.
  prefs: []
  type: TYPE_NORMAL
- en: The following listing shows an example output.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.6 An example output
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Note  The output contains the role (assistant) and the content.
  prefs: []
  type: TYPE_NORMAL
- en: Incorporate the produced content into your chart as a commentary. This example
    has demonstrated how you can perform model fine-tuning using a manual dataset.
    In the example, the output is straightforward. If you want your model to produce
    more complex outputs, you must complicate your fine-tuning dataset—for example,
    by adding new pairs (prompt–completion) specifically designed for your audience
    or your topic.
  prefs: []
  type: TYPE_NORMAL
- en: For comparison with the fine-tuned model, figure 7.11 shows the output produced
    by ChatGPT (without fine-tuning) with a similar input. Now that you have learned
    how to build your dataset manually, let’s move on to the next strategy, building
    from sources.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-11.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 The output produced by ChatGPT without fine-tuning
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Building from sources
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This strategy involves building your dataset from external sources, such as
    your company website or a domain-specific blog. For example, if you work in the
    health field, you could download the title and abstracts of scientific papers
    about health. This enables you to build a dataset with a very domain-specific
    language. Or if you work in the ICT field, you can download the titles and subtitles
    of blog articles from feeds to build your technical dataset. Anyway, you must
    pay attention to the data license in all cases. If the license explicitly prohibits
    their usage, you cannot use those sources, and you must search for other data
    sources. In some cases, contacting the data author directly could be sufficient—for
    example, if you want to download their data.
  prefs: []
  type: TYPE_NORMAL
- en: In the remainder of this section, we will build a dataset tailored to a technical
    audience by extracting feeds from my Medium blog. The objective is to build a
    chart title corresponding to the blog title, providing the blog subheading as
    an input. You can find the example in the GitHub repository for the book under
    07/from-source-chatgpt-fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: First, download the data. Ask Copilot to generate the code for you. The following
    listing shows the instructions for Copilot.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.7 The instructions for Copilot
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note  Specify the feed URL and the information to extract for each item. Also,
    ask Copilot to generate the code to save the extracted items into a CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: Copilot will generate an output similar to that shown in listing 7.8\. Set the
    prompt to the subheading and the completion to the title. Save the script, and
    run it. You can find the code generated by Copilot in the GitHub repository for
    the book in the download-raw-data.py script. You should see the medium-articles.csv
    file in your working directory.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.8 How to extract data from feeds
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Note  Use the `feedparser`, `requests`, and `bs4` libraries. If you don’t have
    them in your environment, install them using the pip package manager.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have built the dataset, follow the procedure described in section 7.4.1
    to fine-tune the dataset (listings 7.2–7.6). You can find the complete example
    in the GitHub repository for the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'To test the fine-tuned model, provide the following prompt as input: *A chart
    on selecting the best sport to fund*. The model generates an output similar to
    the following: *How to Choose the Best Sport to Fund: A Data-Driven Approach*.
    Try a similar prompt with ChatGPT. Figure 7.12 shows a possible output. Since
    ChatGPT is not fine-tuned, you must specify more details in your prompt, as previously
    seen. Instead, for your fine-tuned model, describing the content in your prompt
    is sufficient. Now that you have learned how to perform fine-tuning for data storytelling,
    let’s move on to the next strategy for adapting your model to your specific context:
    retrieval augmented generation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-12.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.12 The output produced by ChatGPT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 7.4.2 Retrieval augmented generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, you have seen how to adapt an LLM to a context by building an ad hoc
    dataset. The effort, in this case, consists in preparing the dataset. Imagine
    how nice it would be to pass a text directly to the LLM without converting it
    to a specific format. Well, the good news is that this is possible, thanks to
    retrieval augmented generation (RAG).
  prefs: []
  type: TYPE_NORMAL
- en: RAG is an advanced natural language processing (NLP) technique that combines
    elements of information retrieval and text generation. First, RAG performs a retrieval
    step, which queries an external knowledge source, such as a vast text corpus or
    a structured database. Next, RAG uses this knowledge source to enhance its response
    generation. RAG integrates the retrieved facts into its generated text.
  prefs: []
  type: TYPE_NORMAL
- en: In the data storytelling domain, you can use RAG to adapt your LLM to your topic,
    such as a product, real-time data, customer reviews, or other relevant information.
    For instance, by querying the knowledge base for specific product details, you
    can generate ad hoc commentaries and annotations.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine you want to build a RAG-based system that retrieves information about
    a product from your website company. Figure 7.13 shows the architecture of the
    RAG system we will implement.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-13.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.13 A RAG-based system
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: First, we will download the text from a specified URL, split it, and represent
    it as vectors we store in a vector database. We will provide the vector database
    as an input to an LLM application, which can answer queries by querying the vector
    database. We will implement an example that generates commentaries for a specific
    smartphone, based on its description contained in an HTML page. In practice, we
    will load the HTML page into the vector database, and then we will implement an
    LLM application to query it. We will use LangChain to implement the LLM application,
    Chroma for the vector database, and OpenAI for the LLM to make everything work.
    For more details on how to install these tools, refer to appendix A.
  prefs: []
  type: TYPE_NORMAL
- en: In the remainder of this section, you will learn how to implement the described
    system. We will start by introducing LangChain. Next, we will see how to store
    data in Chroma. Finally, you will learn how to query the built system.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing LangChain
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: LangChain ([https://www.langchain.com/](https://www.langchain.com/)) is a framework
    that enables you to create applications that connect an LLM to other sources.
    LangChain supports several providers, including OpenAI, Google, Microsoft, Hugging
    Face, and many more. In this book, we will focus on the models provided by OpenAI.
  prefs: []
  type: TYPE_NORMAL
- en: 'The core idea behind LangChain is the concept of a chain, which consists of
    several components from different modules. There are three main components:'
  prefs: []
  type: TYPE_NORMAL
- en: '*LLM wrappers* —Wrappers for LLMs provided by external providers, such as OpenAI
    and Hugging Face'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Prompt templates* —Templates for different prompts, such as chatbot and question
    answering'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Indexes* —External structures you can use to provide additional context to
    an LLM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The LangChain-based applications are *context aware* because they connect LLM
    to external sources. Additionally, such applications are useful because they can
    answer questions based on the provided context, what actions to take, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most straightforward chain consists of just one LLM chained with a prompt
    that enables you to query the model. In the remainder of this section, we will
    implement a LangChain composed of the components shown in figure 7.14: the vector
    database (Chroma), the prompt template, the LLM model (GPT-3.5 Turbo by OpenAI),
    and the retrieval interface.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-14.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.14 The implemented architecture
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You can find the full code described in this example in the GitHub repository
    of this book under 07/rag. We need an `OPENAI_API_KEY`, as specified in appendix
    A. Open a terminal, and export your `OPENAI_API_KEY` as an environment variable
    (`export` `OPENAI_API_KEY='my` `key'`).
  prefs: []
  type: TYPE_NORMAL
- en: Chroma ([https://www.trychroma.com/](https://www.trychroma.com/)) is an embedding
    database you can use as an indexer for your LangChain. To install and configure
    Chroma, refer to appendix A. An *embedding* is a numerical representation of data
    that is easy to index and retrieve, often for real-time tasks (Lane and Dyshel,
    2024). Before storing a text in Chroma, we must convert it into vector embeddings.
    For more details about embeddings, refer to the references section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the product description available on a hypothetical website, as shown
    in figure 7.15\. The objective of our task is to store the product description
    shown in figure 7.15 in Chroma.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-15.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.15 The HTML page with the product description
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The first step involves loading the data from the URL, as shown in the following
    listing. Since Chroma is fully integrated with LangChain, we will use it to accomplish
    our task. LangChain supports multiple formats, including PDFs, URLs, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.9 How to load the HTML document in LangChain
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Loads data'
  prefs: []
  type: TYPE_NORMAL
- en: Note  To load an HTML document in LangChain, build an `UnstructuredHTMLLoader()`
    object.
  prefs: []
  type: TYPE_NORMAL
- en: Next, split the data into chunks of 20, as shown in the following listing. We
    could have chosen any number smaller than the total text size for the chunk size.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.10 How to split the text into chunks
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note  Create a `RecursiveCharacterTextSplitter()` object to split the text into
    chunks.
  prefs: []
  type: TYPE_NORMAL
- en: After that, convert the split text into embeddings and store them in Chroma.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.11 How to generate embeddings in Chroma
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Note  First, create a new `OpenAIEmbeddings()` object. Next, create a Chroma
    store with the split data and the embeddings and associate it with the collection
    `Product-Info`. Finally, store the Chroma store on the filesystem, using the `persist()`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, our vector store is ready, so we can move on to the next step: defining
    a prompt template.'
  prefs: []
  type: TYPE_NORMAL
- en: Defining a prompt template
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A prompt template is a predefined text used for generating prompts for LLMs.
    A prompt template may include instructions, examples, context, and questions appropriate
    for your task. The following listing shows an example of a prompt we can provide
    as an input to our system.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.12 How to structure a prompt template
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Note  First, define the structure of your template. Use brackets to define
    input variables. In the example, there are two variables: `context` and `question`.
    Next, create a new `PromptTemplate()` object, and pass it the template and the
    input variables as parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have built the prompt template, we are ready to proceed with the last
    step: retrieval and query.'
  prefs: []
  type: TYPE_NORMAL
- en: Retrieval interface
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A *retrieval interface* is an interface that enables us to combine the data
    stored in the Chroma database and the OpenAI LLM. We can use a retrieval to query
    our system and generate commentaries and annotations to incorporate in our charts.
    The following listing shows an example of the usage of a retrieval.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.13 How to build a retrieval
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Note  First, create an LLM instance using `ChatOpenAI()`. Set the temperature
    to 0 for conservative output. The temperature spans from 0 (low creativity) to
    1 (high creativity). Set the model to `GPT-3.5-turbo`. Next, create a retrieval
    interface using `RetrievalQA()` by specifying the LLM, the vector store (`retriever`),
    the prompt, and other parameters. Set the `chain_type` to `stuff`, a prepackaged
    document chain that takes a list of documents and inserts them into the prompt,
    which is then passed to the LLM. Finally, ask the question.
  prefs: []
  type: TYPE_NORMAL
- en: The following listing shows the produced output. You can insert the produced
    text (in bold) in your chart.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.14 The produced output
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Note  The output contains the text to insert in the chart (in bold) and other
    useful information, such as the original query and the source documents.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have learned how to apply LLMs to build context in data storytelling,
    let’s move on to a practical example.
  prefs: []
  type: TYPE_NORMAL
- en: '7.5 Case study: From information to knowledge (part 1)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous chapter, we analyzed how to turn data into information in the
    aquaculture case study. As a quick reminder, the case study involved building
    a story around the problem of safety in the salmon aquaculture in the United States.
    We decided to plot the salmon aquaculture sales trend line versus the other types
    of aquaculture. As an insight, we discovered that since 1998, there had been an
    increase in sales, following a period of decrease in sales from 1992 to 1998\.
    We discovered that the decreasing period was partially due to some health problems
    in the salmon aquaculture. Figure 7.16 shows the chart produced at the end of
    the first step of the DIKW pyramid: from data to information.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-16.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.16 The chart produced at the end of the data-to-information phase
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'To transform the chart into a data story, the next step involves turning information
    into knowledge. We will accomplish this by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Some design considerations to tailor the chart to the audience
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding a commentary describing the general situation regarding safety in aquaculture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding an annotation and a symbol to highlight the period of decrease in sales
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s start with the first point: tailoring the chart to the audience.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.1 Tailoring the chart to the audience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The scenario required us to present the data story to an audience of executives,
    which meant we needed a chart easy enough to understand that they could quickly
    make decisions based on its information. In general, executives are familiar with
    trend lines, so we do not need to modify the chart. In addition, the chart is
    neither too detailed nor too simple. It contains the right level of detail to
    allow the audience not to be overwhelmed by information. Additionally, the chart
    doesn’t give the impression of being sparse. Therefore, we can conclude that the
    chart type is perfect for our audience.
  prefs: []
  type: TYPE_NORMAL
- en: We also suppose that our audience is familiar with the $ symbol on the y-axis
    and the Years label on the x-axis, so we do not need to add any further specifications.
    We can leave the comparison between the salmon trend line and the others because
    it is useful for our audience to understand how the salmon sales behave compared
    to the other categories. It is not necessary to add further details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Challenge: How could you tailor the chart to the general public or to an audience
    of professionals?'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For the general public, you could consider simplifying the chart—for example,
    by reducing the number of years. You may also need to better explain the meaning
    of the y-axis. For professionals, you could add more details, such as points with
    values for each year, or you could even show the other aquaculture categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have discussed some design considerations to tailor the chart to
    the audience, let’s move on to the next step: adding a commentary. We will use
    RAG to generate the commentary.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.2 Using RAG to add a commentary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will add a commentary to the chart immediately under the title. Our commentary
    should explain how safety works in US aquaculture. We will base the commentary
    on “Aquacultured Seafood” ([https://mng.bz/WEW0](https://mng.bz/WEW0)), an official
    FDA fact sheet. This document describes, among other topics, the safety levels
    of aquaculture seafood.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can implement a RAG-based system that builds required commentary using
    the code implemented in section 7.4.2\. You only need to provide this prompt:
    *Describe* *the safety of aquaculture seafood in the U.S*. The code of the implemented
    RAG system is also available in the GitHub repository for the book under CaseStudies/aquaculture/
    from-information-to-knowledge/rag.py. The following listing shows the produced
    output, containing the required commentary.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.15 The produced output
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Note  Use the produced output as a commentary for the chart.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we can add this text as a commentary for our chart. Listing 7.16 shows
    only the modifications to our original chart including the commentary. You can
    find the complete code in the GitHub repository for the book under CaseStudies/aquaculture/
    from-information-to-knowledge/chart.py.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.16 The commentary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Note  Use the `title` property to add commentary to the chart, immediately before
    the title. Also, add a provisory title to the chart.
  prefs: []
  type: TYPE_NORMAL
- en: The next step involves highlighting the period of decrease in sales. So let’s
    proceed.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.3 Highlighting the period of decrease in sales
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The period of decrease in sales ranges from 1992 to 1998\. We want to highlight
    it to let the audience know that during this period, there were health problems
    in the salmon aquaculture. This will prepare the audience to consider respecting
    the safety rules to avoid the same problems in the future. We will add two elements
    to highlight this decreasing period:'
  prefs: []
  type: TYPE_NORMAL
- en: A light-gray rectangle covering the decreasing period
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A textual annotation describing the health problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following listing shows the code to build the rectangle.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.17 The rectangle
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '#1 A magic number to set the upper part of the chart'
  prefs: []
  type: TYPE_NORMAL
- en: Note  First, build a DataFrame with the rectangle’s coordinates. Next, draw
    the rectangle using `mark_rect()`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Challenge: Which instructions could you write for Copilot to speed up the coding
    process?'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'You could try adding the following instruction to generate the rectangle: `#`
    `Add` `a` `rectangle` `starting` `from` `1993` `to` `2000`. What output would
    you obtain?'
  prefs: []
  type: TYPE_NORMAL
- en: The following listing shows the code to add the annotation. The decline in sales
    was partially due to fish health issues.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.18 The annotation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note  First, build a DataFrame with the annotation text and its position information.
    Next, draw the annotation using `mark_text()`. Finally, plot and save the chart.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7.17 shows the final chart, after adding context; we have turned information
    into knowledge. In the next chapter, we will further enrich context by adding
    some images, and in chapter 9, we will complete the story by adding the next step:
    wisdom.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/7-17.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.17 The chart produced at the end of the information-to-knowledge phase
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You have now implemented a practical example of turning information into knowledge.
    Before moving to the next chapter, let’s further solidify the concept by completing
    a practical exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.4 Exercise
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Modify the previous chart as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Tailor the chart to an audience of professionals.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add points to the salmon line chart. Suggestion: Use `point=True` as a parameter
    of `mark_line().`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Add values for each point. Suggestion: Use `mark_text()` to add values for
    each point.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Implement a RAG-based system to extract an annotation for the decreasing period
    from the *Governor’s Task Force on the Planning and Development of Marine Aquaculture
    in Maine Report and Recommendations* (pp. 28–32, [https://mng.bz/jXqx](https://mng.bz/jXqx)).
    Suggestion: Use `PDFMinerLoader()` to extract data from PDF. You may need to install
    some additional Python packages, including pdf2image, pdfminer, and pdfminer.six.
    You can find the solution in the GitHub repository for the book under CaseStudies/aquaculture/from-information-to-knowledge/rag-annotation.py.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the first part of this chapter, you learned how to turn information into
    knowledge by adding context to your data visualization chart. You saw that context
    depends on the audience reading your chart. For example, if your chart will be
    read by the general public, avoid technical details and use an appealing visualization.
    On the other hand, if your chart will be read by technical experts, add as many
    details as you can, while keeping the chart easy to read. In the second part of
    the chapter, you saw how to use generative AI tools as assistants to build your
    context. Finally, you learned where to put the textual context in your chart.
    In the next chapter, you will see how to add images to your chart to enrich context.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adding context to your data visualization is crucial for turning information
    into knowledge. Textual context includes all the relevant facts and events useful
    for the audience to understand data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When you build a chart, tailor it to the audience. In general, there are three
    types of audiences: the general public, professionals, and executives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use generative AI tools as assistants to help create context for your data.
    In particular, use ChatGPT to generate commentaries and annotations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If ChatGPT needs to know custom data or topics, extend your LLM with fine-tuning
    or RAG.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning enables you to optimize a pretrained LLM based on a dataset of prompt–completion
    pairs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retrieval augmented generation uses an external database, called a *vector database*,
    to extend the LLM knowledge with domain-specific topics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Lane, H. and Dyshel, M. (2024). *Natural Language Processing in Action* (2nd
    ed.). Manning Publications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI. (n.d.). *Embeddings*. [https://platform.openai.com/docs/guides/embeddings](https://platform.openai.com/docs/guides/embeddings).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Bantilan, N. (2023). *Fine Tuning vs. Prompt Engineering Large Language Models.*
    [https://mlops.community/fine-tuning-vs-prompt-engineering-llms/](https://mlops.community/fine-tuning-vs-prompt-engineering-llms/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jolley, E. (2023). *Introduction to Retrieval Augmented Generation*. [https://arize.com/blog-course/introduction-to-retrieval-augmented-generation/](https://arize.com/blog-course/introduction-to-retrieval-augmented-generation/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marcelo, X. (2023). *How to Fine-Tune OpenAI GPT*. [https://medium.com/@marceloax.br/how-to-fine-tune-openai-gpt-3-d06741f915f4](https://medium.com/@marceloax.br/how-to-fine-tune-openai-gpt-3-d06741f915f4).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenAI. (n.d.). *Fine-Tuning.* [https://platform.openai.com/docs/guides/fine-tuning](https://platform.openai.com/docs/guides/fine-tuning).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LangChain
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Biswas, A. (2023). *How to Work with LangChain Python Modules.* [https://www.packtpub.com/article-hub/how-to-work-with-langchain-python-modules](https://www.packtpub.com/article-hub/how-to-work-with-langchain-python-modules).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geeks for Geeks. (2024). *Introduction to LangChain.* [https://www.geeksforgeeks.org/introduction-to-langchain/](https://www.geeksforgeeks.org/introduction-to-langchain/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pinecone. (n.d.). *LangChain: Introduction and Getting Started.* [https://www.pinecone.io/learn/series/langchain/langchain-intro/](https://www.pinecone.io/learn/series/langchain/langchain-intro/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'De Angelis, L., Baglivo, F., Arzilli, G., Privitera, G. P., Ferragina, P.,
    Tozzi, A. E., and Rizzo, C. (2023). *ChatGPT and the Rise of Large Language Models:
    The New AI-Driven Infodemic Threat in Public Health*. *Frontiers in Public Health*,
    *11*, 1166120\. [https://doi.org/10.3389/fpubh.2023.1166120](https://doi.org/10.3389/fpubh.2023.1166120).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Google Developers. (n.d.). *Introduction to Large Language Models.* [https://developers.google.com/machine-learning/resources/intro-llms?hl=en](https://developers.google.com/machine-learning/resources/intro-llms?hl=en).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RAG
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Jolley, E. (2023). *Introduction to Retrieval Augmented Generation.* [https://arize.com/blog-course/introduction-to-retrieval-augmented-generation](https://arize.com/blog-course/introduction-to-retrieval-augmented-generation).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Needham, M. (2023). *Learn Data with Mark*. [https://github.com/mneedham/LearnDataWithMark/tree/main](https://github.com/mneedham/LearnDataWithMark/tree/main).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ———. (2023). *Retrieval Augmented Generation with OpenAI/GPT and Chrom**a.*
    [https://www.youtube.com/watch?v=Cim1lNXvCzY](https://www.youtube.com/watch?v=Cim1lNXvCzY).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Routu, V. (2023). *Answering with OpenAI and LangChain: Harnessing the Potential
    of Retrieval Augmented Generation (RAG).* [https://www.linkedin.com/pulse/transforming-question-answering-openai-langchain-harnessing-routu/](https://www.linkedin.com/pulse/transforming-question-answering-openai-langchain-harnessing-routu/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schwaber-Cohen, R. (2023). *What Is a Vector Database?* [https://www.pinecone.io/learn/vector-database](https://www.pinecone.io/learn/vector-database).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thinking for the audience
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Bettes, S. (2019). *Technical and Professional Writing Genres.* [https://open.library.okstate.edu/technicalandprofessionalwriting/chapter/chapter-2/](https://open.library.okstate.edu/technicalandprofessionalwriting/chapter/chapter-2/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Emery, A. K. (2021). *Why “Know Your Audience” Is Terrible Dataviz Advice—And
    What to Do Instead.* [https://depictdatastudio.com/why-know-your-audience-is-terrible-dataviz-advice-what-to-do-instead/](https://depictdatastudio.com/why-know-your-audience-is-terrible-dataviz-advice-what-to-do-instead/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: QuantHub. (2023). *How to Identify Your Audience for Impactful Data Storytelling.*
    [https://www.quanthub.com/how-to-identify-your-audience-for-impactful-data-storytelling/](https://www.quanthub.com/how-to-identify-your-audience-for-impactful-data-storytelling/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LinkedIn Community with AI. (n.d.). *How Do You Engage and Nurture Your Technical
    Audience and Build Trust and Authority?* [https://www.linkedin.com/advice/0/how-do-you-engage-nurture-your-technical-audience](https://www.linkedin.com/advice/0/how-do-you-engage-nurture-your-technical-audience).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WirelessLAN Professionals. (n.d.). *How to Present to a Technical Audience.*
    [https://wlanprofessionals.com/how-to-present-to-a-technical-audience/](https://wlanprofessionals.com/how-to-present-to-a-technical-audience/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Koenigstein, N. (2024). *Transformers in Action*. Manning Publications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
    Kaiser, Ł., and Polosukhin, I. (2017). “Attention Is All You Need.” *Advances
    in Neural Information Processing Systems*, *30*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
