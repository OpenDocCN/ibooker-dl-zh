<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">5</span> </span> <span class="chapter-title-text">Improving weak understanding for traditional AI</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header">This chapter covers</h3> 
   <ul> 
    <li class="readable-text" id="p2">Identifying the types of errors a classifier can make</li> 
    <li class="readable-text" id="p3">Establishing a baseline of current classifier performance</li> 
    <li class="readable-text" id="p4">Using data science methodologies to identify and prioritize improvements</li> 
    <li class="readable-text" id="p5">Infusing your traditional AI with generated content to enhance understanding </li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p6"> 
   <p>In this chapter, we will demonstrate a methodical, iterative approach to improving the understanding of a classification-based conversational solution. This chapter builds on the concepts introduced in the previous chapter and uses the output produced by the final exercise in section 4.4 (where you created a test set with the golden intent assigned to each utterance in a format that can be used by your testing tool). Later in this chapter, we’ll explore how large language models can supplement intent-driven output responses to deliver a more robust experience. (If you’re looking for generative AI improvement techniques, feel free to skip ahead to the next chapter.) </p> 
  </div> 
  <div class="readable-text intended-text" id="p7"> 
   <p>We will start by building an improvement plan and identifying the types of errors your classifier may be committing. Next, we’ll iterate through seven improvement cycles to solve the various problems you might see in your own text classifier. Although data science techniques are used, you do not need to be a data scientist to extract meaningful insights about your data using the methodologies presented in this chapter.</p> 
  </div> 
  <div class="readable-text" id="p8"> 
   <h2 class=" readable-text-h2"><span class="num-string">5.1</span> Building your improvement plan</h2> 
  </div> 
  <div class="readable-text" id="p9"> 
   <p>If you built a blind test set using a sample from your production logs, you should have a reliable “representative distribution” test set. This means that the topics that are most frequently asked by your users are represented with corresponding volume in your testing data. This will be a key factor in prioritizing any problems that are surfaced by your test results. </p> 
  </div> 
  <div class="readable-text intended-text" id="p10"> 
   <p>If you are working with the results of a <em>k</em>-fold test (discussed in chapter 4), you won’t know for certain which topics are the most important, so the most egregious accuracy scores are a logical starting point. </p> 
  </div> 
  <div class="readable-text intended-text" id="p11"> 
   <p>In either case, it’s now time to dig into those test results. An improvement plan starts with identifying the biggest problem spots in the bot’s training.</p> 
  </div> 
  <div class="readable-text" id="p12"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.1.1</span> Identify problematic patterns in misunderstood utterances</h3> 
  </div> 
  <div class="readable-text" id="p13"> 
   <p>The first score that will grab your attention is the overall accuracy of your test results. This is a lot like getting back a spelling or math test and looking at the red ink at the top of the page. If your test had 100 questions and you got 79 of them correct, your accuracy score would be 79%. For classifiers, this number is good for an “at a glance” view of the model, but it doesn’t give a complete picture of what is going on or where to start making improvements. For that, we need to understand the possible outcomes and types of errors our classifier may be committing. This is revealed in the measurements of recall, precision, and F1 score.</p> 
  </div> 
  <div class="readable-text" id="p14"> 
   <h4 class=" readable-text-h4">A brief explanation of recall, precision, and F1 scores</h4> 
  </div> 
  <div class="readable-text" id="p15"> 
   <p>In chapter 4, we described <em>recall</em> as the classifier’s ability to predict a correct intent and <em>precision</em> as the ability to refrain from predicting a wrong intent. You can think of this in terms of positive and negative predictions. For every utterance that we test against the model, there are four possible outcomes, and they are not mutually exclusive, meaning that every prediction is going to have two or three of these outcomes happening simultaneously. Figure 5.1 shows a confusion matrix that visualizes these possible outcomes:<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p16">  
   <img alt="figure" src="../Images/CH05_F01_Freed2.png" width="390" height="271"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.1</span> In a 2 <span class="regular-symbol">×</span> 2 confusion matrix, the possible outcomes are derived by comparing the predicted intent to the actual intent.</h5>
  </div> 
  <ul> 
   <li class="readable-text" id="p17"> <em>True positive</em>—A prediction that matches the correct intent </li> 
   <li class="readable-text" id="p18"> <em>True negative</em>—A prediction that does not match an incorrect intent </li> 
   <li class="readable-text" id="p19"> <em>False positive</em>—A prediction that matches an incorrect intent </li> 
   <li class="readable-text" id="p20"> <em>False negative</em>—A prediction that does not match the correct intent </li> 
  </ul> 
  <div class="readable-text" id="p21"> 
   <p>The first metric that might interest us is the recall of our intents. For this, we need to know the true positives and the false negatives. An intent that is returning false negatives is committing an error of under-selection. When measured per intent, this looks like an accuracy score. If our test had five questions for the <code>#Request_Agent</code> intent, and the classifier got those questions correct four times, the intent’s recall would be 80%:</p> 
  </div> 
  <div class="readable-text indented-paragraph equation-paragraph" id="p22"> 
   <p><em>Recall = True positives / (True positives + False negatives)</em></p> 
  </div> 
  <div class="readable-text" id="p23"> 
   <p>The next metric that helps us understand our classifier is precision. This measures how good our classifier is at refraining from giving a false positive. An intent that is returning false positives is committing an error of over-selection. An example of over-selection can be seen in the last two rows of table 5.1: </p> 
  </div> 
  <div class="readable-text indented-paragraph equation-paragraph" id="p24"> 
   <p><em>Precision = True positives / (True positives + False positives)</em></p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p25"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.1</span> Test results show seven utterances, five of which are labeled with the correct <code>#Request_Agent</code> intent. The first four predictions were true positives. The last two rows show where <code>#Request_Agent</code> was predicted twice for utterances where it shouldn’t have been (“What can I ask you” and “Somebody hit my car”). These false positives contribute to our precision calculation: 4 / (4 + 2) = 0.66.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Utterance 
       </div></th> 
      <th> 
       <div>
         Correct intent 
       </div></th> 
      <th> 
       <div>
         Predicted intent 
       </div></th> 
      <th> 
       <div>
         Correct 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Customer service <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  Speak with an agent <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  Can I please speak with somebody? <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  Talk with a human <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  When will I get a live person? <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  <code>Office_Hours</code> <br/></td> 
      <td>  0 <br/></td> 
     </tr> 
     <tr> 
      <td>  What can I ask you? <br/></td> 
      <td>  <code>VA_Capabilities</code> <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  0 <br/></td> 
     </tr> 
     <tr> 
      <td>  Somebody hit my car <br/></td> 
      <td>  <code>Report_Accident</code> <br/></td> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  0 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p26"> 
   <p>A full analysis of all possible outcomes for <code>#Request_Agent</code> is shown in figure 5.2. It also shows the true negatives (which are not used in our calculations but have been included to demonstrate the range of other outcomes). </p> 
  </div> 
  <div class="browsable-container figure-container" id="p27">  
   <img alt="figure" src="../Images/CH05_F02_Freed2.png" width="1012" height="548"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.2</span> The highlighted columns are used for calculating precision and recall for <code>#Request_Agent</code>.</h5>
  </div> 
  <div class="readable-text" id="p28"> 
   <p>Now that we know the recall and precision, we can also calculate the F1 score, which is the harmonic mean of recall and precision. This calculation is made as follows:</p> 
  </div> 
  <div class="readable-text indented-paragraph equation-paragraph" id="p29"> 
   <p><em>F1 score = (2 <em class="obliqued">×</em> Precision <em class="obliqued">×</em> Recall) / (Precision + Recall)</em></p> 
  </div> 
  <div class="readable-text" id="p30"> 
   <p>For our <code>#Request_Agent</code> intent, this would be calculated as (2 <span class="regular-symbol">×</span> 0.66 <span class="regular-symbol">×</span> 0.8) / (0.66 + 0.8) = 0.72. Table 5.2 shows all three scores.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p31"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.2</span> Recall, precision, and F1 score for <code>#Request_Agent</code></h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Recall 
       </div></th> 
      <th> 
       <div>
         Precision 
       </div></th> 
      <th> 
       <div>
         F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Request_Agent</code> <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  0.66 <br/></td> 
      <td>  0.72 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p32"> 
    <h5 class=" callout-container-h5 readable-text-h5">What about the true negatives?</h5> 
   </div> 
   <div class="readable-text" id="p33"> 
    <p>Earlier in this section, we mentioned true negatives—a prediction that does not match an incorrect intent. True negatives occur whenever we have more than one trained intent. However, they are not a useful measurement in our methods. </p> 
   </div> 
   <div class="readable-text" id="p34"> 
    <p>Why not? Well, for every prediction the model makes, there is only one way for it to be right, but there are two ways for it to be wrong. This seems a little unfair, and it’s hard to see why if you’re just looking at two intents. But imagine we have a model that was trained with 20 intents. Whenever we make a single prediction that returns a true positive, we will also get 19 true negatives. And for every false positive prediction,</p> 
   </div> 
   <div class="readable-text" id="p35"> 
    <p>we have 1 false negative and 18 true negatives. So all those true negatives add up to a very large number that, for our purposes, doesn’t give us much insight. Therefore, we don’t factor true negatives into our calculations. </p> 
   </div> 
  </div> 
  <div class="readable-text" id="p36"> 
   <h4 class=" readable-text-h4">Deciding which metric is important</h4> 
  </div> 
  <div class="readable-text" id="p37"> 
   <p>Recall, precision, F1 score: Which number should we care about? That’s a great question! The answer is that it depends on what your organization values most in terms of what the solution needs to deliver. Here are some considerations to guide you to an answer:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p38"> Recall is useful when there is a high cost associated with false negatives. Imagine the effect if a fraud detection tool missed 25% of the fraudulent transactions it evaluated. (For a chatbot, this would look like a correct intent that is not predicted 25% of the time.) </li> 
   <li class="readable-text" id="p39"> Precision is useful when there is a high cost associated with false positives. Think of the gameshow Jeopardy!, which penalizes a contestant for attempting to answer and getting it wrong (or a chatbot that over-selects the <code>#Request_ Agent</code> intent, resulting in unnecessary escalations). </li> 
   <li class="readable-text" id="p40"> The F1 score is useful when there is a high cost associated with both false positives and false negatives. We like to use this for most implementations because it reflects a good balance of the recall and precision scores. </li> 
  </ul> 
  <div class="readable-text" id="p41"> 
   <h4 class=" readable-text-h4">Visualizing your data with a confusion matrix</h4> 
  </div> 
  <div class="readable-text" id="p42"> 
   <p>Earlier in this section, we showed a 2 <span class="regular-symbol">×</span> 2 confusion matrix to demonstrate the potential outcomes. A confusion matrix can help you assess the performance of a classification model by visualizing a summary of the predictions made by your model. Some testing tools produce this with their results output. </p> 
  </div> 
  <div class="readable-text intended-text" id="p43"> 
   <p>Figure 5.3 shows a fictional scenario where a classifier model made ten perfect predictions. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p44">  
   <img alt="figure" src="../Images/CH05_F03_Freed2.png" width="489" height="458"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.3</span> A solid diagonal line shows that each predicted intent (represented by a single letter) matched to the actual intent. </h5>
  </div> 
  <div class="readable-text" id="p45"> 
   <p>Shaded boxes that stray from the diagonal provide useful insights about where your model is confused, as shown in figure 5.4.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p46">  
   <img alt="figure" src="../Images/CH05_F04_Freed2.png" width="489" height="458"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.4</span> This model had nine correct predictions, but wrongly predicted intent G when the actual intent was E.</h5>
  </div> 
  <div class="readable-text" id="p47"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.1.2</span> Incremental improvements</h3> 
  </div> 
  <div class="readable-text" id="p48"> 
   <p>An incremental improvement approach will affect measurable change in a manageable way. Every change you make to a classifier has the potential to affect multiple intents. Sometimes this effect is positive, but sometimes it’s not. You might get away with updating several intents all at once, but if the testing shows a performance decline, it can be difficult to track down the culprit. You will have to balance the need for efficiency with your tolerance for rework. </p> 
  </div> 
  <div class="readable-text" id="p49"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.1.3</span> Where to start: Identifying the biggest problems</h3> 
  </div> 
  <div class="readable-text" id="p50"> 
   <p>Generally, the best place to start is with the highest volume intents that have the lowest F1 scores. The business may also weigh in on priorities. If a lower volume intent fails to recognize the type of request it was designed to handle, but this failure incurs costly human intervention, it might take priority. </p> 
  </div> 
  <div class="readable-text intended-text" id="p51"> 
   <p>For the rest of this chapter, we will explore a fictional use case: a chatbot that serves a population that interacts with a state’s Bureau of Motor Vehicles (a type of US government agency that regulates and manages the issuance of state identification cards, driver’s licenses, certain permits, and vehicle registrations). </p> 
  </div> 
  <div class="readable-text intended-text" id="p52"> 
   <p>To begin, let’s follow the advice given in chapter 4 and take a quick, high-level look at our current training data, as laid out in table 5.3.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p53"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.3</span> Intents with example counts in a baseline training set</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent name 
       </div></th> 
      <th> 
       <div>
         Number of examples 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Accident_Report</code> <br/></td> 
      <td>  2 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Appointment</code> <br/></td> 
      <td>  6 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Change_Contact_Records</code> <br/></td> 
      <td>  3 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Goodbye</code> <br/></td> 
      <td>  3 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Hello</code> <br/></td> 
      <td>  4 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Thanks</code> <br/></td> 
      <td>  2 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_VA_About</code> <br/></td> 
      <td>  8 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Fee_Info</code> <br/></td> 
      <td>  5 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>General_Negative_Feedback</code> <br/></td> 
      <td>  6 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>General_Request_Agent</code> <br/></td> 
      <td>  5 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Get_ID_Number</code> <br/></td> 
      <td>  4 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  8 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_or_ID</code> <br/></td> 
      <td>  5 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_Reinstatement</code> <br/></td> 
      <td>  4 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  4 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Name_Change</code> <br/></td> 
      <td>  6 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Office_Information</code> <br/></td> 
      <td>  6 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Payment_Methods</code> <br/></td> 
      <td>  3 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Refund_Overcharge</code> <br/></td> 
      <td>  4 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Sold_Vehicle</code> <br/></td> 
      <td>  6 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_License_Permit_ID</code> <br/></td> 
      <td>  5 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Plates_Registration</code> <br/></td> 
      <td>  3 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Vehicle</code> <br/></td> 
      <td>  2 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Request_Receipt</code> <br/></td> 
      <td>  4 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Vehicle_Permit</code> <br/></td> 
      <td>  5 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Vehicle_Title</code> <br/></td> 
      <td>  6 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Walk_In</code> <br/></td> 
      <td>  6 <br/></td> 
     </tr> 
     <tr> 
      <td>  <strong>Grand Total</strong> <br/></td> 
      <td>  <strong>125</strong> <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p54"> 
   <p>We can make some quantitative statements about this training set. It has 27 intents with a grand total of 125 training examples. The examples are distributed fairly evenly. As a qualitative assessment, we might say that many of the intents appear to be unique, but a few of them might have some overlap. Some terms definitely overlap across intent names. A peek at the full set of training utterances (not shown) revealed that many terms appear in multiple intents, such as “ID,” “title,” “permit,” “vehicle,” “stolen.” However, as shown in table 5.4, the contexts in which these words appeared were judged to be appropriately labeled. </p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p55"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.4</span> Utterances extracted from the baseline training set show a variety of terms overlapping across multiple intents.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Utterance 
       </div></th> 
      <th> 
       <div>
         Labeled intent 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  How much is an ID? <br/></td> 
      <td>  <code>Fee_Info</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  I need to find out my ID number <br/></td> 
      <td>  <code>Get_ID_Number</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  I didn’t receive my ID <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  Title never came <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  Add a person to the title <br/></td> 
      <td>  <code>Vehicle_Title</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  How do I get a driving permit? <br/></td> 
      <td>  <code>License_or_ID</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  Replace my program parking permit <br/></td> 
      <td>  <code>Vehicle_Permit</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  I sold a vehicle <br/></td> 
      <td>  <code>Report_Sold_Vehicle</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  I need to report a stolen car <br/></td> 
      <td>  <code>Report_Stolen_Vehicle</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  My ID was stolen <br/></td> 
      <td>  <code>Report_Stolen_License_Permit_ID</code> <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p56"> 
   <p>Overall, it seems that the range of topics is reasonable for the chatbot’s purpose, which in this case is to answer questions a user might have when dealing with a state’s Bureau of Motor Vehicles. </p> 
  </div> 
  <div class="readable-text" id="p57"> 
   <h4 class=" readable-text-h4">Establishing a baseline</h4> 
  </div> 
  <div class="readable-text" id="p58"> 
   <p>Now that we have made an initial assessment of our training data, we need to understand how it is currently performing. We’ll start by running a <em>k</em>-fold cross validation test to establish a baseline. The results, our first version (V1) shown in table 5.5, are not that bad, considering the low volume of data present in the training set.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p59"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.5</span> Baseline (V1) <em>k</em>-fold results</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Number of samples 
       </div></th> 
      <th> 
       <div>
         Number of predictions 
       </div></th> 
      <th> 
       <div>
         Recall 
       </div></th> 
      <th> 
       <div>
         Precision 
       </div></th> 
      <th> 
       <div>
         F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Accident_Report</code> <br/></td> 
      <td>  2 <br/></td> 
      <td>  2 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Appointment</code> <br/></td> 
      <td>  6 <br/></td> 
      <td>  8 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.75 <br/></td> 
      <td>  0.8571 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Change_Contact_Records</code> <br/></td> 
      <td>  3 <br/></td> 
      <td>  0 <br/></td> 
      <td>  0 <br/></td> 
      <td>  0 <br/></td> 
      <td>  0 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Goodbye</code> <br/></td> 
      <td>  3 <br/></td> 
      <td>  0 <br/></td> 
      <td>  0 <br/></td> 
      <td>  0 <br/></td> 
      <td>  0 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Hello</code> <br/></td> 
      <td>  4 <br/></td> 
      <td>  6 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Thanks</code> <br/></td> 
      <td>  2 <br/></td> 
      <td>  2 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_VA_About</code> <br/></td> 
      <td>  8 <br/></td> 
      <td>  8 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Fee_Info</code> <br/></td> 
      <td>  5 <br/></td> 
      <td>  2 <br/></td> 
      <td>  0.40 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.5714 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>General_Negative_Feedback</code> <br/></td> 
      <td>  6 <br/></td> 
      <td>  7 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.8571 <br/></td> 
      <td>  0.9231 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>General_Request_Agent</code> <br/></td> 
      <td>  5 <br/></td> 
      <td>  4 <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.8889 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Get_ID_Number</code> <br/></td> 
      <td>  4 <br/></td> 
      <td>  6 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  8 <br/></td> 
      <td>  6 <br/></td> 
      <td>  0.6250 <br/></td> 
      <td>  0.8333 <br/></td> 
      <td>  0.7143 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_Reinstatement</code> <br/></td> 
      <td>  4 <br/></td> 
      <td>  4 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_or_ID</code> <br/></td> 
      <td>  5 <br/></td> 
      <td>  5 <br/></td> 
      <td>  0.60 <br/></td> 
      <td>  0.60 <br/></td> 
      <td>  0.60 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  4 <br/></td> 
      <td>  4 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Name_Change</code> <br/></td> 
      <td>  6 <br/></td> 
      <td>  8 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.75 <br/></td> 
      <td>  0.8571 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Office_Information</code> <br/></td> 
      <td>  6 <br/></td> 
      <td>  6 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Payment_Methods</code> <br/></td> 
      <td>  3 <br/></td> 
      <td>  3 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Refund_Overcharge</code> <br/></td> 
      <td>  4 <br/></td> 
      <td>  4 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Sold_Vehicle</code> <br/></td> 
      <td>  6 <br/></td> 
      <td>  5 <br/></td> 
      <td>  0.8333 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.9091 <br/></td> 
     </tr> 
     <tr> 
      <td>  <pre>Report_Stolen_License_
Permit_ID</pre> <br/></td> 
      <td>  5 <br/></td> 
      <td>  6 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.8333 <br/></td> 
      <td>  0.9091 <br/></td> 
     </tr> 
     <tr> 
      <td>  <pre>Report_Stolen_Plates_
Registration</pre> <br/></td> 
      <td>  3 <br/></td> 
      <td>  3 <br/></td> 
      <td>  0.3333 <br/></td> 
      <td>  0.3333 <br/></td> 
      <td>  0.3333 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Vehicle</code> <br/></td> 
      <td>  2 <br/></td> 
      <td>  3 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Request_Receipt</code> <br/></td> 
      <td>  4 <br/></td> 
      <td>  4 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1.0000 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Vehicle_Permit</code> <br/></td> 
      <td>  5 <br/></td> 
      <td>  6 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.8333 <br/></td> 
      <td>  0.9091 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Vehicle_Title</code> <br/></td> 
      <td>  6 <br/></td> 
      <td>  9 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Walk_In</code> <br/></td> 
      <td>  6 <br/></td> 
      <td>  4 <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p60"> 
   <p>Our <em>k</em>-fold test had a total of 125 questions (the grand total of our training set), and it got 105 of them correct, for an overall accuracy of 84%. Several intents had perfect recall and perfect precision (which is often a hallmark of a manufactured data set). There were two intents that had a recall of 0; they each had only three training examples. This reveals one of the flaws of <em>k</em>-fold testing—there simply weren’t enough examples to distribute across the auto-generated train and test sets. More than likely, those intents will perform better than 0 in production. However, the intents with perfect recall will probably not perform quite as well. If you are launching a pilot and have no other training data available, these results are generally good enough to go live, with a strong caution to the stakeholders that they should expect lower actual performance until representative data is available for use in training updates.</p> 
  </div> 
  <div class="readable-text intended-text" id="p61"> 
   <p>Once the solution is live, a new baseline should be taken using the blind test set you created from the logs. We have an example of this in table 5.6, and it really emphasizes the gap in performance predicted by our <em>k</em>-fold test compared to real user inputs. </p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p62"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.6</span> Baseline (V1) blind results</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Number of samples 
       </div></th> 
      <th> 
       <div>
         Number of predictions 
       </div></th> 
      <th> 
       <div>
         Recall 
       </div></th> 
      <th> 
       <div>
         Precision 
       </div></th> 
      <th> 
       <div>
         F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Accident_Report</code> <br/></td> 
      <td>  2 <br/></td> 
      <td>  2 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Appointment</code> <br/></td> 
      <td>  7 <br/></td> 
      <td>  5 <br/></td> 
      <td>  0.7143 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.8333 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Change_Contact_Records</code> <br/></td> 
      <td>  4 <br/></td> 
      <td>  4 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Goodbye</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Hello</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Thanks</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_VA_About</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  2 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.50 <br/></td> 
      <td>  0.6667 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Fee_Info</code> <br/></td> 
      <td>  11 <br/></td> 
      <td>  9 <br/></td> 
      <td>  0.8182 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.90 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>General_Negative_Feedback</code> <br/></td> 
      <td>  2 <br/></td> 
      <td>  3 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>General_Request_Agent</code> <br/></td> 
      <td>  3 <br/></td> 
      <td>  2 <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Get_ID_Number</code> <br/></td> 
      <td>  3 <br/></td> 
      <td>  5 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.60 <br/></td> 
      <td>  0.75 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  16 <br/></td> 
      <td>  9 <br/></td> 
      <td>  0.4375 <br/></td> 
      <td>  0.7778 <br/></td> 
      <td>  0.56 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_Reinstatement</code> <br/></td> 
      <td>  5 <br/></td> 
      <td>  5 <br/></td> 
      <td>  0.60 <br/></td> 
      <td>  0.60 <br/></td> 
      <td>  0.60 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_or_ID</code> <br/></td> 
      <td>  7 <br/></td> 
      <td>  5 <br/></td> 
      <td>  0.5714 <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  0.6667 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  9 <br/></td> 
      <td>  5 <br/></td> 
      <td>  0.4444 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.6153 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Name_Change</code> <br/></td> 
      <td>  9 <br/></td> 
      <td>  9 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Office_Information</code> <br/></td> 
      <td>  9 <br/></td> 
      <td>  11 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.8182 <br/></td> 
      <td>  0.90 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Payment_Methods</code> <br/></td> 
      <td>  2 <br/></td> 
      <td>  2 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Refund_Overcharge</code> <br/></td> 
      <td>  3 <br/></td> 
      <td>  4 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.7500 <br/></td> 
      <td>  0.8571 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Sold_Vehicle</code> <br/></td> 
      <td>  6 <br/></td> 
      <td>  7 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.8571 <br/></td> 
      <td>  0.9231 <br/></td> 
     </tr> 
     <tr> 
      <td>  <pre>Report_Stolen_License_
Permit_ID</pre> <br/></td> 
      <td>  7 <br/></td> 
      <td>  8 <br/></td> 
      <td>  0.8571 <br/></td> 
      <td>  0.75 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
     <tr> 
      <td>  <pre>Report_Stolen_Plates_
Registration</pre> <br/></td> 
      <td>  5 <br/></td> 
      <td>  4 <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.8889 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Vehicle</code> <br/></td> 
      <td>  2 <br/></td> 
      <td>  2 <br/></td> 
      <td>  0.50 <br/></td> 
      <td>  0.50 <br/></td> 
      <td>  0.50 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Request_Receipt</code> <br/></td> 
      <td>  4 <br/></td> 
      <td>  4 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Vehicle_Permit</code> <br/></td> 
      <td>  4 <br/></td> 
      <td>  5 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  0.8889 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Vehicle_Title</code> <br/></td> 
      <td>  2 <br/></td> 
      <td>  8 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.25 <br/></td> 
      <td>  0.40 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Walk_In</code> <br/></td> 
      <td>  8 <br/></td> 
      <td>  5 <br/></td> 
      <td>  0.3750 <br/></td> 
      <td>  0.60 <br/></td> 
      <td>  0.4615 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p63"> 
   <p>On the first run of our blind test, 102 questions were correct out of 134, for an overall accuracy of 76%—8 points lower than the 84% predicted by our <em>k</em>-fold test. </p> 
  </div> 
  <div class="readable-text" id="p64"> 
   <h4 class=" readable-text-h4">Validating your initial training strategy</h4> 
  </div> 
  <div class="readable-text" id="p65"> 
   <p>Once you have obtained annotated logs and taken some baseline performance measurements, you can validate the decisions that informed your initial training strategy. </p> 
  </div> 
  <div class="readable-text intended-text" id="p66"> 
   <p>Scarcity of representative training data is a very common problem for conversational AI projects. Just like many other newly launched chatbots, our initial training set was developed by subject matter experts (SMEs) who manufactured training examples for the topics they believed would occur most frequently. In figure 5.5, we can compare the number of examples trained for each intent to the number of examples that were present in the randomly selected logs used for testing.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p67">  
   <img alt="figure" src="../Images/CH05_F05_Freed2.png" width="1015" height="531"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.5</span> A comparison of training examples to the utterances in our representative blind test set shows that there is some disparity in volume for many of the most popular intents (the representative blind utterances) on the left side of the graph. We also see disparity across several of the least popular intents (those on the right).</h5>
  </div> 
  <div class="readable-text" id="p68"> 
   <p>A side-by-side volume comparison of training data to representative blind utterances per intent can help us understand if our solution’s topic coverage is in alignment with the real-world interactions. One of the first observations we noted was that <code>#Item_Not_Received</code> was the most popular real-world intent. This validated the initial build strategy of supplying that intent with a higher number of training examples (relative to most other intents). We also noted that <code>#Chitchat_VA_About</code> had a high number of training examples compared to how infrequently this topic came up in the logs. This intent may be over-trained. It certainly doesn’t seem to be as popular as we thought it might be. Yet, until we look at the performance metrics for these intents, we cannot draw any solid conclusions. Rather, these observations might inform our improvement recommendations.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p69"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text" id="p70"> Run a representative blind test using your own data, and identify which intents, if any, exhibit poor performance. </li> 
    <li class="readable-text" id="p71"> Does your training volume align with the intent volume seen in your logs? </li> 
    <li class="readable-text" id="p72"> How would you prioritize improvements for the poorest-performing intents? </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p73"> 
   <h2 class=" readable-text-h2"><span class="num-string">5.2</span> Solving “wrong intent matched”</h2> 
  </div> 
  <div class="readable-text" id="p74"> 
   <p>When your chatbot returns the wrong intent, it has committed two categories of errors: false positives (predicting the wrong intent), and false negatives (failing to predict the right intent). Let’s walk through an improvement cycle to demonstrate how we would approach this problem.</p> 
  </div> 
  <div class="readable-text" id="p75"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.2.1</span> Improve recall for one intent </h3> 
  </div> 
  <div class="readable-text" id="p76"> 
   <p>We will start with <code>#Login_Issue</code>, which was the fifth most popular topic but had a considerably low recall of 0.44. There were nine test utterances in our blind set; it got four questions correct (true positives) and five incorrect (false negatives). This intent had a perfect precision score, which means it never showed up as a wrong prediction for other intents. Table 5.7 shows the summary metrics. </p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p77"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.7</span> Summary metrics for <code>#Login_Issue</code>; a blind test set run against our baseline classifier shows low recall but perfect precision.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Number of samples 
       </div></th> 
      <th> 
       <div>
         Number of predictions 
       </div></th> 
      <th> 
       <div>
         Recall 
       </div></th> 
      <th> 
       <div>
         Precision 
       </div></th> 
      <th> 
       <div>
         F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Login_Issue </code> <br/></td> 
      <td>  9 <br/></td> 
      <td>  5 <br/></td> 
      <td>  0.4444 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.6153 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p78"> 
   <p>In table 5.8, we can drill down to the result details of the blind test. Our classifier failed to predict a correct intent five times. Three of those were predictions of a wrong intent. Two were instances where confidence was so low that the classifier did not return a prediction. </p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p79"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.8</span> Baseline blind result details for <code>#Login_Issue</code> show that we had a recall score of 44%. Out of nine utterances, the correct (aka <em>golden</em>) intent was predicted five times. </h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Utterance 
       </div></th> 
      <th> 
       <div>
         Golden intent 
       </div></th> 
      <th> 
       <div>
         Predicted intent 
       </div></th> 
      <th> 
       <div>
         Confidence 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  BMV portal password reset <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  &lt;none&gt; <br/></td> 
      <td>  n/a <br/></td> 
     </tr> 
     <tr> 
      <td>  I can’t get on my profile <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.8131 <br/></td> 
     </tr> 
     <tr> 
      <td>  I need help logging into my BMV profile <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  &lt;none&gt; <br/></td> 
      <td>  n/a <br/></td> 
     </tr> 
     <tr> 
      <td>  I never got my security verification code <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.2358 <br/></td> 
     </tr> 
     <tr> 
      <td>  I tried logging in and it didn’t work <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.8033 <br/></td> 
     </tr> 
     <tr> 
      <td>  I’m not able to get into the portal <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.6680 <br/></td> 
     </tr> 
     <tr> 
      <td>  Password locked out <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.5520 <br/></td> 
     </tr> 
     <tr> 
      <td>  Password reset <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.4875 <br/></td> 
     </tr> 
     <tr> 
      <td>  You never sent a security code <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.2091 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p80"> 
   <p>If we look at our current trained examples, it’s easy to see why so many questions were missed. There were only four examples:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p81"> I’m unable to log in on the website </li> 
   <li class="readable-text" id="p82"> Online account problem </li> 
   <li class="readable-text" id="p83"> Online problems </li> 
   <li class="readable-text" id="p84"> Problem signing onto my account </li> 
  </ul> 
  <div class="readable-text" id="p85"> 
   <p>Our training examples lack the variety of meaningful words and phrases seen in interactions with real users. Users might refer to their account as their “profile.” They list explicit problems such as being “locked out,” needing a “password reset,” and failing to receive a “security code.” We should expect to see an improvement if we add a few representative examples (obtained from our logs): </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p86"> Help signing in to online portal </li> 
   <li class="readable-text" id="p87"> I need to reset my password </li> 
   <li class="readable-text" id="p88"> I need a security code to log on </li> 
  </ul> 
  <div class="readable-text" id="p89"> 
   <p>With these additions, we updated our classifier to V2 and reran the blind test set. Let’s look at how this affected the recall for <code>#Login_Issue</code> in table 5.9.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p90"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.9</span> Blind test result details show improved recall for our newest classifier version (V2). Out of nine utterances, the correct (aka <em>golden</em>) intent was predicted eight times.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Utterance 
       </div></th> 
      <th> 
       <div>
         Golden intent 
       </div></th> 
      <th> 
       <div>
         Predicted intent 
       </div></th> 
      <th> 
       <div>
         Confidence 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  BMV portal password reset <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.8253 <br/></td> 
     </tr> 
     <tr> 
      <td>  I can’t get on my profile <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.8131 <br/></td> 
     </tr> 
     <tr> 
      <td>  I need help logging into my BMV profile <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.6846 <br/></td> 
     </tr> 
     <tr> 
      <td>  I never got my security verification code <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.7179 <br/></td> 
     </tr> 
     <tr> 
      <td>  I tried logging in and it didn’t work <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.8899 <br/></td> 
     </tr> 
     <tr> 
      <td>  I’m not able to get into the portal <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.7840 <br/></td> 
     </tr> 
     <tr> 
      <td>  Password locked out <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.9083 <br/></td> 
     </tr> 
     <tr> 
      <td>  Password reset <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.9204 <br/></td> 
     </tr> 
     <tr> 
      <td>  You never sent a security code <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.2551 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p91"> 
   <p>Our overall accuracy improved from 76% to 79% (106 out of 134 correct), and table 5.10 shows a dramatic improvement in the recall and F1 score. The precision score also remained steady.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p92"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.10</span> A comparison of summary metrics; our V2 classifier shows an overall improvement compared to the baseline (V1) for <code>#Login_Issue</code>. </h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Number of samples 
       </div></th> 
      <th> 
       <div>
         Number of predictions 
       </div></th> 
      <th> 
       <div>
         Recall 
       </div></th> 
      <th> 
       <div>
         Precision 
       </div></th> 
      <th> 
       <div>
         F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Login_Issue</code>—Baseline (V1) <br/></td> 
      <td>  9 <br/></td> 
      <td>  5 <br/></td> 
      <td>  0.4444 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.6153 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Login_Issue</code>—V2 <br/></td> 
      <td>  9 <br/></td> 
      <td>  8 <br/></td> 
      <td>  0.8889 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.9412 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p93"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.2.2</span> Improve precision for one intent </h3> 
  </div> 
  <div class="readable-text" id="p94"> 
   <p>Next, let’s experiment with improving the precision for an intent. The <code>#Chitchat_VA_About</code> intent remained unchanged between the baseline test results and the V2 test results. (It is important to look at the newest results after each change.) Table 5.11 shows that the recall was perfect, but the precision was only 50%. This means our classifier is placing a bit more importance on this topic, and it is showing up as a false positive (over-selecting) in another intent. </p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p95"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.11</span> Metrics after the V2 update show that <code>#Chitchat_VA_About</code> has perfect recall but poor precision.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Number of samples 
       </div></th> 
      <th> 
       <div>
         Number of predictions 
       </div></th> 
      <th> 
       <div>
         Recall 
       </div></th> 
      <th> 
       <div>
         Precision 
       </div></th> 
      <th> 
       <div>
         F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Chitchat_VA_About</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  2 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.50 <br/></td> 
      <td>  0.6667 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p96"> 
   <p>In table 5.12, we see that there was only one test question in our blind set for this intent, but our classifier predicted the intent twice.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p97"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.12</span> V2 blind result details show an over-selection for <code>#Chitchat_VA_About</code>.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Utterance 
       </div></th> 
      <th> 
       <div>
         Golden intent 
       </div></th> 
      <th> 
       <div>
         Predicted intent 
       </div></th> 
      <th> 
       <div>
         Confidence 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Do you have a name? <br/></td> 
      <td>  <code>Chitchat_VA_About</code> <br/></td> 
      <td>  <code>Chitchat_VA_About</code> <br/></td> 
      <td>  0.8042 <br/></td> 
     </tr> 
     <tr> 
      <td>  Where are my tags? <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  <code>Chitchat_VA_About</code> <br/></td> 
      <td>  0.3015 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p98"> 
   <p>Our training has eight examples. We knew that these examples were manufactured (in fact, they were provided by a template), but our logs show that this is not a very common topic. Our blind test set only contained one utterance for this intent. </p> 
  </div> 
  <div class="readable-text intended-text" id="p99"> 
   <p>One strategy for improving precision is to prune the training examples. This tells our classifier that the intent isn’t quite as dominant as the other intents within our solution. We’ll discard three examples because they are either overly redundant or, in the case of “Where are you from,” there was no evidence in the logs that this was a relevant question:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p100"> Are you a robot? </li> 
   <li class="readable-text" id="p101"> What can I ask you? </li> 
   <li class="readable-text" id="p102"> What can you do? </li> 
   <li class="readable-text" id="p103"> What can you help me with? (REMOVE FROM TRAINING) </li> 
   <li class="readable-text" id="p104"> What’s your name? </li> 
   <li class="readable-text" id="p105"> Where are you from? (REMOVE FROM TRAINING) </li> 
   <li class="readable-text" id="p106"> Who am I talking to? (REMOVE FROM TRAINING) </li> 
   <li class="readable-text" id="p107"> Who are you? </li> 
  </ul> 
  <div class="readable-text" id="p108"> 
   <p>Once the training was updated (now V3), we ran the blind test again and reviewed the results. We saw an improvement to the precision for the <code>#Chitchat_VA_About</code> intent from V2 to V3—it was a perfect score across all metrics. Oddly enough, our overall accuracy dropped to 78% (from 79%), and one of the questions we lost was from our <code>#Login_Issue</code> intent. Table 5.13 shows the changes in metrics from V2 to V3 for both intents.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p109"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.13</span> Metrics before and after V3 update for <code>#Chitchat_VA_About</code> and <code>#Login_Issue</code> show that changing one intent can have an effect on another intent.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Number of samples 
       </div></th> 
      <th> 
       <div>
         Number of predictions 
       </div></th> 
      <th> 
       <div>
         Recall 
       </div></th> 
      <th> 
       <div>
         Precision 
       </div></th> 
      <th> 
       <div>
         F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Chitchat_VA_About</code>—V2 <br/></td> 
      <td>  1 <br/></td> 
      <td>  2 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.50 <br/></td> 
      <td>  0.6667 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_VA_About</code>—V3 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Login_Issue</code>—V2 <br/></td> 
      <td>  9 <br/></td> 
      <td>  8 <br/></td> 
      <td>  0.8889 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.9412 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Login_Issue</code>—V3 <br/></td> 
      <td>  9 <br/></td> 
      <td>  7 <br/></td> 
      <td>  0.7777 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.875 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p110"> 
   <p>Although <code>#Login_Issue</code> had a slight decline, the current F1 score of 0.875 is still far better than the baseline F1 score of 0.6153. Keep in mind that smaller datasets are more sensitive to small changes, and a change to any intent can potentially affect every intent. Those changes may have negative or positive results. Instead of focusing on this, however, we will make a few more changes elsewhere and check back to see if the intent improves.</p> 
  </div> 
  <div class="readable-text" id="p111"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.2.3</span> Improve the F1 score for one intent </h3> 
  </div> 
  <div class="readable-text" id="p112"> 
   <p>Let’s move forward with improving the F1 score for <code>#Item_Not_Received</code>. Table 5.14 shows that it had an F1 score of 56% after our V3 update.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p113"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.14</span> After V3 update, the F1 score remained unchanged at 0.56 for <code>#Item_Not_Received</code>.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Number of samples 
       </div></th> 
      <th> 
       <div>
         Number of predictions 
       </div></th> 
      <th> 
       <div>
         Recall 
       </div></th> 
      <th> 
       <div>
         Precision 
       </div></th> 
      <th> 
       <div>
         F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Item_Not_Received</code>—V2 <br/></td> 
      <td>  16 <br/></td> 
      <td>  9 <br/></td> 
      <td>  0.4375 <br/></td> 
      <td>  0.7777 <br/></td> 
      <td>  0.56 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Item_Not_Received</code>—V3 <br/></td> 
      <td>  16 <br/></td> 
      <td>  9 <br/></td> 
      <td>  0.4375 <br/></td> 
      <td>  0.7777 <br/></td> 
      <td>  0.56 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p114"> 
   <p>The intent had eight training examples, but our logs showed that this is a very popular topic, so we need it to perform much better. We’ll add 10 more examples from our logs to that intent (now V4) and run another experiment. </p> 
  </div> 
  <div class="readable-text intended-text" id="p115"> 
   <p>Table 5.15 shows that our recall for this intent has now more than doubled, and though the precision fell slightly, the F1 score is greatly improved. The classifier’s overall accuracy also increased from 78% to 81%.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p116"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.15</span> Before and after metrics for <code>#Item_Not_Received</code> show an improved F1 score.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Number of samples 
       </div></th> 
      <th> 
       <div>
         Number of predictions 
       </div></th> 
      <th> 
       <div>
         Recall 
       </div></th> 
      <th> 
       <div>
         Precision 
       </div></th> 
      <th> 
       <div>
         F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Item_Not_Received</code>—V3 <br/></td> 
      <td>  16 <br/></td> 
      <td>  9 <br/></td> 
      <td>  0.4375 <br/></td> 
      <td>  0.7777 <br/></td> 
      <td>  0.56 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Item_Not_Received</code>—V4 <br/></td> 
      <td>  16 <br/></td> 
      <td>  19 <br/></td> 
      <td>  0.875 <br/></td> 
      <td>  0.7368 <br/></td> 
      <td>  0.8 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p117"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.2.4</span> Improve precision and recall for multiple intents </h3> 
  </div> 
  <div class="readable-text" id="p118"> 
   <p>Sometimes there is confusion due to a heavy overlap of terms across intents that have similar goals. Figure 5.6 shows the confusion matrix that our testing tool provided.</p> 
  </div> 
  <div class="readable-text intended-text" id="p119"> 
   <p>In our model, we see a fair amount of confusion across the intents that relate to stolen items. One solution to this problem is to merge intents. This must be considered carefully. The intents were probably created separately by design, as they all have different answers. However, entity detection can be used to route the flow to the appropriate answer. </p> 
  </div> 
  <div class="browsable-container figure-container" id="p120">  
   <img alt="figure" src="../Images/CH05_F06_Freed2.png" width="1100" height="1100"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.6</span> Confusion matrix after the V4 update. The density in shading represents the volume of questions predicted for a given intent. If a classifier test had a perfect accuracy score, you would see a solid black diagonal line running from the upper left corner to the lower right corner. The shaded squares that stray away from this diagonal line mark the areas of confusion within your model.</h5>
  </div> 
  <div class="readable-text" id="p121"> 
   <p>We’ll merge all of these into a single intent called <code>#Report_Stolen</code>. These examples are listed in table 5.16. Don’t forget that the blind test set will need to reflect this change, as well as the related dialogue flows. </p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p122"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.16</span> Examples from three intents to be merged into a new <code>#Report_Stolen</code> intent</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent name 
       </div></th> 
      <th> 
       <div>
         Training example 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Report_Stolen_Vehicle</code> <br/></td> 
      <td>  Report a stolen car <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Vehicle</code> <br/></td> 
      <td>  I need to report a stolen car <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Plates_Registration</code> <br/></td> 
      <td>  My plates were stolen <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Plates_Registration</code> <br/></td> 
      <td>  My registration was stolen <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Plates_Registration</code> <br/></td> 
      <td>  License plate stolen off vehicle <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_License_Permit_ID</code> <br/></td> 
      <td>  Stolen real ID <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_License_Permit_ID</code> <br/></td> 
      <td>  Wallet was stolen <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_License_Permit_ID</code> <br/></td> 
      <td>  My drivers license was stolen <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_License_Permit_ID</code> <br/></td> 
      <td>  My ID was stolen <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_License_Permit_ID</code> <br/></td> 
      <td>  My permit was stolen <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p123"> 
   <p>The conversational flow will be updated so that when a defined entity value or synonym is detected in an utterance, the corresponding original answer is provided. You may also need a default condition to disambiguate or provide a generic answer in case an utterance triggers the new intent but no entity is detected. Table 5.17 is an example of what that might look like.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p124"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.17</span> Dialogue updates using entity detection for the new <code>#Report_Stolen</code> intent</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Entity/synonym detected 
       </div></th> 
      <th> 
       <div>
         Treatment 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  vehicle, car, truck, motorcycle <br/></td> 
      <td>  Routes to original answer for <code>#Report Stolen Vehicle</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  plates, registration, tags <br/></td> 
      <td>  Routes to original answer for <code>#Report_Stolen_Plates_Registration</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  ID, license, permit <br/></td> 
      <td>  Routes to original answer for <code>#Report_Stolen_License_Permit_ID</code> <br/></td> 
     </tr> 
     <tr> 
      <td>  (none detected) <br/></td> 
      <td>  Disambiguate (“It sounds like something was stolen; can you tell me what it was?”) <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p125"> 
   <p>With these changes, our classifier is now on V5. Table 5.18 shows the metrics for the three old intents under V4 and the metrics for our new intent in V5.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p126"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.18</span> Metrics before and after V5 update show that merging three intents into the single <code>#Report_Stolen</code> intent results in perfect scores across the board for this topic.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Number of samples 
       </div></th> 
      <th> 
       <div>
         Number of predictions 
       </div></th> 
      <th> 
       <div>
         Recall 
       </div></th> 
      <th> 
       <div>
         Precision 
       </div></th> 
      <th> 
       <div>
         F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <pre>Report_Stolen_License_Permit_
ID</pre>—V4 <br/></td> 
      <td>  7 <br/></td> 
      <td>  5 <br/></td> 
      <td>  0.5714 <br/></td> 
      <td>  0.8 <br/></td> 
      <td>  0.6666 <br/></td> 
     </tr> 
     <tr> 
      <td>  <pre>Report_Stolen_Plates_
Registration</pre>—V4 <br/></td> 
      <td>  5 <br/></td> 
      <td>  4 <br/></td> 
      <td>  0.8 <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.8888 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Vehicle</code>—V4 <br/></td> 
      <td>  2 <br/></td> 
      <td>  2 <br/></td> 
      <td>  0.5 <br/></td> 
      <td>  0.5 <br/></td> 
      <td>  0.5 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen</code>—new intent in V5 <br/></td> 
      <td>  14 <br/></td> 
      <td>  14 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p127"> 
   <p>Our latest change dramatically improved the performance of this topic, and it bumped the overall accuracy to 85%, which is now higher than our baseline <em>k</em>-fold (which was 84%). </p> 
  </div> 
  <div class="readable-text intended-text" id="p128"> 
   <p>With that update complete, we can move on to other intents that need improvement. Following the iterative processes, we updated the remaining intents that showed the poorest performance by adding a few more examples from the logs. This became V6 of our classifier. Table 5.19 is an overview of the intents that were updated.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p129"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.19</span> Training example counts increase from V5 to V6 and more closely align with the volume present in the representative blind test set.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         V5 training example count 
       </div></th> 
      <th> 
       <div>
         V6 training example count 
       </div></th> 
      <th> 
       <div>
         Test utterances in representative blind 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>License_or_ID</code> <br/></td> 
      <td>  5 <br/></td> 
      <td>  6 <br/></td> 
      <td>  7 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_Reinstatement</code> <br/></td> 
      <td>  4 <br/></td> 
      <td>  6 <br/></td> 
      <td>  5 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  7 <br/></td> 
      <td>  8 <br/></td> 
      <td>  9 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Walk_In</code> <br/></td> 
      <td>  6 <br/></td> 
      <td>  8 <br/></td> 
      <td>  8 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p130"> 
   <p>This update resulted in an overall accuracy of 92% for the latest classifier (now on V6). In the world of natural language classification, this is a very good score for a representative blind test set. You will never achieve 100%; even human-to-human communications don’t come close to that. </p> 
  </div> 
  <div class="readable-text intended-text" id="p131"> 
   <p>Every data set is different, and we could spend several more cycles tweaking our training if there is plenty of data available. However, there are diminishing returns associated with pursuing results that approach 100%. There is also a risk of over-fitting your model to the current blind test set. Once additional logs become available and a new test set is created, you may discover additional gaps (or your overfitting will be exposed).</p> 
  </div> 
  <div class="readable-text intended-text" id="p132"> 
   <p>Table 5.20 shows a comparison of the blind test F1 scores of the baseline classifier against our latest updates. Twelve of the intents did not change (and they were already performing very well). One intent decreased from 90% to 80%, and the remaining 14 intents showed improvement. We felt that this was a good and reasonable tradeoff, improving more than half of our intents at the cost of one intent showing a slight decline.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p133"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.20</span> Comparison of baseline F1 scores and V6 F1 scores</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Baseline (V1) F1 score 
       </div></th> 
      <th> 
       <div>
         V6 F1 score 
       </div></th> 
      <th> 
       <div>
         Change 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Accident_Report</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Appointment</code> <br/></td> 
      <td>  0.8333 <br/></td> 
      <td>  0.833 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Change_Contact_Records</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Goodbye</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Hello</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Thanks</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_VA_About</code> <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  0.9524 <br/></td> 
      <td>  + 0.2857 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Fee_Info</code> <br/></td> 
      <td>  0.90 <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  - 0.1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>General_Negative_Feedback</code> <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>General_Request_Agent</code> <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Get_ID_Number</code> <br/></td> 
      <td>  0.75 <br/></td> 
      <td>  0.8571 <br/></td> 
      <td>  + 0.1071 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.56 <br/></td> 
      <td>  0.8750 <br/></td> 
      <td>  + 0.315 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_Reinstatement</code> <br/></td> 
      <td>  0.60 <br/></td> 
      <td>  0.75 <br/></td> 
      <td>  + 0.15 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_or_ID</code> <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  1 <br/></td> 
      <td>  + 0.3333 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.6153 <br/></td> 
      <td>  0.9412 <br/></td> 
      <td>  + 0.3259 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Name_Change</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Office_Information</code> <br/></td> 
      <td>  0.90 <br/></td> 
      <td>  1 <br/></td> 
      <td>  + 0.1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Payment_Methods</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Refund_Overcharge</code> <br/></td> 
      <td>  0.8571 <br/></td> 
      <td>  0.8571 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Sold_Vehicle</code> <br/></td> 
      <td>  0.9231 <br/></td> 
      <td>  1 <br/></td> 
      <td>  + 0.0769 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_License_Permit_ID</code> <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  (n/a - merged) <br/></td> 
      <td>  + 0.2 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Plates_Registration</code> <br/></td> 
      <td>  0.8889 <br/></td> 
      <td>  (n/a - merged) <br/></td> 
      <td>  + 0.1111 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Vehicle</code> <br/></td> 
      <td>  0.50 <br/></td> 
      <td>  (n/a - merged) <br/></td> 
      <td>  + 0.5 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  n/a <br/></td> 
      <td>  1 <br/></td> 
      <td>  (n/a – merged) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Request_Receipt</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
      <td>  (no change) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Vehicle_Permit</code> <br/></td> 
      <td>  0.8889 <br/></td> 
      <td>  1 <br/></td> 
      <td>  + 0.1111 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Vehicle_Title</code> <br/></td> 
      <td>  0.40 <br/></td> 
      <td>  0.8 <br/></td> 
      <td>  + 0.4 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Walk_In</code> <br/></td> 
      <td>  0.4615 <br/></td> 
      <td>  0.75 <br/></td> 
      <td>  + 0.2885 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p134"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text" id="p135"> Using the output from the previous exercise (a prioritized list of your poorest-performing intents), identify the category of error each intent is committing: recall, precision, or both. </li> 
    <li class="readable-text" id="p136"> Make iterative training adjustments to improve each intent. </li> 
    <li class="readable-text buletless-item" id="p137"> Measure each change to verify that 
     <ul> 
      <li> The intended effect is achieved </li> 
      <li> No other intents were negatively affected </li> 
     </ul></li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p138"> 
   <h2 class=" readable-text-h2"><span class="num-string">5.3</span> Solving “no intent matched”</h2> 
  </div> 
  <div class="readable-text" id="p139"> 
   <p>Now that we have our classifier in good shape for the current scope, we can focus on expanding the domain, if needed. During an initial review of your production logs, you will almost surely encounter topics that were not included in the initial training set. Some of these topics will be obvious, but perhaps there wasn’t enough data to train an intent at the time of the initial launch. Maybe the business wasn’t ready to write answers for some topics. Sometimes a seasonal topic is not included because it was not in the forefront of anyone’s mind (e.g., tax season, hurricane season, fiscal year end, etc.). Other topics may be completely unexpected (e.g., a data breach). </p> 
  </div> 
  <div class="readable-text intended-text" id="p140"> 
   <p>Although you don’t have any intents defined to match these utterances, the classifier will always attempt to make a prediction; it doesn’t know what it doesn’t know, so it does its best to match an utterance to what it does know. In an ideal world, the classifier would return very low confidence, and this would trigger an “anything_else” or “no action matches” type of response. In reality, such user utterances often contain words that appear somewhere in your training, so it is possible that the classifier will predict an intent that has training examples with similar words. </p> 
  </div> 
  <div class="readable-text" id="p141"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.3.1</span> Clustering utterances for new intents</h3> 
  </div> 
  <div class="readable-text" id="p142"> 
   <p>In the guidelines described in chapter 4, we recommended setting aside utterances that were related to the domain but not included in the original scope. It’s time to address these.</p> 
  </div> 
  <div class="readable-text intended-text" id="p143"> 
   <p>One of the topics our logs revealed was related to users wanting to cancel their license or registration. We know from our logs how the classifier predicted each utterance at the time the utterance was asked. Now we can test them against our latest classifier (V6) to get new model predictions. </p> 
  </div> 
  <div class="readable-text intended-text" id="p144"> 
   <p>In table 5.21, we see that our classifier exhibited low confidence and/or was incorrect whenever an utterance contained a form of the word “cancel.”</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p145"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.21</span> Unmatched utterances from logs with predictions from the V6 classifier</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Utterance 
       </div></th> 
      <th> 
       <div>
         Predicted intent 
       </div></th> 
      <th> 
       <div>
         Confidence 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Cancel a registration <br/></td> 
      <td>  <code>Appointment</code> <br/></td> 
      <td>  0.2681 <br/></td> 
     </tr> 
     <tr> 
      <td>  Cancel my car registration <br/></td> 
      <td>  <code>License_or_ID</code> <br/></td> 
      <td>  0.3651 <br/></td> 
     </tr> 
     <tr> 
      <td>  Cancel a drivers license <br/></td> 
      <td>  <code>License_Reinstatement</code> <br/></td> 
      <td>  0.3042 <br/></td> 
     </tr> 
     <tr> 
      <td>  Canceling a registration <br/></td> 
      <td>  <code>Appointment</code> <br/></td> 
      <td>  0.2417 <br/></td> 
     </tr> 
     <tr> 
      <td>  Cancellation of registration <br/></td> 
      <td>  <code>Fee_Info</code> <br/></td> 
      <td>  0.2786 <br/></td> 
     </tr> 
     <tr> 
      <td>  Cancelling my registration <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.3004 <br/></td> 
     </tr> 
     <tr> 
      <td>  Cancel a replacement license <br/></td> 
      <td>  <code>Vehicle_Permit</code> <br/></td> 
      <td>  0.3264 <br/></td> 
     </tr> 
     <tr> 
      <td>  Cancel the license <br/></td> 
      <td>  <code>License_Reinstatement</code> <br/></td> 
      <td>  0.3237 <br/></td> 
     </tr> 
     <tr> 
      <td>  Cancel a title or registration <br/></td> 
      <td>  <code>Vehicle_Title</code> <br/></td> 
      <td>  0.5913 <br/></td> 
     </tr> 
     <tr> 
      <td>  Cancel vehicle registrations <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.2914 <br/></td> 
     </tr> 
     <tr> 
      <td>  Commercial drivers license cancel <br/></td> 
      <td>  <code>License_Reinstatement</code> <br/></td> 
      <td>  0.2995 <br/></td> 
     </tr> 
     <tr> 
      <td>  Driver’s license cancellation <br/></td> 
      <td>  <code>Get_ID_Number</code> <br/></td> 
      <td>  0.3387 <br/></td> 
     </tr> 
     <tr> 
      <td>  How do I cancel my vehicle registration? <br/></td> 
      <td>  <code>License_or_ID</code> <br/></td> 
      <td>  0.4324 <br/></td> 
     </tr> 
     <tr> 
      <td>  I need to cancel a vehicle registration <br/></td> 
      <td>  <code>License_or_ID</code> <br/></td> 
      <td>  0.3481 <br/></td> 
     </tr> 
     <tr> 
      <td>  I need to cancel my ID <br/></td> 
      <td>  <code>Get_ID_Number</code> <br/></td> 
      <td>  0.3205 <br/></td> 
     </tr> 
     <tr> 
      <td>  I would like to cancel the registration on my car <br/></td> 
      <td>  <code>Change_Contact_Records</code> <br/></td> 
      <td>  0.3147 <br/></td> 
     </tr> 
     <tr> 
      <td>  I would like to cancel my car registration <br/></td> 
      <td>  <code>License_or_ID</code> <br/></td> 
      <td>  0.3447 <br/></td> 
     </tr> 
     <tr> 
      <td>  I would like to cancel my state identification card <br/></td> 
      <td>  <code>Change_Contact_Records</code> <br/></td> 
      <td>  0.2982 <br/></td> 
     </tr> 
     <tr> 
      <td>  I wanted to cancel a registration <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.3155 <br/></td> 
     </tr> 
     <tr> 
      <td>  I want to confirm cancellation of my registration <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.4092 <br/></td> 
     </tr> 
     <tr> 
      <td>  Questions about cancelling registration for a vehicle <br/></td> 
      <td>  <code>Fee_Info</code> <br/></td> 
      <td>  0.2795 <br/></td> 
     </tr> 
     <tr> 
      <td>  I want to cancel my registration on my pickup <br/></td> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.4761 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p146"> 
   <p>We’ll randomly divide these into a training set of nine utterances under a new <code>#Cancel_Registration_or_License</code> intent and add the remaining thirteen to our blind test set. </p> 
  </div> 
  <div class="readable-text intended-text" id="p147"> 
   <p>When we run the updated blind test set against our updated classifier (now V7), we get an overall accuracy of 92%, which is usually a very good, if not ideal, outcome. This will not always be the case, so if your overall performance drastically drops, you will need to iterate through the applicable improvement steps (depending on whether the problem was recall, precision, or both) for the intents that were affected. </p> 
  </div> 
  <div class="readable-text intended-text" id="p148"> 
   <p>Let’s walk through one more example of adding a new intent. The logs contained several utterances referring to a data breach. This is an example of how a chatbot can exhibit declining performance due to new information in the world. In this case, the organization had never experienced a data breach before. But when it did, and this news became public, users suddenly had a lot of questions about it. This manifested as unmatched and incorrect predictions, as seen in table 5.22.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p149"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.22</span> Unmatched utterances on the topic of “data breach” from logs, with predictions from the V7 classifier. The classifier didn’t have enough confidence to match most of the utterances referring to “hack” or “data breach,” which is good because we hadn’t yet taught it anything about that topic. But most of the utterances that contain the word “stolen” match strongly against our <code>#Report_Stolen</code> intent. This may not go so well for the user because our solution doesn’t have any answers yet concerning data that was stolen.</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Utterance 
       </div></th> 
      <th> 
       <div>
         Predicted intent 
       </div></th> 
      <th> 
       <div>
         Confidence 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  I want to know about that hacking on the BMV <br/></td> 
      <td>  &lt;none&gt; <br/></td> 
      <td>  n/a <br/></td> 
     </tr> 
     <tr> 
      <td>  I want to know about the breach in information at the BMV and if I’m at risk <br/></td> 
      <td>  &lt;none&gt; <br/></td> 
      <td>  n/a <br/></td> 
     </tr> 
     <tr> 
      <td>  My identity has been stolen <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.9483 <br/></td> 
     </tr> 
     <tr> 
      <td>  My license number was stolen <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.9240 <br/></td> 
     </tr> 
     <tr> 
      <td>  Need questions answered about data breach <br/></td> 
      <td>  &lt;none&gt; <br/></td> 
      <td>  n/a <br/></td> 
     </tr> 
     <tr> 
      <td>  No I’m curious about the current breach of stolen IDs <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.8604 <br/></td> 
     </tr> 
     <tr> 
      <td>  Someone hacked my information <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.4662 <br/></td> 
     </tr> 
     <tr> 
      <td>  Someone is using my drivers license number <br/></td> 
      <td>  <code>Get_ID_Number</code> <br/></td> 
      <td>  0.4067 <br/></td> 
     </tr> 
     <tr> 
      <td>  Someone stole my identity <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.7705 <br/></td> 
     </tr> 
     <tr> 
      <td>  Someone stole my information <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.8043 <br/></td> 
     </tr> 
     <tr> 
      <td>  Stolen personal identity <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.9263 <br/></td> 
     </tr> 
     <tr> 
      <td>  Stolen personal information <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.9166 <br/></td> 
     </tr> 
     <tr> 
      <td>  Stolen social security number <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.7515 <br/></td> 
     </tr> 
     <tr> 
      <td>  Was my account affected by the recent data hack? <br/></td> 
      <td>  &lt;none&gt; <br/></td> 
      <td>  n/a <br/></td> 
     </tr> 
     <tr> 
      <td>  Was my account hacked? <br/></td> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.3998 <br/></td> 
     </tr> 
     <tr> 
      <td>  Was there a data breach? <br/></td> 
      <td>  &lt;none&gt; <br/></td> 
      <td>  n/a <br/></td> 
     </tr> 
     <tr> 
      <td>  Yeah I’d like to know if my driver’s license has been breached <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.4092 <br/></td> 
     </tr> 
     <tr> 
      <td>  Yes what do I do about the data breach at the BMV? <br/></td> 
      <td>  &lt;none&gt; <br/></td> 
      <td>  n/a <br/></td> 
     </tr> 
     <tr> 
      <td>  Was my social security number stolen in the hack? <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.7806 <br/></td> 
     </tr> 
     <tr> 
      <td>  I want to know if my information was stolen <br/></td> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  0.9198 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p150"> 
   <p>To resolve the problem of this unmatched intent, we selected seven representative utterances from the logs to create a new intent called <code>#Data_Breach</code>. Our selection ensured that a variety of important terms, such as “hack,” “breach,” and “stolen,” were added to our new training set. The remaining utterances were added to our blind test set, and we tested our newest classifier, V8. The new <code>#Data_Breach</code> intent returned a perfect score, and the F1 score comparisons in table 5.23 show that nearly all others remained steady or improved since our baseline reading. </p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p151"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 5.23</span> Final score comparison between the baseline (V1) and the final version (V8)</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Intent 
       </div></th> 
      <th> 
       <div>
         Baseline (V1) F1 score 
       </div></th> 
      <th> 
       <div>
         V8 F1 score 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  <code>Accident_Report</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Appointment</code> <br/></td> 
      <td>  0.8333 <br/></td> 
      <td>  0.8333 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Cancel_Registration_or_License</code> <br/></td> 
      <td>  n/a (NEW) <br/></td> 
      <td>  0.9630 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Change_Contact_Records</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  0.8889 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Goodbye</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Hello</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_Thanks</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Chitchat_VA_About</code> <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Data_Breach</code> <br/></td> 
      <td>  n/a (NEW) <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Fee_Info</code> <br/></td> 
      <td>  0.90 <br/></td> 
      <td>  0.9524 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>General_Negative_Feedback</code> <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>General_Request_Agent</code> <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Get_ID_Number</code> <br/></td> 
      <td>  0.75 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Item_Not_Received</code> <br/></td> 
      <td>  0.56 <br/></td> 
      <td>  0.8750 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_Reinstatement</code> <br/></td> 
      <td>  0.60 <br/></td> 
      <td>  0.75 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>License_or_ID</code> <br/></td> 
      <td>  0.6667 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Login_Issue</code> <br/></td> 
      <td>  0.6153 <br/></td> 
      <td>  0.9412 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Name_Change</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Office_Information</code> <br/></td> 
      <td>  0.90 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Payment_Methods</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Refund_Overcharge</code> <br/></td> 
      <td>  0.8571 <br/></td> 
      <td>  0.80 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Sold_Vehicle</code> <br/></td> 
      <td>  0.9231 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_License_Permit_ID</code> <br/></td> 
      <td>  0.80 <br/></td> 
      <td>  (n/a - merged) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Plates_Registration</code> <br/></td> 
      <td>  0.8889 <br/></td> 
      <td>  (n/a - merged) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen_Vehicle</code> <br/></td> 
      <td>  0.50 <br/></td> 
      <td>  (n/a - merged) <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Report_Stolen</code> <br/></td> 
      <td>  n/a <br/></td> 
      <td>  0.9630 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Request_Receipt</code> <br/></td> 
      <td>  1 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Vehicle_Permit</code> <br/></td> 
      <td>  0.8889 <br/></td> 
      <td>  1 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Vehicle_Title</code> <br/></td> 
      <td>  0.40 <br/></td> 
      <td>  0.6667 <br/></td> 
     </tr> 
     <tr> 
      <td>  <code>Walk_In</code> <br/></td> 
      <td>  0.4615 <br/></td> 
      <td>  0.75 <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p152"> 
   <p>Our overall accuracy score remained steady at 92%. (Our updated blind test set has 160 questions, and 147 were correct.) You might recall that our very first blind test had an overall accuracy of 76%, so this is quite an improvement. Our V8 confusion matrix, shown in figure 5.7, also looks improved, with a fairly dark diagonal line. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p153">  
   <img alt="figure" src="../Images/CH05_F07_Freed2.png" width="1019" height="545"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.7</span> Comparison of baseline (V1) confusion matrix to the V8 update</h5>
  </div> 
  <div class="readable-text" id="p154"> 
   <p>We could iterate further to try to get a little higher, but for this use case, the classifier’s accuracy is more than good enough for the time being. Any further tweaks with the limited data we have at present are likely to over-fit our model to the current blind test set. Remember that a healthy strategy is to plan to iterate over the life of the bot, using newer logs and refreshed blind test sets.</p> 
  </div> 
  <div class="readable-text" id="p155"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.3.2</span> When to stop adding intents</h3> 
  </div> 
  <div class="readable-text" id="p156"> 
   <p>When reviewing your logs, you may have encountered a diverse range of other questions that are perfectly reasonable for the domain, but very infrequent. In our logs, we saw questions like the following, but no additional utterances with similar goals:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p157"> I need a form for a doctor to fill out saying a driver is not safe to drive anymore. </li> 
   <li class="readable-text" id="p158"> I have a question about electronic signatures. </li> 
   <li class="readable-text" id="p159"> What is the process for getting a specialty license plate? </li> 
  </ul> 
  <div class="readable-text" id="p160"> 
   <p>How do we know when to stop adding intents? It’s best to let the data from our human-annotated logs guide us. We can total up all of the examples by intent and render them as a chart, as in figure 5.8. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p161">  
   <img alt="figure" src="../Images/CH05_F08_Freed2.png" width="927" height="411"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.8</span> Example of a longtail chart. The terms we use to describe the volume distribution of our available training data are “short head” and “long tail.” These terms describe the visual representation of rendering our data on a bar chart. The heavier-volume intents are on the left (the short head), and as the volume decreases for each intent, the data has the appearance of a long tail falling off to the right.</h5>
  </div> 
  <div class="readable-text" id="p162"> 
   <p>In our longtail chart, we picked a point to divide between what should be in scope versus out of scope. This point isn’t a static, prescriptive position. It’s a decision that should be made with the business by establishing a minimum number of training examples required to create a new intent. Everything that falls on the left of this line should probably be included in the training, as there is evidence that these topics will be asked more frequently. Everything to the right will not be trained in the current classifier. Over time, you may find enough data in the logs to justify adding a new intent. Until then, your solution will have to handle such topics with one of the following strategies: give a response saying the bot doesn’t understand, fall back to an agent escalation, add a search integration to find answers in a document repository, or implement a retrieval-augmented generation (RAG) or large language model (LLM) component to generate answers. </p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p163"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text" id="p164"> Identify new topics based on your logs, and build new intents from the utterances found in the logs. </li> 
    <li class="readable-text" id="p165"> Add utterances to your blind set, and test your changes. </li> 
    <li class="readable-text" id="p166"> Is your classifier able to recognize the new intent without negatively affecting the performance of your existing intents? </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p167"> 
   <h2 class=" readable-text-h2"><span class="num-string">5.4</span> Supplementing traditional AI with generative content</h2> 
  </div> 
  <div class="readable-text" id="p168"> 
   <p>In conversational AI, we typically think of delivering either a static answer (as in classic intent-driven implementations) or an answer that is entirely generated (as in a RAG pattern). Static answers fill a need where an answer must maintain consistency, either in content or in structure. Although personalization is possible, it is generally limited to defined entities or other context-driven dialogue conditions. This tends to result in colder, less personalized bot responses. Figure 5.9 shows how three users with the same general goal, but very different personal situations, all receive the same bot response. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p169">  
   <img alt="figure" src="../Images/CH05_F09_Freed2.png" width="925" height="728"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.9</span> In a traditional (classification-based) dialogue pattern, an intent is identified, and the dialogue is configured to give a static or minimally personalized answer.</h5>
  </div> 
  <div class="readable-text" id="p170"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.4.1</span> Combining traditional and generative AI for an intent</h3> 
  </div> 
  <div class="readable-text" id="p171"> 
   <p>We can enhance the user experience using a hybrid response pattern, which combines personalized generated content with the static predefined answers written for our intent. Our goal is to acknowledge the user’s problem while ensuring that important information is delivered with consistency. Many large language models excel at summarization tasks, so a model can be prompted to craft an empathetic message that conveys a personalized level of understanding. Figure 5.10 shows what this looks like from the user’s perspective.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p172">  
   <img alt="figure" src="../Images/CH05_F10_Freed2.png" width="777" height="580"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.10</span> An output response identifies the correct intent using traditional AI and then prepends generated text to the static output response configured for the intent. The generated greeting and summary convey to the user that the bot understands their goal and the particular details of the user’s situation.</h5>
  </div> 
  <div class="readable-text" id="p173"> 
   <p>This pattern employs an API call to the LLM as a dialogue step. Content is generated by the LLM and delivered just before the predefined output response. Figure 5.11 shows the high-level steps for such a pattern.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p174">  
   <img alt="figure" src="../Images/CH05_F11_Freed2.png" width="1013" height="74"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 5.11</span> LLMs can be called within traditional dialogue patterns to greet a user and summarize their problem before delivering a predefined or static answer.</h5>
  </div> 
  <div class="readable-text" id="p175"> 
   <h3 class=" readable-text-h3"><span class="num-string">5.4.2</span> Prompting to convey understanding</h3> 
  </div> 
  <div class="readable-text" id="p176"> 
   <p>In conversational AI, your bot’s role is typically to be a representative of your company. They are a “digital” resource, as opposed to a “human” resource. Still, their job is to be the face of the company. Human agents are great at conveying empathy and understanding. In fact, they will often restate the user’s problem to demonstrate that they understand. LLMs can be prompted to simulate this summarization behavior. </p> 
  </div> 
  <div class="readable-text intended-text" id="p177"> 
   <p>Since our traditional AI has already classified the user’s intent under this pattern, we can craft a prompt that instructs the LLM to perform a specific task. In this case, we want the LLM to generate a personalized, empathetic greeting that can be paired with additional static content. The next listing shows a prompt instruction for summarizing a user’s input.</p> 
  </div> 
  <div class="browsable-container listing-container" id="p178"> 
   <h5 class=" listing-container-h5 browsable-container-h5"><span class="num-string">Listing 5.1</span> Prompting a model to greet and summarize a user problem</h5> 
   <div class="code-area-container"> 
    <pre class="code-area">&lt;|instruction|&gt;
You are a customer service agent for Friendly Skies Airline. Each input contains a customer problem. Greet the customer and summarize their problem. 

&lt;|input|&gt;
Hello! This is Chihiro — I had a flight credit for a cancelled flight from earlier this year. I don’t find the credit anymore. Can you look for me if you can locate it? This is for booking # WKRP01. My frequent flyer # is 8675309. Thanks a lot in advance!


&lt;|output|&gt;
Hello Chihiro. It seems you had a flight credit for a cancelled flight from earlier this year and you need assistance locating the credit for booking number WKRP01.</pre>  
   </div> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p179"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text" id="p180"> Collect a set of user utterances to test and tune an LLM prompt that can greet a user where appropriate and summarize their problem. <br/> Experiment with a variety of instruction prompts. The goal is to create an efficient prompt instruction that will produce good results for the majority of your utterance test set. </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p181"> 
   <h2 class=" readable-text-h2">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p182"> A classifier’s performance can be measured in terms of accuracy, recall, precision, and F1 score. These measurements reflect the types of errors a classifier may be committing. </li> 
   <li class="readable-text" id="p183"> The performance metrics produced by your testing will inform your next steps toward improving classifier performance. Higher volume intents with low performance are a good place to start. </li> 
   <li class="readable-text" id="p184"> Iterative test and train cycles will show you the effects of your changes. </li> 
   <li class="readable-text" id="p185"> A chatbot can use additional strategies, such as disambiguation, clarifying questions, and entity detection to overcome confusion or route answers for merged intents. </li> 
   <li class="readable-text" id="p186"> A chatbot with a strong classifier can deliver more business value by delivering the right answers on the first try and deflecting work that would otherwise be handled by a human agent. You should plan to monitor and retrain your solution throughout the life of the bot. </li> 
   <li class="readable-text" id="p187"> Generative AI can supplement a traditional AI solution by infusing static chatbot responses with personalization and empathy, which enhances the perception of understanding. </li> 
  </ul>
 </div></div></body></html>