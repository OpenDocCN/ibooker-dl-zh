- en: Chapter 1\. Introduction
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 介绍
- en: The goal of this book is to show how any developer with basic experience using
    a command-line terminal and code editor can get started building their own projects
    running machine learning (ML) on embedded devices.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是展示任何具有基本命令行终端和代码编辑器使用经验的开发人员如何开始构建自己的项目，运行嵌入式设备上的机器学习（ML）。
- en: When I first joined Google in 2014, I discovered a lot of internal projects
    that I had no idea existed, but the most exciting was the work that the OK Google
    team were doing. They were running neural networks that were just 14 kilobytes
    (KB) in size! They needed to be so small because they were running on the digital
    signal processors (DSPs) present in most Android phones, continuously listening
    for the “OK Google” wake words, and these DSPs had only tens of kilobytes of RAM
    and flash memory. The team had to use the DSPs for this job because the main CPU
    was powered off to conserve battery, and these specialized chips use only a few
    milliwatts (mW) of power.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当我2014年首次加入谷歌时，我发现了许多我之前不知道存在的内部项目，但最令人兴奋的是OK Google团队正在进行的工作。他们运行的神经网络只有14千字节（KB）！它们需要如此小是因为它们在大多数Android手机中的数字信号处理器（DSP）上运行，持续监听“OK
    Google”唤醒词，而这些DSP只有几十KB的RAM和闪存。团队必须使用DSP来完成这项工作，因为主CPU已关闭以节省电池，而这些专用芯片只使用几毫瓦（mW）的功率。
- en: Coming from the image side of deep learning, I’d never seen networks so small,
    and the idea that you could use such low-power chips to run neural models stuck
    with me. As I worked on getting TensorFlow and later TensorFlow Lite running on
    Android and iOS devices, I remained fascinated by the possibilities of working
    with even simple chips. I learned that there were other pioneering projects in
    the audio world (like Pixel’s Music IQ) for predictive maintenance (like PsiKick)
    and even in the vision world (Qualcomm’s Glance camera module).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 从深度学习的图像方面来看，我从未见过如此小的网络，以及使用低功耗芯片来运行神经模型的想法一直留在我心中。当我努力让TensorFlow和后来的TensorFlow
    Lite在Android和iOS设备上运行时，我仍然被与简单芯片合作的可能性所吸引。我了解到在音频领域还有其他开创性的项目（如Pixel的Music IQ）用于预测性维护（如PsiKick），甚至在视觉领域（高通的Glance相机模块）也有类似的项目。
- en: It became clear to me that there was a whole new class of products emerging,
    with the key characteristics that they used ML to make sense of noisy sensor data,
    could run using a battery or energy harvesting for years, and cost only a dollar
    or two. One term I heard repeatedly was “peel-and-stick sensors,” for devices
    that required no battery changes and could be applied anywhere in an environment
    and forgotten. Making these products real required ways to turn raw sensor data
    into actionable information locally, on the device itself, since the energy costs
    of transmitting streams anywhere have proved to be inherently too high to be practical.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，很明显有一类全新的产品正在涌现，其关键特征是它们利用机器学习来理解嘈杂的传感器数据，可以使用电池或能量收集器运行多年，成本仅为一两美元。我反复听到的一个术语是“剥离和粘贴传感器”，用于不需要更换电池的设备，可以应用于环境中的任何地方并被遗忘。要使这些产品变为现实，需要将原始传感器数据转化为可操作信息的方式，本地在设备上进行处理，因为传输数据流的能量成本被证明太高，以至于不切实际。
- en: This is where the idea of TinyML comes in. Long conversations with colleagues
    across industry and academia have led to the rough consensus that if you can run
    a neural network model at an energy cost of below 1 mW, it makes a lot of entirely
    new applications possible. This might seem like a somewhat arbitrary number, but
    if you translate it into concrete terms, it means a device running on a coin battery
    has a lifetime of a year. That results in a product that’s small enough to fit
    into any environment and able to run for a useful amount of time without any human
    intervention.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是TinyML的概念所在。与行业和学术界同事长时间的交谈导致了一个粗略的共识，即如果你能以低于1毫瓦的能量成本运行神经网络模型，那么将会有许多全新的应用变得可能。这个数字可能看起来有点随意，但如果你将其转化为具体的术语，那就意味着一个运行在硬币电池上的设备可以使用一年。这将导致一个产品足够小，可以适应任何环境，并能够在没有任何人为干预的情况下运行一段有用的时间。
- en: Note
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: I’m going to be jumping straight into using some technical terms to talk about
    what this book will be covering, but don’t worry if some of them are unfamiliar
    to you; we define their meaning the first time we use them.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我将直接使用一些技术术语来讨论本书将涵盖的内容，但如果其中一些对您不熟悉，不要担心；我们在第一次使用它们时会定义它们的含义。
- en: At this point, you might be wondering about platforms like the Raspberry Pi,
    or NVIDIA’s Jetson boards. These are fantastic devices, and I use them myself
    frequently, but even the smallest Pi is similar to a mobile phone’s main CPU and
    so draws hundreds of milliwatts. Keeping one running even for a few days requires
    a battery similar to a smartphone’s, making it difficult to build truly untethered
    experiences. NVIDIA’s Jetson is based on a powerful GPU, and we’ve seen it use
    up to 12 watts of power when running at full speed, so it’s even more difficult
    to use without a large external power supply. This is usually not a problem in
    automotive or robotics applications, since the mechanical parts demand a large
    power source themselves, but it does make it tough to use these platforms for
    the kinds of products I’m most interested in, which need to operate without a
    wired power supply. Happily, when using them the lack of resource constraints
    means that frameworks like TensorFlow, TensorFlow Lite, and NVIDIA’s TensorRT
    are available, since they’re usually based on Linux-capable Arm Cortex-A CPUs,
    which have hundreds of megabytes of memory. This book will not be focused on describing
    how to run on those platforms for the reason just mentioned, but if you’re interested,
    there are a lot of resources and documentation available; for example, see [TensorFlow
    Lite’s mobile documentation](https://www.tensorflow.org/lite).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: Another characteristic I care about is cost. The cheapest Raspberry Pi Zero
    is $5 for makers, but it is extremely difficult to buy that class of chip in large
    numbers at that price. Purchases of the Zero are usually restricted by quantity,
    and while the prices for industrial purchases aren’t transparent, it’s clear that
    $5 is definitely unusual. By contrast, the cheapest 32-bit microcontrollers cost
    much less than a dollar each. This low price has made it possible for manufacturers
    to replace traditional analog or electromechanical control circuits with software-defined
    alternatives for everything from toys to washing machines. I’m hoping we can use
    the ubiquity of microcontrollers in these devices to introduce artificial intelligence
    as a software update, without requiring a lot of changes to existing designs.
    It should also make it possible to get large numbers of smart sensors deployed
    across environments like buildings or wildlife reserves without the costs outweighing
    the benefits or funds available.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: Embedded Devices
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The definition of TinyML as having an energy cost below 1 mW does mean that
    we need to look to the world of embedded devices for our hardware platforms. Until
    a few years ago, I wasn’t familiar with them myself—they were shrouded in mystery
    for me. Traditionally they had been 8-bit devices and used obscure and proprietary
    toolchains, so it seemed very intimidating to get started with any of them. A
    big step forward came when Arduino introduced a user-friendly integrated development
    environment (IDE) along with standardized hardware. Since then, 32-bit CPUs have
    become the standard, largely thanks to Arm’s Cortex-M series of chips. When I
    started to prototype some ML experiments a couple of years ago, I was pleasantly
    surprised by how relatively straightforward the development process had become.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Embedded devices still come with some tough resource constraints, though. They
    often have only a few hundred kilobytes of RAM, or sometimes much less than that,
    and have similar amounts of flash memory for persistent program and data storage.
    A clock speed of just tens of megahertz is not unusual. They will definitely not
    have full Linux (since that requires a memory controller and at least one megabyte
    of RAM), and if there is an operating system, it may well not provide all or any
    of the POSIX or standard C library functions you expect. Many embedded systems
    avoid using dynamic memory allocation functions like `new` or `malloc()` because
    they’re designed to be reliable and long-running, and it’s extremely difficult
    to ensure that if you have a heap that can be fragmented. You might also find
    it tricky to use a debugger or other familiar tools from desktop development,
    since the interfaces you’ll be using to access the chip are very specialized.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: There were some nice surprises as I learned embedded development, though. Having
    a system with no other processes to interrupt your program can make building a
    mental model of what’s happening very simple, and the straightforward nature of
    a processor without branch prediction or instruction pipelining makes manual assembly
    optimization a lot easier than on more complex CPUs. I also find a simple joy
    in seeing LEDs light up on a miniature computer that I can balance on a fingertip,
    knowing that it’s running millions of instructions a second to understand the
    world around it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Changing Landscape
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s only recently that we’ve been able to run ML on microcontrollers at all,
    and the field is very young, which means hardware, software, and research are
    all changing extremely quickly. This book is a based on a snapshot of the world
    as it existed in 2019, which in this area means some parts were out of date before
    we’d even finished writing the last chapter. We’ve tried to make sure we’re relying
    on hardware platforms that will be available over the long term, but it’s likely
    that devices will continue to improve and evolve. The TensorFlow Lite software
    framework that we use has a stable API, and we’ll continue to support the examples
    we give in the text over time, but we also provide web links to the very latest
    versions of all our sample code and documentation. You can expect to see reference
    applications covering more use cases than we have in this book being added to
    the TensorFlow repository, for example. We also aim to focus on skills like debugging,
    model creation, and developing an understanding of how deep learning works, which
    will remain useful even as the infrastructure you’re using changes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: We want this book to give you the foundation you need to develop embedded ML
    products to solve problems you care about. Hopefully we’ll be able to start you
    along the road of building some of the exciting new applications I’m certain will
    be emerging over the next few years in this domain.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Pete Warden
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
