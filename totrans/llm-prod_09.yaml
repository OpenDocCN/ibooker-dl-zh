- en: '10 *Creating a coding copilot project: This would have helped you earlier*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 *创建一个编码助手项目：这会早些时候帮到您*
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Deploying a coding model to an API
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将编码模型部署到 API
- en: Setting up a VectorDB locally and using it for a retrieval-augmented generation
    system
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本地设置 VectorDB 并使用它作为检索增强生成系统
- en: Building a VS Code extension to use our LLM service
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个 VS Code 扩展来使用我们的 LLM 服务
- en: Insights and lessons learned from the project
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从项目中获得的见解和经验教训
- en: Progress doesn’t come from early risers—progress is made by lazy men looking
    for easier ways to do things.—Robert Heinlein
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 进步不是来自早起的人——进步是由寻找更简单做事方式的懒惰人创造的。——罗伯特·海因莱因
- en: If you touch code for your day job, you’ve probably dreamed about having an
    AI assistant helping you out. In fact, maybe you already do. With tools like GitHub
    Copilot out on the market, we have seen LLMs take autocomplete to the next level.
    However, not every company is happy with the offerings on the market, and not
    every enthusiast can afford them. So let’s build our own!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在工作中接触代码，您可能梦想过有一个 AI 助手来帮助您。实际上，也许您已经这样做了。随着市场上出现像 GitHub Copilot 这样的工具，我们已经看到
    LLM 将自动完成提升到了新的水平。然而，并不是每个公司都对市场上的产品感到满意，也不是每个爱好者都能负担得起。所以，让我们自己动手吧！
- en: In this chapter, we will build a Visual Studio Code (VS Code) extension that
    will allow us to use our LLM in the code editor. The editor of choice will be
    VS Code, as it is a popular open source code editor. Popular might be an understatement,
    as the Stack Overflow 2023 Developer Survey showed it’s the preferred editor for
    81% of developers.[¹](#footnote-129) It’s essentially a lightweight version of
    Visual Studio, which is a full IDE that’s been around since 1997\.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将构建一个 Visual Studio Code (VS Code) 扩展，使我们能够在代码编辑器中使用我们的 LLM。首选的编辑器将是
    VS Code，因为它是一个流行的开源代码编辑器。流行可能是一个低估，因为 Stack Overflow 2023 开发者调查表明它是 81% 开发者的首选编辑器。[¹](#footnote-129)
    它基本上是 Visual Studio 的轻量级版本，Visual Studio 是一个自 1997 年以来一直存在的完整 IDE。
- en: Beyond just choosing a specific editor, we will also make some other judicious
    decisions to limit the scope of the project and make it more meaningful. For example,
    in the last project, we focused on building an awesome LLM model we could deploy.
    In this project, we will instead be starting with an open source model that has
    already been trained on coding problems. To customize it, instead of finetuning,
    we’ll build a RAG system around it, which will allow us to keep it up to date
    more easily. Also, since we aren’t training our own model, we’ll focus on building
    a copilot that is good at Python, the main language we’ve used throughout this
    book, and not worry about every language out there.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 除了选择一个特定的编辑器，我们还将做出一些明智的决定来限制项目的范围，使其更有意义。例如，在上一个项目中，我们专注于构建一个可以部署的出色的 LLM 模型。在这个项目中，我们将从已经训练过编码问题的开源模型开始。为了定制它，我们不会微调，而是围绕它构建一个
    RAG 系统，这将使我们更容易保持其更新。此外，由于我们不会训练自己的模型，我们将专注于构建一个擅长 Python 的助手，这是我们在整本书中使用的语言，而不用担心其他所有语言。
- en: Now that we have a clear idea of what we are building and a goal in mind, let’s
    get to it!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经清楚地知道了我们要构建什么，并且有一个目标在心中，让我们开始吧！
- en: 10.1 Our model
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 我们的模型
- en: Since we are only going to be focusing on Python, we decided to use DeciCoder
    as our model. DeciCoder is a commercial open source model that has only 1B parameters.[²](#footnote-130)
    Despite its tiny size, it’s really good at what it does. It has been trained on
    the Stack dataset but filtered to only include Python, Java, and JavaScript code.
    It’s only trained on three languages, which would typically be a limitation, but
    it is actually part of the secret sauce of why it’s so good despite its small
    size.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只关注 Python，我们决定使用 DeciCoder 作为我们的模型。DeciCoder 是一个只有 1B 参数的商业开源模型。[²](#footnote-130)
    尽管它的体积很小，但它确实擅长它所做的事情。它是在 Stack 数据集上训练的，但过滤后只包含 Python、Java 和 JavaScript 代码。它只训练了三种语言，这通常是一个限制，但实际上它是它之所以如此出色的秘密之一。
- en: Some other limitations to be aware of are that it only has a context window
    of 2,048 tokens, which isn’t bad for a model of this size, but it is relatively
    small when we consider that we plan to use a RAG system and will need to give
    it examples of code. Code samples tend to be quite large, which limits what we
    can do and how many examples we can give it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一些其他需要注意的限制是，它只有一个 2,048 个标记的上下文窗口，对于一个这个规模的模型来说并不差，但当我们考虑到我们计划使用 RAG 系统，并需要给它提供代码示例时，它就显得相对较小了。代码示例通常相当大，这限制了我们可以做的事情和我们可以提供的示例数量。
- en: A bigger problem using DeciCoder with RAG is that the model wasn’t instruction
    tuned. Instead, it was designed to beat the HumanEval dataset ([https://github.com/openai/human-eval](https://github.com/openai/human-eval)).
    In this evaluation dataset, a model is given only a function name and docstring
    describing what the function should do. From just this input, the model will generate
    functioning code to complete the function. As a result, it’s hard to know if giving
    the model more context from a RAG system will help it, but we’re going to go ahead
    and try to find out!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 RAG 与 DeciCoder 的大问题是模型没有进行指令微调。相反，它是为了击败 HumanEval 数据集（[https://github.com/openai/human-eval](https://github.com/openai/human-eval)）而设计的。在这个评估数据集中，模型只给出一个函数名和描述函数应该做什么的文档字符串。仅从这个输入，模型将生成可执行的代码来完成函数。因此，很难知道从
    RAG 系统中提供更多上下文是否会帮助模型，但我们将继续尝试找出答案！
- en: Lastly, its tiny size actually makes it an interesting choice for another reason.
    Because it’s so small, we could potentially put the model right inside the VS
    Code extension we are building, using compiling methods we’ve discussed in other
    chapters. This would allow us to build a very compact application! We won’t be
    doing that in this book, mostly because it would require us to write a lot of
    JavaScript. That’s a problem because we only expect our readers to be familiar
    with Python, so it’s a tad too adventurous here to explain the details in-depth,
    but we leave it as an exercise for the readers who are JavaScript pros.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，它的小巧体积实际上使它成为另一个有趣的选择。因为它如此小巧，我们有可能将模型直接放入我们正在构建的 VS Code 扩展程序中，使用我们在其他章节中讨论的编译方法。这将使我们能够构建一个非常紧凑的应用程序！我们在这本书中不会这样做，主要是因为这将要求我们编写大量的
    JavaScript。这是一个问题，因为我们只期望我们的读者熟悉 Python，所以在这里深入解释细节有点过于冒险，但我们将其留作对 JavaScript
    高手读者的练习。
- en: What we will do instead is serve our model as an API that you can run locally
    and will be able to call from the extension. In listing 10.1, we create a simple
    FastAPI service to serve our model. In fact, most of this code you’ve already
    seen back in chapter 6, and we have only made a few slight changes. The first
    is that we have changed the code to use the DeciCoder model and tokenizer. The
    second is a bit more involved, but we have added `stop` tokens. These are tokens
    that will inform the model to stop generating when it runs into them. This is
    done by creating a `StoppingCriteria` class. The tokens we have chosen will make
    a bit more sense once we’ve defined our prompt, but essentially, we are looking
    to have our model create one function at a time.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要做的是将我们的模型作为 API 提供服务，您可以在本地运行它，并且可以从扩展程序中调用它。在列表 10.1 中，我们创建了一个简单的 FastAPI
    服务来提供我们的模型。实际上，您在第六章中已经看到了大部分代码，我们只做了一些小的修改。第一个修改是我们将代码更改为使用 DeciCoder 模型和分词器。第二个修改稍微复杂一些，但我们添加了
    `stop` 标记。这些标记会通知模型在遇到它们时停止生成。这是通过创建一个 `StoppingCriteria` 类来实现的。我们选择的标记在我们定义了提示后会有更多的意义，但本质上，我们希望模型一次创建一个函数。
- en: Listing 10.1 A simple FastAPI endpoint using DeciCoder
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.1 使用 DeciCoder 的简单 FastAPI 端点
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Torch settings'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 火炬设置'
- en: '#2 Δefines the stopping behavior'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 定义停止行为'
- en: '#3 Loads tokenizer and models'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 加载分词器和模型'
- en: '#4 Runs FastAPI'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 运行 FastAPI'
- en: '#5 RAG will go here.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 RAG 将在这里。'
- en: '#6 Generates response'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 生成响应'
- en: '#7 Starts service; defaults to localhost on port 8000'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 启动服务；默认端口为 8000'
- en: 'Assuming this listing is in a Python script server.py, you can start up the
    server by running `$` `python` `server.py`. Once you have it up and running, let’s
    go ahead and make sure it’s working correctly by sending it a request. In a new
    terminal, we can send the API a `curl` request with a simple prompt:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这个列表在一个名为 server.py 的 Python 脚本中，您可以通过运行 `$` `python` `server.py` 来启动服务器。一旦它启动并运行，让我们发送一个请求来确保它正确工作。在一个新的终端中，我们可以使用简单的提示向
    API 发送一个 `curl` 请求：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The response should be a simple Python function to complete a “Hello World”
    function. The response we got back from the server was `return` `f"Hello` `{name}!"`.
    So far, so good! Next, we’ll customize the API to utilize a RAG system.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 响应应该是一个简单的 Python 函数，用于完成“Hello World”函数。我们从服务器收到的响应是 `return` `f"Hello` `{name}!"`。到目前为止，一切顺利！接下来，我们将定制
    API 以利用 RAG 系统。
- en: 10.2 Data is king
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 数据为王
- en: Now that we have decided on a model, let’s prepare a dataset for our RAG system.
    RAG is an effective way to introduce context to our model without having to finetune
    it; it also allows us to customize the results based on our data. Essentially,
    RAG is a good system to follow if you want your model to know the context of your
    organization’s ever-changing code base. It’s great to have a model that’s good
    at coding, but we want it to be good at *our* code. We want it to use the right
    variable names and import custom dependencies built in-house—that sort of thing.
    In this section, we’ll set up a VectorDB, upload a Python coding dataset, and
    then update the API we just built to utilize it all.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经决定了一个模型，让我们为我们的 RAG 系统准备一个数据集。RAG 是在不需要微调模型的情况下向模型引入上下文的有效方法；它还允许我们根据我们的数据自定义结果。本质上，如果你想让你的模型了解你组织不断变化的代码库的上下文，RAG
    是一个很好的系统。有一个擅长编码的模型很好，但我们希望它擅长 *我们的* 代码。我们希望它使用正确的变量名和导入内部构建的定制依赖项——诸如此类的事情。在本节中，我们将设置一个
    VectorDB，上传一个 Python 编码数据集，然后更新我们刚刚构建的 API 以利用它。
- en: 10.2.1 Our VectorDB
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.1 我们的 VectorDB
- en: Before we can really dive into our dataset, we need to first set up our infrastructure.
    Of course, if your dataset is small enough, it is possible to load it into memory
    and run similarity search with tools like Faiss or USearch directly in Python,
    but where’s the fun in that? Plus, we want to show you Milvus.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们真正深入数据集之前，我们首先需要设置我们的基础设施。当然，如果你的数据集足够小，你可以将其加载到内存中，并使用 Faiss 或 USearch 等工具直接在
    Python 中运行相似度搜索，但那样有什么乐趣呢？此外，我们还想向你展示 Milvus。
- en: Milvus is an awesome open source VectorDB that competes with the big players
    in this space. You can run it locally or across a large cloud cluster, so it scales
    easily to your needs. If you’d rather not deal with the setup, there are managed
    Milvus clusters available. One of my favorite features is its GPU-enabled version,
    which makes vector search lightning fast.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Milvus 是一个出色的开源 VectorDB，与这个领域的大玩家竞争。你可以在本地或大型云集群上运行它，因此它可以很容易地扩展到你的需求。如果你不想处理设置，还有可管理的
    Milvus 集群可供选择。我最喜欢的功能是其支持 GPU 的版本，这使得向量搜索变得非常快。
- en: 'Thankfully, the community has also made Milvus extremely approachable and easy
    to set up. In fact, the standalone version only requires Docker to run and comes
    with a startup script to make it even easier. Since we are going to run everything
    locally for this project, we will use the standalone version (to learn more, see
    [https://mng.bz/aVE9](https://mng.bz/aVE9)). To do so, we need to run the following
    commands in a terminal:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，社区也使 Milvus 非常易于接近和设置。事实上，独立版本只需要 Docker 来运行，并附带一个启动脚本，使其更加容易。由于我们将在本项目中本地运行一切，我们将使用独立版本（了解更多信息，请参阅
    [https://mng.bz/aVE9](https://mng.bz/aVE9))。为此，我们需要在终端中运行以下命令：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first command will download a shell script, and the second will run it.
    This script is really only out of convenience since the Docker `run` command gets
    rather long. It also includes two more commands you should know about. The `Stop`
    command, which will stop your Milvus docker container, is
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条命令将会下载一个 shell 脚本，第二条命令将会运行它。这个脚本实际上只是为了方便，因为 Docker 的 `run` 命令相当长。它还包括两个你应该了解的额外命令。`Stop`
    命令，它将停止你的 Milvus Docker 容器，是
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: and the `delete` command, which will delete all the data from your computer
    when you no longer wish to keep it, is
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`delete` 命令，当你不再希望保留数据时，将会从你的电脑中删除所有数据，它是'
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You don’t need to run those yet, but remember them for when we are done. Now
    that we have our database set up, let’s make it useful and load some data into
    it.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在不需要运行这些命令，但记住它们，等我们完成后再用。现在我们已经设置了数据库，让我们让它变得有用，并将一些数据加载到其中。
- en: 10.2.2 Our dataset
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.2 我们的数据集
- en: If this were a workshop, we’d show you how to write a script to pull your organization’s
    code from GitHub and use that to augment your prompts. We could even set up a
    GitHub Actions pipeline to update our VectorDB with your code whenever it merges
    into the main branch. But since we don’t have access to your code and this is
    only a book, we’ll do the reasonable thing and use an open source dataset.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个研讨会，我们会向你展示如何编写一个脚本来从 GitHub 拉取你组织的代码，并使用它来增强你的提示。我们甚至可以设置一个 GitHub Actions
    流水线，以便每次代码合并到主分支时更新我们的 VectorDB。但由于我们没有访问你的代码，这只是一个书籍，我们将做合理的事情并使用开源数据集。
- en: We will choose the Alpaca dataset for our project. The Alpaca dataset was compiled
    by Stanford when it trained the model of the same name using distillation and
    GPT-3 as the mentor model. Since it’s synthetic data, the dataset is extremely
    clean, making it easy to work with. In fact, it’s so easy that multiple copies
    online have already filtered out all the Python code examples. This subset comprises
    18.6K Python coding challenges, consisting of a task or instruction and generated
    code—perfect for what we are trying to accomplish.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为我们的项目选择Alpaca数据集。Alpaca数据集是由斯坦福大学在训练同名模型时编译的，使用了蒸馏和GPT-3作为导师模型。由于它是合成数据，数据集非常干净，这使得它易于处理。事实上，它如此简单，以至于网上的多个副本已经过滤掉了所有的Python代码示例。这个子集包含18.6K个Python编码挑战，包括一个任务或指令和生成的代码——非常适合我们想要达成的目标。
- en: In listing 10.2, we create our pipeline to load the dataset into Milvus. We
    create a `PythonCodeIngestion` class to handle the details of chunking our dataset
    and uploading it in batches. Note that we use the `krlvi/sentence-t5-base-nlpl-code_search_`
    `net` embedding model. This embedding model has been specifically trained on the
    CodeSearchNet dataset ([https://github.com/github/CodeSearchNet](https://github.com/github/CodeSearchNet))
    and is excellent for creating meaningful embeddings of code.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表10.2中，我们创建我们的管道来将数据集加载到Milvus中。我们创建了一个`PythonCodeIngestion`类来处理我们的数据集分块和批量上传的细节。请注意，我们使用了`krlvi/sentence-t5-base-nlpl-code_search_`
    `net`嵌入模型。这个嵌入模型已经在CodeSearchNet数据集([https://github.com/github/CodeSearchNet](https://github.com/github/CodeSearchNet))上进行了专门训练，非常适合创建代码的有意义嵌入。
- en: Listing 10.2 A data pipeline to ingest Alpaca
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.2：摄取Alpaca的数据管道
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 Connects to Milvus'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 连接到Milvus'
- en: Now that we have our ingestion class created, we can move forward with the pipeline.
    First, we’ll need to create our collection if this is the first time we’ve run
    it. A collection is like a table in other databases or an index in Pinecone. We’ll
    define our schema, which is simply an ID field, our embeddings field, and a metadata
    field, which contains freeform JSON. Once that’s set, we’ll upload our data using
    our `PythonCodeIngestion` class.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了我们的摄取类，我们可以继续进行管道操作。首先，如果这是我们第一次运行它，我们需要创建我们的集合。集合在其他数据库中就像一个表，或者在Pinecone中就像一个索引。我们将定义我们的模式，它只是一个ID字段、我们的嵌入字段和一个元数据字段，该字段包含自由形式的JSON。一旦设置好，我们将使用我们的`PythonCodeIngestion`类上传我们的数据。
- en: 'Next, we need to create our search index. The index type we’ll use is `IVF_FLAT`,
    which is the most basic index in Milvus and splits the embedding space into `nlist`
    number of clusters. This accelerates the similarity search by first comparing
    our search embedding against the cluster centers and then against the embedding
    in the cluster it is closest to. We will also use `L2` for our metric type, which
    means we’ll be using Euclidean distance. These are common settings, but we don’t
    need anything special for our dataset. Milvus supports a larger selection of options
    when building an index, and we encourage you to check out their documentation:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建我们的搜索索引。我们将使用的索引类型是`IVF_FLAT`，这是Milvus中最基本的索引，将嵌入空间分割成`nlist`数量的聚类。这通过首先将我们的搜索嵌入与聚类中心进行比较，然后与它最近的聚类中的嵌入进行比较来加速相似性搜索。我们还将使用`L2`作为我们的度量类型，这意味着我们将使用欧几里得距离。这些是常见的设置，但对我们来说不需要任何特殊设置。Milvus在构建索引时支持更多的选项，我们鼓励您查看他们的文档：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 Creates a collection if it doesn’t exist'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 如果不存在则创建集合'
- en: '#2 Connects to the collection and shows its size'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 连接到集合并显示其大小'
- en: '#3 Ingests data and shows the stats now that data is ingested'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 数据摄取并显示数据摄取后的统计数据'
- en: '#4 Builds the search index'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 构建搜索索引'
- en: '#5 The number of clusters'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 聚类的数量'
- en: 'Now that everything is set up, we are good to move on to the next step. But
    first, let’s test it by running a query. We’ll want to make sure our data and
    index are giving us reasonable search results. With Milvus, we’ll first load the
    collection into memory and convert our query into an embedding with our embedder.
    Next, we’ll define some search parameters. Again, `L2` stands for Euclidean distance,
    and the `nprobe` parameter states how many clusters to search. In our case, of
    the 128 clusters we set up, we’ll search the 10 closest ones to our query embedding.
    Lastly, in the actual search, we’ll limit our results to the three best matches
    and return the metadata field along with our queries:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置好了一切，我们可以继续下一步。但在那之前，让我们通过运行一个查询来测试它。我们想要确保我们的数据和索引给我们提供了合理的搜索结果。使用Milvus，我们首先将集合加载到内存中，并使用我们的嵌入器将我们的查询转换为嵌入。接下来，我们将定义一些搜索参数。再次，`L2`代表欧几里得距离，而`nprobe`参数表示要搜索的簇数量。在我们的情况下，在128个我们设置的簇中，我们将搜索与我们的查询嵌入最近的10个簇。最后，在实际搜索中，我们将结果限制为三个最佳匹配，并返回与我们的查询一起的元数据字段：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Before conducting a search, you need to load the data into memory.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 在进行搜索之前，你需要将数据加载到内存中。'
- en: '#2 Makes a query'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 进行查询'
- en: '#3 The number of clusters to search'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 搜索的簇数量'
- en: 'You can see that for our query, the search results are returning strong candidates
    from our dataset:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，对于我们的查询，搜索结果正在返回来自我们数据集的强候选者：
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now that we have our VectorDB set up with data loaded in, let’s update our API
    to retrieve results from our RAG system and inject the context into our prompts.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置了我们的VectorDB并加载了数据，让我们更新我们的API以从我们的RAG系统中检索结果并将上下文注入到我们的提示中。
- en: 10.2.3 Using RAG
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.3 使用RAG
- en: In this section, we will update listing 10.1 to include our retrieval code.
    In listing 10.3, we won’t be repeating everything we did before, in the interests
    of time and space, but will simply be showing the new parts to add. In the repo
    accompanying this book, you’ll be able to find the code that puts everything together
    if you are struggling to understand which piece goes where. First, near the top
    of the script, we’ll need to add our imports, connect to our Milvus service, and
    load our embedding model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将更新列表10.1以包含我们的检索代码。在列表10.3中，我们不会重复之前所做的所有事情，考虑到时间和空间，我们只需展示需要添加的新部分。在伴随本书的仓库中，如果你在理解哪些部分应该放在哪里时遇到困难，你将能够找到将一切组合在一起的代码。首先，在脚本接近顶部的地方，我们需要添加我们的导入，连接到我们的Milvus服务，并加载我们的嵌入模型。
- en: Listing 10.3 Adding RAG to our API
  id: totrans-66
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.3 将RAG添加到我们的API
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#1 Connects to Milvus'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 连接到Milvus'
- en: '#2 Loads our embedding model'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 加载我们的嵌入模型'
- en: 'Next, we’ll add some convenience functions, including a token counter and a
    FastAPI lifecycle, to ensure we load and release our Milvus collection from memory.
    Since we are adding a lifecycle, be sure to update the FastAPI call:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将添加一些便利函数，包括一个标记计数器和FastAPI生命周期，以确保我们加载和释放我们的Milvus集合从内存。由于我们添加了一个生命周期，请确保更新FastAPI调用：
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 Load collection on startup'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 启动时加载集合'
- en: '#2 Releases collection from memory on shutdown'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 关闭时从内存中释放集合'
- en: '#3 Runs FastAPI'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 运行FastAPI'
- en: Now that we have all that set up, we can get to the good part—running the query
    and updating our prompt in our `generate` endpoint. The first part should look
    familiar since we just did it. We’ll encode the user’s prompt and search our collection
    for the nearest neighbors. We’re using all the same search parameters as before,
    except one. We increase our limit from `3` to `5` to potentially add more examples
    to our prompt. Next, we take those results and format them into a few-shot prompt
    example dataset. Then we create our instruction prompt and format the user’s input.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置好了一切，我们可以进入下一步——运行查询并更新我们的`generate`端点的提示。第一部分应该看起来很熟悉，因为我们刚刚做过。我们将编码用户的提示并在我们的集合中搜索最近的邻居。我们使用与之前相同的所有搜索参数，除了一个。我们将限制从`3`增加到`5`，以便可能将更多示例添加到我们的提示中。接下来，我们将这些结果格式化为几个提示示例数据集。然后我们创建指令提示并格式化用户的输入。
- en: 'We are almost at the point where we can combine our instruction, examples,
    and user prompt; however, we need to ensure our examples don’t take up too much
    space. Using a `for` loop utilizing our token counter, we’ll filter out any examples
    that don’t fit our context window. With that, we can now combine everything to
    create our final prompt for our DeciCoder model:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎到了可以结合我们的指令、示例和用户提示的阶段；然而，我们需要确保我们的示例不会占用太多空间。使用一个利用我们的标记计数器的`for`循环，我们将过滤掉任何不符合我们上下文窗口的示例。有了这个，我们现在可以结合所有内容，为我们的DeciCoder模型创建最终的提示：
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#1 Inside the generate function'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 生成函数内部'
- en: '#2 Makes a query'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 进行查询'
- en: 'Alright! Now that we’ve made our updates to our API, let’s start it up and
    test it again like we did before. We’ll send another request to the server to
    make sure everything is still working:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 好的！现在我们已经更新了我们的API，让我们像之前一样启动并测试它。我们将向服务器发送另一个请求以确保一切仍然正常工作：
- en: '[PRE12]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This time we got a response of `print(“Hello,` `World!”)`, which is slightly
    worse than our previous response, but it’s still in the same vein, so there’s
    nothing to be worried about. You’ll likely get something similar. And that concludes
    setting up our LLM service with a RAG system for customization. All we need to
    do now is call it.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这次我们得到了一个`print(“Hello,` `World!”)`的响应，这比我们之前的响应略差，但仍然属于同一类型，所以不必担心。你可能会得到类似的结果。这样，我们就完成了使用RAG系统进行定制的LLM服务的设置。我们现在需要做的就是调用它。
- en: 10.3 Build the VS Code extension
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 构建VS Code扩展
- en: 'Alright, now all we need to do is build our VS Code extension. VS Code extensions
    are written primarily in TypeScript or JavaScript (JS). If you aren’t familiar
    with these languages, don’t worry; we’ll walk you through it. To get started,
    you’ll need Node and npm installed. Node is the JS interpreter, and npm is like
    pip for JS. You can add these tools in multiple ways, but we recommend first installing
    nvm or another node version manager. It’s also a good idea at this time to update
    your VS Code (or install it if you haven’t already). Updating your editor will
    help you avoid many problems, so be sure to do it. From here, we can install the
    VS Code extension template generator:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们只需要构建我们的VS Code扩展。VS Code扩展主要用TypeScript或JavaScript（JS）编写。如果您不熟悉这些语言，不要担心；我们会引导您完成。要开始，您需要安装Node和npm。Node是JS解释器，npm类似于JS的pip。您可以通过多种方式添加这些工具，但我们建议首先安装nvm或其他节点版本管理器。此时更新您的VS
    Code（如果您还没有安装，请安装它）也是一个好主意。更新您的编辑器将帮助您避免许多问题，所以请确保这样做。从这里，我们可以安装VS Code扩展模板生成器：
- en: '[PRE13]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'NOTE  You can find the instructions to install nvm here: [https://mng.bz/gAv8](https://mng.bz/gAv8).
    Then simply run `nvm` `install` `node` to install the latest versions of Node
    and npm.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您可以在以下位置找到安装nvm的说明：[https://mng.bz/gAv8](https://mng.bz/gAv8)。然后只需运行`nvm`
    `install` `node`来安装最新版本的Node和npm。
- en: The template generator will create a basic “Hello World” project repo for us
    that we can use as scaffolding to build off of. To run the generator, use
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 模板生成器将为我们创建一个基本的“Hello World”项目仓库，我们可以用它作为构建的基础。要运行生成器，请使用
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This command will start a walkthrough in your terminal, where you’ll be greeted
    by what appears to us to be an ASCII art representation of a Canadian Mountie
    who will ask you several questions to customize the scaffolding being generated.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将在您的终端中启动一个向导，您将看到一个看似ASCII艺术形式的加拿大骑警形象，他会问您几个问题以定制正在生成的脚手架。
- en: In figure 10.1, you can see an example with our selected answers to the walkthrough
    questions. Guiding you through the questions quickly, we’ll create a new JavaScript
    extension, which you can name whatever you like. We chose `llm_coding_ copilot`,
    if you’d like to follow along with us. For the identifier, press Enter, and it
    will hyphenate the name you chose. Give it a description; anything will do. No,
    we don’t want to enable type-checking. You can choose whether to initialize the
    project as a new Git repository. We chose No, since we are already working in
    one. Lastly, we’ll use npm.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在图10.1中，您可以看到我们对向导问题的选择示例。快速引导您通过问题，我们将创建一个新的JavaScript扩展，您可以根据喜好命名。我们选择了`llm_coding_
    copilot`，如果您想跟随我们的话。对于标识符，按Enter键，它将自动为您选择的名称添加连字符。给它一个描述；任何内容都可以。不，我们不想启用类型检查。您可以选择是否将项目初始化为新的Git仓库。我们选择了“否”，因为我们已经在其中一个仓库中工作了。最后，我们将使用npm。
- en: '![figure](../Images/10-1.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/10-1.png)'
- en: Figure 10.1 The VS Code extension generator with example inputs
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.1 VS Code扩展生成器示例输入
- en: 'When it’s done, it will generate a project repository with all the files we
    need. If you look at figure 10.2, you can see an example of a built project repository.
    It has several different configuration files, which you are welcome to familiarize
    yourself with, but we only care about two of these files: the package.json file
    where we define the extension manifest, which tells VS Code how to use the extension
    we will build to (well, actually extend VS Code), and the extension.js file, which
    holds the actual extension code.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，它将生成一个包含我们所需所有文件的项目仓库。如果你查看图 10.2，你可以看到一个已构建项目仓库的示例。它有几个不同的配置文件，你可以熟悉一下，但我们只关心其中的两个文件：定义扩展清单的
    package.json 文件，它告诉 VS Code 如何使用我们将构建的扩展（实际上，是扩展 VS Code），以及包含实际扩展代码的 extension.js
    文件。
- en: '![figure](../Images/10-2.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/10-2.png)'
- en: Figure 10.2 Example directory structure created with the VS Code extension generator
  id: totrans-95
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 10.2 使用 VS Code 扩展生成器创建的示例目录结构
- en: In the package.json file, the boilerplate gets us almost all the way there,
    but the `activationEvents` field is currently empty and needs to be set. This
    field tells VS Code when to start up our extension. Extensions typically aren’t
    loaded when you open VS Code, which helps keep it lightweight. If it’s not set,
    the extension will only be loaded when the user opens it, which can be a pain.
    A smart strategy typically is to load the extension only when the user opens a
    file of the type we care about—for example, if we were building a Python-specific
    extension, it would only load when a .py file is opened.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在 package.json 文件中，模板代码几乎带我们完成了大部分工作，但 `activationEvents` 字段目前是空的，需要设置。这个字段告诉
    VS Code 何时启动我们的扩展。通常情况下，当你打开 VS Code 时，扩展并不会被加载，这有助于保持其轻量级。如果没有设置，扩展只有在用户打开它时才会被加载，这可能会很麻烦。一个聪明的策略通常是只在用户打开我们关心的文件类型时加载扩展——例如，如果我们正在构建一个针对
    Python 的特定扩展，它只有在打开 .py 文件时才会加载。
- en: 'We will use the `"onCommand:editor.action.inlineSuggest.trigger"` event trigger.
    This trigger fires when a user manually asks for an inline suggestion. It typically
    fires whenever a user stops typing, but we want more control over the process
    to avoid sending unnecessary requests to our LLM service. There’s just one problem:
    VS Code doesn’t have a default shortcut key for users to manually do this! Thankfully,
    we can set this too by adding a `"keybindings"` field to the `"contributes"` section.
    We will set it to the keybindings of `Alt+S`. We are using `S` for “suggestion”
    to be memorable; this keybinding should be available unless another extension
    is using it. Users can always customize their keybindings regardless. You can
    see the finished package.json file in the following listing. It should look very
    similar to what we started with from the scaffolding.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `"onCommand:editor.action.inlineSuggest.trigger"` 事件触发器。这个触发器在用户手动请求内联建议时触发。它通常在用户停止输入时触发，但我们希望对过程有更多的控制，以避免向我们的
    LLM 服务发送不必要的请求。只有一个问题：VS Code 没有为用户手动执行此操作提供默认快捷键！幸运的是，我们也可以通过在 `"contributes"`
    部分添加 `"keybindings"` 字段来设置它。我们将将其设置为 `Alt+S` 的快捷键。我们使用 `S` 代表“建议”以便于记忆；这个快捷键应该可用，除非另一个扩展正在使用它。用户始终可以自定义他们的快捷键。你可以在下面的列表中看到完成的
    package.json 文件。它应该与我们从脚手架开始时非常相似。
- en: Listing 10.4 Extension manifest for our coding copilot
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.4 我们编码同伴的扩展清单
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now that we have an extension manifest file, let’s go ahead and test it. From
    your project repo in VS Code, you can press F5 to compile your extension and launch
    a new VS Code Extension Development Host window with your extension installed.
    In the new window, you should be able to press Alt+S to trigger an inline suggestion.
    If everything is working, then you’ll see a console log in the original window
    that states, `Congratulations,` `your` `extension` `"llm-coding-copilot"` `is`
    `now` `active!`, as shown in figure 10.3.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了扩展清单文件，让我们继续测试它。在你的 VS Code 项目仓库中，你可以按 F5 编译你的扩展并启动一个新的带有你的扩展的 VS Code
    扩展开发主机窗口。在新窗口中，你应该能够按 Alt+S 触发内联建议。如果一切正常，那么你将在原始窗口中看到一个控制台日志，显示“恭喜你，你的扩展`llm-coding-copilot`现在已激活！”，如图
    10.3 所示。
- en: '![figure](../Images/10-3.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/10-3.png)'
- en: Figure 10.3 Example console of successfully activating our VS Code extension
  id: totrans-102
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 10.3 成功激活我们的 VS Code 扩展的示例控制台
- en: Alright, not bad! We can now both run our extension and activate it, as well
    as capture the logs, which is helpful for debugging. Now all we need to do is
    build it, so let’s turn our attention to the extension.js file.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，不错！我们现在可以运行我们的扩展并激活它，同时捕获日志，这对于调试很有帮助。现在我们只需要构建它，让我们将注意力转向 extension.js 文件。
- en: At this point, things get a bit tricky to explain. Even for our readers who
    are familiar with JavaScript, it’s unlikely many are familiar with the VS Code
    API ([https://mng.bz/eVoG](https://mng.bz/eVoG)). Before we get into the weeds,
    let’s remind ourselves what we are building. This will be an extension in VS Code
    that will give us coding suggestions. We already have an LLM trained on code data
    behind an API that is ready for us. We have a dataset in a RAG system loaded to
    give context and improve results, and we have our prompt crafted. All we need
    to do is build the extension that will call our API service. But we also want
    something that allows users an easy way to interact with our model that gives
    us lots of control. We will do this by allowing a user to highlight portions of
    the code, and we’ll send that when our shortcut keybindings, Alt+S, are pressed.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 到这一点，事情变得有点难以解释。即使对于熟悉 JavaScript 的读者来说，也很少有人熟悉 VS Code API ([https://mng.bz/eVoG](https://mng.bz/eVoG))。在我们深入之前，让我们提醒自己我们正在构建什么。这将是一个
    VS Code 扩展，它将为我们提供编码建议。我们已经在 API 后面训练了一个 LLM，该 API 已准备好供我们使用。我们有一个在 RAG 系统中加载的数据集，用于提供上下文并改进结果，并且我们已经精心制作了提示。我们只需要构建一个调用我们的
    API 服务的扩展。但我们还希望有一种允许用户以简单方式与我们的模型交互的方法，同时给我们提供很多控制。我们将通过允许用户突出显示代码的一部分来实现这一点，当按下快捷键绑定
    Alt+S 时，我们将发送这部分代码。
- en: Let’s take a look at the template extension.js file that the generator created
    for us. Listing 10.5 shows us the template with the comments changed for simplicity.
    It simply loads the vscode library and defines `activate` and `deactivate` functions
    that run when you start the extension. The `activate` function demonstrates how
    to create and register a new command, but we won’t be using it. Instead of a command,
    we will create an inline suggestion provider and register it.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看生成器为我们创建的模板 extension.js 文件。列表 10.5 显示了经过简化注释的模板。它只是加载了 vscode 库，并定义了在启动扩展时运行的
    `activate` 和 `deactivate` 函数。`activate` 函数演示了如何创建和注册一个新命令，但我们将不会使用它。我们将创建一个内联建议提供者并注册它，而不是命令。
- en: Listing 10.5 Boilerplate extension.js from template
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.5 模板中的 boilerplate extension.js 文件
- en: '[PRE16]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Since we won’t be using commands, let’s take a look at what we will be using
    instead, an inline suggestion provider. This provider will add our suggestions
    as ghost text where the cursor is. This allows the user to preview what is generated
    and then accept the suggestion with a tab or reject it with another action. Essentially,
    it is doing all the heavy lifting for the user interface in the code completion
    extension we are building.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不会使用命令，让我们看看我们将使用什么，一个内联建议提供者。这个提供者将把我们的建议作为光标处的幽灵文本添加。这使用户能够预览生成的内容，然后使用制表符接受建议或通过其他操作拒绝它。本质上，它正在为我们构建的代码完成扩展中的用户界面做所有繁重的工作。
- en: In listing 10.6, we show you how to create and register a provider, which returns
    inline completion items. It will be an array of potential items the user may cycle
    through to select the best option, but for our extension, we’ll keep things simple
    by only returning one suggestion. The provider takes in several arguments that
    are automatically passed in, like the document the inline suggestion is requested
    for, the position of the user’s cursor, context on how the provider was called
    (manually or automatically), and a cancel token. Lastly, we’ll register the provider,
    telling VS Code which types of documents to call it for; here, we give examples
    of registering it to only Python files or adding it to everything.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 10.6 中，我们向您展示如何创建和注册一个提供者，该提供者返回内联完成项。它将是一个用户可能循环选择最佳选项的潜在项数组，但为了我们的扩展，我们将保持简单，只返回一个建议。提供者接收几个自动传入的参数，例如请求内联建议的文档、用户光标的位置、提供者被调用的上下文（手动或自动）以及一个取消令牌。最后，我们将注册提供者，告诉
    VS Code 为哪些类型的文档调用它；在这里，我们给出将其注册到仅 Python 文件或添加到所有文件的示例。
- en: Listing 10.6 Example inline suggestion provider
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.6 示例内联建议提供者
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Now that we have a provider, we need a way to grab the user’s highlighted text
    to send it to the LLM service and ensure our provider only runs when manually
    triggered via the keybindings, not automatically, which happens every time the
    user stops typing. In listing 10.7, we add this piece to the equation inside our
    provider.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: First, we grab the editor window and anything selected or highlighted. Then
    we determine whether the provider was called because it was automatically or manually
    triggered. Next, we do a little trick for a better user experience. If our users
    highlight their code backward to forward, the cursor will be at the front of their
    code, and our code suggestion won’t be displayed. So we’ll re-highlight the selection,
    which will put the cursor at the end, and retrigger the inline suggestion. Thankfully,
    this retriggering will also be counted as a manual trigger. Lastly, if everything
    is in order—the inline suggestion was called manually, we have highlighted text,
    and our cursor is in the right location—then we’ll go ahead and start the process
    of using our LLM code copilot by grabbing the highlighted text from the selection.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Listing 10.7 Working with the VS Code API
  id: totrans-114
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Alright! Now that we have all the VS Code–specific code out of the way, we just
    need to make a request to our LLM service. This action should feel like familiar
    territory at this point; in fact, we’ll use the code we’ve already discussed in
    chapter 7\. Nothing to fear here! In the next listing, we finish the provider
    by grabbing the highlighted text and using an async `fetch` request to send it
    to our API. Then we take the response and return it to the user.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Listing 10.8 Sending a request to our coding copilot
  id: totrans-117
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now that all the pieces are in place, let’s see it in action. Press F5 again
    to compile your extension anew, launching another VS Code Extension Development
    Host window with our updated extension installed. Create a new Python file with
    a .py extension, and start typing out some code. When you’re ready, highlight
    the portion you’d like to get your copilot’s help with, and press Alt+S to get
    a suggestion. After a little bit, you should see some ghost text pop up with the
    copilot’s suggestion. If you like it, press Tab to accept. Figure 10.4 shows an
    example of our VS Code extension in action.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/10-4.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 Example console of successfully activating our VS Code extension
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Congratulations! You did it! You created your very own coding copilot! It runs
    on your own data and is completely local—a pretty big achievement if you started
    this book knowing nothing about LLMs. In the next section, we’ll talk about next
    steps and some lessons learned from this project.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 10.4 Lessons learned and next steps
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have working code, we could call it a day. However, our project
    is far from completed; there’s still so much we could do with it! To begin, the
    results don’t appear to be all that great. Looking back at figure 10.4, the generated
    code doesn’t reverse a linked list but reverses a regular ol’ list. That’s not
    what we wanted. What are some things we could do to improve it?
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了可以工作的代码，我们可以把它叫作一天的工作。然而，我们的项目还远未完成；我们还有许多可以做的事情！首先，结果看起来并不那么好。回顾一下图10.4，生成的代码并没有反转链表，而是反转了一个普通的列表。这不是我们想要的。我们能做些什么来改进它呢？
- en: Well, for starters, remember our test “Hello World” functions we sent to the
    API to test it out? It seemed we got better results when using the model before
    we added RAG. For fun, let’s spin up our old API with RAG disabled and see what
    we get while using our VS Code extension. Figure 10.5 shows an example result
    of using this API.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，首先，记得我们发送给API测试的“Hello World”函数吗？看起来在我们添加RAG之前使用模型时，我们得到了更好的结果。为了好玩，让我们启动我们旧的API，禁用RAG，看看使用我们的VS
    Code扩展时我们会得到什么。图10.5显示了使用此API的一个示例结果。
- en: '![figure](../Images/10-5.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/10-5.png)'
- en: Figure 10.5 Results of our extension using DeciCoder without RAG
  id: totrans-127
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.5 使用DeciCoder（无RAG）的扩展结果
- en: Wow! That code looks way better! It actually reverses a linked list and is already
    formatted in such a way you wouldn’t even need to edit or format it. What’s going
    on here? Aren’t models supposed to generate better results when we give them a
    few examples of how we want them to behave? Maybe our RAG system isn’t finding
    very good examples. Let’s do some digging and take a look at the prompt generated
    from our RAG system.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！这段代码看起来好多了！它实际上反转了链表，并且已经格式化得很好，以至于你甚至不需要编辑或格式化它。这里发生了什么？模型不是应该在我们给出它们一些我们希望它们如何表现示例后生成更好的结果吗？也许我们的RAG系统没有找到很好的示例。让我们深入挖掘，看看我们的RAG系统生成的提示信息。
- en: MA**Instruction:** What is the most efficient way to reverse a singly linked
    list in 7 lines of Python code?
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: MA**指令**：用7行Python代码反转单链表的最有效方法是什么？
- en: '![chatGpt](../Images/chatGpt.png)**Output:** # Definition for singly-linked
    list.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![chatGpt](../Images/chatGpt.png)**输出**：# 单链表的定义。'
- en: '[PRE20]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: MA**Instruction:** What is the most efficient way to reverse a linked list in
    Python?
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: MA**指令**：在Python中反转链表的最有效方法是什么？
- en: '**![chatGpt](../Images/chatGpt.png)**Output:****'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**![chatGpt](../Images/chatGpt.png)**输出:****'
- en: '[PRE21]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'MA**Instruction:** def reverse_linked_list(list):'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 'MA**指令**：def reverse_linked_list(list):'
- en: '"""Reverses a linked list"""'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '```反转链表```'
- en: '**![chatGpt](../Images/chatGpt.png)**Output:****'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**![chatGpt](../Images/chatGpt.png)**输出:****'
- en: Wow! Those examples seem to be spot on! What exactly could be going on then?
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！这些例子看起来非常准确！那么到底可能发生了什么呢？
- en: Well, first, take a look at the prompt again. The example instructions from
    our dataset are tasks in plain English, but the prompt our users will be sending
    is half-written code. We’d likely get better results if our users wrote in plain
    English. Of course, that’s likely a bit of an awkward experience when our users
    are coding in an editor. It’s more natural to write code and ask for help on the
    hard parts.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，首先，再看看提示信息。我们数据集中的示例指令是用普通英语表述的任务，但用户将要发送的提示信息是半写好的代码。如果我们的用户用普通英语来写，我们可能会得到更好的结果。当然，当我们的用户在编辑器中编码时，这可能会是一种有点尴尬的经历。在难以理解的部分写代码并寻求帮助会更自然。
- en: Second, remember our notes on how DeciCoder was trained? It was trained to beat
    the HumanEval dataset, so it’s really good at taking code as input and generating
    code as output. This makes it good at the task from the get-go without the need
    for prompt tuning. More importantly, it hasn’t been instruction tuned! It’s likely
    a bit confused when it sees our few-shot examples since it didn’t see input like
    that during its training. Being a much smaller model trained for a specific purpose,
    it’s just not as good at generalizing to new tasks.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，记得我们关于DeciCoder训练的笔记吗？它是被训练来击败HumanEval数据集的，所以它非常擅长将代码作为输入并生成代码作为输出。这使得它从一开始就非常适合这项任务，而无需进行提示调整。更重要的是，它还没有被指令调整过！当它看到我们的少量示例时可能会有些困惑，因为它在训练期间没有看到过这样的输入。作为一个为特定目的训练的小型模型，它并不擅长泛化到新的任务。
- en: There are a few key takeaways to highlight from this. First and foremost, while
    prompt tuning is a powerful technique to customize an LLM for new tasks, it is
    still limited in what you can achieve with it alone, even when using a RAG system
    to give highly relevant examples. One has to consider how the model was trained
    or finetuned and what data it was exposed to. In addition, it’s important to consider
    how a user will interact with the model to make sure you are crafting your prompts
    correctly.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个例子中，有几个关键点需要强调。首先，虽然提示调整是一种强大的技术，可以用于为新任务定制 LLM，但它本身所能达到的成就仍然有限，即使在使用 RAG
    系统提供高度相关示例的情况下。必须考虑模型是如何训练或微调的，以及它接触到了哪些数据。此外，考虑用户如何与模型交互，以确保您正确地构建了提示。
- en: So what are some next steps you can try to improve the results? At this stage,
    things appear to be mostly working, so the first thing we might try is adjusting
    the prompt in our RAG system. It doesn’t appear that the instruction data written
    in plain English is very useful to our model, so we could simply try giving the
    model example code and see if that improves the results. Next, we could try to
    finetune the model to take instruction datasets or just look for another model
    entirely.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，您可以尝试哪些下一步来提高结果？在这个阶段，事情似乎大多已经正常工作，所以我们可能会尝试的第一件事是调整我们的 RAG 系统中的提示。看起来用普通英语编写的指令数据对我们的模型并没有很大帮助，所以我们可以简单地尝试给模型提供示例代码，看看是否可以提高结果。接下来，我们可以尝试微调模型以采用指令数据集，或者完全寻找另一个模型。
- en: Beyond just making our app work better, there are likely many next steps to
    customize this project. For example, we could create a collection in Milvus with
    our own code dataset. This way, we could inject the context of relevant code in
    our code base into our prompt. Our model wouldn’t just be good at writing general
    Python code but also code specific to the organization we work for. If we go down
    that route, we might as well deploy our API and Milvus database to a production
    server where we could serve it for other engineers and data scientists in the
    company.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 除了让我们的应用程序工作得更好之外，可能还有很多下一步可以定制这个项目。例如，我们可以在 Milvus 中创建一个包含我们自己的代码数据集的集合。这样，我们就可以将相关代码的上下文注入到我们的代码库中的提示中。我们的模型不仅擅长编写通用的
    Python 代码，还能编写针对我们工作的组织的特定代码。如果我们选择这条路，我们不妨将我们的 API 和 Milvus 数据库部署到生产服务器上，这样我们就可以为公司的其他工程师和数据科学家提供服务。
- en: Alternatively, we could abandon the customization idea and use DeciCoder alone
    since it appears to already give great results. No customization needed. If we
    do that, it would be worth compiling the model to GGUF format and running it via
    the JavaScript SDK directly in the extension. Doing so would allow us to encapsulate
    all the code into a single place and make it easier to distribute and share.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以放弃定制化想法，仅使用 DeciCoder，因为它似乎已经给出了很好的结果。无需定制。如果我们这样做，那么将模型编译为 GGUF 格式并通过
    JavaScript SDK 直接在扩展中运行它将是有价值的。这样做将允许我们将所有代码封装在一个地方，并使其更容易分发和共享。
- en: Lastly, you might consider publishing the extension and sharing it with the
    community. Currently, the project isn’t ready to be shared, since we are running
    our model and RAG system locally, but if you are interested, you can find the
    official instructions online at [https://mng.bz/GNZA](https://mng.bz/GNZA). It
    goes over everything from obtaining API keys, to packaging, publishing, and even
    becoming a verified publisher.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可能考虑发布扩展并与社区分享。目前，该项目尚未准备好分享，因为我们正在本地运行我们的模型和 RAG 系统，但如果您感兴趣，您可以在网上找到官方说明，网址为
    [https://mng.bz/GNZA](https://mng.bz/GNZA)。它涵盖了从获取 API 密钥到打包、发布，甚至成为认证发布者的所有内容。
- en: Summary
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: DeciCoder is a small but mighty model designed for coding tasks in Python, JavaScript,
    and Java.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeciCoder 是一个专为 Python、JavaScript 和 Java 中的编码任务设计的小巧但强大的模型。
- en: Milvus is a powerful open source VectorDB that can scale to meet your needs.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Milvus 是一个强大的开源 VectorDB，可以扩展以满足您的需求。
- en: Your dataset is key to making your RAG system work, so spend the time cleaning
    and preparing it properly.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的数据集对于使您的 RAG 系统正常工作至关重要，因此请花时间对其进行清理和适当准备。
- en: Visual Studio Code is a popular editor that makes it easy to build extensions.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Visual Studio Code 是一款流行的编辑器，它使得构建扩展变得容易。
- en: Just throwing examples and data at your model won’t make it generate better
    results, even when they are carefully curated.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅向您的模型抛出示例和数据，即使它们被精心策划，也不会使其生成更好的结果。
- en: Build prompts in a way that accounts for the model’s training methodology and
    data to maximize results.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以一种考虑到模型训练方法和数据的方式来构建提示，以最大化结果。
- en: '[[1]](#footnote-source-1) D. Ramel, “Stack Overflow dev survey: VS Code, Visual
    Studio still top IDEs 5 years running,” Visual Studio Magazine, June 28, 2023,
    [https://mng.bz/zn86](https://mng.bz/zn86).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[[1]](#footnote-source-1) D. Ramel, “Stack Overflow开发者调查：VS Code和Visual Studio连续5年位居顶级IDE，”
    Visual Studio Magazine，2023年6月28日，[https://mng.bz/zn86](https://mng.bz/zn86).'
- en: '[[2]](#footnote-source-2) Deci, “Introducing DeciCoder: The new gold standard
    in efficient and accurate code generation,” August 15, 2023, [https://mng.bz/yo8o](https://mng.bz/yo8o).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[[2]](#footnote-source-2) Deci, “推出DeciCoder：高效且精确的代码生成新标准，” 2023年8月15日，[https://mng.bz/yo8o](https://mng.bz/yo8o).'
