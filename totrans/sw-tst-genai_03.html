<html><head></head><body>
<div class="calibre1" id="sbo-rt-content"><h1 class="tochead" id="heading_id_2">3 <a id="idTextAnchor000"/>Artificial intelligence, automation, and testing</h1>
<p class="co-summary-head">This chapter covers<a id="idIndexMarker000"/><a id="marker-41"/><a id="idIndexMarker001"/></p>
<ul class="calibre5">
<li class="co-summary-bullet">The value of good testing</li>
<li class="co-summary-bullet">How tools aid in testing</li>
<li class="co-summary-bullet">How to identify when AI tools could be of use in testing</li>
</ul>
<p class="body">Before we delve deeper into the use of large language models (LLMs) in testing, let’s ask ourselves the following questions:</p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">What is the purpose and value of testing?</p>
</li>
<li class="fm-list-bullet">
<p class="list">How can tooling help us?</p>
</li>
<li class="fm-list-bullet">
<p class="list">When is it appropriate to use AI tools?</p>
</li>
</ul>
<p class="body">It may seem that asking these fundamental questions is unnecessary. But if you are someone who sees testing merely as a confirmatory exercise, as in executing test cases to confirm a requirement is correct, then your mileage from the subsequent chapters will be limited. Understanding the value and performance of testing is critical for determining how tools can be used effectively. Thus, in this chapter, we’re going to explore why a deeper understanding of testing can help us utilize tools. That said, if you are someone who already has that deep understanding, feel free to skim through this chapter and move on. For the rest of us, let’s go back to square one by asking why we test.</p>
<h2 class="fm-head" id="heading_id_3">3.1 The value of testing</h2>
<p class="body">To help us appreciate having a clear understanding of why we need testing in software development, let’s return to the common perspective that testing is a confirmatory exercise. By this, we mean that testing is viewed as something done to confirm the following conditions:<a id="idIndexMarker002"/><a id="marker-42"/></p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">Written requirements have been met.</p>
</li>
<li class="fm-list-bullet">
<p class="list">All critical paths have been covered in a system.</p>
</li>
<li class="fm-list-bullet">
<p class="list">The system works as expected.</p>
</li>
</ul>
<p class="body">Teams that hold this perspective tend to overly rely on the use of test cases/scripts that contain explicit instructions for a human, or machine, to follow and confirm whether an expected outcome has been met. The problem with this mindset and approach is less that it’s utilizing test scripts and more that it only uses test scripts and nothing else, which results in edge cases being missed, more complex bugs or behavior left untested, and generally in a limited understanding of how our products behave. Many biases come from an overreliance on test scripts, but if we bring it back to the use of LLMs in testing, then it limits our appreciation of how these tools can help us. When tools such as ChatGPT grew in popularity, a large majority of demonstrations and debates around the use of LLMs in testing focused on one thing: test scripts. People would demonstrate how LLMs could generate test scripts to be executed manually by either a human or a test automation tool.</p>
<p class="body">Although initially these might have had some use, the options for what else could be done with LLMs to help testing began to dry out. On the surface, this appears to be a limitation of the tooling in question, but instead, the real problem is the limited idea of what testing is and how it can help. So, if we are to expand our use of LLMs in testing, we have to first expand our understanding of what testing is and how it works.</p>
<h3 class="fm-head1" id="heading_id_4">3.1.1 A different way of thinking about testing</h3>
<p class="body">To help us establish a deeper understanding, let’s explore a model of testing that I use to define what I believe testing is for and how it helps, which is shown in figure 3.1.<a id="idIndexMarker003"/></p>
<p class="body">The model, based on one created by James Lyndsay in his paper “Exploration and Strategy” (<a class="url" href="https://mng.bz/mRdn">https://mng.bz/mRdn</a>), consists of two circles. The left circle represents imagination, or what we <i class="fm-italics">want</i> in a product, and the right circle represents implementation, or what we <i class="fm-italics">have</i> in a product. The purpose of testing is to learn as much as possible about what’s going on in each of these circles by carrying out testing activities. The more we test in these two circles, the more we learn. We can then</p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">Discover potential problems that might affect the quality</p>
</li>
<li class="fm-list-bullet">
<p class="list">Overlap these two circles of information, ensuring we trust we are building the intended product</p>
</li>
</ul>
<div class="figure">
<p class="figure1"><img alt="" class="calibre11" src="../../OEBPS/Images/CH03_F01_Winteringham2.png"/></p>
<p class="figurecaption">Figure 3.1 A model that helps describe the value and purpose of testing</p>
</div>
<p class="body">To help describe this principle further, let’s look at an example in which a team is delivering a hypothetical search feature that we want to ensure is delivered to a high degree of quality.</p>
<p class="fm-head2">Imagination</p>
<p class="body">The Imagination circle represents what it is that we want from our product, and that includes expectations that are both explicit and implicit. So in this circle, our testing is focused on learning as much as possible about those explicit and implicit expectations. By doing so, we not only learn what has been explicitly stated in writing or verbally shared, but also dig down into the details and remove ambiguity over terms and ideas. Let’s say a representative of the business or a user, such as a product owner, has shared this requirement with their team: “Search results are to be ordered by relevance.”<a id="marker-43"/><a id="idIndexMarker004"/></p>
<p class="body">The explicit information shared here tells us that the product owner wants search results ordered by relevance. However, a lot of implied information can be uncovered by testing the ideas and concepts behind what is being asked. This might come in the form of a series of questions, such as</p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">What is meant by relevant results?</p>
</li>
<li class="fm-list-bullet">
<p class="list">Who benefits from the results?</p>
</li>
<li class="fm-list-bullet">
<p class="list">What information is shared?</p>
</li>
<li class="fm-list-bullet">
<p class="list">How do we order results by relevancy?</p>
</li>
<li class="fm-list-bullet">
<p class="list">What data should we use?</p>
</li>
</ul>
<p class="body">By asking these questions, we gain a broader perspective of what is wanted, remove any misunderstandings and assumptions in our team’s thinking, and identify potential risks that could affect those expectations. If we know more about what we are being asked to build, then we’re more likely to build the right thing the first time.</p>
<p class="fm-head2">Implementation</p>
<p class="body">By testing the imagination, we get a stronger sense of what we are being asked to build. But, just because we might know what to build doesn’t mean we end up with a product that matches our expectations. This is why we also test the implementation to learn<a id="idIndexMarker005"/></p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">Whether the product matches our expectations</p>
</li>
<li class="fm-list-bullet">
<p class="list">How the product might not match our expectations</p>
</li>
</ul>
<p class="body">Both goals are equally important. We want to ensure that we have built the right thing, but there will always be side effects, such as unintended behavior, vulnerabilities, missed expectations, and downright weirdness that might appear in our products. With our search results example, we could not only test whether the feature delivers results in the relevant order but also ask</p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">What if I use different search terms?</p>
</li>
<li class="fm-list-bullet">
<p class="list">What if the relevant results don’t match the behavior of other search tools?</p>
</li>
<li class="fm-list-bullet">
<p class="list">What if part of the service is down when I search?</p>
</li>
<li class="fm-list-bullet">
<p class="list">What if I request results 1000 times in less than 5 seconds?</p>
</li>
<li class="fm-list-bullet">
<p class="list">What happens if there are no results?</p>
</li>
</ul>
<p class="body">By exploring beyond our expectations, we become more aware of what is going on in our product—warts and all. This ensures we don’t end up making incorrect assumptions about how our product behaves and releasing a poor-quality product. It also means that if we find unexpected behavior, we have the choice to attempt to remove or readjust our expectations.<a id="idIndexMarker006"/></p>
<h3 class="fm-head1" id="heading_id_5">3.1.2 A holistic approach to testing</h3>
<p class="body">The described model of testing the imagination and implementation demonstrates that the testing goes beyond a simple confirmation of expectations and lays out a more holistic approach to testing. By implementing different activities that focus on the imagination and implementation spaces, through the testing we execute, we learn more about what we want to build and what we have built. The more we learn in these two areas, the more they align with one another. And the more they align, the more accurate our perception of quality becomes.<a id="marker-44"/><a id="idIndexMarker007"/></p>
<p class="body">A team that is well-informed about their work has a better understanding of their product’s quality. We are then also better equipped to decide what steps to take to improve quality. This enables us to focus our attention on specific risks, make changes in our product to align with users’ expectations or determine what problems we want to invest time in to fix and which to leave alone. This is the value of good testing—to help teams get into a position where they can make these informed decisions and feel confident in the steps they are taking to develop a high-quality product.</p>
<p class="body">To help us better appreciate this model, let’s consider a sample context in which testing is required. For our example, we are responsible for the delivery of a fast-food ordering system. Users log on, find the restaurant they want to order from, place their order (which is sent to the restaurant), and then track the delivery of their order from within the product. A product like this one would need to be highly available, easy to use, and secure. So, to deliver a high-quality product, we might need to utilize different testing activities to focus on different types of risks, as shown in figure 3.2.</p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre12" src="../../OEBPS/Images/CH03_F02_Winteringham2.png"/></p>
<p class="figurecaption">Figure 3.2 The imagination/implementation model with sample activities shown</p>
</div>
<p class="body">In the model, we can see a range of various activities that are placed in specific areas because they are focused on specific types of risks. For example, on the imagination side, we might be concerned with risks that affect the usability of a site. Therefore, we employ testing activities that focus on user experience testing and collaborative design. On the implementation side, we want to ensure the product is stable and minimize risks that might affect the product availability and application. Thus, we employ activities such as exploratory and performance testing. Finally, notice how in the area that overlaps, we have added test scripts. These are useful because they are informed by our explicit expectations (imagination) to mitigate risks around unexpected changes appearing in the product (implementation) as it grows and morphs over time, demonstrating that test scripting and automated checks are of use but are only one part of the holistic whole.</p>
<p class="body">Each of these activities has different implementations, different challenges, and different ways in which tooling can help. But we wouldn’t be able to easily identify these uses if we didn’t understand that testing is an exercise in information gathering and knowledge sharing. With this model in place, an appreciation of the many different risks our work faces, and the testing activities that help mitigate them, we can begin to drill deeper into how tooling plays a part in testing.<a id="idIndexMarker008"/><a id="marker-45"/></p>
<h2 class="fm-head" id="heading_id_6">3.2 How tools help with testing</h2>
<p class="body">You’ll likely hear a tester say (or you may even have said it yourself) that there is never enough time to test everything. It will likely be repeated in this book a few times. Teams are always limited by time, budgets, meetings, staffing, and other factors, so to implement and execute effective, modern testing, we must rely on tools to help us. Tools are essential to testing, but they bring us to our next misconception around testing—that a tool, or machine, can test the way a human can.<a id="idIndexMarker009"/></p>
<h3 class="fm-head1" id="heading_id_7">3.2.1 Automation bias</h3>
<p class="body">To appreciate how machines and humans differ regarding testing, let’s consider an example where both are used to test a website feature. The feature is a full-width banner for an e-commerce website with an image and some text to highlight the deal of the day. Initially, we test it manually, or in a human-led way, and observe the feature is working properly—the image is shown and all the text associated with it is correct. Then we decide to use tools to automate testing. We create code that will open the browser and assert that element A, which is where the deal of the day is loaded, exists. We run the automated test, and it passes. And then, one day, after another successful release in which all our automated tests pass, an end-user raises a bug and informs us they can’t see the deal of the day. All they see is an empty white box at the top of the page. <a id="idIndexMarker010"/><a id="marker-46"/><a id="idIndexMarker011"/></p>
<p class="body">What happened? During the process of creating the automated test, we have transferred our knowledge, which is built on implicit information based on mental heuristics and oracles, and made it explicit. We have stripped a complex understanding of a feature down to a single instruction: element A should exist on a web page. So, when the latest release of our product went out with a faulty function to retrieve the deal of the day, or the CSS was incorrect or broken, the automated test still passed because element A still exists. However, it takes a human a matter of seconds to see something is wrong.</p>
<p class="body">The moral of this story isn’t that tools are bad or unnecessary but that they are often misused or misinterpreted. This behavior is a type of <i class="fm-italics">automation bias</i> that creeps into our perspective on the value of tooling, where we ascribe more value to the output of a tool than what it is relaying to us. That is, when we designed our automated test to look for element A, we assumed that all we as humans were doing was looking for element A. But we were considering many other factors, even if we weren’t doing it consciously.</p>
<p class="body">If we fall prey to automation bias, we run the risk of selecting and implementing tools that we believe can reveal and report information in the same way humans can, when in fact they don’t, leading to misguided overconfidence in the products we’re delivering, or generating a level of workload to have tools emulate human behavior that is unsustainable for a modern project. Tools cannot replace testing activities, and subscribing to that notion will ultimately lead to problems with quality and an increase in risks to a project. So instead, we have to shift our thinking more toward how tools can support our testing.</p>
<h3 class="fm-head1" id="heading_id_8">3.2.2 Being selective with tooling</h3>
<p class="body">Success with tools comes from situations in which some thought has been put into the problem we want to solve and what tools could potentially help. To better understand this, let’s return to our deal-of-the-day feature and look closer at what a human is doing when they test a feature like this.<a id="idIndexMarker012"/><a id="idIndexMarker013"/></p>
<p class="body">First, we consider different ways of testing the feature. We use our current understanding of said feature to formulate test ideas and select what we want to test first. Next, we need to set up our test. This might include setting up an environment or creating/updating the necessary test data. (We might need to create a deal of the day to observe as well as test users to administer and view the deal.) With everything set up, we then need to execute our test, loading the browser or perhaps multiple browsers to verify that the deal renders correctly. Then once we’ve observed the results, we take notes or report our findings to our team, all of which would update our understanding of the feature, ready for us to start the process again. This flow can be summarized as shown in figure 3.3.</p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre13" src="../../OEBPS/Images/CH03_F03_Winteringham2.png"/></p>
<p class="figurecaption">Figure 3.3 A visualization of the process of testing the deal-of-the-day feature</p>
</div>
<p class="body"><a id="marker-47"/>This cycle may be something that happens rapidly—for example, in an exploratory testing session. Or it may take place in a longer form, such as performance testing, in which each step has many details to consider. Regardless of the type of activity, to carry out the loop successfully, we need tools to complete the process. We would likely need to use tools such as database clients, test data managers, or infrastructure tools to set up state management. We would use note-taking tools, screenshot applications, and project management tools to report what has been learned. Figure 3.4 summarizes these tools used in testing by updating our initial visualization.</p>
<p class="body">The visualization demonstrates how modern testing utilizes a range of tools for various tasks that occur rather than attempting to wrap the whole testing performance into the use of one tool. This is because there are many different activities at play when testing is carried out. A tool’s ability to observe patterns, changes, and problems will always be limited compared to a human’s observation skills. So instead, we get value from tools that do one job well, as opposed to a tool that does many things poorly.</p>
<p class="body">What is so interesting about this kind of thinking is that when we take the time to consider it, it seems obvious to us. We all use tools to help us with distinct tasks that make up a larger activity. However, most of us do it without deliberate thought. Although we know that the use of tools in specific tasks is sensible, we need to develop the skills to start choosing and using tools intentionally. This means familiarizing ourselves with tools and being more in tune with what we’re doing daily in our testing so that we can pick the right tool or, in the case of LLMs, the right prompt or enhancement. This is what the rest of this book will be focusing on, providing us with the skills needed to know when LLMs can help with specific tasks.<a id="idIndexMarker014"/></p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre14" src="../../OEBPS/Images/CH03_F04_Winteringham2.png"/></p>
<p class="figurecaption">Figure 3.4 A visualization of the testing process, this time with the addition of tools</p>
</div>
<h2 class="fm-head" id="heading_id_9">3.3 Knowing when to use LLMs in testing</h2>
<p class="body">We now understand how effective tool use in testing is about looking to enhance tasks within testing rather than replicating broad testing activities. But where do LLMs fit into this? Given their broad applications, let’s take a look at some of the common ways in which LLMs are currently being used and see how each can be used to support testing.<a id="idIndexMarker015"/><a id="marker-48"/></p>
<h3 class="fm-head1" id="heading_id_10">3.3.1 Generative capabilities</h3>
<p class="body">In the vast field of artificial intelligence, LLMs fall under the banner of generative AI; that is, LLMs have been built with the purpose of generating content (which differs from other AI that may be used to predict or classify). For example, this means that if an LLM was asked to generate test cases for us, it would do so. However, just because it can generate material like test cases doesn’t mean that those test cases are of value to us. We must remind ourselves that how an LLM generates outputs is based on a complex model of probabilities. This means its generative abilities differ from how we as humans might generate ideas.<a id="idIndexMarker016"/></p>
<p class="body">If you recall, in chapter 1 we explored this concept when sending a prompt to an LLM:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Create tests for a file upload feature</p>
</td>
</tr>
</tbody>
</table>
<p class="body">which might result in a response like this one (shortened for brevity):</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table-list-a">   1.  Test for File Upload Functionality:</p>
<p class="body-table-list-b">   •   Test Case 1.1: Upload a Valid File</p>
<p class="body-table-list-c">   <span class="cambria">−</span>   Input: Choose a file with a valid format (e.g., .jpg, .pdf).</p>
<p class="body-table-list-c">   <span class="cambria">−</span>   Expected Outcome: The file is successfully uploaded, and a confirmation message is displayed.</p>
<p class="body-table-list-b">   •   Test Case 1.2: Attempt to Upload an Invalid File</p>
<p class="body-table-list-c">   <span class="cambria">−</span>   Input: Choose a file with an invalid format (e.g., .exe, .xhtml).</p>
<p class="body-table-list-c">   <span class="cambria">−</span>   Expected Outcome: An error message is displayed, indicating that the file format is not supported.</p>
<p class="body-table-list-a">   2.  Test for File Size Limit:</p>
<p class="body-table-list-b">   •   Test Case 2.1: Upload a File Below the Size Limit</p>
<p class="body-table-list-c">   <span class="cambria">−</span>   Input: Choose a file smaller than the maximum allowed size.</p>
<p class="body-table-list-c">   <span class="cambria">−</span>   Expected Outcome: The file is successfully uploaded, and a confirmation message is displayed.</p>
<p class="body-table-list-b">   •   Test Case 2.2: Attempt to Upload a File Exceeding the Size Limit</p>
<p class="body-table-list-c">   <span class="cambria">−</span>   Input: Choose a file larger than the maximum allowed size.</p>
<p class="body-table-list-c">   <span class="cambria">−</span>   Expected Outcome: An error message is displayed, indicating that the file exceeds the maximum size limit.</p>
</td>
</tr>
</tbody>
</table>
<p class="body"><a id="marker-49"/>How an LLM has generated these test cases is impressive, but they lack context and specificity for the feature or product we are testing. So instead, when working with LLMs, we need to make sure that how we prompt or extend them provides them with enough context to generate valuable outputs.</p>
<p class="body">The consequence of ensuring that we provide sufficient context is that it’s easier to use LLMs to generate outputs for very specific and targeted tasks. The alternative means we would have to provide a massive amount of input data that would result in a prompt that is expensive to build and maintain. For example, imagine the amount of context you would have to put into an LLM to obtain a test strategy relevant to our working context.</p>
<p class="body">Instead, we can get more value from LLMs if we focus on using them to help with tasks such as</p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Test data generation</i>—When given explicit rules around data sets, LLMs can be used to generate rapid sets of data for use in a range of testing activities, from exploratory to performance testing.<a id="idIndexMarker017"/></p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Suggestions for risks and test ideas</i>—We should always avoid letting the output of an LLM be the sole arbiter of what to test. We can use them to suggest test ideas and risks that can be used as jumping-off points for new ideas or factored into our existing work.</p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Code snippets</i>—Similar to the earlier test case example, we gain little value from LLMs if we ask them to generate complete automated tests or frameworks. However, using them to generate smaller parts of automation or scripts used to support testing activities such as exploratory testing can be advantageous.<a id="idIndexMarker018"/></p>
</li>
</ul>
<h3 class="fm-head1" id="heading_id_11">3.3.2 Transformation capabilities</h3>
<p class="body">Another benefit that LLMs offer is the ability to transform natural language from one structure to another. A common example of LLM transformation is language translation. Suppose that we sent something like this to an LLM:<a id="marker-50"/><a id="idIndexMarker019"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Convert the following text delimited by three hashes into French:</p>
<p class="body-table">###</p>
<p class="body-table">Hello, my name is Mark</p>
<p class="body-table">###</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Then it will return a response such as</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Bonjour, je m’appelle Mark</p>
</td>
</tr>
</tbody>
</table>
<p class="body">This is a useful way to illustrate how LLMs transform data, but we shouldn’t be restricted to spoken languages only. LLMs are capable of transforming all types of data from one abstraction to another. Here are some examples that can help with testing:</p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Transforming test data</i>—Using LLMs to rapidly transform data from one structure to another can help speed up testing. For example, we might ask an LLM to convert plain-text test data into SQL statements or to convert SQL statements into helper functions that are called in test automation.<a id="idIndexMarker020"/></p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Converting code</i>—LLMs can convert functions, classes, and other data into new iterations of code. What makes this valuable is that LLMs can transform code into different languages but still keep the logic and flow of the original code in the newly translated output (although we should always test it to be sure).<a id="idIndexMarker021"/></p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Summarizing notes</i>—Although the conversion of data isn’t as direct as, say, converting a code snippet from one language to another, we can use LLMs to transform and summarize at the same time. Also, we can use LLMs to take raw testing notes from testing activities such as exploratory or design testing sessions and have them converted into summary notes to be shared with others.<a id="idIndexMarker022"/></p>
</li>
</ul>
<h3 class="fm-head1" id="heading_id_12">3.3.3 Enhancing capabilities</h3>
<p class="body"><a id="marker-51"/>Finally, we can use LLMs to enhance and expand existing material. This usually means providing an LLM with a snippet of data and prompting the LLM to expand on it. This has some overlap with the generative capabilities because we’re asking LLMs to generate a certain degree of new output, but in this situation, we’re providing a lot more upfront context and instructing it to focus on existing material, as opposed to prompting an LLM to generate something completely new. This means we can use this ability to help us with testing tasks such as<a id="idIndexMarker023"/></p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Reviewing code</i>—Not all who conduct testing are confident coders, and even those who are comfortable with reading code can struggle at times to make sense of the code required to analyze or test. LLMs can enhance our understanding by taking code snippets and providing a natural language breakdown of how said code works, which can help with risk analysis, test design, and more.<a id="idIndexMarker024"/></p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Descriptive code</i>—Similar to reviewing code, we can use LLMs to help improve the descriptiveness of code—for example, rapidly creating code comments that can be easily created and maintained. This can be especially useful for automated testing, where communicating what our automation code is doing is important for maintenance.<a id="idIndexMarker025"/></p>
</li>
<li class="fm-list-bullet">
<p class="list"><i class="fm-italics">Expanding analysis</i>—We can also use LLMs to expand our analysis activities, such as risk analysis and design testing (where we ask questions about requirements before the feature is built). By providing it with our current analysis data, we can ask LLMs to review and expand on it, suggesting new ideas that we can either incorporate into our analysis or ignore.<a id="idIndexMarker026"/></p>
</li>
</ul>
<h3 class="fm-head1" id="heading_id_13">3.3.4 LLMs in use in testing</h3>
<p class="body">To put these different abilities of an LLM into context, let’s return to our visualization of testing with the support of tools (figure 3.5).<a id="idIndexMarker027"/></p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre15" src="../../OEBPS/Images/CH03_F05_Winteringham2.png"/></p>
<p class="figurecaption">Figure 3.5 A visualization of the testing process, this time with the addition of LLMs</p>
</div>
<p class="body">Here, we can see how LLMs can be inserted into distinct and specific tasks within the wider testing lifecycle. It brings us back to our area of effect model that we covered in chapter 1. Instead of attempting to use LLMs to replicate the full gamut of testing activities that exist within a lifecycle, we prioritize the best of our abilities as humans and the value we bring to testing. Then, we choose to add LLMs in select areas to expand our work so that we can move faster, learn more, and help ensure our teams are better informed so that they can build higher-quality products.<a id="idIndexMarker028"/></p>
<h2 class="fm-head" id="heading_id_14">Summary<a id="marker-52"/></h2>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">If we have a limited understanding of what testing is, then the use of tools will also be limited.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Testing is not a confirmatory exercise but rather a collection of different activities that help those seeking to learn about the imagination and implementation of a product.</p>
</li>
<li class="fm-list-bullet">
<p class="list">The imagination implies our understanding of what we want to build.</p>
</li>
<li class="fm-list-bullet">
<p class="list">The implementation implies our understanding of what we have built.</p>
</li>
<li class="fm-list-bullet">
<p class="list">As our understanding of both aspects increases, we bring them into alignment, which helps us deliver a higher-quality product.</p>
</li>
<li class="fm-list-bullet">
<p class="list">We run many different types of testing activities to focus on different types of risks and how they affect both imagination and implementation.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Tools are an essential component of successful testing.</p>
</li>
<li class="fm-list-bullet">
<p class="list">LLMs can be used to generate, transform, and enhance outputs.</p>
</li>
<li class="fm-list-bullet">
<p class="list">LLMs should be used with smaller, specific tasks to generate outputs that provide value.</p>
</li>
<li class="fm-list-bullet">
<p class="list">LLMs can generate content that can help with specific tasks or create suggested content.</p>
</li>
<li class="fm-list-bullet">
<p class="list">LLMs can transform data to help convert raw data into useful formats or summarize it.</p>
</li>
<li class="fm-list-bullet">
<p class="list">LLMs can also enhance existing material, adding new suggestions or expanding details.</p>
</li>
<li class="fm-list-bullet">
<p class="list">We can insert LLMs into many distinct and specific testing tasks, which reflects the area of effect model we learned about in chapter 1.</p>
</li>
</ul>
</div></body></html>