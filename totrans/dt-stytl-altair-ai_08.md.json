["```py\n{\n  \"messages\": [\n     {\n    \"role\": \"system\",\n  \"content\": \"You are a data analyst showing data to the general public.\"\n     },\n     {\n         \"role\": \"user\",\n         \"content\": \"Distribution of household chores \n                                  (Cooking 35% Cleaning 30% Laundry 20%, Yard work 15%)\"\n     },\n     {\n          \"role\": \"assistant\",\n           \"content\": \"Cooking takes up the largest portion at 35%. \n                      Cleaning follows at 30% while laundry \n                      and yard work accounts for 20% and 15% respectively.\"\n\n     }\n  ]\n}\n```", "```py\nimport pandas as pd\nimport json\n\ndf = pd.read_csv('general-public.csv')\n\njson_list = []\n\nfor index, row in df.iterrows():\n    json_object = {\n        \"messages\": [\n            {\n                \"role\": \"system\",\n                \"content\": \"You are a data analyst showing data to the general public.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": row['prompt']\n            },\n            {\n                \"role\": \"assistant\",\n                \"content\": row['completion']\n            }\n        ]\n    }\n    json_list.append(json_object)\n\nwith open('general-public.jsonl', 'w') as outfile:\n    for json_object in json_list:\n        json.dump(json_object, outfile)\n        outfile.write('\\n')\n```", "```py\nimport os\nimport openai\nimport time\n\nopenai.api_key = os.getenv('OPENAI_API_KEY')     #1\n\ndataset = openai.File.create(file=open('general-public.jsonl', \n[CA]'rb'), purpose='fine-tune')          #2\nprint('Uploaded file id', dataset.id)\n\nwhile True:      #3\n    print('Waiting while file is processed...')\n    file_handle = openai.File.retrieve(id=dataset.id)\n    if len(file_handle) and file_handle.status == 'processed':\n        print('File processed')\n        break\n    time.sleep(3)\n\njob = openai.FineTuningJob.create(training_file=dataset.id, model=\"gpt-3.5-turbo\")      #4\n\nwhile True:\n    print('Waiting while fine-tuning is completed...')\n    job_handle = openai.FineTuningJob.retrieve(id=job.id)\n    if job_handle.status == 'succeeded':\n        print('Fine-tuning complete')\n        print('Fine-tuned model info', job_handle)\n        print('Model id', job_handle.fine_tuned_model)     #5\n        break\n    time.sleep(3)\n```", "```py\nfine-tuned model info {\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"your model id\",\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"created_at\": 1693347869,\n  \"finished_at\": 1693348340,\n  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::7t1Xuct5\",\n  \"organization_id\": \"org-jWkYw8hPpaNwkesXezsWOwK8\",\n  \"result_files\": [\n    \"file-ro0BoeariIjOl7NSGRC80v8r\"\n  ],\n  \"status\": \"succeeded\",\n  \"validation_file\": null,\n  \"training_file\": \"file-InGnigMTto3YLrsiLuIUr7ty\",\n  \"hyperparameters\": {\n    \"n_epochs\": 10\n  },\n  \"trained_tokens\": 5930\n}\n```", "```py\nimport os\nimport openai\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\nmodel_id = \"ft:gpt-3.5-turbo-0613:personal::7t1Xuct5\"\n\ncompletion = openai.ChatCompletion.create(\n    model=model_id,\n    messages=[\n        {\n            'role': 'system',\n            'content': 'You are a data analyst showing data to the general public.',\n        },\n        {\n            'role': 'user', \n            'content': 'Top sports: rowing (62%) and cycling (58%)'\n        },\n    ],\n)\n\nprint(completion.choices[0].message)\n```", "```py\n{\n  \"role\": \"assistant\",\n  \"content\": \" \\\"The most popular sports are rowing and cycling with 62% and 58% of people practicing them respectively.\\\"\"\n}\n```", "```py\n# import required libraries\n# extract the title and link from the following rss/feed url: https://alod83.medium.com/feed\n# for each extracted link, extract the subheading from the article\n# create a dataframe with the following columns: 'prompt', ‘completion’\n# save the dataframe to a csv file called 'medium-articles.csv'\n```", "```py\nimport feedparser\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\n\nurl = 'https://alod83.medium.com/feed'\nfeed = feedparser.parse(url)\n\ntitles = []\nlinks = []\nsubheadings = []\n\nfor entry in feed.entries:\n    titles.append(entry.title)\n    links.append(entry.link)\n    print(entry.link)\n    response = requests.get(entry.link)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    subheading = soup.find('h2', attrs={'class': 'pw-subtitle-paragraph'}).text\n    subheadings.append(subheading)\n\ndf = pd.DataFrame({'prompt': subheadings,'completion': titles})\ndf.to_csv('medium-articles.csv', index=False)\n```", "```py\nfrom langchain_community.document_loaders.xhtml import UnstructuredHTMLLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate\nfrom langchain_openai import ChatOpenAI\n\nloader = UnstructuredHTMLLoader('product.xhtml')    #1\ndata = loader.load()\n```", "```py\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 100,\n    chunk_overlap  = 20,\n    length_function = len,\n    is_separator_regex = False,\n)\n\nsplitted_data = text_splitter.split_documents(data)\n```", "```py\nembeddings = OpenAIEmbeddings()\n\nstore = Chroma.from_documents(\n    splitted_data, \n    embeddings, \n    ids = [f\"{item.metadata['source']}-{index}\" for index, item in enumerate(splitted_data)],\n    collection_name='Product-Info', \npersist_directory='db',\n)\nstore.persist()\n```", "```py\ntemplate = \"\"\"You are a bot that answers questions about the product New SmartX 2023, using only the context provided.\nIf you don't know the answer, simply state that you don't know.\n\n{context}\n\nQuestion: {question}\"\"\"\n\nprompt = PromptTemplate(\n    template=template, input_variables=['context', 'question']\n)\n```", "```py\nllm = ChatOpenAI(temperature=0, model='gpt-3.5-turbo')\n\nqa = RetrievalQA.from_chain_type(\n    llm=llm,\n    chain_type='stuff',\n    retriever=store.as_retriever(),\n    chain_type_kwargs={'prompt': prompt, },\n    return_source_documents=True,\n)\n\nprint(\n    qa.invoke({\"query\": 'Describe the product New SmartX 2023 using 30 words'})\n)\n```", "```py\n{'query': 'Describe the product New SmartX 2023 using 30 words', \n    'result': 'The New SmartX 2023 is a cutting-edge smartphone with a 5.7-inch Super AMOLED display and a high-quality camera that captures breathtaking landscapes and detailed close-ups.', \n    'source_documents': \n    [Document(page_content='© 2023 SmartX Technologies. All rights reserved.', \n        metadata={'source': 'product.xhtml'}), \n        Document(page_content='Get ready to experience the future with the all-new SmartX 2023\\. This cutting-edge smartphone', \n        metadata={'source': 'product.xhtml'}), \n        Document(page_content='Introducing the New SmartX 2023\\n\\\\nKey Features:\\n\\\\n5.7-inch Super AMOLED Display', \n            metadata={'source': 'product.xhtml'}), \n        Document(page_content=\"you're taking breathtaking landscapes or detailed close-ups, the SmartX 2023's camera delivers\", \n            metadata={'source': 'product.xhtml'})\n    ]\n}\n```", "```py\n{'query': 'Describe Safety of Aquaculture Seafood in the U.S.', 'result': 'Aquaculture seafood in the U.S. is regulated by the FDA to ensure safety. Strict standards are in place to monitor water quality, feed, and disease control. Regular inspections and testing are conducted to minimize risks and protect consumers.', 'source_documents': [Document(page_content='Safety of Aquaculture Seafood', metadata={'source': 'aquaculture.xhtml'}), Document(page_content='Regulatory Requirements for Aquacultured Seafood', metadata={'source': 'aquaculture.xhtml'}), Document(page_content='Domestic Aquaculture Seafood', metadata={'source': 'aquaculture.xhtml'}), Document(page_content='for additional information on how the FDA ensures the safety of imported seafood products.', metadata={'source': 'aquaculture.xhtml'})]}\n```", "```py\ncommentary = ['Aquaculture seafood in the U.S. is regulated by the FDA to ensure safety. Strict standards are in place to monitor water quality, feed, and disease control.',\n'Regular inspections and testing are conducted to minimize risks and protect consumers. (Source: U.S. Food and Drug Administration)'\n]\n\nbase = alt.Chart(df).encode(\n    x=alt.X('YEAR_ID:O', title=''),\n    y=alt.Y('AMOUNT', title='$',axis=alt.Axis(format='.2s')),\n    color=alt.Color('CATEGORY', \n        legend=None,\n        scale=alt.Scale(range=range, domain=domain)\n    )\n).properties(\n    width=800,\n    height=400,\n    title=alt.TitleParams(\n        text='Aquaculture Exports of Salmon in the U.S.',\n        subtitle=commentary,\n        fontSize=20,\n        subtitleFontSize=14,\n        align='left',\n        anchor='start',\n        offset=20,\n        color=color,\n        subtitleColor='black'\n    )\n)\n```", "```py\nN = 100000000           #1\ny = df['AMOUNT'].max() + N\n\nrect_df = pd.DataFrame({'x': [1992], \n            'x2': [1998],\n            'y' : [0],\n            'y2': [y]\n        })\n\nrect = alt.Chart(rect_df).mark_rect(\n    color='lightgrey',\n    opacity=0.5\n).encode(\n    x='x:O',\n    x2='x2:O',\n    y= 'y:Q',\n    y2= 'y2:Q'\n)\n```", "```py\nann_df = pd.DataFrame({'x': [1992, 1992, 1992],\n            'y': [y, y-N/3*2, y-N/3*4],\n            'text': ['The decline in sales was',\n            'partially due to fish',\n            'health issues']\n            })\n\nannotation = alt.Chart(ann_df\n).mark_text(\n    align='left',\n    baseline='middle',\n    fontSize=14,\n    dx=5,\n    dy=10\n).encode(\n    x='x:O',\n    y='y:Q',\n    text='text:N'\n)\n\nchart = (chart + text + rect + annotation\n).configure_axis(\n    labelFontSize=14,\n    titleFontSize=16,\n    grid=False\n).configure_view(\n    strokeWidth=0\n)\nchart.save('chart.xhtml')\n```"]