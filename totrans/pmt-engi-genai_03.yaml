- en: Chapter 3\. Standard Practices for Text Generation with ChatGPT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 3 章. 使用 ChatGPT 进行文本生成的标准实践
- en: Simple prompting techniques will help you to maximize the output and formats
    from LLMs. You’ll start by tailoring the prompts to explore all of the common
    practices used for text generation.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的提示技术将帮助你最大化 LLM 的输出和格式。你将从定制提示开始，以探索用于文本生成的所有常见实践。
- en: Generating Lists
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成列表
- en: Automatically generating lists is incredibly powerful and enables you to focus
    on higher-level tasks while GPT can automatically generate, refine, rerank, and
    de-duplicate lists on your behalf.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成列表非常强大，使你能够专注于更高层次的任务，而 GPT 可以代表你自动生成、细化、重新排序和去重列表。
- en: 'Input:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Output:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'GPT-4 is perfectly capable of providing a list of characters. However, there
    are some pitfalls with this approach:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4 完全能够提供角色列表。然而，这种方法存在一些陷阱：
- en: GPT has decided to provide 30 examples as a numbered list, separated by `\n`
    characters. However, if your downstream Python code was expecting to split on
    bullet points, then you’ll likely end up with undesirable results or a runtime
    error.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT 决定提供 30 个示例，以编号列表的形式呈现，由 `\n` 字符分隔。然而，如果你的下游 Python 代码期望在项目符号处分割，那么你可能会得到不理想的结果或运行时错误。
- en: GPT has provided preceding commentary; removing any preceding/succeeding commentary
    would make parsing the output easier.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT 提供了先前的评论；移除任何先前的/随后的评论会使解析输出更容易。
- en: The list size wasn’t controlled and was left to the language model.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有控制列表大小，并将其留给语言模型。
- en: Some of the characters have the name of their corresponding film within brackets—for
    example, *Bagheera (The Jungle Book)*—and others don’t. This makes names harder
    to extract because you would need to remove the movie titles.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些字符在其对应电影名称的括号内（例如，*Bagheera (The Jungle Book)*）——而另一些则没有。这使得提取名称变得更加困难，因为你需要移除电影标题。
- en: No filtering or selection has been applied to the LLM generation based on our
    desired result.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 LLM 生成过程中，没有根据我们期望的结果进行过滤或选择。
- en: Following you’ll find an optimized prompt.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个优化的提示。
- en: 'Input:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Output:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Provide Examples
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提供示例
- en: Simply rephrasing your prompt to include examples *(few-shot prompting)* can
    greatly impact the desired output.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地重新措辞你的提示以包含示例 *(few-shot prompting)* 可以极大地影响期望的输出。
- en: 'By optimizing the prompt, you’ve achieved the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通过优化提示，你已经实现了以下效果：
- en: Restricted the list to a fixed size of five
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将列表限制为固定大小五
- en: Generated only male characters
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅生成男性角色
- en: Correctly formatted the list with bullet points
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确格式化带有项目符号的列表
- en: Removed any preceding commentary
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除了任何先前的评论
- en: Simple lists are fine for most tasks; however, they are less structured, and
    for some tasks it’s beneficial to obtain nested data structures from a GPT-4 output.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 简单列表适用于大多数任务；然而，它们结构较少，对于某些任务，从 GPT-4 输出中获取嵌套数据结构是有益的。
- en: 'Three typical data structures include:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 三种典型数据结构包括：
- en: Nested text data (hierarchical lists)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌套文本数据（层次列表）
- en: JSON
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JSON
- en: YAML
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YAML
- en: Hierarchical List Generation
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 层次列表生成
- en: Hierarchical lists are useful for when your desired output is nested. A good
    example of this would be a detailed article structure.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 层次列表在需要嵌套输出时很有用。一个很好的例子就是详细的文章结构。
- en: 'Input:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Output:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To generate an effective article outline in the preceding output, you’ve included
    two key phrases:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在前面的输出中生成有效的文章大纲，你包含了两个关键短语：
- en: Hierarchical
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 层次化
- en: To suggest that the article outline needs to produce a nested structure.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建议文章大纲需要生成嵌套结构。
- en: Incredibly detailed
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 极其详细
- en: To guide the language model towards producing a larger output. Other words that
    you could include that have the same effect would be *very long* or by specifying
    a large number of subheadings, *include at least 10 top-level headings*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了引导语言模型产生更大的输出。其他可以包含以产生相同效果的字词包括 *非常长* 或通过指定大量子标题，*至少包含 10 个顶级标题*。
- en: Note
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Asking a language model for a fixed number of items doesn’t guarantee the language
    model will produce the same length. For example, if you ask for 10 headings, you
    might receive only 8\. Therefore, your code should either validate that 10 headings
    exist or be flexible to handle varying lengths from the LLM.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 询问语言模型固定数量的项目并不能保证语言模型会产生相同长度的输出。例如，如果你要求 10 个标题，你可能会只收到 8 个。因此，你的代码应该验证存在 10
    个标题，或者能够灵活处理来自 LLM 的不同长度。
- en: So you’ve successfully produced a hierarchical article outline, but how could
    you parse the string into structured data?
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你已经成功生成了一个分层文章大纲，但如何将字符串解析成结构化数据呢？
- en: Let’s explore [Example 3-1](#parsing_a_hierarchical_list_one) using Python,
    where you’ve previously made a successful API call against OpenAI’s GPT-4\. Two
    regular expressions are used to extract the headings and subheadings from `openai_result`.
    The `re` module in Python is used for working with regular expressions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用 Python 探索 [示例 3-1](#parsing_a_hierarchical_list_one)，在那里你之前已经成功调用了 OpenAI
    的 GPT-4。使用了两个正则表达式从 `openai_result` 中提取标题和副标题。Python 中的 `re` 模块用于处理正则表达式。
- en: Example 3-1\. [Parsing a hierarchical list](https://oreil.ly/A0otS)
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 3-1\. [解析分层列表](https://oreil.ly/A0otS)
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This code will output:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将输出：
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The use of regular expressions allows for efficient pattern matching, making
    it possible to handle variations in the input text, such as the presence or absence
    of leading spaces or tabs. Let’s explore how these patterns work:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式的使用允许进行高效的模式匹配，使得处理输入文本的变化（如前导空格或制表符的存在或不存在）成为可能。让我们探索这些模式是如何工作的：
- en: '`heading_pattern = r''\* (.+)''`'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`heading_pattern = r''\* (.+)`'
- en: 'This pattern is designed to extract the main headings and consists of:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此模式旨在提取主要标题，由以下内容组成：
- en: '`\*` matches the asterisk `(*)` symbol at the beginning of a heading. The backslash
    is used to escape the asterisk, as the asterisk has a special meaning in regular
    expressions (zero or more occurrences of the preceding character).'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\*` 匹配标题开头处的星号 `(*)` 符号。反斜杠用于转义星号，因为星号在正则表达式中具有特殊含义（匹配前面字符的零个或多个出现）。'
- en: A space character will match after the asterisk.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星号之后将匹配一个空格字符。
- en: '`(.+)`: matches one or more characters, and the parentheses create a capturing
    group. The `.` is a wildcard that matches any character except a newline, and
    the `+` is a quantifier that means *one or more* occurrences of the preceding
    element (the dot, in this case).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(.+)`: 匹配一个或多个字符，并且括号创建了一个捕获组。`.` 是一个通配符，匹配除换行符之外的任何字符，而 `+` 是一个量词，表示前面元素（在这种情况下是点）的一个或多个出现。'
- en: By applying this pattern you can easily extract all of the main headings into
    a list without the asterisk.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 通过应用此模式，你可以轻松地将所有主要标题提取到一个列表中，而不包含星号。
- en: '`subheading_pattern = r''\s+[a-z]\. (.+)`'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subheading_pattern = r''\s+[a-z]\. (.+)`'
- en: 'The `subheading pattern` will match all of the subheadings within the `openai_result`
    string:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`subheading pattern` 将匹配 `openai_result` 字符串中的所有副标题：'
- en: '`\s+` matches one or more whitespace characters (spaces, tabs, and so on).
    The `+` means *one or more* occurrences of the preceding element (the `\s`, in
    this case).'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\s+` 匹配一个或多个空白字符（空格、制表符等）。`+` 表示前面元素（在这种情况下是 `\s`）的一个或多个出现。'
- en: '`[a-z]` matches a single lowercase letter from *a* to *z*.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[a-z]` 匹配从 *a* 到 *z* 的单个小写字母。'
- en: '`\.` matches a period character. The backslash is used to escape the period,
    as it has a special meaning in regular expressions (matches any character except
    a newline).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`\.` 匹配句点字符。反斜杠用于转义句点，因为在正则表达式中句点有特殊含义（匹配除换行符之外的任何字符）。'
- en: '*A space character will match after the period.*'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*一个空格字符将在句号之后匹配*。'
- en: '`(.+)` matches one or more characters, and the parentheses create a capturing
    group. The `.` is a wildcard that matches any character except a newline, and
    the `+` is a quantifier that means *one or more* occurrences of the preceding
    element (the dot, in this case).'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(.+)` 匹配一个或多个字符，并且括号创建了一个捕获组。`.` 是一个通配符，匹配除换行符之外的任何字符，而 `+` 是一个量词，表示前面元素（在这种情况下是点）的一个或多个出现。'
- en: Additionally the `re.findall()` function is used to find all non-overlapping
    matches of the patterns in the input string and return them as a list. The extracted
    headings and subheadings are then printed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`re.findall()` 函数用于在输入字符串中查找所有非重叠模式的匹配项，并将它们作为列表返回。然后打印提取的标题和副标题。
- en: So now you’re able to extract headings and subheadings from hierarchical article
    outlines; however, you can further refine the regular expressions so that each
    heading is associated with corresponding `subheadings`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在你能够从分层文章大纲中提取标题和副标题；然而，你可以进一步细化正则表达式，以便每个标题都与相应的 `subheadings` 相关联。
- en: In [Example 3-2](#parsing_a_hierarchical_list_two), the regex has been slightly
    modified so that each subheading is attached directly with its appropriate subheading.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 3-2](#parsing_a_hierarchical_list_two) 中，正则表达式略有修改，以便每个副标题直接与其相应的副标题相关联。
- en: Example 3-2\. [Parsing a hierarchical list into a Python dictionary](https://oreil.ly/LcMtv)
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例3-2\. [将分层列表解析为Python字典](https://oreil.ly/LcMtv)
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This will output:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出：
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The section title regex, `r'\* (.+)'`, matches an asterisk followed by a space
    and then one or more characters. The parentheses capture the text following the
    asterisk and space to be used later in the code.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 部分标题正则表达式`r'\* (.+)'`匹配一个星号后跟一个空格，然后是一个或多个字符。括号捕获星号和空格后面的文本，以便在代码中稍后使用。
- en: The subsection regex, `r'\s*([a-z]\..+)'`, starts with `\s*`, which matches
    zero or more whitespace characters (spaces or tabs). This allows the regex to
    match subsections with or without leading spaces or tabs. The following part,
    `([a-z]\..+)`, matches a lowercase letter followed by a period and then one or
    more characters. The parentheses capture the entire matched subsection text for
    later use in the code.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 子部分正则表达式`r'\s*([a-z]\..+)'`以`\s*`开始，它匹配零个或多个空白字符（空格或制表符）。这允许正则表达式匹配带有或不带有前导空格或制表符的子部分。接下来的部分`([a-z]\..+)`匹配一个小写字母后跟一个点，然后是一个或多个字符。括号捕获整个匹配的子部分文本，以便在代码中稍后使用。
- en: The `for` loop iterates over each line in the input string, `openai_result`.
    Upon encountering a line that matches the section title regex, the loop sets the
    matched title as the current section and assigns an empty list as its value in
    the `result_dict` dictionary. When a line matches the subsection regex, the matched
    subsection text is appended to the list corresponding to the current section.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`for`循环遍历输入字符串`openai_result`中的每一行。当遇到与部分标题正则表达式匹配的行时，循环将匹配的标题设置为当前部分，并在`result_dict`字典中将它的值设为空列表。当一行与子部分正则表达式匹配时，匹配的子部分文本将被追加到当前部分的列表中。'
- en: Consequently, the loop processes the *input string line by line*, categorizes
    lines as section titles or subsections, and constructs the intended dictionary
    structure.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，循环逐行处理*输入字符串*，将行分类为部分标题或子部分，并构建所需的字典结构。
- en: When to Avoid Using Regular Expressions
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免使用正则表达式的时机
- en: As you work to extract more structured data from LLM responses, relying solely
    on regular expressions can make the control flow *become increasingly complicated.*
    However, there are other formats that can facilitate the parsing of structured
    data from LLM responses with ease. Two common formats are *.json* and *.yml* files.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当你努力从LLM响应中提取更多结构化数据时，仅依赖正则表达式会使控制流*变得越来越复杂*。然而，还有其他格式可以轻松地解析LLM响应中的结构化数据。两种常见的格式是*.json*和*.yml*文件。
- en: Generating JSON
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成JSON
- en: Let’s start by experimenting with some prompt design that will direct an LLM
    to return a JSON response.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从实验一些将指导LLM返回JSON响应的提示设计开始。
- en: 'Input:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Output:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Give Direction and Provide Examples
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 给出指示并提供示例
- en: Notice that in the preceding prompt, you’ve provided direction on the type of
    task, the format, and an example JSON output.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在前面的提示中，你已经提供了关于任务类型、格式和示例JSON输出的指示。
- en: Common errors that you’ll encounter when working with JSON involve invalid payloads,
    or the JSON being wrapped within triple backticks ([PRE12]
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理JSON时遇到的一些常见错误包括无效的负载或JSON被三重反引号包裹([PRE12]
- en: 'Sure here''s the JSON:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这是JSON：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '{"Name": "John Smith"}'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '{"Name": "John Smith"}'
- en: '[PRE15]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'You must follow the following principles:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须遵循以下原则：
- en: '* Only return valid JSON'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '* 只返回有效的JSON'
- en: '* Never include backtick symbols such as: `'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '* 永远不要包含反引号符号，例如：`'
- en: '* The response will be parsed with json.loads(), therefore it must be valid
    JSON.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '* 响应将通过json.loads()解析，因此它必须是有效的JSON。'
- en: '[PRE16]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: import json
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: import json
- en: openai_json_result = generate_article_outline(prompt)
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: openai_json_result = generate_article_outline(prompt)
- en: openai_json_result = """
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: openai_json_result = """
- en: '{'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '{'
- en: '"Introduction": ['
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '"Introduction": ['
- en: '"a. Overview of coding and programming languages",'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '"a. 编码和编程语言的概述",'
- en: '"b. Importance of coding in today''s technology-driven world"],'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '"b. 当代技术驱动世界中编码的重要性"],'
- en: '"Conclusion": ['
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '"结论": ['
- en: '"a. Recap of the benefits of learning code",'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '"a. 学习代码的好处总结",'
- en: '"b. The ongoing importance of coding skills in the modern world"]'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '"b. 现代世界中编码技能的持续重要性"]'
- en: '}'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '}'
- en: '"""'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: parsed_json_payload = json.loads(openai_json_result)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: parsed_json_payload = json.loads(openai_json_result)
- en: print(parsed_json_payload)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: print(parsed_json_payload)
- en: '''''''{''Introduction'': [''a. Overview of coding and programming languages'','
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '''''''{''Introduction'': [''a. 编码和编程语言的概述'','
- en: '"b. Importance of coding in today''s technology-driven world"],'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '"b. 当代技术驱动世界中编码的重要性"],'
- en: '''Conclusion'': [''a. Recap of the benefits of learning code'','
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '''结论'': [''a. 学习代码的好处总结'','
- en: '''b. The ongoing importance of coding skills in the modern world'']}'''''''
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '''b. The ongoing importance of coding skills in the modern world'']}'''''''
- en: '[PRE17]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '- Below you''ll find the current yaml schema.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '- 下面是当前yaml模式。'
- en: '- You can update the quantities based on a User Query.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '- 您可以根据用户查询更新数量。'
- en: '- Filter the User Query based on the schema below, if it doesn''t match and'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '- 根据以下模式过滤用户查询，如果不匹配且'
- en: there are no items left then return `"No Items"`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有剩余的项目，则返回 `"No Items"`.
- en: '- If there is a partial match, then return only the items that are'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '- 如果有部分匹配，则只返回匹配的项目'
- en: 'within the schema below:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 'within the schema below:'
- en: 'schema:'
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模式：
- en: '- item: Apple Slices'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：苹果片'
- en: 'quantity: 5'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：5
- en: 'unit: pieces'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：个
- en: '- item: Milk'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：牛奶'
- en: 'quantity: 1'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：1
- en: 'unit: gallon'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：加仑
- en: '- item: Bread'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：面包'
- en: 'quantity: 2'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：2
- en: 'unit: loaves'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：条
- en: '- item: Eggs'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：鸡蛋'
- en: 'quantity: 1'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：1
- en: 'unit: dozen'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：打
- en: 'User Query: "5 apple slices, and 2 dozen eggs."'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 用户查询："5个苹果片，2打鸡蛋。"
- en: Given the schema below, please return only a valid .yml based on the User
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 根据以下模式，请仅返回基于用户的有效.yml
- en: Query.If there's no match, return `"No Items"`. Do not provide any
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 查询。如果没有匹配，则返回 `"No Items"`。不要提供任何
- en: commentary or explanations.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 注释或解释。
- en: '[PRE18]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '- item: Apple Slices'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：苹果片'
- en: 'quantity: 5'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：5
- en: 'unit: pieces'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：个
- en: '- item: Eggs'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：鸡蛋'
- en: 'quantity: 2'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：2
- en: 'unit: dozen'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：打
- en: '[PRE19]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'User Query:'
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户查询：
- en: '- item: Apple Slices'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：苹果片'
- en: 'quantity: 5'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：5
- en: 'unit: pieces'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：个
- en: '- item: Bananas'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：香蕉'
- en: 'quantity: 3'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：3
- en: 'unit: pieces'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：个
- en: '[PRE20]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Updated yaml list
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新后的yaml列表
- en: '- item: Apple Slices'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：苹果片'
- en: 'quantity: 5'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：5
- en: 'unit: pieces'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：个
- en: '[PRE21]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'User Query:'
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户查询：
- en: '- item: Bananas'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：香蕉'
- en: 'quantity: 3'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：3
- en: 'unit: pieces'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：个
- en: '[PRE22]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: No Items
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 没有项目
- en: '[PRE23]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'class InvalidResponse(Exception):'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 'class InvalidResponse(Exception):'
- en: pass
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pass
- en: 'class InvalidItemType(Exception):'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 'class InvalidItemType(Exception):'
- en: pass
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pass
- en: 'class InvalidItemKeys(Exception):'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 'class InvalidItemKeys(Exception):'
- en: pass
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pass
- en: 'class InvalidItemName(Exception):'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 'class InvalidItemName(Exception):'
- en: pass
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pass
- en: 'class InvalidItemQuantity(Exception):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 'class InvalidItemQuantity(Exception):'
- en: pass
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pass
- en: 'class InvalidItemUnit(Exception):'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 'class InvalidItemUnit(Exception):'
- en: pass
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: pass
- en: '[PRE24]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Provided schema
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提供的模式
- en: schema = """
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: schema = """
- en: '- item: Apple Slices'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：苹果片'
- en: 'quantity: 5'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：5
- en: 'unit: pieces'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：个
- en: '- item: Milk'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：牛奶'
- en: 'quantity: 1'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：1
- en: 'unit: gallon'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：加仑
- en: '- item: Bread'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：面包'
- en: 'quantity: 2'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：2
- en: 'unit: loaves'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：条
- en: '- item: Eggs'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：鸡蛋'
- en: 'quantity: 1'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：1
- en: 'unit: dozen'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：打
- en: '"""'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: '[PRE25]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: import yaml
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: import yaml
- en: 'def validate_response(response, schema):'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 'def validate_response(response, schema):'
- en: Parse the schema
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解析模式
- en: schema_parsed = yaml.safe_load(schema)
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: schema_parsed = yaml.safe_load(schema)
- en: maximum_quantity = 10
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最大数量 = 10
- en: Check if the response is a list
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查响应是否是列表
- en: 'if not isinstance(response, list):'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if not isinstance(response, list):'
- en: raise InvalidResponse("Response is not a list")
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise InvalidResponse("响应不是列表")
- en: Check if each item in the list is a dictionary
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查列表中的每个项目是否是字典
- en: 'for item in response:'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'for item in response:'
- en: 'if not isinstance(item, dict):'
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if not isinstance(item, dict):'
- en: raise InvalidItemType('''Item is not a dictionary''')
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise InvalidItemType('''项目不是字典''')
- en: Check if each dictionary has the keys "item", "quantity", and "unit"
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查每个字典是否有“项目”、“数量”和“单位”键
- en: 'if not all(key in item for key in ("item", "quantity", "unit")):'
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if not all(key in item for key in ("item", "quantity", "unit")):'
- en: raise InvalidItemKeys("Item does not have the correct keys")
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise InvalidItemKeys("项目没有正确的键")
- en: Check if the values associated with each key are the correct type
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查与每个键关联的值是否是正确的类型
- en: 'if not isinstance(item["item"], str):'
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if not isinstance(item["item"], str):'
- en: raise InvalidItemName("Item name is not a string")
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise InvalidItemName("项目名称不是字符串")
- en: 'if not isinstance(item["quantity"], int):'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if not isinstance(item["quantity"], int):'
- en: raise InvalidItemQuantity("Item quantity is not an integer")
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise InvalidItemQuantity("项目数量不是整数")
- en: 'if not isinstance(item["unit"], str):'
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if not isinstance(item["unit"], str):'
- en: raise InvalidItemUnit("Item unit is not a string")
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise InvalidItemUnit("项目单位不是字符串")
- en: Check if the values associated with each key are the correct value
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查与每个键关联的值是否是正确的值
- en: 'if item["item"] not in [x["item"] for x in schema_parsed]:'
  id: totrans-218
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if item["item"] not in [x["item"] for x in schema_parsed]:'
- en: raise InvalidItemName("Item name is not in schema")
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise InvalidItemName("项目名称不在模式中")
- en: 'if item["quantity"] >  maximum_quantity:'
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if item["quantity"] >  最大数量:'
- en: raise InvalidItemQuantity(f'''Item quantity is greater than
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise InvalidItemQuantity(f'''项目数量大于
- en: '{maximum_quantity}'''''')'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{最大数量}'''''')'
- en: 'if item["unit"] not in ["pieces", "dozen"]:'
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if item["unit"] not in ["pieces", "dozen"]:'
- en: raise InvalidItemUnit("Item unit is not pieces or dozen")
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise InvalidItemUnit("项目单位不是个或打")
- en: '[PRE26]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Fake responses
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假设响应
- en: fake_response_1 = """
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: fake_response_1 = """
- en: '- item: Apple Slices'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：苹果片'
- en: 'quantity: 5'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：5
- en: 'unit: pieces'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：个
- en: '- item: Eggs'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '- 项目：鸡蛋'
- en: 'quantity: 2'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 数量：2
- en: 'unit: dozen'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 单位：打
- en: '"""'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: fake_response_2 = """
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: fake_response_2 = """
- en: Updated yaml list
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Updated yaml list
- en: '- item: Apple Slices'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '- item: Apple Slices'
- en: 'quantity: 5'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 'quantity: 5'
- en: 'unit: pieces'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 'unit: pieces'
- en: '"""'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: fake_response_3 = """Unmatched"""
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: fake_response_3 = """Unmatched"""
- en: '[PRE27]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Parse the fake responses
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Parse the fake responses
- en: response_1_parsed = yaml.safe_load(fake_response_1)
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: response_1_parsed = yaml.safe_load(fake_response_1)
- en: response_2_parsed = yaml.safe_load(fake_response_2)
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: response_2_parsed = yaml.safe_load(fake_response_2)
- en: response_3_parsed = yaml.safe_load(fake_response_3)
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: response_3_parsed = yaml.safe_load(fake_response_3)
- en: Validate the responses against the schema
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Validate the responses against the schema
- en: 'try:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 'try:'
- en: validate_response(response_1_parsed, schema)
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: validate_response(response_1_parsed, schema)
- en: print("Response 1 is valid")
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print("Response 1 is valid")
- en: 'except Exception as e:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 'except Exception as e:'
- en: print("Response 1 is invalid:", str(e))
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print("Response 1 is invalid:", str(e))
- en: 'try:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 'try:'
- en: validate_response(response_2_parsed, schema)
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: validate_response(response_2_parsed, schema)
- en: print("Response 2 is valid")
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print("Response 2 is valid")
- en: 'except Exception as e:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 'except Exception as e:'
- en: print("Response 2 is invalid:", str(e))
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print("Response 2 is invalid:", str(e))
- en: 'try:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 'try:'
- en: validate_response(response_3_parsed, schema)
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: validate_response(response_3_parsed, schema)
- en: print("Response 3 is valid")
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print("Response 3 is valid")
- en: 'except Exception as e:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 'except Exception as e:'
- en: print("Response 3 is invalid:", str(e))
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print("Response 3 is invalid:", str(e))
- en: Response 1 is valid
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: Response 1 is valid
- en: Response 2 is valid
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: Response 2 is valid
- en: 'Response 3 is invalid: Response is not a list'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 'Response 3 is invalid: Response is not a list'
- en: '[PRE28]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Create a flowchart diagram in mermaid syntax showing a simple food ordering
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: Create a flowchart diagram in mermaid syntax showing a simple food ordering
- en: process that starts with "Choose food" and ends with "Pay for meal."
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: process that starts with "Choose food" and ends with "Pay for meal."
- en: Include steps for "Add food to cart" and "Confirm cart."
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: Include steps for "Add food to cart" and "Confirm cart."
- en: '[PRE29]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: graph TD
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: graph TD
- en: ChooseFood[Choose Food] --> AddToCart[Add to Cart]
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ChooseFood[Choose Food] --> AddToCart[Add to Cart]
- en: AddToCart --> ConfirmCart[Confirm Cart]
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AddToCart --> ConfirmCart[Confirm Cart]
- en: ConfirmCart --> PayForMeal[Pay for Meal]
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ConfirmCart --> PayForMeal[Pay for Meal]
- en: '[PRE30]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Generate a sample CSV data for five students with the following fields:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 'Generate a sample CSV data for five students with the following fields:'
- en: name, age, grade.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: name, age, grade.
- en: '[PRE31]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: name,age,grade
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: name, age, grade
- en: John,16,A
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: John, 16, A
- en: Alex,17,B
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: Alex, 17, B
- en: Emma,16,A
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: Emma, 16, A
- en: Sophia,16,B
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: Sophia, 16, B
- en: Liam,17,A
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: Liam, 17, A
- en: '[PRE32]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Explain the following text as if I was 5 years old. Explain it like I'm 5.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: Explain the following text as if I was 5 years old. Explain it like I'm 5.
- en: 'Text: This is a review regarding different types of cancer treatments.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 'Text: This is a review regarding different types of cancer treatments.'
- en: We aimed at analyzing the tumor microenvironment and the recent trends
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: We aimed at analyzing the tumor microenvironment and the recent trends
- en: for the therapeutic applications and effectiveness for several kinds
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: for the therapeutic applications and effectiveness for several kinds
- en: of cancers. Traditionally the cancer treatment was based on the
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: of cancers. Traditionally the cancer treatment was based on the
- en: neoplastic cells.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: neoplastic cells.
- en: '...(shortened for brevity)...'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '...(shortened for brevity)...'
- en: '[PRE33]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Cancer is a sickness that makes your body's cells grow and divide in a way
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: Cancer is a sickness that makes your body's cells grow and divide in a way
- en: that is not normal. Doctors have different ways to treat cancer, like
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: that is not normal. Doctors have different ways to treat cancer, like
- en: cutting it out, giving you medicine, or using special rays to kill the
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: cutting it out, giving you medicine, or using special rays to kill the
- en: cancer cells...
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: cancer cells...
- en: '[PRE34]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Create some simple text.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: Create some simple text.
- en: '[PRE35]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: The sun gently rises, painting the sky with hues of orange and pink. Birds
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: The sun gently rises, painting the sky with hues of orange and pink. Birds
- en: chirp merrily as they welcome the new day. The cool breeze whispers through
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: chirp merrily as they welcome the new day. The cool breeze whispers through
- en: the trees, carrying the scent of fresh grass and blooming flowers. Life
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: the trees, carrying the scent of fresh grass and blooming flowers. Life
- en: awakens with a sense of tranquility and promise.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: awakens with a sense of tranquility and promise.
- en: '...(shortened for brevity)...'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '...(shortened for brevity)...'
- en: '[PRE36]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Now make the text incredibly complex and hard to read.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: Now make the text incredibly complex and hard to read.
- en: '[PRE37]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In the ethereal realm of celestial ascendancy, wherein the resplendent
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: In the ethereal realm of celestial ascendancy, wherein the resplendent
- en: orb of the sun commences its gradual ascent, an exquisite phenomenon
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: orb of the sun commences its gradual ascent, an exquisite phenomenon
- en: unfolds,engendering a symphony of chromatic brilliance upon the
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: unfolds, engendering a symphony of chromatic brilliance upon the
- en: expansive canopy of the firmament. Avian denizens, endowed with
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: expansive canopy of the firmament. Avian denizens, endowed with
- en: mellifluous voices, bespeak their jubilant salutations, punctuating
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: mellifluous voices, bespeak their jubilant salutations, punctuating
- en: the aural tapestry with notes of felicity. The zephyr, tenderly
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: the aural tapestry with notes of felicity. The zephyr, tenderly
- en: wafting amidst arboreal sentinels, carries upon its gentle currents
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: wafting amidst arboreal sentinels, carries upon its gentle currents
- en: the redolence of verdant blades and blossoming flora.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: the redolence of verdant blades and blossoming flora.
- en: '...(shortened for brevity)...'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '...(shortened for brevity)...'
- en: '[PRE38]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Now transform the text into a simple, easy to read format that's in Spanish
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: Now transform the text into a simple, easy to read format that's in Spanish
- en: ', make sure that it is very easy to understand and read. You must ensure'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: that it is as simple to comprehend as possible.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '- Use simple language.'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '- Make it concise.'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: En un lugar mágico y celestial, cuando el sol empieza a salir, ocurre algo
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: hermoso en el cielo. Los pájaros cantan alegremente, llenando el aire con
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: sus dulces melodías. Una brisa suave sopla entre los árboles, llevando
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: consigo el olor fresco de la naturaleza. Todo cobra vida y promete momentos
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: felices. Nos invita a disfrutar de las cosas simples y a encontrar la
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: felicidad en los pequeños detalles. En este escenario encantador,
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: encontramos paz y aprendemos que hasta los momentos más simples pueden
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: ser mágicos.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Finally translate it back into English.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: In a magical and celestial place, when the sun begins to rise, something
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: beautiful happens in the sky. The birds sing cheerfully, filling the air
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: with their sweet melodies. A gentle breeze blows among the trees, carrying
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: the fresh scent of nature. Everything comes alive and promises happy
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: moments. It invites us to enjoy the simple things and find happiness in the
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: little details. In this enchanting setting, we find peace and learn that
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: even the simplest moments can be magical.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Should I use MongoDB or PostgreSQL for my project?
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: It's difficult to make a recommendation without knowing more about your
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: specific software requirements. Both MongoDB and PostgreSQL have their
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: advantages, but the best choice depends on the specific needs of your
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: project.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Should I use MongoDB or PostgreSQL for my project?
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: Provide a list of requirements that would help you to make an informed
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: and high-quality decision about which database solution I should choose?
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: To make an informed decision between MongoDB and PostgreSQL for your
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: 'project, consider the following requirements:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Data Structure: Evaluate the structure of your data. If your data'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: is highly unstructured or schema-less, MongoDB's flexible document model
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: may be more suitable. On the other hand, if your data has a fixed schema
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: or requires complex relationships, PostgreSQL's relational model might
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: be a better fit.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '...'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: '10\. Cost: Assess the cost implications of each database solution. MongoDB'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: offers both a community edition (free) and a commercial edition with
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: additional features and support.PostgreSQL is open-source and free to use,
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: with optional commercial support available from various vendors.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Should I use MongoDB or PostgreSQL for my project?
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: 'Context:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '- Data Structure: Highly unstructured data with varying document formats'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: 'and no fixed schema. Scalability: Project requires the ability to handle'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: massive amounts of data and distribute it across multiple servers.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: '- ACID Compliance: Strong data consistency and integrity are crucial for'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: the project's financial transactions.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: '- Querying Capabilities: Complex geospatial queries and aggregations on'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: location-based data.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: 'Community and Ecosystem: Active community with numerous third-party'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: libraries and tools specifically tailored for the project's industry.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: '- Data Integrity and Constraints: Enforcing strict foreign key'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: relationships and complex data validation rules.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: '- Transactions and Concurrency: Requires handling high levels of'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: concurrent read and write operations while maintaining data consistency.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: '- Maturity and Stability: Prioritizing a well-established and extensively'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: tested database for long-term stability.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: '- Development and Operational Ease: Agile development approach with a need'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: for rapid prototyping and iterative schema design.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: '- Cost: Budget constraints necessitate using an open-source solution with'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: no additional licensing or support costs.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: If you need more context, please specify what would help you to make
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: a better decision.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Based on these considerations, both MongoDB and PostgreSQL have their
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: strengths, but given the emphasis on strong data consistency, complex
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: querying, and data integrity constraints, PostgreSQL seems to be a more
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: suitable choice for your project.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Analyze the following text and identify core features that will allow
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: further documents to imitate the same style, consistency, and formatting
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: as the document below.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: Provide all of the features as a style writing guide that will be used
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: for future documents.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: 'Analyze the following text:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: Artificial intelligence is rapidly transforming the world around us,
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: opening up new possibilities and revolutionizing industries. From
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: health care to entertainment, AI is making our lives better and more
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: convenient in countless ways. However, with great power comes great
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: responsibility. We must ensure that AI technologies are developed and
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: deployed ethically and responsibly to protect our privacy and uphold our
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: values.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Style Writing Guide:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: Tone of Voice
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: '- Maintain an informative and optimistic tone throughout the document.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: '- Emphasize the positive impact of the subject matter while acknowledging'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: any potential concerns or responsibilities.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: 'Length:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: '...'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: 'Vocabulary:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: '...'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: 'Structure:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: '...'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: 'Content:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '- Focus on the transformative nature and positive impacts of the subject'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: matter.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: '- Highlight specific industries or areas where the subject matter has'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: made a difference.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: '- Acknowledge any associated responsibilities or potential risks,'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: emphasizing the need for ethical and responsible practices.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: Stress the importance of privacy protection and upholding values in
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: relation to the subject matter.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Analyze the following text to identify and list the entities mentioned:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: Artificial intelligence is rapidly transforming the world around us,
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: opening up new possibilities and revolutionizing industries. From
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: health care to entertainment, AI is making our lives better and more
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: convenient in countless ways. However, with great power comes great
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: responsibility. We must ensure that AI technologies are developed
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: and deployed ethically and responsibly to protect our privacy and
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: uphold our values.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Entities:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: '- Artificial Intelligence (AI)'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: '- Health care'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: '- Entertainment'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: '- Privacy'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: '- Values'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Summarize the following text:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: Whereas the party of the first part, hereinafter referred to as the
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: Whereas the party of the first part, hereinafter referred to as the
- en: '"Purchaser," and the party of the second part, hereinafter referred to'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: '"Purchaser," and the party of the second part, hereinafter referred to'
- en: as the "Vendor," being fully cognizant of their respective legal
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: as the "Vendor," being fully cognizant of their respective legal
- en: obligations and responsibilities pursuant to the applicable statutory
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: obligations and responsibilities pursuant to the applicable statutory
- en: provisions and common law doctrines, have duly entered into a legally
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: provisions and common law doctrines, have duly entered into a legally
- en: binding agreement, hereinafter referred to as the "Agreement," for the
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: binding agreement, hereinafter referred to as the "Agreement," for the
- en: purpose of effectuating a transaction involving the transfer of goods,
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: purpose of effectuating a transaction involving the transfer of goods,
- en: hereinafter referred to as the "Goods," between the Purchaser and the
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: hereinafter referred to as the "Goods," between the Purchaser and the
- en: Vendor, subject to the terms and conditions set forth herein, the Parties
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: Vendor, subject to the terms and conditions set forth herein, the Parties
- en: 'do hereby solemnly acknowledge and affirm the following:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 'do hereby solemnly acknowledge and affirm the following:'
- en: '...'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '...'
- en: '[PRE53]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: This is a legally binding agreement between the Purchaser and the Vendor
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: This is a legally binding agreement between the Purchaser and the Vendor
- en: for the transfer of goods. The agreement incorporates the recitals as an
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: for the transfer of goods. The agreement incorporates the recitals as an
- en: integral part, but in case of any conflict, the operative provisions of the
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: integral part, but in case of any conflict, the operative provisions of the
- en: agreement prevail. The interpretation clause states that singular words
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: agreement prevail. The interpretation clause states that singular words
- en: include the plural and vice versa, and words referring to a gender include
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: include the plural and vice versa, and words referring to a gender include
- en: all genders. References to statutory provisions include any amendments or
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: all genders. References to statutory provisions include any amendments or
- en: replacements.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: replacements.
- en: '[PRE54]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The local council has decided to increase the budget for education by 10%
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: The local council has decided to increase the budget for education by 10%
- en: this year, a move that has been welcomed by parents and teachers alike. The
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: this year, a move that has been welcomed by parents and teachers alike. The
- en: additional funds will be used to improve school infrastructure, hire more
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: additional funds will be used to improve school infrastructure, hire more
- en: teachers, and provide better resources for students. However, some critics
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: teachers, and provide better resources for students. However, some critics
- en: argue that the increase is not enough to address the growing demands of the
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: argue that the increase is not enough to address the growing demands of the
- en: education system.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: education system.
- en: '[PRE55]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '["The", "local", "council", "has", "decided", "to", "increase", "the",'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '["The", "local", "council", "has", "decided", "to", "increase", "the",'
- en: '"budget", ...]'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: '"budget", ...]'
- en: '[PRE56]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '["""The local council has decided to increase the budget for education'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: '["""The local council has decided to increase the budget for education'
- en: by 10% this year, a move that has been welcomed by parents and teachers alike.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: by 10% this year, a move that has been welcomed by parents and teachers alike.
- en: '""",'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '""",'
- en: '"""The additional funds will be used to improve school infrastructure,'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '"""The additional funds will be used to improve school infrastructure,'
- en: hire more teachers, and provide better resources for students.""",
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: hire more teachers, and provide better resources for students.""",
- en: '""""However, some critics argue that the increase is not enough to'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '""""However, some critics argue that the increase is not enough to'
- en: address the growing demands of the education system."""]
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: address the growing demands of the education system."""]
- en: '[PRE57]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: import spacy
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: import spacy
- en: nlp = spacy.load("en_core_web_sm")
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: nlp = spacy.load("en_core_web_sm")
- en: text = "This is a sentence. This is another sentence."
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: text = "This is a sentence. This is another sentence."
- en: doc = nlp(text)
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: doc = nlp(text)
- en: 'for sent in doc.sents:'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 'for sent in doc.sents:'
- en: print(sent.text)
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print(sent.text)
- en: '[PRE58]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: This is a sentence.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: This is a sentence.
- en: This is another sentence.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: This is another sentence.
- en: '[PRE59]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'with open("hubspot_blog_post.txt", "r") as f:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 'with open("hubspot_blog_post.txt", "r") as f:'
- en: text = f.read()
  id: totrans-498
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: text = f.read()
- en: 'chunks = [text[i : i + 200] for i in range(0, len(text), 200)]'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 'chunks = [text[i : i + 200] for i in range(0, len(text), 200)]'
- en: 'for chunk in chunks:'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 'for chunk in chunks:'
- en: print("-" * 20)
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print("-" * 20)
- en: print(chunk)
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print(chunk)
- en: '[PRE60]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: search engine optimization strategy for many local businesses is an optimized
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: search engine optimization strategy for many local businesses is an optimized
- en: Google My Business profile to appear in local search results when people look
    for
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: Google My Business profile to appear in local search results when people look
    for
- en: products or services related to what yo
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: products or services related to what yo
- en: '--------------------'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '--------------------'
- en: u offer.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: u offer.
- en: For Keeps Bookstore, a local bookstore in Atlanta, GA, has optimized its
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: For Keeps Bookstore, a local bookstore in Atlanta, GA, has optimized its
- en: Google My Business profile for local SEO so it appears in queries for
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: Google My Business profile for local SEO so it appears in queries for
- en: “atlanta bookstore.”
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: “atlanta bookstore.”
- en: '--------------------'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: '--------------------'
- en: '...(shortened for brevity)...'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: '...(shortened for brevity)...'
- en: '[PRE61]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'def sliding_window(text, window_size, step_size):'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 'def sliding_window(text, window_size, step_size):'
- en: 'if window_size > len(text) or step_size < 1:'
  id: totrans-516
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if window_size > len(text) or step_size < 1:'
- en: return []
  id: totrans-517
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: return []
- en: return [text[i:i+window_size] for i
  id: totrans-518
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return [text[i:i+window_size] for i
- en: in range(0, len(text) - window_size + 1, step_size)]
  id: totrans-519
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: in range(0, len(text) - window_size + 1, step_size)]
- en: text = "This is an example of sliding window text chunking."
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: text = "这是一个滑动窗口文本分块的示例。"
- en: window_size = 20
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: window_size = 20
- en: step_size = 5
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: step_size = 5
- en: chunks = sliding_window(text, window_size, step_size)
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: chunks = sliding_window(text, window_size, step_size)
- en: 'for idx, chunk in enumerate(chunks):'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 'for idx, chunk in enumerate(chunks):'
- en: 'print(f"Chunk {idx + 1}: {chunk}")'
  id: totrans-525
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print(f"第 {idx + 1} 部分：{chunk}")
- en: '[PRE62]'
  id: totrans-526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Chunk 1: This is an example o'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 第1部分：这是一个示例
- en: 'Chunk 2: is an example of sli'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 第2部分：这是一个滑动窗口示例
- en: 'Chunk 3:  example of sliding'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 第3部分：滑动窗口示例
- en: 'Chunk 4: ple of sliding windo'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 第4部分：滑动窗口示例
- en: 'Chunk 5: f sliding window tex'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 第5部分：滑动窗口文本
- en: 'Chunk 6: ding window text chu'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 第6部分：定窗口文本分块
- en: 'Chunk 7: window text chunking'
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 第7部分：窗口文本分块
- en: '[PRE63]'
  id: totrans-534
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '1\. Import the package:'
  id: totrans-535
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 导入包：
- en: import tiktoken
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: import tiktoken
- en: 2\. Load an encoding with tiktoken.get_encoding()
  id: totrans-537
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 使用 tiktoken.get_encoding() 加载编码
- en: encoding = tiktoken.get_encoding("cl100k_base")
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
  zh: encoding = tiktoken.get_encoding("cl100k_base")
- en: 3\. Turn some text into tokens with encoding.encode()
  id: totrans-539
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 将一些文本转换为标记使用 encoding.encode()
- en: while turning tokens into text with encoding.decode()
  id: totrans-540
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: while 将标记转换为文本使用 encoding.decode()
- en: print(encoding.encode("Learning how to use Tiktoken is fun!"))
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: print(encoding.encode("学习如何使用 Tiktoken 是有趣的！"))
- en: print(encoding.decode([1061, 15009, 374, 264, 2294, 1648,
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: print(encoding.decode([1061, 15009, 374, 264, 2294, 1648,
- en: 311, 4048, 922, 15592, 0]))
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 311, 4048, 922, 15592, 0]))
- en: '[48567, 1268, 311, 1005, 73842, 5963, 374, 2523, 0]'
  id: totrans-544
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[48567, 1268, 311, 1005, 73842, 5963, 374, 2523, 0]'
- en: '"Data engineering is a great way to learn about AI!"'
  id: totrans-545
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '"数据工程是学习人工智能的绝佳方式！"'
- en: '[PRE64]'
  id: totrans-546
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'def count_tokens(text_string: str, encoding_name: str) -> int:'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 'def count_tokens(text_string: str, encoding_name: str) -> int:'
- en: '"""'
  id: totrans-548
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""'
- en: Returns the number of tokens in a text string using a given encoding.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 使用给定的编码返回文本字符串中的标记数。
- en: 'Args:'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 'Args:'
- en: 'text: The text string to be tokenized.'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 'text: 要进行标记化的文本字符串。'
- en: 'encoding_name: The name of the encoding to be used for tokenization.'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 'encoding_name: 要用于标记化的编码的名称。'
- en: 'Returns:'
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: '返回值:'
- en: The number of tokens in the text string.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 文本字符串中的标记数。
- en: 'Raises:'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 'Raises:'
- en: 'ValueError: If the encoding name is not recognized.'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 'ValueError: 如果编码名称不被识别。'
- en: '"""'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: '"""'
- en: encoding = tiktoken.get_encoding(encoding_name)
  id: totrans-558
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: encoding = tiktoken.get_encoding(encoding_name)
- en: num_tokens = len(encoding.encode(text_string))
  id: totrans-559
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: num_tokens = len(encoding.encode(text_string))
- en: return num_tokens
  id: totrans-560
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return num_tokens
- en: 4\. Use the function to count the number of tokens in a text string.
  id: totrans-561
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 使用该函数来计算文本字符串中的标记数。
- en: text_string = "Hello world! This is a test."
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: text_string = "Hello world! This is a test."
- en: print(count_tokens(text_string, "cl100k_base"))
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: print(count_tokens(text_string, "cl100k_base"))
- en: '[PRE65]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'def num_tokens_from_messages(messages, model="gpt-3.5-turbo-0613"):'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 'def num_tokens_from_messages(messages, model="gpt-3.5-turbo-0613"):'
- en: '"""Return the number of tokens used by a list of messages."""'
  id: totrans-566
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"""返回由消息列表使用的标记数。"""'
- en: 'try:'
  id: totrans-567
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'try:'
- en: encoding = tiktoken.encoding_for_model(model)
  id: totrans-568
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: encoding = tiktoken.encoding_for_model(model)
- en: 'except KeyError:'
  id: totrans-569
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'except KeyError:'
- en: 'print("Warning: model not found. Using cl100k_base encoding.")'
  id: totrans-570
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: print("警告：找不到模型。使用 cl100k_base 编码。")
- en: encoding = tiktoken.get_encoding("cl100k_base")
  id: totrans-571
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: encoding = tiktoken.get_encoding("cl100k_base")
- en: if model in {
  id: totrans-572
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: if model in {
- en: '"gpt-3.5-turbo-0613",'
  id: totrans-573
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"gpt-3.5-turbo-0613",'
- en: '"gpt-3.5-turbo-16k-0613",'
  id: totrans-574
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"gpt-3.5-turbo-16k-0613",'
- en: '"gpt-4-0314",'
  id: totrans-575
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"gpt-4-0314",'
- en: '"gpt-4-32k-0314",'
  id: totrans-576
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"gpt-4-32k-0314",'
- en: '"gpt-4-0613",'
  id: totrans-577
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"gpt-4-0613",'
- en: '"gpt-4-32k-0613",'
  id: totrans-578
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"gpt-4-32k-0613",'
- en: '}:'
  id: totrans-579
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}:'
- en: tokens_per_message = 3
  id: totrans-580
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: tokens_per_message = 3
- en: tokens_per_name = 1
  id: totrans-581
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: tokens_per_name = 1
- en: 'elif model == "gpt-3.5-turbo-0301":'
  id: totrans-582
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'elif model == "gpt-3.5-turbo-0301":'
- en: 'tokens_per_message = 4  # every message follows'
  id: totrans-583
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'tokens_per_message = 4  # 每条消息后跟'
- en: <|start|>{role/name}\n{content}<|end|>\n
  id: totrans-584
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: <|start|>{role/name}\n{content}<|end|>\n
- en: 'tokens_per_name = -1  # if there''s a name, the role is omitted'
  id: totrans-585
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'tokens_per_name = -1  # 如果有名称，则省略角色'
- en: 'elif "gpt-3.5-turbo" in model:'
  id: totrans-586
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'elif "gpt-3.5-turbo" in model:'
- en: 'print(''''''Warning: gpt-3.5-turbo may update over time. Returning'
  id: totrans-587
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: print('''警告：gpt-3.5-turbo 可能会随时间更新。返回
- en: num tokens assuming gpt-3.5-turbo-0613.''')
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: num tokens assuming gpt-3.5-turbo-0613。”
- en: return num_tokens_from_messages(messages, model="gpt-3.5-turbo-0613")
  id: totrans-589
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: return num_tokens_from_messages(messages, model="gpt-3.5-turbo-0613")
- en: 'elif "gpt-4" in model:'
  id: totrans-590
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'elif "gpt-4" in model:'
- en: 'print(''''''Warning: gpt-4 may update over time.'
  id: totrans-591
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: print('''警告：gpt-4 可能会随时间更新。返回
- en: Returning num tokens assuming gpt-4-0613.''')
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 假设使用 gpt-4-0613 返回标记数。")
- en: return num_tokens_from_messages(messages, model="gpt-4-0613")
  id: totrans-593
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: return num_tokens_from_messages(messages, model="gpt-4-0613")
- en: 'else:'
  id: totrans-594
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'else:'
- en: raise NotImplementedError(
  id: totrans-595
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: raise NotImplementedError(
- en: f"""num_tokens_from_messages() is not implemented for model
  id: totrans-596
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: f"""num_tokens_from_messages() 对于模型
- en: '{model}."""'
  id: totrans-597
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{model}。”'
- en: )
  id: totrans-598
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: )
- en: num_tokens = 0
  id: totrans-599
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: num_tokens = 0
- en: 'for message in messages:'
  id: totrans-600
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'for message in messages:'
- en: num_tokens += tokens_per_message
  id: totrans-601
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: num_tokens += tokens_per_message
- en: 'for key, value in message.items():'
  id: totrans-602
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'for key, value in message.items():'
- en: num_tokens += len(encoding.encode(value))
  id: totrans-603
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: num_tokens += len(encoding.encode(value))
- en: 'if key == "name":'
  id: totrans-604
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'if key == "name":'
- en: num_tokens += tokens_per_name
  id: totrans-605
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: num_tokens += tokens_per_name
- en: 'num_tokens += 3  # every reply is primed with'
  id: totrans-606
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'num_tokens += 3  # 每个回复都预先填充'
- en: <|start|>assistant<|message|>
  id: totrans-607
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: <|start|>assistant<|message|>
- en: return num_tokens
  id: totrans-608
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: return num_tokens
- en: '[PRE66]'
  id: totrans-609
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: example_messages = [
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: example_messages = [
- en: '{'
  id: totrans-611
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{'
- en: '"role": "system",'
  id: totrans-612
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"role": "system",'
- en: '"content": ''''''You are a helpful, pattern-following assistant that'
  id: totrans-613
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"content": ''''''您是一个有帮助的、遵循模式的助手，它'
- en: translates corporate jargon into plain English.''',
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 将企业术语翻译成通俗易懂的英语。''',
- en: '},'
  id: totrans-615
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '},'
- en: '{'
  id: totrans-616
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{'
- en: '"role": "system",'
  id: totrans-617
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"role": "system",'
- en: '"name": "example_user",'
  id: totrans-618
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"name": "example_user",'
- en: '"content": "New synergies will help drive top-line growth.",'
  id: totrans-619
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"content": "新的协同作用将有助于推动收入增长。",'
- en: '},'
  id: totrans-620
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '},'
- en: '{'
  id: totrans-621
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{'
- en: '"role": "system",'
  id: totrans-622
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"role": "system",'
- en: '"name": "example_assistant",'
  id: totrans-623
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"name": "example_assistant",'
- en: '"content": "Things working well together will increase revenue.",'
  id: totrans-624
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"content": "事物协同工作将增加收入。",'
- en: '},'
  id: totrans-625
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '},'
- en: '{'
  id: totrans-626
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{'
- en: '"role": "system",'
  id: totrans-627
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"role": "system",'
- en: '"name": "example_user",'
  id: totrans-628
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"name": "example_user",'
- en: '"content": ''''''Let''s circle back when we have more bandwidth to touch'
  id: totrans-629
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"content": ''''''当我们有更多带宽来接触'
- en: base on opportunities for increased leverage.''',
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 基于增加杠杆的机会。''',
- en: '},'
  id: totrans-631
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '},'
- en: '{'
  id: totrans-632
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{'
- en: '"role": "system",'
  id: totrans-633
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"role": "system",'
- en: '"name": "example_assistant",'
  id: totrans-634
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"name": "example_assistant",'
- en: '"content": ''''''Let''s talk later when we''re less busy about how to'
  id: totrans-635
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"content": ''''''当我们不那么忙碌时，我们可以稍后再讨论如何'
- en: do better.''',
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 做得更好。''',
- en: '},'
  id: totrans-637
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '},'
- en: '{'
  id: totrans-638
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{'
- en: '"role": "user",'
  id: totrans-639
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"role": "user",'
- en: '"content": ''''''This late pivot means we don''t have'
  id: totrans-640
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '"content": ''''''这种晚期的转变意味着我们没有'
- en: time to boil the ocean for the client deliverable.''',
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: time to boil the ocean for the client deliverable.''',
- en: '},'
  id: totrans-642
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '},'
- en: ']'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: ']'
- en: 'for model in ["gpt-3.5-turbo-0301", "gpt-4-0314"]:'
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: 'for model in ["gpt-3.5-turbo-0301", "gpt-4-0314"]:'
- en: print(model)
  id: totrans-645
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print(model)
- en: example token count from the function defined above
  id: totrans-646
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从上面定义的函数中获取的示例token计数
- en: print(f'''{num_tokens_from_messages(example_messages, model)} `prompt tokens
    counted by num_tokens_from_messages().'''``)`
  id: totrans-647
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: print(f'''{num_tokens_from_messages(example_messages, model)} `prompt tokens
    counted by num_tokens_from_messages().'''``)`
- en: '[PRE67]`# Sentiment Analysis    *Sentiment analysis* is a widely used NLP technique
    that helps in identifying, extracting, and understanding the emotions, opinions,
    or sentiments expressed in a piece of text. By leveraging the power of LLMs like
    GPT-4, sentiment analysis has become an essential tool for businesses, researchers,
    and developers across various industries.    The primary goal of sentiment analysis
    is to determine the attitude or emotional tone conveyed in a text, whether it’s
    positive, negative, or neutral. This information can provide valuable insights
    into consumer opinions about products or services, help monitor brand reputation,
    and even assist in predicting market trends.    The following are several prompt
    engineering techniques for creating effective sentiment analysis prompts:    Input:    [PRE68]    Output:    [PRE69]    Although
    GPT-4 identifies a “mixed tone,” the outcome is a result of several shortcomings
    in the prompt:    Lack of clarity      The prompt does not clearly define the
    desired output format.      Insufficient examples      The prompt does not include
    any examples of positive, negative, or neutral sentiments, which could help guide
    the LLM in understanding the distinctions between them.      No guidance on handling
    mixed sentiments      The prompt does not specify how to handle cases where the
    text contains a mix of positive and negative sentiments.      Input:    [PRE70]    Output:    [PRE71]    This
    prompt is much better because it:    Provides clear instructions      The prompt
    clearly states the task, which is to classify the sentiment of the given text
    into one of three categories: positive, negative, or neutral.      Offers examples      The
    prompt provides examples for each of the sentiment categories, which helps in
    understanding the context and desired output.      Defines the output format      The
    prompt specifies that the output should be a single word, ensuring that the response
    is concise and easy to understand.      ## Techniques for Improving Sentiment
    Analysis    To enhance sentiment analysis accuracy, preprocessing the input text
    is a vital step. This involves the following:    Special characters removal      Exceptional
    characters such as emojis, hashtags, and punctuation may skew the rule-based sentiment
    algorithm’s judgment. Besides, these characters might not be recognized by machine
    learning and deep learning models, resulting in misclassification.      Lowercase
    conversion      Converting all the characters to lowercase aids in creating uniformity.
    For instance, words like *Happy* and *happy* are treated as different words by
    models, which can cause duplication and inaccuracies.      Spelling correction      Spelling
    errors can cause misinterpretation and misclassification. Creating a spell-check
    pipeline can significantly reduce such errors and improve results.      For industry-
    or domain-specific text, embedding domain-specific content in the prompt helps
    in navigating the LLM’s sense of the text’s framework and sentiment. It enhances
    accuracy in the classification and provides a heightened understanding of particular
    jargon and expressions.    ## Limitations and Challenges in Sentiment Analysis    Despite
    the advancements in LLMs and the application of prompt engineering techniques,
    sentiment analysis still faces some limitations and challenges:    Handling sarcasm
    and irony      Detecting sarcasm and irony in text can be difficult for LLMs,
    as it often requires understanding the context and subtle cues that humans can
    easily recognize. Misinterpreting sarcastic or ironic statements may lead to inaccurate
    sentiment classification.      Identifying context-specific sentiment      Sentiment
    analysis can be challenging when dealing with context-specific sentiments, such
    as those related to domain-specific jargon or cultural expressions. LLMs may struggle
    to accurately classify sentiments in these cases without proper guidance or domain-specific
    examples.      # Least to Most    The *least to most* technique in prompt engineering
    is a powerful method for sequentially generating or extracting increasingly detailed
    knowledge on a given topic. This method is particularly effective when dealing
    with complex subjects or when a high level of detail is necessary.    Least to
    most uses a *chain* of prompts where each new prompt is based on the last answer.
    This step-by-step approach helps gather more detailed information each time, making
    it easier to dive deeper into any topic.    This technique can also be applied
    to code generation, as demonstrated in a Flask `Hello World` app example.    ##
    Planning the Architecture    Before diving into the architecture, let’s briefly
    understand what Flask is. [Flask](https://oreil.ly/7N-bs) is a lightweight web
    application framework in Python, widely used for creating web applications quickly
    and with minimal code. (Flask is only used for demonstration purposes here and
    isn’t included within the [*requirements.txt* file](https://oreil.ly/TRK0i) for
    the book.    Now, let’s ask an LLM to outline the basic architecture for a simple
    Flask “Hello World” application.    Input:    [PRE72]    Output:    [PRE73]    ##
    Coding Individual Functions    Before coding, let’s clarify what a Flask route
    is: it’s a function linked to a URL pattern that determines what users see on
    a specific web page. Next, we’ll provide the code snippet for a simple “Hello
    World” route in Flask.    Input:    [PRE74]    Output:    [PRE75]    In this code,
    we import the Flask module and create a Flask application instance named `app`.
    We then define a route using the `@app.route` decorator, specifying the root URL
    path `''/''`. The `hello_world` function is associated with this route, and it
    returns the string `''Hello, World!''` as the response.    The Flask application
    will start by calling `app.run()` when your Python script is executed directly.    ##
    Adding Tests    Finally, let’s ask it to generate a test case for the “Hello World”
    route in the Flask application.    Input:    [PRE76]    Output:    [PRE77]    By
    using the least to most prompt technique, you can gradually build up the knowledge
    and understanding required for the task at hand.    ## Benefits of the Least to
    Most Technique    This method is particularly useful for complex tasks, as it
    allows an LLM to generate relevant knowledge that will subsequently be used as
    context for future tasks.    Let’s dive deeper into the benefits of using this
    approach in various other scenarios:    Progressive exploration      Breaking
    a complex problem into smaller tasks allows an LLM to provide more detailed and
    accurate information at each step. This approach is especially helpful when working
    with a new subject matter or a multifaceted problem.      Flexibility      The
    least to most technique offers flexibility in addressing different aspects of
    a problem. It enables you to pivot, explore alternative solutions, or dive deeper
    into specific areas as needed.      Improved comprehension      By breaking down
    a task into smaller steps, an LLM can deliver information in a more digestible
    format, making it easier for you to understand and follow.      Collaborative
    learning      This technique promotes collaboration between you and an LLM, as
    it encourages an iterative process of refining the output and adjusting your responses
    to achieve the desired outcome.      ## Challenges with the Least to Most Technique    Overreliance
    on previously generated knowledge      Using previous chat history to store the
    state may lead to larger tasks forgetting their initial tasks/outputs due to limitations
    in context length.      Dependence on prior prompts      Since each prompt is
    built upon preceding outputs, it is imperative to ensure that the quality and
    responses of previous prompts provide ample information for the next step.      #
    Evaluate Quality    In the process of designing prompts, make sure to evaluate
    the quality of each prior LLM response. The performance of the next task depends
    upon the quality of information provided by the preceding one.    # Role Prompting    *Role
    prompting* is a technique in which the AI is given a specific role or character
    to assume while generating a response. This helps guide the AI’s response style
    and content to better align with the user’s needs or desired outcome.    ######
    Note    [Awesome ChatGPT prompts](https://oreil.ly/8pf40) provides an extensive
    list of role prompts that you can use.    Let’s ask ChatGPT to take on the role
    of a tech reviewer for MongoDB.    Input:    [PRE78]    Output:    [PRE79]    The
    prompt is an excellent example of role prompting, as it clearly defines the role
    the AI should assume (a tech reviewer) and sets expectations for the type of response
    desired (an in-depth review of MongoDB).    # Give Direction    When crafting
    prompts, consider assigning a specific role to the AI. This sets the proper context
    for the response, creating a more focused and relevant output.    # Benefits of
    Role Prompting    Role prompting helps narrow down the AI’s responses, ensuring
    more focused, contextually appropriate, and tailored results. It can also enhance
    creativity by pushing the AI to think and respond from unique perspectives.    #
    Challenges of Role Prompting    Role prompting can pose certain challenges. There
    might be potential risks for bias or stereotyping based on the role assigned.
    Assigning stereotyped roles can lead to generating biased responses, which could
    harm usability or offend individuals. Additionally, maintaining consistency in
    the role throughout an extended interaction can be difficult. The model might
    drift off-topic or respond with information irrelevant to the assigned role.    #
    Evaluate Quality    Consistently check the quality of the LLM’s responses, especially
    when role prompting is in play. Monitor if the AI is sticking to the role assigned
    or if it is veering off-topic.    # When to Use Role Prompting    Role prompting
    is particularly useful when you want to:    Elicit specific expertise      If
    you need a response that requires domain knowledge or specialized expertise, role
    prompting can help guide the LLM to generate more informed and accurate responses.      Tailor
    response style      Assigning a role can help an LLM generate responses that match
    a specific tone, style, or perspective, such as a formal, casual, or humorous
    response.      Encourage creative responses      Role prompting can be used to
    create fictional scenarios or generate imaginative answers by assigning roles
    like a storyteller, a character from a novel, or a historical figure.    *   *Explore
    diverse perspectives*: If you want to explore different viewpoints on a topic,
    role prompting can help by asking the AI to assume various roles or personas,
    allowing for a more comprehensive understanding of the subject.           *   *Enhance
    user engagement*: Role prompting can make interactions more engaging and entertaining
    by enabling an LLM to take on characters or personas that resonate with the user.                If
    you’re using OpenAI, then the best place to add a role is within the `System Message`
    for chat models.    # GPT Prompting Tactics    So far you’ve already covered several
    prompting tactics, including asking for context, text style bundling, least to
    most, and role prompting.    Let’s cover several more tactics, from managing potential
    hallucinations with appropriate reference text, to providing an LLM with critical
    *thinking time*, to understanding the concept of *task decomposition*—we have
    plenty for you to explore.    These methodologies have been designed to significantly
    boost the precision of your AI’s output and are recommended by [OpenAI](https://oreil.ly/QZE8n).
    Also, each tactic utilizes one or more of the prompt engineering principles discussed
    in [Chapter 1](ch01.html#five_principles_01).    ## Avoiding Hallucinations with
    Reference    The first method for avoiding text-based hallucinations is to instruct
    the model to *only answer using reference text.*    By supplying an AI model with
    accurate and relevant information about a given query, the model can be directed
    to use this information to generate its response.    Input:    [PRE80]    Output:    [PRE81]    If
    you were to ask the same reference text this question:    Input:    [PRE82]    Output:    [PRE83]    #
    Give Direction and Specify Format    The preceding prompt is excellent as it both
    instructs the model on how to find answers and also sets a specific response format
    for any unanswerable questions.    Considering the constrained context windows
    of GPTs, a method for dynamically retrieving information relevant to the asked
    query might be necessary to utilize this strategy.    Another approach is to direct
    the model to *incorporate references* from a given text in its response. When
    the input is enhanced with relevant information, the model can be guided to include
    citations in its responses by referring to sections of the supplied documents.
    This approach has the added benefit that citations in the output can be *authenticated
    automatically by matching strings* within the given documents.    Input:    [PRE84]    Output:    [PRE85]    ##
    Give GPTs “Thinking Time”    Often, by explicitly guiding an LLM to *derive solutions
    from first principles* before reaching a verdict, you can garner more accurate
    responses. Providing an LLM with *thinking time* can often lead to better results.    Input:    [PRE86]    Output:    [PRE87]    In
    some cases, when using GPT-4 or other generative AI models, you may not want the
    model’s reasoning process to be visible to the user.    You can achieve this by
    asking an LLM to *generate an inner monologue*. This is particularly useful in
    tutoring applications, where revealing the model’s reasoning might give away the
    solution prematurely.    ## The Inner Monologue Tactic    The *inner monologue
    tactic* instructs the model to structure parts of the output that should be hidden
    from the user in a specific format. This makes it easy to remove these parts before
    presenting the final output to the user.    Here’s how you can utilize this tactic
    to answer user queries effectively.    Input:    [PRE88]    Output:    [PRE89]    ##
    Self-Eval LLM Responses    Another tactic you can use is to *critque a generated
    LLM output* and ask whether the LLM missed any information or important facts.
    You’re essentially asking an LLM to *evaluate itself* based on its previous output.    First,
    create a prompt to generate a `"Hello World"` function.    Input:    [PRE90]    Output:    [PRE91]    The
    LLM returns a simple Python function called `print_hello_world()` that prints
    the traditional “Hello, World!” greeting.    Then make a second LLM request with
    the previous chat history, asking for the initial output to be improved.    Input:    [PRE92]    Output:    [PRE93]    Consequently
    GPT-4 returns an upgraded version of the function, now furnished with Python type
    hints and a default argument. This enriches the function with greater flexibility,
    allowing it to print not just `"Hello, World!"` but any user-specified message.    These
    prompt-response exchanges illustrate how you can easily refine generated LLM outputs
    until you’re satisfied with the final output.    ###### Note    It’s possible
    to critique an LLM’s response multiple times, until no further refinement is provided
    by the LLM.    # Classification with LLMs    Classifying, in the context of AI,
    refers to the process of predicting the class or category of a given data point
    or sample. It’s a common task in machine learning where models are trained to
    assign predefined labels to unlabeled data based on learned patterns.    LLMs
    are powerful assets when it comes to classification, even with zero or only a
    small number of examples provided within a prompt. Why? That’s because LLMs, like
    GPT-4, have been previously trained on an extensive dataset and now possess a
    degree of reasoning.    There are two overarching strategies in solving classification
    problems with LLMs: *zero-shot learning* and *few-shot learning*.    Zero-shot
    learning      In this process, the LLM classifies data with exceptional accuracy,
    without the aid of any prior specific examples. It’s akin to acing a project without
    any preparation—impressive, right?      Few-shot learning      Here, you provide
    your LLM with a small number of examples. This strategy can significantly influence
    the structure of your output format and enhance the overall classification accuracy.      Why
    is this groundbreaking for you?    Leveraging LLMs lets you sidestep lengthy processes
    that traditional machine learning processes demand. Therefore, you can quickly
    prototype a classification model, determine a base level accuracy, and create
    immediate business value.    ###### Warning    Although an LLM can perform classification,
    depending upon your problem and training data you might find that using a traditional
    machine learning process could yield better results.    # Building a Classification
    Model    Let’s explore a few-shot learning example to determine the sentiment
    of text into either `''Compliment''`, `''Complaint''`, or `''Neutral''`.    [PRE94]    [PRE95]    Several
    good use cases for LLM classification include:    Customer reviews      Classify
    user reviews into categories like “Positive,” “Negative,” or “Neutral.” Dive deeper
    by further identifying subthemes such as “Usability,” “Customer Support,” or “Price.”      Email
    filtering      Detect the intent or purpose of emails and classify them as “Inquiry,”
    “Complaint,” “Feedback,” or “Spam.” This can help businesses prioritize responses
    and manage communications efficiently.      Social media sentiment analysis      Monitor
    brand mentions and sentiment across social media platforms. Classify posts or
    comments as “Praise,” “Critic,” “Query,” or “Neutral.” Gain insights into public
    perception and adapt marketing or PR strategies accordingly.      News article
    categorization      Given the vast amount of news generated daily, LLMs can classify
    articles by themes or topics such as “Politics,” “Technology,” “Environment,”
    or “Entertainment.”      Résumé screening      For HR departments inundated with
    résumés, classify them based on predefined criteria like “Qualified,” “Overqualified,”
    “Underqualified,” or categorize by expertise areas such as “Software Development,”
    “Marketing,” or “Sales.”      ###### Warning    Be aware that exposing emails,
    résumés, or sensitive data does run the risk of data being leaked into OpenAI’s
    future models as training data.    # Majority Vote for Classification    Utilizing
    multiple LLM requests can help in reducing the variance of your classification
    labels. This process, known as *majority vote*, is somewhat like choosing the
    most common fruit out of a bunch. For instance, if you have 10 pieces of fruit
    and 6 out of them are apples, then apples are the majority. The same principle
    goes for choosing the majority vote in classification labels.    By soliciting
    several classifications and taking the *most frequent classification*, you’re
    able to reduce the impact of potential outliers or unusual interpretations from
    a single model inference. However, do bear in mind that there can be significant
    downsides to this approach, including the increased time required and cost for
    multiple API calls.    Let’s classify the same piece of text three times, and
    then take the majority vote:    [PRE96]    Calling the `most_frequent_classification(responses)`
    function should pinpoint `''Neutral''` as the dominant sentiment. You’ve now learned
    how to use the OpenAI package for majority vote classification.    # Criteria
    Evaluation    In [Chapter 1](ch01.html#five_principles_01), a human-based evaluation
    system was used with a simple thumbs-up/thumbs-down rating system to identify
    how often a response met our expectations. Rating manually can be expensive and
    tedious, requiring a qualified human to judge quality or identify errors. While
    this work can be outsourced to low-cost raters on services such as [Mechanical
    Turk](https://www.mturk.com), designing such a task in a way that gets valid results
    can itself be time-consuming and error prone. One increasingly common approach
    is to use a more sophisticated LLM to evaluate the responses of a smaller model.    The
    evidence is mixed on whether LLMs can act as effective evaluators, with some studies
    [claiming LLMs are human-level evaluators](https://oreil.ly/nfc3f) and others
    [identifying inconsistencies in how LLMs evaluate](https://oreil.ly/ykkzY). In
    our experience, GPT-4 is a useful evaluator with consistent results across a diverse
    set of tasks. In particular, GPT-4 is effective and reliable in evaluating the
    responses from smaller, less sophisticated models like GPT-3.5-turbo. In the example
    that follows, we generate concise and verbose examples of answers to a question
    using GPT-3.5-turbo, ready for rating with GPT-4.    Input:    [PRE97]    Output:    [PRE98]    This
    script is a Python program that interacts with the OpenAI API to generate and
    evaluate responses based on their conciseness. Here’s a step-by-step explanation:    1.  `responses
    = []` creates an empty list named `responses` to store the responses generated
    by the OpenAI API.           2.  The `for` loop runs 10 times, generating a response
    for each iteration.           3.  Inside the loop, `style` is determined based
    on the current iteration number (`i`). It alternates between “concise” and “verbose”
    for even and odd iterations, respectively.           4.  Depending on the `style`,
    a `prompt` string is formatted to ask, “What is the meaning of life?” in either
    a concise or verbose manner.           5.  `response = client.chat.completions.create(...)`
    makes a request to the OpenAI API to generate a response based on the `prompt`.
    The model used here is specified as “gpt-3.5-turbo.”           6.  The generated
    response is then stripped of any leading or trailing whitespace and added to the
    `responses` list.           7.  `system_prompt = """You are assessing..."""` sets
    up a prompt used for evaluating the conciseness of the generated responses.           8.  `ratings
    = []` initializes an empty list to store the conciseness ratings.           9.  Another
    `for` loop iterates over each response in `responses`.           10.  For each
    response, the script sends it along with the `system_prompt` to the OpenAI API,
    requesting a conciseness evaluation. This time, the model used is “gpt-4.”           11.  The
    evaluation rating (either 1 for concise or 0 for not concise) is then stripped
    of whitespace and added to the `ratings` list.           12.  The final `for`
    loop iterates over the `ratings` list. For each rating, it prints the `style`
    of the response (either “concise” or “verbose”) and its corresponding conciseness
    `rating`.              For simple ratings like conciseness, GPT-4 performs with
    near 100% accuracy; however, for more complex ratings, it’s important to spend
    some time evaluating the evaluator. For example, by setting test cases that contain
    an issue, as well as test cases that do not contain an issue, you can identify
    the accuracy of your evaluation metric. An evaluator can itself be evaluated by
    counting the number of false positives (when the LLM hallucinates an issue in
    a test case that is known not to contain an issue), as well as the number of false
    negatives (when the LLM misses an issue in a test case that is known to contain
    an issue). In our example we generated the concise and verbose examples, so we
    can easily check the rating accuracy, but in more complex examples you may need
    human evaluators to validate the ratings.    # Evaluate Quality    Using GPT-4
    to evaluate the responses of less sophisticated models is an emerging standard
    practice, but care must be taken that the results are reliable and consistent.    Compared
    to human-based evaluation, LLM-based or synthetic evaluation typically costs an
    order of magnitude less and completes in a few minutes rather than taking days
    or weeks. Even in important or sensitive cases where a final manual review by
    a human is necessary, rapid iteration and A/B testing of the prompt through synthetic
    reviews can save significant time and improve results considerably. However, the
    cost of running many tests at scale can add up, and the latency or rate limits
    of GPT-4 can be a blocker. If at all possible, a prompt engineer should first
    test using programmatic techniques that don’t require a call to an LLM, such as
    simply measuring the length of the response, which runs near instantly for close
    to zero cost.    # Meta Prompting    *Meta prompting* is a technique that involves
    the creation of text prompts that, in turn, generate other text prompts. These
    text prompts are then used to generate new assets in many mediums such as images,
    videos, and more text.    To better understand meta prompting, let’s take the
    example of authoring a children’s book with the assistance of GPT-4\. First, you
    direct the LLM to generate the text for your children’s book. Afterward, you invoke
    meta prompting by instructing GPT-4 to produce prompts that are suitable for image-generation
    models. This could mean creating situational descriptions or specific scenes based
    on the storyline of your book, which then can be given to AI models like Midjourney
    or Stable Diffusion. These image-generation models can, therefore, deliver images
    in harmony with your AI-crafted children’s story.    [Figure 3-8](#figure-3-8)
    visually describes the process of meta prompting in the context of crafting a
    children’s book.  ![Creating image prompts from an LLM that will later be used
    by MidJourney for image creation.](assets/pega_0308.png)  ###### Figure 3-8\.
    Utilizing an LLM to generate image prompts for MidJourney’s image creation in
    the process of crafting a children’s book    Meta prompts offer a multitude of
    benefits for a variety of applications:    Image generation from product descriptions      Meta
    prompts can be employed to derive an image generation prompt for image models
    like [Midjourney](https://www.midjourney.com), effectively creating a visual representation
    of product descriptions.      Generating style/feature prompts      Let’s consider
    you are a copywriter needing to develop a unique style guide prompt from a couple
    of blog posts. Given each client has a distinctive tone and style, it’s beneficial
    to utilize a *meta prompt* that encapsulates all the varied features, rather than
    producing a single prompt output.      Optimizing prompts to achieve specific
    goals      A common approach is to ask ChatGPT or another language model to refine
    or improve `Prompt A` in order to attain `Goal 1`, given `Prompt A` and `Goal
    1`. This method aids in identifying any missed input features, that by adding
    could assist the language model in generating a more detailed and desirable response.      Let’s
    experiment with creating a meta prompt for the copywriting example.    Input:    [PRE99]    Output:    [PRE100]    As
    previously mentioned, it can be beneficial to *critique the model’s output* and
    to ask for a refined prompt either via the interface or API.    ChatGPT can perform
    web searches and can make use of the content of web pages, along with the previously
    generated copywriting style guide. Let’s provide two URLs that ChatGPT will read
    to enhance the output.    Input:    [PRE101]    [Figure 3-9](#figure-3-9) shows
    the output.  ![pega 0309](assets/pega_0309.png)  ###### Figure 3-9\. ChatGPT refining
    a meta prompt by two URL web pages    [PRE102]    Meta prompting offers a dynamic
    and innovative way to harness the power of generative AI models, fostering the
    creation of complex, multifaceted prompts and even prompts that generate other
    prompts. It broadens the application scope, from text and image generation to
    style and feature prompts, and optimization toward specific goals. As you continue
    to refine and explore the potential of meta prompting, it promises to be a game
    changer in how you utilize, interact with, and benefit from using LLMs.    # Summary    After
    reading this chapter, you are now aware of how crucial it is to give clear directions
    and examples to generate desired outputs. Also, you have hands-on experience extracting
    structured data from a hierarchical list using regular expressions in Python,
    and you’ve learned to utilize nested data structures like JSON and YAML to produce
    robust, parsable outputs.    You’ve learned several best practices and effective
    prompt engineering techniques, including the famous “Explain it like I’m five”,
    role prompting, and meta prompting techniques. In the next chapter, you will learn
    how to use a popular LLM package called LangChain that’ll help you to create more
    advanced prompt engineering workflows.````'
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
