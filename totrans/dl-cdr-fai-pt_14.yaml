- en: Chapter 11\. Data Munging with fastai’s Mid-Level API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章。使用fastai的中级API进行数据整理
- en: We have seen what `Tokenizer` and `Numericalize` do to a collection of texts,
    and how they’re used inside the data block API, which handles those transforms
    for us directly using the `TextBlock`. But what if we want to apply only one of
    those transforms, either to see intermediate results or because we have already
    tokenized texts? More generally, what can we do when the data block API is not
    flexible enough to accommodate our particular use case? For this, we need to use
    fastai’s *mid-level API* for processing data. The data block API is built on top
    of that layer, so it will allow you to do everything the data block API does,
    and much much more.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了`Tokenizer`和`Numericalize`对文本集合的处理方式，以及它们如何在数据块API中使用，该API直接使用`TextBlock`处理这些转换。但是，如果我们只想应用这些转换中的一个，要么是为了查看中间结果，要么是因为我们已经对文本进行了标记化，我们该怎么办？更一般地说，当数据块API不足以满足我们特定用例的需求时，我们需要使用fastai的*中级API*来处理数据。数据块API是建立在该层之上的，因此它将允许您执行数据块API所做的一切，以及更多更多。
- en: Going Deeper into fastai’s Layered API
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入了解fastai的分层API
- en: 'The fastai library is built on a *layered API*. In the very top layer are *applications*
    that allow us to train a model in five lines of code, as we saw in [Chapter 1](ch01.xhtml#chapter_intro).
    In the case of creating `DataLoaders` for a text classifier, for instance, we
    used this line:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: fastai库是建立在*分层API*上的。在最顶层是*应用程序*，允许我们在五行代码中训练模型，正如我们在[第1章](ch01.xhtml#chapter_intro)中看到的。例如，对于为文本分类器创建`DataLoaders`，我们使用了这一行：
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The factory method `TextDataLoaders.from_folder` is very convenient when your
    data is arranged the exact same way as the IMDb dataset, but in practice, that
    often won’t be the case. The data block API offers more flexibility. As we saw
    in the preceding chapter, we can get the same result with the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的数据排列方式与IMDb数据集完全相同时，工厂方法`TextDataLoaders.from_folder`非常方便，但实际上，情况通常不会如此。数据块API提供了更多的灵活性。正如我们在前一章中看到的，我们可以通过以下方式获得相同的结果：
- en: '[PRE1]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: But it’s sometimes not flexible enough. For debugging purposes, for instance,
    we might need to apply just parts of the transforms that come with this data block.
    Or we might want to create a `DataLoaders` for an application that isn’t directly
    supported by fastai. In this section, we’ll dig into the pieces that are used
    inside fastai to implement the data block API. Understanding these will enable
    you to leverage the power and flexibility of this mid-tier API.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 但有时它并不够灵活。例如，出于调试目的，我们可能需要仅应用与此数据块一起的部分转换。或者我们可能希望为fastai不直接支持的应用程序创建一个`DataLoaders`。在本节中，我们将深入探讨fastai内部用于实现数据块API的组件。了解这些将使您能够利用这个中间层API的强大和灵活性。
- en: Mid-Level API
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 中级API
- en: The mid-level API does not contain only functionality for creating `DataLoaders`.
    It also has the *callback* system, which allows us to customize the training loop
    any way we like, and the *general optimizer*. Both will be covered in [Chapter 16](ch16.xhtml#chapter_accel_sgd).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 中级API不仅包含用于创建`DataLoaders`的功能。它还具有*回调*系统，允许我们以任何我们喜欢的方式自定义训练循环，以及*通用优化器*。这两者将在[第16章](ch16.xhtml#chapter_accel_sgd)中介绍。
- en: Transforms
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换
- en: 'When we studied tokenization and numericalization in the preceding chapter,
    we started by grabbing a bunch of texts:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中研究标记化和数值化时，我们首先获取了一堆文本：
- en: '[PRE2]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We then showed how to tokenize them with a `Tokenizer`
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们展示了如何使用`Tokenizer`对它们进行标记化
- en: '[PRE3]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'and how to numericalize, including automatically creating the vocab for our
    corpus:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以及如何进行数值化，包括自动为我们的语料库创建词汇表：
- en: '[PRE5]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The classes also have a `decode` method. For instance, `Numericalize.decode`
    gives us back the string tokens:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类还有一个`decode`方法。例如，`Numericalize.decode`会将字符串标记返回给我们：
- en: '[PRE7]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`Tokenizer.decode` turns this back into a single string (it may not, however,
    be exactly the same as the original string; this depends on whether the tokenizer
    is *reversible*, which the default word tokenizer is not at the time we’re writing
    this book):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`Tokenizer.decode`将其转换回一个字符串（但可能不完全与原始字符串相同；这取决于标记器是否是*可逆的*，在我们撰写本书时，默认的单词标记器不是）：'
- en: '[PRE9]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`decode` is used by fastai’s `show_batch` and `show_results`, as well as some
    other inference methods, to convert predictions and mini-batches into a human-understandable
    representation.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`decode`被fastai的`show_batch`和`show_results`以及其他一些推断方法使用，将预测和小批量转换为人类可理解的表示。'
- en: For each of `tok` or `num` in the preceding examples, we created an object called
    the `setup` method (which trains the tokenizer if needed for `tok` and creates
    the vocab for `num`), applied it to our raw texts (by calling the object as a
    function), and then finally decoded the result back to an understandable representation.
    These steps are needed for most data preprocessing tasks, so fastai provides a
    class that encapsulates them. This is the `Transform` class. Both `Tokenize` and
    `Numericalize` are `Transform`s.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，对于`tok`或`num`，我们创建了一个名为`setup`的对象（如果需要为`tok`训练标记器并为`num`创建词汇表），将其应用于我们的原始文本（通过将对象作为函数调用），然后最终将结果解码回可理解的表示。大多数数据预处理任务都需要这些步骤，因此fastai提供了一个封装它们的类。这就是`Transform`类。`Tokenize`和`Numericalize`都是`Transform`。
- en: In general, a `Transform` is an object that behaves like a function and has
    an optional `setup` method that will initialize an inner state (like the vocab
    inside `num`) and an optional `decode` method that will reverse the function (this
    reversal may not be perfect, as we saw with `tok`).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，`Transform`是一个行为类似于函数的对象，它具有一个可选的`setup`方法，用于初始化内部状态（例如`num`内部的词汇表），以及一个可选的`decode`方法，用于反转函数（正如我们在`tok`中看到的那样，这种反转可能不完美）。
- en: 'A good example of `decode` is found in the `Normalize` transform that we saw
    in [Chapter 7](ch07.xhtml#chapter_sizing_and_tta): to be able to plot the images,
    its `decode` method undoes the normalization (i.e., it multiplies by the standard
    deviation and adds back the mean). On the other hand, data augmentation transforms
    do not have a `decode` method, since we want to show the effects on images to
    make sure the data augmentation is working as we want.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`decode` 的一个很好的例子可以在我们在 [第 7 章](ch07.xhtml#chapter_sizing_and_tta) 中看到的 `Normalize`
    转换中找到：为了能够绘制图像，它的 `decode` 方法会撤消归一化（即，乘以标准差并加回均值）。另一方面，数据增强转换没有 `decode` 方法，因为我们希望展示图像上的效果，以确保数据增强按我们的意愿进行工作。'
- en: 'A special behavior of `Transform`s is that they always get applied over tuples.
    In general, our data is always a tuple `(input,target)` (sometimes with more than
    one input or more than one target). When applying a transform on an item like
    this, such as `Resize`, we don’t want to resize the tuple as a whole; instead,
    we want to resize the input (if applicable) and the target (if applicable) separately.
    It’s the same for batch transforms that do data augmentation: when the input is
    an image and the target is a segmentation mask, the transform needs to be applied
    (the same way) to the input and the target.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`Transform` 的一个特殊行为是它们总是应用于元组。一般来说，我们的数据总是一个元组 `(input, target)`（有时有多个输入或多个目标）。当对这样的项目应用转换时，例如
    `Resize`，我们不希望整个元组被调整大小；相反，我们希望分别调整输入（如果适用）和目标（如果适用）。对于进行数据增强的批处理转换也是一样的：当输入是图像且目标是分割掩模时，需要将转换（以相同的方式）应用于输入和目标。'
- en: 'We can see this behavior if we pass a tuple of texts to `tok`:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将一个文本元组传递给 `tok`，我们可以看到这种行为：
- en: '[PRE11]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Writing Your Own Transform
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写您自己的转换
- en: 'If you want to write a custom transform to apply to your data, the easiest
    way is to write a function. As you can see in this example, a `Transform` will
    be applied only to a matching type, if a type is provided (otherwise, it will
    always be applied). In the following code, the `:int` in the function signature
    means that `f` gets applied only to `ints`. That’s why `tfm(2.0)` returns `2.0`,
    but `tfm(2)` returns `3` here:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想编写一个自定义的转换来应用于您的数据，最简单的方法是编写一个函数。正如您在这个例子中看到的，`Transform` 只会应用于匹配的类型，如果提供了类型（否则，它将始终被应用）。在下面的代码中，函数签名中的
    `:int` 表示 `f` 仅应用于 `ints`。这就是为什么 `tfm(2.0)` 返回 `2.0`，但 `tfm(2)` 在这里返回 `3`：
- en: '[PRE13]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here, `f` is converted to a `Transform` with no `setup` and no `decode` method.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`f` 被转换为一个没有 `setup` 和没有 `decode` 方法的 `Transform`。
- en: 'Python has a special syntax for passing a function (like `f`) to another function
    (or something that behaves like a function, known as a *callable* in Python),
    called a *decorator*. A decorator is used by prepending a callable with `@` and
    placing it before a function definition (there are lots of good online tutorials
    about Python decorators, so take a look at one if this is a new concept for you).
    The following is identical to the previous code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Python 有一种特殊的语法，用于将一个函数（如 `f`）传递给另一个函数（或类似函数的东西，在 Python 中称为 *callable*），称为
    *decorator*。通过在可调用对象前加上 `@` 并将其放在函数定义之前来使用装饰器（关于 Python 装饰器有很多很好的在线教程，如果这对您来说是一个新概念，请查看其中一个）。以下代码与前面的代码相同：
- en: '[PRE15]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If you need either `setup` or `decode`, you will need to subclass `Transform`
    to implement the actual encoding behavior in `encodes`, then (optionally) the
    setup behavior in `setups` and the decoding behavior in `decodes`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要 `setup` 或 `decode`，您需要对 `Transform` 进行子类化，以在 `encodes` 中实现实际的编码行为，然后（可选）在
    `setups` 中实现设置行为和在 `decodes` 中实现解码行为：
- en: '[PRE17]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here, `NormalizeMean` will initialize a certain state during the setup (the
    mean of all elements passed); then the transformation is to subtract that mean.
    For decoding purposes, we implement the reverse of that transformation by adding
    the mean. Here is an example of `NormalizeMean` in action:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`NormalizeMean` 将在设置期间初始化某个状态（传递的所有元素的平均值）；然后转换是减去该平均值。为了解码目的，我们通过添加平均值来实现该转换的反向。这里是
    `NormalizeMean` 的一个示例：
- en: '[PRE18]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Note that the method called and the method implemented are different, for each
    of these methods:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，每个方法的调用和实现是不同的：
- en: '| Class | To call | To implement |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 调用 | 实现 |'
- en: '| --- | --- | --- |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `nn.Module` (PyTorch) | `()` (i.e., call as function) | `forward` |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Module`（PyTorch） | `()`（即，作为函数调用） | `forward` |'
- en: '| `Transform` | `()` | `encodes` |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| `Transform` | `()` | `encodes` |'
- en: '| `Transform` | `decode()` | `decodes` |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| `Transform` | `decode()` | `decodes` |'
- en: '| `Transform` | `setup()` | `setups` |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `Transform` | `setup()` | `setups` |'
- en: So, for instance, you would never call `setups` directly, but instead would
    call `setup`. The reason is that `setup` does some work before and after calling
    `setups` for you. To learn more about `Transform`s and how you can use them to
    implement different behavior depending on the type of input, be sure to check
    the tutorials in the fastai docs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，例如，您永远不会直接调用 `setups`，而是会调用 `setup`。原因是 `setup` 在为您调用 `setups` 之前和之后做了一些工作。要了解有关
    `Transform` 及如何使用它们根据输入类型实现不同行为的更多信息，请务必查看 fastai 文档中的教程。
- en: Pipeline
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pipeline
- en: 'To compose several transforms together, fastai provides the `Pipeline` class.
    We define a `Pipeline` by passing it a list of `Transform`s; it will then compose
    the transforms inside it. When you call a `Pipeline` on an object, it will automatically
    call the transforms inside, in order:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要将几个转换组合在一起，fastai 提供了 `Pipeline` 类。我们通过向 `Pipeline` 传递一个 `Transform` 列表来定义一个
    `Pipeline`；然后它将组合其中的转换。当您在对象上调用 `Pipeline` 时，它将自动按顺序调用其中的转换：
- en: '[PRE20]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'And you can call `decode` on the result of your encoding, to get back something
    you can display and analyze:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以对编码结果调用 `decode`，以获取可以显示和分析的内容：
- en: '[PRE22]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The only part that doesn’t work the same way as in `Transform` is the setup.
    To properly set up a `Pipeline` of `Transform`s on some data, you need to use
    a `TfmdLists`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`Transform` 中与 `Transform` 不同的部分是设置。要在一些数据上正确设置 `Transform` 的 `Pipeline`，您需要使用
    `TfmdLists`。'
- en: 'TfmdLists and Datasets: Transformed Collections'
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TfmdLists 和 Datasets：转换的集合
- en: Your data is usually a set of raw items (like filenames, or rows in a DataFrame)
    to which you want to apply a succession of transformations. We just saw that a
    succession of transformations is represented by a `Pipeline` in fastai. The class
    that groups this `Pipeline` with your raw items is called `TfmdLists`.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据通常是一组原始项目（如文件名或DataFrame中的行），您希望对其应用一系列转换。我们刚刚看到，一系列转换在fastai中由`Pipeline`表示。将这个`Pipeline`与您的原始项目组合在一起的类称为`TfmdLists`。
- en: TfmdLists
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TfmdLists
- en: 'Here is the short way of doing the transformation we saw in the previous section:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在前一节中看到的转换的简短方式：
- en: '[PRE24]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'At initialization, the `TfmdLists` will automatically call the `setup` method
    of each `Transform` in order, providing each not with the raw items but the items
    transformed by all the previous `Transform`s, in order. We can get the result
    of our `Pipeline` on any raw element just by indexing into the `TfmdLists`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始化时，`TfmdLists`将自动调用每个`Transform`的`setup`方法，依次提供每个原始项目而不是由所有先前的`Transform`转换的项目。我们可以通过索引到`TfmdLists`中的任何原始元素来获得我们的`Pipeline`的结果：
- en: '[PRE25]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'And the `TfmdLists` knows how to decode for show purposes:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 而`TfmdLists`知道如何解码以进行显示：
- en: '[PRE27]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'In fact, it even has a `show` method:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，它甚至有一个`show`方法：
- en: '[PRE29]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `TfmdLists` is named with an “s” because it can handle a training and a
    validation set with a `splits` argument. You just need to pass the indices of
    the elements that are in the training set and the indices of the elements that
    are in the validation set:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`TfmdLists`以“s”命名，因为它可以使用`splits`参数处理训练集和验证集。您只需要传递在训练集中的元素的索引和在验证集中的元素的索引：'
- en: '[PRE31]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'You can then access them through the `train` and `valid` attributes:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以通过`train`和`valid`属性访问它们：
- en: '[PRE32]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: If you have manually written a `Transform` that performs all of your preprocessing
    at once, turning raw items into a tuple with inputs and targets, then `TfmdLists`
    is the class you need. You can directly convert it to a `DataLoaders` object with
    the `dataloaders` method. This is what we will do in our Siamese example later
    in this chapter.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您手动编写了一个`Transform`，一次执行所有预处理，将原始项目转换为具有输入和目标的元组，那么`TfmdLists`是您需要的类。您可以使用`dataloaders`方法直接将其转换为`DataLoaders`对象。这是我们稍后在本章中将要做的事情。
- en: 'In general, though, you will have two (or more) parallel pipelines of transforms:
    one for processing your raw items into inputs and one to process your raw items
    into targets. For instance, here, the pipeline we defined processes only the raw
    text into inputs. If we want to do text classification, we also have to process
    the labels into targets.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，您将有两个（或更多）并行的转换流水线：一个用于将原始项目处理为输入，另一个用于将原始项目处理为目标。例如，在这里，我们定义的流水线仅将原始文本处理为输入。如果我们要进行文本分类，还必须将标签处理为目标。
- en: 'For this, we need to do two things. First we take the label name from the parent
    folder. There is a function, `parent_label`, for this:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要做两件事。首先，我们从父文件夹中获取标签名称。有一个名为`parent_label`的函数：
- en: '[PRE34]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Then we need a `Transform` that will grab the unique items and build a vocab
    with them during setup, then transform the string labels into integers when called.
    fastai provides this for us; it’s called `Categorize`:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们需要一个`Transform`，在设置期间将抓取的唯一项目构建为词汇表，然后在调用时将字符串标签转换为整数。fastai为我们提供了这个；它被称为`Categorize`：
- en: '[PRE36]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'To do the whole setup automatically on our list of files, we can create a `TfmdLists`
    as before:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 要在我们的文件列表上自动执行整个设置，我们可以像以前一样创建一个`TfmdLists`：
- en: '[PRE38]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: But then we end up with two separate objects for our inputs and targets, which
    is not what we want. This is where `Datasets` comes to the rescue.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 但是然后我们得到了两个分开的对象用于我们的输入和目标，这不是我们想要的。这就是`Datasets`发挥作用的地方。
- en: Datasets
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Datasets
- en: '`Datasets` will apply two (or more) pipelines in parallel to the same raw object
    and build a tuple with the result. Like `TfmdLists`, it will automatically do
    the setup for us, and when we index into a `Datasets`, it will return us a tuple
    with the results of each pipeline:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`Datasets`将并行应用两个（或更多）流水线到相同的原始对象，并构建一个包含结果的元组。与`TfmdLists`一样，它将自动为我们进行设置，当我们索引到`Datasets`时，它将返回一个包含每个流水线结果的元组：'
- en: '[PRE40]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Like a `TfmdLists`, we can pass along `splits` to a `Datasets` to split our
    data between training and validation sets:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 像`TfmdLists`一样，我们可以将`splits`传递给`Datasets`以在训练和验证集之间拆分我们的数据：
- en: '[PRE41]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'It can also decode any processed tuple or show it directly:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 它还可以解码任何处理过的元组或直接显示它：
- en: '[PRE43]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The last step is to convert our `Datasets` object to a `DataLoaders`, which
    can be done with the `dataloaders` method. Here we need to pass along a special
    argument to take care of the padding problem (as we saw in the preceding chapter).
    This needs to happen just before we batch the elements, so we pass it to `before_batch`:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将我们的`Datasets`对象转换为`DataLoaders`，可以使用`dataloaders`方法完成。在这里，我们需要传递一个特殊参数来解决填充问题（正如我们在前一章中看到的）。这需要在我们批处理元素之前发生，所以我们将其传递给`before_batch`：
- en: '[PRE45]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '`dataloaders` directly calls `DataLoader` on each subset of our `Datasets`.
    fastai’s `DataLoader` expands the PyTorch class of the same name and is responsible
    for collating the items from our datasets into batches. It has a lot of points
    of customization, but the most important ones that you should know are as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`dataloaders`直接在我们的`Datasets`的每个子集上调用`DataLoader`。fastai的`DataLoader`扩展了PyTorch中同名类，并负责将我们的数据集中的项目整理成批次。它有很多自定义点，但您应该知道的最重要的是：'
- en: '`after_item`'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`after_item`'
- en: Applied on each item after grabbing it inside the dataset. This is the equivalent
    of `item_tfms` in `DataBlock`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集中抓取项目后应用于每个项目。这相当于`DataBlock`中的`item_tfms`。
- en: '`before_batch`'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`before_batch`'
- en: Applied on the list of items before they are collated. This is the ideal place
    to pad items to the same size.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在整理之前应用于项目列表上。这是将项目填充到相同大小的理想位置。
- en: '`after_batch`'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`after_batch`'
- en: Applied on the batch as a whole after its construction. This is the equivalent
    of `batch_tfms` in `DataBlock`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建后对整个批次应用。这相当于`DataBlock`中的`batch_tfms`。
- en: 'As a conclusion, here is the full code necessary to prepare the data for text
    classification:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这是为了准备文本分类数据所需的完整代码：
- en: '[PRE46]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The two differences from the previous code are the use of `GrandparentSplitter`
    to split our training and validation data, and the `dl_type` argument. This is
    to tell `dataloaders` to use the `SortedDL` class of `DataLoader`, and not the
    usual one. `SortedDL` constructs batches by putting samples of roughly the same
    lengths into batches.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的代码的两个不同之处是使用`GrandparentSplitter`来分割我们的训练和验证数据，以及`dl_type`参数。这是告诉`dataloaders`使用`DataLoader`的`SortedDL`类，而不是通常的类。`SortedDL`通过将大致相同长度的样本放入批次来构建批次。
- en: 'This does the exact same thing as our previous `DataBlock`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们之前的`DataBlock`完全相同：
- en: '[PRE47]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: But now you know how to customize every single piece of it!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在你知道如何定制每一个部分了！
- en: Let’s practice what we just learned about using this mid-level API for data
    preprocessing on a computer vision example now.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在通过一个计算机视觉示例练习刚学到的关于使用这个中级API进行数据预处理。
- en: 'Applying the Mid-Level Data API: SiamesePair'
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用中级数据API：SiamesePair
- en: A *Siamese model* takes two images and has to determine whether they are of
    the same class. For this example, we will use the Pet dataset again and prepare
    the data for a model that will have to predict whether two images of pets are
    of the same breed. We will explain here how to prepare the data for such a model,
    and then we will train that model in [Chapter 15](ch15.xhtml#chapter_arch_details).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*暹罗模型*需要两张图片，并且必须确定它们是否属于同一类。在这个例子中，我们将再次使用宠物数据集，并准备数据用于一个模型，该模型将预测两张宠物图片是否属于同一品种。我们将在这里解释如何为这样的模型准备数据，然后我们将在[第15章](ch15.xhtml#chapter_arch_details)中训练该模型。
- en: 'First things first—let’s get the images in our dataset:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要做的是-让我们获取数据集中的图片：
- en: '[PRE48]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: If we didn’t care about showing our objects at all, we could directly create
    one transform to completely preprocess that list of files. We will want to look
    at those images, though, so we need to create a custom type. When you call the
    `show` method on a `TfmdLists` or a `Datasets` object, it will decode items until
    it reaches a type that contains a `show` method and use it to show the object.
    That `show` method gets passed a `ctx`, which could be a `matplotlib` axis for
    images or a row of a DataFrame for texts.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们根本不关心显示我们的对象，我们可以直接创建一个转换来完全预处理那个文件列表。但是我们想要查看这些图片，因此我们需要创建一个自定义类型。当您在`TfmdLists`或`Datasets`对象上调用`show`方法时，它将解码项目，直到达到包含`show`方法的类型，并使用它来显示对象。该`show`方法会传递一个`ctx`，它可以是图像的`matplotlib`轴，也可以是文本的DataFrame行。
- en: 'Here we create a `SiameseImage` object that subclasses `Tuple` and is intended
    to contain three things: two images, and a Boolean that’s `True` if the images
    are of the same breed. We also implement the special `show` method, such that
    it concatenates the two images with a black line in the middle. Don’t worry too
    much about the part that is in the `if` test (which is to show the `SiameseImage`
    when the images are Python images, not tensors); the important part is in the
    last three lines:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个`SiameseImage`对象，它是`Tuple`的子类，旨在包含三个东西：两张图片和一个布尔值，如果图片是同一品种则为`True`。我们还实现了特殊的`show`方法，使其将两张图片与中间的黑线连接起来。不要太担心`if`测试中的部分（这是在Python图片而不是张量时显示`SiameseImage`的部分）；重要的部分在最后三行：
- en: '[PRE49]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Let’s create a first `SiameseImage` and check that our `show` method works:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个第一个`SiameseImage`并检查我们的`show`方法是否有效：
- en: '[PRE50]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '![](Images/dlcf_11in01.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_11in01.png)'
- en: 'We can also try with a second image that’s not from the same class:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以尝试一个不属于同一类的第二张图片：
- en: '[PRE51]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![](Images/dlcf_11in02.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_11in02.png)'
- en: 'The important thing with transforms that we saw before is that they dispatch
    over tuples or their subclasses. That’s precisely why we chose to subclass `Tuple`
    in this instance—this way, we can apply any transform that works on images to
    our `SiameseImage`, and it will be applied on each image in the tuple:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前看到的转换的重要之处是它们会分派到元组或其子类。这正是为什么在这种情况下我们选择子类化`Tuple`的原因-这样，我们可以将适用于图像的任何转换应用于我们的`SiameseImage`，并且它将应用于元组中的每个图像：
- en: '[PRE52]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '![](Images/dlcf_11in03.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_11in03.png)'
- en: Here the `Resize` transform is applied to each of the two images, but not the
    Boolean flag. Even if we have a custom type, we can thus benefit from all the
    data augmentation transforms inside the library.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这里`Resize`转换应用于两个图片中的每一个，但不应用于布尔标志。即使我们有一个自定义类型，我们也可以从库中的所有数据增强转换中受益。
- en: 'We are now ready to build the `Transform` that we will use to get our data
    ready for a Siamese model. First, we will need a function to determine the classes
    of all our images:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备构建`Transform`，以便为暹罗模型准备数据。首先，我们需要一个函数来确定所有图片的类别：
- en: '[PRE53]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'For each image, our transform will, with a probability of 0.5, draw an image
    from the same class and return a `SiameseImage` with a true label, or draw an
    image from another class and return a `SiameseImage` with a false label. This
    is all done in the private `_draw` function. There is one difference between the
    training and validation sets, which is why the transform needs to be initialized
    with the splits: on the training set, we will make that random pick each time
    we read an image, whereas on the validation set, we make this random pick once
    and for all at initialization. This way, we get more varied samples during training,
    but always the same validation set:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每张图片，我们的转换将以0.5的概率从同一类中绘制一张图片，并返回一个带有真标签的`SiameseImage`，或者从另一类中绘制一张图片并返回一个带有假标签的`SiameseImage`。这一切都在私有的`_draw`函数中完成。训练集和验证集之间有一个区别，这就是为什么转换需要用拆分初始化：在训练集上，我们将每次读取一张图片时进行随机选择，而在验证集上，我们将在初始化时进行一次性随机选择。这样，在训练期间我们会得到更多不同的样本，但始终是相同的验证集：
- en: '[PRE54]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We can then create our main transform:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以创建我们的主要转换：
- en: '[PRE55]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '![](Images/dlcf_11in04.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_11in04.png)'
- en: 'In the mid-level API for data collection, we have two objects that can help
    us apply transforms on a set of items: `TfmdLists` and `Datasets`. If you remember
    what we have just seen, one applies a `Pipeline` of transforms and the other applies
    several `Pipeline`s of transforms in parallel, to build tuples. Here, our main
    transform already builds the tuples, so we use `TfmdLists`:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '![](Images/dlcf_11in05.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
- en: 'And we can finally get our data in `DataLoaders` by calling the `dataloaders`
    method. One thing to be careful of here is that this method does not take `item_tfms`
    and `batch_tfms` like a `DataBlock`. The fastai `DataLoader` has several hooks
    that are named after events; here what we apply on the items after they are grabbed
    is called `after_item`, and what we apply on the batch once it’s built is called
    `after_batch`:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Note that we need to pass more transforms than usual—that’s because the data
    block API usually adds them automatically:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '`ToTensor` is the one that converts images to tensors (again, it’s applied
    on every part of the tuple).'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`IntToFloatTensor` converts the tensor of images containing integers from 0
    to 255 to a tensor of floats, and divides by 255 to make the values between 0
    and 1.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can now train a model using this `DataLoaders`. It will need a bit more customization
    than the usual model provided by `cnn_learner` since it has to take two images
    instead of one, but we will see how to create such a model and train it in [Chapter 15](ch15.xhtml#chapter_arch_details).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: fastai provides a layered API. It takes one line of code to grab the data when
    it’s in one of the usual settings, making it easy for beginners to focus on training
    a model without spending too much time assembling the data. Then, the high-level
    data block API gives you more flexibility by allowing you to mix and match building
    blocks. Underneath it, the mid-level API gives you greater flexibility to apply
    transformations on your items. In your real-world problems, this is probably what
    you will need to use, and we hope it makes the step of data-munging as easy as
    possible.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Questionnaire
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Why do we say that fastai has a “layered” API? What does it mean?
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why does a `Transform` have a `decode` method? What does it do?
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why does a `Transform` have a `setup` method? What does it do?
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does a `Transform` work when called on a tuple?
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Which methods do you need to implement when writing your own `Transform`?
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a `Normalize` transform that fully normalizes items (subtract the mean
    and divide by the standard deviation of the dataset), and that can decode that
    behavior. Try not to peek!
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a `Transform` that does the numericalization of tokenized texts (it should
    set its vocab automatically from the dataset seen and have a `decode` method).
    Look at the source code of fastai if you need help.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a `Pipeline`?
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a `TfmdLists`?
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a `Datasets`? How is it different from a `TfmdLists`?
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are `TfmdLists` and `Datasets` named with an “s”?
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can you build a `DataLoaders` from a `TfmdLists` or a `Datasets`?
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you pass `item_tfms` and `batch_tfms` when building a `DataLoaders` from
    a `TfmdLists` or a `Datasets`?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What do you need to do when you want to have your custom items work with methods
    like `show_batch` or `show_results`?
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why can we easily apply fastai data augmentation transforms to the `SiamesePair`
    we built?
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further Research
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use the mid-level API to prepare the data in `DataLoaders` on your own datasets.
    Try this with the Pet dataset and the Adult dataset from [Chapter 1](ch01.xhtml#chapter_intro).
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Look at the Siamese tutorial in the [fastai documentation](https://docs.fast.ai)
    to learn how to customize the behavior of `show_batch` and `show_results` for
    new types of items. Implement it in your own project.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Understanding fastai’s Applications: Wrap Up'
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations—you’ve completed all of the chapters in this book that cover
    the key practical parts of training models and using deep learning! You know how
    to use all of fastai’s built-in applications, and how to customize them using
    the data block API and loss functions. You even know how to create a neural network
    from scratch and train it! (And hopefully you now know some of the questions to
    ask to make sure your creations help improve society too.)
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你——你已经完成了本书中涵盖训练模型和使用深度学习的关键实用部分的所有章节！你知道如何使用所有fastai内置的应用程序，以及如何使用数据块API和损失函数进行定制。你甚至知道如何从头开始创建神经网络并训练它！（希望你现在也知道一些问题要问，以确保你的创作有助于改善社会。）
- en: The knowledge you already have is enough to create full working prototypes of
    many types of neural network application. More importantly, it will help you understand
    the capabilities and limitations of deep learning models, and how to design a
    system that’s well adapted to them.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经掌握的知识足以创建许多类型的神经网络应用的完整工作原型。更重要的是，它将帮助你了解深度学习模型的能力和局限性，以及如何设计一个适应它们的系统。
- en: In the rest of this book, we will be pulling apart those applications, piece
    by piece, to understand the foundations they are built on. This is important knowledge
    for a deep learning practitioner, because it allows you to inspect and debug models
    that you build and to create new applications that are customized for your particular
    projects.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的其余部分，我们将逐个拆解这些应用程序，以了解它们构建在哪些基础之上。这对于深度学习从业者来说是重要的知识，因为它使您能够检查和调试您构建的模型，并创建定制的新应用程序，以适应您特定的项目。
