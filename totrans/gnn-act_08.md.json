["```py\n   1\n   root 4.40047 17.8934 -21.0986 -0.943965 -8.37963 -7.42612\n   lowerback 11.505 1.60479 4.40928\n   upperback 0.47251 2.84449 2.26157\n   thorax -5.8636 1.30424 -0.569129\n   lowerneck -15.9456 -3.55911 -2.36067\n   upperneck 19.9076 -4.57025 1.03589\n```", "```py\n   num_epochs = 200  \n   train_losses = []\n   valid_losses = []\n\n   pbar = tqdm(range(num_epochs))\n\n   for epoch in pbar:\n\n        train_loss = 0.0  #1\n        valid_loss = 0.0  #1\n\n        modelRNN.train()  #2\n        for i, (inputs, labels) in enumerate(trainloader):\n             inputs = inputs.to(device)\n             labels = labels.to(device)\n\n        optimizer.zero_grad()  #3\n\n        outputs = modelRNN(inputs)  #4\n        loss = criterion(outputs, labels)  #4\n        loss.backward()  #4\n        optimizer.step()  #4\n\n        train_loss += loss.item() * inputs.size(0)  #5\n\n        modelRNN.eval()   #6\n        with torch.no_grad():\n             for i, (inputs, labels) in enumerate(validloader):\n                  inputs = inputs.to(device)\n                  labels = labels.to(device)\n\n                  outputs = modelRNN(inputs) \n                  loss = criterion(outputs, labels)\n                  valid_loss += loss.item() * inputs.size(0)\n\n         if valid_loss < best_loss:  #7\n              best_loss = valid_loss\n              counter = 0\n         else:\n              counter += 1\n\n         scheduler.step(best_loss)  #8\n\n         if counter == early_stop:\n         print(f\"\\n\\nEarly stopping \\\ninitiated, no change \\\nafter {early_stop} steps\")\n         break\n\n        train_loss = train_loss/len(trainloader.dataset)  #9\n        valid_loss = valid_loss/len(validloader.dataset)  #9\n\n        train_losses.append(train_loss)  #9\n        valid_losses.append(valid_loss)  #9\n```", "```py\n   model.eval()   #1\n   predictions = [] \n   test_losses = [] \n   seq_len = 40 \n\n   with torch.no_grad():\n        for i, (inputs, targets) in enumerate(testloader):\n             inputs = inputs.to(device)\n             targets = targets.to(device)\n\n             preds = []\n             for _ in range(seq_len):\n                  output = model(inputs)\n                  preds.append(output)\n\n             inputs = torch.cat([inputs[:, 1:]\\\n, output.unsqueeze(1)], dim=1) \\ #2\n\n        preds = torch.cat(preds, dim=1)  #3\n           loss = criterion(preds, targets)  #3\n           test_losses.append(loss.item())  #3\n\n           predictions.append(preds.detach().cpu().numpy())\n\n    predictions = np.concatenate(predictions, axis=0)  #4\n   test_loss = np.mean(test_losses)  #5\n```", "```py\n   class PoseDataset(Dataset):\n        def __init__(self, loc_path, \n                          vel_path, \n                          edge_path, \n                          mask_path, \n                          mask_size, \n                          transform=True):\n\n       self.locations = np.load(loc_path)  #1\n        self.velocities = np.load(vel_path)  #1\n        self.edges = np.load(edge_path)\n\n        self.transform=transform\n        self.mask_size = mask_size  #2\n        self.window_size = self.locations\\\n.shape[1] - self.mask_size  #3\n```", "```py\n   def __getitem__(self, idx):\n        nodes = np.concatenate((self.locations[idx], \n   self.velocities[idx]), axis=2)  #1\n        nodes = nodes.reshape(-1, nodes.shape[-1])  #2\n\n        if self.transform:  #3\n             nodes, node_min, node_max\\\n    = normalize_array(nodes) \n\n        total_timesteps = self.window_size + self.mask_size  #4\n        edge_index = np.repeat(self.\\\nedges[None, :], total_timesteps, axis=0) \n\n         N_dims = self.locations.shape[2]\n        shift = np.arange(total_\\\n   timesteps)[:, None, None]*N_dims  #5\n         edge_index += shift\n         edge_index = edge_index.reshape(2, -1)   #6\n\n         x = torch.tensor(nodes, dtype=torch.float)  #7\n         edge_index = torch.tensor\\\n(edge_index, dtype=torch.long) \n          mask_indices = np.arange(         #8\n               self.window_size * self.\\\nlocations.shape[2],                        \n               total_timesteps * \\\nself.locations.shape[2]                    \n                    )                      \n           mask_indices = torch.tensor(mask_indices, dtype=torch.long)\n\n           if self.transform:\n                  trnsfm_data = [node_min, node_max]\n                  return Data(x=x, \n                       edge_index=edge_index, \n                       mask_indices=mask_indices,  \n                       trnsfm=trnsfm_data\n                        )\n            return Data(x=x, edge_index=\\\nedge_index, mask_indices=mask_indices)\n```", "```py\n       total_timesteps = self.\\\nwindow_size + self.mask_size  #1\n       edge_index = np.repeat(self.edges[None, :],\\\n total_timesteps, axis=0) \n\n       shift = np.arange(total_timesteps)[:, None, \\\nNone] * num_nodes_per_timestep  #2\n       edge_index += shift  #3\n       edge_index = edge_index.reshape(2, -1)  #4\n```", "```py\n  class GAT(torch.nn.Module):\n        def __init__(self, n_feat,\n                      hidden_size=32,\n                      num_layers=3,\n                      num_heads=1,\n                      dropout=0.2,\n                      mask_size=10):\n             super(GAT, self).__init__()\n\n             self.num_layers = num_layers\n             self.heads = num_heads\n             self.n_feat = n_feat\n             self.hidden_size = hidden_size\n             self.gat_layers = torch.nn.ModuleList()\n             self.batch_norms = torch.nn.ModuleList()\n             self.dropout = nn.Dropout(dropout)\n             self.mask_size = mask_size\n\n             gat_layer = GATv2Conv(self.n_feat,\\\n self.hidden_size, heads=num_heads)  #1\n             self.gat_layers.append(gat_layer)  #1\n             middle_size = self.hidden_size*num_heads \n             batch_layer = nn.BatchNorm1d\\\n(num_features=middle_size)  #2\n             self.batch_norms.append(batch_layer) #2\n\n             for _ in range(num_layers-2):  #3\n                  gat_layer = GATv2Conv(input_size,\\\n self.hidden_size, heads=num_heads) \n                  self.gat_layers.append(gat_layer) \n                  batch_layer = nn.BatchNorm1d(num_features\\\n=middle_size)                                           #4\n                  self.batch_norms.append(batch_layer) \n\n             gat_layer = GATv2Conv(middle_size, self.n_feat)\n             self.gat_layers.append(gat_layer)  #5\n\n        def forward(self, data):\n             x, edge_index = data.x, data.edge_index\n             for i in range(self.num_layers):\n                  x = self.gat_layers[i](x, edge_index)\n                  if i < self.num_layers - 1:  #6\n                       x = self.batch_norms[i](x)  #6\n                       x = torch.relu(x)  #6\n                       x = self.dropout(x)  #6\n\n             n_nodes = edge_index.max().item() + 1  #7\n             x = x.view(-1, n_nodes, self.n_feat)\n             return x[-self.mask_size:].view(-1, self.n_feat)\n```", "```py\n   lr = 0.001\n   criterion = torch.nn.MSELoss()                            #1\n   optimizer = torch.optim.Adam(model.parameters(), lr=lr)  \n\n   for epoch in tqdm(range(epochs), ncols=300):\n        model.train()\n        train_loss = 0.0\n        for data in train_dataset:\n             optimizer.zero_grad()\n             out = model(data)  #2\n\n        loss = criterion(out, \\\ndata.y.reshape(out.shape[0], -1))  #3\n        loss.backward() \n        optimizer.step()\n        train_loss += loss.item()\n\n        model.eval()  #4\n        val_loss = 0.0  #4\n        with torch.no_grad():  #4\n             for val_data in val_dataset:  #4\n               val_out = model(val_data)  #5\n                  val_loss += criterion(out, \\\ndata.y.reshape(out.shape[0],\\\n -1)).item()  #6\n\n        val_loss /= len(val_dataset)\n        train_loss /= len(train_dataset)\n```", "```py\n   test_loss = 0\n   for test_data in test_dataset:\n        test_out = model(test_data)  #1\n        test_loss += criterion(out,\\\n data.y.reshape(out.shape[0], -1)).item()  #2\n```", "```py\n   class BaseNRI(nn.Module):\n        def __init__(self, num_vars, encoder, decoder,\n                num_edge_types=2,\n                gumbel_temp=0.5, \n                prior_variance=5e-5):\n           super(BaseNRI, self).__init__()\n           self.num_vars = num_vars  #1\n           self.encoder = encoder  #2\n           self.decoder = decoder  #3\n           self.num_edge_types = num_edge_types \n           self.gumbel_temp = gumbel_temp  #4\n           self.prior_variance = prior_variance  #5\n\n           self.log_prior = self._initialize_log_prior()\n\n        def _initialize_log_prior(self): \n             prior = torch.zeros(self.num_edge_types)\n             prior.fill_(1.0 / self.num_edge_types)  #6\n             log_prior = torch.log(prior)\\\n   .unsqueeze(0).unsqueeze(0)  #7\n             return log_prior.cuda(non_blocking=True)\n```", "```py\n   def calculate_loss(self, inputs,\n       is_train=False,\n       teacher_forcing=True,\n       return_edges=False,\n       return_logits=False):\n\n       encoder_results = self.encoder(inputs)\n       logits = encoder_results['logits']\n       hard_sample = not is_train\n       edges = F.gumbel_softmax\\\n               (logits.view(-1, self.num_edge_types),\n               tau=self.gumbel_temp,\n               hard=hard_sample).view\\\n                       (logits.shape)  #1\n\n       output = self.decoder(inputs[:, :-1], edges)\n\n       if len(inputs.shape) == 3: \\\ntarget = inputs[:, 1:] \n       else:\n           Target = inputs[:, 1:, :, :]\n\n       loss_nll = F.mse_loss(\\\noutput, target) / (2 * \\\nself.prior_variance)  #2\n\n       probs = F.softmax(logits, dim=-1)\n       log_probs = torch.log(probs + 1e-16)  #3\n       loss_kl = (probs * \\\n(log_probs - torch.log(\\\ntorch.tensor(1.0 /  #4\n       self.num_edge_types)))).\\\nsum(-1).mean() \n\n        loss = loss_nll + loss_kl\n\n        return loss, loss_nll, loss_kl, logits, output\n```", "```py\n   def predict_future(self, inputs, prediction_steps, \n      return_edges=False, \n      return_everything=False): #1\n       encoder_dict = self.encoder(inputs) #1\n       logits = encoder_dict['logits'] \n       edges = nn.functional.gumbel_softmax(  #2\n           logits.view(-1, \\\n           self.num_edge_types),  \n           tau=self.gumbel_temp,\\\n           hard=True).view(logits.shape\\ \n           ) \n       tmp_predictions, decoder_state =\\\n          self.decoder(  #3\n          inputs[:, :-1],  #3\n          edges,  #3\n          return_state=True  #3\n       )  #3\n       predictions = self.decoder(  #4\n          inputs[:, -1].unsqueeze(1),   #4\n          edges,   #4\n          prediction_steps=prediction_steps,   #4\n          teacher_forcing=False,  #4\n          state=decoder_state  #4\n          ) #4\n       if return_everything:  #5\n           predictions = torch.cat([\\  #4\n              tmp_predictions,\\  #5\n              Predictions\\  #5\n              ], dim=1)  #5\n\n       return (predictions, edges)\\\n          if return_edges else predictions  #6\n```", "```py\n   class BaseEncoder(nn.Module):\n       def __init__(self, num_vars):\n           super(BaseEncoder, self).__init__()\n           self.num_vars = num_vars\n           edges = torch.ones(num_vars)\\\n - torch.eye(num_vars)  #1\n           self.send_edges, self.\\\nrecv_edges = torch.where(edges)  #2\n\n           one_hot_recv = torch.nn.functional.one_hot(  #3\n              self.recv_edges,  #3\n              num_classes=num_vars  #3\n                                                ) #3\n           self.edge2node_mat = \\\nnn.Parameter(one_hot_recv.\\\nfloat().T, requires_grad=False)  #4\n\n       def node2edge(self, node_embeddings):\n           send_embed = \\\nnode_embeddings[:, self.send_edges]  #5\n           recv_embed = \\\nnode_embeddings[:, self.recv_edges] \n           return torch.\\\ncat([send_embed, recv_embed], dim=2)  #6\n\n       def edge2node(self, edge_embeddings):\n           incoming = torch.\\\nmatmul(self.edge2node_mat, edge_embeddings)  #7\n           return incoming / (self.num_vars - 1)  #8\n```", "```py\nsend_edges = tensor([0, 0, 1, 1, 2, 2])\nrecv_edges = tensor([1, 2, 0, 2, 0, 1])\n```", "```py\n   class RefMLPEncoder(BaseEncoder):\n       def __init__(self, \n               num_vars=31, \n               input_size=6, \n               input_time_steps=50, \n               encoder_mlp_hidden=256, \n               encoder_hidden=256, \n               num_edge_types=2, \n               encoder_dropout=0.):\n           super(RefMLPEncoder, self).__init__(num_vars)\n           inp_size = input_size * input_time_steps\n           hidden_size = encoder_hidden\n           num_layers = 3\n           self.input_time_steps = input_time_steps\n\n           self.mlp1 = RefNRIMLP\\\n(inp_size, hidden_size, \\\nhidden_size, encoder_dropout)  #1\n           self.mlp2 = RefNRIMLP\\\n(hidden_size*2, hidden_size,\\\n hidden_size, encoder_dropout) \n           self.mlp3 = RefNRIMLP\\\n(hidden_size, hidden_size,\\\n hidden_size, encoder_dropout) \n           mlp4_inp_size = hidden_size * 2\n           self.mlp4 = RefNRIMLP\\\n(mlp4_inp_size, hidden_size,\\\n hidden_size, encoder_dropout)\n\n           layers = [nn.Linear\\\n(hidden_size, encoder_mlp_hidden), \\\nnn.ELU(inplace=True)]  #2\n           layers += [nn.Linear\\\n(encoder_mlp_hidden, \\\nencoder_mlp_hidden),\\ \n   nn.ELU(inplace=True)] \\\n   * (num_layers - 2) \n           layers.append(nn.\\\nLinear(encoder_mlp_hidden, \\\nnum_edge_types)) \n           self.fc_out = nn.Sequential(*layers) \n           self.init_weights()\n```", "```py\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):  #1\n                nn.init.xavier_normal_(m.weight.data)  #2\n                m.bias.data.fill_(0.1)  #3\n```", "```py\n   def forward(self, inputs, state=None, return_state=False):\n       if inputs.size(1) > self.input_time_steps:\n           inputs = inputs[:, -self.input_time_steps:]\n       elif inputs.size(1) < self.input_time_steps:\n           begin_inp = inputs[:, 0:1].expand(\n           -1, \n           self.input_time_steps-inputs.size(1),\n           -1, -1\n           )\n           inputs = torch.cat([begin_inp, inputs], dim=1) #1\n\n       x = inputs.transpose(1, 2).contiguous()  #1\n       x = x.view(inputs.size(0), inputs.size(2), -1) \n\n       x = self.mlp1(x)  #2\n       x = self.node2edge(x)  #3\n       x = self.mlp2(x)  #4\n\n       x = self.edge2node(x)  #5\n       x = self.mlp3(x)\n\n       x = self.node2edge(x)  #6\n       x = self.mlp4(x)\n\n       result =  self.fc_out(x)  #7\n       result_dict = {\n          'logits': result,\n          'state': inputs,\n           }\n       return result_dict\n```", "```py\n   class GraphRNNDecoder(nn.Module):\n       def __init__(self, \n           num_vars=31, \n           input_size=6, \n           decoder_dropout=0., \n           decoder_hidden=64, \n           num_edge_types=2, \n           skip_first=True):\n           super(GraphRNNDecoder, self).__init__()\n           self.num_vars = num_vars\n           self.msg_out_shape = decoder_hidden\n           self.skip_first_edge_type = skip_first\n           self.dropout_prob = decoder_dropout\n           self.edge_types = num_edge_types\n\n           self.msg_fc1 = nn.ModuleList\\\n([nn.Linear(2 * decoder_hidden,\\\n decoder_hidden) for _ in \\\nrange(self.edge_types)])  #1\n           self.msg_fc2 = nn.ModuleList\\\n([nn.Linear(decoder_hidden, decoder_hidden)\\\n for _ in range(self.edge_types)])\n\n           self.custom_gru = CustomGRU\\\n(input_size, decoder_hidden)  #2\n\n           self.out_fc1 = nn.Linear\\\n(decoder_hidden, decoder_hidden)  #3\n           self.out_fc2 = nn.Linear(decoder_hidden, decoder_hidden)\n           self.out_fc3 = nn.Linear(decoder_hidden, input_size)\n\n           self.num_vars = num_vars\n           edges = np.ones(num_vars) - np.eye(num_vars)\n           self.send_edges = np.where(edges)[0]\n           self.recv_edges = np.where(edges)[1]\n           self.edge2node_mat = \\\n                torch.FloatTensor\\\n                (encode_onehot(self.recv_edges))\n           self.edge2node_mat = self.edge2node_mat.cuda(non_blocking=True)\n```", "```py\n      predictions = self.decoder(inputs[:, -1].unsqueeze(1), edges,\n      prediction_steps=prediction_steps, teacher_forcing=False, \n      state=decoder_state)\n```", "```py\n   class CustomGRU(nn.Module):\n       def __init__(self,input_size, n_hid,num_vars=31):\n           super(CustomGRU, self).__init__()\n           self.num_vars = num_vars\n           self.hidden_r = nn.Linear\n(n_hid, n_hid, bias=False)  #1\n           self.hidden_i = nn.Linear\\\n(n_hid, n_hid, bias=False) \n           self.hidden_h = nn.Linear\\\n(n_hid, n_hid, bias=False) \n\n           self.input_r = nn.Linear\\\n(input_size, n_hid, bias=True)  #2\n           self.input_i = nn.Linear(\\\ninput_size, n_hid, bias=True) \n           self.input_n = nn.Linear\\\n(input_size, n_hid, bias=True) \n\n       def forward(self, inputs, agg_msgs, hidden):\n           inp_r = self.input_r(inputs)\\\n.view(inputs.size(0), self.num_vars, -1)\n           inp_i = self.input_i(inputs)\\\n.view(inputs.size(0), self.num_vars, -1)\n           inp_n = self.input_n(inputs)\\\n.view(inputs.size(0), self.num_vars, -1)\n\n           r = torch.sigmoid(inp_r + \\\nself.hidden_r(agg_msgs))  #3\n           i = torch.sigmoid(inp_i + \\\nself.hidden_i(agg_msgs))  #4\n           n = torch.tanh(inp_n + \\\nr*self.hidden_h(agg_msgs))  #5\n           hidden = (1 - i)*n + i*hidden  #6\n\n           return hidden\n```", "```py\n     tmp_predictions, decoder_state = \\\n        self.decoder(inputs[:, :-1], edges, \n        return_state=True)\n     predictions = self.decoder\\\n        (inputs[:, -1].unsqueeze(1), edges, \n        prediction_steps=prediction_steps, \\\n        teacher_forcing=False, state=decoder_state)\n```", "```py\n     def forward(self, inputs, sampled_edges,\n         teacher_forcing=False,\n         return_state=False,\n         prediction_steps=-1,\n         state=None):\n\n         batch_size, time_steps, num_vars, num_feats = inputs.size()\n         pred_steps = prediction_steps if \\\n            prediction_steps > 0 else time_steps  #1\n\n         if len(sampled_edges.shape) == 3:  #2\n             sampled_edges = sampled_edges.unsqueeze(1) \n             sampled_edges = sampled_edges.expand\\\n                (batch_size, pred_steps, -1, -1) \n\n         if state is None:  #3\n             hidden = torch.zeros(batch_size,  #3\n                Num_vars,  #3\n                Self.msg_out_shape,  #3\n                device=inputs.device)  #3\n         else:  #3\n             hidden = state  #3\n             teacher_forcing_steps = time_steps  #4\n\n         pred_all = []\n         for step in range(pred_steps):  #5\n         if step == 0 or (teacher_forcing \\\n            and step < teacher_forcing_steps): \n             ins = inputs[:, step, :] \n         else: \n             ins = pred_all[-1] \n\n         pred, hidden = self.single_step_forward(  #6\n              ins,   #6\n              sampled_edges[:, step, :],   #6\n              hidden  #6\n              )  #6\n              pred_all.append(pred)\n\n         preds = torch.stack(pred_all, dim=1)\n\n         return (preds, hidden) if return_state else preds  #7\n```", "```py\n     def single_step_forward(self, inputs, rel_type, hidden):\n         receivers = hidden[:, self.recv_edges, :]  #1\n         senders = hidden[:, self.send_edges, :]  #1\n\n         pre_msg = torch.cat([receivers, senders], dim=-1)  #2\n\n         all_msgs = torch.zeros(\n             pre_msg.size(0), \n             pre_msg.size(1), \n             self.msg_out_shape, \n             device=inputs.device\n             )\n\n         start_idx = 1 if self.skip_first_edge_type else 0\n         norm = float(len(self.msg_fc2) - start_idx)\n\n         for i in range(start_idx, len(self.msg_fc2)):  #3\n             msg = torch.tanh(self.msg_fc1[i](pre_msg))  #3\n             msg = F.dropout(msg, p=self.dropout_prob)  #3\n             msg = torch.tanh(self.msg_fc2[i](msg))  #3\n             msg = msg * rel_type[:, :, i:i+1]  #3\n             all_msgs += msg / norm  #3\n\n         agg_msgs = all_msgs.transpose(-2, -1)  #4\n         agg_msgs = agg_msgs.matmul(self.edge2node_mat) \n         agg_msgs = agg_msgs.transpose\\\n            (-2, -1) / (self.num_vars - 1) \n\n         hidden = self.custom_gru(inputs, agg_msgs, hidden)  #5\n\n         pred = F.dropout(F.relu\\\n           (self.out_fc1(hidden)), \\\n           p=self.dropout_prob)  #6\n         pred = F.dropout(F.relu\\\n         (self.out_fc2(pred)), \\\n         p=self.dropout_prob) \n         pred = self.out_fc3(pred) \n\n         pred = inputs + pred   \n         return pred, hidden\n```", "```py\n   pbar = tqdm(range(start_epoch, num_epochs + 1), desc='Epochs')\n   for epoch in pbar:\n       model.train()  #1\n       model.train_percent = epoch / num_epochs\n       total_training_loss = 0\n       for batch in train_data_loader:\n           inputs = batch['inputs'].cuda(non_blocking=True)\n           loss, _, _, _, _ = model.\\\n              calculate_loss(inputs, \n              is_train=True, \n              return_logits=True)\n           loss.backward()  #2\n           optimizer.step() \n           optimizer.zero_grad()  #3\n           total_training_loss += loss.item()\n\n      if training_scheduler is not None:\n          training_scheduler.step()\n\n      total_nll, total_kl = 0, 0\n      for batch in val_data_loader:\n          inputs = batch['inputs'].cuda(non_blocking=True)\n            , loss_nll, loss_kl, _, _ = model.calculate_loss(inputs,\n            is_train=False, \n            teacher_forcing=True, \n            return_logits=True)\n          total_kl += loss_kl.sum().item()\n          total_nll += loss_nll.sum().item()\n\n          total_kl /= len(val_data)\n          total_nll /= len(val_data)\n          total_loss = total_kl + total_nll\n          tuning_loss = total_nll \n\n      if tuning_loss < best_val_result:\n          best_val_epoch, best_val_result = epoch, tuning_loss\n```", "```py\ndef eval_forward_prediction(model, \n  dataset, \n  burn_in, \n  forward_steps, \n  gpu=True, batch_size=8, \n  return_total_errors=False):\n\n  dataset.return_edges = False\n\n  data_loader = DataLoader\\\n    (dataset, batch_size=\\\n    batch_size, pin_memory=gpu)\n  model.eval()\n  total_se = 0\n  batch_count = 0\n  all_errors = []\n\n  for batch_ind, batch in enumerate(data_loader):\n    inputs = batch['inputs']\n    with torch.no_grad():\n      model_inputs = inputs[:, :burn_in]\n      gt_predictions = inputs[:, burn_in:burn_in+forward_steps]\n      model_inputs = model_inputs.cuda(non_blocking=True)\n      model_preds = model.predict_future(\n          model_inputs,\n          forward_pred_steps\n          ).cpu()\n      batch_count += 1\n      if return_total_errors:\n          all_errors.append(\n            F.mse_loss(\n              model_preds, \n              gt_predictions,\n              reduction='none'\n             ).view(\n               model_preds.size(0), \n               model_preds.size(1), -1\n             ).mean(dim=-1)\n          )\n      else:\n          total_se += F.mse_loss(\n            model_preds, \n            gt_predictions,\n            reduction='none'\n          ).view(\n            model_preds.size(0),\n            model_preds.size(1),\n            -1\n          ).mean(dim=-1).sum(dim=0)\n\n  if return_total_errors:\n         return torch.cat(all_errors, dim=0)\n     else:\n            return total_se / len(dataset)\n```", "```py\n   class PoseEstimationRNN(nn.Module):\n       def __init__(self, input_size, hidden_size, output_size, num_layers):\n           super(PoseEstimationRNN, self).__init__()\n\n           self.hidden_size = hidden_size\n           self.num_layers = num_layers\n\n           self.rnn = nn.RNN\\\n(input_size, hidden_size, \\\nnum_layers, batch_first=True)  #1\n           self.fc = nn.Linear(hidden_size, output_size)  #2\n\n       def forward(self, x):    \n           h0 = torch.zeros(self.num_layers,\\ #3\n             x.size(0), self.hidden_size)  #3\n           H0 = h0.to(x.device) \n\n           out, _ = self.rnn(x, h0)  #4\n           out = self.fc(out[:, -10:, :]) #5\n           return out\n```", "```py\n   class PoseEstimationGRU(nn.Module):\n       def __init__(self, input_size, hidden_size, output_size, num_layers):\n           super(PoseEstimationGRU, self).__init__()\n           self.hidden_size = hidden_size\n           self.num_layers = num_layers\n           self.gru = nn.GRU\\\n(input_size, hidden_size, \\\nnum_layers, batch_first=True)  #1\n           self.fc = nn.Linear(hidden_size, output_size)  #2\n\n        def forward(self, x):\n\n            h0 = torch.zeros\\\n(self.num_layers, \\\nx.size(0), self.hidden_size)  #3\n            h0 = h0.to(x.device)  #3\n            out, _ = self.gru(x, h0)  #4\n            out = self.fc(out[:, -10:, :])  #5\n            return out\n```"]