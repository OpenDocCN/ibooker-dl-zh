- en: Chapter 1\. The Five Principles of Prompting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章. 提示的五项原则
- en: '*Prompt engineering* is the process of discovering prompts that reliably yield
    useful or desired results.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示工程*是发现可靠产生有用或所需结果的提示的过程。'
- en: 'A *prompt* is the input you provide, typically text, when interfacing with
    an AI model like ChatGPT or Midjourney. The prompt serves as a set of instructions
    the model uses to predict the desired response: text from *large language models*
    (LLMs) like [ChatGPT](https://chat.openai.com), or images from *diffusion models*
    like [Midjourney](https://www.midjourney.com).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示*是您在与ChatGPT或Midjourney等AI模型交互时提供的输入，通常是文本。提示作为模型使用的一组指令，用于预测所需的响应：来自*大型语言模型*（LLMs）如[ChatGPT](https://chat.openai.com)的文本，或来自*扩散模型*如[Midjourney](https://www.midjourney.com)的图像。'
- en: Here is a simple example of a prompt input for a product name generator (inspired
    by one of [OpenAI’s examples](https://oreil.ly/Fc8cq)), and the resulting output
    from ChatGPT.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个产品名称生成器提示输入的简单示例（灵感来源于[OpenAI的示例](https://oreil.ly/Fc8cq)之一），以及ChatGPT生成的结果。
- en: 'Input:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Output:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is already a remarkable response for a naive prompt, which feels like magic
    because we got here with very little effort. As the state-of-the-art models improve,
    the likelihood you will get *good enough* results on your first try goes up. For
    any throwaway interactions with an AI, where you don’t plan to do the same task
    again, the naive approach is all you need.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经是对一个天真提示的非凡响应，感觉像魔法，因为我们几乎不费吹灰之力就做到了。随着最先进模型的改进，您在第一次尝试就获得*足够好*的结果的可能性增加。对于任何与AI的临时互动，您不打算再次执行相同任务，天真方法就足够了。
- en: 'However, if you planned to put this prompt into production, you’d benefit from
    investing more work into getting it right. Mistakes cost you money in terms of
    the fees OpenAI charges based on the length of the prompt and response, as well
    as the time spent fixing mistakes. If you were building a product name generator
    with thousands of users, there are some obvious issues you’d want attempt to fix:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果您计划将此提示投入生产，您将受益于投入更多精力以确保其正确性。错误会花费您金钱，因为OpenAI根据提示和响应的长度以及修复错误所花费的时间来收费。如果您正在构建一个拥有数千用户的名称生成器，有一些明显的问题您会想要尝试解决：
- en: Vague direction
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊的方向
- en: You’re not briefing the AI on what style of name you want, or what attributes
    it should have. Do you want a single word or a concatenation? Can the words be
    made up, or is it important that they’re in real English? Do you want the AI to
    emulate somebody you admire who is famous for great product names?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您没有向AI说明您想要的名称风格或它应该具有的属性。您想要一个单词还是组合？单词可以随意创造，还是它们必须是真正的英语？您想要AI模仿您钦佩的、以优秀产品名称而闻名的人？
- en: Unformatted output
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 未格式化的输出
- en: You’re getting back a list of separated names line by line, of unspecified length.
    When you run this prompt multiple times, you’ll see sometimes it comes back with
    a numbered list, and often it has text at the beginning, which makes it hard to
    parse programmatically.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您正在逐行返回一个分隔的名称列表，长度不固定。当您多次运行此提示时，您会看到有时它会返回一个编号列表，并且经常在开头有文本，这使得它难以程序化解析。
- en: Missing examples
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 缺少示例
- en: You haven’t given the AI any examples of what *good* names look like. It’s autocompleting
    using an average of its training data, i.e., the entire internet (with all its
    inherent bias), but is that what you want? Ideally you’d feed it examples of successful
    names, common names in an industry, or even just other names you like.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您没有给出任何关于*好名字*样子的例子。它正在使用训练数据的平均值自动补全，即整个互联网（及其固有的偏见），但这真的是您想要的吗？理想情况下，您会提供成功名称的例子，行业中的常见名称，或者甚至只是您喜欢的其他名称。
- en: Limited evaluation
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 评估有限
- en: You have no consistent or scalable way to define which names are good or bad,
    so you have to manually review each response. If you can institute a rating system
    or other form of measurement, you can optimize the prompt to get better results
    and identify how many times it fails.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 您没有一致或可扩展的方式来定义哪些名称是好是坏，因此您必须手动审查每个响应。如果您可以建立评分系统或其他形式的测量，您就可以优化提示以获得更好的结果，并确定它失败了多少次。
- en: No task division
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任务划分
- en: 'You’re asking a lot of a single prompt here: there are lots of factors that
    go into product naming, and this important task is being naively outsourced to
    the AI all in one go, with no task specialization or visibility into how it’s
    handling this task for you.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你在这里对单个提示的要求很多：产品命名涉及到许多因素，而这个重要的任务被天真地一次性外包给了AI，没有任何任务专业化或了解它如何为你处理这个任务的可见性。
- en: Addressing these problems is the basis for the core principles we use throughout
    this book. There are many different ways to ask an AI model to do the same task,
    and even slight changes can make a big difference. LLMs work by continuously predicting
    the next token (approximately three-fourths of a word), starting from what was
    in your prompt. Each new token is selected based on its probability of appearing
    next, with an element of randomness (controlled by the *temperature* parameter).
    As demonstrated in [Figure 1-1](#figure-1-1), the word *shoes* had a lower probability
    of coming after the start of the name *AnyFit* (0.88%), where a more predictable
    response would be *Athletic* (72.35%).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些问题是我们在这本书中使用的核心原则的基础。有许多不同的方式可以要求AI模型执行相同的任务，即使是微小的变化也可能产生很大的差异。LLMs通过连续预测下一个标记（大约是四分之三的单词）来工作，从你的提示开始。每个新标记都是根据其出现的概率来选择的，其中包含一定的随机性（由*温度*参数控制）。如图1-1所示，单词*鞋子*在名称*AnyFit*开始后的出现概率较低（0.88%），而更可预测的响应将是*运动型*（72.35%）。
- en: '![pega 0101](assets/pega_0101.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0101](assets/pega_0101.png)'
- en: Figure 1-1\. How the response breaks down into tokens
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 响应如何分解为标记
- en: LLMs are trained on essentially the entire text of the internet, and are then
    further fine-tuned to give helpful responses. Average prompts will return average
    responses, leading some to be underwhelmed when their results don’t live up to
    the hype. What you put in your prompt changes the probability of every word generated,
    so it matters a great deal to the results you’ll get. These models have seen the
    best and worst of what humans have produced and are capable of emulating almost
    anything if you know the right way to ask. OpenAI charges based on the [number
    of tokens used](https://openai.com/pricing) in the prompt and the response, so
    prompt engineers need to make these tokens count by optimizing prompts for cost,
    quality, and reliability.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在本质上训练了整个互联网的文本，然后进一步微调以提供有用的响应。平均提示将返回平均响应，导致一些人当他们的结果没有达到预期时感到失望。你放在提示中的内容会改变每个生成的单词的概率，因此这对你将得到的结果有很大影响。这些模型已经看到了人类产生的最好和最坏的东西，并且如果你知道正确的方式提问，它们几乎可以模仿任何东西。OpenAI根据提示和响应中使用的[标记数量](https://openai.com/pricing)来收费，因此提示工程师需要通过优化提示以成本、质量和可靠性来确保这些标记的价值。
- en: Here’s the same example with the application of several prompt engineering techniques.
    We ask for names in the style of Steve Jobs, state that we want a comma-separated
    list, and supply examples of the task done well.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是应用了几个提示工程技术的相同示例。我们要求以史蒂夫·乔布斯的方式提供名字，并说明我们想要一个以逗号分隔的列表，并提供完成任务做得好的示例。
- en: 'Input:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Output:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: While no prompt is ever perfect, this prompt is optimized to reliably deliver
    solid product names in the right format. The user of your product name generator
    can choose somebody other than Steve Jobs to get the types of names they like,
    they can change the response format if needed, and the output of this prompt can
    become the input of another. Finally, you could periodically update the examples
    you use in the prompt based on user feedback, making your system smarter over
    time.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有任何提示是完美的，但这个提示被优化以可靠地以正确的格式提供坚实的商品名称。你的产品名称生成器的用户可以选择除史蒂夫·乔布斯之外的人来获取他们喜欢的名字，如果需要，他们可以更改响应格式，并且这个提示的输出可以成为另一个输入。最后，你可以根据用户反馈定期更新你在提示中使用的示例，使你的系统随着时间的推移变得更智能。
- en: Overview of the Five Principles of Prompting
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示五原则概述
- en: 'The process for optimizing this prompt follows the *Five Principles of Prompting*,
    which we will dissect using this example in the remainder of this chapter, and
    recall throughout the book. They map exactly to the five issues we raised when
    discussing the naive text prompt. You’ll find references back to these principles
    throughout the rest of the book to help you connect the dots to how they’re used
    in practice. The Five Principles of Prompting are as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 优化此提示的过程遵循**提示的五个原则**，我们将使用本章节的其余部分来剖析这些原则，并在整本书中回顾。它们与我们在讨论天真文本提示时提出的五个问题完全对应。您将在整本书的其余部分找到对这些原则的引用，以帮助您了解它们在实际中的应用。提示的五个原则如下：
- en: Give Direction
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 指明方向
- en: Describe the desired style in detail, or reference a relevant persona
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 详细描述期望的风格，或参考相关角色
- en: Specify Format
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 指定格式
- en: Define what rules to follow, and the required structure of the response
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 定义需要遵循的规则以及响应的所需结构
- en: Provide Examples
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 提供示例
- en: Insert a diverse set of test cases where the task was done correctly
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 插入一组多样化的测试案例，其中任务执行正确
- en: Evaluate Quality
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 评估质量
- en: Identify errors and rate responses, testing what drives performance.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 识别错误并评估响应，测试驱动性能的因素。
- en: Divide Labor
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 分工合作
- en: Split tasks into multiple steps, chained together for complex goals
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 将任务拆分为多个步骤，以实现复杂目标
- en: 'These principles are not short-lived *tips* or *hacks* but are generally accepted
    conventions that are useful for working with any level of intelligence, biological
    or artificial. These principles are model-agnostic and should work to improve
    your prompt no matter which generative text or image model you’re using. We first
    published these principles in July 2022 in the blog post [“Prompt Engineering:
    From Words to Art and Copy”](https://oreil.ly/RYYiV), and they have stood the
    test of time, including mapping quite closely to OpenAI’s own [Prompt Engineering
    Guide](https://oreil.ly/dF8q-), which came a year later. Anyone who works closely
    with generative AI models is likely to converge on a similar set of strategies
    for solving common issues, and throughout this book you’ll see hundreds of demonstrative
    examples of how they can be useful for improving your prompts.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些原则不是短暂的**技巧**或**捷径**，而是普遍接受的、适用于任何智能水平（生物或人工）的惯例。这些原则是模型无关的，并且无论您使用哪种生成文本或图像模型，都应该有助于改进您的提示。我们首次在2022年7月发布的博客文章“提示工程：从文字到艺术和文案”中发布这些原则，并且它们经受了时间的考验，包括与OpenAI一年后发布的[提示工程指南](https://oreil.ly/dF8q-)非常接近。任何与生成AI模型紧密合作的人可能会汇聚到解决常见问题的相似策略，并在整本书中，您将看到数百个如何使用这些策略来改进提示的示范性例子。
- en: We have provided downloadable one-pagers for text and image generation you can
    use as a checklist when applying these principles. These were created for our
    popular Udemy course [The Complete Prompt Engineering for AI Bootcamp](https://oreil.ly/V40zg)
    (70,000+ students), which was based on the same principles but with different
    material to this book.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为文本和图像生成提供了可下载的单页指南，您可以在应用这些原则时将其作为清单使用。这些指南是为我们流行的Udemy课程[AI训练营的完整提示工程](https://oreil.ly/V40zg)（70,000+
    学生）制作的，该课程基于相同的原则，但材料与本书不同。
- en: '[Text Generation One-Pager](https://oreil.ly/VCcgy)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文本生成单页指南](https://oreil.ly/VCcgy)'
- en: '[Image Generation One-Pager](https://oreil.ly/q7wQF)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像生成单页指南](https://oreil.ly/q7wQF)'
- en: To show these principles apply equally well to prompting image models, let’s
    use the following example, and explain how to apply each of the Five Principles
    of Prompting to this specific scenario. Copy and paste the entire input prompt
    into the Midjourney Bot in Discord, including the link to the image at the beginning,
    after typing `**/imagine**` to trigger the prompt box to appear (requires a free
    [Discord](https://discord.com) account, and a paid [Midjourney](https://www.midjourney.com)
    account).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示这些原则同样适用于提示图像模型，让我们使用以下示例，并解释如何将提示的五个原则应用于这个特定场景。将整个输入提示复制并粘贴到Discord的Midjourney
    Bot中，包括开头到图像链接，在键入`**/imagine**`以触发提示框出现之后（需要免费[Discord](https://discord.com)账户和付费[Midjourney](https://www.midjourney.com)账户）。
- en: 'Input:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[Figure 1-2](#figure-1-2) shows the output.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-2](#figure-1-2)显示了输出。'
- en: '![pega 0102](assets/pega_0102.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0102](assets/pega_0102.png)'
- en: Figure 1-2\. Stock photo of business meeting
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2. 商务会议的股票照片
- en: This prompt takes advantage of Midjourney’s ability to take a base image as
    an example by uploading the image to Discord and then copy and pasting the URL
    into the prompt (*[*https://s.mj.run/TKAsyhNiKmc*](https://s.mj.run/TKAsyhNiKmc)*),
    for which the royalty-free image from Unsplash is used ([Figure 1-3](#figure-1-3)).
    If you run into an error with the prompt, try uploading the image yourself and
    reviewing [Midjourney’s documentation](https://oreil.ly/UTxpX) for any formatting
    changes.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示利用了Midjourney将基础图像作为示例的能力，通过将图像上传到Discord，然后将URL复制粘贴到提示中（[*https://s.mj.run/TKAsyhNiKmc*](https://s.mj.run/TKAsyhNiKmc)），这里使用了Unsplash的免费图片（[图1-3](#figure-1-3)）。如果你在提示中遇到错误，请尝试自己上传图像并查看Midjourney的文档（[Midjourney的文档](https://oreil.ly/UTxpX)）以了解任何格式更改。
- en: '![pega 0103](assets/pega_0103.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0103](assets/pega_0103.png)'
- en: Figure 1-3\. Photo by Mimi Thian on [Unsplash](https://oreil.ly/J4Hkr)
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3. 由Mimi Thian在[Unsplash](https://oreil.ly/J4Hkr)拍摄的照片
- en: Let’s compare this well-engineered prompt to what you get back from Midjourney
    if you naively ask for a stock photo in the simplest way possible. [Figure 1-4](#figure-1-4)
    shows an example of what you get without prompt engineering, an image with a darker,
    more stylistic take on a stock photo than you’d typically expect.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较一下这个精心设计的提示与你在以最简单的方式请求股票照片时从Midjourney得到的结果。图1-4显示了没有提示工程时得到的一个例子，这个图像比通常预期的股票照片风格更暗、更具有风格化。
- en: 'Input:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[Figure 1-4](#figure-1-4) shows the output.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-4](#figure-1-4)显示了输出。'
- en: Although less prominent an issue in v5 of Midjourney onwards, community feedback
    mechanisms (when users select an image to resize to a higher resolution, that
    choice may be used to train the model) have reportedly biased the model toward
    a *fantasy* aesthetic, which is less suitable for the stock photo use case. The
    early adopters of Midjourney came from the digital art world and naturally gravitated
    toward fantasy and sci-fi styles, which can be reflected in the results from the
    model even when this aesthetic is not suitable.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在Midjourney v5及以后的版本中这个问题不太突出，但社区反馈机制（当用户选择将图像调整到更高分辨率时，这个选择可能会用于训练模型）据报道已经使模型偏向于*幻想*美学，这对于股票照片用例不太合适。Midjourney的早期用户来自数字艺术界，自然倾向于幻想和科幻风格，即使这种美学不适合，这种风格也会反映在模型的结果中。
- en: '![pega 0104](assets/pega_0104.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0104](assets/pega_0104.png)'
- en: Figure 1-4\. People in a business meeting
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4. 商务会议中的人们
- en: Throughout this book the examples used will be compatiable with ChatGPT Plus
    (GPT-4) as the text model and Midjourney v6 or Stable Diffusion XL as the image
    model, though we will specify if it’s important. These foundational models are
    the current state of the art and are good at a diverse range of tasks. The principles
    are intended to be future-proof as much as is possible, so if you’re reading this
    book when GPT-5, Midjourney v7, or Stable Diffusion XXL is out, or if you’re using
    another vendor like Google, everything you learn here should still prove useful.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中使用的示例将与ChatGPT Plus（GPT-4）作为文本模型和Midjourney v6或Stable Diffusion XL作为图像模型兼容，尽管如果重要我们会进行说明。这些基础模型是当前最先进的技术，擅长各种任务。原则旨在尽可能保证未来兼容性，所以如果你在GPT-5、Midjourney
    v7或Stable Diffusion XXL发布时阅读这本书，或者如果你使用的是其他供应商如Google，这里学到的一切仍然应该是有用的。
- en: 1\. Give Direction
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 给出方向
- en: One of the issues with the naive text prompt discussed earlier was that it wasn’t
    briefing the AI on what *types* of product names you wanted. To some extent, naming
    a product is a subjective endeavor, and without giving the AI an idea of what
    names you like, it has a low probability of guessing right.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 之前讨论的简单文本提示的一个问题是，它没有向AI说明你想要的产品名称的类型。在某种程度上，给产品命名是一项主观的活动，如果不给AI一个你喜欢的名称的想法，它猜对的概率很低。
- en: By the way, a human would also struggle to complete this task without a good
    *brief*, which is why creative and branding agencies require a detailed briefing
    on any task from their clients.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，没有良好的*简报*，人类也很难完成这项任务，这就是为什么创意和品牌代理机构需要从客户那里获得任何任务的详细简报。
- en: Tip
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Although it’s not a perfect mapping, it can be helpful to imagine what context
    a human might need for this task and try including it in the prompt.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这不是完美的映射，但可以想象人类可能需要什么样的上下文来完成这项任务，并尝试将其包含在提示中。
- en: In the example prompt we gave direction through the use of *role-playing*, in
    that case emulating the style of Steve Jobs, who was famous for iconically naming
    products. If you change this aspect of the prompt to someone else who is famous
    in the training data (as well as matching the examples to the right style), you’ll
    get dramatically different results.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们给出的示例提示中，我们通过使用*角色扮演*来给出方向，在那个例子中是模仿史蒂夫·乔布斯，他因标志性地为产品命名而闻名。如果你将提示的这个方面改为训练数据中著名的人物（以及将示例与正确的风格匹配），你会得到截然不同的结果。
- en: 'Input:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Output:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: There are also some rules or best practices you would do well to follow, which
    could be included in the prompt as context to guide the AI toward a name that
    works. This technique is sometimes referred to as *prewarming* or *internal retrieval*,
    and it is simple but effective ([Liu et al., 2021](https://oreil.ly/1lqzK)). Starting
    the conversation asking for best practice advice, then asking it to follow its
    own advice, can help a lot. In effect, you are using it to generate its own direction.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一些规则或最佳实践是你应该遵循的，这些可以包含在提示中作为上下文，以引导AI向一个可行的名字发展。这种技术有时被称为*预热*或*内部检索*，它简单但有效
    ([刘等人，2021](https://oreil.ly/1lqzK))。开始对话时请求最佳实践建议，然后要求它遵循自己的建议，这会有很大帮助。实际上，你是在用它来生成自己的方向。
- en: 'Input:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Output:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Then within the same chat window, where the model has the context of the past
    advice it gave, you ask your initial prompt for the task you wanted to complete.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在同一个聊天窗口中，模型拥有它之前给出的建议的上下文，你提出你想要完成的任务的初始提示。
- en: 'Input:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Output:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Another fruitful strategy in our experience is to take the best advice out there
    for the task you want to accomplish and insert that context into the prompt. For
    example, you could take [Brandwatch’s 5 Golden Rules for naming a product](https://oreil.ly/3bWjz)
    or another trusted external resource you find, and insert that as context into
    the prompt. This will increase the length of the prompt significantly, which costs
    more money (when using the API as a developer), but may be worth the trade-off
    if the quality of the response improves.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的经验中，另一个富有成效的策略是将你想要完成的任务的最佳建议提取出来，并将其上下文插入到提示中。例如，你可以采用[Brandwatch的5条黄金法则来命名产品](https://oreil.ly/3bWjz)或你找到的另一个可信的外部资源，并将其作为上下文插入到提示中。这将显著增加提示的长度，这会花费更多的钱（当作为开发者使用API时），但如果响应的质量有所提高，这可能值得权衡。
- en: 'Input:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Output:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: There are other myriad ways of providing direction. In the image generation
    example, direction was given by specifying that the business meeting is taking
    place around a glass-top table. If you change only that detail, you can get a
    completely different image, as detailed in [Figure 1-5](#figure-1-5).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 提供方向的方法有很多。在图像生成示例中，通过指定商务会议是在一个玻璃桌周围举行的来给出方向。如果你只改变这个细节，你可以得到一个完全不同的图像，如[图1-5](#figure-1-5)中详细说明的那样。
- en: 'Input:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[Figure 1-5](#figure-1-5) shows the output.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-5](#figure-1-5)显示了输出。'
- en: '![pega 0105](assets/pega_0105.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0105](assets/pega_0105.png)'
- en: Figure 1-5\. Stock photo of business meeting in the woods
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-5\. 丛林中的商务会议的股票照片
- en: Role-playing is also important for image generation, and one of the quite powerful
    ways you can give Midjourney direction is to supply the name of an artist or art
    style to emulate. One artist that features heavily in the AI art world is Van
    Gogh, known for his bold, dramatic brush strokes and vivid use of colors. Watch
    what happens when you include his name in the prompt, as shown in [Figure 1-6](#figure-1-6).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 角色扮演对于图像生成也很重要，你可以通过提供要模仿的艺术家或艺术风格的名字来给Midjourney提供方向。在AI艺术界中，梵高是一个经常被提及的艺术家，他以其大胆、戏剧性的笔触和生动的色彩运用而闻名。看看当你将他的名字包含在提示中时会发生什么，如[图1-6](#figure-1-6)所示。
- en: 'Input:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE15]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[Figure 1-6](#figure-1-6) shows the output.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-6](#figure-1-6)显示了输出。'
- en: '![pega 0106](assets/pega_0106.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0106](assets/pega_0106.png)'
- en: Figure 1-6\. People in a business meeting, by Van Gogh
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-6\. 梵高风格的商务会议中的人物
- en: To get that last prompt to work, you need to strip back a lot of the other direction.
    For example, losing the base image and the words *stock photo* as well as the
    camera *Panasonic, DC-GH5* helps bring in Van Gogh’s style. The problem you may
    run into is that often with too much direction, the model can quickly get to a
    conflicting combination that it can’t resolve. If your prompt is overly specific,
    there might not be enough samples in the training data to generate an image that’s
    consistent with all of your criteria. In cases like these, you should choose which
    element is more important (in this case, Van Gogh) and defer to that.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 要使最后一个提示生效，你需要删除很多其他指导。例如，移除基础图像和单词“*库存照片*”，以及相机“*松下，DC-GH5*”有助于引入梵高的风格。你可能会遇到的问题是，通常在过多的指导下，模型会迅速达到一个它无法解决的冲突组合。如果你的提示过于具体，训练数据中可能没有足够的样本来生成符合所有你标准的图像。在这种情况下，你应该选择哪个元素更重要（在这种情况下，是梵高），并据此做出让步。
- en: Direction is one of the most commonly used and broadest principles. It can take
    the form of simply using the right descriptive words to clarify your intent, or
    channeling the personas of relevant business celebrities. While too much direction
    can narrow the creativity of the model, too little direction is the more common
    problem.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 指导是使用最普遍和最广泛的原则之一。它可以采取简单地使用正确的描述性词语来阐明你的意图，或者模仿相关商业名人的形象。虽然过多的指导可能会限制模型的创造力，但指导不足是更常见的问题。
- en: 2\. Specify Format
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 指定格式
- en: AI models are universal translators. Not only does that mean translating from
    French to English, or Urdu to Klingon, but also between data structures like JSON
    to YAML, or natural language to Python code. These models are capable of returning
    a response in almost any format, so an important part of prompt engineering is
    finding ways to specify what format you want the response to be in.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: AI模型是通用的翻译器。这不仅意味着从法语翻译成英语，或从乌尔都语翻译成克林贡语，还包括在数据结构之间，如从JSON到YAML，或从自然语言到Python代码之间的转换。这些模型能够以几乎任何格式返回响应，因此提示工程的重要部分是找到指定你想要响应的格式的方法。
- en: Every now and again you’ll find that the same prompt will return a different
    format, for example, a numbered list instead of comma separated. This isn’t a
    big deal most of the time, because most prompts are one-offs and typed into ChatGPT
    or Midjourney. However, when you’re incorporating AI tools into production software,
    occasional flips in format can cause all kinds of errors.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 有时你会发现相同的提示会返回不同的格式，例如，是编号列表而不是逗号分隔列表。这通常不是什么大问题，因为大多数提示都是一次性的，并且是在ChatGPT或Midjourney中输入的。然而，当你将AI工具集成到生产软件中时，偶尔的格式变化可能会导致各种错误。
- en: Just like when working with a human, you can avoid wasted effort by specifying
    up front the format you expect the response to be in. For text generation models,
    it can often be helpful to output JSON instead of a simple ordered list because
    that’s the universal format for API responses, which can make it simpler to parse
    and spot errors, as well as to use to render the front-end HTML of an application.
    YAML is also another popular choice because it enforces a parseable structure
    while still being simple and human-readable.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 就像与人类合作一样，你可以通过提前指定你期望的响应格式来避免浪费精力。对于文本生成模型来说，输出JSON而不是简单的有序列表通常很有帮助，因为那是API响应的通用格式，这使得解析和查找错误更加简单，同时也可以用来渲染应用程序的前端HTML。YAML也是另一个流行的选择，因为它强制执行可解析的结构，同时仍然简单且易于阅读。
- en: In the original prompt you gave direction through both the examples provided,
    and the colon at the end of the prompt indicated it should complete the list inline.
    To swap the format to JSON, you need to update both and leave the JSON uncompleted,
    so GPT-4 knows to complete it.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在你给出的原始提示中，你通过提供的示例和提示末尾的冒号来指示应该直接在行内完成列表。要将格式转换为JSON，你需要更新这两处，并留下JSON未完成，这样GPT-4就会知道需要完成它。
- en: 'Input:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Output:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output we get back is the completed JSON containing the product names.
    This can then be parsed and used programmatically, in an application or local
    script. It’s also easy from this point to check if there’s an error in the formatting
    using a JSON parser like Python’s standard *json* library, because broken JSON
    will result in a parsing error, which can act as a trigger to retry the prompt
    or investigate before continuing. If you’re still not getting the right format
    back, it can help to specify at the beginning or end of the prompt, or in the
    system message if using a chat model: `You are a helpful assistant that only responds
    in JSON`, or specify [JSON output](https://oreil.ly/E7wua) in the model parameters
    where available (this is called *grammars* with [Llama models](https://oreil.ly/yU27T).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的输出是包含产品名称的完整JSON。然后可以解析并用于程序化，在应用程序或本地脚本中。从这个点开始，使用Python标准 *json* 库之类的JSON解析器检查格式错误也很容易，因为损坏的JSON会导致解析错误，这可以作为重试提示或在进行下一步之前进行调查的触发器。如果你仍然没有得到正确的格式，在提示的开始或结束处，或者在使用聊天模型时在系统消息中指定可能有所帮助：`你是一个只以JSON格式响应的有用助手`，或者在模型参数中指定[JSON输出](https://oreil.ly/E7wua)（这在[Llama模型](https://oreil.ly/yU27T)中被称为*语法*）。
- en: Tip
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: To get up to speed on JSON if you’re unfamiliar, W3Schools [has a good introduction](https://oreil.ly/Xakgc).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不太熟悉JSON，W3Schools [有一个很好的介绍](https://oreil.ly/Xakgc)。
- en: For image generation models, format is very important, because the opportunities
    for modifying an image are near endless. They range from obvious formats like
    `stock photo`, `illustration`, and `oil painting`, to more unusual formats like
    `dashcam footage`, `ice sculpture`, or `in Minecraft` (see [Figure 1-7](#figure-1-7)).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像生成模型来说，格式非常重要，因为修改图像的机会几乎是无穷无尽的。这些格式从明显的类型，如`股票照片`、`插画`和`油画`，到更不寻常的类型，如`行车记录仪视频`、`冰雕`，或者在《我的世界》中（见[图1-7](#figure-1-7)）。
- en: 'Input:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE18]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[Figure 1-7](#figure-1-7) shows the output.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-7](#figure-1-7)显示了输出。'
- en: '![pega 0107](assets/pega_0107.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0107](assets/pega_0107.png)'
- en: Figure 1-7\. Business meeting in Minecraft
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-7. 《我的世界》中的商务会议
- en: When setting a format, it is often necessary to remove other aspects of the
    prompt that might clash with the specified format. For example, if you supply
    a base image of a stock photo, the result is some combination of stock photo and
    the format you wanted. To some degree, image generation models can generalize
    to new scenarios and combinations they haven’t seen before in their training set,
    but in our experience, the more layers of unrelated elements, the more likely
    you are to get an unsuitable image.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置格式时，通常需要删除可能与指定格式冲突的其他提示方面。例如，如果你提供的是股票照片的基础图像，结果将是股票照片和你想要的格式的某种组合。在一定程度上，图像生成模型可以推广到他们在训练集中之前未见过的新的场景和组合，但根据我们的经验，无关元素的层次越多，得到不合适图像的可能性就越大。
- en: There is often some overlap between the first and second principles, Give Direction
    and Specify Format. The latter is about defining what type of output you want,
    for example JSON format, or the format of a stock photo. The former is about the
    style of response you want, independent from the format, for example product names
    in the style of Steve Jobs, or an image of a business meeting in the style of
    Van Gogh. When there are clashes between style and format, it’s often best to
    resolve them by dropping whichever element is less important to your final result.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 第一原则和第二原则之间往往存在一些重叠，即给出方向和指定格式。后者是关于定义你想要的输出类型，例如JSON格式，或股票照片的格式。前者是关于你想要的响应风格，独立于格式，例如以史蒂夫·乔布斯风格的产品名称，或梵高风格的商务会议图像。当风格和格式发生冲突时，通常最好通过删除对最终结果不那么重要的元素来解决。
- en: 3\. Provide Examples
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 提供示例
- en: 'The original prompt didn’t give the AI any examples of what you think *good*
    names look like. Therefore, the response is approximate to an average of the internet,
    and you can do better than that. Researchers would call a prompt with no examples
    *zero-shot*, and it’s always a pleasant surprise when AI can even do a task zero
    shot: it’s a sign of a powerful model. If you’re providing zero examples, you’re
    asking for a lot without giving much in return. Even providing one example (*one-shot*)
    helps considerably, and it’s the norm among researchers to test how models perform
    with multiple examples (*few-shot*). One such piece of research is the famous
    GPT-3 paper [“Language Models are Few-Shot Learners”](https://oreil.ly/KW5PS),
    the results of which are illustrated in [Figure 1-8](#figure-1-8), showing adding
    one example along with a prompt can improve accuracy in some tasks from 10% to
    near 50%!'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 原始提示没有给出你认为*好的*名称样例。因此，响应近似于互联网的平均水平，你可以做得更好。研究人员将没有示例的提示称为*零样本*，当AI甚至能够零样本完成任务时，这总是一个令人愉快的惊喜：这是强大模型的标志。如果你提供零个示例，你是在索取很多而回报很少。即使提供一个示例（*单样本*）也能大大帮助，研究人员通常测试模型在多个示例（*少样本*）下的表现是常态。这样一项著名的研究是GPT-3论文[“语言模型是少样本学习者”](https://oreil.ly/KW5PS)，其结果在[图
    1-8](#figure-1-8)中展示，显示添加一个示例与提示结合可以提高某些任务的准确性，从10%提高到近50%！
- en: '![pega 0108](assets/pega_0108.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0108](assets/pega_0108.png)'
- en: Figure 1-8\. Number of examples in context
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-8\. 上下文中的示例数量
- en: When briefing a colleague or training a junior employee on a new task, it’s
    only natural that you’d include examples of times that task had previously been
    done well. Working with AI is the same, and the strength of a prompt often comes
    down to the examples used. Providing examples can sometimes be easier than trying
    to explain exactly what it is about those examples you like, so this technique
    is most effective when you are not a domain expert in the subject area of the
    task you are attempting to complete. The amount of text you can fit in a prompt
    is limited (at the time of writing around 6,000 characters on Midjourney and approximately
    32,000 characters for the free version of ChatGPT), so a lot of the work of prompt
    engineering involves selecting and inserting diverse and instructive examples.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 当向同事简要介绍一项新任务或培训初级员工时，自然地你会包括该任务之前做得好的示例。与AI合作也是如此，提示的强度通常取决于所使用的示例。提供示例有时比试图解释你为什么喜欢那些示例要容易，因此当你在尝试完成的任务的主题领域不是领域专家时，这种技术最为有效。你可以在提示中放入的文本量是有限的（截至写作时，Midjourney上大约有6,000个字符，ChatGPT免费版本大约有32,000个字符），因此提示工程的大部分工作涉及选择和插入多样且富有教育意义的示例。
- en: 'There’s a trade-off between reliability and creativity: go past three to five
    examples and your results will become more reliable, while sacrificing creativity.
    The more examples you provide, and the lesser the diversity between them, the
    more constrained the response will be to match your examples. If you change all
    of the examples to animal names in the previous prompt, you’ll have a strong effect
    on the response, which will reliably return only names including animals.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在可靠性和创造力之间有一个权衡：超过三个到五个示例，你的结果将变得更加可靠，但会牺牲创造力。你提供的示例越多，它们之间的多样性越少，响应将越受限于匹配你的示例。如果你将前一个提示中的所有示例都改为动物名称，这将强烈影响响应，可靠地只返回包含动物的名称。
- en: 'Input:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE19]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Output:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE20]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Of course this runs the risk of missing out on returning a much better name
    that doesn’t fit the limited space left for the AI to play in. Lack of diversity
    and variation in examples is also a problem in handling edge cases, or uncommon
    scenarios. Including one to three examples is easy and almost always has a positive
    effect, but above that number it becomes essential to experiment with the number
    of examples you include, as well as the similarity between them. There is some
    evidence ([Hsieh et al., 2023](https://oreil.ly/6Ixcw)) that direction works better
    than providing examples, and it typically isn’t straightforward to collect good
    examples, so it’s usually prudent to attempt the principle of Give Direction first.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这也存在错过返回一个更适合有限空间内AI发挥的更好名称的风险。示例的多样性和变化不足也是处理边缘情况或罕见场景的问题。包括一到三个示例很容易，并且几乎总是有积极的效果，但超过这个数量，就变得必须实验包含的示例数量以及它们之间的相似性。有证据([Hsieh
    et al., 2023](https://oreil.ly/6Ixcw))表明，给出方向比提供示例更有效，而且通常收集好的示例并不简单，因此通常明智的做法是首先尝试给出方向的原则。
- en: In the image generation space, providing examples usually comes in the form
    of providing a base image in the prompt, called *img2img* in the open source [Stable
    Diffusion](https://oreil.ly/huVRu) community. Depending on the image generation
    model being used, these images can be used as a starting point for the model to
    generate from, which greatly affects the results. You can keep everything about
    the prompt the same but swap out the provided base image for a radically different
    effect, as in [Figure 1-9](#figure-1-9).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像生成领域，提供示例通常是通过在提示中提供一个基础图像来实现的，在开源 [Stable Diffusion](https://oreil.ly/huVRu)
    社区中被称为 *img2img*。根据所使用的图像生成模型，这些图像可以作为模型生成内容的起点，这对结果有很大影响。你可以保持提示的所有内容不变，但将提供的基图像替换为截然不同的图像，从而产生不同的效果，如[图1-9](#figure-1-9)所示。
- en: 'Input:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE21]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[Figure 1-9](#figure-1-9) shows the output.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-9](#figure-1-9)显示了输出。'
- en: '![pega 0109](assets/pega_0109.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0109](assets/pega_0109.png)'
- en: Figure 1-9\. Stock photo of business meeting of four people
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-9. 四人商务会议的股票照片
- en: In this case, by substituting for the image shown in [Figure 1-10](#figure-1-10),
    also from Unsplash, you can see how the model was pulled in a different direction
    and incorporates whiteboards and sticky notes now.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，通过替换[图1-10](#figure-1-10)中显示的图像，也是来自Unsplash的，你可以看到模型被引导到不同的方向，并且现在包含了白板和便利贴。
- en: Caution
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: These examples demonstrate the capabilities of image generation models, but
    we would exercise caution when uploading base images for use in prompts. Check
    the licensing of the image you plan to upload and use in your prompt as the base
    image, and avoid using clearly copyrighted images. Doing so can land you in legal
    trouble and is against the terms of service for all the major image generation
    model providers.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例展示了图像生成模型的能力，但我们在上传用于提示的基础图像时要谨慎。检查你计划上传并用作提示基图像的图像的许可，并避免使用明显受版权保护的照片。这样做可能会让你陷入法律纠纷，并且违反所有主要图像生成模型提供商的服务条款。
- en: '![pega 0110](assets/pega_0110.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0110](assets/pega_0110.png)'
- en: Figure 1-10\. Photo by Jason Goodman on [Unsplash](https://oreil.ly/ZbzZy)
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10. Jason Goodman在[Unsplash](https://oreil.ly/ZbzZy)上的照片
- en: 4\. Evaluate Quality
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 评估质量
- en: As of yet, there has been no feedback loop to judge the quality of your responses,
    other than the basic trial and error of running the prompt and seeing the results,
    referred to as [*blind prompting*](https://oreil.ly/42rSz). This is fine when
    your prompts are used temporarily for a single task and rarely revisited. However,
    when you’re reusing the same prompt multiple times or building a production application
    that relies on a prompt, you need to be more rigorous with measuring results.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，还没有反馈循环来判断你响应的质量，除了通过运行提示并查看结果的基本试错方法，这被称为[*盲提示*](https://oreil.ly/42rSz)。当你的提示仅用于临时执行单一任务且很少再次访问时，这是可以接受的。然而，当你多次重用相同的提示或构建依赖于提示的生产应用程序时，你需要更严格地衡量结果。
- en: There are a number of ways performance can be evaluated, and it depends largely
    on what tasks you’re hoping to accomplish. When a new AI model is released, the
    focus tends to be on how well the model did on *evals* (evaluations), a standardized
    set of questions with predefined answers or grading criteria that are used to
    test performance across models. Different models perform differently across different
    types of tasks, and there is no guarantee a prompt that worked previously will
    translate well to a new model. OpenAI has [made its evals framework](https://oreil.ly/wolEL)
    for benchmarking performance of LLMs open source and encourages others to contribute
    additional eval templates.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 评估性能的方法有很多，这主要取决于你希望完成哪些任务。当一个新的 AI 模型发布时，重点往往在于模型在*评估*（评估）上的表现如何，这是一个标准化的问题集，具有预定义的答案或评分标准，用于测试模型间的性能。不同的模型在不同类型的任务上表现不同，不能保证之前有效的提示在新模型上也能很好地转换。OpenAI
    已经将其用于基准测试 LLM 性能的 evals 框架开源，并鼓励其他人贡献额外的评估模板。
- en: In addition to the standard academic evals, there are also more headline-worthy
    tests like [GPT-4 passing the bar exam](https://oreil.ly/txhSZ). Evaluation is
    difficult for more subjective tasks, and can be time-consuming or prohibitively
    costly for smaller teams. In some instances researchers have turned to using more
    advanced models like GPT-4 to evaluate responses from less sophisticated models,
    as was done with [the release of Vicuna-13B](https://oreil.ly/NW3WX), a fine-tuned
    model based on Meta’s Llama open source model (see [Figure 1-11](#figure-1-11)).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标准的学术评估外，还有一些更具新闻价值的测试，例如 [GPT-4 通过了律师资格考试](https://oreil.ly/txhSZ)。对于更主观的任务，评估可能很困难，对于较小的团队来说可能耗时或成本高昂。在某些情况下，研究人员已经转向使用更先进的模型，如
    GPT-4，来评估来自较不复杂的模型的响应，正如在 [Vicuna-13B 的发布](https://oreil.ly/NW3WX)中所做的那样，这是一个基于
    Meta 的 Llama 开源模型的微调模型（参见[图 1-11](#figure-1-11)）。
- en: '![pega 0111](assets/pega_0111.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0111](assets/pega_0111.png)'
- en: Figure 1-11\. Vicuna GPT-4 Evals
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-11\. Vicuna GPT-4 评估
- en: More rigorous evaluation techniques are necessary when writing scientific papers
    or grading a new foundation model release, but often you will only need to go
    just one step above basic trial and error. You may find that a simple thumbs-up/thumbs-down
    rating system implemented in a Jupyter Notebook can be enough to add some rigor
    to prompt optimization, without adding too much overhead. One common test is to
    see whether providing examples is worth the additional cost in terms of prompt
    length, or whether you can get away with providing no examples in the prompt.
    The first step is getting responses for multiple runs of each prompt and storing
    them in a spreadsheet, which we will do after setting up our environment.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写科学论文或评估新的基础模型发布时，需要更严格的评估技术，但通常你只需要比基本的试错多走一步。你可能发现，在 Jupyter Notebook 中实现的简单点赞/踩不点赞系统足以增加对提示优化的严谨性，而不会增加太多开销。一个常见的测试是看看提供示例是否值得额外的提示长度成本，或者你是否可以在提示中不提供示例也能应付。第一步是获取每个提示的多次运行响应并将它们存储在电子表格中，我们将在设置好环境后进行此操作。
- en: You can install the OpenAI Python package with `pip install openai`. If you’re
    running into compatability issues with this package, create a virtual environment
    and install our [*requirements.txt*](https://oreil.ly/2KDV6) (instructions in
    the preface).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `pip install openai` 安装 OpenAI Python 包。如果你遇到与此包的兼容性问题，请创建一个虚拟环境并安装我们的[*requirements.txt*](https://oreil.ly/2KDV6)（请参阅前言中的说明）。
- en: To utilize the API, you’ll need to [create an OpenAI account](https://oreil.ly/oGv4j)
    and then [navigate here for your API key](https://oreil.ly/oHID1).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 API，你需要[创建一个 OpenAI 账户](https://oreil.ly/oGv4j)，然后[在此处导航以获取你的 API 密钥](https://oreil.ly/oHID1)。
- en: Warning
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Hardcoding API keys in scripts is not recommended due to security reasons. Instead,
    utilize environment variables or configuration files to manage your keys.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 由于安全原因，不建议在脚本中硬编码 API 密钥。相反，利用环境变量或配置文件来管理你的密钥。
- en: 'Once you have an API key, it’s crucial to assign it as an environment variable
    by executing the following command, replacing `api_key` with your actual API key
    value:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了 API 密钥，至关重要的是通过执行以下命令将其分配为环境变量，将 `api_key` 替换为你的实际 API 密钥值：
- en: '[PRE22]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Or on Windows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，在 Windows 上：
- en: '[PRE23]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Alternatively, if you’d prefer not to preset an API key, then you can manually
    set the key while initializing the model, or load it from an *.env* file using
    *[python-dotenv](https://oreil.ly/IaQjS)*. First, install the library with `pip
    install python-dotenv`, and then load the environment variables with the following
    code at the top of your script or notebook:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你不想预先设置 API 密钥，那么你可以在初始化模型时手动设置密钥，或者从 *.env* 文件中加载它，使用 *[python-dotenv](https://oreil.ly/IaQjS)*。首先，使用
    `pip install python-dotenv` 安装库，然后在脚本或笔记本的顶部使用以下代码加载环境变量：
- en: '[PRE24]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The first step is getting responses for multiple runs of each prompt and storing
    them in a spreadsheet.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是为每个提示的多次运行获取响应并将它们存储在电子表格中。
- en: 'Input:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE25]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Output:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE26]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Here we’re using the OpenAI API to generate model responses to a set of prompts
    and storing the results in a dataframe, which is saved to a CSV file. Here’s how
    it works:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用 OpenAI API 生成对一组提示的模型响应，并将结果存储在数据框中，然后将其保存为 CSV 文件。以下是工作原理：
- en: Two prompt variants are defined, and each variant consists of a product description,
    seed words, and potential product names, but `prompt_B` provides two examples.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义了两个提示变体，每个变体都包含产品描述、种子词和潜在的产品名称，但 `prompt_B` 提供了两个示例。
- en: Import statements are called for the Pandas library, OpenAI library, and os
    library.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要导入 Pandas 库、OpenAI 库和 os 库。
- en: The `get_response` function takes a prompt as input and returns a response from
    the `gpt-3.5-turbo` model. The prompt is passed as a user message to the model,
    along with a system message to set the model’s behavior.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`get_response` 函数接受一个提示作为输入，并从 `gpt-3.5-turbo` 模型返回一个响应。提示作为用户消息传递给模型，同时传递一个系统消息以设置模型的行为。'
- en: Two prompt variants are stored in the `test_prompts` list.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两个提示变体存储在 `test_prompts` 列表中。
- en: An empty list `responses` is created to store the generated responses, and the
    variable `num_tests` is set to 5.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个空列表 `responses` 来存储生成的响应，并将变量 `num_tests` 设置为 5。
- en: A nested loop is used to generate responses. The outer loop iterates over each
    prompt, and the inner loop generates `num_tests` (five in this case) number of
    responses per prompt.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用嵌套循环来生成响应。外循环遍历每个提示，内循环为每个提示生成 `num_tests`（本例中为五个）个响应。
- en: The `enumerate` function is used to get the index and value of each prompt in
    `test_prompts`. This index is then converted to a corresponding uppercase letter
    (e.g., 0 becomes *A*, 1 becomes *B*) to be used as a variant name.
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `enumerate` 函数获取 `test_prompts` 中每个提示的索引和值。然后将此索引转换为相应的大写字母（例如，0 变为 *A*，1
    变为 *B*），用作变体名称。
- en: For each iteration, the `get_response` function is called with the current prompt
    to generate a response from the model.
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每次迭代，使用当前提示调用 `get_response` 函数来从模型生成响应。
- en: A dictionary is created with the variant name, the prompt, and the model’s response,
    and this dictionary is appended to the `responses` list.
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含变体名称、提示和模型响应的字典，并将其追加到 `responses` 列表中。
- en: Once all responses have been generated, the `responses` list (which is now a
    list of dictionaries) is converted into a Pandas DataFrame.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦所有响应都生成完毕，`responses` 列表（现在是一个字典列表）被转换为 Pandas 数据框。
- en: This dataframe is then saved to a CSV file with the Pandas built-in `to_csv`
    function, making the file *responses.csv* with `index=False` so as to not write
    row indices.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后使用 Pandas 内置的 `to_csv` 函数将此数据框保存为 CSV 文件，文件名为 *responses.csv*，`index=False`
    以防止写入行索引。
- en: Finally, the dataframe is printed to the console.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，数据框被打印到控制台。
- en: Having these responses in a spreadsheet is already useful, because you can see
    right away even in the printed response that `prompt_A` (zero-shot) in the first
    five rows is giving us a numbered list, whereas `prompt_B` (few-shot) in the last
    five rows tends to output the desired format of a comma-separated inline list.
    The next step is to give a rating on each of the responses, which is best done
    blind and randomized to avoid favoring one prompt over another.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些响应放在电子表格中已经很有用，因为你可以立即在打印的响应中看到，前五行中的 `prompt_A`（零样本）提供了一个编号列表，而最后五行中的 `prompt_B`（少样本）倾向于输出逗号分隔的行内列表的期望格式。下一步是对每个响应进行评分，最好是无视并随机化，以避免偏向某个提示而忽略另一个。
- en: 'Input:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE27]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output is shown in [Figure 1-12](#figure-1-12):'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如图 [图 1-12](#figure-1-12) 所示：
- en: '![pega 0112](assets/pega_0112.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0112](assets/pega_0112.png)'
- en: Figure 1-12\. Thumbs-up/thumbs-down rating system
  id: totrans-184
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-12\. 点赞/踩不点赞评价系统
- en: If you run this in a Jupyter Notebook, a widget displays each AI response, with
    a thumbs-up or thumbs-down button (see [Figure 1-12](#figure-1-12)) This provides
    a simple interface for quickly labeling responses, with minimal overhead. If you
    wish to do this outside of a Jupyter Notebook, you could change the thumbs-up
    and thumbs-down emojis for *Y* and *N*, and implement a loop using the built-in
    `input()` function, as a text-only replacement for iPyWidgets.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个 Jupyter Notebook 中运行此代码，一个小部件会显示每个 AI 响应，并带有点赞或踩按钮（见 [图 1-12](#figure-1-12)）。这提供了一个简单的界面，可以快速标记响应，且开销最小。如果你想在
    Jupyter Notebook 之外做这件事，你可以将点赞和踩按钮的表情符号改为 *Y* 和 *N*，并使用内置的 `input()` 函数实现循环，作为
    iPyWidgets 的纯文本替代。
- en: Once you’ve finished labeling the responses, you get the output, which shows
    you how each prompt performs.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成标记响应，你将得到输出，它显示了每个提示的性能。
- en: 'Output:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE28]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The dataframe was shuffled at random, and each response was labeled blind (without
    seeing the prompt), so you get an accurate picture of how often each prompt performed.
    Here is the step-by-step explanation:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框被随机洗牌，每个响应都被盲标（没有看到提示），因此你可以准确地了解每个提示执行得多频繁。以下是逐步解释：
- en: 'Three modules are imported: `ipywidgets`, `IPython.display`, and `pandas`.
    `ipywidgets` contains interactive HTML widgets for Jupyter Notebooks and the IPython
    kernel. `IPython.display` provides classes for displaying various types of output
    like images, sound, displaying HTML, etc. Pandas is a powerful data manipulation
    library.'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入了三个模块：`ipywidgets`、`IPython.display` 和 `pandas`。`ipywidgets` 包含用于 Jupyter
    Notebook 和 IPython 内核的交互式 HTML 小部件。`IPython.display` 提供了用于显示各种类型输出的类，如图像、声音、显示
    HTML 等。Pandas 是一个强大的数据处理库。
- en: The pandas library is used to read in the CSV file *responses.csv*, which contains
    the responses you want to test. This creates a Pandas DataFrame called `df`.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 库读取包含你想要测试的响应的 CSV 文件 *responses.csv*，这创建了一个名为 `df` 的 Pandas 数据框。
- en: '`df` is shuffled using the `sample()` function with `frac=1`, which means it
    uses all the rows. The `reset_index(drop=True)` is used to reset the indices to
    the standard 0, 1, 2, …​, n index.'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`df` 使用 `sample()` 函数并设置 `frac=1` 进行洗牌，这意味着它使用了所有行。`reset_index(drop=True)`
    用于将索引重置为标准的 0, 1, 2, …, n 索引。'
- en: The script defines `response_index` as 0\. This is used to track which response
    from the dataframe the user is currently viewing.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 脚本将 `response_index` 定义为 0。这用于跟踪用户当前正在查看数据框中的哪个响应。
- en: A new column `feedback` is added to the dataframe `df` with the data type as
    `str` or string.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `df` 数据框中添加了一个新的列 `feedback`，数据类型为 `str` 或字符串。
- en: Next, the script defines a function `on_button_clicked(b)`, which will execute
    whenever one of the two buttons in the interface is clicked.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，脚本定义了一个函数 `on_button_clicked(b)`，该函数将在界面中的任一按钮被点击时执行。
- en: The function first checks the `description` of the button clicked was the thumbs-up
    button (`\U0001F44D`; ![thumbs up 1f44d](assets/thumbs-up_1f44d.png)), and sets
    `user_feedback` as 1, or if it was the thumbs-down button (`\U0001F44E` ![thumbs
    down 1f44e](assets/thumbs-down_1f44e.png)), it sets `user_feedback` as 0.
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 函数首先检查点击的按钮的 `description` 是否为点赞按钮 (`\U0001F44D`; ![点赞 1f44d](assets/thumbs-up_1f44d.png))，并将
    `user_feedback` 设置为 1，或者如果它是踩按钮 (`\U0001F44E` ![踩 1f44e](assets/thumbs-down_1f44e.png))，则将
    `user_feedback` 设置为 0。
- en: Then it updates the `feedback` column of the dataframe at the current `response_index`
    with `user_feedback`.
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后它更新当前 `response_index` 的数据框的 `feedback` 列为 `user_feedback`。
- en: After that, it increments `response_index` to move to the next response.
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，它将 `response_index` 增加，以移动到下一个响应。
- en: If `response_index` is still less than the total number of responses (i.e.,
    the length of the dataframe), it calls the function `update_response()`.
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果 `response_index` 仍然小于响应的总数（即数据框的长度），则调用 `update_response()` 函数。
- en: If there are no more responses, it saves the dataframe to a new CSV file *results.csv*,
    then prints a message, and also prints a summary of the results by variant, showing
    the count of feedback received and the average score (mean) for each variant.
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有更多的响应，它将数据框保存到新的 CSV 文件 *results.csv*，然后打印一条消息，并按变体打印结果的摘要，显示收到的反馈数量和每个变体的平均分数（平均值）。
- en: The function `update_response()` fetches the next response from the dataframe,
    wraps it in paragraph HTML tags (if it’s not null), updates the `response` widget
    to display the new response, and updates the `count_label` widget to reflect the
    current response number and total number of responses.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`update_response()`函数从数据框中获取下一个响应，将其包裹在段落HTML标签中（如果它不是null），更新`response`小部件以显示新的响应，并更新`count_label`小部件以反映当前响应编号和总响应数。'
- en: Two widgets, `response` (an HTML widget) and `count_label` (a Label widget),
    are instantiated. The `update_response()` function is then called to initialize
    these widgets with the first response and the appropriate label.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化了两个小部件，`response`（一个HTML小部件）和`count_label`（一个标签小部件）。然后调用`update_response()`函数以初始化这些小部件，显示第一个响应和适当的标签。
- en: Two more widgets, `thumbs_up_button` and `thumbs_down_button` (both Button widgets),
    are created with thumbs-up and thumbs-down emoji as their descriptions, respectively.
    Both buttons are configured to call the `on_button_clicked()` function when clicked.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建了两个更多的小部件，`thumbs_up_button`和`thumbs_down_button`（都是按钮小部件），分别以赞同和反对表情符号作为它们的描述。这两个按钮都配置为在点击时调用`on_button_clicked()`函数。
- en: The two buttons are grouped into a horizontal box (`button_box`) using the `HBox`
    function.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`HBox`函数将两个按钮组合成一个水平框（`button_box`）。
- en: Finally, the `response`, `button_box`, and `count_label` widgets are displayed
    to the user using the `display()` function from the `IPython.display` module.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用`IPython.display`模块的`display()`函数将`response`、`button_box`和`count_label`小部件显示给用户。
- en: A simple rating system such as this one can be useful in judging prompt quality
    and encountering edge cases. Usually in less than 10 test runs of a prompt you
    uncover a deviation, which you otherwise wouldn’t have caught until you started
    using it in production. The downside is that it can get tedious rating lots of
    responses manually, and your ratings might not represent the preferences of your
    intended audience. However, even small numbers of tests can reveal large differences
    between two prompting strategies and reveal nonobvious issues before reaching
    production.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的简单评分系统可以用来判断提示质量并处理边缘情况。通常在10次以下的对提示的测试运行中，你会发现偏差，否则你可能直到开始在生产中使用它之前都不会发现。缺点是手动评分大量响应可能会很繁琐，而且你的评分可能无法代表目标受众的偏好。然而，即使是少量测试也可以揭示两种提示策略之间的巨大差异，并在达到生产之前揭示不明显的问题。
- en: Iterating on and testing prompts can lead to radical decreases in the length
    of the prompt and therefore the cost and latency of your system. If you can find
    another prompt that performs equally as well (or better) but uses a shorter prompt,
    you can afford to scale up your operation considerably. Often you’ll find in this
    process that many elements of a complex prompt are completely superfluous, or
    even counterproductive.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 对提示进行迭代和测试可以显著缩短提示的长度，从而降低系统和延迟的成本。如果你能找到另一个性能相同（或更好）但使用更短提示的提示，你就可以大幅度扩大你的运营规模。通常，在这个过程中，你会发现复杂提示的许多元素完全是多余的，甚至可能适得其反。
- en: 'The *thumbs-up* or other manually labeled indicators of quality don’t have
    to be the only judging criteria. Human evaluation is generally considered to be
    the most accurate form of feedback. However, it can be tedious and costly to rate
    many samples manually. In many cases, as in math or classification use cases,
    it may be possible to establish *ground truth* (reference answers to test cases)
    to programmatically rate the results, allowing you to scale up considerably your
    testing and monitoring efforts. The following is not an exhaustive list because
    there are many motivations for evaluating your prompt programmatically:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 赞同或其他手动标记的质量指标不一定是唯一的评判标准。人类评估通常被认为是反馈的最准确形式。然而，手动评估大量样本可能会很繁琐且成本高昂。在许多情况下，例如在数学或分类用例中，可能可以建立*基准真相*（测试用例的参考答案）以编程方式评估结果，从而大大提高你的测试和监控努力。以下列表并不全面，因为有许多动机促使你以编程方式评估提示：
- en: Cost
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 成本
- en: Prompts that use a lot of tokens, or work only with more expensive models, might
    be impractical for production use.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大量标记或仅与更昂贵模型工作的提示可能不适合生产使用。
- en: Latency
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟
- en: Equally the more tokens there are, or the larger the model required, the longer
    it takes to complete a task, which can harm user experience.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，标记越多，或所需的模型越大，完成任务所需的时间就越长，这可能会损害用户体验。
- en: Calls
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 调用
- en: Many AI systems require multiple calls in a loop to complete a task, which can
    seriously slow down the process.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 许多AI系统需要多次循环调用才能完成任务，这可能会严重减慢处理速度。
- en: Performance
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 性能
- en: Implement some form of external feedback system, for example a physics engine
    or other model for predicting real-world results.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 实现某种形式的外部反馈系统，例如用于预测现实世界结果的物理引擎或其他模型。
- en: Classification
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 分类
- en: Determine how often a prompt correctly labels given text, using another AI model
    or rules-based labeling.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 确定提示正确标记给定文本的频率，使用另一个AI模型或基于规则的标记。
- en: Reasoning
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 推理
- en: Work out which instances the AI fails to apply logical reasoning or gets the
    math wrong versus reference cases.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 计算AI未能应用逻辑推理或数学错误的实例与参考案例之间的差异。
- en: Hallucinations
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 幻觉
- en: See how frequently you encouner hallucinations, as measured by invention of
    new terms not included in the prompt’s context.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 看看你遇到幻觉的频率，这是通过发明不在提示上下文中的新术语来衡量的。
- en: Safety
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性
- en: Flag any scenarios where the system might return unsafe or undesirable results
    using a safety filter or detection system.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 使用安全过滤器或检测系统标记任何可能返回不安全或不希望的结果的场景。
- en: Refusals
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 拒绝
- en: Find out how often the system incorrectly refuses to fulfill a reasonable user
    request by flagging known refusal language.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通过标记已知的拒绝语言，找出系统错误拒绝合理用户请求的频率。
- en: Adversarial
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗性
- en: Make the prompt robust against known [prompt injection](https://oreil.ly/KGAqe)
    attacks that can get the model to run undesirable prompts instead of what you
    programmed.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 使提示对已知的[提示注入](https://oreil.ly/KGAqe)攻击具有鲁棒性，这些攻击可以使模型运行不希望运行的提示而不是你编程的内容。
- en: Similarity
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 相似度
- en: Use shared words and phrases ([BLEU or ROGUE](https://oreil.ly/iEGZ9)) or vector
    distance (explained in [Chapter 5](ch05.html#vector_databases_05)) to measure
    similarity between generated and reference text.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 使用共享的单词和短语（[BLEU 或 ROGUE](https://oreil.ly/iEGZ9)）或向量距离（在[第5章](ch05.html#vector_databases_05)中解释）来衡量生成文本和参考文本之间的相似度。
- en: Once you start rating which examples were good, you can more easily update the
    examples used in your prompt as a way to continuously make your system smarter
    over time. The data from this feedback can also feed into examples for fine-tuning,
    which starts to beat prompt engineering once you can [supply a few thousand examples](https://oreil.ly/DZ-br),
    as shown in [Figure 1-13](#figure-1-13).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你开始评估哪些示例是好的，你就可以更容易地更新你的提示中使用的示例，作为随着时间的推移使你的系统变得更智能的一种方式。此反馈的数据还可以用于微调示例，一旦你可以[提供几千个示例](https://oreil.ly/DZ-br)，微调就开始超越提示工程，如图1-13所示。
- en: '![pega 0113](assets/pega_0113.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0113](assets/pega_0113.png)'
- en: Figure 1-13\. How many data points is a prompt worth?
  id: totrans-233
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-13。一个提示值是多少数据点？
- en: Graduating from thumbs-up or thumbs-down, you can implement a 3-, 5-, or 10-point
    rating system to get more fine-grained feedback on the quality of your prompts.
    It’s also possible to determine aggregate relative performance through comparing
    responses side by side, rather than looking at responses one at a time. From this
    you can construct a fair across-model comparison using an *[Elo rating](https://oreil.ly/TlldE)*,
    as is popular in chess and used in the [Chatbot Arena](https://oreil.ly/P2IcU)
    by *lmsys.org*.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 从点赞或点踩过渡到3分、5分或10分的评分系统，以获得对提示质量更细致的反馈。还可以通过并排比较响应，而不是逐个查看响应，来确定总体相对性能。从这些信息中，你可以构建一个公平的跨模型比较，使用*[Elo评分](https://oreil.ly/TlldE)*，这在象棋中很受欢迎，也被*lmsys.org*在[聊天机器人竞技场](https://oreil.ly/P2IcU)中使用。
- en: For image generation, evaluation usually takes the form of *permutation* prompting,
    where you input multiple directions or formats and generate an image for each
    combination. Images can than be scanned or later arranged in a grid to show the
    effect that different elements of the prompt can have on the final image.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像生成，评估通常采用*排列*提示的形式，即你输入多个方向或格式，并为每种组合生成一个图像。然后可以扫描图像或稍后以网格形式排列，以展示提示的不同元素对最终图像的影响。
- en: 'Input:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE29]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In Midjourney this would be compiled into six different prompts, one for every
    combination of the three formats (stock photo, oil painting, illustration) and
    two numbers of people (four, eight).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在Midjourney中，这将被编译成六个不同的提示，每个提示对应于三种格式（股票照片、油画、插图）和两种人数（四、八）的组合。
- en: 'Input:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE30]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Each prompt generates its own four images as usual, which makes the output a
    little harder to see. We have selected one from each prompt to upscale and then
    put them together in a grid, shown as [Figure 1-14](#figure-1-14). You’ll notice
    that the model doesn’t always get the correct number of people (generative AI
    models are surprisingly bad at math), but it has correctly inferred the general
    intention by adding more people to the photos on the right than the left.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 每个提示通常都会生成其自己的四张图像，这使得输出结果稍微难以观察。我们从每个提示中选了一张图像进行放大，然后将它们组合成一个网格，如图[图1-14](#figure-1-14)所示。你会注意到，模型并不总是能得到正确的人数（生成式AI模型在数学上出奇地差），但它通过在右侧照片中添加比左侧更多的人数，正确地推断出了总体意图。
- en: '[Figure 1-14](#figure-1-14) shows the output.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-14](#figure-1-14)显示了输出。'
- en: '![pega 0114](assets/pega_0114.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0114](assets/pega_0114.png)'
- en: Figure 1-14\. Prompt permutations grid
  id: totrans-244
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-14. 提示排列网格
- en: With models that have APIs like Stable Diffusion, you can more easily manipulate
    the photos and display them in a grid format for easy scanning. You can also manipulate
    the random seed of the image to fix a style in place for maximum reproducibility.
    With image classifiers it may also be possible to programmatically rate images
    based on their safe content, or if they contain certain elements associated with
    success or failure.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有类似Stable Diffusion这样的API的模型，你可以更轻松地操作照片并以网格格式显示，以便于扫描。你还可以操作图像的随机种子，以固定一种风格，实现最大程度的可重复性。使用图像分类器时，也可能根据图像的安全内容或是否包含与成功或失败相关的特定元素进行编程评分。
- en: 5\. Divide Labor
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. 分工
- en: As you build out your prompt, you start to get to the point where you’re asking
    a lot in a single call to the AI. When prompts get longer and more convoluted,
    you may find the responses get less deterministic, and hallucinations or anomalies
    increase. Even if you manage to arrive at a reliable prompt for your task, that
    task is likely just one of a number of interrelated tasks you need to do your
    job. It’s natural to start exploring how many other of these tasks could be done
    by AI and how you might string them together.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 当你构建提示时，你开始达到一个点，在这个点上，你在对AI的单次调用中提出了很多要求。当提示变得更长、更复杂时，你可能会发现响应的不确定性降低，幻觉或异常增加。即使你设法为你的任务找到了一个可靠的提示，这个任务也可能是你需要完成的工作中许多相互关联的任务之一。自然地，你会开始探索其他哪些任务可以通过AI完成，以及你如何将它们串联起来。
- en: One of the core principles of engineering is to use task decomposition to break
    problems down into their component parts, so you can more easily solve each individual
    problem and then reaggregate the results. Breaking your AI work into multiple
    calls that are chained together can help you accomplish more complex tasks, as
    well as provide more visibility into what part of the chain is failing.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 工程学的一个核心原则是利用任务分解将问题分解为其组成部分，这样你可以更容易地解决每个单独的问题，然后将结果重新聚合。将你的AI工作分解成多个串联的调用可以帮助你完成更复杂的任务，同时也能提供更多关于链中哪个部分失败的可见性。
- en: There are lots of factors that go into product naming, and an important task
    is naively outsourced to the AI with no visibility into how it’s weighing the
    importance of these factors (if at all). The way our current system works, we’re
    getting a list of names, but all names are displayed with equal importance with
    no further context for helping us decide. Fortunately AI tools are capable of
    self-evaluation; if we add a second step to our task, we can automatically check
    for nondesirable outputs.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 产品命名涉及许多因素，其中一项重要的任务被天真地外包给了AI，我们无法了解它如何权衡这些因素的重要性（如果有的话）。按照我们当前系统的工作方式，我们得到了一个名字列表，但所有名字都以同等的重要性显示，没有进一步的上下文来帮助我们做出决定。幸运的是，AI工具能够进行自我评估；如果我们对任务添加第二步，我们可以自动检查非期望的输出。
- en: 'Input:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE31]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Output:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE32]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In running this multiple times, it consistently rates the name “OneSize Glovewalkers”
    as the worst, providing context (if you ask) that the concept might be confusing
    in a shoe context. You may be wondering why, if the model *knows* this is a bad
    name, does it suggest it in the first place? LLMs work by predicting the next
    token in a sequence and therefore struggle to know what the overall response will
    be when finished. However, when it has all the tokens from a previous response
    to review, it can more easily predict whether this would be labeled as a good
    or bad response.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在多次运行此模型后，它始终将“OneSize Glovewalkers”这个名字评为最差，并提供上下文（如果你询问的话）说明这个概念在鞋类环境中可能会令人困惑。你可能想知道，如果模型*知道*这个名字不好，为什么它最初还会建议这个名字？LLMs通过预测序列中的下一个标记来工作，因此很难知道完成后的整体响应会是什么。然而，当它有了之前响应的所有标记来审查时，它更容易预测这会被标记为好还是坏的反应。
- en: 'We can continue to chain multiple calls together to improve the results of
    our task. For example, we could split this into three separate ratings: clarity,
    memorability, and how well the name communicates the unique selling point of the
    product. These ratings could then be given to a human as additional context on
    the final decision, or even calculated together to select the final name programmatically.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续将多个调用串联起来，以改进我们任务的成果。例如，我们可以将这分成三个单独的评分：清晰度、记忆度和名字传达产品独特卖点的好坏。这些评分可以提供给人类作为最终决策的额外上下文，或者甚至可以一起计算来程序化选择最终的名字。
- en: The real unlock in learning to work professionally with AI versus just playing
    around with prompting is realizing that every part of the system can be broken
    down into a series of iterative steps. Even with a single prompt this principles
    applies, as simply appending `Let's think step by step` to the prompt can lead
    to demonstrable gains in reasoning and proficiency, as well as provide an audit
    trail for quality assurance and debugging. When taking the time and tokens to
    reason, the ratings change and are more consistent with the scoring criteria.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 与仅仅玩转提示相比，学会专业地与AI合作学习的真正突破在于意识到系统的每个部分都可以分解为一系列迭代步骤。即使是一个单独的提示，这个原则也适用，因为简单地将“让我们一步步思考”添加到提示中，可以带来推理和熟练度的明显提升，同时为质量保证和调试提供审计轨迹。当花费时间和标记进行推理时，评分会改变，并且与评分标准更加一致。
- en: 'Input:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE33]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Output:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE34]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: OpenAI [calls this](https://oreil.ly/0MZ3-) “giving the model time to think,”
    and it is a key tenet of prompt engineering. In effect, *chain of thought* techniques
    like this, where the model is encouraged to list out its steps, are like dividing
    a task within the same prompt. Once we’ve automated product naming given a product
    idea, we can call ChatGPT again to describe each product, which in turn can be
    fed into Midjourney to generate an image of each product. Using an AI model to
    generate a prompt for an AI model is *meta prompting*, and it works because LLMs
    are human-level prompt engineers ([Zhou, 2022](https://oreil.ly/Dwszu)).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI [称之为](https://oreil.ly/0MZ3-) “给模型思考的时间”，这是提示工程的一个关键原则。实际上，*思维链*技术就像这种，鼓励模型列出其步骤，就像在同一个提示中分解任务一样。一旦我们自动完成了产品命名的任务，我们就可以再次调用ChatGPT来描述每个产品，然后这些描述可以输入到Midjourney中生成每个产品的图像。使用AI模型为AI模型生成提示词是*元提示*，它之所以有效，是因为LLMs是达到人类水平的提示工程师([周，2022](https://oreil.ly/Dwszu))。
- en: 'Input:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE35]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Output:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE36]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: DALL-E is well-known by GPT-4, and therefore you can invoke its name within
    ChatGPT and it does a reasonable job at crafting a prompt for an image generation
    tool. If you were planning on using this prompt in production, you may consider
    applying the prompting principle of providing examples, but it does a good enough
    job for our purposes without examples.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: DALL-E在GPT-4中是众所周知的，因此你可以在ChatGPT中调用它的名字，并且它为图像生成工具制作提示词做得相当不错。如果你打算在生产中使用这个提示词，你可能考虑应用提供示例的提示原则，但对我们来说，没有示例它也做得足够好。
- en: 'Input:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE37]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Output:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE38]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The output of this prompt can now be plugged into image generation tools like
    DALL-E or Midjourney as a prompt, which can give you a good starting point for
    visualizing what the product might look like. Although this might not be the final
    design you go with, seeing an image is more evocative and helps people form an
    opinion faster. It’s easier cognitively to criticize or compliment an existing
    image than it is to imagine a new image from a blank page or section of text.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以将这个提示的输出连接到图像生成工具，如DALL-E或Midjourney，作为提示，这可以为你可视化产品可能的样子提供一个良好的起点。尽管这可能不是你最终采用的设计，但看到图像更具有启发性，有助于人们更快地形成观点。从空白页面或文本部分想象一个新图像比批评或赞扬现有的图像在认知上更容易。
- en: '[Figure 1-15](#figure-1-15) shows the output.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-15](#figure-1-15)显示了输出结果。'
- en: '![pega 0115](assets/pega_0115.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0115](assets/pega_0115.png)'
- en: Figure 1-15\. OneFit UltraStride shoes
  id: totrans-274
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-15\. OneFit UltraStride运动鞋
- en: It’s common practice when working with AI professionally to chain multiple calls
    to AI together, and even multiple models, to accomplish more complex goals. Even
    single-prompt applications are often built dynamically, based on outside context
    queried from various databases or other calls to an AI model. The library [LangChain](https://www.langchain.com)
    has developed tooling for chaining multiple prompt templates and queries together,
    making this process more observable and well structured. A foundational example
    is progressive summarization, where text that is too large to fit into a context
    window can be split into multiple chunks of text, with each being summarized,
    before finally summarizing the summaries. If you talk to builders of early AI
    products, you’ll find they’re all under the hood chaining multiple prompts together,
    called *AI chaining*, to accomplish better results in the final output.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在专业处理AI时，将多个AI调用甚至多个模型串联起来以实现更复杂的目标是一种常见的做法。即使是单次提示应用也往往是动态构建的，基于从各种数据库或其他AI模型调用中查询的外部上下文。库[LangChain](https://www.langchain.com)开发了将多个提示模板和查询串联起来的工具，使这一过程更加可观察和结构化。一个基础示例是渐进式摘要，其中无法适应上下文窗口的大段文本可以被分成多个文本块，每个块被总结，最后再总结这些摘要。如果你与早期AI产品的构建者交谈，你会发现他们都在底层将多个提示串联起来，称为*AI串联*，以在最终输出中获得更好的结果。
- en: The [Reason and Act (ReAct)](https://oreil.ly/tPPW9) framework was one of the
    first popular attempts at AI agents, including the open source projects [BabyAGI](https://oreil.ly/TEiQx),
    [AgentGPT](https://oreil.ly/48lq6) and [Microsoft AutoGen](https://oreil.ly/KG5Xl).
    In effect, these agents are the result of chaining multiple AI calls together
    in order to plan, observe, act, and then evaluate the results of the action. Autonomous
    agents will be covered in [Chapter 6](ch06.html#autonomous_agents_06) but are
    still not widely used in production at the time of writing. This practice of self-reasoning
    agents is still early and prone to errors, but there are promising signs this
    approach can be useful in achieving complex tasks, and is likely to be part of
    the next stage in evolution for AI systems.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '[原因与行动（ReAct）框架](https://oreil.ly/tPPW9)是AI代理中最早流行的尝试之一，包括开源项目[BabyAGI](https://oreil.ly/TEiQx)、[AgentGPT](https://oreil.ly/48lq6)和[Microsoft
    AutoGen](https://oreil.ly/KG5Xl)。实际上，这些代理是通过将多个AI调用串联起来以实现规划、观察、行动，然后评估行动结果。自主代理将在[第6章](ch06.html#autonomous_agents_06)中介绍，但截至写作时，它们在生产中尚未得到广泛应用。这种自我推理代理的做法还处于早期阶段，容易出错，但有一些迹象表明，这种方法在完成复杂任务时可能是有用的，并且很可能是AI系统下一阶段演化的一个部分。'
- en: There is an AI battle occurring between large tech firms like Microsoft and
    Google, as well as a wide array of open source projects on Hugging Face, and venture-funded
    start-ups like OpenAI and Anthropic. As new models continue to proliferate, they’re
    diversifying in order to compete for different segments of the growing market.
    For example, Anthropic’s Claude 2 had an [100,000-token context window](https://oreil.ly/NQcFW),
    compared to GPT-4’s standard [8,192 tokens](https://oreil.ly/iZhMl). OpenAI soon
    responded with a [128,000-token window version of GPT-4](https://oreil.ly/3TTZ9),
    and Google touts a 1 million token context length with [Gemini 1.5](https://oreil.ly/cyhR4).
    For comparison, one of the Harry Potter books would be around 185,000 tokens,
    so it may become common for an entire book to fit inside a single prompt, though
    processing millions of tokens with each API call may be cost prohibitive for most
    use cases.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在微软和谷歌等大型科技公司之间，以及Hugging Face上的众多开源项目，以及像OpenAI和Anthropic这样的风险投资初创公司之间，正在发生一场AI竞赛。随着新模型的不断涌现，它们正在多样化以争夺不断增长市场的不同细分市场。例如，Anthropic的Claude
    2拥有[10万个令牌的上下文窗口](https://oreil.ly/NQcFW)，而GPT-4的标准[8,192个令牌](https://oreil.ly/iZhMl)。OpenAI很快推出了GPT-4的[128,000个令牌窗口版本](https://oreil.ly/3TTZ9)，而谷歌吹嘘其Gemini
    1.5拥有1百万个令牌的上下文长度。[https://oreil.ly/cyhR4](https://oreil.ly/cyhR4)。为了比较，一本《哈利·波特》的书大约有185,000个令牌，所以整个一本书可能都适合放入一个单一的提示中，尽管每次API调用处理数百万个令牌可能对大多数用例来说成本过高。
- en: This book focuses on GPT-4 for text generation techniques, as well as Midjourney
    v6 and Stable Diffusion XL for image generation techniques, but within months
    these models may no longer be state of the art. This means it will become increasingly
    important to be able to select the right model for the job and chain multiple
    AI systems together. Prompt templates are rarely comparable when transferring
    to a new model, but the effect of the Five Prompting Principles will consistently
    improve any prompt you use, for any model, getting you more reliable results.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书主要关注文本生成技术中的GPT-4，以及Midjourney v6和Stable Diffusion XL在图像生成技术中的应用，但几个月后这些模型可能就不再是业界领先的技术了。这意味着能够选择适合任务的正确模型并将多个AI系统串联起来将变得越来越重要。在迁移到新模型时，提示模板通常难以比较，但五个提示原则的效果将始终如一地提升你使用的任何模型的提示，从而获得更可靠的结果。
- en: Summary
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about the importance of prompt engineering in the
    context of generative AI. We defined prompt engineering as the process of developing
    effective prompts that yield desired results when interacting with AI models.
    You discovered that providing clear direction, formatting the output, incorporating
    examples, establishing an evaluation system, and dividing complex tasks into smaller
    prompts are key principles of prompt engineering. By applying these principles
    and using common prompting techniques, you can improve the quality and reliability
    of AI-generated outputs.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了在生成式AI的背景下提示工程的重要性。我们将提示工程定义为开发有效的提示的过程，这些提示在与AI模型交互时产生预期结果。你发现提供清晰的方向、格式化输出、结合示例、建立评估系统以及将复杂任务分解成更小的提示是提示工程的关键原则。通过应用这些原则和使用常见的提示技术，你可以提高AI生成输出的质量和可靠性。
- en: You also explored the role of prompt engineering in generating product names
    and images. You saw how specifying the desired format and providing instructive
    examples can greatly influence the AI’s output. Additionally, you learned about
    the concept of role-playing, where you can ask the AI to generate outputs as if
    it were a famous person like Steve Jobs. The chapter emphasized the need for clear
    direction and context to achieve desired outcomes when using generative AI models.
    Furthermore, you discovered the importance of evaluating the performance of AI
    models and the various methods used for measuring results, as well as the trade-offs
    between quality and token usage, cost, and latency.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 你还探讨了提示工程在生成产品名称和图像中的作用。你了解到指定所需格式和提供指导性示例如何极大地影响AI的输出。此外，你学习了角色扮演的概念，你可以要求AI生成类似于史蒂夫·乔布斯这样的名人的输出。本章强调了在使用生成式AI模型时，清晰的方向和上下文对于实现预期结果的重要性。此外，你还发现了评估AI模型性能的重要性以及用于衡量结果的多种方法，以及质量与令牌使用、成本和延迟之间的权衡。
- en: In the next chapter, you will be introduced to text generation models. You will
    learn about the different types of foundation models and their capabilities, as
    well as their limitations. The chapter will also review the standard OpenAI offerings,
    as well as competitors and open source alternatives. By the end of the chapter,
    you will have a solid understanding of the history of text generation models and
    their relative strengths and weaknesses. This book will return to image generation
    prompting in Chapters [7](ch07.html#intro_image_07), [8](ch08.html#standard_image_08),
    and [9](ch09.html#advanced_image_09), so you should feel free to skip ahead if
    that is your immediate need. Get ready to dive deeper into the discipline of prompt
    engineering and expand your comfort working with AI.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将了解到文本生成模型。您将学习不同类型的基模及其功能，以及它们的局限性。本章还将回顾标准OpenAI的提供内容，以及竞争对手和开源替代方案。到本章结束时，您将对文本生成模型的历史及其相对优势和劣势有一个扎实的理解。本书将在第[7](ch07.html#intro_image_07)、[8](ch08.html#standard_image_08)和[9](ch09.html#advanced_image_09)章回到图像生成提示，所以如果您对此有迫切需求，可以自由地跳过前面的内容。准备好深入探索提示工程学科，并扩展您与AI合作的舒适度。
