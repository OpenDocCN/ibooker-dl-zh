- en: Chapter 1\. The Five Principles of Prompting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章. 提示的五个原则
- en: '*Prompt engineering* is the process of discovering prompts that reliably yield
    useful or desired results.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示工程* 是一个发现可靠产生有用或期望结果提示的过程。'
- en: 'A *prompt* is the input you provide, typically text, when interfacing with
    an AI model like ChatGPT or Midjourney. The prompt serves as a set of instructions
    the model uses to predict the desired response: text from *large language models*
    (LLMs) like [ChatGPT](https://chat.openai.com), or images from *diffusion models*
    like [Midjourney](https://www.midjourney.com).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示* 是你在与像ChatGPT或Midjourney这样的AI模型交互时提供的输入，通常是文本。提示作为一组指令，模型使用这些指令来预测期望的响应：来自
    *大型语言模型*（LLMs）如 [ChatGPT](https://chat.openai.com) 的文本，或来自 *扩散模型* 如 [Midjourney](https://www.midjourney.com)
    的图像。'
- en: Here is a simple example of a prompt input for a product name generator (inspired
    by one of [OpenAI’s examples](https://oreil.ly/Fc8cq)), and the resulting output
    from ChatGPT.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个产品名称生成器提示输入的简单示例（灵感来源于 [OpenAI 的示例](https://oreil.ly/Fc8cq)），以及ChatGPT的结果输出。
- en: 'Input:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Output:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE1]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is already a remarkable response for a naive prompt, which feels like magic
    because we got here with very little effort. As the state-of-the-art models improve,
    the likelihood you will get *good enough* results on your first try goes up. For
    any throwaway interactions with an AI, where you don’t plan to do the same task
    again, the naive approach is all you need.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于原始提示来说已经是一个了不起的响应，它感觉像是魔法，因为我们几乎不费吹灰之力就达到了这里。随着最先进模型的改进，你第一次尝试就能得到 *足够好*
    的结果的几率会增加。对于任何与AI的临时互动，你不会再次执行相同的任务，原始方法就足够了。
- en: 'However, if you planned to put this prompt into production, you’d benefit from
    investing more work into getting it right. Mistakes cost you money in terms of
    the fees OpenAI charges based on the length of the prompt and response, as well
    as the time spent fixing mistakes. If you were building a product name generator
    with thousands of users, there are some obvious issues you’d want attempt to fix:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你计划将这个提示投入生产，你会从投入更多工作使其正确中受益。错误会花费你金钱，这是基于OpenAI根据提示和响应的长度收取的费用，以及修复错误所花费的时间。如果你正在构建一个拥有数千用户的名称生成器产品，有一些明显的问题你想要尝试解决：
- en: Vague direction
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 模糊的方向
- en: You’re not briefing the AI on what style of name you want, or what attributes
    it should have. Do you want a single word or a concatenation? Can the words be
    made up, or is it important that they’re in real English? Do you want the AI to
    emulate somebody you admire who is famous for great product names?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你没有向AI说明你想要的名称风格或它应该具有的属性。你想要一个单词还是组合？单词可以随意创造，还是它们必须是真正的英语？你想要AI模仿一个以出色的产品名称而闻名的你钦佩的人吗？
- en: Unformatted output
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 未格式化的输出
- en: You’re getting back a list of separated names line by line, of unspecified length.
    When you run this prompt multiple times, you’ll see sometimes it comes back with
    a numbered list, and often it has text at the beginning, which makes it hard to
    parse programmatically.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你会逐行收到一个分隔的名字列表，长度不固定。当你多次运行这个提示时，有时它会返回一个带编号的列表，并且经常在开头有文本，这使得程序解析变得困难。
- en: Missing examples
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 缺少的示例
- en: You haven’t given the AI any examples of what *good* names look like. It’s autocompleting
    using an average of its training data, i.e., the entire internet (with all its
    inherent bias), but is that what you want? Ideally you’d feed it examples of successful
    names, common names in an industry, or even just other names you like.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你没有给出任何关于 *好* 名称的示例。它是使用其训练数据的平均值自动完成的，即整个互联网（及其固有的偏见），但这正是你想要的吗？理想情况下，你会给它提供成功的名称示例，行业中的常见名称，或者甚至只是你喜欢的其他名称。
- en: Limited evaluation
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 有限的评估
- en: You have no consistent or scalable way to define which names are good or bad,
    so you have to manually review each response. If you can institute a rating system
    or other form of measurement, you can optimize the prompt to get better results
    and identify how many times it fails.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你没有一致或可扩展的方式来定义哪些名称是好是坏，所以你必须手动审查每个响应。如果你可以建立评分系统或其他形式的测量，你可以优化提示以获得更好的结果，并确定它失败了多少次。
- en: No task division
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任务划分
- en: 'You’re asking a lot of a single prompt here: there are lots of factors that
    go into product naming, and this important task is being naively outsourced to
    the AI all in one go, with no task specialization or visibility into how it’s
    handling this task for you.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你在这里对单个提示的要求很多：产品命名中有许多因素需要考虑，这个重要的任务被天真地一次性外包给了AI，没有任何任务专业化或对它如何处理这个任务的了解。
- en: Addressing these problems is the basis for the core principles we use throughout
    this book. There are many different ways to ask an AI model to do the same task,
    and even slight changes can make a big difference. LLMs work by continuously predicting
    the next token (approximately three-fourths of a word), starting from what was
    in your prompt. Each new token is selected based on its probability of appearing
    next, with an element of randomness (controlled by the *temperature* parameter).
    As demonstrated in [Figure 1-1](#figure-1-1), the word *shoes* had a lower probability
    of coming after the start of the name *AnyFit* (0.88%), where a more predictable
    response would be *Athletic* (72.35%).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这些问题是我们在这本书中使用的核心原则的基础。有许许多多不同的方式可以要求一个AI模型完成相同的任务，即使是微小的变化也可能产生很大的影响。LLMs通过持续预测下一个标记（大约是四分之三的单词），从你的提示中开始，来工作。每个新的标记都是基于其出现的概率来选择的，其中包含一定的随机性（由*温度*参数控制）。如图1-1所示，单词*鞋子*在名字*AnyFit*之后出现的概率较低（0.88%），而更可预测的回应会是*运动型*（72.35%）。
- en: '![pega 0101](assets/pega_0101.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0101](assets/pega_0101.png)'
- en: Figure 1-1\. How the response breaks down into tokens
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 响应如何分解成标记
- en: LLMs are trained on essentially the entire text of the internet, and are then
    further fine-tuned to give helpful responses. Average prompts will return average
    responses, leading some to be underwhelmed when their results don’t live up to
    the hype. What you put in your prompt changes the probability of every word generated,
    so it matters a great deal to the results you’ll get. These models have seen the
    best and worst of what humans have produced and are capable of emulating almost
    anything if you know the right way to ask. OpenAI charges based on the [number
    of tokens used](https://openai.com/pricing) in the prompt and the response, so
    prompt engineers need to make these tokens count by optimizing prompts for cost,
    quality, and reliability.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs是在互联网的几乎所有文本上训练的，然后进一步微调以提供有用的响应。平均提示将返回平均响应，这导致一些人当他们的结果没有达到预期时感到失望。你放在提示中的内容会改变每个生成单词的概率，因此这对你得到的结果有很大影响。这些模型已经看到了人类产生的最好和最坏的东西，如果你知道正确的方式去问，它们几乎可以模仿任何东西。OpenAI根据提示和响应中使用的[标记数量](https://openai.com/pricing)来收费，因此提示工程师需要通过优化提示以成本、质量和可靠性来确保这些标记的价值。
- en: Here’s the same example with the application of several prompt engineering techniques.
    We ask for names in the style of Steve Jobs, state that we want a comma-separated
    list, and supply examples of the task done well.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是应用了几个提示工程技术的相同示例。我们以史蒂夫·乔布斯的方式请求名字，说明我们想要一个以逗号分隔的列表，并提供了一些任务完成得好的示例。
- en: 'Input:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Output:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: While no prompt is ever perfect, this prompt is optimized to reliably deliver
    solid product names in the right format. The user of your product name generator
    can choose somebody other than Steve Jobs to get the types of names they like,
    they can change the response format if needed, and the output of this prompt can
    become the input of another. Finally, you could periodically update the examples
    you use in the prompt based on user feedback, making your system smarter over
    time.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有任何提示是完美的，但这个提示被优化了，可以可靠地以正确的格式提供坚实的商品名称。你的产品名称生成器的用户可以选择除史蒂夫·乔布斯之外的其他人，如果需要，他们可以更改响应格式，并且这个提示的输出可以成为另一个输入。最后，你可以根据用户反馈定期更新你在提示中使用的示例，使你的系统随着时间的推移变得更智能。
- en: Overview of the Five Principles of Prompting
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示五原则概述
- en: 'The process for optimizing this prompt follows the *Five Principles of Prompting*,
    which we will dissect using this example in the remainder of this chapter, and
    recall throughout the book. They map exactly to the five issues we raised when
    discussing the naive text prompt. You’ll find references back to these principles
    throughout the rest of the book to help you connect the dots to how they’re used
    in practice. The Five Principles of Prompting are as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Give Direction
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Describe the desired style in detail, or reference a relevant persona
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Specify Format
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: Define what rules to follow, and the required structure of the response
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: Provide Examples
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: Insert a diverse set of test cases where the task was done correctly
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Evaluate Quality
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Identify errors and rate responses, testing what drives performance.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: Divide Labor
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Split tasks into multiple steps, chained together for complex goals
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'These principles are not short-lived *tips* or *hacks* but are generally accepted
    conventions that are useful for working with any level of intelligence, biological
    or artificial. These principles are model-agnostic and should work to improve
    your prompt no matter which generative text or image model you’re using. We first
    published these principles in July 2022 in the blog post [“Prompt Engineering:
    From Words to Art and Copy”](https://oreil.ly/RYYiV), and they have stood the
    test of time, including mapping quite closely to OpenAI’s own [Prompt Engineering
    Guide](https://oreil.ly/dF8q-), which came a year later. Anyone who works closely
    with generative AI models is likely to converge on a similar set of strategies
    for solving common issues, and throughout this book you’ll see hundreds of demonstrative
    examples of how they can be useful for improving your prompts.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: We have provided downloadable one-pagers for text and image generation you can
    use as a checklist when applying these principles. These were created for our
    popular Udemy course [The Complete Prompt Engineering for AI Bootcamp](https://oreil.ly/V40zg)
    (70,000+ students), which was based on the same principles but with different
    material to this book.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[Text Generation One-Pager](https://oreil.ly/VCcgy)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Image Generation One-Pager](https://oreil.ly/q7wQF)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To show these principles apply equally well to prompting image models, let’s
    use the following example, and explain how to apply each of the Five Principles
    of Prompting to this specific scenario. Copy and paste the entire input prompt
    into the Midjourney Bot in Discord, including the link to the image at the beginning,
    after typing `**/imagine**` to trigger the prompt box to appear (requires a free
    [Discord](https://discord.com) account, and a paid [Midjourney](https://www.midjourney.com)
    account).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: 'Input:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[Figure 1-2](#figure-1-2) shows the output.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![pega 0102](assets/pega_0102.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: Figure 1-2\. Stock photo of business meeting
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This prompt takes advantage of Midjourney’s ability to take a base image as
    an example by uploading the image to Discord and then copy and pasting the URL
    into the prompt (*[*https://s.mj.run/TKAsyhNiKmc*](https://s.mj.run/TKAsyhNiKmc)*),
    for which the royalty-free image from Unsplash is used ([Figure 1-3](#figure-1-3)).
    If you run into an error with the prompt, try uploading the image yourself and
    reviewing [Midjourney’s documentation](https://oreil.ly/UTxpX) for any formatting
    changes.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示利用了Midjourney能够以一个基础图像为例的能力，通过将图像上传到Discord，然后将URL复制粘贴到提示中（[*https://s.mj.run/TKAsyhNiKmc*](https://s.mj.run/TKAsyhNiKmc)），这里使用了Unsplash的免费图片（[图1-3](#figure-1-3)）。如果你在提示中遇到错误，请尝试自己上传图像并查看Midjourney的文档（[Midjourney的文档](https://oreil.ly/UTxpX)）以了解任何格式更改。
- en: '![pega 0103](assets/pega_0103.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0103](assets/pega_0103.png)'
- en: Figure 1-3\. Photo by Mimi Thian on [Unsplash](https://oreil.ly/J4Hkr)
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-3. 由Mimi Thian在[Unsplash](https://oreil.ly/J4Hkr)拍摄的照片
- en: Let’s compare this well-engineered prompt to what you get back from Midjourney
    if you naively ask for a stock photo in the simplest way possible. [Figure 1-4](#figure-1-4)
    shows an example of what you get without prompt engineering, an image with a darker,
    more stylistic take on a stock photo than you’d typically expect.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较这个精心设计的提示与如果你以最简单的方式天真地要求一张股票照片时从Midjourney得到的输出。[图1-4](#figure-1-4)显示了一个没有提示工程得到的例子，这张图像比通常预期的股票照片风格更暗、更具有风格化。
- en: 'Input:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[Figure 1-4](#figure-1-4) shows the output.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-4](#figure-1-4)显示了输出。'
- en: Although less prominent an issue in v5 of Midjourney onwards, community feedback
    mechanisms (when users select an image to resize to a higher resolution, that
    choice may be used to train the model) have reportedly biased the model toward
    a *fantasy* aesthetic, which is less suitable for the stock photo use case. The
    early adopters of Midjourney came from the digital art world and naturally gravitated
    toward fantasy and sci-fi styles, which can be reflected in the results from the
    model even when this aesthetic is not suitable.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在Midjourney v5及以后的版本中这个问题不太突出，但社区反馈机制（当用户选择一个图像进行放大到更高分辨率时，这个选择可能会用于训练模型）据报道已经使模型偏向于*幻想*美学，这不太适合股票照片的使用场景。Midjourney的早期采用者来自数字艺术界，自然倾向于幻想和科幻风格，即使这种美学不适合，这些风格也可以在模型的结果中反映出来。
- en: '![pega 0104](assets/pega_0104.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0104](assets/pega_0104.png)'
- en: Figure 1-4\. People in a business meeting
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4. 商务会议中的人们
- en: Throughout this book the examples used will be compatiable with ChatGPT Plus
    (GPT-4) as the text model and Midjourney v6 or Stable Diffusion XL as the image
    model, though we will specify if it’s important. These foundational models are
    the current state of the art and are good at a diverse range of tasks. The principles
    are intended to be future-proof as much as is possible, so if you’re reading this
    book when GPT-5, Midjourney v7, or Stable Diffusion XXL is out, or if you’re using
    another vendor like Google, everything you learn here should still prove useful.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中使用的示例将与ChatGPT Plus（GPT-4）作为文本模型以及Midjourney v6或Stable Diffusion XL作为图像模型兼容，尽管我们会指定是否重要。这些基础模型是当前最先进的技术，擅长各种任务。原则旨在尽可能保证未来兼容性，所以如果你在GPT-5、Midjourney
    v7或Stable Diffusion XXL发布时阅读这本书，或者如果你使用的是其他供应商如Google，这里学到的所有内容仍然应该是有用的。
- en: 1\. Give Direction
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 给出方向
- en: One of the issues with the naive text prompt discussed earlier was that it wasn’t
    briefing the AI on what *types* of product names you wanted. To some extent, naming
    a product is a subjective endeavor, and without giving the AI an idea of what
    names you like, it has a low probability of guessing right.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 之前讨论的简单文本提示的一个问题是，它没有向AI说明你想要的*类型*的产品名称。在某种程度上，给产品命名是一项主观的活动，如果不给AI一个你喜欢的名称的想法，它猜对的概率很低。
- en: By the way, a human would also struggle to complete this task without a good
    *brief*, which is why creative and branding agencies require a detailed briefing
    on any task from their clients.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，即使没有良好的*概要*，人类也很难完成这项任务，这也是为什么创意和品牌代理机构需要从客户那里获得任何任务的详细说明。
- en: Tip
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Although it’s not a perfect mapping, it can be helpful to imagine what context
    a human might need for this task and try including it in the prompt.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这不是完美的映射，但可以想象人类可能需要什么样的上下文来完成这项任务，并尝试将其包括在提示中。
- en: In the example prompt we gave direction through the use of *role-playing*, in
    that case emulating the style of Steve Jobs, who was famous for iconically naming
    products. If you change this aspect of the prompt to someone else who is famous
    in the training data (as well as matching the examples to the right style), you’ll
    get dramatically different results.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们给出的示例提示中，我们通过使用 *角色扮演* 来给出方向，在那个例子中是模仿史蒂夫·乔布斯（Steve Jobs）的风格，他因标志性产品命名而闻名。如果你改变提示的这个方面，使其指向训练数据中其他著名人物（以及匹配正确的风格），你会得到截然不同的结果。
- en: 'Input:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Output:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: There are also some rules or best practices you would do well to follow, which
    could be included in the prompt as context to guide the AI toward a name that
    works. This technique is sometimes referred to as *prewarming* or *internal retrieval*,
    and it is simple but effective ([Liu et al., 2021](https://oreil.ly/1lqzK)). Starting
    the conversation asking for best practice advice, then asking it to follow its
    own advice, can help a lot. In effect, you are using it to generate its own direction.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一些规则或最佳实践是你应该遵循的，这些可以包含在提示中作为上下文，以引导 AI 向一个有效的名字发展。这种技术有时被称为 *预热* 或 *内部检索*，它简单但有效
    ([刘等，2021](https://oreil.ly/1lqzK))。从询问最佳实践建议开始对话，然后要求它遵循自己的建议，这会有很大帮助。实际上，你是在用它来生成自己的方向。
- en: 'Input:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Output:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Then within the same chat window, where the model has the context of the past
    advice it gave, you ask your initial prompt for the task you wanted to complete.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在同一个聊天窗口中，当模型有过去给出的建议的上下文时，你提出你想要完成的任务的初始提示。
- en: 'Input:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Output:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Another fruitful strategy in our experience is to take the best advice out there
    for the task you want to accomplish and insert that context into the prompt. For
    example, you could take [Brandwatch’s 5 Golden Rules for naming a product](https://oreil.ly/3bWjz)
    or another trusted external resource you find, and insert that as context into
    the prompt. This will increase the length of the prompt significantly, which costs
    more money (when using the API as a developer), but may be worth the trade-off
    if the quality of the response improves.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的经验中，另一个富有成效的策略是采取针对你想要完成的任务的最好建议，并将其插入到提示中。例如，你可以采用 [Brandwatch 的 5 条产品命名黄金法则](https://oreil.ly/3bWjz)
    或其他你找到的受信任的外部资源，并将其作为上下文插入到提示中。这将显著增加提示的长度，这会花费更多的钱（当作为开发者使用 API 时），但如果响应的质量有所提高，这可能值得这种权衡。
- en: 'Input:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Output:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: There are other myriad ways of providing direction. In the image generation
    example, direction was given by specifying that the business meeting is taking
    place around a glass-top table. If you change only that detail, you can get a
    completely different image, as detailed in [Figure 1-5](#figure-1-5).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 提供方向的方法还有很多。在图像生成示例中，通过指定商务会议是在一个玻璃桌周围举行的来给出方向。如果你只改变这个细节，你可以得到一个完全不同的图像，如图
    [图 1-5](#figure-1-5) 所详细说明的那样。
- en: 'Input:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[Figure 1-5](#figure-1-5) shows the output.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1-5](#figure-1-5) 展示了输出结果。'
- en: '![pega 0105](assets/pega_0105.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0105](assets/pega_0105.png)'
- en: Figure 1-5\. Stock photo of business meeting in the woods
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-5\. 丛林中的商务会议股票照片
- en: Role-playing is also important for image generation, and one of the quite powerful
    ways you can give Midjourney direction is to supply the name of an artist or art
    style to emulate. One artist that features heavily in the AI art world is Van
    Gogh, known for his bold, dramatic brush strokes and vivid use of colors. Watch
    what happens when you include his name in the prompt, as shown in [Figure 1-6](#figure-1-6).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 角色扮演对于图像生成也很重要，你可以通过提供要模仿的艺术家或艺术风格的名字来给 Midjourney 指明方向。在人工智能艺术界中，梵高是一个非常重要的艺术家，他以其大胆、戏剧性的笔触和生动的色彩运用而闻名。看看当你将他的名字包含在提示中时会发生什么，如图
    [图 1-6](#figure-1-6) 所示。
- en: 'Input:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE15]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[Figure 1-6](#figure-1-6) shows the output.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1-6](#figure-1-6) 展示了输出结果。'
- en: '![pega 0106](assets/pega_0106.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0106](assets/pega_0106.png)'
- en: Figure 1-6\. People in a business meeting, by Van Gogh
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-6\. 梵高风格的商务会议场景
- en: To get that last prompt to work, you need to strip back a lot of the other direction.
    For example, losing the base image and the words *stock photo* as well as the
    camera *Panasonic, DC-GH5* helps bring in Van Gogh’s style. The problem you may
    run into is that often with too much direction, the model can quickly get to a
    conflicting combination that it can’t resolve. If your prompt is overly specific,
    there might not be enough samples in the training data to generate an image that’s
    consistent with all of your criteria. In cases like these, you should choose which
    element is more important (in this case, Van Gogh) and defer to that.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 要使最后一个提示生效，你需要删除很多其他指导。例如，去掉基础图像和单词“股票照片”，以及相机“松下，DC-GH5”，有助于引入梵高的风格。你可能会遇到的问题是，通常过多的指导会导致模型快速达到它无法解决的冲突组合。如果你的提示过于具体，训练数据中可能没有足够的样本来生成符合所有你标准的图像。在这种情况下，你应该选择哪个元素更重要（在这种情况下，是梵高），并据此做出决定。
- en: Direction is one of the most commonly used and broadest principles. It can take
    the form of simply using the right descriptive words to clarify your intent, or
    channeling the personas of relevant business celebrities. While too much direction
    can narrow the creativity of the model, too little direction is the more common
    problem.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 指导是使用最广泛和最普遍的原则之一。它可以采取简单地使用正确的描述性词语来阐明你的意图，或者模仿相关商业名人的形象。虽然过多的指导可能会限制模型的创造力，但指导不足是更常见的问题。
- en: 2\. Specify Format
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2. 指定格式
- en: AI models are universal translators. Not only does that mean translating from
    French to English, or Urdu to Klingon, but also between data structures like JSON
    to YAML, or natural language to Python code. These models are capable of returning
    a response in almost any format, so an important part of prompt engineering is
    finding ways to specify what format you want the response to be in.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: AI模型是通用的翻译器。这不仅意味着从法语翻译成英语，或从乌尔都语翻译成克林贡语，还包括在数据结构之间，如从JSON到YAML，或从自然语言到Python代码之间的翻译。这些模型能够以几乎任何格式返回响应，因此提示工程的一个重要部分是找到指定你想要的响应格式的方法。
- en: Every now and again you’ll find that the same prompt will return a different
    format, for example, a numbered list instead of comma separated. This isn’t a
    big deal most of the time, because most prompts are one-offs and typed into ChatGPT
    or Midjourney. However, when you’re incorporating AI tools into production software,
    occasional flips in format can cause all kinds of errors.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 不时你会发现，相同的提示会返回不同的格式，例如，数字列表而不是逗号分隔列表。大多数时候这并不是什么大问题，因为大多数提示都是一次性的，并且是在ChatGPT或Midjourney中输入的。然而，当你将AI工具集成到生产软件中时，偶尔的格式变化可能会导致各种错误。
- en: Just like when working with a human, you can avoid wasted effort by specifying
    up front the format you expect the response to be in. For text generation models,
    it can often be helpful to output JSON instead of a simple ordered list because
    that’s the universal format for API responses, which can make it simpler to parse
    and spot errors, as well as to use to render the front-end HTML of an application.
    YAML is also another popular choice because it enforces a parseable structure
    while still being simple and human-readable.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 就像与人类合作一样，通过提前指定你期望的响应格式，你可以避免浪费精力。对于文本生成模型，输出JSON而不是简单的有序列表通常很有帮助，因为这是API响应的通用格式，这使得解析和查找错误更加简单，同时也可以用来渲染应用程序的前端HTML。YAML也是另一个流行的选择，因为它强制执行可解析的结构，同时仍然简单且易于阅读。
- en: In the original prompt you gave direction through both the examples provided,
    and the colon at the end of the prompt indicated it should complete the list inline.
    To swap the format to JSON, you need to update both and leave the JSON uncompleted,
    so GPT-4 knows to complete it.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在你给出的原始提示中，你通过提供的示例和提示末尾的冒号来指示它应该直接完成列表。要将格式更改为JSON，你需要更新两者，并留下JSON未完成，这样GPT-4就会知道完成它。
- en: 'Input:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Output:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output we get back is the completed JSON containing the product names.
    This can then be parsed and used programmatically, in an application or local
    script. It’s also easy from this point to check if there’s an error in the formatting
    using a JSON parser like Python’s standard *json* library, because broken JSON
    will result in a parsing error, which can act as a trigger to retry the prompt
    or investigate before continuing. If you’re still not getting the right format
    back, it can help to specify at the beginning or end of the prompt, or in the
    system message if using a chat model: `You are a helpful assistant that only responds
    in JSON`, or specify [JSON output](https://oreil.ly/E7wua) in the model parameters
    where available (this is called *grammars* with [Llama models](https://oreil.ly/yU27T).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的输出是包含产品名称的完整JSON。这可以随后被解析并用于程序化，在应用程序或本地脚本中使用。从这个点开始，使用Python标准 *json*
    库之类的JSON解析器检查格式错误也很容易，因为损坏的JSON会导致解析错误，这可以作为重试提示或继续之前进行调查的触发器。如果你仍然没有得到正确的格式，在提示的开始或结束处指定，或者在使用聊天模型时在系统消息中指定可能会有所帮助：“你是一个只以JSON响应的有用助手”，或者如果模型参数中可用，指定[JSON输出](https://oreil.ly/E7wua)（这在[Llama模型](https://oreil.ly/yU27T)中被称为
    *grammars*）。
- en: Tip
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: To get up to speed on JSON if you’re unfamiliar, W3Schools [has a good introduction](https://oreil.ly/Xakgc).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不熟悉JSON，W3Schools [有一个很好的介绍](https://oreil.ly/Xakgc)。
- en: For image generation models, format is very important, because the opportunities
    for modifying an image are near endless. They range from obvious formats like
    `stock photo`, `illustration`, and `oil painting`, to more unusual formats like
    `dashcam footage`, `ice sculpture`, or `in Minecraft` (see [Figure 1-7](#figure-1-7)).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像生成模型来说，格式非常重要，因为修改图像的机会几乎是无限的。它们包括像“股票照片”、“插图”和“油画”这样的明显格式，到更不寻常的格式，如“行车记录仪视频”、“冰雕”或“在Minecraft中”（见[图1-7](#figure-1-7)）。
- en: 'Input:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE18]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[Figure 1-7](#figure-1-7) shows the output.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-7](#figure-1-7) 展示了输出结果。'
- en: '![pega 0107](assets/pega_0107.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0107](assets/pega_0107.png)'
- en: Figure 1-7\. Business meeting in Minecraft
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-7\. Minecraft中的商务会议
- en: When setting a format, it is often necessary to remove other aspects of the
    prompt that might clash with the specified format. For example, if you supply
    a base image of a stock photo, the result is some combination of stock photo and
    the format you wanted. To some degree, image generation models can generalize
    to new scenarios and combinations they haven’t seen before in their training set,
    but in our experience, the more layers of unrelated elements, the more likely
    you are to get an unsuitable image.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置格式时，通常需要移除可能与指定格式冲突的提示的其他方面。例如，如果你提供了一张股票照片的底图，结果将是股票照片和所需格式的某种组合。在一定程度上，图像生成模型可以推广到他们在训练集中之前未见过的新的场景和组合，但根据我们的经验，无关元素的层级越多，你得到不合适图像的可能性就越大。
- en: There is often some overlap between the first and second principles, Give Direction
    and Specify Format. The latter is about defining what type of output you want,
    for example JSON format, or the format of a stock photo. The former is about the
    style of response you want, independent from the format, for example product names
    in the style of Steve Jobs, or an image of a business meeting in the style of
    Van Gogh. When there are clashes between style and format, it’s often best to
    resolve them by dropping whichever element is less important to your final result.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 第一原则和第二原则之间往往存在一些重叠，即给出方向和指定格式。后者是关于定义你想要的输出类型，例如JSON格式，或股票照片的格式。前者是关于你想要的响应风格，独立于格式，例如以史蒂夫·乔布斯风格的产品名称，或梵高风格的商务会议图像。当风格和格式发生冲突时，通常最好通过删除对最终结果不那么重要的元素来解决。
- en: 3\. Provide Examples
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 提供示例
- en: 'The original prompt didn’t give the AI any examples of what you think *good*
    names look like. Therefore, the response is approximate to an average of the internet,
    and you can do better than that. Researchers would call a prompt with no examples
    *zero-shot*, and it’s always a pleasant surprise when AI can even do a task zero
    shot: it’s a sign of a powerful model. If you’re providing zero examples, you’re
    asking for a lot without giving much in return. Even providing one example (*one-shot*)
    helps considerably, and it’s the norm among researchers to test how models perform
    with multiple examples (*few-shot*). One such piece of research is the famous
    GPT-3 paper [“Language Models are Few-Shot Learners”](https://oreil.ly/KW5PS),
    the results of which are illustrated in [Figure 1-8](#figure-1-8), showing adding
    one example along with a prompt can improve accuracy in some tasks from 10% to
    near 50%!'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 原始提示没有给出你认为*好的*名字的任何例子。因此，响应接近互联网的平均水平，你可以做得更好。研究人员将没有例子的提示称为*零样本*，当人工智能甚至能够零样本完成任务时，这总是一个令人愉快的惊喜：这是强大模型的标志。如果你不提供任何例子，你是在索取很多而回报很少。即使提供一个例子（*单样本*）也能大大帮助，研究人员通常测试模型在多个例子（*少样本*）下的表现。其中一项著名的研究是GPT-3论文[“Language
    Models are Few-Shot Learners”](https://oreil.ly/KW5PS)，其结果在[图 1-8](#figure-1-8)中展示，显示添加一个例子与提示结合可以提高某些任务的准确性，从10%提高到近50%！
- en: '![pega 0108](assets/pega_0108.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0108](assets/pega_0108.png)'
- en: Figure 1-8\. Number of examples in context
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-8\. 上下文中的示例数量
- en: When briefing a colleague or training a junior employee on a new task, it’s
    only natural that you’d include examples of times that task had previously been
    done well. Working with AI is the same, and the strength of a prompt often comes
    down to the examples used. Providing examples can sometimes be easier than trying
    to explain exactly what it is about those examples you like, so this technique
    is most effective when you are not a domain expert in the subject area of the
    task you are attempting to complete. The amount of text you can fit in a prompt
    is limited (at the time of writing around 6,000 characters on Midjourney and approximately
    32,000 characters for the free version of ChatGPT), so a lot of the work of prompt
    engineering involves selecting and inserting diverse and instructive examples.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 当向同事简要介绍一项新任务或培训初级员工时，自然地会包括一些该任务之前做得好的例子。与人工智能合作也是如此，提示的强大之处往往取决于所使用的例子。提供例子有时比试图解释你为什么喜欢这些例子要容易，因此当你在尝试完成的任务的主题领域不是领域专家时，这种技术最为有效。你可以在提示中放入的文本量是有限的（截至写作时，Midjourney上大约有6,000个字符，ChatGPT免费版大约有32,000个字符），因此提示工程的大部分工作涉及选择和插入多样且富有教育意义的例子。
- en: 'There’s a trade-off between reliability and creativity: go past three to five
    examples and your results will become more reliable, while sacrificing creativity.
    The more examples you provide, and the lesser the diversity between them, the
    more constrained the response will be to match your examples. If you change all
    of the examples to animal names in the previous prompt, you’ll have a strong effect
    on the response, which will reliably return only names including animals.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在可靠性和创造力之间有一个权衡：超过三个到五个例子，你的结果将变得更加可靠，但会牺牲创造力。你提供的例子越多，它们之间的多样性越少，响应就越有可能与你的例子相匹配。如果你将前一个提示中的所有例子都改为动物名字，这将强烈影响响应，可靠地只返回包含动物名字的名称。
- en: 'Input:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE19]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Output:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE20]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Of course this runs the risk of missing out on returning a much better name
    that doesn’t fit the limited space left for the AI to play in. Lack of diversity
    and variation in examples is also a problem in handling edge cases, or uncommon
    scenarios. Including one to three examples is easy and almost always has a positive
    effect, but above that number it becomes essential to experiment with the number
    of examples you include, as well as the similarity between them. There is some
    evidence ([Hsieh et al., 2023](https://oreil.ly/6Ixcw)) that direction works better
    than providing examples, and it typically isn’t straightforward to collect good
    examples, so it’s usually prudent to attempt the principle of Give Direction first.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这存在错过返回一个更适合在AI有限空间内发挥作用的更好名字的风险。在处理边缘情况或罕见场景时，示例的多样性和变化不足也是一个问题。包含一到三个示例很容易，并且几乎总是有积极的效果，但超过这个数量，就变得必须实验包含的示例数量以及它们之间的相似性。有证据表明（[Hsieh等人，2023](https://oreil.ly/6Ixcw)），提供方向比提供示例更有效，而且通常收集好的示例并不简单，因此通常谨慎地首先尝试提供方向的原则。
- en: In the image generation space, providing examples usually comes in the form
    of providing a base image in the prompt, called *img2img* in the open source [Stable
    Diffusion](https://oreil.ly/huVRu) community. Depending on the image generation
    model being used, these images can be used as a starting point for the model to
    generate from, which greatly affects the results. You can keep everything about
    the prompt the same but swap out the provided base image for a radically different
    effect, as in [Figure 1-9](#figure-1-9).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像生成领域，提供示例通常以在提示中提供基础图像的形式出现，在开源[Stable Diffusion](https://oreil.ly/huVRu)社区中称为*img2img*。根据使用的图像生成模型，这些图像可以作为模型生成的基础，这极大地影响了结果。你可以保持提示的所有内容不变，但用提供的不同基础图像替换，以产生截然不同的效果，如[图1-9](#figure-1-9)所示。
- en: 'Input:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE21]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[Figure 1-9](#figure-1-9) shows the output.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-9](#figure-1-9) 展示了输出结果。'
- en: '![pega 0109](assets/pega_0109.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0109](assets/pega_0109.png)'
- en: Figure 1-9\. Stock photo of business meeting of four people
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-9. 四人商务会议的股票照片
- en: In this case, by substituting for the image shown in [Figure 1-10](#figure-1-10),
    also from Unsplash, you can see how the model was pulled in a different direction
    and incorporates whiteboards and sticky notes now.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，通过替换[图1-10](#figure-1-10)中显示的图片，该图片也来自Unsplash，你可以看到模型被拉向了不同的方向，并且现在包含了白板和便利贴。
- en: Caution
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: These examples demonstrate the capabilities of image generation models, but
    we would exercise caution when uploading base images for use in prompts. Check
    the licensing of the image you plan to upload and use in your prompt as the base
    image, and avoid using clearly copyrighted images. Doing so can land you in legal
    trouble and is against the terms of service for all the major image generation
    model providers.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这些示例展示了图像生成模型的能力，但在上传基础图像用于提示时，我们需要谨慎行事。请检查你计划上传并用于提示的基础图像的许可，并避免使用明显受版权保护的照片。这样做可能会让你陷入法律纠纷，并且违反了所有主要图像生成模型提供商的服务条款。
- en: '![pega 0110](assets/pega_0110.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0110](assets/pega_0110.png)'
- en: Figure 1-10\. Photo by Jason Goodman on [Unsplash](https://oreil.ly/ZbzZy)
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10. 由Jason Goodman在[Unsplash](https://oreil.ly/ZbzZy)拍摄的照片
- en: 4\. Evaluate Quality
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 评估质量
- en: As of yet, there has been no feedback loop to judge the quality of your responses,
    other than the basic trial and error of running the prompt and seeing the results,
    referred to as [*blind prompting*](https://oreil.ly/42rSz). This is fine when
    your prompts are used temporarily for a single task and rarely revisited. However,
    when you’re reusing the same prompt multiple times or building a production application
    that relies on a prompt, you need to be more rigorous with measuring results.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，还没有反馈回路来判断你响应的质量，除了运行提示并查看结果的基本试错法，这被称为[*盲提示*](https://oreil.ly/42rSz)。当你的提示仅用于临时执行单一任务且很少再次访问时，这是可以接受的。然而，当你多次重用相同的提示或构建依赖于提示的生产应用程序时，你需要对结果进行更严格的测量。
- en: There are a number of ways performance can be evaluated, and it depends largely
    on what tasks you’re hoping to accomplish. When a new AI model is released, the
    focus tends to be on how well the model did on *evals* (evaluations), a standardized
    set of questions with predefined answers or grading criteria that are used to
    test performance across models. Different models perform differently across different
    types of tasks, and there is no guarantee a prompt that worked previously will
    translate well to a new model. OpenAI has [made its evals framework](https://oreil.ly/wolEL)
    for benchmarking performance of LLMs open source and encourages others to contribute
    additional eval templates.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 评估性能有多种方式，这主要取决于您希望完成哪些任务。当一个新的AI模型发布时，重点往往在于模型在*评估*（评估）上的表现如何，这是一个标准化的问题集，具有预定义的答案或评分标准，用于测试模型间的性能。不同的模型在不同类型的任务上表现不同，不能保证之前有效的提示在新模型上也能很好地翻译。OpenAI已经将其用于基准测试LLM性能的evals框架开源，并鼓励其他人贡献额外的评估模板。
- en: In addition to the standard academic evals, there are also more headline-worthy
    tests like [GPT-4 passing the bar exam](https://oreil.ly/txhSZ). Evaluation is
    difficult for more subjective tasks, and can be time-consuming or prohibitively
    costly for smaller teams. In some instances researchers have turned to using more
    advanced models like GPT-4 to evaluate responses from less sophisticated models,
    as was done with [the release of Vicuna-13B](https://oreil.ly/NW3WX), a fine-tuned
    model based on Meta’s Llama open source model (see [Figure 1-11](#figure-1-11)).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标准的学术评估外，还有一些更具新闻价值的测试，例如[GPT-4通过律师资格考试](https://oreil.ly/txhSZ)。对于更主观的任务，评估可能很困难，对于小型团队来说可能耗时或成本高昂。在某些情况下，研究人员已经转向使用更先进的模型，如GPT-4，来评估来自不那么复杂的模型的响应，正如在[发布基于Meta的Llama开源模型的微调模型Vicuna-13B](https://oreil.ly/NW3WX)时所做的（参见[图1-11](#figure-1-11)）。
- en: '![pega 0111](assets/pega_0111.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![pega 0111](assets/pega_0111.png)'
- en: Figure 1-11\. Vicuna GPT-4 Evals
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-11. Vicuna GPT-4 评估
- en: More rigorous evaluation techniques are necessary when writing scientific papers
    or grading a new foundation model release, but often you will only need to go
    just one step above basic trial and error. You may find that a simple thumbs-up/thumbs-down
    rating system implemented in a Jupyter Notebook can be enough to add some rigor
    to prompt optimization, without adding too much overhead. One common test is to
    see whether providing examples is worth the additional cost in terms of prompt
    length, or whether you can get away with providing no examples in the prompt.
    The first step is getting responses for multiple runs of each prompt and storing
    them in a spreadsheet, which we will do after setting up our environment.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写科学论文或评估新的基础模型发布时，需要更严格的评估技术，但通常您只需比基本的试错多走一步。您可能会发现，在Jupyter Notebook中实现的简单点赞/踩不点赞系统可以为提示优化增加一些严谨性，而不会增加太多开销。一个常见的测试是看提供示例是否值得额外的提示长度成本，或者是否可以在提示中不提供示例也能过得去。第一步是为每个提示的多次运行获取响应并将它们存储在电子表格中，我们将在设置好环境后进行此操作。
- en: You can install the OpenAI Python package with `pip install openai`. If you’re
    running into compatability issues with this package, create a virtual environment
    and install our [*requirements.txt*](https://oreil.ly/2KDV6) (instructions in
    the preface).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`pip install openai`命令安装OpenAI Python包。如果您遇到与此包的兼容性问题，请创建一个虚拟环境并安装我们的[*requirements.txt*](https://oreil.ly/2KDV6)（请参阅前言中的说明）。
- en: To utilize the API, you’ll need to [create an OpenAI account](https://oreil.ly/oGv4j)
    and then [navigate here for your API key](https://oreil.ly/oHID1).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用API，您需要[创建一个OpenAI账户](https://oreil.ly/oGv4j)，然后[在此处获取您的API密钥](https://oreil.ly/oHID1)。
- en: Warning
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Hardcoding API keys in scripts is not recommended due to security reasons. Instead,
    utilize environment variables or configuration files to manage your keys.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 由于安全原因，不建议在脚本中硬编码API密钥。相反，请使用环境变量或配置文件来管理您的密钥。
- en: 'Once you have an API key, it’s crucial to assign it as an environment variable
    by executing the following command, replacing `api_key` with your actual API key
    value:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了API密钥，执行以下命令将其分配为环境变量至关重要，用您的实际API密钥值替换`api_key`：
- en: '[PRE22]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23] set OPENAI_API_KEY=api_key [PRE24]`Alternatively, if you’d prefer not
    to preset an API key, then you can manually set the key while initializing the
    model, or load it from an *.env* file using *[python-dotenv](https://oreil.ly/IaQjS)*.
    First, install the library with `pip install python-dotenv`, and then load the
    environment variables with the following code at the top of your script or notebook:    [PRE25]    The
    first step is getting responses for multiple runs of each prompt and storing them
    in a spreadsheet.    Input:    [PRE26]    Output:    [PRE27]    Here we’re using
    the OpenAI API to generate model responses to a set of prompts and storing the
    results in a dataframe, which is saved to a CSV file. Here’s how it works:    1.  Two
    prompt variants are defined, and each variant consists of a product description,
    seed words, and potential product names, but `prompt_B` provides two examples.           2.  Import
    statements are called for the Pandas library, OpenAI library, and os library.           3.  The
    `get_response` function takes a prompt as input and returns a response from the
    `gpt-3.5-turbo` model. The prompt is passed as a user message to the model, along
    with a system message to set the model’s behavior.           4.  Two prompt variants
    are stored in the `test_prompts` list.           5.  An empty list `responses`
    is created to store the generated responses, and the variable `num_tests` is set
    to 5.           6.  A nested loop is used to generate responses. The outer loop
    iterates over each prompt, and the inner loop generates `num_tests` (five in this
    case) number of responses per prompt.               1.  The `enumerate` function
    is used to get the index and value of each prompt in `test_prompts`. This index
    is then converted to a corresponding uppercase letter (e.g., 0 becomes *A*, 1
    becomes *B*) to be used as a variant name.                       2.  For each
    iteration, the `get_response` function is called with the current prompt to generate
    a response from the model.                       3.  A dictionary is created with
    the variant name, the prompt, and the model’s response, and this dictionary is
    appended to the `responses` list.                   7.  Once all responses have
    been generated, the `responses` list (which is now a list of dictionaries) is
    converted into a Pandas DataFrame.           8.  This dataframe is then saved
    to a CSV file with the Pandas built-in `to_csv` function, making the file *responses.csv*
    with `index=False` so as to not write row indices.           9.  Finally, the
    dataframe is printed to the console.              Having these responses in a
    spreadsheet is already useful, because you can see right away even in the printed
    response that `prompt_A` (zero-shot) in the first five rows is giving us a numbered
    list, whereas `prompt_B` (few-shot) in the last five rows tends to output the
    desired format of a comma-separated inline list. The next step is to give a rating
    on each of the responses, which is best done blind and randomized to avoid favoring
    one prompt over another.    Input:    [PRE28]    The output is shown in [Figure 1-12](#figure-1-12):  ![pega
    0112](assets/pega_0112.png)  ###### Figure 1-12\. Thumbs-up/thumbs-down rating
    system    If you run this in a Jupyter Notebook, a widget displays each AI response,
    with a thumbs-up or thumbs-down button (see [Figure 1-12](#figure-1-12)) This
    provides a simple interface for quickly labeling responses, with minimal overhead.
    If you wish to do this outside of a Jupyter Notebook, you could change the thumbs-up
    and thumbs-down emojis for *Y* and *N*, and implement a loop using the built-in
    `input()` function, as a text-only replacement for iPyWidgets.    Once you’ve
    finished labeling the responses, you get the output, which shows you how each
    prompt performs.    Output:    [PRE29]    The dataframe was shuffled at random,
    and each response was labeled blind (without seeing the prompt), so you get an
    accurate picture of how often each prompt performed. Here is the step-by-step
    explanation:    1.  Three modules are imported: `ipywidgets`, `IPython.display`,
    and `pandas`. `ipywidgets` contains interactive HTML widgets for Jupyter Notebooks
    and the IPython kernel. `IPython.display` provides classes for displaying various
    types of output like images, sound, displaying HTML, etc. Pandas is a powerful
    data manipulation library.           2.  The pandas library is used to read in
    the CSV file *responses.csv*, which contains the responses you want to test. This
    creates a Pandas DataFrame called `df`.           3.  `df` is shuffled using the
    `sample()` function with `frac=1`, which means it uses all the rows. The `reset_index(drop=True)`
    is used to reset the indices to the standard 0, 1, 2, …​, n index.           4.  The
    script defines `response_index` as 0\. This is used to track which response from
    the dataframe the user is currently viewing.           5.  A new column `feedback`
    is added to the dataframe `df` with the data type as `str` or string.           6.  Next,
    the script defines a function `on_button_clicked(b)`, which will execute whenever
    one of the two buttons in the interface is clicked.               1.  The function
    first checks the `description` of the button clicked was the thumbs-up button
    (`\U0001F44D`; ![thumbs up 1f44d](assets/thumbs-up_1f44d.png)), and sets `user_feedback`
    as 1, or if it was the thumbs-down button (`\U0001F44E` ![thumbs down 1f44e](assets/thumbs-down_1f44e.png)),
    it sets `user_feedback` as 0.                       2.  Then it updates the `feedback`
    column of the dataframe at the current `response_index` with `user_feedback`.                       3.  After
    that, it increments `response_index` to move to the next response.                       4.  If
    `response_index` is still less than the total number of responses (i.e., the length
    of the dataframe), it calls the function `update_response()`.                       5.  If
    there are no more responses, it saves the dataframe to a new CSV file *results.csv*,
    then prints a message, and also prints a summary of the results by variant, showing
    the count of feedback received and the average score (mean) for each variant.                   7.  The
    function `update_response()` fetches the next response from the dataframe, wraps
    it in paragraph HTML tags (if it’s not null), updates the `response` widget to
    display the new response, and updates the `count_label` widget to reflect the
    current response number and total number of responses.           8.  Two widgets,
    `response` (an HTML widget) and `count_label` (a Label widget), are instantiated.
    The `update_response()` function is then called to initialize these widgets with
    the first response and the appropriate label.           9.  Two more widgets,
    `thumbs_up_button` and `thumbs_down_button` (both Button widgets), are created
    with thumbs-up and thumbs-down emoji as their descriptions, respectively. Both
    buttons are configured to call the `on_button_clicked()` function when clicked.           10.  The
    two buttons are grouped into a horizontal box (`button_box`) using the `HBox`
    function.           11.  Finally, the `response`, `button_box`, and `count_label`
    widgets are displayed to the user using the `display()` function from the `IPython.display`
    module.              A simple rating system such as this one can be useful in
    judging prompt quality and encountering edge cases. Usually in less than 10 test
    runs of a prompt you uncover a deviation, which you otherwise wouldn’t have caught
    until you started using it in production. The downside is that it can get tedious
    rating lots of responses manually, and your ratings might not represent the preferences
    of your intended audience. However, even small numbers of tests can reveal large
    differences between two prompting strategies and reveal nonobvious issues before
    reaching production.    Iterating on and testing prompts can lead to radical decreases
    in the length of the prompt and therefore the cost and latency of your system.
    If you can find another prompt that performs equally as well (or better) but uses
    a shorter prompt, you can afford to scale up your operation considerably. Often
    you’ll find in this process that many elements of a complex prompt are completely
    superfluous, or even counterproductive.    The *thumbs-up* or other manually labeled
    indicators of quality don’t have to be the only judging criteria. Human evaluation
    is generally considered to be the most accurate form of feedback. However, it
    can be tedious and costly to rate many samples manually. In many cases, as in
    math or classification use cases, it may be possible to establish *ground truth*
    (reference answers to test cases) to programmatically rate the results, allowing
    you to scale up considerably your testing and monitoring efforts. The following
    is not an exhaustive list because there are many motivations for evaluating your
    prompt programmatically:    Cost      Prompts that use a lot of tokens, or work
    only with more expensive models, might be impractical for production use.      Latency      Equally
    the more tokens there are, or the larger the model required, the longer it takes
    to complete a task, which can harm user experience.      Calls      Many AI systems
    require multiple calls in a loop to complete a task, which can seriously slow
    down the process.      Performance      Implement some form of external feedback
    system, for example a physics engine or other model for predicting real-world
    results.      Classification      Determine how often a prompt correctly labels
    given text, using another AI model or rules-based labeling.      Reasoning      Work
    out which instances the AI fails to apply logical reasoning or gets the math wrong
    versus reference cases.      Hallucinations      See how frequently you encouner
    hallucinations, as measured by invention of new terms not included in the prompt’s
    context.      Safety      Flag any scenarios where the system might return unsafe
    or undesirable results using a safety filter or detection system.      Refusals      Find
    out how often the system incorrectly refuses to fulfill a reasonable user request
    by flagging known refusal language.      Adversarial      Make the prompt robust
    against known [prompt injection](https://oreil.ly/KGAqe) attacks that can get
    the model to run undesirable prompts instead of what you programmed.      Similarity      Use
    shared words and phrases ([BLEU or ROGUE](https://oreil.ly/iEGZ9)) or vector distance
    (explained in [Chapter 5](ch05.html#vector_databases_05)) to measure similarity
    between generated and reference text.      Once you start rating which examples
    were good, you can more easily update the examples used in your prompt as a way
    to continuously make your system smarter over time. The data from this feedback
    can also feed into examples for fine-tuning, which starts to beat prompt engineering
    once you can [supply a few thousand examples](https://oreil.ly/DZ-br), as shown
    in [Figure 1-13](#figure-1-13).  ![pega 0113](assets/pega_0113.png)  ###### Figure
    1-13\. How many data points is a prompt worth?    Graduating from thumbs-up or
    thumbs-down, you can implement a 3-, 5-, or 10-point rating system to get more
    fine-grained feedback on the quality of your prompts. It’s also possible to determine
    aggregate relative performance through comparing responses side by side, rather
    than looking at responses one at a time. From this you can construct a fair across-model
    comparison using an *[Elo rating](https://oreil.ly/TlldE)*, as is popular in chess
    and used in the [Chatbot Arena](https://oreil.ly/P2IcU) by *lmsys.org*.    For
    image generation, evaluation usually takes the form of *permutation* prompting,
    where you input multiple directions or formats and generate an image for each
    combination. Images can than be scanned or later arranged in a grid to show the
    effect that different elements of the prompt can have on the final image.    Input:    [PRE30]    In
    Midjourney this would be compiled into six different prompts, one for every combination
    of the three formats (stock photo, oil painting, illustration) and two numbers
    of people (four, eight).    Input:    [PRE31]    Each prompt generates its own
    four images as usual, which makes the output a little harder to see. We have selected
    one from each prompt to upscale and then put them together in a grid, shown as
    [Figure 1-14](#figure-1-14). You’ll notice that the model doesn’t always get the
    correct number of people (generative AI models are surprisingly bad at math),
    but it has correctly inferred the general intention by adding more people to the
    photos on the right than the left.    [Figure 1-14](#figure-1-14) shows the output.  ![pega
    0114](assets/pega_0114.png)  ###### Figure 1-14\. Prompt permutations grid    With
    models that have APIs like Stable Diffusion, you can more easily manipulate the
    photos and display them in a grid format for easy scanning. You can also manipulate
    the random seed of the image to fix a style in place for maximum reproducibility.
    With image classifiers it may also be possible to programmatically rate images
    based on their safe content, or if they contain certain elements associated with
    success or failure.[PRE32]``  [PRE33]`# 5\. Divide Labor    As you build out your
    prompt, you start to get to the point where you’re asking a lot in a single call
    to the AI. When prompts get longer and more convoluted, you may find the responses
    get less deterministic, and hallucinations or anomalies increase. Even if you
    manage to arrive at a reliable prompt for your task, that task is likely just
    one of a number of interrelated tasks you need to do your job. It’s natural to
    start exploring how many other of these tasks could be done by AI and how you
    might string them together.    One of the core principles of engineering is to
    use task decomposition to break problems down into their component parts, so you
    can more easily solve each individual problem and then reaggregate the results.
    Breaking your AI work into multiple calls that are chained together can help you
    accomplish more complex tasks, as well as provide more visibility into what part
    of the chain is failing.    There are lots of factors that go into product naming,
    and an important task is naively outsourced to the AI with no visibility into
    how it’s weighing the importance of these factors (if at all). The way our current
    system works, we’re getting a list of names, but all names are displayed with
    equal importance with no further context for helping us decide. Fortunately AI
    tools are capable of self-evaluation; if we add a second step to our task, we
    can automatically check for nondesirable outputs.    Input:    [PRE34]    Output:    [PRE35]    In
    running this multiple times, it consistently rates the name “OneSize Glovewalkers”
    as the worst, providing context (if you ask) that the concept might be confusing
    in a shoe context. You may be wondering why, if the model *knows* this is a bad
    name, does it suggest it in the first place? LLMs work by predicting the next
    token in a sequence and therefore struggle to know what the overall response will
    be when finished. However, when it has all the tokens from a previous response
    to review, it can more easily predict whether this would be labeled as a good
    or bad response.    We can continue to chain multiple calls together to improve
    the results of our task. For example, we could split this into three separate
    ratings: clarity, memorability, and how well the name communicates the unique
    selling point of the product. These ratings could then be given to a human as
    additional context on the final decision, or even calculated together to select
    the final name programmatically.    The real unlock in learning to work professionally
    with AI versus just playing around with prompting is realizing that every part
    of the system can be broken down into a series of iterative steps. Even with a
    single prompt this principles applies, as simply appending `Let''s think step
    by step` to the prompt can lead to demonstrable gains in reasoning and proficiency,
    as well as provide an audit trail for quality assurance and debugging. When taking
    the time and tokens to reason, the ratings change and are more consistent with
    the scoring criteria.    Input:    [PRE36]    Output:    [PRE37]    OpenAI [calls
    this](https://oreil.ly/0MZ3-) “giving the model time to think,” and it is a key
    tenet of prompt engineering. In effect, *chain of thought* techniques like this,
    where the model is encouraged to list out its steps, are like dividing a task
    within the same prompt. Once we’ve automated product naming given a product idea,
    we can call ChatGPT again to describe each product, which in turn can be fed into
    Midjourney to generate an image of each product. Using an AI model to generate
    a prompt for an AI model is *meta prompting*, and it works because LLMs are human-level
    prompt engineers ([Zhou, 2022](https://oreil.ly/Dwszu)).    Input:    [PRE38]    Output:    [PRE39]    DALL-E
    is well-known by GPT-4, and therefore you can invoke its name within ChatGPT and
    it does a reasonable job at crafting a prompt for an image generation tool. If
    you were planning on using this prompt in production, you may consider applying
    the prompting principle of providing examples, but it does a good enough job for
    our purposes without examples.    Input:    [PRE40]    Output:    [PRE41]    The
    output of this prompt can now be plugged into image generation tools like DALL-E
    or Midjourney as a prompt, which can give you a good starting point for visualizing
    what the product might look like. Although this might not be the final design
    you go with, seeing an image is more evocative and helps people form an opinion
    faster. It’s easier cognitively to criticize or compliment an existing image than
    it is to imagine a new image from a blank page or section of text.    [Figure 1-15](#figure-1-15)
    shows the output.  ![pega 0115](assets/pega_0115.png)  ###### Figure 1-15\. OneFit
    UltraStride shoes    It’s common practice when working with AI professionally
    to chain multiple calls to AI together, and even multiple models, to accomplish
    more complex goals. Even single-prompt applications are often built dynamically,
    based on outside context queried from various databases or other calls to an AI
    model. The library [LangChain](https://www.langchain.com) has developed tooling
    for chaining multiple prompt templates and queries together, making this process
    more observable and well structured. A foundational example is progressive summarization,
    where text that is too large to fit into a context window can be split into multiple
    chunks of text, with each being summarized, before finally summarizing the summaries.
    If you talk to builders of early AI products, you’ll find they’re all under the
    hood chaining multiple prompts together, called *AI chaining*, to accomplish better
    results in the final output.    The [Reason and Act (ReAct)](https://oreil.ly/tPPW9)
    framework was one of the first popular attempts at AI agents, including the open
    source projects [BabyAGI](https://oreil.ly/TEiQx), [AgentGPT](https://oreil.ly/48lq6)
    and [Microsoft AutoGen](https://oreil.ly/KG5Xl). In effect, these agents are the
    result of chaining multiple AI calls together in order to plan, observe, act,
    and then evaluate the results of the action. Autonomous agents will be covered
    in [Chapter 6](ch06.html#autonomous_agents_06) but are still not widely used in
    production at the time of writing. This practice of self-reasoning agents is still
    early and prone to errors, but there are promising signs this approach can be
    useful in achieving complex tasks, and is likely to be part of the next stage
    in evolution for AI systems.    There is an AI battle occurring between large
    tech firms like Microsoft and Google, as well as a wide array of open source projects
    on Hugging Face, and venture-funded start-ups like OpenAI and Anthropic. As new
    models continue to proliferate, they’re diversifying in order to compete for different
    segments of the growing market. For example, Anthropic’s Claude 2 had an [100,000-token
    context window](https://oreil.ly/NQcFW), compared to GPT-4’s standard [8,192 tokens](https://oreil.ly/iZhMl).
    OpenAI soon responded with a [128,000-token window version of GPT-4](https://oreil.ly/3TTZ9),
    and Google touts a 1 million token context length with [Gemini 1.5](https://oreil.ly/cyhR4).
    For comparison, one of the Harry Potter books would be around 185,000 tokens,
    so it may become common for an entire book to fit inside a single prompt, though
    processing millions of tokens with each API call may be cost prohibitive for most
    use cases.    This book focuses on GPT-4 for text generation techniques, as well
    as Midjourney v6 and Stable Diffusion XL for image generation techniques, but
    within months these models may no longer be state of the art. This means it will
    become increasingly important to be able to select the right model for the job
    and chain multiple AI systems together. Prompt templates are rarely comparable
    when transferring to a new model, but the effect of the Five Prompting Principles
    will consistently improve any prompt you use, for any model, getting you more
    reliable results.    # Summary    In this chapter, you learned about the importance
    of prompt engineering in the context of generative AI. We defined prompt engineering
    as the process of developing effective prompts that yield desired results when
    interacting with AI models. You discovered that providing clear direction, formatting
    the output, incorporating examples, establishing an evaluation system, and dividing
    complex tasks into smaller prompts are key principles of prompt engineering. By
    applying these principles and using common prompting techniques, you can improve
    the quality and reliability of AI-generated outputs.    You also explored the
    role of prompt engineering in generating product names and images. You saw how
    specifying the desired format and providing instructive examples can greatly influence
    the AI’s output. Additionally, you learned about the concept of role-playing,
    where you can ask the AI to generate outputs as if it were a famous person like
    Steve Jobs. The chapter emphasized the need for clear direction and context to
    achieve desired outcomes when using generative AI models. Furthermore, you discovered
    the importance of evaluating the performance of AI models and the various methods
    used for measuring results, as well as the trade-offs between quality and token
    usage, cost, and latency.    In the next chapter, you will be introduced to text
    generation models. You will learn about the different types of foundation models
    and their capabilities, as well as their limitations. The chapter will also review
    the standard OpenAI offerings, as well as competitors and open source alternatives.
    By the end of the chapter, you will have a solid understanding of the history
    of text generation models and their relative strengths and weaknesses. This book
    will return to image generation prompting in Chapters [7](ch07.html#intro_image_07),
    [8](ch08.html#standard_image_08), and [9](ch09.html#advanced_image_09), so you
    should feel free to skip ahead if that is your immediate need. Get ready to dive
    deeper into the discipline of prompt engineering and expand your comfort working
    with AI.[PRE42]``'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
