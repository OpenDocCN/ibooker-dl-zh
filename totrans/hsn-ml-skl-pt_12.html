<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 10. Building Neural Networks with PyTorch"><div class="chapter" id="pytorch_chapter">
<h1><span class="label">Chapter 10. </span>Building Neural Networks with PyTorch</h1>


<p>PyTorch<a data-type="indexterm" data-primary="PyTorch" id="xi_PyTorch1048_1"/> is a powerful open source deep learning library developed by Facebook’s AI Research lab (FAIR, now called Meta AI). It is the Python successor of the Torch library, originally written in the Lua programming language. With PyTorch, you can build all sorts of neural network models and train them at scale using GPUs (or other hardware accelerators, as we will see). In many ways it is similar to NumPy, except it also supports hardware acceleration and autodiff (see <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>), and includes optimizers and ready-to-use neural net components.</p>

<p>When PyTorch<a data-type="indexterm" data-primary="artificial neural networks (ANNs)" data-secondary="deep neural networks" data-see="deep neural networks" id="id2224"/><a data-type="indexterm" data-primary="artificial neural networks (ANNs)" data-secondary="PyTorch" data-see="PyTorch" id="id2225"/><a data-type="indexterm" data-primary="PyTorch" data-secondary="benefits and governance" id="id2226"/> was released in 2016, Google’s TensorFlow<a data-type="indexterm" data-primary="TensorFlow" id="id2227"/> library was by far the most popular: it was fast, it scaled well, and it could be deployed across many platforms. But its programming model was complex and static, making it difficult to use and debug. In contrast, PyTorch was designed from the ground up to provide a more flexible, Pythonic approach to building neural networks. In particular, as you will see, it uses dynamic computation graphs (also known as define-by-run), making it intuitive and easy to debug. PyTorch is also beautifully coded and documented, and focuses on its core task: making it easy to build and train high-performance neural networks. Last but not least, it leans strongly into the open source culture and benefits from an enthusiastic and dedicated community, and a rich ecosystem. In September 2022, PyTorch’s governance was even transferred to the PyTorch Foundation, a subsidiary of the Linux Foundation. All these qualities resonated well with researchers: PyTorch quickly became the most used framework in academia, and once a majority of deep learning papers were based on PyTorch, a large part of the industry was gradually converted as well.⁠<sup><a data-type="noteref" id="id2228-marker" href="ch10.html#id2228">1</a></sup></p>

<p>In this chapter, you will learn how to train, evaluate, fine-tune, optimize, and save neural nets with PyTorch. We will start by getting familiar with the core building blocks of PyTorch, namely tensors and autograd, next we will test the waters by building and training a simple linear regression model, and then we will upgrade this model to a multilayer neural network, first for regression, then for classification. Along the way, we will see how to build custom neural networks with multiple inputs or outputs. Finally, we will discuss how to automatically fine-tune hyperparameters using the Optuna library, and how to optimize and export your models. Hop on board, we’re diving into deep learning!</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Colab runtimes come with a recent version of PyTorch preinstalled. However, if you prefer to install it on your own machine, please see the installation instructions at <a href="https://homl.info/install-p" class="bare"><em class="hyperlink">https://homl.info/install-p</em></a>: this involves installing Python, many libraries, and a GPU driver (if you have one).</p>
</div>






<section data-type="sect1" data-pdf-bookmark="PyTorch Fundamentals"><div class="sect1" id="id158">
<h1>PyTorch Fundamentals</h1>

<p>The<a data-type="indexterm" data-primary="PyTorch" data-secondary="tensors" id="xi_PyTorchtensors10134_1"/><a data-type="indexterm" data-primary="tensors" id="xi_tensors10134_1"/> core data structure of PyTorch is the <em>tensor</em>.⁠<sup><a data-type="noteref" id="id2229-marker" href="ch10.html#id2229">2</a></sup> It’s a multidimensional array with a shape and a data type, used for numerical computations. Isn’t that exactly like a NumPy array<a data-type="indexterm" data-primary="NumPy arrays" id="xi_NumPyarrays1013384_1"/>? Well, yes, it is! But a tensor also has two extra features: it can live on a GPU (or other hardware accelerators, as we will see), and it supports auto-differentiation. Every neural network we will build from now on will input and output tensors (much like Scikit-Learn models input and output NumPy arrays). So let’s start by looking at how to create and manipulate tensors.</p>








<section data-type="sect2" data-pdf-bookmark="PyTorch Tensors"><div class="sect2" id="id159">
<h2>PyTorch Tensors</h2>

<p>First, let’s import the PyTorch library:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">import</code> <code class="nn">torch</code><code class="w"/></pre>

<p>Next you can create a PyTorch tensor much like you would create a NumPy array. For example, let’s create a 2 × 3 array:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">([[</code><code class="mf">1.0</code><code class="p">,</code> <code class="mf">4.0</code><code class="p">,</code> <code class="mf">7.0</code><code class="p">],</code> <code class="p">[</code><code class="mf">2.0</code><code class="p">,</code> <code class="mf">3.0</code><code class="p">,</code> <code class="mf">6.0</code><code class="p">]])</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="w"/>
<code class="go">tensor([[1., 4., 7.],</code>
<code class="go">        [2., 3., 6.]])</code></pre>

<p class="pagebreak-before">Just like a NumPy array, a tensor can contain floats<a data-type="indexterm" data-primary="floats" data-seealso="mixed precision and quantization" id="id2230"/>, integers, booleans, or complex numbers—just one data type per tensor. If you initialize a tensor with values of different types, then the most general one will be selected (i.e., complex &gt; float &gt; integer &gt; bool). You can also select the data type explicitly when creating the tensor, for example <code translate="no">dtype=torch.float16</code> for 16-bit floats<a data-type="indexterm" data-primary="floats" data-secondary="16-bit" id="id2231"/><a data-type="indexterm" data-primary="16-bit floats" data-primary-sortas="sixteen-bit floats" id="id2232"/><a data-type="indexterm" data-primary="fp16 (float16) data type" data-primary-sortas="fpb" id="id2233"/>. Note that tensors of strings or objects are not supported.</p>

<p>You can get a tensor’s shape and data type like this:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="o">.</code><code class="n">shape</code><code class="w"/>
<code class="go">torch.Size([2, 3])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="o">.</code><code class="n">dtype</code><code class="w"/>
<code class="go">torch.float32</code></pre>

<p>Indexing works just like for NumPy arrays:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">]</code><code class="w"/>
<code class="go">tensor(4.)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">]</code><code class="w"/>
<code class="go">tensor([4., 3.])</code></pre>

<p>You can also run all sorts of computations on tensors, and the API is conveniently similar to NumPy’s: for example, there’s <code translate="no">torch.abs()</code>, <code translate="no">torch.cos()</code>, <code translate="no">torch.exp()</code>, <code translate="no">torch.max()</code>, <code translate="no">torch.mean()</code>, <code translate="no">torch.sqrt()</code>, and so on. PyTorch tensors also have methods for most of these operations, so you can write <code translate="no">X.exp()</code> instead of <code translate="no">torch.exp(X)</code>. Let’s try a few operations:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="mi">10</code> <code class="o">*</code> <code class="p">(</code><code class="n">X</code> <code class="o">+</code> <code class="mf">1.0</code><code class="p">)</code>  <code class="c1"># itemwise addition and multiplication</code><code class="w"/>
<code class="go">tensor([[20., 50., 80.],</code>
<code class="go">        [30., 40., 70.]])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="o">.</code><code class="n">exp</code><code class="p">()</code>  <code class="c1"># itemwise exponential</code><code class="w"/>
<code class="go">tensor([[   2.7183,   54.5981, 1096.6332],</code>
<code class="go">        [   7.3891,   20.0855,  403.4288]])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="o">.</code><code class="n">mean</code><code class="p">()</code><code class="w"/>
<code class="go">tensor(3.8333)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="o">.</code><code class="n">max</code><code class="p">(</code><code class="n">dim</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>  <code class="c1"># max values along dimension 0 (i.e., max value per column)</code><code class="w"/>
<code class="go">torch.return_types.max(values=tensor([2., 4., 7.]), indices=tensor([1, 0, 0]))</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code> <code class="o">@</code> <code class="n">X</code><code class="o">.</code><code class="n">T</code>  <code class="c1"># matrix transpose and matrix multiplication</code><code class="w"/>
<code class="go">tensor([[66., 56.],</code>
<code class="go">        [56., 49.]])</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>PyTorch prefers the argument name <code translate="no">dim</code> in operations such as <code translate="no">max()</code>, but it also supports <code translate="no">axis</code> (as in NumPy or Pandas).</p>
</div>

<p>You can also convert a tensor to a NumPy array using the <code translate="no">numpy()</code> method, and create a tensor from a NumPy array:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="o">.</code><code class="n">numpy</code><code class="p">()</code><code class="w"/>
<code class="go">array([[1., 4., 7.],</code>
<code class="go">       [2., 3., 6.]], dtype=float32)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">([[</code><code class="mf">1.</code><code class="p">,</code> <code class="mf">4.</code><code class="p">,</code> <code class="mf">7.</code><code class="p">],</code> <code class="p">[</code><code class="mf">2.</code><code class="p">,</code> <code class="mf">3.</code><code class="p">,</code> <code class="mf">6.</code><code class="p">]]))</code><code class="w"/>
<code class="go">tensor([[1., 4., 7.],</code>
<code class="go">        [2., 3., 6.]], dtype=torch.float64)</code></pre>

<p>Notice that the default precision for floats is 32 bits in PyTorch, whereas it’s 64 bits in NumPy. It’s generally better to use 32 bits<a data-type="indexterm" data-primary="floats" data-secondary="32-bit" id="id2234"/><a data-type="indexterm" data-primary="floats" data-secondary="64-bit" id="id2235"/><a data-type="indexterm" data-primary="32-bit floats" data-primary-sortas="thirty-two bit floats" id="id2236"/><a data-type="indexterm" data-primary="fp32 (float32) data type" data-primary-sortas="fpc" id="id2237"/><a data-type="indexterm" data-primary="fp64 (float64) data type" data-primary-sortas="fpd" id="id2238"/><a data-type="indexterm" data-primary="64-bit floats" data-primary-sortas="sixty-four bit floats" id="id2239"/> in deep learning because this takes half the RAM and speeds up computations, and neural nets do not actually need the extra precision offered by 64-bit floats. So when calling the <code translate="no">torch.tensor()</code> function to convert a NumPy array to a tensor, it’s best to specify <code translate="no">dtype=torch.float32</code>. Alternatively, you can use <code translate="no">torch.FloatTensor()</code><a data-type="indexterm" data-primary="torch" data-secondary="FloatTensor" id="id2240"/> which automatically converts the array to 32 bits:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">torch</code><code class="o">.</code><code class="n">FloatTensor</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">([[</code><code class="mf">1.</code><code class="p">,</code> <code class="mf">4.</code><code class="p">,</code> <code class="mf">7.</code><code class="p">],</code> <code class="p">[</code><code class="mf">2.</code><code class="p">,</code> <code class="mf">3.</code><code class="p">,</code> <code class="mi">6</code><code class="p">]]))</code><code class="w"/>
<code class="go">tensor([[1., 4., 7.],</code>
<code class="go">        [2., 3., 6.]])</code></pre>
<div data-type="tip"><h6>Tip</h6>
<p>Both <code translate="no">torch.tensor()</code><a data-type="indexterm" data-primary="torch" data-secondary="tensor()" id="id2241"/> and <code translate="no">torch.FloatTensor()</code> make a copy of the given NumPy array. If you prefer, you can use <code>torch.​from_numpy()</code><a data-type="indexterm" data-primary="torch" data-secondary="from_numpy()" id="id2242"/> which creates a tensor on the CPU that just uses the NumPy array’s data directly, without copying it. But beware: modifying the NumPy array will also modify the tensor, and vice versa.<a data-type="indexterm" data-startref="xi_NumPyarrays1013384_1" id="id2243"/></p>
</div>

<p>You can also modify a tensor in place using indexing and slicing, as with a NumPy array:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">]</code> <code class="o">=</code> <code class="o">-</code><code class="mi">99</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="w"/>
<code class="go">tensor([[  1., -99.,   7.],</code>
<code class="go">        [  2., -99.,   6.]])</code></pre>

<p>PyTorch’s API provides many in-place operations, such as <code translate="no">abs_()</code>, <code translate="no">sqrt_()</code>, and <code translate="no">zero_()</code>, which modify the input tensor directly: they can sometimes save some memory and speed up your models. For example, the <code translate="no">relu_()</code><a data-type="indexterm" data-primary="torch" data-secondary="relu_()" id="id2244"/> method applies the ReLU activation function in place by replacing all negative values with 0s:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="o">.</code><code class="n">relu_</code><code class="p">()</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X</code><code class="w"/>
<code class="go">tensor([[1., 0., 7.],</code>
<code class="go">        [2., 0., 6.]])</code></pre>
<div data-type="tip"><h6>Tip</h6>
<p>PyTorch’s in-place operations are easy to spot at a glance because their name always ends with an underscore. With very few exceptions (e.g., <code translate="no">zero_()</code>), removing the underscore gives you the regular operation (e.g., <code translate="no">abs_()</code> is in place, <code translate="no">abs()</code> is not).</p>
</div>

<p>We will cover many more operations as we go, but now let’s look at how to use hardware acceleration to make computations much faster.<a data-type="indexterm" data-startref="xi_PyTorchtensors10134_1" id="id2245"/><a data-type="indexterm" data-startref="xi_tensors10134_1" id="id2246"/></p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Hardware Acceleration"><div class="sect2" id="id160">
<h2>Hardware Acceleration</h2>

<p>PyTorch<a data-type="indexterm" data-primary="PyTorch" data-secondary="hardware acceleration" id="xi_PyTorchhardwareacceleration101258_1"/> tensors can be copied easily to the GPU<a data-type="indexterm" data-primary="graphical processing units (GPUs)" data-secondary="tensors" id="xi_graphicalprocessingunitsGPUstensors1012548_1"/><a data-type="indexterm" data-primary="graphical processing units (GPUs)" id="id2247"/><a data-type="indexterm" data-primary="graphical processing units (GPUs)" data-secondary="hardware acceleration" id="id2248"/>, assuming your machine has a compatible GPU, and you have the required libraries installed. On Colab, all you need to do is ensure that you are using a GPU runtime: for this, go to the Runtime menu and select “Change runtime type”, then make sure a GPU is selected (e.g., an Nvidia T4 GPU). The GPU runtime will automatically have the appropriate PyTorch library installed—compiled with GPU support—as well as the appropriate GPU drivers and related libraries<a data-type="indexterm" data-primary="Nvidia, GPUs and" id="xi_Nvidiatensorsand10125517_1"/> (e.g., Nvidia’s CUDA and cuDNN libraries).⁠<sup><a data-type="noteref" id="id2249-marker" href="ch10.html#id2249">3</a></sup> If you prefer to run the code on your own machine, you will need to ensure that you have all the drivers and libraries required. Please follow the instructions at <a href="https://homl.info/install-p" class="bare"><em class="hyperlink">https://homl.info/install-p</em></a>.</p>

<p>PyTorch has excellent support for Nvidia GPUs, as well as several other hardware accelerators:</p>

<ul>
<li>
<p>Apple’s <em>Metal Performance Shaders</em> (MPS)<a data-type="indexterm" data-primary="Metal Performance Shaders (MPS)" id="id2250"/><a data-type="indexterm" data-primary="MPS (Metal Performance Shaders)" id="id2251"/> to accelerate computations on Apple silicon such as the M1, M2, and later chips, as well as some Intel Macs with a compatible GPU.</p>
</li>
<li>
<p>AMD Instinct accelerators<a data-type="indexterm" data-primary="AMD GPUs" id="id2252"/> and AMD Radeon GPUs, through the ROCm software stack, or via DirectML on Windows.</p>
</li>
<li>
<p>Intel GPUs and CPUs<a data-type="indexterm" data-primary="Intel GPUs and CPUs" id="id2253"/> on Linux and Windows via Intel’s oneAPI.</p>
</li>
<li>
<p>Google TPUs<a data-type="indexterm" data-primary="Google TPUs" id="id2254"/> via the <code translate="no">torch_xla</code> library.</p>
</li>
</ul>

<p>Let’s check whether PyTorch can access an Nvidia GPU or Apple’s MPS, otherwise let’s fall back to the CPU:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">if</code> <code class="n">torch</code><code class="o">.</code><code class="n">cuda</code><code class="o">.</code><code class="n">is_available</code><code class="p">():</code>
    <code class="n">device</code> <code class="o">=</code> <code class="s2">"cuda"</code>
<code class="k">elif</code> <code class="n">torch</code><code class="o">.</code><code class="n">backends</code><code class="o">.</code><code class="n">mps</code><code class="o">.</code><code class="n">is_available</code><code class="p">():</code>
    <code class="n">device</code> <code class="o">=</code> <code class="s2">"mps"</code>
<code class="k">else</code><code class="p">:</code>
    <code class="n">device</code> <code class="o">=</code> <code class="s2">"cpu"</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Deep learning generally requires a <em>lot</em> of compute power, especially once we start diving into computer vision and natural language processing, in the following chapters. You will need a reasonably powerful machine, but most importantly you will need a hardware accelerator<a data-type="indexterm" data-primary="hardware acceleration" id="id2255"/> (or several). If you don’t have one, you can try using Colab or Kaggle; they offer runtimes with free GPUs. Or consider using other cloud services. Otherwise, prepare to be very, very patient.</p>
</div>

<p>On a Colab GPU runtime, <code translate="no">device</code> will be equal to <code translate="no">"cuda"</code>. Now let’s create a tensor on that GPU. To do that, one option is to create the tensor on the CPU, then copy it to the GPU using the <code translate="no">to()</code> method:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">M</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">([[</code><code class="mf">1.</code><code class="p">,</code> <code class="mf">2.</code><code class="p">,</code> <code class="mf">3.</code><code class="p">],</code> <code class="p">[</code><code class="mf">4.</code><code class="p">,</code> <code class="mf">5.</code><code class="p">,</code> <code class="mf">6.</code><code class="p">]])</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">M</code> <code class="o">=</code> <code class="n">M</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code><code class="w"/></pre>
<div data-type="tip"><h6>Tip</h6>
<p>The <code translate="no">cpu()</code><a data-type="indexterm" data-primary="torch" data-secondary="cpu()" id="id2256"/> and <code translate="no">cuda()</code><a data-type="indexterm" data-primary="torch" data-secondary="cuda()" id="id2257"/> methods are short for <code translate="no">to("cpu")</code> and <code translate="no">to("cuda")</code>, respectively.</p>
</div>

<p>You can always tell which device a tensor lives on by looking at its <code translate="no">device</code> attribute:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">M</code><code class="o">.</code><code class="n">device</code><code class="w"/>
<code class="go">device(type='cuda', index=0)</code>
<code class="go">----</code></pre>

<p>Alternatively, we can create the tensor directly on the GPU using the <code translate="no">device</code> argument:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">M</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">([[</code><code class="mf">1.</code><code class="p">,</code> <code class="mf">2.</code><code class="p">,</code> <code class="mf">3.</code><code class="p">],</code> <code class="p">[</code><code class="mf">4.</code><code class="p">,</code> <code class="mf">5.</code><code class="p">,</code> <code class="mf">6.</code><code class="p">]],</code> <code class="n">device</code><code class="o">=</code><code class="n">device</code><code class="p">)</code><code class="w"/></pre>
<div data-type="tip"><h6>Tip</h6>
<p>If you have multiple Nvidia GPUs, you can refer to the desired GPU by appending the GPU index: <code translate="no">"cuda:0"</code> (or just <code translate="no">"cuda"</code>) for GPU #0, <code translate="no">"cuda:1"</code> for GPU #1, and so on.</p>
</div>

<p>Once the tensor is on the GPU, we can run operations on it normally, and they will all take place on the GPU:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">R</code> <code class="o">=</code> <code class="n">M</code> <code class="o">@</code> <code class="n">M</code><code class="o">.</code><code class="n">T</code>  <code class="c1"># run some operations on the GPU</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">R</code><code class="w"/>
<code class="go">tensor([[14., 32.],</code>
<code class="go">        [32., 77.]], device='cuda:0')</code></pre>

<p class="pagebreak-before">Note that the result <code translate="no">R</code> also lives on the GPU. This means we can perform multiple operations on the GPU without having to transfer data back and forth between the CPU and the GPU. This is crucial in deep learning because data transfer between devices can often become a performance bottleneck.</p>

<p>How much does a GPU accelerate the computations? Well it depends on the GPU, of course: the more expensive ones are dozens of times faster than the cheap ones. But speed alone is not the only important factor: the data throughput is also crucial, as we just saw. If your model is compute heavy (e.g., a very deep neural net), the GPU’s speed and amount of RAM will typically matter most, but if it is a shallower model, then pumping the training data into the GPU might become the bottleneck. Let’s run a little test to compare the speed of a matrix multiplication running on the CPU versus the GPU:⁠<sup><a data-type="noteref" id="id2258-marker" href="ch10.html#id2258">4</a></sup></p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">M</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">rand</code><code class="p">((</code><code class="mi">1000</code><code class="p">,</code> <code class="mi">1000</code><code class="p">))</code>  <code class="c1"># on the CPU</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="o">%</code><code class="n">timeit</code> <code class="n">M</code> <code class="o">@</code> <code class="n">M</code><code class="o">.</code><code class="n">T</code><code class="w"/>
<code class="go">16.1 ms ± 2.17 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">M</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">rand</code><code class="p">((</code><code class="mi">1000</code><code class="p">,</code> <code class="mi">1000</code><code class="p">),</code> <code class="n">device</code><code class="o">=</code><code class="s2">"cuda"</code><code class="p">)</code>  <code class="c1"># on the GPU</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="o">%</code><code class="n">timeit</code> <code class="n">M</code> <code class="o">@</code> <code class="n">M</code><code class="o">.</code><code class="n">T</code><code class="w"/>
<code class="go">549 µs ± 3.99 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)</code></pre>

<p>Wow! The GPU gave us a 29× speed boost! And that’s just using the free Nvidia T4 GPU on Colab; imagine the speedup we could get using a more powerful GPU. Now try playing around with the matrix size: you will notice that the speedup is much less impressive on smaller matrices (e.g., it’s just 2× for 100 × 100 matrices). That’s because GPUs work by breaking large operations into smaller operations and running them in parallel across thousands of cores. If the task is small, it cannot be broken up into that many pieces, and the performance gain is therefore smaller. In fact, when running many tiny tasks, it can sometimes be faster to just run the operations on the CPU<a data-type="indexterm" data-primary="CPUs, and tensors" id="id2259"/>.<a data-type="indexterm" data-startref="xi_Nvidiatensorsand10125517_1" id="id2260"/></p>

<p>All right, now that we’ve seen what tensors are and how to use them on the CPU or the GPU, let’s look at PyTorch’s auto-differentiation feature.<a data-type="indexterm" data-startref="xi_graphicalprocessingunitsGPUstensors1012548_1" id="id2261"/><a data-type="indexterm" data-startref="xi_PyTorchhardwareacceleration101258_1" id="id2262"/></p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Autograd"><div class="sect2" id="id161">
<h2>Autograd</h2>

<p>PyTorch<a data-type="indexterm" data-primary="autodiff (automatic differentiation)" data-secondary="autograd (automatic gradients)" id="xi_autodiffautomaticdifferentiationautogradautomaticgradients102038_1"/><a data-type="indexterm" data-primary="autograd (automatic gradients)" id="xi_autogradautomaticgradients102038_1"/><a data-type="indexterm" data-primary="PyTorch" data-secondary="autograd" id="xi_PyTorchautograd102038_1"/><a data-type="indexterm" data-primary="tensors" data-secondary="and autograd" data-secondary-sortas="autograd" id="xi_tensorsandautograd102038_1"/> comes with an efficient implementation of reverse-mode auto-differentiation (introduced in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a> and detailed in <a data-type="xref" href="app01.html#autodiff_appendix">Appendix A</a>), called <em>autograd</em>, which stands for automatic gradients. It is quite easy to use. For example, consider a simple function, f(<em>x</em>) = <em>x</em><sup>2</sup>. Differential calculus tells us that the derivative 
<span class="keep-together">of this</span> function is <em>f’</em>(<em>x</em>) = 2<em>x</em>. If we evaluate f(5) and f'(5), we get 25 and 10, respectively. Let’s see if PyTorch agrees:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">x</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="mf">5.0</code><code class="p">,</code> <code class="n">requires_grad</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">f</code> <code class="o">=</code> <code class="n">x</code> <code class="o">**</code> <code class="mi">2</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">f</code><code class="w"/>
<code class="go">tensor(25., grad_fn=&lt;PowBackward0&gt;)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">f</code><code class="o">.</code><code class="n">backward</code><code class="p">()</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">x</code><code class="o">.</code><code class="n">grad</code><code class="w"/>
<code class="go">tensor(10.)</code></pre>

<p>Great, we got the correct results: <code translate="no">f</code> is 25, and <code translate="no">x.grad</code> is 10! Note that the <code translate="no">backward()</code> function automatically computed the gradient f'(<em>x</em>) at the same point <em>x</em> = 5.0. Let’s go through this code line by line:</p>

<ul>
<li>
<p>First, we created a tensor <code translate="no">x</code>, equal to 5.0, and we told PyTorch that it’s a variable (not a constant) by specifying <code translate="no">requires_grad=True</code>. Knowing this, PyTorch will automatically keep track of all operations involving <code translate="no">x</code>: this is needed because PyTorch must capture the computation graph in order to run backprop on it and obtain the derivative of <code translate="no">f</code> with regard to <code translate="no">x</code>. In this computation graph, the tensor <code translate="no">x</code> is a <em>leaf node</em>.<a data-type="indexterm" data-primary="leaf node" data-secondary="in a PyTorch graph" id="id2263"/></p>
</li>
<li>
<p>Then we compute <code translate="no">f = x ** 2</code>. The result is a tensor equal to 25.0, the square of 5.0. But wait, there’s more to it: <code translate="no">f</code> also carries a <code translate="no">grad_fn</code> attribute which represents the operation that created this tensor (<code translate="no">**</code>, power, hence the name <code translate="no">PowBackward0</code>), and which tells PyTorch how to backpropagate the gradients through this particular operation. This <code translate="no">grad_fn</code> attribute is how PyTorch keeps track of the computation graph.</p>
</li>
<li>
<p>Next, we call <code translate="no">f.backward()</code>: <a data-type="indexterm" data-primary="torch" data-secondary="tensor.backward()" id="id2264"/>this backpropagates the gradients through the computation graph, starting with <code translate="no">f</code>, and all the way back to the leaf nodes (just <code translate="no">x</code> in this case).</p>
</li>
<li>
<p>Lastly, we can just read the <code translate="no">x</code> tensor’s <code translate="no">grad</code> attribute, which was computed during backprop: this gives us the derivative of <code translate="no">f</code> with regard to <code translate="no">x</code>. Ta-da!</p>
</li>
</ul>

<p>PyTorch creates a new computation graph on the fly during each forward pass, as the operations are executed. This allows PyTorch to support very dynamic models containing loops and conditionals.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>The way PyTorch accumulates gradients<a data-type="indexterm" data-primary="gradients" data-secondary="in a PyTorch graph" data-secondary-sortas="pytorch" id="id2265"/> in each variable’s <code translate="no">grad</code> attribute can be surprising at first, especially coming from TensorFlow<a data-type="indexterm" data-primary="TensorFlow" id="id2266"/> or JAX<a data-type="indexterm" data-primary="JAX" id="id2267"/>. In these frameworks, computing the gradients of <code translate="no">f</code> with regard to <code translate="no">x</code> just returns the gradients, without affecting <code translate="no">x</code>. In PyTorch, if you call <code translate="no">backward()</code> on a tensor, it will accumulate the gradients in every variable that was used to compute it. So if you call <code translate="no">backward()</code> on two tensors <code translate="no">t1</code> and <code translate="no">t2</code> that both used the same variable <code translate="no">v</code>, then <code translate="no">v.grad</code> will be the sum of their gradients.</p>
</div>

<p>After computing the <a data-type="indexterm" data-primary="gradient descent (GD)" data-secondary="PyTorch for" id="id2268"/>gradients, you generally want to perform a gradient descent step by subtracting a fraction of the gradients from the model variables (at least when training a neural network). In our simple example, running gradient descent will gradually push <code translate="no">x</code> toward 0, since that’s the value that minimizes f(<em>x</em>) = <em>x</em><sup>2</sup>. To do a gradient descent step, you must temporarily disable gradient tracking since you don’t want to track the gradient descent step itself in the computation graph (in fact, PyTorch would raise an exception if you tried to run an in-place operation on a tracked variable). This can be done by placing the gradient descent step inside a <code translate="no">torch.no_grad()</code><a data-type="indexterm" data-primary="torch" data-secondary="no_grad()" id="id2269"/> context, like this:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.1</code>
<code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code>
    <code class="n">x</code> <code class="o">-=</code> <code class="n">learning_rate</code> <code class="o">*</code> <code class="n">x</code><code class="o">.</code><code class="n">grad</code>  <code class="c1"># gradient descent step</code></pre>

<p>The variable <code translate="no">x</code> gets decremented by 0.1 * 10.0 = 1.0, down from 5.0 to 4.0.</p>

<p>Another way to avoid gradient computation is to use the variable’s <code translate="no">detach()</code><a data-type="indexterm" data-primary="torch" data-secondary="tensor.detach()" id="id2270"/> method: this creates a new tensor detached from the computation graph, with <code translate="no">requires_grad=False</code>, but still pointing to the same data in memory. You can then update this detached tensor:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">x_detached</code> <code class="o">=</code> <code class="n">x</code><code class="o">.</code><code class="n">detach</code><code class="p">()</code>
<code class="n">x_detached</code> <code class="o">-=</code> <code class="n">learning_rate</code> <code class="o">*</code> <code class="n">x</code><code class="o">.</code><code class="n">grad</code></pre>

<p>Since <code translate="no">x_detached</code> and <code translate="no">x</code> share the same memory, modifying <code translate="no">x_detached</code> also modifies <code translate="no">x</code>.</p>

<p>The <code translate="no">detach()</code> method can be handy when you need to run some computation on a tensor without affecting the gradients (e.g., for evaluation or logging), or when you need fine-grained control over which operations should contribute to gradient computation. Using <code translate="no">no_grad()</code> is generally preferred when performing inference or doing a gradient descent step, as it provides a convenient context-wide method to disable gradient tracking.</p>

<p>Lastly, before you repeat the whole process (forward pass + backward pass + gradient descent step), it’s essential to zero out the gradients<a data-type="indexterm" data-primary="gradients" data-secondary="in PyTorch" data-secondary-sortas="pytorch" id="id2271"/> of every model parameter (you don’t need a <code translate="no">no_grad()</code> context for this since the gradient tensor has <code translate="no">requires_grad=False</code>):</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">x</code><code class="o">.</code><code class="n">grad</code><code class="o">.</code><code class="n">zero_</code><code class="p">()</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>If you forget to zero out the gradients at each training iteration, the <code translate="no">backward()</code><a data-type="indexterm" data-primary="torch" data-secondary="tensor.backward()" id="id2272"/> method will just accumulate them, causing incorrect gradient descent updates. Since there won’t be any explicit error, just low performance (and perhaps infinite or NaN values), this issue may be hard to debug.</p>
</div>

<p>Putting everything together, the whole training loop looks like this:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.1</code>
<code class="n">x</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="mf">5.0</code><code class="p">,</code> <code class="n">requires_grad</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="k">for</code> <code class="n">iteration</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">100</code><code class="p">):</code>
    <code class="n">f</code> <code class="o">=</code> <code class="n">x</code> <code class="o">**</code> <code class="mi">2</code>  <code class="c1"># forward pass</code>
    <code class="n">f</code><code class="o">.</code><code class="n">backward</code><code class="p">()</code>  <code class="c1"># backward pass</code>
    <code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code>
        <code class="n">x</code> <code class="o">-=</code> <code class="n">learning_rate</code> <code class="o">*</code> <code class="n">x</code><code class="o">.</code><code class="n">grad</code>  <code class="c1"># gradient descent step</code>

    <code class="n">x</code><code class="o">.</code><code class="n">grad</code><code class="o">.</code><code class="n">zero_</code><code class="p">()</code>  <code class="c1"># reset the gradients</code></pre>

<p>If you want to use in-place operations to save memory and speed up your models a bit by avoiding unnecessary copy operations, you have to be careful: in-place operations don’t always play nicely with autograd. Firstly, as we saw earlier, you cannot apply an in-place operation to a leaf node<a data-type="indexterm" data-primary="leaf node" data-secondary="in PyTorch" id="id2273"/> (i.e., a tensor with <code translate="no">requires_grad=True</code>), as PyTorch wouldn’t know where to store the computation graph. For example <code translate="no">x.cos_()</code> or <code translate="no">x += 1</code> would cause a <code translate="no">RuntimeError</code>. Secondly, consider the following code, which computes z(<em>t</em>) = exp(<em>t</em>) + 1 at <em>t</em> = 2 and then tries to compute the gradients:</p>
<pre data-type="programlisting" data-code-language="python">
<code class="n">t</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="mf">2.0</code><code class="p">,</code> <code class="n">requires_grad</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">z</code> <code class="o">=</code> <code class="n">t</code><code class="o">.</code><code class="n">exp</code><code class="p">(</code><code class="p">)</code>  <code class="c1"># this is an intermediate result</code>
<code class="n">z</code> <code class="o">+</code><code class="o">=</code> <code class="mi">1</code>  <code class="c1"># this is an in-place operation</code>
<code class="n">z</code><code class="o">.</code><code class="n">backward</code><code class="p">(</code><code class="p">)</code>  <code class="c1"># </code><img src="assets/warning_26a0-fe0f.png" width="160" height="160"/><code class="c1"> RuntimeError!</code>
</pre>

<p>Oh no! Although <code translate="no">z</code> is computed correctly, the last line causes a <code translate="no">RuntimeError</code>, complaining that “one of the variables needed for gradient computation has been modified by an in-place operation”. Indeed, the intermediate result <code translate="no">z = t.exp()</code> was lost when we ran the in-place operation <code translate="no">z += 1</code>, so when the backward pass reached the exponential operation, the gradients could not be computed. A simple fix is to replace <code translate="no">z += 1</code> with <code translate="no">z = z + 1</code>. It looks similar, but it’s no longer an in-place operation: a new tensor is created and assigned to the same variable, but the original tensor is unchanged and recorded in the computation graph of the final tensor.</p>

<p>Surprisingly, if you replace <code translate="no">exp()</code> with <code translate="no">cos()</code> in the previous code example, the gradients will be computed correctly: no error! Why is that? Well, the outcome depends on the way each operation is implemented:</p>

<ul>
<li>
<p>Some operations—such as <code translate="no">exp()</code>, <code translate="no">relu()</code>, <code translate="no">rsqrt()</code>, <code translate="no">sigmoid()</code>, <code translate="no">sqrt()</code>, <code translate="no">tan()</code>, and <code translate="no">tanh()</code>—save their outputs in the computation graph during the forward pass, then use these outputs to compute the gradients during the backward pass.⁠<sup><a data-type="noteref" id="id2274-marker" href="ch10.html#id2274">5</a></sup> This means that you must not modify such an operation’s output in place, or you will get an error during the backward pass (as we just saw).</p>
</li>
<li>
<p>Other operations—such as <code translate="no">abs()</code>, <code translate="no">cos()</code>, <code translate="no">log()</code>, <code translate="no">sin()</code>, <code translate="no">square()</code>, and <code translate="no">var()</code>—save their inputs instead of their output.⁠<sup><a data-type="noteref" id="id2275-marker" href="ch10.html#id2275">6</a></sup> Such an operation doesn’t care if you modify its output in place, but you must not modify its inputs in place before the backward pass (e.g., to compute something else based on the same inputs).</p>
</li>
<li>
<p>Some operations—such as <code translate="no">max()</code>, <code translate="no">min()</code>, <code translate="no">norm()</code>, <code translate="no">prod()</code>, <code translate="no">sgn()</code>, and <code translate="no">std()</code>—save both the inputs and the outputs, so you must not modify either of them in place before the backward pass.</p>
</li>
<li>
<p>Lastly, a few operations—such as <code translate="no">ceil()</code>, <code translate="no">floor()</code>, <code translate="no">mean()</code>, <code translate="no">round()</code>, and <code translate="no">sum()</code>—save neither their inputs nor their outputs.⁠<sup><a data-type="noteref" id="id2276-marker" href="ch10.html#id2276">7</a></sup> You can safely modify them in place.</p>
</li>
</ul>
<div data-type="tip"><h6>Tip</h6>
<p>Implement your models first without any in-place operations, then if you need to save some memory or speed up your model a bit, you can try converting some of the most costly operations to their in-place counterparts. Just make sure that your model still outputs the same result for a given input, and also make sure you don’t modify in place a tensor needed for backprop (you will get a <code translate="no">RuntimeError</code> in this case).</p>
</div>

<p>OK, let’s step back a bit. We’ve discussed all the fundamentals of PyTorch: how to create tensors and use them to perform all sorts of computations, how to accelerate the computations with a GPU, and how to use autograd to compute gradients for gradient descent. Great! Now let’s apply what we’ve learned so far by building and training a simple linear regression model with PyTorch.<a data-type="indexterm" data-startref="xi_autodiffautomaticdifferentiationautogradautomaticgradients102038_1" id="id2277"/><a data-type="indexterm" data-startref="xi_PyTorchautograd102038_1" id="id2278"/><a data-type="indexterm" data-startref="xi_tensorsandautograd102038_1" id="id2279"/></p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Implementing Linear Regression"><div class="sect1" id="id405">
<h1>Implementing Linear Regression</h1>

<p>We<a data-type="indexterm" data-primary="linear regression" data-secondary="PyTorch for" id="xi_linearregressionPyTorchfor102983_1"/><a data-type="indexterm" data-primary="PyTorch" data-secondary="linear regression" id="xi_PyTorchlinearregression102983_1"/> will start by implementing linear regression using tensors and autograd directly, then we will simplify the code using PyTorch’s high-level API, and also add GPU support.</p>








<section data-type="sect2" data-pdf-bookmark="Linear Regression Using Tensors and Autograd"><div class="sect2" id="id162">
<h2>Linear Regression Using Tensors and Autograd</h2>

<p>Let’s<a data-type="indexterm" data-primary="tensors" data-secondary="linear regression with" id="xi_tensorslinearregressionwith103016_1"/> tackle the same <a data-type="indexterm" data-primary="California Housing Prices dataset" id="xi_CaliforniaHousingPricesdataset1030123_1"/><a data-type="indexterm" data-primary="housing dataset" id="xi_housingdataset1030123_1"/>California housing dataset as in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>. I will assume you have already downloaded it using <code translate="no">sklearn.datasets.fetch_california_housing()</code>, and you have split it into a training set (<code translate="no">X_train</code> and <code translate="no">y_train</code>), a 
<span class="keep-together">validation</span> set (<code translate="no">X_valid</code> and <code translate="no">y_valid</code>), and a test set (<code translate="no">X_test</code> and <code translate="no">y_test</code>), using <code translate="no">sklearn.model_selection.train_test_split()</code>. Next, let’s convert it to tensors and normalize it. We could use a <code translate="no">StandardScaler</code> for this, like we did in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>, but let’s just use tensor operations instead, to get a bit of practice:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">X_train</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">FloatTensor</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>
<code class="n">X_valid</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">FloatTensor</code><code class="p">(</code><code class="n">X_valid</code><code class="p">)</code>
<code class="n">X_test</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">FloatTensor</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code>
<code class="n">means</code> <code class="o">=</code> <code class="n">X_train</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">dim</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">keepdims</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">stds</code> <code class="o">=</code> <code class="n">X_train</code><code class="o">.</code><code class="n">std</code><code class="p">(</code><code class="n">dim</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">keepdims</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">X_train</code> <code class="o">=</code> <code class="p">(</code><code class="n">X_train</code> <code class="o">-</code> <code class="n">means</code><code class="p">)</code> <code class="o">/</code> <code class="n">stds</code>
<code class="n">X_valid</code> <code class="o">=</code> <code class="p">(</code><code class="n">X_valid</code> <code class="o">-</code> <code class="n">means</code><code class="p">)</code> <code class="o">/</code> <code class="n">stds</code>
<code class="n">X_test</code> <code class="o">=</code> <code class="p">(</code><code class="n">X_test</code> <code class="o">-</code> <code class="n">means</code><code class="p">)</code> <code class="o">/</code> <code class="n">stds</code></pre>

<p>Let’s also convert the targets to tensors. Since our predictions will be column vectors<a data-type="indexterm" data-primary="column vectors" id="id2280"/> (i.e., matrices with a single column), we need to ensure that our targets are also column vectors.⁠<sup><a data-type="noteref" id="id2281-marker" href="ch10.html#id2281">8</a></sup> Unfortunately, the NumPy arrays representing the targets are one-dimensional, so we need to reshape the tensors to column vectors by adding a second dimension of size 1:⁠<sup><a data-type="noteref" id="id2282-marker" href="ch10.html#id2282">9</a></sup></p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">y_train</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">FloatTensor</code><code class="p">(</code><code class="n">y_train</code><code class="p">)</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>
<code class="n">y_valid</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">FloatTensor</code><code class="p">(</code><code class="n">y_valid</code><code class="p">)</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>
<code class="n">y_test</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">FloatTensor</code><code class="p">(</code><code class="n">y_test</code><code class="p">)</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="o">-</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code></pre>

<p>Now that the data is ready, let’s create the parameters of our linear regression model:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">torch</code><code class="o">.</code><code class="n">manual_seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>
<code class="n">n_features</code> <code class="o">=</code> <code class="n">X_train</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code>  <code class="c1"># there are 8 input features</code>
<code class="n">w</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">randn</code><code class="p">((</code><code class="n">n_features</code><code class="p">,</code> <code class="mi">1</code><code class="p">),</code> <code class="n">requires_grad</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">b</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="mf">0.</code><code class="p">,</code> <code class="n">requires_grad</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code></pre>

<p>We now have a weights parameter <code translate="no">w</code> (a column vector with one weight per input dimension, in this case 8), and a bias parameter <code translate="no">b</code> (a single scalar). The weights are initialized randomly, while the bias is initialized to zero. We could have initialized the weights to zero as well in this case, but when we get to neural networks it will be important to initialize the weights randomly to break the symmetry between neurons (as explained in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>), so we might as well get into the habit now.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>We called <code translate="no">torch.manual_seed()</code><a data-type="indexterm" data-primary="torch" data-secondary="manual_seed()" id="id2283"/> to ensure that the results are reproducible. However, PyTorch does not guarantee perfectly reproducible results across different releases, platforms, or devices, so if you do not run the code in this chapter with PyTorch 2.8.0 on a Colab runtime with an Nvidia T4 GPU, you may get different results. Moreover, since a GPU<a data-type="indexterm" data-primary="graphical processing units (GPUs)" data-secondary="tensors" id="id2284"/> splits each operation into multiple chunks and runs them in parallel, the order in which these chunks finish may vary across runs, and this may slightly affect the result due to floating-point precision errors. These minor differences may compound during training, and lead to very different models. To avoid this, you can tell PyTorch to use only deterministic algorithms<a data-type="indexterm" data-primary="deterministic algorithms" id="id2285"/> by calling <code translate="no">torch.use_deterministic_algorithms(True)</code> and setting <code translate="no">torch.backends.cudnn.benchmark = False</code>. However, deterministic algorithms are often slower than stochastic ones, and some operations don’t have a deterministic version at all, so you will get an error if your code tries to use one.</p>
</div>

<p>Next, let’s train our model, very much like we did in <a data-type="xref" href="ch04.html#linear_models_chapter">Chapter 4</a>, except we will use autodiff to compute the gradients rather than using a closed-form equation. For now we will use batch gradient<a data-type="indexterm" data-primary="batch gradient descent" id="xi_batchgradientdescent10338211_1"/> descent (BGD), using the full training set at each training step:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.4</code>
<code class="n">n_epochs</code> <code class="o">=</code> <code class="mi">20</code>
<code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
    <code class="n">y_pred</code> <code class="o">=</code> <code class="n">X_train</code> <code class="o">@</code> <code class="n">w</code> <code class="o">+</code> <code class="n">b</code>
    <code class="n">loss</code> <code class="o">=</code> <code class="p">((</code><code class="n">y_pred</code> <code class="o">-</code> <code class="n">y_train</code><code class="p">)</code> <code class="o">**</code> <code class="mi">2</code><code class="p">)</code><code class="o">.</code><code class="n">mean</code><code class="p">()</code>
    <code class="n">loss</code><code class="o">.</code><code class="n">backward</code><code class="p">()</code>
    <code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code>
        <code class="n">b</code> <code class="o">-=</code> <code class="n">learning_rate</code> <code class="o">*</code> <code class="n">b</code><code class="o">.</code><code class="n">grad</code>
        <code class="n">w</code> <code class="o">-=</code> <code class="n">learning_rate</code> <code class="o">*</code> <code class="n">w</code><code class="o">.</code><code class="n">grad</code>
        <code class="n">b</code><code class="o">.</code><code class="n">grad</code><code class="o">.</code><code class="n">zero_</code><code class="p">()</code>
        <code class="n">w</code><code class="o">.</code><code class="n">grad</code><code class="o">.</code><code class="n">zero_</code><code class="p">()</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Epoch </code><code class="si">{</code><code class="n">epoch</code> <code class="o">+</code> <code class="mi">1</code><code class="si">}</code><code class="s2">/</code><code class="si">{</code><code class="n">n_epochs</code><code class="si">}</code><code class="s2">, Loss: </code><code class="si">{</code><code class="n">loss</code><code class="o">.</code><code class="n">item</code><code class="p">()</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code></pre>

<p>Let’s walk through this code:</p>

<ul>
<li>
<p>First we define the <code translate="no">learning_rate</code> hyperparameter<a data-type="indexterm" data-primary="hyperparameters" data-secondary="learning rate" id="id2286"/><a data-type="indexterm" data-primary="learning_rate hyperparameter" id="id2287"/>. You can experiment with different values to find a value that converges fast and gives a precise result.</p>
</li>
<li>
<p>Next, we run 20 epochs. We could implement early stopping to find the right moment to stop and avoid overfitting, like we did in <a data-type="xref" href="ch04.html#linear_models_chapter">Chapter 4</a>, but we will keep things simple for now.</p>
</li>
<li>
<p>Next, we run the forward pass: we compute the predictions <code translate="no">y_pred</code>, and the mean squared error <code translate="no">loss</code>.</p>
</li>
<li>
<p>Then we run <code translate="no">loss.backward()</code><a data-type="indexterm" data-primary="torch" data-secondary="loss.backward()" id="id2288"/> to compute the gradients of the loss with regard to every model parameter. This is autograd in action.</p>
</li>
<li>
<p>Next, we use the gradients <code translate="no">b.grad</code> and <code translate="no">w.grad</code> to perform a gradient descent step. Notice that we’re running this code inside a <code translate="no">with torch.no_grad()</code> context, as discussed earlier.</p>
</li>
<li>
<p>Once we’ve done the gradient descent step, we reset the gradients to zero (very important!).</p>
</li>
<li>
<p>Lastly, we print the epoch number and the current loss at each epoch. The <code translate="no">item()</code> method extracts the value of a scalar tensor.</p>
</li>
</ul>

<p>And that’s it; if you run this code, you should see the training loss going down like this:</p>

<pre translate="no" data-type="programlisting">Epoch 1/20, Loss: 16.158456802368164
Epoch 2/20, Loss: 4.8793745040893555
Epoch 3/20, Loss: 2.255225419998169
[...]
Epoch 20/20, Loss: 0.5684100389480591</pre>

<p>Congratulations, you just trained your first model using PyTorch!<a data-type="indexterm" data-startref="xi_batchgradientdescent10338211_1" id="id2289"/> You can now use the model to make predictions for some new data <code translate="no">X_new</code> (which must be represented as a PyTorch tensor). For example, let’s make predictions for the first three instances in the test set:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X_new</code> <code class="o">=</code> <code class="n">X_test</code><code class="p">[:</code><code class="mi">3</code><code class="p">]</code>  <code class="c1"># pretend these are new instances</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code><code class="w"/>
<code class="gp">... </code>    <code class="n">y_pred</code> <code class="o">=</code> <code class="n">X_new</code> <code class="o">@</code> <code class="n">w</code> <code class="o">+</code> <code class="n">b</code>  <code class="c1"># use the trained parameters to make predictions</code><code class="w"/>
<code class="gp">...</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_pred</code><code class="w"/>
<code class="go">tensor([[0.8916],</code>
<code class="go">        [1.6480],</code>
<code class="go">        [2.6577]])</code></pre>
<div data-type="tip"><h6>Tip</h6>
<p>It’s best to use a <code translate="no">with torch.no_grad()</code> context during inference: PyTorch will consume less RAM and run faster since it won’t have to keep track of the computation graph.</p>
</div>

<p>Implementing linear regression using PyTorch’s low-level API wasn’t too hard, but using this approach for more complex models would get really messy and difficult. So PyTorch offers a higher-level API to simplify all this. Let’s rewrite our model using this higher-level API.<a data-type="indexterm" data-startref="xi_autogradautomaticgradients102038_1" id="id2290"/><a data-type="indexterm" data-startref="xi_CaliforniaHousingPricesdataset1030123_1" id="id2291"/><a data-type="indexterm" data-startref="xi_tensorslinearregressionwith103016_1" id="id2292"/><a data-type="indexterm" data-startref="xi_housingdataset1030123_1" id="id2293"/></p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Linear Regression Using PyTorch’s High-Level API"><div class="sect2" id="id163">
<h2>Linear Regression Using PyTorch’s High-Level API</h2>

<p>PyTorch provides an implementation of linear regression in the <code translate="no">torch.nn.Linear</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.Linear" id="id2294"/> class, so let’s use it:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">torch.nn</code> <code class="k">as</code> <code class="nn">nn</code>  <code class="c1"># by convention, this module is usually imported this way</code>

<code class="n">torch</code><code class="o">.</code><code class="n">manual_seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>  <code class="c1"># to get reproducible results</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="n">in_features</code><code class="o">=</code><code class="n">n_features</code><code class="p">,</code> <code class="n">out_features</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code></pre>

<p>The <code translate="no">nn.Linear</code> class (short for <code translate="no">torch.nn.Linear</code>) is one of many <em>modules</em> <a data-type="indexterm" data-primary="modules, PyTorch" id="id2295"/>provided by PyTorch. Each module is a subclass of the <code translate="no">nn.Module</code> class. To build a simple linear regression model, a single <code translate="no">nn.Linear</code> module is all you need. However, for most neural networks you will need to assemble many modules, as we will see later in this chapter, so you can think of modules as math LEGO<sup>®</sup> bricks. Many modules contain model parameters. For example, the <code translate="no">nn.Linear</code> module contains a <code translate="no">bias</code> vector (with one bias term per neuron), and a <code translate="no">weight</code> matrix (with one row per neuron and one column per input dimension, which is the transpose of the weight matrix we used earlier and in <a data-type="xref" href="ch09.html#neural_network_layer_equation">Equation 9-2</a>). Since our model has a single neuron (because <code translate="no">out_features=1</code>), the <code translate="no">bias</code> vector contains a single bias term, and the <code translate="no">weight</code> matrix contains a single row. These parameters are accessible directly as attributes of the <code translate="no">nn.Linear</code> module:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">model</code><code class="o">.</code><code class="n">bias</code><code class="w"/>
<code class="go">Parameter containing:</code>
<code class="go">tensor([0.3117], requires_grad=True)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">model</code><code class="o">.</code><code class="n">weight</code><code class="w"/>
<code class="go">Parameter containing:</code>
<code class="go">tensor([[ 0.2703, 0.2935, -0.0828, 0.3248, -0.0775, 0.0713, -0.1721, 0.2076]],</code>
<code class="go">       requires_grad=True)</code></pre>

<p>Notice that both parameters were automatically initialized randomly (which is why we used <code translate="no">manual_seed()</code> to get reproducible results). These parameters are instances of the <code translate="no">torch.nn.Parameter</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.Parameter" id="id2296"/> class, which is a subclass of the <code translate="no">tensor.Tensor</code> class: this means that you can use them exactly like normal tensors. A module’s <code translate="no">parameters()</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.Module.parameters()" id="id2297"/> method returns an iterator over all of the module’s attributes of type <code translate="no">Parameter</code>, as well as all the parameters of all its submodules, recursively (if it has any). It does <em>not</em> return regular tensors, even those with <code translate="no">requires_grad=True</code>. That’s the main difference between a regular tensor<a data-type="indexterm" data-primary="tensors" data-secondary="versus Parameters" data-secondary-sortas="parameter" id="id2298"/> and a <code translate="no">Parameter</code>:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">for</code> <code class="n">param</code> <code class="ow">in</code> <code class="n">model</code><code class="o">.</code><code class="n">parameters</code><code class="p">():</code><code class="w"/>
<code class="gp">... </code>    <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># do something with each parameter</code><code class="w"/></pre>

<p>There’s also a <code translate="no">named_parameters()</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.Module.named_parameters()" id="id2299"/> method that returns an iterator over pairs of parameter names and values.</p>

<p>A module can be called just like a regular function. For example, let’s make some predictions for the first two instances in the training set (since the model is not trained yet, its parameters are random and the predictions are terrible):</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">model</code><code class="p">(</code><code class="n">X_train</code><code class="p">[:</code><code class="mi">2</code><code class="p">])</code><code class="w"/>
<code class="go">tensor([[-0.4718],</code>
<code class="go">        [ 0.1131]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>

<p>When we use a module as a function, PyTorch internally calls the module’s <code translate="no">forward()</code><a data-type="indexterm" data-primary="torch" data-secondary="forward()" id="id2300"/> method. In the case of the <code translate="no">nn.Linear</code> module, the <code translate="no">forward()</code> method computes <code translate="no">X @ self.weight.T + self.bias</code> (where <code translate="no">X</code> is the input). That’s just what we need for linear regression!</p>

<p>Notice that the result contains the <code translate="no">grad_fn</code> attribute, showing that autograd did its job and tracked the computation graph while the model was making its predictions.</p>
<div data-type="tip"><h6>Tip</h6>
<p>If you pass a custom function to a module’s <code translate="no">register_forward_hook()</code> <a data-type="indexterm" data-primary="torch" data-secondary="nn.modules.module.register_forward_hook()" id="id2301"/>method, it will be called automatically every time the module itself is called. This is particularly handy for logging or debugging. To remove a hook, just call the <code translate="no">remove()</code> method on the object returned by <code translate="no">register_forward_hook()</code>. Note that hooks<a data-type="indexterm" data-primary="hooks, PyTorch" id="id2302"/> only work if you call the model like a function, not if you call its <code translate="no">forward()</code> method directly (which is why you should never do that). You can also register functions to run during the backward pass using <code translate="no">register_backward_hook()</code>.</p>
</div>

<p>Now that we have our model, we need to create an optimizer<a data-type="indexterm" data-primary="optimizers" data-secondary="PyTorch" id="id2303"/> to update the model parameters, and we must also choose a loss function:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">optimizer</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">optim</code><code class="o">.</code><code class="n">SGD</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">parameters</code><code class="p">(),</code> <code class="n">lr</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">)</code>
<code class="n">mse</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">MSELoss</code><code class="p">()</code></pre>

<p>PyTorch provides a few different optimizers (we will discuss them in the next chapter). Here we’re using the simple stochastic gradient descent (SGD) optimizer<a data-type="indexterm" data-primary="stochastic gradient descent (SGD)" data-secondary="optimizer for" id="id2304"/>, which can be used for SGD, mini-batch GD, or batch gradient descent. To initialize it, we must give it the model parameters and the learning rate.</p>

<p>For the loss function<a data-type="indexterm" data-primary="loss functions" data-secondary="PyTorch" id="id2305"/><a data-type="indexterm" data-primary="torch" data-secondary="nn.MSELoss" id="id2306"/>, we create an instance of the <code translate="no">nn.MSELoss</code> class: this is also a module, so we can use it like a function, giving it the predictions and the targets, and it will compute the MSE. The <code translate="no">nn</code> module<a data-type="indexterm" data-primary="torch" data-secondary="nn" id="id2307"/> contains many other loss functions and other neural net tools, as we will see. Next, let’s write a small function to train our model:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">train_bgd</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">optimizer</code><code class="p">,</code> <code class="n">criterion</code><code class="p">,</code> <code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">n_epochs</code><code class="p">):</code>
    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="n">y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>
        <code class="n">loss</code> <code class="o">=</code> <code class="n">criterion</code><code class="p">(</code><code class="n">y_pred</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>
        <code class="n">loss</code><code class="o">.</code><code class="n">backward</code><code class="p">()</code>
        <code class="n">optimizer</code><code class="o">.</code><code class="n">step</code><code class="p">()</code>
        <code class="n">optimizer</code><code class="o">.</code><code class="n">zero_grad</code><code class="p">()</code>
        <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Epoch </code><code class="si">{</code><code class="n">epoch</code> <code class="o">+</code> <code class="mi">1</code><code class="si">}</code><code class="s2">/</code><code class="si">{</code><code class="n">n_epochs</code><code class="si">}</code><code class="s2">, Loss: </code><code class="si">{</code><code class="n">loss</code><code class="o">.</code><code class="n">item</code><code class="p">()</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code></pre>

<p>Compare this training loop with our earlier training loop: it’s very similar, but we’re now using higher-level constructs rather than working directly with tensors and autograd. Here are a few things to note:</p>

<ul>
<li>
<p>In PyTorch, the loss function object is commonly referred to as the <em>criterion</em>,<a data-type="indexterm" data-primary="criterion versus loss" id="id2308"/> to distinguish it from the loss value itself (which is computed at each training iteration using the criterion). In this example, it’s the <code translate="no">MSELoss</code> instance.</p>
</li>
<li>
<p>The <code translate="no">optimizer.step()</code><a data-type="indexterm" data-primary="torch" data-secondary="optim.optimizer.step()" id="id2309"/> line corresponds to the two lines that updated <code translate="no">b</code> and <code translate="no">w</code> in our earlier code.</p>
</li>
<li>
<p>And of course the <code translate="no">optimizer.zero_grad()</code><a data-type="indexterm" data-primary="torch" data-secondary="optim.optimizer.zero_grad()" id="id2310"/> line corresponds to the two lines that zeroed out <code translate="no">b.grad</code> and <code translate="no">w.grad</code>. Notice that we don’t need to use <code translate="no">with torch.no_grad()</code> here since this is done automatically by the optimizer, inside the <code translate="no">step()</code> and <code translate="no">zero_grad()</code> functions.</p>
</li>
</ul>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Most people prefer to call <code translate="no">zero_grad()</code> <em>before</em> calling <code translate="no">loss.backward()</code>, rather than after: this might be a bit safer in case the gradients are nonzero when calling the function, but in general it makes no difference since gradients are automatically initialized to <code translate="no">None</code>.</p>
</div>

<p>Now let’s call this function to train our model!</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">train_bgd</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">optimizer</code><code class="p">,</code> <code class="n">mse</code><code class="p">,</code> <code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">n_epochs</code><code class="p">)</code><code class="w"/>
<code class="go">Epoch 1/20, Loss: 4.3378496170043945</code>
<code class="go">Epoch 2/20, Loss: 0.780293345451355</code>
<code class="go">[...]</code>
<code class="go">Epoch 20/20, Loss: 0.5374288558959961</code></pre>

<p>All good; the model is trained, and you can now use it to make predictions by simply calling it like a function (preferably inside a <code translate="no">no_grad()</code> context, as we saw earlier):</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X_new</code> <code class="o">=</code> <code class="n">X_test</code><code class="p">[:</code><code class="mi">3</code><code class="p">]</code>  <code class="c1"># pretend these are new instances</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code><code class="w"/>
<code class="gp">... </code>    <code class="n">y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">X_new</code><code class="p">)</code>  <code class="c1"># use the trained model to make predictions</code><code class="w"/>
<code class="gp">...</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_pred</code><code class="w"/>
<code class="go">tensor([[0.8061],</code>
<code class="go">        [1.7116],</code>
<code class="go">        [2.6973]])</code></pre>

<p>These predictions are similar to the ones our previous model made, but not exactly the same. That’s because the <code translate="no">nn.Linear</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.Linear" id="id2311"/> module initializes the parameters slightly differently: it uses a uniform random distribution from <math alttext="minus StartFraction StartRoot 2 EndRoot Over 4 EndFraction">
  <mrow>
    <mo>-</mo>
    <mfrac><msqrt><mn>2</mn></msqrt> <mn>4</mn></mfrac>
  </mrow>
</math> to <math alttext="plus StartFraction StartRoot 2 EndRoot Over 4 EndFraction">
  <mrow>
    <mo>+</mo>
    <mfrac><msqrt><mn>2</mn></msqrt> <mn>4</mn></mfrac>
  </mrow>
</math> for both the weights and the bias term (we will discuss initialization methods in <a data-type="xref" href="ch11.html#deep_chapter">Chapter 11</a>).</p>

<p>Now that you are familiar with PyTorch’s high-level API, you are ready to go beyond linear regression and build a multilayer perceptron (introduced in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>).<a data-type="indexterm" data-startref="xi_linearregressionPyTorchfor102983_1" id="id2312"/><a data-type="indexterm" data-startref="xi_PyTorchlinearregression102983_1" id="id2313"/></p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Implementing a Regression MLP"><div class="sect1" id="id164">
<h1>Implementing a Regression MLP</h1>

<p>PyTorch<a data-type="indexterm" data-primary="multilayer perceptrons (MLPs)" data-secondary="PyTorch for" id="xi_multilayerperceptronsMLPsPyTorchfor105068_1"/><a data-type="indexterm" data-primary="PyTorch" data-secondary="regression MLP" id="xi_PyTorchregressionMLP105068_1"/> provides a helpful <code translate="no">nn.Sequential</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.Sequential" id="id2314"/> module that chains multiple modules: when you call this module with some inputs, it feeds these inputs to the first module, then feeds the output of the first module to the second module, and so on. Most neural networks contain stacks of modules, and in fact many neural networks are just one big stack of modules: this makes the <code translate="no">nn.Sequential</code> module one of the most useful modules in PyTorch. The MLP we want to build is just that: a simple stack of modules—two hidden layers and one output layer. So let’s build it using the <code translate="no">nn.Sequential</code> module:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">torch</code><code class="o">.</code><code class="n">manual_seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">Sequential</code><code class="p">(</code>
    <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="n">n_features</code><code class="p">,</code> <code class="mi">50</code><code class="p">),</code>
    <code class="n">nn</code><code class="o">.</code><code class="n">ReLU</code><code class="p">(),</code>
    <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="mi">50</code><code class="p">,</code> <code class="mi">40</code><code class="p">),</code>
    <code class="n">nn</code><code class="o">.</code><code class="n">ReLU</code><code class="p">(),</code>
    <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="mi">40</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>
<code class="p">)</code></pre>

<p>Let’s go through each layer:</p>

<ul>
<li>
<p>The first layer must have the right number of inputs for our data: <code translate="no">n_features</code> (equal to 8 in our case). However, it can have any number of outputs: let’s pick 50 (that’s a hyperparameter we can tune).</p>
</li>
<li>
<p>Next we have an <code translate="no">nn.ReLU</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.ReLU" id="id2315"/> module, which implements the ReLU activation function for the first hidden layer. This module does not contain any model parameters, and it acts itemwise so the shape of its output is equal to the shape of its input.</p>
</li>
<li>
<p>The second hidden layer must have the same number of inputs as the output of the previous layer: in this case, 50. However, it can have any number of outputs. It’s common to use the same number of output dimensions in all hidden layers, but in this example I used 40 to make it clear that the output of one layer must match the input of the next layer.</p>
</li>
<li>
<p>Then again, an <code translate="no">nn.ReLU</code> module to implement the second hidden layer’s activation function.</p>
</li>
<li>
<p>Finally, the output layer must have 40 inputs, but this time its number of outputs is not free: it must match the targets’ dimensionality. Since our targets have a single dimension, we must have just one output dimension in the output layer.</p>
</li>
</ul>

<p>Now let’s train the model just like we did before:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.1</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">optimizer</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">optim</code><code class="o">.</code><code class="n">SGD</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">parameters</code><code class="p">(),</code> <code class="n">lr</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">mse</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">MSELoss</code><code class="p">()</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">train_bgd</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">optimizer</code><code class="p">,</code> <code class="n">mse</code><code class="p">,</code> <code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">n_epochs</code><code class="p">)</code><code class="w"/>
<code class="go">Epoch 1/20, Loss: 5.045480251312256</code>
<code class="go">Epoch 2/20, Loss: 2.0523128509521484</code>
<code class="go">[...]</code>
<code class="go">Epoch 20/20, Loss: 0.565444827079773</code></pre>

<p>That’s it, you can tell your friends you trained your first neural network with PyTorch! However, we are still using batch gradient descent, computing the gradients over the entire training set at each iteration. This works with small datasets, but if we want to be able to scale up to large datasets and large models, we need to switch to mini-batch gradient descent.<a data-type="indexterm" data-startref="xi_multilayerperceptronsMLPsPyTorchfor105068_1" id="id2316"/><a data-type="indexterm" data-startref="xi_PyTorchregressionMLP105068_1" id="id2317"/></p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Implementing Mini-Batch Gradient &#10;Descent Using DataLoaders"><div class="sect1" id="id165">
<h1>Implementing Mini-Batch Gradient 
<span class="keep-together">Descent Using DataLoaders</span></h1>

<p><a data-type="indexterm" data-primary="gradient descent (GD)" data-secondary="batch gradient descent" id="xi_gradientdescentGDbatchgradientdescent105451_1"/><a data-type="indexterm" data-primary="mini-batch gradient descent" id="xi_minibatchgradientdescent105451_1"/><a data-type="indexterm" data-primary="PyTorch" data-secondary="mini-batch gradient descent" id="xi_PyTorchminibatchgradientdescent105451_1"/>To help implement mini-batch GD, PyTorch provides a class named <code translate="no">DataLoader</code><a data-type="indexterm" data-primary="torch" data-secondary="utils.data.DataLoader()" id="id2318"/><a data-type="indexterm" data-primary="DataLoader(), PyTorch" id="id2319"/> in the <code translate="no">torch.utils.data</code> module. It can efficiently load batches of data of the desired size, and shuffle the data at each epoch if we want it to. The <code translate="no">DataLoader</code> expects the dataset to be represented as an object with at least two methods: <code translate="no">__len__(self)</code> to get the number of samples in the dataset, and <code translate="no">__getitem__(self, index)</code> to load the sample at the given index (including the target).</p>

<p>In our case, the training set is available in the <code translate="no">X_train</code> and <code translate="no">y_train</code> tensors<a data-type="indexterm" data-primary="tensor arrays" data-seealso="tensors" id="id2320"/><a data-type="indexterm" data-primary="tensors" data-secondary="TensorDataset" id="id2321"/>, so we first need to wrap these tensors in a dataset object with the required API. To help with this, PyTorch provides a <code translate="no">TensorDataset</code> class. So let’s build a <code translate="no">TensorDataset</code> to wrap our training set, and a <code translate="no">DataLoader</code> to pull batches from this dataset. During training, we want the dataset to be shuffled, so we specify <code translate="no">shuffle=True</code>:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">torch.utils.data</code> <code class="kn">import</code> <code class="n">TensorDataset</code><code class="p">,</code> <code class="n">DataLoader</code>

<code class="n">train_dataset</code> <code class="o">=</code> <code class="n">TensorDataset</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>
<code class="n">train_loader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">train_dataset</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">32</code><code class="p">,</code> <code class="n">shuffle</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code></pre>

<p>Now that we have a larger model and we have the tools to train it one batch at a time, it’s a good time to start using hardware acceleration<a data-type="indexterm" data-primary="hardware acceleration" id="id2322"/>. It’s really quite simple: we just need to move the model to the GPU<a data-type="indexterm" data-primary="graphical processing units (GPUs)" data-secondary="hardware acceleration" id="id2323"/>, which will move all of its parameters to the GPU RAM, and then at the start of each iteration during training we must copy each batch to the GPU. To move the model, we can just use its <code translate="no">to()</code><a data-type="indexterm" data-primary="torch" data-secondary="tensor.to()" id="id2324"/> method, just like we did with tensors:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">torch</code><code class="o">.</code><code class="n">manual_seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">Sequential</code><code class="p">([</code><code class="o">...</code><code class="p">])</code>  <code class="c1"># create the model just like earlier</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code></pre>

<p>We can also create the loss function and optimizer, as earlier (but using a lower learning rate, such as 0.02).</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Some optimizers<a data-type="indexterm" data-primary="optimizers" data-secondary="PyTorch" id="id2325"/> have some internal state, as we will see in <a data-type="xref" href="ch11.html#deep_chapter">Chapter 11</a>. The optimizer will usually allocate its state on the same device as the model parameters, so it’s important to create the optimizer <em>after</em> you have moved the model to the GPU.</p>
</div>

<p>Now let’s create a <code translate="no">train()</code> function to implement mini-batch GD:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">train</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">optimizer</code><code class="p">,</code> <code class="n">criterion</code><code class="p">,</code> <code class="n">train_loader</code><code class="p">,</code> <code class="n">n_epochs</code><code class="p">):</code>
    <code class="n">model</code><code class="o">.</code><code class="n">train</code><code class="p">()</code>
    <code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
        <code class="n">total_loss</code> <code class="o">=</code> <code class="mf">0.</code>
        <code class="k">for</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="n">train_loader</code><code class="p">:</code>
            <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">X_batch</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">),</code> <code class="n">y_batch</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
            <code class="n">y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">X_batch</code><code class="p">)</code>
            <code class="n">loss</code> <code class="o">=</code> <code class="n">criterion</code><code class="p">(</code><code class="n">y_pred</code><code class="p">,</code> <code class="n">y_batch</code><code class="p">)</code>
            <code class="n">total_loss</code> <code class="o">+=</code> <code class="n">loss</code><code class="o">.</code><code class="n">item</code><code class="p">()</code>
            <code class="n">loss</code><code class="o">.</code><code class="n">backward</code><code class="p">()</code>
            <code class="n">optimizer</code><code class="o">.</code><code class="n">step</code><code class="p">()</code>
            <code class="n">optimizer</code><code class="o">.</code><code class="n">zero_grad</code><code class="p">()</code>

        <code class="n">mean_loss</code> <code class="o">=</code> <code class="n">total_loss</code> <code class="o">/</code> <code class="nb">len</code><code class="p">(</code><code class="n">train_loader</code><code class="p">)</code>
        <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Epoch </code><code class="si">{</code><code class="n">epoch</code> <code class="o">+</code> <code class="mi">1</code><code class="si">}</code><code class="s2">/</code><code class="si">{</code><code class="n">n_epochs</code><code class="si">}</code><code class="s2">, Loss: </code><code class="si">{</code><code class="n">mean_loss</code><code class="si">:</code><code class="s2">.4f</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code></pre>

<p>At every epoch, the function iterates through the whole training set, one batch at a time, and processes each batch just like earlier. But what about the very first line: <code translate="no">model.train()</code>?<a data-type="indexterm" data-primary="torch" data-secondary="model.train()" id="id2326"/> Well, this switches the model and all of its submodules to <em>training mode</em>.<a data-type="indexterm" data-primary="training mode, PyTorch" id="xi_trainingmodePyTorch10591264_1"/> For now, this makes no difference at all, but it will be important in <a data-type="xref" href="ch11.html#deep_chapter">Chapter 11</a> when we start using layers that behave differently during training and evaluation (e.g., <code translate="no">nn.Dropout</code> or <code translate="no">nn.BatchNorm1d</code>). Whenever you want to use the model outside of training (e.g., for evaluation, or to make predictions on new instances), you must first switch the model to <em>evaluation mode</em><a data-type="indexterm" data-primary="evaluation mode, PyTorch" id="id2327"/> by running <code translate="no">model.eval()</code>. Note that <code translate="no">model.training</code><a data-type="indexterm" data-primary="torch" data-secondary="model.training" id="id2328"/> holds a boolean that indicates the current mode.</p>
<div data-type="tip"><h6>Tip</h6>
<p>PyTorch itself does not provide a training loop implementation; you have to build it yourself. As we just saw, it’s not that long, and many people enjoy the freedom, clarity, and control this provides. However, if you would prefer to use a well-tested, off-the-shelf training loop with all the bells and whistles you need (such as multi-GPU support), then you can use a library such as PyTorch Lightning, FastAI, Catalyst, or Keras. These libraries are built on top of PyTorch and include a training loop and many other features (Keras supports PyTorch since version 3, and also supports TensorFlow and JAX). Check them out!</p>
</div>

<p>Now let’s call this <code translate="no">train()</code> function to train our model on the GPU:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">train</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">optimizer</code><code class="p">,</code> <code class="n">mse</code><code class="p">,</code> <code class="n">train_loader</code><code class="p">,</code> <code class="n">n_epochs</code><code class="p">)</code><code class="w"/>
<code class="go">Epoch 1/20, Loss: 0.6958</code>
<code class="go">Epoch 2/20, Loss: 0.4480</code>
<code class="go">[...]</code>
<code class="go">Epoch 20/20, Loss: 0.3227</code></pre>

<p>It worked great: we actually reached a much lower loss in the same number of epochs! However, you probably noticed that each epoch was much slower. There are two easy tweaks you can make to considerably speed up training:</p>

<ul>
<li>
<p>If you are using a CUDA device, you should generally set <code translate="no">pin_memory=True</code> when creating the data loader: this will allocate the data in <em>page-locked memory</em><a data-type="indexterm" data-primary="page-locked memory" id="id2329"/> which guarantees a fixed physical memory location in the CPU RAM, and therefore allows direct memory access (DMA) transfers to the GPU<a data-type="indexterm" data-primary="graphical processing units (GPUs)" data-secondary="and page-locked memory" data-secondary-sortas="page" id="id2330"/>, eliminating an extra copy operation that would otherwise be needed. While this could use more CPU RAM since the memory cannot be swapped out to disk, it typically results in significantly faster data transfers and thus faster training. When transferring a tensor<a data-type="indexterm" data-primary="tensor arrays" id="id2331"/> to the GPU using its <code translate="no">to()</code><a data-type="indexterm" data-primary="torch" data-secondary="tensor.to()" id="id2332"/> method, you may also set <code translate="no">non_blocking=True</code> to avoid blocking the CPU during the data transfer (this only works if 
<span class="keep-together"><code translate="no">pin_memory=True</code>).</span></p>
</li>
<li>
<p>The current training loop waits until a batch has been fully processed before it loads the next batch. You can often speed up training by pre-fetching the next batches on the CPU while the GPU is still working on the current batch. For this, set the data loader’s <code translate="no">num_workers</code> argument to the number of processes you want to use for data loading and preprocessing. The optimal number depends on your platform, hardware, and workload, so you should experiment with different values. You can also tweak the number of batches that each worker pre-fetches by setting the data loader’s <code translate="no">prefetch_factor</code> argument. Note that the overhead of spawning and synchronizing workers can often slow down training rather than speed it up (especially on Windows). In this case, you can try setting <code translate="no">persistent_workers=True</code> to reuse the same workers across epochs.<a data-type="indexterm" data-startref="xi_trainingmodePyTorch10591264_1" id="id2333"/></p>
</li>
</ul>

<p>OK, time to step back a bit: you know the PyTorch fundamentals (tensors and autograd), you can build neural nets using PyTorch’s high-level API, and train them using mini-batch gradient descent, with the help of an optimizer, a criterion, and a data loader. The next step is to learn how to evaluate your model.<a data-type="indexterm" data-startref="xi_gradientdescentGDbatchgradientdescent105451_1" id="id2334"/><a data-type="indexterm" data-startref="xi_minibatchgradientdescent105451_1" id="id2335"/><a data-type="indexterm" data-startref="xi_PyTorchminibatchgradientdescent105451_1" id="id2336"/></p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Model Evaluation"><div class="sect1" id="id166">
<h1>Model Evaluation</h1>

<p>Let’s<a data-type="indexterm" data-primary="model evaluation, PyTorch" id="xi_modelevaluationPyTorch106146_1"/><a data-type="indexterm" data-primary="PyTorch" data-secondary="model evaluation" id="xi_PyTorchmodelevaluation106146_1"/> write a function to evaluate the model. It takes the model and a <code translate="no">DataLoader</code> for the dataset that we want to evaluate the model on, as well as a function to compute the metric for a given batch, and lastly a function to aggregate the batch metrics (by default, it just computes the mean):</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">evaluate</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">data_loader</code><code class="p">,</code> <code class="n">metric_fn</code><code class="p">,</code> <code class="n">aggregate_fn</code><code class="o">=</code><code class="n">torch</code><code class="o">.</code><code class="n">mean</code><code class="p">):</code>
    <code class="n">model</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code>
    <code class="n">metrics</code> <code class="o">=</code> <code class="p">[]</code>
    <code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code>
        <code class="k">for</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="n">data_loader</code><code class="p">:</code>
            <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">X_batch</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">),</code> <code class="n">y_batch</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
            <code class="n">y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">X_batch</code><code class="p">)</code>
            <code class="n">metric</code> <code class="o">=</code> <code class="n">metric_fn</code><code class="p">(</code><code class="n">y_pred</code><code class="p">,</code> <code class="n">y_batch</code><code class="p">)</code>
            <code class="n">metrics</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">metric</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">aggregate_fn</code><code class="p">(</code><code class="n">torch</code><code class="o">.</code><code class="n">stack</code><code class="p">(</code><code class="n">metrics</code><code class="p">))</code></pre>

<p>Now let’s build a <code translate="no">TensorDataset</code> and a <code translate="no">DataLoader</code> for our validation set, and pass it to our <code translate="no">evaluate()</code> function to compute the validation MSE:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">valid_dataset</code> <code class="o">=</code> <code class="n">TensorDataset</code><code class="p">(</code><code class="n">X_valid</code><code class="p">,</code> <code class="n">y_valid</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">valid_loader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">valid_dataset</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">32</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">valid_mse</code> <code class="o">=</code> <code class="n">evaluate</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">valid_loader</code><code class="p">,</code> <code class="n">mse</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">valid_mse</code><code class="w"/>
<code class="go">tensor(0.4080, device='cuda:0')</code></pre>

<p>It works fine. But now suppose we want to use the RMSE instead of the MSE (as we saw in <a data-type="xref" href="ch02.html#project_chapter">Chapter 2</a>, it can be easier to interpret). PyTorch does not have a built-in function for that, but it’s easy enough to write:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">def</code> <code class="nf">rmse</code><code class="p">(</code><code class="n">y_pred</code><code class="p">,</code> <code class="n">y_true</code><code class="p">):</code><code class="w"/>
<code class="gp">... </code>    <code class="k">return</code> <code class="p">((</code><code class="n">y_pred</code> <code class="o">-</code> <code class="n">y_true</code><code class="p">)</code> <code class="o">**</code> <code class="mi">2</code><code class="p">)</code><code class="o">.</code><code class="n">mean</code><code class="p">()</code><code class="o">.</code><code class="n">sqrt</code><code class="p">()</code><code class="w"/>
<code class="gp">...</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">evaluate</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">valid_loader</code><code class="p">,</code> <code class="n">rmse</code><code class="p">)</code><code class="w"/>
<code class="go">tensor(0.5668, device='cuda:0')</code></pre>

<p>But wait a second! The RMSE should be equal to the square root of the MSE; however, when we compute the square root of the MSE that we found earlier, we get a different result:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">valid_mse</code><code class="o">.</code><code class="n">sqrt</code><code class="p">()</code><code class="w"/>
<code class="go">tensor(0.6388, device='cuda:0')</code></pre>

<p>The reason is that instead of calculating the RMSE over the whole validation set, we computed it over each batch and then computed the mean of all these batch RMSEs. That’s not mathematically equivalent to computing the RMSE over the whole validation set. To solve this, we can use the MSE as our <code translate="no">metric_fn</code>, and use the <code translate="no">aggregate_fn</code> to compute the square root of the mean MSE:⁠<sup><a data-type="noteref" id="id2337-marker" href="ch10.html#id2337">10</a></sup></p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">evaluate</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">valid_loader</code><code class="p">,</code> <code class="n">mse</code><code class="p">,</code><code class="w"/>
<code class="gp">... </code>         <code class="n">aggregate_fn</code><code class="o">=</code><code class="k">lambda</code> <code class="n">metrics</code><code class="p">:</code> <code class="n">torch</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">torch</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">metrics</code><code class="p">)))</code><code class="w"/>
<code class="gp">...</code><code class="w"/>
<code class="go">tensor(0.6388, device='cuda:0')</code></pre>

<p>That’s much better!</p>

<p>Rather than implement metrics yourself, you may prefer to use the TorchMetrics library (made by the same team as PyTorch Lightning), which provides many well-tested <em>streaming metrics</em>. A streaming metric is an object that keeps track of a given metric, and can be updated one batch at a time. The TorchMetrics library is not preinstalled on Colab, so we have to run <code translate="no">%pip install torchmetrics</code>, then we can implement the <code translate="no">evaluate_tm()</code> function, like this:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">torchmetrics</code>

<code class="k">def</code> <code class="nf">evaluate_tm</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">data_loader</code><code class="p">,</code> <code class="n">metric</code><code class="p">):</code>
    <code class="n">model</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code>
    <code class="n">metric</code><code class="o">.</code><code class="n">reset</code><code class="p">()</code>  <code class="c1"># reset the metric at the beginning</code>
    <code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code>
        <code class="k">for</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="n">data_loader</code><code class="p">:</code>
            <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">X_batch</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">),</code> <code class="n">y_batch</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
            <code class="n">y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">X_batch</code><code class="p">)</code>
            <code class="n">metric</code><code class="o">.</code><code class="n">update</code><code class="p">(</code><code class="n">y_pred</code><code class="p">,</code> <code class="n">y_batch</code><code class="p">)</code>  <code class="c1"># update it at each iteration</code>
    <code class="k">return</code> <code class="n">metric</code><code class="o">.</code><code class="n">compute</code><code class="p">()</code>  <code class="c1"># compute the final result at the end</code></pre>

<p>Then we can create an RMSE streaming metric, move it to the GPU, and use it to evaluate the validation set:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">rmse</code> <code class="o">=</code> <code class="n">torchmetrics</code><code class="o">.</code><code class="n">MeanSquaredError</code><code class="p">(</code><code class="n">squared</code><code class="o">=</code><code class="kc">False</code><code class="p">)</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">evaluate_tm</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">valid_loader</code><code class="p">,</code> <code class="n">rmse</code><code class="p">)</code><code class="w"/>
<code class="go">tensor(0.6388, device='cuda:0')</code></pre>

<p>Sure enough, we get the correct result! Now try updating the <code translate="no">train()</code> function to evaluate your model’s performance during training, both on the training set (during each epoch) and on the validation set (at the end of each epoch). As always, if the performance on the training set is much better than on the validation set, your model is probably overfitting the training set, or there is a bug, such as a data mismatch between the training set and the validation set. This is easier to detect if you plot and analyze the learning curves, much like we did in <a data-type="xref" href="ch04.html#linear_models_chapter">Chapter 4</a>. For this you can use Matplotlib, or a visualization tool such as TensorBoard (see the notebook for an example).</p>

<p>Now you know how to build, train, and evaluate a regression MLP using PyTorch, and how to use the trained model to make predictions. Great! But so far we have only looked at simple sequential models, composed of a sequence of linear layers and ReLU activation functions. How would you build a more complex, nonsequential model? For this, we will need to build custom modules.<a data-type="indexterm" data-startref="xi_modelevaluationPyTorch106146_1" id="id2338"/><a data-type="indexterm" data-startref="xi_PyTorchmodelevaluation106146_1" id="id2339"/></p>
</div></section>






<section data-type="sect1" class="less_space pagebreak-before" data-pdf-bookmark="Building Nonsequential Models Using Custom Modules"><div class="sect1" id="id167">
<h1>Building Nonsequential Models Using Custom Modules</h1>

<p>One<a data-type="indexterm" data-primary="nonsequential models" id="xi_nonsequentialmodels107034_1"/><a data-type="indexterm" data-primary="PyTorch" data-secondary="nonsequential models" id="xi_PyTorchnonsequentialmodels107034_1"/><a data-type="indexterm" data-primary="Wide &amp; Deep neural network" id="xi_WideDeepneuralnetwork107034_1"/> example of a nonsequential neural network is a <em>Wide &amp; Deep</em> neural network. This neural network architecture was introduced in a 2016 paper by Heng-Tze Cheng et al.⁠<sup><a data-type="noteref" id="id2340-marker" href="ch10.html#id2340">11</a></sup> It connects all or part of the inputs directly to the output layer, as shown in <a data-type="xref" href="#wide_deep_diagram">Figure 10-1</a>. This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path). The short path can also be used to provide manually engineered features to the neural network. In contrast, a regular MLP forces<a data-type="indexterm" data-primary="multilayer perceptrons (MLPs)" data-secondary="versus nonsequential models" data-secondary-sortas="nonsequential" id="id2341"/> all the data to flow through the full stack of layers; thus, simple patterns in the data may end up being distorted by this sequence of transformations.</p>

<figure class="width-30"><div id="wide_deep_diagram" class="figure">
<img src="assets/hmls_1001.png" alt="Diagram illustrating a Wide &amp; Deep neural network architecture, showing both wide and deep paths connecting inputs directly and through hidden layers, converging at a concat layer before the output layer." width="432" height="633"/>
<h6><span class="label">Figure 10-1. </span>Wide &amp; Deep neural network</h6>
</div></figure>

<p>Let’s build such a neural network to tackle the California housing dataset. Because this wide and deep architecture is nonsequential, we have to create a custom module. It’s easier than it sounds: just create a class derived from <code translate="no">torch.nn.Module</code>,<a data-type="indexterm" data-primary="torch" data-secondary="nn.Sequential" id="id2342"/> then create all the layers you need in the constructor (after calling the base class’s <code translate="no">__init__()</code> method), and define how these layers should be used by the module in the <code translate="no">forward()</code> method:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">WideAndDeep</code><code class="p">(</code><code class="n">nn</code><code class="o">.</code><code class="n">Module</code><code class="p">):</code>
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">n_features</code><code class="p">):</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="fm">__init__</code><code class="p">()</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">deep_stack</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">Sequential</code><code class="p">(</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="n">n_features</code><code class="p">,</code> <code class="mi">50</code><code class="p">),</code> <code class="n">nn</code><code class="o">.</code><code class="n">ReLU</code><code class="p">(),</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="mi">50</code><code class="p">,</code> <code class="mi">40</code><code class="p">),</code> <code class="n">nn</code><code class="o">.</code><code class="n">ReLU</code><code class="p">(),</code>
        <code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">output_layer</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="mi">40</code> <code class="o">+</code> <code class="n">n_features</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>

    <code class="k">def</code> <code class="nf">forward</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X</code><code class="p">):</code>
        <code class="n">deep_output</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">deep_stack</code><code class="p">(</code><code class="n">X</code><code class="p">)</code>
        <code class="n">wide_and_deep</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">X</code><code class="p">,</code> <code class="n">deep_output</code><code class="p">],</code> <code class="n">dim</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">output_layer</code><code class="p">(</code><code class="n">wide_and_deep</code><code class="p">)</code></pre>

<p>Notice that we can use any kind of module inside our custom module: in this example, we use an <code translate="no">nn.Sequential</code> module to build the “deep” part of our model (it’s actually not that deep; this is just a toy example). It’s the same MLP as earlier, except we separated the output layer because we need to feed it the concatenation of the model’s inputs and the deep part’s outputs. For this same reason, the output layer now has 40 + <code translate="no">n_features</code> inputs instead of just 40.</p>

<p>In the <code translate="no">forward()</code><a data-type="indexterm" data-primary="torch" data-secondary="forward()" id="id2343"/> method, we just feed the input <code translate="no">X</code> to the deep stack, concatenate the input and the deep stack’s output, and feed the result to the output layer.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Modules have a <code translate="no">children()</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.Module.children()" id="id2344"/><a data-type="indexterm" data-primary="torch" data-secondary="nn.Module.named_children()" id="id2345"/> method that returns an iterator over the module’s submodules (nonrecursively). There’s also a <code translate="no">named_children()</code> method. If your model has a variable number of submodules, you should store them in an <code translate="no">nn.ModuleList</code> or an <code translate="no">nn.ModuleDict</code>, which are returned by the <code translate="no">children()</code> and <code translate="no">named_children()</code> methods (as opposed to regular Python lists and dicts). Similarly, if your model has a variable number of parameters, you should store them in an <code translate="no">nn.ParameterList</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.ParameterList" id="id2346"/> or an <code translate="no">nn.ParameterDict</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.ParameterDict" id="id2347"/> to ensure they are returned by the <code translate="no">parameters()</code> and <code translate="no">named_parameters()</code> methods.</p>
</div>

<p>Now we can create an instance of our custom module, move it to the GPU, train it, evaluate it, and use it exactly like our previous models:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">torch</code><code class="o">.</code><code class="n">manual_seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">WideAndDeep</code><code class="p">(</code><code class="n">n_features</code><code class="p">)</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
<code class="n">learning_rate</code> <code class="o">=</code> <code class="mf">0.002</code>  <code class="c1"># the model changed, so did the optimal learning rate</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># train, evaluate, and use the model, exactly like earlier</code></pre>

<p>But what if you want to send a subset of the features through the wide path and a different subset (possibly overlapping) through the deep path, as illustrated in <a data-type="xref" href="#multiple_inputs_diagram">Figure 10-2</a>? In this case, one approach is to split the inputs inside the <code translate="no">forward()</code> method, for example:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">WideAndDeepV2</code><code class="p">(</code><code class="n">nn</code><code class="o">.</code><code class="n">Module</code><code class="p">):</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># same constructor as earlier, except with adjusted input sizes</code>

    <code class="k">def</code> <code class="nf">forward</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X</code><code class="p">):</code>
        <code class="n">X_wide</code> <code class="o">=</code> <code class="n">X</code><code class="p">[:,</code> <code class="p">:</code><code class="mi">5</code><code class="p">]</code>
        <code class="n">X_deep</code> <code class="o">=</code> <code class="n">X</code><code class="p">[:,</code> <code class="mi">2</code><code class="p">:]</code>
        <code class="n">deep_output</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">deep_stack</code><code class="p">(</code><code class="n">X_deep</code><code class="p">)</code>
        <code class="n">wide_and_deep</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">X_wide</code><code class="p">,</code> <code class="n">deep_output</code><code class="p">],</code> <code class="n">dim</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">output_layer</code><code class="p">(</code><code class="n">wide_and_deep</code><code class="p">)</code></pre>

<p>This works fine; however, in many cases it’s preferable to just let the model take two separate tensors as input. Let’s see why and how.</p>








<section data-type="sect2" data-pdf-bookmark="Building Models with Multiple Inputs"><div class="sect2" id="id168">
<h2>Building Models with Multiple Inputs</h2>

<p>Some<a data-type="indexterm" data-primary="inputs, multiple" id="xi_inputsmultiple107635_1"/><a data-type="indexterm" data-primary="multiple inputs" id="xi_multipleinputs107635_1"/> models require multiple inputs that cannot easily be combined into a single tensor. For example, the inputs may have a different number of dimensions (e.g., when you want to feed both images and text to the neural network). To make our Wide &amp; Deep model take two separate inputs, as shown in <a data-type="xref" href="#multiple_inputs_diagram">Figure 10-2</a>, we must start by changing the model’s <code translate="no">forward()</code> method:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">WideAndDeepV3</code><code class="p">(</code><code class="n">nn</code><code class="o">.</code><code class="n">Module</code><code class="p">):</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># same as WideAndDeepV2</code>

    <code class="k">def</code> <code class="nf">forward</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X_wide</code><code class="p">,</code> <code class="n">X_deep</code><code class="p">):</code>
        <code class="n">deep_output</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">deep_stack</code><code class="p">(</code><code class="n">X_deep</code><code class="p">)</code>
        <code class="n">wide_and_deep</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">X_wide</code><code class="p">,</code> <code class="n">deep_output</code><code class="p">],</code> <code class="n">dim</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">output_layer</code><code class="p">(</code><code class="n">wide_and_deep</code><code class="p">)</code></pre>

<figure class="width-30"><div id="multiple_inputs_diagram" class="figure">
<img src="assets/hmls_1002.png" alt="Diagram illustrating the flow of a neural network with wide and deep inputs, concatenated before feeding into the output layer." width="395" height="624"/>
<h6><span class="label">Figure 10-2. </span>Handling multiple inputs</h6>
</div></figure>

<p>Next, we need to create datasets that return the wide and deep inputs separately:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">train_data_wd</code> <code class="o">=</code> <code class="n">TensorDataset</code><code class="p">(</code><code class="n">X_train</code><code class="p">[:,</code> <code class="p">:</code><code class="mi">5</code><code class="p">],</code> <code class="n">X_train</code><code class="p">[:,</code> <code class="mi">2</code><code class="p">:],</code> <code class="n">y_train</code><code class="p">)</code>
<code class="n">train_loader_wd</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">train_data_wd</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">32</code><code class="p">,</code> <code class="n">shuffle</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># same for the validation set and test set</code></pre>

<p>Since the data loaders now return three tensors instead of two at each iteration, we need to update the main loop in the evaluation and training functions:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">X_batch_wide</code><code class="p">,</code> <code class="n">X_batch_deep</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="n">data_loader</code><code class="p">:</code>
    <code class="n">X_batch_wide</code> <code class="o">=</code> <code class="n">X_batch_wide</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
    <code class="n">X_batch_deep</code> <code class="o">=</code> <code class="n">X_batch_deep</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
    <code class="n">y_batch</code> <code class="o">=</code> <code class="n">y_batch</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
    <code class="n">y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">X_batch_wide</code><code class="p">,</code> <code class="n">X_batch_deep</code><code class="p">)</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># the rest of the function is unchanged</code></pre>

<p>Alternatively, since the order of the inputs matches the order of the <code translate="no">forward()</code> method’s arguments, we can use Python’s <code translate="no">*</code> operator<a data-type="indexterm" data-primary="* operator" id="id2348"/> to unpack all the inputs returned by the <code translate="no">data_loader</code> and pass them to the model. The advantage of this implementation is that it will work with models that take any number of inputs, not just two, as long as the order is correct:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="o">*</code><code class="n">X_batch_inputs</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="n">data_loader</code><code class="p">:</code>
    <code class="n">X_batch_inputs</code> <code class="o">=</code> <code class="p">[</code><code class="n">X</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code> <code class="k">for</code> <code class="n">X</code> <code class="ow">in</code> <code class="n">X_batch_inputs</code><code class="p">]</code>
    <code class="n">y_batch</code> <code class="o">=</code> <code class="n">y_batch</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
    <code class="n">y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="o">*</code><code class="n">X_batch_inputs</code><code class="p">)</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code></pre>

<p>When your model has many inputs, it’s easy to make a mistake and mix up the order of the inputs, which can lead to hard-to-debug issues. To avoid this, it can be a good idea to name each input. For this, you can define a custom dataset that returns a dictionary from input names to input values, like this:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">WideAndDeepDataset</code><code class="p">(</code><code class="n">torch</code><code class="o">.</code><code class="n">utils</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">Dataset</code><code class="p">):</code>
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X_wide</code><code class="p">,</code> <code class="n">X_deep</code><code class="p">,</code> <code class="n">y</code><code class="p">):</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">X_wide</code> <code class="o">=</code> <code class="n">X_wide</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">X_deep</code> <code class="o">=</code> <code class="n">X_deep</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">y</code> <code class="o">=</code> <code class="n">y</code>

    <code class="k">def</code> <code class="fm">__len__</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>
        <code class="k">return</code> <code class="nb">len</code><code class="p">(</code><code class="bp">self</code><code class="o">.</code><code class="n">y</code><code class="p">)</code>

    <code class="k">def</code> <code class="fm">__getitem__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">idx</code><code class="p">):</code>
        <code class="n">input_dict</code> <code class="o">=</code> <code class="p">{</code><code class="s2">"X_wide"</code><code class="p">:</code> <code class="bp">self</code><code class="o">.</code><code class="n">X_wide</code><code class="p">[</code><code class="n">idx</code><code class="p">],</code> <code class="s2">"X_deep"</code><code class="p">:</code> <code class="bp">self</code><code class="o">.</code><code class="n">X_deep</code><code class="p">[</code><code class="n">idx</code><code class="p">]}</code>
        <code class="k">return</code> <code class="n">input_dict</code><code class="p">,</code> <code class="bp">self</code><code class="o">.</code><code class="n">y</code><code class="p">[</code><code class="n">idx</code><code class="p">]</code></pre>

<p>Then create the datasets and data loaders:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">train_data_named</code> <code class="o">=</code> <code class="n">WideAndDeepDataset</code><code class="p">(</code>
    <code class="n">X_wide</code><code class="o">=</code><code class="n">X_train</code><code class="p">[:,</code> <code class="p">:</code><code class="mi">5</code><code class="p">],</code> <code class="n">X_deep</code><code class="o">=</code><code class="n">X_train</code><code class="p">[:,</code> <code class="mi">2</code><code class="p">:],</code> <code class="n">y</code><code class="o">=</code><code class="n">y_train</code><code class="p">)</code>
<code class="n">train_loader_named</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">train_data_named</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">32</code><code class="p">,</code> <code class="n">shuffle</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># same for the validation set and test set</code></pre>

<p>Once again, we also need to update the main loop in the evaluation and training functions:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">inputs</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="n">data_loader</code><code class="p">:</code>
    <code class="n">inputs</code> <code class="o">=</code> <code class="p">{</code><code class="n">name</code><code class="p">:</code> <code class="n">X</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code> <code class="k">for</code> <code class="n">name</code><code class="p">,</code> <code class="n">X</code> <code class="ow">in</code> <code class="n">inputs</code><code class="o">.</code><code class="n">items</code><code class="p">()}</code>
    <code class="n">y_batch</code> <code class="o">=</code> <code class="n">y_batch</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
    <code class="n">y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">X_wide</code><code class="o">=</code><code class="n">inputs</code><code class="p">[</code><code class="s2">"X_wide"</code><code class="p">],</code> <code class="n">X_deep</code><code class="o">=</code><code class="n">inputs</code><code class="p">[</code><code class="s2">"X_deep"</code><code class="p">])</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># the rest of the function is unchanged</code></pre>

<p>Alternatively, since all the input names match the <code translate="no">forward()</code> method’s argument names, we can use Python’s <code translate="no">**</code> operator<a data-type="indexterm" data-primary="** operator" id="id2349"/> to unpack all the tensors in the <code translate="no">inputs</code> dictionary and pass them as named arguments to the model: <code translate="no">y_pred = model(**inputs)</code>.</p>

<p>Now that you know how to build sequential and nonsequential models with one or more inputs, let’s look at models with multiple outputs.<a data-type="indexterm" data-startref="xi_inputsmultiple107635_1" id="id2350"/><a data-type="indexterm" data-startref="xi_multipleinputs107635_1" id="id2351"/><a data-type="indexterm" data-startref="xi_WideDeepneuralnetwork107034_1" id="id2352"/></p>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Building Models with Multiple Outputs"><div class="sect2" id="id169">
<h2>Building Models with Multiple Outputs</h2>

<p>There<a data-type="indexterm" data-primary="multiple outputs" id="xi_multipleoutputs108576_1"/><a data-type="indexterm" data-primary="outputs, multiple" id="xi_outputsmultiple108576_1"/> are many use cases where you may need a neural net with multiple outputs:</p>

<ul>
<li>
<p>The task may demand it. For instance, you may want to locate and classify the main object in a picture. This is both a regression task and a classification task.</p>
</li>
<li>
<p>Similarly, you may have multiple independent tasks based on the same data. Sure, you could train one neural network per task, but in many cases you will get better results on all tasks by training a single neural network with one output per task. This is because the neural network can learn features in the data that are useful across tasks. For example, you could perform <em>multitask classification</em><a data-type="indexterm" data-primary="multitask classification" id="id2353"/> on pictures of faces, using one output to classify the person’s facial expression (smiling, surprised, etc.) and another output to identify whether they are wearing glasses or not.</p>
</li>
<li>
<p>Another use case is regularization<a data-type="indexterm" data-primary="regularization" data-secondary="models with multiple outputs" id="id2354"/> (i.e., a training constraint whose objective is to reduce overfitting and thus improve the model’s ability to generalize). For example, you may want to add an auxiliary output<a data-type="indexterm" data-primary="auxiliary outputs" id="xi_auxiliaryoutputs10861213_1"/> in a neural network architecture (see <a data-type="xref" href="#multiple_outputs_diagram">Figure 10-3</a>) to ensure that the underlying part of the network learns something useful on its own, without relying on the rest of the network.</p>
</li>
</ul>

<figure><div id="multiple_outputs_diagram" class="figure">
<img src="assets/hmls_1003.png" alt="Diagram illustrating a neural network with an auxiliary output layer added for regularization, showcasing the flow from input layers through hidden layers to main and auxiliary outputs." width="607" height="621"/>
<h6><span class="label">Figure 10-3. </span>Handling multiple outputs, in this example to add an auxiliary output for regularization</h6>
</div></figure>

<p>Let’s add an auxiliary output to our Wide &amp; Deep model to ensure the deep part can make good predictions on its own. Since the deep stack’s output dimension is 40, and the targets have a single dimension, we must add an <code translate="no">nn.Linear</code> layer for the auxiliary output to go from 40 dimensions down to 1. We also need to make the <code translate="no">forward()</code> method compute the auxiliary output, and return both the main output and the auxiliary output:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">WideAndDeepV4</code><code class="p">(</code><code class="n">nn</code><code class="o">.</code><code class="n">Module</code><code class="p">):</code>
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">n_features</code><code class="p">):</code>
        <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># same as earlier</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">aux_output_layer</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="mi">40</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>

    <code class="k">def</code> <code class="nf">forward</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X_wide</code><code class="p">,</code> <code class="n">X_deep</code><code class="p">):</code>
        <code class="n">deep_output</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">deep_stack</code><code class="p">(</code><code class="n">X_deep</code><code class="p">)</code>
        <code class="n">wide_and_deep</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">X_wide</code><code class="p">,</code> <code class="n">deep_output</code><code class="p">],</code> <code class="n">dim</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
        <code class="n">main_output</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">output_layer</code><code class="p">(</code><code class="n">wide_and_deep</code><code class="p">)</code>
        <code class="n">aux_output</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">aux_output_layer</code><code class="p">(</code><code class="n">deep_output</code><code class="p">)</code>
        <code class="k">return</code> <code class="n">main_output</code><code class="p">,</code> <code class="n">aux_output</code></pre>

<p>Next, we need to update the main loop in the training function:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">inputs</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="n">train_loader</code><code class="p">:</code>
    <code class="n">y_pred</code><code class="p">,</code> <code class="n">y_pred_aux</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="o">**</code><code class="n">inputs</code><code class="p">)</code>
    <code class="n">main_loss</code> <code class="o">=</code> <code class="n">criterion</code><code class="p">(</code><code class="n">y_pred</code><code class="p">,</code> <code class="n">y_batch</code><code class="p">)</code>
    <code class="n">aux_loss</code> <code class="o">=</code> <code class="n">criterion</code><code class="p">(</code><code class="n">y_pred_aux</code><code class="p">,</code> <code class="n">y_batch</code><code class="p">)</code>
    <code class="n">loss</code> <code class="o">=</code> <code class="mf">0.8</code> <code class="o">*</code> <code class="n">main_loss</code> <code class="o">+</code> <code class="mf">0.2</code> <code class="o">*</code> <code class="n">aux_loss</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># the rest is unchanged</code></pre>

<p>Notice that the model now returns both the main predictions <code translate="no">y_pred</code> and the auxiliary predictions <code translate="no">y_pred_aux</code>. In this example, we can use the same targets and the same loss function to compute the main output’s loss and the auxiliary output’s loss. In other cases, you may have different targets and loss functions<a data-type="indexterm" data-primary="loss functions" data-secondary="and multiple outputs" data-secondary-sortas="multiple" id="id2355"/> for each output, in which case you would need to create a custom dataset to return all the necessary targets. Once we have a loss for each output, we must combine them into a single loss that will be minimized by gradient descent. In general, this final loss is just a weighted sum of all the output losses. In this example, we use a higher weight for the main loss (0.8), because that’s what we care about the most, and a lower weight for the auxiliary loss (0.2). This ratio is a regularization<a data-type="indexterm" data-primary="regularization" data-secondary="hyperparameters" id="id2356"/> hyperparameter<a data-type="indexterm" data-primary="hyperparameters" data-secondary="regularization" id="id2357"/> that you can tune.</p>

<p>We also need to update the main loop in the evaluation function. However, in this case we can just ignore the auxiliary output, since we only really care about the main output—the auxiliary output is just there for regularization during training:<a data-type="indexterm" data-startref="xi_auxiliaryoutputs10861213_1" id="id2358"/></p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">inputs</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="n">data_loader</code><code class="p">:</code>
    <code class="n">y_pred</code><code class="p">,</code> <code class="n">_</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="o">**</code><code class="n">inputs</code><code class="p">)</code>
    <code class="n">metric</code><code class="o">.</code><code class="n">update</code><code class="p">(</code><code class="n">y_pred</code><code class="p">,</code> <code class="n">y_batch</code><code class="p">)</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># the rest is unchanged</code></pre>

<p>Voilà! You can now build and train all sorts of neural net architectures, combining predefined modules and custom modules in any way you please, and with any number of inputs and outputs. The flexibility of neural networks is one of their main qualities. But so far we have only tackled a regression task, so let’s now turn to classification.<a data-type="indexterm" data-startref="xi_multipleoutputs108576_1" id="id2359"/><a data-type="indexterm" data-startref="xi_nonsequentialmodels107034_1" id="id2360"/><a data-type="indexterm" data-startref="xi_outputsmultiple108576_1" id="id2361"/><a data-type="indexterm" data-startref="xi_PyTorchnonsequentialmodels107034_1" id="id2362"/></p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Building an Image Classifier with PyTorch"><div class="sect1" id="id406">
<h1>Building an Image Classifier with PyTorch</h1>

<p>As<a data-type="indexterm" data-primary="PyTorch" data-secondary="image classifier" id="xi_PyTorchimageclassifier109123_1"/> in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>, we will tackle the Fashion MNIST dataset, so the first thing we need to do is to download the dataset. We could use the <code translate="no">fetch_openml()</code> function like we did in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>, but we will show another method instead, using the TorchVision library.</p>








<section data-type="sect2" data-pdf-bookmark="Using TorchVision to Load the Dataset"><div class="sect2" id="id170">
<h2>Using TorchVision to Load the Dataset</h2>

<p>The TorchVision library<a data-type="indexterm" data-primary="TorchVision" id="id2363"/><a data-type="indexterm" data-primary="convolutional neural networks (CNNs)" data-secondary="TorchVision pretrained models" id="id2364"/> is an important part of the PyTorch ecosystem: it provides many tools for computer vision, including utility functions to download common datasets, such as MNIST or Fashion MNIST<a data-type="indexterm" data-primary="Fashion MNIST dataset" data-secondary="TorchVision for loading" id="xi_FashionMNISTdatasetTorchVisionforloading10915203_1"/>, as well as pretrained models for various computer vision tasks (see <a data-type="xref" href="ch12.html#cnn_chapter">Chapter 12</a>), functions to transform images (e.g., crop, rotate, resize, etc.), and more. It is preinstalled on Colab, so let’s go ahead and use it to load Fashion MNIST. It is already split into a training set (60,000 images) and a test set (10,000 images), but we’ll hold out the last 5,000 images from the training set for validation, using PyTorch’s <code translate="no">random_split()</code> function:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">torchvision</code>
<code class="kn">import</code> <code class="nn">torchvision.transforms.v2</code> <code class="k">as</code> <code class="nn">T</code>

<code class="n">toTensor</code> <code class="o">=</code> <code class="n">T</code><code class="o">.</code><code class="n">Compose</code><code class="p">([</code><code class="n">T</code><code class="o">.</code><code class="n">ToImage</code><code class="p">(),</code> <code class="n">T</code><code class="o">.</code><code class="n">ToDtype</code><code class="p">(</code><code class="n">torch</code><code class="o">.</code><code class="n">float32</code><code class="p">,</code> <code class="n">scale</code><code class="o">=</code><code class="kc">True</code><code class="p">)])</code>

<code class="n">train_and_valid_data</code> <code class="o">=</code> <code class="n">torchvision</code><code class="o">.</code><code class="n">datasets</code><code class="o">.</code><code class="n">FashionMNIST</code><code class="p">(</code>
    <code class="n">root</code><code class="o">=</code><code class="s2">"datasets"</code><code class="p">,</code> <code class="n">train</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <code class="n">download</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <code class="n">transform</code><code class="o">=</code><code class="n">toTensor</code><code class="p">)</code>
<code class="n">test_data</code> <code class="o">=</code> <code class="n">torchvision</code><code class="o">.</code><code class="n">datasets</code><code class="o">.</code><code class="n">FashionMNIST</code><code class="p">(</code>
    <code class="n">root</code><code class="o">=</code><code class="s2">"datasets"</code><code class="p">,</code> <code class="n">train</code><code class="o">=</code><code class="kc">False</code><code class="p">,</code> <code class="n">download</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <code class="n">transform</code><code class="o">=</code><code class="n">toTensor</code><code class="p">)</code>

<code class="n">torch</code><code class="o">.</code><code class="n">manual_seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>
<code class="n">train_data</code><code class="p">,</code> <code class="n">valid_data</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">utils</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">random_split</code><code class="p">(</code>
    <code class="n">train_and_valid_data</code><code class="p">,</code> <code class="p">[</code><code class="mi">55_000</code><code class="p">,</code> <code class="mi">5_000</code><code class="p">])</code></pre>

<p>After the imports and before loading the datasets, we create a <code translate="no">toTensor</code><a data-type="indexterm" data-primary="torchvision" data-secondary="target_transform argument" id="id2365"/><a data-type="indexterm" data-primary="torchvision" data-secondary="transform argument" id="id2366"/> object. What’s that about? Well, by default, the <code translate="no">FashionMNIST</code> class loads images as PIL (Python Image Library) images, with integer pixel values ranging from 0 to 255. But we need PyTorch float tensors instead, with scaled pixel values. Luckily, TorchVision datasets accept a <code translate="no">transform</code> argument which lets you pass a preprocessing function that will get executed on the fly whenever the data is accessed (there’s also a <code translate="no">target_transform</code> argument if you need to preprocess the targets). TorchVision provides many transform objects that you can use for this (most of these transforms are PyTorch modules).</p>

<p>In this code, we create a <code translate="no">Compose</code><a data-type="indexterm" data-primary="torchvision" data-secondary="transforms.v2.Compose" id="id2367"/> transform to chain two transforms: a <code translate="no">ToImage</code> transform followed by a <code translate="no">ToDtype</code> transform. <code translate="no">ToImage</code><a data-type="indexterm" data-primary="torchvision" data-secondary="ToImage" id="id2368"/> converts various formats—including PIL images, NumPy arrays, and tensors—to TorchVision’s <code translate="no">Image</code> class, which is a subclass of <code translate="no">Tensor</code>. The <code translate="no">ToDtype</code><a data-type="indexterm" data-primary="torchvision" data-secondary="ToDtype" id="id2369"/> transform converts the data type, in this case to 32-bit floats. We also set its <code translate="no">scale</code> argument to <code translate="no">True</code> to ensure the values get scaled between 0.0 and 1.0.⁠<sup><a data-type="noteref" id="id2370-marker" href="ch10.html#id2370">12</a></sup></p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Version 1 of TorchVision’s transforms API is still available for backward compatibility and can be imported using <code translate="no">import</code> <code translate="no">torchvision.transforms</code>, However, you should use version 2 
<span class="keep-together">(<code translate="no">torchvision.transformers.v2</code>)</span> instead, since it’s faster and has more features.</p>
</div>

<p>Next, we load the dataset: first the training and validation data, then the test data. The <code translate="no">root</code> argument<a data-type="indexterm" data-primary="torchvision" data-secondary="root argument" id="id2371"/> is the path to the directory where TorchVision will create a subdirectory for the Fashion MNIST dataset. The <code translate="no">train</code> argument<a data-type="indexterm" data-primary="Datasets library" data-secondary="train argument" id="id2372"/> indicates whether you want to load the training set (<code translate="no">True</code> by default) or the test set. The <code translate="no">download</code> 
<span class="keep-together">argument</span> indicates whether to download the dataset if it cannot be found locally (<code translate="no">False</code> by default)<a data-type="indexterm" data-primary="torchvision" data-secondary="download argument" id="id2373"/>. And we also set <code translate="no">transform=toTensor</code> to use our custom preprocessing pipeline.</p>

<p>As usual, we must create data loaders:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">train_loader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">train_data</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">32</code><code class="p">,</code> <code class="n">shuffle</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">valid_loader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">valid_data</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">32</code><code class="p">)</code>
<code class="n">test_loader</code> <code class="o">=</code> <code class="n">DataLoader</code><code class="p">(</code><code class="n">test_data</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">32</code><code class="p">)</code></pre>

<p>Now let’s look at the first image in the training set:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X_sample</code><code class="p">,</code> <code class="n">y_sample</code> <code class="o">=</code> <code class="n">train_data</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X_sample</code><code class="o">.</code><code class="n">shape</code><code class="w"/>
<code class="go">torch.Size([1, 28, 28])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X_sample</code><code class="o">.</code><code class="n">dtype</code><code class="w"/>
<code class="go">torch.float32</code></pre>

<p>In <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>, each image was represented by a 1D array containing 784 pixel intensities, but now each image tensor has 3 dimensions, and its shape is: <code translate="no">[1, 28, 28]</code>. The first dimension is the <em>channel</em> dimension<a data-type="indexterm" data-primary="channel dimension" id="id2374"/>. For grayscale images, there is a single channel (color images usually have three channels, as we will see in <a data-type="xref" href="ch12.html#cnn_chapter">Chapter 12</a>). The other two dimensions are the height and width dimensions. For example, <code translate="no">X_sample[0, 2, 4]</code> represents the pixel located in channel 0, row 2, column 4. In Fashion MNIST, a larger value means a darker pixel.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>PyTorch expects the channel dimension to be first, while many other libraries, such as Matplotlib, PIL, TensorFlow, OpenCV, or Scikit-Image, expect it to be last. Always make sure to move the channel dimension to the right place, depending on the library you are using. <code translate="no">ToImage</code><a data-type="indexterm" data-primary="torchvision" data-secondary="ToImage" id="id2375"/> already took care of moving the channel dimension to the first position, otherwise we could have used the <code translate="no">torch.permute()</code> function.</p>
</div>

<p>As for the targets, they are integers from 0 to 9, and we can interpret them using the same <code translate="no">class_names</code> array as in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>. In fact, many datasets—including 
<span class="keep-together"><code translate="no">FashionMNIST</code>—have</span> a <code translate="no">classes</code> attribute<a data-type="indexterm" data-primary="classes attribute, TorchVision" id="id2376"/> containing the list of class names. For example, here’s how we can tell that the sample image represents an ankle boot:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">train_and_valid_data</code><code class="o">.</code><code class="n">classes</code><code class="p">[</code><code class="n">y_sample</code><code class="p">]</code><code class="w"/>
<code class="go">'Ankle boot'</code></pre>
</div></section>








<section data-type="sect2" data-pdf-bookmark="Building the Classifier"><div class="sect2" id="id171">
<h2>Building the Classifier</h2>

<p>Let’s <a data-type="indexterm" data-primary="classification" data-secondary="MLPs for" id="xi_classificationMLPsfor109757_1"/><a data-type="indexterm" data-primary="multilayer perceptrons (MLPs)" data-secondary="classification MLPs" id="xi_multilayerperceptronsMLPsclassificationMLPs109757_1"/>build a custom module for a classification MLP with two hidden layers:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">ImageClassifier</code><code class="p">(</code><code class="n">nn</code><code class="o">.</code><code class="n">Module</code><code class="p">):</code>
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">n_inputs</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">,</code> <code class="n">n_classes</code><code class="p">):</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="fm">__init__</code><code class="p">()</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">mlp</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">Sequential</code><code class="p">(</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">Flatten</code><code class="p">(),</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="n">n_inputs</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="p">),</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">ReLU</code><code class="p">(),</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="n">n_hidden1</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="p">),</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">ReLU</code><code class="p">(),</code>
            <code class="n">nn</code><code class="o">.</code><code class="n">Linear</code><code class="p">(</code><code class="n">n_hidden2</code><code class="p">,</code> <code class="n">n_classes</code><code class="p">)</code>
        <code class="p">)</code>

    <code class="k">def</code> <code class="nf">forward</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X</code><code class="p">):</code>
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">mlp</code><code class="p">(</code><code class="n">X</code><code class="p">)</code>

<code class="n">torch</code><code class="o">.</code><code class="n">manual_seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">ImageClassifier</code><code class="p">(</code><code class="n">n_inputs</code><code class="o">=</code><code class="mi">28</code> <code class="o">*</code> <code class="mi">28</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="o">=</code><code class="mi">300</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code>
                        <code class="n">n_classes</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>
<code class="n">xentropy</code> <code class="o">=</code> <code class="n">nn</code><code class="o">.</code><code class="n">CrossEntropyLoss</code><code class="p">()</code></pre>

<p>There are a few things to note in this code:</p>

<ul>
<li>
<p>First, the model is composed of a single sequence of layers, which is why we used the <code translate="no">nn.Sequential</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.Sequential" id="id2377"/> module. We did not have to create a custom module; we could have written <code translate="no">model = nn.Sequential(...)</code> instead, but it’s generally preferable to wrap your models in custom modules, as it makes your code easier to deploy and reuse, and it’s also easier to tune the hyperparameters.</p>
</li>
<li>
<p>The model starts with an <code translate="no">nn.Flatten</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.Flatten" id="id2378"/> layer: this layer does not have any parameters, it just reshapes each input sample to a single dimension, which is needed for the <code translate="no">nn.Linear</code> layers. For example, a batch of 32 Fashion MNIST images has a shape of <code translate="no">[32, 1, 28, 28]</code>, but after going through the <code translate="no">nn.Flatten</code> layer, it ends up with a shape of <code translate="no">[32, 784]</code> (since 28 × 28 = 784).</p>
</li>
<li>
<p>The first hidden layer must have the correct number of inputs (28 × 28 = 784), and the output layer must have the correct number of outputs (10, one per class).</p>
</li>
<li>
<p>We use a ReLU activation function<a data-type="indexterm" data-primary="activation functions" data-secondary="classification MLPs" id="id2379"/> after each hidden layer, and no activation function at all after the output layer.</p>
</li>
<li>
<p>Since this is a multiclass classification task, we use <code translate="no">nn.CrossEntropyLoss</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.CrossEntropyLoss" id="id2380"/>. It accepts either class indices as targets (as in this example), or class probabilities (such as one-hot vectors).</p>
</li>
</ul>
<div data-type="tip"><h6>Tip</h6>
<p>Shape errors are quite common, especially when getting started, so you should familiarize yourself with the error messages: try removing the <code translate="no">nn.Flatten</code> module, or try messing with the shape of the inputs and/or labels, and see the errors you get.</p>
</div>

<p>But wait! Didn’t we say in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a> that we should use the softmax activation function<a data-type="indexterm" data-primary="softmax activation function" data-secondary="image classifiers" id="id2381"/> on the output layer for multiclass classification tasks? Well it turns out that PyTorch’s <code translate="no">nn.CrossEntropyLoss</code> computes the cross-entropy loss directly from the logits (i.e., the class scores, introduced in <a data-type="xref" href="ch04.html#linear_models_chapter">Chapter 4</a>), rather than from the class probabilities. This bypasses some costly computations during training (e.g., logarithms and exponentials that cancel out), saving both compute and RAM. It’s also more numerically stable. However, the downside is that the model must output logits, which means that we will have to call the softmax function manually on the logits whenever we want class probabilities, as we will see shortly.<a data-type="indexterm" data-primary="binary classification tasks" id="id2382"/><a data-type="indexterm" data-primary="multiclass (multinomial) classification" id="id2383"/><a data-type="indexterm" data-primary="multilabel binary classification" id="id2384"/><a data-type="indexterm" data-primary="multinomial (multiclass) classification" id="id2385"/><a data-type="indexterm" data-primary="torch" data-secondary="nn.BCEWithLogitsLoss" id="id2386"/><a data-type="indexterm" data-primary="torch" data-secondary="nn.LogSoftmax" id="id2387"/><a data-type="indexterm" data-primary="torch" data-secondary="nn.NLLLoss" id="id2388"/></p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id2389">
<h1>Other Classification Losses</h1>
<p>For multiclass classification, another option is to add the <code translate="no">nn.LogSoftmax</code> activation function to the output layer, and then use the <code translate="no">nn.NLLLoss</code> (negative log-likelihood loss). The model then outputs log probabilities (rather than logits), and the loss computes the cross-entropy based on these log probabilities. Whenever you need actual estimated probabilities, just pass the log probabilities through the exponential function. This approach is a bit slower than using <code translate="no">nn.CrossEntropyLoss</code>, so it’s not used as often, but it can sometimes be useful if you want your model to output log probabilities, or when you wish to tweak the probability distribution before computing the loss.</p>

<p>For binary classification tasks, you must use a single output neuron in the output layer, and use the <code translate="no">nn.BCEWithLogitsLoss</code> (BCE stands for binary cross-entropy). The model outputs logits, so you must apply the sigmoid function to get estimated probabilities (for the positive class). Alternatively, you can add the <code translate="no">nn.Sigmoid</code> activation function to the output layer, and use the <code translate="no">nn.BCELoss</code>: the model will then output estimated probabilities directly (but it’s a bit slower and less numerically stable).</p>

<p>For multilabel binary classification, the only difference is that you must have one neuron per label in the output layer.</p>
</div></aside>

<p>Now we can train the model as usual (e.g., using the <code translate="no">train()</code> function with an <code translate="no">SGD</code> optimizer). To evaluate the model, we can use the <code translate="no">Accuracy</code><a data-type="indexterm" data-primary="TorchMetrics library" id="id2390"/> streaming metric from the <code translate="no">torchmetrics</code> library, and move it to the GPU:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">accuracy</code> <code class="o">=</code> <code class="n">torchmetrics</code><code class="o">.</code><code class="n">Accuracy</code><code class="p">(</code><code class="n">task</code><code class="o">=</code><code class="s2">"multiclass"</code><code class="p">,</code> <code class="n">num_classes</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Training the model will take a few minutes with a GPU (or much longer without one). Handling images requires significantly more compute and memory than handling low-dimensional data.</p>
</div>

<p>The model reaches around 92.8% accuracy on the training set, and 87.2% accuracy on the validation set (the results might differ a bit depending on the hardware accelerator you use). This means there’s a little bit of overfitting going on, so you may want to reduce the number of neurons or add some regularization (see <a data-type="xref" href="ch11.html#deep_chapter">Chapter 11</a>).</p>

<p>Now that the model is trained, we can use it to make predictions on new images. As an example, let’s make predictions for the first batch in the validation set, and look at the results for the first three images:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">model</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X_new</code><code class="p">,</code> <code class="n">y_new</code> <code class="o">=</code> <code class="nb">next</code><code class="p">(</code><code class="nb">iter</code><code class="p">(</code><code class="n">valid_loader</code><code class="p">))</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">X_new</code> <code class="o">=</code> <code class="n">X_new</code><code class="p">[:</code><code class="mi">3</code><code class="p">]</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="k">with</code> <code class="n">torch</code><code class="o">.</code><code class="n">no_grad</code><code class="p">():</code><code class="w"/>
<code class="gp">... </code>    <code class="n">y_pred_logits</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">X_new</code><code class="p">)</code><code class="w"/>
<code class="gp">...</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_pred</code> <code class="o">=</code> <code class="n">y_pred_logits</code><code class="o">.</code><code class="n">argmax</code><code class="p">(</code><code class="n">dim</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>  <code class="c1"># index of the largest logit</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_pred</code><code class="w"/>
<code class="go">tensor([7, 4, 2], device='cuda:0')</code>
<code class="gp">&gt;&gt;&gt; </code><code class="p">[</code><code class="n">train_and_valid_data</code><code class="o">.</code><code class="n">classes</code><code class="p">[</code><code class="n">index</code><code class="p">]</code> <code class="k">for</code> <code class="n">index</code> <code class="ow">in</code> <code class="n">y_pred</code><code class="p">]</code><code class="w"/>
<code class="go">['Sneaker', 'Coat', 'Pullover']</code></pre>

<p>For each image, the predicted class is the one with the highest logit. In this example, all three predictions are correct!</p>

<p class="pagebreak-before">But what if we want the model’s estimated probabilities? For this, we need to compute the softmax of the logits manually, since the model does not include the softmax activation function on the output layer, as we discussed earlier. We could create an <code translate="no">nn.Softmax</code> module and pass it the logits, but we can also just call the <code translate="no">softmax()</code> function, which is just one of many functions you will find in the <code translate="no">torch.nn.functional</code> module (by convention, this module is usually imported as <code translate="no">F</code>). It doesn’t make much difference, it just avoids creating a module instance that we don’t need:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">import</code> <code class="nn">torch.nn.functional</code> <code class="k">as</code> <code class="nn">F</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_proba</code> <code class="o">=</code> <code class="n">F</code><code class="o">.</code><code class="n">softmax</code><code class="p">(</code><code class="n">y_pred_logits</code><code class="p">,</code> <code class="n">dim</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_proba</code><code class="o">.</code><code class="n">round</code><code class="p">(</code><code class="n">decimals</code><code class="o">=</code><code class="mi">3</code><code class="p">)</code><code class="w"/>
<code class="go">tensor([[0.000, 0.000, 0.000, 0.000, 0.000, 0.001, 0.000, 0.911, 0.000, 0.088],</code>
<code class="go">        [0.000, 0.000, 0.004, 0.000, 0.996, 0.000, 0.000, 0.000, 0.000, 0.000],</code>
<code class="go">        [0.000, 0.000, 0.625, 0.000, 0.335, 0.000, 0.039, 0.000, 0.000, 0.000]],</code>
<code class="go">       device='cuda:0')</code></pre>

<p>Just like in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>, the model is very confident about the first two predictions: 91.1% and 99.6%, respectively.</p>
<div data-type="tip"><h6>Tip</h6>
<p>If you wish to apply label smoothing<a data-type="indexterm" data-primary="label smoothing technique" id="id2391"/> during training, just set the <code translate="no">label_smoothing</code> hyperparameter<a data-type="indexterm" data-primary="hyperparameters" data-secondary="label_smoothing" id="id2392"/><a data-type="indexterm" data-primary="label_smoothing hyperparameter" id="id2393"/> of the <code translate="no">nn.CrossEntropyLoss</code> to the amount of smoothing you wish, between 0 and 1 (e.g., 0.05).</p>
</div>

<p>It can often be useful to get the model’s top <em>k</em> predictions. For this, we can use the <code translate="no">torch.topk()</code> function, which returns a tuple containing both the top <em>k</em> values and their indices:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">y_top4_logits</code><code class="p">,</code> <code class="n">y_top4_indices</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">topk</code><code class="p">(</code><code class="n">y_pred_logits</code><code class="p">,</code> <code class="n">k</code><code class="o">=</code><code class="mi">4</code><code class="p">,</code> <code class="n">dim</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_top4_probas</code> <code class="o">=</code> <code class="n">F</code><code class="o">.</code><code class="n">softmax</code><code class="p">(</code><code class="n">y_top4_logits</code><code class="p">,</code> <code class="n">dim</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="w"/>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_top4_probas</code><code class="o">.</code><code class="n">round</code><code class="p">(</code><code class="n">decimals</code><code class="o">=</code><code class="mi">3</code><code class="p">)</code><code class="w"/>
<code class="go">tensor([[0.9110, 0.0880, 0.0010, 0.0000],</code>
<code class="go">        [0.9960, 0.0040, 0.0000, 0.0000],</code>
<code class="go">        [0.6250, 0.3350, 0.0390, 0.0000]], device='cuda:0')</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">y_top4_indices</code><code class="w"/>
<code class="go">tensor([[7, 9, 5, 8],</code>
<code class="go">        [4, 2, 6, 0],</code>
<code class="go">        [2, 4, 6, 0]], device='cuda:0')</code></pre>

<p>For the first image, the model’s best guess is class 7 (Sneaker) with 91.1% confidence, its second best guess is class 9 (Ankle boot) with 8.8% confidence, and so on.</p>
<div data-type="tip"><h6>Tip</h6>
<p>The Fashion MNIST dataset is balanced, meaning it has the same number of instances of each class. When dealing with an unbalanced dataset<a data-type="indexterm" data-primary="unbalanced datasets" id="id2394"/>, you should generally give more weight to the rare classes and less weight to the frequent ones, or else your model will be biased toward the more frequent classes. You can do this by setting the <code translate="no">weight</code> argument of the <code translate="no">nn.CrossEntropyLoss</code><a data-type="indexterm" data-primary="torch" data-secondary="nn.CrossEntropyLoss" id="id2395"/>. For example, if there are three classes with 900, 700, and 400 instances, respectively (i.e., 2000 instances in total), then the respective weights should be 2000/900, 2000/700, and 2000/400. It’s preferable to normalize these weights to ensure they add up to 1, so in this example you would set <code translate="no">weight=torch.tensor([0.2205, 0.2835, 0.4961])</code>.</p>
</div>

<p>Your PyTorch superpowers are growing: you can now build, train, and evaluate both regression and classification neural nets. The next step is to learn how to fine-tune the model hyperparameters.<a data-type="indexterm" data-startref="xi_classificationMLPsfor109757_1" id="id2396"/><a data-type="indexterm" data-startref="xi_FashionMNISTdatasetTorchVisionforloading10915203_1" id="id2397"/><a data-type="indexterm" data-startref="xi_multilayerperceptronsMLPsclassificationMLPs109757_1" id="id2398"/><a data-type="indexterm" data-startref="xi_PyTorchimageclassifier109123_1" id="id2399"/></p>
</div></section>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Fine-Tuning Neural Network &#10;Hyperparameters with Optuna"><div class="sect1" id="id172">
<h1>Fine-Tuning Neural Network 
<span class="keep-together">Hyperparameters with Optuna</span></h1>

<p>We<a data-type="indexterm" data-primary="hyperparameters" data-secondary="fine-tuning with Optuna" id="xi_hyperparametersfinetuningwithOptuna1010913_1"/><a data-type="indexterm" data-primary="Optuna library" id="xi_Optuna1010913_1"/><a data-type="indexterm" data-primary="PyTorch" data-secondary="fine-tuning hyperparameters" id="xi_PyTorchfinetuninghyperparameters1010913_1"/> discussed how to manually pick reasonable values for your model’s hyperparameters in <a data-type="xref" href="ch09.html#ann_chapter">Chapter 9</a>, but what if you want to go further and automatically search for good hyperparameter values? One option is to convert your PyTorch model to a Scikit-Learn estimator, either by writing your own custom estimator class or by using a wrapper library such as Skorch (<a href="https://skorch.readthedocs.io" class="bare"><em class="hyperlink">https://skorch.readthedocs.io</em></a>), and then use <code translate="no">GridSearchCV</code> or <code translate="no">RandomizedSearchCV</code> to fine-tune the hyperparameters, as you did in <a data-type="xref" href="ch02.html#project_chapter">Chapter 2</a>.  However, you will usually get better results by using a dedicated fine-tuning library such as Optuna (<a href="https://optuna.org" class="bare"><em class="hyperlink">https://optuna.org</em></a>), Ray Tune (<a href="https://docs.ray.io" class="bare"><em class="hyperlink">https://docs.ray.io</em></a>), or Hyperopt (<a href="https://hyperopt.github.io/hyperopt" class="bare"><em class="hyperlink">https://hyperopt.github.io/hyperopt</em></a>). These libraries offer several powerful tuning strategies, and they’re highly customizable.</p>

<p>Let’s look at an example using Optuna. It is not preinstalled on Colab, so we need to install it using <code translate="no">%pip install optuna</code> (if you prefer to run the code locally, please follow the installation instructions at <a href="https://homl.info/install-p" class="bare"><em class="hyperlink">https://homl.info/install-p</em></a>). Let’s tune the learning rate and the number of neurons in the hidden layers (for simplicity, we will use the same number of neurons in both hidden layers). First, we need to define a function that Optuna will call many times to perform hyperparameter tuning: this function must take a <code translate="no">Trial</code> object and use it to ask Optuna for hyperparameter values, and then use these hyperparameter values to build and train a model. Finally, the function must evaluate the model (typically on the validation set) and return the metric:</p>

<pre translate="no" data-type="programlisting" data-code-language="python" class="less_space pagebreak-before"><code class="kn">import</code> <code class="nn">optuna</code>

<code class="k">def</code> <code class="nf">objective</code><code class="p">(</code><code class="n">trial</code><code class="p">):</code>
    <code class="n">learning_rate</code> <code class="o">=</code> <code class="n">trial</code><code class="o">.</code><code class="n">suggest_float</code><code class="p">(</code><code class="s2">"learning_rate"</code><code class="p">,</code> <code class="mf">1e-5</code><code class="p">,</code> <code class="mf">1e-1</code><code class="p">,</code> <code class="n">log</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
    <code class="n">n_hidden</code> <code class="o">=</code> <code class="n">trial</code><code class="o">.</code><code class="n">suggest_int</code><code class="p">(</code><code class="s2">"n_hidden"</code><code class="p">,</code> <code class="mi">20</code><code class="p">,</code> <code class="mi">300</code><code class="p">)</code>
    <code class="n">model</code> <code class="o">=</code> <code class="n">ImageClassifier</code><code class="p">(</code><code class="n">n_inputs</code><code class="o">=</code><code class="mi">1</code> <code class="o">*</code> <code class="mi">28</code> <code class="o">*</code> <code class="mi">28</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="o">=</code><code class="n">n_hidden</code><code class="p">,</code>
                            <code class="n">n_hidden2</code><code class="o">=</code><code class="n">n_hidden</code><code class="p">,</code> <code class="n">n_classes</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code><code class="o">.</code><code class="n">to</code><code class="p">(</code><code class="n">device</code><code class="p">)</code>
    <code class="n">optimizer</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">optim</code><code class="o">.</code><code class="n">SGD</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">parameters</code><code class="p">(),</code> <code class="n">lr</code><code class="o">=</code><code class="n">learning_rate</code><code class="p">)</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># train the model, then evaluate it on the validation set</code>
    <code class="k">return</code> <code class="n">validation_accuracy</code></pre>

<p>The <code translate="no">suggest_float()</code> and <code translate="no">suggest_int()</code> methods let us ask Optuna for a good hyperparameter value in a given range (Optuna also provides a <code translate="no">suggest_categorical()</code> method). For the <code translate="no">learning_rate</code> hyperparameter<a data-type="indexterm" data-primary="hyperparameters" data-secondary="learning rate" id="id2400"/><a data-type="indexterm" data-primary="learning_rate hyperparameter" id="id2401"/>, we ask for a value between 10<sup>–5</sup> and 10<sup>–1</sup>, and since we don’t know what the optimal scale is, we add <code translate="no">log=True</code>: this will make Optuna sample values from a log distribution, which makes it explore all possible scales. If we used the default uniform distribution instead, Optuna would be very unlikely to explore tiny values.</p>

<p>To start hyperparameter tuning, we create a <code translate="no">Study</code> object and call its <code translate="no">optimize()</code> method, passing it the objective function we just defined, as well as the number of trials to run (i.e., the number of times Optuna should call the objective function). Since our objective function returns a score—higher is better—we set <code translate="no">direction="maximize"</code> when creating the study (by default, Optuna tries to <em>minimize</em> the objective). To ensure reproducibility, we also set PyTorch’s random seed, as well as the random seed used by Optuna’s sampler:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">torch</code><code class="o">.</code><code class="n">manual_seed</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>
<code class="n">sampler</code> <code class="o">=</code> <code class="n">optuna</code><code class="o">.</code><code class="n">samplers</code><code class="o">.</code><code class="n">TPESampler</code><code class="p">(</code><code class="n">seed</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>
<code class="n">study</code> <code class="o">=</code> <code class="n">optuna</code><code class="o">.</code><code class="n">create_study</code><code class="p">(</code><code class="n">direction</code><code class="o">=</code><code class="s2">"maximize"</code><code class="p">,</code> <code class="n">sampler</code><code class="o">=</code><code class="n">sampler</code><code class="p">)</code>
<code class="n">study</code><code class="o">.</code><code class="n">optimize</code><code class="p">(</code><code class="n">objective</code><code class="p">,</code> <code class="n">n_trials</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code></pre>

<p>By default, Optuna uses the <em>Tree-structured Parzen Estimator</em> (TPE) algorithm<a data-type="indexterm" data-primary="TPE (Tree-structured Parzen Estimator) algorithm" id="id2402"/><a data-type="indexterm" data-primary="Tree-structured Parzen Estimator (TPE) algorithm" id="id2403"/> to optimize the hyperparameters: this is a sequential model-based optimization algorithm, meaning it learns from past results to better select promising hyperparameters. In other words, Optuna starts with random hyperparameter values, but it progressively focuses its search on the most promising regions of the hyperparameter space. This allows Optuna to find much better hyperparameters than random search in the same amount of time.</p>
<div data-type="tip"><h6>Tip</h6>
<p>You can add more hyperparameters to the search space, such as the batch size, the type of optimizer, the number of hidden layers, or the type of activation function, but remember that the search space will grow exponentially as you add more hyperparameters, so make sure it’s worth the extra search time and compute.</p>
</div>

<p>Once Optuna is done, you can look at the best hyperparameters it found, as well as the corresponding validation accuracy:</p>

<pre translate="no" data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">study</code><code class="o">.</code><code class="n">best_params</code><code class="w"/>
<code class="go">{'learning_rate': 0.08525846269447772, 'n_hidden': 116}</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">study</code><code class="o">.</code><code class="n">best_value</code><code class="w"/>
<code class="go">0.8867999911308289</code></pre>

<p>This is slightly better than the performance we got earlier. If you increase <code translate="no">n_trials</code> up to 50 or more, you will get much better results, but of course it will take hours to run. You can also just run <code translate="no">optimize()</code> repeatedly and stop once you are happy with the performance.</p>

<p>Optuna can also run trials in parallel across multiple machines, which can offer a near linear speed boost. For this, you will need to set up a SQL database (e.g., SQLite or PostgreSQL), and set the <code translate="no">storage</code> parameter of the <code translate="no">create_study()</code> function to point to that database. You also need to set the study’s name via the <code translate="no">study_name</code> parameter, and set <code translate="no">load_if_exists=True</code>. After that, you can copy your hyperparameter tuning script to multiple machines, and run it on each one (if you are using random seeds, make sure they are different on each machine). The scripts will work in parallel, reading and writing the trial results to the database. This has the additional benefit of keeping a full log of all your experiment results.</p>

<p>You may have noticed that we assumed that the <code translate="no">objective()</code> function had direct access to the training set and validation, presumably via global variables. In general, it’s much cleaner to pass them as extra arguments to the <code translate="no">objective()</code> function, for example, like this:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">objective</code><code class="p">(</code><code class="n">trial</code><code class="p">,</code> <code class="n">train_loader</code><code class="p">,</code> <code class="n">valid_loader</code><code class="p">):</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># the rest of the function remains the same as above</code>

<code class="n">objective_with_data</code> <code class="o">=</code> <code class="k">lambda</code> <code class="n">trial</code><code class="p">:</code> <code class="n">objective</code><code class="p">(</code>
    <code class="n">trial</code><code class="p">,</code> <code class="n">train_loader</code><code class="o">=</code><code class="n">train_loader</code><code class="p">,</code> <code class="n">valid_loader</code><code class="o">=</code><code class="n">valid_loader</code><code class="p">)</code>
<code class="n">study</code><code class="o">.</code><code class="n">optimize</code><code class="p">(</code><code class="n">objective_with_data</code><code class="p">,</code> <code class="n">n_trials</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code></pre>

<p>To set the extra arguments (the dataset loaders in this case), we just create a lambda function when needed and pass it to the <code translate="no">optimize()</code> method. Alternatively, you can use the <code translate="no">functools.partial()</code><a data-type="indexterm" data-primary="functools.partial()" id="id2404"/> function which creates a thin wrapper function around the given callable to provide default values for any number of arguments:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">functools</code> <code class="kn">import</code> <code class="n">partial</code>

<code class="n">objective_with_data</code> <code class="o">=</code> <code class="n">partial</code><code class="p">(</code><code class="n">objective</code><code class="p">,</code> <code class="n">train_loader</code><code class="o">=</code><code class="n">train_loader</code><code class="p">,</code>
                              <code class="n">valid_loader</code><code class="o">=</code><code class="n">valid_loader</code><code class="p">)</code></pre>

<p>It’s often possible to quickly tell that a trial is absolutely terrible: for example, when the loss shoots up during the first epoch, or when the model barely improves during the first few epochs. In such a case, it’s a good idea to interrupt training early to avoid wasting time and compute. You can simply return the model’s current validation accuracy and hope that Optuna will learn to avoid this region of hyperparameter space. Alternatively, you can interrupt training by raising the <code translate="no">optuna.TrialPruned</code> exception: this tells Optuna to ignore this trial altogether. In many cases, this leads to a more efficient search because it avoids polluting Optuna’s search algorithm with many noisy model evaluations.</p>

<p>Optuna comes with several <code translate="no">Pruner</code> classes that can detect and prune bad trials. For example, the <code translate="no">MedianPruner</code> will prune trials whose performance is below the median performance, at regular intervals during training. It starts pruning after a given number of trials have completed, controlled by <code translate="no">n_startup_trials</code> (5 by default). For each trial after that, it lets training start for a few epochs, controlled by <code translate="no">n_warmup_steps</code> (0 by default); then every few epochs (controlled by <code translate="no">interval_steps</code>), it ensures that the model’s performance is better than the median performance at the same epoch in past trials. To use this pruner, create an instance and pass it to the <code translate="no">create_study()</code> method:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">pruner</code> <code class="o">=</code> <code class="n">optuna</code><code class="o">.</code><code class="n">pruners</code><code class="o">.</code><code class="n">MedianPruner</code><code class="p">(</code><code class="n">n_startup_trials</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> <code class="n">n_warmup_steps</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code>
                                     <code class="n">interval_steps</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="n">study</code> <code class="o">=</code> <code class="n">optuna</code><code class="o">.</code><code class="n">create_study</code><code class="p">(</code><code class="n">direction</code><code class="o">=</code><code class="s2">"maximize"</code><code class="p">,</code> <code class="n">sampler</code><code class="o">=</code><code class="n">sampler</code><code class="p">,</code>
                            <code class="n">pruner</code><code class="o">=</code><code class="n">pruner</code><code class="p">)</code></pre>

<p>Then in the <code translate="no">objective()</code> function, add the following code so it runs after each epoch:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_epochs</code><code class="p">):</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># train the model for one epoch</code>
    <code class="n">validation_accuracy</code> <code class="o">=</code> <code class="p">[</code><code class="o">...</code><code class="p">]</code>  <code class="c1"># evaluate the model's validation accuracy</code>
    <code class="n">trial</code><code class="o">.</code><code class="n">report</code><code class="p">(</code><code class="n">validation_accuracy</code><code class="p">,</code> <code class="n">epoch</code><code class="p">)</code>
    <code class="k">if</code> <code class="n">trial</code><code class="o">.</code><code class="n">should_prune</code><code class="p">():</code>
        <code class="k">raise</code> <code class="n">optuna</code><code class="o">.</code><code class="n">TrialPruned</code><code class="p">()</code></pre>

<p>The <code translate="no">report()</code> method informs Optuna of the current validation accuracy and epoch, so it can determine whether the trial should be pruned. If <code translate="no">trial.should_prune()</code> returns <code translate="no">True</code>, we raise a <code translate="no">TrialPruned</code> exception.</p>
<div data-type="tip"><h6>Tip</h6>
<p>Optuna has many other features well worth exploring, such as visualization tools, persistence tools for trial results and other artifacts, a dashboard for human-in-the-loop optimization, and many other algorithms for hyperparameter search and trial pruning.</p>
</div>

<p>Once you are happy with the hyperparameters, you can train the model on the full training set (i.e., the training set plus the validation set), then evaluate it on the test set. Hopefully, it will perform great! If it does, you will want to save the model, then load it and use it in production: that’s the final topic of this chapter.<a data-type="indexterm" data-startref="xi_hyperparametersfinetuningwithOptuna1010913_1" id="id2405"/><a data-type="indexterm" data-startref="xi_Optuna1010913_1" id="id2406"/><a data-type="indexterm" data-startref="xi_PyTorchfinetuninghyperparameters1010913_1" id="id2407"/></p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Saving and Loading PyTorch Models"><div class="sect1" id="id173">
<h1>Saving and Loading PyTorch Models</h1>

<p>The<a data-type="indexterm" data-primary="PyTorch" data-secondary="saving and loading models" id="xi_PyTorchsavingandloadingmodels1011924_1"/> simplest way to save a PyTorch model is to use the <code translate="no">torch.save()</code><a data-type="indexterm" data-primary="torch" data-secondary="save()" id="id2408"/> method, passing it the model and the filepath. The model object is serialized using Python’s <code translate="no">pickle</code> module<a data-type="indexterm" data-primary="pickle" id="id2409"/> (which can convert objects into a sequence of bytes), then the result is compressed (zip) and saved to disk. The convention is to use the <code translate="no">.pt</code> or <code translate="no">.pth</code> extension for PyTorch files:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">torch</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="s2">"my_fashion_mnist.pt"</code><code class="p">)</code></pre>

<p>Simple! Now you can load the model (e.g., in your production code) just as easily:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">loaded_model</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="s2">"my_fashion_mnist.pt"</code><code class="p">,</code> <code class="n">weights_only</code><code class="o">=</code><code class="kc">False</code><code class="p">)</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>If your model uses any custom functions or classes (e.g., <code translate="no">ImageClassifier</code>), then <code translate="no">torch.save()</code> only saves references to them, not the code itself. Therefore you must ensure that any custom code is loaded in the Python environment before calling <code translate="no">torch.load()</code>. Also make sure to use the same version of the code to avoid any mismatch issues.</p>
</div>

<p>Setting <code translate="no">weights_only=False</code> ensures that the whole model object is loaded rather than just the model parameters. Then you can use the loaded model for inference. Don’t forget to switch to evaluation mode first using the <code translate="no">eval()</code> method:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">loaded_model</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code>
<code class="n">y_pred_logits</code> <code class="o">=</code> <code class="n">loaded_model</code><code class="p">(</code><code class="n">X_new</code><code class="p">)</code></pre>

<p>This is nice and easy, but unfortunately this approach has some very serious 
<span class="keep-together">drawbacks:</span></p>

<ul>
<li>
<p>Firstly, pickle’s serialization format is notoriously insecure. While <code translate="no">torch.save()</code> doesn’t save custom code, the pickle format supports it, so a hacker could inject malicious code in a saved PyTorch model: this code would be run automatically by the <code translate="no">pickle</code> module when the model is loaded. So always make sure you fully trust the model’s source before you load it this way.</p>
</li>
<li>
<p>Second, pickle is somewhat brittle. It can vary depending on the Python version (e.g., there were big changes between Python 3.7 and 3.8), and it saves specific filepaths to locate code, which can break if the loading environment has a different folder structure.</p>
</li>
</ul>

<p>To avoid these issues, it is recommended to save and load the model weights only, rather than the full model object:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">torch</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">state_dict</code><code class="p">(),</code> <code class="s2">"my_fashion_mnist_weights.pt"</code><code class="p">)</code></pre>

<p>The state dictionary returned by the <code translate="no">state_dict()</code> method is just a Python <code translate="no">OrderedDict</code> containing an entry for each parameter returned by the <code translate="no">named_parameters()</code> method. It also contains buffers<a data-type="indexterm" data-primary="buffers, PyTorch" id="id2410"/>, if the model has any: a buffer is just a regular tensor that was registered with the model (or any of its submodules) using the <code translate="no">register_buffer()</code> method. Buffers hold extra data that needs to be stored along with the model, but that is not a model parameter. We will see an example in <a data-type="xref" href="ch11.html#deep_chapter">Chapter 11</a> with the batch-norm layer.</p>

<p>To load these weights, we must first create a model with the exact same structure, then load the weights using <code translate="no">torch.load()</code> with <code translate="no">weights_only=True</code>, and finally call the model’s <code translate="no">load_state_dict()</code> method with the loaded weights:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">new_model</code> <code class="o">=</code> <code class="n">ImageClassifier</code><code class="p">(</code><code class="n">n_inputs</code><code class="o">=</code><code class="mi">1</code> <code class="o">*</code> <code class="mi">28</code> <code class="o">*</code> <code class="mi">28</code><code class="p">,</code> <code class="n">n_hidden1</code><code class="o">=</code><code class="mi">300</code><code class="p">,</code> <code class="n">n_hidden2</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code>
                            <code class="n">n_classes</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>
<code class="n">loaded_weights</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="s2">"my_fashion_mnist_weights.pt"</code><code class="p">,</code> <code class="n">weights_only</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">new_model</code><code class="o">.</code><code class="n">load_state_dict</code><code class="p">(</code><code class="n">loaded_weights</code><code class="p">)</code>
<code class="n">new_model</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code></pre>

<p>The saved model contains only data, and the <code translate="no">load()</code><a data-type="indexterm" data-primary="torch" data-secondary="load()" id="id2411"/> function makes sure of that, so this is safe, and also much less likely to break between Python versions or to cause any deployment issue. However, it only works if you are able to create the exact same model architecture before loading the state dictionary. For this, you need to know the number of layers, the number of neurons per layer, and so on. It’s a good idea to save this information along with the state dictionary<a data-type="indexterm" data-primary="state dictionary" id="id2412"/>:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">model_data</code> <code class="o">=</code> <code class="p">{</code>
    <code class="s2">"model_state_dict"</code><code class="p">:</code> <code class="n">model</code><code class="o">.</code><code class="n">state_dict</code><code class="p">(),</code>
    <code class="s2">"model_hyperparameters"</code><code class="p">:</code> <code class="p">{</code><code class="s2">"n_inputs"</code><code class="p">:</code> <code class="mi">1</code> <code class="o">*</code> <code class="mi">28</code> <code class="o">*</code> <code class="mi">28</code><code class="p">,</code> <code class="s2">"n_hidden1"</code><code class="p">:</code> <code class="mi">300</code><code class="p">,</code> <code class="p">[</code><code class="o">...</code><code class="p">]}</code>
<code class="p">}</code>
<code class="n">torch</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="n">model_data</code><code class="p">,</code> <code class="s2">"my_fashion_mnist_model.pt"</code><code class="p">)</code></pre>

<p>You can then load this dictionary, construct the model based on the saved hyperparameters, and load the state dictionary into this model:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">loaded_data</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="s2">"my_fashion_mnist_model.pt"</code><code class="p">,</code> <code class="n">weights_only</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">new_model</code> <code class="o">=</code> <code class="n">ImageClassifier</code><code class="p">(</code><code class="o">**</code><code class="n">loaded_data</code><code class="p">[</code><code class="s2">"model_hyperparameters"</code><code class="p">])</code>
<code class="n">new_model</code><code class="o">.</code><code class="n">load_state_dict</code><code class="p">(</code><code class="n">loaded_data</code><code class="p">[</code><code class="s2">"model_state_dict"</code><code class="p">])</code>
<code class="n">new_model</code><code class="o">.</code><code class="n">eval</code><code class="p">()</code></pre>

<p>If you want to be able to continue training where it left off, you will also need to save the optimizer’s state dictionary, its hyperparameters, and any other training information you may need, such as the current epoch and the loss history.</p>
<div data-type="tip"><h6>Tip</h6>
<p>The <code translate="no">safetensors</code><a data-type="indexterm" data-primary="safetensors library" id="id2413"/> library by Hugging Face is another popular way to save model weights safely.</p>
</div>

<p>There is yet another way to save and load your model: by first converting it to TorchScript. This also makes it possible to speed up your model’s inference.<a data-type="indexterm" data-startref="xi_PyTorchsavingandloadingmodels1011924_1" id="id2414"/></p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Compiling and Optimizing a PyTorch Model"><div class="sect1" id="id174">
<h1>Compiling and Optimizing a PyTorch Model</h1>

<p>PyTorch<a data-type="indexterm" data-primary="PyTorch" data-secondary="compiling and optimizing models" id="xi_PyTorchcompilingandoptimizingmodels1012698_1"/> comes with a very nice feature: it can automatically convert your model’s code to <em>TorchScript</em>,<a data-type="indexterm" data-primary="TorchScript" id="xi_TorchScript101269105_1"/> which you can think of as a statically typed subset of Python. There are two main benefits:</p>

<ul>
<li>
<p>First, TorchScript code can be compiled and optimized to produce significantly faster models. For example, multiple operations can often be fused into a single, more efficient operation. Operations on constants (e.g., 2 * 3) can be replaced with their result (e.g., 6); this is called <em>constant folding</em><a data-type="indexterm" data-primary="constant folding" id="id2415"/>. Unused code can be pruned, and so on.</p>
</li>
<li>
<p>Secondly, TorchScript can be serialized, saved to disk, and then loaded and executed in Python or in a C++ environment using the LibTorch library. This makes it possible to run PyTorch models on a wide range of devices, including embedded devices.</p>
</li>
</ul>

<p>There are two ways to convert a PyTorch model to TorchScript. The first way is called <em>tracing</em>.<a data-type="indexterm" data-primary="tracing" id="id2416"/> PyTorch just runs your model with some sample data, logs every operation that takes place, and then converts this log to TorchScript. This is done using the <code translate="no">torch.jit.trace()</code><a data-type="indexterm" data-primary="torch" data-secondary="jit.trace()" id="id2417"/> function:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">torchscript_model</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">jit</code><code class="o">.</code><code class="n">trace</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">X_new</code><code class="p">)</code></pre>

<p>This generally works well with static models whose <code translate="no">forward()</code> method doesn’t use conditionals or loops. However, if you try to trace a model that includes an <code translate="no">if</code> or <code translate="no">match</code> statement, then only the branch that is actually executed will be captured by TorchScript, which is generally not what you want. Similarly, if you use tracing with a model that contains a loop, then the TorchScript code will contain one copy of the operations within that loop for each iteration that was actually executed. Again, not what you generally want.</p>

<p>For such dynamic models, you will probably want to try another approach named <em>scripting</em>. <a data-type="indexterm" data-primary="scripting, TorchScript" id="id2418"/>In this case, PyTorch<a data-type="indexterm" data-primary="models, in PyTorch" data-see="PyTorch" id="id2419"/> actually parses your Python code directly and converts it to TorchScript. This method supports <code translate="no">if</code> statements and <code translate="no">while</code> loops properly, as long as the conditions are tensors. It also supports <code translate="no">for</code> loops when iterating over tensors. However, it only works on a subset of Python. For example, you cannot use global variables, Python generators (<code translate="no">yield</code>), complex list comprehensions, variable length function arguments (<code translate="no">*args</code> or <code translate="no">**kwargs</code>), or <code translate="no">match</code> statements. Moreover, types must be fixed (a function cannot return an integer in some cases and a float in others), and you can only call other functions if they also respect these rules, so no standard library, no third-party libraries, etc. (see the documentation for the full list of constraints). This sounds daunting, but for most real-world models, these rules are actually not too hard to respect, and you can save your model like this:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">torchscript_model</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">jit</code><code class="o">.</code><code class="n">script</code><code class="p">(</code><code class="n">model</code><code class="p">)</code></pre>

<p>Regardless of whether you use tracing or scripting to produce your TorchScript model, you can then further optimize it:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">optimized_model</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">jit</code><code class="o">.</code><code class="n">optimize_for_inference</code><code class="p">(</code><code class="n">torchscript_model</code><code class="p">)</code></pre>

<p>TorchScript models can only be used for inference, not for training, since the TorchScript environment doesn’t support gradient tracking or parameter updates.</p>

<p>Finally, you can save a TorchScript model using its <code translate="no">save()</code> method:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">torchscript_model</code><code class="o">.</code><code class="n">save</code><code class="p">(</code><code class="s1">'my_fashion_mnist_torchscript.pt'</code><code class="p">)</code></pre>

<p>And then load it using the <code translate="no">torch.jit.load()</code> function:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">loaded_torchscript_model</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">jit</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="s2">"my_fashion_mnist_torchscript.pt"</code><code class="p">)</code></pre>

<p>One important caveat: TorchScript is no longer under active development—bugs are fixed but no new features are added. It still works fine and it remains one of the best ways to run your PyTorch models in a C++ environment,⁠<sup><a data-type="noteref" id="id2420-marker" href="ch10.html#id2420">13</a></sup> but since the release of PyTorch 2.0 in March 2023, the PyTorch team has been focusing its efforts on a new set of compilation tools centered around the <code translate="no">torch.compile()</code><a data-type="indexterm" data-primary="torch" data-secondary="compile()" id="id2421"/> function, which you can use very easily:</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">compiled_model</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">model</code><code class="p">)</code></pre>

<p>The resulting model can now be used normally, and it will automatically be compiled and optimized when you use it. This is called Just-In-Time (JIT) compilation<a data-type="indexterm" data-primary="Just-In-Time (JIT) compilation" id="id2422"/>, as opposed to Ahead-Of-Time (AOT) compilation. Under the hood, <code translate="no">torch.compile()</code> relies on <em>TorchDynamo</em><a data-type="indexterm" data-primary="Dynamo" id="id2423"/><a data-type="indexterm" data-primary="TorchDynamo" id="id2424"/> (or <em>Dynamo</em> for short) which hooks directly into Python bytecode to capture the model’s computation graph at inference time. Having access to the bytecode allows Dynamo to efficiently and reliably capture the computation graph, properly handling conditionals and loops, while also benefiting from dynamic information that can be used to better optimize the model. The actual compilation and optimization is performed by default by a backend component named <em>TorchInductor</em><a data-type="indexterm" data-primary="TorchInductor" id="id2425"/>, which in turn relies on the Triton language to generate highly efficient GPU code (Nvidia only), or on the OpenMP API for CPU optimization. PyTorch 2.x offers a few other optimization backends<a data-type="indexterm" data-primary="optimization backends" id="id2426"/>, including the XLA backend<a data-type="indexterm" data-primary="XLA backend" id="id2427"/> for Google’s TPU devices: just set <code translate="no">device="xla"</code> when calling <code translate="no">torch.compile()</code>.<a data-type="indexterm" data-startref="xi_TorchScript101269105_1" id="id2428"/></p>

<p>With that, you now have all the tools you need to start building and training complex and efficient neural networks. I hope you enjoyed this introduction to PyTorch! We covered a lot, but the adventure is only beginning: in the next chapter we will discuss techniques to train very deep nets. After that, we will dive into other popular neural network architectures: convolutional neural networks for image processing, recurrent neural networks for sequential data, transformers for text (and much more), autoencoders for representation learning, and generative adversarial networks and diffusion models to generate data.⁠<sup><a data-type="noteref" id="id2429-marker" href="ch10.html#id2429">14</a></sup> Then we will visit reinforcement learning to train autonomous agents, and finally, we will learn more about deploying and optimizing your PyTorch models. Let’s go!<a data-type="indexterm" data-startref="xi_PyTorch1048_1" id="id2430"/><a data-type="indexterm" data-startref="xi_PyTorchcompilingandoptimizingmodels1012698_1" id="id2431"/></p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Exercises"><div class="sect1" id="id734">
<h1>Exercises</h1>
<ol>
<li>
<p>PyTorch is similar to NumPy is many ways, but it offers some extra features. Can you name the most important ones?</p>
</li>
<li>
<p>What is the difference between <code translate="no">torch.exp()</code> and <code translate="no">torch.exp_()</code>, or between <code translate="no">torch.relu()</code> and <code translate="no">torch.relu_()</code>?</p>
</li>
<li>
<p>What are two ways to create a new tensor on the GPU?</p>
</li>
<li>
<p>What are three ways to perform tensor computations without using autograd?</p>
</li>
<li>
<p>Will the following code cause a <code translate="no">RuntimeError</code>? What if you replace the second line with <code translate="no">z = t.cos_().exp()</code>? And what if you replace it with <code translate="no">z = t.exp().cos_()</code>?</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">t</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="mf">2.0</code><code class="p">,</code> <code class="n">requires_grad</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">z</code> <code class="o">=</code> <code class="n">t</code><code class="o">.</code><code class="n">cos</code><code class="p">()</code><code class="o">.</code><code class="n">exp_</code><code class="p">()</code>
<code class="n">z</code><code class="o">.</code><code class="n">backward</code><code class="p">()</code></pre>

<p>How about the following code, will it cause an error? And what if you replace the third line with <code translate="no">w = v.cos_() * v.sin()</code>? Will <code translate="no">w</code> have the same value in both cases?</p>

<pre translate="no" data-type="programlisting" data-code-language="python"><code class="n">u</code> <code class="o">=</code> <code class="n">torch</code><code class="o">.</code><code class="n">tensor</code><code class="p">(</code><code class="mf">2.0</code><code class="p">,</code> <code class="n">requires_grad</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
<code class="n">v</code> <code class="o">=</code> <code class="n">u</code> <code class="o">+</code> <code class="mi">1</code>
<code class="n">w</code> <code class="o">=</code> <code class="n">v</code><code class="o">.</code><code class="n">cos</code><code class="p">()</code> <code class="o">*</code> <code class="n">v</code><code class="o">.</code><code class="n">sin_</code><code class="p">()</code>
<code class="n">w</code><code class="o">.</code><code class="n">backward</code><code class="p">()</code></pre>
</li>
<li>
<p>Suppose you create a <code translate="no">Linear(100, 200)</code> module. How many neurons does it have? What is the shape of is <code translate="no">weight</code> and <code translate="no">bias</code> parameters? What input shape does it expect? What output shape does it produce?</p>
</li>
<li>
<p>What are the main steps of a PyTorch training loop?</p>
</li>
<li>
<p>Why is it recommended to create the optimizer <em>after</em> the model is moved to the GPU?</p>
</li>
<li>
<p>What <code translate="no">DataLoader</code> options should you generally set to speed up training when using a GPU?</p>
</li>
<li>
<p>What are the main classification losses provided by PyTorch, and when should you use each of them?</p>
</li>
<li>
<p>Why is it important to call <code translate="no">model.train()</code> before training and <code translate="no">model.eval()</code> before evaluation?</p>
</li>
<li>
<p>What is the difference between <code translate="no">torch.jit.trace()</code> and <code translate="no">torch.jit.script()</code>?</p>
</li>
<li>
<p>Use autograd to find the gradient vector of f(<em>x</em>, <em>y</em>) = sin(<em>x</em><sup>2</sup> <em>y</em>) at the point (<em>x</em>, <em>y</em>) = (1.2, 3.4).</p>
</li>
<li>
<p>Create a custom <code translate="no">Dense</code> module that replicates the functionality of an <code translate="no">nn.Linear</code> module followed by an <code translate="no">nn.ReLU</code> module. Try implementing it first using the <code translate="no">nn.Linear</code> and <code translate="no">nn.ReLU</code> modules, and then reimplement it using <code translate="no">nn.Parameter</code> and the <code translate="no">relu()</code> function.</p>
</li>
<li>
<p>Build and train a classification MLP on the CoverType dataset:</p>
<ol>
<li>
<p>Load the dataset using <code translate="no">sklearn.datasets.fetch_covtype()</code> and create a custom PyTorch <code translate="no">Dataset</code> for this data.</p>
</li>
<li>
<p>Create data loaders for training, validation, and testing.</p>
</li>
<li>
<p>Build a custom MLP module to tackle this classification task. You can optionally use the custom <code translate="no">Dense</code> module from the previous exercise.</p>
</li>
<li>
<p>Train this model on the GPU, and try to reach 93% accuracy on the test set. For this, you will likely have to perform hyperparameter search to find the right number of layers and neurons per layer, a good learning rate and batch size, and so on. You can optionally use Optuna for this.</p>
</li>

</ol>
</li>

</ol>

<p>Solutions to these exercises are available at the end of this chapter’s notebook, at <a href="https://homl.info/colab-p" class="bare"><em class="hyperlink">https://homl.info/colab-p</em></a>.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="id2228"><sup><a href="ch10.html#id2228-marker">1</a></sup> To be fair, most of TensorFlow’s usability issues were fixed in version 2, and Google also launched JAX<a data-type="indexterm" data-primary="JAX" id="id2432"/>, which is well designed and extremely fast, so PyTorch still has some healthy competition. The good news is that the APIs of all these libraries have converged quite a bit, so switching from one to the other is much easier than it used to be.</p><p data-type="footnote" id="id2229"><sup><a href="ch10.html#id2229-marker">2</a></sup> There are things called tensors in mathematics and physics, but ML tensors are simpler: they’re really just multidimensional arrays for numerical computations, plus a few extra features.</p><p data-type="footnote" id="id2249"><sup><a href="ch10.html#id2249-marker">3</a></sup> CUDA<a data-type="indexterm" data-primary="CUDA library" id="id2433"/> is Nvidia’s proprietary platform to run code on its CUDA-compatible GPUs, and cuDNN<a data-type="indexterm" data-primary="cuDNN library" id="id2434"/> is a library built on CUDA to accelerate various deep neural network architectures.</p><p data-type="footnote" id="id2258"><sup><a href="ch10.html#id2258-marker">4</a></sup> The <code translate="no">%timeit</code> magic command only works in Jupyter notebooks and Colab, as well as in the iPython shell; in a regular Python shell or program, you can use the <code translate="no">timeit.timeit()</code> function instead.</p><p data-type="footnote" id="id2274"><sup><a href="ch10.html#id2274-marker">5</a></sup> For example, since the derivative of exp(<em>x</em>)<a data-type="indexterm" data-primary="torch" data-secondary="exp()" id="id2435"/> is equal to exp(<em>x</em>), it makes a lot of sense to store the output of this operation in the computation graph during the forward pass, then use this output during the backward pass to get the gradients: no need to store additional data, and no need to recompute exp(<em>x</em>).</p><p data-type="footnote" id="id2275"><sup><a href="ch10.html#id2275-marker">6</a></sup> For example, the derivative of abs(<em>x</em>)<a data-type="indexterm" data-primary="torch" data-secondary="abs()" id="id2436"/> is –1 when <em>x</em> &lt; 0 and +1 when <em>x</em> &gt; 0. If this operation saved its output in the computation graph, the backward pass would be unable to know whether <em>x</em> was positive or negative (since abs(<em>x</em>) is always positive), so it wouldn’t be able to compute the gradients. This is why this operation must save its input instead.</p><p data-type="footnote" id="id2276"><sup><a href="ch10.html#id2276-marker">7</a></sup> For example, the derivative of floor(<em>x</em>)<a data-type="indexterm" data-primary="torch" data-secondary="floor()" id="id2437"/> is always zero (at least for noninteger inputs), so the <code translate="no">floor()</code> operation just saves the shape of the inputs during the forward pass, then during the backward pass it produces gradients of the same shape but full of zeros. For integer inputs, autograd also returns zeros instead of NaN.</p><p data-type="footnote" id="id2281"><sup><a href="ch10.html#id2281-marker">8</a></sup> Column vectors (shape [<em>m</em>, 1]) and row vectors<a data-type="indexterm" data-primary="row vectors" id="id2438"/> (shape [1, <em>m</em>]) are often preferred over 1D vectors (shape [<em>m</em>]) in machine learning, as they avoid ambiguity in some operations, such as matrix multiplication or broadcasting, and they make the code more consistent whether there’s just one feature or more.</p><p data-type="footnote" id="id2282"><sup><a href="ch10.html#id2282-marker">9</a></sup> Just like in NumPy, the <code translate="no">reshape()</code><a data-type="indexterm" data-primary="torch" data-secondary="reshape()" id="id2439"/> method allows you to specify –1 for one of the dimensions. This dimension’s size is automatically calculated to ensure the new tensor has the same number of cells as the original.</p><p data-type="footnote" id="id2337"><sup><a href="ch10.html#id2337-marker">10</a></sup> The mean of the batch MSEs is equal to the overall MSE since all batches have the same size. Well, except the last batch, which is often smaller, but this makes very little difference.</p><p data-type="footnote" id="id2340"><sup><a href="ch10.html#id2340-marker">11</a></sup> Heng-Tze Cheng et al., <a href="https://homl.info/widedeep">“Wide &amp; Deep Learning for Recommender Systems”</a>, <em>Proceedings of the First Workshop on Deep Learning for Recommender Systems</em> (2016): 7–10.</p><p data-type="footnote" id="id2370"><sup><a href="ch10.html#id2370-marker">12</a></sup> TorchVision includes a <code translate="no">ToTensor</code><a data-type="indexterm" data-primary="torchvision" data-secondary="ToTensor" id="id2440"/> transform which does all this, but it’s deprecated so it’s recommended to use this pipeline instead.</p><p data-type="footnote" id="id2420"><sup><a href="ch10.html#id2420-marker">13</a></sup> Another popular option is exporting your PyTorch model to the open ONNX standard using <code translate="no">torch.onnx.export()</code>. The ONNX model<a data-type="indexterm" data-primary="ONNX models" id="id2441"/> can then be used for inference in a wide variety of environments.</p><p data-type="footnote" id="id2429"><sup><a href="ch10.html#id2429-marker">14</a></sup> A few extra ANN architectures are presented in the online notebook at <a href="https://homl.info/extra-anns" class="bare"><em class="hyperlink">https://homl.info/extra-anns</em></a>.</p></div></div></section></div></div></body></html>