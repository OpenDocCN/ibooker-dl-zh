- en: Chapter 2\. Fundamentals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [Chapter 1](ch01.html#foundations), I described the major conceptual building
    block for understanding deep learning: nested, continuous, differentiable functions.
    I showed how to represent these functions as computational graphs, with each node
    in a graph representing a single, simple function. In particular, I demonstrated
    that such a representation showed easily how to calculate the derivative of the
    output of the nested function with respect to its input: we simply take the derivatives
    of all the constituent functions, evaluate these derivatives at the input that
    these functions received, and then multiply all of the results together; this
    will result in a correct derivative for the nested function because of the chain
    rule. I illustrated that this does in fact work with some simple examples, with
    functions that took NumPy’s `ndarray`s as inputs and produced `ndarray`s as outputs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I showed that this method of computing derivatives works even when the function
    takes in multiple `ndarray`s as inputs and combines them via a *matrix multiplication*
    operation, which, unlike the other operations we saw, changes the shape of its
    inputs. Specifically, if one input to this operation—call the input *X*—is a B
    × N `ndarray`, and another input to this operation, *W*, is an N × M `ndarray`,
    then its output *P* is a B × M `ndarray`. While it isn’t clear what the derivative
    of such an operation would be, I showed that when a matrix multiplication *ν*(*X,
    W*) is included as a “constituent operation” in a nested function, we can still
    use a simple expression *in place of* its derivative to compute the derivatives
    of its inputs: specifically, the role of <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>W</mi> <mo>)</mo></mrow></mrow></math>
    can be filled by *X*^(*T*), and the role of <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow>
    <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow></mrow></math>
    can be played by *W*^(*T*).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll start translating these concepts into real-world applications,
    Specifically, we will:'
  prefs: []
  type: TYPE_NORMAL
- en: Express linear regression in terms of these building blocks
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Show that the reasoning around derivatives that we did in [Chapter 1](ch01.html#foundations)
    allows us to train this linear regression model
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extend this model (still using our building blocks) to a one-layer neural network
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, in [Chapter 3](ch03.html#deep_learning_from_scratch), it will be straightforward
    to use these same building blocks to build deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Before we dive into all this, though, let’s give an overview of *supervised
    learning*, the subset of machine learning that we’ll focus on as we see how to
    use neural networks to solve problems.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised Learning Overview
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At a high level, machine learning can be described as building algorithms that
    can uncover or “learn” *relationships* in data; supervised learning can be described
    as the subset of machine learning dedicated to finding relationships *between
    characteristics of the data that have already been measured*.^([1](ch02.html#idm45732627218840))
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’ll deal with a typical supervised learning problem that
    you might encounter in the real world: finding the relationship between characteristics
    of a house and the value of the house. Clearly, there is some relationship between
    characteristics such as the number of rooms, the square footage, or the proximity
    to schools and how desirable a house is to live in or own. At a high level, the
    aim of supervised learning is to uncover these relationships, given that we’ve
    *already measured* these characteristics.'
  prefs: []
  type: TYPE_NORMAL
- en: By “measure,” I mean that each characteristic has been defined precisely and
    represented as a number. Many characteristics of a house, such as the number of
    bedrooms, the square footage, and so on, naturally lend themselves to being represented
    as numbers, but if we had other, different kinds of information, such as natural
    language descriptions of the house’s neighborhood from TripAdvisor, this part
    of the problem would be much less straightforward, and doing the translation of
    this less-structured data into numbers in a reasonable way could make or break
    our ability to uncover relationships. In addition, for any concept that is ambiguously
    defined, such as the value of a house, we simply have to pick a single number
    to describe it; here, an obvious choice is to use the price of the house.^([2](ch02.html#idm45732627215256))
  prefs: []
  type: TYPE_NORMAL
- en: Once we’ve translated our “characteristics” into numbers, we have to decide
    what structure to use to represent these numbers. One that is nearly universal
    across machine learning and turns out to make computations easy is to represent
    each set of numbers for a single observation—for example, a single house—as a
    *row* of data, and then stack these rows on top of each other to form “batches”
    of data that will get fed into our models as two-dimensional `ndarray`s. Our models
    will then return predictions as output `ndarray`s with each prediction in a row,
    similarly stacked on top of each other, with one prediction for each observation
    in the batch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now for some definitions: we say that the length of each row in this `ndarray`
    is the number of *features* of our data. In general, a single characteristic can
    map to many features, a classic example being a characteristic that describes
    our data as belonging to one of several *categories*, such as being a red brick
    house, a tan brick house, or a slate house;^([3](ch02.html#idm45732627208776))
    in this specific case we might describe this single characteristic with three
    features. The process of mapping what we informally think of as characteristics
    of our observations into features is called *feature engineering*. I won’t spend
    much time discussing this process in this book; indeed, in this chapter we’ll
    deal with a problem in which we have 13 characteristics of each observation, and
    we simply represent each characteristic with a single numeric feature.'
  prefs: []
  type: TYPE_NORMAL
- en: I said that the goal of supervised learning is ultimately to uncover relationships
    between characteristics of data. In practice, we do this by choosing one characteristic
    that we want to predict from the others; we call this characteristic our *target*.
    The choice of which characteristic to use as the target is completely arbitrary
    and depends on the problem you are trying to solve. For example, if your goal
    is just to *describe* the relationship between the prices of houses and the number
    of rooms they have, you could do this by training a model with the prices of houses
    as the target and the number of rooms as a feature, or vice versa; either way,
    the resulting model will indeed contain a description of the relationship between
    these two characteristics, allowing you to say, for example, a higher number of
    rooms in a house is associated with higher prices. On the other hand, if your
    goal is to *predict* the prices of houses *for which no price information is available*,
    you have to choose the price as your target, so that you can ultimately feed the
    other information into your model once it is trained.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 2-1](#fig_02-01) shows this hierarchy of descriptions of supervised
    learning, from the highest-level description of finding relationships in data,
    to the lowest level of quantifying those relationships by training models to uncover
    numerical representations between the features and the target.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Supervised Learning overview](assets/dlfs_0201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. Supervised learning overview
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As mentioned, we’ll spend almost all our time on the level highlighted at the
    bottom of [Figure 2-1](#fig_02-01); nevertheless, in many problems, getting the
    parts at the top correct—collecting the right data, defining the problem you are
    trying to solve, and doing feature engineering—is much harder than the actual
    modeling. Still, since this book is focused on modeling—specifically, on understanding
    how deep learning models work—let’s return to that subject.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised Learning Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now we know at a high level what supervised learning models are trying to do—and
    as I alluded to earlier in the chapter, such models are just nested, mathematical
    functions. We spent the last chapter seeing how to represent such functions in
    terms of diagrams, math, and code, so now I can state the goal of supervised learning
    more precisely in terms of both math and code (I’ll show plenty of diagrams later):
    the goal is to *find* (a mathematical function) / (a function that takes an `ndarray`
    as input and produces an `ndarray` as output) that can (map characteristics of
    observations to the target) / (given an input `ndarray` containing the features
    we created, produce an output `ndarray` whose values are “close to” the `ndarray`
    containing the target).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, our data will be represented in a matrix *X* with *n* rows, each
    of which represents an observation with *k* features, all of which are numbers.
    Each row observation will be a vector, as in <math><mrow><msub><mi>x</mi> <mi>i</mi></msub>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi> <mrow><mi>i</mi><mn>1</mn></mrow></msub></mtd>
    <mtd><msub><mi>x</mi> <mrow><mi>i</mi><mn>2</mn></mrow></msub></mtd> <mtd><msub><mi>x</mi>
    <mrow><mi>i</mi><mn>3</mn></mrow></msub></mtd> <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi>
    <mrow><mi>i</mi><mi>k</mi></mrow></msub></mtd></mtr></mtable></mfenced></mrow></math>
    , and these observations will be stacked on top of one another to form a batch.
    For example, a batch of size 3 would look like:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>X</mi> <mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi> <mn>11</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>12</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>13</mn></msub></mtd>
    <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi> <mrow><mn>1</mn><mi>k</mi></mrow></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>21</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>22</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>23</mn></msub></mtd> <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi>
    <mrow><mn>2</mn><mi>k</mi></mrow></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi>
    <mn>31</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>32</mn></msub></mtd> <mtd><msub><mi>x</mi>
    <mn>33</mn></msub></mtd> <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi> <mrow><mn>3</mn><mi>k</mi></mrow></msub></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'For each batch of observations, we will have a corresponding batch of *targets*,
    each element of which is the target number for the corresponding observation.
    We can represent these in a one-dimensional vector:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>y</mi>
    <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>y</mi> <mn>2</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>y</mi> <mn>3</mn></msub></mtd></mtr></mtable></mfenced></math>
  prefs: []
  type: TYPE_NORMAL
- en: In terms of these arrays, our goal with supervised learning will be to use the
    tools I described in the last chapter to build a function that can take as input
    batches of observations with the structure of *X*[*batch*] and produce vectors
    of values *p*[i]—which we’ll interpret as “predictions”—that (for data in our
    particular dataset *X*, at least) are “close to the target values” *y*[i] for
    some reasonable measure of closeness.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we are ready to make all of this concrete and start building our first
    model for a real-world dataset. We’ll start with a straightforward model—*linear
    regression*—and show how to express it in terms of the building blocks from the
    prior chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Linear Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Linear regression is often shown as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>y</mi> <mi>i</mi></msub> <mo>=</mo> <msub><mi>β</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub> <mo>×</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>β</mi> <mi>n</mi></msub>
    <mo>×</mo> <msub><mi>x</mi> <mi>k</mi></msub> <mo>+</mo> <mi>ϵ</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This representation describes mathematically our belief that the numeric value
    of each target is a linear combination of the *k* features of *X*, plus the *β*[0]
    term to adjust the “baseline” value of the prediction (specifically, the prediction
    that will be made when the value of all of the features is 0).
  prefs: []
  type: TYPE_NORMAL
- en: This, of course, doesn’t give us much insight into how we would code this up
    so that we could “train” such a model. To do that, we have to translate this model
    into the language of the functions we saw in [Chapter 1](ch01.html#foundations);
    the best place to start is with a diagram.
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear Regression: A Diagram'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: How can we represent linear regression as a computational graph? We *could*
    break it down all the way to the individual elements, with each *x*[i] being multiplied
    by another element *w*[i] and then the results being added together, as in [Figure 2-2](#fig_02-02).
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear regression full](assets/dlfs_0202.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-2\. The operations of a linear regression shown at the level of individual
    multiplications and additions
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: But again, as we saw in [Chapter 1](ch01.html#foundations), if we can represent
    these operations as just a matrix multiplication, we’ll be able to write the function
    more concisely while still being able to correctly calculate the derivative of
    the output with respect to the input, which will allow us to train the model.
  prefs: []
  type: TYPE_NORMAL
- en: 'How can we do this? First, let’s handle the simpler scenario in which we don’t
    have an intercept term (*β*[0] shown previously). Note that we can represent the
    output of a linear regression model as the *dot product* of each observation vector
    <math><mrow><msub><mi>x</mi> <mi>i</mi></msub> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>1</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>2</mn></msub></mtd> <mtd><msub><mi>x</mi>
    <mn>3</mn></msub></mtd> <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi> <mi>k</mi></msub></mtd></mtr></mtable></mfenced></mrow></math>
    with another vector of parameters that we’ll call *W*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi>
    <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>w</mi> <mn>2</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mn>3</mn></msub></mtd></mtr> <mtr><mtd><mo>⋮</mo></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mi>k</mi></msub></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Our prediction would then simply be:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>p</mi> <mi>i</mi></msub> <mo>=</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>×</mo> <mi>W</mi> <mo>=</mo> <msub><mi>w</mi> <mn>1</mn></msub>
    <mo>×</mo> <msub><mi>x</mi> <mrow><mi>i</mi><mn>1</mn></mrow></msub> <mo>+</mo>
    <msub><mi>w</mi> <mn>2</mn></msub> <mo>×</mo> <msub><mi>x</mi> <mrow><mi>i</mi><mn>2</mn></mrow></msub>
    <mo>+</mo> <mo>...</mo> <mo>+</mo> <msub><mi>w</mi> <mi>k</mi></msub> <mo>×</mo>
    <msub><mi>x</mi> <mrow><mi>i</mi><mi>k</mi></mrow></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we can represent “generating the predictions” for a linear regression using
    a single operation: the dot product.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, when we want to make predictions using linear regression with
    a batch of observations, we can use another, single operation: the matrix multiplication.
    If we have a batch of size 3, for example:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>X</mi> <mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi> <mn>11</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>12</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>13</mn></msub></mtd>
    <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi> <mrow><mn>1</mn><mi>k</mi></mrow></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>21</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>22</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>23</mn></msub></mtd> <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi>
    <mrow><mn>2</mn><mi>k</mi></mrow></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi>
    <mn>31</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>32</mn></msub></mtd> <mtd><msub><mi>x</mi>
    <mn>33</mn></msub></mtd> <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi> <mrow><mn>3</mn><mi>k</mi></mrow></msub></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'then performing the *matrix multiplication* of this batch *X*[*batch*] with
    *W* gives a vector of predictions for the batch, as desired:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>p</mi> <mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub>
    <mo>=</mo> <msub><mi>X</mi> <mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub>
    <mo>×</mo> <mi>W</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>x</mi>
    <mn>11</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>12</mn></msub></mtd> <mtd><msub><mi>x</mi>
    <mn>13</mn></msub></mtd> <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi> <mrow><mn>1</mn><mi>k</mi></mrow></msub></mtd></mtr>
    <mtr><mtd><msub><mi>x</mi> <mn>21</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>22</mn></msub></mtd>
    <mtd><msub><mi>x</mi> <mn>23</mn></msub></mtd> <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi>
    <mrow><mn>2</mn><mi>k</mi></mrow></msub></mtd></mtr> <mtr><mtd><msub><mi>x</mi>
    <mn>31</mn></msub></mtd> <mtd><msub><mi>x</mi> <mn>32</mn></msub></mtd> <mtd><msub><mi>x</mi>
    <mn>33</mn></msub></mtd> <mtd><mo>...</mo></mtd> <mtd><msub><mi>x</mi> <mrow><mn>3</mn><mi>k</mi></mrow></msub></mtd></mtr></mtable></mfenced>
    <mo>×</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>w</mi> <mn>1</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>w</mi> <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>w</mi>
    <mn>3</mn></msub></mtd></mtr> <mtr><mtd><mo>⋮</mo></mtd></mtr> <mtr><mtd><msub><mi>w</mi>
    <mi>k</mi></msub></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]"
    open="["><mtable><mtr><mtd><mrow><msub><mi>x</mi> <mn>11</mn></msub> <mo>×</mo>
    <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>12</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>13</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo></mrow></mtd>
    <mtd><mrow><msub><mi>x</mi> <mrow><mn>1</mn><mi>k</mi></mrow></msub> <mo>×</mo>
    <msub><mi>w</mi> <mi>k</mi></msub></mrow></mtd></mtr> <mtr><mtd><mrow><msub><mi>x</mi>
    <mn>21</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>22</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>23</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>+</mo> <mo>...</mo>
    <mo>+</mo></mrow></mtd> <mtd><mrow><msub><mi>x</mi> <mrow><mn>2</mn><mi>k</mi></mrow></msub>
    <mo>×</mo> <msub><mi>w</mi> <mi>k</mi></msub></mrow></mtd></mtr> <mtr><mtd><mrow><msub><mi>x</mi>
    <mn>31</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>32</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>33</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>+</mo> <mo>...</mo>
    <mo>+</mo></mrow></mtd> <mtd><mrow><msub><mi>x</mi> <mrow><mn>3</mn><mi>k</mi></mrow></msub>
    <mo>×</mo> <msub><mi>w</mi> <mi>k</mi></msub></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>p</mi> <mn>1</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>p</mi> <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>p</mi>
    <mn>3</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: So generating predictions for a batch of observations in a linear regression
    can be done with a matrix multiplication. Next, I’ll show how to use this fact,
    along with the reasoning about derivatives from the prior chapter, to train this
    model.
  prefs: []
  type: TYPE_NORMAL
- en: “Training” this model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'What does it mean to “train” a model? At a high level, models^([4](ch02.html#idm45732626899528))
    take in data, combine them with *parameters* in some way, and produce predictions.
    For example, the linear regression model shown earlier takes in data *X* and parameters
    *W* and produces the predictions *p*[*batch*] using a matrix multiplication:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>p</mi> <mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>p</mi> <mn>1</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>p</mi> <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>p</mi>
    <mn>3</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'To train our model, however, we need another crucial piece of information:
    whether or not these predictions are good. To learn this, we bring in the vector
    of *targets* *y*[*batch*] associated with the batch of observations *X*[*batch*]
    fed into the function, and we compute a *single number* that is a function of
    *y*[*batch*] and *p*[*batch*] and that represents the model’s “penalty” for making
    the predictions that it did. A reasonable choice is *mean squared error*, which
    is simply the average squared value that our model’s predictions “missed” by:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>M</mi> <mi>S</mi> <mi>E</mi> <mrow><mo>(</mo>
    <msub><mi>p</mi> <mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub>
    <mo>,</mo> <msub><mi>y</mi> <mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi></mrow></msub>
    <mo>)</mo></mrow> <mo>=</mo> <mi>M</mi> <mi>S</mi> <mi>E</mi> <mrow><mo>(</mo>
    <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>p</mi> <mn>1</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>p</mi> <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>p</mi>
    <mn>3</mn></msub></mtd></mtr></mtable></mfenced> <mo>,</mo> <mfenced close="]"
    open="["><mtable><mtr><mtd><msub><mi>y</mi> <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>y</mi>
    <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>y</mi> <mn>3</mn></msub></mtd></mtr></mtable></mfenced>
    <mo>)</mo></mrow> <mo>=</mo> <mfrac><mrow><msup><mrow><mo>(</mo><msub><mi>y</mi>
    <mn>1</mn></msub> <mo>-</mo><msub><mi>p</mi> <mn>1</mn></msub> <mo>)</mo></mrow>
    <mn>2</mn></msup> <mo>+</mo><msup><mrow><mo>(</mo><msub><mi>y</mi> <mn>2</mn></msub>
    <mo>-</mo><msub><mi>p</mi> <mn>2</mn></msub> <mo>)</mo></mrow> <mn>2</mn></msup>
    <mo>+</mo><msup><mrow><mo>(</mo><msub><mi>y</mi> <mn>3</mn></msub> <mo>-</mo><msub><mi>p</mi>
    <mn>3</mn></msub> <mo>)</mo></mrow> <mn>2</mn></msup></mrow> <mn>3</mn></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Getting to this number, which we can call *L*, is key: once we have it, we
    can use all the techniques we saw in [Chapter 1](ch01.html#foundations) to compute
    the *gradient* of this number with respect to each element of *W*. Then *we can
    use these derivatives to update each element of W in the direction that would
    cause L to decrease*. Repeating this procedure many times, we hope, will “train”
    our model; in this chapter, we’ll see that this can indeed work in practice. To
    see clearly how to compute these gradients, we’ll complete the process of representing
    linear regression as a computational graph.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear Regression: A More Helpful Diagram (and the Math)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Figure 2-3](#fig_02-03) shows how to represent linear regression in terms
    of the diagrams from the last chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear regression simple](assets/dlfs_0203.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-3\. The linear regression equations expressed as a computational graph—the
    dark blue letters are the data inputs to the function, and the light blue W denotes
    the weights
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Finally, to reinforce that we’re still representing a nested mathematical function
    with this diagram, we could represent the loss value *L* that we ultimately compute
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>L</mi> <mo>=</mo> <mi>Λ</mi> <mo>(</mo> <mo>(</mo>
    <mi>ν</mi> <mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo> <mo>,</mo> <mi>Y</mi>
    <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Adding in the Intercept
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Representing models as diagrams shows us conceptually how we can add an intercept
    to the model. We simply add an extra step at the end that involves adding a “bias,”
    as shown in [Figure 2-4](#fig_02-04).
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear regression](assets/dlfs_0204.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-4\. The computational graph of linear regression, with the addition
    of a bias term at the end
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Here, though, we should reason mathematically about what is going on before
    moving on to the code; with the bias added, each element of our model’s prediction
    *p*[*i*] will be the dot product described earlier with the quantity *b* added
    to it:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>p</mi> <mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mo>_</mo><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mo>_</mo><mi>b</mi><mi>i</mi><mi>a</mi><mi>s</mi></mrow></msub>
    <mo>=</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mtext>dot</mtext> <mi>W</mi> <mo>+</mo>
    <mi>b</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><msub><mi>x</mi>
    <mn>11</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>12</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi>
    <mn>13</mn></msub> <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>+</mo> <mo>...</mo>
    <mo>+</mo></mrow></mtd> <mtd><mrow><msub><mi>x</mi> <mrow><mn>1</mn><mi>k</mi></mrow></msub>
    <mo>×</mo> <msub><mi>w</mi> <mi>k</mi></msub> <mo>+</mo> <mi>b</mi></mrow></mtd></mtr>
    <mtr><mtd><mrow><msub><mi>x</mi> <mn>21</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>22</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>23</mn></msub> <mo>×</mo> <msub><mi>w</mi>
    <mn>3</mn></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo></mrow></mtd> <mtd><mrow><msub><mi>x</mi>
    <mrow><mn>2</mn><mi>k</mi></mrow></msub> <mo>×</mo> <msub><mi>w</mi> <mi>k</mi></msub>
    <mo>+</mo> <mi>b</mi></mrow></mtd></mtr> <mtr><mtd><mrow><msub><mi>x</mi> <mn>31</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>32</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>x</mi> <mn>33</mn></msub>
    <mo>×</mo> <msub><mi>w</mi> <mn>3</mn></msub> <mo>+</mo> <mo>...</mo> <mo>+</mo></mrow></mtd>
    <mtd><mrow><msub><mi>x</mi> <mrow><mn>3</mn><mi>k</mi></mrow></msub> <mo>×</mo>
    <msub><mi>w</mi> <mi>k</mi></msub> <mo>+</mo> <mi>b</mi></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>p</mi> <mn>1</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>p</mi> <mn>2</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>p</mi>
    <mn>3</mn></msub></mtd></mtr></mtable></mfenced></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Note that because the intercept in linear regression should be just a single
    number rather than being different for each observation, the *same number* should
    get added to each observation of the input to the bias operation that is passed
    in; we’ll discuss what this means for computing the derivatives in a later section
    of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear Regression: The Code'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll now tie things together and code up the function that makes predictions
    and computes losses given batches of observations *X*[*batch*] and their corresponding
    targets *y*[*batch*]. Recall that computing derivatives for nested functions using
    the chain rule involves two sets of steps: first, we perform a “forward pass,”
    passing the input successively forward through a series of operations and saving
    the quantities computed as we go; then we use those quantities to compute the
    appropriate derivatives during the backward pass.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code does this, saving the quantities computed on the forward
    pass in a dictionary; furthermore, to differentiate between the quantities computed
    on the forward pass and the parameters themselves (which we’ll also need for the
    backward pass), our function will expect to receive a dictionary containing the
    parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Now we have all the pieces in place to start “training” this model. Next, we’ll
    cover exactly what this means and how we’ll do it.
  prefs: []
  type: TYPE_NORMAL
- en: Training the Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now going to use all the tools we learned in the last chapter to compute
    <math><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow> <mrow><mi>∂</mi><msub><mi>w</mi>
    <mi>i</mi></msub></mrow></mfrac></math> for every *w*[*i*] in *W*, as well as
    <math><mfrac><mrow><mi>∂</mi><mi>L</mi></mrow> <mrow><mi>∂</mi><mi>b</mi></mrow></mfrac></math>
    . How? Well, since the “forward pass” of this function was passing the input through
    a series of nested functions, the backward pass will simply involve computing
    the partial derivatives of each function, evaluating those derivatives at the
    functions’ inputs, and multiplying them together—and even though a matrix multiplication
    is involved, we’ll be able to handle this using the reasoning we covered in the
    last chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculating the Gradients: A Diagram'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Conceptually, we want something like what is depicted in [Figure 2-5](#fig_02-05).
  prefs: []
  type: TYPE_NORMAL
- en: '![Linear regression full](assets/dlfs_0205.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-5\. The backward pass through the linear regression computational graph
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We simply step backward, computing the derivative of each constituent function
    and evaluating those derivatives at the inputs that those functions received on
    the forward pass, and then multiplying these derivatives together at the end.
    This is straightforward enough, so let’s get into the details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculating the Gradients: The Math (and Some Code)'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From [Figure 2-5](#fig_02-05), we can see that the derivative product that
    we ultimately want to compute is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>P</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>P</mi> <mo>,</mo> <mi>Y</mi> <mo>)</mo></mrow> <mo>×</mo>
    <mfrac><mrow><mi>∂</mi><mi>α</mi></mrow> <mrow><mi>∂</mi><mi>N</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>N</mi> <mo>,</mo> <mi>B</mi> <mo>)</mo></mrow> <mo>×</mo>
    <mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: There are three components here; let’s compute each of them in turn.
  prefs: []
  type: TYPE_NORMAL
- en: 'First up: <math><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>P</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>P</mi> <mo>,</mo> <mi>Y</mi> <mo>)</mo></mrow></mrow></math>
    . Since <math><mrow><mi>Λ</mi> <mrow><mo>(</mo> <mi>P</mi> <mo>,</mo> <mi>Y</mi>
    <mo>)</mo></mrow> <mo>=</mo> <msup><mrow><mo>(</mo><mi>Y</mi><mo>-</mo><mi>P</mi><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></math> for each element in *Y* and *P*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>P</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>P</mi> <mo>,</mo> <mi>Y</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mn>1</mn> <mo>×</mo> <mrow><mo>(</mo> <mn>2</mn> <mo>×</mo> <mrow><mo>(</mo>
    <mi>Y</mi> <mo>-</mo> <mi>P</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'We’re jumping ahead of ourselves a bit, but note that coding this up would
    simply be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we have an expression involving matrices: <math><mrow><mfrac><mrow><mi>∂</mi><mi>α</mi></mrow>
    <mrow><mi>∂</mi><mi>N</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>,</mo>
    <mi>B</mi> <mo>)</mo></mrow></mrow></math> . But since *α* is just addition, the
    same logic that we reasoned through with numbers in the prior chapter applies
    here: increasing any element of *N* by one unit will increase <math><mrow><mi>P</mi>
    <mo>=</mo> <mi>α</mi> <mo>(</mo> <mi>N</mi> <mo>,</mo> <mi>B</mi> <mo>)</mo> <mo>=</mo>
    <mi>N</mi> <mo>+</mo> <mi>B</mi></mrow></math> by one unit. Thus, <math><mrow><mfrac><mrow><mi>∂</mi><mi>α</mi></mrow>
    <mrow><mi>∂</mi><mi>N</mi></mrow></mfrac> <mrow><mo>(</mo> <mi>N</mi> <mo>,</mo>
    <mi>B</mi> <mo>)</mo></mrow></mrow></math> is just a matrix of +1+s, of the same
    shape as *N*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Coding *this* expression, therefore, would simply be:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we have <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow></mrow></math>
    . As we discussed in detail in the last chapter, when computing derivatives of
    nested functions where one of the constituent functions is a matrix multiplication,
    we can act *as if*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>W</mi> <mo>)</mo></mrow> <mo>=</mo>
    <msup><mi>X</mi> <mi>T</mi></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'which in code is simply:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll do the same for the intercept term; since we are just adding it, the
    partial derivative of the intercept term with respect to the output is simply
    1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The last step is to simply multiply these together, making sure we use the correct
    order for the matrix multiplications involving `dNdW` and `dNdX` based on what
    we reasoned through at the end of the last chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculating the Gradients: The (Full) Code'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Recall that our goal is to take everything computed on or inputed into the
    forward pass—which, from the diagram in [Figure 2-5](#fig_02-05), will include
    *X*, *W*, *N*, *B*, *P*, and *y*—and compute <math><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac></math> and <math><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow>
    <mrow><mi>∂</mi><mi>B</mi></mrow></mfrac></math> . The following code does that,
    receiving *W* and *B* as inputs in a dictionary called `weights` and the rest
    of the quantities in a dictionary called `forward_info`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we simply compute the derivatives with respect to each operation
    and successively multiply them together, taking care that we do the matrix multiplication
    in the right order.^([5](ch02.html#idm45732626271592)) As we’ll see shortly, this
    actually works—and after the intuition we built up around the chain rule in the
    last chapter, this shouldn’t be too surprising.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'An implementation detail about those loss gradients: we’re storing them as
    a dictionary, with the names of the weights as keys and the amounts that increasing
    the weights affect the losses as values. The `weights` dictionary is structured
    the same way. Therefore, we’ll iterate through the weights in our model in the
    following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: There is nothing special about storing them in this way; if we stored them differently,
    we would simply iterate through them and refer to them differently.
  prefs: []
  type: TYPE_NORMAL
- en: Using These Gradients to Train the Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now we’ll simply run the following procedure over and over again:'
  prefs: []
  type: TYPE_NORMAL
- en: Select a batch of data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the forward pass of the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the backward pass of the model using the info computed on the forward pass.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the gradients computed on the backward pass to update the weights.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The [Jupyter Notebook](https://oreil.ly/2TDV5q9) for this chapter of the book
    includes a `train` function that codes this up. It isn’t too interesting; it simply
    implements the preceding steps and adds a few sensible things such as shuffling
    the data to ensure that it is fed through in a random order. The key lines, which
    get repeated inside of a `for` loop, are these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we run the `train` function for a certain number of *epochs*, or cycles
    through the entire training dataset, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `train` function returns `train_info`, a `Tuple`, one element of which is
    the parameters or *weights* that represent what the model has learned.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The terms “parameters” and “weights” are used interchangeably throughout deep
    learning, so we will use them interchangeably in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assessing Our Model: Training Set Versus Testing Set'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To understand whether our model uncovered relationships in our data, we have
    to introduce some terms and ways of thinking from statistics. We think of any
    dataset received as being a *sample* from a *population*. Our goal is always to
    find a model that uncovers relationships in the population, despite us seeing
    only a sample.
  prefs: []
  type: TYPE_NORMAL
- en: There is always a danger that we build a model that picks up relationships that
    exist in the sample but not in the population. For example, it might be the case
    in our sample that yellow slate houses with three bathrooms are relatively inexpensive,
    and a complicated neural network model we build could pick up on this relationship
    even though it may not exist in the population. This is a problem known as *overfitting*.
    How can we detect whether a model structure we use is likely to have this problem?
  prefs: []
  type: TYPE_NORMAL
- en: The solution is to split our sample into a *training set* and a *testing set*.
    We use the training data to train the model (that is, to iteratively update the
    weights), and then we evaluate the model on the testing set to estimate its performance.
  prefs: []
  type: TYPE_NORMAL
- en: The full logic here is that if our model was able to successfully pick up on
    relationships that generalize from the *training set* to *the rest of the sample*
    (our whole dataset), then it is likely that the same “model structure” will generalize
    from our *sample*—which, again, is our entire dataset—to the *population*, which
    is what we want.
  prefs: []
  type: TYPE_NORMAL
- en: 'Assessing Our Model: The Code'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With that understanding, let’s evaluate our model on the testing set. First,
    we’ll write a function to generate predictions by truncating the `forward_pass`
    function we saw previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we simply use the weights returned earlier from the `train` function and
    write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: How good are these predictions? Keep in mind that at this point we haven’t validated
    our seemingly strange approach of defining models as a series of operations, and
    training them by iteratively adjusting the parameters involved using the partial
    derivatives of the loss calculated with respect to the parameters using the chain
    rule; thus, we should be pleased if this approach works at all.
  prefs: []
  type: TYPE_NORMAL
- en: The first thing we can do to see whether our model worked is to make a plot
    with the model’s predictions on the x-axis and the actual values on the y-axis.
    If every point fell exactly on the 45-degree line, the model would be perfect.
    [Figure 2-6](#fig_02-06) shows a plot of our model’s predicted and actual values.
  prefs: []
  type: TYPE_NORMAL
- en: '![Custom prediction versus actual](assets/dlfs_0206.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-6\. Predicted versus actual values for our custom linear regression
    model
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Our plot looks pretty good, but let’s quantify how good the model is. There
    are a couple of common ways to do that:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the mean distance, in absolute value, between our model’s predictions
    and the actual values, a metric called *mean absolute error*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the mean squared distance between our model’s predictions and the
    actual values, a metric known as *root mean squared error*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The values for this particular model are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Root mean squared error is a particularly common metric since it is on the same
    scale as the target. If we divide this number by the mean value of the target,
    we can get a measure of how far off a prediction is, on average, from its actual
    value. Since the mean value of `y_test` is `22.0776`, we see that this model’s
    predictions of house prices are off by 5.0508 / 22.0776 ≅ 22.9% on average.
  prefs: []
  type: TYPE_NORMAL
- en: So are these numbers any good? In the [Jupyter Notebook](https://oreil.ly/2TDV5q9)
    containing the code for this chapter, I show that performing a linear regression
    on this dataset using the most popular Python library for machine learning, Sci-Kit
    Learn, results in a mean absolute error and root mean squared error of `3.5666`
    and `5.0482`, respectively, which are virtually identical to what we calculated
    in our “first-principles-based” linear regression previously. This should give
    you confidence that the approach we’ve been taking so far in this book is in fact
    a valid approach for reasoning about and training models! Both later in this chapter,
    and in the next chapter we’ll extend this approach to neural networks and deep
    learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Analyzing the Most Important Feature
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before beginning modeling, we scaled each feature of our data to have mean
    0 and standard deviation 1; this has computational advantages that we’ll discuss
    in more detail in [Chapter 4](ch04.html#extensions). A benefit of doing this that
    is specific to linear regression is that we can interpret the absolute values
    of the coefficients as corresponding to the importance of the different features
    to the model; a larger coefficient means that the feature is more important. Here
    are the coefficients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: The fact that the last coefficient is largest means that the last feature in
    the dataset is the most important one.
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 2-7](#fig_02-07), we plot this feature against our target.
  prefs: []
  type: TYPE_NORMAL
- en: '![Custom prediction versus actual](assets/dlfs_0207.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-7\. Most important feature versus target in custom linear regression
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We see that this feature is indeed strongly correlated with the target: as
    this feature increases, the value of the target decreases, and vice versa. However,
    this relationship is *not* linear. The expected amount that the target changes
    as the feature changes from –2 to –1 is *not* the same amount that it changes
    as the feature changes from 1 to 2\. We’ll come back to this later.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In [Figure 2-8](#fig_02-08), we overlay onto this plot the relationship between
    this feature and the *model predictions*. We’ll generate this by feeding the following
    data through our trained model:'
  prefs: []
  type: TYPE_NORMAL
- en: The values of all features set equal to their mean
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The values of the most important feature linearly interpolated over 40 steps
    from –1.5 to 3.5, which is roughly the range of this scaled feature in our data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Custom prediction versus actual](assets/dlfs_0208.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-8\. Most important feature versus target and predictions in custom
    linear regression
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'This figure shows (literally) a limitation of linear regression: despite the
    fact that there is a visually clear and “model-able” *non*linear relationship
    between this feature and the target, our model is only able to “learn” a linear
    relationship because of its intrinsic structure.'
  prefs: []
  type: TYPE_NORMAL
- en: To have our model learn a more complex, nonlinear relationship between our features
    and our target, we’re going to have to build a more complicated model than linear
    regression. But how? The answer will lead us, in a principles-based way, to building
    a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Neural Networks from Scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve just seen how to build and train a linear regression model from first
    principles. How can we extend this chain of reasoning to design a more complex
    model that can learn nonlinear relationships? The central idea is that we’ll first
    do *many* linear regressions, then feed the results through a nonlinear function,
    and finally do one last linear regression that ultimately makes the predictions.
    As it will turn out, we can reason through how to compute the gradients for this
    more complicated model in the same way we did for the linear regression model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: A Bunch of Linear Regressions'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'What does it mean to do “a bunch of linear regressions”? Well, doing one linear
    regression involved doing a matrix multiplication with a set of parameters: if
    our data *X* had dimensions `[batch_size, num_features]`, then we multiplied it
    by a weight matrix *W* with dimensions `[num_features, 1]` to get an output of
    dimension `[batch_size, 1]`; this output is, for each observation in the batch,
    simply a *weighted sum* of the original features. To do multiple linear regressions,
    we’ll simply multiply our input by a weight matrix with dimensions `[num_features,
    num_outputs]`, resulting in an output of dimensions `[batch_size, num_outputs]`;
    now, *for each observation*, we have `num_outputs` different weighted sums of
    the original features.'
  prefs: []
  type: TYPE_NORMAL
- en: What are these weighted sums? We should think of each of them as a “learned
    feature”—a combination of the original features that, once the network is trained,
    will represent its attempt to learn combinations of features that help it accurately
    predict house prices. How many learned features should we create? Let’s create
    13 of them, since we created 13 original features.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 2: A Nonlinear Function'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Next, we’ll feed each of these weighted sums through a *non*linear function;
    the first function we’ll try is the `sigmoid` function that was mentioned in [Chapter 1](ch01.html#foundations).
    As a refresher, [Figure 2-9](#fig_02-09) plots the `sigmoid` function.
  prefs: []
  type: TYPE_NORMAL
- en: '![Sigmoid](assets/dlfs_0209.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-9\. Sigmoid function plotted from x = –5 to x = 5
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Why is using this nonlinear function a good idea? Why not the `square` function
    *f*(*x*) = *x*², for example? There are a couple of reasons. First, we want the
    function we use here to be *monotonic* so that it “preserves” information about
    the numbers that were fed in. Let’s say that, given the date that was fed in,
    two of our linear regressions produced values of –3 and 3, respectively. Feeding
    these through the `square` function would then produce a value of 9 for each,
    so that any function that receives these numbers as inputs after they were fed
    through the `square` function would “lose” the information that one of them was
    originally –3 and the other was 3.
  prefs: []
  type: TYPE_NORMAL
- en: The second reason, of course, is that the function is nonlinear; this nonlinearity
    will enable our neural network to model the inherently nonlinear relationship
    between the features and the target.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the `sigmoid` function has the nice property that its derivative can
    be expressed in terms of the function itself:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>σ</mi> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>×</mo> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo>
    <mi>σ</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: We’ll make use of this shortly when we use the `sigmoid` function in the backward
    pass of our neural network.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Another Linear Regression'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Finally, we’ll take the resulting 13 elements—each of which is a combination
    of the original features, fed through the `sigmoid` function so that they all
    have values between 0 and 1—and feed them into a regular linear regression, using
    them the same way we used our original features previously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we’ll try training the *entire* resulting function in the same way we
    trained the standard linear regression earlier in this chapter: we’ll feed data
    through the model, use the chain rule to figure out how much increasing the weights
    would increase (or decrease) the loss, and then update the weights in the direction
    that decreases the loss at each iteration. Over time (we hope) we’ll end up with
    a more accurate model than before, one that has “learned” the inherent nonlinearity
    of the relationship between our features and our target.'
  prefs: []
  type: TYPE_NORMAL
- en: It might be tough to wrap your mind around what’s going on based on this description,
    so let’s look at an illustration.
  prefs: []
  type: TYPE_NORMAL
- en: Diagrams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Figure 2-10](#fig_02-10) is a diagram of what our more complicated model now
    looks like.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Neural network forward pass](assets/dlfs_0210.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-10\. Steps 1–3 translated into a computational graph of the kind we
    saw in [Chapter 1](ch01.html#foundations)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'You’ll see that we start with matrix multiplication and matrix addition, as
    before. Now let’s formalize some terminology that was mentioned previously: when
    we apply these operations in the course of a nested function, we’ll call the first
    matrix that we use to transform the input features the *weight* matrix, and we’ll
    call the second matrix, the one that is added to each resulting set of features,
    the *bias*. That’s why we’ll denote these as *W*[1] and *B*[1].'
  prefs: []
  type: TYPE_NORMAL
- en: After applying these operations, we’ll feed the results through a sigmoid function
    and then repeat the process again with *another* set of weights and biases—now
    called *W*[2] and *B*[2]—to get our final prediction, *P*.
  prefs: []
  type: TYPE_NORMAL
- en: Another diagram?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Does representing things in terms of these individual steps give you intuition
    for what is going on? This question gets at a key theme of this book: to fully
    understand neural networks, we have to see multiple representations, each one
    of which highlights a different aspect of how neural networks work. The representation
    in [Figure 2-10](#fig_02-10) doesn’t give much intuition about the “structure”
    of the network, but it does indicate clearly how to train such a model: on the
    backward pass, we’ll compute the partial derivative of each constituent function,
    evaluated at the input to that function, and then calculate the gradients of the
    loss with respect to each of the weights by simply multiplying all of these derivatives
    together—just as we saw in the simple chain rule examples from [Chapter 1](ch01.html#foundations).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Nevertheless, there is another, more standard way to represent a neural network
    like this: we could represent each of our original features as circles. Since
    we have 13 features, we need 13 circles. Then we need 13 more circles to represent
    the 13 outputs of the “linear regression-sigmoid” operation we’re doing. In addition,
    each of these circles is a function of all 13 of our original features, so we’ll
    need lines connecting all of the first set of 13 circles to all of the second
    set.^([6](ch02.html#idm45732625500232))'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, all of these 13 outputs are used to make a single final prediction,
    so we’ll draw one more circle to represent the final prediction and 13 lines showing
    that these “intermediate outputs” are “connected” to this final prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 2-11](#fig_02-11) shows the final diagram.^([7](ch02.html#idm45732625497016))'
  prefs: []
  type: TYPE_NORMAL
- en: '![Neural network representation 2](assets/dlfs_0211.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-11\. A more common (but in many ways less helpful) visual representation
    of a neural network
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'If you’ve read anything about neural networks before, you may have seen them
    represented like the diagram in [Figure 2-11](#fig_02-11): as circles with lines
    connecting them. While this representation does have some advantages—it lets you
    see “at a glance” what kind of neural network this is, how many layers it has,
    and so on—it doesn’t give any indication of the actual calculations involved,
    or of how such a network might be trained. Therefore, while this diagram is extremely
    important for you to see because you’ll see it in other places, it’s included
    here primarily so you can see the *connection* between it and the primary way
    we are representing neural networks: as boxes with lines connecting them, where
    each box represents a function that defines both what should happen on the forward
    pass for the model to make predictions and what should happen on the backward
    pass for the model to learn. We’ll see in the next chapter how to translate even
    more directly between these diagrams and code by coding each function as a Python
    class inheriting from a base `Operation` class—and speaking of code, let’s cover
    that next.'
  prefs: []
  type: TYPE_NORMAL
- en: Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In coding this up, we follow the same function structure as in the simpler
    linear regression function from earlier in the chapter—taking in `weights` as
    a dictionary and returning both the loss value and the `forward_info` dictionary,
    while replacing the internals with the operations specified in [Figure 2-10](#fig_02-10):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Even though we’re now dealing with a more complicated diagram, we’re still just
    going step by step through each operation, doing the appropriate computation,
    and saving the results in `forward_info` as we go.
  prefs: []
  type: TYPE_NORMAL
- en: 'Neural Networks: The Backward Pass'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The backward pass works the same way as in the simpler linear regression model
    from earlier in the chapter, just with more steps.
  prefs: []
  type: TYPE_NORMAL
- en: Diagram
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The steps, as a reminder, are:'
  prefs: []
  type: TYPE_NORMAL
- en: Compute the derivative of each operation and evaluate it at its input.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Multiply the results together.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As we’ll see yet again, this will work because of the chain rule. [Figure 2-12](#fig_02-12)
    shows all the partial derivatives we have to compute.
  prefs: []
  type: TYPE_NORMAL
- en: '![Neural network regression backward](assets/dlfs_0212.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-12\. The partial derivatives associated with each operation in the
    neural network that will be multiplied together on the backward pass
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Conceptually, we want to compute all these partial derivatives, tracing backward
    through our function, and then multiply them together to get the gradients of
    the loss with respect to each of the weights, just as we did for the linear regression
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Math (and code)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Table 2-1](#table-2-1) lists these partial derivatives and the lines in the
    code that correspond to each one.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-1\. Derivative table for neural network
  prefs: []
  type: TYPE_NORMAL
- en: '| Derivative | Code |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| <math><mrow><mfrac><mrow><mi>∂</mi><mi>Λ</mi></mrow> <mrow><mi>∂</mi><mi>P</mi></mrow></mfrac>
    <mrow><mo>(</mo> <mi>P</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow></mrow></math>
    | `dLdP = -(forward_info[*y*] - forward_info[*P*])` |'
  prefs: []
  type: TYPE_TB
- en: '| <math><mrow><mfrac><mrow><mi>∂</mi><mi>α</mi></mrow> <mrow><mi>∂</mi><msub><mi>M</mi>
    <mn>2</mn></msub></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>M</mi> <mn>2</mn></msub>
    <mo>,</mo> <msub><mi>B</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mrow></math>
    | `np.ones_like(forward_info[*M2*])` |'
  prefs: []
  type: TYPE_TB
- en: '| <math><mrow><mfrac><mrow><mi>∂</mi><mi>α</mi></mrow> <mrow><mi>∂</mi><msub><mi>B</mi>
    <mn>2</mn></msub></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>M</mi> <mn>2</mn></msub>
    <mo>,</mo> <msub><mi>B</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mrow></math>
    | `np.ones_like(weights[*B2*])` |'
  prefs: []
  type: TYPE_TB
- en: '| <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>W</mi>
    <mn>2</mn></msub></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>O</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>W</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mrow></math>
    | `dM2dW2 = np.transpose(forward_info[*O1*], (1, 0))` |'
  prefs: []
  type: TYPE_TB
- en: '| <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>O</mi>
    <mn>1</mn></msub></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>O</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>W</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mrow></math>
    | `dM2dO1 = np.transpose(weights[*W2*], (1, 0))` |'
  prefs: []
  type: TYPE_TB
- en: '| <math><mrow><mfrac><mrow><mi>∂</mi><mi>σ</mi></mrow> <mrow><mi>∂</mi><mi>u</mi></mrow></mfrac>
    <mrow><mo>(</mo> <msub><mi>N</mi> <mn>1</mn></msub> <mo>)</mo></mrow></mrow></math>
    | `dO1dN1 = sigmoid(forward_info[*N1*] × (1 - sigmoid(forward_info[*N1*])` |'
  prefs: []
  type: TYPE_TB
- en: '| <math><mrow><mfrac><mrow><mi>∂</mi><mi>α</mi></mrow> <mrow><mi>∂</mi><msub><mi>M</mi>
    <mn>1</mn></msub></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>M</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>B</mi> <mn>1</mn></msub> <mo>)</mo></mrow></mrow></math>
    | `dN1dM1 = np.ones_like(forward_info[*M1*])` |'
  prefs: []
  type: TYPE_TB
- en: '| <math><mrow><mfrac><mrow><mi>∂</mi><mi>α</mi></mrow> <mrow><mi>∂</mi><msub><mi>B</mi>
    <mn>1</mn></msub></mrow></mfrac> <mrow><mo>(</mo> <msub><mi>M</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>B</mi> <mn>1</mn></msub> <mo>)</mo></mrow></mrow></math>
    | `dN1dB1 = np.ones_like(weights[*B1*])` |'
  prefs: []
  type: TYPE_TB
- en: '| <math><mrow><mfrac><mrow><mi>∂</mi><mi>ν</mi></mrow> <mrow><mi>∂</mi><msub><mi>W</mi>
    <mn>1</mn></msub></mrow></mfrac> <mrow><mo>(</mo> <mi>X</mi> <mo>,</mo> <msub><mi>W</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow></mrow></math> | `dM1dW1 = np.transpose(forward_info[*X*],
    (1, 0))` |'
  prefs: []
  type: TYPE_TB
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The expressions we compute for the gradient of the loss with respect to the
    bias terms, `dLdB1` and `dLdB2`, will have to be summed along the rows to account
    for the fact that the same bias element is added to each row in the batch of data
    passed through. See [“Gradient of the Loss with Respect to the Bias Terms”](app01.html#gradient-loss-bias-terms)
    for details.
  prefs: []
  type: TYPE_NORMAL
- en: The overall loss gradient
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can see the full `loss_gradients` function in the [Jupyter Notebook](https://oreil.ly/2TDV5q9)
    for this chapter on the book’s GitHub page. This function computes each of the
    partial derivatives in [Table 2-1](#table-2-1) and multiplies them together to
    get the gradients of the loss with respect to each of the `ndarray`s containing
    the weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '`dLdW2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dLdB2`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dLdW1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dLdB1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The only caveat is that we sum the expressions we compute for `dLdB1` and `dLdB2`
    along `axis = 0`, as described in [“Gradient of the Loss with Respect to the Bias
    Terms”](app01.html#gradient-loss-bias-terms).
  prefs: []
  type: TYPE_NORMAL
- en: We’ve finally built our first neural network from scratch! Let’s see if it is
    in fact any better than our linear regression model.
  prefs: []
  type: TYPE_NORMAL
- en: Training and Assessing Our First Neural Network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Just as the forward and backward passes worked the same for our neural network
    as for the linear regression model from earlier in the chapter, so too are training
    and evaluation the same: for each iteration of data, we pass the input forward
    through the function on the forward pass, compute the gradients of loss with respect
    to the weights on the backward pass, and then use these gradients to update the
    weights. In fact, we can use the following identical code inside the training
    loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The difference simply lies in the internals of the `forward_loss` and `loss_gradients`
    functions, and in the `weights` dictionary, which now has four keys (`W1`, `B1`,
    `W2`, and `B2`) instead of two. Indeed, this is a major takeaway from this book:
    even for very complex architectures, the mathematical principles and high-level
    training procedures are the same as for simple models.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We also get predictions from this model in the same way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The difference again is simply in the internals of the `predict` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Using these predictions, we can calculate the mean absolute error and root
    mean squared error on the validation set, as before:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Both values are significantly lower than the prior model! Looking at the plot
    of predictions versus actuals in [Figure 2-13](#fig_02-13) shows similar improvements.
  prefs: []
  type: TYPE_NORMAL
- en: '![dPdB one element](assets/dlfs_0213.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-13\. Predicted value versus target, in neural network regression
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Visually, the points look closer to the 45-degree line than in [Figure 2-6](#fig_02-06).
    I encourage you to step through the [Jupyter Notebook](https://oreil.ly/2TDV5q9)
    on the book’s GitHub page and run the code yourself!
  prefs: []
  type: TYPE_NORMAL
- en: Two Reasons Why This Is Happening
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Why does this model appear to be performing better than the model before? Recall
    that there was a *nonlinear* relationship between the most important feature of
    our earlier model and our target; nevertheless, our model was constrained to learn
    only *linear* relationships between individual features and our target. I claim
    that, by adding a nonlinear function into the mix, we have allowed our model to
    learn the proper, nonlinear relationship between our features and our target.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s visualize this. [Figure 2-14](#fig_02-14) shows the same plot we showed
    in the linear regression section, plotting the normalized values of the most important
    feature from our model along with both the values of the target and the *predictions*
    that would result from feeding the mean values of the other features while varying
    the values of the most important feature from –3.5 to 1.5, as before.
  prefs: []
  type: TYPE_NORMAL
- en: '![dPdB one element](assets/dlfs_0214.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-14\. Most important feature versus target and predictions, neural network
    regression
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We can see that the relationship shown (a) is now nonlinear and (b) more closely
    matches the relationship between this feature and the target (represented by the
    points), as desired. So adding the nonlinear function to our model allowed it
    to learn, via iteratively updating the weights using the training, the nonlinear
    relationship that existed between the inputs and the outputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'That’s the first reason why our neural network performed better than a straightforward
    linear regression. The second reason is that our neural network can learn relationships
    between *combinations* of our original features and our target, as opposed to
    just individual features. This is because the neural network uses a matrix multiplication
    to create 13 “learned features,” each of which is a combination of all the original
    features, and then essentially applies another linear regression on top of these
    learned features. For example, doing some exploratory analysis that is shared
    on the book’s website, we can see that the most important combinations of the
    13 original features that the model has learned are:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mo>-</mo> <mn>4.44</mn> <mo>×</mo> <msub><mi>feature</mi>
    <mn>6</mn></msub> <mo>-</mo> <mn>2.77</mn> <mo>×</mo> <msub><mi>feature</mi> <mn>1</mn></msub>
    <mo>-</mo> <mn>2.07</mn> <mo>×</mo> <msub><mi>feature</mi> <mn>7</mn></msub> <mo>+</mo>
    <mo>.</mo> <mo>.</mo> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'and:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mn>4.43</mn> <mo>×</mo> <msub><mi>feature</mi>
    <mn>2</mn></msub> <mo>-</mo> <mn>3.39</mn> <mo>×</mo> <msub><mi>feature</mi> <mn>4</mn></msub>
    <mo>-</mo> <mn>2.39</mn> <mo>×</mo> <msub><mi>feature</mi> <mn>1</mn></msub> <mo>+</mo>
    <mo>.</mo> <mo>.</mo> <mo>.</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: These will then be included, along with 11 other learned features, in a linear
    regression in the last two layers of the neural network.
  prefs: []
  type: TYPE_NORMAL
- en: These two things—learning *nonlinear* relationships between individual features
    and our target, and learning relationships between *combinations* of features
    and our target—are what allow neural networks to often work better than straightforward
    regressions on real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to use the building blocks and mental models
    from [Chapter 1](ch01.html#foundations) to understand, build, and train two standard
    machine learning models to solve real problems. I started by showing how to represent
    a simple machine learning model from classical statistics—linear regression—using
    a computational graph. This representation allowed us to compute the gradients
    of the loss from this model with respect to the model’s parameters and thus train
    the model by continually feeding in data from the training set and updating the
    model’s parameters in the direction that would decrease the loss.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we saw a limitation of this model: it can only learn *linear* relationships
    between the features and target; this motivated us to try building a model that
    could learn *nonlinear* relationships between the features and target, which led
    us to build our first neural network. You learned how neural networks work by
    building one from scratch, and you also learned how to train them using the same
    high-level procedure we used to train our linear regression models. You then saw
    empirically that the neural network performed better than the simple linear regression
    model and learned two key reasons why: the neural network was able to learn *nonlinear*
    relationships between the features and the target and also to learn relationships
    between *combinations* of features and the target.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, there’s a reason we ended this chapter still covering a relatively
    simple model: defining neural networks in this way is an extremely manual process.
    Defining the forward pass involved 6 individually coded operations, and the backward
    pass involved 17\. However, discerning readers will have noticed that there is
    a lot of repetition in these steps, and by properly defining abstractions, we
    can move from defining models in terms of individual operations (as in this chapter)
    to defining models in terms of these abstractions. This will allow us to build
    more complex models, including deep learning models, while deepening our understanding
    of how these models work. That is what we’ll begin to do in the next chapter.
    Onward!'
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch02.html#idm45732627218840-marker)) The other kind of machine learning,
    *un*supervised learning, can be thought of as finding relationships between things
    you have measured and things that have not been measured yet.
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](ch02.html#idm45732627215256-marker)) Though in a real-world problem,
    even how to choose a price isn’t obvious: would it be the price the house last
    sold for? What about a house that hasn’t been on the market for a long time? In
    this book, we’ll focus on examples in which the numeric representation of the
    data is obvious or has been decided for you, but in many real-world problems,
    getting this right is critical.'
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch02.html#idm45732627208776-marker)) Most of you probably know that these
    are called “categorical” features.
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch02.html#idm45732626899528-marker)) At least the ones we’ll see in this
    book.
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch02.html#idm45732626271592-marker)) In addition, we have to sum `dLdB`
    along axis 0; we explain this step in more detail later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: '^([6](ch02.html#idm45732625500232-marker)) This highlights an interesting idea:
    we *could* have outputs that are connected to only *some* of our original features;
    this is in fact what convolutional neural networks do.'
  prefs: []
  type: TYPE_NORMAL
- en: '^([7](ch02.html#idm45732625497016-marker)) Well, not quite: we haven’t drawn
    *all* of the 169 lines we would need to show all the connections between the first
    two “layers” of features, but we have drawn enough of them so that you get the
    idea.'
  prefs: []
  type: TYPE_NORMAL
