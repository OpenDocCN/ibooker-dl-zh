- en: 10 Learning to rank for generalizable search relevance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 为可推广的搜索相关性学习排名
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: An introduction to machine-learned ranking, also known as learning to rank (LTR)
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习排名简介，也称为学习排名（LTR）
- en: How LTR differs from other machine learning methods
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LTR与其他机器学习方法的区别
- en: Training and deploying a ranking classifier
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和部署排名分类器
- en: Feature engineering, judgment lists, and integrating machine-learned ranking
    models into a search engine
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程、判断列表以及将机器学习排名模型集成到搜索引擎中
- en: Validating an LTR model using a train/test split
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用训练/测试分割验证LTR模型
- en: Performance tradeoffs for LTR-based ranking models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于LTR的排名模型的性能权衡
- en: It’s a random Tuesday. You review your search logs, and the searches range from
    the frustrated runner’s `polar m430 running watch charger` query to the worried
    hypochondriac’s `weird bump` `on nose` `-` `cancer?` to the curious cinephile’s
    `william shatner` `first` `film`. Even though these may be one-off queries, you
    know each user expects nothing less than amazing search results.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 今天是个随意的星期二。你回顾了你的搜索日志，搜索内容从沮丧的跑者的`polar m430 运动手表充电器`查询，到担忧的疑病症患者的`鼻子上的奇怪肿块`
    `-` `癌症？`，再到好奇的电影爱好者的`william shatner` `第一部电影`。即使这些可能只是一次性的查询，你知道每个用户都期望得到不亚于惊人的搜索结果。
- en: 'You feel hopeless. You know many query strings, by themselves, are distressingly
    rare. You have very little click data to know what’s relevant for these searches.
    Every day gets more challenging: trends, use cases, products, user interfaces,
    and even user terminology evolve. How can anyone hope to build search that amazes
    when users seem to constantly surprise us with new ways of searching?'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你感到绝望。你知道许多查询字符串本身就很罕见。你几乎没有点击数据来了解这些搜索的相关性。每一天都变得更加具有挑战性：趋势、用例、产品、用户界面，甚至用户术语都在不断演变。当用户似乎不断以新的搜索方式让我们感到惊讶时，任何人如何希望构建令人惊叹的搜索呢？
- en: 'Despair not, there is hope! In this chapter, we’ll introduce generalizable
    relevance models. These models learn the underlying patterns that drive relevance
    ranking. Instead of memorizing that the article entitled “Zits: bumps on nose”
    is the answer for the query `weird` `bump` `on` `nose` `-` `cancer?` we observe
    the underlying pattern—that a strong title match corresponds to high probability
    of relevance. If we can learn these patterns and encode them into a model, we
    can give relevant results *even for search queries we’ve never seen*.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 不要绝望，还有希望！在本章中，我们将介绍可推广的相关性模型。这些模型学习驱动相关性排名的潜在模式。我们不再需要记住标题为“Zits：鼻子上的肿块”的文章是针对查询`weird
    bump on nose - cancer？`的答案，我们观察到潜在的规律——一个强有力的标题匹配对应着高相关性的可能性。如果我们能够学习这些模式并将它们编码到模型中，我们就可以为*我们从未见过的搜索查询*提供相关结果。
- en: 'This chapter explores *learning to rank* (LTR): a technique that uses machine
    learning to create generalizable relevance ranking models. We’ll prepare, train,
    and search with LTR models using the search engine.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了*学习排名* (LTR)：一种使用机器学习来创建可推广的相关性排名模型的技巧。我们将使用搜索引擎准备、训练和搜索LTR模型。
- en: 10.1 What is LTR?
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 什么是LTR？
- en: Let’s explore what LTR does. We’ll see how LTR creates generalizable ranking
    models by finding patterns that predict relevance. We’ll then explore more of
    the nuts and bolts of building a model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索LTR做了什么。我们将看到LTR如何通过寻找预测相关性的模式来创建可推广的排名模型。然后我们将探索构建模型的更多细节。
- en: 10.1.1 Moving beyond manual relevance tuning
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 超越手动相关性调整
- en: Recall manual relevance tuning from chapter 3\. We observe factors that correspond
    with relevant results, and we combine those factors mathematically into a *ranking
    function*. The ranking function returns a relevance score that orders results
    as closely as possible to our ideal ranking.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾第3章中的手动相关性调整。我们观察到与相关结果相对应的因素，并将这些因素通过数学方法组合成一个*排名函数*。排名函数返回一个相关性分数，将结果尽可能紧密地排序到我们的理想排名。
- en: For example, consider a movie search engine with documents like those in the
    following listing. This document comes from TheMovieDB (tmdb) corpus ([http://themoviedb.org](http://themoviedb.org)),
    which we’ll use in this chapter. If you wish to follow along with the code for
    this chapter, use this chapter’s first notebook to index the tmdb dataset.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个包含以下列表中文档的电影搜索引擎。这份文档来自TheMovieDB (tmdb)语料库([http://themoviedb.org](http://themoviedb.org))，我们将在本章中使用它。如果你希望跟随本章的代码，请使用本章的第一个笔记本来索引tmdb数据集。
- en: Listing 10.1 A document for the movie *The Social Network*
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.1 电影《社交网络》的文档
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Through endless iterations and tweaks, we might arrive at a generalizable movie
    ranking function that looks something like the next listing.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通过无数次的迭代和调整，我们可能得到一个通用的电影排名函数，其外观可能类似于下一个列表。
- en: Listing 10.2 A generalizable ranking function using manual boosts
  id: totrans-20
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.2 使用手动提升的通用排名函数
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Manually optimizing the feature weights of general ranking functions like this
    to work over many queries can take significant effort, but such optimizations
    are perfect for machine learning.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 手动优化此类通用排名函数的特征权重以适用于许多查询可能需要大量的努力，但此类优化非常适合机器学习。
- en: This is where LTR comes in—it takes our proposed relevance factors and learns
    an optimal ranking function. LTR takes several forms, from a simple set of linear
    weights (like the boosts here) to a complex deep learning model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是LTR发挥作用的地方——它从我们提出的相关性因素中学习一个最佳排名函数。LTR可以采取多种形式，从一组简单的线性权重（如这里的提升）到复杂的深度学习模型。
- en: To learn the ropes, we’ll build a simple LTR model in this chapter. We’ll find
    the optimal weights for `title`, `overview`, and `release_year` in a scoring function
    like the one in listing 10.2\. With this relatively simple task, we’ll see the
    full lifecycle of developing an LTR solution.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了学习基础知识，我们将在本章构建一个简单的LTR模型。我们将找到评分函数中`title`、`overview`和`release_year`的最佳权重，如列表10.2中的函数。通过这个相对简单的任务，我们将看到开发LTR解决方案的完整生命周期。
- en: 10.1.2 Implementing LTR in the real world
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.2 在现实世界中实现LTR
- en: As we continue to define LTR at a high level, let’s quickly clarify where LTR
    fits into the overall picture of a search system. Then we can look at the kinds
    of data we’ll need to build an LTR model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续从高层次定义LTR，让我们快速明确LTR在搜索系统整体图景中的位置。然后我们可以看看我们需要构建LTR模型所需的数据类型。
- en: We’ll focus on building LTR for production search systems, which can be quite
    different from a research context. We not only need relevant results, but results
    returned suitably quickly, with mainstream, well-understood search techniques.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将专注于构建适用于生产搜索系统的LTR，这可能与研究环境大不相同。我们不仅需要相关的结果，还需要以主流、易于理解的技术快速返回结果。
- en: 'Conceptually, invoking LTR usually involves three high-level steps:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，调用LTR通常涉及三个高级步骤：
- en: Training an LTR model
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练一个LTR模型
- en: Deploying the model to production
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型部署到生产环境
- en: Using the model to rank (or rerank) search results
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型对搜索结果进行排序（或重新排序）
- en: Most modern search engines support deploying ranking models directly into the
    search engine, allowing the LTR model to be invoked efficiently “where the data
    lives”. Usually, LTR models are significantly slower at ranking than basic keyword-based
    ranking functions like BM25, so LTR models are often only invoked for subsequent-pass
    ranking (or reranking) on a subset of the top search results ranked by an initial,
    faster ranking function. Pushing the LTR model into the engine (if supported)
    prevents the need to return hundreds or thousands of documents and their metadata
    from the search engine to an external model service for reranking, which can be
    slow and inefficient compared to doing the work in-engine and at scale.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现代搜索引擎支持直接将排名模型部署到搜索引擎中，允许LTR模型在“数据所在之处”高效地被调用。通常，LTR模型在排序方面比基于基本关键词的排名函数（如BM25）慢得多，因此LTR模型通常仅用于对初始、更快的排名函数排序的顶级搜索结果子集的后续排序（或重新排序）。将LTR模型推入引擎（如果支持）可以防止需要从搜索引擎返回数百或数千个文档及其元数据到外部模型服务进行重新排序，这相对于在引擎内和大规模上工作可能会慢且效率低下。
- en: For this reason, our `ltr` library in this chapter implements pluggable support
    for deploying and invoking each supported search engine or vector database’s native
    LTR model integration capabilities when available. The code in each listing will
    work with any supported engine (see appendix B to change it), but the listing
    output you’ll see in this chapter will reflect Solr’s LTR implementation, since
    Solr is configured by default. If you change the engine, you’ll see the output
    from your chosen engine when you run the Jupyter notebooks.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本章中，我们的`ltr`库实现了对部署和调用每个支持的搜索引擎或向量数据库的本地LTR模型集成功能的可插拔支持，当这些功能可用时。每个列表中的代码将与任何支持的引擎一起工作（参见附录B进行更改），但本章中您将看到的列表输出将反映Solr的LTR实现，因为Solr默认配置。如果您更改引擎，当您运行Jupyter笔记本时，您将看到您选择的引擎的输出。
- en: Solr was one of the first major open source search engines to natively support
    LTR model serving, with the capabilities later being ported to a community-developed
    Elasticsearch LTR plugin ([https://github.com/o19s/elasticsearch-learning-to-rank](https://github.com/o19s/elasticsearch-learning-to-rank))
    and then forked to the OpenSearch LTR plugin ([https://github.com/opensearch-project/opensearch-learning-to-rank-base](https://github.com/opensearch-project/opensearch-learning-to-rank-base)).
    As such, the Elasticsearch and OpenSearch LTR plugins implement nearly identical
    concepts as those in Solr. Vespa implements phased ranking (reranking) and the
    ability to invoke models during each phase, and Weaviate also implements various
    reranking capabilities. Other engines that support native LTR will follow similar
    patterns.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Solr是第一个原生支持LTR模型服务的开源搜索引擎之一，后来这些功能被移植到社区开发的Elasticsearch LTR插件（[https://github.com/o19s/elasticsearch-learning-to-rank](https://github.com/o19s/elasticsearch-learning-to-rank)）中，然后被分叉到OpenSearch
    LTR插件（[https://github.com/opensearch-project/opensearch-learning-to-rank-base](https://github.com/opensearch-project/opensearch-learning-to-rank-base)）。因此，Elasticsearch和OpenSearch
    LTR插件在概念上几乎与Solr中的相同。Vespa实现了分阶段排名（重排名）和在每个阶段调用模型的能力，而Weaviate也实现了各种重排名功能。其他支持原生LTR的引擎将遵循类似的模式。
- en: Figure 10.1 outlines the workflow for developing a practical LTR solution.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1概述了开发实用LTR解决方案的工作流程。
- en: '![figure](../Images/CH10_F01_Grainger.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F01_Grainger.png)'
- en: Figure 10.1 LTR systems transform our training data (judgment lists) into models
    that generalize relevance ranking. This type of system lets us find the underlying
    patterns in our training data.
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.1 LTR系统将我们的训练数据（判断列表）转换为泛化相关性排名的模型。这类系统使我们能够找到训练数据中的潜在模式。
- en: You may notice similarities between LTR and traditional machine learning–based
    classification or regression system workflows. But the exceptions are what make
    it interesting. Table 10.1 maps definitions between traditional machine learning
    objectives and LTR.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到LTR与传统基于机器学习的分类或回归系统工作流程之间的相似之处。但正是这些例外让它变得有趣。表10.1将传统机器学习目标与LTR之间的定义进行了映射。
- en: Table 10.1 Traditional machine learning vs. LTR
  id: totrans-39
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表10.1 传统机器学习与LTR
- en: '| Concept | Traditional machine learning | LTR |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 概念 | 传统机器学习 | LTR |'
- en: '| --- | --- | --- |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Training data  | Set of historical or “true” examples the model should try
    to predict, e.g., stock prices on past days, like “Apple” was $125 on June 6th,
    2021\.  | A *judgment list*: A *judgment* simply labels a document as relevant
    or irrelevant for a query. In figure 10.2, *Return of the Jedi* is labeled relevant
    ( `grade` of `1`), for the query `star wars`.  |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 训练数据 | 模型应尝试预测的历史或“真实”示例集，例如，过去某天的股票价格，如“苹果”在2021年6月6日的价格为125美元。 | *判断列表*：一个*判断*简单地标记一个文档对于查询的相关性或非相关性。在图10.2中，“星球大战”被标记为相关（`grade`为`1`），针对查询`star
    wars`。 |'
- en: '| Feature  | The data we can use to predict the training data, e.g., Apple
    had 147,000 employees and revenue of $90 billion.  | Data used so that relevant
    results rank higher than irrelevant ones and, ideally, values the search engine
    can compute quickly. Our features are search queries like `title:({keywords})`
    from listing 10.2\.  |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 特征 | 我们可以用来预测训练数据的资料，例如，苹果公司在2021年有147,000名员工，收入为900亿美元。 | 用于使相关结果比不相关结果排名更高的数据，理想情况下，搜索引擎可以快速计算的价值。我们的特征是来自列表10.2的搜索查询，如`title:({keywords})`。
    |'
- en: '| Model  | The algorithm that takes features as input to make a prediction.
    Given that Apple has 157,000 employees on July 6th, 2021, with $95 billion in
    revenue, the model might predict a stock price of $135 for that date.  | Combines
    the ranking features (search queries) together to assign a relevance *score* to
    each potential search result. Results are sorted by score descending, hopefully
    placing more relevant results first.  |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 输入特征以进行预测的算法。鉴于苹果公司在2021年7月6日有157,000名员工，收入为950亿美元，该模型可能会预测该日期的股价为135美元。
    | 将排名特征（搜索查询）组合起来，为每个潜在搜索结果分配一个相关性*分数*。结果按分数降序排列，希望将更相关的结果排在前面。 |'
- en: 'This chapter follows the steps in figure 10.1 to train an LTR model:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本章遵循图10.1中的步骤来训练一个LTR模型：
- en: '*Gather judgments*—We derive judgments from clicks or other sources. We’ll
    cover this step in depth in chapter 11\.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*收集判断*—我们从点击或其他来源中推导出判断。我们将在第11章中深入探讨这一步骤。'
- en: '*Feature logging*—To train a model, we must combine the judgments with features
    to see the overall pattern. This step requires us to ask the search engine to
    store and compute queries representing the features.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*特征记录*——为了训练一个模型，我们必须将判断与特征结合起来，以查看整体模式。这一步骤需要我们要求搜索引擎存储和计算代表特征的查询。'
- en: '*Transform to a traditional machine learning problem*—You’ll see that most
    LTR really is about translating the ranking task into something that looks more
    like the “traditional machine learning” column in table 10.1\.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*转换为传统的机器学习问题*——你会发现，大多数LTR实际上是将排名任务转换为类似于表10.1中“传统机器学习”列的东西。'
- en: '*Train and evaluate the model*—Here we construct our model and confirm that
    it is, indeed, generalizable, and thus will perform well for queries it hasn’t
    seen.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*训练和评估模型*——在这里，我们构建我们的模型，并确认它确实是可泛化的，因此对于它尚未看到的查询将表现良好。'
- en: '*Store the model*—We upload the model to our search infrastructure, tell the
    search engine which features to use as input, and enable it for users to use in
    their searches.'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*存储模型*——我们将模型上传到我们的搜索基础设施，告诉搜索引擎哪些特征作为输入使用，并启用用户在他们的搜索中使用它。'
- en: '*Search using the model*—We finally can execute searches using the model!'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*使用模型进行搜索*——我们终于可以使用模型进行搜索了！'
- en: The rest of the chapter will walk through each of these steps in detail to build
    our first LTR implementation. Let’s get cracking!
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的其余部分将详细介绍这些步骤，以构建我们的第一个LTR实现。让我们开始吧！
- en: '10.2 Step 1: A judgment list, starting with the training data'
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 步骤 1：判断列表，从训练数据开始
- en: 'You already saw what LTR is at a high level, so let’s get into the nitty-gritty.
    Before implementing LTR, we must first learn about the data used to train an LTR
    model: the judgment list.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经从高层次了解了LTR是什么，那么让我们深入了解。在实现LTR之前，我们首先必须了解用于训练LTR模型的训练数据：判断列表。
- en: A *judgment list* is a list of relevance labels or *grades*, each indicating
    the relevance of a document to a query. Grades can come in a variety of forms.
    For now, we’ll stick to simple *binary judgments*—a `0` indicates an irrelevant
    document and a `1` indicates a relevant one.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*判断列表*是一系列相关性标签或评分，每个标签都指示一个文档与查询的相关性。评分可以有多种形式。目前，我们将坚持简单的*二元判断*——`0`表示无关文档，而`1`表示相关文档。'
- en: 'Using the `Judgment` class provided with this book’s code, we’ll label *The
    Social Network* as relevant for the query `social network` by creating a `Judgment`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用本书代码提供的`Judgment`类，我们将通过创建一个`Judgment`将《社交网络》标记为`social network`查询的相关：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: It’s more interesting to look over multiple queries. In listing 10.3, we have
    `social network` and `star wars` as two different queries, with movies graded
    as relevant or irrelevant.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 查看多个查询更有趣。在列表10.3中，我们将`social network`和`star wars`作为两个不同的查询，对电影进行相关或不相关的评分。
- en: Listing 10.3 Labeling movie judgments as relevant or irrelevant
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.3 标记电影判断为相关或不相关
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can see that we labeled *Star Trek into Darkness* and *Battlestar Galactica*
    as irrelevant for the query `star wars`, but *Return of the Jedi* as relevant.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，我们将《星际迷航：暗黑无界》和《星际迷航：银河系漫游指南》标记为与查询`star wars`无关，但将《星球大战：绝地归来》标记为相关。
- en: You’re hopefully asking yourself “where did these grades come from?” Hand labeled
    by movie experts? Based on user clicks? Good questions! Creating a good training
    set, based on user interactions with search results, is crucial for getting LTR
    to work well. To get training data in bulk, we usually derive these labels from
    click traffic using a type of algorithm known as a *click model*. As this step
    is so foundational, we’ll dedicate all of chapter 11 to diving deeper into the
    topic. In this chapter, however, we’ll start with manually labeled judgments so
    we can initially focus on the mechanics of LTR.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道“这些评分是从哪里来的？”是由电影专家手工标记的吗？基于用户点击的吗？好问题！基于用户与搜索结果交互创建一个好的训练集对于LTR良好工作至关重要。为了大量获取训练数据，我们通常使用一种称为*点击模型*的算法从点击流量中提取这些标签。由于这一步骤非常基础，我们将用整个第11章深入探讨这个主题。然而，在这一章中，我们将从手动标记的判断开始，以便我们最初可以专注于LTR的机制。
- en: Each judgment also has a `features` vector, which can be used to train a model.
    The first feature in the `features` vector could be made to correspond to the
    `title` BM25 score, the second to the `overview` BM25 score, and so on. We haven’t
    populated the `features` vectors yet, so if you inspect `sample_judgments[0].features`,
    it’s currently empty (`[]`).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 每个判断还有一个`features`向量，可以用来训练模型。`features`向量的第一个特征可以对应于`title` BM25得分，第二个对应于`overview`
    BM25得分，依此类推。我们还没有填充`features`向量，所以如果您检查`sample_judgments[0].features`，它目前是空的（`[]`）。
- en: Let’s use the search engine to gather some features.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用搜索引擎来收集一些特征。
- en: '10.3 Step 2: Feature logging and engineering'
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 步骤2：特征记录和工程
- en: Feature engineering requires identifying patterns between document attributes
    and relevance. For example, we might hypothesize that “relevant results in our
    judgments correspond to strong title matches”. In this case, “title match” would
    be a feature we’d need to define. In this section, you’ll see what features (like
    “title match”) are and how to use a modern search engine to engineer and extract
    these features from a corpus.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程需要识别文档属性和相关性之间的模式。例如，我们可能会假设“我们判断中的相关结果对应于强大的标题匹配”。在这种情况下，“标题匹配”将是我们需要定义的特征。在本节中，您将了解什么是特征（如“标题匹配”），以及如何使用现代搜索引擎从语料库中构建和提取这些特征。
- en: 'For the purposes of LTR, a *feature* is some numerical attribute of the document,
    the query, or the query-document relationship. Features are the mathematical building
    blocks we use to build a ranking function. You’ve already seen a manual ranking
    function with features in listing 10.2: the keyword score in the `title` field
    is one such feature, as are the `release_year` and `overview` keyword scores:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于LTR的目的，一个**特征**是文档、查询或查询-文档关系的某些数值属性。特征是我们用来构建排名函数的数学构建块。您已经看到了一个带有特征的手动排名函数，如列表10.2中的关键字得分在`title`字段中就是一个这样的特征，同样还有`release_year`和`overview`关键字得分：
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Of course, the features you end up using could be more complex or domain-specific,
    such as the commute distance in a job search, or some knowledge graph relationship
    between query and document. Anything you can compute relatively quickly when a
    user searches might be a reasonable feature.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你最终使用的功能可能更复杂或更具有领域特定性，例如在求职中通勤的距离，或者查询与文档之间的某些知识图谱关系。当用户搜索时，任何可以相对快速计算的内容都可能是一个合理的特征。
- en: '*Feature logging* takes a judgment list and computes features for each labeled
    query-document pair. If we computed the values of each component of listing 10.2
    for the query `social network`, we would arrive at something like table 10.2.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**特征记录**从判断列表中计算每个标记的查询-文档对的特征。如果我们为查询`social network`计算列表10.2中每个组件的值，我们就会得到类似于表10.2的内容。'
- en: Table 10.2 Features logged for the keywords `social network` for relevant (`grade=1`)
    and irrelevant (`grade=0`) documents
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表10.2 为关键词“social network”记录的相关（`grade=1`）和不相关（`grade=0`）文档的特征
- en: '| Grade | Movie | **`title:({keywords})`** | **`overview: ({keywords})`** |
    **`{!func}release_year`** |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 等级 | 电影 | **`title:({keywords})`** | **`overview: ({keywords})`** | **`{!func}release_year`**
    |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1  | Social Network  | 8.243603  | 3.8143613  | 2010.0  |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 1  | Social Network  | 8.243603  | 3.8143613  | 2010.0  |'
- en: '| 0  | #chicagoGirl  | 0.0  | 6.0172443  | 2013.0  |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 0  | #chicagoGirl  | 0.0  | 6.0172443  | 2013.0  |'
- en: '| 0  | Life As We Know It  | 0.0  | 4.353118  | 2010.0  |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 0  | Life As We Know It  | 0.0  | 4.353118  | 2010.0  |'
- en: '| 0  | The Cheyenne Social Club  | 3.4286604  | 3.1086721  | 1970.0  |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 0  | The Cheyenne Social Club  | 3.4286604  | 3.1086721  | 1970.0  |'
- en: A machine learning algorithm might examine the feature values from table 10.2
    and converge on a good ranking function. From just the data in table 10.2, it
    seems such an algorithm might produce a ranking function with a higher weight
    for the `title` feature and lower weights for the other features.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法可能会检查表10.2中的特征值，并收敛到一个好的排名函数。仅从表10.2中的数据来看，这样的算法可能会产生一个对`title`特征赋予更高权重而对其他特征赋予更低权重的排名函数。
- en: Before we get to the algorithms, however, we need to examine the feature logging
    workflow in a production search system.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们到达算法之前，我们需要检查生产搜索系统中的特征记录工作流程。
- en: 10.3.1 Storing features in a modern search engine
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.1 在现代搜索引擎中存储特征
- en: Modern search engines that support LTR help us store, manage, and extract features.
    Engines like Solr, Elasticsearch, and OpenSearch track features in a *feature
    store*—a list of named features. It’s crucial that we log features for training
    in a manner consistent with how the search engine will execute the model.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 支持LTR的现代搜索引擎帮助我们存储、管理和提取特征。像Solr、Elasticsearch和OpenSearch这样的引擎在*特征存储*中跟踪特征——一个命名特征的列表。我们以与搜索引擎执行模型一致的方式记录用于训练的特征至关重要。
- en: 'As shown in listing 10.4, we generate and upload features to the search engine.
    We use a generic feature store abstraction in the book’s codebase, allowing us
    to generate various search-based features and upload them as a *feature set* to
    the feature store of a supported search engine. Here we create three features:
    a title field relevance score `title_bm25`, an overview field relevance score
    `overview_bm25`, and the value of the `release_year` field. BM25 here corresponds
    to the BM25-based scoring defined in chapter 3, which will be our default method
    for scoring term matches in text fields.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如列表10.4所示，我们生成并上传特征到搜索引擎。我们在本书的代码库中使用通用的特征存储抽象，允许我们生成各种基于搜索的特征，并将它们作为*特征集*上传到支持搜索引擎的特征存储。在这里，我们创建了三个特征：标题字段的相关度分数`title_bm25`、概述字段的相关度分数`overview_bm25`以及`release_year`字段的值。这里的BM25对应于第3章中定义的基于BM25的评分，这将成为我们在文本字段中评分词匹配的默认方法。
- en: Listing 10.4 Creating three features for LTR
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.4 创建LTR的三个特征
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Engine-specific feature set definition (for `engine=solr`):'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 特定于引擎的特征集定义（对于`engine=solr`）：
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 The name of the feature'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 特征的名称'
- en: '#2 The feature store where the feature will be saved'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将特征保存到特征存储'
- en: '#3 A parametrized feature taking the keywords (e.g., star wars) and searching
    the title field'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 一个参数化特征，接受关键词（例如，星球大战）并搜索标题字段'
- en: '#4 Another feature that searches against the overview field'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 另一个针对概述字段进行搜索的特征'
- en: '#5 A document-only feature, the release_year of the movie'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 仅文档特征，电影的发布年份'
- en: '#6 params are the same params for a Solr query, allowing you to use the full
    power of Solr’s extensive Query DSL to craft features.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 params是与Solr查询相同的参数，允许您使用Solr广泛的查询DSL的全部功能来构建特征。'
- en: 'The output of listing 10.4 shows the feature set that’s uploaded to the search
    engine—in this case, a Solr feature set. This output will obviously look different
    based on which search engine implementation you configure (as discussed in appendix
    B). The first two features are parameterized: they each take the search keywords
    (`social` `network`, `star wars`) and execute a search on the corresponding field.
    The final one is a field value feature utilizing the release year of a movie,
    which will boost more recent movies higher.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.4的输出显示了上传到搜索引擎的特征集——在本例中，是一个Solr特征集。根据你配置的搜索引擎实现（如附录B所述），此输出将明显不同。前两个特征是参数化的：它们各自接受搜索关键词（例如，“社交网络”、“星球大战”）并在相应的字段上执行搜索。最后一个是一个利用电影发布年份的字段值特征，这将使较新的电影排名更高。
- en: 10.3.2 Logging features from our search engine corpus
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.2 从我们的搜索引擎语料库记录特征
- en: With features loaded into the search engine, our next focus will be to log features
    for every row in our judgment list. After we get this last bit of plumbing out
    of the way, we will then train a model that can observe relationships between
    each relevant and irrelevant document for each query.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在将特征加载到搜索引擎后，我们的下一个重点是记录我们判断列表中每一行的特征。在我们完成最后一部分管道之后，我们将训练一个模型，该模型可以观察每个查询中每个相关和不相关文档之间的关系。
- en: For each unique query in our judgment list, we need to extract the features
    for the query’s graded documents. For the query `social network` in the sample
    judgment list from listing 10.3, we have one relevant document (37799) and three
    irrelevant documents (267752, 38408, and 28303).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们判断列表中的每个唯一查询，我们需要提取查询评分文档的特征。对于列表10.3中样本判断列表中的查询“社交网络”，我们有一个相关文档（37799）和三个不相关文档（267752、38408和28303）。
- en: The following listing shows an example of feature logging for the query `social
    network`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表显示了查询“社交网络”的特征记录示例。
- en: Listing 10.5 Logging feature values for `social network` results
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.5 记录“社交网络”结果的特征值
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Relevant and irrelevant documents for the “social network” query'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 “社交网络”查询的相关和不相关文档'
- en: '#2 Queries the search engine for feature values contained in the movies feature
    store'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 查询包含在电影特征存储中的特征值'
- en: 'Engine-specific search request (for `engine=solr`):'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 特定于引擎的搜索请求（对于`engine=solr`）：
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#1 Example Solr query syntax to retrieve feature values from each returned
    document'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 示例Solr查询语法，用于从每个返回的文档中检索特征值'
- en: 'Documents with logged features:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 带有日志特征的文档：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#1 Each feature value logged for this movie for the “social network” query'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 为“社交网络”查询记录的此电影的特征值'
- en: Notice that the search request (for Solr in this case) in listing 10.5 has a
    return field containing square brackets. This syntax tells Solr to return an extra
    field on each document containing the feature data defined in the feature store
    (the `movies` feature store in this case). The `efi` parameter stands for *external
    feature information*, and it’s used here to pass the keyword query (`social network`)
    and any additional query-time information needed to compute each feature. The
    response contains the four requested documents with their corresponding features.
    These parameters will be different for each search engine, but the concepts will
    be similar.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到列表10.5中的搜索请求（在本例中为Solr）包含一个包含方括号的返回字段。这种语法告诉Solr在每份文档上返回一个额外的字段，包含特征存储库中定义的特征数据（在本例中为`movies`特征存储库）。`efi`参数代表*外部特征信息*，它在这里用于传递关键字查询（`social
    network`）以及计算每个特征所需的任何附加查询时间信息。响应包含四个请求的文档及其相应的特征。这些参数对于每个搜索引擎都不同，但概念将是相似的。
- en: 'With some mundane Python data transformation, we can fill in the features for
    the query `social network` in our training set from this response. In listing
    10.6, we apply feature data to judgments for the query `social network`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一些平凡的Python数据转换，我们可以从响应中填充训练集中查询`social network`的特征。在列表10.6中，我们将特征数据应用于查询`social
    network`的判断：
- en: Listing 10.6 Judgments with logged features for query `social network`
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.6 对于查询`social network`的带有日志特征的判断
- en: '[PRE10]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 Judgment for the movie The Social Network relative to the “social network”
    query, including the logged feature values'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 与“社交网络”查询相关的电影《社交网络》的判断，包括日志特征值'
- en: '#2 An irrelevant document for the “social network” query (note the low first
    feature value, the title_bm25 score of 0.0)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 对于“社交网络”查询的不相关文档（注意第一个特征值的低值，标题BM25得分为0.0）'
- en: In listing 10.6, as we might expect, the first feature value corresponds to
    the first feature in our feature store (`title_bm25`), the second value to the
    second feature in our feature store (`overview_bm25`), and so on. Let’s repeat
    the process of logging features for judgments for the query `star wars`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表10.6中，正如我们可能预期的，第一个特征值对应于我们特征存储库中的第一个特征（`title_bm25`），第二个值对应于我们特征存储库中的第二个特征（`overview_bm25`），依此类推。让我们重复对查询`star
    wars`的判断进行特征日志记录的过程。
- en: Listing 10.7 Logged judgments for the query `star wars`
  id: totrans-115
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.7 对于查询`star wars`的日志判断
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: With the ability to generate logged judgments, let’s expand the judgment list
    to about a hundred movie queries, each with about 40 movies graded as relevant/irrelevant.
    Code for loading and logging features for this larger training set essentially
    repeats the search engine request shown in listing 10.5\. The end result of this
    feature logging looks just like listing 10.7, but created from a much larger judgment
    list.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 通过生成日志判断的能力，让我们将判断列表扩展到大约一百个电影查询，每个查询大约有40部电影被标记为相关/不相关。加载和记录这个更大训练集特征的代码基本上重复了列表10.5中显示的搜索引擎请求。特征记录的最终结果看起来就像列表10.7，但来自一个更大的判断列表。
- en: We’ll move on next to consider how to handle the problem of ranking as a machine
    learning problem.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将考虑如何将排名问题作为一个机器学习问题来处理。
- en: '10.4 Step 3: Transforming LTR to a traditional machine learning problem'
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 步骤3：将LTR转换为传统机器学习问题
- en: In this section, we’re going to explore ranking as a machine learning problem.
    This will help us understand how to apply well-known, traditional machine learning
    concepts to our LTR task.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨将排名作为一个机器学习问题。这将帮助我们理解如何将众所周知的传统机器学习概念应用于我们的LTR任务。
- en: The task of LTR is to look over many relevant and irrelevant training examples
    for a query and then build a model to bring more relevant documents to the top
    (and conversely push less relevant documents down). Each training example doesn’t
    have much value by itself; what matters is how it’s ordered alongside its peers
    in a query. Figure 10.2 shows this task, with two queries. The goal is to find
    a scoring function that can use the features to correctly order results.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: LTR的任务是在许多相关和不相关的训练示例中查找查询，然后构建一个模型，将更多相关文档置于顶部（反之，将不太相关的文档推到底部）。每个训练示例本身并没有多少价值；重要的是它在查询中与同侪的排序。图10.2展示了这个任务，有两个查询。目标是找到一个评分函数，可以使用特征来正确排序结果。
- en: '![figure](../Images/CH10_F02_Grainger.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F02_Grainger.png)'
- en: Figure 10.2 LTR is about placing each query’s result set in the ideal order,
    not about predicting individual relevance grades. That means we need to look at
    each query as a case unto itself.
  id: totrans-123
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.2 LTR是关于将每个查询的结果集放置在理想顺序中，而不是关于预测单个相关性等级。这意味着我们需要将每个查询视为一个独立的案例。
- en: 'Contrast LTR with a more traditional pointwise machine learning task: a task
    like predicting a company’s stock price as mentioned in table 10.2 earlier. *Pointwise
    machine learning* means that we can evaluate the model’s accuracy on each example
    in isolation, predicting its absolute value as opposed to its relative value versus
    other examples. We know, just by looking at one company, how well we predicted
    that company’s stock price. Compare figure 10.3 showing a pointwise task to figure
    10.2\. Notice in figure 10.3 that the learned function attempts to predict the
    stock price directly, whereas with LTR, the function’s output is only meaningful
    for ordering items relative to their peers for a query.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 将LTR与一个更传统的点wise机器学习任务进行对比：例如，预测公司在表10.2中提到的股价。*Pointwise机器学习*意味着我们可以独立评估模型在每个示例上的准确性，预测其绝对值而不是与其他示例的相对值。仅通过观察一家公司，我们就能知道我们预测该公司股价的准确性。将图10.3显示的点wise任务与图10.2进行比较。注意在图10.3中，学习到的函数试图直接预测股价，而LTR中，函数的输出仅对查询中相对于其同侪的排序有意义。
- en: '![figure](../Images/CH10_F03_Grainger.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F03_Grainger.png)'
- en: Figure 10.3 Pointwise machine learning tries to optimize predictions of individual
    points (such as a stock price or the temperature). Search relevance is a different
    problem than pointwise prediction. Instead, we need to optimize a ranking of examples
    grouped by a search query.
  id: totrans-126
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.3 Pointwise机器学习试图优化单个点（如股价或温度）的预测。搜索相关性是一个与点wise预测不同的问题。相反，我们需要优化由搜索查询分组的示例的排序。
- en: LTR targets a very different objective (ranking multiple results) than pointwise
    machine learning (predicting specific values of results). Most LTR methods use
    clever alchemy to transmogrify this “ranking of pairs” task into a classification
    task per document that learns to predict which features and feature weights best
    separate “relevant” from “irrelevant” documents. This transformation is the key
    to building a generalizable LTR model that can operate on specific documents as
    opposed to only pairs of documents. We’ll look at one model’s method for transforming
    the ranking task in the next section by exploring a popular LTR model named SVMrank.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: LTR的目标与pointwise机器学习（预测结果的具体值）非常不同（对多个结果进行排序）。大多数LTR方法使用巧妙的炼金术将这个“成对排序”任务转化为每个文档的分类任务，该任务学习预测哪些特征和特征权重最能区分“相关”文档和“不相关”文档。这种转换是构建一个可推广的LTR模型的关键，该模型可以针对特定文档操作，而不仅仅是文档对。我们将在下一节通过探索一个名为SVMrank的流行LTR模型来查看一个模型转换排序任务的方法。
- en: '10.4.1 SVMrank: Transforming ranking to binary classification'
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.1 SVMrank：将排序转换为二元分类
- en: 'At the core of LTR is the model: the actual algorithm that learns the relationship
    between relevance/irrelevance and the features like `title_bm25`, `overview_bm25`,
    etc. In this section, we’ll explore one such model, SVMrank, first understanding
    what “SVM” stands for and then how it can be used to build a great, generalizable
    LTR model.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: LTR的核心是模型：学习相关性/非相关性与`title_bm25`、`overview_bm25`等特征之间关系的实际算法。在本节中，我们将探讨这样一个模型，SVMrank，首先了解“SVM”代表什么，然后了解它如何被用来构建一个优秀且可推广的LTR模型。
- en: SVMrank transforms relevance into a binary classification problem. *Binary classification*
    simply means classifying items as one of two classes (like “relevant” versus “irrelevant”,
    “adult” versus “child”, “dog” versus “cat”) using the available features.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: SVMrank将相关性转化为二元分类问题。**二元分类**简单地说就是使用可用特征将项目分类为两个类别之一（如“相关”与“不相关”，“成人”与“儿童”，“狗”与“猫”）。
- en: An *SVM* or *support vector machine* is one method of performing binary classification.
    We won’t go in-depth into SVMs, as you need not be a machine learning expert to
    follow the discussion. Nevertheless, if you want to get a deeper overview of SVMs,
    you can look at a book such as *Grokking Machine Learning* by Luis Serrano (Manning,
    2021).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量机**或**支持向量机**是执行二元分类的一种方法。我们不会深入探讨支持向量机，因为您不需要成为机器学习专家就能理解讨论。不过，如果您想对支持向量机有一个更深入的了解，您可以查阅Luis
    Serrano所著的《Grokking Machine Learning》（Manning, 2021）一书。'
- en: Intuitively, an SVM finds the best, most generalizable hyperplane to draw between
    the two classes. A *hyperplane* is a boundary that separates a vector space into
    two parts. A 1D point can be a hyperplane separating a 2D line into two parts,
    just as a line can be a hyperplane separating a 3D space into two parts. A plane
    is usually a 3D boundary separating a 4D space. All of these, as well as boundaries
    even greater than three dimensions are generically referred to as hyperplanes.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，支持向量机（SVM）寻找最佳、最通用的超平面来在两类之间绘制。一个**超平面**是一个将向量空间分成两部分的边界。一个一维点可以是一个将二维线分成两部分的超平面，就像一条线可以是一个将三维空间分成两部分的超平面。一个平面通常是一个将四维空间分开的三维边界。所有这些，以及甚至超过三维的边界，通常统称为超平面。
- en: As an example, if we were trying to build a model to predict whether an animal
    is a dog or cat, we might look at a 2D graph of the heights and weights of known
    dogs or cats and draw a line separating the two classes as shown in figure 10.4.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们试图构建一个预测动物是狗还是猫的模型，我们可能会查看已知狗或猫的高度和重量的二维图，并绘制一条线来分隔这两类，如图10.4所示。
- en: '![figure](../Images/CH10_F04_Grainger.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH10_F04_Grainger.png)'
- en: 'Figure 10.4 SVM example: Is an animal a dog or a cat? This hyperplane (the
    line here) separates these two cases based on two features: height and weight.
    Soon you’ll see how we might do something similar to separate relevant and irrelevant
    search results for a query.'
  id: totrans-135
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.4 SVM示例：动物是狗还是猫？这个超平面（这里的线）根据两个特征：高度和重量，将这两个案例分开。很快你就会看到我们如何可能做到类似的事情，以分隔查询的相关和不相关搜索结果。
- en: A good separating hyperplane drawn between the classes attempts to minimize
    the mistakes it makes in classifying the training data (fewer dogs on the cat
    side and vice versa). We also want a hyperplane that is *generalizable*, meaning
    that it will probably do a good job of classifying animals that weren’t seen during
    training. After all, what good is a model if it can’t make predictions about new
    data? It wouldn’t be very AI-powered!
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在类别之间绘制的良好分离超平面试图最小化它在分类训练数据时犯的错误（猫一边的狗少，反之亦然）。我们还希望一个**可泛化**的超平面，这意味着它可能会很好地对训练期间未看到的动物进行分类。毕竟，如果一个模型不能对新数据进行预测，那它有什么用呢？它不会很有AI能力！
- en: Another detail to know about SVMs is that they can be sensitive to the range
    of our features. For example, imagine if the `height` feature was millimeters
    instead of centimeters, like in figure 10.5\. It forces the data to stretch out
    on the *x*-axis, and the separating hyperplane looks quite different!
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 关于支持向量机（SVMs）的另一个细节是，它们可能对我们的特征范围敏感。例如，想象一下，如果`高度`特征是毫米而不是厘米，就像图10.5中那样，它迫使数据在*x*轴上拉伸，分离超平面看起来相当不同！
- en: '![figure](../Images/CH10_F05_Grainger.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH10_F05_Grainger.png)'
- en: Figure 10.5 Separating hyperplane affected by the range of one of the features.
    This causes SVMs to be sensitive to the range of features, and thus we need to
    normalize the features so one feature doesn’t create undue influence on the model.
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.5 受一个特征范围影响的分离超平面。这导致支持向量机（SVMs）对特征的范围敏感，因此我们需要对特征进行归一化，以便一个特征不会对模型产生不适当的影响。
- en: SVMs work best when our data is normalized. *Normalization* just means scaling
    features to a comparable range. We’ll normalize our data by mapping `0` to the
    mean of the feature values. If the average `release_year` is `1990`, movies released
    in 1990 will normalize to `0`. We’ll also map `+1` and `-1` to one standard deviation
    above or below the mean. So if the standard deviation of movie release years is
    22 years, then movies in 2012 turn into a `1.0`; movies in 1968 turn into a `-1.0`.
    We can repeat this for `title_bm25` and `overview_bm25` using those features’
    means and standard deviations in our training data. This helps make the features
    a bit more comparable when finding a separating hyperplane.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: SVM在数据归一化时表现最佳。*归一化*只是将特征缩放到一个可比较的范围。我们将通过将`0`映射到特征值的平均值来归一化我们的数据。如果平均`release_year`是`1990`，那么在`1990`发布的电影将归一化为`0`。我们还将`+1`和`-1`映射到平均值以上或以下的一个标准差。所以如果电影发布年份的标准差是22年，那么在2012年的电影将变成`1.0`；在1968年的电影将变成`-1.0`。我们可以使用训练数据中这些特征的均值和标准差对`title_bm25`和`overview_bm25`重复此操作。这有助于在寻找分离超平面时使特征更具有可比性。
- en: With that brief background out of the way, let’s now explore how SVMrank can
    create a generalizable model to distinguish relevant from irrelevant documents,
    even for queries it has never seen before.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在简要介绍背景之后，现在让我们探索SVMrank如何创建一个可推广的模型来区分相关和不相关的文档，即使对于它以前从未见过的查询。
- en: 10.4.2 Transforming our LTR training task to binary classification
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.2 将我们的LTR训练任务转换为二进制分类
- en: With LTR, we must reframe the task from ranking to a traditional machine learning
    task. In this section, we’ll explore how SVMrank transforms ranking into a binary
    classification task suitable for an SVM.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在LTR中，我们必须将任务从排序重新定位为一个传统的机器学习任务。在本节中，我们将探索SVMrank如何将排序转换为适合SVM的二进制分类任务。
- en: Before we get started, let’s inspect the fully logged training set from the
    end of step 2 for our two favorite queries, `star` `wars` and `social` `network`.
    In this section, we’ll focus on just two features (`title_bm25` and `overview_bm25`)
    to help us explore feature relationships graphically. Figure 10.6 shows these
    two features for every graded document for the `star` `wars` and `social` `network`
    queries, labeling some prominent movies from the training set.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们检查从步骤2的末尾开始的完整日志训练集，针对我们最喜欢的两个查询`star` `wars`和`social` `network`。在本节中，我们将只关注两个特征（`title_bm25`和`overview_bm25`），以帮助我们通过图形探索特征之间的关系。图10.6显示了针对`star`
    `wars`和`social` `network`查询的每个评分文档的这两个特征，并标记了训练集中的几个突出电影。
- en: '![figure](../Images/CH10_F06_Grainger.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F06_Grainger.png)'
- en: Figure 10.6 Logged feature scores for `social network` and `star wars` queries
  id: totrans-146
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.6 `社交网络`和`星球大战`查询的日志特征分数
- en: First, normalize the LTR features
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 首先，归一化LTR特征
- en: Our first step is to normalize each feature. The following listing takes the
    logged output from step 2 and normalizes features into `normed_judgments`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是归一化每个特征。以下列表将步骤2的日志输出归一化到`normed_judgments`。
- en: Listing 10.8 Normalizing logged LTR training data
  id: totrans-149
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.8归一化日志LTR训练数据
- en: '[PRE12]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Output:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE13]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '#1 Unnormalized example, with raw title_bm25, overview_bm25, and release_year'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 未归一化的示例，包含原始的title_bm25、overview_bm25和release_year'
- en: '#2 Same judgment, but normalized'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 相同的判断，但归一化'
- en: You can see that the output from listing 10.8 shows first the logged BM25 scores
    for title and overview (`8.244`, `3.814`) alongside the release year (`2010`).
    These features are then normalized, where `8.244` for `title_bm25` corresponds
    to `4.483` standard deviations above the mean `title_bm25`, and so on for each
    feature.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，列表10.8的输出首先显示了标题和概述的日志BM25分数（`8.244`, `3.814`），以及发布年份（`2010`）。然后，这些特征被归一化，其中`title_bm25`的`8.244`对应于平均`title_bm25`以上的`4.483`个标准差，每个特征都是如此。
- en: We’ve plotted the normalized features in figure 10.7\. This looks very similar
    to figure 10.6, with only the scale on each axis differing.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在图10.7中绘制了归一化的特征。这看起来与图10.6非常相似，只是每个轴的刻度不同。
- en: '![figure](../Images/CH10_F07_Grainger.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F07_Grainger.png)'
- en: Figure 10.7 Normalized `star wars` and `social network` graded movies. Each
    increment in the graph is a standard deviation above or below the mean.
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.7归一化的`星球大战`和`社交网络`评分电影。图中每一点的增量都是相对于平均值的正负一个标准差。
- en: Next, we’ll turn ranking into a binary classification learning problem to separate
    the relevant from irrelevant results.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将把排序转换成一个二进制分类学习问题，以区分相关和不相关的结果。
- en: Second, compute the pairwise differences
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第二，计算成对差异
- en: With normalized data, we’ve forced features to a consistent range. Now our SVM
    should not be biased by features that happen to have very large ranges. In this
    section, we’re ready to transform the task into a binary classification problem,
    setting the stage for us to train our model.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通过归一化数据，我们已强制特征保持一致的范围。现在我们的 SVM 不应受到具有非常大范围的特征的偏差。在本节中，我们将任务转换为二元分类问题，为我们训练模型做好准备。
- en: SVMrank uses a pairwise transformation to reformulate LTR to a binary classification
    problem. *Pairwise* simply means turning ranking into the task of minimizing out-of-order
    pairs for a query.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: SVMrank 使用成对转换将 LTR 重新表述为二元分类问题。*成对*简单来说就是将排序任务转化为最小化查询中顺序错误的成对。
- en: In the rest of this section, we’ll carefully walk through SVMrank’s pairwise
    algorithm, outlined in listing 10.9\. The SVMrank algorithm takes every judgment
    for each query and compares it to every other judgment for that same query. It
    computes the feature differences (`feature_deltas`) between every relevant and
    irrelevant pair for that query. When adding to `feature_deltas`, if the first
    judgment is more relevant than the second, it’s labeled with a `+1` in `predictor_deltas`.
    If the first judgment is less relevant, it is labeled with a `-1`. This pairwise
    transform algorithm yields training data (the `feature_deltas` and `predictor_deltas`)
    needed for binary classification.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的其余部分，我们将仔细介绍 SVMrank 的成对算法，该算法在列表 10.9 中概述。SVMrank 算法对每个查询的每个判断进行比较，并与该查询的每个其他判断进行比较。它计算该查询中每个相关和不相关成对的特征差异（`feature_deltas`）。在添加到
    `feature_deltas` 时，如果第一个判断比第二个判断更相关，则在 `predictor_deltas` 中标记为 `+1`。如果第一个判断不如第二个判断相关，则标记为
    `-1`。这种成对转换算法产生了用于二元分类所需的训练数据（`feature_deltas` 和 `predictor_deltas`）。
- en: Listing 10.9 Transforming features into pairwise data for SVMrank
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.9 将特征转换为 SVMrank 的成对数据
- en: '[PRE14]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#1 Stores a label of +1 if doc1 is more relevant than doc2.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 如果 doc1 比 doc2 更相关，则存储标签为 +1。'
- en: '#2 Stores the feature deltas'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 存储特征差值'
- en: '#3 Stores a label of –1 if doc1 is less relevant than doc2.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 如果 doc1 比 doc2 不相关，则存储标签为 -1。'
- en: '#4 Stores the feature deltas'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 存储特征差值'
- en: Figure 10.8 plots the pairwise differences and highlights important points.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 绘制了成对差异并突出了重要点。
- en: '![figure](../Images/CH10_F08_Grainger.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F08_Grainger.png)'
- en: Figure 10.8 Pairwise differences after SVMrank’s transformation for `social`
    `network` and `star wars` documents, along with a candidate separating hyperplane.
  id: totrans-172
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 10.8 展示了 SVMrank 对 `social` `network` 和 `star wars` 文档的转换后的成对差异，以及一个候选分离超平面。
- en: You’ll notice that the positive pairwise deltas (+) tend to be toward the upper
    right. This means relevant documents have a higher `title_bm25` and `overview_bm25`
    when compared to irrelevant ones.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到正的成对差值（+）倾向于向上右方。这意味着相关文档的 `title_bm25` 和 `overview_bm25` 与无关文档相比更高。
- en: That’s a lot to digest! Let’s walk through a few examples carefully, step-by-step,
    to see how this algorithm constructs the data points in figure 10.9\. This algorithm
    compares relevant and irrelevant documents for each query, comparing two documents
    (*Network* and *The Social Network*) within the query `social network` as shown
    in figure 10.9.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要很多消化！让我们仔细地一步一步地通过几个例子，看看这个算法是如何在图 10.9 中构建数据点的。这个算法比较每个查询的相关和不相关文档，比较查询
    `social network` 中的两个文档（*Network* 和 *The Social Network*），如图 10.9 所示。
- en: '![figure](../Images/CH10_F09_Grainger.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH10_F09_Grainger.png)'
- en: Figure 10.9 Comparing *Network* to *The Social Network* for the query `social`
    `network`
  id: totrans-176
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 10.9 比较 `social` `network` 查询中的 `Network` 与 `The Social Network`
- en: 'These are the features for *The Social Network*:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是《社交网络》的特征：
- en: '[PRE15]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#1 title_bm25 is 4.483 standard deviations above the mean, and overview_bm25
    is 2.100 standard deviations above the mean.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 title_bm25 的均值高于标准差 4.483，而 overview_bm25 的均值高于标准差 2.100。'
- en: 'These are the features for *Network*:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是《网络》的特征：
- en: '[PRE16]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '#1 title_bm25 is 3.101 standard deviations above the mean, and overview_bm25
    is 1.443 standard deviations above the mean.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 title_bm25 的均值高于标准差 3.101，而 overview_bm25 的均值高于标准差 1.443。'
- en: We then insert the delta between *The Social Network* and *Network* in the following
    listing.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后将《社交网络》与《网络》之间的差值插入到下面的列表中。
- en: Listing 10.10 Calculating and storing the feature delta
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.10 计算并存储特征差值
- en: '[PRE17]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#1 Adds [1.382, 0.657] to feature_deltas'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将 [1.382, 0.657] 添加到 feature_deltas'
- en: To restate listing 10.10, we might say that here is one example of a movie,
    *The Social Network*, that’s more relevant than the movie *Network* for this query
    `social network`. Interesting! Let’s look at what makes them different. Of course,
    “difference” in math means subtraction, which we’ll do here. Ah yes, after taking
    the difference we see *The Social Network’*s `title_bm25` is `1.382` standard
    deviations higher than *Network’*s; similarly, the `overview_bm25` is `0.657`
    standard deviations higher. Indeed, note the `+` for *The Social Network* minus
    *Network* in figure 10.8 showing the point `[1.382, 0.657]` amongst the deltas.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为了重申列表10.10，我们可以说，这里有一个例子，即电影《社交网络》，对于这个查询`social network`比电影《网络》更相关。有趣！让我们看看它们有什么不同。当然，数学中的“差异”意味着减法，我们在这里会这样做。是的，在取差之后，我们看到`The
    Social Network`的`title_bm25`比`Network`的`title_bm25`高1.382个标准差；同样，`overview_bm25`高0.657个标准差。确实，注意图10.8中显示的`The
    Social Network`减去`Network`的`+`号，在变化量中点 `[1.382, 0.657]`。
- en: The algorithm would also note that *Network* is less relevant than *The Social
    Network* for the query `social network`, as shown in figure 10.10.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 算法还会注意到，对于查询`social network`，`Network`不如`The Social Network`相关，如图10.10所示。
- en: '![figure](../Images/CH10_F10_Grainger.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH10_F10_Grainger.png)'
- en: Figure 10.10 Comparing *Network* to *The Social Network* for the query `social
    network`
  id: totrans-190
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.10 比较查询`social network`下的《网络》与《社交网络》
- en: Just as in listing 10.9, our code captures this difference in relevance between
    these two documents, but this time in the opposite direction (irrelevant-minus-relevant).
    So it’s no surprise that we see the same values, but in the negative.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 正如列表10.9中所示，我们的代码捕捉了这两个文档之间的相关性差异，但这次是在相反的方向（不相关减去相关）。因此，我们看到相同的值并不奇怪，但它们是负值。
- en: '[PRE18]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '#1 Evaluates to [–1.382, –0.657]'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 计算结果为[–1.382, –0.657]'
- en: In figure 10.11, we move on to another relevant-irrelevant comparison of two
    documents for the query `social network`, appending another comparison to the
    new training set.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在图10.11中，我们继续对两个与查询`social network`相关的文档进行相关-不相关比较，并将另一个比较添加到新的训练集中。
- en: Listing 10.11 shows appending both positive deltas (with the more relevant document
    listed first) and negative deltas (with the less relevant document listed first)
    for the highlighted pair of documents compared in figure 10.11.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.11显示了在图10.11中比较的突出显示的文档对中，添加了正变化量（更相关的文档排在前面）和负变化量（不那么相关的文档排在前面）。
- en: Listing 10.11 Adding the positive and negative deltas
  id: totrans-196
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.11 添加正负变化量
- en: '[PRE19]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '#1 Evaluates to [2.249, 2.544]'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 计算结果为[2.249, 2.544]'
- en: '#2 Evaluates to [–2.249, –2.544]'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 计算结果为[–2.249, –2.544]'
- en: '![figure](../Images/CH10_F11_Grainger.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH10_F11_Grainger.png)'
- en: Figure 10.11 Comparing *Social Genocide* to *The Social Network* for the query
    `social network`
  id: totrans-201
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.11 比较查询`social network`下的《社会大屠杀》与《社交网络》
- en: Once we iterate through every pairwise difference between documents matching
    the query `social network` to create a pointwise training set, we can move on
    to also logging differences for other queries. Figure 10.12 shows differences
    for a second query, this time comparing the relevance of documents matching the
    query `star wars`.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们迭代通过匹配查询`social network`的每对文档之间的差异以创建点训练集，我们就可以继续记录其他查询的差异。图10.12显示了第二个查询的差异，这次比较的是匹配查询`star
    wars`的文档的相关性。
- en: '![figure](../Images/CH10_F12_Grainger.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH10_F12_Grainger.png)'
- en: 'Figure 10.12 Comparing *Rogue One: A Star Wars Movie* to *Star!* for the query
    `star wars`. We’ve moved on from `social network` and have begun to look at patterns
    within another query.'
  id: totrans-204
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.12 比较查询`star wars`下的《侠盗一号：星球大战外传》与《星！》。我们已经从`social network`转向了另一个查询，并开始研究另一个查询中的模式。
- en: '[PRE20]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#1 Rogue One features minus Star! features'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 《侠盗一号》特色减去《星！》特色'
- en: '#2 Star! features minus Rogue One features'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 《星！》特色减去《侠盗一号》特色'
- en: We continue this process of calculating differences between feature values for
    relevant versus irrelevant documents until we have calculated all the pairwise
    differences for our training and test queries.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续这个过程，计算相关和不相关文档的特征值之间的差异，直到我们计算出所有训练和测试查询的成对差异。
- en: You can see back in figure 10.8 that the positive examples show a positive `title_bm25`
    delta, and possibly a slightly positive `overview_bm25` delta. This becomes even
    more clear if we calculate deltas over the full dataset of 100 queries, as shown
    in figure 10.13.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图10.8中看到，正例显示了正的`title_bm25`变化量，可能还有略微正的`overview_bm25`变化量。如果我们计算100个查询的全数据集的变化量，如图10.13所示，这会变得更加清晰。
- en: '![figure](../Images/CH10_F13_Grainger.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH10_F13_Grainger.png)'
- en: Figure 10.13 Full training set with a hyperplane separating relevant from irrelevant
    documents. We see a pattern! Relevant documents have a higher `title_bm25` and
    perhaps a modestly higher `overview_bm25`.
  id: totrans-211
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.13 完整训练集与分离相关和无关文档的超平面。我们看到一个模式！相关文档的`title_bm25`更高，也许`overview_bm25`也略有提高。
- en: Interesting! It is now very easy to visually identify that a larger `title_bm25`
    score match is highly correlated with a document being relevant for a query, and
    that having a higher `overview_bm25` score is at least somewhat positively correlated.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，现在很容易直观地识别出更大的`title_bm25`分数匹配与文档对查询的相关性高度相关，并且拥有更高的`overview_bm25`分数至少在一定程度上是正相关的。
- en: It’s worth taking a step back now and asking whether this formulation of ranking
    is appropriate for your domain. Different LTR models have their own method of
    mapping pairwise comparisons into classification problems as needed. As another
    example, LambdaMART—a popular LTR algorithm based on boosted trees—uses pairwise
    swapping and measures the change in *discounted cumulative gain* (DCG).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在值得退一步思考，看看这种排名公式的形式是否适合你的领域。不同的LTR模型都有自己的方法，将成对比较映射到所需的分类问题。作为另一个例子，LambdaMART——一种基于提升树的流行LTR算法——使用成对交换并测量**折算累积增益**（DCG）的变化。
- en: Next up, we’ll train a robust model to capture the patterns in our fully transformed
    ranking dataset.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将训练一个鲁棒的模型来捕捉我们完全转换后的排名数据集中的模式。
- en: '10.5 Step 4: Training (and testing!) the model'
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 步骤 4：训练（和测试！）模型
- en: Good machine learning clearly requires a lot of data preparation. Luckily, you’ve
    arrived at the section where we actually train a model! With the `feature_deltas`
    and `predictor_deltas` from the last section, we now have a training set suitable
    for training a ranking classifier. This model will let us predict when documents
    might be relevant, even for queries and documents it hasn’t seen yet.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的机器学习显然需要大量的数据准备。幸运的是，你已经到达了实际训练模型的章节！有了上一节中的`feature_deltas`和`predictor_deltas`，我们现在有一个适合训练排名分类器的训练集。这个模型将使我们能够预测文档何时可能相关，即使对于它尚未见过的查询和文档。
- en: 10.5.1 Turning a separating hyperplane’s vector into a scoring function
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.1 将分离超平面的向量转换为评分函数
- en: We’ve seen how SVMrank’s separating hyperplane can classify and differentiate
    irrelevant examples from the relevant ones. That’s useful, but you may remember
    that our task is to find *optimal* weights for our features, not just to classify
    documents. Let’s therefore look at how we can *score* search results using this
    hyperplane.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了SVMrank的分离超平面如何将无关的例子与相关的例子区分开来。这很有用，但你可能还记得，我们的任务是找到我们特征的**最优**权重，而不仅仅是分类文档。因此，让我们看看我们如何使用这个超平面来**评分**搜索结果。
- en: It turns out that the separating hyperplane also gives us what we need to learn
    optimal weights. Any hyperplane is defined by the vector orthogonal to the plane.
    So when an SVM machine learning library does its work, it gives us a sense of
    the weights that each feature should have, as shown in figure 10.14.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，分离超平面也为我们提供了学习最优权重所需的东西。任何超平面都是由垂直于平面的向量定义的。因此，当SVM机器学习库执行其工作时，它给我们一个感觉，即每个特征应该有的权重，如图10.14所示。
- en: '![figure](../Images/CH10_F14_Grainger.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH10_F14_Grainger.png)'
- en: Figure 10.14 Full training set with a candidate-separating hyperplane, showing
    the orthogonal vector defining the hyperplane.
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图10.14 完整训练集与候选分离超平面，显示定义超平面的正交向量。
- en: 'Think about what this orthogonal vector represents. This vector points in the
    direction of relevance! It says relevant examples are this way, and irrelevant
    ones are in the opposite direction. This vector *definitely* points to `title_bm25`
    having a strong influence on relevance, with some smaller influence coming from
    `overview_bm25`. This vector might be something like:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一下这个正交向量代表什么。这个向量指向相关性的方向！它说相关例子是这样的，无关的例子在相反的方向。这个向量**肯定**指向`title_bm25`对相关性有强烈的影响，同时`overview_bm25`有一些较小的影响。这个向量可能类似于：
- en: '[PRE21]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We used the pairwise transform algorithm in listing 10.9 to compute the deltas
    needed to perform classification between irrelevant and relevant examples. If
    we train an SVM on this data, as in the following listing, the model gives us
    the vector defining the separating hyperplane.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用列表10.9中的成对转换算法来计算执行无关和相关信息分类所需的delta值。如果我们在这个数据上训练一个SVM，如下面的列表所示，模型会给我们定义分离超平面的向量。
- en: Listing 10.12 Training a linear SVM with scikit-learn
  id: totrans-225
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.12使用scikit-learn训练线性SVM
- en: '[PRE22]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '#1 Creates a linear model with sklearn'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用sklearn创建线性模型'
- en: '#2 Fits to deltas using an SVM'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用SVM对delta进行拟合'
- en: '#3 The vector that defines the separating hyperplane'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 定义分离超平面的向量'
- en: 'Output:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE23]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Listing 10.12 trains an SVM to separate the `predictor_deltas` (remember they’re
    `+1` and `-1`) using the corresponding `feature_deltas` (the deltas in the normalized
    `title_bm25`, `overview_bm25`, and `release_year` features). The resulting model
    is a vector orthogonal to the separating hyperplane. As expected, it shows a strong
    weight on `title_bm25`, a more modest one on `overview_bm25`, and a weaker weight
    on `release_year`.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.12训练一个SVM来分离`predictor_deltas`（记住它们是`+1`和`-1`），使用相应的`feature_deltas`（归一化`title_bm25`、`overview_bm25`和`release_year`特征中的delta）。得到的模型是与分离超平面正交的向量。正如预期的那样，它对`title_bm25`有很强的权重，对`overview_bm25`有更适度的权重，对`release_year`的权重较弱。
- en: 10.5.2 Taking the model for a test drive
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.2 对模型进行测试
- en: 'How does this model work as a ranking function? Let’s suppose the user enters
    the query `wrath of khan`. How might this model score the document *Star Trek
    II: The Wrath of Khan* relative to this query? The unnormalized feature vector
    indicates a strong title and overview match for this query.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型作为排名函数是如何工作的？假设用户输入查询`wrath of khan`。这个模型会如何对这个查询的文档`星际迷航II：怒火中烧`进行评分？未归一化的特征向量表明这个查询有很强的标题和概述匹配。
- en: '[PRE24]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '#1 Raw features for “Star Trek II”'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 “星际迷航II”的原始特征'
- en: 'Normalizing it, each feature value is this many standard deviations above or
    below each feature’s mean:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化后，每个特征值是每个特征平均值的多少个标准差以上或以下：
- en: '[PRE25]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '#1 Normalized features for “Star Trek II”'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 “星际迷航II”的归一化特征'
- en: 'We simply multiply each normalized feature with its corresponding `coef_` value.
    Summing them then gives us a relevance score:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只是将每个归一化特征与其对应的`coef_`值相乘。将它们相加后，我们得到一个相关性分数：
- en: '[PRE26]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '#1 Relevance score calculation for “Star Trek II”'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 “星际迷航II”的相关性分数计算'
- en: 'How would this model rank *Star Trek III: The Search for Spock* relative to
    *Star Trek II: The Wrath of Khan* for our query `wrath of khan`? Hopefully not
    nearly as highly! Indeed, it doesn’t:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型会如何将“星际迷航III：寻宝”相对于“星际迷航II：怒火中烧”在我们的查询`wrath of khan`中的排名？希望不会太高！实际上，它并没有：
- en: '[PRE27]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '#1 Raw features for “Star Trek III”'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 “星际迷航III”的原始特征'
- en: '#2 Normalized features for “Star Trek III”'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 “星际迷航III”的归一化特征'
- en: '#3 Relevance calculation for “Star Trek III”'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 计算“星际迷航III”的相关性'
- en: The model seems to be correctly predicting the most relevant answer.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型似乎正确地预测了最相关的答案。
- en: 10.5.3 Validating the model
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.3 验证模型
- en: Testing a couple of queries helps us spot problems, but we’d prefer a more systematic
    way of checking if the model is generalizable.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 测试几个查询有助于我们发现问题，但我们更希望有一个更系统的方法来检查模型是否具有可推广性。
- en: One difference between LTR and traditional machine learning is that we usually
    evaluate queries and entire result sets, not individual data points, to prove
    our model is effective. We’ll perform a test/training split at the query level.
    This will let us spot types of queries with problems. We’ll evaluate using a simple
    precision metric, counting the proportion of results in the top *K* (with `k=5`
    in our case) that are relevant. You should choose the relevance metric best suited
    to your own use case.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: LTR与传统机器学习之间的一个区别是，我们通常评估查询和整个结果集，而不是单个数据点，以证明我们的模型是有效的。我们将在查询级别进行测试/训练分割。这将使我们能够发现存在问题的查询类型。我们将使用简单的精确度指标进行评估，计算前*K*（在我们的案例中`k=5`）个结果中有多少是相关的。你应该选择最适合你自己的用例的相关性指标。
- en: First, we will randomly put our queries into a test or training set, as shown
    in the following listing.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将我们的查询随机放入测试集或训练集，如下所示。
- en: Listing 10.13 Simple test/training split at the query level
  id: totrans-253
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.13在查询级别进行简单的测试/训练分割
- en: '[PRE28]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '#1 Identifies a random 10% of the judgments to go into the training set'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 从中随机选择10%的判断进入训练集'
- en: '#2 Places each judgment into training data (10%) or test set (90%)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将每个判断放入训练数据（10%）或测试集（90%）'
- en: With the training data split out, we can perform the pairwise transform trick
    from step 3\. We can then retrain on just the training data.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 将训练数据分割出来后，我们可以执行步骤3中的成对转换技巧。然后我们可以在仅使用训练数据的情况下重新训练。
- en: Listing 10.14 Train just on training data
  id: totrans-258
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.14仅使用训练数据进行训练
- en: '[PRE29]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '#1 Fits only to training data'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 仅适用于训练数据'
- en: 'Output:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE30]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: So far, we have held back the test data. Just like a good teacher, we don’t
    want to give the student all the answers. We want to see if the model has learned
    anything beyond rote memorization of the training examples.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们保留了测试数据。就像一个好的老师一样，我们不想给学生所有答案。我们想看看模型是否学到了除了死记硬背训练示例之外的东西。
- en: In the next listing, we evaluate our model using the test data. This code loops
    over every test query and ranks every test judgment using the model. It then computes
    the precision for the top four judgments.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个列表中，我们使用测试数据评估我们的模型。此代码遍历每个测试查询，并使用模型对每个测试判断进行排序。然后，它计算前四个判断的精确度。
- en: Listing 10.15 Can our model generalize beyond the training data?
  id: totrans-265
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.15 我们的模型能否泛化到训练数据之外？
- en: '[PRE31]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '#1 For each test query'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 对于每个测试查询'
- en: '#2 Scores each judgment and ranks this query using the model'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用模型对每个判断进行评分并排序此查询'
- en: '#3 Compute the precisions for this query'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 计算此查询的精确度'
- en: 'Evaluation:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 评估：
- en: '[PRE32]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: On multiple runs, you should expect a precision of approximately 0.3–0.4\. Not
    bad for our first iteration, where we just guessed at a few features (`title_bm25`,
    `overview_bm25`, and `release_year`)!
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在多次运行中，你应该期望精确度大约为 0.3–0.4。对于我们第一次迭代，只是猜测了几个特征（`title_bm25`、`overview_bm25`
    和 `release_year`），这还不错！
- en: In LTR, you can always look back at previous steps to see what might be improved.
    This precision test is the first time we’ve been able to systematically evaluate
    our model, so it’s a natural time to revisit the features to see how the precision
    might be improved in subsequent runs. Go all the way back up to step 2\. See what
    examples are on the wrong side of the separating hyperplane. For example, if you
    look back at figure 10.8, the third Star Wars movie, *Return of the Jedi*, fits
    a pattern of a relevant document that doesn’t have a keyword match in the title.
    In the absence of a title, what other features might be added to help capture
    that a movie belongs in a specific collection like Star Wars? Perhaps there is
    a property within the TMDB dataset that we could experiment with.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LTR 中，你总是可以回顾之前的步骤，看看可能有哪些改进。这个精确度测试是我们第一次能够系统地评估我们的模型，因此这是一个自然的时间来回顾特征，看看在后续运行中精确度可能如何提高。一直回溯到步骤
    2。看看哪些例子位于分离超平面的错误一侧。例如，如果你回顾图 10.8，第三部星球大战电影，《星球大战：绝地归来》，它符合一个相关文档的模式，标题中没有关键词匹配。在没有标题的情况下，可以添加哪些其他特征来帮助捕捉这部电影属于像星球大战这样的特定收藏？也许
    TMDB 数据集中有一个我们可以实验的属性。
- en: For now, though, let’s take the model we just built and see how we can deploy
    it to production.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现在让我们看看我们刚刚构建的模型，看看我们如何将其部署到生产环境中。
- en: '10.6 Steps 5 and 6: Upload a model and search'
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.6 步骤 5 和 6：上传模型和搜索
- en: In this section, we’ll finally upload our model so that it can be applied to
    rank future search results. We’ll then discuss both applying the model to rank
    all documents, as well as applying it to rerank an already-run and likely more
    efficient initial query. Finally, we’ll discuss some of the performance implications
    of using LTR models in production.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们最终将上传我们的模型，以便它可以应用于对未来的搜索结果进行排名。然后，我们将讨论将模型应用于对所有文档进行排名，以及将其应用于重新排名一个已经运行且可能更有效的初始查询。最后，我们将讨论在生产中使用
    LTR 模型的性能影响。
- en: 10.6.1 Deploying and using the LTR model
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.1 部署和使用 LTR 模型
- en: 'Originally, we presented our objective as finding *ideal* boosts for a hardcoded
    ranking function like the one in listing 10.2:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我们提出的目标是找到对硬编码的排名函数（如列表 10.2 中的函数）的 *理想* 提升值：
- en: '[PRE33]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: This boosted query indeed multiplies each feature by a weight (the boost) and
    sums the results. But it turns out that we don’t want the search engine to multiply
    the *raw* feature values. Instead, we need the feature values to be normalized.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 这个增强查询确实将每个特征乘以一个权重（增强）并将结果相加。但结果证明，我们不想让搜索引擎乘以 *原始* 特征值。相反，我们需要特征值进行归一化。
- en: Many search engines let us store a linear ranking model along with feature normalization
    statistics. We saved the `means` and `std_devs` of each feature, which will be
    used to normalize values for any document being evaluated. These coefficients
    are associated with each feature when uploading the model, as shown in the next
    listing.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 许多搜索引擎允许我们存储线性排名模型以及特征归一化统计信息。我们保存了每个特征的 `means` 和 `std_devs`，这些将被用于对任何正在评估的文档进行归一化。这些系数在上传模型时与每个特征相关联，如下一个列表所示。
- en: Listing 10.16 Generating and uploading a linear model
  id: totrans-282
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 10.16 生成和上传线性模型
- en: '[PRE34]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Generated linear model (for `engine=solr`):'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的线性模型（对于 `engine=solr`）：
- en: '[PRE35]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '#1 Feature store to locate the features'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 特征存储以定位特征'
- en: '#2 Which feature to execute before evaluating this model'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 在评估此模型之前要执行哪个特征'
- en: '#3 How to normalize this feature before applying the weight'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 在应用权重之前如何归一化此特征'
- en: '#4 The weight of each feature in the model'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 模型中每个特征的权重'
- en: The `response` from listing 10.16 is Solr-specific and will change depending
    on which search engine you have configured. Next, we can issue a search using
    the uploaded LTR model, as shown in the following listing.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.16中的`response`是Solr特定的，并且会根据您配置的搜索引擎而变化。接下来，我们可以使用上传的LTR模型发出搜索，如下面的列表所示。
- en: Listing 10.17 Ranking all documents with LTR model for `harry potter`
  id: totrans-291
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.17 使用LTR模型对`harry potter`进行所有文档排序
- en: '[PRE36]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Engine-specific search request (for `engine=solr`):'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 特定于引擎的搜索请求（对于`engine=solr`）：
- en: '[PRE37]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '#1 Executes our model over the maximum number of documents with the specified
    parameters'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用指定参数在最大数量的文档上执行我们的模型'
- en: 'Returned documents:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的文档：
- en: '[PRE38]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: In listing 10.17, the LTR model ranks all the documents in the corpus using
    the keywords in the `rerank_query` parameter as input to the model. Since no initial
    `query` parameter is specified in the request, no matching filter is applied to
    the collection before the search results (all documents) are ranked by the LTR
    model. Though scoring such a large number of documents with the model will lead
    to nontrivial latency, it allows us to test the model directly, absent of any
    other matching parameters.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表10.17中，LTR模型使用`rerank_query`参数中的关键词作为模型的输入，对所有语料库中的文档进行排序。由于请求中没有指定初始`query`参数，因此在搜索结果（所有文档）被LTR模型排序之前，不对集合应用匹配过滤器。尽管使用该模型对如此大量的文档进行评分会导致非平凡的延迟，但它允许我们在没有其他匹配参数的情况下直接测试模型。
- en: Notice in listing 10.17 the use of the term “rerank” in the `rerank_query` parameter.
    As this term implies, LTR usually happens as a second ranking phase on results
    first calculated by a more efficient algorithm (such as BM25 and/or an initial
    Boolean match). This is to reduce the number of documents that must be scored
    by the more expensive LTR model. The following listing demonstrates executing
    a baseline search and then reranking the top `500` results with the LTR model.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在列表10.17中`rerank_query`参数中使用了“重新排序”这个术语。正如这个术语所暗示的，LTR通常作为第二个排序阶段，在由更有效的算法（如BM25和/或初始布尔匹配）首先计算出的结果上发生。这是为了减少必须由更昂贵的LTR模型评分的文档数量。以下列表演示了执行基线搜索然后使用LTR模型重新排序前`500`个结果。
- en: Listing 10.18 Searching for `harry potter` and reranking with the model
  id: totrans-300
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表10.18 使用模型对`harry potter`进行搜索和重新排序
- en: '[PRE39]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Engine-specific search request (for `engine=solr`):'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 特定于引擎的搜索请求（对于`engine=solr`）：
- en: '[PRE40]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '#1 First-pass Solr query—a simple keyword query with BM25 ranking'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 首次通过Solr查询——一个简单的带有BM25排序的关键词查询'
- en: '#2 Reranks only the top 500 documents'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 仅重新排序前500个文档'
- en: 'Returned documents:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的文档：
- en: '[PRE41]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This request is much faster, and it still yields the same top results when performing
    the cheaper initial BM25 ranking on the filtered `query` followed by the more
    expensive LTR-based reranking on just the top `500` results.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这个请求速度更快，并且在执行更便宜的初始BM25排序（在过滤的`query`之后）以及仅对前`500`个结果进行昂贵的基于LTR的重新排序时，仍然会产生相同的前几名结果。
- en: 10.6.2 A note on LTR performance
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.6.2 关于LTR性能的说明
- en: 'As you can see, many steps are required to build a real-world LTR model. Let’s
    close the chapter with some additional thoughts on practical performance constraints
    in LTR systems:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，构建一个真实的LTR模型需要许多步骤。让我们以对LTR系统中实际性能约束的一些额外思考来结束本章。
- en: '*Model complexity*—The more complex the model, the more accurate it *might*
    be. A simpler model can be faster and easier to understand, though perhaps less
    accurate. Here we’ve stuck to a very simple model (a set of linear weights). Imagine
    a complex deep-learning model—how well would that work? Would the complexity be
    worth it? Would it be as generalizable (or could it possibly be more generalizable)?'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型复杂性*——模型越复杂，可能越准确。一个简单的模型可能更快、更容易理解，尽管可能不太准确。在这里，我们坚持使用一个非常简单的模型（一组线性权重）。想象一下复杂的深度学习模型——它会工作得怎么样？复杂性是否值得？它是否具有足够的泛化能力（或者它可能具有更强的泛化能力）？'
- en: '*Rerank depth*—The deeper you rerank, the more you might find additional documents
    that could be hidden gems. On the other hand, the deeper you rerank, the more
    compute cycles your model spends scoring results in your live search engine cluster.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*重新排序深度*——重新排序越深，可能找到的额外文档就越多，这些文档可能是隐藏的宝藏。另一方面，重新排序越深，模型在您的实时搜索引擎集群中评分结果所花费的计算周期就越多。'
- en: '*Feature complexity*—If you compute very complex features at query time, they
    might help your model. However, they’ll slow down evaluation and search response
    time.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征复杂性*——如果你在查询时计算非常复杂的特征，它们可能会帮助你的模型。然而，它们会减慢评估和搜索响应时间。'
- en: '*Number of features*—A model with many features might lead to higher relevance.
    However, it will also take more time to compute every feature on each document,
    so ask yourself which features are crucial. Many academic LTR systems use hundreds.
    Practical LTR systems usually boil these down to dozens. You will almost always
    see diminishing returns for relevance ranking and rising compute and latency costs
    as you continue adding additional features, so prioritizing which features to
    include is important.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征数量*——具有许多特征的模型可能会导致更高的相关性。然而，它将需要更多的时间来计算每个文档上的每个特征，所以问问自己哪些特征是至关重要的。许多学术LTR系统使用数百个。实用的LTR系统通常将这些特征减少到几十个。你几乎总是会看到相关性排名的递减回报，以及随着你继续添加更多特征而计算和延迟成本的上升，因此优先考虑要包含哪些特征是很重要的。'
- en: Cross-encoders
  id: totrans-315
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 跨度编码器
- en: A cross-encoder is a specialized kind of machine-learned ranking model. Cross-encoders
    are trained to score the relevance of two pieces of input (usually text), such
    as a query and a document. They use a Transformer architecture to combine both
    pieces of input into a single representation, which is then used in search to
    rank the relevance of the document for the query based upon interpreting both
    the query and document within their shared semantic context. Cross-encoders are
    ranking classifiers, like other LTR models, but they are unique in that they are
    pretrained on a large amount of data and are generally only focused on the textual
    similarity between the query and document instead of other features like popularity,
    recency, or user behavior. While they can be fine-tuned on your dataset, they
    are often used as is, since they are already trained on a large amount of data
    and can generalize well to new textual inputs.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 跨度编码器是一种专门的机器学习排名模型。跨度编码器被训练来评分两段输入（通常是文本）的相关性，例如查询和文档。它们使用Transformer架构将这两段输入组合成一个单一表示，然后在搜索中使用这个表示来根据查询和文档在共享语义上下文中的解释来排名文档对查询的相关性。跨度编码器是排名分类器，就像其他LTR模型一样，但它们独特之处在于它们在大数据集上进行了预训练，并且通常只关注查询和文档之间的文本相似性，而不是其他特征，如流行度、时效性或用户行为。虽然它们可以在你的数据集上进行微调，但它们通常直接使用，因为它们已经在大量数据上进行了训练，并且可以很好地泛化到新的文本输入。
- en: Cross-encoders are very easy to use out of the box, and they’re often the easiest
    way to get started with machine-learned ranking without having to do your own
    training. Cross-encoders tend to be slow, so they’re not typically used to rerank
    large numbers of documents. Our focus in this chapter and in the coming chapter
    is on more flexible models that can use reflected intelligence, including those
    trained on your users’ judgments and implicit judgments from user signals, but
    it’s good to be familiar with cross-encoders, as they are a popular choice for
    many search teams, particularly when just getting started. We’ll cover cross-encoders
    in more detail, with example code, in section 13.7\.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 跨度编码器非常容易使用，通常也是开始使用机器学习排名而不必进行自己训练的最简单方式。跨度编码器通常运行较慢，因此通常不用于重新排序大量文档。在本章和下一章中，我们的重点是更灵活的模型，这些模型可以使用反射智能，包括基于用户判断和用户信号隐式判断的模型，但了解跨度编码器是很有好处的，因为它们是许多搜索团队的首选，尤其是在刚开始的时候。我们将在第13.7节中更详细地介绍跨度编码器，包括示例代码。
- en: 10.7 Rinse and repeat
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.7 清洗并重复
- en: Congrats! You’ve done one full cycle of LTR! Like many data problems, though,
    you’ll likely need to continue iterating on the problem. There’s always something
    new you can do to improve.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经完成了一个完整的LTR循环！尽管如此，像许多数据问题一样，你可能需要继续迭代问题。你总是可以做一些新的事情来提高。
- en: 'On your second iteration, you might consider the following:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的第二次迭代中，你可能需要考虑以下内容：
- en: '*New and better features*—Are there types of queries or examples on which the
    model performs poorly, such as `title` searches where there’s no `title` mention?
    (“Star Wars” is not mentioned in the title of *Return of the Jedi*. What features
    could capture these?) Could we incorporate lessons from chapters 1–9 to construct
    more advanced features?'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*新和更好的特征*——模型在哪些类型的查询或示例上表现不佳，例如在没有任何`title`提及的`title`搜索中？ （“星球大战”没有在《星球大战：帝国反击战》的标题中提及。哪些特征可以捕捉这些？）我们能从第1章到第9章的章节中吸取教训来构建更高级的特征吗？'
- en: '*Training data coverage of all features*—The flip side of more features is
    more training data. As you increase the features you’d like to try, you should
    be wondering whether your training data has enough examples of relevant and irrelevant
    documents across each different combination of your features. Otherwise, your
    model won’t know how to use features to solve the problem.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*所有特征的训练数据覆盖范围*——更多特征意味着更多的训练数据。随着你想要尝试的特征增加，你应该想知道你的训练数据是否在每个不同特征组合中都有足够的相关和不相关文档的示例。否则，你的模型将不知道如何使用特征来解决问题。'
- en: '*Different model architectures*—We used a relatively simple model that expects
    features to linearly and independently correlate with relevance, but relevance
    can often be nonlinear and multidimensional. A shopper searching for `ipad` might
    expect the most recent Apple iPad release, except when they add the word “cable”,
    making the query `ipad cable`. For that query, the shopper might just want the
    cheapest cable they can find instead of the most recent. In this case, there may
    be “recency” and “price” features that activate depending on specific keyword
    combinations, necessitating a more complicated model architecture.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*不同的模型架构*——我们使用了一个相对简单的模型，该模型期望特征线性且独立地与相关性相关联，但相关性通常是非线性且多维的。一个搜索`ipad`的购物者可能期望最新的苹果iPad发布，除非他们添加了“cable”这个词，使查询变为`ipad
    cable`。对于这个查询，购物者可能只想找到最便宜的电缆，而不是最新的。在这种情况下，可能会有“时效性”和“价格”特征根据特定的关键词组合激活，需要更复杂的模型架构。'
- en: 'In the next chapter, we will focus on the foundation of good LTR: great judgments!'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将重点关注良好LTR的基础：出色的判断！
- en: Summary
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Learning to rank (LTR) builds generalized ranking functions that can be applied
    across all searches, using robust machine learning techniques.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习排序（LTR）构建了可以应用于所有搜索的泛化排序函数，使用稳健的机器学习技术。
- en: LTR features generally correspond to search queries. Search engines that support
    LTR often let you store and log features for use when training, and later applying,
    a ranking model.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LTR特征通常对应于搜索查询。支持LTR的搜索引擎通常允许你在训练和后来应用排序模型时存储和记录特征。
- en: We have tremendous freedom in what features we use to generalize relevance.
    Features could be properties of queries (like the number of terms), properties
    of documents (like popularity), or relationships between queries and documents
    (like BM25 or other relevance scores).
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在用于泛化相关性的特征选择上拥有巨大的自由度。特征可以是查询的属性（如术语数量），文档的属性（如流行度），或者查询和文档之间的关系（如BM25或其他相关性分数）。
- en: To do LTR well and apply well-known machine learning techniques, we typically
    reformulate the relevance ranking problem into a traditional, pointwise machine
    learning problem.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要做好LTR并应用已知的机器学习技术，我们通常将相关性排序问题重新表述为传统的、点对点的机器学习问题。
- en: SVMrank creates simple linear weights on normalized feature values, a good first
    step on your LTR journey.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVMrank 在归一化特征值上创建简单的线性权重，这是你在LTR旅程中的良好开端。
- en: To be truly useful, we need our model to generalize beyond what it’s learned.
    We can confirm an LTR model’s ability to generalize by setting some judgments
    aside in a test dataset and not using them during training. After training, we
    can then evaluate the model on that previously unseen test dataset to confirm
    the model’s ability to generalize.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要真正有用，我们需要我们的模型泛化到它所学习的内容之外。我们可以通过在测试数据集中留出一些判断并不在训练中使用它们来确认LTR模型泛化的能力。训练后，我们可以在之前未见过的测试数据集上评估模型，以确认模型的泛化能力。
- en: Once an LTR model is loaded into your search engine, be sure to consider performance
    (as in speed) tradeoffs with relevance. Real-life search systems require both.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦LTR模型加载到你的搜索引擎中，务必考虑性能（如速度）与相关性的权衡。现实世界的搜索系统都需要这两者。
