["```py\nfrom sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier\n\niris = load_iris(as_frame=True)\nX_iris = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\ny_iris = iris.target\n\ntree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\ntree_clf.fit(X_iris, y_iris)\n```", "```py\nfrom sklearn.tree import export_graphviz\n\nexport_graphviz(\n        tree_clf,\n        out_file=\"iris_tree.dot\",\n        feature_names=[\"petal length (cm)\", \"petal width (cm)\"],\n        class_names=iris.target_names,\n        rounded=True,\n        filled=True\n    )\n```", "```py\nfrom graphviz import Source\n\nSource.from_file(\"iris_tree.dot\")\n```", "```py\n>>> tree_clf.predict_proba([[5, 1.5]]).round(3) `array([[0\\.   , 0.907, 0.093]])`\n`>>>` `tree_clf``.``predict``([[``5``,` `1.5``]])` `` `array([1])` ``\n```", "```py```", "```py```", "```py from sklearn.datasets import make_moons  X_moons, y_moons = make_moons(n_samples=150, noise=0.2, random_state=42)  tree_clf1 = DecisionTreeClassifier(random_state=42) tree_clf2 = DecisionTreeClassifier(min_samples_leaf=5, random_state=42) tree_clf1.fit(X_moons, y_moons) tree_clf2.fit(X_moons, y_moons) ```", "```py >>> X_moons_test, y_moons_test = make_moons(n_samples=1000, noise=0.2, `... `                                        `random_state``=``43``)` ```", "```py` `>>>` `tree_clf1``.``score``(``X_moons_test``,` `y_moons_test``)` ```", "```py ```", "```py`` ```", "```py `` `Indeed, the second tree has a better accuracy on the test set.` `` ```", "```py```", "````` ```py`# Regression    Decision trees are also capable of performing regression tasks. While linear regression only works well with linear data, decision trees can fit all sorts of complex datasets. Let’s build a regression tree using Scikit-Learn’s `DecisionTreeRegressor` class, training it on a noisy quadratic dataset with `max_depth=2`:    ``` import numpy as np from sklearn.tree import DecisionTreeRegressor  rng = np.random.default_rng(seed=42) X_quad = rng.random((200, 1)) - 0.5  # a single random input feature y_quad = X_quad ** 2 + 0.025 * rng.standard_normal((200, 1))  tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42) tree_reg.fit(X_quad, y_quad) ```py    The resulting tree is represented in [Figure 5-4](#regression_tree).  ![A decision tree diagram for regression, showing how input variables are split at different nodes with squared error, sample size, and predicted value at each node.](assets/hmls_0504.png)  ###### Figure 5-4\\. A decision tree for regression    This tree looks very similar to the classification tree you built earlier. The main difference is that instead of predicting a class in each node, it predicts a value. For example, suppose you want to make a prediction for a new instance with *x*[1] = 0.2\\. The root node asks whether *x*[1] ≤ 0.343\\. Since it is, the algorithm goes to the left child node, which asks whether *x*[1] ≤ –0.302\\. Since it is not, the algorithm goes to the right child node. This is a leaf node, and it predicts `value=0.038`. This prediction is the average target value of the 133 training instances associated with this leaf node, and it results in a mean squared error equal to 0.002 over these 133 instances.    This model’s predictions are represented on the left in [Figure 5-5](#tree_regression_plot). If you set `max_depth=3`, you get the predictions represented on the right. Notice how the predicted value for each region is always the average target value of the instances in that region. The algorithm splits each region in a way that makes most training instances as close as possible to that predicted value.  ![Two plots show decision tree regression predictions: the left with max depth 2 having simpler splits, and the right with max depth 3 showing more detailed splits.](assets/hmls_0505.png)  ###### Figure 5-5\\. Predictions of two decision tree regression models    The CART algorithm works as described earlier, except that instead of trying to split the training set in a way that minimizes impurity, it now tries to split the training set in a way that minimizes the MSE. [Equation 5-4](#regression_cart_cost_function) shows the cost function that the algorithm tries to minimize.    ##### Equation 5-4\\. CART cost function for regression  $upper J left-parenthesis k comma t Subscript k Baseline right-parenthesis equals StartFraction m Subscript left Baseline Over m EndFraction MSE Subscript left Baseline plus StartFraction m Subscript right Baseline Over m EndFraction MSE Subscript right Baseline where StartLayout Enlarged left-brace 1st Row  MSE Subscript node Baseline equals StartFraction sigma-summation Underscript i element-of node Endscripts left-parenthesis ModifyingAbove y With caret Subscript node Baseline minus y Superscript left-parenthesis i right-parenthesis Baseline right-parenthesis squared Over m Subscript node Baseline EndFraction 2nd Row  ModifyingAbove y With caret Subscript node Baseline equals StartFraction sigma-summation Underscript i element-of node Endscripts y Superscript left-parenthesis i right-parenthesis Baseline Over m Subscript node Baseline EndFraction EndLayout$  Just like for classification tasks, decision trees are prone to overfitting when dealing with regression tasks. Without any regularization (i.e., using the default hyperparameters), you get the predictions on the left in [Figure 5-6](#tree_regression_regularization_plot). These predictions are obviously overfitting the training set very badly. Just setting `min_samples_leaf=10` results in a much more reasonable model, represented on the right in [Figure 5-6](#tree_regression_regularization_plot).  ![Comparison of regression tree predictions showing overfitting with no restrictions and improved fit with `min_samples_leaf=10`.](assets/hmls_0506.png)  ###### Figure 5-6\\. Predictions of an unregularized regression tree (left) and a regularized tree (right)    # Sensitivity to Axis Orientation    Hopefully by now you are convinced that decision trees have a lot going for them: they are relatively easy to understand and interpret, simple to use, versatile, and powerful. However, they do have a few limitations. First, as you may have noticed, decision trees love orthogonal decision boundaries (all splits are perpendicular to an axis), which makes them sensitive to the data’s orientation. For example, [Figure 5-7](#sensitivity_to_rotation_plot) shows a simple linearly separable dataset: on the left, a decision tree can split it easily, while on the right, after the dataset is rotated by 45°, the decision boundary looks unnecessarily convoluted. Although both decision trees fit the training set perfectly, it is very likely that the model on the right will not generalize well.  ![Diagram showing decision trees' sensitivity to data orientation, with a clear boundary before rotation and a complex boundary after rotation by 45 degrees.](assets/hmls_0507.png)  ###### Figure 5-7\\. Sensitivity to training set rotation    One way to limit this problem is to scale the data, then apply a principal component analysis (PCA) transformation. We will look at PCA in detail in [Chapter 7](ch07.html#dimensionality_chapter), but for now you only need to know that it rotates the data in a way that reduces the correlation between the features, which often (not always) makes things easier for trees.    Let’s create a small pipeline that scales the data and rotates it using PCA, then train a `DecisionTreeClassifier` on that data. [Figure 5-8](#pca_preprocessing_plot) shows the decision boundaries of that tree: as you can see, the rotation makes it possible to fit the dataset pretty well using only one feature, *z*[1], which is a linear function of the original petal length and width. Here’s the code:    ``` from sklearn.decomposition import PCA from sklearn.pipeline import make_pipeline from sklearn.preprocessing import StandardScaler  pca_pipeline = make_pipeline(StandardScaler(), PCA()) X_iris_rotated = pca_pipeline.fit_transform(X_iris) tree_clf_pca = DecisionTreeClassifier(max_depth=2, random_state=42) tree_clf_pca.fit(X_iris_rotated, y_iris) ```py    ###### Tip    The `DecisionTreeClassifier` and `DecisionTreeRegressor` classes both support missing values natively, no need for an imputer.  ![Diagram illustrating decision boundaries of a decision tree on the scaled and PCA-rotated iris dataset, with separate regions for Iris setosa, versicolor, and virginica.](assets/hmls_0508.png)  ###### Figure 5-8\\. A tree’s decision boundaries on the scaled and PCA-rotated iris dataset    # Decision Trees Have a High Variance    More generally, the main issue with decision trees is that they have quite a high variance: small changes to the hyperparameters or to the data may produce very different models. In fact, since the training algorithm used by Scikit-Learn is stochastic—it randomly selects the set of features to evaluate at each node—even retraining the same decision tree on the exact same data may produce a very different model, such as the one represented in [Figure 5-9](#decision_tree_high_variance_plot) (unless you set the `random_state` hyperparameter). As you can see, it looks very different from the previous decision tree ([Figure 5-2](#decision_tree_decision_boundaries_plot)).  ![Diagram showing decision boundaries for petal width and length in a decision tree, illustrating high variance due to changes in depth and classification regions.](assets/hmls_0509.png)  ###### Figure 5-9\\. Retraining the same model on the same data may produce a very different model    Luckily, by averaging predictions over many trees, it’s possible to reduce variance significantly. Such an *ensemble* of trees is called a *random forest*, and it’s one of the most powerful types of models available today, as you will see in the next chapter.    # Exercises    1.  What is the approximate depth of a decision tree trained (without restrictions) on a training set with one million instances?           2.  Is a node’s Gini impurity generally lower or higher than its parent’s? Is it *generally* lower/higher, or *always* lower/higher?           3.  If a decision tree is overfitting the training set, is it a good idea to try decreasing `max_depth`?           4.  If a decision tree is underfitting the training set, is it a good idea to try scaling the input features?           5.  If it takes one hour to train a decision tree on a training set containing one million instances, roughly how much time will it take to train another decision tree on a training set containing ten million instances? Hint: consider the CART algorithm’s computational complexity.           6.  If it takes one hour to train a decision tree on a given training set, roughly how much time will it take if you double the number of features?           7.  Train and fine-tune a decision tree for the moons dataset by following these steps:               1.  Use `make_moons(n_samples=10000, noise=0.4)` to generate a moons dataset.                       2.  Use `train_test_split()` to split the dataset into a training set and a test set.                       3.  Use grid search with cross-validation (with the help of the `GridSearchCV` class) to find good hyperparameter values for a `DecisionTreeClassifier`. Hint: try various values for `max_leaf_nodes`.                       4.  Train it on the full training set using these hyperparameters, and measure your model’s performance on the test set. You should get roughly 85% to 87% accuracy.                   8.  Grow a forest by following these steps:               1.  Continuing the previous exercise, generate 1,000 subsets of the training set, each containing 100 instances selected randomly. Hint: you can use Scikit-Learn’s `ShuffleSplit` class for this.                       2.  Train one decision tree on each subset, using the best hyperparameter values found in the previous exercise. Evaluate these 1,000 decision trees on the test set. Since they were trained on smaller sets, these decision trees will likely perform worse than the first decision tree, achieving only about 80% accuracy.                       3.  Now comes the magic. For each test set instance, generate the predictions of the 1,000 decision trees, and keep only the most frequent prediction (you can use SciPy’s `mode()` function for this). This approach gives you *majority-vote predictions* over the test set.                       4.  Evaluate these predictions on the test set: you should obtain a slightly higher accuracy than your first model (about 0.5 to 1.5% higher). Congratulations, you have trained a random forest classifier!                      Solutions to these exercises are available at the end of this chapter’s notebook, at [*https://homl.info/colab-p*](https://homl.info/colab-p).    ^([1](ch05.html#id1673-marker)) P is the set of problems that can be solved in *polynomial time* (i.e., a polynomial of the dataset size). NP is the set of problems whose solutions can be verified in polynomial time. An NP-hard problem is a problem that can be reduced to a known NP-hard problem in polynomial time. An NP-complete problem is both NP and NP-hard. A major open mathematical question is whether P = NP. If P ≠ NP (which seems likely), then no polynomial algorithm will ever be found for any NP-complete problem (except perhaps one day on a quantum computer).    ^([2](ch05.html#id1674-marker)) This *big O notation* means that as *m* (i.e., the number of training instances) gets larger, the computation time becomes proportional to the exponential of *m* (it’s actually an upper bound, but we make it as small as we can). This tells us how “fast” the computation grows with *m*, and *O*(exp(*m*)) is very fast.    ^([3](ch05.html#id1691-marker)) See Sebastian Raschka’s [interesting analysis](https://homl.info/19) for more details.```` ```py`` `````", "``````py` ``````"]