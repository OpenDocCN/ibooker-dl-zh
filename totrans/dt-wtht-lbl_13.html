<html><head></head><body>

  <div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">11</span> </span> <span class="chapter-title-text">End-to-end model deployment</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header">This chapter covers</h3> 
   <ul> 
    <li class="readable-text" id="p2">The end-to-end model deployment process</li> 
    <li class="readable-text" id="p3">Maintenance of the model postdeployment</li> 
    <li class="readable-text" id="p4">Python codes for each of the steps </li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p5"> 
   <blockquote>
    <div>
     The journey is the destination. 
     <div class=" quote-cite">
       —Dan Eldon 
     </div>
    </div>
   </blockquote> 
  </div> 
  <div class="readable-text" id="p6"> 
   <p>The path to learning never ends. It takes a lot of courage, patience, and hard work to learn something. We have to be persistent, resourceful, and always looking for opportunities to learn and excel. </p> 
  </div> 
  <div class="readable-text intended-text" id="p7"> 
   <p>Across all of the chapters so far, you have covered a lot of concepts, techniques, and algorithms. In this last chapter of the book, we are going to discuss the end-to-end model deployment process. We will cover various aspects ranging from a business problem definition, data cleaning, and exploratory data analysis (EDA) to model deployment and maintenance. This end-to-end journey is crucial for you to appreciate the entire process. We will discuss Python codes at all the relevant places. </p> 
  </div> 
  <div class="readable-text intended-text" id="p8"> 
   <p>Welcome to this last chapter, and all the very best!</p> 
  </div> 
  <div class="readable-text" id="p9"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.1</span> The machine learning modeling process</h2> 
  </div> 
  <div class="readable-text" id="p10"> 
   <p>Recall in chapter 1 we briefly discussed end-to-end model development. In this section, we cover each of the respective steps in detail and the most common problems we face with each of them and how to tackle them. It will finally lead to the model deployment phase. Figure 11.1 shows the model development process we follow.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p11">  
   <img alt="figure" src="../Images/CH11_F01_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 11.1</span> The complete machine learning modeling process </h5>
  </div> 
  <div class="readable-text" id="p12"> 
   <p>The steps in the model development process are as follows:</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p13"> Business problem definition </li> 
   <li class="readable-text" id="p14"> Data discovery and feasibility analysis </li> 
   <li class="readable-text" id="p15"> Data cleaning and prepreparation </li> 
   <li class="readable-text" id="p16"> Exploratory data analysis </li> 
   <li class="readable-text" id="p17"> Modeling process and business approval </li> 
   <li class="readable-text" id="p18"> Model deployment </li> 
   <li class="readable-text" id="p19"> Model documentation </li> 
   <li class="readable-text" id="p20"> Model maintenance and model refresh </li> 
  </ol> 
  <div class="readable-text" id="p21"> 
   <p>Throughout this chapter, we will cover each of these processes in much more detail. These are all relevant to the modeling process.</p> 
  </div> 
  <div class="readable-text" id="p22"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.2</span> Business problem definition</h2> 
  </div> 
  <div class="readable-text" id="p23"> 
   <p>Your business problem definition is the very first step. It is vital that the business problem is concise, clear, measurable, and achievable. Many times, in practice, the business problem is vaguely defined, such as “decrease the costs or increase the revenue,” which often leads to poor results throughout the rest of the process. A good business problem is defined clearly with key performance indicators (KPIs) and parameters that can be used to measure the effect. A good business problem ensures there is no ambiguity, the goal is clear, and we can achieve it with the available resources and within the timeframe. </p> 
  </div> 
  <div class="readable-text intended-text" id="p24"> 
   <p>Some of the most important considerations regarding a business problem are as follows:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p25"> If a business problem is vaguely defined, it is going to cause problems and should be avoided. For example, all of the businesses and various functions would want to increase their revenue and profits, reduce costs, optimize various processes, and so forth. With a vague business problem, we will not have clarity on the process, which will lead to ambiguity. </li> 
   <li class="readable-text" id="p26"> The business purpose should be practically achievable. Unrealistic goals like doubling the revenue or halving the cost should not be set. Unrealistic goals mean that good results might get rejected, as they do not meet the business targets. </li> 
   <li class="readable-text" id="p27"> The business problem should be measurable if possible. If the business problem is only qualitative, then it will be of limited help. We won’t be able to understand the real effect of the machine learning model created. </li> 
   <li class="readable-text" id="p28"> Scope creep is one of the problems we face sometimes. Scope creep happens when at the start of the project, during project building, the scope is changed drastically, changing the requirements and time needs of the project without changing resources and deadlines accordingly. </li> 
  </ul> 
  <div class="readable-text" id="p29"> 
   <p>An effective business problem is defined correctly, completely, and in discussion with the business teams. It is concise with measurable KPIs and is achievable within a given timeframe. </p> 
  </div> 
  <div class="readable-text print-book-callout" id="p30"> 
   <p><span class="print-book-callout-head">NOTE </span> Business stakeholders and subject matter experts should be involved in defining the business problems. They should be a part of the team from the start and own the overall process.</p> 
  </div> 
  <div class="readable-text" id="p31"> 
   <p>A few examples of a good business problem are as follows:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p32"> The marketing team in an organization aims to optimize the various costs and maximize the return on investments. They want to identify the optimal combinations of marketing efforts (email, calls, TV advertising, and meetings) to increase the return on investment by 1.5% in the next six months. </li> 
   <li class="readable-text" id="p33"> A manufacturing team faces an increase in the number of defects in the last three months. The business problem can be to identify all the potential reasons for such an increase in defects. The team also wishes to know if there is a trend or pattern. The business goal may be to shortlist the most significant reasons for defects and reduce them by 2.5% in the next six months. </li> 
  </ul> 
  <div class="readable-text" id="p34"> 
   <p>We have described the attributes of a business problem. We now move to the next phase, which is data discovery and feasibility.</p> 
  </div> 
  <div class="readable-text" id="p35"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.3</span> Data discovery and feasibility analysis</h2> 
  </div> 
  <div class="readable-text" id="p36"> 
   <p>The data discovery phase is one of the most important steps in the entire model building process. If there is not enough data, both quantitatively and qualitatively, it might be very difficult to create the solution we desire. At the same time, having access to this data is of paramount importance.</p> 
  </div> 
  <div class="readable-text intended-text" id="p37"> 
   <p>During this process, we also do the feasibility analysis for the project:</p> 
  </div> 
  <ol> 
   <li class="readable-text buletless-item" id="p38"> The data is the protagonist. The very first step is the identification of the datasets required for the business problem use case and mechanisms for its access by all the stakeholders. For this reason, it is advisable that 
    <ul> 
     <li> The dataset is available from servers or clouds and relevant permissions are set correctly to the people who need access. The servers can access the data from a database such as SQL/MySQL/NoSQL/MongoDB. </li> 
     <li> If the data is in Excel/.csv/text files, it will be useful to make it available on the server. In recent times, cloud servers like AWS, Azure, Google Cloud, etc., are used for storing the data. </li> 
    </ul></li> 
   <li class="readable-text" id="p39"> It is imperative to check that the dataset is complete and relevant to the business problem. The dataset should be representative enough of the business problem at hand and capture all the variability in the business. The time and duration of the data is another important dimension we should bear in mind. For example, if we wish to analyze the business of a telecom operator or a retail company, we should have enough data (for at least the last year so that we capture seasonality as well) and variables around sales, transactions, discounts, products/services purchased, marketing behaviors, historical behaviors, offline/online purchases, etc. </li> 
   <li class="readable-text" id="p40"> It is prudent to plan the data refresh at this stage. After all, once the model is built, we will have to maintain it and refresh it. </li> 
  </ol> 
  <div class="readable-text" id="p41"> 
   <p>During this phase, the most common problems we can face are as follows:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p42"> We might find that there are certain missing values, outliers, etc., in the dataset. We will cover that in detail in the next section. </li> 
   <li class="readable-text buletless-item" id="p43"> We must also ensure that correct business rules are applied on the dataset. The steps to ensure it are 
    <ul> 
     <li> Get the relevant dataset for the business problem. </li> 
     <li> Make some basic analyses like total sales, number of customers, month-wise trends, discounts, etc. </li> 
     <li> Get these KPIs verified by the business stakeholders. If the numbers are wrong, the business rules are refined. </li> 
    </ul></li> 
  </ul> 
  <div class="readable-text" id="p44"> 
   <p>Only once the data is correct and the numbers are accurate can we move on to the feasibility analysis for the use case. For the feasibility analysis, we do the following:</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p45"> Check the data quality in detail. We cover the various aspects in the next section. </li> 
   <li class="readable-text" id="p46"> Analyze the data for any patterns, such as seasonality, etc. We also check if there are any correlations present among various variables to ensure which variables are related to each other. </li> 
   <li class="readable-text" id="p47"> Check for relationships between the business problem and the dataset. This is followed by an exploratory analysis to identify if there is any significant difference between various customer groups. </li> 
  </ol> 
  <div class="readable-text" id="p48"> 
   <p>After this step, we go to the data cleaning, preprocessing, and data preparation step. This is one of the most time-consuming steps we have to do. </p> 
  </div> 
  <div class="readable-text" id="p49"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.4</span> Data cleaning and prepreparation </h2> 
  </div> 
  <div class="readable-text" id="p50"> 
   <p>In the last step, we shortlisted the data for the business problem. Now we will go to the data cleaning and preprocessing phase of the modeling process. </p> 
  </div> 
  <div class="readable-text intended-text" id="p51"> 
   <p>Data in its original form might not be usable enough to be fed to the machine learning model. We have to create a few additional variables and treat some others. In the real business world, the dataset is generally “dirty.” There can be many problems that can be present in the data, which are as follows:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p52"> Duplicate values </li> 
   <li class="readable-text" id="p53"> Categorical variables (may cause some problem for certain algorithms) </li> 
   <li class="readable-text" id="p54"> Missing values, NULL, or not a number (NaN), etc. </li> 
   <li class="readable-text" id="p55"> Outliers </li> 
   <li class="readable-text" id="p56"> Other problems (as described in previous chapters) </li> 
  </ul> 
  <div class="readable-text" id="p57"> 
   <p>Let’s deal with each of these things in turn. The code for this chapter has been checked in at <a href="https://mng.bz/vKY7">https://mng.bz/vKY7</a>. You can access the code and datasets there. We will now work on how to deal with duplicate values in a dataset.</p> 
  </div> 
  <div class="readable-text" id="p58"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.5</span> Duplicate values in the data </h2> 
  </div> 
  <div class="readable-text" id="p59"> 
   <p>Duplicates are often a problem in datasets. If there are two rows in the dataset that are a complete copy of each other, they are duplicates in nature. This problem might occur during data-capturing time. The problem with duplicates is that the statistics will be affected—for example, by making some events appear to be more frequent than they are. When removing duplicates, one needs to pay attention to not removing genuine data of events that happened twice—for example, a customer purchasing an item twice at two different times or a customer purchasing two identical items at the same time versus the transaction of the purchase being recorded twice.</p> 
  </div> 
  <div class="readable-text intended-text" id="p60"> 
   <p>The following are the steps of a simple Python program to remove duplicates (see figure 11.2):</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p61"> Import <code>numpy</code> and <code>pandas</code>. </li> 
   <li class="readable-text" id="p62"> Define a dataframe with some dummy variables. </li> 
   <li class="readable-text" id="p63"> Print the dataframe. </li> 
   <li class="readable-text" id="p64"> There is an inbuilt method: <code>drop_duplicates()</code>. Use it to drop the duplicates. </li> 
   <li class="readable-text" id="p65"> Print the dataframe and find that the duplicate rows have been dropped. </li> 
  </ol> 
  <div class="browsable-container figure-container" id="p66">  
   <img alt="figure" src="../Images/CH11_F02_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 11.2</span> Removing duplicates in a simple Python program</h5>
  </div> 
  <div class="readable-text" id="p67"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.6</span> Categorical variables</h2> 
  </div> 
  <div class="readable-text" id="p68"> 
   <p>The next step is treating the categorical variable. Let’s revisit the definition of categorical variables. Variables like gender, city, product categories, zip codes, etc., are examples of categorical variables. Categorical variables may not strictly be a problem in the data, but they can create problems for certain algorithms like k-means clustering. Recall that for k-means clustering, the distance needs to be calculated between the data points. </p> 
  </div> 
  <div class="readable-text intended-text" id="p69"> 
   <p>In certain datasets, a categorical variable can have nearly all values as the same. For example, if the whole dataset is for the UK and a variable is “city,” since a significant percentage of the population lives in London, then this variable might be of limited benefit. It will not create any variation in the dataset and will not be useful. Similarly, a categorical variable like “zip code” can have all the values as distinct and will not add much to the analysis.</p> 
  </div> 
  <div class="readable-text intended-text" id="p70"> 
   <p>Perhaps the most common method to deal with categorical variables is using one-hot encoding. In one-hot encoding, as shown in the Python code book, the variable gets transformed: </p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p71"> Use the same dataset we used in the last code. </li> 
   <li class="readable-text" id="p72"> There is a built-in method in pandas, <code>get_dummies()</code>, which can be used for converting categorical variables to numeric ones. See figure 11.3. </li> 
  </ol> 
  <div class="browsable-container figure-container" id="p73">  
   <img alt="figure" src="../Images/CH11_F03_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 11.3</span> The output of the code when executed</h5>
  </div> 
  <div class="readable-text" id="p74"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.7</span> Missing values in dataset</h2> 
  </div> 
  <div class="readable-text" id="p75"> 
   <p>One of the most common challenges in real-world datasets is missing values, which might be blank, NULL, NaN, etc. It might be due to a data capturing problem or data transformation. Missing values should be treated to ensure a robust solution. There can be a few reasons for missing values:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p76"> The values were not recorded properly during data capturing. This can be due to faulty equipment or a manual error when recording the data. </li> 
   <li class="readable-text" id="p77"> Many times, nonmandatory fields are not entered. For example, a customer might not enter age while filling out a retail loyalty form. </li> 
   <li class="readable-text" id="p78"> Survey responses might not be completely filled out—for example, salary details. </li> 
  </ul> 
  <div class="readable-text" id="p79"> 
   <p>To mitigate the missing values, there are a few options:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p80"> First, we should check if the data is missing by design and whether it is a problem that needs to be addressed. For example, it is possible for a sensor to not record any temperature values above a certain pressure range. In that case, having missing values of temperature is correct. </li> 
   <li class="readable-text" id="p81"> We should also check if there are any patterns in the missing values with respect to the other independent variables and with respect to the target variable. For example, in the dataset used in the next example we can deduce that whenever the value of temperature is NULL, then the equipment has failed. In such a case, there is a clear pattern in this data between temperature and the failed equipment. Hence, it will be the wrong step to delete the temperature or treat the temperature variable. </li> 
   <li class="readable-text" id="p82"> Perhaps the easiest approach to deal with missing values is to delete the rows that have missing values. Though this is simple and fast, it reduces the size of the population and can delete very important pieces of information, as described earlier, or, for example, if a person has a legitimate last name that is not available. Hence, we should be careful deleting rows. </li> 
   <li class="readable-text" id="p83"> We can impute the missing values by the mean, median, or mode values. Mean or median are only possible for continuous variables. Mode can be used for both continuous and categorical variables. </li> 
   <li class="readable-text" id="p84"> There are also other popular methods for imputing the missing values like using k-nearest neighbor and multivariate imputation by chained equation. </li> 
  </ul> 
  <div class="readable-text" id="p85"> 
   <p>We now use Python to impute missing values. We will use the built-in method <code>SimpleImputer</code> and impute the missing values with the mean. The second solution is for the categorical variables, where the mode is used to replace the missing values. See figure 11.4.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p86">  
   <img alt="figure" src="../Images/CH11_F04_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 11.4</span> The output of the code when executed</h5>
  </div> 
  <div class="readable-text" id="p87"> 
   <p>In the next solutions, we will use <code>IterativeImputer</code> and the k-nearest neighbor algorithm.</p> 
  </div> 
  <div class="readable-text" id="p88"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.8</span> Outliers present in the data</h2> 
  </div> 
  <div class="readable-text" id="p89"> 
   <p>Outliers can be a big problem in the data. Consider this: let’s assume that average rainfall for a city is 50 cm. But one particular year, due to heavy rains, the average rainfall is 100 cm. This data point would be an outlier and will completely change the analysis results should it be included. In the example, depending on whether the year of heavy precipitation is included or not in the statistical analysis, the results (say, of likely insurance claims) would be very different.</p> 
  </div> 
  <div class="readable-text intended-text" id="p90"> 
   <p>Therefore, like missing values, outliers may not necessarily be an error. We should apply business acumen to infer if the data points are really outliers for the problem under study.</p> 
  </div> 
  <div class="readable-text intended-text" id="p91"> 
   <p>We can detect outliers in the following ways:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p92"> If a data point lies beyond the 5th percentile and 95th percentile or 1st percentile and 99th percentile, it can be considered an outlier. </li> 
   <li class="readable-text" id="p93"> A value that is beyond –1.5 × interquartile range (IQR) and +1.5 × IQR can also be considered an outlier. Here IQR is given by (value at 75th percentile) – (value at 25th percentile). </li> 
   <li class="readable-text" id="p94"> Values beyond one, two, or three standard deviations from the mean can be termed outliers. </li> 
  </ul> 
  <div class="readable-text" id="p95"> 
   <p>We can create charts and visualize outliers. We can treat outliers by using the following methods:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p96"> A data point beyond the 5th percentile and 95th percentile can be capped at the 5th percentile and 95th percentile, respectively. Or a data point beyond the 1st percentile and 99th percentile can be capped at the 1st percentile and 99th percentile, respectively. </li> 
   <li class="readable-text" id="p97"> Replacement by mean, median, or mode is also used sometimes. </li> 
   <li class="readable-text" id="p98"> Sometimes taking a natural log of the variable reduces the effect of outliers. But since a natural log will change the actual values, we should use sound mathematical models for the problem under investigation to make sure it’s appropriate. </li> 
  </ul> 
  <div class="readable-text" id="p99"> 
   <p>Outliers pose a big challenge to our datasets. They skew the insights we have generated from the data. Sometimes this skew is appropriate (e.g., the insurance claims of an outlier heavy precipitation year, which the insurance company needs to take into account). In any case, it becomes important that we at least highlight outliers in the dataset and sometimes modify them.</p> 
  </div> 
  <div class="readable-text" id="p100"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.9</span> Exploratory data analysis</h2> 
  </div> 
  <div class="readable-text" id="p101"> 
   <p>EDA is one of the most crucial steps before we start modeling. Using EDA, we generate insights that are quite useful for the business. The insights generated from the EDA conform to the modeling outputs too. </p> 
  </div> 
  <div class="readable-text intended-text" id="p102"> 
   <p>In EDA, we examine all the variables and understand their patterns, interdependencies, relationships, and trends. During the EDA phase, we come to know how the data is expected to behave. We uncover insights and recommendations from the data at this stage. A strong visualization complements the complete EDA. </p> 
  </div> 
  <div class="readable-text print-book-callout" id="p103"> 
   <p><span class="print-book-callout-head">NOTE </span> EDA is the key to success; many times, a good EDA can solve the business problem.</p> 
  </div> 
  <div class="readable-text" id="p104"> 
   <p>Next we perform a detailed EDA on a dataset using Python. The entire code is quite big for a book; hence, the Python notebook has been checked in to the GitHub repository (<a href="https://mng.bz/vKY7">https://mng.bz/vKY7</a>) with full explanations and comments.</p> 
  </div> 
  <div class="readable-text" id="p105"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.10</span> Model development and business approval</h2> 
  </div> 
  <div class="readable-text" id="p106"> 
   <p>We have already covered the modeling process in detail throughout the book. This includes creating the first version of the model and then iterating with different hyperparameters and with different algorithms. </p> 
  </div> 
  <div class="readable-text intended-text" id="p107"> 
   <p>Throughout the book, we have covered a lot of algorithms on clustering and dimensionality reduction methods. We also covered modeling for the text datasets. During the model development phase, based on the business problem and dataset at hand, we choose the candidate algorithms. We always strive to select the best algorithm based on the accuracy measurement parameters we have discussed in earlier chapters. </p> 
  </div> 
  <div class="readable-text intended-text" id="p108"> 
   <p>The output of the modeling process is the final algorithm that delivers the best output for the business problem at hand. After a model with satisfactory performance is found, we should have a discussion with the business stakeholders for their final feedback. There might be a few iterations required to further improve the model. </p> 
  </div> 
  <div class="readable-text intended-text" id="p109"> 
   <p>Now, you have a model that is statistically significant, useful, and approved by the business stakeholders. We can move on to the model deployment stage. </p> 
  </div> 
  <div class="readable-text" id="p110"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.11</span> Model deployment</h2> 
  </div> 
  <div class="readable-text" id="p111"> 
   <p>A critical stage in the development of AI and machine learning models is model deployment. It is the changeover point between the development and production environments, where the model is used for real-world business purposes. There are many facets to be considered, like infrastructure concerns, deployment methodologies, monitoring, and maintenance. We discuss the challenges and recommended steps related to model deployment, with a methodical and organized strategy to put the models into production.</p> 
  </div> 
  <div class="readable-text" id="p112"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.12</span> Purpose of model deployment</h2> 
  </div> 
  <div class="readable-text" id="p113"> 
   <p>Model deployment is a crucial process. The primary reasons for model deployment are given as follows:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p114"> Deployment of a model leads to the transformation of insights into actionable and practical purposes. The model is used for making predictions, optimizations, recommendations, and suggestions. </li> 
   <li class="readable-text" id="p115"> The deployed models are integrated with the business processes and workflows. This facilitates the automation of various processes and business functions based on the insights and recommendations made by the model. </li> 
   <li class="readable-text" id="p116"> Real-time predictions ensure that the business is responding quickly to the ever-changing business conditions. Real-time predictions are particularly useful for scenarios like credit card fraud detection in transactions, dynamic pricing, etc. </li> 
   <li class="readable-text" id="p117"> Optimization and automation are enhanced. Model deployment leads to a decrease in the efforts of the employees by automating the business functions. With the help of deployed models, hardware use is optimized, business functions and processes are made more efficient, and the overall return on investment is increased. </li> 
   <li class="readable-text" id="p118"> With deployed models, the versioning of the models can be done. This ensures that the organization can track changes, perform A/B tests, and even perform rollback if required. </li> 
  </ul> 
  <div class="readable-text" id="p119"> 
   <p>In summary, the purpose of model deployment is to translate the potential of machine learning models into practical applications, making them an integral part of business operations and decision-making processes. Deployment enables organizations to harness the power of AI and data science to derive value from their models in real-world scenarios.</p> 
  </div> 
  <div class="readable-text" id="p120"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.13</span> Types of model deployment</h2> 
  </div> 
  <div class="readable-text" id="p121"> 
   <p>There are several types of model deployments. Based on the requirements and the strategic objectives, we can choose between them. The various types of deployment strategies are</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p122"> <em>Batch deployment</em><em> </em>—This methodology is used when we have a large dataset that has been collected over a period of time and we need to use the machine learning model to assess this data and make predictions in an offline mode. Generally, the processing is done in large batches. For example, if we want to cluster the customers of a retail store based on k-means clustering, we can take their attributes for the last two years and generate a corresponding cluster for each customer. We can refresh the underlying data after one month, and hence we can reassign these clusters.  </li> 
   <li class="readable-text" id="p123"> <em>Real-time deployment</em><em> </em>—Consider this: we want to check if the incoming credit card transaction is genuine or fraudulent. In such a scenario, we use a real-time check. The predictions are generated in real time based on the latest information available. Generally, to support real-time predictions, we should employ a multithreaded process so that multiple prediction requests can be handled at the same time. For example, there can be hundreds of credit card requests made simultaneously, which our system needs to classify with very little latency. </li> 
   <li class="readable-text" id="p124"> <em>Edge deployment</em><em> </em>—Nowadays, people expect smartphones or Internet of Things devices to have sophisticated features that are a good fit for a machine learning or AI algorithm. In such a scenario, a deployment in the cloud is possible, but edge deployment is also used when an internet connection is not available. The prerequisite for edge deployment is that the machine learning model should be small in size and require less computation to facilitate running it on the devices with limited resources.  </li> 
   <li class="readable-text" id="p125"> <em>Canary deployment</em><em> </em>—In canary deployment, we release the model to a subset of users before we make a full-scale deployment for all users. This ensures that an unstable version is not released to all users as we will get the feedback from the test users in the first phase. This is typically done by large companies with a huge number of users providing services through the cloud, such as Google or Facebook. </li> 
   <li class="readable-text" id="p126"> <em>A/B testing</em><em> </em>—A/B testing is not actually a model deployment technique, but it can be used as one and that is why it is listed here. In A/B testing, organizations want to test how one solution/service/product compares with another. For example, if the product team wishes to test which of the two offers delivers better profitability, they will use A/B testing. The example of two offers can be “spend $100 and get a 15% discount” or “spend $50 and get a 10% discount.” In such a scenario, there can be two similar groups of customers that will receive these offers, and we will check which one delivers better profitability. In A/B testing deployments, two different models (or the same model with different hyperparameters) are tested against each other. </li> 
  </ul> 
  <div class="readable-text" id="p127"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.14</span> Considerations while deploying the model</h2> 
  </div> 
  <div class="readable-text" id="p128"> 
   <p>There are quite a few factors we should keep in mind while deploying the model to ensure smooth and effective transition from development of the model to deployment:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p129"> <em>Accuracy monitoring</em><em> </em>—We should constantly monitor the performance of the model and improve it if the performance falls below a threshold. We should cover key metrics like accuracy, resource utilizations, time, and accuracy. </li> 
   <li class="readable-text" id="p130"> <em>Scalability</em><em> </em>—A solution should be scalable to other departments or brands. Even the volume of the data can increase with time. </li> 
   <li class="readable-text" id="p131"> <em>Security and compliance</em><em> </em>—This is one consideration that cannot be compromised at all. Any kind of deployment should be completely secure from any threats and fully compliant with the existing best practices, policies, and requirements.  </li> 
   <li class="readable-text" id="p132"> <em>Model drift and data drift</em><em> </em>—These should be monitored because the overall business scenario can change. Customers, their preferences, the market, and the overall economy may change. There are events like COVID, war, floods, etc., and hence there is a data drift. It results in a model’s performance change too. Hence, we should plan for model drift in advance. </li> 
   <li class="readable-text" id="p133"> <em>Reproducibility</em><em> </em>—Reproducibility of the results is an important factor when we deploy the models. We should be able to replicate the results.  </li> 
   <li class="readable-text" id="p134"> <em>Continuous integration and continuous deployment</em><em> </em>—These pipelines are required to automate the testing and the deployment process. This reduces the risk of errors and ensures smooth deployments.  </li> 
   <li class="readable-text" id="p135"> <em>User feedback and successive iterations</em><em> </em>—These are very important for a successful project. While planning for the deployment, we should give due diligence to incorporating users’ feedback and the iterations in the model. </li> 
   <li class="readable-text" id="p136"> <em>Versioning and rollback</em><em> </em>—No model is ever final. There are successive iterations to it. In the infrastructure, there should be a provision to roll back to the previous version if the new version has any problems or if there are reasons based on the business requirements.  </li> 
  </ul> 
  <div class="readable-text" id="p137"> 
   <p>With this, we have covered all the considerations in model deployment. We will now deploy a model using Flask. The entire code has been uploaded to the GitHub repository (<a href="https://mng.bz/vKY7">https://mng.bz/vKY7</a>) with full comments and explanations.</p> 
  </div> 
  <div class="readable-text" id="p138"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.15</span> Documentation</h2> 
  </div> 
  <div class="readable-text" id="p139"> 
   <p>Our model is deployed. Now we ensure that all the code snippets are cleaned, are properly commented, and adhere to best practices. The code files should be checked in and properly documented. Documentation is often (unfortunately) not given enough time, but it is a very important step that should not be ignored. Should priorities be set in writing in the documentation, precedence should be given to the aspects more likely to change and to those that require understanding and interaction with external stakeholders.</p> 
  </div> 
  <div class="readable-text intended-text" id="p140"> 
   <p>There are quite a few tools for version controlling of the code. Git is perhaps the most common one. It is a very good practice to ensure that all of our code is checked in regularly to safeguard ourselves from any potential computer failures. For documentation, we do have a lot of options available in the industry, ranging from Word to PowerPoint to Confluence pages, depending on the industry we work in. </p> 
  </div> 
  <div class="readable-text" id="p141"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.16</span> Model maintenance and refresh</h2> 
  </div> 
  <div class="readable-text" id="p142"> 
   <p>So far, we have covered all the stages of model development and deployment. But once a model is put into production, it needs constant monitoring. We must ensure that the model is always performing at the desired level of accuracy. To achieve this, it is advised to have a dashboard or a monitoring system to gauge the performance of the model regularly. In case of nonavailability of such a system, a monthly or quarterly check-up of the model can be done. </p> 
  </div> 
  <div class="readable-text intended-text" id="p143"> 
   <p>Once the model is deployed, we can do a monthly health check of the model. It means that we compare the performance of the model with the expected accuracy. If the performance is not good, the model requires a refresh. Even though the model might not be deteriorating, it is still a good practice to refresh the model on new data points that are constantly created and saved. The model refresh is generally based on the business problem as well as the business domain for which the model has been built. For example, in the telecom domain, data updates are faster as customers use their mobile phones daily. On the other hand, for retail apparel, we don’t expect customers to buy clothes every day. Hence, the model for the telecom domain can be refreshed weekly or biweekly, while for apparel, we can refresh once a quarter or once every six months.</p> 
  </div> 
  <div class="readable-text intended-text" id="p144"> 
   <p>Model refresh is quite an important phenomenon. Our business scenarios are always dynamic in nature. The customers’ preferences and lifestyles will change, and there’s always some activity being done by the competitor. There are certain scenarios that are beyond our control, like war, COVID, etc. Hence, we always should strive to adjust our models to the latest scenario in our business.</p> 
  </div> 
  <div class="readable-text intended-text" id="p145"> 
   <p>Model refresh means that we are retraining the model based on the new data points we have collected. It ensures that we are capturing the latest trends, backgrounds, and emerging relationships in the data, and hence our models are able to predict, optimize, and expedite the latest data points.</p> 
  </div> 
  <div class="readable-text intended-text" id="p146"> 
   <p>With this we have completed all the steps to design a machine learning system: how to develop it from scratch, how to deploy it, and how to maintain it. It is a long process that is quite tedious and requires teamwork.</p> 
  </div> 
  <div class="readable-text" id="p147"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.17</span> Concluding thoughts</h2> 
  </div> 
  <div class="readable-text" id="p148"> 
   <p>End-to-end machine learning development is quite a time-consuming one. From scratch to maintenance, it requires a lot of planning, teamwork, business knowledge, and effort. In this chapter, we have covered a lot of those steps. There can be other possible solutions too, which are dependent on the business domain and the requirements.</p> 
  </div> 
  <div class="readable-text intended-text" id="p149"> 
   <p>With this we come to the close of this book. We all read and feel that in this new age, data is the new oil, new electricity, new power, and new currency. The field is rapidly growing and making its effect felt across the globe. The pace of enhancements and improvements has opened new job opportunities like data engineers, data scientists, visualization experts, machine learning engineers, MLOps, DevOps, GenAI experts, and so on, with demand increasing day by day. But there is a dearth of professionals who fulfill the rigorous criteria for these job descriptions. The need of the hour is to have <em>data artists</em> who can marry business objectives with analytical problems, envision solutions to solve the dynamic business problems, adjust to the ever-changing technical landscape, and yet deliver cost-effective business solutions. </p> 
  </div> 
  <div class="readable-text intended-text" id="p150"> 
   <p>More sophisticated systems are being created every day. We can see examples of self-driving cars, human chatbots, fraud detection systems, facial recognition solutions, object-detection solutions, optimization and monitoring solutions, etc. The use of GenAI has further enhanced the effect. </p> 
  </div> 
  <div class="readable-text intended-text" id="p151"> 
   <p>At the same time, there are some risks too, which we should be aware of. The onus lies on humankind regarding how to harness this power of data. There are instances where (if we believe the claims made) AI has been used for rigging election results or DeepFake has been used for morphing pictures of people or profiling people based on race/color etc. We can use machine learning and AI to spread love or hatred–it is our choice. And like the cliché goes: with great power comes great responsibility!</p> 
  </div> 
  <div class="readable-text intended-text" id="p152"> 
   <p>We sincerely hope you enjoyed the book. Congratulations, and all the very best for your next steps!</p> 
  </div> 
  <div class="readable-text" id="p153"> 
   <h2 class=" readable-text-h2"><span class="num-string">11.18</span> Practical next steps and suggested readings</h2> 
  </div> 
  <div class="readable-text" id="p154"> 
   <p>The following provides suggestions for what to do next and offers some helpful reading:</p> 
  </div> 
  <ul> 
   <li class="readable-text buletless-item" id="p155"> Go through these two research papers on model deployment: 
    <ul> 
     <li> Paleyes, A., Urma, R-G., and Lawrence, N. D. (2020). Challenges in Deploying Machine Learning: a Survey of Case Studies. <a href="https://arxiv.org/abs/2011.09926v2">https://arxiv.org/abs/2011.09926v2</a> </li> 
     <li> Sculley, D., Holt, G., Golovin, D., et al. (2015). Hidden Technical Debt in Machine Learning Systems. <a href="https://mng.bz/4azw">https://mng.bz/4azw</a> </li> 
    </ul></li> 
   <li class="readable-text" id="p156"> Use the datasets we have developed in the last few chapters and perform EDA on those datasets. </li> 
  </ul> 
  <div class="readable-text" id="p157"> 
   <h2 class=" readable-text-h2">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p158"> The journey of learning is ongoing, requiring courage, patience, and diligence; understanding the entire process from conceptualization to model deployment is essential for mastering machine learning. </li> 
   <li class="readable-text" id="p159"> The end-to-end model deployment process involves key steps such as business problem definition, data cleaning, and EDA and culminating in model deployment and maintenance. </li> 
   <li class="readable-text" id="p160"> The machine learning modeling process includes distinct stages such as business problem definition, data discovery and feasibility analysis, data prepreparation, EDA, modeling, deployment, documentation, and maintenance. </li> 
   <li class="readable-text" id="p161"> Clear and achievable business problem definition is crucial to align goals effectively, prevent scope creep, and ensure that KPIs are measurable to assess the model’s effect. </li> 
   <li class="readable-text" id="p162"> Data discovery involves identifying necessary datasets, ensuring access and completeness, and analyzing feasibility, with particular attention to data relevance, quality, and representation. </li> 
   <li class="readable-text" id="p163"> Data cleaning and prepreparation address common problems like duplicates, categorical variables, missing data, and outliers, utilizing various techniques to prepare the dataset for effective modeling. </li> 
   <li class="readable-text" id="p164"> EDA is key to understanding data patterns and relationships and generating actionable insights, laying the groundwork for successful model development. </li> 
   <li class="readable-text" id="p165"> The model development phase uses algorithms suitable for the business problem and requires stakeholder collaboration for refinement. </li> 
   <li class="readable-text" id="p166"> Model deployment bridges development and production, necessitating considerations for infrastructure, real-time applications, scaling, security, and continuous integration to optimize model utility. </li> 
   <li class="readable-text" id="p167"> Types of model deployment include batch, real-time, edge, canary, and A/B testing, each offering different advantages based on strategic objectives and application contexts. </li> 
   <li class="readable-text" id="p168"> Effective deployment involves accuracy monitoring, detecting model and data drift, securing compliance and data, and ensuring reproducibility and scalability. </li> 
   <li class="readable-text" id="p169"> Postdeployment, thorough documentation and version control are vital for code integrity and facilitating future iterations or rollbacks when necessary. </li> 
   <li class="readable-text" id="p170"> Model maintenance involves regular performance checks and refreshes, adapting to dynamic business environments and ensuring alignment with evolving data trends. </li> 
   <li class="readable-text" id="p171"> Data-driven solutions have vast potential but also an equally high duty of responsible use. We wrap up this book by stressing the importance of ethical application. </li> 
  </ul>
 </body></html>