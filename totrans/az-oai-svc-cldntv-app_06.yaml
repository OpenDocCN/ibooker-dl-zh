- en: Chapter 5\. Operationalizing Generative AI Implementations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, we have explored the evolution of generative AI and Azure OpenAI
    Service, the main approaches for cloud native generative AI app development, and
    AI architectures and building blocks for LLM-enabled applications with Azure.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore the main considerations for going from implementation
    to production-level deployments. For this purpose, we will talk about advanced
    prompt engineering topics, related operations, security, and responsible AI considerations.
    All of these will contribute to a proper enterprise-grade implementation of cloud
    native, generative AI–enabled applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: The Art of Prompt Engineering
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Prompt engineering* is one of those disciplines that has taken existing AI
    skills frameworks by surprise. Before OpenAI’s ChatGPT, no one could imagine that
    the ability to interact with AI models by using just natural written language
    would be one of the most precious skills for companies trying to adopt, test,
    and deploy their generative AI systems. If there is an equivalent of the famous
    [“Data Scientist: The Sexiest Job of the 21st Century”](https://oreil.ly/0ZFLS),
    it is prompt engineering, with powerful examples such as the [prompt engineer
    job at Anthropic in the US](https://oreil.ly/kNLkR), with a base salary of $300K+.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: It is also a highly evolving area. What started as a simple way to send instructions
    to models is becoming a sort of “art” that allows you to also contextualize, secure,
    and operationalize LLMs. It has a mix of technical and creative skills. Some people
    see similarities between prompt engineer and QA (quality assurance) skills, as
    they both include empathy, creativity, technical testing, planning, etc. The lingo
    is also new. Similar to the call-response dynamics of traditional APIs, here we
    talk about prompt (request) and completion (answer from the model).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: '[Microsoft describes](https://oreil.ly/T7PuQ) prompt engineering as a key element
    to obtaining the best performance from GPT-enabled models, as models are very
    sensitive to the quality or shape of the prompts. Here is the [official guidance
    for prompting techniques with Azure OpenAI Service](https://oreil.ly/jJkyA), both
    for [chat](https://oreil.ly/8SMeX) or [completion](https://oreil.ly/1VuzR) scenarios.
    [Table 5-1](#table-5-1) shows the recommended techniques in general terms.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-1\. Recommended prompting techniques
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '| Recommendation | Example |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
- en: '| *Leverage both system messages* (at the beginning of the prompt to set context,
    instructions, etc.) *and few-shot learning* (for examples of the desired input
    and output) as a way to improve performance. | *Meta-prompt or system message:*“You
    are an AI assistant for finance topics for company X, if anyone asks about something
    else, please say you cannot answer.”*Few-shot examples:*“If anyone asks about
    the price of product A, redirect to this URL.”“If you get a question about company
    services, enumerate A, B, C, and D. Then ask the client to choose.” |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 利用系统消息（在提示的开头设置上下文、指令等）和**少量样本学习**（提供期望的输入和输出的示例）作为提高性能的方法。 | **元提示或系统消息**：“你是公司X的金融主题AI助手，如果有人询问其他内容，请说您无法回答。”**少量样本示例**：“如果有人询问产品A的价格，请将其重定向到这个URL。”“如果有人询问公司服务，列出A、B、C和D。然后请客户选择。”
    |'
- en: '| *Use clear instructions*, define the expected format, and leverage both positive
    and negative examples. | “Provide answers in two paragraphs, max 1,000 tokens.”“Avoid
    talking about specific stock prices as they may be outdated. Instead, focus on
    enumerating trusted sources where clients can find those prices.” |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| **使用清晰的指令**，定义期望的格式，并利用正例和反例。 | “以两段回答，最多1,000个标记。”“避免谈论具体的股票价格，因为它们可能已经过时。相反，关注列出客户可以找到这些价格的可信来源。”
    |'
- en: '| *Adapt the prompts* to multiple scenarios or subtasks, depending on the context
    or user input, and *use variables* as a technique to represent dynamic or unknown
    values in the input or output (for example, $name for username or $date for current
    date). | *Passing the parameters as variables for the string:*“Provide recommendations
    to a user who is $age years old, from $location, adapting the language to their
    local context. Use their name $name when providing an answer.” |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 根据上下文或用户输入，**调整提示**以适应多个场景或子任务，并**使用变量**作为表示输入或输出中动态或未知值的技术（例如，$name代表用户名或$date代表当前日期）。
    | **将参数作为变量传递给字符串**：“为$age岁的用户提供推荐，来自$location，根据他们的本地上下文调整语言。在提供答案时使用他们的名字$name。”
    |'
- en: '| *Apply conditional logic*, as a way of using if-then statements or other
    logical operators to control the flow and content of the output, such as changing
    the tone, format, or information based on certain conditions or criteria. | “If
    the sentiment from the user prompts is mostly negative, use a kind, explicative,
    step-by-step approach.”“If the user prompts have a friendly tone, go directly
    to the point. One paragraph max” |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| **应用条件逻辑**，作为使用if-then语句或其他逻辑运算符来控制输出流程和内容的方法，例如根据某些条件或标准更改语气、格式或信息。 | “如果用户提示中的情感主要是负面的，使用友好、解释性、逐步的方法。”“如果用户提示的语气友好，直接切入要点。最多一段。”
    |'
- en: '| *Use feedback loops* by adding the model’s output as part of the input for
    the next iteration, such as appending the output to the prompt or using it to
    generate new questions or instructions. | *Meta-prompt or system message:*“Answer
    user questions for company X, and keep in mind…<output from previous discussion>
    while answering. Explain the why of your reasoning.” |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 通过将模型的输出作为下一次迭代的输入的一部分来使用**反馈循环**，例如将输出附加到提示中或用它来生成新问题或指令。 | **元提示或系统消息**：“回答公司X的用户问题，并在回答时记住…<前一次讨论的输出>。解释你推理的原因。”
    |'
- en: '[OpenAI defines](https://oreil.ly/gtxFR) their own set of best practices as
    well to optimize prompting and get the best model performance:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[OpenAI定义](https://oreil.ly/gtxFR)了自己的最佳实践集，以优化提示并获取最佳模型性能：'
- en: Always leverage the most recent model.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 总是利用最新的模型。
- en: This allows you to take advantage of the latest advancements and updates. Ensure
    you are working with the most recent iteration of the model. This does not mean
    to use the most powerful model, but the most recent version of each model. You
    can always obtain the most recent version from the [official Azure OpenAI model
    page](https://oreil.ly/BI5Ue).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这使您能够利用最新的进步和更新。确保您正在使用模型的最新迭代版本。这并不意味着使用最强大的模型，而是每个模型的最新版本。您可以从[官方Azure OpenAI模型页面](https://oreil.ly/BI5Ue)获取最新版本。
- en: Incorporate instructions at the outset.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在一开始就融入指令。
- en: 'Position your instructions at the start of your prompt. Use markers like ###
    or “"” to distinctly separate these instructions from the context.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 将您的指令放在提示的开头。使用###或“"”等标记来明确地将这些指令与上下文区分开来。
- en: Aim for specificity and detail.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 寻求具体性和细节。
- en: Avoid vagueness when defining the desired context, outcome, length, format,
    and style.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义期望的上下文、结果、长度、格式和风格时，避免含糊不清。
- en: Provide a clear output format via examples.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通过示例提供清晰的输出格式。
- en: Examples can help guide the model toward your preferred output. For instance,
    Example 1, Example 2, etc.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 示例可以帮助引导模型走向你期望的输出。例如，示例1、示例2等。
- en: Follow a progression by starting with a zero-shot approach.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 从零样本方法开始，遵循一个渐进的过程。
- en: This implies testing the model for specific questions without providing any
    illustrative examples. Then, proceed to few-shot scenarios, in which you provide
    one or several examples to the model, as LLMs can learn from their content and
    shape. If neither of these strategies yields the desired results, consider fine-tuning
    or grounding the model.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在没有任何说明性示例的情况下测试模型以回答特定问题。然后，进入少量示例场景，在这种情况下，你向模型提供一到几个示例，因为大型语言模型可以从其内容中学习和塑造。如果这些策略中没有一个产生期望的结果，考虑微调或使模型接地。
- en: Eliminate fluffy descriptions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 消除浮夸的描述。
- en: Favor precision and brevity over vague, overcomplicated language to streamline
    your prompt and improve the model’s understanding.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 优先考虑精确性和简洁性，而不是模糊或过于复杂的语言，以简化你的提示并提高模型的理解能力。
- en: Specify what to do.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 明确说明要做什么。
- en: Rather than merely pointing out what should be avoided, clearly articulate the
    desired action. This positively guides the model to perform as intended.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是仅仅指出应该避免什么，明确阐述期望的行为。这积极地引导模型按预期执行。
- en: Nudge the model with leading words in code generation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码生成中使用引导词来推动模型。
- en: When your task is related to code generation, “leading words” can be instrumental
    in guiding the model toward a specific pattern.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的任务与代码生成相关时，“引导词”可以在引导模型走向特定模式方面发挥重要作用。
- en: 'All of these recommendations and [further recommendations](https://oreil.ly/Xfw5-)
    are oriented to reduce *generative AI model hallucination*, which is the ability
    (or limitation) of LLMs to create nonfactual information based on their creative
    ability. This is a recurring topic for all generative AI technologies, and most
    advanced architectures are created so that LLMs don’t deliver imaginary or incorrect
    results. Besides Microsoft’s and OpenAI’s best practices, this four-step framework
    can help with this problem by leveraging the best prompt engineering practices:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些建议和[更多建议](https://oreil.ly/Xfw5-)都是针对减少*生成式AI模型幻觉*，这是LLMs基于其创造性能力创建非事实信息的能力（或限制）。这是所有生成式AI技术的常见话题，大多数高级架构都是创建的，以便LLMs不提供虚构或错误的结果。除了微软和OpenAI的最佳实践之外，这个四步框架可以通过利用最佳的提示工程实践来帮助解决这个问题：
- en: 1\. Include.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 包含。
- en: This strategy suggests including specific instructions in the prompt, such as
    requesting that the model not make stuff up and stick to facts. By providing clear
    guidelines, the AI model is more likely to generate accurate and factual content.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这种策略建议在提示中包含具体指令，例如要求模型不要编造内容并坚持事实。通过提供明确的指南，AI模型更有可能生成准确和事实性的内容。
- en: 2\. Restrict.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 限制。
- en: This approach involves limiting the output of the AI model. For example, you
    can choose from a confined list of options instead of allowing the model to generate
    free-form strings. By restricting the output, you can ensure that the generated
    text stays within the desired boundaries and is less likely to be based on hallucination.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法涉及限制AI模型的输出。例如，你可以从受限的选项列表中选择，而不是允许模型生成自由形式的字符串。通过限制输出，你可以确保生成的文本保持在期望的范围内，并且不太可能基于幻觉。
- en: 3\. Add chain of thought (CoT).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 添加思维链（CoT）。
- en: This strategy recommends incorporating a “chain of thought” style of instruction,
    such as “Solve the problem step by step.” By guiding the AI model to follow a
    logical and structured thought process, it is more likely to produce coherent
    and accurate text.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这种策略建议采用“思维链”风格的指令，例如“逐步解决问题。”通过引导AI模型遵循逻辑和结构化的思维过程，它更有可能产生连贯和准确的文章。
- en: 4\. Repeat and position.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 重复并定位。
- en: This technique involves repeating the most important instructions in the prompt
    a couple of times and positioning them at the end of the prompt. This makes use
    of the latency effect, which means that the AI model is more likely to remember
    and follow the instructions that are presented last.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术涉及在提示中重复最重要的指令几次，并将它们放在提示的末尾。这是利用延迟效应，这意味着AI模型更有可能记住并遵循最后呈现的指令。
- en: By implementing these strategies in prompt engineering, you can improve the
    quality of AI-generated text and reduce the chances of hallucination, leading
    to more accurate and reliable content. This is fundamental for the operationalization
    of generative AI in the enterprise.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在提示工程中实施这些策略，您可以提高AI生成文本的质量，并减少幻觉的可能性，从而产生更准确和可靠的内容。这对于在企业中实施生成式AI至关重要。
- en: 'As prompt engineering is a highly evolving area, I recommend you expand your
    knowledge with other fabulous external resources from community pros:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于提示工程是一个高度发展的领域，我建议您通过社区专业人士的其他精彩外部资源来扩展您的知识：
- en: '[PromptsLab’s Awesome-Prompt-Engineering repo](https://oreil.ly/ZmTev)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[PromptsLab的出色提示工程仓库](https://oreil.ly/ZmTev)'
- en: This repository contains hand-curated resources for prompt engineering with
    a focus on generative pre-trained transformers (GPT), ChatGPT, PaLM, etc. It includes
    papers, tutorials, blogs, videos, courses, and tools related to prompt engineering.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 本仓库包含针对提示工程的手选资源，重点关注生成式预训练转换器（GPT）、ChatGPT、PaLM等。它包括与提示工程相关的论文、教程、博客、视频、课程和工具。
- en: '[Lilian Weng’s blog](https://oreil.ly/lIbm7)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[Lilian Weng的博客](https://oreil.ly/lIbm7)'
- en: Lilian is Head of Safety Systems at OpenAI. Her blog introduces the concept
    of prompt engineering, the challenges and opportunities it poses, and some examples
    of how to design effective prompts for different tasks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Lilian是OpenAI的安全系统负责人。她的博客介绍了提示工程的概念，它带来的挑战和机遇，以及如何为不同任务设计有效提示的一些示例。
- en: '[Chip Huyen’s blog](https://oreil.ly/yQ7rt)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[Chip Huyen的博客](https://oreil.ly/yQ7rt)'
- en: Chip is a well-known industry expert, cofounder of Claypot AI, and the author
    of [*Designing Machine Learning Systems* (O’Reilly)](https://oreil.ly/7UWAL).
    She shares some best practices and tips for building LLM applications for production,
    such as how to choose the right model, how to optimize the inference speed, and
    how to monitor the quality and reliability of the outputs.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Chip是一位知名的行业专家，Claypot AI的联合创始人，也是[*设计机器学习系统*（O’Reilly）](https://oreil.ly/7UWAL)一书的作者。她分享了一些构建LLM应用程序的最佳实践和技巧，例如如何选择合适的模型、如何优化推理速度以及如何监控输出质量和可靠性。
- en: '[Xavier Amatriain’s blog](https://oreil.ly/3jvie)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[Xavier Amatriain的博客](https://oreil.ly/3jvie)'
- en: Xavier shares his incredible wealth of knowledge with [101 (introduction and
    resources)](https://oreil.ly/ZT8WB) and [201 (advanced methods and toolkits)](https://oreil.ly/n_unu)
    articles, as well as [online intro level prompt engineering training](https://oreil.ly/jIbNt).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Xavier通过[101（介绍和资源）](https://oreil.ly/ZT8WB)和[201（高级方法和工具包）](https://oreil.ly/n_unu)文章，以及[在线入门级提示工程培训](https://oreil.ly/jIbNt)分享了他丰富的知识。
- en: DAIR.AI’s [Prompt Engineering Guide](https://oreil.ly/JBB67) and its [related
    GitHub repository](https://oreil.ly/QzS_D)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: DAIR.AI的[提示工程指南](https://oreil.ly/JBB67)及其[相关GitHub仓库](https://oreil.ly/QzS_D)
- en: Guides, papers, lectures, notebooks, and resources for prompt engineering, including
    a series of [examples for advanced prompt engineering scenarios](https://oreil.ly/0sWII).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程的指南、论文、讲座、笔记本和资源，包括一系列[高级提示工程场景的示例](https://oreil.ly/0sWII)。
- en: Prompt engineering is just one step in operationalizing our generative AI implementations.
    We will now explore other operations related to Azure OpenAI and LLMs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程只是将我们的生成式AI实施投入运营的一个步骤。我们现在将探讨与Azure OpenAI和LLMs相关的其他操作。
- en: Generative AI and LLMOps
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI和LLMOps
- en: If we take all the architectural, model, and prompting considerations, and we
    explore the envisioned workflow for an end-to-end LLM implementation, we come
    to the notion of *LLMOps*, a new term used to define all LLM-related operations
    in the enterprise. LLMOps is similar to [MLOps (machine learning operations)](https://oreil.ly/VLSZA),
    which is a set of tools and best practices to manage the lifecycle of ML-powered
    applications.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们考虑所有架构、模型和提示因素，并探索端到端LLM实施的预期工作流程，我们就会得出*LLMOps*的概念，这是一个新术语，用于定义企业中所有与LLM相关的操作。LLMOps类似于[MLOps（机器学习操作）](https://oreil.ly/VLSZA)，它是一套工具和最佳实践，用于管理由机器学习驱动的应用程序的生命周期。
- en: '[LLMOps](https://oreil.ly/dgVl1) is a discipline that combines several techniques
    for the development, deployment, and maintenance of LLM and generative AI applications.
    This includes prompt engineering, but also deployment and observability topics.
    The operations related to AI topics are not new, but have evolved exponentially
    in recent years, as you can see in [Figure 5-1](#fig_1_evolution_of_llmops).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[LLMOps](https://oreil.ly/dgVl1) 是一个结合了多种技术以开发、部署和维护LLM和生成式AI应用的学科。这包括提示工程，但也包括部署和可观察性话题。与AI相关的一些操作并非新事物，但近年来呈指数级发展，正如您可以在[图5-1](#fig_1_evolution_of_llmops)中看到的那样。'
- en: '![](assets/aoas_0501.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0501.png)'
- en: Figure 5-1\. Evolution of LLMOps
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1. LLMOps的演变
- en: 'This was an evolution in terms of operations complexity, but also the scalability
    of the methods, and the availability of commercial platforms to make them simpler:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这在操作复杂度方面是一个进化，同时也涉及方法的可扩展性和商业平台使其简化的可用性：
- en: Up to 2015
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 2015年之前
- en: This period represents the time before the development of modern MLOps practices.
    During this period, proprietary tools were used for modeling and inference, but
    there was also a rise of open source data science tools such as Python and R.
    These tools allowed for more flexibility and accessibility in data science and
    machine learning.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这一时期代表了现代MLOps实践发展之前的时期。在这一时期，用于建模和推理的专有工具，但同时也出现了开源数据科学工具，如Python和R的兴起。这些工具使得数据科学和机器学习在灵活性和可访问性方面有了更大的提升。
- en: 2015+
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 2015+
- en: The inclusion of cloud native and containerization made it a bit easier to put
    models into production, and to scale in a robust and more efficient manner. This
    period witnessed the growth of MLOps platforms, which use dockerized ML stacks
    and deploy them both on premises or in the cloud via Kubernetes, including manageability
    and monitoring features.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生和容器化的引入使得将模型投入生产以及以更稳健和更高效的方式扩展变得容易一些。这一时期见证了MLOps平台的发展，这些平台使用docker化的ML堆栈，并通过Kubernetes在本地或云中部署，包括可管理性和监控功能。
- en: 2023+
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 2023+
- en: The beginning of the LLMOps solutions market. A promising area, but still a
    very new one (we will explore one of the first LLMOps tools in this chapter),
    focused on specific functionalities that were not part of the traditional MLOps
    tools. That said, existing MLOps and new LLMOps approaches share some similarities,
    as you can see in [Figure 5-2](#fig_2_comparison_of_mlops_llmops_and_ai_provider_adopter).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: LLMOps解决方案市场的开始。一个有希望但仍然非常新的领域（我们将在本章中探讨第一个LLMOps工具），专注于传统MLOps工具之外的特定功能。尽管如此，现有的MLOps和新的LLMOps方法在某种程度上是相似的，正如您可以在[图5-2](#fig_2_comparison_of_mlops_llmops_and_ai_provider_adopter)中看到的那样。
- en: '![](assets/aoas_0502.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0502.png)'
- en: Figure 5-2\. Comparison of MLOps/LLMOps and AI provider/adopter scope of activity
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-2. MLOps/LLMOps和AI提供者/使用者活动范围的比较
- en: Summarizing, LLMOps bring a completely different split of AI model provider
    versus adopter activities as compared to MLOps, given the role of the pre-trained
    foundation models and their massive datasets. There are also clear differences
    in data needs (format, volume), the creation of pipelines and flows, and the methods
    to evaluate and monitor the results of the models. Also, some engineering tasks
    traditionally focused on preparing and testing ML models are evolving toward prompt
    engineering.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，LLMOps与MLOps相比，在预训练基础模型及其大量数据集的作用下，带来了AI模型提供者与使用者活动的完全不同的划分。在数据需求（格式、数量）、管道和流程的创建，以及评估和监控模型结果的方法上，也存在明显的差异。此外，一些传统上专注于准备和测试ML模型的工程任务正在向提示工程发展。
- en: 'Additionally, companies such as Databricks [compare LLMOps to traditional MLOps](https://oreil.ly/Rle9o)
    based on these concepts:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，像Databricks这样的公司[基于这些概念将LLMOps与传统的MLOps进行比较](https://oreil.ly/Rle9o)。
- en: LLMs can be *fine-tuned with new data* to adapt to specific domains or tasks,
    which reduces the amount of data and resources needed compared to training from
    scratch.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs可以通过*新数据微调*来适应特定领域或任务，与从头开始训练相比，这减少了所需的数据和资源量。
- en: LLMs can benefit from *reinforcement learning from human feedback*, which helps
    in improving their performance and evaluating their outputs in open-ended tasks.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs可以从*人类反馈的强化学习*中受益，这有助于提高其性能并在开放性任务中评估其输出。
- en: LLMs have *different performance metrics* than traditional ML models, such as
    [BLEU](https://oreil.ly/dWQ8D) and [ROUGE](https://oreil.ly/SRoZf), or any of
    the [built-in evaluation metrics](https://oreil.ly/gfK28) from Azure AI Studio
    that we discussed in [Chapter 3](ch03.html#implementing_cloud_native_generative_ai_with_azure).
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs的性能指标与传统ML模型不同，例如[BLEU](https://oreil.ly/dWQ8D)和[ROUGE](https://oreil.ly/SRoZf)，或者我们在[第3章](ch03.html#implementing_cloud_native_generative_ai_with_azure)中讨论的Azure
    AI Studio的任何[内置评估指标](https://oreil.ly/gfK28)。
- en: LLMs can be *combined with other systems*, such as web search or vector databases,
    to create pipelines that can handle complex tasks like knowledge base Q&A, or
    even combined in more complex [multi-agent systems (MAS)](https://oreil.ly/CXcJI).
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs可以与其他系统**结合**，例如网络搜索或向量数据库，以创建可以处理复杂任务如知识库问答的管道，甚至可以结合更复杂的[多智能体系统（MAS）](https://oreil.ly/CXcJI)。
- en: 'Coming back to generative AI activities, it is already clear that they go way
    beyond simply prompt engineering activities and include additional considerations
    at the system and application levels. Technical LLM and prompt-related questions
    can be explored from many different perspectives. For example:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 回到生成式AI活动，很明显，它们远远超出了简单的提示工程活动，并在系统和应用层面包含额外的考虑因素。技术LLM和提示相关的问题可以从许多不同的角度进行探讨。例如：
- en: From a *user experience* perspective, by anticipating customer questions and
    assessing model responses, and including UX designers during the generative AI
    app development process
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从**用户体验**的角度来看，通过预测客户问题、评估模型响应，并在生成式AI应用开发过程中包含用户体验设计师
- en: 'Keeping in mind *application capabilities*, including:'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑到**应用能力**，包括：
- en: Cost, latency, and token length limitations (e.g., splitting tasks into smaller
    chunks)
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本、延迟和令牌长度限制（例如，将任务拆分为更小的块）
- en: Articulating instructions, orchestrating prompt flows, and shifting things back
    and forth between assistant and system roles
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明确指令、编排提示流，并在助手和系统角色之间来回切换
- en: Adjusting model parameters such as temperature, output formats, etc.
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整模型参数，如温度、输出格式等。
- en: 'Combining core LLM and prompt activities with the overall *architecture design*:'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将核心LLM和提示活动与整体**架构设计**相结合：
- en: Working with architects to address complex system requirements
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与架构师合作，解决复杂系统需求
- en: Employing advanced patterns like RAG and rounding AI responses in enterprise
    data to obtain accurate answers
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采用高级模式如RAG，以及在企业数据中对AI响应进行四舍五入以获得准确答案
- en: Including *compliance, security, and responsibility* questions from the design
    phase—for example, choosing the best Azure region to guarantee data residency
    in EU countries, or choosing the best filtering/moderation settings at both the
    prompt and completion levels
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在设计阶段就包含**合规性、安全性和责任**问题——例如，选择最佳的Azure区域以确保欧盟国家数据驻留，或者在提示和完成级别选择最佳的过滤/审查设置
- en: In the following sections, we will explore some of these topics, and the considerations
    and options available from an Azure and Azure OpenAI perspective. Let’s start
    by talking about prompt flows and pipelines.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将探讨这些主题，以及从Azure和Azure OpenAI的角度可用的考虑因素和选项。让我们先从提示流和管道开始谈。
- en: Prompt Flow and Azure ML
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示流和Azure ML
- en: Azure AI Studio and [Azure ML](https://oreil.ly/JyodR) are enterprise-grade
    AI services for the end-to-end machine learning lifecycle, which includes building,
    testing, deploying, and managing machine learning models. They are PaaSs that
    include [AutoML functionalities](https://oreil.ly/i0jAV) to leverage existing
    pre-built classification, regression, forecasting, computer vision, and NLP models.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Azure AI Studio和[Azure ML](https://oreil.ly/JyodR)是端到端机器学习生命周期的企业级AI服务，包括构建、测试、部署和管理机器学习模型。它们是包含[AutoML功能](https://oreil.ly/i0jAV)的PaaS，以利用现有的预构建分类、回归、预测、计算机视觉和NLP模型。
- en: With the arrival of Azure OpenAI Service to the family of Azure AI solutions,
    Azure ML has incorporated a new functionality called *prompt flow*. A prompt flow
    is a graphical representation of the data flow and processing logic of your AI
    application (it offers a [Python library](https://oreil.ly/_JxYW) and a [Visual
    Studio extension](https://oreil.ly/FjBbh) as well); this Azure ML feature is a
    development tool designed to streamline the entire development cycle of LLM-enabled
    applications.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Azure OpenAI服务加入Azure AI解决方案的大家庭，Azure ML已经引入了一个名为*提示流*的新功能。提示流是您AI应用程序数据流和处理逻辑的图形表示（它还提供[Python库](https://oreil.ly/_JxYW)和[Visual
    Studio扩展](https://oreil.ly/FjBbh)）；这个Azure ML功能是一个旨在简化LLM启用应用程序整个开发周期的开发工具。
- en: 'Microsoft [defines flows](https://oreil.ly/AI5N-) as executable workflows that
    streamline the development of your LLM-based AI application, with a comprehensive
    framework for managing and processing data flows. Prompt flow includes three different
    [types of flows](https://oreil.ly/BZRXb):'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 微软[定义流程](https://oreil.ly/AI5N-)为可执行的流程，用于简化基于LLM的AI应用程序的开发，并提供了管理和处理数据流的全面框架。提示流包括三种不同的[流程类型](https://oreil.ly/BZRXb)：
- en: Standard flow
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 标准流程
- en: This is the [default flow type](https://oreil.ly/3yWpf) for general application
    development, for instruction (not chat) scenarios. You can use a variety of built-in
    tools to create a flow that connects LLMs, prompts, and Python tools. You can
    also customize and debug your flow using a notebook-like interface.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[默认流程类型](https://oreil.ly/3yWpf)，适用于通用应用程序开发，对于指令（非聊天）场景。您可以使用各种内置工具创建连接LLMs、提示和Python工具的流程。您还可以使用类似笔记本的界面自定义和调试您的流程。
- en: Chat flow
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天流程
- en: This is a [specialized flow type](https://oreil.ly/XlxTr) for conversational
    applications. You can use the same tools as the standard flow, but with additional
    features for chat inputs/outputs and chat history management. You can also test
    and debug your flow in a native conversation mode.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个[专门用于聊天应用的流程类型](https://oreil.ly/XlxTr)。您可以使用与标准流程相同的工具，但具有额外的聊天输入/输出和聊天历史管理功能。您还可以在原生对话模式下测试和调试您的流程。
- en: Evaluation flow
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 评估流程
- en: This is a [dedicated flow type for evaluation scenarios](https://oreil.ly/IGZNA).
    You can use this flow to measure the quality and effectiveness of your prompts
    and flows using built-in or custom evaluation flows. You can also compare the
    results of different prompt variants using charts and tables.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个[专门用于评估场景的流程类型](https://oreil.ly/IGZNA)。您可以使用此流程使用内置或自定义评估流程来衡量您提示和流程的质量和有效性。您还可以使用图表和表格比较不同提示变体的结果。
- en: Regardless of the prompt type, the [prompt flow platform](https://oreil.ly/jZEeX)
    focuses on the different implementation phases of Azure OpenAI and other LLMs
    in Azure, including the four-stage process that you can see in [Figure 5-3](#fig_3_llm_prompt_flow_steps_source_microsoft).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 不论是哪种提示类型，[提示流平台](https://oreil.ly/jZEeX)都专注于Azure OpenAI和其他LLMs在Azure中的不同实现阶段，包括您可以在[图5-3](#fig_3_llm_prompt_flow_steps_source_microsoft)中看到的四阶段流程。
- en: '![](assets/aoas_0503.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0503.png)'
- en: 'Figure 5-3\. LLM prompt flow steps (source: adapted from an image by Microsoft)'
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-3\. LLM提示流步骤（来源：改编自微软的一张图片）
- en: 'Let’s walk through each step:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一了解每个步骤：
- en: 1\. Initialization (or creation)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 初始化或创建
- en: Use the prompt flow authoring canvas to design and develop your prompt flow.
    It connects LLMs, prompts, and Python tools in one prompt flow, and it can generate
    multiple [prompt variants](https://oreil.ly/MWjlS) to adjust the LLM outputs.
    It also allows [integration with LangChain functionalities](https://oreil.ly/7GqOL).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用提示流创作画布来设计和开发您的提示流。它在一个提示流中连接LLMs、提示和Python工具，并可以生成多个[提示变体](https://oreil.ly/MWjlS)以调整LLMs的输出。它还允许[与LangChain功能集成](https://oreil.ly/7GqOL)。
- en: 2\. Experimentation (or testing)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 实验或测试
- en: In this stage, the prompt flow testing panel helps you run and debug your prompt
    flow. You can see the input and output of each node in your prompt flow and their
    variants.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，提示流测试面板帮助您运行和调试您的提示流。您可以看到您提示流中每个节点及其变体的输入和输出。
- en: 3\. Evaluation and refinement
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 评估和改进
- en: In this stage, you can use the [prompt flow evaluation panel](https://oreil.ly/4NrIz)
    to assess the quality and effectiveness of your prompt [flow versions/variants](https://oreil.ly/htoB5).
    You can use built-in evaluation flows or create your own custom evaluation flows
    to measure different metrics, such as accuracy, fluency, diversity, and relevance.
    You can also see the results of your evaluation flows in charts and tables.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，您可以使用[提示流评估面板](https://oreil.ly/4NrIz)来评估您提示[流版本/变体](https://oreil.ly/htoB5)的质量和有效性。您可以使用内置的评估流程或创建自己的自定义评估流程来衡量不同的指标，例如准确性、流畅性、多样性和相关性。您还可以在图表和表格中查看您评估流程的结果。
- en: 4\. Production (or deployment)
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 生产（或部署）
- en: In this stage, you can use the prompt flow deployment panel to [deploy your
    prompt flow](https://oreil.ly/FPZDN) as a real-time endpoint, for example via
    Azure Kubernetes Service (AKS). You can also [monitor the endpoints via Azure
    Monitor](https://oreil.ly/0GS-u), [troubleshoot](https://oreil.ly/XuSsH), and
    manage them using Azure AI/ML Studio’s [prompt flow runtimes](https://oreil.ly/6UWqf).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，您可以使用提示流部署面板将您的提示流[部署为实时端点](https://oreil.ly/FPZDN)，例如通过Azure Kubernetes服务（AKS）。您还可以通过[Azure
    Monitor](https://oreil.ly/0GS-u)监控端点、[故障排除](https://oreil.ly/XuSsH)并使用Azure AI/ML
    Studio的[提示流运行时](https://oreil.ly/6UWqf)来管理它们。
- en: Prompt flow is a very powerful (and evolving) tool with the capability to plan
    and deploy prompt-based implementations. The next step is to plan security requirements
    for these generative AI applications.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 提示流是一个非常强大（且不断发展）的工具，具有规划和部署基于提示的实施的能力。下一步是为这些生成式AI应用规划安全要求。
- en: Note
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'At the time of writing this book, Microsoft released [a series of functionalities](https://oreil.ly/QdI37)
    that are relevant to this and the next section, as they include performance, safety,
    and security capabilities:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写此书时，微软发布了一系列与这一部分和下一部分相关的功能，因为它们包括性能、安全和安全功能：
- en: '[AI-assisted safety evaluations](https://oreil.ly/GcCSo)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[AI辅助安全评估](https://oreil.ly/GcCSo)'
- en: This powerful feature will help you create automated evaluations to systematically
    assess and improve your generative AI applications before deploying to production.
    You can check the [transparency note](https://oreil.ly/XKzEs) to understand how
    and when to use them.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这个强大的功能将帮助您创建自动化的评估，以系统性地评估和改进您的生成式AI应用，在部署到生产之前。您可以查看[透明度说明](https://oreil.ly/XKzEs)以了解如何以及何时使用它们。
- en: '[Prompt Shield](https://oreil.ly/KwA_D)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[提示盾牌](https://oreil.ly/KwA_D)'
- en: This functionality protects generative AI development against direct and indirect
    attacks. Direct attacks are those included directly in the prompt, while indirect
    attacks happen when the application processes information that wasn’t directly
    authored by either the developer of the application or the user. You can learn
    more about Prompt Shields from the [official documentation](https://oreil.ly/_J-J9).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能保护生成式AI开发免受直接和间接攻击。直接攻击是直接包含在提示中的那些，而间接攻击发生在应用程序处理的信息不是由应用程序的开发者或用户直接创作时。您可以从[官方文档](https://oreil.ly/_J-J9)中了解更多关于提示盾牌的信息。
- en: '[Spotlighting](https://oreil.ly/P_Oz6)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[突出显示](https://oreil.ly/P_Oz6)'
- en: A technique from Microsoft Research that leverages the [system prompt](https://oreil.ly/Wbc7V)
    to protect against indirect attacks.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 来自微软研究的一个技术，它利用[系统提示](https://oreil.ly/Wbc7V)来防止间接攻击。
- en: Securing LLMs
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保护LLM
- en: Creating efficient prompts and managing all required flows is key to reaching
    a high level of performance for enterprise-level implementations. However, companies
    developing generative AI applications have high security requirements to reduce
    any potential risk. As you can see in [Figure 5-4](#fig_4_layered_approach_to_securing_llms),
    there are several levels of security for any LLM development with Microsoft’s
    Azure Cloud and Azure OpenAI Service.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 创建高效的提示并管理所有必要的流程是实现企业级实施高性能的关键。然而，开发生成式AI应用的公司对安全性有很高的要求，以降低任何潜在的风险。正如您在[图5-4](#fig_4_layered_approach_to_securing_llms)中看到的，使用微软的Azure云和Azure
    OpenAI服务，任何LLM开发都有几个安全级别。
- en: '![](assets/aoas_0504.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0504.png)'
- en: Figure 5-4\. Layered approach to securing LLMs
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-4. 保护LLM的分层方法
- en: 'This approach includes:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法包括：
- en: Service-level measures
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 服务级别指标
- en: 'Securing a generative AI implementation with Azure OpenAI starts by managing
    all service model-related topics, including core model performance, but also the
    protection of prompts, endpoints, and the APIs. Here are some ways to implement
    these:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Azure OpenAI 保护生成式 AI 实施的起点是管理所有与服务模型相关的主题，包括核心模型性能，以及提示、端点和 API 的保护。以下是一些实现这些措施的方法：
- en: For interaction with the model, use contextualization methods via *system message/meta-prompts*
    to define and reduce the topic scope. This allows you to programmatically avoid
    prompts that are not desired by design.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于与模型的交互，使用通过 *系统消息/元提示* 的上下文化方法来定义和缩小主题范围。这允许您通过编程方式避免设计上不希望出现的提示。
- en: For the prompt templates we define as reusable text strings, store and protect
    them via databases in Azure. Regardless of the format, those databases can be
    securely consumed by implementing [monitoring activities with Azure Monitor](https://oreil.ly/mp1Ls).
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于我们定义的可重复使用的文本字符串提示模板，通过 Azure 中的数据库进行存储和保护。无论格式如何，这些数据库都可以通过实施 [Azure Monitor
    的监控活动](https://oreil.ly/mp1Ls) 来安全地消费。
- en: For Azure OpenAI endpoints, Azure Application Gateway provides a [single point
    of entry and load balancing](https://oreil.ly/6plOw) to get the responses in a
    fast and reliable way. An Application Gateway can function as a Web Application
    Firewall (WAF), providing protection against common web-based attacks, configured
    with a custom set of rules that match the requirements of your OpenAI application
    to ensure only authorized access. That said, load balancing is not supported for
    stateful operations like model fine-tuning, deployments, and inference of fine-tuned
    models.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 Azure OpenAI 端点，Azure 应用网关提供了一个 [单一入口和负载均衡](https://oreil.ly/6plOw) 的解决方案，以便快速且可靠地获取响应。应用网关可以作为
    Web 应用防火墙 (WAF) 使用，通过配置一组自定义规则来保护您的 OpenAI 应用，确保只有授权访问。但需要注意的是，对于像模型微调、部署和微调模型的推理这样的有状态操作，负载均衡是不支持的。
- en: You can also leverage [RBAC (role-based access control) with Azure OpenAI](https://oreil.ly/YJOZv),
    to decide who can access what, depending on their rights to access specific information
    via generative AI applications. This is useful if you want to develop internal
    copilots for different departments that should access different information.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您还可以利用 [Azure OpenAI 的基于角色的访问控制 (RBAC)](https://oreil.ly/YJOZv) 来决定谁可以访问什么，这取决于他们通过生成式
    AI 应用访问特定信息的权限。如果您想为不同部门开发应访问不同信息的内部共飞行员，这将非常有用。
- en: For additional security controls, such as [model auditing and monitoring](https://oreil.ly/4uV20),
    Azure API Management helps grant [access to the model APIs](https://oreil.ly/sQuG_),
    leveraging [Microsoft Entra ID](https://oreil.ly/EXO6A) (Azure Active Directory)
    groups with subscription-based permissions, enabling request logging with Azure
    Monitor, and providing detailed usage metrics and key performance indicators for
    your models.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于额外的安全控制，例如 [模型审计和监控](https://oreil.ly/4uV20)，Azure API Management 通过利用 [Microsoft
    Entra ID](https://oreil.ly/EXO6A)（Azure Active Directory）组以及基于订阅的权限来帮助授予 [模型 API
    的访问权限](https://oreil.ly/sQuG_)，启用 Azure Monitor 的请求记录，并为您的模型提供详细的用法指标和关键性能指标。
- en: Other cloud-level measures
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 其他云级别措施
- en: 'Besides the core model measures, there are other security and networking best
    practices that will help secure the rest of the cloud native architecture:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 除了核心模型度量之外，还有一些其他的安全和网络最佳实践可以帮助保护云原生架构的其他部分：
- en: Use *Azure Private Link* to connect API Management to your Azure OpenAI instances
    and [other Azure resources such as AI Search](https://oreil.ly/iBwcQ). This can
    help [protect data and traffic](https://oreil.ly/jcELV) from external exposure
    and keep them within the private network. You can use [private endpoints](https://oreil.ly/q0MUT)
    to connect between different virtual networks.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 *Azure Private Link* 将 API 管理连接到您的 Azure OpenAI 实例以及其他 Azure 资源，例如 [AI 搜索](https://oreil.ly/iBwcQ)。这有助于
    [保护数据和流量](https://oreil.ly/jcELV) 免受外部暴露，并将它们保持在私有网络内。您可以使用 [私有端点](https://oreil.ly/q0MUT)
    在不同的虚拟网络之间进行连接。
- en: Enable *Azure Key Vault* to [store the security keys and secrets](https://oreil.ly/aTyqt)
    that are used by the generative AI applications. This can help prevent unauthorized
    access to your data and models. Alternatively, tools like [Databricks MLflow AI
    Gateway](https://oreil.ly/owP_k) can also help centralize management of LLM credentials
    and deployments, especially for cases that combine Azure OpenAI Service and other
    non-OpenAI LLMs.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用*Azure密钥保管库*来[存储生成式AI应用程序使用的安全密钥和秘密](https://oreil.ly/aTyqt)。这可以帮助防止对您的数据和模型进行未经授权的访问。或者，像[Databricks
    MLflow AI Gateway](https://oreil.ly/owP_k)这样的工具也可以帮助集中管理LLM凭证和部署，特别是对于结合Azure
    OpenAI服务和其他非OpenAI LLMs的情况。
- en: Deploy *Azure Storage* to store model training artifacts and data, and *Defender
    for Storage* to add an Azure-native [layer of security intelligence](https://oreil.ly/cAjUN)
    that detects potential threats to storage accounts. This helps prevent malicious
    file uploads, sensitive data exfiltration, and data corruption. Additionally,
    you can leverage services such as Microsoft Sentinel and *Cloud Defender for Databases*,
    a security service that protects databases with [attack detection and threat response](https://oreil.ly/Xk9Q-),
    or [Defender for APIs](https://oreil.ly/FPScz), a service that offers protection,
    detection, and response capabilities for your APIs. All this can help ensure that
    your data is accessible and secure.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署*Azure存储*来存储模型训练工件和数据，以及*存储Defender*来添加一个检测存储账户潜在威胁的Azure原生[安全智能层](https://oreil.ly/cAjUN)。这有助于防止恶意文件上传、敏感数据泄露和数据损坏。此外，你还可以利用Microsoft
    Sentinel和*数据库Cloud Defender*等服务，这是一种提供[攻击检测和威胁响应](https://oreil.ly/Xk9Q-)的安全服务，或者[API
    Defender](https://oreil.ly/FPScz)，这是一种提供保护、检测和响应能力的API服务。所有这些都可以帮助确保你的数据既可访问又安全。
- en: Leverage by-default [encryption mechanisms](https://oreil.ly/n9bqC) in [Azure](https://oreil.ly/zwa8V)
    as a way to protect data natively at rest and in transit. More specifically, Azure
    OpenAI Service includes automatic ways to [encrypt your data](https://oreil.ly/aTCqC)
    when it’s persisted to the cloud, in order to meet organizational security and
    compliance commitments.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用Azure默认的[加密机制](https://oreil.ly/n9bqC)作为在本地和传输中保护数据的一种方式。更具体地说，Azure OpenAI服务包括将数据持久化到云时自动[加密数据](https://oreil.ly/aTCqC)的方法，以满足组织的安全和合规承诺。
- en: '*Govern data and manage data quality* by using [Microsoft Purview (Microsoft’s
    unified data governance solution)](https://oreil.ly/KFNn6) and third-party tools
    such as [CluedIn](https://oreil.ly/thi-L) or [Profisee](https://oreil.ly/Y4IPx)
    for master data management (MDM) and data quality. You will learn more about this
    topic in [Chapter 7](ch07.html#exploring_the_big_picture) within the book’s expert
    interviews.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用[微软Purview（微软统一数据治理解决方案）](https://oreil.ly/KFNn6)和第三方工具，如[CluedIn](https://oreil.ly/thi-L)或[Profisee](https://oreil.ly/Y4IPx)来*管理和维护数据质量*，进行主数据管理（MDM）和数据质量。你将在本书的专家访谈中第[第7章](ch07.html#exploring_the_big_picture)中了解更多关于这个主题的内容。
- en: Last but not least, there are other building blocks based on the [Well-Architected
    Framework](https://oreil.ly/jHwtt) that help build an [end-to-end landing zone](https://oreil.ly/wQkFc)
    for highly secured Azure OpenAI implementations.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，还有一些基于[架构良好框架](https://oreil.ly/jHwtt)的构建块，有助于构建高度安全的Azure OpenAI实施的[端到端着陆区](https://oreil.ly/wQkFc)。
- en: General company-level governance measures
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 公司级别的通用治理措施
- en: 'These may include measures such as the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可能包括以下措施：
- en: From a general *security management* perspective, the [AI Security Risk Assessment
    at Microsoft](https://oreil.ly/YzOaS) is a process of evaluating the potential
    risks and vulnerabilities of AI systems, such as machine learning models, data
    pipelines, and deployment environments. Microsoft developed a framework and a
    tool to help organizations conduct AI security risk assessments and improve the
    security of their AI systems, and it can be leveraged for Azure OpenAI and generative
    AI implementations.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从一般的安全管理角度来看，[微软的AI安全风险评估](https://oreil.ly/YzOaS)是一个评估人工智能系统潜在风险和漏洞的过程，例如机器学习模型、数据管道和部署环境。微软开发了一个框架和工具，帮助组织进行AI安全风险评估并提高其AI系统的安全性，这可以用于Azure
    OpenAI和生成式AI的实施。
- en: From a *security testing and risk mitigation* point of view, the notion of [red
    teaming](https://oreil.ly/JLZeB) defines systematic adversarial attacks for testing
    security vulnerabilities. [Red teaming for Azure OpenAI and other LLMs](https://oreil.ly/oDBO_)
    is a practice of testing the security and robustness of generative AI systems.
    It involves simulating adversarial attacks on AI systems and identifying potential
    harms or vulnerabilities that could affect their quality, reliability, and trustworthiness.
    Red teaming is an important part of the responsible development and deployment
    of AI systems that use LLMs. Testing is done at both the LLM and application/UI
    levels.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从*安全测试和风险缓解*的角度来看，[红队行动](https://oreil.ly/JLZeB)的概念定义了用于测试安全漏洞的系统对抗性攻击。[针对Azure
    OpenAI和其他LLM的红队行动](https://oreil.ly/oDBO_)是一种测试生成AI系统安全和鲁棒性的实践。它涉及模拟对AI系统的对抗性攻击，并确定可能影响其质量、可靠性和可信度的潜在危害或漏洞。红队行动是使用LLM的AI系统负责任开发和部署的重要部分。测试在LLM和应用/用户界面级别进行。
- en: Even if this three-level approach can help secure and avoid most security risks,
    this new area of development requires continued analysis and improvement. As with
    any other generative AI topics, the industry keeps updating the list of potential
    risks related to LLMs, and being aware of them can help reinforce your security
    initiatives.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这种三级方法可以帮助确保并避免大多数安全风险，但这个新的开发领域仍需要持续的分析和改进。与任何其他生成AI主题一样，行业持续更新与LLM相关的潜在风险列表，了解这些风险可以帮助加强您的安全措施。
- en: 'The [OWASP Foundation](https://oreil.ly/WnMkm) has elaborated a comprehensive
    list of the main risks and vulnerabilities often seen in LLM applications, highlighting
    their potential impact, ease of exploitation, and prevalence in real-world applications:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '[OWASP基金会](https://oreil.ly/WnMkm)已经详细列出了一组在LLM应用程序中经常看到的主要风险和漏洞，突出了它们的潜在影响、利用的容易程度以及在现实世界应用中的普遍性：'
- en: Prompt injection
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 提示注入
- en: This is a way of tricking an LLM by giving it clever inputs that change its
    behavior (for example, imagine an HR application for automated CV analysis that
    leverages LLMs where someone inserts a prompt in hidden text that alters the backend
    of the AI-enabled tool). In general, the inputs can overwrite the system prompts
    that guide the LLM, or even manipulate data from other sources that the LLM uses.
    This includes jailbreaking, a technique that exploits prompt manipulation to bypass
    usage policy measures in LLM chatbots, enabling the generation of responses and
    malicious content that violate the policies of the chatbot. All these issues can
    come from any part of the generative AI code, including development with pieces
    such as LangChain and Semantic Kernel.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种通过提供巧妙的输入来欺骗LLM并改变其行为的方法（例如，想象一个用于自动简历分析的HR应用程序，其中有人将提示插入到隐藏文本中，从而改变AI工具的后端）。一般来说，输入可以覆盖引导LLM的系统提示，甚至可以操纵LLM使用的数据来源。这包括越狱技术，这是一种利用提示操作来绕过LLM聊天机器人使用策略措施的技术，使得生成违反聊天机器人政策的响应和恶意内容。所有这些问题都可能来自生成AI代码的任何部分，包括使用LangChain和Semantic
    Kernel等组件的开发。
- en: Insecure output handling
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 不安全输出处理
- en: This is a problem that occurs when an LLM output is not checked carefully before
    using it, exposing other systems to risks. The output may contain harmful content
    that can cause different kinds of attacks. For example, this could occur in RAG
    scenarios with LLMs connecting and sending insecure queries to databases.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个在LLM输出在使用前未仔细检查时出现的问题，使其他系统面临风险。输出可能包含有害内容，可能导致不同类型的攻击。例如，这可能在LLM连接并发送不安全查询到数据库的RAG场景中发生。
- en: Training data poisoning
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据投毒
- en: Someone messes with the data that is used to train an LLM, making it vulnerable
    or biased and affecting its security, performance, or ethics.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 某人篡改用于训练LLM的数据，使其易受攻击或存在偏见，并影响其安全性、性能或伦理。
- en: Model denial of service
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 模型拒绝服务
- en: Attackers make an LLM do a lot of work that uses up its resources, making it
    slow or expensive. The problem is worse because LLMs need a lot of resources to
    run, and the user inputs are hard to predict.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者让LLM做大量工作，消耗其资源，使其变慢或昂贵。问题更严重，因为LLM需要大量资源来运行，而用户输入难以预测。
- en: Supply chain vulnerabilities
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 供应链漏洞
- en: An LLM application can be compromised by using components or services that have
    weaknesses, leading to security attacks. The components or services may include
    third-party datasets, pre-trained models, and plug-ins.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: LLM应用程序可能会因为使用具有弱点的组件或服务而被破坏，从而导致安全攻击。这些组件或服务可能包括第三方数据集、预训练模型和插件。
- en: Sensitive information disclosure
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感信息泄露
- en: This can occur when an LLM accidentally reveals private data in its responses,
    allowing unauthorized access, privacy violations, and security breaches. It is
    important to clean the data and enact strict user policies to prevent this. This
    can also apply to meta-prompt leakage, revealing key performance information to
    external users.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能发生在LLM在响应中意外泄露私人数据时，允许未经授权的访问、隐私侵犯和安全漏洞。重要的是要清理数据并实施严格的使用政策以防止这种情况发生。这也适用于元提示泄露，向外部用户透露关键性能信息。
- en: Insecure plug-in design
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 不安全的插件设计
- en: This becomes an issue when LLM plug-ins have unsafe inputs and poor access control.
    This lack of application control makes them easy to exploit and can result in
    consequences like remote code execution.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 当LLM插件存在不安全的输入和较差的访问控制时，这成为一个问题。这种缺乏应用程序控制使得它们容易被利用，并可能导致远程代码执行等后果。
- en: Excessive agency
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 过度授权
- en: LLM-based systems may do things that have unintended consequences. For example,
    if the LLM can interface and control other systems (i.e., an AI copilot controlling
    some software-based functionalities for an autonomous car), it can increase the
    attack surface. The issue comes from giving too much functionality, permissions,
    or autonomy to LLM-based systems, and can impact not only the AI piece, but also
    the rest of the connected systems.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 基于LLM的系统可能会产生意想不到的后果。例如，如果LLM可以与控制其他系统（例如，AI副驾驶控制自动驾驶汽车的一些基于软件的功能），它可能会增加攻击面。问题在于给予基于LLM的系统过多的功能、权限或自主权，这不仅会影响AI部分，还会影响其他连接的系统。
- en: Overreliance
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 过度依赖
- en: This occurs when systems or people depend too much on LLMs without supervision.
    They may face problems like misinformation, miscommunication, legal issues, and
    security vulnerabilities due to incorrect or inappropriate content generated by
    LLMs. It can also generate shadow IT issues, where company employees may be using
    LLM-enabled systems that are not part of the approved list of applications.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况发生在系统或人员过度依赖LLM（大型语言模型）而没有监督的情况下。他们可能会因为LLM生成的不正确或不适当的内容而面临诸如错误信息、沟通不畅、法律问题和安全漏洞等问题。它还可能产生影子IT问题，即公司员工可能在使用未经批准的应用程序列表之外的LLM启用系统。
- en: Model theft
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 模型盗窃
- en: This occurs when someone accesses, copies, or steals proprietary LLM models
    without permission. The impacts include economic losses, compromised competitive
    advantage, and potential access to sensitive information. Research has shown that
    it is even possible to [re-create part of the training sets of an LLM](https://oreil.ly/gvG-Q).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况发生在未经许可的情况下，有人访问、复制或窃取专有LLM模型。其影响包括经济损失、竞争优势受损以及可能访问敏感信息。研究表明，甚至可以[重新创建LLM的部分训练集](https://oreil.ly/gvG-Q)。
- en: Additionally, there are other organizations already [exploring risks related
    to generative AI open source software (OSS)](https://oreil.ly/8vcyo), due to its
    special nature. That said, securing both closed and open models will continue
    to be an important area of study. Let’s now analyze other legal considerations.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有其他组织已经开始[探索与生成式AI开源软件（OSS）相关的风险](https://oreil.ly/8vcyo)，鉴于其特殊性质。话虽如此，确保封闭和开放模型的安全将继续是一个重要的研究领域。现在让我们分析其他法律考虑因素。
- en: Managing Privacy and Compliance
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理隐私和合规性
- en: Securing generative AI developments is a must, but it is just one of the key
    elements for company-level implementations. There are additional compliance and
    data privacy requirements that will impact the technology choice, including considerations
    such as data residency, model availability by geographic region, etc.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 保护生成式AI的发展是必须的，但这只是公司级实施的关键要素之一。还有其他合规性和数据隐私要求将影响技术选择，包括数据驻留、按地理区域提供模型可用性等考虑因素。
- en: 'For that purpose, there are core features related to Microsoft Azure and the
    managed Azure OpenAI Service that help achieve compliance and facilitate any legal
    and auditing activity:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了这个目的，有一些与Microsoft Azure和管理的Azure OpenAI服务相关的核心功能，有助于实现合规性并促进任何法律和审计活动：
- en: General *data protection* mechanisms for Microsoft Azure services, which focus
    on the [key principle](https://oreil.ly/SfBXe) of “giving you control over the
    data you put in the cloud. In other words, you control your data.” This is important
    to leverage key security and data protection features, while keeping control of
    the data.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软 Azure 服务的通用 *数据保护* 机制，重点关注“赋予您对放入云中的数据的控制权”这一[关键原则](https://oreil.ly/SfBXe)。换句话说，您控制着您的数据。”这对于利用关键的安全和数据保护功能，同时保持对数据的控制至关重要。
- en: '[Compliance information](https://oreil.ly/lKBjQ) related to all Azure-related
    services. This includes international regulations such as [GDPR](https://oreil.ly/hiTwi),
    [CCPA](https://oreil.ly/2btT8), [HIPAA](https://oreil.ly/Uy8hS), etc. This guarantees
    that any implementation with Microsoft Azure (including Azure OpenAI) is aligned
    with all regulatory requirements.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与所有 Azure 相关服务的[合规信息](https://oreil.ly/lKBjQ)。这包括国际法规，如 [GDPR](https://oreil.ly/hiTwi)、[CCPA](https://oreil.ly/2btT8)、[HIPAA](https://oreil.ly/Uy8hS)
    等。这保证了任何使用微软 Azure（包括 Azure OpenAI）的实施都符合所有监管要求。
- en: Personally identifiable information (PII) [detection and document redaction](https://oreil.ly/kFlHF)
    via [Azure AI Language](https://oreil.ly/b191_), which can enable your generative
    AI scenarios with a preliminary filtering of any sensitive data before creating
    your RAG-enabled scenario with your knowledge base. For example, this is very
    relevant for personal information in healthcare or finance scenarios.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 [Azure AI Language](https://oreil.ly/b191_) 进行 [个人身份信息（PII）检测和文档红字](https://oreil.ly/kFlHF)，这可以使您的生成式
    AI 场景在创建具有您的知识库的 RAG 启用场景之前对任何敏感数据进行初步筛选。例如，这对于医疗保健或金融场景中的个人信息非常相关。
- en: 'Specific advantages of *Azure OpenAI as a managed service*, when compared to
    other non-Azure options. Specifically:'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他非 Azure 选项相比，*Azure OpenAI 作为托管服务的具体优势*。具体来说：
- en: '*Data privacy and security*: The data sent to Azure OpenAI Service stays within
    Microsoft Azure and is not passed to OpenAI (the company) for predictions. Azure
    OpenAI Service automatically encrypts any data that is persisted in the cloud,
    including training data and fine-tuned models. It includes specific information
    about how data and prompts are handled. Refer to the [official Microsoft documentation](https://oreil.ly/1hpAO)
    for any updates to this information:'
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据隐私和安全*：发送到 Azure OpenAI 服务的所有数据都保留在微软 Azure 内，不会传递给 OpenAI（公司）进行预测。Azure
    OpenAI 服务自动加密任何持久化在云中的数据，包括训练数据和微调模型。它包括有关如何处理数据和提示的特定信息。有关此信息的任何更新，请参阅[官方微软文档](https://oreil.ly/1hpAO)：'
- en: 'Your prompts (inputs) and completions (outputs), your embeddings, and your
    training data:'
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 您的提示（输入）和完成（输出），您的嵌入和您的训练数据：
- en: ''
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: are NOT available to other customers.
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不对其他客户可用。
- en: are NOT available to OpenAI.
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不对 OpenAI 可用。
- en: are NOT used to improve OpenAI models.
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不用于改进 OpenAI 模型。
- en: are NOT used to improve any Microsoft or 3rd party products or services.
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不用于改进任何微软或第三方产品或服务。
- en: are NOT used for automatically improving Azure OpenAI models for your use in
    your resource (The models are stateless, unless you explicitly fine-tune models
    with your training data).
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不用于自动改进适用于您在资源中使用的 Azure OpenAI 模型（除非您明确使用您的训练数据微调模型，否则模型是无状态的）。
- en: Your fine-tuned Azure OpenAI models are available exclusively for your use.
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您微调的 Azure OpenAI 模型仅可供您使用。
- en: ''
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: The Azure OpenAI Service is fully controlled by Microsoft; Microsoft hosts the
    OpenAI models in Microsoft’s Azure environment and the Service does NOT interact
    with any services operated by OpenAI (e.g. ChatGPT, or the OpenAI API).
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Azure OpenAI 服务完全由微软控制；微软在微软的 Azure 环境中托管 OpenAI 模型，并且服务不与 OpenAI 运营的任何服务（例如
    ChatGPT 或 OpenAI API）交互。
- en: '*Regional availability and private networks*: Azure OpenAI Service allows you
    to define the location of the models (based on specific [model region availability](https://oreil.ly/BI5Ue))
    data processing and storage for your training data, which can be important for
    meeting local regulations or customer preferences.'
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*区域可用性和私有网络*：Azure OpenAI 服务允许您定义模型的位置（基于特定的[模型区域可用性](https://oreil.ly/BI5Ue)）以及您的训练数据的数据处理和存储，这对于满足当地法规或客户偏好可能很重要。'
- en: '*Responsible content filtering:* Azure OpenAI Service provides an [additional
    layer of content filtering](https://oreil.ly/SzGoi) to prevent models from generating
    inappropriate or offensive content. At the API level, this means that the response
    may include [`finish_reason = content_filter`](https://oreil.ly/dQJ34) when the
    content is filtered.'
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*负责任的内容过滤*：Azure OpenAI Service提供了一层额外的[内容过滤](https://oreil.ly/SzGoi)，以防止模型生成不适当或冒犯性的内容。在API级别，这意味着当内容被过滤时，响应可能包括`finish_reason
    = content_filter`。'
- en: '*Other AI content safety features:* These included [jailbreak detection (now
    called Prompt Shields)](https://oreil.ly/_J-J9), [protected material detection](https://oreil.ly/mbVoM),
    and [service abuse monitoring](https://oreil.ly/hIfnG). These advantages, plus
    the content filtering, help improve the quality and safety of applications that
    use Azure OpenAI Service.'
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*其他AI内容安全功能*：这些包括[越狱检测（现称为Prompt Shields）](https://oreil.ly/_J-J9)、[受保护材料检测](https://oreil.ly/mbVoM)和[服务滥用监控](https://oreil.ly/hIfnG)。这些优势加上内容过滤，有助于提高使用Azure
    OpenAI Service的应用的质量和安全。'
- en: '*Support and SLAs for reliability*: Azure OpenAI Service offers more comprehensive
    technical support and a [service level agreement (SLA)](https://oreil.ly/stFaz)
    that guarantees high availability of the service. This can provide more confidence
    and peace of mind to customers who use Azure OpenAI Service for their critical
    applications.'
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*支持和SLA的可靠性*：Azure OpenAI Service提供更全面的技术支持和一项[服务水平协议（SLA）](https://oreil.ly/stFaz)，保证服务的高可用性。这可以为使用Azure
    OpenAI Service进行关键应用的客户提供更多信心和安心。'
- en: '*Specific* [*Azure OpenAI product terms*](https://oreil.ly/9LTNj) with data,
    intended use, intellectual property, and other details. This documents relevant
    conditions and Microsoft commitments for enterprise-grade implementations.'
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*具体* [*Azure OpenAI产品条款*](https://oreil.ly/9LTNj) 包括数据、预期用途、知识产权和其他细节。这份文件记录了企业级实施的相关条件和Microsoft承诺。'
- en: Last but not least, Azure OpenAI includes custom data management options at
    both the data and prompt levels (which are equally considered private customer
    data), such as DELETE API operations, and the [option to opt out](https://oreil.ly/66UHN)
    of automated prompt monitoring and filtering for harmful topics.
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，Azure OpenAI在数据和提示级别都提供了定制数据管理选项（这些都被视为私人客户数据），例如DELETE API操作，以及[选择退出](https://oreil.ly/66UHN)自动提示监控和过滤有害主题的选项。
- en: Now, let’s continue with the last item of our generative AI operationalization
    topics, which focuses on existing and future regulations, as well as responsible
    AI practices for implementations with Azure OpenAI Service.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续我们生成式AI实施主题的最后一条，它侧重于现有和未来的法规，以及使用Azure OpenAI Service的实施中的负责任AI实践。
- en: Responsible AI and New Regulations
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 负责任AI和新法规
- en: One of the direct consequences of the new generative AI era was the general
    awareness from all society actors of the potential advantages and risks of artificial
    intelligence. The “AI Ethics” movements are not new, but they were mainly related
    to academics, AI observatories, and international associations trying to make
    sense of the principles that should guide what a “good AI” would be, as well as
    the potential negative outcomes of AI-enabled systems. Now, with the arrival of
    generative AI and ChatGPT, regulatory initiatives are accelerating and including
    new considerations for LLMs, etc. From a platform point of view, Azure OpenAI
    Service and Azure AI Studio have evolved and incorporated several responsible
    AI (RAI) measures.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 新的生成式AI时代的直接后果之一是，所有社会参与者都普遍认识到人工智能的潜在优势和风险。 “AI伦理”运动并非新鲜事物，但它们主要与学术界、AI观测站和国际协会有关，这些机构试图弄清楚应该指导“良好AI”的原则，以及AI赋能系统的潜在负面影响。现在，随着生成式AI和ChatGPT的到来，监管倡议正在加速，并包括对LLMs等的新考虑。从平台角度来看，Azure
    OpenAI Service和Azure AI Studio已经发展并纳入了多项负责任AI（RAI）措施。
- en: This section includes contextual information (e.g., international regulations)
    that will be important to keep in mind while designing generative AI solutions,
    plus several resources that facilitate the implementation of generative AI with
    responsible AI approaches, including several Microsoft resources for RAI and LLMs,
    including Azure OpenAI Service models.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包含在设计生成式AI解决方案时需要牢记的上下文信息（例如，国际法规），以及一些有助于以负责任AI方法实施生成式AI的资源，包括多个用于RAI和LLMs的Microsoft资源，例如Azure
    OpenAI Service模型。
- en: Relevant Regulatory Context for Generative AI Systems
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成式AI系统的相关监管环境
- en: 'Even if AI regulations are still a work-in-progress at the international level
    (at least in 2024), there are some key initiatives that will help you understand
    what regulators will be focusing on, especially for your generative AI development:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 即使AI法规在国际层面（至少在2024年）仍处于工作状态，也有一些关键举措将帮助您了解监管机构将关注什么，特别是对于您的生成式AI开发：
- en: The European Union (EU) AI Act
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 欧洲联盟（EU）的AI法案
- en: 'The first example of comprehensive [regulation for AI systems](https://oreil.ly/JGDQh),
    and a key reference for [other international regulations](https://oreil.ly/x0Hi6)
    (e.g., Canada’s AI and Data Act, China’s AI regulation). It is mainly based on
    several levels of risks, with specific obligations for both providers and adopters
    (in this case, Microsoft is the provider of your Azure OpenAI models, and you
    or your company are the adopters). It also includes *specific requirements for
    generative AI systems*. There are several levels of AI risk:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这是针对AI系统的全面[监管](https://oreil.ly/JGDQh)的第一个例子，也是[其他国际监管](https://oreil.ly/x0Hi6)（例如，加拿大的AI和数据法案、中国的AI法规）的关键参考。它主要基于几个风险级别，对提供者和采用者（在这种情况下，微软是您的Azure
    OpenAI模型的提供者，而您或您的公司是采用者）都有具体的义务。它还包括*对生成式AI系统的具体要求*。AI风险有几个级别：
- en: Unacceptable risk
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 不可接受的风险
- en: These are AI systems that pose a clear threat to people’s safety, dignity, or
    rights, such as those that manipulate human behavior, exploit vulnerabilities,
    or enable social scoring or mass surveillance. Some exceptions may be allowed
    for law enforcement purposes under strict conditions and oversight. Most of your
    applications will never be at this level, but it is important to be aware of the
    “forbidden” kind of systems.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是会对人们的安全、尊严或权利构成明确威胁的AI系统，例如那些操纵人类行为、利用漏洞或启用社会评分或大规模监控的系统。在严格条件和监督下，可能允许出于执法目的进行一些例外。大多数您的应用程序永远不会达到这个级别，但了解“禁止”类型的系统很重要。
- en: High-risk systems
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 高风险系统
- en: These are AI systems that have a significant impact on people’s lives or the
    functioning of society, such as those used in health, education, employment, justice,
    or transport. These systems will have to meet strict requirements before and after
    being deployed, such as ensuring data quality, human oversight, accuracy, security,
    and transparency. They will also have to be registered in an EU database.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是会对人们的生活或社会功能产生重大影响的AI系统，例如在健康、教育、就业、司法或交通中使用的系统。这些系统在部署前后都必须满足严格的要求，例如确保数据质量、人工监督、准确性、安全性和透明度。它们还必须在欧盟数据库中注册。
- en: Depending on your industry and area of activity, it will be important to align
    to this sort of requirement. In general, it will be a way to provide information
    about the details of the system, at both a performance and maintenance level.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的行业和活动领域，将此类要求对齐将很重要。一般来说，这将是一种提供有关系统细节的方法，无论是在性能层面还是在维护层面。
- en: Generative AI systems
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI系统
- en: 'These are specific requirements for generative AI systems, all of them relatively
    simple to implement with Azure and Azure OpenAI:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是针对生成式AI系统的具体要求，所有这些要求都相对简单，可以使用Azure和Azure OpenAI实现：
- en: Disclosing content that is generated by AI
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 揭示由AI生成的内容
- en: This can be easily achieved by providing a watermark for the generated content,
    at both the UI level and when the user copies answers from the Azure OpenAI–enabled
    tool.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过在UI层面和用户从Azure OpenAI启用的工具复制答案时提供水印来轻松实现。
- en: Designing the model to prevent it from generating illegal content
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 设计模型以防止其生成非法内容
- en: This is directly related to the ability to filter inputs and outputs to avoid
    any kind of negative content. We will deep dive into this later in this chapter.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这与过滤输入和输出以避免任何负面内容的能力直接相关。我们将在本章后面深入探讨这一点。
- en: Publishing summaries of copyrighted data used for training
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 发布用于训练的受版权保护数据的摘要
- en: This will include the initial provider obligations (directly related to the
    baseline LLM), and your obligations in the case of fine-tuning or grounding with
    other copyrighted data.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这将包括初始提供者的义务（直接与基线LLM相关），以及在使用其他受版权保护的数据进行微调或归一化时的义务。
- en: Limited-risk systems
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 低风险系统
- en: These are AI systems that pose little or no risk to people or society, such
    as those used for entertainment, leisure, or personal use. These systems will
    be mostly free from regulation, but will still have to comply with existing laws
    and ethical principles.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是风险极低或对个人或社会没有风险的AI系统，例如用于娱乐、休闲或个人使用的系统。这些系统将主要不受监管，但仍需遵守现有法律和伦理原则。
- en: The AI Risk Management Framework
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能风险管理框架
- en: From the National Institute of Standards and Technology (NIST) in the United
    States, [this framework](https://oreil.ly/o3Y12) is not an AI regulation per se,
    but it sets the field for a definition of what a trustworthy AI should be, including
    generative AI applications. The framework says that AI systems need to be valid
    and reliable, safe, secure and resilient, accountable and transparent, explainable
    and interpretable, privacy-enhanced, and fair with harmful bias managed. NIST
    has launched a specific [working group](https://oreil.ly/HRZ4D) for generative
    AI topics to catch up with latest developments. This framework is part of [Microsoft’s
    commitment](https://oreil.ly/T23SA) to adopt best practices in their products.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 来自美国国家标准与技术研究院（NIST）的[此框架](https://oreil.ly/o3Y12)本身不是AI法规，但它为可信AI的定义设定了领域，包括生成式AI应用。该框架指出，AI系统需要是有效和可靠的、安全的、有弹性的、可问责和透明的、可解释和可理解的、增强隐私的，并且公平地管理有害偏见。NIST已启动一个专门的[工作组](https://oreil.ly/HRZ4D)来关注生成式AI主题，以跟上最新发展。此框架是[微软对采用最佳实践的承诺](https://oreil.ly/T23SA)的一部分。
- en: Other generative AI development regulatory resources
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 其他生成式AI开发监管资源
- en: For example, the *Association for Computing Machinery (ACM)*’s [generative AI
    principles](https://oreil.ly/81nar) include considerations for generative AI models,
    including limits and usage, personal data, correctability, and system ownership
    questions.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，*计算机协会（ACM）*的[生成式AI原则](https://oreil.ly/81nar)包括对生成式AI模型（包括限制和用途、个人数据、可纠正性和系统所有权问题）的考虑。
- en: Meanwhile, the *Global Partnership on AI (GPAI)*’s 2023 report on [Detection
    Mechanisms for Foundation Models](https://oreil.ly/LZaot) focuses on the detection
    side of AI-generated content, and complements the transparency requirements of
    international regulations and frameworks. There is a similar initiative from the
    [Partnership on AI](https://oreil.ly/WAEgA) for generative AI and responsible
    practices for synthetic media.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，*全球人工智能伙伴关系（GPAI）*的2023年关于[基础模型检测机制](https://oreil.ly/LZaot)的报告侧重于AI生成内容的检测方面，并补充了国际法规和框架的透明度要求。来自[人工智能伙伴关系](https://oreil.ly/WAEgA)的类似倡议针对生成式AI和合成媒体的责任实践。
- en: This list of regulations, frameworks, and recommendations will continue evolving
    in upcoming years, but all of them converge and include transparency and accountability
    questions that should be considered when developing an Azure OpenAI system. For
    that purpose, the next two sections include organization- and technical-level
    resources that you can apply to your generative AI development.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这份法规、框架和建议清单将在未来几年持续演变，但它们都汇聚在一起，并包括在开发Azure OpenAI系统时应考虑的透明度和问责制问题。为此，接下来的两个部分包括组织和技术层面的资源，您可以将这些资源应用于您的生成式AI开发。
- en: Company-Level AI Governance Resources
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 公司级AI治理资源
- en: 'Microsoft has released a series of resources to guide the responsible implementation
    of AI systems, including generative AI, which can serve as baseline or inspiration
    to adapt generative AI development with Azure OpenAI to responsible approaches:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 微软发布了一系列资源，以指导AI系统（包括生成式AI）的负责任实施，这些资源可以作为基准或灵感，以将Azure OpenAI的生成式AI开发与负责任的方法相结合：
- en: Microsoft’s [Responsible AI Standard (version 2)](https://oreil.ly/fqvjp), which
    includes RAI principles, and a comprehensive document with [requirements to adopt
    those principles](https://oreil.ly/ACiW4). This is the approach used at Microsoft
    to achieve fairness, reliability and safety, privacy and security, inclusiveness,
    transparency, and accountability. These principles are highly related to the regulations
    and frameworks we have previously analyzed, so they represent a good baseline
    for your generative AI implementations for the enterprise. If you want an alternative
    version, also oriented to generative AI, here is a list of [RAI principles from
    LinkedIn](https://oreil.ly/cmghy).
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软的[负责任AI标准（版本2）](https://oreil.ly/fqvjp)，其中包括RAI原则，以及一个包含[采用这些原则的要求](https://oreil.ly/ACiW4)的全面文档。这是微软实现公平性、可靠性、安全性、隐私和安全、包容性、透明度和问责制的做法。这些原则与我们之前分析过的法规和框架高度相关，因此它们代表了您企业生成AI实现的良好基线。如果您想要一个替代版本，也面向生成AI，这里有一个[LinkedIn的RAI原则列表](https://oreil.ly/cmghy)。
- en: The [Responsible AI Maturity Model](https://oreil.ly/LV_Ei), a way to analyze
    and evaluate the level of responsible AI maturity at your company. It includes
    5 levels and 24 empirically derived dimensions. This is a good way to make sure
    we are setting the foundations for a generative AI aligned with future regulations.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[负责任AI成熟度模型](https://oreil.ly/LV_Ei)，一种分析和评估公司负责任AI成熟度水平的方法。它包括5个级别和24个经验推导的维度。这是确保我们为与未来法规一致的生成AI奠定基础的好方法。'
- en: 'Specific LLM and Azure OpenAI best practices and requirements to guarantee
    RAI approaches, including:'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保RAI方法的具体LLM和Azure OpenAI最佳实践和需求，包括：
- en: 'A *four-stage methodology for responsible AI and Azure OpenAI*, adapted from
    the general Microsoft RAI Standard, which [includes measures](https://oreil.ly/uJiId)
    to:'
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*负责任AI和Azure OpenAI的四阶段方法论*，改编自通用Microsoft RAI标准，其中[包括措施](https://oreil.ly/uJiId)来：
- en: '*Identify* and prioritize potential harms that could result from your AI system
    through iterative red teaming, stress testing, and analysis.'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过迭代红队、压力测试和分析来*识别*和优先考虑可能导致AI系统产生危害的潜在危害。
- en: '*Measure* the frequency and severity of those harms by establishing clear metrics,
    creating measurement test sets, and completing iterative, systematic testing (both
    manual and automated).'
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过建立明确的指标、创建测量测试集和完成迭代、系统的测试（手动和自动）来*测量*那些危害的频率和严重性。
- en: '*Mitigate* harm by implementing tools and strategies such as prompt engineering
    and content filters. Repeat measurement to test effectiveness after implementing
    mitigations.'
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过实施提示工程和内容过滤等工具和策略来*减轻*危害。在实施缓解措施后，重复测量以测试其有效性。
- en: '*Define and execute* a deployment and operational readiness plan.'
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*定义和执行*部署和运营准备计划。'
- en: An [*eight-step approach to responsible AI for LLMs*](https://oreil.ly/l3zSt),
    including Azure OpenAI and other open source options in Azure, such as Meta’s
    LLaMA2\. It focuses on risk mitigation, user-centric design, and additional safety
    measures.
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个[*针对LLM的八步负责任AI方法*](https://oreil.ly/l3zSt)，包括Azure OpenAI和其他Azure中的开源选项，如Meta的LLaMA2。它侧重于风险缓解、以用户为中心的设计和额外的安全措施。
- en: Specific *requirements for adopting Azure OpenAI*, which includes a [code of
    conduct with forbidden use cases](https://oreil.ly/PHCsq), including violence,
    exploitation, harmful content, etc. and a [transparency note with intended use
    cases](https://oreil.ly/nCF82) and adoption considerations.
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采用Azure OpenAI的具体*要求*，包括一个[行为准则，禁止使用案例](https://oreil.ly/PHCsq)，包括暴力、剥削、有害内容等，以及一个[透明度说明，说明预期用途](https://oreil.ly/nCF82)和采用考虑事项。
- en: The [HAX Toolkit](https://oreil.ly/XPSKw), which is a very good resource for
    your user-facing AI solutions, to support the design process and anticipate how
    the AI-enabled system will work and behave.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HAX工具包](https://oreil.ly/XPSKw)，这是一个非常好的资源，用于您的面向用户的AI解决方案，以支持设计过程并预测AI赋能系统的工作和行为。'
- en: Organizational-level measures will help you align with regulations and international
    requirements. However, the actual implementation of countermeasures at the model
    level requires technical RAI tools.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 组织层面的措施将帮助您与法规和国际要求保持一致。然而，在模型级别实施对策的实际实施需要技术RAI工具。
- en: Technical-Level Responsible AI Tools
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术级别的负责任AI工具
- en: 'These are the main tools and features you can use to guarantee that your Azure
    OpenAI implementations are aligned with RAI principles:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是您可以使用的主要工具和功能，以确保您的Azure OpenAI实现与RAI原则一致：
- en: The general RAI [Dashboard](https://oreil.ly/AP5-N) and [Toolbox](https://oreil.ly/Z8187),
    which Microsoft defines as the way to assess, develop, and deploy AI systems in
    a safe, trustworthy, and ethical manner, by using a collection of integrated tools
    and functionalities to help operationalize responsible AI in practice. The [official
    repository](https://oreil.ly/gnM8L) includes tools to evaluate errors, analyze
    fairness, understand data dimensions, interpret models, etc.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软定义的通用 RAI [仪表板](https://oreil.ly/AP5-N) 和 [工具箱](https://oreil.ly/Z8187)，它通过使用一系列集成工具和功能来评估、开发和部署
    AI 系统，以安全、值得信赖和道德的方式进行，以帮助在实践中实现负责任的 AI。[官方仓库](https://oreil.ly/gnM8L) 包括评估错误、分析公平性、理解数据维度、解释模型等工具。
- en: '*Azure AI Content Safety*, which adds an [extra layer of protection](https://oreil.ly/6LWOF)
    to filter out harmful inputs and outputs from the model. This can help prevent
    intentional abuse by your users and mistakes by the model. This safety system
    works by checking both the prompt and completion for your model with a group of
    classification models that aim to detect and stop the output of harmful content
    in four categories (hate, sexual, violence, and self-harm) and four severity levels
    (safe, low, medium, and high). The default setting is to filter content at the
    medium severity level for all four harm categories for both prompts and completions.
    You can access it:'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Azure AI 内容安全*，它为模型添加了一个额外的保护层（[额外保护层](https://oreil.ly/6LWOF)），以过滤掉模型的有害输入和输出。这可以帮助防止用户有意滥用和模型错误。这个安全系统通过使用一组旨在检测和阻止四个类别（仇恨、性、暴力和自残）和四个严重程度级别（安全、低、中、高）的有害内容输出的分类模型来检查您的模型的提示和完成。默认设置是过滤所有四个危害类别在提示和完成中的中等严重程度的内容。您可以访问它：'
- en: Directly from [AI Content Safety Studio](https://oreil.ly/C0iVp), which allows
    text, image, and multimodal moderation, as well as customization and online activity
    monitorization. It also includes Prompt Shields for your LLM-enabled deployments.
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接从 [AI 内容安全工作室](https://oreil.ly/C0iVp)，它允许文本、图像和多模态审查，以及定制和在线活动监控。它还包括为您的
    LLM 启用部署的提示盾牌。
- en: Via [Azure OpenAI Studio’s content filter](https://oreil.ly/9W9J9) for responsible
    AI moderation. Each filter can be applied to Azure OpenAI “deployments,” and those
    deployments will include the content filter for each chat or completion implementation.
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 [Azure OpenAI 工作室的内容过滤器](https://oreil.ly/9W9J9) 进行负责任的 AI 监管。每个过滤器都可以应用于
    Azure OpenAI “部署”，并且这些部署将包括每个聊天或完成实现的 内容过滤器。
- en: Conclusion
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This chapter covered the final set of technical considerations for generative
    AI applications with Azure OpenAI Service. You have explored all relevant operational
    questions related to deploying, securing, protecting, and responsibly adopting
    generative AI. Remember, designing and architecting solutions with Azure OpenAI
    is “just” the first step (as we discussed in Chapters [2](ch02.html#designing_cloud_native_architectures_for_generativ),
    [3](ch03.html#implementing_cloud_native_generative_ai_with_azure), and [4](ch04.html#additional_cloud_and_ai_capabilities)).
    The operationalization of these generative AI applications is key for company-level
    implementations, where security, performance, and privacy, as well as regulations
    and AI ethics, are key aspects for sustainable project implementations.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了使用 Azure OpenAI 服务进行生成式 AI 应用时的最后一组技术考虑因素。您已经探讨了与部署、安全、保护和负责任地采用生成式 AI
    相关的所有相关运营问题。请记住，使用 Azure OpenAI 设计和构建解决方案“只是”第一步（正如我们在第 [2](ch02.html#designing_cloud_native_architectures_for_generativ)、[3](ch03.html#implementing_cloud_native_generative_ai_with_azure)
    和 [4](ch04.html#additional_cloud_and_ai_capabilities) 章所讨论的）。这些生成式 AI 应用的运营化对于公司层面的实施至关重要，其中安全、性能、隐私，以及法规和
    AI 伦理都是可持续项目实施的关键方面。
- en: 'Now, we will continue with a key business-related aspect of generative AI:
    elaborating realistic and financially sustainable business cases. This means analyzing
    potential projects and their expected benefit and justifying the human and technical
    cost by discussing ROI (return on investment) scenarios. These aspects are as
    relevant as the technical details we’ve explored thus far to successfully implementing
    generative AI applications in your company.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将继续探讨生成式 AI 的一个关键业务相关方面：阐述现实且财务可持续的业务案例。这意味着分析潜在项目及其预期效益，并通过讨论投资回报率（ROI）场景来证明人力和技术的成本。这些方面与我们迄今为止探索的技术细节一样，对于在您的公司中成功实施生成式
    AI 应用至关重要。
