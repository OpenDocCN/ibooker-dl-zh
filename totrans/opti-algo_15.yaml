- en: 11 Supervised and unsupervised learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Reviewing the basics of artificial intelligence, machine learning, and deep
    learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding graph machine learning, graph embedding, and graph convolutional
    networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding attention mechanisms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding self-organizing maps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solving optimization problems using supervised and unsupervised machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artificial intelligence (AI) is one of the fastest growing fields of technology,
    driven by advancements in computing power, access to vast amounts of data, breakthroughs
    in algorithms, and increased investment from both public and private sectors.
    AI aims to create intelligent systems or machines that can exhibit intelligent
    behavior, often by mimicking or drawing inspiration from biological intelligence.
    These systems can be designed to function autonomously or with some human guidance,
    and ideally, they can adapt to environments with diverse structures, observability
    levels, and dynamics. AI augments our intelligence by empowering us to analyze
    vast amounts of multidimensional, multimodal data and identify hidden patterns
    that would be difficult for humans to recognize. AI also supports our learning
    and decision-making by providing relevant insights and potential courses of action.
    AI encompasses various subfields, such as situation awareness (comprising perception,
    comprehension, and projection), knowledge representation, cognitive reasoning,
    machine learning, data analytics (covering descriptive, diagnostic, predictive,
    and prescriptive analytics), problem solving (involving constraint satisfaction
    and problem-solving using search and optimization), as well as digital and physical
    automation (such as conversational AI and robotics).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this last part of the book, we will explore the convergence of two branches
    of AI: machine learning and optimization. Our focus will be on showcasing the
    practical applications of machine learning in tackling optimization problems.
    This chapter provides an overview of machine learning fundamentals as essential
    background knowledge, and then it delves into applications of supervised and unsupervised
    machine learning in handling optimization problems. Reinforcement learning will
    be covered in the next chapter.'
  prefs: []
  type: TYPE_NORMAL
- en: 11.1 A day in the life of AI-empowered daily routines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AI, and machine learning in particular, forms the foundation of many successful
    disruptive industries and has successfully delivered many commercial products
    that touch everybody’s life every day. Starting at home, voice assistants eagerly
    await your commands, effortlessly controlling smart appliances and adjusting the
    smart thermostat to ensure comfort and convenience. Smart meters intelligently
    manage energy consumption, optimizing efficiency and reducing costs.
  prefs: []
  type: TYPE_NORMAL
- en: On the route to school or work, navigation apps with location intelligence guide
    the way, considering real-time traffic updates to provide the fastest and most
    efficient route. Shared mobility services offer flexible transportation options
    on demand, while advanced driver assistance systems enhance safety and convenience
    if you decide to drive. In the not-too-distant future, we will enjoy safe and
    entertaining self-driving vehicles as a third living space, after our homes and
    workplaces, with consumer-centric products and services.
  prefs: []
  type: TYPE_NORMAL
- en: Once at school or at the workplace, AI becomes an invaluable tool for personalization
    and to boost productivity. Personalized learning platforms cater to individual
    needs, adapting teaching methods and content to maximize understanding and retention.
    Summarization and grammar-checking algorithms aid in crafting flawless documents,
    while translation tools bridge language barriers effortlessly. Excel AI formula
    generators streamline complex calculations, saving time and effort. Human-like
    text generation enables natural and coherent writing, while audio, image, and
    video generation from text unlock creative possibilities. Optimization algorithms
    ensure optimal resource allocation and scheduling, maximizing efficiency in various
    scenarios, and handle different design, planning, and control problems.
  prefs: []
  type: TYPE_NORMAL
- en: During shopping, AI enhances the experience in numerous ways. Voice search enables
    hands-free exploration, while searching by images allows for effortless discovery
    of desired items. Semantic search understands context and intent, providing more
    accurate results. Recommendation engines offer personalized suggestions based
    on individual preferences and online shopping behavior, while last-mile or door-to-door
    delivery services ensure timely, transparent, and convenient package arrival.
  prefs: []
  type: TYPE_NORMAL
- en: In the realm of health, AI revolutionizes personalized healthcare, assisting
    with diagnosis, treatment planning, and rehabilitation. Lab automation speeds
    up testing processes, improving accuracy and efficiency. AI-driven drug discovery
    and delivery enable the development of innovative treatments and targeted therapies,
    transforming lives.
  prefs: []
  type: TYPE_NORMAL
- en: During leisure time, AI contributes to physical and mental well-being. Fitness
    planning apps tailor workout routines to individual goals and capabilities, providing
    personalized guidance and motivation. Trip planning tools recommend exciting destinations
    and itineraries, ensuring memorable experiences. AI-powered meditation apps offer
    customized relaxation experiences, soothing the mind and promoting mindfulness.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning, a prominent subfield of artificial intelligence, has played
    a pivotal role in bringing AI from the confines of high-tech research labs to
    the convenience of our daily lives.
  prefs: []
  type: TYPE_NORMAL
- en: 11.2 Demystifying machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The goal of learning is to create an internal model or abstraction of the external
    world. More comprehensively, Stanislas Dehaene, in *How We Learn* [1], introduced
    seven key definitions of learning that lie at the heart of present-day machine
    learning algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: Learning is adjusting the parameters of a mental model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning is exploring a combinatorial explosion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning is minimizing errors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning is exploring the space of possibilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning is optimizing a reward function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning is restricting search space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning is projecting a priori hypotheses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Machine learning (ML) is a subfield of AI that endows an artificial system
    or process with the ability to learn from experience and observation without being
    explicitly programmed. Thomas Mitchell, in *Machine Learning*, defines ML as follows:
    “A computer program is said to learn from experience *E* with respect to some
    class of tasks *T* and performance measure *P*, if its performance at tasks in
    *T*, as measured by *P*, improves with experience *E*” [2]. In his book *The Master
    Algorithm*, Pedro Domingos summarizes the ML schools of thought into five main
    schools [3], illustrated in figure 11.1:'
  prefs: []
  type: TYPE_NORMAL
- en: Bayesians with probabilistic inference as the master algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Symbolists with rules and trees as the main core algorithm within this paradigm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Connectionists who use neural networks with backpropagation as a master algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evolutionaries who rely on the evolutionary computing paradigm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analogizers who use mathematical techniques like support vector machines with
    different kernels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F01_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 Different ML schools of thought according to Domingos’ *The Master
    Algorithm*
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, connectionist learning approaches have attracted most of the attention,
    thanks to their perception and learning capabilities in several challenging domains.
    These statistical ML algorithms follow a bottom-up inductive reasoning paradigm
    (i.e., inferring general rules from a set of examples) to discover patterns from
    vast amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: The unreasonable effectiveness of data
  prefs: []
  type: TYPE_NORMAL
- en: Simple models and a lot of data trump more elaborate models based on less data
    [4]. This means that having a large amount of data to train simple models is often
    more effective than using complex models with only a small amount of data. For
    example, in self-driving vehicles, a simple model that has been trained on millions
    of hours of driving data can often be more effective in recognizing and reacting
    to diverse road situations than a more complex model trained on a smaller dataset.
    This is because the massive amount of data helps the simple model learn a wide
    range of patterns and scenarios, including adversarial and edge cases it might
    encounter, making it more adaptable and reliable in real-world driving conditions.
  prefs: []
  type: TYPE_NORMAL
- en: These connectionist learning or statistical ML approaches are based on the experimental
    findings that even very complex problems in artificial intelligence may be solved
    by simple statistical models trained on massive datasets [4]. Statistical ML is
    currently the most famous form of AI. The rapid advancement of this form of ML
    can be attributed primarily to the widespread availability of big data and open
    source tools, enhanced computational power such as AI accelerators, and substantial
    research and development funding from both public and private sectors.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, ML algorithms can be categorized into supervised, unsupervised,
    hybrid learning, and reinforcement learning algorithms, as illustrated in figure
    11.2.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F02_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.2 ML taxonomy as a subfield of AI
  prefs: []
  type: TYPE_NORMAL
- en: '*Supervised learning*—This approach uses inductive inference to approximate
    mapping functions between data and known labels or classes. This mapping is learned
    using already labeled training data. *Classification* (predicting discrete or
    categorical values) and *regression* (predicting continuous values) are common
    tasks in supervised learning. For example, classification seeks a scoring function
    *f*:*Χ*×*C*⟶*R*, where *X* represents the training data space and *C* represents
    the label or class space. This mapping can be learned using *N* training examples
    of the form {(*x*[11], *x*[21], …, *x[m]*[1], *c*[1]), (*x*[12], *x*[22], …, *x[m]*[2],
    *c*[2]), …, (*x*[1]*[N], x*[2]*[N]*, …, *x[mN], c[N]*)}, where *x[i]* is the feature
    vector of the *i*-th example, *m* is number of features, and *c[i]* is the corresponding
    class. The predicted class is the class that gives the highest score of *f*, i.e.,
    *c*(*x*) = argmax*[c]f*(*x*,*c*). In the context of self-driving vehicles, supervised
    learning might be used to train a model to recognize traffic signs. The input
    data would be images of various traffic signs, and the correct output (the labels)
    would be the type of each sign. The trained model could then identify traffic
    signs correctly when driving. Feedforward neural networks (FNNs) or multilayer
    perceptrons (MLPs), convolutional neural networks (CNNs), recurrent neural networks
    (RNNs), long short-term memory (LSTM) networks, and sequence-to-sequence (Seq2Seq)
    models are examples of common neural network architectures that are typically
    trained using supervised learning. Examples of solving combinatorial problems
    using supervised ML are provided in sections 11.6, 11.7, and 11.9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Unsupervised learning*—This approach deals with unlabeled data through techniques
    like *clustering* and *dimensionality reduction*. In clustering, for example,
    *n* objects (each could be a vector of *d* features) are given, and the task is
    to group them based on certain similarity measures into *c* groups (clusters)
    in such a way that all objects in a single group have a “natural” relation to
    one another, and objects not in the same group are somehow different. For instance,
    unsupervised learning might be used in self-driving vehicles to cluster similar
    driving scenarios or environments. Using unsupervised learning, the car might
    learn to identify different types of intersections or roundabouts, even if no
    one has explicitly labeled the data with these categories. Autoencoders, k-means,
    density-based spatial clustering (DBSCAN), principal component analysis (PCA),
    and self- organizing maps (SOMs) are examples of unsupervised learning methods.
    SOM is explained in section 11.4\. An example of a combinatorial problem using
    SOM is provided in section 11.8\.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hybrid learning*—This approach includes *semi-supervised learning and self-supervised
    learning* techniques. Semi-supervised learning is a mix of supervised and unsupervised
    learning where only a fraction of the input data is labeled with corresponding
    outputs. In this case, the training process uses the small amount of labeled data
    available and pseudo-labels the rest of the dataset—for example, training a self-driving
    vehicle''s perception system with a limited set of labeled driving scenarios,
    then using a vast collection of unlabeled driving data to improve its ability
    to recognize and respond to various road conditions and obstacles. Self-supervised
    learning is an ML process where a model learns meaningful representations of the
    input data by using the inherent structure or relationships within the data itself.
    This is achieved by creating supervised learning tasks from the unlabeled data.
    For instance, a self-supervised model might be trained to predict the next word
    in a sentence based on the previous words or to reconstruct an image from a scrambled
    version. These learned representations can then be used for various downstream
    tasks, such as image classification or object detection. In the context of self-driving
    vehicles, a perception system can be trained to identify essential features in
    unlabeled driving scenes, such as lane markings, pedestrians, and other vehicles.
    Then, the learned features are utilized as pseudo-labels to classify new driving
    scenes in a supervised manner, enabling the vehicle to make decisions based on
    its understanding of the road environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Reinforcement learning (RL)*—This approach learns from interactions through
    a feedback loop or by trial and error. A learning agent learns to make decisions
    by taking actions in an environment to maximize some notion of cumulative reward.
    For self-driving vehicles, reinforcement learning could be used in the decision-making
    process. For instance, the car might learn over time the best way to merge into
    traffic on a busy highway. It would receive positive rewards for successful merges
    and negative rewards for dangerous maneuvers or failed attempts. Over time, through
    trial and error and the desire to maximize the reward, the car would learn an
    optimal policy for merging into traffic. More details about RL are provided in
    the next chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning (DL) is a subfield of ML concerned with learning underlying features
    in data using neural networks with many layers (hence “deep”) enabling artificial
    systems to build complex concepts out of simpler concepts. DL enables learning
    discriminative features or representations and learning at different levels of
    abstraction. To achieve this, the network uses hierarchical feature learning and
    employs a handful of convolutional layers. DL revolutionizes the field of ML by
    reducing the need for extensive data preprocessing. DL models can automatically
    extract highly discriminative features from raw data, eliminating the need for
    hand-crafted feature engineering. This end-to-end learning process significantly
    reduces the reliance on human experts, as the model learns to extract meaningful
    representations and patterns directly from the input data.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike traditional ML algorithms, DL models have the ability to directly consume
    and process various forms of structured and unstructured data, such as text, audio,
    images, video, and even graphs. Graph-structured data is particularly important
    in the field of combinatorial optimization due to its ability to capture and represent
    the relationships and constraints between elements in optimization problems. Geometric
    DL is a subfield of ML that combines graph theory with DL.
  prefs: []
  type: TYPE_NORMAL
- en: The following two sections address graph machine learning and self-organizing
    maps in more detail. They are essential background knowledge to the use cases
    described later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 11.3 Machine learning with graphs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As explained in section 3.1, a graph is a nonlinear data structure composed
    of entities known as *vertices* (or nodes) and the relationships between them,
    known as *edges* (or *arcs* or *links*). Data coming from different domains can
    be nicely captured using a graph. Social media networks, for instance, employ
    graphs to depict connections between users and to analyze social interactions,
    which in turn drive content propagation and recommendations. Navigation applications
    use graphs to represent physical locations and the paths between them, enabling
    route calculations, real-time traffic updates, and estimated time of arrival (ETA)
    predictions. Recommender systems rely on graphs to model user–item interactions
    and preferences, thereby offering personalized recommendations. Search engines
    use web graphs, where web pages are nodes and hyperlinks are edges, to crawl and
    index the internet and facilitate efficient information retrieval. Knowledge graphs
    offer a structured representation of factual information, relationships, and entities,
    and they’re used in diverse fields from digital assistants to enterprise data
    integration. Question-answering engines use graphs to understand and decompose
    complex questions and search for relevant answers in structured datasets. In the
    realm of chemistry, molecular structures can be viewed as graphs, where atoms
    are nodes and bonds are edges, supporting tasks like discovering compounds and
    predicting properties.
  prefs: []
  type: TYPE_NORMAL
- en: 'Graph-structured data is vital due to its power to model complex relationships
    and dependencies between entities in an intuitive, self-descriptive, intrinsically
    explainable, and natural way. Unlike traditional tabular data, graphs allow for
    the representation of networked relationships and complex interconnectedness between
    entities of interest, making them an excellent tool for modeling numerous real-world
    systems. Tabular data can be converted into graph-structured data—the specific
    definitions of nodes and edges would depend on what relationships you’re interested
    in examining within the data. For example, in the context of a FIFA dataset, we
    can define nodes and edges based on the information available in this dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Nodes*—Nodes represent entities of interest and could be the players, the
    clubs they play for, or their nationalities. Each of these entities could be a
    separate node in the graph. For example, Lionel Messi, Inter Miami, and Argentina
    could all be individual nodes in the graph.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Edges*—Edges represent the relationships between the nodes. For instance,
    an edge could connect a player to the club they play for, indicating that the
    player is part of that club. Another edge could connect a player to their nationality,
    showing that the player belongs to that country. So, for example, Lionel Messi
    could be connected to Inter Miami with an edge indicating that Messi plays for
    Inter Miami, and another edge could connect Lionel Messi to Argentina, indicating
    his nationality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next listing shows how to convert tabular data for 10 selected soccer players
    into a graph using NetworkX.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.1 Converting tabular data to a graph
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: As a continuation of listing 11.1, we can create a NetworkX graph whose nodes
    represent the player name, club, and nationality and whose edges represent the
    semantic relationships between these nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: ① Create a new graph.
  prefs: []
  type: TYPE_NORMAL
- en: ② Add nodes and edges for clubs.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Add nodes and edges for nationalities.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Create the layout
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Set the size of the figure.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Get lists of player, club, and nationality nodes.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Draw nodes in different colors.
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Draw edges.
  prefs: []
  type: TYPE_NORMAL
- en: ⑨ Draw edge labels.
  prefs: []
  type: TYPE_NORMAL
- en: ⑩ Draw node labels.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.3 shows the data for the 10 selected soccer players in a graph. This
    graph shows the entities of interest (player, club, and nationality) and their
    relationships. For example, L. Messi is a player who plays for Inter Miami and
    is from Argentina.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F03_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.3 Graph-structured data for 10 selected soccer players
  prefs: []
  type: TYPE_NORMAL
- en: Graph data fundamentally differs from Euclidean data, as the concept of distance
    is not simply a matter of straight-line (Euclidean) distance between two points.
    In the case of a graph, what matters is the structure of the nodes and edges—whether
    two nodes are connected by an edge and how they are connected to other nodes in
    the graph. Table 11.1 summarizes the differences between Euclidean and non-Euclidean
    graph data.
  prefs: []
  type: TYPE_NORMAL
- en: Table 11.1 Euclidean data versus non-Euclidean graph data
  prefs: []
  type: TYPE_NORMAL
- en: '| Aspects | Euclidean data | Non-Euclidean graph data |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Common data types | Numerical, text, audio, images, videos | Road networks,
    social networks, web pages, and molecular structures |'
  prefs: []
  type: TYPE_TB
- en: '| Dimensionality | Can be 1D (e.g., numbers, text), 2D (e.g., images, heatmaps),
    or higher-dimensional (e.g., RGB-D images or depth maps, 3D point cloud data)
    | Large dimensionality (e.g., a Pinterest graph has 3 billion nodes and 18 billion
    edges) |'
  prefs: []
  type: TYPE_TB
- en: '| Structure | Fixed structure (e.g., in the case of an image, the structure
    is embedded via pixel proximity) | Arbitrary structure (every node can have a
    different neural structure because the network neighborhood around it is different,
    as the model adapts to the data) |'
  prefs: []
  type: TYPE_TB
- en: '| Spatial locality | Yes (i.e., data points that are close together in the
    input space are also likely to be close together in the output space). | No, “closeness”
    is determined by the graph structure, not spatial arrangement (i.e., two nodes
    that are “close” to each other might not necessarily have similar properties or
    features, such as in the case of a traffic light node and a crosswalk node). |'
  prefs: []
  type: TYPE_TB
- en: '| Shift-invariance | Yes (i.e., data-inherent meaning is preserved when shifted;
    for instance, the concept of a cat in a picture does not change if the cat is
    in the top left corner or the bottom right corner of the image). | No (in a graph,
    there’s no inherent meaning to the “position” of a node that can be “shifted”).
    |'
  prefs: []
  type: TYPE_TB
- en: '| Ordinality or hierarchy | Yes | No, graph data has “permutation invariance”—the
    specific ordering or labeling of nodes doesn’t usually affect the underlying relationships
    and properties of the graph. |'
  prefs: []
  type: TYPE_TB
- en: '| Shortest path between two points | A straight line | Is not necessarily a
    straight line |'
  prefs: []
  type: TYPE_TB
- en: '| Examples of ML models | Convolutional neural networks (CNNs), long short-term
    memory (LSTM), and recurrent neural networks (RNNs) | Graph neural networks (GNNs),
    graph convolutional networks (GCNs), temporal graph networks (TGNs), spatial-temporal
    graph neural networks (STGNNs) |'
  prefs: []
  type: TYPE_TB
- en: '*Geometric deep learning* (GDL) is an umbrella term for emerging techniques
    seeking to extend (structured) deep neural models to handle non-Euclidean data
    with underlying geometric structures, such as graphs (networks of connected entities),
    point clouds (collections of 3D data points), molecules (chemical structures),
    and manifolds (curved, high-dimensional surfaces). Graph machine learning (GML)
    is a subfield of ML that focuses on developing algorithms and models capable of
    learning from graph-structured data. Graph embedding or representation learning
    is the first step in performing ML tasks such as node classification (predicting
    a category for each node), link prediction (forecasting connections between nodes),
    and community detection (identifying groups of interconnected nodes). The next
    subsection describes different graph embedding techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.1 Graph embedding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Graph embedding is a task that aims to learn a mapping from a discrete high-
    dimensional graph domain to a low-dimensional continuous domain. Through the process
    of graph embedding, graph nodes, edges, and their features are transformed into
    continuous vectors while preserving the structural information of the graph. For
    example, as shown in figure 11.4, an encoder, *ENC*(*v*), maps node *v* from the
    input graph space *G* to a low-dimensional vector *h[v]* in the embedding or latent
    space *H* based on the node’s position in the graph, its local neighborhood structure,
    or its features, or some combination of the three.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F04_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.4 Graph embedding
  prefs: []
  type: TYPE_NORMAL
- en: This encoder needs to be optimized to minimize the difference between the similarity
    of a pair of nodes in the graph and their similarity in the embedding space. Nodes
    that are connected or nearby in the graph should be close in the embedded space.
    Conversely, nodes that are not connected or are far apart in the graph should
    be far apart in the embedded space. In a more generalized encoder/decoder architecture,
    a decoder is added to extract user-specified information from the low-dimensional
    embedding [5]. By jointly optimizing the encoder and decoder, the system learns
    to compress information about the graph structure into the low-dimensional embedding
    space.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are various methods for graph embedding which can be broadly classified
    into transductive (shallow) embedding and inductive embedding:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Transductive embedding*—In the transductive learning paradigm, the model learns
    embeddings only for the nodes present in the graph during the training phase.
    The learned embeddings are specific to these nodes, and the model cannot generate
    embeddings for new nodes that weren’t present during training. These methods are
    difficult to scale and are suitable for static graphs. Examples of transductive
    methods for graph embedding include random walk (e.g., node2vec and DeepWalk)
    and matrix factorization (e.g., graph factorization and HOPE).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Inductive embedding*—Inductive learning methods can generalize to unseen nodes
    or entire graphs that were not present during training. They do this by learning
    a function that generates the embedding of a node based on its features and the
    structure of its local neighborhood, which can be applied to any node, regardless
    of whether it was present during training or not. These methods are suitable for
    evolving graphs. Examples of inductive methods for graph embedding are graph neural
    networks (GNN) and graph convolutional networks (GCNs).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A contains examples of some of these methods. For more information,
    see Broadwater and Stillman’s *Graph Neural Networks in Action* [6]. We’ll focus
    on GCN, as it is the most relevant approach to the combinatorial optimization
    application presented in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Transductive versus inductive learning
  prefs: []
  type: TYPE_NORMAL
- en: '*Transductive learning* aims to learn from a specific set of data to a specific
    set of predictions without generalizing to new data. *Inductive learning* aims
    to learn general rules from observed training cases. These general rules can then
    be applied to new, unseen data.'
  prefs: []
  type: TYPE_NORMAL
- en: The *convolution operation* forms the basis of representation learning in many
    structured data scenarios, enabling the automatic learning of meaningful features
    from raw data, thereby obviating the need for manual feature engineering. Convolution
    is a mathematical operation that takes two functions (input data and a kernel,
    filter, or feature detector) and measures their overlap or merges the two sets
    of information to produce a feature map. One critical aspect of convolution is
    its ability to respect and utilize the known structural relationships among data
    points, such as the positional associations among pixels, the temporal order of
    time points, or the edges linking nodes in a network. In traditional ML, convolutional
    neural networks (CNNs) employ the convolution operator as a key tool for identifying
    spatial patterns within images. This is made possible by the inherent grid-like
    structure of image data, which allows the model to slide filters over the image,
    exploit the spatial regularities, and extract features in a manner akin to pattern
    recognition.
  prefs: []
  type: TYPE_NORMAL
- en: However, in the realm of graph machine learning (GML), the situation changes
    considerably. The data in this context is non-Euclidean, as explained previously
    in table 11.1, meaning that it isn’t arranged on a regular grid like pixels are
    in an image or points are on a 3D surface. Instead, it’s represented in the form
    of a network or graph, which can capture complex relationships. Moreover, this
    data exhibits order invariance, implying that the output does not change with
    the rearrangement of nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike CNNs, which operate on a regular grid, GCNs are designed to work with
    data that’s structured as a graph, which can represent a wide variety of irregular
    and complex structures. Each node is connected to its neighbors without any predefined
    pattern, and the convolution operation is applied to a node and its direct neighbors
    in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: How does Google DeepMind predict the estimated time of arrival?
  prefs: []
  type: TYPE_NORMAL
- en: Have you ever wondered how Google Maps predicts the estimated time of arrival
    (ETA) when you’re planning your trip? Google DeepMind uses a GML approach to do
    so. The traditional ML approach would be to break the route down into a number
    of road segments, predict the time to traverse each road segment using a feedforward
    neural network, and sum them up to get the ETA. However, the underlying assumption
    of feedforward NN is that the road segments are independent of each other. In
    reality, road segment traffic easily influences the ETA of neighboring road segments,
    so the samples are not independent.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, consider the situation where congestion on a minor road influences
    the traffic flow on a main road. When the model encompasses multiple junctions,
    it naturally develops the capacity to predict slowdowns at intersections, delays
    due to converging traffic, and the total time taken in stop-and-go traffic conditions.
    A better approach is to use GML to take the influence of the neighboring road
    segments into consideration.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the road network will first be converted into a graph where each
    road segment is represented as a node. If two road segments are connected to each
    other, their corresponding nodes will be connected by an edge in the graph. Graph
    embedding is then generated by GNN to map the node features and graph structures
    from a high- dimensional discrete graph space to a low-dimensional continuous
    latent space. Information is propagated and aggregated across the graph through
    a technique called *message passing*, where, at the end, the embedding vector
    for each node contains and encodes its own information as well as the network
    information from all its neighboring nodes, according to the degree of neighborhood.
    Adjacent nodes pass messages to each other. In the first pass, each node knows
    about its neighbor. In the second pass, every node knows about its neighbor’s
    neighbors, and this information is encoded into the embedding, and so on. This
    allows us to represent the influence of the traffic in each of the neighboring
    road segments.
  prefs: []
  type: TYPE_NORMAL
- en: The accuracy of real time ETAs was improved by up to 50% in places like Berlin,
    Jakarta, São Paulo, Sydney, Tokyo, and Washington DC using this approach [7].
  prefs: []
  type: TYPE_NORMAL
- en: As illustrated in figure 11.5, given an input graph, which includes node features
    *x[v]* and an adjacency matrix *A*, a GCN transforms the features of each node
    into a latent or embedding space *H*, while preserving the graph structure denoted
    by the adjacency matrix *A*. These latent vectors provide a rich representation
    of each node, making it possible to perform node classification independently.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F05_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5 Graph embedding and node, link, and graph classification
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, GCNs are also capable of predicting characteristics related to edges,
    such as whether a link exists between two nodes. Once node embeddings are generated,
    the likelihood of an edge between two nodes *v* and *u* can be predicted based
    on their embeddings *h[v]*, *h[u]*. A common approach is to compute a similarity
    measure (e.g., a dot product) between the embeddings of two nodes. This similarity
    can then be passed through a sigmoid function to predict the probability of an
    edge. The errors (loss) on predictions will be backpropagated and update the weights
    in neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, GCNs enable classification at the level of the entire graph. This can
    be achieved by aggregating all the latent or embedding vectors (*H*) for all the
    nodes. The aggregation function used must be permutation invariant, meaning the
    output should remain the same regardless of the order of the nodes. Common examples
    of such functions are summation or averaging or maximizing. Once you’ve aggregated
    the latent vectors into a single representation, you can feed this representation
    into a module (e.g., a neural network layer) to predict an output for the whole
    graph. In essence, GCNs allow node-level, edge-level, and graph-level predictions.
  prefs: []
  type: TYPE_NORMAL
- en: To better understand how GCN works, let’s consider a graph with five nodes,
    as shown in figure 11.6\. For each node in the graph, the first step is to find
    the neighboring nodes. Let’s assume we want to examine how the embedding for node
    5 is generated. As you can see in the original graph (upper-left corner of figure
    11.6), nodes 2 and 4 are neighbors of node 5\. The second step is message-passing,
    which is the process of nodes sending, receiving, and aggregating messages from
    their neighbors to iteratively update their features. This allows GCNs to learn
    a representation for each node that captures both its own features and its context
    within the graph. The learned representations can then be used for downstream
    tasks like node classification, link prediction, or graph classification.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F06_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.6 Message passing and updating in GCN
  prefs: []
  type: TYPE_NORMAL
- en: The embedding of node *v* after *t* layers of neighborhood aggregation considering
    *N*(*v*) neighboring nodes is based on the formula shown in figure 11.7\. The
    initial 0^(th) layer embeddings *h[v]*⁰ are equal to node features x[v].
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F07_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.7 Embedding function in GCN
  prefs: []
  type: TYPE_NORMAL
- en: This formula is applied recursively to get another, better vector *h* at each
    time step, where *h* is the vector representation of the nodes in the latent space.
    The weight matrix is learned through training on given data. At the beginning,
    each node in the graph is aware only of its own initial features. In the first
    layer of the GCN, each node communicates with its immediate neighbors, aggregating
    its own features and receiving features from those neighbors. As we move to the
    second layer, each node again communicates with its neighbors. However, because
    the neighbors have already incorporated information from their own neighbors in
    the first layer, the original node now indirectly accesses information from two
    hops away in the graph—its neighbors’ neighbors. As this process repeats through
    more layers in the GCN, information is propagated and aggregated across the graph.
    At the end, the embedding vector for each node contains and encodes its own information
    as well as the network information from all its neighboring nodes according to
    the degree of neighborhood, or its *k*-hop neighborhood, to create context embedding.
    The *k-hop neighborhood*, or neighborhood of radius *k*, of a node is a set of
    neighboring nodes at a distance less than or equal to *k*.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.2 shows how to generate node embedding for the Cora dataset using
    GCN. The Cora dataset consists of 2,708 scientific publications classified into
    one of seven classes. The citation network consists of 5,429 links. Each publication
    in the dataset is described by a 0/1-valued word vector indicating the absence/presence
    of the corresponding word in the dictionary. The dictionary consists of 1,433
    unique words.
  prefs: []
  type: TYPE_NORMAL
- en: 'PyG (PyTorch Geometric) is used and can be installed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: More information about PyG CUDA installation is available in the PyG documentation
    ([https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html)).
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start by importing the libraries we’ll use.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.2 Node embedding using GCN
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'PyG provides several datasets that can be loaded directly, such as KarateClub,
    Cora, Amazon, Reddit, etc. The Cora dataset is part of the Planetoid dataset and
    can be loaded as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the following code, the GCN model is defined with two `GCNConv`
    layers (`GCNConv`) and a `torch.nn.Dropout` layer. `GCNConv` is a graph convolution
    layer, and `torch.nn.Dropout` is a dropout layer, which randomly zeroes some of
    the elements of the input tensor with probability 0.5 during training as a simple
    way to prevent overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `forward` function defines the forward pass of the model. It takes a data
    object as input, representing the graph, and the features of the nodes and the
    adjacency list of the graph are extracted from the input data. The node features
    (`x`) are passed through the first GCN layer `conv1`, a `relu` activation function,
    a dropout layer, and finally the second GCN layer `conv2`. The adjacency list,
    `edge_index`, is required for the convolution operation in the GCN layers. The
    output of the network is then returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As a continuation of listing 11.2, the following code snippet trains the GCN
    model on a single graph and extracts the node embedding from the trained model.
    The `model` is trained for 200 epochs. Its gradients are first zeroed, then the
    forward pass is computed, and the negative log-likelihood loss is calculated on
    the training nodes (those marked by `data.train_mask`). The backward pass is then
    computed to get the gradients, and the optimizer performs a step to update the
    model parameters. The model is set to evaluation mode and is run on the graph
    again to obtain the final node embeddings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: ① If CUDA is available, the code uses the GPU; otherwise, it will use the CPU.
  prefs: []
  type: TYPE_NORMAL
- en: ② Create an instance of the GCN model, and move it to the chosen device.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Load the first graph in the dataset, and move it to the device.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Use the Adam optimizer with a learning rate of 0.01 and weight decay (a form
    of regularization) of 0.0005.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Train the model for 200 epochs.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Set evaluation mode.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Obtain the final node embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: The `.detach()` function is used to detach the output from the computational
    graph and returns a new tensor that doesn’t require a gradient. The embeddings
    are then moved from the GPU (if they were on the GPU) to the CPU. This is done
    to make the data accessible for further processing, such as converting it to a
    NumPy array. The generated embedding has a size of (2708, 7), where the number
    of nodes is 2,708 and the number of classes or subjects is 7\. Dimensionality
    reduction using principle component analysis (PCA) is applied to visualize the
    embedding in 2D as shown in figure 11.8\.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F08_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.8 Node embedding using GCN in PyG
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the node embedding makes the nodes belonging to the same classes
    cluster together. This means increased discrimination power of the features, which
    results in more accurate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: The complete version of listing 11.2 available in the book’s GitHub repo also
    shows how to generate node embedding using the GCN available in StellarGraph.
    StellarGraph is a Python library for ML on graphs and networks.
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.2 Attention mechanisms
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As you saw in figure 11.7, the embedding function in GCN consists of message
    passing, aggregation, and update functions. The message passing function mainly
    integrates messages from the node’s neighbors based on a learnable weight matrix
    *W^t*. This weight matrix does not reflect the degree of importance of neighboring
    nodes. The convolution operation applies the same learned weights to all neighbors
    of a node as a linear transformation, without explicitly accounting for their
    importance or relevance. This might not be ideal because some segments may need
    more attention than others.
  prefs: []
  type: TYPE_NORMAL
- en: The concept of “attention” in DL essentially permits the model to selectively
    concentrate on specific segments of the input data as it produces the output sequence.
    This mechanism ensures that context is maintained and propagated from the initial
    stages to the end. It also allows the model to dynamically allocate its resources
    by focusing on the most important parts of the input at each time step. In a broad
    sense, attention in DL can be visualized as a vector consisting of importance
    or relevance scores. These scores help quantify the relationship or association
    between a node in a graph and all other nodes in the graph.
  prefs: []
  type: TYPE_NORMAL
- en: Attention is all you need
  prefs: []
  type: TYPE_NORMAL
- en: The groundbreaking paper “Attention Is All You Need” [8] proposes a new Transformer
    model for processing sequential data like text. In the world of language processing
    and translation, models usually read an entire sentence or document word by word,
    in order (like we do when we read a book), and then make predictions based on
    that. These models have some difficulties understanding long sentences and recalling
    information from far away in the text. In the case of long sequences, there is
    a high probability that the initial context will be lost by the end of the sequence.
    This is called the *forgetting problem*.
  prefs: []
  type: TYPE_NORMAL
- en: The authors of the paper propose a different way of handling this task. Instead
    of reading everything in order, their model focuses on different parts of the
    input at different times, almost like it’s jumping around the text. This is what
    they refer to as “attention.” The attention mechanism allows the model to dynamically
    prioritize which parts of the input are most relevant for each word it’s trying
    to predict, making it more effective at understanding context and reducing confusion
    arising from long sentences or complex phrases. For more details, see “The Annotated
    Transformer” [9].
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.9b shows a graph attention network (GAT), where a weighting factor
    or attention coefficient *α* is added to the embedding equation to reflect the
    importance of the neighboring nodes. GAT uses a weighted adjacency matrix instead
    of nonweighted adjacency matrix used in case of GCN (figure 11.9a). An attentional
    mechanism *a* is used to compute unnormalized coefficients *e[vu]* across pairs
    of nodes *v* and *u* based on their features:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F08_Khamis-EQ01.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 11.1 |'
  prefs: []
  type: TYPE_TB
- en: An example of this attentional mechanism can be dot-product attention that measures
    the similarity or alignment between the features of the two nodes, providing a
    quantitative indication of how much attention node *v* should give to node *u*.
    Other mechanisms may involve learned attention weights, nonlinear transformations,
    or more complex interactions between node features. Following the graph structure,
    node *v* can attend over nodes in its neighborhood only *i* ∈ *N[v]*.
  prefs: []
  type: TYPE_NORMAL
- en: Attention coefficients are typically normalized using the softmax function so
    that they are comparable, irrespective of the scale or distribution of raw scores
    in different neighborhoods or contexts. Note that in figure 11.9b, for simplicity,
    the attention coefficients *α[vu]* are denoted as *α[u]*.
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F08_Khamis-EQ02.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 11.2 |'
  prefs: []
  type: TYPE_TB
- en: '![](../Images/CH11_F09_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.9 Graph convolutional network (GCN) vs. graph attention network (GAT)
  prefs: []
  type: TYPE_NORMAL
- en: '*Multi-head attention* is a key component in GATs and also in the Transformer
    model discussed in the “Attention Is All You Need” paper. In a multi-head attention
    mechanism, the model has multiple sets of attention weights. Each set (or “head”)
    can learn to pay attention to different parts of the input. Instead of having
    just one focus of attention, the model can have multiple focuses, allowing it
    to capture different types of relationships and patterns in the data. In the context
    of GATs, a multi-head attention mechanism allows each node in the graph to focus
    on different neighboring nodes in different ways, as shown in figure 11.10.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F10_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 Multi-head attention with *H* = 3 heads by node 5\. *α*[52], *α*[54],
    and *α*[55] are the attention coefficients between the nodes. The aggregated features
    from each head are averaged to obtain the final embedding of the node.
  prefs: []
  type: TYPE_NORMAL
- en: Once the multiple heads have performed their respective attention operations,
    their results are typically averaged. This process condenses the diverse perspectives
    captured by the multiple attention heads into a single output. After the results
    of the multi-head attention operation are combined, a final nonlinearity is then
    applied. This step typically involves the use of a softmax function or logistic
    sigmoid function, especially in classification problems. These functions serve
    to translate the model’s final outputs into probabilities, making the output easier
    to interpret and more useful for prediction tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.3 Pointer networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sequential ML involves dealing with data where the order of observations matters,
    such as time series data, sentences, or permutations. Sequential ML tasks can
    be classified based on the number of inputs and outputs, as shown in table 11.2\.
    A *sequence-to- sequence* (seq2seq) model takes a sequence of items and outputs
    another sequence of items. Recurrent neural networks (RNN) and long short-term
    memory (LSTM) have been established as state-of-the-art approaches in seq2seq
    modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Table 11.2 Sequential ML
  prefs: []
  type: TYPE_NORMAL
- en: '| Task | Example |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| One-to-one | Image classification. We provide a single image as input, and
    the model outputs the classification or category, like “dog” or “cat,” as a single
    output. |'
  prefs: []
  type: TYPE_TB
- en: '| One-to-many | Image captioning. We input a single image into the model, and
    it generates a sequence of words describing that image. |'
  prefs: []
  type: TYPE_TB
- en: '| Many-to-one | Sentiment analysis. We input a sequence of words (like a sentence
    or a tweet), and the model outputs a single sentiment score (like “positive,"
    “negative,” or “neutral”). |'
  prefs: []
  type: TYPE_TB
- en: '| Many-to-many (type 1) | Sequence input and sequence output, like in the case
    of named entity recognition (NER). We input a sentence (a sequence of words),
    and the model outputs the recognized entity, such as a person, organization, location,
    etc. |'
  prefs: []
  type: TYPE_TB
- en: '| Many-to-many (type 2), known as a synchronized sequence model | Synced sequence
    input and output. The model takes a sequence of inputs but doesn’t output anything
    until the entire sequence has been read. Then it outputs a sequence. An example
    of this is video classification, where the model takes a sequence of video frames
    as input and then outputs a sequence of labels for those frames. |'
  prefs: []
  type: TYPE_TB
- en: In discrete combinatorial optimization problems like the travelling salesman
    problem, sorting tasks, or the convex hull problem, both the input and output
    data are sequential. However, traditional seq2seq models struggle to solve these
    problems effectively. This is primarily because the discrete categories of output
    elements are not predetermined. Instead, they are contingent on the variable size
    of the input (for instance, the output dictionary is dependent on the input length).
    The *pointer network* (Ptr-Net) model [10] addresses this problem by utilizing
    attention as a mechanism to point to or select a member of the input sequence
    for the output. This model not only enhances performance over the conventional
    seq2seq model equipped with input attention, but it also enables us to generalize
    to output dictionaries of variable sizes.
  prefs: []
  type: TYPE_NORMAL
- en: 'While traditional attention mechanisms distribute attention over the input
    sequence to generate an output element, Ptr-Net instead uses attention as a pointer.
    This pointer is used to select an element from the input sequence to be included
    in the output sequence. Let’s consider the convex hull problem as an example of
    a discrete combinatorial optimization problem. A convex hull is a geometric shape,
    specifically a polygon, that fully encompasses a given set of points. It achieves
    this by optimizing two distinct parameters: it maximizes the area that the shape
    covers, while simultaneously minimizing the boundary or circumference of the shape,
    as illustrated in figure 11.11\. To understand this concept, it can be useful
    to imagine stretching a rubber band around the extreme points or vertices of the
    set. When you release the rubber band, it automatically encompasses the entire
    set in the smallest perimeter possible, and this is essentially what a convex
    hull does.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F11_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11 The convex hull problem. a) A valid convex hull that encloses all
    points while maximizing the area and minimizing the circumference. Note that the
    number of points included in the output sequence of the polygon may be smaller
    than the number of given points. b) An invalid convex hull, as the circumference
    is not minimized. c) An invalid convex hull, as not all the points are enclosed.
  prefs: []
  type: TYPE_NORMAL
- en: Convex hulls have a multitude of applications across a variety of disciplines.
    For example, in the field of image recognition, convex hulls can help determine
    the shape and boundary of objects within an image. Similarly, in robotics, they
    can assist in obstacle detection and navigation by defining the “reachable” space
    around a robot.
  prefs: []
  type: TYPE_NORMAL
- en: The problem of finding or computing a convex hull, given a set of points, has
    been addressed through various algorithms. For example, the Graham scan algorithm
    sorts the points according to their angle with the point at the bottom of the
    hull and then processes them to find the convex hull [11]. The Jarvis march (or
    the gift wrapping algorithm) starts with the leftmost point and wraps the remaining
    points like wrapping a gift [12]. The quickhull algorithm finds the convex hull
    of a point set by recursively dividing the set into subsets, selecting the point
    farthest from the line between two extreme points, and eliminating points within
    the formed triangles until the hull’s vertices are identified [13].
  prefs: []
  type: TYPE_NORMAL
- en: As shown in figure 11.12, Ptr-Net takes as input a planar set of points *P*
    = {*P*[1], *P*[2], …, *P[n]*} with *n* elements each, where *P[j]* = (*x[j], y[j]*)
    are the Cartesian coordinates of the points. The outputs *C[P]* = {*C*[1], *C*[2],…,
    *C[m]*[(]*[P]*[)]} are sequences representing the solution associated with the
    point set *P*. In this figure, Ptr-Net estimates the output sequence [1 4 2] from
    the input data points [1 2 3 4]. This output sequence represents the convex hull
    that includes all the input points with maximum area and minimum circumference.
    As can be seen, the convex hull is formed by connecting *P*[1], *P*[2], and *P*[4].
    The third point *P*[3] is inside this convex hull.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F12_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.12 Pointer network (Prt-Net) estimating the output sequence [1 4 2]
    from the input data points [1 2 3 4]
  prefs: []
  type: TYPE_NORMAL
- en: 'Ptr-Net consists of three main components:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Encoder*—The encoder is a recurrent neural network (RNN), often implemented
    with long short-term memory (LSTM) units or gated recurrent units (GRUs). The
    encoder’s purpose is to process the input sequence, converting each input element
    into a corresponding hidden state. These hidden states (*e*[1],…, *e*[n]) encapsulate
    the context-dependent representation of the elements in the input sequence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Decoder*—Like the encoder, the decoder is also an RNN. It’s responsible for
    generating the output sequence (*d*[1],…, *d*[m]). For each output step, it takes
    the previous output and its own hidden state as inputs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Attention mechanism (pointer)*—The attention mechanism in a Ptr-Net operates
    as a pointer. It computes a distribution over the hidden states output by the
    encoder, indicating where to “point” in the input sequence for each output step.
    Essentially, it decides which of the inputs should be the next output. The attention
    mechanism is a softmax function over the learned attention scores, which gives
    a probability distribution over the input sequence, signifying the likeliness
    of each element being pointed at.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The attention vector at each output time *i* is computed using the following
    equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F12_Khamis-EQ03.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 11.3 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F12_Khamis-EQ04.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 11.4 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F12_Khamis-EQ05.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 11.5 |'
  prefs: []
  type: TYPE_TB
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '*u[j]* is the attention vector or alignment score that represents the similarity
    between the decoder and encoder hidden states. *v, W*[1], and *W*[2] are learnable
    parameters of the model. If the same hidden dimensionality is used for the encoder
    and decoder (typically 512), *v* is a vector, and *W*[1] and *W*[2] are square
    matrices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*a[j]* is the attention mask over the input or weights computed by applying
    the softmax operation to the alignment scores.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*d[i]*^’ is the context vector that is fed into the decoder at each time step.
    In other words, *d[i]* and *d[i]*^’ are concatenated and used as the hidden states
    from which the predictions are made. This weighted sum of all the encoder hidden
    states allows the decoder to flexibly focus the attention on the most relevant
    parts of the input sequence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ptr-Net can process variable-length sequences and solve complex combinatorial
    problems, especially those involving sorting or ordering tasks, where the output
    is a permutation of the input, as you will see in section 11.9.
  prefs: []
  type: TYPE_NORMAL
- en: 11.4 Self-organizing maps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *self-organizing map* (SOM), also known as a *self-organizing feature map*
    (SOFM) or *Kohonen map*, is a type of artificial neural network (ANN) that is
    trained with unsupervised learning to produce a low-dimensional (typically two-dimensional),
    discretized representation of the input space of the training samples, called
    a *map*. SOMs are distinguished from traditional ANNs by the nature of their learning
    process, known as *competitive learning*. In such algorithms, processing elements
    or neurons compete for the right to respond to a subset of the input data. The
    degree to which an output neuron is activated is amplified as the similarity between
    the neuron’s weight vector and the input grows. The similarity between the weight
    vector and the input, leading to neuron activation, is commonly gauged through
    the calculation of Euclidean distance. The output unit that demonstrates the highest
    level of activation, or equivalently the shortest distance, in response to a specific
    input is deemed the best matching unit (BMU) or the “winning” neuron, as illustrated
    in figure 11.13\. This winner is then drawn incrementally closer to the input
    data point by adjusting its weight.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F13_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.13 Self-organizing map (SOM) with a Gaussian neighborhood function
  prefs: []
  type: TYPE_NORMAL
- en: 'A key characteristic of SOM is the concept of a *neighborhood function*, which
    ensures that not only the winning neuron but also its neighbors learn from each
    new input, creating clusters of similar data. This allows the network to preserve
    the topological properties of the input space. Equation 11.6 shows an example
    of a neighborhood function:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F13_Khamis-EQ06.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 11.6 |'
  prefs: []
  type: TYPE_TB
- en: where *v* is the index of the node in the map, *u* is the index of the winning
    neuron, *LDist*(*u,v*) represents the lattice distance between *u* and *v*, and
    *σ* is the bandwidth of the Gaussian kernel. In SOMs, *σ* represents the radius
    or width of the neighborhood and determines how far the influence of the winning
    neuron extends to its neighbors during the weight update phase. A large *σ* means
    a broader neighborhood is affected. On the other hand, a small *σ* means that
    fewer neighboring neurons are influenced. When *σ* is set to an extremely small
    value, the neighborhood effectively shrinks to include only the winning neuron
    itself. This means that only the winning neuron’s weights are significantly updated
    in response to the input, while the weights of the other neurons are barely or
    not at all affected. This behavior, where only the winning neuron is updated,
    is referred to as “winner take all” learning.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 11.1 shows the steps of SOM, assuming that *D[t]* is a target input
    data vector, *W[v]* is the current weight vector of node *v, θ*(*u*,*v*,*s*) is
    the neighborhood function that represents the restraint due to the distance from
    the winning neuron, and *α* is a learning rate where *α* ∈ (0,1).
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 11.1 Self-organizing map (SOM)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: SOMs were initially used as a dimensionality reduction method for data visualization
    and clustering tasks. For example, the neural phonetic typewriter was one of the
    early applications of Kohonen’s SOM algorithm. It was a system where spoken phonemes
    (the smallest unit of speech that can distinguish one word from another) were
    recognized and converted into symbols. When someone spoke into the system, the
    SOM would classify the input phoneme and type the corresponding symbol. SOMs can
    be applied to different problems such as feature extraction, adaptive control,
    and travelling salesman problems (see section 11.8).
  prefs: []
  type: TYPE_NORMAL
- en: SOMs offer a significant advantage in that they preserve the relative distances
    between points as calculated within the input space. Points that are close in
    the input space are mapped onto neighboring units within the SOM, making SOMs
    effective tools for analyzing clusters within high-dimensional data. When using
    techniques like principal component analysis (PCA) to handle high-dimensional
    data, data loss may occur when reducing the dimensions to two. If the data contains
    numerous dimensions and if each dimension carries valuable information, then SOMs
    can be superior to PCA for dimensionality reduction purposes. Beyond this, SOMs
    also possess the ability to generalize. Through this process, the network can
    identify or categorize input data that it has not previously encountered. This
    new input is associated with a specific unit on the map and is thus mapped accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: The previous sections have offered a fundamental foundation in ML, equipping
    you with essential background knowledge. The upcoming sections will delve deeply
    into the practical applications of supervised and unsupervised ML in tackling
    optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: 11.5 Machine learning for optimization problems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The utilization of ML techniques to tackle combinatorial optimization problems
    represents an emergent and exciting field of study. *Neural combinatorial optimization*
    refers to the application of ML and neural network models, specifically seq2seq
    supervised models, unsupervised models, and reinforcement learning, to solve combinatorial
    optimization problems. Within this context, the application of ML to combinatorial
    optimization has been comprehensively described by Yoshua Bengio and his co-authors
    [14]. The authors depict three distinctive methods for harnessing ML for combinatorial
    optimization (see figure 11.14):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F14_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.14 Machine learning (ML) for combinatorial optimization (CO) problems
  prefs: []
  type: TYPE_NORMAL
- en: '*End-to-end learning*—To use ML to address optimization problems, we need to
    instruct the ML model to formulate solutions directly from the input instance.
    An example of this approach is Ptr-Net, which is trained on *m* points and validated
    on *n* points for a Euclidean planar symmetric TSP [10]. Examples of solving combinatorial
    optimization problems using end-to-end learning are provided in sections 11.6,
    11.7, and 11.9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Learning to configure algorithms*—The second method involves applying an ML
    model to enhance a combinatorial optimization algorithm with pertinent information.
    In this regard, ML can offer a parameterization of the algorithm. Examples of
    such parameters comprise, but are not restricted to, learning rate or step size
    in gradient descent methodologies; initial temperature or cooling schedule in
    simulated annealing; standard deviation of Gaussian mutation or selective crossover
    in genetic algorithms; inertia weight or cognitive and social acceleration coefficients
    in particle swarm optimization (PSO); or rate of evaporation, influence of pheromone
    deposition, or influence of the desirability of state transition in ant colony
    optimization (ACO).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ML in conjunction with optimization algorithms*—The third method calls for
    a combinatorial optimization algorithm to repetitively consult the same ML model
    for decision-making purposes. The ML model accepts as input the current state
    of the algorithm, which could encompass the problem definition. The fundamental
    distinction between this approach and the other two lies in the repeated utilization
    of the same ML model by the combinatorial optimization algorithm to make identical
    kinds of decisions, approximately as many times as the total number of iterations
    of the algorithm. An example of this approach is DL-assisted heuristic tree search
    (DLTS), which consists of a heuristic tree search in which decisions about which
    branches to explore and how to bound nodes are made by deep neural networks (DNNs)
    [15].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Another intriguing research paper by Vesselinova et al. delves into some pertinent
    questions concerning the intersection of ML and combinatorial optimization [16].
    Specifically, the paper investigates the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Can ML techniques be utilized to automate the process of learning heuristics
    for combinatorial optimization tasks and, as a result, solve these problems more
    efficiently?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What essential ML methods have been employed to tackle these real-world problems?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How applicable are these methods to practical domains?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This paper offers a thorough survey of various applications of supervised and
    reinforcement learning strategies in tackling optimization problems. The authors
    analyze these learning approaches by examining their application to a range of
    optimization problems:'
  prefs: []
  type: TYPE_NORMAL
- en: The knapsack problem (KP), where the goal is to maximize the total value of
    items chosen without exceeding the capacity of the knapsack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximal clique (MC) and maximal independent set (MIS) problems, which both
    involve identifying subsets of a graph with specific properties
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum coverage problem (MCP), which requires selecting a subset of items
    to maximize coverage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum cut (MaxCut) and minimum vertex cover (MVC) problems, which involve
    partitioning a graph in particular ways
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, the paper discusses the application of ML approaches to the satisfiability
    problem (SAT), which is a decision problem involving Boolean logic; the classic
    TSP, which requires finding the shortest possible route that visits a given set
    of cities and returns to the origin city; and the vehicular routing problem (VRP),
    which is a generalized version of TSP where multiple “salesmen” (vehicles) are
    allowed. More information about benchmark optimization problems is provided in
    appendix B.
  prefs: []
  type: TYPE_NORMAL
- en: Optimization by prompting (OPRO) is described in Chengrun et al.’s “Large Language
    Models as Optimizers” article as a simple and effective approach to using large
    language models (LLMs) as optimizers, where the optimization task is described
    in natural language [17]. Additional examples showcasing the use of ML in addressing
    optimization problems can be accessed through the AI for Smart Mobility publication
    hub ([https://medium.com/ai4sm](https://medium.com/ai4sm)). To stimulate further
    exploration and draw more researchers into this emerging domain, a competition
    named Machine Learning for Combinatorial Optimization (ML4CO) was organized as
    part of the Neural Information Processing Systems (NeurIPS) conference. The competition
    posed a unique proposition for participants, requiring them to devise ML models
    or algorithms targeted at resolving three separate challenges. Each of these challenges
    mirrors a specific control task that commonly emerges in conventional optimization
    solvers. This competition provides a platform where researchers can explore and
    test novel ML strategies, contributing to the advancement of the field of combinatorial
    optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 11.6 Solving function optimization using supervised machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Amortized optimization*, or *learning to optimize*, is an approach where ML
    models are used to rapidly predict the solutions to an optimization problem. Amortized
    optimization methods try to learn the mapping between the decision variable space
    and the optimal or near-optimal solution space. The learned model can be used
    to predict the optimal value of an objective function, enabling fast solvers.
    The computation cost of the optimization process is spread out between learning
    and inferencing. This is the reason for the name “amortized optimization,” as
    the word “amortization” generally refers to spreading out costs.'
  prefs: []
  type: TYPE_NORMAL
- en: B. Amos shows several examples of how to use amortized optimization to solve
    optimization problems in his tutorial [18]. For example, a supervised ML approach
    can learn to solve optimization problems over spheres. Here the objective is to
    find the extreme values of a function defined on the earth or other space that
    can be approximated with a sphere of the form
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F14_Khamis-EQ07.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 11.7 |'
  prefs: []
  type: TYPE_TB
- en: 'where *S*² is the surface of the unit 2-sphere embedded in real-number space
    *R*³ as *S*²:= {*y* ∈ *R*³ | ||*y*||[2] =1}, and *x* is some parameterization
    of the function *f* : *S*² × *X* → *R*. ||*y*||[2] refers to the Euclidean norm
    (also known as the *L2 norm* or *2-norm*) of a vector *y*. More details about
    the amortization objective function are available in Amos’s “Tutorial on amortized
    optimization for learning to optimize over continuous domains” [18].'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.3 shows the steps for applying amortized optimization based on supervised
    learning to solve the problem of finding the extreme values of a function defined
    on the earth or other spaces. We’ll start by defining two conversion functions,
    `celestial_to_euclidean()` and `euclidean_to_celestial()`, that convert between
    celestial coordinates (right ascension, `ra`, and declination, `dec`) and Euclidean
    coordinates (`x, y, z`).
  prefs: []
  type: TYPE_NORMAL
- en: The celestial coordinate system
  prefs: []
  type: TYPE_NORMAL
- en: The *astronomical* or *celestial coordinate system* is a reference system used
    to specify the positions of objects in the sky, such as satellites, stars, planets,
    galaxies, and other celestial bodies. There are several celestial coordinate systems,
    with the most common being the equatorial system. In the equatorial system, right
    ascension (RA) and declination (Dec) are the two numbers used to fix the location
    of an object in the sky. These coordinates are analogous to the latitude and longitude
    used in earth’s geographic coordinate system.
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the following figure, RA is measured in hours, minutes, and seconds
    (h:m:s), and it is analogous to longitude in earth’s coordinate system. RA is
    the angular distance of an object measured eastward along the celestial equator
    from the vernal equinox (the point where the sun crosses the celestial equator
    during the March equinox). The celestial equator is an imaginary great circle
    on the celestial sphere, lying in the same plane as earth’s equator. Dec is measured
    in degrees and represents the angular distance of an object north or south of
    the celestial equator. It is analogous to latitude in earth’s coordinate system.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F14_UN01_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Celestial coordinate system with an example point with a right ascension of
    10 hours and a declination of 30 degrees
  prefs: []
  type: TYPE_NORMAL
- en: Positive declination is used for objects above the celestial equator, and negative
    declination is used for objects below the celestial equator.
  prefs: []
  type: TYPE_NORMAL
- en: The `sphere_dist(x, y)` function calculates the Riemannian distance (the great-
    circle distance) between two points on the sphere in the Euclidean space. This
    distance represents the shortest (geodesic) path between two points on the surface
    of a sphere, measured along the surface rather than through the interior of the
    sphere. The function asserts that the input vectors are two-dimensional. Then
    it calculates the dot product of *x* and *y* and returns the arccosine of the
    result, which corresponds to the angle between *x* and *y*.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.3 Solving a function optimization problem using supervised learning
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: ① Convert from celestial coordinates to Euclidean coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: ② Convert from Euclidean coordinates to celestial coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Calculate the Riemannian distance between two points on the sphere.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then define a `c-convex` class as a subclass of `nn.Module`, which makes
    it a trainable model in PyTorch. Cohen and his co-authors defined *c-convex* in
    their “Riemannian convex potential maps” article as a synthetic class of optimization
    problems defined on the sphere [19]. The `c-convex` class models a c-convex function
    on the sphere with `n_components` components that we can sample data from for
    training. The `gamma` parameter controls the aggregation of the components of
    the function, and `seed` is used to initialize the random number generator for
    reproducibility. It also generates random parameters `ys` (which are unit vectors
    in the 3D space) and `alphas` (which are scalars between 0 and 0.7) for each component
    of the c-convex function. The parameters are concatenated into a single `params`
    vector. The `forward(xyz)` method calculates the value of the c-convex function
    at the point `xyz`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: ① Define a c-convex function.
  prefs: []
  type: TYPE_NORMAL
- en: ② Sample random parameters.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Computes the output of the c-convex function given input coordinates xyz on
    the sphere.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a continuation of the preceding code, we define an amortized model, which
    takes a parameter vector as input and outputs a 3D vector representing a point
    on the sphere. The amortized model uses a neural network to learn a mapping from
    the parameter space to the 3D space of points on the sphere. The code also initializes
    a list of `c_convex` objects with different seeds and sets the number of parameters
    for the amortized model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: ① Create a list of integers representing different seeds.
  prefs: []
  type: TYPE_NORMAL
- en: ② Create an fs list that contains different instances of the c_convex class.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Set the number of parameters in the first c_convex object (fs[0]).
  prefs: []
  type: TYPE_NORMAL
- en: 'The amortized model is represented as `nn.Module` in the following code. The
    neural network is defined as a feedforward neural network or a multilayer perceptron
    that consists of three fully connected (linear) layers with ReLU activation functions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: ① Number of parameters in the c-convex function that will be used as input to
    the neural network
  prefs: []
  type: TYPE_NORMAL
- en: ② Define the layers of the neural network in sequence.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Define the forward pass of the amortized model, which maps the input p (parameter
    vector) to a point on the sphere.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now train the amortized model to learn a mapping from parameter vectors
    to points on the sphere. It uses a list of c_convex functions (fs) with different
    random seeds to generate training data. The amortized model is trained using an
    Adam optimizer, and its progress is visualized using a tqdm progress bar. The
    resulting output points on the sphere are stored in a tensor xs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: ① Set the number of hidden units for the AmortizedModel neural network.
  prefs: []
  type: TYPE_NORMAL
- en: ② Set the random seed to ensure the reproducibility of the training process.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Create an instance of the AmortizedModel.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Create an Adam optimizer to update the parameters with a learning rate of
    0.0005.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Store the output points on the sphere for each iteration of training.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Training loop
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Store the losses for each c_convex function and the corresponding output points
    on the sphere (xis).
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Iterate over each c_convex function (f) in the list fs.
  prefs: []
  type: TYPE_NORMAL
- en: 'After training is complete, all the predicted output points on the sphere are
    stacked along a new dimension, resulting in a tensor `xs` with the following shape:
    number of iterations, number of `c_convex` functions, 3\. Each element in this
    tensor represents a point on the sphere predicted by the amortized model at different
    stages of training. It generates a visual representation of the training progress
    for the amortized model and `c_convex` functions, as shown in figure 11.15.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F15_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.15 Examples of output from the trained amortized model
  prefs: []
  type: TYPE_NORMAL
- en: The complete version of listing 11.3 is available in the book’s GitHub repo.
    It creates a grid of celestial coordinates, evaluates the `c_convex` functions
    and the amortized model on this grid, and then plots contour maps of the functions,
    the predicted paths, and the optimal points on the sphere. The optimal points
    are the points that give minimum loss, given that supervised learning is used
    to train the amortized model.
  prefs: []
  type: TYPE_NORMAL
- en: 11.7 Solving TSP using supervised graph machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Joshi, Laurent, and Bresson, in their “Graph Neural Networks for the Travelling
    Salesman Problem” article [20], proposed a generic end-to-end pipeline to tackle
    combinatorial optimization problems such as the traveling salesman problem (TSP),
    vehicle routing problem (VRP), satisfiability problem (SAT), maximum cut (MaxCut),
    and maximal independent set (MIS). Figure 11.16 shows the steps of solving TSP
    using ML.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F16_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.16 End-to-end pipeline for combinatorial optimization problems
  prefs: []
  type: TYPE_NORMAL
- en: Following this approach, we start by defining the graph problem in the form
    of node features and an adjacency matrix between the nodes. A low-dimensional
    graph embedding is then generated using GNN or GCN, based on the message-passing
    approach. The probability of nodes or edges belonging to the solution is predicted
    using multilayer perceptrons (MLPs). A graph search, such as beam search (see
    chapter 4), is then applied to search the graph with the probability distribution
    over the edge to find a feasible candidate solution. Learning by imitation (supervised
    learning) and learning by exploration (reinforcement learning) are applied. Supervised
    learning minimizes the loss between optimal solutions (obtained by a well-known
    solver such as Concorde in the case of TSP) and the model’s prediction. The reinforcement
    learning approach uses a policy gradient to minimize the length of the tour predicted
    by the model at the end of decoding. Reinforcement learning is discussed in the
    next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Training an ML model from scratch and applying it to solve TSP requires a substantial
    amount of code and data preprocessing. Listing 11.4 shows how you can use the
    pretrained models to solve different instances of TSP. We start by importing the
    libraries and modules we’ll use. These libraries provide functionality for handling
    data, performing computations, visualization, and optimization. The Gurobi library
    is used to eliminate subtours during optimization and to calculate the reduce
    costs for a set of points (see appendix A). We set the `CUDA_DEVICE_ORDER` and
    `CUDA_VISIBLE_DEVICES` environment variables to control the GPU device visibility.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.4 Solving TSP using supervised ML
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'As a continuation, the following `opts` class contains several class-level
    attributes that define the following options and configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '`dataset path`—The TSP dataset available in the book’s GitHub repo.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch size`—This determines the number of TSP instances (problems) processed
    simultaneously during training or evaluation. It specifies how many TSP instances
    are grouped together and processed in parallel.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`number of samples`—This is the number of samples per TSP size.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`neighbors`—This is used in the TSP data processing pipeline to specify the
    proportion (percentage) of nearest neighbors to consider for graph sparsification.
    It controls the connectivity of the TSP graph by selecting a subset of the nearest
    neighbors for each node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`knn strategy`—This is the strategy used to determine the number of nearest
    neighbors when performing graph sparsification. In the code, the `''percentage''`
    value indicates that the number of nearest neighbors is determined by the `neighbors`
    parameter, which specifies the percentage of neighbors to consider.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model`—This is the path for the pretrained ML model. The model used is a pretrained
    GNN model available in the book’s GitHub repo.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_cuda`—This checks if CUDA is available on the system. CUDA is a parallel
    computing platform and programming model that allows for efficient execution of
    computations on NVIDIA GPUs. `torch.cuda.is_available()` returns a Boolean value
    (true or false) indicating whether CUDA is available or not. If CUDA is available,
    that means a compatible NVIDIA GPU is present on the system and can be utilized
    for accelerated computations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`device`—This is the device to be used for computations:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to create a dataset object using the TSP class with the following
    parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`filename`—The path or filename of the dataset to be used, specified by `opts
    .dataset_path`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size`—The number of samples to include in each batch, specified by `opts.batch_size`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_samples`—The total number of samples to include in the dataset, specified
    by `opts.num_samples`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`neighbors`—The value representing the number of nearest neighbors for graph
    sparsification, specified by `opts.neighbors`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`knn_strat`—The strategy for selecting nearest neighbors (`''percentage''`
    or `None`), specified by `opts.knn_strat`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`supervised`—A Boolean value indicating whether the dataset is used for supervised
    learning, set to `True`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The `make_dataset` method creates an instance of the TSP dataset class and
    initializes it with the provided arguments, returning the `dataset` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The following line creates a data loader object that enables convenient iteration
    over the dataset in batches, which is useful for processing the data during evaluation.
    The `dataset` object created in the previous line will be used as the source of
    the data. You can provide other optional arguments to customize the behavior of
    the data loader, such as `shuffle` (to shuffle the data) and `num_workers` (to
    specify the number of worker processes for data loading):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now load the trained model and assign it to the `model` variable. If
    the model is wrapped in `torch.nn.DataParallel`, it extracts the underlying module
    by accessing `model.module`. `DataParallel` is a PyTorch wrapper that allows for
    parallel execution of models on multiple GPUs. If the model is indeed an instance
    of `DataParallel`, it extracts the underlying model module by accessing the `module`
    attribute. This step is necessary to ensure consistent behavior when accessing
    model attributes and methods. The decode type of the model is then set to `"greedy"`.
    This means that during inference or evaluation, the model should use a greedy
    decoding strategy to generate output predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: ① Load a pretrained model.
  prefs: []
  type: TYPE_NORMAL
- en: ② Extract the underlying module.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Set the decoding type of the model to "greedy".
  prefs: []
  type: TYPE_NORMAL
- en: ④ Set the model’s mode to evaluation
  prefs: []
  type: TYPE_NORMAL
- en: The complete version of listing 11.4, including the visualization code, is available
    in the book’s GitHub repo. Figure 11.17 shows the output produced by the pretrained
    ML model for the TSP50 instance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F17_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.17 The TSP50 solution using a pretrained ML model
  prefs: []
  type: TYPE_NORMAL
- en: 'The figure shows the following seven plots related to the TSP instance and
    the model’s predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Concorde*—The plot in the upper-left corner shows the ground truth solution
    generated by the Concorde solver, which is an efficient implementation of the
    branch-and-cut algorithm for solving TSP instances to optimality. It shows the
    nodes of the TSP problem as circles connected by edges, representing the optimal
    tour calculated by Concorde. The title of the plot indicates the length (cost)
    of the tour obtained from Concorde.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*1 - (Reduce Costs)*—The second plot contains the shortest subtour and shows
    the reduced costs for the points in these subtours using the Gurobi optimization
    library. It displays the edges of the TSP as red lines, with the edge color indicating
    the reduced cost value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Prediction Heatmap*—The third plot presents a heatmap visualization of the
    model’s predictions for the TSP problem. It uses a color scale to represent the
    prediction probabilities of edges, with higher probabilities shown in darker shades.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Greedy Solution*—The fourth plot illustrates the solution generated by the
    ML model using a greedy decoding strategy. It displays the nodes of the TSP problem
    connected by edges, representing the tour obtained from the model. The title of
    the plot shows the length (cost) of the tour calculated by the model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Euclidean Distance (norm by max)*—The lower-left plot is a heatmap visualization
    of the Euclidean distances between nodes in the TSP problem. It uses a color scale
    to represent the distances, with lighter shades indicating smaller distances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Reduce Costs*—The lower-middle plot is a heatmap representation of the reduced
    costs of edges in the TSP problem. It shows the reduced costs as a color scale,
    with lower values displayed in lighter shades.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*1 - (Model Predictions)*—The lower-right plot presents a heatmap visualization
    of the model’s predictions for the TSP problem, similar to the third plot. However,
    in this case, the heatmap displays “1 - (Model Predictions)” by subtracting the
    model’s prediction probabilities from 1\. Darker shades represent lower probabilities,
    indicating stronger confidence in the edge selection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This example demonstrated how we can employ a pretrained GNN model for solving
    TSP. Figure 11.17 displays the model’s solution alongside the Concorde TSP solver’s
    results for a TSP instance comprising 50 points of interest. More information
    and complete code, including model training steps, are available in “Learning
    the Travelling Salesperson Problem Requires Rethinking Generalization” GitHub
    repo [21].
  prefs: []
  type: TYPE_NORMAL
- en: 11.8 Solving TSP using unsupervised machine learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As an example of an unsupervised ML approach, listing 11.5 shows how we can
    solve TSP using self-organizing maps (SOMs). We start by importing the libraries
    we’ll use. Some helper functions are imported from the som-tsp implementation
    described in Vicente’s blog post [22] to read the TSP instance, get the neighborhood,
    get the route, select the closest candidate, and calculate the route distance
    and plot the route. We read the TSP instance from the provided URL and obtain
    the cities and normalize their coordinates to a range of [0, 1].
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.5 Solving TSP using unsupervised learning
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: ① Define the URL where the TSP instances are located.
  prefs: []
  type: TYPE_NORMAL
- en: ② TSP instance
  prefs: []
  type: TYPE_NORMAL
- en: ③ Download the file if it does not exist.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Read the TSP problem.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Obtain the normalized set of cities (with coordinates in [0,1]).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now set up various parameters and initialize a network of neurons for
    the SOM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: ① The population size is 8 times the number of cities.
  prefs: []
  type: TYPE_NORMAL
- en: ② Set the number of iterations.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Set the learning rate.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Generate an adequate network of neurons.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a continuation, the following code snippet implements the training loop
    for SOM. This loop iterates over the specified number of training iterations using
    `tqdm` to show a progress bar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: ① Store the lengths of the TSP routes during the SOM training iterations.
  prefs: []
  type: TYPE_NORMAL
- en: ② Store the x and y coordinates of the neurons in the network during the training
    iterations.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Training loop
  prefs: []
  type: TYPE_NORMAL
- en: ④ Print only if the current iteration index is a multiple of 100.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Choose a random city.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Find the index of the neuron (winner) in the SOM network that is closest to
    the randomly chosen city.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Generate a filter that applies changes to the winner’s gaussian.
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Update the network’s weights.
  prefs: []
  type: TYPE_NORMAL
- en: ⑨ Append the current coordinates to the paths.
  prefs: []
  type: TYPE_NORMAL
- en: ⑩ Decay the learning rate and the neighborhood radius n at each iteration to
    gradually reduce the influence of the Gaussian filter over time.
  prefs: []
  type: TYPE_NORMAL
- en: ⑪ Check for the plotting interval.
  prefs: []
  type: TYPE_NORMAL
- en: ⑫ Check if any parameter has completely decayed.
  prefs: []
  type: TYPE_NORMAL
- en: ⑬ Calculate distance, and store it in the route_lengths list.
  prefs: []
  type: TYPE_NORMAL
- en: ⑭ Indicate that the specified number of training iterations has been completed.
  prefs: []
  type: TYPE_NORMAL
- en: The following code snippet plots the route length in each iteration.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Figure 11.18 shows the route length per iteration. The final route length is
    9,816, and the optimal length for the Qatar TSP instance used, `qa194.tsp`, is
    9,352\.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F18_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.18 Route length per iteration of SOM for the Qatar TSP. The final
    route length is 9,816, and the optimal solution is 9,352.
  prefs: []
  type: TYPE_NORMAL
- en: The complete version of listing 11.5 is available in the book’s GitHub repo,
    and it contains an implementation based on MiniSom. MiniSom is a minimalistic
    and Numpy-based implementation of SOM. You can install this library using `!pip
    install minisom`. However, the route obtained by MiniSom is 11,844.47, which is
    far from the optimal length of 9,352 for this TSP instance. To improve the result,
    you can experiment with the provided code and try to tune SOM parameters such
    as the number of neurons, the sigma, the learning rate, and the number of iterations.
  prefs: []
  type: TYPE_NORMAL
- en: 11.9 Finding a convex hull
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Ptr-Net can be used to tackle the convex hull problem using a supervised learning
    approach, as described by Vinyals and his co-authors in their “Pointer networks”
    article [10]. Ptr-Net has two key components: an encoder and a decoder, as illustrated
    in figure 11.19\.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F19_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.19 Solving the convex hull problem using Ptr-Net. The output in each
    step is a pointer to the input that maximizes the probability distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The encoder, a recurrent neural network (RNN), converts the raw input sequence.
    In this case, it coordinates delineating the points for which we want to determine
    the convex hull into a more manageable representation.
  prefs: []
  type: TYPE_NORMAL
- en: This encoded vector is then passed on to the decoder. The vector acts as the
    modulator for a content-based attention mechanism, which is applied over the inputs.
    The content-based attention mechanism can be likened to a spotlight that highlights
    different segments of the input data at varying times, focusing on the most pertinent
    parts of the task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: The output of this attention mechanism is a softmax distribution with a dictionary
    size equal to the length of the input. This softmax distribution gives probabilities
    to every point in the input sequence. This setup allows Ptr-Net to probabilistically
    decide at each step which point should be added next to the convex hull. This
    is determined based on the current state of the input and the network’s internal
    state. The training process is repeated until the network has made a decision
    for every point, yielding a complete resolution to the convex hull problem.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.6 shows the steps for solving convex hull problem using pointer networks.
    We start by importing several necessary libraries and modules, such as torch,
    numpy, and matplotlib. The three helper classes `Data`, `ptr_net`, and `Disp`
    are imported based on the implementations provided in McGough’s “Pointer Networks
    with Transformers” article [23]. They contain functions for generating training
    and validation data, defining the pointer network architecture, and visualizing
    the results. This code generates two datasets for training and validation respectively.
    These datasets consist of random 2D points, where the number of points in each
    sample (the convex hull problem’s input) varies between `min_samples` and `max_samples`.
    `Scatter2DDataset` is a custom dataset class used to generate these random 2D
    point datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 11.6 Solving a convex hull problem using pointer networks
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this code generates 100,000 training points and 1,000 validation points.
    We can then set the parameters of the pointer network. These parameters include
    a `TOKENS` dictionary containing the following tokens:'
  prefs: []
  type: TYPE_NORMAL
- en: '`<eos>`—End-of-sequence token with the index 0'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`c_inputs`—Number of input features for the model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`c_embed`—Number of embedding dimensions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`c_hidden`—Number of hidden units in the model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_heads`—Number of attention heads in the multi-head self-attention mechanism'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_layers`—Number of layers in the model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dropout`—Dropout probability, which is used for regularization'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_cuda`—A Boolean flag indicating whether to use CUDA (GPU) if available
    or CPU'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_workers`—Number of worker threads for data loading in DataLoader'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The training parameters include `n_epochs` (number of training epochs), `batch_size`
    (batch size used during training), `lr` (learning rate for the optimizer), and
    `log_interval` (interval for logging training progress). The code checks if CUDA
    (GPU) is available and sets the `device` variable accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'As a continuation, we load the training and validation data with the specified
    `batch_size` and `num_workers`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ConvexNet` model is a Ptr-Net model that is implemented as a transformer
    architecture with an encoder and decoder that use `nn.TransformerEncoderLayer`
    and apply multi-head self-attention. The complete code is available in the `ptr_net.py`
    class, available in the book’s GitHub repo. This model is initialized with the
    predefined hyperparameters. The `AverageMeter` class is used for keeping track
    of the average loss and accuracy during training and validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: ① Create a ConvexNet model.
  prefs: []
  type: TYPE_NORMAL
- en: ② Use the Adam optimizer for training the model.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Use negative log-likelihood loss as the loss function.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Keep track of the average loss and accuracy during training and validation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now perform the training and evaluation loop for a model (`ConvexNet`)
    using PyTorch. The model is being trained on the `train_loader` dataset with known
    labels and evaluated on the `val_loader` dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: ① Train the model.
  prefs: []
  type: TYPE_NORMAL
- en: ② Iterate over batches of training data.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Set the model’s parameters’ gradients to zero to avoid accumulation from previous
    batches.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Calculate the loss
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ A safeguard check to ensure that the loss value during the training process
    is not a NaN.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Perform a backward pass and optimization step.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Update training loss and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Print the training progress.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a continuation, the trained model (model) is evaluated on a validation dataset
    (val_dataset) to calculate the validation loss, accuracy, and overlap between
    the convex hull of the input data and the predicted pointer sequences. We start
    by setting the model to evaluation mode, where the model’s parameters are frozen
    and the batch normalization or dropout layers behave differently than during training.
    The code then iterates through the validation dataset using the val_loader, which
    provides batches of data (batch_data), ground truth labels (batch_labels), and
    the lengths of each sequence (batch_lengths):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: ① Set the model to evaluation mode.
  prefs: []
  type: TYPE_NORMAL
- en: ② Initialize an empty list to store the overlap values between the convex hull
    of the input data and the predicted pointer sequences.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Iterate through the validation dataset.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Produce pointer scores and argmax predictions.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Calculate the validation loss.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Update the validation loss.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Ignore the loss contribution from positions where the <eos> token is present
    in batch_labels.
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Calculate the masked accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: ⑨ Update the validation accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: ⑩ Iterate through each batch’s data, lengths, and pointer argmax predictions.
  prefs: []
  type: TYPE_NORMAL
- en: ⑪ Calculate the overlap between the convex hull of the input data and the predicted
    pointer sequences.
  prefs: []
  type: TYPE_NORMAL
- en: ⑫ Print the epoch-wise validation loss, accuracy, and mean overlap.
  prefs: []
  type: TYPE_NORMAL
- en: ⑬ Reset the metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can display the results of training and validation losses and accuracies
    using the `Disp_results` helper function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding line of code will generate output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'After model training and validation, we can test the model. The following test
    function will evaluate a trained model (`model`) on a test dataset. The function
    evaluates the model’s accuracy and overlap with the convex hull for different
    test sample sizes. This test function takes as inputs the model, the number of
    test samples, and the number of points per sample. The code performs the test
    for different numbers of points per sample (`i`) by iterating from 5 to 45 in
    steps of 5\. The `AverageMeter` class is used to keep track of average loss and
    accuracy during testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: ① Set the number of test samples to be generated for each test.
  prefs: []
  type: TYPE_NORMAL
- en: ② Test function
  prefs: []
  type: TYPE_NORMAL
- en: ③ Generate the test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Iterate through the batches of test data.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Track the loss and accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Update the overlap between the convex hull and predicted pointer sequences.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Print the accuracy and overlap.
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Iterate and print results for different sample sizes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code will produce output like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s now test the trained model and see how well this model generalizes to
    new unseen data. We’ll use a dataset with 50 points to test the trained and validated
    model and calculate the convex hull overlap between the predicted hull and the
    ground truth hull obtained by SciPy. We pass the batch of input data and its lengths
    through the model to obtain the predicted scores (`log_pointer_scores`) and the
    argmax indices (`pointer_argmaxs`) of the pointer network. The ground truth is
    the convex hull obtained using the `ConvexHull` function from `scipy.spatial`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: ① Set the number of points in each sample.
  prefs: []
  type: TYPE_NORMAL
- en: ② Create a test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Load the first batch of data from the test dataset.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Obtain the predicted scores and the argmax indices of the pointer network.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Extract the predicted argmax indices for the selected sample from the batch.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Filter out the special tokens (e.g., <eos>) and adjust the indices for indexing
    the points correctly.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Extract and print the 2D points for the selected sample from the batch.
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Ground truth convex hull
  prefs: []
  type: TYPE_NORMAL
- en: ⑨ Calculate the convex hull overlap.
  prefs: []
  type: TYPE_NORMAL
- en: ⑩ Print the list of predicted convex hull indices, convex hull indices, and
    overlap percentage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the code will produce output like the following. You can run the preceding
    code snippets multiple times to get a high percentage of hull overlap:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code snippet can be used to visualize the convex hull generated
    by the pointer network (`ConvexNet`) in comparison with the convex hull generated
    by `scipy.spatial` as a ground truth:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: ① Set the default figure size, and create the first subplot.
  prefs: []
  type: TYPE_NORMAL
- en: ② Compute the convex hull of a set of points (points) using the ConvexHull function
    from scipy.spatial.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Display the points and their convex hull in the first subplot.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Create a second subplot.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Display the points and the convex hull generated by ConvexNet.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 11.20 shows the convex hulls generated by SciPy and ConvexNet. These
    convex hulls are identical in some instances (i.e., hull overlap = 100.00%), yet
    achieving this consistency requires proper training and careful tuning of the
    ConvexNet parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F20_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.20 Convex hulls generated by SciPy and Ptr-Net for 50 points
  prefs: []
  type: TYPE_NORMAL
- en: This chapter has offered a fundamental foundation in ML and discussed the applications
    of supervised and unsupervised ML in handling optimization problems. The next
    chapter will focus on reinforcement learning and will delve deeply into its practical
    applications in tackling optimization problems.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machine learning (ML), a branch of artificial intelligence (AI), grants an artificial
    system or process the capacity to learn from experiences and observations, rather
    than through explicit programming.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning (DL) is a subset of ML that is focused on the detection of inherent
    features within data by employing deep neural networks. This allows artificial
    systems to form intricate concepts from simpler ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geometric deep learning (GDL) extends (structured) deep neural models to handle
    non-Euclidean data with underlying geometric structures, such as graphs, point
    clouds, and manifolds.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graph machine learning (GML) is a subfield of ML that focuses on developing
    algorithms and models capable of learning from graph-structured data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graph embedding represents the process of creating a conversion from the discrete,
    high-dimensional graph domain to a lower-dimensional continuous domain.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The attention mechanism allows a model to selectively focus on certain portions
    of the input data while it is in the process of generating the output sequence.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The pointer network (Ptr-Net) is a variation of the sequence-to-sequence model
    with attention designed to deal with variable-sized input data sequences.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A self-organizing map (SOM), also known as a Kohonen map, is a type of artificial
    neural network (ANN) used for unsupervised learning. SOMs differ from other types
    of ANNs, as they apply competitive learning rather than error-correction learning
    (such as backpropagation with gradient descent).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural combinatorial optimization refers to the application of ML to solve combinatorial
    optimization problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Harnessing ML for combinatorial optimization can be achieved through three
    main methods: end-to-end learning where the model directly formulates solutions,
    using ML to configure and improve optimization algorithms, and integrating ML
    with optimization algorithms where the model continuously guides the optimization
    algorithm based on its current state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
