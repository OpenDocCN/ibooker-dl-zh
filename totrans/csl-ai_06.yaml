- en: 5 Connecting causality and deep learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 连接因果性和深度学习
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Incorporating deep learning into a causal graphical model
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将深度学习融入因果图模型
- en: Training a causal graphical model with a variational autoencoder
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用变分自动编码器训练因果图模型
- en: Using causal methods to enhance machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用因果方法来增强机器学习
- en: 'The title of this book is *Causal AI*, but how exactly does causality connect
    to AI? More specifically, how does causality connect with deep learning, the dominant
    paradigm in AI? In this chapter, I look at this question from two perspectives:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的标题是《因果AI》，但因果性究竟是如何与AI联系起来的？更具体地说，因果性是如何与深度学习联系起来的，深度学习是AI的主导范式？在本章中，我从两个角度来探讨这个问题：
- en: '*How to incorporate deep learning into a causal model*—We’ll look at a causal
    model of a computer vision problem (section 5.1) and then train the deep causal
    image model (section 5.2).'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如何将深度学习融入因果模型*——我们将研究一个计算机视觉问题的因果模型（第5.1节），然后训练深度因果图像模型（第5.2节）。'
- en: '*How to use causal reasoning to do better deep learning*—We’ll look at a case
    study on independence of mechanism and semi-supervised learning (section 5.3.1
    and 5.3.2), and we’ll demystify deep learning with causality (section 5.3.3).'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如何利用因果推理进行更好的深度学习*——我们将研究关于机制独立性和半监督学习的案例研究（第5.3.1节和5.3.2节），并使用因果性来揭示深度学习的神秘面纱（第5.3.3节）。'
- en: The term *deep learning* broadly refers to applications of deep neural networks.
    It’s a machine learning approach that stacks many nonlinear models together in
    sequential layers, emulating the connections of neurons in brains. “Deep” refers
    to stacking many layers to achieve more modeling power, particularly in terms
    of modeling high-dimensional and nonlinear data, such as visual media and natural
    language text. Neural nets have been around for a while, but relatively recent
    advancements in hardware and automatic differentiation have made it possible to
    scale deep neural networks to extremely large sizes. That scaling is why, in recent
    years, there have been multiple cases of deep learning outperforming humans on
    many advanced inference and decision-making tasks, such as image recognition,
    natural language processing, game playing, medical diagnosis, autonomous driving,
    and generating lifelike text, images, and video.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: “深度学习”一词广泛指代深度神经网络的运用。这是一种机器学习方法，通过在序列层中堆叠许多非线性模型，模拟大脑中神经元的连接。“深度”指的是堆叠许多层以实现更强的建模能力，尤其是在建模高维和非线性数据方面，如视觉媒体和自然语言文本。“深度”一词指的是堆叠许多层以达到更强的建模能力，尤其是在建模高维和非线性数据方面，如视觉媒体和自然语言文本。神经网络已经存在了一段时间，但相对较近的硬件和自动微分技术的进步使得深度神经网络可以扩展到极其大的规模。正是这种扩展使得近年来，深度学习在许多高级推理和决策任务上超越了人类，例如图像识别、自然语言处理、游戏、医疗诊断、自动驾驶以及生成逼真的文本、图像和视频。
- en: But asking how deep learning connects to causality can elicit frustrating answers.
    AI company CEOs and leaders in big tech fuel hype about the power of deep learning
    models and even claim they can learn the causal structure of the world. On the
    other hand, some leading researchers claim these models are merely “stochastic
    parrots” that can echo patterns of correlation that, while nuanced and complex,
    still fall short of true causal understanding.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 但询问深度学习如何与因果性联系起来可能会得到令人沮丧的答案。AI公司的首席执行官和大型科技公司的领导者们炒作深度学习模型的力量，甚至声称它们可以学习世界的因果结构。另一方面，一些领先的研究人员声称这些模型仅仅是“随机鹦鹉”，它们可以回声相关模式，尽管这些模式细微而复杂，但仍然不足以达到真正的因果理解。
- en: Our goal in this chapter is to reconcile these perspectives. But skipping ahead,
    the main takeaway is that deep learning architecture can be integrated into a
    causal model and we can train the model using deep learning training techniques.
    But also, we can use causal reasoning to build better deep learning models and
    improve how we train them.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是调和这些观点。但跳过前面的内容，主要的收获是深度学习架构可以集成到因果模型中，我们可以使用深度学习训练技术来训练模型。但不仅如此，我们还可以使用因果推理来构建更好的深度学习模型，并改进我们的训练方法。
- en: 'We’ll anchor this idea in two case studies:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过两个案例研究来巩固这一想法：
- en: Building a causal DAG for computer vision using a variational autoencoder
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用变分自动编码器为计算机视觉构建因果DAG
- en: Implementing better semi-supervised learning using independence of mechanism
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用机制独立性实现更好的半监督学习
- en: Other examples of the interplay of causality and AI that you’ll see in the rest
    of the book will build on the intuition we get from these case studies. For example,
    chapter 9 will illustrate counterfactual reasoning using a variational autoencoder
    like the one we’ll build in this chapter. In chapter 11, we’ll explore machine
    learning and probabilistic deep learning approaches for causal effect inference.
    Chapter 13 will show how to combine large language models and causal reasoning.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的其余部分，你将看到的因果与AI相互作用的其他示例将建立在我们从这些案例研究中获得的直觉之上。例如，第9章将使用本章我们将构建的变分自动编码器来展示反事实推理。在第11章中，我们将探讨因果效应推断的机器学习和概率深度学习方法。第13章将展示如何结合大型语言模型和因果推理。
- en: We’ll start by considering how to incorporate deep learning into a causal model.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先考虑如何将深度学习融入因果模型中。
- en: 5.1 A causal model of a computer vision problem
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 计算机视觉问题的因果模型
- en: Let’s look at a computer vision problem that we can approach with a causal DAG.
    Recall the MNIST data from chapter 1, composed of images of digits and their labels,
    illustrated in figure 5.1.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们可以用因果DAG来处理的一个计算机视觉问题。回忆一下第1章中的MNIST数据，由数字图像及其标签组成，如图5.1所示。
- en: '![figure](../Images/CH05_F01_Ness.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F01_Ness.png)'
- en: Figure 5.1 MNIST data featuring images of handwritten digits and their digit
    labels
  id: totrans-19
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.1 MNIST数据，包括手写数字图像及其数字标签
- en: There is a related dataset called Typeface MNIST (TMNIST) that also features
    digit images and their digit labels. However, instead of handwritten digits, the
    images are digits rendered in 2,990 different fonts, illustrated in figure 5.2\.
    For each image, in addition to a digit label, there is a font label. Examples
    of the font labels include “GrandHotel-Regular,” “KulimPark-Regular,” and “Gorditas-Bold.”
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个相关的数据集叫做Typeface MNIST（TMNIST），它也包含数字图像及其数字标签。然而，与手写数字不同，图像是渲染在2,990种不同字体中的数字，如图5.2所示。对于每个图像，除了数字标签外，还有一个字体标签。字体标签的例子包括“GrandHotel-Regular”、“KulimPark-Regular”和“Gorditas-Bold”。
- en: '![figure](../Images/CH05_F02_Ness.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F02_Ness.png)'
- en: Figure 5.2 Examples from the Typeface MNIST, which is composed of typed digits
    with different typefaces. In addition to a digit label for each digit, there is
    a label for one of 2,990 different typefaces (fonts).
  id: totrans-22
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.2 Typeface MNIST的示例，它由不同字体的数字组成。除了每个数字的数字标签外，还有一个标签表示2,990种不同字体（字体）中的一种。
- en: In this analysis, we’ll combine these datasets into one and build a simple deep
    causal generative model on that data. We’ll simplify the “fonts” label into a
    sample binary label that indicates “handwritten” for MNIST images and “typed”
    for the TMNIST images.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次分析中，我们将将这些数据集合并为一个，并在该数据上构建一个简单的深度因果生成模型。我们将“字体”标签简化为一个样本二进制标签，表示MNIST图像为“手写”，TMNIST图像为“打字”。
- en: We have seen how to build a causal generative model on top of a DAG. We factorized
    the joint distribution into a product of *causal Markov kernels* representing
    the conditional probability distributions for each node, conditional on their
    parents in the DAG. In our previous examples in pgmpy, we fit a conditional probability
    table for each of these kernels.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了如何在DAG之上构建因果生成模型。我们将联合分布分解为表示每个节点条件概率分布的因果马尔可夫核的乘积，这些核在DAG中基于其父节点。在我们之前的pgmpy示例中，我们为这些核中的每一个都拟合了一个条件概率表。
- en: You can imagine how hard it would be to use a conditional probability table
    to represent the conditional probability distribution of pixels in an image. But
    there is nothing stopping us from modeling the causal Markov kernel with a deep
    neural net, which we know is flexible enough to work with high-dimensional features
    like pixels. In this section, I’ll demonstrate how to use deep neural nets to
    model the causal Markov kernels defined by a causal DAG.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象使用条件概率表来表示图像中像素的条件概率分布会有多困难。但是，没有任何阻止我们用深度神经网络来建模因果马尔可夫核，我们知道它足够灵活，可以处理像像素这样的高维特征。在本节中，我将演示如何使用深度神经网络来建模由因果DAG定义的因果马尔可夫核。
- en: 5.1.1 Leveraging the universal function approximator
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 利用通用函数逼近器
- en: Deep learning is a highly effective universal function approximator. Let’s imagine
    there is a function that maps some set of inputs to some set of outputs, but we
    either don’t know the function or it’s too hard to write down in math or code.
    Given enough examples of those inputs and outputs, deep learning can approximate
    that function with high precision. Even if that function is nonlinear and high-dimensional,
    with enough data, deep learning will learn a good approximation.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是一种高度有效的通用函数逼近器。让我们想象有一个函数将一组输入映射到一组输出，但我们要么不知道这个函数，要么很难用数学或代码表达它。给定足够的输入和输出的例子，深度学习可以以高精度近似该函数。即使该函数是非线性和高维的，只要有足够的数据，深度学习将学会一个好的近似。
- en: We regularly work with functions in causal modeling and inference, and sometimes
    it makes sense to approximate them, so long as the approximations preserve the
    causal information we care about. For example, the causal Markov property makes
    us interested in functions that map values of a node’s parents in the causal DAG
    to values (or probability values) of that node.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常在因果建模和推理中使用函数，有时对它们进行近似是有意义的，只要这些近似保留了我们关心的因果信息。例如，因果马尔可夫性质使我们感兴趣的是将因果有向图中节点父节点的值映射到该节点值（或概率值）的函数。
- en: In this section, we’ll do this mapping between a node and its parents with the
    variational autoencoder (VAE) framework. We’ll train two deep neural nets in the
    VAE, one of which maps parent cause variables to a distribution of the outcome
    variable, and another that maps the outcome variable to a distribution of the
    cause variables. This example will showcase the use of deep learning when causality
    is nonlinear and high-dimensional; the effect variable will be an image represented
    as a high-dimensional array, and the cause variables will represent the contents
    of the image.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用变分自编码器（VAE）框架来执行节点与其父节点之间的映射。在VAE中，我们将训练两个深度神经网络，其中一个将父原因变量映射到结果变量的分布，另一个将结果变量映射到原因变量的分布。这个例子将展示在因果是非线性和高维时深度学习的应用；效应变量将是一个表示为高维数组的图像，原因变量将代表图像的内容。
- en: 5.1.2 Causal abstraction and plate models
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2 因果抽象和板模型
- en: But what does it mean to build a causal model of an image? Images are comprised
    of pixels arranged in a grid. As data, we can represent that pixel grid as a matrix
    of numerical values corresponding to color. In the case of both MNIST and TMNIST,
    the image is a 28 × 28 matrix of grayscale values, as illustrated in figure 5.3\.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 但构建图像的因果模型意味着什么呢？图像由排列成网格的像素组成。作为数据，我们可以将像素网格表示为数值矩阵，这些数值对应于颜色。在MNIST和TMNIST的情况下，图像是一个28
    × 28的灰度值矩阵，如图5.3所示。
- en: '![figure](../Images/CH05_F03_Ness.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F03_Ness.png)'
- en: Figure 5.3 An MNIST image of “6” (left) and a TMNIST image of “7”. In their
    raw form, these are 28 × 28 matrices of numeric values corresponding to grayscale
    values.
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.3展示了“6”的MNIST图像（左侧）和“7”的TMNIST图像。在它们的原始形式中，这些是28 × 28的数值矩阵，对应于灰度值。
- en: A typical machine learning model looks at this 28 × 28 matrix of pixels as 28
    × 28 = 784 features. The machine learning algorithm learns statistical patterns
    connecting the pixels to one another and their labels. Based on this fact, one
    might be tempted to treat each individual pixel as a node in the naive causal
    DAG, as in figure 5.4, where for visual simplicity I’ve drawn 16 pixels (an arbitrary
    number) instead of all 784\.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的机器学习模型将这个28 × 28的像素矩阵视为784个特征。机器学习算法学习将像素及其标签连接起来的统计模式。基于这个事实，人们可能会倾向于将每个单独的像素视为朴素因果有向图中的一个节点，如图5.4所示，为了视觉上的简单，我画了16个像素（一个任意数）而不是所有的784个。
- en: '![figure](../Images/CH05_F04_Ness.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F04_Ness.png)'
- en: Figure 5.4 What a naive causal DAG might look like for an image represented
    by a 4 × 4 matrix
  id: totrans-36
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.4一个由4 × 4矩阵表示的图像的朴素因果有向图可能看起来是什么样子
- en: In figure 5.4, there are edges from the *digit* and *is-handwritten* variables
    to each pixel. Further, there are examples of edges representing possible causal
    relationships *between* pixels. Causal edges between pixels imply the color of
    one pixel is a cause of another. Perhaps most of these relationships are between
    nodes that are close, with a few far-reaching edges. But how would we know if
    one pixel causes another? If two pixels are connected, how would we know the direction
    of causality?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在图5.4中，存在从*数字*和*手写*变量到每个像素的边缘。此外，还有一些表示像素之间可能因果关系的边缘示例。像素之间的因果边缘意味着一个像素的颜色是另一个像素的原因。也许这些关系大多数都在节点之间，只有少数是远距离的。但我们如何知道一个像素是否导致另一个像素？如果两个像素相连，我们如何知道因果关系的方向？
- en: Working at the right level of abstraction
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在正确的抽象层次上工作
- en: With these connections among only 16 pixels, the naive DAG in figure 5.4 is
    already quite unwieldy. It would be much worse with 784 pixels. Aside from the
    unwieldiness of a DAG, the problem with a pixel-level model is that our causal
    questions are generally not at the pixel level—we’d probably never ask “what is
    the causal effect of this pixel on that pixel?” In other words, the pixel is too
    low a level of abstraction, which is why thinking about causal relationships between
    individual pixels feels a bit absurd.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 仅用16个像素之间的这些连接，图5.4中的朴素DAG就已经相当难以处理了。如果用784个像素，情况会更糟。除了DAG的难以处理之外，像素级模型的问题在于我们的因果问题通常不是在像素级别——我们可能永远不会问“这个像素对这个像素的因果效应是什么？”换句话说，像素的抽象层次太低，这就是为什么考虑单个像素之间的因果关系感觉有点荒谬。
- en: In applied statistics domains, such as econometrics, social science, public
    health, and business, our data has variables like per capita income, revenue,
    location, age, etc. These variables are typically already at the level of abstraction
    we want to think about when we get the data. But modern machine learning focuses
    on many perception problems from raw media, such as images, video, text, and sensor
    data. We don’t generally want to do causal reasoning at the low level of these
    features. Our causal questions are usually about the high-level abstractions behind
    these low-level features. We need to model at these higher abstraction levels.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用统计学领域，如计量经济学、社会科学、公共卫生和商业，我们的数据有诸如人均收入、收入、位置、年龄等变量。这些变量通常已经是我们获取数据时想要思考的抽象层次。但现代机器学习专注于从原始媒体（如图像、视频、文本和传感器数据）中提取的许多感知问题。我们通常不希望在低级特征上进行因果推理。我们的因果问题通常关于这些低级特征背后的高级抽象。我们需要在这些更高抽象层次上建模。
- en: Instead of thinking about individual pixels, we’ll think about the entire image.
    We’ll define a variable *X* to represent how the image appears; i.e., *X* is a
    matrix random variable representing pixels. Figure 5.5 illustrates a causal DAG
    for the TMNIST case. Simply put, the identity of the digits (0–9) and the font
    (2,990 possible values) are the causes, and the image is the effect.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会考虑单个像素，而是会考虑整个图像。我们将定义一个变量*X*来表示图像的外观；即，*X*是一个表示像素的矩阵随机变量。图5.5说明了TMNIST案例的因果DAG。简单来说，数字（0-9）和字体（2,990种可能值）是原因，图像是结果。
- en: '![figure](../Images/CH05_F05_Ness.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F05_Ness.png)'
- en: Figure 5.5 A simple causal DAG that represents the implied DGP behind Typeface
    MNIST
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.5 表示Typeface MNIST背后隐含DGP的简单因果DAG
- en: In this case, we are using the causal DAG to make an assertion that the label
    causes the image. That is not always the case, as we’ll discuss in our case study
    on semi-supervised learning in section 5.3\. As with all causal models, it depends
    on the data generating process (DGP) within a domain.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们使用因果DAG来做出一个断言，即标签导致图像。这并不总是情况，正如我们将在5.3节讨论的半监督学习案例研究中讨论的那样。与所有因果模型一样，它取决于一个领域内的数据生成过程（DGP）。
- en: Why say that the digit *causes* the image?
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 为什么说数字*导致*了图像？
- en: Plato’s allegory of the cave describes a group of people who have lived in a
    cave all their lives, without seeing the world. They face a blank cave wall and
    watch shadows projected on the wall from objects passing in front of a fire behind
    them. The shadows are simplified and sometimes distorted representations of the
    true objects passing in front of the fire. In this case, we can think of the form
    of the objects as being the cause of the shadow.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 柏拉图的洞穴寓言描述了一群人，他们一生都在洞穴中生活，从未见过世界。他们面对一个空白的洞穴墙壁，并观看从他们身后火堆前经过的物体在墙壁上投射的影子。这些影子是真实物体经过火堆前的简化且有时扭曲的表示。在这种情况下，我们可以认为物体的形式是影子的原因。
- en: Analogously, the true form of the digit label causes the representation in the
    image. The MNIST images were written by people, and they have some *Platonic ideal*
    of the digit in their head that they want to render onto paper. In the process,
    that ideal is distorted by motor variation in the hand, the angle of the paper,
    the friction of the pen on the paper, and other factors—the rendered image is
    a “shadow” caused by that “ideal.”
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，数字标签的真实形式导致图像中的表示。MNIST图像是由人们书写的，他们心中有一个想要渲染到纸上的数字的柏拉图理想。在这个过程中，这个理想受到手的运动变化、纸张的角度、笔在纸上的摩擦以及其他因素的影响——渲染的图像是那个“理想”的“影子”。
- en: This idea is related to a concept called “vision as inverse graphics” in computer
    vision (see [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for sources with more information). In causal terms, the takeaway is that when
    we are analyzing images rendered from raw signals from the environment, and the
    task is to infer the actual objects or events that resulted in those signals,
    causality flows from those objects or events to the signals. The inference task
    is to use the observed signals (shadows on the cave wall) to infer the nature
    of the causes (objects in front of the fire).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法与计算机视觉中称为“视觉作为逆图形”的概念相关（有关更多信息，请参阅[https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)）。在因果的术语中，要点是当我们分析从环境原始信号渲染的图像时，如果任务是推断导致这些信号的实际物体或事件，因果性从这些物体或事件流向信号。推断任务是使用观察到的信号（洞穴墙壁上的影子）来推断原因的性质（火堆前的物体）。
- en: That said, images can be causes too. For example, if you were modeling how people
    behave *after* seeing an image in a mobile app (e.g., whether they “click”, “like”,
    or “swipe left”), you could model the image as a cause of the behavior.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，图像也可以是原因。例如，如果你正在模拟人们在移动应用中看到图像后的行为（例如，他们是否“点击”、“点赞”或“向左滑动”），你可以将图像建模为导致该行为的原因。
- en: Plate modeling
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 板模型
- en: Modeling 2,990 fonts in our TMNIST data is overkill for our purposes here. Instead,
    I combined these datasets into one—half from MNIST and half from Typeface MNIST.
    Along with the “digit” label, I’m just going to have a simple binary label called
    “is-handwritten”, which is 1 (true) for images of handwritten digits from MNIST
    and 0 (false) for images of “typed” digits from TMNIST. We can modify our causal
    DAG to get figure 5.6.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的TMNIST数据中建模2,990种字体对于我们的目的来说过于冗余。相反，我将这些数据集合并为一个——一半来自MNIST，一半来自Typeface
    MNIST。除了“数字”标签外，我还要有一个简单的二进制标签，称为“is-handwritten”，对于MNIST的手写数字图像为1（真实），对于TMNIST的“打字”数字图像为0（假）。我们可以修改我们的因果DAG以获得图5.6。
- en: '![figure](../Images/CH05_F06_Ness.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F06_Ness.png)'
- en: Figure 5.6 A causal DAG representing the combined MNIST and TMNIST data, where
    “is-handwritten” is 1 (MNIST images) or 0 (TMNIST images)
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.6 表示MNIST和TMNIST数据组合的因果DAG，其中“is-handwritten”为1（MNIST图像）或0（TMNIST图像）
- en: Plate modeling is a visualizing technique used in probabilistic machine learning
    that provides an excellent way to visualize the higher-level abstractions while
    preserving the lower-level dimensional detail. Plate notation is a method of visually
    representing variables that repeat in a DAG (e.g., *X*[1] to *X*[16] in figure
    5.4)—in our case, we have repetition of the pixels.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 板模型是一种在概率机器学习中使用的可视化技术，它提供了一种在保留低级维度细节的同时，可视化高级抽象的绝佳方法。板符号是一种在DAG（例如，图5.4中的*X*[1]到*X*[16]）中视觉表示重复变量的方法——在我们的情况下，我们有像素的重复。
- en: Instead of drawing each of the 784 pixels as an individual node, we use a rectangle
    or “plate” to group repeating variables into subgraphs. We then write a number
    on the plate to represent the number of repetitions of the entities on the plate.
    Plates can nest within one another to indicate repeated entities nested within
    repeated entities. Each plate gets a letter subscript indexing the elements on
    that plate. The causal DAG in figure 5.7 represents one image.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不是将每个784个像素作为单独的节点来绘制，而是使用矩形或“板”将重复变量分组到子图中。然后我们在板上写一个数字来表示板上实体的重复次数。板可以嵌套在另一个板中，以表示嵌套在重复实体中的重复实体。每个板都有一个字母下标，用于索引该板上的元素。图5.7中的因果DAG代表一个图像。
- en: '![figure](../Images/CH05_F07_Ness.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F07_Ness.png)'
- en: Figure 5.7 A plate model representation of the causal DAG. Plates represent
    repeating variables, in this case 28 × 28 = 784 pixels. *X**[j]* is the *j*^(th)
    pixel.
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.7展示了因果DAG的板模型表示。板代表重复变量，在这种情况下是28 × 28 = 784像素。*X**[j]*是第*j*个像素。
- en: During training, we’ll have a large set of training images. Next, we’ll modify
    the DAG to capture all the images in the training data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们将有一大批训练图像。接下来，我们将修改DAG以捕获训练数据中的所有图像。
- en: 5.2 Training a neural causal model
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 训练神经因果模型
- en: To train our neural causal model, we need to load and prepare the training data,
    create the architecture of our model, write a training procedure, and implement
    some tools for evaluating how well training is progressing. We’ll start by loading
    and preparing the data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练我们的神经因果模型，我们需要加载数据并准备，创建我们模型的架构，编写训练过程，并实现一些评估训练进展的工具。我们将首先加载数据并准备。
- en: 5.2.1 Setting up the training data
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 设置训练数据
- en: Our training data has *N* example images, so we need our plate model to represent
    all *N* images in the training data, half handwritten and half typed. We’ll add
    another plate corresponding to repeating *N* sets of images and labels, as in
    figure 5.8.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的训练数据包含*N*个示例图像，因此我们需要我们的板模型来表示训练数据中的所有*N*个图像，一半是手写的，一半是打印的。我们将在图5.8中添加另一个板，对应于重复*N*组图像和标签。
- en: '![figure](../Images/CH05_F08_Ness.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F08_Ness.png)'
- en: Figure 5.8 The causal model with an additional plate for the *N* images in the
    data
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.8展示了包含数据中*N*个图像的因果模型，并添加了一个额外的板。
- en: Now we have a causal DAG that illustrates both our desired level of causal abstraction
    as well as the dimensional information we need to start training the neural nets
    in the model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个因果DAG，它展示了我们希望达到的因果抽象水平以及我们开始训练模型中的神经网络所需的维度信息。
- en: Let’s first load Pyro and some other libraries and set some hyperparameters.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先加载Pyro和其他一些库，并设置一些超参数。
- en: Setting up your environment
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 设置你的环境
- en: This code was written using Python version 3.10.12 and tested in Google Colab.
    The versions of the main libraries include Pyro (pyro-ppl) version 1.8.4, torch
    version 2.2.1, torchvision version 0.18.0+cu121, and pandas version 2.0.3\. We’ll
    also use matplotlib for plotting.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码使用Python 3.10.12版本编写，并在Google Colab中进行测试。主要库的版本包括Pyro (pyro-ppl) 1.8.4、torch
    2.2.1、torchvision 0.18.0+cu121和pandas 2.0.3。我们还将使用matplotlib进行绘图。
- en: Visit [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for links to a notebook that will load in Google Colab.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 访问[https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)获取一个笔记本的链接，该笔记本将在Google
    Colab中加载。
- en: If GPUs are available on your device, it will be faster to train the neural
    nets with CUDA (a platform for parallel computing on GPUs). We’ll run a bit of
    code that lets us toggle it on. If you don’t have GPUs or aren’t sure if you do,
    leave `USE_CUDA` set to `False`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的设备上有GPU，使用CUDA（一个在GPU上并行计算的平台）训练神经网络将更快。我们将运行一些代码来切换它。如果您没有GPU或者不确定是否有，请将`USE_CUDA`设置为`False`。
- en: Listing 5.1 Setting up for GPU training
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.1 设置GPU训练
- en: '[PRE0]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Use CUDA if it is available.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 如果可用，使用CUDA。'
- en: First, we’ll make a subclass of the `Dataset` class (a class for loading and
    preprocessing data) that will let us combine the MNIST and TMNIST datasets.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建一个`Dataset`类的子类（用于加载数据和预处理数据的类），这将使我们能够结合MNIST和TMNIST数据集。
- en: Listing 5.2 Combining the data
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.2 合并数据
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#1 This class loads and processes a dataset that combines MNIST and Typeface
    MNIST. The output is a torch.utils.data.Dataset object.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 此类加载并处理结合MNIST和Typeface MNIST的数据集。输出是一个torch.utils.data.Dataset对象。'
- en: '#2 Load, normalize, and reshape the images to 28 × 28 pixels.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 加载、归一化和重塑图像为28 × 28像素。'
- en: '#3 Get and process the digit labels, 0–9.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 获取和处理数字标签，0–9。'
- en: '#4 1 for handwritten digits (MNIST), and 0 for “typed” digits (TMNIST)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 1 对于手写数字（MNIST），以及 0 对于“输入”数字（TMNIST）'
- en: '#5 Return a tuple of the image, the digit label, and the is_handwritten label.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 返回一个包含图像、数字标签和 is_handwritten 标签的元组。'
- en: Next, we’ll use the `DataLoader` class (which allows for efficient data iteration
    and batching during training) to load the data from a CSV file in GitHub and split
    it into training and test sets.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 `DataLoader` 类（它允许在训练期间高效地进行数据迭代和批处理）从 GitHub 中的 CSV 文件加载数据，并将其分为训练集和测试集。
- en: Listing 5.3 Downloading, splitting, and loading the data
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.3 下载、分割和加载数据
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#1 Set up the data loader that loads the data and splits it into training and
    test sets.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 设置数据加载器，用于加载数据并将其分为训练集和测试集。'
- en: '#2 Allot 80% of the data to training data and the remaining 20% to test data.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将 80% 的数据分配给训练数据，剩余的 20% 分配给测试数据。'
- en: '#3 Create training and test loaders.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 创建训练和测试加载器。'
- en: Next, we’ll set up the full variational autoencoder.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将设置完整的变分自编码器。
- en: 5.2.2 Setting up the variational autoencoder
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 设置变分自编码器
- en: The variational autoencoder (VAE) is perhaps the simplest deep probabilistic
    machine learning modeling approach. In the typical setup for applying VAE to images,
    we introduce a latent continuous variable *Z* that has a smaller dimension than
    the image data. Here, *dimensionality* refers to the number of elements in a vector
    representation of the data. For instance, our image is a 28 × 28 matrix of pixels,
    or alternatively a vector with dimension 28 × 28 = 784\. By having a much smaller
    dimension than the image dimension, the latent variable *Z* represents a compressed
    encoding of the image information. For each image in the dataset, there is a corresponding
    latent *Z* value that represents an encoding of that image. This setup is illustrated
    in figure 5.9.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 变分自编码器（VAE）可能是最简单的深度概率机器学习建模方法。在将 VAE 应用于图像的典型设置中，我们引入一个比图像数据维度小的潜在连续变量 *Z*。在这里，*维度*指的是数据向量表示中的元素数量。例如，我们的图像是一个
    28 × 28 的像素矩阵，或者也可以是一个维度为 28 × 28 = 784 的向量。由于比图像维度小得多，潜在变量 *Z* 代表了图像信息的压缩编码。对于数据集中的每个图像，都有一个相应的潜在
    *Z* 值，它代表了该图像的编码。这种设置如图 5.9 所示。
- en: '![figure](../Images/CH05_F09_Ness.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F09_Ness.png)'
- en: Figure 5.9 The causal DAG plate model, extended to include an “encoding” variable
    *Z*. During training, the variable is latent, indicated by the dashed line. (After
    the model is deployed, *digit* and *is-handwritten*are also latent).
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.9 因果 DAG 盘模型，扩展以包括一个“编码”变量 *Z*。在训练期间，该变量是潜在的，由虚线表示。（在模型部署后，*digit* 和 *is-handwritten*
    也都是潜在的）。
- en: '*Z* appears as a new parent in the causal DAG, but it’s important to note that
    the classical VAE framework does not define *Z* as causal. Now that we are thinking
    causally, we’ll give *Z* a causal interpretation. Specifically, as parents of
    the image node in the DAG, we view *digit* and *is-handwritten* as causal drivers
    of what we see in the image. Yet there are other elements of the image (e.g.,
    the stroke thickness of a handwritten character, or the font of a typed character)
    that are also causes of what we see in the image. We’ll think of *Z* as a continuous
    latent *stand-in* for all of these other causes of the image that we are not explicitly
    modeling, like *digit* and *is-handwritten*. Examples of these causes include
    the nuance of the various fonts in the TMNIST labels and all of the variations
    in the handwritten digits due to different writers and motor movements as they
    wrote. With that in mind, we can view *P*(*X*| *digit*, *is-handwritten*, *Z*)
    as the causal Markov kernel of *X*. That said, it is important to remember that
    the representation we learn for *Z* is a stand-in for latent causes and is not
    the same as learning the actual latent causes.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '*Z* 在因果 DAG 中表现为一个新的父节点，但需要注意的是，经典的 VAE 框架并没有将 *Z* 定义为因果的。现在我们正在进行因果思考，我们将
    *Z* 给予因果解释。具体来说，作为 DAG 中图像节点的父节点，我们将 *digit* 和 *is-handwritten* 视为图像中我们所看到的因果驱动因素。然而，图像中还有其他元素（例如，手写字符的笔画粗细或输入字符的字体）也是我们所看到的图像的因果因素。我们将
    *Z* 视为所有这些我们未明确建模的图像因果因素的连续潜在“替身”，例如 *digit* 和 *is-handwritten*。这些因果因素的例子包括 TMNIST
    标签中各种字体的细微差别以及由于不同作者和书写时的运动方式而导致的书写数字的所有变化。考虑到这一点，我们可以将 *P*(*X*| *digit*, *is-handwritten*,
    *Z*) 视为 *X* 的因果马尔可夫核。话虽如此，重要的是要记住，我们为 *Z* 学习到的表示是潜在因果的替身，并不等同于学习实际的潜在因果。'
- en: 'The VAE setup will train two deep neural networks: One called an “encoder”,
    which encodes an image into a value for *Z*. The other neural network, called
    the “decoder,” will align with our DAG. The decoder generates an image from the
    *digit* label, the *is-handwritten* label, and a *Z* value, as in figure 5.10.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: VAE 设置将训练两个深度神经网络：一个称为“编码器”，它将图像编码为 *Z* 的一个值。另一个神经网络，称为“解码器”，将与我们的 DAG 对齐。解码器将从
    *digit* 标签、*is-handwritten* 标签和 *Z* 值生成图像，如图 5.10 所示。
- en: The decoder acts like a rendering engine; given a *Z* encoding value and the
    values for *digit* and *is-handwritten*, it renders an image.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器的作用像一个渲染引擎；给定一个 *Z* 编码值和 *digit* 以及 *is-handwritten* 的值，它将渲染一个图像。
- en: '![figure](../Images/CH05_F10_Ness.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH05_F10_Ness.png)'
- en: Figure 5.10 The decoder neural network generates as output an image *X* from
    inputs *Z* and the labels *is-handwritten* and *digit*. As with any neural net,
    the inputs are processed through one or more “hidden layers.”
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.10 解码器神经网络从输入 *Z* 和标签 *is-handwritten* 以及 *digit* 生成输出图像 *X*。与任何神经网络一样，输入通过一个或多个“隐藏层”进行处理。
- en: Key VAE concepts so far
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 到目前为止的关键 VAE 概念
- en: '*Variational autoencoder (VAE)*—A popular framework in deep generative modeling.
    We’re using it to model a causal Markov kernel in a causal model.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '*变分自编码器 (VAE)*——深度生成建模中的一种流行框架。我们正在使用它来模拟因果马尔可夫核中的因果模型。'
- en: '*Decoder*—We use the decoder as the model of the causal Markov kernel. It maps
    the observed causes *is-handwritten* and *digit*, and the latent variable *Z*,
    to our image outcome variable *X*.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*解码器*——我们使用解码器作为因果马尔可夫核的模型。它将观察到的原因 *is-handwritten* 和 *digit* 以及潜在变量 *Z* 映射到我们的图像结果变量
    *X*。'
- en: This VAE approach allows us to use a neural net, a la the decoder, to capture
    the complex and nonlinear relations needed to model the image as an effect caused
    by *digit* and *is-handwritten*. Modeling images would be difficult with the conditional
    probability tables and other simple parameterizations of causal Markov kernels
    we’ve discussed previously.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这种 VAE 方法允许我们使用神经网络，类似于解码器，来捕捉建模图像作为由 *digit* 和 *is-handwritten* 造成的效应所需的复杂和非线性关系。使用我们之前讨论过的条件概率表和其他简单的因果马尔可夫核参数化来建模图像将是困难的。
- en: First, let’s implement the decoder. We’ll pass in arguments `z_dim` for the
    dimension of *Z* and `hidden_dim` for the dimension (width) of the hidden layers.
    We’ll specify these variables when we instantiate the full VAE. The decoder combines
    the latent vector *Z* with additional inputs—the variable representing the *digit,*
    and *is-handwritten* (a binary indicator of whether the digit is handwritten).
    It will produce a 784-dimensional output vector representing an image of size
    28 × 28 pixels. This output vector contains the parameters for a Bernoulli distribution
    for each pixel, essentially modeling the likelihood of each pixel being “on.”
    The class uses two fully connected layers (`fc1` and `fc2`), and employs `Softplus`
    and `Sigmoid` “activation functions,” which are the hallmarks of how neural nets
    emulate neurons.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们实现解码器。我们将传递 `z_dim` 作为 *Z* 的维度和 `hidden_dim` 作为隐藏层（宽度）的维度。当我们实例化完整的 VAE
    时将指定这些变量。解码器将潜在向量 *Z* 与额外的输入相结合——代表 *digit* 的变量和 *is-handwritten*（一个指示数字是否手写的二进制指示符）。它将生成一个
    784 维的输出向量，代表大小为 28 × 28 像素的图像。这个输出向量包含每个像素的伯努利分布的参数，本质上是对每个像素“开启”的可能性的建模。该类使用两个全连接层（`fc1`
    和 `fc2`），并采用 `Softplus` 和 `Sigmoid` “激活函数”，这是神经网络模拟神经元的特点。
- en: Listing 5.4 Implement the decoder
  id: totrans-103
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.4 实现解码器
- en: '[PRE3]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#1 A class for the decoder used in the VAE'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 用于 VAE 中的解码器的类'
- en: '#2 Image is 28 × 28 pixels.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 图像大小为 28 × 28 像素。'
- en: '#3 Digit is one-hot encoded digits 0–9, i.e., a vector of length 10.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 数字是 0-9 的一热编码数字，即长度为 10 的向量。'
- en: '#4 An indicator for whether the digit is handwritten that has size 1'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 一个指示数字是否手写的指示符，大小为 1'
- en: '#5 Softplus and sigmoid are nonlinear transforms (activation functions) used
    in mapping between layers.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 Softplus 和 sigmoid 是在层之间映射时使用的非线性变换（激活函数）。'
- en: '#6 fc1 is a linear function that maps the Z vector, the digit, and is_handwritten
    to a linear output, which is passed through a softplus activation function to
    create a hidden layer-a vector whose length is given by hidden_layer.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 fc1 是一个线性函数，它将 Z 向量、数字和 is_handwritten 映射到一个线性输出，该输出通过 softplus 激活函数传递，创建一个隐藏层——其长度由
    hidden_layer 给出。'
- en: '#7 fc2 linearly maps the hidden layer to an output passed to a sigmoid function.
    The resulting value is between 0 and 1.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 fc2 线性地将隐藏层映射到传递给 sigmoid 函数的输出。得到的值介于 0 和 1 之间。'
- en: '#8 Define the forward computation from the latent Z variable value to a generated
    X variable value.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '#9 Combine Z and the labels.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: '#10 Compute the hidden layer.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '#11 Pass the hidden layer to a linear transform and then to a sigmoid transform
    to output a parameter vector of length 784\. Each element of the vector corresponds
    to a Bernoulli parameter value for an image pixel.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: We use the decoder in the causal model. Our causal DAG acts as the scaffold
    for a causal probabilistic machine learning model that, with the help of the decoder,
    defines a joint probability distribution on {*is-handwritten*, *digit*, *X*, *Z*},
    where *Z* is latent. We can use the model to calculate the likelihood of the training
    data for a given value of *Z*.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: The latent variable `z`, the digit identity represented as a one-hot vector
    `digit`, and a binary indicator `is_handwritten` are modeled as samples from standard
    distributions. These variables are then fed into the decoder to produce parameters
    (`img_param`) for a Bernoulli distribution representing individual pixel probabilities
    of an image.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Note, using the Bernoulli distribution to model the pixels is a bit of a hack.
    The pixels are not binary black and white outcomes—they have grayscale values.
    The line `dist.enable_validation(False)` lets us cheat by getting Bernoulli log
    likelihoods for the images given a decoder’s `img_param` output.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: The following model code is a class method for a PyTorch neural network module.
    We’ll see the entire class later.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.5 The causal model
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#1 Disabling distribution validation lets Pyro calculate log likelihoods for
    pixels even though the pixels are not binary values.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The model of a single image. Within the method, we register the decoder,
    a PyTorch module, with Pyro. This lets Pyro know about the parameters inside of
    the decoder network.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '#3 We model the joint probability of Z, digit, and is_handwritten, sampling
    each from canonical distributions. We sample Z from a multivariate normal with
    location parameter z_loc (all zeros) and scale parameter z_scale (all ones).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '#4 We also sample the digit from a one-hot categorical distribution. Equal
    probability is assigned to each digit.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '#5 We similarly sample the is_handwritten variable from a Bernoulli distribution.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '#6 The decoder maps digit, is_handwritten, and Z to a probability parameter
    vector.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '#7 The parameter vector is passed to the Bernoulli distribution, which models
    the pixel values in the data. The pixels are not technically Bernoulli binary
    variables, but we’ll relax this assumption.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: The preceding `model` method represents the DGP for one image. The `training_
    model` method in the following listing applies that `model` method to the *N*
    images in the training data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.6 Method for applying `model` to *N* images in data
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 The model represents the DGP for one image. The training_model applies that
    model to the N images in the training data.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Now we condition the model on the evidence in the training data.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '#3 This context manager represents the N-size plate representing repeating
    IID examples in the data in figure 5.9\. In this case, N is the batch size. It
    works like a for loop, iterating over each data unit in the batch.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Our probabilistic machine learning model models the joint distribution of {*Z*,
    *X*, *digit*, *is-handwritten*}. But since *Z* is latent, the model will need
    to learn *P*(*Z*|*X*, *digit*, *is-handwritten*). Given that we use the decoder
    neural net to go from *Z* and the labels to *X*, the distribution of *Z*, given
    *X* and the labels will be complex. We will use *variational inference*, a technique
    where we first define an approximating distribution *Q*(*Z*|*X*, *digit*, *is-handwritten*),
    and try to make that distribution as close to *P*(*Z*|*X*, *digit*, *is-handwritten*)
    as we can.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: The main ingredient of the approximating distribution is the second neural net
    in the VAE framework, the encoder, illustrated in figure 5.11\. The encoder maps
    an observed image and its labels in the training data to a latent *Z* variable.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F11_Ness.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 The encoder maps actual images as input to the latent *Z* variable
    as output.
  id: totrans-138
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The encoder does the work of compressing the information in the image into a
    lower-dimensional encoding.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Key VAE concepts so far
  id: totrans-140
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*Variational autoencoder (VAE)*—A popular framework in deep generative modeling.
    We’re using it to model a causal Markov kernel in our causal model.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '*Decoder*—We use the decoder as the model of the causal Markov kernel. It maps
    observed causes *is-handwritten* and *digit*, and the latent variable *Z*, to
    our image outcome variable *X*.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '*Encoder*—The encoder maps the image, *digit*, and *is-handwritten* indicator
    to the parameters of a distribution where we can draw samples of *Z*.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: In the following code, the encoder takes as input an image, a digit label, and
    the *is-handwritten* indicator. These inputs are concatenated and passed through
    a series of fully connected layers with Softplus activation functions. The final
    output of the encoder consists of two vectors representing the location (`z_loc`)
    and scale (`z_scale`) parameters of the latent space distribution on *Z*, given
    observed values for *image* (`img`), *digit* (`digit`), and *is-handwritten* (`is_handwritten`).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.7 Implement the encoder
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 The encoder is an instance of a PyTorch module.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The input image is 28 × 28 = 784 pixels.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '#3 The digit dimension is 10.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '#4 In the encoder, we’ll only use the softplus transform (activation function).'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '#5 The linear transform fc1 combines with the softplus to map the 784-dimensional
    pixel vector, 10-dimensional digit label vector, and 2-dimensional is_handwritten
    vector to the hidden layer.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '#6 The linear transforms, fc21 and fc22, will combine with the softplus to
    map the hidden vector to Z’s vector space.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Define the reverse computation from an observed X variable value to a latent
    Z variable value.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '#8 Combine the image vector, digit label, and is_handwritten label into one
    input.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '#9 Map the input to the hidden layer.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '#10 The VAE framework will sample Z from a normal distribution that approximates
    P(Z|img, digit, is_handwritten). The final transforms map the hidden layer to
    a location and scale parameter for that normal distribution.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: The output of the encoder produces the parameters of a distribution on *Z*.
    During training, given an image and its labels (*is-handwritten* and *digit*),
    we want to get a good value of *Z*, so we write a *guide function* that will use
    the encoder to sample values of *Z*.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.8 The guide function
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 training_guide is a method of the VAE that will use the encoder.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Register the encoder so Pyro is aware of its weight parameters.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '#3 This is the same plate context manager for iterating over the batch data
    that we see in the training_model.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Use the encoder to map an image and its labels to parameters of a normal
    distribution.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Sample Z from that normal distribution'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: We combine these elements into one PyTorch neural network module representing
    the VAE. We’ll initialize the latent dimension of *Z* to be 50\. We’ll set our
    hidden layer dimension to 400 in both the encoder and decoder. That means that
    given a dimension of 28 × 28 for the image, 1 for the binary *is-handwritten*,
    and 10 for the one-hot-encoded *digit* variable, we’ll take a 28 × 28 + 1 + 10
    = 795-dimensional feature vector and compress it down to a 400-dimensional hidden
    layer, and then compress that down to a 50-dimensional location and scale parameter
    for *Z*’s multivariate normal (Gaussian) distribution. The decoder takes as input
    the values of *digit*, *is-handwritten*, and *Z* and maps these to a 400-dimensional
    hidden layer and to the 28 × 28–dimensional image. These architectural choices
    of latent variable dimension, number of layers, activation functions, and hidden
    layer dimensions depend on the problem and are typically selected by convention
    or by experimenting with different values.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: Now we’ll put these pieces together into the full VAE class.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.9 Full VAE class
  id: totrans-167
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '#1 Set the latent dimension to 50.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Set the hidden layers to have a dimension of 400.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Set up the encoder and decoder.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Add in the methods for model, training_model, and training_guide.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Having specified the VAE, we can now move on to training.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.3 The training procedure
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We know we have a good generative model when the encoder can encode an image
    into a latent value of *Z*, and then decode it into a *reconstructed* version
    of the image. We can minimize the *reconstruction error*—the difference between
    original and reconstructed images—in the training data.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: A bit of perspective on the “variational inference” training algorithm
  id: totrans-176
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this section, you’ll see a bunch of jargon relating to variational inference,
    which is the algorithm we’ll use for training. It helps to zoom out and examine
    why we’re using this algorithm. There are many statistical estimators and algorithms
    both for fitting neural net weights and other parameters and for causal inference.
    One of these is variational inference.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: To be clear, variational inference is not a “causal” idea. It is just another
    probabilistic inference algorithm. In this book, I favor this inference algorithm
    more than others because it scales well even when variables in the DAG are latent
    in the training data, and it works with deep neural nets and leverages deep learning
    frameworks like PyTorch. This opens the door to reasoning causally about richer
    modalities such as text, images, video, etc., whereas traditional causal inference
    estimators were developed for numerical data. Further, we can tailor the method
    to different problems (see the discussion of “commodification of inference” in
    chapter 1) and leverage domain knowledge during inference (such as by using knowledge
    of conditional independence in the guide). Finally, the core concepts of variational
    inference show up across many deep generative modeling approaches (such as latent
    diffusion models).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: 'In practice, solely minimizing reconstruction error leads to overfitting and
    other issues, so we’ll opt for a probabilistic approach: given an image, we’ll
    use our guide function to sample a value of *Z* from *P*(*Z*|*image*, *is-handwritten*,
    *digi**t*). Then we’ll plug that value into our model’s decoder, and the output
    parameterizes *P*(*image*|*is-handwritten*, *digit*, *Z*). Our probabilistic approach
    to minimizing reconstruction error optimizes the encoder and decoder such that
    we’ll maximize the likelihood of *Z* with respect to *P*(*Z*|*image*, *is-handwritten*,
    *digit*) and the likelihood of the original image with respect to *P*(*image*|*is-handwritten*,
    *digit*, *Z*).'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: But typically we can’t directly sample from or get likelihoods from the distribution
    *P*(*Z*|*image*, *is-handwritten*, *digit*). So, instead, our guide function attempts
    to approximate it. The guide represents a *variational distribution*, denoted
    *Q*(*Z*|*X*, *is-handwritten*, *digit*). A change in the weights of the encoder
    represents a shifting of the variational distribution. Training will optimize
    the weights of the encoder such that the variational distribution shifts toward
    *P*(*Z*|*image*, *is-handwritten*, *digit*). That training approach is called
    *variational inference*, and it works by minimizing the *Kullback–Leibler divergence*
    (KL divergence) between the two distributions; KL divergence is a way of quantifying
    how two distributions differ.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Our variational inference procedure optimizes a quantity called *ELBO*, which
    means *expected lower bound on the log-likelihood of the data*. Minimizing negative
    ELBO loss indirectly minimizes reconstruction error and KL divergence between
    *Q*(*Z*|…) and *P*(*Z*|…). Pyro implements ELBO in a utility called `Trace_ELBO`.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: Our procedure will use *stochastic* variational inference (SVI), which simply
    means doing variational inference with a training procedure that works with randomly
    selected subsets of the data, or “batches”, rather than the full dataset, which
    reduces memory use and helps scale to larger data.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Key VAE concepts so far
  id: totrans-183
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*Variational autoencoder (VAE)*—A popular framework in deep generative modeling.
    We’re using it to model a causal Markov kernel in our causal model.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '*Decoder*—We use the decoder as the model of the causal Markov kernel. It maps
    the observed causes *is-handwritten* and *digit*, and the latent variable *Z*,
    to our image outcome variable *X*.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '*Encoder*—The encoder maps the *image*, *digit*, and *is-handwritten* to the
    parameters of a distribution where we can draw samples of *Z*.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '*Guide function*—During training, we want values of *Z* that represent an image,
    given *is-handwritten* and *digit*; i.e., we want to generate *Z*s from *P*(*Z*|*image*,
    *is-handwritten*, *digit*). But we can’t sample from this distribution directly.
    So we write a *guide function* that uses the encoder and convenient canonical
    distributions like the multivariate normal to sample values of *Z*.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '*Variational distribution*—The guide function represents a distribution called
    *the variational distribution*, denoted *Q*(*Z*|*image*, *is-handwritten*, *digit*).
    During inference, we want to sample from *Q*(*Z*|…) in a way that is representative
    of *P*(*Z*|*image*, *is-handwritten*, *digit*).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '*Variational inference*—This is the training procedure that seeks to maximize
    the closeness between *Q*(*Z*|…) and *P*(*Z*|…) so sampling from *Q*(*Z*|…) produces
    samples representative of *P*(*Z*|…) (e.g., by minimizing KL divergence).'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '*Stochastic variational inference (SVI)*—Variational inference where training
    relies on randomly selected subsets of the data, rather than on the full data,
    in order to make training faster and more scalable.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: Before we get started, we’ll make a helper function for plotting images so we
    can see how we are doing during training.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.10 Helper function for plotting images
  id: totrans-192
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#1 Helper function for plotting an image'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll create a `reconstruct_img` helper function that will *reconstruct*
    an image, given its labels, where “reconstruct” means encoding the image into
    a latent representation and then decoding the latent representation back into
    an image. We can then compare the original image and its reconstruction to see
    how well the encoder and decoder have been trained. We’ll create a `compare_images`
    function to do that comparison.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.11 Define a helper function for reconstructing and viewing the images
  id: totrans-196
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 Given an input image, this function reconstructs the image by passing it
    through the encoder and then through the decoder.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Plots the two images side by side for comparison'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll create some helper functions for handling the data. We’ll use `get_random_example`
    to grab random images from the dataset. The `reshape_data` function will convert
    an image and its labels into input for the encoder. And we’ll use `generate_data`
    and `generate_coded_data` to simulate an image from the model.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.12 Data processing helper functions for training
  id: totrans-201
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '#1 Choose a random example from the dataset.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Reshape the data.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Generate data that is encoded.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Generate (unencoded) data.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we can run the training procedure. First, we’ll set up stochastic variational
    inference. We’ll first set up an instance of the Adam optimizer, which will handle
    optimization of the parameters in `training_guide`. Then we’ll pass `training_model`,
    `training_guide`, the optimizer, and the ELBO loss function to the SVI constructor
    to get an SVI instance.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.13 Set up the training procedure
  id: totrans-208
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#1 Clear any values of the parameters in the guide memory.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Initialize the VAE.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Load the data.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Initialize the optimizer.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Initialize the SVI loss calculator. Loss negative “expected lower bound”
    (ELBO).'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: When training generative models, it is useful to set up a procedure that uses
    test data to evaluate how well training is progressing. You can include anything
    you think is useful to monitor during training. Here, I calculate and print the
    loss function on the test data, just to make sure the test loss is progressively
    decreasing along with training loss (a flattening of test loss while training
    loss continues to decrease would indicate overfitting).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: A more direct way of determining how well our model is training is to generate
    and view images. In my test evaluation procedure, I produce two visualizations.
    First, I inspect how well it can reconstruct a random image from the test data.
    I pass the image through the encoder and then through the decoder, creating a
    “reconstruction” of the image. Then I plot the original and reconstructed images
    side by side and compare them visually, looking to see that they are close to
    identical.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Next, I visualize how well it is performing as an overall generative model by
    generating and plotting an image from scratch. I run this code once each time
    a certain number of epochs are run.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.14 Setting up a test evaluation procedure
  id: totrans-218
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '#1 Calculate and print test loss.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Compare a random test image to its reconstruction.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Generate a random image from the model.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Now we’ll run the training. For a single epoch, we’ll iteratively get a batch
    of data from the training data loader and pass it to the step method and run a
    training step. After a certain number of epochs (a number set by `TEST_FREQUENCY`),
    we’ll use our helper functions to compare a random image to its reconstruction,
    as well as simulate an image from scratch and plot it.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.15 Running training and plotting progress
  id: totrans-224
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#1 Run the training procedure for a certain number of epochs.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Run a training step on one batch in one epoch.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '#3 The test data evaluation procedure runs every 10 epochs.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Again, see [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for a link to a Jupyter notebook with the full VAE, encoder/decoder, and training
    code, including a link for running it in Google Colab.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.4 Evaluating training
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At certain points during training, we randomly choose an image and “reconstruct”
    it by passing the image through the encoder to get a latent value of *Z*, and
    passing that value back through the decoder. In one run, the first image I see
    is a non-handwritten number 6\. Figure 5.12 shows this image and its reconstruction.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: During training, we also simulate random images from the generative model and
    plot it. Figure 5.13 shows the first simulated image in one run—in this case,
    the number 3.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F12_Ness.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 The first attempt to reconstruct an image during training shows
    the model has learned something but still has much progress to make.
  id: totrans-234
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F13_Ness.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 The first instance of an image generated from the generative model
    during training
  id: totrans-236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: But the model learns quickly. By 130 epochs, we get the results in figure 5.14.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: After training is complete, we can see a visualization of loss over training
    (negative ELBO) in figure 5.15.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: The code will train the parameters of the encoder that maps images and the labels
    to the latent variable. It will also train the decoder that maps the latent variable
    and the labels to the image. That latent variable is a fundamental feature of
    the VAE, but we should take a closer look at how to interpret the latent variable
    in causal terms.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F14_Ness.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
- en: Figure 5.14 Reconstructed and randomly generated images from the model after
    130 epochs of training look much better.
  id: totrans-241
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F15_Ness.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
- en: Figure 5.15 Test loss as training progresses. The *x*-axis is the epoch.
  id: totrans-243
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 5.2.5 How should we causally interpret Z?
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I said we can view *Z* as a “stand-in” for all the independent latent causes
    of the object in the image. *Z* is a representation we learn from the pixels in
    the images. It is tempting to treat that representation like a higher-level causal
    abstraction of those latent causes, but it is probably not doing a great job as
    a causal abstraction. The autoencoder paradigm trains an encoder that can take
    an image and embed it into a low-dimensional representation *Z*. It tries to do
    so in a way that enables it to reconstruct the original image as well as possible.
    In order to reconstruct the image with little loss, the framework tries to encode
    as much information from the original image as it can in that lower dimensional
    representation.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: A good *causal* representation, however, shouldn’t try to capture as much information
    as possible. Rather, it should strive to capture only the *causal* information
    in the images and ignore everything else. Indeed, the task of “disentangling”
    the causal and non-causal factors in *Z* is generally impossible when *Z* is unsupervised
    (meaning we lack labels for *Z*). However, domain knowledge, interventions, and
    semi-supervision can help. See [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for references on *causal representation learning* and *disentanglement of causal
    factors*. As we progress through the book, we’ll develop intuition for what the
    “causal information” in such a representation should look like.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.6 Advantages of this causal interpretation
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There is nothing inherently causal about our VAE’s setup and training procedure;
    it is typical of a vanilla supervised VAE you’d see in many machine learning settings.
    The only causal element of our approach was our interpretation. We say that the
    *digit* and *is-handwritten* are causes, and *Z* is a stand-in for latent causes,
    and the image is the outcome. Applying the causal Markov property, our causal
    model factorizes the joint distribution into *P*(*Z*), *P*(*is-handwritten*),
    *P*(*digit*), and *P*(*image*|*Z*, *is-handwritten*, *digit*), where the latter
    factor is the causal Markov kernel of the image.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: What can we do with this causal interpretation? First, we can use it to improve
    deep learning and general machine learning workflows and tasks. We’ll see an example
    of this with *semi-supervised learning* in the next section.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: Incorporating generative AI in causal models is not limited to VAEs
  id: totrans-250
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: I demonstrated how to use a VAE framework to fit a causal Markov kernel entailed
    by a causal DAG, but a VAE was just one approach to achieving this end. We could
    have used another deep probabilistic machine learning framework, such as a generative
    adversarial network (GAN) or a diffusion model.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we incorporated deep learning into a causal graphical model.
    Next, we investigate how to use causal ideas to enhance deep learning.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Using causal inference to enhance deep learning
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can use causal insights to improve how we set up and train deep learning
    models. These insights tend to lead to benefits such as improved sample efficiency
    (i.e., doing more with less data), the ability to do transfer learning (using
    what a model learned in solving one task to improve performance on another), data
    fusion (combining different datasets), and enabling more robust predictions.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Much of the work of deep learning is trial and error. For example, when training
    a VAE or other deep learning models, you typically experiment with different approaches
    (VAE vs. another framework), architectural choices (latent variable and hidden
    layer dimension, activation functions, number of layers, etc.), and training approaches
    (choice of loss function, learning rate, optimizer, etc.) before you get a good
    result. These experiments cost time, effort, and resources. In some cases, causal
    modeling can help you make better choices about what might work and what is unlikely
    to work, leading to cost savings. In this section, we’ll look at a particular
    example of this case in the context of semi-supervised learning.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.1 Independence of mechanism as an inductive bias
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Suppose we had a DAG with two variables: “cause” *C* and “outcome” *O*. The
    DAG is simply *C* → *O*. Our causal Markov kernels are *P*(*C*) and *P*(*O*|*C*).
    Recall the idea of *independence of mechanism* from chapter 3—the causal Markov
    kernel *P*(*O*|*C*) represents a mechanism of how the cause *C* drives the outcome
    *O*. That mechanism is distinct from other mechanisms in the system, such that
    changes to those mechanisms have no effect on *P*(*O*|*C*). Thus, knowing about
    *P*(*O*|*C*) tells you nothing about the distribution of the cause *P*(*C*) and
    vice versa. However, knowing something about the distribution of the outcome *P*(*O*)
    might tell you something about the distribution of the cause given the outcome
    *P*(*C*|*O*), and vice versa.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate, consider a scenario where *C* represents sunscreen usage and
    *O* indicates whether someone has sunburn. You understand the *mechanism* by which
    sunscreen protects against sunburn (UV rays, SPF levels, regular application,
    the perils of sweat and swimming, etc.), and by extension, the chances of getting
    sunburn given how one uses sunscreen, captured by *P*(*O*|*C*). However, this
    understanding of the mechanism doesn’t provide any information about how *common*
    sunscreen use is, denoted by *P*(*C*).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Now, suppose you’re trying to guess whether a sunburned person used sunscreen,
    i.e., you’re mentally modeling *P*(*C*|*O*). In this case, knowing the prevalence
    of sunburns, *P*(*O*), could help. Consider whether the sunburned individual was
    a case of someone who did use sunscreen but got a sunburn anyway. That case would
    be more likely if sunburns were a common problem than if sunburns were rare—if
    sunburns are common, sunscreen use is probably common, but if sunburns were uncommon,
    people would be less cautious about prevention.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, suppose *C* represents study effort and *O* represents test scores.
    You know the causal mechanism behind how studying more causes higher test scores,
    captured by *P*(*O*|*C*). But this doesn’t tell you how common it is for students
    to study hard, captured by *P*(*C*). Suppose a student got a low test score, and
    you are trying to infer whether they studied hard—you are mentally modeling *P*(*C*|*O*).
    Again, knowing the typical distribution of test scores *P*(*O*) can help. If low
    scores are rare, students might be complacent, and thus more likely not to study
    hard. You can use that insight as an *inductive bias*—a way to constrain your
    mental model of *P*(*C*|*O*).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Causal inductive bias
  id: totrans-261
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: “Inductive bias” refers to the assumptions (explicit or implicit) that lead
    an inference algorithm to prefer certain inferences or predictions over others.
    Examples of inductive bias include Occam’s Razor and the assumption in forecasting
    that trends in the past will continue into the future.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: Modern deep learning relies on using neural network architectures and training
    objectives to encode inductive bias. For example, “convolutions” and “max pooling”
    are architectural elements in convolutional neural networks for computer vision
    that encode an inductive bias called “translation invariance”; i.e., a kitten
    is still a kitten regardless of whether it appears on the left or right of an
    image.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Causal models provide inductive biases in the form of causal assumptions about
    the DGP (such as a causal DAG). Deep learning can leverage these causal inductive
    biases to attain better results just as it does with other types of inductive
    biases. For example, independence of mechanism suggests that knowing *P*(*O*)
    could provide a useful inductive bias in learning *P*(*C*|*O*).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Now consider two variables *X* and *Y* (which can be vectors) with joint distribution
    *P*(*X*, *Y*). We want to design an algorithm that solves a task by learning from
    data observed from *P*(*X*, *Y*). The chain rule of probability tells us that
    *P*(*X*=*x*, *Y*=*y*) = *P*(*X*=*x*|*Y*=*y*)*P*(*Y*=*y*) = *P*(*Y*=*y*|*X*=*x*)*P*(*X*=*x*).
    So, from that basic probabilistic perspective, modeling the set {*P*(*X*|*Y*),
    *P*(*Y*)} is equivalent to modeling the set {*P*(*Y*|*X*), *P*(*X*)}. But consider
    the cases where either *X* is a cause of *Y* or where *Y* is a cause of *X*. Under
    these circumstances, the independence of mechanism gives us an asymmetry between
    sets {*P*(*X*|*Y*), *P*(*Y*)} and {*P*(*Y*|*X*), *P*(*X*)} (specifically, {*P*(*Y*|*X*),
    *P*(*X*)} represents the independent mechanism behind *X*’s causal influence on
    *Y*, and {*P*(*X*|*Y*), *P*(*Y*)} does not) that we can possibly leverage as an
    inductive bias in these algorithms. Semi-supervised learning is a good example.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '5.3.2 Case study: Semi-supervised learning'
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Returning to our TMNIST-MNIST VAE-based causal model, suppose we had, in addition
    to our original data, a large set of images of digits that were unlabeled (i.e.,
    *digit* and *is-handwritten* are not observed). Our causal interpretation of our
    model suggests we can leverage this data during training using semi-supervised
    learning.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Independence of mechanism can help you determine when semi-supervised learning
    will be effective. In *supervised learning*, the training data consists of *N*
    samples of *X*, *Y* pairs; (*x*[1], *y*[1]), (*x*[2], *y*[2]), …, (*x*[*N*], *y*[*N*]).
    *X* is the *feature data* used to predict the *labels* *Y*. The data is “supervised”
    because every *x* is paired with a *y*. We can use these pairs to learn *P*(*Y*|*X*).
    In *unsupervised learning*, the data *X* is unsupervised, meaning we have no labels,
    no observed value of *Y*. Our data looks like (*x*[1]), (*x*[2]), …, (*x*[*N*]).
    With this data alone, we can’t directly learn anything about *P*(*Y*|*X*); we
    can only learn about *P*(*X*). Semi-supervised learning asks the question, suppose
    we had a combination of supervised and unsupervised data. Could these two sets
    of data be combined in a way such that our ability to predict *Y* was better than
    if we only used the supervised data? In other words, can learning more about *P*(*X*)
    from the unsupervised data somehow augment our learning of *P*(*Y*|*X*) from the
    supervised data?
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: The semi-supervised question is quite practical. It is common to have abundant
    unsupervised examples if labeling those examples is costly. For example, suppose
    you worked at a social media site and were tasked with building an algorithm that
    classified whether an uploaded image depicted gratuitous violence. The first step
    is to create supervised data by having humans manually label images as gratuitously
    violent or not. Not only does this cost many people-hours, but it is mentally
    stressful for the labelers. A successful semi-supervised approach would mean you
    could minimize the amount of labeling work you need to do.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Our task is to learn a representation of *P*(*X* ,*Y*) and use it to predict
    from *P*(*Y*|*X*). For semi-supervised learning to work, the unlabeled values
    of *X* must update the representation of *P*(*X* , *Y*) in a way that provides
    information about *P*(*Y*|*X*). However, independence of mechanism means the task
    of learning *P*(*X* ,*Y*) decomposes into learning distinct representations of
    the causal Markov kernels, where the parameter vector of each representation is
    orthogonal to the others. That parameter modularity (see section 3.2) can block
    flow of parameter updating information from the unlabeled observations of *X*
    to the learned representation of *P*(*Y*|*X*). To illustrate, let's consider two
    possibilities, one where *Y* is a cause of *X*, and one where *X* is a cause of
    *Y*. If *Y* is a cause of *X*, such as in our MNIST-TMNIST example (*Y* is the
    is-handwritten and digit variables, and *X* is the image), then our learning task
    decomposes into learning distinct representations of *P*(*X*|*Y*) and P(Y). Unlabeled
    observations of *X* can give us a better representation of *P*(*X*), we can use
    to flip *P*(*X*|*Y*) into *P*(*Y*|*X*) by way of Bayes rule. However, when *X*
    is a cause of *Y*, our learning task decomposes into learning distinct representations
    of *P*(*X*) and *P*(*Y*|*X*). That parameter modularity means those unlabeled
    values of *X* will help us update *P*(*X*)’s representation but not that of *P*(*Y*|*X*).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F16_Ness.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
- en: Figure 5.16 In causal learning, the features cause the label. In anti-causal
    learning, the label causes the features.
  id: totrans-272
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The case where the feature causes the label is sometimes called *causal learning*
    because the direction of the prediction is from the cause to the effect. *Anti-causal
    learning* refers to the case when the label causes the feature. The two cases
    are illustrated in figure 5.16.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Independence of mechanism suggests semi-supervised learning can achieve performance
    gains (relative to a baseline of supervised learning on only the labeled data)
    only in the anti-causal case. See the chapter notes at www.altdeep.ai/causalAIbook
    for a more detailed explanation and references. But intuitively, we can see that
    this mirrors the the sunscreen and sunburn example—knowing the prevalence of sunburns
    *P*(*O*) helped in learning how to guess sunscreen use when you know if someone
    has a sunburn *P*(*C*|*O*). In this same anti-causal learning case, having only
    observations from *P*(*X*) can still be helpful in learning a good model of *P*(*Y*|*X*).
    But in the causal learning case, it would be a waste of effort and resources.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the causal structure between *X* and *Y* could be more nuanced
    and complicated than these simple *X*→*Y* and *X*←*Y* cases. For example, there
    could be unobserved common causes of *X* and *Y*. The takeaway here is that when
    you know something about the causal relationships between the variables in your
    machine learning problem, you can leverage that knowledge to model more effectively,
    even if the task is not a causal inference task (e.g., simply predicting *Y* given
    *X*). This could help you avoid spending time and resources on an approach that
    is not likely to work, as in the semi-supervised case. Or it could enable more
    efficient, robust, or better performing inferences.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.3 Demystifying deep learning with causality
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our semi-supervised learning example highlights how a causal perspective can
    explain when we’d expect semi-supervised learning to work and when to fail. In
    other words, it somewhat *demystifies* semi-supervised learning.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: That mystery around the effectiveness of deep learning methods led AI researcher
    Ali Rahimi to compare modern machine learning to alchemy.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Alchemy worked. Alchemists invented metallurgy, ways to dye textiles, modern
    glass-making processes, and medications. Then again, alchemists also believed
    they could cure diseases with leeches and transmute base metals into gold.
  id: totrans-279
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In other words, alchemy works, but alchemists lacked an understanding of the
    underlying scientific principles that made it work when it did. That *mystery*
    made it hard to know when it would fail. As a result, alchemists wasted considerable
    effort on dead ends (philosopher’s stones, immortality elixirs, etc.).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Chapter checkpoint
  id: totrans-281
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*Incorporating deep learning into a causal model:*'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: ✓ A causal model of a computer vision problem
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: ✓ Training the deep causal image model
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '*Using causal reasoning to enhance machine learning:*'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: ✓ Case study on independence of mechanism and semi-supervised learning
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: 👉 Demystifying deep learning with causality
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, deep learning “works” in that it achieves good performance on a wide
    variety of prediction and inference tasks. But we often have an incomplete understanding
    of why and when it works. That *mystery* has led to problems with reproducibility,
    robustness, and safety. It also leads to irresponsible applications of AI, such
    as published work that attempts to predict behavior (e.g., criminality) from profile
    photos. Such efforts are the machine learning analog of the alchemical immortality
    elixirs that contained toxins like mercury; they don’t work *and* they cause harm.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: We often hear about the “superhuman” performance of deep learning. Speaking
    of superhuman ability, imagine an alternative telling of Superman’s origin story.
    Imagine if, when Superman made his first public appearance, his superhuman abilities
    were unreliable? Suppose he demonstrated astounding superhuman feats like flight,
    super strength, and laser vision, but sometimes his flight ability failed and
    his super strength faltered. Sometimes his laser vision was dangerously unfocused,
    resulting in terrible collateral damage. The public would be impressed and hopeful
    that he could do some good, but unsure if it would be safe to rely on him when
    the stakes were high.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Now imagine that his adoptive Midwestern parents, experts in causal inference,
    used causal analysis to model the *how* and *why* of his powers. Having demystified
    the mechanisms underlying his superpowers, they were able to engineer a pill that
    stabilized those powers. The pill wouldn’t so much give Superman new powers; it
    would just make his existing powers more reliable. The work of developing that
    pill would get fewer headlines than flight and laser vision, but it would be the
    difference between merely having superpowers and being Superman.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: This analogy helps us understand the impact of using causal methods to demystify
    deep learning and other machine learning methods. Less mystery leads to more robust
    methods and helps us avoid wasteful or harmful applications.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning can be used to enhance causal modeling and inference. Causal reasoning
    can enhance the setup, training, and performance of deep learning models.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Causal models can leverage the ability of deep learning to scale and work with
    high-dimensional nonlinear relationships.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use generative AI frameworks like the variational autoencoder to build
    a causal generative model on a DAG just as we did with pgmpy.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The decoder maps the outcomes of direct parents (the labels of an image) to
    the outcomes of the child (the image).
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In other words, the decoder gives us a nonlinear high-dimensional representation
    of the causal Markov kernel for the image.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The encoder maps the image variable and the causes (labels) back to the latent
    variable *Z*.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can view the learned representation of the latent variable as a stand-in
    for unmodeled causes, but it still lacks the qualities we’d expect from an ideal
    causal representation. Learning latent causal representations is an active area
    of research.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Causality often enhances deep learning and other machine learning methods by
    helping elucidate the underlying principles that make it work. For example, causal
    analysis shows semi-supervised learning should work in the case of *anti-causal
    learning* (when the features are *caused by* the label) but not in the case of
    *causal learning* (when the features cause the label).
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Such causal insights can help the modeler avoid spending time, compute, person-hours,
    and other resources on a given algorithm when it is not likely to work in a given
    problem setting.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Causal insights can demystify elements of building and training deep learning
    models, such that they become more robust, efficient, and safe.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
