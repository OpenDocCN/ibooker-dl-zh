- en: 1 Introduction to the use of generative AI in data analytics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 生成式AI在数据分析中的应用介绍
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Introducing key limitations of generative AI models
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍生成式AI模型的几个关键局限性
- en: The role of generative AI in data analytics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI在数据分析中的作用
- en: Getting started using LLMs to support data analytics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用LLMs支持数据分析
- en: 'As the dust over the generative AI hype begins to settle and the notes of disappointment
    mix in with the chorus of praises, it may be a good time to ask yourself a question:
    “If LLMs aren’t the silver bullet to all world problems, what are they really
    good for?” Our experience using these amazing tools to improve various processes
    gave us the answer. They are really good, and we mean *really* *good* in supporting
    improvements for different processes. Throughout this book, we will guide you
    through our methods for utilizing the enormous potential hidden in the matrices
    of generative AI to improve your analytics skills without falling victim to the
    risks inherent in this technology.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当生成式AI的炒作尘埃开始落定，失望的音符与赞扬的合唱交织在一起时，可能是一个问自己问题的好时机：“如果LLMs不是解决所有世界问题的银弹，它们究竟有什么真正的用途？”我们使用这些令人惊叹的工具来改进各种流程的经验给了我们答案。它们真的很棒，我们说的“真的很棒”是指它们在支持不同流程的改进方面真的很出色。在这本书中，我们将引导你了解我们利用生成式AI矩阵中隐藏的巨大潜力来提高你的分析技能的方法，同时避免这项技术固有的风险。
- en: Under the hood  To excel in these goals, you will preferably have in the back
    of your mind what drives the responses you get to your prompts. However, due to
    the architecture-agnostic nature of this book and the rapidly changing technology
    landscape, we have consciously avoided the technological nitty-gritty, focusing
    instead on process implementation. We encourage you, though, to get a good overview
    of what’s what. You can learn it from several Manning books, such as *The Complete
    Obsolete Guide to Generative AI* by David Clinton or *Introduction to Generative
    AI* by Numa Dhamani and Maggie Engler. For the technical details of GPT models,
    see *How GPT Works* by Drew Farris, Edward Raff, and Stella Biderman.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 内部结构  为了在这些目标上取得卓越成绩，你最好在心中牢记是什么驱使你从提示中获得的响应。然而，由于本书的架构无关性质和快速变化的技术环境，我们有意避免了技术细节，而是专注于过程实施。尽管如此，我们鼓励你获得一个全面的了解。你可以从几本Manning出版的书籍中学习，例如David
    Clinton的《生成式AI的完整过时指南》或Numa Dhamani和Maggie Engler的《生成式AI入门》。关于GPT模型的技术细节，请参阅Drew
    Farris、Edward Raff和Stella Biderman的《GPT是如何工作的》。
- en: In this chapter, you will learn about three important aspects of working with
    generative AI. As we strongly believe that first things should indeed be first,
    we’ll start by presenting the inherent limitations of generative AI. We already
    mentioned the misalignment between the expectations and results of generative
    AI applications. A good understanding of the unavoidable limitations is critical
    to avoid disappointments at your work. The second aspect is related to embedding
    generative AI into the data analytics process. This part of the chapter will help
    you develop your first intuition about when and how to use generative AI when
    trying to solve an analytical problem. We will also manage expectations when it
    comes to automating processes involving generative AI. The last part of the chapter
    will provide you with knowledge about methods of accessing generative AIs. In
    the lion’s share of cases, browser-based access to chat would be sufficient, but
    history teaches us that this may not be an advisable method when working with
    sensitive data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解与生成式AI合作的重要三个方面。因为我们坚信，首要之事确实应该是首要的，所以我们将首先介绍生成式AI的固有局限性。我们已经提到了生成式AI应用中期望与结果之间的不匹配。对不可避免的局限性的良好理解对于避免工作中的失望至关重要。第二个方面与将生成式AI嵌入数据分析过程相关。本章的这一部分将帮助你形成关于何时以及如何使用生成式AI来解决分析问题的第一直觉。我们还将管理涉及生成式AI的自动化过程的期望。本章的最后一部分将为你提供关于访问生成式AI的方法的知识。在大多数情况下，基于浏览器的聊天访问就足够了，但历史告诉我们，当处理敏感数据时，这可能不是一个明智的方法。
- en: The overall goal of this chapter is not to give you encyclopedic knowledge of
    this technology, but to ensure you have a deep enough understanding to demystify
    generative AI and allow for a more critical interpretation of its abilities.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的总体目标不是给你提供关于这项技术的百科全书式知识，而是确保你对它有足够的理解，以便揭开生成式AI的神秘面纱，并允许对其能力进行更批判性的解读。
- en: 1.1 Inherent limitations of generative AI models
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 生成式AI模型的固有局限性
- en: In the Middle Ages, map edges had the inscription *Hic sunt dracones* (Latin
    for “Here be dragons”). You also may find monsters depicted in areas of uncharted
    waters. Later, the dragons, sirens, and krakens were replaced with depictions
    of reefs, shoals, and ice fields. We would like you to consider our warnings as
    the latter, rather than the former. For any endeavor, knowing the dangers to be
    wary of is at least as important as knowing what benefits to hope for.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在中世纪，地图的边缘刻有“Hic sunt dracones”（拉丁语意为“这里有龙”）。你也许还会在未知的海洋区域找到描绘的怪物。后来，龙、女妖和海怪被描绘为暗礁、浅滩和冰原。我们希望您将我们的警告视为后者，而不是前者。对于任何一项事业，了解需要警惕的危险至少与了解希望得到的利益一样重要。
- en: 'The following list outlines the inherent limitations of any generative AI system.
    Some of them may be reduced or even removed in the future, but reading about a
    potentially obsolete limitation will cost you less than being unaware of even
    one that remains valid. So, here are the treacherous waters we should be aware
    of:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表概述了任何生成式AI系统的固有局限性。其中一些可能在将来减少甚至消除，但了解一个可能过时的局限性所花费的成本要低于对仍然有效的任何一个局限性的无知。因此，以下是我们应该警惕的险恶水域：
- en: '*Generative AIs will always provide an answer (even if it’s a wrong one)*—Like
    a child who finished their “why?” phase, or an overpromoted manager with heavy
    impostor syndrome, generative AIs, when asked a question, know everything and,
    as their first reaction, are unable to admit the limits of their knowledge. One
    of the main reasons you really want to read this book is because generative AIs
    can be convinced otherwise. In chapter 8, we’ll also discuss the model’s sensitivity
    to input phrasing. Slightly rephrasing a question may result in different answers
    with varying degrees of quality and relevance. It’s worth noting that, since prompts
    are usually supplied in natural language, this sensitivity is slightly different
    than for search engines. The latter only react to clusters of keywords, whereas
    generative AI may provide a different response based not just on the keywords,
    but also on the grammatical structure of the prompt, its perceived emotional tone
    of writing, and the context created by recent exchanges.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*生成式AI总是会提供一个答案（即使它是错误的)*—就像完成了“为什么？”阶段的孩子，或者是一个过度提升的管理者，有着严重的冒充者综合症，生成式AI在被问及问题时，知道一切，并且作为他们的第一反应，无法承认他们知识的局限性。你真正想读这本书的主要原因之一就是生成式AI可以被说服否则。在第8章，我们还将讨论模型对输入语法的敏感性。稍微改写一个问题可能会导致不同质量、相关性的答案。值得注意的是，由于提示通常以自然语言提供，这种敏感性略不同于搜索引擎。后者只对关键词簇做出反应，而生成式AI可能会根据提示的关键词、语法结构、写作感知的情感基调以及最近交流产生的上下文提供不同的回答。'
- en: '*Some of the answers might be entirely made up*—There are instances where generative
    AI provides an answer that appears plausible but is not based on facts or directly
    linked to the training material. This is because the model sometimes fills in
    gaps in its knowledge by generating content that aligns with the patterns observed
    in the training data, even if the information is not accurate or complete. We
    will cover this problem in chapter 7, when we discuss the phenomenon of AI hallucinations.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*一些答案可能是完全虚构的*—存在这样的情况，生成式AI提供的答案看似合理，但实际上并非基于事实或与训练材料直接相关。这是因为模型有时会通过生成与训练数据中观察到的模式一致的内容来填补其知识中的空白，即使信息不准确或不完整。我们将在第7章讨论AI幻觉现象时，涵盖这个问题。'
- en: '*Inherent sycophancy*—The larger the model at the base of generative AI, the
    more likely it is to exercise agreeability over reliability and accuracy. If confronted
    or questioned about the provided answer, it’s likely to apologize and present
    the point of view contradicting its previous statement, even if it was correct
    the first time—truth be damned! Generative models can even make up numbers and
    falsify references to support the user’s perspective!'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*固有的谄媚性*—生成式AI的基础模型越大，就越有可能在可靠性、准确性与顺从性之间选择顺从性。如果面对或质疑提供的答案，它很可能会道歉并呈现与其先前陈述相矛盾的观点，即使第一次是正确的—真理见鬼去吧！生成模型甚至可以编造数字和伪造参考资料来支持用户的观点！'
- en: '*Inaccurate or outdated information*—Each generative AI’s knowledge is derived
    from the content corpus it was trained on. The model may provide outdated or incorrect
    information depending on the knowledge cutoff. This will be visible in examples
    in this book, where the model gives answers using API calls or programming language
    structures from obsolete versions. This is not as severe a limitation as it might
    initially seem. First, the majority of the concepts covered don’t evolve that
    quickly, and most people will have a lot of ground to cover in the basics before
    they reach the need to tap the latest developments. Second, many generative AIs
    have access to the internet. However, mixing the time-constrained body of knowledge
    used to train the model with continuous updates may lead to inaccurate results.
    It’s also worth remembering that some generative AIs only check the internet for
    the latest information when directly prompted.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*不准确或过时的信息*—每个生成式AI的知识来源于其训练所用的内容语料库。模型可能会根据知识截止点提供过时或不正确的信息。这在本书的例子中会很明显，模型会使用API调用或编程语言结构从过时的版本中给出答案。这并不像最初看起来那样严重。首先，大多数概念的变化并不快，大多数人需要在达到需要利用最新发展之前，在基础知识方面有很多要覆盖。其次，许多生成式AI可以访问互联网。然而，将用于训练模型的受时间限制的知识体系与持续更新混合可能会导致不准确的结果。还值得记住的是，一些生成式AI只有在直接被提示时才会检查互联网上的最新信息。'
- en: '*Input and output limits*—When using generative AIs, you should be aware that
    the amount of text they can process (the amount of input they can read as a whole
    and, on this basis, generate the output) is limited, although it can vary greatly
    between different models and implementations. The unit of text processed by generative
    AI is called a *token*, and it can be a word, part of a word, or a punctuation
    mark, depending on the tokenization method employed. Tokenization algorithms translate
    text into tokens with an average of 4 tokens per 3 words, or 0.75 words per token
    (this value should be relatively stable). At the time of writing this book, models
    have context windows ranging from several thousand up to millions of tokens, and
    the race to truly limitless context is full-on. For now, however, the available
    tools offer a limited number of input (prompt) and output (response) tokens, and
    you should remember that the context window covers both. You will get no warning
    if some data falls out of the window (no pun intended) and gets forgotten. Such
    truncation will usually manifest itself by the model giving responses inconsistent
    with previous exchanges, showing it has forgotten previous prompts or responses.
    In section 1.3, we present methods for estimating the number of tokens used. As
    a way of dealing with this limitation, you may frequently summarize the conversation
    and its key findings to ensure they are not left out of the context window.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*输入和输出限制*—在使用生成式AI时，你应该意识到它们可以处理文本的数量（它们可以整体读取的输入量，以及在此基础上生成输出）是有限的，尽管不同模型和实现之间的差异可能很大。生成式AI处理文本的单位称为*标记*，它可以是一个单词、单词的一部分或一个标点符号，这取决于所采用的标记化方法。标记化算法将文本转换为标记，平均每3个单词有4个标记，或者每个标记0.75个单词（这个值应该是相对稳定的）。在撰写本书时，模型有从几千到数百万个标记的上下文窗口，真正无限上下文的竞赛正在进行中。然而，目前可用的工具提供的输入（提示）和输出（响应）标记数量有限，你应该记住上下文窗口覆盖了这两者。如果某些数据超出窗口范围（无意中用了双关语）并被遗忘，你将不会收到任何警告。这种截断通常表现为模型给出与前一次交流不一致的响应，表明它已经忘记了之前的提示或响应。在第1.3节中，我们介绍了估算使用标记数量的方法。作为一种处理这种限制的方法，你可能需要经常总结对话及其关键发现，以确保它们不会从上下文窗口中遗漏。'
- en: '*Verbosity*—When you try some prompts, it will quickly become apparent that
    generative AIs generate overly verbose responses or overuse certain phrases (e.g.,
    they tend to “unwaveringly delve into vast landscapes of the rich tapestry of
    intricacies of…” anything they encounter). This verbosity can be attributed to
    biases or patterns in the training data, where longer responses, or responses
    of a particular structure, might be more common.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*冗长*—当你尝试一些提示时，很快就会很明显，生成式AI会生成过于冗长的响应或过度使用某些短语（例如，它们倾向于“坚定不移地深入到丰富复杂的错综复杂性的广阔领域中的...”任何它们遇到的东西）。这种冗长可以归因于训练数据中的偏差或模式，其中较长的响应或特定结构的响应可能更常见。'
- en: '*Biased or inappropriate content*—Despite efforts to reduce harmful and biased
    content, generative AIs, especially those fine-tuned on unknown data, may still
    generate responses that exhibit biases or produce content that could be considered
    inappropriate. This can result from some biases still being present in the training
    data, biases that are hidden or purposefully included in the prompts, or a multitude
    of other overlapping factors. However, the developers of most generative AIs have
    gone to great lengths to balance the model’s responses. An example can be found
    in the GPT-4 System Card document (https://cdn.openai.com/papers/gpt-4-system-card.pdf).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*有偏见或不适当的内容*——尽管努力减少有害和有偏见的内容，生成式AI，尤其是那些在未知数据上微调的AI，仍然可能生成表现出偏见或产生被认为不适当的内容的响应。这可能是由于训练数据中仍然存在一些偏见，这些偏见隐藏或故意包含在提示中，或者是由众多其他重叠因素造成的。然而，大多数生成式AI的开发者已经竭尽全力来平衡模型的响应。一个例子可以在GPT-4系统卡文档（https://cdn.openai.com/papers/gpt-4-system-card.pdf）中找到。'
- en: He said, she said  You can help generative AI provide correct, or at least useful,
    answers by providing underlying LLMs with the ability to search additional data
    sources and require linking answers to sources. You can learn more about that
    form from *Generative AI in Action* by Amit Bahree or *AI-Powered Search* by Trey
    Grainger, Doug Turnbull, and Max Irwin, both available from Manning Publications.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 他说，她说——你可以通过为底层LLM提供搜索额外数据源的能力，并要求将答案与来源链接，来帮助生成式AI提供正确或至少有用的答案。你可以从Amit Bahree的《生成式AI实战》或Trey
    Grainger、Doug Turnbull和Max Irwin的《AI驱动搜索》中了解更多信息，这两本书都由Manning Publications出版。
- en: A word to the wise  The prompt/response size limit and the verbosity can often
    lead to incomplete or cut-off responses. When designing a conversation with a
    generative AI, one option is to ensure that the combined length of the prompt
    and expected response doesn’t exceed the token limit.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对智者而言——提示/响应大小限制和冗长性往往会导致不完整或截断的响应。在设计与生成式AI的对话时，一个选择是确保提示和预期响应的总长度不超过令牌限制。
- en: Awareness of these limitations is crucial when you are interacting with generative
    AIs or incorporating them into various applications. Continued research and development
    aim to address these limitations and improve the performance and safety of generative
    AIs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当你与生成式AI互动或将它们纳入各种应用时，对这些限制的认识至关重要。持续的研究和开发旨在解决这些限制，并提高生成式AI的性能和安全。
- en: 1.2 The role of generative AIs in data analytics
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 生成式AI在数据分析中的作用
- en: On groups and forums focused on generative AIs, there are dozens of questions
    to the effect of “Where can I find a GenAI-based tool that does [very specific
    task description here]?” Even if a requested tool does not exist yet, it probably
    will, and soon. And it’s all good. Data warehouses, lakes, lakehouses, meshes,
    fabrics, and so on replace Excel files, data in emails, and napkins (if not for
    all intended purposes). Dashboards and self-serve business intelligence (BI) platforms
    replace manually created reports and PowerPoint presentations (OK, questions about
    using generative AI to create, modify, or improve PowerPoint slides are the most
    common). However, beware of silver bullets. Only 0.5% of data collected in data
    warehouses, lakes, and so on is ever analyzed, while the remaining 99.5% generates
    costs and big-data hangover to companies that over-eagerly started to collect
    the data without a data utilization plan. BI platforms, in turn, are filled to
    the brim with rogue analytics (for example, data slicing and dicing that serves
    no purpose other than the justification of poor business decisions).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在专注于生成式AI的群组和论坛上，有大量类似“我在哪里可以找到一个基于生成式AI的工具来完成[此处非常具体的任务描述]？”的问题。即使请求的工具目前还不存在，它可能很快就会出现。而且这都没问题。数据仓库、湖泊、湖屋、网格、织物等等正在取代Excel文件、电子邮件中的数据以及便条（如果不是所有目的的话）。仪表板和自助式商业智能（BI）平台正在取代手动创建的报告和PowerPoint演示文稿（好吧，关于使用生成式AI创建、修改或改进PowerPoint幻灯片的问题是最常见的）。然而，要小心那些万能的解决方案。在数据仓库、湖泊等地方收集的数据中，只有0.5%被分析过，而剩下的99.5%则给那些没有数据利用计划而过于急切地开始收集数据的公司带来了成本和大数据后遗症。反过来，BI平台则充满了无用的分析（例如，那些除了为糟糕的商业决策提供正当理由之外没有其他目的的数据切片和切块）。
- en: The effectiveness of generative AI use in data analytics will depend on your,
    the data analyst’s, ability to harness the possibilities and overcome the limitations
    of this new tool. Generative AIs, like any tool or technology, cannot be expected
    to do all the work. Let’s look closely at what we are dealing with and at generative
    AI’s differences from and similarities to other elements of the data analytics
    flow, namely the analytical process and software.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI在数据分析中的有效性将取决于你，作为数据分析师，利用这种新工具的可能性并克服其局限性的能力。生成式AI，就像任何工具或技术一样，不能期望它做所有的工作。让我们仔细看看我们正在处理的内容，以及生成式AI与数据分析流程中其他元素（即分析过程和软件）的不同和相似之处。
- en: Until now, we have leaned toward the doom-and-gloom side of things, giving you
    a lot of warnings about generative AI’s limitations and discouraging you from
    jumping onto every tool labeled as “GenAI-powered” (we have an internal betting
    pool regarding when the first toothbrush labeled as such will hit the market).
    We did this on purpose as we noticed that overinflated expectations are the main
    blocker to the efficient use of this amazing tool. Now let’s get out of this shadow
    of doubt and step into the light of the bright generative AI-supported future
    of data analytics.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，我们倾向于悲观的一面，给你提供了很多关于生成式AI局限性的警告，并劝阻你不要盲目跳上任何标有“GenAI-powered”标签的工具（我们内部有一个关于第一个标有此类标签的牙刷何时进入市场的赌局）。我们故意这样做，因为我们注意到过高的期望是阻碍高效使用这个神奇工具的主要因素。现在让我们摆脱这个怀疑的阴影，步入数据分析光明的生成式AI支持的未来的光明之中。
- en: 1.2.1 Generative AI in the data analytics flow
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 数据分析流程中的生成式AI
- en: Years and years of working with data has convinced us that its value does not
    come from the complexity of the utilized technologies. We’ve seen millions of
    dollars saved with a simple breakdown of costs done by process rather than by
    organizational unit. We’ve seen millions of dollars lost because an overcomplicated
    market analysis involving dozens of tools and teams poorly reflected actual customer
    sentiments. *Data analysis is not about transforming raw data into charts. It’s
    about supporting business decisions using conclusions from relevant business data.*
    Your success in this endeavor will depend on a couple of aspects, of which the
    available tooling is just one.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 年复一年与数据打交道让我们坚信，其价值并非来源于所使用技术的复杂性。我们见证了通过按流程而非按组织单位进行简单的成本分解，节省了数百万美元。我们也看到了因为涉及数十种工具和团队的过度复杂的市场分析，导致数百万美元的损失，因为这些分析并没有很好地反映实际客户情绪。*数据分析并非是将原始数据转化为图表。它是利用相关业务数据的结论来支持业务决策。*
    在这项事业中，你的成功将取决于几个方面，其中可用的工具只是其中之一。
- en: 'Different types of data and different business questions require different
    analytic pipelines. If you work in a retail company, you most likely seek insights
    into customer behavior. Your pipeline may begin with the collection and cleaning
    of data from multiple sources: transaction records, customer feedback, and website
    interactions. Once the data is scrubbed and standardized, you will process it
    through algorithms performing customer segmentation, product affinity analysis,
    and sales forecasting. Working with a healthcare provider, your input data would
    include patient electronic health records, medical imaging, and sensor data from
    wearable devices. Your processing would employ algorithms for disease diagnosis,
    treatment optimization, and patient outcome prediction. If you find yourself in
    a manufacturing firm, you’ll be integrating data from IoT sensors on the factory
    floor, quality control checks, and supply chain logistics, with the analytics
    focused on anomaly detection, predictive maintenance, and supply/demand forecasting.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的数据和不同的商业问题需要不同的分析流程。如果你在一家零售公司工作，你很可能寻求对客户行为的洞察。你的流程可能从收集和清理来自多个来源的数据开始：交易记录、客户反馈和网站互动。一旦数据被清洗和标准化，你将通过执行客户细分、产品亲和力分析和销售预测的算法来处理这些数据。与医疗保健提供者合作时，你的输入数据将包括患者的电子健康记录、医学影像和可穿戴设备的传感器数据。你的处理将采用用于疾病诊断、治疗优化和患者结果预测的算法。如果你发现自己身处一家制造企业，你将整合来自工厂地面物联网传感器的数据、质量控制检查和供应链物流数据，分析将集中在异常检测、预测性维护和供需预测上。
- en: 'Irrespective of what you’re analyzing and for whom, the essence of the process
    remains the same: collect and clean input data, process it using more or less
    advanced algorithms, and finally, present the results to the desired audience.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你分析的是什么以及为谁分析，过程的本质保持不变：收集和清理输入数据，使用更多或更少的先进算法进行处理，最后，将结果呈现给目标受众。
- en: The details differ greatly depending on the business area, data sources, analytical
    methods applied, and expected output format. Each of these topics warrants a book
    (or six) on how to most effectively perform each of these steps, taking into account
    both cost and time, using this or that technology stack.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 具体细节因业务领域、数据来源、应用的分析方法以及预期的输出格式而大相径庭。每个这些主题都值得有一本书（或六本）来讲述如何最有效地执行每个步骤，考虑到成本和时间，使用这个或那个技术栈。
- en: This book does not aim to answer all possible questions about all the possible
    scenarios you may encounter in your work as a data analyst. We offer you something
    much, much better. We propose a structured method to effectively use generative
    AIs’ unbelievable knowledge repository (from Wikipedia to scientific papers, to
    books and literature, to dialogue data, to the Pile ([https://pile.eleuther.ai/](https://pile.eleuther.ai/)),
    and so on) to prepare an analytical pipeline tailor-made to solve exactly your
    problem.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本书并不旨在回答你作为数据分析师在工作中可能遇到的所有可能场景的所有可能问题。我们提供给你更好的东西。我们提出了一种结构化方法，有效地利用生成式人工智能难以置信的知识库（从维基百科到科学论文，到书籍和文献，到对话数据，到Pile（[https://pile.eleuther.ai/](https://pile.eleuther.ai/）），等等），以准备一个定制的分析流程，专门解决你的问题。
- en: The missing link  The scale of generative AIs’ abilities is only starting to
    be explored. However, it’s already clear that they can be taught to respond consistently
    and relevantly on a wide range of topics. They have the ability to drill down
    into details, summarize, explain, and associate related concepts to an extraordinary
    degree. These abilities can be used to effectively unblock your own thinking and
    get you out of your rut. You no longer have to trawl through dozens of random
    articles trying to find inspiration or pointers. Just ask a question. Even if
    the answer is imperfect, it may point you to concepts you haven’t thought of before.
    Use this to expand your horizons.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失的环节  生成式人工智能的能力规模才刚刚开始被探索。然而，已经很明显，它们可以被训练在广泛的主题上做出一致且相关的回应。它们有能力深入细节，总结，解释，并将相关概念以非凡的程度联系起来。这些能力可以有效地解开你的思维，帮助你走出困境。你不再需要翻阅数十篇随机文章来寻找灵感或线索。只需提出一个问题。即使答案不完美，也可能指向你之前未曾考虑过的概念。利用这一点来拓宽你的视野。
- en: 'In the preface, we identified a question you should ask yourself every time
    you encounter a new analytical problem: *where do I star**t*? Searching for the
    right input data might not be the worst possible choice, especially if it’s accompanied
    by an analysis of what input data is actually relevant. Let’s assume you work
    in a healthcare unit and get a question like “What are the average patient waiting
    times on Tuesdays?”, or you work in retail and are asked to analyze, “How do our
    customers use loyalty cards?” Do not be fooled by the simplicity of the former
    question. They can, in fact, both be tricky.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在序言中，我们确定了一个你应该在遇到每个新的分析问题时问自己的问题：*我从哪里开始*？寻找正确的输入数据可能不是最糟糕的选择，尤其是如果它伴随着对哪些输入数据实际上相关的分析。让我们假设你在一个医疗单位工作，收到一个像“周二平均患者等待时间是多长？”这样的问题，或者你在一个零售业工作，被要求分析“我们的客户如何使用忠诚度卡？”不要被前者问题的简单性所迷惑。实际上，它们都可能很棘手。
- en: The flow presented in figure 1.1 will help guide you through the crucial steps
    in going from the question to decision-enabling conclusions, focusing on getting
    the most added value from both the human and generative AI along the way, while
    avoiding the common pitfalls. It can be applied to any analytical task and technology
    stack you may have. All the examples you’ll encounter in this book will follow
    this general structure.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1中展示的流程将帮助你指导从问题到决策支持结论的关键步骤，专注于在过程中从人类和生成式人工智能中获得最大附加值，同时避免常见的陷阱。它可以应用于任何分析任务和技术栈。本书中你将遇到的全部示例都将遵循这一通用结构。
- en: '![figure](../Images/CH01_F01_Siwiak3.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F01_Siwiak3.png)'
- en: Figure 1.1 Recommended generative AI–supported data analysis flow
  id: totrans-36
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.1 推荐的生成式人工智能支持的数据分析流程
- en: You always need to start with a problem statement. Let’s look at our healthcare
    example. We were asked a question about waiting times on Tuesdays; however, issues
    around waiting times on a specific day are more likely to be the symptom of a
    deeper problem. The question you get asked will not often translate directly into
    an effective problem statement. We should ask ourselves, “What real problem are
    we looking at here?” While it’s the job of the final decision maker to define
    the scope of the requested analysis, the guided questions can get you into a much
    better starting position for your analysis and, ultimately, provide more value
    from the analyzed data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你始终需要从一个问题陈述开始。让我们看看我们的医疗例子。我们被问及周二等待时间的问题；然而，特定日期的等待时间问题更有可能是更深层次问题的症状。你被问到的的问题通常不会直接转化为一个有效的问题陈述。我们应该问自己，“我们在这里真正面对的是什么问题？”虽然最终决策者的工作是定义请求分析的范围，但引导性问题可以帮助你进入分析的一个更好的起点，并最终从分析数据中获得更多价值。
- en: Now, the fun part. Even if the request comes from an area of operations you
    don’t have experience with, generative AI can help you put the received request
    into a business context without bothering your stakeholders with unnecessary inquiries!
    Let’s try a couple of generative AI on our Tuesdays-specific question.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，有趣的部分来了。即使请求来自你缺乏经验的运营领域，生成式AI也能帮助你将收到的请求放入业务背景中，而无需打扰你的利益相关者进行不必要的查询！让我们尝试用几个生成式AI来回答我们关于周二的具体问题。
- en: '**![image](../Images/Init-MA.png)**I work in a healthcare unit. I’ve been asked
    to answer a question: “What is the average waiting time for patients on Tuesdays?”
    What do you think could be some actual reasons behind such a question?'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Init-MA.png)**我在一个医疗单位工作。我被要求回答一个问题：“周二患者的平均等待时间是多长？”你认为这个问题背后可能有哪些实际原因？'
- en: The answers are too long to include here, but both OpenAI’s ChatGPTs (3.5 and
    4), Google Gemini and Gemini Pro, and Meta’s Llama 2 (13B) provided lists of possible
    project types where such an analysis could be of importance. The answers generally
    involve planning and budgeting (including resource allocation and staffing optimization),
    patient experience and quality of care, operational efficiency, and staff training.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 答案太长，无法在此处列出，但OpenAI的ChatGPT（3.5和4）、Google Gemini和Gemini Pro，以及Meta的Llama 2（13B）都提供了可能的项目类型列表，在这些项目中这样的分析可能很重要。这些答案通常涉及规划和预算（包括资源分配和人员优化）、患者体验和护理质量、运营效率和员工培训。
- en: 'Depending on your knowledge of current projects in your environment, you may
    come back with more or less specific questions, which shouldn’t be considered
    a waste of time. For example, if you ask a stakeholder asking for an analysis
    a follow-up question like, “Is it connected to our latest focus on increasing
    patient satisfaction?”, you could get an answer like, “Oh yeah, we’ve often heard
    complaints about Tuesdays, and we want to try to do something about it.” Once
    you understand that patient complaints and waiting times are the root issues behind
    the original question about waiting times on Tuesdays, your final problem statement
    may look something like this: “What is the distribution of waiting times and its
    correlation with patient satisfaction?” This question balances specificity with
    scope, aiming to uncover actionable insights that can directly influence patient
    care protocols and satisfaction.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你对环境中当前项目的了解，你可能会有更具体或更不具体的问题，这不应该被视为浪费时间。例如，如果你向请求分析的利益相关者提出一个后续问题，比如，“这与我们最近关注提高患者满意度有关吗？”，你可能会得到这样的回答，“哦，是的，我们经常听到关于周二的投诉，我们想尝试做些什么。”一旦你了解到患者投诉和等待时间是周二等待时间原始问题背后的根本问题，你的最终问题陈述可能看起来像这样：“等待时间的分布及其与患者满意度的相关性是什么？”这个问题在具体性和范围之间取得平衡，旨在揭示可以直接影响患者护理协议和满意度的可操作见解。
- en: The level of detail you disclose about your project in conversations with your
    generative AI advisor should be tailored to the confidentiality requirements of
    your analysis and the specifics of your generative AI setup. It’s advisable to
    share more freely within a locally managed software environment than on public
    platforms. This topic, including the associated risks of employing generative
    AI, is explored further in chapter 8.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在与你的生成式AI顾问的对话中，你关于项目的详细程度应该根据你分析的秘密性要求和你的生成式AI设置的具体情况来调整。在本地管理的软件环境中比在公共平台上更自由地分享是明智的。这个主题，包括使用生成式AI的相关风险，将在第8章中进一步探讨。
- en: You can then try querying generative AI about the best ways to answer the final
    question.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以尝试向生成式AI查询回答最终问题的最佳方法。
- en: '**![image](../Images/Init-MA.png)**And how could I approach analysis leading
    to answering the question: “What is the distribution of waiting times and its
    correlation with patient satisfaction?”'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**![图片](../Images/Init-MA.png)**我该如何进行分析，以回答以下问题：“等待时间的分布及其与患者满意度的相关性？”'
- en: Yet again, the answers are quite lengthy and detailed. They offer you seven-
    to nine-step approaches, which, with additional iterative inquiries, should allow
    you to construct a robust pipeline. Chapter 3 provides a practical example of
    using generative AI to develop a detailed analysis design from an extremely vague
    request (unfortunately, likely to be encountered in the real world). Here, our
    aim is to show you that the value of generative AIs extends beyond just answering
    highly specific queries. Their utility isn’t really reliant on the craft of “prompt
    engineering.” Instead, it depends on your readiness to present the full scope
    of your problem and to recognize that (as in the case of any meaningful conversation
    with a well-informed colleague) you’re unlikely to receive a flawless answer on
    the first attempt. Instead, expect to engage in an iterative process, refining
    broad concepts to meet your particular requirements.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这些答案相当长且详细。它们提供了七到九步的方法，通过额外的迭代查询，应该可以帮助您构建一个稳健的流程。第三章提供了一个使用生成式AI从极其模糊的要求（不幸的是，在现实世界中可能会遇到）开发详细分析设计的实际例子。在这里，我们的目标是向您展示生成式AI的价值不仅限于回答高度具体的问题。它们的实用性并不真正依赖于“提示工程”的技巧。相反，它取决于您准备好展示您问题的全部范围，并认识到（就像与任何知识渊博的同事进行有意义的对话一样）您不太可能在第一次尝试就收到完美的答案。相反，您应该期待参与一个迭代过程，将广泛的概念细化以满足您的特定需求。
- en: Inquiring into details of the analysis or code and discussing the received results
    are common for all the steps of your analytical process on all levels of granularity.
    You should use them as elements of the flow of the whole project and when going
    through detailed substeps, such as when cleaning the data or formatting the final
    charts. Generative AI can help you clarify what you want to achieve at any given
    moment, determine how to effectively get there, and test if what you got is what
    you wanted.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析或代码的细节上进行询问，并讨论收到的结果，是您分析过程所有步骤和所有粒度级别上的常见做法。您应该将它们作为整个项目流程的元素，并在进行详细子步骤时使用，例如在清理数据或格式化最终图表时。生成式AI可以帮助您在任何给定时刻明确您想要实现的目标，确定如何有效地达到那里，并测试您得到的是否正是您想要的。
- en: As we mentioned, generative AI will not replace analytical tools but help you
    optimize their use. Let’s have a look at the areas where they shine the brightest.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们提到的，生成式AI不会取代分析工具，而是帮助您优化它们的使用。让我们看看它们最闪耀的领域。
- en: 1.2.2 The complementarity of language models and other data analytics tools
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 语言模型和其他数据分析工具的互补性
- en: On their own, generative AIs are particularly well-suited for tasks involving
    text data, such as sentiment analysis, text classification, summarization, and
    question-answering. However, their potential extends beyond text-based tasks.
    Multimodal AIs like Google’s Gemini or OpenAI’s GPT-4 allow you to upload different
    types of files, with the latter accepting raw data in formats such as CSV. But
    as we mentioned before, your success as a data analyst will depend on your ability
    to utilize generative AIs in a wider analytical environment. Luckily, that’s precisely
    where you can get excellent support from generative AI. It’s like having an expert
    on a speed dial!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 单独来看，生成式AI特别适合涉及文本数据的工作，如情感分析、文本分类、摘要和问答。然而，它们的潜力并不仅限于基于文本的任务。像谷歌的Gemini或OpenAI的GPT-4这样的多模态AI允许您上传不同类型的文件，后者接受如CSV格式的原始数据。但正如我们之前提到的，您作为数据分析师的成功将取决于您在更广泛的分析环境中利用生成式AI的能力。幸运的是，这正是您可以获得出色支持的地方。这就像拥有一个专家随时可以联系！
- en: 'First, all generative AIs worth their mettle have deep knowledge of most analytical
    frameworks available on the market. They can help you navigate through a vast
    array of technologies to extract, process, analyze, and visualize data. Suppose
    you have data in a bunch of Excel files and are tasked with creating the dashboard
    in Power BI. Try dropping the following question into the generative AI of your
    choice:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，所有值得其价值的生成式AI对市场上大多数分析框架都有深入的了解。它们可以帮助您在众多技术中导航，以提取、处理、分析和可视化数据。假设您有一堆Excel文件中的数据，并被分配创建Power
    BI仪表板。尝试将以下问题放入您选择的生成式AI中：
- en: '**![image](../Images/Init-MA.png)**I have data in a bunch of Excel files and
    am tasked with creating the dashboard in Power BI. What shall I do?'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Init-MA.png)**我有一堆Excel文件中的数据，并被分配创建Power BI仪表板。我该怎么做？'
- en: You will get detailed instructions, including where to click to upload your
    data, basic options for modeling it, and, again, where to click to prepare a dashboard.
    And that’s just the first step of the iteration.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 您将获得详细的说明，包括点击上传数据的位置，建模的基本选项，以及再次点击准备仪表板的位置。这只是迭代的第一个步骤。
- en: Did your company just move from WordPress plugins to Google Analytics, but Google
    Tag Manager–based event tracking is needed for yesterday?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您的公司是否刚刚从WordPress插件迁移到谷歌分析，但需要基于谷歌标签管理器的基于事件的跟踪呢？
- en: '**![image](../Images/Init-MA.png)**I’m tasked with enhancing our website’s
    performance and need to leverage Google Tag Manager (GTM) for tracking various
    user interactions. Additionally, I must provide detailed reports in Google Analytics
    4 (GA4). I’m completely new to the Google environment. Can you please help?'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Init-MA.png)**我被分配了提升我们网站性能的任务，需要利用谷歌标签管理器（GTM）来跟踪各种用户交互。此外，我必须提供详细的报告到谷歌分析4（GA4）。我对谷歌环境一无所知。您能帮帮我吗？'
- en: You’ll get a good list of options, and you will be able to choose what’s right
    for your specific case. Again, no “prompt engineering” is needed. Just a good,
    old cry for help.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 您将获得一个很好的选项列表，您将能够选择适合您特定情况的选项。再次强调，不需要“提示工程”。只需一个老式的求助即可。
- en: Second, if you’re more invested in serious data analytics, language models can
    generate code in various programming languages, such as Python, R, Scala, or even,
    for the more adventurous, PHP, Perl, or even Cobol or Intercal. The best-known
    example of this concept implementation is the GitHub Copilot, with software like
    Bito, Tabnine, Codeium, and FauxPilot (and many more) following in its footsteps.
    This capability allows you to obtain ready-to-use code for data processing, analysis,
    and visualization tasks, saving time and effort. The generated code can vary in
    size and complexity, from short snippets and single functions serving as a starting
    point for customizing and refining analyses to whole algorithm implementations
    and modules, limited only by your imagination and patience to coax the model to
    spit it out. Unlike raw code snippets downloaded off the internet, generative
    AI will provide code suited exactly to your needs, and it has the invaluable ability
    to explain the code, as we’ll see in several examples in this book, and optimize
    it to your specifications.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，如果您更注重严肃的数据分析，语言模型可以在各种编程语言中生成代码，例如Python、R、Scala，甚至对于更有冒险精神的，PHP、Perl，甚至是Cobol或Intercal。这个概念的最佳实现例子是GitHub
    Copilot，Bito、Tabnine、Codeium、FauxPilot（以及更多）紧随其后。这种能力允许您获得用于数据处理、分析和可视化的现成代码，节省时间和精力。生成的代码大小和复杂度各异，从作为定制和优化分析起点的短代码片段和单个函数，到整个算法实现和模块，仅限于您的想象力和耐心来诱导模型输出。与从互联网下载的原始代码片段不同，生成式AI将提供完全符合您需求的代码，并且它具有在本书中我们将看到的几个例子中解释代码和优化到您指定规格的无价能力。
- en: This ability to generate and explain code will be the most helpful feature for
    us throughout the book, but it also comes with the biggest warning, which we’ll
    repeat in many places and cover in depth in chapter 7\. Specifically, never *trust*
    the model to spit out entirely correct answers or perfectly working code on the
    first try. The higher the importance or risk of your project, the more scrupulously
    you should verify any output through review and testing. In subsequent chapters,
    you’ll find examples of model-generated code that doesn’t work as expected or
    that has incorrect explanations attached to it. Caveat emptor!
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这种生成和解释代码的能力将是我们全书中最有帮助的功能，但它也伴随着最大的警告，我们将在许多地方重复并深入探讨第7章。具体来说，永远不要*信任*模型第一次就能吐出完全正确或完美工作的答案或代码。你的项目的重要性或风险越高，你就越应该仔细通过审查和测试来验证任何输出。在随后的章节中，你会找到一些模型生成的代码，这些代码不符合预期或附有错误的解释。买者自慎！
- en: Finally, once the analysis is performed, language models can help interpret
    the results by generating natural language summaries and explanations. This feature
    may help you understand the intricacies of complex analytical results and communicate
    your findings to a broader audience.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一旦分析完成，语言模型可以通过生成自然语言摘要和解释来帮助解释结果。这个功能可以帮助你理解复杂分析结果的细节，并将你的发现传达给更广泛的受众。
- en: 'There is an old story of a math professor complaining to his colleague about
    students: *I explained it to them three times, I finally understood it myself,
    and they still had questions*. With generative AI, you can allow yourself to be
    such a student, shamelessly pestering your advisor with questions until you’re
    comfortable with the answer.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个关于数学教授抱怨学生的老故事：*我给他们解释了三次，我自己最后才明白，他们仍然有疑问*。使用生成式AI，你可以让自己成为一个这样的学生，厚颜无耻地向你的导师提问，直到你对答案感到满意。
- en: If you wish to practice and feel audacious, start by pasting the following prompt
    into multiple generative AIs of your choice.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要练习并感到大胆，请先将以下提示粘贴到你选择的多个生成式AI中。
- en: '**![image](../Images/Init-MA.png)**I got a confidence interval of 0.55-0.9
    using the Wilson Score Interval (95% confidence level). How should I precisely
    communicate what it means for the performed test?'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Init-MA.png)**我使用威尔逊评分区间（95%置信水平）得到了0.55-0.9的置信区间。我应该如何精确地传达这个结果对所进行的测试的意义？'
- en: 'Statistics should be a very important part of your toolbox. Generative AI can
    help you avoid situations where stakeholders will evaluate your analyses on this
    scale: small lies, big lies, and statistics.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学应该是你工具箱中非常重要的一个部分。生成式AI可以帮助你避免利益相关者在这个尺度上评估你的分析的情况：小谎言、大谎言和统计数据。
- en: After reading the previous two sections, you should now feel excited about adding
    generative AI to your data analytics practice. We share that feeling every time
    we accomplish our tasks in a third or a quarter of the time they used to take.
    But, as always with generative AI, you need to be aware of some limitations.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读了前面的两个章节之后，你现在应该对将生成式AI添加到你的数据分析实践中感到兴奋。每次我们用三分之一或四分之一的时间完成任务，我们都会有这种感觉。但是，就像使用生成式AI时总是那样，你需要意识到一些局限性。
- en: 1.2.3 Limits of generative AIs’ ability to automate and streamline data analytics
    processes
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 生成式AI在自动化和简化数据分析流程方面的局限性
- en: While you can successfully employ generative AIs in all the applications listed
    previously and in the subsequent sections of this book (and more), their effectiveness
    in automating and streamlining data analytics processes has certain limitations.
    You can incorporate them into the data analytics domain, but their limitations
    make them an amazing supplement, not a replacement, for a data analyst.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你可以在本书前面列出的所有应用以及后续章节中成功使用生成式AI（以及更多），但它们在自动化和简化数据分析流程方面的有效性存在某些局限性。你可以将它们纳入数据分析领域，但它们的局限性使它们成为数据分析师的一个惊人的补充，而不是替代品。
- en: Lack of quantitative analysis skills
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 缺乏定量分析技能
- en: Generative AIs excel at understanding and generating natural language, but they
    lack the inherent ability to perform complex quantitative analysis (aka math).
    ChatGPT has already included an add-on running Python code on the fly (utilizing
    an external environment, not as a native LLM capability), and other generative
    AIs will probably follow suit, but the success rate of the generated analytical
    runs, as you’ll see in the following sections, is not something we’d wage the
    success of our business on. Data analytics processes often require mathematical
    and statistical methods, such as regression analysis, time-series forecasting,
    and clustering techniques. While generative AIs can suggest such methods and often
    offer the relevant code, the code must be thoroughly tested before it is put into
    the production environment.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI在理解和生成自然语言方面表现出色，但它们缺乏进行复杂定量分析（即数学）的内在能力。ChatGPT已经包含了一个运行Python代码的附加组件（利用外部环境，而不是作为原生LLM功能），其他生成式AI可能会效仿，但如以下章节所示，生成的分析运行的成功率并不是我们愿意赌上我们业务成功的东西。数据分析过程通常需要数学和统计方法，如回归分析、时间序列预测和聚类技术。虽然生成式AI可以建议这样的方法，并且经常提供相关的代码，但在将其投入生产环境之前，这些代码必须经过彻底的测试。
- en: Limited understanding of domain-specific concepts
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对特定领域概念的理解有限
- en: While generative AIs can generate human-like text based on the context provided,
    their training data may not include highly specialized domain knowledge. Consequently,
    their ability to accurately generate insights or recommendations in the context
    of specific industries or niche subjects may be limited. This problem is enhanced
    by the already mentioned inherent inability of generative AIs to admit their ignorance.
    Knowledge limitations differ between generative AI providers and can be somewhat
    mitigated by providing GenAI with internet access, but you really don’t want to
    base critical business decisions on an enthusiastic hallucination!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然生成式AI可以根据提供的内容生成类似人类的文本，但它们的训练数据可能不包括高度专业化的领域知识。因此，它们在特定行业或细分主题的背景下准确生成见解或建议的能力可能有限。这个问题通过前面提到的生成式AI固有的无法承认自己无知的能力而加剧。知识限制在不同生成式AI提供商之间有所不同，通过为GenAI提供互联网接入可以一定程度上缓解，但你真的不希望基于热情的幻觉来做出关键的商业决策！
- en: In the case of such specific needs, your best option is to provide the model
    with more general prompts and refine the answer based on your specialist knowledge.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种特定需求的情况下，你最好的选择是向模型提供更一般的提示，并根据你的专业知识对答案进行细化。
- en: Inability to interact with databases and APIs
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 无法与数据库和API交互
- en: Your work in data analytics will, more often than not, involve working with
    databases, APIs, or other data sources to extract, clean, and process data. Generative
    AIs lack the built-in capability to interact directly with these sources. While
    it is possible to integrate generative AIs with custom-built solutions to bridge
    this gap, doing so can be resource-intensive and challenging to implement effectively.
    As in the previous cases, the model can still be effectively used to guide your
    analysis and provide solutions or even whole swathes of code, which you can execute
    independently of the model.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你的数据分析工作往往需要与数据库、API或其他数据源交互，以提取、清洗和处理数据。生成式AI缺乏直接与这些来源交互的内置能力。虽然有可能将生成式AI与定制解决方案集成以弥合这一差距，但这可能需要大量资源，并且难以有效实施。正如前述案例，模型仍然可以有效地指导你的分析并提供解决方案，甚至是一整块代码，你可以独立于模型执行这些代码。
- en: Unreliable internet access
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 不可靠的互联网接入
- en: Some generative AIs, such as Google’s Gemini, are “internet native.” The internet
    connectivity is a natural part of their operations. For others, not so much. Self-hosted
    models, which you can download and run on your machine, such as Llama 2, need
    access to a search engine API and an implementation of so-called multistage reasoning,
    where in the first answer, the LLM decides what it needs to do to get the proper
    answer, and in the following steps, the architecture runs the internet search
    and provides the answer to the LLM, which on that basis can form the final response.
    ChatGPT 4 implements this in its web-based interface.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一些生成式AI，如谷歌的Gemini，是“互联网原生”的。互联网连接是它们操作的自然部分。对于其他一些AI，则不然。自托管模型，如Llama 2，你可以下载并在你的机器上运行，需要访问搜索引擎API和所谓的多阶段推理的实现，其中在第一个答案中，LLM决定它需要做什么才能得到正确的答案，在随后的步骤中，架构运行互联网搜索并向LLM提供答案，基于这个答案，LLM可以形成最终的响应。ChatGPT
    4在其基于网络的界面中实现了这一点。
- en: It seems complicated, and it is. The connectivity of self-hosted LLMs depends
    on external APIs and either a lot of code or fast-changing libraries. ChatGPT,
    in turn, sometimes forgets it can connect to the internet. When it was trained,
    it couldn’t, and this memory still lingers in its network’s deep layers. If your
    analysis depends on access to the latest data or news, you need to choose your
    tools very carefully.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎很复杂，确实如此。自托管LLM的连通性依赖于外部API和大量代码或快速变化的库。反过来，ChatGPT有时会忘记它可以连接到互联网。在它被训练的时候，它不能，这种记忆仍然留在其网络的深层中。如果您的分析依赖于访问最新的数据或新闻，您需要非常仔细地选择您的工具。
- en: In the following chapters of this book, we will show you how to apply this general-to-specific
    problem-solving path for the best results.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的后续章节中，我们将向您展示如何应用这种从一般到具体的解决问题的路径以获得最佳结果。
- en: 1.3 Getting started with generative AIs for data analytics
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 数据分析中生成式AI的入门
- en: There is an old Chinese proverb, “In the forest of algorithms, the path to wisdom
    has many branches.” Actually, there isn’t—ChatGPT generated it for us. We have
    tried to convey that, depending on the situation, you have more than one way to
    access your AI advisor. To utilize generative AI’s potential, you need to get
    comfortable with conversing with it, as most of the tools built upon it strip
    its answers of relevant nuance, but you should know your options here.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个古老的中国谚语，“在算法的森林中，通往智慧的道路有许多分支。”实际上，并没有——ChatGPT为我们生成了它。我们试图传达的是，根据情况，您有不止一种方式可以访问您的AI顾问。为了利用生成式AI的潜力，您需要习惯与它进行对话，因为建立在它之上的大多数工具都去除了其答案的相关细微差别，但您应该知道您在这里的选择。
- en: 1.3.1 Web interface
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 网络界面
- en: In this book, we will mainly use ChatGPT ([https://chat.openai.com](https://chat.openai.com))
    and Gemini([https://gemini.google.com](https://gemini.google.com)) as examples
    of generative AI. These are readily accessible (it’s more true than you’d like,
    as this access can be bidirectional—do not paste your confidential data there!),
    and the underlying language models are in constant, rapid development. There is
    also a chance that your company will have a self-hosted generative AI based on
    either of these or some other model, such as the *n*-th incarnation of Llama or
    Mixtral, but hopefully it will be accompanied by a proper web interface.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将主要使用ChatGPT ([https://chat.openai.com](https://chat.openai.com)) 和
    Gemini([https://gemini.google.com](https://gemini.google.com)) 作为生成式AI的例子。这些资源很容易获取（这比您想象的要真实，因为这种访问是双向的——不要在那里粘贴您的机密数据！），并且其底层语言模型正在不断、快速地发展。也有可能您的公司将基于这些或某些其他模型（如Llama或Mixtral的第n个版本）拥有自托管的生成式AI，但希望它将伴随着适当的网络界面。
- en: And the winner is…  *At the time of writing this book*, GPT 4 was by far the
    most useful of all the tested generative AIs for any analytics-related tasks.
    However, this *will* change (just not with GPT 4o). Keep your eyes open and don’t
    be shy when it comes to engaging new generative AIs and testing their usefulness.
    Each model has its own training dataset and an architecture influencing its interpretation
    of your prompts and the resulting answer. Just remember that the technicalities
    behind them are irrelevant from your perspective (unless they are related to cost-effectiveness,
    of course). What interests you, as a data analyst, is the model’s ability to support
    your process.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 而赢家是……  *在撰写本书时*，GPT 4在所有测试的生成式AI中对于任何与数据分析相关的任务来说是最有用的。然而，这*将会*改变（只是不是GPT 4o）。保持警觉，当涉及到参与新的生成式AI并测试其有用性时，不要害羞。每个模型都有其自己的训练数据集和影响其对提示的解释以及产生的答案的架构。只需记住，从您的角度来看，它们背后的技术细节是无关紧要的（除非它们与成本效益相关，当然）。作为数据分析师，您感兴趣的是模型支持您过程的能力。
- en: If you need specific models, you can search for one of half a million hosted
    on the AI-development website, www.huggingface.co. Some of them require downloading,
    but some can be run there. You can register for free, but extensive model use
    will require creating your own “Space” and purchasing processing power.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要特定的模型，您可以在AI开发网站www.huggingface.co上搜索其中的一半，即五十万个模型。其中一些需要下载，但也有一些可以直接在那里运行。您可以免费注册，但广泛使用模型将需要创建自己的“空间”并购买处理能力。
- en: The use of generative AI via web interface is as simple as writing a query and
    reading the answer. Sometimes, there will also be a button allowing you to upload
    files to be analyzed.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通过网络界面使用生成式AI就像撰写查询并阅读答案一样简单。有时，也会有按钮允许您上传要分析的文件。
- en: 1.3.2 Beware of tokens
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.2 警惕令牌
- en: If you plan to connect directly to a model, you must understand the critical
    difference between your and GenAIs’ perceptions of text. As explained earlier,
    generative AIs break down input text into manageable units known as *tokens*.
    This foundational step is critical, as it transforms raw text into a structured
    form that an AI model can efficiently process and learn from.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你计划直接连接到模型，你必须理解你和GenAIs对文本感知之间的关键差异。如前所述，生成式AI将输入文本分解成称为*标记*的可管理单元。这一基础步骤至关重要，因为它将原始文本转换成AI模型可以高效处理和学习的结构化形式。
- en: Tokenization involves dissecting the input text into a sequence of tokens. This
    process is not a mere splitting by whitespace; it’s more nuanced, incorporating
    an understanding of the language’s syntax and semantics. For instance, the word
    “don’t” may be tokenized into “do” and “n’t” to better capture its meaning and
    structure. Advanced models leverage subword tokenization schemes to balance the
    tradeoff between representing common words as single tokens and decomposing less
    common words into smaller, meaningful components. This approach enables the model
    to handle a vast vocabulary, including neologisms, with a fixed set of tokens.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 分词涉及将输入文本分解成一系列标记。这个过程不仅仅是按空白字符分割；它更加复杂，需要理解语言的语法和语义。例如，单词“don’t”可能被分词为“do”和“n’t”，以更好地捕捉其意义和结构。高级模型利用子词分词方案来平衡将常见单词表示为单个标记和将不常见单词分解成更小、更有意义的组件之间的权衡。这种方法使模型能够处理包括新词在内的广泛词汇，同时使用固定数量的标记。
- en: Tokens of Babel  The method of tokenization—how the words are split before processing—is
    specific for each model. This is a critical point, as using tokenization meant
    for one model as input for another may case the latter model to interpret the
    input as a meaningless, or worse, misleading, soup of semi-words misaligned with
    how the model’s training material has been prepared.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 巴别塔的标记法——分词的方法——在处理之前如何分割单词——对每个模型都是特定的。这是一个关键点，因为将一个模型用于另一个模型的分词作为输入可能会导致后者模型将输入解释为无意义，或者更糟，误导性的半词的混合体，这与模型训练材料准备的方式不符。
- en: As we warned you in section 1.1, when the input surpasses the context window,
    the earliest tokens are truncated, leaving the model with only the most recent
    tokens within its comprehension horizon. This truncation can lead to a loss of
    crucial context or information necessary for generating coherent and relevant
    responses. Have you ever been in a situation where someone overheard just the
    last couple sentences of a lengthy conversation and offered unsolicited advice?
    Such a response rarely adds to the conversation. Exceeding the context puts generative
    AI in a similar position. It’s “deaf” to parts of the conversation exceeding its
    context window. This is particularly dangerous if you work with a large piece
    of code!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在1.1节中警告你的那样，当输入超过上下文窗口时，最早的标记将被截断，模型将只剩下其理解范围内的最新标记。这种截断可能导致丢失生成连贯和相关信息所必需的关键上下文或信息。你是否曾经处于这样的情况：有人只听到了一段长对话的最后几句话，并提供了不请自来的建议？这样的回应很少能增加对话的价值。超出上下文窗口会使生成式AI处于类似的位置。它对超出其上下文窗口的对话部分“充耳不闻”。如果你处理的是大量代码，这尤其危险！
- en: Several strategies can be employed to navigate the constraints of limited context
    windows. One common method is chunking the input text into smaller segments that
    fit within the model’s context window, ensuring that each segment contains enough
    context to stand on its own for generation tasks. Another approach involves using
    techniques like sliding windows or iterative refinement, where the model progressively
    processes text, maintaining as much relevant context as possible across segments.
    For more complex interactions involving longer texts or conversations, strategies
    like creating a summary of previous interactions or leveraging external memory
    mechanisms can help maintain coherence.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 可以采用几种策略来应对有限上下文窗口的约束。一种常见的方法是将输入文本分成更小的段落，这些段落适合模型上下文窗口的大小，确保每个段落都包含足够的信息，可以独立用于生成任务。另一种方法涉及使用滑动窗口或迭代细化等技术，模型逐步处理文本，尽可能在段落之间保持尽可能多的相关上下文。对于涉及更长时间文本或对话的复杂交互，创建先前交互的摘要或利用外部记忆机制等策略可以帮助保持连贯性。
- en: 1.3.3 Accessing and using the API
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.3 访问和使用API
- en: For more advanced use cases and seamless integration with your existing data
    analysis tools, you can access most of the popular models via their application
    programming interface (API). These APIs suit various programming languages, including
    Python, JavaScript, and more. With API access, you can create custom applications,
    integrate generative AIs into your existing data analysis workflows, and even
    build GenAI-powered analytics dashboards.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更高级的使用案例和与现有数据分析工具的无缝集成，您可以通过它们的API访问大多数流行的模型。这些API适用于各种编程语言，包括Python、JavaScript等。通过API访问，您可以创建自定义应用程序，将生成式AI集成到现有的数据分析工作流程中，甚至构建由GenAI驱动的分析仪表板。
- en: To further simplify the process of integrating generative AIs into your data
    analysis projects, you can use available SDKs (software development kits) and
    libraries created by model or third-party developers, one of the most prominent
    being LangChain ([www.langchain.com](http://www.langchain.com)). These resources
    can save you time and effort when it comes to working with the API, as they provide
    prebuilt functions and classes that handle common tasks. You can find popular
    SDKs and libraries for various programming languages on platforms like GitHub.
    Make sure to check the compatibility and support status before using them in your
    projects.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步简化将生成式AI集成到您的数据分析项目中的过程，您可以使用由模型或第三方开发者创建的SDK（软件开发工具包）和库，其中最突出的是LangChain
    ([www.langchain.com](http://www.langchain.com))). 这些资源在处理API时可以节省您的时间和精力，因为它们提供了预构建的函数和类来处理常见任务。您可以在GitHub等平台上找到各种编程语言的流行SDK和库。在使用它们的项目之前，请确保检查其兼容性和支持状态。
- en: An example of programmatic access to ChatGPT
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 程序化访问ChatGPT的示例
- en: You can access different ChatGPT versions through the OpenAI API. This method
    allows you to programmatically send requests and receive responses, giving you
    greater control over the AI’s capabilities. Sign up for an API key on the OpenAI
    website to get started ([https://platform.openai.com/signup](https://platform.openai.com/signup)).
    Then, follow the API documentation to learn how to interact with ChatGPT using
    your preferred programming language.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过OpenAI API访问不同的ChatGPT版本。此方法允许您以编程方式发送请求并接收响应，从而让您对AI的能力有更大的控制权。在OpenAI网站上注册API密钥以开始使用（[https://platform.openai.com/signup](https://platform.openai.com/signup)）。然后，按照API文档学习如何使用您首选的编程语言与ChatGPT交互。
- en: To illustrate programmatic access, let’s look at an example of accessing the
    ChatGPT models from Python. Similar code will be used in some of the discussions
    in chapter 5 on using ChatGPT directly for data analysis. If you haven’t yet set
    up the OpenAI API, follow the instructions to install the library and set up an
    API key at the OpenAI signup page.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明程序化访问，让我们看看从Python访问ChatGPT模型的示例。在第五章关于直接使用ChatGPT进行数据分析的讨论中，将使用类似的代码。如果您尚未设置OpenAI
    API，请按照说明在OpenAI注册页面安装库并设置API密钥。
- en: A rose by any other name . . . Throughout this book, we’ll work with Python
    (in a Jupyter environment or any Unix environment). In chapter 7, we’ll show that
    generative AIs are also capable of supporting many other programming environments.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 爱上一朵花，无关乎它的名字……在这本书中，我们将使用Python（在Jupyter环境中或任何Unix环境中）。在第七章中，我们将展示生成式AI也支持许多其他编程环境。
- en: Once you have the OpenAI API, it is recommended that you assign it to the `OPENAI_API_KEY`
    variable in the environment, either through your shell setup (depending on your
    system) or, preferably, through a .env file in your project. You can then use
    the following simple Python code to interact with ChatGPT.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您拥有OpenAI API，建议您将其分配给环境中的`OPENAI_API_KEY`变量，无论是通过您的shell设置（取决于您的系统）还是，更理想的是，通过项目中的`.env`文件。然后，您可以使用以下简单的Python代码与ChatGPT交互。
- en: Listing 1.1 Interacting with ChatGPT through the API
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表1.1 通过API与ChatGPT交互
- en: '[PRE0]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding code sets up an example exchange to be further completed by the
    model. It exemplifies how the model can handle multiturn exchanges (for example,
    multiple question-answer iterations) with context. The main input is the `messages`
    array of message objects, where each object consists of two components:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码设置了一个示例交换，由模型进一步完成。它展示了模型如何处理带有上下文的多次交互（例如，多个问答迭代）。主要输入是`messages`数组中的消息对象，其中每个对象由两个组件组成：
- en: A `role`, either `system`, `user`, or `assistant`
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`角色`，可以是`system`、`user`或`assistant`
- en: The content
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内容
- en: A system-role message is typically included first, followed by alternating user
    and assistant messages. The system-role message sets up the background for the
    behavior of the assistant. The example in listing 1.1 modifies the assistant’s
    personality to reflect the style of responses we want it to take. This can be
    omitted, and without any specific tone or audience requirement, the model will
    reply in its usual helpful but flat language.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 系统角色消息通常首先包含，然后是交替的用户和助手消息。系统角色消息为助手的行性行为设定背景。列表1.1中的示例修改了助手的个性，以反映我们希望其采取的响应风格。这可以省略，如果没有特定的语气或受众要求，模型将以通常的有帮助但平淡的语言回复。
- en: The rest of the messages should consist of alternating user and assistant content,
    providing the model with the exchange context. Initially, you can provide one
    user message to which the model should respond. In subsequent exchanges, you can
    build up the message array with the history of prompts and responses to provide
    the model with a context of the exchange so far, allowing the model to relate
    better to subsequent prompts. By default, the models have no memory of past requests,
    and all the relevant information must be supplied as part of the message array
    in each request.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的消息应包含交替的用户和助手内容，为模型提供交流上下文。最初，您可以提供一个用户消息，模型应该对此做出回应。在随后的交流中，您可以通过提示和响应的历史记录构建消息数组，为模型提供迄今为止的交流上下文，使模型能够更好地关联后续提示。默认情况下，模型没有对过去请求的记忆，所有相关信息都必须作为消息数组的一部分在每个请求中提供。
- en: 'The `model` parameter specifies which instance of LLM we want to access. It’s
    best to refer to the OpenAI models website ([https://platform.openai.com/docs/models/](https://platform.openai.com/docs/models/))
    for the latest list of available models, as it changes quite frequently. To get
    started, a good choice would be to experiment with the following:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`model`参数指定我们想要访问的LLM实例。最好参考OpenAI模型网站([https://platform.openai.com/docs/models/](https://platform.openai.com/docs/models/))获取最新可用的模型列表，因为它变化相当频繁。要开始，一个好的选择是尝试以下内容：'
- en: gpt-4—The latest production version of the GPT 4 model
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gpt-4—GPT 4模型的最新生产版本
- en: gpt-4o—A younger, faster, if less thoughtful brother of GPT 4
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gpt-4o—GPT 4的一个年轻、快速但不太深思熟虑的兄弟
- en: gpt-3.5-turbo—Still a very good choice, and it can be more cost-effective in
    some cases
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gpt-3.5-turbo—仍然是一个非常好的选择，在某些情况下可能更具成本效益
- en: dall-e-3—Optimized for image generation
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: dall-e-3—优化用于图像生成
- en: tts-1—Designed to generate natural-sounding speech from text
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tts-1—旨在从文本生成自然语音
- en: whisper-1—Can recognize speech and transcribe it as text
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: whisper-1—能够识别语音并将其转录为文本
- en: New models are being developed continuously; the preceding list illustrates
    the breadth of capabilities already available. Obviously, for the models using
    images or sound as either input or output, more advanced programming techniques
    will be required to interact with them.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 新模型正在持续开发中；上述列表展示了目前已有的能力范围。显然，对于使用图像或声音作为输入或输出的模型，需要更高级的编程技术才能与之交互。
- en: 'Listing 1.1 used only one of the plethora of other optional parameters: `temperature`.
    As you can guess, this controls randomness in the model responses. Increasing
    `temperature` can generate interesting results, but it has a high risk of causing
    the model to hallucinate. Experimenting with this is very interesting, but please
    use it cautiously in production environments. We’ll touch more on hallucinations
    and related risks in chapter 8.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 列表1.1仅使用了众多其他可选参数中的一个：`temperature`。正如您所猜想的，这控制着模型响应中的随机性。增加`temperature`可以生成有趣的结果，但有很大的风险导致模型产生幻觉。在生产环境中谨慎使用这一点非常有趣，但请谨慎使用。我们将在第8章中更多地讨论幻觉和相关风险。
- en: Refer to the latest OpenAI documentation for other up-to-date information and
    additional parameters.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 参考最新的OpenAI文档以获取其他最新信息和附加参数。
- en: Programmatic access to other OpenAI API-compatible models
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 可通过编程访问其他与OpenAI API兼容的模型
- en: Many models are available in the market (over a million models in HuggingFace
    alone), each with its own interface. However, a lot of them are compatible with
    OpenAI API de facto standards, such as Meta’s Llama models.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 市面上有许多模型（仅HuggingFace就有超过一百万个模型），每个都有自己的界面。然而，许多模型实际上与OpenAI API的事实标准兼容，例如Meta的Llama模型。
- en: To access these models, you can just replace the OpenAI API call code in the
    previous example.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问这些模型，您只需替换前一个示例中的OpenAI API调用代码。
- en: Listing 1.2 Code to direct the client to a specific model, e.g., Llama
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表1.2：将客户端指向特定模型（例如，Llama）的代码
- en: '[PRE1]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The base URL parameter specifies the server hosting the model. Obviously, you’ll
    need to provide a specific API key, such as the Llama API token referenced here,
    as each provider will require their own user authentication.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, as you probably noticed, we used the “gpt-4-0125-preview” model
    in listing 1.1\. If you switch to Llama, you’ll need to provide a valid model,
    such as “llama-13b-chat” or one of the other available Llama variants. The rest
    of the code can remain unchanged most of the time.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Example of programmatic access to Google Vertex AI
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A slightly different API worth mentioning is the one defined by Google to access
    its powerful Gemini AI models, as well as Codey, which is optimized for code generation
    and completion, and Imagen, designed for image generation, editing, captioning,
    and visual question answering. Given the power of Google in the market, this API
    may also be a good contender for a standard in the future.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: The quickest way to access these models is through the Cloud Shell ([https://cloud.google.com/shell/docs/launching-cloud-shell](https://cloud.google.com/shell/docs/launching-cloud-shell)),
    which is a terminal, or command line, used to access cloud services. Once you
    activate the shell, you need to install the API.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.3 Command to install the Google AI package on Google Cloud
  id: totrans-125
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Then you can use the following script to generate completions from the selected
    model.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.4 Example code to call Vertex AI on Google Cloud
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The preceding code follows a similar flow as the OpenAI example. Apart from
    the project ID and location, which Google uses to authenticate access to the API,
    we need to specify which model we want to use. In this case, we chose “gemini-1.0-pro”,
    the basic text-only model. Google’s API also supports multimodal requests, including
    sound and images both in the input and response. A range of examples is available
    on the API web pages. We’d need to specify the “gemini-1.0-pro-vision” model for
    multimodal requests.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.4 also shows how to provide the `temperature` parameter, analogous
    to the one discussed in the OpenAI example, which is used to control the randomness
    in the responses.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: It’s worth mentioning that Google provides an interface for explicitly setting
    the safety parameters of the model to block unsafe content, based on a list of
    defined blocking thresholds (table 1.1). The safety parameters can limit the model
    when it comes to generating content containing harassment, hate speech, explicit
    sexuality, or that may otherwise be dangerous. The full list for the newest Google
    models is provided on Google’s AI website([https://ai.google.dev/gemini-api/docs/safety-settings](https://ai.google.dev/gemini-api/docs/safety-settings)).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Table 1.1 Blocking thresholds for configuring Google’s model safety parameters
  id: totrans-133
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Threshold name | Description |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
- en: '| `BLOCK_NONE`  | Always show, regardless of the probability of unsafe content.  |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
- en: '| `BLOCK_ONLY_HIGH`  | Block when there is a high probability of unsafe content.  |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
- en: '| `BLOCK_MEDIUM_AND_ABOVE` (default)  | Block when there is a medium or high
    probability of unsafe content.  |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
- en: '| `BLOCK_LOW_AND_ABOVE`  | Block when there is a low, medium, or high probability
    of unsafe content.  |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
- en: '| `HARM_BLOCK_THRESHOLD_UNSPECIFIED`  | The threshold is unspecified, so block
    using the default threshold.  |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
- en: In listing 1.4, we set very conservative parameters, `safety_config` `=` `{...}`,
    so the model would apply quite stringent filters to the output. This may result
    in a lower risk while the model is used, but at the cost of returning less useful
    responses to some prompts. Chapter 8 will offer a broader discussion of model
    risk considerations.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.4 Third-party integrations of generative AI models
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In addition to the methods mentioned in previous sections, you may also find
    a number of generative AI models integrated into various third-party applications
    and plugins. These integrations typically focus on specific use cases, such as
    code generation and completion, data visualization, natural language processing,
    or predictive analytics.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: 'These are some examples of such integrated models:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Copilot, designed to assist with code generation, completion, and explanation,
    with integrations available for the most common integrated development environments
    (IDEs), such as VSCode, Visual Studio, and the JetBrains suite of IDEs.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Packages within the RStudio IDE, like *air*, provide integration of LLM models
    into this popular R and Python environment.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The advantage of such integrations is that they usually have direct access to
    the data or code inside the host environment and are able to directly insert and
    modify the code, which saves the user the effort of copying each code snippet
    from the IDE to the model chat window and back again.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 1.3.5 Running LLMs locally
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Running any downloadable model on your personal computer isn’t rocket science.
    You don’t need NASA-grade equipment either; a decent PC with enough RAM should
    suffice (with a definition of “decent” being somewhat dynamic). A solid GPU would
    speed things up, but that is not an absolute requirement. You will need some familiarity
    with the command line and a couple of libraries to bridge the gap between ambition
    and reality.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at how we can use Python to connect to the Llama 2 model. Implementing
    it as advertised on Meta’s page is a bit daunting, so we’ll cheat a little. First,
    we’ll use a quantized model to save on RAM requirements. In essence, quantization
    of the model means “shaving off,” or rounding, the model weights, sacrificing
    a little accuracy in exchange for computational efficiency. We’ll also utilize
    models transitioned into an easy-to-use GGUF file format. If you requested and
    got a proper license from Meta, you can download the Llama of your choice from
    the HuggingFace portal.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Two libraries we propose to make your task easier are LangChain and llama-cpp-python.
    Overall, the environment setup is as simple as presented in listings 1.1 and 1.2\.
    It’s worth mentioning that LangChain could also be used to streamline connecting
    to ChatGPT or Gemini as well.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出的两个库可以帮助你简化任务，它们是LangChain和llama-cpp-python。总体来说，环境设置与列表1.1和1.2中展示的一样简单。值得一提的是，LangChain也可以用来简化连接到ChatGPT或Gemini的过程。
- en: Listing 1.5 Command to install the LangChain and Llama libraries
  id: totrans-152
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表1.5 安装LangChain和Llama库的命令
- en: '[PRE4]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: A word of fair warning. The llama-cpp-python library has some non-negotiable
    requirements, especially when installed in a Windows environment. However, as
    it’s a fast-developing tool, check the library site for the latest details.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一句。llama-cpp-python库在Windows环境下有一些不可协商的要求。然而，作为一个快速发展的工具，请检查库网站以获取最新详情。
- en: Now that we have our model downloaded and the proper libraries installed, all
    we need to do is send a prompt to a model and capture the result.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经下载了模型并安装了适当的库，我们所需做的就是向模型发送一个提示并捕获结果。
- en: Listing 1.6 Example of sending a prompt to Llama
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表1.6 向Llama发送提示的示例
- en: '[PRE5]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: And that’s it! Depending on your hardware and the chosen model size, you should
    get your answer in anywhere from a few seconds to a few minutes.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！根据你的硬件和所选模型大小，你应该能在几秒到几分钟内得到你的答案。
- en: Context is not only about tokens  The minimalistic implementation we have presented
    here does not have any conversation memory. It’s a shoot-and-forget method of
    getting a specific answer to a specific question. Implementing chat memory using
    LangChain is, however, relatively simple, and you should not be afraid to check
    the website for current instructions. Funnily enough, it even has an LLM-powered
    chatbot to answer your questions about the library.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文不仅仅是关于标记  我们在这里展示的最简实现没有任何对话记忆。它是一种针对特定问题的特定答案的射击和忘记的方法。然而，使用LangChain实现聊天记忆相对简单，你不必害怕查看网站上的当前说明。有趣的是，它甚至有一个由LLM驱动的聊天机器人来回答你关于库的问题。
- en: 'There are many options for both model instantiation and prompt development,
    which you may find useful. You’ll find detailed instructions on the LangChain
    library website (www.langchain.com). We will not dig into them deeper, as this
    simple setup is sufficient for our purposes: asking Llama a question and getting
    an answer.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型实例化和提示开发方面有许多选项，你可能觉得它们很有用。你可以在LangChain库网站上找到详细的说明（www.langchain.com）。我们不会深入探讨，因为这种简单的设置已经足够满足我们的需求：向Llama提问并获取答案。
- en: 1.3.6 Best practices and tips for successful generative AI implementation
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.6 成功实施生成式AI的最佳实践和技巧
- en: 'Although this book won’t cover advanced topics related to the direct integration
    of generative AI into applications using APIs, we encourage you to follow some
    best practices and consider the following tips to successfully integrate generative
    AIs with your data analytics solutions:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这本书不会涵盖与使用API将生成式AI直接集成到应用程序相关的先进主题，但我们鼓励你遵循一些最佳实践，并考虑以下提示，以成功地将生成式AI与你的数据分析解决方案集成：
- en: '*Define clear objectives*—Start by clearly identifying the goals and expectations
    of integrating generative AI into your data analytics solution. Determine the
    tasks you want generative AI to perform, such as data preprocessing, generating
    insights, or creating visualizations, and tailor your integration accordingly.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*定义明确的目标*——首先明确地将集成生成式AI到你的数据分析解决方案的目标和期望识别出来。确定你希望生成式AI执行的任务，例如数据预处理、生成洞察或创建可视化，并相应地调整你的集成。'
- en: '*Familiarize yourself with the API or SDK you are planning to use*—Thoroughly
    read and understand the OpenAI API documentation, including details about the
    API’s or SDK’s features, limitations, and best practices. This knowledge will
    help you design efficient and reliable interactions between generative AI and
    your data analytics tools.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*熟悉你计划使用的API或SDK*——仔细阅读并理解OpenAI API文档，包括API或SDK的功能、限制和最佳实践。这些知识将帮助你设计高效且可靠的生成式AI与你的数据分析工具之间的交互。'
- en: '*Use appropriate data formats*—Ensure that you are using compatible data formats
    when sending requests to and receiving responses from generative AI. Transform
    your data, if necessary, to ensure seamless integration and prevent data loss
    or misinterpretation.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用适当的数据格式*——确保你在向生成式AI发送请求和接收响应时使用兼容的数据格式。如有必要，转换你的数据，以确保无缝集成并防止数据丢失或误解释。'
- en: '*Monitor usage and costs*—Keep track of your API usage to prevent unexpected
    costs, especially when working with large datasets or complex analytics tasks.
    Implement rate limiting, caching, or other optimizations to manage your API calls
    and stay within your plan’s limits.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Handle errors and timeouts*—Implement proper error handling and retry mechanisms
    to deal with potential issues, such as timeouts or rate-limit errors. This will
    help ensure the stability and reliability of your integration.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Simplify and optimize your prompts*—Craft your prompts carefully to obtain
    the most accurate and relevant results from generative AI. Use clear, concise
    language, and provide enough context to help the AI understand your requirements.
    You may need to experiment with different prompt structures to find the best approach
    for your specific use case.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Maintain the prompt cheatsheet after optimizing (and verifying the output)*—Regularly
    update and refine your prompt notes as you continue to work with generative AI.
    As your application evolves and your understanding of AI capabilities deepens,
    your cheatsheet should evolve to include new findings, common errors to avoid,
    and updated best practices.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Provide source material and context*—Alongside the problem or question, give
    the model context data examples or explicitly ask it to follow a certain reasoning
    path. You can also suggest steps in the prompt for the model to follow in its
    reasoning or ask it to explain certain solution steps. All of this will ensure
    a greater probability of a correct response and increased transparency regarding
    how it was generated.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Evaluate the AI’s output*—Generative AI’s output may not always be accurate
    or relevant. Always double-check the results provided by the AI, and consider
    implementing human review or validation processes, especially for critical or
    high-stakes decisions.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Test and iterate*—Before fully integrating generative AI into your data analytics
    solution, thoroughly test its performance with various tasks and datasets. This
    will help you identify any issues, limitations, or inaccuracies. Continuously
    iterate on your prompts, data formats, and integration methods to improve the
    overall effectiveness of the AI in your analytics workflows.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Ensure data security and privacy*—When working with sensitive data, make sure
    you comply with data protection regulations and follow security best practices.
    If you’re working with cloud-based generative AI, encrypt data when transmitting
    it to and from the provider, and consider using data anonymization techniques
    to protect the privacy of your users.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Stay updated on generative AI developments*—Keep track of updates and new
    features developed in the field, as these may impact your integration or offer
    additional capabilities. Regularly review the API documentation, and subscribe
    to relevant newsletters or forums to stay informed about any changes or improvements
    to generative AI.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Leverage community resources*—Take advantage of resources provided by the
    AI community, such as sample code, tutorials, and forums. These resources can
    help you learn from others’ experiences and discover best practices for integrating
    generative AIs with various data analytics solutions.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*利用社区资源*—利用人工智能社区提供的资源，例如示例代码、教程和论坛。这些资源可以帮助你从他人的经验中学习，并发现将生成式人工智能与各种数据分析解决方案集成的最佳实践。'
- en: By following these best practices and tips, you can successfully integrate generative
    AI into your data analytics workflows and harness its full potential to enhance
    your decision-making, automate tasks, and uncover valuable insights.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这些最佳实践和技巧，你可以成功地将生成式人工智能集成到你的数据分析工作流程中，并充分利用其全部潜力来增强你的决策能力、自动化任务并揭示有价值的见解。
- en: Hopefully, after this introduction, generative AI no longer appears to be a
    mysterious and, possibly, useless invention. Subsequent chapters will demonstrate
    specific exchanges between a human and a generative AI and will show us using
    the responses in all aspects of data analytical work. We’ll also comment on the
    shortcomings and pitfalls that need to be looked out for to make this cooperation
    between humans and AI as painless and productive as possible.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 希望在这次介绍之后，生成式人工智能不再显得神秘，甚至可能无用。后续章节将展示人类与生成式人工智能之间的具体交流，并展示我们在数据分析工作的各个方面使用这些回应。我们还将评论需要警惕的缺点和陷阱，以使人类与人工智能之间的合作尽可能无痛且高效。
- en: Things to ask generative AI
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 询问生成式人工智能的事项
- en: What are your limitations?
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的局限性是什么？
- en: What is the knowledge base you’ve been built upon?
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你基于什么知识库构建？
- en: What is the latest version of <insert favorite analytics tool> that you know
    about?
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你知道关于<插入你最喜欢的分析工具>的最新版本是什么？
- en: Summary
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Generative AI and derivative tools have taken great strides in recent years
    and can be used as invaluable support in many fields, including data analytics.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 近年来，生成式人工智能及其衍生工具取得了巨大进步，可以在许多领域作为无价的支持，包括数据分析。
- en: Despite the progress, these tools won’t (yet!) replace a competent data analyst,
    and there are many limitations that users should be aware of.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管取得了进步，但这些工具（目前！）还不能取代合格的数据分析师，用户应该意识到许多局限性。
- en: At the same time, we encourage you to take full advantage of the immense possibilities
    of supporting your data analytical work with these language models, which can
    be done safely by following a few common-sense guidelines.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时，我们鼓励你充分利用这些语言模型支持你的数据分析工作的巨大可能性，这可以通过遵循一些常识性指南来安全地实现。
- en: The easiest way to access generative AIs is via their web interfaces, although
    APIs and SDKs can be used in more advanced applications.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问生成式人工智能最简单的方式是通过它们的网页界面，尽管在更高级的应用中可以使用API和SDK。
