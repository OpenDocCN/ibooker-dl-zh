<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="appendix" epub:type="appendix" data-pdf-bookmark="Appendix A. Practice Exam"><div class="appendix" id="practice_exam">
<h1><span class="label">Appendix A. </span>Practice Exam</h1>

<p>To check your answers, please refer to the <a data-type="xref" href="app02.html#exam_answers">“Practice Exam Answer Key”</a>.</p>

<ol>
<li><p>What is an availability zone (AZ)?</p>
<ol type="a">
<li><p>A physical data center containing multiple AWS servers</p></li>
<li><p>A logical partition of AWS infrastructure that provides redundancy</p></li>
<li><p>A security group that isolates AWS resources</p></li>
<li><p>A region that spans multiple continents</p></li>
</ol>
</li>

<li><p>Which cloud service model provides full applications to users without requiring them to manage infrastructure?</p>
<ol type="a">
<li><p>Infrastructure as a service (IaaS)</p></li>
<li><p>Platform as a service (PaaS)</p></li>
<li><p>Software as a service (SaaS) </p></li>
<li><p>Virtualization as a service (VaaS)</p></li>
</ol>
</li>

<li><p>What is a defining characteristic of the hybrid cloud model?</p>
<ol type="a">
<li><p>It exclusively uses private data centers for all workloads.</p></li>
<li><p>It combines public and private cloud environments. </p></li>
<li><p>It relies only on on-premises infrastructure.</p></li>
<li><p>It uses a multitenant model for security.</p></li>
</ol>
</li>
</ol>

<ol class="less_space pagebreak-before" start="4">
<li><p>What is a key advantage of AWS regions?</p>
<ol type="a">
<li><p>They eliminate the need for availability zones (AZs).</p></li>
<li><p>They allow customers to comply with data residency requirements.</p></li>
<li><p>They are only available in Asia.</p></li>
<li><p>They provide unlimited computing power without redundancy.</p></li>
</ol>
</li>

<li><p>Which AWS service allows developers to deploy applications without managing servers?</p>
<ol type="a">
<li><p>Amazon EC2</p></li>
<li><p>AWS Lambda</p></li>
<li><p>Amazon RDS</p></li>
<li><p>Amazon CloudFront</p></li>
</ol>
</li>

<li><p>Which of the following best describes Amazon S3?</p>
<ol type="a">
<li><p>A relational database service for structured data storage</p></li>
<li><p>A scalable object storage service designed for durability and availability</p></li>
<li><p>A high-performance compute service for running applications</p></li>
<li><p>A content delivery network (CDN) for accelerating web traffic</p></li>
</ol>
</li>

<li><p>What is the main benefit of using a confusion matrix to evaluate a machine learning (ML) model?</p>
<ol type="a">
<li><p>It shows the training time of the model.</p></li>
<li><p>It helps analyze false positives and false negatives.</p></li>
<li><p>It calculates the total number of data points used in training.</p></li>
<li><p>It eliminates the need for additional performance metrics.</p></li>
</ol>
</li>

<li><p>A bank wants to detect fraudulent transactions in real time. What type of inference should they use?</p>
<ol type="a">
<li><p>Batch inference</p></li>
<li><p>Asynchronous inference</p></li>
<li><p>Real-time inference</p></li>
<li><p>On-demand inference</p></li>
</ol>
</li>
</ol>

<ol class="less_space pagebreak-before" start="9">
<li><p>What is a major challenge when using high-dimensional datasets in machine learning (ML)?</p>
<ol type="a">
<li><p>It reduces the need for model tuning.</p></li>
<li><p>It increases computational costs and complexity.</p></li>
<li><p>It makes models interpret data more efficiently.</p></li>
<li><p>It ensures better accuracy for all ML tasks.</p></li>
</ol>
</li>

<li><p>A company notices that its deployed machine learning (ML) model is becoming less accurate over time due to changing customer behavior. What issue is this?</p>
<ol type="a">
<li><p>Model overfitting</p></li>
<li><p>Hyperparameter tuning issue</p></li>
<li><p>Feature engineering error</p></li>
<li><p>Drift</p></li>
</ol>
</li>

<li><p>What is the primary reason for using Amazon SageMaker Model Monitor?</p>
<ol type="a">
<li><p>To train deep-learning models faster</p></li>
<li><p>To automatically deploy machine learning (ML) models</p></li>
<li><p>To detect issues such as data drift and concept drift</p></li>
<li><p>To fine-tune pretrained models</p></li>
</ol>
</li>

<li><p>A business wants to improve the efficiency of their data processing pipeline by automating feature extraction and transformation. Which AWS tool is best suited for this?</p>
<ol type="a">
<li><p>Amazon Rekognition</p></li>
<li><p>Amazon Textract</p></li>
<li><p>Amazon SageMaker Data Wrangler</p></li>
<li><p>AWS Glue</p></li>
</ol>
</li>

<li><p>A software company wants to analyze customer feedback to determine whether reviews are positive, neutral, or negative. Which AWS service should they use?</p>
<ol type="a">
<li><p>Amazon Textract</p></li>
<li><p>Amazon Comprehend</p></li>
<li><p>AWS Lambda</p></li>
<li><p>Amazon SageMaker Feature Store</p></li>
</ol>
</li>
</ol>

<ol class="less_space pagebreak-before" start="14">
<li><p>What is the primary purpose of hyperparameter tuning in machine learning (ML)?</p>
<ol type="a">
<li><p>To create new training data</p></li>
<li><p>To adjust model parameters for improved performance</p></li>
<li><p>To convert categorical data into numerical form</p></li>
<li><p>To speed up the training process</p></li>
</ol>
</li>

<li><p>How do diffusion models work?</p>
<ol type="a">
<li><p>They add and remove noise in various steps.</p></li>
<li><p>They use competing neural networks.</p></li>
<li><p>They only create text.</p></li>
<li><p>They only create sound.</p></li>
</ol>
</li>

<li><p>What is the primary purpose of fine-tuning a foundation model (FM)?</p>
<ol type="a">
<li><p>To make a model more general-purpose</p></li>
<li><p>To customize the model for a specific domain</p></li>
<li><p>To lower the latency</p></li>
<li><p>To train the model from scratch</p></li>
</ol>
</li>

<li><p>How does an encoder work in a transformer model?</p>
<ol type="a">
<li><p>It creates synthetic data.</p></li>
<li><p>It fine-tunes hyperparameters.</p></li>
<li><p>It evaluates model predictions.</p></li>
<li><p>It processes input sequences and extracts meaningful representations.</p></li>
</ol>
</li>

<li><p>Which of the following describes a limit on how much a large language model (LLM) can process at a time? </p>
<ol type="a">
<li><p>Overfitting</p></li>
<li><p>Bias</p></li>
<li><p>Context windows</p></li>
<li><p>The discriminator</p></li>
</ol>
</li>

<li><p>What’s the reason for using reinforcement learning from human feedback (RLHF) in generative AI models?</p>
<ol type="a">
<li><p>To improve the alignment the model’s responses with human preferences</p></li>
<li><p>To lower training costs</p></li>
<li><p>To replace deep learning models</p></li>
<li><p>To reduce the latency of the model</p></li>
</ol>
</li>

<li><p>What is a key benefit of a multimodal foundation model (FM)?</p>
<ol type="a">
<li><p>It requires much less data for the training</p></li>
<li><p>It can process and create different types of content like text, images, and <span class="keep-together">videos</span></p></li>
<li><p>It is more explainable than text-based models</p></li>
<li><p>It does not require GPUs</p></li>
</ol>
</li>

<li><p>Of the choices below, which is a main reason why large language models consume significant compute resources?</p>
<ol type="a">
<li><p>They use retrieval-augmented generation (RAG).</p></li>
<li><p>They use complex linear algebra.</p></li>
<li><p>They process billions of parameters to generate accurate responses.</p></li>
<li><p>They rely on human feedback and evaluation for all responses.</p></li>
</ol>
</li>

<li><p>Why can RAG help lower hallucinations in AI models?</p>
<ol type="a">
<li><p>It has guardrails for certain types of prompts</p></li>
<li><p>It searches a proprietary database to enhance the response</p></li>
<li><p>It disables the probability system</p></li>
<li><p>It relies only on human supervision</p></li>
</ol>
</li>

<li><p>Among these choices, what is a core capability of Amazon Lex?</p>
<ol type="a">
<li><p>It analyzes data for fraud detection.</p></li>
<li><p>It allows for video analysis.</p></li>
<li><p>It supports intents and slot filling to create conversational AI experiences.</p></li>
<li><p>It automates the extraction of text from scanned documents.</p></li>
</ol>
</li>

<li><p>What can you do with Amazon Comprehend?</p>
<ol type="a">
<li><p>Analyze text to extract insights such as for sentiment, key phrases, and entities.</p></li>
<li><p>Transcribe audio recordings into text.</p></li>
<li><p>Convert text into humanlike speech.</p></li>
<li><p>Translate text into multiple languages.</p></li>
</ol>
</li>

<li><p>What is a major capability of Amazon Rekognition?</p>
<ol type="a">
<li><p>The translation of spoken language into text.</p></li>
<li><p>The use of optical character recognition (OCR) for scanned documents.</p></li>
<li><p>The generation of AI-powered chatbot responses.</p></li>
<li><p>The ability to recognize faces, objects, and scenes in images and videos.</p></li>
</ol>
</li>

<li><p>Among these options, which is a technique used in natural language processing (NLP) preprocessing?</p>
<ol type="a">
<li><p>Automatically correcting all grammatical errors in a sentence.</p></li>
<li><p>Translating text into another language before processing.</p></li>
<li><p>Lemmatization, which reduces words to their root form.</p></li>
<li><p>Applying deepfake detection to verify text authenticity.</p></li>
</ol>
</li>

<li><p>Why is stopword removal used in natural language processing (NLP) <span class="keep-together">preprocessing?</span></p>
<ol type="a">
<li><p>Stopwords add important meaning to a text.</p></li>
<li><p>It helps remove uncommon words to focus only on frequently used terms.</p></li>
<li><p>Stopwords are removed to reduce text length to speed up processing.</p></li>
<li><p>Removing stopwords like the and is helps improve efficiency without losing essential meaning.</p></li>
</ol>
</li>

<li><p>When is AI not always the best solution for a business use case?</p>
<ol type="a">
<li><p>AI models do not work well in cloud-based environments.</p></li>
<li><p>AI requires human oversight at all times.</p></li>
<li><p>AI can only be used for simple automation tasks.</p></li>
<li><p>AI solutions can be complex and costly when a simpler approach may suffice.</p></li>
</ol>
</li>

<li><p>What is the Compare Models feature in the Bedrock playground?</p>
<ol type="a">
<li><p>It allows for using image and text responses.</p></li>
<li><p>It provides for making longer responses for two different models.</p></li>
<li><p>It combines responses from two models.</p></li>
<li><p>It allows for evaluating the side-by-side responses from two different models.</p></li>
</ol>
</li>

<li><p>Why would you fine-tune a model in Bedrock? </p>
<ol type="a">
<li><p>To reduce compute costs</p></li>
<li><p>To improve latency</p></li>
<li><p>To improve response accuracy for domain-specific scenarios</p></li>
<li><p>To use images</p></li>
</ol>
</li>
</ol>

<ol class="less_space pagebreak-before" start="31">
<li><p>What is a key advantage of using open source foundation models (FMs) in AWS Bedrock?</p>
<ol type="a">
<li><p>They are always free to use.</p></li>
<li><p>They support real-time inference by default.</p></li>
<li><p>They offer transparency, customization, and community innovation.</p></li>
<li><p>They provide the codebase and datasets.</p></li>
</ol>
</li>

<li><p>What’s a benefit of using a distilled model in Bedrock?</p>
<ol type="a">
<li><p>It reduces compute requirements, making it suitable for edge devices.</p></li>
<li><p>It increases the context window.</p></li>
<li><p>It increases the creativity of the responses.</p></li>
<li><p>It guarantees higher accuracy than larger models.</p></li>
</ol>
</li>

<li><p>What is a key benefit of multiagent collaboration in Bedrock?</p>
<ol type="a">
<li><p>It relies on distilled models.</p></li>
<li><p>It provides for 100% accuracy.</p></li>
<li><p>It allows different agents to specialize in specific tasks, leading to better problem solving.</p></li>
<li><p>It enables users to edit model weights and biases.</p></li>
</ol>
</li>

<li><p>What is a key benefit of batch processing when using Bedrock?</p>
<ol type="a">
<li><p>There is low latency.</p></li>
<li><p>The context window is unlimited.</p></li>
<li><p>There is higher accuracy.</p></li>
<li><p>Lower costs.</p></li>
</ol>
</li>

<li><p>Which technique improves the consistency and clarity of prompts when used repeatedly?</p>
<ol type="a">
<li><p>Few-shot prompting</p></li>
<li><p>Zero-shot prompting</p></li>
<li><p>Chain-of-thought prompting</p></li>
<li><p>Prompt templates</p></li>
</ol>
</li>
</ol>

<ol class="less_space pagebreak-before" start="36">
<li><p>What is the purpose of chain-of-thought (CoT) prompting?</p>
<ol type="a">
<li><p>To specify for the large language model (LLM) which examples to use</p></li>
<li><p>To limit the response of the large language model (LLM) </p></li>
<li><p>To allow for step-by-step reasoning for complex problems</p></li>
<li><p>To adjust the large language model (LLM) parameters</p></li>
</ol>
</li>

<li><p>Which type of prompting involves providing several examples to help the model learn a pattern?</p>
<ol type="a">
<li><p>Zero-shot prompting</p></li>
<li><p>Chain-of-thought (CoT) prompting</p></li>
<li><p>Few-shot prompting</p></li>
<li><p>Template prompting</p></li>
</ol>
</li>

<li><p>What is model poisoning?</p>
<ol type="a">
<li><p>This allows a model to process personal health data.</p></li>
<li><p>This is when biased or malicious data is injected into the training process.</p></li>
<li><p>This when a model lacks proper licensing.</p></li>
<li><p>This is where there are conflicting instructions in a single prompt.</p></li>
</ol>
</li>

<li><p>What is exposure as it relates to security risks with foundation models (FMs)?</p>
<ol type="a">
<li><p>The use of the model for consumer apps</p></li>
<li><p>The loss of GPU performance during training</p></li>
<li><p>The unintentional inclusion of sensitive data in training sets</p></li>
<li><p>The failure to generate output within token limits</p></li>
</ol>
</li>

<li><p>What is jailbreaking of a foundation model (FM)?</p>
<ol type="a">
<li><p>Running a model without GPU acceleration</p></li>
<li><p>Resetting a model’s API token for expanding the access</p></li>
<li><p>Deleting a model’s training history</p></li>
<li><p>Tricking the model into bypassing safety and ethical restrictions</p></li>
</ol>
</li>

<li><p>Which of the following best describes AI governance?</p>
<ol type="a">
<li><p>A set of marketing strategies for AI adoption</p></li>
<li><p>Policies and oversight structures to guide ethical AI development</p></li>
<li><p>Legal ownership of AI-generated content</p></li>
<li><p>Techniques for building large language models (LLMs)</p></li>
</ol>
</li>
</ol>

<ol class="less_space pagebreak-before" start="42">
<li><p>What does controllability in AI focus on?</p>
<ol type="a">
<li><p>Reducing computational costs</p></li>
<li><p>Building faster AI systems</p></li>
<li><p>Aligning AI actions with human intent and oversight</p></li>
<li><p>Removing human involvement</p></li>
</ol>
</li>

<li><p>Which of the following is a business advantage of adopting responsible AI <span class="keep-together">practices?</span></p>
<ol type="a">
<li><p>Enhanced trust and improved brand reputation</p></li>
<li><p>Reduced need for data collection</p></li>
<li><p>Increased dependence on human intervention</p></li>
<li><p>Elimination of all algorithmic errors</p></li>
</ol>
</li>

<li><p>What is the role of Amazon SageMaker Clarify in responsible AI?</p>
<ol type="a">
<li><p>Detecting harmful URLs in user prompts</p></li>
<li><p>Managing compute costs during training</p></li>
<li><p>Identifying and explaining bias in data and models</p></li>
<li><p>Encrypting training data</p></li>
</ol>
</li>

<li><p>What is Amazon Augmented AI (A2I) primarily used for?</p>
<ol type="a">
<li><p>Accelerating training of neural networks</p></li>
<li><p>Creating synthetic data from scratch</p></li>
<li><p>Managing GPUs in SageMaker</p></li>
<li><p>Integrating human reviews into AI workflows</p></li>
</ol>
</li>

<li><p>What is a key advantage of reinforcement learning from human feedback (RLHF)?</p>
<ol type="a">
<li><p>It removes the need for model retraining.</p></li>
<li><p>It ensures AI systems remain static.</p></li>
<li><p>It helps models align outputs with human preferences and judgments.</p></li>
<li><p>It eliminates the need for data labeling.</p></li>
</ol>
</li>

<li><p>What is a compliance risk caused by AI systems developing emergent <span class="keep-together">capabilities?</span></p>
<ol type="a">
<li><p>They strictly follow preprogrammed features with no surprises.</p></li>
<li><p>They may behave unpredictably in ways not planned by the original designers.</p></li>
<li><p>They automatically file compliance reports as they change.</p></li>
<li><p>They prevent the need for any human oversight.</p></li>
</ol>
</li>

<li><p>What is a key characteristic of a regulated workload?</p>
<ol type="a">
<li><p>It only applies to gaming or entertainment systems.</p></li>
<li><p>It only focuses on making systems faster, not safer.</p></li>
<li><p>It only requires encryption of stored data.</p></li>
<li><p>It must follow specific compliance rules due to legal, industry, or safety concerns.</p></li>
</ol>
</li>

<li><p>Why is data logging important in AI systems?</p>
<ol type="a">
<li><p>It helps speed up model training by skipping error checks.</p></li>
<li><p>It captures inputs, outputs, and system events, supporting debugging, monitoring, and transparency.</p></li>
<li><p>It prevents the need for data residency compliance.</p></li>
<li><p>It automatically guarantees 100% model accuracy.</p></li>
</ol>
</li>

<li><p>Which AWS service provides a detailed history of resource configuration changes and relationships to support compliance auditing?</p>
<ol type="a">
<li><p>AWS Config</p></li>
<li><p>AWS Trusted Advisor</p></li>
<li><p>Amazon Inspector</p></li>
<li><p>AWS Artifact</p></li>
</ol>
</li>

<li><p>In the Generative AI Security Scoping Matrix, which scope involves using publicly available generative AI tools without backend access or customization?</p>
<ol type="a">
<li><p>Scope 3: Pretrained models</p></li>
<li><p>Scope 4: Fine-tuned models</p></li>
<li><p>Scope 5: Self-trained models</p></li>
<li><p>Scope 1: Consumer applications</p></li>
</ol>
</li>

<li><p>Which AWS service uses machine learning (ML) to detect and classify sensitive data like personally identifiable information (PII) or protected health information (PHI) across your environment?</p>
<ol type="a">
<li><p>AWS Verified Permissions</p></li>
<li><p>AWS Shield Advanced</p></li>
<li><p>Amazon Macie</p></li>
<li><p>Amazon SageMaker Role Manager</p></li>
</ol>
</li>
</ol>

<ol class="less_space pagebreak-before" start="53">
<li><p>What is the purpose of a model card in the context of generative AI?</p>
<ol type="a">
<li><p>To automatically retrain models with new data</p></li>
<li><p>To manage access controls across cloud infrastructure</p></li>
<li><p>To document the data sources, intended uses, risks, and limitations of a model</p></li>
<li><p>To optimize compute resources for faster model deployment.</p></li>
</ol>
</li>

<li><p>In a generative AI system, who always controls user data, regardless of application scope?</p>
<ol type="a">
<li><p>The application provider</p></li>
<li><p>The cloud service provider</p></li>
<li><p>The data annotation team</p></li>
<li><p>The customer or end user</p></li>
</ol>
</li>
</ol>
</div></section></div></div></body></html>