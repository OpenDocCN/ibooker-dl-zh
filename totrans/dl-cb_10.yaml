- en: Chapter 10\. Building an Inverse Image Search Service
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章。构建反向图像搜索服务
- en: In the previous chapter we saw how to use a pretrained network on our own images,
    first by running a classifier on top of the network and then in a more complex
    example in which we trained only part of a network to recognize new classes of
    images. In this chapter we will use a similar approach to build a reverse image
    search engine, or a search by example.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们看到如何在我们自己的图像上使用预训练网络，首先通过在网络顶部运行分类器，然后在一个更复杂的示例中，我们只训练网络的部分来识别新的图像类别。在本章中，我们将使用类似的方法来构建一个反向图像搜索引擎，或者通过示例搜索。
- en: We’ll start by looking at how we can acquire a good base set of images from
    Wikipedia by querying Wikidata. We’ll then use a pretrained network to extract
    values for each of those images to get embeddings. Once we have those embeddings,
    finding similar images is a mere matter of nearest neighbor search. Finally, we’ll
    look at principal components analysis (PCA) as a way to visualize relationships
    between images.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从查找维基数据查询维基百科获取一组良好的基础图像开始。然后，我们将使用预训练网络提取每个图像的值以获得嵌入。一旦我们有了这些嵌入，找到相似的图像只是最近邻搜索的一个简单问题。最后，我们将研究主成分分析（PCA）作为一种可视化图像之间关系的方法。
- en: 'The code for this chapter can be found in the following notebook:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在以下笔记本中找到：
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 10.1 Acquiring Images from Wikipedia
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10.1 从维基百科获取图像
- en: Problem
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How do you get a clean set of images from Wikipedia covering the major categories
    of things?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如何从维基百科获取一组覆盖主要类别的干净图像？
- en: Solution
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Use Wikidata’s metainformation to find Wikipedia pages that represent a class
    of things.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用维基数据的元信息来查找代表一类事物的维基百科页面。
- en: Wikipedia contains a great number of pictures that can be used for most purposes.
    The vast majority of those pictures, though, represent concrete instances, which
    is not really what we need for a reverse search engine. We want to return a picture
    representative of a cat as a species, not a specific cat like Garfield.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科包含大量可用于大多数目的的图片。然而，其中绝大多数图片代表具体实例，这并不是反向搜索引擎所需要的。我们希望返回代表猫作为一个物种的图片，而不是像加菲猫这样的特定猫。
- en: 'Wikidata, the structured cousin of Wikipedia, is based around triplets of the
    form (subject, relation, object) and has a great number of predicates encoded,
    partly on top of Wikipedia. One of those “instance of” is represented by `P31`.
    What we are after is a list of images of the objects in the instance-of relationships.
    We can use the Wikidata query language to ask for this:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 维基数据，维基百科的结构化表亲，基于形式为（主题，关系，对象）的三元组，并且有大量编码的谓词，部分基于维基百科。其中之一“实例”由`P31`表示。我们要找的是实例关系中对象的图像列表。我们可以使用维基数据查询语言来请求这个：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can call the query backend of Wikidata using requests and unroll the resulting
    JSON into a list of image references:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用请求调用维基数据的查询后端，并将结果JSON展开为图像引用列表：
- en: '[PRE2]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The references returned are URLs to the image pages, not the images themselves.
    Images in the various wiki projects are supposed to be stored in *http://upload.wikimedia.org/wikipedia/commons/*,
    but unfortunately this isn’t always the case yet—some are still stored in the
    folder for a specific language. So, we’ll also have to check at least the English
    folder (*en*). The actual URL for the image is determined by the filename and
    the first two characters of the `hexdigest` of the MD5 hash of the file name.
    Caching the image locally helps if we have to do this multiple times:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的引用是指向图像页面的URL，而不是图像本身。各种维基项目中的图像应该存储在*http://upload.wikimedia.org/wikipedia/commons/*，但不幸的是，这并不总是情况—有些仍然存储在特定语言的文件夹中。因此，我们还必须至少检查英语文件夹（*en*）。图像的实际URL由文件名和文件名的MD5哈希的`hexdigest`的前两个字符确定。如果我们需要多次执行此操作，则将图像缓存到本地会有所帮助：
- en: '[PRE3]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Even this doesn’t always seem to work. The notebook for this chapter contains
    some more corner case–handling code to increase the yield of images.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这样有时候也不起作用。本章的笔记本包含一些更多处理边缘情况的代码，以增加图像的产出。
- en: 'Now all we need to do is fetch the images. This can take a long time, so we
    use `tqdm` to show our progress:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要做的就是获取图像。这可能需要很长时间，因此我们使用`tqdm`来显示我们的进度：
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Discussion
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Wikidata’s query language is not widely known, but it’s an effective way to
    access structured data. The example here is quite straightforward, but online
    you can find more complex queries, for example, to return the largest cities in
    the world with a female mayor or the most popular surnames for fictional characters.
    A lot of this data can also be extracted from Wikipedia, but running a Wikidata
    query is usually faster, more precise, and more fun.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 维基数据的查询语言并不广为人知，但它是访问结构化数据的有效方式。这里的示例非常简单，但在线上可以找到更复杂的查询，例如返回世界上最大的女市长或虚构角色中最流行的姓氏。这些数据大部分也可以从维基百科中提取，但运行维基数据查询通常更快、更精确且更有趣。
- en: The Wikimedia universe is also a good source for images. There are tens of millions
    of images available, all with a friendly reuse license. Moreover, using Wikidata
    we can get access to all kinds of properties for these images. It would be easy
    to expand this recipe to return not just the image URLs, but also the names of
    the objects in the images in a language of our choice.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 维基媒体宇宙也是图像的良好来源。有数千万张可用的图像，全部都有友好的重用许可证。此外，使用维基数据，我们可以访问这些图像的各种属性。很容易扩展这个方法，不仅返回图像URL，还返回图像中对象的名称，可以选择使用我们选择的语言。
- en: Note
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The `fetch_image` function described here works most of the time, but not always.
    We can improve upon this by fetching the contents of the URL returned from the
    Wikidata query and extracting the `<img>` tag from the HTML code.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里描述的`fetch_image`函数大多数时候都有效，但并非总是有效。我们可以通过获取从维基数据查询返回的URL的内容，并从HTML代码中提取`<img>`标签来改进这一点。
- en: 10.2 Projecting Images into an N-Dimensional Space
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10.2 将图像投影到N维空间
- en: Problem
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: Given a set of images, how do you organize them such that images that look similar
    are near each other?
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一组图像，如何组织它们以使相似的图像彼此靠近？
- en: Solution
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Treat the weights of the last-but-one layer of an image recognition net as image
    embeddings. This layer is connected directly to the `softmax` layer that draws
    the conclusions. Anything that the network thinks is a cat should therefore have
    similar values.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像识别网络的倒数第二层的权重视为图像嵌入。这一层直接连接到绘制结论的`softmax`层。因此，网络认为是猫的任何东西应该具有相似的值。
- en: 'Let’s load and instantiate the pretrained network. We’ll use Inception again—let’s
    peek at its structure using `.summary()`:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们加载并实例化预训练网络。我们将再次使用Inception——让我们使用`.summary()`来查看其结构：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As you can see, we need the `avg_pool` layer, which has a size of 2,048:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们需要`avg_pool`层，其大小为2,048：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now we can run the model on an image or a set of images:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在一张图像或一组图像上运行模型：
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'and index the images we acquired in the previous recipe in chunks (of course,
    if you have enough memory, you can try to do the entire shot in one go):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 并对我们在上一个示例中获取的图像进行分块索引（当然，如果您有足够的内存，可以尝试一次性完成整个操作）：
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Discussion
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: In this recipe we used the last-but-one layer of the network to extract the
    embeddings. Since this layer is directly connected to the `softmax` layer that
    determines the actual output layers, we expect the weights to form a semantic
    space that puts all the cat images in roughly the same space. But what happens
    if we pick a different layer?
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们使用了网络的倒数第二层来提取嵌入。由于这一层直接连接到确定实际输出层的`softmax`层，我们期望权重形成一个语义空间，将所有猫的图像大致放在同一空间中。但如果我们选择不同的层会发生什么呢？
- en: One way to think about convolutional networks that do image recognition is to
    treat the successive layers as feature detectors of increasing levels of abstraction.
    The lowest level works directly on the pixel values and will detect very local
    patterns. The last layer detects concepts like “catness.”
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 将卷积网络视为图像识别的特征检测器，逐层增加抽象级别。最低级别直接处理像素值，并将检测到非常局部的模式。最后一层检测“猫”的概念。
- en: Picking a lower layer should result in similarity on a lower level of abstractness,
    so instead of returning things that are cat-like, we would expect to see images
    that have similar textures.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 选择一个较低的层应该会导致在较低的抽象级别上的相似性，所以我们不会返回类似猫的东西，而是期望看到具有相似纹理的图像。
- en: 10.3 Finding Nearest Neighbors in High-Dimensional Spaces
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10.3 在高维空间中找到最近邻
- en: Problem
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: How do you find the points that are closest to each other in a high-dimensional
    space?
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如何在高维空间中找到彼此最接近的点？
- en: Solution
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Use scikit-learn’s *k*-nearest neighbors implementation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用scikit-learn的*k*-最近邻实现。
- en: 'The *k*-nearest neighbors algorithm builds a model that can quickly return
    nearest neighbors. It does so with some loss of accuracy, but is much faster than
    doing the precise calculations. Effectively, it builds a distance index on our
    vectors:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*k*-最近邻算法构建一个模型，可以快速返回最近邻。虽然会有一些精度损失，但比进行精确计算要快得多。实际上，它在我们的向量上构建了一个距离索引：'
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'With this distance index we can now quickly return near matches from our set
    of images given an input image. We have arrived at our reverse image search implementation!
    Let’s put it all together to find more cats:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个距离索引，我们现在可以快速返回给定输入图像的图像集中的近似匹配。我们已经实现了逆图像搜索！让我们把所有这些放在一起找更多的猫：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And display the top results using inline HTML images:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 并使用内联HTML图像显示前几个结果：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You should see a nice list of images dominated by cats!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到一个由猫主导的漂亮图像列表！
- en: Discussion
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: Fast computation of nearest neighbors is an active area of research in machine
    learning. The most naive neighbor search implementation involves the brute-force
    computation of distances between all pairs of points in the dataset, which quickly
    gets out of hand if we have a large number of points in a high-dimensional space.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，快速计算最近邻是一个活跃的研究领域。最简单的邻居搜索实现涉及在数据集中所有点对之间计算距离，如果我们在高维空间中有大量点，这种方法很快就会失控。
- en: Scikit-learn provides us with a number of algorithms that precalculate a tree
    that can help us find nearest neighbors fast, at the cost of some memory. The
    different approaches are discussed in [the documentation](http://scikit-learn.org/stable/modules/neighbors.html),
    but the general approach is to use an algorithm to recursively split the space
    into subspaces, this way building a tree. This allows us to quickly identify which
    subspaces to check when looking for neighbors.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn为我们提供了许多预先计算树的算法，可以帮助我们快速找到最近邻居，但会消耗一些内存。不同的方法在[文档](http://scikit-learn.org/stable/modules/neighbors.html)中有所讨论，但一般的方法是使用算法递归地将空间分割成子空间，从而构建树。这样我们可以快速识别在寻找邻居时要检查哪些子空间。
- en: 10.4 Exploring Local Neighborhoods in Embeddings
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10.4 在嵌入中探索局部邻域
- en: Problem
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题
- en: You’d like to explore what local clusters of images look like.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 您想探索图像的局部聚类是什么样子。
- en: Solution
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Use principal component analysis to find the dimensions among a local set of
    images that discriminate the most between images.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用主成分分析找到在局部图像集中最能区分图像的维度。
- en: 'For example, let’s say we have the 64 images that are the closest match to
    our cat image:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有与我们的猫图像最接近的64张图像：
- en: '[PRE12]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'PCA allows us to reduce the dimensionality of a space in such a way that the
    original space can be constructed with as little loss as possible. If we reduce
    the dimensionality to two, PCA will find the plane that the examples provided
    can be projected upon with as little loss as possible. If we then look at where
    the examples landed on that plane, we get a good idea of the structure of the
    local neighborhood. `TruncatedSVD` is the implementation we’ll use in this case:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: PCA允许我们以尽可能少的损失降低空间的维度。如果我们将维度降低到二维，PCA将找到可以将提供的示例投影到的平面，以尽可能少的损失。然后，我们看看这些示例在平面上的位置，就可以很好地了解本地邻域的结构。在这种情况下，我们将使用`TruncatedSVD`实现：
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`vectors64_transformed` now has a shape of 64×2\. We are going to draw the
    64 images on an 8×8 grid with a cell size of 75×75\. Let’s start by normalizing
    the coordinates onto a 0 to 1 scale:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`vectors64_transformed`现在的形状是64×2。我们将在一个8×8的网格上绘制这64个图像，每个单元格的大小为75×75。让我们首先将坐标归一化到0到1的比例上：'
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now we can draw and display the local area:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以绘制并显示本地区域：
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![Tile images of a local cluster](assets/dlcb_10in01.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![本地聚类的图像](assets/dlcb_10in01.png)'
- en: We see a cat image roughly in the middle, with one corner dominated by animals
    and the rest of the images matched because of other reasons. Note that we plot
    over existing images, so the grid won’t actually be filled completely.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到一个猫图像大致位于中间，一个角被动物主导，其余的图像由于其他原因匹配。请注意，我们在现有图像上绘制，因此网格实际上不会完全填满。
- en: Discussion
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 讨论
- en: In [Recipe 3.3](ch03.html#visualizing-word-embeddings) we used t-SNE to fold
    a higher-dimensional space into a two-dimensional plane. In this recipe we used
    principal component analysis instead. The two algorithms accomplish the same thing,
    reducing the dimensions of a space, but do so in different ways.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在[食谱3.3](ch03.html#visualizing-word-embeddings)中，我们使用t-SNE将高维空间折叠成二维平面。在这个食谱中，我们改用主成分分析。这两种算法实现了相同的目标，即降低空间的维度，但是它们的方式不同。
- en: t-SNE tries to keep the distances between points in the space the same, despite
    the reduction of dimensionality. Some information is of course lost in this transformation,
    so we can make a choice as to whether we want to try to keep clusters locally
    intact (distances between points that were close to each other in the higher dimensions
    are kept similar) or keep distances between clusters intact (distances between
    points that were far from each other in the higher dimensions are kept similar).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: t-SNE试图保持空间中点之间的距离相同，尽管降低了维度。在这种转换中当然会丢失一些信息，因此我们可以选择是尝试保持簇在本地保持完整（在高维度中彼此接近的点之间的距离保持相似）还是保持簇之间的距离保持完整（在高维度中彼此远离的点之间的距离保持相似）。
- en: PCA tries to find an *N*-dimensional hyperplane that is the closest possible
    to all the items in the space. If *N* is 2, we’re talking about a normal plane,
    and so it tries to find the plane in our high-dimensional space that is closest
    to all images. In other words, it captures the two most important dimensions (the
    principal components), which we then use to visualize the cat space.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: PCA试图找到一个* N *维的超平面，该超平面与空间中的所有项目尽可能接近。如果* N *为2，我们谈论的是一个普通平面，因此它试图找到在我们的高维空间中与所有图像最接近的平面。换句话说，它捕捉了两个最重要的维度（主成分），然后我们用它们来可视化猫空间。
