<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 6. Advanced Use Cases for Generative AI in SEO"><div class="chapter" id="ch06_advanced_use_cases_for_generative_ai_in_seo_1748359259642070">
      <h1><span class="label">Chapter 6. </span>Advanced Use Cases for Generative AI <span class="keep-together">in SEO</span></h1>
      <p>With some technical skills or a developer team supporting you, you can create powerful customizations to use generative AI at scale to accelerate growth and increase revenues. Building SEO systems at scale is where you’ll find the real power in generative AI. Instead of training junior SEO associates to research keyword targets or do competitive analysis, you can train a model and deploy it, which gives you an AI assistant at your fingertips with the ability to get your answers in seconds. Instead of scaling content creation by hiring additional writers, you can use generative AI to help your existing writers increase their output while improving their content quality. </p>
      <p>We discussed the basics in <a data-type="xref" href="ch03.html#ch03_getting_started_with_generative_ai_1748358214007893">Chapter 3</a>, but in this chapter we’ll look at the more technical side of scaling up with<a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="benefits of" id="automation-benefits"/><a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="benefits of" id="seo-automation-benefits"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="automation" data-see="automation in SEO" id="id646"/><a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="use cases" data-seealso="automation in SEO" id="id647"/><a contenteditable="false" data-type="indexterm" data-primary="use cases for SEO" data-seealso="automation in SEO" id="id648"/> automation and generative AI. We’ll dive deeper into generative AI implementation, including the infrastructure in retrieval-augmented generation (RAG), how to use enterprise APIs, and the benefits of generative AI for creating video and audio. </p>
      <p>Automation for SEO practitioners increases productivity and reduces the time needed for many of your day-to-day tasks. This chapter covers the many benefits, use cases, and advantages of automation in SEO using generative AI. We’ll also discuss customizing your own <a contenteditable="false" data-type="indexterm" data-primary="retrieval-augmented generation" data-see="RAG" id="id649"/>generative pretrained transformer (GPT).</p>
      <section data-type="sect1" data-pdf-bookmark="The Value of Using Generative AI at Scale"><div class="sect1" id="ch06_the_value_of_using_generative_ai_at_scale_1748359259642382">
        <h1>The Value of Using Generative AI at Scale</h1>
        <p>Think of generative AI as a team of junior associates that you can have do much of the tedious SEO legwork for you. Tasks they can perform on your behalf include:</p>
        <ul>
          <li>
            <p>Discovering topics for your site that competitors don’t cover</p>
          </li>
          <li>
            <p>Identifying areas of SEO weakness in your existing content that should be addressed</p>
          </li>
          <li>
            <p>Creating draft outlines for new content</p>
          </li>
          <li>
            <p>Researching key data points and sources for those data points that could add depth to your content</p>
          </li>
          <li>
            <p>Drafting sections of content for new articles on your site or even full articles</p>
          </li>
        </ul>
        <p>These are just some examples of how you might employ AI-based associates. You wouldn’t expect to use the work they do without review by one of your expert staff, but their work makes your job of creating and improving your content much easier—and arguably increases the content’s quality. The result is more cost-effective use of your time and effort.</p>
        <p>Generative AI can effectively be your brainstorming and drafting partner, just as we described in the prior chapters, but on a larger scale if you have technical skills or access to developers. As we refer to ways to use generative AI in content development in this chapter (and throughout the book), this is how you should think about its value.</p>
        <p>You can also improve the quality of the output of generative AI tools by connecting them to your own market-specific knowledge base, which will give you a competitive edge. Whatever your business, if you’re not building your own knowledge base, you’re going to fall behind. Your market knowledge base is a set of data points that AI can ingest to return an output of ideas, outlines, and summaries of your content, informed by your unique data. Data fuels AI and produces richer outputs and personalization from generative AI.</p>
        <p>One prerequisite is some technical know-how. To take advantage of many of the advanced use cases mentioned in this chapter, you’ll need some background knowledge in software engineering, or you’ll need an engineering team to help with the technical aspects of the work. The technical investment will give you exponential returns, so it’s worth the time and money necessary to invest in advanced generative AI <a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="benefits of" data-startref="automation-benefits" id="id650"/><a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="benefits of" data-startref="seo-automation-benefits" id="id651"/>use cases. </p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="AI-Powered SEO Tools for Inspiration"><div class="sect1" id="ch06_ai_powered_seo_tools_for_inspiration_1748359259642457">
        <h1>AI-Powered SEO Tools for Inspiration</h1>
        <p>Before we <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="AI-powered tools" id="seo-ai-powered-tools"/><a contenteditable="false" data-type="indexterm" data-primary="AI-powered SEO tools" id="ai-powered-tools"/><a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="AI-powered SEO tools" id="seo-automation-ai-powered-tools"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="AI-powered tools" id="automation-ai-powered-tools"/>get into the more advanced technical side of generative AI, we should mention that you can leverage several AI-powered features using premade tools already on the market with a long history of SEO benefits. These tools are much more limited than what you can do with your own programming and custom models, but they are a good starting point and can give you ideas for developing your own tools.</p>
        <p>Let’s say <a contenteditable="false" data-type="indexterm" data-primary="keyword research" data-secondary="AI-powered tools for" id="id652"/>you want to find new content to publish on your site. You know you should focus on content that can get you more visibility, but where do you start looking for ideas? You could home in on trends, but how do you find these trends? Google Trends helps you get a general idea of topics, but it won’t find you keywords to target. AI-powered tools can generate a long list of content topics to target based on keywords from third-party APIs, their popularity in users’ search queries, and related keywords to suggest similar content you may not have thought about without the tools. The third-party APIs (e.g., Semrush or Ahrefs) require additional coding, but automation agents can use third-party APIs to come up with common keywords that you can then feed to generative AI models to find content topics and suggest titles. </p>
        <p>In <a data-type="xref" href="ch04.html#ch04_using_ai_to_scale_content_development_1748358216258351">Chapter 4</a>, we discussed manual processes for using generative AI for parts of this process; now envision AI agents querying these data sources and making the output better at scale, without manual intervention at each step. The main human intervention other than prompt tuning is the expert review and edits at the end.</p>
        <p>AI-powered tools can also help with <a contenteditable="false" data-type="indexterm" data-primary="backlink analysis" id="id653"/><a contenteditable="false" data-type="indexterm" data-primary="gap analysis" data-secondary="AI-powered tools for" id="id654"/>backlinking opportunities. Just like content topic ideas, you first need a third-party API to obtain information about competitors. Agents poll these APIs for competitor analysis and information, and then feed results to a generative AI model to find topics for backlinks or a gap analysis to understand your competitor’s backlink profile better. You can use them to find where competitors have their backlinks or domains with similar keywords that might be beneficial. You can also discover mentions of your brand on social media or other sites with third-party APIs and use AI to analyze user feedback about your brand. </p>
        <p class="pagebreak-before">The following tools existed before GPTs and current generative AI models, but they each have their own AI that you can use in your agents and scripts:</p>
        <dl>
          <dt>Semrush</dt>
          <dd>
            <p>Semrush <a contenteditable="false" data-type="indexterm" data-primary="Semrush" id="id655"/>is a subscription service for keyword research, competitor analysis, and topic research for generative AI creation. It also has a rich database of your backlinks.</p>
          </dd>
          <dt>Ahrefs</dt>
          <dd>
            <p>Audit <a contenteditable="false" data-type="indexterm" data-primary="Ahrefs" id="id656"/>your backlink history and find opportunities for content topics. Ahrefs also can be used for keyword research.</p>
          </dd>
          <dt>Grammarly</dt>
          <dd>
            <p>Grammarly is <a contenteditable="false" data-type="indexterm" data-primary="Grammarly" id="id657"/>beneficial for optimizing content and finding awkward wording to create more engaging content.</p>
          </dd>
          <dt>Google Analytics</dt>
          <dd>
            <p>Most <a contenteditable="false" data-type="indexterm" data-primary="Google Analytics" id="id658"/>SEO practitioners already work with Google Analytics, but it’s a great tool for identifying traffic trends and optimizing ad content for better conversions.</p>
          </dd>
          <dt>Yoast SEO</dt>
          <dd>
            <p>The<a contenteditable="false" data-type="indexterm" data-primary="Yoast SEO" id="id659"/> Premium version of Yoast SEO gives you AI-powered titles and meta descriptions. It also provides content suggestions for better <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="AI-powered tools" data-startref="seo-ai-powered-tools" id="id660"/><a contenteditable="false" data-type="indexterm" data-primary="AI-powered SEO tools" data-startref="ai-powered-tools" id="id661"/><a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="AI-powered SEO tools" data-startref="seo-automation-ai-powered-tools" id="id662"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="AI-powered tools" data-startref="automation-ai-powered-tools" id="id663"/>search <span class="keep-together">visibility.</span></p>
          </dd>
        </dl>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Custom GPTs for More Targeted Brand Content"><div class="sect1" id="ch06_custom_gpts_for_more_targeted_brand_content_1748359259642525">
        <h1>Custom GPTs for More Targeted Brand Content</h1>
        <p>In <a contenteditable="false" data-type="indexterm" data-primary="GPTs (generative pretrained transformers), custom" id="gpt-custom"/><a contenteditable="false" data-type="indexterm" data-primary="custom GPTs" id="custom-gpt"/><a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="custom GPTs" id="seo-automation-custom-gpt"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="custom GPTs" id="automation-custom-gpt"/>November 2023, OpenAI released functionality that enables users to create custom GPTs. Custom GPTs are beneficial for very defined use cases. When you build a custom GPT using an LLM like OpenAI’s ChatGPT, you<a contenteditable="false" data-type="indexterm" data-primary="custom GPTs" data-secondary="benefits of" id="custom-gpt-benefit"/> can use your own proprietary data, but ChatGPT will fall back on its knowledge base in scenarios when it does not have an answer from your data.</p>
        <p class="pagebreak-after">ChatGPT is great at helping you create content ideas, but you will want to narrow down topics to content related to your brand. For example, suppose you want to develop a chatbot to answer basic customer service questions. You don’t need your chatbot lecturing users on the history of a product. You need the chatbot to provide information specific to the product that draws key information from your knowledge base. You can do this by creating your own custom GPT that focuses on just those topics.</p>
        <p>Another good use for custom GPTs is to recommend products based on your users’ search and purchase history—similar to the “people who bought this also bought” feature you see on many ecommerce sites. If you can save and store that data in a knowledge base, you can use a custom GPT to implement the solution. You can also use custom GPTs for content creation, language translations, and marketing messages created for social media (though these will still need human editors to check for accuracy and brand tone before publishing). Any generative AI product can be customized with its own GPT for your <a contenteditable="false" data-type="indexterm" data-primary="custom GPTs" data-secondary="benefits of" data-startref="custom-gpt-benefit" id="id664"/>brand.</p>
        <p>Before you create a custom GPT, you first need to define several factors:</p>
        <ul>
          <li>
            <p>What do you want the GPT to generate? Answers to customers’ questions? Content for your site?</p>
          </li>
          <li>
            <p>What tone do you want to use? Maybe you want to generate content in pirate-speak for children’s learning or you want your GPT to stay professional and answer customers’ queries. GPTs can generate responses using a specific tone and personality. </p>
          </li>
          <li>
            <p>What are your data sources? Will you be using a database of orders for your ecommerce chatbot assistant, recent search data collected from your site, or general knowledge about your market?</p>
          </li>
        </ul>
        <p>Answers to these questions will be used to set up and configure your custom GPT. Don’t forget that you still need to monitor and continually update your GPT with new data as you incorporate more information in your knowledge base. After the GPT’s initial deployment, it’s common for businesses to find bugs or make changes to configurations as well.</p>
        <section data-type="sect2" data-pdf-bookmark="Creating a Custom GPT"><div class="sect2" id="ch06_creating_a_custom_gpt_1748359259642590">
          <h2>Creating a Custom GPT</h2>
          <p class="pagebreak-after">To create<a contenteditable="false" data-type="indexterm" data-primary="custom GPTs" data-secondary="creating" id="custom-gpt-create"/><a contenteditable="false" data-type="indexterm" data-primary="OpenAI" data-secondary="custom GPT creation" id="openai-custom-gpt-create"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT" data-secondary="custom GPT creation" id="chatgpt-custom-gpt-create"/> a custom GPT, you first need an OpenAI Plus account. OpenAI has a free version of ChatGPT, but you cannot create custom GPTs or use the latest version of ChatGPT. As of the time of writing, a Plus subscription costs $20 per month. You can also work with a Team account for enterprises at $25 per person per month. The examples shared here were created using the Plus subscription of ChatGPT.</p>
          <p>In your Plus OpenAI account, click the icon with your initials in the upper-right corner as shown in <a data-type="xref" href="#ch06_figure_1_1748359259618009">Figure 6-1</a> and then click My GPTs. OpenAI has its own tool to help you create your custom GPT, so you get some direction as you go through the process.</p>
          <figure><div id="ch06_figure_1_1748359259618009" class="figure">
            <img src="assets/ugai_0601.png" width="301" height="393"/>
            <h6><span class="label">Figure 6-1. </span>OpenAI’s drop-down menu for accessing custom GPTs</h6>
          </div></figure>
          <p>Next, click Create a GPT, as shown in <a data-type="xref" href="#ch06_figure_2_1748359259618055">Figure 6-2</a>.</p>
          <figure class="pagebreak-after"><div id="ch06_figure_2_1748359259618055" class="figure">
            <img src="assets/ugai_0602.png" width="408" height="122"/>
            <h6><span class="label">Figure 6-2. </span>OpenAI interface to create a new custom GPT</h6>
          </div></figure>
          <p>You’re now in the interface to create your custom GPT. You should be looking at a web page like the one shown in <a data-type="xref" href="#ch06_figure_3_1748359259618082">Figure 6-3</a>.</p>
          <figure><div id="ch06_figure_3_1748359259618082" class="figure">
            <img src="assets/ugai_0603.png" width="743" height="263"/>
            <h6><span class="label">Figure 6-3. </span>First prompt to create a custom GPT in the OpenAI web interface</h6>
          </div></figure>
          <p>Let’s create a custom GPT that answers questions about writing a book. We want a GPT that helps writers understand the process of outlining, writing, editing, proofing, and publishing an ebook. Because ChatGPT is conversational, we can enter instructions using the same tone you would use to instruct a writer in person. We’ll use the following prompt:</p>
          <blockquote>
            <p>I want a custom GPT that helps writers understand the process of outlining, writing, editing, proofing, and publishing an ebook.</p>
          </blockquote>
          <p>You’ll see a wait message indicating that a custom GPT is being created. Then, you’ll receive a suggestion for a GPT name. For simplicity, we’ll use the suggested title “Ebook Guide” shown in the interface in <a data-type="xref" href="#ch06_figure_4_1748359259618104">Figure 6-4</a>. ChatGPT will also generate a suggested image. For simplicity, we’ll use the suggested image.</p>
          <figure><div id="ch06_figure_4_1748359259618104" class="figure">
            <img src="assets/ugai_0604.png" width="683" height="762"/>
            <h6><span class="label">Figure 6-4. </span>OpenAI instructions for a custom GPT</h6>
          </div></figure>
          <p>The example creates a custom GPT for you, but you can save yourself some time by using third-party custom GPTs available in the OpenAI marketplace. In the OpenAI interface, you’ll see a button for Explore GPTs in the top-left corner. Clicking this button opens an interface where you can search for custom GPTs that others have developed. The quality and usefulness of these GPTs vary depending on the creators, but you can find dozens of custom GPTs for SEO already built and ready to use.</p>
          <p class="pagebreak-before">As an example, suppose you want to improve engagement with your content. Several custom GPTs are available that can help with content tweaks to improve readability and give the text a more human tone. You can also use these GPTs for keyword focusing, editing, fact-checking, analyzing content for gaps, analyzing links to compare your content with competitors’ content, and numerous other tasks that you can leverage without the need to create and customize<a contenteditable="false" data-type="indexterm" data-primary="custom GPTs" data-secondary="creating" data-startref="custom-gpt-create" id="id665"/><a contenteditable="false" data-type="indexterm" data-primary="OpenAI" data-secondary="custom GPT creation" data-startref="openai-custom-gpt-create" id="id666"/><a contenteditable="false" data-type="indexterm" data-primary="ChatGPT" data-secondary="custom GPT creation" data-startref="chatgpt-custom-gpt-create" id="id667"/> your own GPT.</p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Configuring Your GPT"><div class="sect2" id="ch06_configuring_your_gpt_1748359259642649">
          <h2>Configuring Your GPT</h2>
          <p>At the<a contenteditable="false" data-type="indexterm" data-primary="custom GPTs" data-secondary="configuring" id="custom-gpt-configure"/> top of the ChatGPT creation window is a Configure button. Click it to see the configuration options. For example, ChatGPT gives you suggested conversation starters to help your users, but you can write your own to fit your brand and the questions you commonly get from customers. In this window, you can also change the description and title of your GPT.</p>
          <p>If you already have a knowledge base for your business, that’s where the real power lies because you can generate content and answers for your brand and customers. In the configuration window, you can upload files to add your knowledge base to your custom GPT. Since this example is a chatbot to help writers, you could upload files with tips and tricks for outlining, writing chapters, and self-editing. This information is ingested and incorporated into your custom GPT’s responses to queries.</p>
          <p>For brands, you can upload files like data sheets or marketing brochures that explain your products. An enterprise could have thousands of pages of product information, and a custom GPT will ingest those in seconds and use the data for customer queries. Instead of training a team of people to answer questions, a custom GPT becomes your customer support team to help answer brand questions (though you will still want some level of human oversight).</p>
          <p>Instructions for our custom GPT are shown in <a data-type="xref" href="#ch06_figure_5_1748359259618124">Figure 6-5</a>.</p>
          <figure><div id="ch06_figure_5_1748359259618124" class="figure">
            <img src="assets/ugai_0605.png" width="922" height="884"/>
            <h6><span class="label">Figure 6-5. </span>Configuration window for a custom GPT</h6>
          </div></figure>
          <p>Notice that you can give your custom GPT image generation capabilities. You could include this option if you want to create custom images for your brand. For basic chatbots, you probably don’t want to allow this option. Another added function is code interpretation. You might use this function, for example, if you have a custom GPT for a GitHub library where the GPT can answer questions about coding errors and bugs.</p>
          <p>You<a contenteditable="false" data-type="indexterm" data-primary="external APIs" data-secondary="custom GPTs and" id="external-api-custom-gpt"/><a contenteditable="false" data-type="indexterm" data-primary="APIs (application programming interfaces)" data-secondary="custom GPTs and" id="api-custom-gpt"/> can also hook your custom GPT into external APIs. The external APIs can feed your custom GPT’s data and knowledge. For example, suppose you want to continually feed new data to a user’s web shopping interface in an ecommerce store. You can feed data from an API to the custom GPT in real time to constantly update a customer’s suggestions with seasonal or current news content with an abnormal spike in popularity. </p>
          <p>In addition, you can create GPT actions, which enable users of your custom GPTs to make calls to APIs of tools outside ChatGPT so that you can significantly extend the functionality of your GPT. Users continue to make their requests using natural language, and the GPT automatically converts those requests into the JSON schema required by the API. This can include accessing third-party data stores, so you don’t need to download copies of their data, and it increases the resiliency of your custom GPT by allowing it to always access the latest data rather than a potentially outdated data store that you may have downloaded.</p>
          <p>After you’re finished configuring your GPT, click Create in the upper-right corner. You can publish it to only yourself (the “Only me” option), to anyone with the link (such as sharing with a team), or to the GPT store. The GPT store makes your custom GPT available to the public. </p>
          <p>After you create a custom GPT, your job isn’t over, though. You still need to test it. Your custom GPT will be available in your OpenAI dashboard. After publishing the GPT, you can click on it and ask it questions. </p>
          <p>As with anything AI, you never want to “set it and forget it” without any review, especially if you use advanced configurations with API integration. You might need to change the knowledge section or tweak the data returned by your API. Even after you tweak the custom GPT, you should check it thoroughly to ensure that it’s still returning helpful answers to<a contenteditable="false" data-type="indexterm" data-primary="external APIs" data-secondary="custom GPTs and" data-startref="external-api-custom-gpt" id="id668"/><a contenteditable="false" data-type="indexterm" data-primary="APIs (application programming interfaces)" data-secondary="custom GPTs and" data-startref="api-custom-gpt" id="id669"/><a contenteditable="false" data-type="indexterm" data-primary="custom GPTs" data-secondary="configuring" data-startref="custom-gpt-configure" id="id670"/><a contenteditable="false" data-type="indexterm" data-primary="GPTs (generative pretrained transformers), custom" data-startref="gpt-custom" id="id671"/><a contenteditable="false" data-type="indexterm" data-primary="custom GPTs" data-startref="custom-gpt" id="id672"/><a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="custom GPTs" data-startref="seo-automation-custom-gpt" id="id673"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="custom GPTs" data-startref="automation-custom-gpt" id="id674"/> customers’ queries.</p>
        </div></section>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Personalized and Dynamic Content Optimization"><div class="sect1" id="ch06_personalized_and_dynamic_content_optimization_1748359259642724">
        <h1>Personalized and Dynamic Content Optimization</h1>
        <p>The <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="personalized and dynamic content" id="seo-automation-personal-dynamic"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="personalized and dynamic content" id="automation-seo-personal-dynamic"/><a contenteditable="false" data-type="indexterm" data-primary="personalized content optimization" id="personal-content"/><a contenteditable="false" data-type="indexterm" data-primary="dynamic content optimization" id="dynamic-content"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="personalized and dynamic content" id="content-generate-personal-dynamic"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" id="rag"/>power of generative AI is in its ability to generate personalized and dynamic content at scale. The “at scale” power of generative AI is in automation. </p>
        <p>We created a custom GPT in the previous section, so now we’ll talk about generating personalized and dynamic content. GPT is sufficient for basic queries, but more advanced automation is done with a system called <em>retrieval-augmented generation</em> (RAG). RAG feeds data into an LLM from various sources that you control, ensuring that the generative AI tool you’re working with uses information that you know is correct. For RAG, you need more technical skills, but you can completely automate many of the manual SEO procedures that you might currently perform.</p>
        <section data-type="sect2" data-pdf-bookmark="An Introduction to RAG"><div class="sect2" id="ch06_an_introduction_to_rag_1748359259642798">
          <h2>An Introduction to RAG</h2>
          <p>RAG <a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="personalized and dynamic content" data-tertiary="RAG benefits" id="automation-seo-personal-dynamic-rag-benefit"/><a contenteditable="false" data-type="indexterm" data-primary="personalized content optimization" data-secondary="RAG benefits" id="personal-content-rag-benefit"/><a contenteditable="false" data-type="indexterm" data-primary="dynamic content optimization" data-secondary="RAG benefits" id="dynamic-content-rag-benefit"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="personalized and dynamic content" data-tertiary="RAG benefits" id="content-generate-personal-dynamic-rag-benefit"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="benefits of" id="rag-benefit"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="RAG benefits" id="llm-rag-benefit"/>architecture incorporates LLMs with traditional data storage systems. For example, you can use RAG with a standard relational database collecting data from a custom GPT, or you can use it with large datasets collected from web searches or knowledge bases. SEO practitioners can use RAG for generating content from data collected in keyword research, backlink analysis, or locally from your brand’s site.</p>
          <p>Merging data retrieval with dynamic data enables RAG systems to find similarity in content and use your unique knowledge base in crafting the output. LLMs take time to train, and many common models work with slightly older data, so they aren’t aware of more recent events. You can make the more recent information available through your RAG system. More important, using custom data will be much more efficient than relying on the data from broad LLM systems, and it can more easily be personalized for highly dynamic businesses. RAG architecture lets LLMs retrieve data during the time it takes to process a user query, allowing LLMs to ingest data in real time to produce more accurate answers with as much relevant context as possible. You get higher generative AI accuracy with content generation at scale. You can still get errors once you implement RAG to address them, but you can reduce the rate at which they occur.</p>
          <p>An LLM needs data to provide accurate answers, and generative AI tools still have significant issues with accuracy when data is insufficient. For example, suppose you want to identify common questions from a chatbot. Your chatbot collects questions and stores them in a relational database. You can feed an LLM questions and answers from the relational database to then generate content and upload it to a WordPress blog hosting your knowledge base. This process can be used to protect you from hallucinations that the generative AI tool may make. The<a contenteditable="false" data-type="indexterm" data-primary="hallucinations" id="id675"/> term <em>hallucinations</em> describes the inaccurate results you might get from AI when the LLM does not have enough reference material or simply references incorrect information found online.</p>
          <p>RAG content generation provides a personalized experience for your readers. Your business might launch a new product, so you now need to generate content for a knowledge base. It can take weeks to build out a large knowledge base for a new product, but generative AI can provide you with a draft for human review in minutes. APIs can have hundreds of endpoints, but generative AI can generate draft developer knowledge base content in minutes when developers deploy their solution. Anytime you need personalized content based on custom brand input, generative AI can <a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="personalized and dynamic content" data-tertiary="RAG benefits" data-startref="automation-seo-personal-dynamic-rag-benefit" id="id676"/><a contenteditable="false" data-type="indexterm" data-primary="personalized content optimization" data-secondary="RAG benefits" data-startref="personal-content-rag-benefit" id="id677"/><a contenteditable="false" data-type="indexterm" data-primary="dynamic content optimization" data-secondary="RAG benefits" data-startref="dynamic-content-rag-benefit" id="id678"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="personalized and dynamic content" data-tertiary="RAG benefits" data-startref="content-generate-personal-dynamic-rag-benefit" id="id679"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="benefits of" data-startref="rag-benefit" id="id680"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="RAG benefits" data-startref="llm-rag-benefit" id="id681"/>help.</p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="The Many Different Types of LLMs"><div class="sect2" id="ch06_the_many_different_types_of_llms_1748359259642858">
          <h2>The Many Different Types of LLMs</h2>
          <p>Before <a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="personalized and dynamic content" data-tertiary="LLM types" id="automation-seo-personal-dynamic-llm-type"/><a contenteditable="false" data-type="indexterm" data-primary="personalized content optimization" data-secondary="LLM types" id="personal-content-llm-type"/><a contenteditable="false" data-type="indexterm" data-primary="dynamic content optimization" data-secondary="LLM types" id="dynamic-content-llm-type"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="personalized and dynamic content" data-tertiary="LLM types" id="content-generate-personal-dynamic-llm-type"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="LLM types" id="rag-llm-type"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="types of" id="llm-type"/>you build out your RAG architecture, you need to determine which LLM you want to use. You have several options, but each one has its own tone when it writes content. For example, ChatGPT is one of the most popular generative AI models available, but it can be much more robotic sounding and verbose than some of the other platforms. Claude, on the other hand, produces content that is considered much closer to sounding human.</p>
          <div data-type="note" epub:type="note"><h6>Note</h6>
            <p>AI is quickly evolving, so it’s important to note that new LLMs and updates to existing LLMs will be available after the publication of this book. It’s likely that newer versions are available as you’re reading this. </p>
          </div>
          <p>Here are a few LLMs as of May 2025 that you can consider working with:</p>
          <dl>
            <dt>ChatGPT-4.5 and OpenAI o1</dt>
            <dd>
              <p>ChatGPT-4.5 is<a contenteditable="false" data-type="indexterm" data-primary="ChatGPT-4.5" id="id682"/><a contenteditable="false" data-type="indexterm" data-primary="OpenAI o1" id="id683"/> one of the more popular and flexible multimodal LLMs. It also has DALL-E for creating images. It’s fast and has been trained on the billions of pages published on the internet, including trillions of words of text, code, and translations. OpenAI fine-tunes its LLM with<a contenteditable="false" data-type="indexterm" data-primary="reinforcement learning from human feedback (RLHF)" id="id684"/><a contenteditable="false" data-type="indexterm" data-primary="RLHF (reinforcement learning from human feedback)" id="id685"/> reinforcement learning from human feedback (RLHF), which you can use to improve results as you work with the model. OpenAI o1 integrates advanced reasoning and is better for advanced coding, scientific research, or anything that requires step-by-step problem-solving. Keep in mind that o1 is slower and costs more per token. (<em>Tokens</em> are like <a contenteditable="false" data-type="indexterm" data-primary="tokens" id="id686"/>credits or digital currency to “pay” for generative AI output.)</p>
            </dd>
            <dt>Anthropic Claude 3.7 Sonnet and Opus</dt>
            <dd>
              <p>As of this writing, Claude 3.7 Sonnet is <a contenteditable="false" data-type="indexterm" data-primary="Claude 3.7" id="id687"/><a contenteditable="false" data-type="indexterm" data-primary="Claude" data-secondary="Sonnet" id="id688"/><a contenteditable="false" data-type="indexterm" data-primary="Claude" data-secondary="Opus" id="id689"/><a contenteditable="false" data-type="indexterm" data-primary="Anthropic" id="id690"/>the most recent LLM model from Anthropic. It’s known for having more humanlike output, but it also excels at analyzing visual input, such as graphs or photos. Sonnet is best for multistep workflows and is particularly effective for orchestrating tasks that require fast processing and context-sensitive responses. Claude Opus performs well with advanced content creation. It’s known for its ability to handle intricate tasks like generating detailed research reports, analyzing complex data, and creating high-quality content that demands a deeper understanding. </p>
            </dd>
            <dt>Google Gemini 1.5 Pro and 1.5 Flash</dt>
            <dd>
              <p>Google has<a contenteditable="false" data-type="indexterm" data-primary="Gemini 1.5 Pro" id="id691"/><a contenteditable="false" data-type="indexterm" data-primary="Gemini 1.5 Flash" id="id692"/><a contenteditable="false" data-type="indexterm" data-primary="Google Gemini" data-see="Gemini" id="id693"/> been using AI for years and published the original paper on transformers—the technology that LLMs are based on—in 2017. As of this writing, Google has two notable models: Google Gemini 1.5 Pro and 1.5 Flash. Both AI models can process text, images, audio, and video, but they have different uses and are optimized for different tasks. Gemini 1.5 Pro is designed for complex tasks and is better for deep reasoning and nuanced understanding. It can perform sophisticated reasoning tasks, such as generating summaries of long-form text, audio recordings, or video content. Gemini 1.5 Pro can also be used for content creation, story writing, and scriptwriting. Gemini 1.5 Flash is optimized for rapid response times and is better for applications that require quick processing and low latency. It’s ideal for time-sensitive tasks, such as chat applications and real-time data analytics.</p>
            </dd>
            <dt>Google PaLM 2</dt>
            <dd>
              <p>PaLM 2 is <a contenteditable="false" data-type="indexterm" data-primary="PaLM 2" id="id694"/><a contenteditable="false" data-type="indexterm" data-primary="Google PaLM 2" id="id695"/>designed for language applications while Gemini is designed for multimodal applications. PaLM 2 is better at advanced tasks like summarization and question answering in languages it knows well. Gemini is better at creative writing, such as poems, lyrics, or dialogue. If you’re dealing only with text-based modalities and need translations, you might consider <a href="https://oreil.ly/yqCV4">PaLM 2</a> to help produce content at scale for multiple languages.</p>
            </dd>
          </dl>
          <p>Several open source models also exist if you want to lower costs and customize models. We’ll discuss why and when to use custom LLMs in <a data-type="xref" href="#ch06_building_rag_architecture_1748359259642922">“Building RAG Architecture”</a>, but know that you have several options for open source LLMs if<a contenteditable="false" data-type="indexterm" data-primary="open source LLMs" id="id696"/> you have the technical expertise (or technical team) to customize a preexisting model. Open source LLMs may require a steeper learning curve but could have a lower overall cost of ownership after setup. Open source models are available to anyone, so vulnerabilities must be reported to the creator to be patched. Vulnerabilities are dangerous because they can be used to poison results or gain access to your data.</p>
          <p class="pagebreak-before">A few of the available open source models include:</p>
          <dl>
            <dt>Milvus</dt>
            <dd>
              <p>A <a contenteditable="false" data-type="indexterm" data-primary="Milvus" id="id697"/>vector database built for scale and machine learning applications</p>
            </dd>
            <dt>Meta Llama</dt>
            <dd>
              <p>An AI model<a contenteditable="false" data-type="indexterm" data-primary="Meta Llama" id="id698"/> provided for text-based output</p>
            </dd>
            <dt>Grok</dt>
            <dd>
              <p>An AI model for text-based output but built to be<a contenteditable="false" data-type="indexterm" data-primary="Grok" id="id699"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="personalized and dynamic content" data-tertiary="LLM types" data-startref="automation-seo-personal-dynamic-llm-type" id="id700"/><a contenteditable="false" data-type="indexterm" data-primary="personalized content optimization" data-secondary="LLM types" data-startref="personal-content-llm-type" id="id701"/><a contenteditable="false" data-type="indexterm" data-primary="dynamic content optimization" data-secondary="LLM types" data-startref="dynamic-content-llm-type" id="id702"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="personalized and dynamic content" data-tertiary="LLM types" data-startref="content-generate-personal-dynamic-llm-type" id="id703"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="LLM types" data-startref="rag-llm-type" id="id704"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="types of" data-startref="llm-type" id="id705"/> more conversational</p>
            </dd>
          </dl>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Building RAG Architecture"><div class="sect2" id="ch06_building_rag_architecture_1748359259642922">
          <h2>Building RAG Architecture</h2>
          <p>The <a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="personalized and dynamic content" data-tertiary="building RAG architecture" id="automation-seo-personal-dynamic-rag-archbuild"/><a contenteditable="false" data-type="indexterm" data-primary="personalized content optimization" data-secondary="building RAG architecture" id="personal-content-rag-archbuild"/><a contenteditable="false" data-type="indexterm" data-primary="dynamic content optimization" data-secondary="building RAG architecture" id="dynamic-content-rag-archbuild"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="personalized and dynamic content" data-tertiary="building RAG architecture" id="content-generate-personal-dynamic-rag-archbuild"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="building architecture" id="rag-archbuild"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="building RAG architecture" id="llm-rag-archbuild"/>algorithms and backend processing for RAG are complex, but creating the architecture has only two steps:</p>
          <ol>
            <li>
              <p>User input, such as a query from your site’s search functionality or a chatbot question</p>
            </li>
            <li>
              <p>The source data, which could be a database, a group of dynamically created files, a NoSQL database, web pages, or any other source that can be fed to an LLM</p>
            </li>
          </ol>
          <p>Although creating a custom GPT requires no coding, creating RAG architecture requires some technical knowledge. You can use your own local LLMs with RAG. We’ll use the same custom GPT that we created previously to generate output content. You can see an example of RAG infrastructure in <a data-type="xref" href="#ch06_figure_6_1748359259618143">Figure 6-6</a>.</p>
          <figure><div id="ch06_figure_6_1748359259618143" class="figure">
            <img src="assets/ugai_0606.png" width="1425" height="537"/>
            <h6><span class="label">Figure 6-6. </span>General overview of RAG infrastructure</h6>
          </div></figure>
          <p class="pagebreak-before">Suppose you need to create content about your brand, but you don’t want it to include knowledge that is too general about your products. Your brand might sell mobile phone accessories, but you don’t want a history of mobile phones in your content collection. You can use your own brand content to feed an LLM—in this case, ChatGPT—and then build content based on the input.</p>
          <p>In the following example, we’ll use keyword input to build brand content from a corpus of web pages on your site. For example, suppose you did some keyword research (which, incidentally, can be automated with AI, but more on that later), and you want to use common search phrases to build content around your brand. You can automate this using your language of choice. Examples in this section will use Python. </p>
          <p>To create a RAG implementation, you need three things:</p>
          <ul>
            <li>
              <p>A corpus, or the collection of data the LLM will use to generate content </p>
            </li>
            <li>
              <p>The API for ChatGPT for the LLM</p>
            </li>
            <li>
              <p>Content generation from input of keywords or search phrases</p>
            </li>
          </ul>
          <section data-type="sect3" data-pdf-bookmark="Gathering the corpus"><div class="sect3" id="ch06_gathering_the_corpus_1748359259643007">
            <h3>Gathering the corpus</h3>
            <p>The first <a contenteditable="false" data-type="indexterm" data-primary="corpus" id="id706"/>step to creating a RAG implementation is to gather the corpus. The <em>corpus</em> is the collection of data used to train AI. It’s a fancy term for “background knowledge.” You can use any amount of corpus data, including information stored in a database, web pages, static files, and even images. </p>
            <p>Without the corpus, you will get general information in response to the input provided. For example, if you input “mobile phone,” you’ll get all kinds of output ranging from the history of the mobile phone to mobile phone vendors to questions and answers about fixing a mobile phone. If you’re selling accessories, this information will pollute your content output. The corpus will train the LLM on your brand and target audience so that you can get much more precise and accurate results. </p>
            <p class="pagebreak-after">In our example, a local collection of brand web pages will serve as the corpus. In a real-world situation, you’d crawl your site or use a sitemap to add to the corpus, but for simplicity we’ll use hardcoded text for our example. The following code example has a sentence or two to represent a brand page, but your web pages will contain several lines of content to train the LLM. Notice that the corpus is specific to our brand: </p>
            <pre data-type="programlisting" data-code-language="python"><code class="n">brand_corpus</code> <code class="o">=</code> <code class="p">[</code>
  <code class="s2">"This yellow mobile phone case is perfect for the iPhone 16 and can..."</code><code class="p">,</code>
  <code class="s2">"Mobile phone cases are perfect for protecting your device from rain..."</code><code class="p">,</code>
  <code class="s2">"Our mobile phone accessories cost between $10 and $100 and can be..."</code>
<code class="p">]</code></pre>
          </div></section>
          <section data-type="sect3" data-pdf-bookmark="Connecting to the LLM API"><div class="sect3" id="ch06_connecting_to_the_llm_api_1748359259643068">
            <h3>Connecting to the LLM API</h3>
            <p>After <a contenteditable="false" data-type="indexterm" data-primary="external APIs" data-secondary="connecting to" id="external-api-connect"/><a contenteditable="false" data-type="indexterm" data-primary="APIs (application programming interfaces)" data-secondary="connecting to" id="api-connect"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="API connections" id="llm-api-connect"/>you have the corpus, you then need to connect to the LLM API. For this example, we’ll use ChatGPT as the LLM, but several others have APIs (e.g., Microsoft Azure, Google Cloud, Anthropic, Hugging Face). You’ll need an account, which must be a paid account for any of the major LLMs. Every API also requires access keys. You can find out how to generate keys for your account in the LLM’s documentation. We’ll assume you have the OpenAI Python library installed. If not, you can use the following install prompt in your Python development interface:</p>
            <pre data-type="programlisting">pip install --upgrade openai</pre>
            <p>With OpenAI installed, you can now create a connection to<!--<a contenteditable="false" data-type="indexterm" data-primary="external APIs" data-secondary="connecting to" data-startref="external-api-connect">&nbsp;</a>--><!--<a contenteditable="false" data-type="indexterm" data-primary="APIs (application programming interfaces)" data-secondary="connecting to" data-startref="api-connect">&nbsp;</a>--><!--<a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="API connections" data-startref="llm-api-connect">&nbsp;</a>--> the ChatGPT API:</p>
            <pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">openai</code> <code class="kn">import</code> <code class="n">OpenAI</code>
<code class="n">client</code> <code class="o">=</code> <code class="n">OpenAI</code><code class="p">(</code><code class="n">api_key</code><code class="o">=</code><code class="s2">"..."</code><code class="p">)</code></pre>
          </div></section>
          <section data-type="sect3" data-pdf-bookmark="Generating content from user input"><div class="sect3" id="ch06_generating_content_from_user_input_1748359259643125">
            <h3>Generating content from user input</h3>
            <p>Now <a contenteditable="false" data-type="indexterm" data-primary="user input, content generation from" id="user-input-content-generate"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="from user input" id="content-generate-user-input"/><a contenteditable="false" data-type="indexterm" data-primary="keyword research" data-secondary="building RAG architecture" id="keyword-research-ch6"/>you need the code to pull a document—a web page in this scenario—and you’ll work with user input to create content. Our user input is from keyword research. Keyword research can be done manually using the SEO tools mentioned in <a data-type="xref" href="#ch06_ai_powered_seo_tools_for_inspiration_1748359259642457">“AI-Powered SEO Tools for Inspiration”</a>, or you can perform research using automated agents (discussed in the next section). For this example, it’s assumed you have a list of keywords in a text file:</p>
            <pre data-type="programlisting" data-code-language="python" class="widows20"><code class="kn">from</code> <code class="nn">openai</code> <code class="kn">import</code> <code class="n">OpenAI</code>
<code class="n">client</code> <code class="o">=</code> <code class="n">OpenAI</code><code class="p">(</code><code class="n">api_key</code><code class="o">=</code><code class="s2">"your_api_key"</code><code class="p">)</code>
 
<code class="n">brand_corpus</code> <code class="o">=</code> <code class="p">[</code>
  <code class="s2">"This yellow mobile phone case is perfect for the iPhone 16 and can..."</code><code class="p">,</code>
  <code class="s2">"Mobile phone cases are perfect for protecting your device from rain..."</code><code class="p">,</code>
  <code class="s2">"Our mobile phone accessories cost between $10 and $100 and can be..."</code>
<code class="p">]</code>

<code class="n">prompt</code> <code class="o">=</code> <code class="p">(</code>
  <code class="s2">"Create a 500 word article and incorporate brand information "</code>
  <code class="s2">"from this content: </code><code class="si">{brand_page}</code><code class="s2">. Use this keyword as the "</code>
  <code class="s2">"focus for the topic: </code><code class="si">{keyword}</code><code class="s2">."</code>
<code class="p">)</code>
 
<code class="n">response</code> <code class="o">=</code> <code class="n">client</code><code class="o">.</code><code class="n">chat</code><code class="o">.</code><code class="n">completions</code><code class="o">.</code><code class="n">create</code><code class="p">(</code>
  <code class="n">model</code><code class="o">=</code><code class="s2">"gpt-4"</code><code class="p">,</code>
  <code class="n">messages</code><code class="o">=</code><code class="p">[</code>
    <code class="p">{</code>
      <code class="s2">"role"</code><code class="p">:</code> <code class="s2">"user"</code><code class="p">,</code>
      <code class="s2">"content"</code><code class="p">:</code> <code class="n">prompt</code><code class="o">.</code><code class="n">format</code><code class="p">(</code>
          <code class="n">brand_page</code><code class="o">=</code><code class="n">brand_content</code><code class="p">[</code><code class="mi">0</code><code class="p">],</code>
          <code class="n">keyword</code><code class="o">=</code><code class="s2">"iphone 16"</code>
      <code class="p">)</code>
    <code class="p">}</code>
  <code class="p">]</code>
<code class="p">)</code>
 
<code class="nb">print</code><code class="p">(</code><code class="n">response</code><code class="p">)</code></pre>
            <p>This example is simple, but you can incorporate agent output and automation into content generation and RAG. The important part of this code is the prompt. The prompt is sent to the LLM and tells it what to use to generate content. </p>
            <p>LLMs can generate more than simple page content. You could use competitor analysis to create a list of publications for backlink opportunities, find the top five competitor pages and their keywords to create drafts of your own content, create outlines from a gap analysis from your pages compared to competitors’ pages, or simply make content based on trending keywords, just like we did here. </p>
            <p>Using RAG gives your brand the ability to work with real-time data for content generation, but you don’t always need human queries. You can automate draft content generation using agents to identify keywords and input these keywords into your <a contenteditable="false" data-type="indexterm" data-primary="user input, content generation from" data-startref="user-input-content-generate" id="id707"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="from user input" data-startref="content-generate-user-input" id="id708"/><a contenteditable="false" data-type="indexterm" data-primary="keyword research" data-secondary="building RAG architecture" data-startref="keyword-research-ch6" id="id709"/>RAG system. </p>
          </div></section>
          <section data-type="sect3" data-pdf-bookmark="Custom LLMs or building from scratch"><div class="sect3" id="ch06_custom_llms_or_building_from_scratch_1748359259643184">
            <h3>Custom LLMs or building from scratch</h3>
            <p>In the preceding example, we used ChatGPT as the model, but you aren’t limited to common LLMs. You can also use <a contenteditable="false" data-type="indexterm" data-primary="custom LLMs" id="id710"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="custom LLMs" id="id711"/>custom LLMs, but you should use them only with very specific use cases. The common LLMs mentioned previously have trillions of data points to work with, so you can ask them anything with varying degrees of results. With a custom LLM, you define the model and limit it to your specific use case. For most businesses, a custom LLM is not necessary. The model will be able to produce results only on certain data, so it does not have the additional information available with common LLMs.</p>
            <p>To <a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="creating" id="llm-create"/>create your own LLM, you need the infrastructure, a large corpus, testing resources, technical development experience, and funds to host it. Models require graphics processing unit (GPU) hours to compute training. You can use cloud providers to train a model, but of course you must pay for the resources. It costs about $1–$2 per GPU hour, so a small 10-billion parameter model that takes about 100,000 GPU hours could cost you up to $200,000 to train. For a frame of reference, Llama 2 has about 70 billion parameters, so it can cost well over $1 million to train a large model.</p>
            <p>There are four steps in building an LLM from scratch:</p>
            <dl class="pagebreak-after">
              <dt>Curating the data</dt>
              <dd>
                <p>This is the most time-consuming step. You need accurate, quality, deduplicated data and a source with enough information to train the model. You can use the internet, but you can also use public datasets, including Common Crawl and Hugging Face. Another option is using an LLM to create a dataset. Datasets should be diverse, depending on your desired output. You can use web pages, code, books, news, articles, and scientific journals.</p>
              </dd>
              <dt>Building the model architecture</dt>
              <dd>
                <p>This is a neural network with attention mechanisms to match input with output. Neural networks identify patterns and context so that a word can be “understood” compared to other similar words. For example, the neural network must identify the position and sequence of a word like <em>park</em>. It must identify if the word means to park a vehicle or a public place where people hang out.</p>
              </dd>
              <dt>Training</dt>
              <dd>
                <p>Training at scale is complex and requires high-value GPUs, mentioned previously. </p>
              </dd>
              <dt>Testing and review</dt>
              <dd>
                <p>You must evaluate and review the results of your model. The Hugging Face site has benchmarks that can be used to identify the success of your model.</p>
              </dd>
            </dl>
            <p>As you can tell, building your own LLM requires extreme technical knowledge. You need a team to help you and a large budget for compute power. If your use case is very specific, you can generate content that is highly targeted and effective at selling your brand services. This can boost sales and make it easier to build thousands of pages for your business with a good return on your investment, but it’s a long-term, high-value project that must be carefully planned <a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="creating" data-startref="llm-create" id="id712"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="personalized and dynamic content" data-tertiary="building RAG architecture" data-startref="automation-seo-personal-dynamic-rag-archbuild" id="id713"/><a contenteditable="false" data-type="indexterm" data-primary="personalized content optimization" data-secondary="building RAG architecture" data-startref="personal-content-rag-archbuild" id="id714"/><a contenteditable="false" data-type="indexterm" data-primary="dynamic content optimization" data-secondary="building RAG architecture" data-startref="dynamic-content-rag-archbuild" id="id715"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="personalized and dynamic content" data-tertiary="building RAG architecture" data-startref="content-generate-personal-dynamic-rag-archbuild" id="id716"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="building architecture" data-startref="rag-archbuild" id="id717"/><a contenteditable="false" data-type="indexterm" data-primary="LLMs (large language models)" data-secondary="building RAG architecture" data-startref="llm-rag-archbuild" id="id718"/>first.</p>
          </div></section>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Automating SEO Tasks with AI"><div class="sect2" id="ch06_automating_seo_tasks_with_ai_1748359259643251">
          <h2>Automating SEO Tasks with AI</h2>
          <p>Think of<a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="personalized and dynamic content" data-tertiary="AI agents as SEO assistants" id="automation-seo-personal-dynamic-agent"/><a contenteditable="false" data-type="indexterm" data-primary="personalized content optimization" data-secondary="AI agents as SEO assistants" id="personal-content-agent"/><a contenteditable="false" data-type="indexterm" data-primary="dynamic content optimization" data-secondary="AI agents as SEO assistants" id="dynamic-content-agent"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="personalized and dynamic content" data-tertiary="AI agents as SEO assistants" id="content-generate-personal-dynamic-agent"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="AI agents as SEO assistants" id="rag-agent"/><a contenteditable="false" data-type="indexterm" data-primary="agents (AI), as SEO assistants" id="agent-seo-assist"/> AI agents as your automated assistants. Your automated SEO assistant might know that every morning you need keyword research on the latest trends affecting your brand. The agent pulls information from an API and inputs keywords into generative AI prompts for content suggestions. An AI agent can gather this data for you every day, so you don’t have to rely on a person to perform this task. Your AI agent can also analyze trends multiple times during the day so that you can change your goals as trends change, making your marketing much more effective.</p>
          <p>Suppose that after an agent performs trend analysis for you, you decide to create content or perform competitor analysis to see if competitors are ranking for specific keywords already. You can have multiple agents “talking” to one another to make decisions based on their own output. The AI agent gathering trends every morning can send output to another agent that will make the decision to generate content based on competitor analysis. The second agent can take these trends, find the top five pages for related search terms, and decide if content should be generated. Content generation decisions can also be sent to a third agent to create draft content ideas based on its own analysis.</p>
          <p>Agents are powerful automation tools, but they need a goal. When you build an agent, you can integrate generative AI models to help agents make decisions. For example, you can have an agent using Claude to evaluate content generated from ChatGPT. The back-and-forth evaluation can be used to generate and evaluate content until you create a piece that fits your tone and brand style. </p>
          <p>In this section, we’ll break down the components of an agent system for generating content for a brand.</p>
          <section data-type="sect3" data-pdf-bookmark="Infrastructure for AI agents"><div class="sect3" id="ch06_infrastructure_for_ai_agents_1748359259643317">
            <h3>Infrastructure for AI agents</h3>
            <p>An AI agent is like a script running silently on a machine. <a data-type="xref" href="#ch06_figure_7_1748359259618161">Figure 6-7</a> shows a few potential roles for agents.</p>
            <figure><div id="ch06_figure_7_1748359259618161" class="figure">
              <img src="assets/ugai_0607.png" width="918" height="437"/>
              <h6><span class="label">Figure 6-7. </span>Potential roles for agents</h6>
            </div></figure>
            <p>When you build your own agents, you need infrastructure to host them. The development can be done in any language, but AI is generally built with Python because of its prebuilt libraries, which are freely available to developers. You aren’t limited to Python, though, and some businesses choose to use R, Java, C++, JavaScript, Lisp, and other languages. </p>
            <p>You’ll likely use hosting in the cloud for the ease of resource allocation, but you need more than host machines. Here are several factors to consider for your AI agent infrastructure:</p>
            <dl>
              <dt>Database storage and management</dt>
              <dd>
                <p>AI requires data for training, and your database of choice can store it. You don’t need a database if you plan to ingest data entirely from the internet, but chances are you will want to log errors and track what your AI agent is doing, which still requires a database to store this data. Also consider the type of data you plan to store. Unstructured data requires a NoSQL database, but structured data can use traditional relational databases. For example, storing web page data is easier with unstructured databases like MongoDB, but logged events could use a relational database like MariaDB or PostgreSQL.</p>
              </dd>
              <dt>Internet access</dt>
              <dd>
                <p>Your agents will likely run on a local network, but they need access to the internet if you plan to understand the third-party content on your topic out there, use third-party APIs, or post content to your public-facing site.</p>
              </dd>
              <dt>Virtual machines or compute resources</dt>
              <dd>
                <p>Agents are like services that execute an action at a time you program. This could be once a day or multiple times a day. You need a host machine and compute resources to run the agent and process its results. Don’t provision resources that handle only the initial agent processing. You want enough resources for scaling as you acquire more data and add more agent tasks.</p>
              </dd>
              <dt>Security</dt>
              <dd>
                <p>Don’t forget that security should be integrated into your design workflow. Poor security could open your business to lawsuits or data disclosure. Validate data, especially when using external internet sources for ingestion and output.</p>
              </dd>
            </dl>
          </div></section>
          <section data-type="sect3" data-pdf-bookmark="Agent roles"><div class="sect3" id="ch06_agent_roles_1748359259643380">
            <h3>Agent roles</h3>
            <p>We will have four agents that will fulfill the following roles:</p>
            <dl>
              <dt>SEO analyst</dt>
              <dd>
                <p>This agent will take common keywords for a brand and get the top articles (or top list of articles) from competitors ranking for them.</p>
              </dd>
              <dt>Researcher</dt>
              <dd>
                <p>You want content that can perform better than a competitor, so the researcher will evaluate each section of content.</p>
              </dd>
              <dt>Writer</dt>
              <dd>
                <p>The research agent will feed output to the writer agent, and this agent will generate ideas and—if necessary—a summary of these ideas used for drafting content with generative AI. A human writer can then take these ideas and write content that will be fed to the content editor. You might even have a human editor review content and skip the content editor agent.</p>
              </dd>
              <dt>Content editor</dt>
              <dd>
                <p>The first pass on draft content might not match what you need, so an editor agent can be used to identify mismatched tone and technical information.</p>
              </dd>
            </dl>
            <section data-type="sect4" data-pdf-bookmark="SEO analyst"><div class="sect4" id="ch06_seo_analyst_1748359259643440">
              <h4>SEO analyst</h4>
              <p>As an <a contenteditable="false" data-type="indexterm" data-primary="SEO analysts, AI agents as" id="seo-analyst"/>SEO practitioner, you likely monitor specific keywords for your brand. You might have a list of trending keywords, a list of seasonal keywords, and general brand-related keywords used to generate content. You could manually identify competitor performance in search engines, but an AI-powered agent can do it for you. An agent will take less time to perform this step, and it can perform analysis several times a day rather than having to rely on an analyst to do this manually. You might even automate this step, having this agent feed into the next agent to increase efficiency.</p>
              <p>The SEO analyst agent can pull the top list of articles either from a third-party API or using your own search engine scraping solution. Not only will the agent identify the top-ranking pages, but it will also extract the content from each article. Every agent needs a goal, and this agent’s goal is to pull top-ranking articles for a list of keywords. As you can imagine, this is a full-time job for a human SEO analyst, but AI-powered agents can perform this activity in seconds. An SEO analyst agent is your first step to using AI to power activity at scale without staffing limitations.</p>
              <p>As you build this agent, you write code to cover the actions that other agents need to perform. Here are a few examples of tasks you might need agents to do, all of which can be prompts entered into one of the common models:</p>
              <ul>
                <li>
                  <p>Keep a log of sites you want to track, such as competitors’ sites or sites that have content you want to analyze. Make sure to create prompts with a list of sites or ask the model to pull a list of the top-ranking content for a specific search query.</p>
                </li>
                <li>
                  <p>Extract content from code. This can be done using a third-party library. You need headers, title, and section content, but you don’t need code or formatting. You should keep links, though, and their anchor text.</p>
                </li>
                <li>
                  <p>Avoid recrawling the same content over and over. Some server headers return a last updated variable, but that’s rare. It might be worth keeping a log of URLs previously scraped unless you want to analyze updated content. To save resources, you can recrawl competitor content only when the search ranking increases.</p>
                </li>
                <li>
                  <p>Server statistics might be useful if you are analyzing redirects or errors, so it may be helpful to pull and log server responses. For example, the first time you pull articles could result in a server 404 error, so you want to retry when the agent performs its activity <a contenteditable="false" data-type="indexterm" data-primary="SEO analysts, AI agents as" data-startref="seo-analyst" id="id719"/>again.</p>
                </li>
              </ul>
            </div></section>
            <section data-type="sect4" data-pdf-bookmark="Researcher"><div class="sect4" id="ch06_researcher_1748359259643494">
              <h4>Researcher</h4>
              <p>After <a contenteditable="false" data-type="indexterm" data-primary="researchers, AI agents as" id="research-ai-agent"/>you extract content from top-ranking search links, you need to analyze the content. The SEO analyst agent sends its output to the researcher agent. At scale, this is where the power of AI can really make you more efficient. A person could feasibly go through several articles during the day to identify content quality, but they can’t go through dozens of articles a day without help. The SEO research agent uses an LLM to analyze the content for opportunities to improve.</p>
              <p>As the researcher analyzes content, it must determine content keywords and if your brand has opportunities to write better content. It’s important to note that you want better content, not content that’s “just as good.” The SEO researcher agent can help perform this step for you in seconds. With an objective analysis, the next agent can assist with building draft content.</p>
              <p>To generate better content, the researcher agent might even perform secondary searches based on extracted keywords or work with your current brand content to identify whether content should be added to existing articles rather than creating an entirely new page. You might have a page already ranking in search engines, so you may choose to add new relevant content to that. The researcher agent could also do a gap analysis to identify the difference between competitors’ content and your own so that you can improve your content in line with what’s ranking in search. </p>
              <p>The researcher agent is limited only by what you can code. You can have additional researcher agents in your scaled system, but for this example, we’ll use the goal of identifying additional content that can be generated on your site. After the researcher agent has finished its analysis, new content ideas are sent to the writer agent.</p>
              <p>Much of the “meat” of your analysis can be done with this agent. Here are a few technical aspects that should be coded into your agent:</p>
              <ul>
                <li>
                  <p>Extract keywords using generative AI prompts for help. You could code your own extractor, but that would be extremely tedious. Generative AI can do this for you.</p>
                </li>
                <li>
                  <p>Compare the title of the article with your own and other articles ranking in search engines. Research agents can suggest better titles to potentially improve rankings.</p>
                </li>
                <li>
                  <p>Perform a gap analysis on your content with the content extracted from top-ranking articles. You can prompt generative AI to do the gap analysis for you, so you don’t need to create any complex code that could take days to build and test.</p>
                </li>
                <li>
                  <p>Using a gap analysis and generative AI results, determine the content you want to write and the content you want to update. You might have content that must be rewritten or sections that need to be added. Other keywords could be used to generate new content.</p>
                </li>
                <li>
                  <p>Use a secondary model to fact-check <a contenteditable="false" data-type="indexterm" data-primary="researchers, AI agents as" data-startref="research-ai-agent" id="id720"/>content.</p>
                </li>
              </ul>
            </div></section>
            <section data-type="sect4" data-pdf-bookmark="Writer"><div class="sect4" id="ch06_writer_1748359259643549">
              <h4>Writer</h4>
              <p>If you <a contenteditable="false" data-type="indexterm" data-primary="writers, AI agents as" id="writer-ai-agent"/>already use an LLM to write draft content, you know the prompts involved with writing. The writer agent calls an LLM API to draft the content. You’ll need to experiment to find the LLM that works best for you. Most people think of ChatGPT for content creation, but ChatGPT’s output can often seem robotic. You can still use ChatGPT if that’s your preference. Your reviews and the editor agent (discussed in the next section) should perform fact-checking and validate content tone.</p>
              <p>The prompt you use for the LLM depends on your goals. This agent sends the writing prompt to the LLM’s API. You’ll need the keyword, tone, intent (e.g., informational or transactional), audience, and any brand pages you want to use to shape the draft content around your own products. The API returns content, but you can’t leave generative AI to write content without any type of validation.</p>
              <p>As you build your agent system, always review the content to ensure it is still accurate and that the agents are working as they should. When LLMs deploy version upgrades, you may want to upgrade your generative AI draft content process for the latest version. An update will generate different content compared to older versions, so always review new content after upgrading the version.</p>
              <p>The writer agent is familiar territory if you’ve already used generative AI for content. The difference is that the agent automates the creation of draft content. Some technical tasks of this agent include:</p>
              <ul>
                <li>
                  <p>Generate section headers to separate content and make it easier for users to scan and find the information they want to read.</p>
                </li>
                <li>
                  <p>Ask generative AI to create engaging call-to-action links to your products.</p>
                </li>
                <li>
                  <p>Include links to other content within your site.</p>
                </li>
                <li>
                  <p>Generate meta descriptions, titles, and a summary of the content.</p>
                </li>
                <li>
                  <p>Build questions and answers and focus content on problems that your brand solves.</p>
                </li>
                <li>
                  <p>Use examples of your own content or content that you like to get the style and tone you’re looking for.</p>
                </li>
              </ul>
              <p>Note the emphasis on draft content creation in this section. Generative AI cannot be depended upon to write content that you can publish without expert human review. Recall our analogy of having a team of junior researchers working for you from earlier in this chapter. Generative AI is prone to mistakes, it will miss important things, it will not capture your position accurately, and more. The editor agent that we discuss in the next section helps make your content better by addressing some of these issues, but you still need expert human review before you <a contenteditable="false" data-type="indexterm" data-primary="writers, AI agents as" data-startref="writer-ai-agent" id="id721"/>publish.</p>
            </div></section>
            <section data-type="sect4" data-pdf-bookmark="Editor"><div class="sect4" id="ch06_editor_1748359259643604">
              <h4>Editor</h4>
              <p>The <a contenteditable="false" data-type="indexterm" data-primary="editors, AI agents as" id="editor-ai-agent"/>final agent in your system checks the writer agent’s draft content. Just as in a real-world publishing system, a writer needs an editor to identify awkward wording, factual issues, or unclear sections or to add content that improves the quality and readability of the text. The editor agent performs this step without you having to hire dozens of editors. With generative AI, you create content at a greater scale than you can with human writers, so you need to scale your editors as well.</p>
              <p>As mentioned in the previous section, you should have a second LLM check for errors and content tone instead of the same one. This will improve the accuracy of the results. If the editor agent has issues with content, you could send it back to the writer agent to have the content rewritten. Another option is having the editor generate improved content, but this depends on your system design. How you set up your agent design depends on your preferences, but we recommend having your editor agent validate content only and send feedback to the writer agent. This keeps your system compartmentalized so that you can easily make changes to content generation in one location.</p>
              <p>The editor agent can also log feedback and content-generation events for further review to help you with your management. For example, you may want to know how much content was kicked back to the writer agent for factual mistakes, which is serious when you want to be seen as an authority in your industry. The editor agent can log these events so that you can take a look when too many mistakes are being made. You might need to tweak the prompt, or your code could have logic errors.</p>
              <p>As with human writers, the draft content output from generative AI needs an editor. You need to fact-check output and ensure that the content has a human tone. Some models like ChatGPT can sound very robotic, but other models, such as Claude, are known for sounding a bit more humanlike, so check for the tone of the output. </p>
              <p>Here are a few technical points for creating an editor agent:</p>
              <ul>
                <li>
                  <p>Fact-check output. You fact-checked competitor content with the researcher agent, but you must again fact-check the new output to avoid publishing embarrassing misinformation on your brand site.</p>
                </li>
                <li>
                  <p>Check for tone using a third model. For example, use Claude to check ChatGPT content for any tone issues or errors.</p>
                </li>
                <li>
                  <p>Send content to a human reviewer before publishing any AI-generated content.</p>
                </li>
                <li>
                  <p>If any errors are found, this agent can send content back to a writer agent to reanalyze and<a contenteditable="false" data-type="indexterm" data-primary="editors, AI agents as" data-startref="editor-ai-agent" id="id722"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="personalized and dynamic content" data-tertiary="AI agents as SEO assistants" data-startref="automation-seo-personal-dynamic-agent" id="id723"/><a contenteditable="false" data-type="indexterm" data-primary="personalized content optimization" data-secondary="AI agents as SEO assistants" data-startref="personal-content-agent" id="id724"/><a contenteditable="false" data-type="indexterm" data-primary="dynamic content optimization" data-secondary="AI agents as SEO assistants" data-startref="dynamic-content-agent" id="id725"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="personalized and dynamic content" data-tertiary="AI agents as SEO assistants" data-startref="content-generate-personal-dynamic-agent" id="id726"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-secondary="AI agents as SEO assistants" data-startref="rag-agent" id="id727"/><a contenteditable="false" data-type="indexterm" data-primary="agents (AI), as SEO assistants" data-startref="agent-seo-assist" id="id728"/><a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="personalized and dynamic content" data-startref="seo-automation-personal-dynamic" id="id729"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="personalized and dynamic content" data-startref="automation-seo-personal-dynamic" id="id730"/><a contenteditable="false" data-type="indexterm" data-primary="personalized content optimization" data-startref="personal-content" id="id731"/><a contenteditable="false" data-type="indexterm" data-primary="dynamic content optimization" data-startref="dynamic-content" id="id732"/><a contenteditable="false" data-type="indexterm" data-primary="content generation" data-secondary="personalized and dynamic content" data-startref="content-generate-personal-dynamic" id="id733"/><a contenteditable="false" data-type="indexterm" data-primary="RAG (retrieval-augmented generation)" data-startref="rag" id="id734"/> re-create it.</p>
                </li>
              </ul>
            </div></section>
          </div></section>
        </div></section>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Using Enterprise Platforms for Large-Scale Projects"><div class="sect1" id="ch06_using_enterprise_platforms_for_large_scale_project_1748359259643666">
        <h1>Using Enterprise Platforms for Large-Scale Projects</h1>
        <p>As we <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="enterprise platforms" id="seo-automation-enterprise-platform"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="enterprise platforms" id="automation-enterprise-platform"/><a contenteditable="false" data-type="indexterm" data-primary="enterprise platforms" id="enterprise-platform"/>have said before, the power of advanced generative AI is in its ability to scale your SEO projects. You can easily generate one or two articles a day for your site, but AI can help you increase content production while improving content quality. In <a data-type="xref" href="ch02.html#ch02_essential_background_on_generative_ai_1748358211788823">Chapter 2</a>, we mentioned that using AI for content can increase throughput by 30%, reduce costs by 30%, and increase quality by 30%. </p>
        <p>To scale at an enterprise level, you need enterprise platforms. Several cloud platforms offer APIs and computing resources to support massive agent systems, generative AI content generation, automated analysis, and any other code-based SEO project. If you can code it, you need a place to host it.</p>
        <p>The biggest and most popular platforms are:</p>
        <dl>
          <dt>Microsoft Azure</dt>
          <dd>
            <p>Microsoft <a contenteditable="false" data-type="indexterm" data-primary="Microsoft Azure" id="id735"/><a contenteditable="false" data-type="indexterm" data-primary="Azure" id="id736"/>has made a large investment in OpenAI and is the creator of Copilot. <a href="https://oreil.ly/dtTcC">OpenAI’s API</a> has endpoints for chatbots, content management, and direct questions and answers.</p>
          </dd>
          <dt>Amazon Web Services (AWS)</dt>
          <dd>
            <p>Amazon <a contenteditable="false" data-type="indexterm" data-primary="Amazon Web Services (AWS)" id="id737"/><a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" id="id738"/>has several APIs and endpoints for all types of machine learning and generative AI. For example, <a href="https://oreil.ly/e98mO">Amazon Bedrock</a> helps with building generative AI applications. Bedrock can also be used in RAG.</p>
          </dd>
          <dt>OpenAI</dt>
          <dd>
            <p>OpenAI <a contenteditable="false" data-type="indexterm" data-primary="OpenAI" id="id739"/>has a convenient <a href="https://oreil.ly/jgFL7">API for content generation</a>. ChatGPT is popular for content generation, so it’s likely you’ll have at least one agent using the API.</p>
          </dd>
          <dt>Google Cloud Platform (GCP)</dt>
          <dd>
            <p>Google<a contenteditable="false" data-type="indexterm" data-primary="Google Cloud Platform (GCP)" id="id740"/><a contenteditable="false" data-type="indexterm" data-primary="GCP (Google Cloud Platform)" id="id741"/> has an <a href="https://oreil.ly/6j69Z">agent builder</a> that you can use to alleviate much of the technical overhead of building your own infrastructure. Vertex Agent Builder API can help with your workflows, and Gemini is beneficial for generating text and images.</p>
          </dd>
        </dl>
        <p>You aren’t limited to these four platforms, but these have integrated AI APIs and services already available. If you choose a smaller provider, make sure they have the resources to support generative AI and AI-powered automation.</p>
        <div data-type="tip"><h6>Tip</h6>
          <p>Once you integrate with a single API provider, you are tied to that particular provider. Therefore, you should ensure that the provider has all the features and scalability options for your current and future SEO projects. </p>
        </div>
        <p>Any API that you choose will be integrated into your agent programming. It does the heavy lifting for you so that you can rely on the third-party infrastructure to assist with generating content. The writing agent from our AI agent system example could use one of the content generation APIs to build the content, for example.</p>
        <p>Before you adopt a specific model, you must understand its limitations and what you can do to scale your operations. Using enterprise platforms is about scaling, but not every API offers the speed and content quality you need. The following are some of the most important features you’ll want to consider when selecting a provider for large-scale projects:</p>
        <dl>
          <dt>Availability</dt>
          <dd>
            <p>Most <a contenteditable="false" data-type="indexterm" data-primary="availability of enterprise platforms" id="id742"/>large providers offer at least 99% uptime service-level agreements, but regions are important for enterprise-level processing. The farther a region is from your processing, the more latency you’ll experience with a delay in transferring data. Availability regions are data centers present in the general geographic location of your business and your users. To take it a step further, availability zones are located in regions of a site user’s country for redundancy. For example, <a href="https://oreil.ly/wnDB8">Azure has 54 regions in 140 countries, AWS has 66 availability zones, and GCP has 173 zones</a>. Should one data center suffer from an outage, another availability zone can take over. Redundancy is important for failover and uptime. </p>
          </dd>
          <dt>Latency</dt>
          <dd>
            <p>Latency <a contenteditable="false" data-type="indexterm" data-primary="latency of enterprise platforms" id="id743"/>is the time it takes for data to transfer over the network, including processing at the database. Having low latency is critical to your application’s performance. CPU and storage performance play a part in latency, and these factors can turn a one-hour process into a daylong one if they are not optimized. When you have to use more computing to reduce latency, you will likely incur higher costs. Optimizing computing resources is a must and requires the technical know-how to create a scalable infrastructure that doesn’t waste your budget.</p>
            <p>Every provider does well with offering computing and networking power for various data-transfer sizes. <a href="https://oreil.ly/jUA1t">Benchmarks</a> show that GCP does the best with processing power, AWS does the best with network throughput, and Azure does the best with I/O throughput. You can test your applications on all three, but fast computing power and network performance are most important when working with large data searches and AI processing.</p>
          </dd>
          <dt>Cost</dt>
          <dd>
            <p>The <a contenteditable="false" data-type="indexterm" data-primary="cost" data-secondary="of enterprise platforms" data-secondary-sortas="enterprise platforms" id="cost-enterprise-platform"/>cost of your applications will vary depending on the billing model you choose and the amount of resources you use. All providers have tools that help you estimate how much you will spend each month based on the resources you deploy, but your costs will also depend on the number of resources used during agent deployments and processing and the number of times you call the provider’s APIs. If you’re not careful, you can get blindsided by high costs when your applications make too many resource calls. These resource calls could be deliberate, or you could have logic errors that exhaust your budget.</p>
            <p>All three providers offer on-demand payment plans, but they have alternatives for enterprise pricing that give discounts for high-resource applications. As of this writing, Azure has a plan named ExpressRoute for leasing a private cloud, meaning your data never leaves the data center. This option is great for businesses with strict compliance requirements. </p>
            <p>Depending on your resources and data usage, you could pay from a couple of hundred dollars a month to a few thousand. It’s difficult to say exactly how much you will pay, so check the provider’s calculator to help<!--<a contenteditable="false" data-type="indexterm" data-primary="cost" data-secondary="of enterprise platforms" data-secondary-sortas="enterprise platforms" data-startref="cost-enterprise-platform">&nbsp;</a>--> you estimate.</p>
          </dd>
          <dt>API quotas and token limits</dt>
          <dd>
            <p>API quotas<a contenteditable="false" data-type="indexterm" data-primary="quotas of enterprise platforms" id="id744"/><a contenteditable="false" data-type="indexterm" data-primary="token limits of enterprise platforms" id="id745"/> and costs could be considered the same, but providers often have subscription requirements or limitations to the number of API requests. Limitations are set to avoid a denial-of-service (DoS) attack on the API servers but are usually based on your subscription model. Any calls over the limitations could be extremely costly. </p>
            <p>The cost of accidentally making too many calls to an API with quotas isn’t just a few hundred dollars. Going over API quotas can cost you tens of thousands of dollars. Mistakes happen when you have a subscription with high charges after you go over a certain number of requests or you have logic errors in your code. Let’s say you have a logic error that turns what you think is 5 requests into 50 requests. Your code runs several times an hour. You could then have hundreds of unforeseen requests to an API. If you don’t plan for these requests, you could get an unpleasant surprise when you receive the cloud provider’s bill.</p>
            <p>Each model and API have different token limits and context-window limitations as well. The impact will depend on your<a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="enterprise platforms" data-startref="seo-automation-enterprise-platform" id="id746"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="enterprise platforms" data-startref="automation-enterprise-platform" id="id747"/><a contenteditable="false" data-type="indexterm" data-primary="enterprise platforms" data-startref="enterprise-platform" id="id748"/> use case. </p>
          </dd>
        </dl>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Building Your Own AI Tools and Plug-ins"><div class="sect1" id="ch06_building_your_own_ai_tools_and_plug_ins_1748359259643727">
        <h1>Building Your Own AI Tools and Plug-ins</h1>
        <p>By now, <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="building custom tools and plug-ins" id="seo-automation-tools-plugins"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="building custom tools and plug-ins" id="automation-tools-plugins"/><a contenteditable="false" data-type="indexterm" data-primary="custom AI tools and plug-ins, building" id="custom-tools-plugins-build"/>you should be familiar with the typical prompt interfaces provided by model vendors, but you can also use APIs to build enterprise-tier plug-ins and tools. As an example, let’s say you have a team of marketing people responsible for generating content. You might have Microsoft Teams set up for them to speak throughout the day. You can create bots for Teams (and other collaboration software), so you could create a bot in Teams where all your marketing people can generate content. </p>
        <p>A Teams bot acts like a user added to your Teams group. A custom bot can give an array of different replies to user messages, and a generative AI bot can provide content ideas for your marketing team. The bot looks like a standard user account. If you’re familiar with Slack, you know that a bot instantly greets you when you join a new server. It looks and acts like a real user, but you send it specific commands to ask how to use Slack. The same can be done with a Teams bot, except this bot will take prompts and instructions from your marketing team and provide output text that can be used for content.</p>
        <p>Let’s use a simple example of writing content about US presidents. You know from <a data-type="xref" href="#ch06_automating_seo_tasks_with_ai_1748359259643251">“Automating SEO Tasks with AI”</a> that you can use code to analyze a web page, but we want assistance with generating content about the US president James Polk at scale. ChatGPT will let you use an example to shape the way it outputs content, so you don’t even need your own analysis code. ChatGPT will do it for you. As shown in <a data-type="xref" href="#ch06_figure_8_1748359259618179">Figure 6-8</a>, the Biden White House archive provides information about Polk, so our bot will be instructed to take information from this page and generate content ideas.</p>
        <figure><div id="ch06_figure_8_1748359259618179" class="figure">
          <img src="assets/ugai_0608.png" width="1745" height="1022"/>
          <h6><span class="label">Figure 6-8. </span>Biden White House archive page on President Polk</h6>
        </div></figure>
        <p>A Teams bot can be coded in any language, but we will use Python in this example. In the earlier agents system example, we used Python to create a small application that pulled answers from ChatGPT. Instead of prompting ChatGPT to answer a question, our Teams bot will generate draft content for anyone in marketing (or another department) who sends it a message with specific prompts. The Python code can interface with the generative AI model—in our example, it’s ChatGPT—and send back content. The advantage is that you could have 20 marketing people generating draft content and ideas from one location, and they can collaboratively determine strategies for SEO. For example, suppose you have a site selling computer equipment. NVIDIA announces a new GPU, so you need to generate content to keep up with the trend and help drive traffic to your local site. Your marketing team can chat with a Teams bot to come up with ideas and draft pages to publish during the spike in interest for new NVIDIA GPUs.</p>
        <p>We’ll keep our example simple by focusing on content from the White House page on Polk. ChatGPT has plenty of content and information to generate good content on old topics, but you still need to review output. A human reviewer can identify errors or low-quality content, so always have a gatekeeper review output before it’s published to your site. The Teams interface lets you install your own bot from the Apps interface. Coding a full bot is beyond the scope of the book, but after you code a bot, you must upload the code from your Teams interface. You also need privileges to make bots available in Teams, so check with your Teams administrator if you do not have permission.</p>
        <p>Our bot connects to the ChatGPT API, and we can ask it to write content with the White House web page as a reference, as shown in <a data-type="xref" href="#ch06_figure_9_1748359259618198">Figure 6-9</a>.</p>
        <figure><div id="ch06_figure_9_1748359259618198" class="figure">
          <img src="assets/ugai_0609.png" width="1364" height="365"/>
          <h6><span class="label">Figure 6-9. </span>Example request for a Teams bot named StudyAI</h6>
        </div></figure>
        <p>As you can see, we ask the Teams chatbot to write us content based on the White House URL. The chatbot takes a minute and responds with what’s shown in <a data-type="xref" href="#ch06_figure_10_1748359259618216">Figure 6-10</a>.</p>
        <figure><div id="ch06_figure_10_1748359259618216" class="figure">
          <img src="assets/ugai_0610.png" width="923" height="286"/>
          <h6><span class="label">Figure 6-10. </span>Output from a ChatGPT-based chatbot</h6>
        </div></figure>
        <p class="widows4">You shouldn’t post this without human review. As you can see, you need to format the content and likely fact-check it, but using a factual URL will help eliminate errors. Once you check for errors, you can then have ChatGPT generate pages at scale while improving quality based on your chosen topic. You can tell ChatGPT to use your formatted original content from the first page generated as a foundation for other content. We don’t recommend you take this technique to the extreme of generating SEO programmatic content with generative AI. However, you could significantly speed up the process at scale while still inserting human review and editing into the process. </p>
        <p>Going back to the NVIDIA example mentioned earlier, imagine that you have a product being built based on another trending topic or have additional ideas based on trending topics. You can have an agent constantly checking for trending topics in your industry and sending ideas and updates to marketing people. Marketing can then use custom bots and plug-ins to generate pages quickly without waiting for writers to write content. Plug-ins and custom tools can change your content-production time from weeks to hours to keep up with rapidly changing industry<a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="building custom tools and plug-ins" data-startref="seo-automation-tools-plugins" id="id749"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="building custom tools and plug-ins" data-startref="automation-tools-plugins" id="id750"/><a contenteditable="false" data-type="indexterm" data-primary="custom AI tools and plug-ins, building" data-startref="custom-tools-plugins-build" id="id751"/> trends.</p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="AI-Assisted Link Attraction and Outreach"><div class="sect1" id="ch06_ai_assisted_link_attraction_and_outreach_1748359259643786">
        <h1>AI-Assisted Link Attraction and Outreach</h1>
        <p>SEO is <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="link attraction and outreach" id="seo-automation-links"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="link attraction and outreach" id="automation-links"/><a contenteditable="false" data-type="indexterm" data-primary="links" data-secondary="attracting" id="link-attract"/><a contenteditable="false" data-type="indexterm" data-primary="backlink analysis" id="backlink-analysis"/>more than generating content on your site. Another area you need to address is marketing and outreach to increase your visibility, attract links, and generate interest in your brand from people reading third-party sites. Focus your efforts on marketing and promotions that develop visibility and recognition from the top sites that cover your market. Avoid traditional SEO link-building strategies that lead to lots of low-quality links—Google just ignores those anyway. Further, spamming the internet with large-scale outreach only causes problems and is a waste of your time and money.</p>
        <p>As an example, suppose you have a new product you need to introduce. You can create press releases and reach out to editors on sites that cover your market. The idea is to generate discussion in the market about your product. An agent using generative AI can help.</p>
        <p>The agent example in <a data-type="xref" href="#ch06_building_your_own_ai_tools_and_plug_ins_1748359259643727">“Building Your Own AI Tools and Plug-ins”</a> pulled content from the internet and analyzed it for opportunities. With a different agent, you can have it see what sites link to your competitors. Some of these may be sites that you can attract links from as well as other sites that are like those that link to your competitors. You can also use tools to find backlink gaps yourself. For example, <a contenteditable="false" data-type="indexterm" data-primary="Semrush" data-secondary="backlink gap analysis" id="semrush-backlink"/>Semrush lets you perform a keyword gap and backlink gap analysis, as shown in <a data-type="xref" href="#ch06_figure_11_1748359259618235">Figure 6-11</a>.</p>
        <figure><div id="ch06_figure_11_1748359259618235" class="figure">
          <img src="assets/ugai_0611.png" width="1899" height="1101"/>
          <h6><span class="label">Figure 6-11. </span>Backlink gap analysis from Semrush</h6>
        </div></figure>
        <p>With a list of backlinks from your competitors, you can then identify your own backlink opportunities. So far, we haven’t used generative AI, but we could use it in several different ways. When you want to contact a site to establish a relationship, you can use it to draft email messages. However, don’t generate automated email messages and send them without human review. If you create messages that look like AI or have a poor message, you could be blacklisted by that particular publisher.</p>
        <p>Third-party backlink analytic tools are best for finding competitor backlinks, but you can feed information from a third-party API (e.g., data from Semrush or Ahrefs) to generative AI. The logic you use depends on the way you program your agent, but you can use an agent to call the API and retrieve data that can be fed to generative AI. For example, the Semrush API can be used to find domain authority for a list of potential backlink locations. With this information, you can then ask generative AI to suggest content or build a list of topic ideas suitable for each site. AI can then identify the editor or person in charge of a target site that an email can be sent to for outreach. Note that you will still want to verify you have the right contacts by human review. This may seem like a minor advantage, but it can save a lot of time when you have significant outreach efforts driving your brand’s <a contenteditable="false" data-type="indexterm" data-primary="Semrush" data-secondary="backlink gap analysis" data-startref="semrush-backlink" id="id752"/><a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="link attraction and outreach" data-startref="seo-automation-links" id="id753"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="link attraction and outreach" data-startref="automation-links" id="id754"/><a contenteditable="false" data-type="indexterm" data-primary="links" data-secondary="attracting" data-startref="link-attract" id="id755"/><a contenteditable="false" data-type="indexterm" data-primary="backlink analysis" data-startref="backlink-analysis" id="id756"/>marketing.</p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Creating Video and Audio with AI"><div class="sect1" id="ch06_creating_video_and_audio_with_ai_1748359259643843">
        <h1>Creating Video and Audio with AI</h1>
        <p>Another <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="audio and video creation" id="id757"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="audio and video creation" id="id758"/><a contenteditable="false" data-type="indexterm" data-primary="audio, AI-created" id="id759"/><a contenteditable="false" data-type="indexterm" data-primary="video, AI-created" id="id760"/>valuable use of generative AI is image, video, and audio creation. Unfortunately, it can be somewhat obvious when audio and video have been generated by AI. For example, a video of a person speaking might show unnatural mouth movements. AI-generated images tend to be prone to oddities and AI-generated audio can sound robotic, for instance. If you choose to generate this type of content, know that it will need to be heavily edited.</p>
        <p>Instead of using generative AI to create video and audio, SEO practitioners can work with AI to improve current audio and video. AI can enhance color grading, program transitions between scenes, and add special effects. When your brand focuses on creating and publishing video rather than text content, this can save hours of editing time for every video.</p>
        <p>Other advantages of using AI with video and audio content include writing meta descriptions, transcribing video content, and generating summaries of content for text-based searches. Generative AI is best used for text-based optimizations around video content to satisfy user engagement and quality search signals. </p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Using AI to Manage and Optimize Local SEO Listings"><div class="sect1" id="ch06_using_ai_to_manage_and_optimize_local_seo_listings_1748359259643901">
        <h1>Using AI to Manage and Optimize Local SEO Listings</h1>
        <p>Local SEO <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="local SEO" id="seo-automation-local"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="local SEO" id="automation-local"/><a contenteditable="false" data-type="indexterm" data-primary="local SEO" id="local-seo"/>targets potential customers in a specific geolocation, so it has a different approach than global SEO. Instead of attracting global visitors, your goal is to show up in searches when users want a business or service near them. You could be a single brick-and-mortar store looking for better online visibility or a large-scale brand with hundreds or thousands of locations looking for better reach in each location. Generative AI can help create optimized meta descriptions for your local customers, check your listings to ensure consistent information like addresses and phone numbers, collect customer reviews, and identify competitors ranking for local keywords. </p>
        <p>As with global SEO, relying too heavily on automated content without reviewing its output could do more damage than help. With that said, AI can reduce overhead and help with reputation management, tracking local listings, drafting replies to comments and reviews, updating addresses, and alerting business owners of potential dissatisfied customers. The biggest advantage is in AI’s predictive analysis, which helps businesses determine the best products to sell during busy seasons and to satisfy ever-changing trends. AI automation changes the game for SEO practitioners responsible for local businesses relying on search visibility in a small region.</p>
        <p>A major part of good local SEO is keeping local listings updated with a business’s current address, location, and phone number. This information should be consistent across all platforms to send accurate signals to search engines. Search engines must know where the business is located to provide accurate results to users querying for services in their local area. Businesses move, telephone numbers and hours of operation change, and many other factors could also change. You might remember to update an address change on a handful of business listing sites but miss several others. When information is out of sync, that sends low-quality signals to search engines, which affects how high you rank for local search queries.</p>
        <p>Using AI automation, local business SEO practitioners can identify sites with outdated information and either send an email to the individual location’s manager or owner or draft updates to the content with automated scripts. This automation is the first step, but in the process, AI can scrape a large number of sites, pull ratings and customer comments, and analyze them. The analysis can provide customer sentiment and identify issues. For example, customers might have posted several low ratings complaining about customer service or product quality. AI can identify this issue and send alerts to marketing, SEO practitioners, and PR management to help identify opportunities for improvement.</p>
        <p>With enough data extracted from customer activity on a business website, AI can be used to personalize user experiences when they visit. Suppose you have a visitor from a specific city. Data extracted from visitors in this particular city says that most visitors search for a specific item during the summer. As an SEO practitioner, you can instruct developers to display this item more prominently to these users during summer and change the promoted item for the same customer in other seasons.</p>
        <p>Voice and image optimization hasn’t quite happened yet, but it’s something to be aware of for the future. We’ll discuss voice and image search in <a data-type="xref" href="ch08.html#ch08_the_future_of_generative_ai_and_seo_1748358221787429">Chapter 8</a>, but keep in mind that using simple voice or image searches will be an expanding area of interest for SEO. Users already can search using images, but that’s still primitive. Generative AI can be used to create images on the fly to get your business brand in image searches, offering a new opportunity for visitor traffic. Search using voice has been available for some time, but usage has been relatively low; this will likely<a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="local SEO" data-startref="seo-automation-local" id="id761"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="local SEO" data-startref="automation-local" id="id762"/><a contenteditable="false" data-type="indexterm" data-primary="local SEO" data-startref="local-seo" id="id763"/> also grow.</p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="AI-Enhanced Reputation Management for SEO"><div class="sect1" id="ch06_ai_enhanced_reputation_management_for_seo_1748359259643959">
        <h1>AI-Enhanced Reputation Management for SEO</h1>
        <p>Word of mouth <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="brand reputation management" id="seo-automation-brand"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="brand reputation management" id="automation-brand"/><a contenteditable="false" data-type="indexterm" data-primary="brand reputation management" id="brand-mgmt"/><a contenteditable="false" data-type="indexterm" data-primary="reputation management" id="reputation-mgmt"/><a contenteditable="false" data-type="indexterm" data-primary="user sentiment" id="user-sentiment"/>is important for every business, but it’s even more important for local businesses. Whether it’s a service you offer or a local product, potential customers will likely research reviews before committing to a purchase. Reviews and comments around the web can have a huge impact on revenue. However, a proactive approach to addressing customer issues can turn this around and ensure that the impact is positive.</p>
        <p>In <a data-type="xref" href="#ch06_automating_seo_tasks_with_ai_1748359259643251">“Automating SEO Tasks with AI”</a>, we talked about agents collecting data online and using it for gap analysis and assisting in content generation using keyword research automation. You can do the same with brand reputation. One of the most powerful uses for AI and machine learning is predictive analysis. In SEO, you can also gain insights into user sentiment.</p>
        <p>You can project your brand reputation by monitoring the internet for brand mentions and finding opportunities from user sentiment, positive or negative. The negative reputation from poor reviews can be mitigated by responding to them. You could hire someone full time to respond to negative reviews, especially if the business is a large enterprise, but AI automation can also be your full-time employee and help draft responses to these customer complaints.</p>
        <p>Many businesses respond to negative reviews by suggesting that the complainant call customer service. This response is better than nothing, but it’s not particularly satisfying, and it’s a missed opportunity for the brand. There are opportunities to do so much more with this interaction that helps satisfy not only the complainant but also others watching the conversation online. Brands should view these complaints as an opportunity to show publicly how much they support their customers and project that as part of their brand image. </p>
        <p>Instead of having employees scour the internet for brand comments, AI automation can be used to find new brand mentions and draft comments based on users’ feedback. Instead of using a canned reply that looks robotic and can actually harm brand reputation, AI can ingest a user’s comment and generate a draft customized response for each customer comment.</p>
        <p>For example, in <a data-type="xref" href="#ch06_figure_12_1748359259618254">Figure 6-12</a>, ChatGPT is given a request to find the latest review for Study.com. This review is positive, but it could be a negative review, too. This prompt can be fed to your RAG system to automatically find reviews at specified intervals (e.g., every day or once a week). You can then take the reviews and formulate a response.</p>
        <figure><div id="ch06_figure_12_1748359259618254" class="figure">
          <img src="assets/ugai_0612.png" width="707" height="222"/>
          <h6><span class="label">Figure 6-12. </span>ChatGPT prompt to find the latest review for Study.com</h6>
        </div></figure>
        <p><a data-type="xref" href="#ch06_figure_13_1748359259618281">Figure 6-13</a> is a generative AI response to the Study.com review. This generated response is appreciative of the positive review, but it could also be a response to a negative review. This example is for a single review, but you can use your RAG agents to track and respond to numerous reviews found around the internet.</p>
        <figure><div id="ch06_figure_13_1748359259618281" class="figure">
          <img src="assets/ugai_0613.png" width="705" height="206"/>
          <h6><span class="label">Figure 6-13. </span>Generative AI response to an Instagram review for Study.com</h6>
        </div></figure>
        <p>You can also use generative AI for chatbot support. Visitors arriving at your site from search engines can be greeted by a chatbot to help them find a product. While this might not seem like an SEO issue, keeping visitors engaged improves dwell time on a site and reduces the chance of a visitor bouncing to find another site in search. This can affect SEO and directly improve sales, which is the ultimate goal for any SEO or marketing.</p>
        <p>Collecting data to gain insights into user sentiment helps with numerous business changes to improve revenue. It can drive new products, suggest changes to products, or let you know when it’s time to deprecate a product or service. Marketers and SEO practitioners also can collect data on competitor insights to find out what customers like about a competitor and where the general public wants improvements. Your business can then determine if there are opportunities to create advantages for your own brand based on customer sentiment targeting<a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="brand reputation management" data-startref="seo-automation-brand" id="id764"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="brand reputation management" data-startref="automation-brand" id="id765"/><a contenteditable="false" data-type="indexterm" data-primary="brand reputation management" data-startref="brand-mgmt" id="id766"/><a contenteditable="false" data-type="indexterm" data-primary="reputation management" data-startref="reputation-mgmt" id="id767"/><a contenteditable="false" data-type="indexterm" data-primary="user sentiment" data-startref="user-sentiment" id="id768"/> a competitor.</p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Integrating Generative AI with Other Marketing Channels"><div class="sect1" id="ch06_integrating_generative_ai_with_other_marketing_cha_1748359259644017">
        <h1>Integrating Generative AI with Other Marketing Channels</h1>
        <p>In the <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="social media integration" id="seo-automation-social-media"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="social media integration" id="automation-social-media"/><a contenteditable="false" data-type="indexterm" data-primary="social media" data-secondary="AI integration with" id="social-media-integrate"/>previous section, we talked about using generative AI to analyze customer sentiment on sites where users post reviews or make comments on products. The same can be done with social media. Some review sites even scrape social media accounts for product reviews, so your time could be well spent creating automation scripts to find social media posts that mention your brand and use generative AI to create comments. For example, use generative AI to respond to bad customer experience by suggesting the customer contact customer service. This type of activity is best for reputation management and can span social media and review sites. More broadly, you can use generative AI to discover posts that are relevant to your business and surface them as posts you may want to respond to. Engaging active dialogues on social media and enticing additional visitors to your site can be good for SEO.</p>
        <p>PPC is<a contenteditable="false" data-type="indexterm" data-primary="PPC (pay-per-click)" id="id769"/><a contenteditable="false" data-type="indexterm" data-primary="pay-per-click (PPC)" id="id770"/> a common traffic generator in marketing. PPC is expensive, but for some brands it’s essential to sales. There are a few steps to creating ads: do keyword research to find out what search queries to target, optimize your bids to determine the right price per click, create ad content that drives visitors to your products, schedule ads for optimal times when customers are online, and add tracking to see which ads bring in revenue and which ones don’t. As you can imagine, doing all these steps and monitoring ad revenue is a big job. Without optimization, PPC ads can provide a suboptimal return on investment and waste money. Generative AI can help reduce this overhead and make your PPC efforts more cost efficient and optimized for a target audience.</p>
        <p>With generative AI, SEO practitioners can create draft ad content based on insights from predictive analytics. The predictive analytics can come from your own agents ingesting data from around the web and from your sales and marketing departments. The predictive analytics results feed optimization of ads and determine when you publish ads and how much you should spend.</p>
        <p>Generative AI also handles the draft content creation for human review, so you can reduce the costs of making changes to your ads based on the time of day, the season, results from capturing user activity on landing pages, or general sentiment from scraping reviews from the web. What you do with generative AI depends on your goals, but it can make ad spend and decision making much more precise. </p>
        <p>The data you collect from landing pages can be fed to AI and machine learning to make predictions based on user activity. For example, suppose you have a landing page with three product options and the data suggests that more users prefer the blue item out of the three. You can then have generative AI create draft ads (for human review and approval) targeting people with this preference, increasing your ROI.</p>
        <p>One more advantage of AI in PPC and marketing is optimization of landing pages. <em>Heat maps</em>—common locations <a contenteditable="false" data-type="indexterm" data-primary="heat maps" id="id771"/>where visitors interact—show popular areas where users click on your page. Heat maps are nothing new, but suppose that a heat map shows common areas in a specific menu of your site. You can take this information, feed it to AI and machine learning, and have generative AI suggest changes to your landing page and its content for a more optimized layout. Heat maps already give you ideas for landing-page layouts, but generative AI can make your marketing much more dynamic and quicker to adapt to changes in the way users interact with ads and <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="social media integration" data-startref="seo-automation-social-media" id="id772"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="social media integration" data-startref="automation-social-media" id="id773"/><a contenteditable="false" data-type="indexterm" data-primary="social media" data-secondary="AI integration with" data-startref="social-media-integrate" id="id774"/>landing pages.</p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Get Started with Generative AI Automation"><div class="sect1" id="ch06_get_started_with_generative_ai_automation_1748359259644074">
        <h1>Get Started with Generative AI Automation</h1>
        <p>With so <a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="initial steps" id="seo-automation-initial-step"/><a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="initial steps" id="automation-initial-step"/>many options for applying generative AI, the first step is to determine what results you want to see. For example, you might wonder if generative AI can help with ad optimization. Your goal might be to increase the brand’s conversion rate. Using generative AI, you can suggest updates to landing pages and ads based on data collected from your current pages. You can also use data from sales and user activity to determine your best sellers and any seasonal or trend changes that might affect sales.</p>
        <p>With these goals in mind, you can map out your agents and programming design. If you don’t have a technical background, you will likely need the help of an engineering team. While a single script might not be too complex, provisioning infrastructure, building multiple agents, and using available APIs can get quite complicated. Engineering teams can help alleviate this overhead and work with your brand to build complete RAG with a system of agents using AI.</p>
        <p>As with any generative AI outputs, review of these outputs is critical to ensure that you don’t put out incorrect or nonsensical information. You will also need to tweak code or infrastructure to keep up with version changes or trends in your<!--<a contenteditable="false" data-type="indexterm" data-primary="SEO (search engine optimization)" data-secondary="automation in" data-tertiary="initial steps" data-startref="seo-automation-initial-step">&nbsp;</a>--><!--<a contenteditable="false" data-type="indexterm" data-primary="automation in SEO" data-secondary="initial steps" data-startref="automation-initial-step">&nbsp;</a>--> industry.</p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="ch06_conclusion_1748359259644154">
        <h1>Conclusion</h1>
        <p>In this chapter, we discussed advanced generative AI uses and how to automate many common SEO tasks. With productivity benefits come common pitfalls you must avoid. Automation has its benefits, but it can create serious ranking issues if you don’t properly implement and review its output. It’s important that you understand the risks associated with the technology so that you can build mitigation strategies into your designs. </p>
        <p>As we will discuss in <a data-type="xref" href="ch07.html#ch07_ai_risks_and_challenges_1748358220835353">Chapter 7</a>, after systems are in place you must monitor and continually adjust the output based on human reviews. Even when you implement these advanced techniques, you’ll still need continual human review. We’ll get into the possible risks in the next chapter.</p>
      </div></section>
    </div></section></div></div></body></html>