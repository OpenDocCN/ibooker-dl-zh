["```py\nbash scripts/download_kaggle_data.sh hugodarwood epirecipes\n```", "```py\nwith open('/app/data/epirecipes/full_format_recipes.json') as json_data:\n    recipe_data = json.load(json_data)\n\nfiltered_data = [\n    'Recipe for ' + x['title']+ ' | ' + ' '.join(x['directions'])\n    for x in recipe_data\n    if 'title' in x\n    and x['title'] is not None\n    and 'directions' in x\n    and x['directions'] is not None\n]\n```", "```py\nRecipe for Ham Persillade with Mustard Potato Salad and Mashed Peas  | Chop enough\nparsley leaves to measure 1 tablespoon; reserve. Chop remaining leaves and stems\nand simmer with broth and garlic in a small saucepan, covered, 5 minutes.\nMeanwhile, sprinkle gelatin over water in a medium bowl and let soften 1 minute.\nStrain broth through a fine-mesh sieve into bowl with gelatin and stir to dissolve.\nSeason with salt and pepper. Set bowl in an ice bath and cool to room temperature,\nstirring. Toss ham with reserved parsley and divide among jars. Pour gelatin on top\nand chill until set, at least 1 hour. Whisk together mayonnaise, mustard, vinegar,\n1/4 teaspoon salt, and 1/4 teaspoon pepper in a large bowl. Stir in celery,\ncornichons, and potatoes. Pulse peas with marjoram, oil, 1/2 teaspoon pepper, and\n1/4 teaspoon salt in a food processor to a coarse mash. Layer peas, then potato\nsalad, over ham.\n```", "```py\ndef pad_punctuation(s):\n    s = re.sub(f\"([{string.punctuation}])\", r' \\1 ', s)\n    s = re.sub(' +', ' ', s)\n    return s\n\ntext_data = [pad_punctuation(x) for x in filtered_data] ![1](Images/1.png)\n\ntext_ds = tf.data.Dataset.from_tensor_slices(text_data).batch(32).shuffle(1000) ![2](Images/2.png)\n\nvectorize_layer = layers.TextVectorization( ![3](Images/3.png)\n    standardize = 'lower',\n    max_tokens = 10000,\n    output_mode = \"int\",\n    output_sequence_length = 200 + 1,\n)\n\nvectorize_layer.adapt(text_ds) ![4](Images/4.png)\nvocab = vectorize_layer.get_vocabulary() ![5](Images/5.png)\n```", "```py\n[  26   16  557    1    8  298  335  189    4 1054  494   27  332  228\n  235  262    5  594   11  133   22  311    2  332   45  262    4  671\n    4   70    8  171    4   81    6    9   65   80    3  121    3   59\n   12    2  299    3   88  650   20   39    6    9   29   21    4   67\n  529   11  164    2  320  171  102    9  374   13  643  306   25   21\n    8  650    4   42    5  931    2   63    8   24    4   33    2  114\n   21    6  178  181 1245    4   60    5  140  112    3   48    2  117\n  557    8  285  235    4  200  292  980    2  107  650   28   72    4\n  108   10  114    3   57  204   11  172    2   73  110  482    3  298\n    3  190    3   11   23   32  142   24    3    4   11   23   32  142\n   33    6    9   30   21    2   42    6  353    3 3224    3    4  150\n    2  437  494    8 1281    3   37    3   11   23   15  142   33    3\n    4   11   23   32  142   24    6    9  291  188    5    9  412  572\n    2  230  494    3   46  335  189    3   20  557    2    0    0    0\n    0    0    0    0    0]\n```", "```py\n0:\n1: [UNK]\n2: .\n3: ,\n4: and\n5: to\n6: in\n7: the\n8: with\n9: a\n```", "```py\ndef prepare_inputs(text):\n    text = tf.expand_dims(text, -1)\n    tokenized_sentences = vectorize_layer(text)\n    x = tokenized_sentences[:, :-1]\n    y = tokenized_sentences[:, 1:]\n    return x, y\n\ntrain_ds = text_ds.map(prepare_inputs) ![1](Images/1.png)\n```", "```py\ninputs = layers.Input(shape=(None,), dtype=\"int32\") ![1](Images/1.png)\nx = layers.Embedding(10000, 100)(inputs) ![2](Images/2.png)\nx = layers.LSTM(128, return_sequences=True)(x) ![3](Images/3.png)\noutputs = layers.Dense(10000, activation = 'softmax')(x) ![4](Images/4.png)\nlstm = models.Model(inputs, outputs) ![5](Images/5.png)\n\nloss_fn = losses.SparseCategoricalCrossentropy()\nlstm.compile(\"adam\", loss_fn) ![6](Images/6.png)\nlstm.fit(train_ds, epochs=25) ![7](Images/7.png)\n```", "```py\nclass TextGenerator(callbacks.Callback):\n    def __init__(self, index_to_word, top_k=10):\n        self.index_to_word = index_to_word\n        self.word_to_index = {\n            word: index for index, word in enumerate(index_to_word)\n        } ![1](Images/1.png)\n\n    def sample_from(self, probs, temperature): ![2](Images/2.png)\n        probs = probs ** (1 / temperature)\n        probs = probs / np.sum(probs)\n        return np.random.choice(len(probs), p=probs), probs\n\n    def generate(self, start_prompt, max_tokens, temperature):\n        start_tokens = [\n            self.word_to_index.get(x, 1) for x in start_prompt.split()\n        ] ![3](Images/3.png)\n        sample_token = None\n        info = []\n        while len(start_tokens) < max_tokens and sample_token != 0: ![4](Images/4.png)\n            x = np.array([start_tokens])\n            y = self.model.predict(x) ![5](Images/5.png)\n            sample_token, probs = self.sample_from(y[0][-1], temperature) ![6](Images/6.png)\n            info.append({'prompt': start_prompt , 'word_probs': probs})\n            start_tokens.append(sample_token) ![7](Images/7.png)\n            start_prompt = start_prompt + ' ' + self.index_to_word[sample_token]\n        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n        return info\n\n    def on_epoch_end(self, epoch, logs=None):\n        self.generate(\"recipe for\", max_tokens = 100, temperature = 1.0)\n```", "```py\ntext_in = layers.Input(shape = (None,))\nembedding = layers.Embedding(total_words, embedding_size)(text_in)\nx = layers.LSTM(n_units, return_sequences = True)(x)\nx = layers.LSTM(n_units, return_sequences = True)(x)\nprobabilites = layers.Dense(total_words, activation = 'softmax')(x)\nmodel = models.Model(text_in, probabilites)\n```", "```py\nlayer = layers.Bidirectional(layers.GRU(100))\n```", "```py\nclass MaskedConvLayer(layers.Layer):\n    def __init__(self, mask_type, **kwargs):\n        super(MaskedConvLayer, self).__init__()\n        self.mask_type = mask_type\n        self.conv = layers.Conv2D(**kwargs) ![1](Images/1.png)\n\n    def build(self, input_shape):\n        self.conv.build(input_shape)\n        kernel_shape = self.conv.kernel.get_shape()\n        self.mask = np.zeros(shape=kernel_shape) ![2](Images/2.png)\n        self.mask[: kernel_shape[0] // 2, ...] = 1.0 ![3](Images/3.png)\n        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0 ![4](Images/4.png)\n        if self.mask_type == \"B\":\n            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0 ![5](Images/5.png)\n\n    def call(self, inputs):\n        self.conv.kernel.assign(self.conv.kernel * self.mask) ![6](Images/6.png)\n        return self.conv(inputs)\n```", "```py\nclass ResidualBlock(layers.Layer):\n    def __init__(self, filters, **kwargs):\n        super(ResidualBlock, self).__init__(**kwargs)\n        self.conv1 = layers.Conv2D(\n            filters=filters // 2, kernel_size=1, activation=\"relu\"\n        ) ![1](Images/1.png)\n        self.pixel_conv = MaskedConv2D(\n            mask_type=\"B\",\n            filters=filters // 2,\n            kernel_size=3,\n            activation=\"relu\",\n            padding=\"same\",\n        ) ![2](Images/2.png)\n        self.conv2 = layers.Conv2D(\n            filters=filters, kernel_size=1, activation=\"relu\"\n        ) ![3](Images/3.png)\n\n    def call(self, inputs):\n        x = self.conv1(inputs)\n        x = self.pixel_conv(x)\n        x = self.conv2(x)\n        return layers.add([inputs, x]) ![4](Images/4.png)\n```", "```py\ninputs = layers.Input(shape=(16, 16, 1)) ![1](Images/1.png)\nx = MaskedConv2D(mask_type=\"A\"\n                   , filters=128\n                   , kernel_size=7\n                   , activation=\"relu\"\n                   , padding=\"same\")(inputs)![2](Images/2.png)\n\nfor _ in range(5):\n    x = ResidualBlock(filters=128)(x) ![3](Images/3.png)\n\nfor _ in range(2):\n    x = MaskedConv2D(\n        mask_type=\"B\",\n        filters=128,\n        kernel_size=1,\n        strides=1,\n        activation=\"relu\",\n        padding=\"valid\",\n    )(x) ![4](Images/4.png)\n\nout = layers.Conv2D(\n    filters=4, kernel_size=1, strides=1, activation=\"softmax\", padding=\"valid\"\n)(x) ![5](Images/5.png)\n\npixel_cnn = models.Model(inputs, out) ![6](Images/6.png)\n\nadam = optimizers.Adam(learning_rate=0.0005)\npixel_cnn.compile(optimizer=adam, loss=\"sparse_categorical_crossentropy\")\n\npixel_cnn.fit(\n    input_data\n    , output_data\n    , batch_size=128\n    , epochs=150\n) ![7](Images/7.png)\n```", "```py\nclass ImageGenerator(callbacks.Callback):\n    def __init__(self, num_img):\n        self.num_img = num_img\n\n    def sample_from(self, probs, temperature):\n        probs = probs ** (1 / temperature)\n        probs = probs / np.sum(probs)\n        return np.random.choice(len(probs), p=probs)\n\n    def generate(self, temperature):\n        generated_images = np.zeros(\n            shape=(self.num_img,) + (pixel_cnn.input_shape)[1:]\n        ) ![1](Images/1.png)\n        batch, rows, cols, channels = generated_images.shape\n\n        for row in range(rows):\n            for col in range(cols):\n                for channel in range(channels):\n                    probs = self.model.predict(generated_images)[\n                        :, row, col, :\n                    ] ![2](Images/2.png)\n                    generated_images[:, row, col, channel] = [\n                        self.sample_from(x, temperature) for x in probs\n                    ] ![3](Images/3.png)\n                    generated_images[:, row, col, channel] /= 4 ![4](Images/4.png)\n        return generated_images\n\n    def on_epoch_end(self, epoch, logs=None):\n        generated_images = self.generate(temperature = 1.0)\n        display(\n            generated_images,\n            save_to = \"./output/generated_img_%03d.png\" % (epoch)\n        s)\n\nimg_generator_callback = ImageGenerator(num_img=10)\n```", "```py\nimport tensorflow_probability as tfp\n\ndist = tfp.distributions.PixelCNN(\n    image_shape=(32, 32, 1),\n    num_resnet=1,\n    num_hierarchies=2,\n    num_filters=32,\n    num_logistic_mix=5,\n    dropout_p=.3,\n) ![1](Images/1.png)\n\nimage_input = layers.Input(shape=(32, 32, 1)) ![2](Images/2.png)\n\nlog_prob = dist.log_prob(image_input)\n\nmodel = models.Model(inputs=image_input, outputs=log_prob) ![3](Images/3.png)\nmodel.add_loss(-tf.reduce_mean(log_prob)) ![4](Images/4.png)\n```", "```py\ndist.sample(10).numpy()\n```"]