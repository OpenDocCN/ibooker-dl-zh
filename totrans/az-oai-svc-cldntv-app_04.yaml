- en: Chapter 3\. Implementing Cloud Native Generative AI with Azure OpenAI Service
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 3 章：使用 Azure OpenAI 服务实现云原生生成式 AI
- en: This chapter will focus on the implementation of generative AI architectures
    with Microsoft Azure and Azure OpenAI models, always aiming to present all available
    options, and minimize the required development, integration, and usage cost, while
    accelerating the operationalization. For that purpose, I’ve included a series
    of best practices and typical architectures that will allow you to choose the
    best building blocks for your specific scenarios.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将专注于使用 Microsoft Azure 和 Azure OpenAI 模型实现生成式 AI 架构，始终旨在展示所有可用选项，并最小化所需的开发、集成和使用成本，同时加速运营。为此，我包括了一系列最佳实践和典型架构，这将使您能够为您的特定场景选择最佳的构建块。
- en: We will include the most relevant Azure OpenAI implementation approaches, based
    on existing features and repositories that will continue evolving, improving,
    and including new functionalities. I’ve included URLs to the original documentation
    because they are continuously updated with new features, so these links will allow
    you to explore any details you need. Most of them rely on official accelerators
    from GitHub repositories, and projects that you will be able to follow and/or
    fork. But before getting into the details, let’s explore some fundamental topics
    that will help you understand the full extent of what a generative AI with Azure
    OpenAI Service means.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将包括基于现有功能和持续发展的存储库的最相关 Azure OpenAI 实现方法，这些存储库将不断改进，包括新的功能。我包括了原始文档的 URL，因为它们会持续更新以包含新功能，因此这些链接将允许您探索您需要的任何细节。其中大部分依赖于来自
    GitHub 存储库的官方加速器，以及您可以跟踪和/或分叉的项目。但在深入细节之前，让我们探索一些基本主题，这将帮助您理解 Azure OpenAI 服务所代表的生成式
    AI 的全面范围。
- en: Defining the Knowledge Scope of Azure OpenAI Service–Enabled Apps
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义 Azure OpenAI 服务启用应用的认知范围
- en: Generative AI applications on Microsoft Azure are not only for regular ChatGPT-type
    applications. They are advanced architectures that rely on diverse technology
    pieces, including the core infrastructure (servers, [GPUs](https://oreil.ly/y5mXm),
    etc.) required to run generative AI models, and that allow adopters to create
    conversational applications and search engines, develop and integrate new AI copilots
    into their applications, customize customer attention, etc.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Microsoft Azure 上的生成式 AI 应用不仅限于常规的 ChatGPT 类型应用。它们是依赖于多种技术组件的高级架构，包括运行生成式
    AI 模型所需的核心基础设施（服务器、[GPU](https://oreil.ly/y5mXm) 等），并允许采用者创建对话应用和搜索引擎，将新的 AI 协作者集成到他们的应用中，定制客户关注点等。
- en: 'From an Azure OpenAI point of view, we are talking about a managed service
    that includes advanced functionalities that will allow you to implement *different
    levels of knowledge*, depending on the desired scope of your applications, and
    based on default capabilities and specific adjustment and customization techniques.
    By levels of knowledge, we mean something that goes beyond the initial scope of
    the LLM and its massive dataset (e.g., adding new information for an internal
    company application, based on its own data). Some of the options to adjust that
    knowledge include the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Azure OpenAI 的角度来看，我们谈论的是一个包含高级功能的管理服务，这将允许您根据应用所需的范围实现 *不同级别的知识*，基于默认功能和特定的调整和定制技术。通过知识级别，我们指的是超越
    LLM 及其大量数据集初始范围的东西（例如，基于自身数据为内部公司应用添加新信息）。调整该知识的某些选项包括以下内容：
- en: Baseline LLM
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 基准大型语言模型
- en: Azure OpenAI’s language models are trained on enormous datasets containing billions
    of words. These datasets are carefully curated to include a wide range of topics,
    genres, and writing styles. The size and diversity of the training data helps
    the models develop a broad understanding of human language. The specific details
    of the training data have not been disclosed, but it includes text data from a
    variety of sources, including books, articles, websites, and other publicly available
    written material. Additionally, the training process (RLHF) includes human reviewers
    who help annotate and curate the data, flagging and addressing potential biases
    or problematic content. Feedback loops with reviewers are established to continuously
    improve and refine the models. One of the key advantages of the enterprise-grade
    Azure OpenAI service is that [your data is only yours](https://oreil.ly/qA5Ok)
    and is not used by anyone to retrain models. The end-to-end process is explained
    in [OpenAI’s public paper](https://oreil.ly/2uFNS) titled “Training language models
    to follow instructions with human feedback,” and their official GPT model card,
    shown in [Figure 3-1](#fig_1_the_chatgpt_training_process_source).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Azure OpenAI的语言模型是在包含数十亿单词的巨大数据集上训练的。这些数据集经过精心策划，包括广泛的主题、流派和写作风格。训练数据的大小和多样性有助于模型发展对人类语言的广泛理解。训练数据的具体细节尚未公开，但它包括来自各种来源的文本数据，包括书籍、文章、网站和其他公开可用的书面材料。此外，训练过程（RLHF）包括人类审稿人，他们帮助标注和策划数据，标记并解决潜在的偏见或问题内容。与审稿人的反馈循环被建立起来，以持续改进和精炼模型。企业级Azure
    OpenAI服务的一个关键优势是[您的数据仅属于您](https://oreil.ly/qA5Ok)且不会被任何人用于重新训练模型。端到端过程在[OpenAI的公开论文](https://oreil.ly/2uFNS)中解释，标题为“通过人类反馈训练语言模型以遵循指令”，以及他们官方的GPT模型卡，如图[图3-1](#fig_1_the_chatgpt_training_process_source)所示。
- en: '![](assets/aoas_0301.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0301.png)'
- en: 'Figure 3-1\. The ChatGPT training process (source: adapted from an image by
    [OpenAI](https://oreil.ly/9Lt-2); [Creative Commons 4.0 license](https://oreil.ly/YGKJ5))'
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1. ChatGPT的训练过程（来源：改编自[OpenAI](https://oreil.ly/9Lt-2)的一张图片；[Creative Commons
    4.0许可](https://oreil.ly/YGKJ5))
- en: Additional knowledge (grounding)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 额外知识（扎根）
- en: 'You can provide the LLMs with some additional context or knowledge, making
    them specific to the activity scope of the developed system. This could go from
    setting the topic of discussion for a chatbot to specifying URLs that are related
    to the topics we want to include. There are different ways to implement this grounding:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以为LLM提供一些额外的上下文或知识，使它们特定于开发系统的活动范围。这可以从为聊天机器人设定讨论主题到指定与我们想要包含的主题相关的URL。实现这种扎根的方式有多种：
- en: Fine tuning
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 微调
- en: Using small knowledge bases or private data to retrain the LLM with new additional
    information. Available via Azure OpenAI Service, it’s a good option to adjust
    the knowledge scope of the LLM, but a less cost-efficient option (as we will explore
    in [Chapter 5](ch05.html#operationalizing_generative_ai_implementations) when
    we calculate the cost of the Azure OpenAI–enabled implementations). In reality,
    there are very few use cases that require fine-tuning, because it updates the
    weights of the models but does not necessarily make the model more factual with
    respect to the data it was fine-tuned for. Most use cases can be achieved through
    retrieval-augmented generation (RAG).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 使用小型知识库或私有数据，通过Azure OpenAI服务重新训练LLM，以添加新的附加信息。这是一个调整LLM知识范围的好选择，但成本效益较低（我们将在[第5章](ch05.html#operationalizing_generative_ai_implementations)中探讨，当我们计算Azure
    OpenAI启用实现的成本时）。实际上，需要微调的使用案例非常少，因为它更新了模型的权重，但并不一定使模型在微调的数据上更符合事实。大多数使用案例可以通过检索增强生成（RAG）来实现。
- en: RAG, embeddings-based retrieval
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: RAG，基于嵌入的检索
- en: 'Based on [Microsoft’s definition](https://oreil.ly/QlN0L), embeddings are:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[微软的定义](https://oreil.ly/QlN0L)，嵌入是：
- en: representations or encodings of tokens, such as sentences, paragraphs, or documents,
    in a high-dimensional vector space, where each dimension corresponds to a learned
    feature or attribute of the language. Embeddings are the way that the model captures
    and stores the meaning and the relationships of the language, and the way that
    the model compares and contrasts different tokens or units of language. Embeddings
    are the bridge between the discrete and the continuous, and between the symbolic
    and the numeric, aspects of language for the model.
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 表示或编码标记（如句子、段落或文档）的高维向量空间中的表示，其中每个维度对应于语言的一个学习特征或属性。嵌入是模型捕捉和存储语言的意义和关系的方式，也是模型比较和对比不同标记或语言单位的方式。嵌入是离散和连续、符号和数值语言方面的桥梁。
- en: RAG, index-based retrieval
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: RAG，基于索引的检索
- en: 'The ability to index existing files so we can locate them when interacting
    with the LLM engine. Microsoft [defines indexes](https://oreil.ly/iJSKP) as:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 能够索引现有文件，以便我们在与 LLM 引擎交互时可以找到它们。Microsoft [定义索引](https://oreil.ly/iJSKP)为：
- en: crawlers that extract searchable content from data sources and populate a search
    index using field-to-field mappings between source data and a search index. This
    approach is sometimes referred to as a “pull model” because the search service
    pulls data in without you having to write any code that adds data to an index.
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 爬虫从数据源中提取可搜索内容，并使用源数据与搜索索引之间的字段映射来填充搜索索引。这种方法有时被称为“拉模型”，因为搜索服务在不需要你编写任何将数据添加到索引的代码的情况下拉取数据。
- en: RAG, hybrid search
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: RAG，混合搜索
- en: As the result of combining grounding techniques, [hybrid search](https://oreil.ly/c2W8A)
    leverages both embedding-based retrieval in combination with index-based retrieval
    to unlock some of the most powerful techniques.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 作为结合基础技术的结果，[混合搜索](https://oreil.ly/c2W8A)利用基于嵌入的检索和基于索引的检索相结合，解锁一些最强大的技术。
- en: Other grounding techniques
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 其他基础技术
- en: Other techniques include contextualization (providing information about topics
    and/or specific URLs to define a reduced knowledge scope) and live internet results
    to complement the LLM information and include external sources.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 其他技术包括上下文化（提供有关主题和/或特定 URL 的信息以定义一个减少的知识范围）和实时互联网结果，以补充 LLM 信息并包含外部来源。
- en: As you can see in [Figure 3-2](#fig_2_knowledge_scope_for_generative_ai), all
    these elements contribute to the creation of an extended knowledge domain from
    regular LLMs, based on internet and private data. The rest of this chapter will
    focus on different techniques to implement them with Azure OpenAI and other Microsoft
    services.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[图 3-2](#fig_2_knowledge_scope_for_generative_ai)中可以看到，所有这些元素都为从常规 LLMs
    基于互联网和私有数据创建一个扩展的知识领域做出了贡献。本章的其余部分将专注于使用 Azure OpenAI 和其他 Microsoft 服务实现这些技术的不同方法。
- en: Summarizing, any generative AI architecture or approach will depend on the knowledge
    domains and levels we require for the end solutions. If our application can rely
    on (just) the LLM, which already contains a massive amount of information, then
    we can implement the model with no additional building blocks. On the other hand,
    if we need to add specific information from other sources (including PDFs, text
    documents, websites, databases, etc.), then we will leverage the so-called fine-tuning
    and grounding techniques.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，任何生成式 AI 架构或方法都将取决于我们为最终解决方案所需的知识领域和水平。如果我们的应用程序可以依赖（仅仅是）已经包含大量信息的 LLM，那么我们可以不添加任何额外的构建块来实现该模型。另一方面，如果我们需要添加来自其他来源的特定信息（包括
    PDF、文本文档、网站、数据库等），那么我们将利用所谓的微调和基础技术。
- en: Let’s now explore the available interfaces and tools for you to create new applications
    with Azure OpenAI Service. You will understand the key building blocks before
    moving into a step-by-step guide of the most relevant implementation approaches.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来探索可用的接口和工具，以便你使用 Azure OpenAI 服务创建新的应用程序。在进入最相关实现方法的逐步指南之前，你将了解关键构建块。
- en: '![](assets/aoas_0302.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0302.png)'
- en: Figure 3-2\. Knowledge scope for generative AI
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. 生成式 AI 的知识范围
- en: Generative AI Modeling with Azure OpenAI Service
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Azure OpenAI 服务进行生成式 AI 模型构建
- en: One of the key adoption factors that encourages people to use Azure OpenAI is
    the availability of different visual and code-based interfaces that you can leverage
    while using the service. In this section we will explore them as well as how to
    use these interfaces depending on your generative AI implementation approach.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励人们使用 Azure OpenAI 的一个关键采用因素是服务中可用的不同视觉和基于代码的界面。在本节中，我们将探讨这些界面以及如何根据您的生成式 AI
    实施方法使用这些界面。
- en: Warning
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Initially, Microsoft released Azure OpenAI Service with “Gated General Availability,”
    meaning that any organization willing to use the service had to *complete a detailed
    application form* to explain the potential use cases and guarantee good usage
    of the platform. Microsoft’s goal was to validate that any application enabled
    by Azure OpenAI was always aligned with their [responsible AI approach](https://oreil.ly/QsuYY)
    and the [intended use](https://oreil.ly/7ojQP) of the platform. If you are getting
    started with Azure OpenAI Service, [check first if you still need to apply for
    access](https://oreil.ly/MDBhf) and prepare the required information for the [application
    form](https://oreil.ly/dp14y).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，Microsoft 以“有限通用可用性”的方式发布了 Azure OpenAI 服务，这意味着任何希望使用该服务的组织都必须 *填写一份详细的申请表*
    来解释潜在的使用案例并保证平台得到良好的使用。Microsoft 的目标是验证任何由 Azure OpenAI 启用的应用程序始终与其 [负责任的 AI 方法](https://oreil.ly/QsuYY)
    和平台的 [预期用途](https://oreil.ly/7ojQP) 保持一致。如果您刚开始使用 Azure OpenAI 服务，请先 [检查是否还需要申请访问权限](https://oreil.ly/MDBhf)，并准备申请表所需的必要信息。
- en: Azure OpenAI Service Building Blocks
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure OpenAI 服务构建模块
- en: 'Before diving into the “how to,” let’s explore the available building blocks
    for any Azure OpenAI practitioner to prepare and deploy new solutions. Essentially,
    there are two primary components for the Azure OpenAI Service: the *visual interfaces*
    that allow users to test, customize, and deploy their generative AI models and
    the *development interfaces* that enable the exploitation and integration of those
    advanced capabilities with any application.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨“如何做”之前，让我们探索任何 Azure OpenAI 实践者可用的构建模块，以便准备和部署新的解决方案。本质上，Azure OpenAI
    服务有两个主要组件：允许用户测试、定制和部署其生成式 AI 模型的 *视觉界面* 以及使高级功能能够被利用和集成到任何应用程序中的 *开发界面*。
- en: Both elements are complementary and great assets for any kind of adopter, as
    they require a relatively low level of AI knowledge to make them work. For example,
    *citizen users* (hybrid technical-business profiles that are not very technical,
    but that understand the principles of generative AI and have some knowledge of
    prompt engineering, can use the visual playground, or leverage Microsoft Copilot
    Studio) and *regular developers* are great candidates for the development platforms.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个元素对任何类型的采用者来说都是互补的，并且是宝贵的资产，因为它们只需要相对较低水平的 AI 知识就能使其工作。例如，*公民用户*（混合技术-商业背景，技术性不强，但理解生成式
    AI 的原理并具备一些提示工程知识，可以使用视觉游乐场，或利用 Microsoft Copilot Studio）和 *常规开发者* 都是开发平台的理想人选。
- en: 'Visual interfaces: Azure OpenAI Studio and Playground'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 视觉界面：Azure OpenAI Studio 和 Playground
- en: As with any other [Azure AI service](https://oreil.ly/TDoRH), Azure OpenAI includes
    the notion of a “Studio” (i.e., [Azure OpenAI Studio)](https://oreil.ly/LWQO1)
    that makes the interaction with generative AI models very simple, by providing
    an intuitive UI that facilitates service deployments and leverages existing Azure
    OpenAI APIs without any code required from the user perspective.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何其他 [Azure AI 服务](https://oreil.ly/TDoRH) 一样，Azure OpenAI 包含了“工作室”的概念（即 [Azure
    OpenAI Studio](https://oreil.ly/LWQO1)），通过提供直观的 UI，使与生成式 AI 模型的交互变得非常简单，用户无需编写任何代码即可利用现有的
    Azure OpenAI API 进行服务部署。
- en: Azure OpenAI Studio includes access to [all available models](https://oreil.ly/BI5Ue)
    (by type and geographic region), predefined prompting scenarios and examples,
    and several applications called *playgrounds*. The Azure OpenAI Playgrounds are
    different apps within Azure OpenAI Service, which include (as you can see in [Figure 3-3](#fig_3_azure_openai_studio))
    a customizable ChatGPT type of instance (*Chat*), other GPT language models for
    nonchat scenarios (*Completion*), a playground to connect AI models with your
    data (*Bring your own data*), and one for image generation applications with OpenAI’s
    DALL·E models.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Azure OpenAI Studio 包括对所有可用模型（按类型和地理区域划分）的访问权限，预定义的提示场景和示例，以及几个称为 *playgrounds*
    的应用程序。Azure OpenAI Playgrounds 是 Azure OpenAI 服务内的不同应用程序，包括（如图 [图 3-3](#fig_3_azure_openai_studio)
    所示）一个可定制的 ChatGPT 类型实例 (*Chat*)，其他用于非聊天场景的 GPT 语言模型 (*Completion*)，一个连接 AI 模型与您的数据的游乐场
    (*Bring your own data*)，以及一个用于图像生成应用程序的 OpenAI 的 DALL·E 模型。
- en: '![](assets/aoas_0303.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0303.png)'
- en: Figure 3-3\. Azure OpenAI Studio
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. Azure OpenAI Studio
- en: 'You can access each playground (and their related management features) from
    the left panel of the studio, or visit them directly by following the URLs included
    here:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从工作室的左侧面板访问每个游乐场（及其相关管理功能），或直接通过以下网址访问：
- en: '[Chat playground](https://oreil.ly/FRU9K)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[聊天游乐场](https://oreil.ly/FRU9K)'
- en: This includes both the conversational Chat playground with the [features and
    settings](https://oreil.ly/K_fjL) required to create a private ChatGPT implementation,
    and the bring your own data (represented as one of the playgrounds in Azure OpenAI
    Studio) functionality that I will explain later in this section. The Chat playground
    (shown in [Figure 3-4](#fig_4_azure_openai_studio_chat_playground)) leverages
    the [Chat Completion API](https://oreil.ly/ZJOLp).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这包括用于创建私有 ChatGPT 实现所需的对话式聊天游乐场 [功能和设置](https://oreil.ly/K_fjL)，以及我将在本节后面解释的“自带数据”功能（在
    Azure OpenAI Studio 中表示为其中一个游乐场）。聊天游乐场（如图 [图 3-4](#fig_4_azure_openai_studio_chat_playground)
    所示）利用了 [聊天完成 API](https://oreil.ly/ZJOLp)。
- en: '![](assets/aoas_0304.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0304.png)'
- en: 'Figure 3-4\. Azure OpenAI Studio: Chat playground'
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. Azure OpenAI Studio：聊天游乐场
- en: 'As indicated in [Figure 3-4](#fig_4_azure_openai_studio_chat_playground), the
    main tiles and features of the Chat playground comprise the following:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [图 3-4](#fig_4_azure_openai_studio_chat_playground) 所示，聊天游乐场的主要板块和功能包括以下内容：
- en: 1\. Assistant setup
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 助手设置
- en: 'This area is located on the left side of the screen and allows users to configure
    the chatbot’s behavior. Users can choose from templates or create their own custom
    system messages. This section helps users define how the chatbot should act and
    respond to user queries:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 此区域位于屏幕左侧，允许用户配置聊天机器人的行为。用户可以从模板中选择或创建自己的自定义系统消息。本节帮助用户定义聊天机器人应该如何行动并响应用户查询：
- en: System message
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 系统消息
- en: A type of [meta-prompt](https://oreil.ly/OmKQO) (i.e., a prompt that sets the
    by-default context of the discussion) to guide the AI system’s behavior. It can
    be used to introduce the system, set expectations, provide feedback, or handle
    errors. One important thing to remember is that even if there is no token limit
    for this message, it will be included with every API call, so it counts against
    the overall [token limit/context length](https://oreil.ly/BI5Ue) of the model.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一种 [元提示](https://oreil.ly/OmKQO) 类型（即设置讨论默认上下文的提示）以指导 AI 系统的行为。它可以用来介绍系统，设定期望，提供反馈或处理错误。需要记住的一个重要事项是，即使此消息没有令牌限制，它也将包含在每个
    API 调用中，因此它将计入模型的总体 [令牌限制/上下文长度](https://oreil.ly/BI5Ue)。
- en: Examples
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: 'This area is located at the bottom-left corner of the screen. You can add examples
    to the bot intelligence, so it learns the proper way to answer specific questions.
    It’s a good option when we don’t need to fully retrain a model, for example, when
    you need to add a couple of topics from your company’s knowledge base and you
    want to define the best way to answer. From the official description: “Add examples
    to show the chat what responses you want. It will try to mimic any responses you
    add here so make sure they match the rules you laid out in the system message.”'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此区域位于屏幕左下角。您可以为机器人智能添加示例，以便它学习正确回答特定问题的方法。当我们不需要完全重新训练模型时，这是一个很好的选项，例如，当您需要从公司的知识库中添加几个主题，并希望定义最佳回答方式时。根据官方描述：“添加示例以显示聊天希望得到的响应。它将尝试模仿您在此处添加的任何响应，因此请确保它们与系统消息中设定的规则相匹配。”
- en: 2\. Chat session
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 聊天会话
- en: This area is located in the middle of the screen and serves as the main interaction
    point between you and the chatbot. You can type your queries here and the chatbot
    will respond accordingly. The chat session allows you to test the chatbot’s performance
    and make adjustments to the assistant setup as needed, as well as import and export
    bot configurations, or get the result as a [JavaScript Object Notation (JSON)
    file](https://oreil.ly/LZJH4).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个区域位于屏幕中间，是你与聊天机器人之间主要交互点。你可以在这里输入你的查询，聊天机器人将相应地做出回应。聊天会话允许你测试聊天机器人的性能，并根据需要调整助手设置，以及导入和导出机器人配置，或以[JavaScript对象表示法（JSON）文件](https://oreil.ly/LZJH4)的形式获取结果。
- en: 3\. Deploy to
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 部署到
- en: This option allows you to deploy your chatbot to a specific platform or environment.
    Azure OpenAI Studio allows direct deployments to both [Azure Web Apps](https://oreil.ly/TtlXr)
    and [Microsoft Copilot Studio](https://oreil.ly/YV0SN). We will explore these
    deployment options later in this chapter.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此选项允许你将你的聊天机器人部署到特定的平台或环境。Azure OpenAI Studio允许直接部署到[Azure Web Apps](https://oreil.ly/TtlXr)和[Microsoft
    Copilot Studio](https://oreil.ly/YV0SN)。我们将在本章后面探索这些部署选项。
- en: 4\. Configuration
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 配置
- en: 'This area is located in the top-right corner of the screen. It provides options
    for you to access deployment and session settings. Users can also clear the chat
    history and manage parameters related to the chatbot’s deployment:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这个区域位于屏幕右上角。它提供了访问部署和会话设置选项。用户还可以清除聊天历史记录和管理与聊天机器人部署相关的参数：
- en: Deployment
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 部署
- en: 'To handle session-level configurations, such as the Azure OpenAI deployment
    resource you want to use (e.g., you may have several for different geographic
    regions), as well as the memory of the session, which will impact how many interactions
    the system can remember when getting new questions:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理会话级配置，例如你想要使用的Azure OpenAI部署资源（例如，你可能为不同的地理区域有几个），以及会话的内存，这将影响系统在获取新问题时能记住多少交互：
- en: Deployment instance
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 部署实例
- en: You will select one option, from the resources you have [previously deployed](https://oreil.ly/-4D4f)
    (if you haven’t, you will need to create one before using Azure OpenAI Studio),
    based on the geography and model needs you may have.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你将根据可能需要的地理和模型需求，从你之前部署的资源中选择一个选项（如果你还没有，在使用Azure OpenAI Studio之前，你需要创建一个），基于地理和模型需求。
- en: Past messages included and current token count
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 包含的历史消息和当前令牌计数
- en: Session-level parameters you may want to adjust for the specific test you do
    via the Chat playground. These parameters will be gone when you finish the playground
    session, except if you deploy an application (we will see the deployment options
    in a couple of sections).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想要调整的会话级参数，这些参数是在通过聊天游乐场进行的特定测试时使用的。当你完成游乐场会话后，这些参数将消失，除非你部署了一个应用程序（我们将在接下来的几个部分中看到部署选项）。
- en: Parameters
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 参数
- en: 'This right panel includes all technical settings that will allow you to configure
    the expected output message, including the level of creativity versus determinism
    of the answer:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此右侧面板包括所有技术设置，允许你配置预期的输出消息，包括答案的创造性与确定性水平：
- en: Max response
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最大响应
- en: This parameter helps you set a limit on the number of tokens per model response.
    The max response is measured in the number of tokens, and it is shared between
    the question (including system message, examples, message history, and prompt/user
    query) and the model’s response.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此参数帮助你为每个模型响应设置令牌数量的上限。最大响应以令牌数量衡量，它包括问题（包括系统消息、示例、消息历史和提示/用户查询）和模型的响应。
- en: Temperature
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 温度
- en: This parameter and the Top-p parameter are direct alternatives to control the
    AI model’s randomness. Lowering the temperature means that the model will produce
    more repetitive and deterministic responses. Increasing the temperature will result
    in more unexpected or creative responses. Try adjusting temperature or Top-p,
    but not both.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 此参数和Top-p参数是直接替代品，用于控制AI模型的随机性。降低温度意味着模型将产生更多重复和确定性的响应。提高温度将导致更多意外或创造性的响应。尝试调整温度或Top-p，但不要同时调整两者。
- en: '[Assistants playground](https://oreil.ly/S4KFy)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[助手游乐场](https://oreil.ly/S4KFy)'
- en: '[Released in 2024](https://oreil.ly/MdxvG), the Assistants playground is visually
    similar to the Chat playground, but it includes:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[于2024年发布](https://oreil.ly/MdxvG)，助手游乐场在视觉上与聊天游乐场相似，但它包括：'
- en: The ability to handle conversation threads, by using the “thread ID” parameter
    that converts the chat discussion into a stateful application that keeps context
    and memory. You can see the details in Azure OpenAI’s [Assistants API specification](https://oreil.ly/ErRd6).
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用“线程 ID”参数，可以将聊天讨论转换为具有状态的应用程序，以保持上下文和记忆。您可以在 Azure OpenAI 的 [助手 API 规范](https://oreil.ly/ErRd6)中查看详细信息。
- en: Other functionalities such as the API call log, the [Code Interpreter](https://oreil.ly/3jSFV),
    and [function calling](https://oreil.ly/2R7Pz).
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他功能，如 API 调用日志、[代码解释器](https://oreil.ly/3jSFV)和[函数调用](https://oreil.ly/2R7Pz)。
- en: Keep in mind that this is a relatively new option, but the [official documentation](https://oreil.ly/HH4hH)
    includes the detailed steps for creation and management of assistant files. Keep
    an eye on and bookmark this URL to follow any news and technical resources.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这是一个相对较新的选项，但[官方文档](https://oreil.ly/HH4hH)包括了助手文件创建和管理的详细步骤。请关注并收藏此 URL，以跟踪任何新闻和技术资源。
- en: '[Completions playground](https://oreil.ly/zJYtL)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[完成度游乐场](https://oreil.ly/zJYtL)'
- en: As we reviewed in [Chapter 1](ch01.html#introduction_to_generative_ai_and_azure_openai_ser),
    the completion skill is (along with chat and embeddings models) one of the core
    concepts for NLP and modern LLMs. Completion focuses on unitary interactions for
    all kinds of text-based requests (with no need for memory between interactions,
    as you may need for chat-based applications in which the model keeps the discussion
    context). It leverages the [Completions API](https://oreil.ly/Uczv9). As shown
    in [Figure 3-5](#fig_5_azure_openai_studio_completions_playground), the Completions
    playground allows you to type a prompt, or choose from a series of examples. It
    also includes the same kind of setting parameters that we reviewed in the Chat
    playground.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在 [第 1 章](ch01.html#introduction_to_generative_ai_and_azure_openai_ser) 中所回顾的，完成度技能（与聊天和嵌入模型一起）是
    NLP 和现代 LLM 的核心概念之一。完成度专注于各种基于文本请求的单一交互（无需在交互之间保持记忆，如聊天应用程序中可能需要的，其中模型保持讨论上下文）。它利用了
    [完成度 API](https://oreil.ly/Uczv9)。如图 3-5 所示，完成度游乐场允许您输入提示，或从一系列示例中选择。它还包括我们在聊天游乐场中回顾过的相同类型的设置参数。
- en: '![](assets/aoas_0305.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0305.png)'
- en: 'Figure 3-5\. Azure OpenAI Studio: Completions playground'
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-5\. Azure OpenAI Studio：完成度游乐场
- en: You can generate an answer (completion), and even regenerate it to obtain a
    totally new output. If you choose one of the examples from the drop-down menu,
    you will see an automatic prompt appear and the corresponding completion, highlighted
    as in [Figure 3-6](#fig_6_azure_openai_studio_completions_playground_examp).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以生成一个答案（完成度），甚至可以重新生成它以获得全新的输出。如果您从下拉菜单中选择一个示例，您将看到一个自动提示出现，并显示相应的完成度，如图 3-6
    所示。
- en: '![](assets/aoas_0306.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0306.png)'
- en: 'Figure 3-6\. Azure OpenAI Studio: Completions playground (example)'
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-6\. Azure OpenAI Studio：完成度游乐场（示例）
- en: Summarizing, you may use chat for multistep scenarios where you need to maintain
    a sequence of interactions with the AI model, while completions can be used for
    specific unitary cases. As you will see later, these two playgrounds are just
    visual interfaces that consume existing Azure OpenAI [completion](https://oreil.ly/Uczv9)
    and [chat](https://oreil.ly/ZJOLp) APIs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，您可以使用聊天进行多步骤场景，在这些场景中您需要与 AI 模型保持一系列交互，而完成度可以用于特定的单一案例。正如您稍后将会看到的，这两个游乐场只是消耗现有
    Azure OpenAI [完成度](https://oreil.ly/Uczv9)和[聊天](https://oreil.ly/ZJOLp) API 的可视化界面。
- en: Bring your own data playground
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 带上您自己的数据游乐场
- en: Even if Azure OpenAI Studio shows this feature as a separate playground, it
    is technically part of the Chat playground. To access this functionally, you can
    either use the Chat playground’s Assistant setup and select the “Add your data”
    tab or go directly to the “Bring your own data” tile of the Studio ([Figure 3-7](#fig_7_azure_openai_studio_bring_your_own_data)).
    For both cases, the result will be the same.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 即使 Azure OpenAI Studio 将此功能显示为单独的游乐场，但从技术上讲，它仍然是聊天游乐场的一部分。要访问此功能，您可以使用聊天游乐场的助手设置并选择“添加您的数据”标签，或者直接转到工作室的“带上您自己的数据”磁贴（[图
    3-7](#fig_7_azure_openai_studio_bring_your_own_data)）。在两种情况下，结果都将相同。
- en: Once you reach this point, the sequence of steps is pretty simple. As you can
    see in [Figure 3-8](#fig_8_azure_openai_studio_bring_your_own_data_source_de),
    the system will allow you to select your own sources of data, to combine their
    knowledge with the baseline LLM. That knowledge can come from PDF files, text-based
    documents, slides, web files, etc. In this case, besides the Azure OpenAI resource
    previously deployed, the bring your own data functionality will leverage other
    resources such as Azure Data Lake Gen2/Azure Storage, to save the files, and Azure
    Cognitive Search, to index the files. Azure Cognitive Search offers a vector search
    functionality based on the [Embeddings API](https://oreil.ly/imKOS)) that I will
    explain by the end of the chapter. Finally, you can always check the [official
    documentation](https://oreil.ly/z_iRM) to follow the latest updates for this Azure
    OpenAI feature, as it is a quickly evolving one due to the continuous incorporation
    of new functionalities.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦达到这一点，步骤序列相当简单。如图3-8所示，系统将允许您选择自己的数据源，将它们的知识与基线LLM相结合。这些知识可以来自PDF文件、基于文本的文档、幻灯片、网页文件等。在这种情况下，除了之前部署的Azure
    OpenAI资源外，自带数据功能还将利用其他资源，如Azure Data Lake Gen2/Azure Storage来保存文件，以及Azure Cognitive
    Search来索引文件。Azure Cognitive Search提供基于[嵌入API](https://oreil.ly/imKOS)的向量搜索功能，我将在本章末尾解释。最后，您始终可以查看[官方文档](https://oreil.ly/z_iRM)，以了解此Azure
    OpenAI功能的最新更新，因为它是一个快速发展的功能，因为持续整合新的功能。
- en: '![](assets/aoas_0307.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0307.png)'
- en: 'Figure 3-7\. Azure OpenAI Studio: Bring your own data'
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-7\. Azure OpenAI Studio：自带数据
- en: '![](assets/aoas_0308.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0308.png)'
- en: 'Figure 3-8\. Azure OpenAI Studio: Bring your own data source details'
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-8\. Azure OpenAI Studio：自带数据源详情
- en: '[DALL·E playground](https://oreil.ly/r4h7Y)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[DALL·E游乐场](https://oreil.ly/r4h7Y)'
- en: The last playground tile provides direct access to the generative AI DALL·E
    models (versions 2 and 3) from OpenAI. This is a text-to-image model that allows
    you to create new images from just text-based descriptions. Imagine describing
    a place or a scene and getting a visual representation in the form of images that
    are freshly created on demand. This means they didn’t exist previously and that
    you can integrate this capability into your solutions and combine it with the
    rest of the language. The DALL·E playground (shown in [Figure 3-9](#fig_9_azure_openai_studio_dall_e_playground))
    leverages the [Image Generation API](https://oreil.ly/bm-7a).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个游乐场瓷砖可以直接访问来自OpenAI的生成式AI DALL·E模型（版本2和3）。这是一个基于文本描述创建新图像的文本到图像模型。想象一下描述一个地方或场景，并得到以图像形式呈现的视觉表示，这些图像是按需新鲜创建的。这意味着它们之前并不存在，您可以将此功能集成到您的解决方案中，并与语言的其他部分结合。DALL·E游乐场（如图3-9所示）利用了[图像生成API](https://oreil.ly/bm-7a)。
- en: '![](assets/aoas_0309.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0309.png)'
- en: 'Figure 3-9\. Azure OpenAI Studio: DALL·E playground'
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-9\. Azure OpenAI Studio：DALL·E游乐场
- en: 'As shown in [Figure 3-9](#fig_9_azure_openai_studio_dall_e_playground), relevant
    aspects of the playground include the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图3-9](#fig_9_azure_openai_studio_dall_e_playground)所示，游乐场的相关方面包括以下内容：
- en: 1\. Playground
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 游乐场
- en: The DALL·E playground is visually simple—a prompt field and the results (image)
    below. It’s similar to the structure of the [Bing Create application](https://oreil.ly/YwDy-),
    but with the option to deploy the DALL·E model for your own development.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: DALL·E游乐场在视觉上很简单——一个提示字段和下面的结果（图像）。它与[Bing Create应用程序](https://oreil.ly/YwDy-)的结构相似，但提供了部署DALL·E模型以供您自己开发的选择。
- en: 2\. Settings
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 设置
- en: The settings panel offers you the option to choose the number of images you
    want to generate and the image size.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 设置面板为您提供选择要生成的图像数量和图像大小的选项。
- en: 3\. Album
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 相册
- en: The album section showcases all past image experiments, offering you the option
    to review previously created images, generate new ones, etc.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 相册部分展示了所有过去进行的图像实验，为您提供查看先前创建的图像、生成新的图像等选项。
- en: Besides the different playgrounds, you can also explore the left-side *Management*
    panel shown in [Figure 3-10](#fig_10_azure_openai_studio_management_panels), which
    include options such as deployments, models, data files, quotas, and content filters.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 除了不同的游乐场外，您还可以探索[图3-10](#fig_10_azure_openai_studio_management_panels)中显示的左侧*管理*面板，其中包括部署、模型、数据文件、配额和内容过滤器等选项。
- en: '![](assets/aoas_0310.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0310.png)'
- en: 'Figure 3-10\. Azure OpenAI Studio: Management panels'
  id: totrans-104
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-10\. Azure OpenAI Studio：管理面板
- en: 'Let’s explore the most important features:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索最重要的功能：
- en: '[Deployments](https://oreil.ly/PGocU)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[部署](https://oreil.ly/PGocU)'
- en: Allows you to deploy any specific model instance [available in the geographic
    region](https://oreil.ly/XZnCX) of your Azure OpenAI resource and to visualize
    those that you previously deployed ([Figure 3-11](#fig_11_azure_openai_studio_deployments)).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 允许您部署Azure OpenAI资源地理区域中[任何可用的特定模型实例](https://oreil.ly/XZnCX)，并可视化您之前部署的模型（[图3-11](#fig_11_azure_openai_studio_deployments)）。
- en: '![](assets/aoas_0311.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0311.png)'
- en: 'Figure 3-11\. Azure OpenAI Studio: deployments'
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-11\. Azure OpenAI Studio：部署
- en: '[Content filters](https://oreil.ly/Bpsud)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[内容过滤器](https://oreil.ly/Bpsud)'
- en: For responsible AI moderation. Each filter from those in [Figure 3-12](#fig_12_azure_openai_studio_content_filters)
    (e.g., hate, sexual, self-harm, and violence topics for both prompts and completions,
    with different levels of filtering) can be applied to the deployments, and those
    deployments will include the content filter for each chat or completion implementation.
    We will explore this feature in [Chapter 4](ch04.html#additional_cloud_and_ai_capabilities),
    as part of the responsible AI measures for generative AI implementations.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于负责任的AI监管。从[图3-12](#fig_12_azure_openai_studio_content_filters)中的过滤器（例如，针对提示和完成的仇恨、性、自残和暴力主题，具有不同的过滤级别）可以应用于部署，并且这些部署将包括每个聊天或完成实现的
    内容过滤器。我们将在[第4章](ch04.html#additional_cloud_and_ai_capabilities)中探讨此功能，作为生成式AI实现负责任AI措施的一部分。
- en: '![](assets/aoas_0312.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0312.png)'
- en: 'Figure 3-12\. Azure OpenAI Studio: content filters'
  id: totrans-113
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-12\. Azure OpenAI Studio：内容过滤器
- en: '[Models](https://oreil.ly/oC3Hj)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[模型](https://oreil.ly/oC3Hj)'
- en: This option shows the [available Azure OpenAI models](https://oreil.ly/XZnCX),
    related to the specific geographic region of the chosen deployment.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 此选项显示与所选部署的特定地理区域相关的[可用的Azure OpenAI模型](https://oreil.ly/XZnCX)。
- en: '[Data files](https://oreil.ly/2TZwW)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[数据文件](https://oreil.ly/2TZwW)'
- en: This file management feature allows you to [prepare the dataset for fine-tuned
    implementations](https://oreil.ly/FDMr1). We will explore more about fine-tuning
    later in this chapter.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 此文件管理功能允许您[为微调实现准备数据集](https://oreil.ly/FDMr1)。我们将在本章后面探讨更多关于微调的内容。
- en: '[Quotas](https://oreil.ly/ONn5Q)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[配额](https://oreil.ly/ONn5Q)'
- en: The quota panel shows the [usage quotas](https://oreil.ly/bEN4D) related to
    different models and geographic regions. It also helps you [request a quota increase](https://oreil.ly/iiysu)
    if you need more. Alternatively, and I will explain this in [Chapter 6](ch06.html#elaborating_generative_ai_business_cases)
    as part of the pricing and estimation exercise, you have an option to hire dedicated
    capacity, by leveraging the so-called [provisioned throughput units (PTU) for
    Azure OpenAI](https://oreil.ly/KCC6K), which are reserved instances with performance
    and service availability benefits.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 配额面板显示了与不同模型和地理区域相关的[使用配额](https://oreil.ly/bEN4D)。它还帮助您[请求配额增加](https://oreil.ly/iiysu)，如果您需要更多的话。或者，我将在[第6章](ch06.html#elaborating_generative_ai_business_cases)中解释这一点，作为定价和估算练习的一部分，您可以选择通过利用所谓的[Azure
    OpenAI的预留吞吐量单位（PTU）](https://oreil.ly/KCC6K)来雇佣专用容量，这些是具有性能和服务可用性优势的预留实例。
- en: We will explore some of these functionalities later in this chapter and in [Chapter 4](ch04.html#additional_cloud_and_ai_capabilities),
    as they will all be relevant, depending on the type of Azure OpenAI implementation
    you plan to utilize. Now, let’s see what you can do to deploy these models via
    Azure OpenAI Studio.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章和[第4章](ch04.html#additional_cloud_and_ai_capabilities)中探讨这些功能的一些内容，因为它们都将与您计划利用的Azure
    OpenAI实现类型相关。现在，让我们看看您可以通过Azure OpenAI Studio部署这些模型能做什么。
- en: 'Deployment interfaces: Web apps and Microsoft Copilot agents'
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署接口：Web应用和Microsoft Copilot代理
- en: 'As mentioned in this chapter, the Chat playground includes some easy-to-use
    deployment options. They are not available for the rest of the playgrounds, but
    they can simplify the preliminary deployment of Azure OpenAI models for internal
    testing and use purposes, without any coding required. These no-code deployments
    can incorporate the specific knowledge from the bring your own data functionality.
    There are two possibilities:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章所述，聊天游乐场包括一些易于使用的部署选项。它们对其他游乐场不可用，但可以简化Azure OpenAI模型在内部测试和使用目的的初步部署，无需任何编码。这些无代码部署可以结合从“自带数据”功能中获取的特定知识。有两种可能性：
- en: Web apps with [Azure App Service](https://oreil.ly/moBFz)
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 带有[Azure App Service](https://oreil.ly/moBFz)的Web应用
- en: The first available deployment option, which you can use with or without the
    “bring your own data” feature activated. As we discussed in [Chapter 2](ch02.html#designing_cloud_native_architectures_for_generativ),
    App Service is the Azure option to deploy native web apps; it allows integrations
    with both external and internal systems and web development with a variety of
    programming languages. From Azure OpenAI Studio and its Chat playground, you can
    simply “Deploy to” and then configure your deployment (see [Figure 3-13](#fig_13_azure_openai_studio_web_app_deployment)).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个可用的部署选项，您可以使用或不需要激活“自带数据”功能。正如我们在 [第 2 章](ch02.html#designing_cloud_native_architectures_for_generativ)
    中讨论的那样，App Service 是 Azure 部署原生 Web 应用的选项；它允许与外部和内部系统以及使用各种编程语言的 Web 开发进行集成。从
    Azure OpenAI Studio 和其 Chat playground，您可以简单地“部署到”，然后配置您的部署（见 [图 3-13](#fig_13_azure_openai_studio_web_app_deployment)）。
- en: '![](assets/aoas_0313.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0313.png)'
- en: 'Figure 3-13\. Azure OpenAI Studio: web app deployment'
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-13\. Azure OpenAI Studio：Web 应用部署
- en: 'As shown in [Figure 3-13](#fig_13_azure_openai_studio_web_app_deployment),
    configuration options include the following:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [图 3-13](#fig_13_azure_openai_studio_web_app_deployment) 所示，配置选项包括以下内容：
- en: Choosing the web app
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 Web 应用
- en: You can create a new App Service resource directly from this feature (in that
    case, you will need to define the “app name” that will be part of your web app
    URL), or choose an existing one if you have previously deployed via [Azure portal’s
    App Service panel](https://oreil.ly/dPLy2).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以直接从该功能创建一个新的 App Service 资源（在这种情况下，您需要定义将成为您 Web 应用 URL 的一部分的“应用程序名称”），或者如果您之前通过
    [Azure 门户的 App Service 面板](https://oreil.ly/dPLy2) 部署过，可以选择现有的一个。
- en: Pricing plan
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 定价计划
- en: To select the preferred [pricing tier](https://oreil.ly/IdDXQ) for the web app.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 Web 应用的首选 [定价层](https://oreil.ly/IdDXQ)。
- en: Chat history
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天历史记录
- en: A functionality that allows the web app users to recover their [previous interactions](https://oreil.ly/-yyQg)
    with chat. It relies on [Cosmos DB (Azure’s NoSQL database)](https://oreil.ly/-yyQg),
    which obviously adds cost to the existing Azure OpenAI and App Service resources.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一种允许 Web 应用用户恢复其与聊天 [先前交互](https://oreil.ly/-yyQg) 的功能。它依赖于 [Cosmos DB（Azure
    的 NoSQL 数据库）](https://oreil.ly/-yyQg)，这显然会增加现有的 Azure OpenAI 和 App Service 资源的成本。
- en: Once you have selected all these options, you can click on Deploy. You will
    need to wait around 10 minutes for all the resources to be deployed, then you
    will be able to launch your web app from the studio, or by typing the URL *https://<appname>.azurewebsites.net**.*The
    look and feel will be something like the interface you see in [Figure 3-14](#fig_14_azure_openai_studio_web_app_interface).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您选择了所有这些选项，您就可以点击部署。您需要等待大约 10 分钟，以便所有资源被部署，然后您将能够从工作室或通过输入 URL *https://<appname>.azurewebsites.net**
    启动您的 Web 应用。外观和感觉将类似于您在 [图 3-14](#fig_14_azure_openai_studio_web_app_interface)
    中看到的界面。
- en: '![](assets/aoas_0314.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0314.png)'
- en: 'Figure 3-14\. Azure OpenAI Studio: web app interface'
  id: totrans-136
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-14\. Azure OpenAI Studio：Web 应用界面
- en: The UI of the new app will contain a regular chatbot setup, with options to
    share and check previous discussions on the top-right side of the window. You
    can also [customize the visual aspect of the application](https://oreil.ly/BVUkG)
    by using the [official source code](https://oreil.ly/MeBin), and deploy it programmatically,
    with Azure App Service and using your preferred programming language, instead
    of leveraging Azure OpenAI Studio.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 新应用的 UI 将包含一个常规聊天机器人设置，并在窗口右上角提供分享和检查先前讨论的选项。您还可以通过使用 [官方源代码](https://oreil.ly/MeBin)
    来 [自定义应用程序的视觉外观](https://oreil.ly/BVUkG)，并通过 Azure App Service 以编程方式部署，使用您首选的编程语言，而不是利用
    Azure OpenAI Studio。
- en: Bots with [Microsoft Copilot Studio (formerly Power Virtual Agents [PVAs])](https://oreil.ly/YV0SN)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 带有 [Microsoft Copilot Studio（以前称为 Power Virtual Agents [PVAs]）](https://oreil.ly/YV0SN)
    的机器人
- en: This option is available for Chat playground implementations that include the
    “bring your own data” feature. That means that if you don’t add extended knowledge
    from PDFs or other documents, the Chat playground won’t include Microsoft Copilot
    Studio/PVA as a deployment option in the top-right corner in [Figure 3-15](#fig_15_azure_openai_studio_copilot_deployment).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此选项适用于包含“自带数据”功能的 Chat playground 实现。这意味着如果您不添加来自 PDF 或其他文档的扩展知识，Chat playground
    不会在 [图 3-15](#fig_15_azure_openai_studio_copilot_deployment) 的右上角将 Microsoft Copilot
    Studio/PVA 作为部署选项。
- en: '![](assets/aoas_0315.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0315.png)'
- en: 'Figure 3-15\. Azure OpenAI Studio: Copilot deployment'
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-15\. Azure OpenAI Studio：Copilot 部署
- en: How to handle PVAs is outside of the scope of this book, but you can explore
    the [detailed instructions from the official documentation](https://oreil.ly/Qi9J3)
    that show how to use PVAs with Azure OpenAI for the *generative answers* feature.
    This option is available for only certain geographic regions, so you will need
    to validate if your deployments with Azure OpenAI models show the PVA deployment
    option in the Chat playground. If this is not the case, you may want to deploy
    new models in other regions.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如何处理PVAs超出了本书的范围，但您可以探索[官方文档中的详细说明](https://oreil.ly/Qi9J3)，其中展示了如何使用PVAs与Azure
    OpenAI结合使用以实现*生成式答案*功能。此选项仅适用于某些地理区域，因此您需要验证您的Azure OpenAI模型部署是否在Chat playground中显示PVA部署选项。如果不是这种情况，您可能需要在其他地区部署新模型。
- en: Summarizing, these visual interfaces can help you leverage Azure OpenAI models
    in a simple manner. They provide an intuitive way to launch the Azure OpenAI APIs
    in just a few clicks. However, you will need code-based tools to implement the
    other advanced architectures you will see later in this chapter. Let’s now explore
    those APIs and other development kits so you can leverage everything that Azure
    OpenAI Service has to offer.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，这些可视化界面可以帮助您以简单的方式利用Azure OpenAI模型。它们提供了一种直观的方式，只需几点击即可启动Azure OpenAI API。然而，您需要基于代码的工具来实现本章后面将看到的其他高级架构。现在让我们探索这些API和其他开发工具包，以便您可以利用Azure
    OpenAI服务提供的一切。
- en: 'Development interfaces: APIs and SDKs'
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开发接口：API和SDK
- en: In addition to all the previously explored interfaces, one of the key enablers
    for integrating Azure OpenAI with existing or new applications is the ability
    to consume the preconfigured models as regular endpoints. From a development point
    of view, we can call those models by using the APIs and related software development
    kits (SDKs) and pass any input and configuration parameters within the code. This
    section covers the main pieces you need to know—the *Azure OpenAI Service REST
    APIs*, including the [official API reference documentation](https://oreil.ly/qH3FL),
    with specific details for chat, completions, embeddings, and other deployments.
    There is also an [official repo](https://oreil.ly/mbA1v) with the full specifications.
    There are general APIs that will help you with the configuration and deployment
    of Azure OpenAI services, while the service APIs help you consume the models to
    bring the AI capabilities to your generative AI applications.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 除了之前探索的所有接口之外，将Azure OpenAI与现有或新应用程序集成的关键推动因素之一是能够将预配置模型作为常规端点进行消费。从开发的角度来看，我们可以使用API和相关软件开发工具包（SDKs）来调用这些模型，并在代码中传递任何输入和配置参数。本节涵盖了您需要了解的主要内容——*Azure
    OpenAI服务REST API*，包括[官方API参考文档](https://oreil.ly/qH3FL)，其中包含聊天、完成、嵌入和其他部署的详细信息。还有一个[官方仓库](https://oreil.ly/mbA1v)，包含完整的规范。有一些通用API可以帮助您配置和部署Azure
    OpenAI服务，而服务API可以帮助您消费模型，将AI能力带到您的生成式AI应用程序中。
- en: 'The main APIs you need to know and their high-level call details are as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要了解的主要API及其高级调用细节如下：
- en: '[General management APIs](https://oreil.ly/xkqqk)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[通用管理API](https://oreil.ly/xkqqk)'
- en: For Azure AI service account management (including Azure OpenAI), with tasks
    such as account creation, deletion, listing, etc.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Azure AI服务账户管理（包括Azure OpenAI），包括账户创建、删除、列出等任务。
- en: '[APIs for model-related information](https://oreil.ly/Y7VMR)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '[模型相关信息API](https://oreil.ly/Y7VMR)'
- en: To obtain the list of available Azure OpenAI models and information about their
    specific capabilities and the model lifecycle (including potential deprecation
    details).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 获取可用的Azure OpenAI模型列表以及它们的具体功能和模型生命周期（包括潜在的弃用细节）。
- en: '[Completions](https://oreil.ly/Uczv9)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[完成](https://oreil.ly/Uczv9)'
- en: 'The required API for nonchat language scenarios. This and other APIs are versioned
    by using the “YYYY-MM-DD” date structure for `api-version`, and you will need
    to copy the resource name and deployment-ID from the Azure OpenAI model you previously
    deployed (remember the step-by-step process from the Azure portal, in [Chapter 2](ch02.html#designing_cloud_native_architectures_for_generativ)).
    To create a completion resource, the POST operation is:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 非聊天语言场景所需的API。这些API以及其他API通过使用“YYYY-MM-DD”日期结构来对`api-version`进行版本控制，并且您需要从之前部署的Azure
    OpenAI模型中复制资源名称和部署-ID（记住从Azure门户中逐步处理的过程，在[第2章](ch02.html#designing_cloud_native_architectures_for_generativ)中）。要创建一个完成资源，POST操作如下：
- en: '[PRE0]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The request and response dynamic follows this structure, with the prompt parameter
    the input for the model to generate a specific completion, and a series of [optional
    parameters](https://oreil.ly/Uczv9) such as `max_tokens` (the limit of tokens
    for the expected answer) or the number `n` of expected completions/answers.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 请求和响应动态遵循此结构，其中提示参数是模型生成特定完成的输入，以及一系列[可选参数](https://oreil.ly/Uczv9)，例如`max_tokens`（预期答案的令牌限制）或预期完成/答案的数量`n`。
- en: '*Request*:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '*请求*：'
- en: '[PRE1]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Response*:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*响应*：'
- en: '[PRE2]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The answers (completions) contain the `finish_reason` parameter. `finish_reason`
    defines why the model stopped generating more information; for most cases this
    will be due to `max_tokens`, which stops the model once it reaches the limit.
    However, there is another option that we will explore in [Chapter 4](ch04.html#additional_cloud_and_ai_capabilities)
    that stops the model due to what we call *content filters*.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 答案（完成）包含`finish_reason`参数。`finish_reason`定义了模型停止生成更多信息的理由；在大多数情况下，这将是由于`max_tokens`，一旦模型达到限制就会停止。然而，我们将在[第4章](ch04.html#additional_cloud_and_ai_capabilities)中探讨另一种选项，即由于我们所说的*内容过滤器*而停止模型。
- en: '[Chat completions](https://oreil.ly/ZJOLp)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[聊天完成](https://oreil.ly/ZJOLp)'
- en: 'Dedicated API for chat scenarios (and the only supported one for future model
    versions), including the configuration parameters we previously reviewed with
    the Chat playground. This includes input parameters we discussed for the Azure
    OpenAI Playground, such as `temperature` and `max_tokens`. There is one important
    parameter for chat messages, known as the [ChatRole](https://oreil.ly/WLv1g).
    This allows you to split the interactions based on different roles:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 专为聊天场景设计的API（并且是未来模型版本唯一支持的API），包括我们之前在聊天沙盒中审查过的配置参数。这包括我们讨论过的Azure OpenAI沙盒的输入参数，例如`temperature`和`max_tokens`。对于聊天消息有一个重要的参数，称为[ChatRole](https://oreil.ly/WLv1g)。这允许你根据不同的角色来分割交互：
- en: System
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 系统
- en: Helps you set the behavior of the assistant.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 帮助你设置助手的行怍。
- en: User
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 用户
- en: Provides input for chat completions.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 提供聊天完成的输入。
- en: Assistant
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 助手
- en: Provides responses to system-instructed, user-prompted input.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 提供对系统指令、用户提示输入的响应。
- en: Function
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 功能
- en: Provides function results for chat completions. We will explore this concept
    later in this chapter, after we cover the different Azure OpenAI APIs.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 提供聊天完成的函数结果。我们将在本章后面探讨这个概念，在我们介绍不同的Azure OpenAI API之后。
- en: 'The sequence for a typical chat scenario follows these steps:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 典型聊天场景的序列遵循以下步骤：
- en: 1\. Resource creation
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 资源创建
- en: 'Using a similar structure to what you have seen in a regular completion API
    call (including the date as the API version). The regular POST operation for chat
    completion is:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与你在常规完成API调用中看到的类似的结构（包括日期作为API版本）。聊天完成的常规POST操作如下：
- en: '[PRE3]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 2\. System message
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 系统消息
- en: 'This is how you set the context of the chat engine, by defining the scope of
    the discussion, allowed or forbidden topics, etc. The system message is also called
    the context prompt or *meta-prompt*. The [`messages` parameter](https://oreil.ly/vFEYS),
    along with the [`role` subparameter](https://oreil.ly/y5HFq), is the place where
    you will define your system message, using:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是设置聊天引擎上下文的方式，通过定义讨论的范围、允许或禁止的主题等。系统消息也称为上下文提示或*元提示*。`messages`参数（[https://oreil.ly/vFEYS](https://oreil.ly/vFEYS)）以及`role`子参数（[https://oreil.ly/y5HFq](https://oreil.ly/y5HFq)）是定义你的系统消息的地方，使用：
- en: '[PRE4]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 3\. User-assistant interaction
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 用户-助手交互
- en: This leverages the same `messages` parameter, with the *user* and *assistant*
    roles. The structure for both roles is similar to what we have discussed for the
    system message, and the response includes the same `finish-reason` parameter that
    will give you a hint about the result (i.e., if the completion has finished due
    to the `max_tokens` assigned to the answer, or if there is a filtering reason
    due to negative topic detection).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这利用了相同的`messages`参数，包括*用户*和*助手*角色。这两个角色的结构类似于我们之前讨论的系统消息，响应中包括相同的`finish-reason`参数，这将给你一个关于结果（即，如果由于分配给答案的`max_tokens`而完成，或者如果由于负面主题检测而存在过滤原因）的提示。
- en: '[Image generation](https://oreil.ly/bm-7a)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[图像生成](https://oreil.ly/bm-7a)'
- en: 'The API call to generate images based on text-to-image DALL·E models. As with
    the visual playground, the input parameters include the text-based prompt, and
    two optional inputs such as the number `n` of desired images (if you don’t include
    it, the system will generate only one image), and the size (by default 1024×1024,
    with alternative 256×256 and 512×512 options). The POST operation to create an
    image generation resource is:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 基于文本到图像的DALL·E模型的API调用用于生成图像。与视觉游乐场类似，输入参数包括基于文本的提示，以及两个可选输入，例如所需图像的数量`n`（如果您不包含它，系统将只生成一张图像），以及大小（默认为1024×1024，有256×256和512×512的替代选项）。创建图像生成资源的POST操作如下：
- en: '[PRE5]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here is an example of a [curl (command-line tool for downloading and uploading
    files from various protocols and servers)](https://oreil.ly/xApmg) request:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个curl（用于从各种协议和服务器下载和上传文件的命令行工具）请求的示例：
- en: '[PRE6]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The end-to-end process includes three different steps:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端过程包括三个不同的步骤：
- en: '*Request*the image generation ([via POST operation](https://oreil.ly/kPf-m)),
    which helps you pre-generate the images based on the text-based input prompt.
    It returns an operation ID that you will leverage for the next step.'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*请求*图像生成（[通过POST操作](https://oreil.ly/kPf-m)），这有助于您根据基于文本的输入提示预先生成图像。它返回一个操作ID，您将在下一步中使用它。'
- en: '*Get*the result of the image generation ([GET operation](https://oreil.ly/lxX0B)),
    which allows you to recover the pre-generated images for the specific operation
    ID.'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*获取*图像生成的结果（[GET操作](https://oreil.ly/lxX0B)），允许您恢复特定操作ID预先生成的图像。'
- en: '*Delete*the previously loaded images ([DELETE operation](https://oreil.ly/5UfTB))
    from the server, for the specific Azure OpenAI resource, and the existing operation
    ID. If you don’t use this option, the images will be automatically deleted after
    24 hours.'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*删除*服务器上之前加载的图像（[DELETE操作](https://oreil.ly/5UfTB)），对于特定的Azure OpenAI资源以及现有的操作ID。如果您不使用此选项，图像将在24小时后自动删除。'
- en: '[Speech to text](https://oreil.ly/hKakE)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[语音到文本](https://oreil.ly/hKakE)'
- en: 'Based on the [Azure OpenAI Whisper model](https://oreil.ly/SJNcT), these APIs
    allow you create transcriptions from audio pieces, for a variety of languages
    and accents, with great performance and the possibility to combine it with other
    Azure OpenAI models. You can specify the input audio file, language, discussion
    style, output format (by default a JSON file), etc. This Azure OpenAI speech-to-text
    (S2T) feature has a limitation of 25 MB for the input audio file, but you can
    leverage the [batch transcription mode of Azure AI Speech](https://oreil.ly/NnMTz)
    (not Azure OpenAI, but the [Azure AI Speech services for voice ↔ text features](https://oreil.ly/-HLPL))
    to transcribe bigger files. The POST operation looks similar to the previous APIs:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Azure OpenAI Whisper模型（[Azure OpenAI Whisper模型](https://oreil.ly/SJNcT)），这些API允许您从音频片段创建转录，支持多种语言和口音，性能出色，并且可以与其他Azure
    OpenAI模型结合使用。您可以指定输入音频文件、语言、讨论风格、输出格式（默认为JSON文件）等。Azure OpenAI语音到文本（S2T）功能对输入音频文件的大小有限制，为25
    MB，但您可以使用Azure AI Speech的[批量转录模式](https://oreil.ly/NnMTz)（不是Azure OpenAI，而是[Azure
    AI Speech语音 ↔ 文本功能的服务](https://oreil.ly/-HLPL)）来转录更大的文件。POST操作看起来与之前的API类似：
- en: '[PRE7]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The corresponding curl request (illustrative example):'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 相应的curl请求（示例）：
- en: '[PRE8]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[Embeddings](https://oreil.ly/imKOS)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '[嵌入](https://oreil.ly/imKOS)'
- en: 'This API call allows you to generate embeddings from specific text inputs,
    from some of the architectures you will see in this chapter. The model and its
    specific input length will depend on [model availability](https://oreil.ly/gvAHr)
    at the time of your implementation. The POST operation is similar to the previous
    ones, and the dynamic is as simple as [requesting the embeddings](https://oreil.ly/xFJTh)
    for a text input and [obtaining a JSON response](https://oreil.ly/yYCuU) with
    the generated embeddings, for you to store (we will see several vector store/database
    options by the end of the chapter) and leverage them later:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 此API调用允许您从特定的文本输入生成嵌入，从您将在本章中看到的一些架构中。模型及其特定的输入长度将取决于您实现时的[模型可用性](https://oreil.ly/gvAHr)。POST操作与之前的类似，动态与请求文本输入的嵌入（[请求嵌入](https://oreil.ly/xFJTh)）和获取包含生成的嵌入的JSON响应（[获取JSON响应](https://oreil.ly/yYCuU)）一样简单，以便您存储（我们将在本章末尾看到几个向量存储/数据库选项）并在以后使用：
- en: '[PRE9]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'And the corresponding curl example:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以及相应的curl示例：
- en: '[PRE10]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[Fine-tuning](https://oreil.ly/1pqcT)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '[微调](https://oreil.ly/1pqcT)'
- en: As we reviewed at the beginning of this chapter, one of the implementation options
    includes the ability to fine-tune pre-built models with your specific, available
    information. We will see more details later in this chapter, but for now keep
    in mind that if you choose this option, there is a specific set of APIs that you
    can leverage to create, manage, explore, and delete new fine-tuning “jobs.” Also,
    you will handle your own input files for the fine-tuned models.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章开头所回顾的，实现选项之一包括使用您特定的、可用的信息微调预构建模型。我们将在本章后面看到更多细节，但到目前为止，请记住，如果您选择此选项，您可以使用一组特定的
    API 来创建、管理、探索和删除新的微调“作业”。此外，您将处理微调模型的输入文件。
- en: Other relevant APIs
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 其他相关 API
- en: 'Other relevant APIs include the following:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 其他相关 API 包括以下内容：
- en: '[Bing Search](https://oreil.ly/2yZuu)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '[必应搜索](https://oreil.ly/2yZuu)'
- en: The Bing Search API allows you to leverage Microsoft Bing’s search engine for
    your own development. You can extend the capabilities of your Azure OpenAI–enabled
    implementations with live search functionalities.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Bing Search API 允许您利用微软必应搜索引擎进行自己的开发。您可以通过实时搜索功能扩展您 Azure OpenAI 启用的实现的功能。
- en: '[Form Recognizer (currently known as Azure AI Document Intelligence)](https://oreil.ly/vxtJA)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[表单识别器（目前称为 Azure AI 文档智能）](https://oreil.ly/vxtJA)'
- en: This helps you transform information from forms and images into structured data.
    It includes advanced optical character recognition (OCR) functionalities that
    will support your Azure OpenAI development with specific data sources such as
    PDF or DOC files.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这有助于您将表单和图像中的信息转换为结构化数据。它包括高级光学字符识别 (OCR) 功能，这将支持您使用特定数据源（如 PDF 或 DOC 文件）进行
    Azure OpenAI 开发。
- en: '[Azure AI Search (previously known as Azure Cognitive Search)](https://oreil.ly/wp6r8)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '[Azure AI Search（之前称为 Azure 认知搜索）](https://oreil.ly/wp6r8)'
- en: One of the most important elements for RAG architectures, for both vectors and
    index approaches.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 架构中最重要的元素之一，适用于向量和索引方法。
- en: In addition to these APIs, there is an Azure [OpenAI library for .NET developers](https://oreil.ly/9XMBN)
    and the [OpenAI library for Python](https://oreil.ly/-cwGH), which essentially
    replicates the features of the official API for a .NET development environment.
    It provides an interface with the rest of the Azure SDK ecosystem, and it facilitates
    the connection to Azure OpenAI resources or to non–Azure OpenAI endpoints.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些 API，还有为 .NET 开发者提供的 Azure [OpenAI 库](https://oreil.ly/9XMBN) 和 [Python
    的 OpenAI 库](https://oreil.ly/-cwGH)，它们本质上复制了官方 API 在 .NET 开发环境中的功能。它提供了一个与 Azure
    SDK 生态系统其余部分的接口，并简化了与 Azure OpenAI 资源或非 Azure OpenAI 终端的连接。
- en: 'This set of visual and development interfaces are your toolkit for most of
    the Azure OpenAI implementations out there. They are rapidly evolving, but the
    links to the official documentation will help you access updated information any
    time. Now, before moving on to the implementation approaches, let’s take a look
    at a powerful feature that will enable your generative AI systems to interact
    with other external APIs: function calling.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这套视觉和开发接口是大多数 Azure OpenAI 实现的工具包。它们正在快速发展，但官方文档的链接将帮助您随时获取更新信息。现在，在继续到实现方法之前，让我们看看一个强大的功能，它将使您的生成式
    AI 系统能够与其他外部 API 交互：函数调用。
- en: 'Interoperability features: Function calling and “JSONization”'
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 互操作性功能：函数调用和“JSON化”
- en: 'The [Azure OpenAI function calling](https://oreil.ly/bQdsv) option is a way
    to leverage language models to generate API calls and structure data outputs based
    on a specific target format. Technically, it is one of the options within the
    Chat Completion API—the [function](https://oreil.ly/WLv1g) chat role. You can
    see [several samples](https://oreil.ly/0nhYM) on how to use this functionality,
    but it essentially relies on the following steps:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[Azure OpenAI 函数调用](https://oreil.ly/bQdsv)选项是利用语言模型生成 API 调用并根据特定目标格式结构化数据输出的方式。技术上，它是
    Chat Completion API 中的一个选项——[函数](https://oreil.ly/WLv1g)聊天角色。您可以在[几个示例](https://oreil.ly/0nhYM)中看到如何使用此功能，但本质上它依赖于以下步骤：'
- en: Calling the Chat Completions API, including the functions (based on the official
    [FunctionDefinition format](https://oreil.ly/5Q-8c)) and the user’s input
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用 Chat Completions API，包括基于官方 [FunctionDefinition 格式](https://oreil.ly/5Q-8c)
    的函数和用户的输入
- en: Using the model’s chat response to call your API or function
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型的聊天响应来调用您的 API 或函数
- en: Calling the Chat Completions API again, including the response from your function,
    to get a final response
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次调用Chat Completions API，包括您函数的响应，以获取最终响应
- en: This is a relatively new functionality, so you can expect some feature improvements
    over time. You can always check the [official documentation](https://oreil.ly/UAYNH)
    to get the latest details and advice. Additionally, you can also explore the [JSON
    mode](https://oreil.ly/Fi3-l) for Azure OpenAI, as it allows you to get a JSON
    object from the Chat Completions API answer, a powerful feature for interoperability
    purposes.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相对较新的功能，因此您可以期待随着时间的推移会有一些功能改进。您始终可以检查[官方文档](https://oreil.ly/UAYNH)以获取最新细节和建议。此外，您还可以探索Azure
    OpenAI的[JSON模式](https://oreil.ly/Fi3-l)，因为它允许您从Chat Completions API的答案中获取JSON对象，这对于互操作性来说是一个强大的功能。
- en: This completes the first part of this section. You have learned about the knowledge
    domains, how to leverage different building blocks to improve and increase the
    level of knowledge of your generative AI solutions, and the availability tools
    you will use for implementation. Now, we will move to the next part of this chapter,
    in which we will explore some of the most relevant development approaches, based
    on the industry’s best practices. Let’s get started.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了本节的第一部分。您已经了解了知识领域，如何利用不同的构建块来提高和增加您生成式AI解决方案的知识水平，以及您将用于实施的可用工具。现在，我们将进入本章的下一部分，我们将探讨一些最相关的开发方法，基于行业的最佳实践。让我们开始吧。
- en: Potential Implementation Approaches
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可能的实施方法
- en: There are several ways to implement generative AI applications with Azure OpenAI
    Service. The type of implementations you use will mostly depend on your specific
    use case, as well as the technical and financial context for adoption. This means
    there are situations where the most expensive option is not always the best, or
    other options may have limitations, such as when we don’t have specific data besides
    our website, etc. Let’s explore the primary implementation types, based on the
    customization levels of [Figure 3-16](#fig_16_implementation_approaches_with_azure_openai).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Azure OpenAI服务实施生成式AI应用有几种方法。您使用的实施类型将主要取决于您的具体用例，以及采用的技术和财务背景。这意味着在某些情况下，最昂贵的选项并不总是最好的，或者其他选项可能有限制，例如当我们除了我们的网站之外没有具体数据时等。让我们根据[图3-16](#fig_16_implementation_approaches_with_azure_openai)的定制级别探索主要的实施类型。
- en: '![](assets/aoas_0316.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0316.png)'
- en: Figure 3-16\. Implementation approaches with Azure OpenAI Service
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-16\. 使用Azure OpenAI服务的实施方法
- en: As you can see from the figure, you can customize a model by preparing a good
    meta-prompt, adjusting technical parameters, providing one or a few “shots” as
    examples to guide the model, and implementing fine-tuning and/or grounding techniques.
    The next sections will go into the details of how to do all of this.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从图中所见，您可以通过准备一个好的元提示、调整技术参数、提供一或几个“示例”来引导模型，以及实施微调和/或归一化技术来自定义一个模型。接下来的几节将详细介绍如何完成所有这些操作。
- en: Basic Azure ChatGPT instance
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本的Azure ChatGPT实例
- en: A basic, private GPT type of instance is the simplest kind of implementation,
    and one of the most popular Azure OpenAI cases nowadays. When companies want to
    have a private “ChatGPT” for their employees, this is the answer. It keeps your
    own data safe and private and deploys the instance within your own cloud infrastructure.
    It’s one of the favorite options for internal use with employees.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 一种基本的、私有的GPT类型的实例是最简单的实施方式，也是目前Azure OpenAI最受欢迎的案例之一。当公司想要为员工提供一个私人的“ChatGPT”时，这就是答案。它保护您的数据安全并私有，并在您自己的云基础设施中部署实例。这是内部员工使用中最受欢迎的选项之一。
- en: 'The deployment process is relatively simple:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 部署过程相对简单：
- en: Within your Azure OpenAI Studio, deploy a GPT-3.5 Turbo, GPT-4, GPT-4 Turbo,
    or GPT-4o model instance. This type of model is technically similar to what ChatGPT
    is, and it will deliver that level of performance. Remember to choose the specific
    geographic region that is closest to you.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的Azure OpenAI Studio中部署一个GPT-3.5 Turbo、GPT-4、GPT-4 Turbo或GPT-4o模型实例。这种模型在技术上与ChatGPT相似，并将提供相同级别的性能。请记住选择最接近您的具体地理位置。
- en: Once you have created the resource, go to the visual playground. There, you
    will see a left menu with the option “Chat.”
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您创建了资源，请转到可视化游乐场。在那里，您将看到一个左侧菜单，其中包含“聊天”选项。
- en: Once there, you can prepare the [system message](https://oreil.ly/OmKQO) / meta-prompt
    to contextualize the chatbot by telling it something like “You are an AI assistant
    for company X, to answer questions from the employees” (internal use) or “You
    are an AI assistant for company X with website Y. If anyone asks something that
    is not related to this topic, say you cannot answer” (for clients).
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦到达那里，您可以为聊天机器人准备[系统消息](https://oreil.ly/OmKQO) / 元提示，通过告诉它诸如“您是公司 X 的 AI 助手，用于回答员工的问题”（内部使用）或“您是公司
    X 的 AI 助手，网站为 Y。如果有人问与此话题无关的问题，请说您无法回答”（面向客户）之类的信息来上下文化聊天机器人。
- en: You can also customize parameters such as the max length of the answers or the
    temperature of the messages, which is a metric between 0 and 1 to define the level
    of creativity of the model.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您还可以自定义参数，例如答案的最大长度或消息的温度，这是一个介于 0 和 1 之间的度量，用于定义模型的创造力水平。
- en: Once you have tested performance and you are ready to deploy the model, you
    can come back to the resource page (Azure portal) and find both the endpoint and
    the keys for that specific resource. That page contains examples of code to for
    calling the APIs.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦您测试了性能并且准备部署模型，您就可以回到资源页面（Azure 门户）并找到该特定资源的端点和密钥。该页面包含调用 API 的代码示例。
- en: The end-to-end architecture ([Figure 3-17](#fig_17_simplified_azure_chatgpt_architecture))
    is pretty simple—a pre-deployed model that we can directly consume from our applications,
    based on the existing endpoints and APIs.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 端到端架构（[图 3-17](#fig_17_simplified_azure_chatgpt_architecture)）相当简单——一个预先部署的模型，我们可以直接从我们的应用程序中消费，基于现有的端点和
    API。
- en: '![](assets/aoas_0317.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0317.png)'
- en: Figure 3-17\. Simplified Azure ChatGPT architecture
  id: totrans-232
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-17\. 简化的 Azure ChatGPT 架构
- en: This type of implementation is good enough for internal company cases where
    you don’t require any customization based on private data, for example, internal
    chatbots for employee productivity based on general internet information, or search
    engines for intranet sites. For the rest of the cases where there is some custom
    data involved, we will explore other options. Let’s dig into the first of them
    next.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '这种类型的实现对于不需要基于私有数据的任何定制的内部公司案例来说已经足够好了，例如，基于一般互联网信息的员工生产力内部聊天机器人或内部网站搜索引擎。对于涉及一些定制数据的其他案例，我们将探索其他选项。让我们深入了解其中的第一个选项。 '
- en: Minimal customization with one- or few-shot learning
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用单次或少量学习进行最小化定制
- en: Besides the baseline model, and system message/meta-prompt and parameters customization,
    there is an option to perform *one- or few-shot learning*, which means providing
    the LLM with examples of discussions based on the expected output for a specific
    topic. This is a useful and simple option for small adjustments, and it relies
    on a very similar architecture to the previous one, with relatively light changes.
    The main difference when compared to the previous approach is the inclusion of
    one or few examples to guide the LLM before starting to use it ([Figure 3-18](#fig_18_one_few_shot_learning_architecture)).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基线模型、系统消息/元提示和参数定制之外，还有一个选项进行**单次或少量学习**，这意味着向 LLM 提供基于特定主题预期输出的讨论示例。这是一个用于小调整的有用且简单的选项，并且它依赖于与之前非常相似的架构，变化相对较小。与之前的方法相比，主要区别在于在开始使用之前包含一个或几个示例来引导
    LLM（[图 3-18](#fig_18_one_few_shot_learning_architecture)）。
- en: '![](assets/aoas_0318.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0318.png)'
- en: Figure 3-18\. One/few-shot learning architecture
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-18\. 单次/少量学习架构
- en: 'The one-shot/few-shot learning process can be achieved in several ways:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 单次/少量学习过程可以通过几种方式实现：
- en: Via APIs (code)
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 API（代码）
- en: Use the Chat Completions API with GPT-4 and other models that are designed to
    take input formatted in a chat-like transcript. You can provide conversational
    examples that are used by the model for in-context learning.
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GPT-4 和其他设计为接受类似聊天记录格式的输入的 Chat Completions API。您可以为模型提供用于上下文学习的对话示例。
- en: Use the Completions API with the GPT-3 models, which can take a string of text
    with no specific format rules. You can provide a set of training examples as part
    of the prompt to give additional context to the model.
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GPT-3 模型的 Completions API，它可以接受没有特定格式规则的文本字符串。您可以在提示中提供一组训练示例，以向模型提供额外的上下文。
- en: Via playground (visual)
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过游乐场（视觉）
- en: Use the Chat playground to interact with GPT-4, GPT-4o, etc. You can add few-shot
    examples in the chat transcript and see how the model responds.
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Chat 游乐场与 GPT-4、GPT-4o 等交互。您可以在聊天记录中添加少量示例，并查看模型如何响应。
- en: Use the Completions playground to interact with the GPT-x models. You can write
    your prompt with few-shot examples and see how the model completes it.
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Completions playground 与 GPT-x 模型进行交互。您可以用少量示例编写提示并查看模型如何完成它。
- en: Overall, all these customizations are intended to improve the performance of
    the model versus a regular vanilla “ChatGPT” implementation like the one we previously
    explored, but there are ways to retrain the model in a deeper way, like the one
    we will explore next.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，所有这些定制都是为了提高模型相对于我们之前探索的常规“ChatGPT”实现（如“ChatGPT”）的性能，但存在更深入地重新训练模型的方法，我们将在下一部分探讨。
- en: Fine-tuned GPT models
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微调后的 GPT 模型
- en: 'As mentioned earlier in the chapter, there are different ways to customize
    an LLM to adjust its knowledge scope. Most of them rely on the orchestration/combination
    of the LLM with other knowledge pieces, without really combining the data sources
    (i.e., grounding). In this case, we will focus on the only way to “retrain” an
    Azure OpenAI model with custom company data: the [Azure OpenAI Service fine-tuning
    feature](https://oreil.ly/T0GP8).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章前面所述，有不同方式来定制一个大型语言模型（LLM）以调整其知识范围。其中大部分依赖于将 LLM 与其他知识片段的编排/组合，而没有真正结合数据源（即，扎根）。在这种情况下，我们将专注于唯一一种使用定制公司数据“重新训练”Azure
    OpenAI 模型的途径：[Azure OpenAI 服务微调功能](https://oreil.ly/T0GP8)。
- en: This approach may have some advantages for companies with very specific and
    valuable data intellectual property, but its cost (you will need to add hosting
    cost to the regular API calls for the fine-tuning process) and technical complexity
    will probably lead you (and most of the adopters out there) to other kinds of
    grounding approaches with better performance/cost balance.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可能对具有非常具体和有价值的数据知识产权的公司有一些优势，但其成本（您需要将托管成本添加到常规 API 调用以进行微调过程）和技术复杂性可能会让您（以及大多数采用者）转向其他具有更好性能/成本平衡的扎根方法。
- en: Also, the fine-tuning feature relies on a very special kind of training process.
    It is not the regular label-based training process you can do, for example, in
    classification tasks with traditional AI models. We are talking about a new kind
    of supervised process that leverages Azure OpenAI’s prompting system to inject
    information based on the [JSON Lines (JSONL) file format](https://oreil.ly/SdBph).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，微调功能依赖于一种非常特殊的训练过程。它不是您可以在例如使用传统 AI 模型进行分类任务时进行的常规基于标签的训练过程。我们谈论的是一种新的监督过程，它利用
    Azure OpenAI 的提示系统根据 [JSON Lines (JSONL) 文件格式](https://oreil.ly/SdBph)注入信息。
- en: 'For example, with GPT-3.5 Turbo, you will leverage the system and user roles
    to reeducate the model:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用 GPT-3.5 Turbo，您将利用系统和用户角色来重新教育模型：
- en: '[PRE11]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Other legacy models such as DaVinci require a prompt/completion format based
    on a question-answer logic:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 其他如 DaVinci 这样的旧模型需要基于问答逻辑的提示/完成格式：
- en: '[PRE12]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This new way to inject data and knowledge allows us to reeducate the model in
    a very granular manner, but it is a complex way to do so. You can see the overall
    architecture in [Figure 3-19](#fig_19_azure_openai_fine_tuning_architecture),
    in which you will basically customize the model, based on a fine-tuning process
    that relies on specific organizational data.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这种注入数据和知识的新方法允许我们以非常细粒度的方式重新教育模型，但这是一个复杂的过程。您可以在 [图 3-19](#fig_19_azure_openai_fine_tuning_architecture)
    中看到整体架构，其中您将基本上根据依赖于特定组织数据的微调过程来定制模型。
- en: '![](assets/aoas_0319.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0319.png)'
- en: Figure 3-19\. Azure OpenAI fine-tuning architecture
  id: totrans-256
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-19\. Azure OpenAI 微调架构
- en: 'The steps to perform *fine-tuning* with Azure OpenAI Service are:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure OpenAI 服务中执行**微调**的步骤如下：
- en: '*Prepare your dataset* in JSONL format. For recent models such as GPT-3.5 Turbo,
    GPT-4, and GPT-4o, you will leverage the Chat Completions API structure for system
    and user messages.'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*准备您的数据集*为 JSONL 格式。对于最近发布的模型，如 GPT-3.5 Turbo、GPT-4 和 GPT-4o，您将利用 Chat Completions
    API 结构来处理系统和用户消息。'
- en: Launch the *custom model wizard* from Azure OpenAI Studio, as shown in [Figure 3-20](#fig_20_azure_openai_custom_model_wizard),
    to train your new customized model.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Azure OpenAI Studio 中启动*自定义模型向导*，如图 [图 3-20](#fig_20_azure_openai_custom_model_wizard)
    所示，以训练您的新定制模型。
- en: '![](assets/aoas_0320.png)'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](assets/aoas_0320.png)'
- en: 'Figure 3-20\. Azure OpenAI: custom model wizard'
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-20\. Azure OpenAI：自定义模型向导
- en: '*Select a base model* (e.g., GPT-3.5 Turbo), choosing your training data and,
    optionally, your validation data to evaluate model performance. Those datasets
    are the JSON files you previously prepared.'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*选择一个基础模型*（例如，GPT-3.5 Turbo），选择您的训练数据以及可选的验证数据来评估模型性能。这些数据集是您之前准备好的 JSON 文件。'
- en: Review your choices and *launch the training* of the new customized model. Check
    the status of your customized model and wait for the training to finish.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 审查您的选择并*启动*新自定义模型的训练。检查您自定义模型的状态，等待训练完成。
- en: '*Deploy your customized model* for use in an application or service, via APIs.'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*部署您的自定义模型*以在应用程序或服务中使用，通过API进行。'
- en: All these options can work [depending on the type of application](https://oreil.ly/cK_7b)
    and the intended scope of the model customization. However, there are ways to
    combine the LLM with internal data sources, from which you can extract knowledge,
    and then refer to that information from the Azure OpenAI completion and chat completion
    models. This is what we call [RAG](https://oreil.ly/26QYs) or grounding, and there
    are different ways to implement it. The next sections contain different grounding
    alternatives.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些选项都可以根据应用程序的类型[（https://oreil.ly/cK_7b）]和模型定制的预期范围工作。然而，有方法可以将LLM与内部数据源相结合，从中提取知识，然后从Azure
    OpenAI的完成和聊天完成模型中引用该信息。我们称之为[RAG](https://oreil.ly/26QYs)或扎根，有不同的实现方式。下一节包含不同的扎根替代方案。
- en: Embedding-based grounding
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于嵌入的扎根
- en: As you now know from earlier chapters, embeddings are mathematical representations
    of text-based information as vectors in a vector space, and an alternative and/or
    complement to the traditional index-based approach. These embeddings are stored
    and managed as mathematical vectors that represent distances between topics. This
    means if we are looking for information about animals and we have a vectorized
    knowledge base that includes animal-related topics, we can recover the Top-k answers
    (i.e., the most relevant “K” number of pieces of information).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您从前面的章节中了解到的，嵌入是文本信息在向量空间中的数学表示，是传统基于索引方法的替代品和/或补充。这些嵌入作为表示主题之间距离的数学向量存储和管理。这意味着如果我们正在寻找有关动物的信息，并且我们有一个包含与动物相关主题的向量化知识库，我们可以恢复Top-k答案（即最相关的“K”数量信息）。
- en: You can use the Azure OpenAI embeddings API to generate vector representations
    of text that capture the semantic meaning and similarity of the text. Some possible
    use cases for embeddings are document search, text classification, clustering,
    or text similarity.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Azure OpenAI嵌入API生成捕获文本语义意义和相似性的文本向量表示。嵌入的一些可能用例包括文档搜索、文本分类、聚类或文本相似度。
- en: 'The end-to-end process to create and use an embedding-based system is aligned
    with what you have seen thus far in this chapter. From an Azure OpenAI perspective,
    the steps are as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 创建和使用基于嵌入的系统端到端过程与您在本章中迄今为止所看到的内容一致。从Azure OpenAI的角度来看，步骤如下：
- en: '*Select the knowledge base* that contains the information that will complement
    the baseline LLM knowledge domain. This may include PDF, DOC, PPT, TXT, and other
    file formats. In Azure, you may store that information via Azure Blob Storage
    or Azure Data Lake Gen2\. Keep in mind that if your files are similar to any general
    information that may be available on the internet (for example, public descriptions
    of industry concepts), you probably don’t need to ground them. However, if you
    have very specific files with information on how to answer questions, or perform
    internal tasks, those may be good candidates for embeddings generation.'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*选择包含将补充基线LLM知识域的信息的知识库*。这可能包括PDF、DOC、PPT、TXT和其他文件格式。在Azure中，您可以通过Azure Blob
    Storage或Azure Data Lake Gen2存储这些信息。请记住，如果您的文件与互联网上可能可用的任何一般信息（例如，行业概念的公共描述）相似，您可能不需要将它们扎根。然而，如果您有非常具体的文件，其中包含如何回答问题或执行内部任务的信息，这些可能是生成嵌入的良好候选者。'
- en: '*Choose and deploy your database/vector store*. By the end of this chapter,
    you will see all available options for implementation in Azure with Azure OpenAI–generated
    embeddings.'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*选择并部署您的数据库/向量存储*。到本章结束时，您将看到所有在Azure中使用Azure OpenAI生成的嵌入进行实现的可用选项。'
- en: '*Prepare the input dataset*. This includes two different steps:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*准备输入数据集*。这包括两个不同的步骤：'
- en: '*Extract the information* from your documents. For example, you can use Azure
    Document Intelligence/Form Recognizer to extract text from your PDFs with the
    OCR feature. You can also use other non-Azure tools.'
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*从您的文档中提取信息*。例如，您可以使用Azure Document Intelligence/表单识别器使用OCR功能从您的PDF中提取文本。您还可以使用其他非Azure工具。'
- en: '*Split the information*. For this to work, it is important to keep in mind
    the [embeddings model token limit](https://oreil.ly/SQSGw) (e.g., 8K for Ada model
    version 2) to prepare the input without exceeding the limit (you can use [OpenAI’s
    tokenizer tool](https://oreil.ly/DDQHG) to understand the extent of what 8K means
    in terms of document length). This means you will need to make one API call for
    each of the limited-size blocks you have prepared before, or leverage [chunking
    techniques](https://oreil.ly/3DHfa) to split and handle larger documents.'
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*分割信息*。为了使这可行，重要的是要记住[嵌入模型令牌限制](https://oreil.ly/SQSGw)（例如，Ada 模型版本 2 的 8K），以准备输入而不超过限制（你可以使用[OpenAI
    的分词工具](https://oreil.ly/DDQHG)来了解 8K 在文档长度方面的含义）。这意味着你将需要为之前准备的每个有限大小的块进行一次 API
    调用，或者利用[分块技术](https://oreil.ly/3DHfa)来分割和处理更大的文档。'
- en: '*Leverage the Azure OpenAI [embeddings models](https://oreil.ly/gvAHr)*. Use
    the API operations you saw earlier in this chapter and get the mathematical vectors
    from the API response. *Store the vectors* within the chosen vector store.'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*利用 Azure OpenAI [嵌入模型](https://oreil.ly/gvAHr)*。使用本章前面看到的 API 操作，并从 API 响应中获取数学向量。*存储这些向量*到所选的向量存储中。'
- en: Any time you want to find information from your knowledge base, or if you want
    to leverage it from any chat or search application, you will need to *generate
    the embeddings of the question itself*, then perform the search against the vector
    search. Keep in mind that you will need to leverage the same model (e.g., Ada
    version 2) for both your knowledge base and the question. You can send the result
    of the search, with the Top-k results, to the chat or search application, directly
    or by including it as content for the answer of the completion.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无论何时你想从你的知识库中查找信息，或者如果你想从任何聊天或搜索应用中利用它，你都需要*生成问题的嵌入表示*，然后对向量搜索进行搜索。请记住，你需要利用与你的知识库和问题相同的模型（例如，Ada
    版本 2）。你可以直接发送搜索结果，包括 Top-k 结果到聊天或搜索应用，或者将其作为回答内容的一部分。
- en: 'This process is similar for other embeddings and conversation models (for example,
    those that are available via Azure AI Studio’s model catalog and Hugging Face),
    and the high-level architecture includes the elements you can see in [Figure 3-21](#fig_21_embedding_based_grounding_architecture):
    basically, the baseline Azure OpenAI model gets complemented with the internal
    knowledge base that contains PDFs, Word docs, etc. Instead of retraining/fine-tuning
    the model, we just combine it with that knowledge base so it can find similarities
    between the users’ questions and the information contained within the data sources.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 此过程与其他嵌入和对话模型（例如，通过 Azure AI Studio 的模型目录和 Hugging Face 可用的模型）类似，高级架构包括你在[图
    3-21](#fig_21_embedding_based_grounding_architecture)中可以看到的元素：基本上，基本的 Azure OpenAI
    模型通过包含 PDF、Word 文档等的内部知识库得到补充。我们不是重新训练/微调模型，而是将其与知识库结合，以便它可以在用户的问题和数据源中包含的信息之间找到相似性。
- en: '![](assets/aoas_0321.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_0321.png)'
- en: Figure 3-21\. Embedding-based grounding architecture
  id: totrans-279
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-21\. 基于嵌入的定位架构
- en: You can find more information and code examples on [how to create embeddings](https://oreil.ly/8Duc8)
    from the official Microsoft documentation (in addition to the API definitions
    we covered earlier in this chapter).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在官方微软文档中找到更多信息和代码示例，了解如何[创建嵌入](https://oreil.ly/8Duc8)（除了本章前面提到的 API 定义）。
- en: Additionally, there is [one official Microsoft accelerator](https://oreil.ly/iG5UU)
    for this type of implementation that you can leverage during the development phase.
    There are several deployment and storage options. Feel free to explore the code
    to see the API call details.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有[一个官方的微软加速器](https://oreil.ly/iG5UU)可用于此类实现，你可以在开发阶段利用它。有几种部署和存储选项。请随意探索代码以查看
    API 调用细节。
- en: Document indexing/retrieval-based grounding
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于文档索引/检索的定位
- en: The document indexing/retrieval-based grounding approach is an alternative to
    the embedding-based approach. In this case, we will not generate mathematical
    vectors. Instead, we will generate indexes of specific documents, so Azure OpenAI
    Service can find the information from those sources and include it as part of
    its answers. For that purpose, we will also use Azure Cognitive Search, which
    is a service that allows you to index, understand, and retrieve relevant data
    from a knowledge base or a collection of documents.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 基于文档索引/检索的 grounding 方法是基于嵌入方法的替代方案。在这种情况下，我们不会生成数学向量。相反，我们将生成特定文档的索引，这样 Azure
    OpenAI 服务就可以从这些来源找到信息，并将其作为其答案的一部分。为此，我们还将使用 Azure Cognitive Search，这是一种允许您从知识库或文档集合中索引、理解和检索相关数据的服务。
- en: The combination of both services enables powerful chatbot applications that
    can communicate with users in natural language and provide intuitive and personalized
    interactions, based on specific data from the organization. Much like the embedding-based
    approach, there is an official [Microsoft accelerator](https://oreil.ly/JNWAz)
    available for you to deploy your first proof of concept, in addition to a second
    one called [GPT-RAG](https://oreil.ly/Q5NK9) from the Microsoft Argentina team,
    with some additional functionalities for bigger implementations. You can explore
    both to see updated details and implementation approaches with Azure OpenAI and
    Azure Cognitive Search. You can also see the high-level architecture of the key
    building blocks in [Figure 3-22](#fig_22_retrieval_based_grounding_architecture).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种服务的结合使得强大的聊天机器人应用程序成为可能，这些应用程序可以用自然语言与用户交流，并基于组织的具体数据提供直观和个性化的交互。与基于嵌入的方法类似，官方的[Microsoft
    加速器](https://oreil.ly/JNWAz)可供您部署您的第一个概念验证，此外，还有来自微软阿根廷团队的第二个名为 [GPT-RAG](https://oreil.ly/Q5NK9)
    的加速器，它为更大的实现提供了一些额外的功能。您可以探索这两个选项，以查看 Azure OpenAI 和 Azure Cognitive Search 的更新细节和实现方法。您还可以在[图
    3-22](#fig_22_retrieval_based_grounding_architecture) 中查看关键构建块的高级架构。
- en: '![](assets/aoas_0322.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_0322.png)'
- en: Figure 3-22\. Retrieval-based grounding architecture
  id: totrans-286
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-22\. 基于检索的 grounding 架构
- en: The main difference when compared to the embedding-based approach is that instead
    of generating embeddings for both the knowledge base and the user question, you
    will just perform a search against the Azure AI Search engine (or any equivalent,
    as we will explore in [Chapter 4](ch04.html#additional_cloud_and_ai_capabilities)
    for vector databases).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于嵌入的方法相比，主要区别在于，您不会为知识库和用户问题生成嵌入，而是只需对 Azure AI Search 引擎（或任何等效的，我们将在[第 4
    章](ch04.html#additional_cloud_and_ai_capabilities)中探讨向量数据库）进行搜索。
- en: You may see this option as something a bit simpler than the embeddings approach,
    and a better fit for applications where you need to find the source of information
    (and even provide a link to the original document as part of the answer); embeddings
    can potentially handle bigger datasets and deliver better performance. However,
    it really depends on the specific dataset and its knowledge scope and file format
    as well as the envisioned use case, so my recommendation is for you to try both
    options and evaluate the one that delivers best results from a user perspective.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会认为这个选项比嵌入方法简单一些，更适合需要找到信息来源（甚至可以将链接到原始文档作为答案的一部分）的应用程序；嵌入可以处理更大的数据集并实现更好的性能。然而，这实际上取决于特定的数据集及其知识范围和文件格式，以及预期的用例，因此我的建议是您尝试这两种选项，并从用户的角度评估哪种选项能提供最佳结果。
- en: Hybrid search–based grounding
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混合搜索基础 grounding
- en: There are newer implementation approaches based on [hybrid search techniques](https://oreil.ly/mwZPy).
    Concretely, hybrid search combines vector embeddings and doc retrieval capabilities.
    The [hybrid search feature](https://oreil.ly/c2W8A) from Azure AI Search offers
    that combination, plus a [reranking technique](https://oreil.ly/S7b8p) that produces
    the final result, with better performance than the previously mentioned grounding
    techniques. Now, let’s explore some additional grounding options that can add
    more knowledge scope to your generative AI applications.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 基于混合搜索技术的[新实现方法](https://oreil.ly/mwZPy)正在出现。具体来说，混合搜索结合了向量嵌入和文档检索能力。Azure AI
    Search 的[混合搜索功能](https://oreil.ly/c2W8A)提供了这种组合，以及一个[重排序技术](https://oreil.ly/S7b8p)，该技术可以产生最终结果，其性能优于之前提到的
    grounding 技术。现在，让我们探索一些额外的 grounding 选项，这些选项可以为您的生成式 AI 应用程序添加更多的知识范围。
- en: Other grounding techniques
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他基础技术
- en: 'We have explored several fine-tuning and grounding techniques, mainly based
    on text information from different sources. But what happens if you want to leverage
    other kinds of data? Or if the required information can be found only via live
    internet results? Here are some other grounding techniques you may want to explore:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探索了多种微调和根植技术，主要基于来自不同来源的文本信息。但如果你想要利用其他类型的数据呢？或者如果所需信息只能通过实时网络结果找到？这里有一些你可能想要探索的其他根植技术：
- en: LLM + web results
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: LLM + 网络结果
- en: This approach relies on the [Bing Web Search API](https://oreil.ly/qud-9) to
    extend the knowledge scope of Azure OpenAI Service models. As you may know, all
    LLMs are based on training datasets that go up to a specific date (e.g., initial
    Azure OpenAI models were updated with data up to 2021). If you need updated information,
    you can use the Bing Web Search API to find web pages, images, videos, news, etc.,
    or use it to create a custom search instance that filters web results based on
    the criteria. The result from the API can then be used by Azure OpenAI to return
    an answer based on that information.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法依赖于[必应网络搜索API](https://oreil.ly/qud-9)来扩展Azure OpenAI服务模型的认知范围。正如您可能知道的，所有LLM都是基于截至特定日期的训练数据集（例如，最初的Azure
    OpenAI模型更新到2021年的数据）。如果您需要更新信息，可以使用必应网络搜索API查找网页、图片、视频、新闻等，或者用它来创建一个自定义搜索实例，根据标准过滤网络结果。然后，API的结果可以由Azure
    OpenAI使用，根据该信息返回答案。
- en: LLM + tabular data and/or databases
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: LLM + 表格数据和/或数据库
- en: Similar to other sources, tabular data (e.g., Excel and CSV files) and regular
    SQL-type databases (e.g., SQL Server, Azure SQL, PostgreSQL) can be good grounding
    sources. You can develop what the industry calls Database Copilots to allow end
    users to query information without any complex SQL syntax, just natural language–based
    prompts. Or you can leverage it for [other data exploration](https://oreil.ly/s3snz)
    topics, such as exploratory data analysis or root-case analysis.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他来源类似，表格数据（例如，Excel和CSV文件）和常规SQL类型数据库（例如，SQL Server、Azure SQL、PostgreSQL）可以作为良好的根植来源。您可以开发行业所称的数据库协同助手，允许最终用户查询信息而无需任何复杂的SQL语法，只需基于自然语言的提示。或者，您可以利用它进行[其他数据探索](https://oreil.ly/s3snz)主题，例如探索性数据分析或根本原因分析。
- en: Just as with the other previous grounding options, there is an [official Microsoft
    accelerator](https://oreil.ly/eFneC) that combines these grounding techniques,
    with specific code samples and updated implementations.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 就像其他之前的根植选项一样，有一个[官方微软加速器](https://oreil.ly/eFneC)，它结合了这些根植技术，包括具体的代码示例和更新后的实现。
- en: At the end of the day, each implementation approach (baseline, fine-tuned, or
    grounding based) serves a different purpose, but the next section is a summarized
    guide for you to understand the pros and cons of each one, so you can make the
    most informed decision and create your generative AI applications with Azure OpenAI
    with the best balance of performance, cost, and technical complexity.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，每种实现方法（基线、微调或基于根植）都服务于不同的目的，但下一节为您提供了一个总结性指南，以了解每种方法的优缺点，以便您做出最明智的决定，并使用Azure
    OpenAI创建性能、成本和技术复杂度最佳平衡的生成式AI应用。
- en: Approach Comparison and Final Recommendation
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法比较和最终推荐
- en: There is not a single right answer to the question, “Which approach should I
    use for my generative AI implementation?” It really depends on the use case, type
    and volume of available data, existing IT architectures, available budget and
    resources, etc. Again, there is no right answer, and the choice relies for now
    on experimentation and performance testing.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 对于“我应该使用哪种方法进行我的生成式AI实现？”这个问题，并没有一个唯一的正确答案。这实际上取决于用例、可用数据的类型和数量、现有的IT架构、可用预算和资源等。再次强调，没有正确答案，选择目前依赖于实验和性能测试。
- en: '[Table 3-1](#table-3-1) shows the general pros and cons of the implementation
    approaches.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-1](#table-3-1) 展示了实现方法的优缺点。'
- en: Table 3-1\. Comparison of implementation approaches with Azure OpenAI Service
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-1\. Azure OpenAI服务的实现方法比较
- en: '|  | Approach | Pros | Cons |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '|  | 方法 | 优点 | 缺点 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1 | Basic ChatGPT-type instance (vanilla, private) |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 基本ChatGPT类型实例（原味、私有） |'
- en: Relatively simple and quick to deploy
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相对简单且快速部署
- en: Good option for internal (employee) use cases
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于内部（员工）用例的好选择
- en: Available via Azure OpenAI’s visual playground
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可通过Azure OpenAI的视觉游乐场获取
- en: Option to define the topic scope based on URLs, by leveraging the system message
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可根据URL定义主题范围，通过利用系统消息
- en: '|'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Lack of updated data
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏更新数据
- en: Very limited for client-side applications
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于客户端应用非常有限
- en: Higher risk of model hallucination
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型幻觉风险更高
- en: '|'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 2 | Examples with one-shot/few-shot learning |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 使用单次/少次学习示例 |'
- en: Easy to implement
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易实现
- en: Good option to adapt system behavior based on specific pieces of knowledge from
    your company
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据公司具体知识调整系统行为的好选择
- en: Available via Azure OpenAI’s visual playground
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Azure OpenAI的视觉游乐场提供
- en: '|'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Lack of updated data
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏更新数据
- en: Very limited for client-side applications
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于客户端应用非常有限
- en: Higher risk of model hallucination
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型幻觉风险更高
- en: '|'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 3 | Fine-tuning |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 微调 |'
- en: Good to fine-tune an existing model with specific company data
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用特定公司数据微调现有模型是个不错的选择
- en: Leverages mature product features
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用成熟的产品功能
- en: '|'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Complex to prepare input data for both fine-tuning and few-shot learning
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备输入数据以进行微调和少样本学习都较为复杂
- en: Increased cost for fine-tuned models
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调模型的成本增加
- en: '|'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 4 | Embedding-based grounding (vectors with Azure AI Search) |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 基于嵌入的定位（使用Azure AI Search的向量） |'
- en: Great for customization without requiring fine-tuning
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无需微调即可进行定制的优秀选择
- en: Good fit for large amounts of data
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于大量数据
- en: Easy use of embeddings APIs
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易使用嵌入API
- en: '|'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Requires preparation of the input data based on token limits
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要根据令牌限制准备输入数据
- en: Need to scan files via OCR to extract content first
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要通过OCR扫描文件以提取内容
- en: Initial embeddings generation cost for custom data (depending on the data scope)
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为定制数据生成初始嵌入的成本（取决于数据范围）
- en: '|'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 5 | Retrieval-based grounding (indexing with Azure AI Search, no embeddings)
    |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 基于检索的定位（使用Azure AI Search进行索引，无嵌入） |'
- en: Good option for information retrieval from existing files
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从现有文件中检索信息的好选择
- en: Indexing allows for citing sources (good for explainability)
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引允许引用来源（有利于可解释性）
- en: Option to use the “add your own data” option from the Playground, for small
    implementations
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用游乐场中的“添加自己的数据”选项进行小型实现
- en: '|'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Potentially less performant than embeddings for large amounts of private data
    (to be confirmed during your preliminary experimentation)
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于大量私有数据，可能不如嵌入性能好（将在初步实验中确认）
- en: '|'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 6 | Hybrid search |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 混合搜索 |'
- en: More performant thanks to the combination of indexing, embeddings, and reranking
    of model results
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于索引、嵌入和模型结果重排的组合，性能更优
- en: Relatively feasible via Azure OpenAI Playground
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Azure OpenAI游乐场相对可行
- en: '|'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Complex, but for Azure OpenAI, no more than the regular embedding-based RAG
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于Azure OpenAI，复杂度不高于常规基于嵌入的RAG
- en: '|'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| 7 | Other grounding techniques (Bing Search, databases, etc.) |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 其他定位技术（Bing搜索、数据库等） |'
- en: Great to add live results to the LLM, and to explore internal sources such as
    databases and tabular files
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常适合向LLM添加实时结果，并探索内部来源，如数据库和表格文件
- en: Updated results with no need to retrain or adjust the model
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无需重新训练或调整模型即可更新结果
- en: '|'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: A bit more complex (requires orchestration engines such as LangChain or Semantic
    Kernel)
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稍微复杂一些（需要编排引擎如LangChain或Semantic Kernel）
- en: Less documentation available for this kind of implementation
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于此类实现，可用的文档较少
- en: '|'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: These implementation approaches have different advantages and levels of complexity.
    One of the key aspects is the ability to evaluate how well they perform, and how
    good these Azure OpenAI models are for specific questions and tasks. Let’s explore
    all of this in the next section.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 这些实现方法具有不同的优势和复杂度水平。其中一个关键方面是评估它们的性能如何，以及这些Azure OpenAI模型对于特定问题和任务有多好。让我们在下一节中探讨所有这些内容。
- en: AI Performance Evaluation Methods
  id: totrans-361
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能性能评估方法
- en: One of the key stages of any generative AI project is model performance evaluation.
    However, it is not a simple task to evaluate the performance of LLM-enabled systems,
    and it is not fully standardized yet. That said, you can start evaluating metrics
    with Azure OpenAI and Azure AI Studio, as you will see in [Chapter 5](ch05.html#operationalizing_generative_ai_implementations)
    with LLMOps and prompt flow for evals.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 任何生成式AI项目的关键阶段之一是模型性能评估。然而，评估启用LLM的系统性能并不简单，而且尚未完全标准化。话虽如此，你可以从Azure OpenAI和Azure
    AI Studio开始评估指标，正如你将在第5章（ch05.html#operationalizing_generative_ai_implementations）中看到的那样，使用LLMOps和提示流进行评估。
- en: 'Here is a selection of the most important metrics for generative AI evaluation:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是生成式AI评估最重要的指标选择：
- en: Groundedness
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 定位性
- en: Groundedness refers to how well a generative AI’s responses are based on the
    information given or available in the input. This is a good metric to analyze
    how AI sticks to the facts, in order to avoid hallucinations. You can explore
    the new [Groundedness Detection feature](https://oreil.ly/Lk4ZI) from the AI Content
    Safety Studio.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 基于事实性是指生成式AI的响应基于给定或输入中可用的信息有多好。这是一个分析AI如何坚持事实、避免幻觉的好指标。您可以从AI内容安全工作室探索新的[基于事实性检测功能](https://oreil.ly/Lk4ZI)。
- en: Similarity
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 相似度
- en: This metric measures how much a GPT output resembles that of a human one. This
    is useful for human validation of the results from Azure OpenAI models.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 该指标衡量GPT输出与人类输出的相似程度。这对于验证Azure OpenAI模型的结果非常有用。
- en: Relevance
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性
- en: It measures how connected an AI’s output is to the input given. It’s like checking
    if someone’s answer in a conversation is related to the question you asked.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 它衡量AI的输出与输入之间的关联程度。这就像检查在对话中某人的回答是否与您提出的问题相关。
- en: Classification accuracy
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 分类准确率
- en: A metric for classification tasks, between 0 and 1, that measures the output
    of the AI model compared to a ground truth.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 用于分类任务的指标，介于0到1之间，衡量AI模型输出与真实值之间的差异。
- en: Levenshtein distance
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: Levenshtein距离
- en: This measures how many changes, such as adding, deleting, or changing pieces,
    you would need to make to get from the AI’s output to the expected output.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 这衡量了您需要做出多少更改，例如添加、删除或更改部分，才能从AI的输出到预期的输出。
- en: Coherence
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性
- en: This checks if the AI’s output makes sense and follows a logical order, like
    checking if a story has a beginning, middle, and end, and doesn’t jump around
    randomly.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 这检查AI的输出是否有意义且遵循逻辑顺序，例如检查一个故事是否有开头、中间和结尾，并且不会随机跳跃。
- en: Fluency
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 流畅性
- en: This measures how smoothly the AI’s output reads, by checking if a written paragraph
    is easy to read and understand, from a linguistics and grammar point of view.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 该指标通过检查书面段落是否易于阅读和理解（从语言学和语法角度来看）来衡量AI的输出读起来有多流畅。
- en: F1 score
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数
- en: This is a balance between the words in the model answer and the ground truth.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在模型答案中的单词与真实值之间的平衡。
- en: Other metrics
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 其他指标
- en: Other metrics from traditional NLP.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 来自传统NLP的其他指标。
- en: 'From an Azure perspective, you can explore the available metrics for evaluation
    via [Azure AI Studio](https://oreil.ly/q2S7r) and [Azure Databricks with MLFlow](https://oreil.ly/3kONX).
    Here are several ongoing initiatives from some of the main industry actors (including
    Microsoft and OpenAI), but you can expect more news and tools in the upcoming
    months and years:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 从Azure的角度来看，您可以通过[Azure AI Studio](https://oreil.ly/q2S7r)和[Azure Databricks与MLFlow](https://oreil.ly/3kONX)探索可用的评估指标。以下是一些主要行业参与者（包括微软和OpenAI）的一些正在进行中的倡议，但您可以期待在接下来的几个月和几年内会有更多新闻和工具：
- en: Microsoft’s [LLM evaluation framework](https://oreil.ly/H6gB8)
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软的[LLM评估框架](https://oreil.ly/H6gB8)
- en: Microsoft’s [evaluation flows (Azure AI Studio)](https://oreil.ly/4NrIz)
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软的[评估流程（Azure AI Studio）](https://oreil.ly/4NrIz)
- en: Microsoft’s documentation for [LLM metrics monitoring](https://oreil.ly/VtjxD)
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软对[LLM 指标监控](https://oreil.ly/VtjxD)的文档
- en: OpenAI’s [Evals project](https://oreil.ly/NgdLZ)
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI的[Evals项目](https://oreil.ly/NgdLZ)
- en: 'Additionally, there are other families of metrics that you can use to measure
    and analyze performance:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有其他一系列的指标，您可以使用它们来衡量和分析性能：
- en: Positive/negative review of answers
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 答案的正面/负面评论
- en: A manual way to both track performance and potentially reeducate the model with
    weighted reconfigurations (e.g., few-shot learning with the good answers). You
    could enable this by using a positive/negative sign in the UI and by adding a
    binary numeric value at the database level if you decide to store the questions
    and answers for review purposes (e.g., ID, question, answer, review) in a JSON
    file stored via Cosmos DB. For this purpose, my recommendation is to create a
    set of test questions, and to involve subject-matter experts during the creation
    of that set and during the evaluation of the system.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 一种手动跟踪性能并可能通过加权重新配置（例如，使用良好答案的少样本学习）重新教育模型的方法。您可以通过在UI中使用正/负符号，并在决定将问题答案（例如，ID、问题、答案、审查）存储在通过Cosmos
    DB存储的JSON文件中时在数据库级别添加二进制数值来启用此功能（例如，ID、问题、答案、审查）。为此，我的建议是创建一组测试问题，并在创建该组以及评估系统期间涉及主题专家。
- en: Traditional product analytics metrics
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 传统产品分析指标
- en: For example, session time, amount of re-questioning to get the best answer,
    overall product rating, etc. This would require tools such as [Microsoft Clarity](https://oreil.ly/2RHm1),
    Pendo, Amplitude, Mixpanel, etc., connected to the cloud native app (e.g., iOS,
    Android, web, etc.). Alternatively, there are cloud native features such as [Azure
    App Insights](https://oreil.ly/HXkzL) that can be deployed as part of the generative
    AI app monitoring system. Additionally, these tools can be leveraged to track
    performance for A/B testing experiments (for example, if we launch two different
    versions of the AI model with different user sets).
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，会话时间、获取最佳答案所需的重问次数、整体产品评分等。这需要连接到云原生应用程序（例如，iOS、Android、Web 等）的工具，如 [Microsoft
    Clarity](https://oreil.ly/2RHm1)、Pendo、Amplitude、Mixpanel 等。或者，有如 [Azure App Insights](https://oreil.ly/HXkzL)
    这样的云原生功能，可以作为生成式 AI 应用程序监控系统的一部分进行部署。此外，这些工具还可以用于跟踪 A/B 测试实验的性能（例如，如果我们推出两个不同版本的
    AI 模型，针对不同的用户群体）。
- en: Conclusion
  id: totrans-392
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This chapter includes not only the available visual and code-based tools for
    your Azure OpenAI implementations, but also the recommended implementation approaches,
    to help you understand the differences between regular, fine-tuned, and grounded
    LLMs. Once again, there is not a perfect or a single way to do it. All of these
    approaches try to leverage the existing power of the Azure OpenAI models, and
    the ability to increase the knowledge scope of your applications with examples,
    internal data sources, live internet search, etc. In [Chapter 4](ch04.html#additional_cloud_and_ai_capabilities)
    we’ll take a look at additional building blocks for your generative AI development.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不仅包括适用于您的 Azure OpenAI 实现的可用的视觉和基于代码的工具，还包括推荐的实现方法，以帮助您理解常规、微调和基于事实的 LLM 之间的区别。再次强调，没有完美或唯一的方法来做这件事。所有这些方法都试图利用
    Azure OpenAI 模型的现有能力，以及通过示例、内部数据源、实时互联网搜索等来增加您应用程序的知识范围。在[第 4 章](ch04.html#additional_cloud_and_ai_capabilities)中，我们将探讨您生成式
    AI 开发所需的额外构建块。
