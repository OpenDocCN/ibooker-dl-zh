<html><head></head><body>
  <h1 class="tochead" id="heading_id_2">1 <a id="idTextAnchor002"/>Understanding tabular data</h1>

  <p class="co-summary-head"><a id="marker-3"/>This chapter covers<a id="idIndexMarker000"/></p>

  <ul class="calibre5">
    <li class="co-summary-bullet">What tabular data is</li>

    <li class="co-summary-bullet">Why tabular data matters</li>

    <li class="co-summary-bullet">The distinction between deep learning andnon-deep learning approaches to tabular data</li>

    <li class="co-summary-bullet">What people think about using deep learning with tabular data</li>

    <li class="co-summary-bullet">Characteristics of tabular data that distinguish it from other kinds of data, like image, sound, or text data</li>
  </ul>

  <p class="body">Tabular data is central to our modern lives and, for most of us, to our work lives. Tabular data exists in spreadsheets as CSV files and in the tables of relational databases, it populates analysis and reports, and it can be the fuel for training machine learning models. Machine learning models trained on your tabular business can successfully solve many useful problems, such as predicting inventory requirements in retail outlets or predicting the price of market commodities.</p>

  <p class="body">In this chapter, we introduce the process of selecting the appropriate modeling approach for tabular data problems. We present two main approaches: deep learning and classical machine learning. Then, from the data perspective, we look at some of the unique considerations you face when using tabular data with machine learning models.<a id="idTextAnchor003"/></p>

  <h2 class="fm-head" id="heading_id_3">1.1 What is tabular data?</h2>

  <p class="body">For the purposes of this book, <i class="fm-italics">tabular data</i> is simply data that is organized in rows and columns. A collection of tabular data can be called a <i class="fm-italics">tabular dataset</i> or a <i class="fm-italics">table</i>. All the entries in a row are related to a common data point or an observation. Each row is autonomous from the other rows and completely describes a specific condition. The columns represent attributes for that data point, and they are often mentioned as variables (a more statistical term) or features (a term more typical of machine learning). All the entries in a column have a common data type, such as integer, string, or floating point number. The columns in a table usually have a common type. <a id="idIndexMarker001"/><a id="idIndexMarker002"/><a id="idIndexMarker003"/><a id="marker-4"/></p>

  <p class="body">Consider a table that contains information about currencies used in a set of nations, as shown in figure 1.1.<a id="idTextAnchor004"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH01_F01_Ryan2.png"/></p>

    <p class="figurecaption">Figure 1.1 An example of tabular data</p>
  </div>

  <p class="body">Columns in this table contain values of different types:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Country, Currency name, Currency symbol, and ISO 4217 code are all <i class="fm-italics">categorical columns</i> because valid values for these columns come from a finite, relatively small set of values.<a id="idIndexMarker004"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Currency nicknames are free-form text columns because they can contain a range of values or no value at all, depending on the country.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Units per US Dollar is a continuous column because it contains real number values.</p>
    </li>
  </ul>

  <p class="body">We will explore more details about the characteristics of tabular data in chapter 2.</p>

  <p class="body">Tabular data can reside in a variety of physical formats:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Standalone files,</i> including CSV files and spreadsheet files such as Excel and Google Sheets files.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Tables in relational databases,</i> such as</p>

      <ul class="calibre6">
        <li class="fm-list-bullet">
          <p class="list">Open-source databases, such as Postgres (<a class="url" href="https://www.postgresql.org/">https://www.postgresql.org/</a>) and MySQL (<a class="url" href="https://www.mysql.com/">https://www.mysql.com/</a>)</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list">On-premise vendor databases, such as SQL Serv<a id="idTextAnchor005"/>er (<a class="url" href="https://mng.bz/MD2W">https://mng.bz/MD2W</a>) and Oracle (<a class="url" href="https://www.oracle.com/ca-en/database/">https://www.oracle.com/ca-en/database/</a>)</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list">Cloud-native databases, such as Google Cloud Spanner (https://cloud.google.com/spanner), AWS Aurora (<a class="url" href="https://aws.amazon.com/rds/aurora/">https://aws.amazon.com/rds/aurora/</a>), and Snowflake(<a class="url" href="https://www.snowflake.com/">https://www.snowflake.com/</a><span id="idTextAnchor006"/>)</p>
        </li>
      </ul>
    </li>
  </ul>

  <p class="fm-callout"><span class="fm-callout-head">NOTE</span> You may have heard the term <i class="fm-italics">structured data</i> used interchangeably with <i class="fm-italics">tabular data</i>. However, these two terms are not synonymous. For example, people sometimes refer to data that has a degree of structure but is not tabular, such as nested JSON, as structured data. Structured data, also encompasses relational data, time series data, graph data, and spatial data, any of which might also be represented in tabular form. To avoid any confusion, we will use the term <i class="fm-italics">tabular data</i> exclusively in this book.<a id="marker-5"/><a id="idIndexMarker005"/></p>

  <p class="body">Now that we have established what tabular data is, what isn’t tabular data? This is an important question because the differences between tabular data and nontabular data help explain one of the key questions answered in this book: Are there situations where you should use deep learning with tabular data? The following are some examples of data that is not tabular:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Images</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Videos</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Audio</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Text</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Sensor data in JSON format, such as data generated by Internet of Things devices</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Social media streaming data</p>
    </li>
  </ul>

  <p class="body">Can you think of one thing all these nontabular data types have in common? If you answered, “They have all been very successfully used to train deep learning models,” you would be absolutely right. Indeed, in the last 10 years, one groundbreaking model after another has been created using various nontabular datasets. In this book, we’ll explore why deep learning hasn’t set the world of tabular data on fire in the same way and under what circumstances it makes sense to apply deep learning to tabular d<a id="idTextAnchor007"/>ata.</p>

  <h2 class="fm-head" id="heading_id_4">1.2 The world runs on tabular data</h2>

  <p class="body">According to the article “Structured vs Unstructured Data” (<a class="url" href="https://mng.bz/5g7Z">https://mng.bz/5g7Z</a>), up to 90% of all the digital data in the world is nontabular, and the proportion that is nontabular is increasing every year. If this is true, then why read a book about applying machine learning methods to tabular data? While it’s probably true that only a small portion of the world’s data is tabular, this portion is absolutely essential. Every bank, every insurance company, every government agency, every retailer, every manufac<a id="idTextAnchor008"/>turer—all of them run their core activities on tabular data. Such predominance is dictated, first, because its format as a table arranged in rows and columns makes tabular data easy to input, retrieve, manage, and analyze. Second, tabular data is supported by many business software and applications, such as spreadsheets, databases, and business intelligence tools. <a id="marker-6"/><a id="idIndexMarker006"/></p>

  <p class="body">In addition to their core activities, these organizations depend on tabular data to monitor their progress and detect problems. As you live a modern life as a consumer, an employee, and a citizen, your daily activities generate updates in hundreds, even thousands, of tables.</p>

  <p class="body">For three years, one of the authors of this book had the privilege of running the worldwide support function for one of the largest relational database products in the world. Around the clock, seven days a week, this job exposed the width and breadth of organizations that ran on tabular data. It also exposed what happens when the tabular data systems fail. Shoppers across an entire continent couldn’t use their credit cards, trucks were backed up for miles at the border, freight trains stopped running, retail websites crashed on Black Friday, and factories creating artificial hearts ground to a halt. It is no exaggeration—the world runs on tabular data and on structured data in general.</p>

  <p class="body">Tabular data is everywhere, and it is critically important. For many of us, our jobs revolve around tabular data. Because of this, understanding how to efficiently apply machine learning (and, where appropriate, deep learning) to tabular data is a very useful skill. In this book, you will learn techniques to unlock the potential of tabular d<a id="idTextAnchor009"/>ata.</p>

  <h2 class="fm-head" id="heading_id_5">1.3 Machine learning vs. deep learning</h2>

  <p class="body">Both deep learning and classical machine learning methods aim to map input data to a prediction. However, they take different approaches, as deep learning methods have been designed to mimic the behavior of a biological brain, whereas other machine learning techniques are often based on statistical optimizations or similarity comparisons. However, apart from the different approaches taken, they also imply a profoundly different way to make good use of data. <a id="idIndexMarker007"/><a id="idIndexMarker008"/></p>

  <p class="body">In classical machine learning approaches, feature transformation and engineering are king because, no matter the model you adopt, you will always need to apply appropriate transformations to your data based on data characteristics and the knowledge domain the data comes from (Is it business data? Does it represent any social, economic, or physical phenomena?). The following are some reasons why feature engineering is so essential in classical machine learning:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Relevant information extraction</i>—Not all raw data is equally relevant for a specific task. Feature engineering helps identify and extract the most informative aspects of the data, discarding irrelevant or noisy parts. By focusing on the relevant features, the model can concentrate on learning the essential patterns, leading to better generalization and improved performance.<a id="idIndexMarker009"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Data representation</i>—Different models have different requirements in terms of data representation. Feature engineering allows you to convert the data into a suitable format that fits the model’s assumptions and limitations. This step guarantees that the model can learn effectively from the data and make accurate predictions.<a id="idIndexMarker010"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Addressing nonlinearity</i>—In many real-world problems, the relationships between the features and the target variable may not be linear. Feature engineering can help transform the data to address nonlinearities, making it easier for linear models to approximate complex relationships.<a id="idIndexMarker011"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Domain-specific knowledge</i>—In some cases, domain experts may have valuable insights about the data that can be used to engineer relevant features. Incorporating domain knowledge can significantly improve the model’s performance in specific applications.<a id="idIndexMarker012"/><a id="marker-7"/></p>
    </li>
  </ul>

  <p class="body">On the other hand, deep learning approaches rely on <i class="fm-italics">representation learning</i>, which is their ability to internally and automatically process the data into a meaningful form for solving the problem at hand. Representation learning capabilities of deep learning models allow them to transform the data into a more compact and meaningful format that captures relevant features and patterns for a specific task. In fact, during the learning process, thanks to the fact that all input features interact in a nonlinear way with the others, deep learning models discover by themselves intricate patterns and dependencies in the data that may not be apparent through manual feature engineering, and they manage to develop hierarchical representations of the input data, starting from basic features and gradually building up to more complex and abstract ones.<a id="idIndexMarker013"/></p>

  <p class="body">Therefore, classical machine learning primarily centers on thorough and effective feature engineering, whereas deep learning models for tabular data are much more focused on the architecture of the arrangement of the layers of neurons and on the characteristics of individual neurons. This dichotomy constitutes a fundamental aspect of our book: upcoming chapters not only emphasize the distinction between classical machine learning and deep learning models but also introduce different ways to frame data problems and find solutions based on this distinction.</p>

  <p class="body">While it may not be completely orthodox to simplify the terminology in such a way, throughout the book, we use the generic term <i class="fm-italics">machine learning</i> or <i class="fm-italics">classical machine learning</i> for all the machine learning approaches but neural networks and use <i class="fm-italics">deep learning</i> for neural network-based approaches. <a id="idIndexMarker014"/><a id="idIndexMarker015"/></p>

  <p class="body">We will cover basic and more advanced machine learning models based on popular packages such as</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Basic machine learning models available in Scikit-learn (<a class="url" href="https://scikit-learn.org/">https://scikit-learn.org/</a>) and in GPU-specialized libraries [such as NVIDIA Rapids (<a class="url" href="https://developer.nvidia.com/rapids">https://developer.nvidia.com/rapids</a>)]:</p>

      <ul class="calibre6">
        <li class="fm-list-bullet">
          <p class="list">Linear regression</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list">Logistic regression</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list">Generalized linear models</p>
        </li>
      </ul>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Some tree-based methods available in Scikit-learn are</p>

      <ul class="calibre6">
        <li class="fm-list-bullet">
          <p class="list">Bagging ensembles of weak predictors</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list">Random forest</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list">Extremely randomized trees</p>
        </li>
      </ul>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Histogram-based gradient-boosted approaches, including</p>

      <ul class="calibre6">
        <li class="fm-list-bullet">
          <p class="list">XGBoost eXtreme Gradient Boosting (<a class="url" href="https://github.com/dmlc/xgboost">https://github.com/dmlc/xgboost</a>)</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list">Microsoft’s LightGBM (<a class="url" href="https://github.com/Microsoft/LightGBM">https://github.com/Microsoft/LightGBM</a>)</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list">HistGradientBoosting from Scikit-learn</p>
        </li>
      </ul>
    </li>
  </ul>

  <p class="body">For deep learning, we will cover a range of architectures that are effective with tabular data implemented in TensorFlow or PyTorch deep learning frameworks:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Shallow networks with categorical embeddings (directly implemented using one of the available deep learning frameworks)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">fastai tabular (<a class="url" href="https://docs.fast.ai/tabular.model.html">https://docs.fast.ai/tabular.model.html</a>)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">PyTorch Tabular (<a class="url" href="https://github.com/manujosephv/pytorch_tabular">https://github.com/manujosephv/pytorch_tabular</a>)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">TabNet (<a class="url" href="https://arxiv.org/abs/1908.07442">https://arxiv.org/abs/1908.07442</a>)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">SAINT (<a class="url" href="https://arxiv.org/abs/2106.01342">https://arxiv.org/abs/2106.01342</a>)</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">DeepTables (<a class="url" href="https://github.com/DataCanvasIO/deeptables">https://github.com/DataCanvasIO/deeptables</a>)</p>
    </li>
  </ul>

  <p class="body">You will see this distinction between machine learning and deep learning throughout this book as we explore both approaches and advise when to use each approach to solve tabular d<a id="idTextAnchor010"/>ata problems. <a id="idIndexMarker016"/><a id="marker-8"/><a id="idIndexMarker017"/></p>

  <h2 class="fm-head" id="heading_id_6">1.4 What makes tabular data different?</h2>

  <p class="body">We know that deep learning approaches dominate solving problems involving many types of data that we could define as “nontabular” or “unstructured” because of their great variety of characteristics, sizes, and modalities that you cannot constrain in a rows/columns data model. Typical examples of unstructured data that have been successfully tackled by deep learning are<a id="idIndexMarker018"/><a id="idIndexMarker019"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Audio</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Video</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Images</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Text</p>
    </li>
  </ul>

  <p class="body">Here, contrary to structured tabular data problems, you don’t have anything near the typical matrix-shaped format but different files or instances containing a multitude of information in an unordered way. Before deep learning revolutionized the way unstructured data is modeled, unstructured data that we wanted to use for a predictive model had to be brought back into a structured data format by carefully creating well-defined and specific features (a procedure called feature engineering). For each type of unstructured data problem, researchers and practitioners took years to find the best features to be extracted from the data to feed a machine learning model and then obtain satisfactory predictive results.</p>

  <p class="body">Thanks to their representational power, deep learning models can handle all the necessary transformations to turn unstructured data into a viable prediction, in an end-to-end fashion, directly from input to solution. Given this background, you might expect deep learning models to be even more effective on tabular data, but this has not been the case up to now.</p>

  <p class="body">There are, in truth, various reasons that can explain the challenge that deep learning faces with tabular data problems. The first reason involves the actual directions of academic research and private investment in new technologies and methodologies. As we mentioned, in the past, researchers spent time and effort finding the best way to turn unstructured data into structured data to fit the machine learning paradigm of the time. Nowadays, the same efforts are spent on advancing deep learning, concentrating particularly on unstructured data because it is more easily available in public repositories and more “uniform” than tabular data, thus bringing more research success.</p>

  <p class="body">Image repositories such as ImageNet (<a class="url" href="https://image-net.org/index.php">https://image-net.org/index.php</a>) and open text corpora such as Wikipedia or the Common Crawl’s web archive (<a class="url" href="https://commoncrawl.org/">https://commoncrawl.org/</a>) are easily available to both academic researchers and practitioners to train or refine their deep learning models. As for tabular data, there is no equivalent in terms of a common open-source data repository. On the contrary, tabular data is dispersed into a multitude of private databases, each one showing an even higher degree of variability than unstructured data because each database has its own data collection rules and structure of features.<a id="marker-9"/></p>

  <p class="body">In addition to the fact that open-source tabular datasets representing real-world business problems are generally harder to find, you must also consider a second reason. Open-source tabular datasets are usually smaller in size and often quite different from the data that is owned privately by businesses and governments. Consequently, the lack of data usually causes neural networks to underperform. In addition, there is no golden rule to benchmark one’s progress because using a particular kind of data is limited to a specific problem in the vast domain of tabular data problems. For any researcher, it is much more challenging to generalize best practices starting from a tabular dataset, or even a limited choice of them, than to do the same using images, audio, or texts that are universally available and accepted as a reference benchmark.</p>

  <p class="body">Being difficult to access and extremely varied in the type of information they contain, tabular datasets present a further limitation for deep learning solutions: you cannot think of any pretrained solutions because you cannot get a hold of all the kinds of tabular problems. Once you develop a deep learning model for images and text problems, you can make it available to the public and expect other academics or practitioners to find it useful for their problem after tweaking it a bit. This is technically called <i class="fm-italics">transfer learning</i> because you can successfully apply, with a limited additional modeling effort, the deep learning network trained on a problem to another similar task. Such an opportunity has strongly driven the diffusion of deep learning models in their pretrained form in recent years.<a id="idIndexMarker020"/></p>

  <p class="body">In conclusion, the lack of generalizable tabular examples, a great variety of kinds of tabular data, and more attention from academics on unstructured data have led to feature engineering playing a different role between machine learning and deep learning:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">In machine learning, feature engineering can yield much more predictive power for tabular data than algorithms themselves, and it is commonly regarded more as an art than a science.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">In deep learning, on the contrary, academics and practitioners tend to rely too much on representation learning and let the network deal with everything instead of using feature engineering themselves and demonstrating how deep learning, given the same data framework as a machine learning algorithm, can learn a solution in a different and useful way.</p>
    </li>
  </ul>

  <p class="body">Truly, as demonstrated by recent studies, tabular data characteristics such as redundant features, skewed distributions, and irregular patterns of the prediction target pose a challenge to neural networks. We will discuss this in more detail in chapter 5, when dealing specifically with the gradient boosting models. All the same, we assert that both machine learning and deep learning models are viable ways to solve tabular data problems, and deep learning will grow in importance as practitioners and researchers put more effort into testing architectures and solutions on more realistic tabular data than those that are easil<a id="idTextAnchor011"/>y available today. <a id="idIndexMarker021"/><a id="marker-10"/><a id="idIndexMarker022"/></p>

  <h2 class="fm-head" id="heading_id_7">1.5 Generative AI and tabular data</h2>

  <p class="body">Generative AI—in particular, large language models (LLMs)—are capable assistants in various tasks related to text production and processing. Generally speaking, LLMs have proven to be a breakthrough solution for a certain range of tasks, such as<a id="idIndexMarker023"/><a id="idIndexMarker024"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Generation</i>—Generate text such as the next token, words to complete a phrase, up to generate a text from an instructional prompt</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Extraction</i>—Named entity recognition, sentence segmentation, keyword extraction, topic modeling, named entity recognition, semantic relationship extraction</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Classification</i>—Language, intention, sentiment, semantics, and even tricky problems such as sarcasm, irony, negation</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Transformation</i> of the text—Translations, corrections, style modifications, paraphrasing, summarization</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Comprehension</i>—Leading to question and answering, reasoning, knowledge completion</p>
    </li>
  </ul>

  <p class="body">Many of these tasks can extend to the work of a data scientist or a data engineer. LLMs can support the user in activities such as feature engineering, coding functions, and visualization instructions (for instance, using commands from the matplotlib package), providing analytical advice, helping interpret results, and presenting them synthetically for charts and reports. One notable practical application of LLMs in tabular data is automating textual data-related tasks. When dealing with textual variable fields, they can engineer new features by summarizing, categorizing, and identifying key themes. They can also develop the code to process the same text in Python, for instance, by creating functions or figuring out the correct regular expression for text processing.</p>

  <p class="body">Besides supporting the user and being a useful assistant, LLMs can also play a more direct and active role in analytics. Recent applications for ChatGPT (the Advanced Data Analytics API) also provide direct data analysis in CSV format, followed by other data-related tasks, including summarization, preprocessing, analysis, visualization, and report generation. At each step, the tool can provide the Python code to execute and obtain the same results, it runs the code for you and provides some visualizations in charts and tables. This aligns with the expected capabilities for TableGPT or other tools such as MediTab. TableGPT (<a class="url" href="https://arxiv.org/pdf/2307.08674.pdf">https://arxiv.org/pdf/2307.08674.pdf</a>) is a new framework that utilizes LLMs to enhance human interaction with tabular data. It enables users to interact with tables using commands expressed in natural language and perform various tasks such as question answering, data manipulation, data visualization, report generation, and automated prediction. MediTab (<a class="url" href="https://arxiv.org/pdf/2305.12081.pdf">https://arxiv.org/pdf/2305.12081.pdf</a>), instead, works on medical tabular data by consolidating tabular samples, aligning out-domain data with the target task, and expanding the training data. Faced with prediction tasks based on textual data, it even demonstrated performances superior to classical machine learning algorithms such as XGBoost.<a id="idIndexMarker025"/><a id="idIndexMarker026"/><a id="idIndexMarker027"/><a id="marker-11"/><a id="idIndexMarker028"/></p>

  <p class="body">Generally speaking, LLMs do not offer comparable performance in prediction tasks on tabular data, as demonstrated by the TABLET benchmark (<a class="url" href="https://arxiv.org/pdf/2304.13188.pdf">https://arxiv.org/pdf/2304.13188.pdf</a>). In assessing LLMs’ performance relative to fully supervised models, the paper compared Flan-T5 11b and ChatGPT using 4-shot examples compared with XGBoost trained on the entire dataset. The XGBoost model, when applied to all the data, achieved an average F1 score of 0.94 on the prediction tasks. In contrast, ChatGPT averaged a score of 0.68, and Flan-T5 11b achieved a score of 0.66 using the F1 score. This analysis highlights that there is still a significant margin for improvement in predictive tasks for LLMs involving tabular data with multimodal types (text and numbers) and that such tools continue to excel in executing instructions, particularly when working with textual inputs and producing textual outputs. A tool such as llm-classifier (<a class="url" href="https://github.com/lamini-ai/llm-classifier">https://github.com/lamini-ai/llm-classifier</a>) works and surprises because it can use the information already contained in the used LLM but cannot acquire much additional information typical of tabular problems.<a id="idIndexMarker029"/></p>

  <p class="body">In sum, generative AI is not yet the solution when dealing with tabular data, not only due to performance reasons but also for other crucial aspects, such as</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Cost</i>—Generative AI models often require intensive GPU resources, leading to higher operational costs.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Scalability</i>—The resource-intensive nature of generative AI models, particularly their reliance on GPUs, can hinder scalability.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Latency and throughput</i>—Larger models tend to increase processing time per request, affecting latency and throughput.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Bias</i>—Generative AI models may inherit biases from the data they were trained on, potentially perpetuating or amplifying existing biases.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Flexibility</i>—Adapting generative AI models to custom tasks often necessitates extensive retraining, limiting their flexibility.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Determinism</i>—The inherent complexity of generative AI models can make it challenging to control and predict their output, affecting determinism.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Explainability</i>—The complexity of generative AI models can hinder explainability, making it difficult to understand how they operate and produce results.</p>
    </li>
  </ul>

  <p class="body">Acknowledging such present limitations for generative AI to handle tabular data problems, we will focus on the core classical machine learning and deep learning techniques for learning from tabular data and on how to prepare this data for analysis correctly and properly. However, we will also reserve some space to deal with generative AI tools such as ChatGPT, Google Gemini, and Gemini for Google Cloud because we recognize generative AI’s transformative force in the tabular data field. Based on our experience in the field, we do not foresee any replacement by LLMs or other generative tools of the classical machine learning algorithms or the deep learning architecture specialized in tabular data because of the advantages that such consolidated tools offer, both in terms of performance and control. Instead, we recognize how LLMs and other generative AI models can support and enhance tabular data processing, analysis, and modeling, helping practitioners become more proficient and performative in <a id="idTextAnchor012"/>their tabular data projects.<a id="idIndexMarker030"/><a id="marker-12"/><a id="idIndexMarker031"/></p>

  <h2 class="fm-head" id="heading_id_8">Summary</h2>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Tabular data is data organized in rows and columns, such as data in CSV files or relational database tables.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Structured data is sometimes used as an alternative term for tabular data, but it is a broader concept, including JSON formatted data.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Tabular data makes up a small portion of all the digital data in the world, but it has an enormous effect on our lives.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Compared to other types of data (e.g., images, video, text, audio), the type of data that most jobs revolve around is tabular data, so learning how to efficiently apply machine learning/deep learning to tabular data is a useful skill that many people can apply to their jobs.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">In this book, we simply refer to machine learning approaches excluding neural networks (going from linear regressions to gradient boosting methods) as <i class="fm-italics">classical machine learning</i> or just <i class="fm-italics">machine learning</i> to distinguish them from deep learning.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Compared to deep learning with other types of data (e.g., images, video, text, audio), deep learning with tabular data gets little attention from academic researchers.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Conventional wisdom is to use a gradient boosting approach like XGBoost with tabular data.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">There’s a lively debate in social media about whether or not there is a place for deep learning in solving problems involving tabular data. In this book, we don’t pick a side in this debate. Instead, we try to objectively describe why you would use machine learning or deep learning for a given tabular data problem and the best practices to use for each approach.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Tabular data has some unique characteristics not shared by other types of data, such as images, video, or text. These characteristics include a lack of large open-source datasets that represent the kinds of tabular datasets that you would see in real-world business problems.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Generative AI, especially LLMs, significantly affects how AI is perceived, diffused across individuals and organizations, and utilized. LLMs can help automate various tasks related to tabular data analysis and modeling, especially when related to textual inputs and outputs.<a id="marker-13"/></p>
    </li>
  </ul>
</body></html>