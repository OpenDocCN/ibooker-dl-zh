- en: Prefazione
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Questo lavoro è stato tradotto utilizzando l''AI. Siamo lieti di ricevere il
    tuo feedback e i tuoi commenti: [translation-feedback@oreilly.com](mailto:translation-feedback@oreilly.com)'
  prefs: []
  type: TYPE_NORMAL
- en: L'*IA generativa* (GenAI) sta conquistando il mondo dopo il rilascio di tecnologie
    come ChatGPT. Questo nuovo tipo di IA è in grado di creare contenuti in varie
    *modalità* (come testo, audio, video, ecc.) imparando a imitare gli schemi dei
    dati di addestramento. Con l'aumento delle capacità dell'IA generativa, molte
    aziende stanno investendo in strumenti di IA off-the-shelf o personalizzati. Questi
    strumenti richiedono servizi di backend manutenibili e scalabili in grado di adattarsi
    a una domanda elevata.
  prefs: []
  type: TYPE_NORMAL
- en: Le capacità dell'IA sono entusiasmanti perché aprono le porte a infinite possibilità
    che liberano il potenziale di nuovi strumenti. Prima dell'IA generativa, gli sviluppatori
    dovevano scrivere script e addestrare modelli di ottimizzazione per creare automazione
    e pipeline di dati per l'elaborazione di dati non strutturati come i corpora di
    testi. Questo processo poteva essere noioso, soggetto a errori e applicabile solo
    a casi d'uso limitati. Tuttavia, con l'avvento dei modelli di IA generativa, come
    i modelli linguistici di grandi dimensioni (LLMs), ora possiamo digerire, confrontare
    e riassumere set di dati e documenti non strutturati, riformulare idee complesse
    e generare visualizzazioni e illustrazioni.
  prefs: []
  type: TYPE_NORMAL
- en: Sebbene la maggior parte dei modelli generativi come ChatGPT siano eccellenti
    per quello che fanno da soli, riesci a immaginare le possibilità che si aprono
    quando li colleghiamo a internet, ai nostri database e ad altri servizi? Se possiamo
    "parlare" ai nostri servizi inlinguaggio naturale o fornire loro immagini, video
    o audio e fargli fare delle cose per noi, si aprono tantissime opportunità per
    creare nuoveapplicazioni accessibili e automatizzate.
  prefs: []
  type: TYPE_NORMAL
- en: I chatbot non sono le uniche applicazioni che possiamo creare con questi modelli
    generativi. Possiamo creare agenti di servizio backend in grado di eseguire diversi
    compiti complessi che richiedono la comprensione, il ragionamento logico e l'analisi
    dei testi.
  prefs: []
  type: TYPE_NORMAL
- en: Collegando i nostri modelli generativi ai servizi esistenti e a internet, forniamo
    ai nostri servizi di IA ulteriori dati per arricchire la loro comprensione del
    problema in questione. Ad esempio, un'azienda può utilizzare un LLM open source,
    interno e ottimizzato per analizzare gli ordini di acquisto, generare fatture
    e convalidare i dati rispetto al database dei clienti prima di effettuare un ordine
    con un sistema di pagamento. Altri casi d'uso possono essere i sistemi di gestione
    dei contenuti che possono aiutare gli utenti a generare contenuti e i costruttori
    di siti web che possono suggerire immagini, icone e componenti dell'interfaccia
    utente (UI) per velocizzare il design del sito.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs e altri modelli generativi richiedono una grande potenza di elaborazione
    e una grande quantità di memoria per funzionare e non è chiaro quali siano i modelli
    di distribuzione e i livelli di integrazione che gli sviluppatori dovrebbero utilizzare
    per sfruttare questi modelli. Costruire servizi di IA generativa è impegnativo
    perché devi trovare un equilibrio tra scalabilità, sicurezza, prestazioni e privacy
    dei dati. Vorrai anche avere la possibilità di moderare, riqualificare e ottimizzare
    questi servizi per l'inferenza in tempo reale. Queste sfide saranno diverse per
    ogni organizzazione e il modo in cui costruirai i tuoi servizi di IA generativa
    dipenderà dai tuoi sistemi e servizi software esistenti.
  prefs: []
  type: TYPE_NORMAL
- en: Le risorse e la documentazione esistenti forniscono le informazioni necessarie
    per iniziare ad addestrare modelli personalizzati e a mettere a punto modelli
    linguistici di grandi dimensioni. Tuttavia, la maggior parte degli sviluppatori
    potrebbe continuare a incontrare difficoltà nel confezionare e distribuire questi
    nuovi modelli generativi come parte di sistemi e servizi software esistenti.
  prefs: []
  type: TYPE_NORMAL
- en: L'obiettivo di questo libro è quello di mostrarti come produrre GenAI comprendendo
    il processo end-to-end di costruzione e distribuzione dei tuoi servizi AI con
    strumenti come il framework web FastAPI.
  prefs: []
  type: TYPE_NORMAL
- en: Obiettivo e approccio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: L'obiettivo di questo libro è quello di aiutarti a esplorare le sfide dello
    sviluppo, della messa in sicurezza, del test e dell'implementazione dell'IA generativa
    come servizio integrato con i tuoi sistemi e le tue applicazioni esterne.
  prefs: []
  type: TYPE_NORMAL
- en: Questo libro è incentrato sulla costruzione di servizi AI generativi modulari
    e sicuri dal punto di vista tipologico in FastAPI, con un supporto continuo alla
    gestione degli schemi di database e all'integrazione dei modelli per alimentare
    backend in grado di generare nuovi dati.
  prefs: []
  type: TYPE_NORMAL
- en: L'importanza di questi argomenti deriva dalla crescente richiesta di costruire
    servizi flessibili in grado di adattarsi a requisiti mutevoli, di mantenere prestazioni
    elevate e di scalare in modo efficiente utilizzando il modello dei microservizi.
  prefs: []
  type: TYPE_NORMAL
- en: Imparerai anche il processo di arricchimento dei tuoi servizi con dati contestuali
    provenienti da diverse fonti come database, web, sistemi esterni e file caricati
    dagli utenti.
  prefs: []
  type: TYPE_NORMAL
- en: Alcuni modelli generativi richiedono una grande potenza di elaborazione e una
    grande quantità di memoria per poter funzionare. Esplorerai come gestire questi
    modelli in produzione e come scalare i tuoi servizi per gestire il carico. Esplorerai
    anche come gestire le attività di lunga durata come l'inferenza del modello.
  prefs: []
  type: TYPE_NORMAL
- en: Infine, discuteremo i concetti di autenticazione, le considerazioni sulla sicurezza,
    l'ottimizzazione delle prestazioni, i test e l'implementazione di servizi di IA
    generativa pronti per la produzione.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisiti
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Questo libro non presuppone alcuna conoscenza preliminare dell'IA generativa
    e non richiede che tu comprenda appieno il funzionamento dei modelli generativi.
    Tratterò l'intuizione di come questi modelli generano i dati, ma non mi addentrerò
    nella loro matematica di base. Tuttavia, se vuoi saperne di più su come costruire
    i tuoi modelli di IA generativa in dettaglio, ti consiglio [*Generative Deep Learning*](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/)
    di David Foster (O'Reilly, 2024).
  prefs: []
  type: TYPE_NORMAL
- en: Poiché si tratta di un libro su FastAPI per le applicazioni di intelligenza
    artificiale generativa, presuppongo una certa familiarità con questo framework
    web. Se hai bisogno di un ripasso o vuoi ampliare la tua comprensione delle funzionalità
    di FastAPI, ti consiglio di leggere [*FastAPI*](https://www.oreilly.com/library/view/fastapi/9781098135492/)
    di Bill Lubanovic (O'Reilly, 2023). Tuttavia, non è un requisito per seguire questo
    libro.
  prefs: []
  type: TYPE_NORMAL
- en: Inoltre, il libro presuppone una certa esperienza con Python, con Docker per
    il deployment, con il funzionamento del web e con la comunicazione attraverso
    il protocollo HTTP.
  prefs: []
  type: TYPE_NORMAL
- en: Per migliorare le tue conoscenze di Python, ti consiglio di visitare il sito
    [realpython.org](https://realpython.org) per trovare ottimi tutorial su concetti
    più avanzati. Anche il [sito](https://www.docker.com) ufficiale [di Docker](https://www.docker.com)
    offre un eccellente tutorial pratico sulla containerizzazione e sulla scrittura
    dei file Docker.
  prefs: []
  type: TYPE_NORMAL
- en: In questo libro non tratterò i fondamenti del web, ma consiglio vivamente [la
    documentazione di MDN](https://oreil.ly/vvwzI) come punto di partenza.
  prefs: []
  type: TYPE_NORMAL
- en: Infine, il libro non richiede la conoscenza di framework per l'apprendimento
    profondo come TensorFlow e Keras, che verranno introdotti laddove necessario.
    Al contrario, lavoreremo per lo più con modelli pre-addestrati ospitati nel [repository
    di modelli di Hugging Face](https://oreil.ly/vC0DA).
  prefs: []
  type: TYPE_NORMAL
- en: Struttura del libro
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Il libro è suddiviso in tre parti:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Parte I, "Sviluppare i servizi AI"](part01.html#part1)'
  prefs: []
  type: TYPE_NORMAL
- en: Questa parte copre tutti i passi necessari per impostare un progetto FastAPI
    che alimenterà il tuo servizio GenAI. Imparerai a integrare vari modelli generativi
    in un'applicazione FastAPI type-safe e a esporre gli endpoint per interagire con
    essi.
  prefs: []
  type: TYPE_NORMAL
- en: '[Capitolo 1, "Introduzione":](ch01.html#ch01) Questo capitolo parla dell''importanza
    di GenAI nel futuro e introduce i progetti pratici che realizzerai nel corso del
    libro.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Capitolo 2, "Come iniziare con FastAPI":](ch02.html#ch02) Questo capitolo
    introduce FastAPI, un framework moderno per la creazione di servizi di intelligenza
    artificiale, di cui comprenderai le caratteristiche, le limitazioni e il confronto
    con altri framework web. Alla fine del capitolo sarai in grado di iniziare a creare
    applicazioni FastAPI, organizzare progressivamente i progetti e migrare da framework
    come Flask o Django.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Capitolo 3, "Integrazione dell''intelligenza artificiale e servizio di modelli":](ch03.html#ch03)
    Questo capitolo tratta l''intero processo di integrazione e di servizio di vari
    modelli GenAI (tra cui modelli linguistici, audio, di visione e 3D) come servizio
    FastAPI utilizzando l''application lifespan. Verranno esaminate varie strategie
    per il servizio dei modelli, come il precaricamento, l''esternalizzazione e il
    monitoraggio dei modelli con il middleware.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Capitolo 4, "Implementare servizi AI sicuri dal punto di vista tipologico":](ch04.html#ch04)
    Questo capitolo introduce il concetto di sicurezza dei tipi e come le annotazioni
    sui tipi di Python e gli strumenti di validazione dei dati come Pydantic possono
    aiutare a validare e serializzare i dati che passano attraverso i tuoi servizi
    di intelligenza artificiale.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Parte II, "Comunicare con i sistemi esterni".](part02.html#part2)'
  prefs: []
  type: TYPE_NORMAL
- en: In questa parte, integreremo i nostri servizi di intelligenza artificiale con
    sistemi esterni come i database e impareremo a servire utenti simultanei. Implementeremo
    anche lo streaming in tempo reale dei risultati dei modelli.
  prefs: []
  type: TYPE_NORMAL
- en: '[Capitolo 5, "Ottenere la concomitanza nei carichi di lavoro dell''intelligenza
    artificiale":](ch05.html#ch05) Questo capitolo introduce i concetti di concomitanza
    e parallelismo e mette a confronto diverse strategie per risolvere i problemi
    di concomitanza. Rivedremo lo scopo della programmazione asincrona nella gestione
    dei compiti a lungo termine e di quelli bloccanti ed esamineremo i limiti del
    Global Interpreter Lock (GIL) di Python nella gestione di questi processi asincroni.
    Per fare pratica, implementeremo un chatbot funzionante "parla con il web e con
    i tuoi documenti" utilizzando una tecnica chiamata *retrieval augmented generation
    (RAG* ). Infine, tratteremo la funzione dei compiti in background di FastAPI per
    affrontare le operazioni a lungo termine.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Capitolo 6, "Comunicazione in tempo realecon i modelli generativi":](ch06.html#ch06)
    In questo capitolo ci concentreremo sull''abilitazione della comunicazione client-server
    in tempo reale con i modelli generativi, confrontando vari meccanismi come i web
    socket e gli eventi di streaming del server per lo streaming dei dati da/verso
    i modelli generativi con esempi pratici.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Capitolo 7, "Integrazione dei database nei servizi di intelligenza artificiale":](ch07.html#ch07)
    Questo capitolo offre una panoramica delle tecnologie di database adatte ai servizi
    GenAI e illustra le migliori pratiche per lavorare con i database utilizzando
    strumenti collaudati come l''ORM SQLAlchemy e Alembic per facilitare le migrazioni.
    Infine, presenteremo Prisma, uno strumento di prossima uscita per generare un
    client di database completamente tipizzato e gestire automaticamente le migrazioni.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Parte III, "Protezione, ottimizzazione, test e distribuzione dei servizi di
    intelligenza artificiale".](part03.html#part3)'
  prefs: []
  type: TYPE_NORMAL
- en: In questa parte ci concentriamo sull'implementazione del livello di autenticazione
    per la gestione degli utenti, oltre che sui miglioramenti della sicurezza e dell'ottimizzazione.
    Ci concentreremo poi sui test e infine sul deploy del nostro servizio AI attraverso
    la containerizzazione.
  prefs: []
  type: TYPE_NORMAL
- en: '[Capitolo 8, "Autenticazione e autorizzazione":](ch08.html#ch08) In questo
    capitolo tratteremo l''implementazione dei livelli di autenticazione per la gestione
    degli utenti, al fine di proteggere e limitare l''accesso ai servizi di IA. Esamineremo
    e implementeremo diverse strategie di autenticazione, tra cui quella di base,
    quella basata sui token e quella OAuth. Introdurremo poi i modelli di autorizzazione,
    tra cui il controllo dell''accesso basato sui ruoli (RBAC) e spiegheremo il ruolo
    del grafo delle dipendenze di FastAPI in questo processo. Questo includerà l''aggiunta
    di permessi restrittivi per gli utenti in base ai ruoli, in modo che le interazioni
    con i servizi di IA possano essere moderate automaticamente.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Capitolo 9, "Messa in sicurezza dei servizi di intelligenza artificiale":](ch09.html#ch09)
    Questo capitolo offre una panoramica dei vettori di attacco più comuni per le
    soluzioni generative. Qui ci concentreremo sull''implementazione di varie misure
    di sicurezza nel nostro servizio di IA, come la limitazione del tasso e i guardrail,
    per proteggerci dagli output tossici del modello, dagli attacchi comuni, dagli
    abusi e dall''uso improprio.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Capitolo 10, "Ottimizzazione dei servizi di intelligenza artificiale":](ch10.html#ch10)
    Questo capitolo tratta diverse tecniche di ottimizzazione delle prestazioni come
    l''elaborazione in batch, il caching semantico e il prompt engineering per migliorare
    la qualità e la velocità dei servizi di IA.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Capitolo 11, "Test dei servizi AI":](ch11.html#ch11) Questo capitolo tratta
    le sfide e le migliori pratiche per testare i servizi di intelligenza artificiale.
    Passeremo in rassegna vari concetti di test, tra cui le fasi di test, i confini
    e i mock, per poi implementare i mock dei servizi esterni, mantenendo isolati
    gli ambienti di test. Infine, introdurremo un nuovo approccio per testare i modelli
    generativi di intelligenza artificiale anche quando producono output diversi nelle
    varie esecuzioni di test.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Capitolo 12, "Distribuzione dei servizi AI":](ch12.html#ch12) Questo capitolo
    tratta vari approcci di distribuzione, tra cui l''uso di macchine virtuali, funzioni
    cloud, servizi app gestiti e tecnologie di containerizzazione come Docker. Ci
    concentreremo quindi sui concetti di containerizzazione, come lo storage e il
    networking, per distribuire il nostro servizio AI utilizzando Docker.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Come leggere questo libro
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Questo libro può essere letto tutto d''un fiato oppure può essere utilizzato
    come riferimento per poter approfondire qualsiasi capitolo. In ogni capitolo spiego
    i concetti e confronto gli approcci prima di immergerci in esempi pratici di codice.
    Per questo motivo, ti consiglio di leggere ogni capitolo due volte: una volta
    per capire l''approccio e poi per ripassare gli esempi di codice usando il [repository
    di codice](https://github.com/Ali-Parandeh/building-generative-ai-services) allegato
    al libro.'
  prefs: []
  type: TYPE_NORMAL
- en: Suggerimento
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Sono un convinto sostenitore della spiegazione di concetti tecnici complessi
    con analogie, diagrammi e storie di tutti i giorni a cui chiunque può fare riferimento.
    Spesso questi vengono utilizzati dopo l'introduzione di un nuovo concetto complesso.
    Cerca sezioni di suggerimenti come questa per migliorare la tua comprensione dei
    concetti.
  prefs: []
  type: TYPE_NORMAL
- en: In definitiva, il modo migliore per imparare i concetti contenuti in questo
    libro è quello di mettere le mani su un modello generativo open source e poi costruire
    un servizio attorno ad esso utilizzando il tuo codice. Soprattutto, ti auguro
    di trovarlo utile e piacevole da leggere!
  prefs: []
  type: TYPE_NORMAL
- en: Requisiti hardware e software
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: L'esecuzione di modelli generativi è generalmente un'attività ad alta intensità
    di calcolo che richiede una GPU potente. Tuttavia, ho fatto del mio meglio per
    fornire esempi di codice che utilizzano piccoli modelli generativi open source
    che non richiedono una GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Solo alcuni capitoli contengono esempi di codice che richiedono l'accesso a
    una GPU per l'elaborazione di operazioni simultanee o per l'esecuzione di modelli
    più pesanti. In questi casi, ti consiglio di noleggiare una macchina virtuale
    con GPU NVIDIA abilitata a CUDA da qualsiasi provider cloud o di lavorare da un
    desktop con GPU abilitata a CUDA con un minimo di 16 GB di VRAM.
  prefs: []
  type: TYPE_NORMAL
- en: Consulta le istruzioni di installazione di NVIDIA CUDA per [Windows](https://oreil.ly/fgwVk)
    o [Linux](https://oreil.ly/3rMv2).
  prefs: []
  type: TYPE_NORMAL
- en: Infine, per eseguire i modelli su una GPU NVIDIA compatibile con CUDA, dovrai
    installare il pacchetto `torch` compilato per CUDA.
  prefs: []
  type: TYPE_NORMAL
- en: Convenzioni utilizzate in questo libro
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In questo libro vengono utilizzate le seguenti convenzioni tipografiche:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Corsivo*'
  prefs: []
  type: TYPE_NORMAL
- en: Indica nuovi termini, URL, indirizzi e-mail, nomi di file ed estensioni di file.
  prefs: []
  type: TYPE_NORMAL
- en: '`Constant width`'
  prefs: []
  type: TYPE_NORMAL
- en: Utilizzato per i listati dei programmi e all'interno dei paragrafi per fare
    riferimento a elementi del programma come nomi di variabili o funzioni, database,
    tipi di dati, variabili d'ambiente, dichiarazioni e parole chiave.
  prefs: []
  type: TYPE_NORMAL
- en: '*`Constant width italic`*'
  prefs: []
  type: TYPE_NORMAL
- en: Mostra il testo che deve essere sostituito con valori forniti dall'utente o
    con valori determinati dal contesto.
  prefs: []
  type: TYPE_NORMAL
- en: Suggerimento
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Questo elemento indica un consiglio o un suggerimento.
  prefs: []
  type: TYPE_NORMAL
- en: Nota
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Questo elemento indica una nota generale.
  prefs: []
  type: TYPE_NORMAL
- en: Avvertenze
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Questo elemento indica un avviso o un'avvertenza.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizzo di esempi di codice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Il libro è accompagnato da un repository di codice per i progetti guidati, disponibile
    per il download all'indirizzo [*https://github.com/Ali-Parandeh/building-generative-ai-services.*](https://github.com/Ali-Parandeh/building-generative-ai-services)
    Puoi trovare altre risorse, articoli e materiali di supporto sul sito web del
    libro all'indirizzo [*https://buildinggenai.com*](https://buildinggenai.com) [*.*](https://github.com/Ali-Parandeh/building-generative-ai-services)
  prefs: []
  type: TYPE_NORMAL
- en: 'Dopo aver scaricato e clonato il repository, puoi eseguire un''installazione
    locale. Ad esempio, se utilizzi `conda`, puoi seguire questo setup per creare
    il tuo ambiente `genaiservice`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Puoi quindi installare tutte le dipendenze necessarie nell''ambiente Python
    appena creato:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Ci sono più di 170 esempi di codice sparsi nei vari capitoli, che ti mostrano
    come costruire progressivamente un servizio di IA generativa pronto per la produzione
    con il framework web FastAPI. Ti illustreremo il codice per ogni passo, con indicazioni
    chiare che mostrano come il codice implementa la teoria alla base di ogni tecnica.
  prefs: []
  type: TYPE_NORMAL
- en: Il repository del codice contiene diversi rami che mappano lo stato del codice
    dell'applicazione all'inizio e alla fine di ogni capitolo, mentre gli esempi si
    sviluppano in modo incrementale. Gli esempi di codice sono organizzati per rami
    invece che per cartelle, per evitare il disordine e per fornire una base di codice
    pulita su cui lavorare. Il ramo `main` contiene lo stato finale del codice dell'applicazione
    alla fine del libro.
  prefs: []
  type: TYPE_NORMAL
- en: All'inizio di ogni capitolo, consulta il ramo `starter` corrispondente per seguire
    gli esempi di codice durante lo sviluppo dell'applicazione. Per esempio, all'inizio
    del [Capitolo 2](ch02.html#ch02), puoi consultare il ramo `ch02-start`. Se ti
    blocchi o vuoi vedere lo stato del repository alla fine di ogni capitolo, puoi
    consultare il ramo `end` corrispondente (cioè `ch02-end`) e confrontare il tuo
    codice con quello presente nel repository.
  prefs: []
  type: TYPE_NORMAL
- en: Nota
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Il repository di codice contiene istruzioni nel file *README.md* del ramo `main`
    su come clonare il repository e cambiare ramo se non hai familiarità con Git.
  prefs: []
  type: TYPE_NORMAL
- en: Ogni ramo conterrà anche un file *README.md* per guidarti negli elementi pratici
    del capitolo.
  prefs: []
  type: TYPE_NORMAL
- en: Nel corso del libro, fornirò ulteriori compiti ed esercizi per aiutarti a consolidare
    la comprensione dei concetti come parte del progetto guidato. Tieni d'occhio queste
    sezioni per le istruzioni sull'implementazione di questi compiti. Le soluzioni
    sono fornite all'interno del repository di codice. Tuttavia, ti consiglio di provare
    a risolvere questi compiti da solo prima di consultare le soluzioni. Tieni presente
    che possono esistere molte soluzioni per un determinato compito.
  prefs: []
  type: TYPE_NORMAL
- en: Se hai una domanda tecnica o un problema nell'utilizzo degli esempi di codice,
    invia un'e-mail a [*support@oreilly.com.*](mailto:support@oreilly.com)
  prefs: []
  type: TYPE_NORMAL
- en: In generale, se insieme a questo libro viene offerto del codice di esempio,
    puoi utilizzarlo nei tuoi programmi e nella tua documentazione. Non è necessario
    contattarci per ottenere l'autorizzazione, a meno che tu non stia riproducendo
    una parte significativa del codice. Ad esempio, scrivere un programma che utilizzi
    diverse parti di codice di questo libro non richiede l'autorizzazione. Vendere
    o distribuire esempi tratti dai libri di O'Reilly richiede l'autorizzazione. Rispondere
    a una domanda citando questo libro e citando il codice di esempio non richiede
    l'autorizzazione. Incorporare una quantità significativa di codice di esempio
    tratto da questo libro nella documentazione del tuo prodotto richiede l'autorizzazione.
  prefs: []
  type: TYPE_NORMAL
- en: Apprezziamo, ma generalmente non richiediamo, l'attribuzione. Un'attribuzione
    di solito include il titolo, l'autore, l'editore e l'ISBN. Ad esempio, "*Building
    Generative AI Services with FastAPI* by Alireza Parandeh (O'Reilly). Copyright
    2025 Ali Parandeh, 978-1-098-16030-2".
  prefs: []
  type: TYPE_NORMAL
- en: Se ritieni che il tuo utilizzo di esempi di codice non rientri nell'ambito del
    fair use o dei permessi sopra indicati, contattaci all'indirizzo [*permissions@oreilly.com.*](mailto:permissions@oreilly.com)
  prefs: []
  type: TYPE_NORMAL
- en: Formazione online O'Reilly
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nota
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Da oltre 40 anni, [*O'Reilly Media*](https://oreilly.com) fornisce formazione,
    conoscenze e approfondimenti tecnologici e commerciali per aiutare le aziende
    ad avere successo.
  prefs: []
  type: TYPE_NORMAL
- en: La nostra rete unica di esperti e innovatori condivide le proprie conoscenze
    e competenze attraverso libri, articoli e la nostra piattaforma di apprendimento
    online. La piattaforma di apprendimento online di O'Reilly ti dà accesso on-demand
    a corsi di formazione dal vivo, percorsi di apprendimento approfonditi, ambienti
    di codifica interattivi e una vasta collezione di testi e video di O'Reilly e
    di oltre 200 altri editori. Per maggiori informazioni, visita [*https://oreilly.com*](https://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: Come contattarci
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Ti invitiamo a rivolgere commenti e domande su questo libro all''editore:'
  prefs: []
  type: TYPE_NORMAL
- en: O'Reilly Media, Inc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1005 Gravenstein Highway North
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sebastopol, CA 95472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 800-889-8969 (negli Stati Uniti o in Canada)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-827-7019 (internazionale o locale)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-829-0104 (fax)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*support@oreilly.com*](mailto:support@oreilly.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abbiamo una pagina web dedicata a questo libro, dove elenchiamo gli errori,
    gli esempi e tutte le informazioni aggiuntive. Puoi accedere a questa pagina all'indirizzo
    [*https://oreil.ly/building-gen-ai-fastAPI.*](https://oreil.ly/building-gen-ai-fastAPI)
  prefs: []
  type: TYPE_NORMAL
- en: Per notizie e informazioni sui nostri libri e corsi, visita il sito [*https://oreilly.com.*](https://oreilly.com)
  prefs: []
  type: TYPE_NORMAL
- en: 'Trovaci su LinkedIn: [*https://linkedin.com/company/oreilly-media.*](https://linkedin.com/company/oreilly-media)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Guardaci su YouTube: [*https://youtube.com/oreillymedia.*](https://youtube.com/oreillymedia)'
  prefs: []
  type: TYPE_NORMAL
- en: Ringraziamenti
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Scrivere questo libro è stata un'esperienza e un viaggio incredibili per me.
    La mia più profonda gratitudine va alla mia famiglia per il suo sostegno incondizionato
    durante il processo di scrittura. Vorrei dare un riconoscimento speciale a mia
    sorella, Tara Parandeh; ai miei genitori, Mansoureh Tahabaz e Mohammadreza Parandeh;
    e alla mia compagna, Cherry Waller.
  prefs: []
  type: TYPE_NORMAL
- en: Sono grato agli amici, ai colleghi, ai collaboratori e al personale dell'ADSP
    che mi hanno aiutato a coltivare un ambiente favorevole. Grazie a David Foster,
    Ross Witeszczak, Amy Bull, Zine Eddine, Joe Rowe, Jonathan Davies, Aneta Blazyczek,
    Giulia Scardovi, Maddy Clements, Sarah Davies, Evelina Kireilyte, Khaleel Syed,
    Rob Foster, Mai Do, Bogdan Bija, Nicholas Rawitscher Torres, Snehan Sighat e Leon
    Watson.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particolare, vorrei ringraziare il mio mentore, David Foster, autore di
    *Generative Deep Learning* (O''Reilly), per avermi ispirato a scrivere il mio
    libro. Il suo libro è stato una fonte di apprendimento e di ispirazione sull''IA
    generativa durante il processo di stesura. Inoltre, sono grato agli amici più
    stretti che hanno contribuito a plasmare la mia carriera: Lee Dalchow, Isaac Cleave
    e Rabah Tahraoui.'
  prefs: []
  type: TYPE_NORMAL
- en: Lavorare con O'Reilly è stato incredibile. Un ringraziamento speciale va alle
    mie meravigliose editor Rita Fernando e Melissa Potter per il loro supporto durante
    il processo di scrittura, per l'entusiasmo e per l'eccellente feedback. Non avrei
    potuto chiedere editor migliori. Grazie a Clare Laylock per aver preparato i capitoli
    in anteprima e per aver risolto i problemi di formattazione durante il processo.
    Vedere questi capitoli sulla piattaforma O'Reilly e ricevere un feedback positivo
    da parte dei lettori è stata una motivazione importante per la scrittura. Grazie
    anche a Nicole Butterfield e Amanda Quinn per il loro aiuto nella realizzazione
    di questo libro e per aver dato il via al progetto.
  prefs: []
  type: TYPE_NORMAL
- en: Infine, un enorme ringraziamento va ai miei revisori tecnici, David Foster,
    Joe Rowe e Julien Brendel, per la loro meticolosa e dettagliata revisione del
    libro. Ogni revisore ha contribuito con una prospettiva diversa per garantire
    che tutte le incongruenze, le imprecisioni e le lacune fossero affrontate. Senza
    il loro contributo, la qualità di questo librone avrebbe risentito.
  prefs: []
  type: TYPE_NORMAL
