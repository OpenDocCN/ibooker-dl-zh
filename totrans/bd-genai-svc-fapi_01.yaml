- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Generative AI* (GenAI) is taking the world by storm since the release of technologies
    like ChatGPT. This new type of AI can create content in various *modalities* (such
    as text, audio, video, etc.) by learning to mimic patterns from its training data.
    With the increased advancement in GenAI capabilities, many businesses are investing
    in off-the-shelf or custom AI tools. These tools require maintainable and scalable
    backend services that can adapt to high demand.'
  prefs: []
  type: TYPE_NORMAL
- en: AI capabilities are exciting because they open the door to endless possibilities
    that unlock the potential for new tools. Before generative AI, developers had
    to write scripts and train optimization models to build automation and data pipelines
    for their processing of unstructured data like corpora of texts. This process
    could be tedious, error-prone, and applicable only to limited use cases. However,
    with the rise of GenAI models such as large language models (LLMs), we can now
    digest, compare, and summarize unstructured datasets and documents; reword complex
    ideas; and generate visualizations and illustrations.
  prefs: []
  type: TYPE_NORMAL
- en: While most generative models such as ChatGPT are excellent at what they do on
    their own, can you imagine the possibilities when we connect them to the internet,
    our own databases, and other services? If we can just “talk” to our services in
    natural language or give them some image, video, or audio and get them to do things
    for us, it opens up so many opportunities to create newly accessible and automated
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Chatbots are not the only apps that we can create with such generative models.
    There is so much more we can do. We can create backend service agents that can
    perform various complex tasks requiring comprehension, logical reasoning, and
    analysis of texts.
  prefs: []
  type: TYPE_NORMAL
- en: By connecting our generative models to existing services and the internet, we
    are giving our AI services additional data to enrich their understanding of the
    problem at hand. For instance, a company can use an open source, in-house, fine-tuned
    LLM to parse purchase orders, generate invoices, and validate data against their
    customer database before placing an order with a payment system. This is where
    generative models shine. Other use cases can include content management systems
    that can help users with generating content and website builders that can suggest
    imagery, icons, and user interface (UI) components to fast-track the site’s design.
  prefs: []
  type: TYPE_NORMAL
- en: There is a catch. LLMs and other generative models require heavy processing
    power and memory to function, and it is not clear what deployment patterns and
    integration layers the developers should use to leverage these models. Building
    generative AI services is challenging because you need to balance scalability,
    security, performance, and data privacy. You’ll also want the ability to moderate,
    retrain, and optimize these services for real-time inference. These challenges
    will be different for every organization, and how you build your generative AI
    services will depend on your existing software systems and services.
  prefs: []
  type: TYPE_NORMAL
- en: Existing resources and documentation provide the necessary information to get
    started with training custom models and fine-tuning large language models. However,
    most developers may continue to face challenges in packaging and deploying these
    novel generative models as part of existing software systems and services.
  prefs: []
  type: TYPE_NORMAL
- en: My aim with this book is to show you how to productionize GenAI by understanding
    the end-to-end process in building and deploying your own AI services with tools
    such as the FastAPI web framework.
  prefs: []
  type: TYPE_NORMAL
- en: Objective and Approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The objective of this book is to help you explore the challenges of developing,
    securing, testing, and deploying generative AI as services integrated with your
    own external systems and applications.
  prefs: []
  type: TYPE_NORMAL
- en: This book centers on constructing modular, type-safe generative AI services
    in FastAPI with seamless database schema handling support and model integration
    to power backends that can generate new data.
  prefs: []
  type: TYPE_NORMAL
- en: The significance of these topics stems from the growing demand for building
    flexible services that can adapt to changing requirements, maintain high performance,
    and scale efficiently using the microservice pattern.
  prefs: []
  type: TYPE_NORMAL
- en: You will also learn the process of enriching your services with contextual data
    from a variety of sources such as databases, the web, external systems, and files
    uploaded by users.
  prefs: []
  type: TYPE_NORMAL
- en: A few generative models require heavy processing power and memory to function.
    You will explore how to handle these models in production and how to scale your
    services to handle the load. You will also explore how to handle long-running
    tasks such as model inference.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we will discuss authentication concepts, security considerations, performance
    optimization, testing, and deployment of production-ready generative AI services.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book assumes no prior knowledge of generative AI and won’t require you
    to fully understand how generative models work. I will be covering the intuition
    of how such models generate data but will not dive into their underlying mathematics.
    However, if you want to learn more about building your own generative AI models
    in detail, I recommend [*Generative Deep Learning*](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/)
    by David Foster (O’Reilly, 2024).
  prefs: []
  type: TYPE_NORMAL
- en: As this is a FastAPI book for generative AI applications, I do assume some familiarity
    with this web framework. If you need a refresher or would like to expand your
    understanding of FastAPI features, I recommend reading [*FastAPI*](https://www.oreilly.com/library/view/fastapi/9781098135492/)
    by Bill Lubanovic (O’Reilly, 2023). However, this is not a requirement for following
    along with this book.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the book does assume some experience with Python, with Docker for
    deployment, with how the web works, and with communicating through the HTTP protocol.
  prefs: []
  type: TYPE_NORMAL
- en: To brush up on your Python skills, I highly recommend visiting [realpython.org](https://realpython.org)
    for excellent tutorials on more advanced concepts. The official [Docker website](https://www.docker.com)
    also provides an excellent practical tutorial on containerization and writing
    Dockerfiles.
  prefs: []
  type: TYPE_NORMAL
- en: I will not be covering the fundamentals of the web in this book, but I highly
    recommend [MDN’s documentation](https://oreil.ly/vvwzI) as a starting point.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the book won’t require knowledge of deep learning frameworks such as
    Tensorflow and Keras. Where relevant, you’ll be introduced to these frameworks.
    Instead, we will mostly work with pretrained models hosted on the [Hugging Face
    model repository](https://oreil.ly/vC0DA).
  prefs: []
  type: TYPE_NORMAL
- en: Book Structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The book is broken into three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Part I, “Developing AI Services”](part01.html#part1)'
  prefs: []
  type: TYPE_NORMAL
- en: This part covers all the necessary steps to set up a FastAPI project that will
    power your GenAI service. You will learn to integrate various generative models
    into a type-safe FastAPI application and expose endpoints to interact with them.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 1, “Introduction”](ch01.html#ch01): This chapter discusses the importance
    of GenAI in the future and introduces the practical projects you’ll build throughout
    the book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 2, “Getting Started with FastAPI”](ch02.html#ch02): This chapter introduces
    FastAPI, a modern framework for building AI services. You will understand its
    features, limitations, and how it compares to other web frameworks. By the end
    of this chapter, you will be able to start creating FastAPI applications, progressively
    organize projects, and migrate from frameworks like Flask or Django.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 3, “AI Integration and Model Serving”](ch03.html#ch03): This chapter
    covers the full process of integrating and serving various GenAI models (including
    language, audio, vision, and 3D models) as a FastAPI service using application
    lifespan. We’ll review various strategies for model serving like preloading, externalizing,
    and monitoring models with middleware.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 4, “Implementing Type-Safe AI Services”](ch04.html#ch04): This chapter
    introduces the concept of type-safety and how Python’s type annotations and data
    validation tools like Pydantic can help validate and serialize data running past
    your AI services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Part II, “Communicating with External Systems”](part02.html#part2)'
  prefs: []
  type: TYPE_NORMAL
- en: In this part, we’ll integrate our AI services with external systems such as
    databases and learn how to serve concurrent users. We will also implement real-time
    streaming of model outputs.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 5, “Achieving Concurrency in AI Workloads”](ch05.html#ch05): This
    chapter introduces the concepts of concurrency and parallelism alongside comparing
    different strategies for solving concurrency problems. We’ll review the purpose
    of asynchronous programming in handling long-running and blocking tasks and review
    the limitations of Python’s Global Interpreter Lock (GIL) when handling these
    asynchronous processes. To practice, we’ll implement a working “talk to the web
    and your documents” chatbot using a technique called *retrieval augmented generation*
    (RAG). Finally, we’ll cover FastAPI’s background tasks feature for tackling long-running
    operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 6, “Real-Time Communication with Generative Models”](ch06.html#ch06):
    In this chapter, we will focus on enabling real-time client-server communication
    with generative models. As part of this, we’ll compare various mechanisms such
    as web sockets and server streaming events when streaming data to/from generative
    models with practical examples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 7, “Integrating Databases into AI Services”](ch07.html#ch07): This
    chapter provides an overview of database technologies suitable for GenAI services.
    We’ll cover best practices when working with databases using battle-tested tools
    such as SQLAlchemy ORM and Alembic for facilitating migrations. Finally, we’ll
    introduce Prisma, an upcoming tool for generating a fully typed database client
    and automatic handling of migrations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Part III, “Securing, Optimizing, Testing, and Deploying AI Services”](part03.html#part3)'
  prefs: []
  type: TYPE_NORMAL
- en: In this part, we focus on implementing the authentication layer for user management,
    alongside security and optimization enhancements. We’ll then shift our focus on
    testing and finally deploying our AI service through containerization.
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 8, “Authentication and Authorization”](ch08.html#ch08): In this chapter,
    we will cover the implementation of authentication layers for user management
    to secure, protect, and restrict access to AI services. We’ll review and implement
    various authentication strategies including basic, token-based, and OAuth. We’ll
    then introduce authorization models including role-based access control (RBAC)
    and explain the role of FastAPI’s dependency graph in the process. This will include
    adding restrictive permissions for users based on roles where AI service interactions
    can be automatically moderated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 9, “Securing AI Services”](ch09.html#ch09): This chapter provides
    an overview of common attack vectors for generative solutions. Here, we’ll shift
    focus on implementing various security measures across our AI service, such as
    rate limiting and guardrails, to protect against toxic model outputs, common attacks,
    abuse, and misuse.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 10, “Optimizing AI Services”](ch10.html#ch10): This chapter covers
    various performance optimization techniques like batch processing, semantic caching,
    and prompt engineering for enhancing the quality and speed of AI services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 11, “Testing AI Services”](ch11.html#ch11): This chapter covers the
    challenges and best practices in testing AI services. We’ll review various testing
    concepts including testing phases, boundaries, and mocks and then implement mocks
    of external services, keeping test environments isolated. Finally, we’ll introduce
    a novel approach to testing generative AI models even when they produce varying
    outputs across test runs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 12, “Deployment of AI Services”](ch12.html#ch12): This chapter covers
    various deployment approaches including the use of virtual machines, cloud functions,
    managed app services, and containerization technologies like Docker. We’ll then
    focus on containerization concepts, such as storage and networking, for deploying
    our AI service using Docker.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to Read This Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This book can be read cover to cover or used as a reference so you can dip
    into any chapter. In every chapter, I explain the concepts and compare approaches
    before we dive into practical code examples. Therefore, I recommend reading each
    chapter twice: once to understand the approach and then revisiting them to work
    through the code examples yourself using this book’s accompanying [code repository](https://github.com/Ali-Parandeh/building-generative-ai-services).'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: I am a firm believer in explaining complex technical concepts with everyday
    analogies, diagrams, and stories that anyone can relate to. These are often used
    after a new complex concept is introduced. Look out for tip sections like this
    one to help improve your understanding of the concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, the best way to learn the concepts in this book is to get your hands
    on an open source generative model and then build a service around it using your
    own code. Above all, I hope you find it a useful and enjoyable read!
  prefs: []
  type: TYPE_NORMAL
- en: Hardware and Software Requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running generative models is generally a compute-intensive task that requires
    a strong GPU. However, I’ve tried my best to provide code examples that use small
    open source generative models that won’t require a GPU.
  prefs: []
  type: TYPE_NORMAL
- en: Only a few chapters will have code examples that require you to have access
    to a GPU to process concurrent operations or to run heavier models. In such cases,
    I recommend renting a virtual machine with CUDA-enabled NVIDIA GPUs from any cloud
    provider or to work from a CUDA-enabled GPU desktop with a minimum of 16 GB of
    VRAM.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to NVIDIA’s CUDA installation instructions for [Windows](https://oreil.ly/fgwVk)
    or [Linux](https://oreil.ly/3rMv2).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to run models on a CUDA-enabled NVIDIA GPU, you will also need to install
    the `torch` package compiled for CUDA.
  prefs: []
  type: TYPE_NORMAL
- en: Conventions Used in This Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following typographical conventions are used in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Italic*'
  prefs: []
  type: TYPE_NORMAL
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  prefs: []
  type: TYPE_NORMAL
- en: '`Constant width`'
  prefs: []
  type: TYPE_NORMAL
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  prefs: []
  type: TYPE_NORMAL
- en: '*`Constant width italic`*'
  prefs: []
  type: TYPE_NORMAL
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element signifies a tip or suggestion.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element signifies a general note.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This element indicates a warning or caution.
  prefs: []
  type: TYPE_NORMAL
- en: Using Code Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The book accompanies a code repository for the guided projects. This repository
    is available for download at [*https://github.com/Ali-Parandeh/building-generative-ai-services*](https://github.com/Ali-Parandeh/building-generative-ai-services).
    You can also find additional resources, articles, and supporting materials on
    the book’s companion website at [*https://buildinggenai.com*](https://buildinggenai.com).
  prefs: []
  type: TYPE_NORMAL
- en: 'After downloading and cloning the repository, you can perform a local installation.
    For example, if using `conda`, you can follow this setup to create your `genaiservice`
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You can then install all the necessary dependencies in your newly created Python
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: There are around 170+ code examples scattered across the chapters. These code
    examples show you how to progressively build a production-ready generative AI
    service with the FastAPI web framework. We will walk through the code for each
    step-by-step, with clear signposts that show how the code implements the theory
    underpinning each technique.
  prefs: []
  type: TYPE_NORMAL
- en: The code repository contains several branches that map the state of application
    code to the start and end of each chapter as examples incrementally build on one
    another. The code examples are organized by branches instead of folders to avoid
    clutter and to provide you with a clean codebase to work from. The `main` branch
    contains the final state of the application code at the end of the book.
  prefs: []
  type: TYPE_NORMAL
- en: At the start of each chapter, check out the relevant `starter` branch to follow
    along with the code examples as you develop the application. For instance, at
    the start of [Chapter 2](ch02.html#ch02), you can check out the `ch02-start` branch.
    If you get stuck or want to view the repository state at the end of each chapter,
    you can then check out the corresponding `end` branch (i.e., `ch02-end`) and compare
    your code with the code in the repository.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The code repository contains instructions in the *README.md* file on the `main`
    branch on how to clone the repository and switch branches if you’re not familiar
    with Git.
  prefs: []
  type: TYPE_NORMAL
- en: Each branch will also contain a *README.md* file to guide you with the practical
    elements of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the book, I will provide additional tasks and exercises to help solidify
    your understanding of the concepts as part of the guided project. Look out for
    these sections for instructions on implementing these tasks. Solutions are provided
    within the code repository. However, I recommend trying to solve these tasks on
    your own before consulting the solutions. Please note that many solutions can
    exist for a given task.
  prefs: []
  type: TYPE_NORMAL
- en: If you have a technical question or a problem using the code examples, please
    send an email to [*support@oreilly.com*](mailto:support@oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing examples
    from O’Reilly books does require permission. Answering a question by citing this
    book and quoting example code does not require permission. Incorporating a significant
    amount of example code from this book into your product’s documentation does require
    permission.
  prefs: []
  type: TYPE_NORMAL
- en: We appreciate, but generally do not require, attribution. An attribution usually
    includes the title, author, publisher, and ISBN. For example, “*Building Generative
    AI Services with FastAPI* by Alireza Parandeh (O’Reilly). Copyright 2025 Ali Parandeh,
    978-1-098-16030-2.”
  prefs: []
  type: TYPE_NORMAL
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: O’Reilly Online Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For more than 40 years, [*O’Reilly Media*](https://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  prefs: []
  type: TYPE_NORMAL
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*https://oreilly.com*](https://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: How to Contact Us
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please address comments and questions concerning this book to the publisher:'
  prefs: []
  type: TYPE_NORMAL
- en: O’Reilly Media, Inc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 1005 Gravenstein Highway North
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sebastopol, CA 95472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 800-889-8969 (in the United States or Canada)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-827-7019 (international or local)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 707-829-0104 (fax)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*support@oreilly.com*](mailto:support@oreilly.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/building-gen-ai-fastAPI*](https://oreil.ly/building-gen-ai-fastAPI).
  prefs: []
  type: TYPE_NORMAL
- en: For news and information about our books and courses, visit [*https://oreilly.com*](https://oreilly.com).
  prefs: []
  type: TYPE_NORMAL
- en: 'Find us on LinkedIn: [*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Watch us on YouTube: [*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia).'
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Writing this book has been an incredible experience and journey for me. My deepest
    gratitude to my family for their unconditional support during the writing process.
    I would like to give special recognition to my sister, Tara Parandeh; my parents,
    Mansoureh Tahabaz and Mohammadreza Parandeh; and my partner, Cherry Waller.
  prefs: []
  type: TYPE_NORMAL
- en: I’m grateful to the friends, colleagues, collaborators, and ADSP folks who helped
    cultivate a supportive environment. Thank you to David Foster, Ross Witeszczak,
    Amy Bull, Zine Eddine, Joe Rowe, Jonathan Davies, Aneta Blazyczek, Giulia Scardovi,
    Maddy Clements, Sarah Davies, Evelina Kireilyte, Khaleel Syed, Rob Foster, Mai
    Do, Bogdan Bija, Nicholas Rawitscher Torres, Snehan Sighat, and Leon Watson.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, I would like to thank my mentor, David Foster, author of *Generative
    Deep Learning* (O’Reilly), for inspiring me to write my own book. His book was
    a source of learning and inspiration on generative AI during the drafting process.
    In addition, I’m grateful to the close friends who played a role in shaping my
    career: Lee Dalchow, Isaac Cleave, and Rabah Tahraoui.'
  prefs: []
  type: TYPE_NORMAL
- en: Working with O’Reilly was incredible. Special thanks to my wonderful editors
    Rita Fernando and Melissa Potter for their support during the writing process,
    enthusiasm, and excellent feedback. I could not have asked for better editors.
    Thanks to Clare Laylock for preparing early release chapters and fixing formatting
    issues during the process. Seeing these chapters on the O’Reilly platform and
    receiving positive feedback from readers was a significant motivator with writing.
    Also thanks to Nicole Butterfield and Amanda Quinn for their help in realizing
    this book and kick-starting the project.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, massive thanks to my technical reviewers, David Foster, Joe Rowe, and
    Julien Brendel, for their meticulous and detailed run-through of the book. Each
    reviewer contributed a different perspective to ensure all inconsistencies, inaccuracies,
    and gaps were addressed. Without their input, the quality of this book would have
    suffered.
  prefs: []
  type: TYPE_NORMAL
