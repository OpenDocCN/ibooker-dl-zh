- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: '*Generative AI* (GenAI) is taking the world by storm since the release of technologies
    like ChatGPT. This new type of AI can create content in various *modalities* (such
    as text, audio, video, etc.) by learning to mimic patterns from its training data.
    With the increased advancement in GenAI capabilities, many businesses are investing
    in off-the-shelf or custom AI tools. These tools require maintainable and scalable
    backend services that can adapt to high demand.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 自从ChatGPT等技术的发布以来，*生成式人工智能*（GenAI）正席卷全球。这种新型人工智能通过学习模仿其训练数据中的模式，能够在各种*模态*（如文本、音频、视频等）中创建内容。随着生成式AI能力的不断提高，许多企业正在投资现成的或定制的AI工具。这些工具需要可维护和可扩展的后端服务，以适应高需求。
- en: AI capabilities are exciting because they open the door to endless possibilities
    that unlock the potential for new tools. Before generative AI, developers had
    to write scripts and train optimization models to build automation and data pipelines
    for their processing of unstructured data like corpora of texts. This process
    could be tedious, error-prone, and applicable only to limited use cases. However,
    with the rise of GenAI models such as large language models (LLMs), we can now
    digest, compare, and summarize unstructured datasets and documents; reword complex
    ideas; and generate visualizations and illustrations.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的能力令人兴奋，因为它们打开了通往无限可能的大门，释放了新工具的潜力。在生成式人工智能出现之前，开发者必须编写脚本和训练优化模型来构建自动化和数据管道，以处理诸如文本语料库之类的非结构化数据。这个过程可能很繁琐，容易出错，并且仅适用于有限的用例。然而，随着大型语言模型（LLMs）等生成式AI模型的兴起，我们现在可以消化、比较和总结非结构化数据集和文档；重新措辞复杂的思想；并生成可视化和插图。
- en: While most generative models such as ChatGPT are excellent at what they do on
    their own, can you imagine the possibilities when we connect them to the internet,
    our own databases, and other services? If we can just “talk” to our services in
    natural language or give them some image, video, or audio and get them to do things
    for us, it opens up so many opportunities to create newly accessible and automated
    applications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数生成式模型，如ChatGPT，在各自领域表现出色，你能想象当我们将它们连接到互联网、我们的数据库和其他服务时会有什么可能性吗？如果我们能够用自然语言“交谈”我们的服务，或者给他们一些图像、视频或音频，并让他们为我们做事，这将为创建新的可访问和自动化的应用程序打开无数机会。
- en: Chatbots are not the only apps that we can create with such generative models.
    There is so much more we can do. We can create backend service agents that can
    perform various complex tasks requiring comprehension, logical reasoning, and
    analysis of texts.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人并不是我们能够使用这种生成式模型创建的唯一应用程序。我们还能做更多的事情。我们可以创建后端服务代理，它们可以执行需要理解、逻辑推理和文本分析的各种复杂任务。
- en: By connecting our generative models to existing services and the internet, we
    are giving our AI services additional data to enrich their understanding of the
    problem at hand. For instance, a company can use an open source, in-house, fine-tuned
    LLM to parse purchase orders, generate invoices, and validate data against their
    customer database before placing an order with a payment system. This is where
    generative models shine. Other use cases can include content management systems
    that can help users with generating content and website builders that can suggest
    imagery, icons, and user interface (UI) components to fast-track the site’s design.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将我们的生成式模型连接到现有服务和互联网，我们正在为我们的AI服务提供额外的数据，以丰富他们对当前问题的理解。例如，一家公司可以使用开源的、定制的、微调的大型语言模型来解析采购订单、生成发票，并在向支付系统下单之前验证数据与客户数据库的一致性。这正是生成式模型大放异彩的地方。其他用例可能包括内容管理系统，可以帮助用户生成内容，以及可以建议图像、图标和用户界面（UI）组件以加快网站设计的网站构建器。
- en: There is a catch. LLMs and other generative models require heavy processing
    power and memory to function, and it is not clear what deployment patterns and
    integration layers the developers should use to leverage these models. Building
    generative AI services is challenging because you need to balance scalability,
    security, performance, and data privacy. You’ll also want the ability to moderate,
    retrain, and optimize these services for real-time inference. These challenges
    will be different for every organization, and how you build your generative AI
    services will depend on your existing software systems and services.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 但有一个问题。大型语言模型和其他生成模型需要大量的处理能力和内存才能运行，目前尚不清楚开发者应该使用哪些部署模式和集成层来利用这些模型。构建生成式AI服务具有挑战性，因为你需要平衡可扩展性、安全性、性能和数据隐私。你还将希望拥有对服务进行监管、重新训练和优化以进行实时推理的能力。这些挑战对每个组织来说都不同，你构建生成式AI服务的方式将取决于你现有的软件系统和服务。
- en: Existing resources and documentation provide the necessary information to get
    started with training custom models and fine-tuning large language models. However,
    most developers may continue to face challenges in packaging and deploying these
    novel generative models as part of existing software systems and services.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的资源和文档提供了开始训练自定义模型和微调大型语言模型所需的信息。然而，大多数开发者可能仍然会面临将这些新颖的生成模型作为现有软件系统和服务的部分进行打包和部署的挑战。
- en: My aim with this book is to show you how to productionize GenAI by understanding
    the end-to-end process in building and deploying your own AI services with tools
    such as the FastAPI web framework.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我写这本书的目的是通过理解构建和部署你自己的AI服务（使用如FastAPI网络框架等工具）的端到端过程，向你展示如何将GenAI投入生产。
- en: Objective and Approach
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标和方法
- en: The objective of this book is to help you explore the challenges of developing,
    securing, testing, and deploying generative AI as services integrated with your
    own external systems and applications.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是帮助你探索将生成式AI作为服务与你的外部系统和应用程序集成时在开发、安全、测试和部署过程中面临的挑战。
- en: This book centers on constructing modular, type-safe generative AI services
    in FastAPI with seamless database schema handling support and model integration
    to power backends that can generate new data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本书侧重于在FastAPI中构建模块化、类型安全的生成式AI服务，并支持无缝的数据库模式处理和模型集成，以支持能够生成新数据的后端。
- en: The significance of these topics stems from the growing demand for building
    flexible services that can adapt to changing requirements, maintain high performance,
    and scale efficiently using the microservice pattern.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些主题的重要性源于对构建能够适应变化需求、保持高性能并使用微服务模式高效扩展的灵活服务的日益增长的需求。
- en: You will also learn the process of enriching your services with contextual data
    from a variety of sources such as databases, the web, external systems, and files
    uploaded by users.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你还将学习如何通过从数据库、网络、外部系统和用户上传的文件等多种来源获取的上下文数据来丰富你的服务。
- en: A few generative models require heavy processing power and memory to function.
    You will explore how to handle these models in production and how to scale your
    services to handle the load. You will also explore how to handle long-running
    tasks such as model inference.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一些生成模型需要大量的处理能力和内存才能运行。你将探索如何在生产中处理这些模型，以及如何扩展你的服务以处理负载。你还将探索如何处理长时间运行的任务，如模型推理。
- en: Finally, we will discuss authentication concepts, security considerations, performance
    optimization, testing, and deployment of production-ready generative AI services.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将讨论身份验证概念、安全考虑、性能优化、测试和部署生产就绪的生成式AI服务。
- en: Prerequisites
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 先决条件
- en: This book assumes no prior knowledge of generative AI and won’t require you
    to fully understand how generative models work. I will be covering the intuition
    of how such models generate data but will not dive into their underlying mathematics.
    However, if you want to learn more about building your own generative AI models
    in detail, I recommend [*Generative Deep Learning*](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/)
    by David Foster (O’Reilly, 2024).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本书假设你对生成式AI没有先前的知识，并且不会要求你完全理解生成模型的工作原理。我将涵盖这些模型生成数据的直觉，但不会深入其背后的数学。然而，如果你想详细了解如何构建自己的生成式AI模型，我推荐David
    Foster的[*生成式深度学习*](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/)（O’Reilly，2024年）。
- en: As this is a FastAPI book for generative AI applications, I do assume some familiarity
    with this web framework. If you need a refresher or would like to expand your
    understanding of FastAPI features, I recommend reading [*FastAPI*](https://www.oreilly.com/library/view/fastapi/9781098135492/)
    by Bill Lubanovic (O’Reilly, 2023). However, this is not a requirement for following
    along with this book.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, the book does assume some experience with Python, with Docker for
    deployment, with how the web works, and with communicating through the HTTP protocol.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: To brush up on your Python skills, I highly recommend visiting [realpython.org](https://realpython.org)
    for excellent tutorials on more advanced concepts. The official [Docker website](https://www.docker.com)
    also provides an excellent practical tutorial on containerization and writing
    Dockerfiles.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: I will not be covering the fundamentals of the web in this book, but I highly
    recommend [MDN’s documentation](https://oreil.ly/vvwzI) as a starting point.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the book won’t require knowledge of deep learning frameworks such as
    Tensorflow and Keras. Where relevant, you’ll be introduced to these frameworks.
    Instead, we will mostly work with pretrained models hosted on the [Hugging Face
    model repository](https://oreil.ly/vC0DA).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Book Structure
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The book is broken into three parts:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[Part I, “Developing AI Services”](part01.html#part1)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: This part covers all the necessary steps to set up a FastAPI project that will
    power your GenAI service. You will learn to integrate various generative models
    into a type-safe FastAPI application and expose endpoints to interact with them.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 1, “Introduction”](ch01.html#ch01): This chapter discusses the importance
    of GenAI in the future and introduces the practical projects you’ll build throughout
    the book.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 2, “Getting Started with FastAPI”](ch02.html#ch02): This chapter introduces
    FastAPI, a modern framework for building AI services. You will understand its
    features, limitations, and how it compares to other web frameworks. By the end
    of this chapter, you will be able to start creating FastAPI applications, progressively
    organize projects, and migrate from frameworks like Flask or Django.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 3, “AI Integration and Model Serving”](ch03.html#ch03): This chapter
    covers the full process of integrating and serving various GenAI models (including
    language, audio, vision, and 3D models) as a FastAPI service using application
    lifespan. We’ll review various strategies for model serving like preloading, externalizing,
    and monitoring models with middleware.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 4, “Implementing Type-Safe AI Services”](ch04.html#ch04): This chapter
    introduces the concept of type-safety and how Python’s type annotations and data
    validation tools like Pydantic can help validate and serialize data running past
    your AI services.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Part II, “Communicating with External Systems”](part02.html#part2)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: In this part, we’ll integrate our AI services with external systems such as
    databases and learn how to serve concurrent users. We will also implement real-time
    streaming of model outputs.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分中，我们将集成我们的AI服务与外部系统，如数据库，并学习如何服务并发用户。我们还将实现模型输出的实时流。
- en: '[Chapter 5, “Achieving Concurrency in AI Workloads”](ch05.html#ch05): This
    chapter introduces the concepts of concurrency and parallelism alongside comparing
    different strategies for solving concurrency problems. We’ll review the purpose
    of asynchronous programming in handling long-running and blocking tasks and review
    the limitations of Python’s Global Interpreter Lock (GIL) when handling these
    asynchronous processes. To practice, we’ll implement a working “talk to the web
    and your documents” chatbot using a technique called *retrieval augmented generation*
    (RAG). Finally, we’ll cover FastAPI’s background tasks feature for tackling long-running
    operations.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第5章，“在AI工作负载中实现并发”](ch05.html#ch05)：本章介绍了并发和并行性的概念，并比较了解决并发问题的不同策略。我们将回顾异步编程在处理长时间运行和阻塞任务中的作用，并回顾Python的全局解释器锁（GIL）在处理这些异步进程时的局限性。为了实践，我们将使用称为*检索增强生成*（RAG）的技术实现一个“与网络和文档交谈”的聊天机器人。最后，我们将介绍FastAPI的背景任务功能，用于处理长时间运行的操作。'
- en: '[Chapter 6, “Real-Time Communication with Generative Models”](ch06.html#ch06):
    In this chapter, we will focus on enabling real-time client-server communication
    with generative models. As part of this, we’ll compare various mechanisms such
    as web sockets and server streaming events when streaming data to/from generative
    models with practical examples.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第6章，“使用生成模型进行实时通信”](ch06.html#ch06)：在本章中，我们将专注于实现使用生成模型进行实时客户端-服务器通信。作为其中的一部分，我们将通过实际示例比较各种机制，例如WebSocket和服务器流事件，当在生成模型之间传输数据时。'
- en: '[Chapter 7, “Integrating Databases into AI Services”](ch07.html#ch07): This
    chapter provides an overview of database technologies suitable for GenAI services.
    We’ll cover best practices when working with databases using battle-tested tools
    such as SQLAlchemy ORM and Alembic for facilitating migrations. Finally, we’ll
    introduce Prisma, an upcoming tool for generating a fully typed database client
    and automatic handling of migrations.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第7章，“将数据库集成到AI服务中”](ch07.html#ch07)：本章提供了适用于GenAI服务的数据库技术的概述。我们将介绍在使用数据库时的一些最佳实践，例如使用经过实战检验的工具如SQLAlchemy
    ORM和Alembic来促进迁移。最后，我们将介绍Prisma，这是一个即将推出的工具，用于生成一个完全类型化的数据库客户端，并自动处理迁移。'
- en: '[Part III, “Securing, Optimizing, Testing, and Deploying AI Services”](part03.html#part3)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[第三部分，“保护、优化、测试和部署AI服务”](part03.html#part3)'
- en: In this part, we focus on implementing the authentication layer for user management,
    alongside security and optimization enhancements. We’ll then shift our focus on
    testing and finally deploying our AI service through containerization.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分中，我们专注于实现用户管理的身份验证层，以及安全和优化增强。然后，我们将转向测试，最后通过容器化部署我们的AI服务。
- en: '[Chapter 8, “Authentication and Authorization”](ch08.html#ch08): In this chapter,
    we will cover the implementation of authentication layers for user management
    to secure, protect, and restrict access to AI services. We’ll review and implement
    various authentication strategies including basic, token-based, and OAuth. We’ll
    then introduce authorization models including role-based access control (RBAC)
    and explain the role of FastAPI’s dependency graph in the process. This will include
    adding restrictive permissions for users based on roles where AI service interactions
    can be automatically moderated.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第8章，“身份验证和授权”](ch08.html#ch08)：在本章中，我们将介绍为用户管理实现身份验证层，以保护、保护和限制对AI服务的访问。我们将回顾并实现各种身份验证策略，包括基本、基于令牌和OAuth。然后，我们将介绍授权模型，包括基于角色的访问控制（RBAC），并解释FastAPI的依赖关系图在过程中的作用。这包括根据角色添加限制性权限，以便AI服务交互可以自动进行监管。'
- en: '[Chapter 9, “Securing AI Services”](ch09.html#ch09): This chapter provides
    an overview of common attack vectors for generative solutions. Here, we’ll shift
    focus on implementing various security measures across our AI service, such as
    rate limiting and guardrails, to protect against toxic model outputs, common attacks,
    abuse, and misuse.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第9章，“保护AI服务”](ch09.html#ch09)：本章提供了对生成解决方案常见攻击向量的概述。在这里，我们将重点转向在AI服务中实施各种安全措施，例如速率限制和防护栏，以保护免受有毒模型输出、常见攻击、滥用和误用的侵害。'
- en: '[Chapter 10, “Optimizing AI Services”](ch10.html#ch10): This chapter covers
    various performance optimization techniques like batch processing, semantic caching,
    and prompt engineering for enhancing the quality and speed of AI services.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第10章，“优化AI服务”](ch10.html#ch10)：本章涵盖了各种性能优化技术，如批量处理、语义缓存和提示工程，以增强AI服务的质量和速度。'
- en: '[Chapter 11, “Testing AI Services”](ch11.html#ch11): This chapter covers the
    challenges and best practices in testing AI services. We’ll review various testing
    concepts including testing phases, boundaries, and mocks and then implement mocks
    of external services, keeping test environments isolated. Finally, we’ll introduce
    a novel approach to testing generative AI models even when they produce varying
    outputs across test runs.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第11章，“测试AI服务”](ch11.html#ch11)：本章涵盖了测试AI服务的挑战和最佳实践。我们将回顾各种测试概念，包括测试阶段、边界和模拟，然后实现外部服务的模拟，保持测试环境隔离。最后，我们将介绍一种新颖的测试生成AI模型的方法，即使它们在测试运行中产生不同的输出。'
- en: '[Chapter 12, “Deployment of AI Services”](ch12.html#ch12): This chapter covers
    various deployment approaches including the use of virtual machines, cloud functions,
    managed app services, and containerization technologies like Docker. We’ll then
    focus on containerization concepts, such as storage and networking, for deploying
    our AI service using Docker.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第12章，“AI服务的部署”](ch12.html#ch12)：本章涵盖了各种部署方法，包括使用虚拟机、云函数、托管应用服务和像Docker这样的容器化技术。然后我们将重点关注容器化概念，如存储和网络，以使用Docker部署我们的AI服务。'
- en: How to Read This Book
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何阅读本书
- en: 'This book can be read cover to cover or used as a reference so you can dip
    into any chapter. In every chapter, I explain the concepts and compare approaches
    before we dive into practical code examples. Therefore, I recommend reading each
    chapter twice: once to understand the approach and then revisiting them to work
    through the code examples yourself using this book’s accompanying [code repository](https://github.com/Ali-Parandeh/building-generative-ai-services).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 本书可以逐章阅读，也可以作为参考，您可以随时查阅任何章节。在每一章中，我在我们深入实际代码示例之前，都会解释概念并比较方法。因此，我建议您阅读每一章两次：一次是为了理解方法，然后再次回顾它们，使用本书附带的[代码仓库](https://github.com/Ali-Parandeh/building-generative-ai-services)亲自处理代码示例。
- en: Tip
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: I am a firm believer in explaining complex technical concepts with everyday
    analogies, diagrams, and stories that anyone can relate to. These are often used
    after a new complex concept is introduced. Look out for tip sections like this
    one to help improve your understanding of the concepts.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我坚信用日常类比、图表和故事来解释复杂的技术概念，任何人都能与之产生共鸣。这些通常在介绍新的复杂概念之后使用。注意像这样的提示部分，以帮助提高您对这些概念的理解。
- en: Ultimately, the best way to learn the concepts in this book is to get your hands
    on an open source generative model and then build a service around it using your
    own code. Above all, I hope you find it a useful and enjoyable read!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，学习本书中的概念的最佳方法是亲自尝试开源生成模型，然后使用您自己的代码围绕它构建服务。最重要的是，我希望您发现这是一本有用且愉快的读物！
- en: Hardware and Software Requirements
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 硬件和软件要求
- en: Running generative models is generally a compute-intensive task that requires
    a strong GPU. However, I’ve tried my best to provide code examples that use small
    open source generative models that won’t require a GPU.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 运行生成模型通常是一个计算密集型任务，需要强大的GPU。然而，我已经尽力提供使用小型开源生成模型的代码示例，这些模型不需要GPU。
- en: Only a few chapters will have code examples that require you to have access
    to a GPU to process concurrent operations or to run heavier models. In such cases,
    I recommend renting a virtual machine with CUDA-enabled NVIDIA GPUs from any cloud
    provider or to work from a CUDA-enabled GPU desktop with a minimum of 16 GB of
    VRAM.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 只有少数章节会有需要您访问GPU以处理并发操作或运行更重模型的代码示例。在这种情况下，我建议从任何云服务提供商那里租用具有CUDA启用的NVIDIA GPU的虚拟机，或者在一个具有至少16
    GB VRAM的CUDA启用的GPU台式机上工作。
- en: Please refer to NVIDIA’s CUDA installation instructions for [Windows](https://oreil.ly/fgwVk)
    or [Linux](https://oreil.ly/3rMv2).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅NVIDIA的CUDA安装说明，适用于[Windows](https://oreil.ly/fgwVk)或[Linux](https://oreil.ly/3rMv2)。
- en: Finally, to run models on a CUDA-enabled NVIDIA GPU, you will also need to install
    the `torch` package compiled for CUDA.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，要在CUDA启用的NVIDIA GPU上运行模型，您还需要安装为CUDA编译的`torch`包。
- en: Conventions Used in This Book
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书使用的约定
- en: 'The following typographical conventions are used in this book:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用的排版约定：
- en: '*Italic*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*斜体*'
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 指示新术语、URL、电子邮件地址、文件名和文件扩展名。
- en: '`Constant width`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`常宽字体`'
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 用于程序列表，以及段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。
- en: '*`Constant width italic`*'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '*`常宽斜体`*'
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 显示应替换为用户提供的值或由上下文确定的值的文本。
- en: Tip
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: This element signifies a tip or suggestion.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示提示或建议。
- en: Note
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This element signifies a general note.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示一般性说明。
- en: Warning
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: This element indicates a warning or caution.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示警告或注意。
- en: Using Code Examples
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用代码示例
- en: The book accompanies a code repository for the guided projects. This repository
    is available for download at [*https://github.com/Ali-Parandeh/building-generative-ai-services*](https://github.com/Ali-Parandeh/building-generative-ai-services).
    You can also find additional resources, articles, and supporting materials on
    the book’s companion website at [*https://buildinggenai.com*](https://buildinggenai.com).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本书附带了指导项目的代码仓库。此仓库可在[*https://github.com/Ali-Parandeh/building-generative-ai-services*](https://github.com/Ali-Parandeh/building-generative-ai-services)下载。您还可以在本书的配套网站上找到额外的资源、文章和支持材料[*https://buildinggenai.com*](https://buildinggenai.com)。
- en: 'After downloading and cloning the repository, you can perform a local installation.
    For example, if using `conda`, you can follow this setup to create your `genaiservice`
    environment:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并克隆仓库后，您可以在本地执行安装。例如，如果您使用`conda`，您可以按照以下设置创建您的`genaiservice`环境：
- en: '[PRE0]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can then install all the necessary dependencies in your newly created Python
    environment:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以在新创建的Python环境中安装所有必要的依赖项：
- en: '[PRE1]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: There are around 170+ code examples scattered across the chapters. These code
    examples show you how to progressively build a production-ready generative AI
    service with the FastAPI web framework. We will walk through the code for each
    step-by-step, with clear signposts that show how the code implements the theory
    underpinning each technique.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在各章节中散布着大约170多个代码示例。这些代码示例展示了如何使用FastAPI Web框架逐步构建一个生产就绪的生成式AI服务。我们将逐行分析代码，清晰的指示将展示代码如何实现支撑每个技术的理论。
- en: The code repository contains several branches that map the state of application
    code to the start and end of each chapter as examples incrementally build on one
    another. The code examples are organized by branches instead of folders to avoid
    clutter and to provide you with a clean codebase to work from. The `main` branch
    contains the final state of the application code at the end of the book.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 代码仓库包含几个分支，这些分支将应用程序代码的状态映射到每个章节的开始和结束，作为示例，这些示例逐步构建在彼此之上。代码示例按分支而不是文件夹组织，以避免混乱，并为您提供干净的基础代码库进行工作。`main`分支包含书中结束时的应用程序代码最终状态。
- en: At the start of each chapter, check out the relevant `starter` branch to follow
    along with the code examples as you develop the application. For instance, at
    the start of [Chapter 2](ch02.html#ch02), you can check out the `ch02-start` branch.
    If you get stuck or want to view the repository state at the end of each chapter,
    you can then check out the corresponding `end` branch (i.e., `ch02-end`) and compare
    your code with the code in the repository.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个章节的开始，查看相关的`starter`分支，以跟随代码示例开发应用程序。例如，在[第2章](ch02.html#ch02)的开始，您可以查看`ch02-start`分支。如果您遇到困难或想查看每个章节结束时的仓库状态，您可以查看相应的`end`分支（即`ch02-end`），并将您的代码与仓库中的代码进行比较。
- en: Note
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The code repository contains instructions in the *README.md* file on the `main`
    branch on how to clone the repository and switch branches if you’re not familiar
    with Git.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 代码仓库在`main`分支的`README.md`文件中包含有关如何克隆仓库和切换分支的说明，如果您不熟悉Git。
- en: Each branch will also contain a *README.md* file to guide you with the practical
    elements of the chapter.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 每个分支也将包含一个*README.md*文件，以指导您了解章节的实践元素。
- en: Throughout the book, I will provide additional tasks and exercises to help solidify
    your understanding of the concepts as part of the guided project. Look out for
    these sections for instructions on implementing these tasks. Solutions are provided
    within the code repository. However, I recommend trying to solve these tasks on
    your own before consulting the solutions. Please note that many solutions can
    exist for a given task.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我将提供额外的任务和练习，以帮助您在指导项目中巩固对概念的理解。请注意这些部分以获取实施这些任务的说明。解决方案在代码存储库中提供。然而，我建议在查阅解决方案之前先尝试自己解决这些任务。请注意，对于给定的任务可能有多种解决方案。
- en: If you have a technical question or a problem using the code examples, please
    send an email to [*support@oreilly.com*](mailto:support@oreilly.com).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有技术问题或使用代码示例时遇到问题，请发送电子邮件到[*support@oreilly.com*](mailto:support@oreilly.com)。
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing examples
    from O’Reilly books does require permission. Answering a question by citing this
    book and quoting example code does not require permission. Incorporating a significant
    amount of example code from this book into your product’s documentation does require
    permission.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在帮助您完成工作。一般来说，如果本书提供了示例代码，您可以在您的程序和文档中使用它。除非您正在复制代码的很大一部分，否则您无需联系我们获取许可。例如，编写一个使用本书中几个代码块的程序不需要许可。通过引用本书并引用示例代码来回答问题不需要许可。将本书的大量示例代码纳入您产品的文档中需要许可。
- en: We appreciate, but generally do not require, attribution. An attribution usually
    includes the title, author, publisher, and ISBN. For example, “*Building Generative
    AI Services with FastAPI* by Alireza Parandeh (O’Reilly). Copyright 2025 Ali Parandeh,
    978-1-098-16030-2.”
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢，但通常不需要归属。归属通常包括标题、作者、出版社和ISBN。例如，“*Building Generative AI Services with
    FastAPI* by Alireza Parandeh (O’Reilly). Copyright 2025 Ali Parandeh, 978-1-098-16030-2。”
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您认为您对代码示例的使用超出了合理使用或上述许可，请随时联系我们[*permissions@oreilly.com*](mailto:permissions@oreilly.com)。
- en: O’Reilly Online Learning
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O’Reilly在线学习
- en: Note
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For more than 40 years, [*O’Reilly Media*](https://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 超过40年来，[*O’Reilly Media*](https://oreilly.com)一直为科技公司提供技术和商业培训、知识和洞察力，以帮助公司成功。
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*https://oreilly.com*](https://oreilly.com).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们独特的专家和创新者网络通过书籍、文章和我们的在线学习平台分享他们的知识和专业知识。O’Reilly的在线学习平台为您提供按需访问实时培训课程、深入的学习路径、交互式编码环境以及来自O’Reilly和200多家其他出版商的大量文本和视频。有关更多信息，请访问[*https://oreilly.com*](https://oreilly.com)。
- en: How to Contact Us
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何联系我们
- en: 'Please address comments and questions concerning this book to the publisher:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 请将有关本书的评论和问题提交给出版社：
- en: O’Reilly Media, Inc.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: O’Reilly Media, Inc.
- en: 1005 Gravenstein Highway North
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1005 Gravenstein Highway North
- en: Sebastopol, CA 95472
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sebastopol, CA 95472
- en: 800-889-8969 (in the United States or Canada)
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 800-889-8969（美国或加拿大）
- en: 707-827-7019 (international or local)
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-827-7019（国际或本地）
- en: 707-829-0104 (fax)
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0104（传真）
- en: '[*support@oreilly.com*](mailto:support@oreilly.com)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*support@oreilly.com*](mailto:support@oreilly.com)'
- en: '[*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)'
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/building-gen-ai-fastAPI*](https://oreil.ly/building-gen-ai-fastAPI).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为本书有一个网页，其中列出了勘误表、示例和任何其他附加信息。您可以通过[*https://oreil.ly/building-gen-ai-fastAPI*](https://oreil.ly/building-gen-ai-fastAPI)访问此页面。
- en: For news and information about our books and courses, visit [*https://oreilly.com*](https://oreilly.com).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解我们书籍和课程的相关新闻和信息，请访问[*https://oreilly.com*](https://oreilly.com)。
- en: 'Find us on LinkedIn: [*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media).'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在LinkedIn上找到我们：[*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)。
- en: 'Watch us on YouTube: [*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia).'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在YouTube上关注我们：[*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)。
- en: Acknowledgments
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: Writing this book has been an incredible experience and journey for me. My deepest
    gratitude to my family for their unconditional support during the writing process.
    I would like to give special recognition to my sister, Tara Parandeh; my parents,
    Mansoureh Tahabaz and Mohammadreza Parandeh; and my partner, Cherry Waller.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为我来说，撰写这本书是一次难以置信的经历和旅程。我要向我的家人表达最深切的感激，感谢他们在写作过程中的无条件支持。我特别想对我的妹妹Tara Parandeh、我的父母Mansoureh
    Tahabaz和Mohammadreza Parandeh以及我的伴侣Cherry Waller表示特别的感谢。
- en: I’m grateful to the friends, colleagues, collaborators, and ADSP folks who helped
    cultivate a supportive environment. Thank you to David Foster, Ross Witeszczak,
    Amy Bull, Zine Eddine, Joe Rowe, Jonathan Davies, Aneta Blazyczek, Giulia Scardovi,
    Maddy Clements, Sarah Davies, Evelina Kireilyte, Khaleel Syed, Rob Foster, Mai
    Do, Bogdan Bija, Nicholas Rawitscher Torres, Snehan Sighat, and Leon Watson.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我要感谢那些帮助营造支持性环境的亲朋好友、同事、合作者和ADSP团队。感谢David Foster、Ross Witeszczak、Amy Bull、Zine
    Eddine、Joe Rowe、Jonathan Davies、Aneta Blazyczek、Giulia Scardovi、Maddy Clements、Sarah
    Davies、Evelina Kireilyte、Khaleel Syed、Rob Foster、Mai Do、Bogdan Bija、Nicholas Rawitscher
    Torres、Snehan Sighat和Leon Watson。
- en: 'Specifically, I would like to thank my mentor, David Foster, author of *Generative
    Deep Learning* (O’Reilly), for inspiring me to write my own book. His book was
    a source of learning and inspiration on generative AI during the drafting process.
    In addition, I’m grateful to the close friends who played a role in shaping my
    career: Lee Dalchow, Isaac Cleave, and Rabah Tahraoui.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 特别感谢我的导师，David Foster，他是《生成式深度学习》（O’Reilly出版）的作者，他的书籍激励我撰写自己的书籍。在撰写过程中，他的书籍是我在生成式AI方面的学习和灵感来源。此外，我还要感谢那些在我职业生涯中扮演重要角色的亲密朋友：Lee
    Dalchow、Isaac Cleave和Rabah Tahraoui。
- en: Working with O’Reilly was incredible. Special thanks to my wonderful editors
    Rita Fernando and Melissa Potter for their support during the writing process,
    enthusiasm, and excellent feedback. I could not have asked for better editors.
    Thanks to Clare Laylock for preparing early release chapters and fixing formatting
    issues during the process. Seeing these chapters on the O’Reilly platform and
    receiving positive feedback from readers was a significant motivator with writing.
    Also thanks to Nicole Butterfield and Amanda Quinn for their help in realizing
    this book and kick-starting the project.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 与O’Reilly合作是一次难以置信的经历。特别感谢我出色的编辑Rita Fernando和Melissa Potter在写作过程中的支持、热情和优秀的反馈。我无法想象更好的编辑了。感谢Clare
    Laylock在过程中准备早期发布章节并解决格式问题。看到这些章节在O’Reilly平台上，并收到读者的积极反馈，是写作过程中的一个重要动力。还要感谢Nicole
    Butterfield和Amanda Quinn在实现这本书和启动项目中的帮助。
- en: Lastly, massive thanks to my technical reviewers, David Foster, Joe Rowe, and
    Julien Brendel, for their meticulous and detailed run-through of the book. Each
    reviewer contributed a different perspective to ensure all inconsistencies, inaccuracies,
    and gaps were addressed. Without their input, the quality of this book would have
    suffered.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我要向我的技术审稿人David Foster、Joe Rowe和Julien Brendel表示衷心的感谢，他们仔细且详细地审阅了本书。每位审稿人提供了不同的视角，确保所有不一致、不准确和空白都得到了解决。没有他们的贡献，本书的质量将大打折扣。
