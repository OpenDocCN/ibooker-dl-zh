["```py\nimport tensorflow as tf\n\nNUM_STEPS = 10\n\ng = tf.Graph()\nwb_ = []\nwith g.as_default():\n  x = tf.placeholder(tf.float32,shape=[None,3])\n  y_true = tf.placeholder(tf.float32,shape=None)\n\n  with tf.name_scope('inference') as scope:\n    w = tf.Variable([[0,0,0]],dtype=tf.float32,name='weights')\n    b = tf.Variable(0,dtype=tf.float32,name='bias')\n    y_pred = tf.matmul(w,tf.transpose(x)) + b\n\n  with tf.name_scope('loss') as scope:\n    loss = tf.reduce_mean(tf.square(y_true-y_pred))\n\n  with tf.name_scope('train') as scope:\n    learning_rate = 0.5\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    train = optimizer.minimize(loss)\n\n  init = tf.global_variables_initializer()\n  with tf.Session() as sess:\n    sess.run(init)   \n    for step in range(NUM_STEPS):\n      sess.run(train,{x: x_data, y_true: y_data})\n      if (step % 5 == 0):\n        print(step, sess.run([w,b]))\n        wb_.append(sess.run([w,b]))\n\n    print(10, sess.run([w,b]))\n\n```", "```py\n(0, [array([[ 0.30149955,\u00a0\u00a00.49303722,\u00a0\u00a00.11409992]], \n                                        dtype=float32), -0.18563795])\n(5, [array([[ 0.30094019,\u00a0\u00a00.49846715,\u00a0\u00a00.09822173]], \n                                        dtype=float32), -0.19780949])\n(10, [array([[ 0.30094025,\u00a0\u00a00.49846718,\u00a0\u00a00.09822182]], \n\u00a0                                       dtype=float32), -0.19780946])\n\n```", "```py\ndef predict(x,y_true,w,b):\n  y_pred = tf.matmul(w,tf.transpose(x)) + b\n  return y_pred\n\ndef get_loss(y_pred,y_true):\n  loss = tf.reduce_mean(tf.square(y_true-y_pred))\n  return loss\n\ndef get_optimizer(y_pred,y_true):\n  loss = get_loss(y_pred,y_true)\n  optimizer = tf.train.GradientDescentOptimizer(0.5)\n  train = optimizer.minimize(loss)\n  return train\n\ndef run_model(x_data,y_data):\n    wb_ = []\n    # Define placeholders and variables\n    x = tf.placeholder(tf.float32,shape=[None,3])\n    y_true = tf.placeholder(tf.float32,shape=None)\n    w = tf.Variable([[0,0,0]],dtype=tf.float32)\n    b = tf.Variable(0,dtype=tf.float32)\n    print(b.name)\n\n    # Form predictions\n    y_pred = predict(x,y_true,w,b)\n\n    # Create optimizer\n    train = get_optimizer(y_pred,y_data)\n\n    # Run session\n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n      sess.run(init)   \n      for step in range(10):\n        sess.run(train,{x: x_data, y_true: y_data})\n          if (step % 5 == 0):\n          print(step, sess.run([w,b]))\n          wb_.append(sess.run([w,b]))\n\nrun_model(x_data,y_data)\nrun_model(x_data,y_data)\n```", "```py\nVariable_9:0 Variable_8:0\n0 [array([[ 0.27383861,\u00a0\u00a00.48421991,\u00a0\u00a00.09082422]], \n                                      dtype=float32), -0.20805186]\n4 [array([[ 0.29868397,\u00a0\u00a00.49840903,\u00a0\u00a00.10026278]], \n                                      dtype=float32), -0.20003076]\n9 [array([[ 0.29868546,\u00a0\u00a00.49840906,\u00a0\u00a00.10026464]], \n                                      dtype=float32), -0.20003042]\n\nVariable_11:0 Variable_10:0\n0 [array([[ 0.27383861,\u00a0\u00a00.48421991,\u00a0\u00a00.09082422]], \n                                      dtype=float32), -0.20805186]\n4 [array([[ 0.29868397,\u00a0\u00a00.49840903,\u00a0\u00a00.10026278]], \n                                      dtype=float32), -0.20003076]\n9 [array([[ 0.29868546,\u00a0\u00a00.49840906,\u00a0\u00a00.10026464]], \n                                      dtype=float32), -0.20003042]\n\n```", "```py\nw = tf.get_variable('w',[1,3],initializer=tf.zeros_initializer())\nb = tf.get_variable('b',[1,1],initializer=tf.zeros_initializer())\n\n```", "```py\ndef run_model(x_data,y_data):\n    wb_ = []\n    # Define placeholders and variables\n    x = tf.placeholder(tf.float32,shape=[None,3])\n    y_true = tf.placeholder(tf.float32,shape=None)\n\n    w = tf.get_variable('w',[1,3],initializer=tf.zeros_initializer())\n    b = tf.get_variable('b',[1,1],initializer=tf.zeros_initializer())\n\n    print(b.name,w.name)\n\n    # Form predictions\n    y_pred = predict(x,y_true,w,b)\n\n    # Create optimizer\n    train = get_optimizer(y_pred,y_data)\n\n    # Run session\n    init = tf.global_variables_initializer()\n    sess.run(init)   \n    for step in range(10):\n      sess.run(train,{x: x_data, y_true: y_data})\n      if (step % 5 == 4) or (step == 0):\n        print(step, sess.run([w,b]))\n        wb_.append(sess.run([w,b]))\n\nsess = tf.Session()\n\nwith tf.variable_scope(\"Regression\") as scope:\n  run_model(x_data,y_data)\n  scope.reuse_variables()\n  run_model(x_data,y_data)\nsess.close()\n\n```", "```py\nRegression/b:0 Regression/w:0\n0 [array([[ 0.27383861,\u00a0\u00a00.48421991,\u00a0\u00a00.09082422]], \n              dtype=float32), array([[-0.20805186]], dtype=float32)]\n4 [array([[ 0.29868397,\u00a0\u00a00.49840903,\u00a0\u00a00.10026278]], \n              dtype=float32), array([[-0.20003076]], dtype=float32)]\n9 [array([[ 0.29868546,\u00a0\u00a00.49840906,\u00a0\u00a00.10026464]], \n              dtype=float32), array([[-0.20003042]], dtype=float32)]\n\nRegression/b:0 Regression/w:0\n0 [array([[ 0.27383861,\u00a0\u00a00.48421991,\u00a0\u00a00.09082422]], \n              dtype=float32), array([[-0.20805186]], dtype=float32)]\n4 [array([[ 0.29868397,\u00a0\u00a00.49840903,\u00a0\u00a00.10026278]], \n              dtype=float32), array([[-0.20003076]], dtype=float32)]\n9 [array([[ 0.29868546,\u00a0\u00a00.49840906,\u00a0\u00a00.10026464]], \n              dtype=float32), array([[-0.20003042]], dtype=float32)]\n\n```", "```py\nclass Model:\n  def __init__(self):\n\n    # Model\n    self.x = tf.placeholder(tf.float32,shape=[None,3])\n    self.y_true = tf.placeholder(tf.float32,shape=None)\n    self.w = tf.Variable([[0,0,0]],dtype=tf.float32)\n    self.b = tf.Variable(0,dtype=tf.float32)\n\n    init = tf.global_variables_initializer()\n    self.sess = tf.Session()\n    self.sess.run(init)\n\n    self._output = None\n    self._optimizer = None\n    self._loss = None\n\n  def fit(self,x_data,y_data):\n    print(self.b.name)\n\n    for step in range(10):\n      self.sess.run(self.optimizer,{self.x: x_data, self.y_true: y_data})\n      if (step % 5 == 4) or (step == 0):\n        print(step, self.sess.run([self.w,self.b]))\n\n  @property\n  def output(self):\n    if not self._output:\n      y_pred = tf.matmul(self.w,tf.transpose(self.x)) + self.b\n      self._output = y_pred\n    return self._output\n\n  @property\n  def loss(self):\n    if not self._loss:\n      error = tf.reduce_mean(tf.square(self.y_true-self.output))\n      self._loss= error\n    return self._loss\n\n  @property\n  def optimizer(self):\n    if not self._optimizer:\n      opt = tf.train.GradientDescentOptimizer(0.5)\n      opt = opt.minimize(self.loss)\n      self._optimizer = opt\n    return self._optimizer\n\nlin_reg = Model()\nlin_reg.fit(x_data,y_data)\nlin_reg.fit(x_data,y_data)\n\n```", "```py\nVariable_89:0\n0 [array([[ 0.32110521,\u00a0\u00a00.4908163 ,\u00a0\u00a00.09833425]], \n                                       dtype=float32), -0.18784374]\n4 [array([[ 0.30250472,\u00a0\u00a00.49442694,\u00a0\u00a00.10041162]], \n                                       dtype=float32), -0.1999902]\n9 [array([[ 0.30250433,\u00a0\u00a00.49442688,\u00a0\u00a00.10041161]], \n                                       dtype=float32), -0.19999036]\n\nVariable_89:0\n0 [array([[ 0.30250433,\u00a0\u00a00.49442688,\u00a0\u00a00.10041161]], \n                                       dtype=float32), -0.19999038]\n4 [array([[ 0.30250433,\u00a0\u00a00.49442688,\u00a0\u00a00.10041161]], \n                                       dtype=float32), -0.19999038]\n9 [array([[ 0.30250433,\u00a0\u00a00.49442688,\u00a0\u00a00.10041161]], \n                                       dtype=float32), -0.19999036]\n\n```", "```py\nclass Model:\n  def __init__(self):\n\n    # Model\n    self.x = tf.placeholder(tf.float32,shape=[None,3])\n    self.y_true = tf.placeholder(tf.float32,shape=None)\n\n    self.params = self._initialize_weights()\n\n    init = tf.global_variables_initializer()\n    self.sess = tf.Session()\n    self.sess.run(init)\n\n    self.output\n    self.optimizer\n    self.loss\n\n  def _initialize_weights(self):\n    params = dict()\n    params['w'] = tf.Variable([[0,0,0]],dtype=tf.float32)\n    params['b'] = tf.Variable(0,dtype=tf.float32)\n    return params\n\n  def fit(self,x_data,y_data):\n    print(self.params['b'].name)\n\n    for step in range(10):\n      self.sess.run(self.optimizer,{self.x: x_data, self.y_true: y_data})\n      if (step % 5 == 4) or (step == 0):\n        print(step, \n                self.sess.run([self.params['w'],self.params['b']]))\n\n  def evaluate(self,x_data,y_data):\n    print(self.params['b'].name)\n\n    MSE = self.sess.run(self.loss,{self.x: x_data, self.y_true: y_data})\n    return MSE\n\n  def getWeights(self):\n    return self.sess.run([self.params['b']])\n\n  @property_with_check\n  def output(self):\n    y_pred = tf.matmul(self.params['w'],tf.transpose(self.x)) + \\\n        self.params['b']\n    return y_pred\n\n  @property_with_check\n  def loss(self):\n    error = tf.reduce_mean(tf.square(self.y_true-self.output))\n    return error\n\n  @property_with_check\n  def optimizer(self):\n    opt = tf.train.GradientDescentOptimizer(0.5)\n    opt = opt.minimize(self.loss)\n    return opt\n\nlin_reg = Model()\nlin_reg.fit(x_data,y_data)\nMSE = lin_reg.evaluate(x_data,y_data)\nprint(MSE)\n\nprint(lin_reg.getWeights())\n\n```", "```py\nVariable_87:0\n0 [array([[ 0.32110521,\u00a0\u00a00.4908163 ,\u00a0\u00a00.09833425]], \n                                        dtype=float32), -0.18784374]\n4 [array([[ 0.30250472,\u00a0\u00a00.49442694,\u00a0\u00a00.10041162]], \n                                        dtype=float32), -0.1999902]\n9 [array([[ 0.30250433,\u00a0\u00a00.49442688,\u00a0\u00a00.10041161]], \n                                        dtype=float32), -0.19999036]\n\nVariable_87:0\n0 [array([[ 0.30250433,\u00a0\u00a00.49442688,\u00a0\u00a00.10041161]], \n                                        dtype=float32), -0.19999038]\n4 [array([[ 0.30250433,\u00a0\u00a00.49442688,\u00a0\u00a00.10041161]], \n                                        dtype=float32), -0.19999038]\n9 [array([[ 0.30250433,\u00a0\u00a00.49442688,\u00a0\u00a00.10041161]], \n                                        dtype=float32), -0.19999036]\nVariable_87:0\n0.0102189\n[-0.19999036]\u00a0\n```", "```py\nimport functools\n\ndef property_with_check(input_fn):\n  attribute = '_cache_' + input_fn.__name__\n\n  @property\n  @functools.wraps(input_fn)\n  def check_attr(self):\n    if not hasattr(self, attribute):\n      setattr(self, attribute, input_fn(self))\n    return getattr(self, attribute)\n\n  return check_attr\n\n```", "```py\ncross_entropy = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n```", "```py\nloss = tf.reduce_mean(tf.square(y_true-y_pred))\n```", "```py\ndef my_loss_function(key-variables...):\nloss = ...\nreturn loss\n\nmy_loss = my_loss_function(key-variables...)\ngd_step = tf.train.GradientDescentOptimizer().minimize(my_loss)\n```", "```py\nx = tf.placeholder(tf.float32, [None, 784])\nW = tf.Variable(tf.zeros([784, 10]))\n\ny_true = tf.placeholder(tf.float32, [None, 10])\ny_pred = tf.matmul(x, W)\n\ncross_entropy = tf.reduce_mean(\n        tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n\ntotal_loss = cross_entropy + LAMBDA * tf.nn.l2_loss(W)\n\ngd_step = tf.train.GradientDescentOptimizer(0.5).minimize(total_loss)\n```", "```py\nDense(100, W_regularizer=l1(0.01))\n```", "```py\nDense(100, W_regularizer=l2(0.01))\n```", "```py\nDense(100, W_regularizer=l1l2(0.01))\n```", "```py\nDense(100, activity_regularizer=activity_l1(0.01))\n```", "```py\nDense(100, activity_regularizer=activity_l2(0.01))\n```", "```py\nDense(100, activity_regularizer=activity_l1l2(0.01))\n```", "```py\nimport numpy as np\n\nLAMBDA = 1e-5\n\ndef mul_lambda(val):\n    return np.multiply(val, LAMBDA).astype(np.float32)\n```", "```py\ntf.py_func(my_python_function, [input], [output_types])\n\n```", "```py\ntotal_loss = cross_entropy + \\\n        tf.py_func(mul_lambda, [tf.nn.l2_loss(W)], [tf.float32])[0]\n```", "```py\n@tf.RegisterGradient(\"PyMulLambda\")\ndef grad_mul_lambda(op, grad):\n    return LAMBDA*grad\n\n```", "```py\nwith tf.get_default_graph().gradient_override_map({\"PyFunc\": \"PyMulLambda\"}):\n    total_loss = cross_entropy + \\\n            tf.py_func(mul_lambda, [tf.nn.l2_loss(W)], [tf.float32])[0]\n```", "```py\nimport numpy as np\nimport tensorflow as tf\n\nLAMBDA = 1e-5\n\ndef mul_lambda(val):\n    return np.multiply(val, LAMBDA).astype(np.float32)\n\n@tf.RegisterGradient(\"PyMulLambda\")\ndef grad_mul_lambda(op, grad):\n    return LAMBDA*grad\n\nx = tf.placeholder(tf.float32, [None, 784])\nW = tf.Variable(tf.zeros([784, 10]))\n\ny_true = tf.placeholder(tf.float32, [None, 10])\ny_pred = tf.matmul(x, W)\n\ncross_entropy = \n        tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\\\n                (logits=y_pred, labels=y_true))\n\nwith tf.get_default_graph().gradient_override_map({\"PyFunc\": \"PyMulLambda\"}):\n    total_loss = cross_entropy + \\\n            tf.py_func(mul_lambda, [tf.nn.l2_loss(W)], [tf.float32])[0]\n\ngd_step = tf.train.GradientDescentOptimizer(0.5).minimize(total_loss)\n\ncorrect_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))\n```", "```py\nx = op.inputs[0]\n```", "```py\nsudo apt-get update && sudo apt-get install -y \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0build-essential \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0curl \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0libcurl3-dev \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0git \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0libfreetype6-dev \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0libpng12-dev \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0libzmq3-dev \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0pkg-config \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0python-dev \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0python-numpy \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0python-pip \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0software-properties-common \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0swig \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0zip \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0zlib1g-dev\n```", "```py\ngit clone --recurse-submodules https://github.com/tensorflow/serving\ncd serving\u00a0\u00a0\n```"]