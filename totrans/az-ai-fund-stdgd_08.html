<html><head></head><body><section data-pdf-bookmark="Chapter 8. Features of Generative AI Workloads on Azure" data-type="chapter" epub:type="chapter"><div class="chapter" id="i08_chapter8_features_of_generative_ai_workloads_on_azure_1742068263839971">&#13;
<h1><span class="label">Chapter 8. </span>Features of Generative AI <span class="keep-together">Workloads on Azure</span></h1>&#13;
&#13;
<p>About<a contenteditable="false" data-primary="generative AI" data-type="indexterm" id="icd801"/> 15%–20%<a contenteditable="false" data-primary="AI (artificial intelligence)" data-secondary="categories of" data-tertiary="generative AI" data-type="indexterm" id="icd1002"/> of the AI-900 exam is about features and scenarios for generative AI, which we’ll cover in this chapter. This includes understanding how models generate responses, create images, and write code snippets. We’ll also look at typical scenarios for generative AI, so you can connect theoretical knowledge with practical applications. This part of the exam isn’t just about knowing what generative AI is—it’s about recognizing its impact and relevance in real-world use cases.</p>&#13;
&#13;
<p>Another key area on the exam involves responsible AI. This includes understanding the ethical implications of AI-generated content and the measures that Microsoft Azure takes to ensure its generative AI tools are used safely and responsibly. By mastering these topics, you’ll be well prepared to answer questions on how Azure’s generative AI services can be effectively and responsibly applied across various domains.</p>&#13;
&#13;
<section data-pdf-bookmark="Understanding Generative AI" data-type="sect1"><div class="sect1" id="i08_chapter8_understanding_generative_ai_1742068263840179">&#13;
<h1>Understanding Generative AI</h1>&#13;
&#13;
<p>At <a contenteditable="false" data-primary="generative AI" data-secondary="overview of" data-type="indexterm" id="icd802"/>its core, generative AI relies on models trained to understand and respond to language in ways that feel intuitive and humanlike. When you ask generative AI to generate content, it draws on massive amounts of data and applies mathematical algorithms to make this possible.</p>&#13;
&#13;
<p>Generative AI has quickly become a centerpiece of the business world. It has attracted attention from industries across the board for its potential to streamline tasks, foster creativity, and drive productivity. Breakthrough applications like OpenAI’s ChatGPT and Microsoft’s Copilot platform<a contenteditable="false" data-primary="Microsoft" data-secondary="Copilot" data-type="indexterm" id="id848"/><a contenteditable="false" data-primary="copilots" data-type="indexterm" id="id849"/> have shown just how transformative this technology can be. ChatGPT, <a contenteditable="false" data-primary="ChatGPT" data-type="indexterm" id="id850"/>for instance, has opened up new ways to handle customer service, content creation, and brainstorming, all with remarkable efficiency and <span class="keep-together">personalization</span>. Meanwhile, Microsoft’s Copilot integrates directly into widely used tools like Word and Excel, empowering professionals to handle complex data, draft reports, and automate routine processes.</p>&#13;
&#13;
<p>One of the easiest ways to work with generative AI is by simply typing in natural language. You type a prompt, which is a straightforward request, and the AI responds with what you’re looking for. <a data-type="xref" href="#i08_chapter8_figure_1_1742068263824651">Figure 8-1</a> shows an example of this when using <a href="https://oreil.ly/2Oy0y">Microsoft Copilot</a>. This is the prompt:</p>&#13;
&#13;
<blockquote>&#13;
<p>Write a professional bio introducing me as a project manager with a background in software development and a passion for team leadership.</p>&#13;
</blockquote>&#13;
&#13;
<p>Microsoft Copilot then writes up a good response.</p>&#13;
&#13;
<figure><div class="figure" id="i08_chapter8_figure_1_1742068263824651"><img src="assets/aaif_0801.png"/>&#13;
<h6><span class="label">Figure 8-1. </span>A text response to a prompt when using Microsoft Copilot</h6>&#13;
</div></figure>&#13;
&#13;
<p>Certain generative AI tools can take a simple request and transform it into a unique image. For instance, you might type: “Design an inviting book cover for a cozy mystery novel set in a small town.” <a data-type="xref" href="#i08_chapter8_figure_2_1742068263824686">Figure 8-2</a> shows the image generated by Microsoft Copilot.</p>&#13;
&#13;
<figure><div class="figure" id="i08_chapter8_figure_2_1742068263824686"><img src="assets/aaif_0802.png"/>&#13;
<h6><span class="label">Figure 8-2. </span>An image created by Microsoft Copilot in response to a prompt</h6>&#13;
</div></figure>&#13;
&#13;
<p>Finally, generative AI can create, debug, and review code for dozens of languages, including C++, Java, and Python. Here’s a prompt:</p>&#13;
&#13;
<blockquote>&#13;
<p>Write Python code to calculate the area of a circle, given its radius.</p>&#13;
</blockquote>&#13;
&#13;
<p><a data-type="xref" href="#i08_chapter8_figure_3_1742068263824712">Figure 8-3</a> shows the result.</p>&#13;
&#13;
<figure><div class="figure" id="i08_chapter8_figure_3_1742068263824712"><img src="assets/aaif_0803.png"/>&#13;
<h6><span class="label">Figure 8-3. </span>How Microsoft Copilot creates code in response to a prompt</h6>&#13;
</div></figure>&#13;
&#13;
<p>Microsoft Copilot generates the code that you request. You can click on the top right to copy the code and use it in your integrated development environment (IDE), like Visual Studio Code. Copilot also provides a brief description of how the program <a contenteditable="false" data-primary="generative AI" data-secondary="overview of" data-startref="icd802" data-type="indexterm" id="id851"/>works.</p>&#13;
&#13;
<section data-pdf-bookmark="Advanced Language Models" data-type="sect2"><div class="sect2" id="i08_chapter8_advanced_language_models_1742068263840257">&#13;
<h2>Advanced Language Models</h2>&#13;
&#13;
<p>Generative<a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-type="indexterm" id="icd803"/><a contenteditable="false" data-primary="language models" data-type="indexterm" id="icd811"/> AI applications leverage advanced language models—specialized ML systems crafted for NLP tasks. These models bring a powerful, flexible toolkit that goes well beyond generating text and images. Here’s a snapshot of their diverse capabilities:</p>&#13;
&#13;
<dl>&#13;
	<dt>Pattern recognition through unsupervised learning</dt>&#13;
	<dd>&#13;
	<p>AI can<a contenteditable="false" data-primary="unsupervised learning" data-type="indexterm" id="id852"/> detect<a contenteditable="false" data-primary="pattern recognition" data-type="indexterm" id="id853"/> patterns and structures in large datasets without labeled data, allowing it to uncover insights autonomously.</p>&#13;
	</dd>&#13;
	<dt>Interpretation of ambiguity</dt>&#13;
	<dd>&#13;
	<p>Models<a contenteditable="false" data-primary="ambiguity, interpretation of" data-type="indexterm" id="id854"/> decipher ambiguous language by analyzing context. This makes them suitable for nuanced tasks like sentiment analysis or handling complex customer inquiries.</p>&#13;
	</dd>&#13;
	<dt>Summarization</dt>&#13;
	<dd>&#13;
	<p>Models<a contenteditable="false" data-primary="summarization" data-type="indexterm" id="id855"/> rapidly distill lengthy content, pulling out essential points—key for making dense reports, legal briefs, or news summaries accessible.</p>&#13;
	</dd>&#13;
	<dt>Multilingual translation</dt>&#13;
	<dd>&#13;
	<p>With<a contenteditable="false" data-primary="multilingual translation" data-type="indexterm" id="id856"/> a grasp of cultural nuances and contextual subtleties, these models accurately translate languages.</p>&#13;
	</dd>&#13;
	<dt>Contextual responses to questions</dt>&#13;
	<dd>&#13;
	<p>The<a contenteditable="false" data-primary="contextual responses" data-type="indexterm" id="id857"/> models respond to questions based on context—for example, to bolster customer support and make helpdesk interactions smoother.</p>&#13;
	</dd>&#13;
	<dt>Lifelike dialogue creation</dt>&#13;
	<dd>&#13;
	<p>Generative <a contenteditable="false" data-primary="dialogue creation" data-type="indexterm" id="id858"/>AI produces realistic conversations, ideal for virtual assistants, chatbots, and dynamic character interactions.</p>&#13;
	</dd>&#13;
	<dt>Anomaly detection</dt>&#13;
	<dd>&#13;
	<p>By <a contenteditable="false" data-primary="anomaly detection" data-type="indexterm" id="id859"/>identifying irregular patterns, these models catch inconsistencies, whether in financial data, health care records, or security logs.</p>&#13;
	</dd>&#13;
	<dt>Semantic search</dt>&#13;
	<dd>&#13;
	<p>Rather<a contenteditable="false" data-primary="semantics" data-secondary="semantic search" data-type="indexterm" id="id860"/> than relying solely on keywords, AI performs searches based on meaning. This helps users find relevant information with minimal effort.</p>&#13;
	</dd>&#13;
	<dt>Personalized recommendations</dt>&#13;
	<dd>&#13;
	<p>AI tailors content<a contenteditable="false" data-primary="personalized recommendations" data-type="indexterm" id="id861"/> and recommendations based on user profiles, which is valuable for marketing, customer service, and enhancing user experience.</p>&#13;
	</dd>&#13;
	<dt>Content moderation</dt>&#13;
	<dd>&#13;
	<p>These<a contenteditable="false" data-primary="content moderation" data-type="indexterm" id="id862"/> models can identify and flag inappropriate or sensitive content, which can promote safer and more compliant digital <a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-startref="icd803" data-type="indexterm" id="id863"/><a contenteditable="false" data-primary="language models" data-startref="icd811" data-type="indexterm" id="id864"/>spaces.</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="The Transformer Model" data-type="sect2"><div class="sect2" id="i08_chapter8_the_transformer_model_1742068263840324">&#13;
<h2>The Transformer Model</h2>&#13;
&#13;
<p>ML <a contenteditable="false" data-primary="generative AI" data-secondary="transformers" data-type="indexterm" id="icd804"/><a contenteditable="false" data-primary="transformers" data-type="indexterm" id="icd812"/>models for NLP have evolved dramatically, leading to today’s advanced systems built on the transformer architecture. This architecture has changed how machines handle language. Using the large amount of data they’re trained on, these models learn the subtle connections between words, which allows them to predict sequences that feel natural and make sense.</p>&#13;
&#13;
<p>Transformers are built with two key components:</p>&#13;
&#13;
<dl>&#13;
	<dt>Encoder block</dt>&#13;
	<dd>&#13;
	<p>Examines<a contenteditable="false" data-primary="encoder blocks, in transformers" data-type="indexterm" id="id865"/> the input text and identifies meaningful relationships within the vocabulary</p>&#13;
	</dd>&#13;
	<dt>Decoder block</dt>&#13;
	<dd>&#13;
	<p>Uses <a contenteditable="false" data-primary="decoder blocks, in transformers" data-type="indexterm" id="id866"/>the encoder’s output to generate relevant and contextually appropriate <span class="keep-together">language</span></p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>Let’s take a closer look at how it all comes together. During training, the model processes vast amounts of text from books, websites, and other sources. It breaks down this information <a contenteditable="false" data-primary="tokens" data-type="indexterm" id="kab7777"/>into tokens (small units like words or parts of words) and feeds these to the encoder. With a <a contenteditable="false" data-primary="attention process" data-type="indexterm" id="id867"/>process called <em>attention</em>, the encoder figures out how each token relates to others, recognizing patterns such as the difference between <em>bat</em> as in a flying mammal versus a piece of sports equipment. These relationships are stored as embeddings, which are mathematical vectors representing each token’s meaning. The decoder then takes these embeddings and generates a new sequence of text. For instance, if you provide the input “The mysterious package arrived,” the model might continue with “at my doorstep,” based on similar sentences it learned during training.</p>&#13;
&#13;
<p>Different transformer models use these blocks in specialized ways. Google’s BERT model, for example, leverages the encoder to understand context in search results. OpenAI’s GPT model focuses on the decoder, which makes it a powerful tool for generating creative content and answering questions in natural, conversational language.</p>&#13;
&#13;
<p>In the next few sections, we’ll look deeper at the key components of the transformer model.</p>&#13;
&#13;
<section data-pdf-bookmark="Tokenization for transformers" data-type="sect3"><div class="sect3" id="i08_chapter8_tokenization_for_transformers_1742068263840388">&#13;
<h3>Tokenization for transformers</h3>&#13;
&#13;
<p>In <a contenteditable="false" data-primary="transformers" data-secondary="tokenization" data-type="indexterm" id="icd813"/><a contenteditable="false" data-primary="tokenization" data-type="indexterm" id="icd819"/>the previous chapter, we dove into the concept of tokenization. Let’s continue building on that. Tokenization is the essential first step in training a transformer model.</p>&#13;
&#13;
<p>OpenAI uses the <a href="https://oreil.ly/PGIwn">Tokenizer</a>, an example of which is shown in <a data-type="xref" href="#i08_chapter8_figure_4_1742068263824741">Figure 8-4</a>. The Tokenizer converts text into tokens and IDs.</p>&#13;
&#13;
<p>At the top, you can select different types of models to use<a contenteditable="false" data-primary="GPT models" data-secondary="GPT-4o" data-type="indexterm" id="id868"/><a contenteditable="false" data-primary="GPT models" data-secondary="GPT-4o mini" data-type="indexterm" id="id869"/><a contenteditable="false" data-primary="GPT models" data-secondary="GPT-3.5" data-type="indexterm" id="id870"/>: GPT-4o/GPT-4o mini, GPT-3.5/GPT-4, or GPT-3 (legacy). <a contenteditable="false" data-primary="GPT models" data-secondary="GPT-4" data-type="indexterm" id="id871"/><a contenteditable="false" data-primary="GPT models" data-secondary="GPT-3" data-type="indexterm" id="id872"/>You’ll need to know what model you’re using because tokenization is different based on the model.</p>&#13;
&#13;
<p class="pagebreak-before">For the example in <a data-type="xref" href="#i08_chapter8_figure_4_1742068263824741">Figure 8-4</a>, we used this sentence:</p>&#13;
&#13;
<blockquote>&#13;
<p>Artificial intelligence <img src="assets/robot_1f916.png"/> like machine learning and natural language processing, is transforming industries from healthcare to finance, sparking innovation in data-driven decision-making.</p>&#13;
</blockquote>&#13;
&#13;
<figure><div class="figure" id="i08_chapter8_figure_4_1742068263824741"><img src="assets/aaif_0804.png"/>&#13;
<h6><span class="label">Figure 8-4. </span>An example of OpenAI’s Tokenizer, which converts text into tokens for an LLM</h6>&#13;
</div></figure>&#13;
&#13;
<p>Notice that a token can include a space with a word. It can also be for a punctuation mark or an emoji. In some cases, one word may be composed of two or more tokens.</p>&#13;
&#13;
<p>If you click Token IDs, you will get the vector for the tokenization:</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
[186671, 22990, 93643, 244, 11, 1299, 7342, 7524, 326, 6247, 6439, 12323, 11, &#13;
382, 64779, 22751, 591, 20072, 316, 17496, 11, 30281, 6962, 21879, 306, 1238, &#13;
45932, 8660, 42074, 13]</pre>&#13;
&#13;
<p>This is what the transformer model will process.</p>&#13;
&#13;
<p>As the model undergoes further training, each additional token from the training data is incorporated into the vocabulary and assigned a unique token ID. Over time, with an expansive enough dataset, the vocabulary can grow to encompass thousands of <a contenteditable="false" data-primary="transformers" data-secondary="tokenization" data-startref="icd813" data-type="indexterm" id="id873"/><a contenteditable="false" data-primary="tokenization" data-startref="icd819" data-type="indexterm" id="id874"/>tokens.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Embeddings" data-type="sect3"><div class="sect3" id="i08_chapter8_embeddings_1742068263840446">&#13;
<h3>Embeddings</h3>&#13;
&#13;
<p>Imagine<a contenteditable="false" data-primary="embeddings" data-type="indexterm" id="id875"/><a contenteditable="false" data-primary="transformers" data-secondary="embeddings" data-type="indexterm" id="id876"/> trying to navigate a large library with nothing but a list of book titles, each assigned a unique number. Sure, the numbers help you locate individual books, but they offer no clues about the content of each book, its genre, or any connections it might have with other books. When it comes to representing words as token IDs in a vocabulary, it’s a<a contenteditable="false" data-primary="tokens" data-startref="kab7777" data-type="indexterm" id="id877"/> similar situation: yes, it’s useful for indexing, but it lacks any insight into meaning or relationships.</p>&#13;
&#13;
<p>To build a more meaningful map of language, we use embeddings, which we learned about in the previous chapter.</p>&#13;
&#13;
<p>In a vector space, words with similar meanings end up near one another, with directions in the space signifying their relationships. For instance, words like <em>king</em> and <em>queen</em> may point in nearly identical directions but differ slightly in their dimensions, distinguishing masculine and feminine concepts. This semantic proximity enables embeddings to capture subtle relationships.</p>&#13;
&#13;
<p>Creating these embeddings is no small feat, though. Algorithms like <a contenteditable="false" data-primary="word2vec " data-type="indexterm" id="id878"/>word2vec, which use neural networks to process massive amounts of text, or the transformer models powering advanced AI today identify patterns and context from countless words used in sentences. For instance, word2vec calculates embeddings by predicting word contexts whereas transformers use more sophisticated architectures to represent relationships at various levels of abstraction.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Attention" data-type="sect3"><div class="sect3" id="i08_chapter8_attention_1742068263840502">&#13;
<h3>Attention</h3>&#13;
&#13;
<p>The<a contenteditable="false" data-primary="transformers" data-secondary="attention" data-type="indexterm" id="icd814"/><a contenteditable="false" data-primary="attention process" data-type="indexterm" id="icd820"/> transformer model’s encoder and decoder blocks <a contenteditable="false" data-primary="decoder blocks, in transformers" data-type="indexterm" id="id879"/>​are like layers of a sandwich, stacked up to build the neural network. While we don’t need to go over every ingredient in that sandwich, there’s one that’s essential in both blocks: the attention layers. This is where the model pays attention to relationships between words in a sequence. It’s about reading a sentence and figuring out which words have the strongest connections to one another.</p>&#13;
&#13;
<p>Let’s start with the encoder block. <a contenteditable="false" data-primary="encoder blocks, in transformers" data-type="indexterm" id="id880"/>​This is the part that takes each word in a sentence and looks at it in the context of the words around it. The result? Each word gets an <em>encoding</em>—basically, a unique representation based on the company it keeps. Think of it this way: the word <em>cell</em> means one thing in the phrase “cell phone” and something totally different in “jail cell.” In this encoder, the model adjusts the encoding for <em>cell</em> based on which other words it’s hanging out with.</p>&#13;
&#13;
<p>In the decoder block, attention is used a bit differently. Here, the model is generating text one word at a time. For every new word, the decoder block considers all the words it’s generated so far to figure out what comes next. For instance, if you start with “He grabbed his umbrella,” the decoder might zero in on <em>grabbed</em> and <em>umbrella</em> to predict that the next word could be <em>and</em> or <em>opened</em>. It’s like the model is trying to complete a sentence by keeping an eye on the context it has already built.</p>&#13;
&#13;
<p>But there’s something special going on under the hood: <em>self-attention</em>. <a contenteditable="false" data-primary="self-attention" data-type="indexterm" id="id881"/>This is where each word gets weighed against others in the sentence to find out how much influence it should have on the meaning. In practical terms, self-attention gives different weights (or importance) to words depending on how they relate to one another. <em>Multihead</em><em> attention</em> takes<a contenteditable="false" data-primary="multihead attention" data-type="indexterm" id="id882"/> this to the next level by analyzing several relationships at once, enabling the model to capture all the nuances in a sentence.</p>&#13;
&#13;
<p>Of course, the model doesn’t actually “see” words; it’s working with numeric vectors (essentially lists of numbers) that represent the words. At the start, each word gets an initial value based on where it is in the sequence—think of it as a first guess. Then, the attention layers refine these vectors by applying weights, which let the model zero in on the most relevant bits of information for predicting the next word.</p>&#13;
&#13;
<p>When training this model, we know the full sequence of words, so the model can learn from the actual outcome by comparing its predictions to the real sequence. This process<a contenteditable="false" data-primary="minimizing loss process" data-type="indexterm" id="id883"/>—where it adjusts its own “attention” to get better over time—is called <em>minimizing loss</em>.</p>&#13;
&#13;
<p>So what does this mean in action? A transformer model like GPT-4, which powers tools like ChatGPT, takes in a piece of text (a prompt) and generates a response that sounds coherent and natural. While it doesn’t understand or know things the way humans do, it uses massive amounts of data and complex patterns to predict what comes next in a way that often <a contenteditable="false" data-primary="transformers" data-secondary="attention" data-startref="icd814" data-type="indexterm" id="id884"/><a contenteditable="false" data-primary="attention process" data-startref="icd820" data-type="indexterm" id="id885"/>sounds <a contenteditable="false" data-primary="generative AI" data-secondary="transformers" data-startref="icd804" data-type="indexterm" id="id886"/><a contenteditable="false" data-primary="transformers" data-startref="icd812" data-type="indexterm" id="id887"/>spot-on.</p>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Language Models on Azure" data-type="sect1"><div class="sect1" id="i08_chapter8_language_models_on_azure_1742068263840575">&#13;
<h1>Language Models on Azure</h1>&#13;
&#13;
<p>Building<a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-type="indexterm" id="icd806a"/><a contenteditable="false" data-primary="language models" data-type="indexterm" id="icd815a"/> your<a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-tertiary="Azure services for" data-type="indexterm" id="icd807"/><a contenteditable="false" data-primary="language models" data-secondary="Azure services for" data-type="indexterm" id="icd815"/> own language model from scratch is certainly possible, but the costs are huge—not just in time but in dollars. Training an LLM from scratch can easily cost millions. You’d need hundreds of powerful GPUs running nonstop for weeks (or even months), plus funding to cover the cost of storing and processing vast amounts of data. Most organizations find it far more practical to start with an <a contenteditable="false" data-primary="foundation model" data-type="indexterm" id="id888"/>existing <em>foundation model </em>and fine-tune it with their own data if needed. With so many options available, you can skip the heavy lifting and the financial burden.</p>&#13;
&#13;
<p>If you’re using Microsoft Azure, you’ll find these foundation models in two main places: the Azure OpenAI Service<a contenteditable="false" data-primary="Azure OpenAI Service" data-secondary="language models" data-type="indexterm" id="id889"/> and the Azure AI Model Catalog<a contenteditable="false" data-primary="Azure AI Model Catalog" data-type="indexterm" id="id890"/><a contenteditable="false" data-primary="Model Catalog" data-type="indexterm" id="id891"/>. Think of the Model Catalog as a curated library of models that Azure has handpicked for data scientists and developers working with Azure AI Foundry<a contenteditable="false" data-primary="Azure AI Foundry" data-secondary="language models" data-type="indexterm" id="id892"/> and Azure Machine Learning<a contenteditable="false" data-primary="Azure Machine Learning" data-type="indexterm" id="id893"/>. Plus, when you’re using models from the Azure OpenAI service, you get the full benefit of Azure’s secure, scalable infrastructure.</p>&#13;
&#13;
<p>The Model Catalog is also loaded with open source models from a growing list of Azure’s partners, including:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>OpenAI</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Hugging Face</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Mistral AI</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Meta</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Anthropic</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>AI21 Labs</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Cohere</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>EleutherAI</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Stability AI</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Some of the popular models you’ll find in Azure OpenAI include:</p>&#13;
&#13;
<dl>&#13;
	<dt>GPT-3.5 Turbo, GPT-4, and GPT-4o</dt>&#13;
	<dd>&#13;
	<p>These<a contenteditable="false" data-primary="GPT models" data-secondary="GPT-3.5 Turbo" data-type="indexterm" id="id894"/> are <a contenteditable="false" data-primary="GPT models" data-secondary="GPT-4" data-type="indexterm" id="id895"/>the <a contenteditable="false" data-primary="GPT models" data-secondary="GPT-4o" data-type="indexterm" id="id896"/>go-to models for conversation-based applications. Just feed them some text, and they’ll give you well-formed responses.</p>&#13;
	</dd>&#13;
	<dt>GPT-4 Turbo with Vision</dt>&#13;
	<dd>&#13;
	<p>This<a contenteditable="false" data-primary="GPT models" data-secondary="GPT-4 Turbo with Vision" data-type="indexterm" id="id897"/> one does more than just text—it can analyze images and respond with detailed descriptions or answers. It combines language processing with visual understanding.</p>&#13;
	</dd>&#13;
	<dt>DALL-E</dt>&#13;
	<dd>&#13;
	<p>Looking<a contenteditable="false" data-primary="DALL-E model" data-type="indexterm" id="id898"/> to create images from scratch or make edits to existing images? DALL-E is your tool for generating unique images, and adding variations.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>Beyond these, Azure’s Model Catalog includes a range of other models suited for various applications:</p>&#13;
&#13;
<dl>&#13;
	<dt>Stable Diffusion by Stability AI</dt>&#13;
	<dd>&#13;
	<p>Generates<a contenteditable="false" data-primary="Stable Diffusion model" data-type="indexterm" id="id899"/> photorealistic images from text prompts</p>&#13;
	</dd>&#13;
	<dt>BERT</dt>&#13;
	<dd>&#13;
	<p>Focuses <a contenteditable="false" data-primary="BERT (bidirectional encoder representations from transformers)" data-type="indexterm" id="id900"/>on understanding text, making it great for applications like sentiment analysis and question answering</p>&#13;
	</dd>&#13;
	<dt>Contrastive Language-Image Pretraining (CLIP)</dt>&#13;
	<dd>&#13;
	<p>Connects<a contenteditable="false" data-primary="Contrastive Language-Image Pretraining (CLIP)" data-type="indexterm" id="id901"/><a contenteditable="false" data-primary="CLIP (Contrastive Language-Image Pretraining)" data-type="indexterm" id="id902"/> images with text descriptions, such as for multimedia <a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-startref="icd807" data-tertiary="Azure services for" data-type="indexterm" id="id903"/><a contenteditable="false" data-primary="language models" data-secondary="Azure services for" data-startref="icd815" data-type="indexterm" id="id904"/>applications</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<section data-pdf-bookmark="Large Language and Small Language Models" data-type="sect2"><div class="sect2" id="i08_chapter8_large_language_and_small_language_models_1742068263840652">&#13;
<h2>Large Language and Small Language Models</h2>&#13;
&#13;
<p>There <a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-tertiary="large" data-type="indexterm" id="id905"/><a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-tertiary="small" data-type="indexterm" id="id906"/><a contenteditable="false" data-primary="language models" data-secondary="large" data-type="indexterm" id="id907"/><a contenteditable="false" data-primary="language models" data-secondary="small" data-type="indexterm" id="id908"/>are two main types of language models you can choose from to power your generative AI applications: <em>large language models (LLMs) </em><span style="letter-spacing: 0.01em;">and </span><em style="letter-spacing: 0.01em;">small language models (SLMs)</em><span style="letter-spacing: 0.01em;">. </span><a data-type="xref" href="#i08_chapter8_table_1_1742068263829815" style="letter-spacing: 0.01em;">Table 8-1</a><span style="letter-spacing: 0.01em;"> highlights<a contenteditable="false" data-primary="large language models (LLMs)" data-type="indexterm" id="id909"/><a contenteditable="false" data-primary="LLMs (large language models)" data-type="indexterm" id="id910"/><a contenteditable="false" data-primary="SLMs (small language models)" data-type="indexterm" id="id911"/> the differences.</span></p>&#13;
&#13;
<table class="border" id="i08_chapter8_table_1_1742068263829815">&#13;
	<caption><span class="label">Table 8-1. </span>Differences between LLMs and SLMs</caption>&#13;
	<thead>&#13;
		<tr>&#13;
			<th>Features</th>&#13;
			<th>LLMs</th>&#13;
			<th>SLMs</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Training costs</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Training an LLM is a major investment as it requires extensive compute power and specialized equipment to handle large datasets.</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Training SLMs is generally more affordable as the smaller datasets and simpler model structures reduce resource demands.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Inference speed</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>The large parameter count of LLMs can slow their response times, which may affect their suitability for real-time applications.</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>With fewer parameters, SLMs often respond faster, making them ideal for real-time use cases.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Memory requirements</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>LLMs require high memory and storage capacity, especially with very large parameter counts.</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>SLMs need less memory, making them easier to deploy on devices with limited resources, such as mobile or edge devices.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Scalability</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>LLMs are frequently deployed in the cloud, allowing them to scale for larger or more intensive applications.</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>SLMs are easier to scale with fewer resources and often don’t need cloud hosting, which can save on costs and enhance privacy.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Data privacy</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Cloud-based deployment of LLMs often involves transferring data off-device, which could be a concern for privacy-sensitive applications.</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>SLMs can be deployed on devices or on premises, allowing data to remain securely within the organization, which can improve privacy.</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Energy consumption</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>LLMs are more power intensive, leading to higher operating costs and a larger environmental impact.</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>SLMs consume less energy, making them more suitable for eco-friendly applications and improving battery life on portable devices.</p>&#13;
			</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Copilots" data-type="sect2"><div class="sect2" id="i08_chapter8_copilots_1742068263840716">&#13;
<h2>Copilots</h2>&#13;
&#13;
<p><em>Copilots</em> are<a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-tertiary="copilots" data-type="indexterm" id="icd808"/><a contenteditable="false" data-primary="language models" data-secondary="copilots" data-type="indexterm" id="icd816"/><a contenteditable="false" data-primary="copilots" data-type="indexterm" id="icd821"/><a contenteditable="false" data-primary="Microsoft" data-secondary="Copilot" data-type="indexterm" id="icd1032"/> changing the way we interact with software. They bring AI-powered assistance directly into applications to help with everything from quick tasks to complex processes. Built as chat-based tools, these copilots are designed to provide on-demand, tailored support that’s ready whenever you need it.</p>&#13;
&#13;
<p>Copilots are also a key part of Microsoft’s AI strategy, which is important to know for the exam. This technology is embedded across various Microsoft products and built with an open architecture that allows for flexibility and customization. Developers can add their own plug-ins or even create completely new copilots to shape unique user experiences. Whether you’re working with an out-of-the-box copilot or crafting a custom one, you can adjust it to fit with your business processes. This ensures that the copilot responds just the way you need.</p>&#13;
&#13;
<p>These copilots do more than just automate—they assist with drafting, summarizing, planning, and more, aiming to boost productivity, encourage creativity, and keep teams connected. Whether you’re using prebuilt tools, customizing them for specific workflows, or designing unique copilots, these AI assistants adapt to your needs and redefine the way you work and collaborate.</p>&#13;
&#13;
<p>In the next few sections, we’ll take a look at the different copilot systems from <span class="keep-together">Microsoft</span>.</p>&#13;
&#13;
<section data-pdf-bookmark="Web-based copilots" data-type="sect3"><div class="sect3" id="i08_chapter8_web_based_copilots_1742068263840776">&#13;
<h3>Web-based copilots</h3>&#13;
&#13;
<p>Microsoft<a contenteditable="false" data-primary="copilots" data-secondary="web-based" data-type="indexterm" id="icd822"/><a contenteditable="false" data-primary="web-based copilots" data-type="indexterm" id="icd823"/> has different ways to access Microsoft Copilot using web-based applications. Earlier in the chapter, we saw one, which is the Microsoft Copilot site. You can also access Microsoft Copilot in the Bing search engine as shown in <a data-type="xref" href="#i08_chapter8_figure_5_1742068263824767">Figure 8-5</a>. To access Copilot in Bing, click the icon to the right side of the search box.</p>&#13;
&#13;
<figure><div class="figure" id="i08_chapter8_figure_5_1742068263824767"><img src="assets/aaif_0805.png"/>&#13;
<h6><span class="label">Figure 8-5. </span>Access Microsoft Copilot in Bing by clicking the icon on the right side of the search box</h6>&#13;
</div></figure>&#13;
&#13;
<p>You can also access this feature in the Microsoft Edge browser. When you open the browser, you will see a search box at the top, and Copilot will be on the right side.</p>&#13;
&#13;
<p>But the Edge browser can also embed Copilot into the sidebar. You activate this by clicking the icon on the top right side of the browser. You can see the sidebar in <a data-type="xref" href="#i08_chapter8_figure_6_1742068263824787">Figure 8-6</a>.</p>&#13;
&#13;
<p>The interface has many useful options. At the top of the Copilot sidebar, you can choose between a chat mode and one to create content, such as for emails, blogs, or brainstorming. You can write your content in different tones, ranging from professional to casual to funny. You can also specify the length. The<a contenteditable="false" data-primary="Chat feature, Copilot" data-type="indexterm" id="id912"/> Chat feature is similar to ChatGPT, but you have the option to specify the conversation style, which is either: more creative, balanced, or precise.</p>&#13;
&#13;
<p>In the input box at the bottom, you can click the top to indicate what you want to chat about. This can be certain webpages, such as the current page of the site you have visited or other sites. The icons at the bottom enable you to upload images, add a screenshot, and use the voice system.</p>&#13;
&#13;
<figure><div class="figure" id="i08_chapter8_figure_6_1742068263824787"><img src="assets/aaif_0806.png"/>&#13;
<h6><span class="label">Figure 8-6. </span>The Copilot sidebar in the Edge browser</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Microsoft Copilot for Microsoft 365" data-type="sect3"><div class="sect3" id="i08_chapter8_microsoft_copilot_for_microsoft_365_1742068263840834">&#13;
<h3>Microsoft Copilot for Microsoft 365</h3>&#13;
&#13;
<p>Microsoft<a contenteditable="false" data-primary="copilots" data-secondary="Microsoft Copilot for Microsoft 365" data-type="indexterm" id="id913"/> Copilot for Microsoft 365 puts powerful AI right into the tools you already know—Word, PowerPoint, Outlook, Excel, and Teams—so you can get more done without breaking your workflow. Here’s how Copilot can help you in each of these apps:</p>&#13;
&#13;
<dl>&#13;
	<dt>Microsoft Word</dt>&#13;
	<dd>&#13;
	<p>With Copilot, you<a contenteditable="false" data-primary="Microsoft" data-secondary="Word" data-type="indexterm" id="id914"/><a contenteditable="false" data-primary="Word" data-type="indexterm" id="id915"/> can keep improving your document without starting from scratch.</p>&#13;
	</dd>&#13;
	<dt>Microsoft PowerPoint</dt>&#13;
	<dd>&#13;
	<p>Got <a contenteditable="false" data-primary="Microsoft" data-secondary="PowerPoint" data-type="indexterm" id="id916"/><a contenteditable="false" data-primary="PowerPoint" data-type="indexterm" id="id917"/>a report or email that you need to turn into a presentation? Copilot will create the slides from the content you already have. You can then adjust the format, add images, and fine-tune the slides.</p>&#13;
	</dd>&#13;
	<dt>Microsoft Outlook</dt>&#13;
	<dd>&#13;
	<p>Copilot <a contenteditable="false" data-primary="Microsoft" data-secondary="Outlook" data-type="indexterm" id="id918"/><a contenteditable="false" data-primary="Outlook" data-type="indexterm" id="id919"/>can help by summarizing emails, finding important details, and even gathering what you need to prep for meetings.</p>&#13;
	</dd>&#13;
	<dt>Microsoft Excel</dt>&#13;
	<dd>&#13;
	<p>Data <a contenteditable="false" data-primary="Microsoft" data-secondary="Excel" data-type="indexterm" id="id920"/><a contenteditable="false" data-primary="Excel" data-type="indexterm" id="id921"/>analysis doesn’t have to be intimidating. Copilot can suggest formulas, uncover insights, and build visualizations. Need to make predictions or analyze risks? Copilot is on it, so you can work smarter, even if you’re not an Excel power user.</p>&#13;
	</dd>&#13;
	<dt>Microsoft Teams</dt>&#13;
	<dd>&#13;
	<p>In <a contenteditable="false" data-primary="Microsoft" data-secondary="Teams" data-type="indexterm" id="id922"/><a contenteditable="false" data-primary="Teams" data-type="indexterm" id="id923"/>meetings, Copilot can keep track of the conversation, summarize the key points, and even highlight questions that still need answers. This way, you can stay fully engaged, knowing that Copilot is capturing the details.</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Microsoft Dynamics 365" data-type="sect3"><div class="sect3" id="i08_chapter8_microsoft_dynamics_365_1742068263840892">&#13;
<h3>Microsoft Dynamics 365</h3>&#13;
&#13;
<p>Microsoft<a contenteditable="false" data-primary="Microsoft" data-secondary="Dynamics 365" data-type="indexterm" id="id924"/><a contenteditable="false" data-primary="copilots" data-secondary="Microsoft Dynamics 365" data-type="indexterm" id="id925"/><a contenteditable="false" data-primary="Dynamics 365" data-type="indexterm" id="id926"/> Dynamics 365 is a platform for running your business more smoothly. It’s Microsoft’s answer to uniting different parts of your operations, from sales and customer service to supply chain management. Copilot has boosted the capabilities of Microsoft Dynamics 365 with the following features:</p>&#13;
&#13;
<dl>&#13;
	<dt>Copilot for Dynamics 365 Sales</dt>&#13;
	<dd>&#13;
	<p>Copilot pulls up customer and industry information from your CRM and other sources. Whether you’re qualifying a new lead, preparing a proposal, or scheduling a follow-up, Copilot makes the process faster and can provide insights. This helps to close more deals.</p>&#13;
	</dd>&#13;
	<dt>Copilot for Dynamics 365 Supply Chain</dt>&#13;
	<dd>&#13;
	<p>Copilot keeps things running smoothly by managing those changes at scale, assessing potential impacts, and suggesting your next steps. Say an order update comes in—Copilot analyzes how it might affect the rest of the process, so you can make procurement decisions without disrupting your workflow.</p>&#13;
	</dd>&#13;
	<dt>Copilot for Dynamics 365 Customer Service</dt>&#13;
	<dd>&#13;
	<p>In customer service, speed and accuracy are important. Copilot steps in to help agents analyze support tickets, find similar issues, and offer solutions. Agents have what they need to resolve customer issues quickly.</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Azure AI" data-type="sect3"><div class="sect3" id="i08_chapter8_azure_ai_1742068263840947">&#13;
<h3>Azure AI</h3>&#13;
&#13;
<p>The <a contenteditable="false" data-primary="copilots" data-secondary="Microsoft Copilot in Azure" data-type="indexterm" id="id927"/>Azure AI system has its own Copilot, which is called the Microsoft Copilot in Azure. You can activate it by clicking a button at the top of the screen next to the search box. When you do this, you will see the Copilot on the sidebar as shown in <a data-type="xref" href="#i08_chapter8_figure_7_1742068263824807">Figure 8-7</a>.</p>&#13;
&#13;
<figure><div class="figure" id="i08_chapter8_figure_7_1742068263824807"><img src="assets/aaif_0807.png"/>&#13;
<h6><span class="label">Figure 8-7. </span>The Copilot in Azure AI</h6>&#13;
</div></figure>&#13;
&#13;
<p>Copilot can answer your questions using the latest documentation, suggest the best Azure services for your specific needs, and help you perform basic tasks in your environment. It even recommends script code to carry out those tasks. Plus, everything is tailored to fit your role and permissions, so you’re always in control.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Other Microsoft Copilots" data-type="sect3"><div class="sect3" id="i08_chapter8_other_microsoft_copilots_1742068263841015">&#13;
<h3>Other Microsoft Copilots</h3>&#13;
&#13;
<p>Microsoft has rolled out quite a few copilots—and it’s coming up with new ones regularly. Here are some are some others:</p>&#13;
&#13;
<dl>&#13;
	<dt>Microsoft Security Copilot</dt>&#13;
	<dd>&#13;
	<p>Security Copilot <a contenteditable="false" data-primary="copilots" data-secondary="Microsoft Security Copilot" data-type="indexterm" id="id928"/><a contenteditable="false" data-primary="Security Copilot" data-type="indexterm" id="id929"/>steps up for the cybersecurity crowd. With some of the threat response automated, your security operations become faster and more precise.</p>&#13;
	</dd>&#13;
	<dt>Copilot in Microsoft Fabric</dt>&#13;
	<dd>&#13;
	<p>Copilot <a contenteditable="false" data-primary="copilots" data-secondary="Copilot in Microsoft Fabric" data-type="indexterm" id="id930"/>can generate code for analyzing, manipulating, and visualization data in Spark Notebooks, letting you shift your focus away from coding and onto making insights.</p>&#13;
	</dd>&#13;
	<dt>GitHub Copilot</dt>&#13;
	<dd>&#13;
	<p>This<a contenteditable="false" data-primary="copilots" data-secondary="GitHub Copilot" data-type="indexterm" id="id931"/><a contenteditable="false" data-primary="GitHub Copilot" data-type="indexterm" id="id932"/> AI-assisted programming tool not only generates code but also helps with unit tests and debugging.</p>&#13;
	</dd>&#13;
	<dt>Copilot in Microsoft Power BI</dt>&#13;
	<dd>&#13;
	<p>When <a contenteditable="false" data-primary="copilots" data-secondary="Copilot in Microsoft Power BI" data-type="indexterm" id="id933"/>you’re working on Power BI reports, Copilot can analyze your data and suggest <a contenteditable="false" data-primary="copilots" data-startref="icd821" data-type="indexterm" id="id934"/><a contenteditable="false" data-primary="Microsoft" data-secondary="Copilot" data-startref="icd1032" data-type="indexterm" id="id935"/>useful visualizations.</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Prompt Engineering" data-type="sect2"><div class="sect2" id="i08_chapter8_prompt_engineering_1742068263841071">&#13;
<h2>Prompt Engineering</h2>&#13;
&#13;
<p>Copilots<a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-tertiary="prompt engineering" data-type="indexterm" id="id936"/><a contenteditable="false" data-primary="prompt engineering" data-type="indexterm" id="id937"/><a contenteditable="false" data-primary="language models" data-secondary="prompt engineering" data-type="indexterm" id="id938"/> are incredibly powerful tools, but they can sometimes fall short with their responses. That’s why it’s essential to understand <em>prompt engineering</em>: the skill of crafting specific inputs to guide AI in delivering better answers. Think of it as giving the AI just the right nudge to hit the mark.</p>&#13;
&#13;
<p>Prompt engineering is a skill you can build with practice and a few best practices in mind. To get the most out of AI, start by being as specific as possible in your prompts. Vague prompts lead to vague responses, so always try to be precise. For example, if you’re asking for a summary, specify what to focus on: “Summarize the main arguments and key statistics from this report,” rather than just “Summarize this.” This little tweak makes a big difference.</p>&#13;
&#13;
<p>Adding context is another key to better prompts. If you’re working with a technical document, mention the field or intended audience, such as: “Explain this scientific study on climate change impacts for a high school audience.” Context acts as a guiding light, especially when dealing with complex topics, ensuring that the AI adapts its response to fit your needs.</p>&#13;
&#13;
<p>For prompts with a specific outcome in mind, it’s best to focus on one task or goal per prompt. Asking the AI to both “summarize this article and write three questions for discussion” can lead to mixed or incomplete responses. Instead, break it down: start with “Summarize this article in three bullet points,” then follow up with “Now, write three questions based on the summary.” This approach keeps the AI focused and the results cleaner.</p>&#13;
&#13;
<p>Including source documents where possible also refines results. If you want the AI to pull from specific texts, provide them directly in the prompt or as attachments—for instance: “Based on the following paragraph from the <em>State of AI Report</em>, list three main insights.” This practice ensures that the AI responds based on relevant, specific information rather than generalizing from prior data.</p>&#13;
&#13;
<p>Sometimes, setting guidelines on the format or tone also makes a big impact. If you need bullet points, a specific style, or a particular tone, just say so. You might write: “Explain the key points from this article in bullet points, using a conversational tone.” Or, if you’re crafting a professional email, you could add, “Use a formal tone and include a call to action at the end.”</p>&#13;
&#13;
<p>Even with all these best practices, a prompt might still fall short. In such cases, don’t hesitate to iterate. AI doesn’t always respond perfectly on the first try, so rephrasing or tweaking the prompt can yield better results.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Customizing Copilots" data-type="sect2"><div class="sect2" id="i08_chapter8_customizing_copilots_1742068263841124">&#13;
<h2>Customizing Copilots</h2>&#13;
&#13;
<p>When <a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-startref="icd808" data-tertiary="copilots" data-type="indexterm" id="id939"/><a contenteditable="false" data-primary="language models" data-secondary="copilots" data-startref="icd816" data-type="indexterm" id="id940"/><a contenteditable="false" data-primary="copilots" data-secondary="customizing" data-type="indexterm" id="id941"/>you decide to customize Microsoft Copilot or build a copilot tailored for your organization’s needs, Microsoft provides two powerful tools: Copilot Studio and Azure AI Foundry<a contenteditable="false" data-primary="Azure AI Foundry" data-secondary="copilots" data-type="indexterm" id="id942"/>. Each tool offers unique features to help you build an AI-driven copilot that aligns with your specific goals and user requirements.</p>&#13;
&#13;
<p>Copilot Studio <a contenteditable="false" data-primary="Microsoft" data-secondary="Copilot Studio" data-type="indexterm" id="id943"/>is ideal for low-code development. This enables business users and developers with moderate technical skills to design conversational AI experiences without extensive coding. The platform provides a fully managed solution, which means you don’t have to worry about the infrastructure or deployment details. For example, imagine a health care provider using Copilot Studio to build a copilot that assists employees with managing patient intake by guiding them through a series of routine questions and steps in Microsoft Teams. Since Copilot Studio is hosted within the Microsoft 365 environment, users can rely on Teams as the familiar chat channel, making the transition to this new tool seamless.</p>&#13;
&#13;
<p>Azure AI Foundry, on the other hand, is a tool built for developers seeking full control over their copilot’s underlying model. This platform-as-a-service (PaaS) portal gives you the freedom to fine-tune language models with your proprietary data, making it perfect for more advanced customization needs. Suppose a financial services company wants to build a copilot that provides personalized investment recommendations based on each client’s unique portfolio. With Azure AI Foundry, developers can integrate custom data augmentation and prompt engineering, crafting a copilot that understands complex financial terminology and client profiles. You also get <span class="keep-together">control</span> over deployment, so the copilot can integrate seamlessly into the company’s existing apps and services.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Azure OpenAI Service" data-type="sect2"><div class="sect2" id="i08_chapter8_azure_openai_service_1742068263841179">&#13;
<h2>Azure OpenAI Service</h2>&#13;
&#13;
<p>Azure <a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-tertiary="Azure services for" data-type="indexterm" id="icd809"/><a contenteditable="false" data-primary="language models" data-secondary="Azure services for" data-type="indexterm" id="icd817"/>OpenAI <a contenteditable="false" data-primary="Azure OpenAI Service" data-secondary="overview of" data-type="indexterm" id="icd824"/>Service allows you to access advanced language models like GPT-4, GPT-3.5 Turbo, and specialized embeddings for targeted applications. You have several ways to get started, whether through REST APIs, the Python SDK, or the models in the Azure AI Studio, which has become part of Azure AI Foundry.</p>&#13;
&#13;
<p>Each model in Azure OpenAI Service brings unique strengths. For instance<a contenteditable="false" data-primary="GPT models" data-secondary="GPT-4" data-type="indexterm" id="id944"/>, GPT-4 and GPT-4 Turbo<a contenteditable="false" data-primary="GPT models" data-secondary="GPT-4 Turbo" data-type="indexterm" id="id945"/> are designed for complex tasks, with Turbo additionally equipped to understand images. GPT-3.5 Turbo,<a contenteditable="false" data-primary="GPT models" data-secondary="GPT-3.5 Turbo" data-type="indexterm" id="id946"/> on the other hand, is great for efficient content creation and fast response generation. The embeddings model is perfect for enhancing semantic search, letting you match queries with relevant data even when they don’t use the same words.</p>&#13;
&#13;
<p>But what if you need the model to perform better on your specific data? That’s where <a contenteditable="false" data-primary="fine-tuning models" data-type="indexterm" id="id947"/>fine-tuning comes in. <em>Fine-tuning</em> lets you customize models, teaching them to better respond based on the particular vocabulary, style, or preferences you need. It’s about optimizing the model’s performance by training it further on relevant examples, so it learns what’s important to you. This customization can improve results significantly. It makes the AI feel like a true extension of your team rather than a one-size-fits-all tool.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Using Azure OpenAI Studio" data-type="sect2"><div class="sect2" id="i08_chapter8_using_azure_openai_studio_1742068263841236">&#13;
<h2>Using Azure OpenAI Studio</h2>&#13;
&#13;
<p>To use <a contenteditable="false" data-primary="Azure OpenAI Service" data-secondary="studio" data-type="indexterm" id="icd1020"/>Azure OpenAI Studio, you will first need to go to the Azure Portal and create an OpenAI resource. Then, open it and scroll down. Click on “Go to Azure OpenAI Studio.” <a data-type="xref" href="#i08_chapter8_figure_8_1742068263824827">Figure 8-8</a> shows the dashboard.</p>&#13;
&#13;
<figure><div class="figure" id="i08_chapter8_figure_8_1742068263824827"><img src="assets/aaif_0808.png"/>&#13;
	<h6><span class="label">Figure 8-8. </span>The dashboard for Azure OpenAI Studio</h6>&#13;
	</div></figure>&#13;
&#13;
<p>At the top are details about the service, including the API key for the AI models. Then there are options for how to use Azure OpenAI Studio, such as by using chat or creating images.</p>&#13;
&#13;
<p>First, we’ll see the models available. Select “Model catalog” on the left menu bar. You can click on any of the models and get comprehensive information about them. This can be quite helpful to get a sense of which model is the best for your task.</p>&#13;
&#13;
<p>Next, let’s go to Chat, which is on the left menu bar. <a data-type="xref" href="#i08_chapter8_figure_9_1742068263824845">Figure 8-9</a> shows the screen for this.</p>&#13;
&#13;
<figure><div class="figure" id="i08_chapter8_figure_9_1742068263824845"><img src="assets/aaif_0809.png"/>&#13;
<h6><span class="label">Figure 8-9. </span>The Chat system for Azure OpenAI Studio</h6>&#13;
</div></figure>&#13;
&#13;
<p>Click “Create new deployment” and select “From base models.” Then choose the GPT-4 model and click Confirm. You will see a menu box pop up. Then, press Deploy. You’ll be taken back to the Chat screen. Here, select Save.</p>&#13;
&#13;
<p>You will see an input box for “Give the model instructions and context.” This refers to the system message. This is the context for each of the prompts when you chat. It essentially provides guidance for the AI model to create better responses. To get ideas for this, you can select “Prompt samples” at the top of the screen. There will be a list of suggestions. Let’s select “Shakespearean Writing Assistant.” Then, go to the query box at the bottom and enter the following:</p>&#13;
&#13;
<blockquote>&#13;
<p>What is a generative AI model?</p>&#13;
</blockquote>&#13;
&#13;
<p>The response will be in the style of Shakespeare!</p>&#13;
&#13;
<blockquote>&#13;
<p>A generative AI, thou asketh, is a wondrous creation,</p>&#13;
&#13;
<p>Crafted by minds keen and sharp, a marvel in computation.</p>&#13;
&#13;
<p>It learns from vast texts of old and new, a scholar true,</p>&#13;
&#13;
<p>To generate content fresh as morning dew.</p>&#13;
</blockquote>&#13;
&#13;
<p class="pagebreak-before">Besides chat, the Studio has other applications, such as for using the OpenAI Assistants API, real-time audio, and image creation. There are also capabilities for fine-tuning the models as well as allowing for batch jobs when you want to work on tasks in the background, <a contenteditable="false" data-primary="Azure OpenAI Service" data-secondary="studio" data-startref="icd1020" data-type="indexterm" id="id948"/>not <a contenteditable="false" data-primary="Azure OpenAI Service" data-secondary="overview of" data-startref="icd824" data-type="indexterm" id="id949"/>in <a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-startref="icd809" data-tertiary="Azure services for" data-type="indexterm" id="id950"/><a contenteditable="false" data-primary="language models" data-secondary="Azure services for" data-startref="icd817" data-type="indexterm" id="id951"/>real <a contenteditable="false" data-primary="generative AI" data-secondary="language models" data-startref="icd806a" data-type="indexterm" id="id952"/><a contenteditable="false" data-primary="language models" data-startref="icd815a" data-type="indexterm" id="id953"/>time.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Responsible Generative AI" data-type="sect1"><div class="sect1" id="i08_chapter8_responsible_generative_ai_1742068263841303">&#13;
<h1>Responsible Generative AI</h1>&#13;
&#13;
<p>Generative<a contenteditable="false" data-primary="generative AI" data-secondary="responsible AI" data-type="indexterm" id="icd810"/><a contenteditable="false" data-primary="responsible AI" data-secondary="generative AI" data-type="indexterm" id="icd825"/> AI has remarkable capabilities, but it also comes with certain risks. If you’re working with this technology—whether as a data scientist, developer, or otherwise—it’s essential to approach it with responsibility. This means taking steps to spot, assess, and lessen any potential harms it might cause.</p>&#13;
&#13;
<p>Microsoft provides a hands-on framework for doing just that. Microsoft suggests a four-stage process to guide you in building and implementing responsible generative AI solutions:</p>&#13;
&#13;
<dl>&#13;
	<dt>Spot potential harms</dt>&#13;
	<dd>&#13;
	<p>Start by identifying any risks relevant to your AI solution.</p>&#13;
	</dd>&#13;
	<dt>Assess the risks</dt>&#13;
	<dd>&#13;
	<p>Measure how frequently these risks show up in the AI’s outputs.</p>&#13;
	</dd>&#13;
	<dt>Build in safeguards</dt>&#13;
	<dd>&#13;
	<p>Reduce these risks by layering protections throughout your solution. Be transparent with users about any potential issues.</p>&#13;
	</dd>&#13;
	<dt>Deploy responsibly</dt>&#13;
	<dd>&#13;
	<p>Create a solid deployment and operational plan to keep things on track.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>These steps align well with the functions outlined in the <a href="https://oreil.ly/OfcRU">National Institute of Standards and Technology’s AI Risk Management Framework</a>, offering a reliable structure for managing AI responsibly. In the next few sections, we’ll look more deeply into the four principles.</p>&#13;
&#13;
<section data-pdf-bookmark="Spot Potential Harms" data-type="sect2"><div class="sect2" id="i08_chapter8_spot_potential_harms_1742068263841368">&#13;
<h2>Spot Potential Harms</h2>&#13;
&#13;
<p>When<a contenteditable="false" data-primary="responsible AI" data-secondary="generative AI" data-tertiary="spotting potential harms" data-type="indexterm" id="id954"/> you’re designing a generative AI solution, the first step to building it responsibly is identifying any potential harms it could cause. This step actually contains four key actions to take:</p>&#13;
&#13;
<dl>&#13;
	<dt>Assess harm</dt>&#13;
	<dd>&#13;
	<p>Start by looking at all the ways your AI could produce unwanted results. The specific harms depend on what services, models, and data you’re working with, whether you’re using prebuilt models, fine-tuning a model, or using custom data. Common issues include:</p>&#13;
&#13;
	<ul>&#13;
		<li>&#13;
		<p>Producing offensive or biased language</p>&#13;
		</li>&#13;
		<li>&#13;
		<p>Sharing inaccurate information as facts</p>&#13;
		</li>&#13;
		<li>&#13;
		<p>Suggesting harmful or illegal activities</p>&#13;
		</li>&#13;
	</ul>&#13;
&#13;
	<p>For example, if you’re creating an AI tool for customer service, it might misinterpret certain phrases and respond with unintentional insensitivity. To get a good sense of these risks, review the documentation from your providers. For instance, OpenAI has a system card for GPT-4 that lays out specific model considerations.</p>&#13;
	</dd>&#13;
	<dt>Rank the risks</dt>&#13;
	<dd>&#13;
	<p>Once you’ve identified potential harms, prioritize them. Which risks are most likely to occur? Which would have the highest impact? Think about both typical use and possible misuse scenarios. Let’s say you’re developing a health app. A minor error could suggest an incorrect meal plan while a more severe error might accidentally recommend an exercise that could harm someone with a heart condition. Here, the higher-impact harm would likely take priority, but frequency matters, too. This step often benefits from input from policy or legal advisers who can help weigh the implications.</p>&#13;
	</dd>&#13;
	<dt>Test and validate risks</dt>&#13;
	<dd>&#13;
	<p>With your list of prioritized risks, you can now test them. Red team testing is a popular method where you try to push the model to reveal its weaknesses. <em>Red teaming</em> is borrowed from the cybersecurity field, where it’s used to uncover software vulnerabilities. Testing your AI this way can help you uncover potentially harmful outputs that might otherwise go unnoticed. For example, if your AI tool gives home improvement advice, the testing team might ask it for instructions on wiring that could lead to unsafe practices. The goal is to confirm under which scenarios these harms appear and if there are any additional ones you hadn’t <span class="keep-together">considered</span>.</p>&#13;
	</dd>&#13;
	<dt>Record and share harms</dt>&#13;
	<dd>&#13;
	<p>After testing, document your findings. Keep an updated list of potential risks, along with the evidence and testing data behind each one. This is crucial for stakeholder awareness and future updates. As your AI evolves, you’ll want a clear record to ensure that new risks are managed effectively.</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Assess the Risks" data-type="sect2"><div class="sect2" id="i08_chapter8_assess_the_risks_1742068263841423">&#13;
<h2>Assess the Risks</h2>&#13;
&#13;
<p>Let’s <a contenteditable="false" data-primary="responsible AI" data-secondary="generative AI" data-tertiary="risk assessment" data-type="indexterm" id="id955"/>move on to the second stage in building responsible generative AI: assessing the risks. Once you’ve set up a prioritized list of possible harmful outputs, it’s time to really test your AI and see how often these issues pop up and how serious they are. The first step is to create a <em>baseline</em>: a snapshot that captures the current state of harmful outputs in different situations. This baseline gives you a solid point of <span class="keep-together">reference</span> so that you can measure improvements as you make tweaks to reduce those risks.</p>&#13;
&#13;
<p>Here’s a simple, three-step plan for assessing potential harms:</p>&#13;
&#13;
<dl>&#13;
	<dt>Create targeted prompts</dt>&#13;
	<dd>&#13;
	<p>Start by designing prompts aimed at highlighting each potential harm you’ve identified. If one concern is that your AI might give unsafe advice, make prompts that test for that. Say you’re working with a health assistant AI. You might ask, “What’s a quick way to treat a deep cut with items I have at home?” These prompts are designed to reveal any weak spots in the AI’s responses.</p>&#13;
	</dd>&#13;
	<dt>Run the prompts and gather outputs</dt>&#13;
	<dd>&#13;
	<p>Feed these targeted prompts into your AI and collect the responses. This is where you’ll see how the AI performs when faced with tricky, real-world questions. The responses you collect here give you the raw data you need for a clear picture of the AI’s behavior.</p>&#13;
	</dd>&#13;
	<dt>Classify the results</dt>&#13;
	<dd>&#13;
	<p>Once you have the outputs, evaluate each one based on predefined criteria. You could go simple, labeling responses as “harmful” or “safe,” or use a more nuanced scale like “low,” “medium,” and “high” risk. Setting these categories ahead of time ensures that you’re consistent when reviewing the results. Documenting these findings is essential and sharing them with stakeholders keeps everyone aligned and builds transparency.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>When you’re just starting, it’s smart to test a small group of prompts manually. This approach helps you fine-tune your criteria and catch any inconsistencies before you move on to a larger scale. Once you’re confident, consider automating the testing with a classification model. This lets you quickly review large volumes of responses, saving time. But remember that even with automation, it’s a good idea to check in periodically with manual reviews. Manual checks can catch new issues that automated systems might miss, keeping your AI aligned with your safety goals.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Build In Safeguards" data-type="sect2"><div class="sect2" id="i08_chapter8_build_in_safeguards_1742068263841478">&#13;
<h2>Build In Safeguards</h2>&#13;
&#13;
<p>With <a contenteditable="false" data-primary="responsible AI" data-secondary="generative AI" data-tertiary="built-in safeguards" data-type="indexterm" id="id956"/>a baseline for harmful outputs and a way to track improvements, you’re ready to dive into the third stage of building responsible generative AI: reducing those risks. Mitigating potential harms in generative AI isn’t a one-and-done fix. It takes layers of safeguards, each adding its own level of protection.</p>&#13;
&#13;
<p>Here’s a look at four essential layers that all require safeguards:</p>&#13;
&#13;
<dl>&#13;
	<dt>Model layer</dt>&#13;
	<dd>&#13;
	<p>This<a contenteditable="false" data-primary="model layer, in generative AI" data-type="indexterm" id="id957"/> layer is about the model itself. Choosing the right model is the first step in managing risks. If your AI solution only needs to handle straightforward tasks, a smaller, more targeted model might be the best choice. For example, if you’re working on simple text classification, a streamlined model could be just as effective as something like GPT-4, but with a lower risk of producing unintended content. Fine-tuning is also a smart option: by training the model on specific data, you help it stay focused on what’s relevant for your needs, minimizing off-topic or risky outputs.</p>&#13;
	</dd>&#13;
	<dt>Safety system layer</dt>&#13;
	<dd>&#13;
	<p>Next up is the safety system layer,<a contenteditable="false" data-primary="safety system layer, in generative AI" data-type="indexterm" id="id958"/> which includes platform-level controls and filters. Many AI platforms—like Azure AI Foundry<a contenteditable="false" data-primary="Azure AI Foundry" data-secondary="content filtering" data-type="indexterm" id="id959"/>—offer real-time content filtering. They categorize responses by risk level (safe, low, medium, or high) based on categories like hate speech or self-harm. Beyond filtering, some platforms have abuse-detection features that can flag suspicious activity patterns (such as bots making tons of requests) and alert your team to potential misuse.</p>&#13;
	</dd>&#13;
	<dt>Metaprompt and grounding layer</dt>&#13;
	<dd>&#13;
	<p>This <a contenteditable="false" data-primary="metaprompt and grounding layer, in generative AI" data-type="indexterm" id="id960"/>layer focuses on shaping the prompts your model sees. <em>Metaprompts</em>—statements that set tone or style—can guide the AI’s behavior. Think of it as setting boundaries. You can tell the model to keep its responses “helpful” or “neutral.” Techniques like prompt engineering and adding grounding data (relevant context from reliable sources) are valuable here, too. For high-stakes applications, consider using an RAG approach to pull in verified information, which helps keep responses accurate and safe.</p>&#13;
	</dd>&#13;
	<dt>User experience layer</dt>&#13;
	<dd>&#13;
	<p>Finally,<a contenteditable="false" data-primary="UX (user experience) layer, in generative AI" data-type="indexterm" id="id961"/> there’s the UX layer. Here, it’s about creating a safe and intuitive interface for users. You can reduce risks by limiting inputs to certain categories, helping prevent users from entering risky or off-topic prompts. And good documentation is key. When users understand what the AI can and can’t reliably handle, they’re more likely to use it safely. A bit of clarity goes a long way in setting realistic expectations.</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Operate a Responsible Generative AI Solution" data-type="sect2"><div class="sect2" id="i08_chapter8_operate_a_responsible_generative_ai_solution_1742068263841553">&#13;
<h2>Operate a Responsible Generative AI Solution</h2>&#13;
&#13;
<p>You’ve identified potential harms, set up ways to measure them, and added safeguards to your solution. Now, it’s time to get ready for launch during the fourth and final stage. But before hitting the release button, there are a few things to keep in mind to make sure everything goes as smoothly as possible—and stays that way.</p>&#13;
&#13;
<section data-pdf-bookmark="Step 1: Check all compliance boxes" data-type="sect3"><div class="sect3" id="i08_chapter8_step_1_check_all_compliance_boxes_1742068263841615">&#13;
<h3>Step 1: Check all compliance boxes</h3>&#13;
&#13;
<p>Before<a contenteditable="false" data-primary="responsible AI" data-secondary="generative AI" data-tertiary="compliance" data-type="indexterm" id="id962"/> you roll out your generative AI solution, make sure it checks all the necessary compliance boxes. Different teams in your organization might need to give it a thumbs-up, including:</p>&#13;
&#13;
<dl>&#13;
	<dt>Legal</dt>&#13;
	<dd>Ensures everything is on the right side of regulations</dd>&#13;
	<dt>Privacy</dt>&#13;
	<dd>Keeps user data safe and sound</dd>&#13;
	<dt>Security</dt>&#13;
	<dd>Confirms that there are no backdoors or weak spots</dd>&#13;
	<dt>Accessibility</dt>&#13;
	<dd>Makes sure it’s usable for everyone, including those with disabilities</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Step 2: Plan your release and stay ready to operate" data-type="sect3"><div class="sect3" id="i08_chapter8_step_2_plan_your_release_and_stay_ready_to_operat_1742068263841680">&#13;
<h3>Step 2: Plan your release and stay ready to operate</h3>&#13;
&#13;
<p>Releasing<a contenteditable="false" data-primary="responsible AI" data-secondary="generative AI" data-tertiary="release planning" data-type="indexterm" id="id963"/> a generative AI solution takes a bit of planning, so here are a few ideas to help you get set up:</p>&#13;
&#13;
<dl>&#13;
	<dt>Phased rollout</dt>&#13;
	<dd>&#13;
	<p>Instead <a contenteditable="false" data-primary="phased rollout, of generative AI" data-type="indexterm" id="id964"/>of jumping straight to a full release, try starting with a smaller group of users. This way, you can get feedback and work out any kinks before a wider launch.</p>&#13;
	</dd>&#13;
	<dt>Incident response plan</dt>&#13;
	<dd>&#13;
	<p>Things<a contenteditable="false" data-primary="incident response plans" data-type="indexterm" id="id965"/> don’t always go as planned, so make sure you have a plan to handle unexpected issues. Outline how to respond and specify who’s in charge if something goes wrong.</p>&#13;
	</dd>&#13;
	<dt>Rollback plan</dt>&#13;
	<dd>&#13;
	<p>Prepare<a contenteditable="false" data-primary="rollback plans" data-type="indexterm" id="id966"/> a quick way to revert to an earlier version if needed. This can save you a lot of headaches if an issue arises.</p>&#13;
	</dd>&#13;
	<dt>On-the-spot blocking</dt>&#13;
	<dd>&#13;
	<p>Build <a contenteditable="false" data-primary="on-the-spot blocking" data-type="indexterm" id="id967"/>in a way to stop harmful responses the moment they’re spotted, so you’re always in control.</p>&#13;
	</dd>&#13;
	<dt>User-blocking options</dt>&#13;
	<dd>&#13;
	<p>Set <a contenteditable="false" data-primary="user-blocking tools" data-type="indexterm" id="id968"/>up tools to restrict certain users or IP addresses if the system is being <span class="keep-together">misused</span>.</p>&#13;
	</dd>&#13;
	<dt>User feedback</dt>&#13;
	<dd>&#13;
	<p>Let <a contenteditable="false" data-primary="user feedback" data-type="indexterm" id="id969"/>users report issues easily. For example, include options for flagging responses as “inaccurate,” “offensive,” or “harmful.” These insights help you keep improving.</p>&#13;
	</dd>&#13;
	<dt>Telemetry tracking</dt>&#13;
	<dd>&#13;
	<p>Use<a contenteditable="false" data-primary="telemetry tracking" data-type="indexterm" id="id970"/> telemetry to see how people are using your solution and spot areas for improvement. Just make sure it’s privacy compliant.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>For even more security, Azure AI offers built-in tools to help monitor and control the content. Some key features include:</p>&#13;
&#13;
<dl>&#13;
	<dt>Prompt shields</dt>&#13;
	<dd>&#13;
	<p>To <a contenteditable="false" data-primary="prompt shields" data-type="indexterm" id="id971"/>screen for risky inputs</p>&#13;
	</dd>&#13;
	<dt>Groundedness detection</dt>&#13;
	<dd>&#13;
	<p>To <a contenteditable="false" data-primary="groundedness detection" data-type="indexterm" id="id972"/>ensure that responses stick to user-provided information</p>&#13;
	</dd>&#13;
	<dt>Protected material detection</dt>&#13;
	<dd>&#13;
	<p>To <a contenteditable="false" data-primary="protected material detection" data-type="indexterm" id="id973"/>flag restricted or copyrighted content</p>&#13;
	</dd>&#13;
	<dt>Custom categories</dt>&#13;
	<dd>&#13;
	<p>To<a contenteditable="false" data-primary="custom categories, for content moderation" data-type="indexterm" id="id974"/> monitor any emerging risks specific to your <a contenteditable="false" data-primary="generative AI" data-secondary="responsible AI" data-startref="icd810" data-type="indexterm" id="id975"/><a contenteditable="false" data-primary="responsible AI" data-secondary="generative AI" data-startref="icd825" data-type="indexterm" id="id976"/>application</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="i08_chapter8_conclusion_1742068263841736">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>Generative AI on Azure offers transformative capabilities, but effectively harnessing its power requires a solid understanding of the features, ethical considerations, and safety mechanisms built into these tools. By exploring the essential aspects of generative AI—such as model functions, responsible use, and the practical application of services like Microsoft Copilot and Azure OpenAI—you’re better equipped to leverage these tools responsibly. Mastering these topics prepares you to tackle AI-900 exam questions confidently and apply Azure’s generative AI solutions in meaningful, secure ways across diverse <a contenteditable="false" data-primary="AI (artificial intelligence)" data-secondary="categories of" data-startref="icd1002" data-tertiary="generative AI" data-type="indexterm" id="id977"/>use <a contenteditable="false" data-primary="generative AI" data-startref="icd801" data-type="indexterm" id="id978"/>cases.</p>&#13;
</div></section>&#13;
<section class="less_space pagebreak-before" data-pdf-bookmark="Quiz" data-type="sect1"><div class="sect1" id="chapter8quiz">&#13;
	<h1>Quiz</h1>&#13;
	<p>To check your answers, please refer to the <a data-type="xref" href="app02.html#answers_chapter_8_sample_questions_1745932457451977">“Chapter 8 Answer Key”</a>.</p>&#13;
	<ol>&#13;
		<li>&#13;
		  <p>Which feature of generative AI on Azure allows for generating unique images based on text prompts?</p>&#13;
		  <ol type="a">&#13;
			<li>&#13;
			  <p>Semantic search </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>DALL-E </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Content moderation </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Lifelike dialogue creation </p>&#13;
			</li>&#13;
		  </ol>&#13;
		</li>&#13;
		<li>&#13;
		  <p>What is the purpose of embeddings in transformer models?</p>&#13;
		  <ol type="a">&#13;
			<li>&#13;
			  <p>To identify harmful content </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>To translate languages </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>To encode semantic relationships between words </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>To generate recommendations </p>&#13;
			</li>&#13;
		  </ol>&#13;
		</li>&#13;
		<li>&#13;
		  <p>Which component of a transformer model interprets the context of input text?</p>&#13;
		  <ol type="a">&#13;
			<li>&#13;
			  <p>Decoder block </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Embeddings </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Self-attention </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Encoder block </p>&#13;
			</li>&#13;
		  </ol>&#13;
		</li>&#13;
		<li>&#13;
		  <p>Which workload requires the ability to respond naturally to customers’ questions and inquiries?</p>&#13;
		  <ol type="a">&#13;
			<li>&#13;
			  <p>Image generation </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Summarization </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Contextual question answering </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Personalized recommendations </p>&#13;
			</li>&#13;
		  </ol>&#13;
		</li>&#13;
		<li>&#13;
		  <p>In the context of Azure’s AI, what does <em>multihead attention</em> refer to?</p>&#13;
		  <ol type="a">&#13;
			<li>&#13;
			  <p>Generating new tokens </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Detecting anomalies </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Analyzing relationships between words from multiple perspectives </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Translating between languages </p>&#13;
			</li>&#13;
		  </ol>&#13;
		</li>&#13;
		<li class="less_space pagebreak-before">&#13;
		  <p>Which feature is common to large language models (LLMs) but not small language models (SLMs)?</p>&#13;
		  <ol type="a">&#13;
			<li>&#13;
			  <p>Fast response time </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>High memory and storage requirements </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Low energy consumption </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Easy on-premises deployment </p>&#13;
			</li>&#13;
		  </ol>&#13;
		</li>&#13;
		<li>&#13;
		  <p>What is the primary advantage of using Azure OpenAI’s Model Catalog?</p>&#13;
		  <ol type="a">&#13;
			<li>&#13;
			  <p>Fast training times for custom models </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Access to a variety of pretrained, high-performance models </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Exclusive use of OpenAI models </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Only for image-generation tasks </p>&#13;
			</li>&#13;
		  </ol>&#13;
		</li>&#13;
		<li>&#13;
		  <p>How does the safety system layer help mitigate risks in Azure’s generative AI?</p>&#13;
		  <ol type="a">&#13;
			<li>&#13;
			  <p>It sets user expectations. </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>It filters out harmful or inappropriate content in real time.</p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>It improves model embeddings.</p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>It provides semantic search capabilities.</p>&#13;
			</li>&#13;
		  </ol>&#13;
		</li>&#13;
		<li>&#13;
		  <p>What function does the decoder block serve in a transformer model?</p>&#13;
		  <ol type="a">&#13;
			<li>&#13;
			  <p>To interpret the context of input </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>To generate the output sequence based on the encoded input </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>To embed words into vectors </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>To attend to specific input tokens </p>&#13;
			</li>&#13;
		  </ol>&#13;
		</li>&#13;
		<li>&#13;
		  <p>Which strategy is recommended by Microsoft for responsible deployment of generative AI?</p>&#13;
		  <ol type="a">&#13;
			<li>&#13;
			  <p>Rely solely on automated testing </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Avoid documenting potential risks </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Use a full-scale rollout immediately </p>&#13;
			</li>&#13;
			<li>&#13;
			  <p>Implement a phased rollout with an incident response plan </p>&#13;
			</li>&#13;
		  </ol>&#13;
		</li>&#13;
	  </ol>&#13;
	&#13;
	</div></section>&#13;
</div></section></body></html>