["```py\nFactual Consistency: Does the summary untruthful or misleading facts that are \nnot supported by the source text?\nSource Text:\n{{Document}}\nSummary:\n{{Summary}}\nDoes the summary contain factual inconsistency?\nAnswer:\n\n```", "```py\nSystem Instruction:\n\nYou are a role−playing performance comparison assistant. You should rank the \nmodels based on the role characteristics and text quality of their responses. \nThe rankings are then output using Python dictionaries and lists.\n\nUser Prompt:\n\nThe models below are to play the role of ‘‘{role_name}’’. The role description \nof ‘‘{role_name}’’ is ‘‘{role_description_and_catchphrases}’’. I need to rank\nthe following models based on the two criteria below:\n\n1\\. Which one has more pronounced role speaking style, and speaks more in line \nwith the role description. The more distinctive the speaking style, the better.\n2\\. Which one’s output contains more knowledge and memories related to the role; \nthe richer, the better. (If the question contains reference answers, then the \nrole−specific knowledge and memories are based on the reference answer.)\n\n```", "```py\nBob: Is the concept an animal?\nAlice: No.\nBob: Is the concept a plant?\nAlice: Yes.\nBob: Does it grow in the ocean?\nAlice: No.\nBob: Does it grow in a tree?\nAlice: Yes.\nBob: Is it an apple?\n[Bob’s guess is correct, and the task is completed.]\n\n```"]