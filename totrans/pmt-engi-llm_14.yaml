- en: Chapter 11\. Looking Ahead
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 11 章\. 展望未来
- en: Human history only makes sense on a logarithmic scale. It took humans countless
    eons to figure out farming, millennia beyond that to invent writing, centuries
    more to invent the steam engine, and decades more to invent the automobile, computer,
    and smartphone. Just a few years after that, around 2012, deep learning appeared
    on the scene.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 人类历史只有在对数尺度上才有意义。人类花费了无数个时代来了解农业，在那之后的千年发明了书写，再之后的几个世纪发明了蒸汽机，再之后的几十年发明了汽车、计算机和智能手机。在那之后仅仅几年，大约在
    2012 年，深度学习出现在了舞台上。
- en: OpenAI’s GPT-2 was announced in 2019, and then ChatGPT was announced in 2022\.
    This ignited an explosion of development around LLMs. Many companies have jumped
    into the fray—Anthropic, Google, Microsoft, Meta, xAI, NVIDIA, Mistral, and more—all
    building new LLMs that have leap-frogged the previous ones in capability, capacity,
    and speed. In mere months, LLMs have morphed from document completion engines,
    to chat engines, to agents that can interact with the outside world.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 的 GPT-2 在 2019 年宣布，然后 ChatGPT 在 2022 年宣布。这引发了围绕 LLM 的开发爆炸。许多公司都加入了这场混战——Anthropic、Google、Microsoft、Meta、xAI、NVIDIA、Mistral
    以及更多——所有这些公司都在构建新的 LLM，这些 LLM 在能力、容量和速度上都超越了之前的版本。仅仅几个月的时间，LLM 就从文档完成引擎变成了聊天引擎，再到可以与外界互动的代理。
- en: Buckle up, readers. If you think the pace of change is fast now, then just wait,
    it’s only going to get faster. (Maybe that Ray Kurzweil guy was on to something!)
    In this final chapter, let’s look ahead to some of the developments on our horizon
    and how they will change your work as a prompt engineer.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 读者们，系好安全带。如果你认为现在的变化速度已经很快，那么就再等等，它只会变得更快。（也许那个雷·库兹韦尔家伙真的有所发现！）在本章的最后，让我们展望一下我们眼前的某些发展，以及它们将如何改变你作为提示工程师的工作。
- en: Multimodality
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多模态
- en: There is a huge push toward the use of multimodal models. OpenAI kicked off
    this trend with GPT-4, which was able to process images as part of the prompt.
    Although OpenAI has not disclosed details about how exactly the model works, most
    likely, it closely follows the methods published in [academic literature](https://arxiv.org/abs/2202.10936).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 对多模态模型的使用有着巨大的推动力。OpenAI 通过 GPT-4 启动了这一趋势，该模型能够作为提示的一部分处理图像。尽管 OpenAI 没有披露模型具体工作方式的细节，但很可能是它紧密遵循了在[学术文献](https://arxiv.org/abs/2202.10936)中发布的方法。
- en: In one such method, a convolutional network is used to convert image features
    into embedding vectors of the same dimensions as those used for text tokens. The
    image vectors are imbued with positional information so that the relationships
    among the features in the image are retained. The image and text vectors are then
    concatenated. Finally, the transformer architecture processes this information
    in much the same way that text-only LLMs process pure text (see [Chapter 2](ch02.html#ch02_understanding_llms_1728407258904677)).
    Multimodality can naively be extended to video input—all you have to do is sample
    images from the video, as demonstrated in this [OpenAI cookbook](https://oreil.ly/RhK-7).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这样的方法中，卷积网络被用来将图像特征转换为与用于文本标记的维度相同的嵌入向量。图像向量被赋予了位置信息，以便保留图像中特征之间的关系。然后，将图像和文本向量连接起来。最后，Transformer
    架构以与仅处理纯文本的 LLM 相似的方式处理这些信息（参见[第 2 章](ch02.html#ch02_understanding_llms_1728407258904677)）。多模态可以天真地扩展到视频输入——你所要做的就是从视频中采样图像，如本[OpenAI
    烹饪书](https://oreil.ly/RhK-7)中所示。
- en: As they mature, multimodal models are going to be extremely useful in domains
    that can’t be captured by text. For example, it’s easy to imagine how these models
    can be used to make the world much more accessible to a person with vision impairment.
    A vision model could help them read signs, find buildings, and navigate unfamiliar
    environments.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 随着它们的发展成熟，多模态模型将在无法仅通过文本捕捉的领域变得极其有用。例如，很容易想象这些模型如何被用来使世界对视力受损的人更加易于访问。一个视觉模型可以帮助他们阅读标志、寻找建筑物，以及导航不熟悉的环境。
- en: Another reason that multimodal models are important is because they give the
    models access to a large volume of rich training data. Over the past few years,
    there has been increasing concern that we might actually run out of training data!
    The models are large enough that they can learn increasingly intricate details
    about the world. However, if we overtrain with a set of data that is too small,
    then these models can overfit—effectively memorizing text rather than modeling
    how the world works. Amazingly, literally *the text of the entire public internet*
    may not be enough for the next generation of large models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态模型之所以重要，另一个原因是它们为模型提供了访问大量丰富训练数据的机会。在过去的几年里，人们越来越担心我们可能会真正耗尽训练数据！模型足够大，可以学习关于世界的越来越复杂的细节。然而，如果我们用一组过小的数据过度训练，那么这些模型可能会过拟合——实际上是记住文本而不是模拟世界的工作方式。令人惊讶的是，即使是整个公共互联网的文本可能也不足以满足下一代大型模型的需求。
- en: However, when we incorporate images and video into the training, we gain access
    to vastly more content. Moreover, the image and video content carry a very different
    type of information that can help models better understand the world around them;
    with access to images, it should become much simpler for models to understand
    tasks related to spatial reasoning, social cues, physical common sense, and much
    more.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我们把图像和视频纳入训练时，我们能够接触到大量内容。此外，图像和视频内容携带了一种非常不同的信息类型，这有助于模型更好地理解周围的世界；有了图像的访问权限，模型理解与空间推理、社交线索、物理常识等相关任务应该会变得简单得多。
- en: As a prompt engineer, when you build future LLM applications, you are likely
    to include images and videos in the prompt—and even though they constitute a completely
    different form of information, you can make use of some of the lessons in this
    book when dealing with them. Remember to include only images that are relevant
    to the conversation at hand so that the model doesn’t get distracted. Frame the
    images with text that properly introduces their role in the conversation and make
    use of patterns and motifs that were in the training data. For instance, don’t
    introduce a new type of diagram to convey information when there is a common format
    that is more readily available on the internet.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提示工程师，当你构建未来的LLM应用时，你可能会在提示中包含图像和视频——尽管它们构成了完全不同的信息形式，但在处理它们时，你可以利用这本书中的一些教训。请记住，只包含与当前对话相关的图像，以免模型分心。用文字为图像设定框架，正确介绍它们在对话中的作用，并利用训练数据中的模式和主题。例如，当互联网上已经有现成的通用格式时，不要引入一种新的图表类型来传达信息。
- en: User Experience and User Interface
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户体验和用户界面
- en: The UI of many consumer applications is currently moving toward conversational
    interactions. It makes sense, right? Humans have been speaking to each other for
    200,000 years but only clicking buttons on screens for the past 40\. In this section,
    we’ll focus on a new element of the conversation that has caught our attention—artifacts—or,
    as we like to call them, *stateful objects of discourse*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 许多消费应用的UI目前正朝着对话交互的方向发展。这合理吗？人类已经相互交谈了20万年，但只在屏幕上点击按钮才40年。在本节中，我们将关注一个引起我们注意的新对话元素——*文物*，或者我们喜欢称之为*状态化的讨论对象*。
- en: Think about it. In day-to-day collaboration with other humans, we often talk
    about a *thing*—the *object of discourse*. And as we talk about it, we can talk
    about how we want to change it, we can actually modify it, and we can talk about
    how it has changed over time—meaning we can talk about its state. Pair programming
    is a great example here. The files are the objects of discourse, and during pairing,
    we can change them and talk about how they are changing.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 想想看。在日常与人合作中，我们经常谈论一个*事物*——*讨论的对象*。当我们谈论它时，我们可以讨论我们想要如何改变它，我们实际上可以修改它，我们还可以讨论它随时间的变化——这意味着我们可以讨论它的状态。结对编程就是一个很好的例子。文件是讨论的对象，在结对编程过程中，我们可以修改它们并讨论它们是如何变化的。
- en: In most chat applications today, the assistants don’t address the object of
    the conversation in a stateful way. If you ask ChatGPT to write a function and
    then later modify it, it can’t go back and update the contents of the function.
    Instead, it rewrites the function over and over again, from scratch. Rather than
    having one object whose state has evolved, ChatGPT writes *N* objects into the
    conversation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今大多数聊天应用中，助手并没有以有状态的方式处理对话对象。如果你要求 ChatGPT 编写一个函数，然后稍后修改它，它无法回过头来更新函数的内容。相反，它每次都会从头开始重写函数。ChatGPT
    不是写一个状态演变的对象，而是将*N*个对象写入对话。
- en: What’s more, it is difficult to specify which object you’re talking about, especially
    if you have multiple objects in play. Which function were you talking about? Which
    version? These problems make it difficult to work with the assistant *on* something
    rather than just having a conversation in which ideas are expected to fly by and
    go out of scope.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，指定你正在谈论的对象很困难，尤其是如果你有多个对象在操作中。你谈论的是哪个函数？哪个版本？这些问题使得与助手一起在某个事物上工作变得困难，而不是仅仅进行一个期望想法飞快而过并超出范围的对话。
- en: As we were wrapping up this book, Anthropic introduced *Artifacts*, which represents
    a step in the direction of stateful objects of discourse. In a conversation with
    Anthropic’s Claude, the Artifact *is* the stateful object of discourse. It can
    be an SVG image, an HTML file, a mermaid diagram, code, or any other type of text
    fragment. During a conversation, the user works with the assistant to modify the
    Artifact until it reaches the user’s expectations. And while the back-and-forth
    conversation is captured in a transcript on the left side of the screen, the Artifact
    they are discussing remains—statefully—on the right side of the screen (see [Figure 11-1](#ch11_figure_1_1728407067176842)).
    If the user asks for the Artifact to be modified, then the state of the Artifact
    is updated in place rather than regurgitated over and over again in the transcript.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们完成这本书的时候，Anthropic 引入了*文物*，这代表了向有状态的对话对象迈出的一步。在与 Anthropic 的克劳德对话中，文物*就是*有状态的对话对象。它可以是
    SVG 图像、HTML 文件、mermaid 图表、代码或任何其他类型的文本片段。在对话过程中，用户与助手一起修改文物，直到达到用户的期望。虽然来回对话被记录在屏幕左边的记录中，但他们讨论的文物仍然——有状态地——保持在屏幕的右侧（见[图
    11-1](#ch11_figure_1_1728407067176842)）。如果用户要求修改文物，那么文物的状态将就地更新，而不是在记录中反复重复。
- en: '![A screenshot of a chat  Description automatically generated](assets/pefl_1101.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![聊天截图  描述由自动生成](assets/pefl_1101.png)'
- en: Figure 11-1\. Working with Claude to draw a peg-legged pirate with a patch over
    his eye while statefully discussing the fact that the image appears to be missing
    actual legs and eyes
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-1\. 与克劳德一起绘制一个戴眼罩的独腿海盗，同时有状态地讨论图像似乎缺少实际腿和眼睛的事实
- en: Claude’s Artifacts paradigm is very close to what we have in mind, but there’s
    still room for improvement. For instance, much of the change is just in the UI,
    rather than in the prompt engineering. When you ask for a change, Claude is still
    rewriting the entire Artifact from scratch; it just knows to put the Artifact
    in the right pane. This form of editing might not scale well to longer documents.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 克劳德的文物范式与我们心中的想法非常接近，但仍有改进的空间。例如，大部分变化只是在于用户界面，而不是在提示工程上。当你要求更改时，克劳德仍然会从头开始重写整个文物；它只是知道将文物放在正确的面板中。这种编辑形式可能不适合较长的文档。
- en: Additionally, it’s not easy to interact with multiple Artifacts at once. Claude’s
    interface assumes one Artifact at a time. If you start talking about a different
    Artifact, then the UI treats it as if it were just a different version of the
    previous interface. Another problem with multiple Artifacts is that it’s hard
    to refer to them. It would be nice if both the UI and the prompt included shorthand
    names for the items.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，同时与多个文物互动并不容易。克劳德的界面假设一次只处理一个文物。如果你开始谈论不同的文物，那么用户界面会将其视为前一个界面的一个不同版本。多个文物的另一个问题是很难引用它们。如果用户界面和提示都包含项目的缩写名称，那就太好了。
- en: Finally, Claude’s interface and the prompt engineering (for that matter) don’t
    allow the user to edit the Artifact. If you see a small problem that you could
    easily fix, the only way to address it is to tell the assistant to fix the problem
    for you (by retyping the whole file). It would be a better experience if the user
    could update the Artifact and then have this update reflected in the next prompt
    so that the model is aware of the change.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Claude的界面和提示工程（同样）不允许用户编辑工件。如果你看到一个小问题，你很容易就能修复，唯一解决问题的方法就是告诉助手帮你修复问题（通过重新输入整个文件）。如果用户能够更新工件，并在下一个提示中反映这一更新，以便模型意识到这一变化，那将是一个更好的体验。
- en: When building LLM interfaces in your own LLM applications, it can be a good
    idea to lean into a conversational interface since conversation is so intuitive
    for humans. But if so, you need to invest time to really get it right—it’s easy
    to whip up something bare-bones with LLMs, but it will be a gimmicky distraction
    rather than something that provides true benefits, unless it’s properly thought
    through and fleshed out.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在自己的LLM应用中构建LLM界面时，考虑到对话对人类来说非常直观，采用对话界面可能是个不错的选择。但如果是这样的话，你需要投入时间去真正做好它——使用LLM可以轻易地制作出基础版本，但如果没有经过深思熟虑和充分完善，它将只会是一个花哨的干扰，而不是真正提供好处的东西。
- en: Model designers are aware of this need, and they innovate to support it. Tools
    were a great improvement—they gave the assistants the ability to take action in
    the world. Artifacts are similarly useful—they allow conversations to be about
    *things* (i.e., stateful objects of discourse). What’s next?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 模型设计者意识到这个需求，并为此进行创新。工具的改进是一个巨大的进步——它们赋予了助手在现实世界中采取行动的能力。类似地，工件也非常有用——它们使得对话可以围绕*事物*（即，有状态的讨论对象）进行。接下来是什么？
- en: The conversational UI is also a great way to keep users in the loop. As we discussed
    in [Chapter 8](ch08.html#ch08_01_conversational_agency_1728429579285372), models
    tend to stray off course if left to their own devices. But in a close conversational
    interaction, users can identify problems early and put the assistant back on course.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对话式用户界面也是让用户保持参与的好方法。正如我们在[第8章](ch08.html#ch08_01_conversational_agency_1728429579285372)中讨论的那样，如果让模型自行其是，它们往往会偏离轨道。但在紧密的对话互动中，用户可以及早发现问题，并将助手重新引回正轨。
- en: Intelligence
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 智能化
- en: Has anyone noticed that LLMs are getting a lot smarter? Yeah…and they’re going
    to keep getting smarter too. Let’s look at some upcoming developments.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 有没有人注意到LLM变得越来越聪明了？是的，而且它们还会继续变得更聪明。让我们看看一些即将到来的发展。
- en: 'For one thing, we’re getting smarter with our benchmarks. Benchmarks are problem
    sets with known answers that allow us to measure how well models perform relative
    to humans and relative to one another. At this point, several of the most useful
    benchmarks have saturated (see [Figure 11-2](#ch11_figure_2_1728407067176876)),
    meaning that the leading models tend to ace them. This makes the benchmarks useless
    for evaluating model improvements. There are two reasons that models saturate
    the benchmarks: (1) models really are getting smarter—*a good thing*, and (2)
    models are cheating by training on the benchmarks—*a very bad thing*. The “cheating”
    isn’t intentional; it’s just that after a couple of years, information from benchmarks
    gets duplicated (verbatim or through descriptions) all over the internet and accidentally
    pulled into training.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们在基准测试上变得更聪明了。基准测试是包含已知答案的问题集，它允许我们衡量模型相对于人类和彼此的表现。到目前为止，一些最有用的基准测试已经饱和（见[图11-2](#ch11_figure_2_1728407067176876)），这意味着领先模型往往能轻松通过它们。这使得基准测试在评估模型改进方面变得无用。模型饱和基准测试有两个原因：（1）模型确实变得更聪明了——这是一件好事；（2）模型通过在基准测试上训练来作弊——这是一件非常糟糕的事情。这种“作弊”并非有意为之；只是经过几年后，基准测试的信息在互联网上到处重复（字面或通过描述），并意外地被拉入训练中。
- en: To fix this, we in the AI community are being diligent in upgrading our benchmarks
    (for instance, on the [Open LLM Leaderboard 2](https://oreil.ly/zr_z6)). We have
    also started using nonmemorizable benchmarks such as [ARC-AGI](https://oreil.ly/YTM0M),
    which is effectively a set of psychometric intelligence tests composed of patterns
    of shapes. They test how well the individual—or LLM—can understand and reproduce
    novel patterns, and it’s impossible to memorize all of the test questions because
    they belong to a very large space of possible tests, they are algorithmically
    generated, and you can always generate more of them.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们这个AI社区正在勤奋地升级我们的基准（例如，在[Open LLM Leaderboard 2](https://oreil.ly/zr_z6)上）。我们还开始使用不可记忆的基准，如[ARC-AGI](https://oreil.ly/YTM0M)，它实际上是一套由形状模式组成的心理测量智力测试。它们测试个人或LLM理解并再现新模式的能力，由于测试问题属于一个非常大的可能测试空间，它们是算法生成的，你可以总是生成更多。
- en: '![A graph of different colored lines   Description automatically generated](assets/pefl_1102.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![不同颜色线条的图表   自动生成的描述](assets/pefl_1102.png)'
- en: Figure 11-2\. Popular benchmarks saturate over time, making them useless as
    benchmarks going forward
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-2\. 流行基准随着时间的推移而饱和，这使得它们作为基准变得无用
- en: We’re also getting smarter with model training. You can actually watch this
    happen when you use ChatGPT or its competitors because, thanks to better RLHF
    training (refer back to [Chapter 3](ch03.html#ch03a_moving_toward_chat_1728432131625250)),
    the models are doing a much better job of expressing their chain-of-thought reasoning,
    which inevitably leads to more useful responses.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在模型训练方面也越来越聪明。当你使用ChatGPT或其竞争对手时，你可以实际看到这一过程的发生，因为得益于更好的RLHF训练（参考[第3章](ch03.html#ch03a_moving_toward_chat_1728432131625250)），模型在表达它们的思维链推理方面做得更好，这不可避免地导致更有效的响应。
- en: Next, we’re getting more creative with training approaches. For example, large
    models generally don’t utilize their full capacity, so, if you can figure out
    a way to convey knowledge to a small model, then you can effectively compress
    the information of the large model into the small model. A training approach known
    as *knowledge distillation* uses a large model as a “teacher” of a small model.
    Rather than training the small model to predict the next token, knowledge distillation
    trains the small model to mimic the large model by predicting the full set of
    probabilities for the next token. This richer set of training data allows smaller
    models to be trained quickly, with only a slight decrease in accuracy compared
    to their teacher models. In exchange for the hit in accuracy, these small models
    are significantly cheaper and faster than the large models they were trained from.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们在训练方法上变得更加有创意。例如，大型模型通常没有充分利用它们的全部能力，所以，如果你能想出一种方法将知识传达给小型模型，那么你就可以有效地将大型模型的信息压缩到小型模型中。一种称为*知识蒸馏*的训练方法使用大型模型作为小型模型的“教师”。知识蒸馏不是训练小型模型来预测下一个标记，而是训练小型模型通过预测下一个标记的完整概率集来模仿大型模型。这更丰富的训练数据集允许小型模型快速训练，与它们的教师模型相比，准确度略有下降。作为对准确度下降的补偿，这些小型模型比它们训练的大型模型便宜得多，速度快得多。
- en: Besides training, model improvements will come from architectural innovation.
    Here, we name just a few. For one, models are getting smaller and faster through
    *quantization* approaches, in which, instead of representing parameters as 32-bit
    floating point numbers, you can approximate them with 8-bit parameters, reducing
    the model size considerably and correspondingly decreasing the cost and increasing
    the speed.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了训练之外，模型改进还将来自架构创新。在这里，我们只列举几个。首先，通过*量化*方法，模型正变得越来越小和更快，在这种方法中，你不需要用32位浮点数来表示参数，而是可以用8位参数来近似它们，从而大大减少模型大小，相应地降低成本并提高速度。
- en: In your prompt-engineering work, you should be able to expect these trends to
    continue. If something is too expensive today, it will be cheaper tomorrow. If
    something is too slow today, it will be faster tomorrow. If something doesn’t
    fit in the context today, it will fit tomorrow. And if the model isn’t smart enough
    today, it will be tomorrow. However, always remember that even though models will
    get smarter, they will never be psychic. If the prompt doesn’t contain the information
    that *you* would need to solve the problem, then it’s probably insufficient for
    the model as well.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的提示工程工作中，你应该能够预期这些趋势会继续。如果今天某件事太贵，明天就会便宜。如果今天某件事太慢，明天就会更快。如果今天某件事不适合上下文，明天就会适合。如果模型今天不够聪明，明天就会更聪明。然而，始终记住，尽管模型会变得更聪明，但它们永远不会是通灵者。如果提示中没有包含你解决问题所需的信息，那么它可能对模型来说也不充分。
- en: Conclusion
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'If we had to sum up the main lessons from this book, there would be two:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要总结这本书的主要教训，那么会有两个：
- en: LLMs are nothing more than text completion engines that mimic the text they
    see during training.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM不过是模仿训练期间看到的文本的文本完成引擎。
- en: You should empathize with the LLM and understand how it thinks.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你应该同情LLM并理解它是如何思考的。
- en: Regarding the first lesson, when we started writing this book, the only models
    we had access to were completion models—give them a portion of a document (a.k.a.
    *the prompt*), and they would generate plausible text to complete the document.
    But then, the chat APIs came to dominate, tools came along next, and perhaps,
    Artifacts will be the next big thing. But even still, at their core, LLMs are
    just completing documents so that they resemble other documents the model has
    been taught to “like.” It’s just that now, the documents look like a chat transcript.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 关于第一个教训，当我们开始写这本书时，我们所能接触到的唯一模型是完成模型——给他们一部分文档（即*提示*），然后它们会生成合理的文本来完成文档。但是，随后聊天API开始主导，工具随之而来，也许，艺术品将是下一个大事件。但即便如此，LLM的核心仍然是完成文档，以便它们看起来像模型被训练去“喜欢”的其他文档。只是现在，这些文档看起来像聊天记录。
- en: The prompt-engineering lesson here is to follow the well-trodden course (the
    Little Red Riding Hood principle from [Chapter 4](ch04.html#ch04_designing_llm_applications_1728407230643376))—make
    your prompts follow the patterns and motifs seen in training data and you will
    be much more likely to get completions that are well behaved and easy to anticipate.
    For instance, you can format complex text as markdown, and if there is a standard
    document format for information you are communicating to the LLM, then you’ll
    have better luck using that format than coming up with a new one the model has
    never seen.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里的提示工程教训是要遵循既定的路线（第四章中提到的《小红帽原则》[ch04.html#ch04_designing_llm_applications_1728407230643376]）——让你的提示遵循训练数据中看到的模式和主题，这样你更有可能得到行为良好且易于预测的完成结果。例如，你可以将复杂文本格式化为Markdown，如果你要传达给LLM的信息有标准的文档格式，那么使用该格式比提出一个模型从未见过的格式更有可能成功。
- en: 'Regarding the second lesson, on empathy, think of an LLM as your big, dumb
    mechanical friend who happens to know much of the content of the internet. Here
    are some things that will help you understand:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 关于第二个教训，即同情，将LLM想象成你的一个大而笨拙的机械朋友，碰巧知道互联网的大部分内容。以下是一些帮助你理解的事情：
- en: LLMs are easily distracted
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: LLM很容易分心
- en: Don’t fill up the prompt with useless information that—*cross your fingers*—might
    just help. Make sure every piece of information matters.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 不要在提示中填满无用的信息，这些信息——*交叉手指*——可能刚好有帮助。确保每一条信息都至关重要。
- en: LLMs should be able to decipher the prompt
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: LLM应该能够解读提示
- en: If, as a human, you can’t understand the fully rendered prompt, then there is
    a very high chance that the LLM will be equally confused.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你作为一个人类无法理解完全渲染的提示，那么LLM同样可能会感到困惑。
- en: LLMs need to be led
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: LLM需要被引导
- en: Provide explicit instructions for what is to be accomplished and, when appropriate,
    provide examples demonstrating how the task should proceed.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 提供明确的指令来完成什么，并在适当的时候提供示例，说明任务应该如何进行。
- en: LLMs aren’t psychic
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LLM不是通灵者
- en: As the prompt engineer, it’s your job to make sure the prompt contains the information
    that the model needs to address the problem. Alternatively, give the model the
    tools and the instructions to retrieve it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提示工程师，你的任务是确保提示包含模型解决问题所需的信息。或者，给模型提供工具和指令来检索它。
- en: LLMs don’t have internal monologues
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: LLM没有内心独白
- en: If the LLM is allowed to think about the problem out loud (in a chain of thought),
    then it will be much easier for it to come to a useful solution.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果允许LLM大声思考问题（在思维链中），那么它找到有用解决方案的过程将容易得多。
- en: Hopefully, this book has given you all that you need to jump headlong into prompt
    engineering and LLM application development. Be assured, the accelerating change
    that we currently experience will continue. Since software will be easier to create,
    you will find more examples of highly individualized apps or even disposable apps.
    Applications will take on the nondeterministic nature of the LLMs, leading to
    more flexible and open-ended experiences. Development will change. You will work
    in tandem with an AI assistant to get your work done—if you don’t already.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这本书已经为你提供了跳入提示工程和LLM应用开发所需的一切。请放心，我们目前经历的加速变化将继续。由于软件将更容易创建，你会发现更多高度个性化的应用或甚至一次性应用。应用将具有LLM的非确定性特征，导致更灵活和开放式的体验。开发将发生变化。你将与人工智能助手协同工作以完成你的工作——如果你还没有这样做的话。
- en: 'Whatever shape the world finds itself in, it will be a shape of your making.
    As a prompt engineer, you have the tools at hand and the know-how to build a future
    of your choosing. Embrace the acceleration. Keep experimenting. Stay flexible.
    In the words of the late Sir Terry Pratchett:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 无论世界呈现何种形态，那都将是你塑造的形态。作为一名提示工程师，你手握工具，拥有构建你选择未来的知识和技能。拥抱加速。持续实验。保持灵活。正如已故的特里·普拉切特爵士所说：
- en: The whole world is tap-dancing on quicksand. In this case, the prize goes to
    the best dancer.^([1](ch11.html#id1251))
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 整个世界都在快速沙上踢踏舞。在这种情况下，奖项授予最佳舞者.^([1](ch11.html#id1251)))
- en: '^([1](ch11.html#id1251-marker)) Terry Pratchett, *The Fifth Elephant* (New
    York: Doubleday, 1999)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch11.html#id1251-marker)) 特里·普拉切特，《第五头象》（纽约：道布迪，1999）
