["```py\nmodel = dc.models.TensorGraph(batch_size=1000)\nfeatures = layers.Feature(shape=(None, 101, 4))\nlabels = layers.Label(shape=(None, 1))\nweights = layers.Weights(shape=(None, 1))\n\n```", "```py\nprev = features\nfor i in range(3):\n  prev = layers.Conv1D(filters=15, kernel_size=10,\n                       activation=tf.nn.relu, padding='same',\n                       in_layers=prev)\n  prev = layers.Dropout(dropout_prob=0.5, in_layers=prev)\n\n```", "```py\nlogits = layers.Dense(out_channels=1, in_layers=layers.Flatten(prev))\noutput = layers.Sigmoid(logits)\nmodel.add_output(output)\n\n```", "```py\nloss = layers.SigmoidCrossEntropy(in_layers=[labels, logits])\nweighted_loss = layers.WeightedError(in_layers=[loss, weights])\nmodel.set_loss(weighted_loss)\n\n```", "```py\ntrain = dc.data.DiskDataset('train_dataset')\nvalid = dc.data.DiskDataset('valid_dataset')\nmetric = dc.metrics.Metric(dc.metrics.roc_auc_score)\nfor i in range(20):\n  model.fit(train, nb_epoch=10)\n  print(model.evaluate(train, [metric]))\n  print(model.evaluate(valid, [metric]))\n\n```", "```py\nspan_accessibility = {}\nfor line in open('accessibility.txt'):\n  fields = line.split()\n  span_accessibility[fields[0]] = float(fields[1])\n\n```", "```py\naccessibility = layers.Feature(shape=(None, 1))\n\n```", "```py\nlogits = layers.Dense(out_channels=1, in_layers=layers.Flatten(prev))\n\n```", "```py\nprev = layers.Concat([layers.Flatten(prev), accessibility])\nlogits = layers.Dense(out_channels=1, in_layers=prev)\n\n```", "```py\ndef generate_batches(dataset, epochs):\n  for epoch in range(epochs):\n    for X, y, w, ids in dataset.iterbatches(batch_size=1000,\n                                            pad_batches=True):\n      yield {\n\tfeatures: X,\n\taccessibility: np.array([span_accessibility[id] for id in ids]),\n\tlabels: y,\n\tweights: w\n      }\n\n```", "```py\nfor i in range(20):\n  model.fit_generator(generate_batches(train, 10))\n  print(model.evaluate_generator(generate_batches(train, 1), [metric],\n                                 labels=[labels], weights=[weights]))\n  print(model.evaluate_generator(generate_batches(valid, 1), [metric],\n                                 labels=[labels], weights=[weights]))\n\n```", "```py\nmodel = dc.models.TensorGraph()\nfeatures = layers.Feature(shape=(None, 21, 4))\nlabels = layers.Label(shape=(None, 1))\nprev = features\nfor i in range(2):\n  prev = layers.Conv1D(filters=10, kernel_size=10,\n                       activation=tf.nn.relu, padding='same',\n                       in_layers=prev)\n  prev = layers.Dropout(dropout_prob=0.3, in_layers=prev)\noutput = layers.Dense(out_channels=1, activation_fn=tf.sigmoid,\n                      in_layers=layers.Flatten(prev))\nmodel.add_output(output)\nloss = layers.ReduceMean(layers.L2Loss(in_layers=[labels, output]))\nmodel.set_loss(loss)\n\n```", "```py\ntrain = dc.data.DiskDataset('train_siRNA')\nvalid = dc.data.DiskDataset('valid_siRNA')\nmetric = dc.metrics.Metric(dc.metrics.pearsonr, mode='regression')\nfor i in range(20):\n  model.fit(train, nb_epoch=10)\n  print(model.evaluate(train, [metric]))\n  print(model.evaluate(valid, [metric]))\n\n```"]