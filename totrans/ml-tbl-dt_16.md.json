["```py\nimport numpy as np\nimport pandas as pd\nexcluding_list = [\n    'price', 'id', 'latitude', 'longitude', \n    'host_id', 'last_review', 'name', 'host_name'\n]                                                ①\ncategorical = [\n    'neighbourhood_group', 'neighbourhood', \n    'room_type'\n]                                                ②\ncontinuous = [\n    'minimum_nights', 'number_of_reviews', 'reviews_per_month', \n    'Calculated_host_listings_count'\n]                                                ③\ndata = pd.read_csv(\"./AB_NYC_2019.csv\")\ntarget_median = (\n    data[\"price\"] > data[\"price\"].median()\n).astype(int)                                    ④\n```", "```py\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.metrics import accuracy_score\n\ncategorical_onehot_encoding = OneHotEncoder(handle_unknown='ignore')\n\naccuracy = make_scorer(accuracy_score)                            ①\ncv = KFold(5, shuffle=True, random_state=0)                       ②\nmodel = KNeighborsClassifier(n_neighbors=30,\n                             weights=\"uniform\",\n                             algorithm=\"auto\",\n                             n_jobs=-1)                           ③\n\ncolumn_transform = ColumnTransformer(\n    [('categories', categorical_onehot_encoding, low_card_categorical),\n     ('numeric', numeric_discretizing, continuous)],\n    remainder='drop',\n    verbose_feature_names_out=False,\n    sparse_threshold=0.0)                                         ④\n\nmodel_pipeline = Pipeline(\n    [('processing', column_transform),\n     ('pca', PCA(n_components=\"mle\")),\n     ('modeling', model)])                                        ⑤\n\ncv_scores = cross_validate(estimator=model_pipeline,\n                           X=data,\n                           y=target_median,\n                           scoring=accuracy,\n                           cv=cv,\n                           return_train_score=True,\n                           return_estimator=True)                 ⑥\n\nmean_cv = np.mean(cv_scores['test_score'])\nstd_cv = np.std(cv_scores['test_score'])\nfit_time = np.mean(cv_scores['fit_time'])\nscore_time = np.mean(cv_scores['score_time'])\nprint(f\"{mean_cv:0.3f} ({std_cv:0.3f})\",\n      f\"fit: {fit_time:0.2f}\",\n      f\"secs pred: {score_time:0.2f} secs\")                       ⑦\n```", "```py\n0.814 (0.005) fit: 0.13 secs pred: 8.75 secs\n```", "```py\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\nnumeric_standardization = Pipeline([\n       (\"imputation\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n       (\"standardizing\", StandardScaler())\n       ])\n\naccuracy = make_scorer(accuracy_score)                            ①\ncv = KFold(5, shuffle=True, random_state=0)                       ②\nmodel = SVC(\n    C=1.0,\n    kernel='rbf',\n    gamma='scale',\n    probability=False\n)                                                                 ③\n\ncolumn_transform = ColumnTransformer(\n    [('categories', categorical_onehot_encoding, low_card_categorical),\n     ('numeric', numeric_standardization, continuous)],\n    remainder='drop',\n    verbose_feature_names_out=False,\n    sparse_threshold=0.0)                                         ④\n\nmodel_pipeline = Pipeline(\n    [('processing', column_transform),\n     ('modeling', model)])                                        ⑤\n\ncv_scores = cross_validate(estimator=model_pipeline,\n                           X=data,\n                           y=target_median,\n                           scoring=accuracy,\n                           cv=cv,\n                           return_train_score=True,\n                           return_estimator=True)                 ⑥\n\nmean_cv = np.mean(cv_scores['test_score'])\nstd_cv = np.std(cv_scores['test_score'])\nfit_time = np.mean(cv_scores['fit_time'])\nscore_time = np.mean(cv_scores['score_time'])\nprint(f\"{mean_cv:0.3f} ({std_cv:0.3f})\",\n      f\"fit: {fit_time:0.2f}\",\n      f\"secs pred: {score_time:0.2f} secs\")                       ⑦\n```", "```py\n0.821 (0.004) fit: 102.28 secs pred: 9.80 secs\n```", "```py\nfrom cuml.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\naccuracy = make_scorer(accuracy_score)                            ①\ncv = KFold(5, shuffle=True, random_state=0)                       ②\nmodel = SVC(\n    C=1.0,\n    kernel='rbf',\n    gamma='scale',\n    probability=False\n)                                                                 ③\n\ncolumn_transform = ColumnTransformer(\n    [('categories', categorical_onehot_encoding, low_card_categorical),\n     ('numeric', numeric_standardization, continuous)],\n    remainder='drop',\n    verbose_feature_names_out=False,\n    sparse_threshold=0.0)                                         ④\n\nmodel_pipeline = Pipeline(\n    [('processing', column_transform),\n     ('modeling', model)])                                        ⑤\n\ncv_scores = cross_validate(estimator=model_pipeline,\n                           X=data,\n                           y=target_median,\n                           scoring=accuracy,\n                           cv=cv,\n                           return_train_score=True,\n                           return_estimator=True)                 ⑥\n\nmean_cv = np.mean(cv_scores['test_score'])\nstd_cv = np.std(cv_scores['test_score'])\nfit_time = np.mean(cv_scores['fit_time'])\nscore_time = np.mean(cv_scores['score_time'])\nprint(f\"{mean_cv:0.3f} ({std_cv:0.3f})\",\n      f\"fit: {fit_time:0.2f}\",\n\n      f\"secs pred: {score_time:0.2f} secs\")                       ⑦\n```", "```py\n0.821 (0.004) fit: 4.09 secs pred: 0.11 secs\n```"]