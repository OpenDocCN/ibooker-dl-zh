["```py\nimport torch\n\nclass LeNet(torch.nn.Module):\n    def __init__(self, num_classes):\n        super(LeNet, self).__init__()\n        self.conv1 = torch.nn.Sequential(\n                        torch.nn.Conv2d(\n                            in_channels=1, out_channels=6,     ①\n                            kernel_size=5, stride=1),\n                        torch.nn.Tanh(),                       ②\n                        torch.nn.AvgPool2d(kernel_size=2))     ③\n        self.conv2 = torch.nn.Sequential(\n                        torch.nn.Conv2d(\n                            in_channels=6, out_channels=16,\n                            kernel_size=5, stride=1),\n                        torch.nn.Tanh(),\n                        torch.nn.AvgPool2d(kernel_size=2))\n        self.conv3 = torch.nn.Sequential(\n                        torch.nn.Conv2d(\n                            in_channels=16, out_channels=120,\n                            kernel_size=5, stride=1),\n                        torch.nn.Tanh())\n        self.fc1 = torch.nn.Sequential(\n                        torch.nn.Linear(\n                            in_features=120, out_features=84), ④\n                        torch.nn.Tanh())\n        self.fc2 = torch.nn.Linear(\n            in_features=84, out_features=num_classes)          ⑤\n\n    def forward(self, X):                                      ⑥\n        conv_out = self.conv3(self.conv2(self.conv1(X)))\n        batch_size = conv_out.shape[0]\n        conv_out = conv_out.reshape(batch_size, -1)            ⑦\n        logits = self.fc2(self.fc1(conv_out))                  ⑧\n        return logits\n\n    def predict(self, X):\n        logits = self.forward(X)\n        probs = torch.softmax(logits, dim=1)                   ⑨\n        return torch.argmax(probs, 1)\n```", "```py\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, num_conv_layers, num_features):\n        super(ConvBlock, self).__init__()\n\n        modules = []\n\n        for i in range(num_conv_layers):\n            modules.extend([\n                nn.Conv2d(\n                    in_channels, num_features,      ①\n                    kernel_size=3, padding=1),      ②\n                nn.ReLU(inplace=True)\n            ])\n\n            in_channels = num_features\n        modules.append(nn.MaxPool2d(kernel_size=2)) ③\n        self.conv_block = nn.Sequential(*modules)\n\n    def forward(self, x):\n        return self.conv_block(x)\n```", "```py\nclass ConvBackbone(nn.Module):\n    def __init__(self, cfg):                        ①\n\n        super(ConvBackbone, self).__init__()\n\n        self.cfg = cfg\n\n        self.validate_config(cfg)\n\n        modules = []\n        for block_cfg in cfg:                       ②\n            in_channels, num_conv_layers, num_features = block_cfg \n            modules.append(ConvBlock(               ③\n            in_channels, num_conv_layers, num_features))\n        self.features = nn.Sequential(*modules)\n\n    def validate_config(self, cfg):\n        assert len(cfg) == 5 # 5  conv blocks\n        for i, block_cfg in enumerate(cfg):\n            assert type(block_cfg) == tuple and len(block_cfg) == 3\n            if i == 0:\n                assert block_cfg[0] == 3            ④\n            else:\n                assert block_cfg[0] == cfg[i-1][-1] ⑤\n\n    def forward(self, x):\n        return self.features(x)\n```", "```py\nclass VGG(nn.Module):\n    def __init__(self, conv_backbone, num_classes):\n        super(VGG, self).__init__()\n        self.conv_backbone = conv_backbone   ①\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),           ②\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, num_classes)\n        )\n\n    def forward(self, x):\n        conv_features = self.conv_backbone(x)\n\n        logits = self.classifier(\n            conv_features.view(\n                conv_features.shape[0], -1)) ③\n        return logits\n```", "```py\nvgg11_cfg = [                             ①\n    (3, 1, 64),\n    (64, 1, 128),\n    (128, 2, 256),\n    (256, 2, 512),\n    (512, 2, 512)\n]\n\nvgg11_backbone = ConvBackbone(vgg11_cfg)  ①\nnum_classes = 1000\nvgg11 = VGG(vgg11_backbone, num_classes)  ①\n```", "```py\nimport torchvision\nvgg11 = torchvision.models.vgg11()\n```", "```py\nclass NaiveInceptionModule(nn.Module):\n    def __init__(self, in_channels, num_features=64):\n        super(NaiveInceptionModule, self).__init__()\n\n        self.branch1x1 = torch.nn.Sequential(                   ①\n                        nn.Conv2d(\n                            in_channels, num_features,\n                            kernel_size=1, bias=False),\n                        nn.BatchNorm2d(num_features, eps=0.001),\n                        nn.ReLU(inplace=True))\n\n        self.branch3x3 = torch.nn.Sequential( \n                        nn.Conv2d(                              ②\n                            in_channels, num_features,\n                            kernel_size=3, padding=1, bias=False),\n                        nn.BatchNorm2d(num_features, eps=0.001),\n                        nn.ReLU(inplace=True))\n\n        self.branch5x5 = torch.nn.Sequential(                   ③\n                        nn.Conv2d(\n                            in_channels, num_features,\n                            kernel_size=5, padding=2, bias=False),\n                        nn.BatchNorm2d(num_features, eps=0.001),\n                        nn.ReLU(inplace=True))\n\n        self.pool = torch.nn.MaxPool2d(                         ④\n            kernel_size=3, stride=1, padding=1)\n\n    def forward(self, x):\n        conv1x1 = self.branch1x1(x)\n        conv3x3 = self.branch3x3(x)\n        conv5x5 = self.branch5x5(x)\n        pool_out = self.pool(x)\n        out = torch.cat(                                        ⑤\n            [conv1x1, conv3x3, conv5x5, pool_out], 1)\n        return out\n```", "```py\nclass Inceptionv1Module(nn.Module):\n    def __init__(self, in_channels, num_1x1=64,\n                 reduce_3x3=96, num_3x3=128,\n                 reduce_5x5=16, num_5x5=32,\n                 pool_proj=32):\n        super(Inceptionv1Module, self).__init__()\n\n        self.branch1x1 = torch.nn.Sequential(\n                        nn.Conv2d(               ①\n                            in_channels, num_1x1,\n                            kernel_size=1, bias=False),\n                        nn.BatchNorm2d(num_1x1, eps=0.001),\n                        nn.ReLU(inplace=True))\n\n        self.branch3x3_1 = torch.nn.Sequential( ②\n                        nn.Conv2d(\n                            in_channels, reduce_3x3,\n                            kernel_size=1, bias=False),\n                        nn.BatchNorm2d(reduce_3x3, eps=0.001),\n                        nn.ReLU(inplace=True))\n\n        self.branch3x3_2 = torch.nn.Sequential(  ③\n                        nn.Conv2d(\n                            reduce_3x3, num_3x3,\n                            kernel_size=3, padding=1, bias=False),\n                        nn.BatchNorm2d(num_3x3, eps=0.001),\n                        nn.ReLU(inplace=True))\n\n        self.branch5x5_1 = torch.nn.Sequential(  ④\n                        nn.Conv2d(\n                            in_channels, reduce_5x5,\n                            kernel_size=5, padding=2, bias=False),\n                        nn.BatchNorm2d(reduce_5x5, eps=0.001),\n                        nn.ReLU(inplace=True))\n        self.branch5x5_2 = torch.nn.Sequential(  ⑤\n                        nn.Conv2d(\n                            reduce_5x5, num_5x5,\n                            kernel_size=5, padding=2, bias=False),\n                        nn.BatchNorm2d(num_5x5, eps=0.001),\n                        nn.ReLU(inplace=True))\n\n        self.pool = torch.nn.Sequential(         ⑥\n                        torch.nn.MaxPool2d(\n                            kernel_size=3, stride=1, padding=1),\n                        nn.Conv2d(\n                            in_channels, pool_proj,\n                            kernel_size=1, bias=False),\n                        nn.BatchNorm2d(pool_proj, eps=0.001),\n                        nn.ReLU(inplace=True))\n\n    def forward(self, x):\n        conv1x1 = self.branch1x1(x)\n        conv3x3 = self.branch3x3_2(self.branch3x3_1((x)))\n        conv5x5 = self.branch5x5_2(self.branch5x5_1((x)))\n        pool_out = self.pool(x)\n        out = torch.cat(                         ⑦\n            [conv1x1, conv3x3, conv5x5, pool_out], 1)\n        return out\n```", "```py\nclass BasicBlock(nn.Module):\n    def __init__(self, in_channels, num_features, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Sequential(                        ①\n\n                        nn.Conv2d(\n                            in_channels, num_features,\n                            kernel_size=3, stride=stride, padding=1, bias=False),\n                        nn.BatchNorm2d(num_features, eps=0.001),\n                        nn.ReLU(inplace=True))\n        self.conv2 = nn.Sequential(\n                        nn.Conv2d(\n                            num_features, num_features,\n                            kernel_size=3, stride=1, padding=1, bias=False),\n                        nn.BatchNorm2d(num_features, eps=0.001))\n\n        self.downsample = downsample                       ②\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        conv_out = self.conv2(self.conv1(x))\n        identity = x\n        if self.downsample is not None:\n            identity = self.downsample(x)\n        assert identity.shape == conv_out.shape,\n            f\"Identity {identity.shape} and conv out {conv_out.shape} have different shapes\"\n\n        out = self.relu(conv_out + identity)               ③\n        return out\n```", "```py\nclass ResidualConvBlock(nn.Module):\n    def __init__(self, in_channels, num_blocks, reduce_fm_size=True):\n        super(ResidualConvBlock, self).__init__()\n\n        num_features = in_channels * 2 if reduce_fm_size else in_channels\n        modules = []\n\n        for i in range(num_blocks):                          ①\n            if i == 0 and reduce_fm_size:\n                stride = 2\n                downsample = nn.Sequential( \n                    nn.Conv2d(                               ②\n                        in_channels, num_features,\n                        kernel_size=1, stride=stride, bias=False),\n                    nn.BatchNorm2d(num_features, eps=0.001),\n                )\n                basic_block = BasicBlock(\n                    in_channels=in_channels, num_features=num_features,\n                    stride=stride, downsample=downsample)\n            else:\n                basic_block = BasicBlock(\n                    in_channels=num_features, num_features=num_features, stride=1)\n            modules.append(basic_block)\n\n        self.conv_block = nn.Sequential(*modules)\n\n    def forward(self, x):\n        return self.conv_block(x)\n```", "```py\nclass ResNet34(nn.Module):\n    def __init__(self, num_basic_blocks, num_classes):\n        super(ResNet, self).__init__()\n        conv1 = nn.Sequential(                       ①\n            nn.Conv2d(3, 64, kernel_size=7,\n                stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64, eps=0.001),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(\n                kernel_size=3, stride=2, padding=1)\n        )\n\n        assert len(num_basic_blocks) == 4            ②\n\n        conv2 = ResidualConvBlock(                   ③\n            in_channels=64, num_blocks=num_basic_blocks[0], reduce_fm_size=False)\n        conv3 = ResidualConvBlock(\n            in_channels=64, num_blocks=num_basic_blocks[1], reduce_fm_size=True)\n        conv4 = ResidualConvBlock(\n            in_channels=128, num_blocks=num_basic_blocks[2], reduce_fm_size=True)\n        conv5 = ResidualConvBlock(\n            in_channels=256, num_blocks=num_basic_blocks[3], reduce_fm_size=True)\n\n        self.conv_backbone = nn.Sequential(*[conv1, conv2, conv3, conv4, conv5])\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        conv_out = self.conv_backbone(x)\n        conv_out = self.avg_pool(conv_out)\n        logits = self.classifier(                    ④\n            conv_out.view(conv_out.shape[0], -1))\n        return logits\n```", "```py\nimport torchvision\nresnet34 = torchvision.models.resnet34()  ①\n```", "```py\nclass MNISTDataModule(LightningDataModule):\n    DATASET_DIR = \"datasets\"\n\n    def __init__(self, transform=None, batch_size=100):\n        super(MNISTDataModule, self).__init__()\n        if transform is None:\n            transform = transforms.Compose(\n                [transforms.Resize((32, 32)),\n                transforms.ToTensor()])\n        self.transform = transform\n        self.batch_size = batch_size\n\n    def prepare_data(self):                                  ①\n        datasets.MNIST(root = MNISTDataModule.DATASET_DIR,\n            train=True, download=True)\n        datasets.MNIST(root=MNISTDataModule.DATASET_DIR,\n            train=False, download=True)\n\n    def setup(self, stage=None):\n        train_dataset = datasets.MNIST(\n            root = MNISTDataModule.DATASET_DIR, train=True,\n            download=False, transform=self.transform)\n        self.train_dataset, self.val_dataset = random_split( ②\n            train_dataset, [55000, 5000])\n\n        self.test_dataset = datasets.MNIST(\n            root = MNISTDataModule.DATASET_DIR, train = False,\n            download = False, transform=self.transform)\n\n    def train_dataloader(self):                              ③\n        return DataLoader(\n            self.train_dataset, batch_size=self.batch_size,\n            shuffle=True, num_workers=0)\n\n    def val_dataloader(self):                                ④\n        return DataLoader(\n            self.val_dataset, batch_size=self.batch_size,\n            shuffle=False, num_workers=0)\n\n    def test_dataloader(self):                               ⑤\n        return DataLoader(\n            self.test_dataset, batch_size=self.batch_size,\n            shuffle=False, num_workers=0)\n\n    @property\n    def num_classes(self):                                   ⑥\n        return 10\n```", "```py\nclass LeNetClassifier(LightningModule):\n\n    def __init__(self, num_classes):                 ①\n\n        super(LeNetClassifier, self).__init__()\n        self.save_hyperparameters()\n\n        self.conv1 = torch.nn.Sequential(\n                        torch.nn.Conv2d(\n                            in_channels=1, out_channels=6,\n                            kernel_size=5, stride=1),\n                        torch.nn.Tanh(),\n\n                        torch.nn.AvgPool2d(kernel_size=2))\n        self.conv2 = torch.nn.Sequential(\n                        torch.nn.Conv2d(\n                            in_channels=6, out_channels=16,\n                            kernel_size=5, stride=1),\n                        torch.nn.Tanh(),\n                        torch.nn.AvgPool2d(kernel_size=2))\n        self.conv3 = torch.nn.Sequential(\n                        torch.nn.Conv2d(\n                            in_channels=16, out_channels=120,\n                            kernel_size=5, stride=1),\n                        torch.nn.Tanh())\n        self.fc1 = torch.nn.Sequential(\n                        torch.nn.Linear(in_features=120, out_features=84),\n                        torch.nn.Tanh())\n        self.fc2 = torch.nn.Linear(in_features=84,\n            out_features=num_classes)\n\n        self.criterion = torch.nn.CrossEntropyLoss() ②\n\n        self.accuracy = torchmetrics.Accuracy()\n\n    def forward(self, X):                            ③\n        conv_out = self.conv3(\n            self.conv2(self.conv1(X)))\n        batch_size = conv_out.shape[0]\n        conv_out = conv_out.reshape(\n            batch_size, -1)\n        logits = self.fc2(self.fc1(conv_out))\n        return logits                                ④\n\n    def predict(self, X):                            ⑤\n        logits = self.forward(X)\n        probs = torch.softmax(logits, dim=1)\n        return torch.argmax(probs, 1)\n\n    def core_step(self, batch):                      ⑥\n        X, y_true = batch\n        y_pred_logits = self.forward(X)\n        loss = self.criterion(y_pred_logits, y_true)\n        accuracy = self.accuracy(y_pred_logits, y_true)\n        return loss, accuracy\n\n    def training_step(self, batch, batch_idx):       ⑦\n\n        loss, accuracy = self.core_step(batch)\n        if self.global_step \\% 100 == 0:\n            self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n            self.log(\"train_accuracy\", accuracy, on_step=True, on_epoch=True)\n        return loss\n\n    def validation_step(self, batch,\n        batch_idx, dataset_idx=None):                ⑧\n        return self.core_step(batch)\n\n    def validation_epoch_end(self, outputs):         ⑨\n        avg_loss = torch.tensor([x[0] for x in outputs]).mean()\n        avg_accuracy = torch.tensor([x[1] for x in outputs]).mean()\n        self.log(\"val_loss\", avg_loss)\n        self.log(\"val_accuracy\", avg_accuracy)\n        print(f\"Epoch {self.current_epoch},\n            Val loss: {avg_loss:0.2f}, Accuracy: {avg_accuracy:0.2f}\")\n        return avg_loss\n\n    def configure_optimizers(self):                  ⑩\n        return torch.optim.SGD(model.parameters(), lr=0.01,\n                      momentum=0.9)\n\n    def checkpoint_callback(self):                   ⑪\n        return ModelCheckpoint(monitor=\"val_accuracy\", mode=\"max\", save_top_k=1)\n```", "```py\ndm = MNISTDataModule()                               ①\nmodel = LeNetClassifier(num_classes=dm.num_classes)  ②\nexp_dir = \"/tmp/mnist\"\ntrainer = Trainer(                                   ③\n        default_root_dir=exp_dir,\n        callbacks=[model.checkpoint_callback()],\n        gpus=torch.cuda.device_count(), # Number of GPUs to run on\n        max_epochs=10,\n        num_sanity_val_steps=0\n    )\ntrainer.fit(model, dm)                               ④\n```", "```py\nX, y_true = (iter(dm.test_dataloader())).next()\nwith torch.no_grad():\n    y_pred = model.predict(X) ①\n```", "```py\ndef generate_anchors_at_grid_point(\n    ctr_x, ctr_y, subsample, scales, aspect_ratios):\n    anchors = torch.zeros(\n        (len(aspect_ratios) * len(scales), 4), dtype=torch.float)\n\n    for i, scale in enumerate(scales):\n        for j, aspect_ratio in enumerate(aspect_ratios): ①\n\n            w = subsample * scale * torch.sqrt(aspect_ratio)\n            h = subsample * scale * torch.sqrt(1 / aspect_ratio)\n\n            xtl = ctr_x - w / 2                          ②\n            ytl = ctr_y - h / 2\n            xbr = ctr_x + w / 2\n            ybr = ctr_y + h / 2\n\n            index = i * len(aspect_ratios) + j\n            anchors[index] = torch.tensor([xtl, ytl, xbr, ybr])\n    return anchors\n```", "```py\n def generate_all_anchors(                       ①\n\n     input_img_size, subsample, scales, aspect_ratios):\n\n    _, h, w = input_img_size\n\n    conv_feature_map_size = (h//subsample, w//subsample)\n\n    all_anchors = []                             ②\n\n    ctr_x = torch.arange(\n        subsample/2, conv_feature_map_size[1]*subsample+1, subsample)\n    ctr_y = torch.arange(\n        subsample/2, conv_feature_map_size[0]*subsample+1, subsample)\n\n    for y in ctr_y:\n        for x in ctr_x:\n            all_anchors.append(\n                generate_anchors_at_grid_point(  ③\n                    x, y, subsample, scales, aspect_ratios))\n\n    all_anchors = torch.cat(all_anchors)\n    return all_anchors\n\ninput_img_size = (3, 800, 800)                   ④\nc, height, width = input_img_size\nscales = torch.tensor([8, 16, 32], dtype=torch.float)\naspect_ratios = torch.tensor([0.5, 1, 2])\nsubsample = 16\nanchors = generate_all_anchors(input_img_size, subsample, scales, aspect_ratios)\n```", "```py\nclass RPN_FCN(nn.Module):\n\n    def __init__(self, k, in_channels=512):  ①\n        super(RPN_FCN, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(\n                in_channels, 512, kernel_size=3,\n                stride=1, padding=1),\n            nn.ReLU(True))\n        self.cls = nn.Conv2d(512, 2*k, kernel_size=1)\n        self.reg = nn.Conv2d(512, 4*k, kernel_size=1)\n\n    def forward(self, x):\n        out = self.conv(x)                   ②\n\n        rpn_cls_scores = self.cls(out).view( ③\n            x.shape[0], -1, 2)\n        rpn_loc = self.reg(out).view(        ④\n            x.shape[0], -1, 4)\n\n        ⑤\n       return rpn_cls_scores       ,rpn_loc  ⑥\n```", "```py\nvalid_indices = torch.where(\n    (anchors[:, 0] >=0) &\n    (anchors[:, 1] >=0) &\n    (anchors[:, 2] <=width) &                         ①\n    (anchors[:, 3] <=height))[0]\n\nrpn_valid_labels = -1 * torch.ones_like(              ②\n    valid_indices, dtype=torch.int)\n\nvalid_anchor_bboxes = anchors[valid_indices]          ③\n\nious = torchvision.ops.box_iou(                       ④\n    gt_bboxes, valid_anchor_bboxes)\n\nassert ious.shape == torch.Size(\n    [gt_bboxes.shape[0], valid_anchor_bboxes.shape[0]])\n\ngt_ious_max = torch.max(ious, dim=1)[0]               ⑤\n\n# Find all the indices where the IOU = highest GT IOU \ngt_ious_argmax = torch.where(                         ⑥\n    gt_ious_max.unsqueeze(1).repeat(1, gt_ious_max.shape[1]) == ious)[1]\n\nanchor_ious_argmax = torch.argmax(ious, dim=0)        ⑦\nanchor_ious = ious[anchor_ious_argmax, torch.arange(len(anchor_ious_argmax))]\n\npos_iou_threshold  = 0.7\nneg_iou_threshold = 0.3\n\nrpn_valid_labels[anchor_ious < neg_iou_threshold] = 0 ⑧\n\nrpn_valid_labels[anchor_ious > pos_iou_threshold] = 1 ⑨\n\nrpn_valid_labels[gt_ious_argmax] = 1                  ⑩\n```", "```py\ndef transform_bboxes(bboxes):                      ①\n    height = bboxes[:, 3] - bboxes[:, 1]\n    width = bboxes[:, 2] - bboxes[:, 0]\n    x_ctr = bboxes[:, 0] + width / 2\n    y_ctr = bboxes[:, 1] +  height /2 \n    return torch.stack(                            ②\n        [x_ctr, y_ctr, width, height], dim=1)\n\ndef get_regression_targets(roi_bboxes, gt_bboxes): ③\n\n    assert roi_bboxes.shape == gt_bboxes.shape\n    roi_bboxes_t = transform_bboxes(roi_bboxes)\n    gt_bboxes_t = transform_bboxes(gt_bboxes)\n    tx = (gt_bboxes_t[:, 0] - roi_bboxes_t[:, 0]) / roi_bboxes_t[:, 2]\n    ty = (gt_bboxes_t[:, 1] - roi_bboxes_t[:, 1]) / roi_bboxes_t[:, 3]\n    tw = torch.log(gt_bboxes_t[:, 2] / roi_bboxes_t[:, 2])\n    th = torch.log(gt_bboxes_t[:, 3] / roi_bboxes_t[:, 3])\n\n    return  torch.stack([tx, ty, tw, th], dim=1)   ④\n```", "```py\ndef rpn_loss(\n    rpn_cls_scores, rpn_loc, rpn_labels,\n    rpn_loc_targets, lambda_ = 10):                  ①\n\n    classification_criterion = nn.CrossEntropyLoss( \n        ignore_index=-1)                             ②\n    reg_criterion = nn.SmoothL1Loss(reduction=\"sum\")\n\n    cls_loss = classification_criterion(rpn_cls_scores, rpn_labels)\n\n    positive_indices = torch.where(rpn_labels==1)[0] ③\n    pred_positive_anchor_offsets = rpn_loc[positive_indices]\n    gt_positive_loc_targets = rpn_loc_targets[positive_indices]\n    reg_loss = reg_criterion(\n        pred_positive_anchor_offsets,\n        gt_positive_loc_targets) / len(positive_indices)\n    return {\n        \"rpn_cls_loss\": cls_loss,\n        \"rpn_reg_loss\": reg_loss,\n        \"rpn_total_loss\": cls_loss + lambda_* reg_loss\n\n    }\n```", "```py\nrois = generate_bboxes_from_offset(rpn_loc, anchors)\n\nrois = rois.clamp(min=0, max=width)       ①\n\nroi_heights = rois[:, 3] - rois[:, 1]     ②\nroi_widths = rois[:, 2] - rois[:, 0]\nmin_roi_threshold = 16\n\nvalid_idxes = torch.where((roi_heights > min_roi_threshold) &\n    (roi_widths > min_roi_threshold))[0]\nrois = rois[valid_idxes]\nvalid_cls_scores = rpn_loc[valid_idxes]\n\nobjectness_scores = valid_cls_scores[:, 1]\n\nsorted_idx = torch.argsort(               ③\n    objectness_scores, descending=True)\nn_train_pre_nms = 12000\nn_val_pre_nms = 300\n\nrois = rois[sorted_idx][:n_train_pre_nms] ④\n\nobjectness_scores = objectness_scores[ \n    sorted_idx][:n_train_pre_nms]         ⑤\n```", "```py\nn_train_post_nms = 2000\nn_val_post_nms = 300\nnms_threshold = 0.7\n\npost_nms_indices = torchvision.ops.nms(     ①\n    rois, objectness_scores, nms_threshold)\n\npost_nms_rois = rois[post_nms_indices[:n_train_post_nms]]\n```", "```py\nclass Fast_RCNN_ROI_Head(nn.Module):\n    def __init__(self, num_classes, H, W, subsample=16, embedding_size=512):\n\n        super(Fast_RCNN_ROI_Head, self).__init__()\n\n        self.num_classes = num_classes\n        self.H = H\n        self.W = W\n        self.embedding_size = embedding_size\n        self.subsample = 16\n\n        self.roi_head_classifier = nn.Sequential(\n            nn.Linear(H*W*embedding_size, 4096),\n            nn.ReLU(True),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n        )\n        self.cls = torch.nn.Linear(4096, num_classes+1) ①\n        self.reg = torch.nn.Linear(4096, (num_classes+1)*4)\n\n    def forward(self, x, rois):                         ②\n        assert x.shape[0] == 1 # This code only supports batch size of 1\n        roi_pooled_features = torchvision.ops.roi_pool(\n            x, [rois], output_size=(self.H, self.W), spatial_scale=1/subsample)\n        roi_pooled_features = roi_pooled_features.view(\n            -1, self.H*self.W*self.embedding_size)\n        fc_out = self.roi_head_classifier(roi_pooled_features)\n        roi_cls_scores = self.cls(fc_out)\n        roi_loc = self.reg(fc_out)\n\n        return roi_cls_scores, roi_loc                  ③\n```", "```py\ndef rcnn_loss(\n    roi_cls_scores,                              ①\n    roi_loc,                                     ②\n    roi_labels,                                  ③\n    rcnn_loc_targets,                            ④\n    lambda_ = 1):\n\n    classification_criterion = nn.CrossEntropyLoss()\n    reg_criterion = nn.SmoothL1Loss(reduction=\"sum\")\n\n    cls_loss = classification_criterion(roi_cls_scores, roi_labels)\n\n    pos_roi_idxes = torch.where(roi_labels>0)[0] ⑤\n    pred_all_offsets = roi_loc[pos_roi_idxes]\n\n    num_pos_rois = len(pos_roi_idxes)\n    pred_all_offsets = pred_all_offsets.view(    ⑥\n        num_pos_rois, -1, 4)\n\n    pred_cls_offsets = pred_all_offsets[\n        torch.arange(num_pos_rois) , roi_labels[pos_roi_idxes]]\n\n    gt_offsets = rcnn_loc_targets[pos_roi_idxes]\n\n    reg_loss = reg_criterion(pred_cls_offsets, gt_offsets) / num_pos_rois\n    return {\n        \"rcnn_cls_loss\": cls_loss,\n        \"rcnn_reg_loss\": reg_loss,\n        \"rcnn_total_loss\": cls_loss + lambda_* reg_loss\n\n    }\n```", "```py\ndef fast_rcnn_inference(\n    frcnn_roi_head,                                      ①\n    rois,                                                ②\n    conv_feature_map,                                    ③\n    nms_threshold=0.7):\n\n    frcnn_roi_head.eval()                                ④\n    roi_cls_scores, roi_loc = frcnn_roi_head(conv_feature_map, rois)\n\n    output_labels = torch.argmax(                        ⑤\n        roi_cls_scores, dim=1)\n\n    output_probs = nn.functional.softmax(\n        roi_cls_scores, dim=1)[torch.arange(             ⑥\n            rois.shape[0]), output_labels]\n\n    output_offsets = roi_loc.view(                       ⑦\n        rois.shape[0], -1, 4)\n\n    output_offsets = output_offsets[                     ⑧\n        torch.arange(rois.shape[0]), output_labels]\n\n    assert output_offsets.shape == torch.Size(           ⑨\n        [rois.shape[0], 4])\n\n    output_bboxes = generate_bboxes_from_offset(         ⑩\n        output_offsets, rois)\n\n    rois = output_bboxes.clamp(min=0, max=width)         ⑪\n\n    post_nms_labels, post_nms_probs, post_nms_boxes = [], [], []\n\n    for cls in range(1, frcnn_roi_head.num_classes+1):   ⑫\n\n        cls_idxes = torch.where(output_labels == cls)[0] ⑬\n        cls_labels = output_labels[cls_idxes]\n        cls_bboxes = output_bboxes[cls_idxes]\n        cls_probs = output_probs[cls_idxes]\n        keep_indices = torchvision.ops.nms(\n            cls_bboxes, cls_probs, nms_threshold)\n\n        post_nms_labels.append(cls_labels[keep_indices])\n        post_nms_probs.append(cls_probs[keep_indices])\n        post_nms_boxes.append(cls_bboxes[keep_indices])\n\n    return {\n        \"labels\": torch.cat(post_nms_labels),\n        \"probs\": torch.cat(post_nms_probs),\n        \"bboxes\": torch.cat(post_nms_boxes)\n    }\n```"]