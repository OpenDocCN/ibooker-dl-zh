- en: Chapter 5\. Can Your LLM Know Too Much?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。你的LLM是否知道得太多？
- en: In 2023, a rash of companies began banning or heavily restricting the usage
    of LLM services, like ChatGPT, based on concerns about possible leaks of confidential
    data. A partial list of such companies includes Samsung, JPMorgan Chase, Amazon,
    Bank of America, Citigroup, Deutsche Bank, Wells Fargo, and Goldman Sachs. These
    actions by giant finance and tech corporations show substantial concern about
    LLMs disclosing confidential and sensitive information, but how critical is the
    risk? As the developer of an LLM application, do you need to care?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年，许多公司开始禁止或严格限制使用LLM服务，如ChatGPT，基于对可能泄露机密数据的担忧。这些公司的部分名单包括三星、摩根大通、亚马逊、美国银行、花旗集团、德意志银行、富国银行和高盛。这些大型金融和科技公司采取的行动表明，他们对LLM泄露机密和敏感信息表示了极大的关注，但这种风险有多严重？作为LLM应用程序的开发者，你是否需要关心？
- en: In the Tay story from [Chapter 1](ch01.html#chatbots_breaking_bad), Microsoft’s
    chatbot was attacked by hackers. As bad as the damage was, it was limited because
    Tay didn’t have access to much sensitive data she could have disclosed. However,
    the intersection of LLMs with real-world data can harbor the potential of unintended
    information disclosure, as seen in cases where employees have inadvertently fed
    sensitive business data to ChatGPT, which then became integrated into the system’s
    training base so that others could discover it.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中提到的泰勒故事[第1章](ch01.html#chatbots_breaking_bad)，微软的聊天机器人遭到了黑客的攻击。虽然造成的损害很严重，但由于泰勒没有访问到大量敏感数据，因此损害是有限的。然而，大型语言模型（LLM）与真实世界数据的交集可能会带来无意中泄露信息的潜在风险，正如员工不小心将敏感的商业数据输入到ChatGPT中，这些数据随后被整合到系统的训练库中，使得其他人能够发现。
- en: This chapter will dig into the various ways that LLMs acquire access to data.
    We will examine the three predominant knowledge acquisition methods and the risks
    associated with your LLM having this access. Along the way, we’ll try to answer
    the question “Can your LLM know too much?” and discuss how to mitigate the risks
    associated with your application disclosing sensitive, private, or confidential
    data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将深入探讨LLM获取数据的各种方式。我们将研究三种主要的知识获取方法以及与LLM获取数据相关的风险。在这个过程中，我们将尝试回答“你的LLM是否知道得太多？”这个问题，并讨论如何减轻应用程序泄露敏感、私人或机密数据的风险。
- en: Real-World Examples
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 真实世界案例
- en: Let’s examine two examples of the impacts seen in the real world. We’ll start
    with a chatbot example, which was somewhat similar to Tay, except the damage was
    much more significant due to the data to which the chatbot had access and how
    it was disclosed. Then we’ll look at a copilot example that put its owner at elevated
    legal and reputational risk.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考察两个在真实世界中看到的例子的影响。我们将从一个聊天机器人的例子开始，这个例子与泰勒有些相似，但由于聊天机器人可以访问的数据以及数据的披露方式，造成的损害要大得多。然后我们将看看一个机组成员的例子，这个例子使所有者面临了更高的法律和声誉风险。
- en: Lee Luda
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 李路达
- en: Seoul-based start-up Scatter Lab, also briefly mentioned in [Chapter 1](ch01.html#chatbots_breaking_bad),
    faced severe legal and reputational repercussions due to its irresponsible handling
    of personal data. The company operated a popular app called Science of Love, which
    helped users analyze their compatibility with a romantic partner by analyzing
    their text messages. This service accumulated 9.4 billion conversations from 600,000
    users. The company later introduced Lee Luda, [“an A.I. chatbot that people prefer
    as a conversation partner over a person.”](https://oreil.ly/PDF3e) Lee Luda used
    Science of Love’s massive dataset as its training base—without applying any proper
    sanitization. Not only did Lee Luda exhibit some of the toxic behavior we saw
    from Tay, but, more concerning, she began to leak sensitive data such as users’
    names, private nicknames, and home addresses.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 位于首尔的初创公司Scatter Lab，在第一章中也简要提到了[第1章](ch01.html#chatbots_breaking_bad)，由于其不负责任地处理个人数据而面临严重的法律和声誉后果。该公司运营了一个流行的应用程序“爱情科学”，该应用程序通过分析用户的短信来帮助用户分析他们与浪漫伴侣的兼容性。这项服务积累了来自60万用户的940亿条对话。该公司后来推出了李路达，[“一个人们更喜欢作为对话伙伴的人工智能聊天机器人。”](https://oreil.ly/PDF3e)李路达使用“爱情科学”的庞大数据集作为其训练基础——而没有应用任何适当的净化措施。李路达不仅表现出我们从泰勒那里看到的一些有毒行为，而且更令人担忧的是，她开始泄露敏感数据，例如用户的姓名、私人昵称和家庭地址。
- en: South Korea’s Personal Information Protection Commission imposed a fine of 103.3
    million won (around US$93k) on Scatter Lab for failing to obtain proper user permissions,
    marking a precedent in penalizing AI technology firms for data mismanagement in
    South Korea.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 韩国个人信息保护委员会对Scatter Lab未能获得适当用户许可处以1.033亿韩元（约合9.3万美元）的罚款，这在韩国为惩罚AI技术公司数据管理不当树立了先例。
- en: 'There was substantial impact from this incident. Let’s look at the various
    facets:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这起事件产生了重大影响。让我们来看看各个方面：
- en: Public exposure of sensitive data
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感数据的公开曝光
- en: The exposure of sensitive data jeopardized user privacy, revealing personal
    information like names, locations, relationship statuses, and medical information.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感数据的公开暴露威胁到用户隐私，揭示了诸如姓名、位置、关系状态和医疗信息等个人信息。
- en: Financial penalty
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 财务罚款
- en: Scatter Lab incurred a substantial fine for neglecting to manage user data responsibly.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Scatter Lab因未能负责任地管理用户数据而遭受了巨额罚款。
- en: Reputational damage
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 声誉损害
- en: The incident significantly tarnished Scatter Lab’s reputation, as evidenced
    by mainstream press coverage and a deluge of negative reviews on Google Play,
    especially targeting the Science of Love app.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这起事件严重损害了Scatter Lab的声誉，正如主流媒体的报道和Google Play上大量负面评论所证明的，特别是针对“爱情科学”应用。
- en: Service discontinuation
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 服务中断
- en: The offending chatbot service, Lee Luda, was shut down following the incident,
    halting the company’s expansion plans.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件发生后，违规的聊天机器人服务Lee Luda被关闭，阻碍了公司的扩张计划。
- en: 'Now, let’s examine the lessons you can learn and apply to your own projects:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来探讨你可以从中学习并应用到自己的项目中的经验教训：
- en: Stringent data privacy protocols
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 严格的数据隐私协议
- en: This incident highlights the imperative for robust data privacy protocols to
    ensure user data is handled with the utmost care and within legal frameworks.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这个事件强调了确保用户数据得到最严格保护和在法律框架内处理的强大数据隐私协议的必要性。
- en: User consent
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 用户同意
- en: Obtaining explicit and informed consent before collecting and processing users’
    data is legally mandated and a cornerstone of ethical data practices.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在收集和处理用户数据之前获得明确和知情同意是法律规定的，也是道德数据实践的基础。
- en: Age verification mechanisms
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 年龄验证机制
- en: In this case, the damage was more severe because some of the data gathered by
    Science of Love belonged to minors. Data mining from minors requires special care
    in many regulatory environments.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，损害更为严重，因为“爱情科学”收集的一些数据属于未成年人。在许多监管环境中，从未成年人那里进行数据挖掘需要特别注意。
- en: Public awareness
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 公众意识
- en: Companies must be transparent with users regarding how they will utilize data
    and effectively communicate the risks.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 公司必须向用户透明地说明他们将如何利用数据，并有效地传达风险。
- en: Monitoring and auditing
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 监控和审计
- en: Regular monitoring and auditing of data handling practices can help identify
    and rectify privacy issues promptly, mitigating the risk of sensitive data exposure.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 定期监控和审计数据处理实践可以帮助及时识别和纠正隐私问题，减轻敏感数据泄露的风险。
- en: This account emphasizes the delicate balance between leveraging user data to
    enhance LLM capabilities and ensuring the stringent safeguarding of user privacy
    and data integrity.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这个案例强调了在利用用户数据增强LLM能力与确保严格保护用户隐私和数据完整性之间的微妙平衡。
- en: GitHub Copilot and OpenAI’s Codex
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GitHub Copilot和OpenAI的Codex
- en: A notable incident in 2023 highlighted the risks associated with sensitive data
    disclosure through LLMs involving GitHub Copilot, a tool powered by OpenAI’s Codex
    model. GitHub designed Copilot to assist developers by autocompleting code, a
    feat achieved by training on a vast corpus of code from GitHub’s public repositories.
    However, the tool soon found itself in a quagmire of legal and ethical challenges.
    Some developers discovered Copilot suggesting snippets of their copyrighted code—despite
    the original code being under a license that restricted such use. This possible
    copyright violation sparked a lawsuit against GitHub, Microsoft, and OpenAI, with
    the developers alleging copyright, contract, and privacy violations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 2023年的一起显著事件突出了通过LLM（大型语言模型）涉及GitHub Copilot（一个由OpenAI的Codex模型驱动的工具）的敏感数据披露风险。GitHub设计Copilot旨在通过自动补全代码来帮助开发者，这是通过在GitHub公共存储库的大量代码语料库上训练实现的。然而，这个工具很快陷入了法律和伦理挑战的泥潭。一些开发者发现Copilot建议了他们的版权代码片段——尽管原始代码处于一个限制此类使用的许可证之下。这种可能的版权侵犯引发了GitHub、微软和OpenAI的诉讼，开发者指控版权、合同和隐私侵犯。
- en: 'The case unfolded in a US district court. The developers’ argument hinged on
    two primary claims: Codex’s ability to reproduce portions of their code breached
    software licensing terms and violated the Digital Millennium Copyright Act by
    reproducing copyrighted code without the necessary copyright management information.
    The judge denied a motion to dismiss these two claims, keeping the lawsuit alive.
    While the court rejected some allegations, the crux of the case revolved around
    the potential infringement of the developers’ intellectual property rights due
    to the reproduction of code by Codex and Copilot.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 此案在美国地区法院展开。开发者的论点基于两个主要主张：Codex能够复制其代码的部分内容，违反了软件许可条款，并且通过复制受版权保护的代码而没有必要的版权管理信息，违反了《数字千年版权法案》。法官驳回了驳回这两个主张的动议，使诉讼得以继续。尽管法院驳回了某些指控，但案件的焦点在于由于Codex和Copilot复制代码，可能侵犯了开发者的知识产权。
- en: As of this writing, the lawsuit is still being litigated, and we may not know
    the full impact for some time. The lawsuit underscores a critical concern in the
    field of LLMs—the potential for unintentional sensitive data disclosure. The repercussions
    extended beyond the parties involved, resonating across the tech industry and
    sparking discussions on the legal and ethical implications of LLMs accessing and
    learning from publicly available data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，诉讼仍在进行中，我们可能需要一段时间才能了解其全部影响。这场诉讼突显了LLM（大型语言模型）领域的一个关键问题——无意中泄露敏感数据的潜在风险。其影响超出了涉案各方，在整个科技行业引起共鸣，并引发了关于LLM访问和使用公开数据的法律和伦理影响的讨论。
- en: 'Even though the full intellectual property issues raised by this case are not
    yet fully settled, there are several lessons you can take from this and apply
    to your own projects:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管此案提出的全部知识产权问题尚未完全解决，但您可以从中学到一些经验教训，并将其应用到自己的项目中：
- en: Data governance
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 数据治理
- en: This incident emphasized the importance of robust data governance frameworks,
    underscoring the need for clear guidelines on data usage, especially concerning
    publicly available or open source data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这起事件强调了稳健的数据治理框架的重要性，强调了在数据使用方面需要明确的指南，特别是关于公开可用或开源数据。
- en: Legal clarity
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 法律清晰度
- en: The case illuminated the legal gray areas surrounding the interaction of LLMs
    with real-world data, suggesting a need for more explicit laws and regulations
    defining the bounds of permissible data usage and copyright adherence.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此案阐明了LLM与真实世界数据交互周围的合法灰色区域，表明需要更明确的法律和法规来定义可允许的数据使用范围和版权遵守。
- en: Ethical engagement
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 伦理参与
- en: Beyond legal compliance, the ethical dimensions of data usage by LLMs call for
    a conscientious approach by developers and organizations, respecting both the
    letter and spirit of open source contributions and licensing agreements.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 除了法律合规性之外，LLM数据使用的伦理维度要求开发者和组织采取负责任的态度，尊重开源贡献和许可协议的字面意义和精神。
- en: User awareness
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 用户意识
- en: The incident also highlighted the importance of user awareness regarding how
    corporations might utilize their data, suggesting a precedent for more transparent
    disclosures by organizations employing LLMs.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此事件还突显了用户对如何利用其数据的意识的重要性，为使用LLM的组织提供了更透明披露的先例。
- en: The unfolding of this lawsuit provides a real-world tableau illustrating the
    complex interplay of legal, ethical, and technical factors in the domain of LLM
    applications. It is a harbinger of the challenges (particularly concerning sensitive
    data disclosure risks) to come as LLMs evolve and interact with diverse data sources.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这场诉讼的展开提供了一个现实世界的场景，展示了LLM应用领域中法律、伦理和技术因素之间的复杂相互作用。它是LLM发展和与各种数据源互动时即将到来的挑战（尤其是关于敏感数据泄露风险的挑战）的预兆。
- en: Knowledge Acquisition Methods
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知识获取方法
- en: The power of your LLM application will grow with the amount of data it has access
    to. At the same time, risks associated with that data also increase. If your LLM
    has been exposed to data of a particular type, you’ll need to manage the risk
    of disclosure. Let’s look at three common ways that LLMs acquire knowledge.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您的LLM应用的力量将随着其可访问的数据量而增长。同时，与这些数据相关的风险也在增加。如果您的LLM接触到了特定类型的数据，您将需要管理数据泄露的风险。让我们看看LLM获取知识的三种常见方式。
- en: Central to an LLM’s knowledge base is its *model training*. The process begins
    with *foundation model training*, where the LLM immerses itself in vast datasets,
    acquiring a broad grasp of language, context, and worldly insights. This foundational
    knowledge can then be refined through *model fine-tuning*, adapting the LLM to
    cater to more specialized tasks or niche domains using targeted datasets.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的知识库的核心是其*模型训练*。这个过程从*基础模型训练*开始，LLM沉浸在庞大的数据集中，获得对语言、上下文和世界洞察的广泛理解。然后，这种基础知识可以通过*模型微调*进行细化，使用目标数据集将LLM调整到更专业化的任务或细分领域。
- en: LLMs learn in a distinct, infrequent training phase, which means their information
    is often out of date, and that limits their use in applications that require up-to-date
    knowledge. This is where *retrieval-augmented generation* (RAG) comes into play.
    LLMs can venture into the expansive realms of the public web, garner real-time
    updates, or dive deep into structured or unstructured databases. Further amplifying
    their knowledge spectrum, LLMs can connect with external systems, databases, or
    online platforms via APIs, enriching their responses with a wealth of external
    data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs在独特的、不频繁的训练阶段进行学习，这意味着它们的信息通常过时，这限制了它们在需要最新知识的应用中的使用。这就是*检索增强生成*（RAG）发挥作用的地方。LLMs可以进入广阔的公共网络领域，获取实时更新，或者深入到结构化或非结构化数据库中。通过API连接外部系统、数据库或在线平台，LLMs可以进一步扩展其知识范围，用丰富的外部数据丰富其回答。
- en: Some applications can go even further. User interactions like queries, conversations,
    and feedback enable LLMs to acquire new knowledge continuously. Processing these
    inputs allows the LLM to expand its understanding, refining its capabilities with
    each interaction and delivering increasingly personalized and relevant responses.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一些应用甚至可以更进一步。用户交互，如查询、对话和反馈，使LLMs能够持续获取新知识。处理这些输入允许LLM扩展其理解，通过每次交互改进其能力，并交付越来越个性化和相关的回答。
- en: Each of these categories—training, retrieval-augmented generation, and user
    interaction—possesses nuances that can significantly influence the security landscape
    of your LLM application. While they serve as conduits for knowledge acquisition,
    they also introduce potential vulnerabilities and challenges that need careful
    consideration. As we progress through this chapter, we’ll probe each category
    to expose the crucial security implications inherent in each method. Through this
    exploration, we aim to equip you with a comprehensive understanding of the potential
    risks and the measures to mitigate them.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类别——训练、检索增强生成和用户交互——各自都有细微差别，这些差别可以显著影响您LLM应用的网络安全格局。虽然它们作为知识获取的渠道，但也引入了需要仔细考虑的潜在漏洞和挑战。随着我们进入本章，我们将深入探究每个类别，揭示每种方法固有的关键安全影响。通过这次探索，我们的目标是让您全面了解潜在风险及其缓解措施。
- en: Model Training
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'Training is a crucial step in developing and refining LLMs. It encompasses
    two distinct phases: creating the foundation model and its subsequent fine-tuning.
    The *foundation model training* establishes broad linguistic and contextual understanding,
    while *fine-tuning* hones this generalized knowledge for specific tasks or domains.
    In this section, we’ll explore the intricacies of both these phases, emphasizing
    their respective methodologies. Following this, we’ll expand on the crucial security
    implications inherent in each step, equipping you with insights into potential
    vulnerabilities and best practices for safeguarding against them.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 训练是开发和精炼大型语言模型（LLMs）的关键步骤。它包括两个不同的阶段：创建基础模型及其后续的微调。*基础模型训练*建立了广泛的语言和上下文理解，而*微调*则将这种通用知识针对特定任务或领域进行细化。在本节中，我们将探讨这两个阶段的复杂性，强调它们各自的方法。随后，我们将深入探讨每个步骤固有的关键安全影响，为您提供关于潜在漏洞和防范最佳实践的见解。
- en: Foundation Model Training
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础模型训练
- en: Foundation model training is the initial step in building an LLM. In this phase,
    the model is trained on a vast and diverse dataset, often encompassing various
    topics, languages, and text formats. The objective is to equip the model with
    a broad understanding of language, contextual relationships, and general world
    knowledge. This foundational training forms the base upon which the LLM can generate
    coherent, contextually relevant, and informed responses, akin to a basic understanding
    of the world, much like a human before specializing in a particular field.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型训练是构建大型语言模型（LLM）的第一步。在这个阶段，模型在广泛且多样化的数据集上进行训练，通常包括各种主题、语言和文本格式。目标是让模型具备对语言、语境关系和一般世界知识的广泛理解。这种基础训练构成了LLM生成连贯、语境相关和有见地回应的基础，类似于人类在特定领域专业化之前对世界的初步理解。
- en: 'At its core, the process of foundation model training an LLM is a sophisticated
    exercise in pattern recognition. Training involves using advanced algorithms to
    analyze vast datasets, identify relationships between words, understand context,
    and generate coherent responses based on this understanding. Let’s look at the
    steps involved:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本质上，训练一个LLM的基础模型是一个复杂的模式识别练习。训练涉及使用高级算法分析大量数据集，识别词语之间的关系，理解语境，并根据这种理解生成连贯的回应。让我们看看涉及到的步骤：
- en: 1\. Pattern recognition
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 模式识别
- en: The training foundation feeds the model vast text data—sometimes billions of
    tokens. As it processes this data, the model learns to recognize patterns. For
    instance, it starts to understand that the word “apple” can be associated with
    “fruit,” “tree,” “pie,” or “technology,” depending on the context.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 训练基础模型向模型提供大量的文本数据——有时是数十亿个标记。在处理这些数据时，模型学会识别模式。例如，它开始理解“苹果”这个词可以根据语境与“水果”、“树”、“派”或“技术”相关联。
- en: 2\. Contextual understanding
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 语境理解
- en: Next, the model starts discerning the nuanced differences in word usage based
    on context. It learns, for example, that the phrase “Apple’s growth” can refer
    to the expansion of a tech company or the development of fruit on a tree, based
    on surrounding words and phrases. Training algorithms will adjust internal parameters,
    often numbering billions, to capture these intricate contextual relationships.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，模型开始根据语境辨别词语使用的细微差别。例如，它学会根据周围的词语和短语，短语“苹果的增长”可以指一家科技公司的扩张或树上水果的发展。训练算法将调整内部参数，通常数量以亿计，以捕捉这些复杂语境关系。
- en: 3\. Response generation
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 回应生成
- en: The model’s ability to generate responses is developed through repeated iterations
    of training, continuously refining its understanding of language and context.
    Unlike human memory recall, the model analyzes input, matches it with learned
    patterns, understands the context, and constructs a response based on training
    data. The diversity and breadth of the training data are critical, as they directly
    influence the model’s capability to produce accurate and contextually appropriate
    responses.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 模型生成回应的能力是通过反复的训练迭代来发展的，不断精炼其对语言和语境的理解。与人类的记忆回忆不同，模型分析输入，将其与学习到的模式匹配，理解语境，并根据训练数据构建回应。训练数据的多样性和广度至关重要，因为它们直接影响到模型产生准确和语境适当的回应的能力。
- en: Security Considerations for Foundation Models
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础模型的安全考量
- en: 'The preceding steps show why training a custom foundation model can be complex
    and costly. That’s why most projects today start with an existing foundation model.
    The starting point might be a proprietary model accessed via a SaaS (software
    as a service) product, such as OpenAI’s GPT series, or a privately hosted open
    source model, such as Meta’s Llama. In either of those cases, the foundation model’s
    creator has hopefully done some level of work to ensure that things like personally
    identifiable information (PII) are kept out of the training base, although that
    might not always be the case. Choose your foundation model carefully! Even with
    the best intentions, there are numerous examples of these foundational models
    accumulating sensitive information that might be inappropriate in some contexts.
    A few examples of potentially problematic information types to look out for include:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的步骤说明了为什么训练一个定制的基座模型可能很复杂且成本高昂。这就是为什么今天的大多数项目都是从现有的基座模型开始的。起点可能是一个通过SaaS（软件即服务）产品访问的专有模型，例如OpenAI的GPT系列，或者一个私有托管的开源模型，例如Meta的Llama。在任一情况下，基座模型的创建者都希望已经做了一定程度的工作，以确保个人信息（PII）等敏感信息不会出现在训练基础中，尽管这并不总是可能。请仔细选择您的基座模型！即使有最好的意图，也有许多这些基座模型积累敏感信息的例子，这些信息在某些情况下可能是不适当的。以下是一些可能需要留意的问题信息类型示例：
- en: Someone else’s intellectual property, such as copyrighted text
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他人知识产权，例如受版权保护的文本
- en: Dangerous or illegal information related to weapons, drugs, or other topics
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与武器、毒品或其他相关话题的危险或非法信息
- en: Cultural or religious texts that may be inappropriate in specific contexts or
    discussions
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在特定情境或讨论中可能不适当的文化或宗教文本
- en: If you decide to train your own foundational model, you can achieve a higher
    level of control over many aspects of your system. This control may be highly
    advantageous. However, you’re now assuming some responsibility for every part
    of the training data you use in your model. Keeping it free of sensitive information
    may prove a significant challenge for you. We’ll discuss this more later in this
    chapter.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您决定训练自己的基座模型，您可以对系统许多方面实现更高程度的控制。这种控制可能非常有优势。然而，您现在需要承担使用在模型中使用的所有训练数据的责任。保持其无敏感信息可能对您来说是一个重大的挑战。我们将在本章后面进一步讨论这个问题。
- en: Model Fine-Tuning
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型微调
- en: Model fine-tuning is an optional step following foundation model training, aimed
    at specializing a general-purpose model for specific tasks or domains. You will
    use a smaller, domain-specific dataset to adjust the model’s weights during fine-tuning.
    This way, you can refine its responses to perform well in the targeted application.
    This process significantly enhances the model’s performance, making it more relevant
    and accurate for the intended use case. The specialized data used for fine-tuning
    allows the model to adapt its generalized understanding acquired during foundation
    training to the nuances and specifics of the task, providing a more tailored and
    effective solution.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 模型微调是基座模型训练之后的可选步骤，旨在针对特定任务或领域对通用模型进行专业化。您将使用一个较小的、特定领域的数据集来调整模型在微调期间的权重。这样，您可以细化其响应，以在目标应用中表现良好。这个过程显著提高了模型的表现，使其对预期用途更加相关和准确。用于微调的专用数据允许模型将基座训练期间获得的泛化理解适应到任务的细微差别和具体细节，从而提供更定制和有效的解决方案。
- en: 'At its core, fine-tuning addresses a fundamental challenge in machine learning:
    while foundational models have broad knowledge, they often need more depth and
    specificity for particular tasks. For example, while a general model might have
    been trained using some medical information, it might generate responses at a
    different level of precision than those expected by medical professionals. Fine-tuning
    bridges this gap by adapting the general knowledge of the foundational model to
    a specific domain or task.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，微调解决了机器学习中的一个基本挑战：虽然基座模型具有广泛的知识，但它们通常需要更多深度和特定性来完成特定任务。例如，虽然一个通用模型可能使用了一些医疗信息进行训练，但它可能产生的响应精度与医疗专业人员预期的不同。微调通过将基座模型的通用知识适应到特定领域或任务来弥合这一差距。
- en: Training Risks
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练风险
- en: Whether training a foundation model from scratch or fine-tuning an existing
    model, you must carefully consider the risks of incorporating sensitive data into
    your training set. Any data used in training your model might become a long-term
    memory. And even with attempts to align your model and provide guardrails against
    inappropriate disclosure, your model might disclose this information to a third
    party.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是从头训练基础模型还是微调现有模型，都必须仔细考虑将敏感数据纳入训练集的风险。用于训练模型的数据可能会成为长期记忆。即使尝试调整模型并提供防止不当披露的护栏，模型仍可能将此类信息泄露给第三方。
- en: 'Here are some risks you’ll want to consider as you craft the dataset for training
    your model:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在为训练模型构建数据集时，以下是一些您需要考虑的风险：
- en: Direct data leakage
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 直接数据泄露
- en: If you expose a model to PII or confidential information during training, it
    might generate outputs that inadvertently disclose this data.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在训练过程中将模型暴露于PII或机密信息，它可能会生成意外泄露这些数据的输出。
- en: Inference attacks
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 推理攻击
- en: An attacker might use prompt injection to extract sensitive data from the model.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 攻击者可能使用提示注入来从模型中提取敏感数据。
- en: Regulatory and compliance violations
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 违规和合规问题
- en: Training models with a dataset that includes PII, especially without user consent,
    can lead to breaches of data protection regulations like the Health Insurance
    Portability and Accountability Act (HIPAA), the General Data Protection Regulation
    (GDPR), or the California Consumer Privacy Act (CCPA). This can result in hefty
    fines and legal consequences, not to mention reputational damage.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用包含个人身份信息（PII）的数据集训练模型，尤其是未经用户同意，可能导致违反数据保护法规，如健康保险可携带性和问责制法案（HIPAA）、通用数据保护条例（GDPR）或加利福尼亚消费者隐私法案（CCPA）。这可能导致巨额罚款和法律责任，更不用说声誉损害。
- en: Loss of public trust
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 公众信任的丧失
- en: If it becomes public knowledge that a corporation trained its model with PII
    or confidential data and can leak such data, the organization might face significant
    backlash and loss of trust.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果公众得知一家公司使用PII或机密数据训练了其模型，并且可以泄露此类数据，该组织可能会面临重大反弹和信任丧失。
- en: Compromised data anonymization
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 数据匿名化受损
- en: Even if PII is “anonymized” before training, models might still discern patterns
    that allow data de-anonymization, particularly if they correlate inputs with other
    publicly available datasets.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在训练前将PII“匿名化”，模型仍可能发现允许数据去匿名化的模式，尤其是如果它们将输入与其他公开可用的数据集相关联。
- en: Increased attractiveness as a target
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 作为目标吸引力增加
- en: If malicious actors believe that a model contains confidential information or
    PII, they might be more motivated to launch sophisticated attacks against it,
    aiming to extract valuable data.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果恶意行为者认为模型包含机密信息或PII，他们可能会更有动力对其发起复杂的攻击，旨在提取有价值的数据。
- en: Model rollbacks and financial implications
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 模型回滚和财务影响
- en: If a team later discovers that a model was previously trained using PII, it
    might need to roll back to a previous version, leading to financial implications
    and project delays.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果团队后来发现模型之前曾使用PII进行训练，可能需要回滚到早期版本，从而导致财务影响和项目延误。
- en: Given these significant risks, it’s crucial to ensure that data used in training
    is thoroughly sanitized. Furthermore, periodic audits, rigorous data vetting,
    and advanced differential privacy techniques can help mitigate potential risks.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些重大风险，确保用于训练的数据得到彻底清洗至关重要。此外，定期审计、严格的数据审查和高级差分隐私技术可以帮助减轻潜在风险。
- en: Retrieval-Augmented Generation
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）
- en: RAG is a transformative approach in LLM data acquisition and response generation.
    Instead of solely relying on a vast internal knowledge base acquired from training,
    as traditional LLMs do, RAG first retrieves relevant document snippets or *passages*
    from an external dataset. Then, the LLM utilizes these passages to inform its
    generated responses. This two-step approach—retrieving relevant information and
    then developing an answer based on that retrieval—allows the model to pull in
    real-time or more updated information that wasn’t part of its original training
    data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: RAG是LLM数据获取和响应生成的变革性方法。与传统LLM仅依赖从训练中获得的庞大内部知识库不同，RAG首先从外部数据集中检索相关的文档片段或*段落*。然后，LLM利用这些段落来指导其生成的响应。这种两步法——检索相关信息然后基于检索开发答案——允许模型实时或更及时地获取其原始训练数据中未包含的信息。
- en: RAG is a significant leap forward in the ability of language models to handle
    large amounts of real-time data. No matter how expansive their training data,
    traditional LLMs are inherently limited to their last training cutoff, making
    them potentially outdated for specific topics or real-time events. RAG solves
    this limitation by allowing LLMs to access and integrate external, up-to-date
    information seamlessly. This dynamic capability enhances the accuracy and relevance
    of the model’s outputs and positions LLMs to be more versatile and adaptive in
    rapidly evolving domains. The ability to fuse retrieval and generation processes
    promises a new frontier of more informed and context-aware conversational AI.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: RAG是语言模型处理大量实时数据能力的重大飞跃。无论他们的训练数据多么庞大，传统LLM本质上都局限于他们最后的训练截止日期，这使得他们在特定主题或实时事件上可能过时。RAG通过允许LLM无缝访问和整合外部、最新的信息来解决这一限制。这种动态能力提高了模型输出的准确性和相关性，并将LLM定位为在快速发展的领域中更具多样性和适应性。融合检索和生成过程的能力预示着更知情和情境感知的对话AI的新前沿。
- en: However, attaching your LLM to large, live data stores opens up a Pandora’s
    box of security considerations. One issue is indirect prompt injection, which
    we discussed in [Chapter 4](ch04.html#prompt_injection). Prompt injection attacks
    are possible when you feed your LLM untrusted data as part of a RAG prompt. But,
    for this chapter, we’ll focus on the risks associated with sensitive data disclosure
    to help answer the question “Can your LLM know too much?”
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，将您的LLM连接到大型、实时数据存储会打开一个潘多拉的盒子，涉及安全考虑。一个问题是我们之前在[第4章](ch04.html#prompt_injection)中讨论的间接提示注入。当您将不受信任的数据作为RAG提示的一部分提供给LLM时，可能会发生提示注入攻击。但，对于本章，我们将关注与敏感数据披露相关的风险，以帮助回答“您的LLM知道得太多吗？”这个问题。
- en: Let’s review some common ways a RAG system gets access to larger data stores.
    By understanding how your LLM might access these knowledge bases, we can better
    plan for the security risks and considerations. Here, we’ll look at accessing
    data directly from the web and accessing databases.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下RAG系统获取更大数据存储的常见方式。通过了解您的LLM可能如何访问这些知识库，我们可以更好地规划安全风险和考虑因素。在这里，我们将探讨直接从网络访问数据和访问数据库。
- en: Direct Web Access
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 直接网络访问
- en: Providing your LLM with a direct connection to the web can be a powerful mechanism
    to get real-time or updated information to augment its knowledge base. A web connection
    enables the model to fetch the latest data, stay current with evolving topics,
    and provide more accurate and up-to-date responses. By interacting with the web,
    the LLM can bridge the gap between its last training cutoff and the present, ensuring
    its information is relevant and timely. This feature significantly enhances the
    utility of LLMs in dynamic or rapidly changing domains.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为您的LLM提供直接连接到网络的能力，可以是一种强大的机制，以便获取实时或更新的信息来增强其知识库。网络连接使模型能够获取最新数据，跟上不断发展的主题，并提供更准确和最新的响应。通过与网络互动，LLM可以弥合其最后训练截止日期和现在之间的差距，确保其信息的相关性和时效性。这一功能显著提高了LLM在动态或快速变化的领域中的实用性。
- en: Let’s look at a couple of patterns for accessing the web.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看访问网络的几种模式。
- en: Scraping a specific URL
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 抓取特定URL
- en: Directly accessing a predetermined URL to extract its content is a particularly
    useful approach when you know the exact source of the information you want the
    LLM to access. This technique is appropriate for many cases, such as extracting
    daily stock prices from a financial news website, pulling regular updates from
    a specific news source or blog, or retrieving product details or reviews from
    an ecommerce site.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 直接访问预定的URL以提取其内容，当您知道您想要LLM访问的信息的确切来源时，这是一种特别有用的方法。这种方法适用于许多情况，例如从金融新闻网站提取每日股价，从特定的新闻来源或博客中获取定期更新，或从电子商务网站检索产品详情或评论。
- en: 'For these types of use cases, there are several advantages:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些类型的用例，有几个优点：
- en: Precision
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 精确性
- en: Targets the desired web page, eliminating potential noise from unrelated sources.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 针对目标网页，消除了来自无关来源的潜在噪声。
- en: Efficiency
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 效率
- en: Since the URL is predetermined, you can optimize the scraping process for that
    page’s specific structure and content.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 由于URL是预定的，您可以优化该页面的特定结构和内容的抓取过程。
- en: Reliability
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 可靠性
- en: Consistently accessing a single or a set of known URLs can provide more stable
    results over time.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 持续访问单个或一组已知的URL可以在一段时间内提供更稳定的结果。
- en: 'But there are also some critical challenges:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 但也存在一些关键挑战：
- en: Page structure changes
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 页面结构变化
- en: Web pages often undergo redesigns or structural changes. If the specific URL’s
    content structure changes, the scraping mechanism might need adjustment.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 网页经常进行重新设计或结构变化。如果特定URL的内容结构发生变化，抓取机制可能需要调整。
- en: Access restrictions
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 访问限制
- en: Some websites use CAPTCHAs, rate limits, or *robots.txt* restrictions to prevent
    or limit automated access.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一些网站使用CAPTCHA、速率限制或*robots.txt*限制来防止或限制自动化访问。
- en: Legal or ethical challenges
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 法律或伦理挑战
- en: If you do not own the content on the web page you’re scraping, you must consider
    whether the owner of that page could object to how you’re using that data within
    your system. Consider copyrights and other licensing terms as needed.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有拥有你正在抓取的网页上的内容，你必须考虑该页面的所有者是否可能反对你在系统中使用这些数据的方式。根据需要考虑版权和其他许可条款。
- en: Using a search engine followed by content scraping
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用搜索引擎后进行内容抓取
- en: In this method, you issue a search query to a platform like Google or Bing to
    find relevant content based on specific keywords or topics and then scrape the
    content from one or more top search results. This approach is most appropriate
    for use cases such as researching current public sentiment on a specific topic
    or product by scraping top news articles or blogs, retrieving recent academic
    publications or articles on a particular subject, and understanding market trends
    by analyzing the top results for industry-specific keywords.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，你向谷歌或必应等平台发出搜索查询，根据特定的关键词或主题找到相关内容，然后从一或多个顶级搜索结果中抓取内容。这种方法最适用于以下用例：通过抓取顶级新闻文章或博客来研究特定主题或产品的当前公众情绪，检索特定主题的最近学术出版物或文章，以及通过分析特定行业关键词的顶级结果来了解市场趋势。
- en: 'For these types of use cases, there are several advantages:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些类型的用例，有几个优点：
- en: Relevance
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性
- en: Search engines rank content based on relevance, ensuring the LLM accesses high-quality
    and pertinent information.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎根据相关性对内容进行排名，确保LLM访问高质量和相关的信息。
- en: Timeliness
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 及时性
- en: Search engines constantly index new content, making them a valuable resource
    for obtaining recent information on a topic.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎不断索引新内容，使它们成为获取特定主题最新信息的宝贵资源。
- en: Diversity
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 多样性
- en: By accessing multiple top results, LLMs can gain a more comprehensive understanding
    of a topic from various perspectives.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 通过访问多个顶级结果，LLMs可以从不同的角度更全面地了解一个主题。
- en: 'Challenges include:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战包括：
- en: Indirect prompt injection
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 间接提示注入
- en: As discussed in [Chapter 4](ch04.html#prompt_injection), malicious prompts may
    not come directly from users. They may be secretly embedded into data included
    in a prompt in a RAG system. In this case, an attacker may embed malicious data
    within a web page, leading to an indirect prompt injection attack when the page
    is parsed and data is included in a prompt passed to the LLM by the application.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第4章](ch04.html#prompt_injection)所述，恶意提示可能不是直接来自用户。它们可能被秘密嵌入到RAG系统中的提示数据中。在这种情况下，攻击者可以在网页中嵌入恶意数据，当页面被解析并且数据包含在通过应用程序传递给LLM的提示中时，导致间接提示注入攻击。
- en: Dynamic results
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 动态结果
- en: Search results for a particular query can change over time, introducing variability
    in the content the LLM accesses.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 特定查询的搜索结果可能会随时间变化，这引入了LLM访问的内容的变异性。
- en: Search limitations
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索限制
- en: Search engines may have request limits, especially for automated queries, which
    could restrict the number of searches.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索引擎可能有请求限制，尤其是对于自动化查询，这可能会限制搜索次数。
- en: Depth of scraping
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 抓取深度
- en: Deciding how many top results to scrape can affect the quality and breadth of
    information. Scraping too many might dilute the relevance; scraping too few might
    miss out on valuable perspectives.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 决定抓取多少顶级结果会影响信息的质量和广度。抓取太多可能会稀释相关性；抓取太少可能会错过有价值的观点。
- en: Legal and ethical concerns
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 法律和伦理问题
- en: When scraping content, it’s important to abide by search engines’ terms of service
    and consider copyright and licensing terms.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在抓取内容时，重要的是遵守搜索引擎的服务条款，并考虑版权和许可条款。
- en: Example risks
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例风险
- en: 'Direct web access or search engines carry various risks related to the unintentional
    acquisition or disclosure of PII and other sensitive information. Here are some
    examples of how this might happen:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 直接网络访问或搜索引擎携带各种风险，与无意中获取或披露PII和其他敏感信息有关。以下是一些可能发生这种情况的例子：
- en: Comment sections and forums
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 评论区和论坛
- en: A model might scrape a technical article or news piece from a reputable source,
    but in doing so, it could also unintentionally pull in comments or forum posts
    attached to the article. These sections often contain personal anecdotes, email
    addresses, or other identifiable details. For example, a user might ask the LLM
    for recent discussions on a particular health topic. The model could pull data
    from a health forum where users have shared personal stories, names, ages, or
    even specific medical details.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一个模型可能会从一个可信赖的来源抓取技术文章或新闻报道，但在这样做的时候，它也可能无意中拉入了与文章相关的评论或论坛帖子。这些部分通常包含个人轶事、电子邮件地址或其他可识别的细节。例如，一个用户可能会要求LLM提供关于特定健康主题的最新讨论。模型可能会从用户分享个人故事、姓名、年龄或甚至特定医疗细节的健康论坛中提取数据。
- en: User profiles
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 用户资料
- en: Some websites include user profiles or author bios at the end of articles or
    posts. Scraping such sites might accidentally gather personal details or contacts
    in these profiles. For example, an LLM fetching entries from a blogging platform
    might also scrape the author’s bio, including their full name, location, workplace,
    and email address.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一些网站在文章或帖子末尾包含用户资料或作者简介。抓取此类网站可能会意外收集这些资料中的个人细节或联系信息。例如，一个从博客平台抓取条目的LLM可能会也抓取作者的简介，包括他们的全名、位置、工作单位和电子邮件地址。
- en: Hidden data in web pages
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 网页中的隐藏数据
- en: Some web pages store metadata or secret information in the background. While
    this data may not be visible to human viewers, an LLM with web access might still
    access and process it. For example, an LLM scraping a corporate website might
    unintentionally access embedded metadata that contains internal document paths
    or even confidential revision comments.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 一些网页在后台存储元数据或秘密信息。虽然这些数据可能对人类观众不可见，但具有网络访问权限的LLM仍然可以访问和处理它。例如，一个抓取企业网站的LLM可能会无意中访问包含内部文档路径或甚至机密修订注释的嵌入式元数据。
- en: Inaccurate or broad search queries
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 不准确或宽泛的搜索查询
- en: When using search engines, if the queries are too broad or not accurately defined,
    the model might pull in unrelated content that contains sensitive information.
    For example, a query like “John Doe’s presentation” intended to find a public
    lecture by a notable figure might also yield results from a different John Doe’s
    blog where he shared his phone number for contact.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用搜索引擎时，如果查询过于宽泛或定义不准确，模型可能会拉入包含敏感信息的不相关内容。例如，一个旨在寻找知名人物公开演讲的查询“John Doe的演示”可能会也产生来自不同John
    Doe的博客的结果，他在那里分享了他的联系电话。
- en: Advertisements and sponsored content
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 广告和赞助内容
- en: Web scraping might inadvertently gather data from ads or sponsored posts that
    can sometimes contain personalized content based on prior user behavior or other
    targeted criteria. For example, an LLM scraping news from a web page might also
    pull in an ad that says “Special deals for residents of [location],” revealing
    location data.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 网络抓取可能会无意中收集来自广告或赞助帖子的数据，这些帖子有时可能包含基于先前用户行为或其他针对性标准的个性化内容。例如，一个抓取网页新闻的LLM可能会也拉入一个广告，声称“[地点]居民的特别优惠”，揭示了位置数据。
- en: Dynamic content and pop-ups
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 动态内容和弹出窗口
- en: Many websites have dynamic content that changes based on user interaction, location,
    or time. Pop-up surveys, chatbots, or feedback forms can contain prompts for personal
    information. For example, in scraping a service provider’s web page, the LLM might
    pull a pop-up content asking, “Are you from [city]? Answer this survey!” which
    can disclose geolocation details.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 许多网站具有基于用户交互、位置或时间变化的动态内容。弹出调查、聊天机器人或反馈表单可能包含个人信息提示。例如，在抓取服务提供商的网页时，LLM可能会拉入一个弹出内容询问：“你是来自[城市]的吗？回答这个调查！”这可能会披露地理位置细节。
- en: Document metadata and properties
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 文档元数据和属性
- en: When accessing online documents or files, their associated metadata can contain
    author names, editing histories, or internal comments. For example, the LLM might
    pull a company’s public financial report, but along with it, the properties might
    show “last edited by [employee name] from [department],” revealing internal company
    information.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当访问在线文档或文件时，它们相关的元数据可以包含作者姓名、编辑历史或内部评论。例如，LLM可能会抓取一家公司的公开财务报告，但与其相关的属性可能会显示“最后由[员工姓名]从[部门]编辑”，揭示了公司内部信息。
- en: Accessing a Database
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问数据库
- en: This pattern involves an LLM retrieving data stored in structured or unstructured
    databases. This approach can include querying traditional databases for specific
    data or accessing vector databases for embeddings. By leveraging databases, LLMs
    can provide precise and data-driven responses, making them significantly more
    valuable in scenarios requiring real-time or historical data retrieval. This method
    of knowledge acquisition allows LLMs to operate in data-rich environments and
    provide highly accurate, context-aware, and personalized responses based on the
    data available in the databases.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式涉及一个LLM检索存储在结构化或非结构化数据库中的数据。这种方法可以包括查询传统数据库以获取特定数据或访问向量数据库以获取嵌入。通过利用数据库，LLM可以提供精确且数据驱动的响应，使它们在需要实时或历史数据检索的场景中具有显著的价值。这种知识获取方法允许LLM在数据丰富的环境中运行，并基于数据库中可用的数据提供高度准确、上下文感知和个性化的响应。
- en: Relational databases
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关系数据库
- en: Relational databases have been the de facto standard since the late 1970s, underpinning
    the infrastructure of countless industries and applications. They revolutionized
    how developers organize and access data using tables and ensure data integrity
    through established relationships. Their structured approach to data management,
    paired with the power of SQL (Structured Query Language) for data manipulation,
    enabled organizations to handle complex datasets efficiently and precisely. While
    modern technological advancements have brought forth new types of databases, the
    robustness of relational databases continues to make them a trusted choice for
    many enterprises.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 自20世纪70年代末以来，关系数据库一直是事实上的标准，支撑着无数行业和应用程序的基础设施。它们革命性地改变了开发者使用表格组织和访问数据的方式，并通过建立的关系确保数据完整性。它们对数据管理的结构化方法，加上SQL（结构化查询语言）在数据处理方面的力量，使组织能够高效且精确地处理复杂的数据集。尽管现代技术进步带来了新型数据库，但关系数据库的稳健性继续使它们成为许多企业的信任之选。
- en: 'Giving your LLM access to the vast data stores inside your enterprise is powerful
    and thus tempting. The advantages are clear: instant access to enormous amounts
    of historical and real-time data allows for richer, more informed responses tailored
    to specific organizational needs and contexts. The LLM can provide insights, answer
    intricate queries, or even automate tasks that would otherwise take hours for
    a human to compile. It can transform the user experience, offering a seamless
    interface between vast data repositories and end users, whether employees, stakeholders,
    or customers. However, with this immense power comes an equally tremendous responsibility
    to safeguard sensitive information and ensure data access remains securely and
    ethically managed. Let’s examine risk areas related to accessing databases as
    part of your LLM application:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 给你的LLM访问企业内部庞大的数据存储库是强大且诱人的。优势是明显的：即时访问大量历史和实时数据，可以提供更丰富、更全面的信息，以满足特定组织的需求和情境。LLM可以提供见解，回答复杂的查询，甚至自动化原本需要数小时人工编译的任务。它可以改变用户体验，在庞大的数据存储库和最终用户之间提供一个无缝的界面，无论是员工、利益相关者还是客户。然而，随着这种巨大的力量，也带来了同样巨大的责任，即保护敏感信息并确保数据访问保持安全且道德地管理。让我们检查与LLM应用程序相关的数据库访问风险区域：
- en: Complex relationships amplify exposure
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂关系放大暴露
- en: Relational databases link structured datasets through relationships. While one
    table might seem benign, its linkage to another could inadvertently reveal sensitive
    patterns. For instance, an innocent list of product IDs can become sensitive when
    linked to specific customer transactions.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 关系数据库通过关系链接结构化数据集。虽然一张表可能看似无害，但其与其他表的关联可能会无意中揭示敏感模式。例如，一个无辜的产品ID列表在关联到特定的客户交易时可能会变得敏感。
- en: Unintended queries
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 非预期查询
- en: A misinterpreted command or a poorly phrased question could lead the LLM to
    fetch data the developer didn’t intend the user to access. Imagine a scenario
    where a casual inquiry inadvertently brings up a detailed record, revealing more
    than was asked.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 误解的命令或措辞不当的问题可能导致LLM检索到开发者不希望用户访问的数据。想象一下，一个随意的询问无意中调出了一份详细的记录，揭示了比询问的更多内容。
- en: Permission oversights
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 授权疏忽
- en: Relational databases have intricate permission systems. In the integration process,
    an LLM might be granted broader access than necessary due to oversight or misconfiguration,
    opening doors to data that should remain restricted.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 关系数据库具有复杂的权限系统。在集成过程中，LLM可能会由于疏忽或配置错误而获得比必要的更广泛的访问权限，从而打开了应该保持限制的数据的大门。
- en: Inadvertent data inferences
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 无意的数据推断
- en: LLMs identify patterns. Over multiple interactions, they might collate seemingly
    nonsensitive data, leading to unintended sensitive insights. For example, while
    individual purchases might not disclose much, a pattern might hint at a company’s
    upcoming product launch or a shift in strategy.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs识别模式。在多次交互中，它们可能会收集看似不敏感的数据，导致意外的敏感见解。例如，虽然个别购买可能不会透露太多信息，但模式可能会暗示公司即将推出的产品发布或战略转变。
- en: Auditability and accountability challenges
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 审计性和问责制挑战
- en: Relational databases traditionally offer robust audit trails, tying actions
    to specific users. With LLMs as intermediaries, ensuring that every query and
    data fetch remains traceable is vital. Without clear audit trails, pinpointing
    the origin of a data breach or understanding unexpected behaviors becomes intricate.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 关系型数据库传统上提供强大的审计跟踪，将操作与特定用户关联。随着LLMs（大型语言模型）作为中介，确保每个查询和数据检索都保持可追溯性至关重要。没有清晰的审计跟踪，确定数据泄露的源头或理解意外行为变得复杂。
- en: In conclusion, integrating LLMs with trusted relational databases can improve
    functionality and performance. Still, it is important to use these integrations
    with an awareness of the associated risks. Implementing stringent safeguards and
    oversight can harness the LLM’s capabilities while ensuring data integrity and
    security.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，将LLMs与受信任的关系型数据库集成可以提高功能和性能。然而，在使用这些集成时，重要的是要意识到相关的风险。实施严格的保障措施和监督可以发挥LLM的能力，同时确保数据完整性和安全性。
- en: Vector databases
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向量数据库
- en: '*Vector databases* represent a significant evolution in the way we think about
    and handle data, particularly in the context of machine learning and AI operations.
    Unlike relational databases that organize data into rows and columns, vector databases
    store data as high-dimensional vectors. These vectors are arrays of numbers that
    effectively capture the essence of objects or data points in terms of their features
    or attributes. This structure is advantageous for performing similarity or proximity-based
    operations in a vector space.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量数据库*代表了我们在处理数据方式上的重大进步，尤其是在机器学习和AI操作方面。与将数据组织成行和列的关系型数据库不同，向量数据库将数据存储为高维向量。这些向量是数字数组，能够有效地捕捉对象或数据点的特征或属性的本质。这种结构在执行向量空间中的相似性或邻近性操作时具有优势。'
- en: High-dimensional vectors are adept at handling complex operations like *nearest
    neighbor* searches, which are crucial for many AI applications. These searches
    allow the database to quickly find data points closest to a given query point
    in the vector space, facilitating operations that rely on finding the most similar
    items or patterns. By managing data as *vectors*—essentially mathematical representations
    that encode information about data items—vector databases excel in rapidly retrieving
    and comparing data, thereby enabling efficient and accurate similarity searches
    across vast datasets.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 高维向量擅长处理复杂的操作，如*最近邻*搜索，这对于许多AI应用至关重要。这些搜索允许数据库快速找到向量空间中与给定查询点最近的点，从而促进依赖于找到最相似项或模式的操作。通过将数据作为*向量*——本质上是对数据项信息的数学表示——管理，向量数据库在快速检索和比较数据方面表现出色，从而在庞大的数据集中实现高效和准确的相似性搜索。
- en: 'Integrating your LLM with vector databases via the RAG pattern can supercharge
    its capabilities. By linking the model to these databases, you can harness the
    power of similarity-based searches, allowing for contextually richer responses
    that are more attuned to nuanced user queries. The model can swiftly locate and
    leverage embeddings that resonate with the query’s intent, serving accurate and
    relevant results. For certain this is revolutionary. Let’s examine some examples
    where combining a vector database with the RAG pattern can produce excellent results:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 通过RAG模式将您的LLM与向量数据库集成可以极大地增强其功能。通过将这些数据库与模型链接，您可以利用基于相似性的搜索能力，从而提供更丰富、更符合用户细微查询的响应。模型可以迅速定位并利用与查询意图产生共鸣的嵌入，提供准确和相关的结果。这无疑是革命性的。让我们看看一些将向量数据库与RAG模式结合可以产生优秀结果的例子：
- en: Question answering systems
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 问答系统
- en: Users expect precise and accurate responses when answering questions. RAG systems
    can retrieve relevant documents or data snippets from the vector DB to inform
    the LLM’s responses, making the answers more accurate and detailed than those
    generated from the model’s knowledge alone.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 用户在回答问题时期望得到精确和准确的响应。RAG系统可以从向量数据库检索相关文档或数据片段，以告知LLM的响应，使答案比仅从模型知识生成的答案更准确和详细。
- en: Content recommendation
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 内容推荐
- en: For platforms requiring personalized content recommendations—such as news aggregators,
    streaming services, and ecommerce websites—RAG can enhance recommendation engines
    by retrieving content from the vector DB that closely matches user profiles or
    previous interactions, thus improving user engagement and satisfaction.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要个性化内容推荐的平台——如新闻聚合器、流媒体服务和电子商务网站——RAG可以通过从向量数据库检索与用户配置文件或先前交互紧密匹配的内容来增强推荐引擎，从而提高用户参与度和满意度。
- en: Academic research and summarization
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 学术研究和总结
- en: RAG systems can significantly speed up the research process by retrieving relevant
    documents from the vector DB and providing summaries or connections between them.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: RAG系统可以通过从向量数据库检索相关文档并提供它们之间的摘要或关联来显著加快研究过程。
- en: Customer support
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 客户支持
- en: Chatbots can pull from FAQs, product manuals, and customer interaction logs
    to provide support agents or automated chatbots with the information needed to
    answer customer inquiries effectively and efficiently.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人可以从常见问题解答、产品手册和客户交互日志中提取信息，为支持代理或自动聊天机器人提供有效且高效回答客户询问所需的信息。
- en: Legal and compliance review
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 法律和合规性审查
- en: For applications requiring review of large volumes of legal or regulatory documents,
    RAG can quickly retrieve relevant documents based on queries, thereby aiding in
    compliance checks or legal research.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要审查大量法律或监管文件的用例，RAG可以根据查询快速检索相关文档，从而帮助进行合规性检查或法律研究。
- en: Medical information systems
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗信息系统
- en: In health care, RAG can support diagnostic processes, patient management, and
    medical research by retrieving patient records, scientific studies, and clinical
    trial results relevant to a doctor’s query or a specific medical condition.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在医疗保健领域，RAG可以通过检索与医生查询或特定医疗状况相关的患者记录、科学研究和临床试验结果来支持诊断过程、患者管理和医学研究。
- en: 'This architecture has great power. However, the dynamic nature of vector databases
    and their unique data-handling mechanisms present security challenges that development
    teams must address:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构具有巨大的力量。然而，向量数据库的动态性质及其独特的数据处理机制带来了安全挑战，开发团队必须解决：
- en: Embedding reversibility
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入可逆性
- en: While embeddings in vector databases are abstract numerical representations,
    there is a risk that sophisticated techniques might reverse engineer these embeddings,
    revealing the sensitive information from which they were derived. For instance,
    embeddings created from confidential documents might have unique patterns that
    can hint at the document’s content.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然向量数据库中的嵌入是抽象的数值表示，但存在风险，即复杂的技术可能逆向工程这些嵌入，揭示其来源的敏感信息。例如，从机密文件中创建的嵌入可能具有独特的模式，这可能会暗示文档的内容。
- en: Information leakage via similarity searches
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 通过相似性搜索的信息泄露
- en: Similarity searches, the core advantage of vector databases, can pose a risk
    in the context of sensitive data disclosure. An attacker might infer certain sensitive
    aspects about the dataset by analyzing the results of proximity-based queries.
    If, for instance, a user finds that specific queries yield close matches, they
    might deduce the nature or specifics of the data behind the embeddings.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 相似性搜索，向量数据库的核心优势，在敏感数据泄露的背景下可能构成风险。攻击者通过分析基于邻近度的查询结果，可能会推断出关于数据集的某些敏感方面。例如，如果用户发现特定的查询产生接近匹配的结果，他们可能会推断嵌入背后的数据性质或具体细节。
- en: Data granularity and vector representations
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 数据粒度和向量表示
- en: Depending on the granularity of the embeddings, specific patterns or clusters
    in the vector space might indirectly disclose information about the nature of
    the data. For instance, if particular data points are always clustered together,
    it might reveal relationships or characteristics about the original data.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 根据嵌入的粒度，向量空间中的特定模式或簇可能会间接泄露关于数据性质的信息。例如，如果特定的数据点总是聚集在一起，这可能会揭示原始数据的关系或特征。
- en: Interactions with other systems
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他系统的交互
- en: Often, vector databases aren’t standalone but interact with other systems. The
    flow of embeddings or derived vectors between systems can become a point of exposure,
    especially if data lineage and flow aren’t securely managed.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，向量数据库不是独立的，而是与其他系统交互。系统之间嵌入或派生向量的流动可能成为暴露点，特别是如果数据来源和流动没有安全地管理。
- en: In conclusion, while vector databases enhance the capabilities of LLMs by offering
    a nuanced, similarity-based approach to data, it’s paramount to be vigilant about
    potential avenues of sensitive data disclosure. These databases’ very strengths
    can be leveraged by malicious actors if not safeguarded adequately. Understanding
    these risks and taking proactive measures will be essential in maintaining the
    integrity and confidentiality of the data they manage.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，虽然向量数据库通过提供基于细微差异的相似性方法来增强LLM的功能，但密切关注敏感数据泄露的潜在途径至关重要。如果未能充分保护，这些数据库的强大功能可能会被恶意行为者利用。了解这些风险并采取主动措施对于维护他们管理的数据的完整性和机密性至关重要。
- en: Reducing database risk
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 降低数据库风险
- en: 'Here are some ideas for best practices and mitigation strategies for reducing
    the risks of sensitive data exposure when connecting your LLM to a database:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些最佳实践和缓解策略，用于降低将LLM连接到数据库时敏感数据泄露的风险：
- en: Role-based access control (RBAC)
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 基于角色的访问控制（RBAC）
- en: Ensure that the LLM has restricted access to the database. Grant only the necessary
    permissions and avoid giving the LLM blanket access. Using roles, you can ensure
    the LLM can pull only the information that it absolutely needs.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 确保LLM对数据库的访问受到限制。仅授予必要的权限，避免给予LLM全面访问权限。通过使用角色，你可以确保LLM只能获取它绝对需要的信息。
- en: Data classification
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分类
- en: Categorize your data based on sensitivity (public, internal, confidential, restricted).
    Ensure that LLMs have no access or limited, sanitized access to high-sensitivity
    data categories.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 根据敏感性（公开、内部、机密、受限）对数据进行分类。确保LLM无法访问或仅有限、清洁访问高敏感性数据类别。
- en: Audit trails
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 审计跟踪
- en: Maintain logs of every database query made by the application. Review these
    logs regularly to identify patterns, anomalies, or unintended data access.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 记录应用程序发出的每个数据库查询。定期审查这些日志以识别模式、异常或未预期的数据访问。
- en: Data redaction and masking
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 数据删除和屏蔽
- en: For sensitive fields, consider using redaction (completely hiding the data)
    or masking (obfuscating part of the data) to limit the exposure of sensitive data.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 对于敏感字段，考虑使用删除（完全隐藏数据）或屏蔽（模糊部分数据）来限制敏感数据的暴露。
- en: Input sanitization
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 输入清理
- en: Ensure that any queries or inputs processed by the LLM to access the database
    are sanitized and checked to prevent SQL injection or other data manipulation
    attacks.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 确保LLM处理以访问数据库的任何查询或输入都经过清理并检查，以防止SQL注入或其他数据操纵攻击。
- en: Automated data scanners
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 自动数据扫描器
- en: Use automated tools to scan and flag sensitive information, ensuring such data
    is removed or adequately safeguarded before the LLM can access it.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自动化工具扫描并标记敏感信息，确保在LLM访问之前，此类数据被移除或得到充分保护。
- en: Use views instead of direct table access
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 使用视图而不是直接访问表
- en: For relational databases, consider providing the LLM with access to views that
    are sanitized versions of tables, rather than giving access to the actual raw
    tables.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 对于关系型数据库，考虑为LLM提供访问经过清理的视图，这些视图是表的清洁版本，而不是直接访问实际原始表。
- en: Data retention policies
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 数据保留政策
- en: Implement policies that dictate how long a database should retain certain data.
    Regularly purge data that is no longer needed to reduce the potential data exposure
    footprint.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 实施政策，规定数据库应保留某些数据的时间长度。定期清除不再需要的旧数据，以减少潜在的数据泄露足迹。
- en: Learning from User Interaction
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从用户交互中学习
- en: While simple LLMs don’t modify their behaviors based on usage, we now see increasingly
    common scenarios where developers add this capability. By processing queries,
    feedback, or other forms of input from users, LLMs can refine their understanding,
    provide more accurate responses, and even learn new information over time. This
    dynamic interaction allows the LLM to stay updated, learn from user feedback,
    and tailor its responses to individual or collective user preferences, thus enhancing
    the user experience and the utility of the LLM in practical applications.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然简单的LLM不会根据使用情况修改其行为，但现在我们看到越来越多的场景中，开发者添加了这种能力。通过处理查询、反馈或其他形式的用户输入，LLM可以完善其理解，提供更准确的响应，甚至随着时间的推移学习新信息。这种动态互动使LLM能够保持更新，从用户反馈中学习，并根据个人或集体用户偏好调整其响应，从而提高用户体验和LLM在实际应用中的实用性。
- en: In [Chapter 1](ch01.html#chatbots_breaking_bad), we saw one type of risk associated
    with directly incorporating untrusted user input into your LLM’s knowledge base.
    In that case, Microsoft’s Tay picked up toxic language and bias. However, there
    is another set of risks related to sensitive data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第一章](ch01.html#chatbots_breaking_bad)中，我们看到了直接将不受信任的用户输入纳入LLM知识库的风险之一。在这种情况下，微软的Tay学会了有毒语言和偏见。然而，还存在与敏感数据相关的另一组风险。
- en: When an LLM continually interacts with diverse users, there’s a potential influx
    of sensitive data, intentionally or inadvertently. While the learning capacity
    of an LLM ensures it evolves and becomes more efficient over time, this continuous
    learning can also be its Achilles’ heel when it comes to data protection. The
    very nature of user interaction, being diverse and unpredictable, means there’s
    a potential for users to input or reference personal, confidential, or proprietary
    information.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 当LLM持续与不同用户互动时，可能会无意或有意地涌入大量敏感数据。虽然LLM的学习能力确保其随着时间的推移不断进化并变得更加高效，但这种持续学习在数据保护方面也可能成为其致命弱点。用户互动的本质，即多样性和不可预测性，意味着用户可能会输入或引用个人、机密或专有信息。
- en: For instance, consider a business executive using an LLM to draft a message.
    They might feed the system snippets of confidential business strategies, expecting
    a more polished output. We’ve seen real-world scenarios of this at Samsung and
    other major corporations. Or, a user might query the LLM with personal medical
    symptoms, hoping for insights into potential conditions. In both situations, the
    user shared sensitive data with your application. If you’re using any of this
    data in future training or storing it for real-time access, this information could
    become part of the LLM’s internal knowledge structure, or your application could
    store it for future reference.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一位商业高管使用LLM来撰写信息。他们可能会向系统提供一些机密商业策略的片段，期望得到更精炼的输出。我们在三星和其他大型企业中看到了这种情况的真实案例。或者，用户可能会向LLM查询个人医疗症状，希望了解潜在状况。在这两种情况下，用户都与应用程序分享了敏感数据。如果您未来使用这些数据进行训练或存储以供实时访问，这些信息可能会成为LLM内部知识结构的一部分，或者您的应用程序可能会将其存储以供将来参考。
- en: Furthermore, the challenge with user interactions is that the LLM might only
    sometimes recognize sensitive data when it sees it. Whereas a human might realize
    the importance of a Social Security number, proprietary formula, or a unique business
    strategy, an LLM might treat it as just another piece of information. This lack
    of understanding could lead to scenarios where an LLM, when queried later by another
    user on a related topic, might inadvertently disclose fragments of the previously
    fed sensitive information.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，用户交互的挑战在于LLM可能只在某些时候识别到敏感数据。而人类可能会意识到社会保险号码、专有公式或独特商业策略的重要性，而LLM可能会将其视为另一条信息。这种缺乏理解可能导致LLM在稍后由另一用户就相关主题进行查询时，无意中泄露之前输入的敏感信息片段。
- en: Moreover, with the rise of multimodal LLMs that can process not just text but
    also images, audio, and video, the potential for sensitive data disclosure multiplies.
    A user might input a photo for image recognition, not realizing that the background
    contains identifiable information or copyrighted material.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，随着多模态LLM（能够处理文本、图像、音频和视频）的兴起，敏感数据泄露的潜在风险也随之增加。用户可能输入一张照片进行图像识别，却未意识到背景中包含可识别的信息或受版权保护的材料。
- en: 'To address these issues, employ the following mitigation strategies:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题，采用以下缓解策略：
- en: Clear communication
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 清晰的沟通
- en: Users should be informed about the LLM’s learning capabilities and data retention
    policies. An initial disclaimer about not sharing personal or sensitive information
    can be helpful.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 用户应了解LLM的学习能力和数据保留政策。一个关于不分享个人或敏感信息的初始免责声明可能是有帮助的。
- en: Data sanitization
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 数据净化
- en: Implement algorithms that identify and remove potential PII or other sensitive
    data from user inputs before processing.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 实施算法，在处理之前识别并删除用户输入中可能存在的PII或其他敏感数据。
- en: Temporary memory
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 临时记忆
- en: Consider giving the LLM a temporary memory for user-specific information that
    the system automatically erases after the session ends, ensuring no long-term
    retention of sensitive data.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑给LLM一个用于用户特定信息的临时记忆，系统在会话结束后自动删除，确保没有长期保留敏感数据。
- en: No persistent learning
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 无持续学习
- en: Design the LLM so it doesn’t persistently learn from user interactions, thus
    minimizing the risk of internalizing sensitive data.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 设计LLM，使其不会持续地从用户交互中学习，从而最大限度地减少内部化敏感数据的风险。
- en: Conclusion
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: The core question of this chapter was “Can your LLM know too much?” The answer
    is clearly yes. We need our LLMs to have access to information to be helpful.
    However, we must carefully evaluate what types of information we provide to these
    systems and view that information through a lens asking, “What happens if this
    information is disclosed?” If the penalty for unintentional disclosure is too
    high, then you must carefully weigh the risk of training or equipping your model
    with such data.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的核心问题是“你的LLM知道得太多吗？”答案显然是肯定的。我们需要我们的LLMs能够访问信息以提供帮助。然而，我们必须仔细评估我们提供给这些系统的信息类型，并通过一个透镜来审视这些信息，问自己，“如果这些信息被披露会发生什么？”如果无意泄露的惩罚过高，那么你必须仔细权衡在训练或装备模型时使用此类数据的风险。
- en: 'We studied the three main avenues through which LLMs acquire their vast knowledge:
    training, retrieval-augmented generation, and user interaction. Each method came
    with its own advantages and unique challenges when guarding against unintentional
    data exposure. Key insights garnered include:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了LLMs获取其庞大知识的三条主要途径：训练、检索增强生成和用户交互。每种方法在防止意外数据泄露时都伴随着其自身的优势和独特的挑战。获得的关键见解包括：
- en: Training
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 训练
- en: The foundation of LLMs. While training equips LLMs with vast knowledge, it is
    imperative to vet training data meticulously, eliminating any traces of PII, proprietary
    insights, or controversial content. Periodic audits and employing data sanitization
    strategies are nonnegotiable.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的基础。虽然训练为LLMs配备了大量知识，但仔细审查训练数据、消除任何PII、专有见解或争议内容的痕迹是至关重要的。定期的审计和采用数据净化策略是不可或缺的。
- en: Retrieval-augmented generation
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 检索增强生成
- en: A bridge between the LLM and the vast sea of unstructured data on the web. The
    power of real-time data comes with the responsibility of filtering out sensitive
    or misleading information. When accessing APIs or databases, setting stringent
    access controls is crucial.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: LLM与网络上无结构数据汪洋之间的桥梁。实时数据的强大力量伴随着过滤掉敏感或误导性信息的责任。在访问API或数据库时，设置严格的访问控制至关重要。
- en: Learning from user interaction
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户交互中学习
- en: The most dynamic knowledge source. Every user query carries the potential of
    revealing personal or corporate secrets. Protecting against this necessitates
    clear user communication, data sanitization, and judicious use of persistent learning.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 最动态的知识来源。每个用户查询都可能揭示个人或公司机密。为此，需要明确与用户沟通、数据净化和谨慎使用持续学习。
- en: In conclusion, your LLM’s ability to process vast knowledge stores can be of
    substantial value, but that’s also where the danger may lie. The key is to balance
    empowering LLMs with ensuring they don’t inadvertently “know too much.” This chapter
    was dedicated to understanding this delicate balance, hoping to guide readers
    in harnessing the power of LLMs responsibly, ensuring they are both potent tools
    and trustworthy guardians of sensitive information.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，你的LLM处理大量知识库的能力可能具有重大价值，但危险也可能隐藏在这里。关键在于在赋予LLM能力的同时确保它们不会无意中“知道太多”。本章致力于理解这种微妙的平衡，希望引导读者负责任地利用LLMs的力量，确保它们既是强大的工具也是敏感信息的值得信赖的守护者。
